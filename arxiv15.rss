<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 06 May 2025 14:25:43 +0800</lastBuildDate>
    <item>
      <title>DualDiff: Dual-branch Diffusion Model for Autonomous Driving with Semantic Fusion</title>
      <link>http://arxiv.org/abs/2505.01857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures,&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DualDiff的双重分支条件扩散模型，用于增强多视角驾驶场景生成，旨在提高场景重建的准确性和高保真度。&lt;h4&gt;背景&lt;/h4&gt;现有的驾驶场景重建方法主要依赖3D边界框和前景背景的二值图，这些方法无法充分捕捉场景的复杂性并整合多模态信息。&lt;h4&gt;目的&lt;/h4&gt;提高场景重建的准确性和高保真度，增强多视角驾驶场景生成。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种名为Occupancy Ray Sampling (ORS)的语义丰富的3D表示方法，以实现全面的前景和背景控制。2. 设计了语义融合注意力（SFA）机制，以改善跨模态信息整合。3. 设计了前景感知掩码（FGM）损失，以增强小对象的生成。&lt;h4&gt;主要发现&lt;/h4&gt;DualDiff在FID评分中达到了最先进的性能，并在下游的BEV分割和3D目标检测任务中取得了持续的良好结果。&lt;h4&gt;结论&lt;/h4&gt;DualDiff模型在驾驶场景重建方面具有显著优势，能够有效提升重建的准确性和细节表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and high-fidelity driving scene reconstruction relies on fullyleveraging scene information as conditioning. However, existing approaches,which primarily use 3D bounding boxes and binary maps for foreground andbackground control, fall short in capturing the complexity of the scene andintegrating multi-modal information. In this paper, we propose DualDiff, adual-branch conditional diffusion model designed to enhance multi-view drivingscene generation. We introduce Occupancy Ray Sampling (ORS), a semantic-rich 3Drepresentation, alongside numerical driving scene representation, forcomprehensive foreground and background control. To improve cross-modalinformation integration, we propose a Semantic Fusion Attention (SFA) mechanismthat aligns and fuses features across modalities. Furthermore, we design aforeground-aware masked (FGM) loss to enhance the generation of tiny objects.DualDiff achieves state-of-the-art performance in FID score, as well asconsistently better results in downstream BEV segmentation and 3D objectdetection tasks.</description>
      <author>example@mail.com (Haoteng Li, Zhao Yang, Zezhong Qian, Gongpeng Zhao, Yuqi Huang, Jun Yu, Huazheng Zhou, Longjun Liu)</author>
      <guid isPermaLink="false">2505.01857v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
  <item>
      <title>No Other Representation Component Is Needed: Diffusion Transformers Can Provide Representation Guidance by Themselves</title>
      <link>http://arxiv.org/abs/2505.02831v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Self-Representation Alignment for Diffusion Transformers. arXiv admin  note: text overlap with arXiv:2410.06940 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了Self-Representation Alignment（SRA）方法，通过自我蒸馏的方式，在仅生成训练过程中，提升扩散变换器的内部表示学习，从而加速生成训练并提高生成质量。&lt;h4&gt;背景&lt;/h4&gt;现有方法要么需要引入额外的复杂表示训练框架，要么依赖大规模预训练的表示基础模型来提供表示指导。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要外部表示组件的简单方法，利用扩散变换器自身的独特判别过程来提供表示指导。&lt;h4&gt;方法&lt;/h4&gt;SRA方法通过将扩散变换器早期层输出高噪声的潜在表示与后期层低噪声的潜在表示进行对齐，以逐步增强仅在生成训练过程中的整体表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，将SRA应用于DiTs和SiTs可以获得一致的性能提升。SRA不仅显著优于依赖于辅助的复杂表示训练框架的方法，而且达到了依赖于强大外部表示先验的方法的性能。&lt;h4&gt;结论&lt;/h4&gt;SRA方法能够有效提升扩散变换器的生成训练速度和生成质量，是一种简单且有效的内部表示学习方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/vvvvvjdy/SRA&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies have demonstrated that learning a meaningful internalrepresentation can both accelerate generative training and enhance generationquality of the diffusion transformers. However, existing approaches necessitateto either introduce an additional and complex representation training frameworkor rely on a large-scale, pre-trained representation foundation model toprovide representation guidance during the original generative trainingprocess. In this study, we posit that the unique discriminative processinherent to diffusion transformers enables them to offer such guidance withoutrequiring external representation components. We therefore proposeSelf-Representation A}lignment (SRA), a simple yet straightforward method thatobtain representation guidance through a self-distillation manner.Specifically, SRA aligns the output latent representation of the diffusiontransformer in earlier layer with higher noise to that in later layer withlower noise to progressively enhance the overall representation learning duringonly generative training process. Experimental results indicate that applyingSRA to DiTs and SiTs yields consistent performance improvements. Moreover, SRAnot only significantly outperforms approaches relying on auxiliary, complexrepresentation training frameworks but also achieves performance comparable tomethods that heavily dependent on powerful external representation priors.</description>
      <author>example@mail.com (Dengyang Jiang, Mengmeng Wang, Liuzhuozheng Li, Lei Zhang, Haoyu Wang, Wei Wei, Guang Dai, Yanning Zhang, Jingdong Wang)</author>
      <guid isPermaLink="false">2505.02831v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Grasp the Graph (GtG) 2.0: Ensemble of GNNs for High-Precision Grasp Pose Detection in Clutter</title>
      <link>http://arxiv.org/abs/2505.02664v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 Pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Grasp the Graph 2.0（GtG 2.0）方法，这是一种轻量级且高效的机器人抓取框架，通过集成图神经网络从点云数据中进行高效的几何推理。&lt;h4&gt;背景&lt;/h4&gt;在杂乱的真实环境中进行抓取姿态检测是一个重大挑战，因为噪声和不完整的感觉数据与复杂对象几何形状相结合。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理噪声和不完整数据，并适应复杂对象几何形状的抓取姿态检测方法。&lt;h4&gt;方法&lt;/h4&gt;GtG 2.0方法利用传统的抓取姿态生成器高效地生成7自由度的抓取候选者，并通过包含夹爪爪口内点和周围环境点的集成图神经网络模型对这些候选者进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;GtG 2.0在GraspNet-1Billion基准测试中，与基于假设和测试以及基于图神经网络的方法相比，平均精度提高了35%，并排名前三。&lt;h4&gt;结论&lt;/h4&gt;GtG 2.0在3自由度Delta并联机器人和Kinect-v1摄像头上的实验中，成功率达到91%，杂乱完成率为100%，证明了其灵活性和可靠性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在杂乱的真实环境中进行抓取姿态检测仍然是一个重大挑战，因为噪声和不完整的感觉数据与复杂对象几何形状相结合。本文介绍了Grasp the Graph 2.0（GtG 2.0）方法，这是一种轻量级且高效的机器人抓取框架，通过集成图神经网络从点云数据中进行高效的几何推理。基于GtG 1.0的成功，它证明了图神经网络在抓取检测中的潜力，但受限于完整、无噪声的点云和4自由度抓取的假设，GtG 2.0采用传统的抓取姿态生成器来高效地生成7自由度的抓取候选者。候选者通过包含夹爪爪口内点和周围环境点的集成图神经网络模型进行评估。这种改进的表示提高了抓取检测性能，与使用相同生成器的先前方法相比，GtG 2.0在GraspNet-1Billion基准测试中的平均精度提高了35%，并排名前三。使用3自由度Delta并联机器人和Kinect-v1摄像头进行的实验表明，成功率为91%，杂乱完成率为100%，证明了其灵活性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasp pose detection in cluttered, real-world environments remains asignificant challenge due to noisy and incomplete sensory data combined withcomplex object geometries. This paper introduces Grasp the Graph 2.0 (GtG 2.0)method, a lightweight yet highly effective hypothesis-and-test roboticsgrasping framework which leverages an ensemble of Graph Neural Networks forefficient geometric reasoning from point cloud data. Building on the success ofGtG 1.0, which demonstrated the potential of Graph Neural Networks for graspdetection but was limited by assumptions of complete, noise-free point cloudsand 4-Dof grasping, GtG 2.0 employs a conventional Grasp Pose Generator toefficiently produce 7-Dof grasp candidates. Candidates are assessed with anensemble Graph Neural Network model which includes points within the gripperjaws (inside points) and surrounding contextual points (outside points). Thisimproved representation boosts grasp detection performance over previousmethods using the same generator. GtG 2.0 shows up to a 35% improvement inAverage Precision on the GraspNet-1Billion benchmark compared tohypothesis-and-test and Graph Neural Network-based methods, ranking it amongthe top three frameworks. Experiments with a 3-Dof Delta Parallel robot andKinect-v1 camera show a success rate of 91% and a clutter completion rate of100%, demonstrating its flexibility and reliability.</description>
      <author>example@mail.com (Ali Rashidi Moghadam, Sayedmohammadreza Rastegari, Mehdi Tale Masouleh, Ahmad Kalhor)</author>
      <guid isPermaLink="false">2505.02664v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised training of keypoint-agnostic descriptors for flexible retinal image registration</title>
      <link>http://arxiv.org/abs/2505.02787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的无监督描述符学习方法，用于眼底图像配准，无需依赖关键点检测，并在多个测试中展示了其准确性和性能。&lt;h4&gt;背景&lt;/h4&gt;当前眼底图像配准方法受限于缺乏标记数据，尤其在医疗领域更为显著，这促使了无监督学习技术的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种不依赖关键点检测的无监督描述符学习方法，以实现眼底图像配准。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的无监督描述符学习方法，并在公共眼底图像注册数据集上进行了广泛和全面的比较。同时，测试了多种不同类型的关键点检测器，并提出了新的检测器。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在注册精度上不亚于监督方法，且在不同关键点检测器下均表现出准确性能。&lt;h4&gt;结论&lt;/h4&gt;这项工作在医疗领域利用无监督学习方面迈出了重要一步。&lt;h4&gt;翻译&lt;/h4&gt;Current color fundus image registration approaches are limited, among other things, by the lack of labeled data, which is even more significant in the medical domain, motivating the use of unsupervised learning. Therefore, in this work, we develop a novel unsupervised descriptor learning method that does not rely on keypoint detection. This enables the resulting descriptor network to be agnostic to the keypoint detector used during the registration inference. To validate this approach, we perform an extensive and comprehensive comparison on the reference public retinal image registration dataset. Additionally, we test our method with multiple keypoint detectors of varied nature, even proposing some novel ones. Our results demonstrate that the proposed approach offers accurate registration, not incurring in any performance loss versus supervised methods. Additionally, it demonstrates accurate performance regardless of the keypoint detector used. Thus, this work represents a notable step towards leveraging unsupervised learning in the medical domain.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current color fundus image registration approaches are limited, among otherthings, by the lack of labeled data, which is even more significant in themedical domain, motivating the use of unsupervised learning. Therefore, in thiswork, we develop a novel unsupervised descriptor learning method that does notrely on keypoint detection. This enables the resulting descriptor network to beagnostic to the keypoint detector used during the registration inference.  To validate this approach, we perform an extensive and comprehensivecomparison on the reference public retinal image registration dataset.Additionally, we test our method with multiple keypoint detectors of variednature, even proposing some novel ones. Our results demonstrate that theproposed approach offers accurate registration, not incurring in anyperformance loss versus supervised methods. Additionally, it demonstratesaccurate performance regardless of the keypoint detector used. Thus, this workrepresents a notable step towards leveraging unsupervised learning in themedical domain.</description>
      <author>example@mail.com (David Rivas-Villar, Álvaro S. Hervella, José Rouco, Jorge Novo)</author>
      <guid isPermaLink="false">2505.02787v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection</title>
      <link>http://arxiv.org/abs/2505.02393v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为IEF-VAD的视频异常检测框架，通过融合图像和事件表示来提高检测精度。&lt;h4&gt;背景&lt;/h4&gt;现有的视频异常检测器主要依赖于RGB帧，这限制了捕捉突发事件中的快速或短暂运动。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，该框架能够从RGB视频中直接合成事件表示，并通过不确定性感知的过程与图像特征融合。&lt;h4&gt;方法&lt;/h4&gt;IEF-VAD框架包括：(i) 使用Student-t分布来建模传感器噪声，并通过Laplace近似得到价值级别的逆方差权重；(ii) 应用类似Kalman的帧级更新来平衡不同模态随时间的变化；(iii) 通过迭代细化融合的潜在状态来消除残存的跨模态噪声。&lt;h4&gt;主要发现&lt;/h4&gt;IEF-VAD在多个真实世界的异常检测基准测试中达到了新的水平，并且无需专用的事件传感器或帧级标签。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了合成事件表示在强调通常在RGB帧中未被充分表示的运动线索中的效用，这使得在不同应用中实现准确和鲁棒的视频理解成为可能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大多数现有的视频异常检测器仅依赖于RGB帧，这缺乏捕捉突变或短暂运动线索所需的时间分辨率，而这些线索是异常事件的关键指标。为了解决这一限制，我们提出了用于视频异常检测的图像-事件融合（IEF-VAD）框架，该框架直接从RGB视频中合成事件表示，并通过一种原则性、不确定性感知的过程与图像特征融合。该系统（i）使用Student-t分布来建模传感器噪声，通过Laplace近似推导出价值级别的逆方差权重；（ii）应用类似Kalman的帧级更新来平衡模态随时间的变化；（iii）迭代细化融合的潜在状态，以消除残留的跨模态噪声。无需专用的事件传感器或帧级标签，IEF-VAD在多个真实世界的异常检测基准测试中达到了新的水平。这些发现突出了合成事件表示在强调通常在RGB帧中未被充分表示的运动线索中的效用，使得在不同应用中实现准确和鲁棒的视频理解成为可能。代码和模型可在https://github.com/EavnJeong/IEF-VAD上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most existing video anomaly detectors rely solely on RGB frames, which lackthe temporal resolution needed to capture abrupt or transient motion cues, keyindicators of anomalous events. To address this limitation, we proposeImage-Event Fusion for Video Anomaly Detection (IEF-VAD), a framework thatsynthesizes event representations directly from RGB videos and fuses them withimage features through a principled, uncertainty-aware process. The system (i)models heavy-tailed sensor noise with a Student`s-t likelihood, derivingvalue-level inverse-variance weights via a Laplace approximation; (ii) appliesKalman-style frame-wise updates to balance modalities over time; and (iii)iteratively refines the fused latent state to erase residual cross-modal noise.Without any dedicated event sensor or frame-level labels, IEF-VAD sets a newstate of the art across multiple real-world anomaly detection benchmarks. Thesefindings highlight the utility of synthetic event representations inemphasizing motion cues that are often underrepresented in RGB frames, enablingaccurate and robust video understanding across diverse applications withoutrequiring dedicated event sensors. Code and models are available athttps://github.com/EavnJeong/IEF-VAD.</description>
      <author>example@mail.com (Sungheon Jeong, Jihong Park, Mohsen Imani)</author>
      <guid isPermaLink="false">2505.02393v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Lidar Point Cloud Sampling via Colorization and Super-Resolution of Lidar Imagery</title>
      <link>http://arxiv.org/abs/2505.02049v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages. arXiv admin note: substantial text overlap with  arXiv:2409.11532&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了激光雷达技术的最新进展，特别是在点云分辨率提高和生成360度低分辨率图像方面的突破。这些图像的应用使深度学习技术能够在激光雷达系统中替代传统方法，提高了在恶劣环境下的鲁棒性，并解决了点云几何信息退化的问题。&lt;h4&gt;背景&lt;/h4&gt;背景提到了激光雷达技术的进步，以及由此带来的点云分辨率提升和生成360度低分辨率图像的能力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一个新颖的框架，利用基于深度学习的彩色化和超分辨率技术在激光雷达图像上提取可靠样本，以提高里程计估计的精度。&lt;h4&gt;方法&lt;/h4&gt;该方法采用深度学习技术对激光雷达图像进行彩色化和超分辨率处理，以提高关键点检测的准确性，进而进行有效的点云降采样，从而提升点云注册精度并减少由于几何信息不足或误点引起的误差。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在翻译和旋转误差方面优于先前的方法，并且在使用更少点的情况下取得了更好的效果。&lt;h4&gt;结论&lt;/h4&gt;结论强调了该研究提出的框架在提高激光雷达里程计估计精度方面的有效性，并指出了其在减少错误和提高数据处理效率方面的优势。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in lidar technology have led to improved point cloud resolution as well as the generation of 360 degrees, low-resolution images by encoding depth, reflectivity, or near-infrared light within each pixel. These images enable the application of deep learning (DL) approaches, originally developed for RGB images from cameras to lidar-only systems, eliminating other efforts, such as lidar-camera calibration. Compared with conventional RGB images, lidar imagery demonstrates greater robustness in adverse environmental conditions, such as low light and foggy weather. Moreover, the imaging capability addresses the challenges in environments where the geometric information in point clouds may be degraded, such as long corridors, and dense point clouds may be misleading, potentially leading to drift errors. Therefore, this paper proposes a novel framework that leverages DL-based colorization and super-resolution techniques on lidar imagery to extract reliable samples from lidar point clouds for odometry estimation. The enhanced lidar images, enriched with additional information, facilitate improved keypoint detection, which is subsequently employed for more effective point cloud downsampling. The proposed method enhances point cloud registration accuracy and mitigates mismatches arising from insufficient geometric information or misleading extra points. Experimental results indicate that our approach surpasses previous methods, achieving lower translation and rotation errors while using fewer points.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in lidar technology have led to improved point cloudresolution as well as the generation of 360 degrees, low-resolution images byencoding depth, reflectivity, or near-infrared light within each pixel. Theseimages enable the application of deep learning (DL) approaches, originallydeveloped for RGB images from cameras to lidar-only systems, eliminating otherefforts, such as lidar-camera calibration. Compared with conventional RGBimages, lidar imagery demonstrates greater robustness in adverse environmentalconditions, such as low light and foggy weather. Moreover, the imagingcapability addresses the challenges in environments where the geometricinformation in point clouds may be degraded, such as long corridors, and densepoint clouds may be misleading, potentially leading to drift errors.  Therefore, this paper proposes a novel framework that leverages DL-basedcolorization and super-resolution techniques on lidar imagery to extractreliable samples from lidar point clouds for odometry estimation. The enhancedlidar images, enriched with additional information, facilitate improvedkeypoint detection, which is subsequently employed for more effective pointcloud downsampling. The proposed method enhances point cloud registrationaccuracy and mitigates mismatches arising from insufficient geometricinformation or misleading extra points. Experimental results indicate that ourapproach surpasses previous methods, achieving lower translation and rotationerrors while using fewer points.</description>
      <author>example@mail.com (Sier Ha, Honghao Du, Xianjia Yu, Tomi Westerlund)</author>
      <guid isPermaLink="false">2505.02049v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>JTCSE: Joint Tensor-Modulus Constraints and Cross-Attention for Unsupervised Contrastive Learning of Sentence Embeddings</title>
      <link>http://arxiv.org/abs/2505.02366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的无监督对比学习方法JTCSE，用于自然语言处理中的文本语义嵌入。&lt;h4&gt;背景&lt;/h4&gt;无监督对比学习在自然语言处理领域受到关注，但现有方法忽略了语义表示张量的模量特征，导致对比学习效果不足。&lt;h4&gt;目的&lt;/h4&gt;旨在增强对比学习中正样本之间的对齐，并优化模型对CLS token的注意力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种训练目标，旨在对语义表示张量施加模量约束，并设计了交叉注意力结构以增强模型对CLS token的注意力。&lt;h4&gt;主要发现&lt;/h4&gt;JTCSE在七个语义文本相似度计算任务中表现出色，其双塔集成模型和单塔蒸馏模型优于其他基线，成为当前SOTA。在超过130个零样本下游任务评估中，JTCSE整体优于其他基线。&lt;h4&gt;结论&lt;/h4&gt;JTCSE通过结合模量约束和交叉注意力机制，在文本语义嵌入方面取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised contrastive learning has become a hot research topic in naturallanguage processing. Existing works usually aim at constraining the orientationdistribution of the representations of positive and negative samples in thehigh-dimensional semantic space in contrastive learning, but the semanticrepresentation tensor possesses both modulus and orientation features, and theexisting works ignore the modulus feature of the representations and causeinsufficient contrastive learning. % Therefore, we firstly propose a trainingobjective that aims at modulus constraints on the semantic representationtensor, to strengthen the alignment between the positive samples in contrastivelearning. Therefore, we first propose a training objective that is designed toimpose modulus constraints on the semantic representation tensor, to strengthenthe alignment between positive samples in contrastive learning. Then, theBERT-like model suffers from the phenomenon of sinking attention, leading to alack of attention to CLS tokens that aggregate semantic information. Inresponse, we propose a cross-attention structure among the twin-tower ensemblemodels to enhance the model's attention to CLS token and optimize the qualityof CLS Pooling. Combining the above two motivations, we propose a new\textbf{J}oint \textbf{T}ensor representation modulus constraint and\textbf{C}ross-attention unsupervised contrastive learning \textbf{S}entence\textbf{E}mbedding representation framework JTCSE, which we evaluate in sevensemantic text similarity computation tasks, and the experimental results showthat JTCSE's twin-tower ensemble model and single-tower distillation modeloutperform the other baselines and become the current SOTA. In addition, wehave conducted an extensive zero-shot downstream task evaluation, which showsthat JTCSE outperforms other baselines overall on more than 130 tasks.</description>
      <author>example@mail.com (Tianyu Zong, Hongzhu Yi, Bingkang Shi, Yuanxiang Wang, Jungang Xu)</author>
      <guid isPermaLink="false">2505.02366v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network-Based Reinforcement Learning for Controlling Biological Networks: The GATTACA Framework</title>
      <link>http://arxiv.org/abs/2505.02712v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过深度强化学习控制布尔网络模型，以探索细胞重编程策略，并展示该方法在处理复杂生物系统中的有效性。&lt;h4&gt;背景&lt;/h4&gt;细胞重编程在治疗复杂疾病方面具有潜在的治疗价值，但传统的实验方法耗时且成本高。&lt;h4&gt;目的&lt;/h4&gt;利用深度强化学习来控制布尔网络模型，以发现细胞重编程的策略。&lt;h4&gt;方法&lt;/h4&gt;提出了布尔网络模型在异步更新模式下的新型控制问题，引入了伪吸引子的概念并改进了伪吸引子状态识别的流程，并设计了计算框架来解决控制问题。将图神经网络和图卷积集成到人工神经网络近似器中，以利用生物系统的结构。&lt;h4&gt;主要发现&lt;/h4&gt;在多个来自文献的大规模真实世界生物网络上进行了实验，证明了该方法的可扩展性和有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法在细胞重编程中具有实际应用潜力，并展示了深度强化学习在处理复杂生物系统中的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cellular reprogramming, the artificial transformation of one cell type intoanother, has been attracting increasing research attention due to itstherapeutic potential for complex diseases. However, discovering reprogrammingstrategies through classical wet-lab experiments is hindered by lengthy timecommitments and high costs. In this study, we explore the use of deepreinforcement learning (DRL) to control Boolean network models of complexbiological systems, such as gene regulatory networks and signalling pathwaynetworks. We formulate a novel control problem for Boolean network models underthe asynchronous update mode in the context of cellular reprogramming. Tofacilitate scalability, we consider our previously introduced concept of apseudo-attractor and we improve our procedure for effective identification ofpseudo-attractor states. Finally, we devise a computational framework to solvethe control problem. To leverage the structure of biological systems, weincorporate graph neural networks with graph convolutions into the artificialneural network approximator for the action-value function learned by the DRLagent. Experiments on a number of large real-world biological networks fromliterature demonstrate the scalability and effectiveness of our approach.</description>
      <author>example@mail.com (Andrzej Mizera, Jakub Zarzycki)</author>
      <guid isPermaLink="false">2505.02712v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>fastabx: A library for efficient computation of ABX discriminability</title>
      <link>http://arxiv.org/abs/2505.02692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了名为fastabx的高性能Python库，用于构建ABXdiscrimination任务。&lt;h4&gt;背景&lt;/h4&gt;ABX是一种衡量感兴趣的一般类别之间分离程度的度量，广泛用于评估自监督语音表示中的语音可辨性。然而，由于其缺乏适当的工具，其更广泛的应用受到了限制。&lt;h4&gt;目的&lt;/h4&gt;fastabx通过提供一个能够构建任何类型ABX任务的框架，同时提供快速开发周期所需的效率，来解决这一差距。&lt;h4&gt;方法&lt;/h4&gt;fastabx提供了一种构建ABX任务的方法，并能够计算表示之间的距离。&lt;h4&gt;主要发现&lt;/h4&gt;fastabx将成为更广泛的表示学习社区的有价值资源，使研究人员能够系统地研究可以从学习到的表示中直接提取哪些信息，而不仅限于语音处理领域。&lt;h4&gt;结论&lt;/h4&gt;fastabx的源代码可在https://github.com/bootphon/fastabx上获取。&lt;h4&gt;翻译&lt;/h4&gt;We introduce fastabx, a high-performance Python library for building ABXdiscrimination tasks. ABX is a measure of the separation between generic categories of interest. It has been used extensively to evaluate phonetic discriminability in self-supervised speech representations. However, its broader adoption has been limited by the absence of adequate tools. fastabx addresses this gap by providing a framework capable of constructing any type of ABX task while delivering the efficiency necessary for rapid development cycles, both in task creation and in calculating distances between representations. We believe that fastabx will serve as a valuable resource for the broader representation learning community, enabling researchers to systematically investigate what information can be directly extracted from learned representations across several domains beyond speech processing. The source code is available at https://github.com/bootphon/fastabx.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce fastabx, a high-performance Python library for building ABXdiscrimination tasks. ABX is a measure of the separation between genericcategories of interest. It has been used extensively to evaluate phoneticdiscriminability in self-supervised speech representations. However, itsbroader adoption has been limited by the absence of adequate tools. fastabxaddresses this gap by providing a framework capable of constructing any type ofABX task while delivering the efficiency necessary for rapid developmentcycles, both in task creation and in calculating distances betweenrepresentations. We believe that fastabx will serve as a valuable resource forthe broader representation learning community, enabling researchers tosystematically investigate what information can be directly extracted fromlearned representations across several domains beyond speech processing. Thesource code is available at https://github.com/bootphon/fastabx.</description>
      <author>example@mail.com (Maxime Poli, Emmanuel Chemla, Emmanuel Dupoux)</author>
      <guid isPermaLink="false">2505.02692v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Recombination: Systematic Real Data Augmentation Using Robotic Targets for LiDAR Perception Validation</title>
      <link>http://arxiv.org/abs/2505.02476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Pre-print for IEEE IAVVC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为点云重组的方法，用于增强现实世界点云数据，以解决智能移动系统在开放世界应用中基于LiDAR感知的验证问题。&lt;h4&gt;背景&lt;/h4&gt;由于真实环境条件的可变性，基于LiDAR的感知验证是一个挑战。虚拟模拟可以生成任意场景，但缺乏物理传感器特性；而真实世界数据提供真实的传感器特性，但难以控制影响因素。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过整合实验室环境中测量的物理目标对象的点云，系统地增强捕获的点云场景，以创建大量和多样化的可重复、物理准确的测试场景。&lt;h4&gt;方法&lt;/h4&gt;点云重组方法通过将实验室环境中测量的物理目标对象的点云与真实世界场景中的点云进行整合，从而增强真实世界点云数据。&lt;h4&gt;主要发现&lt;/h4&gt;使用Ouster OS1-128 Rev7传感器，该方法展示了如何将具有不同服装和姿势的人形目标添加到真实世界的城市和乡村场景中，以实现可重复的位置定位。重组的场景与真实传感器的输出非常接近，从而实现了有针对性的测试、可扩展的故障分析和系统安全性的提高。&lt;h4&gt;结论&lt;/h4&gt;通过提供受控且传感器真实的数据，该方法使得对特定传感器及其算法局限性的结论更加可靠，例如物体检测。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于真实环境条件的变化，基于LiDAR的智能移动系统在开放世界应用中的感知验证仍然是一个挑战。虚拟模拟允许在受控条件下生成任意场景，但缺乏物理传感器特性，如强度响应或材料依赖效应。相比之下，真实世界数据提供了真实的传感器特性，但提供了较少的控制影响因素，阻碍了充分的验证。现有的方法通过在场景之间转移对象来增强真实世界点云数据，但这些问题没有考虑验证，并且由于依赖于经验数据而在可控性方面有限。我们通过提出点云重组来解决这些限制，该方法通过整合在受控实验室环境中测量的物理目标对象的点云，系统地增强捕获的点云场景。因此，能够创建大量和多样化的可重复、物理准确的测试场景，与具有注册3D网格的现象感知遮挡相关。使用Ouster OS1-128 Rev7传感器，我们展示了如何通过添加具有不同服装和姿势的人形目标来增强真实世界的城市和乡村场景，以实现可重复的位置定位。我们表明，重组的场景与真实传感器的输出非常接近，从而实现了有针对性的测试、可扩展的故障分析和系统安全性的提高。通过提供受控但传感器真实的数据，我们的方法使得对特定传感器及其算法局限性的结论更加可靠，例如物体检测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The validation of LiDAR-based perception of intelligent mobile systemsoperating in open-world applications remains a challenge due to the variabilityof real environmental conditions. Virtual simulations allow the generation ofarbitrary scenes under controlled conditions but lack physical sensorcharacteristics, such as intensity responses or material-dependent effects. Incontrast, real-world data offers true sensor realism but provides less controlover influencing factors, hindering sufficient validation. Existing approachesaddress this problem with augmentation of real-world point cloud data bytransferring objects between scenes. However, these methods do not considervalidation and remain limited in controllability because they rely on empiricaldata. We solve these limitations by proposing Point Cloud Recombination, whichsystematically augments captured point cloud scenes by integrating point cloudsacquired from physical target objects measured in controlled laboratoryenvironments. Thus enabling the creation of vast amounts and varieties ofrepeatable, physically accurate test scenes with respect to phenomena-awareocclusions with registered 3D meshes. Using the Ouster OS1-128 Rev7 sensor, wedemonstrate the augmentation of real-world urban and rural scenes with humanoidtargets featuring varied clothing and poses, for repeatable positioning. Weshow that the recombined scenes closely match real sensor outputs, enablingtargeted testing, scalable failure analysis, and improved system safety. Byproviding controlled yet sensor-realistic data, our method enables trustworthyconclusions about the limitations of specific sensors in compound with theiralgorithms, e.g., object detection.</description>
      <author>example@mail.com (Hubert Padusinski, Christian Steinhauser, Christian Scherl, Julian Gaal, Jacob Langner)</author>
      <guid isPermaLink="false">2505.02476v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Aerodynamic and structural airfoil shape optimisation via Transfer Learning-enhanced Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2505.02634v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于迁移学习、多目标深度强化学习（DRL）的方法，能够根据气动和结构标准优化任何机翼的几何形状。&lt;h4&gt;背景&lt;/h4&gt;研究背景未在摘要中提及。&lt;h4&gt;目的&lt;/h4&gt;旨在展示该方法，通过最大化升阻比（$C_L/C_D$）同时保持机翼的结构完整性（通过最大厚度建模），并使用不同的迁移学习（TL）策略训练DRL智能体。&lt;h4&gt;方法&lt;/h4&gt;将DRL智能体的性能与粒子群优化（PSO）进行比较，PSO是一种传统的无梯度优化方法。&lt;h4&gt;主要发现&lt;/h4&gt;DRL智能体能够执行多目标形状优化，DRL方法在计算效率和形状优化性能方面优于PSO，迁移学习增强的DRL智能体在性能上与DRL相当，同时节省了大量计算资源。&lt;h4&gt;结论&lt;/h4&gt;DRL方法在多目标形状优化中表现优异，迁移学习可以显著提高DRL的性能并节省计算资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The main objective of this paper is to introduce a transferlearning-enhanced, multi-objective, deep reinforcement learning (DRL)methodology that is able to optimise the geometry of any airfoil based onconcomitant aerodynamic and structural criteria. To showcase the method, we aimto maximise the lift-to-drag ratio $C_L/C_D$ while preserving the structuralintegrity of the airfoil -- as modelled by its maximum thickness -- and trainthe DRL agent using a list of different transfer learning (TL) strategies. Theperformance of the DRL agent is compared with Particle Swarm Optimisation(PSO), a traditional gradient-free optimisation method. Results indicate thatDRL agents are able to perform multi-objective shape optimisation, that the DRLapproach outperforms PSO in terms of computational efficiency and shapeoptimisation performance, and that the TL-enhanced DRL agent achievesperformance comparable to the DRL one, while further saving substantialcomputational resources.</description>
      <author>example@mail.com (David Ramos, Lucas Lacasa, Eusebio Valero, Gonzalo Rubio)</author>
      <guid isPermaLink="false">2505.02634v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>VAEmo: Efficient Representation Learning for Visual-Audio Emotion with Knowledge Injection</title>
      <link>http://arxiv.org/abs/2505.02331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Source code and pre-trained models will be available at  https://github.com/MSA-LMC/VAEmo&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VAEmo是一种高效的两阶段框架，用于基于情感联合视觉-听觉表示学习，并通过外部知识注入解决情感识别的挑战。&lt;h4&gt;背景&lt;/h4&gt;音频视觉情感识别（AVER）旨在从非语言视觉-听觉线索中推断人类情感，具有模态互补和语言无关的优势，但面临情感表达的不确定性、跨模态表达差异和可靠标注数据稀缺等问题。&lt;h4&gt;目的&lt;/h4&gt;提出VAEmo，以解决AVER中的挑战，实现高效的跨模态情感语义建模。&lt;h4&gt;方法&lt;/h4&gt;第一阶段，通过掩码重建和对比性目标，在大型以说话者为中心的VA语料库上预训练一个统一且轻量级的表示网络；第二阶段，使用多模态大型语言模型根据设计的思维链提示生成详细的情感描述，并通过双路径对比学习将丰富的文本语义注入到VA表示中。&lt;h4&gt;主要发现&lt;/h4&gt;VAEmo在多个下游AVER基准测试中实现了最先进的性能，证明了统一跨模态编码和情感感知语义指导对高效、通用VA情感表示的益处。&lt;h4&gt;结论&lt;/h4&gt;VAEmo通过统一跨模态编码和情感感知语义指导，为高效、通用的VA情感表示提供了新的解决方案，并实现了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audiovisual emotion recognition (AVER) aims to infer human emotions fromnonverbal visual-audio (VA) cues, offering modality-complementary andlanguage-agnostic advantages. However, AVER remains challenging due to theinherent ambiguity of emotional expressions, cross-modal expressivedisparities, and the scarcity of reliably annotated data. Recentself-supervised AVER approaches have introduced strong multimodalrepresentations, yet they predominantly rely on modality-specific encoders andcoarse content-level alignment, limiting fine-grained emotional semanticmodeling. To address these issues, we propose VAEmo, an efficient two-stageframework for emotion-centric joint VA representation learning with externalknowledge injection. In Stage 1, a unified and lightweight representationnetwork is pre-trained on large-scale speaker-centric VA corpora via maskedreconstruction and contrastive objectives, mitigating the modality gap andlearning expressive, complementary representations without emotion labels. InStage 2, multimodal large language models automatically generate detailedaffective descriptions according to our well-designed chain-of-thoughtprompting for only a small subset of VA samples; these rich textual semanticsare then injected by aligning their corresponding embeddings with VArepresentations through dual-path contrastive learning, further bridging theemotion gap. Extensive experiments on multiple downstream AVER benchmarks showthat VAEmo achieves state-of-the-art performance with a compact design,highlighting the benefit of unified cross-modal encoding and emotion-awaresemantic guidance for efficient, generalizable VA emotion representations.</description>
      <author>example@mail.com (Hao Cheng, Zhiwei Zhao, Yichao He, Zhenzhen Hu, Jia Li, Meng Wang, Richang Hong)</author>
      <guid isPermaLink="false">2505.02331v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Sparse Ellipsoidal Radial Basis Function Network for Point Cloud Surface Representation</title>
      <link>http://arxiv.org/abs/2505.02350v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用稀疏椭球径向基函数网络逼近点云上签名的距离函数（SDF）的机器学习方法，实现了紧凑且精确的表面表示。&lt;h4&gt;背景&lt;/h4&gt;点云表面表示是计算机图形学和视觉中的基本问题。&lt;h4&gt;目的&lt;/h4&gt;通过使用尽可能少的椭球径向基函数（ERBFs）来逼近SDF，实现点云的紧凑和精确的表面表示。&lt;h4&gt;方法&lt;/h4&gt;引入了一种动态多目标优化策略，自适应地添加正则化项，并联合优化ERBFs的权重、中心、形状和方向。为了提高计算效率，采用了基于最近邻的数据结构，并将每个核的计算并行化在CUDA上。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多个基准数据集上的广泛实验，证明了该方法在准确性、鲁棒性和计算效率方面优于之前的稀疏表示方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为点云表面表示提供了一种高效且准确的解决方案，并公开了相应的代码。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云表面表示是计算机图形学和视觉中的基本问题。本文提出了一种机器学习方法，使用稀疏椭球径向基函数网络逼近点云的签名距离函数（SDF），从而实现紧凑且精确的表面表示。给定由点云构建的网格点上的SDF值，我们的方法尽可能准确地逼近SDF，即使用尽可能少的椭球径向基函数（ERBFs）来表示点云的SDF。为了平衡稀疏性和逼近精度，引入了一种动态多目标优化策略，该策略自适应地添加正则化项，并联合优化ERBFs的权重、中心、形状和方向。为了提高计算效率，采用了一种基于最近邻的数据结构，将函数计算限制在每个高斯核中心附近的点。进一步地，每个核的计算在CUDA上进行了并行化，这显著提高了优化速度。此外，设计了一种基于分层八叉树的细化策略进行训练。具体来说，使用八叉树晶格结构中的粗网格点初始化和优化网络参数。随后，逐步引入细晶格点以加速模型收敛并提高训练效率。在多个基准数据集上的广泛实验表明，我们的方法在准确性、鲁棒性和计算效率方面优于之前的稀疏表示方法。相应的代码可在https://github.com/lianbobo/SE-RBFNet.git上公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud surface representation is a fundamental problem in computergraphics and vision. This paper presents a machine learning approach forapproximating the signed distance function (SDF) of a point cloud using sparseellipsoidal radial basis function networks, enabling a compact and accuratesurface representation. Given the SDF values defined on the grid pointsconstructed from the point cloud, our method approximates the SDF accuratelywith as few ellipsoidal radial basis functions (ERBFs) as possible, i.e.,represent the SDF of a point cloud by sparse ERBFs. To balance sparsity andapproximation precision, a dynamic multi-objective optimization strategy isintroduced, which adaptively adds the regularization terms and jointlyoptimizes the weights, centers, shapes, and orientations of ERBFs. To improvecomputational efficiency, a nearest-neighbor-based data structure is employed,restricting function calculations to points near each Gaussian kernel center.The computations for each kernel are further parallelized on CUDA, whichsignificantly improves the optimization speed. Additionally, a hierarchicaloctree-based refinement strategy is designed for training. Specifically, theinitialization and optimization of network parameters are conducted usingcoarse grid points in the octree lattice structure. Subsequently, fine latticepoints are progressively incorporated to accelerate model convergence andenhance training efficiency. Extensive experiments on multiple benchmarkdatasets demonstrate that our method outperforms previous sparse representationapproaches in terms of accuracy, robustness, and computational efficiency. Thecorresponding code is publicly available athttps://github.com/lianbobo/SE-RBFNet.git.</description>
      <author>example@mail.com (Bobo Lian, Dandan Wang, Chenjian Wu, Minxin Chen)</author>
      <guid isPermaLink="false">2505.02350v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>TEMPURA: Temporal Event Masked Prediction and Understanding for Reasoning in Action</title>
      <link>http://arxiv.org/abs/2505.01583v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TEMPURA的视频理解框架，旨在提高视觉语言模型对视频的时序理解和因果事件关系处理能力。&lt;h4&gt;背景&lt;/h4&gt;当前视觉语言模型在处理视频时，要么压缩视频标记以降低时间分辨率，要么将视频视为未分割的流，这导致无法精确识别事件边界和建模因果依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提高视频时序理解能力，实现细粒度的时间定位。&lt;h4&gt;方法&lt;/h4&gt;TEMPURA采用两阶段训练框架：首先，通过掩码事件预测推理重建缺失事件并生成因果解释；其次，学习视频分割和密集描述，将视频分解为非重叠事件，并配以详细的时间戳对齐描述。&lt;h4&gt;主要发现&lt;/h4&gt;TEMPURA在时序定位和突出检测基准测试中优于强基线模型，证明了将因果推理与细粒度时序分割相结合可以提升视频理解能力。&lt;h4&gt;结论&lt;/h4&gt;TEMPURA框架通过结合因果推理和细粒度时序分割，有效提高了视觉语言模型对视频的理解能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：理解因果事件关系和实现视频中的细粒度时间定位对视觉语言模型来说仍然具有挑战性。现有方法要么压缩视频标记以降低时间分辨率，要么将视频视为未分割的流，这模糊了细粒度事件边界并限制了因果依赖关系的建模。我们提出了TEMPURA（用于动作推理的时序事件掩码预测和理解），一个两阶段训练框架，用于增强视频时序理解。TEMPURA首先应用掩码事件预测推理来重建缺失事件，并从密集事件注释中生成逐步的因果解释，从中汲取有效的填充技术。然后，TEMPURA学习执行视频分割和密集描述，将视频分解为非重叠事件，并配以详细的时间戳对齐描述。我们在我们自己编纂的VER数据集上训练TEMPURA，该数据集包含100万个训练实例和50万个具有时间对齐事件描述和结构化推理步骤的视频。在时序定位和突出检测基准测试中进行的实验表明，TEMPURA优于强基线模型，证实了将因果推理与细粒度时序分割相结合可提高视频理解能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding causal event relationships and achieving fine-grained temporalgrounding in videos remain challenging for vision-language models. Existingmethods either compress video tokens to reduce temporal resolution, or treatvideos as unsegmented streams, which obscures fine-grained event boundaries andlimits the modeling of causal dependencies. We propose TEMPURA (Temporal EventMasked Prediction and Understanding for Reasoning in Action), a two-stagetraining framework that enhances video temporal understanding. TEMPURA firstapplies masked event prediction reasoning to reconstruct missing events andgenerate step-by-step causal explanations from dense event annotations, drawinginspiration from effective infilling techniques. TEMPURA then learns to performvideo segmentation and dense captioning to decompose videos intonon-overlapping events with detailed, timestamp-aligned descriptions. We trainTEMPURA on VER, a large-scale dataset curated by us that comprises 1M traininginstances and 500K videos with temporally aligned event descriptions andstructured reasoning steps. Experiments on temporal grounding and highlightdetection benchmarks demonstrate that TEMPURA outperforms strong baselinemodels, confirming that integrating causal reasoning with fine-grained temporalsegmentation leads to improved video understanding.</description>
      <author>example@mail.com (Jen-Hao Cheng, Vivian Wang, Huayu Wang, Huapeng Zhou, Yi-Hao Peng, Hou-I Liu, Hsiang-Wei Huang, Kuang-Ming Chen, Cheng-Yen Yang, Wenhao Chai, Yi-Ling Chen, Vibhav Vineet, Qin Cai, Jenq-Neng Hwang)</author>
      <guid isPermaLink="false">2505.01583v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Feature Upsampling Methods for Vision Foundation Models using Interactive Segmentation</title>
      <link>http://arxiv.org/abs/2505.02075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉基础模型（VFMs）在密集预测任务中的有效性，并提出了一种任务无关的特征上采样模块来提高VFM特征分辨率。&lt;h4&gt;背景&lt;/h4&gt;随着VFMs的流行，人们对其在密集预测任务中的效果越来越感兴趣，但由于VFM通常产生低分辨率特征，限制了其直接应用。&lt;h4&gt;目的&lt;/h4&gt;为了评估特征上采样方法在VFM上的有效性，本研究以交互式分割（IS）作为新的基准。&lt;h4&gt;方法&lt;/h4&gt;通过使用任务无关的特征上采样模块来提高VFM特征分辨率，并利用交互式分割作为评估环境。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，选择合适的上采样策略可以显著提高VFM特征的质量。&lt;h4&gt;结论&lt;/h4&gt;本研究提出的方法可以有效地提高VFM在密集预测任务中的性能。&lt;h4&gt;翻译&lt;/h4&gt;Vision Foundation Models (VFMs) are large-scale, pre-trained models that serve as general-purpose backbones for various computer vision tasks. As VFMs' popularity grows, there is an increasing interest in understanding their effectiveness for dense prediction tasks. However, VFMs typically produce low-resolution features, limiting their direct applicability in this context. One way to tackle this limitation is by employing a task-agnostic feature upsampling module that refines VFM features resolution. To assess the effectiveness of this approach, we investigate Interactive Segmentation (IS) as a novel benchmark for evaluating feature upsampling methods on VFMs. Due to its inherent multimodal input, consisting of an image and a set of user-defined clicks, as well as its dense mask output, IS creates a challenging environment that demands comprehensive visual scene understanding. Our benchmarking experiments show that selecting appropriate upsampling strategies significantly improves VFM features quality. The code is released at https://github.com/havrylovv/iSegProbe&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Foundation Models (VFMs) are large-scale, pre-trained models thatserve as general-purpose backbones for various computer vision tasks. As VFMs'popularity grows, there is an increasing interest in understanding theireffectiveness for dense prediction tasks. However, VFMs typically producelow-resolution features, limiting their direct applicability in this context.One way to tackle this limitation is by employing a task-agnostic featureupsampling module that refines VFM features resolution. To assess theeffectiveness of this approach, we investigate Interactive Segmentation (IS) asa novel benchmark for evaluating feature upsampling methods on VFMs. Due to itsinherent multimodal input, consisting of an image and a set of user-definedclicks, as well as its dense mask output, IS creates a challenging environmentthat demands comprehensive visual scene understanding. Our benchmarkingexperiments show that selecting appropriate upsampling strategies significantlyimproves VFM features quality. The code is released athttps://github.com/havrylovv/iSegProbe</description>
      <author>example@mail.com (Volodymyr Havrylov, Haiwen Huang, Dan Zhang, Andreas Geiger)</author>
      <guid isPermaLink="false">2505.02075v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>LISAT: Language-Instructed Segmentation Assistant for Satellite Imagery</title>
      <link>http://arxiv.org/abs/2505.02829v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 10 figures, 19 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为LISAt的视觉-语言模型，用于描述复杂遥感场景、回答相关问题并分割感兴趣的对象。&lt;h4&gt;背景&lt;/h4&gt;现有的分割模型可以识别图像中的预定义对象，但难以处理涉及多个对象的复杂用户查询。&lt;h4&gt;目的&lt;/h4&gt;开发LISAt模型，使其能够描述复杂遥感场景，回答相关问题，并分割感兴趣的对象。&lt;h4&gt;方法&lt;/h4&gt;在新的地理空间推理-分割数据集GRES上训练LISAt，该数据集包含27,615个标注和9,205张图像，以及包含超过100万个问答对的模态预训练数据集PreGRES。&lt;h4&gt;主要发现&lt;/h4&gt;LISAt在遥感描述任务上优于现有的地理空间基础模型RS-GPT4V，在推理分割任务上超越了最先进的开放域模型，分别提高了10.04%和143.36%。&lt;h4&gt;结论&lt;/h4&gt;LISAt模型、数据集和代码可在https://lisat-bair.github.io/LISAt/获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Segmentation models can recognize a pre-defined set of objects in images.However, models that can reason over complex user queries that implicitly referto multiple objects of interest are still in their infancy. Recent advances inreasoning segmentation--generating segmentation masks from complex, implicitquery text--demonstrate that vision-language models can operate across an opendomain and produce reasonable outputs. However, our experiments show that suchmodels struggle with complex remote-sensing imagery. In this work, we introduceLISAt, a vision-language model designed to describe complex remote-sensingscenes, answer questions about them, and segment objects of interest. Wetrained LISAt on a new curated geospatial reasoning-segmentation dataset, GRES,with 27,615 annotations over 9,205 images, and a multimodal pretrainingdataset, PreGRES, containing over 1 million question-answer pairs. LISAtoutperforms existing geospatial foundation models such as RS-GPT4V by over10.04 % (BLEU-4) on remote-sensing description tasks, and surpassesstate-of-the-art open-domain models on reasoning segmentation tasks by 143.36 %(gIoU). Our model, datasets, and code are available athttps://lisat-bair.github.io/LISAt/</description>
      <author>example@mail.com (Jerome Quenum, Wen-Han Hsieh, Tsung-Han Wu, Ritwik Gupta, Trevor Darrell, David M. Chan)</author>
      <guid isPermaLink="false">2505.02829v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>CircuitFusion: Multimodal Circuit Representation Learning for Agile Chip Design</title>
      <link>http://arxiv.org/abs/2505.02168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025 (https://openreview.net/forum?id=rbnf7oe6JQ)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CircuitFusion，这是一种多模态和实现感知的电路编码器，能够将电路编码成支持不同下游电路设计任务的一般表示。&lt;h4&gt;背景&lt;/h4&gt;AI的快速发展依赖于IC的支持，但数字IC的日益复杂使得传统的IC设计过程成本高昂且耗时。&lt;h4&gt;目的&lt;/h4&gt;提出CircuitFusion，以解决传统IC设计过程的成本和时间问题，并提高电路设计效率。&lt;h4&gt;方法&lt;/h4&gt;CircuitFusion融合了三种电路模态：硬件代码、结构图和功能摘要，并识别了电路的四个独特属性：并行执行、功能等效变换、多个设计阶段和电路可重用性。&lt;h4&gt;主要发现&lt;/h4&gt;CircuitFusion在五个不同的电路设计任务上表现优于特定于每个任务的SOTA监督方法，证明了其泛化能力和学习电路固有属性的能力。&lt;h4&gt;结论&lt;/h4&gt;CircuitFusion为电路设计提供了一种新的、高效的方法，能够显著提高设计效率和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancements of AI rely on the support of ICs. However, the growingcomplexity of digital ICs makes the traditional IC design process costly andtime-consuming. In recent years, AI-assisted IC design methods havedemonstrated great potential, but most methods are task-specific or focussolely on the circuit structure in graph format, overlooking other circuitmodalities with rich functional information. In this paper, we introduceCircuitFusion, the first multimodal and implementation-aware circuit encoder.It encodes circuits into general representations that support differentdownstream circuit design tasks. To learn from circuits, we propose to fusethree circuit modalities: hardware code, structural graph, and functionalitysummary. More importantly, we identify four unique properties of circuits:parallel execution, functional equivalent transformation, multiple designstages, and circuit reusability. Based on these properties, we propose newstrategies for both the development and application of CircuitFusion: 1) Duringcircuit preprocessing, utilizing the parallel nature of circuits, we split eachcircuit into multiple sub-circuits based on sequential-element boundaries, eachsub-circuit in three modalities. 2) During CircuitFusion pre-training, weintroduce three self-supervised tasks that utilize equivalent transformationsboth within and across modalities. 3) When applying CircuitFusion to downstreamtasks, we propose a new retrieval-augmented inference method, which retrievessimilar known circuits as a reference for predictions. It improves fine-tuningperformance and even enables zero-shot inference. Evaluated on five differentcircuit design tasks, CircuitFusion consistently outperforms the SOTAsupervised method specifically developed for every single task, demonstratingits generalizability and ability to learn circuits' inherent properties.</description>
      <author>example@mail.com (Wenji Fang, Shang Liu, Jing Wang, Zhiyao Xie)</author>
      <guid isPermaLink="false">2505.02168v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Generative Sign-description Prompts with Multi-positive Contrastive Learning for Sign Language Recognition</title>
      <link>http://arxiv.org/abs/2505.02304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GSP-MC的生成式手语描述提示多正对比学习方法，用于手语识别，通过结合检索增强生成和领域特定的大型语言模型，以及多步提示工程和专家验证的手语语料库，生成精确的多部分描述。&lt;h4&gt;背景&lt;/h4&gt;手语识别（SLR）在创建准确标注方面面临挑战，因为同时手动和非手动信号固有的复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，将生成式大型语言模型（LLMs）集成到手语识别任务中。&lt;h4&gt;方法&lt;/h4&gt;GSP-MC方法利用检索增强生成（RAG）与领域特定LLMs，结合多步提示工程和专家验证的手语语料库。它还采用双编码器架构，通过概率匹配双向对齐层次骨骼特征与多个文本描述（全局、同义词和部分级别）。该方法结合全局和部分级别的损失，优化KL散度，确保所有相关文本-骨骼对之间的鲁棒对齐，同时捕获手势级别的语义和详细的部件动态。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在中文SLR500（达到97.1%）和土耳其AUTSL数据集（97.07%准确率）上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该方法的多语言有效性突显了其在开发包容性通信技术方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：手语识别（SLR）在创建准确标注方面面临基本挑战，因为同时手动和非手动信号固有的复杂性。据我们所知，这是首次将生成式大型语言模型（LLMs）集成到手语识别任务中的工作。我们提出了一种名为GSP-MC的新颖的生成式手语描述提示多正对比学习方法，该方法利用检索增强生成（RAG）与领域特定LLMs，结合多步提示工程和专家验证的手语语料库，以生成精确的多部分描述。GSP-MC方法还采用双编码器架构，通过概率匹配双向对齐层次骨骼特征与多个文本描述（全局、同义词和部分级别）。我们的方法结合全局和部分级别的损失，优化KL散度，以确保所有相关文本-骨骼对之间的鲁棒对齐，同时捕获手势级别的语义和详细的部件动态。实验表明，该方法在中文SLR500（达到97.1%）和土耳其AUTSL数据集（97.07%准确率）上优于现有方法。该方法的多语言有效性突显了其在开发包容性通信技术方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sign language recognition (SLR) faces fundamental challenges in creatingaccurate annotations due to the inherent complexity of simultaneous manual andnon-manual signals. To the best of our knowledge, this is the first work tointegrate generative large language models (LLMs) into SLR tasks. We propose anovel Generative Sign-description Prompts Multi-positive Contrastive learning(GSP-MC) method that leverages retrieval-augmented generation (RAG) withdomain-specific LLMs, incorporating multi-step prompt engineering andexpert-validated sign language corpora to produce precise multipartdescriptions. The GSP-MC method also employs a dual-encoder architecture tobidirectionally align hierarchical skeleton features with multiple textdescriptions (global, synonym, and part level) through probabilistic matching.Our approach combines global and part-level losses, optimizing KL divergence toensure robust alignment across all relevant text-skeleton pairs while capturingboth sign-level semantics and detailed part dynamics. Experiments demonstratestate-of-the-art performance against existing methods on the Chinese SLR500(reaching 97.1%) and Turkish AUTSL datasets (97.07% accuracy). The method'scross-lingual effectiveness highlight its potential for developing inclusivecommunication technologies.</description>
      <author>example@mail.com (Siyu Liang, Yunan Li, Wentian Xin, Huizhou Chen, Xujie Liu, Kang Liu, Qiguang Miao)</author>
      <guid isPermaLink="false">2505.02304v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Ranked differences Pearson correlation dissimilarity with an application to electricity users time series clustering</title>
      <link>http://arxiv.org/abs/2505.02173v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的时间序列聚类方法，用于将具有相似行为的时间序列数据分类成组。&lt;h4&gt;背景&lt;/h4&gt;时间序列聚类是一种无监督学习方法，用于将时间序列数据分类。它广泛应用于医疗保健、金融、经济、能源和气候科学等领域。已有多种时间序列聚类方法被提出并使用了四十多年。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的相似性度量方法，并将其应用于时间序列聚类。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为“排序皮尔逊相关差异度”（RDPC）的新差异度量方法，该方法结合了加权平均的指定分数的最大元素差异与已知的皮尔逊相关差异度。该方法被整合到层次聚类中，并与其他聚类算法的性能进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;RDPC算法在涉及不同季节模式、趋势和峰值的复杂情况下优于其他算法。&lt;h4&gt;结论&lt;/h4&gt;通过将泰国的随机样本客户聚类到具有独特特征的七个组中，展示了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：时间序列聚类是一种无监督学习方法，用于将具有相似行为的时间序列数据分类成组。它在医疗保健、金融、经济、能源和气候科学等应用中得到了使用。几十年来，已经提出了几种时间序列聚类方法。大多数方法都集中在测量时间序列之间的欧几里得距离或关联差异度。在这项工作中，我们提出了一种新的差异度量方法，称为排序皮尔逊相关差异度（RDPC），它将指定分数的最大元素差异的加权平均与已知的皮尔逊相关差异度相结合。它被整合到层次聚类中。性能得到了评估，并与现有的聚类算法进行了比较。结果表明，RDPC算法在涉及不同季节模式、趋势和峰值的复杂情况下优于其他算法。最后，我们通过将来自泰国电力消耗时间序列数据集的随机样本客户聚类到具有独特特征的七个组中，证明了我们方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series clustering is an unsupervised learning method for classifyingtime series data into groups with similar behavior. It is used in applicationssuch as healthcare, finance, economics, energy, and climate science. Severaltime series clustering methods have been introduced and used for over fourdecades. Most of them focus on measuring either Euclidean distances orassociation dissimilarities between time series. In this work, we propose a newdissimilarity measure called ranked Pearson correlation dissimilarity (RDPC),which combines a weighted average of a specified fraction of the largestelement-wise differences with the well-known Pearson correlation dissimilarity.It is incorporated into hierarchical clustering. The performance is evaluatedand compared with existing clustering algorithms. The results show that theRDPC algorithm outperforms others in complicated cases involving differentseasonal patterns, trends, and peaks. Finally, we demonstrate our method byclustering a random sample of customers from a Thai electricity consumptiontime series dataset into seven groups with unique characteristics.</description>
      <author>example@mail.com (Chutiphan Charoensuk, Nathakhun Wiroonsri)</author>
      <guid isPermaLink="false">2505.02173v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>GarmentGS: Point-Cloud Guided Gaussian Splatting for High-Fidelity Non-Watertight 3D Garment Reconstruction</title>
      <link>http://arxiv.org/abs/2505.02126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GarmentGS的新方法，用于高保真地重建服装表面，并生成非密封的单层网格。该方法通过密集点云引导，实现快速重建和高质量的渲染效果。&lt;h4&gt;背景&lt;/h4&gt;传统的3D服装制作需要大量的人工操作，导致时间和劳动力成本高。3D高斯Splatting在3D场景重建和渲染方面取得了突破性进展，为3D服装重建开辟了新的途径。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决传统方法中由于高斯原元的无结构和不规则性质导致的难以重建高保真、非密封的3D服装的问题。&lt;h4&gt;方法&lt;/h4&gt;GarmentGS方法引入了一个快速密集点云重建模块，可以在10分钟内完成服装点云重建，并使用密集点云引导高斯原元的移动、展平和旋转，以在服装表面上实现更好的分布，达到优异的渲染效果和几何精度。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了快速训练和实时渲染，同时保持了有竞争力的质量。&lt;h4&gt;结论&lt;/h4&gt;GarmentGS方法通过密集点云引导，能够高效地重建高保真服装表面，为3D服装设计提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统的3D服装制作需要大量的人工操作，导致时间和劳动力成本高。近年来，3D高斯Splatting在3D场景重建和渲染方面取得了突破性进展，引起了广泛关注，并为3D服装重建开辟了新的途径。然而，由于高斯原元的无结构和不规则性质，难以重建高保真、非密封的3D服装。在本文中，我们提出了一种名为GarmentGS的密集点云引导方法，可以重建具有高几何精度的服装表面，并生成非密封的单层网格。我们的方法引入了一个快速密集点云重建模块，可以在10分钟内完成服装点云重建，比传统方法所需的几个小时要快。此外，我们使用密集点云来引导高斯原元的移动、展平和旋转，以在服装表面上实现更好的分布，从而实现优异的渲染效果和几何精度。通过数值和可视化比较，我们的方法在保持有竞争力的质量的同时，实现了快速训练和实时渲染。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional 3D garment creation requires extensive manual operations,resulting in time and labor costs. Recently, 3D Gaussian Splatting has achievedbreakthrough progress in 3D scene reconstruction and rendering, attractingwidespread attention and opening new pathways for 3D garment reconstruction.However, due to the unstructured and irregular nature of Gaussian primitives,it is difficult to reconstruct high-fidelity, non-watertight 3D garments. Inthis paper, we present GarmentGS, a dense point cloud-guided method that canreconstruct high-fidelity garment surfaces with high geometric accuracy andgenerate non-watertight, single-layer meshes. Our method introduces a fastdense point cloud reconstruction module that can complete garment point cloudreconstruction in 10 minutes, compared to traditional methods that requireseveral hours. Furthermore, we use dense point clouds to guide the movement,flattening, and rotation of Gaussian primitives, enabling better distributionon the garment surface to achieve superior rendering effects and geometricaccuracy. Through numerical and visual comparisons, our method achieves fasttraining and real-time rendering while maintaining competitive quality.</description>
      <author>example@mail.com (Zhihao Tang, Shenghao Yang, Hongtao Zhang, Mingbo Zhao)</author>
      <guid isPermaLink="false">2505.02126v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications</title>
      <link>http://arxiv.org/abs/2505.02179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为ProDisc-VAD的弱监督视频异常检测框架，通过两个协同组件解决标签模糊性问题，提高了特征学习的区分度。&lt;h4&gt;背景&lt;/h4&gt;现有的基于MIL的WS-VAD方法在处理标签模糊性时，难以进行有效的特征学习。&lt;h4&gt;目的&lt;/h4&gt;提出ProDisc-VAD框架，旨在解决标签模糊性问题，提高异常检测的准确性。&lt;h4&gt;方法&lt;/h4&gt;ProDisc-VAD包含原型交互层（PIL）和伪实例判别增强（PIDE）损失。PIL使用少量可学习的原型进行正常性建模，而PIDE损失通过对比学习增强最可靠的极端评分实例的区分度。&lt;h4&gt;主要发现&lt;/h4&gt;ProDisc-VAD在ShanghaiTech和UCF-Crime数据集上取得了优异的AUC值（97.98%和87.12%），且参数数量仅为0.4M，远低于基于ViT的方法。&lt;h4&gt;结论&lt;/h4&gt;ProDisc-VAD框架在效率和性能方面表现出色，代码已开源。&lt;h4&gt;翻译&lt;/h4&gt;摘要：使用多个实例学习（MIL）的弱监督视频异常检测（WS-VAD）由于标签模糊性而受到阻碍，影响了特征学习的区分度。我们提出了ProDisc-VAD，一个高效的框架，通过两个协同组件来解决这个问题。原型交互层（PIL）通过使用一组可学习的原型提供受控的正常性建模，建立了一个稳健的基线，而不会被主导的正常数据所淹没。伪实例判别增强（PIDE）损失通过仅对最可靠的极端评分实例（最高/最低评分）应用有针对性的对比学习来增强可分性。ProDisc-VAD仅使用0.4M参数就实现了强大的AUCs（ShanghaiTech：97.98%，UCF-Crime：87.12%），比最近的基于ViT的方法如VadCLIP少800多倍，展示了卓越的效率以及最先进的性能。代码可在https://github.com/modadundun/ProDisc-VAD上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Weakly-supervised video anomaly detection (WS-VAD) using Multiple InstanceLearning (MIL) suffers from label ambiguity, hindering discriminative featurelearning. We propose ProDisc-VAD, an efficient framework tackling this via twosynergistic components. The Prototype Interaction Layer (PIL) providescontrolled normality modeling using a small set of learnable prototypes,establishing a robust baseline without being overwhelmed by dominant normaldata. The Pseudo-Instance Discriminative Enhancement (PIDE) loss boostsseparability by applying targeted contrastive learning exclusively to the mostreliable extreme-scoring instances (highest/lowest scores). ProDisc-VADachieves strong AUCs (97.98% ShanghaiTech, 87.12% UCF-Crime) using only 0.4Mparameters, over 800x fewer than recent ViT-based methods like VadCLIP,demonstrating exceptional efficiency alongside state-of-the-art performance.Code is available at https://github.com/modadundun/ProDisc-VAD.</description>
      <author>example@mail.com (Tao Zhu, Qi Yu, Xinru Dong, Shiyu Li, Yue Liu, Jinlong Jiang, Lei Shu)</author>
      <guid isPermaLink="false">2505.02179v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning of Limit Order Book: A Comprehensive Study and Benchmarking</title>
      <link>http://arxiv.org/abs/2505.02139v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对订单簿（LOB）表示学习进行了系统性比较研究，以识别提取可迁移、紧凑特征的有效方法，这些特征能够捕捉订单簿的基本属性。&lt;h4&gt;背景&lt;/h4&gt;订单簿是金融市场最基本的数据之一，提供了市场动态的精细视图，但由于其强烈的自相关性、交叉特征约束和特征尺度差异，处理深度模型时面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在分析现有方法中代表学习与特定下游任务的紧密耦合，并提出一种有效的方法来提取可迁移的特征。&lt;h4&gt;方法&lt;/h4&gt;引入了LOBench，一个使用真实中国A股市场数据的标准化基准，提供精心制作的数据集、统一的预处理、一致的评估指标和强大的基线。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了订单簿表示对于各种下游任务的充分性和必要性，并突出了其相对于传统任务特定端到端模型和高级表示学习模型在通用时间序列上的优势。&lt;h4&gt;结论&lt;/h4&gt;本研究建立了一个可重复的框架，并为未来的研究提供了明确的指导，数据集和代码将公开可用。&lt;h4&gt;翻译&lt;/h4&gt;The Limit Order Book (LOB), the mostly fundamental data of the financial market, provides a fine-grained view of market dynamics while poses significant challenges in dealing with the esteemed deep models due to its strong autocorrelation, cross-feature constraints, and feature scale disparity. Existing approaches often tightly couple representation learning with specific downstream tasks in an end-to-end manner, failed to analyze the learned representations individually and explicitly, limiting their reusability and generalization. This paper conducts the first systematic comparative study of LOB representation learning, aiming to identify the effective way of extracting transferable, compact features that capture essential LOB properties. We introduce LOBench, a standardized benchmark with real China A-share market data, offering curated datasets, unified preprocessing, consistent evaluation metrics, and strong baselines. Extensive experiments validate the sufficiency and necessity of LOB representations for various downstream tasks and highlight their advantages over both the traditional task-specific end-to-end models and the advanced representation learning models for general time series. Our work establishes a reproducible framework and provides clear guidelines for future research. Datasets and code will be publicly available at https://github.com/financial-simulation-lab/LOBench.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Limit Order Book (LOB), the mostly fundamental data of the financialmarket, provides a fine-grained view of market dynamics while poses significantchallenges in dealing with the esteemed deep models due to its strongautocorrelation, cross-feature constrains, and feature scale disparity.Existing approaches often tightly couple representation learning with specificdownstream tasks in an end-to-end manner, failed to analyze the learnedrepresentations individually and explicitly, limiting their reusability andgeneralization. This paper conducts the first systematic comparative study ofLOB representation learning, aiming to identify the effective way of extractingtransferable, compact features that capture essential LOB properties. Weintroduce LOBench, a standardized benchmark with real China A-share marketdata, offering curated datasets, unified preprocessing, consistent evaluationmetrics, and strong baselines. Extensive experiments validate the sufficiencyand necessity of LOB representations for various downstream tasks and highlighttheir advantages over both the traditional task-specific end-to-end models andthe advanced representation learning models for general time series. Our workestablishes a reproducible framework and provides clear guidelines for futureresearch. Datasets and code will be publicly available athttps://github.com/financial-simulation-lab/LOBench.</description>
      <author>example@mail.com (Muyao Zhong, Yushi Lin, Peng Yang)</author>
      <guid isPermaLink="false">2505.02139v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Local Herb Identification Using Transfer Learning: A CNN-Powered Mobile Application for Nepalese Flora</title>
      <link>http://arxiv.org/abs/2505.02147v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 6 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新颖的深度学习方法，使用卷积神经网络和迁移学习技术对60种不同的草药进行分类，旨在解决在生物多样性丰富的地区（如尼泊尔）中草药分类的挑战。&lt;h4&gt;背景&lt;/h4&gt;草药分类在植物研究中是一个关键的挑战，特别是在像尼泊尔这样生物多样性丰富的地区。&lt;h4&gt;目的&lt;/h4&gt;开发一个鲁棒的机器学习模型，用于对草药进行分类，以解决现有草药识别方法中的局限性。&lt;h4&gt;方法&lt;/h4&gt;研究使用了12000张草药图片的手动整理数据集，并采用了多种模型架构，包括DenseNet121、ResNet50、VGG16、InceptionV3、EfficientNetV2和Vision Transformer（VIT），其中DenseNet121最终表现出最佳性能。还应用了数据增强和正则化技术来减轻过拟合并提高模型的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;DenseNet121模型在草药分类任务中表现出优越的性能。&lt;h4&gt;结论&lt;/h4&gt;这项工作推动了草药分类技术的发展，同时保护了传统的植物学知识并促进了草药的可持续利用。&lt;h4&gt;翻译&lt;/h4&gt;Herb classification presents a critical challenge in botanical research, particularly in regions with rich biodiversity such as Nepal. This study introduces a novel deep learning approach for classifying 60 different herb species using Convolutional Neural Networks (CNNs) and transfer learning techniques. Using a manually curated dataset of 12,000 herb images, we developed a robust machine learning model that addresses existing limitations in herb recognition methodologies. Our research employed multiple model architectures, including DenseNet121, 50-layer Residual Network (ResNet50), 16-layer Visual Geometry Group Network (VGG16), InceptionV3, EfficientNetV2, and Vision Transformer (VIT), with DenseNet121 ultimately demonstrating superior performance. Data augmentation and regularization techniques were applied to mitigate overfitting and enhance the generalizability of the model. This work advances herb classification techniques, preserving traditional botanical knowledge and promoting sustainable herb utilization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Herb classification presents a critical challenge in botanical research,particularly in regions with rich biodiversity such as Nepal. This studyintroduces a novel deep learning approach for classifying 60 different herbspecies using Convolutional Neural Networks (CNNs) and transfer learningtechniques. Using a manually curated dataset of 12,000 herb images, wedeveloped a robust machine learning model that addresses existing limitationsin herb recognition methodologies. Our research employed multiple modelarchitectures, including DenseNet121, 50-layer Residual Network (ResNet50),16-layer Visual Geometry Group Network (VGG16), InceptionV3, EfficientNetV2,and Vision Transformer (VIT), with DenseNet121 ultimately demonstratingsuperior performance. Data augmentation and regularization techniques wereapplied to mitigate overfitting and enhance the generalizability of the model.This work advances herb classification techniques, preserving traditionalbotanical knowledge and promoting sustainable herb utilization.</description>
      <author>example@mail.com (Prajwal Thapa, Mridul Sharma, Jinu Nyachhyon, Yagya Raj Pandeya)</author>
      <guid isPermaLink="false">2505.02147v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Weakly-supervised Audio Temporal Forgery Localization via Progressive Audio-language Co-learning Network</title>
      <link>http://arxiv.org/abs/2505.01880v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9pages, 5figures. This paper has been accepted for IJCAI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种渐进式音频-语言共学习网络（LOCO），用于定位音频时间伪造区域，旨在解决现有方法依赖昂贵且难以获取的精细标注的问题。&lt;h4&gt;背景&lt;/h4&gt;音频时间伪造定位（ATFL）旨在识别部分伪造音频中被故意修改的精确伪造区域。现有的ATFL方法依赖于使用精细标注来训练高效的网络，而这种标注在现实场景中获取成本高昂且具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了克服上述挑战，本文旨在提出一种能够在弱监督场景下提升定位性能的方法。&lt;h4&gt;方法&lt;/h4&gt;本文提出的LOCO网络采用共学习和自监督的方法，具体包括：1）设计了一个音频-语言共学习模块，通过从时间和全局视角对齐语义来捕获伪造一致性特征；2）通过结合语音级别的标注和可学习提示构建伪造感知提示，动态地将语义先验融入时间内容特征；3）应用伪造定位模块，基于融合的伪造类别激活序列生成伪造提案；4）引入渐进式细化策略，生成伪帧级标签，利用监督语义对比学习增强真实内容与伪造内容之间的语义区别，从而不断优化伪造感知特征。&lt;h4&gt;主要发现&lt;/h4&gt;大量的实验表明，提出的LOCO在网络性能上达到了在三个公开基准测试上的SOTA（最先进的技术水平）。&lt;h4&gt;结论&lt;/h4&gt;本文提出的LOCO方法能够有效地定位音频时间伪造区域，并且在公开基准测试中取得了优异的性能，为音频伪造检测领域提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio temporal forgery localization (ATFL) aims to find the precise forgeryregions of the partial spoof audio that is purposefully modified. Existing ATFLmethods rely on training efficient networks using fine-grained annotations,which are obtained costly and challenging in real-world scenarios. To meet thischallenge, in this paper, we propose a progressive audio-language co-learningnetwork (LOCO) that adopts co-learning and self-supervision manners to promptlocalization performance under weak supervision scenarios. Specifically, anaudio-language co-learning module is first designed to capture forgeryconsensus features by aligning semantics from temporal and global perspectives.In this module, forgery-aware prompts are constructed by using utterance-levelannotations together with learnable prompts, which can incorporate semanticpriors into temporal content features dynamically. In addition, a forgerylocalization module is applied to produce forgery proposals based on fusedforgery-class activation sequences. Finally, a progressive refinement strategyis introduced to generate pseudo frame-level labels and leverage supervisedsemantic contrastive learning to amplify the semantic distinction between realand fake content, thereby continuously optimizing forgery-aware features.Extensive experiments show that the proposed LOCO achieves SOTA performance onthree public benchmarks.</description>
      <author>example@mail.com (Junyan Wu, Wenbo Xu, Wei Lu, Xiangyang Luo, Rui Yang, Shize Guo)</author>
      <guid isPermaLink="false">2505.01880v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Deep Representation Learning for Electronic Design Automation</title>
      <link>http://arxiv.org/abs/2505.02105v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在电子设计自动化（EDA）领域中，表示学习作为一种有效技术，如何利用自然表示工作流程元素作为图像、网格和图，通过解决电路复杂性增加和严格的功率、性能和面积（PPA）要求，自动从复杂数据格式中提取有意义的特征。&lt;h4&gt;背景&lt;/h4&gt;表示学习已成为EDA算法中的一种有效技术，它利用工作流程元素的自然表示，如图像、网格和图。&lt;h4&gt;目的&lt;/h4&gt;本文旨在分析表示学习在EDA中的应用，包括基础概念，以及时间预测、可布线分析和自动化布局等任务的先前工作和案例研究。&lt;h4&gt;方法&lt;/h4&gt;本文介绍了基于图像的方法、基于图的方法和混合多模态解决方案等关键技术，以展示表示学习在路由、时序和寄生预测方面的改进。&lt;h4&gt;主要发现&lt;/h4&gt;本文提供的进步展示了表示学习在提高当前集成电路设计流程中的效率、准确性和可扩展性方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;表示学习在EDA领域有广泛的应用前景，可以显著提高集成电路设计的效率和质量。&lt;h4&gt;翻译&lt;/h4&gt;Representation learning has become an effective technique utilized by electronic design automation (EDA) algorithms, which leverage the natural representation of workflow elements as images, grids, and graphs. By addressing challenges related to the increasing complexity of circuits and stringent power, performance, and area (PPA) requirements, representation learning facilitates the automatic extraction of meaningful features from complex data formats, including images, grids, and graphs. This paper examines the application of representation learning in EDA, covering foundational concepts and analyzing prior work and case studies on tasks that include timing prediction, routability analysis, and automated placement. Key techniques, including image-based methods, graph-based approaches, and hybrid multimodal solutions, are presented to illustrate the improvements provided in routing, timing, and parasitic prediction. The provided advancements demonstrate the potential of representation learning to enhance efficiency, accuracy, and scalability in current integrated circuit design flows.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning has become an effective technique utilized byelectronic design automation (EDA) algorithms, which leverage the naturalrepresentation of workflow elements as images, grids, and graphs. By addressingchallenges related to the increasing complexity of circuits and stringentpower, performance, and area (PPA) requirements, representation learningfacilitates the automatic extraction of meaningful features from complex dataformats, including images, grids, and graphs. This paper examines theapplication of representation learning in EDA, covering foundational conceptsand analyzing prior work and case studies on tasks that include timingprediction, routability analysis, and automated placement. Key techniques,including image-based methods, graph-based approaches, and hybrid multimodalsolutions, are presented to illustrate the improvements provided in routing,timing, and parasitic prediction. The provided advancements demonstrate thepotential of representation learning to enhance efficiency, accuracy, andscalability in current integrated circuit design flows.</description>
      <author>example@mail.com (Pratik Shrestha, Saran Phatharodom, Alec Aversa, David Blankenship, Zhengfeng Wu, Ioannis Savidis)</author>
      <guid isPermaLink="false">2505.02105v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Segment Any RGB-Thermal Model with Language-aided Distillation</title>
      <link>http://arxiv.org/abs/2505.01950v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2412.04220 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SARTM是一个针对RGB-T语义分割的框架，通过改进SAM模型，并结合语义理解模块，提升了分割性能。&lt;h4&gt;背景&lt;/h4&gt;SAM模型在RGB数据上表现良好，但在RGB-T语义分割上有局限性。&lt;h4&gt;目的&lt;/h4&gt;提出SARTM框架，以增强SAM模型在RGB-T语义分割中的应用。&lt;h4&gt;方法&lt;/h4&gt;1. 通过添加LoRA层微调SAM模型，保留其泛化能力和分割能力。2. 引入语言信息作为训练指导。3. 引入跨模态知识蒸馏模块（CMKD）以实现模态适应。4. 调整SAM的分割头，并加入辅助语义分割头，融合多尺度特征。&lt;h4&gt;主要发现&lt;/h4&gt;SARTM在三个多模态RGB-T语义分割基准测试中（MFNET、PST900、FMB）表现出色，优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;SARTM显著提升了RGB-T语义分割的性能，适用于各种视觉条件。&lt;h4&gt;翻译&lt;/h4&gt;The recent Segment Anything Model (SAM) demonstrates strong instance segmentation performance across various downstream tasks. However, SAM is trained solely on RGB data, limiting its direct applicability to RGB-thermal (RGB-T) semantic segmentation. Given that RGB-T provides a robust solution for scene understanding in adverse weather and lighting conditions, such as low-light and overexposure, we propose a novel framework, SARTM, which customizes the powerful SAM for RGB-T semantic segmentation. Our key idea is to unleash the potential of SAM while introduce semantic understanding modules for RGB-T data pairs. Specifically, our framework first involves fine tuning the original SAM by adding extra LoRA layers, aiming at preserving SAM's strong generalization and segmentation capabilities for downstream tasks. Secondly, we introduce language information as guidance for training our SARTM. To address cross-modal inconsistencies, we introduce a Cross-Modal Knowledge Distillation (CMKD) module that effectively achieves modality adaptation while maintaining its generalization capabilities. This semantic module enables the minimization of modality gaps and alleviates semantic ambiguity, facilitating the combination of any modality under any visual conditions. Furthermore, we enhance the segmentation performance by adjusting the segmentation head of SAM and incorporating an auxiliary semantic segmentation head, which integrates multi-scale features for effective fusion. Extensive experiments are conducted across three multi-modal RGBT semantic segmentation benchmarks: MFNET, PST900, and FMB. Both quantitative and qualitative results consistently demonstrate that the proposed SARTM significantly outperforms state-of-the-art approaches across a variety of conditions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent Segment Anything Model (SAM) demonstrates strong instancesegmentation performance across various downstream tasks. However, SAM istrained solely on RGB data, limiting its direct applicability to RGB-thermal(RGB-T) semantic segmentation. Given that RGB-T provides a robust solution forscene understanding in adverse weather and lighting conditions, such as lowlight and overexposure, we propose a novel framework, SARTM, which customizesthe powerful SAM for RGB-T semantic segmentation. Our key idea is to unleashthe potential of SAM while introduce semantic understanding modules for RGB-Tdata pairs. Specifically, our framework first involves fine tuning the originalSAM by adding extra LoRA layers, aiming at preserving SAM's stronggeneralization and segmentation capabilities for downstream tasks. Secondly, weintroduce language information as guidance for training our SARTM. To addresscross-modal inconsistencies, we introduce a Cross-Modal KnowledgeDistillation(CMKD) module that effectively achieves modality adaptation whilemaintaining its generalization capabilities. This semantic module enables theminimization of modality gaps and alleviates semantic ambiguity, facilitatingthe combination of any modality under any visual conditions. Furthermore, weenhance the segmentation performance by adjusting the segmentation head of SAMand incorporating an auxiliary semantic segmentation head, which integratesmulti-scale features for effective fusion. Extensive experiments are conductedacross three multi-modal RGBT semantic segmentation benchmarks: MFNET, PST900,and FMB. Both quantitative and qualitative results consistently demonstratethat the proposed SARTM significantly outperforms state-of-the-art approachesacross a variety of conditions.</description>
      <author>example@mail.com (Dong Xing, Xianxun Zhu, Wei Zhou, Qika Lin, Hang Yang, Yuqing Wang)</author>
      <guid isPermaLink="false">2505.01950v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Using Knowledge Graphs to harvest datasets for efficient CLIP model training</title>
      <link>http://arxiv.org/abs/2505.02746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用智能网络搜索策略和知识图谱来训练高质量CLIP模型的方法，显著减少了所需数据量，从而降低了训练成本。&lt;h4&gt;背景&lt;/h4&gt;训练高质量的CLIP模型通常需要大量的数据集，这限制了特定领域模型的发展，尤其是在CLIP模型覆盖不佳的领域，同时也增加了训练成本。&lt;h4&gt;目的&lt;/h4&gt;为了解决需要对CLIP模型训练过程进行精细控制的科学研究的挑战。&lt;h4&gt;方法&lt;/h4&gt;通过采用智能网络搜索策略和知识图谱，从少量数据中从头开始训练一个鲁棒的CLIP模型。&lt;h4&gt;主要发现&lt;/h4&gt;只需要10M张图片就可以构建一个专门针对生物有机体的专家基础模型，并引入了包含3300万张图片和4600万文本描述的EntityNet数据集，这显著缩短了训练通用CLIP模型所需的时间。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地降低了训练高质量CLIP模型的数据需求，为特定领域模型的发展提供了新的可能性，并减少了训练成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training high-quality CLIP models typically requires enormous datasets, whichlimits the development of domain-specific models -- especially in areas thateven the largest CLIP models do not cover well -- and drives up training costs.This poses challenges for scientific research that needs fine-grained controlover the training procedure of CLIP models. In this work, we show that byemploying smart web search strategies enhanced with knowledge graphs, a robustCLIP model can be trained from scratch with considerably less data.Specifically, we demonstrate that an expert foundation model for livingorganisms can be built using just 10M images. Moreover, we introduce EntityNet,a dataset comprising 33M images paired with 46M text descriptions, whichenables the training of a generic CLIP model in significantly reduced time.</description>
      <author>example@mail.com (Simon Ging, Sebastian Walter, Jelena Bratulić, Johannes Dienert, Hannah Bast, Thomas Brox)</author>
      <guid isPermaLink="false">2505.02746v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Federated Graph Learning: A Data Condensation Perspective</title>
      <link>http://arxiv.org/abs/2505.02573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了联邦图学习（Federated Graph Learning）的一种新范式FedGM，旨在解决现有联邦图学习中数据异质性和隐私风险的问题。&lt;h4&gt;背景&lt;/h4&gt;联邦图学习通过多客户端的图促进图神经网络（GNNs）的协作训练，但现有方法在联邦优化中过于依赖模型参数或梯度的通信，未能有效处理由复杂多变的图分布引入的数据异质性。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为压缩图的优化载体，以及新的FGL范式FedGM，以解决FGL的数据异质性和隐私风险问题。&lt;h4&gt;方法&lt;/h4&gt;FedGM利用广义的压缩图共识聚合分布式图的综合知识，同时通过单次传输压缩数据来最小化通信成本和隐私风险。&lt;h4&gt;主要发现&lt;/h4&gt;在六个公开数据集上的大量实验表明，FedGM优于最先进的基础方案，突显了其在新型FGL范式中的潜力。&lt;h4&gt;结论&lt;/h4&gt;FedGM是一种有效的联邦图学习新方法，可以解决数据异质性和隐私风险问题，具有潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated graph learning is a widely recognized technique that promotescollaborative training of graph neural networks (GNNs) by multi-clientgraphs.However, existing approaches heavily rely on the communication of modelparameters or gradients for federated optimization and fail to adequatelyaddress the data heterogeneity introduced by intricate and diverse graphdistributions. Although some methods attempt to share additional messages amongthe server and clients to improve federated convergence during communication,they introduce significant privacy risks and increase communication overhead.To address these issues, we introduce the concept of a condensed graph as anovel optimization carrier to address FGL data heterogeneity and propose a newFGL paradigm called FedGM. Specifically, we utilize a generalized condensationgraph consensus to aggregate comprehensive knowledge from distributed graphs,while minimizing communication costs and privacy risks through a singletransmission of the condensed data. Extensive experiments on six publicdatasets consistently demonstrate the superiority of FedGM overstate-of-the-art baselines, highlighting its potential for a novel FGLparadigm.</description>
      <author>example@mail.com (Hao Zhang, Xunkai Li, Yinlin Zhu, Lianglin Hu)</author>
      <guid isPermaLink="false">2505.02573v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>An LLM-Empowered Low-Resolution Vision System for On-Device Human Behavior Understanding</title>
      <link>http://arxiv.org/abs/2505.01743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Llambda的劳动力节约系统，旨在支持低分辨率的人机行为理解（HBU）。该系统通过利用有限的标记数据和大量的未标记数据来指导大视觉语言模型（LVLM）生成信息丰富的字幕，从而有效微调LVLM模型以理解低分辨率视频。&lt;h4&gt;背景&lt;/h4&gt;随着大视觉语言模型（LVLMs）的快速发展，它们在生成关于低分辨率视觉系统（如深度、热成像和红外）的人机行为理解（HBU）描述方面具有超越传统标注的潜力。然而，现有的LVLM方法无法很好地理解低分辨率数据，因为它们主要设计用于处理高分辨率数据，如RGB图像。&lt;h4&gt;目的&lt;/h4&gt;提出一种劳动力节约的系统Llambda，以支持低分辨率HBU。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种对比性导向的数据标注器，可以从长低分辨率视频中捕获与行为相关的信息，并通过对比学习生成高质量的伪标签。2. 提出了一种物理知识引导的字幕生成器，利用空间和时间一致性检查来减轻伪标签中的错误。3. 使用基于LoRA的高效微调技术来确保设备上的部署。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，Llambda在区域尺度真实测试平台上使用三个不同的低分辨率数据集进行评估时，平均在Bert-Score上优于几个最先进的LVLM系统，提高了40.03%。&lt;h4&gt;结论&lt;/h4&gt;Llambda系统通过有效利用有限标记数据和大量未标记数据，能够显著提高LVLM模型对低分辨率视频的理解能力，并在实际应用中展现出优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancements in Large Vision Language Models (LVLMs) offer thepotential to surpass conventional labeling by generating richer, more detaileddescriptions of on-device human behavior understanding (HBU) in low-resolutionvision systems, such as depth, thermal, and infrared. However, existing largevision language model (LVLM) approaches are unable to understand low-resolutiondata well as they are primarily designed for high-resolution data, such as RGBimages. A quick fixing approach is to caption a large amount of low-resolutiondata, but it requires a significant amount of labor-intensive annotationefforts. In this paper, we propose a novel, labor-saving system, Llambda,designed to support low-resolution HBU. The core idea is to leverage limitedlabeled data and a large amount of unlabeled data to guide LLMs in generatinginformative captions, which can be combined with raw data to effectivelyfine-tune LVLM models for understanding low-resolution videos in HBU. First, wepropose a Contrastive-Oriented Data Labeler, which can capturebehavior-relevant information from long, low-resolution videos and generatehigh-quality pseudo labels for unlabeled data via contrastive learning. Second,we propose a Physical-Knowledge Guided Captioner, which utilizes spatial andtemporal consistency checks to mitigate errors in pseudo labels. Therefore, itcan improve LLMs' understanding of sequential data and then generatehigh-quality video captions. Finally, to ensure on-device deployability, weemploy LoRA-based efficient fine-tuning to adapt LVLMs for low-resolution data.We evaluate Llambda using a region-scale real-world testbed and three distinctlow-resolution datasets, and the experiments show that Llambda outperformsseveral state-of-the-art LVLM systems up to $40.03\%$ on average Bert-Score.</description>
      <author>example@mail.com (Siyang Jiang, Bufang Yang, Lilin Xu, Mu Yuan, Yeerzhati Abudunuer, Kaiwei Liu, Liekang Zeng, Hongkai Chen, Zhenyu Yan, Xiaofan Jiang, Guoliang Xing)</author>
      <guid isPermaLink="false">2505.01743v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Embracing Diffraction: A Paradigm Shift in Wireless Sensing and Communication</title>
      <link>http://arxiv.org/abs/2505.01625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出将电磁衍射作为无线信号传播中的一个重要且未被充分利用的机制，并探讨了其在环境感知和通信中的应用。&lt;h4&gt;背景&lt;/h4&gt;无线信号在现代社会中至关重要，而电磁衍射现象通常被视为次要效应或校正因子。&lt;h4&gt;目的&lt;/h4&gt;通过理解和利用衍射效应，提高无线系统的感知能力和通信策略的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;引入了一个通用的优化框架，以形式化利用衍射的概念，并讨论了边缘衍射和凯勒的几何衍射理论（GTD）在射频感知和通信中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;衍射诱导的元素具有丰富的信息，可以揭示其几何特性等底层属性。&lt;h4&gt;结论&lt;/h4&gt;本文为将衍射系统地纳入未来无线系统的设计和运行提供了愿景，为增强感知能力和更鲁棒的通信策略铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无线信号是现代社会不可或缺的一部分，它既支持通信，也越来越多地用于环境感知。尽管存在各种传播模型，从经验方法到全波模拟，电磁衍射现象通常被视为次要效应或校正因子。本文将衍射定位为一个基本重要且未被充分利用的机制，它富含关于物理环境的丰富信息。具体来说，衍射诱导的元素产生了丰富的特征，这些特征蕴含了它们底层属性（如几何形状）的信息。我们进一步论证，通过理解和利用这些关系，衍射可以被战略性地利用。我们引入了一个通用的优化框架来形式化这一概念，说明了如何利用衍射来解决逆问题（如从测量场中感知场景细节，如物体几何形状）和正问题（通过配置衍射元素来塑造射频场以实现通信目标）。主要关注边缘衍射和凯勒的几何衍射理论（GTD），我们讨论了在射频感知中用于场景理解以及在通信中用于射频场编程的具体应用，借鉴了最近的研究成果。总的来说，本文为将衍射系统地纳入未来无线系统的设计和运行提供了愿景，为增强感知能力和更鲁棒的通信策略铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wireless signals are integral to modern society, enabling both communicationand increasingly, environmental sensing. While various propagation modelsexist, ranging from empirical methods to full-wave simulations, the phenomenonof electromagnetic diffraction is often treated as a secondary effect or acorrection factor. This paper positions diffraction as a fundamentallyimportant and underutilized mechanism that is rich with information about thephysical environment. Specifically, diffraction-inducing elements generatedistinct signatures that are rich with information about their underlyingproperties such as their geometries. We then argue that by understanding andexploiting these relationships, diffraction can be harnessed strategically. Weintroduce a general optimization framework to formalize this concept,illustrating how diffraction can be leveraged for both inverse problems(sensing scene details such as object geometries from measured fields) andforward problems (shaping RF fields for communication objectives by configuringdiffracting elements). Focusing primarily on edge diffraction and Keller'sGeometrical Theory of Diffraction (GTD), we discuss specific applications in RFsensing for scene understanding and in communications for RF field programming,drawing upon recent work. Overall, this paper lays out a vision forsystematically incorporating diffraction into the design and operation offuture wireless systems, paving the way for enhanced sensing capabilities andmore robust communication strategies.</description>
      <author>example@mail.com (Anurag Pallaprolu, Winston Hurst, Yasamin Mostofi)</author>
      <guid isPermaLink="false">2505.01625v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Compact Clustering Attention (COCA) for Unsupervised Object-Centric Learning</title>
      <link>http://arxiv.org/abs/2505.02071v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为COCA的紧凑聚类注意力层，用于对象中心表示学习，并解决单图像中的无监督对象发现任务。&lt;h4&gt;背景&lt;/h4&gt;在多对象场景中提取对象中心表示，并构建了COCA-Net，一个自下而上的层次网络架构。&lt;h4&gt;目的&lt;/h4&gt;提高对象检测和分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;COCA使用一种新的聚类算法，利用紧凑性的物理概念来突出场景中的不同对象质心，并提供空间归纳偏差。&lt;h4&gt;主要发现&lt;/h4&gt;COCA-Net在解码器和编码器端都生成高质量的分割掩码，且不受预定义对象掩码数量的限制，比竞争对手更好地处理背景元素的分割。&lt;h4&gt;结论&lt;/h4&gt;在六个广泛采用的数据集上，COCA-Net在九个不同的评估指标上实现了优于或与最先进模型相当的结果。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种紧凑聚类注意力层（COCA），这是一种有效的构建块，它引入了一种面向对象表示学习的高级策略，同时解决了单图像中的无监督对象发现任务。COCA是一个基于注意力的聚类模块，能够从多对象场景中提取对象中心表示，当级联到自下而上的层次网络架构中时，被称为COCA-Net。在其核心，COCA利用了一种新的聚类算法，该算法利用紧凑性的物理概念来突出场景中的不同对象质心，从而提供空间归纳偏差。多亏了这种策略，COCA-Net在其管道的解码器和编码器端都生成了高质量的分割掩码。此外，COCA-Net不受它生成的预定义对象掩码数量的限制，并且比竞争对手更好地处理背景元素的分割。我们在六个广泛采用的数据集上展示了COCA-Net的分割性能，在九个不同的评估指标上与最先进模型相比实现了优越或竞争性的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose the Compact Clustering Attention (COCA) layer, an effectivebuilding block that introduces a hierarchical strategy for object-centricrepresentation learning, while solving the unsupervised object discovery taskon single images. COCA is an attention-based clustering module capable ofextracting object-centric representations from multi-object scenes, whencascaded into a bottom-up hierarchical network architecture, referred to asCOCA-Net. At its core, COCA utilizes a novel clustering algorithm thatleverages the physical concept of compactness, to highlight distinct objectcentroids in a scene, providing a spatial inductive bias. Thanks to thisstrategy, COCA-Net generates high-quality segmentation masks on both thedecoder side and, notably, the encoder side of its pipeline. Additionally,COCA-Net is not bound by a predetermined number of object masks that itgenerates and handles the segmentation of background elements better than itscompetitors. We demonstrate COCA-Net's segmentation performance on six widelyadopted datasets, achieving superior or competitive results against thestate-of-the-art models across nine different evaluation metrics.</description>
      <author>example@mail.com (Can Küçüksözen, Yücel Yemez)</author>
      <guid isPermaLink="false">2505.02071v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play</title>
      <link>http://arxiv.org/abs/2505.02707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, Website: https://voila.maitrix.org&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Voila是一个大型语音语言基础模型系列，旨在实现一个能够无缝融入日常生活、自主、实时且情感表达的语音AI代理。&lt;h4&gt;背景&lt;/h4&gt;目前语音AI代理主要依赖于命令反应，缺乏自主性和情感表达。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够实现流畅、动态和情感共鸣的交互的语音AI代理。&lt;h4&gt;方法&lt;/h4&gt;Voila采用了一种新的端到端架构，实现了全双工、低延迟的对话，并保留了丰富的语音细微差别。它集成了大型语言模型（LLMs）的推理能力和强大的声学建模，支持自然、个性化的语音生成。此外，Voila支持超过一百万个预构建的语音和基于简短音频样本的高效定制。&lt;h4&gt;主要发现&lt;/h4&gt;Voila实现了195毫秒的响应延迟，超过了人类的平均反应时间。它能够通过文本指令定义说话者的身份、语气和其他特征，支持自动语音识别（ASR）、文本到语音（TTS）和多语言语音翻译。&lt;h4&gt;结论&lt;/h4&gt;Voila是一个统一模型，适用于各种基于语音的应用，并且是完全开源的，以支持开放研究和加速下一代人机交互的进步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：一个能够无缝融入日常生活的语音AI代理将以自主、实时和情感表达的方式与人类互动。它不仅会响应命令，还会持续监听、推理并主动响应，从而促进流畅、动态和情感共鸣的交互。我们介绍了Voila，这是一系列大型语音语言基础模型，朝着这个愿景迈出了第一步。Voila超越了传统的管道系统，采用了一种新的端到端架构，实现了全双工、低延迟的对话，同时保留了丰富的语音细微差别，如音调、节奏和情感。它实现了仅195毫秒的响应延迟，超过了人类的平均反应时间。其分层多尺度Transformer集成了大型语言模型（LLMs）的推理能力和强大的声学建模，实现了自然、个性化的语音生成——用户可以通过简单的文本指令来定义说话者的身份、语气和其他特征。此外，Voila支持超过一百万个预构建的语音和基于10秒短音频样本的高效定制。除了语音对话外，Voila还被设计为一个统一模型，适用于广泛的基于语音的应用，包括自动语音识别（ASR）、文本到语音（TTS）和，经过最小适应，多语言语音翻译。Voila是完全开源的，以支持开放研究和加速向下一代人机交互的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A voice AI agent that blends seamlessly into daily life would interact withhumans in an autonomous, real-time, and emotionally expressive manner. Ratherthan merely reacting to commands, it would continuously listen, reason, andrespond proactively, fostering fluid, dynamic, and emotionally resonantinteractions. We introduce Voila, a family of large voice-language foundationmodels that make a step towards this vision. Voila moves beyond traditionalpipeline systems by adopting a new end-to-end architecture that enablesfull-duplex, low-latency conversations while preserving rich vocal nuances suchas tone, rhythm, and emotion. It achieves a response latency of just 195milliseconds, surpassing the average human response time. Its hierarchicalmulti-scale Transformer integrates the reasoning capabilities of large languagemodels (LLMs) with powerful acoustic modeling, enabling natural, persona-awarevoice generation -- where users can simply write text instructions to definethe speaker's identity, tone, and other characteristics. Moreover, Voilasupports over one million pre-built voices and efficient customization of newones from brief audio samples as short as 10 seconds. Beyond spoken dialogue,Voila is designed as a unified model for a wide range of voice-basedapplications, including automatic speech recognition (ASR), Text-to-Speech(TTS), and, with minimal adaptation, multilingual speech translation. Voila isfully open-sourced to support open research and accelerate progress towardnext-generation human-machine interactions.</description>
      <author>example@mail.com (Yemin Shi, Yu Shu, Siwei Dong, Guangyi Liu, Jaward Sesay, Jingwen Li, Zhiting Hu)</author>
      <guid isPermaLink="false">2505.02707v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Robustness questions the interpretability of graph neural networks: what to do?</title>
      <link>http://arxiv.org/abs/2505.02566v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个全面的基准，用于系统分析影响图神经网络（GNN）可解释性的各种因素，包括增强鲁棒性的防御机制的影响。&lt;h4&gt;背景&lt;/h4&gt;GNN在生物信息学、社交网络和推荐系统等领域得到广泛应用，但其模型可解释性与鲁棒性之间的相互作用在对抗性场景（如中毒和逃避攻击）下理解不足。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过防御中毒和逃避攻击来影响GNN的可解释性，并强调鲁棒性与可解释性之间的关键权衡。&lt;h4&gt;方法&lt;/h4&gt;评估基于GCN、SAGE、GIN和GAT的六种GNN架构，在两个不同领域的五个数据集上使用四个可解释性指标（保真度、稳定性、一致性和稀疏性）。&lt;h4&gt;主要发现&lt;/h4&gt;根据选择的防御方法和模型架构特征，可解释性存在显著差异。&lt;h4&gt;结论&lt;/h4&gt;通过建立标准化基准，本研究为开发既具有鲁棒性又可解释的GNN提供了基础，有助于在敏感应用中部署这些模型时建立信任。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have become a cornerstone in graph-based data analysis, with applications in diverse domains such as bioinformatics, social networks, and recommendation systems. However, the interplay between model interpretability and robustness remains poorly understood, especially under adversarial scenarios like poisoning and evasion attacks. This paper presents a comprehensive benchmark to systematically analyze the impact of various factors on the interpretability of GNNs, including the influence of robustness-enhancing defense mechanisms. We evaluate six GNN architectures based on GCN, SAGE, GIN, and GAT across five datasets from two distinct domains, employing four interpretability metrics: Fidelity, Stability, Consistency, and Sparsity. Our study examines how defenses against poisoning and evasion attacks, applied before and during model training, affect interpretability and highlights critical trade-offs between robustness and interpretability. The framework will be published as open source. The results reveal significant variations in interpretability depending on the chosen defense methods and model architecture characteristics. By establishing a standardized benchmark, this work provides a foundation for developing GNNs that are both robust to adversarial threats and interpretable, facilitating trust in their deployment in sensitive applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become a cornerstone in graph-based dataanalysis, with applications in diverse domains such as bioinformatics, socialnetworks, and recommendation systems. However, the interplay between modelinterpretability and robustness remains poorly understood, especially underadversarial scenarios like poisoning and evasion attacks. This paper presents acomprehensive benchmark to systematically analyze the impact of various factorson the interpretability of GNNs, including the influence ofrobustness-enhancing defense mechanisms.  We evaluate six GNN architectures based on GCN, SAGE, GIN, and GAT acrossfive datasets from two distinct domains, employing four interpretabilitymetrics: Fidelity, Stability, Consistency, and Sparsity. Our study examines howdefenses against poisoning and evasion attacks, applied before and during modeltraining, affect interpretability and highlights critical trade-offs betweenrobustness and interpretability. The framework will be published as opensource.  The results reveal significant variations in interpretability depending onthe chosen defense methods and model architecture characteristics. Byestablishing a standardized benchmark, this work provides a foundation fordeveloping GNNs that are both robust to adversarial threats and interpretable,facilitating trust in their deployment in sensitive applications.</description>
      <author>example@mail.com (Kirill Lukyanov, Georgii Sazonov, Serafim Boyarsky, Ilya Makarov)</author>
      <guid isPermaLink="false">2505.02566v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Runtime Anomaly Detection for Drones: An Integrated Rule-Mining and Unsupervised-Learning Approach</title>
      <link>http://arxiv.org/abs/2505.01947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by the 29th International Conference on Engineering of  Complex Computer Systems (ICECCS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了RADD，一种结合规则挖掘和无监督学习的无人机异常检测方法。&lt;h4&gt;背景&lt;/h4&gt;无人机（UAVs）因其多用途而日益受到关注，但传感器故障可能导致物理不稳定和安全问题。&lt;h4&gt;目的&lt;/h4&gt;为了减少这些风险，本文旨在提出一种能够检测无人机异常并允许操作者在运行时采取预防措施的方法。&lt;h4&gt;方法&lt;/h4&gt;RADD结合了规则挖掘和无监督学习，利用规则捕获传感器和执行器之间的预期关系，并使用无监督学习技术覆盖规则可能遗漏的微妙关系。&lt;h4&gt;主要发现&lt;/h4&gt;RADD在Gazebo模拟器中实现了基于ArduPilot无人机软件的方法，使用44条规则和五个无监督学习模型，成功检测了93.84%的异常，错误警报率低（2.33%）。&lt;h4&gt;结论&lt;/h4&gt;RADD在检测无人机故障方面优于基于LSTM的最新方法，并且可以有效地在运行时部署。&lt;h4&gt;翻译&lt;/h4&gt;UAVs, commonly referred to as drones, have witnessed a remarkable surge in popularity due to their versatile applications. These cyber-physical systems depend on multiple sensor inputs, such as cameras, GPS receivers, accelerometers, and gyroscopes, with faults potentially leading to physical instability and serious safety concerns. To mitigate such risks, anomaly detection has emerged as a crucial safeguarding mechanism, capable of identifying the physical manifestations of emerging issues and allowing operators to take preemptive action at runtime. Recent anomaly detection methods based on LSTM neural networks have shown promising results, but three challenges persist: the need for models that can generalise across the diverse mission profiles of drones; the need for interpretability, enabling operators to understand the nature of detected problems; and the need for capturing domain knowledge that is difficult to infer solely from log data. Motivated by these challenges, this paper introduces RADD, an integrated approach to anomaly detection in drones that combines rule mining and unsupervised learning. In particular, we leverage rules (or invariants) to capture expected relationships between sensors and actuators during missions, and utilise unsupervised learning techniques to cover more subtle relationships that the rules may have missed. We implement this approach using the ArduPilot drone software in the Gazebo simulator, utilising 44 rules derived across the main phases of drone missions, in conjunction with an ensemble of five unsupervised learning models. We find that our integrated approach successfully detects 93.84% of anomalies over six types of faults with a low false positive rate (2.33%), and can be deployed effectively at runtime. Furthermore, RADD outperforms a state-of-the-art LSTM-based method in detecting the different types of faults evaluated in our study.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; UAVs, commonly referred to as drones, have witnessed a remarkable surge inpopularity due to their versatile applications. These cyber-physical systemsdepend on multiple sensor inputs, such as cameras, GPS receivers,accelerometers, and gyroscopes, with faults potentially leading to physicalinstability and serious safety concerns. To mitigate such risks, anomalydetection has emerged as a crucial safeguarding mechanism, capable ofidentifying the physical manifestations of emerging issues and allowingoperators to take preemptive action at runtime. Recent anomaly detectionmethods based on LSTM neural networks have shown promising results, but threechallenges persist: the need for models that can generalise across the diversemission profiles of drones; the need for interpretability, enabling operatorsto understand the nature of detected problems; and the need for capturingdomain knowledge that is difficult to infer solely from log data. Motivated bythese challenges, this paper introduces RADD, an integrated approach to anomalydetection in drones that combines rule mining and unsupervised learning. Inparticular, we leverage rules (or invariants) to capture expected relationshipsbetween sensors and actuators during missions, and utilise unsupervisedlearning techniques to cover more subtle relationships that the rules may havemissed. We implement this approach using the ArduPilot drone software in theGazebo simulator, utilising 44 rules derived across the main phases of dronemissions, in conjunction with an ensemble of five unsupervised learning models.We find that our integrated approach successfully detects 93.84% of anomaliesover six types of faults with a low false positive rate (2.33%), and can bedeployed effectively at runtime. Furthermore, RADD outperforms astate-of-the-art LSTM-based method in detecting the different types of faultsevaluated in our study.</description>
      <author>example@mail.com (Ivan Tan, Wei Minn, Christopher M. Poskitt, Lwin Khin Shar, Lingxiao Jiang)</author>
      <guid isPermaLink="false">2505.01947v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Deep Learning for Stroke Prediction and Detection using Retinal Imaging and Clinical Data</title>
      <link>http://arxiv.org/abs/2505.02677v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了利用视网膜图像和临床数据对中风进行检测和风险评估的影响。&lt;h4&gt;背景&lt;/h4&gt;中风是全球主要的公共卫生问题，深度学习在提高中风诊断和风险评估方面显示出潜力，但现有方法依赖于昂贵的医学成像技术。&lt;h4&gt;目的&lt;/h4&gt;研究视网膜成像在识别高风险患者和改善长期预后方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种多模态深度神经网络，处理光学相干断层扫描（OCT）和红外反射视网膜扫描，并结合临床数据，如人口统计学、生命体征和诊断代码。使用自监督学习框架和包含37k扫描的现实世界数据集进行预训练，然后使用较小的标记子集进行微调和评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与仅使用单模态图像的基线相比，该框架实现了5%的AUROC提升，与现有最先进的基础模型相比提高了8%。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了视网膜成像在识别高风险患者和改善长期预后方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：中风是全球主要的公共卫生问题，影响着数百万人的健康。深度学习最近在提高中风诊断和风险评估方面显示出希望。然而，现有方法依赖于昂贵的医学成像技术，如计算机断层扫描。最近的研究表明，视网膜成像可以作为一种成本效益高的替代方案，用于评估脑血管健康，因为视网膜和大脑之间存在共同的临床途径。因此，本研究探讨了利用视网膜图像和临床数据对中风检测和风险评估的影响。我们提出了一种多模态深度神经网络，处理光学相干断层扫描（OCT）和红外反射视网膜扫描，并结合临床数据，如人口统计学、生命体征和诊断代码。我们使用自监督学习框架和包含37k扫描的现实世界数据集进行预训练，然后使用较小的标记子集进行微调和评估。我们的实证发现确立了所考虑模态在检测与急性中风相关的视网膜持久效应和预测特定时间范围内的未来风险方面的预测能力。实验结果表明，与仅使用单模态图像的基线相比，我们的提议框架实现了5%的AUROC提升，与现有最先进的基础模型相比提高了8%。总之，我们的研究突出了视网膜成像在识别高风险患者和改善长期预后方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stroke is a major public health problem, affecting millions worldwide. Deeplearning has recently demonstrated promise for enhancing the diagnosis and riskprediction of stroke. However, existing methods rely on costly medical imagingmodalities, such as computed tomography. Recent studies suggest that retinalimaging could offer a cost-effective alternative for cerebrovascular healthassessment due to the shared clinical pathways between the retina and thebrain. Hence, this study explores the impact of leveraging retinal images andclinical data for stroke detection and risk prediction. We propose a multimodaldeep neural network that processes Optical Coherence Tomography (OCT) andinfrared reflectance retinal scans, combined with clinical data, such asdemographics, vital signs, and diagnosis codes. We pretrained our model using aself-supervised learning framework using a real-world dataset consisting of$37$ k scans, and then fine-tuned and evaluated the model using a smallerlabeled subset. Our empirical findings establish the predictive ability of theconsidered modalities in detecting lasting effects in the retina associatedwith acute stroke and forecasting future risk within a specific time horizon.The experimental results demonstrate the effectiveness of our proposedframework by achieving $5$\% AUROC improvement as compared to the unimodalimage-only baseline, and $8$\% improvement compared to an existingstate-of-the-art foundation model. In conclusion, our study highlights thepotential of retinal imaging in identifying high-risk patients and improvinglong-term outcomes.</description>
      <author>example@mail.com (Saeed Shurrab, Aadim Nepal, Terrence J. Lee-St. John, Nicola G. Ghazi, Bartlomiej Piechowski-Jozwiak, Farah E. Shamout)</author>
      <guid isPermaLink="false">2505.02677v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>DeepSparse: A Foundation Model for Sparse-View CBCT Reconstruction</title>
      <link>http://arxiv.org/abs/2505.02628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DeepSparse的深度学习模型，用于稀疏视图锥束CT（CBCT）重建，以减少辐射暴露，并通过实验证明其优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;CBCT是医学领域的重要3D成像技术，但高质量成像所需的辐射暴露对易受伤害的人群引起担忧。稀疏视图重建通过使用较少的X射线投影来减少辐射，但现有方法面临计算需求高和泛化性差的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的深度学习模型DeepSparse，以解决现有稀疏视图CBCT重建方法的问题，并提高重建质量。&lt;h4&gt;方法&lt;/h4&gt;DeepSparse模型采用DiCE网络，该网络整合了多视图2D特征和多尺度3D特征。此外，引入了HyViP框架进行预训练，并在新数据集上进行两步微调。&lt;h4&gt;主要发现&lt;/h4&gt;DeepSparse在重建质量上优于现有方法，为更安全、更高效的CBCT成像铺平了道路。&lt;h4&gt;结论&lt;/h4&gt;DeepSparse模型能够有效减少CBCT成像的辐射暴露，同时保持高质量的重建图像。&lt;h4&gt;翻译&lt;/h4&gt;Cone-beam computed tomography (CBCT) is a critical 3D imaging technology in the medical field, while the high radiation exposure required for high-quality imaging raises significant concerns, particularly for vulnerable populations. Sparse-view reconstruction reduces radiation by using fewer X-ray projections while maintaining image quality, yet existing methods face challenges such as high computational demands and poor generalizability to different datasets. To overcome these limitations, we propose DeepSparse, the first foundation model for sparse-view CBCT reconstruction, featuring DiCE (Dual-Dimensional Cross-Scale Embedding), a novel network that integrates multi-view 2D features and multi-scale 3D features. Additionally, we introduce the HyViP (Hybrid View Sampling Pretraining) framework, which pretrains the model on large datasets with both sparse-view and dense-view projections, and a two-step finetuning strategy to adapt and refine the model for new datasets. Extensive experiments and ablation studies demonstrate that our proposed DeepSparse achieves superior reconstruction quality compared to state-of-the-art methods, paving the way for safer and more efficient CBCT imaging.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cone-beam computed tomography (CBCT) is a critical 3D imaging technology inthe medical field, while the high radiation exposure required for high-qualityimaging raises significant concerns, particularly for vulnerable populations.Sparse-view reconstruction reduces radiation by using fewer X-ray projectionswhile maintaining image quality, yet existing methods face challenges such ashigh computational demands and poor generalizability to different datasets. Toovercome these limitations, we propose DeepSparse, the first foundation modelfor sparse-view CBCT reconstruction, featuring DiCE (Dual-DimensionalCross-Scale Embedding), a novel network that integrates multi-view 2D featuresand multi-scale 3D features. Additionally, we introduce the HyViP (Hybrid ViewSampling Pretraining) framework, which pretrains the model on large datasetswith both sparse-view and dense-view projections, and a two-step finetuningstrategy to adapt and refine the model for new datasets. Extensive experimentsand ablation studies demonstrate that our proposed DeepSparse achieves superiorreconstruction quality compared to state-of-the-art methods, paving the way forsafer and more efficient CBCT imaging.</description>
      <author>example@mail.com (Yiqun Lin, Hualiang Wang, Jixiang Chen, Jiewen Yang, Jiarong Guo, Xiaomeng Li)</author>
      <guid isPermaLink="false">2505.02628v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Context-Aware Online Conformal Anomaly Detection with Prediction-Powered Data Acquisition</title>
      <link>http://arxiv.org/abs/2505.01783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为C-PP-COAD的上下文感知预测驱动的在线异常检测框架，用于解决网络安全、医疗保健和工业监控等领域中实时识别行为偏差的问题。&lt;h4&gt;背景&lt;/h4&gt;在线异常检测在网络安全、医疗保健和工业监控等领域至关重要，这些领域需要及时识别偏差以避免关键故障或安全漏洞。&lt;h4&gt;目的&lt;/h4&gt;为了解决有限的真实校准数据带来的挑战，本文旨在提出一种新的异常检测方法，以减少对真实校准数据的依赖。&lt;h4&gt;方法&lt;/h4&gt;C-PP-COAD框架利用合成校准数据来缓解数据稀缺问题，并基于上下文线索自适应地整合真实数据。它使用符合性p值、主动p值统计和在线FDR控制机制来保持严格的异常检测性能。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实世界数据集上的实验表明，C-PP-COAD显著减少了对外部校准数据的依赖，同时保证了FDR控制的可靠性。&lt;h4&gt;结论&lt;/h4&gt;C-PP-COAD是一种有效的在线异常检测方法，能够减少对真实校准数据的依赖，同时保持对FDR的保证控制。&lt;h4&gt;翻译&lt;/h4&gt;Online anomaly detection is essential in fields such as cybersecurity, healthcare, and industrial monitoring, where promptly identifying deviations from expected behavior can avert critical failures or security breaches. While numerous anomaly scoring methods based on supervised or unsupervised learning have been proposed, current approaches typically rely on a continuous stream of real-world calibration data to provide assumption-free guarantees on the false discovery rate (FDR). To address the inherent challenges posed by limited real calibration data, we introduce context-aware prediction-powered conformal online anomaly detection (C-PP-COAD). Our framework strategically leverages synthetic calibration data to mitigate data scarcity, while adaptively integrating real data based on contextual cues. C-PP-COAD utilizes conformal p-values, active p-value statistics, and online FDR control mechanisms to maintain rigorous and reliable anomaly detection performance over time. Experiments conducted on both synthetic and real-world datasets demonstrate that C-PP-COAD significantly reduces dependency on real calibration data without compromising guaranteed FDR control.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Online anomaly detection is essential in fields such as cybersecurity,healthcare, and industrial monitoring, where promptly identifying deviationsfrom expected behavior can avert critical failures or security breaches. Whilenumerous anomaly scoring methods based on supervised or unsupervised learninghave been proposed, current approaches typically rely on a continuous stream ofreal-world calibration data to provide assumption-free guarantees on the falsediscovery rate (FDR). To address the inherent challenges posed by limited realcalibration data, we introduce context-aware prediction-powered conformalonline anomaly detection (C-PP-COAD). Our framework strategically leveragessynthetic calibration data to mitigate data scarcity, while adaptivelyintegrating real data based on contextual cues. C-PP-COAD utilizes conformalp-values, active p-value statistics, and online FDR control mechanisms tomaintain rigorous and reliable anomaly detection performance over time.Experiments conducted on both synthetic and real-world datasets demonstratethat C-PP-COAD significantly reduces dependency on real calibration datawithout compromising guaranteed FDR control.</description>
      <author>example@mail.com (Amirmohammad Farzaneh, Osvaldo Simeone)</author>
      <guid isPermaLink="false">2505.01783v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>NbBench: Benchmarking Language Models for Comprehensive Nanobody Tasks</title>
      <link>http://arxiv.org/abs/2505.02022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了NbBench，第一个用于纳米抗体表征学习的全面基准套件，旨在提升纳米抗体建模的标准化和可重复性。&lt;h4&gt;背景&lt;/h4&gt;纳米抗体作为单域抗体片段，具有体积小、稳定性高和结合亲和力强的特点，在治疗和诊断领域具有潜在价值。&lt;h4&gt;目的&lt;/h4&gt;为了解决纳米抗体特定建模未充分探索且缺乏统一基准的问题，引入NbBench。&lt;h4&gt;方法&lt;/h4&gt;NbBench包含八个生物意义明确的任务，涵盖结构注释、结合预测和开发性评估，并对十一种代表性模型进行了系统评估。&lt;h4&gt;主要发现&lt;/h4&gt;抗体语言模型在抗原相关任务中表现优秀，但在回归任务（如热稳定性和亲和力）上所有模型的性能都面临挑战，没有单一模型在所有任务中都优于其他模型。&lt;h4&gt;结论&lt;/h4&gt;NbBench通过标准化数据集、任务定义和评估协议，为评估和推进纳米抗体建模提供了一个可重复的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nanobodies, single-domain antibody fragments derived from camelidheavy-chain-only antibodies, exhibit unique advantages such as compact size,high stability, and strong binding affinity, making them valuable tools intherapeutics and diagnostics. While recent advances in pretrained protein andantibody language models (PPLMs and PALMs) have greatly enhanced biomolecularunderstanding, nanobody-specific modeling remains underexplored and lacks aunified benchmark. To address this gap, we introduce NbBench, the firstcomprehensive benchmark suite for nanobody representation learning. Spanningeight biologically meaningful tasks across nine curated datasets, NbBenchencompasses structure annotation, binding prediction, and developabilityassessment. We systematically evaluate eleven representative models--includinggeneral-purpose protein LMs, antibody-specific LMs, and nanobody-specificLMs--in a frozen setting. Our analysis reveals that antibody language modelsexcel in antigen-related tasks, while performance on regression tasks such asthermostability and affinity remains challenging across all models. Notably, nosingle model consistently outperforms others across all tasks. By standardizingdatasets, task definitions, and evaluation protocols, NbBench offers areproducible foundation for assessing and advancing nanobody modeling.</description>
      <author>example@mail.com (Yiming Zhang, Koji Tsuda)</author>
      <guid isPermaLink="false">2505.02022v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Low-Complexity Acoustic Scene Classification with Device Information in the DCASE 2025 Challenge</title>
      <link>http://arxiv.org/abs/2505.01747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Task Description Page:  https://dcase.community/challenge2025/task-low-complexity-acoustic-scene-classification-with-device-information&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DCASE 2025挑战赛中低复杂度声场景分类任务及其基线系统，继续关注低复杂度模型、数据效率和设备不匹配问题，并引入了新的关键变化。&lt;h4&gt;背景&lt;/h4&gt;前几届DCASE挑战赛（2022-2024年）已经关注了低复杂度模型、数据效率和设备不匹配问题。&lt;h4&gt;目的&lt;/h4&gt;开发设备特定的模型，利用设备特性，反映实际部署场景中模型对底层硬件的了解。&lt;h4&gt;方法&lt;/h4&gt;今年的任务引入了新的变化，即在推理时提供记录设备信息。训练集与DCASE 2024挑战赛使用的25%子集相匹配，没有对外部数据使用的限制，突出了迁移学习的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;基线系统在十个类别的任务中，使用设备通用模型达到了50.72%的准确率，当使用可用的设备信息时，准确率提高到了51.89%。&lt;h4&gt;结论&lt;/h4&gt;通过提供设备信息，可以开发出更适应特定设备的模型，从而提高声场景分类的准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents the Low-Complexity Acoustic Scene Classification withDevice Information Task of the DCASE 2025 Challenge and its baseline system.Continuing the focus on low-complexity models, data efficiency, and devicemismatch from previous editions (2022--2024), this year's task introduces a keychange: recording device information is now provided at inference time. Thisenables the development of device-specific models that leverage devicecharacteristics -- reflecting real-world deployment scenarios in which a modelis designed with awareness of the underlying hardware. The training set matchesthe 25% subset used in the corresponding DCASE 2024 challenge, with norestrictions on external data use, highlighting transfer learning as a centraltopic. The baseline achieves 50.72% accuracy on this ten-class problem with adevice-general model, improving to 51.89% when using the available deviceinformation.</description>
      <author>example@mail.com (Florian Schmid, Paul Primus, Toni Heittola, Annamaria Mesaros, Irene Martín-Morató, Gerhard Widmer)</author>
      <guid isPermaLink="false">2505.01747v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Point2Primitive: CAD Reconstruction from Point Cloud by Direct Primitive Prediction</title>
      <link>http://arxiv.org/abs/2505.02043v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从点云数据直接预测并重建CAD模型的网络方法，通过改进的Transformer直接检测和预测草图曲线，重建拓扑结构并优化曲线参数，实现高精度的CAD模型重建。&lt;h4&gt;背景&lt;/h4&gt;现有的CAD模型重建方法通常使用隐式场来表示草图，导致曲线形状的重建精度不高。&lt;h4&gt;目的&lt;/h4&gt;提高从点云数据重建CAD模型的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Point2Primitive的CAD重建网络，该网络通过直接预测扩展原语的所有元素来生成可编辑的CAD模型。使用改进的Transformer直接从点云中检测和预测草图曲线，并将草图曲线参数作为位置查询进行自回归优化，重建拓扑结构并通过结合预测曲线和计算出的扩展操作来恢复每个扩展参数。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在原语预测精度和CAD重建方面表现出色，重建的形状具有较高的几何精度。&lt;h4&gt;结论&lt;/h4&gt;该方法为从点云数据重建CAD模型提供了一种有效且准确的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从点云恢复CAD模型，尤其是草图扩展过程，可以看作是重建拓扑结构和扩展原语的过程。先前的方法利用隐式场来表示草图，导致曲线形状的重建。在本文中，我们提出了一种CAD重建网络（Point2Primitive），它通过直接预测扩展原语的每个元素从输入点云生成可编辑的CAD模型。Point2Primitive基于改进的Transformer直接从点云中检测和预测草图曲线（类型和参数）。草图曲线参数被表示为位置查询并以自回归方式进行优化，从而实现高参数精度。拓扑结构通过扩展分割重建，每个扩展参数（草图和扩展操作）通过结合预测曲线和计算出的扩展操作来恢复。大量实验表明，我们的方法在原语预测精度和CAD重建方面优于现有方法。重建的形状具有高几何保真度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recovering CAD models from point clouds, especially the sketch-extrusionprocess, can be seen as the process of rebuilding the topology and extrusionprimitives. Previous methods utilize implicit fields for sketch representation,leading to shape reconstruction of curved edges. In this paper, we proposed aCAD reconstruction network that produces editable CAD models from input pointclouds (Point2Primitive) by directly predicting every element of the extrusionprimitives. Point2Primitive can directly detect and predict sketch curves (typeand parameter) from point clouds based on an improved transformer. The sketchcurve parameters are formulated as position queries and optimized in anautoregressive way, leading to high parameter accuracy. The topology is rebuiltby extrusion segmentation, and each extrusion parameter (sketch and extrusionoperation) is recovered by combining the predicted curves and the computedextrusion operation. Extensive experiments demonstrate that our method issuperior in primitive prediction accuracy and CAD reconstruction. Thereconstructed shapes are of high geometrical fidelity.</description>
      <author>example@mail.com (Cheng Wang, Xinzhu Ma, Bin Wang, Shixiang Tang, Yuan Meng, Ping Jiang)</author>
      <guid isPermaLink="false">2505.02043v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>MolQAE: Quantum Autoencoder for Molecular Representation Learning</title>
      <link>http://arxiv.org/abs/2505.01875v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为量子分子自动编码器的新方法，该方法将量子计算与分子表示学习相结合，旨在解决传统分子表示方法在处理高维数据时遇到的计算瓶颈。&lt;h4&gt;背景&lt;/h4&gt;传统分子表示方法在处理高维数据时存在计算瓶颈，而量子计算通过其固有的并行性和量子叠加特性提供了有希望的替代方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于量子电路的自动编码器架构，将SMILES分子表示映射到量子状态空间，并利用SWAP测试评估编码质量。&lt;h4&gt;方法&lt;/h4&gt;量子自动编码器架构通过参数化量子电路进行降维，并使用SWAP测试来评估编码质量。&lt;h4&gt;主要发现&lt;/h4&gt;理论研究表明，该方法可以在指数级较小的空间中保留分子特征，同时保持分子之间的相似性关系。实验结果表明，量子自动编码器有效地捕捉了分子结构和化学性质。&lt;h4&gt;结论&lt;/h4&gt;该框架不仅为分子表示学习建立了量子途径，也为药物发现和材料设计开辟了新的可能性。作为分子表示学习与量子计算交叉领域的首次研究，本研究为化学信息学的发展奠定了理论和实践基础。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为量子分子自动编码器的新方法，该方法将量子计算与分子表示学习相结合。传统分子表示方法在处理高维数据时存在计算瓶颈，而量子计算通过其固有的并行性和量子叠加特性提供了有希望的替代方案。本文提出了一种基于量子电路的自动编码器架构，将SMILES分子表示映射到量子状态空间，并利用SWAP测试评估编码质量。理论研究表明，该方法可以在指数级较小的空间中保留分子特征，同时保持分子之间的相似性关系。实验结果表明，量子自动编码器有效地捕捉了分子结构和化学性质。该框架不仅为分子表示学习建立了量子途径，也为药物发现和材料设计开辟了新的可能性。作为分子表示学习与量子计算交叉领域的首次研究，本研究为化学信息学的发展奠定了理论和实践基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces the Quantum Molecular Autoencoder, a novel approachthat integrates quantum computing with molecular representation learning. Whileconventional molecular representation methods face computational bottleneckswhen processing high-dimensional data, quantum computing offers a promisingalternative through its inherent parallelism and quantum superpositionproperties. We present a quantum circuit-based autoencoder architecture thatmaps SMILES molecular representations into quantum state space, employsparameterized quantum circuits for dimensional reduction, and utilizes SWAPtests to evaluate encoding quality. Theoretically, our approach preservesessential molecular features in exponentially smaller spaces while maintainingsimilarity relationships between molecules. Experimental results demonstratethat quantum autoencoders effectively capture molecular structures and chemicalproperties. The proposed framework not only establishes a quantum pathway formolecular representation learning but also opens new possibilities forapplications in drug discovery and materials design. As the first investigationat the intersection of molecular representation learning and quantum computing,this research lays both theoretical and practical foundations for theadvancement of cheminformatics.</description>
      <author>example@mail.com (Yi Pan, Hanqi Jiang, Wei Ruan, Dajiang Zhu, Xiang Li, Yohannes Abate, Yingfeng Wang, Tianming Liu)</author>
      <guid isPermaLink="false">2505.01875v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning-Based Deep Residual Learning for Speech Recognition in Clean and Noisy Environments</title>
      <link>http://arxiv.org/abs/2505.01632v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的神经网络框架，用于解决非平稳环境噪声对自动语音识别的影响。&lt;h4&gt;背景&lt;/h4&gt;非平稳环境噪声对自动语音识别系统的影响是一个持续且重要的研究焦点。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的神经网络框架，以克服非平稳环境噪声带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了鲁棒的前端处理，并在Aurora-2语音数据库上使用基于ResNet的迁移学习方法，对Mel频率声学特征集进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与卷积神经网络和长短期记忆网络相比，该方法在识别准确率上有显著提升，在干净和噪声环境下的准确率分别为98.94%和91.21%。&lt;h4&gt;结论&lt;/h4&gt;该神经网络框架在自动语音识别中有效提高了识别准确率，特别是在噪声环境下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICTIS62692.2024.10894239&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Addressing the detrimental impact of non-stationary environmental noise onautomatic speech recognition (ASR) has been a persistent and significantresearch focus. Despite advancements, this challenge continues to be a majorconcern. Recently, data-driven supervised approaches, such as deep neuralnetworks, have emerged as promising alternatives to traditional unsupervisedmethods. With extensive training, these approaches have the potential toovercome the challenges posed by diverse real-life acoustic environments. Inthis light, this paper introduces a novel neural framework that incorporates arobust frontend into ASR systems in both clean and noisy environments.Utilizing the Aurora-2 speech database, the authors evaluate the effectivenessof an acoustic feature set for Mel-frequency, employing the approach oftransfer learning based on Residual neural network (ResNet). The experimentalresults demonstrate a significant improvement in recognition accuracy comparedto convolutional neural networks (CNN) and long short-term memory (LSTM)networks. They achieved accuracies of 98.94% in clean and 91.21% in noisy mode.</description>
      <author>example@mail.com (Noussaiba Djeffal, Djamel Addou, Hamza Kheddar, Sid Ahmed Selouani)</author>
      <guid isPermaLink="false">2505.01632v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>MC3D-AD: A Unified Geometry-aware Reconstruction Model for Multi-category 3D Anomaly Detection</title>
      <link>http://arxiv.org/abs/2505.01969v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages of main text, 3 pages of appendix, accepted to IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的多类别3D异常检测（MC3D-AD）模型，旨在利用局部和全局几何感知信息来重建所有类别的正常表示，以提高检测效率和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的3D异常检测方法通常需要针对每个类别独立训练模型，导致成本高、效率低和泛化能力弱。&lt;h4&gt;目的&lt;/h4&gt;设计一个统一的模型，实现多类别3D异常检测，利用局部和全局几何感知信息来重建正常表示。&lt;h4&gt;方法&lt;/h4&gt;1. 提出自适应几何感知掩码注意力模块，提取几何变化信息以引导掩码注意力；2. 引入局部几何感知编码器，增强掩码注意力以编码组级特征标记；3. 设计全局查询解码器，利用点云位置嵌入来改善解码过程和重建能力。&lt;h4&gt;主要发现&lt;/h4&gt;MC3D-AD在Real3D-AD和Anomaly-ShapeNet数据集上评估，在对象级AUROC上分别比现有单类别方法提高了3.1%和9.3%。&lt;h4&gt;结论&lt;/h4&gt;MC3D-AD模型在多类别3D异常检测任务中表现出显著优越性，能够有效提高检测效率和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;3D Anomaly Detection (AD) is a promising means of controlling the quality of manufactured products. However, existing methods typically require carefully training a task-specific model for each category independently, leading to high cost, low efficiency, and weak generalization. Therefore, this paper presents a novel unified model for Multi-Category 3D Anomaly Detection (MC3D-AD) that aims to utilize both local and global geometry-aware information to reconstruct normal representations of all categories. First, to learn robust and generalized features of different categories, we propose an adaptive geometry-aware masked attention module that extracts geometry variation information to guide mask attention. Then, we introduce a local geometry-aware encoder reinforced by the improved mask attention to encode group-level feature tokens. Finally, we design a global query decoder that utilizes point cloud position embeddings to improve the decoding process and reconstruction ability. This leads to local and global geometry-aware reconstructed feature tokens for the AD task. MC3D-AD is evaluated on two publicly available Real3D-AD and Anomaly-ShapeNet datasets, and exhibits significant superiority over current state-of-the-art single-category methods, achieving 3.1% and 9.3% improvement in object-level AUROC over Real3D-AD and Anomaly-ShapeNet, respectively. The source code will be released upon acceptance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Anomaly Detection (AD) is a promising means of controlling the quality ofmanufactured products. However, existing methods typically require carefullytraining a task-specific model for each category independently, leading to highcost, low efficiency, and weak generalization. Therefore, this paper presents anovel unified model for Multi-Category 3D Anomaly Detection (MC3D-AD) that aimsto utilize both local and global geometry-aware information to reconstructnormal representations of all categories. First, to learn robust andgeneralized features of different categories, we propose an adaptivegeometry-aware masked attention module that extracts geometry variationinformation to guide mask attention. Then, we introduce a local geometry-awareencoder reinforced by the improved mask attention to encode group-level featuretokens. Finally, we design a global query decoder that utilizes point cloudposition embeddings to improve the decoding process and reconstruction ability.This leads to local and global geometry-aware reconstructed feature tokens forthe AD task. MC3D-AD is evaluated on two publicly available Real3D-AD andAnomaly-ShapeNet datasets, and exhibits significant superiority over currentstate-of-the-art single-category methods, achieving 3.1\% and 9.3\% improvementin object-level AUROC over Real3D-AD and Anomaly-ShapeNet, respectively. Thesource code will be released upon acceptance.</description>
      <author>example@mail.com (Jiayi Cheng, Can Gao, Jie Zhou, Jiajun Wen, Tao Dai, Jinbao Wang)</author>
      <guid isPermaLink="false">2505.01969v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Machine-learning interatomic potentials from a users perspective: A comparison of accuracy, speed and data efficiency</title>
      <link>http://arxiv.org/abs/2505.02503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;机器学习原子间势（MLIPs）显著改变了原子建模领域，提高了密度泛函理论在大规模模拟中的精度，同时接近经典原子间势的运行速度。&lt;h4&gt;背景&lt;/h4&gt;近年来，开发了多种类型的MLIPs，但对于特定问题设置，判断哪种方法最佳往往很困难。&lt;h4&gt;目的&lt;/h4&gt;针对结构和化学上复杂的固体（如Al-Cu-Zr和Si-O），比较了多种MLIPs方法，包括GAP、HDNNP、MTP、线性和非线性ACE、NequIP、Allegro和MACE。&lt;h4&gt;方法&lt;/h4&gt;进行了基准测试，并分析了非线性ACE、NequIP和MACE在精度与计算成本之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;非线性ACE、NequIP和MACE在精度与计算成本之间达到Pareto最优。对于Al-Cu-Zr系统，MACE和Allegro提供最高精度，而NequIP在Si-O系统中表现更优。GPU可以大幅加速MLIPs，使其在可访问的时间尺度上与未加速的经典原子间势相当甚至更优。&lt;h4&gt;结论&lt;/h4&gt;探讨了相应势的外推行为，研究了势能表面的平滑性，并评估了相应的拟合代码和分子动力学界面的用户友好性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：机器学习原子间势（MLIPs）极大地改变了原子建模领域。它们在大型模拟中提高了密度泛函理论的精度，同时几乎与经典原子间势一样快。在过去的几年里，开发了各种类型的MLIPs，但对于给定的问题设置，判断哪种方法最佳往往很困难。对于结构和化学上复杂的固体，即Al-Cu-Zr和Si-O，我们对一系列机器学习原子间势方法进行了基准测试，特别是高斯近似势（GAP）、高维神经网络势（HDNNP）、矩张量势（MTP）、线性和非线性原子簇展开（ACE）、神经网络等变原子间势（NequIP）、Allegro和MACE。我们发现非线性ACE、等变的消息传递图神经网络NequIP和MACE在精度与计算成本权衡中形成了Pareto前沿。在Al-Cu-Zr系统中，我们发现MACE和Allegro提供了最高的精度，而NequIP在Si-O中表现更优。此外，GPU可以大幅加速MLIPs，使它们在可访问的时间尺度上与未加速的经典原子间势相当甚至更优。最后，我们探讨了相应势的外推行为，探究了势能表面的平滑性，并最终估计了相应的拟合代码和分子动力学界面的用户友好性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning interatomic potentials (MLIPs) have massively changed thefield of atomistic modeling. They enable the accuracy of density functionaltheory in large-scale simulations while being nearly as fast as classicalinteratomic potentials. Over the last few years, a wide range of differenttypes of MLIPs have been developed, but it is often difficult to judge whichapproach is the best for a given problem setting. For the case of structurallyand chemically complex solids, namely Al-Cu-Zr and Si-O, we benchmark a rangeof machine learning interatomic potential approaches, in particular, theGaussian approximation potential (GAP), high-dimensional neural networkpotentials (HDNNP), moment tensor potentials (MTP), the atomic clusterexpansion (ACE) in its linear and nonlinear version, neural equivariantinteratomic potentials (NequIP), Allegro, and MACE. We find that nonlinear ACEand the equivariant, message-passing graph neural networks NequIP and MACE formthe Pareto front in the accuracy vs. computational cost trade-off. In case ofthe Al-Cu-Zr system we find that MACE and Allegro offer the highest accuracy,while NequIP outperforms them for Si-O. Furthermore, GPUs can massivelyaccelerate the MLIPs, bringing them on par with and even ahead ofnon-accelerated classical interatomic potentials (IPs) with regards toaccessible timescales. Finally, we explore the extrapolation behavior of thecorresponding potentials, probe the smoothness of the potential energysurfaces, and finally estimate the user friendliness of the correspondingfitting codes and molecular dynamics interfaces.</description>
      <author>example@mail.com (Niklas Leimeroth, Linus C. Erhard, Karsten Albe, Jochen Rohrer)</author>
      <guid isPermaLink="false">2505.02503v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Scale Target-Aware Representation Learning for Fundus Image Enhancement</title>
      <link>http://arxiv.org/abs/2505.01831v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review at Neural Networks&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MTRL-FIE的多尺度目标感知表示学习框架，用于高效的眼底图像增强。&lt;h4&gt;背景&lt;/h4&gt;高质量的眼底图像对于临床筛查和眼科疾病诊断至关重要，但由于硬件限制、操作可变性和患者依从性，眼底图像往往存在分辨率低和信噪比低的问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了一种新的图像增强框架，以恢复全面的多尺度信息，并针对图像增强的目标，如病变，进行优化。&lt;h4&gt;方法&lt;/h4&gt;该方法包括一个多尺度特征编码器（MFE），使用小波分解嵌入低频结构信息和高频细节，以及一个结构保持的层次解码器（SHD），用于融合多尺度特征嵌入以实现真实眼底图像的恢复。SHD集成了层次融合和组注意力机制，同时使用目标感知特征聚合（TFA）模块来增强病理区域并减少伪影。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MTRL-FIE在多个眼底图像数据集上展现了有效性和泛化能力，与现有方法相比，MTRL-FIE在更轻量级的架构下实现了更优越的增强性能。&lt;h4&gt;结论&lt;/h4&gt;MTRL-FIE不仅能够有效增强眼底图像，而且可以泛化到其他眼科图像处理任务，无需监督微调，具有临床应用的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multi-scale target-aware representation learning framework named MTRL-FIE for efficient fundus image enhancement.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-quality fundus images provide essential anatomical information forclinical screening and ophthalmic disease diagnosis. Yet, due to hardwarelimitations, operational variability, and patient compliance, fundus imagesoften suffer from low resolution and signal-to-noise ratio. Recent years havewitnessed promising progress in fundus image enhancement. However, existingworks usually focus on restoring structural details or global characteristicsof fundus images, lacking a unified image enhancement framework to recovercomprehensive multi-scale information. Moreover, few methods pinpoint thetarget of image enhancement, e.g., lesions, which is crucial for medicalimage-based diagnosis. To address these challenges, we propose a multi-scaletarget-aware representation learning framework (MTRL-FIE) for efficient fundusimage enhancement. Specifically, we propose a multi-scale feature encoder (MFE)that employs wavelet decomposition to embed both low-frequency structuralinformation and high-frequency details. Next, we design a structure-preservinghierarchical decoder (SHD) to fuse multi-scale feature embeddings for realfundus image restoration. SHD integrates hierarchical fusion and groupattention mechanisms to achieve adaptive feature fusion while retaining localstructural smoothness. Meanwhile, a target-aware feature aggregation (TFA)module is used to enhance pathological regions and reduce artifacts.Experimental results on multiple fundus image datasets demonstrate theeffectiveness and generalizability of MTRL-FIE for fundus image enhancement.Compared to state-of-the-art methods, MTRL-FIE achieves superior enhancementperformance with a more lightweight architecture. Furthermore, our approachgeneralizes to other ophthalmic image processing tasks without supervisedfine-tuning, highlighting its potential for clinical applications.</description>
      <author>example@mail.com (Haofan Wu, Yin Huang, Yuqing Wu, Qiuyu Yang, Bingfang Wang, Li Zhang, Muhammad Fahadullah Khan, Ali Zia, M. Saleh Memon, Syed Sohail Bukhari, Abdul Fattah Memon, Daizong Ji, Ya Zhang, Ghulam Mustafa, Yin Fang)</author>
      <guid isPermaLink="false">2505.01831v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Text to Image Generation and Editing: A Survey</title>
      <link>http://arxiv.org/abs/2505.02527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  49 pages,3 figures,3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对2021年至2024年间141篇关于文本到图像生成（T2I）的研究进行了全面综述。&lt;h4&gt;背景&lt;/h4&gt;近年来，T2I技术受到广泛关注，涌现出大量研究成果。&lt;h4&gt;目的&lt;/h4&gt;本文旨在为未来研究者提供有价值的指导，并推动T2I领域的发展。&lt;h4&gt;方法&lt;/h4&gt;首先介绍了T2I的四种基础模型架构（自回归、非自回归、GAN和扩散）以及常用的关键技术（自动编码器、注意力和无分类器引导）。然后，系统比较了这些研究在T2I生成和T2I编辑两个方向上的方法，包括编码器及其使用的关键技术。此外，还从数据集、评估指标、训练资源和推理速度等方面对比了这些研究的性能。除了四种基础模型外，还调查了T2I领域的其他工作，如基于能量的模型、最新的Mamba和多模态模型。最后，探讨了T2I的社会影响并提供了一些解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出了提高T2I模型性能的独特见解和可能的未来发展方向。&lt;h4&gt;结论&lt;/h4&gt;本文是T2I领域的首次系统性和全面性概述，为未来研究者提供了宝贵的参考，并刺激了该领域的持续进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-to-image generation (T2I) refers to the text-guided generation ofhigh-quality images. In the past few years, T2I has attracted widespreadattention and numerous works have emerged. In this survey, we comprehensivelyreview 141 works conducted from 2021 to 2024. First, we introduce fourfoundation model architectures of T2I (autoregression, non-autoregression, GANand diffusion) and the commonly used key technologies (autoencoder, attentionand classifier-free guidance). Secondly, we systematically compare the methodsof these studies in two directions, T2I generation and T2I editing, includingthe encoders and the key technologies they use. In addition, we also comparethe performance of these researches side by side in terms of datasets,evaluation metrics, training resources, and inference speed. In addition to thefour foundation models, we survey other works on T2I, such as energy-basedmodels and recent Mamba and multimodality. We also investigate the potentialsocial impact of T2I and provide some solutions. Finally, we propose uniqueinsights of improving the performance of T2I models and possible futuredevelopment directions. In summary, this survey is the first systematic andcomprehensive overview of T2I, aiming to provide a valuable guide for futureresearchers and stimulate continued progress in this field.</description>
      <author>example@mail.com (Pengfei Yang, Ngai-Man Cheung, Xinda Ma)</author>
      <guid isPermaLink="false">2505.02527v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>TV-SurvCaus: Dynamic Representation Balancing for Causal Survival Analysis</title>
      <link>http://arxiv.org/abs/2505.01785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TV-SurvCaus的新框架，用于估计时间变化治疗对生存结果的影响，并证明了其在动态治疗制度中的有效性。&lt;h4&gt;背景&lt;/h4&gt;在医学等领域，治疗协议会随时间变化，这使得估计时间变化治疗对生存结果的影响成为一个具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过引入TV-SurvCaus框架，扩展表示平衡技术，以处理时间变化治疗设置下的生存分析。&lt;h4&gt;方法&lt;/h4&gt;TV-SurvCaus框架通过以下方法提供理论保证：(1) 对估计异质性效应的时间变化精度提供了一般性界限；(2) 通过顺序平衡权重控制方差；(3) 对动态治疗制度的一致性结果；(4) 对于具有时间依赖性的表示学习提供了收敛速率；(5) 对治疗-混杂因素反馈的偏差提供了正式界限。&lt;h4&gt;主要发现&lt;/h4&gt;通过在合成和真实世界数据集上的广泛实验，证明了TV-SurvCaus在估计具有时间变化协变量和治疗的个体化治疗效果方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该框架通过在动态、纵向设置中更准确地估计治疗效应，推动了因果推断领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：估计时间变化治疗对生存结果的影响在许多领域都是一个具有挑战性的任务，尤其是在医学领域，治疗协议会随时间变化。尽管最近在表示学习方面的进展已经改善了静态治疗中的因果推断，但将这些方法扩展到具有生存结果的时间变化治疗制度仍然没有得到充分探索。在本文中，我们引入了TV-SurvCaus，这是一种新颖的框架，它将表示平衡技术扩展到时间变化治疗设置下的生存分析。我们通过以下方式提供理论保证：(1) 对估计异质性效应的时间变化精度提供了一般性界限；(2) 通过顺序平衡权重控制方差；(3) 对动态治疗制度的一致性结果；(4) 对于具有时间依赖性的表示学习提供了收敛速率；(5) 对治疗-混杂因素反馈的偏差提供了正式界限。我们的神经架构通过序列建模来处理时间依赖性，同时平衡时间依赖性表示。通过在合成和真实世界数据集上的广泛实验，我们证明了TV-SurvCaus在估计具有时间变化协变量和治疗的个体化治疗效果方面优于现有方法。我们的框架通过在动态、纵向设置中更准确地估计治疗效应，推动了因果推断领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating the causal effect of time-varying treatments on survival outcomesis a challenging task in many domains, particularly in medicine where treatmentprotocols adapt over time. While recent advances in representation learninghave improved causal inference for static treatments, extending these methodsto dynamic treatment regimes with survival outcomes remains under-explored. Inthis paper, we introduce TV-SurvCaus, a novel framework that extendsrepresentation balancing techniques to the time-varying treatment setting forsurvival analysis. We provide theoretical guarantees through (1) a generalizedbound for time-varying precision in estimation of heterogeneous effects, (2)variance control via sequential balancing weights, (3) consistency results fordynamic treatment regimes, (4) convergence rates for representation learningwith temporal dependencies, and (5) a formal bound on the bias due totreatment-confounder feedback. Our neural architecture incorporates sequencemodeling to handle temporal dependencies while balancing time-dependentrepresentations. Through extensive experiments on both synthetic and real-worlddatasets, we demonstrate that TV-SurvCaus outperforms existing methods inestimating individualized treatment effects with time-varying covariates andtreatments. Our framework advances the field of causal inference by enablingmore accurate estimation of treatment effects in dynamic, longitudinal settingswith survival outcomes.</description>
      <author>example@mail.com (Ayoub Abraich)</author>
      <guid isPermaLink="false">2505.01785v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Beyond the model: Key differentiators in large language models and multi-agent services</title>
      <link>http://arxiv.org/abs/2505.02489v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;大语言模型（LLMs）不再是生成AI的唯一定义因素，优化周边生态系统成为关键。&lt;h4&gt;背景&lt;/h4&gt;随着DeepSeek、Manus AI和Llama 4等基础模型的推出，LLMs不再独占鳌头。&lt;h4&gt;目的&lt;/h4&gt;分析确保现代AI服务高效和盈利的关键不同点。&lt;h4&gt;方法&lt;/h4&gt;探讨数据质量和管理、计算效率、延迟和评估框架等方面的优化。&lt;h4&gt;主要发现&lt;/h4&gt;优化周边生态系统对于生成AI至关重要。&lt;h4&gt;结论&lt;/h4&gt;除了模型大小，数据管理、计算效率等因素对AI服务的效率与盈利性具有决定性影响。&lt;h4&gt;翻译&lt;/h4&gt;With the launch of foundation models like DeepSeek, Manus AI, and Llama 4, ithas become evident that large language models (LLMs) are no longer the soledefining factor in generative AI. As many now operate at comparable levels ofcapability, the real race is not about having the biggest model but optimizingthe surrounding ecosystem, including data quality and management, computationalefficiency, latency, and evaluation frameworks. This review article delves intothese critical differentiators that ensure modern AI services are efficient andprofitable.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.30574/wjarr.2025.26.1.1295&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the launch of foundation models like DeepSeek, Manus AI, and Llama 4, ithas become evident that large language models (LLMs) are no longer the soledefining factor in generative AI. As many now operate at comparable levels ofcapability, the real race is not about having the biggest model but optimizingthe surrounding ecosystem, including data quality and management, computationalefficiency, latency, and evaluation frameworks. This review article delves intothese critical differentiators that ensure modern AI services are efficient andprofitable.</description>
      <author>example@mail.com (Muskaan Goyal, Pranav Bhasin)</author>
      <guid isPermaLink="false">2505.02489v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Real-time Spatial Retrieval Augmented Generation for Urban Environments</title>
      <link>http://arxiv.org/abs/2505.02271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了生成式人工智能，特别是大型语言模型在城市化应用中的潜力，并提出了一个基于FIWARE的实时空间RAG架构，以解决传统RAG架构在城市化环境中的不足。&lt;h4&gt;背景&lt;/h4&gt;生成式人工智能在城市化应用中具有变革性潜力，但基础模型存在局限性，更新耗时且成本高。&lt;h4&gt;目的&lt;/h4&gt;提出一种实时空间RAG架构，以有效整合生成式人工智能到城市中，并解决传统RAG架构在城市化环境中的不足。&lt;h4&gt;方法&lt;/h4&gt;使用FIWARE开发实时空间RAG架构，利用链接数据的时空过滤能力。&lt;h4&gt;主要发现&lt;/h4&gt;该架构在Madrid市的旅游助手用例中得到了验证，证明了通过RAG架构正确整合基础模型的可行性。&lt;h4&gt;结论&lt;/h4&gt;提出的实时空间RAG架构能够有效解决城市化环境中的信息注入问题，为生成式人工智能在城市化中的应用提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;The paper discusses the potential of generative artificial intelligence, especially large language models, in urban applications, and proposes a real-time spatial RAG architecture based on FIWARE to address the limitations of traditional RAG architectures in urban contexts.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of Generative Artificial Ingelligence (AI), especiallyLarge Language Models, presents transformative opportunities for urbanapplications through Urban Foundation Models. However, base models facelimitations, as they only contain the knowledge available at the time oftraining, and updating them is both time-consuming and costly. RetrievalAugmented Generation (RAG) has emerged in the literature as the preferredapproach for injecting contextual information into Foundation Models. Itprevails over techniques such as fine-tuning, which are less effective indynamic, real-time scenarios like those found in urban environments. However,traditional RAG architectures, based on semantic databases, knowledge graphs,structured data, or AI-powered web searches, do not fully meet the demands ofurban contexts. Urban environments are complex systems characterized by largevolumes of interconnected data, frequent updates, real-time processingrequirements, security needs, and strong links to the physical world. This workproposes a real-time spatial RAG architecture that defines the necessarycomponents for the effective integration of generative AI into cities,leveraging temporal and spatial filtering capabilities through linked data. Theproposed architecture is implemented using FIWARE, an ecosystem of softwarecomponents to develop smart city solutions and digital twins. The design andimplementation are demonstrated through the use case of a tourism assistant inthe city of Madrid. The use case serves to validate the correct integration ofFoundation Models through the proposed RAG architecture.</description>
      <author>example@mail.com (David Nazareno Campo, Javier Conde, Álvaro Alonso, Gabriel Huecas, Joaquín Salvachúa, Pedro Reviriego)</author>
      <guid isPermaLink="false">2505.02271v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>HybridGS: High-Efficiency Gaussian Splatting Data Compression using Dual-Channel Sparse Representation and Point Cloud Encoder</title>
      <link>http://arxiv.org/abs/2505.01938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HybridGS的3D Gaussian Splatting压缩框架，旨在提高3DGS数据的压缩效率。&lt;h4&gt;背景&lt;/h4&gt;现有的3DGS压缩方案主要通过隐式数据嵌入来生成紧凑的表示，但存在编码时间长、数据格式高度定制化的问题，难以广泛应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个既能够生成紧凑表示，又能进行标准化点云数据编码的3DGS压缩框架。&lt;h4&gt;方法&lt;/h4&gt;HybridGS首先生成紧凑且显式的3DGS数据，引入双通道稀疏表示来监督基本位置和特征位深。然后，使用规范化的点云编码器进行进一步的数据压缩，形成标准输出位流。此外，提出了一种简单有效的速率控制方案来调整可解释的数据压缩方案。&lt;h4&gt;主要发现&lt;/h4&gt;目前，HybridGS不包含旨在提高3DGS生成质量的模块。然而，实验结果表明，它仍然提供了与现有方法相当的重构性能，并且编码和解码速度明显更高。&lt;h4&gt;结论&lt;/h4&gt;HybridGS是一种高效且易于部署的3DGS压缩框架。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大多数现有的3D高斯分层（3DGS）压缩方案都侧重于通过隐式数据嵌入来生成紧凑的3DGS表示。它们具有较长的编码时间和高定制化的数据格式，这使得它们难以广泛应用。本文提出了一种新的3DGS压缩框架，称为HybridGS，它利用了紧凑生成和标准化点云数据编码的优势。HybridGS首先生成紧凑且显式的3DGS数据。引入双通道稀疏表示来监督基本位置和特征位深。然后，利用规范化的点云编码器进行进一步的数据压缩，形成标准输出位流。提出了一种简单有效的速率控制方案来调整可解释的数据压缩方案。目前，HybridGS不包含旨在提高3DGS生成质量的模块。但实验结果表明，它仍然提供了与现有方法相当的重构性能，并且编码和解码速度明显更高。代码可在https://github.com/Qi-Yangsjtu/HybridGS上公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most existing 3D Gaussian Splatting (3DGS) compression schemes focus onproducing compact 3DGS representation via implicit data embedding. They havelong coding times and highly customized data format, making it difficult forwidespread deployment. This paper presents a new 3DGS compression frameworkcalled HybridGS, which takes advantage of both compact generation andstandardized point cloud data encoding. HybridGS first generates compact andexplicit 3DGS data. A dual-channel sparse representation is introduced tosupervise the primitive position and feature bit depth. It then utilizes acanonical point cloud encoder to perform further data compression and formstandard output bitstreams. A simple and effective rate control scheme isproposed to pivot the interpretable data compression scheme. At the currentstage, HybridGS does not include any modules aimed at improving 3DGS qualityduring generation. But experiment results show that it still providescomparable reconstruction performance against state-of-the-art methods, withevidently higher encoding and decoding speed. The code is publicly available athttps://github.com/Qi-Yangsjtu/HybridGS.</description>
      <author>example@mail.com (Qi Yang, Le Yang, Geert Van Der Auwera, Zhu Li)</author>
      <guid isPermaLink="false">2505.01938v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>RISE: Radius of Influence based Subgraph Extraction for 3D Molecular Graph Explanation</title>
      <link>http://arxiv.org/abs/2505.02247v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的解释方法，专门针对3D Geometric Graph Neural Networks（GNNs），旨在解决3D GNNs在分子数据建模中的可解释性问题。&lt;h4&gt;背景&lt;/h4&gt;3D GNNs在分子数据建模中具有强大的预测能力，但通常缺乏可解释性，这在需要可靠和透明洞察的科学应用中引起担忧。&lt;h4&gt;目的&lt;/h4&gt;提高3D GNNs的可解释性，使其在科学应用中更加可靠和透明。&lt;h4&gt;方法&lt;/h4&gt;该方法将解释局部化到每个节点的3D空间中的直接邻域，并为每个节点分配一个影响半径，定义了消息传递捕获空间和结构交互的局部化区域。&lt;h4&gt;主要发现&lt;/h4&gt;通过限制子图到局部化的影响半径，这种方法不仅增强了可解释性，而且与3D图应用中典型的物理和结构依赖性相一致，如分子学习。&lt;h4&gt;结论&lt;/h4&gt;该方法利用了3D图固有的空间和几何特征，为3D GNNs提供了一种新的解释方法，有助于提高模型的可解释性和透明度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Geometric Graph Neural Networks (GNNs) have emerged as transformativetools for modeling molecular data. Despite their predictive power, these modelsoften suffer from limited interpretability, raising concerns for scientificapplications that require reliable and transparent insights. While existingmethods have primarily focused on explaining molecular substructures in 2DGNNs, the transition to 3D GNNs introduces unique challenges, such as handlingthe implicit dense edge structures created by a cut-off radius. To tackle this,we introduce a novel explanation method specifically designed for 3D GNNs,which localizes the explanation to the immediate neighborhood of each nodewithin the 3D space. Each node is assigned an radius of influence, defining thelocalized region within which message passing captures spatial and structuralinteractions crucial for the model's predictions. This method leverages thespatial and geometric characteristics inherent in 3D graphs. By constrainingthe subgraph to a localized radius of influence, the approach not only enhancesinterpretability but also aligns with the physical and structural dependenciestypical of 3D graph applications, such as molecular learning.</description>
      <author>example@mail.com (Jingxiang Qu, Wenhan Gao, Jiaxing Zhang, Xufeng Liu, Hua Wei, Haibin Ling, Yi Liu)</author>
      <guid isPermaLink="false">2505.02247v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Prompt-responsive Object Retrieval with Memory-augmented Student-Teacher Learning</title>
      <link>http://arxiv.org/abs/2505.02232v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合提示式基础模型和强化学习的方法，使机器人能够以提示响应的方式执行灵活的操纵任务。&lt;h4&gt;背景&lt;/h4&gt;构建对输入提示有响应的模型是机器学习领域的一次变革，这种方法在机器人领域，如杂乱环境中的针对性操作等问题上具有巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法难以将高级命令与精细的灵活控制相联系的问题。&lt;h4&gt;方法&lt;/h4&gt;采用了一种记忆增强的学生-教师学习框架，使用Segment-Anything 2 (SAM 2)模型作为感知骨干，从用户提示中推断出感兴趣的对象。虽然检测可能不完美，但它们的时序为记忆增强模型提供了丰富的隐含状态估计信息。&lt;h4&gt;主要发现&lt;/h4&gt;该方法成功地学习了提示响应策略，并在从杂乱场景中拾取物体等任务中得到了演示。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在机器人灵活操纵任务中表现出色，并展示了其在实际应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Building models responsive to input prompts represents a transformative shift in machine learning. This paradigm holds significant potential for robotics problems, such as targeted manipulation amidst clutter. In this work, we present a novel approach to combine promptable foundation models with reinforcement learning (RL), enabling robots to perform dexterous manipulation tasks in a prompt-responsive manner. Existing methods struggle to link high-level commands with fine-grained dexterous control. We address this gap with a memory-augmented student-teacher learning framework. We use the Segment-Anything 2 (SAM 2) model as a perception backbone to infer an object of interest from user prompts. While detections are imperfect, their temporal sequence provides rich information for implicit state estimation by memory-augmented models. Our approach successfully learns prompt-responsive policies, demonstrated in picking objects from cluttered scenes. Videos and code are available at https://memory-student-teacher.github.io&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building models responsive to input prompts represents a transformative shiftin machine learning. This paradigm holds significant potential for roboticsproblems, such as targeted manipulation amidst clutter. In this work, wepresent a novel approach to combine promptable foundation models withreinforcement learning (RL), enabling robots to perform dexterous manipulationtasks in a prompt-responsive manner. Existing methods struggle to linkhigh-level commands with fine-grained dexterous control. We address this gapwith a memory-augmented student-teacher learning framework. We use theSegment-Anything 2 (SAM 2) model as a perception backbone to infer an object ofinterest from user prompts. While detections are imperfect, their temporalsequence provides rich information for implicit state estimation bymemory-augmented models. Our approach successfully learns prompt-responsivepolicies, demonstrated in picking objects from cluttered scenes. Videos andcode are available at https://memory-student-teacher.github.io</description>
      <author>example@mail.com (Malte Mosbach, Sven Behnke)</author>
      <guid isPermaLink="false">2505.02232v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Graph Representation Learning for Robust Surgical Workflow Recognition with Adversarial Feature Disentanglement</title>
      <link>http://arxiv.org/abs/2505.01766v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Information Fusion&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于图的鲁棒多模态方法，以整合视觉和运动数据，提高手术流程识别的准确性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;手术流程识别对于自动化任务、支持决策和培训新外科医生至关重要，但数据损坏可能导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;旨在提高手术流程识别的鲁棒性，特别是在有领域偏移或数据损坏的复杂场景中。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为GRAD的多模态图表示网络，用于捕捉精细的视觉信息，并通过基于图的消息建模显式地建模视觉和运动嵌入之间的复杂关系。还提出了一个视觉-运动对抗框架和上下文校准解码器。&lt;h4&gt;主要发现&lt;/h4&gt;模型和模块的有效性通过广泛的比较和消融实验得到了证明。鲁棒性实验表明，该方法能够有效处理存储和传输过程中的数据损坏，表现出良好的稳定性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该方法旨在推进自动化手术流程识别，解决手术程序固有的复杂性和动态性。&lt;h4&gt;翻译&lt;/h4&gt;Surgical workflow recognition is vital for automating tasks, supporting decision-making, and training novice surgeons, ultimately improving patient safety and standardizing procedures. However, data corruption can lead to performance degradation due to issues like occlusion from bleeding or smoke in surgical scenes and problems with data storage and transmission. In this case, we explore a robust graph-based multimodal approach to integrating vision and kinematic data to enhance accuracy and reliability. Vision data captures dynamic surgical scenes, while kinematic data provides precise movement information, overcoming limitations of visual recognition under adverse conditions. We propose a multimodal Graph Representation network with Adversarial feature Disentanglement (GRAD) for robust surgical workflow recognition in challenging scenarios with domain shifts or corrupted data. Specifically, we introduce a Multimodal Disentanglement Graph Network that captures fine-grained visual information while explicitly modeling the complex relationships between vision and kinematic embeddings through graph-based message modeling. To align feature spaces across modalities, we propose a Vision-Kinematic Adversarial framework that leverages adversarial training to reduce modality gaps and improve feature consistency. Furthermore, we design a Contextual Calibrated Decoder, incorporating temporal and contextual priors to enhance robustness against domain shifts and corrupted data. Extensive comparative and ablation experiments demonstrate the effectiveness of our model and proposed modules. Moreover, our robustness experiments show that our method effectively handles data corruption during storage and transmission, exhibiting excellent stability and robustness. Our approach aims to advance automated surgical workflow recognition, addressing the complexities and dynamism inherent in surgical procedures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgical workflow recognition is vital for automating tasks, supportingdecision-making, and training novice surgeons, ultimately improving patientsafety and standardizing procedures. However, data corruption can lead toperformance degradation due to issues like occlusion from bleeding or smoke insurgical scenes and problems with data storage and transmission. In this case,we explore a robust graph-based multimodal approach to integrating vision andkinematic data to enhance accuracy and reliability. Vision data capturesdynamic surgical scenes, while kinematic data provides precise movementinformation, overcoming limitations of visual recognition under adverseconditions. We propose a multimodal Graph Representation network withAdversarial feature Disentanglement (GRAD) for robust surgical workflowrecognition in challenging scenarios with domain shifts or corrupted data.Specifically, we introduce a Multimodal Disentanglement Graph Network thatcaptures fine-grained visual information while explicitly modeling the complexrelationships between vision and kinematic embeddings through graph-basedmessage modeling. To align feature spaces across modalities, we propose aVision-Kinematic Adversarial framework that leverages adversarial training toreduce modality gaps and improve feature consistency. Furthermore, we design aContextual Calibrated Decoder, incorporating temporal and contextual priors toenhance robustness against domain shifts and corrupted data. Extensivecomparative and ablation experiments demonstrate the effectiveness of our modeland proposed modules. Moreover, our robustness experiments show that our methodeffectively handles data corruption during storage and transmission, exhibitingexcellent stability and robustness. Our approach aims to advance automatedsurgical workflow recognition, addressing the complexities and dynamisminherent in surgical procedures.</description>
      <author>example@mail.com (Long Bai, Boyi Ma, Ruohan Wang, Guankun Wang, Beilei Cui, Zhongliang Jiang, Mobarakol Islam, Zhe Min, Jiewen Lai, Nassir Navab, Hongliang Ren)</author>
      <guid isPermaLink="false">2505.01766v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Exploring new Approaches for Information Retrieval through Natural Language Processing</title>
      <link>http://arxiv.org/abs/2505.02199v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 4 figures, comprehensive literature review covering six key  IR-NLP papers, plus keywords and full reference list&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了信息检索（IR）在自然语言处理（NLP）中的应用的最新进展和新兴方法。&lt;h4&gt;背景&lt;/h4&gt;文章回顾了传统的IR模型，包括布尔模型、向量空间模型、概率模型和推理网络模型。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探讨现代技术，如深度学习、强化学习和预训练的转换器模型（如BERT）。&lt;h4&gt;方法&lt;/h4&gt;文章讨论了用于高效文本索引和搜索的关键工具和库，如Lucene、Anserini和Pyserini。&lt;h4&gt;主要发现&lt;/h4&gt;文章对稀疏、密集和混合检索方法进行了比较分析，并展示了它们在网页搜索引擎、跨语言IR、论点挖掘、私人信息检索和仇恨言论检测中的应用。&lt;h4&gt;结论&lt;/h4&gt;最后，文章确定了提高检索精度、可扩展性和考虑伦理问题的开放挑战和未来研究方向。&lt;h4&gt;翻译&lt;/h4&gt;This review paper explores recent advancements and emerging approaches in Information Retrieval (IR) applied to Natural Language Processing (NLP). We examine traditional IR models such as Boolean, vector space, probabilistic, and inference network models, and highlight modern techniques including deep learning, reinforcement learning, and pretrained transformer models like BERT. We discuss key tools and libraries - Lucene, Anserini, and Pyserini - for efficient text indexing and search. A comparative analysis of sparse, dense, and hybrid retrieval methods is presented, along with applications in web search engines, cross-language IR, argument mining, private information retrieval, and hate speech detection. Finally, we identify open challenges and future research directions to enhance retrieval accuracy, scalability, and ethical considerations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This review paper explores recent advancements and emerging approaches inInformation Retrieval (IR) applied to Natural Language Processing (NLP). Weexamine traditional IR models such as Boolean, vector space, probabilistic, andinference network models, and highlight modern techniques including deeplearning, reinforcement learning, and pretrained transformer models like BERT.We discuss key tools and libraries - Lucene, Anserini, and Pyserini - forefficient text indexing and search. A comparative analysis of sparse, dense,and hybrid retrieval methods is presented, along with applications in websearch engines, cross-language IR, argument mining, private informationretrieval, and hate speech detection. Finally, we identify open challenges andfuture research directions to enhance retrieval accuracy, scalability, andethical considerations.</description>
      <author>example@mail.com (Manak Raj, Nidhi Mishra)</author>
      <guid isPermaLink="false">2505.02199v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Contextures: Representations from Contexts</title>
      <link>http://arxiv.org/abs/2505.01557v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025, longer version. arXiv admin note: substantial text overlap  with arXiv:2504.19792&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了上下文结构理论，用以描述大型模型学习到的表示，并证明了许多流行的学习方法都可以通过学习输入与上下文变量之间的关联来表征。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型在实证上取得了成功，但我们缺乏对这些模型学习到的表示的系统描述。&lt;h4&gt;目的&lt;/h4&gt;建立上下文结构理论，以系统地描述大型模型学习到的表示。&lt;h4&gt;方法&lt;/h4&gt;通过证明许多流行的学习方法可以描述为从输入和上下文变量之间的关联中学习，以及上下文结构理论在监督学习、自监督学习和流形学习等不同学习范式中的适用性。&lt;h4&gt;主要发现&lt;/h4&gt;上下文结构理论表明，学习上下文结构的表示在兼容上下文的任务上是最优的；模型规模达到可以近似最高奇异函数的程度后，进一步扩大模型规模将带来递减的回报；提出了一种评估上下文有用性的指标，并通过实验证明它与编码器在实际数据集上的性能有很好的相关性。&lt;h4&gt;结论&lt;/h4&gt;上下文结构理论为理解大型模型的学习提供了新的视角，并指出除了规模扩大外，提高上下文质量也是进一步提升模型性能的关键。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管基础模型在实证上取得了成功，但我们缺乏对这些模型学习到的表示的系统描述。在本文中，我们建立了上下文结构理论。它表明，一类广泛的表示学习方法可以表征为从输入与上下文变量之间的关联中学习。具体来说，我们表明许多流行的方法旨在逼近由上下文诱导的期望算子的最高奇异函数，在这种情况下，我们说表示学习上下文结构。我们通过证明表示学习在各种学习范式（监督学习、自监督学习和流形学习）中都可以从这种角度进行研究，来演示上下文结构理论的普遍性。我们还证明，学习上下文结构的表示在兼容上下文的任务上是最佳的。上下文结构理论的一个重要含义是，一旦模型足够大，可以逼近最高奇异函数，进一步扩大模型规模将带来递减的回报。因此，规模扩大并不是我们所需要的全部，进一步的改进需要更好的上下文。为此，我们研究了如何在不知道下游任务的情况下评估上下文的有用性。我们提出了一种指标，并通过实验表明，它与编码器在许多真实数据集上的实际性能有很好的相关性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the empirical success of foundation models, we do not have asystematic characterization of the representations that these models learn. Inthis paper, we establish the contexture theory. It shows that a large class ofrepresentation learning methods can be characterized as learning from theassociation between the input and a context variable. Specifically, we showthat many popular methods aim to approximate the top-d singular functions ofthe expectation operator induced by the context, in which case we say that therepresentation learns the contexture. We demonstrate the generality of thecontexture theory by proving that representation learning within variouslearning paradigms -- supervised, self-supervised, and manifold learning -- canall be studied from such a perspective. We also prove that the representationsthat learn the contexture are optimal on those tasks that are compatible withthe context. One important implication of the contexture theory is that oncethe model is large enough to approximate the top singular functions, furtherscaling up the model size yields diminishing returns. Therefore, scaling is notall we need, and further improvement requires better contexts. To this end, westudy how to evaluate the usefulness of a context without knowing thedownstream tasks. We propose a metric and show by experiments that itcorrelates well with the actual performance of the encoder on many realdatasets.</description>
      <author>example@mail.com (Runtian Zhai, Kai Yang, Che-Ping Tsai, Burak Varici, Zico Kolter, Pradeep Ravikumar)</author>
      <guid isPermaLink="false">2505.01557v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>Sparfels: Fast Reconstruction from Sparse Unposed Imagery</title>
      <link>http://arxiv.org/abs/2505.02178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page : https://shubhendu-jena.github.io/Sparfels/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种使用表面元素平铺的稀疏视图重建方法，该方法在消费级GPU上运行时间少于3分钟。&lt;h4&gt;背景&lt;/h4&gt;目前关于从噪声或未定位的稀疏相机学习稀疏辐射场的方法较少，在此设置下的形状恢复相对较少研究。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效且简单的流程，利用最新的3D基础模型，以实现稀疏视图重建。&lt;h4&gt;方法&lt;/h4&gt;利用3D基础模型的多个任务头，特别是点图和相机初始化，构建一个2D高斯平铺（2DGS）模型，并通过图像对应关系指导2DGS训练中的相机优化。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种新的沿射线平铺颜色变差的公式，该公式可以高效计算。在训练中降低这一时刻可以导致更准确的形状重建。&lt;h4&gt;结论&lt;/h4&gt;在稀疏未校准设置中的重建和基于已建立的多视图数据集的新视角基准测试中，该方法展示了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种稀疏视图重建方法，该方法使用表面元素平铺，在消费级GPU上运行时间少于3分钟。虽然很少有方法解决从噪声或未定位的稀疏相机学习稀疏辐射场的问题，但在此设置下的形状恢复相对较少被探索。一些辐射场和形状学习测试时间优化方法通过学习数据先验或使用外部单目几何先验的组合来解决稀疏定位设置。不同之处在于，我们提出了一种高效且简单的流程，利用单个最新的3D基础模型。我们利用其各种任务头，特别是点图和相机初始化来实例化一个2D高斯平铺（2DGS）模型，并通过图像对应关系引导2DGS训练中的相机优化。我们贡献的关键是一个新的沿射线平铺颜色变差的公式，该公式可以高效计算。在训练中降低这一时刻可以导致更准确的形状重建。我们在稀疏未校准设置中的重建和基于已建立的多视图数据集的新视角基准测试中展示了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a method for Sparse view reconstruction with surface elementsplatting that runs within 3 minutes on a consumer grade GPU. While few methodsaddress sparse radiance field learning from noisy or unposed sparse cameras,shape recovery remains relatively underexplored in this setting. Severalradiance and shape learning test-time optimization methods address the sparseposed setting by learning data priors or using combinations of externalmonocular geometry priors. Differently, we propose an efficient and simplepipeline harnessing a single recent 3D foundation model. We leverage itsvarious task heads, notably point maps and camera initializations toinstantiate a bundle adjusting 2D Gaussian Splatting (2DGS) model, and imagecorrespondences to guide camera optimization midst 2DGS training. Key to ourcontribution is a novel formulation of splatted color variance along rays,which can be computed efficiently. Reducing this moment in training leads tomore accurate shape reconstructions. We demonstrate state-of-the-artperformances in the sparse uncalibrated setting in reconstruction and novelview benchmarks based on established multi-view datasets.</description>
      <author>example@mail.com (Shubhendu Jena, Amine Ouasfi, Mae Younes, Adnane Boukhayma)</author>
      <guid isPermaLink="false">2505.02178v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:42 +0800</pubDate>
    </item>
    <item>
      <title>3DWG: 3D Weakly Supervised Visual Grounding via Category and Instance-Level Alignment</title>
      <link>http://arxiv.org/abs/2505.01809v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的弱监督视觉定位方法，用于在点云中根据自然语言描述定位定向3D框，无需标注来指导模型学习。&lt;h4&gt;背景&lt;/h4&gt;该任务面临两个主要挑战：类别级别的模糊性和实例级别的复杂性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一个能够明确区分类别和实例的新方法。&lt;h4&gt;方法&lt;/h4&gt;在类别级别分支中，利用预训练的外部检测器的大量类别知识，将对象提议特征与句子级别的类别特征对齐，从而增强类别意识。在实例级别分支中，利用语言查询中的空间关系描述来细化对象提议特征，确保对象之间的清晰区分。&lt;h4&gt;主要发现&lt;/h4&gt;这些设计使得模型能够准确识别目标类别对象，同时区分同一类别内的实例。&lt;h4&gt;结论&lt;/h4&gt;与先前的方法相比，该方法在三个广泛使用的基准测试（Nr3D、Sr3D和ScanRef）上实现了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The 3D weakly-supervised visual grounding task aims to localize oriented 3Dboxes in point clouds based on natural language descriptions without requiringannotations to guide model learning. This setting presents two primarychallenges: category-level ambiguity and instance-level complexity.Category-level ambiguity arises from representing objects of fine-grainedcategories in a highly sparse point cloud format, making category distinctionchallenging. Instance-level complexity stems from multiple instances of thesame category coexisting in a scene, leading to distractions during grounding.To address these challenges, we propose a novel weakly-supervised groundingapproach that explicitly differentiates between categories and instances. Inthe category-level branch, we utilize extensive category knowledge from apre-trained external detector to align object proposal features withsentence-level category features, thereby enhancing category awareness. In theinstance-level branch, we utilize spatial relationship descriptions fromlanguage queries to refine object proposal features, ensuring cleardifferentiation among objects. These designs enable our model to accuratelyidentify target-category objects while distinguishing instances within the samecategory. Compared to previous methods, our approach achieves state-of-the-artperformance on three widely used benchmarks: Nr3D, Sr3D, and ScanRef.</description>
      <author>example@mail.com (Xiaoqi Li, Jiaming Liu, Nuowei Han, Liang Heng, Yandong Guo, Hao Dong, Yang Liu)</author>
      <guid isPermaLink="false">2505.01809v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data</title>
      <link>http://arxiv.org/abs/2505.02130v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML2025 Accept&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;注意力机制对大型语言模型（LLMs）的成功至关重要，但在处理图结构数据时，与图神经网络（GNNs）中使用的基于固定链接的消息传递机制相比，存在不足。&lt;h4&gt;背景&lt;/h4&gt;对于图结构数据，需要强调拓扑连接，而现有的注意力机制在处理这类数据时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;从注意力机制的角度进行实证研究，探索LLMs如何处理图结构数据，以深入了解LLMs在图结构上的注意力行为。&lt;h4&gt;方法&lt;/h4&gt;分析LLMs在图结构数据上的注意力应用，并评估不同注意力模型的效果。&lt;h4&gt;主要发现&lt;/h4&gt;1) LLMs可以识别图数据并捕捉文本节点之间的交互，但由于固有架构限制，难以建模图结构内部的节点关系。2) LLMs在图节点上的注意力分布不符合理想的结构模式，表明其未能适应图拓扑的细微差别。3) 无论是全连接注意力还是固定连接性都不理想；每种方法在其应用场景中都有特定的局限性。相反，中间状态注意力窗口可以提高LLMs的训练性能，并在推理过程中无缝过渡到全连接窗口。&lt;h4&gt;结论&lt;/h4&gt;LLMs在处理图结构数据时存在局限性，需要改进模型以更好地处理此类数据。&lt;h4&gt;翻译&lt;/h4&gt;注意力机制对于大型语言模型（LLMs）的成功至关重要，然而，在处理需要强调拓扑连接的图结构数据时，与在固定链接上使用的消息传递机制（如图神经网络GNNs所采用的）相比，它们存在不足。然而，对于图结构数据，需要强调拓扑连接，而现有的注意力机制在处理这类数据时存在局限性。受这些观察的启发，我们从注意力机制的角度进行了实证研究，以探索LLMs如何处理图结构数据。目的是深入了解LLMs在图结构上的注意力行为。我们发现了一些关于LLMs如何将注意力应用于图结构数据的独特现象，并分析了这些发现以改进LLMs对这类数据的建模。研究的主要发现是：1）虽然LLMs可以识别图数据并捕捉文本节点之间的交互，但由于固有的架构限制，它们难以建模图结构内部的节点关系。2）LLMs在图节点上的注意力分布不符合理想的结构模式，表明其未能适应图拓扑的细微差别。3）无论是全连接注意力还是固定连接性都不理想；每种方法在其应用场景中都有特定的局限性。相反，中间状态注意力窗口可以提高LLMs的训练性能，并在推理过程中无缝过渡到全连接窗口。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Attention mechanisms are critical to the success of large language models(LLMs), driving significant advancements in multiple fields. However, forgraph-structured data, which requires emphasis on topological connections, theyfall short compared to message-passing mechanisms on fixed links, such as thoseemployed by Graph Neural Networks (GNNs). This raises a question: ``Doesattention fail for graphs in natural language settings?'' Motivated by theseobservations, we embarked on an empirical study from the perspective ofattention mechanisms to explore how LLMs process graph-structured data. Thegoal is to gain deeper insights into the attention behavior of LLMs over graphstructures. We uncovered unique phenomena regarding how LLMs apply attention tograph-structured data and analyzed these findings to improve the modeling ofsuch data by LLMs. The primary findings of our research are: 1) While LLMs canrecognize graph data and capture text-node interactions, they struggle to modelinter-node relationships within graph structures due to inherent architecturalconstraints. 2) The attention distribution of LLMs across graph nodes does notalign with ideal structural patterns, indicating a failure to adapt to graphtopology nuances. 3) Neither fully connected attention nor fixed connectivityis optimal; each has specific limitations in its application scenarios.Instead, intermediate-state attention windows improve LLM training performanceand seamlessly transition to fully connected windows during inference. Sourcecode: \href{https://github.com/millioniron/LLM_exploration}{LLM4Exploration}</description>
      <author>example@mail.com (Zhong Guan, Likang Wu, Hongke Zhao, Ming He, Jianpin Fan)</author>
      <guid isPermaLink="false">2505.02130v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Interleave-VLA: Enhancing Robot Manipulation with Interleaved Image-Text Instructions</title>
      <link>http://arxiv.org/abs/2505.02152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Interleave-VLA框架，该框架能够理解交错图像-文本指令并在物理世界中直接生成连续的动作序列。&lt;h4&gt;背景&lt;/h4&gt;现有的VLA模型仅限于处理机器人的观察和文本指令，缺乏数字世界中由基础模型进展带来的交错多模态指令的灵活性。&lt;h4&gt;目的&lt;/h4&gt;提出一个灵活的、模型无关的范式，通过最小修改扩展最先进的VLA模型，并实现强大的零样本泛化。&lt;h4&gt;方法&lt;/h4&gt;开发了一个自动管道，将Open X-Embodiment中的真实世界数据集的纯文本指令转换为交错图像-文本指令，构建了第一个包含210k个场景的大型真实世界交错具身数据集。&lt;h4&gt;主要发现&lt;/h4&gt;Interleave-VLA在模拟基准和真实机器人实验中表现出显著优势：1）与最先进的基线相比，它将域外泛化能力提高了2-3倍；2）支持灵活的任务接口；3）以零样本方式处理多样化的用户提供的图像指令，如手绘草图。&lt;h4&gt;结论&lt;/h4&gt;Interleave-VLA通过交错范式有效地利用了异构数据集和多样化的指令图像，包括来自互联网的图像，显示出强大的扩展潜力。模型和数据集将开源。&lt;h4&gt;翻译&lt;/h4&gt;Vision-Language-Action (VLA) 模型在物理世界的通用机器人操作方面展现出巨大潜力。然而，现有的模型局限于机器人观察和纯文本指令，缺乏由数字世界中基础模型进展带来的交错多模态指令的灵活性。在本文中，我们提出了Interleave-VLA，这是第一个能够理解交错图像-文本指令并在物理世界中直接生成连续动作序列的框架。它提供了一个灵活的、模型无关的范式，通过最小修改扩展了最先进的VLA模型，并实现了强大的零样本泛化。实现Interleave-VLA的一个关键挑战是缺乏大规模的交错具身数据集。为了弥合这一差距，我们开发了一个自动管道，将Open X-Embodiment中的真实世界数据集的纯文本指令转换为交错图像-文本指令，从而产生了第一个包含210k个场景的大型真实世界交错具身数据集。通过在模拟基准和真实机器人实验上的综合评估，我们证明了Interleave-VLA的优势：1）与最先进的基线相比，它将域外泛化能力提高了2-3倍；2）支持灵活的任务接口；3）以零样本方式处理多样化的用户提供的图像指令，如手绘草图。我们进一步分析了Interleave-VLA强大零样本性能背后的因素，表明交错范式有效地利用了异构数据集和多样化的指令图像，包括来自互联网的图像，这表明了强大的扩展潜力。我们的模型和数据集将开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language-Action (VLA) models have shown great promise for generalistrobotic manipulation in the physical world. However, existing models arerestricted to robot observations and text-only instructions, lacking theflexibility of interleaved multimodal instructions enabled by recent advancesin foundation models in the digital world. In this paper, we presentInterleave-VLA, the first framework capable of comprehending interleavedimage-text instructions and directly generating continuous action sequences inthe physical world. It offers a flexible, model-agnostic paradigm that extendsstate-of-the-art VLA models with minimal modifications and strong zero-shotgeneralization. A key challenge in realizing Interleave-VLA is the absence oflarge-scale interleaved embodied datasets. To bridge this gap, we develop anautomatic pipeline that converts text-only instructions from real-worlddatasets in Open X-Embodiment into interleaved image-text instructions,resulting in the first large-scale real-world interleaved embodied dataset with210k episodes. Through comprehensive evaluation on simulation benchmarks andreal-robot experiments, we demonstrate that Interleave-VLA offers significantbenefits: 1) it improves out-of-domain generalization to unseen objects by 2-3xcompared to state-of-the-art baselines, 2) supports flexible task interfaces,and 3) handles diverse user-provided image instructions in a zero-shot manner,such as hand-drawn sketches. We further analyze the factors behindInterleave-VLA's strong zero-shot performance, showing that the interleavedparadigm effectively leverages heterogeneous datasets and diverse instructionimages, including those from the Internet, which demonstrates strong potentialfor scaling up. Our model and dataset will be open-sourced.</description>
      <author>example@mail.com (Cunxin Fan, Xiaosong Jia, Yihang Sun, Yixiao Wang, Jianglan Wei, Ziyang Gong, Xiangyu Zhao, Masayoshi Tomizuka, Xue Yang, Junchi Yan, Mingyu Ding)</author>
      <guid isPermaLink="false">2505.02152v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Probabilistic Interactive 3D Segmentation with Hierarchical Neural Processes</title>
      <link>http://arxiv.org/abs/2505.01726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 Proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NPISeg3D的新颖概率框架，用于解决交互式3D分割中的两个关键挑战：从稀疏用户点击生成准确分割以及量化预测不确定性。&lt;h4&gt;背景&lt;/h4&gt;交互式3D分割通过结合用户点击在复杂3D场景中生成准确的对象掩码，但存在两个未充分探索的挑战：从稀疏用户点击到准确分割的有效泛化，以及量化预测不确定性以帮助用户识别不可靠区域。&lt;h4&gt;目的&lt;/h4&gt;提出NPISeg3D框架，以解决上述两个挑战，实现更准确的分割和可靠的预测不确定性估计。&lt;h4&gt;方法&lt;/h4&gt;NPISeg3D利用神经过程（NPs）构建了一个具有场景特异性和对象特异性潜在变量的分层潜在变量结构，以增强少样本泛化能力。此外，设计了一个概率原型调制器，通过对象特异性潜在变量自适应地调节点击原型，提高模型捕捉对象感知上下文和量化预测不确定性的能力。&lt;h4&gt;主要发现&lt;/h4&gt;在四个3D点云数据集上的实验表明，NPISeg3D在较少点击的情况下实现了优越的分割性能，并提供了可靠的预测不确定性估计。&lt;h4&gt;结论&lt;/h4&gt;NPISeg3D框架能够有效地解决交互式3D分割中的关键挑战，为生成准确的对象掩码提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Interactive 3D segmentation has emerged as a promising solution for generating accurate object masks in complex 3D scenes by incorporating user-provided clicks. However, two critical challenges remain underexplored: (1) effectively generalizing from sparse user clicks to produce accurate segmentation, and (2) quantifying predictive uncertainty to help users identify unreliable regions. In this work, we propose NPISeg3D, a novel probabilistic framework that builds upon Neural Processes (NPs) to address these challenges. Specifically, NPISeg3D introduces a hierarchical latent variable structure with scene-specific and object-specific latent variables to enhance few-shot generalization by capturing both global context and object-specific characteristics. Additionally, we design a probabilistic prototype modulator that adaptively modulates click prototypes with object-specific latent variables, improving the model's ability to capture object-aware context and quantify predictive uncertainty. Experiments on four 3D point cloud datasets demonstrate that NPISeg3D achieves superior segmentation performance with fewer clicks while providing reliable uncertainty estimations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interactive 3D segmentation has emerged as a promising solution forgenerating accurate object masks in complex 3D scenes by incorporatinguser-provided clicks. However, two critical challenges remain underexplored:(1) effectively generalizing from sparse user clicks to produce accuratesegmentation, and (2) quantifying predictive uncertainty to help users identifyunreliable regions. In this work, we propose NPISeg3D, a novel probabilisticframework that builds upon Neural Processes (NPs) to address these challenges.Specifically, NPISeg3D introduces a hierarchical latent variable structure withscene-specific and object-specific latent variables to enhance few-shotgeneralization by capturing both global context and object-specificcharacteristics. Additionally, we design a probabilistic prototype modulatorthat adaptively modulates click prototypes with object-specific latentvariables, improving the model's ability to capture object-aware context andquantify predictive uncertainty. Experiments on four 3D point cloud datasetsdemonstrate that NPISeg3D achieves superior segmentation performance with fewerclicks while providing reliable uncertainty estimations.</description>
      <author>example@mail.com (Jie Liu, Pan Zhou, Zehao Xiao, Jiayi Shen, Wenzhe Yin, Jan-Jakob Sonke, Efstratios Gavves)</author>
      <guid isPermaLink="false">2505.01726v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>TeMTG: Text-Enhanced Multi-Hop Temporal Graph Modeling for Audio-Visual Video Parsing</title>
      <link>http://arxiv.org/abs/2505.02096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICMR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TeMTG的多模态优化框架，用于解析视频中的事件类别和发生时间。&lt;h4&gt;背景&lt;/h4&gt;现有的音频-视觉视频解析方法通常通过弱标签隐式建模音频和视觉特征，而没有挖掘不同模态之间的语义关系以及显式建模事件的时间依赖性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出TeMTG框架以更准确地解析在弱监督下每个段落的 eventos 信息。&lt;h4&gt;方法&lt;/h4&gt;TeMTG框架结合了文本增强和多跳时间图建模。具体来说，利用预训练的多模态模型生成特定模态的文本嵌入，并将其与音频-视觉特征融合以增强这些特征的语义表示。此外，引入了多跳时间图神经网络，它显式地建模了段落之间的局部时间关系，捕捉了短期和长期事件的时间连续性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在LLP数据集的多个关键指标上，该方法达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;TeMTG框架在音频-视觉视频解析任务中取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-Visual Video Parsing (AVVP) task aims to parse the event categories andoccurrence times from audio and visual modalities in a given video. Existingmethods usually focus on implicitly modeling audio and visual features throughweak labels, without mining semantic relationships for different modalities andexplicit modeling of event temporal dependencies. This makes it difficult forthe model to accurately parse event information for each segment under weaksupervision, especially when high similarity between segmental modal featuresleads to ambiguous event boundaries. Hence, we propose a multimodaloptimization framework, TeMTG, that combines text enhancement and multi-hoptemporal graph modeling. Specifically, we leverage pre-trained multimodalmodels to generate modality-specific text embeddings, and fuse them withaudio-visual features to enhance the semantic representation of these features.In addition, we introduce a multi-hop temporal graph neural network, whichexplicitly models the local temporal relationships between segments, capturingthe temporal continuity of both short-term and long-range events. Experimentalresults demonstrate that our proposed method achieves state-of-the-art (SOTA)performance in multiple key indicators in the LLP dataset.</description>
      <author>example@mail.com (Yaru Chen, Peiliang Zhang, Fei Li, Faegheh Sardari, Ruohao Guo, Zhenbo Li, Wenwu Wang)</author>
      <guid isPermaLink="false">2505.02096v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing LLM Code Generation: A Systematic Evaluation of Multi-Agent Collaboration and Runtime Debugging for Improved Accuracy, Reliability, and Latency</title>
      <link>http://arxiv.org/abs/2505.02133v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大型语言模型（LLMs）在自动代码生成中的应用，探讨了提升代码生成功能、可靠性和实用性的方法。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在代码生成领域的应用已成为人工智能研究的重要焦点，随着模型的发展，其在理解和生成复杂代码结构方面的能力为自动化编程任务提供了新的可能性。&lt;h4&gt;目的&lt;/h4&gt;旨在通过结合多代理协作和基于运行时执行信息调试两种方法，提升代码生成的功能、可靠性和实用性。&lt;h4&gt;方法&lt;/h4&gt;进行实证研究，评估了单独策略以及两种策略组合的效果，使用了19个LLM来检验策略的性能，并分析了不同编程活动组合和训练范式对代码生成有效性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;实现了结合两种策略的链式系统，使用两个常用的代码生成基准数据集评估了功能准确性、代码可靠性和生成延迟。&lt;h4&gt;结论&lt;/h4&gt;研究结果为寻求稳健的AI驱动编码解决方案的组织提供了有价值的见解，指导他们选择能够更好地适应复杂后训练策略的模型，从而促进更有效和可靠的代码生成技术的采用。&lt;h4&gt;翻译&lt;/h4&gt;The use of large language models (LLMs) for automated code generation has emerged as a significant focus within AI research. As these pretrained models continue to evolve, their ability to understand and generate complex code structures has opened new possibilities for automating intricate programming tasks for the sake of accurate code generation. Although contemporary foundational models demonstrate promoting results, researchers continue to explore optimal post-training strategies to enhance code quality. These include supervised fine-tuning, retrieval-augmented generation (RAG), debugging, and many others. In this paper, we combine two widely used approaches namely multi-agent collaboration and runtime execution information-based debugging, for improving code generation functionality, reliability, and practical applicability. We perform an empirical study in order to extend the evaluation of the individual strategies as well as the proposed composition of the activities of both strategies. Our study uses 19 LLMs to examine the performance of individual and the proposed strategies, offering comprehensive insights into how different programming activities compositions and training paradigms influence code generation effectiveness. In particular, we implement a chained system that combines both strategies to assess their combined impact on functional accuracy, code reliability, and generation latency using two benchmark datasets commonly used for code generation. Our findings provide valuable insights for organizations seeking robust AI-driven coding solutions by guiding them in selecting models that can better adapt to complex post-training strategies, ultimately fostering the adoption of more effective and reliable code generation technologies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The use of large language models (LLMs) for automated code generation hasemerged as a significant focus within AI research. As these pretrained modelscontinue to evolve, their ability to understand and generate complex codestructures has opened new possibilities for automating intricate programmingtasks for the sake of accurate code generation. Although contemporaryfoundational models demonstrate promoting results, researchers continue toexplore optimal post-training strategies to enhance code quality. These includesupervised fine-tuning, retrieval-augmented generation (RAG), debugging, andmany others. In this paper, we combine two widely used approaches namelymulti-agent collaboration and runtime execution information-based debugging,for improving code generation functionality, reliability, and practicalapplicability. We perform an empirical study in order to extend the evaluationof the individual strategies as well as the proposed composition of theactivities of both strategies. Our study use 19 LLMs to examines theperformance of individual and the proposed strategies, offering comprehensiveinsights into how different programming activities compositions and trainingparadigms influence code generation effectiveness. In particular, we implementa chained system that combines both strategies to assess their combined impacton functional accuracy, code reliability, and generation latency using twobenchmark datasets commonly used for code generation. Our findings providevaluable insights for organizations seeking robust AI-driven coding solutionsby guiding them in selecting models that can better adapt to complexpost-training strategies, ultimately fostering the adoption of more effectiveand reliable code generation technologies.</description>
      <author>example@mail.com (Nazmus Ashrafi, Salah Bouktif, Mohammed Mediani)</author>
      <guid isPermaLink="false">2505.02133v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal and Multiview Deep Fusion for Autonomous Marine Navigation</title>
      <link>http://arxiv.org/abs/2505.01615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于跨注意力机制的Transformer方法，用于多模态传感器融合，以构建船舶周围环境的鸟瞰图，支持更安全的自主航行。&lt;h4&gt;背景&lt;/h4&gt;为了提高航行准确性和鲁棒性，需要详细可靠的场景表示。&lt;h4&gt;目的&lt;/h4&gt;通过深度融合多视角RGB图像、长波红外图像和稀疏LiDAR点云，以及X波段雷达和电子海图数据，提高导航准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;使用跨注意力Transformer模型进行多模态传感器融合，结合多种数据源进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;模型能够提供详细的可靠场景表示，即使在恶劣天气和复杂的航海环境中也能有效工作。&lt;h4&gt;结论&lt;/h4&gt;该方法在真实世界的海试中得到了验证，证明了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种基于跨注意力机制的Transformer方法，用于多模态传感器融合，以构建船舶周围环境的鸟瞰图，支持更安全的自主航行。该模型深度融合多视角RGB图像和长波红外图像与稀疏LiDAR点云。训练还整合了X波段雷达和电子海图数据以提供预测信息。所得到的视图提供了一个详细的可靠场景表示，提高了导航的准确性和鲁棒性。现实世界的海试证实了该方法的有效性，即使在恶劣天气和复杂的航海环境中也是如此。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a cross attention transformer based method for multimodal sensorfusion to build a birds eye view of a vessels surroundings supporting saferautonomous marine navigation. The model deeply fuses multiview RGB and longwave infrared images with sparse LiDAR point clouds. Training also integrates Xband radar and electronic chart data to inform predictions. The resulting viewprovides a detailed reliable scene representation improving navigationalaccuracy and robustness. Real world sea trials confirm the methodseffectiveness even in adverse weather and complex maritime settings.</description>
      <author>example@mail.com (Dimitrios Dagdilelis, Panagiotis Grigoriadis, Roberto Galeazzi)</author>
      <guid isPermaLink="false">2505.01615v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Lightweight Defense Against Adversarial Attacks in Time Series Classification</title>
      <link>http://arxiv.org/abs/2505.02073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures. Accepted at RAFDA Workshop, PAKDD 2025  (Springer, EI &amp; Scopus indexed). Code:  https://github.com/Yi126/Lightweight-Defence&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对时间序列分类（TSC）领域，提出了五种基于数据增强的时间序列对抗防御方法，以降低计算成本，并提升了模型的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;随着时间序列分类在计算机视觉领域的兴起，保证TSC模型对抗攻击的鲁棒性变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发高效、计算成本低的对抗防御方法，以提高TSC模型的鲁棒性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出五种基于数据增强的防御方法，其中最计算密集的方法相比原始TSC模型仅增加14.07%的计算资源。创建了两种结合方法：一种是所有提出技术的集成，另一种是集成方法与PGD-based AT方法的对比。&lt;h4&gt;主要发现&lt;/h4&gt;提出的集成方法不仅提供了比基于PGD的AT方法更好的防御性能，而且增强了TSC模型的泛化能力，且所需的计算资源仅为PGD-based AT的三分之一以下。&lt;h4&gt;结论&lt;/h4&gt;这些方法推进了数据挖掘中鲁棒TSC的发展，并为将数据增强对抗防御与大规模预训练模型结合的未来研究提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;As time series classification (TSC) gains prominence, ensuring robust TSC models against adversarial attacks is crucial. While adversarial defense is well-studied in Computer Vision (CV), the TSC field has primarily relied on adversarial training (AT), which is computationally expensive. In this paper, five data augmentation-based defense methods tailored for time series are developed, with the most computationally intensive method among them increasing the computational resources by only 14.07% compared to the original TSC model. Moreover, the deployment process for these methods is straightforward. By leveraging these advantages of our methods, we create two combined methods. One of these methods is an ensemble of all the proposed techniques, which not only provides better defense performance than PGD-based AT but also enhances the generalization ability of TSC models. Moreover, the computational resources required for our ensemble are less than one-third of those required for PGD-based AT. These methods advance robust TSC in data mining. Furthermore, as foundation models are increasingly explored for time series feature learning, our work provides insights into integrating data augmentation-based adversarial defense with large-scale pre-trained models in future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As time series classification (TSC) gains prominence, ensuring robust TSCmodels against adversarial attacks is crucial. While adversarial defense iswell-studied in Computer Vision (CV), the TSC field has primarily relied onadversarial training (AT), which is computationally expensive. In this paper,five data augmentation-based defense methods tailored for time series aredeveloped, with the most computationally intensive method among them increasingthe computational resources by only 14.07% compared to the original TSC model.Moreover, the deployment process for these methods is straightforward. Byleveraging these advantages of our methods, we create two combined methods. Oneof these methods is an ensemble of all the proposed techniques, which not onlyprovides better defense performance than PGD-based AT but also enhances thegeneralization ability of TSC models. Moreover, the computational resourcesrequired for our ensemble are less than one-third of those required forPGD-based AT. These methods advance robust TSC in data mining. Furthermore, asfoundation models are increasingly explored for time series feature learning,our work provides insights into integrating data augmentation-based adversarialdefense with large-scale pre-trained models in future research.</description>
      <author>example@mail.com (Yi Han)</author>
      <guid isPermaLink="false">2505.02073v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>From Players to Champions: A Generalizable Machine Learning Approach for Match Outcome Prediction with Insights from the FIFA World Cup</title>
      <link>http://arxiv.org/abs/2505.01902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种机器学习框架，用于预测FIFA世界杯比赛的胜者。该框架结合了球队历史数据和球员个人表现指标，并使用分类技术以及降维和超参数优化，以创建鲁棒的预测模型。&lt;h4&gt;背景&lt;/h4&gt;准确预测FIFA世界杯比赛结果对分析师、教练、赌徒和球迷都有重要价值。&lt;h4&gt;目的&lt;/h4&gt;开发一种机器学习框架，用于预测FIFA世界杯比赛的胜者。&lt;h4&gt;方法&lt;/h4&gt;通过整合球队历史数据和球员个人表现指标，创建年度球队档案，采用分类技术、降维和超参数优化来提高预测准确性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在FIFA 2022世界杯数据上的预测准确性优于基线方法，强调了结合个人球员属性和球队构成的重要性。&lt;h4&gt;结论&lt;/h4&gt;本文强调了丰富、以球员为中心的数据在体育分析中的变革潜力，并为未来探索高级学习架构如图神经网络来模拟复杂团队互动奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of FIFA World Cup match outcomes holds significant valuefor analysts, coaches, bettors, and fans. This paper presents a machinelearning framework specifically designed to forecast match winners in FIFAWorld Cup. By integrating both team-level historical data and player-specificperformance metrics such as goals, assists, passing accuracy, and tackles, wecapture nuanced interactions often overlooked by traditional aggregate models.Our methodology processes multi-year data to create year-specific team profilesthat account for evolving rosters and player development. We employclassification techniques complemented by dimensionality reduction andhyperparameter optimization, to yield robust predictive models. Experimentalresults on data from the FIFA 2022 World Cup demonstrate our approach'ssuperior accuracy compared to baseline method. Our findings highlight theimportance of incorporating individual player attributes and team-levelcomposition to enhance predictive performance, offering new insights intoplayer synergy, strategic match-ups, and tournament progression scenarios. Thiswork underscores the transformative potential of rich, player-centric data insports analytics, setting a foundation for future exploration of advancedlearning architectures such as graph neural networks to model complex teaminteractions.</description>
      <author>example@mail.com (Ali Al-Bustami, Zaid Ghazal)</author>
      <guid isPermaLink="false">2505.01902v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Lifelong Whole Slide Image Analysis: Online Vision-Language Adaptation and Past-to-Present Gradient Distillation</title>
      <link>http://arxiv.org/abs/2505.01984v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ADaFGrad的方法，用于增强全切片图像（WSI）分析中的终身学习能力，以提高癌症诊断的准确性。&lt;h4&gt;背景&lt;/h4&gt;全切片图像在癌症诊断和预后中起着关键作用，但由于其巨大的数据量，存储、处理和模型训练都面临挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种终身学习的方法，以利用分布在多个机构的切片来开发一个统一的在线模型，作为临床和医院环境中癌症诊断的计算工具。&lt;h4&gt;方法&lt;/h4&gt;ADaFGrad方法利用病理视觉语言基础模型，开发了一个框架，允许切片的区域组织特征与预定义的基于文本的原型缓冲区进行交互。此外，还提出了一种梯度蒸馏机制，模拟了在持续学习环境中，过去和当前迭代中logit相对于分类头参数的梯度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ADaFGrad在仅经过几个训练周期后，在类增量学习场景中比最先进的WSI特定方法和传统持续学习方法表现更好，提高了5.068%。此外，ADaFGrad的准确率比基线提高了40.084%，显示出所提出模块的有效性。&lt;h4&gt;结论&lt;/h4&gt;ADaFGrad方法在癌症诊断中的终身学习能力方面具有显著优势，能够提高诊断的准确性并减少知识遗忘。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Whole Slide Images (WSIs) play a crucial role in accurate cancer diagnosisand prognosis, as they provide tissue details at the cellular level. However,the rapid growth of computational tasks involving WSIs poses significantchallenges. Given that WSIs are gigapixels in size, they present difficultiesin terms of storage, processing, and model training. Therefore, it is essentialto develop lifelong learning approaches for WSI analysis. In scenarios whereslides are distributed across multiple institutes, we aim to leverage them todevelop a unified online model as a computational tool for cancer diagnosis inclinical and hospital settings. In this study, we introduce ADaFGrad, a methoddesigned to enhance lifelong learning for whole-slide image (WSI) analysis.First, we leverage pathology vision-language foundation models to develop aframework that enables interaction between a slide's regional tissue featuresand a predefined text-based prototype buffer. Additionally, we propose agradient-distillation mechanism that mimics the gradient of a logit withrespect to the classification-head parameters across past and currentiterations in a continual-learning setting. We construct a sequence of six TCGAdatasets for training and evaluation. Experimental results show that ADaFGradoutperforms both state-of-the-art WSI-specific and conventionalcontinual-learning methods after only a few training epochs, exceeding them byup to +5.068% in the class-incremental learning scenario while exhibiting theleast forgetting (i.e., retaining the most knowledge from previous tasks).Moreover, ADaFGrad surpasses its baseline by as much as +40.084% in accuracy,further demonstrating the effectiveness of the proposed modules.</description>
      <author>example@mail.com (Doanh C. Bui, Hoai Luan Pham, Vu Trung Duong Le, Tuan Hai Vu, Van Duy Tran, Khang Nguyen, Yasuhiko Nakashima)</author>
      <guid isPermaLink="false">2505.01984v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models</title>
      <link>http://arxiv.org/abs/2505.01912v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了在分子发现领域，基于深度学习和生成模型的数据驱动发现流程的发展。研究了机器学习模型在过滤和设计新型分子时的应用，同时评估了模型在分子性质预测中的泛化能力，并提出一个新的开源基准研究BOOM（Benchmark for Out-of-Distribution Molecular Property Predictions）。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习和生成模型的发展，数据驱动分子发现管道受到广泛关注，这类管道利用机器学习模型过滤和设计新型分子，而无需进行昂贵的第一性原理模拟。然而，发现新的分子需要准确的超出分布（OOD）预测，而ML模型在泛化OOD方面往往存在困难。&lt;h4&gt;目的&lt;/h4&gt;研究并提出一个基准（BOOM）来评估基于属性的超出分布分子性质预测模型，通过评估多个模型和性质预测任务组合的泛化能力，为深度学习模型在OOD性能上提供基准。&lt;h4&gt;方法&lt;/h4&gt;研究人员评估了超过140种模型和性质预测任务组合，以在多个任务上基准测试深度学习模型的OOD性能，并通过消融实验研究了数据生成、预训练、超参数优化、模型架构和分子表示对OOD性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现没有现存的模型在所有任务上都能实现强的OOD泛化；即使表现最好的模型，其平均OOD误差也比分布内的误差大3倍。此外，具有高归纳偏置的深度学习模型在具有简单、特定性质的OOD任务上表现良好。化学基础模型虽然在有限的训练数据场景中提供了有希望的解决方案，但目前的模型并未展现出强大的OOD外推能力。&lt;h4&gt;结论&lt;/h4&gt;提出发展具有强大OOD泛化的机器学习模型是化学机器学习模型开发的新前沿挑战，并且开源的BOOM基准研究将被发布在Github上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in deep learning and generative modeling have driven interest indata-driven molecule discovery pipelines, whereby machine learning (ML) modelsare used to filter and design novel molecules without requiring prohibitivelyexpensive first-principles simulations. Although the discovery of novelmolecules that extend the boundaries of known chemistry requires accurateout-of-distribution (OOD) predictions, ML models often struggle to generalizeOOD. Furthermore, there are currently no systematic benchmarks for molecularOOD prediction tasks. We present BOOM, $\boldsymbol{b}$enchmarks for$\boldsymbol{o}$ut-$\boldsymbol{o}$f-distribution $\boldsymbol{m}$olecularproperty predictions -- a benchmark study of property-based out-of-distributionmodels for common molecular property prediction models. We evaluate more than140 combinations of models and property prediction tasks to benchmark deeplearning models on their OOD performance. Overall, we do not find any existingmodels that achieve strong OOD generalization across all tasks: even the topperforming model exhibited an average OOD error 3x larger than in-distribution.We find that deep learning models with high inductive bias can perform well onOOD tasks with simple, specific properties. Although chemical foundation modelswith transfer and in-context learning offer a promising solution for limitedtraining data scenarios, we find that current foundation models do not showstrong OOD extrapolation capabilities. We perform extensive ablationexperiments to highlight how OOD performance is impacted by data generation,pre-training, hyperparameter optimization, model architecture, and molecularrepresentation. We propose that developing ML models with strong OODgeneralization is a new frontier challenge in chemical ML model development.This open-source benchmark will be made available on Github.</description>
      <author>example@mail.com (Evan R. Antoniuk, Shehtab Zaman, Tal Ben-Nun, Peggy Li, James Diffenderfer, Busra Demirci, Obadiah Smolenski, Tim Hsu, Anna M. Hiszpanski, Kenneth Chiu, Bhavya Kailkhura, Brian Van Essen)</author>
      <guid isPermaLink="false">2505.01912v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>ReLI: A Language-Agnostic Approach to Human-Robot Interaction</title>
      <link>http://arxiv.org/abs/2505.01862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ReLI的语言无关框架，旨在使自主代理能够在不同语言中自然交流、语义推理并执行任务，解决了跨语言应用中与环境的交互和执行人类指令的问题。&lt;h4&gt;背景&lt;/h4&gt;在工业、家庭和其他日常任务中，自适应自主代理的应用正在增加，但在全球或跨语言的应用环境中，确保自主代理能够有效与环境互动并执行多样化语言的指令仍然是一个未解决的问题。&lt;h4&gt;目的&lt;/h4&gt;提出ReLI框架，以实现自主代理在不同语言环境中自然交流、语义推理并执行任务，不受指令语言起源的限制。&lt;h4&gt;方法&lt;/h4&gt;ReLI框架首先将大规模预训练的基础模型转化为语言到行动模型，这些模型可以通过自然的人类-机器人对话直接提供常识推理和高级机器人控制。此外，还进行了跨语言的模型固化，以确保ReLI能够跨全球语言泛化。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的模拟和真实世界实验，包括零样本和少样本的时空导航、场景信息检索和查询导向任务，ReLI在140种语言的超过70K次多轮对话中进行了性能评估。平均而言，ReLI在跨语言指令解析和任务执行成功率方面达到了90%±0.2的准确率。&lt;h4&gt;结论&lt;/h4&gt;ReLI有望增强现实世界中的人机自然交互，同时支持语言多样性。演示和资源将在https://linusnep.github.io/ReLI/上公开提供。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：Adapting autonomous agents to industrial, domestic, and other daily tasks is currently gaining momentum. However, in the global or cross-lingual application contexts, ensuring effective interaction with the environment and executing unrestricted human task-specified instructions in diverse languages remains an unsolved problem. To address this challenge, we propose ReLI, a language-agnostic framework designed to enable autonomous agents to conversenaturally, semantically reason about the environment, and to perform downstream tasks, regardless of the task instruction's linguistic origin. First, we ground large-scale pre-trained foundation models and transform them into language-to-action models that can directly provide common-sense reasoning and high-level robot control through natural, free-flow human-robot conversational interactions. Further, we perform cross-lingual grounding of the models to ensure that ReLI generalises across the global languages. To demonstrate the ReLI's robustness, we conducted extensive simulated and real-world experiments on various short- and long-horizon tasks, including zero-shot and few-shot spatial navigation, scene information retrieval, and query-oriented tasks. We benchmarked the performance on 140 languages involving over 70K multi-turn conversations. On average, ReLI achieved over 90%±0.2 accuracy in cross-lingual instruction parsing and task execution success rates. These results demonstrate the ReLI's potential to enhance natural human-robot interaction in the real world while championing linguistic diversity. Demonstrations and resources will be publicly available at https://linusnep.github.io/ReLI/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adapting autonomous agents to industrial, domestic, and other daily tasks iscurrently gaining momentum. However, in the global or cross-lingual applicationcontexts, ensuring effective interaction with the environment and executingunrestricted human task-specified instructions in diverse languages remains anunsolved problem. To address this challenge, we propose ReLI, alanguage-agnostic framework designed to enable autonomous agents to conversenaturally, semantically reason about the environment, and to perform downstreamtasks, regardless of the task instruction's linguistic origin. First, we groundlarge-scale pre-trained foundation models and transform them intolanguage-to-action models that can directly provide common-sense reasoning andhigh-level robot control through natural, free-flow human-robot conversationalinteractions. Further, we perform cross-lingual grounding of the models toensure that ReLI generalises across the global languages. To demonstrate theReLI's robustness, we conducted extensive simulated and real-world experimentson various short- and long-horizon tasks, including zero-shot and few-shotspatial navigation, scene information retrieval, and query-oriented tasks. Webenchmarked the performance on 140 languages involving over 70K multi-turnconversations. On average, ReLI achieved over 90%$\pm$0.2 accuracy incross-lingual instruction parsing and task execution success rates. Theseresults demonstrate the ReLI's potential to enhance natural human-robotinteraction in the real world while championing linguistic diversity.Demonstrations and resources will be publicly available athttps://linusnep.github.io/ReLI/.</description>
      <author>example@mail.com (Linus Nwankwo, Bjoern Ellensohn, Ozan Özdenizci, Elmar Rueckert)</author>
      <guid isPermaLink="false">2505.01862v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating Volumetric Medical Image Annotation via Short-Long Memory SAM 2</title>
      <link>http://arxiv.org/abs/2505.01854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Short-Long Memory SAM 2（SLM-SAM 2）的新型架构，用于提高医学图像分割的自动化标注准确性。&lt;h4&gt;背景&lt;/h4&gt;医学图像（如MRI和CT）的手动标注是劳动密集型且耗时的过程，而视频对象分割的基础模型（如SAM 2）有望加快标注速度。&lt;h4&gt;目的&lt;/h4&gt;为了解决SAM 2在边界区域易出错的问题，提出SLM-SAM 2以提升分割精度。&lt;h4&gt;方法&lt;/h4&gt;SLM-SAM 2结合了短时和长时记忆银行以及独立的注意力模块，并在三个公开数据集上进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;SLM-SAM 2在5个体积和1个体积可用的情况下，与默认SAM 2相比，分别实现了Dice相似系数平均提升0.14和0.11。SLM-SAM 2对过度传播具有更强的抵抗力。&lt;h4&gt;结论&lt;/h4&gt;SLM-SAM 2在医学图像分割的自动化标注方面取得了显著进展，有助于分割模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Manual annotation of volumetric medical images, such as magnetic resonanceimaging (MRI) and computed tomography (CT), is a labor-intensive andtime-consuming process. Recent advancements in foundation models for videoobject segmentation, such as Segment Anything Model 2 (SAM 2), offer apotential opportunity to significantly speed up the annotation process bymanually annotating one or a few slices and then propagating target masksacross the entire volume. However, the performance of SAM 2 in this contextvaries. Our experiments show that relying on a single memory bank and attentionmodule is prone to error propagation, particularly at boundary regions wherethe target is present in the previous slice but absent in the current one. Toaddress this problem, we propose Short-Long Memory SAM 2 (SLM-SAM 2), a novelarchitecture that integrates distinct short-term and long-term memory bankswith separate attention modules to improve segmentation accuracy. We evaluateSLM-SAM 2 on three public datasets covering organs, bones, and muscles acrossMRI and CT modalities. We show that the proposed method markedly outperformsthe default SAM 2, achieving average Dice Similarity Coefficient improvement of0.14 and 0.11 in the scenarios when 5 volumes and 1 volume are available forthe initial adaptation, respectively. SLM-SAM 2 also exhibits strongerresistance to over-propagation, making a notable step toward more accurateautomated annotation of medical images for segmentation model development.</description>
      <author>example@mail.com (Yuwen Chen, Zafer Yildiz, Qihang Li, Yaqian Chen, Haoyu Dong, Hanxue Gu, Nicholas Konz, Maciej A. Mazurowski)</author>
      <guid isPermaLink="false">2505.01854v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge-Augmented Language Models Interpreting Structured Chest X-Ray Findings</title>
      <link>http://arxiv.org/abs/2505.01711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CXR-TextInter的新框架，用于通过利用大型语言模型（LLMs）来提高胸部X光片（CXR）的自动解释能力，同时结合医学知识模块增强临床推理。&lt;h4&gt;背景&lt;/h4&gt;自动解释胸部X光片是提高临床工作流程和患者护理的关键任务。尽管多模态基础模型有潜力，但有效利用大型语言模型（LLMs）进行视觉任务仍是一个未充分探索的领域。&lt;h4&gt;目的&lt;/h4&gt;开发CXR-TextInter框架，通过结构化文本表示和医学知识模块，实现CXR的准确解释。&lt;h4&gt;方法&lt;/h4&gt;开发了一个名为MediInstruct-CXR的数据集，其中包含结构化图像表示和多样化的临床指令-响应示例，以及CXR-ClinEval基准，用于综合评估各种解释任务。通过在CXR-ClinEval上进行大量实验，评估CXR-TextInter的性能。&lt;h4&gt;主要发现&lt;/h4&gt;CXR-TextInter在病理检测、报告生成和视觉问答等任务上达到了最先进的性能，超过了现有的多模态基础模型。消融实验证实了知识集成模块的关键作用。盲法评估表明，认证放射科医生对CXR-TextInter生成的输出质量有显著偏好。&lt;h4&gt;结论&lt;/h4&gt;本文验证了医学图像AI的替代范式，展示了当视觉信息得到有效结构化且领域知识得到整合时，利用高级LLM能力的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Automated interpretation of chest X-rays (CXR) is a critical task with the potential to significantly improve clinical workflow and patient care. While recent advances in multimodal foundation models have shown promise, effectively leveraging the full power of large language models (LLMs) for this visual task remains an underexplored area. This paper introduces CXR-TextInter, a novel framework that repurposes powerful text-centric LLMs for CXR interpretation by operating solely on a rich, structured textual representation of the image content, generated by an upstream image analysis pipeline. We augment this LLM-centric approach with an integrated medical knowledge module to enhance clinical reasoning. To facilitate training and evaluation, we developed the MediInstruct-CXR dataset, containing structured image representations paired with diverse, clinically relevant instruction-response examples, and the CXR-ClinEval benchmark for comprehensive assessment across various interpretation tasks. Extensive experiments on CXR-ClinEval demonstrate that CXR-TextInter achieves state-of-the-art quantitative performance across pathology detection, report generation, and visual question answering, surpassing existing multimodal foundation models. Ablation studies confirm the critical contribution of the knowledge integration module. Furthermore, blinded human evaluation by board-certified radiologists shows a significant preference for the clinical quality of outputs generated by CXR-TextInter. Our work validates an alternative paradigm for medical image AI, showcasing the potential of harnessing advanced LLM capabilities when visual information is effectively structured and domain knowledge is integrated.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated interpretation of chest X-rays (CXR) is a critical task with thepotential to significantly improve clinical workflow and patient care. Whilerecent advances in multimodal foundation models have shown promise, effectivelyleveraging the full power of large language models (LLMs) for this visual taskremains an underexplored area. This paper introduces CXR-TextInter, a novelframework that repurposes powerful text-centric LLMs for CXR interpretation byoperating solely on a rich, structured textual representation of the imagecontent, generated by an upstream image analysis pipeline. We augment thisLLM-centric approach with an integrated medical knowledge module to enhanceclinical reasoning. To facilitate training and evaluation, we developed theMediInstruct-CXR dataset, containing structured image representations pairedwith diverse, clinically relevant instruction-response examples, and theCXR-ClinEval benchmark for comprehensive assessment across variousinterpretation tasks. Extensive experiments on CXR-ClinEval demonstrate thatCXR-TextInter achieves state-of-the-art quantitative performance acrosspathology detection, report generation, and visual question answering,surpassing existing multimodal foundation models. Ablation studies confirm thecritical contribution of the knowledge integration module. Furthermore, blindedhuman evaluation by board-certified radiologists shows a significant preferencefor the clinical quality of outputs generated by CXR-TextInter. Our workvalidates an alternative paradigm for medical image AI, showcasing thepotential of harnessing advanced LLM capabilities when visual information iseffectively structured and domain knowledge is integrated.</description>
      <author>example@mail.com (Alexander Davis, Rafael Souza, Jia-Hao Lim)</author>
      <guid isPermaLink="false">2505.01711v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Focal-SAM: Focal Sharpness-Aware Minimization for Long-Tailed Classification</title>
      <link>http://arxiv.org/abs/2505.01660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Focal-SAM的新方法，用于解决现实世界数据集中长尾分布导致的泛化困难问题。&lt;h4&gt;背景&lt;/h4&gt;现实世界数据集通常遵循长尾分布，使得对尾部类别的泛化变得困难。&lt;h4&gt;目的&lt;/h4&gt;提高模型对尾部类别的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;Focal-SAM通过为类间锐度分配不同的惩罚，在不进行额外反向传播的情况下实现细粒度控制，从而保持效率。&lt;h4&gt;主要发现&lt;/h4&gt;Focal-SAM在提高泛化能力的同时，避免了ImbSAM和CC-SAM在计算效率和损失景观控制之间的权衡。&lt;h4&gt;结论&lt;/h4&gt;Focal-SAM在传统和基础模型上的广泛实验验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Real-world datasets often follow a long-tailed distribution, making generalization to tail classes difficult. Recent methods resorted to long-tail variants of Sharpness-Aware Minimization (SAM), such as ImbSAM and CC-SAM, to improve generalization by flattening the loss landscape. However, these attempts face a trade-off between computational efficiency and control over the loss landscape. On the one hand, ImbSAM is efficient but offers only coarse control as it excludes head classes from the SAM process. On the other hand, CC-SAM provides fine-grained control through class-dependent perturbations but at the cost of efficiency due to multiple backpropagations. Seeing this dilemma, we introduce Focal-SAM, which assigns different penalties to class-wise sharpness, achieving fine-grained control without extra backpropagations, thus maintaining efficiency. Furthermore, we theoretically analyze Focal-SAM's generalization ability and derive a sharper generalization bound. Extensive experiments on both traditional and foundation models validate the effectiveness of Focal-SAM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world datasets often follow a long-tailed distribution, makinggeneralization to tail classes difficult. Recent methods resorted to long-tailvariants of Sharpness-Aware Minimization (SAM), such as ImbSAM and CC-SAM, toimprove generalization by flattening the loss landscape. However, theseattempts face a trade-off between computational efficiency and control over theloss landscape. On the one hand, ImbSAM is efficient but offers only coarsecontrol as it excludes head classes from the SAM process. On the other hand,CC-SAM provides fine-grained control through class-dependent perturbations butat the cost of efficiency due to multiple backpropagations. Seeing thisdilemma, we introduce Focal-SAM, which assigns different penalties toclass-wise sharpness, achieving fine-grained control without extrabackpropagations, thus maintaining efficiency. Furthermore, we theoreticallyanalyze Focal-SAM's generalization ability and derive a sharper generalizationbound. Extensive experiments on both traditional and foundation models validatethe effectiveness of Focal-SAM.</description>
      <author>example@mail.com (Sicong Li, Qianqian Xu, Zhiyong Yang, Zitai Wang, Linchao Zhang, Xiaochun Cao, Qingming Huang)</author>
      <guid isPermaLink="false">2505.01660v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Human-AI Governance (HAIG): A Trust-Utility Approach</title>
      <link>http://arxiv.org/abs/2505.01651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages including references and appendix, 25 pages core text, 3  figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HAIG框架，用于分析人类-人工智能关系中的信任动态。&lt;h4&gt;背景&lt;/h4&gt;现有的分类框架（如“人机交互”模型）不足以捕捉人工智能系统如何从工具发展到伙伴，尤其是在基础模型展现出涌现能力，多智能体系统表现出自主目标设定行为时。&lt;h4&gt;目的&lt;/h4&gt;HAIG框架旨在更好地描述系统发展过程中代理权的复杂分配模式，以及信任关系的维护。&lt;h4&gt;方法&lt;/h4&gt;HAIG框架在三个层面运作：维度（决策权分配、过程自主性和问责配置）、连续体（每个维度的渐进变化）和阈值（需要治理适应的关键点）。&lt;h4&gt;主要发现&lt;/h4&gt;HAIG框架采用信任-效用导向，关注维持适当的信任关系，以最大化效用并确保足够的保障措施。分析揭示了自我监督、推理权限和分布式决策在非均匀信任演化中的作用，这些演化是在情境变化和技术进步的驱动下发生的。&lt;h4&gt;结论&lt;/h4&gt;案例研究在医疗保健和欧洲法规中展示了HAIG框架如何补充现有框架，并为预测治理挑战的替代方法提供基础。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为HAIG的框架，用于分析人类与人工智能之间信任动态的发展。现有的分类框架，如“人机交互”模型，无法充分捕捉人工智能系统从工具发展到伙伴的过程，尤其是在基础模型展现出涌现能力，多智能体系统表现出自主目标设定行为时。HAIG框架在三个层面运作：维度（决策权分配、过程自主性和问责配置）、连续体（每个维度的渐进变化）和阈值（需要治理适应的关键点）。该框架采用信任-效用导向，关注维持适当的信任关系，以最大化效用并确保足够的保障措施。研究发现，自我监督、推理权限和分布式决策在非均匀信任演化中发挥了作用，这些演化是在情境变化和技术进步的驱动下发生的。在医疗保健和欧洲法规的案例研究中，HAIG框架展示了其如何补充现有框架，并为预测治理挑战的替代方法提供基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces the HAIG framework for analysing trust dynamics acrossevolving human-AI relationships. Current categorical frameworks (e.g.,"human-in-the-loop" models) inadequately capture how AI systems evolve fromtools to partners, particularly as foundation models demonstrate emergentcapabilities and multi-agent systems exhibit autonomous goal-settingbehaviours. As systems advance, agency redistributes in complex patterns thatare better represented as positions along continua rather than discretecategories, though progression may include both gradual shifts and significantstep changes. The HAIG framework operates across three levels: dimensions(Decision Authority Distribution, Process Autonomy, and AccountabilityConfiguration), continua (gradual shifts along each dimension), and thresholds(critical points requiring governance adaptation). Unlike risk-based orprinciple-based approaches, HAIG adopts a trust-utility orientation, focusingon maintaining appropriate trust relationships that maximise utility whileensuring sufficient safeguards. Our analysis reveals how technical advances inself-supervision, reasoning authority, and distributed decision-making drivenon-uniform trust evolution across both contextual variation and technologicaladvancement. Case studies in healthcare and European regulation demonstrate howHAIG complements existing frameworks while offering a foundation foralternative approaches that anticipate governance challenges before theyemerge.</description>
      <author>example@mail.com (Zeynep Engin)</author>
      <guid isPermaLink="false">2505.01651v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>PainFormer: a Vision Foundation Model for Automatic Pain Assessment</title>
      <link>http://arxiv.org/abs/2505.01571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为PainFormer的自动疼痛评估系统，通过多任务学习在14个任务/数据集上训练，能够有效提取多种输入模态的高质量嵌入，并在疼痛评估方面取得卓越表现。&lt;h4&gt;背景&lt;/h4&gt;疼痛是一个影响大量人群的复杂状况，准确可靠的疼痛评估对于开发有效的疼痛管理方案至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够进行连续监测并支持决策过程的自动疼痛评估系统，以减轻痛苦并预防功能下降。&lt;h4&gt;方法&lt;/h4&gt;PainFormer是一个基于视觉的多任务学习基础模型，同时训练于14个任务/数据集，共计1090万个样本。它作为各种输入模态的嵌入提取器，为基于Transformer的Embedding-Mixer模块提供特征表示，该模块执行最终的疼痛评估。&lt;h4&gt;主要发现&lt;/h4&gt;使用包括RGB、合成热成像和估计深度视频在内的行为模态以及ECG、EMG、GSR和fNIRS在内的生理模态的广泛实验表明，PainFormer能够从不同的输入模态中有效提取高质量嵌入。&lt;h4&gt;结论&lt;/h4&gt;在单模态和多模态设置中进行的实验证明了该框架在各个模态中均达到最先进的性能，为通用自动疼痛评估模型的发展铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;The study proposes an automatic pain assessment system named PainFormer, which is a vision foundation model based on multi-task learning principles trained on 14 tasks/datasets with a total of 10.9 million samples. It acts as an embedding extractor for various input modalities, providing feature representations to the Embedding-Mixer module, which is based on Transformer and performs the final pain assessment. Extensive experiments using behavioral modalities such as RGB, synthetic thermal, and estimated depth videos, as well as physiological modalities such as ECG, EMG, GSR, and fNIRS, show that PainFormer can effectively extract high-quality embeddings from diverse input modalities. The proposed framework is evaluated on two pain datasets, BioVid and AI4Pain, and directly compared to 73 different methodologies documented in the literature. Experiments conducted in unimodal and multimodal settings demonstrate state-of-the-art performances across modalities and pave the way toward general-purpose models for automatic pain assessment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pain is a manifold condition that impacts a significant percentage of thepopulation. Accurate and reliable pain evaluation for the people suffering iscrucial to developing effective and advanced pain management protocols.Automatic pain assessment systems provide continuous monitoring and supportdecision-making processes, ultimately aiming to alleviate distress and preventfunctionality decline. This study introduces PainFormer, a vision foundationmodel based on multi-task learning principles trained simultaneously on 14tasks/datasets with a total of 10.9 million samples. Functioning as anembedding extractor for various input modalities, the foundation model providesfeature representations to the Embedding-Mixer, a transformer-based module thatperforms the final pain assessment. Extensive experiments employing behavioralmodalities-including RGB, synthetic thermal, and estimated depth videos-andphysiological modalities such as ECG, EMG, GSR, and fNIRS revealed thatPainFormer effectively extracts high-quality embeddings from diverse inputmodalities. The proposed framework is evaluated on two pain datasets, BioVidand AI4Pain, and directly compared to 73 different methodologies documented inthe literature. Experiments conducted in unimodal and multimodal settingsdemonstrate state-of-the-art performances across modalities and pave the waytoward general-purpose models for automatic pain assessment.</description>
      <author>example@mail.com (Stefanos Gkikas, Raul Fernandez Rojas, Manolis Tsiknakis)</author>
      <guid isPermaLink="false">2505.01571v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>A Sensor Agnostic Domain Generalization Framework for Leveraging Geospatial Foundation Models: Enhancing Semantic Segmentation viaSynergistic Pseudo-Labeling and Generative Learning</title>
      <link>http://arxiv.org/abs/2505.01558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in the 2025 CVPR Workshop on Foundation and Large Vision  Models in Remote Sensing, to appear in CVPR 2025 Workshop Proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用新兴地理空间基础模型进行领域泛化的方法，通过结合软对齐伪标签和源到目标生成预训练，以提高模型泛化能力。&lt;h4&gt;背景&lt;/h4&gt;遥感技术在土地覆盖和土地利用制图、作物产量预测以及环境监测等方面有广泛应用。尽管卫星技术的发展扩大了遥感数据集，但高性能分割模型仍然依赖于大量标注数据，受到标注稀缺性和传感器、光照和地理差异性的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种领域泛化方法，以改善模型泛化能力。&lt;h4&gt;方法&lt;/h4&gt;结合软对齐伪标签和源到目标生成预训练，利用新兴地理空间基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;新的数学洞察力被应用于基于MAE的生成学习，以实现领域不变特征学习。&lt;h4&gt;结论&lt;/h4&gt;在超光谱和多光谱遥感数据集上的实验证实了该方法在提高适应性和分割效果方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：遥感技术使多种关键应用成为可能，如土地覆盖和土地利用制图、作物产量预测和环境监测。卫星技术的进步扩大了遥感数据集，但高性能分割模型仍然依赖于大量标注数据，面临着标注稀缺性和传感器、光照和地理差异性的挑战。领域自适应提供了一种改善模型泛化能力的有希望的方法。本文介绍了一种利用新兴地理空间基础模型进行领域泛化的方法，通过结合软对齐伪标签与源到目标生成预训练。我们进一步对基于MAE的生成学习进行了新的数学洞察，以实现领域不变特征学习。在超光谱和多光谱遥感数据集上的实验证实了我们的方法在提高适应性和分割效果方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remote sensing enables a wide range of critical applications such as landcover and land use mapping, crop yield prediction, and environmentalmonitoring. Advances in satellite technology have expanded remote sensingdatasets, yet high-performance segmentation models remain dependent onextensive labeled data, challenged by annotation scarcity and variabilityacross sensors, illumination, and geography. Domain adaptation offers apromising solution to improve model generalization. This paper introduces adomain generalization approach to leveraging emerging geospatial foundationmodels by combining soft-alignment pseudo-labeling with source-to-targetgenerative pre-training. We further provide new mathematical insights intoMAE-based generative learning for domain-invariant feature learning.Experiments with hyperspectral and multispectral remote sensing datasetsconfirm our method's effectiveness in enhancing adaptability and segmentation.</description>
      <author>example@mail.com (Anan Yaghmour, Melba M. Crawford, Saurabh Prasad)</author>
      <guid isPermaLink="false">2505.01558v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations for Synthetic Videos</title>
      <link>http://arxiv.org/abs/2505.01481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VideoHallu，一个用于评估合成视频真实性的基准，并探讨了现有模型在常识和物理法则上的幻觉问题。&lt;h4&gt;背景&lt;/h4&gt;合成视频生成技术因其真实性和广泛应用而受到关注，但现有模型在生成内容时往往忽视常识和物理法则，导致异常内容。&lt;h4&gt;目的&lt;/h4&gt;提出VideoHallu基准，用于检测合成视频中的异常内容，并研究如何提高多模态大型语言模型（MLLMs）在合成视频中的推理能力。&lt;h4&gt;方法&lt;/h4&gt;设计包含多种类别和专家设计的问答任务的基准，评估多个MLLMs模型，并通过Group Relative Policy Optimization（GRPO）对模型进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;尽管在MVBench和MovieChat等任务上表现良好，这些模型在合成视频中的常识和物理任务上仍存在幻觉问题。微调后，模型在推理能力上取得了显著提升。&lt;h4&gt;结论&lt;/h4&gt;VideoHallu基准有助于评估合成视频的真实性，微调MLLMs可以提升其在合成视频中的推理能力。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces VideoHallu, a benchmark for evaluating the authenticity of synthetic videos, and explores the hallucination problems of existing models in common sense and physical laws.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Synthetic video generation with foundation models has gained attention forits realism and wide applications. While these models produce high-qualityframes, they often fail to respect common sense and physical laws, resulting inabnormal content. Existing metrics like VideoScore emphasize general qualitybut ignore such violations and lack interpretability. A more insightfulapproach is using multi-modal large language models (MLLMs) as interpretableevaluators, as seen in FactScore. Yet, MLLMs' ability to detect abnormalitiesin synthetic videos remains underexplored. To address this, we introduceVideoHallu, a benchmark featuring synthetic videos from models like Veo2, Sora,and Kling, paired with expert-designed QA tasks solvable via human-levelreasoning across various categories. We assess several SoTA MLLMs, includingGPT-4o, Gemini-2.5-Pro, Qwen-2.5-VL, and newer models like Video-R1 andVideoChat-R1. Despite strong real-world performance on MVBench and MovieChat,these models still hallucinate on basic commonsense and physics tasks insynthetic settings, underscoring the challenge of hallucination. We furtherfine-tune SoTA MLLMs using Group Relative Policy Optimization (GRPO) on realand synthetic commonsense/physics data. Results show notable accuracy gains,especially with counterexample integration, advancing MLLMs' reasoningcapabilities. Our data is available at https://github.com/zli12321/VideoHallu.</description>
      <author>example@mail.com (Zongxia Li, Xiyang Wu, Yubin Qin, Guangyao Shi, Hongyang Du, Dinesh Manocha, Tianyi Zhou, Jordan Lee Boyd-Graber)</author>
      <guid isPermaLink="false">2505.01481v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Global Stress Generation and Spatiotemporal Super-Resolution Physics-Informed Operator under Dynamic Loading for Two-Phase Random Materials</title>
      <link>http://arxiv.org/abs/2505.01438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在动态加载下，两相随机材料（TRMs）中的全局应力演变和时空超分辨率问题。&lt;h4&gt;背景&lt;/h4&gt;材料应力分析对材料和性能优化至关重要。在动态加载下，材料的全局应力演变表现出复杂的时空特性，特别是在两相随机材料中。这种材料的失效通常与应力集中有关，相界面是应力集中的关键位置。&lt;h4&gt;目的&lt;/h4&gt;解决在实际工程应用中，由于微结构数据的时空分辨率有限，深学习方法在生成高分辨率时空应力场方面面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种动态加载下两相随机材料全局应力生成和时空超分辨率的框架。首先，引入了一种基于扩散模型的时空应力扩散（STS-diffusion）方法来生成全局时空应力数据。其次，开发了一种物理信息网络，称为时空超分辨率物理信息算子（ST-SRPINN），用于时空超分辨率。ST-SRPINN是一种无监督学习方法，详细探讨了数据驱动和物理信息损失函数权重对模型准确性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;提出的框架通过物理约束，可以在训练过程中仅需要低分辨率的应力场数据，并将其时空分辨率升级到任意放大倍数。&lt;h4&gt;结论&lt;/h4&gt;该研究为两相随机材料在动态加载下的应力分析和超分辨率提供了新的方法。&lt;h4&gt;翻译&lt;/h4&gt;Material stress analysis is a critical aspect of material design and performance optimization. Under dynamic loading, the global stress evolution in materials exhibits complex spatiotemporal characteristics, especially in two-phase random materials (TRMs). Such kind of material failure is often associated with stress concentration, and the phase boundaries are key locations where stress concentration occurs. In practical engineering applications, the spatiotemporal resolution of acquired microstructural data and its dynamic stress evolution is often limited. This poses challenges for deep learning methods in generating high-resolution spatiotemporal stress fields, particularly for accurately capturing stress concentration regions. In this study, we propose a framework for global stress generation and spatiotemporal super-resolution in TRMs under dynamic loading. First, we introduce a diffusion model-based approach, named as Spatiotemporal Stress Diffusion (STS-diffusion), for generating global spatiotemporal stress data. This framework incorporates Space-Time U-Net (STU-net), and we systematically investigate the impact of different attention positions on model accuracy. Next, we develop a physics-informed network for spatiotemporals super-resolution, termed as Spatiotemporal Super-Resolution Physics-Informed Operator (ST-SRPINN). The proposed ST-SRPINN is an unsupervised learning method. The influence of data-driven and physics-informed loss function weights on model accuracy is explored in detail. Benefiting from physics-based constraints, ST-SRPINN requires only low-resolution stress field data during training and can upscale the spatiotemporal resolution of stress fields to arbitrary magnifications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Material stress analysis is a critical aspect of material design andperformance optimization. Under dynamic loading, the global stress evolution inmaterials exhibits complex spatiotemporal characteristics, especially intwo-phase random materials (TRMs). Such kind of material failure is oftenassociated with stress concentration, and the phase boundaries are keylocations where stress concentration occurs. In practical engineeringapplications, the spatiotemporal resolution of acquired microstructural dataand its dynamic stress evolution is often limited. This poses challenges fordeep learning methods in generating high-resolution spatiotemporal stressfields, particularly for accurately capturing stress concentration regions. Inthis study, we propose a framework for global stress generation andspatiotemporal super-resolution in TRMs under dynamic loading. First, weintroduce a diffusion model-based approach, named as Spatiotemporal StressDiffusion (STS-diffusion), for generating global spatiotemporal stress data.This framework incorporates Space-Time U-Net (STU-net), and we systematicallyinvestigate the impact of different attention positions on model accuracy.Next, we develop a physics-informed network for spatiotemporalsuper-resolution, termed as Spatiotemporal Super-Resolution Physics-InformedOperator (ST-SRPINN). The proposed ST-SRPINN is an unsupervised learningmethod. The influence of data-driven and physics-informed loss function weightson model accuracy is explored in detail. Benefiting from physics-basedconstraints, ST-SRPINN requires only low-resolution stress field data duringtraining and can upscale the spatiotemporal resolution of stress fields toarbitrary magnifications.</description>
      <author>example@mail.com (Tengfei Xing, Xiaodan Ren, Jie Li)</author>
      <guid isPermaLink="false">2505.01438v1</guid>
      <pubDate>Tue, 06 May 2025 14:25:43 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning-Enabled System Diagnosis in Microgrids: A Feature-Feedback GAN Approach</title>
      <link>http://arxiv.org/abs/2505.01366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对逆变器微电网的两阶段故障和网络安全攻击检测框架。&lt;h4&gt;背景&lt;/h4&gt;逆变器资源和通信网络的集成带来了现代化，同时也引入了新的电力系统基础设施脆弱性，特别是虚假数据注入（FDI）攻击。&lt;h4&gt;目的&lt;/h4&gt;开发一种检测逆变器微电网内部故障和网络安全攻击的方法。&lt;h4&gt;方法&lt;/h4&gt;第一阶段引入了无监督学习模型F2GAN来区分微电网中的真实内部故障和由网络引起的异常。第二阶段应用了支持向量机（SVM）、k-最近邻（KNN）、决策树（DT）和人工神经网络（ANN）来定位和分类逆变器开关中的故障。&lt;h4&gt;主要发现&lt;/h4&gt;F2GAN在系统诊断和适应零日攻击方面优于传统的GAN架构。所提出的框架在模拟微电网环境中得到了验证，表明其在检测和分类物理和网络安全干扰方面具有稳健的性能。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效检测和分类逆变器微电网中的故障和网络安全攻击，对电力电子主导系统中的干扰具有识别能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing integration of inverter-based resources (IBRs) andcommunication networks has brought both modernization and new vulnerabilitiesto the power system infrastructure. These vulnerabilities expose the system tointernal faults and cyber threats, particularly False Data Injection (FDI)attacks, which can closely mimic real fault scenarios. Hence, this workpresents a two-stage fault and cyberattack detection framework tailored forinverter-based microgrids. Stage 1 introduces an unsupervised learning modelFeature Feedback Generative Adversarial Network (F2GAN), to distinguish betweengenuine internal faults and cyber-induced anomalies in microgrids. Compared toconventional GAN architectures, F2GAN demonstrates improved system diagnosisand greater adaptability to zero-day attacks through its feature-feedbackmechanism. In Stage 2, supervised machine learning techniques, includingSupport Vector Machines (SVM), k-Nearest Neighbors (KNN), Decision Trees (DT),and Artificial Neural Networks (ANN) are applied to localize and classifyfaults within inverter switches, distinguishing between single-switch andmulti-switch faults. The proposed framework is validated on a simulatedmicrogrid environment, illustrating robust performance in detecting andclassifying both physical and cyber-related disturbances in powerelectronic-dominated systems.</description>
      <author>example@mail.com (Swetha Rani Kasimalla, Kuchan Park, Junho Hong, Young-Jin Kim, HyoJong Lee)</author>
      <guid isPermaLink="false">2505.01366v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
  <item>
      <title>Tightly Coupled Range Inertial Odometry and Mapping with Exact Point Cloud Downsampling</title>
      <link>http://arxiv.org/abs/2505.01017v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE International Conference on Robotics and Automation (ICRA2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于因子图的点云下采样算法，用于实时处理多扫描配准误差最小化，并设计了一个完整的SLAM框架，该框架在标准CPU上实时运行，实验结果表明，该框架优于现有的基于CPU的SLAM框架。&lt;h4&gt;背景&lt;/h4&gt;为了实时处理多扫描配准误差最小化问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种算法，以减少需要评估的残差数量，同时保持采样点的无近似误差。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于核心集提取的点云下采样算法，该算法从输入点的残差中提取子集，使得子集在给定姿态下产生与原始集相同的二次误差函数。此外，还设计了一个完整的SLAM框架，包括基于滑动窗口优化的里程计估计和基于整个地图注册误差最小化的全局轨迹优化。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在标准CPU上实时运行，且实验结果表明，该框架优于现有的基于CPU的SLAM框架，无需使用GPU加速。&lt;h4&gt;结论&lt;/h4&gt;提出的算法和SLAM框架能够有效减少计算量，提高处理速度，且性能优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;In this work, to facilitate the real-time processing of multi-scan registration error minimization on factor graphs, we devise a point cloud downsampling algorithm based on coreset extraction. This algorithm extracts a subset of the residuals of input points such that the subset yields exactly the same quadratic error function as that of the original set for a given pose. This enables a significant reduction in the number of residuals to be evaluated without approximation errors at the sampling point. Using this algorithm, we devise a complete SLAM framework that consists of odometry estimation based on sliding window optimization and global trajectory optimization based on registration error minimization over the entire map, both of which can run in real time on a standard CPU. The experimental results demonstrate that the proposed framework outperforms state-of-the-art CPU-based SLAM frameworks without the use of GPU acceleration.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, to facilitate the real-time processing of multi-scanregistration error minimization on factor graphs, we devise a point clouddownsampling algorithm based on coreset extraction. This algorithm extracts asubset of the residuals of input points such that the subset yields exactly thesame quadratic error function as that of the original set for a given pose.This enables a significant reduction in the number of residuals to be evaluatedwithout approximation errors at the sampling point. Using this algorithm, wedevise a complete SLAM framework that consists of odometry estimation based onsliding window optimization and global trajectory optimization based onregistration error minimization over the entire map, both of which can run inreal time on a standard CPU. The experimental results demonstrate that theproposed framework outperforms state-of-the-art CPU-based SLAM frameworkswithout the use of GPU acceleration.</description>
      <author>example@mail.com (Kenji Koide, Aoki Takanose, Shuji Oishi, Masashi Yokozuka)</author>
      <guid isPermaLink="false">2505.01017v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>How Effective are Large Time Series Models in Hydrology? A Study on Water Level Forecasting in Everglades</title>
      <link>http://arxiv.org/abs/2505.01415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在佛罗里达州的艾维尔吉斯地区进行水位预测的模型，探讨了多种模型在预测洪水和干旱调节、水资源规划和生态系统管理方面的应用。&lt;h4&gt;背景&lt;/h4&gt;艾维尔吉斯在洪水和干旱调节、水资源规划和生态系统管理中扮演着关键角色，但传统的预测方法存在计算成本高和适应性差的问题。&lt;h4&gt;目的&lt;/h4&gt;研究十二种特定任务的模型和五种时间序列基础模型，以解决艾维尔吉斯地区水位预测的挑战。&lt;h4&gt;方法&lt;/h4&gt;在艾维尔吉斯地区进行了水位预测的实际应用研究，测试了多种模型，包括Chronos等基础模型和特定任务的模型。&lt;h4&gt;主要发现&lt;/h4&gt;Chronos基础模型在所有模型中表现最佳，其他基础模型表现相对较差。特定模型的表现因模型架构而异。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果表明，深度学习和基础模型在艾维尔吉斯地区的水位预测中具有潜力，但不同模型的表现差异较大。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Everglades在洪水和干旱调节、水资源规划以及周边地区的生态系统管理中发挥着至关重要的作用。然而，传统的基于物理和统计的方法在预测水位时往往面临重大挑战，包括高计算成本和有限的适应不同或不可预见条件的能力。最近在大型时间序列模型方面的进步表明，它们有潜力解决这些限制，最先进的深度学习和基础模型在各种领域的时间序列预测中取得了显著的成功。尽管取得了这些进展，但它们在关键环境系统，如Everglades中的应用仍然很少被探索。在这项研究中，我们通过调查十二种特定任务的模型和五种时间序列基础模型，填补了这一空白，这些模型涵盖了六个类别，以关注Everglades水位预测的实际应用。我们的主要结果表明，基础模型Chronos显著优于所有其他模型，而其他基础模型表现出相对较差的性能。此外，特定模型的表现因模型架构而异。最后，我们讨论了模型性能差异的可能原因。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Everglades play a crucial role in flood and drought regulation, waterresource planning, and ecosystem management in the surrounding regions.However, traditional physics-based and statistical methods for predicting waterlevels often face significant challenges, including high computational costsand limited adaptability to diverse or unforeseen conditions. Recentadvancements in large time series models have demonstrated the potential toaddress these limitations, with state-of-the-art deep learning and foundationmodels achieving remarkable success in time series forecasting across variousdomains. Despite this progress, their application to critical environmentalsystems, such as the Everglades, remains underexplored. In this study, we fillthe gap by investigating twelve task-specific models and five time seriesfoundation models across six categories for a real-world application focused onwater level prediction in the Everglades. Our primary results show that thefoundation model, Chronos, significantly outperforms all other models while theremaining foundation models exhibit relatively poor performance. Moreover, theperformance of task-specific models varies with the model architectures.Lastly, we discuss the possible reasons for the varying performance of models.</description>
      <author>example@mail.com (Rahuul Rangaraj, Jimeng Shi, Azam Shirali, Rajendra Paudel, Yanzhao Wu, Giri Narasimhan)</author>
      <guid isPermaLink="false">2505.01415v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Qracle: A Graph-Neural-Network-based Parameter Initializer for Variational Quantum Eigensolvers</title>
      <link>http://arxiv.org/abs/2505.01236v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的参数初始化方法Qracle，用于解决变分量子本征求解器（VQEs）在复杂问题中的优化挑战。&lt;h4&gt;背景&lt;/h4&gt;VQEs是NISQ算法中的领先类别，在量子物理和量子化学中有广泛应用。但随着系统规模的增加，VQE优化受到 barren plateau现象的阻碍，导致梯度消失和损失函数陷入局部最小值。&lt;h4&gt;目的&lt;/h4&gt;提出Qracle以解决VQE优化中的挑战，提高初始损失、加速收敛并改善最终性能。&lt;h4&gt;方法&lt;/h4&gt;Qracle将哈密顿量和相关基函数电路编码为统一的图表示，并利用GNN学习从VQE问题图到优化基函数参数的映射。&lt;h4&gt;主要发现&lt;/h4&gt;与最先进的初始化技术相比，Qracle将初始损失减少了10.86，通过减少优化步骤加速收敛高达64.42%，并使对称平均绝对百分比误差（SMAPE）降低了26.43%。&lt;h4&gt;结论&lt;/h4&gt;Qracle是一种有效的VQE参数初始化方法，能够显著提高VQE问题的优化性能。&lt;h4&gt;翻译&lt;/h4&gt;Variational Quantum Eigensolvers (VQEs) 是一种在量子物理和量子化学中具有广泛应用的前沿噪声中等规模量子（NISQ）算法。然而，随着系统规模的增加，VQE优化越来越受到 barren plateau 现象的阻碍，其中梯度消失，损失函数陷入局部最小值。虽然已经提出了基于机器学习的参数初始化方法来应对这一挑战，但它们在复杂的 VQE 问题中往往效果有限。这主要是因为它们无法充分模拟嵌入在哈密顿量结构和相关基函数电路中的复杂相关性。在本文中，我们提出了一种基于图神经网络（GNN）的 VQE 参数初始化方法 Qracle。Qracle 系统地将哈密顿量和相关基函数电路编码为统一的图表示，并利用 GNN 学习从 VQE 问题图到优化基函数参数的映射。与最先进的初始化技术相比，Qracle 实现了初始损失的减少高达 10.86，通过减少优化步骤加速收敛高达 64.42%，并使对称平均绝对百分比误差（SMAPE）降低了 26.43%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Variational Quantum Eigensolvers (VQEs) are a leading class of noisyintermediate-scale quantum (NISQ) algorithms with broad applications in quantumphysics and quantum chemistry. However, as system size increases, VQEoptimization is increasingly hindered by the barren plateau phenomenon, wheregradients vanish and the loss function becomes trapped in local minima. Whilemachine learning-based parameter initialization methods have been proposed toaddress this challenge, they often show limited effectiveness in complex VQEproblems. This is primarily due to their inadequate ability to model theintricate correlations embedded in the Hamiltonian structure and the associatedansatz circuits. In this paper, we propose \textit{Qracle}, a graph neuralnetwork (GNN)-based parameter initializer for VQEs. \textit{Qracle}systematically encodes both the Hamiltonian and the associated ansatz circuitinto a unified graph representation and leverages a GNN to learn a mapping fromVQE problem graphs to optimized ansatz parameters. Compared to state-of-the-artinitialization techniques, \textit{Qracle} achieves a reduction in initial lossof up to $10.86$, accelerates convergence by decreasing optimization steps byup to $64.42\%$, and improves final performance with up to a $26.43\%$reduction in Symmetric Mean Absolute Percentage Error (SMAPE).</description>
      <author>example@mail.com (Chi Zhang, Lei Jiang, Fan Chen)</author>
      <guid isPermaLink="false">2505.01236v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>SMSAT: A Multimodal Acoustic Dataset and Deep Contrastive Learning Framework for Affective and Physiological Modeling of Spiritual Meditation</title>
      <link>http://arxiv.org/abs/2505.00839v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了听觉刺激如何影响情绪和生理状态，提出了一个多模态评估方法，并引入了新的数据集和深度学习框架，用于分析精神冥想、音乐和自然寂静三种听觉条件下的情感和生理影响。&lt;h4&gt;背景&lt;/h4&gt;理解听觉刺激如何影响情绪和生理状态对于情感计算和心理健康技术的发展至关重要。&lt;h4&gt;目的&lt;/h4&gt;评估三种听觉条件（精神冥想、音乐和自然寂静）对情感和生理状态的影响。&lt;h4&gt;方法&lt;/h4&gt;使用生物特征信号测量方法，引入了Spiritual, Music, Silence Acoustic Time Series (SMSAT)数据集，并开发了一个基于对比学习的SMSAT音频编码器以及一个集成25个手工和学习的特征的Calmness Analysis Model (CAM)。&lt;h4&gt;主要发现&lt;/h4&gt;SMSAT音频编码器实现了99.99%的分类准确率，CAM在情感状态分类中达到了99.99%的分类准确率。SM分析通过ANOVA显示显著的生理波动。与现有方法的最高90%的准确率相比，本文提出的方法性能提升显著，最高达到99%。&lt;h4&gt;结论&lt;/h4&gt;本文为情感计算应用提供了经过验证的多模态数据集和可扩展的深度学习框架，可用于压力监测、心理健康和基于音频的治疗干预。&lt;h4&gt;翻译&lt;/h4&gt;Understanding how auditory stimuli influence emotional and physiological states is fundamental to advancing affective computing and mental health technologies. In this paper, we present a multimodal evaluation of the affective and physiological impacts of three auditory conditions, that is, spiritual meditation (SM), music (M), and natural silence (NS), using a comprehensive suite of biometric signal measures. To facilitate this analysis, we introduce the Spiritual, Music, Silence Acoustic Time Series (SMSAT) dataset, a novel benchmark comprising acoustic time series (ATS) signals recorded under controlled exposure protocols, with careful attention to demographic diversity and experimental consistency. To model the auditory induced states, we develop a contrastive learning based SMSAT audio encoder that extracts highly discriminative embeddings from ATS data, achieving 99.99% classification accuracy in interclass and intraclass evaluations. Furthermore, we propose the Calmness Analysis Model (CAM), a deep learning framework integrating 25 handcrafted and learned features for affective state classification across auditory conditions, attaining robust 99.99% classification accuracy. In contrast, pairwise t tests reveal significant deviations in cardiac response characteristics (CRC) between SM analysis via ANOVA inducing more significant physiological fluctuations. Compared to existing state of the art methods reporting accuracies up to 90%, the proposed model demonstrates substantial performance gains (up to 99%). This work contributes a validated multimodal dataset and a scalable deep learning framework for affective computing applications in stress monitoring, mental well-being, and therapeutic audio-based interventions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding how auditory stimuli influence emotional and physiologicalstates is fundamental to advancing affective computing and mental healthtechnologies. In this paper, we present a multimodal evaluation of theaffective and physiological impacts of three auditory conditions, that is,spiritual meditation (SM), music (M), and natural silence (NS), using acomprehensive suite of biometric signal measures. To facilitate this analysis,we introduce the Spiritual, Music, Silence Acoustic Time Series (SMSAT)dataset, a novel benchmark comprising acoustic time series (ATS) signalsrecorded under controlled exposure protocols, with careful attention todemographic diversity and experimental consistency. To model the auditoryinduced states, we develop a contrastive learning based SMSAT audio encoderthat extracts highly discriminative embeddings from ATS data, achieving 99.99%classification accuracy in interclass and intraclass evaluations. Furthermore,we propose the Calmness Analysis Model (CAM), a deep learning frameworkintegrating 25 handcrafted and learned features for affective stateclassification across auditory conditions, attaining robust 99.99%classification accuracy. In contrast, pairwise t tests reveal significantdeviations in cardiac response characteristics (CRC) between SM analysis viaANOVA inducing more significant physiological fluctuations. Compared toexisting state of the art methods reporting accuracies up to 90%, the proposedmodel demonstrates substantial performance gains (up to 99%). This workcontributes a validated multimodal dataset and a scalable deep learningframework for affective computing applications in stress monitoring, mentalwell-being, and therapeutic audio-based interventions.</description>
      <author>example@mail.com (Ahmad Suleman, Yazeed Alkhrijah, Misha Urooj Khan, Hareem Khan, Muhammad Abdullah Husnain Ali Faiz, Mohamad A. Alawad, Zeeshan Kaleem, Guan Gui)</author>
      <guid isPermaLink="false">2505.00839v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing User Sequence Modeling through Barlow Twins-based Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2505.00953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Barlow Twins的自监督学习方法，用于用户序列建模，旨在减少对大量负样本的需求，从而在有限的标记数据和负样本情况下实现有效的表示学习。&lt;h4&gt;背景&lt;/h4&gt;用户序列建模对于现代大规模推荐系统至关重要，因为它可以从用户的历史交互中提取用户和项目的有用表示。然而，学习这些表示的一个关键挑战是缺乏标记的训练数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种适应Barlow Twins的自监督学习方法，通过结合合适的增强方法，减少对大量负样本的需求，以实现有效的表示学习。&lt;h4&gt;方法&lt;/h4&gt;在用户序列建模中应用Barlow Twins，并引入适当的增强方法，以减少对负样本批次的需求，从而在较小的批次大小和有限的标记数据下进行有效的表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;在MovieLens-1M、MovieLens-20M和Yelp数据集上评估了该方法，结果显示在三个下游任务中，该方法始终优于广泛使用的双编码器模型，准确率提高了8%-20%。&lt;h4&gt;结论&lt;/h4&gt;该方法在提取用户建模中的有价值序列信息方面非常有效，特别是在标记数据稀缺和负样本有限的情况下。&lt;h4&gt;翻译&lt;/h4&gt;摘要：用户序列建模对于现代大规模推荐系统至关重要，因为它能够从用户的历史交互中提取用户和物品的有用表示。这些用户表示被广泛用于各种下游任务，以增强用户的在线体验。学习这些表示的一个关键挑战是缺乏标记的训练数据。虽然自监督学习（SSL）方法已经出现，作为一种从无标签数据中学习表示的有希望解决方案，但许多现有方法依赖于大量的负样本采样，这可能是计算上昂贵的，并且在现实场景中可能并不总是可行。在本工作中，我们提出了一种Barlow Twins（一种最先进的SSL方法）的改编，用于用户序列建模，通过结合适当的增强方法。我们的方法旨在减少对大量负样本批次的需求，从而使用较小的批次大小和有限的标记数据实现有效的表示学习。我们在MovieLens-1M、MovieLens-20M和Yelp数据集上评估了我们的方法，表明我们的方法在三个下游任务中始终优于广泛使用的双编码器模型，实现了8%-20%的准确率提升。我们的发现强调了我们的方法在提取用户建模的有价值序列信息方面的有效性，尤其是在标记数据稀缺和负样本有限的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; User sequence modeling is crucial for modern large-scale recommendationsystems, as it enables the extraction of informative representations of usersand items from their historical interactions. These user representations arewidely used for a variety of downstream tasks to enhance users' onlineexperience. A key challenge for learning these representations is the lack oflabeled training data. While self-supervised learning (SSL) methods haveemerged as a promising solution for learning representations from unlabeleddata, many existing approaches rely on extensive negative sampling, which canbe computationally expensive and may not always be feasible in real-worldscenario. In this work, we propose an adaptation of Barlow Twins, astate-of-the-art SSL methods, to user sequence modeling by incorporatingsuitable augmentation methods. Our approach aims to mitigate the need for largenegative sample batches, enabling effective representation learning withsmaller batch sizes and limited labeled data. We evaluate our method on theMovieLens-1M, MovieLens-20M, and Yelp datasets, demonstrating that our methodconsistently outperforms the widely-used dual encoder model across threedownstream tasks, achieving an 8%-20% improvement in accuracy. Our findingsunderscore the effectiveness of our approach in extracting valuablesequence-level information for user modeling, particularly in scenarios wherelabeled data is scarce and negative examples are limited.</description>
      <author>example@mail.com (Yuhan Liu, Lin Ning, Neo Wu, Karan Singhal, Philip Andrew Mansfield, Devora Berlowitz, Sushant Prakash, Bradley Green)</author>
      <guid isPermaLink="false">2505.00953v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>A Physics-preserved Transfer Learning Method for Differential Equations</title>
      <link>http://arxiv.org/abs/2505.01281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对微分方程的通用迁移学习方法，该方法能够自适应地纠正领域偏移并保留物理信息。&lt;h4&gt;背景&lt;/h4&gt;尽管基于数据的神经网络算子等在求解微分方程方面取得了成功，但它们受到不同学习环境（数据偏差或方程变化）导致的领域偏移问题的影响，这些问题可以通过迁移学习（TL）来缓解。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有迁移学习方法在微分方程问题中缺乏泛化能力或训练过程中的物理信息保留的问题。&lt;h4&gt;方法&lt;/h4&gt;将数据域表征为产品分布，将基本问题表征为分布偏差和算子偏差。提出了一种物理保留最优张量传输（POTT）方法，该方法同时允许对常见微分方程的泛化性和对特定问题的物理信息保留，利用POTT映射诱导的推前分布将数据驱动模型适应到目标域。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验，证明了所提出的POTT方法在性能、泛化性和物理信息保留方面的优越性。&lt;h4&gt;结论&lt;/h4&gt;POTT方法能够有效地解决微分方程中的领域偏移问题，同时保持物理信息的准确性。&lt;h4&gt;翻译&lt;/h4&gt;While data-driven methods such as neural operator have achieved great success in solving differential equations (DEs), they suffer from domain shift problems caused by different learning environments (with data bias or equation changes), which can be alleviated by transfer learning (TL). However, existing TL methods adopted in DEs problems lack either generalizability in general DEs problems or physics preservation during training. In this work, we focus on a general transfer learning method that adaptively correct the domain shift and preserve physical information. Mathematically, we characterize the data domain as product distribution and the essential problems as distribution bias and operator bias. A Physics-preserved Optimal Tensor Transport (POTT) method that simultaneously admits generalizability to common DEs and physics preservation of specific problem is proposed to adapt the data-driven model to target domain utilizing the push-forward distribution induced by the POTT map. Extensive experiments demonstrate the superior performance, generalizability and physics preservation of the proposed POTT method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While data-driven methods such as neural operator have achieved great successin solving differential equations (DEs), they suffer from domain shift problemscaused by different learning environments (with data bias or equation changes),which can be alleviated by transfer learning (TL). However, existing TL methodsadopted in DEs problems lack either generalizability in general DEs problems orphysics preservation during training. In this work, we focus on a generaltransfer learning method that adaptively correct the domain shift and preservephysical information. Mathematically, we characterize the data domain asproduct distribution and the essential problems as distribution bias andoperator bias. A Physics-preserved Optimal Tensor Transport (POTT) method thatsimultaneously admits generalizability to common DEs and physics preservationof specific problem is proposed to adapt the data-driven model to target domainutilizing the push-forward distribution induced by the POTT map. Extensiveexperiments demonstrate the superior performance, generalizability and physicspreservation of the proposed POTT method.</description>
      <author>example@mail.com (Hao-Ran Yang, Chuan-Xian Ren)</author>
      <guid isPermaLink="false">2505.01281v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>FreeInsert: Disentangled Text-Guided Object Insertion in 3D Gaussian Scene without Spatial Priors</title>
      <link>http://arxiv.org/abs/2505.01322v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FreeInsert的框架，用于在3D场景中通过自然语言实现直观的场景编辑，无需依赖空间先验信息。&lt;h4&gt;背景&lt;/h4&gt;现有的基于2D编辑的方法通常依赖于空间先验，如2D掩膜或3D边界框，难以保证插入对象的一致性，限制了其在现实应用中的灵活性和可扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，使对象生成与空间放置分离，实现3D场景中无空间先验的灵活和自动化的对象插入。&lt;h4&gt;方法&lt;/h4&gt;FreeInsert利用基础模型，包括MLLMs、LGMs和扩散模型，从用户指令中提取结构化语义，包括对象类型、空间关系和附加区域。这些语义指导插入对象的3D一致性重建和自由度学习。MLLMs的空间推理能力用于初始化对象的姿态和比例。一个分层、空间感知的细化阶段进一步整合空间语义和MLLM推断的先验，以增强放置。最后，使用插入对象的图像来提高外观，以增强视觉保真度。&lt;h4&gt;主要发现&lt;/h4&gt;FreeInsert在不依赖空间先验的情况下，实现了语义上连贯、空间上精确和视觉上逼真的3D插入。&lt;h4&gt;结论&lt;/h4&gt;FreeInsert提供了一个用户友好且灵活的编辑体验，为3D场景编辑提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;在3D场景中进行文本驱动对象插入是一个新兴的任务，它通过自然语言实现直观的场景编辑。然而，现有的基于2D编辑的方法通常依赖于空间先验，如2D掩膜或3D边界框，并且难以确保插入对象的一致性。这些限制阻碍了其在现实应用中的灵活性和可扩展性。在本文中，我们提出了一种名为FreeInsert的新框架，该框架利用包括MLLMs、LGMs和扩散模型在内的基础模型，将对象生成与空间放置分离。这可以实现3D场景中无空间先验的灵活和自动化的对象插入。FreeInsert从基于MLLM的解析器开始，该解析器从用户指令中提取结构化语义，包括对象类型、空间关系和附加区域。这些语义指导插入对象的3D一致性重建和自由度学习。我们利用MLLMs的空间推理能力来初始化对象的位置和比例。一个分层、空间感知的细化阶段进一步整合空间语义和MLLM推断的先验，以增强放置。最后，使用插入对象的图像来提高外观，以增强视觉保真度。实验结果表明，FreeInsert在不依赖空间先验的情况下，实现了语义上连贯、空间上精确和视觉上逼真的3D插入，提供了一种用户友好且灵活的编辑体验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-driven object insertion in 3D scenes is an emerging task that enablesintuitive scene editing through natural language. However, existing 2Dediting-based methods often rely on spatial priors such as 2D masks or 3Dbounding boxes, and they struggle to ensure consistency of the inserted object.These limitations hinder flexibility and scalability in real-worldapplications. In this paper, we propose FreeInsert, a novel framework thatleverages foundation models including MLLMs, LGMs, and diffusion models todisentangle object generation from spatial placement. This enables unsupervisedand flexible object insertion in 3D scenes without spatial priors. FreeInsertstarts with an MLLM-based parser that extracts structured semantics, includingobject types, spatial relationships, and attachment regions, from userinstructions. These semantics guide both the reconstruction of the insertedobject for 3D consistency and the learning of its degrees of freedom. Weleverage the spatial reasoning capabilities of MLLMs to initialize object poseand scale. A hierarchical, spatially aware refinement stage further integratesspatial semantics and MLLM-inferred priors to enhance placement. Finally, theappearance of the object is improved using the inserted-object image to enhancevisual fidelity. Experimental results demonstrate that FreeInsert achievessemantically coherent, spatially precise, and visually realistic 3D insertionswithout relying on spatial priors, offering a user-friendly and flexibleediting experience.</description>
      <author>example@mail.com (Chenxi Li, Weijie Wang, Qiang Li, Bruno Lepri, Nicu Sebe, Weizhi Nie)</author>
      <guid isPermaLink="false">2505.01322v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Efficient On-Chip Implementation of 4D Radar-Based 3D Object Detection on Hailo-8L</title>
      <link>http://arxiv.org/abs/2505.00757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于4D雷达的3D物体检测模型，在Hailo-8L AI加速器上实现了芯片级部署，解决了传统3D卷积神经网络架构与Hailo-8L 4D张量支持的兼容性问题。&lt;h4&gt;背景&lt;/h4&gt;4D雷达在自动驾驶领域受到关注，因为它能够在恶劣天气条件下实现鲁棒的3D物体检测。&lt;h4&gt;目的&lt;/h4&gt;在低功耗嵌入式环境中实现4D雷达技术的实时处理。&lt;h4&gt;方法&lt;/h4&gt;提出了一种张量变换方法，在编译过程中将5D输入转换为4D格式，以适应Hailo-8L的4D张量支持。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在Hailo-8L上实现了46.47%的AP_3D和52.75%的AP_BEV，保持了与基于GPU的模型相当的准确性，同时达到了13.76 Hz的推理速度。&lt;h4&gt;结论&lt;/h4&gt;4D雷达感知技术适用于自动驾驶系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 4D radar has attracted attention in autonomous driving due to its ability toenable robust 3D object detection even under adverse weather conditions. Topractically deploy such technologies, it is essential to achieve real-timeprocessing within low-power embedded environments. Addressing this, we presentthe first on-chip implementation of a 4D radar-based 3D object detection modelon the Hailo-8L AI accelerator. Although conventional 3D convolutional neuralnetwork (CNN) architectures require 5D inputs, the Hailo-8L only supports 4Dtensors, posing a significant challenge. To overcome this limitation, weintroduce a tensor transformation method that reshapes 5D inputs into 4Dformats during the compilation process, enabling direct deployment withoutaltering the model structure. The proposed system achieves 46.47% AP_3D and52.75% AP_BEV, maintaining comparable accuracy to GPU-based models whileachieving an inference speed of 13.76 Hz. These results demonstrate theapplicability of 4D radar-based perception technologies to autonomous drivingsystems.</description>
      <author>example@mail.com (Woong-Chan Byun, Dong-Hee Paek, Seung-Hyun Song, Seung-Hyun Kong)</author>
      <guid isPermaLink="false">2505.00757v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network-based structural classification of glass-forming liquids and its interpretation via Self-Attention mechanism</title>
      <link>http://arxiv.org/abs/2505.00993v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9pages, 5 figures for main text, 12 pages for Supplementary Material&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究利用机器学习中的图神经网络（GNNs）和自注意力机制，探索了玻璃形成液体在不同温度下的结构变化及其机理。&lt;h4&gt;背景&lt;/h4&gt;玻璃形成液体在熔点以下表现出缓慢的动力学，并保持类似正常液体的非晶结构。区分超冷却和高温下的微观结构是一个有争议的话题。&lt;h4&gt;目的&lt;/h4&gt;研究目的是通过机器学习方法揭示玻璃形成液体结构变化的基本机制。&lt;h4&gt;方法&lt;/h4&gt;研究使用图神经网络自动提取特征，并通过自注意力机制生成注意力系数，量化图节点之间连接的重要性，同时使用物理定义的结构描述符来探索结构随温度降低的变化。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，高注意力系数与更无序的结构之间存在强相关性，这被认为是玻璃形成液体变化的关键指标。&lt;h4&gt;结论&lt;/h4&gt;该研究通过GNN+自注意力方法揭示了玻璃形成液体结构变化的内在机理，为理解这些液体的性质提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要：玻璃形成液体在其熔点以下表现出缓慢的动力学，保持与非晶态液体相似的结构。区分超冷却和高温下的微观结构是一个有争议的话题。基于最近在机器学习，尤其是图神经网络（GNNs）方面的进展，我们的研究自动提取特征，揭示了在不同温度下驱动结构变化的根本机制。我们采用自注意力机制来生成注意力系数，量化图节点之间连接的重要性，为GNN预测背后的原因提供洞察。通过使用物理定义的结构描述符，包括键取向序参数、Voronoi单元体积和配位数，以及GNN+自注意力方法，我们发现了高注意力系数与更无序结构之间的强相关性，这被认为是玻璃形成液体变化的关键指标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Glass-forming liquids exhibit slow dynamics below their melting temperatures,maintaining an amorphous structure reminiscent of normal liquids.Distinguishing microscopic structures in the supercooled and high-temperatureregimes remains a debated topic. Building on recent advances in machinelearning, particularly Graph Neural Networks (GNNs), our study automaticallyextracts features, unveiling fundamental mechanisms driving structural changesat varying temperatures. We employ the Self-Attention mechanism to generateattention coefficients that quantify the importance of connections betweengraph nodes, providing insights into the rationale behind GNN predictions.Exploring structural changes with decreasing temperature through theGNN+Self-Attention using physically-defined structural descriptors, includingthe bond-orientational order parameter, Voronoi cell volume, and coordinationnumber, we identify strong correlations between high attention coefficients andmore disordered structures as a key indicator of variations in glass-formingliquids.</description>
      <author>example@mail.com (Kohei Yoshikawa, Kentaro Yano, Shota Goto, Kang Kim, Nobuyuki Matubayasi)</author>
      <guid isPermaLink="false">2505.00993v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Can Foundation Models Really Segment Tumors? A Benchmarking Odyssey in Lung CT Imaging</title>
      <link>http://arxiv.org/abs/2505.01239v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究对基于深度学习的肺肿瘤分割模型进行了全面基准分析，比较了传统架构如U-Net和DeepLabV3，自配置模型如nnUNet，以及基础模型如MedSAM和MedSAM~2，评估了在不同学习范式下的分割准确性和计算效率，发现基础模型在准确性和计算效率上优于传统模型。&lt;h4&gt;背景&lt;/h4&gt;精确的肺肿瘤分割对于提高肿瘤学中的诊断、治疗规划和患者预后至关重要。&lt;h4&gt;目的&lt;/h4&gt;评估基于深度学习的肺肿瘤分割模型在不同学习范式下的性能，特别是分割准确性和计算效率。&lt;h4&gt;方法&lt;/h4&gt;对U-Net、DeepLabV3、nnUNet、MedSAM和MedSAM~2等模型进行了比较，并在两个肺肿瘤分割数据集上进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;传统模型在肿瘤分割方面存在困难，而基础模型MedSAM~2在准确性和计算效率上都优于传统模型。&lt;h4&gt;结论&lt;/h4&gt;基础模型在肺肿瘤分割中具有潜力，有助于改善临床工作流程和患者预后。&lt;h4&gt;翻译&lt;/h4&gt;Accurate lung tumor segmentation is crucial for improving diagnosis, treatment planning, and patient outcomes in oncology. However, the complexity of tumor morphology, size, and location poses significant challenges for automated segmentation. This study presents a comprehensive benchmarking analysis of deep learning-based segmentation models, comparing traditional architectures such as U-Net and DeepLabV3, self-configuring models like nnUNet, and foundation models like MedSAM, and MedSAM~2. Evaluating performance across two lung tumor segmentation datasets, we assess segmentation accuracy and computational efficiency under various learning paradigms, including few-shot learning and fine-tuning. The results reveal that while traditional models struggle with tumor delineation, foundation models, particularly MedSAM~2, outperform them in both accuracy and computational efficiency. These findings underscore the potential of foundation models for lung tumor segmentation, highlighting their applicability in improving clinical workflows and patient outcomes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate lung tumor segmentation is crucial for improving diagnosis,treatment planning, and patient outcomes in oncology. However, the complexityof tumor morphology, size, and location poses significant challenges forautomated segmentation. This study presents a comprehensive benchmarkinganalysis of deep learning-based segmentation models, comparing traditionalarchitectures such as U-Net and DeepLabV3, self-configuring models like nnUNet,and foundation models like MedSAM, and MedSAM~2. Evaluating performance acrosstwo lung tumor segmentation datasets, we assess segmentation accuracy andcomputational efficiency under various learning paradigms, including few-shotlearning and fine-tuning. The results reveal that while traditional modelsstruggle with tumor delineation, foundation models, particularly MedSAM~2,outperform them in both accuracy and computational efficiency. These findingsunderscore the potential of foundation models for lung tumor segmentation,highlighting their applicability in improving clinical workflows and patientoutcomes.</description>
      <author>example@mail.com (Elena Mulero Ayllón, Massimiliano Mantegna, Linlin Shen, Paolo Soda, Valerio Guarrasi, Matteo Tortora)</author>
      <guid isPermaLink="false">2505.01239v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Identifying Root Cause of bugs by Capturing Changed Code Lines with Relational Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2505.00990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种即时缺陷预测模型，旨在帮助开发团队提高软件质量和效率，通过实时评估开发者提交的代码变更是否可能引入缺陷，以便在提交阶段及时识别潜在问题。&lt;h4&gt;背景&lt;/h4&gt;由于所有删除和添加的代码行可能与引入的缺陷的根本原因相关，当前工作中存在两个主要挑战：1）缺乏有效集成异构图信息；2）缺乏更改代码行之间的语义关系。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了RC-Detection方法，该方法利用关系图卷积网络来捕捉更改代码行之间的语义关系，并用于检测更改代码行中的根本原因删除行，从而识别修复提交中引入的缺陷的根本原因。&lt;h4&gt;方法&lt;/h4&gt;RC-Detection方法用于检测更改代码行中的根本原因删除行，并通过收集来自87个开源项目的数据（包括675个修复提交）来评估其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与最先进的根本原因检测方法相比，RC-Detection在Recall@1、Recall@2、Recall@3和MFR方面分别提高了4.107%、5.113%、4.289%和24.536%。&lt;h4&gt;结论&lt;/h4&gt;RC-Detection方法在实时缺陷预测中显示出显著的性能提升，有助于提高软件质量和开发效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：即时缺陷预测模型通过评估开发者提交的代码变更是否可能引入缺陷，帮助开发团队提高软件质量和效率，允许在提交阶段及时识别潜在问题。然而，由于所有删除和添加的代码行可能与引入的缺陷的根本原因相关，当前工作中存在两个主要挑战：1）缺乏有效集成异构图信息；2）缺乏更改代码行之间的语义关系。为了解决这些挑战，我们提出了一种名为RC-Detection的方法，该方法利用关系图卷积网络来捕捉更改代码行之间的语义关系。RC-Detection用于检测更改代码行中的根本原因删除行，从而识别修复提交中引入的缺陷的根本原因。为了评估RC-Detection的有效性，我们使用了包含高质量修复和引入提交的三个数据集。我们通过收集来自87个开源项目的数据（包括675个修复提交）进行了广泛的实验，以评估我们模型的表现。实验结果表明，与最先进的根本原因检测方法相比，RC-Detection在Recall@1、Recall@2、Recall@3和MFR方面分别提高了4.107%、5.113%、4.289%和24.536%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Just-In-Time defect prediction model helps development teams improvesoftware quality and efficiency by assessing whether code changes submitted bydevelopers are likely to introduce defects in real-time, allowing timelyidentification of potential issues during the commit stage. However, two mainchallenges exist in current work due to the reality that all deleted and addedlines in bug-fixing commits may be related to the root cause of the introducedbug: 1) lack of effective integration of heterogeneous graph information, and2) lack of semantic relationships between changed code lines. To address thesechallenges, we propose a method called RC-Detection, which utilizes relationalgraph convolutional network to capture the semantic relationships betweenchanged code lines. RC-Detection is used to detect root-cause deletion lines inchanged code lines, thereby identifying the root cause of introduced bugs inbug-fixing commits. To evaluate the effectiveness of RC-Detection, we usedthree datasets that contain high-quality bug-fixing and bug-introducingcommits. Extensive experiments were conducted to evaluate the performance ofour model by collecting data from 87 open-source projects, including 675bug-fix commits. The experimental results show that, compared to the mostadvanced root cause detection methods, RC-Detection improved Recall@1,Recall@2, Recall@3, and MFR by at 4.107%, 5.113%, 4.289%, and 24.536%,respectively.</description>
      <author>example@mail.com (Jiaqi Zhang, Shikai Guo, Hui Li, Chenchen Li, Yu Chai, Rong Chen)</author>
      <guid isPermaLink="false">2505.00990v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>TSTMotion: Training-free Scene-awarenText-to-motion Generation</title>
      <link>http://arxiv.org/abs/2505.01182v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICME2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TSTMotion的无需训练的场感知文本到动作生成框架，用于在空白背景中生成人类动作序列，并有效利用预训练的运动生成器。&lt;h4&gt;背景&lt;/h4&gt;当前文本到动作生成研究主要集中于空白背景中的人类动作序列生成，但现实中的动作通常发生在多样化的3D场景中。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需使用大量真实3D场景动作数据集的场感知文本到动作生成方法，以降低成本。&lt;h4&gt;方法&lt;/h4&gt;采用基础模型进行推理、预测和验证场景感知的运动引导，并将该引导融入空白背景动作生成器，通过两种修改实现场感知文本驱动的动作序列。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法有效且具有泛化能力。&lt;h4&gt;结论&lt;/h4&gt;TSTMotion框架在无需训练的情况下实现了高效的场感知文本到动作生成。&lt;h4&gt;翻译&lt;/h4&gt;Text-to-motion generation has recently garnered significant research interest, primarily focusing on generating human motion sequences in blank backgrounds. However, human motions commonly occur within diverse 3D scenes, which has prompted exploration into scene-aware text-to-motion generation methods. Yet, existing scene-aware methods often rely on large-scale ground-truth motion sequences in diverse 3D scenes, which poses practical challenges due to the expensive cost. To mitigate this challenge, we are the first to propose a Training-free Scene-aware Text-to-Motion framework, dubbed as TSMotion, that efficiently empowers pre-trained blank-background motion generators with the scene-aware capability. Specifically, conditioned on the given 3D scene and text description, we adopt foundation models together to reason, predict and validate a scene-aware motion guidance. Then, the motion guidance is incorporated into the blank-background motion generators with two modifications, resulting in scene-aware text-driven motion sequences. Extensive experiments demonstrate the efficacy and generalizability of our proposed framework. We release our code in ProjectPage.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-to-motion generation has recently garnered significant researchinterest, primarily focusing on generating human motion sequences in blankbackgrounds. However, human motions commonly occur within diverse 3D scenes,which has prompted exploration into scene-aware text-to-motion generationmethods. Yet, existing scene-aware methods often rely on large-scaleground-truth motion sequences in diverse 3D scenes, which poses practicalchallenges due to the expensive cost. To mitigate this challenge, we are thefirst to propose a \textbf{T}raining-free \textbf{S}cene-aware\textbf{T}ext-to-\textbf{Motion} framework, dubbed as \textbf{TSTMotion}, thatefficiently empowers pre-trained blank-background motion generators with thescene-aware capability. Specifically, conditioned on the given 3D scene andtext description, we adopt foundation models together to reason, predict andvalidate a scene-aware motion guidance. Then, the motion guidance isincorporated into the blank-background motion generators with twomodifications, resulting in scene-aware text-driven motion sequences. Extensiveexperiments demonstrate the efficacy and generalizability of our proposedframework. We release our code in \href{https://tstmotion.github.io/}{ProjectPage}.</description>
      <author>example@mail.com (Ziyan Guo, Haoxuan Qu, Hossein Rahmani, Dewen Soh, Ping Hu, Qiuhong Ke, Jun Liu)</author>
      <guid isPermaLink="false">2505.01182v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Toward Data-centric Directed Graph Learning: An Entropy-driven Approach</title>
      <link>http://arxiv.org/abs/2505.00983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EDEN的熵驱动的有向图知识蒸馏方法，旨在提高有向图神经网络（DiGNNs）的性能。&lt;h4&gt;背景&lt;/h4&gt;有向图（digraph）在复杂拓扑系统建模中具有优越的表示能力，但现有的DiGNNs未能充分利用有向图中的数据知识，导致模型预测性能不佳。&lt;h4&gt;目的&lt;/h4&gt;通过探索有向边（拓扑）和节点特征（特征和标签）之间的潜在相关性，增强模型中心的神经网络编码能力。&lt;h4&gt;方法&lt;/h4&gt;EDEN采用层次编码理论，首先利用拓扑视角的定向结构度量构建粗粒度层次知识树（HKT），然后量化节点特征的互信息以优化知识流。&lt;h4&gt;主要发现&lt;/h4&gt;EDEN在14个（有向）图数据集和4个下游任务上进行了广泛评估，结果表明EDEN达到了最先进的性能，并显著提高了常见的DiGNNs的性能。&lt;h4&gt;结论&lt;/h4&gt;EDEN作为一种数据中心的图学习范式或模型无关的知识蒸馏模块，能够有效地提升有向图神经网络的学习效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The directed graph (digraph), as a generalization of undirected graphs,exhibits superior representation capability in modeling complex topologysystems and has garnered considerable attention in recent years. Despite thenotable efforts made by existing DiGraph Neural Networks (DiGNNs) to leveragedirected edges, they still fail to comprehensively delve into the abundant dataknowledge concealed in the digraphs. This data-level limitation results inmodel-level sub-optimal predictive performance and underscores the necessity offurther exploring the potential correlations between the directed edges(topology) and node profiles (feature and labels) from a data-centricperspective, thereby empowering model-centric neural networks with strongerencoding capabilities.  In this paper, we propose \textbf{E}ntropy-driven \textbf{D}igraphknowl\textbf{E}dge distillatio\textbf{N} (EDEN), which can serve as adata-centric digraph learning paradigm or a model-agnostic hot-and-plugdata-centric Knowledge Distillation (KD) module. The core idea is to achievedata-centric ML, guided by our proposed hierarchical encoding theory forstructured data. Specifically, EDEN first utilizes directed structuralmeasurements from a topology perspective to construct a coarse-grainedHierarchical Knowledge Tree (HKT). Subsequently, EDEN quantifies the mutualinformation of node profiles to refine knowledge flow in the HKT, enablingdata-centric KD supervision within model training. As a general framework, EDENcan also naturally extend to undirected scenarios and demonstrate satisfactoryperformance. In our experiments, EDEN has been widely evaluated on 14 (di)graphdatasets (homophily and heterophily) and across 4 downstream tasks. The resultsdemonstrate that EDEN attains SOTA performance and exhibits strong improvementfor prevalent (Di)GNNs.</description>
      <author>example@mail.com (Xunkai Li, Zhengyu Wu, Kaichi Yu, Hongchao Qin, Guang Zeng, Rong-Hua Li, Guoren Wang)</author>
      <guid isPermaLink="false">2505.00983v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervision Enhances Instance-based Multiple Instance Learning Methods in Digital Pathology: A Benchmark Study</title>
      <link>http://arxiv.org/abs/2505.01109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in the Journal of Medical Imaging (SPIE)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MIL（多实例学习）是全切片图像分类的最佳解决方案，本文通过实验验证了基于实例的MIL方法在特定条件下可以媲美复杂的基于嵌入的MIL方法。&lt;h4&gt;背景&lt;/h4&gt;MIL通过将切片划分为多个补丁，每个补丁作为一个包含全局标签的实例的包进行处理。MIL主要有两种方法：基于实例和基于嵌入。尽管基于实例的方法更易于解释，但基于嵌入的方法由于对特征提取器的鲁棒性而更受欢迎。&lt;h4&gt;目的&lt;/h4&gt;研究基于实例的MIL方法是否可以通过使用自监督学习（SSL）提高性能。&lt;h4&gt;方法&lt;/h4&gt;作者在4个数据集上进行了710次实验，比较了10种MIL策略，6种自监督方法与4个骨干网络，4个基础模型以及各种病理适应性技术。此外，作者引入了4种在病理学领域从未使用过的基于实例的MIL方法。&lt;h4&gt;主要发现&lt;/h4&gt;通过这些广泛的实验，作者发现使用良好的SSL特征提取器，简单的基于实例的MIL方法，参数非常少，可以获得与复杂的、最先进的（SOTA）基于嵌入的MIL方法相似甚至更好的性能，并在BRACS和Camelyon16数据集上设定了新的SOTA结果。&lt;h4&gt;结论&lt;/h4&gt;简单基于实例的MIL方法由于更易于解释和向临床医生解释，因此建议在WSI中投入更多努力进行良好的SSL方法适配，而不是复杂的基于嵌入的MIL方法。&lt;h4&gt;翻译&lt;/h4&gt;Multiple Instance Learning (MIL) has emerged as the best solution for WholeSlide Image (WSI) classification. It consists of dividing each slide into patches, which are treated as a bag of instances labeled with a global label. MIL includes two main approaches: instance-based and embedding-based. In the former, each patch is classified independently, and then the patch scores are aggregated to predict the bag label. In the latter, bag classification is performed after aggregating patch embeddings. Even if instance-based methods are naturally more interpretable, embedding-based MILs have usually been preferred in the past due to their robustness to poor feature extractors. However, recently, the quality of feature embeddings has drastically increased using self-supervised learning (SSL). Nevertheless, many authors continue to endorse the superiority of embedding-based MIL. To investigate this further, we conduct 710 experiments across 4 datasets, comparing 10 MIL strategies, 6 self-supervised methods with 4 backbones, 4 foundation models, and various pathology-adapted techniques. Furthermore, we introduce 4 instance-based MIL methods never used before in the pathology domain. Through these extensive experiments, we show that with a good SSL feature extractor, simple instance-based MILs, with very few parameters, obtain similar or better performance than complex, state-of-the-art (SOTA) embedding-based MIL methods, setting new SOTA results on the BRACS and Camelyon16 datasets. Since simple instance-based MIL methods are naturally more interpretable and explainable to clinicians, our results suggest that more effort should be put into well-adapted SSL methods for WSI rather than into complex embedding-based MIL methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiple Instance Learning (MIL) has emerged as the best solution for WholeSlide Image (WSI) classification. It consists of dividing each slide intopatches, which are treated as a bag of instances labeled with a global label.MIL includes two main approaches: instance-based and embedding-based. In theformer, each patch is classified independently, and then the patch scores areaggregated to predict the bag label. In the latter, bag classification isperformed after aggregating patch embeddings. Even if instance-based methodsare naturally more interpretable, embedding-based MILs have usually beenpreferred in the past due to their robustness to poor feature extractors.However, recently, the quality of feature embeddings has drastically increasedusing self-supervised learning (SSL). Nevertheless, many authors continue toendorse the superiority of embedding-based MIL. To investigate this further, weconduct 710 experiments across 4 datasets, comparing 10 MIL strategies, 6self-supervised methods with 4 backbones, 4 foundation models, and variouspathology-adapted techniques. Furthermore, we introduce 4 instance-based MILmethods never used before in the pathology domain. Through these extensiveexperiments, we show that with a good SSL feature extractor, simpleinstance-based MILs, with very few parameters, obtain similar or betterperformance than complex, state-of-the-art (SOTA) embedding-based MIL methods,setting new SOTA results on the BRACS and Camelyon16 datasets. Since simpleinstance-based MIL methods are naturally more interpretable and explainable toclinicians, our results suggest that more effort should be put intowell-adapted SSL methods for WSI rather than into complex embedding-based MILmethods.</description>
      <author>example@mail.com (Ali Mammadov, Loic Le Folgoc, Julien Adam, Anne Buronfosse, Gilles Hayem, Guillaume Hocquet, Pietro Gori)</author>
      <guid isPermaLink="false">2505.01109v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>SA-GAT-SR: Self-Adaptable Graph Attention Networks with Symbolic Regression for high-fidelity material property prediction</title>
      <link>http://arxiv.org/abs/2505.00625v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SA-GAT-SR的新计算范式，它结合了图神经网络和符号回归的优势，以提高材料科学中的预测精度和可解释性。&lt;h4&gt;背景&lt;/h4&gt;深度学习，特别是图神经网络（GNNs），在材料科学中显示出巨大的实用价值，但复杂的模型往往缺乏物理可解释性。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合GNNs和符号回归的新框架，以实现材料属性的高通量预测，同时保持物理可解释性。&lt;h4&gt;方法&lt;/h4&gt;开发了一种自适应性图注意力网络（SA-GAT）和符号回归（SR）的集成框架，其中SA-GAT自动识别和调整注意力权重，SR模块将特征转化为简明的分析表达式。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在180维特征空间中筛选关键特征，同时保持O(n)的计算规模，实现了比传统SR方法23倍的速度提升，并揭示了量子力学意义上的关系。&lt;h4&gt;结论&lt;/h4&gt;SA-GAT-SR框架为计算材料科学提供了一种新方法，在预测精度和物理可解释性之间架起桥梁，为材料行为提供了有价值的物理见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，机器学习的进步展示了深度学习方法，尤其是图神经网络（GNNs）在材料科学中的巨大效用。这些方法已成为预测材料属性的高通量工具，为传统的第一性原理计算提供了令人信服的增强和替代方案。尽管社区主要关注开发越来越复杂和通用的模型以提高预测精度，但这些方法往往缺乏物理可解释性和对材料行为的洞察。在这里，我们引入了一种新的计算范式，即与符号回归集成的自适应性图注意力网络（SA-GAT-SR），它协同结合了GNNs的预测能力和符号回归的解释能力。我们的框架采用了一种自适应性编码算法，该算法自动识别和调整注意力权重，以便从庞大的180维特征空间中筛选关键特征，同时保持O(n)的计算规模。集成的SR模块随后将这些特征提炼成紧凑的分析表达式，这些表达式明确揭示了量子力学意义上的关系，比严重依赖第一性原理计算得出的特征作为输入的传统SR实现快23倍。这项工作在计算材料科学中提出了一种新框架，在预测精度和物理可解释性之间架起了桥梁，为材料行为提供了有价值的物理见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/MustBeOne/SA-GAT-SR&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in machine learning have demonstrated an enormous utility ofdeep learning approaches, particularly Graph Neural Networks (GNNs) formaterials science. These methods have emerged as powerful tools forhigh-throughput prediction of material properties, offering a compellingenhancement and alternative to traditional first-principles calculations. Whilethe community has predominantly focused on developing increasingly complex anduniversal models to enhance predictive accuracy, such approaches often lackphysical interpretability and insights into materials behavior. Here, weintroduce a novel computational paradigm, Self-Adaptable Graph AttentionNetworks integrated with Symbolic Regression (SA-GAT-SR), that synergisticallycombines the predictive capability of GNNs with the interpretative power ofsymbolic regression. Our framework employs a self-adaptable encoding algorithmthat automatically identifies and adjust attention weights so as to screencritical features from an expansive 180-dimensional feature space whilemaintaining O(n) computational scaling. The integrated SR module subsequentlydistills these features into compact analytical expressions that explicitlyreveal quantum-mechanically meaningful relationships, achieving 23 timesacceleration compared to conventional SR implementations that heavily rely onfirst principle calculations-derived features as input. This work suggests anew framework in computational materials science, bridging the gap betweenpredictive accuracy and physical interpretability, offering valuable physicalinsights into material behavior.</description>
      <author>example@mail.com (Liu Junchi, Tang Ying, Tretiak Sergei, Duan Wenhui, Zhou Liujiang)</author>
      <guid isPermaLink="false">2505.00625v2</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>TRAVELER: A Benchmark for Evaluating Temporal Reasoning across Vague, Implicit and Explicit References</title>
      <link>http://arxiv.org/abs/2505.01325v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 6 figures, submitted to Springer Nature Computer Science&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TRAVELER，一个用于评估模型处理时间参照能力的合成基准数据集，并探讨了不同类型时间参照对模型性能的影响。&lt;h4&gt;背景&lt;/h4&gt;在自然语言理解中，理解和解决时间参照是至关重要的，因为我们在日常交流中经常提到过去或未来。&lt;h4&gt;目的&lt;/h4&gt;为了弥补现有基准在系统处理时间参照能力上的系统性评估不足，本文提出了TRAVELER。&lt;h4&gt;方法&lt;/h4&gt;TRAVELER是一个基于问答范式的合成数据集，包含涉及时间参照的问题及其正确答案。它评估模型处理明确、隐含相对说话时间和模糊时间参照的能力。对于模糊时间参照，通过在Prolific上进行的问卷调查确定了真实答案。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果显示，尽管基准LLMs在处理少量事件和明确时间参照的问题时表现良好，但随着事件集长度的增加和时间参照的减少，性能明显下降。模糊问题类别在所有模型中表现最差。&lt;h4&gt;结论&lt;/h4&gt;TRAVELER基准可以用于评估不同类型时间参照对模型性能的影响，并提供了对模型处理复杂时间参照能力的深入了解。&lt;h4&gt;翻译&lt;/h4&gt;Understanding and resolving temporal references is essential in NaturalLanguage Understanding as we often refer to the past or future in dailycommunication. Although existing benchmarks address a system's ability toreason about and resolve temporal references, systematic evaluation of specifictemporal references remains limited. Towards closing this gap, we introduceTRAVELER, a novel synthetic benchmark dataset that follows a Question Answeringparadigm and consists of questions involving temporal references with thecorresponding correct answers. TRAVELER assesses models' abilities to resolveexplicit, implicit relative to speech time, and vague temporal references.Beyond investigating the performance of state-of-the-art LLMs depending on thetype of temporal reference, our benchmark also allows evaluation of performancein relation to the length of the set of events. For the category of vaguetemporal references, ground-truth answers were established via human surveys onProlific, following a procedure similar to the one from Kenneweg et al. Todemonstrate the benchmark's applicability, we evaluate four state-of-the-artLLMs using a question-answering task encompassing 3,300 questions. Our findingsshow that while the benchmarked LLMs can answer questions over event sets witha handful of events and explicit temporal references successfully, performanceclearly deteriorates with larger event set length and when temporal referencesget less explicit. Notably, the vague question category exhibits the lowestperformance across all models. The benchmark is publicly available at:https://gitlab.ub.uni-bielefeld.de/s.kenneweg/TRAVELER&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding and resolving temporal references is essential in NaturalLanguage Understanding as we often refer to the past or future in dailycommunication. Although existing benchmarks address a system's ability toreason about and resolve temporal references, systematic evaluation of specifictemporal references remains limited. Towards closing this gap, we introduceTRAVELER, a novel synthetic benchmark dataset that follows a Question Answeringparadigm and consists of questions involving temporal references with thecorresponding correct answers. TRAVELER assesses models' abilities to resolveexplicit, implicit relative to speech time, and vague temporal references.Beyond investigating the performance of state-of-the-art LLMs depending on thetype of temporal reference, our benchmark also allows evaluation of performancein relation to the length of the set of events. For the category of vaguetemporal references, ground-truth answers were established via human surveys onProlific, following a procedure similar to the one from Kenneweg et al. Todemonstrate the benchmark's applicability, we evaluate four state-of-the-artLLMs using a question-answering task encompassing 3,300 questions. Our findingsshow that while the benchmarked LLMs can answer questions over event sets witha handful of events and explicit temporal references successfully, performanceclearly deteriorates with larger event set length and when temporal referencesget less explicit. Notably, the vague question category exhibits the lowestperformance across all models.  The benchmark is publicly available at:https://gitlab.ub.uni-bielefeld.de/s.kenneweg/TRAVELER</description>
      <author>example@mail.com (Svenja Kenneweg, Jörg Deigmöller, Philipp Cimiano, Julian Eggert)</author>
      <guid isPermaLink="false">2505.01325v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>High Dynamic Range Novel View Synthesis with Single Exposure</title>
      <link>http://arxiv.org/abs/2505.01212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  It has been accepted by ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的HDR-NVS方法，旨在从低动态范围（LDR）图像中建立3D场景的HDR模型。&lt;h4&gt;背景&lt;/h4&gt;传统的HDR-NVS方法使用多曝光LDR图像来捕捉场景中的广泛亮度级别，但这种方法存在易受运动伪影影响、捕获和存储成本高等问题。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，本文首次提出单曝光HDR-NVS问题，并引入了一种名为Mono-HDR-3D的新方法，该方法通过两个专门模块实现，一个用于将LDR颜色转换为HDR颜色，另一个用于将HDR图像转换为LDR格式，从而实现闭环的无监督学习。&lt;h4&gt;方法&lt;/h4&gt;Mono-HDR-3D是一个元算法，可以无缝集成到现有的NVS模型中。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，Mono-HDR-3D在性能上显著优于之前的方法。&lt;h4&gt;结论&lt;/h4&gt;Mono-HDR-3D是一种有效的方法，可以用于从单曝光LDR图像中合成高质量的HDR图像，并将在未来发布源代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High Dynamic Range Novel View Synthesis (HDR-NVS) aims to establish a 3Dscene HDR model from Low Dynamic Range (LDR) imagery. Typically,multiple-exposure LDR images are employed to capture a wider range ofbrightness levels in a scene, as a single LDR image cannot represent both thebrightest and darkest regions simultaneously. While effective, thismultiple-exposure HDR-NVS approach has significant limitations, includingsusceptibility to motion artifacts (e.g., ghosting and blurring), high captureand storage costs. To overcome these challenges, we introduce, for the firsttime, the single-exposure HDR-NVS problem, where only single exposure LDRimages are available during training. We further introduce a novel approach,Mono-HDR-3D, featuring two dedicated modules formulated by the LDR imageformation principles, one for converting LDR colors to HDR counterparts, andthe other for transforming HDR images to LDR format so that unsupervisedlearning is enabled in a closed loop. Designed as a meta-algorithm, ourapproach can be seamlessly integrated with existing NVS models. Extensiveexperiments show that Mono-HDR-3D significantly outperforms previous methods.Source code will be released.</description>
      <author>example@mail.com (Kaixuan Zhang, Hu Wang, Minxian Li, Mingwu Ren, Mao Ye, Xiatian Zhu)</author>
      <guid isPermaLink="false">2505.01212v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Empowering Agentic Video Analytics Systems with Video Language Models</title>
      <link>http://arxiv.org/abs/2505.00254v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, AVAS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AVAS的基于视频语言模型（VLM）的系统，用于开放式的视频分析，解决了现有系统在处理超长视频内容时的挑战。&lt;h4&gt;背景&lt;/h4&gt;AI驱动的视频分析在多个领域变得至关重要，但现有系统通常局限于特定任务，限制了其在开放式分析场景中的适应性。&lt;h4&gt;目的&lt;/h4&gt;开发AVAS系统，以实现开放式的视频理解、推理和分析。&lt;h4&gt;方法&lt;/h4&gt;AVAS系统包含两个关键创新：(1) 构建事件知识图谱（EKGs）以高效索引长视频流；(2) 利用EKGs进行检索生成，以处理复杂和多样化的查询。&lt;h4&gt;主要发现&lt;/h4&gt;在公共基准测试LVBench和VideoMME-Long上，AVAS取得了最先进的性能，分别达到62.3%和64.1%的准确率，显著超过现有的VLM和视频检索增强生成（RAG）系统。在新的基准AVAS-100上，AVAS也取得了优异的性能，准确率达到75.8%。&lt;h4&gt;结论&lt;/h4&gt;AVAS系统在超长和开放式视频场景中的视频分析方面表现出色，为视频分析领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：AI驱动的视频分析在多个领域变得至关重要。然而，现有系统通常局限于特定任务，限制了其在开放式分析场景中的适应性。最近出现的视频语言模型（VLMs）作为颠覆性技术，为开放式的视频理解、推理和分析提供了巨大的潜力。尽管如此，它们有限的上下文窗口在处理超长视频内容时带来了挑战，这在现实世界应用中很常见。为了解决这个问题，我们引入了AVAS，这是一个由VLM驱动的系统，旨在进行开放式的、高级视频分析。AVAS包含两个关键创新：(1) 近实时构建事件知识图谱（EKGs）以高效索引长或连续视频流；(2) 利用EKGs进行检索生成，以处理复杂和多样化的查询。在公共基准测试LVBench和VideoMME-Long上的全面评估表明，AVAS实现了最先进的性能，分别达到62.3%和64.1%的准确率，显著优于现有的VLM和视频检索增强生成（RAG）系统。此外，为了评估超长和开放式视频场景中的视频分析，我们引入了一个新的基准，AVAS-100。该基准包含8个视频，每个视频的时长超过10小时，以及120对手动标注的、多样化的、复杂的问答对。在AVAS-100上，AVAS取得了顶级性能，准确率达到75.8%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AI-driven video analytics has become increasingly pivotal across diversedomains. However, existing systems are often constrained to specific,predefined tasks, limiting their adaptability in open-ended analyticalscenarios. The recent emergence of Video-Language Models (VLMs) astransformative technologies offers significant potential for enablingopen-ended video understanding, reasoning, and analytics. Nevertheless, theirlimited context windows present challenges when processing ultra-long videocontent, which is prevalent in real-world applications. To address this, weintroduce AVAS, a VLM-powered system designed for open-ended, advanced videoanalytics. AVAS incorporates two key innovations: (1) the near real-timeconstruction of Event Knowledge Graphs (EKGs) for efficient indexing of long orcontinuous video streams, and (2) an agentic retrieval-generation mechanismthat leverages EKGs to handle complex and diverse queries. Comprehensiveevaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate thatAVAS achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy,respectively, significantly surpassing existing VLM and videoRetrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate videoanalytics in ultra-long and open-world video scenarios, we introduce a newbenchmark, AVAS-100. This benchmark comprises 8 videos, each exceeding 10 hoursin duration, along with 120 manually annotated, diverse, and complexquestion-answer pairs. On AVAS-100, AVAS achieves top-tier performance with anaccuracy of 75.8%.</description>
      <author>example@mail.com (Yuxuan Yan, Shiqi Jiang, Ting Cao, Yifan Yang, Qianqian Yang, Yuanchao Shu, Yuqing Yang, Lili Qiu)</author>
      <guid isPermaLink="false">2505.00254v2</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Federated Adapter on Foundation Models: An Out-Of-Distribution Approach</title>
      <link>http://arxiv.org/abs/2505.01075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了FedOA，一种用于联邦学习框架中隐私保护模型微调的方法，以解决联邦基础模型（FedFM）中的分布外（OOD）泛化问题。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型在联邦学习中的广泛应用，FedFM作为一种隐私保护的方法应运而生。然而，FedFM面临的一个关键挑战是如何处理分布外泛化问题，即未见过的新任务或客户端可能表现出分布偏移，导致性能不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，本文旨在提出一种新的方法来增强FedFM中的OOD泛化能力。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种基于适配器的参数高效微调方法，并引入了基于特征距离正则化的个性化适配器，以对齐分布并保证每个客户端的OOD泛化。&lt;h4&gt;主要发现&lt;/h4&gt;理论上证明了传统的FedFM全局聚合模型本身具有OOD泛化能力，并且通过全局模型提供的信息进行正则化，可以增强个性化模型的OOD泛化，且在一般非凸设置下已证明收敛。&lt;h4&gt;结论&lt;/h4&gt;实证结果表明，所提出的方法在各种NLP任务上的基准数据集上有效。&lt;h4&gt;翻译&lt;/h4&gt;As foundation models gain prominence, Federated Foundation Models (FedFM) have emerged as a privacy-preserving approach to collaboratively fine-tune models in federated learning (FL) frameworks using distributed datasets across clients. A key challenge for FedFM, given the versatile nature of foundation models, is addressing out-of-distribution (OOD) generalization, where unseen tasks or clients may exhibit distribution shifts leading to suboptimal performance. Although numerous studies have explored OOD generalization in conventional FL, these methods are inadequate for FedFM due to the challenges posed by large parameter scales and increased data heterogeneity. To address these, we propose FedOA, which employs adapter-based parameter-efficient fine-tuning methods for efficacy and introduces personalized adapters with feature distance-based regularization to align distributions and guarantee OOD generalization for each client. Theoretically, we demonstrate that the conventional aggregated global model in FedFM inherently retains OOD generalization capabilities, and our proposed method enhances the personalized model's OOD generalization through regularization informed by the global model, with proven convergence under general non-convex settings. Empirically, the effectiveness of the proposed method is validated on benchmark datasets across various NLP tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As foundation models gain prominence, Federated Foundation Models (FedFM)have emerged as a privacy-preserving approach to collaboratively fine-tunemodels in federated learning (FL) frameworks using distributed datasets acrossclients. A key challenge for FedFM, given the versatile nature of foundationmodels, is addressing out-of-distribution (OOD) generalization, where unseentasks or clients may exhibit distribution shifts leading to suboptimalperformance. Although numerous studies have explored OOD generalization inconventional FL, these methods are inadequate for FedFM due to the challengesposed by large parameter scales and increased data heterogeneity. To addressthese, we propose FedOA, which employs adapter-based parameter-efficientfine-tuning methods for efficacy and introduces personalized adapters withfeature distance-based regularization to align distributions and guarantee OODgeneralization for each client. Theoretically, we demonstrate that theconventional aggregated global model in FedFM inherently retains OODgeneralization capabilities, and our proposed method enhances the personalizedmodel's OOD generalization through regularization informed by the global model,with proven convergence under general non-convex settings. Empirically, theeffectiveness of the proposed method is validated on benchmark datasets acrossvarious NLP tasks.</description>
      <author>example@mail.com (Yiyuan Yang, Guodong Long, Tianyi Zhou, Qinghua Lu, Shanshan Ye, Jing Jiang)</author>
      <guid isPermaLink="false">2505.01075v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Vocabulary-Free Fine-Grained Visual Recognition in the Age of Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2505.01064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  preprint; earlier version accepted at NeurIPS 2024 Workshop on  Adaptive Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NeaR的新方法，用于解决Vocabulary-Free Fine-grained Visual Recognition（VF-FGVR）问题，即在没有预先标签信息的情况下，从不受约束的输出空间中预测标签。&lt;h4&gt;背景&lt;/h4&gt;Fine-grained Visual Recognition（FGVR）在医学成像等领域由于隐私和标注成本问题，缺乏专家标注的数据集。VF-FGVR模型需要从不受约束的输出空间预测标签，而现有的Multimodal Large Language Models（MLLMs）查询成本高，推理时间长。&lt;h4&gt;目的&lt;/h4&gt;提出NeaR方法，以解决VF-FGVR中的成本和推理时间问题。&lt;h4&gt;方法&lt;/h4&gt;NeaR通过使用MLLM生成的标签微调下游CLIP模型，并从少量未标注训练集中构建弱监督数据集。&lt;h4&gt;主要发现&lt;/h4&gt;NeaR能够处理MLLM生成标签中的噪声、随机性和开放性，并建立了高效VF-FGVR的新基准。&lt;h4&gt;结论&lt;/h4&gt;NeaR是一种有效的VF-FGVR方法，能够降低成本和推理时间。&lt;h4&gt;翻译&lt;/h4&gt;Fine-grained Visual Recognition (FGVR) involves distinguishing between visually similar categories, which is inherently challenging due to subtle inter-class differences and the need for large, expert-annotated datasets. In domains like medical imaging, such curated datasets are unavailable due to issues like privacy concerns and high annotation costs. In such scenarios lacking labeled data, an FGVR model cannot rely on a predefined set of training labels, and hence has an unconstrained output space for predictions. We refer to this task as Vocabulary-Free FGVR (VF-FGVR), where a model must predict labels from an unconstrained output space without prior label information. While recent Multimodal Large Language Models (MLLMs) show potential for VF-FGVR, querying these models for each test input is impractical because of high costs and prohibitive inference times. To address these limitations, we introduce NeaRest-Neighbor Label Refinement (NeaR), a novel approach that fine-tunes a downstream CLIP model using labels generated by an MLLM. Our approach constructs a weakly supervised dataset from a small, unlabeled training set, leveraging MLLMs for label generation. NeaR is designed to handle the noise, stochasticity, and open-endedness inherent in labels generated by MLLMs, and establishes a new benchmark for efficient VF-FGVR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-grained Visual Recognition (FGVR) involves distinguishing betweenvisually similar categories, which is inherently challenging due to subtleinter-class differences and the need for large, expert-annotated datasets. Indomains like medical imaging, such curated datasets are unavailable due toissues like privacy concerns and high annotation costs. In such scenarioslacking labeled data, an FGVR model cannot rely on a predefined set of traininglabels, and hence has an unconstrained output space for predictions. We referto this task as Vocabulary-Free FGVR (VF-FGVR), where a model must predictlabels from an unconstrained output space without prior label information.While recent Multimodal Large Language Models (MLLMs) show potential forVF-FGVR, querying these models for each test input is impractical because ofhigh costs and prohibitive inference times. To address these limitations, weintroduce \textbf{Nea}rest-Neighbor Label \textbf{R}efinement (NeaR), a novelapproach that fine-tunes a downstream CLIP model using labels generated by anMLLM. Our approach constructs a weakly supervised dataset from a small,unlabeled training set, leveraging MLLMs for label generation. NeaR is designedto handle the noise, stochasticity, and open-endedness inherent in labelsgenerated by MLLMs, and establishes a new benchmark for efficient VF-FGVR.</description>
      <author>example@mail.com (Hari Chandana Kuchibhotla, Sai Srinivas Kancheti, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian)</author>
      <guid isPermaLink="false">2505.01064v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Fast and Low-Cost Genomic Foundation Models via Outlier Removal</title>
      <link>http://arxiv.org/abs/2505.00598v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  International Conference on Machine Learning (ICML) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GERM是一种基因组基础模型，具有强大的压缩性能和快速适应能力，旨在解决基因组建模中计算资源稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;基因组建模需要大量的计算资源，而现有的模型如DNABERT-2在适应性和鲁棒性方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;提出GERM模型，以改善基因组建模的效率和质量。&lt;h4&gt;方法&lt;/h4&gt;GERM通过消除异常值来增强低秩适应和后训练量化，使用受联想记忆模型启发的无异常值机制替换了传统的注意力层。同时，提出了GERM-T策略，利用小步持续学习在无异常值框架内，避免从头开始重新训练。&lt;h4&gt;主要发现&lt;/h4&gt;GERM在微调性能上比基线模型提高了37.98%，在量化上提高了64.34%，同时减少了平均峰度和最大无穷范数的百分比。&lt;h4&gt;结论&lt;/h4&gt;GERM在资源受限的环境中为基因组建模提供了一个实用的解决方案，并在性能上优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;为了解决基因组建模中计算资源稀缺的挑战，我们引入了GERM，这是一种具有强大压缩性能和快速适应能力的基因组基础模型。GERM通过消除阻碍低秩适应和后训练量化的异常值，改进了如DNABERT-2等模型，增强了效率和鲁棒性。我们用受联想记忆模型启发的无异常值机制替换了常规的注意力层。通过在预训练和微调过程中移除异常值，这种方法加速了适应过程，降低了计算成本，并在可接受的损失范围内增强了量化的鲁棒性。此外，我们还提出了GERM-T策略，它利用无异常值框架内的小步持续学习，利用原始检查点以避免从头开始重新训练。实证表明，GERM在微调性能上比基线模型提高了37.98%，在量化上提高了64.34%，同时平均峰度降低了92.14%，最大无穷范数降低了82.77%。与领先方法相比，GERM在性能上始终优于其他方法，为资源受限环境中的基因组建模提供了一个实用的解决方案。代码可在https://github.com/MAGICS-LAB/GERM上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/MAGICS-LAB/GERM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To address the challenge of scarce computational resources in genomicmodeling, we introduce GERM, a genomic foundation model with strong compressionperformance and fast adaptability. GERM improves upon models like DNABERT-2 byeliminating outliers that hinder low-rank adaptation and post-trainingquantization, enhancing both efficiency and robustness. We replace the vanillaattention layer with an outlier-free mechanism inspired by associative memorymodels. By removing outliers during both pre-training and fine-tuning, thisapproach accelerates adaptation, reduces computational costs, and enhancesquantization robustness within acceptable loss margins. Additionally, wepropose GERM-T, a strategy that employs small-step continual learning withinthe outlier-free framework, leveraging original checkpoints to avoid retrainingfrom scratch. Empirically, GERM improves fine-tuning performance by 37.98% andquantization by 64.34% over the baseline model. It also reduces averagekurtosis by 92.14% and maximum infinity norm by 82.77%. Compared to leadingmethods, GERM consistently delivers superior performance, offering a practicalsolution for genomic modeling in resource-constrained settings. Code isavailable at https://github.com/MAGICS-LAB/GERM.</description>
      <author>example@mail.com (Haozheng Luo, Chenghao Qiu, Maojiang Su, Zhihan Zhou, Zoe Mehta, Guo Ye, Jerry Yao-Chieh Hu, Han Liu)</author>
      <guid isPermaLink="false">2505.00598v2</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>ClearVision: Leveraging CycleGAN and SigLIP-2 for Robust All-Weather Classification in Traffic Camera Imagery</title>
      <link>http://arxiv.org/abs/2504.19684v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合CycleGAN域适应和对比学习的框架，以增强天气分类，特别是在低光夜间条件下的分类性能。&lt;h4&gt;背景&lt;/h4&gt;恶劣天气对交通安全构成挑战，需要从交通摄像头图像中进行稳健的实时天气检测。&lt;h4&gt;目的&lt;/h4&gt;提高夜间条件下天气分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用轻量级的SigLIP-2模型，并结合CycleGAN将夜间图像转换为类似白天的表示，同时保留天气信息。使用对比学习方法提高分类性能。&lt;h4&gt;主要发现&lt;/h4&gt;在Iowa Department of Transportation数据集上，CycleGAN辅助的EVA-02模型在三类天气条件（无降水、雨、雪）下的整体准确率达到96.55%，白天/夜间整体准确率达到96.55%，但存在显著的日夜差距。改进后的模型Vision-SigLIP-2 + Text-SigLIP-2 + CycleGAN + Contrastive在夜间场景中表现优异，达到最高夜间准确率85.90%，整体准确率达到93.35%，同时大幅减少了训练和推理时间。&lt;h4&gt;结论&lt;/h4&gt;该框架提供了一种可扩展、高效的解决方案，可以缩小日夜性能差距，利用现有摄像头基础设施进行全天候分类。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种结合CycleGAN域适应和高效对比学习的框架，以增强天气分类，特别是在低光夜间条件下的分类性能。背景是恶劣天气对交通安全构成挑战，需要从交通摄像头图像中进行稳健的实时天气检测。目的是提高夜间条件下天气分类的准确性。方法包括采用轻量级的SigLIP-2模型，并结合CycleGAN将夜间图像转换为类似白天的表示，同时保留天气信息。使用对比学习方法提高分类性能。主要发现是在Iowa Department of Transportation数据集上，CycleGAN辅助的EVA-02模型在三类天气条件（无降水、雨、雪）下的整体准确率达到96.55%，白天/夜间整体准确率达到96.55%，但存在显著的日夜差距。改进后的模型Vision-SigLIP-2 + Text-SigLIP-2 + CycleGAN + Contrastive在夜间场景中表现优异，达到最高夜间准确率85.90%，整体准确率达到93.35%，同时大幅减少了训练和推理时间。结论是该框架提供了一种可扩展、高效的解决方案，可以缩小日夜性能差距，利用现有摄像头基础设施进行全天候分类。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adverse weather conditions challenge safe transportation, necessitatingrobust real-time weather detection from traffic camera imagery. We propose anovel framework combining CycleGAN-based domain adaptation with efficientcontrastive learning to enhance weather classification, particularly inlow-light nighttime conditions. Our approach leverages the lightweight SigLIP-2model, which employs pairwise sigmoid loss to reduce computational demands,integrated with CycleGAN to transform nighttime images into day-likerepresentations while preserving weather cues. Evaluated on an Iowa Departmentof Transportation dataset, the baseline EVA-02 model with CLIP achieves aper-class overall accuracy of 96.55\% across three weather conditions (NoPrecipitation, Rain, Snow) and a day/night overall accuracy of 96.55\%, butshows a significant day-night gap (97.21\% day vs.\ 63.40\% night). WithCycleGAN, EVA-02 improves to 97.01\% per-class accuracy and 96.85\% day/nightaccuracy, boosting nighttime performance to 82.45\%. Our Vision-SigLIP-2 +Text-SigLIP-2 + CycleGAN + Contrastive configuration excels in nighttimescenarios, achieving the highest nighttime accuracy of 85.90\%, with 94.00\%per-class accuracy and 93.35\% day/night accuracy. This model reduces trainingtime by 89\% (from 6 hours to 40 minutes) and inference time by 80\% (from 15seconds to 3 seconds) compared to EVA-02. By narrowing the day-nightperformance gap from 33.81 to 8.90 percentage points, our framework provides ascalable, efficient solution for all-weather classification using existingcamera infrastructure.</description>
      <author>example@mail.com (Anush Lakshman Sivaraman, Kojo Adu-Gyamfi, Ibne Farabi Shihab, Anuj Sharma)</author>
      <guid isPermaLink="false">2504.19684v2</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Responsive DNN Adaptation for Video Analytics against Environment Shift via Hierarchical Mobile-Cloud Collaborations</title>
      <link>http://arxiv.org/abs/2505.00745v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Sensys 2025 final version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MOCHA的新型框架，用于优化移动视频分析系统中模型的适应性响应。&lt;h4&gt;背景&lt;/h4&gt;移动视频分析系统在部署过程中面临各种环境变化，对模型的适应性响应提出了更高的要求。&lt;h4&gt;目的&lt;/h4&gt;提高模型在环境变化时的适应性响应速度。&lt;h4&gt;方法&lt;/h4&gt;MOCHA通过移动设备和云资源之间的分层协作实现这一点，具体方法包括：在请求云模型检索和端到端重新训练之前，在设备上执行模型重用和快速微调；通过云基础模型分析的领域语义，将历史专家模型组织成结构化的分类法，以加速检索；维护设备上的专家模型缓存，以便频繁场景的本地模型重用，并主动从云模型数据库中预取模型权重。&lt;h4&gt;主要发现&lt;/h4&gt;在三个深度神经网络任务上进行的广泛评估表明，MOCHA在适应过程中提高了模型准确性，最多提高了6.8%，同时将响应延迟和重新训练时间分别减少了35.5倍和3.0倍。&lt;h4&gt;结论&lt;/h4&gt;MOCHA框架有效地提高了移动视频分析系统中模型的适应性响应速度，同时提高了模型准确性并减少了响应延迟和重新训练时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile video analysis systems often encounter various deploying environments,where environment shifts present greater demands for responsiveness inadaptations of deployed "expert DNN models". Existing model adaptationframeworks primarily operate in a cloud-centric way, exhibiting degradedperformance during adaptation and delayed reactions to environment shifts.Instead, this paper proposes MOCHA, a novel framework optimizing theresponsiveness of continuous model adaptation through hierarchicalcollaborations between mobile and cloud resources. Specifically, MOCHA (1)reduces adaptation response delays by performing on-device model reuse and fastfine-tuning before requesting cloud model retrieval and end-to-end retraining;(2) accelerates history expert model retrieval by organizing them into astructured taxonomy utilizing domain semantics analyzed by a cloud foundationmodel as indices; (3) enables efficient local model reuse by maintainingonboard expert model caches for frequent scenes, which proactively prefetchmodel weights from the cloud model database. Extensive evaluations withreal-world videos on three DNN tasks show MOCHA improves the model accuracyduring adaptation by up to 6.8% while saving the response delay and retrainingtime by up to 35.5x and 3.0x respectively.</description>
      <author>example@mail.com (Maozhe Zhao, Shengzhong Liu, Fan Wu, Guihai Chen)</author>
      <guid isPermaLink="false">2505.00745v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>MoSAM: Motion-Guided Segment Anything Model with Spatial-Temporal Memory Selection</title>
      <link>http://arxiv.org/abs/2505.00739v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了MoSAM，一种结合运动引导提示和时空记忆选择机制的对象分割模型，用于解决Segment Anything Model 2（SAM2）在视频分割中存在的长期跟踪能力和记忆准确性问题。&lt;h4&gt;背景&lt;/h4&gt;SAM2在交互式对象分割方面表现出色，但其基于过去六帧的掩码记忆进行分割的方式存在两个主要挑战：无法处理视频中的对象消失和遮挡，以及缺乏运动信息导致的长距离跟踪限制。&lt;h4&gt;目的&lt;/h4&gt;提出MoSAM模型，旨在解决SAM2在视频分割中的这两个挑战，提高模型在跟踪和记忆准确性方面的性能。&lt;h4&gt;方法&lt;/h4&gt;MoSAM模型采用了两种关键策略：运动引导提示（MGP）和时空记忆选择（ST-MS）机制。MGP通过多种方式表示物体运动，并引导模型关注运动方向；ST-MS机制动态识别可能包含准确分割的帧，从而提高记忆的可靠性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MoSAM在视频对象分割和视频实例分割的多个基准测试中取得了优于其他竞争者的最新水平的结果。&lt;h4&gt;结论&lt;/h4&gt;MoSAM模型通过引入运动引导和时空记忆选择机制，有效提高了SAM2在视频分割任务中的性能，尤其是在长期跟踪和记忆准确性方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent Segment Anything Model 2 (SAM2) has demonstrated exceptionalcapabilities in interactive object segmentation for both images and videos.However, as a foundational model on interactive segmentation, SAM2 performssegmentation directly based on mask memory from the past six frames, leading totwo significant challenges. Firstly, during inference in videos, objects maydisappear since SAM2 relies solely on memory without accounting for objectmotion information, which limits its long-range object tracking capabilities.Secondly, its memory is constructed from fixed past frames, making itsusceptible to challenges associated with object disappearance or occlusion,due to potentially inaccurate segmentation results in memory. To address theseproblems, we present MoSAM, incorporating two key strategies to integrateobject motion cues into the model and establish more reliable feature memory.Firstly, we propose Motion-Guided Prompting (MGP), which represents the objectmotion in both sparse and dense manners, then injects them into SAM2 through aset of motion-guided prompts. MGP enables the model to adjust its focus towardsthe direction of motion, thereby enhancing the object tracking capabilities.Furthermore, acknowledging that past segmentation results may be inaccurate, wedevise a Spatial-Temporal Memory Selection (ST-MS) mechanism that dynamicallyidentifies frames likely to contain accurate segmentation in both pixel- andframe-level. By eliminating potentially inaccurate mask predictions frommemory, we can leverage more reliable memory features to exploit similarregions for improving segmentation results. Extensive experiments on variousbenchmarks of video object segmentation and video instance segmentationdemonstrate that our MoSAM achieves state-of-the-art results compared to othercompetitors.</description>
      <author>example@mail.com (Qiushi Yang, Yuan Yao, Miaomiao Cui, Liefeng Bo)</author>
      <guid isPermaLink="false">2505.00739v1</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>RIS Optimization Algorithms for Urban Wireless Scenarios in Sionna RT</title>
      <link>http://arxiv.org/abs/2501.05817v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in IEEE VTC2025-Spring, Copyright IEEE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了可重构智能表面（RIS）优化算法在基于射线追踪（RT）模拟的城市数字孪生环境中的性能，并通过实际实验强调了在接近真实环境中的算法验证的重要性。&lt;h4&gt;背景&lt;/h4&gt;研究背景为城市数字孪生环境中的RIS优化算法。&lt;h4&gt;目的&lt;/h4&gt;目的是评估RIS优化算法在不同部署条件下的性能。&lt;h4&gt;方法&lt;/h4&gt;方法包括在Sionna的RT模拟中实现和基准测试基于信道估计的额外RIS优化算法，并生成RIS辅助通信系统的覆盖图。&lt;h4&gt;主要发现&lt;/h4&gt;主要发现是，在接近真实环境的模拟中验证算法的必要性，因为测量设置中的微小变化可能会显著影响性能。&lt;h4&gt;结论&lt;/h4&gt;结论是，RIS优化算法的性能在接近真实环境的模拟中得到了验证。&lt;h4&gt;翻译&lt;/h4&gt;This paper evaluates the performance of reconfigurable intelligent surface (RIS) optimization algorithms, which utilize channel estimation methods, in raytracing (RT) simulations within urban digital twin environments. Beyond Sionna's native capabilities, we implement and benchmark additional RIS optimization algorithms based on channel estimation, enabling an evaluation of RIS strategies under various deployment conditions. Coverage maps for RIS-assisted communication systems are generated through the integration of Sionna's RT simulations. Moreover, real-world experimentation underscores the necessity of validating algorithms in near-realistic simulation environments, as minor variations in measurement setups can significantly affect performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper evaluates the performance of reconfigurable intelligent surface(RIS) optimization algorithms, which utilize channel estimation methods, in raytracing (RT) simulations within urban digital twin environments. BeyondSionna's native capabilities, we implement and benchmark additional RISoptimization algorithms based on channel estimation, enabling an evaluation ofRIS strategies under various deployment conditions. Coverage maps forRIS-assisted communication systems are generated through the integration ofSionna's RT simulations. Moreover, real-world experimentation underscores thenecessity of validating algorithms in near-realistic simulation environments,as minor variations in measurement setups can significantly affect performance.</description>
      <author>example@mail.com (Ahmet Esad Güneşer, Berkay Şekeroğlu, Sefa Kayraklık, Erhan Karakoca, İbrahim Hökelek, Sultan Aldirmaz-Colak, Ali Görçin)</author>
      <guid isPermaLink="false">2501.05817v2</guid>
      <pubDate>Mon, 05 May 2025 14:09:37 +0800</pubDate>
    </item>
    <item>
      <title>Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction</title>
      <link>http://arxiv.org/abs/2505.00237v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE RA-L&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于在动态和不确定环境中安全高效控制移动机器人的集成方法。&lt;h4&gt;背景&lt;/h4&gt;该方法由两个关键步骤组成，一个是一步式多模态运动预测，用于预测动态障碍物的运动，另一个是模型预测控制，将这些预测纳入运动规划过程。&lt;h4&gt;目的&lt;/h4&gt;该方法旨在使移动机器人在动态环境中有效导航。&lt;h4&gt;方法&lt;/h4&gt;运动预测由一个基于能量的神经网络驱动，在单次操作中生成高分辨率、多步预测。预测结果被进一步用于创建几何形状，作为数学约束。预测的障碍物通过非监督方式根据邻近性分组，以改进性能和效率。整体无碰撞导航由针对主动动态障碍物避免的特定设计的模型预测控制处理。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在代表典型仓库设置的多种场景中对各种情况进行了性能评估。结果显示，该方法优于其他现有的动态障碍物避免方法。&lt;h4&gt;结论&lt;/h4&gt;该集成方法使移动机器人在动态环境中有效导航，并在实际应用中显示出优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an integrated approach for the safe and efficient controlof mobile robots in dynamic and uncertain environments. The approach consistsof two key steps: one-shot multimodal motion prediction to anticipate motionsof dynamic obstacles and model predictive control to incorporate thesepredictions into the motion planning process. Motion prediction is driven by anenergy-based neural network that generates high-resolution, multi-steppredictions in a single operation. The prediction outcomes are further utilizedto create geometric shapes formulated as mathematical constraints. Instead oftreating each dynamic obstacle individually, predicted obstacles are grouped byproximity in an unsupervised way to improve performance and efficiency. Theoverall collision-free navigation is handled by model predictive control with aspecific design for proactive dynamic obstacle avoidance. The proposed approachallows mobile robots to navigate effectively in dynamic environments. Itsperformance is accessed across various scenarios that represent typicalwarehouse settings. The results demonstrate that the proposed approachoutperforms other existing dynamic obstacle avoidance methods.</description>
      <author>example@mail.com (Ze Zhang, Georg Hess, Junjie Hu, Emmanuel Dean, Lennart Svensson, Knut Åkesson)</author>
      <guid isPermaLink="false">2505.00237v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:44 +0800</pubDate>
    </item>
  <item>
      <title>Empowering Agentic Video Analytics Systems with Video Language Models</title>
      <link>http://arxiv.org/abs/2505.00254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了基于AI的视频分析技术，特别是在开放性分析场景中的重要性以及存在的问题，并提出了一种名为AVA的系统，用于解决超长视频内容处理的挑战。&lt;h4&gt;背景&lt;/h4&gt;AI驱动的视频分析在多个领域变得至关重要，但现有系统通常受限于特定任务，限制了其在开放性分析场景中的适应性。&lt;h4&gt;目的&lt;/h4&gt;开发一个名为AVA的系统，旨在实现开放性、高级视频分析，解决超长视频内容处理的挑战。&lt;h4&gt;方法&lt;/h4&gt;AVA系统包括两个关键创新：(1) 实时构建事件知识图谱（EKGs）以高效索引长视频流，(2) 利用EKGs的智能检索-生成机制处理复杂和多样化的查询。&lt;h4&gt;主要发现&lt;/h4&gt;在公共基准测试LVBench和VideoMME-Long上，AVA系统取得了最先进的性能，分别达到62.3%和64.1%的准确率，显著优于现有的VLM和视频检索增强生成（RAG）系统。此外，AVA系统在新的基准测试AVA-100上也表现出色，该基准测试包含超过10小时的视频和120个复杂的问题-答案对，准确率达到75.8%。&lt;h4&gt;结论&lt;/h4&gt;AVA系统为超长和开放世界视频场景的视频分析提供了有效的解决方案，并在相关基准测试中取得了优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AI-driven video analytics has become increasingly pivotal across diversedomains. However, existing systems are often constrained to specific,predefined tasks, limiting their adaptability in open-ended analyticalscenarios. The recent emergence of Video-Language Models (VLMs) astransformative technologies offers significant potential for enablingopen-ended video understanding, reasoning, and analytics. Nevertheless, theirlimited context windows present challenges when processing ultra-long videocontent, which is prevalent in real-world applications. To address this, weintroduce AVA, a VLM-powered system designed for open-ended, advanced videoanalytics. AVA incorporates two key innovations: (1) the near real-timeconstruction of Event Knowledge Graphs (EKGs) for efficient indexing of long orcontinuous video streams, and (2) an agentic retrieval-generation mechanismthat leverages EKGs to handle complex and diverse queries. Comprehensiveevaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate thatAVA achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy,respectively, significantly surpassing existing VLM and videoRetrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate videoanalytics in ultra-long and open-world video scenarios, we introduce a newbenchmark, AVA-100. This benchmark comprises 8 videos, each exceeding 10 hoursin duration, along with 120 manually annotated, diverse, and complexquestion-answer pairs. On AVA-100, AVA achieves top-tier performance with anaccuracy of 75.8%.</description>
      <author>example@mail.com (Yuxuan Yan, Shiqi Jiang, Ting Cao, Yifan Yang, Qianqian Yang, Yuanchao Shu, Yuqing Yang, Lili Qiu)</author>
      <guid isPermaLink="false">2505.00254v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:44 +0800</pubDate>
    </item>
    <item>
      <title>V3LMA: Visual 3D-enhanced Language Model for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2505.00156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为V3LMA的新方法，通过结合大型语言模型（LLMs）和大型视觉语言模型（LVLMs）来增强3D场景理解，以提高自动驾驶系统在复杂交通场景中的情境意识和决策能力。&lt;h4&gt;背景&lt;/h4&gt;LVLMs在理解与分析不同领域的视觉场景方面表现出强大的能力，但在自动驾驶领域，它们对3D环境的理解有限，限制了其在动态环境中实现全面安全理解的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出V3LMA方法，旨在通过整合LLMs和LVLMs来提升3D场景理解能力，以实现更安全的自动驾驶。&lt;h4&gt;方法&lt;/h4&gt;V3LMA利用从对象检测和视频输入生成的文本描述，通过一个专门的预处理流程提取3D对象数据，从而在不需微调的情况下显著提升性能。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在LingoQA基准测试中取得了0.56的分数，证明了其在复杂交通场景中的情境意识和决策能力得到了提升。&lt;h4&gt;结论&lt;/h4&gt;通过探索不同的融合策略和标记组合，V3LMA有望进一步推进对交通场景的解释，从而最终实现更安全的自动驾驶系统。&lt;h4&gt;翻译&lt;/h4&gt;Large Vision Language Models (LVLMs) have shown strong capabilities in understanding and analyzing visual scenes across various domains. However, in the context of autonomous driving, their limited comprehension of 3D environments restricts their effectiveness in achieving a complete and safe understanding of dynamic surroundings. To address this, we introduce V3LMA, a novel approach that enhances 3D scene understanding by integrating Large Language Models (LLMs) with LVLMs. V3LMA leverages textual descriptions generated from object detections and video inputs, significantly boosting performance without requiring fine-tuning. Through a dedicated preprocessing pipeline that extracts 3D object data, our method improves situational awareness and decision-making in complex traffic scenarios, achieving a score of 0.56 on the LingoQA benchmark. We further explore different fusion strategies and token combinations with the goal of advancing the interpretation of traffic scenes, ultimately enabling safer autonomous driving systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Vision Language Models (LVLMs) have shown strong capabilities inunderstanding and analyzing visual scenes across various domains. However, inthe context of autonomous driving, their limited comprehension of 3Denvironments restricts their effectiveness in achieving a complete and safeunderstanding of dynamic surroundings. To address this, we introduce V3LMA, anovel approach that enhances 3D scene understanding by integrating LargeLanguage Models (LLMs) with LVLMs. V3LMA leverages textual descriptionsgenerated from object detections and video inputs, significantly boostingperformance without requiring fine-tuning. Through a dedicated preprocessingpipeline that extracts 3D object data, our method improves situationalawareness and decision-making in complex traffic scenarios, achieving a scoreof 0.56 on the LingoQA benchmark. We further explore different fusionstrategies and token combinations with the goal of advancing the interpretationof traffic scenes, ultimately enabling safer autonomous driving systems.</description>
      <author>example@mail.com (Jannik Lübberstedt, Esteban Rivera, Nico Uhlemann, Markus Lienkamp)</author>
      <guid isPermaLink="false">2505.00156v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:44 +0800</pubDate>
    </item>
    <item>
      <title>Synthesizing and Identifying Noise Levels in Autonomous Vehicle Camera Radar Datasets</title>
      <link>http://arxiv.org/abs/2505.00584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究自动驾驶中的目标检测和跟踪，提出了一种针对相机雷达自动驾驶数据集的合成数据增强方法，以增强检测和跟踪管道的鲁棒性，并评估了一种轻量级噪声识别神经网络的效果。&lt;h4&gt;背景&lt;/h4&gt;过去几十年中，使用神经网络在各种数据集上进行目标检测取得了有希望的结果，但大多数方法关注性能指标，而较少关注提高检测和跟踪管道的鲁棒性，尤其是针对传感器故障。&lt;h4&gt;目的&lt;/h4&gt;通过创建一个逼真的合成数据增强管道，模拟传感器故障和数据退化，提高自动驾驶车辆中目标检测和跟踪的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;开发了一个针对相机雷达自动驾驶数据集的合成数据增强管道，并训练了一个轻量级噪声识别神经网络，在增强的数据集上进行训练和测试。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的轻量级噪声识别神经网络在增强的数据集上达到了54.4%的整体识别准确率，覆盖了11个类别，共包含10086张图像和2145个雷达点云。&lt;h4&gt;结论&lt;/h4&gt;该方法提高了目标检测和跟踪的鲁棒性，为自动驾驶系统中的传感器故障处理提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：检测和跟踪对象是任何自主导航方法的关键组成部分。在过去几十年中，使用神经网络在各种数据集上进行目标检测取得了有希望的结果。虽然许多方法关注性能指标，但很少有项目关注提高这些检测和跟踪管道的鲁棒性，特别是针对传感器故障。在本文中，我们试图通过为相机雷达自动驾驶数据集创建一个逼真的合成数据增强管道来解决这个问题。我们的目标是准确地模拟传感器故障和由于现实世界的干扰而导致的数据退化。我们还展示了在增强的数据集上训练和测试的基线轻量级噪声识别神经网络的结果，在11个类别中，10086张图像和2145个雷达点云上达到了54.4%的整体识别准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting and tracking objects is a crucial component of any autonomousnavigation method. For the past decades, object detection has yielded promisingresults using neural networks on various datasets. While many methods focus onperformance metrics, few projects focus on improving the robustness of thesedetection and tracking pipelines, notably to sensor failures. In this paper weattempt to address this issue by creating a realistic synthetic dataaugmentation pipeline for camera-radar Autonomous Vehicle (AV) datasets. Ourgoal is to accurately simulate sensor failures and data deterioration due toreal-world interferences. We also present our results of a baseline lightweightNoise Recognition neural network trained and tested on our augmented dataset,reaching an overall recognition accuracy of 54.4\% on 11 categories across10086 images and 2145 radar point-clouds.</description>
      <author>example@mail.com (Mathis Morales, Golnaz Habibi)</author>
      <guid isPermaLink="false">2505.00584v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:44 +0800</pubDate>
    </item>
    <item>
      <title>HeAL3D: Heuristical-enhanced Active Learning for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2505.00507v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HeAL的主动学习方法，用于3D目标检测中的样本选择，通过结合启发式特征和定位与分类来提高模型的训练效果。&lt;h4&gt;背景&lt;/h4&gt;主动学习在自动驾驶模型训练的样本选择方面已证明是相关的方法。3D目标检测在未控制场景下的样本选择具有挑战性，当前方法主要关注样本选择问题的理论方面，而忽略了从大量文献和应用中获得的实用见解。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合启发式特征的方法，用于3D目标检测的样本选择，以提高模型的训练效果。&lt;h4&gt;方法&lt;/h4&gt;引入HeAL方法，该方法集成启发式特征如物体距离和点数量来估计不确定性，增强所选样本对检测模型训练的有用性。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI数据集上的定量评估表明，HeAL在mAP（平均精度）方面与现有最佳方法具有竞争力，并且只需24%的样本就能达到与全监督基线相同的mAP。&lt;h4&gt;结论&lt;/h4&gt;HeAL方法能够有效地提高3D目标检测模型的性能，并且相较于传统方法在样本利用率上有了显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Active Learning has proved to be a relevant approach to perform sampleselection for training models for Autonomous Driving. Particularly, previousworks on active learning for 3D object detection have shown that selection ofsamples in uncontrolled scenarios is challenging. Furthermore, currentapproaches focus exclusively on the theoretical aspects of the sample selectionproblem but neglect the practical insights that can be obtained from theextensive literature and application of 3D detection models. In this paper, weintroduce HeAL (Heuristical-enhanced Active Learning for 3D Object Detection)which integrates those heuristical features together with Localization andClassification to deliver the most contributing samples to the model'straining. In contrast to previous works, our approach integrates heuristicalfeatures such as object distance and point-quantity to estimate theuncertainty, which enhance the usefulness of selected samples to traindetection models. Our quantitative evaluation on KITTI shows that HeAL presentscompetitive mAP with respect to the State-of-the-Art, and achieves the same mAPas the full-supervised baseline with only 24% of the samples.</description>
      <author>example@mail.com (Esteban Rivera, Surya Prabhakaran, Markus Lienkamp)</author>
      <guid isPermaLink="false">2505.00507v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:44 +0800</pubDate>
    </item>
    <item>
      <title>Brain Foundation Models with Hypergraph Dynamic Adapter for Brain Disease Analysis</title>
      <link>http://arxiv.org/abs/2505.00627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAM-Brain3D的脑部特定基础模型和Hypergraph Dynamic Adapter（HyDA）适配器，用于脑部疾病的分割和分类任务，通过多模态、多尺度动态建模提供了一种新的脑部疾病分析方法。&lt;h4&gt;背景&lt;/h4&gt;脑部疾病如阿尔茨海默病和脑瘤因其复杂性和社会影响而带来巨大挑战。现有的脑部基础模型在任务和数据同质性、泛化能力以及适应不同临床任务方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的脑部疾病分析范式，通过改进脑部基础模型和适配器，提高脑部疾病分割和分类任务的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 设计了SAM-Brain3D，一个在超过66,000个脑部图像-标签对上训练的脑部特定基础模型，覆盖14种MRI亚模态。2. 开发了Hypergraph Dynamic Adapter（HyDA），一个轻量级的适配器，用于高效且有效地进行下游适应。&lt;h4&gt;主要发现&lt;/h4&gt;SAM-Brain3D能够捕捉详细的脑部解剖和模态先验知识，用于分割各种脑部目标和更广泛的下游任务。HyDA利用超图融合互补的多模态数据，并动态生成针对患者的卷积核，以实现多尺度特征融合和个性化适应。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法在广泛的脑部疾病分割和分类任务中优于现有最先进的方法，为脑部疾病分析提供了一种新的范式。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Brain diseases, such as Alzheimer's disease and brain tumors, present profound challenges due to their complexity and societal impact. Recent advancements in brain foundation models have shown significant promise in addressing a range of brain-related tasks. However, current brain foundation models are limited by task and data homogeneity, restricted generalization beyond segmentation or classification, and inefficient adaptation to diverse clinical tasks. In this work, we propose SAM-Brain3D, a brain-specific foundation model trained on over 66,000 brain image-label pairs across 14 MRI sub-modalities, and Hypergraph Dynamic Adapter (HyDA), a lightweight adapter for efficient and effective downstream adaptation. SAM-Brain3D captures detailed brain-specific anatomical and modality priors for segmenting diverse brain targets and broader downstream tasks. HyDA leverages hypergraphs to fuse complementary multi-modal data and dynamically generate patient-specific convolutional kernels for multi-scale feature fusion and personalized patient-wise adaptation. Together, our framework excels across a broad spectrum of brain disease segmentation and classification tasks. Extensive experiments demonstrate that our method consistently outperforms existing state-of-the-art approaches, offering a new paradigm for brain disease analysis through multi-modal, multi-scale, and dynamic foundation modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain diseases, such as Alzheimer's disease and brain tumors, presentprofound challenges due to their complexity and societal impact. Recentadvancements in brain foundation models have shown significant promise inaddressing a range of brain-related tasks. However, current brain foundationmodels are limited by task and data homogeneity, restricted generalizationbeyond segmentation or classification, and inefficient adaptation to diverseclinical tasks. In this work, we propose SAM-Brain3D, a brain-specificfoundation model trained on over 66,000 brain image-label pairs across 14 MRIsub-modalities, and Hypergraph Dynamic Adapter (HyDA), a lightweight adapterfor efficient and effective downstream adaptation. SAM-Brain3D capturesdetailed brain-specific anatomical and modality priors for segmenting diversebrain targets and broader downstream tasks. HyDA leverages hypergraphs to fusecomplementary multi-modal data and dynamically generate patient-specificconvolutional kernels for multi-scale feature fusion and personalizedpatient-wise adaptation. Together, our framework excels across a broad spectrumof brain disease segmentation and classification tasks. Extensive experimentsdemonstrate that our method consistently outperforms existing state-of-the-artapproaches, offering a new paradigm for brain disease analysis throughmulti-modal, multi-scale, and dynamic foundation modeling.</description>
      <author>example@mail.com (Zhongying Deng, Haoyu Wang, Ziyan Huang, Lipei Zhang, Angelica I. Aviles-Rivero, Chaoyu Liu, Junjun He, Zoe Kourtzi, Carola-Bibiane Schönlieb)</author>
      <guid isPermaLink="false">2505.00627v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:44 +0800</pubDate>
    </item>
    <item>
      <title>OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery and Survival Stratification</title>
      <link>http://arxiv.org/abs/2505.00650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code available at: https://github.com/Atahanka/OmicsCL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了OmicsCL，一种模块化的对比学习框架，用于从多组学数据中无监督地学习疾病亚型，以推进个性化医学。&lt;h4&gt;背景&lt;/h4&gt;无监督地从多组学数据中学习疾病亚型为个性化医学提供了巨大的机会。&lt;h4&gt;目的&lt;/h4&gt;开发OmicsCL，一个能够联合嵌入异质组学模态（如基因表达、DNA甲基化和miRNA表达）到统一潜在空间的对比学习框架。&lt;h4&gt;方法&lt;/h4&gt;OmicsCL包含一个生存感知的对比损失，该损失鼓励模型学习与生存相关模式对齐的表示，而不依赖于标记的输出。该方法在TCGA BRCA数据集上进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;OmicsCL揭示了具有临床意义的聚类，并在患者生存方面实现了强大的无监督一致性。该框架在超参数配置方面表现出鲁棒性，并且可以调整以优先考虑亚型一致性或生存分层。消融研究表明，整合生存感知损失显著增强了学习嵌入的预测能力。&lt;h4&gt;结论&lt;/h4&gt;这些结果突出了对比目标在从高维、异质组学数据中揭示生物洞察力方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised learning of disease subtypes from multi-omics data presents asignificant opportunity for advancing personalized medicine. We introduceOmicsCL, a modular contrastive learning framework that jointly embedsheterogeneous omics modalities-such as gene expression, DNA methylation, andmiRNA expression-into a unified latent space. Our method incorporates asurvival-aware contrastive loss that encourages the model to learnrepresentations aligned with survival-related patterns, without relying onlabeled outcomes. Evaluated on the TCGA BRCA dataset, OmicsCL uncoversclinically meaningful clusters and achieves strong unsupervised concordancewith patient survival. The framework demonstrates robustness acrosshyperparameter configurations and can be tuned to prioritize either subtypecoherence or survival stratification. Ablation studies confirm that integratingsurvival-aware loss significantly enhances the predictive power of learnedembeddings. These results highlight the promise of contrastive objectives forbiological insight discovery in high-dimensional, heterogeneous omics data.</description>
      <author>example@mail.com (Atahan Karagoz)</author>
      <guid isPermaLink="false">2505.00650v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:44 +0800</pubDate>
    </item>
    <item>
      <title>SA-GAT-SR: Self-Adaptable Graph Attention Networks with Symbolic Regression for high-fidelity material property prediction</title>
      <link>http://arxiv.org/abs/2505.00625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的计算材料科学框架，结合了图神经网络（GNNs）的预测能力和符号回归（SR）的解释能力，以实现材料性质的高通量预测。&lt;h4&gt;背景&lt;/h4&gt;深度学习，尤其是图神经网络（GNNs），在材料科学中显示出巨大的效用，特别是在材料性质的高通量预测方面。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的计算范式，Self-Adaptable Graph Attention Networks integrated with Symbolic Regression (SA-GAT-SR)，以增强预测准确性并提高物理可解释性。&lt;h4&gt;方法&lt;/h4&gt;该方法使用自适应性编码算法来自动识别和调整注意力权重，以从180维特征空间中筛选关键特征，同时保持O(n)的计算规模。符号回归模块随后将这些特征提炼成紧凑的分析表达式，揭示量子力学上有意义的关联。&lt;h4&gt;主要发现&lt;/h4&gt;与依赖第一性原理计算特征的传统符号回归实现相比，该框架实现了23倍的加速，并提供了对材料行为的宝贵物理见解。&lt;h4&gt;结论&lt;/h4&gt;SA-GAT-SR框架在计算材料科学中提供了一个新的框架，弥合了预测准确性和物理可解释性之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in machine learning have demonstrated an enormous utility of deep learning approaches, particularly Graph Neural Networks (GNNs) for materials science. These methods have emerged as powerful tools for high-throughput prediction of material properties, offering a compelling enhancement and alternative to traditional first-principles calculations. While the community has predominantly focused on developing increasingly complex and universal models to enhance predictive accuracy, such approaches often lack physical interpretability and insights into materials behavior. Here, we introduce a novel computational paradigm, Self-Adaptable Graph Attention Networks integrated with Symbolic Regression (SA-GAT-SR), that synergistically combines the predictive capability of GNNs with the interpretative power of symbolic regression. Our framework employs a self-adaptable encoding algorithm that automatically identifies and adjust attention weights so as to screen critical features from an expansive 180-dimensional feature space while maintaining O(n) computational scaling. The integrated SR module subsequently distills these features into compact analytical expressions that explicitly reveal quantum-mechanically meaningful relationships, achieving 23 times acceleration compared to conventional SR implementations that heavily rely on first principle calculations-derived features as input. This work suggests a new framework in computational materials science, bridging the gap between predictive accuracy and physical interpretability, offering valuable physical insights into material behavior.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/MustBeOne/SA-GAT-SR&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in machine learning have demonstrated an enormous utility ofdeep learning approaches, particularly Graph Neural Networks (GNNs) formaterials science. These methods have emerged as powerful tools forhigh-throughput prediction of material properties, offering a compellingenhancement and alternative to traditional first-principles calculations. Whilethe community has predominantly focused on developing increasingly complex anduniversal models to enhance predictive accuracy, such approaches often lackphysical interpretability and insights into materials behavior. Here, weintroduce a novel computational paradigm, Self-Adaptable Graph AttentionNetworks integrated with Symbolic Regression (SA-GAT-SR), that synergisticallycombines the predictive capability of GNNs with the interpretative power ofsymbolic regression. Our framework employs a self-adaptable encoding algorithmthat automatically identifies and adjust attention weights so as to screencritical features from an expansive 180-dimensional feature space whilemaintaining O(n) computational scaling. The integrated SR module subsequentlydistills these features into compact analytical expressions that explicitlyreveal quantum-mechanically meaningful relationships, achieving 23 timesacceleration compared to conventional SR implementations that heavily rely onfirst principle calculations-derived features as input. This work suggests anew framework in computational materials science, bridging the gap betweenpredictive accuracy and physical interpretability, offering valuable physicalinsights into material behavior.</description>
      <author>example@mail.com (Liu Junchi, Tang Ying, Tretiak Sergei, Duan Wenhui, Zhou Liujiang)</author>
      <guid isPermaLink="false">2505.00625v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>On the Mechanistic Interpretability of Neural Networks for Causality in Bio-statistics</title>
      <link>http://arxiv.org/abs/2505.00555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在生物统计学因果推断的背景下，将机制可解释性技术应用于神经网络的方法。&lt;h4&gt;背景&lt;/h4&gt;在生物统计学中，从预测模型中提取可解释的洞察力对于评估因果性至关重要，而神经网络虽然在建模复杂生物数据方面具有强大的能力，但其传统的“黑盒”特性给验证和高风险健康应用中的信任带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探索如何利用机制可解释性技术来提升神经网络在生物统计学因果推断中的应用。&lt;h4&gt;方法&lt;/h4&gt;研究通过以下方式实现：1) 探测和验证神经网络学习到的内部表示，例如在目标最小损失估计（TMLE）框架中估计混杂函数；2) 发现和可视化网络处理不同类型输入时采用的独特计算路径，可能揭示混杂因素和治疗方法是如何处理的；3) 提供比较学习机制和提取的洞察力跨统计、机器学习和神经网络模型的方法，以加深对它们各自优势和劣势的理解。&lt;h4&gt;主要发现&lt;/h4&gt;机制可解释性工具可以用于探测和验证神经网络学习到的内部表示，发现和可视化计算路径，以及比较不同模型的学习机制。&lt;h4&gt;结论&lt;/h4&gt;机制可解释性技术有助于提升神经网络在生物统计学因果推断中的应用，增强了模型的可信度和理解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从预测模型中提取可解释的洞察力在生物统计学中仍然至关重要，特别是在评估因果性时，经典统计和机器学习方法往往提供内在的清晰性。虽然神经网络（NN）在建模复杂生物数据方面提供了强大的能力，但它们的传统“黑盒”特性给验证和高风险健康应用中的信任带来了挑战。近期在机制可解释性（MI）方面的进展旨在解析这些网络学习到的内部计算。本研究调查了MI技术在生物统计学因果推断背景下应用于神经网络的方法。我们证明，MI工具可以用来：1) 探测和验证神经网络学习到的内部表示，如估计目标最小损失估计（TMLE）框架中的混杂函数等内部表示；2) 发现和可视化网络处理不同类型输入时采用的独特计算路径，可能揭示混杂因素和治疗方法是如何处理的；3) 提供比较学习机制和提取的洞察力跨统计、机器学习和神经网络模型的方法，促进对这些模型各自优势和劣势的深入理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretable insights from predictive models remain critical inbio-statistics, particularly when assessing causality, where classicalstatistical and machine learning methods often provide inherent clarity. WhileNeural Networks (NNs) offer powerful capabilities for modeling complexbiological data, their traditional "black-box" nature presents challenges forvalidation and trust in high-stakes health applications. Recent advances inMechanistic Interpretability (MI) aim to decipher the internal computationslearned by these networks. This work investigates the application of MItechniques to NNs within the context of causal inference for bio-statistics.  We demonstrate that MI tools can be leveraged to: (1) probe and validate theinternal representations learned by NNs, such as those estimating nuisancefunctions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)discover and visualize the distinct computational pathways employed by thenetwork to process different types of inputs, potentially revealing howconfounders and treatments are handled; and (3) provide methodologies forcomparing the learned mechanisms and extracted insights across statistical,machine learning, and NN models, fostering a deeper understanding of theirrespective strengths and weaknesses for causal bio-statistical analysis.</description>
      <author>example@mail.com (Jean-Baptiste A. Conan)</author>
      <guid isPermaLink="false">2505.00555v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Implicit Neural-Representation Learning for Elastic Deformable-Object Manipulations</title>
      <link>http://arxiv.org/abs/2505.00500v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为INR-DOM的新方法，用于解决在现实场景中操作可变形物体，特别是弹性带的问题。&lt;h4&gt;背景&lt;/h4&gt;由于可变形物体的无限自由度（DoF）和密集但部分可观测的观测（如图像或点云），可变形物体操作（DOM）需要在大状态空间上工作的策略，这增加了采样复杂性和策略学习的不确定性。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现实场景中可变形物体操作的问题，特别是弹性带。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的隐式神经网络表示（INR）学习方法，用于弹性DOM，称为INR-DOM。该方法学习与部分可观测的弹性物体相关的一致状态表示，重建一个表示为符号距离函数的完整且隐式的表面。此外，通过强化学习（RL）进行探索性表示微调，使RL算法能够有效地学习可利用的表示，同时高效地获得DOM策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过构建三个模拟环境和使用Franka Emika Panda机械臂进行的真实世界操作研究，对方法进行了定量和定性分析。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效地处理可变形物体的操作问题，为现实场景中的DOM策略学习提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;We aim to solve the problem of manipulating deformable objects, particularly elastic bands, in real-world scenarios. However, deformable object manipulation (DOM) requires a policy that works on a large state space due to the unlimited degree of freedom (DoF) of deformable objects. Further, their dense but partial observations (e.g., images or point clouds) may increase the sampling complexity and uncertainty in policy learning. To figure it out, we propose a novel implicit neural-representation (INR) learning for elastic DOMs, called INR-DOM. Our method learns consistent state representations associated with partially observable elastic objects reconstructing a complete and implicit surface represented as a signed distance function. Furthermore, we perform exploratory representation fine-tuning through reinforcement learning (RL) that enables RL algorithms to effectively learn exploitable representations while efficiently obtaining a DOM policy. We perform quantitative and qualitative analyses building three simulated environments and real-world manipulation studies with a Franka Emika Panda arm. Videos are available at http://inr-dom.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We aim to solve the problem of manipulating deformable objects, particularlyelastic bands, in real-world scenarios. However, deformable object manipulation(DOM) requires a policy that works on a large state space due to the unlimiteddegree of freedom (DoF) of deformable objects. Further, their dense but partialobservations (e.g., images or point clouds) may increase the samplingcomplexity and uncertainty in policy learning. To figure it out, we propose anovel implicit neural-representation (INR) learning for elastic DOMs, calledINR-DOM. Our method learns consistent state representations associated withpartially observable elastic objects reconstructing a complete and implicitsurface represented as a signed distance function. Furthermore, we performexploratory representation fine-tuning through reinforcement learning (RL) thatenables RL algorithms to effectively learn exploitable representations whileefficiently obtaining a DOM policy. We perform quantitative and qualitativeanalyses building three simulated environments and real-world manipulationstudies with a Franka Emika Panda arm. Videos are available athttp://inr-dom.github.io.</description>
      <author>example@mail.com (Minseok Song, JeongHo Ha, Bonggyeong Park, Daehyung Park)</author>
      <guid isPermaLink="false">2505.00500v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>AnimalMotionCLIP: Embedding motion in CLIP for Animal Behavior Analysis</title>
      <link>http://arxiv.org/abs/2505.00569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures,Accepted for the poster session at the CV4Animals  workshop: Computer Vision for Animal Behavior Tracking and Modeling In  conjunction with Computer Vision and Pattern Recognition 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了AnimalMotionCLIP，用于动物行为识别，通过结合视频帧和光流信息，以及多种时间建模方案，提高了动物行为分析的准确性。&lt;h4&gt;背景&lt;/h4&gt;近年来，深度学习技术在动物行为识别中的应用受到关注，尤其是利用预训练的视觉语言模型如CLIP，因为它们在各类下游任务中表现出优异的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;解决将深度学习模型应用于动物行为识别时遇到的两个主要挑战：整合运动信息和设计有效的时序建模方案。&lt;h4&gt;方法&lt;/h4&gt;在CLIP框架中，通过交错视频帧和光流信息，以及使用密集、半密集和稀疏的分类器聚合方法来构建时间建模方案。&lt;h4&gt;主要发现&lt;/h4&gt;AnimalMotionCLIP能够在Animal Kingdom数据集上实现比现有方法更优的性能，能够正确识别精细的时序动作，这对动物行为分析至关重要。&lt;h4&gt;结论&lt;/h4&gt;AnimalMotionCLIP为动物行为识别提供了一种有效的方法，并展示了在动物行为分析中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, there has been a surge of interest in applying deep learningtechniques to animal behavior recognition, particularly leveraging pre-trainedvisual language models, such as CLIP, due to their remarkable generalizationcapacity across various downstream tasks. However, adapting these models to thespecific domain of animal behavior recognition presents two significantchallenges: integrating motion information and devising an effective temporalmodeling scheme. In this paper, we propose AnimalMotionCLIP to address thesechallenges by interleaving video frames and optical flow information in theCLIP framework. Additionally, several temporal modeling schemes using anaggregation of classifiers are proposed and compared: dense, semi dense, andsparse. As a result, fine temporal actions can be correctly recognized, whichis of vital importance in animal behavior analysis. Experiments on the AnimalKingdom dataset demonstrate that AnimalMotionCLIP achieves superior performancecompared to state-of-the-art approaches.</description>
      <author>example@mail.com (Enmin Zhong, Carlos R. del-Blanco, Daniel Berjón, Fernando Jaureguizar, Narciso García)</author>
      <guid isPermaLink="false">2505.00569v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Pixel3DMM: Versatile Screen-Space Priors for Single-Image 3D Face Reconstruction</title>
      <link>http://arxiv.org/abs/2505.00615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Website: https://simongiebenhain.github.io/pixel3dmm/ ;  Video: https://www.youtube.com/watch?v=BwxwEXJwUDc&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种从单张RGB图像中重建3D人脸的方法。&lt;h4&gt;背景&lt;/h4&gt;针对3D人脸重建问题。&lt;h4&gt;目的&lt;/h4&gt;为了提高3D人脸重建的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 提出Pixel3DMM，一套高度通用的视觉Transformer，预测每个像素的几何线索。2. 利用DINO基础模型的潜在特征，并引入定制的表面法线和uv坐标预测头。3. 通过将三个高质量的3D人脸数据集与FLAME网格拓扑进行配准来训练模型。4. 提出FLAME fitting优化，从uv坐标和法线估计中求解3DMM参数。&lt;h4&gt;主要发现&lt;/h4&gt;1. 通过新基准评估了单图像人脸重建。2. 该基准首次评估了姿态和自然面部几何。3. 在姿态面部表达方面，方法在几何精度上优于最具有竞争力的基线超过15%。&lt;h4&gt;结论&lt;/h4&gt;该方法在3D人脸重建方面表现优于现有基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We address the 3D reconstruction of human faces from a single RGB image. Tothis end, we propose Pixel3DMM, a set of highly-generalized vision transformerswhich predict per-pixel geometric cues in order to constrain the optimizationof a 3D morphable face model (3DMM). We exploit the latent features of the DINOfoundation model, and introduce a tailored surface normal and uv-coordinateprediction head. We train our model by registering three high-quality 3D facedatasets against the FLAME mesh topology, which results in a total of over1,000 identities and 976K images. For 3D face reconstruction, we propose aFLAME fitting opitmization that solves for the 3DMM parameters from theuv-coordinate and normal estimates. To evaluate our method, we introduce a newbenchmark for single-image face reconstruction, which features high diversityfacial expressions, viewing angles, and ethnicities. Crucially, our benchmarkis the first to evaluate both posed and neutral facial geometry. Ultimately,our method outperforms the most competitive baselines by over 15% in terms ofgeometric accuracy for posed facial expressions.</description>
      <author>example@mail.com (Simon Giebenhain, Tobias Kirschstein, Martin Rünz, Lourdes Agapito, Matthias Nießner)</author>
      <guid isPermaLink="false">2505.00615v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>A Robust Deep Networks based Multi-Object MultiCamera Tracking System for City Scale Traffic</title>
      <link>http://arxiv.org/abs/2505.00534v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的多目标多摄像头跟踪（MO-MCT）框架，用于解决城市规模交通场景中的自动目标跟踪问题。&lt;h4&gt;背景&lt;/h4&gt;随着网络摄像头的数量增加，视觉传感器在智能交通系统（ITS）中的重要性日益提高，但手动对象跟踪和匹配在多个非重叠摄像头之间存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且经济的深度学习框架，以解决城市规模交通场景中的手动对象跟踪和匹配问题。&lt;h4&gt;方法&lt;/h4&gt;该框架利用Mask R-CNN进行目标检测，使用非极大值抑制（NMS）从重叠检测中选择目标对象，并采用迁移学习进行再识别。此外，利用适当的损失函数和距离度量和ResNet-152进行特征提取，结合Deep SORT进行车辆跟踪。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在5th AI City Challenge数据集（Track 3）上实现了竞争性能，IDF1分数为0.8289，精确率和召回率分别为0.9026和0.8527。&lt;h4&gt;结论&lt;/h4&gt;该框架在鲁棒和准确的车辆跟踪方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着网络摄像头数量的持续增加，视觉传感器在智能交通系统（ITS）中对于交通监测、管理和优化变得日益重要。然而，在跨多个非重叠摄像头的城市规模交通场景中进行手动对象跟踪和匹配存在重大挑战。这些挑战包括处理多样化的车辆属性、遮挡、光照变化、阴影以及不同的视频分辨率。为了解决这些问题，我们提出了一种高效且经济的基于深度学习的多目标多摄像头跟踪（MO-MCT）框架。所提出的框架利用Mask R-CNN进行目标检测，并采用非极大值抑制（NMS）从重叠检测中选择目标对象。迁移学习用于再识别，能够实现跨多个摄像头的车辆轨迹块的关联和生成。此外，我们利用适当的损失函数和距离度量和ResNet-152进行特征提取，结合Deep SORT进行车辆跟踪。所提出的框架在5th AI City Challenge数据集（Track 3）上进行了评估，包括46个摄像头流。在这些46个摄像头流中，40个用于模型训练和验证，其余6个用于模型测试。所提出的框架实现了具有竞争力的性能，IDF1分数为0.8289，精确率和召回率分别为0.9026和0.8527，证明了其在鲁棒和准确的车辆跟踪方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s11042-023-16243-7&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision sensors are becoming more important in Intelligent TransportationSystems (ITS) for traffic monitoring, management, and optimization as thenumber of network cameras continues to rise. However, manual object trackingand matching across multiple non-overlapping cameras pose significantchallenges in city-scale urban traffic scenarios. These challenges includehandling diverse vehicle attributes, occlusions, illumination variations,shadows, and varying video resolutions. To address these issues, we propose anefficient and cost-effective deep learning-based framework for Multi-ObjectMulti-Camera Tracking (MO-MCT). The proposed framework utilizes Mask R-CNN forobject detection and employs Non-Maximum Suppression (NMS) to select targetobjects from overlapping detections. Transfer learning is employed forre-identification, enabling the association and generation of vehicle trackletsacross multiple cameras. Moreover, we leverage appropriate loss functions anddistance measures to handle occlusion, illumination, and shadow challenges. Thefinal solution identification module performs feature extraction usingResNet-152 coupled with Deep SORT based vehicle tracking. The proposedframework is evaluated on the 5th AI City Challenge dataset (Track 3),comprising 46 camera feeds. Among these 46 camera streams, 40 are used formodel training and validation, while the remaining six are utilized for modeltesting. The proposed framework achieves competitive performance with an IDF1score of 0.8289, and precision and recall scores of 0.9026 and 0.8527respectively, demonstrating its effectiveness in robust and accurate vehicletracking.</description>
      <author>example@mail.com (Muhammad Imran Zaman, Usama Ijaz Bajwa, Gulshan Saleem, Rana Hammad Raza)</author>
      <guid isPermaLink="false">2505.00534v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching</title>
      <link>http://arxiv.org/abs/2505.00562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TeLoGraF的方法，通过利用图神经网络编码器和流程匹配来学习通用信号时序逻辑(STL)规范，以解决复杂任务。&lt;h4&gt;背景&lt;/h4&gt;由于缺乏多样化的STL数据集和编码器来有效提取时序逻辑信息，大多数先前的工作仅考虑了固定或参数化的STL规范。&lt;h4&gt;目的&lt;/h4&gt;提高对通用STL规范的学习能力，解决实际应用中的复杂任务。&lt;h4&gt;方法&lt;/h4&gt;提出TeLoGraF方法，使用图神经网络编码器识别四种常用的STL模板，并收集了包含200K规范及其配对演示的数据集。在五个模拟环境中进行了实验，包括2D空间中的简单动态模型和高维7DoF Franka Panda机械臂以及Ant四足导航。&lt;h4&gt;主要发现&lt;/h4&gt;TeLoGraF在STL满意度率上优于其他基线方法。与经典STL规划算法相比，TeLoGraF在推理速度上快10-100倍，并且可以处理任何系统动力学。此外，该方法在解决复杂STL和抵抗分布外STL规范方面表现出强大的能力。&lt;h4&gt;结论&lt;/h4&gt;TeLoGraF是一种高效且通用的STL解决方案，可以应用于各种动态系统。&lt;h4&gt;翻译&lt;/h4&gt;Learning to solve complex tasks with signal temporal logic (STL) specifications is crucial to many real-world applications. However, most previous works only consider fixed or parametrized STL specifications due to the lack of a diverse STL dataset and encoders to effectively extract temporal logic information for downstream tasks. In this paper, we propose TeLoGraF, Temporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN) encoder and flow-matching to learn solutions for general STL specifications. We identify four commonly used STL templates and collect a total of 200K specifications with paired demonstrations. We conduct extensive experiments in five simulation environments ranging from simple dynamical models in the 2D space to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped navigation. Results show that our method outperforms other baselines in the STL satisfaction rate. Compared to classical STL planning algorithms, our approach is 10-100X faster in inference and can work on any system dynamics. Besides, we show our graph-encoding method's capability to solve complex STLs and robustness to out-distribution STL specifications. Code is available at https://github.com/mengyuest/TeLoGraF&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning to solve complex tasks with signal temporal logic (STL)specifications is crucial to many real-world applications. However, mostprevious works only consider fixed or parametrized STL specifications due tothe lack of a diverse STL dataset and encoders to effectively extract temporallogic information for downstream tasks. In this paper, we propose TeLoGraF,Temporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN)encoder and flow-matching to learn solutions for general STL specifications. Weidentify four commonly used STL templates and collect a total of 200Kspecifications with paired demonstrations. We conduct extensive experiments infive simulation environments ranging from simple dynamical models in the 2Dspace to high-dimensional 7DoF Franka Panda robot arm and Ant quadrupednavigation. Results show that our method outperforms other baselines in the STLsatisfaction rate. Compared to classical STL planning algorithms, our approachis 10-100X faster in inference and can work on any system dynamics. Besides, weshow our graph-encoding method's capability to solve complex STLs androbustness to out-distribution STL specifications. Code is available athttps://github.com/mengyuest/TeLoGraF</description>
      <author>example@mail.com (Yue Meng, Chuchu Fan)</author>
      <guid isPermaLink="false">2505.00562v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>CSE-SFP: Enabling Unsupervised Sentence Representation Learning via a Single Forward Pass</title>
      <link>http://arxiv.org/abs/2505.00389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGIR 2025 (Full)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的句子表示方法CSE-SFP，用于高效的文本表示。&lt;h4&gt;背景&lt;/h4&gt;句子表示在信息检索和计算语言学中是一个基本任务，对文本聚类、内容分析、问答系统和网络搜索等多种应用有重要影响。&lt;h4&gt;目的&lt;/h4&gt;为了解决由于时间和计算限制，将无监督句子表示与生成性PLMs结合的困难，尤其是针对参数规模更大的生成性PLMs。&lt;h4&gt;方法&lt;/h4&gt;CSE-SFP方法利用生成模型的特性，通过单次前向传递进行有效的无监督对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;CSE-SFP不仅生成高质量的嵌入，而且显著减少了训练时间和内存消耗。此外，引入了两个比率指标，用于评估编码模型的语义空间属性。&lt;h4&gt;结论&lt;/h4&gt;CSE-SFP是一种针对解码器PLM的高效无监督文本表示框架，为评估编码模型的语义空间属性提供了更可靠的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As a fundamental task in Information Retrieval and Computational Linguistics,sentence representation has profound implications for a wide range of practicalapplications such as text clustering, content analysis, question-answeringsystems, and web search. Recent advances in pre-trained language models (PLMs)have driven remarkable progress in this field, particularly throughunsupervised embedding derivation methods centered on discriminative PLMs likeBERT. However, due to time and computational constraints, few efforts haveattempted to integrate unsupervised sentence representation with generativePLMs, which typically possess much larger parameter sizes. Given thatstate-of-the-art models in both academia and industry are predominantly basedon generative architectures, there is a pressing need for an efficientunsupervised text representation framework tailored to decoder-only PLMs. Toaddress this concern, we propose CSE-SFP, an innovative method that exploitsthe structural characteristics of generative models. Compared to existingstrategies, CSE-SFP requires only a single forward pass to perform effectiveunsupervised contrastive learning. Rigorous experimentation demonstrates thatCSE-SFP not only produces higher-quality embeddings but also significantlyreduces both training time and memory consumption. Furthermore, we introducetwo ratio metrics that jointly assess alignment and uniformity, therebyproviding a more robust means for evaluating the semantic spatial properties ofencoding models.</description>
      <author>example@mail.com (Bowen Zhang, Zixin Song, Chunping Li)</author>
      <guid isPermaLink="false">2505.00389v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Fast and Low-Cost Genomic Foundation Models via Outlier Removal</title>
      <link>http://arxiv.org/abs/2505.00598v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  International Conference on Machine Learning (ICML) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了首个针对基因组基础模型（GFMs）的统一对抗攻击基准，名为GERM，用于系统地评估GFMs对对抗攻击的脆弱性。&lt;h4&gt;背景&lt;/h4&gt;现有GFM基准未能全面评估GFMs对对抗攻击的脆弱性。&lt;h4&gt;目的&lt;/h4&gt;建立一种全面的评估框架，分析GFMs的脆弱性，包括模型架构、量化方案和训练数据集。&lt;h4&gt;方法&lt;/h4&gt;使用四种广泛采用的攻击算法和三种防御策略，对五种最先进的GFMs进行对抗鲁棒性评估。&lt;h4&gt;主要发现&lt;/h4&gt;基于transformer的模型比HyenaDNA具有更强的对抗扰动鲁棒性，强调了架构设计对脆弱性的影响；对抗攻击通常针对生物上重要的基因组区域，表明这些模型有效地捕捉到了有意义的序列特征。&lt;h4&gt;结论&lt;/h4&gt;GERM基准为评估GFMs的脆弱性提供了一个可访问和全面的框架，揭示了架构设计和序列特征在模型鲁棒性中的作用。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了首个针对基因组基础模型（GFMs）的统一对抗攻击基准，名为GERM。与现有的GFM基准不同，GERM提供了首个全面评估GFMs对抗攻击脆弱性的评估框架。在方法论上，我们使用四种广泛采用的攻击算法和三种防御策略评估了五种最先进的GFMs的对抗鲁棒性。重要的是，我们的基准提供了一个可访问且全面的框架，以分析GFMs的脆弱性与模型架构、量化方案和训练数据集的关系。经验表明，基于transformer的模型与HyenaDNA相比，对对抗扰动的鲁棒性更强，突出了架构设计对脆弱性的影响。此外，对抗攻击通常针对生物上重要的基因组区域，表明这些模型有效地捕捉到了有意义的序列特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose the first unified adversarial attack benchmark for GenomicFoundation Models (GFMs), named GERM. Unlike existing GFM benchmarks, GERMoffers the first comprehensive evaluation framework to systematically assessthe vulnerability of GFMs to adversarial attacks. Methodologically, we evaluatethe adversarial robustness of five state-of-the-art GFMs using four widelyadopted attack algorithms and three defense strategies. Importantly, ourbenchmark provides an accessible and comprehensive framework to analyze GFMvulnerabilities with respect to model architecture, quantization schemes, andtraining datasets. Empirically, transformer-based models exhibit greaterrobustness to adversarial perturbations compared to HyenaDNA, highlighting theimpact of architectural design on vulnerability. Moreover, adversarial attacksfrequently target biologically significant genomic regions, suggesting thatthese models effectively capture meaningful sequence features.</description>
      <author>example@mail.com (Haozheng Luo, Chenghao Qiu, Maojiang Su, Zhihan Zhou, Zoe Mehta, Guo Ye, Jerry Yao-Chieh Hu, Han Liu)</author>
      <guid isPermaLink="false">2505.00598v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Pretrained Diffusion Models for Zero-Shot Part Assembly</title>
      <link>http://arxiv.org/abs/2505.00426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 12 figures, Accepted by IJCAI-2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种零样本3D零件组装方法，通过使用预训练的点云扩散模型作为组装过程中的判别器，指导零件操作形成真实形状。&lt;h4&gt;背景&lt;/h4&gt;随着自主组装的需求增长，3D零件组装技术对于机器人至关重要。现有方法主要通过监督学习训练神经网络来估计每个零件的变换，但需要大量手动标注数据，成本高且不适用于大规模应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种零样本零件组装方法，降低数据收集成本，提高组装的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;1. 利用预训练的点云扩散模型作为判别器；2. 将扩散模型应用于零样本组装，转化为迭代最近点（ICP）过程；3. 提出新的推离策略处理重叠部分。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过实验和定量比较，证明其有效性，甚至在某些方面超过了监督学习方法。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了零样本3D零件组装的鲁棒性，适用于大规模应用。&lt;h4&gt;翻译&lt;/h4&gt;3D零件组装旨在理解零件关系并预测其6自由度姿态以构建逼真的3D形状，满足自主组装的需求，这对机器人至关重要。现有方法主要通过在监督下训练神经网络来估计每个零件的变换，这需要大量的手动标注数据。然而，数据收集的高成本和现实世界中形状和零件的巨大可变性使得传统方法不适用于大规模应用。在本文中，我们首先提出了一种零样本零件组装方法，该方法利用预训练的点云扩散模型作为组装过程中的判别器，指导零件操作形成真实形状。具体来说，我们理论证明了利用扩散模型进行零样本零件组装可以转化为迭代最近点（ICP）过程。然后，我们提出了一种新的推离策略来解决重叠部分，从而进一步提高方法的鲁棒性。为了验证我们的工作，我们进行了广泛的实验和与几个强基线方法的定量比较，证明了所提出方法的有效性，该方法甚至在某些方面超过了监督学习方法。代码已发布在https://github.com/Ruiyuan-Zhang/Zero-Shot-Assembly。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D part assembly aims to understand part relationships and predict their6-DoF poses to construct realistic 3D shapes, addressing the growing demand forautonomous assembly, which is crucial for robots. Existing methods mainlyestimate the transformation of each part by training neural networks undersupervision, which requires a substantial quantity of manually labeled data.However, the high cost of data collection and the immense variability ofreal-world shapes and parts make traditional methods impractical forlarge-scale applications. In this paper, we propose first a zero-shot partassembly method that utilizes pre-trained point cloud diffusion models asdiscriminators in the assembly process, guiding the manipulation of parts toform realistic shapes. Specifically, we theoretically demonstrate thatutilizing a diffusion model for zero-shot part assembly can be transformed intoan Iterative Closest Point (ICP) process. Then, we propose a novel pushing-awaystrategy to address the overlap parts, thereby further enhancing the robustnessof the method. To verify our work, we conduct extensive experiments andquantitative comparisons to several strong baseline methods, demonstrating theeffectiveness of the proposed approach, which even surpasses the supervisedlearning method. The code has been released onhttps://github.com/Ruiyuan-Zhang/Zero-Shot-Assembly.</description>
      <author>example@mail.com (Ruiyuan Zhang, Qi Wang, Jiaxiang Liu, Yu Zhang, Yuchi Huo, Chao Wu)</author>
      <guid isPermaLink="false">2505.00426v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors</title>
      <link>http://arxiv.org/abs/2505.00580v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to appear in Proceedings of the 2025 International Joint Conference  on Artificial Intelligence (IJCAI-2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过分解方法降低复杂度的模型微调方法，并解决了非方阵微调权重的问题，实验表明该方法在多个任务上表现良好，同时减少了浮点运算和可训练参数的数量。&lt;h4&gt;背景&lt;/h4&gt;基础模型在不同领域取得了巨大成功，但它们的计算和存储复杂度高，使得模型难以微调并在实际应用中受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种降低模型微调复杂度的方法，同时提高模型性能。&lt;h4&gt;方法&lt;/h4&gt;通过分解方法，使用交错循环矩阵和斜对角矩阵的乘积，解决非方阵微调权重问题，并使用1D快速傅里叶变换（FFT）代替2D FFT。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个任务上实现了与现有方法相似或更好的性能，同时显著减少了浮点运算和可训练参数的数量。&lt;h4&gt;结论&lt;/h4&gt;提出的方法有效降低了模型微调的复杂度，并提高了实际应用中的适用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型在不同领域取得了巨大成功。然而，它们的巨大计算和存储复杂度使得这些模型难以微调，并且在实际应用中受限。最近的研究表明，在傅里叶域进行训练可以是一种在模型性能和训练参数数量方面都有效的微调方法。在这项工作中，我们通过交错循环矩阵和斜对角矩阵的乘积的分解进一步降低了复杂性。此外，我们通过将循环矩阵划分为块来解决非方阵微调权重的情况。我们的方法避免了权重变化矩阵的构建，并使用1D快速傅里叶变换（FFT）而不是2D FFT。实验结果表明，我们的方法在各种任务上实现了类似或更好的性能，同时大幅减少了浮点运算（FLOPs）和可训练参数的数量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have achieved tremendous success in different domains.However, their huge computation and storage complexity make these modelsdifficult to fine-tune and also less applicable in practice. Recent study showstraining in Fourier domain can be an effective fine-tuning method in terms ofboth model performance and number of training parameters. In this work, wepropose to further reduce the complexity by the factorization through theproduct of interleaved circulant and diagonal matrices. In addition, we addressthe case of non-square fine-tuning weights by partitioning the circulant matrixinto blocks. Our method avoids the construction of weight change matrix andutilizes 1D fast Fourier transform (FFT) instead of 2D FFT. Experimentalresults show that our method achieves similar or better performance acrossvarious tasks with much less floating-point operations (FLOPs) and the numberof trainable parameters.</description>
      <author>example@mail.com (Xinyu Ding, Lexuan Chen, Siyu Liao, Zhongfeng Wang)</author>
      <guid isPermaLink="false">2505.00580v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Per-Domain Generalizing Policies: On Validation Instances and Scaling Behavior</title>
      <link>http://arxiv.org/abs/2505.00439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 3 tables, 3 figures, 3 algorithms&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种动态生成验证集的方法，以提升域内泛化动作策略的缩放行为，并通过实验证明这种方法在9个领域中提升了图神经网络策略的缩放行为。&lt;h4&gt;背景&lt;/h4&gt;现有工作已表明，成功的域内泛化动作策略可以通过学习获得，从小规模训练实例到大规模测试实例的缩放行为是关键目标。&lt;h4&gt;目的&lt;/h4&gt;旨在通过使用比训练实例更大的验证实例来提升策略的缩放行为。&lt;h4&gt;方法&lt;/h4&gt;提出了一种动态生成验证集的方法，并在评估缩放行为时，通过系统地生成测试实例，以确保对每个实例规模覆盖性能的置信度。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，动态验证方法在所有9个测试领域中都提升了图神经网络策略的缩放行为。&lt;h4&gt;结论&lt;/h4&gt;动态验证是一种有效的提升域内泛化动作策略缩放行为的方法。&lt;h4&gt;翻译&lt;/h4&gt;Recent work has shown that successful per-domain generalizing action policies can be learned. Scaling behavior, from small training instances to large test instances, is the key objective; and the use of validation instances larger than training instances is one key to achieve it. Prior work has used fixed validation sets. Here, we introduce a method generating the validation set dynamically, on the fly, increasing instance size so long as informative and feasible. We also introduce refined methodology for evaluating scaling behavior, generating test instances systematically to guarantee a given confidence in coverage performance for each instance size. In experiments, dynamic validation improves scaling behavior of GNN policies in all 9 domains used.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work has shown that successful per-domain generalizing action policiescan be learned. Scaling behavior, from small training instances to large testinstances, is the key objective; and the use of validation instances largerthan training instances is one key to achieve it. Prior work has used fixedvalidation sets. Here, we introduce a method generating the validation setdynamically, on the fly, increasing instance size so long as informative andfeasible.We also introduce refined methodology for evaluating scaling behavior,generating test instances systematically to guarantee a given confidence incoverage performance for each instance size. In experiments, dynamic validationimproves scaling behavior of GNN policies in all 9 domains used.</description>
      <author>example@mail.com (Timo P. Gros, Nicola J. Müller, Daniel Fiser, Isabel Valera, Verena Wolf, Jörg Hoffmann)</author>
      <guid isPermaLink="false">2505.00439v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented Contour Quality</title>
      <link>http://arxiv.org/abs/2505.00308v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于深度学习的质量评估方法，用于评估放射治疗中的自动生成的轮廓（auto-contours），特别关注在线自适应放射治疗（OART）。该方法利用贝叶斯有序分类（BOC）和校准的不确定性阈值，能够在不依赖真实轮廓或大量人工标注的情况下进行有信心的质量预测。&lt;h4&gt;背景&lt;/h4&gt;放射治疗中自动生成的轮廓质量评估是一个重要的任务，特别是对于在线自适应放射治疗（OART），需要一种无需真实轮廓或大量人工标注的方法来进行质量评估。&lt;h4&gt;目的&lt;/h4&gt;研究旨在开发一种基于深度学习的质量评估方法，用于评价放射治疗中自动生成的轮廓质量，并特别关注在线自适应放射治疗（OART）。&lt;h4&gt;方法&lt;/h4&gt;研究人员开发了一个BOC模型来对自动轮廓的质量进行分类，并量化预测的不确定性。通过校准步骤优化不确定性阈值以满足临床准确性的需求。方法在无手动标注、有限标注和广泛标注的三种数据场景下进行了验证。对于前列腺癌中的直肠轮廓，当没有手动标注时，使用几何代理标签；当有限时，使用迁移学习；当有充足标注时，使用直接监督。&lt;h4&gt;主要发现&lt;/h4&gt;BOC模型在所有场景下都表现出稳健的性能。仅使用30个手动标注和通过34名受试者校准后，在测试数据上达到了超过90%的准确率。使用校准阈值，超过98%的情况下，自动轮廓的质量被准确地预测，准确率超过93%，从而减少了不必要的手动审查并突出了需要纠正的案例。&lt;h4&gt;结论&lt;/h4&gt;提出的质量评估模型通过减少人工工作量并允许快速、有信息量的临床决策，提高了OART中的轮廓效率。通过不确定性量化，确保了更安全、更可靠的放射治疗工作流程。&lt;h4&gt;翻译&lt;/h4&gt;本研究提出了一种基于深度学习的质量评估方法，用于评估放射治疗中的自动生成的轮廓（auto-contours），重点在于在线自适应放射治疗（OART）。该方法利用贝叶斯有序分类（BOC）和校准的不确定性阈值，可以在不依赖真实轮廓或大量人工标注的情况下进行有信心的质量预测。我们开发了一个BOC模型来对自动轮廓的质量进行分类并量化预测的不确定性。使用校准步骤优化不确定性阈值以满足临床准确性的需求。该方法在无手动标注、有限标注和广泛标注的三种数据场景下进行了验证。对于前列腺癌中的直肠轮廓，在没有手动标注时应用几何代理标签；在有限标注时使用迁移学习；在有充足标注时使用直接监督。BOC模型在所有场景下都表现出稳健的性能。仅使用30个手动标注和通过34名受试者校准后，在测试数据上达到了超过90%的准确率。使用校准阈值，超过98%的情况下，自动轮廓的质量被准确地预测，准确率超过93%，从而减少了不必要的手动审查并突出了需要纠正的案例。提出的质量评估模型通过减少人工工作量并允许快速、有信息量的临床决策，提高了OART中的轮廓效率。通过不确定性量化，确保了更安全、更可靠的放射治疗工作流程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: This study presents a Deep Learning (DL)-based quality assessment(QA) approach for evaluating auto-generated contours (auto-contours) inradiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). LeveragingBayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds,the method enables confident QA predictions without relying on ground truthcontours or extensive manual labeling. Methods: We developed a BOC model toclassify auto-contour quality and quantify prediction uncertainty. Acalibration step was used to optimize uncertainty thresholds that meet clinicalaccuracy needs. The method was validated under three data scenarios: no manuallabels, limited labels, and extensive labels. For rectum contours in prostatecancer, we applied geometric surrogate labels when manual labels were absent,transfer learning when limited, and direct supervision when ample labels wereavailable. Results: The BOC model delivered robust performance across allscenarios. Fine-tuning with just 30 manual labels and calibrating with 34subjects yielded over 90% accuracy on test data. Using the calibratedthreshold, over 93% of the auto-contours' qualities were accurately predictedin over 98% of cases, reducing unnecessary manual reviews and highlightingcases needing correction. Conclusion: The proposed QA model enhances contouringefficiency in OART by reducing manual workload and enabling fast, informedclinical decisions. Through uncertainty quantification, it ensures safer, morereliable radiotherapy workflows.</description>
      <author>example@mail.com (Biling Wang, Austen Maniscalco, Ti Bai, Siqiu Wang, Michael Dohopolski, Mu-Han Lin, Chenyang Shen, Dan Nguyen, Junzhou Huang, Steve Jiang, Xinlei Wang)</author>
      <guid isPermaLink="false">2505.00308v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions</title>
      <link>http://arxiv.org/abs/2505.00402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CIKM 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DeepSTA的深度时空注意力模型，用于预测快递员的准时送达率，以应对异常情况下的物流挑战。&lt;h4&gt;背景&lt;/h4&gt;预测快递员准时送达率对于物流行业至关重要，特别是在疫情等异常情况下，快递员准时送达率会显著下降且波动较大。&lt;h4&gt;目的&lt;/h4&gt;针对现有研究对物流场景关注不足、异常事件建模不明确、传统数据驱动方法在异常情况下表现不佳等问题，提出一种新的预测模型。&lt;h4&gt;方法&lt;/h4&gt;设计了一种异常时空学习模块，利用循环神经网络来建模事件信息；使用Node2Vec模型来建模道路区域之间的相关性；采用图神经网络和长短期记忆网络来捕捉快递员的时空依赖性；提出了一种异常模式注意力模块，利用记忆网络通过注意力机制存储快递员的异常特征模式。&lt;h4&gt;主要发现&lt;/h4&gt;在2022年COVID-19疫情期间的真实物流数据集上的实验表明，该模型在MAE和MSE方面分别优于最佳基线12.11%和13.71%，证明了其在多个竞争基线中的优越性能。&lt;h4&gt;结论&lt;/h4&gt;DeepSTA模型在预测快递员准时送达率方面表现出色，能够有效应对异常情况下的物流挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3583780.3614671&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prediction of couriers' delivery timely rates in advance is essential to thelogistics industry, enabling companies to take preemptive measures to ensurethe normal operation of delivery services. This becomes even more criticalduring anomaly conditions like the epidemic outbreak, during which couriers'delivery timely rate will decline markedly and fluctuates significantly.Existing studies pay less attention to the logistics scenario. Moreover, manyworks focusing on prediction tasks in anomaly scenarios fail to explicitlymodel abnormal events, e.g., treating external factors equally with otherfeatures, resulting in great information loss. Further, since some anomalousevents occur infrequently, traditional data-driven methods perform poorly inthese scenarios. To deal with them, we propose a deep spatial-temporalattention model, named DeepSTA. To be specific, to avoid information loss, wedesign an anomaly spatio-temporal learning module that employs a recurrentneural network to model incident information. Additionally, we utilize Node2vecto model correlations between road districts, and adopt graph neural networksand long short-term memory to capture the spatial-temporal dependencies ofcouriers. To tackle the issue of insufficient training data in abnormalcircumstances, we propose an anomaly pattern attention module that adopts amemory network for couriers' anomaly feature patterns storage via attentionmechanisms. The experiments on real-world logistics datasets during theCOVID-19 outbreak in 2022 show the model outperforms the best baselines by12.11% in MAE and 13.71% in MSE, demonstrating its superior performance overmultiple competitive baselines.</description>
      <author>example@mail.com (Jinhui Yi, Huan Yan, Haotian Wang, Jian Yuan, Yong Li)</author>
      <guid isPermaLink="false">2505.00402v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>SacFL: Self-Adaptive Federated Continual Learning for Resource-Constrained End Devices</title>
      <link>http://arxiv.org/abs/2505.00365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TNNLS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SacFL的新型联邦持续学习框架，旨在解决移动设备在持续学习过程中的存储资源限制、任务切换检测自主性差以及对抗新任务困难等问题。&lt;h4&gt;背景&lt;/h4&gt;随着终端设备的普及，分布式计算模式中，设备上机器学习模型持续处理由这些设备生成的多样化数据。数据的动态特性，即连续变化或数据漂移，对设备上的模型构成了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文提出了联邦持续学习（FCL），在保护用户数据隐私的同时，通过协作更新来增强模型。&lt;h4&gt;方法&lt;/h4&gt;SacFL采用编码器-解码器架构，将任务鲁棒和任务敏感组件分离，通过保留轻量级任务敏感组件来显著减少存储需求。此外，SacFL利用对比学习引入了自主数据漂移检测机制，能够识别新任务的出现以及其是否为良性任务。&lt;h4&gt;主要发现&lt;/h4&gt;在多个文本和图像数据集（如Cifar100和THUCNews）上进行的综合实验验证了SacFL在类增量学习和领域增量场景中的有效性。&lt;h4&gt;结论&lt;/h4&gt;SacFL框架在解决移动设备持续学习中的挑战方面表现出色，并已开发出演示系统以验证其实用性。&lt;h4&gt;翻译&lt;/h4&gt;The proliferation of end devices has led to a distributed computing paradigm, wherein on-device machine learning models continuously process diverse data generated by these devices. The dynamic nature of this data, characterized by continuous changes or data drift, poses significant challenges for on-device models. To address this issue, continual learning (CL) is proposed, enabling machine learning models to incrementally update their knowledge and mitigate catastrophic forgetting. However, the traditional centralized approach to CL is unsuitable for end devices due to privacy and data volume concerns. In this context, federated continual learning (FCL) emerges as a promising solution, preserving user data locally while enhancing models through collaborative updates. Aiming at the challenges of limited storage resources for CL, poor autonomy in task shift detection, and difficulty in coping with new adversarial tasks in FCL scenario, we propose a novel FCL framework named SacFL. SacFL employs an Encoder-Decoder architecture to separate task-robust and task-sensitive components, significantly reducing storage demands by retaining lightweight task-sensitive components for resource-constrained end devices. Moreover, SacFL leverages contrastive learning to introduce an autonomous data shift detection mechanism, enabling it to discern whether a new task has emerged and whether it is a benign task. This capability ultimately allows the device to autonomously trigger CL or attack defense strategy without additional information, which is more practical for end devices. Comprehensive experiments conducted on multiple text and image datasets, such as Cifar100 and THUCNews, have validated the effectiveness of SacFL in both class-incremental and domain-incremental scenarios. Furthermore, a demo system has been developed to verify its practicality.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of end devices has led to a distributed computing paradigm,wherein on-device machine learning models continuously process diverse datagenerated by these devices. The dynamic nature of this data, characterized bycontinuous changes or data drift, poses significant challenges for on-devicemodels. To address this issue, continual learning (CL) is proposed, enablingmachine learning models to incrementally update their knowledge and mitigatecatastrophic forgetting. However, the traditional centralized approach to CL isunsuitable for end devices due to privacy and data volume concerns. In thiscontext, federated continual learning (FCL) emerges as a promising solution,preserving user data locally while enhancing models through collaborativeupdates. Aiming at the challenges of limited storage resources for CL, poorautonomy in task shift detection, and difficulty in coping with new adversarialtasks in FCL scenario, we propose a novel FCL framework named SacFL. SacFLemploys an Encoder-Decoder architecture to separate task-robust andtask-sensitive components, significantly reducing storage demands by retaininglightweight task-sensitive components for resource-constrained end devices.Moreover, $\rm{SacFL}$ leverages contrastive learning to introduce anautonomous data shift detection mechanism, enabling it to discern whether a newtask has emerged and whether it is a benign task. This capability ultimatelyallows the device to autonomously trigger CL or attack defense strategy withoutadditional information, which is more practical for end devices. Comprehensiveexperiments conducted on multiple text and image datasets, such as Cifar100 andTHUCNews, have validated the effectiveness of $\rm{SacFL}$ in bothclass-incremental and domain-incremental scenarios. Furthermore, a demo systemhas been developed to verify its practicality.</description>
      <author>example@mail.com (Zhengyi Zhong, Weidong Bao, Ji Wang, Jianguo Chen, Lingjuan Lyu, Wei Yang Bryan Lim)</author>
      <guid isPermaLink="false">2505.00365v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Cues3D: Unleashing the Power of Sole NeRF for Consistent and Unique Instances in Open-Vocabulary 3D Panoptic Segmentation</title>
      <link>http://arxiv.org/abs/2505.00378v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Information Fusion&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Cues3D的紧凑型方法，用于Open-vocabulary 3D panoptic segmentation，该方法仅依赖于NeRF，避免了预关联，并通过NeRF的隐式3D场实现全局一致的几何结构，从而有效地区分物体。&lt;h4&gt;背景&lt;/h4&gt;Open-vocabulary 3D panoptic segmentation成为研究热点，现有方法结合2D分割和几何感知3D原语，但NeRF类方法因缺乏高保真3D点云而受限。&lt;h4&gt;目的&lt;/h4&gt;提出Cues3D方法，解决NeRF类方法在保持观察一致性方面的不足。&lt;h4&gt;方法&lt;/h4&gt;Cues3D利用NeRF的隐式3D场建立全局一致的几何结构，并提出一个三阶段训练框架：初始化-去歧义-细化，以及实例去歧义方法来匹配NeRF渲染的3D掩码。&lt;h4&gt;主要发现&lt;/h4&gt;Cues3D在ScanNet v2、ScanNet200、ScanNet++和Replica数据集上表现出色，优于其他2D图像方法，与最新的2D-3D融合方法竞争，并在使用额外3D点云时甚至超越。&lt;h4&gt;结论&lt;/h4&gt;Cues3D是一种有效的3D panoptic segmentation方法，能够提供高度一致和独特的3D实例ID。&lt;h4&gt;翻译&lt;/h4&gt;Open-vocabulary 3D panoptic segmentation最近成为了一个显著的研究趋势。目前表现最好的方法将2D分割与几何感知的3D原语相结合。然而，如果没有高保真的3D点云，如基于NeRF的方法，这种优势就会丧失。这些方法受限于在部分观察中保持一致性的能力不足。为了解决这个问题，最近的工作利用对比损失或跨视图关联预处理来进行视图一致性。与它们相反，我们提出了Cues3D，一种仅依赖于NeRF而不是预关联的紧凑方法。其核心思想是NeRF的隐式3D场内在地建立了一个全局一致的几何结构，从而在没有显式跨视图监督的情况下有效地区分物体。我们提出了一个针对NeRF的三阶段训练框架，即初始化-去歧义-细化，其中使用最初学习到的知识来纠正实例ID。此外，还提出了一种实例去歧义方法来匹配NeRF渲染的3D掩码，并确保全局唯一的3D实例身份。借助Cues3D，我们使用平衡版本的NeRF在视图中为每个对象获得了高度一致和独特的3D实例ID。我们的实验在ScanNet v2、ScanNet200、ScanNet++和Replica数据集上进行了3D实例、panoptic和语义分割任务。Cues3D优于其他基于2D图像的方法，并与最新的2D-3D融合方法竞争，甚至在使用额外的3D点云时甚至超过了它们。代码链接可在附录中找到，并将发布在github上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary 3D panoptic segmentation has recently emerged as asignificant trend. Top-performing methods currently integrate 2D segmentationwith geometry-aware 3D primitives. However, the advantage would be lost withouthigh-fidelity 3D point clouds, such as methods based on Neural Radiance Field(NeRF). These methods are limited by the insufficient capacity to maintainconsistency across partial observations. To address this, recent works haveutilized contrastive loss or cross-view association pre-processing for viewconsensus. In contrast to them, we present Cues3D, a compact approach thatrelies solely on NeRF instead of pre-associations. The core idea is that NeRF'simplicit 3D field inherently establishes a globally consistent geometry,enabling effective object distinction without explicit cross-view supervision.We propose a three-phase training framework for NeRF,initialization-disambiguation-refinement, whereby the instance IDs arecorrected using the initially-learned knowledge. Additionally, an instancedisambiguation method is proposed to match NeRF-rendered 3D masks and ensureglobally unique 3D instance identities. With the aid of Cues3D, we obtainhighly consistent and unique 3D instance ID for each object across views with abalanced version of NeRF. Our experiments are conducted on ScanNet v2,ScanNet200, ScanNet++, and Replica datasets for 3D instance, panoptic, andsemantic segmentation tasks. Cues3D outperforms other 2D image-based methodsand competes with the latest 2D-3D merging based methods, while even surpassingthem when using additional 3D point clouds. The code link could be found in theappendix and will be released on\href{https://github.com/mRobotit/Cues3D}{github}</description>
      <author>example@mail.com (Feng Xue, Wenzhuang Xu, Guofeng Zhong, Anlong Minga, Nicu Sebe)</author>
      <guid isPermaLink="false">2505.00378v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>R&amp;B: Domain Regrouping and Data Mixture Balancing for Efficient Foundation Model Training</title>
      <link>http://arxiv.org/abs/2505.00358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为R&amp;B的框架，用于改进数据混合策略，以降低训练语言模型的成本。&lt;h4&gt;背景&lt;/h4&gt;数据混合策略在降低语言模型训练成本方面取得了成功，但存在两个主要缺陷：依赖预定的数据域和计算效率问题。&lt;h4&gt;目的&lt;/h4&gt;旨在解决数据混合策略的缺陷，提出一种更有效的框架。&lt;h4&gt;方法&lt;/h4&gt;R&amp;B框架通过基于语义相似性重新划分训练数据（Regroup）来创建更细粒度的领域，并通过利用训练过程中获得的领域梯度诱导的Gram矩阵来有效优化数据组合（Balance）。&lt;h4&gt;主要发现&lt;/h4&gt;R&amp;B框架无需额外的计算即可获得评估信息，如损失或梯度，并且与现有非自适应混合方法相比，在理论和实证上都表现出更高的有效性。&lt;h4&gt;结论&lt;/h4&gt;R&amp;B框架在五个不同数据集上证明了其有效性，且只需极小的额外计算开销（0.01%）即可匹配或超越最先进的数据混合策略的性能。&lt;h4&gt;翻译&lt;/h4&gt;Data mixing strategies have successfully reduced the costs involved in training language models. While promising, such methods suffer from two flaws. First, they rely on predetermined data domains (e.g., data sources, task types), which may fail to capture critical semantic nuances, leaving performance on the table. Second, these methods scale with the number of domains in a computationally prohibitive way. We address these challenges via R&amp;B, a framework that re-partitions training data based on semantic similarity (Regroup) to create finer-grained domains, and efficiently optimizes the data composition (Balance) by leveraging a Gram matrix induced by domain gradients obtained throughout training. Unlike prior works, it removes the need for additional compute to obtain evaluation information such as losses or gradients. We analyze this technique under standard regularity conditions and provide theoretical insights that justify R&amp;B's effectiveness compared to non-adaptive mixing approaches. Empirically, we demonstrate the effectiveness of R&amp;B on five diverse datasets ranging from natural language to reasoning and multimodal tasks. With as little as 0.01% additional compute overhead, R&amp;B matches or exceeds the performance of state-of-the-art data mixing strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data mixing strategies have successfully reduced the costs involved intraining language models. While promising, such methods suffer from two flaws.First, they rely on predetermined data domains (e.g., data sources, tasktypes), which may fail to capture critical semantic nuances, leavingperformance on the table. Second, these methods scale with the number ofdomains in a computationally prohibitive way. We address these challenges viaR&amp;B, a framework that re-partitions training data based on semantic similarity(Regroup) to create finer-grained domains, and efficiently optimizes the datacomposition (Balance) by leveraging a Gram matrix induced by domain gradientsobtained throughout training. Unlike prior works, it removes the need foradditional compute to obtain evaluation information such as losses orgradients. We analyze this technique under standard regularity conditions andprovide theoretical insights that justify R&amp;B's effectiveness compared tonon-adaptive mixing approaches. Empirically, we demonstrate the effectivenessof R&amp;B on five diverse datasets ranging from natural language to reasoning andmultimodal tasks. With as little as 0.01% additional compute overhead, R&amp;Bmatches or exceeds the performance of state-of-the-art data mixing strategies.</description>
      <author>example@mail.com (Albert Ge, Tzu-Heng Huang, John Cooper, Avi Trost, Ziyi Chu, Satya Sai Srinath Namburi GNVV, Ziyang Cai, Kendall Park, Nicholas Roberts, Frederic Sala)</author>
      <guid isPermaLink="false">2505.00358v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>From GNNs to Trees: Multi-Granular Interpretability for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2505.00364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TIF的新颖的图分类可解释框架，通过将GNN转换为层次树，以不同粒度的粗化图作为树节点，提供多粒度的可解释性。&lt;h4&gt;背景&lt;/h4&gt;现有的基于子图的可解释方法过于强调局部结构，可能忽略了图中的长距离依赖关系。虽然基于图粗化的方法对全局可解释性有益，但它们不可避免地将图简化为固定的粒度。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够在不同粒度上捕捉现实世界图任务中的关系，同时保持模型的可解释性。&lt;h4&gt;方法&lt;/h4&gt;TIF通过迭代采用图粗化模块将原始图压缩为越来越粗的子图，并通过特定的图扰动模块保持不同分支中树节点的多样性。此外，还引入了自适应路由模块来识别最有信息的根到叶路径。&lt;h4&gt;主要发现&lt;/h4&gt;TIF在可解释性方面表现出优越性，同时在预测性能上与最先进的模型相当。&lt;h4&gt;结论&lt;/h4&gt;TIF为图分类提供了一个既可解释又有竞争力的预测性能的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretable Graph Neural Networks (GNNs) aim to reveal the underlyingreasoning behind model predictions, attributing their decisions to specificsubgraphs that are informative. However, existing subgraph-based interpretablemethods suffer from an overemphasis on local structure, potentially overlookinglong-range dependencies within the entire graphs. Although recent efforts thatrely on graph coarsening have proven beneficial for global interpretability,they inevitably reduce the graphs to a fixed granularity. Such an inflexibleway can only capture graph connectivity at a specific level, whereas real-worldgraph tasks often exhibit relationships at varying granularities (e.g.,relevant interactions in proteins span from functional groups, to amino acids,and up to protein domains). In this paper, we introduce a novel Tree-likeInterpretable Framework (TIF) for graph classification, where plain GNNs aretransformed into hierarchical trees, with each level featuring coarsened graphsof different granularity as tree nodes. Specifically, TIF iteratively adopts agraph coarsening module to compress original graphs (i.e., root nodes of trees)into increasingly coarser ones (i.e., child nodes of trees), while preservingdiversity among tree nodes within different branches through a dedicated graphperturbation module. Finally, we propose an adaptive routing module to identifythe most informative root-to-leaf paths, providing not only the finalprediction but also the multi-granular interpretability for the decision-makingprocess. Extensive experiments on the graph classification benchmarks with bothsynthetic and real-world datasets demonstrate the superiority of TIF ininterpretability, while also delivering a competitive prediction performanceakin to the state-of-the-art counterparts.</description>
      <author>example@mail.com (Jie Yang, Yuwen Wang, Kaixuan Chen, Tongya Zheng, Yihe Zhou, Zhenbang Xiao, Ji Cao, Mingli Song, Shunyu Liu)</author>
      <guid isPermaLink="false">2505.00364v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Pack-PTQ: Advancing Post-training Quantization of Neural Networks by Pack-wise Reconstruction</title>
      <link>http://arxiv.org/abs/2505.00259v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的PTQ方法，称为Pack-PTQ，用于压缩复杂模型。&lt;h4&gt;背景&lt;/h4&gt;PTQ已成为压缩复杂模型的重要解决方案，它倡导使用小的校准数据集并避免端到端重训练。&lt;h4&gt;目的&lt;/h4&gt;解决现有PTQ方法中块状重建忽略跨块依赖和低比特率下准确率下降的问题。&lt;h4&gt;方法&lt;/h4&gt;Pack-PTQ首先设计了一种Hessian引导的自适应打包机制，将块分为非重叠的打包单元，作为重建的基本单位，从而保留跨块依赖并实现准确的量化参数估计。其次，基于打包配置，提出了一种混合精度量化方法，根据打包单元的不同敏感性分配不同的比特宽度，从而进一步提高性能。&lt;h4&gt;主要发现&lt;/h4&gt;在2D图像和3D点云分类任务上进行的广泛实验表明，该方法在性能上优于现有的PTQ方法。&lt;h4&gt;结论&lt;/h4&gt;Pack-PTQ是一种有效的PTQ方法，可以显著提高压缩模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;Post-training quantization (PTQ) has evolved as a prominent solution for compressing complex models, which advocates a small calibration dataset and avoids end-to-end retraining. However, most existing PTQ methods employ block-wise reconstruction, which neglects cross-block dependency and exhibits an noticeable accuracy drop in low-bit cases. To address these limitations, this paper presents a novel PTQ method, dubbed Pack-PTQ. First, we design a Hessian-guided adaptive packing mechanism to partition blocks into non-overlapping packs, which serve as the base unit for reconstruction, thereby preserving the cross-block dependency and enabling accurate quantization parameters estimation. Second, based on the pack configuration, we propose a mixed-precision quantization approach to assign varied bit-widths to packs according to their distinct sensitivities, thereby further enhancing performance. Extensive experiments on 2D image and 3D point cloud classification tasks, using various network architectures, demonstrate the superiority of our method over the state-of-the-art PTQ methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Post-training quantization (PTQ) has evolved as a prominent solution forcompressing complex models, which advocates a small calibration dataset andavoids end-to-end retraining. However, most existing PTQ methods employblock-wise reconstruction, which neglects cross-block dependency and exhibits anotable accuracy drop in low-bit cases. To address these limitations, thispaper presents a novel PTQ method, dubbed Pack-PTQ. First, we design aHessian-guided adaptive packing mechanism to partition blocks intonon-overlapping packs, which serve as the base unit for reconstruction, therebypreserving the cross-block dependency and enabling accurate quantizationparameters estimation. Second, based on the pack configuration, we propose amixed-precision quantization approach to assign varied bit-widths to packsaccording to their distinct sensitivities, thereby further enhancingperformance. Extensive experiments on 2D image and 3D point cloudclassification tasks, using various network architectures, demonstrate thesuperiority of our method over the state-of-the-art PTQ methods.</description>
      <author>example@mail.com (Changjun Li, Runqing Jiang, Zhuo Song, Pengpeng Yu, Ye Zhang, Yulan Guo)</author>
      <guid isPermaLink="false">2505.00259v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Quaternion Wavelet-Conditioned Diffusion Models for Image Super-Resolution</title>
      <link>http://arxiv.org/abs/2505.00334v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at IJCNN 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的图像超分辨率（SR）框架ResQu，它结合了四元数小波预处理框架和潜在扩散模型，以提高从低分辨率图像重建高分辨率图像的质量。&lt;h4&gt;背景&lt;/h4&gt;图像超分辨率是计算机视觉中的基本问题，它在医学成像、卫星分析等领域有广泛的应用。从低分辨率输入重建高分辨率图像对于增强下游任务如目标检测和分割至关重要。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种能够平衡感知质量和结构保真度的图像超分辨率方法，特别是在高放大倍数的情况下。&lt;h4&gt;方法&lt;/h4&gt;ResQu框架结合了四元数小波预处理和潜在扩散模型，并引入了一种新的四元数小波和时间感知的编码器。此外，该方法还利用了如Stable Diffusion等基础模型的生成先验。&lt;h4&gt;主要发现&lt;/h4&gt;在特定领域的数据集上的大量实验表明，ResQu方法在感知质量和标准评估指标上优于许多现有方法。&lt;h4&gt;结论&lt;/h4&gt;ResQu框架能够实现出色的图像超分辨率结果，在感知质量和结构保真度方面取得了显著进步。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel image super-resolution (SR) framework called ResQu, which integrates a quaternion wavelet preprocessing framework with latent diffusion models to enhance the quality of high-resolution image reconstruction from low-resolution inputs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image Super-Resolution is a fundamental problem in computer vision with broadapplications spacing from medical imaging to satellite analysis. The ability toreconstruct high-resolution images from low-resolution inputs is crucial forenhancing downstream tasks such as object detection and segmentation. Whiledeep learning has significantly advanced SR, achieving high-qualityreconstructions with fine-grained details and realistic textures remainschallenging, particularly at high upscaling factors. Recent approachesleveraging diffusion models have demonstrated promising results, yet they oftenstruggle to balance perceptual quality with structural fidelity. In this work,we introduce ResQu a novel SR framework that integrates a quaternion waveletpreprocessing framework with latent diffusion models, incorporating a newquaternion wavelet- and time-aware encoder. Unlike prior methods that simplyapply wavelet transforms within diffusion models, our approach enhances theconditioning process by exploiting quaternion wavelet embeddings, which aredynamically integrated at different stages of denoising. Furthermore, we alsoleverage the generative priors of foundation models such as Stable Diffusion.Extensive experiments on domain-specific datasets demonstrate that our methodachieves outstanding SR results, outperforming in many cases existingapproaches in perceptual quality and standard evaluation metrics. The code willbe available after the revision process.</description>
      <author>example@mail.com (Luigi Sigillo, Christian Bianchi, Danilo Comminiello)</author>
      <guid isPermaLink="false">2505.00334v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Repetition Makes Perfect: Recurrent Sum-GNNs Match Message Passing Limit</title>
      <link>http://arxiv.org/abs/2505.00291v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提供了有限精度参数的循环图神经网络（recurrent GNNs）的精确表达能力界限。&lt;h4&gt;背景&lt;/h4&gt;GNNs的表达能力受到由颜色细化（或Weisfeiler-Leman）算法引起的自然消息传递不变性的限制。&lt;h4&gt;目的&lt;/h4&gt;研究循环GNNs在有限精度参数下的表达能力。&lt;h4&gt;方法&lt;/h4&gt;通过证明循环GNNs（使用求和聚合和ReLU激活）可以模拟遵循颜色细化算法消息传递不变性的任何图算法。&lt;h4&gt;主要发现&lt;/h4&gt;循环GNNs可以达到由上述不变性限制的表达能力极限，这与非循环GNNs形成对比，后者只能在非常弱的形式下实现Weisfeiler-Leman的能力。&lt;h4&gt;结论&lt;/h4&gt;通过引入随机初始化，循环GNNs可以模拟所有图算法，特别是任何多项式时间复杂度的图算法都可以由随机初始化的循环GNN在多项式时间内模拟。&lt;h4&gt;翻译&lt;/h4&gt;我们为具有有限精度参数的循环图神经网络（recurrent GNNs）的表达能力提供了首次精确界限。我们证明，使用求和聚合和ReLU激活的循环GNNs可以模拟遵循颜色细化（或Weisfeiler-Leman）算法诱导的自然消息传递不变性的任何图算法。虽然众所周知，GNNs的表达能力受到这种不变性的限制[Morris等人，AAAI2019；Xu等人，ICLR 2019]，但我们证明循环GNNs实际上可以达到这个极限。这与非循环GNNs形成对比，后者只有在非常弱的形式下才具有Weisfeiler-Leman的能力，即每个图大小都需要不同的GNN模型来计算。我们构建的模拟只在时间和空间上引入了多项式开销。此外，我们展示了通过引入随机初始化，循环GNNs可以模拟所有图算法，这特别意味着任何具有多项式时间复杂度的图算法都可以由随机初始化的循环GNN在多项式时间内模拟。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We provide first tight bounds for the expressivity of Recurrent Graph NeuralNetworks (recurrent GNNs) with finite-precision parameters. We prove thatrecurrent GNNs, with sum aggregation and ReLU activation, can emulate any graphalgorithm that respects the natural message-passing invariance induced by thecolor refinement (or Weisfeiler-Leman) algorithm. While it is well known thatthe expressive power of GNNs is limited by this invariance [Morris et al., AAAI2019; Xu et al., ICLR 2019], we establish that recurrent GNNs can actuallyreach this limit. This is in contrast to non-recurrent GNNs, which have thepower of Weisfeiler-Leman only in a very weak, "non-uniform", sense where everygraph size requires a different GNN model to compute with. The emulation weconstruct introduces only a polynomial overhead in both time and space.  Furthermore, we show that by incorporating random initialization, recurrentGNNs can emulate all graph algorithms, implying in particular that any graphalgorithm with polynomial-time complexity can be emulated by a recurrent GNNwith random initialization, running in polynomial time.</description>
      <author>example@mail.com (Eran Rosenbluth, Martin Grohe)</author>
      <guid isPermaLink="false">2505.00291v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Explorative Curriculum Learning for Strongly Correlated Electron Systems</title>
      <link>http://arxiv.org/abs/2505.00233v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了基于转移学习和课程学习框架的NQS，用于高效稳定地探索量子多体系统的大参数空间，并通过Pairing-Net架构验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;神经网络量子态（NQS）在预测复杂量子多体系统方面取得了进展，但计算成本高，探索参数效率低。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于转移学习和课程学习框架的NQS，以解决计算成本高和参数探索效率低的问题。&lt;h4&gt;方法&lt;/h4&gt;设计了基于转移学习的课程学习框架，并通过Pairing-Net架构在强关联电子系统中实现这一策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法相较于传统方法在计算速度上提高了约200倍，并在优化稳定性上有所改善。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法可以有效地提高NQS的计算效率和稳定性，为探索量子多体系统提供了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，神经网络量子态（NQS）在复杂量子多体系统，如强关联电子系统的预测中取得了显著的进展。然而，其计算成本仍然很高，这使得探索各种相互作用强度和其他物理参数变得效率低下。尽管提出了迁移学习来缓解这一挑战，但将泛化到大规模系统和多样化的参数范围内仍然困难。为了解决这一局限性，我们提出了一种基于迁移学习的NQS课程学习框架的新方法。这有助于高效稳定地在量子多体系统的大参数空间中进行探索。此外，通过通过微扰的角度来解释NQS迁移学习，我们展示了如何将先前的物理知识灵活地纳入课程学习过程中。我们还提出了Pairing-Net架构，这是一种在强关联电子系统中实际实现这一策略的方法，并通过实证验证了其有效性。我们的结果表明，与传统的计算方法相比，该方法在计算速度上提高了大约200倍，在优化稳定性方面也有所改善。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in neural network quantum states (NQS) have enabledhigh-accuracy predictions for complex quantum many-body systems such asstrongly correlated electron systems. However, the computational cost remainsprohibitive, making exploration of the diverse parameters of interactionstrengths and other physical parameters inefficient. While transfer learninghas been proposed to mitigate this challenge, achieving generalization tolarge-scale systems and diverse parameter regimes remains difficult. To addressthis limitation, we propose a novel curriculum learning framework based ontransfer learning for NQS. This facilitates efficient and stable explorationacross a vast parameter space of quantum many-body systems. In addition, byinterpreting NQS transfer learning through a perturbative lens, we demonstratehow prior physical knowledge can be flexibly incorporated into the curriculumlearning process. We also propose Pairing-Net, an architecture to practicallyimplement this strategy for strongly correlated electron systems, andempirically verify its effectiveness. Our results show an approximately200-fold speedup in computation and a marked improvement in optimizationstability compared to conventional methods.</description>
      <author>example@mail.com (Kimihiro Yamazaki, Takuya Konishi, Yoshinobu Kawahara)</author>
      <guid isPermaLink="false">2505.00233v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models as AI Agents for Digital Atoms and Molecules: Catalyzing a New Era in Computational Biophysics</title>
      <link>http://arxiv.org/abs/2505.00270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 3 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了计算生物物理学领域中的LLMs和基于代理的系统如何改变该领域，并介绍了ADAM框架，一个基于多代理的LLMs框架，用于生物物理计算。&lt;h4&gt;背景&lt;/h4&gt;计算生物物理学领域分子数据迅速增长，系统复杂性呈指数增长，LLMs和基于代理的系统正在重塑该领域。&lt;h4&gt;目的&lt;/h4&gt;考察LLMs、智能代理和科学计算交叉领域的近期进展，并介绍ADAM框架。&lt;h4&gt;方法&lt;/h4&gt;ADAM采用模块化设计，结合LLM驱动的语义工具和确定性符号计算，并引入ADAM工具协议（ATP）以实现异步、数据库中心的工具编排。&lt;h4&gt;主要发现&lt;/h4&gt;ADAM通过混合神经符号架构和模块化设计重塑科学工作流程，并促进社区驱动的可扩展性。&lt;h4&gt;结论&lt;/h4&gt;尽管取得了显著进展，但建立基准标准、优化基础模型和代理以及构建开放协作生态系统仍需进一步努力。&lt;h4&gt;翻译&lt;/h4&gt;在计算生物物理学领域，随着分子数据的快速增长和系统复杂性的指数增长，大型语言模型（LLMs）和基于代理的系统正在从根本上改变该领域。本文从LLMs、智能代理和科学计算的交叉领域考察了最近的研究进展，并在此基础上介绍了ADAM（数字原子和分子的代理），一个创新的基于多代理的LLMs框架。ADAM利用先进的AI架构通过模块化设计重塑科学工作流程。它采用混合神经符号架构，结合LLM驱动的语义工具和确定性符号计算。此外，它的ADAM工具协议（ATP）实现了异步、数据库中心的工具编排，促进了社区驱动的可扩展性。尽管取得了显著的进展，但持续的挑战需要进一步努力来建立基准标准、优化基础模型和代理以及构建开放的协作生态系统。ADAM可在https://sidereus-ai.com访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In computational biophysics, where molecular data is expanding rapidly andsystem complexity is increasing exponentially, large language models (LLMs) andagent-based systems are fundamentally reshaping the field. This perspectivearticle examines the recent advances at the intersection of LLMs, intelligentagents, and scientific computation, with a focus on biophysical computation.Building on these advancements, we introduce ADAM (Agent for Digital Atoms andMolecules), an innovative multi-agent LLM-based framework. ADAM employscutting-edge AI architectures to reshape scientific workflows through a modulardesign. It adopts a hybrid neural-symbolic architecture that combinesLLM-driven semantic tools with deterministic symbolic computations. Moreover,its ADAM Tool Protocol (ATP) enables asynchronous, database-centric toolorchestration, fostering community-driven extensibility. Despite thesignificant progress made, ongoing challenges call for further efforts inestablishing benchmarking standards, optimizing foundational models and agents,and building an open collaborative ecosystem. ADAM is accessible athttps://sidereus-ai.com.</description>
      <author>example@mail.com (Yijie Xia, Xiaohan Lin, Zicheng Ma, Jinyuan Hu, Yanheng Li, Zhaoxin Xie, Hao Li, Li Yang, Zhiqiang Zhao, Lijiang Yang, Zhenyu Chen, Yi Qin Gao)</author>
      <guid isPermaLink="false">2505.00270v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Graph Privacy: A Heterogeneous Federated GNN for Trans-Border Financial Data Circulation</title>
      <link>http://arxiv.org/abs/2505.00257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Heterogeneous Federated Graph Neural Network (HFGNN)的方法，旨在解决跨境金融数据共享中的隐私问题。&lt;h4&gt;背景&lt;/h4&gt;金融机构对共享外部数据有强烈需求，但隐私问题导致不同平台间互联困难，数据开放程度低。&lt;h4&gt;目的&lt;/h4&gt;为了有效解决跨境金融数据共享中的隐私问题，确保数据可用但不可见，实现不同行业业务组织的异构数据联合画像。&lt;h4&gt;方法&lt;/h4&gt;该方法将跨境组织的异构业务数据分布作为子图，通过中央服务器将子图之间的共享和流通过程构建为统计异构的全局图。每个子图通过本地训练学习相应的个性化服务模型，选择和更新带有聚合参数的相关子图子集，有效分离和结合子图之间的拓扑和特征信息。&lt;h4&gt;主要发现&lt;/h4&gt;模拟实验结果表明，所提出的方法在准确性和收敛速度方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;HFGNN方法能够有效解决跨境金融数据共享中的隐私问题，提高了数据共享的准确性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The sharing of external data has become a strong demand of financialinstitutions, but the privacy issue has led to the difficulty ofinterconnecting different platforms and the low degree of data openness. Toeffectively solve the privacy problem of financial data in trans-border flowand sharing, to ensure that the data is available but not visible, to realizethe joint portrait of all kinds of heterogeneous data of business organizationsin different industries, we propose a Heterogeneous Federated Graph NeuralNetwork (HFGNN) approach. In this method, the distribution of heterogeneousbusiness data of trans-border organizations is taken as subgraphs, and thesharing and circulation process among subgraphs is constructed as astatistically heterogeneous global graph through a central server. Eachsubgraph learns the corresponding personalized service model through localtraining to select and update the relevant subset of subgraphs with aggregatedparameters, and effectively separates and combines topological and featureinformation among subgraphs. Finally, our simulation experimental results showthat the proposed method has higher accuracy performance and faster convergencespeed than existing methods.</description>
      <author>example@mail.com (Zhizhong Tan, Jiexin Zheng, Kevin Qi Zhang, Wenyong Wang)</author>
      <guid isPermaLink="false">2505.00257v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Node2Vec-DGI-EL: A Hierarchical Graph Representation Learning Model for Ingredient-Disease Association Prediction</title>
      <link>http://arxiv.org/abs/2505.00236v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于分层图表示学习的成分-疾病关联预测模型（Node2Vec-DGI-EL），用于预测中药成分与疾病之间的潜在关联，并验证了该模型的有效性。&lt;h4&gt;背景&lt;/h4&gt;中药作为传统医学的重要组成部分，包含对现代药物开发至关重要的活性成分，具有巨大的治疗潜力和开发价值。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效预测中药成分与疾病之间关联的模型。&lt;h4&gt;方法&lt;/h4&gt;使用Node2Vec算法提取网络节点的嵌入向量作为初始特征，利用DGI算法对网络节点进行深层表示和学习，并采用集成学习方法提高预测准确性和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;该模型显著优于现有方法，AUC达到0.9987，AUPR达到0.9545，表明其具有优越的预测能力。消融实验进一步揭示了各模块的贡献和重要性。案例研究探讨了潜在的关联，如三尖杉酯碱与高血压视网膜病变，甲基牛磺酸与结直肠癌。分子对接实验验证了这些发现。&lt;h4&gt;结论&lt;/h4&gt;Node2Vec-DGI-EL模型专注于中药数据集，并有效地预测了成分-疾病关联，克服了对节点语义信息的依赖。&lt;h4&gt;翻译&lt;/h4&gt;This research proposes an ingredient-disease association prediction model (Node2Vec-DGI-EL) based on hierarchical graph representation learning, for effectively predicting potential associations between traditional Chinese medicine ingredients and diseases, and verifies the effectiveness of the model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional Chinese medicine, as an essential component of traditionalmedicine, contains active ingredients that serve as a crucial source for moderndrug development, holding immense therapeutic potential and development value.A multi-layered and complex network is formed from Chinese medicine to diseasesand used to predict the potential associations between Chinese medicineingredients and diseases. This study proposes an ingredient-disease associationprediction model (Node2Vec-DGI-EL) based on hierarchical graph representationlearning. First, the model uses the Node2Vec algorithm to extract nodeembedding vectors from the network as the initial features of the nodes. Next,the network nodes are deeply represented and learned using the DGI algorithm toenhance the model's expressive power. To improve prediction accuracy androbustness, an ensemble learning method is incorporated to achieve moreaccurate ingredient-disease association predictions. The effectiveness of themodel is then evaluated through a series of theoretical verifications. Theresults demonstrated that the proposed model significantly outperformedexisting methods, achieving an AUC of 0.9987 and an AUPR of 0.9545, therebyindicating superior predictive capability. Ablation experiments furtherrevealed the contribution and importance of each module. Additionally, casestudies explored potential associations, such as triptonide with hypertensiveretinopathy and methyl ursolate with colorectal cancer. Molecular dockingexperiments validated these findings, showing the triptonide-PGR interactionand the methyl ursolate-NFE2L2 interaction can bind stable. In conclusion, theNode2Vec-DGI-EL model focuses on TCM datasets and effectively predictsingredient-disease associations, overcoming the reliance on node semanticinformation.</description>
      <author>example@mail.com (Leifeng Zhang, Xin Dong, Shuaibing Jia, Jianhua Zhang)</author>
      <guid isPermaLink="false">2505.00236v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>CLR-Wire: Towards Continuous Latent Representations for 3D Curve Wireframe Generation</title>
      <link>http://arxiv.org/abs/2504.19174v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SIGGRAPH 2025 (Patent Protected); Project page:  https://vcc.tech/research/2025/CLRWire&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CLR-Wire是一种新的3D曲线线框生成框架，通过将几何和拓扑集成到一个统一的连续潜在表示中，实现了曲线的编码。&lt;h4&gt;背景&lt;/h4&gt;传统的线框生成方法将顶点、边和面解耦，而CLR-Wire将曲线及其拓扑连接编码为连续且固定长度的潜在空间。&lt;h4&gt;目的&lt;/h4&gt;CLR-Wire旨在提供一种能够联合学习几何和拓扑的方法，以生成高质量的线框。&lt;h4&gt;方法&lt;/h4&gt;CLR-Wire使用注意力驱动的变分自编码器（VAE）将曲线编码到潜在空间中，并使用流匹配模型将高斯噪声映射到这些潜在空间，最终解码成完整的3D线框。&lt;h4&gt;主要发现&lt;/h4&gt;与最先进的生成方法相比，CLR-Wire在准确性、新颖性和多样性方面取得了显著改进，为CAD设计、几何重建和3D内容创作提供了一个高效且全面的解决方案。&lt;h4&gt;结论&lt;/h4&gt;CLR-Wire提供了一种细粒度的复杂形状和不规则拓扑建模方法，并支持无条件和基于点云或图像输入的条件生成。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为CLR-Wire的新型3D曲线线框生成框架，该框架将几何和拓扑集成到一个统一的连续潜在表示中。与将顶点、边和面解耦的传统方法不同，CLR-Wire通过使用注意力驱动的变分自编码器（VAE）将曲线及其拓扑连接编码为连续且固定长度的潜在空间。这种统一的方法促进了几何和拓扑的联合学习和生成。为了生成线框，我们采用流匹配模型将高斯噪声逐步映射到这些潜在空间，然后解码成完整的3D线框。我们的方法提供了复杂形状和不规则拓扑的细粒度建模，并支持无条件和基于点云或图像输入的条件生成。实验结果表明，与最先进的生成方法相比，我们的方法在准确性、新颖性和多样性方面取得了显著的改进，为CAD设计、几何重建和3D内容创作提供了一个高效且全面的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce CLR-Wire, a novel framework for 3D curve-based wireframegeneration that integrates geometry and topology into a unified ContinuousLatent Representation. Unlike conventional methods that decouple vertices,edges, and faces, CLR-Wire encodes curves as Neural Parametric Curves alongwith their topological connectivity into a continuous and fixed-length latentspace using an attention-driven variational autoencoder (VAE). This unifiedapproach facilitates joint learning and generation of both geometry andtopology. To generate wireframes, we employ a flow matching model toprogressively map Gaussian noise to these latents, which are subsequentlydecoded into complete 3D wireframes. Our method provides fine-grained modelingof complex shapes and irregular topologies, and supports both unconditionalgeneration and generation conditioned on point cloud or image inputs.Experimental results demonstrate that, compared with state-of-the-artgenerative approaches, our method achieves substantial improvements inaccuracy, novelty, and diversity, offering an efficient and comprehensivesolution for CAD design, geometric reconstruction, and 3D content creation.</description>
      <author>example@mail.com (Xueqi Ma, Yilin Liu, Tianlong Gao, Qirui Huang, Hui Huang)</author>
      <guid isPermaLink="false">2504.19174v2</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Towards Autonomous Micromobility through Scalable Urban Simulation</title>
      <link>http://arxiv.org/abs/2505.00690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 Highlight. Project page:  https://metadriverse.github.io/urban-sim/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用人工智能辅助微移动设备（如配送机器人和电动滑板车）在繁忙的城市环境中提高安全性和效率的方法。&lt;h4&gt;背景&lt;/h4&gt;微移动设备作为一种替代传统车辆移动的方案，目前主要依赖人工操作，这在充满不确定性和行人的城市环境中存在安全隐患和效率问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种可扩展的城市模拟解决方案，以推进自主微移动。&lt;h4&gt;方法&lt;/h4&gt;构建了URBAN-SIM，一个用于在大规模训练具身智能体在交互式城市场景中的高性能机器人学习平台。URBAN-SIM包含三个关键模块：分层城市生成流水线、交互式动力学生成策略和异步场景采样方案。同时，提出了URBAN-BENCH，一套用于评估智能体实现自主微移动能力的基本任务和基准。&lt;h4&gt;主要发现&lt;/h4&gt;URBAN-BENCH包括基于智能体三个核心技能（城市移动、城市导航和城市穿越）的八个任务。实验评估了四种不同具身形式的机器人（如轮式和腿式机器人）在这些任务中的表现，揭示了每种机器人的优势和局限性。&lt;h4&gt;结论&lt;/h4&gt;通过实验验证了所提出的方法在提高微移动设备在复杂城市环境中的安全性和效率方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Micromobility, which utilizes lightweight mobile machines moving in urbanpublic spaces, such as delivery robots and mobility scooters, emerges as apromising alternative to vehicular mobility. Current micromobility dependsmostly on human manual operation (in-person or remote control), which raisessafety and efficiency concerns when navigating busy urban environments full ofunpredictable obstacles and pedestrians. Assisting humans with AI agents inmaneuvering micromobility devices presents a viable solution for enhancingsafety and efficiency. In this work, we present a scalable urban simulationsolution to advance autonomous micromobility. First, we build URBAN-SIM - ahigh-performance robot learning platform for large-scale training of embodiedagents in interactive urban scenes. URBAN-SIM contains three critical modules:Hierarchical Urban Generation pipeline, Interactive Dynamics Generationstrategy, and Asynchronous Scene Sampling scheme, to improve the diversity,realism, and efficiency of robot learning in simulation. Then, we proposeURBAN-BENCH - a suite of essential tasks and benchmarks to gauge variouscapabilities of the AI agents in achieving autonomous micromobility.URBAN-BENCH includes eight tasks based on three core skills of the agents:Urban Locomotion, Urban Navigation, and Urban Traverse. We evaluate four robotswith heterogeneous embodiments, such as the wheeled and legged robots, acrossthese tasks. Experiments on diverse terrains and urban structures reveal eachrobot's strengths and limitations.</description>
      <author>example@mail.com (Wayne Wu, Honglin He, Chaoyuan Zhang, Jack He, Seth Z. Zhao, Ran Gong, Quanyi Li, Bolei Zhou)</author>
      <guid isPermaLink="false">2505.00690v1</guid>
      <pubDate>Fri, 02 May 2025 14:11:45 +0800</pubDate>
    </item>
    <item>
      <title>Recursive KL Divergence Optimization: A Dynamic Framework for Representation Learning</title>
      <link>http://arxiv.org/abs/2504.21707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将现代表征学习目标重新定义为局部条件分布上的递归散度对齐过程的方法。&lt;h4&gt;背景&lt;/h4&gt;现有框架如信息对比学习（I-Con）通过固定邻域条件间的KL散度统一了多个学习范式，但忽视了学习过程中的关键递归结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为Recursive KLDivergence Optimization（RKDO）的动态公式，将表征学习视为KL散度在数据邻域上的演变。&lt;h4&gt;方法&lt;/h4&gt;RKDO捕捉对比聚类和降维方法作为静态切片，同时提供了一条新的路径以实现模型稳定性和局部适应。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，RKDO提供了双重效率优势：与静态方法相比，在三个不同的数据集上损失值降低约30%，并且所需计算资源减少了60%至80%。&lt;h4&gt;结论&lt;/h4&gt;RKDO的递归更新机制为表征学习提供了一种更有效的优化景观，对资源受限的应用具有重大意义。&lt;h4&gt;翻译&lt;/h4&gt;We propose a generalization of modern representation learning objectives by reframing them as recursive divergence alignment processes over localized conditional distributions. While recent frameworks like Information Contrastive Learning (I-Con) unify multiple learning paradigms through KL divergence between fixed neighborhood conditionals, we argue this view underplays a crucial recursive structure inherent in the learning process. We introduce Recursive KLDivergence Optimization (RKDO), a dynamic formalism where representation learning is framed as the evolution of KL divergences across data neighborhoods. This formulation captures contrastive clustering and dimensionality reduction methods as static slices while offering a new path to model stability and local adaptation. Our experiments demonstrate that RKDO offers dual efficiency advantages: approximately 30 percent lower loss values compared to static approaches across three different datasets and 60 to 80 percent reduction in computational resources needed to achieve comparable results. This suggests that RKDO's recursive updating mechanism provides a fundamentally more efficient optimization landscape for representation learning with significant implications for resource constrained applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/anthonymartin/RKDO-recursive-kl-divergence-optimization&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a generalization of modern representation learning objectives byreframing them as recursive divergence alignment processes over localizedconditional distributions While recent frameworks like Information ContrastiveLearning I-Con unify multiple learning paradigms through KL divergence betweenfixed neighborhood conditionals we argue this view underplays a crucialrecursive structure inherent in the learning process. We introduce Recursive KLDivergence Optimization RKDO a dynamic formalism where representation learningis framed as the evolution of KL divergences across data neighborhoods. Thisformulation captures contrastive clustering and dimensionality reductionmethods as static slices while offering a new path to model stability and localadaptation. Our experiments demonstrate that RKDO offers dual efficiencyadvantages approximately 30 percent lower loss values compared to staticapproaches across three different datasets and 60 to 80 percent reduction incomputational resources needed to achieve comparable results. This suggeststhat RKDOs recursive updating mechanism provides a fundamentally more efficientoptimization landscape for representation learning with significantimplications for resource constrained applications.</description>
      <author>example@mail.com (Anthony D Martin)</author>
      <guid isPermaLink="false">2504.21707v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
  <item>
      <title>REHEARSE-3D: A Multi-modal Emulated Rain Dataset for 3D Point Cloud De-raining</title>
      <link>http://arxiv.org/abs/2504.21699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究传感器退化对自动驾驶的影响，特别是在大雨天气下，如何通过新的数据集和模型来改善LiDAR点云的去雨处理。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶系统在恶劣天气下可能会因为传感器退化而导致安全问题，如LiDAR点云质量下降。&lt;h4&gt;目的&lt;/h4&gt;发布一个新的、大规模的多模态模拟雨数据集REHEARSE-3D，以促进3D点云去雨研究。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含高分辨率LiDAR数据和4D雷达数据的点云去雨数据集，并利用该数据集进行雨滴检测和去除的基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;REHEARSE-3D数据集是最大的点标注数据集，具有高分辨率LiDAR数据，并记录了白天和夜晚的4D雷达点云数据，同时包含了雨特征信息。&lt;h4&gt;结论&lt;/h4&gt;通过REHEARSE-3D数据集，可以评估和比较不同的统计和深度学习模型在融合LiDAR和4D雷达点云的去雨性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传感器退化对自动驾驶构成了重大挑战。在暴雨天气中，雨滴的干扰会严重影响LiDAR点云的质量，导致不准确的点测量。这反过来可能导致安全担忧，如果自动驾驶系统没有意识到这种变化，即如果它们无法识别这种变化。在本研究中，我们发布了一个新的、大规模的多模态模拟雨数据集REHEARSE-3D，以促进3D点云去雨研究。与最相关的竞争对手相比，我们的数据集在几个方面是独特的。首先，它是最大的点标注数据集，其次，它是唯一一个包含高分辨率LiDAR数据（LiDAR-256）的数据集，该数据集在受控的天气环境中记录了白天和夜晚的4D雷达点云。此外，REHEARSE-3D涉及雨特征信息，这对于传感器噪声建模以及分析点级别的天气影响都具有重要意义。利用REHEARSE-3D，我们基准测试了融合LiDAR和4D雷达点云中的雨滴检测和去除。我们的综合研究进一步评估了各种统计和深度学习模型。在发表后，数据集和基准模型将在以下网址公开：https://sporsho.github.io/REHEARSE3D。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sensor degradation poses a significant challenge in autonomous driving.During heavy rainfall, the interference from raindrops can adversely affect thequality of LiDAR point clouds, resulting in, for instance, inaccurate pointmeasurements. This, in turn, can potentially lead to safety concerns ifautonomous driving systems are not weather-aware, i.e., if they are unable todiscern such changes. In this study, we release a new, large-scale, multi-modalemulated rain dataset, REHEARSE-3D, to promote research advancements in 3Dpoint cloud de-raining. Distinct from the most relevant competitors, ourdataset is unique in several respects. First, it is the largest point-wiseannotated dataset, and second, it is the only one with high-resolution LiDARdata (LiDAR-256) enriched with 4D Radar point clouds logged in both daytime andnighttime conditions in a controlled weather environment. Furthermore,REHEARSE-3D involves rain-characteristic information, which is of significantvalue not only for sensor noise modeling but also for analyzing the impact ofweather at a point level. Leveraging REHEARSE-3D, we benchmark raindropdetection and removal in fused LiDAR and 4D Radar point clouds. Ourcomprehensive study further evaluates the performance of various statisticaland deep-learning models. Upon publication, the dataset and benchmark modelswill be made publicly available at: https://sporsho.github.io/REHEARSE3D.</description>
      <author>example@mail.com (Abu Mohammed Raisuddin, Jesper Holmblad, Hamed Haghighi, Yuri Poledna, Maikol Funk Drechsler, Valentina Donzella, Eren Erdal Aksoy)</author>
      <guid isPermaLink="false">2504.21699v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics</title>
      <link>http://arxiv.org/abs/2504.21716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Austrian Robotics Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种基于LLM驱动的机器人系统，用于自主家庭物品管理，通过内存增强的任务规划实现机器人执行高级用户命令并跟踪过去的行为。&lt;h4&gt;背景&lt;/h4&gt;现有的家庭物品管理机器人缺乏有效的任务规划和长期物体跟踪能力。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够自主管理家庭物品的机器人系统，并提高其任务规划和记忆召回能力。&lt;h4&gt;方法&lt;/h4&gt;该系统采用LLM驱动的代理编排架构，包括一个路由代理、一个任务规划代理和一个知识库代理，每个代理都由特定于任务的LLM提供支持。系统利用情境学习避免显式模型训练，并利用RAG（关系图模型）从过去的交互中检索上下文，增强长期物体跟踪。结合Grounded SAM和LLaMa3.2-Vision提供鲁棒的物体检测，以促进任务规划中的语义场景理解。&lt;h4&gt;主要发现&lt;/h4&gt;系统在三个家庭场景中的评估显示，任务规划准确率很高，并且由于RAG的引入，记忆召回能力得到了改善。Qwen2.5在专用代理中表现最佳，而LLaMa3.1在路由任务中表现突出。&lt;h4&gt;结论&lt;/h4&gt;该系统有效地提高了家庭物品管理的自主性，并展示了在多个场景中实现高任务规划准确率的能力。&lt;h4&gt;翻译&lt;/h4&gt;We present an embodied robotic system with an LLM-driven agent-orchestration architecture for autonomous household object management. The system integrates memory-augmented task planning, enabling robots to execute high-level user commands while tracking past actions. It employs three specialized agents: a routing agent, a task planning agent, and a knowledge base agent, each powered by task-specific LLMs. By leveraging in-context learning, our system avoids the need for explicit model training. RAG enables the system to retrieve context from past interactions, enhancing long-term object tracking. A combination of Grounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating semantic scene understanding for task planning. Evaluation across three household scenarios demonstrates high task planning accuracy and an improvement in memory recall due to RAG. Specifically, Qwen2.5 yields best performance for specialized agents, while LLaMa3.1 excels in routing tasks. The source code is available at: https://github.com/marc1198/chat-hsr.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present an embodied robotic system with an LLM-driven agent-orchestrationarchitecture for autonomous household object management. The system integratesmemory-augmented task planning, enabling robots to execute high-level usercommands while tracking past actions. It employs three specialized agents: arouting agent, a task planning agent, and a knowledge base agent, each poweredby task-specific LLMs. By leveraging in-context learning, our system avoids theneed for explicit model training. RAG enables the system to retrieve contextfrom past interactions, enhancing long-term object tracking. A combination ofGrounded SAM and LLaMa3.2-Vision provides robust object detection, facilitatingsemantic scene understanding for task planning. Evaluation across threehousehold scenarios demonstrates high task planning accuracy and an improvementin memory recall due to RAG. Specifically, Qwen2.5 yields best performance forspecialized agents, while LLaMA3.1 excels in routing tasks. The source code isavailable at: https://github.com/marc1198/chat-hsr.</description>
      <author>example@mail.com (Marc Glocker, Peter Hönig, Matthias Hirschmanner, Markus Vincze)</author>
      <guid isPermaLink="false">2504.21716v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>LRBO2: Improved 3D Vision Based Hand-Eye Calibration for Collaborative Robot Arm</title>
      <link>http://arxiv.org/abs/2504.21619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的手眼标定方法，用于协作机器人领域，该方法可以减少对外部标定对象的需求，并实现快速标定。&lt;h4&gt;背景&lt;/h4&gt;手眼标定在协作机器人领域是常见问题，涉及视觉传感器与机器人法兰之间的变换矩阵确定，但传统方法耗时且不便。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需外部标定对象的新方法，以减少标定时间和提高效率。&lt;h4&gt;方法&lt;/h4&gt;改进了LRBO方法，通过生成通用数据集进行点云注册，以对齐机器人底座点云和扫描数据。同时，通过模拟和实际工业环境中的实验进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过模拟14个品牌的机器人臂进行测试，表现与现有商业手眼标定解决方案相当，且标定过程仅需几秒钟。&lt;h4&gt;结论&lt;/h4&gt;该方法提供了一个用户友好的手眼标定解决方案，代码已公开。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了在协作机器人领域，一种新的手眼标定方法，通过减少对外部标定对象的需求和缩短标定时间，提高了标定的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hand-eye calibration is a common problem in the field of collaborativerobotics, involving the determination of the transformation matrix between thevisual sensor and the robot flange to enable vision-based robotic tasks.However, this process typically requires multiple movements of the robot armand an external calibration object, making it both time-consuming andinconvenient, especially in scenarios where frequent recalibration isnecessary. In this work, we extend our previous method, Look at Robot Base Once(LRBO), which eliminates the need for external calibration objects such as achessboard. We propose a generic dataset generation approach for point cloudregistration, focusing on aligning the robot base point cloud with the scanneddata. Furthermore, a more detailed simulation study is conducted involvingseveral different collaborative robot arms, followed by real-world experimentsin an industrial setting. Our improved method is simulated and evaluated usinga total of 14 robotic arms from 9 different brands, including KUKA, UniversalRobots, UFACTORY, and Franka Emika, all of which are widely used in the fieldof collaborative robotics. Physical experiments demonstrate that our extendedapproach achieves performance comparable to existing commercial hand-eyecalibration solutions, while completing the entire calibration procedure injust a few seconds. In addition, we provide a user-friendly hand-eyecalibration solution, with the code publicly available atgithub.com/leihui6/LRBO2.</description>
      <author>example@mail.com (Leihui Li, Lixuepiao Wan, Volker Krueger, Xuping Zhang)</author>
      <guid isPermaLink="false">2504.21619v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Convergence rate for Nearest Neighbour matching: geometry of the domain and higher-order regularity</title>
      <link>http://arxiv.org/abs/2504.21633v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了从部分观察数据和缺失结果中估计某些数学期望的问题，特别是在迁移学习、反事实分析或因果推断等领域。论文分析了匹配估计器的性质，特别是其偏差的高阶特性。&lt;h4&gt;背景&lt;/h4&gt;匹配估计器，基于k-近邻的估计器，在上述领域中广泛应用。已知这类估计器的方差可以以参数速率收敛到零，但当协变量的维度大于2时，其偏差可能以较慢的速率收敛，这使得偏差分析尤为重要。&lt;h4&gt;目的&lt;/h4&gt;提供匹配估计器偏差的高阶性质，并分析避免边界偏差问题的几何条件。&lt;h4&gt;方法&lt;/h4&gt;不假设协变量目标分布的支持严格包含在源分布的支持中，分析了两个几何条件，并展示了这些条件比通常的凸支持假设更为一般，从而改进了现有结果。&lt;h4&gt;主要发现&lt;/h4&gt;证明了当协变量的维度小于4时，Abadie和Imbens（2006）研究的匹配估计器对于平均处理效应可以渐近有效，这一结果在维度1时已知。&lt;h4&gt;结论&lt;/h4&gt;本文提供了一种更通用的方法来分析匹配估计器的偏差，并展示了在特定条件下，匹配估计器可以达到渐近有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从部分观察数据和缺失结果中估计某些数学期望是一个在许多领域（如迁移学习、反事实分析或因果推断）中遇到的核心问题。匹配估计器，基于k-近邻的估计器，在此背景下被广泛使用。已知此类估计器的方差可以以参数速率收敛到零，但当协变量的维度大于2时，其偏差可能以较慢的速率收敛，这使得偏差分析尤为重要。本文提供了偏差的高阶性质。与现有文献相比，本文不假设协变量目标分布的支持严格包含在源分布的支持中，并分析了两个几何条件以避免此类边界偏差问题。本文表明，这些条件比通常的凸支持假设更为一般，从而改进了现有结果。此外，本文表明，当协变量的维度小于4时，Abadie和Imbens（2006）研究的匹配估计器对于平均处理效应可以渐近有效，这一结果在维度1时已知。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating some mathematical expectations from partially observed data and inparticular missing outcomes is a central problem encountered in numerous fieldssuch as transfer learning, counterfactual analysis or causal inference.Matching estimators, estimators based on k-nearest neighbours, are widely usedin this context. It is known that the variance of such estimators can convergeto zero at a parametric rate, but their bias can have a slower rate when thedimension of the covariates is larger than 2. This makes analysis of this biasparticularly important. In this paper, we provide higher order properties ofthe bias. In contrast to the existing literature related to this problem, we donot assume that the support of the target distribution of the covariates isstrictly included in that of the source, and we analyse two geometricconditions on the support that avoid such boundary bias problems. We show thatthese conditions are much more general than the usual convex supportassumption, leading to an improvement of existing results. Furthermore, we showthat the matching estimator studied by Abadie and Imbens (2006) for the averagetreatment effect can be asymptotically efficient when the dimension of thecovariates is less than 4, a result only known in dimension 1.</description>
      <author>example@mail.com (Simon Viel, Lionel Truquet, Ikko Yamane)</author>
      <guid isPermaLink="false">2504.21633v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Why Compress What You Can Generate? When GPT-4o Generation Ushers in Image Compression Fields</title>
      <link>http://arxiv.org/abs/2504.21814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了AIGC基础模型在图像压缩领域的应用潜力，通过实验证明了结合结构扫描提示和GPT-4o图像生成功能在超低比特率下的优异性能。&lt;h4&gt;背景&lt;/h4&gt;AIGC基础模型的快速发展改变了图像压缩的范式，使得大部分像素级的转换和编码可以被放弃。&lt;h4&gt;目的&lt;/h4&gt;探究GPT-4o图像生成在图像压缩领域的潜在应用，并比较其与现有图像压缩技术的性能。&lt;h4&gt;方法&lt;/h4&gt;研究了文本编码和多模态编码（即文本+极低分辨率图像）两种压缩范式，通过GPT-4o图像生成功能生成所有/大部分像素级信息，而非压缩。&lt;h4&gt;主要发现&lt;/h4&gt;提出的结构扫描提示机制能够保持解码过程中的语义和结构一致性，实验结果显示在超低比特率下，结合结构扫描提示和GPT-4o的图像生成功能表现出色。&lt;h4&gt;结论&lt;/h4&gt;AIGC生成在图像压缩领域具有巨大的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：AIGC基础模型的高速发展颠覆了图像压缩的范式，为放弃大多数像素级转换和编码铺平了道路，迫使我们思考：如果AIGC基础模型能够从一些紧凑的描述符（如文本或线索）中忠实生成复杂结构和精细细节，那么为什么还要压缩可以生成的内容？幸运的是，OpenAI最近推出的GPT-4o图像生成在跨模态生成、编辑和设计能力方面取得了令人印象深刻的成果，这激励我们通过探索其在图像压缩领域的潜力来回答上述问题。在本研究中，我们调查了两种典型的压缩范式：文本编码和多模态编码（即文本+极低分辨率图像），其中所有/大部分像素级信息是通过GPT-4o图像生成功能生成，而不是通过先进的GPT-4o图像生成功能进行压缩。核心挑战在于如何在解码过程中保持语义和结构一致性。为了克服这一挑战，我们提出了一种结构扫描提示工程机制，将图像转换为文本空间，作为GPT-4o图像生成的条件。大量实验表明，我们设计的结构扫描提示与GPT-4o图像生成功能的结合在超低比特率下实现了令人印象深刻的性能，进一步表明了AIGC生成在图像压缩领域的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of AIGC foundation models has revolutionized theparadigm of image compression, which paves the way for the abandonment of mostpixel-level transform and coding, compelling us to ask: why compress what youcan generate if the AIGC foundation model is powerful enough to faithfullygenerate intricate structure and fine-grained details from nothing more thansome compact descriptors, i.e., texts, or cues. Fortunately, recent GPT-4oimage generation of OpenAI has achieved impressive cross-modality generation,editing, and design capabilities, which motivates us to answer the abovequestion by exploring its potential in image compression fields. In this work,we investigate two typical compression paradigms: textual coding and multimodalcoding (i.e., text + extremely low-resolution image), where all/mostpixel-level information is generated instead of compressing via the advancedGPT-4o image generation function. The essential challenge lies in how tomaintain semantic and structure consistency during the decoding process. Toovercome this, we propose a structure raster-scan prompt engineering mechanismto transform the image into textual space, which is compressed as the conditionof GPT-4o image generation. Extensive experiments have shown that thecombination of our designed structural raster-scan prompts and GPT-4o's imagegeneration function achieved the impressive performance compared with recentmultimodal/generative image compression at ultra-low bitrate, furtherindicating the potential of AIGC generation in image compression fields.</description>
      <author>example@mail.com (Yixin Gao, Xiaohan Pan, Xin Li, Zhibo Chen)</author>
      <guid isPermaLink="false">2504.21814v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation</title>
      <link>http://arxiv.org/abs/2504.21650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project homepage: https://zhouhyocean.github.io/holotime/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HoloTime框架通过集成视频扩散模型和360度4D场景重建方法，能够从单张图片生成全景视频，并转化为4D资产，提供沉浸式4D体验。&lt;h4&gt;背景&lt;/h4&gt;现有的扩散模型主要关注静态3D场景或对象级别的动态，限制了提供真正沉浸式体验的能力。&lt;h4&gt;目的&lt;/h4&gt;提出HoloTime框架，解决现有扩散模型在提供沉浸式体验方面的不足。&lt;h4&gt;方法&lt;/h4&gt;引入360World数据集，提出Panoramic Animator模型将全景图像转换为高质量全景视频，以及Panoramic Space-Time Reconstruction方法将全景视频转换为4D点云。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，HoloTime在全景视频生成和4D场景重建方面表现出优越性，能够创建更吸引人、更逼真的沉浸式环境。&lt;h4&gt;结论&lt;/h4&gt;HoloTime框架能够提升VR和AR应用中的用户体验，实现更加沉浸式的4D体验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of diffusion models holds the promise ofrevolutionizing the application of VR and AR technologies, which typicallyrequire scene-level 4D assets for user experience. Nonetheless, existingdiffusion models predominantly concentrate on modeling static 3D scenes orobject-level dynamics, constraining their capacity to provide truly immersiveexperiences. To address this issue, we propose HoloTime, a framework thatintegrates video diffusion models to generate panoramic videos from a singleprompt or reference image, along with a 360-degree 4D scene reconstructionmethod that seamlessly transforms the generated panoramic video into 4D assets,enabling a fully immersive 4D experience for users. Specifically, to tame videodiffusion models for generating high-fidelity panoramic videos, we introducethe 360World dataset, the first comprehensive collection of panoramic videossuitable for downstream 4D scene reconstruction tasks. With this curateddataset, we propose Panoramic Animator, a two-stage image-to-video diffusionmodel that can convert panoramic images into high-quality panoramic videos.Following this, we present Panoramic Space-Time Reconstruction, which leveragesa space-time depth estimation method to transform the generated panoramicvideos into 4D point clouds, enabling the optimization of a holistic 4DGaussian Splatting representation to reconstruct spatially and temporallyconsistent 4D scenes. To validate the efficacy of our method, we conducted acomparative analysis with existing approaches, revealing its superiority inboth panoramic video generation and 4D scene reconstruction. This demonstratesour method's capability to create more engaging and realistic immersiveenvironments, thereby enhancing user experiences in VR and AR applications.</description>
      <author>example@mail.com (Haiyang Zhou, Wangbo Yu, Jiawen Guan, Xinhua Cheng, Yonghong Tian, Li Yuan)</author>
      <guid isPermaLink="false">2504.21650v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Visual Layer Selection in Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2504.21447v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures, submitted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多模态大语言模型（MLLMs）中的视觉层选择问题，提出了一种分层表示相似度方法来对CLIP-ViT的层进行分类，并通过实验验证了不同层对MLLM性能的影响。&lt;h4&gt;背景&lt;/h4&gt;现有的MLLMs通常使用CLIP-ViT作为视觉编码器，但不同层捕获的信息类型不同，浅层关注细节，深层与文本语义更接近。目前，大多数MLLMs基于经验选择视觉特征，而非系统分析。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来对CLIP-ViT层进行分类，并评估其对MLLM性能的影响，从而为视觉表示学习提供原则性的研究。&lt;h4&gt;方法&lt;/h4&gt;提出分层表示相似度方法，对CLIP-ViT层进行分组，并训练了不同参数规模的LLaVA-style模型，通过10个数据集和4个任务的实验来评估不同层对性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;发现深层层对OCR任务至关重要；浅层和中层在涉及计数、定位和对象定位的推理任务中显著优于深层层；跨浅层、中层和深层层的轻量级特征融合在10个数据集中有9个实现了性能提升。&lt;h4&gt;结论&lt;/h4&gt;本文首次对MLLM中的视觉层选择进行了原则性研究，为深入探究MLLM的视觉表示学习奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal large language models (MLLMs) have achieved impressive performance across a wide range of tasks, typically using CLIP-ViT as their visual encoder due to its strong text-image alignment capabilities. While prior studies suggest that different CLIP-ViT layers capture different types of information, with shallower layers focusing on fine visual details and deeper layers aligning more closely with textual semantics, most MLLMs still select visual features based on empirical heuristics rather than systematic analysis. In this work, we propose a Layer-wise Representation Similarity approach to group CLIP-ViT layers with similar behaviors into {shallow, middle, and deep} categories and assess their impact on MLLM performance. Building on this foundation, we revisit the visual layer selection problem in MLLMs at scale, training LLaVA-style models ranging from 1.4B to 7B parameters. Through extensive experiments across 10 datasets and 4 tasks, we find that: (1) deep layers are essential for OCR tasks; (2) shallow and middle layers substantially outperform deep layers on reasoning tasks involving counting, positioning, and object localization; (3) a lightweight fusion of features across shallow, middle, and deep layers consistently outperforms specialized fusion baselines and single-layer selections, achieving gains on 9 out of 10 datasets. Our work offers the first principled study of visual layer selection in MLLMs, laying the groundwork for deeper investigations into visual representation learning for MLLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal large language models (MLLMs) have achieved impressive performanceacross a wide range of tasks, typically using CLIP-ViT as their visual encoderdue to its strong text-image alignment capabilities. While prior studiessuggest that different CLIP-ViT layers capture different types of information,with shallower layers focusing on fine visual details and deeper layersaligning more closely with textual semantics, most MLLMs still select visualfeatures based on empirical heuristics rather than systematic analysis. In thiswork, we propose a Layer-wise Representation Similarity approach to groupCLIP-ViT layers with similar behaviors into {shallow, middle, and deep}categories and assess their impact on MLLM performance. Building on thisfoundation, we revisit the visual layer selection problem in MLLMs at scale,training LLaVA-style models ranging from 1.4B to 7B parameters. Throughextensive experiments across 10 datasets and 4 tasks, we find that: (1) deeplayers are essential for OCR tasks; (2) shallow and middle layers substantiallyoutperform deep layers on reasoning tasks involving counting, positioning, andobject localization; (3) a lightweight fusion of features across shallow,middle, and deep layers consistently outperforms specialized fusion baselinesand single-layer selections, achieving gains on 9 out of 10 datasets. Our workoffers the first principled study of visual layer selection in MLLMs, layingthe groundwork for deeper investigations into visual representation learningfor MLLMs.</description>
      <author>example@mail.com (Haoran Chen, Junyan Lin, Xinhao Chen, Yue Fan, Xin Jin, Hui Su, Jianfeng Dong, Jinlan Fu, Xiaoyu Shen)</author>
      <guid isPermaLink="false">2504.21447v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Overlapping data in network protocols: bridging OS and NIDS reassembly gap</title>
      <link>http://arxiv.org/abs/2504.21618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了网络入侵检测系统（NIDS）在处理重叠数据块攻击时的抵抗能力，提出了新的分析方法，并分析了操作系统和网络入侵检测系统的重组行为。&lt;h4&gt;背景&lt;/h4&gt;IPv4、IPv6和TCP协议允许将数据包分割成多个块，这些块可能包含重叠的数据部分，操作系统网络堆栈的实现可能会以不同的方式重新组装这些重叠部分。&lt;h4&gt;目的&lt;/h4&gt;研究NIDS在处理重叠数据块攻击时的抵抗能力，并提出解决方案。&lt;h4&gt;方法&lt;/h4&gt;1. 扩展了插入和规避攻击的表征，以解决重叠上下文中的局限性。2. 提出使用艾伦的时间区间代数来建模重叠类型。3. 分析了操作系统和网络入侵检测系统在处理建模的重叠测试案例时的重组行为。&lt;h4&gt;主要发现&lt;/h4&gt;1. 操作系统的重组策略会随时间变化。2. 所有测试的网络入侵检测系统都容易受到基于重叠的规避和插入攻击。&lt;h4&gt;结论&lt;/h4&gt;NIDS在处理重叠数据块攻击时存在局限性，需要进一步的研究和改进来提高其安全性。&lt;h4&gt;翻译&lt;/h4&gt;This paper discusses the resistance of Network Intrusion Detection Systems (NIDS) to overlapping data chunk attacks, proposes new analytical methods, and analyzes the reassembly behavior of operating systems and NIDS when processing modeled overlapping test cases.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; IPv4, IPv6, and TCP have a common mechanism allowing one to split an originaldata packet into several chunks. Such chunked packets may have overlapping dataportions and, OS network stack implementations may reassemble these overlapsdifferently. A Network Intrusion Detection System (NIDS) that tries toreassemble a given flow data has to use the same reassembly policy as themonitored host OS; otherwise, the NIDS or the host may be subject to attack. Inthis paper, we provide several contributions that enable us to analyze NIDSresistance to overlapping data chunks-based attacks. First, we extendstate-of-the-art insertion and evasion attack characterizations to addresstheir limitations in an overlap-based context. Second, we propose a new way tomodel overlap types using Allen's interval algebra, a spatio-temporalreasoning. This new modeling allows us to formalize overlap test cases, whichensures exhaustiveness in overlap coverage and eases the reasoning about anduse of reassembly policies. Third, we analyze the reassembly behavior ofseveral OSes and NIDSes when processing the modeled overlap test cases. We showthat 1) OS reassembly policies evolve over time and 2) all the tested NIDSesare (still) vulnerable to overlap-based evasion and insertion attacks.</description>
      <author>example@mail.com (Lucas Aubard, Johan Mazel, Gilles Guette, Pierre Chifflier)</author>
      <guid isPermaLink="false">2504.21618v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Multi-Task Learning for Particle Collision Event Reconstruction with Heterogeneous Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.21844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 10 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的异构图神经网络（HGNN）架构，用于解决大型强子对撞机中粒子碰撞事件重建和分析的挑战。&lt;h4&gt;背景&lt;/h4&gt;随着大型强子对撞机中亮度边界的增长，粒子碰撞事件的重建和分析面临挑战，包括数据采集阶段的延迟和存储需求增加，以及背景水平升高和粒子顶点误关联等问题。&lt;h4&gt;目的&lt;/h4&gt;开发更全面和可扩展的重建方法，利用机器学习的最新进展来解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的HGNN架构，具有不同粒子碰撞关系的独特表示，并集成了图剪枝层以提高可扩展性。该网络在模拟LHCb实验的环境中，采用多任务范式进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;HGNN显著提高了美子介子重建性能，并在单个框架内同时执行粒子顶点关联和图剪枝。该网络量化了重建和剪枝性能，展示了随着事件复杂性的增加而增强的推理时间可扩展性，并使用加权消息传递方案来减轻潜在的性能损失。&lt;h4&gt;结论&lt;/h4&gt;HGNN是一种有效的工具，可以解决大型强子对撞机中粒子碰撞事件重建和分析的挑战，并有望提高实验的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着大型强子对撞机亮度边界的增长，对粒子碰撞事件的重建和分析提出了挑战。增加的粒子多重性正在考验数据采集阶段的延迟和存储需求，同时出现了新的复杂问题，包括更高的背景水平和更频繁的粒子顶点误关联。这反过来又需要开发更全面和可扩展的重建方法，这些方法可以利用机器学习的最新进展。我们提出了一种新的异构图神经网络（HGNN）架构，具有不同粒子碰撞关系的独特表示，并集成了图剪枝层以提高可扩展性。在模拟LHCb实验的环境中，采用多任务范式进行训练的该HGNN显著提高了美子介子重建性能。值得注意的是，它同时在单个框架内执行粒子顶点关联和图剪枝。我们量化了重建和剪枝性能，展示了随着事件复杂性的增加而增强的推理时间可扩展性，并使用加权消息传递方案来减轻潜在的性能损失。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing luminosity frontier at the Large Hadron Collider is challengingthe reconstruction and analysis of particle collision events. Increasedparticle multiplicities are straining latency and storage requirements at thedata acquisition stage, while new complications are emerging, including higherbackground levels and more frequent particle vertex misassociations. This inturn necessitates the development of more holistic and scalable reconstructionmethods that take advantage of recent advances in machine learning. We proposea novel Heterogeneous Graph Neural Network (HGNN) architecture featuring uniquerepresentations for diverse particle collision relationships and integratedgraph pruning layers for scalability. Trained with a multi-task paradigm in anenvironment mimicking the LHCb experiment, this HGNN significantly improvesbeauty hadron reconstruction performance. Notably, it concurrently performsparticle vertex association and graph pruning within a single framework. Wequantify reconstruction and pruning performance, demonstrate enhanced inferencetime scaling with event complexity, and mitigate potential performance lossusing a weighted message passing scheme.</description>
      <author>example@mail.com (William Sutcliffe, Marta Calvi, Simone Capelli, Jonas Eschle, Julián García Pardiñas, Abhijit Mathad, Azusa Uzuki, Nicola Serra)</author>
      <guid isPermaLink="false">2504.21844v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Multiview Point Cloud Registration via Optimization in an Autoencoder Latent Space</title>
      <link>http://arxiv.org/abs/2504.21467v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 19 figures, IEEE Transactions on Image Processing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为POLAR的多视角点云刚性配准方法，该方法能够高效处理大量视图，同时对高水平的退化和大初始角度具有鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;点云刚性配准是3D计算机视觉中的一个基本问题，现有方法在处理大量视图和高水平退化时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;旨在寻找一种能够高效处理大量视图，同时鲁棒于高水平退化和大初始角度的多视角点云刚性配准方法。&lt;h4&gt;方法&lt;/h4&gt;将配准问题转化为预训练自动编码器的潜在空间，设计考虑退化的损失函数，并开发了一种高效的多次启动优化策略。&lt;h4&gt;主要发现&lt;/h4&gt;POLAR在合成和真实数据上显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;POLAR是一种有效的多视角点云刚性配准方法，可通过github.com/pypolar/polar或pip install polaregistration进行获取和使用。&lt;h4&gt;翻译&lt;/h4&gt;点云刚性配准是多维计算机视觉中的基本问题。在多视角情况下，我们旨在找到一组6D姿态来对齐一组对象。基于成对配准的方法依赖于后续同步算法，这使得它们随着视图数量的增加而扩展性较差。生成方法克服了这一限制，但基于高斯混合模型并使用期望最大化算法，因此它们不适合处理大变换。此外，大多数现有方法无法处理高水平的退化。在本文中，我们引入了POLAR（POint cloud LAtent Registration），这是一种多视角配准方法，能够有效地处理大量视图，同时对高水平的退化和大的初始角度具有鲁棒性。为了实现这一点，我们将配准问题转化为预训练自动编码器的潜在空间，设计了一个考虑退化的损失函数，并开发了一种高效的多次启动优化策略。我们提出的方法在合成和真实数据上显著优于现有方法。POLAR可在github.com/pypolar/polar或作为独立的包通过pip install polaregistration安装。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TIP.2025.3565998&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud rigid registration is a fundamental problem in 3D computervision. In the multiview case, we aim to find a set of 6D poses to align a setof objects. Methods based on pairwise registration rely on a subsequentsynchronization algorithm, which makes them poorly scalable with the number ofviews. Generative approaches overcome this limitation, but are based onGaussian Mixture Models and use an Expectation-Maximization algorithm. Hence,they are not well suited to handle large transformations. Moreover, mostexisting methods cannot handle high levels of degradations. In this paper, weintroduce POLAR (POint cloud LAtent Registration), a multiview registrationmethod able to efficiently deal with a large number of views, while beingrobust to a high level of degradations and large initial angles. To achievethis, we transpose the registration problem into the latent space of apretrained autoencoder, design a loss taking degradations into account, anddevelop an efficient multistart optimization strategy. Our proposed methodsignificantly outperforms state-of-the-art approaches on synthetic and realdata. POLAR is available at github.com/pypolar/polar or as a standalone packagewhich can be installed with pip install polaregistration.</description>
      <author>example@mail.com (Luc Vedrenne, Sylvain Faisan, Denis Fortun)</author>
      <guid isPermaLink="false">2504.21467v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>ImaginateAR: AI-Assisted In-Situ Authoring in Augmented Reality</title>
      <link>http://arxiv.org/abs/2504.21360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ImaginateAR，一个基于AI的移动AR内容创作系统，旨在让非专业人士通过语音输入实现AR内容的创作。&lt;h4&gt;背景&lt;/h4&gt;当前AR内容的创作对于非专业人士来说较为困难，通常需要专业工具和时间。&lt;h4&gt;目的&lt;/h4&gt;ImaginateAR的目标是让任何人都能在任何地方通过语音表达他们的想象力来构建AR内容。&lt;h4&gt;方法&lt;/h4&gt;ImaginateAR采用离线场景理解、快速3D资产生成和基于LLM的语音交互技术。&lt;h4&gt;主要发现&lt;/h4&gt;技术评估表明，ImaginateAR产生的户外场景图更准确，并且比先前的方法生成3D网格更快。用户研究揭示了AI在创作中的作用、用户在自由创作中创造的内容以及未来AR创作工具的设计启示。&lt;h4&gt;结论&lt;/h4&gt;ImaginateAR为非专业人士提供了更便捷的AR内容创作方式，并揭示了AI在AR内容创作中的重要作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While augmented reality (AR) enables new ways to play, tell stories, andexplore ideas rooted in the physical world, authoring personalized AR contentremains difficult for non-experts, often requiring professional tools and time.Prior systems have explored AI-driven XR design but typically rely onmanually-defined environments and fixed asset libraries, limiting creativeflexibility and real-world relevance. We introduce ImaginateAR, a mobileAI-assisted AR authoring system that aims to let anyone build anything,anywhere -- simply by speaking their imagination. ImaginateAR is powered bycustom pipelines for offline scene understanding, fast 3D asset generation, andLLM-driven speech interaction. Users might say "a dragon enjoying a campfire"(P7) and iteratively refine the scene using both AI and manual tools. Ourtechnical evaluation shows that ImaginateAR produces more accurate outdoorscene graphs and generates 3D meshes faster than prior methods. A three-partuser study (N=20) revealed preferred roles for AI in authoring, what and howusers create in free-form use, and design implications for future AR authoringtools.</description>
      <author>example@mail.com (Jaewook Lee, Filippo Aleotti, Diego Mazala, Guillermo Garcia-Hernando, Sara Vicente, Oliver James Johnston, Isabel Kraus-Liang, Jakub Powierza, Donghoon Shin, Jon E. Froehlich, Gabriel Brostow, Jessica Van Brummelen)</author>
      <guid isPermaLink="false">2504.21360v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>MAGNET: an open-source library for mesh agglomeration by Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.21780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MAGNET是一个开源的Python库，用于二维和三维网格的聚合，基于图神经网络（GNN）。&lt;h4&gt;背景&lt;/h4&gt;MAGNET旨在为训练各种GNN模型提供全面解决方案，结合深度学习和其他高级算法如METIS和k-means，以促进网格聚合和质量指标计算。&lt;h4&gt;目的&lt;/h4&gt;MAGNET旨在提高网格聚合和GNN模型训练的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;MAGNET采用图二分法，利用SAGE卷积层利用连通性和几何网格信息，与Antonietti等人（2024）提出的方法一致。此外，MAGNET结合了强化学习来提高模型预测粗划分的准确性和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;MAGNET通过提供详细的教程，指导用户进行网格聚合和GNN二分模型的训练。MAGNET在多种场景中的应用得到展示，其性能与METIS和k-means相比，在划分质量和计算效率方面具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;MAGNET的接口具有多功能性，通过集成Lymph库（一个实现多物理场微分问题数值离散化的开源库）展示了其接口的灵活性。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一个名为MAGNET的开源Python库，该库旨在用于二维和三维网格的聚合，基于图神经网络（GNN）。MAGNET作为训练各种GNN模型的全面解决方案，结合深度学习和其他高级算法，如METIS和k-means，以促进网格聚合和质量指标计算。通过其代码结构和主要功能概述了库的引入。GNN框架采用图二分法，通过SAGE卷积层利用连通性和几何网格信息，与Antonietti等人（2024）提出的方法一致。此外，提出的MAGNET库结合了强化学习，以提高模型在多级框架内预测粗划分的准确性和鲁棒性。提供了一个详细的教程，指导用户通过网格聚合和GNN二分模型的训练过程。我们展示了MAGNET执行的网格聚合的几个示例，证明了该库在各种场景中的应用。此外，新引入的模型性能与METIS和k-means进行了对比，表明所提出的GNN模型在划分质量和计算效率方面具有竞争力。最后，通过其与Lymph库的集成展示了MAGNET接口的灵活性，Lymph是一个在多顶点网格上实现不连续伽辽金方法的开源库，用于多物理场微分问题的数值离散化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce MAGNET, an open-source Python library designed for meshagglomeration in both two- and three-dimensions, based on employing GraphNeural Networks (GNN). MAGNET serves as a comprehensive solution for training avariety of GNN models, integrating deep learning and other advanced algorithmssuch as METIS and k-means to facilitate mesh agglomeration and quality metriccomputation. The library's introduction is outlined through its code structureand primary features. The GNN framework adopts a graph bisection methodologythat capitalizes on connectivity and geometric mesh information via SAGEconvolutional layers, in line with the methodology proposed by Antonietti etal. (2024). Additionally, the proposed MAGNET library incorporatesreinforcement learning to enhance the accuracy and robustness of the model forpredicting coarse partitions within a multilevel framework. A detailed tutorialis provided to guide the user through the process of mesh agglomeration and thetraining of a GNN bisection model. We present several examples of meshagglomeration conducted by MAGNET, demonstrating the library's applicabilityacross various scenarios. Furthermore, the performance of the newly introducedmodels is contrasted with that of METIS and k-means, illustrating that theproposed GNN models are competitive regarding partition quality andcomputational efficiency. Finally, we exhibit the versatility of MAGNET'sinterface through its integration with Lymph, an open-source libraryimplementing discontinuous Galerkin methods on polytopal grids for thenumerical discretization of multiphysics differential problems.</description>
      <author>example@mail.com (Paola F. Antonietti, Matteo Caldana, Ilario Mazzieri, Andrea Re Fraschini)</author>
      <guid isPermaLink="false">2504.21780v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Robust Orthogonal NMF with Label Propagation for Image Clustering</title>
      <link>http://arxiv.org/abs/2504.21472v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为RONMF（鲁棒正交非负矩阵分解）的新方法，用于图像聚类，旨在克服现有NMF方法对噪声敏感和无法有效利用有限监督信息的缺点。&lt;h4&gt;背景&lt;/h4&gt;NMF在图像聚类中是一种流行的无监督学习方法，但在实际应用中，大多数现有方法对噪声污染敏感，且无法有效利用有限的监督信息。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些缺点，提出了一种名为RONMF的统一非凸框架，结合标签传播，以提高鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;RONMF方法不仅考虑了图拉普拉斯和标签传播作为正则化项，还引入了一种更有效的非凸结构来衡量重建误差，并对基矩阵施加正交约束以减少噪声污染。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在八个公共图像数据集上，所提出的RONMF在各种标准指标上优于最先进的NMF方法，并显示出卓越的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;RONMF是一种有效且鲁棒的图像聚类方法，能够处理噪声污染并有效利用有限的监督信息。&lt;h4&gt;翻译&lt;/h4&gt;摘要：非负矩阵分解（NMF）是一种流行的无监督学习方法，广泛应用于图像聚类。然而，在现实世界的聚类场景中，大多数现有的NMF方法对噪声污染非常敏感，并且无法有效地利用有限的监督信息。为了克服这些缺点，我们提出了一种名为鲁棒正交非负矩阵分解（RONMF）的统一非凸框架，称为标签传播。该方法不仅将图拉普拉斯和标签传播作为正则化项，还引入了一种更有效的非凸结构来衡量重建误差，并对基矩阵施加正交约束以减少噪声污染，从而提高了鲁棒性。为了解决RONMF，我们开发了一种基于交替方向乘子法（ADMM）的优化算法。特别是，所有子问题都有封闭形式的解，这确保了其效率。在八个公共图像数据集上的实验评估表明，所提出的RONMF在各种标准指标上优于最先进的NMF方法，并显示出卓越的鲁棒性。代码可在https://github.com/slinda-liu上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-negative matrix factorization (NMF) is a popular unsupervised learningapproach widely used in image clustering. However, in real-world clusteringscenarios, most existing NMF methods are highly sensitive to noise corruptionand are unable to effectively leverage limited supervised information. Toovercome these drawbacks, we propose a unified non-convex framework with labelpropagation called robust orthogonal nonnegative matrix factorization (RONMF).This method not only considers the graph Laplacian and label propagation asregularization terms but also introduces a more effective non-convex structureto measure the reconstruction error and imposes orthogonal constraints on thebasis matrix to reduce the noise corruption, thereby achieving higherrobustness. To solve RONMF, we develop an alternating direction method ofmultipliers (ADMM)-based optimization algorithm. In particular, all subproblemshave closed-form solutions, which ensures its efficiency. Experimentalevaluations on eight public image datasets demonstrate that the proposed RONMFoutperforms state-of-the-art NMF methods across various standard metrics andshows excellent robustness. The code will be available athttps://github.com/slinda-liu.</description>
      <author>example@mail.com (Jingjing Liu, Nian Wu, Xianchao Xiu, Jianhua Zhang)</author>
      <guid isPermaLink="false">2504.21472v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>A simple and effective approach for body part recognition on CT scans based on projection estimation</title>
      <link>http://arxiv.org/abs/2504.21810v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于2D X射线类似估计的3D CT扫描体区域识别方法，旨在通过简化标注过程提高医学数据集的质量。&lt;h4&gt;背景&lt;/h4&gt;机器学习模型需要大量标注数据才能获得最佳性能，而CT数据标注由于其体积性和缺失或不完整的元数据而特别具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;通过估计2D图像来识别14个不同的身体区域，为构建高质量的医学数据集提供有价值的信息。&lt;h4&gt;方法&lt;/h4&gt;本研究提出了一种基于2D X射线类似估计的3D CT扫描体区域识别方法，并与2.5D、3D和基础模型（MI2）方法进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在统计显著性方面优于其他方法，其最佳模型EffNet-B0的F1-Score为0.980 ± 0.016，而其他方法的F1-Score分别为0.840 ± 0.114（2.5D DenseNet-161）、0.854 ± 0.096（3D VoxCNN）和0.852 ± 0.104（MI2基础模型）。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的基于2D X射线类似估计的3D CT扫描体区域识别方法在医学数据集构建中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;众所周知，机器学习模型需要大量标注数据以获得最佳性能。由于CT数据的体积性以及通常缺失或不完整的关联元数据，标注CT数据可能是一项特别具有挑战性的任务。即使是检查一张CT扫描，也需要额外的计算机软件，或者在编程语言的情况下，还需要额外的编程库。本研究提出了一种简单但有效的方法，基于2D X射线类似估计的3D CT扫描体区域识别。尽管体区域通常与CT扫描相关联，但它通常只描述了主要关注的体区域，而忽略了观察到的CT中存在的其他解剖区域。在所提出的方法中，利用估计的2D图像来识别14个不同的身体区域，为构建高质量医学数据集提供了有价值的信息。为了评估所提出方法的有效性，将其与2.5D、3D和基础模型（MI2）方法进行了比较。我们的方法优于其他方法，其中以统计显著性和最佳性能模型EffNet-B0的F1-Score为0.980 ± 0.016，相比之下，其他方法的F1-Score分别为0.840 ± 0.114（2.5D DenseNet-161）、0.854 ± 0.096（3D VoxCNN）和0.852 ± 0.104（MI2基础模型）。所使用的数据集由三个不同的临床中心组成，包括15,622张CT扫描（44,135个标签）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; It is well known that machine learning models require a high amount ofannotated data to obtain optimal performance. Labelling Computed Tomography(CT) data can be a particularly challenging task due to its volumetric natureand often missing and$/$or incomplete associated meta-data. Even inspecting oneCT scan requires additional computer software, or in the case of programminglanguages $-$ additional programming libraries. This study proposes a simple,yet effective approach based on 2D X-ray-like estimation of 3D CT scans forbody region identification. Although body region is commonly associated withthe CT scan, it often describes only the focused major body region neglectingother anatomical regions present in the observed CT. In the proposed approach,estimated 2D images were utilized to identify 14 distinct body regions,providing valuable information for constructing a high-quality medical dataset.To evaluate the effectiveness of the proposed method, it was compared against2.5D, 3D and foundation model (MI2) based approaches. Our approach outperformedthe others, where it came on top with statistical significance and F1-Score forthe best-performing model EffNet-B0 of 0.980 $\pm$ 0.016 in comparison to the0.840 $\pm$ 0.114 (2.5D DenseNet-161), 0.854 $\pm$ 0.096 (3D VoxCNN), and 0.852$\pm$ 0.104 (MI2 foundation model). The utilized dataset comprised threedifferent clinical centers and counted 15,622 CT scans (44,135 labels).</description>
      <author>example@mail.com (Franko Hrzic, Mohammadreza Movahhedi, Ophelie Lavoie-Gagne, Ata Kiapour)</author>
      <guid isPermaLink="false">2504.21810v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>ABG-NAS: Adaptive Bayesian Genetic Neural Architecture Search for Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2504.21254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ABG-NAS的自动图神经网络架构搜索框架，旨在提高图表示学习的效率和效果。&lt;h4&gt;背景&lt;/h4&gt;现有的图神经网络架构难以适应多样化的复杂图结构，限制了其提供稳健和可泛化表示的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出ABG-NAS框架，以实现高效的图表示学习。&lt;h4&gt;方法&lt;/h4&gt;ABG-NAS包含三个关键组件：全面架构搜索空间（CASS）、自适应遗传优化策略（AGOS）和贝叶斯引导调优模块（BGTM）。CASS系统地探索了不同的传播和转换操作，AGOS动态平衡探索和利用，BGTM定期优化超参数。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的实验表明，ABG-NAS在性能上优于手动设计的GNN和最先进的神经架构搜索（NAS）方法。&lt;h4&gt;结论&lt;/h4&gt;ABG-NAS通过提供可扩展和自适应的解决方案，有望推动图表示学习的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：有效的图表示学习对于实现关键下游任务（如节点分类、链接预测和子图搜索）至关重要。然而，现有的图神经网络（GNN）架构往往难以适应多样化的复杂图结构，限制了它们提供稳健和可泛化表示的能力。为了应对这一挑战，我们提出了ABG-NAS，这是一种针对高效图表示学习的自动图神经网络架构搜索的新框架。ABG-NAS包含三个关键组件：一个全面的架构搜索空间（CASS）、一个自适应遗传优化策略（AGOS）和一个贝叶斯引导调优模块（BGTM）。CASS系统地探索了不同的传播（P）和转换（T）操作，使得能够发现能够捕捉复杂图特征的GNN架构。AGOS动态平衡探索和利用，确保搜索效率并保持解决方案的多样性。BGTM进一步定期优化超参数，增强了结果的架构的可扩展性和鲁棒性。在基准数据集（Cora、PubMed、Citeseer和CoraFull）上的实证评估表明，ABG-NAS在性能上始终优于手动设计的GNN和最先进的神经架构搜索（NAS）方法。这些结果突出了ABG-NAS通过为多样化的图结构提供可扩展和自适应的解决方案，在推进图表示学习方面的潜力。我们的代码在https://github.com/sserranw/ABG-NAS上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective and efficient graph representation learning is essential forenabling critical downstream tasks, such as node classification, linkprediction, and subgraph search. However, existing graph neural network (GNN)architectures often struggle to adapt to diverse and complex graph structures,limiting their ability to provide robust and generalizable representations. Toaddress this challenge, we propose ABG-NAS, a novel framework for automatedgraph neural network architecture search tailored for efficient graphrepresentation learning. ABG-NAS encompasses three key components: aComprehensive Architecture Search Space (CASS), an Adaptive GeneticOptimization Strategy (AGOS), and a Bayesian-Guided Tuning Module (BGTM). CASSsystematically explores diverse propagation (P) and transformation (T)operations, enabling the discovery of GNN architectures capable of capturingintricate graph characteristics. AGOS dynamically balances exploration andexploitation, ensuring search efficiency and preserving solution diversity.BGTM further optimizes hyperparameters periodically, enhancing the scalabilityand robustness of the resulting architectures. Empirical evaluations onbenchmark datasets (Cora, PubMed, Citeseer, and CoraFull) demonstrate thatABG-NAS consistently outperforms both manually designed GNNs andstate-of-the-art neural architecture search (NAS) methods. These resultshighlight the potential of ABG-NAS to advance graph representation learning byproviding scalable and adaptive solutions for diverse graph structures. Ourcode is publicly available at https://github.com/sserranw/ABG-NAS.</description>
      <author>example@mail.com (Sixuan Wang, Jiao Yin, Jinli Cao, MingJian Tang, Hua Wang, Yanchun Zhang)</author>
      <guid isPermaLink="false">2504.21254v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Path Planning on Multi-level Point Cloud with a Weighted Traversability Graph</title>
      <link>http://arxiv.org/abs/2504.21622v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对多层次地形情况的新路径规划方法，该方法在三个层面进行了创新。&lt;h4&gt;背景&lt;/h4&gt;路径规划在复杂地形中的有效性是研究的关键。&lt;h4&gt;目的&lt;/h4&gt;解决多层次地形情况下的路径规划问题。&lt;h4&gt;方法&lt;/h4&gt;1) 使用多级跳表结构和数据精简算法预处理点云地图，以实现地图的有序化和简化；2) 通过车辆和点云的交互分析直接获取局部可通行性指数，以节省表面拟合工作；3) 在多层次连通图上分配可通行性指数，生成加权可通行性图，用于基于搜索的路径规划；4) 修改A*算法以利用可通行性图生成短且安全的路径。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过室内和室外实验在各种环境中验证了其有效性和可靠性，包括多层建筑、林地和崎岖山区。&lt;h4&gt;结论&lt;/h4&gt;该方法可以有效地解决地面车辆在广泛情况下的3D路径规划问题。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的路径规划方法来解决多层次地形情况。该方法在三个方面进行了创新：1) 使用多级跳表结构和数据精简算法对点云地图进行预处理，以实现地图的有序化和简化；2) 通过车辆和点云的交互分析直接获取局部可通行性指数，从而节省表面拟合工作；3) 在多层次连通图上分配可通行性指数，生成加权可通行性图，用于基于搜索的路径规划；4) 修改A*算法以利用可通行性图生成短且安全的路径。通过在多种环境中的室内和室外实验验证了该方法的有效性和可靠性，包括多层建筑、林地和崎岖山区。结果表明，该方法可以有效地解决地面车辆在广泛情况下的3D路径规划问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This article proposes a new path planning method for addressing multi-levelterrain situations. The proposed method includes innovations in three aspects:1) the pre-processing of point cloud maps with a multi-level skip-liststructure and data-slimming algorithm for well-organized and simplified mapformalization and management, 2) the direct acquisition of local traversabilityindexes through vehicle and point cloud interaction analysis, which saves workin surface fitting, and 3) the assignment of traversability indexes on amulti-level connectivity graph to generate a weighted traversability graph forgenerally search-based path planning. The A* algorithm is modified to utilizethe traversability graph to generate a short and safe path. The effectivenessand reliability of the proposed method are verified through indoor and outdoorexperiments conducted in various environments, including multi-floor buildings,woodland, and rugged mountainous regions. The results demonstrate that theproposed method can properly address 3D path planning problems for groundvehicles in a wide range of situations.</description>
      <author>example@mail.com (Yujie Tang, Quan Li, Hao Geng, Yangmin Xie, Hang Shi, Yusheng Yang)</author>
      <guid isPermaLink="false">2504.21622v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Synergy-CLIP: Extending CLIP with Multi-modal Integration for Robust Representation Learning</title>
      <link>http://arxiv.org/abs/2504.21375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Multi-modal, Multi-modal Representation Learning, Missing Modality,  Missing Modality Reconstruction, Speech and Multi-modality, Vision and  Language&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Synergy-CLIP的新框架，用于增强多模态表示学习，通过整合视觉、文本和音频模态，并验证了其在多种下游任务中的有效性。&lt;h4&gt;背景&lt;/h4&gt;多模态表示学习在人工智能领域变得至关重要，但现有方法主要关注双模态交互，且在等规模环境中整合模态的研究尚不充分。&lt;h4&gt;目的&lt;/h4&gt;提出Synergy-CLIP框架，以增强多模态表示学习，并解决构建大规模平衡数据集的挑战。&lt;h4&gt;方法&lt;/h4&gt;Synergy-CLIP扩展了CLIP架构，通过整合视觉、文本和音频模态，并引入了VGG-sound+数据集，以提供等规模的多模态数据表示。&lt;h4&gt;主要发现&lt;/h4&gt;Synergy-CLIP在零样本分类等任务中优于现有基线，并展示了其在实际应用场景中提取模态间协同作用的能力。&lt;h4&gt;结论&lt;/h4&gt;Synergy-CLIP为多模态表示学习的进步和新的研究方向提供了坚实的基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态表示学习已成为人工智能领域的关键领域，它使视觉、文本和音频等不同模态的集成成为可能，以解决复杂问题。然而，现有方法主要关注双模态交互，如图像-文本对，这限制了它们充分利用多模态数据丰富性的能力。此外，由于构建大规模平衡数据集的挑战，等规模环境中模态的整合仍被探索不足。在本研究中，我们提出了Synergy-CLIP，这是一个新颖的框架，它扩展了对比语言-图像预训练（CLIP）架构，通过整合视觉、文本和音频模态来增强多模态表示学习。与现有方法不同，Synergy-CLIP通过平等地对齐和捕获三个模态的潜在信息。为了解决构建大规模多模态数据集的高成本，我们引入了VGG-sound+数据集，该数据集旨在提供视觉、文本和音频数据的等规模表示。Synergy-CLIP在各种下游任务中得到了验证，包括零样本分类，其中它优于现有基线。此外，我们引入了一个缺失模态重建任务，展示了Synergy-CLIP在现实应用场景中提取模态间协同作用的能力。这些贡献为多模态表示学习的进步和新的研究方向提供了坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal representation learning has become a pivotal area in artificialintelligence, enabling the integration of diverse modalities such as vision,text, and audio to solve complex problems. However, existing approachespredominantly focus on bimodal interactions, such as image-text pairs, whichlimits their ability to fully exploit the richness of multi-modal data.Furthermore, the integration of modalities in equal-scale environments remainsunderexplored due to the challenges of constructing large-scale, balanceddatasets. In this study, we propose Synergy-CLIP, a novel framework thatextends the contrastive language-image pre-training (CLIP) architecture toenhance multi-modal representation learning by integrating visual, textual, andaudio modalities. Unlike existing methods that focus on adapting individualmodalities to vanilla-CLIP, Synergy-CLIP aligns and captures latent informationacross three modalities equally. To address the high cost of constructinglarge-scale multi-modal datasets, we introduce VGG-sound+, a triple-modaldataset designed to provide equal-scale representation of visual, textual, andaudio data. Synergy-CLIP is validated on various downstream tasks, includingzero-shot classification, where it outperforms existing baselines.Additionally, we introduce a missing modality reconstruction task,demonstrating Synergy-CLIP's ability to extract synergy among modalities inrealistic application scenarios. These contributions provide a robustfoundation for advancing multi-modal representation learning and exploring newresearch directions.</description>
      <author>example@mail.com (Sangyeon Cho, Jangyeong Jeon, Mingi Kim, Junyeong Kim)</author>
      <guid isPermaLink="false">2504.21375v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding</title>
      <link>http://arxiv.org/abs/2504.21435v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 15 figures, CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的视频理解基准SeriesBench，用于评估多模态大型语言模型在理解叙事驱动系列视频方面的能力。&lt;h4&gt;背景&lt;/h4&gt;现有的视频理解基准主要关注独立视频，评估视觉元素如人类动作和物体状态，而现实中的视频往往包含复杂连续的叙事，通常以系列形式呈现。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出SeriesBench，包含105个精心挑选的叙事驱动系列，涵盖28个需要深度叙事理解的专项任务。&lt;h4&gt;方法&lt;/h4&gt;首先选择涵盖各种类型的戏剧系列，然后引入一种新的长跨度叙事标注方法，结合全信息转换方法将人工标注转换为不同的任务格式。此外，提出了一种新的叙事推理框架PC-DCoT，以增强模型对剧情结构和人物关系分析的详细分析能力。&lt;h4&gt;主要发现&lt;/h4&gt;在SeriesBench上的广泛结果表明，现有的MLLMs在理解叙事驱动系列视频方面仍面临重大挑战，而PC-DCoT使这些MLLMs能够实现性能提升。&lt;h4&gt;结论&lt;/h4&gt;SeriesBench和PC-DCoT强调了提高模型理解叙事驱动系列视频能力的重要性，为MLLMs的未来发展提供了指导。&lt;h4&gt;翻译&lt;/h4&gt;With the rapid development of Multi-modal Large Language Models (MLLMs), anincreasing number of benchmarks have been established to evaluate the videounderstanding capabilities of these models. However, these benchmarks focus onextbf{standalone} videos and mainly assess ``visual elements'' like humanactions and object states. In reality, contemporary videos often encompasscomplex and continuous narratives, typically presented as a extbf{series}. Toaddress this challenge, we propose extbf{SeriesBench}, a benchmark consistingof 105 carefully curated narrative-driven series, covering 28 specialized tasksthat require deep narrative understanding. Specifically, we first select adiverse set of drama series spanning various genres. Then, we introduce a novellong-span narrative annotation method, combined with a full-informationtransformation approach to convert manual annotations into diverse taskformats. To further enhance model capacity for detailed analysis of plotstructures and character relationships within series, we propose a novelnarrative reasoning framework, extbf{PC-DCoT}. Extensive results onextbf{SeriesBench} indicate that existing MLLMs still face significantchallenges in understanding narrative-driven series, while extbf{PC-DCoT}enables these MLLMs to achieve performance improvements. Overall, ourextbf{SeriesBench} and extbf{PC-DCoT} highlight the critical necessity ofadvancing model capabilities to understand narrative-driven series, guiding thefuture development of MLLMs. SeriesBench is publicly available at https://github.com/zackhxn/SeriesBench-CVPR2025.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of Multi-modal Large Language Models (MLLMs), anincreasing number of benchmarks have been established to evaluate the videounderstanding capabilities of these models. However, these benchmarks focus on\textbf{standalone} videos and mainly assess ``visual elements'' like humanactions and object states. In reality, contemporary videos often encompasscomplex and continuous narratives, typically presented as a \textbf{series}. Toaddress this challenge, we propose \textbf{SeriesBench}, a benchmark consistingof 105 carefully curated narrative-driven series, covering 28 specialized tasksthat require deep narrative understanding. Specifically, we first select adiverse set of drama series spanning various genres. Then, we introduce a novellong-span narrative annotation method, combined with a full-informationtransformation approach to convert manual annotations into diverse taskformats. To further enhance model capacity for detailed analysis of plotstructures and character relationships within series, we propose a novelnarrative reasoning framework, \textbf{PC-DCoT}. Extensive results on\textbf{SeriesBench} indicate that existing MLLMs still face significantchallenges in understanding narrative-driven series, while \textbf{PC-DCoT}enables these MLLMs to achieve performance improvements. Overall, our\textbf{SeriesBench} and \textbf{PC-DCoT} highlight the critical necessity ofadvancing model capabilities to understand narrative-driven series, guiding thefuture development of MLLMs. SeriesBench is publicly available athttps://github.com/zackhxn/SeriesBench-CVPR2025.</description>
      <author>example@mail.com (Chenkai Zhang, Yiming Lei, Zeming Liu, Haitao Leng, ShaoGuo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang)</author>
      <guid isPermaLink="false">2504.21435v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Phi-4-reasoning Technical Report</title>
      <link>http://arxiv.org/abs/2504.21318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为Phi-4-reasoning的推理模型，在复杂推理任务上表现出色。&lt;h4&gt;背景&lt;/h4&gt;Phi-4-reasoning是一个拥有140亿参数的推理模型，它在推理任务上取得了显著成绩。&lt;h4&gt;目的&lt;/h4&gt;开发Phi-4-reasoning模型和Phi-4-reasoning-plus变体，以实现更高的推理性能。&lt;h4&gt;方法&lt;/h4&gt;通过在精心挑选的“可教”提示集上对Phi-4进行监督微调，并使用o3-mini生成推理演示来训练模型。Phi-4-reasoning-plus通过基于结果的强化学习进一步优化。&lt;h4&gt;主要发现&lt;/h4&gt;Phi-4-reasoning和Phi-4-reasoning-plus在数学、科学推理、编码、算法问题解决、规划和空间理解等多个推理任务上优于更大的开放模型，并接近DeepSeek-R1模型的表现。&lt;h4&gt;结论&lt;/h4&gt;精心数据整理对监督微调有益，且可以通过强化学习进一步增强。评估表明，有改进推理模型性能和鲁棒性的评估方法的机会。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为Phi-4-reasoning的推理模型，它是一个拥有140亿参数的推理模型，在复杂推理任务上取得了显著成绩。通过在精心挑选的“可教”提示集上对Phi-4进行监督微调，并使用o3-mini生成推理演示来训练模型。Phi-4-reasoning-plus通过基于结果的强化学习进一步优化。在数学、科学推理、编码、算法问题解决、规划和空间理解等多个推理任务上，这两个模型都优于更大的开放模型，如DeepSeek-R1-Distill-Llama-70B模型，并接近DeepSeek-R1模型的表现。我们的全面评估涵盖了这些基准测试。有趣的是，我们还观察到这些改进对通用基准测试也有非平凡的迁移。在本报告中，我们提供了关于我们的训练数据、训练方法和评估的见解。我们表明，精心数据整理对监督微调有益，并且可以通过强化学习进一步增强。最后，我们的评估指出了改进推理模型性能和鲁棒性的评估方法的机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Phi-4-reasoning, a 14-billion parameter reasoning model thatachieves strong performance on complex reasoning tasks. Trained via supervisedfine-tuning of Phi-4 on carefully curated set of "teachable" prompts-selectedfor the right level of complexity and diversity-and reasoning demonstrationsgenerated using o3-mini, Phi-4-reasoning generates detailed reasoning chainsthat effectively leverage inference-time compute. We further developPhi-4-reasoning-plus, a variant enhanced through a short phase of outcome-basedreinforcement learning that offers higher performance by generating longerreasoning traces. Across a wide range of reasoning tasks, both modelsoutperform significantly larger open-weight models such asDeepSeek-R1-Distill-Llama-70B model and approach the performance levels of fullDeepSeek-R1 model. Our comprehensive evaluations span benchmarks in math andscientific reasoning, coding, algorithmic problem solving, planning, andspatial understanding. Interestingly, we observe a non-trivial transfer ofimprovements to general-purpose benchmarks as well. In this report, we provideinsights into our training data, our training methodologies, and ourevaluations. We show that the benefit of careful data curation for supervisedfine-tuning (SFT) extends to reasoning language models, and can be furtheramplified by reinforcement learning (RL). Finally, our evaluation points toopportunities for improving how we assess the performance and robustness ofreasoning models.</description>
      <author>example@mail.com (Marah Abdin, Sahaj Agarwal, Ahmed Awadallah, Vidhisha Balachandran, Harkirat Behl, Lingjiao Chen, Gustavo de Rosa, Suriya Gunasekar, Mojan Javaheripi, Neel Joshi, Piero Kauffmann, Yash Lara, Caio César Teodoro Mendes, Arindam Mitra, Besmira Nushi, Dimitris Papailiopoulos, Olli Saarikivi, Shital Shah, Vaishnavi Shrivastava, Vibhav Vineet, Yue Wu, Safoora Yousefi, Guoqing Zheng)</author>
      <guid isPermaLink="false">2504.21318v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Mamba Based Feature Extraction And Adaptive Multilevel Feature Fusion For 3D Tumor Segmentation From Multi-modal Medical Image</title>
      <link>http://arxiv.org/abs/2504.21281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Mamba模型的三维医学图像肿瘤分割方法，该方法结合了特征提取和自适应多级特征融合技术，旨在提高多模态医学图像分割的准确性。&lt;h4&gt;背景&lt;/h4&gt;多模态3D医学图像分割在识别肿瘤区域时面临图像强度和肿瘤形态变化带来的挑战。传统的基于CNN的方法难以捕捉全局特征，而基于Transformers的方法虽然能有效地捕捉全局上下文，但在3D医学图像分割中计算成本高。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Mamba模型的特征提取和自适应多级特征融合方法，用于三维肿瘤分割，以提高分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 开发特定模态的Mamba编码器，以高效提取代表各模态中解剖和病理结构的远程相关特征。2. 设计双向协同集成块，通过模态注意力和通道注意力学习动态融合多模态和多级互补特征。3. 解码器结合深度语义信息和细粒度细节生成肿瘤分割图。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有的CNN、Transformer和基于Mamba的方法相比，该方法在PET/CT和MRI多序列医学图像数据集上取得了具有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地提高多模态3D医学图像肿瘤分割的准确性，为临床应用提供了新的技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal 3D medical image segmentation aims to accurately identify tumorregions across different modalities, facing challenges from variations in imageintensity and tumor morphology. Traditional convolutional neural network(CNN)-based methods struggle with capturing global features, whileTransformers-based methods, despite effectively capturing global context,encounter high computational costs in 3D medical image segmentation. The Mambamodel combines linear scalability with long-distance modeling, making it apromising approach for visual representation learning. However, Mamba-based 3Dmulti-modal segmentation still struggles to leverage modality-specific featuresand fuse complementary information effectively. In this paper, we propose aMamba based feature extraction and adaptive multilevel feature fusion for 3Dtumor segmentation using multi-modal medical image. We first develop thespecific modality Mamba encoder to efficiently extract long-range relevantfeatures that represent anatomical and pathological structures present in eachmodality. Moreover, we design an bi-level synergistic integration block thatdynamically merges multi-modal and multi-level complementary features by themodality attention and channel attention learning. Lastly, the decoder combinesdeep semantic information with fine-grained details to generate the tumorsegmentation map. Experimental results on medical image datasets (PET/CT andMRI multi-sequence) show that our approach achieve competitive performancecompared to the state-of-the-art CNN, Transformer, and Mamba-based approaches.</description>
      <author>example@mail.com (Zexin Ji, Beiji Zou, Xiaoyan Kui, Hua Li, Pierre Vera, Su Ruan)</author>
      <guid isPermaLink="false">2504.21281v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Anti-Intercept OFDM Waveform Design with Secure Coding for Satellite Networks</title>
      <link>http://arxiv.org/abs/2504.21446v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究低地球轨道卫星网络中物理层安全设计，旨在提高对窃听威胁的抵抗能力。&lt;h4&gt;背景&lt;/h4&gt;低地球轨道卫星网络对下一代通信系统至关重要，但它们的特点，如有限的机载资源、视距传播和易受广泛覆盖区域监听攻击，给物理层安全带来挑战。&lt;h4&gt;目的&lt;/h4&gt;设计适用于卫星-地面链路的抗截获波形，以提高在正交频分复用（OFDM）系统中的保密性能。&lt;h4&gt;方法&lt;/h4&gt;提出一种基于二分搜索激活神经网络（BSA-Net）的解决方案，结合无监督学习进行安全编码优化和二分搜索进行动态功率分配。&lt;h4&gt;主要发现&lt;/h4&gt;该方案分为两个阶段，第一阶段在功率限制下优化安全编码，第二阶段在窃听限制下对子载波进行功率分配。仿真结果表明，该方法在保密率性能方面有显著提升。&lt;h4&gt;结论&lt;/h4&gt;所提出的抗截获波形设计方法有效提高了卫星网络对抗窃听威胁的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low Earth Orbit (LEO) satellite networks are integral to next-generationcommunication systems, providing global coverage, low latency, and minimalsignal loss. However, their unique characteristics, such as constrained onboardresources, Line-of-Sight (LoS) propagation, and vulnerability to eavesdroppingover wide coverage areas, present significant challenges to physical layersecurity. To address these challenges, this paper focuses on the design ofanti-intercept waveforms for satellite-ground links within Orthogonal FrequencyDivision Multiplexing (OFDM) systems, aiming to enhance security againsteavesdropping threats. We formulate a secrecy rate maximization problem thataims to balance secrecy performance and communication reliability undereavesdropping constraints and sub-carrier power limitations. To solve thisnon-convex optimization problem, we propose a bisection search-activated neuralnetwork (BSA-Net) that integrates unsupervised learning for secure codingoptimization and bisection search for dynamic power allocation. The proposedmethod is structured in two stages: the first optimizes secure coding underpower constraints, while the second allocates power across sub-carriers undereavesdropping constraints. Extensive simulation results demonstrate theefficacy of our approach, showcasing significant improvements in secrecy rateperformance.</description>
      <author>example@mail.com (Zhisheng Yin, Yonghong Liu, Dongbo Li, Nan Cheng, Linlin Liang, Changle Li, Jie Liu)</author>
      <guid isPermaLink="false">2504.21446v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Visual Text Processing: A Comprehensive Review and Unified Evaluation</title>
      <link>http://arxiv.org/abs/2504.21682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了视觉文本处理领域的最新进展，重点关注文本特征的适用性和有效整合方法，并提出了新的基准和评估指标。&lt;h4&gt;背景&lt;/h4&gt;视觉文本在文档和场景图像中扮演关键角色，传递丰富的语义信息，并在计算机视觉领域受到广泛关注。&lt;h4&gt;目的&lt;/h4&gt;探讨适用于不同视觉文本处理任务的文本特征，以及如何将这些特征有效整合到处理框架中。&lt;h4&gt;方法&lt;/h4&gt;提出了VTPBench基准和VTPScore评估指标，并通过实证研究验证了现有技术的改进空间。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，在视觉文本处理中，文本特征的有效捕捉和利用对于开发鲁棒的模型至关重要。&lt;h4&gt;结论&lt;/h4&gt;本工作旨在为视觉文本处理领域提供基础资源，促进未来在该领域的探索和创新。&lt;h4&gt;翻译&lt;/h4&gt;This paper reviews the latest advancements in the field of visual text processing, focusing on the suitability of text features for different tasks and how these distinctive text features can be effectively integrated into processing frameworks. The paper introduces VTPBench, a new benchmark that encompasses a wide range of visual text processing datasets, and VTPScore, a novel evaluation metric designed to ensure fair and reliable evaluation. An empirical study with more than 20 specific models reveals substantial room for improvement in current techniques. The aim of this work is to establish a fundamental resource that fosters future exploration and innovation in the dynamic field of visual text processing.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual text is a crucial component in both document and scene images,conveying rich semantic information and attracting significant attention in thecomputer vision community. Beyond traditional tasks such as text detection andrecognition, visual text processing has witnessed rapid advancements driven bythe emergence of foundation models, including text image reconstruction andtext image manipulation. Despite significant progress, challenges remain due tothe unique properties that differentiate text from general objects. Effectivelycapturing and leveraging these distinct textual characteristics is essentialfor developing robust visual text processing models. In this survey, we presenta comprehensive, multi-perspective analysis of recent advancements in visualtext processing, focusing on two key questions: (1) What textual features aremost suitable for different visual text processing tasks? (2) How can thesedistinctive text features be effectively incorporated into processingframeworks? Furthermore, we introduce VTPBench, a new benchmark thatencompasses a broad range of visual text processing datasets. Leveraging theadvanced visual quality assessment capabilities of multimodal large languagemodels (MLLMs), we propose VTPScore, a novel evaluation metric designed toensure fair and reliable evaluation. Our empirical study with more than 20specific models reveals substantial room for improvement in the currenttechniques. Our aim is to establish this work as a fundamental resource thatfosters future exploration and innovation in the dynamic field of visual textprocessing. The relevant repository is available athttps://github.com/shuyansy/Visual-Text-Processing-survey.</description>
      <author>example@mail.com (Yan Shu, Weichao Zeng, Fangmin Zhao, Zeyu Chen, Zhenhang Li, Xiaomeng Yang, Yu Zhou, Paolo Rota, Xiang Bai, Lianwen Jin, Xu-Cheng Yin, Nicu Sebe)</author>
      <guid isPermaLink="false">2504.21682v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Database and deep-learning scalability of anharmonic phonon properties by automated brute-force first-principles calculations</title>
      <link>http://arxiv.org/abs/2504.21245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过开发自动化的第一性原理工作流程，计算了晶体化合物的非谐和声子性质，并构建了一个包含6000多种无机化合物的数据库，以优化其热传输行为，并分析其光学、电子和磁特性。&lt;h4&gt;背景&lt;/h4&gt;理解晶体化合物的非谐和声子性质（如声子寿命和热导率）对于研究和优化其热传输行为至关重要，这些性质还通过声子与其他准粒子和场的相互作用影响光学、电子和磁特性。&lt;h4&gt;目的&lt;/h4&gt;开发一个自动化的第一性原理工作流程，构建一个包含多种无机化合物的数据库，并利用此数据库预测热导率和光谱。&lt;h4&gt;方法&lt;/h4&gt;建立了一个包含超过6000种无机化合物的数据库，并训练了一个图神经网络模型，使用结构参数预测热导率和光谱值。&lt;h4&gt;主要发现&lt;/h4&gt;预测准确性随着训练数据量的增加而提高，模型能够识别出具有极端热导率的材料（无论是高还是低）。数据库提供了对声子非谐和行为的宝贵见解。&lt;h4&gt;结论&lt;/h4&gt;该研究加速了先进功能材料的设计和开发，为理解和优化材料的热传输特性提供了新的工具和资源。&lt;h4&gt;翻译&lt;/h4&gt;摘要：理解晶体化合物的非谐和声子性质（如声子寿命和热导率）对于研究和优化它们的热传输行为至关重要。这些性质还通过声子与其他准粒子和场的相互作用影响光学、电子和磁特性。在本研究中，我们开发了一个自动化的第一性原理工作流程来计算非谐和声子性质，并构建了一个包含6000多种无机化合物的综合数据库。利用这个数据集，我们训练了一个图神经网络模型，从结构参数预测热导率和光谱值，证明了预测精度随着训练数据量的增加而提高的缩放规律。使用该模型进行高通量筛选，可以识别出具有极端热导率的材料——无论是高还是低。所得到的数据库为声子的非谐和行为提供了有价值的见解，从而加速了先进功能材料的设计和开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the anharmonic phonon properties of crystal compounds -- suchas phonon lifetimes and thermal conductivities -- is essential forinvestigating and optimizing their thermal transport behaviors. Theseproperties also impact optical, electronic, and magnetic characteristicsthrough interactions between phonons and other quasiparticles and fields. Inthis study, we develop an automated first-principles workflow to calculateanharmonic phonon properties and build a comprehensive database encompassingmore than 6,000 inorganic compounds. Utilizing this dataset, we train a graphneural network model to predict thermal conductivity values and spectra fromstructural parameters, demonstrating a scaling law in which prediction accuracyimproves with increasing training data size. High-throughput screening with themodel enables the identification of materials exhibiting extreme thermalconductivities -- both high and low. The resulting database offers valuableinsights into the anharmonic behavior of phonons, thereby accelerating thedesign and development of advanced functional materials.</description>
      <author>example@mail.com (Masato Ohnishi, Tianqi Deng, Pol Torres, Zhihao Xu, Terumasa Tadano, Haoming Zhang, Wei Nong, Masatoshi Hanai, Zhiting Tian, Ming Hu, Xiulin Ruan, Ryo Yoshida, Toyotaro Suzumura, Lucas Lindsay, Alan J. H. McGaughey, Tengfei Luo, Kedar Hippalgaonkar, Junichiro Shiomi)</author>
      <guid isPermaLink="false">2504.21245v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>FedHERO: A Federated Learning Approach for Node Classification Task on Heterophilic Graphs</title>
      <link>http://arxiv.org/abs/2504.21206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Federated Graph Learning (FGL) 通过保护数据隐私，允许客户端以分布式方式协作训练图神经网络 (GNNs)。然而，现有的FGL方法通常要求所有客户端拥有的图数据同质，以保证节点邻居分布模式的相似性。本文提出了FedHERO，一个旨在有效利用和共享异质图洞察的FGL框架，以解决节点邻居分布模式差异导致的问题。&lt;h4&gt;背景&lt;/h4&gt;FGL方法需要客户端拥有的图数据同质，以保证学习到的知识在所有客户端的本地模型中保持一致，从而在全局模型中正确聚合。&lt;h4&gt;目的&lt;/h4&gt;解决节点邻居分布模式差异导致的全局模型性能下降的问题。&lt;h4&gt;方法&lt;/h4&gt;FedHERO使用一个双通道GNN，并配备结构学习者，以识别和在学习不同节点邻居分布模式下的图中的通用模式。&lt;h4&gt;主要发现&lt;/h4&gt;FedHERO通过利用本地和共享的结构洞察，提高了单个客户端模型的表现，并为此领域处理具有各种节点邻居分布模式的图数据树立了新的先例。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的实验验证了FedHERO相较于现有方法的优越性能。&lt;h4&gt;翻译&lt;/h4&gt;Federated Graph Learning (FGL) 使客户端能够以保护数据隐私的方式协作训练图神经网络 (GNNs)。然而，现有的FGL方法通常要求所有客户端拥有的图数据同质，以确保节点邻居分布模式的相似性。因此，这些本地模型可以正确地聚合为全局模型，而不会损害整体性能。尽管如此，当节点的邻居分布模式在不同客户端之间发生变化时（例如，当客户端持有具有不同异质性的图时），它们的本地模型可能会从节点级别的预测任务中获得不同甚至冲突的知识。因此，通常会导致全局模型性能的灾难性下降。为了解决这个挑战，我们提出了FedHERO，一个旨在有效利用和共享异质图洞察的FGL框架。FedHERO的核心是一个双通道GNN，配备了一个结构学习者，旨在识别本地图中编码的结构知识。借助这个专门的组件，FedHERO使每个客户端的本地模型能够识别和学习适用于具有不同节点邻居分布模式图的通用模式。FedHERO不仅通过利用本地和共享的结构洞察来提高单个客户端模型的表现，而且在该领域树立了处理具有各种节点邻居分布模式图数据的新先例。我们进行了广泛的实验，以验证FedHERO相较于现有方法的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Graph Learning (FGL) empowers clients to collaboratively trainGraph neural networks (GNNs) in a distributed manner while preserving dataprivacy. However, FGL methods usually require that the graph data owned by allclients is homophilic to ensure similar neighbor distribution patterns ofnodes. Such an assumption ensures that the learned knowledge is consistentacross the local models from all clients. Therefore, these local models can beproperly aggregated as a global model without undermining the overallperformance. Nevertheless, when the neighbor distribution patterns of nodesvary across different clients (e.g., when clients hold graphs with differentlevels of heterophily), their local models may gain different and even conflictknowledge from their node-level predictive tasks. Consequently, aggregatingthese local models usually leads to catastrophic performance deterioration onthe global model. To address this challenge, we propose FedHERO, an FGLframework designed to harness and share insights from heterophilic graphseffectively. At the heart of FedHERO is a dual-channel GNN equipped with astructure learner, engineered to discern the structural knowledge encoded inthe local graphs. With this specialized component, FedHERO enables the localmodel for each client to identify and learn patterns that are universallyapplicable across graphs with different patterns of node neighbordistributions. FedHERO not only enhances the performance of individual clientmodels by leveraging both local and shared structural insights but also sets anew precedent in this field to effectively handle graph data with various nodeneighbor distribution patterns. We conduct extensive experiments to validatethe superior performance of FedHERO against existing alternatives.</description>
      <author>example@mail.com (Zihan Chen, Xingbo Fu, Yushun Dong, Jundong Li, Cong Shen)</author>
      <guid isPermaLink="false">2504.21206v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Multi-level datasets training method in Physics-Informed Neural Networks</title>
      <link>http://arxiv.org/abs/2504.21328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  33 pages, 12figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Physics-Informed Neural Networks (PINNs) 在解决偏微分方程 (PDEs) 方面表现出巨大潜力，但面临难以解决的挑战和高频成分问题，影响准确性和收敛性。&lt;h4&gt;背景&lt;/h4&gt;PINNs 能够结合物理定律进行多领域应用，但存在计算成本增加、精度损失或解发散的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来减轻上述问题，提高训练准确性。&lt;h4&gt;方法&lt;/h4&gt;受CFD领域的多网格方法启发，通过不同级别的训练样本训练，有效去除不同频率的错误，从而在不调整神经网络结构、损失权重和超参数的情况下提高训练精度。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在1D高频率常微分方程和2D对流扩散方程中表现出效，并且在稳态Lid-driven cavity flows的经典基准问题中应用，显示了对高频多模式问题的适用性和效果。通过不同的训练序列模式，预测精度提高了30%至60%。&lt;h4&gt;结论&lt;/h4&gt;该方法与迁移学习技术结合，可以解决更复杂的问题（如更高的Reynolds数）。结果表明，该方法能够在Re=5000的情况下产生良好的预测，展示了解决复杂高频PDEs的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于物理的神经网络（PINNs）作为一种解决偏微分方程（PDEs）的有前景的方法，在计算机科学和各个物理相关领域受到广泛关注。尽管已证明其能够结合物理定律进行多种应用，PINNs 仍面临难以解决的挑战，这些挑战涉及难以解决的问题和/或具有高频成分的解，导致精度和收敛性问题。这不仅会增加计算成本，还可能导致精度损失或解发散。本研究提出了一种替代方法来减轻上述问题。受CFD社区中的多网格方法的启发，当前方法的底层思想是通过使用不同级别的训练样本进行训练，有效地去除不同频率的错误，从而以更简单的方式提高训练精度，而不需要在微调神经网络结构、损失权重以及超参数上花费时间。为了证明当前方法的效力，我们首先研究了具有高频成分的1D常微分方程和具有V循环训练策略的2D对流扩散方程。最后，当前方法被用于不同雷诺数下的经典基准问题——稳态Lid-driven cavity flows，以研究该问题涉及多模式高频的适用性和效果。通过各种训练序列模式，预测精度提高了30%至60%。我们还研究了当前方法与迁移学习技术之间的协同作用，以解决更复杂的问题（即更高的Re）。从目前的结果来看，当前框架甚至对于Re=5000的情况也能产生良好的预测，展示了其解决复杂高频PDEs的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-Informed Neural Networks have emerged as a promising methodology forsolving PDEs, gaining significant attention in computer science and variousphysics-related fields. Despite being demonstrated the ability to incorporatethe physics of laws for versatile applications, PINNs still struggle with thechallenging problems which are stiff to be solved and/or have high-frequencycomponents in the solutions, resulting in accuracy and convergence issues. Itmay not only increase computational costs, but also lead to accuracy loss orsolution divergence. In this study, an alternative approach is proposed tomitigate the above-mentioned problems. Inspired by the multi-grid method in CFDcommunity, the underlying idea of the current approach is to efficiently removedifferent frequency errors via training with different levels of trainingsamples, resulting in a simpler way to improve the training accuracy withoutspending time in fine-tuning of neural network structures, loss weights as wellas hyperparameters. To demonstrate the efficacy of current approach, we firstinvestigate canonical 1D ODE with high-frequency component and 2Dconvection-diffusion equation with V-cycle training strategy. Finally, thecurrent method is employed for the classical benchmark problem of steadyLid-driven cavity flows at different Reynolds numbers, to investigate theapplicability and efficacy for the problem involved multiple modes of high andlow frequency. By virtue of various training sequence modes, improvementthrough predictions lead to 30% to 60% accuracy improvement. We alsoinvestigate the synergies between current method and transfer learningtechniques for more challenging problems (i.e., higher Re). From the presentresults, it also revealed that the current framework can produce goodpredictions even for the case of Re=5000, demonstrating the ability to solvecomplex high-frequency PDEs.</description>
      <author>example@mail.com (Yao-Hsuan Tsai, Hsiao-Tung Juan, Pao-Hsiung Chiu, Chao-An Lin)</author>
      <guid isPermaLink="false">2504.21328v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>eNCApsulate: NCA for Precision Diagnosis on Capsule Endoscopes</title>
      <link>http://arxiv.org/abs/2504.21562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于神经细胞自动机（NCA）的无线胶囊内窥镜图像处理方法，用于病理检测和深度估计，并在ESP32微控制器上实现，以实现胶囊内窥镜的精确定位。&lt;h4&gt;背景&lt;/h4&gt;无线胶囊内窥镜是一种非侵入性的胃肠道成像方法，但其视频数据量大，定位胶囊后需要大量时间审查，且现有技术如出血检测和深度估计方法存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一种在小型化设备上可靠进行出血分割和深度估计的方法，以实现胶囊内窥镜的精确定位。&lt;h4&gt;方法&lt;/h4&gt;使用NCA进行出血分割和深度估计，将大型基础模型精简为轻量级NCA架构，并将训练好的NCA模型部署到ESP32微控制器上。&lt;h4&gt;主要发现&lt;/h4&gt;NCA在出血分割和深度估计方面比其他便携式分割模型更准确，同时内存参数存储量比其他小型化模型低100倍以上。NCA的深度估计视觉效果令人信服，有时甚至优于伪地面真实值。对ESP32-S3的运行时优化显著提高了平均推理速度。&lt;h4&gt;结论&lt;/h4&gt;本研究首次实现了在小型化设备上进行可靠出血分割和深度估计，为结合视觉里程计进行胶囊精确定位的精确诊断开辟了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无线胶囊内窥镜是一种非侵入性的整个胃肠道成像方法，是传统内窥镜的无痛替代品。它生成大量的视频数据，需要大量审查时间，并且在吞咽后定位胶囊是一个挑战。出血检测和深度估计等技术有助于病理定位，但深度学习模型通常太大，无法直接在胶囊上运行。针对出血分割和深度估计的神经网络细胞自动机（NCA）在胶囊内窥镜图像上进行了训练。对于单目深度估计，我们将大型基础模型精简为轻量级的NCA架构，将基础模型的输出作为伪地面真实值。然后，我们将训练好的NCA移植到ESP32微控制器上，使小型化到摄像头胶囊的硬件上实现高效的图像处理。NCA比其他便携式分割模型更准确（Dice），同时比其他小型化模型在内存中存储的参数少100倍以上。NCA的深度估计视觉效果令人信服，有时甚至优于伪地面真实值。在ESP32-S3上的运行时优化显著提高了平均推理速度，提高了3倍以上。通过几个算法调整和蒸馏，可以将NCA模型封装到适合无线胶囊内窥镜的微控制器中。这是首次在小型化设备上实现可靠出血分割和深度估计的工作，为结合视觉里程计作为胶囊精确定位手段的精确诊断铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wireless Capsule Endoscopy is a non-invasive imaging method for the entiregastrointestinal tract, and is a pain-free alternative to traditionalendoscopy. It generates extensive video data that requires significant reviewtime, and localizing the capsule after ingestion is a challenge. Techniqueslike bleeding detection and depth estimation can help with localization ofpathologies, but deep learning models are typically too large to run directlyon the capsule. Neural Cellular Automata (NCA) for bleeding segmentation anddepth estimation are trained on capsule endoscopic images. For monocular depthestimation, we distill a large foundation model into the lean NCA architecture,by treating the outputs of the foundation model as pseudo ground truth. We thenport the trained NCA to the ESP32 microcontroller, enabling efficient imageprocessing on hardware as small as a camera capsule. NCA are more accurate(Dice) than other portable segmentation models, while requiring more than 100xfewer parameters stored in memory than other small-scale models. The visualresults of NCA depth estimation look convincing, and in some cases beat therealism and detail of the pseudo ground truth. Runtime optimizations on theESP32-S3 accelerate the average inference speed significantly, by more thanfactor 3. With several algorithmic adjustments and distillation, it is possibleto eNCApsulate NCA models into microcontrollers that fit into wireless capsuleendoscopes. This is the first work that enables reliable bleeding segmentationand depth estimation on a miniaturized device, paving the way for precisediagnosis combined with visual odometry as a means of precise localization ofthe capsule -- on the capsule.</description>
      <author>example@mail.com (Henry John Krumb, Anirban Mukhopadhyay)</author>
      <guid isPermaLink="false">2504.21562v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>VideoMultiAgents: A Multi-Agent Framework for Video Question Answering</title>
      <link>http://arxiv.org/abs/2504.20091v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为VideoMultiAgents的视频问答框架，该框架通过整合视觉、场景图分析和文本处理等专门代理，增强了视频理解能力，并通过问题引导的标题生成提高了答案的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的视频问答方法往往依赖于将帧级字幕输入到单一模型中，这难以充分捕捉时间和交互式上下文。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述局限性，提出了VideoMultiAgents框架，旨在通过多模态推理提高视频理解。&lt;h4&gt;方法&lt;/h4&gt;VideoMultiAgents框架包括视觉、场景图分析和文本处理等专门代理，并通过问题引导的标题生成来生成与查询直接相关的字幕。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在Intent-QA、EgoSchema子集和NExT-QA数据集上均取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;VideoMultiAgents框架通过多模态推理和问题引导的标题生成，显著提高了视频问答的准确性。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a video question answering framework called VideoMultiAgents, which integrates specialized agents for vision, scene graph analysis, and text processing to enhance video understanding and improve answer accuracy through question-guided caption generation. Experimental results demonstrate that this method achieves state-of-the-art performance on the Intent-QA, EgoSchema subset, and NExT-QA datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Question Answering (VQA) inherently relies on multimodal reasoning,integrating visual, temporal, and linguistic cues to achieve a deeperunderstanding of video content. However, many existing methods rely on feedingframe-level captions into a single model, making it difficult to adequatelycapture temporal and interactive contexts. To address this limitation, weintroduce VideoMultiAgents, a framework that integrates specialized agents forvision, scene graph analysis, and text processing. It enhances videounderstanding leveraging complementary multimodal reasoning from independentlyoperating agents. Our approach is also supplemented with a question-guidedcaption generation, which produces captions that highlight objects, actions,and temporal transitions directly relevant to a given query, thus improving theanswer accuracy. Experimental results demonstrate that our method achievesstate-of-the-art performance on Intent-QA (79.0%, +6.2% over previous SOTA),EgoSchema subset (75.4%, +3.4%), and NExT-QA (79.6%, +0.4%). The source code isavailable at https://github.com/PanasonicConnect/VideoMultiAgents.</description>
      <author>example@mail.com (Noriyuki Kugo, Xiang Li, Zixin Li, Ashish Gupta, Arpandeep Khatua, Nidhish Jain, Chaitanya Patel, Yuta Kyuragi, Yasunori Ishii, Masamoto Tanabiki, Kazuki Kozuka, Ehsan Adeli)</author>
      <guid isPermaLink="false">2504.20091v2</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal Transfer Learning for Dynamic Facial Emotion Recognition in the Wild</title>
      <link>http://arxiv.org/abs/2504.21248v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用多模态迁移学习来提高基于视频的动态面部表情识别（DFEW）数据集上的面部表情识别（FER）性能。&lt;h4&gt;背景&lt;/h4&gt;面部表情识别是计算机视觉的一个子集，在人类-计算机交互、医疗保健和客户服务中具有重要作用。FER是一个具有挑战性的问题领域，因为准确的分类需要模型能够区分面部特征的微妙变化。&lt;h4&gt;目的&lt;/h4&gt;探索使用预训练的ResNets、OpenPose和OmniVec网络组合，以及跨时间、多模态特征对分类准确性的影响。&lt;h4&gt;方法&lt;/h4&gt;本文使用预训练的ResNets、OpenPose和OmniVec网络，结合多模态特征生成器，来提高基于变换器的分类模型的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，这些精心调整的多模态特征生成器适度提高了基于变换器的分类模型的准确性。&lt;h4&gt;结论&lt;/h4&gt;多模态迁移学习可以有效地提高视频基础上面部表情识别的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Facial expression recognition (FER) is a subset of computer vision withimportant applications for human-computer-interaction, healthcare, and customerservice. FER represents a challenging problem-space because accurateclassification requires a model to differentiate between subtle changes infacial features. In this paper, we examine the use of multi-modal transferlearning to improve performance on a challenging video-based FER dataset,Dynamic Facial Expression in-the-Wild (DFEW). Using a combination of pretrainedResNets, OpenPose, and OmniVec networks, we explore the impact ofcross-temporal, multi-modal features on classification accuracy. Ultimately, wefind that these finely-tuned multi-modal feature generators modestly improveaccuracy of our transformer-based classification model.</description>
      <author>example@mail.com (Ezra Engel, Lishan Li, Chris Hudy, Robert Schleusner)</author>
      <guid isPermaLink="false">2504.21248v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Diff-Prompt: Diffusion-Driven Prompt Generator with Mask Supervision</title>
      <link>http://arxiv.org/abs/2504.21423v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Diff-Prompt的Prompt学习新方法，通过扩散模型生成丰富且精细的提示信息，用于复杂下游任务，并取得了显著的效果。&lt;h4&gt;背景&lt;/h4&gt;Prompt学习在微调预训练的多模态模型中显示出有前景的结果，但在更复杂和精细的任务中，性能提升有限。&lt;h4&gt;目的&lt;/h4&gt;旨在使用扩散模型为复杂下游任务生成丰富和精细的提示信息。&lt;h4&gt;方法&lt;/h4&gt;方法包括三个阶段：首先训练一个Mask-VAE来压缩掩码到潜在空间；其次，利用改进的Diffusion Transformer在潜在空间中训练提示生成器；最后，将提示生成器的去噪过程与预训练模型在语义空间中对齐，并使用生成的提示来微调模型。&lt;h4&gt;主要发现&lt;/h4&gt;在复杂像素级下游任务，即指代表达理解任务上，Diff-Prompt相较于基础模型在R@1和R@5上分别提升了8.87和14.05，并在多个指标上优于其他最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;实验结果验证了该方法的有效性，并突出了使用生成模型进行提示生成的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Prompt学习在微调预训练的多模态模型中已显示出有前景的结果。然而，当应用于更复杂和精细的任务时，性能提升有限。原因是大多数现有方法直接通过损失反向传播优化提示生成过程中涉及的参数，这限制了提示表示的丰富性和特异性。在本文中，我们提出了扩散驱动提示生成器（Diff-Prompt），旨在使用扩散模型为复杂下游任务生成丰富和精细的提示信息。具体来说，我们的方法包括三个阶段。在第一阶段，我们训练一个Mask-VAE将掩码压缩到潜在空间。在第二阶段，我们利用改进的扩散Transformer（DiT）在潜在空间中训练提示生成器，使用掩码进行监督。在第三阶段，我们将提示生成器的去噪过程与预训练模型在语义空间中对齐，并使用生成的提示来微调模型。我们在一个复杂的像素级下游任务，即指代表达理解任务上进行了实验，并将我们的方法与各种参数高效的微调方法进行了比较。与基础模型相比，Diff-Prompt在R@1和R@5上分别提高了8.87和14.05，并在多个指标上优于其他最先进的方法。实验结果验证了我们的方法的有效性，并突出了使用生成模型进行提示生成的潜力。代码可在https://github.com/Kelvin-ywc/diff-prompt上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prompt learning has demonstrated promising results in fine-tuning pre-trainedmultimodal models. However, the performance improvement is limited when appliedto more complex and fine-grained tasks. The reason is that most existingmethods directly optimize the parameters involved in the prompt generationprocess through loss backpropagation, which constrains the richness andspecificity of the prompt representations. In this paper, we proposeDiffusion-Driven Prompt Generator (Diff-Prompt), aiming to use the diffusionmodel to generate rich and fine-grained prompt information for complexdownstream tasks. Specifically, our approach consists of three stages. In thefirst stage, we train a Mask-VAE to compress the masks into latent space. Inthe second stage, we leverage an improved Diffusion Transformer (DiT) to traina prompt generator in the latent space, using the masks for supervision. In thethird stage, we align the denoising process of the prompt generator with thepre-trained model in the semantic space, and use the generated prompts tofine-tune the model. We conduct experiments on a complex pixel-level downstreamtask, referring expression comprehension, and compare our method with variousparameter-efficient fine-tuning approaches. Diff-Prompt achieves a maximumimprovement of 8.87 in R@1 and 14.05 in R@5 compared to the foundation modeland also outperforms other state-of-the-art methods across multiple metrics.The experimental results validate the effectiveness of our approach andhighlight the potential of using generative models for prompt generation. Codeis available at https://github.com/Kelvin-ywc/diff-prompt.</description>
      <author>example@mail.com (Weicai Yan, Wang Lin, Zirun Guo, Ye Wang, Fangming Feng, Xiaoda Yang, Zehan Wang, Tao Jin)</author>
      <guid isPermaLink="false">2504.21423v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Artificial Intelligence for Personalized Prediction of Alzheimer's Disease Progression: A Survey of Methods, Data Challenges, and Future Directions</title>
      <link>http://arxiv.org/abs/2504.21189v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了人工智能在个性化阿尔茨海默病进展预测中的应用方法。&lt;h4&gt;背景&lt;/h4&gt;阿尔茨海默病的进展存在显著的个体差异，这给准确预测和个性化护理规划带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发能够预测患者特定疾病轨迹的预测模型。&lt;h4&gt;方法&lt;/h4&gt;文章回顾了包括状态空间模型、深度学习技术（如循环神经网络）、图神经网络以及人工智能驱动的数字孪生等关键方法。&lt;h4&gt;主要发现&lt;/h4&gt;讨论了数据限制带来的挑战，如高维度、缺失数据和数据集不平衡，并提出了合成数据生成策略。&lt;h4&gt;结论&lt;/h4&gt;强调了多模态集成、模型可解释性和泛化性的趋势，并指出了开放性挑战和未来研究方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：阿尔茨海默病（AD）的特征是个体间进展的显著差异，这给准确的预测和个性化的护理规划带来了复杂性。这种异质性强调了开发能够预测患者特定疾病轨迹的预测模型的迫切需要。人工智能（AI）通过分析复杂、多模态和纵向患者数据，提供了强大的工具来应对这一挑战。本文全面概述了应用于个性化AD进展预测的AI方法。我们回顾了包括用于捕捉时间动态的状态空间模型、用于序列建模的深度学习技术（如循环神经网络）、用于利用网络结构的图神经网络（GNNs）以及人工智能驱动的数字孪生等新兴概念。认识到数据限制往往阻碍进展，我们检查了常见挑战，如高维度、缺失数据和数据集不平衡。我们进一步讨论了人工智能驱动的缓解策略，特别是使用变分自编码器（VAEs）和生成对抗网络（GANs）进行数据增强和平衡。该综述综合了当前方法的优点和局限性，强调了向多模态集成和持续需要模型可解释性和泛化性的趋势。最后，我们确定了关键开放性挑战，包括稳健的外部验证、临床整合和伦理考虑，并概述了混合模型、因果推理和联邦学习等有希望的未来研究方向。本综述旨在巩固现有知识并指导未来在开发与临床相关的AI工具以实现个性化AD预测方面的努力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Alzheimer's Disease (AD) is marked by significant inter-individualvariability in its progression, complicating accurate prognosis andpersonalized care planning. This heterogeneity underscores the critical needfor predictive models capable of forecasting patient-specific diseasetrajectories. Artificial Intelligence (AI) offers powerful tools to addressthis challenge by analyzing complex, multi-modal, and longitudinal patientdata. This paper provides a comprehensive survey of AI methodologies applied topersonalized AD progression prediction. We review key approaches includingstate-space models for capturing temporal dynamics, deep learning techniqueslike Recurrent Neural Networks for sequence modeling, Graph Neural Networks(GNNs) for leveraging network structures, and the emerging concept of AI-drivendigital twins for individualized simulation. Recognizing that data limitationsoften impede progress, we examine common challenges such as highdimensionality, missing data, and dataset imbalance. We further discussAI-driven mitigation strategies, with a specific focus on synthetic datageneration using Variational Autoencoders (VAEs) and Generative AdversarialNetworks (GANs) to augment and balance datasets. The survey synthesizes thestrengths and limitations of current approaches, emphasizing the trend towardsmultimodal integration and the persistent need for model interpretability andgeneralizability. Finally, we identify critical open challenges, includingrobust external validation, clinical integration, and ethical considerations,and outline promising future research directions such as hybrid models, causalinference, and federated learning. This review aims to consolidate currentknowledge and guide future efforts in developing clinically relevant AI toolsfor personalized AD prognostication.</description>
      <author>example@mail.com (Gulsah Hancerliogullari Koksalmis, Bulent Soykan, Laura J. Brattain, Hsin-Hsiung Huang)</author>
      <guid isPermaLink="false">2504.21189v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Galvatron: An Automatic Distributed System for Efficient Foundation Model Training</title>
      <link>http://arxiv.org/abs/2504.21411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Galvatron是一个用于高效训练大规模基础模型的分布式系统。&lt;h4&gt;背景&lt;/h4&gt;传统模型训练过程中，选择最优并行策略非常复杂。&lt;h4&gt;目的&lt;/h4&gt;Galvatron旨在自动识别最有效的混合策略，提高大规模模型训练的效率。&lt;h4&gt;方法&lt;/h4&gt;系统包括硬件和模型分析的性能分析器，决策树和动态规划策略的搜索引擎，以及执行这些策略的高效运行时环境。&lt;h4&gt;主要发现&lt;/h4&gt;在各种集群上的基准测试表明，Galvatron相比现有框架具有更高的吞吐量。&lt;h4&gt;结论&lt;/h4&gt;Galvatron是一个开源系统，提供了用户友好的界面和全面的文档，使复杂的分布式训练变得可行和高效。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Galvatron is a distributed system for efficiently training large-scaleFoundation Models. It overcomes the complexities of selecting optimalparallelism strategies by automatically identifying the most efficient hybridstrategy, incorporating data, tensor, pipeline, sharded data, and sequenceparallelism, along with recomputation. The system's architecture includes aprofiler for hardware and model analysis, a search engine for strategyoptimization using decision trees and dynamic programming, and a runtime forexecuting these strategies efficiently. Benchmarking on various clustersdemonstrates Galvatron's superior throughput compared to existing frameworks.This open-source system offers user-friendly interfaces and comprehensivedocumentation, making complex distributed training accessible and efficient.The source code of Galvatron is available athttps://github.com/PKU-DAIR/Hetu-Galvatron.</description>
      <author>example@mail.com (Xinyi Liu, Yujie Wang, Shenhan Zhu, Fangcheng Fu, Qingshuo Liu, Guangming Lin, Bin Cui)</author>
      <guid isPermaLink="false">2504.21411v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>LIFT: LLM-Based Pragma Insertion for HLS via GNN Supervised Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.21187v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于大型语言模型（LLM）的HLS编码助手LIFT，用于自动生成性能关键pragma，以解决FPGA编程中性能优化的问题。&lt;h4&gt;背景&lt;/h4&gt;FPGA在数据中心环境中因其可重构性和能效而被广泛采用。尽管HLS工具提高了编程抽象级别，但实现高性能仍需要专家知识和手动插入优化pragma。&lt;h4&gt;目的&lt;/h4&gt;提出一种自动生成性能关键pragma的方法，以简化FPGA编程并提高性能。&lt;h4&gt;方法&lt;/h4&gt;LIFT通过将LLM与图神经网络（GNN）紧密集成和监督训练过程来优化。它结合了LLM的序列建模能力和GNN的结构和语义理解，以处理代码及其控制/数据依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;LIFT在性能上优于现有的AutoDSE和HARP，以及GPT-4o，平均性能提升分别为3.52倍、2.16倍和66倍。&lt;h4&gt;结论&lt;/h4&gt;LIFT是一种有效的编码助手，可以自动生成性能关键pragma，从而提高FPGA设计的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; FPGAs are increasingly adopted in datacenter environments for theirreconfigurability and energy efficiency. High-Level Synthesis (HLS) tools haveeased FPGA programming by raising the abstraction level from RTL to untimedC/C++, yet attaining high performance still demands expert knowledge anditerative manual insertion of optimization pragmas to modify themicroarchitecture. To address this challenge, we propose LIFT, a large languagemodel (LLM)-based coding assistant for HLS that automatically generatesperformance-critical pragmas given a C/C++ design. We fine-tune the LLM bytightly integrating and supervising the training process with a graph neuralnetwork (GNN), combining the sequential modeling capabilities of LLMs with thestructural and semantic understanding of GNNs necessary for reasoning over codeand its control/data dependencies. On average, LIFT produces designs thatimprove performance by 3.52x and 2.16x than prior state-of the art AutoDSE andHARP respectively, and 66x than GPT-4o.</description>
      <author>example@mail.com (Neha Prakriya, Zijian Ding, Yizhou Sun, Jason Cong)</author>
      <guid isPermaLink="false">2504.21187v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>JAvaScript Multimodal INformation Explorer</title>
      <link>http://arxiv.org/abs/2504.21393v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Jasmine，一个基于JavaScript的多模态信息探索器，用于处理和分析大量天文数据。&lt;h4&gt;背景&lt;/h4&gt;天文数据量庞大、信息丰富，处理这些数据是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决处理天文数据的问题。&lt;h4&gt;方法&lt;/h4&gt;引入了Jasmine，它允许用户打开不同的数据查看模态，显示集合中的特定数据点。目前支持图像数据和点云对象。用户可以选择显示哪些数据点信息。点云具有交互性，允许缩放、滚动和旋转。通过自动编码实现数据集的键属性排列。&lt;h4&gt;主要发现&lt;/h4&gt;Jasmine支持多种数据视图，具有交互性，并通过自动编码优化了数据点的显示。&lt;h4&gt;结论&lt;/h4&gt;Jasmine是一个有效的工具，可以用于分析、查看、探索和通信天文数据。&lt;h4&gt;翻译&lt;/h4&gt;Astronomical data is rich in volume, information and facets. Although this offers multiple research perspectives, processing the data remains a challenge. Infrastructures for analyzing, inspecting, exploring and communicating with data are mandatory. To address this issue, we introduce Jasmine, the JAvaScript Multimodal INformation Explorer. Jasmine allows users to open different dataviewer modals that show a specific data point from a set. The viewer currently supports image data, as well as point cloud objects. Users can decide on which information about the data point they like to have displayed. Point clouds are interactive and allow for zooming, tossing, and turning. Picking a data point is enabled by providing a structured view of the set, arranged by a key property. This arrangement is achieved by autoencoding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Astronomical data is rich in volume, information and facets. Although thisoffers multiple research perspectives, processing the data remains a challenge.Infrastructures for analyzing, inspecting, exploring and communicating withdata are mandatory. To address this issue, we introduce Jasmine, the JAvaScriptMultimodal INformation Explorer. Jasmine allows users to open different dataviewer modals that show a specific data point from a set. The viewer currentlysupports image data, as well as point cloud objects. Users can decide on whichinformation about the data point they like to have displayed. Point clouds areinteractive and allow for zooming, tossing, and turning. Picking a data pointis enabled by providing a structured view of the set, arranged by a keyproperty. This arrangement is achieved by autoencoding.</description>
      <author>example@mail.com (Fenja Schweder, Sebastian Trujillo-Gomez, Kai Polsterer)</author>
      <guid isPermaLink="false">2504.21393v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>A Brief Review for Compression and Transfer Learning Techniques in DeepFake Detection</title>
      <link>http://arxiv.org/abs/2504.21066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在边缘设备上训练和部署深度伪造检测模型，探讨了通过压缩技术和迁移学习方法来降低计算需求和训练开销，以提高数据隐私和保密性。&lt;h4&gt;背景&lt;/h4&gt;在边缘设备上处理数据可以保护数据隐私，但受限于边缘设备的计算和内存资源。&lt;h4&gt;目的&lt;/h4&gt;通过压缩技术和迁移学习方法，解决边缘设备资源受限的问题。&lt;h4&gt;方法&lt;/h4&gt;使用Synthbuster、RAISE和ForenSynths数据集，评估了剪枝、知识蒸馏（KD）、量化、微调和基于适配器的技术。&lt;h4&gt;主要发现&lt;/h4&gt;压缩和迁移学习在高达90%的压缩率下仍能有效实现，且当训练和验证数据来自同一深度伪造模型时，性能保持不变。然而，当测试数据集由训练集中未出现的深度伪造模型生成时，出现了领域泛化问题。&lt;h4&gt;结论&lt;/h4&gt;压缩和迁移学习是提高边缘设备上深度伪造检测模型性能的有效方法，但在处理未在训练集中出现的深度伪造模型时存在挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training and deploying deepfake detection models on edge devices offers theadvantage of maintaining data privacy and confidentiality by processing itclose to its source. However, this approach is constrained by the limitedcomputational and memory resources available at the edge. To address thischallenge, we explore compression techniques to reduce computational demandsand inference time, alongside transfer learning methods to minimize trainingoverhead. Using the Synthbuster, RAISE, and ForenSynths datasets, we evaluatethe effectiveness of pruning, knowledge distillation (KD), quantization,fine-tuning, and adapter-based techniques. Our experimental results demonstratethat both compression and transfer learning can be effectively achieved, evenwith a high compression level of 90%, remaining at the same performance levelwhen the training and validation data originate from the same DeepFake model.However, when the testing dataset is generated by DeepFake models not presentin the training set, a domain generalization issue becomes evident.</description>
      <author>example@mail.com (Andreas Karathanasis, John Violos, Ioannis Kompatsiaris, Symeon Papadopoulos)</author>
      <guid isPermaLink="false">2504.21066v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*</title>
      <link>http://arxiv.org/abs/2504.11014v4</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted (Poster) to the 3rd CV4MR Workshop at CVPR 2025:  https://openreview.net/forum?id=00RQ8Cv3ia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GATE3D的新型弱监督框架，专门用于通用单目3D目标检测，通过一致性损失在2D和3D预测之间架起桥梁，以解决多领域训练中标注数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;计算机视觉领域正趋向于开发能够同时处理多种不同任务的通用模型，这通常需要跨多领域数据集进行联合训练以确保有效的泛化。然而，由于标注有准确3D地面真实标签的数据集稀缺，尤其是在典型的基于道路的自动驾驶环境之外，单目3D目标检测在多领域训练中面临独特挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出一种能够有效处理非道路环境中的行人检测问题的弱监督框架。&lt;h4&gt;方法&lt;/h4&gt;GATE3D通过使用伪标签和一致性损失在2D和3D预测之间进行联合训练，以实现跨领域的泛化。&lt;h4&gt;主要发现&lt;/h4&gt;GATE3D在KITTI基准数据集和作者收集的室内办公数据集上取得了有竞争力的性能，表明该框架能够显著加速从有限标注数据中的学习过程。&lt;h4&gt;结论&lt;/h4&gt;GATE3D在机器人、增强现实和虚拟现实应用中具有广泛的应用潜力，通过有效的预训练策略，显著加速了从有限标注数据中的学习。&lt;h4&gt;翻译&lt;/h4&gt;The emerging trend in computer vision emphasizes developing universal models capable of simultaneously addressing multiple diverse tasks. Such universality typically requires joint training across multi-domain datasets to ensure effective generalization. However, monocular 3D object detection presents unique challenges in multi-domain training due to the scarcity of datasets annotated with accurate 3D ground-truth labels, especially beyond typical road-based autonomous driving contexts. To address this challenge, we introduce a novel weakly supervised framework leveraging pseudo-labels. Current pretrained models often struggle to accurately detect pedestrians in non-road environments due to inherent dataset biases. Unlike generalized image-based 2D object detection models, achieving similar generalization in monocular 3D detection remains largely unexplored. In this paper, we propose GATE3D, a novel framework designed specifically for generalized monocular 3D object detection via weak supervision. GATE3D effectively bridges domain gaps by employing consistency losses between 2D and 3D predictions. Remarkably, our model achieves competitive performance on the KITTI benchmark as well as on an indoor-office dataset collected by us to evaluate the generalization capabilities of our framework. Our results demonstrate that GATE3D significantly accelerates learning from limited annotated data through effective pre-training strategies, highlighting substantial potential for broader impacts in robotics, augmented reality, and virtual reality applications. Project page: https://ies0411.github.io/GATE3D/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emerging trend in computer vision emphasizes developing universal modelscapable of simultaneously addressing multiple diverse tasks. Such universalitytypically requires joint training across multi-domain datasets to ensureeffective generalization. However, monocular 3D object detection presentsunique challenges in multi-domain training due to the scarcity of datasetsannotated with accurate 3D ground-truth labels, especially beyond typicalroad-based autonomous driving contexts. To address this challenge, we introducea novel weakly supervised framework leveraging pseudo-labels. Currentpretrained models often struggle to accurately detect pedestrians in non-roadenvironments due to inherent dataset biases. Unlike generalized image-based 2Dobject detection models, achieving similar generalization in monocular 3Ddetection remains largely unexplored. In this paper, we propose GATE3D, a novelframework designed specifically for generalized monocular 3D object detectionvia weak supervision. GATE3D effectively bridges domain gaps by employingconsistency losses between 2D and 3D predictions. Remarkably, our modelachieves competitive performance on the KITTI benchmark as well as on anindoor-office dataset collected by us to evaluate the generalizationcapabilities of our framework. Our results demonstrate that GATE3Dsignificantly accelerates learning from limited annotated data througheffective pre-training strategies, highlighting substantial potential forbroader impacts in robotics, augmented reality, and virtual realityapplications. Project page: https://ies0411.github.io/GATE3D/</description>
      <author>example@mail.com (Eunsoo Im, Changhyun Jee, Jung Kwon Lee)</author>
      <guid isPermaLink="false">2504.11014v4</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>UniBiomed: A Universal Foundation Model for Grounded Biomedical Image Interpretation</title>
      <link>http://arxiv.org/abs/2504.21336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first universal foundation model for grounded biomedical image  interpretation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;UniBiomed是一种新型的基于多模态大语言模型和Segment Anything Model的通用基础模型，用于生物医学图像的 grounded interpretation，显著提高了生物医学图像分析的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;传统的AI方法在生物医学图像分析中通常依赖于分离的训练，如大型语言模型用于临床文本生成和分割模型用于目标提取，这导致在实际应用中缺乏灵活性，无法充分利用整体生物医学信息。&lt;h4&gt;目的&lt;/h4&gt;提出UniBiomed，旨在解决传统方法的问题，实现生物医学图像的全面、灵活的grounded interpretation。&lt;h4&gt;方法&lt;/h4&gt;UniBiomed结合了多模态大语言模型（MLLM）和Segment Anything Model（SAM），能够同时生成临床文本和分割相应的生物医学对象，实现grounded interpretation。为了开发UniBiomed，研究人员创建了一个包含超过2700万对图像、注释和文本描述的大规模数据集。&lt;h4&gt;主要发现&lt;/h4&gt;在84个内部和外部数据集上的广泛验证表明，UniBiomed在分割、疾病识别、区域感知诊断、视觉问答和报告生成等方面均达到了最先进的性能。与依赖临床专家进行预诊断和手动制作精确文本或视觉提示的先前模型不同，UniBiomed能够提供自动化的端到端grounded interpretation。&lt;h4&gt;结论&lt;/h4&gt;UniBiomed代表了生物医学AI的一个新突破，为更准确和高效的生物医学图像分析打开了强大的grounded interpretation能力，代表了临床工作流程中的一个新颖范式转变，将显著提高诊断效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态生物医学图像的解释为生物医学图像分析开辟了新的机遇。传统的AI方法通常依赖于分离的训练，即大型语言模型（LLMs）用于临床文本生成和分割模型用于目标提取，这导致在实际应用中缺乏灵活性，无法充分利用整体生物医学信息。为此，我们引入了UniBiomed，这是第一个用于grounded生物医学图像解释的通用基础模型。UniBiomed基于多模态大语言模型（MLLM）和Segment Anything Model（SAM）的全新集成，有效地统一了临床文本的生成和对应生物医学对象的分割，以实现grounded interpretation。这样，UniBiomed能够处理跨十个不同生物医学成像模态的广泛生物医学任务。为了开发UniBiomed，我们创建了一个包含超过2700万对图像、注释和文本描述的大规模数据集。在84个内部和外部数据集上的广泛验证表明，UniBiomed在分割、疾病识别、区域感知诊断、视觉问答和报告生成等方面均达到了最先进的性能。此外，与依赖临床专家进行预诊断和手动制作精确文本或视觉提示的先前模型不同，UniBiomed能够提供自动化的端到端grounded interpretation。这代表了临床工作流程中的一个新颖范式转变，将显著提高诊断效率。总之，UniBiomed代表了生物医学AI的一个新突破，为更准确和高效的生物医学图像分析打开了强大的grounded interpretation能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal interpretation of biomedical images opens up novel opportunitiesin biomedical image analysis. Conventional AI approaches typically rely ondisjointed training, i.e., Large Language Models (LLMs) for clinical textgeneration and segmentation models for target extraction, which results ininflexible real-world deployment and a failure to leverage holistic biomedicalinformation. To this end, we introduce UniBiomed, the first universalfoundation model for grounded biomedical image interpretation. UniBiomed isbased on a novel integration of Multi-modal Large Language Model (MLLM) andSegment Anything Model (SAM), which effectively unifies the generation ofclinical texts and the segmentation of corresponding biomedical objects forgrounded interpretation. In this way, UniBiomed is capable of tackling a widerange of biomedical tasks across ten diverse biomedical imaging modalities. Todevelop UniBiomed, we curate a large-scale dataset comprising over 27 milliontriplets of images, annotations, and text descriptions across ten imagingmodalities. Extensive validation on 84 internal and external datasetsdemonstrated that UniBiomed achieves state-of-the-art performance insegmentation, disease recognition, region-aware diagnosis, visual questionanswering, and report generation. Moreover, unlike previous models that rely onclinical experts to pre-diagnose images and manually craft precise textual orvisual prompts, UniBiomed can provide automated and end-to-end groundedinterpretation for biomedical image analysis. This represents a novel paradigmshift in clinical workflows, which will significantly improve diagnosticefficiency. In summary, UniBiomed represents a novel breakthrough in biomedicalAI, unlocking powerful grounded interpretation capabilities for more accurateand efficient biomedical image analysis.</description>
      <author>example@mail.com (Linshan Wu, Yuxiang Nie, Sunan He, Jiaxin Zhuang, Hao Chen)</author>
      <guid isPermaLink="false">2504.21336v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>NEP89: Universal neuroevolution potential for inorganic and organic materials across 89 elements</title>
      <link>http://arxiv.org/abs/2504.21286v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为NEP89的机器学习势能模型，该模型基于神经进化势能架构，在89种化学元素上实现了经验势能的速度和高度准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的机器学习势能模型往往针对特定材料或计算密集，限制了其更广泛的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个高效且准确的机器学习势能模型，以促进原子尺度模拟的广泛应用。&lt;h4&gt;方法&lt;/h4&gt;通过描述符空间子采样和迭代主动学习过程，构建了一个涵盖无机和有机材料的89种元素的紧凑且全面的训练数据集。&lt;h4&gt;主要发现&lt;/h4&gt;NEP89在预测性能上经过严格评估，与代表性基础模型相比，展现出可靠性和竞争力。NEP89的计算效率比同类模型高3-4个数量级，使得大规模原子尺度模拟成为可能，并支持在小型数据集上进行微调。&lt;h4&gt;结论&lt;/h4&gt;NEP89是机器学习势能领域的一项重大进步，能够支持高性能的原子尺度模拟，适用于多个研究领域和社区。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learned potentials (MLPs) offer near-first-principles accuracy foratomistic simulations, but many models are material-specific or computationallyintensive, limiting their broader use. Here, we introduce NEP89, a foundationmodel based on the neuroevolution potential (NEP) architecture, deliveringempirical-potential-like speed and high accuracy across 89 chemical elements. Acompact yet comprehensive training dataset covering inorganic and organicmaterials across 89 elements was curated through descriptor-space subsamplingand an iterative active-learning-like process applied to multiple datasets. Werigorously evaluated NEP89's predictive performance against representativefoundation models, demonstrating its reliability and competitive accuracyacross diverse benchmark studies. NEP89 is 3-4 orders of magnitude morecomputationally efficient than comparable models, enabling previouslyimpractical large-scale atomistic simulations for both inorganic and organicsystems. It also supports fine-tuning on small datasets, allowing rapidadaptation to user-specific applications. This work marks a significantadvancement in MLPs, enabling high-performance atomistic simulations acrossdiverse research fields and communities.</description>
      <author>example@mail.com (Ting Liang, Ke Xu, Eric Lindgren, Zherui Chen, Rui Zhao, Jiahui Liu, Benrui Tang, Bohan Zhang, Yanzhou Wang, Keke Song, Penghua Ying, Haikuan Dong, Shunda Chen, Paul Erhart, Zheyong Fan, Tapio Ala-Nissila, Jianbin Xu)</author>
      <guid isPermaLink="false">2504.21286v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks</title>
      <link>http://arxiv.org/abs/2504.20869v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络在应对图对抗攻击时的鲁棒性问题，并提出了基于噪声和分类边界的攻击策略。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在利用局部信息方面具有较强的学习能力，但在对抗攻击下不够鲁棒。&lt;h4&gt;目的&lt;/h4&gt;量化对抗攻击中每个扰动的强度，提高攻击策略的可解释性。&lt;h4&gt;方法&lt;/h4&gt;提出了噪声概念来量化对抗链接的攻击强度，并基于噪声和分类边界提出了三种攻击策略，通过单步和多步优化进行攻击。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上进行的实验证明了所提出的攻击策略的有效性，并分析了有效对抗扰动的偏好模式。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效量化攻击强度，并提供具有较高解释性的攻击策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have been widely utilized to solve graph-related tasksbecause of their strong learning power in utilizing the local information ofneighbors. However, recent studies on graph adversarial attacks have proventhat current graph neural networks are not robust against malicious attacks.Yet much of the existing work has focused on the optimization objective basedon attack performance to obtain (near) optimal perturbations, but paid lessattention to the strength quantification of each perturbation such as theinjection of a particular node/link, which makes the choice of perturbations ablack-box model that lacks interpretability. In this work, we propose theconcept of noise to quantify the attack strength of each adversarial link.Furthermore, we propose three attack strategies based on the defined noise andclassification margins in terms of single and multiple steps optimization.Extensive experiments conducted on benchmark datasets against threerepresentative graph neural networks demonstrate the effectiveness of theproposed attack strategies. Particularly, we also investigate the preferredpatterns of effective adversarial perturbations by analyzing the correspondingproperties of the selected perturbation nodes.</description>
      <author>example@mail.com (Junyuan Fang, Han Yang, Haixian Wen, Jiajing Wu, Zibin Zheng, Chi K. Tse)</author>
      <guid isPermaLink="false">2504.20869v2</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>GLIP-OOD: Zero-Shot Graph OOD Detection with Foundation Model</title>
      <link>http://arxiv.org/abs/2504.21186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图基础模型（GFM）的零样本图域外的检测方法，解决了图结构数据中的零样本OD检测问题。&lt;h4&gt;背景&lt;/h4&gt;零样本OD检测对于确保机器学习系统在动态和开放世界环境中的安全和可靠性至关重要。在视觉和文本领域，大规模预训练模型如视觉-语言模型（VLMs）和大型语言模型（LLMs）已经使零样本OD检测取得了显著进展。然而，由于图结构数据的复杂关系结构和缺乏针对图的强大、大规模预训练模型，图域外的零样本OD检测尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过利用图基础模型（GFM）实现零样本图域外的检测，并针对OD标签名称不可用的情况，提出一种新的框架GLIP-OOD。&lt;h4&gt;方法&lt;/h4&gt;1. 利用GFM在只有类别标签名称的情况下进行OD检测，无需节点级监督，在多个数据集上优于现有的监督方法。2. 引入GLIP-OOD框架，使用LLMs从无标签数据中生成语义信息丰富的伪OD标签，使GFM能够捕捉ID和OD类别之间的细微语义边界，并执行细粒度OD检测。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出的方法是第一个在完全零样本设置中实现节点级图域外检测的方法，并在四个基准文本属性图数据集上达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为图结构数据中的零样本OD检测提供了新的思路，对于提高机器学习系统的安全和可靠性具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution (OOD) detection is critical for ensuring the safety andreliability of machine learning systems, particularly in dynamic and open-worldenvironments. In the vision and text domains, zero-shot OOD detection - whichrequires no training on in-distribution (ID) data - has made significantprogress through the use of large-scale pretrained models such asvision-language models (VLMs) and large language models (LLMs). However,zero-shot OOD detection in graph-structured data remains largely unexplored,primarily due to the challenges posed by complex relational structures and theabsence of powerful, large-scale pretrained models for graphs. In this work, wetake the first step toward enabling zero-shot graph OOD detection by leveraginga graph foundation model (GFM). We show that, when provided only with classlabel names, the GFM can perform OOD detection without any node-levelsupervision - outperforming existing supervised methods across multipledatasets. To address the more practical setting where OOD label names areunavailable, we introduce GLIP-OOD, a novel framework that employs LLMs togenerate semantically informative pseudo-OOD labels from unlabeled data. Theselabels enable the GFM to capture nuanced semantic boundaries between ID and OODclasses and perform fine-grained OOD detection - without requiring any labelednodes. Our approach is the first to enable node-level graph OOD detection in afully zero-shot setting, and achieves state-of-the-art performance on fourbenchmark text-attributed graph datasets.</description>
      <author>example@mail.com (Haoyan Xu, Zhengtao Yao, Xuzhi Zhang, Ziyi Wang, Langzhou He, Yushun Dong, Philip S. Yu, Mengyuan Li, Yue Zhao)</author>
      <guid isPermaLink="false">2504.21186v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Parameter-Efficient Fine-Tuning for Foundation Models in Federated Learning</title>
      <link>http://arxiv.org/abs/2504.21099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  survey paper, under updating&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了在联邦学习环境中整合参数高效微调（PEFT）技术的进展。&lt;h4&gt;背景&lt;/h4&gt;基础模型通过在大规模数据集上预训练提供了强大而通用的架构，但针对特定任务进行微调需要大量计算资源。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供PEFT技术在联邦学习环境中的全面回顾，并分析其在数据异质性、通信效率、计算限制和隐私问题等挑战上的应用。&lt;h4&gt;方法&lt;/h4&gt;将现有方法分为三类：添加PEFT（引入新的可训练参数）、选择性PEFT（仅微调现有参数的子集）和重新参数化PEFT（转换模型架构以实现高效更新）。&lt;h4&gt;主要发现&lt;/h4&gt;分析了不同方法如何解决联邦设置中的独特挑战，并按应用领域组织文献，包括自然语言处理和计算机视觉任务。&lt;h4&gt;结论&lt;/h4&gt;讨论了有前景的研究方向，包括扩展到更大的基础模型、联邦PEFT方法的理论分析和资源受限环境中的可持续方法。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了在联邦学习环境中整合参数高效微调（PEFT）技术的进展。基础模型通过在大规模数据集上预训练提供了强大而通用的架构，但针对特定任务进行微调需要大量计算资源。本文旨在提供PEFT技术在联邦学习环境中的全面回顾，并分析其在数据异质性、通信效率、计算限制和隐私问题等挑战上的应用。将现有方法分为三类：添加PEFT（引入新的可训练参数）、选择性PEFT（仅微调现有参数的子集）和重新参数化PEFT（转换模型架构以实现高效更新）。分析了不同方法如何解决联邦设置中的独特挑战，并按应用领域组织文献，包括自然语言处理和计算机视觉任务。讨论了有前景的研究方向，包括扩展到更大的基础模型、联邦PEFT方法的理论分析和资源受限环境中的可持续方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have revolutionized artificial intelligence by providingrobust, versatile architectures pre-trained on large-scale datasets. However,adapting these massive models to specific downstream tasks requiresfine-tuning, which can be prohibitively expensive in computational resources.Parameter-Efficient Fine-Tuning (PEFT) methods address this challenge byselectively updating only a small subset of parameters. Meanwhile, FederatedLearning (FL) enables collaborative model training across distributed clientswithout sharing raw data, making it ideal for privacy-sensitive applications.This survey provides a comprehensive review of the integration of PEFTtechniques within federated learning environments. We systematically categorizeexisting approaches into three main groups: Additive PEFT (which introduces newtrainable parameters), Selective PEFT (which fine-tunes only subsets ofexisting parameters), and Reparameterized PEFT (which transforms modelarchitectures to enable efficient updates). For each category, we analyze howthese methods address the unique challenges of federated settings, includingdata heterogeneity, communication efficiency, computational constraints, andprivacy concerns. We further organize the literature based on applicationdomains, covering both natural language processing and computer vision tasks.Finally, we discuss promising research directions, including scaling to largerfoundation models, theoretical analysis of federated PEFT methods, andsustainable approaches for resource-constrained environments.</description>
      <author>example@mail.com (Jieming Bian, Yuanzhe Peng, Lei Wang, Yin Huang, Jie Xu)</author>
      <guid isPermaLink="false">2504.21099v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Learning Hierarchical Interaction for Accurate Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2504.20127v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的深度学习模型HimNet，用于发现具有理想分子属性的分子，并通过在多个基准数据集上的实验证明其在分子属性预测任务中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;药物发现过程中，了解分子的吸收、分布、代谢、排泄和毒性（ADMET）属性至关重要。目前常用的深度学习模型如GNN和Transformer在处理分子结构的多层次特性方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的局限性，本文旨在提出一种能够有效捕捉分子结构层次特性，并通过有效特征交互来预测分子属性的深度学习模型。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个分层交互消息传递机制，作为新模型HimNet的基础。该方法通过分层注意力引导的消息传递，使模型能够在原子、基序和分子层面进行交互感知的表示学习，平衡全局和局部信息，以实现对下游属性预测任务的丰富特征提取。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，HimNet在大多数分子属性预测任务中达到了最佳或接近最佳的性能，并展现出良好的层次可解释性，与化学直觉对代表性分子的理解相吻合。&lt;h4&gt;结论&lt;/h4&gt;HimNet为分子活性和ADMET属性预测提供了一个准确高效的方法，对药物发现早期阶段的决策有重大贡献。&lt;h4&gt;翻译&lt;/h4&gt;Discovering molecules with desirable molecular properties, including ADMET profiles, is of great importance in drug discovery. Existing approaches typically employ deep learning models, such as Graph Neural Networks (GNNs) and Transformers, to predict these molecular properties by learning from diverse chemical information. However, these models often fail to efficiently capture and utilize the hierarchical nature of molecular structures, and lack mechanisms for effective interaction among multi-level features. To address these limitations, we propose a Hierarchical Interaction Message Passing Mechanism, which serves as the foundation of our novel model, HimNet. Our method enables interaction-aware representation learning across atomic, motif, and molecular levels via hierarchical attention-guided message passing. This design allows HimNet to effectively balance global and local information, ensuring rich and task-relevant feature extraction for downstream property prediction tasks, such as Blood-Brain Barrier Permeability (BBBP). Extensive experiments on multiple benchmark datasets demonstrate that HimNet achieves the best or near-best performance in most molecular property prediction tasks. Furthermore, our method exhibits promising hierarchical interpretability, aligning well with chemical intuition on representative molecules. We believe that HimNet offers an accurate and efficient solution for molecular activity and ADMET property prediction, contributing significantly to advanced decision-making in the early stages of drug discovery.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Discovering molecules with desirable molecular properties, including ADMET(Absorption, Distribution, Metabolism, Excretion, and Toxicity) profiles, is ofgreat importance in drug discovery. Existing approaches typically employ deeplearning models, such as Graph Neural Networks (GNNs) and Transformers, topredict these molecular properties by learning from diverse chemicalinformation. However, these models often fail to efficiently capture andutilize the hierarchical nature of molecular structures, and lack mechanismsfor effective interaction among multi-level features. To address theselimitations, we propose a Hierarchical Interaction Message Passing Mechanism,which serves as the foundation of our novel model, HimNet. Our method enablesinteraction-aware representation learning across atomic, motif, and molecularlevels via hierarchical attention-guided message passing. This design allowsHimNet to effectively balance global and local information, ensuring rich andtask-relevant feature extraction for downstream property prediction tasks, suchas Blood-Brain Barrier Permeability (BBBP). Extensive experiments on multiplebenchmark datasets demonstrate that HimNet achieves the best or near-bestperformance in most molecular property prediction tasks. Furthermore, ourmethod exhibits promising hierarchical interpretability, aligning well withchemical intuition on representative molecules. We believe that HimNet offersan accurate and efficient solution for molecular activity and ADMET propertyprediction, contributing significantly to advanced decision-making in the earlystages of drug discovery.</description>
      <author>example@mail.com (Huiyang Hong, Xinkai Wu, Hongyu Sun, Chaoyang Xie, Qi Wang, Yuquan Li)</author>
      <guid isPermaLink="false">2504.20127v2</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Frequency Feature Fusion Graph Network For Depression Diagnosis Via fNIRS</title>
      <link>http://arxiv.org/abs/2504.21064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于图神经网络（GNN）的抑郁症诊断新方法，利用离散傅里叶变换（DFT）和时序图卷积网络（TGCN）构建模型，并通过倾向得分匹配（PSM）提高了数据集质量。&lt;h4&gt;背景&lt;/h4&gt;数据驱动的抑郁症诊断成为神经医学的研究重点，GNN模型因能捕捉大脑通道的时空联系而广泛应用，但缺乏鲁棒的时间生物标志物限制了其效果。&lt;h4&gt;目的&lt;/h4&gt;引入一个新型有效的时间生物标志物，提高抑郁症诊断的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用DFT方法设计时间生物标志物，构建基于TGCN的定制图网络架构，使用包含1086个受试者的数据集进行训练，并进行了倾向得分匹配（PSM）来创建更精细的数据集。使用SHAP方法进行模型可解释性验证。&lt;h4&gt;主要发现&lt;/h4&gt;新设计的生物标志物增强了大脑通道的时间特征表示，提高了F1分数，在现实世界数据和PSM数据集上均有提升。&lt;h4&gt;结论&lt;/h4&gt;该方法有助于开发更有效的抑郁症诊断工具，并通过SHAP方法验证了模型的解释性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：数据驱动的抑郁症诊断方法已成为神经医学的研究重点，这一进展得益于相关数据集的发展。近年来，基于图神经网络（GNN）的模型因其能够从时空角度捕捉大脑通道的功能连通性而得到了广泛应用。然而，它们的效果受到了缺乏鲁棒时间生物标志物的限制。在本研究中，我们通过利用离散傅里叶变换（DFT）提出了一种新颖且有效的抑郁症诊断生物标志物，并提出了一种基于时序图卷积网络（TGCN）的定制图网络架构。我们的模型在一个包含1086个受试者的数据集上进行训练，这个数据集比该领域之前的所有数据集都要大10倍以上。此外，为了满足医学要求，我们对数据进行倾向得分匹配（PSM），创建了一个更精细的数据子集，称为PSM数据集。实验结果表明，结合我们的新设计的生物标志物增强了大脑通道的时间特征表示，从而在现实世界数据和PSM数据集上都提高了F1分数。这一进展有可能为更有效的抑郁症诊断工具的开发做出贡献。此外，我们还使用了SHapley Additive exPlanation（SHAP）方法来验证我们模型的解释性，确保其在医疗环境中的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-driven approaches for depression diagnosis have emerged as a significantresearch focus in neuromedicine, driven by the development of relevantdatasets. Recently, graph neural network (GNN)-based models have gainedwidespread adoption due to their ability to capture brain channel functionalconnectivity from both spatial and temporal perspectives. However, theireffectiveness is hindered by the absence of a robust temporal biomarker. Inthis paper, we introduce a novel and effective biomarker for depressiondiagnosis by leveraging the discrete Fourier transform (DFT) and propose acustomized graph network architecture based on Temporal Graph ConvolutionalNetwork (TGCN). Our model was trained on a dataset comprising 1,086 subjects,which is over 10 times larger than previous datasets in the field of depressiondiagnosis. Furthermore, to align with medical requirements, we performedpropensity score matching (PSM) to create a refined subset, referred to as thePSM dataset. Experimental results demonstrate that incorporating our newlydesigned biomarker enhances the representation of temporal characteristics inbrain channels, leading to improved F1 scores in both the real-world datasetand the PSM dataset. This advancement has the potential to contribute to thedevelopment of more effective depression diagnostic tools. In addition, we usedSHapley Additive exPlaination (SHAP) to validate the interpretability of ourmodel, ensuring its practical applicability in medical settings.</description>
      <author>example@mail.com (Chengkai Yang, Xingping Dong, Xiaofen Zong)</author>
      <guid isPermaLink="false">2504.21064v1</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>LLMs for Engineering: Teaching Models to Design High Powered Rockets</title>
      <link>http://arxiv.org/abs/2504.19394v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了大型语言模型（LLMs）在火箭工程设计中的应用，发现虽然LLMs在工程知识方面表现良好，但通过强化学习（RL）增强后，模型的表现优于现有技术和人类专家。&lt;h4&gt;背景&lt;/h4&gt;LLMs在软件工程领域已有显著应用，但在物理工程领域的应用尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;评估LLMs在火箭工程设计中的能力。&lt;h4&gt;方法&lt;/h4&gt;通过RocketBench，一个将LLMs与高保真火箭模拟连接的基准，测试模型在两个越来越复杂的设计任务上的表现：目标高度优化和精确着陆挑战。&lt;h4&gt;主要发现&lt;/h4&gt;先进的LLMs表现出强大的工程基础知识，但在给定模拟结果后难以迭代其设计，最终表现低于人类水平。然而，通过强化学习增强后，一个7B参数的模型在表现上优于现有的SoTA基础模型和人类专家。&lt;h4&gt;结论&lt;/h4&gt;强化学习训练的LLMs可以成为复杂工程优化的有效工具，有望改变软件开发之外的工程领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have transformed software engineering, but theirapplication to physical engineering domains remains underexplored. This paperevaluates LLMs' capabilities in high-powered rocketry design throughRocketBench, a benchmark connecting LLMs to high-fidelity rocket simulations.We test models on two increasingly complex design tasks: target altitudeoptimization and precision landing challenges. Our findings reveal that whilestate-of-the-art LLMs demonstrate strong baseline engineering knowledge, theystruggle to iterate on their designs when given simulation results andultimately plateau below human performance levels. However, when enhanced withreinforcement learning (RL), we show that a 7B parameter model outperforms bothSoTA foundation models and human experts. This research demonstrates thatRL-trained LLMs can serve as effective tools for complex engineeringoptimization, potentially transforming engineering domains beyond softwaredevelopment.</description>
      <author>example@mail.com (Toby Simonds)</author>
      <guid isPermaLink="false">2504.19394v2</guid>
      <pubDate>Thu, 01 May 2025 14:15:22 +0800</pubDate>
    </item>
    <item>
      <title>Comments on the minimal training set for CNN: a case study of the frustrated $J_1$-$J_2$ Ising model on the square lattice</title>
      <link>http://arxiv.org/abs/2504.19795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  46 figures, 16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文详细探讨了训练工作CNN所需的最小训练集，并针对挫败的$J_1$-$J_2$伊辛模型在正方形格子上进行了研究。&lt;h4&gt;背景&lt;/h4&gt;考虑的模型是挫败的$J_1$-$J_2$伊辛模型，其中$J_1 &lt; 0$和$J_2 &gt; 0$分别是最近邻和次近邻耦合。&lt;h4&gt;目的&lt;/h4&gt;研究训练CNN所需的最小训练集，并利用训练好的CNN研究$g = 0.8$的相变。&lt;h4&gt;方法&lt;/h4&gt;使用$g = J_2/|J_1| = 0.7$的配置来训练CNN，并用训练好的CNN来研究$g = 0.8$的相变。发现转移学习是成功的，只需要两种温度下的配置（一个低于临界温度$T_c$，一个高于临界温度$T_c$）即可准确确定$g = 0.8$的$T_c$。&lt;h4&gt;主要发现&lt;/h4&gt;发现使用单个自旋翻转算法在低温区域采样配置时效率低下，因此训练集中关联的两个温度不应与$g = 0.7$的$T_c$相距太远，否则获得的CNN性能不高，无法准确确定$g = 0.8$的$T_c$。同时，揭示了只考虑两种温度配置作为训练集时训练成功CNN的条件。&lt;h4&gt;结论&lt;/h4&gt;通过转移学习，使用两种温度的配置即可准确确定$g = 0.8$的$T_c$，但需注意配置的温度不应与$g = 0.7$的$T_c$相差太远，以保证CNN的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The minimal training set to train a working CNN is explored in detail. Theconsidered model is the frustrated $J_1$-$J_2$ Ising model on the squarelattice. Here $J_1 &lt; 0$ and $J_2 &gt; 0$ are the nearest and next-to-nearestneighboring couplings, respectively. We train the CNN using the configurationsof $g \stackrel{\text{def}}{=} J_2/|J_1| = 0.7$ and employ the resulting CNN tostudy the phase transition of $g = 0.8$. We find that this transfer learning issuccessful. In particular, only configurations of two temperatures, one isbelow and one is above the critical temperature $T_c$ of $g=0.7$, are needed toreach accurately determination of the $T_c$ of $g=0.8$. However, it may besubtle to use this strategy for the training. Specifically, for the consideredmodel, due to the inefficiency of the single spin flip algorithm used insampling the configurations at the low-temperature region, the two temperaturesassociated with the training set should not be too far away from the $T_c$ of$g=0.7$, otherwise, the performance of the obtained CNN is not of high quality,hence cannot determine the $T_c$ of $g=0.8$ accurately. For the consideredmodel, we also uncover the condition for training a successful CNN when onlyconfigurations of two temperatures are considered as the training set.</description>
      <author>example@mail.com (Shang-Wei Li, Yuan-Heng Tseng, Ming-Che Hsieh, Fu-Jiun Jiang)</author>
      <guid isPermaLink="false">2504.19795v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
  <item>
      <title>ClearVision: Leveraging CycleGAN and SigLIP-2 for Robust All-Weather Classification in Traffic Camera Imagery</title>
      <link>http://arxiv.org/abs/2504.19684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合生成域适应和高效对比学习的可扩展框架，以提升从低质量交通摄像头图像中准确分类天气的能力，特别是在夜间恶劣条件下。&lt;h4&gt;背景&lt;/h4&gt;准确从低质量交通摄像头图像中分类天气是一个具有挑战性的任务，尤其是在夜间不利条件下。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效提升夜间天气分类准确性的框架。&lt;h4&gt;方法&lt;/h4&gt;使用基于CycleGAN的域转换技术提升夜间图像质量，结合SigLIP-2（Sigmoid对比损失）进行对比学习，以及结合Vision-SigLIP-2、Text-SigLIP-2、CycleGAN和对比训练。&lt;h4&gt;主要发现&lt;/h4&gt;使用CLIP对比损失的EVA-02模型在整体准确率上达到96.55%，但白天（97.21%）和夜间（63.40%）存在性能差距。替换CLIP为SigLIP-2后，整体准确率提升至94.00%，夜间准确率提高至85.90%。结合所有技术的模型在夜间准确率上达到85.90%，而EVA-02结合CycleGAN在整体准确率和每类准确率上保持最高（97.01%）。&lt;h4&gt;结论&lt;/h4&gt;域适应和高效对比学习结合的方法有望构建实用、资源高效的天气分类系统，适用于智能交通基础设施。&lt;h4&gt;翻译&lt;/h4&gt;Accurate weather classification from low-quality traffic camera imagery remains a challenging task, particularly under adverse nighttime conditions. In this study, we propose a scalable framework that combines generative domain adaptation with efficient contrastive learning to enhance classification performance. Using CycleGAN-based domain translation, we improve the quality of nighttime images, enabling better feature extraction by downstream models. While the baseline EVA-02 model employing CLIP-based contrastive loss achieves an overall accuracy of 96.55%, it exhibits a significant performance gap between daytime (97.21%) and nighttime conditions (63.40%). Replacing CLIP with the lightweight SigLIP-2 (Sigmoid contrastive loss) achieves a competitive overall accuracy of 94.00%, with substantial improvements in nighttime performance (85.90% accuracy). The combination of Vision-SigLIP-2, Text-SigLIP-2, CycleGAN, and contrastive training achieves the best nighttime accuracy (85.90%) among all models tested, while EVA-02 with CycleGAN maintains the highest overall accuracy (97.01%) and per-class accuracies. These findings demonstrate the potential of combining domain adaptation and efficient contrastive learning to build practical, resource-efficient weather classification systems for intelligent transportation infrastructure.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate weather classification from low-quality traffic camera imageryremains a challenging task, particularly under adverse nighttime conditions. Inthis study, we propose a scalable framework that combines generative domainadaptation with efficient contrastive learning to enhance classificationperformance. Using CycleGAN-based domain translation, we improve the quality ofnighttime images, enabling better feature extraction by downstream models.While the baseline EVA-02 model employing CLIP-based contrastive loss achievesan overall accuracy of 96.55\%, it exhibits a significant performance gapbetween daytime (97.21\%) and nighttime conditions (63.40\%). Replacing CLIPwith the lightweight SigLIP-2 (Sigmoid contrastive loss) achieves a competitiveoverall accuracy of 94.00\%, with substantial improvements in nighttimeperformance (85.90\% accuracy). The combination of Vision-SigLIP-2,Text-SigLIP-2, CycleGAN, and contrastive training achieves the best nighttimeaccuracy (85.90\%) among all models tested, while EVA-02 with CycleGANmaintains the highest overall accuracy (97.01\%) and per-class accuracies.These findings demonstrate the potential of combining domain adaptation andefficient contrastive learning to build practical, resource-efficient weatherclassification systems for intelligent transportation infrastructure.</description>
      <author>example@mail.com (Anush Lakshman Sivaraman, Kojo Adu-Gyamfi, Ibne Farabi Shihab, Anuj Sharma)</author>
      <guid isPermaLink="false">2504.19684v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification</title>
      <link>http://arxiv.org/abs/2504.20930v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ChestX-Reasoner的放射学诊断多模态大型语言模型（MLLM），该模型通过利用从临床报告中挖掘的过程监督来增强推理能力，并提出了RadRBench-CXR基准和RadRScore评估指标，显著提升了诊断准确性和推理能力。&lt;h4&gt;背景&lt;/h4&gt;尽管推理增强的大型语言模型和多模态大型语言模型在复杂任务中的性能有了显著提升，但医疗AI模型往往忽略了临床实践中固有的结构化推理过程。&lt;h4&gt;目的&lt;/h4&gt;设计ChestX-Reasoner，以利用从临床报告中挖掘的过程监督，反映放射科医生逐步推理的过程。&lt;h4&gt;方法&lt;/h4&gt;通过从常规放射学报告中提取和细化推理链来构建大型数据集。采用两阶段训练框架，结合监督微调和由过程奖励引导的强化学习，以更好地使模型推理与临床标准对齐。&lt;h4&gt;主要发现&lt;/h4&gt;ChestX-Reasoner在诊断准确性和推理能力方面优于现有的医疗和通用领域MLLM，与最佳医疗MLLM、最佳通用MLLM及其基模型相比，推理能力分别提高了16%、5.9%和18%，在结果准确性方面分别提高了3.3%、24%和27%。&lt;h4&gt;结论&lt;/h4&gt;所有资源均已开源，以促进医疗推理MLLM的进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces ChestX-Reasoner, a radiology diagnosis multimodal large language model (MLLM) designed to enhance reasoning capability by leveraging process supervision mined directly from clinical reports, and reflects the step-by-step reasoning followed by radiologists. We introduce RadRBench-CXR, a comprehensive benchmark featuring 59K visual question answering samples with 301K clinically validated reasoning steps, and propose RadRScore, a metric evaluating reasoning factuality, completeness, and effectiveness. ChestX-Reasoner outperforms existing medical and general-domain MLLMs in both diagnostic accuracy and reasoning ability, achieving 16%, 5.9%, and 18% improvements in reasoning ability compared to the best medical MLLM, the best general MLLM, and its base model, respectively, as well as 3.3%, 24%, and 27% improvements in outcome accuracy. All resources are open-sourced to facilitate further research in medical reasoning MLLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in reasoning-enhanced large language models (LLMs) andmultimodal LLMs (MLLMs) have significantly improved performance in complextasks, yet medical AI models often overlook the structured reasoning processesinherent in clinical practice. In this work, we present ChestX-Reasoner, aradiology diagnosis MLLM designed to leverage process supervision mineddirectly from clinical reports, reflecting the step-by-step reasoning followedby radiologists. We construct a large dataset by extracting and refiningreasoning chains from routine radiology reports. Our two-stage trainingframework combines supervised fine-tuning and reinforcement learning guided byprocess rewards to better align model reasoning with clinical standards. Weintroduce RadRBench-CXR, a comprehensive benchmark featuring 59K visualquestion answering samples with 301K clinically validated reasoning steps, andpropose RadRScore, a metric evaluating reasoning factuality, completeness, andeffectiveness. ChestX-Reasoner outperforms existing medical and general-domainMLLMs in both diagnostic accuracy and reasoning ability, achieving 16%, 5.9%,and 18% improvements in reasoning ability compared to the best medical MLLM,the best general MLLM, and its base model, respectively, as well as 3.3%, 24%,and 27% improvements in outcome accuracy. All resources are open-sourced tofacilitate further research in medical reasoning MLLMs.</description>
      <author>example@mail.com (Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie)</author>
      <guid isPermaLink="false">2504.20930v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>CMT: A Cascade MAR with Topology Predictor for Multimodal Conditional CAD Generation</title>
      <link>http://arxiv.org/abs/2504.20830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CMT的CAD生成框架，用于解决现有CAD方法在复杂设计要求下的不足。同时，开发了一个大规模的多模态CAD数据集mmABC。&lt;h4&gt;背景&lt;/h4&gt;现有CAD方法在复杂设计要求下存在表现不足，原因在于其过于简化的表示或架构无法支持多模态设计需求。&lt;h4&gt;目的&lt;/h4&gt;通过改进方法和数据集来提高CAD生成的准确性和用户友好性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于边界表示（B-Rep）的多模态CAD生成框架CMT，包括拓扑预测器。同时，开发了一个包含超过130万个B-Rep模型的大规模数据集mmABC，包含点云、文本描述和多视角图像等多模态标注。&lt;h4&gt;主要发现&lt;/h4&gt;CMT在条件和无条件CAD生成任务中均表现出优越性。与现有方法相比，CMT在无条件的生成任务中提高了覆盖率和有效率的10.68%和10.3%，在mmABC上的图像条件CAD生成任务中Chamfer距离减少了4.01。&lt;h4&gt;结论&lt;/h4&gt;CMT框架和数据集mmABC能够显著提高CAD生成的质量和效率，并将相关资源（数据集、代码和预训练网络）公开。&lt;h4&gt;翻译&lt;/h4&gt;While accurate and user-friendly Computer-Aided Design (CAD) is crucial for industrial design and manufacturing, existing methods still struggle to achieve this due to their over-simplified representations or architectures incapable of supporting multimodal design requirements. In this paper, we attempt to tackle this problem from both methods and datasets aspects. First, we propose a cascade MAR with topology predictor (CMT), the first multimodal framework for CAD generation based on Boundary Representation (B-Rep). Specifically, the cascade MAR can effectively capture the 'edge-counters-surface' priors that are essential in B-Reps, while the topology predictor directly estimates topology in B-Reps from the compact tokens in MAR. Second, to facilitate large-scale training, we develop a large-scale multimodal CAD dataset, mmABC, which includes over 1.3 million B-Rep models with multimodal annotations, including point clouds, text descriptions, and multi-view images. Extensive experiments show the superior of CMT in both conditional and unconditional CAD generation tasks. For example, we improve Coverage and Valid ratio by +10.68% and +10.3%, respectively, compared to state-of-the-art methods on ABC in unconditional generation. CMT also improves +4.01 Chamfer on image conditioned CAD generation on mmABC. The dataset, code and pretrained network shall be released.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While accurate and user-friendly Computer-Aided Design (CAD) is crucial forindustrial design and manufacturing, existing methods still struggle to achievethis due to their over-simplified representations or architectures incapable ofsupporting multimodal design requirements. In this paper, we attempt to tacklethis problem from both methods and datasets aspects. First, we propose acascade MAR with topology predictor (CMT), the first multimodal framework forCAD generation based on Boundary Representation (B-Rep). Specifically, thecascade MAR can effectively capture the ``edge-counters-surface'' priors thatare essential in B-Reps, while the topology predictor directly estimatestopology in B-Reps from the compact tokens in MAR. Second, to facilitatelarge-scale training, we develop a large-scale multimodal CAD dataset, mmABC,which includes over 1.3 million B-Rep models with multimodal annotations,including point clouds, text descriptions, and multi-view images. Extensiveexperiments show the superior of CMT in both conditional and unconditional CADgeneration tasks. For example, we improve Coverage and Valid ratio by +10.68%and +10.3%, respectively, compared to state-of-the-art methods on ABC inunconditional generation. CMT also improves +4.01 Chamfer on image conditionedCAD generation on mmABC. The dataset, code and pretrained network shall bereleased.</description>
      <author>example@mail.com (Jianyu Wu, Yizhou Wang, Xiangyu Yue, Xinzhu Ma, Jingyang Guo, Dongzhan Zhou, Wanli Ouyang, Shixiang Tang)</author>
      <guid isPermaLink="false">2504.20830v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>SAM-Guided Robust Representation Learning for One-Shot 3D Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2504.20501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RRL-MedSAM的新型框架，用于解决单次医学图像分割的问题，通过利用SAM编码器的泛化能力来学习更好的特征表示。&lt;h4&gt;背景&lt;/h4&gt;单次医学图像分割对于医学分析至关重要，但传统方法依赖于专家手动标注，且计算成本高。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，以适应单次3D医学图像分割，减少对专家标注的依赖和降低计算成本。&lt;h4&gt;方法&lt;/h4&gt;1. 设计了RRL-MedSAM框架，利用SAM编码器的泛化能力。2. 采用双阶段知识蒸馏策略，从基础模型中提取自然和医学图像之间的通用知识。3. 使用互指数移动平均（mutual-EMA）更新通用轻量级编码器和医学特定编码器的权重。4. 引入自动提示（AP）分割解码器，利用通用轻量级模型生成的掩码来辅助医学特定模型。5. 使用伪标签进行互监督。&lt;h4&gt;主要发现&lt;/h4&gt;在OASIS、CT-lung等三个公开数据集上进行的实验表明，RRL-MedSAM在分割和配准任务上优于现有的单次医学图像分割方法。特别是，与SAM-Base的编码器相比，我们的轻量级编码器仅使用了3%的参数。&lt;h4&gt;结论&lt;/h4&gt;RRL-MedSAM框架能够有效提高单次医学图像分割的性能，同时减少计算资源的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; One-shot medical image segmentation (MIS) is crucial for medical analysis dueto the burden of medical experts on manual annotation. The recent emergence ofthe segment anything model (SAM) has demonstrated remarkable adaptation in MISbut cannot be directly applied to one-shot medical image segmentation (MIS) dueto its reliance on labor-intensive user interactions and the high computationalcost. To cope with these limitations, we propose a novel SAM-guided robustrepresentation learning framework, named RRL-MedSAM, to adapt SAM to one-shot3D MIS, which exploits the strong generalization capabilities of the SAMencoder to learn better feature representation. We devise a dual-stageknowledge distillation (DSKD) strategy to distill general knowledge betweennatural and medical images from the foundation model to train a lightweightencoder, and then adopt a mutual exponential moving average (mutual-EMA) toupdate the weights of the general lightweight encoder and medical-specificencoder. Specifically, pseudo labels from the registration network are used toperform mutual supervision for such two encoders. Moreover, we introduce anauto-prompting (AP) segmentation decoder which adopts the mask generated fromthe general lightweight model as a prompt to assist the medical-specific modelin boosting the final segmentation performance. Extensive experiments conductedon three public datasets, i.e., OASIS, CT-lung demonstrate that the proposedRRL-MedSAM outperforms state-of-the-art one-shot MIS methods for bothsegmentation and registration tasks. Especially, our lightweight encoder usesonly 3\% of the parameters compared to the encoder of SAM-Base.</description>
      <author>example@mail.com (Jia Wang, Yunan Mei, Jiarui Liu, Xin Fan)</author>
      <guid isPermaLink="false">2504.20501v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Dual Explanations via Subgraph Matching for Malware Detection</title>
      <link>http://arxiv.org/abs/2504.20904v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型双原型驱动的可解释框架，用于解释基于图神经网络（GNN）的恶意软件检测决策，在保持高检测性能的同时显著提高了恶意软件分析的可解释性。&lt;h4&gt;背景&lt;/h4&gt;传统可解释方法在图神经网络中突出显示重要区域，但无法将它们与已知的良性或恶意行为模式关联起来，这在安全环境中限制了其效用。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以解释基于GNN的恶意软件检测决策，并提高其在安全环境中的可解释性。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的双可解释框架，该框架结合了基线解释器和一种名为SubMatch解释器的二级解释器。SubMatch解释器通过子图匹配技术为节点分配可解释的分数，从而在良性和恶意区域之间提供更精细的区别。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在保持高检测性能的同时，显著提高了恶意软件分析的可解释性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为恶意软件分析提供了一种更加可解释、行为对齐的解释机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretable malware detection is crucial for understanding harmfulbehaviors and building trust in automated security systems. Traditionalexplainable methods for Graph Neural Networks (GNNs) often highlight importantregions within a graph but fail to associate them with known benign ormalicious behavioral patterns. This limitation reduces their utility insecurity contexts, where alignment with verified prototypes is essential. Inthis work, we introduce a novel dual prototype-driven explainable frameworkthat interprets GNN-based malware detection decisions. This dual explainableframework integrates a base explainer (a state-of-the-art explainer) with anovel second-level explainer which is designed by subgraph matching technique,called SubMatch explainer. The proposed explainer assigns interpretable scoresto nodes based on their association with matched subgraphs, offering afine-grained distinction between benign and malicious regions. Thisprototype-guided scoring mechanism enables more interpretable, behavior-alignedexplanations. Experimental results demonstrate that our method preserves highdetection performance while significantly improving interpretability in malwareanalysis.</description>
      <author>example@mail.com (Hossein Shokouhinejad, Roozbeh Razavi-Far, Griffin Higgins, Ali A. Ghorbani)</author>
      <guid isPermaLink="false">2504.20904v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks</title>
      <link>http://arxiv.org/abs/2504.20869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Ubder Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于量化攻击强度的噪声概念，并提出基于此的攻击策略，通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;图神经网络因其强大的学习能力被广泛应用于解决图相关任务，但近年来研究表明它们对恶意攻击不够鲁棒。&lt;h4&gt;目的&lt;/h4&gt;为了提高图神经网络的鲁棒性，本文旨在提出一种方法来量化攻击强度并选择合适的攻击策略。&lt;h4&gt;方法&lt;/h4&gt;本文提出了噪声的概念来量化每个对抗链接的攻击强度，并基于噪声和分类边界定义了三种攻击策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过在基准数据集上进行的实验，验证了所提出的攻击策略的有效性，并分析了有效对抗扰动节点的偏好模式。&lt;h4&gt;结论&lt;/h4&gt;本文提出的噪声概念和攻击策略能够有效提高图神经网络的鲁棒性，并提供了对抗扰动选择的可解释性。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks have been widely utilized to solve graph-related tasks because of their strong learning power in utilizing the local information of neighbors. However, recent studies on graph adversarial attacks have proved that current graph neural networks are not robust against malicious attacks. Yet much of the existing work has focused on the optimization objective based on attack performance to obtain (near) optimal perturbations, but paid less attention to the strength quantification of each perturbation such as the injection of a particular node/link, which makes the choice of perturbations a black-box model that lacks interpretability. In this work, we propose the concept of noise to quantify the attack strength of each adversarial link. Furthermore, we propose three attack strategies based on the defined noise and classification margins in terms of single and multiple steps optimization. Extensive experiments conducted on benchmark datasets against three representative graph neural networks demonstrate the effectiveness of the proposed attack strategies. Particularly, we also investigate the preferred patterns of effective adversarial perturbations by analyzing the corresponding properties of the selected perturbation nodes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have been widely utilized to solve graph-related tasksbecause of their strong learning power in utilizing the local information ofneighbors. However, recent studies on graph adversarial attacks have proventhat current graph neural networks are not robust against malicious attacks.Yet much of the existing work has focused on the optimization objective basedon attack performance to obtain (near) optimal perturbations, but paid lessattention to the strength quantification of each perturbation such as theinjection of a particular node/link, which makes the choice of perturbations ablack-box model that lacks interpretability. In this work, we propose theconcept of noise to quantify the attack strength of each adversarial link.Furthermore, we propose three attack strategies based on the defined noise andclassification margins in terms of single and multiple steps optimization.Extensive experiments conducted on benchmark datasets against threerepresentative graph neural networks demonstrate the effectiveness of theproposed attack strategies. Particularly, we also investigate the preferredpatterns of effective adversarial perturbations by analyzing the correspondingproperties of the selected perturbation nodes.</description>
      <author>example@mail.com (Junyuan Fang, Han Yang, Haixian Wen, Jiajing Wu, Zibin Zheng, Chi K. Tse)</author>
      <guid isPermaLink="false">2504.20869v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Explanations Go Linear: Interpretable and Individual Latent Encoding for Post-hoc Explainability</title>
      <link>http://arxiv.org/abs/2504.20667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ILLUME的灵活且可解释的框架，用于理解黑盒机器学习模型，该框架可以与各种代理模型集成，提供对任何黑盒分类器的解释。&lt;h4&gt;背景&lt;/h4&gt;后验可解释性对于理解黑盒机器学习模型至关重要。基于代理的技术在局部和全局模型无关的解释中广泛使用，但存在显著局限性。&lt;h4&gt;目的&lt;/h4&gt;提出ILLUME框架，以提供准确、鲁棒且忠实于黑盒的特徵归因和决策规则，从而有效解决传统代理方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;ILLUME结合了一个全局训练的代理模型和通过元编码器学习的实例特定线性变换，以生成局部和全局解释。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实证评估，证明了ILLUME在生成特征归因和决策规则方面的有效性，这些规则不仅准确，而且鲁棒且忠实于黑盒。&lt;h4&gt;结论&lt;/h4&gt;ILLUME是一个统一的解释框架，能够有效解决传统代理方法的局限性，为理解黑盒机器学习模型提供了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Post-hoc explainability is essential for understanding black-box machinelearning models. Surrogate-based techniques are widely used for local andglobal model-agnostic explanations but have significant limitations. Localsurrogates capture non-linearities but are computationally expensive andsensitive to parameters, while global surrogates are more efficient butstruggle with complex local behaviors. In this paper, we present ILLUME, aflexible and interpretable framework grounded in representation learning, thatcan be integrated with various surrogate models to provide explanations for anyblack-box classifier. Specifically, our approach combines a globally trainedsurrogate with instance-specific linear transformations learned with ameta-encoder to generate both local and global explanations. Through extensiveempirical evaluations, we demonstrate the effectiveness of ILLUME in producingfeature attributions and decision rules that are not only accurate but alsorobust and faithful to the black-box, thus providing a unified explanationframework that effectively addresses the limitations of traditional surrogatemethods.</description>
      <author>example@mail.com (Simone Piaggesi, Riccardo Guidotti, Fosca Giannotti, Dino Pedreschi)</author>
      <guid isPermaLink="false">2504.20667v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>DB-GNN: Dual-Branch Graph Neural Network with Multi-Level Contrastive Learning for Jointly Identifying Within- and Cross-Frequency Coupled Brain Networks</title>
      <link>http://arxiv.org/abs/2504.20744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种双重分支图神经网络（DB-GNN），用于联合识别脑网络中的频率内耦合（WFC）和跨频率耦合（CFC），并通过实验验证了其在情感识别任务中的高效性。&lt;h4&gt;背景&lt;/h4&gt;脑网络中的WFC和CFC分别反映了同一频率带内的神经同步和跨带振荡相互作用，它们的协同作用有助于理解认知状态如情感背后的神经机制。&lt;h4&gt;目的&lt;/h4&gt;提出DB-GNN以更全面地利用WFC和CFC的互补特性，从而更好地理解认知状态。&lt;h4&gt;方法&lt;/h4&gt;DB-GNN利用独特的双重分支学习架构来高效挖掘全局协作信息和局部跨频率及频率内耦合信息；采用Transformer架构来增强对全局信息的感知；通过整合先验的WFC和CFC信息来防止过拟合；引入多尺度图对比学习正则化项来增强全局和局部感知分支的联合感知能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证表明，DB-GNN在情感识别数据集上实现了97.88%的测试准确率和97.87%的F1分数，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;DB-GNN能够有效识别WFC和CFC，并显著提高情感识别任务的性能，为认知状态的理解提供了新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：脑网络中的频率内耦合（WFC）和跨频率耦合（CFC）分别反映了同一频率带内的神经同步和跨带振荡相互作用。它们的协同作用为理解认知状态（如情感）背后的神经机制提供了全面的视角。然而，现有的多通道脑电图（EEG）研究通常分别分析WFC或CFC，未能充分利用它们的互补特性。本研究提出了一种双重分支图神经网络（DB-GNN）来联合识别频率内和跨频率耦合的脑网络。首先，DB-GNN利用其独特的双重分支学习架构高效挖掘全局协作信息和局部跨频率及频率内耦合信息。其次，为了更全面地感知跨频率和频率内耦合的全局信息，DB-GNN的全局感知分支采用了Transformer架构。为了避免Transformer架构的过拟合，本研究将先验的WFC和CFC信息整合到Transformer推理过程中，从而增强了DB-GNN的泛化能力。最后，引入了多尺度图对比学习正则化项，以约束DB-GNN的全局和局部感知分支在图级别和节点级别，从而增强了其联合感知能力，并进一步提高了其泛化性能。在情感识别数据集上的实验验证表明，DB-GNN实现了97.88%的测试准确率和97.87%的F1分数，达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Within-frequency coupling (WFC) and cross-frequency coupling (CFC) in brainnetworks reflect neural synchronization within the same frequency band andcross-band oscillatory interactions, respectively. Their synergy provides acomprehensive understanding of neural mechanisms underlying cognitive statessuch as emotion. However, existing multi-channel EEG studies often analyze WFCor CFC separately, failing to fully leverage their complementary properties.This study proposes a dual-branch graph neural network (DB-GNN) to jointlyidentify within- and cross-frequency coupled brain networks. Firstly, DBGNNleverages its unique dual-branch learning architecture to efficiently mineglobal collaborative information and local cross-frequency and within-frequencycoupling information. Secondly, to more fully perceive the global informationof cross-frequency and within-frequency coupling, the global perception branchof DB-GNN adopts a Transformer architecture. To prevent overfitting of theTransformer architecture, this study integrates prior within- andcross-frequency coupling information into the Transformer inference process,thereby enhancing the generalization capability of DB-GNN. Finally, amulti-scale graph contrastive learning regularization term is introduced toconstrain the global and local perception branches of DB-GNN at bothgraph-level and node-level, enhancing its joint perception ability and furtherimproving its generalization performance. Experimental validation on theemotion recognition dataset shows that DB-GNN achieves a testing accuracy of97.88% and an F1- score of 97.87%, reaching the state-of-the-art performance.</description>
      <author>example@mail.com (Xiang Wang, Hui Xu, Jing Cai, Ta Zhou, Xibei Yang, Wei Xue)</author>
      <guid isPermaLink="false">2504.20744v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Autoencoder Models for Point Cloud Environmental Synthesis from WiFi Channel State Information: A Preliminary Study</title>
      <link>http://arxiv.org/abs/2504.20541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于深度学习的框架，用于从WiFi信道状态信息（CSI）数据生成点云。&lt;h4&gt;背景&lt;/h4&gt;研究背景为从无线信号数据中重建环境点云。&lt;h4&gt;目的&lt;/h4&gt;研究目的是开发一种方法，能够从WiFi数据中准确重建环境点云。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段自动编码器方法：使用具有卷积层的PointNet自动编码器进行点云生成，以及使用卷积神经网络自动编码器将CSI数据映射到匹配的潜在空间。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法有效，突出了其在无线传感和环境制图应用中的潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法能够通过WiFi数据准确重建环境点云，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a deep learning framework for generating point clouds from WiFi Channel State Information data. We employ a two-stage autoencoder approach: a PointNet autoencoder with convolutional layers for point cloud generation, and a Convolutional Neural Network autoencoder to map CSI data to a matching latent space. By aligning these latent spaces, our method enables accurate environmental point cloud reconstruction from WiFi data. Experimental results validate the effectiveness of our approach, highlighting its potential for wireless sensing and environmental mapping applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a deep learning framework for generating point cloudsfrom WiFi Channel State Information data. We employ a two-stage autoencoderapproach: a PointNet autoencoder with convolutional layers for point cloudgeneration, and a Convolutional Neural Network autoencoder to map CSI data to amatching latent space. By aligning these latent spaces, our method enablesaccurate environmental point cloud reconstruction from WiFi data. Experimentalresults validate the effectiveness of our approach, highlighting its potentialfor wireless sensing and environmental mapping applications.</description>
      <author>example@mail.com (Daniele Pannone, Danilo Avola)</author>
      <guid isPermaLink="false">2504.20541v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.20464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于多模态大型语言模型（MLLMs）的图形用户界面（GUI）代理的最新进展进行了结构化总结，重点关注通过强化学习（RL）增强的架构。&lt;h4&gt;背景&lt;/h4&gt;GUI代理作为实现与数字系统智能交互的有前景的方法，近年来得到了快速发展。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供对GUI代理领域最近进展的全面概述，特别是那些通过强化学习增强的架构。&lt;h4&gt;方法&lt;/h4&gt;首先，将GUI代理任务形式化为马尔可夫决策过程，并讨论了典型的执行环境和评估指标。接着，回顾了基于（M）LLM的GUI代理的模块化架构，包括感知、规划和行动模块，并追踪了它们的演变过程。此外，将GUI代理的训练方法分为基于提示、基于监督微调（SFT）和基于RL的方法，强调了从简单的提示工程到通过RL进行动态策略学习的进展。&lt;h4&gt;主要发现&lt;/h4&gt;本文说明了在多模态感知、决策推理和自适应动作生成方面的最新创新如何显著提高了GUI代理在复杂真实世界环境中的泛化能力和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;最后，本文确定了构建更强大和可靠的GUI代理的关键挑战和未来方向。&lt;h4&gt;翻译&lt;/h4&gt;Graphical User Interface (GUI) agents, driven by Multi-modal Large Language Models (MLLMs), have emerged as a promising paradigm for enabling intelligent interaction with digital systems. This paper provides a structured summary of recent advances in GUI agents, focusing on architectures enhanced by Reinforcement Learning (RL). We first formalize GUI agent tasks as Markov Decision Processes and discuss typical execution environments and evaluation metrics. We then review the modular architecture of (M)LLM-based GUI agents, covering Perception, Planning, and Acting modules, and trace their evolution through representative works. Furthermore, we categorize GUI agent training methodologies into Prompt-based, Supervised Fine-Tuning (SFT)-based, and RL-based approaches, highlighting the progression from simple prompt engineering to dynamic policy learning via RL. Our summary illustrates how recent innovations in multimodal perception, decision reasoning, and adaptive action generation have significantly improved the generalization and robustness of GUI agents in complex real-world environments. We conclude by identifying key challenges and future directions for building more capable and reliable GUI agents.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphical User Interface (GUI) agents, driven by Multi-modal Large LanguageModels (MLLMs), have emerged as a promising paradigm for enabling intelligentinteraction with digital systems. This paper provides a structured summary ofrecent advances in GUI agents, focusing on architectures enhanced byReinforcement Learning (RL). We first formalize GUI agent tasks as MarkovDecision Processes and discuss typical execution environments and evaluationmetrics. We then review the modular architecture of (M)LLM-based GUI agents,covering Perception, Planning, and Acting modules, and trace their evolutionthrough representative works. Furthermore, we categorize GUI agent trainingmethodologies into Prompt-based, Supervised Fine-Tuning (SFT)-based, andRL-based approaches, highlighting the progression from simple promptengineering to dynamic policy learning via RL. Our summary illustrates howrecent innovations in multimodal perception, decision reasoning, and adaptiveaction generation have significantly improved the generalization and robustnessof GUI agents in complex real-world environments. We conclude by identifyingkey challenges and future directions for building more capable and reliable GUIagents.</description>
      <author>example@mail.com (Jiahao Li, Kaer Huang)</author>
      <guid isPermaLink="false">2504.20464v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep Features</title>
      <link>http://arxiv.org/abs/2504.20970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint submitted to IEEE International Workshop on Machine Learning  for Signal Processing (MLSP), 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于奇异值分解的最小二乘法（SVD-LS）框架，用于多类肺炎分类，旨在通过高效的诊断工具辅助放射科医生做出更可靠和高效的决策。&lt;h4&gt;背景&lt;/h4&gt;准确且早期通过X光成像诊断肺炎对于有效治疗和改善患者预后至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的肺炎分类方法，以辅助放射科医生进行更准确的诊断。&lt;h4&gt;方法&lt;/h4&gt;利用最先进的自监督和迁移学习模型，采用闭式、非迭代的方法进行分类，避免了梯度优化的计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;SVD-LS在保持准确性的同时，显著降低了计算成本，在实验中表现出与现有方法相竞争的性能。&lt;h4&gt;结论&lt;/h4&gt;SVD-LS是一个可行的实时医学成像应用替代方案，能够提高肺炎诊断的效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;Accurate and early diagnosis of pneumonia through X-ray imaging is essential for effective treatment and improved patient outcomes. Recent advancements in machine learning have enabled automated diagnostic tools that assist radiologists in making more reliable and efficient decisions. In this work, we propose a Singular Value Decomposition-based Least Squares (SVD-LS) framework for multi-class pneumonia classification, leveraging powerful feature representations from state-of-the-art self-supervised and transfer learning models. Rather than relying on computationally expensive gradient based fine-tuning, we employ a closed-form, non-iterative classification approach that ensures efficiency without compromising accuracy. Experimental results demonstrate that SVD-LS achieves competitive performance while offering significantly reduced computational costs, making it a viable alternative for real-time medical imaging applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and early diagnosis of pneumonia through X-ray imaging is essentialfor effective treatment and improved patient outcomes. Recent advancements inmachine learning have enabled automated diagnostic tools that assistradiologists in making more reliable and efficient decisions. In this work, wepropose a Singular Value Decomposition-based Least Squares (SVD-LS) frameworkfor multi-class pneumonia classification, leveraging powerful featurerepresentations from state-of-the-art self-supervised and transfer learningmodels. Rather than relying on computationally expensive gradient basedfine-tuning, we employ a closed-form, non-iterative classification approachthat ensures efficiency without compromising accuracy. Experimental resultsdemonstrate that SVD-LS achieves competitive performance while offeringsignificantly reduced computational costs, making it a viable alternative forreal-time medical imaging applications.</description>
      <author>example@mail.com (Mete Erdogan, Sebnem Demirtas)</author>
      <guid isPermaLink="false">2504.20970v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>FiLA-Video: Spatio-Temporal Compression for Fine-Grained Long Video Understanding</title>
      <link>http://arxiv.org/abs/2504.20384v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FiLA-Video的轻量级视频理解框架，旨在解决长视频理解中的复杂性和处理限制问题。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉大语言模型（VLLMs）在视频理解方面取得了显著进展，但视频数据的复杂性和上下文处理限制仍然阻碍了长视频的理解。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的方法，即视频特征压缩，以减少大型语言模型的token输入，但许多方法要么未能优先考虑关键特征，导致冗余的帧间信息，要么引入了计算成本高的模块。&lt;h4&gt;方法&lt;/h4&gt;FiLA-Video采用了一种轻量级的动态权重多帧融合策略，自适应地将多个帧整合成一个单一表示，同时保留关键视频信息并降低计算成本。为了提高融合中的帧选择，引入了一种关键帧选择策略，有效地从更大的帧池中识别出信息丰富的帧，以改善总结。此外，还提出了一种简单而有效的长视频训练数据生成策略，无需大量手动标注即可提高模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有方法相比，FiLA-Video在长视频理解方面实现了更高的效率和准确性。&lt;h4&gt;结论&lt;/h4&gt;FiLA-Video框架为长视频理解提供了一种高效且准确的方法，有望在视频理解领域得到广泛应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in video understanding within visual large languagemodels (VLLMs) have led to notable progress. However, the complexity of videodata and contextual processing limitations still hinder long-videocomprehension. A common approach is video feature compression to reduce tokeninput to large language models, yet many methods either fail to prioritizeessential features, leading to redundant inter-frame information, or introducecomputationally expensive modules.To address these issues, we proposeFiLA(Fine-grained Vision Language Model)-Video, a novel framework thatleverages a lightweight dynamic-weight multi-frame fusion strategy, whichadaptively integrates multiple frames into a single representation whilepreserving key video information and reducing computational costs. To enhanceframe selection for fusion, we introduce a keyframe selection strategy,effectively identifying informative frames from a larger pool for improvedsummarization. Additionally, we present a simple yet effective long-videotraining data generation strategy, boosting model performance without extensivemanual annotation. Experimental results demonstrate that FiLA-Video achievessuperior efficiency and accuracy in long-video comprehension compared toexisting methods.</description>
      <author>example@mail.com (Yanan Guo, Wenhui Dong, Jun Song, Shiding Zhu, Xuan Zhang, Hanqing Yang, Yingbo Wang, Yang Du, Xianing Chen, Bo Zheng)</author>
      <guid isPermaLink="false">2504.20384v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating the Structural Bias in Graph Adversarial Defenses</title>
      <link>http://arxiv.org/abs/2504.20848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种防御策略，旨在缓解图神经网络（GNNs）在对抗攻击下的结构偏差，并提高其鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;近年来，图神经网络在处理与图结构相关的下游任务中展现出巨大潜力，但现有的GNNs易受恶意对抗攻击的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种防御策略，以减少GNNs在对抗攻击下的结构偏差，特别是针对低度节点（尾节点）的防御能力。&lt;h4&gt;方法&lt;/h4&gt;策略包括异同质增强图构建、kNN增强图构建和多视图节点级注意力模块。异同质增强图通过移除异质链接（特征不同的节点之间的链接）和为低度节点添加同质链接（特征相似的节点之间的链接）来构建。此外，采用注意力机制以自适应地结合两种图视图的表示。&lt;h4&gt;主要发现&lt;/h4&gt;该策略在基准数据集上展示了防御和去偏效果，表明其能有效缓解GNNs的结构偏差。&lt;h4&gt;结论&lt;/h4&gt;提出的防御策略能够有效提升GNNs在对抗攻击下的鲁棒性，特别是在低度节点方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，图神经网络（GNNs）在解决各种与图结构相关的下游任务中显示出巨大的潜力。然而，最近的研究发现，当前的GNNs容易受到恶意对抗攻击的影响。鉴于对抗攻击在现实世界中的不可避免性，已经提出了各种防御方法来对抗这些攻击并提高GNNs的鲁棒性。尽管这些防御方法表现出可嘉的性能，但我们观察到它们在防御能力上往往表现出对低度节点（即尾节点）的结构偏差，这与传统GNNs在干净图中对低度节点的结构偏差相似。因此，在本工作中，我们提出了一种防御策略，通过包括异同质增强图构建、kNN增强图构建和多视图节点级注意力模块来缓解GNNs对抗攻击的结构偏差。值得注意的是，异同质增强图由全局移除异质链接（即连接具有不同特征的节点的链接）和为低度节点添加同质链接（即连接具有相似特征的节点的链接）组成。为了进一步增强防御能力，采用了一种注意力机制来自适应地结合上述两种图视图的表示。我们进行了广泛的实验，以证明所提出的策略在基准数据集上的防御和去偏效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, graph neural networks (GNNs) have shown great potential inaddressing various graph structure-related downstream tasks. However, recentstudies have found that current GNNs are susceptible to malicious adversarialattacks. Given the inevitable presence of adversarial attacks in the realworld, a variety of defense methods have been proposed to counter these attacksand enhance the robustness of GNNs. Despite the commendable performance ofthese defense methods, we have observed that they tend to exhibit a structuralbias in terms of their defense capability on nodes with low degree (i.e., tailnodes), which is similar to the structural bias of traditional GNNs on nodeswith low degree in the clean graph. Therefore, in this work, we propose adefense strategy by including hetero-homo augmented graph construction, $k$NNaugmented graph construction, and multi-view node-wise attention modules tomitigate the structural bias of GNNs against adversarial attacks. Notably, thehetero-homo augmented graph consists of removing heterophilic links (i.e.,links connecting nodes with dissimilar features) globally and adding homophiliclinks (i.e., links connecting nodes with similar features) for nodes with lowdegree. To further enhance the defense capability, an attention mechanism isadopted to adaptively combine the representations from the above two kinds ofgraph views. We conduct extensive experiments to demonstrate the defense anddebiasing effect of the proposed strategy on benchmark datasets.</description>
      <author>example@mail.com (Junyuan Fang, Huimin Liu, Han Yang, Jiajing Wu, Zibin Zheng, Chi K. Tse)</author>
      <guid isPermaLink="false">2504.20848v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>DeepAndes: A Self-Supervised Vision Foundation Model for Multi-Spectral Remote Sensing Imagery of the Andes</title>
      <link>http://arxiv.org/abs/2504.20303v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了DeepAndes，一个专门为安第斯考古学设计的基于Transformer的视觉基础模型，通过大规模的自监督预训练，在考古遥感领域取得了显著成效。&lt;h4&gt;背景&lt;/h4&gt;利用遥感数据在大规模上对遗址进行映射，可以帮助考古学家深入了解长期人口趋势、区域间社会网络以及过去对气候变化的适应。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理多光谱卫星图像的深度学习模型，以解决传统监督学习方法在标注考古特征时遇到的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出DeepAndes模型，该模型基于三百万张多光谱卫星图像进行训练，并采用了定制化的DINOv2自监督学习算法，针对8波段多光谱图像进行了优化。&lt;h4&gt;主要发现&lt;/h4&gt;DeepAndes在图像理解任务中表现出色，包括不平衡图像分类、图像实例检索和像素级语义分割，其F1分数、平均精度和Dice分数在少量样本学习场景中优于从头开始训练或在小数据集上预训练的模型。&lt;h4&gt;结论&lt;/h4&gt;大规模自监督预训练在考古遥感领域是有效的，DeepAndes模型为这一领域提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;通过在大规模上使用遥感数据对遗址进行映射，考古学家可以生成关于长期人口趋势、区域间社会网络和过去对气候变化适应的独特见解。遥感调查补充了基于现场的方法，当与深度学习和计算机视觉技术结合时，其范围可以特别广泛。然而，传统的监督深度学习方法在标注大规模精细考古特征时面临挑战。尽管最近的视觉基础模型在利用最小标注学习大规模遥感数据方面取得了显著的成功，但大多数现成的解决方案是为RGB图像而不是多光谱卫星图像（如我们研究中使用的8波段数据）设计的。在本文中，我们介绍了DeepAndes，这是一个基于Transformer的视觉基础模型，在300万张多光谱卫星图像上进行了训练，专门针对安第斯考古学进行了定制。DeepAndes集成了针对8波段多光谱图像优化的定制化DINOv2自监督学习算法，标志着第一个专门为安第斯地区设计的基座模型。我们通过不平衡图像分类、图像实例检索和像素级语义分割任务评估了其图像理解性能。我们的实验表明，DeepAndes在少量样本学习场景中实现了优越的F1分数、平均精度和Dice分数，显著优于从头开始训练或在小数据集上预训练的模型。这强调了大规模自监督预训练在考古遥感中的有效性。代码将在https://github.com/geopacha/DeepAndes上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; By mapping sites at large scales using remotely sensed data, archaeologistscan generate unique insights into long-term demographic trends, inter-regionalsocial networks, and past adaptations to climate change. Remote sensing surveyscomplement field-based approaches, and their reach can be especially great whencombined with deep learning and computer vision techniques. However,conventional supervised deep learning methods face challenges in annotatingfine-grained archaeological features at scale. While recent vision foundationmodels have shown remarkable success in learning large-scale remote sensingdata with minimal annotations, most off-the-shelf solutions are designed forRGB images rather than multi-spectral satellite imagery, such as the 8-banddata used in our study. In this paper, we introduce DeepAndes, atransformer-based vision foundation model trained on three millionmulti-spectral satellite images, specifically tailored for Andean archaeology.DeepAndes incorporates a customized DINOv2 self-supervised learning algorithmoptimized for 8-band multi-spectral imagery, marking the first foundation modeldesigned explicitly for the Andes region. We evaluate its image understandingperformance through imbalanced image classification, image instance retrieval,and pixel-level semantic segmentation tasks. Our experiments show thatDeepAndes achieves superior F1 scores, mean average precision, and Dice scoresin few-shot learning scenarios, significantly outperforming models trained fromscratch or pre-trained on smaller datasets. This underscores the effectivenessof large-scale self-supervised pre-training in archaeological remote sensing.Codes will be available on https://github.com/geopacha/DeepAndes.</description>
      <author>example@mail.com (Junlin Guo, James R. Zimmer-Dauphinee, Jordan M. Nieusma, Siqi Lu, Quan Liu, Ruining Deng, Can Cui, Jialin Yue, Yizhe Lin, Tianyuan Yao, Juming Xiong, Junchao Zhu, Chongyu Qu, Yuechen Yang, Mitchell Wilkes, Xiao Wang, Parker VanValkenburgh, Steven A. Wernke, Yuankai Huo)</author>
      <guid isPermaLink="false">2504.20303v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>DRO: Doppler-Aware Direct Radar Odometry</title>
      <link>http://arxiv.org/abs/2504.20339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at RSS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于旋转频率调制连续波雷达的SE(2)里程计方法，用于移动机器人应用。&lt;h4&gt;背景&lt;/h4&gt;雷达在移动机器人应用中的重要性正在兴起，尤其是在需要穿透障碍物和恶劣天气条件的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要特征或点云提取的直接扫描到局部地图注册的方法，以提高移动机器人的定位精度。&lt;h4&gt;方法&lt;/h4&gt;该方法利用雷达强度信息进行直接注册，并考虑了运动和多普勒畸变。在特定频率调制模式下，还引入了基于多普勒的约束来提高速度估计。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在超过250公里的公共数据集上进行了验证，与现有方法相比，平均相对位置误差降低了0.26%。在具有适当多普勒调制模式的场景中，位置误差进一步降低至0.18%。&lt;h4&gt;结论&lt;/h4&gt;该方法在几何特征稀缺的场景中表现良好，并且实时实现已经公开。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于旋转频率调制连续波雷达的SE(2)里程计方法，用于移动机器人应用。与相机或激光雷达相比，毫米波雷达能够在薄墙、植被和恶劣天气条件下（如大雨、雾、雪和灰尘）进行探测。本文提出了一种新的SE(2)里程计方法，用于旋转频率调制连续波雷达。该方法以直接方式使用所有雷达强度信息进行输入雷达数据的扫描到局部地图注册，无需特征或点云提取。该方法执行局部连续轨迹估计，并考虑雷达扫描的运动和多普勒畸变。如果雷达具有使径向多普勒速度可观测的特定频率调制模式，则还制定了基于多普勒的约束，以提高速度估计并使里程计在几何特征稀缺的场景（例如无特征隧道）中成为可能。该方法已在超过250公里的公共数据集（Boreas和MulRan）上进行了验证，这些数据是通过我们的汽车平台收集的。在有陀螺仪的帮助下，它优于最先进的方法，在Boreas排行榜上实现了0.26%的平均相对位置误差。当使用具有适当多普勒启用频率调制模式的数据时，在类似环境中，位置误差降低至0.18%。我们还使用在具有不同结构级别的越野环境中收集的1.5小时数据对该算法进行了基准测试，以展示其多功能性。我们的实时实现已经公开：https://github.com/utiasASRL/dro。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A renaissance in radar-based sensing for mobile robotic applications isunderway. Compared to cameras or lidars, millimetre-wave radars have theability to `see' through thin walls, vegetation, and adversarial weatherconditions such as heavy rain, fog, snow, and dust. In this paper, we propose anovel SE(2) odometry approach for spinning frequency-modulated continuous-waveradars. Our method performs scan-to-local-map registration of the incomingradar data in a direct manner using all the radar intensity information withoutthe need for feature or point cloud extraction. The method performs locallycontinuous trajectory estimation and accounts for both motion and Dopplerdistortion of the radar scans. If the radar possesses a specific frequencymodulation pattern that makes radial Doppler velocities observable, anadditional Doppler-based constraint is formulated to improve the velocityestimate and enable odometry in geometrically feature-deprived scenarios (e.g.,featureless tunnels). Our method has been validated on over 250km of on-roaddata sourced from public datasets (Boreas and MulRan) and collected using ourautomotive platform. With the aid of a gyroscope, it outperformsstate-of-the-art methods and achieves an average relative translation error of0.26% on the Boreas leaderboard. When using data with the appropriateDoppler-enabling frequency modulation pattern, the translation error is reducedto 0.18% in similar environments. We also benchmarked our algorithm using 1.5hours of data collected with a mobile robot in off-road environments withvarious levels of structure to demonstrate its versatility. Our real-timeimplementation is publicly available: https://github.com/utiasASRL/dro.</description>
      <author>example@mail.com (Cedric Le Gentil, Leonardo Brizi, Daniil Lisus, Xinyuan Qiao, Giorgio Grisetti, Timothy D. Barfoot)</author>
      <guid isPermaLink="false">2504.20339v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning Preserving Ignorability and Covariate Matching for Treatment Effects</title>
      <link>http://arxiv.org/abs/2504.20579v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了利用神经网络解决观察数据中治疗效应估计的挑战，包括隐藏混杂因素和协变量不匹配问题。&lt;h4&gt;背景&lt;/h4&gt;由于隐藏混杂因素和协变量不匹配，从观察数据中估计治疗效应具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出神经网络架构，旨在学习有效的调整表示，并满足协变量匹配约束。&lt;h4&gt;方法&lt;/h4&gt;结合了基于梯度匹配的跨域神经网络和协变量匹配变换的神经网络。&lt;h4&gt;主要发现&lt;/h4&gt;证明了近似不变表示可以产生近似有效的调整集，从而能够估计真实因果效应的区间。&lt;h4&gt;结论&lt;/h4&gt;该方法在ATE和PEHE误差方面优于多种基线模型，并在IHDP、Jobs、Cattaneo和基于图像的Crowd Management数据集等因果基准测试中表现良好。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从观察数据中估计治疗效应具有挑战性，主要由于隐藏混杂因素和协变量不匹配。针对这些问题，本文提出了神经网络架构，旨在学习有效的调整表示，并满足协变量匹配约束。结合了基于梯度匹配的跨域神经网络和协变量匹配变换的神经网络。证明了近似不变表示可以产生近似有效的调整集，从而能够估计真实因果效应的区间。在ATE和PEHE误差方面，该方法优于多种基线模型，并在多个因果基准测试中表现良好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating treatment effects from observational data is challenging due totwo main reasons: (a) hidden confounding, and (b) covariate mismatch (controland treatment groups not having identical distributions). Long lines of worksexist that address only either of these issues. To address the former,conventional techniques that require detailed knowledge in the form of causalgraphs have been proposed. For the latter, covariate matching and importanceweighting methods have been used. Recently, there has been progress incombining testable independencies with partial side information for tacklinghidden confounding. A common framework to address both hidden confounding andselection bias is missing. We propose neural architectures that aim to learn arepresentation of pre-treatment covariates that is a valid adjustment and alsosatisfies covariate matching constraints. We combine two different neuralarchitectures: one based on gradient matching across domains created bysubsampling a suitable anchor variable that assumes causal side information,followed by the other, a covariate matching transformation. We prove thatapproximately invariant representations yield approximate valid adjustment setswhich would enable an interval around the true causal effect. In contrast tousual sensitivity analysis, where an unknown nuisance parameter is varied, wehave a testable approximation yielding a bound on the effect estimate. We alsooutperform various baselines with respect to ATE and PEHE errors on causalbenchmarks that include IHDP, Jobs, Cattaneo, and an image-based CrowdManagement dataset.</description>
      <author>example@mail.com (Praharsh Nanavati, Ranjitha Prasad, Karthikeyan Shanmugam)</author>
      <guid isPermaLink="false">2504.20579v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning Under High-Dimensional Network Convolutional Regression Model</title>
      <link>http://arxiv.org/abs/2504.19979v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于网络卷积回归（NCR）的高维迁移学习框架，用于处理网络数据中的依赖性，并通过仿真和实际应用证明了其在预测准确性上的提升。&lt;h4&gt;背景&lt;/h4&gt;迁移学习通过利用相关领域的知识来提高模型性能，尤其是在标注数据稀缺的情况下。然而，在处理网络数据中的依赖性时，现有的研究仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决网络数据中依赖性的处理问题，本文提出了一个基于NCR的迁移学习框架，旨在提高预测准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法包括一个两步迁移学习算法，用于解决源网络和目标网络之间的领域偏移，并包含一个源检测机制来识别信息丰富的领域。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，在Erdos-Renyi模型假设下的随机图背景下，当存在信息丰富的源时，迁移学习可以改善收敛速度。实证评估显示，在目标域的标注数据有限的情况下，该方法在预测准确性上有了显著提升。&lt;h4&gt;结论&lt;/h4&gt;提出的NCR迁移学习框架在处理网络数据依赖性方面有效，并在预测准确性上取得了显著成果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过利用相关领域的知识，迁移学习可以增强模型性能，尤其是在标注数据稀缺的情况下。尽管现有研究在独立设置下解决了各种分布偏移的迁移学习问题，但处理网络数据中的依赖性仍然具有挑战性。为了应对这一挑战，我们提出了一种基于网络卷积回归（NCR）的高维迁移学习框架，该框架受到图卷积网络（GCNs）成功应用的启发。NCR模型通过允许每个节点的响应依赖于其特征及其邻居的聚合特征，有效地捕捉了局部依赖性。我们的方法包括一个两步迁移学习算法，用于解决源网络和目标网络之间的领域偏移，以及一个源检测机制来识别信息丰富的领域。从理论上讲，我们在基于Erdos-Renyi模型假设的随机图背景下分析了lasso估计量，证明了当存在信息丰富的源时，迁移学习可以改善收敛速度。实证评估，包括模拟和利用SinaWeibo数据的实际应用，证明了在目标域的标注数据有限的情况下，该方法在预测准确性上有了显著提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning enhances model performance by utilizing knowledge fromrelated domains, particularly when labeled data is scarce. While existingresearch addresses transfer learning under various distribution shifts inindependent settings, handling dependencies in networked data remainschallenging. To address this challenge, we propose a high-dimensional transferlearning framework based on network convolutional regression (NCR), inspired bythe success of graph convolutional networks (GCNs). The NCR model incorporatesrandom network structure by allowing each node's response to depend on itsfeatures and the aggregated features of its neighbors, capturing localdependencies effectively. Our methodology includes a two-step transfer learningalgorithm that addresses domain shift between source and target networks, alongwith a source detection mechanism to identify informative domains.Theoretically, we analyze the lasso estimator in the context of a random graphbased on the Erdos-Renyi model assumption, demonstrating that transfer learningimproves convergence rates when informative sources are present. Empiricalevaluations, including simulations and a real-world application using SinaWeibo data, demonstrate substantial improvements in prediction accuracy,particularly when labeled data in the target domain is limited.</description>
      <author>example@mail.com (Liyuan Wang, Jiachen Chen, Kathryn L. Lunetta, Danyang Huang, Huimin Cheng, Debarghya Mukherjee)</author>
      <guid isPermaLink="false">2504.19979v2</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting</title>
      <link>http://arxiv.org/abs/2504.20630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为ISDrama的多模态沉浸式空间戏剧生成模型，该模型通过多模态提示创建连续多说话者的双耳语音，并具有戏剧性的韵律，应用于AR、VR等领域。&lt;h4&gt;背景&lt;/h4&gt;多模态沉浸式空间戏剧生成需要同时模拟空间信息和戏剧韵律，且数据收集成本高，目前尚无解决这些挑战的方法。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够通过多模态提示生成沉浸式空间戏剧的模型，并构建相应的数据集。&lt;h4&gt;方法&lt;/h4&gt;1) 构建了名为MRSDrama的多模态记录空间戏剧数据集，包含双耳戏剧音频、剧本、视频、几何姿态和文本提示。2) 提出了ISDrama模型，该模型包含以下主要组件：多模态姿态编码器（考虑移动说话者引起的多普勒效应，提取统一姿态信息）、沉浸式戏剧Transformer（基于流的mamba-transformer模型，结合Drama-MOE以增强韵律和姿态控制）以及上下文一致的分类器无关的指导策略以生成连贯的戏剧。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ISDrama在客观和主观指标上优于基线模型。&lt;h4&gt;结论&lt;/h4&gt;ISDrama模型能够有效地生成沉浸式空间戏剧，为相关应用提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multimodal immersive spatial drama generation model named ISDrama, which creates continuous binaural speech with dramatic prosody based on multimodal prompts and has potential applications in AR and VR. The model simultaneously models spatial information and dramatic prosody based on multimodal inputs, with high data collection costs. The paper constructs the MRSDrama dataset, the first multimodal recorded spatial drama dataset, containing binaural drama audios, scripts, videos, geometric poses, and textual prompts. Then, it proposes ISDrama, the first immersive spatial drama generation model through multimodal prompting. ISDrama consists of the following main components: 1) Multimodal Pose Encoder, which uses contrastive learning to consider the Doppler effect caused by moving speakers to extract unified pose information from multimodal prompts. 2) Immersive Drama Transformer, a flow-based mamba-transformer model that generates high-quality drama, incorporating Drama-MOE to select proper experts for enhanced prosody and pose control. It also designs a context-consistent classifier-free guidance strategy to generate coherent drama. Experimental results show that ISDrama outperforms baseline models on objective and subjective metrics. The demos and dataset are available at https://aaronz345.github.io/ISDramaDemo.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal immersive spatial drama generation focuses on creating continuousmulti-speaker binaural speech with dramatic prosody based on multimodalprompts, with potential applications in AR, VR, and others. This task requiressimultaneous modeling of spatial information and dramatic prosody based onmultimodal inputs, with high data collection costs. To the best of ourknowledge, our work is the first attempt to address these challenges. Weconstruct MRSDrama, the first multimodal recorded spatial drama dataset,containing binaural drama audios, scripts, videos, geometric poses, and textualprompts. Then, we propose ISDrama, the first immersive spatial drama generationmodel through multimodal prompting. ISDrama comprises these primary components:1) Multimodal Pose Encoder, based on contrastive learning, considering theDoppler effect caused by moving speakers to extract unified pose informationfrom multimodal prompts. 2) Immersive Drama Transformer, a flow-basedmamba-transformer model that generates high-quality drama, incorporatingDrama-MOE to select proper experts for enhanced prosody and pose control. Wealso design a context-consistent classifier-free guidance strategy tocoherently generate complete drama. Experimental results show that ISDramaoutperforms baseline models on objective and subjective metrics. The demos anddataset are available at https://aaronz345.github.io/ISDramaDemo.</description>
      <author>example@mail.com (Yu Zhang, Wenxiang Guo, Changhao Pan, Zhiyuan Zhu, Tao Jin, Zhou Zhao)</author>
      <guid isPermaLink="false">2504.20630v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>FreBIS: Frequency-Based Stratification for Neural Implicit Surface Representations</title>
      <link>http://arxiv.org/abs/2504.20222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025 CV4Metaverse Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FreBIS是一种新的神经网络隐式表面表示方法，用于解决复杂场景中的表面建模问题。&lt;h4&gt;背景&lt;/h4&gt;神经网络隐式表面表示技术在增强现实/虚拟现实、数字孪生、自主导航等领域需求增加。&lt;h4&gt;目的&lt;/h4&gt;提出FreBIS方法以克服传统3D表面重建方法在处理复杂场景时的局限性。&lt;h4&gt;方法&lt;/h4&gt;FreBIS通过根据表面频率分层场景，并为每个频率级别（或一组频率级别）分配专用编码器。它还通过一个新颖的冗余感知加权模块鼓励编码器捕获互补信息。&lt;h4&gt;主要发现&lt;/h4&gt;在BlendedMVS数据集上的实证评估表明，使用FreBIS的频率分层编码器替换标准编码器，可以显著提高重建3D表面的质量和渲染的保真度。&lt;h4&gt;结论&lt;/h4&gt;FreBIS在处理复杂场景的表面建模方面具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经网络隐式表面表示技术在增强现实/虚拟现实、数字孪生、自主导航等多个技术领域需求日益增长。这种技术能够将场景中的物体表面建模为连续函数，近年来在超越经典3D表面重建方法（如使用体素或点云的方法）方面取得了显著进展。然而，这些方法在处理具有多样化和复杂表面的场景时存在困难，主要是因为它们使用单个编码网络来同时捕获场景中从低到高表面频率的全部信息。在这项工作中，我们提出了一种名为FreBIS的新型神经网络隐式表面表示方法，以克服这一挑战。FreBIS通过根据表面频率将场景分层到多个频率级别，并为每个级别（或一组级别）分配一个专门的编码器。此外，FreBIS通过一种新颖的冗余感知加权模块促进编码特征的相互差异，从而鼓励这些编码器捕获互补信息。在具有挑战性的BlendedMVS数据集上的实证评估表明，用我们的频率分层编码器替换标准编码器，可以显著提高3D表面重建的质量及其从任何视角的渲染保真度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural implicit surface representation techniques are in high demand foradvancing technologies in augmented reality/virtual reality, digital twins,autonomous navigation, and many other fields. With their ability to modelobject surfaces in a scene as a continuous function, such techniques have maderemarkable strides recently, especially over classical 3D surfacereconstruction methods, such as those that use voxels or point clouds. However,these methods struggle with scenes that have varied and complex surfacesprincipally because they model any given scene with a single encoder networkthat is tasked to capture all of low through high-surface frequency informationin the scene simultaneously. In this work, we propose a novel, neural implicitsurface representation approach called FreBIS to overcome this challenge.FreBIS works by stratifying the scene based on the frequency of surfaces intomultiple frequency levels, with each level (or a group of levels) encoded by adedicated encoder. Moreover, FreBIS encourages these encoders to capturecomplementary information by promoting mutual dissimilarity of the encodedfeatures via a novel, redundancy-aware weighting module. Empirical evaluationson the challenging BlendedMVS dataset indicate that replacing the standardencoder in an off-the-shelf neural surface reconstruction method with ourfrequency-stratified encoders yields significant improvements. Theseenhancements are evident both in the quality of the reconstructed 3D surfacesand in the fidelity of their renderings from any viewpoint.</description>
      <author>example@mail.com (Naoko Sawada, Pedro Miraldo, Suhas Lohit, Tim K. Marks, Moitreya Chatterjee)</author>
      <guid isPermaLink="false">2504.20222v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection</title>
      <link>http://arxiv.org/abs/2504.20498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Manuscript submitted to IEEE Transactions on Multimedia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Style-Adaptive Detection Transformer (SA-DETR)的检测器，用于解决单源域泛化（SDG）在目标检测中的问题，该检测器能够使用源域数据实现强泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于CNN的检测器主要通过精心设计的数据增强策略和特征对齐技术来提高鲁棒性，但数据增强方法存在局限性，且DETR在域适应任务中表现出色，但在SDG任务中的应用潜力尚未探索。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够使用源域数据在未见过的目标域上展示强泛化能力的目标检测器。&lt;h4&gt;方法&lt;/h4&gt;提出了一种域风格适配器，将未见目标域的风格表示投影到训练域，实现动态风格适配；并提出了一种对象感知对比学习模块，通过对比学习引导检测器提取域不变特征；使用对象感知门控掩码在空间和语义维度上约束特征聚合，实现跨域实例级特征的对比，从而增强泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;SA-DETR在五个不同的天气场景下表现出了优越的性能和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;SA-DETR是一种有效的SDG检测器，能够显著提高目标检测的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Single-source Domain Generalization (SDG) in object detection aims to develop a detector using only data from a source domain that can exhibit strong generalization capability when applied to unseen target domains. Existing methods are built upon CNN-based detectors and primarily improve robustness by employing carefully designed data augmentation strategies integrated with feature alignment techniques. However, data augmentation methods have inherent drawbacks; they are only effective when the augmented sample distribution approximates or covers the unseen scenarios, thus failing to enhance generalization across all unseen domains. Furthermore, while the recent Detection Transformer (DETR) has demonstrated superior generalization capability in domain adaptation tasks due to its efficient global information extraction, its potential in SDG tasks remains unexplored. To this end, we introduce a strong DETR-based detector named the Style-Adaptive Detection Transformer (SA-DETR) for SDG in object detection. Specifically, we present a domain style adapter that projects the style representation of the unseen target domain into the training domain, enabling dynamic style adaptation. Then, we propose an object-aware contrastive learning module to guide the detector in extracting domain-invariant features through contrastive learning. By using object-aware gating masks to constrain feature aggregation in both spatial and semantic dimensions, this module achieves cross-domain contrast of instance-level features, thereby enhancing generalization. Extensive experiments demonstrate the superior performance and generalization capability of SA-DETR across five different weather scenarios. Code is released at https://github.com/h751410234/SA-DETR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-source Domain Generalization (SDG) in object detection aims to developa detector using only data from a source domain that can exhibit stronggeneralization capability when applied to unseen target domains. Existingmethods are built upon CNN-based detectors and primarily improve robustness byemploying carefully designed data augmentation strategies integrated withfeature alignment techniques. However, data augmentation methods have inherentdrawbacks; they are only effective when the augmented sample distributionapproximates or covers the unseen scenarios, thus failing to enhancegeneralization across all unseen domains. Furthermore, while the recentDetection Transformer (DETR) has demonstrated superior generalizationcapability in domain adaptation tasks due to its efficient global informationextraction, its potential in SDG tasks remains unexplored. To this end, weintroduce a strong DETR-based detector named the Style-Adaptive DetectionTransformer (SA-DETR) for SDG in object detection. Specifically, we present adomain style adapter that projects the style representation of the unseentarget domain into the training domain, enabling dynamic style adaptation.Then, we propose an object-aware contrastive learning module to guide thedetector in extracting domain-invariant features through contrastive learning.By using object-aware gating masks to constrain feature aggregation in bothspatial and semantic dimensions, this module achieves cross-domain contrast ofinstance-level features, thereby enhancing generalization. Extensiveexperiments demonstrate the superior performance and generalization capabilityof SA-DETR across five different weather scenarios. Code is released athttps://github.com/h751410234/SA-DETR.</description>
      <author>example@mail.com (Jianhong Han, Yupei Wang, Liang Chen)</author>
      <guid isPermaLink="false">2504.20498v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>VideoMultiAgents: A Multi-Agent Framework for Video Question Answering</title>
      <link>http://arxiv.org/abs/2504.20091v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为VideoMultiAgents的视频问答框架，该框架通过整合专门用于视觉、场景图分析和文本处理的代理，利用多模态推理来增强视频内容的理解，并通过问题引导的标题生成来提高答案的准确性。&lt;h4&gt;背景&lt;/h4&gt;视频问答（VQA）需要多模态推理，结合视觉、时间和语言线索来深入理解视频内容。然而，许多现有方法依赖于将帧级标题输入到单个模型中，这使得难以充分捕捉时间和交互式上下文。&lt;h4&gt;目的&lt;/h4&gt;提出VideoMultiAgents框架，以解决现有方法在捕捉时间和交互式上下文方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;VideoMultiAgents框架通过整合专门代理，包括视觉代理、场景图分析代理和文本处理代理，以及问题引导的标题生成来提高视频问答的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在Intent-QA（79.0%，比之前的SOTA高6.2%）、EgoSchema子集（75.4%，比之前的SOTA高3.4%）和NExT-QA（79.6%，比之前的SOTA高0.4%）上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;VideoMultiAgents框架通过多模态推理和问题引导的标题生成，显著提高了视频问答的性能，并在多个数据集上取得了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Question Answering (VQA) inherently relies on multimodal reasoning,integrating visual, temporal, and linguistic cues to achieve a deeperunderstanding of video content. However, many existing methods rely on feedingframe-level captions into a single model, making it difficult to adequatelycapture temporal and interactive contexts. To address this limitation, weintroduce VideoMultiAgents, a framework that integrates specialized agents forvision, scene graph analysis, and text processing. It enhances videounderstanding leveraging complementary multimodal reasoning from independentlyoperating agents. Our approach is also supplemented with a question-guidedcaption generation, which produces captions that highlight objects, actions,and temporal transitions directly relevant to a given query, thus improving theanswer accuracy. Experimental results demonstrate that our method achievesstate-of-the-art performance on Intent-QA (79.0%, +6.2% over previous SOTA),EgoSchema subset (75.4%, +3.4%), and NExT-QA (79.6%, +0.4%).</description>
      <author>example@mail.com (Noriyuki Kugo, Xiang Li, Zixin Li, Ashish Gupta, Arpandeep Khatua, Nidhish Jain, Chaitanya Patel, Yuta Kyuragi, Masamoto Tanabiki, Kazuki Kozuka, Ehsan Adeli)</author>
      <guid isPermaLink="false">2504.20091v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning a General Model: Folding Clothing with Topological Dynamics</title>
      <link>http://arxiv.org/abs/2504.20720v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种拓扑动力学模型，用于折叠复杂的服装。&lt;h4&gt;背景&lt;/h4&gt;服装具有高自由度和复杂结构，对服装操作提出了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种方法来折叠复杂的服装。&lt;h4&gt;方法&lt;/h4&gt;利用可见的折叠结构作为拓扑骨架，设计了一种新的拓扑图来表示服装状态。应用语义分割分析遮挡关系，并分解服装结构，结合关键点检测生成拓扑图。使用改进的图神经网络（GNN）学习一般动力学，预测服装变形并计算变形雅可比矩阵。&lt;h4&gt;主要发现&lt;/h4&gt;拓扑图可以指示服装的约束，并预测服装的运动。&lt;h4&gt;结论&lt;/h4&gt;实验验证了算法在识别和折叠具有遮挡的复杂服装方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of the paper is summarized as follows: The high degrees of freedom and complex structure of garments present significant challenges for clothing manipulation. In this paper, we propose a general topological dynamics model to fold complex clothing. By utilizing the visible folding structure as the topological skeleton, we design a novel topological graph to represent the clothing state. This topological graph is low-dimensional and applied for complex clothing in various folding states. It indicates the constraints of clothing and enables predictions regarding clothing movement. To extract graphs from self-occlusion, we apply semantic segmentation to analyze the occlusion relationships and decompose the clothing structure. The decomposed structure is then combined with keypoint detection to generate the topological graph. To analyze the behavior of the topological graph, we employ an improved Graph Neural Network (GNN) to learn the general dynamics. The GNN model can predict the deformation of clothing and is employed to calculate the deformation Jacobi matrix for control. Experiments using jackets validate the algorithm's effectiveness to recognize and fold complex clothing with self-occlusion.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The high degrees of freedom and complex structure of garments presentsignificant challenges for clothing manipulation. In this paper, we propose ageneral topological dynamics model to fold complex clothing. By utilizing thevisible folding structure as the topological skeleton, we design a noveltopological graph to represent the clothing state. This topological graph islow-dimensional and applied for complex clothing in various folding states. Itindicates the constraints of clothing and enables predictions regardingclothing movement. To extract graphs from self-occlusion, we apply semanticsegmentation to analyze the occlusion relationships and decompose the clothingstructure. The decomposed structure is then combined with keypoint detection togenerate the topological graph. To analyze the behavior of the topologicalgraph, we employ an improved Graph Neural Network (GNN) to learn the generaldynamics. The GNN model can predict the deformation of clothing and is employedto calculate the deformation Jacobi matrix for control. Experiments usingjackets validate the algorithm's effectiveness to recognize and fold complexclothing with self-occlusion.</description>
      <author>example@mail.com (Yiming Liu, Lijun Han, Enlin Gu, Hesheng Wang)</author>
      <guid isPermaLink="false">2504.20720v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>FALCO: a Foundation model of Astronomical Light Curves for time dOmain astronomy</title>
      <link>http://arxiv.org/abs/2504.20290v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FALCO是一种用于时域天文观测的光曲线分析基础模型，通过自监督学习在未标记的开普勒光曲线上训练，表现出强大的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;时域天文观测揭示了多种可变现象，但数据规模和复杂性以及快速分类的需求对分析提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理时域天文观测数据并具有良好泛化能力的模型。&lt;h4&gt;方法&lt;/h4&gt;使用基于Transformer的架构，通过自监督学习在未标记的开普勒光曲线上训练FALCO模型。&lt;h4&gt;主要发现&lt;/h4&gt;FALCO在三个不同任务上表现出色：在八类恒星可变性分类中达到95%的准确率，表面重力估计的RMSE为0.1305 dex，在耀斑识别中达到87%的精确度。&lt;h4&gt;结论&lt;/h4&gt;FALCO模型能够从光曲线中学习可泛化的表示，并能够轻松适应不同的任务。模型性能随着模型规模和输入序列长度的增加而提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time-domain surveys have advanced astronomical research by revealing diversevariable phenomena, from stellar flares to transient events. The scale andcomplexity of survey data, along with the demand for rapid classification,present significant challenges for analysis. While machine learning offerssolutions, most existing models are tailored to single tasks, struggle togeneralize, and depend heavily on large, accurately labeled datasets. Weintroduce FALCO, a foundation model for astronomical light curve analysis intime-domain astronomy. This work presents the initial version of FALCO trainedvia self-supervised learning on unlabeled Kepler light curves using aTransformer-based architecture. The model has been evaluated on three distincttasks and demonstrates strong generalization: achieving 95 percent accuracy instellar variability classification across eight classes, an overall RMSE of0.1305 dex in surface gravity estimation (notably improved to below 0.08 dexwhen log g is less than 1, and approximately 0.02 dex near log g equals 3), and87 percent precision in flare identification. These results highlight themodel's versatility and ability to learn generalizable representations fromlight curves, enabling straightforward adaptation to diverse tasks. We furtheranalyze the impact of model scaling and sequence length, finding performanceimproves with larger models and longer input sequences. We also apply FALCO toderive surface gravity (log g) measurements for 179,732 Kepler stars from theirlight curves.</description>
      <author>example@mail.com (Xiaoxiong Zuo, Yihan Tao, Yang Huang, Zhixuan Kang, Huaxi Chen, Chenzhou Cui, Jiashu Pan, Xiao Kong, Xiaoyu Tang, Henggeng Han, Haiyang Mu, Yunfei Xu, Dongwei Fan, Guirong Xue, Ali Luo, Jifeng Liu)</author>
      <guid isPermaLink="false">2504.20290v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>SFi-Former: Sparse Flow Induced Attention for Graph Transformer</title>
      <link>http://arxiv.org/abs/2504.20666v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICMR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的注意力机制SFi-attention，以及基于此的SFi-Former模型，用于处理具有长距离依赖的图数据，以提高图神经网络（GNN）的性能并解决传统GNN存在的问题。&lt;h4&gt;背景&lt;/h4&gt;Graph Transformers在处理具有长距离依赖的图数据时表现出色，但传统的密集注意力机制导致诱导偏置弱、过拟合和过全局化等问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的注意力机制以缓解密集注意力带来的问题，并提高GNN模型在处理长距离依赖图数据时的性能。&lt;h4&gt;方法&lt;/h4&gt;引入SFi-attention，通过最小化基于网络流的能量函数来学习稀疏模式，并设计SFi-Former模型利用稀疏注意力模式生成稀疏网络流，从而从其他节点选择性地聚合特征。&lt;h4&gt;主要发现&lt;/h4&gt;SFi-Former在GNN基准数据集上获得了有竞争力的性能，在长距离图基准（LRGB）数据集上实现了SOTA性能，并且具有更小的泛化差距，表明它更不容易过拟合。&lt;h4&gt;结论&lt;/h4&gt;SFi-attention和SFi-Former模型为处理长距离依赖的图数据提供了一种有效的方法，并有望提高GNN模型的整体性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Transformers在许多研究中显示出比传统消息传递图神经网络（GNN）更优越的性能，尤其是在处理具有长距离依赖的图数据时。然而，由于密集注意力，GTs往往会遭受弱诱导偏置、过拟合和过全局化问题。在本文中，我们引入了SFi-attention，这是一种新的注意力机制，通过最小化基于网络流的能量函数（带有l1范数正则化）来学习稀疏模式，以缓解由密集注意力引起的问题。此外，相应地设计了SFi-Former，该模型可以利用SFi-attention的稀疏注意力模式在图数据的邻接矩阵之外生成稀疏网络流。具体来说，SFi-Former通过灵活地调整稀疏注意力来选择性地从其他节点聚合特征，从而得到一个更稳健的模型。我们在各种图数据集上验证了我们的SFi-Former，特别是那些表现出长距离依赖的图数据。实验结果表明，我们的SFi-Former在GNN基准数据集上获得了有竞争力的性能，在长距离图基准（LRGB）数据集上实现了SOTA性能。此外，我们的模型产生了更小的泛化差距，这表明它不太可能过拟合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs) have demonstrated superior performance compared totraditional message-passing graph neural networks in many studies, especiallyin processing graph data with long-range dependencies. However, GTs tend tosuffer from weak inductive bias, overfitting and over-globalizing problems dueto the dense attention. In this paper, we introduce SFi-attention, a novelattention mechanism designed to learn sparse pattern by minimizing an energyfunction based on network flows with l1-norm regularization, to relieve thoseissues caused by dense attention. Furthermore, SFi-Former is accordinglydevised which can leverage the sparse attention pattern of SFi-attention togenerate sparse network flows beyond adjacency matrix of graph data.Specifically, SFi-Former aggregates features selectively from other nodesthrough flexible adaptation of the sparse attention, leading to a more robustmodel. We validate our SFi-Former on various graph datasets, especially thosegraph data exhibiting long-range dependencies. Experimental results show thatour SFi-Former obtains competitive performance on GNN Benchmark datasets andSOTA performance on LongRange Graph Benchmark (LRGB) datasets. Additionally,our model gives rise to smaller generalization gaps, which indicates that it isless prone to over-fitting. Click here for codes.</description>
      <author>example@mail.com (Zhonghao Li, Ji Shi, Xinming Zhang, Miao Zhang, Bo Li)</author>
      <guid isPermaLink="false">2504.20666v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Exploring internal representation of self-supervised networks: few-shot learning abilities and comparison with human semantics and recognition of objects</title>
      <link>http://arxiv.org/abs/2504.20364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了自监督学习在机器学习和神经科学领域的最新进展，并研究了自监督学习方法在训练人工神经网络方面的应用潜力。&lt;h4&gt;背景&lt;/h4&gt;自监督学习方法不需要标注的监督信息，可以应用于不需要大量数据集的神经网络训练，并可能为大脑如何无监督地适应环境提供见解。&lt;h4&gt;目的&lt;/h4&gt;研究使用自监督对比学习算法训练的DCNN内部表示与人类语义和识别之间的对应关系。&lt;h4&gt;方法&lt;/h4&gt;采用少量样本学习评估程序，测量DCNN识别新概念的能力，并使用两种比较方法将少量样本学习结果与人类语义和识别联系起来。&lt;h4&gt;主要发现&lt;/h4&gt;通过对比学习获得的表示与人类认知高度一致，表明自监督对比学习框架在无法获得明确监督的情况下，如人类婴儿在语言习得之前，具有模拟人类大脑学习机制的可能性。&lt;h4&gt;结论&lt;/h4&gt;自监督对比学习框架在模拟人类大脑学习机制方面具有潜力，尤其是在无法获得明确监督的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in self-supervised learning have attracted significantattention from both machine learning and neuroscience. This is primarilybecause self-supervised methods do not require annotated supervisoryinformation, making them applicable to training artificial networks withoutrelying on large amounts of curated data, and potentially offering insightsinto how the brain adapts to its environment in an unsupervised manner.Although several previous studies have elucidated the correspondence betweenneural representations in deep convolutional neural networks (DCNNs) andbiological systems, the extent to which unsupervised or self-supervisedlearning can explain the human-like acquisition of categorically structuredinformation remains less explored. In this study, we investigate thecorrespondence between the internal representations of DCNNs trained using aself-supervised contrastive learning algorithm and human semantics andrecognition. To this end, we employ a few-shot learning evaluation procedure,which measures the ability of DCNNs to recognize novel concepts from limitedexposure, to examine the inter-categorical structure of the learnedrepresentations. Two comparative approaches are used to relate the few-shotlearning outcomes to human semantics and recognition, with results suggestingthat the representations acquired through contrastive learning are well alignedwith human cognition. These findings underscore the potential ofself-supervised contrastive learning frameworks to model learning mechanismssimilar to those of the human brain, particularly in scenarios where explicitsupervision is unavailable, such as in human infants prior to languageacquisition.</description>
      <author>example@mail.com (Asaki Kataoka, Yoshihiro Nagano, Masafumi Oizumi)</author>
      <guid isPermaLink="false">2504.20364v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Creating Your Editable 3D Photorealistic Avatar with Tetrahedron-constrained Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2504.20403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于创建可编辑3D虚拟形象的框架，旨在为普通用户提供精确的区域定位、几何适应性和逼真的渲染效果。&lt;h4&gt;背景&lt;/h4&gt;个性化3D形象编辑因其用户友好性和在AR/VR和虚拟试穿等应用中的可用性而具有巨大潜力。然而，先前的研究在生成视觉上令人满意的结果方面遇到了困难，这可能是由于在复杂重建场景中混合优化几何和纹理下的不稳定表示学习。&lt;h4&gt;目的&lt;/h4&gt;旨在为普通用户提供一种创建精确区域定位、几何适应性和逼真渲染的3D可编辑形象的可访问解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一个精心设计的框架，该框架将编辑过程分解为局部空间适应和逼真外观学习，使用混合四面体约束高斯分层（TetGS）作为底层表示。TetGS结合了四面体网格的可控显式结构和3D高斯分层的精确渲染能力，并经过三个阶段的优化：从现实世界的单目视频实例化3D形象以提供TetGS初始化的准确先验；使用显式划分的四面体进行局部空间适应以引导高斯核的重新分配；以及基于几何的外观生成，采用由粗到细的激活策略。&lt;h4&gt;主要发现&lt;/h4&gt;定性和定量实验都证明了该方法在生成逼真的3D可编辑形象方面的有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地生成逼真的3D可编辑形象，为普通用户提供了创建个性化虚拟形象的新途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Personalized 3D avatar editing holds significant promise due to itsuser-friendliness and availability to applications such as AR/VR and virtualtry-ons. Previous studies have explored the feasibility of 3D editing, butoften struggle to generate visually pleasing results, possibly due to theunstable representation learning under mixed optimization of geometry andtexture in complicated reconstructed scenarios. In this paper, we aim toprovide an accessible solution for ordinary users to create their editable 3Davatars with precise region localization, geometric adaptability, andphotorealistic renderings. To tackle this challenge, we introduce ameticulously designed framework that decouples the editing process into localspatial adaptation and realistic appearance learning, utilizing a hybridTetrahedron-constrained Gaussian Splatting (TetGS) as the underlyingrepresentation. TetGS combines the controllable explicit structure oftetrahedral grids with the high-precision rendering capabilities of 3D GaussianSplatting and is optimized in a progressive manner comprising three stages: 3Davatar instantiation from real-world monocular videos to provide accuratepriors for TetGS initialization; localized spatial adaptation with explicitlypartitioned tetrahedrons to guide the redistribution of Gaussian kernels; andgeometry-based appearance generation with a coarse-to-fine activation strategy.Both qualitative and quantitative experiments demonstrate the effectiveness andsuperiority of our approach in generating photorealistic 3D editable avatars.</description>
      <author>example@mail.com (Hanxi Liu, Yifang Men, Zhouhui Lian)</author>
      <guid isPermaLink="false">2504.20403v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>What Causes Knowledge Loss in Multilingual Language Models?</title>
      <link>http://arxiv.org/abs/2504.20356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了自然语言处理模型中的跨语言迁移问题，通过实验验证了参数共享在减轻遗忘和保留先验知识方面的效果。&lt;h4&gt;背景&lt;/h4&gt;跨语言迁移在自然语言处理中通过利用共享的语言知识来增强多语言性能。然而，传统方法在处理所有数据时往往无法模拟真实场景，导致灾难性遗忘等问题。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过实验评估参数共享通过适配器能否减轻遗忘同时保留先验知识。&lt;h4&gt;方法&lt;/h4&gt;研究在52种语言中使用不同阶数的LoRA适配器，对非共享、部分共享和完全共享的参数进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现使用非拉丁文字的语言更容易受到灾难性遗忘的影响，而使用拉丁文字的语言则更有利于有效的跨语言迁移。&lt;h4&gt;结论&lt;/h4&gt;参数共享通过适配器可以有效减轻遗忘并保留先验知识，特别是在使用拉丁文字的语言中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-lingual transfer in natural language processing (NLP) models enhancesmultilingual performance by leveraging shared linguistic knowledge. However,traditional methods that process all data simultaneously often fail to mimicreal-world scenarios, leading to challenges like catastrophic forgetting, wherefine-tuning on new tasks degrades performance on previously learned ones. Ourstudy explores this issue in multilingual contexts, focusing on linguisticdifferences affecting representational learning rather than just modelparameters. We experiment with 52 languages using LoRA adapters of varyingranks to evaluate non-shared, partially shared, and fully shared parameters.Our aim is to see if parameter sharing through adapters can mitigate forgettingwhile preserving prior knowledge. We find that languages using non-Latinscripts are more susceptible to catastrophic forgetting, whereas those writtenin Latin script facilitate more effective cross-lingual transfer.</description>
      <author>example@mail.com (Maria Khelli, Samuel Cahyawijaya, Ayu Purwarianti, Genta Indra Winata)</author>
      <guid isPermaLink="false">2504.20356v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning on a Random Lattice</title>
      <link>http://arxiv.org/abs/2504.20197v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Proceedings of ILIAD (2024),  https://www.iliadconference.com/proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将深度神经网络学习到的表示分解为可解释特征，以提高其安全性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;为了更好地理解特征，本文采用了几何视角，将特征视为学习到的坐标系统，用于映射嵌入数据分布。&lt;h4&gt;目的&lt;/h4&gt;通过分析数据分布的模型，提高对深度神经网络特征的理解。&lt;h4&gt;方法&lt;/h4&gt;将通用数据分布模型为一个随机晶格，并使用渗透理论分析其性质。&lt;h4&gt;主要发现&lt;/h4&gt;将学习到的特征分为上下文、组件和表面特征，模型与机制可解释性领域的近期发现相一致。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为未来研究提供了方向。&lt;h4&gt;翻译&lt;/h4&gt;Decomposing a deep neural network's learned representations into interpretable features could greatly enhance its safety and reliability. To better understand features, we adopt a geometric perspective, viewing them as a learned coordinate system for mapping an embedded data distribution. We motivate a model of a generic data distribution as a random lattice and analyze its properties using percolation theory. Learned features are categorized into context, component, and surface features. The model is qualitatively consistent with recent findings in mechanistic interpretability and suggests directions for future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decomposing a deep neural network's learned representations intointerpretable features could greatly enhance its safety and reliability. Tobetter understand features, we adopt a geometric perspective, viewing them as alearned coordinate system for mapping an embedded data distribution. Wemotivate a model of a generic data distribution as a random lattice and analyzeits properties using percolation theory. Learned features are categorized intocontext, component, and surface features. The model is qualitatively consistentwith recent findings in mechanistic interpretability and suggests directionsfor future research.</description>
      <author>example@mail.com (Aryeh Brill)</author>
      <guid isPermaLink="false">2504.20197v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Triadic Closure-Heterogeneity-Harmony GCN for Link Prediction</title>
      <link>http://arxiv.org/abs/2504.20492v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了TriHetGCN模型，用于复杂网络的链接预测，通过结合拓扑指示符，提高了预测准确性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;链接预测在复杂网络分析中应用广泛，但传统方法依赖于预定义的节点连接假设，而基于GNN的方法常忽视节点属性和节点对之间的结构关系。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够有效处理节点属性和节点对之间结构关系的链接预测模型。&lt;h4&gt;方法&lt;/h4&gt;TriHetGCN模型包含拓扑特征构建、图结构表示和连接概率预测三个模块，利用三度闭包和度异质性等拓扑指示符来提高预测能力。&lt;h4&gt;主要发现&lt;/h4&gt;在九个真实世界数据集上的评估中，TriHetGCN模型取得了最先进的性能，超越了主流方法，表现出较强的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;TriHetGCN模型提供了一个连接统计物理和图深度学习的有希望的框架，具有良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction aims to estimate the likelihood of connections between pairsof nodes in complex networks, which is beneficial to many applications fromfriend recommendation to metabolic network reconstruction. Traditionalheuristic-based methodologies in the field of complex networks typically dependon predefined assumptions about node connectivity, limiting theirgeneralizability across diverse networks. While recent graph neural network(GNN) approaches capture global structural features effectively, they oftenneglect node attributes and intrinsic structural relationships between nodepairs. To address this, we propose TriHetGCN, an extension of traditional GraphConvolutional Networks (GCNs) that incorporates explicit topological indicators-- triadic closure and degree heterogeneity. TriHetGCN consists of threemodules: topology feature construction, graph structural representation, andconnection probability prediction. The topology feature module constructs nodefeatures using shortest path distances to anchor nodes, enhancing globalstructure perception. The graph structural module integrates topologicalindicators into the GCN framework to model triadic closure and heterogeneity.The connection probability module uses deep learning to predict links.Evaluated on nine real-world datasets, from traditional networks without nodeattributes to large-scale networks with rich features, TriHetGCN achievesstate-of-the-art performance, outperforming mainstream methods. This highlightsits strong generalization across diverse network types, offering a promisingframework that bridges statistical physics and graph deep learning.</description>
      <author>example@mail.com (Ke-ke Shang, Junfan Yi, Michael Small, Yijie Zhou)</author>
      <guid isPermaLink="false">2504.20492v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation</title>
      <link>http://arxiv.org/abs/2504.17365v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TimeSoccer是一种新的足球视频多模态大型语言模型，用于全场比赛视频的密集视频字幕生成（SDVC），通过引入MoFA-Select模块和联合预测时间戳和字幕，实现了长视频理解并达到先进性能。&lt;h4&gt;背景&lt;/h4&gt;足球是一项全球流行的运动赛事，通常具有长时间的赛程和独特的精彩时刻。现有的足球多模态大型语言模型在字幕生成时依赖时间先验知识，无法端到端处理足球视频。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的问题，提出TimeSoccer，旨在实现全场比赛视频的端到端密集视频字幕生成，并生成高质量、时间对齐准确、语义相关的评论。&lt;h4&gt;方法&lt;/h4&gt;TimeSoccer联合预测时间戳和字幕，一次生成，并在45分钟的比赛中进行全局上下文建模。MoFA-Select是一个无训练的动觉帧压缩模块，通过粗到细的策略自适应选择代表性帧，并采用补充训练范式加强模型处理长时序的能力。&lt;h4&gt;主要发现&lt;/h4&gt;TimeSoccer在SDVC任务上实现了最先进（SoTA）的性能，能够生成高质量、时间对齐准确、语义相关的评论。&lt;h4&gt;结论&lt;/h4&gt;TimeSoccer在足球视频字幕生成方面取得了显著进步，为长视频理解提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soccer is a globally popular sporting event, typically characterized by longmatches and distinctive highlight moments. Recent advances in Multimodal LargeLanguage Models (MLLMs) offer promising capabilities in temporal grounding andvideo understanding, soccer commentary generation often requires precisetemporal localization and semantically rich descriptions over long-form video.However, existing soccer MLLMs often rely on the temporal a priori for captiongeneration, so they cannot process the soccer video end-to-end. While sometraditional approaches follow a two-step paradigm that is complex and fails tocapture the global context to achieve suboptimal performance. To solve theabove issues, we present TimeSoccer, the first end-to-end soccer MLLM forSingle-anchor Dense Video Captioning (SDVC) in full-match soccer videos.TimeSoccer jointly predicts timestamps and generates captions in a single pass,enabling global context modeling across 45-minute matches. To support longvideo understanding of soccer matches, we introduce MoFA-Select, atraining-free, motion-aware frame compression module that adaptively selectsrepresentative frames via a coarse-to-fine strategy, and incorporatescomplementary training paradigms to strengthen the model's ability to handlelong temporal sequences. Extensive experiments demonstrate that our TimeSoccerachieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-endform, generating high-quality commentary with accurate temporal alignment andstrong semantic relevance.</description>
      <author>example@mail.com (Ling You, Wenxuan Huang, Xinni Xie, Xiangyi Wei, Bangyan Li, Shaohui Lin, Yang Li, Changbo Wang)</author>
      <guid isPermaLink="false">2504.17365v3</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning Laplacian Positional Encodings for Heterophilous Graphs</title>
      <link>http://arxiv.org/abs/2504.20430v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AISTATS 2025; version with full appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文从理论上证明了当前图位置编码（PEs）在处理异质图任务时可能不利于性能，甚至可能损害性能。为了解决这一局限性，提出了可学习的拉普拉斯位置编码（LLPE），它能够利用图拉普拉斯的全谱，从而在亲缘性和异质图上捕捉图结构。&lt;h4&gt;背景&lt;/h4&gt;许多现实世界的网络表现出异质性，即使是高度同质性的图也可能包含局部强异质性的区域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的PE方法，以有效捕捉异质图中的复杂结构。&lt;h4&gt;方法&lt;/h4&gt;提出了Learnable Laplacian Positional Encodings (LLPE)，并通过理论证明和实证评估来验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;LLPE能够近似一类通用的图距离，并在12个基准数据集上对多种GNN（包括图变换器）进行了评估，结果表明LLPE在合成和现实世界的图上分别提高了35%和14%的准确率。&lt;h4&gt;结论&lt;/h4&gt;LLPE是向开发能够有效捕捉异质图中复杂结构的位置编码方法迈出的重要一步。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we theoretically demonstrate that current graph positional encodings (PEs) are not beneficial and could potentially hurt performance in tasks involving heterophilous graphs, where nodes that are close tend to have different labels. This limitation is critical as many real-world networks exhibit heterophily, and even highly homophilous graphs can contain local regions of strong heterophily. To address this limitation, we propose Learnable Laplacian Positional Encodings (LLPE), a new PE that leverages the full spectrum of the graph Laplacian, enabling them to capture graph structure on both homophilous and heterophilous graphs. Theoretically, we prove LLPE's ability to approximate a general class of graph distances and demonstrate its generalization properties. Empirically, our evaluation on 12 benchmarks demonstrates that LLPE improves accuracy across a variety of GNNs, including graph transformers, by up to 35% and 14% on synthetic and real-world graphs, respectively. Going forward, our work represents a significant step towards developing PEs that effectively capture complex structures in heterophilous graphs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we theoretically demonstrate that current graph positionalencodings (PEs) are not beneficial and could potentially hurt performance intasks involving heterophilous graphs, where nodes that are close tend to havedifferent labels. This limitation is critical as many real-world networksexhibit heterophily, and even highly homophilous graphs can contain localregions of strong heterophily. To address this limitation, we propose LearnableLaplacian Positional Encodings (LLPE), a new PE that leverages the fullspectrum of the graph Laplacian, enabling them to capture graph structure onboth homophilous and heterophilous graphs. Theoretically, we prove LLPE'sability to approximate a general class of graph distances and demonstrate itsgeneralization properties. Empirically, our evaluation on 12 benchmarksdemonstrates that LLPE improves accuracy across a variety of GNNs, includinggraph transformers, by up to 35% and 14% on synthetic and real-world graphs,respectively. Going forward, our work represents a significant step towardsdeveloping PEs that effectively capture complex structures in heterophilousgraphs.</description>
      <author>example@mail.com (Michael Ito, Jiong Zhu, Dexiong Chen, Danai Koutra, Jenna Wiens)</author>
      <guid isPermaLink="false">2504.20430v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Understanding GNNs and Homophily in Dynamic Node Classification</title>
      <link>http://arxiv.org/abs/2504.20421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AISTATS 2025; version with full appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了动态图中的同质性，提出了一个新的同质性度量方法，并探讨了其在图神经网络（GNN）性能上的应用。&lt;h4&gt;背景&lt;/h4&gt;同质性作为度量，对于理解图神经网络（GNN）至关重要，但至今为止，这一度量仅在静态图环境中进行分析。&lt;h4&gt;目的&lt;/h4&gt;探索动态环境中的同质性，并提出一种适用于动态环境的新同质性度量方法。&lt;h4&gt;方法&lt;/h4&gt;重点关注图卷积网络（GCN），理论上证明了在动态环境中，当前GCN的判别性能由节点未来标签与其邻居当前标签相同性的概率决定。&lt;h4&gt;主要发现&lt;/h4&gt;提出了动态同质性，这一新度量与GNN的判别性能相关，并揭示了如何设计更强大的GNN以适应动态图。&lt;h4&gt;结论&lt;/h4&gt;本文的研究工作对于理解同质性和GNN在动态节点分类中的性能具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;Homophily, as a measure, has been critical to increasing our understanding of graph neural networks (GNNs). However, to date this measure has only been analyzed in the context of static graphs. In our work, we explore homophily in dynamic settings. Focusing on graph convolutional networks (GCNs), we demonstrate theoretically that in dynamic settings, current GCN discriminative performance is characterized by the probability that a node's future label is the same as its neighbors' current labels. Based on this insight, we propose dynamic homophily, a new measure of homophily that applies in the dynamic setting. This new measure correlates with GNN discriminative performance and sheds light on how to potentially design more powerful GNNs for dynamic graphs. Leveraging a variety of dynamic node classification datasets, we demonstrate that popular GNNs are not robust to low dynamic homophily. Going forward, our work represents an important step towards understanding homophily and GNN performance in dynamic node classification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Homophily, as a measure, has been critical to increasing our understanding ofgraph neural networks (GNNs). However, to date this measure has only beenanalyzed in the context of static graphs. In our work, we explore homophily indynamic settings. Focusing on graph convolutional networks (GCNs), wedemonstrate theoretically that in dynamic settings, current GCN discriminativeperformance is characterized by the probability that a node's future label isthe same as its neighbors' current labels. Based on this insight, we proposedynamic homophily, a new measure of homophily that applies in the dynamicsetting. This new measure correlates with GNN discriminative performance andsheds light on how to potentially design more powerful GNNs for dynamic graphs.Leveraging a variety of dynamic node classification datasets, we demonstratethat popular GNNs are not robust to low dynamic homophily. Going forward, ourwork represents an important step towards understanding homophily and GNNperformance in dynamic node classification.</description>
      <author>example@mail.com (Michael Ito, Danai Koutra, Jenna Wiens)</author>
      <guid isPermaLink="false">2504.20421v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Skill Discovery for Software Scripting Automation via Offline Simulations with LLMs</title>
      <link>http://arxiv.org/abs/2504.20406v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用大型语言模型和公开的脚本指南构建离线模拟框架的方法，以自动化任务和定制软件工作流程，旨在解决传统脚本创建的障碍。&lt;h4&gt;背景&lt;/h4&gt;脚本接口允许用户自动化任务和定制软件工作流程，但创建脚本通常需要编程专长和对特定API的熟悉度，这对许多用户来说构成了障碍。&lt;h4&gt;目的&lt;/h4&gt;为了解决运行时代码生成的问题，如未验证的代码、安全风险、较长的响应时间和较高的计算成本，本文旨在通过构建一个离线模拟框架来创建软件特定的技能集。&lt;h4&gt;方法&lt;/h4&gt;该框架包括两个组件：（1）任务创建，使用自上而下的功能指导和自下而上的API协同探索来生成有用的任务；（2）技能生成，通过试验、优化和验证脚本，基于执行反馈来生成技能。为了高效地导航广泛的API景观，引入了一个基于图神经网络（GNN）的链接预测模型来捕捉API协同，从而生成涉及未充分利用的API的技能，并扩展技能集的多样性。&lt;h4&gt;主要发现&lt;/h4&gt;Adobe Illustrator的实验表明，与传统的运行时代码生成相比，该框架显著提高了自动化成功率，减少了响应时间，并节省了运行时令牌成本。&lt;h4&gt;结论&lt;/h4&gt;这是首次尝试将软件脚本接口作为基于LLM系统的测试平台，强调了在受控环境中利用执行反馈的优势，并为将AI能力与用户需求对齐提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;Scripting interfaces enable users to automate tasks and customize software workflows, but creating scripts traditionally requires programming expertise and familiarity with specific APIs, posing barriers for many users. While Large Language Models (LLMs) can generate code from natural language queries, runtime code generation is severely limited due to unverified code, security risks, longer response times, and higher computational costs. To bridge the gap, we propose an offline simulation framework to curate a software-specific skillset, a collection of verified scripts, by exploiting LLMs and publicly available scripting guides. Our framework comprises two components: (1) task creation, using top-down functionality guidance and bottom-up API synergy exploration to generate helpful tasks; and (2) skill generation with trials, refining and validating scripts based on execution feedback. To efficiently navigate the extensive API landscape, we introduce a Graph Neural Network (GNN)-based link prediction model to capture API synergy, enabling the generation of skills involving underutilized APIs and expanding the skillset's diversity. Experiments with Adobe Illustrator demonstrate that our framework significantly improves automation success rates, reduces response time, and saves runtime token costs compared to traditional runtime code generation. This is the first attempt to use software scripting interfaces as a testbed for LLM-based systems, highlighting the advantages of leveraging execution feedback in a controlled environment and offering valuable insights into aligning AI capabilities with user needs in specialized software domains.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scripting interfaces enable users to automate tasks and customize softwareworkflows, but creating scripts traditionally requires programming expertiseand familiarity with specific APIs, posing barriers for many users. While LargeLanguage Models (LLMs) can generate code from natural language queries, runtimecode generation is severely limited due to unverified code, security risks,longer response times, and higher computational costs. To bridge the gap, wepropose an offline simulation framework to curate a software-specific skillset,a collection of verified scripts, by exploiting LLMs and publicly availablescripting guides. Our framework comprises two components: (1) task creation,using top-down functionality guidance and bottom-up API synergy exploration togenerate helpful tasks; and (2) skill generation with trials, refining andvalidating scripts based on execution feedback. To efficiently navigate theextensive API landscape, we introduce a Graph Neural Network (GNN)-based linkprediction model to capture API synergy, enabling the generation of skillsinvolving underutilized APIs and expanding the skillset's diversity.Experiments with Adobe Illustrator demonstrate that our framework significantlyimproves automation success rates, reduces response time, and saves runtimetoken costs compared to traditional runtime code generation. This is the firstattempt to use software scripting interfaces as a testbed for LLM-basedsystems, highlighting the advantages of leveraging execution feedback in acontrolled environment and offering valuable insights into aligning AIcapabilities with user needs in specialized software domains.</description>
      <author>example@mail.com (Paiheng Xu, Gang Wu, Xiang Chen, Tong Yu, Chang Xiao, Franck Dernoncourt, Tianyi Zhou, Wei Ai, Viswanathan Swaminathan)</author>
      <guid isPermaLink="false">2504.20406v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Generative Diffusion Models for Resource Allocation in Wireless Networks</title>
      <link>http://arxiv.org/abs/2504.20277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成扩散模型（GDMs）的监督训练算法，用于学习随机资源分配策略。&lt;h4&gt;背景&lt;/h4&gt;资源分配问题被表述为在满足稳态服务质量（QoS）约束下最大化稳态效用函数。&lt;h4&gt;目的&lt;/h4&gt;目的是训练一个GDM策略来模仿专家政策，并从最优分布中生成新的样本。&lt;h4&gt;方法&lt;/h4&gt;通过序列执行生成的样本来达到近最优性能。为了使算法适用于多种网络配置，使用图神经网络（GNN）架构参数化反向扩散过程。&lt;h4&gt;主要发现&lt;/h4&gt;在多用户干扰网络中的功率控制案例研究中，展示了数值结果。&lt;h4&gt;结论&lt;/h4&gt;该算法能够通过生成扩散模型学习到近最优的资源分配策略，并能够适应不同的网络配置。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a supervised training algorithm for learning stochasticresource allocation policies with generative diffusion models (GDMs). Weformulate the allocation problem as the maximization of an ergodic utilityfunction subject to ergodic Quality of Service (QoS) constraints. Given samplesfrom a stochastic expert policy that yields a near-optimal solution to theproblem, we train a GDM policy to imitate the expert and generate new samplesfrom the optimal distribution. We achieve near-optimal performance throughsequential execution of the generated samples. To enable generalization to afamily of network configurations, we parameterize the backward diffusionprocess with a graph neural network (GNN) architecture. We present numericalresults in a case study of power control in multi-user interference networks.</description>
      <author>example@mail.com (Yigit Berkay Uslu, Samar Hadou, Shirin Saeedi Bidokhti, Alejandro Ribeiro)</author>
      <guid isPermaLink="false">2504.20277v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning Hierarchical Interaction for Accurate Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2504.20127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HimNet的新型模型，用于预测分子的ADMET属性，通过层次交互信息传递机制，实现了对分子结构的有效捕捉和特征提取，提高了分子属性预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;在药物发现过程中，发现具有理想分子属性的分子至关重要。现有的方法通常使用深度学习模型，如图神经网络（GNNs）和Transformer，通过学习化学信息来预测这些分子属性。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型在捕捉分子结构层次性和多级特征交互方面存在的不足，提出了一种新的层次交互信息传递机制。&lt;h4&gt;方法&lt;/h4&gt;该方法通过层次注意力引导的信息传递，实现了在原子、基序和分子层面的交互感知表示学习，从而有效平衡全局和局部信息。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准数据集上的实验表明，HimNet在大多数分子属性预测任务中取得了最佳或接近最佳的性能，并且表现出良好的层次可解释性，与化学直觉相符。&lt;h4&gt;结论&lt;/h4&gt;HimNet为分子活性和ADMET属性预测提供了一种准确且高效的方法，对药物发现早期阶段的决策具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在药物发现中，发现具有理想分子属性（包括ADMET特性）的分子至关重要。现有方法通常采用深度学习模型，如图神经网络（GNNs）和Transformer，通过学习多样化的化学信息来预测这些分子属性。然而，这些模型往往无法有效地捕捉和利用分子结构的层次性，并且缺乏多级特征之间有效交互的机制。为了解决这些限制，我们提出了一种层次交互信息传递机制，作为我们新颖模型HimNet的基础。我们的方法通过层次注意力引导的信息传递，实现了在原子、基序和分子层面的交互感知表示学习。这种设计使得HimNet能够有效地平衡全局和局部信息，确保为下游属性预测任务（如血脑屏障通透性BBBP）提供丰富且与任务相关的特征提取。在多个基准数据集上的大量实验表明，HimNet在大多数分子属性预测任务中实现了最佳或接近最佳的性能。此外，我们的方法表现出有希望的结构可解释性，与代表性分子的化学直觉相吻合。我们相信，HimNet为分子活性和ADMET属性预测提供了一种准确且高效的方法，对药物发现早期阶段的决策具有重大贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Discovering molecules with desirable molecular properties, including ADMET(Absorption, Distribution, Metabolism, Excretion, and Toxicity) profiles, is ofgreat importance in drug discovery. Existing approaches typically employ deeplearning models, such as Graph Neural Networks (GNNs) and Transformers, topredict these molecular properties by learning from diverse chemicalinformation. However, these models often fail to efficiently capture andutilize the hierarchical nature of molecular structures, and lack mechanismsfor effective interaction among multi-level features. To address theselimitations, we propose a Hierarchical Interaction Message Passing Mechanism,which serves as the foundation of our novel model, HimNet. Our method enablesinteraction-aware representation learning across atomic, motif, and molecularlevels via hierarchical attention-guided message passing. This design allowsHimNet to effectively balance global and local information, ensuring rich andtask-relevant feature extraction for downstream property prediction tasks, suchas Blood-Brain Barrier Permeability (BBBP). Extensive experiments on multiplebenchmark datasets demonstrate that HimNet achieves the best or near-bestperformance in most molecular property prediction tasks. Furthermore, ourmethod exhibits promising hierarchical interpretability, aligning well withchemical intuition on representative molecules. We believe that HimNet offersan accurate and efficient solution for molecular activity and ADMET propertyprediction, contributing significantly to advanced decision-making in the earlystages of drug discovery.</description>
      <author>example@mail.com (Huiyang Hong, Xinkai Wu, Hongyu Sun, Qi Wang, Yuquan Li)</author>
      <guid isPermaLink="false">2504.20127v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>If Concept Bottlenecks are the Question, are Foundation Models the Answer?</title>
      <link>http://arxiv.org/abs/2504.19774v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了概念瓶颈模型（CBMs），这是一种结合高性能和先验可解释性的神经网络。&lt;h4&gt;背景&lt;/h4&gt;CBMs通过将输入（如图像）映射到高级概念（如可见物体及其属性），然后以可解释的方式使用这些概念解决下游任务（如图像标签或评分）。然而，这些模型的表现和可解释性依赖于它们学习到的概念质量。&lt;h4&gt;目的&lt;/h4&gt;研究使用VLM-CBM架构代替手动标注（专家标注）的方法，以及这种做法对学习到的概念质量的影响。&lt;h4&gt;方法&lt;/h4&gt;研究者通过实证分析，使用一系列重要的指标来测试最先进的VLM-CBMs，并评估其学习到的概念。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，VLM监督与专家标注在性能上可能存在明显差异，并且概念准确性和质量并不强烈相关。&lt;h4&gt;结论&lt;/h4&gt;本文的结论是，VLM监督在概念质量上可能不如专家标注，但其在某些任务中可以提供合理的性能。&lt;h4&gt;翻译&lt;/h4&gt;Concept Bottleneck Models (CBMs) are neural networks designed to conjoin high-performance with ante-hoc interpretability. CBMs work by first mapping inputs (e.g., images) to high-level concepts (e.g., visible objects and their properties) and then use these to solve a downstream task (e.g., tagging or scoring an image) in an interpretable manner. Their performance and interpretability, however, hinge on the quality of the concepts they learn. The go-to strategy for ensuring good quality concepts is to leverage expert annotations, which are expensive to collect and seldom available in applications. Researchers have recently addressed this issue by introducing 'VLM-CBM' architectures that replace manual annotations with weak supervision from foundation models. It is, however, unclear what is the impact of doing so on the quality of the learned concepts. To answer this question, we put state-of-the-art VLM-CBMs to the test, analyzing their learned concepts empirically using a selection of significant metrics. Our results show that, depending on the task, VLM supervision can sensibly differ from expert annotations, and that concept accuracy and quality are not strongly correlated. Our code is available at https://github.com/debryu/CQA.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Concept Bottleneck Models (CBMs) are neural networks designed to conjoin highperformance with ante-hoc interpretability. CBMs work by first mapping inputs(e.g., images) to high-level concepts (e.g., visible objects and theirproperties) and then use these to solve a downstream task (e.g., tagging orscoring an image) in an interpretable manner. Their performance andinterpretability, however, hinge on the quality of the concepts they learn. Thego-to strategy for ensuring good quality concepts is to leverage expertannotations, which are expensive to collect and seldom available inapplications. Researchers have recently addressed this issue by introducing"VLM-CBM" architectures that replace manual annotations with weak supervisionfrom foundation models. It is however unclear what is the impact of doing so onthe quality of the learned concepts. To answer this question, we putstate-of-the-art VLM-CBMs to the test, analyzing their learned conceptsempirically using a selection of significant metrics. Our results show that,depending on the task, VLM supervision can sensibly differ from expertannotations, and that concept accuracy and quality are not strongly correlated.Our code is available at https://github.com/debryu/CQA.</description>
      <author>example@mail.com (Nicola Debole, Pietro Barbiero, Francesco Giannini, Andrea Passerini, Stefano Teso, Emanuele Marconato)</author>
      <guid isPermaLink="false">2504.19774v2</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Pediatric Asthma Detection with Googles HeAR Model: An AI-Driven Respiratory Sound Classifier</title>
      <link>http://arxiv.org/abs/2504.20124v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于人工智能的诊断流程，利用Google的Health Acoustic Representations (HeAR)模型从儿童呼吸声音中检测哮喘的早期迹象。&lt;h4&gt;背景&lt;/h4&gt;早期检测儿童哮喘对于预防长期呼吸并发症和减少紧急干预至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够快速、非侵入性地筛查哮喘的方法。&lt;h4&gt;方法&lt;/h4&gt;使用SPRSound数据集，该数据集是第一个公开的、标注了1个月至18岁儿童呼吸声音的集合。数据集中的每个2秒音频片段被嵌入到512维度的表示中，使用的是在3亿个与健康相关的音频剪辑（包括1亿个咳嗽声音）上预训练的HeAR模型。然后，使用SVM、随机森林和MLP等多个分类器在这些嵌入上进行训练，以区分哮喘指示性声音和正常声音。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在分类任务上达到了超过91%的准确率，在正例的精确度-召回率指标上表现良好。通过PCA可视化学习到的嵌入，通过波形回放分析误分类，并提供了ROC和混淆矩阵的见解。&lt;h4&gt;结论&lt;/h4&gt;这种方法表明，由基础音频模型驱动的短、低资源的儿童录音可以实现快速、非侵入性的哮喘筛查，特别适用于远程或服务不足的医疗保健环境。&lt;h4&gt;翻译&lt;/h4&gt;摘要：儿童哮喘的早期检测对于预防长期呼吸并发症和减少紧急干预至关重要。本研究提出了一种基于人工智能的诊断流程，利用Google的Health Acoustic Representations (HeAR)模型从儿童呼吸声音中检测哮喘的早期迹象。使用SPRSound数据集，该数据集是第一个公开的、标注了1个月至18岁儿童呼吸声音的集合。数据集中的每个2秒音频片段被嵌入到512维度的表示中，使用的是在3亿个与健康相关的音频剪辑（包括1亿个咳嗽声音）上预训练的HeAR模型。然后，使用SVM、随机森林和MLP等多个分类器在这些嵌入上进行训练，以区分哮喘指示性声音和正常声音。该系统在分类任务上达到了超过91%的准确率，在正例的精确度-召回率指标上表现良好。通过PCA可视化学习到的嵌入，通过波形回放分析误分类，并提供了ROC和混淆矩阵的见解。这种方法表明，由基础音频模型驱动的短、低资源的儿童录音可以实现快速、非侵入性的哮喘筛查，特别适用于远程或服务不足的医疗保健环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early detection of asthma in children is crucial to prevent long-termrespiratory complications and reduce emergency interventions. This workpresents an AI-powered diagnostic pipeline that leverages Googles HealthAcoustic Representations (HeAR) model to detect early signs of asthma frompediatric respiratory sounds. The SPRSound dataset, the first open-accesscollection of annotated respiratory sounds in children aged 1 month to 18years, is used to extract 2-second audio segments labeled as wheeze, crackle,rhonchi, stridor, or normal. Each segment is embedded into a 512-dimensionalrepresentation using HeAR, a foundation model pretrained on 300 millionhealth-related audio clips, including 100 million cough sounds. Multipleclassifiers, including SVM, Random Forest, and MLP, are trained on theseembeddings to distinguish between asthma-indicative and normal sounds. Thesystem achieves over 91\% accuracy, with strong performance on precision-recallmetrics for positive cases. In addition to classification, learned embeddingsare visualized using PCA, misclassifications are analyzed through waveformplayback, and ROC and confusion matrix insights are provided. This methoddemonstrates that short, low-resource pediatric recordings, when powered byfoundation audio models, can enable fast, noninvasive asthma screening. Theapproach is especially promising for digital diagnostics in remote orunderserved healthcare settings.</description>
      <author>example@mail.com (Abul Ehtesham, Saket Kumar, Aditi Singh, Tala Talaei Khoei)</author>
      <guid isPermaLink="false">2504.20124v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Geometry-Informed Neural Operator Transformer</title>
      <link>http://arxiv.org/abs/2504.19452v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GINOT的几何信息神经网络算子Transformer，该模型结合了transformer架构和神经网络算子框架，实现了对任意几何形状的前向预测。&lt;h4&gt;背景&lt;/h4&gt;基于机器学习的代理模型在计算效率方面优于传统的数值方法，尤其在需要重复评估偏微分方程的问题中。&lt;h4&gt;目的&lt;/h4&gt;提出GINOT的目的是为了实现任意几何形状的前向预测。&lt;h4&gt;方法&lt;/h4&gt;GINOT通过采样和分组机制结合注意力机制对几何形状的点云进行编码，确保对点顺序和填充的不变性，同时保持对点密度变化的鲁棒性。几何信息通过注意力机制与解解码器中的查询点无缝集成。&lt;h4&gt;主要发现&lt;/h4&gt;GINOT在多个具有挑战性的数据集上进行了验证，展示了其在复杂和任意2D和3D几何形状上的高精度和强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;GINOT是一种高效且准确的方法，可以用于对任意几何形状进行前向预测。&lt;h4&gt;翻译&lt;/h4&gt;Machine-learning-based surrogate models offer significant computational efficiency and faster simulations compared to traditional numerical methods, especially for problems requiring repeated evaluations of partial differential equations. This work introduces the Geometry-Informed Neural Operator Transformer (GINOT), which integrates the transformer architecture with the neural operator framework to enable forward predictions for arbitrary geometries. GINOT encodes the surface point cloud of a geometry using a sampling and grouping mechanism combined with an attention mechanism, ensuring invariance to point order and padding while maintaining robustness to variations in point density. The geometry information is seamlessly integrated with query points in the solution decoder through the attention mechanism. The performance of GINOT is validated on multiple challenging datasets, showcasing its high accuracy and strong generalization capabilities for complex and arbitrary 2D and 3D geometries.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learning-based surrogate models offer significant computationalefficiency and faster simulations compared to traditional numerical methods,especially for problems requiring repeated evaluations of partial differentialequations. This work introduces the Geometry-Informed Neural OperatorTransformer (GINOT), which integrates the transformer architecture with theneural operator framework to enable forward predictions for arbitrarygeometries. GINOT encodes the surface points cloud of a geometry using asampling and grouping mechanism combined with an attention mechanism, ensuringinvariance to point order and padding while maintaining robustness tovariations in point density. The geometry information is seamlessly integratedwith query points in the solution decoder through the attention mechanism. Theperformance of GINOT is validated on multiple challenging datasets, showcasingits high accuracy and strong generalization capabilities for complex andarbitrary 2D and 3D geometries.</description>
      <author>example@mail.com (Qibang Liu, Vincient Zhong, Hadi Meidani, Diab Abueidda, Seid Koric, Philippe Geubelle)</author>
      <guid isPermaLink="false">2504.19452v2</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Supervised Pretraining for Material Property Prediction</title>
      <link>http://arxiv.org/abs/2504.20112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 7 figures, 2 algorithms, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的监督预训练方法，用于材料性能预测，通过使用可用的类别信息作为代理标签，提高了模型的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;准确预测材料性能对于发现具有定制功能的新型材料至关重要。深度学习模型在捕捉结构-性能关系方面表现出色，但通常依赖于需要大量、标注良好的数据集的监督学习。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过使用自我监督学习（SSL）和监督预训练来预测材料性能，以减少对大量标注数据集的依赖。&lt;h4&gt;方法&lt;/h4&gt;研究者提出了监督预训练，其中可用的类别信息作为代理标签来指导学习，并评估了这种方法在两个最先进的SSL模型上的效果。此外，他们还提出了一种基于图的增强技术，通过向材料图注入噪声来提高鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法在六个具有挑战性的材料性能预测任务上进行了微调，平均绝对误差（MAE）提高了2%至6.67%，并建立了新的基准。&lt;h4&gt;结论&lt;/h4&gt;这项研究是第一次探索在材料性能预测中使用代理标签进行监督预训练，推动了该领域的方法和应用的进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测材料属性有助于发现具有定制功能的新型材料。最近，深度学习模型在捕捉结构-属性关系方面显示出优异的准确性和灵活性。然而，这些模型通常依赖于需要大量、标注良好的数据集的监督学习。自我监督学习（SSL）通过在大规模无标签数据集上预训练来开发可以微调用于材料属性预测的基础模型，提供了一种有希望的选择。在本工作中，我们提出了监督预训练，其中可用的类别信息作为代理标签来引导学习，即使下游任务涉及无关的材料属性。我们评估了这种策略在两个最先进的SSL模型上的效果，并介绍了一种新的监督预训练框架。为了进一步提高表示学习，我们提出了一种基于图的增强技术，通过向材料图注入噪声来提高鲁棒性，而不破坏材料图的结构。所得到的基模模型用于六个具有挑战性的材料性能预测任务，与基线相比，平均绝对误差（MAE）提高了2%至6.67%，并在材料性能预测中建立了新的基准。这项研究是第一次在材料性能预测中探索使用代理标签进行监督预训练，推动了该领域的方法和应用的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of material properties facilitates the discovery of novelmaterials with tailored functionalities. Deep learning models have recentlyshown superior accuracy and flexibility in capturing structure-propertyrelationships. However, these models often rely on supervised learning, whichrequires large, well-annotated datasets an expensive and time-consumingprocess. Self-supervised learning (SSL) offers a promising alternative bypretraining on large, unlabeled datasets to develop foundation models that canbe fine-tuned for material property prediction. In this work, we proposesupervised pretraining, where available class information serves as surrogatelabels to guide learning, even when downstream tasks involve unrelated materialproperties. We evaluate this strategy on two state-of-the-art SSL models andintroduce a novel framework for supervised pretraining. To further enhancerepresentation learning, we propose a graph-based augmentation technique thatinjects noise to improve robustness without structurally deforming materialgraphs. The resulting foundation models are fine-tuned for six challengingmaterial property predictions, achieving significant performance gains overbaselines, ranging from 2% to 6.67% improvement in mean absolute error (MAE)and establishing a new benchmark in material property prediction. This studyrepresents the first exploration of supervised pertaining with surrogate labelsin material property prediction, advancing methodology and application in thefield.</description>
      <author>example@mail.com (Chowdhury Mohammad Abid Rahman, Aldo H. Romero, Prashnna K. Gyawali)</author>
      <guid isPermaLink="false">2504.20112v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous network drug-target interaction prediction model based on graph wavelet transform and multi-level contrastive learning</title>
      <link>http://arxiv.org/abs/2504.20103v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种异构网络药物靶点相互作用预测框架，结合图神经网络和多尺度信号处理技术，构建了一个既高效预测又具有多层次可解释性的模型。&lt;h4&gt;背景&lt;/h4&gt;药物-靶点相互作用预测在生物医学领域的药物开发和精准医学中是一个核心任务。然而，传统的机器学习方法通常存在黑盒问题，这使得揭示模型决策机制与生物分子间相互作用模式之间的深层相关性变得困难。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提供一种从黑盒预测到机制解码的完整解决方案，以发现药物靶点。&lt;h4&gt;方法&lt;/h4&gt;该框架的技术突破主要体现在以下三个方面：1. 设计了基于异构图卷积神经网络（HGCN）的多阶邻域聚合策略；2. 提出了多尺度图信号分解和生物解释模块；3. 结合多维度视角和层次表示的对比学习，通过比较学习模型，将HGCN和GWT两个视角的节点表示对齐和融合，使模型能够整合多维度信息并提高预测鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在所有数据集上均表现出优异的预测性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为药物靶点发现提供了一种完整的解决方案，其方法论对于建模复杂的生物分子相互作用系统具有重要参考价值。&lt;h4&gt;翻译&lt;/h4&gt;This study proposes a heterogeneous network drug target interaction prediction framework, integrating graph neural network and multi scale signal processing technology to construct a model with both efficient prediction and multi level interpretability. The technical breakthroughs are mainly reflected in the following three dimensions: Local global feature collaborative perception module based on Heterogeneous Graph Convolutional Neural Network (HGCN), multi scale graph signal decomposition and biological interpretation module, and contrastive learning combining multi dimensional perspectives and hierarchical representations. The experimental results show that our framework shows excellent prediction performance on all datasets. This study provides a complete solution for drug target discovery from black box prediction to mechanism decoding, and its methodology has important reference value for modeling complex biomolecular interaction systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug-target interaction (DTI) prediction is a core task in drug developmentand precision medicine in the biomedical field. However, traditional machinelearning methods generally have the black box problem, which makes it difficultto reveal the deep correlation between the model decision mechanism and theinteraction pattern between biological molecules. This study proposes aheterogeneous network drug target interaction prediction framework, integratinggraph neural network and multi scale signal processing technology to constructa model with both efficient prediction and multi level interpretability. Itstechnical breakthroughs are mainly reflected in the following threedimensions:Local global feature collaborative perception module. Based onheterogeneous graph convolutional neural network (HGCN), a multi order neighboraggregation strategy is designed.Multi scale graph signal decomposition andbiological interpretation module. A deep hierarchical node feature transform(GWT) architecture is proposed.Contrastive learning combining multi dimensionalperspectives and hierarchical representations. By comparing the learningmodels, the node representations from the two perspectives of HGCN and GWT arealigned and fused, so that the model can integrate multi dimensionalinformation and improve the prediction robustness. Experimental results showthat our framework shows excellent prediction performance on all datasets. Thisstudy provides a complete solution for drug target discovery from black boxprediction to mechanism decoding, and its methodology has important referencevalue for modeling complex biomolecular interaction systems.</description>
      <author>example@mail.com (Wenfeng Dai, Yanhong Wang, Shuai Yan, Qingzhi Yu, Xiang Cheng)</author>
      <guid isPermaLink="false">2504.20103v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Attention to Detail: Fine-Scale Feature Preservation-Oriented Geometric Pre-training for AI-Driven Surrogate Modeling</title>
      <link>http://arxiv.org/abs/2504.20110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自监督几何表示学习方法，用于从非参数3D模型中捕捉精细几何特征，以支持数据稀缺场景下的代理建模。&lt;h4&gt;背景&lt;/h4&gt;AI驱动的代理建模正成为3D设计、分析和制造中替代基于物理模拟的有效方法，但这些方法通常需要大量的标记CAD到模拟数据集。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够捕捉精细几何特征的自监督几何表示学习方法，以支持需要精细几何细节的复杂应用。&lt;h4&gt;方法&lt;/h4&gt;该方法将几何特征提取与下游物理任务解耦，通过几何重建损失来学习一个潜在空间嵌入。它使用近零级采样和创新的批量自适应注意力加权损失函数，以增强对复杂设计特征的编码。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在结构力学案例研究中得到了验证，表现出在捕捉设计特征和实现准确的少样本物理预测方面的强大性能。&lt;h4&gt;结论&lt;/h4&gt;与传统参数化代理建模相比，该方法有望弥合几何和基于物理的表示之间的差距，为数据稀缺场景下的代理建模提供有效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;AI驱动的代理建模已经成为3D设计、分析和制造中替代基于物理模拟的有效方法。这些模型利用数据驱动的方法来预测通常需要计算昂贵的模拟的物理量。然而，标记的CAD到模拟数据集的稀缺推动了自监督和基础模型最近的进步，其中几何表示学习是在线进行的，然后针对特定的下游任务进行微调。尽管这些方法显示出希望，但它们在需要精细尺度几何细节保留的应用中效果有限。这项工作介绍了一种自监督几何表示学习方法，旨在从非参数3D模型中捕获精细几何特征。与传统的端到端代理模型不同，这种方法将几何特征提取与下游物理任务解耦，通过几何重建损失学习一个潜在空间嵌入。关键元素包括近零级采样的基本使用和创新的批量自适应注意力加权损失函数，这些函数增强了复杂设计特征的编码。该方法通过结构力学案例研究得到了验证，证明了在捕捉设计特征和实现准确的少样本物理预测方面的强大性能。与传统参数化代理建模的比较突出了其弥合几何和基于物理表示之间差距的潜力，为数据稀缺场景下的代理建模提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AI-driven surrogate modeling has become an increasingly effective alternativeto physics-based simulations for 3D design, analysis, and manufacturing. Thesemodels leverage data-driven methods to predict physical quantitiestraditionally requiring computationally expensive simulations. However, thescarcity of labeled CAD-to-simulation datasets has driven recent advancementsin self-supervised and foundation models, where geometric representationlearning is performed offline and later fine-tuned for specific downstreamtasks. While these approaches have shown promise, their effectiveness islimited in applications requiring fine-scale geometric detail preservation.This work introduces a self-supervised geometric representation learning methoddesigned to capture fine-scale geometric features from non-parametric 3Dmodels. Unlike traditional end-to-end surrogate models, this approach decouplesgeometric feature extraction from downstream physics tasks, learning a latentspace embedding guided by geometric reconstruction losses. Key elements includethe essential use of near-zero level sampling and the innovative batch-adaptiveattention-weighted loss function, which enhance the encoding of intricatedesign features. The proposed method is validated through case studies instructural mechanics, demonstrating strong performance in capturing designfeatures and enabling accurate few-shot physics predictions. Comparisons withtraditional parametric surrogate modeling highlight its potential to bridge thegap between geometric and physics-based representations, providing an effectivesolution for surrogate modeling in data-scarce scenarios.</description>
      <author>example@mail.com (Yu-hsuan Chen, Jing Bi, Cyril Ngo Ngoc, Victor Oancea, Jonathan Cagan, Levent Burak Kara)</author>
      <guid isPermaLink="false">2504.20110v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Decoding Latent Spaces: Assessing the Interpretability of Time Series Foundation Models for Visual Analytics</title>
      <link>http://arxiv.org/abs/2504.20099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Currently under review at the International Journal of Interactive  Multimedia and Artificial Intelligence (IJIMAI)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了时间序列基础模型产生的潜在空间的可解释性，重点关注其在视觉分析任务中的潜力。&lt;h4&gt;背景&lt;/h4&gt;该研究评估了MOMENT系列模型，这是一组基于Transformer的预训练架构，用于处理多元时间序列任务，如数据插补、预测、分类和异常检测。&lt;h4&gt;目的&lt;/h4&gt;研究旨在评估这些模型在五个数据集上的能力，以捕捉时间序列数据在其潜在空间投影中的底层结构，并验证微调是否可以改善结果嵌入空间的清晰度。&lt;h4&gt;方法&lt;/h4&gt;研究人员对MOMENT模型进行了评估，并进行了微调以观察性能改进，同时进行了可视化分析以评估嵌入的可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;微调后观察到损失减少方面的显著性能提升。可视化分析显示，嵌入的可解释性改善有限，需要进一步研究。&lt;h4&gt;结论&lt;/h4&gt;尽管MOMENT等时间序列基础模型稳健，但其潜在空间可能需要额外的方法论改进才能得到充分解释，例如替代投影技术、损失函数或数据预处理策略。尽管MOMENT存在局限性，但基础模型在执行时间上提供了大幅减少，这对于交互式可视化分析是一个重大进步。&lt;h4&gt;翻译&lt;/h4&gt;The present study explores the interpretability of latent spaces produced by time series foundation models, focusing on their potential for visual analysis tasks. Specifically, we evaluate the MOMENT family of models, a set of transformer-based, pre-trained architectures for multivariate time series tasks such as: imputation, prediction, classification, and anomaly detection. We evaluate the capacity of these models on five datasets to capture the underlying structures in time series data within their latent space projection and validate whether fine tuning improves the clarity of the resulting embedding spaces. Notable performance improvements in terms of loss reduction were observed after fine tuning. Visual analysis shows limited improvement in the interpretability of the embeddings, requiring further work. Results suggest that, although Time Series Foundation Models such as MOMENT are robust, their latent spaces may require additional methodological refinements to be adequately interpreted, such as alternative projection techniques, loss functions, or data preprocessing strategies. Despite the limitations of MOMENT, foundation models supose a big reduction in execution time and so a great advance for interactive visual analytics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The present study explores the interpretability of latent spaces produced bytime series foundation models, focusing on their potential for visual analysistasks. Specifically, we evaluate the MOMENT family of models, a set oftransformer-based, pre-trained architectures for multivariate time series taskssuch as: imputation, prediction, classification, and anomaly detection. Weevaluate the capacity of these models on five datasets to capture theunderlying structures in time series data within their latent space projectionand validate whether fine tuning improves the clarity of the resultingembedding spaces. Notable performance improvements in terms of loss reductionwere observed after fine tuning. Visual analysis shows limited improvement inthe interpretability of the embeddings, requiring further work. Results suggestthat, although Time Series Foundation Models such as MOMENT are robust, theirlatent spaces may require additional methodological refinements to beadequately interpreted, such as alternative projection techniques, lossfunctions, or data preprocessing strategies. Despite the limitations of MOMENT,foundation models supose a big reduction in execution time and so a greatadvance for interactive visual analytics.</description>
      <author>example@mail.com (Inmaculada Santamaria-Valenzuela, Victor Rodriguez-Fernandez, Javier Huertas-Tato, Jong Hyuk Park, David Camacho)</author>
      <guid isPermaLink="false">2504.20099v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>HyboWaveNet: Hyperbolic Graph Neural Networks with Multi-Scale Wavelet Transform for Protein-Protein Interaction Prediction</title>
      <link>http://arxiv.org/abs/2504.20102v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为HyboWaveNet的深度学习框架，用于蛋白质-蛋白质相互作用（PPI）的预测，该框架结合了双曲图神经网络和多尺度图小波变换，以解决现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;蛋白质-蛋白质相互作用对于理解细胞功能、疾病途径和药物发现至关重要。现有方法在PPI预测方面虽然准确，但缺乏可解释性和难以捕捉蛋白质之间的层次几何和动态相互作用模式。&lt;h4&gt;目的&lt;/h4&gt;提出HyboWaveNet以解决现有PPI预测方法的局限性，提高预测结果的因果解释性和对多尺度动态相互作用模式的捕捉能力。&lt;h4&gt;方法&lt;/h4&gt;HyboWaveNet通过将蛋白质特征映射到洛伦兹空间，利用双曲距离度量模拟生物分子之间的层次拓扑关系。它结合了图神经网络和图小波变换，以自适应地提取不同分辨率下的局部和全局交互特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，HyboWaveNet在公共数据集上优于现有方法，并且多尺度图小波变换模块提高了HyboWaveNet的预测性能和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;HyboWaveNet将几何深度学习和信号处理相结合，为分析复杂生物系统提供了一种原则性的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Protein-protein interactions (PPIs) are fundamental for deciphering cellularfunctions,disease pathways,and drug discovery.Although existing neural networksand machine learning methods have achieved high accuracy in PPIprediction,their black-box nature leads to a lack of causal interpretation ofthe prediction results and difficulty in capturing hierarchical geometries andmulti-scale dynamic interaction patterns among proteins.To address thesechallenges, we propose HyboWaveNet,a novel deep learning framework thatcollaborates with hyperbolic graphical neural networks (HGNNs) and multiscalegraphical wavelet transform for robust PPI prediction. Mapping protein featuresto Lorentz space simulates hierarchical topological relationships amongbiomolecules via a hyperbolic distance metric,enabling node featurerepresentations that better fit biological a priori.HyboWaveNet inherentlysimulates hierarchical and scale-free biological relationships, while theintegration of wavelet transforms enables adaptive extraction of local andglobal interaction features across different resolutions. Our frameworkgenerates node feature representations via a graph neural network under theLorenz model and generates pairs of positive samples under multiple differentviews for comparative learning, followed by further feature extraction viamulti-scale graph wavelet transforms to predict potential PPIs. Experiments onpublic datasets show that HyboWaveNet improves over both existingstate-of-the-art methods. We also demonstrate through ablation experimentalstudies that the multi-scale graph wavelet transform module improves thepredictive performance and generalization ability of HyboWaveNet. This worklinks geometric deep learning and signal processing to advance PPI prediction,providing a principled approach for analyzing complex biological systems</description>
      <author>example@mail.com (Qingzhi Yu, Shuai Yan, Wenfeng Dai, Xiang Cheng)</author>
      <guid isPermaLink="false">2504.20102v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Perception Encoder: The best visual embeddings are not at the output of the network</title>
      <link>http://arxiv.org/abs/2504.13181v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Updated refs, fixed typos, and added new COCO SotA: 66.0 val mAP!  Code, models, and data at  https://github.com/facebookresearch/perception_models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为感知编码器（PE）的先进视觉编码器，用于图像和视频理解。通过简单的视觉-语言学习进行训练，该编码器在多种下游任务上表现出色。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉编码器依赖于多种预训练目标，针对分类、字幕或定位等特定任务进行优化。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够通过简单的视觉-语言学习训练，并在多个下游任务上取得优异表现的视觉编码器。&lt;h4&gt;方法&lt;/h4&gt;采用精心调整的图像预训练食谱和强大的视频数据引擎进行训练，并通过语言对齐和空间对齐两种方法提取隐藏在中间层的嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;对比视觉-语言训练单独就能产生强大的通用嵌入，适用于多种下游任务。PE系列模型在多种任务上达到最佳水平，包括零样本图像和视频分类与检索，文档、图像和视频问答，以及空间任务如检测、跟踪和深度估计。&lt;h4&gt;结论&lt;/h4&gt;PE系列模型在多个视觉理解任务上取得了最先进的成果，并发布了相关模型、代码和新型数据集。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为感知编码器（PE）的先进视觉编码器，用于图像和视频理解。通过简单的视觉-语言学习进行训练，该编码器在多种下游任务上表现出色。传统的视觉编码器依赖于多种预训练目标，针对分类、字幕或定位等特定任务进行优化。本文的目的是开发一种能够通过简单的视觉-语言学习训练，并在多个下游任务上取得优异表现的视觉编码器。采用精心调整的图像预训练食谱和强大的视频数据引擎进行训练，并通过语言对齐和空间对齐两种方法提取隐藏在中间层的嵌入。研究发现，对比视觉-语言训练单独就能产生强大的通用嵌入，适用于多种下游任务。PE系列模型在多种任务上达到最佳水平，包括零样本图像和视频分类与检索，文档、图像和视频问答，以及空间任务如检测、跟踪和深度估计。结论是，PE系列模型在多个视觉理解任务上取得了最先进的成果，并发布了相关模型、代码和新型数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Perception Encoder (PE), a state-of-the-art vision encoder forimage and video understanding trained via simple vision-language learning.Traditionally, vision encoders have relied on a variety of pretrainingobjectives, each tailored to specific downstream tasks such as classification,captioning, or localization. Surprisingly, after scaling our carefully tunedimage pretraining recipe and refining with our robust video data engine, wefind that contrastive vision-language training alone can produce strong,general embeddings for all of these downstream tasks. There is only one caveat:these embeddings are hidden within the intermediate layers of the network. Todraw them out, we introduce two alignment methods: language alignment formultimodal language modeling, and spatial alignment for dense prediction.Together, our PE family of models achieves best-in-class results on a widevariety of tasks, including (1) zero-shot image and video classification andretrieval, simultaneously obtaining 86.6 average zero-shot ImageNet robustnessand 76.9 zero-shot Kinetics-400 video classification; (2) document, image, andvideo Q&amp;A, enabling 94.6 DocVQA, 80.9 InfographicVQA, and 82.7 PerceptionTestwith an 8B LLM; and (3) spatial tasks such as detection, tracking, and depthestimation, setting a new COCO state-of-the-art of 66.0 box mAP. To fosterfurther research, we release our models, code, and novel dataset ofsynthetically and human-annotated videos:https://github.com/facebookresearch/perception_models</description>
      <author>example@mail.com (Daniel Bolya, Po-Yao Huang, Peize Sun, Jang Hyun Cho, Andrea Madotto, Chen Wei, Tengyu Ma, Jiale Zhi, Jathushan Rajasegaran, Hanoona Rasheed, Junke Wang, Marco Monteiro, Hu Xu, Shiyu Dong, Nikhila Ravi, Daniel Li, Piotr Dollár, Christoph Feichtenhofer)</author>
      <guid isPermaLink="false">2504.13181v2</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>QuickGrasp: Lightweight Antipodal Grasp Planning with Point Clouds</title>
      <link>http://arxiv.org/abs/2504.19716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种轻量级的解析方法，用于机器人抓取规划，特别是针对抗对称抓取，这种方法在六自由度空间中几乎不进行采样。&lt;h4&gt;背景&lt;/h4&gt;抓取一直是机器人与环境之间最终接口的一个长期挑战。随着环境和任务的复杂化，嵌入更高智能以从周围环境中推断并对其采取行动的需求变得必要。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决现有抓取规划方法在现实生活中的泛化能力差、生成抓取计划所需时间过长以及缺乏可重复性等问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于优化的抓取规划算法，通过在物体表面上估计抓取点来解决问题，而不是直接估计末端执行器的位置。此外，提出了一种软区域生长算法，用于有效分割平面，即使在曲面上也能有效工作。&lt;h4&gt;主要发现&lt;/h4&gt;该抓取框架在多个模拟物体上与现有的抓取规划方法Grasp Pose Detection (GPD)进行了比较，并使用图像和点云数据在现实世界中进行了评估，结果显示了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;与GPD相比，本文提出的方法在模拟和现实世界的抓取规划中表现出更高的效率和质量。&lt;h4&gt;翻译&lt;/h4&gt;摘要：抓取一直是机器人与环境之间最终接口的一个长期挑战。随着环境和任务的复杂化，嵌入更高智能以从周围环境中推断并对其采取行动的需求变得必要。尽管大多数方法利用技术来通过在六自由度空间中采用纯采样方法或作为学习问题来处理估计抓取位姿的问题，但它们通常由于跨领域泛化能力差而在现实生活中的设置中失败。此外，由于采样效率低下和现有抓取规划方法的概率性质，生成抓取计划所需的时间以及缺乏可重复性严重限制了它们在现实世界任务中的应用。本文提出了一种轻量级的解析方法，用于机器人抓取规划，特别是抗对称抓取，这种方法在六自由度空间中几乎不进行采样。所提出的抓取规划算法被表述为一个优化问题，用于估计物体表面上的抓取点，而不是直接估计末端执行器的位置。为此，提出了一种软区域生长算法，用于有效分割平面，即使在曲面上也能有效工作。然后使用基于优化的质量指标来评估抓取点，以确保间接力闭合。所提出的抓取框架与现有的最先进的抓取规划方法Grasp Pose Detection (GPD)在多个模拟物体上进行了比较，作为一个基线。与GPD相比，本文提出的方法在模拟和现实世界的抓取规划中表现出更高的效率和质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasping has been a long-standing challenge in facilitating the finalinterface between a robot and the environment. As environments and tasks becomecomplicated, the need to embed higher intelligence to infer from thesurroundings and act on them has become necessary. Although most methodsutilize techniques to estimate grasp pose by treating the problem via puresampling-based approaches in the six-degree-of-freedom space or as a learningproblem, they usually fail in real-life settings owing to poor generalizationacross domains. In addition, the time taken to generate the grasp plan and thelack of repeatability, owing to sampling inefficiency and the probabilisticnature of existing grasp planning approaches, severely limits their applicationin real-world tasks. This paper presents a lightweight analytical approachtowards robotic grasp planning, particularly antipodal grasps, with little tono sampling in the six-degree-of-freedom space. The proposed grasp planningalgorithm is formulated as an optimization problem towards estimating grasppoints on the object surface instead of directly estimating the end-effectorpose. To this extent, a soft-region-growing algorithm is presented foreffective plane segmentation, even in the case of curved surfaces. Anoptimization-based quality metric is then used for the evaluation of grasppoints to ensure indirect force closure. The proposed grasp framework iscompared with the existing state-of-the-art grasp planning approach, Grasp posedetection (GPD), as a baseline over multiple simulated objects. Theeffectiveness of the proposed approach in comparison to GPD is also evaluatedin a real-world setting using image and point-cloud data, with the plannedgrasps being executed using a ROBOTIQ gripper and UR5 manipulator.</description>
      <author>example@mail.com (Navin Sriram Ravie, Keerthi Vasan M, Asokan Thondiyath, Bijo Sebastian)</author>
      <guid isPermaLink="false">2504.19716v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
  <item>
      <title>WLTCL: Wide Field-of-View 3-D LiDAR Truck Compartment Automatic Localization System</title>
      <link>http://arxiv.org/abs/2504.18870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in IEEE TIM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种创新的宽视场3D激光雷达车辆舱自动定位系统，以提高物流自动化中的操作效率和安全性。&lt;h4&gt;背景&lt;/h4&gt;自动化装载系统是物流自动化的重要组成部分，但在不同尺寸的货车舱中进行精确自动定位存在挑战，包括适应性、统一坐标系和可靠性问题。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有方法的局限性，实现大、中、小尺寸围栏式货车舱在杂乱环境中的关键点精确自动定位。&lt;h4&gt;方法&lt;/h4&gt;提出了一种利用LiDAR生成宽视场范围内高密度点云的方法，结合停车区域约束进行车辆点云分割，以及利用货车舱的几何特征进行关键点定位。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该系统具有可靠的定位精度和降低的计算资源消耗。&lt;h4&gt;结论&lt;/h4&gt;该系统能够应用于相关领域，提升物流自动化水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As an essential component of logistics automation, the automated loadingsystem is becoming a critical technology for enhancing operational efficiencyand safety. Precise automatic positioning of the truck compartment, whichserves as the loading area, is the primary step in automated loading. However,existing methods have difficulty adapting to truck compartments of varioussizes, do not establish a unified coordinate system for LiDAR and mobilemanipulators, and often exhibit reliability issues in cluttered environments.To address these limitations, our study focuses on achieving precise automaticpositioning of key points in large, medium, and small fence-style truckcompartments in cluttered scenarios. We propose an innovative widefield-of-view 3-D LiDAR vehicle compartment automatic localization system. Forvehicles of various sizes, this system leverages the LiDAR to generatehigh-density point clouds within an extensive field-of-view range. Byincorporating parking area constraints, our vehicle point cloud segmentationmethod more effectively segments vehicle point clouds within the scene. Ourcompartment key point positioning algorithm utilizes the geometric features ofthe compartments to accurately locate the corner points, providing stackablespatial regions. Extensive experiments on our collected data and publicdatasets demonstrate that this system offers reliable positioning accuracy andreduced computational resource consumption, leading to its application andpromotion in relevant fields.</description>
      <author>example@mail.com (Guodong Sun, Mingjing Li, Dingjie Liu, Mingxuan Liu, Bo Wu, Yang Zhang)</author>
      <guid isPermaLink="false">2504.18870v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning</title>
      <link>http://arxiv.org/abs/2504.20024v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://spatial-reasoner.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为SpatialReasoner的新颖的大视觉语言模型（LVLM），用于解决3D空间推理问题，并通过显式的3D表示在3D感知、计算和推理阶段之间共享，从而提高了空间推理的性能，并研究了LVLM在3D空间推理中可能出现的错误。&lt;h4&gt;背景&lt;/h4&gt;近期研究探索了基于数据驱动的3D空间推理方法，并使用强化学习（RL）实现了空间推理性能的提升。然而，这些方法通常以隐式的方式进行空间推理，且未充分研究在训练过程中获得的3D知识是否能够泛化到未见过的问答类型。&lt;h4&gt;目的&lt;/h4&gt;提出SpatialReasoner模型，旨在通过显式的3D表示来增强3D空间推理，并研究LVLM在3D空间推理中可能出现的错误。&lt;h4&gt;方法&lt;/h4&gt;SpatialReasoner模型采用了大视觉语言模型，并在3D感知、计算和推理阶段之间共享显式的3D表示，以支持高级3D空间推理。&lt;h4&gt;主要发现&lt;/h4&gt;SpatialReasoner在多种空间推理基准测试中实现了改进的性能，并且在评估新颖的3D空间推理问题时表现出更好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究将先前视觉基础模型的3D解析能力与大型语言模型的强大推理能力相结合，为3D空间推理开辟了新的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;Recent studies in 3D spatial reasoning explore data-driven approaches and achieve enhanced spatial reasoning performance with reinforcement learning (RL). However, these methods typically perform spatial reasoning in an implicit manner, and it remains underexplored whether the acquired 3D knowledge generalizes to unseen question types at any stage of the training. In this work we introduce SpatialReasoner, a novel large vision-language model (LVLM) that address 3D spatial reasoning with explicit 3D representations shared between stages -- 3D perception, computation, and reasoning. Explicit 3D representations provide a coherent interface that supports advanced 3D spatial reasoning and enable us to study the factual errors made by LVLMs. Results show that our SpatialReasoner achieve improved performance on a variety of spatial reasoning benchmarks and generalizes better when evaluating on novel 3D spatial reasoning questions. Our study bridges the 3D parsing capabilities of prior visual foundation models with the powerful reasoning abilities of large language models, opening new directions for 3D spatial reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies in 3D spatial reasoning explore data-driven approaches andachieve enhanced spatial reasoning performance with reinforcement learning(RL). However, these methods typically perform spatial reasoning in an implicitmanner, and it remains underexplored whether the acquired 3D knowledgegeneralizes to unseen question types at any stage of the training. In this workwe introduce SpatialReasoner, a novel large vision-language model (LVLM) thataddress 3D spatial reasoning with explicit 3D representations shared betweenstages -- 3D perception, computation, and reasoning. Explicit 3Drepresentations provide a coherent interface that supports advanced 3D spatialreasoning and enable us to study the factual errors made by LVLMs. Results showthat our SpatialReasoner achieve improved performance on a variety of spatialreasoning benchmarks and generalizes better when evaluating on novel 3D spatialreasoning questions. Our study bridges the 3D parsing capabilities of priorvisual foundation models with the powerful reasoning abilities of largelanguage models, opening new directions for 3D spatial reasoning.</description>
      <author>example@mail.com (Wufei Ma, Yu-Cheng Chou, Qihao Liu, Xingrui Wang, Celso de Melo, Jieneng Chen, Jianwen Xie, Alan Yuille)</author>
      <guid isPermaLink="false">2504.20024v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Taming the Randomness: Towards Label-Preserving Cropping in Contrastive Learning</title>
      <link>http://arxiv.org/abs/2504.19824v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了对比学习（CL）在自监督学习（SSL）中的应用，提出了一种新的参数化裁剪方法，以提高自标签的鲁棒性和模型性能。&lt;h4&gt;背景&lt;/h4&gt;自监督学习（SSL）在深度学习，特别是计算机视觉（CV）领域，通过利用大量未标记数据来促进学习，对比学习（CL）是SSL方法中的一个成功分支。&lt;h4&gt;目的&lt;/h4&gt;为了提高自标签的鲁棒性和模型在下游任务中的准确性。&lt;h4&gt;方法&lt;/h4&gt;引入了两种新的参数化裁剪方法，并与非参数化的随机裁剪方法进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，使用这些方法在CIFAR-10分类任务上，模型的准确性提高了2.7%到12.4%，具体取决于裁剪大小。&lt;h4&gt;结论&lt;/h4&gt;提出的参数化裁剪方法能够有效提高对比学习在自监督学习中的应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning (CL) approaches have gained great recognition as a verysuccessful subset of self-supervised learning (SSL) methods. SSL enableslearning from unlabeled data, a crucial step in the advancement of deeplearning, particularly in computer vision (CV), given the plethora of unlabeledimage data. CL works by comparing different random augmentations (e.g.,different crops) of the same image, thus achieving self-labeling. Nevertheless,randomly augmenting images and especially random cropping can result in animage that is semantically very distant from the original and therefore leadsto false labeling, hence undermining the efficacy of the methods. In thisresearch, two novel parameterized cropping methods are introduced that increasethe robustness of self-labeling and consequently increase the efficacy. Theresults show that the use of these methods significantly improves the accuracyof the model by between 2.7\% and 12.4\% on the downstream task of classifyingCIFAR-10, depending on the crop size compared to that of the non-parameterizedrandom cropping method.</description>
      <author>example@mail.com (Mohamed Hassan, Mohammad Wasil, Sebastian Houben)</author>
      <guid isPermaLink="false">2504.19824v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Category-Level and Open-Set Object Pose Estimation for Robotics</title>
      <link>http://arxiv.org/abs/2504.19572v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Austrian Robotics Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文比较了用于解决类别级6D姿态估计的算法、数据集和精度指标，并分析了如何将类别级和开放集对象姿态估计连接起来以实现泛化，并提供有针对性的建议。&lt;h4&gt;背景&lt;/h4&gt;对象姿态估计在计算机视觉和机器人学中扮演重要角色，但类别级和开放集方法在处理未知纹理、形状和大小等基本材料属性时存在挑战。&lt;h4&gt;目的&lt;/h4&gt;比较不同方法在类别级6D姿态估计中的表现，并分析如何实现泛化。&lt;h4&gt;方法&lt;/h4&gt;本文通过比较不同的数据集、精度指标和算法，对类别级6D姿态估计进行了研究。&lt;h4&gt;主要发现&lt;/h4&gt;类别级和开放集对象姿态估计面临复杂性和不确定性，需要多种数据集、精度指标和算法解决方案。&lt;h4&gt;结论&lt;/h4&gt;研究提供了将类别级和开放集对象姿态估计连接起来的方法，以实现更广泛的泛化，并为实际应用提供指导。&lt;h4&gt;翻译&lt;/h4&gt;摘要：对象姿态估计在计算机视觉和机器人学中能够实现多种任务，包括场景理解和机器人抓取。姿态估计任务的复杂性取决于与目标对象相关的未知变量。尽管实例级方法在处理不透明和朗伯物体方面已经表现出色，但类别级和开放集方法（其中纹理、形状和大小部分或全部未知）在这些基本材料属性上仍然存在困难。在这些场景中，由于纹理未知，无法用于区分对象对称性，这是6D对象姿态估计的另一个核心挑战。估计具有如此众多未知因素的6D姿态的复杂性导致了各种数据集、精度指标和算法解决方案的出现。本文比较了用于解决类别级6D姿态估计的算法、数据集和精度指标。基于这种比较，我们分析了如何将类别级和开放集对象姿态估计连接起来以实现泛化，并提供有针对性的建议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object pose estimation enables a variety of tasks in computer vision androbotics, including scene understanding and robotic grasping. The complexity ofa pose estimation task depends on the unknown variables related to the targetobject. While instance-level methods already excel for opaque and Lambertianobjects, category-level and open-set methods, where texture, shape, and sizeare partially or entirely unknown, still struggle with these basic materialproperties. Since texture is unknown in these scenarios, it cannot be used fordisambiguating object symmetries, another core challenge of 6D object poseestimation. The complexity of estimating 6D poses with such a manifold ofunknowns led to various datasets, accuracy metrics, and algorithmic solutions.This paper compares datasets, accuracy metrics, and algorithms for solving 6Dpose estimation on the category-level. Based on this comparison, we analyze howto bridge category-level and open-set object pose estimation to reachgeneralization and provide actionable recommendations.</description>
      <author>example@mail.com (Peter Hönig, Matthias Hirschmanner, Markus Vincze)</author>
      <guid isPermaLink="false">2504.19572v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network Prediction of Nonlinear Optical Properties</title>
      <link>http://arxiv.org/abs/2504.19987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 2 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了非线性光学材料，通过深度学习技术预测其非线性光学性质，以加速新型光学材料的发现和设计。&lt;h4&gt;背景&lt;/h4&gt;非线性光学材料在激光生成领域有广泛应用，但发现具有显著二次谐波产生（SHG）性质的新材料困难重重，因为实验和理论计算耗时且成本高昂。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于深度学习的方法，使用原子线图神经网络（ALIGNN）预测非线性光学材料的性质，以加快新型光学材料的发现和设计。&lt;h4&gt;方法&lt;/h4&gt;从新型光电材料发现数据库（NOEMD）中获取数据，以库尔特斯-佩里（KP）系数作为关键目标，构建了一个鲁棒的模型，该模型能够准确估计非线性光学响应。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在可接受的绝对误差不超过1 pm/V和相对误差不超过0.5的条件下，实现了82.5%的准确率。&lt;h4&gt;结论&lt;/h4&gt;这项工作突出了深度学习在加速具有所需特性的先进光学材料发现和设计中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This abstract is a summary of a study that uses deep learning to predict nonlinear optical properties of materials for laser generation. The research aims to accelerate the discovery and design of new optical materials. Data from the NOEMD database is used, and the Kurtz-Perry coefficient is targeted. The model achieves high accuracy and highlights the potential of deep learning in this field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nonlinear optical (NLO) materials for generating lasers via second harmonicgeneration (SHG) are highly sought in today's technology. However, discoveringnovel materials with considerable SHG is challenging due to the time-consumingand costly nature of both experimental methods and first-principlescalculations. In this study, we present a deep learning approach using theAtomistic Line Graph Neural Network (ALIGNN) to predict NLO properties.Sourcing data from the Novel Opto-Electronic Materials Discovery (NOEMD)database and using the Kurtz-Perry (KP) coefficient as the key target, wedeveloped a robust model capable of accurately estimating nonlinear opticalresponses. Our results demonstrate that the model achieves 82.5% accuracy at atolerated absolute error up to 1 pm/V and relative error not exceeding 0.5.This work highlights the potential of deep learning in accelerating thediscovery and design of advanced optical materials with desired properties.</description>
      <author>example@mail.com (Yomn Alkabakibi, Congwei Xie, Artem R. Oganov)</author>
      <guid isPermaLink="false">2504.19987v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models</title>
      <link>http://arxiv.org/abs/2504.20020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为模块化机器学习（MML）的新颖学习范式，旨在解决大型语言模型（LLMs）在推理、事实一致性和可解释性方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;尽管LLMs在自然语言处理、计算机视觉、数据挖掘等领域推动了机器学习研究，但它们在推理、事实一致性和可解释性方面仍存在关键局限性。&lt;h4&gt;目的&lt;/h4&gt;通过引入MML，旨在增强LLMs的逆事实推理能力、减轻幻觉现象，并促进公平性、安全性和透明度。&lt;h4&gt;方法&lt;/h4&gt;MML将LLMs的复杂结构分解为三个相互依存的组件：模块化表示、模块化模型和模块化推理。通过使用解耦表示学习、神经架构搜索和神经符号学习等技术实现MML。&lt;h4&gt;主要发现&lt;/h4&gt;MML范式可以：1）通过解耦语义组件来阐明LLMs的内部工作机制；2）允许灵活且适应任务的模型设计；3）实现可解释且基于逻辑的决策过程。&lt;h4&gt;结论&lt;/h4&gt;MML与LLMs的结合有望弥合统计（深度）学习和形式（逻辑）推理之间的差距，为广泛实际应用中的稳健、适应性强和值得信赖的AI系统铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;Large language models (LLMs) have dramatically advanced machine learning research including natural language processing, computer vision, data mining, etc., yet they still exhibit critical limitations in reasoning, factual consistency, and interpretability. In this paper, we introduce a novel learning paradigm -- Modular Machine Learning (MML) -- as an essential approach toward new-generation LLMs. MML decomposes the complex structure of LLMs into three interdependent components: modular representation, modular model, and modular reasoning, aiming to enhance LLMs' capability of counterfactual reasoning, mitigating hallucinations, as well as promoting fairness, safety, and transparency. Specifically, the proposed MML paradigm can: i) clarify the internal working mechanism of LLMs through the disentanglement of semantic components; ii) allow for flexible and task-adaptive model design; iii) enable interpretable and logic-driven decision-making process. We present a feasible implementation of MML-based LLMs via leveraging advanced techniques such as disentangled representation learning, neural architecture search and neuro-symbolic learning. We critically identify key challenges, such as the integration of continuous neural and discrete symbolic processes, joint optimization, and computational scalability, present promising future research directions that deserve further exploration. Ultimately, the integration of the MML paradigm with LLMs has the potential to bridge the gap between statistical (deep) learning and formal (logical) reasoning, thereby paving the way for robust, adaptable, and trustworthy AI systems across a wide range of real-world applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have dramatically advanced machine learningresearch including natural language processing, computer vision, data mining,etc., yet they still exhibit critical limitations in reasoning, factualconsistency, and interpretability. In this paper, we introduce a novel learningparadigm -- Modular Machine Learning (MML) -- as an essential approach towardnew-generation LLMs. MML decomposes the complex structure of LLMs into threeinterdependent components: modular representation, modular model, and modularreasoning, aiming to enhance LLMs' capability of counterfactual reasoning,mitigating hallucinations, as well as promoting fairness, safety, andtransparency. Specifically, the proposed MML paradigm can: i) clarify theinternal working mechanism of LLMs through the disentanglement of semanticcomponents; ii) allow for flexible and task-adaptive model design; iii) enableinterpretable and logic-driven decision-making process. We present a feasibleimplementation of MML-based LLMs via leveraging advanced techniques such asdisentangled representation learning, neural architecture search andneuro-symbolic learning. We critically identify key challenges, such as theintegration of continuous neural and discrete symbolic processes, jointoptimization, and computational scalability, present promising future researchdirections that deserve further exploration. Ultimately, the integration of theMML paradigm with LLMs has the potential to bridge the gap between statistical(deep) learning and formal (logical) reasoning, thereby paving the way forrobust, adaptable, and trustworthy AI systems across a wide range of real-worldapplications.</description>
      <author>example@mail.com (Xin Wang, Haoyang Li, Zeyang Zhang, Haibo Chen, Wenwu Zhu)</author>
      <guid isPermaLink="false">2504.20020v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Uncertainty-Aware Graph Neural Network</title>
      <link>http://arxiv.org/abs/2504.19820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为HU-GNN的新型图神经网络架构，该架构通过统一多尺度表示学习、原理性不确定性估计和自监督嵌入多样性，有效缓解了数据稀疏性和利用结构属性。&lt;h4&gt;背景&lt;/h4&gt;近年来，图神经网络（GNNs）的研究探索了捕获局部不确定性和利用图层次结构来缓解数据稀疏性和利用结构属性的方法，但这两者之间的协同集成尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出HU-GNN的目的是为了解决上述问题，实现多尺度表示学习、不确定性估计和嵌入多样性的统一。&lt;h4&gt;方法&lt;/h4&gt;HU-GNN通过自适应形成节点簇，并在多个结构尺度上从单个节点到更高级别估计不确定性。这些不确定性估计引导了一个鲁棒的消息传递机制和注意力权重，从而有效缓解了噪声和对抗性扰动，同时保持了节点和图级别任务的预测精度。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出了概率公式、严格的不确定性校准保证和正式的鲁棒性界限等关键理论贡献。通过结合图对比学习的最新进展，HU-GNN保持了多样性和结构上忠实嵌入。&lt;h4&gt;结论&lt;/h4&gt;在标准基准上的大量实验表明，该模型实现了最先进的鲁棒性和可解释性。&lt;h4&gt;翻译&lt;/h4&gt;最近关于图神经网络（GNNs）的研究探讨了捕获局部不确定性和利用图层次结构来缓解数据稀疏性和利用结构属性的方法。然而，这两种方法的协同集成尚未得到充分探索。在本工作中，我们引入了一种新的架构，即分层不确定性感知图神经网络（HU-GNN），它在一个端到端的框架内统一了多尺度表示学习、原理性不确定性估计和自监督嵌入多样性。具体来说，HU-GNN自适应地形成节点簇，并从单个节点到更高级别估计多个结构尺度的不确定性。这些不确定性估计引导了一个鲁棒的消息传递机制和注意力权重，有效地缓解了噪声和对抗性扰动，同时在节点和图级别任务上保持了预测精度。我们还提供了关键的理论贡献，包括概率公式、严格的不确定性校准保证和正式的鲁棒性界限。最后，通过结合图对比学习的最新进展，HU-GNN保持了多样性和结构上忠实嵌入。在标准基准上的大量实验表明，我们的模型实现了最先进的鲁棒性和可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research on graph neural networks (GNNs) has explored mechanisms forcapturing local uncertainty and exploiting graph hierarchies to mitigate datasparsity and leverage structural properties. However, the synergisticintegration of these two approaches remains underexplored. In this work, weintroduce a novel architecture, the Hierarchical Uncertainty-Aware Graph NeuralNetwork (HU-GNN), which unifies multi-scale representation learning, principleduncertainty estimation, and self-supervised embedding diversity within a singleend-to-end framework. Specifically, HU-GNN adaptively forms node clusters andestimates uncertainty at multiple structural scales from individual nodes tohigher levels. These uncertainty estimates guide a robust message-passingmechanism and attention weighting, effectively mitigating noise and adversarialperturbations while preserving predictive accuracy on both node- andgraph-level tasks. We also offer key theoretical contributions, including aprobabilistic formulation, rigorous uncertainty-calibration guarantees, andformal robustness bounds. Finally, by incorporating recent advances in graphcontrastive learning, HU-GNN maintains diverse, structurally faithfulembeddings. Extensive experiments on standard benchmarks demonstrate that ourmodel achieves state-of-the-art robustness and interpretability.</description>
      <author>example@mail.com (Yoonhyuk Choi, Chong-Kwon Kim)</author>
      <guid isPermaLink="false">2504.19820v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>SAMBLE: Shape-Specific Point Cloud Sampling for an Optimal Trade-Off Between Local Detail and Global Uniformity</title>
      <link>http://arxiv.org/abs/2504.19581v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAMBLE的方法，用于学习特定形状的点云采样策略，以实现更精确和高效的3D数据表示。&lt;h4&gt;背景&lt;/h4&gt;随着对3D数据精确和高效表示的需求增加，点云采样已成为3D计算机视觉中的一个关键研究课题。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有学习型采样方法存在的问题，如产生不可识别的采样模式或偏置采样结果，同时忽略不同形状点分布的自然变化。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于稀疏注意力图和分箱的SAMBLE方法，用于学习特定形状的点云采样策略。&lt;h4&gt;主要发现&lt;/h4&gt;SAMBLE有效地在采样边缘点以获得局部细节和保持全局形状均匀性之间实现了平衡，在多个常见的点云下游任务中取得了优越的性能，即使在少数点采样的情况下也是如此。&lt;h4&gt;结论&lt;/h4&gt;SAMBLE方法能够显著提高点云采样在3D数据表示中的应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Driven by the increasing demand for accurate and efficient representation of3D data in various domains, point cloud sampling has emerged as a pivotalresearch topic in 3D computer vision. Recently, learning-to-sample methods havegarnered growing interest from the community, particularly for their ability tobe jointly trained with downstream tasks. However, previous learning-basedsampling methods either lead to unrecognizable sampling patterns by generatinga new point cloud or biased sampled results by focusing excessively on sharpedge details. Moreover, they all overlook the natural variations in pointdistribution across different shapes, applying a similar sampling strategy toall point clouds. In this paper, we propose a Sparse Attention Map andBin-based Learning method (termed SAMBLE) to learn shape-specific samplingstrategies for point cloud shapes. SAMBLE effectively achieves an improvedbalance between sampling edge points for local details and preservinguniformity in the global shape, resulting in superior performance acrossmultiple common point cloud downstream tasks, even in scenarios with few-pointsampling.</description>
      <author>example@mail.com (Chengzhi Wu, Yuxin Wan, Hao Fu, Julius Pfrommer, Zeyun Zhong, Junwei Zheng, Jiaming Zhang, Jürgen Beyerer)</author>
      <guid isPermaLink="false">2504.19581v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning Under High-Dimensional Network Convolutional Regression Model</title>
      <link>http://arxiv.org/abs/2504.19979v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于网络卷积回归（NCR）的高维迁移学习框架，用于解决网络数据中的依赖性问题，并通过仿真和真实世界应用验证了其在预测精度上的提升。&lt;h4&gt;背景&lt;/h4&gt;迁移学习通过利用相关领域的知识提升模型性能，特别是在标注数据稀缺的情况下。然而，现有研究主要关注独立设置下的分布变化，而处理网络数据中的依赖性仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种高维迁移学习框架，解决网络数据中的依赖性问题，并提高预测精度。&lt;h4&gt;方法&lt;/h4&gt;1. 基于网络卷积回归（NCR）模型，允许节点的响应依赖于其特征和邻居的聚合特征，有效捕获局部依赖性；2. 设计了两个步骤的迁移学习算法，处理源和目标网络之间的领域差异；3. 引入源检测机制来识别信息丰富的领域；4. 理论上分析基于Erdős-Rényi模型的随机图上的lasso估计器，证明在存在信息源时，迁移学习可以提高收敛速度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在预测精度上取得了显著提升，特别是在目标域的标注数据有限的情况下。&lt;h4&gt;结论&lt;/h4&gt;提出的NCR迁移学习框架能够有效处理网络数据中的依赖性，并显著提高预测精度，特别是在数据稀缺的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning enhances model performance by utilizing knowledge fromrelated domains, particularly when labeled data is scarce. While existingresearch addresses transfer learning under various distribution shifts inindependent settings, handling dependencies in networked data remainschallenging. To address this challenge, we propose a high-dimensional transferlearning framework based on network convolutional regression (NCR), inspired bythe success of graph convolutional networks (GCNs). The NCR model incorporatesrandom network structure by allowing each node's response to depend on itsfeatures and the aggregated features of its neighbors, capturing localdependencies effectively. Our methodology includes a two-step transfer learningalgorithm that addresses domain shift between source and target networks, alongwith a source detection mechanism to identify informative domains.Theoretically, we analyze the lasso estimator in the context of a random graphbased on the Erdos-Renyi model assumption, demonstrating that transfer learningimproves convergence rates when informative sources are present. Empiricalevaluations, including simulations and a real-world application using SinaWeibo data, demonstrate substantial improvements in prediction accuracy,particularly when labeled data in the target domain is limited.</description>
      <author>example@mail.com (Liyuan Wang, Jiachen Chen, Kathryn L. Lunetta, Danyang Huang, Huimin Cheng, Debarghya Mukherjee)</author>
      <guid isPermaLink="false">2504.19979v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Learning Streaming Video Representation via Multitask Training</title>
      <link>http://arxiv.org/abs/2504.20041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report. Project Page:  https://go2heart.github.io/streamformer&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了StreamFormer，一种新的流式视频处理框架，用于实时应用，如具身AI和自动驾驶。StreamFormer通过引入因果时序注意力机制，在预训练视觉Transformer中实现了高效的流式视频处理，同时保持了图像表示能力。&lt;h4&gt;背景&lt;/h4&gt;在实时应用中，理解连续视频流非常重要。与离线视频理解不同，流式视频理解需要逐帧处理视频流，保留历史信息，并做出低延迟决策。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决流式视频理解中的挑战，如高效处理视频流、保留历史信息和低延迟决策。&lt;h4&gt;方法&lt;/h4&gt;（i）开发了一种新的流式视频主干网络StreamFormer，通过将因果时序注意力机制整合到预训练视觉Transformer中；（ii）提出将多种时空视频理解任务统一到一个多任务视觉-语言对齐框架中，以训练StreamFormer；（iii）在在线动作检测、在线视频实例分割和视频问答等任务上进行了广泛的实验。&lt;h4&gt;主要发现&lt;/h4&gt;StreamFormer在保持效率的同时，在在线动作检测、在线视频实例分割和视频问答等任务上实现了有竞争力的结果，证明了其在实时应用中的潜力。&lt;h4&gt;结论&lt;/h4&gt;StreamFormer是一种高效的流式视频处理框架，适用于实时应用，如具身AI和自动驾驶，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Understanding continuous video streams plays a fundamental role in real-time applications including embodied AI and autonomous driving. Unlike offline video understanding, streaming video understanding requires the ability to process video streams frame by frame, preserve historical information, and make low-latency decisions. To address these challenges, our main contributions are three-fold. (i) We develop a novel streaming video backbone, termed as StreamFormer, by incorporating causal temporal attention into a pre-trained vision transformer. This enables efficient streaming video processing while maintaining image representation capability. (ii) To train StreamFormer, we propose to unify diverse spatial-temporal video understanding tasks within a multitask visual-language alignment framework. Hence, StreamFormer learns global semantics, temporal dynamics, and fine-grained spatial relationships simultaneously. (iii) We conduct extensive experiments on online action detection, online video instance segmentation, and video question answering. StreamFormer achieves competitive results while maintaining efficiency, demonstrating its potential for real-time applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding continuous video streams plays a fundamental role in real-timeapplications including embodied AI and autonomous driving. Unlike offline videounderstanding, streaming video understanding requires the ability to processvideo streams frame by frame, preserve historical information, and makelow-latency decisions.To address these challenges, our main contributions arethree-fold. (i) We develop a novel streaming video backbone, termed asStreamFormer, by incorporating causal temporal attention into a pre-trainedvision transformer. This enables efficient streaming video processing whilemaintaining image representation capability.(ii) To train StreamFormer, wepropose to unify diverse spatial-temporal video understanding tasks within amultitask visual-language alignment framework. Hence, StreamFormer learnsglobal semantics, temporal dynamics, and fine-grained spatial relationshipssimultaneously. (iii) We conduct extensive experiments on online actiondetection, online video instance segmentation, and video question answering.StreamFormer achieves competitive results while maintaining efficiency,demonstrating its potential for real-time applications.</description>
      <author>example@mail.com (Yibin Yan, Jilan Xu, Shangzhe Di, Yikun Liu, Yudi Shi, Qirui Chen, Zeqian Li, Yifei Huang, Weidi Xie)</author>
      <guid isPermaLink="false">2504.20041v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>A Review of 3D Object Detection with Vision-Language Models</title>
      <link>http://arxiv.org/abs/2504.18738v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对3D对象检测与视觉语言模型（VLMs）的综述进行了系统分析。&lt;h4&gt;背景&lt;/h4&gt;3D对象检测是3D视觉与多模态AI交叉领域的快速发展的一个领域。&lt;h4&gt;目的&lt;/h4&gt;提供首个针对3D对象检测与视觉语言模型的系统分析。&lt;h4&gt;方法&lt;/h4&gt;通过审查超过100篇研究论文，分析3D对象检测的独特挑战，比较传统方法和现代视觉语言框架，并回顾关键架构、预训练策略和提示工程方法。&lt;h4&gt;主要发现&lt;/h4&gt;分析了3D对象检测与视觉语言模型在空间推理和数据复杂性方面的差异，并讨论了性能和评估基准。&lt;h4&gt;结论&lt;/h4&gt;强调了当前挑战，如有限的3D语言数据集和计算需求，并提出了未来研究方向。&lt;h4&gt;翻译&lt;/h4&gt;This review provides a systematic analysis of comprehensive survey of 3Dobject detection with vision-language models(VLMs), a rapidly advancing areaat the intersection of 3D vision and multimodal AI. By examining over 100research papers, we provide the first systematic analysis dedicated to 3Dobject detection with vision-language models. We begin by outlining the uniquechallenges of 3D object detection with vision-language models, emphasizingdifferences from 2D detection in spatial reasoning and data complexity.Traditional approaches using point clouds and voxel grids are compared tomodern vision-language frameworks like CLIP and 3D LLMs, which enableopen-vocabulary detection and zero-shot generalization. We review keyarchitectures, pretraining strategies, and prompt engineering methods thatalign textual and 3D features for effective 3D object detection withvision-language models. Visualization examples and evaluation benchmarks arediscussed to illustrate performance and behavior. Finally, we highlight currentchallenges, such as limited 3D-language datasets and computational demands, andpropose future research directions to advance 3D object detection withvision-language models. &gt;Object Detection, Vision-Language Models, Agents,VLMs, LLMs, AI&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This review provides a systematic analysis of comprehensive survey of 3Dobject detection with vision-language models(VLMs) , a rapidly advancing areaat the intersection of 3D vision and multimodal AI. By examining over 100research papers, we provide the first systematic analysis dedicated to 3Dobject detection with vision-language models. We begin by outlining the uniquechallenges of 3D object detection with vision-language models, emphasizingdifferences from 2D detection in spatial reasoning and data complexity.Traditional approaches using point clouds and voxel grids are compared tomodern vision-language frameworks like CLIP and 3D LLMs, which enableopen-vocabulary detection and zero-shot generalization. We review keyarchitectures, pretraining strategies, and prompt engineering methods thatalign textual and 3D features for effective 3D object detection withvision-language models. Visualization examples and evaluation benchmarks arediscussed to illustrate performance and behavior. Finally, we highlight currentchallenges, such as limited 3D-language datasets and computational demands, andpropose future research directions to advance 3D object detection withvision-language models. &gt;Object Detection, Vision-Language Models, Agents,VLMs, LLMs, AI</description>
      <author>example@mail.com (Ranjan Sapkota, Konstantinos I Roumeliotis, Rahul Harsha Cheppally, Marco Flores Calero, Manoj Karkee)</author>
      <guid isPermaLink="false">2504.18738v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>HJRNO: Hamilton-Jacobi Reachability with Neural Operators</title>
      <link>http://arxiv.org/abs/2504.19989v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了HJRNO，一种基于神经操作符的框架，用于高效准确地解决向后可达管（BRTs），以保障自主系统在不确定环境下的安全性。&lt;h4&gt;背景&lt;/h4&gt;确保自主系统在不确定性下的安全性是关键挑战。传统的HJR分析方法在提供安全性保证的同时，受到维度灾难的限制，限制了其在高维系统或变化环境条件下的可扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，即HJRNO，以解决传统HJR方法在处理高维系统时的可扩展性问题，并实现高效准确的安全分析。&lt;h4&gt;方法&lt;/h4&gt;HJRNO利用傅里叶神经网络操作符（FNO）学习值函数之间的映射，通过这种方式，可以实现快速推理并具有良好的泛化能力，能够适应不同的障碍物形状、系统配置和超参数。&lt;h4&gt;主要发现&lt;/h4&gt;HJRNO在随机障碍物场景中实现了低误差，并在不同的系统动力学下表现出有效的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;HJRNO为自主系统提供了一种可扩展且实时的安全分析方法，是一种有前景的基础模型方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于神经操作符的框架HJRNO，用于解决向后可达管问题，以提高自主系统在不确定性环境下的安全性。传统方法在处理高维系统时受到限制，而HJRNO通过傅里叶神经网络操作符实现了高效和准确的解决方案，展现出良好的泛化能力，为自主系统的实时安全分析提供了有希望的基础模型方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety of autonomous systems under uncertainty is a criticalchallenge. Hamilton-Jacobi reachability (HJR) analysis is a widely used methodfor guaranteeing safety under worst-case disturbances. Traditional HJR methodsprovide safety guarantees but suffer from the curse of dimensionality, limitingtheir scalability to high-dimensional systems or varying environmentalconditions. In this work, we propose HJRNO, a neural operator-based frameworkfor solving backward reachable tubes (BRTs) efficiently and accurately. Byleveraging the Fourier Neural Operator (FNO), HJRNO learns a mapping betweenvalue functions, enabling fast inference with strong generalization acrossdifferent obstacle shapes, system configurations, and hyperparameters. Wedemonstrate that HJRNO achieves low error on random obstacle scenarios andgeneralizes effectively across varying system dynamics. These results suggestthat HJRNO offers a promising foundation model approach for scalable, real-timesafety analysis in autonomous systems.</description>
      <author>example@mail.com (Yankai Li, Mo Chen)</author>
      <guid isPermaLink="false">2504.19989v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Masked Point-Entity Contrast for Open-Vocabulary 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2504.19500v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MPEC的新型掩码点-实体对比学习方法，用于开放词汇的3D语义分割，旨在通过实体-语言对齐和点-实体一致性来提升实体特征表示，实现了在ScanNet上的最先进性能和零样本场景理解能力。&lt;h4&gt;背景&lt;/h4&gt;开放词汇的3D场景理解对于增强物理智能至关重要，因为它使具身智能体能够解释和动态交互于现实世界环境中。&lt;h4&gt;目的&lt;/h4&gt;提出MPEC方法，旨在改善语义区分能力，增强独特实例的区分度，并展示该方法在零样本场景理解上的优势。&lt;h4&gt;方法&lt;/h4&gt;MPEC方法结合了3D实体-语言对齐和点-实体一致性，用于开放词汇的3D语义分割，并在8个数据集上进行了广泛的微调实验，这些数据集涵盖了从低级感知到高级推理任务。&lt;h4&gt;主要发现&lt;/h4&gt;MPEC方法在ScanNet上取得了最先进的结果，并在多种3D场景理解任务上展示了稳定的表现。&lt;h4&gt;结论&lt;/h4&gt;MPEC方法展示了3D特征的潜力，并能够在不同的3D场景理解任务中带来持续的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：开放式词汇的3D场景理解对于提高物理智能至关重要，因为它允许具身智能体解释和动态地与真实世界环境互动。本文提出了一种名为MPEC的新型掩码点-实体对比学习方法，用于开放式词汇的3D语义分割，它利用了3D实体-语言对齐和不同点云视图中的点-实体一致性来培养特定于实体的特征表示。该方法提高了语义区分度，增强了独特实例的区分能力，在ScanNet开放式词汇的3D语义分割任务上取得了最先进的成果，并展示了卓越的零样本场景理解能力。在从低级感知到高级推理任务的8个数据集上进行的广泛微调实验展示了学习到的3D特征的潜力，推动在不同3D场景理解任务中的性能持续提升。项目网站：https://mpec-3d.github.io/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary 3D scene understanding is pivotal for enhancing physicalintelligence, as it enables embodied agents to interpret and interactdynamically within real-world environments. This paper introduces MPEC, a novelMasked Point-Entity Contrastive learning method for open-vocabulary 3D semanticsegmentation that leverages both 3D entity-language alignment and point-entityconsistency across different point cloud views to foster entity-specificfeature representations. Our method improves semantic discrimination andenhances the differentiation of unique instances, achieving state-of-the-artresults on ScanNet for open-vocabulary 3D semantic segmentation anddemonstrating superior zero-shot scene understanding capabilities. Extensivefine-tuning experiments on 8 datasets, spanning from low-level perception tohigh-level reasoning tasks, showcase the potential of learned 3D features,driving consistent performance gains across varied 3D scene understandingtasks. Project website: https://mpec-3d.github.io/</description>
      <author>example@mail.com (Yan Wang, Baoxiong Jia, Ziyu Zhu, Siyuan Huang)</author>
      <guid isPermaLink="false">2504.19500v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Heterophily-informed Message Passing</title>
      <link>http://arxiv.org/abs/2504.19785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Appearing in Transactions on Machine Learning Research (TMLR) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图神经网络（GNN）方法，旨在解决GNN过度平滑的问题，该方法通过调节消息的聚合来保护信息中的低频和高频成分。&lt;h4&gt;背景&lt;/h4&gt;GNNs由于其隐含的同质性假设而容易受到过度平滑的影响。&lt;h4&gt;目的&lt;/h4&gt;缓解GNN的过度平滑问题，同时保留信息中的低频和高频成分。&lt;h4&gt;方法&lt;/h4&gt;该方法依赖于学习到的嵌入，无需辅助标签，从而将异质性感知嵌入的好处扩展到更广泛的应用，例如生成建模。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在各种数据集和GNN架构上都有性能提升，并揭示了标准分类基准中的异质性模式。此外，在分子生成中的应用在化学信息学基准上展示了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;提出的方案有效地减轻了GNN的过度平滑问题，并提高了其性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) are known to be vulnerable to oversmoothing due to their implicit homophily assumption. We mitigate this problem with a novel scheme that regulates the aggregation of messages, modulating the type and extent of message passing locally thereby preserving both the low and high-frequency components of information. Our approach relies solely on learned embeddings, obviating the need for auxiliary labels, thus extending the benefits of heterophily-aware embeddings to broader applications, e.g., generative modelling. Our experiments, conducted across various data sets and GNN architectures, demonstrate performance enhancements and reveal heterophily patterns across standard classification benchmarks. Furthermore, application to molecular generation showcases notable performance improvements on chemoinformatics benchmarks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are known to be vulnerable to oversmoothing dueto their implicit homophily assumption. We mitigate this problem with a novelscheme that regulates the aggregation of messages, modulating the type andextent of message passing locally thereby preserving both the low andhigh-frequency components of information. Our approach relies solely on learntembeddings, obviating the need for auxiliary labels, thus extending thebenefits of heterophily-aware embeddings to broader applications, e.g.,generative modelling. Our experiments, conducted across various data sets andGNN architectures, demonstrate performance enhancements and reveal heterophilypatterns across standard classification benchmarks. Furthermore, application tomolecular generation showcases notable performance improvements onchemoinformatics benchmarks.</description>
      <author>example@mail.com (Haishan Wang, Arno Solin, Vikas Garg)</author>
      <guid isPermaLink="false">2504.19785v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>CE-NPBG: Connectivity Enhanced Neural Point-Based Graphics for Novel View Synthesis in Autonomous Driving Scenes</title>
      <link>http://arxiv.org/abs/2504.19557v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 2025 IEEE/CVF Conference on Computer Vision and Pattern  Recognition Workshops (CVPRW)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基于神经的点云合成方法，用于解决大规模自动驾驶场景中新型视图合成的问题。&lt;h4&gt;背景&lt;/h4&gt;当前基于点的三维点云地图在用于新型视图合成（NVS）时，由于可扩展性和渲染质量受限，导致可视化效果下降。&lt;h4&gt;目的&lt;/h4&gt;为了解决渲染质量低的问题，提出了一种名为CE-NPBG的新方法，用于大规模自动驾驶场景中的新型视图合成。&lt;h4&gt;方法&lt;/h4&gt;该方法利用两种模态：摆姿势的图像（相机）和同步的原始3D点云（LiDAR）。它首先使用外观和几何之间的连接关系图，从当前相机视角检索3D点云图中的点进行渲染。此外，该方法将神经网络描述符与点关联，并使用它们来合成视图。为了提高描述符的编码质量和渲染质量，提出了联合对抗和点光栅化训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用连接关系图，该方法显著提高了渲染质量，并通过仅使用大型3D点云图的一小部分点来增强运行时间和可扩展性。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法对于提高渲染质量和可扩展性具有显著优势，并已集成到最近的3D高斯喷溅工作中。&lt;h4&gt;翻译&lt;/h4&gt;摘要：当前基于点的三维点云地图在用于新型视图合成（NVS）时，由于可扩展性和渲染质量受限，导致可视化效果下降。我们识别出这些低质量渲染背后的主要问题是几何和外观之间的可见性不匹配，这是由于同时使用这两种模态造成的。为了解决这个问题，我们提出了CE-NPBG，这是一种用于大规模自动驾驶场景中新型视图合成（NVS）的新方法。我们的方法是一种神经点云技术，利用两种模态：摆姿势的图像（相机）和同步的原始3D点云（LiDAR）。我们首先使用外观和几何之间的连接关系图，从当前相机视角检索3D点云图中的点进行渲染。通过利用这种连接关系，我们的方法显著提高了渲染质量，并通过仅使用大型3D点云图的一小部分点来增强运行时间和可扩展性。我们的方法将神经网络描述符与点关联，并使用它们来合成视图。为了提高这些描述符的编码质量和渲染质量，我们提出了联合对抗和点光栅化训练。在训练期间，我们将图像合成网络与多分辨率判别器配对。在推理期间，我们将它们解耦，并使用图像合成网络生成新型视图。我们还把我们提出的方案集成到最近的3D高斯喷溅工作中，以突出其在提高渲染和可扩展性方面的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current point-based approaches encounter limitations in scalability andrendering quality when using large 3D point cloud maps because using themdirectly for novel view synthesis (NVS) leads to degraded visualizations. Weidentify the primary issue behind these low-quality renderings as a visibilitymismatch between geometry and appearance, stemming from using these twomodalities together. To address this problem, we present CE-NPBG, a newapproach for novel view synthesis (NVS) in large-scale autonomous drivingscenes. Our method is a neural point-based technique that leverages twomodalities: posed images (cameras) and synchronized raw 3D point clouds(LiDAR). We first employ a connectivity relationship graph between appearanceand geometry, which retrieves points from a large 3D point cloud map observedfrom the current camera perspective and uses them for rendering. By leveragingthis connectivity, our method significantly improves rendering quality andenhances run-time and scalability by using only a small subset of points fromthe large 3D point cloud map. Our approach associates neural descriptors withthe points and uses them to synthesize views. To enhance the encoding of thesedescriptors and elevate rendering quality, we propose a joint adversarial andpoint rasterization training. During training, we pair an image-synthesizernetwork with a multi-resolution discriminator. At inference, we decouple themand use the image-synthesizer to generate novel views. We also integrate ourproposal into the recent 3D Gaussian Splatting work to highlight its benefitsfor improved rendering and scalability.</description>
      <author>example@mail.com (Mohammad Altillawi, Fengyi Shen, Liudi Yang, Sai Manoj Prakhya, Ziyuan Liu)</author>
      <guid isPermaLink="false">2504.19557v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Point2Quad: Generating Quad Meshes from Point Clouds via Face Prediction</title>
      <link>http://arxiv.org/abs/2504.19545v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Point2Quad的基于学习的四边形网格生成方法，用于从点云中生成四边形网格。&lt;h4&gt;背景&lt;/h4&gt;尽管基于学习的三角形网格生成方法取得了显著进展，但由于确保共面性、凸性和仅使用四边形的挑战，四边形网格生成仍然相对较少探索。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的学习算法，能够从点云中生成符合要求的四边形网格。&lt;h4&gt;方法&lt;/h4&gt;Point2Quad通过以下步骤实现：使用k-NN生成候选四边形，考虑共面性和正方形性；使用两个编码器提取几何和拓扑特征；结合四边形特定的特性来解决四边形相关约束问题；融合提取的特征以训练分类器，并设计复合损失函数；最后，通过四边形特定的后处理进行细化。&lt;h4&gt;主要发现&lt;/h4&gt;在清晰和噪声数据上进行的广泛实验证明了Point2Quad的有效性和优越性，与基线方法相比，在综合指标下表现更优。&lt;h4&gt;结论&lt;/h4&gt;Point2Quad是一种有效的基于学习的方法，可以用于从点云中生成高质量的四边形网格。&lt;h4&gt;翻译&lt;/h4&gt;摘要：四边形网格在几何建模和计算力学中至关重要。尽管基于学习的三角形网格生成方法取得了显著进展，但由于确保共面性、凸性和仅使用四边形的挑战，四边形网格生成仍然相对较少探索。在本文中，我们提出了Point2Quad，这是第一个从点云生成仅四边形网格的基于学习的方法。其关键思想是学习识别融合了点级和面级特征的四边形网格。具体来说，Point2Quad从基于k-NN的候选生成开始，考虑共面性和正方形性。然后，跟随两个编码器提取几何和拓扑特征，以解决四边形相关约束的挑战，特别是通过结合深入的特定于四边形的特性。随后，提取的特征被融合以训练具有设计复合损失的分类器。最后，通过四边形特定的后处理进行细化。在清晰和噪声数据上的广泛实验证明了Point2Quad的有效性和优越性，与基线方法相比，在综合指标下表现更优。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TCSVT.2025.3556130&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quad meshes are essential in geometric modeling and computational mechanics.Although learning-based methods for triangle mesh demonstrate considerableadvancements, quad mesh generation remains less explored due to the challengeof ensuring coplanarity, convexity, and quad-only meshes. In this paper, wepresent Point2Quad, the first learning-based method for quad-only meshgeneration from point clouds. The key idea is learning to identify quad meshwith fused pointwise and facewise features. Specifically, Point2Quad beginswith a k-NN-based candidate generation considering the coplanarity andsquareness. Then, two encoders are followed to extract geometric andtopological features that address the challenge of quad-related constraints,especially by combining in-depth quadrilaterals-specific characteristics.Subsequently, the extracted features are fused to train the classifier with adesigned compound loss. The final results are derived after the refinement by aquad-specific post-processing. Extensive experiments on both clear and noisedata demonstrate the effectiveness and superiority of Point2Quad, compared tobaseline methods under comprehensive metrics.</description>
      <author>example@mail.com (Zezeng Li, Zhihui Qi, Weimin Wang, Ziliang Wang, Junyi Duan, Na Lei)</author>
      <guid isPermaLink="false">2504.19545v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Do You Know the Way? Human-in-the-Loop Understanding for Fast Traversability Estimation in Mobile Robotics</title>
      <link>http://arxiv.org/abs/2504.19851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by RA-L. Code is available at  https://github.com/andreschreiber/CHUNGUS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于在非结构化环境中进行机器导航的可穿越性估计方法，旨在解决现有方法的局限性和提高可穿越性预测的性能。&lt;h4&gt;背景&lt;/h4&gt;随着机器人在非结构化环境中应用的增加，有效的感知和导航策略变得至关重要，特别是在可穿越性估计方面。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的方法来改善机器人在环境中移动的能力，通过准确地预测它们可以或不可以到达的区域。&lt;h4&gt;方法&lt;/h4&gt;提出了一个结合人工参与（HiL）的可穿越性估计方法，该方法根据需要向人类请求标注，并使用基础模型快速学习新标注，即使在标注数量较少的情况下也能提供准确的预测。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在仿真和实际数据集上进行了广泛验证，证明了其能提供业界领先的可穿越性预测性能。&lt;h4&gt;结论&lt;/h4&gt;该方法通过结合人工智能和人工参与，在提高可穿越性估计准确性方面具有显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2025.3563819&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing use of robots in unstructured environments necessitates thedevelopment of effective perception and navigation strategies to enable fieldrobots to successfully perform their tasks. In particular, it is key for suchrobots to understand where in their environment they can and cannot travel -- atask known as traversability estimation. However, existing geometric approachesto traversability estimation may fail to capture nuanced representations oftraversability, whereas vision-based approaches typically either involvemanually annotating a large number of images or require robot experience. Inaddition, existing methods can struggle to address domain shifts as theytypically do not learn during deployment. To this end, we propose ahuman-in-the-loop (HiL) method for traversability estimation that prompts ahuman for annotations as-needed. Our method uses a foundation model to enablerapid learning on new annotations and to provide accurate predictions even whentrained on a small number of quickly-provided HiL annotations. We extensivelyvalidate our method in simulation and on real-world data, and demonstrate thatit can provide state-of-the-art traversability prediction performance.</description>
      <author>example@mail.com (Andre Schreiber, Katherine Driggs-Campbell)</author>
      <guid isPermaLink="false">2504.19851v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Physical Reach: Comparing Head- and Cane-Mounted Cameras for Last-Mile Navigation by Blind Users</title>
      <link>http://arxiv.org/abs/2504.19345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过调查和实验研究，探讨了盲人在导航过程中面临的挑战，并提出了基于多传感器融合的导航辅助系统设计方案。&lt;h4&gt;背景&lt;/h4&gt;盲人在导航过程中存在困难，如定位入口、识别障碍物以及导航复杂或拥挤的空间。&lt;h4&gt;目的&lt;/h4&gt;为了填补现有辅助系统设计的空白，本文通过两部分研究来指导设计：调查盲人的导航策略和偏好，以及通过实验研究不同视角下的导航效果。&lt;h4&gt;方法&lt;/h4&gt;首先，通过调查10位经验丰富的盲人使用拐杖的用户，了解他们的导航策略、痛点和技术偏好；其次，通过实验，让一位盲人使用同步的头戴式和拐杖式摄像头在五个真实环境中导航，以视角放置为变量，评估不同视角对空间感知的支持，包括SLAM性能和基于NeRF的3D重建。&lt;h4&gt;主要发现&lt;/h4&gt;头戴式传感器提供了更高的定位精度，而拐杖式视角提供了更全面的地面覆盖和丰富的环境重建。头戴式和拐杖式结合的配置在性能上优于单独使用。&lt;h4&gt;结论&lt;/h4&gt;不同传感器的放置位置具有互补的优势，为开发感知能力强、鲁棒且用户友好的混合导航辅助系统提供了实际指导。&lt;h4&gt;翻译&lt;/h4&gt;摘要：盲人在最后一英里导航中面临持续挑战，包括定位入口、识别障碍物以及导航复杂或拥挤的空间。尽管可穿戴摄像头在辅助系统中越来越被使用，但还没有系统性的、以视角为焦点的比较来指导其设计。本文通过两部分研究来填补这一空白。首先，我们调查了10位有经验的盲人拐杖使用者，揭示了导航策略、痛点和技术偏好。参与者强调了多感官整合、以目的地为导向的旅行和补充（而不是替代）拐杖触觉功能辅助工具的重要性。其次，我们进行了一项受控数据收集，让一位盲人在使用同步的头戴式和拐杖式摄像头在五个真实环境中导航，将视角放置作为主要变量。为了评估每个视角如何支持空间感知，我们评估了SLAM性能（用于定位和制图）和基于NeRF的3D重建（用于下游场景理解）。头戴式传感器提供了优越的定位精度，而拐杖式视角提供了更广泛的地面覆盖和更丰富的环境重建。头戴式和拐杖式结合的配置在性能上始终优于单独使用。这些结果突出了不同传感器放置位置的互补优势，并为开发感知能力强、鲁棒且用户友好的混合导航辅助系统提供了实际指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Blind individuals face persistent challenges in last-mile navigation,including locating entrances, identifying obstacles, and navigating complex orcluttered spaces. Although wearable cameras are increasingly used in assistivesystems, there has been no systematic, vantage-focused comparison to guidetheir design. This paper addresses that gap through a two-part investigation.First, we surveyed ten experienced blind cane users, uncovering navigationstrategies, pain points, and technology preferences. Participants stressed theimportance of multi-sensory integration, destination-focused travel, andassistive tools that complement (rather than replace) the cane's tactileutility. Second, we conducted controlled data collection with a blindparticipant navigating five real-world environments using synchronized head-and cane-mounted cameras, isolating vantage placement as the primary variable.To assess how each vantage supports spatial perception, we evaluated SLAMperformance (for localization and mapping) and NeRF-based 3D reconstruction(for downstream scene understanding). Head-mounted sensors delivered superiorlocalization accuracy, while cane-mounted views offered broader ground-levelcoverage and richer environmental reconstructions. A combined (head+cane)configuration consistently outperformed both. These results highlight thecomplementary strengths of different sensor placements and offer actionableguidance for developing hybrid navigation aids that are perceptive, robust, anduser-aligned.</description>
      <author>example@mail.com (Apurv Varshney, Lucas Nadolskis, Tobias Höllerer, Michael Beyeler)</author>
      <guid isPermaLink="false">2504.19345v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Contextures: The Mechanism of Representation Learning</title>
      <link>http://arxiv.org/abs/2504.19792v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD Dissertation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文建立了情境理论，以数学方式描述了表示学习或预训练的机制。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型在实证上取得了显著成功，但它们学习到的表示以及为什么这些表示对各种下游任务有用尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;对表示学习有一个科学理解，特别是在模型规模扩大导致回报递减，设计新的预训练方法对于进一步进步至关重要的时候。&lt;h4&gt;方法&lt;/h4&gt;情境理论提供了一个统一的框架来分析不同的表示学习方法，其核心论点是表示是通过输入X与情境变量A之间的关联来学习的。&lt;h4&gt;主要发现&lt;/h4&gt;如果编码器捕捉到这种关联的最大信息，即编码器学习到情境，那么它将在与情境兼容的任务类别中表现最优。此外，当X和A之间的关联既不过强也不过弱时，情境最有用。&lt;h4&gt;结论&lt;/h4&gt;情境理论的重要含义是，仅增加模型规模将导致回报递减，进一步的进步需要更好的情境。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了情境理论，用以数学化地刻画表示学习（预训练）的机制。尽管基础模型在实证上取得了显著的成功，但它们学习到的表示以及这些表示为何对各种下游任务有用尚不明确。对表示学习有一个科学理解至关重要，尤其是在模型规模扩大导致回报递减，设计新的预训练方法对于进一步进步变得至关重要的当下。先前的研究对不同的表示学习方法采取了不同的处理方式，而情境理论提供了一个统一的框架来分析这些方法。其核心论点是，表示是通过输入X与情境变量A之间的关联来学习的。我们证明了，如果编码器捕捉到这种关联的最大信息，在这种情况下我们说编码器学习到了情境，那么它将在与情境兼容的任务类别中表现最优。我们还表明，当X和A之间的关联既不过强也不过弱时，情境最有用。情境理论的重要含义是，仅增加模型规模将导致回报递减，进一步的进步需要更好的情境。我们证明了包括监督学习、自监督学习、生成模型等许多预训练目标都可以学习情境。然后，我们引入了两个用于学习情境的通用目标——SVME和KISE。我们还展示了如何混合多个情境，这是一种从现有情境中轻松创建更好情境的方法。然后，我们为表示学习证明了统计学习界限。最后，我们讨论了从预训练到下游任务的数据分布变化的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This dissertation establishes the contexture theory to mathematicallycharacterize the mechanism of representation learning, or pretraining. Despitethe remarkable empirical success of foundation models, it is not very clearwhat representations they learn, and why these representations are useful forvarious downstream tasks. A scientific understanding of representation learningis critical, especially at this point when scaling up the model size isproducing diminishing returns, and designing new pretraining methods isimperative for further progress.  Prior work treated different representation learning methods quitedifferently, whereas the contexture theory provides a unified framework foranalyzing these methods. The central argument is that a representation islearned from the association between the input X and a context variable A. Weprove that if an encoder captures the maximum information of this association,in which case we say that the encoder learns the contexture, then it will beoptimal on the class of tasks that are compatible with the context. We alsoshow that a context is the most useful when the association between X and A isneither too strong nor too weak. The important implication of the contexturetheory is that increasing the model size alone will achieve diminishingreturns, and further advancements require better contexts.  We demonstrate that many pretraining objectives can learn the contexture,including supervised learning, self-supervised learning, generative models,etc. Then, we introduce two general objectives -- SVME and KISE, for learningthe contexture. We also show how to mix multiple contexts together, aneffortless way to create better contexts from existing ones. Then, we provestatistical learning bounds for representation learning. Finally, we discussthe effect of the data distribution shift from pretraining to the downstreamtask.</description>
      <author>example@mail.com (Runtian Zhai)</author>
      <guid isPermaLink="false">2504.19792v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.19627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  VCM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VCM是一种端到端自监督视觉概念建模框架，旨在提高大型视觉语言模型（LVLMs）在现实世界应用中的效率和性能。&lt;h4&gt;背景&lt;/h4&gt;当前LVLMs在处理图像时效率低下，因为它们在标记级别处理整个图像，而人类可以在概念级别分析信息和生成内容。&lt;h4&gt;目的&lt;/h4&gt;提出VCM框架，以解决LVLMs缺乏视觉概念模型导致的效率低下问题。&lt;h4&gt;方法&lt;/h4&gt;VCM利用跨多个采样实例的隐式对比学习和视觉语言微调来构建视觉概念模型，无需昂贵的概念级别标注。&lt;h4&gt;主要发现&lt;/h4&gt;VCM显著降低了计算成本（例如，LLaVA-1.5-7B的FLOPs减少了85%）同时保持了在多种图像理解任务上的强大性能。此外，VCM增强了视觉编码器在经典视觉概念感知任务中的能力。&lt;h4&gt;结论&lt;/h4&gt;广泛的定量和定性实验验证了VCM的有效性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Vision-Language Models (LVLMs) are pivotal for real-world AI tasks likeembodied intelligence due to their strong vision-language reasoning abilities.However, current LVLMs process entire images at the token level, which isinefficient compared to humans who analyze information and generate content atthe conceptual level, extracting relevant visual concepts with minimal effort.This inefficiency, stemming from the lack of a visual concept model, limitsLVLMs' usability in real-world applications. To address this, we propose VCM,an end-to-end self-supervised visual concept modeling framework. VCM leveragesimplicit contrastive learning across multiple sampled instances andvision-language fine-tuning to construct a visual concept model withoutrequiring costly concept-level annotations. Our results show that VCMsignificantly reduces computational costs (e.g., 85\% fewer FLOPs forLLaVA-1.5-7B) while maintaining strong performance across diverse imageunderstanding tasks. Moreover, VCM enhances visual encoders' capabilities inclassic visual concept perception tasks. Extensive quantitative and qualitativeexperiments validate the effectiveness and efficiency of VCM.</description>
      <author>example@mail.com (Run Luo, Renke Shan, Longze Chen, Ziqiang Liu, Lu Wang, Min Yang, Xiaobo Xia)</author>
      <guid isPermaLink="false">2504.19627v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>OpenFusion++: An Open-vocabulary Real-time Scene Understanding System</title>
      <link>http://arxiv.org/abs/2504.19266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;OpenFusion++是一种基于TSDF的实时3D语义-几何重建系统，旨在解决现有方法在实例分割、语义更新和复杂查询处理方面的不足。&lt;h4&gt;背景&lt;/h4&gt;实时开放词汇场景理解对于视觉语言导航、具身智能和增强现实等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的问题，如不精确的实例分割、静态语义更新和复杂查询处理能力有限。&lt;h4&gt;方法&lt;/h4&gt;OpenFusion++通过融合基础模型中的置信图来优化3D点云，使用基于实例面积的自适应缓存动态更新全局语义标签，并采用双路径编码框架将对象属性与环境上下文集成，以实现精确的查询响应。&lt;h4&gt;主要发现&lt;/h4&gt;在ICL、Replica、ScanNet和ScanNet++数据集上的实验表明，OpenFusion++在语义准确性和查询响应速度方面均显著优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;OpenFusion++能够有效提升3D感知的效率和准确性，为视觉语言导航、具身智能和增强现实等应用提供强有力的支持。&lt;h4&gt;翻译&lt;/h4&gt;实时开放词汇场景理解对于高效的三维感知至关重要，对于如视觉语言导航、具身智能和增强现实等应用至关重要。然而，现有方法在实例分割、静态语义更新和复杂查询处理方面存在不足。为了解决这些问题，我们提出了一种基于TSDF的实时3D语义-几何重建系统，称为OpenFusion++。我们的方法通过融合基础模型的置信图来优化3D点云，通过基于实例面积的自适应缓存动态更新全局语义标签，并采用双路径编码框架将对象属性与环境上下文集成，以实现精确的查询响应。在ICL、Replica、ScanNet和ScanNet++数据集上的实验表明，OpenFusion++在语义准确性和查询响应速度方面均显著优于基线方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-time open-vocabulary scene understanding is essential for efficient 3Dperception in applications such as vision-language navigation, embodiedintelligence, and augmented reality. However, existing methods suffer fromimprecise instance segmentation, static semantic updates, and limited handlingof complex queries. To address these issues, we present OpenFusion++, aTSDF-based real-time 3D semantic-geometric reconstruction system. Our approachrefines 3D point clouds by fusing confidence maps from foundational models,dynamically updates global semantic labels via an adaptive cache based oninstance area, and employs a dual-path encoding framework that integratesobject attributes with environmental context for precise query responses.Experiments on the ICL, Replica, ScanNet, and ScanNet++ datasets demonstratethat OpenFusion++ significantly outperforms the baseline in both semanticaccuracy and query responsiveness.</description>
      <author>example@mail.com (Xiaofeng Jin, Matteo Frosi, Matteo Matteucci)</author>
      <guid isPermaLink="false">2504.19266v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Graph Fourier Transformer with Structure-Frequency Information</title>
      <link>http://arxiv.org/abs/2504.19740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Grafourierformer，一种结合了图傅里叶变换的图变换器（GTs），通过考虑节点频率信息来优化注意力机制，以提升图结构任务的性能。&lt;h4&gt;背景&lt;/h4&gt;虽然图变换器在图结构任务中表现出优势，但其自注意力机制忽略了图的一般化偏差，现有方法主要通过位置编码、注意力偏差和相对距离等方面进行补偿，但性能仍不理想。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理图的一般化偏差的方法，并提升图分类和节点分类任务的性能。&lt;h4&gt;方法&lt;/h4&gt;Grafourierformer通过将图傅里叶变换应用于注意力矩阵，使用图拉普拉斯矩阵的特征值构建特征值矩阵掩码，并通过傅里叶逆变换提取节点的高频和低频特征，构建节点频率能量矩阵，以实现注意力头对图结构信息和节点频率信息的优化。&lt;h4&gt;主要发现&lt;/h4&gt;Grafourierformer在多个基准测试中均优于GNN和基于GT的模型，消融实验进一步验证了该方法的有效性和必要性。&lt;h4&gt;结论&lt;/h4&gt;Grafourierformer通过结合图傅里叶变换和节点频率信息，有效地抑制了冗余信息干扰，提升了图结构任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Transformers have shown advantages in numerous graph structure tasks but their self-attention mechanism ignores the generalization bias of graphs, with existing methods mainly compensating for this bias from aspects like position encoding, attention bias and relative distance yet still having sub-optimal performance and being insufficient by only considering the structural perspective of generalization bias. To address this, this paper proposes Grafourierformer, which innovatively combines GT with inductive bias containing Frequency-Structure information by applying Graph Fourier Transform to the Attention Matrix: specifically, eigenvalues from the Graph Laplacian matrix are used to construct an Eigenvalue matrix mask (reflecting node positions and structural relationships with neighboring nodes to enable consideration of node range structural characteristics and focus on local graph details), and inverse Fourier transform is employed to extract node high-frequency and low-frequency features, calculate low-frequency and high-frequency energy, and construct a node frequency-energy matrix to filter the eigenvalue matrix mask, allowing attention heads to incorporate both graph structural information and node frequency information optimization, adaptively distinguish global trends from local details, and effectively suppress redundant information interference. Extensive experiments on various benchmarks show Grafourierformer consistently outperforms GNN and GT-based models in graph classification and node classification tasks, with ablation experiments further validating the effectiveness and necessity of the method. Codes are available at https://github.com/Arichibald/Grafourierformer.git&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs) have shown advantages in numerous graph structuretasks but their self-attention mechanism ignores the generalization bias ofgraphs, with existing methods mainly compensating for this bias from aspectslike position encoding, attention bias and relative distance yet still havingsub-optimal performance and being insufficient by only considering thestructural perspective of generalization bias. To address this, this paperproposes Grafourierformer, which innovatively combines GT with inductive biascontaining Frequency-Structure information by applying Graph Fourier Transformto the Attention Matrix: specifically, eigenvalues from the Graph Laplacianmatrix are used to construct an Eigenvalue matrix mask (reflecting nodepositions and structural relationships with neighboring nodes to enableconsideration of node range structural characteristics and focus on local graphdetails), and inverse Fourier transform is employed to extract nodehigh-frequency and low-frequency features, calculate low-frequency andhigh-frequency energy, and construct a node frequency-energy matrix to filterthe eigenvalue matrix mask, allowing attention heads to incorporate both graphstructural information and node frequency information optimization, adaptivelydistinguish global trends from local details, and effectively suppressredundant information interference. Extensive experiments on various benchmarksshow Grafourierformer consistently outperforms GNN and GT-based models in graphclassification and node classification tasks, with ablation experiments furthervalidating the effectiveness and necessity of the method. Codes are availableat https://github.com/Arichibald/Grafourierformer.git</description>
      <author>example@mail.com (Yonghui Zhai, Yang Zhang, Minghao Shang, Lihua Pang, Yaxin Ren)</author>
      <guid isPermaLink="false">2504.19740v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Language-Image Learning with Augmented Textual Prompts for 3D/4D FER Using Vision-Language Model</title>
      <link>http://arxiv.org/abs/2504.19739v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了AffectVLM，这是一种用于从3D/4D数据中理解面部情感的多视角视觉语言模型。&lt;h4&gt;背景&lt;/h4&gt;该模型旨在通过集成多视角来提供语义丰富和视觉全面的情感理解。&lt;h4&gt;目的&lt;/h4&gt;目的是开发一个能够有效捕捉视觉特征并具有良好语言能力的模型，同时能够进行实时交互推理和分布式学习。&lt;h4&gt;方法&lt;/h4&gt;方法包括提出一个联合表示学习框架和新的梯度友好损失函数，引入增强文本提示和混合视角增强，以及开发一个Streamlit应用程序用于实时交互推理。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验验证了AffectVLM在多个基准测试中的优越性能。&lt;h4&gt;结论&lt;/h4&gt;AffectVLM在面部情感理解方面表现出色，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce AffectVLM, a vision-language model designed tointegrate multiviews for a semantically rich and visually comprehensiveunderstanding of facial emotions from 3D/4D data. To effectively capture visualfeatures, we propose a joint representation learning framework paired with anovel gradient-friendly loss function that accelerates model convergencetowards optimal feature representation. Additionally, we introduce augmentedtextual prompts to enhance the model's linguistic capabilities and employ mixedview augmentation to expand the visual dataset. We also develop a Streamlit appfor a real-time interactive inference and enable the model for distributedlearning. Extensive experiments validate the superior performance of AffectVLMacross multiple benchmarks.</description>
      <author>example@mail.com (Muzammil Behzad, Guoying Zhao)</author>
      <guid isPermaLink="false">2504.19739v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis</title>
      <link>http://arxiv.org/abs/2504.19223v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为CARL的模型，用于跨不同成像模态（如RGB、多光谱和超光谱成像）进行相机无关的表征学习，以解决光谱成像在人工智能应用中的挑战。&lt;h4&gt;背景&lt;/h4&gt;光谱成像在医学和城市场景理解等领域具有广泛应用前景，但在遥感领域已确立为关键模态。然而，不同光谱相机在通道维度和捕获波长上的差异阻碍了AI驱动方法的发展，导致具有有限泛化能力和不足跨相机适用性的相机特定模型。&lt;h4&gt;目的&lt;/h4&gt;提出CARL模型，旨在解决光谱成像在AI应用中的瓶颈，实现不同通道维度的光谱图像到相机无关嵌入的转换。&lt;h4&gt;方法&lt;/h4&gt;CARL模型通过波长位置编码和自注意力-交叉注意力机制，将光谱信息压缩到学习的查询表示中。采用一种新的基于JEPA的谱自监督策略进行光谱-空间预训练。&lt;h4&gt;主要发现&lt;/h4&gt;在大规模实验中，CARL模型在医学成像、自动驾驶和卫星成像等领域显示出对光谱异质性的独特鲁棒性，在具有模拟和真实世界跨相机光谱变化的数据库上表现优于其他模型。&lt;h4&gt;结论&lt;/h4&gt;该模型的可扩展性和多功能性使其成为未来光谱基础模型的骨干。&lt;h4&gt;翻译&lt;/h4&gt;Spectral imaging offers promising applications across diverse domains, including medicine and urban scene understanding, and is already established as a critical modality in remote sensing. However, variability in channel dimensionality and captured wavelengths among spectral cameras impedes the development of AI-driven methodologies, leading to camera-specific models with limited generalizability and inadequate cross-camera applicability. To address this bottleneck, we introduce $extbf{CARL}$, a model for $extbf{C}$amera-$extbf{A}$gnostic $extbf{R}$epresentation$extbf{L}$earning across RGB, multispectral, and hyperspectral imaging modalities. To enable the conversion of a spectral image with any channel dimensionality to a camera-agnostic embedding, we introduce wavelength positional encoding and a self-attention-cross-attention mechanism to compress spectral information into learned query representations. Spectral-spatial pre-training is achieved with a novel spectral self-supervised JEPA-inspired strategy tailored to CARL. Large-scale experiments across the domains of medical imaging, autonomous driving, and satellite imaging demonstrate our model's unique robustness to spectral heterogeneity, outperforming on datasets with simulated and real-world cross-camera spectral variations. The scalability and versatility of the proposed approach position our model as a backbone for future spectral foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spectral imaging offers promising applications across diverse domains,including medicine and urban scene understanding, and is already established asa critical modality in remote sensing. However, variability in channeldimensionality and captured wavelengths among spectral cameras impede thedevelopment of AI-driven methodologies, leading to camera-specific models withlimited generalizability and inadequate cross-camera applicability. To addressthis bottleneck, we introduce $\textbf{CARL}$, a model for$\textbf{C}$amera-$\textbf{A}$gnostic $\textbf{R}$epresentation$\textbf{L}$earning across RGB, multispectral, and hyperspectral imagingmodalities. To enable the conversion of a spectral image with any channeldimensionality to a camera-agnostic embedding, we introduce wavelengthpositional encoding and a self-attention-cross-attention mechanism to compressspectral information into learned query representations. Spectral-spatialpre-training is achieved with a novel spectral self-supervised JEPA-inspiredstrategy tailored to CARL. Large-scale experiments across the domains ofmedical imaging, autonomous driving, and satellite imaging demonstrate ourmodel's unique robustness to spectral heterogeneity, outperforming on datasetswith simulated and real-world cross-camera spectral variations. The scalabilityand versatility of the proposed approach position our model as a backbone forfuture spectral foundation models.</description>
      <author>example@mail.com (Alexander Baumann, Leonardo Ayala, Silvia Seidlitz, Jan Sellner, Alexander Studier-Fischer, Berkin Özdemir, Lena Maier-Hein, Slobodan Ilic)</author>
      <guid isPermaLink="false">2504.19223v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Improving Pretrained YAMNet for Enhanced Speech Command Detection via Transfer Learning</title>
      <link>http://arxiv.org/abs/2504.19030v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究旨在提高语音命令识别系统的准确性和效率，通过使用预训练的YAMNet模型和迁移学习技术，显著提升了语音命令识别效果。&lt;h4&gt;背景&lt;/h4&gt;语音命令识别是智能应用中用户交互的关键组成部分，目前存在准确性和效率的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，以增强语音命令识别系统的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的YAMNet模型和迁移学习技术，对语音命令进行检测和解释，并在Speech Commands数据集上进行了细致的数据增强和特征提取。&lt;h4&gt;主要发现&lt;/h4&gt;通过这种方法，模型达到了95.28%的识别准确率，证明了高级机器学习技术在语音命令识别中的影响。&lt;h4&gt;结论&lt;/h4&gt;这一成果在音频处理技术方面取得了实质性进展，并为该领域未来的研究设定了新的基准。&lt;h4&gt;翻译&lt;/h4&gt;This work addresses the need for enhanced accuracy and efficiency in speech command recognition systems, a critical component for improving user interaction in various smart applications. Leveraging the robust pretrained YAMNet model and transfer learning, this study develops a method that significantly improves speech command recognition. We adapt and train a YAMNet deep learning model to effectively detect and interpret speech commands from audio signals. Using the extensively annotated Speech Commands dataset (speech_commands_v0.01), our approach demonstrates the practical application of transfer learning to accurately recognize a predefined set of speech commands. The dataset is meticulously augmented, and features are strategically extracted to boost model performance. As a result, the final model achieved a recognition accuracy of 95.28%, underscoring the impact of advanced machine learning techniques on speech command recognition. This achievement marks substantial progress in audio processing technologies and establishes a new benchmark for future research in the field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICTIS62692.2024.10894266&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work addresses the need for enhanced accuracy and efficiency in speechcommand recognition systems, a critical component for improving userinteraction in various smart applications. Leveraging the robust pretrainedYAMNet model and transfer learning, this study develops a method thatsignificantly improves speech command recognition. We adapt and train a YAMNetdeep learning model to effectively detect and interpret speech commands fromaudio signals. Using the extensively annotated Speech Commands dataset(speech_commands_v0.01), our approach demonstrates the practical application oftransfer learning to accurately recognize a predefined set of speech commands.The dataset is meticulously augmented, and features are strategically extractedto boost model performance. As a result, the final model achieved a recognitionaccuracy of 95.28%, underscoring the impact of advanced machine learningtechniques on speech command recognition. This achievement marks substantialprogress in audio processing technologies and establishes a new benchmark forfuture research in the field.</description>
      <author>example@mail.com (Sidahmed Lachenani, Hamza Kheddar, Mohamed Ouldzmirli)</author>
      <guid isPermaLink="false">2504.19030v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Semantic-Aligned Learning with Collaborative Refinement for Unsupervised VI-ReID</title>
      <link>http://arxiv.org/abs/2504.19244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SALCR的无监督可见光-红外行人重识别框架，该框架通过语义对齐学习和协作优化来提高跨模态图像的重识别性能。&lt;h4&gt;背景&lt;/h4&gt;当前方法在统一跨模态图像的伪标签和设计对比学习框架时，忽略了特征表示和伪标签分布的跨模态变化。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有方法中由于只优化全局特征而导致的模态共享学习不足的问题。&lt;h4&gt;方法&lt;/h4&gt;1. 提出DAGI模块双向统一跨模态实例的伪标签；2. 使用FGSAL模块探索跨模态实例中每种模态强调的语义对齐模式；3. 基于语义对齐特征及其对应的标签空间构建优化目标；4. 提出GPCR模块动态挖掘可靠的正样本集，优化实例间关系。&lt;h4&gt;主要发现&lt;/h4&gt;SALCR框架通过强调特定细粒度模式，实现了不同模态标签分布的互补对齐。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法在性能上优于现有方法，并且代码已开源。&lt;h4&gt;翻译&lt;/h4&gt;The proposed SALCR framework for unsupervised visible-infrared person re-identification addresses the insufficient modality-shared learning issue in existing methods by employing semantic-aligned learning and collaborative refinement. It achieves complementary alignment between the label distributions of different modalities by emphasizing specific fine-grained patterns. Extensive experiments demonstrate its superiority over state-of-the-art methods, and the code is publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised visible-infrared person re-identification (USL-VI-ReID) seeks tomatch pedestrian images of the same individual across different modalitieswithout human annotations for model learning. Previous methods unifypseudo-labels of cross-modality images through label association algorithms andthen design contrastive learning framework for global feature learning.However, these methods overlook the cross-modality variations in featurerepresentation and pseudo-label distributions brought by fine-grained patterns.This insight results in insufficient modality-shared learning when only globalfeatures are optimized. To address this issue, we propose a Semantic-AlignedLearning with Collaborative Refinement (SALCR) framework, which builds upoptimization objective for specific fine-grained patterns emphasized by eachmodality, thereby achieving complementary alignment between the labeldistributions of different modalities. Specifically, we first introduce a DualAssociation with Global Learning (DAGI) module to unify the pseudo-labels ofcross-modality instances in a bi-directional manner. Afterward, a Fine-GrainedSemantic-Aligned Learning (FGSAL) module is carried out to explore part-levelsemantic-aligned patterns emphasized by each modality from cross-modalityinstances. Optimization objective is then formulated based on thesemantic-aligned features and their corresponding label space. To alleviate theside-effects arising from noisy pseudo-labels, we propose a Global-PartCollaborative Refinement (GPCR) module to mine reliable positive sample setsfor the global and part features dynamically and optimize the inter-instancerelationships. Extensive experiments demonstrate the effectiveness of theproposed method, which achieves superior performances to state-of-the-artmethods. Our code is available at\href{https://github.com/FranklinLingfeng/code-for-SALCR}.</description>
      <author>example@mail.com (De Cheng, Lingfeng He, Nannan Wang, Dingwen Zhang, Xinbo Gao)</author>
      <guid isPermaLink="false">2504.19244v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model-Driven Framework for Human-Object Interaction Prediction with Segmentation Mask Integration</title>
      <link>http://arxiv.org/abs/2504.19847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Seg2HOI的新框架，该框架将基于分割的视觉基础模型与人类-物体交互任务相结合，区别于传统的基于检测的人类-物体交互方法。&lt;h4&gt;背景&lt;/h4&gt;在人类-物体交互（HOI）任务中，传统方法依赖于检测，而本文提出的方法采用分割技术。&lt;h4&gt;目的&lt;/h4&gt;提高HOI检测的准确性，并通过引入四元组扩展三元组，包括人类-物体对的分割掩码。&lt;h4&gt;方法&lt;/h4&gt;Seg2HOI继承了视觉基础模型（如可提示和交互机制）的特性，并包含一个解码器，将这些属性应用于HOI任务。尽管仅针对HOI进行训练，但没有对这些属性进行额外的训练机制，该框架仍然表现出高效的性能。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公共基准数据集上的大量实验表明，Seg2HOI即使在零样本场景下也能达到与最先进方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;Seg2HOI可以从未在训练中使用的新型文本和视觉提示中生成HOI四元组和交互式HOI分割，这使得它能够通过这种灵活性在广泛的应用中发挥作用。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we introduce Segmentation to Human-Object Interaction (Seg2HOI) approach, a novel framework that integrates segmentation-based vision foundation models with the human-object interaction task, distinguished from traditional detection-based Human-Object Interaction (HOI) methods. Our approach enhances HOI detection by not only predicting the standard triplets but also introducing quadruplets, which extend HOI triplets by including segmentation masks for human-object pairs. More specifically, Seg2HOI inherits the properties of the vision foundation model (e.g., promptable and interactive mechanisms) and incorporates a decoder that applies these attributes to the HOI task. Despite training only for HOI, without additional training mechanisms for these properties, the framework demonstrates that such features still operate efficiently. Extensive experiments on two public benchmark datasets demonstrate that Seg2HOI achieves performance comparable to state-of-the-art methods, even in zero-shot scenarios. Lastly, we propose that Seg2HOI can generate HOI quadruplets and interactive HOI segmentation from novel text and visual prompts that were not used during training, making it versatile for a wide range of applications by leveraging this flexibility.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce Segmentation to Human-Object Interaction(\textit{\textbf{Seg2HOI}}) approach, a novel framework that integratessegmentation-based vision foundation models with the human-object interactiontask, distinguished from traditional detection-based Human-Object Interaction(HOI) methods. Our approach enhances HOI detection by not only predicting thestandard triplets but also introducing quadruplets, which extend HOI tripletsby including segmentation masks for human-object pairs. More specifically,Seg2HOI inherits the properties of the vision foundation model (e.g.,promptable and interactive mechanisms) and incorporates a decoder that appliesthese attributes to HOI task. Despite training only for HOI, without additionaltraining mechanisms for these properties, the framework demonstrates that suchfeatures still operate efficiently. Extensive experiments on two publicbenchmark datasets demonstrate that Seg2HOI achieves performance comparable tostate-of-the-art methods, even in zero-shot scenarios. Lastly, we propose thatSeg2HOI can generate HOI quadruplets and interactive HOI segmentation fromnovel text and visual prompts that were not used during training, making itversatile for a wide range of applications by leveraging this flexibility.</description>
      <author>example@mail.com (Juhan Park, Kyungjae Lee, Hyung Jin Chang, Jungchan Cho)</author>
      <guid isPermaLink="false">2504.19847v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Predicting Stress in Two-phase Random Materials and Super-Resolution Method for Stress Images by Embedding Physical Information</title>
      <link>http://arxiv.org/abs/2504.18854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了两相随机材料（TRM）的应力分析，提出了一种基于深度学习的应力预测框架。&lt;h4&gt;背景&lt;/h4&gt;应力分析是材料设计的重要部分，对于具有复杂微结构的材料，如两相随机材料，应力集中是材料失效的常见原因，而相界面是应力集中的关键。&lt;h4&gt;目的&lt;/h4&gt;减少相界面的应力预测误差，提高应力图像的分辨率，并实现多尺度分析。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为MC U-net的神经网络来预测低分辨率材料微结构中的应力，并引入了相界面信息以减少预测误差；同时，提出了一种基于物理信息混合的神经网络（MPINN）的方法，用于应力图像超分辨率，无需成对训练数据，并能提高应力图像的分辨率。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够有效减少相界面的预测误差，提高应力图像的分辨率，并实现多尺度分析。&lt;h4&gt;结论&lt;/h4&gt;所提出的应力预测框架具有较高的准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Stress analysis is an important part of material design. For materials with complex microstructures, such as two-phase random materials (TRMs), material failure is often accompanied by stress concentration. Phase interfaces in two-phase materials are critical for stress concentration. Therefore, the prediction error of stress at phase boundaries is crucial. In practical engineering, the pixels of the obtained material microstructure images are limited, which limits the resolution of stress images generated by deep learning methods, making it difficult to observe stress concentration regions. Existing Image Super-Resolution (ISR) technologies are all based on data-driven supervised learning. However, stress images have natural physical constraints, which provide new ideas for new ISR technologies. In this study, we constructed a stress prediction framework for TRMs. First, the framework uses a proposed Multiple Compositions U-net (MC U-net) to predict stress in low-resolution material microstructures. By considering the phase interface information of the microstructure, the MC U-net effectively reduces the problem of excessive prediction errors at phase boundaries. Secondly, a Mixed Physics-Informed Neural Network (MPINN) based method for stress ISR (SRPINN) was proposed. By introducing the constraints of physical information, the new method does not require paired stress images for training and can increase the resolution of stress images to any multiple. This enables a multiscale analysis of the stress concentration regions at phase boundaries. Finally, we performed stress analysis on TRMs with different phase volume fractions and loading states through transfer learning. The results show the proposed stress prediction framework has satisfactory accuracy and generalization ability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.2139/ssrn.5096177&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stress analysis is an important part of material design. For materials withcomplex microstructures, such as two-phase random materials (TRMs), materialfailure is often accompanied by stress concentration. Phase interfaces intwo-phase materials are critical for stress concentration. Therefore, theprediction error of stress at phase boundaries is crucial. In practicalengineering, the pixels of the obtained material microstructure images arelimited, which limits the resolution of stress images generated by deeplearning methods, making it difficult to observe stress concentration regions.Existing Image Super-Resolution (ISR) technologies are all based on data-drivensupervised learning. However, stress images have natural physical constraints,which provide new ideas for new ISR technologies. In this study, we constructeda stress prediction framework for TRMs. First, the framework uses a proposedMultiple Compositions U-net (MC U-net) to predict stress in low-resolutionmaterial microstructures. By considering the phase interface information of themicrostructure, the MC U-net effectively reduces the problem of excessiveprediction errors at phase boundaries. Secondly, a Mixed Physics-InformedNeural Network (MPINN) based method for stress ISR (SRPINN) was proposed. Byintroducing the constraints of physical information, the new method does notrequire paired stress images for training and can increase the resolution ofstress images to any multiple. This enables a multiscale analysis of the stressconcentration regions at phase boundaries. Finally, we performed stressanalysis on TRMs with different phase volume fractions and loading statesthrough transfer learning. The results show the proposed stress predictionframework has satisfactory accuracy and generalization ability.</description>
      <author>example@mail.com (Tengfei Xing, Xiaodan Ren, Jie Li)</author>
      <guid isPermaLink="false">2504.18854v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Relative Contrastive Learning for Sequential Recommendation with Similarity-based Positive Pair Selection</title>
      <link>http://arxiv.org/abs/2504.19178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code can be found at https://github.com/Cloudcatcher888/RCL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为RCL的相对对比学习框架，用于序列推荐模型的训练，以改善对比学习的效果。&lt;h4&gt;背景&lt;/h4&gt;现有的对比学习方法通常依赖于数据增强策略来创建正样本和促进表示不变性，但可能会无意中改变用户意图。&lt;h4&gt;目的&lt;/h4&gt;解决监督对比学习（SCL）方法由于同目标序列稀缺而缺乏足够信号的问题。&lt;h4&gt;方法&lt;/h4&gt;提出使用相似序列（具有不同目标项目）作为额外的正样本，并引入RCL框架。RCL包括双级正样本选择模块和相对对比学习模块，分别用于选择强正样本和弱正样本，以及确保每个序列更接近其强正样本。&lt;h4&gt;主要发现&lt;/h4&gt;将RCL应用于两个主流的深度学习序列推荐模型，实验结果表明，在五个公共数据集和一个私有数据集上，RCL的平均性能比最先进的序列推荐方法提高了4.88%。&lt;h4&gt;结论&lt;/h4&gt;RCL能够有效提高序列推荐模型的性能，是一个有潜力的新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3627673.3679681&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Learning (CL) enhances the training of sequential recommendation(SR) models through informative self-supervision signals. Existing methodsoften rely on data augmentation strategies to create positive samples andpromote representation invariance. Some strategies such as item reordering anditem substitution may inadvertently alter user intent. Supervised ContrastiveLearning (SCL) based methods find an alternative to augmentation-based CLmethods by selecting same-target sequences (interaction sequences with the sametarget item) to form positive samples. However, SCL-based methods suffer fromthe scarcity of same-target sequences and consequently lack enough signals forcontrastive learning. In this work, we propose to use similar sequences (withdifferent target items) as additional positive samples and introduce a RelativeContrastive Learning (RCL) framework for sequential recommendation. RCLcomprises a dual-tiered positive sample selection module and a relativecontrastive learning module. The former module selects same-target sequences asstrong positive samples and selects similar sequences as weak positive samples.The latter module employs a weighted relative contrastive loss, ensuring thateach sequence is represented closer to its strong positive samples than itsweak positive samples. We apply RCL on two mainstream deep learning-based SRmodels, and our empirical results reveal that RCL can achieve 4.88% improvementaveragely than the state-of-the-art SR methods on five public datasets and oneprivate dataset.</description>
      <author>example@mail.com (Zhikai Wang, Yanyan Shen, Zexi Zhang, Li He, Yichun Li, Hao Gu, Yinghua Zhang)</author>
      <guid isPermaLink="false">2504.19178v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>FiberKAN: Kolmogorov-Arnold Networks for Nonlinear Fiber Optics</title>
      <link>http://arxiv.org/abs/2504.18833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Kolmogorov-Arnold网络（KAN）的人工智能科学（AI4S）框架FiberKAN，用于非线性光纤的科学研究与动态特性描述。&lt;h4&gt;背景&lt;/h4&gt;尽管许多系统动力学已经从严格的原理推导出理论，但仍有大量复杂的动力学尚未被发现和描述，这阻碍了相关领域科学进步。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种新的AI4S框架，用于科学发现和动态特性描述。&lt;h4&gt;方法&lt;/h4&gt;提出了FiberKAN框架，该框架使用KAN而非传统的多层感知器（MLP）结构，并具有可训练和透明的激活函数，增强了网络的物理可解释性和非线性特征描述能力。&lt;h4&gt;主要发现&lt;/h4&gt;KAN可以有效地发现和描述不同影响下的显式、隐式和非解析解，并且在与MLP具有等效可训练参数规模的情况下，性能更优。&lt;h4&gt;结论&lt;/h4&gt;这项工作突出了KAN的变革潜力，将其确立为AI4S的先驱范式，推动了非线性光纤光学领域的进步，并在广泛的科学和工程学科中促进了创新。&lt;h4&gt;翻译&lt;/h4&gt;Scientific discovery and dynamic characterization of the physical system play a critical role in understanding, learning, and modeling the physical phenomena and behaviors in various fields. Although theories and laws of many system dynamics have been derived from rigorous first principles, there are still a considerable number of complex dynamics that have not yet been discovered and characterized, which hinders the progress of science in corresponding fields. To address these challenges, artificial intelligence for science (AI4S) has emerged as a burgeoning research field. In this paper, a Kolmogorov-Arnold Network (KAN)-based AI4S framework named FiberKAN is proposed for scientific discovery and dynamic characterization of nonlinear fiber optics. Unlike the classic multi-layer perceptron (MLP) structure, the trainable and transparent activation functions in KAN make the network have stronger physical interpretability and nonlinear characterization abilities. Multiple KANs are established for fiber-optic system dynamics under various physical effects. Results show that KANs can well discover and characterize the explicit, implicit, and non-analytical solutions under different effects, and achieve better performance than MLPs with the equivalent scale of trainable parameters. Moreover, the effectiveness, computational cost, interactivity, noise resistance, transfer learning ability, and comparison between related algorithms in fiber-optic systems are also studied and analyzed. This work highlights the transformative potential of KAN, establishing it as a pioneering paradigm in AI4S that propels advancements in nonlinear fiber optics, and fosters groundbreaking innovations across a broad spectrum of scientific and engineering disciplines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scientific discovery and dynamic characterization of the physical system playa critical role in understanding, learning, and modeling the physical phenomenaand behaviors in various fields. Although theories and laws of many systemdynamics have been derived from rigorous first principles, there are still aconsiderable number of complex dynamics that have not yet been discovered andcharacterized, which hinders the progress of science in corresponding fields.To address these challenges, artificial intelligence for science (AI4S) hasemerged as a burgeoning research field. In this paper, a Kolmogorov-ArnoldNetwork (KAN)-based AI4S framework named FiberKAN is proposed for scientificdiscovery and dynamic characterization of nonlinear fiber optics. Unlike theclassic multi-layer perceptron (MLP) structure, the trainable and transparentactivation functions in KAN make the network have stronger physicalinterpretability and nonlinear characterization abilities. Multiple KANs areestablished for fiber-optic system dynamics under various physical effects.Results show that KANs can well discover and characterize the explicit,implicit, and non-analytical solutions under different effects, and achievebetter performance than MLPs with the equivalent scale of trainable parameters.Moreover, the effectiveness, computational cost, interactivity, noiseresistance, transfer learning ability, and comparison between relatedalgorithms in fiber-optic systems are also studied and analyzed. This workhighlights the transformative potential of KAN, establishing it as a pioneeringparadigm in AI4S that propels advancements in nonlinear fiber optics, andfosters groundbreaking innovations across a broad spectrum of scientific andengineering disciplines.</description>
      <author>example@mail.com (Xiaotian Jiang, Min Zhang, Xiao Luo, Zelai Yu, Yiming Meng, Danshi Wang)</author>
      <guid isPermaLink="false">2504.18833v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Geometry-Informed Neural Operator Transformer</title>
      <link>http://arxiv.org/abs/2504.19452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GINOT的机器学习代理模型，该模型结合了transformer架构和神经算子框架，能够对任意几何形状进行正向预测，具有计算效率高、模拟速度快的特点。&lt;h4&gt;背景&lt;/h4&gt;传统的数值方法在需要重复求解偏微分方程的问题上计算效率较低，而基于机器学习的代理模型则提供了显著的计算效率提升。&lt;h4&gt;目的&lt;/h4&gt;提出GINOT模型，以实现对任意几何形状的高精度正向预测。&lt;h4&gt;方法&lt;/h4&gt;GINOT通过采样和分组机制以及注意力机制对几何形状的点云进行编码，确保对点顺序和填充的不变性，同时保持对点密度变化的鲁棒性。几何信息通过注意力机制与解的查询点无缝集成。&lt;h4&gt;主要发现&lt;/h4&gt;GINOT在多个具有挑战性的数据集上进行了验证，展示了其在复杂和任意2D和3D几何形状上的高精度和强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;GINOT模型在计算效率和预测精度方面具有显著优势，适用于需要重复计算偏微分方程的问题。&lt;h4&gt;翻译&lt;/h4&gt;Machine-learning-based surrogate models offer significant computational efficiency and faster simulations compared to traditional numerical methods, especially for problems requiring repeated evaluations of partial differential equations. This work introduces the Geometry-Informed Neural Operator Transformer (GINOT), which integrates the transformer architecture with the neural operator framework to enable forward predictions for arbitrary geometries. GINOT encodes the surface points cloud of a geometry using a sampling and grouping mechanism combined with an attention mechanism, ensuring invariance to point order and padding while maintaining robustness to variations in point density. The geometry information is seamlessly integrated with query points in the solution decoder through the attention mechanism. The performance of GINOT is validated on multiple challenging datasets, showcasing its high accuracy and strong generalization capabilities for complex and arbitrary 2D and 3D geometries.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learning-based surrogate models offer significant computationalefficiency and faster simulations compared to traditional numerical methods,especially for problems requiring repeated evaluations of partial differentialequations. This work introduces the Geometry-Informed Neural OperatorTransformer (GINOT), which integrates the transformer architecture with theneural operator framework to enable forward predictions for arbitrarygeometries. GINOT encodes the surface points cloud of a geometry using asampling and grouping mechanism combined with an attention mechanism, ensuringinvariance to point order and padding while maintaining robustness tovariations in point density. The geometry information is seamlessly integratedwith query points in the solution decoder through the attention mechanism. Theperformance of GINOT is validated on multiple challenging datasets, showcasingits high accuracy and strong generalization capabilities for complex andarbitrary 2D and 3D geometries.</description>
      <author>example@mail.com (Qibang Liu, Vincient Zhong, Hadi Meidani, Diab Abueidda, Seid Koric, Philippe Geubelle)</author>
      <guid isPermaLink="false">2504.19452v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Learning Efficiency Meets Symmetry Breaking</title>
      <link>http://arxiv.org/abs/2504.19738v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于图神经网络的学习型规划器，该规划器能够学习适用于大搜索空间的搜索指导，但其在处理对称性方面的潜力尚未得到充分探索。&lt;h4&gt;背景&lt;/h4&gt;现有的学习型规划器虽然能够学习适用于大搜索空间的搜索指导，但尚未探索如何处理搜索空间中的对称性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够检测对称性并提高学习效率的图表示方法，以及两种剪枝方法（动作剪枝和状态剪枝）来管理搜索过程中的对称性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种图表示规划问题的方法，并整合了动作剪枝和状态剪枝技术，以提高规划器的学习效率和对称性处理能力。&lt;h4&gt;主要发现&lt;/h4&gt;将提出的方法整合到Fast Downward中，在最新的IPC学习轨迹数据集上首次成功超越LAMA。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在处理规划问题的对称性方面取得了显著成效。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a learning-based planner leveraging Graph Neural Networks, which can learn search guidance applicable to large search spaces, yet the potential to address symmetries remains largely unexplored. In this paper, we introduce a graph representation of planning problems, which combines learning efficiency with the ability to detect symmetries, along with two pruning methods, action pruning and state pruning, designed to manage symmetries during search. The integration of these techniques into Fast Downward achieves a first-time success over LAMA on the latest IPC learning track dataset. Code is released at: https://github.com/bybeye/Distincter.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning-based planners leveraging Graph Neural Networks can learn searchguidance applicable to large search spaces, yet their potential to addresssymmetries remains largely unexplored. In this paper, we introduce a graphrepresentation of planning problems allying learning efficiency with theability to detect symmetries, along with two pruning methods, action pruningand state pruning, designed to manage symmetries during search. The integrationof these techniques into Fast Downward achieves a first-time success over LAMAon the latest IPC learning track dataset. Code is released at:https://github.com/bybeye/Distincter.</description>
      <author>example@mail.com (Yingbin Bai, Sylvie Thiebaux, Felipe Trevizan)</author>
      <guid isPermaLink="false">2504.19738v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>ALF: Advertiser Large Foundation Model for Multi-Modal Advertiser Understanding</title>
      <link>http://arxiv.org/abs/2504.18785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ALF的多模态Transformer架构，用于理解广告商在文本、图像、视频和结构化数据模态中的行为和意图。&lt;h4&gt;背景&lt;/h4&gt;研究者们在分析广告商行为和意图方面面临挑战，需要一种能够处理多种数据模态的模型。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效理解广告商行为和意图的模型，以应用于欺诈检测、违规政策识别和广告商相似度匹配等任务。&lt;h4&gt;方法&lt;/h4&gt;ALF通过对比学习和多任务优化，创建统一的广告商表示，捕捉内容和行为模式。其架构结合了多模态变换、样本间注意力机制、频谱归一化投影和校准概率输出。&lt;h4&gt;主要发现&lt;/h4&gt;ALF在关键任务上实现了最先进的性能，如欺诈检测、违规政策识别和广告商相似度匹配。在生产部署中，ALF将滥用检测任务中的误报率降低了90%，同时保持了99.8%的精确度。&lt;h4&gt;结论&lt;/h4&gt;ALF的有效性源于其新颖的多模态变换组合、样本间注意力机制、频谱归一化投影和校准概率输出的结合。&lt;h4&gt;翻译&lt;/h4&gt;We present ALF (Advertiser Large Foundation model), a multi-modal transformer architecture for understanding advertiser behavior and intent across text, image, video and structured data modalities. Through contrastive learning and multi-task optimization, ALF creates unified advertiser representations that capture both content and behavioral patterns. Our model achieves state-of-the-art performance on critical tasks including fraud detection, policy violation identification, and advertiser similarity matching. In production deployment, ALF reduces false positives by 90% while maintaining 99.8% precision on abuse detection tasks. The architecture's effectiveness stems from its novel combination of multi-modal transformations, inter-sample attention mechanism, spectrally normalized projections, and calibrated probabilistic outputs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present ALF (Advertiser Large Foundation model), a multi-modal transformerarchitecture for understanding advertiser behavior and intent across text,image, video and structured data modalities. Through contrastive learning andmulti-task optimization, ALF creates unified advertiser representations thatcapture both content and behavioral patterns. Our model achievesstate-of-the-art performance on critical tasks including fraud detection,policy violation identification, and advertiser similarity matching. Inproduction deployment, ALF reduces false positives by 90% while maintaining99.8% precision on abuse detection tasks. The architecture's effectivenessstems from its novel combination of multi-modal transformations, inter-sampleattention mechanism, spectrally normalized projections, and calibratedprobabilistic outputs.</description>
      <author>example@mail.com (Santosh Rajagopalan, Jonathan Vronsky, Songbai Yan, S. Alireza Golestaneh, Shubhra Chandra, Min Zhou)</author>
      <guid isPermaLink="false">2504.18785v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>A Real-Time Event-Based Normal Flow Estimator</title>
      <link>http://arxiv.org/abs/2504.19417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种实时、异步的事件驱动正常流估计器，通过优化实现提升了性能。&lt;h4&gt;背景&lt;/h4&gt;传统方法将事件切片视为3D点云，编码局部几何为固定长度向量，使用多层感知器预测正常流，但计算复杂度较高。&lt;h4&gt;目的&lt;/h4&gt;开发一种更高效的事件相机正常流预测方法。&lt;h4&gt;方法&lt;/h4&gt;该方法利用事件坐标为整数的特性，将表示步骤重构为池化操作，降低计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;该方法支持实时正常流预测，使用1 GB的CUDA内存，在RTX 3070上每秒处理400万个正常流，在RTX A5000上每秒处理600万个。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种高效的事件相机正常流预测方法，并发布了CUDA实现和Python接口。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种实时、异步的事件驱动正常流估计器。它遵循与《直接从事件邻域学习正常流》相同的算法，但具有更优化的实现。原始方法将事件切片视为3D点云，将每个事件的局部几何编码为固定长度的向量，并使用多层感知器来预测正常流。它通过将邻接矩阵与特征矩阵相乘来构建表示，从而在事件数量上具有二次时间复杂度。相比之下，我们利用事件坐标是整数的事实，将表示步骤重构成池化操作。这实现了与邻接矩阵相同的效果，但具有更低的计算成本。因此，我们的方法支持事件相机的实时正常流预测。我们的估计器使用1 GB的CUDA内存，在RTX 3070上每秒处理4百万个正常流，在RTX A5000上每秒处理600万个。我们在https://github.com/dhyuan99/VecKM_flow_cpp上发布了CUDA实现和Python接口。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a real-time, asynchronous, event-based normal flowestimator. It follows the same algorithm as Learning Normal Flow Directly FromEvent Neighborhoods, but with a more optimized implementation. The originalmethod treats event slices as 3D point clouds, encodes each event's localgeometry into a fixed-length vector, and uses a multi-layer perceptron topredict normal flow. It constructs representations by multiplying an adjacencymatrix with a feature matrix, resulting in quadratic time complexity withrespect to the number of events. In contrast, we leverage the fact that eventcoordinates are integers and reformulate the representation step as a poolingoperation. This achieves the same effect as the adjacency matrix but with muchlower computational cost. As a result, our method supports real-time normalflow prediction on event cameras. Our estimator uses 1 GB of CUDA memory andruns at 4 million normal flows per second on an RTX 3070, or 6 million persecond on an RTX A5000. We release the CUDA implementation along with a Pythoninterface at https://github.com/dhyuan99/VecKM_flow_cpp.</description>
      <author>example@mail.com (Dehao Yuan, Cornelia Fermüller)</author>
      <guid isPermaLink="false">2504.19417v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Segmenting Objectiveness and Task-awareness Unknown Region for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.19183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SOTA的新框架，用于自动驾驶场景中的道路场景分割，该框架通过语义融合块（SFB）增强客观性分割，并通过场景理解引导的提示上下文适配器（SG-PCA）过滤与道路导航任务无关的异常。&lt;h4&gt;背景&lt;/h4&gt;随着基于transformer架构和大型语言模型（LLMs）的出现，道路场景感知的准确性得到了显著提高。然而，现有的道路场景分割方法主要在闭集数据上训练，导致对分布外（OOD）对象的检测能力不足。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一局限性，本文提出了SOTA框架，旨在提高自动驾驶场景中道路场景分割的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;SOTA通过语义融合块（SFB）增强分割的客观性，并通过场景理解引导的提示上下文适配器（SG-PCA）过滤与道路导航任务无关的异常。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准数据集上的广泛实证评估表明，SOTA在多个检测器上持续提高OOD检测性能，实现了鲁棒和准确的分割结果。&lt;h4&gt;结论&lt;/h4&gt;SOTA框架在自动驾驶场景中的道路场景分割方面具有显著优势，能够有效提高异常检测的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;With the emergence of transformer-based architectures and large language models (LLMs), the accuracy of road scene perception has substantially advanced. Nonetheless, current road scene segmentation approaches are predominantly trained on closed-set data, resulting in insufficient detection capabilities for out-of-distribution (OOD) objects. To overcome this limitation, road anomaly detection methods have been proposed. However, existing methods primarily depend on image inpainting and OOD distribution detection techniques, facing two critical issues: (1) inadequate consideration of the objectiveness attributes of anomalous regions, causing incomplete segmentation when anomalous objects share similarities with known classes, and (2) insufficient attention to environmental constraints, leading to the detection of anomalies irrelevant to autonomous driving tasks. In this paper, we propose a novel framework termed Segmenting Objectiveness and Task-Awareness (SOTA) for autonomous driving scenes. Specifically, SOTA enhances the segmentation of objectiveness through a Semantic Fusion Block (SFB) and filters anomalies irrelevant to road navigation tasks using a Scene-understanding Guided Prompt-Context Adaptor (SG-PCA). Extensive empirical evaluations on multiple benchmark datasets, including Fishyscapes Lost and Found, Segment-Me-If-You-Can, and RoadAnomaly, demonstrate that the proposed SOTA consistently improves OOD detection performance across diverse detectors, achieving robust and accurate segmentation outcomes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the emergence of transformer-based architectures and large languagemodels (LLMs), the accuracy of road scene perception has substantiallyadvanced. Nonetheless, current road scene segmentation approaches arepredominantly trained on closed-set data, resulting in insufficient detectioncapabilities for out-of-distribution (OOD) objects. To overcome thislimitation, road anomaly detection methods have been proposed. However,existing methods primarily depend on image inpainting and OOD distributiondetection techniques, facing two critical issues: (1) inadequate considerationof the objectiveness attributes of anomalous regions, causing incompletesegmentation when anomalous objects share similarities with known classes, and(2) insufficient attention to environmental constraints, leading to thedetection of anomalies irrelevant to autonomous driving tasks. In this paper,we propose a novel framework termed Segmenting Objectiveness and Task-Awareness(SOTA) for autonomous driving scenes. Specifically, SOTA enhances thesegmentation of objectiveness through a Semantic Fusion Block (SFB) and filtersanomalies irrelevant to road navigation tasks using a Scene-understandingGuided Prompt-Context Adaptor (SG-PCA). Extensive empirical evaluations onmultiple benchmark datasets, including Fishyscapes Lost and Found,Segment-Me-If-You-Can, and RoadAnomaly, demonstrate that the proposed SOTAconsistently improves OOD detection performance across diverse detectors,achieving robust and accurate segmentation outcomes.</description>
      <author>example@mail.com (Mi Zheng, Guanglei Yang, Zitong Huang, Zhenhua Guo, Kevin Han, Wangmeng Zuo)</author>
      <guid isPermaLink="false">2504.19183v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Explaining Vision GNNs: A Semantic and Visual Analysis of Graph-based Image Classification</title>
      <link>http://arxiv.org/abs/2504.19682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 3 figures, accepted for presentation at  xAI-World-Conference 2025, code is available at  https://github.com/nickhaidos/Vision-GNNs-Explainer&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）在视觉任务中的应用，分析了GNN图像分类器在不同层形成的图的语义一致性，并比较了标准与对抗环境下的解释性，通过可视化技术揭示了模型的解释性。&lt;h4&gt;背景&lt;/h4&gt;GNNs作为卷积方法在图像分类等视觉任务中的替代方案，利用图像块表示，通过块相似性或分类相关性建立边。&lt;h4&gt;目的&lt;/h4&gt;分析GNN图像分类器在不同层形成的图的语义一致性，评估其保留物体结构和有意义关系的能力。&lt;h4&gt;方法&lt;/h4&gt;通过量化层间图连接反映语义相似性和空间一致性的程度，比较标准与对抗环境下的解释性，使用基于热图的可视化技术展示信息流动。&lt;h4&gt;主要发现&lt;/h4&gt;模型的决策过程可以有效地解释，但其推理过程不一定与人类感知一致，尤其是在深层。&lt;h4&gt;结论&lt;/h4&gt;GNNs在视觉任务中的应用具有较高的解释性，但其推理过程与人类感知存在差异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as an efficient alternative toconvolutional approaches for vision tasks such as image classification,leveraging patch-based representations instead of raw pixels. These methodsconstruct graphs where image patches serve as nodes, and edges are establishedbased on patch similarity or classification relevance. Despite theirefficiency, the explainability of GNN-based vision models remainsunderexplored, even though graphs are naturally interpretable. In this work, weanalyze the semantic consistency of the graphs formed at different layers ofGNN-based image classifiers, focusing on how well they preserve objectstructures and meaningful relationships. A comprehensive analysis is presentedby quantifying the extent to which inter-layer graph connections reflectsemantic similarity and spatial coherence. Explanations from standard andadversarial settings are also compared to assess whether they reflect theclassifiers' robustness. Additionally, we visualize the flow of informationacross layers through heatmap-based visualization techniques, therebyhighlighting the models' explainability. Our findings demonstrate that thedecision-making processes of these models can be effectively explained, whilealso revealing that their reasoning does not necessarily align with humanperception, especially in deeper layers.</description>
      <author>example@mail.com (Nikolaos Chaidos, Angeliki Dimitriou, Nikolaos Spanos, Athanasios Voulodimos, Giorgos Stamou)</author>
      <guid isPermaLink="false">2504.19682v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Co-Training with Active Contrastive Learning and Meta-Pseudo-Labeling on 2D Projections for Deep Semi-Supervised Learning</title>
      <link>http://arxiv.org/abs/2504.18666v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Journal of the Brazilian Computer Society (JBCS)  [https://journals-sol.sbc.org.br]&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为active-DeepFA的方法，用于在标注数据稀缺、未标注数据丰富的情况下训练深度学习模型。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型的训练面临的一个主要挑战是准确标注数据的有限可用性，特别是在数据标注耗时且易出错的任务中。&lt;h4&gt;目的&lt;/h4&gt;提出active-DeepFA方法，以有效地结合聚类（CL）、基于教师-学生的元伪标签（meta-pseudo-labeling）和主动学习（AL）来训练非预训练的CNN架构，用于图像分类。&lt;h4&gt;方法&lt;/h4&gt;该方法将DeepFA集成到协同训练设置中，实现两个合作网络以减轻伪标签的确认偏差。它通过监督CL预热网络，然后定期进行标签传播和伪标签交换，同时将最有意义的样本标注并添加到标注集中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在三个具有挑战性的生物图像数据集上进行了评估，仅使用5%的标注样本，提高了基线并优于六种其他SoTA方法。此外，它通过仅使用3%的标注数据就达到了与对手相当的结果，从而减少了标注工作量。&lt;h4&gt;结论&lt;/h4&gt;active-DeepFA方法在标注数据稀缺的情况下，能够有效提高图像分类的准确率，并显著减少标注工作的工作量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A major challenge that prevents the training of DL models is the limitedavailability of accurately labeled data. This shortcoming is highlighted inareas where data annotation becomes a time-consuming and error-prone task. Inthis regard, SSL tackles this challenge by capitalizing on scarce labeled andabundant unlabeled data; however, SoTA methods typically depend on pre-trainedfeatures and large validation sets to learn effective representations forclassification tasks. In addition, the reduced set of labeled data is oftenrandomly sampled, neglecting the selection of more informative samples. Here,we present active-DeepFA, a method that effectively combines CL,teacher-student-based meta-pseudo-labeling and AL to train non-pretrained CNNarchitectures for image classification in scenarios of scarcity of labeled andabundance of unlabeled data. It integrates DeepFA into a co-training setup thatimplements two cooperative networks to mitigate confirmation bias frompseudo-labels. The method starts with a reduced set of labeled samples bywarming up the networks with supervised CL. Afterward and at regular epochintervals, label propagation is performed on the 2D projections of thenetworks' deep features. Next, the most reliable pseudo-labels are exchangedbetween networks in a cross-training fashion, while the most meaningful samplesare annotated and added into the labeled set. The networks independentlyminimize an objective loss function comprising supervised contrastive,supervised and semi-supervised loss components, enhancing the representationstowards image classification. Our approach is evaluated on three challengingbiological image datasets using only 5% of labeled samples, improving baselinesand outperforming six other SoTA methods. In addition, it reduces annotationeffort by achieving comparable results to those of its counterparts with only3% of labeled data.</description>
      <author>example@mail.com (David Aparco-Cardenas, Jancarlo F. Gomes, Alexandre X. Falcão, Pedro J. de Rezende)</author>
      <guid isPermaLink="false">2504.18666v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Intelligent4DSE: Optimizing High-Level Synthesis Design Space Exploration with Graph Neural Networks and Large Language Models</title>
      <link>http://arxiv.org/abs/2504.19649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CoGNNs-LLMEA的框架，用于优化HLS设计空间探索过程，通过结合图神经网络、任务自适应消息传递和大型语言模型增强的进化算法，提高预测准确性，减少预测误差。&lt;h4&gt;背景&lt;/h4&gt;HLS设计空间探索是电子设计自动化中的一个优化过程，旨在通过系统性地探索高级设计配置来实现性能、面积和功耗（PPA）平衡的硬件实现。&lt;h4&gt;目的&lt;/h4&gt;优化HLS预测任务，提高预测准确性，减少预测误差，同时减少对领域特定知识的依赖。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为CoGNNs-LLMEA的框架，该框架集成了图神经网络、任务自适应消息传递和大型语言模型增强的进化算法。CoGNNs直接利用编译器前端处理后的源代码生成的中间表示，预测结果质量（QoR），无需调用HLS工具。&lt;h4&gt;主要发现&lt;/h4&gt;CoGNNs在HLS后的QoR预测中达到了最先进的预测准确性，与基线模型相比，平均预测误差在延迟方面降低了2.8倍，在资源利用率方面降低了3.4倍。&lt;h4&gt;结论&lt;/h4&gt;CoGNNs-LLMEA框架能够有效提高HLS设计空间探索的预测准确性，减少预测误差，并降低对领域特定知识的依赖。&lt;h4&gt;翻译&lt;/h4&gt;摘要：高级综合（HLS）设计空间探索（DSE）是电子设计自动化（EDA）中的一个优化过程，它系统地探索高级设计配置，以实现平衡性能、面积和功耗（PPA）的帕累托最优硬件实现。为了优化此过程，HLS预测任务通常采用消息传递神经网络（MPNN），利用复杂的架构以实现高精度。这些预测器作为DSE过程中的评估者，有效地绕过了传统上由HLS工具要求的耗时估计。然而，现有的模型往往优先考虑结构复杂性和训练损失的优化，而忽略了特定任务的特性。此外，尽管进化算法在DSE中得到广泛应用，但它们通常需要大量的领域特定知识来设计有效的交叉和变异算子。为了解决这些限制，我们提出了一种名为CoGNNs-LLMEA的框架，该框架将图神经网络与任务自适应消息传递和大型语言模型增强的进化算法相结合。作为预测模型，CoGNNs直接利用源代码在编译器前端处理后的中间表示，能够在不调用HLS工具的情况下预测结果质量（QoR）。由于其强大的任务适应性，CoGNNs可以调整以预测HLS后和实现后的结果，有效地弥合了高级抽象和物理实现特性之间的差距。CoGNNs在HLS后的QoR预测中实现了最先进的预测准确性，与基线模型相比，平均预测误差在延迟方面降低了2.8倍，在资源利用率方面降低了3.4倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-level synthesis (HLS) design space exploration (DSE) is an optimizationprocess in electronic design automation (EDA) that systematically exploreshigh-level design configurations to achieve Pareto-optimal hardwareimplementations balancing performance, area, and power (PPA). To optimize thisprocess, HLS prediction tasks often employ message-passing neural networks(MPNNs), leveraging complex architectures to achieve high accuracy. Thesepredictors serve as evaluators in the DSE process, effectively bypassing thetime-consuming estimations traditionally required by HLS tools. However,existing models often prioritize structural complexity and minimization oftraining loss, overlooking task-specific characteristics. Additionally, whileevolutionary algorithms are widely used in DSE, they typically requireextensive domain-specific knowledge to design effective crossover and mutationoperators. To address these limitations, we propose CoGNNs-LLMEA, a frameworkthat integrates a graph neural network with task-adaptive message passing and alarge language model-enhanced evolutionary algorithm. As a predictive model,CoGNNs directly leverages intermediate representations generated from sourcecode after compiler front-end processing, enabling prediction of quality ofresults (QoR) without invoking HLS tools. Due to its strong adaptability totasks, CoGNNs can be tuned to predict post-HLS and post-implementationoutcomes, effectively bridging the gap between high-level abstractions andphysical implementation characteristics. CoGNNs achieves state-of-the-artprediction accuracy in post-HLS QoR prediction, reducing mean prediction errorsby 2.8$\times$ for latency and 3.4$\times$ for resource utilization compared tobaseline models.</description>
      <author>example@mail.com (Lei Xu, Shanshan Wang, Emmanuel Casseau, Chenglong Xiao)</author>
      <guid isPermaLink="false">2504.19649v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>CLR-Wire: Towards Continuous Latent Representations for 3D Curve Wireframe Generation</title>
      <link>http://arxiv.org/abs/2504.19174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SIGGRAPH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CLR-Wire是一种基于3D曲线的线框生成框架，它将几何和拓扑整合到一个统一的连续潜在表示中。&lt;h4&gt;背景&lt;/h4&gt;传统方法将顶点、边和面解耦，而CLR-Wire将曲线及其拓扑连接编码为神经网络参数曲线，并使用注意力驱动的变分自编码器（VAE）将它们映射到连续且固定长度的潜在空间。&lt;h4&gt;目的&lt;/h4&gt;CLR-Wire旨在提供一种能够同时学习几何和拓扑的统一方法，并生成高质量的线框。&lt;h4&gt;方法&lt;/h4&gt;CLR-Wire使用流匹配模型将高斯噪声映射到潜在空间，然后解码为完整的3D线框。它支持无条件生成和基于点云或图像输入的生成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与最先进的生成方法相比，CLR-Wire在准确性、新颖性和多样性方面有显著提升。&lt;h4&gt;结论&lt;/h4&gt;CLR-Wire为CAD设计、几何重建和3D内容创建提供了一种高效且全面的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为CLR-Wire的新型框架，该框架用于基于3D曲线的线框生成，它将几何和拓扑整合到一个统一的连续潜在表示中。与将顶点、边和面解耦的传统方法不同，CLR-Wire将曲线及其拓扑连接编码为神经网络参数曲线，并使用注意力驱动的变分自编码器（VAE）将它们映射到连续且固定长度的潜在空间。这种统一的方法促进了几何和拓扑的联合学习和生成。为了生成线框，我们使用流匹配模型将高斯噪声逐步映射到这些潜在空间，然后解码为完整的3D线框。我们的方法提供了对复杂形状和不规则拓扑的精细建模，并支持无条件生成和基于点云或图像输入的生成。实验结果表明，与最先进的生成方法相比，我们的方法在准确性、新颖性和多样性方面取得了显著提高，为CAD设计、几何重建和3D内容创作提供了一种高效且全面的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce CLR-Wire, a novel framework for 3D curve-based wireframegeneration that integrates geometry and topology into a unified ContinuousLatent Representation. Unlike conventional methods that decouple vertices,edges, and faces, CLR-Wire encodes curves as Neural Parametric Curves alongwith their topological connectivity into a continuous and fixed-length latentspace using an attention-driven variational autoencoder (VAE). This unifiedapproach facilitates joint learning and generation of both geometry andtopology. To generate wireframes, we employ a flow matching model toprogressively map Gaussian noise to these latents, which are subsequentlydecoded into complete 3D wireframes. Our method provides fine-grained modelingof complex shapes and irregular topologies, and supports both unconditionalgeneration and generation conditioned on point cloud or image inputs.Experimental results demonstrate that, compared with state-of-the-artgenerative approaches, our method achieves substantial improvements inaccuracy, novelty, and diversity, offering an efficient and comprehensivesolution for CAD design, geometric reconstruction, and 3D content creation.</description>
      <author>example@mail.com (Xueqi Ma, Yilin Liu, Tianlong Gao, Qirui Huang, Hui Huang)</author>
      <guid isPermaLink="false">2504.19174v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>If Concept Bottlenecks are the Question, are Foundation Models the Answer?</title>
      <link>http://arxiv.org/abs/2504.19774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了概念瓶颈模型（CBMs），这是一种结合高性能和先验可解释性的神经网络。通过将输入映射到高级概念并使用这些概念解决下游任务，CBMs旨在提高可解释性。然而，模型性能和可解释性依赖于学习到的概念质量，而高质量概念的学习往往依赖于昂贵的专家标注。本文通过实验分析了使用弱监督的VLM-CBM架构对学习到的概念质量的影响。&lt;h4&gt;背景&lt;/h4&gt;概念瓶颈模型（CBMs）旨在结合高性能和可解释性，通过将输入映射到高级概念来解决下游任务。&lt;h4&gt;目的&lt;/h4&gt;研究使用弱监督的VLM-CBM架构对学习到的概念质量的影响，并分析其与专家标注的差异。&lt;h4&gt;方法&lt;/h4&gt;通过实验分析VLM-CBMs架构，使用一系列显著指标评估学习到的概念。&lt;h4&gt;主要发现&lt;/h4&gt;VLM监督与专家标注在任务上可能存在显著差异，概念准确性和质量之间没有强相关性。&lt;h4&gt;结论&lt;/h4&gt;VLM监督可以作为一种替代专家标注的方法，但需要根据具体任务调整以保持概念质量。&lt;h4&gt;翻译&lt;/h4&gt;Concept Bottleneck Models (CBMs) are neural networks designed to conjoin high-performance with ante-hoc interpretability. CBMs work by first mapping inputs (e.g., images) to high-level concepts (e.g., visible objects and their properties) and then use these to solve a downstream task (e.g., tagging or scoring an image) in an interpretable manner. Their performance and interpretability, however, hinge on the quality of the concepts they learn. The go-to strategy for ensuring good quality concepts is to leverage expert annotations, which are expensive to collect and seldom available in applications. Researchers have recently addressed this issue by introducing 'VLM-CBM' architectures that replace manual annotations with weak supervision from foundation models. It is however unclear what is the impact of doing so on the quality of the learned concepts. To answer this question, we put state-of-the-art VLM-CBMs to the test, analyzing their learned concepts empirically using a selection of significant metrics. Our results show that, depending on the task, VLM supervision can sensibly differ from expert annotations, and that concept accuracy and quality are not strongly correlated. Our code is available at https://github.com/debryu/CQA.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Concept Bottleneck Models (CBMs) are neural networks designed to conjoin highperformance with ante-hoc interpretability. CBMs work by first mapping inputs(e.g., images) to high-level concepts (e.g., visible objects and theirproperties) and then use these to solve a downstream task (e.g., tagging orscoring an image) in an interpretable manner. Their performance andinterpretability, however, hinge on the quality of the concepts they learn. Thego-to strategy for ensuring good quality concepts is to leverage expertannotations, which are expensive to collect and seldom available inapplications. Researchers have recently addressed this issue by introducing"VLM-CBM" architectures that replace manual annotations with weak supervisionfrom foundation models. It is however unclear what is the impact of doing so onthe quality of the learned concepts. To answer this question, we putstate-of-the-art VLM-CBMs to the test, analyzing their learned conceptsempirically using a selection of significant metrics. Our results show that,depending on the task, VLM supervision can sensibly differ from expertannotations, and that concept accuracy and quality are not strongly correlated.Our code is available at https://github.com/debryu/CQA.</description>
      <author>example@mail.com (Nicola Debole, Pietro Barbiero, Francesco Giannini, Andrea Passeggini, Stefano Teso, Emanuele Marconato)</author>
      <guid isPermaLink="false">2504.19774v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>An SE(3) Noise Model for Range-Azimuth-Elevation Sensors</title>
      <link>http://arxiv.org/abs/2504.19009v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了点云配准在状态估计中的应用，特别是Scan matching技术。分析了当前方法中协方差表示不准确和忽略传感器与车辆外部不确定性以及里程计不确定性对权重的影响。&lt;h4&gt;背景&lt;/h4&gt;Scan matching是一种在状态估计中广泛使用的技术，其中点云配准是一种加权最小二乘问题，其权重由测量点的逆协方差确定。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过开发一个基于矩阵李群的测距-方位-高度传感器模型来解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;该方法允许无缝地结合外部和里程计不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;文章展示了模拟示例和实际水下激光扫描收集的点云子图的结果，说明了新模型的有效性。&lt;h4&gt;结论&lt;/h4&gt;新模型能够更准确地处理Scan matching中的不确定性，提高估计的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scan matching is a widely used technique in state estimation. Point-cloudalignment, one of the most popular methods for scan matching, is a weightedleast-squares problem in which the weights are determined from the inversecovariance of the measured points. An inaccurate representation of thecovariance will affect the weighting of the least-squares problem. For example,if ellipsoidal covariance bounds are used to approximate the curved,"banana-shaped" noise characteristics of many scanning sensors, the weightingin the least-squares problem may be overconfident. Additionally,sensor-to-vehicle extrinsic uncertainty and odometry uncertainty during submapformation are two sources of uncertainty that are often overlooked in scanmatching applications, also likely contributing to overconfidence on the scanmatching estimate. This paper attempts to address these issues by developing amodel for range-azimuth-elevation sensors on matrix Lie groups. The modelallows for the seamless incorporation of extrinsic and odometry uncertainty.Illustrative results are shown both for a simulated example and for a realpoint-cloud submap collected with an underwater laser scanner.</description>
      <author>example@mail.com (Thomas Hitchcox, James Richard Forbes)</author>
      <guid isPermaLink="false">2504.19009v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Feature Fusion Revisited: Multimodal CTR Prediction for MMCTR Challenge</title>
      <link>http://arxiv.org/abs/2504.18961v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A technical report for the MMCTR Challenge held by EReL@MIR Workshop  at WWW 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了在Multimodal Large Language Models (MLLMs)快速发展的背景下，研究人员在推荐系统中的应用探索，以及针对提高信息检索任务中多模态表示学习效率的各种方法的实验。&lt;h4&gt;背景&lt;/h4&gt;MLLMs的快速发展促使研究人员探索其在推荐系统中的应用，但大型模型的高延迟给此类应用带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;EREL@MIR研讨会为提高多模态表示学习效率提供了实验机会，要求参赛者提交技术报告详细说明他们的方法和发现。&lt;h4&gt;方法&lt;/h4&gt;我们的团队在竞赛中获得了Task 2 - Winner (Multimodal CTR Prediction)的奖项，并在报告中详细介绍了我们的方法和关键发现。&lt;h4&gt;主要发现&lt;/h4&gt;提出了如何有效地将推荐信号整合到多模态表示中的几个研究方向。&lt;h4&gt;结论&lt;/h4&gt;公开了我们的实现代码库和训练模型权重。&lt;h4&gt;翻译&lt;/h4&gt;With the rapid advancement of Multimodal Large Language Models (MLLMs), an increasing number of researchers are exploring their application in recommendation systems. However, the high latency associated with large models presents a significant challenge for such use cases. The EReL@MIR workshop provided a valuable opportunity to experiment with various approaches aimed at improving the efficiency of multimodal representation learning for information retrieval tasks. As part of the competition's requirements, participants were mandated to submit a technical report detailing their methodologies and findings. Our team was honored to receive the award for Task 2 - Winner (Multimodal CTR Prediction). In this technical report, we present our methods and key findings. Additionally, we propose several directions for future work, particularly focusing on how to effectively integrate recommendation signals into multimodal representations. The codebase for our implementation is publicly available at: https://github.com/Lattice-zjj/MMCTR_Code, and the trained model weights can be accessed at: https://huggingface.co/FireFlyCourageous/MMCTR_DIN_MicroLens_1M_x1.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancement of Multimodal Large Language Models (MLLMs), anincreasing number of researchers are exploring their application inrecommendation systems. However, the high latency associated with large modelspresents a significant challenge for such use cases. The EReL@MIR workshopprovided a valuable opportunity to experiment with various approaches aimed atimproving the efficiency of multimodal representation learning for informationretrieval tasks. As part of the competition's requirements, participants weremandated to submit a technical report detailing their methodologies andfindings. Our team was honored to receive the award for Task 2 - Winner(Multimodal CTR Prediction). In this technical report, we present our methodsand key findings. Additionally, we propose several directions for future work,particularly focusing on how to effectively integrate recommendation signalsinto multimodal representations. The codebase for our implementation ispublicly available at: https://github.com/Lattice-zjj/MMCTR_Code, and thetrained model weights can be accessed at:https://huggingface.co/FireFlyCourageous/MMCTR_DIN_MicroLens_1M_x1.</description>
      <author>example@mail.com (Junjie Zhou)</author>
      <guid isPermaLink="false">2504.18961v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>A Universal Spin-Orbit-Coupled Hamiltonian Model for Accelerated Quantum Material Discovery</title>
      <link>http://arxiv.org/abs/2504.19586v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages,8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Uni-HamGNN的通用自旋轨道耦合（SOC）哈密顿量图神经网络，用于准确模拟复杂系统中的SOC效应，同时解决了传统密度泛函理论（DFT）计算需求高和现有机器学习框架可迁移性有限的问题。&lt;h4&gt;背景&lt;/h4&gt;在模拟复杂系统中的SOC效应时，DFT的计算需求高，且现有机器学习框架的可迁移性有限，导致准确建模成为一大挑战。&lt;h4&gt;目的&lt;/h4&gt;通过引入Uni-HamGNN，旨在解决高计算需求和有限的可迁移性问题，实现复杂系统中SOC效应的准确建模。&lt;h4&gt;方法&lt;/h4&gt;该方法将SOC哈密顿量分解为自旋无关项和SOC校正项，以保持SU(2)对称性，并显著降低参数需求。基于这种分解，提出了delta-learning策略来分别拟合两个组成部分，从而解决由它们之间的幅度差异引起的训练困难，并实现高效训练。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在SOC相关组件上实现了显著的准确性（平均绝对误差为0.0025 meV），并通过GNoME数据集的高通量筛选和2D谷电子材料和过渡金属二硫化物（TMD）异质结构的精确预测，展示了其广泛的应用性。&lt;h4&gt;结论&lt;/h4&gt;这一突破消除了对系统特定重新训练和高成本的SOC-DFT计算的需求，为量子材料的快速发现铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;The accurate modeling of spin-orbit coupling (SOC) effects in diverse complex systems remains a significant challenge due to the high computational demands of density functional theory (DFT) and the limited transferability of existing machine-learning frameworks. This study addresses these limitations by introducing Uni-HamGNN, a universal SOC Hamiltonian graph neural network that is applicable across the periodic table. By decomposing the SOC Hamiltonian into spin-independent and SOC correction terms, our approach preserves SU(2) symmetry while significantly reducing parameter requirements. Based on this decomposition, we propose a delta-learning strategy to separately fit the two components, thereby addressing the training difficulties caused by magnitude discrepancies between them and enabling efficient training. The model achieves remarkable accuracy (mean absolute error of 0.0025 meV for the SOC-related component) and demonstrates broad applicability through high-throughput screening of the GNoME dataset for topological insulators, as well as precise predictions for 2D valleytronic materials and transition metal dichalcogenide (TMD) heterostructures. This breakthrough eliminates the need for system-specific retraining and costly SOC-DFT calculations, paving the way for rapid discovery of quantum materials.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accurate modeling of spin-orbit coupling (SOC) effects in diverse complexsystems remains a significant challenge due to the high computational demandsof density functional theory (DFT) and the limited transferability of existingmachine-learning frameworks. This study addresses these limitations byintroducing Uni-HamGNN, a universal SOC Hamiltonian graph neural network thatis applicable across the periodic table. By decomposing the SOC Hamiltonianinto spin-independent and SOC correction terms, our approach preserves SU(2)symmetry while significantly reducing parameter requirements. Based on thisdecomposition, we propose a delta-learning strategy to separately fit the twocomponents, thereby addressing the training difficulties caused by magnitudediscrepancies between them and enabling efficient training. The model achievesremarkable accuracy (mean absolute error of 0.0025 meV for the SOC-relatedcomponent) and demonstrates broad applicability through high-throughputscreening of the GNoME dataset for topological insulators, as well as precisepredictions for 2D valleytronic materials and transition metal dichalcogenide(TMD) heterostructures. This breakthrough eliminates the need forsystem-specific retraining and costly SOC-DFT calculations, paving the way forrapid discovery of quantum materials.</description>
      <author>example@mail.com (Yang Zhong, Rui Wang, Xingao Gong, Hongjun Xiang)</author>
      <guid isPermaLink="false">2504.19586v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Graph Reinforcement Learning for QoS-Aware Load Balancing in Open Radio Access Networks</title>
      <link>http://arxiv.org/abs/2504.19499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in the proceedings of the 2025 IEEE International  Conference on Communications (ICC), Seventh Workshop on Data Driven  Intelligence for Networks and Systems (DDINS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图强化学习的QoS感知负载均衡方法，用于优化多频段O-RAN中GBR和BE流量的性能，同时满足QoS和资源约束。&lt;h4&gt;背景&lt;/h4&gt;下一代无线蜂窝网络需要提供卓越的服务质量，以支持新兴无线应用，这要求严格的性能保证，如链路层数据速率。&lt;h4&gt;目的&lt;/h4&gt;解决满足QoS要求的关键挑战，即防止小区拥塞，通过平衡负载确保每个小区有足够的无线资源来服务其指定的用户设备。&lt;h4&gt;方法&lt;/h4&gt;提出的方法基于图强化学习（GRL），将QoS感知负载均衡建模为马尔可夫决策过程，状态表示为图。QoS考虑因素集成到状态表示和奖励信号设计中。使用基于GNN架构的离策略对抗深度Q网络（DQN）训练负载均衡代理。&lt;h4&gt;主要发现&lt;/h4&gt;与两种基线方法相比，GRL解决方案的性能显著提高，包括QoS违规减少了53%，BE流量的第5百分位数速率提高了四倍。&lt;h4&gt;结论&lt;/h4&gt;该方法确保了负载均衡策略对节点（UE或小区）的顺序不变，能够灵活处理各种网络大小，并在负载均衡决策中考虑空间节点依赖性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Next-generation wireless cellular networks are expected to provideunparalleled Quality-of-Service (QoS) for emerging wireless applications,necessitating strict performance guarantees, e.g., in terms of link-level datarates. A critical challenge in meeting these QoS requirements is the preventionof cell congestion, which involves balancing the load to ensure sufficientradio resources are available for each cell to serve its designated UserEquipments (UEs). In this work, a novel QoS-aware Load Balancing (LB) approachis developed to optimize the performance of Guaranteed Bit Rate (GBR) and BestEffort (BE) traffic in a multi-band Open Radio Access Network (O-RAN) under QoSand resource constraints. The proposed solution builds on Graph ReinforcementLearning (GRL), a powerful framework at the intersection of Graph NeuralNetwork (GNN) and RL. The QoS-aware LB is modeled as a Markov Decision Process,with states represented as graphs. QoS consideration are integrated into bothstate representations and reward signal design. The LB agent is then trainedusing an off-policy dueling Deep Q Network (DQN) that leverages a GNN-basedarchitecture. This design ensures the LB policy is invariant to the ordering ofnodes (UE or cell), flexible in handling various network sizes, and capable ofaccounting for spatial node dependencies in LB decisions. Performance of theGRL-based solution is compared with two baseline methods. Results showsubstantial performance gains, including a $53\%$ reduction in QoS violationsand a fourfold increase in the 5th percentile rate for BE traffic.</description>
      <author>example@mail.com (Omid Semiari, Hosein Nikopour, Shilpa Talwar)</author>
      <guid isPermaLink="false">2504.19499v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Pixels2Points: Fusing 2D and 3D Features for Facial Skin Segmentation</title>
      <link>http://arxiv.org/abs/2504.19718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 4 figures, to be published in Eurographics 2025 as a short  paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的方法，用于在3D人脸扫描中准确区分皮肤和非皮肤几何形状，以提高人脸注册的质量。&lt;h4&gt;背景&lt;/h4&gt;由于在非皮肤区域（如头发、胡须、配饰）中扫描质量通常下降，现有的人脸注册方法难以处理这些问题。&lt;h4&gt;目的&lt;/h4&gt;提高人脸注册的质量，通过在扫描网格上准确区分皮肤和非皮肤区域。&lt;h4&gt;方法&lt;/h4&gt;该方法通过使用冻结的图像基础模型从多视角图像中提取特征，并在3D空间中聚合这些特征。然后，将这些提升的2D特征与从扫描网格中提取的3D几何特征融合，以在扫描网格上直接预测分割掩码。&lt;h4&gt;主要发现&lt;/h4&gt;该方法的分割结果比纯2D或3D分割方法分别提高了8.89%和14.3%的注册准确性。&lt;h4&gt;结论&lt;/h4&gt;尽管仅用合成数据进行训练，但该模型对真实数据具有良好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel method for accurately separating skin from non-skin geometry on 3D human head scans to improve the quality of face registration.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Face registration deforms a template mesh to closely fit a 3D face scan, thequality of which commonly degrades in non-skin regions (e.g., hair, beard,accessories), because the optimized template-to-scan distance pulls thetemplate mesh towards the noisy scan surface. Improving registration qualityrequires a clean separation of skin and non-skin regions on the scan mesh.Existing image-based (2D) or scan-based (3D) segmentation methods howeverperform poorly. Image-based segmentation outputs multi-view inconsistent masks,and they cannot account for scan inaccuracies or scan-image misalignment, whilescan-based methods suffer from lower spatial resolution compared to images. Inthis work, we introduce a novel method that accurately separates skin fromnon-skin geometry on 3D human head scans. For this, our method extractsfeatures from multi-view images using a frozen image foundation model andaggregates these features in 3D. These lifted 2D features are then fused with3D geometric features extracted from the scan mesh, to then predict asegmentation mask directly on the scan mesh. We show that our segmentationsimprove the registration accuracy over pure 2D or 3D segmentation methods by8.89% and 14.3%, respectively. Although trained only on synthetic data, ourmodel generalizes well to real data.</description>
      <author>example@mail.com (Victoria Yue Chen, Daoye Wang, Stephan Garbin, Sebastian Winberg, Timo Bolkart, Thabo Beeler)</author>
      <guid isPermaLink="false">2504.19718v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>UNILoc: Unified Localization Combining Model-Based Geometry and Unsupervised Learning</title>
      <link>http://arxiv.org/abs/2504.17676v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, submitted to IEEE conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的定位方法，该方法结合了基于模型和基于机器学习的方法，通过利用可用的地图信息来发挥各自的优势。&lt;h4&gt;背景&lt;/h4&gt;精确的移动设备定位对于新兴的5G/6G应用（如自动驾驶和增强现实）至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种统一的方法，以提高定位精度，并避免监督学习。&lt;h4&gt;方法&lt;/h4&gt;通过融合几何估计和建筑布局来生成训练标签，避免监督学习；使用基于光线追踪的模拟来验证方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在视线（LoS）用户和非视线（NLoS）用户的位置精度上均有显著提升；与完全监督的指纹识别相比，该方法在整体性能上具有竞争力，同时消除了繁琐的标签数据测量和收集的需求。&lt;h4&gt;结论&lt;/h4&gt;提出的统一方法能够显著提高定位精度，同时避免了传统方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate mobile device localization is critical for emerging 5G/6Gapplications such as autonomous vehicles and augmented reality. In this paper,we propose a unified localization method that integrates model-based andmachine learning (ML)-based methods to reap their respective advantages byexploiting available map information. In order to avoid supervised learning, wegenerate training labels automatically via optimal transport (OT) by fusinggeometric estimates with building layouts. Ray-tracing based simulations arecarried out to demonstrate that the proposed method significantly improvespositioning accuracy for both line-of-sight (LoS) users (compared to ML-basedmethods) and non-line-of-sight (NLoS) users (compared to model-based methods).Remarkably, the unified method is able to achieve competitive overallperformance with the fully-supervised fingerprinting, while eliminating theneed for cumbersome labeled data measurement and collection.</description>
      <author>example@mail.com (Yuhao Zhang, Guangjin Pan, Musa Furkan Keskin, Ossi Kaltiokallio, Mikko Valkama, Henk Wymeersch)</author>
      <guid isPermaLink="false">2504.17676v2</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>ReLU integral probability metric and its applications</title>
      <link>http://arxiv.org/abs/2504.18897v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  49 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种参数化的积分概率度量（IPM）来衡量两个概率测度之间的差异，并在多个任务中展示了其有效性和优越性能。&lt;h4&gt;背景&lt;/h4&gt;在衡量两个概率测度之间的差异时，需要一种有效的度量方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的IPM，用于测量两个概率测度之间的差异，并应用于高维设置。&lt;h4&gt;方法&lt;/h4&gt;使用特定的参数化判别器家族，如具有ReLU激活的单节点神经网络，来区分分布，并通过优化所选判别器的参数来提高估计器的收敛速度。&lt;h4&gt;主要发现&lt;/h4&gt;提出的IPM在多个任务中提供了强大的理论保证，并且实证实验表明，其性能与其他方法相当甚至更优。&lt;h4&gt;结论&lt;/h4&gt;该IPM在处理概率测度差异时表现出色，具有高效算法和较少的超参数，适用于高维设置，并在因果推断和公平表示学习等任务中具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种参数化的积分概率度量（IPM）来衡量两个概率测度之间的差异。所提出的IPM利用特定的参数化判别器家族，例如具有ReLU激活的单节点神经网络，以有效地区分分布，使其适用于高维设置。通过优化所选判别器类的参数，所提出的IPM表明其估计器具有良好的收敛速度，可以成为使用平滑非参数判别器类的其他IPM的替代品。我们提出了一种高效的算法用于实际计算，提供了一种简单的实现，并需要较少的超参数。此外，我们探讨了其在各种任务中的应用，如因果推断的协变量平衡和公平表示学习。在如此多样的应用中，我们证明了所提出的IPM提供了强大的理论保证，并且实证实验表明，它实现了与其他方法相当甚至更优的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a parametric integral probability metric (IPM) to measure thediscrepancy between two probability measures. The proposed IPM leverages aspecific parametric family of discriminators, such as single-node neuralnetworks with ReLU activation, to effectively distinguish betweendistributions, making it applicable in high-dimensional settings. By optimizingover the parameters of the chosen discriminator class, the proposed IPMdemonstrates that its estimators have good convergence rates and can serve as asurrogate for other IPMs that use smooth nonparametric discriminator classes.We present an efficient algorithm for practical computation, offering a simpleimplementation and requiring fewer hyperparameters. Furthermore, we explore itsapplications in various tasks, such as covariate balancing for causal inferenceand fair representation learning. Across such diverse applications, wedemonstrate that the proposed IPM provides strong theoretical guarantees, andempirical experiments show that it achieves comparable or even superiorperformance to other methods.</description>
      <author>example@mail.com (Yuha Park, Kunwoong Kim, Insung Kong, Yongdai Kim)</author>
      <guid isPermaLink="false">2504.18897v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>MASR: Self-Reflective Reasoning through Multimodal Hierarchical Attention Focusing for Agent-based Video Understanding</title>
      <link>http://arxiv.org/abs/2504.17213v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于代理的视频理解框架MASR，该框架在视频理解方面取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;尽管大模型在快速发展的时代，视频理解仍然是一个极具挑战的任务。&lt;h4&gt;目的&lt;/h4&gt;针对视频信息丰富且冗余的问题，提出MASR框架以提高视频理解的全面性和准确性。&lt;h4&gt;方法&lt;/h4&gt;MASR通过多模态粗到细的相关性感知（MCRS）和膨胀时间扩展（DTE）来检测和优先处理与查询高度相关的视频片段，并在自反推理过程中迭代应用MCRS和DTE，以自适应调整注意力。&lt;h4&gt;主要发现&lt;/h4&gt;MASR在EgoSchema数据集上比之前的方法提高了5%的性能，在Next-QA和IntentQA数据集上分别超过了最先进的标准的0.2%和0.3%，在包含长期视频的Video-MME数据集上，MASR也优于其他基于代理的方法。&lt;h4&gt;结论&lt;/h4&gt;MASR框架在视频理解任务中表现优异，为提高视频理解性能提供了有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Even in the era of rapid advances in large models, video understandingremains a highly challenging task. Compared to texts or images, videos commonlycontain more information with redundancy, requiring large models to properlyallocate attention at a global level for comprehensive and accurateunderstanding. To address this, we propose a Multimodal hierarchical Attentionfocusing Self-reflective Reasoning (MASR) framework for agent-based videounderstanding. The key innovation lies in its ability to detect and prioritizesegments of videos that are highly relevant to the query. Firstly, MASRrealizes Multimodal Coarse-to-fine Relevance Sensing (MCRS) which enhances thecorrelation between the acquired contextual information and the query.Secondly, MASR employs Dilated Temporal Expansion (DTE) to mitigate the risk ofmissing crucial details when extracting semantic information from the focusedframes selected through MCRS. By iteratively applying MCRS and DTE in theself-reflective reasoning process, MASR is able to adaptively adjust theattention to extract highly query-relevant context and therefore improve theresponse accuracy. In the EgoSchema dataset, MASR achieves a remarkable 5%performance gain over previous leading approaches. In the Next-QA and IntentQAdatasets, it outperforms the state-of-the-art standards by 0.2% and 0.3%respectively. In the Video-MME dataset that contains long-term videos, MASRalso performs better than other agent-based methods.</description>
      <author>example@mail.com (Shiwen Cao, Zhaoxing Zhang, Junming Jiao, Juyi Qiao, Guowen Song, Rong Shen, Xiangbing Meng)</author>
      <guid isPermaLink="false">2504.17213v2</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>HeartSimSage: Attention-Enhanced Graph Neural Networks for Accelerating Cardiac Mechanics Modeling</title>
      <link>http://arxiv.org/abs/2504.18968v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于注意力增强图神经网络的心脏生物力学有限元分析模拟器HeartSimSage，用于快速预测心脏被动双心室心肌位移。&lt;h4&gt;背景&lt;/h4&gt;有限元分析（FEA）是心脏生物力学建模的基础，但其计算成本高，限制了其在数字孪生创建中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发HeartSimSage以解决现有模拟器的限制，快速预测患者特定几何形状、心室压力和材料属性下的被动双心室心肌位移。&lt;h4&gt;方法&lt;/h4&gt;HeartSimSage能够有效处理不同的三维双心室几何形状、网格拓扑、纤维方向、基于结构的本构模型和生理边界条件。它支持可变节点数、排序和单元连接的灵活网格结构。通过设计受GraphSAGE启发的邻近连接策略，优化信息传播，并采用基于子集的训练提高效率。HeartSimSage集成了注意力机制，自适应地权衡邻居贡献并过滤无关信息，从而提高预测精度。&lt;h4&gt;主要发现&lt;/h4&gt;HeartSimSage在GPU上实现了约13,000倍的加速，在CPU上实现了190倍的加速，同时保持预测双心室位移的平均误差为0.13% ± 0.12%。&lt;h4&gt;结论&lt;/h4&gt;通过使用HeartSimSage，可以在不牺牲精度的情况下显著提高心脏生物力学模拟的计算效率。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Finite element analysis (FEA) forms the cornerstone of modeling cardiac biomechanics but is computationally expensive, limiting its clinical application for digital twin creation, which often requires tens to hundreds of simulations to estimate tissue parameters. We developed an attention-enhanced graph neural network (GNN)-based FEA emulator, HeartSimSage, to rapidly predict passive biventricular myocardial displacements from patient-specific geometries, chamber pressures, and material properties. HeartSimSage addresses the limitations of current emulators by effectively handling diverse three-dimensional (3D) biventricular geometries, mesh topologies, fiber directions, structurally based constitutive models, and physiological boundary conditions. It supports flexible mesh structures with variable node counts, orderings, and element connectivity. To optimize information propagation, we designed a neighboring connection strategy inspired by Graph Sample and Aggregate (GraphSAGE) that prioritizes local interactions while maintaining mid-to-long-range dependencies. We further incorporated Laplace-Dirichlet solutions for enhanced spatial encoding and employed subset-based training for improved efficiency. By integrating an attention mechanism, HeartSimSage adaptively weighs neighbor contributions and filters irrelevant information, enhancing prediction accuracy. HeartSimSage achieves approximately 13,000x speedup on GPU and 190x on CPU compared to traditional FEA, while maintaining a nominal averaged error of 0.13% ± 0.12% in predicting biventricular displacements. We validated our model using a published left ventricle dataset and conducted sensitivity analyses on hyperparameters, neighboring strategies, and the attention mechanism.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Finite element analysis (FEA) forms the cornerstone of modeling cardiacbiomechanics but is computationally expensive, limiting its clinicalapplication for digital twin creation, which often requires tens to hundreds ofsimulations to estimate tissue parameters. We developed an attention-enhancedgraph neural network (GNN)-based FEA emulator, HeartSimSage, to rapidly predictpassive biventricular myocardial displacements from patient-specificgeometries, chamber pressures, and material properties. HeartSimSage addressesthe limitations of current emulators by effectively handling diversethree-dimensional (3D) biventricular geometries, mesh topologies, fiberdirections, structurally based constitutive models, and physiological boundaryconditions. It supports flexible mesh structures with variable node counts,orderings, and element connectivity. To optimize information propagation, wedesigned a neighboring connection strategy inspired by Graph Sample andAggregate (GraphSAGE) that prioritizes local interactions while maintainingmid-to-long-range dependencies. We further incorporated Laplace-Dirichletsolutions for enhanced spatial encoding and employed subset-based training forimproved efficiency. By integrating an attention mechanism, HeartSimSageadaptively weighs neighbor contributions and filters irrelevant information,enhancing prediction accuracy. HeartSimSage achieves approximately 13,000xspeedup on GPU and 190x on CPU compared to traditional FEA, while maintaining anominal averaged error of 0.13% +- 0.12% in predicting biventriculardisplacements. We validated our model using a published left ventricle datasetand conducted sensitivity analyses on hyperparameters, neighboring strategies,and the attention mechanism.</description>
      <author>example@mail.com (Lei Shi, Yurui Chen, Vijay Vedula)</author>
      <guid isPermaLink="false">2504.18968v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Dexonomy: Synthesizing All Dexterous Grasp Types in a Grasp Taxonomy</title>
      <link>http://arxiv.org/abs/2504.18829v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Robotics: Science and Systems (RSS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效的抓取合成方法，能够为任何抓取类型、物体和机械手合成丰富的接触、无穿透和物理上可行的抓取。&lt;h4&gt;背景&lt;/h4&gt;智能机器人需要掌握多样化的抓取技能，但收集涵盖多种抓取类型的海量高质量数据集极具挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够合成适用于任何抓取类型、物体和机械手的抓取的方法。&lt;h4&gt;方法&lt;/h4&gt;从每个手型和抓取类型的一个单一人工标注模板开始，通过两个阶段进行合成：首先优化物体以适应手模板，然后在模拟中对手进行局部细化以适应物体。引入了一种接触感知控制策略来验证合成的抓取，并允许手在接触点对物体施加适当的力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在模拟中显著优于之前的类型无关抓取合成基线。构建了一个包含10.7k个物体和9.5M个抓取的数据集，涵盖了GRASP分类法中的31种抓取类型。在现实世界实验中，通过训练的类型条件生成模型，从单视图物体点云中成功执行所需的抓取类型，成功率达到82.3%。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地解决了抓取合成问题，为智能机器人提供了强大的抓取能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：具有广泛适用性的灵活抓取是智能机器人的一项基本技能。开发这种技能需要一个大规模且高质量的数据集，该数据集涵盖了多种抓取类型（即至少那些由GRASP分类法归类的类型），但收集此类数据极为困难。现有的自动抓取合成方法通常局限于特定的抓取类型或物体类别，阻碍了可扩展性。这项工作提出了一种高效的管道，能够为任何抓取类型、物体和机械手合成丰富的接触、无穿透和物理上可行的抓取。从每个手型和抓取类型的一个单一人工标注模板开始，我们的管道通过两个阶段解决复杂的合成问题：首先优化物体以适应手模板，然后在模拟中对手进行局部细化以适应物体。为了验证合成的抓取，我们引入了一种接触感知控制策略，该策略允许手在每个接触点对物体施加适当的力。这些经过验证的抓取也可以用作新的抓取模板，以促进未来的合成。实验表明，我们的方法在模拟中显著优于之前的类型无关抓取合成基线。使用我们的算法，我们构建了一个包含10.7k个物体和9.5M个抓取的数据集，涵盖了GRASP分类法中的31种抓取类型。最后，我们训练了一个类型条件生成模型，该模型成功地从单视图物体点云中执行所需的抓取类型，在现实世界实验中的成功率为82.3%。项目页面：https://pku-epic.github.io/Dexonomy。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalizable dexterous grasping with suitable grasp types is a fundamentalskill for intelligent robots. Developing such skills requires a large-scale andhigh-quality dataset that covers numerous grasp types (i.e., at least thosecategorized by the GRASP taxonomy), but collecting such data is extremelychallenging. Existing automatic grasp synthesis methods are often limited tospecific grasp types or object categories, hindering scalability. This workproposes an efficient pipeline capable of synthesizing contact-rich,penetration-free, and physically plausible grasps for any grasp type, object,and articulated hand. Starting from a single human-annotated template for eachhand and grasp type, our pipeline tackles the complicated synthesis problemwith two stages: optimize the object to fit the hand template first, and thenlocally refine the hand to fit the object in simulation. To validate thesynthesized grasps, we introduce a contact-aware control strategy that allowsthe hand to apply the appropriate force at each contact point to the object.Those validated grasps can also be used as new grasp templates to facilitatefuture synthesis. Experiments show that our method significantly outperformsprevious type-unaware grasp synthesis baselines in simulation. Using ouralgorithm, we construct a dataset containing 10.7k objects and 9.5M grasps,covering 31 grasp types in the GRASP taxonomy. Finally, we train atype-conditional generative model that successfully performs the desired grasptype from single-view object point clouds, achieving an 82.3% success rate inreal-world experiments. Project page: https://pku-epic.github.io/Dexonomy.</description>
      <author>example@mail.com (Jiayi Chen, Yubin Ke, Lin Peng, He Wang)</author>
      <guid isPermaLink="false">2504.18829v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Towards Robust Multimodal Physiological Foundation Models: Handling Arbitrary Missing Modalities</title>
      <link>http://arxiv.org/abs/2504.19596v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhysioOmni是一种用于多模态生理信号分析的基础模型，旨在解决现有方法在处理不同数据集和缺失模态时的局限性。&lt;h4&gt;背景&lt;/h4&gt;多模态生理信号（如脑电图、心电图、眼电图和肌电图）在医疗和脑机接口领域至关重要，但现有方法依赖于特定架构和针对数据集的融合策略，难以学习通用的表示形式。&lt;h4&gt;目的&lt;/h4&gt;提出PhysioOmni模型，以实现跨数据集的泛化能力并处理推理时的缺失模态。&lt;h4&gt;方法&lt;/h4&gt;PhysioOmni训练了一个解耦的多模态分词器，通过模态不变和模态特定的目标进行掩码信号预训练。此外，通过原型对齐在下游数据集上进行鲁棒的微调，以确保对不同和缺失模态组合的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;在情绪识别、睡眠阶段分类、运动预测和心理负荷检测等四个下游任务上，PhysioOmni实现了最先进的性能，同时保持了对抗缺失模态的强大鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;PhysioOmni模型有效解决了多模态生理信号分析中的挑战，并将在未来发布代码和模型权重。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal physiological signals, such as EEG, ECG, EOG, and EMG, are crucialfor healthcare and brain-computer interfaces. While existing methods rely onspecialized architectures and dataset-specific fusion strategies, they struggleto learn universal representations that generalize across datasets and handlemissing modalities at inference time. To address these issues, we proposePhysioOmni, a foundation model for multimodal physiological signal analysisthat models both homogeneous and heterogeneous features to decouple multimodalsignals and extract generic representations while maintaining compatibilitywith arbitrary missing modalities. PhysioOmni trains a decoupled multimodaltokenizer, enabling masked signal pre-training via modality-invariant andmodality-specific objectives. To ensure adaptability to diverse and incompletemodality combinations, the pre-trained encoders undergo resilient fine-tuningwith prototype alignment on downstream datasets. Extensive experiments on fourdownstream tasks, emotion recognition, sleep stage classification, motorprediction, and mental workload detection, demonstrate that PhysioOmni achievesstate-of-the-art performance while maintaining strong robustness to missingmodalities. Our code and model weights will be released.</description>
      <author>example@mail.com (Xi Fu, Wei-Bang Jiang, Yi Ding, Cuntai Guan)</author>
      <guid isPermaLink="false">2504.19596v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>TSRM: A Lightweight Temporal Feature Encoding Architecture for Time Series Forecasting and Imputation</title>
      <link>http://arxiv.org/abs/2504.18878v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为时间序列表示模型（TSRM）的时序特征编码架构，用于多变量时间序列的预测和插补。&lt;h4&gt;背景&lt;/h4&gt;在多变量时间序列预测和插补领域，现有方法存在复杂度高的问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够高效学习时间序列模式并进行预测和插补的架构。&lt;h4&gt;方法&lt;/h4&gt;架构基于CNN的表示层，每个层负责独立的学习任务，以捕获多样化的时间模式。之后通过注意力机制提取特征，并使用合并层聚合提取的特征。架构灵感来源于Transformer编码器，核心机制为自注意力。&lt;h4&gt;主要发现&lt;/h4&gt;TSRM在大多数七个已建立的基准数据集上优于现有方法，同时显著减少了可学习参数的数量。&lt;h4&gt;结论&lt;/h4&gt;TSRM是一种高效且性能优越的时间序列预测和插补模型。&lt;h4&gt;翻译&lt;/h4&gt;We introduce a temporal feature encoding architecture called Time SeriesRepresentation Model (TSRM) for multivariate time series forecasting andimputation. The architecture is structured around CNN-based representationlayers, each dedicated to an independent representation learning task anddesigned to capture diverse temporal patterns, followed by an attention-basedfeature extraction layer and a merge layer, designed to aggregate extractedfeatures. The architecture is fundamentally based on a configuration that isinspired by a Transformer encoder, with self-attention mechanisms at its core.The TSRM architecture outperforms state-of-the-art approaches on most of theseven established benchmark datasets considered in our empirical evaluation forboth forecasting and imputation tasks. At the same time, it significantlyreduces complexity in the form of learnable parameters. The source code isavailable at https://github.com/RobertLeppich/TSRM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a temporal feature encoding architecture called Time SeriesRepresentation Model (TSRM) for multivariate time series forecasting andimputation. The architecture is structured around CNN-based representationlayers, each dedicated to an independent representation learning task anddesigned to capture diverse temporal patterns, followed by an attention-basedfeature extraction layer and a merge layer, designed to aggregate extractedfeatures. The architecture is fundamentally based on a configuration that isinspired by a Transformer encoder, with self-attention mechanisms at its core.The TSRM architecture outperforms state-of-the-art approaches on most of theseven established benchmark datasets considered in our empirical evaluation forboth forecasting and imputation tasks. At the same time, it significantlyreduces complexity in the form of learnable parameters. The source code isavailable at https://github.com/RobertLeppich/TSRM.</description>
      <author>example@mail.com (Robert Leppich, Michael Stenger, Daniel Grillmeyer, Vanessa Borst, Samuel Kounev)</author>
      <guid isPermaLink="false">2504.18878v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Kinship Verification through a Forest Neural Network</title>
      <link>http://arxiv.org/abs/2504.18910v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的概念的新方法，用于人脸表征在血缘关系验证中的应用，该方法在准确性上与从头开始学习的父母和子女人脸图像的联合表征算法相当。&lt;h4&gt;背景&lt;/h4&gt;早期方法在血缘关系验证中使用人脸表征，但这些表征的准确性不如从头开始学习的父母和子女人脸图像的联合表征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以改善血缘关系验证中人脸表征的准确性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种结合图神经网络概念的算法，并设计了分类模块的结构，引入了一种新的损失组合，以在训练网络时逐渐引入中心损失。&lt;h4&gt;主要发现&lt;/h4&gt;在KinFaceW-I和II数据集上进行了实验，证明了该方法的有效性，并在KinFaceW-II上取得了最佳结果，对所有血缘类型平均提高了近1.6，在KinFaceW-I上接近最佳。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在血缘关系验证中取得了显著的性能提升，并提供了可用的代码实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early methods used face representations in kinship verification, which areless accurate than joint representations of parents' and children's facialimages learned from scratch. We propose an approach featuring graph neuralnetwork concepts to utilize face representations and have comparable results tojoint representation algorithms. Moreover, we designed the structure of theclassification module and introduced a new combination of losses to engage thecenter loss gradually in training our network. Additionally, we conductedexperiments on KinFaceW-I and II, demonstrating the effectiveness of ourapproach. We achieved the best result on KinFaceW-II, an average improvement ofnearly 1.6 for all kinship types, and we were near the best on KinFaceW-I. Thecode is available at https://github.com/ali-nazari/Kinship-Verification</description>
      <author>example@mail.com (Ali Nazari, Mohsen Ebrahimi Moghaddam, Omidreza Borzoei)</author>
      <guid isPermaLink="false">2504.18910v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>PiercingEye: Dual-Space Video Violence Detection with Hyperbolic Vision-Language Guidance</title>
      <link>http://arxiv.org/abs/2504.18866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Transactions on Pattern Analysis and Machine  Intelligence&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PiercingEye的新颖的弱监督视频暴力检测（VVD）方法，该方法结合了欧几里得和双曲几何，以增强特征表示的判别性。&lt;h4&gt;背景&lt;/h4&gt;现有的弱监督视频暴力检测方法主要依赖于欧几里得表示学习，但往往难以区分视觉相似但语义不同的事件，这是由于有限的层次建模和不足的模糊训练样本。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出了一种新的双空间学习框架。&lt;h4&gt;方法&lt;/h4&gt;PiercingEye引入了一种层敏感的双曲聚合策略，并使用双曲Dirichlet能量约束来逐步建模事件层次，同时引入了一种跨空间注意力机制，以促进欧几里得和双曲空间之间的互补特征交互。此外，为了缓解模糊样本的稀缺性，利用大型语言模型生成逻辑引导的模糊事件描述，并通过双曲视觉-语言对比损失实现显式监督，该损失通过动态相似度感知加权优先考虑高混淆样本。&lt;h4&gt;主要发现&lt;/h4&gt;在XD-Violence和UCF-Crime数据集上的大量实验表明，PiercingEye达到了最先进的性能，尤其是在新创建的模糊事件子集上，验证了其在细粒度暴力检测中的优越能力。&lt;h4&gt;结论&lt;/h4&gt;PiercingEye在视频暴力检测领域取得了显著的成果，为未来的研究提供了新的方向和方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现有的弱监督视频暴力检测方法主要依赖于欧几里得表示学习，这往往由于有限的层次建模和不足的模糊训练样本，难以区分视觉相似但语义不同的事件。为了解决这一挑战，我们提出了PiercingEye，一种新的双空间学习框架，它结合了欧几里得和双曲几何来增强判别性特征表示。具体来说，PiercingEye引入了一种层敏感的双曲聚合策略，并使用双曲Dirichlet能量约束来逐步建模事件层次，同时引入了一种跨空间注意力机制，以促进欧几里得和双曲空间之间的互补特征交互。此外，为了缓解模糊样本的稀缺性，我们利用大型语言模型生成逻辑引导的模糊事件描述，通过双曲视觉-语言对比损失实现显式监督，该损失通过动态相似度感知加权优先考虑高混淆样本。在XD-Violence和UCF-Crime数据集上的大量实验表明，PiercingEye达到了最先进的性能，尤其是在新创建的模糊事件子集上，验证了其在细粒度暴力检测中的优越能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing weakly supervised video violence detection (VVD) methods primarilyrely on Euclidean representation learning, which often struggles to distinguishvisually similar yet semantically distinct events due to limited hierarchicalmodeling and insufficient ambiguous training samples. To address thischallenge, we propose PiercingEye, a novel dual-space learning framework thatsynergizes Euclidean and hyperbolic geometries to enhance discriminativefeature representation. Specifically, PiercingEye introduces a layer-sensitivehyperbolic aggregation strategy with hyperbolic Dirichlet energy constraints toprogressively model event hierarchies, and a cross-space attention mechanism tofacilitate complementary feature interactions between Euclidean and hyperbolicspaces. Furthermore, to mitigate the scarcity of ambiguous samples, we leveragelarge language models to generate logic-guided ambiguous event descriptions,enabling explicit supervision through a hyperbolic vision-language contrastiveloss that prioritizes high-confusion samples via dynamic similarity-awareweighting. Extensive experiments on XD-Violence and UCF-Crime benchmarksdemonstrate that PiercingEye achieves state-of-the-art performance, withparticularly strong results on a newly curated ambiguous event subset,validating its superior capability in fine-grained violence detection.</description>
      <author>example@mail.com (Jiaxu Leng, Zhanjie Wu, Mingpi Tan, Mengjingcheng Mo, Jiankang Zheng, Qingqing Li, Ji Gan, Xinbo Gao)</author>
      <guid isPermaLink="false">2504.18866v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal graph representation learning for website generation based on visual sketch</title>
      <link>http://arxiv.org/abs/2504.18729v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用多模态图表示学习的新方法，用于将数字设计转换为功能性源代码，以解决设计到代码转换中的复杂性和耗时问题。&lt;h4&gt;背景&lt;/h4&gt;设计到代码转换是一个在软件开发中具有挑战性的问题，传统方法在准确解析网页设计的复杂视觉细节和结构关系方面存在困难，导致自动化和效率受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过整合设计草图中的视觉和结构信息，提高代码生成的准确性和效率，特别是生成语义正确和结构良好的HTML代码。&lt;h4&gt;方法&lt;/h4&gt;采用多模态图表示学习，结合视觉和结构信息，以增强代码生成的准确性和效率。&lt;h4&gt;主要发现&lt;/h4&gt;对方法进行了全面评估，与现有技术相比，在准确性和效率方面均有显著提升，多模态图学习在现有技术中表现出显著的优势，突显了该方法在自动化设计到代码转换中的潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法有望革新设计到代码的自动化过程，相关代码可在https://github.com/HySonLab/Design2Code获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Design2Code problem, which involves converting digital designs intofunctional source code, is a significant challenge in software development dueto its complexity and time-consuming nature. Traditional approaches oftenstruggle with accurately interpreting the intricate visual details andstructural relationships inherent in webpage designs, leading to limitations inautomation and efficiency. In this paper, we propose a novel method thatleverages multimodal graph representation learning to address these challenges.By integrating both visual and structural information from design sketches, ourapproach enhances the accuracy and efficiency of code generation, particularlyin producing semantically correct and structurally sound HTML code. We presenta comprehensive evaluation of our method, demonstrating significantimprovements in both accuracy and efficiency compared to existing techniques.Extensive evaluation demonstrates significant improvements of multimodal graphlearning over existing techniques, highlighting the potential of our method torevolutionize design-to-code automation. Code available athttps://github.com/HySonLab/Design2Code</description>
      <author>example@mail.com (Tung D. Vu, Chung Hoang, Truong-Son Hy)</author>
      <guid isPermaLink="false">2504.18729v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Towards Faster and More Compact Foundation Models for Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2504.19538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过减少模型尺寸来提高分子性质预测中机器学习模型的效率，同时保持性能。&lt;h4&gt;背景&lt;/h4&gt;尽管机器学习在分子性质预测方面的准确性有所提高，但代价是更高的计算成本和更长的训练时间。&lt;h4&gt;目的&lt;/h4&gt;提高JMP模型在分子数据集上的微调效率，同时保持或提高性能。&lt;h4&gt;方法&lt;/h4&gt;分析了JMP模型的层贡献，通过剪枝预训练模型来探索模型压缩策略，并评估其对微调期间效率和准确性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;移除两个交互块可以最小化性能下降，将模型尺寸减少32%，同时将推理吞吐量提高1.3倍。&lt;h4&gt;结论&lt;/h4&gt;JMP-L模型存在过度参数化问题，一个更小、更高效的变体可以实现可比的性能，同时降低计算成本。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在分子性质预测的机器学习方面，尽管准确率有所提高，但代价是更高的计算成本和更长的训练时间。最近，联合多域预训练（JMP）基础模型在各种下游任务中表现出强大的性能，且训练时间低于之前的模型。尽管JMP具有优势，但将其在从小规模到大规模的分子数据集上进行微调需要相当多的时间和计算资源。在这项工作中，我们研究了通过减少模型尺寸来提高效率的策略，同时保持性能。为了更好地理解模型的效率，我们分析了JMP的层贡献，发现后续交互块提供的回报逐渐减少，这表明存在模型压缩的机会。我们通过剪枝预训练模型来探索块减少策略，并在微调期间评估其对效率和准确性的影响。我们的分析表明，移除两个交互块会导致最小的性能下降，将模型尺寸减少32%，同时将推理吞吐量提高1.3倍。这些结果表明，JMP-L模型过度参数化，一个更小、更高效的变体可以以更低的计算成本实现可比的性能。我们的研究为开发更轻量级、更快、更可扩展的基础模型提供了见解，用于分子和材料发现。代码可在以下链接公开获取：https://github.com/Yasir-Ghunaim/efficient-jmp。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in machine learning for molecular property prediction haveimproved accuracy but at the expense of higher computational cost and longertraining times. Recently, the Joint Multi-domain Pre-training (JMP) foundationmodel has demonstrated strong performance across various downstream tasks withreduced training time over previous models. Despite JMP's advantages,fine-tuning it on molecular datasets ranging from small-scale to large-scalerequires considerable time and computational resources. In this work, weinvestigate strategies to enhance efficiency by reducing model size whilepreserving performance. To better understand the model's efficiency, we analyzethe layer contributions of JMP and find that later interaction blocks providediminishing returns, suggesting an opportunity for model compression. Weexplore block reduction strategies by pruning the pre-trained model andevaluating its impact on efficiency and accuracy during fine-tuning. Ouranalysis reveals that removing two interaction blocks results in a minimalperformance drop, reducing the model size by 32% while increasing inferencethroughput by 1.3x. These results suggest that JMP-L is over-parameterized andthat a smaller, more efficient variant can achieve comparable performance withlower computational cost. Our study provides insights for developing lighter,faster, and more scalable foundation models for molecular and materialsdiscovery. The code is publicly available at:https://github.com/Yasir-Ghunaim/efficient-jmp.</description>
      <author>example@mail.com (Yasir Ghunaim, Andrés Villa, Gergo Ignacz, Gyorgy Szekely, Motasem Alfarra, Bernard Ghanem)</author>
      <guid isPermaLink="false">2504.19538v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations</title>
      <link>http://arxiv.org/abs/2504.18591v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了基于神经场的 enf2enf 方法，用于预测具有非参数化几何变异性稳态偏微分方程的解。&lt;h4&gt;背景&lt;/h4&gt;神经场在处理偏微分方程解的近似学习方面取得了进展，能够处理一般几何形状。&lt;h4&gt;目的&lt;/h4&gt;提出 enf2enf 方法，以预测具有非参数化几何变异性稳态偏微分方程的解。&lt;h4&gt;方法&lt;/h4&gt;enf2enf 方法通过将输入几何编码为潜在点云嵌入，保留几何基础并捕捉局部现象，然后将这些表示与全局参数结合，直接解码为连续输出场，从而有效地模拟几何与物理之间的耦合。&lt;h4&gt;主要发现&lt;/h4&gt;该方法利用局部性和平移不变性的归纳偏置，能够捕捉精细的物理特征和复杂的形状变化，从而提高泛化能力和物理合规性。&lt;h4&gt;结论&lt;/h4&gt;在高质量空气动力学数据集、超弹性材料基准和多元素翼型几何形状上的实验表明，所提出的模型与最先进的基于图、操作学习和神经场的方法相比，实现了优越或具有竞争力的性能。该方法支持实时推理和零样本超分辨率，能够在低分辨率网格上高效训练，同时在全尺度离散化上保持高精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近在神经场方面的进展使得学习神经算子，该算子可以近似求解一般几何形状上的偏微分方程（PDEs）的解，成为了一种强大的、离散化不变的方法。基于这些进展，我们介绍了 enf2enf，这是一种编码器-解码器方法，用于预测具有非参数化几何变异性稳态偏微分方程。在 enf2enf 中，输入几何被编码为保留几何基础并捕捉局部现象的潜在点云嵌入。然后，这些表示与全局参数结合，直接解码为连续输出场，从而有效地模拟几何与物理之间的耦合。通过利用局部性和平移不变性的归纳偏置，我们的方法能够捕捉精细的物理特征以及复杂的形状变化，从而增强泛化能力和物理合规性。在高质量空气动力学数据集、超弹性材料基准和多元素翼型几何形状上的广泛实验表明，与最先进的基于图、操作学习和神经场的方法相比，所提出的模型实现了优越或具有竞争力的性能。值得注意的是，我们的方法支持实时推理和零样本超分辨率，能够在低分辨率网格上高效训练，同时在全尺度离散化上保持高精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Neural Fields have enabled powerful,discretization-invariant methods for learning neural operators that approximatesolutions of Partial Differential Equations (PDEs) on general geometries.Building on these developments, we introduce enf2enf, an encoder--decodermethodology for predicting steady-state Partial Differential Equations withnon-parameterized geometric variability, based on recently proposed EquivariantNeural Field architectures. In enf2enf, input geometries are encoded intolatent point cloud embeddings that inherently preserve geometric grounding andcapture local phenomena. The resulting representations are then combined withglobal parameters and directly decoded into continuous output fields, thusefficiently modeling the coupling between geometry and physics. By leveragingthe inductive biases of locality and translation invariance, our approach isable to capture fine-scale physical features as well as complex shapevariations, thereby enhancing generalization and physical compliance. Extensiveexperiments on a high-fidelity aerodynamic dataset, a hyper-elastic materialbenchmark, and multi-element airfoil geometries, demonstrate that the proposedmodel achieves superior or competitive performance compared to state-of-the-artgraph based, operator learning, and neural field methods. Notably, our methodsupports real time inference and zero-shot super-resolution, enabling efficienttraining on low-resolution meshes while maintaining high accuracy on full-scalediscretizations.</description>
      <author>example@mail.com (Giovanni Catalani, Michael Bauerheim, Frédéric Tost, Xavier Bertrand, Joseph Morlier)</author>
      <guid isPermaLink="false">2504.18591v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>High-order Graph Neural Networks with Common Neighbor Awareness for Link Prediction</title>
      <link>http://arxiv.org/abs/2504.18758v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted By ICAIS&amp;ISAS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于高阶图神经网络（HGNN-CNA）的动态图学习中的链接预测方法，通过考虑多跳共同邻居来捕捉节点间的复杂交互，并直接在动态图学习（DGL）中融合这种交互，从而显著提高了链接预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;链接预测是动态图学习中的一个基本任务，动态图神经网络的进步主要通过对节点间关系进行消息传递来建模，但它们依赖于成对节点交互，忽略了DGL中的共同邻居交互。&lt;h4&gt;目的&lt;/h4&gt;提出HGNN-CNA以解决DGL中共同邻居交互被忽略的问题，从而提高链接预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;HGNN-CNA通过以下两种方法实现：a) 通过考虑多跳共同邻居来估计相关性分数，以捕捉节点间的复杂交互；b) 将这种相关性融合到消息传递过程中，直接在DGL中考虑共同邻居交互。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实动态图上的实验结果表明，与几个最先进的模型相比，所提出的HGNN-CNA在链接预测任务上取得了显著的准确性提升。&lt;h4&gt;结论&lt;/h4&gt;HGNN-CNA通过直接考虑DGL中的共同邻居交互，显著提高了链接预测的准确性，为动态图学习中的链接预测提供了一种新的有效方法。&lt;h4&gt;翻译&lt;/h4&gt;链接预测是动态图学习中的基础任务，它被动态图（DG）的拓扑结构所塑造。动态图神经网络（DGNN）的最近进展，主要通过消息传递方案建模节点之间的关系，已经显著提高了链接预测的性能。然而，DGNNs高度依赖于成对节点交互，这忽略了DGL中的共同邻居交互。为了解决这一局限性，我们提出了一种具有共同邻居感知能力的高阶图神经网络（HGNN-CNA）用于链接预测，具有两个方面的想法：a）通过考虑多跳共同邻居来估计相关性分数，以捕捉节点之间的复杂交互；b）将相关性融合到消息传递过程中，直接在DGL中考虑共同邻居交互。在三个真实动态图上的实验结果表明，所提出的HGNN-CNA在链接预测任务上相对于几个最先进的模型取得了显著的准确性提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction is a fundamental task in dynamic graph learning (DGL),inherently shaped by the topology of the DG. Recent advancements in dynamicgraph neural networks (DGNN), primarily by modeling the relationships amongnodes via a message passing scheme, have significantly improved link predictionperformance. However, DGNNs heavily rely on the pairwise node interactions,which neglect the common neighbor interaction in DGL. To address thislimitation, we propose a High-order Graph Neural Networks with Common NeighborAwareness (HGNN-CNA) for link prediction with two-fold ideas: a) estimatingcorrelation score by considering multi-hop common neighbors for capturing thecomplex interaction between nodes; b) fusing the correlation into themessage-passing process to consider common neighbor interaction directly inDGL. Experimental results on three real DGs demonstrate that the proposedHGNN-CNA acquires a significant accuracy gain over several state-of-the-artmodels on the link prediction task.</description>
      <author>example@mail.com (Ling Wang, Minglian Han)</author>
      <guid isPermaLink="false">2504.18758v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>LLMs for Engineering: Teaching Models to Design High Powered Rockets</title>
      <link>http://arxiv.org/abs/2504.19394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了大型语言模型（LLMs）在火箭设计中的应用能力，发现RL训练的LLMs在复杂工程优化中具有潜力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）已经改变了软件工程，但其在物理工程领域的应用仍不充分。&lt;h4&gt;目的&lt;/h4&gt;评估LLMs在火箭设计中的能力。&lt;h4&gt;方法&lt;/h4&gt;通过RocketBench基准测试连接LLMs与高保真火箭模拟，测试模型在两个设计任务上的表现：目标高度优化和精度着陆挑战。&lt;h4&gt;主要发现&lt;/h4&gt;最先进的LLMs显示出强大的工程基础知识，但在给定模拟结果后难以迭代设计，最终性能低于人类水平。然而，通过强化学习（RL）增强后，一个7B参数的模型优于最先进的基础模型和人类专家。&lt;h4&gt;结论&lt;/h4&gt;RL训练的LLMs可以成为复杂工程优化的有效工具，有可能改变软件以外的工程领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have transformed software engineering, but theirapplication to physical engineering domains remains underexplored. This paperevaluates LLMs' capabilities in high-powered rocketry design throughRocketBench, a benchmark connecting LLMs to high-fidelity rocket simulations.We test models on two increasingly complex design tasks: target altitudeoptimization and precision landing challenges. Our findings reveal that whilestate-of-the-art LLMs demonstrate strong baseline engineering knowledge, theystruggle to iterate on their designs when given simulation results andultimately plateau below human performance levels. However, when enhanced withreinforcement learning (RL), we show that a 7B parameter model outperforms bothSoTA foundation models and human experts. This research demonstrates thatRL-trained LLMs can serve as effective tools for complex engineeringoptimization, potentially transforming engineering domains beyond softwaredevelopment.</description>
      <author>example@mail.com (Toby Simonds)</author>
      <guid isPermaLink="false">2504.19394v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Explainable Deep-Learning Based Potentially Hazardous Asteroids Classification Using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.18605v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的近地小行星（PHA）分类方法，用于行星防御和深空导航。&lt;h4&gt;背景&lt;/h4&gt;传统方法在近地小行星分类中往往忽略了小行星之间的动态关系。&lt;h4&gt;目的&lt;/h4&gt;通过模型识别具有潜在危害的小行星。&lt;h4&gt;方法&lt;/h4&gt;将小行星作为节点，利用轨道和物理特征建模，节点之间通过表示相似性的边连接。使用NASA的958,524条记录的数据集进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;模型在数据集极度不平衡（仅0.22%为危险标签）的情况下，实现了99%的总体准确率和0.99的AUC。应用合成少数类过采样技术后，对于危险小行星的召回率为78%，F1分数为37%。特征重要性分析显示反照率、近日点和半长轴为主要预测因子。&lt;h4&gt;结论&lt;/h4&gt;该框架支持行星防御任务，并证实了人工智能在实现未来任务如NASA的近地天体调查员和ESA的拉姆塞斯自主导航方面的潜力，为小行星危害评估提供了一种可解释和可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Classifying potentially hazardous asteroids (PHAs) is crucial for planetary defense and deep space navigation, yet traditional methods often overlook the dynamical relationships among asteroids. We introduce a Graph Neural Network (GNN) approach that models asteroids as nodes with orbital and physical features, connected by edges representing their similarities, using a NASA dataset of 958,524 records. Despite an extreme class imbalance with only 0.22% of the dataset with the hazardous label, our model achieves an overall accuracy of 99% and an AUC of 0.99, with a recall of 78% and an F1-score of 37% for hazardous asteroids after applying the Synthetic Minority Oversampling Technique. Feature importance analysis highlights albedo, perihelion distance, and semi-major axis as main predictors. This framework supports planetary defense missions and confirms AI's potential in enabling autonomous navigation for future missions such as NASA's NEO Surveyor and ESA's Ramses, offering an interpretable and scalable solution for asteroid hazard assessment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classifying potentially hazardous asteroids (PHAs) is crucial for planetarydefense and deep space navigation, yet traditional methods often overlook thedynamical relationships among asteroids. We introduce a Graph Neural Network(GNN) approach that models asteroids as nodes with orbital and physicalfeatures, connected by edges representing their similarities, using a NASAdataset of 958,524 records. Despite an extreme class imbalance with only 0.22%of the dataset with the hazardous label, our model achieves an overall accuracyof 99% and an AUC of 0.99, with a recall of 78% and an F1-score of 37% forhazardous asteroids after applying the Synthetic Minority OversamplingTechnique. Feature importance analysis highlights albedo, perihelion distance,and semi-major axis as main predictors. This framework supports planetarydefense missions and confirms AI's potential in enabling autonomous navigationfor future missions such as NASA's NEO Surveyor and ESA's Ramses, offering aninterpretable and scalable solution for asteroid hazard assessment.</description>
      <author>example@mail.com (Baimam Boukar Jean Jacques)</author>
      <guid isPermaLink="false">2504.18605v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Anyprefer: An Agentic Framework for Preference Data Synthesis</title>
      <link>http://arxiv.org/abs/2504.19276v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Anyprefer的框架，旨在合成高质量偏好数据以对齐目标模型，并通过实验证明其能显著提升模型在不同应用中的对齐性能。&lt;h4&gt;背景&lt;/h4&gt;高质量偏好数据对于通过偏好学习使基础模型与人类价值观保持一致至关重要，但手动标注此类数据耗时且成本高。&lt;h4&gt;目的&lt;/h4&gt;提出Anyprefer框架，以合成高质量偏好数据，解决手动标注数据耗时且成本高的问题，并减少由于奖励模型与目标模型共享权重而导致的偏差。&lt;h4&gt;方法&lt;/h4&gt;Anyprefer将数据合成过程视为一个合作的双玩家马尔可夫博弈，其中目标模型和裁判模型协作。引入一系列外部工具协助裁判模型准确奖励目标模型的响应，并引入反馈机制优化模型的提示，以增强合作并提高数据质量。&lt;h4&gt;主要发现&lt;/h4&gt;Anyprefer-V1数据集包含58K高质量偏好对，实验表明Anyprefer在四个主要应用中显著提升了模型的对齐性能，平均提升18.55%在五个自然语言生成数据集，3.66%在九个视觉-语言理解数据集，30.05%在三个医学图像分析数据集，以及16.00%在四个视觉-运动控制任务中。&lt;h4&gt;结论&lt;/h4&gt;Anyprefer框架能够有效合成高质量偏好数据，并显著提升模型在不同应用中的对齐性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-quality preference data is essential for aligning foundation models withhuman values through preference learning. However, manual annotation of suchdata is often time-consuming and costly. Recent methods often adopt aself-rewarding approach, where the target model generates and annotates its ownpreference data, but this can lead to inaccuracies since the reward modelshares weights with the target model, thereby amplifying inherent biases. Toaddress these issues, we propose Anyprefer, a framework designed to synthesizehigh-quality preference data for aligning the target model. Anyprefer framesthe data synthesis process as a cooperative two-player Markov Game, where thetarget model and the judge model collaborate together. Here, a series ofexternal tools are introduced to assist the judge model in accurately rewardingthe target model's responses, mitigating biases in the rewarding process. Inaddition, a feedback mechanism is introduced to optimize prompts for bothmodels, enhancing collaboration and improving data quality. The synthesizeddata is compiled into a new preference dataset, Anyprefer-V1, consisting of 58Khigh-quality preference pairs. Extensive experiments show that Anyprefersignificantly improves model alignment performance across four mainapplications, covering 21 datasets, achieving average improvements of 18.55% infive natural language generation datasets, 3.66% in nine vision-languageunderstanding datasets, 30.05% in three medical image analysis datasets, and16.00% in four visuo-motor control tasks.</description>
      <author>example@mail.com (Yiyang Zhou, Zhaoyang Wang, Tianle Wang, Shangyu Xing, Peng Xia, Bo Li, Kaiyuan Zheng, Zijian Zhang, Zhaorun Chen, Wenhao Zheng, Xuchao Zhang, Chetan Bansal, Weitong Zhang, Ying Wei, Mohit Bansal, Huaxiu Yao)</author>
      <guid isPermaLink="false">2504.19276v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>TeleSparse: Practical Privacy-Preserving Verification of Deep Neural Networks</title>
      <link>http://arxiv.org/abs/2504.19274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted to the Privacy Enhancing Technologies  Symposium (PETS) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TeleSparse是一种ZK-friendly后处理机制，用于解决将ZK-SNARKs应用于现代神经网络时的计算开销问题。&lt;h4&gt;背景&lt;/h4&gt;验证深度学习推理的完整性对于确保模型应用正确至关重要，但通常需要访问模型权重和训练数据，这可能导致敏感信息泄露。&lt;h4&gt;目的&lt;/h4&gt;提出TeleSparse以解决将ZK-SNARKs应用于现代神经网络时的计算开销问题。&lt;h4&gt;方法&lt;/h4&gt;TeleSparse通过两种方式解决挑战：减少电路约束和最小化查找表的大小。具体包括：1）通过稀疏化神经网络模型来减少约束；2）通过神经遥传来优化激活范围。&lt;h4&gt;主要发现&lt;/h4&gt;TeleSparse在相同模型上减少了证明生成时间46%，内存使用减少了67%，精度损失约为1%。&lt;h4&gt;结论&lt;/h4&gt;TeleSparse为ZK-friendly模型设计开辟了新方向，推动了可扩展、资源高效的验证深度学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：验证深度学习推理的完整性对于理解模型是否被正确应用至关重要。然而，这种验证通常需要访问模型权重和（可能敏感或私有的）训练数据。所谓的零知识简明非交互式知识证明（ZK-SNARKs）似乎提供了在不访问此类敏感数据的情况下验证模型推理的能力。然而，将ZK-SNARKs应用于现代神经网络（如transformers和大型视觉模型）会引入显著的计算开销。我们提出了TeleSparse，这是一种ZK-friendly的后处理机制，用于提供实际的解决方案。TeleSparse解决了将ZK-SNARKs应用于现代神经网络时固有的两个基本挑战：（1）减少电路约束：过参数化的模型导致ZK-SNARK验证的约束数量众多，从而增加了内存和证明生成成本。我们通过应用稀疏化来解决这一问题，在不损害精度或安全性的情况下提高了证明效率。（2）通过优化激活范围，最小化非线性函数所需的查找表大小，这是一种新颖的神经网络遥传方法，用于缩小激活函数的范围。TeleSparse在相同模型上减少了证明生成时间46%，内存使用减少了67%，精度损失约为1%。我们使用Halo2证明系统实现了我们的框架，并在多个架构（Vision-transformer、ResNet、MobileNet）和数据集（ImageNet、CIFAR-10、CIFAR-100）上证明了其有效性。这项工作为ZK-friendly模型设计开辟了新方向，推动了可扩展、资源高效的验证深度学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Verification of the integrity of deep learning inference is crucial forunderstanding whether a model is being applied correctly. However, suchverification typically requires access to model weights and (potentiallysensitive or private) training data. So-called Zero-knowledge SuccinctNon-Interactive Arguments of Knowledge (ZK-SNARKs) would appear to provide thecapability to verify model inference without access to such sensitive data.However, applying ZK-SNARKs to modern neural networks, such as transformers andlarge vision models, introduces significant computational overhead.  We present TeleSparse, a ZK-friendly post-processing mechanisms to producepractical solutions to this problem. TeleSparse tackles two fundamentalchallenges inherent in applying ZK-SNARKs to modern neural networks: (1)Reducing circuit constraints: Over-parameterized models result in numerousconstraints for ZK-SNARK verification, driving up memory and proof generationcosts. We address this by applying sparsification to neural network models,enhancing proof efficiency without compromising accuracy or security. (2)Minimizing the size of lookup tables required for non-linear functions, byoptimizing activation ranges through neural teleportation, a novel adaptationfor narrowing activation functions' range.  TeleSparse reduces prover memory usage by 67% and proof generation time by46% on the same model, with an accuracy trade-off of approximately 1%. Weimplement our framework using the Halo2 proving system and demonstrate itseffectiveness across multiple architectures (Vision-transformer, ResNet,MobileNet) and datasets (ImageNet,CIFAR-10,CIFAR-100). This work opens newdirections for ZK-friendly model design, moving toward scalable,resource-efficient verifiable deep learning.</description>
      <author>example@mail.com (Mohammad M Maheri, Hamed Haddadi, Alex Davidson)</author>
      <guid isPermaLink="false">2504.19274v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Speaker Diarization for Low-Resource Languages Through Wav2vec Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.18582v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究针对低资源语言如库尔德语的说话人分割问题进行了研究，提出了一种基于Wav2Vec 2.0模型的方法，通过迁移学习提高了低资源语言的说话人分割性能。&lt;h4&gt;背景&lt;/h4&gt;说话人分割是语音处理中的基础任务，但在低资源语言如库尔德语中由于数据有限、方言多样和代码转换频繁，存在独特挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在解决低资源语言库尔德语的说话人分割问题，提高其分割性能。&lt;h4&gt;方法&lt;/h4&gt;研究者通过在专门为库尔德语准备的语料库上训练Wav2Vec 2.0自监督学习模型，并利用迁移学习，将其他语言学到的多语言表示应用于库尔德语语音的语音学和声学特征。&lt;h4&gt;主要发现&lt;/h4&gt;与基线方法相比，该方法将分割错误率降低了7.2%，并将聚类纯度提高了13%。&lt;h4&gt;结论&lt;/h4&gt;这些发现表明，对现有模型的改进可以显著提高低资源语言的说话人分割性能，为其他研究不足的语言构建有效的说话人分割系统奠定了基础，有助于提高语音技术的公平性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：说话人分割是语音处理中的基本任务，它涉及将音频流分割成说话人。尽管最先进的模型在高资源语言上取得了先进的性能，但像库尔德语这样的低资源语言由于有限的注释数据、多种方言和频繁的代码转换而提出了独特的挑战。在本研究中，我们通过在专门的库尔德语语料库上训练Wav2Vec 2.0自监督学习模型来解决这些问题。通过迁移学习，我们将从其他语言学习到的多语言表示调整为捕获库尔德语语音的语音学和声学特征。与基线方法相比，我们的方法将分割错误率降低了7.2%，并将聚类纯度提高了13%。这些发现表明，对现有模型的改进可以显著提高低资源语言的分割性能。我们的工作对开发库尔德语媒体转录服务以及在多语言呼叫中心、电话会议和视频会议系统中的说话人分割具有实际意义。这些结果为构建其他研究不足的语言的有效分割系统奠定了基础，有助于提高语音技术的公平性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speaker diarization is a fundamental task in speech processing that involvesdividing an audio stream by speaker. Although state-of-the-art models haveadvanced performance in high-resource languages, low-resource languages such asKurdish pose unique challenges due to limited annotated data, multiple dialectsand frequent code-switching. In this study, we address these issues by trainingthe Wav2Vec 2.0 self-supervised learning model on a dedicated Kurdish corpus.By leveraging transfer learning, we adapted multilingual representationslearned from other languages to capture the phonetic and acousticcharacteristics of Kurdish speech. Relative to a baseline method, our approachreduced the diarization error rate by seven point two percent and improvedcluster purity by thirteen percent. These findings demonstrate thatenhancements to existing models can significantly improve diarizationperformance for under-resourced languages. Our work has practical implicationsfor developing transcription services for Kurdish-language media and forspeaker segmentation in multilingual call centers, teleconferencing andvideo-conferencing systems. The results establish a foundation for buildingeffective diarization systems in other understudied languages, contributing togreater equity in speech technology.</description>
      <author>example@mail.com (Abdulhady Abas Abdullah, Sarkhel H. Taher Karim, Sara Azad Ahmed, Kanar R. Tariq, Tarik A. Rashid)</author>
      <guid isPermaLink="false">2504.18582v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions</title>
      <link>http://arxiv.org/abs/2504.19056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  50 main pages, 30 pages appendix, 21 figures, 8 tables, GitHub  Repository:  https://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了生成式人工智能在艺术、游戏和动画领域的应用，特别是动画内容生产的成本和时间减少。文章全面分析了面部动画、表情渲染、图像合成、角色创建、手势建模、运动合成、物体生成和纹理合成等领域的最新进展。&lt;h4&gt;背景&lt;/h4&gt;生成式人工智能在动画领域的应用越来越广泛，但现有综述往往缺乏综合性，未能全面涵盖所有相关技术。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供一个综合性的视角，全面概述生成式人工智能在角色动画中的应用，并帮助新进入该领域的研究者和开发者。&lt;h4&gt;方法&lt;/h4&gt;文章首先回顾了面部动画、表情渲染等领域的最新研究，然后讨论了实际应用、常用数据集和新兴趋势。此外，还提供了基础模型和评估指标的相关背景介绍。&lt;h4&gt;主要发现&lt;/h4&gt;近年来，生成式人工智能在动画领域的应用取得了显著进展，包括面部动画、表情渲染、图像合成等方面的技术革新。&lt;h4&gt;结论&lt;/h4&gt;本文为生成式人工智能动画领域的研究者和开发者提供了一个资源，并指出了未来研究方向，以推动人工智能驱动的角色动画技术发展。&lt;h4&gt;翻译&lt;/h4&gt;Generative AI is reshaping art, gaming, and most notably animation. Recent breakthroughs in foundation and diffusion models have reduced the time and cost of producing animated content. Characters are central animation components, involving motion, emotions, gestures, and facial expressions. The pace and breadth of advances in recent months make it difficult to maintain a coherent view of the field, motivating the need for an integrative review. Unlike earlier overviews that treat avatars, gestures, or facial animation in isolation, this survey offers a single, comprehensive perspective on all the main generative AI applications for character animation. We begin by examining the state-of-the-art in facial animation, expression rendering, imagesynthesis, avatar creation, gesture modeling, motion synthesis, object generation, and texture synthesis. We highlight leading research, practical deployments, commonly used datasets, and emerging trends for each area. To support newcomers, we also provide a comprehensive background section that introduces foundational models and evaluation metrics, equipping readers with the knowledge needed to enter the field. We discuss open challenges and map future research directions, providing a roadmap to advance AI-driven character-animation technologies. This survey is intended as a resource for researchers and developers entering the field of generative AI animation or adjacent fields. Resources are available at: https://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative AI is reshaping art, gaming, and most notably animation. Recentbreakthroughs in foundation and diffusion models have reduced the time and costof producing animated content. Characters are central animation components,involving motion, emotions, gestures, and facial expressions. The pace andbreadth of advances in recent months make it difficult to maintain a coherentview of the field, motivating the need for an integrative review. Unlikeearlier overviews that treat avatars, gestures, or facial animation inisolation, this survey offers a single, comprehensive perspective on all themain generative AI applications for character animation. We begin by examiningthe state-of-the-art in facial animation, expression rendering, imagesynthesis, avatar creation, gesture modeling, motion synthesis, objectgeneration, and texture synthesis. We highlight leading research, practicaldeployments, commonly used datasets, and emerging trends for each area. Tosupport newcomers, we also provide a comprehensive background section thatintroduces foundational models and evaluation metrics, equipping readers withthe knowledge needed to enter the field. We discuss open challenges and mapfuture research directions, providing a roadmap to advance AI-drivencharacter-animation technologies. This survey is intended as a resource forresearchers and developers entering the field of generative AI animation oradjacent fields. Resources are available at:https://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey.</description>
      <author>example@mail.com (Mohammad Mahdi Abootorabi, Omid Ghahroodi, Pardis Sadat Zahraei, Hossein Behzadasl, Alireza Mirrokni, Mobina Salimipanah, Arash Rasouli, Bahar Behzadipour, Sara Azarnoush, Benyamin Maleki, Erfan Sadraiye, Kiarash Kiani Feriz, Mahdi Teymouri Nahad, Ali Moghadasi, Abolfazl Eshagh Abianeh, Nizi Nazar, Hamid R. Rabiee, Mahdieh Soleymani Baghshah, Meisam Ahmadi, Ehsaneddin Asgari)</author>
      <guid isPermaLink="false">2504.19056v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:02 +0800</pubDate>
    </item>
    <item>
      <title>PyViT-FUSE: A Foundation Model for Multi-Sensor Earth Observation Data</title>
      <link>http://arxiv.org/abs/2504.18770v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 13 figures, Published at ICLR 2025 - Machine Learning for  Remote Sensing (ML4RS) Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为PyViT-FUSE的基础模型，专门设计用于处理多模态图像，通过注意力机制将任意数量的混合分辨率输入波段融合成一个单一表示。&lt;h4&gt;背景&lt;/h4&gt;针对地球观测数据的多模态图像处理需求。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够融合多模态图像的基础模型。&lt;h4&gt;方法&lt;/h4&gt;使用注意力机制融合不同分辨率的输入波段，并通过具有新颖金字塔结构的视觉Transformer对融合后的块状标记进行处理。采用SwAV算法的核心概念进行自监督训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过可视化注意力分数展示了融合机制的可解释性，并证明了模型在下游任务中的应用能力。&lt;h4&gt;结论&lt;/h4&gt;PyViT-FUSE模型在地球观测数据的多模态图像处理方面具有良好的表现。&lt;h4&gt;翻译&lt;/h4&gt;We propose PyViT-FUSE, a foundation model for earth observation data explicitly designed to handle multi-modal imagery by learning to fuse an arbitrary number of mixed-resolution input bands into a single representation through an attention mechanism. The learned patch tokens are further processed by a stack of vision transformers with a novel pyramidal structure. We train the model on a globally sampled dataset in a self-supervised manner, leveraging core concepts of the SwAV algorithm. We show the interpretability of the fusion mechanism by visualization of the attention scores and the models applicability to downstream tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose PyViT-FUSE, a foundation model for earth observation dataexplicitly designed to handle multi-modal imagery by learning to fuse anarbitrary number of mixed-resolution input bands into a single representationthrough an attention mechanism. The learned patch tokens are further processedby a stack of vision transformers with a novel pyramidal structure. We trainthe model on a globally sampled dataset in a self-supervised manner, leveragingcore concepts of the SwAV algorithm. We show the interpretability of the fusionmechanism by visualization of the attention scores and the models applicabilityto downstream tasks.</description>
      <author>example@mail.com (Manuel Weber, Carly Beneke)</author>
      <guid isPermaLink="false">2504.18770v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:02 +0800</pubDate>
    </item>
    <item>
      <title>EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception</title>
      <link>http://arxiv.org/abs/2504.16616v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EHGCN的新方法，用于在欧几里得和双曲空间中感知事件流，通过自适应采样策略、运动感知超边生成方法和欧几里得-双曲GCN融合，实现了混合事件感知。&lt;h4&gt;背景&lt;/h4&gt;事件相机具有微秒级时间分辨率和高清特性，尽管基于图神经网络（GNN）的感知方法有进展，但它们在纯欧几里得空间中使用简单的成对连接机制，难以捕捉长距离依赖关系，也无法有效表征非均匀分布事件流的内在层次结构。&lt;h4&gt;目的&lt;/h4&gt;提出EHGCN方法，以改善事件流感知，尤其是在欧几里得和双曲空间中。&lt;h4&gt;方法&lt;/h4&gt;EHGCN中引入了自适应采样策略来动态调节采样率，通过保留判别性事件来降低噪声。此外，提出了基于运动状态转移概率的马尔可夫向量场（MVF）驱动的运动感知超边生成方法，以消除跨目标的虚假关联并提供拓扑先验，同时捕捉事件之间的长距离依赖关系。最后，提出了欧几里得-双曲GCN来融合在欧几里得和双曲空间中局部聚合和全局层次建模的信息。&lt;h4&gt;主要发现&lt;/h4&gt;EHGCN能够有效捕捉事件之间的长距离依赖关系，并通过融合欧几里得和双曲空间的信息实现混合事件感知。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，EHGCN在事件感知任务（如目标检测和识别）中是有效的。&lt;h4&gt;翻译&lt;/h4&gt;摘要：事件相机，具有微秒级时间分辨率和高动态范围（HDR）特性，为感知任务提供高速事件流。尽管基于图神经网络（GNN）的感知方法最近有了进展，但它们容易使用简单的成对连接机制在纯欧几里得空间中，这使它们难以捕捉长距离依赖关系，并且无法有效表征非均匀分布事件流的固有层次结构。为此，本文提出了一种名为EHGCN的新方法，这是首次在欧几里得和双曲空间中感知事件流。在EHGCN中，我们引入了一种自适应采样策略来动态调节采样率，在保留判别性事件的同时降低噪声。然后，我们提出了一种基于运动状态转移概率的马尔可夫向量场（MVF）驱动的运动感知超边生成方法，从而消除跨目标的虚假关联并提供关键拓扑先验，同时捕捉事件之间的长距离依赖关系。最后，我们提出了一个欧几里得-双曲GCN，以融合在欧几里得和双曲空间中分别局部聚合和全局层次建模的信息，以实现混合事件感知。在事件感知任务（如目标检测和识别）上的实验结果验证了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras, with microsecond temporal resolution and high dynamic range(HDR) characteristics, emit high-speed event stream for perception tasks.Despite the recent advancement in GNN-based perception methods, they are proneto use straightforward pairwise connectivity mechanisms in the pure Euclideanspace where they struggle to capture long-range dependencies and fail toeffectively characterize the inherent hierarchical structures of non-uniformlydistributed event stream. To this end, in this paper we propose a novelapproach named EHGCN, which is a pioneer to perceive event stream in bothEuclidean and hyperbolic spaces for event vision. In EHGCN, we introduce anadaptive sampling strategy to dynamically regulate sampling rates, retainingdiscriminative events while attenuating chaotic noise. Then we present a MarkovVector Field (MVF)-driven motion-aware hyperedge generation method based onmotion state transition probabilities, thereby eliminating cross-targetspurious associations and providing critically topological priors whilecapturing long-range dependencies between events. Finally, we propose aEuclidean-Hyperbolic GCN to fuse the information locally aggregated andglobally hierarchically modeled in Euclidean and hyperbolic spaces,respectively, to achieve hybrid event perception. Experimental results on eventperception tasks such as object detection and recognition validate theeffectiveness of our approach.</description>
      <author>example@mail.com (Haosheng Chen, Lian Luo, Mengjingcheng Mo, Zhanjie Wu, Guobao Xiao, Ji Gan, Jiaxu Leng, Xinbo Gao)</author>
      <guid isPermaLink="false">2504.16616v2</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:02 +0800</pubDate>
    </item>
    <item>
      <title>A Generative Graph Contrastive Learning Model with Global Signal</title>
      <link>http://arxiv.org/abs/2504.18148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的对比信号生成框架CSG2L，用于精确的图学习，旨在解决现有图对比学习模型的性能退化问题。&lt;h4&gt;背景&lt;/h4&gt;图对比学习（GCL）通过自监督学习方式从图中学习复杂结构信息，但现有的GCL模型可能因为不适当的对比信号而性能下降。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有GCL模型的性能退化问题，提出CSG2L框架。&lt;h4&gt;方法&lt;/h4&gt;CSG2L框架包含以下两个方面的创新：1）构建SVD导向的增强模块（SVD-aug），以获得全局交互并避免随机噪声扰动；2）设计局部-全局依赖学习模块（LGDL）和自适应重加权策略，以区分硬样本对和易样本对的影响。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的实验表明，提出的CSG2L优于现有基准模型，并且CSG2L与多种图神经网络（GNNs）兼容。&lt;h4&gt;结论&lt;/h4&gt;CSG2L是一种有效的图学习框架，可以提升图对比学习模型的性能，并具有广泛的适用性。&lt;h4&gt;翻译&lt;/h4&gt;Graph contrastive learning (GCL) has garnered significant attention recently since it learns complex structural information from graphs through self-supervised learning manner. However, prevalent GCL models may suffer from performance degradation due to inappropriate contrastive signals. Concretely, they commonly generate augmented views based on random perturbation, which leads to biased essential structures due to the introduction of noise. In addition, they assign equal weight to both hard and easy sample pairs, thereby ignoring the difference in importance of the sample pairs. To address these issues, this study proposes a novel Contrastive Signal Generative Framework for Accurate Graph Learning (CSG2L) with the following two-fold ideas: a) building a singular value decomposition (SVD)-directed augmented module (SVD-aug) to obtain the global interactions as well as avoiding the random noise perturbation; b) designing a local-global dependency learning module (LGDL) with an adaptive reweighting strategy which can differentiate the effects of hard and easy sample pairs. Extensive experiments on benchmark datasets demonstrate that the proposed CSG2L outperforms the state-of-art baselines. Moreover, CSG2L is compatible with a variety of GNNs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph contrastive learning (GCL) has garnered significant attention recentlysince it learns complex structural information from graphs throughself-supervised learning manner. However, prevalent GCL models may suffer fromperformance degradation due to inappropriate contrastive signals. Concretely,they commonly generate augmented views based on random perturbation, whichleads to biased essential structures due to the introduction of noise. Inaddition, they assign equal weight to both hard and easy sample pairs, therebyignoring the difference in importance of the sample pairs. To address theseissues, this study proposes a novel Contrastive Signal Generative Framework forAccurate Graph Learning (CSG2L) with the following two-fold ideas: a) buildinga singular value decomposition (SVD)-directed augmented module (SVD-aug) toobtain the global interactions as well as avoiding the random noiseperturbation; b) designing a local-global dependency learning module (LGDL)with an adaptive reweighting strategy which can differentiate the effects ofhard and easy sample pairs. Extensive experiments on benchmark datasetsdemonstrate that the proposed CSG2L outperforms the state-of-art baselines.Moreover, CSG2L is compatible with a variety of GNNs.</description>
      <author>example@mail.com (Xiaofan Wei, Binyan Zhang)</author>
      <guid isPermaLink="false">2504.18148v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
  <item>
      <title>Combating the Bucket Effect:Multi-Knowledge Alignment for Medication Recommendation</title>
      <link>http://arxiv.org/abs/2504.18096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MKMed的跨模态药物编码器，用于提高药物推荐系统的准确性和安全性，以解决药物推荐中的数据不平衡问题。&lt;h4&gt;背景&lt;/h4&gt;药物推荐在医疗保健中至关重要，依赖于患者的电子健康记录（EHR）。然而，不同药物的数据类型不均衡，限制了现有模型的表现，这被称为“桶效应”。&lt;h4&gt;目的&lt;/h4&gt;旨在解决药物推荐中的“桶效应”，提高药物推荐的准确性和安全性。&lt;h4&gt;方法&lt;/h4&gt;引入了MKMed框架，该框架使用对比学习在五种知识模态上预训练一个跨模态编码器，并将多知识药物表示与患者记录结合进行推荐。&lt;h4&gt;主要发现&lt;/h4&gt;数据分析揭示了药物推荐中“桶效应”的严重性，MKMed框架有效缓解了数据不平衡问题，并在MIMIC-III和MIMIC-IV数据集上显著优于现有基准。&lt;h4&gt;结论&lt;/h4&gt;MKMed框架通过跨模态编码和多知识集成，显著提高了药物推荐的准确性和安全性，是解决药物推荐中数据不平衡问题的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medication recommendation is crucial in healthcare, offering effectivetreatments based on patient's electronic health records (EHR). Previous studiesshow that integrating more medication-related knowledge improves medicationrepresentation accuracy. However, not all medications encompass multiple typesof knowledge data simultaneously. For instance, some medications provide onlytextual descriptions without structured data. This imbalance in dataavailability limits the performance of existing models, a challenge we term the"bucket effect" in medication recommendation. Our data analysis uncovers theseverity of the "bucket effect" in medication recommendation. To fill this gap,we introduce a cross-modal medication encoder capable of seamlessly aligningdata from different modalities and propose a medication recommendationframework to integrate Multiple types of Knowledge, named MKMed. Specifically,we first pre-train a cross-modal encoder with contrastive learning on fiveknowledge modalities, aligning them into a unified space. Then, we combine themulti-knowledge medication representations with patient records forrecommendations. Extensive experiments on the MIMIC-III and MIMIC-IV datasetsdemonstrate that MKMed mitigates the "bucket effect" in data, and significantlyoutperforms state-of-the-art baselines in recommendation accuracy and safety.</description>
      <author>example@mail.com (Xiang Li, Haixu Ma, Guanyong Wu, Shi Mu, Chen Li, Shunpan Liang)</author>
      <guid isPermaLink="false">2504.18096v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Testing Individual Fairness in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.18353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了人工智能模型中的偏见可能导致歧视，并重点研究了图神经网络（GNNs）中的个体公平性问题。&lt;h4&gt;背景&lt;/h4&gt;当前研究主要集中在诊断和减轻各种AI模型中的偏见，但关于GNNs中个体公平性的研究较少。&lt;h4&gt;目的&lt;/h4&gt;本项目旨在开发一个测试框架，以评估和确保GNNs中的个体公平性。&lt;h4&gt;方法&lt;/h4&gt;首先，系统回顾个体公平性的文献，并对现有方法进行分类，创建个体公平性的分类法。其次，通过改编和扩展当前的公平性测试和缓解技术，开发一个测试和确保GNNs公平性的框架。&lt;h4&gt;主要发现&lt;/h4&gt;GNNs能够捕捉节点间的图结构，但这也意味着偏见可能通过这些连接传播，从而增加了检测和缓解个体公平性违规的复杂性。&lt;h4&gt;结论&lt;/h4&gt;通过工业案例研究评估框架，重点关注基于图的的大型语言模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人工智能（AI）模型中的偏见可能导致自动决策过程歧视基于性别和种族等敏感属性的群体和/或个人。尽管有许多关于诊断和减轻各种AI模型中偏见的研究，但关于图神经网络（GNNs）中个体公平性的研究却很少。与独立处理数据特征的传统模型不同，GNNs旨在捕捉节点间相互连接的图结构。这种关系方法使GNNs能够模拟复杂的依赖关系，但也意味着偏见可能通过这些连接传播，从而增加了检测和缓解个体公平性违规的复杂性。本博士项目旨在开发一个测试框架来评估和确保GNNs中的个体公平性。首先，系统地回顾个体公平性的文献，对现有方法进行分类，创建个体公平性的分类法。接下来，通过改编和扩展当前的公平性测试和缓解技术，开发一个测试和确保GNNs公平性的框架。该框架将通过工业案例研究进行评估，重点关注基于图的的大型语言模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The biases in artificial intelligence (AI) models can lead to automateddecision-making processes that discriminate against groups and/or individualsbased on sensitive properties such as gender and race. While there are manystudies on diagnosing and mitigating biases in various AI models, there islittle research on individual fairness in Graph Neural Networks (GNNs). Unliketraditional models, which treat data features independently and overlook theirinter-relationships, GNNs are designed to capture graph-based structure wherenodes are interconnected. This relational approach enables GNNs to modelcomplex dependencies, but it also means that biases can propagate through theseconnections, complicating the detection and mitigation of individual fairnessviolations. This PhD project aims to develop a testing framework to assess andensure individual fairness in GNNs. It first systematically reviews theliterature on individual fairness, categorizing existing approaches to define,measure, test, and mitigate model biases, creating a taxonomy of individualfairness. Next, the project will develop a framework for testing and ensuringfairness in GNNs by adapting and extending current fairness testing andmitigation techniques. The framework will be evaluated through industrial casestudies, focusing on graph-based large language models.</description>
      <author>example@mail.com (Roya Nasiri)</author>
      <guid isPermaLink="false">2504.18353v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>S3MOT: Monocular 3D Object Tracking with Selective State Space Model</title>
      <link>http://arxiv.org/abs/2504.18068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的单目三维多目标跟踪方法，该方法通过三种创新技术提高了异质信息的融合和利用。&lt;h4&gt;背景&lt;/h4&gt;在单目设置中，准确可靠的三维多目标跟踪是机器人学和计算机视觉应用发展的关键，但由于从二维视频流中挖掘三维时空关联的困难，这仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提高单目三维多目标跟踪的准确性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;1) 引入匈牙利状态空间模型（HSSM），一种新的数据关联机制，通过压缩多个路径上的上下文跟踪线索，以线性复杂度实现高效全面的分配决策。2) 提出全卷积单阶段嵌入（FCOE），通过直接使用密集特征图进行对比学习，消除了ROI池化，从而在如视角变化和光照条件变化等具有挑战性的条件下提高了物体重识别的准确性。3) 通过VeloSSM增强6自由度姿态估计，这是一种编码器-解码器架构，它通过模拟速度中的时间依赖性来捕捉运动动力学，克服了基于帧的3D推理的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI公共测试基准上的实验表明，该方法达到了76.86 HOTA的新状态-of-the-art性能，在31 FPS下，优于以前的最佳方法，显著提高了2.63 HOTA和3.62 AssA。&lt;h4&gt;结论&lt;/h4&gt;该方法在单目三维多目标跟踪任务中表现出色，具有鲁棒性和效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel monocular 3D multi-object tracking method that improves the fusion and exploitation of heterogeneous information through three innovative techniques.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and reliable multi-object tracking (MOT) in 3D space is essentialfor advancing robotics and computer vision applications. However, it remains asignificant challenge in monocular setups due to the difficulty of mining 3Dspatiotemporal associations from 2D video streams. In this work, we presentthree innovative techniques to enhance the fusion and exploitation ofheterogeneous cues for monocular 3D MOT: (1) we introduce the Hungarian StateSpace Model (HSSM), a novel data association mechanism that compressescontextual tracking cues across multiple paths, enabling efficient andcomprehensive assignment decisions with linear complexity. HSSM features aglobal receptive field and dynamic weights, in contrast to traditional linearassignment algorithms that rely on hand-crafted association costs. (2) Wepropose Fully Convolutional One-stage Embedding (FCOE), which eliminates ROIpooling by directly using dense feature maps for contrastive learning, thusimproving object re-identification accuracy under challenging conditions suchas varying viewpoints and lighting. (3) We enhance 6-DoF pose estimationthrough VeloSSM, an encoder-decoder architecture that models temporaldependencies in velocity to capture motion dynamics, overcoming the limitationsof frame-based 3D inference. Experiments on the KITTI public test benchmarkdemonstrate the effectiveness of our method, achieving a new state-of-the-artperformance of 76.86~HOTA at 31~FPS. Our approach outperforms the previous bestby significant margins of +2.63~HOTA and +3.62~AssA, showcasing its robustnessand efficiency for monocular 3D MOT tasks. The code and models are available athttps://github.com/bytepioneerX/s3mot.</description>
      <author>example@mail.com (Zhuohao Yan, Shaoquan Feng, Xingxing Li, Yuxuan Zhou, Chunxi Xia, Shengyu Li)</author>
      <guid isPermaLink="false">2504.18068v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Learning on Large Graphs using a Densifying Regularity Lemma</title>
      <link>http://arxiv.org/abs/2504.18273v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Intersecting Block Graph (IBG)，一种基于交错二分组件的低秩分解的大规模有向图学习方法，旨在解决传统消息传递神经网络在处理大型图时计算和内存成本的问题。&lt;h4&gt;背景&lt;/h4&gt;传统消息传递神经网络在处理大型图时，计算和内存成本会随着边的数量线性增长，给学习大型图带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出IBG方法，通过降低非边的权重，有效地近似任何稀疏或密集的图，以降低计算和内存成本。&lt;h4&gt;方法&lt;/h4&gt;IBG方法基于交错二分组件的低秩分解，其中每个组件由一对社区组成，分别对应源节点和目标节点。通过证明弱正则性公理的构造性版本，证明了对于任何选择的精度，无论图的大小或稀疏性如何，都可以用一个低秩的密集IBG来近似。&lt;h4&gt;主要发现&lt;/h4&gt;IBG的秩仅取决于精度，而与稀疏程度无关，这与之前的弱正则性公理形式不同。此外，基于IBG的图神经网络在节点分类、时空图分析和知识图谱补全任务上表现出竞争力，同时具有与节点数量线性相关的内存和计算复杂度。&lt;h4&gt;结论&lt;/h4&gt;IBG是一种有效的大规模图学习方法，可以显著降低计算和内存成本，并在多个图学习任务中取得良好性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在大型图上进行学习带来了重大挑战，传统的消息传递神经网络因计算和内存成本随边的数量线性增长而受到限制。我们引入了交错的块图（IBG），这是一种基于交错二分组件的大规模有向图低秩分解方法，每个组件由一对社区组成，分别对应源节点和目标节点。通过降低非边的权重，我们展示了如何有效地用密集的IBG近似任何图，无论是稀疏的还是密集的。具体来说，我们证明了弱正则性公理的构造性版本，表明对于任何选择的精度，无论图的大小或稀疏性如何，都可以用一个低秩的密集IBG来近似。这种秩仅依赖于精度，而不依赖于稀疏程度，这与之前的弱正则性公理形式不同。我们提出了一种在图的IBG表示上运行的图神经网络架构，并在节点分类、时空图分析和知识图谱补全任务上展示了有竞争力的性能，同时具有与节点数量线性相关的内存和计算复杂度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning on large graphs presents significant challenges, with traditionalMessage Passing Neural Networks suffering from computational and memory costsscaling linearly with the number of edges. We introduce the Intersecting BlockGraph (IBG), a low-rank factorization of large directed graphs based oncombinations of intersecting bipartite components, each consisting of a pair ofcommunities, for source and target nodes. By giving less weight to non-edges,we show how to efficiently approximate any graph, sparse or dense, by a denseIBG. Specifically, we prove a constructive version of the weak regularitylemma, showing that for any chosen accuracy, every graph, regardless of itssize or sparsity, can be approximated by a dense IBG whose rank depends only onthe accuracy. This dependence of the rank solely on the accuracy, and not onthe sparsity level, is in contrast to previous forms of the weak regularitylemma. We present a graph neural network architecture operating on the IBGrepresentation of the graph and demonstrating competitive performance on nodeclassification, spatio-temporal graph analysis, and knowledge graph completion,while having memory and computational complexity linear in the number of nodesrather than edges.</description>
      <author>example@mail.com (Jonathan Kouchly, Ben Finkelshtein, Michael Bronstein, Ron Levie)</author>
      <guid isPermaLink="false">2504.18273v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>A Multimodal Hybrid Late-Cascade Fusion Network for Enhanced 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.18419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的方法来检测三维物体，该方法利用激光雷达和RGB摄像头，通过混合级联方案结合RGB检测网络和3D激光雷达检测器。&lt;h4&gt;背景&lt;/h4&gt;现有的三维物体检测方法通常依赖于单一传感器，如激光雷达或RGB摄像头。&lt;h4&gt;目的&lt;/h4&gt;提高三维物体检测的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;采用后期融合原理减少激光雷达的误报，通过将激光雷达的边界框投影到图像上来匹配激光雷达检测与RGB检测。利用级联融合原理，通过视差约束和由RGB检测生成的视锥恢复激光雷达的漏检。&lt;h4&gt;主要发现&lt;/h4&gt;该方法可以集成到任何底层的单模态检测器中，允许灵活的训练过程，可以利用预训练的激光雷达和RGB检测器，或者分别训练两个分支。在KITTI物体检测基准测试中，该方法显示出显著的性能提升，尤其是在行人自行车检测方面。&lt;h4&gt;结论&lt;/h4&gt;该方法为三维物体检测提供了一种有效且灵活的解决方案，提高了检测准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种从多模态输入中检测三维物体的新方法，该方法利用激光雷达和RGB摄像头，采用混合后期级联方案，结合RGB检测网络和3D激光雷达检测器。我们利用后期融合原理来减少激光雷达的误报，通过将激光雷达的边界框投影到图像上来匹配激光雷达检测与RGB检测。我们依靠级联融合原理，利用视差约束和由RGB检测生成的视锥恢复激光雷达的漏检。我们的解决方案可以集成到任何底层的单模态检测器中，允许灵活的训练过程，可以利用预训练的激光雷达和RGB检测器，或者分别训练两个分支。我们在KITTI物体检测基准测试中评估了我们的结果，显示出显著的性能提升，尤其是在行人自行车检测方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a new way to detect 3D objects from multimodal inputs, leveragingboth LiDAR and RGB cameras in a hybrid late-cascade scheme, that combines anRGB detection network and a 3D LiDAR detector. We exploit late fusionprinciples to reduce LiDAR False Positives, matching LiDAR detections with RGBones by projecting the LiDAR bounding boxes on the image. We rely on cascadefusion principles to recover LiDAR False Negatives leveraging epipolarconstraints and frustums generated by RGB detections of separate views. Oursolution can be plugged on top of any underlying single-modal detectors,enabling a flexible training process that can take advantage of pre-trainedLiDAR and RGB detectors, or train the two branches separately. We evaluate ourresults on the KITTI object detection benchmark, showing significantperformance improvements, especially for the detection of Pedestrians andCyclists.</description>
      <author>example@mail.com (Carlo Sgaravatti, Roberto Basla, Riccardo Pieroni, Matteo Corno, Sergio M. Savaresi, Luca Magri, Giacomo Boracchi)</author>
      <guid isPermaLink="false">2504.18419v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Efficient GNN Training Through Structure-Aware Randomized Mini-Batching</title>
      <link>http://arxiv.org/abs/2504.18082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为COMM-RAND的新方法，用于GNN的小批量训练，该方法在保持模型精度的同时，显著提高了训练效率。&lt;h4&gt;背景&lt;/h4&gt;当前GNN的小批量训练策略大多忽略了效率考虑，现有的随机化方案虽然能提高准确性和收敛速度，但往往忽视了图的拓扑结构特性，导致内存访问模式不规律，影响了GPU缓存的利用效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的小批量训练方法，在保证模型准确度的同时，提高GNN训练的效率。&lt;h4&gt;方法&lt;/h4&gt;该方法称为Community-structure-aware Randomized Mini-batching (COMM-RAND)，它允许在构建小批量时探索介于纯随机性和纯图结构意识之间的空间。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果显示，COMM-RAND将GNN训练时间减少了高达2.76倍（平均1.8倍），同时与常见的随机小批量方法相比，准确度只降低了1.79个百分点（平均0.42个百分点）。&lt;h4&gt;结论&lt;/h4&gt;COMM-RAND是一种有效的GNN小批量训练方法，能够在保证模型精度的同时，显著提高训练效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a novel methodology called Community-structure-aware Randomized Mini-batching (COMM-RAND) for GNN mini-batch training, which significantly improves training efficiency while maintaining model accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) enable learning on realworld graphs andmini-batch training has emerged as the de facto standard for training GNNsbecause it can scale to very large graphs and improve convergence. Currentmini-batch construction policies largely ignore efficiency considerations ofGNN training. Specifically, existing mini-batching techniques employrandomization schemes to improve accuracy and convergence. However, theserandomization schemes are often agnostic to the structural properties of thegraph (for eg. community structure), resulting in highly irregular memoryaccess patterns during GNN training that make suboptimal use of on-chip GPUcaches. On the other hand, while deterministic mini-batching based solely ongraph structure delivers fast runtime performance, the lack of randomnesscompromises both the final model accuracy and training convergence speed. Inthis paper, we present Community-structure-aware Randomized Mini-batching(COMM-RAND), a novel methodology that bridges the gap between the aboveextremes. COMM-RAND allows practitioners to explore the space between purerandomness and pure graph structural awareness during mini-batch construction,leading to significantly more efficient GNN training with similar accuracy. Weevaluated COMM-RAND across four popular graph learning benchmarks. COMM-RANDcuts down GNN training time by up to 2.76x (1.8x on average) while achieving anaccuracy that is within 1.79% points (0.42% on average) compared to popularrandom mini-batching approaches.</description>
      <author>example@mail.com (Vignesh Balaji, Christos Kozyrakis, Gal Chechik, Haggai Maron)</author>
      <guid isPermaLink="false">2504.18082v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning for Distributional Perturbation Extrapolation</title>
      <link>http://arxiv.org/abs/2504.18522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint; work presented at the ICLR Workshop on Learning Meaningful  Representations of Life&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在未知扰动（如基因敲低或药物组合）对RNA测序等低层次测量数据影响建模的问题。&lt;h4&gt;背景&lt;/h4&gt;针对给定的扰动数据，研究者们试图预测新扰动下的测量分布。&lt;h4&gt;目的&lt;/h4&gt;通过证明在足够多样化的训练扰动下，扰动效果在空间表示上是可识别的，本研究旨在预测未知扰动的影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为扰动分布自动编码器（PDAE）的新方法，通过最大化真实和预测扰动分布之间的分布相似性来估计模型。&lt;h4&gt;主要发现&lt;/h4&gt;PDAE模型能够有效预测未知扰动的影响，并在实证研究中显示出与现有方法和基线相比的优势。&lt;h4&gt;结论&lt;/h4&gt;PDAE方法为预测未知扰动提供了有力的工具，并有望在生物信息学等领域得到应用。&lt;h4&gt;翻译&lt;/h4&gt;We consider the problem of modeling the effects of unseen perturbations such as gene knockdowns or drug combinations on low-level measurements such as RNA sequencing data. Specifically, given data collected under some perturbations, we aim to predict the distribution of measurements for new perturbations. To address this challenging extrapolation task, we posit that perturbations act additively in a suitable, unknown embedding space. More precisely, we formulate the generative process underlying the observed data as a latent variable model, in which perturbations amount to mean shifts in latent space and can be combined additively. Unlike previous work, we prove that, given sufficiently diverse training perturbations, the representation and perturbation effects are identifiable up to affine transformation, and use this to characterize the class of unseen perturbations for which we obtain extrapolation guarantees. To estimate the model from data, we propose a new method, the perturbation distribution autoencoder (PDAE), which is trained by maximizing the distributional similarity between true and predicted perturbation distributions. The trained model can then be used to predict previously unseen perturbation distributions. Empirical evidence suggests that PDAE compares favorably to existing methods and baselines at predicting the effects of unseen perturbations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of modelling the effects of unseen perturbations suchas gene knockdowns or drug combinations on low-level measurements such as RNAsequencing data. Specifically, given data collected under some perturbations,we aim to predict the distribution of measurements for new perturbations. Toaddress this challenging extrapolation task, we posit that perturbations actadditively in a suitable, unknown embedding space. More precisely, we formulatethe generative process underlying the observed data as a latent variable model,in which perturbations amount to mean shifts in latent space and can becombined additively. Unlike previous work, we prove that, given sufficientlydiverse training perturbations, the representation and perturbation effects areidentifiable up to affine transformation, and use this to characterize theclass of unseen perturbations for which we obtain extrapolation guarantees. Toestimate the model from data, we propose a new method, the perturbationdistribution autoencoder (PDAE), which is trained by maximising thedistributional similarity between true and predicted perturbationdistributions. The trained model can then be used to predict previously unseenperturbation distributions. Empirical evidence suggests that PDAE comparesfavourably to existing methods and baselines at predicting the effects ofunseen perturbations.</description>
      <author>example@mail.com (Julius von Kügelgen, Jakob Ketterer, Xinwei Shen, Nicolai Meinshausen, Jonas Peters)</author>
      <guid isPermaLink="false">2504.18522v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>POET: Prompt Offset Tuning for Continual Human Action Adaptation</title>
      <link>http://arxiv.org/abs/2504.18059v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECCV 2024 (Oral), webpage  https://humansensinglab.github.io/POET-continual-action-recognition/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究扩展现实（XR）背景下的人体动作识别，提出了一种隐私感知的少量样本持续动作识别方法POET，旨在允许用户持续添加新动作类别到设备模型中，而不需要存储或回放敏感训练数据。&lt;h4&gt;背景&lt;/h4&gt;扩展现实（XR）技术正在改变用户与计算设备交互的方式，人体动作识别在沉浸式计算设备中的应用研究越来越受到重视。&lt;h4&gt;目的&lt;/h4&gt;提供用户和开发者持续添加新动作类别到设备模型的能力，实现低样本和高效的用户个性化体验。&lt;h4&gt;方法&lt;/h4&gt;提出POET方法，通过轻量级的预训练骨干网络和新的时空可学习提示偏移调整方法，首次将提示调整应用于图神经网络，并提出NTURGB+D和SHREC-2017两个新的基准数据集。&lt;h4&gt;主要发现&lt;/h4&gt;POET在持续学习和隐私保护方面表现出色，在多个基准数据集上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;POET是一种有效且隐私友好的持续动作识别方法，为扩展现实技术中的人体动作识别提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;As extended reality (XR) is redefining how users interact with computing devices, research in human action recognition is gaining prominence. Typically, models deployed on immersive computing devices are static and limited to their default set of classes. The goal of our research is to provide users and developers with the capability to personalize their experience by adding new action classes to their device models continually. Importantly, a user should be able to add new classes in a low-shot and efficient manner, while this process should not require storing or replaying any of user's sensitivetraining data. We formalize this problem as privacy-aware few-shot continual action recognition. Towards this end, we propose POET: Prompt-Offset Tuning. While existing prompt tuning approaches have shown great promise for continual learning of image, text, and video modalities; they demand access to extensively pretrained transformers. Breaking away from this assumption, POET demonstrates the efficacy of prompt tuning a significantly lightweight backbone, pretrained exclusively on the base class data. We propose a novel spatial-temporal learnable prompt offset tuning approach, and are the first to apply such prompt tuning to Graph Neural Networks. We contribute two new benchmarks for our new problem setting in human action recognition: (i) NTURGB+D dataset for activity recognition, and (ii) SHREC-2017 dataset for handgesture recognition. We find that POET consistently outperforms comprehensive benchmarks. Source code at https://github.com/humansensinglab/POET-continual-action-recognition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-73039-9_25&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As extended reality (XR) is redefining how users interact with computingdevices, research in human action recognition is gaining prominence. Typically,models deployed on immersive computing devices are static and limited to theirdefault set of classes. The goal of our research is to provide users anddevelopers with the capability to personalize their experience by adding newaction classes to their device models continually. Importantly, a user shouldbe able to add new classes in a low-shot and efficient manner, while thisprocess should not require storing or replaying any of user's sensitivetraining data. We formalize this problem as privacy-aware few-shot continualaction recognition. Towards this end, we propose POET: Prompt-Offset Tuning.While existing prompt tuning approaches have shown great promise for continuallearning of image, text, and video modalities; they demand access toextensively pretrained transformers. Breaking away from this assumption, POETdemonstrates the efficacy of prompt tuning a significantly lightweightbackbone, pretrained exclusively on the base class data. We propose a novelspatio-temporal learnable prompt offset tuning approach, and are the first toapply such prompt tuning to Graph Neural Networks. We contribute two newbenchmarks for our new problem setting in human action recognition: (i) NTURGB+D dataset for activity recognition, and (ii) SHREC-2017 dataset for handgesture recognition. We find that POET consistently outperforms comprehensivebenchmarks. Source code athttps://github.com/humansensinglab/POET-continual-action-recognition.</description>
      <author>example@mail.com (Prachi Garg, Joseph K J, Vineeth N Balasubramanian, Necati Cihan Camgoz, Chengde Wan, Kenrick Kin, Weiguang Si, Shugao Ma, Fernando De La Torre)</author>
      <guid isPermaLink="false">2504.18059v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>LiDAR-Guided Monocular 3D Object Detection for Long-Range Railway Monitoring</title>
      <link>http://arxiv.org/abs/2504.18203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for the Data-Driven Learning for Intelligent Vehicle  Applications Workshop at the 36th IEEE Intelligent Vehicles Symposium (IV)  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的长距离3D物体检测方法，旨在解决铁路系统自动化中的感知挑战，并针对德国铁路系统进行优化。&lt;h4&gt;背景&lt;/h4&gt;德国铁路系统需要高度自动化来解决遗留基础设施挑战，并安全增加列车交通。&lt;h4&gt;目的&lt;/h4&gt;开发一种长距离感知技术，用于早期危险检测，如道口障碍物或铁轨上的行人。&lt;h4&gt;方法&lt;/h4&gt;该方法基于深度学习，仅使用单目图像，并借鉴了Faraway-Frustum方法。在训练过程中结合LiDAR数据以改进深度估计。主要模块包括：(1)修改后的YOLOv9进行2.5D物体检测，(2)深度估计网络，以及(3-4)专用短距离和长距离3D检测头。&lt;h4&gt;主要发现&lt;/h4&gt;在OSDaR23数据集上的评估显示，该方法能够检测到250米范围内的物体，具有在铁路自动化中的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法在铁路自动化方面具有潜力，并指出了未来改进的领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要：铁路系统，特别是在德国，需要高度自动化来解决遗留基础设施挑战并安全增加列车交通。自动化的关键组成部分是强大的长距离感知，这对于早期危险检测至关重要，例如道口的障碍物或铁轨上的行人。与制动距离约为70米的汽车系统不同，列车需要超过1公里的感知范围。本文提出了一种基于深度学习的方法，用于针对自动驾驶火车进行长距离3D物体检测。该方法仅依赖于单目图像，灵感来源于Faraway-Frustum方法，并在训练过程中结合LiDAR数据以改进深度估计。所提出的流程包括四个关键模块：(1)用于2.5D物体检测的修改后的YOLOv9，(2)深度估计网络，以及(3-4)专门的短距离和长距离3D检测头。在OSDaR23数据集上的评估表明，该方法在检测250米范围内的物体方面是有效的。结果突出了其在铁路自动化方面的潜力，并概述了未来改进的领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Railway systems, particularly in Germany, require high levels of automationto address legacy infrastructure challenges and increase train traffic safely.A key component of automation is robust long-range perception, essential forearly hazard detection, such as obstacles at level crossings or pedestrians ontracks. Unlike automotive systems with braking distances of ~70 meters, trainsrequire perception ranges exceeding 1 km. This paper presents andeep-learning-based approach for long-range 3D object detection tailored forautonomous trains. The method relies solely on monocular images, inspired bythe Faraway-Frustum approach, and incorporates LiDAR data during training toimprove depth estimation. The proposed pipeline consists of four key modules:(1) a modified YOLOv9 for 2.5D object detection, (2) a depth estimationnetwork, and (3-4) dedicated short- and long-range 3D detection heads.Evaluations on the OSDaR23 dataset demonstrate the effectiveness of theapproach in detecting objects up to 250 meters. Results highlight its potentialfor railway automation and outline areas for future improvement.</description>
      <author>example@mail.com (Raul David Dominguez Sanchez, Xavier Diaz Ortiz, Xingcheng Zhou, Max Peter Ronecker, Michael Karner, Daniel Watzenig, Alois Knoll)</author>
      <guid isPermaLink="false">2504.18203v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography</title>
      <link>http://arxiv.org/abs/2504.18400v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 3 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Tract2Shape是一种新型多模态深度学习框架，用于预测白质束追踪的形状度量，具有计算效率高、预测准确和泛化能力强等特点。&lt;h4&gt;背景&lt;/h4&gt;传统的形状度量计算方法计算量大，不适用于大规模数据集。&lt;h4&gt;目的&lt;/h4&gt;提出Tract2Shape框架，以实现快速、准确和可泛化的白质形状度量预测。&lt;h4&gt;方法&lt;/h4&gt;Tract2Shape利用几何（点云）和标量（表格）特征预测十个白质束追踪的形状度量，并使用降维算法预测五个主要形状成分。&lt;h4&gt;主要发现&lt;/h4&gt;Tract2Shape在HCP-YA数据集上优于现有的深度学习模型，实现了最高的平均Pearson相关系数和最低的均方误差。消融研究表明，多模态输入和PCA对性能提升有贡献。在未见的PPMI数据集上，Tract2Shape保持了高Pearson相关系数和低均方误差，显示了强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;Tract2Shape框架为未来大规模白质形状分析提供了有希望的起点，支持数据集的可扩展分析。&lt;h4&gt;翻译&lt;/h4&gt;Shape measures have emerged as promising descriptors of white matter tractography, offering complementary insights into anatomical variability and associations with cognitive and clinical phenotypes. However, conventional methods for computing shape measures are computationally expensive and time-consuming for large-scale datasets due to reliance on voxel-based representations. We propose Tract2Shape, a novel multimodal deep learning framework that leverages geometric (point cloud) and scalar (tabular) featuresto predict ten white matter tractography shape measures. To enhance model efficiency, we utilize a dimensionality reduction algorithm for the model topredict five primary shape components. The model is trained and evaluated on two independently acquired datasets, the HCP-YA dataset, and the PPMI dataset. We evaluate the performance of Tract2Shape by training and testing it on the HCP-YA dataset and comparing the results with state-of-the-art models. To further assess its robustness and generalization ability, we also test Tract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deep learning models across all ten shape measures, achieving the highest average Pearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study shows that both multimodal input and PCA contribute to performance gains. On the unseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and low nMSE, demonstrating strong generalizability in cross-dataset evaluation. Tract2Shape enables fast, accurate, and generalizable prediction of white matter shape measures from tractography data, supporting scalable analysis across datasets. This framework lays a promising foundation for future large-scale white matter shape analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Shape measures have emerged as promising descriptors of white mattertractography, offering complementary insights into anatomical variability andassociations with cognitive and clinical phenotypes. However, conventionalmethods for computing shape measures are computationally expensive andtime-consuming for large-scale datasets due to reliance on voxel-basedrepresentations. We propose Tract2Shape, a novel multimodal deep learningframework that leverages geometric (point cloud) and scalar (tabular) featuresto predict ten white matter tractography shape measures. To enhance modelefficiency, we utilize a dimensionality reduction algorithm for the model topredict five primary shape components. The model is trained and evaluated ontwo independently acquired datasets, the HCP-YA dataset, and the PPMI dataset.We evaluate the performance of Tract2Shape by training and testing it on theHCP-YA dataset and comparing the results with state-of-the-art models. Tofurther assess its robustness and generalization ability, we also testTract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deeplearning models across all ten shape measures, achieving the highest averagePearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study showsthat both multimodal input and PCA contribute to performance gains. On theunseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and lownMSE, demonstrating strong generalizability in cross-dataset evaluation.Tract2Shape enables fast, accurate, and generalizable prediction of whitematter shape measures from tractography data, supporting scalable analysisacross datasets. This framework lays a promising foundation for futurelarge-scale white matter shape analysis.</description>
      <author>example@mail.com (Yui Lo, Yuqian Chen, Dongnan Liu, Leo Zekelman, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Fan Zhang, Weidong Cai, Lauren J. O'Donnell)</author>
      <guid isPermaLink="false">2504.18400v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>TGDT: A Temporal Graph-based Digital Twin for Urban Traffic Corridors</title>
      <link>http://arxiv.org/abs/2504.18008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TGDT的基于时间图的城市交通数字孪生框架，用于解决城市信号交叉口拥堵问题。&lt;h4&gt;背景&lt;/h4&gt;城市信号交叉口的拥堵导致重大延误、经济损失和排放增加。现有的深度学习模型通常缺乏空间泛化能力，依赖于复杂的架构，并且难以实时部署。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有模型的局限性，提出一种能够动态、方向感知地建模和评估城市走廊交通的框架。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了时间卷积网络和注意力图神经网络，能够估计交叉口和走廊层面的关键有效性指标（MOEs），如排队长度、等待时间、交通量和旅行时间。&lt;h4&gt;主要发现&lt;/h4&gt;TGDT模型能够准确产生高维、并发多输出估计，优于现有的基准模型。它在不同的交通条件下表现出高鲁棒性和准确性，包括极端情况，且仅依赖于最小数量的交通特征。&lt;h4&gt;结论&lt;/h4&gt;TGDT是一种成本效益高、可解释和实时的解决方案，可以快速模拟大量场景，为交通信号优化提供支持。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is summarized as follows: We propose the TemporalGraph-based Digital Twin (TGDT) framework to address the issue of urban congestion at signalized intersections. This framework combines Temporal Convolutional Networks and Attentional Graph Neural Networks to dynamically and directionally model traffic on urban corridors, and estimates key Measures of Effectiveness (MOEs) for traffic flow optimization at both intersection and corridor levels. TGDT demonstrates high robustness and accuracy across diverse traffic conditions, and is a cost-effective, interpretable, and real-time solution for traffic signal optimization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban congestion at signalized intersections leads to significant delays,economic losses, and increased emissions. Existing deep learning models oftenlack spatial generalizability, rely on complex architectures, and struggle withreal-time deployment. To address these limitations, we propose the TemporalGraph-based Digital Twin (TGDT), a scalable framework that integrates TemporalConvolutional Networks and Attentional Graph Neural Networks for dynamic,direction-aware traffic modeling and assessment at urban corridors. TGDTestimates key Measures of Effectiveness (MOEs) for traffic flow optimization atboth the intersection level (e.g., queue length, waiting time) and the corridorlevel (e.g., traffic volume, travel time). Its modular architecture andsequential optimization scheme enable easy extension to any number ofintersections and MOEs. The model outperforms state-of-the-art baselines byaccurately producing high-dimensional, concurrent multi-output estimates. Italso demonstrates high robustness and accuracy across diverse trafficconditions, including extreme scenarios, while relying on only a minimal set oftraffic features. Fully parallelized, TGDT can simulate over a thousandscenarios within a matter of seconds, offering a cost-effective, interpretable,and real-time solution for traffic signal optimization.</description>
      <author>example@mail.com (Nooshin Yousefzadeh, Rahul Sengupta, Sanjay Ranka)</author>
      <guid isPermaLink="false">2504.18008v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Unifying Direct and Indirect Learning for Safe Control of Linear Systems</title>
      <link>http://arxiv.org/abs/2504.18331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2502.04195&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文旨在学习不确定离散时间线性系统在扰动下的安全控制器，同时实现两个关键目标：1)整合不同来源的信息（即物理知识的先验信息和流数据的后验信息），2)统一直接学习和间接学习。&lt;h4&gt;背景&lt;/h4&gt;研究不确定离散时间线性系统在扰动下的控制器设计。&lt;h4&gt;目的&lt;/h4&gt;学习安全控制器，并实现信息整合和学习方法的统一。&lt;h4&gt;方法&lt;/h4&gt;1)利用矩阵区群表示闭环系统，并通过数据对其进行特征化。2)通过添加等式一致性约束，将数据得到的矩阵区群转化为约束矩阵区群，并利用先验知识进行细化。3)利用基于区群的系统识别方法，从不同数据源中进行迁移学习。4)直接学习控制器，通过多边形和区群安全集来实现闭环系统的鲁棒安全性。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种结合先验知识和数据驱动的约束矩阵区群形式的闭环系统表示方法，并开发了一种针对多边形安全集的原对偶优化方法，以实现闭环系统的安全。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效地实现闭环系统的安全控制，并支持信息整合和在线数据适应。&lt;h4&gt;翻译&lt;/h4&gt;本文旨在学习不确定离散时间线性系统在扰动下的安全控制器，在实现以下两个关键目标的同时：1)整合不同来源的信息（即基于物理知识的先验信息和基于流数据的后验信息），2)统一直接学习与间接学习。这些目标通过表示与先验知识一致的参数化数据驱动的约束矩阵区群闭环系统而实现。为此，首先利用收集的数据通过矩阵区群来表征闭环系统，并展示通过添加等式一致性约束，可以使用先验知识的形式化地解释这些闭环系统，从而将数据得到的矩阵区群细化为约束矩阵区群。进一步地，通过使其与从基于区群的系统识别中获得的一组模型相一致来细化先验知识。用于基于区群的系统识别的数据源可以不同于用于闭环表示的数据源，从而允许进行迁移学习和在线新数据适应。然后利用参数化的闭环系统集直接学习一个鲁棒地对闭环系统施加安全性的控制器。考虑了多边形和区群安全集，并使用线性规划提供了集包含条件，以通过λ-收缩性实现安全性。对于多边形安全集，开发了一种原对偶优化来形式化线性规划优化，以证明集合包含。对于区群安全集，形成了所有下一个状态的有约束区群集，并通过确保该约束区群包含在安全集的λ缩放水平集中来实现集合包含。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper aims to learn safe controllers for uncertain discrete-time linearsystems under disturbances while achieving the following two crucial goals: 1)integration of different sources of information (i.e., prior information interms of physical knowledge and posterior information in terms of streamingdata), and 2) unifying direct learning with indirect learning. These goals areachieved by representing a parametrized data-driven constrained matrix zonotopeform of closed-loop systems that is conformant to prior knowledge. To this end,we first leverage collected data to characterize closed-loop systems by amatrix zonotope and then show that the explainability of these closed-loopsystems by prior knowledge can be formalized by adding an equality conformityconstraint, which refines the matrix zonotope obtained by data to a constrainedmatrix zonotope. The prior knowledge is further refined by conforming it to theset of models obtained from a novel zonotope-based system identifier. Thesource of data used for zonotope-based system identification can be differentthan the one used for closed-loop representation, allowing to perform transferlearning and online adaptation to new data. The parametrized closed-loop set ofsystems is then leveraged to directly learn a controller that robustly imposessafety on the closed-loop system. We consider both polytope and zonotope safesets and provide set inclusion conditions using linear programming to imposesafety through {\lambda}-contractivity. For polytope safe sets, a primal-dualoptimization is developed to formalize a linear programming optimization thatcertifies the set inclusion. For zonotope safe sets, the constrained zonotopeset of all next states is formed, and set inclusion is achieved by ensuring theinclusion of this constrained zonotope in a {\lambda}-scaled level set of thesafe set.</description>
      <author>example@mail.com (Amir Modares, Niyousha Ghiasi, Bahare Kiumarsi, Hamidreza Modares)</author>
      <guid isPermaLink="false">2504.18331v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Affordance Detection on 3D Point Clouds with Probabilistic Prototypes</title>
      <link>http://arxiv.org/abs/2504.18355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于原型学习的方法，用于3D点云上的可及性检测，旨在提高人机交互中的信任和安全。&lt;h4&gt;背景&lt;/h4&gt;机器人需要理解如何与环境中的物体进行交互，无论是自主操作还是与人类交互。传统的可及性检测依赖于深学习模型，如PointNet++、DGCNN或PointTransformerV3，但这些模型作为黑盒模型，缺乏决策过程的洞察。&lt;h4&gt;目的&lt;/h4&gt;提出一种可解释的原型学习方法，以替代黑盒模型，并在3D点云的可及性检测中应用。&lt;h4&gt;方法&lt;/h4&gt;将原型学习方法应用于3D点云的可及性检测模型，并在3D-AffordanceNet基准数据集上进行了实验。&lt;h4&gt;主要发现&lt;/h4&gt;原型模型在3D-AffordanceNet数据集上实现了与最先进黑盒模型相当的性能，并提供了内在的可解释性。&lt;h4&gt;结论&lt;/h4&gt;原型模型在需要增加信任和安全的场景中，如人机交互，是一个有希望的候选方案。&lt;h4&gt;翻译&lt;/h4&gt;This abstract discusses the application of prototypical learning to affordance detection on 3D point clouds, aiming to enhance trust and safety in human-robot interaction scenarios. Traditional methods rely on deep learning models, which are black boxes and lack interpretability. The proposed prototypical models achieve competitive performance on a benchmark dataset and offer inherent interpretability, making them a promising candidate for human-robot interaction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic agents need to understand how to interact with objects in theirenvironment, both autonomously and during human-robot interactions. Affordancedetection on 3D point clouds, which identifies object regions that allowspecific interactions, has traditionally relied on deep learning models likePointNet++, DGCNN, or PointTransformerV3. However, these models operate asblack boxes, offering no insight into their decision-making processes.Prototypical Learning methods, such as ProtoPNet, provide an interpretablealternative to black-box models by employing a "this looks like that"case-based reasoning approach. However, they have been primarily applied toimage-based tasks. In this work, we apply prototypical learning to models foraffordance detection on 3D point clouds. Experiments on the 3D-AffordanceNetbenchmark dataset show that prototypical models achieve competitive performancewith state-of-the-art black-box models and offer inherent interpretability.This makes prototypical models a promising candidate for human-robotinteraction scenarios that require increased trust and safety.</description>
      <author>example@mail.com (Maximilian Xiling Li, Korbinian Rudolf, Nils Blank, Rudolf Lioutikov)</author>
      <guid isPermaLink="false">2504.18355v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>STP4D: Spatio-Temporal-Prompt Consistent Modeling for Text-to-4D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2504.18318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;STP4D是一个用于高质量文本到4D生成的创新方法，通过集成空间-时间-提示一致性建模来解决现有方法中存在的问题。&lt;h4&gt;背景&lt;/h4&gt;文本到4D生成技术在各种场景中得到广泛应用，但现有方法往往缺乏统一框架内的充分空间-时间建模和提示对齐，导致时间不一致、几何扭曲或低质量4D内容。&lt;h4&gt;目的&lt;/h4&gt;提出STP4D，旨在整合空间-时间-提示一致性建模，以实现高质量的文本到4D生成。&lt;h4&gt;方法&lt;/h4&gt;STP4D采用三个精心设计的模块：时变提示嵌入、几何信息增强和时态扩展变形，共同实现目标。同时，STP4D是首批利用扩散模型生成4D高斯的方法之一，结合了4DGS的细粒度建模能力和实时渲染过程与扩散模型的快速推理速度。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，STP4D在生成高保真4D内容方面表现出色，效率极高（每资产大约4.6秒），在质量和速度上都优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;STP4D是文本到4D生成领域的一项重大进步，为该领域提供了高效、高质量的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-to-4D generation is rapidly developing and widely applied in variousscenarios. However, existing methods often fail to incorporate adequatespatio-temporal modeling and prompt alignment within a unified framework,resulting in temporal inconsistencies, geometric distortions, or low-quality 4Dcontent that deviates from the provided texts. Therefore, we propose STP4D, anovel approach that aims to integrate comprehensive spatio-temporal-promptconsistency modeling for high-quality text-to-4D generation. Specifically,STP4D employs three carefully designed modules: Time-varying Prompt Embedding,Geometric Information Enhancement, and Temporal Extension Deformation, whichcollaborate to accomplish this goal. Furthermore, STP4D is among the firstmethods to exploit the Diffusion model to generate 4D Gaussians, combining thefine-grained modeling capabilities and the real-time rendering process of 4DGSwith the rapid inference speed of the Diffusion model. Extensive experimentsdemonstrate that STP4D excels in generating high-fidelity 4D content withexceptional efficiency (approximately 4.6s per asset), surpassing existingmethods in both quality and speed.</description>
      <author>example@mail.com (Yunze Deng, Haijun Xiong, Bin Feng, Xinggang Wang, Wenyu Liu)</author>
      <guid isPermaLink="false">2504.18318v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>LaRI: Layered Ray Intersections for Single-view 3D Geometric Reasoning</title>
      <link>http://arxiv.org/abs/2504.18424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://ruili3.github.io/lari&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为分层光线交点（LaRI）的新方法，用于从单张图像中进行未见几何推理。&lt;h4&gt;背景&lt;/h4&gt;传统的深度估计方法仅限于可见表面，而LaRI通过使用分层点图来模拟被相机光线交错的多个表面。&lt;h4&gt;目的&lt;/h4&gt;LaRI旨在通过分层表示和高效推理，实现物体和场景级别的任务统一。&lt;h4&gt;方法&lt;/h4&gt;LaRI提出预测光线停止索引，以从其输出中识别有效的交点和层。此外，还建立了一个完整的训练数据生成流程，包括合成和真实世界数据，包括3D物体和场景，并进行了必要的数据清理和渲染引擎之间的协调。&lt;h4&gt;主要发现&lt;/h4&gt;LaRI在两个场景中验证了其性能：使用4%的训练数据和17%的参数，其物体级别结果与最近的大型生成模型相当。同时，它在仅一次前馈中实现了场景级别的遮挡几何推理。&lt;h4&gt;结论&lt;/h4&gt;LaRI是一种通用的方法，在物体和场景级别的几何推理方面表现良好，具有高效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present layered ray intersections (LaRI), a new method for unseen geometryreasoning from a single image. Unlike conventional depth estimation that islimited to the visible surface, LaRI models multiple surfaces intersected bythe camera rays using layered point maps. Benefiting from the compact andlayered representation, LaRI enables complete, efficient, and view-alignedgeometric reasoning to unify object- and scene-level tasks. We further proposeto predict the ray stopping index, which identifies valid intersecting pixelsand layers from LaRI's output. We build a complete training data generationpipeline for synthetic and real-world data, including 3D objects and scenes,with necessary data cleaning steps and coordination between rendering engines.As a generic method, LaRI's performance is validated in two scenarios: Ityields comparable object-level results to the recent large generative modelusing 4% of its training data and 17% of its parameters. Meanwhile, it achievesscene-level occluded geometry reasoning in only one feed-forward.</description>
      <author>example@mail.com (Rui Li, Biao Zhang, Zhenyu Li, Federico Tombari, Peter Wonka)</author>
      <guid isPermaLink="false">2504.18424v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset</title>
      <link>http://arxiv.org/abs/2504.17371v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DeepScenario Open 3D Dataset（DSC3D），一个高质量的、无遮挡的3D轨迹数据集，用于推进自动驾驶技术的发展。&lt;h4&gt;背景&lt;/h4&gt;传统的3D轨迹数据集通常由固定在车辆上的传感器捕获，容易受到遮挡，且只能精确地重建测量车辆附近动态环境，忽略了更远处的物体。&lt;h4&gt;目的&lt;/h4&gt;通过提供详细的3D环境表示，提高自动驾驶系统的障碍物交互和安全性能。&lt;h4&gt;方法&lt;/h4&gt;使用一种新型的单目相机无人机跟踪流程，收集了超过175,000条14种交通参与者的轨迹数据，数据集包括停车场的场景、拥挤的城市街道、陡峭的城市交叉口、联邦公路和郊区的交叉口等。&lt;h4&gt;主要发现&lt;/h4&gt;DSC3D数据集在多样性和规模上显著超过了现有数据集，包括许多前所未有的场景，如高度人口密集的城市街道上的复杂车辆-行人交互和从入口到出口的全面停车操作。&lt;h4&gt;结论&lt;/h4&gt;DSC3D数据集对多个应用有用，包括运动预测、运动规划、场景挖掘和生成式反应式交通代理。数据集和在线可视化平台公开可用，促进了运动预测、行为建模和安全验证的研究。&lt;h4&gt;翻译&lt;/h4&gt;Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet, traditional datasets are usually captured by fixed sensors mounted on a car and are susceptible to occlusion. Additionally, such an approach can precisely reconstruct the dynamic environment in the close vicinity of the measurement vehicle only, while neglecting objects that are further away. In this paper, we introduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality, occlusion-free dataset of 6 degrees of freedom bounding box trajectories acquired through a novel monocular camera drone tracking pipeline. Our dataset includes more than 175,000 trajectories of 14 types of traffic participants and significantly exceeds existing datasets in terms of diversity and scale, containing many unprecedented scenarios such as complex vehicle-pedestrian interaction on highly populated urban streets and comprehensive parking maneuvers from entry to exit. DSC3D dataset was captured in five various locations in Europe and the United States and include: a parking lot, a crowded inner-city, a steep urban intersection, a federal highway, and a suburban intersection. Our 3D trajectory dataset aims to enhance autonomous driving systems by providing detailed environmental 3D representations, which could lead to improved obstacle interactions and safety. We demonstrate its utility across multiple applications including motion prediction, motion planning, scenario mining, and generative reactive traffic agents. Our interactive online visualization platform and the complete dataset are publicly available at https://app.deepscenario.com, facilitating research in motion prediction, behavior modeling, and safety validation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet,traditional datasets are usually captured by fixed sensors mounted on a car andare susceptible to occlusion. Additionally, such an approach can preciselyreconstruct the dynamic environment in the close vicinity of the measurementvehicle only, while neglecting objects that are further away. In this paper, weintroduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality,occlusion-free dataset of 6 degrees of freedom bounding box trajectoriesacquired through a novel monocular camera drone tracking pipeline. Our datasetincludes more than 175,000 trajectories of 14 types of traffic participants andsignificantly exceeds existing datasets in terms of diversity and scale,containing many unprecedented scenarios such as complex vehicle-pedestrianinteraction on highly populated urban streets and comprehensive parkingmaneuvers from entry to exit. DSC3D dataset was captured in five variouslocations in Europe and the United States and include: a parking lot, a crowdedinner-city, a steep urban intersection, a federal highway, and a suburbanintersection. Our 3D trajectory dataset aims to enhance autonomous drivingsystems by providing detailed environmental 3D representations, which couldlead to improved obstacle interactions and safety. We demonstrate its utilityacross multiple applications including motion prediction, motion planning,scenario mining, and generative reactive traffic agents. Our interactive onlinevisualization platform and the complete dataset are publicly available athttps://app.deepscenario.com, facilitating research in motion prediction,behavior modeling, and safety validation.</description>
      <author>example@mail.com (Oussema Dhaouadi, Johannes Meier, Luca Wahl, Jacques Kaiser, Luca Scalerandi, Nick Wandelburg, Zhuolun Zhou, Nijanthan Berinpanathan, Holger Banzhaf, Daniel Cremers)</author>
      <guid isPermaLink="false">2504.17371v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Generalization Capability for Imitation Learning</title>
      <link>http://arxiv.org/abs/2504.18538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文从信息论和数据分布性质出发，对模仿学习中的泛化能力进行了统一的理论分析。&lt;h4&gt;背景&lt;/h4&gt;模仿学习通过学习专家的演示来赋予机器人灵活的技能，但基于有限数据集训练的策略在超出训练分布的泛化上存在困难。&lt;h4&gt;目的&lt;/h4&gt;研究如何提高模仿学习的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于信息论和数据分布性质的理论视角，通过分析条件信息瓶颈和模型参数与训练数据集之间的互信息来界定泛化差距。&lt;h4&gt;主要发现&lt;/h4&gt;1. 泛化差距可以通过中间表示的条件信息瓶颈和模型参数与训练数据集之间的互信息来界定。2. 输入到输出的高条件熵会使得似然度景观更平坦，从而减少泛化差距的上界。3. 高条件熵还能缩短随机梯度下降（SGD）从尖锐局部最小值逃逸的时间，提高在固定优化预算下达到全局优化的可能性。&lt;h4&gt;结论&lt;/h4&gt;这些发现解释了为什么模仿学习通常泛化能力有限，并强调了不仅需要扩展输入数据的多样性，还需要丰富同一输入条件下的输出标签的变异性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：模仿学习有希望通过学习专家演示来赋予机器人多样化的技能。然而，在有限数据集上训练的策略往往难以泛化到训练分布之外。在这项工作中，我们提出了对模仿学习泛化能力的一个统一视角，该视角建立在信息论和数据分布性质的基础上。我们首先表明，泛化差距可以通过（i）中间表示的条件信息瓶颈和（ii）模型参数与训练数据集之间的互信息来上界。这种特征化提供了在模仿学习中设计有效训练策略的理论指导，特别是在确定是否冻结、微调或从头开始训练大型预训练编码器（例如视觉-语言模型或视觉基础模型）以实现更好的泛化方面。此外，我们表明，从输入到输出的高条件熵会诱导一个更平的似然度景观，从而降低泛化差距的上界。此外，它缩短了随机梯度下降（SGD）从尖锐局部最小值逃逸的时间，这可能会在固定的优化预算下增加达到全局优化的可能性。这些见解解释了为什么模仿学习经常表现出有限的泛化能力，并强调了不仅需要扩展输入数据的多样性，还需要丰富同一输入条件下的输出标签的变异性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning holds the promise of equipping robots with versatileskills by learning from expert demonstrations. However, policies trained onfinite datasets often struggle to generalize beyond the training distribution.In this work, we present a unified perspective on the generalization capabilityof imitation learning, grounded in both information theorey and datadistribution property. We first show that the generalization gap can be upperbounded by (i) the conditional information bottleneck on intermediaterepresentations and (ii) the mutual information between the model parametersand the training dataset. This characterization provides theoretical guidancefor designing effective training strategies in imitation learning, particularlyin determining whether to freeze, fine-tune, or train large pretrained encoders(e.g., vision-language models or vision foundation models) from scratch toachieve better generalization. Furthermore, we demonstrate that highconditional entropy from input to output induces a flatter likelihoodlandscape, thereby reducing the upper bound on the generalization gap. Inaddition, it shortens the stochastic gradient descent (SGD) escape time fromsharp local minima, which may increase the likelihood of reaching global optimaunder fixed optimization budgets. These insights explain why imitation learningoften exhibits limited generalization and underscore the importance of not onlyscaling the diversity of input data but also enriching the variability ofoutput labels conditioned on the same input.</description>
      <author>example@mail.com (Yixiao Wang)</author>
      <guid isPermaLink="false">2504.18538v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Generalization Guarantees for Multi-View Representation Learning and Application to Regularization via Gaussian Product Mixture Prior</title>
      <link>http://arxiv.org/abs/2504.18455v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2502.15540&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了分布式多视角表示学习问题，探讨了在没有明确协调的情况下，每个代理应从其视角中提取哪些信息以实现正确估计。&lt;h4&gt;背景&lt;/h4&gt;分布式多视角表示学习问题涉及多个代理各自观察不同的视角并独立提取表示，然后解码器使用这些表示来估计隐藏标签。&lt;h4&gt;目的&lt;/h4&gt;从泛化误差的角度研究如何让每个代理提取必要且足够的信息以实现正确估计。&lt;h4&gt;方法&lt;/h4&gt;建立了基于相对熵（表示提取分布与对称先验，即所有视角和训练测试数据集的潜在变量的最小描述长度）的泛化界限，并利用这些界限设计正则化器，深入研究选择合适先验的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，基于数据依赖的高斯混合先验和精心选择的权重可以带来良好的性能；对于单视角设置，实验结果优于现有的先验艺术变分信息瓶颈（VIB）和类别依赖VIB（CDVIB）方法；在多视角设置中，选择联合先验为高斯乘积混合导致每个边际视角的高斯混合边缘先验，并隐式鼓励代理提取和输出冗余特征。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在分布式多视角表示学习方面取得了良好的性能，并揭示了新的发现，如加权注意力机制和冗余特征提取的鼓励。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of distributed multi-view representation learning. Inthis problem, $K$ agents observe each one distinct, possibly statisticallycorrelated, view and independently extracts from it a suitable representationin a manner that a decoder that gets all $K$ representations estimatescorrectly the hidden label. In the absence of any explicit coordination betweenthe agents, a central question is: what should each agent extract from its viewthat is necessary and sufficient for a correct estimation at the decoder? Inthis paper, we investigate this question from a generalization errorperspective. First, we establish several generalization bounds in terms of therelative entropy between the distribution of the representations extracted fromtraining and "test" datasets and a data-dependent symmetric prior, i.e., theMinimum Description Length (MDL) of the latent variables for all views andtraining and test datasets. Then, we use the obtained bounds to devise aregularizer; and investigate in depth the question of the selection of asuitable prior. In particular, we show and conduct experiments that illustratethat our data-dependent Gaussian mixture priors with judiciously chosen weightslead to good performance. For single-view settings (i.e., $K=1$), ourexperimental results are shown to outperform existing prior art VariationalInformation Bottleneck (VIB) and Category-Dependent VIB (CDVIB) approaches.Interestingly, we show that a weighted attention mechanism emerges naturally inthis setting. Finally, for the multi-view setting, we show that the selectionof the joint prior as a Gaussians product mixture induces a Gaussian mixturemarginal prior for each marginal view and implicitly encourages the agents toextract and output redundant features, a finding which is somewhatcounter-intuitive.</description>
      <author>example@mail.com (Milad Sefidgaran, Abdellatif Zaidi, Piotr Krasnowski)</author>
      <guid isPermaLink="false">2504.18455v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Post-Transfer Learning Statistical Inference in High-Dimensional Regression</title>
      <link>http://arxiv.org/abs/2504.18212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PTL-SI（后迁移学习统计推断）的新统计推断框架，用于评估迁移学习高维回归（TL-HDR）中特征选择的可靠性。&lt;h4&gt;背景&lt;/h4&gt;迁移学习在高维回归任务中非常重要，尤其是在目标任务样本量有限的情况下。然而，目前缺乏一种方法来量化TL-HDR设置中特征与响应之间的关系统计显著性。&lt;h4&gt;目的&lt;/h4&gt;目的是提供一个统计推断框架，用于在TL-HDR环境中评估特征选择的可靠性，并提供有效的p值来控制假阳性率。&lt;h4&gt;方法&lt;/h4&gt;PTL-SI框架能够为TL-HDR中选定的特征提供有效的p值，并通过结合战略性的分而治之方法来增强统计功效。&lt;h4&gt;主要发现&lt;/h4&gt;通过在合成和真实世界的高维数据集上进行广泛实验，验证了PTL-SI的有效性和实用性，并确认了其在测试迁移学习场景中特征选择可靠性方面的理论特性和效用。&lt;h4&gt;结论&lt;/h4&gt;PTL-SI是一种有效的工具，可以用于迁移学习高维回归中特征选择的可靠性评估，有助于提高模型性能和降低错误率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning (TL) for high-dimensional regression (HDR) is an importantproblem in machine learning, particularly when dealing with limited sample sizein the target task. However, there currently lacks a method to quantify thestatistical significance of the relationship between features and the responsein TL-HDR settings. In this paper, we introduce a novel statistical inferenceframework for assessing the reliability of feature selection in TL-HDR, calledPTL-SI (Post-TL Statistical Inference). The core contribution of PTL-SI is itsability to provide valid $p$-values to features selected in TL-HDR, therebyrigorously controlling the false positive rate (FPR) at desired significancelevel $\alpha$ (e.g., 0.05). Furthermore, we enhance statistical power byincorporating a strategic divide-and-conquer approach into our framework. Wedemonstrate the validity and effectiveness of the proposed PTL-SI throughextensive experiments on both synthetic and real-world high-dimensionaldatasets, confirming its theoretical properties and utility in testing thereliability of feature selection in TL scenarios.</description>
      <author>example@mail.com (Nguyen Vu Khai Tam, Cao Huyen My, Vo Nguyen Le Duy)</author>
      <guid isPermaLink="false">2504.18212v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>ActionArt: Advancing Multimodal Large Models for Fine-Grained Human-Centric Video Understanding</title>
      <link>http://arxiv.org/abs/2504.18152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为ActionArt的细粒度视频描述数据集，旨在推进以人为本的多模态理解研究。&lt;h4&gt;背景&lt;/h4&gt;细粒度理解视频中的人类动作和姿态对于以人为本的AI应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出ActionArt数据集，以提升现有大型多模态模型在细粒度理解方面的能力。&lt;h4&gt;方法&lt;/h4&gt;数据集包含数千个视频，涵盖广泛的动作、人-物交互和场景，每个视频都有详细的标注，精确地标记了每个肢体的运动。开发了八个子任务来评估模型在不同维度上的细粒度理解能力。提出使用代理任务来增强模型在空间和时间维度上的感知能力，这些代理任务由自动生成数据驱动，以减少对昂贵的手动标注的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，尽管当前大型多模态模型在各项任务上表现良好，但它们在实现细粒度理解方面往往不足。这种限制归因于精心标注数据的稀缺性，这些数据既昂贵又难以手动扩展。&lt;h4&gt;结论&lt;/h4&gt;提出的代理任务显著缩小了与手动标注细粒度数据所达到的性能差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-grained understanding of human actions and poses in videos is essentialfor human-centric AI applications. In this work, we introduce ActionArt, afine-grained video-caption dataset designed to advance research inhuman-centric multimodal understanding. Our dataset comprises thousands ofvideos capturing a broad spectrum of human actions, human-object interactions,and diverse scenarios, each accompanied by detailed annotations thatmeticulously label every limb movement. We develop eight sub-tasks to evaluatethe fine-grained understanding capabilities of existing large multimodal modelsacross different dimensions. Experimental results indicate that, while currentlarge multimodal models perform commendably on various tasks, they often fallshort in achieving fine-grained understanding. We attribute this limitation tothe scarcity of meticulously annotated data, which is both costly and difficultto scale manually. Since manual annotations are costly and hard to scale, wepropose proxy tasks to enhance the model perception ability in both spatial andtemporal dimensions. These proxy tasks are carefully crafted to be driven bydata automatically generated from existing MLLMs, thereby reducing the relianceon costly manual labels. Experimental results show that the proposed proxytasks significantly narrow the gap toward the performance achieved withmanually annotated fine-grained data.</description>
      <author>example@mail.com (Yi-Xing Peng, Qize Yang, Yu-Ming Tang, Shenghao Fu, Kun-Yu Lin, Xihan Wei, Wei-Shi Zheng)</author>
      <guid isPermaLink="false">2504.18152v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Eval3D: Interpretable and Fine-grained Evaluation for 3D Generation</title>
      <link>http://arxiv.org/abs/2504.18509v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025. Project page and codes: https://eval3d.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Eval3D，一个用于评估3D生成数据质量的细粒度、可解释工具，它能够基于多种互补标准对生成的3D资产进行忠实评估。&lt;h4&gt;背景&lt;/h4&gt;尽管3D生成领域取得了前所未有的进展，但现有系统往往无法生成高质量且在多个视角下视觉吸引、几何和语义一致的3D资产。&lt;h4&gt;目的&lt;/h4&gt;为了有效评估生成3D数据的质量，需要一种可靠的3D评估工具。&lt;h4&gt;方法&lt;/h4&gt;Eval3D通过测量不同基础模型和工具之间的不一致性来捕捉3D生成中所需的属性，如语义和几何一致性，并利用多种模型和工具作为探针来评估生成3D资产在不同方面的不一致性。&lt;h4&gt;主要发现&lt;/h4&gt;Eval3D提供了像素级的测量，能够实现精确的3D空间反馈，并与人类判断更为接近。&lt;h4&gt;结论&lt;/h4&gt;使用Eval3D对现有的3D生成模型进行了全面评估，并突出了当前模型的局限性和挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管在3D生成领域取得了前所未有的进步，但现有系统仍然常常无法生成高质量的3D资产，这些资产在视觉上吸引人，并且在多个视角下在几何和语义上保持一致。为了有效评估生成的3D数据的质量，需要一种可靠的3D评估工具。不幸的是，现有的3D评估指标往往忽略了生成资产的几何质量，或者仅仅依赖于黑盒多模态大型语言模型进行粗略评估。在本文中，我们介绍了Eval3D，这是一个细粒度、可解释的评估工具，可以根据各种不同但互补的标准忠实评估生成的3D资产的质量。我们的关键观察是，3D生成中许多期望的属性，如语义和几何一致性，可以通过测量各种基础模型和工具之间的一致性来有效地捕获。因此，我们利用多种模型和工具作为探针来评估生成的3D资产在不同方面的不一致性。与先前的工作相比，Eval3D提供了像素级的测量，实现了精确的3D空间反馈，并且与人类判断更为接近。我们使用Eval3D对现有的3D生成模型进行了全面评估，并突出了当前模型的局限性和挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the unprecedented progress in the field of 3D generation, currentsystems still often fail to produce high-quality 3D assets that are visuallyappealing and geometrically and semantically consistent across multipleviewpoints. To effectively assess the quality of the generated 3D data, thereis a need for a reliable 3D evaluation tool. Unfortunately, existing 3Devaluation metrics often overlook the geometric quality of generated assets ormerely rely on black-box multimodal large language models for coarseassessment. In this paper, we introduce Eval3D, a fine-grained, interpretableevaluation tool that can faithfully evaluate the quality of generated 3D assetsbased on various distinct yet complementary criteria. Our key observation isthat many desired properties of 3D generation, such as semantic and geometricconsistency, can be effectively captured by measuring the consistency amongvarious foundation models and tools. We thus leverage a diverse set of modelsand tools as probes to evaluate the inconsistency of generated 3D assets acrossdifferent aspects. Compared to prior work, Eval3D provides pixel-wisemeasurement, enables accurate 3D spatial feedback, and aligns more closely withhuman judgments. We comprehensively evaluate existing 3D generation modelsusing Eval3D and highlight the limitations and challenges of current models.</description>
      <author>example@mail.com (Shivam Duggal, Yushi Hu, Oscar Michel, Aniruddha Kembhavi, William T. Freeman, Noah A. Smith, Ranjay Krishna, Antonio Torralba, Ali Farhadi, Wei-Chiu Ma)</author>
      <guid isPermaLink="false">2504.18509v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation</title>
      <link>http://arxiv.org/abs/2504.17365v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为TimeSoccer的端到端足球多模态大型语言模型，用于对完整足球比赛视频进行密集视频字幕生成（SDVC）。该模型通过联合预测时间戳和生成字幕，以及引入MoFA-Select模块来增强对长视频内容的理解，实现了高质量字幕的生成。&lt;h4&gt;背景&lt;/h4&gt;足球是一项全球流行的体育赛事，其评论生成需要精确的时间定位和丰富的语义描述。现有的足球多模态大型语言模型通常依赖于时间先验知识，无法端到端处理足球视频。&lt;h4&gt;目的&lt;/h4&gt;解决现有足球多模态大型语言模型在时间定位和语义描述方面的不足，实现端到端的足球视频字幕生成。&lt;h4&gt;方法&lt;/h4&gt;TimeSoccer模型通过联合预测时间戳和生成字幕，实现全局上下文建模。同时，引入MoFA-Select模块，通过粗到细的策略自适应选择代表性帧，并采用补充训练范式来增强模型处理长时间序列的能力。&lt;h4&gt;主要发现&lt;/h4&gt;TimeSoccer在SDVC任务上实现了最先进的性能，生成了具有准确时间对齐和强语义相关性的高质量字幕。&lt;h4&gt;结论&lt;/h4&gt;TimeSoccer是一种有效的足球视频字幕生成工具，能够提高足球比赛的评论质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soccer is a globally popular sporting event, typically characterized by longmatches and distinctive highlight moments. Recent advances in Multimodal LargeLanguage Models (MLLMs) offer promising capabilities in temporal grounding andvideo understanding, soccer commentary generation often requires precisetemporal localization and semantically rich descriptions over long-form video.However, existing soccer MLLMs often rely on the temporal a priori for captiongeneration, so they cannot process the soccer video end-to-end. While sometraditional approaches follow a two-step paradigm that is complex and fails tocapture the global context to achieve suboptimal performance. To solve theabove issues, we present TimeSoccer, the first end-to-end soccer MLLM forSingle-anchor Dense Video Captioning (SDVC) in full-match soccer videos.TimeSoccer jointly predicts timestamps and generates captions in a single pass,enabling global context modeling across 45-minute matches. To support longvideo understanding of soccer matches, we introduce MoFA-Select, atraining-free, motion-aware frame compression module that adaptively selectsrepresentative frames via a coarse-to-fine strategy, and incorporatescomplementary training paradigms to strengthen the model's ability to handlelong temporal sequences. Extensive experiments demonstrate that our TimeSoccerachieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-endform, generating high-quality commentary with accurate temporal alignment andstrong semantic relevance.</description>
      <author>example@mail.com (Ling You, Wenxuan Huang, Xinni Xie, Xiangyi Wei, Bangyan Li, Shaohui Lin, Yang Li, Changbo Wang)</author>
      <guid isPermaLink="false">2504.17365v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology</title>
      <link>http://arxiv.org/abs/2504.18256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025, EarthVision workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于自监督学习的生态遥感数据集SSL4Eco，用于解决全球生态研究中的数据稀缺和季节性问题。&lt;h4&gt;背景&lt;/h4&gt;生物多样性和气候变化加剧，全球生物多样性映射等宏观生态研究变得紧迫。遥感提供了丰富的地球观测数据，但标注数据集的稀缺是主要挑战。&lt;h4&gt;目的&lt;/h4&gt;为了更好地捕捉全球植被的季节性，提出了一种简单的基于物候的采样策略，并引入了SSL4Eco数据集。&lt;h4&gt;方法&lt;/h4&gt;使用多日期Sentinel-2数据集，通过季节对比目标训练现有模型，并在不同生态下游任务中比较从SSL4Eco学习到的表示。&lt;h4&gt;主要发现&lt;/h4&gt;简单采样方法能持续提高表示质量，强调数据集构建的重要性。在8个下游任务中，SSL4Eco预训练模型在7个任务上达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;SSL4Eco数据集有助于提升生态研究中的模型性能，并支持宏观生态和计算机视觉研究。&lt;h4&gt;翻译&lt;/h4&gt;With the exacerbation of the biodiversity and climate crises, macroecological pursuits such as global biodiversity mapping become more urgent. Remote sensing offers a wealth of Earth observation data for ecological studies, but the scarcity of labeled datasets remains a major challenge. Recently, self-supervised learning has enabled learning representations from unlabeled data, triggering the development of pretrained geospatial models with generalizable features. However, these models are often trained on datasets biased toward areas of high human activity, leaving entire ecological regions underrepresented. Additionally, while some datasets attempt to address seasonality through multi-date imagery, they typically follow calendar seasons rather than local phenological cycles. To better capture vegetation seasonality at a global scale, we propose a simple phenology-informed sampling strategy and introduce corresponding SSL4Eco, a multi-date Sentinel-2 dataset, on which we train an existing model with a season-contrastive objective. We compare representations learned from SSL4Eco against other datasets on diverse ecological downstream tasks and demonstrate that our straightforward sampling method consistently improves representation quality, highlighting the importance of dataset construction. The model pretrained on SSL4Eco reaches state of the art performance on 7 out of 8 downstream tasks spanning (multi-label) classification and regression. We release our code, data, and model weights to support macroecological and computer vision research at https://github.com/PlekhanovaElena/ssl4eco.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the exacerbation of the biodiversity and climate crises, macroecologicalpursuits such as global biodiversity mapping become more urgent. Remote sensingoffers a wealth of Earth observation data for ecological studies, but thescarcity of labeled datasets remains a major challenge. Recently,self-supervised learning has enabled learning representations from unlabeleddata, triggering the development of pretrained geospatial models withgeneralizable features. However, these models are often trained on datasetsbiased toward areas of high human activity, leaving entire ecological regionsunderrepresented. Additionally, while some datasets attempt to addressseasonality through multi-date imagery, they typically follow calendar seasonsrather than local phenological cycles. To better capture vegetation seasonalityat a global scale, we propose a simple phenology-informed sampling strategy andintroduce corresponding SSL4Eco, a multi-date Sentinel-2 dataset, on which wetrain an existing model with a season-contrastive objective. We comparerepresentations learned from SSL4Eco against other datasets on diverseecological downstream tasks and demonstrate that our straightforward samplingmethod consistently improves representation quality, highlighting theimportance of dataset construction. The model pretrained on SSL4Eco reachesstate of the art performance on 7 out of 8 downstream tasks spanning(multi-label) classification and regression. We release our code, data, andmodel weights to support macroecological and computer vision research athttps://github.com/PlekhanovaElena/ssl4eco.</description>
      <author>example@mail.com (Elena Plekhanova, Damien Robert, Johannes Dollinger, Emilia Arens, Philipp Brun, Jan Dirk Wegner, Niklaus Zimmermann)</author>
      <guid isPermaLink="false">2504.18256v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Kimi-Audio Technical Report</title>
      <link>http://arxiv.org/abs/2504.18425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Kimi-Audio，这是一个在音频理解、生成和对话方面表现卓越的开源音频基础模型。&lt;h4&gt;背景&lt;/h4&gt;Kimi-Audio是一个音频理解、生成和对话的模型。&lt;h4&gt;目的&lt;/h4&gt;详细描述了构建Kimi-Audio的过程，包括模型架构、数据整理、训练方案、推理部署和评估。&lt;h4&gt;方法&lt;/h4&gt;使用了12.5Hz音频标记器，设计了一种基于LLM的新型架构，以连续特征作为输入，以离散标记作为输出，并开发了基于流匹配的块级流解标记器。整理了一个包含超过1300万小时音频数据的预训练数据集，包括语音、声音和音乐等多种模态，并建立了一个管道来构建高质量的训练数据。&lt;h4&gt;主要发现&lt;/h4&gt;Kimi-Audio在语音识别、音频理解、音频问答和语音对话等多个音频基准测试中达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;发布了代码、模型检查点和评估工具包。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为Kimi-Audio的开源音频基础模型，它在音频理解、生成和对话方面表现出色。我们详细介绍了构建Kimi-Audio的实践，包括模型架构、数据整理、训练方案、推理部署和评估。我们利用12.5Hz音频标记器，设计了一种基于LLM的新型架构，以连续特征作为输入，以离散标记作为输出，并开发了一种基于流匹配的块级流解标记器。我们整理了一个包含超过1300万小时音频数据的预训练数据集，包括语音、声音和音乐等多种模态，并建立了一个管道来构建高质量的训练数据。Kimi-Audio从预训练的LLM开始，在音频和文本数据上进行了连续预训练，并进行了精心设计的任务，然后进行了微调以支持各种音频相关任务。广泛的评估表明，Kimi-Audio在语音识别、音频理解、音频问答和语音对话等多个音频基准测试中达到了最先进的性能。我们在https://github.com/MoonshotAI/Kimi-Audio上发布了代码、模型检查点和评估工具包。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Kimi-Audio, an open-source audio foundation model that excels inaudio understanding, generation, and conversation. We detail the practices inbuilding Kimi-Audio, including model architecture, data curation, trainingrecipe, inference deployment, and evaluation. Specifically, we leverage a12.5Hz audio tokenizer, design a novel LLM-based architecture with continuousfeatures as input and discrete tokens as output, and develop a chunk-wisestreaming detokenizer based on flow matching. We curate a pre-training datasetthat consists of more than 13 million hours of audio data covering a wide rangeof modalities including speech, sound, and music, and build a pipeline toconstruct high-quality and diverse post-training data. Initialized from apre-trained LLM, Kimi-Audio is continual pre-trained on both audio and textdata with several carefully designed tasks, and then fine-tuned to support adiverse of audio-related tasks. Extensive evaluation shows that Kimi-Audioachieves state-of-the-art performance on a range of audio benchmarks includingspeech recognition, audio understanding, audio question answering, and speechconversation. We release the codes, model checkpoints, as well as theevaluation toolkits in https://github.com/MoonshotAI/Kimi-Audio.</description>
      <author>example@mail.com (KimiTeam, Ding Ding, Zeqian Ju, Yichong Leng, Songxiang Liu, Tong Liu, Zeyu Shang, Kai Shen, Wei Song, Xu Tan, Heyi Tang, Zhengtao Wang, Chu Wei, Yifei Xin, Xinran Xu, Jianwei Yu, Yutao Zhang, Xinyu Zhou, Y. Charles, Jun Chen, Yanru Chen, Yulun Du, Weiran He, Zhenxing Hu, Guokun Lai, Qingcheng Li, Yangyang Liu, Weidong Sun, Jianzhou Wang, Yuzhi Wang, Yuefeng Wu, Yuxin Wu, Dongchao Yang, Hao Yang, Ying Yang, Zhilin Yang, Aoxiong Yin, Ruibin Yuan, Yutong Zhang, Zaida Zhou)</author>
      <guid isPermaLink="false">2504.18425v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>A Model Zoo on Phase Transitions in Neural Networks</title>
      <link>http://arxiv.org/abs/2504.18072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了利用训练好的神经网络模型权重作为数据模态的研究领域——称为权重空间学习（WSL）。作者提出了一个新的方法，结合了模型动物园和相信息，以创造一个受控的多样性概念。他们创建了12个大型动物园，系统性地覆盖了已知的相和模型架构、大小和数据集，为WSL和更多应用提供了资源。&lt;h4&gt;背景&lt;/h4&gt;权重空间学习（WSL）是利用训练好的神经网络模型权重作为数据模态的研究领域，但现有的模型动物园结构不清晰，缺乏多样性。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合模型动物园和相信息的方法，以创造一个受控的多样性概念，并为权重空间学习（WSL）和其他应用提供资源。&lt;h4&gt;方法&lt;/h4&gt;创建了12个大型动物园，系统性地覆盖了已知的相和模型架构、大小和数据集。为每个模型计算损失景观指标，并验证相的全覆盖。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一个结合模型动物园和相信息的新方法，并创建了覆盖不同领域的动物园，如计算机视觉、自然语言处理和科学机器学习。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了广泛的资源，可能对模型训练、分析或稀疏化等应用中的损失景观相具有重要作用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用训练好的神经网络（NN）模型权重作为数据模态的研究领域——称为权重空间学习（WSL），最近已经成为一个研究领域。许多最近的研究提出了WSL方法来分析模型、评估方法或合成权重。权重空间学习方法需要训练好的模型群体作为开发和分析的数据集。然而，现有的模型集合——称为“模型动物园”——结构不清晰或遵循原始的多样性定义。与此同时，基于统计物理的研究已经确定了神经网络模型中的相和相变。在同一相中的模型是同质的，但彼此不同相的模型在质量上有所不同。我们将“模型动物园”的概念与相信息相结合，以创造一个受控的多样性概念。我们引入了12个大型动物园，系统地覆盖了已知的相以及模型架构、大小和数据集。这些数据集涵盖了不同的模态，如计算机视觉、自然语言处理和科学机器学习。对于每个模型，我们计算损失景观指标，并验证相的全覆盖。利用这个数据集，我们为社区提供了一个具有广泛潜在应用的资源，包括WSL以外的应用。证据表明，损失景观相在模型训练、分析或稀疏化等应用中起着作用。我们在下游方法（如迁移学习或模型权重平均）的探索性研究中证明了这一点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Using the weights of trained Neural Network (NN) models as data modality hasrecently gained traction as a research field - dubbed Weight Space Learning(WSL). Multiple recent works propose WSL methods to analyze models, evaluatemethods, or synthesize weights. Weight space learning methods requirepopulations of trained models as datasets for development and evaluation.However, existing collections of models - called `model zoos' - areunstructured or follow a rudimentary definition of diversity. In parallel, workrooted in statistical physics has identified phases and phase transitions in NNmodels. Models are homogeneous within the same phase but qualitatively differfrom one phase to another. We combine the idea of `model zoos' with phaseinformation to create a controlled notion of diversity in populations. Weintroduce 12 large-scale zoos that systematically cover known phases and varyover model architecture, size, and datasets. These datasets cover differentmodalities, such as computer vision, natural language processing, andscientific ML. For every model, we compute loss landscape metrics and validatefull coverage of the phases. With this dataset, we provide the community with aresource with a wide range of potential applications for WSL and beyond.Evidence suggests the loss landscape phase plays a role in applications such asmodel training, analysis, or sparsification. We demonstrate this in anexploratory study of the downstream methods like transfer learning or modelweights averaging.</description>
      <author>example@mail.com (Konstantin Schürholt, Léo Meynent, Yefan Zhou, Haiquan Lu, Yaoqing Yang, Damian Borth)</author>
      <guid isPermaLink="false">2504.18072v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Label-independent hyperparameter-free self-supervised single-view deep subspace clustering</title>
      <link>http://arxiv.org/abs/2504.18179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages; 1 figure; 10 Tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对深度子空间聚类（DSC）算法的局限性，提出了一种新的单视图DSC方法。&lt;h4&gt;背景&lt;/h4&gt;DSC算法在实际应用中存在几个挑战，包括只使用编码器的输出层评估聚类质量、将表示学习和子空间聚类视为独立任务、假设存在用于超参数调整的保留数据集、训练终止基于聚类错误监控需要外部标签以及性能依赖于依赖标签数据的后处理技术。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的DSC方法，以解决上述局限性。&lt;h4&gt;方法&lt;/h4&gt;该方法包括：(i) 使用联合表示矩阵最小化分层自我表达损失；(ii) 优化子空间结构范数以增强聚类质量；(iii) 采用多阶段顺序学习框架，包括预训练和微调，允许使用多个正则化项而不需要超参数调整；(iv) 采用基于相对误差的自我停止机制，无需标签即可终止训练；(v) 根据先验知识保留学习表示矩阵中的前导系数。&lt;h4&gt;主要发现&lt;/h4&gt;在六个代表人脸、数字和物体的数据集上评估了该方法，结果表明该方法在性能上优于大多数线性SC算法，同时与最佳线性方法保持竞争力。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效解决DSC算法的局限性，并在实际应用中取得良好的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep subspace clustering (DSC) algorithms face several challenges that hindertheir widespread adoption across variois application domains. First, clusteringquality is typically assessed using only the encoder's output layer,disregarding valuable information present in the intermediate layers. Second,most DSC approaches treat representation learning and subspace clustering asindependent tasks, limiting their effectiveness. Third, they assume theavailability of a held-out dataset for hyperparameter tuning, which is oftenimpractical in real-world scenarios. Fourth, learning termination is commonlybased on clustering error monitoring, requiring external labels. Finally, theirperformance often depends on post-processing techniques that rely on labeleddata. To address this limitations, we introduce a novel single-view DSCapproach that: (i) minimizes a layer-wise self expression loss using a jointrepresentation matrix; (ii) optimizes a subspace-structured norm to enhanceclustering quality; (iii) employs a multi-stage sequential learning framework,consisting of pre-training and fine-tuning, enabling the use of multipleregularization terms without hyperparameter tuning; (iv) incorporates arelative error-based self-stopping mechanism to terminate training withoutlabels; and (v) retains a fixed number of leading coefficients in the learnedrepresentation matrix based on prior knowledge. We evaluate the proposed methodon six datasets representing faces, digits, and objects. The results show thatour method outperforms most linear SC algorithms with careffulyl tunedhyperparameters while maintaining competitive performance with the bestperforming linear appoaches.</description>
      <author>example@mail.com (Lovro Sindicic, Ivica Kopriva)</author>
      <guid isPermaLink="false">2504.18179v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>ShapeSpeak: Body Shape-Aware Textual Alignment for Visible-Infrared Person Re-Identification</title>
      <link>http://arxiv.org/abs/2504.18025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种Body Shape-aware Textual Alignment (BSaTa)框架，通过利用身体形状信息来提高VIReID的性能。&lt;h4&gt;背景&lt;/h4&gt;可见光和红外行人图像的匹配是一个挑战，因为模态差异和身份特征的复杂性。现有方法依赖于身份标签监督，难以提取高级语义信息。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法未显式建模身体形状特征的问题，提高跨模态匹配能力。&lt;h4&gt;方法&lt;/h4&gt;设计了一个Body Shape Textual Alignment (BSTA)模块，使用人体解析模型提取身体形状信息，并通过CLIP将其转换为结构化文本表示。还设计了一个Text-Visual Consistency Regularizer (TVCR)来确保身体形状文本表示与视觉身体形状特征的对齐。此外，引入了一个Shape-aware Representation Learning (SRL)机制，结合多文本监督和分布一致性约束来指导视觉编码器学习模态不变和判别性身份特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在SYSU-MM01和RegDB数据集上实现了优越的性能。&lt;h4&gt;结论&lt;/h4&gt;验证了BSaTa框架在VIReID中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Visible-Infrared Person Re-identification (VIReID) aims to match visible and infrared pedestrian images, but the modality differences and the complexity of identity features make it challenging. Existing methods rely solely on identity label supervision, which makes it difficult to fully extract high-level semantic information. Recently, vision-language pre-trained models have been introduced to VIReID, enhancing semantic information modeling by generating textual descriptions. However, such methods do not explicitly model body shape features, which are crucial for cross-modal matching. To address this, we propose an effective Body Shape-aware Textual Alignment (BSaTa) framework that explicitly models and utilizes body shape information to improve VIReID performance. Specifically, we design a Body Shape Textual Alignment (BSTA) module that extracts body shape information using a human parsing model and converts it into structured text representations via CLIP. We also design a Text-Visual Consistency Regularizer (TVCR) to ensure alignment between body shape textual representations and visual body shape features. Furthermore, we introduce a Shape-aware Representation Learning (SRL) mechanism that combines Multi-text Supervision and Distribution Consistency Constraints to guide the visual encoder to learn modality-invariant and discriminative identity features, thus enhancing modality invariance. Experimental results demonstrate that our method achieves superior performance on the SYSU-MM01 and RegDB datasets, validating its effectiveness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visible-Infrared Person Re-identification (VIReID) aims to match visible andinfrared pedestrian images, but the modality differences and the complexity ofidentity features make it challenging. Existing methods rely solely on identitylabel supervision, which makes it difficult to fully extract high-levelsemantic information. Recently, vision-language pre-trained models have beenintroduced to VIReID, enhancing semantic information modeling by generatingtextual descriptions. However, such methods do not explicitly model body shapefeatures, which are crucial for cross-modal matching. To address this, wepropose an effective Body Shape-aware Textual Alignment (BSaTa) framework thatexplicitly models and utilizes body shape information to improve VIReIDperformance. Specifically, we design a Body Shape Textual Alignment (BSTA)module that extracts body shape information using a human parsing model andconverts it into structured text representations via CLIP. We also design aText-Visual Consistency Regularizer (TVCR) to ensure alignment between bodyshape textual representations and visual body shape features. Furthermore, weintroduce a Shape-aware Representation Learning (SRL) mechanism that combinesMulti-text Supervision and Distribution Consistency Constraints to guide thevisual encoder to learn modality-invariant and discriminative identityfeatures, thus enhancing modality invariance. Experimental results demonstratethat our method achieves superior performance on the SYSU-MM01 and RegDBdatasets, validating its effectiveness.</description>
      <author>example@mail.com (Shuanglin Yan, Neng Dong, Shuang Li, Rui Yan, Hao Tang, Jing Qin)</author>
      <guid isPermaLink="false">2504.18025v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>VEU-Bench: Towards Comprehensive Understanding of Video Editing</title>
      <link>http://arxiv.org/abs/2504.17828v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VEU-Bench，一个用于视频编辑理解的综合基准，并提出了Oscars模型以提升Vid-LLMs在视频编辑理解任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;互联网上广泛共享的视频通常经过编辑，尽管Vid-LLMs在视频理解任务上取得了显著进展，但它们在视频编辑理解（VEU）任务上的能力尚未得到探索。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文旨在提出一个综合基准和模型，以提升Vid-LLMs在VEU任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;VEU-Bench将视频编辑组件按照帧内特征和帧间属性进行分类，并包含19个细粒度任务，分为识别、推理和判断三个阶段。为了自动增强VEU的标注，构建了一个与本体知识库集成的标注流程。通过使用11个最先进的Vid-LLMs进行实验，并开发了一个名为Oscars的VEU专家模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，当前的Vid-LLMs在VEU任务上面临重大挑战，某些模型的表现甚至不如随机选择。Oscars模型在VEU-Bench上的准确率比现有开源Vid-LLMs高出28.3%，且性能与商业模型如GPT-4o相当。VEU数据的引入显著提高了Vid-LLMs在一般视频理解基准上的性能，平均提升了8.3%。&lt;h4&gt;结论&lt;/h4&gt;VEU-Bench为VEU任务提供了一个全面的基准，Oscars模型有效地提升了Vid-LLMs在VEU任务上的性能，并为Vid-LLMs在视频理解任务上的应用提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：互联网上广泛共享的视频通常经过编辑。尽管Video Large Language Models (Vid-LLMs) 在一般视频理解任务上取得了巨大进步，但它们在视频编辑理解（VEU）任务上的能力仍然未被探索。为了解决这一差距，本文提出了VEU-Bench（视频编辑理解基准），这是一个全面基准，它从帧大小等帧内特征到剪辑类型和过渡等帧间属性等多个维度对视频编辑组件进行了分类。与主要关注编辑元素分类的先前视频编辑理解基准不同，VEU-Bench涵盖了三个阶段的19个细粒度任务：识别、推理和判断。为了自动增强VEU的标注，我们构建了一个与本体知识库集成的标注流程。通过使用11个最先进的Vid-LLMs进行的大量实验，我们发现当前的Vid-LLMs在VEU任务上面临重大挑战，一些模型的表现甚至不如随机选择。为了解决这个问题，我们开发了一个名为Oscars的VEU专家模型，它在VEU-Bench上的准确率比现有的开源Vid-LLMs高出28.3%，并且其性能与GPT-4o等商业模型相当。我们还证明，引入VEU数据显著提高了Vid-LLMs在一般视频理解基准上的性能，平均提高了8.3%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Widely shared videos on the internet are often edited. Recently, althoughVideo Large Language Models (Vid-LLMs) have made great progress in generalvideo understanding tasks, their capabilities in video editing understanding(VEU) tasks remain unexplored. To address this gap, in this paper, we introduceVEU-Bench (Video Editing Understanding Benchmark), a comprehensive benchmarkthat categorizes video editing components across various dimensions, fromintra-frame features like shot size to inter-shot attributes such as cut typesand transitions. Unlike previous video editing understanding benchmarks thatfocus mainly on editing element classification, VEU-Bench encompasses 19fine-grained tasks across three stages: recognition, reasoning, and judging. Toenhance the annotation of VEU automatically, we built an annotation pipelineintegrated with an ontology-based knowledge base. Through extensive experimentswith 11 state-of-the-art Vid-LLMs, our findings reveal that current Vid-LLMsface significant challenges in VEU tasks, with some performing worse thanrandom choice. To alleviate this issue, we develop Oscars, a VEU expert modelfine-tuned on the curated VEU-Bench dataset. It outperforms existingopen-source Vid-LLMs on VEU-Bench by over 28.3% in accuracy and achievesperformance comparable to commercial models like GPT-4o. We also demonstratethat incorporating VEU data significantly enhances the performance of Vid-LLMson general video understanding benchmarks, with an average improvement of 8.3%across nine reasoning tasks.</description>
      <author>example@mail.com (Bozheng Li, Yongliang Wu, Yi Lu, Jiashuo Yu, Licheng Tang, Jiawang Cao, Wenqing Zhu, Yuyang Sun, Jay Wu, Wenbo Zhu)</author>
      <guid isPermaLink="false">2504.17828v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>What is the Added Value of UDA in the VFM Era?</title>
      <link>http://arxiv.org/abs/2504.18190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了无监督领域自适应（UDA）在视觉基础模型（VFMs）中的应用，分析了其在不同数据场景下的表现，并讨论了UDA如何支持大规模的稳健自动驾驶。&lt;h4&gt;背景&lt;/h4&gt;UDA可以从标记的源域改进感知模型的泛化能力到未标记的目标域。使用合成源数据的VFMs可以达到与使用真实目标数据的全监督学习相当的泛化性能。&lt;h4&gt;目的&lt;/h4&gt;研究UDA在更具代表性和多样性数据下的行为，以及仅使用源数据进行微调的VFMs在这些场景下的表现是否相同。&lt;h4&gt;方法&lt;/h4&gt;该研究关注语义分割作为代表性的感知任务，评估了UDA在合成到真实和真实到真实用例中的表现，并调查了在使用少量标记目标数据时UDA的效果。&lt;h4&gt;主要发现&lt;/h4&gt;使用更强的合成源数据时，UDA相对于仅源微调的VFMs的改进从+8 mIoU减少到+2 mIoU；使用更多样化的真实源数据时，UDA没有额外的价值；所有合成数据场景下的UDA泛化始终高于仅源微调；当只包含Cityscapes标签的1/16时，合成UDA获得与使用所有标签的全监督模型相同的85 mIoU分割质量。&lt;h4&gt;结论&lt;/h4&gt;UDA在某些情况下可以减少对大量标记数据的依赖，但并非总是提供额外的价值，且在更具现实性的场景下可能并不更具挑战性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised Domain Adaptation (UDA) can improve a perception model'sgeneralization to an unlabeled target domain starting from a labeled sourcedomain. UDA using Vision Foundation Models (VFMs) with synthetic source datacan achieve generalization performance comparable to fully-supervised learningwith real target data. However, because VFMs have strong generalization fromtheir pre-training, more straightforward, source-only fine-tuning can alsoperform well on the target. As data scenarios used in academic research are notnecessarily representative for real-world applications, it is currently unclear(a) how UDA behaves with more representative and diverse data and (b) ifsource-only fine-tuning of VFMs can perform equally well in these scenarios.Our research aims to close these gaps and, similar to previous studies, wefocus on semantic segmentation as a representative perception task. We assessUDA for synth-to-real and real-to-real use cases with different source andtarget data combinations. We also investigate the effect of using a smallamount of labeled target data in UDA. We clarify that while these scenarios aremore realistic, they are not necessarily more challenging. Our results showthat, when using stronger synthetic source data, UDA's improvement oversource-only fine-tuning of VFMs reduces from +8 mIoU to +2 mIoU, and when usingmore diverse real source data, UDA has no added value. However, UDAgeneralization is always higher in all synthetic data scenarios thansource-only fine-tuning and, when including only 1/16 of Cityscapes labels,synthetic UDA obtains the same state-of-the-art segmentation quality of 85 mIoUas a fully-supervised model using all labels. Considering the mixed results, wediscuss how UDA can best support robust autonomous driving at scale.</description>
      <author>example@mail.com (Brunó B. Englert, Tommie Kerssies, Gijs Dubbelman)</author>
      <guid isPermaLink="false">2504.18190v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>FlexPINN: Modeling Fluid Dynamics and Mass Transfer in 3D Micromixer Geometries Using a Flexible Physics-Informed Neural Network</title>
      <link>http://arxiv.org/abs/2504.17896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究利用改进的物理信息神经网络（FlexPINN）研究了具有不同鳍形状和配置的3D T形微混器内的流体流动和浓度分布，分析了鳍几何形状和放置位置的影响。&lt;h4&gt;背景&lt;/h4&gt;研究使用了FlexPINN，这是对传统PINN架构的改进，以解决使用标准PINN模拟3D问题的挑战。&lt;h4&gt;目的&lt;/h4&gt;评估压力降系数、混合指数和混合效率，以FlexPINN方法为基础。&lt;h4&gt;方法&lt;/h4&gt;考虑了三种鳍形状（矩形、椭圆形和三角形）和四种鳍配置，在单单元（四个鳍）和双单元（八个鳍）配置下，以不同的雷诺数（5、20、40、80）进行模拟。&lt;h4&gt;主要发现&lt;/h4&gt;FlexPINN方法在预测压力降系数和混合指数时，与CFD结果相比，误差分别最大为3.25%和2.86%。在所有测试案例中，矩形鳍在双单元配置下的配置C在雷诺数40时显示出最高的混合效率，达到1.63。&lt;h4&gt;结论&lt;/h4&gt;FlexPINN框架在模拟复杂3D几何形状中的流体流动和物质传输方面表现出强大的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, fluid flow and concentration distribution inside a 3D T-shapedmicromixer with various fin shapes and configurations are investigated using aFlexible Physics-Informed Neural Network (FlexPINN), which includesmodifications over the vanilla PINN architecture. Three types of fins(rectangular, elliptical, and triangular) are considered to evaluate theinfluence of fin geometry, along with four different fin configurations insidethe 3D channel to examine the effect of placement. The simulations areconducted at four Reynolds numbers: 5, 20, 40, and 80, in both single-unit(four fins) and double-unit (eight fins) configurations. The goal is to assesspressure drop coefficient, mixing index, and mixing efficiency using theFlexPINN method. Given the challenges in simulating 3D problems with standardPINN, several improvements are introduced. The governing equations are injectedinto the network as first-order, dimensionless derivatives to enhance accuracy.Transfer learning is used to reduce computational cost, and adaptive lossweighting is applied to improve convergence compared to the vanilla PINNapproach. These modifications enable a consistent and flexible architecturethat can be used across numerous tested cases. Using the proposed FlexPINNmethod, the pressure drop coefficient and mixing index are predicted withmaximum errors of 3.25% and 2.86%, respectively, compared to ComputationalFluid Dynamics (CFD) results. Among all the tested cases, the rectangular finwith configuration C in the double-unit setup at Reynolds number 40 shows thehighest mixing efficiency, reaching a value of 1.63. The FlexPINN frameworkdemonstrates strong capabilities in simulating fluid flow and species transportin complex 3D geometries.</description>
      <author>example@mail.com (Meraj Hassanzadeh, Ehsan Ghaderi, Mohamad Ali Bijarchi)</author>
      <guid isPermaLink="false">2504.17896v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>L4P: Low-Level 4D Vision Perception Unified</title>
      <link>http://arxiv.org/abs/2502.13078v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为L4P的通用前馈架构，用于解决低级4D感知任务，该架构结合了预训练的ViT视频编码器和轻量级的任务头，能够在统一框架内解决多种任务，包括稠密任务（如深度或光流估计）和稀疏任务（如2D/3D跟踪）。&lt;h4&gt;背景&lt;/h4&gt;视频像素的空间时间关系对于低级4D感知任务至关重要，而大多数最先进的方法依赖于针对特定任务专门化的架构。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够解决多种低级4D感知任务的通用模型。&lt;h4&gt;方法&lt;/h4&gt;L4P架构利用预训练的ViT视频编码器，并结合轻量级的任务头，这些头轻量到不需要大量训练。&lt;h4&gt;主要发现&lt;/h4&gt;L4P在稠密和稀疏任务上均达到了或超过了现有专用方法的性能，并且能够在与单任务方法相当的时间内解决所有任务。&lt;h4&gt;结论&lt;/h4&gt;L4P是一种有效的通用架构，能够同时解决多种低级4D感知任务，且性能优越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The spatio-temporal relationship between the pixels of a video carriescritical information for low-level 4D perception tasks. A single model thatreasons about it should be able to solve several such tasks well. Yet, moststate-of-the-art methods rely on architectures specialized for the task athand. We present L4P, a feedforward, general-purpose architecture that solveslow-level 4D perception tasks in a unified framework. L4P leverages apre-trained ViT-based video encoder and combines it with per-task heads thatare lightweight and therefore do not require extensive training. Despite itsgeneral and feedforward formulation, our method matches or surpasses theperformance of existing specialized methods on both dense tasks, such as depthor optical flow estimation, and sparse tasks, such as 2D/3D tracking. Moreover,it solves all tasks at once in a time comparable to that of single-taskmethods.</description>
      <author>example@mail.com (Abhishek Badki, Hang Su, Bowen Wen, Orazio Gallo)</author>
      <guid isPermaLink="false">2502.13078v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Quadratic Interest Network for Multimodal Click-Through Rate Prediction</title>
      <link>http://arxiv.org/abs/2504.17699v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Quadratic Interest Network (QIN)的新模型，用于多模态点击率预测，该模型在多模态CTR预测挑战中取得了优异成绩。&lt;h4&gt;背景&lt;/h4&gt;多模态点击率预测是工业推荐系统中的关键技术，它通过利用文本、图像和行为日志等异构模态，捕捉用户与物品之间的高阶特征交互，从而增强系统对用户兴趣的理解和预测点击行为的能力。&lt;h4&gt;目的&lt;/h4&gt;为了促进这一领域的发展，WWW 2025 EReL@MIR Workshop的Multimodal CTR Prediction Challenge Track提出了两个任务：多模态物品嵌入和多模态CTR预测。&lt;h4&gt;方法&lt;/h4&gt;本文提出的QIN模型使用自适应稀疏目标注意力机制提取多模态用户行为特征，并利用二次神经网络捕获高阶特征交互。&lt;h4&gt;主要发现&lt;/h4&gt;QIN在挑战赛中的排行榜上取得了AUC 0.9798的成绩，排名第二。&lt;h4&gt;结论&lt;/h4&gt;QIN模型能够有效地利用多模态嵌入特征，实现更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal click-through rate (CTR) prediction is a key technique in industrial recommender systems. It leverages heterogeneous modalities such as text, images, and behavioral logs to capture high-order feature interactions between users and items, thereby enhancing the system's understanding of user interests and its ability to predict click behavior. The primary challenge in this field lies in effectively utilizing the rich semantic information from multiple modalities while satisfying the low-latency requirements of online inference in real-world applications. To foster progress in this area, the Multimodal CTR Prediction Challenge Track of the WWW 2025 EReL@MIR Workshop formulates the problem into two tasks: (1) Task 1 of Multimodal Item Embedding: this task aims to explore multimodal information extraction and item representation learning methods that enhance recommendation tasks; and (2) Task 2 of Multimodal CTR Prediction: this task aims to explore what multimodal recommendation model can effectively leverage multimodal embedding features and achieve better performance. In this paper, we propose a novel model for Task 2, named Quadratic Interest Network (QIN) for Multimodal CTR Prediction. Specifically, QIN employs adaptive sparse target attention to extract multimodal user behavior features, and leverages Quadratic Neural Networks to capture high-order feature interactions. As a result, QIN achieved an AUC of 0.9798 on the leaderboard and ranked second in the competition. The model code, training logs, hyperparameter configurations, and checkpoints are available at https://github.com/salmon1802/QIN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal click-through rate (CTR) prediction is a key technique inindustrial recommender systems. It leverages heterogeneous modalities such astext, images, and behavioral logs to capture high-order feature interactionsbetween users and items, thereby enhancing the system's understanding of userinterests and its ability to predict click behavior. The primary challenge inthis field lies in effectively utilizing the rich semantic information frommultiple modalities while satisfying the low-latency requirements of onlineinference in real-world applications. To foster progress in this area, theMultimodal CTR Prediction Challenge Track of the WWW 2025 EReL@MIR Workshopformulates the problem into two tasks: (1) Task 1 of Multimodal Item Embedding:this task aims to explore multimodal information extraction and itemrepresentation learning methods that enhance recommendation tasks; and (2) Task2 of Multimodal CTR Prediction: this task aims to explore what multimodalrecommendation model can effectively leverage multimodal embedding features andachieve better performance. In this paper, we propose a novel model for Task 2,named Quadratic Interest Network (QIN) for Multimodal CTR Prediction.Specifically, QIN employs adaptive sparse target attention to extractmultimodal user behavior features, and leverages Quadratic Neural Networks tocapture high-order feature interactions. As a result, QIN achieved an AUC of0.9798 on the leaderboard and ranked second in the competition. The model code,training logs, hyperparameter configurations, and checkpoints are available athttps://github.com/salmon1802/QIN.</description>
      <author>example@mail.com (Honghao Li, Hanwei Li, Jing Zhang, Yi Zhang, Ziniu Yu, Lei Sang, Yiwen Zhang)</author>
      <guid isPermaLink="false">2504.17699v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Opportunistic Collaborative Planning with Large Vision Model Guided Control and Joint Query-Service Optimization</title>
      <link>http://arxiv.org/abs/2504.18057v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为OCP的机会性协作规划方法，通过高效整合本地模型和云端模型，解决了自动驾驶车辆在开放场景中导航的挑战。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶车辆在开放场景中导航面临处理未知物体的困难，现有解决方案要么依赖于小模型，难以泛化，要么依赖于大模型，资源消耗大。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以解决如何决定何时以及如何使用大模型的问题。&lt;h4&gt;方法&lt;/h4&gt;1. 提出大型视觉模型引导的模型预测控制（LVM-MPC），利用云端进行LVM感知和决策，云端输出作为本地MPC的全局指导，形成一个闭环的感知到控制系统。2. 提出协作时机优化（CTO），包括目标检测置信度阈值（ODCT）和云端前向模拟（CFS），以决定何时寻求云端帮助和何时提供云端服务。&lt;h4&gt;主要发现&lt;/h4&gt;OCP在导航时间和成功率方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;OCP方法通过高效整合本地和云端模型，提高了自动驾驶车辆在开放场景中的导航性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Navigating autonomous vehicles in open scenarios is a challenge due to thedifficulties in handling unseen objects. Existing solutions either rely onsmall models that struggle with generalization or large models that areresource-intensive. While collaboration between the two offers a promisingsolution, the key challenge is deciding when and how to engage the large model.To address this issue, this paper proposes opportunistic collaborative planning(OCP), which seamlessly integrates efficient local models with powerful cloudmodels through two key innovations. First, we propose large vision model guidedmodel predictive control (LVM-MPC), which leverages the cloud for LVMperception and decision making. The cloud output serves as a global guidancefor a local MPC, thereby forming a closed-loop perception-to-control system.Second, to determine the best timing for large model query and service, wepropose collaboration timing optimization (CTO), including object detectionconfidence thresholding (ODCT) and cloud forward simulation (CFS), to decidewhen to seek cloud assistance and when to offer cloud service. Extensiveexperiments show that the proposed OCP outperforms existing methods in terms ofboth navigation time and success rate.</description>
      <author>example@mail.com (Jiayi Chen, Shuai Wang, Guoliang Li, Wei Xu, Guangxu Zhu, Derrick Wing Kwan Ng, Chengzhong Xu)</author>
      <guid isPermaLink="false">2504.18057v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>On the workflow, opportunities and challenges of developing foundation model in geophysics</title>
      <link>http://arxiv.org/abs/2504.17384v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个完整的框架，系统探讨将基础模型与地球物理数据相结合的整个流程。&lt;h4&gt;背景&lt;/h4&gt;基础模型在人工智能领域成为主流技术，近年来在处理复杂任务和多种模态数据方面展现出巨大潜力。在地球物理学领域，尽管基础模型的应用逐渐扩展，但缺乏关于其与地球物理数据集成全流程的综合性综述。&lt;h4&gt;目的&lt;/h4&gt;填补地球物理学领域在基础模型全流程综述方面的空白，并为地球物理数据分析中的应用提供有价值的实践指导。&lt;h4&gt;方法&lt;/h4&gt;从数据收集和预处理到模型架构选择、预训练策略和模型部署，详细分析了每个阶段的关键技术和方法。特别讨论了针对地球物理数据多样性、复杂性和物理一致性约束的针对性解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;通过利用基础模型的迁移学习能力，减少对标记数据的依赖，提高计算效率，并将物理约束纳入模型训练，从而提高物理一致性和可解释性。&lt;h4&gt;结论&lt;/h4&gt;本文不仅填补了地球物理学领域基础模型全流程综述的空白，还为该领域的技术创新和进步提供了宝贵的实践指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, as a mainstream technology in artificial intelligence,have demonstrated immense potential across various domains in recent years,particularly in handling complex tasks and multimodal data. In the field ofgeophysics, although the application of foundation models is graduallyexpanding, there is currently a lack of comprehensive reviews discussing thefull workflow of integrating foundation models with geophysical data. Toaddress this gap, this paper presents a complete framework that systematicallyexplores the entire process of developing foundation models in conjunction withgeophysical data. From data collection and preprocessing to model architectureselection, pre-training strategies, and model deployment, we provide a detailedanalysis of the key techniques and methodologies at each stage. In particular,considering the diversity, complexity, and physical consistency constraints ofgeophysical data, we discuss targeted solutions to address these challenges.Furthermore, we discuss how to leverage the transfer learning capabilities offoundation models to reduce reliance on labeled data, enhance computationalefficiency, and incorporate physical constraints into model training, therebyimproving physical consistency and interpretability. Through a comprehensivesummary and analysis of the current technological landscape, this paper notonly fills the gap in the geophysics domain regarding a full-process review offoundation models but also offers valuable practical guidance for theirapplication in geophysical data analysis, driving innovation and advancement inthe field.</description>
      <author>example@mail.com (Hanlin Sheng, Xinming Wu, Hang Gao, Haibin Di, Sergey Fomel, Jintao Li, Xu Si)</author>
      <guid isPermaLink="false">2504.17384v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Federated Client-tailored Adapter for Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2504.18020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的联邦客户端定制适配器（FCA）框架，用于医学图像分割，该框架能够稳定且定制化地进行分割，而不需要共享敏感的本地数据。&lt;h4&gt;背景&lt;/h4&gt;现有的医学图像分割方法主要采用集中式学习范式，但在只有分布式数据岛屿的实际情况中不适用。联邦学习虽然具有分布式解决方案的潜力，但由于客户端域异质性（包括分布多样性和类别不平衡）而难以实现稳定的训练。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的联邦客户端定制适配器（FCA）框架，用于医学图像分割，以实现稳定和客户端定制的自适应分割。&lt;h4&gt;方法&lt;/h4&gt;该框架通过在现成的医学基础模型中搅拌通用知识来稳定联邦训练过程。此外，开发了两种客户端定制的联邦更新策略，这些策略自适应地将适配器分解为公共和个体组件，然后分别全局和独立地更新与公共客户端不变和个体客户端特定单元相关的参数组。&lt;h4&gt;主要发现&lt;/h4&gt;FCA框架在三个大规模数据集上的广泛实验表明，该方法对于联邦医学分割是有效和优越的。&lt;h4&gt;结论&lt;/h4&gt;FCA框架能够实现稳定和客户端定制的医学图像分割，为联邦医学分割提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在X射线图像中进行医学图像分割对计算机辅助诊断和病变定位有益。现有方法主要属于集中式学习范式，这在只有访问分布式数据岛屿的实际医学场景中不适用。联邦学习有提供分布式解决方案的潜力，但由于客户端域异质性（包括分布多样性和类别不平衡）而难以实现稳定的训练。在本文中，我们提出了一种用于医学图像分割的新型联邦客户端定制适配器（FCA）框架，该框架在不共享敏感本地数据的情况下实现了稳定和客户端定制的自适应分割。具体来说，联邦适配器搅拌现成的医学基础模型中的通用知识，以稳定联邦训练过程。此外，我们开发了两种客户端定制的联邦更新策略，这些策略自适应地将适配器分解为公共和个体组件，然后分别全局和独立地更新与公共客户端不变和个体客户端特定单元相关的参数组。它们进一步稳定了异构联邦学习过程，并实现了最优的客户端定制而不是次优的全局妥协分割模型。在三个大规模数据集上的广泛实验证明了所提出的FCA框架对于联邦医学分割的有效性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image segmentation in X-ray images is beneficial for computer-aideddiagnosis and lesion localization. Existing methods mainly fall into acentralized learning paradigm, which is inapplicable in the practical medicalscenario that only has access to distributed data islands. Federated Learninghas the potential to offer a distributed solution but struggles with heavytraining instability due to client-wise domain heterogeneity (includingdistribution diversity and class imbalance). In this paper, we propose a novelFederated Client-tailored Adapter (FCA) framework for medical imagesegmentation, which achieves stable and client-tailored adaptive segmentationwithout sharing sensitive local data. Specifically, the federated adapter stirsuniversal knowledge in off-the-shelf medical foundation models to stabilize thefederated training process. In addition, we develop two client-tailoredfederated updating strategies that adaptively decompose the adapter into commonand individual components, then globally and independently update the parametergroups associated with common client-invariant and individual client-specificunits, respectively. They further stabilize the heterogeneous federatedlearning process and realize optimal client-tailored instead of sub-optimalglobal-compromised segmentation models. Extensive experiments on threelarge-scale datasets demonstrate the effectiveness and superiority of theproposed FCA framework for federated medical segmentation.</description>
      <author>example@mail.com (Guyue Hu, Siyuan Song, Yukun Kang, Zhu Yin, Gangming Zhao, Chenglong Li, Jin Tang)</author>
      <guid isPermaLink="false">2504.18020v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Sky-Drive: A Distributed Multi-Agent Simulation Platform for Socially-Aware and Human-AI Collaborative Future Transportation</title>
      <link>http://arxiv.org/abs/2504.18010v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Sky-Drive是一个新型的分布式多智能体仿真平台，通过四个关键创新解决了现有仿真器的局限性。&lt;h4&gt;背景&lt;/h4&gt;尽管自主系统仿真平台在驾驶策略的安全和可扩展测试方面取得了进展，但现有仿真器尚未完全满足未来交通研究的需求。&lt;h4&gt;目的&lt;/h4&gt;Sky-Drive旨在解决建模具有社会意识驾驶代理和促进有效人机协作的挑战。&lt;h4&gt;方法&lt;/h4&gt;Sky-Drive的四个关键创新包括：分布式架构、多模态人机在环框架、人机协作机制和数字孪生框架。&lt;h4&gt;主要发现&lt;/h4&gt;Sky-Drive支持多种应用，如自动驾驶车辆与易受伤害道路使用者交互建模、人机在环训练、具有社会意识的强化学习、个性化驾驶策略和定制场景生成。&lt;h4&gt;结论&lt;/h4&gt;Sky-Drive有望成为下一代具有社会意识和以人为中心的自动驾驶交通研究的基础平台。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in autonomous system simulation platforms have significantly enhanced the safe and scalable testing of driving policies. However, existing simulators do not yet fully meet the needs of future transportation research, particularly in modeling socially-aware driving agents and enabling effective human-AI collaboration. This paper introduces Sky-Drive, a novel distributed multi-agent simulation platform that addresses these limitations through four key innovations: (a) a distributed architecture for synchronized simulation across multiple terminals; (b) a multi-modal human-in-the-loop framework integrating diverse sensors to collect rich behavioral data; (c) a human-AI collaboration mechanism supporting continuous and adaptive knowledge exchange; and (d) a digital twin (DT) framework for constructing high-fidelity virtual replicas of real-world transportation environments. Sky-Drive supports diverse applications such as autonomous vehicle (AV)-vulnerable road user (VRU) interaction modeling, human-in-the-loop training, socially-aware reinforcement learning, personalized driving policy, and customized scenario generation. Future extensions will incorporate foundation models for context-aware decision support and hardware-in-the-loop (HIL) testing for real-world validation. By bridging scenario generation, data collection, algorithm training, and hardware integration, Sky-Drive has the potential to become a foundational platform for the next generation of socially-aware and human-centered autonomous transportation research. The demo video and code are available at: https://sky-lab-uw.github.io/Sky-Drive-website/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in autonomous system simulation platforms have significantlyenhanced the safe and scalable testing of driving policies. However, existingsimulators do not yet fully meet the needs of future transportation research,particularly in modeling socially-aware driving agents and enabling effectivehuman-AI collaboration. This paper introduces Sky-Drive, a novel distributedmulti-agent simulation platform that addresses these limitations through fourkey innovations: (a) a distributed architecture for synchronized simulationacross multiple terminals; (b) a multi-modal human-in-the-loop frameworkintegrating diverse sensors to collect rich behavioral data; (c) a human-AIcollaboration mechanism supporting continuous and adaptive knowledge exchange;and (d) a digital twin (DT) framework for constructing high-fidelity virtualreplicas of real-world transportation environments. Sky-Drive supports diverseapplications such as autonomous vehicle (AV)-vulnerable road user (VRU)interaction modeling, human-in-the-loop training, socially-aware reinforcementlearning, personalized driving policy, and customized scenario generation.Future extensions will incorporate foundation models for context-aware decisionsupport and hardware-in-the-loop (HIL) testing for real-world validation. Bybridging scenario generation, data collection, algorithm training, and hardwareintegration, Sky-Drive has the potential to become a foundational platform forthe next generation of socially-aware and human-centered autonomoustransportation research. The demo video and code are availableat:https://sky-lab-uw.github.io/Sky-Drive-website/</description>
      <author>example@mail.com (Zilin Huang, Zihao Sheng, Zhengyang Wan, Yansong Qu, Yuhao Luo, Boyue Wang, Pei Li, Yen-Jung Chen, Jiancong Chen, Keke Long, Jiayi Meng, Yue Leng, Sikai Chen)</author>
      <guid isPermaLink="false">2504.18010v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Assessing the Utility of Audio Foundation Models for Heart and Respiratory Sound Analysis</title>
      <link>http://arxiv.org/abs/2504.18004v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 1 figure, and 4 tables. Accepted by IEEE EMBC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了现成的音频基础模型在呼吸和心脏声音任务中的实际有效性，通过比较其性能与最先进（SOTA）微调结果，发现模型在噪声数据任务上表现不佳，但在干净数据任务上达到了SOTA性能，并且通用音频模型优于呼吸声音模型，表明其更广泛的应用性。&lt;h4&gt;背景&lt;/h4&gt;预训练的深度学习模型，称为基础模型，已成为自然语言处理和图像领域机器学习的重要构建块，这一趋势扩展到了呼吸和心脏声音模型，它们作为现成的特征提取器已证明其有效性。&lt;h4&gt;目的&lt;/h4&gt;评估现成的音频基础模型在呼吸和心脏声音任务中的实际有效性。&lt;h4&gt;方法&lt;/h4&gt;通过比较这些模型在四个呼吸和心脏声音任务上的性能与SOTA微调结果来进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;模型在噪声数据任务上表现不佳，但在干净数据任务上达到了SOTA性能。通用音频模型优于呼吸声音模型，显示了更广泛的应用性。&lt;h4&gt;结论&lt;/h4&gt;该研究通过实验结果和代码发布，为未来研究开发和使用基础模型进行呼吸和心脏声音分析做出了贡献。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预训练的深度学习模型，被称为基础模型，已成为机器学习领域，如自然语言处理和图像领域的必要构建块。这一趋势已经扩展到呼吸和心脏声音模型，这些模型作为现成的特征提取器已经证明其有效性。然而，它们的评估基准有限，导致与最先进（SOTA）性能的不兼容，从而阻碍了它们有效性的证明。本研究通过比较四个呼吸和心脏声音任务上的性能与SOTA微调结果，调查了现成音频基础模型的实际有效性。实验表明，模型在噪声数据任务上表现不佳，但在干净数据任务上达到了SOTA性能。此外，通用音频模型优于呼吸声音模型，突出了其更广泛的应用性。通过获得见解和发布的代码，我们为未来研究开发和利用基础模型进行呼吸和心脏声音分析做出了贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-trained deep learning models, known as foundation models, have becomeessential building blocks in machine learning domains such as natural languageprocessing and image domains. This trend has extended to respiratory and heartsound models, which have demonstrated effectiveness as off-the-shelf featureextractors. However, their evaluation benchmarking has been limited, resultingin incompatibility with state-of-the-art (SOTA) performance, thus hinderingproof of their effectiveness. This study investigates the practicaleffectiveness of off-the-shelf audio foundation models by comparing theirperformance across four respiratory and heart sound tasks with SOTA fine-tuningresults. Experiments show that models struggled on two tasks with noisy databut achieved SOTA performance on the other tasks with clean data. Moreover,general-purpose audio models outperformed a respiratory sound model,highlighting their broader applicability. With gained insights and the releasedcode, we contribute to future research on developing and leveraging foundationmodels for respiratory and heart sounds.</description>
      <author>example@mail.com (Daisuke Niizumi, Daiki Takeuchi, Masahiro Yasuda, Binh Thien Nguyen, Yasunori Ohishi, Noboru Harada)</author>
      <guid isPermaLink="false">2504.18004v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Improving Significant Wave Height Prediction Using Chronos Models</title>
      <link>http://arxiv.org/abs/2504.16834v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2403.07815 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于大语言模型（LLM）的时间架构（Chronos），用于波高预测，通过历史波浪数据的时序模式识别，实现了多模态的改进。&lt;h4&gt;背景&lt;/h4&gt;精确的波高预测对航海安全和海岸韧性至关重要，但传统的物理模型和机器学习方法在计算效率和非线性动力学建模方面面临挑战。&lt;h4&gt;目的&lt;/h4&gt;通过引入Chronos，优化波高预测的计算效率，提高非线性动力学建模的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用大语言模型的时间架构（Chronos），利用历史波浪数据在西北太平洋三个选定的海洋区域进行时序模式识别。&lt;h4&gt;主要发现&lt;/h4&gt;（1）训练时间减少了14.3%，推理速度比PatchTST基准快2.5倍，实现了0.575的均方根误差（MASE）；（2）短期预测（1-24小时）在全面指标上表现优异；（3）在长期预测（1-120小时）中保持预测优势；（4）在没有额外训练的情况下，与专业操作模型相比，Chronos的平均性能达到第四名（12个模型中）。&lt;h4&gt;结论&lt;/h4&gt;LLM增强的时间建模范式在波高预测中建立了新的标准，提供了计算高效的解决方案，并为复杂地球物理系统建模提供了一个可转移的框架。&lt;h4&gt;翻译&lt;/h4&gt;Accurate wave height prediction is critical for maritime safety and coastal resilience, yet conventional physics-based models and traditional machine learning methods face challenges in computational efficiency and nonlinear dynamics modeling. This study introduces Chronos, the first implementation of a large language model (LLM)-powered temporal architecture (Chronos) optimized for wave forecasting. Through advanced temporal pattern recognition applied to historical wave data from three strategically chosen marine zones in the Northwest Pacific basin, our framework achieves multimodal improvements: (1) 14.3% reduction in training time with 2.5x faster inference speed compared to PatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units; (2) superior short-term forecasting (1-24h) across comprehensive metrics; (3) sustained predictive leadership in extended-range forecasts (1-120h); and (4) demonstrated zero-shot capability maintaining median performance (rank 4/12) against specialized operational models. This LLM-enhanced temporal modeling paradigm establishes a new standard in wave prediction, offering both computationally efficient solutions and a transferable framework for complex geophysical systems modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate wave height prediction is critical for maritime safety and coastalresilience, yet conventional physics-based models and traditional machinelearning methods face challenges in computational efficiency and nonlineardynamics modeling. This study introduces Chronos, the first implementation of alarge language model (LLM)-powered temporal architecture (Chronos) optimizedfor wave forecasting. Through advanced temporal pattern recognition applied tohistorical wave data from three strategically chosen marine zones in theNorthwest Pacific basin, our framework achieves multimodal improvements: (1)14.3% reduction in training time with 2.5x faster inference speed compared toPatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)sustained predictive leadership in extended-range forecasts (1-120h); and (4)demonstrated zero-shot capability maintaining median performance (rank 4/12)against specialized operational models. This LLM-enhanced temporal modelingparadigm establishes a new standard in wave prediction, offering bothcomputationally efficient solutions and a transferable framework for complexgeophysical systems modeling.</description>
      <author>example@mail.com (Yilin Zhai, Hongyuan Shi, Chao Zhan, Qing Wang, Zaijin You, Nan Wang)</author>
      <guid isPermaLink="false">2504.16834v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>OmniSage: Large Scale, Multi-Entity Heterogeneous Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2504.17811v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为OmniSage的大规模表示学习框架，该框架通过整合多种技术支持Pinterest上的多种应用。&lt;h4&gt;背景&lt;/h4&gt;表示学习是提高网络应用中搜索和推荐系统性能的关键任务，包括基于图的关系表示、基于序列的用户活动时序捕获和基于内容的文本及视觉内容利用等方法。&lt;h4&gt;目的&lt;/h4&gt;开发一个统一框架，整合各种表示学习技术以支持多种应用。&lt;h4&gt;方法&lt;/h4&gt;OmniSage通过采用多种对比学习任务，整合图神经网络、基于内容的模型和用户序列模型，并开发了一个高效的支撑数十亿节点Pinterest图的基础设施。&lt;h4&gt;主要发现&lt;/h4&gt;OmniSage生成的通用表示显著提升了Pinterest的用户体验，使站内收藏量增加了约2.5%。&lt;h4&gt;结论&lt;/h4&gt;本文强调了统一表示学习方法的重要性，并计划在论文发表时开源OmniSage代码。&lt;h4&gt;翻译&lt;/h4&gt;Representation learning, a task of learning latent vectors to represententities, is a key task in improving search and recommender systems in webapplications. Various representation learning methods have been developed,including graph-based approaches for relationships among entities,sequence-based methods for capturing the temporal evolution of user activities,and content-based models for leveraging text and visual content. However, thedevelopment of a unifying framework that integrates these diverse techniques tosupport multiple applications remains a significant challenge. This paperpresents OmniSage, a large-scale representation framework that learns universalrepresentations for a variety of applications at Pinterest. OmniSage integratesgraph neural networks with content-based models and user sequence models byemploying multiple contrastive learning tasks to effectively process graphdata, user sequence data, and content signals. To support the training andinference of OmniSage, we developed an efficient infrastructure capable ofsupporting Pinterest graphs with billions of nodes. The universalrepresentations generated by OmniSage have significantly enhanced userexperiences on Pinterest, leading to an approximate 2.5% increase in sitewiderepins (saves) across five applications. This paper highlights the impact ofunifying representation learning methods, and we will open source the OmniSagecode by the time of publication.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning, a task of learning latent vectors to represententities, is a key task in improving search and recommender systems in webapplications. Various representation learning methods have been developed,including graph-based approaches for relationships among entities,sequence-based methods for capturing the temporal evolution of user activities,and content-based models for leveraging text and visual content. However, thedevelopment of a unifying framework that integrates these diverse techniques tosupport multiple applications remains a significant challenge. This paperpresents OmniSage, a large-scale representation framework that learns universalrepresentations for a variety of applications at Pinterest. OmniSage integratesgraph neural networks with content-based models and user sequence models byemploying multiple contrastive learning tasks to effectively process graphdata, user sequence data, and content signals. To support the training andinference of OmniSage, we developed an efficient infrastructure capable ofsupporting Pinterest graphs with billions of nodes. The universalrepresentations generated by OmniSage have significantly enhanced userexperiences on Pinterest, leading to an approximate 2.5% increase in sitewiderepins (saves) across five applications. This paper highlights the impact ofunifying representation learning methods, and we will open source the OmniSagecode by the time of publication.</description>
      <author>example@mail.com (Anirudhan Badrinath, Alex Yang, Kousik Rajesh, Prabhat Agarwal, Jaewon Yang, Haoyu Chen, Jiajing Xu, Charles Rosenberg)</author>
      <guid isPermaLink="false">2504.17811v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Optimism, Expectation, or Sarcasm? Multi-Class Hope Speech Detection in Spanish and English</title>
      <link>http://arxiv.org/abs/2504.17974v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了多语言细粒度希望语音数据集PolyHope V2，用于情感识别任务，并探讨了在区分不同希望类别和讽刺方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;希望是一种复杂且未被充分研究的情绪状态，在教育、心理健康和社会互动中扮演重要角色。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一个能够准确检测不同希望类别的多语言数据集，并评估预训练模型在识别希望和讽刺方面的性能。&lt;h4&gt;方法&lt;/h4&gt;研究人员创建了一个包含超过30,000条标注推文的PolyHope V2数据集，区分了四种希望子类型：一般化、现实主义、不切实际和讽刺。他们还在零样本和少样本情况下，将多个预训练变压器模型与大型语言模型（如GPT 4和Llama 3）进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，经过微调的变压器在区分细微的希望类别和讽刺方面优于基于提示的大型语言模型。&lt;h4&gt;结论&lt;/h4&gt;该数据集和结果为未来需要跨语言语义和语境敏感性的情感识别任务提供了一个坚实的基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：希望是一种复杂且未被充分研究的情绪状态，在教育、心理健康和社会互动中扮演着重要的角色。与基本情绪不同，希望以细微的形式表现出来，从基于现实的乐观到过度的愿望或讽刺，这使得自然语言处理系统难以准确检测。本研究介绍了PolyHope V2，这是一个多语言、细粒度的希望语音数据集，包含超过30,000条英语和西班牙语的标注推文。这个资源区分了四种希望子类型：一般化、现实主义、不切实际和讽刺，并通过明确标注讽刺实例来增强现有数据集。研究比较了多个预训练的变压器模型，以及在大语言模型（如GPT 4和Llama 3）下的零样本和少样本规则。研究发现，经过微调的变压器在区分细微的希望类别和讽刺方面优于基于提示的大型语言模型。通过定性分析和混淆矩阵，研究突出了在区分密切相关希望子类型方面的系统性挑战。该数据集和结果为未来需要跨语言语义和语境敏感性的情感识别任务提供了一个坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hope is a complex and underexplored emotional state that plays a significantrole in education, mental health, and social interaction. Unlike basicemotions, hope manifests in nuanced forms ranging from grounded optimism toexaggerated wishfulness or sarcasm, making it difficult for Natural LanguageProcessing systems to detect accurately. This study introduces PolyHope V2, amultilingual, fine-grained hope speech dataset comprising over 30,000 annotatedtweets in English and Spanish. This resource distinguishes between four hopesubtypes Generalized, Realistic, Unrealistic, and Sarcastic and enhancesexisting datasets by explicitly labeling sarcastic instances. We benchmarkmultiple pretrained transformer models and compare them with large languagemodels (LLMs) such as GPT 4 and Llama 3 under zero-shot and few-shot regimes.Our findings show that fine-tuned transformers outperform prompt-based LLMs,especially in distinguishing nuanced hope categories and sarcasm. Throughqualitative analysis and confusion matrices, we highlight systematic challengesin separating closely related hope subtypes. The dataset and results provide arobust foundation for future emotion recognition tasks that demand greatersemantic and contextual sensitivity across languages.</description>
      <author>example@mail.com (Sabur Butt, Fazlourrahman Balouchzahi, Ahmad Imam Amjad, Maaz Amjad, Hector G. Ceballos, Salud Maria Jimenez-Zafra)</author>
      <guid isPermaLink="false">2504.17974v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Subject-driven Video Generation via Disentangled Identity and Motion</title>
      <link>http://arxiv.org/abs/2504.17816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page :  https://carpedkm.github.io/projects/disentangled_sub/index.html&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种通过解耦主题特定学习与时间动态，在零样本情况下无需额外调整的训练主题驱动个性化视频生成模型的方法。&lt;h4&gt;背景&lt;/h4&gt;传统的无调整视频定制方法通常依赖于大型、标注的视频数据集，这既计算成本高又需要大量的标注。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种更高效、成本更低的视频定制模型。&lt;h4&gt;方法&lt;/h4&gt;引入了图像定制数据集直接用于训练视频定制模型，将视频定制分为两个步骤：(1)通过图像定制数据集进行身份注入；(2)通过图像到视频的训练方法，使用少量未标注视频进行时间建模的保留。此外，在图像到视频微调期间采用随机图像标记丢弃和随机图像初始化来减轻复制粘贴问题。在联合优化主题特定和时间特征时引入随机切换，以减轻灾难性遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了强大的主题一致性和可扩展性，在零样本设置中优于现有的视频定制模型，证明了该框架的有效性。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在零样本设置中表现出色，为视频定制提供了一种高效且成本低的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose to train a subject-driven customized video generation modelthrough decoupling the subject-specific learning from temporal dynamics inzero-shot without additional tuning. A traditional method for videocustomization that is tuning-free often relies on large, annotated videodatasets, which are computationally expensive and require extensive annotation.In contrast to the previous approach, we introduce the use of an imagecustomization dataset directly on training video customization models,factorizing the video customization into two folds: (1) identity injectionthrough image customization dataset and (2) temporal modeling preservation witha small set of unannotated videos through the image-to-video training method.Additionally, we employ random image token dropping with randomized imageinitialization during image-to-video fine-tuning to mitigate the copy-and-pasteissue. To further enhance learning, we introduce stochastic switching duringjoint optimization of subject-specific and temporal features, mitigatingcatastrophic forgetting. Our method achieves strong subject consistency andscalability, outperforming existing video customization models in zero-shotsettings, demonstrating the effectiveness of our framework.</description>
      <author>example@mail.com (Daneul Kim, Jingxu Zhang, Wonjoon Jin, Sunghyun Cho, Qi Dai, Jaesik Park, Chong Luo)</author>
      <guid isPermaLink="false">2504.17816v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order Neighboring Feature Fusion</title>
      <link>http://arxiv.org/abs/2504.15920v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为ScaleGNN的新框架，用于解决大规模图上的GNN模型面临的过平滑和可扩展性问题。&lt;h4&gt;背景&lt;/h4&gt;Graph Neural Networks (GNNs) 在图相关任务中表现出色，通过迭代消息传递有效地捕获节点之间的关系信息。然而，GNNs 存在过平滑和可扩展性两大挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在同时解决GNN在大型图上的过平滑和可扩展性问题。&lt;h4&gt;方法&lt;/h4&gt;ScaleGNN通过自适应融合多级图特征来解决这些问题，包括构建每个阶数的邻接矩阵，学习通过可训练权重传递的相对信息，引入基于局部贡献分数（LCS）的高阶冗余特征掩码机制，以及低阶增强特征聚合。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，ScaleGNN在真实世界数据集上，无论是在准确性还是计算效率方面，都优于最先进的GNN模型。&lt;h4&gt;结论&lt;/h4&gt;ScaleGNN框架能够有效地提高GNN模型在大型图上的性能，同时保持高效的计算效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated strong performance acrossvarious graph-based tasks by effectively capturing relational informationbetween nodes. These models rely on iterative message passing to propagate nodefeatures, enabling nodes to aggregate information from their neighbors. Recentresearch has significantly improved the message-passing mechanism, enhancingGNN scalability on large-scale graphs. However, GNNs still face two mainchallenges: over-smoothing, where excessive message passing results inindistinguishable node representations, especially in deep networksincorporating high-order neighbors; and scalability issues, as traditionalarchitectures suffer from high model complexity and increased inference timedue to redundant information aggregation. This paper proposes a novel frameworkfor large-scale graphs named ScaleGNN that simultaneously addresses bothchallenges by adaptively fusing multi-level graph features. We first constructneighbor matrices for each order, learning their relative information throughtrainable weights through an adaptive high-order feature fusion module. Thisallows the model to selectively emphasize informative high-order neighborswhile reducing unnecessary computational costs. Additionally, we introduce aHigh-order redundant feature masking mechanism based on a Local ContributionScore (LCS), which enables the model to retain only the most relevant neighborsat each order, preventing redundant information propagation. Furthermore,low-order enhanced feature aggregation adaptively integrates low-order andhigh-order features based on task relevance, ensuring effective capture of bothlocal and global structural information without excessive complexity. Extensiveexperiments on real-world datasets demonstrate that our approach consistentlyoutperforms state-of-the-art GNN models in both accuracy and computationalefficiency.</description>
      <author>example@mail.com (Xiang Li, Haobing Liu, Jianpeng Qi, Yuan Cao, Guoqing Chao, Yanwei Yu)</author>
      <guid isPermaLink="false">2504.15920v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>CLOC: Contrastive Learning for Ordinal Classification with Multi-Margin N-pair Loss</title>
      <link>http://arxiv.org/abs/2504.17813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CLOC的新方法，用于解决序数分类中相邻类别错误的重要性不同的问题。&lt;h4&gt;背景&lt;/h4&gt;在序数分类中，相邻类别的错误分类很常见，但这些错误的后果并不相同。例如，将良性肿瘤分类错误的重要性低于在癌前病变到癌症的转变阈值处的错误，后者可能会深刻影响治疗选择。&lt;h4&gt;目的&lt;/h4&gt;针对现有序数分类方法未考虑这些边界的不同重要性的局限性，本文提出了一种新的基于边界的对比学习方法CLOC，通过优化多个边缘来学习有序表示。&lt;h4&gt;方法&lt;/h4&gt;CLOC通过一个新颖的多边缘n对损失（MMNP）来学习有序表示，它允许在关键相邻类别之间灵活设置决策边界，从而促进类别之间的平滑过渡并减少对训练数据中存在的偏差过度拟合的风险。&lt;h4&gt;主要发现&lt;/h4&gt;本文提供了关于MMNP特性的实证讨论，并在五个真实世界图像数据集（Adience、Historical Colour Image Dating、Knee Osteoarthritis、Indian Diabetic Retinopathy Image和Breast Carcinoma Subtyping）以及一个模拟临床决策偏差的合成数据集上展示了实验结果。结果表明，CLOC优于现有的序数分类方法，并展示了CLOC在学习和有意义、有序表示方面的可解释性和可控性，这些表示与临床和实际需求相一致。&lt;h4&gt;结论&lt;/h4&gt;CLOC在序数分类中显示出优于现有方法的性能，并且能够学习到符合临床和实际需求的有序表示。&lt;h4&gt;翻译&lt;/h4&gt;在序数分类中，相邻类别的错误分类很常见，但这些错误的后果并不相同。例如，将良性肿瘤分类错误的重要性低于在癌前病变到癌症的转变阈值处的错误，后者可能会深刻影响治疗选择。尽管如此，现有的序数分类方法并没有考虑到这些边界的不同重要性，将所有相邻类别视为同等重要。为了解决这一局限性，我们提出了CLOC，一种基于边界的对比学习方法，用于序数分类，该方法通过优化多个边缘来学习有序表示，并使用一种新颖的多边缘n对损失（MMNP）。CLOC能够在关键相邻类别之间灵活设置决策边界，从而促进类别之间的平滑过渡并减少对训练数据中存在的偏差过度拟合的风险。我们对MMNP的特性进行了实证讨论，并在五个真实世界图像数据集（Adience、Historical Colour Image Dating、Knee Osteoarthritis、Indian Diabetic Retinopathy Image和Breast Carcinoma Subtyping）以及一个模拟临床决策偏差的合成数据集上展示了实验结果。我们的结果表明，CLOC优于现有的序数分类方法，并展示了CLOC在学习和有意义、有序表示方面的可解释性和可控性，这些表示与临床和实际需求相一致。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In ordinal classification, misclassifying neighboring ranks is common, yetthe consequences of these errors are not the same. For example, misclassifyingbenign tumor categories is less consequential, compared to an error at thepre-cancerous to cancerous threshold, which could profoundly influencetreatment choices. Despite this, existing ordinal classification methods do notaccount for the varying importance of these margins, treating all neighboringclasses as equally significant. To address this limitation, we propose CLOC, anew margin-based contrastive learning method for ordinal classification thatlearns an ordered representation based on the optimization of multiple marginswith a novel multi-margin n-pair loss (MMNP). CLOC enables flexible decisionboundaries across key adjacent categories, facilitating smooth transitionsbetween classes and reducing the risk of overfitting to biases present in thetraining data. We provide empirical discussion regarding the properties of MMNPand show experimental results on five real-world image datasets (Adience,Historical Colour Image Dating, Knee Osteoarthritis, Indian DiabeticRetinopathy Image, and Breast Carcinoma Subtyping) and one synthetic datasetsimulating clinical decision bias. Our results demonstrate that CLOCoutperforms existing ordinal classification methods and show theinterpretability and controllability of CLOC in learning meaningful, orderedrepresentations that align with clinical and practical needs.</description>
      <author>example@mail.com (Dileepa Pitawela, Gustavo Carneiro, Hsiang-Ting Chen)</author>
      <guid isPermaLink="false">2504.17813v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Class-Conditional Distribution Balancing for Group Robust Classification</title>
      <link>http://arxiv.org/abs/2504.17314v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的方法来解决由虚假相关性导致的模型错误预测问题，这些问题在现实世界的通用化中构成了一个关键挑战。&lt;h4&gt;背景&lt;/h4&gt;现有的研究将这个问题归因于组不平衡，并通过最大化组平衡或最差组精度来解决这个问题，这依赖于昂贵的偏差注释。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种简单而有效的鲁棒学习方法，该方法不需要偏差注释或预测，以减少虚假因素与标签信息之间的互信息。&lt;h4&gt;方法&lt;/h4&gt;该方法通过样本重加权策略来实现类条件分布的平衡，自动突出少数群体和类别，从而有效消除虚假相关性，并生成用于分类的去偏差数据分布。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量的实验和分析，证明了该方法在性能上始终处于领先地位，与依赖于偏差监督的方法相媲美。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在处理虚假相关性方面取得了显著成果，为鲁棒学习和数据分布平衡提供了新的视角和有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spurious correlations that lead models to correct predictions for the wrongreasons pose a critical challenge for robust real-world generalization.Existing research attributes this issue to group imbalance and addresses it bymaximizing group-balanced or worst-group accuracy, which heavily relies onexpensive bias annotations. A compromise approach involves predicting biasinformation using extensively pretrained foundation models, which requireslarge-scale data and becomes impractical for resource-limited rare domains. Toaddress these challenges, we offer a novel perspective by reframing thespurious correlations as imbalances or mismatches in class-conditionaldistributions, and propose a simple yet effective robust learning method thateliminates the need for both bias annotations and predictions. With the goal ofreducing the mutual information between spurious factors and label information,our method leverages a sample reweighting strategy to achieve class-conditionaldistribution balancing, which automatically highlights minority groups andclasses, effectively dismantling spurious correlations and producing a debiaseddata distribution for classification. Extensive experiments and analysisdemonstrate that our approach consistently delivers state-of-the-artperformance, rivaling methods that rely on bias supervision.</description>
      <author>example@mail.com (Miaoyun Zhao, Qiang Zhang, Chenrong Li)</author>
      <guid isPermaLink="false">2504.17314v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Research on Cloud Platform Network Traffic Monitoring and Anomaly Detection System based on Large Language Models</title>
      <link>http://arxiv.org/abs/2504.17807v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of 2025 IEEE 7th International Conference on  Communications, Information System and Computer Engineering (CISCE 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于大型语言模型的网络流量监控和异常检测系统，以应对云计算平台快速发展和网络流量复杂性增加的挑战。&lt;h4&gt;背景&lt;/h4&gt;云计算平台迅速发展，网络流量复杂性不断提高，这要求有适当的网络流量监控和异常检测机制来确保网络的安全和性能。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于大型语言模型的网络流量监控和异常检测系统，以提高检测精度和计算效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结合注意力机制的混合模型，将大型语言模型与监督学习框架结合，通过预训练的大型语言模型分析预测网络流量，并增加考虑时序性和上下文的异常检测层。同时，采用了一种基于迁移学习的方法，以增强模型快速适应未知网络结构和对抗条件的能力。&lt;h4&gt;主要发现&lt;/h4&gt;所设计的模型在检测准确率和计算效率方面优于传统方法，能够有效识别包括零日攻击和流量拥堵模式在内的各种网络异常，并显著降低误报率。&lt;h4&gt;结论&lt;/h4&gt;本文提出的网络流量监控和异常检测系统在准确性和效率方面表现出色，为网络安全和性能提供了有效的保障。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapidly evolving cloud platforms and the escalating complexity of networktraffic demand proper network traffic monitoring and anomaly detection toensure network security and performance. This paper introduces a large languagemodel (LLM)-based network traffic monitoring and anomaly detection system. Inaddition to existing models such as autoencoders and decision trees, we harnessthe power of large language models for processing sequence data from networktraffic, which allows us a better capture of underlying complex patterns, aswell as slight fluctuations in the dataset. We show for a given detection task,the need for a hybrid model that incorporates the attention mechanism of thetransformer architecture into a supervised learning framework in order toachieve better accuracy. A pre-trained large language model analyzes andpredicts the probable network traffic, and an anomaly detection layer thatconsiders temporality and context is added. Moreover, we present a noveltransfer learning-based methodology to enhance the model's effectiveness toquickly adapt to unknown network structures and adversarial conditions withoutrequiring extensive labeled datasets. Actual results show that the designedmodel outperforms traditional methods in detection accuracy and computationalefficiency, effectively identify various network anomalies such as zero-dayattacks and traffic congestion pattern, and significantly reduce the falsepositive rate.</description>
      <author>example@mail.com (Ze Yang, Yihong Jin, Juntian Liu, Xinhe Xu, Yihan Zhang, Shuyang Ji)</author>
      <guid isPermaLink="false">2504.17807v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search</title>
      <link>http://arxiv.org/abs/2504.15865v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Medical Neural Network Search (MedNNS)，这是一个用于医学影像应用的新颖的神经网络搜索框架，旨在解决深度学习模型在医学任务中的适配问题。&lt;h4&gt;背景&lt;/h4&gt;深度学习在医学影像领域取得了显著进展，但将深度学习模型适配到医学任务仍然是一个重大挑战，主要由于架构选择和权重初始化的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效解决医学影像领域深度学习模型适配问题的框架。&lt;h4&gt;方法&lt;/h4&gt;MedNNS通过构建一个元空间来编码数据集和模型，优化架构选择和权重初始化。该框架使用基于超网络的策略，将模型动物园规模扩大了51倍，并引入了排名损失和弗雷歇起始距离损失来捕捉模型和数据集之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MedNNS在多个数据集上显著优于ImageNet预训练的深度学习模型和最先进的神经网络搜索方法，平均准确率提高了1.7%，并且收敛速度更快。&lt;h4&gt;结论&lt;/h4&gt;MedNNS是医学影像领域一个有效的神经网络搜索框架，有助于提高深度学习模型在医学任务中的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：深度学习（DL）在医学影像领域取得了显著进展。然而，将深度学习模型适配到医学任务仍然是一个重大挑战，主要由于两个关键因素：（1）架构选择，因为不同的任务需要专门的设计；（2）权重初始化，这直接影响模型的收敛速度和最终性能。尽管从ImageNet迁移学习是一个广泛采用的策略，但其有效性受到自然图像和医学图像之间巨大差异的限制。为了解决这些挑战，我们引入了医学神经网络搜索（MedNNS），这是第一个用于医学影像应用的神经网络搜索框架。MedNNS通过构建一个元空间来联合优化架构选择和权重初始化，该空间根据数据集和模型共同表现的好坏来编码它们。我们使用基于超网络的策略构建这个空间，将模型动物园规模扩大了51倍，超过之前的最佳方法（SOTA）。此外，我们将排名损失和弗雷歇起始距离损失引入到空间构建中，以捕捉模型间和数据集间的关系，从而在元空间中实现更准确的校准。多个数据集上的实验结果表明，MedNNS在性能上显著优于ImageNet预训练的深度学习模型和SOTA神经网络搜索（NAS）方法，平均准确率在数据集上提高了1.7%，并且收敛速度更快。代码和处理的元空间可在https://github.com/BioMedIA-MBZUAI/MedNNS上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning (DL) has achieved remarkable progress in the field of medicalimaging. However, adapting DL models to medical tasks remains a significantchallenge, primarily due to two key factors: (1) architecture selection, asdifferent tasks necessitate specialized model designs, and (2) weightinitialization, which directly impacts the convergence speed and finalperformance of the models. Although transfer learning from ImageNet is a widelyadopted strategy, its effectiveness is constrained by the substantialdifferences between natural and medical images. To address these challenges, weintroduce Medical Neural Network Search (MedNNS), the first Neural NetworkSearch framework for medical imaging applications. MedNNS jointly optimizesarchitecture selection and weight initialization by constructing a meta-spacethat encodes datasets and models based on how well they perform together. Webuild this space using a Supernetwork-based approach, expanding the model zoosize by 51x times over previous state-of-the-art (SOTA) methods. Moreover, weintroduce rank loss and Fr\'echet Inception Distance (FID) loss into theconstruction of the space to capture inter-model and inter-datasetrelationships, thereby achieving more accurate alignment in the meta-space.Experimental results across multiple datasets demonstrate that MedNNSsignificantly outperforms both ImageNet pre-trained DL models and SOTA NeuralArchitecture Search (NAS) methods, achieving an average accuracy improvement of1.7% across datasets while converging substantially faster. The code and theprocessed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS.</description>
      <author>example@mail.com (Lotfi Abdelkrim Mecharbat, Ibrahim Almakky, Martin Takac, Mohammad Yaqub)</author>
      <guid isPermaLink="false">2504.15865v2</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
  <item>
      <title>Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset</title>
      <link>http://arxiv.org/abs/2504.17371v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DeepScenario Open 3D Dataset（DSC3D），这是一个高质量的、无遮挡的6自由度边界框轨迹数据集，通过新型单目相机无人机跟踪流程获取。该数据集包含超过17.5万条14种交通参与者的轨迹，在多样性和规模上显著超过现有数据集。&lt;h4&gt;背景&lt;/h4&gt;精确的3D轨迹数据对于自动驾驶技术的发展至关重要。传统的数据集通常由安装在汽车上的固定传感器捕获，容易受到遮挡，并且只能精确地重建测量车辆附近动态环境，而忽略了更远处的物体。&lt;h4&gt;目的&lt;/h4&gt;提高自动驾驶系统的性能，通过提供详细的3D环境表示，改善障碍物交互和安全性。&lt;h4&gt;方法&lt;/h4&gt;使用新型单目相机无人机跟踪流程采集数据，包括停车场、拥挤的内城区、陡峭的城市交叉口、联邦高速公路和郊外交叉口等五个不同地点的多种场景。&lt;h4&gt;主要发现&lt;/h4&gt;DSC3D数据集在多样性和规模上超过现有数据集，包含许多前所未有的场景，如高度人口密集的街道上的复杂车辆行人交互和从入口到出口的综合停车操作。&lt;h4&gt;结论&lt;/h4&gt;DSC3D数据集对多个应用有实用价值，包括运动预测、运动规划、场景挖掘和生成反应式交通代理。数据集的交互式在线可视化平台和完整数据集公开可用，促进了运动预测、行为建模和安全验证的研究。&lt;h4&gt;翻译&lt;/h4&gt;Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet, traditional datasets are usually captured by fixed sensors mounted on a car and are susceptible to occlusion. Additionally, such an approach can precisely reconstruct the dynamic environment in the close vicinity of the measurement vehicle only, while neglecting objects that are further away. In this paper, we introduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality, occlusion-free dataset of 6 degrees of freedom bounding box trajectories acquired through a novel monocular camera drone tracking pipeline. Our dataset includes more than 175,000 trajectories of 14 types of traffic participants and significantly exceeds existing datasets in terms of diversity and scale, containing many unprecedented scenarios such as complex vehicle-pedestrian interaction on highly populated urban streets and comprehensive parking maneuvers from entry to exit. DSC3D dataset was captured in five various locations in Europe and the United States and include: a parking lot, a crowded inner-city, a steep urban intersection, a federal highway, and a suburban intersection. Our 3D trajectory dataset aims to enhance autonomous driving systems by providing detailed environmental 3D representations, which could lead to improved obstacle interactions and safety. We demonstrate its utility across multiple applications including motion prediction, motion planning, scenario mining, and generative reactive traffic agents. Our interactive online visualization platform and the complete dataset are publicly available at app.deepscenario.com, facilitating research in motion prediction, behavior modeling, and safety validation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet,traditional datasets are usually captured by fixed sensors mounted on a car andare susceptible to occlusion. Additionally, such an approach can preciselyreconstruct the dynamic environment in the close vicinity of the measurementvehicle only, while neglecting objects that are further away. In this paper, weintroduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality,occlusion-free dataset of 6 degrees of freedom bounding box trajectoriesacquired through a novel monocular camera drone tracking pipeline. Our datasetincludes more than 175,000 trajectories of 14 types of traffic participants andsignificantly exceeds existing datasets in terms of diversity and scale,containing many unprecedented scenarios such as complex vehicle-pedestrianinteraction on highly populated urban streets and comprehensive parkingmaneuvers from entry to exit. DSC3D dataset was captured in five variouslocations in Europe and the United States and include: a parking lot, a crowdedinner-city, a steep urban intersection, a federal highway, and a suburbanintersection. Our 3D trajectory dataset aims to enhance autonomous drivingsystems by providing detailed environmental 3D representations, which couldlead to improved obstacle interactions and safety. We demonstrate its utilityacross multiple applications including motion prediction, motion planning,scenario mining, and generative reactive traffic agents. Our interactive onlinevisualization platform and the complete dataset are publicly available atapp.deepscenario.com, facilitating research in motion prediction, behaviormodeling, and safety validation.</description>
      <author>example@mail.com (Oussema Dhaouadi, Johannes Meier, Luca Wahl, Jacques Kaiser, Luca Scalerandi, Nick Wandelburg, Zhuolun Zhou, Nijanthan Berinpanathan, Holger Banzhaf, Daniel Cremers)</author>
      <guid isPermaLink="false">2504.17371v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning for Continuous Touch-Based Authentication</title>
      <link>http://arxiv.org/abs/2504.17271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于触摸行为的连续用户认证方法，旨在为智能手机提供更可靠和有效的安全解决方案。&lt;h4&gt;背景&lt;/h4&gt;随着智能手机在日常生活中的普及，对安全控制的需求日益增加，尤其是在处理、存储和传输敏感信息时。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用触摸屏进行连续用户认证，以实现自然和无缝的安全解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一种统一的对比学习框架，利用时间掩码自动编码器（TMAE）从原始多传感器数据流中提取时间模式，并集成到Siamese时间注意卷积网络中，以模型化序列和跨模态模式。同时，引入多头注意力和通道注意力机制来捕捉长距离依赖关系和优化通道间特征集成。&lt;h4&gt;主要发现&lt;/h4&gt;在公共基准数据集和自收集数据集上的实验表明，该方法优于现有方法，提供了可靠和有效的移动设备用户认证解决方案。&lt;h4&gt;结论&lt;/h4&gt;该方法为智能手机用户认证提供了一种有效的解决方案，具有较好的性能和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Smart mobile devices have become indispensable in modern daily life, wheresensitive information is frequently processed, stored, and transmitted-posingcritical demands for robust security controls. Given that touchscreens are theprimary medium for human-device interaction, continuous user authenticationbased on touch behavior presents a natural and seamless security solution.While existing methods predominantly adopt binary classification undersingle-modal learning settings, we propose a unified contrastive learningframework for continuous authentication in a non-disruptive manner.Specifically, the proposed method leverages a Temporal Masked Autoencoder toextract temporal patterns from raw multi-sensor data streams, capturingcontinuous motion and gesture dynamics. The pre-trained TMAE is subsequentlyintegrated into a Siamese Temporal-Attentive Convolutional Network within acontrastive learning paradigm to model both sequential and cross-modalpatterns. To further enhance performance, we incorporate multi-head attentionand channel attention mechanisms to capture long-range dependencies andoptimize inter-channel feature integration. Extensive experiments on publicbenchmarks and a self-collected dataset demonstrate that our approachoutperforms state-of-the-art methods, offering a reliable and effectivesolution for user authentication on mobile devices.</description>
      <author>example@mail.com (Mengyu Qiao, Yunpeng Zhai, Yang Wang)</author>
      <guid isPermaLink="false">2504.17271v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>MSGCN: Multiplex Spatial Graph Convolution Network for Interlayer Link Weight Prediction</title>
      <link>http://arxiv.org/abs/2504.17749v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了Graph Neural Networks（GNNs）在多种学习任务中的应用，特别是针对链接权重预测的新方法Multiplex Spatial Graph Convolution Network（MSGCN）。&lt;h4&gt;背景&lt;/h4&gt;GNNs在节点分类和链接预测等领域表现出色，但在链接权重预测，尤其是多层网络中的链接权重预测方面，由于复杂性较高而受到较少关注。&lt;h4&gt;目的&lt;/h4&gt;提出MSGCN方法，旨在解决多层网络中链接权重预测的挑战，通过在多个层之间嵌入信息来预测层间链接权重。&lt;h4&gt;方法&lt;/h4&gt;MSGCN模型将空间图卷积推广到复用网络，并捕捉多层节点间的几何结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MSGCN模型在各种复用网络结构中具有稳健、准确和可推广的链接权重预测性能。&lt;h4&gt;结论&lt;/h4&gt;MSGCN方法在多层网络链接权重预测方面是一种有效且可靠的方法。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络（GNNs）已被广泛应用于各种学习任务，从节点分类到链接预测。它们在涉及图结构数据的多个领域表现出卓越的性能。然而，由于与二元链接分类相比复杂性增加，链接权重预测这一重要类别的学习任务得到了较少的关注。当考虑多层网络时，节点可以在多个层之间相互连接，链接权重预测变得更加具有挑战性。为了解决这些挑战，我们提出了一种名为多路空间图卷积网络（MSGCN）的新方法，该方法在多个层之间空间嵌入信息以预测层间链接权重。MSGCN模型将空间图卷积推广到复用网络，并捕捉多层节点间的几何结构。使用具有已知层间链接信息的数据的广泛实验表明，MSGCN模型在各种复用网络结构中具有稳健、准确和可推广的链接权重预测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have been widely used for various learningtasks, ranging from node classification to link prediction. They havedemonstrated excellent performance in multiple domains involvinggraph-structured data. However, an important category of learning tasks, namelylink weight prediction, has received less emphasis due to its increasedcomplexity compared to binary link classification. Link weight predictionbecomes even more challenging when considering multilayer networks, where nodescan be interconnected across multiple layers. To address these challenges, wepropose a new method named Multiplex Spatial Graph Convolution Network (MSGCN),which spatially embeds information across multiple layers to predict interlayerlink weights. The MSGCN model generalizes spatial graph convolution tomultiplex networks and captures the geometric structure of nodes acrossmultiple layers. Extensive experiments using data with known interlayer linkinformation show that the MSGCN model has robust, accurate, and generalizablelink weight prediction performance across a wide variety of multiplex networkstructures.</description>
      <author>example@mail.com (Steven E. Wilson, Sina Khanmohammadi)</author>
      <guid isPermaLink="false">2504.17749v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>PICO: Reconstructing 3D People In Contact with Objects</title>
      <link>http://arxiv.org/abs/2504.17695v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in CVPR'25. Project Page: https://pico.is.tue.mpg.de&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从单色图像中恢复3D人-物交互的方法，以克服深度模糊、遮挡和物体形状和外观的巨大变化等挑战。&lt;h4&gt;背景&lt;/h4&gt;从单色图像中恢复3D人-物交互是一个挑战，因为深度模糊、遮挡和物体形状和外观的巨大变化。&lt;h4&gt;目的&lt;/h4&gt;开发能够泛化到自然图像和新型物体类别的3D人-物交互恢复方法。&lt;h4&gt;方法&lt;/h4&gt;（1）收集了PICO-db数据集，其中包含与密集3D接触唯一匹配的自然图像；（2）使用PICO-fit方法，通过渲染和比较拟合来恢复交互中的3D身体和物体网格。&lt;h4&gt;主要发现&lt;/h4&gt;PICO-fit方法能够处理许多现有方法无法处理的物体类别，对于在野外扩展人-物交互理解至关重要。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和数据集为从单色图像中恢复3D人-物交互提供了新的可能性，并促进了该领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从单色图像中恢复3D人-物交互（HOI）是一项挑战，因为深度模糊、遮挡和物体形状和外观的巨大变化。因此，过去的工作需要在已知物体形状和接触的受控环境中进行，并且只处理有限的物体类别。相反，我们需要泛化到自然图像和新型物体类别的方 法。我们以两种主要方式解决这个问题：（1）我们收集了PICO-db，这是一个新的数据集，其中包含与身体和物体网格上的密集3D接触唯一匹配的自然图像。为此，我们使用了与接触匹配的DAMON数据集中的图像，但这些接触仅在标准3D身体上进行了标注。相比之下，我们寻求在身体和物体上的接触标签。为了从图像中推断这些标签，我们通过利用视觉基础模型从数据库中检索适当的3D物体网格。然后，我们通过一种新的方法将DAMON的身体接触块投影到物体上，每个块只需要2次点击。这种最小的人为输入在身体和物体之间建立了丰富的接触对应关系。（2）我们利用我们新的接触对应关系数据集，通过一种称为PICO-fit的新渲染和比较拟合方法，来恢复交互中的3D身体和物体网格。PICO-fit推断SMPL-X身体的接触，从PICO-db检索该物体的可能3D物体网格和接触，并使用接触通过优化迭代地拟合3D身体和物体网格到图像证据。独特的是，PICO-fit对于许多现有方法无法处理的物体类别都表现良好。这对于在野外扩展HOI理解至关重要。我们的数据和代码可在https://pico.is.tue.mpg.de获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recovering 3D Human-Object Interaction (HOI) from single color images ischallenging due to depth ambiguities, occlusions, and the huge variation inobject shape and appearance. Thus, past work requires controlled settings suchas known object shapes and contacts, and tackles only limited object classes.Instead, we need methods that generalize to natural images and novel objectclasses. We tackle this in two main ways: (1) We collect PICO-db, a new datasetof natural images uniquely paired with dense 3D contact on both body and objectmeshes. To this end, we use images from the recent DAMON dataset that arepaired with contacts, but these contacts are only annotated on a canonical 3Dbody. In contrast, we seek contact labels on both the body and the object. Toinfer these given an image, we retrieve an appropriate 3D object mesh from adatabase by leveraging vision foundation models. Then, we project DAMON's bodycontact patches onto the object via a novel method needing only 2 clicks perpatch. This minimal human input establishes rich contact correspondencesbetween bodies and objects. (2) We exploit our new dataset of contactcorrespondences in a novel render-and-compare fitting method, called PICO-fit,to recover 3D body and object meshes in interaction. PICO-fit infers contactfor the SMPL-X body, retrieves a likely 3D object mesh and contact from PICO-dbfor that object, and uses the contact to iteratively fit the 3D body and objectmeshes to image evidence via optimization. Uniquely, PICO-fit works well formany object categories that no existing method can tackle. This is crucial toenable HOI understanding to scale in the wild. Our data and code are availableat https://pico.is.tue.mpg.de.</description>
      <author>example@mail.com (Alpár Cseke, Shashank Tripathi, Sai Kumar Dwivedi, Arjun Lakshmipathy, Agniv Chatterjee, Michael J. Black, Dimitrios Tzionas)</author>
      <guid isPermaLink="false">2504.17695v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2504.17264v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in International Joint Conference on Neural Networks (IJCNN)  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为JurisCTC的新模型，用于提高法律判决预测（LJP）任务的准确性，并在不同法律领域之间实现有效的知识迁移。&lt;h4&gt;背景&lt;/h4&gt;近年来，无监督领域自适应（UDA）在自然语言处理（NLP）领域受到关注，因为它能够增强模型在不同领域间的泛化能力。然而，其在不同法律领域间知识迁移的应用仍鲜有探索。&lt;h4&gt;目的&lt;/h4&gt;为了解决长篇复杂法律文本和大规模标注数据集有限可用的问题，提出JurisCTC模型。&lt;h4&gt;方法&lt;/h4&gt;JurisCTC通过对比学习区分不同领域的样本，实现民事法和刑法领域之间的知识迁移，以提高LJP任务的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法和特定的大型语言模型（LLMs）相比，JurisCTC在LJP任务上取得了显著的进展，分别达到了76.59%和78.83%的峰值准确率。&lt;h4&gt;结论&lt;/h4&gt;JurisCTC模型在法律判决预测任务中表现出色，为不同法律领域间的知识迁移提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Unsupervised Domain Adaptation (UDA) has gained significantattention in the field of Natural Language Processing (NLP) owing to itsability to enhance model generalization across diverse domains. However, itsapplication for knowledge transfer between distinct legal domains remainslargely unexplored. To address the challenges posed by lengthy and complexlegal texts and the limited availability of large-scale annotated datasets, wepropose JurisCTC, a novel model designed to improve the accuracy of LegalJudgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTCfacilitates effective knowledge transfer across various legal domains andemploys contrastive learning to distinguish samples from different domains.Specifically, for the LJP task, we enable knowledge transfer between civil andcriminal law domains. Compared to other models and specific large languagemodels (LLMs), JurisCTC demonstrates notable advancements, achieving peakaccuracies of 76.59% and 78.83%, respectively.</description>
      <author>example@mail.com (Zhaolu Kang, Hongtian Cai, Xiangyang Ji, Jinzhe Li, Nanfei Gu)</author>
      <guid isPermaLink="false">2504.17264v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Prototype-enhanced prediction in graph neural networks for climate applications</title>
      <link>http://arxiv.org/abs/2504.17492v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过使用原型来提高数据驱动模拟器输出质量的方法，并展示了其在模拟大气扩散（对温室气体排放监测至关重要）中的应用。&lt;h4&gt;背景&lt;/h4&gt;数据驱动模拟器被广泛应用于学习并模拟基于物理的模拟，以减少计算成本和运行时间。&lt;h4&gt;目的&lt;/h4&gt;目的是通过使用原型来提高高维模拟输出的质量。&lt;h4&gt;方法&lt;/h4&gt;方法包括使用原型的近似输出作为输入，以改进模型并提高预测的准确性。此外，通过比较使用原型作为额外输入训练的模型与基线模型，来演示该方法在模拟大气扩散中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;原型模型即使在原型数量较少甚至随机选择的情况下，也实现了更好的性能。通过数据驱动方法（如k-means）选择原型，可以在某些指标上提高近10%的性能。&lt;h4&gt;结论&lt;/h4&gt;选择原型通过数据驱动方法可以提高模拟器的性能，特别是在关键的应用如大气扩散模拟中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-driven emulators are increasingly being used to learn and emulatephysics-based simulations, reducing computational expense and run time. Here,we present a structured way to improve the quality of these high-dimensionalemulated outputs, through the use of prototypes: an approximation of theemulator's output passed as an input, which informs the model and leads tobetter predictions. We demonstrate our approach to emulate atmosphericdispersion, key for greenhouse gas emissions monitoring, by comparing abaseline model to models trained using prototypes as an additional input. Theprototype models achieve better performance, even with few prototypes and evenif they are chosen at random, but we show that choosing the prototypes throughdata-driven methods (k-means) can lead to almost 10\% increased performance insome metrics.</description>
      <author>example@mail.com (Nawid Keshtmand, Elena Fillola, Jeffrey Nicholas Clark, Raul Santos-Rodriguez, Matthew Rigby)</author>
      <guid isPermaLink="false">2504.17492v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Effortless, Simulation-Efficient Bayesian Inference using Tabular Foundation Models</title>
      <link>http://arxiv.org/abs/2504.17660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于模拟的推理（SBI）方法，利用预训练的表格基础模型TabPFN，实现了高效的贝叶斯推理，并在模拟效率上优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;SBI是一种灵活的贝叶斯推理方法，通过训练神经网络在模拟数据上进行快速后验分布推断。&lt;h4&gt;目的&lt;/h4&gt;减少SBI所需的模拟次数，特别是在昂贵模拟器的情况下。&lt;h4&gt;方法&lt;/h4&gt;使用TabPFN作为预训练的自回归条件密度估计器，提出了一种名为NPE-PF的神经网络后验估计方法，无需选择、训练和调整推理网络。&lt;h4&gt;主要发现&lt;/h4&gt;NPE-PF在基准任务和两个复杂的科学逆问题中，在准确性方面与现有SBI方法相当，但在模拟效率方面显著优于它们，有时需要的模拟次数少几个数量级。&lt;h4&gt;结论&lt;/h4&gt;NPE-PF为SBI提供了新的方向，提供了无训练、通用的推理模型，为广泛的随机逆问题提供了高效、易于使用和灵活的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Simulation-based inference (SBI) offers a flexible and general approach to performing Bayesian inference: In SBI, a neural network is trained on synthetic data simulated from a model and used to rapidly infer posterior distributions for observed data. A key goal for SBI is to achieve accurate inference with as few simulations as possible, especially for expensive simulators. In this work, we address this challenge by repurposing recent probabilistic foundation models for tabular data: We show how tabular foundation models -- specifically TabPFN-- can be used as pre-trained autoregressive conditional density estimators for SBI. We propose Neural Posterior Estimation with Prior-data Fitted Networks (NPE-PF) and show that it is competitive with current SBI approaches in terms of accuracy for both benchmark tasks and two complex scientific inverse problems. Crucially, it often substantially outperforms them in terms of simulation efficiency, sometimes requiring orders of magnitude fewer simulations. NPE-PF eliminates the need for inference network selection, training, and hyperparameter tuning. We also show that it exhibits superior robustness to model misspecification and can be scaled to simulation budgets that exceed the context size limit of TabPFN. NPE-PF provides a new direction for SBI, where training-free, general-purpose inference models offer efficient, easy-to-use, and flexible solutions for a wide range of stochastic inverse problems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation-based inference (SBI) offers a flexible and general approach toperforming Bayesian inference: In SBI, a neural network is trained on syntheticdata simulated from a model and used to rapidly infer posterior distributionsfor observed data. A key goal for SBI is to achieve accurate inference with asfew simulations as possible, especially for expensive simulators. In this work,we address this challenge by repurposing recent probabilistic foundation modelsfor tabular data: We show how tabular foundation models -- specifically TabPFN-- can be used as pre-trained autoregressive conditional density estimators forSBI. We propose Neural Posterior Estimation with Prior-data Fitted Networks(NPE-PF) and show that it is competitive with current SBI approaches in termsof accuracy for both benchmark tasks and two complex scientific inverseproblems. Crucially, it often substantially outperforms them in terms ofsimulation efficiency, sometimes requiring orders of magnitude fewersimulations. NPE-PF eliminates the need for inference network selection,training, and hyperparameter tuning. We also show that it exhibits superiorrobustness to model misspecification and can be scaled to simulation budgetsthat exceed the context size limit of TabPFN. NPE-PF provides a new directionfor SBI, where training-free, general-purpose inference models offer efficient,easy-to-use, and flexible solutions for a wide range of stochastic inverseproblems.</description>
      <author>example@mail.com (Julius Vetter, Manuel Gloeckler, Daniel Gedon, Jakob H. Macke)</author>
      <guid isPermaLink="false">2504.17660v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>UNILoc: Unified Localization Combining Model-Based Geometry and Unsupervised Learning</title>
      <link>http://arxiv.org/abs/2504.17676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, submitted to IEEE conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的定位方法，该方法结合了基于模型和机器学习的方法，通过利用可用的地图信息来发挥各自的优势。&lt;h4&gt;背景&lt;/h4&gt;准确的移动设备定位对于5G/6G应用，如自动驾驶和增强现实至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够提高定位精度的方法，同时避免监督学习的需求。&lt;h4&gt;方法&lt;/h4&gt;该方法通过最优传输（OT）自动生成训练标签，结合几何估计和建筑布局。还进行了基于光线追踪的模拟来验证方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在视线（LoS）用户和非视线（NLoS）用户中显著提高了定位精度，并且与完全监督的指纹识别相比，能够实现有竞争力的整体性能，同时消除了繁琐的标签数据测量和收集的需求。&lt;h4&gt;结论&lt;/h4&gt;所提出的统一方法在保持高性能的同时，简化了数据收集过程，为5G/6G应用中的定位问题提供了一种有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate mobile device localization is critical for emerging 5G/6Gapplications such as autonomous vehicles and augmented reality. In this paper,we propose a unified localization method that integrates model-based andmachine learning (ML)-based methods to reap their respective advantages byexploiting available map information. In order to avoid supervised learning, wegenerate training labels automatically via optimal transport (OT) by fusinggeometric estimates with building layouts. Ray-tracing based simulations arecarried out to demonstrate that the proposed method significantly improvespositioning accuracy for both line-of-sight (LoS) users (compared to ML-basedmethods) and non-line-of-sight (NLoS) users (compared to model-based methods).Remarkably, the unified method is able to achieve competitive overallperformance with the fully-supervised fingerprinting, while eliminating theneed for cumbersome labeled data measurement and collection.</description>
      <author>example@mail.com (Yuhao Zhang, Guangjin Pan, Musa Furkan Keskin, Ossi Kaltiokallio, Mikko Valkama, Henk Wymeersch)</author>
      <guid isPermaLink="false">2504.17676v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Range Image-Based Implicit Neural Compression for LiDAR Point Clouds</title>
      <link>http://arxiv.org/abs/2504.17229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的高效压缩激光雷达点云的方案，使得高精度的3D场景归档成为可能，这些归档有助于深入理解相应的3D场景。&lt;h4&gt;背景&lt;/h4&gt;研究基于2D距离图像（RIs）作为表示3D激光雷达观测的轻量级格式。尽管传统的图像压缩技术可以适应以提高RIs的压缩效率，但由于自然图像和RIs在位精度和像素值分布特性上的差异，其实际性能预计会有限。&lt;h4&gt;目的&lt;/h4&gt;提出了一种基于隐式神经网络表示（INR）的RI压缩方法，以有效处理浮点值像素。&lt;h4&gt;方法&lt;/h4&gt;该方法将RIs分为深度图像和掩码图像，并分别使用带有模型剪枝和量化的块状和像素级INR架构进行压缩。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI数据集上的实验表明，该方法在低比特率和解码延迟方面优于现有的图像、点云、RI和基于INR的压缩方法，在3D重建和检测质量方面表现更优。&lt;h4&gt;结论&lt;/h4&gt;提出的基于INR的RI压缩方法在保持高压缩效率的同时，显著提升了3D场景的重建和检测质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel scheme to efficiently compress Light Detectionand Ranging~(LiDAR) point clouds, enabling high-precision 3D scene archives,and such archives pave the way for a detailed understanding of thecorresponding 3D scenes. We focus on 2D range images~(RIs) as a lightweightformat for representing 3D LiDAR observations. Although conventional imagecompression techniques can be adapted to improve compression efficiency forRIs, their practical performance is expected to be limited due to differencesin bit precision and the distinct pixel value distribution characteristicsbetween natural images and RIs. We propose a novel implicit neuralrepresentation~(INR)--based RI compression method that effectively handlesfloating-point valued pixels. The proposed method divides RIs into depth andmask images and compresses them using patch-wise and pixel-wise INRarchitectures with model pruning and quantization, respectively. Experiments onthe KITTI dataset show that the proposed method outperforms existing image,point cloud, RI, and INR-based compression methods in terms of 3Dreconstruction and detection quality at low bitrates and decoding latency.</description>
      <author>example@mail.com (Akihiro Kuwabara, Sorachi Kato, Takuya Fujihashi, Toshiaki Koike-Akino, Takashi Watanabe)</author>
      <guid isPermaLink="false">2504.17229v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Quadratic Interest Network for Multimodal Click-Through Rate Prediction</title>
      <link>http://arxiv.org/abs/2504.17699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QIN的模型，用于多模态点击率预测，通过自适应稀疏目标注意力机制提取多模态用户行为特征，并利用二次神经网络捕获高阶特征交互，在竞赛中取得了优异成绩。&lt;h4&gt;背景&lt;/h4&gt;多模态点击率预测是工业推荐系统中的关键技术，它利用文本、图像和行为日志等异构模态信息来捕捉用户与物品之间的高阶特征交互，以增强系统对用户兴趣的理解和预测点击行为的能力。&lt;h4&gt;目的&lt;/h4&gt;为了推动这一领域的发展，WWW 2025 EReL@MIR Workshop提出了两个任务：多模态物品嵌入和多模态点击率预测，旨在探索如何有效地利用多种模态的丰富语义信息，同时满足在线推理的低延迟要求。&lt;h4&gt;方法&lt;/h4&gt;本文提出的QIN模型采用自适应稀疏目标注意力机制提取多模态用户行为特征，并利用二次神经网络来捕获高阶特征交互。&lt;h4&gt;主要发现&lt;/h4&gt;QIN模型在竞赛中取得了AUC 0.9798的好成绩，排名第二。&lt;h4&gt;结论&lt;/h4&gt;QIN模型能够有效地利用多模态信息进行点击率预测，为推荐系统提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态点击率（CTR）预测是工业推荐系统中的关键技术。它利用文本、图像和行为日志等异构模态来捕捉用户与物品之间的高阶特征交互，从而增强系统对用户兴趣的理解及其预测点击行为的能力。该领域的挑战在于如何有效地利用多种模态的丰富语义信息，同时满足实际应用中在线推理的低延迟需求。为了推动这一领域的发展，WWW 2025 EReL@MIR Workshop的Multimodal CTR Prediction Challenge Track将其问题定义为两个任务：（1）多模态物品嵌入任务1：该任务旨在探索多模态信息提取和物品表示学习方法，以增强推荐任务；（2）多模态点击率预测任务2：该任务旨在探索哪种多模态推荐模型能够有效地利用多模态嵌入特征并实现更好的性能。在本文中，我们提出了一个名为QIN的新模型，用于任务2的多模态点击率预测。具体来说，QIN采用自适应稀疏目标注意力机制来提取多模态用户行为特征，并利用二次神经网络来捕获高阶特征交互。因此，QIN在排行榜上取得了AUC 0.9798的成绩，并在比赛中排名第二。模型代码、训练日志、超参数配置和检查点可在https://github.com/salmon1802/QIN找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal click-through rate (CTR) prediction is a key technique inindustrial recommender systems. It leverages heterogeneous modalities such astext, images, and behavioral logs to capture high-order feature interactionsbetween users and items, thereby enhancing the system's understanding of userinterests and its ability to predict click behavior. The primary challenge inthis field lies in effectively utilizing the rich semantic information frommultiple modalities while satisfying the low-latency requirements of onlineinference in real-world applications. To foster progress in this area, theMultimodal CTR Prediction Challenge Track of the WWW 2025 EReL@MIR Workshopformulates the problem into two tasks: (1) Task 1 of Multimodal Item Embedding:this task aims to explore multimodal information extraction and itemrepresentation learning methods that enhance recommendation tasks; and (2) Task2 of Multimodal CTR Prediction: this task aims to explore what multimodalrecommendation model can effectively leverage multimodal embedding features andachieve better performance. In this paper, we propose a novel model for Task 2,named Quadratic Interest Network (QIN) for Multimodal CTR Prediction.Specifically, QIN employs adaptive sparse target attention to extractmultimodal user behavior features, and leverages Quadratic Neural Networks tocapture high-order feature interactions. As a result, QIN achieved an AUC of0.9798 on the leaderboard and ranked second in the competition. The model code,training logs, hyperparameter configurations, and checkpoints are available athttps://github.com/salmon1802/QIN.</description>
      <author>example@mail.com (Honghao Li, Hanwei Li, Jing Zhang, Yi Zhang, Ziniu Yu, Lei Sang, Yiwen Zhang)</author>
      <guid isPermaLink="false">2504.17699v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>A Guide to Structureless Visual Localization</title>
      <link>http://arxiv.org/abs/2504.17636v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了无结构视觉定位方法，与基于结构的视觉定位方法相比，无结构方法在场景变化后更新3D模型更加灵活。&lt;h4&gt;背景&lt;/h4&gt;视觉定位算法是自动驾驶汽车和增强/混合现实系统等应用的核心组件。&lt;h4&gt;目的&lt;/h4&gt;提供对无结构方法的首次全面讨论和比较。&lt;h4&gt;方法&lt;/h4&gt;通过实验比较了不同方法在姿态估计方面的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;使用更高程度的经典几何推理的方法通常能实现更高的姿态估计精度。&lt;h4&gt;结论&lt;/h4&gt;无结构方法在灵活性方面具有优势，但以略微降低的姿态估计精度为代价。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉定位算法，即估计查询图像在已知场景中相机位姿的方法，是许多应用的核心组件，包括自动驾驶汽车和增强/混合现实系统。最先进的视觉定位算法是基于结构的，即它们存储场景的3D模型，并使用查询图像与模型中3D点之间的2D-3D对应关系进行相机位姿估计。虽然这种方法非常准确，但在场景变化后调整底层3D模型时也相当不灵活。无结构定位方法将场景表示为已知姿态的图像数据库，从而提供了一种更加灵活的表示，可以通过添加或删除图像轻松更新。尽管关于基于结构的方法有大量的文献，但关于无结构方法的工作却相对较少。因此，本文致力于提供我们所知的关于无结构方法的首次全面讨论和比较。广泛的实验表明，使用更高程度的经典几何推理的方法通常能实现更高的姿态估计精度。特别是，基于经典绝对或半广义相对姿态估计的方法在精度上远远超过了基于姿态回归的非常最近的方法。与最先进的基于结构的方法相比，无结构方法的灵活性是以（略微）降低的姿态估计精度为代价的，这表明了未来工作的一个有趣方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization algorithms, i.e., methods that estimate the camera poseof a query image in a known scene, are core components of many applications,including self-driving cars and augmented / mixed reality systems.State-of-the-art visual localization algorithms are structure-based, i.e., theystore a 3D model of the scene and use 2D-3D correspondences between the queryimage and 3D points in the model for camera pose estimation. While suchapproaches are highly accurate, they are also rather inflexible when it comesto adjusting the underlying 3D model after changes in the scene. Structurelesslocalization approaches represent the scene as a database of images with knownposes and thus offer a much more flexible representation that can be easilyupdated by adding or removing images. Although there is a large amount ofliterature on structure-based approaches, there is significantly less work onstructureless methods. Hence, this paper is dedicated to providing the, to thebest of our knowledge, first comprehensive discussion and comparison ofstructureless methods. Extensive experiments show that approaches that use ahigher degree of classical geometric reasoning generally achieve higher poseaccuracy. In particular, approaches based on classical absolute orsemi-generalized relative pose estimation outperform very recent methods basedon pose regression by a wide margin. Compared with state-of-the-artstructure-based approaches, the flexibility of structureless methods comes atthe cost of (slightly) lower pose accuracy, indicating an interesting directionfor future work.</description>
      <author>example@mail.com (Vojtech Panek, Qunjie Zhou, Yaqing Ding, Sérgio Agostinho, Zuzana Kukelova, Torsten Sattler, Laura Leal-Taixé)</author>
      <guid isPermaLink="false">2504.17636v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation</title>
      <link>http://arxiv.org/abs/2504.17365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TimeSoccer的端到端足球多模态大型语言模型（MLLM），用于对全场比赛视频进行单主播密集视频字幕生成（SDVC）。该模型通过引入MoFA-Select模块，实现了对足球比赛的长期视频理解，并在SDVC任务上达到了最先进（SoTA）的性能。&lt;h4&gt;背景&lt;/h4&gt;足球是一项全球流行的体育赛事，通常具有漫长的比赛时间和独特的精彩瞬间。现有的足球MLLM在字幕生成时通常依赖于时间先验，无法端到端处理足球视频。&lt;h4&gt;目的&lt;/h4&gt;解决现有足球MLLM在时间定位和语义描述方面的不足，实现端到端对全场比赛视频的理解。&lt;h4&gt;方法&lt;/h4&gt;TimeSoccer模型通过一次性预测时间戳并生成字幕，实现全局上下文建模。MoFA-Select模块通过自底向上的策略自适应选择代表性帧，并采用补充训练范式加强模型处理长时间序列的能力。&lt;h4&gt;主要发现&lt;/h4&gt;TimeSoccer在SDVC任务上实现了最先进的性能，能够生成高质量的字幕，具有准确的时间对齐和强语义相关性。&lt;h4&gt;结论&lt;/h4&gt;TimeSoccer模型为足球比赛的长期视频理解提供了有效的解决方案，并在SDVC任务上取得了显著成果。&lt;h4&gt;翻译&lt;/h4&gt;Soccer is a globally popular sporting event, typically characterized by longmatches and distinctive highlight moments. Recent advances in Multimodal LargeLanguage Models (MLLMs) offer promising capabilities in temporal grounding andvideo understanding, soccer commentary generation often requires precisetemporal localization and semantically rich descriptions over long-form video.However, existing soccer MLLMs often rely on the temporal a priori for captiongeneration, so they cannot process the soccer video end-to-end. While sometraditional approaches follow a two-step paradigm that is complex and fails tocapture the global context to achieve suboptimal performance. To solve theabove issues, we present TimeSoccer, the first end-to-end soccer MLLM forSingle-anchor Dense Video Captioning (SDVC) in full-match soccer videos.TimeSoccer jointly predicts timestamps and generates captions in a single pass,enabling global context modeling across 45-minute matches. To support longvideo understanding of soccer matches, we introduce MoFA-Select, atraining-free, motion-aware frame compression module that adaptively selectsrepresentative frames via a coarse-to-fine strategy, and incorporatescomplementary training paradigms to strengthen the model's ability to handlelong temporal sequences. Extensive experiments demonstrate that our TimeSoccerachieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-endform, generating high-quality commentary with accurate temporal alignment andstrong semantic relevance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soccer is a globally popular sporting event, typically characterized by longmatches and distinctive highlight moments. Recent advances in Multimodal LargeLanguage Models (MLLMs) offer promising capabilities in temporal grounding andvideo understanding, soccer commentary generation often requires precisetemporal localization and semantically rich descriptions over long-form video.However, existing soccer MLLMs often rely on the temporal a priori for captiongeneration, so they cannot process the soccer video end-to-end. While sometraditional approaches follow a two-step paradigm that is complex and fails tocapture the global context to achieve suboptimal performance. To solve theabove issues, we present TimeSoccer, the first end-to-end soccer MLLM forSingle-anchor Dense Video Captioning (SDVC) in full-match soccer videos.TimeSoccer jointly predicts timestamps and generates captions in a single pass,enabling global context modeling across 45-minute matches. To support longvideo understanding of soccer matches, we introduce MoFA-Select, atraining-free, motion-aware frame compression module that adaptively selectsrepresentative frames via a coarse-to-fine strategy, and incorporatescomplementary training paradigms to strengthen the model's ability to handlelong temporal sequences. Extensive experiments demonstrate that our TimeSoccerachieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-endform, generating high-quality commentary with accurate temporal alignment andstrong semantic relevance.</description>
      <author>example@mail.com (Ling You, Wenxuan Huang, Xinni Xie, Xiangyi Wei, Bangyan Li, Shaohui Lin, Yang Li, Changbo Wang)</author>
      <guid isPermaLink="false">2504.17365v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>PhysioSync: Temporal and Cross-Modal Contrastive Learning Inspired by Physiological Synchronization for EEG-Based Emotion Recognition</title>
      <link>http://arxiv.org/abs/2504.17163v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The source code will be publicly available at  https://github.com/MSA-LMC/PhysioSync&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhysioSync是一种新的预训练框架，利用时间和跨模态对比学习，以解决EEG信号在情感识别中的噪声和个体差异问题，并通过融合跨分辨率和跨模态特征来提高识别效果。&lt;h4&gt;背景&lt;/h4&gt;EEG信号提供关于情绪状态的脑活动信息，但通常受噪声和个体差异影响，导致情感识别复杂。多模态方法虽然使用PPS如GSR，但常忽视模态间的动态同步和语义一致性。&lt;h4&gt;目的&lt;/h4&gt;提出PhysioSync框架以解决EEG信号在情感识别中的挑战，包括噪声、个体差异、模态间动态同步和语义一致性以及情绪波动的时间动态问题。&lt;h4&gt;方法&lt;/h4&gt;PhysioSync利用时间对比学习和跨模态对比学习，结合交叉模态一致性对齐（CM-CA）和长短期时间对比学习（LS-TCL），以建模EEG和PPS之间的动态关系，并捕捉不同时间分辨率内的情绪同步。&lt;h4&gt;主要发现&lt;/h4&gt;PhysioSync在DEAP和DREAMER数据集上的实验表明，在单模态和跨模态条件下，其性能优于其他方法，证明了其在EEG中心情感识别中的有效性。&lt;h4&gt;结论&lt;/h4&gt;PhysioSync框架通过有效的预训练和特征融合方法，显著提高了EEG中心情感识别的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：脑电图（EEG）信号提供了关于情绪状态相关脑活动的有希望的无意识反映，相较于面部表情等行为线索具有显著优势。然而，EEG信号经常受到噪声和伪影的影响，并且因个体差异而变化，这使得情感识别变得复杂。虽然多模态方法使用了如皮肤电（GSR）等外周生理信号（PPS）来补充EEG，但它们往往忽视了模态间的动态同步和一致性语义。此外，PPS中情绪波动在不同时间分辨率上的时间动态仍被低估。为了解决这些挑战，我们提出了一种名为PhysioSync的新颖的预训练框架，该框架利用时间和跨模态对比学习，灵感来源于生理同步现象。PhysioSync结合了交叉模态一致性对齐（CM-CA）来建模EEG和补充PPS之间的动态关系，使跨模态的情绪同步成为可能。此外，它引入了长短期时间对比学习（LS-TCL）来捕捉模态内部不同时间分辨率上的情绪同步。预训练后，跨分辨率和跨模态特征被分层融合并微调以提高情感识别。在DEAP和DREAMER数据集上的实验证明了PhysioSync在单模态和跨模态条件下的先进性能，突出了其在EEG中心情感识别中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electroencephalography (EEG) signals provide a promising and involuntaryreflection of brain activity related to emotional states, offering significantadvantages over behavioral cues like facial expressions. However, EEG signalsare often noisy, affected by artifacts, and vary across individuals,complicating emotion recognition. While multimodal approaches have usedPeripheral Physiological Signals (PPS) like GSR to complement EEG, they oftenoverlook the dynamic synchronization and consistent semantics between themodalities. Additionally, the temporal dynamics of emotional fluctuationsacross different time resolutions in PPS remain underexplored. To address thesechallenges, we propose PhysioSync, a novel pre-training framework leveragingtemporal and cross-modal contrastive learning, inspired by physiologicalsynchronization phenomena. PhysioSync incorporates Cross-Modal ConsistencyAlignment (CM-CA) to model dynamic relationships between EEG and complementaryPPS, enabling emotion-related synchronizations across modalities. Besides, itintroduces Long- and Short-Term Temporal Contrastive Learning (LS-TCL) tocapture emotional synchronization at different temporal resolutions withinmodalities. After pre-training, cross-resolution and cross-modal features arehierarchically fused and fine-tuned to enhance emotion recognition. Experimentson DEAP and DREAMER datasets demonstrate PhysioSync's advanced performanceunder uni-modal and cross-modal conditions, highlighting its effectiveness forEEG-centered emotion recognition.</description>
      <author>example@mail.com (Kai Cui, Jia Li, Yu Liu, Xuesong Zhang, Zhenzhen Hu, Meng Wang)</author>
      <guid isPermaLink="false">2504.17163v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>HeRB: Heterophily-Resolved Structure Balancer for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.17276v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了图神经网络（GNNs）在图数据表示领域的显著进步，并提出了一种名为HeRB的方法来解决GNNs中结构不平衡的问题。&lt;h4&gt;背景&lt;/h4&gt;GNNs在处理图数据时遇到了结构不平衡的挑战，先前的方法没有考虑图异质性的影响，导致效果不足。&lt;h4&gt;目的&lt;/h4&gt;提出HeRB方法，首先解决图异质性问题，然后转移同质性知识，以提升GNNs的性能。&lt;h4&gt;方法&lt;/h4&gt;HeRB方法包括两个创新组件：1) 一个减少跨类边并增加同类边的无异质性增强模块；2) 一个将同质性信息从头部节点传递到尾部节点的同质性知识转移机制。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，HeRB在两个同质性和六个异质性基准数据集上实现了优异的性能，消融研究进一步验证了两个提出的组件的有效性。&lt;h4&gt;结论&lt;/h4&gt;HeRB方法有效提升了GNNs在处理图数据时的性能，特别是在解决结构不平衡问题上表现突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research has witnessed the remarkable progress of Graph NeuralNetworks (GNNs) in the realm of graph data representation. However, GNNs stillencounter the challenge of structural imbalance. Prior solutions to thisproblem did not take graph heterophily into account, namely that connectednodes process distinct labels or features, thus resulting in a deficiency ineffectiveness. Upon verifying the impact of heterophily on solving thestructural imbalance problem, we propose to rectify the heterophily first andthen transfer homophilic knowledge. To the end, we devise a method named HeRB(Heterophily-Resolved Structure Balancer) for GNNs. HeRB consists of twoinnovative components: 1) A heterophily-lessening augmentation module whichserves to reduce inter-class edges and increase intra-class edges; 2) Ahomophilic knowledge transfer mechanism to convey homophilic information fromhead nodes to tail nodes. Experimental results demonstrate that HeRB achievessuperior performance on two homophilic and six heterophilic benchmark datasets,and the ablation studies further validate the efficacy of two proposedcomponents.</description>
      <author>example@mail.com (Ke-Jia Chen, Wenhui Mu, Zheng Liu)</author>
      <guid isPermaLink="false">2504.17276v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>TimeChat-Online: 80% Visual Tokens are Naturally Redundant in Streaming Videos</title>
      <link>http://arxiv.org/abs/2504.17343v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为TimeChat-Online的新型在线视频语言模型，它通过创新的Differential Token Drop（DTD）模块解决了在线视频理解中的视觉冗余问题，实现了实时视频交互。&lt;h4&gt;背景&lt;/h4&gt;随着在线视频平台的快速发展，尤其是直播服务，对实时视频理解系统的需求变得迫切。现有的视频大语言模型在处理完整视频方面表现出色，但在流媒体场景中存在处理密集、冗余帧的局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效处理连续视频流并即时响应用户查询的实时视频理解系统。&lt;h4&gt;方法&lt;/h4&gt;提出了TimeChat-Online，其核心是DTD模块，该模块通过模仿人类的视觉感知中的变化盲现象，在流媒体视频中保留有意义的时序变化，同时过滤掉帧之间的静态、冗余内容。&lt;h4&gt;主要发现&lt;/h4&gt;DTD模块实现了视频token数量的82.8%减少，同时在StreamingBench上的性能保持98%，表明超过80%的流媒体视频中的视觉内容是自然冗余的，不需要语言指导。TimeChat-Online还具备独特的主动响应能力，通过DTD模块连续监控视频场景转换。&lt;h4&gt;结论&lt;/h4&gt;TimeChat-Online在流媒体基准测试（StreamingBench和OvOBench）中表现出色，在长视频任务（如Video-MME和MLVU）上也能保持有竞争力的结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着在线视频平台的快速增长，尤其是直播服务，对实时视频理解系统的需求变得迫切。这些系统必须处理连续的视频流并即时响应用户查询，这对当前的视频大语言模型（VideoLLMs）提出了独特的挑战。尽管现有的VideoLLMs在处理完整视频方面表现出色，但由于无法有效地处理密集、冗余的帧，它们在流媒体场景中存在显著的局限性。我们介绍了TimeChat-Online，这是一种新的在线VideoLLM，它革命性地改变了实时视频交互。其核心是我们的创新Differential Token Drop（DTD）模块，它解决了流媒体视频中视觉冗余的根本挑战。我们从人类视觉感知中的变化盲现象中汲取灵感，DTD在保留有意义的时序变化的同时，过滤掉帧之间的静态、冗余内容。令人惊讶的是，我们的实验表明DTD实现了视频token数量的82.8%减少，同时在StreamingBench上的性能保持98%，这表明超过80%的流媒体视频中的视觉内容是自然冗余的，不需要语言指导。为了实现无缝的实时交互，我们提出了TimeChat-Online-139K，这是一个综合的流媒体视频数据集，包括多种交互模式，如回溯、当前感知和未来响应场景。TimeChat-Online独特的主动响应能力，通过DTD模块自然地连续监控视频场景转换，使其区别于传统方法。我们广泛的评估表明TimeChat-Online在流媒体基准测试（StreamingBench和OvOBench）中表现出色，在长视频任务（如Video-MME和MLVU）上也能保持有竞争力的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of online video platforms, particularly live streamingservices, has created an urgent need for real-time video understanding systems.These systems must process continuous video streams and respond to user queriesinstantaneously, presenting unique challenges for current Video Large LanguageModels (VideoLLMs). While existing VideoLLMs excel at processing completevideos, they face significant limitations in streaming scenarios due to theirinability to handle dense, redundant frames efficiently. We introduceTimeChat-Online, a novel online VideoLLM that revolutionizes real-time videointeraction. At its core lies our innovative Differential Token Drop (DTD)module, which addresses the fundamental challenge of visual redundancy instreaming videos. Drawing inspiration from human visual perception's ChangeBlindness phenomenon, DTD preserves meaningful temporal changes while filteringout static, redundant content between frames. Remarkably, our experimentsdemonstrate that DTD achieves an 82.8% reduction in video tokens whilemaintaining 98% performance on StreamingBench, revealing that over 80% ofvisual content in streaming videos is naturally redundant without requiringlanguage guidance. To enable seamless real-time interaction, we presentTimeChat-Online-139K, a comprehensive streaming video dataset featuring diverseinteraction patterns including backward-tracing, current-perception, andfuture-responding scenarios. TimeChat-Online's unique Proactive Responsecapability, naturally achieved through continuous monitoring of video scenetransitions via DTD, sets it apart from conventional approaches. Our extensiveevaluation demonstrates TimeChat-Online's superior performance on streamingbenchmarks (StreamingBench and OvOBench) and maintaining competitive results onlong-form video tasks such as Video-MME and MLVU.</description>
      <author>example@mail.com (Linli Yao, Yicheng Li, Yuancheng Wei, Lei Li, Shuhuai Ren, Yuanxin Liu, Kun Ouyang, Lean Wang, Shicheng Li, Sida Li, Lingpeng Kong, Qi Liu, Yuanxing Zhang, Xu Sun)</author>
      <guid isPermaLink="false">2504.17343v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2504.17432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures, Project page: https://garygutc.github.io/UniME&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;UniME是一种新型的两阶段框架，利用多模态大型语言模型（MLLMs）来学习各种下游任务的判别性表示。&lt;h4&gt;背景&lt;/h4&gt;CLIP框架在多模态表示学习中广泛使用，但存在文本标记截断、图像-文本编码孤立以及由于词袋行为导致的组合性不足等关键限制。&lt;h4&gt;目的&lt;/h4&gt;提出UniME框架，以克服CLIP框架的局限性，并通过MLLMs学习可迁移的多模态表示。&lt;h4&gt;方法&lt;/h4&gt;第一阶段，从基于强大LLM的教师模型进行文本判别性知识蒸馏，以增强MLLM语言组件的嵌入能力；第二阶段，引入增强的硬负样本指令微调，以进一步推进判别性表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;UniME在MMEB基准和多个检索任务上进行了广泛实验，包括短和长标题检索以及组合检索，结果表明UniME在所有任务上都实现了持续的性能提升，展现出优越的判别性和组合能力。&lt;h4&gt;结论&lt;/h4&gt;UniME通过改进判别能力和增强下游任务中的指令跟随能力，为多模态表示学习提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Contrastive Language-Image Pre-training (CLIP) framework has become awidely used approach for multimodal representation learning, particularly inimage-text retrieval and clustering. However, its efficacy is constrained bythree key limitations: (1) text token truncation, (2) isolated image-textencoding, and (3) deficient compositionality due to bag-of-words behavior.While recent Multimodal Large Language Models (MLLMs) have demonstratedsignificant advances in generalized vision-language understanding, theirpotential for learning transferable multimodal representations remainsunderexplored.In this work, we present UniME (Universal Multimodal Embedding),a novel two-stage framework that leverages MLLMs to learn discriminativerepresentations for diverse downstream tasks. In the first stage, we performtextual discriminative knowledge distillation from a powerful LLM-based teachermodel to enhance the embedding capability of the MLLM\'s language component. Inthe second stage, we introduce hard negative enhanced instruction tuning tofurther advance discriminative representation learning. Specifically, weinitially mitigate false negative contamination and then sample multiple hardnegatives per instance within each batch, forcing the model to focus onchallenging samples. This approach not only improves discriminative power butalso enhances instruction-following ability in downstream tasks. We conductextensive experiments on the MMEB benchmark and multiple retrieval tasks,including short and long caption retrieval and compositional retrieval. Resultsdemonstrate that UniME achieves consistent performance improvement across alltasks, exhibiting superior discriminative and compositional capabilities.</description>
      <author>example@mail.com (Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng)</author>
      <guid isPermaLink="false">2504.17432v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Fine-tune Smarter, Not Harder: Parameter-Efficient Fine-Tuning for Geospatial Foundation Models</title>
      <link>http://arxiv.org/abs/2504.17397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code available at https://github.com/IBM/peft-geofm&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了地球观测（EO）中基础模型的应用和参数高效微调（PEFT）技术的效果，以实现准确和高效的地理信息提取。&lt;h4&gt;背景&lt;/h4&gt;地球观测对于监测环境变化、应对灾害和管理自然资源至关重要。然而，随着模型规模的增大，微调变得越来越困难，限制了其可访问性和可扩展性。&lt;h4&gt;目的&lt;/h4&gt;通过实验评估PEFT技术在五个不同地球观测数据集上的有效性，并探讨其如何支持预训练地理空间模型的适应。&lt;h4&gt;方法&lt;/h4&gt;进行广泛的实验，涉及不同的基础模型架构和PEFT技术，并对结果进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;PEFT技术能够匹配甚至超过全微调的性能，同时增强模型对未见地理区域的泛化能力，并减少训练时间和内存需求。&lt;h4&gt;结论&lt;/h4&gt;PEFT技术是提高地球观测模型适应性的有效方法，且通过TerraTorch开源包实现了快速、可扩展和成本效益高的模型适应。&lt;h4&gt;翻译&lt;/h4&gt;摘要：地球观测（EO）对于监测环境变化、应对灾害以及管理自然资源至关重要。在此背景下，基础模型有助于远程传感图像分析，以准确和高效地获取相关地理信息。然而，随着这些模型规模的增大，由于相关的计算资源和成本，微调变得越来越具有挑战性，限制了其可访问性和可扩展性。此外，完全微调可能导致忘记预训练特征，甚至降低模型泛化能力。为了解决这个问题，参数高效微调（PEFT）技术提供了一种有希望的方法。在本文中，我们通过各种基础模型架构和PEFT技术进行了广泛的实验，以评估它们在五个不同地球观测数据集上的有效性。我们的结果提供了一个全面的比较，提供了关于何时以及如何使用PEFT方法支持预训练地理空间模型适应的见解。我们证明了PEFT技术匹配甚至超过全微调的性能，并增强了模型对未见地理区域的泛化能力，同时减少了训练时间和内存需求。另外的实验研究了架构选择的影响，如解码器类型或元数据的使用，建议使用UNet解码器和无需元数据的微调作为推荐配置。我们将所有评估的基础模型和技术整合到开源包TerraTorch中，以支持快速、可扩展和成本效益高的模型适应。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Earth observation (EO) is crucial for monitoring environmental changes,responding to disasters, and managing natural resources. In this context,foundation models facilitate remote sensing image analysis to retrieve relevantgeoinformation accurately and efficiently. However, as these models grow insize, fine-tuning becomes increasingly challenging due to the associatedcomputational resources and costs, limiting their accessibility andscalability. Furthermore, full fine-tuning can lead to forgetting pre-trainedfeatures and even degrade model generalization. To address this,Parameter-Efficient Fine-Tuning (PEFT) techniques offer a promising solution.In this paper, we conduct extensive experiments with various foundation modelarchitectures and PEFT techniques to evaluate their effectiveness on fivedifferent EO datasets. Our results provide a comprehensive comparison, offeringinsights into when and how PEFT methods support the adaptation of pre-trainedgeospatial models. We demonstrate that PEFT techniques match or even exceedfull fine-tuning performance and enhance model generalisation to unseengeographic regions, while reducing training time and memory requirements.Additional experiments investigate the effect of architecture choices such asthe decoder type or the use of metadata, suggesting UNet decoders andfine-tuning without metadata as the recommended configuration. We haveintegrated all evaluated foundation models and techniques into the open-sourcepackage TerraTorch to support quick, scalable, and cost-effective modeladaptation.</description>
      <author>example@mail.com (Francesc Marti-Escofet, Benedikt Blumenstiel, Linus Scheibenreif, Paolo Fraccaro, Konrad Schindler)</author>
      <guid isPermaLink="false">2504.17397v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>An Explainable Nature-Inspired Framework for Monkeypox Diagnosis: Xception Features Combined with NGBoost and African Vultures Optimization Algorithm</title>
      <link>http://arxiv.org/abs/2504.17540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于深度学习的框架，用于自动检测猴痘，通过使用迁移学习、降维和高级机器学习技术，以提高早期和准确的诊断，从而有效管理疾病。&lt;h4&gt;背景&lt;/h4&gt;近年来，猴痘在全球范围内的传播，尤其是在以往没有流行过的地区，引发了重大的公共卫生关注。&lt;h4&gt;目的&lt;/h4&gt;为了有效管理疾病和控制猴痘，本研究旨在开发一个自动检测猴痘的深度学习框架。&lt;h4&gt;方法&lt;/h4&gt;研究使用了新的猴痘皮肤病变数据集（MSLD），其中包括猴痘、水痘和麻疹的图像，并采用了Xception架构进行深度特征提取，随后使用主成分分析（PCA）进行降维，并使用自然梯度提升（NGBoost）算法进行分类。为了优化模型性能和泛化能力，引入了非洲秃鹫优化算法（AVOA）进行超参数调整。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的AVOA-NGBoost模型实现了最先进的性能，准确率为97.53%，F1分数为97.72%，AUC为97.47%。此外，还使用Grad-CAM和LIME技术增强了模型的可解释性，揭示了决策过程和影响分类的关键特征。&lt;h4&gt;结论&lt;/h4&gt;该框架提供了一种高度精确和高效的诊断工具，有助于医疗保健提供者在资源受限的环境中早期检测和诊断猴痘。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近猴痘在全球范围内的传播，尤其是在历史上未曾流行的地区，引起了重大的公共卫生担忧。早期和准确的诊断对于有效的疾病管理和控制至关重要。为此，本研究提出了一种基于深度学习的框架，用于从皮肤病变图像中自动检测猴痘，利用迁移学习、降维和高级机器学习技术的力量。我们使用了新开发的猴痘皮肤病变数据集（MSLD），该数据集包括猴痘、水痘和麻疹的图像，以训练和评估我们的模型。所提出的框架采用了Xception架构进行深度特征提取，随后使用主成分分析（PCA）进行降维，并使用自然梯度提升（NGBoost）算法进行分类。为了优化模型性能和泛化，我们引入了非洲秃鹫优化算法（AVOA）进行超参数调整，确保参数空间的效率探索。我们的结果表明，所提出的AVOA-NGBoost模型实现了最先进的性能，准确率为97.53%，F1分数为97.72%，AUC为97.47%。此外，我们还使用Grad-CAM和LIME技术增强了模型的可解释性，揭示了决策过程和影响分类的关键特征。该框架提供了一种高度精确和高效的诊断工具，可能有助于医疗保健提供者在资源受限的环境中早期检测和诊断。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent global spread of monkeypox, particularly in regions where it hasnot historically been prevalent, has raised significant public health concerns.Early and accurate diagnosis is critical for effective disease management andcontrol. In response, this study proposes a novel deep learning-based frameworkfor the automated detection of monkeypox from skin lesion images, leveragingthe power of transfer learning, dimensionality reduction, and advanced machinelearning techniques. We utilize the newly developed Monkeypox Skin LesionDataset (MSLD), which includes images of monkeypox, chickenpox, and measles, totrain and evaluate our models. The proposed framework employs the Xceptionarchitecture for deep feature extraction, followed by Principal ComponentAnalysis (PCA) for dimensionality reduction, and the Natural Gradient Boosting(NGBoost) algorithm for classification. To optimize the model's performance andgeneralization, we introduce the African Vultures Optimization Algorithm (AVOA)for hyperparameter tuning, ensuring efficient exploration of the parameterspace. Our results demonstrate that the proposed AVOA-NGBoost model achievesstate-of-the-art performance, with an accuracy of 97.53%, F1-score of 97.72%and an AUC of 97.47%. Additionally, we enhance model interpretability usingGrad-CAM and LIME techniques, providing insights into the decision-makingprocess and highlighting key features influencing classification. Thisframework offers a highly precise and efficient diagnostic tool, potentiallyaiding healthcare providers in early detection and diagnosis, particularly inresource-constrained environments.</description>
      <author>example@mail.com (Ahmadreza Shateri, Negar Nourani, Morteza Dorrigiv, Hamid Nasiri)</author>
      <guid isPermaLink="false">2504.17540v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing</title>
      <link>http://arxiv.org/abs/2504.17213v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MCAF是一种基于代理的训练免费框架，通过多模态粗到细注意力聚焦进行视频理解，显著提高了视频理解性能。&lt;h4&gt;背景&lt;/h4&gt;尽管大模型在快速发展，但视频理解，尤其是长视频理解，仍然极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出MCAF框架，以解决视频信息冗余和全局注意力分配问题，实现准确的视频理解。&lt;h4&gt;方法&lt;/h4&gt;MCAF通过以下方式实现视频理解：1）通过多模态信息对高度相关的视频片段进行分层关注；2）采用时间扩展机制减少从集中帧中提取信息时遗漏关键细节的风险；3）利用模型响应的置信度作为反馈，实现自我反思。&lt;h4&gt;主要发现&lt;/h4&gt;MCAF在EgoSchema数据集上比领先方法提高了5%的性能；在Next-QA和IntentQA数据集上分别比当前最先进的标准提高了0.2%和0.3%；在Video-MME数据集上，也优于其他基于代理的方法。&lt;h4&gt;结论&lt;/h4&gt;MCAF在视频理解任务上优于现有的最先进方法，有效提高了视频理解的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Even in the era of rapid advances in large models, video understanding, particularly long videos, remains highly challenging. Compared with textual or image-based information, videos commonly contain more information with redundancy, requiring large models to strategically allocate attention at a global level for accurate comprehension. To address this, we propose MCAF, an agent-based, training-free framework perform video understanding through Multimodal Coarse-to-fine Attention Focusing. The key innovation lies in its ability to sense and prioritize segments of the video that are highly relevant to the understanding task. First, MCAF hierarchically concentrates on highly relevant frames through multimodal information, enhancing the correlation between the acquired contextual information and the query. Second, it employs a dilated temporal expansion mechanism to mitigate the risk of missing crucial details when extracting information from these concentrated frames. In addition, our framework incorporates a self-reflection mechanism utilizing the confidence level of the model's responses as feedback. By iteratively applying these two creative focusing strategies, it adaptively adjusts attention to capture highly query-connected context and thus improves response accuracy. MCAF outperforms comparable state-of-the-art methods on average. On the EgoSchema dataset, it achieves a remarkable 5% performance gain over the leading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperforms the current state-of-the-art standard by 0.2% and 0.3% respectively. On the Video-MME dataset, which features videos averaging nearly an hour in length, MCAF also outperforms other agent-based methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Even in the era of rapid advances in large models, video understanding,particularly long videos, remains highly challenging. Compared with textual orimage-based information, videos commonly contain more information withredundancy, requiring large models to strategically allocate attention at aglobal level for accurate comprehension. To address this, we propose MCAF, anagent-based, training-free framework perform video understanding throughMultimodal Coarse-to-fine Attention Focusing. The key innovation lies in itsability to sense and prioritize segments of the video that are highly relevantto the understanding task. First, MCAF hierarchically concentrates on highlyrelevant frames through multimodal information, enhancing the correlationbetween the acquired contextual information and the query. Second, it employs adilated temporal expansion mechanism to mitigate the risk of missing crucialdetails when extracting information from these concentrated frames. Inaddition, our framework incorporates a self-reflection mechanism utilizing theconfidence level of the model's responses as feedback. By iteratively applyingthese two creative focusing strategies, it adaptively adjusts attention tocapture highly query-connected context and thus improves response accuracy.MCAF outperforms comparable state-of-the-art methods on average. On theEgoSchema dataset, it achieves a remarkable 5% performance gain over theleading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperformsthe current state-of-the-art standard by 0.2% and 0.3% respectively. On theVideo-MME dataset, which features videos averaging nearly an hour in length,MCAF also outperforms other agent-based methods.</description>
      <author>example@mail.com (Shiwen Cao, Zhaoxing Zhang, Junming Jiao, Juyi Qiao, Guowen Song, Rong Shen)</author>
      <guid isPermaLink="false">2504.17213v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>On the workflow, opportunities and challenges of developing foundation model in geophysics</title>
      <link>http://arxiv.org/abs/2504.17384v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一套完整的框架，用于系统地探讨与地球物理数据结合开发基础模型的全过程。&lt;h4&gt;背景&lt;/h4&gt;基础模型作为人工智能的主流技术，近年来在处理复杂任务和多模态数据方面展现出巨大潜力。在地球物理学领域，虽然基础模型的应用正在逐步扩展，但目前缺乏对整合基础模型与地球物理数据全工作流程的全面综述。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文旨在提供一个全面框架，系统地探讨与地球物理数据结合开发基础模型的全过程。&lt;h4&gt;方法&lt;/h4&gt;本文从数据收集和预处理到模型架构选择、预训练策略和模型部署，详细分析了每个阶段的关键技术和方法。特别地，考虑到地球物理数据的多样性、复杂性和物理一致性约束，本文讨论了针对这些挑战的特定解决方案。此外，本文还讨论了如何利用基础模型的迁移学习能力来减少对标记数据的依赖，提高计算效率，并将物理约束纳入模型训练，从而提高物理一致性和可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;本文不仅填补了地球物理学领域关于基础模型全流程综述的空白，还为地球物理数据分析中的应用提供了有价值的实践指导，推动了该领域的创新和进步。&lt;h4&gt;结论&lt;/h4&gt;本文提出的框架为地球物理数据中的基础模型应用提供了系统的方法和策略，有助于提高模型性能和地球物理数据分析的效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a comprehensive framework for systematically exploring the entire process of developing foundation models in conjunction with geophysical data. From data collection and preprocessing to model architecture selection, pre-training strategies, and model deployment, a detailed analysis of the key techniques and methodologies at each stage is provided. In particular, considering the diversity, complexity, and physical consistency constraints of geophysical data, targeted solutions to address these challenges are discussed. Furthermore, strategies for leveraging the transfer learning capabilities of foundation models to reduce reliance on labeled data, enhance computational efficiency, and incorporate physical constraints into model training are presented, thereby improving physical consistency and interpretability. Through a comprehensive summary and analysis of the current technological landscape, this paper not only fills the gap in the geophysics domain regarding a full-process review of foundation models but also offers valuable practical guidance for their application in geophysical data analysis, driving innovation and advancement in the field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, as a mainstream technology in artificial intelligence,have demonstrated immense potential across various domains in recent years,particularly in handling complex tasks and multimodal data. In the field ofgeophysics, although the application of foundation models is graduallyexpanding, there is currently a lack of comprehensive reviews discussing thefull workflow of integrating foundation models with geophysical data. Toaddress this gap, this paper presents a complete framework that systematicallyexplores the entire process of developing foundation models in conjunction withgeophysical data. From data collection and preprocessing to model architectureselection, pre-training strategies, and model deployment, we provide a detailedanalysis of the key techniques and methodologies at each stage. In particular,considering the diversity, complexity, and physical consistency constraints ofgeophysical data, we discuss targeted solutions to address these challenges.Furthermore, we discuss how to leverage the transfer learning capabilities offoundation models to reduce reliance on labeled data, enhance computationalefficiency, and incorporate physical constraints into model training, therebyimproving physical consistency and interpretability. Through a comprehensivesummary and analysis of the current technological landscape, this paper notonly fills the gap in the geophysics domain regarding a full-process review offoundation models but also offers valuable practical guidance for theirapplication in geophysical data analysis, driving innovation and advancement inthe field.</description>
      <author>example@mail.com (Hanlin Sheng, Xinming Wu, Hang Gao, Haibin Di, Sergey Fomel, Jintao Li, Xu Si)</author>
      <guid isPermaLink="false">2504.17384v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs</title>
      <link>http://arxiv.org/abs/2504.17040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为DyMU的框架，该框架在无需训练的情况下，动态减少视觉语言模型（VLMs）的计算负担，同时保持高任务性能。&lt;h4&gt;背景&lt;/h4&gt;视觉语言模型在处理图像和文本数据时，计算负担较大，且固定长度的输出在视觉Transformer中存在固有低效问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，能够在不牺牲任务性能的情况下，降低视觉语言模型的计算成本。&lt;h4&gt;方法&lt;/h4&gt;DyMU包含两个关键组件：动态标记合并（DToMe）和虚拟标记解合并（VTU）。DToMe通过根据图像复杂度合并相似标记来减少视觉标记嵌入的数量；VTU通过高效重建完整序列的注意力动态来模拟大型语言模型（LLMs）期望的标记序列。&lt;h4&gt;主要发现&lt;/h4&gt;DyMU在图像和视频理解任务上进行了广泛的实验，结果表明，它可以平均减少32%-85%的视觉标记计数，同时在不同VLM架构上实现与全长模型相当的性能，包括流行的AnyRes视觉编码器。通过定性分析，发现DToMe能够根据图像复杂度有效地调整标记减少，并且与现有系统不同，为用户提供更多控制计算成本的能力。&lt;h4&gt;结论&lt;/h4&gt;DyMU是一种高效、无需训练的框架，能够动态地降低视觉语言模型的计算负担，同时保持高任务性能，适用于大多数最先进的VLM架构。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为DyMU的框架，该框架在无需训练的情况下，动态减少视觉语言模型（VLMs）的计算负担，同时保持高任务性能。我们的方法包含两个关键组件。首先，动态标记合并（DToMe）通过基于图像复杂度合并相似标记来减少视觉标记嵌入的数量，解决了视觉Transformer中固定长度输出的固有低效问题。其次，虚拟标记解合并（VTU）通过高效重建完整序列的注意力动态来模拟大型语言模型（LLMs）期望的标记序列，从而在不进行额外微调的情况下保持下游性能。与先前的方法不同，我们的方法根据图像内容动态调整标记压缩，并且完全无需训练，使其适用于大多数最先进的VLM架构。在图像和视频理解任务上的广泛实验表明，DyMU可以减少平均视觉标记计数32%-85%，同时在不同的VLM架构上实现与全长模型相当的性能，包括最近流行的基于AnyRes的视觉编码器。此外，通过定性分析，我们发现DToMe能够根据图像复杂度有效地调整标记减少，并且与现有系统不同，为用户提供更多控制计算成本的能力。项目页面：https://mikewangwzhl.github.io/dymu/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present DyMU, an efficient, training-free framework that dynamicallyreduces the computational burden of vision-language models (VLMs) whilemaintaining high task performance. Our approach comprises two key components.First, Dynamic Token Merging (DToMe) reduces the number of visual tokenembeddings by merging similar tokens based on image complexity, addressing theinherent inefficiency of fixed-length outputs in vision transformers. Second,Virtual Token Unmerging (VTU) simulates the expected token sequence for largelanguage models (LLMs) by efficiently reconstructing the attention dynamics ofa full sequence, thus preserving the downstream performance without additionalfine-tuning. Unlike previous approaches, our method dynamically adapts tokencompression to the content of the image and operates completely training-free,making it readily applicable to most state-of-the-art VLM architectures.Extensive experiments on image and video understanding tasks demonstrate thatDyMU can reduce the average visual token count by 32%-85% while achievingcomparable performance to full-length models across diverse VLM architectures,including the recently popularized AnyRes-based visual encoders. Furthermore,through qualitative analyses, we demonstrate that DToMe effectively adaptstoken reduction based on image complexity and, unlike existing systems,provides users more control over computational costs. Project page:https://mikewangwzhl.github.io/dymu/.</description>
      <author>example@mail.com (Zhenhailong Wang, Senthil Purushwalkam, Caiming Xiong, Silvio Savarese, Heng Ji, Ran Xu)</author>
      <guid isPermaLink="false">2504.17040v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Discovering the Precursors of Traffic Breakdowns Using Spatiotemporal Graph Attribution Networks</title>
      <link>http://arxiv.org/abs/2504.17109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合时空图神经网络（ST-GNN）和Shapley值的方法，用于识别和解释交通拥堵的前兆，以改善道路安全和交通流管理。&lt;h4&gt;背景&lt;/h4&gt;理解和预测交通拥堵的前兆对于提高道路安全和交通流管理至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过将Shapley解释方法扩展到时空环境，本研究旨在连接黑盒神经网络预测和可解释原因之间的差距。&lt;h4&gt;方法&lt;/h4&gt;本研究采用了一种新的方法，结合了时空图神经网络（ST-GNN）和Shapley值，以识别和解释交通拥堵的前兆。&lt;h4&gt;主要发现&lt;/h4&gt;在I-24州际公路数据上，研究揭示了道路拓扑和急刹车是导致交通拥堵的主要因素。&lt;h4&gt;结论&lt;/h4&gt;该方法有助于识别和理解导致交通拥堵的关键因素，从而为改善交通流和道路安全提供依据。&lt;h4&gt;翻译&lt;/h4&gt;Understanding and predicting the precursors of traffic breakdowns is critical for improving road safety and traffic flow management. This paper presents a novel approach combining spatiotemporal graph neural networks (ST-GNNs) with Shapley values to identify and interpret traffic breakdown precursors. By extending Shapley explanation methods to a spatiotemporal setting, our proposed method bridges the gap between black-box neural network predictions and interpretable causes. We demonstrate the method on the Interstate-24 data, and identify that road topology and abrupt braking are major factors that lead to traffic breakdowns.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding and predicting the precursors of traffic breakdowns is criticalfor improving road safety and traffic flow management. This paper presents anovel approach combining spatiotemporal graph neural networks (ST-GNNs) withShapley values to identify and interpret traffic breakdown precursors. Byextending Shapley explanation methods to a spatiotemporal setting, our proposedmethod bridges the gap between black-box neural network predictions andinterpretable causes. We demonstrate the method on the Interstate-24 data, andidentify that road topology and abrupt braking are major factors that lead totraffic breakdowns.</description>
      <author>example@mail.com (Zhaobin Mo, Xiangyi Liao, Dominik A. Karbowski, Yanbing Wang)</author>
      <guid isPermaLink="false">2504.17109v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>DRC: Enhancing Personalized Image Generation via Disentangled Representation Composition</title>
      <link>http://arxiv.org/abs/2504.17349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DRC的个性化图像生成框架，用于解决现有方法在融合用户风格偏好和语义意图时的不足，通过解耦表示组合增强LMMs，以实现可控和有效的个性化图像生成。&lt;h4&gt;背景&lt;/h4&gt;个性化图像生成是跨模态内容创作中的一个有前景方向，旨在通过利用用户交互的历史图像和多模态指令来合成符合个人风格偏好和语义意图的图像。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在准确捕捉和融合用户风格偏好和语义意图时的不足，特别是解决LMMs中视觉特征纠缠导致的Guidance Collapse问题。&lt;h4&gt;方法&lt;/h4&gt;DRC框架包括两个关键的学习阶段：1）解耦学习，使用双塔解耦器显式分离风格和语义特征，并通过重构驱动的范式和困难感知的重要性采样进行优化；2）个性化建模，应用语义保持的增强来有效适应解耦表示，以实现鲁棒的个性化生成。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准测试上的大量实验表明，DRC在性能上具有竞争力，并有效地缓解了Guidance Collapse问题，强调了解耦表示学习对于可控和有效的个性化图像生成的重要性。&lt;h4&gt;结论&lt;/h4&gt;DRC框架通过解耦表示组合，有效提升了LMMs在个性化图像生成中的性能，为该领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Personalized image generation has emerged as a promising direction inmultimodal content creation. It aims to synthesize images tailored toindividual style preferences (e.g., color schemes, character appearances,layout) and semantic intentions (e.g., emotion, action, scene contexts) byleveraging user-interacted history images and multimodal instructions. Despitenotable progress, existing methods -- whether based on diffusion models, largelanguage models, or Large Multimodal Models (LMMs) -- struggle to accuratelycapture and fuse user style preferences and semantic intentions. In particular,the state-of-the-art LMM-based method suffers from the entanglement of visualfeatures, leading to Guidance Collapse, where the generated images fail topreserve user-preferred styles or reflect the specified semantics.  To address these limitations, we introduce DRC, a novel personalized imagegeneration framework that enhances LMMs through Disentangled RepresentationComposition. DRC explicitly extracts user style preferences and semanticintentions from history images and the reference image, respectively, to formuser-specific latent instructions that guide image generation within LMMs.Specifically, it involves two critical learning stages: 1) Disentanglementlearning, which employs a dual-tower disentangler to explicitly separate styleand semantic features, optimized via a reconstruction-driven paradigm withdifficulty-aware importance sampling; and 2) Personalized modeling, whichapplies semantic-preserving augmentations to effectively adapt the disentangledrepresentations for robust personalized generation. Extensive experiments ontwo benchmarks demonstrate that DRC shows competitive performance whileeffectively mitigating the guidance collapse issue, underscoring the importanceof disentangled representation learning for controllable and effectivepersonalized image generation.</description>
      <author>example@mail.com (Yiyan Xu, Wuqiang Zheng, Wenjie Wang, Fengbin Zhu, Xinting Hu, Yang Zhang, Fuli Feng, Tat-Seng Chua)</author>
      <guid isPermaLink="false">2504.17349v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Dargana: fine-tuning EarthPT for dynamic tree canopy mapping from space</title>
      <link>http://arxiv.org/abs/2504.17321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures, spotlight at `Tackling Climate Change with  Machine Learning', ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Dargana，这是对EarthPT时间序列基础模型进行微调的变体，通过使用不到3%的预训练数据量和5%的预训练计算量实现专业化。Dargana经过微调，能够以10米分辨率定期更新树木冠层覆盖的分类，区分针叶和阔叶树木类型。&lt;h4&gt;背景&lt;/h4&gt;本文的研究背景是利用预训练的大规模观测模型（如EarthPT）进行土地覆盖的精细动态监测。&lt;h4&gt;目的&lt;/h4&gt;本文旨在展示如何利用预训练模型实现土地覆盖的精细动态监测，为自然资源管理和保护提供有价值的、可扩展的工具。&lt;h4&gt;方法&lt;/h4&gt;Dargana模型通过微调EarthPT模型，使用Cornwall地区的卫星图像进行测试，识别10米分辨率的树木冠层覆盖，并区分不同类型的树木。&lt;h4&gt;主要发现&lt;/h4&gt;Dargana模型在未见过的卫星图像上实现了像素级的ROC-AUC为0.98和PR-AUC为0.83。它能够识别训练样本限制以下的精细结构，如树篱和砍伐地，并追踪冠层覆盖随时间的变化，如新林地的建立。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果表明，预训练的大型观测模型可以通过微调来专门用于空间上的精细土地覆盖监测，为自然资源管理和保护提供了有价值的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Dargana, a fine-tuned variant of the EarthPT time-seriesfoundation model that achieves specialisation using &lt;3% of its pre-trainingdata volume and 5% of its pre-training compute. Dargana is fine-tuned togenerate regularly updated classification of tree canopy cover at 10mresolution, distinguishing conifer and broadleaved tree types. Using Cornwall,UK, as a test case, the model achieves a pixel-level ROC-AUC of 0.98 and aPR-AUC of 0.83 on unseen satellite imagery. Dargana can identify finestructures like hedgerows and coppice below the training sample limit, and cantrack temporal changes to canopy cover such as new woodland establishment. Ourresults demonstrate how pre-trained Large Observation Models like EarthPT canbe specialised for granular, dynamic land cover monitoring from space,providing a valuable, scalable tool for natural capital management andconservation.</description>
      <author>example@mail.com (Michael J. Smith, Luke Fleming, James E. Geach, Ryan J. Roberts, Freddie Kalaitzis, James Banister)</author>
      <guid isPermaLink="false">2504.17321v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>The Riemannian Means Field Classifier for EEG-Based BCI Data</title>
      <link>http://arxiv.org/abs/2504.17352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究证明了Riemannian最小距离到均值（MDM）分类器在各类基于脑电图（EEG）的脑机接口（BCI）中的鲁棒性和准确性。提出了一种改进的MDM方法，通过分析多个公共数据库，证明了该方法在性能上优于传统的MDM，同时保持了简单性和确定性。&lt;h4&gt;背景&lt;/h4&gt;大量研究表明，Riemannian最小距离到均值（MDM）分类器在所有类型的基于EEG的BCI中表现出鲁棒性和准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种改进的MDM方法，通过使用多个幂平均数代替单一的几何平均数，以提升分类器的性能。&lt;h4&gt;方法&lt;/h4&gt;通过分析20个公共数据库，包括10个用于运动想象BCI范式和10个用于P300 BCI范式的数据库，总共包含587个个体，来评估改进的MDM方法。&lt;h4&gt;主要发现&lt;/h4&gt;改进的MDM方法在性能上明显优于传统的MDM，接近当前的最佳水平，同时保持了简单性和确定性。&lt;h4&gt;结论&lt;/h4&gt;改进的MDM方法在保持简单性和确定性的同时，显著提升了分类器的性能，并计划将相关代码以开源形式发布，以促进可重复研究。&lt;h4&gt;翻译&lt;/h4&gt;大量研究证明了Riemannian最小距离到均值（MDM）分类器在所有类型的基于脑电图（EEG）的脑机接口（BCI）中的鲁棒性和准确性。该分类器简单、完全确定、对噪声鲁棒、计算效率高，且易于迁移学习。其训练非常简单，只需计算每个类别的对称正定（SPD）矩阵的几何平均值。我们提出了一种改进的MDM方法，涉及使用多个SPD矩阵的幂平均数而不是单一的几何平均数。通过分析20个公共数据库，其中10个用于运动想象BCI范式，10个用于P300 BCI范式，总共包含587个个体，我们表明所提出的分类器在性能上明显优于MDM，在性能上接近当前的最佳水平，同时保持了简单性和确定性。为了促进可重复研究，我们的代码将以开源形式发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/s25072305&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A substantial amount of research has demonstrated the robustness and accuracyof the Riemannian minimum distance to mean (MDM) classifier for all kinds ofEEG-based brain--computer interfaces (BCIs). This classifier is simple, fullydeterministic, robust to noise, computationally efficient, and prone totransfer learning. Its training is very simple, requiring just the computationof a geometric mean of a symmetric positive-definite (SPD) matrix per class. Wepropose an improvement of the MDM involving a number of power means of SPDmatrices instead of the sole geometric mean. By the analysis of 20 publicdatabases, 10 for the motor-imagery BCI paradigm and 10 for the P300 BCIparadigm, comprising 587 individuals in total, we show that the proposedclassifier clearly outperforms the MDM, approaching the state-of-the art interms of performance while retaining the simplicity and the deterministicbehavior. In order to promote reproducible research, our code will be releasedas open source.</description>
      <author>example@mail.com (Anton Andreev, Grégoire Cattan, Marco Congedo)</author>
      <guid isPermaLink="false">2504.17352v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Class-Conditional Distribution Balancing for Group Robust Classification</title>
      <link>http://arxiv.org/abs/2504.17314v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种解决模型因错误原因作出正确预测的虚假相关性问题的方法。&lt;h4&gt;背景&lt;/h4&gt;现有研究将此问题归因于群体不平衡，并通过最大化平衡群体或最坏群体准确性来解决，但这依赖于昂贵的偏差标注。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要偏差标注和预测的简单而有效的鲁棒学习方法，以减少虚假因素与标签信息之间的互信息。&lt;h4&gt;方法&lt;/h4&gt;通过重新定义虚假相关性为条件分布中的不平衡或错配，利用样本重加权策略来实现条件分布平衡，自动突出少数群体和类别，从而消除虚假相关性并产生用于分类的无偏差数据分布。&lt;h4&gt;主要发现&lt;/h4&gt;实验和分析表明，该方法在性能上持续优于依赖偏差监督的方法。&lt;h4&gt;结论&lt;/h4&gt;该论文提出的方法能够有效解决虚假相关性问题，并在分类任务中实现无偏差的数据分布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spurious correlations that lead models to correct predictions for the wrongreasons pose a critical challenge for robust real-world generalization.Existing research attributes this issue to group imbalance and addresses it bymaximizing group-balanced or worst-group accuracy, which heavily relies onexpensive bias annotations. A compromise approach involves predicting biasinformation using extensively pretrained foundation models, which requireslarge-scale data and becomes impractical for resource-limited rare domains. Toaddress these challenges, we offer a novel perspective by reframing thespurious correlations as imbalances or mismatches in class-conditionaldistributions, and propose a simple yet effective robust learning method thateliminates the need for both bias annotations and predictions. With the goal ofreducing the mutual information between spurious factors and label information,our method leverages a sample reweighting strategy to achieve class-conditionaldistribution balancing, which automatically highlights minority groups andclasses, effectively dismantling spurious correlations and producing a debiaseddata distribution for classification. Extensive experiments and analysisdemonstrate that our approach consistently delivers state-of-the-artperformance, rivaling methods that rely on bias supervision.</description>
      <author>example@mail.com (Miaoyun Zhao, Qiang Zhang, Chenrong Li)</author>
      <guid isPermaLink="false">2504.17314v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Low-Resource Neural Machine Translation Using Recurrent Neural Networks and Transfer Learning: A Case Study on English-to-Igbo</title>
      <link>http://arxiv.org/abs/2504.17252v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 14 combined figures (19 total), includes horizontal  layouts. Submitted to arXiv for open access&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究开发了基于神经机器翻译（NMT）和Transformer的迁移学习模型，用于英语到伊博语的翻译，伊博语是一种在尼日利亚和西非地区由超过4000万人使用的低资源非洲语言。&lt;h4&gt;背景&lt;/h4&gt;伊博语是一种低资源的非洲语言，而现有的英语到伊博语的翻译模型效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提高英语到伊博语的翻译准确性。&lt;h4&gt;方法&lt;/h4&gt;在经过专家验证的、由圣经、本地新闻、维基百科文章和Common Crawl组成的基准数据集上训练模型。模型架构包括RNN，如LSTM和GRU，并增强了注意力机制。此外，还使用了MarianNMT预训练模型和SimpleTransformers框架进行迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;基于RNN的系统达到了与现有英语到伊博语基准相当的结果。应用迁移学习后，性能提升了+4.83 BLEU分，估计翻译准确率达到70%。&lt;h4&gt;结论&lt;/h4&gt;将RNN与迁移学习相结合，可以有效地解决低资源语言翻译任务中的性能差距问题。&lt;h4&gt;翻译&lt;/h4&gt;本研究开发了一种基于神经机器翻译（NMT）和Transformer的迁移学习模型，用于英语到伊博语的翻译，伊博语是一种在尼日利亚和西非地区由超过4000万人使用的低资源非洲语言。模型在经过专家验证的、由圣经、本地新闻、维基百科文章和Common Crawl组成的基准数据集上训练，并利用了RNN架构，包括LSTM和GRU，以及注意力机制。此外，还采用了MarianNMT预训练模型和SimpleTransformers框架进行迁移学习。实验结果表明，基于RNN的系统在翻译准确率上与现有英语到伊博语的基准相当，应用迁移学习后，性能提升了+4.83 BLEU分，估计翻译准确率达到70%。这些发现突出了将RNN与迁移学习相结合在解决低资源语言翻译任务性能差距方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we develop Neural Machine Translation (NMT) andTransformer-based transfer learning models for English-to-Igbo translation - alow-resource African language spoken by over 40 million people across Nigeriaand West Africa. Our models are trained on a curated and benchmarked datasetcompiled from Bible corpora, local news, Wikipedia articles, and Common Crawl,all verified by native language experts. We leverage Recurrent Neural Network(RNN) architectures, including Long Short-Term Memory (LSTM) and GatedRecurrent Units (GRU), enhanced with attention mechanisms to improvetranslation accuracy. To further enhance performance, we apply transferlearning using MarianNMT pre-trained models within the SimpleTransformersframework. Our RNN-based system achieves competitive results, closely matchingexisting English-Igbo benchmarks. With transfer learning, we observe aperformance gain of +4.83 BLEU points, reaching an estimated translationaccuracy of 70%. These findings highlight the effectiveness of combining RNNswith transfer learning to address the performance gap in low-resource languagetranslation tasks.</description>
      <author>example@mail.com (Ocheme Anthony Ekle, Biswarup Das)</author>
      <guid isPermaLink="false">2504.17252v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation</title>
      <link>http://arxiv.org/abs/2504.17207v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://apc-vlm.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过心理意象模拟实现视觉语言模型（VLMs）中的视角感知推理框架。&lt;h4&gt;背景&lt;/h4&gt;视角感知，即从不同视角感知环境或情况的能力，是人类视觉理解的关键基准，对于与自主代理的环境交互和协作至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了弥合VLMs与人类感知之间的差距，本文重点关注心理意象在视角转换中的作用。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个名为抽象视角变化（APC）的框架，该框架有效地利用视觉基础模型（如目标检测、分割和方向估计）来构建场景抽象并实现视角变换。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实图像基准上的实验表明，与各种VLMs相比，本文的框架在视角感知推理方面取得了显著改进，并优于微调的空間推理模型和基于新视角合成的方案。&lt;h4&gt;结论&lt;/h4&gt;APC框架为VLMs提供了视角感知推理的能力，有助于提高VLMs在环境交互和协作中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a framework for perspective-aware reasoning in vision-languagemodels (VLMs) through mental imagery simulation. Perspective-taking, theability to perceive an environment or situation from an alternative viewpoint,is a key benchmark for human-level visual understanding, essential forenvironmental interaction and collaboration with autonomous agents. Despiteadvancements in spatial reasoning within VLMs, recent research has shown thatmodern VLMs significantly lack perspective-aware reasoning capabilities andexhibit a strong bias toward egocentric interpretations. To bridge the gapbetween VLMs and human perception, we focus on the role of mental imagery,where humans perceive the world through abstracted representations thatfacilitate perspective shifts. Motivated by this, we propose a framework forperspective-aware reasoning, named Abstract Perspective Change (APC), thateffectively leverages vision foundation models, such as object detection,segmentation, and orientation estimation, to construct scene abstractions andenable perspective transformations. Our experiments on synthetic and real-imagebenchmarks, compared with various VLMs, demonstrate significant improvements inperspective-aware reasoning with our framework, further outperformingfine-tuned spatial reasoning models and novel-view-synthesis-based approaches.</description>
      <author>example@mail.com (Phillip Y. Lee, Jihyeon Je, Chanho Park, Mikaela Angelina Uy, Leonidas Guibas, Minhyuk Sung)</author>
      <guid isPermaLink="false">2504.17207v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs</title>
      <link>http://arxiv.org/abs/2504.17006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is a result of the collaboration by JACOBB, AMII(Alberta Machine  Intelligence Institute), Thales and AI Redefined (AIR) in 2021-2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的多层分层人机交互深度强化学习（HITL DRL）算法，并探讨了HITL在解决复杂问题中的挑战、权衡和优势。&lt;h4&gt;背景&lt;/h4&gt;随着深度强化学习（DRL）的日益流行，人机交互（HITL）方法有望革新决策问题的处理方式，并为人类与人工智能合作创造新的机遇。&lt;h4&gt;目的&lt;/h4&gt;设计一种可扩展的HITL DRL算法，用于盟军无人机在中敌机到达受限区域前将其摧毁。&lt;h4&gt;方法&lt;/h4&gt;算法包含自我学习、模仿学习和迁移学习三种学习方式，并考虑了奖励、动作和演示三种人类输入形式。&lt;h4&gt;主要发现&lt;/h4&gt;HITL能够加快训练速度并提高性能，建议作为梯度方法的指导方向，降低方差，但建议的数量不应过多或过少，以避免过拟合和欠拟合。&lt;h4&gt;结论&lt;/h4&gt;HITL在解决复杂问题时具有重要作用，人类与人工智能的合作对于解决两个真实世界的复杂场景（如超载和诱饵攻击）至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着深度强化学习（DRL）的日益流行，人机交互（HITL）方法有潜力改变我们处理决策问题的方法，并为人类-人工智能合作开辟新的机会。在本文中，我们介绍了一种新颖的多层分层人机交互深度强化学习（HITL DRL）算法，该算法包括三种学习类型：自我学习、模仿学习和迁移学习。此外，我们考虑了三种形式的人类输入：奖励、动作和演示。此外，我们讨论了HITL在解决复杂问题中的主要挑战、权衡和优势以及如何系统地整合人类信息到人工智能解决方案中。为了验证我们的技术成果，我们提出一个真实世界的无人机问题，其中多个敌机攻击一个受限区域。目标是设计一个可扩展的HITL DRL算法，用于盟军无人机在中敌机到达受限区域前将其摧毁。为此，我们首先使用一个名为Cogment的获奖开源HITL软件实现了我们的解决方案。然后，我们展示了一些有趣的结果，例如（a）HITL导致更快的学习和更高的性能，（b）建议作为梯度方法的指导方向，降低方差，（c）建议的数量既不应过多也不应过少，以避免过拟合和欠拟合。最后，我们说明了人类-人工智能合作在解决两个真实世界复杂场景中的作用，即超载和诱饵攻击。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing popularity of deep reinforcement learning (DRL),human-in-the-loop (HITL) approach has the potential to revolutionize the way weapproach decision-making problems and create new opportunities for human-AIcollaboration. In this article, we introduce a novel multi-layered hierarchicalHITL DRL algorithm that comprises three types of learning: self learning,imitation learning and transfer learning. In addition, we consider three formsof human inputs: reward, action and demonstration. Furthermore, we discuss mainchallenges, trade-offs and advantages of HITL in solving complex problems andhow human information can be integrated in the AI solution systematically. Toverify our technical results, we present a real-world unmanned aerial vehicles(UAV) problem wherein a number of enemy drones attack a restricted area. Theobjective is to design a scalable HITL DRL algorithm for ally drones toneutralize the enemy drones before they reach the area. To this end, we firstimplement our solution using an award-winning open-source HITL software calledCogment. We then demonstrate several interesting results such as (a) HITL leadsto faster training and higher performance, (b) advice acts as a guidingdirection for gradient methods and lowers variance, and (c) the amount ofadvice should neither be too large nor too small to avoid over-training andunder-training. Finally, we illustrate the role of human-AI cooperation insolving two real-world complex scenarios, i.e., overloaded and decoy attacks.</description>
      <author>example@mail.com (Jalal Arabneydi, Saiful Islam, Srijita Das, Sai Krishna Gottipati, William Duguay, Cloderic Mars, Matthew E. Taylor, Matthew Guzdial, Antoine Fagette, Younes Zerouali)</author>
      <guid isPermaLink="false">2504.17006v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>A Genealogy of Multi-Sensor Foundation Models in Remote Sensing</title>
      <link>http://arxiv.org/abs/2504.17177v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, submitted to ACM SigSpatial, currently under peer review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在遥感领域应用基础模型进行表征学习的情况，分析了不同方法的优缺点，并提出了未来改进方向。&lt;h4&gt;背景&lt;/h4&gt;基础模型在遥感领域的应用越来越受到关注，主要借鉴了在计算机视觉领域已取得成功的算法，但这一领域的发展仍处于初期阶段。&lt;h4&gt;目的&lt;/h4&gt;研究不同方法在计算机视觉领域的根源，分析其在遥感领域的潜在优势和不足，并展望未来改进方向。&lt;h4&gt;方法&lt;/h4&gt;讨论了学习到的表征质量、减少计算资源需求的方法，以及多传感器在地球观测和多模态基础模型训练中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;发现了多种竞争方法，每种方法都有其显著的优点和缺点，并提出了进一步利用大量未标记、季节性和多传感器遥感观测数据的机会。&lt;h4&gt;结论&lt;/h4&gt;强调了在遥感领域进一步发展基础模型的重要性，并指出了未来研究的方向和可能的机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have garnered increasing attention for representationlearning in remote sensing, primarily adopting approaches that havedemonstrated success in computer vision with minimal domain-specificmodification. However, the development and application of foundation models inthis field are still burgeoning, as there are a variety of competing approachesthat each come with significant benefits and drawbacks. This paper examinesthese approaches along with their roots in the computer vision field in orderto characterize potential advantages and pitfalls while outlining futuredirections to further improve remote sensing-specific foundation models. Wediscuss the quality of the learned representations and methods to alleviate theneed for massive compute resources. We place emphasis on the multi-sensoraspect of Earth observations, and the extent to which existing approachesleverage multiple sensors in training foundation models in relation tomulti-modal foundation models. Finally, we identify opportunities for furtherharnessing the vast amounts of unlabeled, seasonal, and multi-sensor remotesensing observations.</description>
      <author>example@mail.com (Kevin Lane, Morteza Karimzadeh)</author>
      <guid isPermaLink="false">2504.17177v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Simple Graph Contrastive Learning via Fractional-order Neural Diffusion Networks</title>
      <link>http://arxiv.org/abs/2504.16748v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICML&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络扩散模型的新的无增强图对比学习（GCL）框架，通过可学习的编码器产生多样化的视图，捕捉局部或全局信息，实现对比学习，且不需要负样本训练，适用于同质和异质数据集，并在多个数据集上实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;图对比学习（GCL）作为一种无监督的图表示学习方法，最近取得了进展。GCL方法可以分为基于增强和无需增强的方法。基于增强的方法依赖于复杂的数据增强，而无需增强的方法依赖于能够生成同一输入不同视图的编码器。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无增强的GCL框架，该框架能够生成多样化的视图，实现对比学习，且不需要负样本训练。&lt;h4&gt;方法&lt;/h4&gt;使用受分数微分方程（FDE）控制的可学习编码器，每个FDE由微分算子的阶参数特性化。通过调整这些参数，产生能够生成多样化视图的可学习编码器，用于对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;模型不需要负样本进行训练，且适用于同质和异质数据集，在各种数据集上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在多个数据集上有效，为图对比学习提供了一种新的无增强框架，具有潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning (GCL) has recently made progress as anunsupervised graph representation learning paradigm. GCL approaches can becategorized into augmentation-based and augmentation-free methods. The formerrelies on complex data augmentations, while the latter depends on encoders thatcan generate distinct views of the same input. Both approaches may requirenegative samples for training. In this paper, we introduce a novelaugmentation-free GCL framework based on graph neural diffusion models.Specifically, we utilize learnable encoders governed by Fractional DifferentialEquations (FDE). Each FDE is characterized by an order parameter of thedifferential operator. We demonstrate that varying these parameters allows usto produce learnable encoders that generate diverse views, capturing eitherlocal or global information, for contrastive learning. Our model does notrequire negative samples for training and is applicable to both homophilic andheterophilic datasets. We demonstrate its effectiveness across variousdatasets, achieving state-of-the-art performance.</description>
      <author>example@mail.com (Yanan Zhao, Feng Ji, Kai Zhao, Xuhao Li, Qiyu Kang, Wenfei Liang, Yahya Alkhatib, Xingchao Jian, Wee Peng Tay)</author>
      <guid isPermaLink="false">2504.16748v2</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Physiological neural representation for personalised tracer kinetic parameter estimation from dynamic PET</title>
      <link>http://arxiv.org/abs/2504.17122v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code is available at: https://github.com/tkartikay/PhysNRPET&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于隐式神经网络表示（INRs）的生理神经网络，用于个人化的动态正电子发射断层扫描（PET）葡萄糖代谢参数估计，以提高图像分辨率和数据效率。&lt;h4&gt;背景&lt;/h4&gt;传统的PET葡萄糖代谢参数估计方法计算量大，空间分辨率有限，而深度神经网络（DNNs）虽然是一种替代方案，但需要大量训练数据和计算资源。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于INRs的生理神经网络，以解决传统方法计算量大和DNNs需要大量数据资源的问题。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了3D CT基础模型提供的解剖先验信息，以增强动力学的鲁棒性和精度，并在[$^{18}$F]FDG动态PET/CT数据集上进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法具有更高的空间分辨率，更低的均方误差，以及在肿瘤和高血管化区域中更好的解剖一致性。&lt;h4&gt;结论&lt;/h4&gt;INRs在个性化、数据高效的同位素示踪剂动力学建模中具有潜力，可以应用于肿瘤特征描述、分割和预后评估。&lt;h4&gt;翻译&lt;/h4&gt;Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enables non-invasive quantification of glucose metabolism through kinetic analysis, often modelled by the two-tissue compartment model (TCKM). However, voxel-wise kinetic parameter estimation using conventional methods is computationally intensive and limited by spatial resolution. Deep neural networks (DNNs) offer an alternative but require large training datasets and significant computational resources. To address these limitations, we propose a physiological neural representation based on implicit neural representations (INRs) for personalized kinetic parameter estimation. INRs, which learn continuous functions, allow for efficient, high-resolution parametric imaging with reduced data requirements. Our method also integrates anatomical priors from a 3D CT foundation model to enhance robustness and precision in kinetic modelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT dataset and compare it to state-of-the-art DNNs. Results demonstrate superior spatial resolution, lower mean-squared error, and improved anatomical consistency, particularly in tumour and highly vascularized regions. Our findings highlight the potential of INRs for personalized, data-efficient tracer kinetic modelling, enabling applications in tumour characterization, segmentation, and prognostic assessment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enablesnon-invasive quantification of glucose metabolism through kinetic analysis,often modelled by the two-tissue compartment model (TCKM). However, voxel-wisekinetic parameter estimation using conventional methods is computationallyintensive and limited by spatial resolution. Deep neural networks (DNNs) offeran alternative but require large training datasets and significantcomputational resources. To address these limitations, we propose aphysiological neural representation based on implicit neural representations(INRs) for personalized kinetic parameter estimation. INRs, which learncontinuous functions, allow for efficient, high-resolution parametric imagingwith reduced data requirements. Our method also integrates anatomical priorsfrom a 3D CT foundation model to enhance robustness and precision in kineticmodelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT datasetand compare it to state-of-the-art DNNs. Results demonstrate superior spatialresolution, lower mean-squared error, and improved anatomical consistency,particularly in tumour and highly vascularized regions. Our findings highlightthe potential of INRs for personalized, data-efficient tracer kineticmodelling, enabling applications in tumour characterization, segmentation, andprognostic assessment.</description>
      <author>example@mail.com (Kartikay Tehlan, Thomas Wendler)</author>
      <guid isPermaLink="false">2504.17122v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications</title>
      <link>http://arxiv.org/abs/2504.16972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了利用自动编码器和视觉Transformer进行无监督信号分析的最新进展，包括其架构、应用和新兴趋势。&lt;h4&gt;背景&lt;/h4&gt;无线通信、雷达、生物医学工程和物联网（IoT）等领域未标记时间序列数据的快速增长推动了无监督学习的进步。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探讨如何通过这些模型在多种信号类型中进行特征提取、异常检测和分类，如心电图、雷达波形和物联网传感器数据。&lt;h4&gt;方法&lt;/h4&gt;本文分析了混合架构和自监督学习的优势，同时识别了可解释性、可扩展性和领域泛化等方面的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;本文指出，混合架构和自监督学习具有优势，但在可解释性、可扩展性和领域泛化方面存在挑战。&lt;h4&gt;结论&lt;/h4&gt;通过结合方法创新和实际应用，本文为开发稳健、自适应的信号智能模型提供了路线图。&lt;h4&gt;翻译&lt;/h4&gt;This review synthesizes recent progress in applying autoencoders and vision transformers for unsupervised signal analysis, focusing on their architectures, applications, and emerging trends. We explore how these models enable feature extraction, anomaly detection, and classification across diverse signal types, including electrocardiograms, radar waveforms, and IoT sensor data. The review highlights the strengths of hybrid architectures and self-supervised learning, while identifying challenges in interpretability, scalability, and domain generalization. By bridging methodological innovations and practical applications, this work offers a roadmap for developing robust, adaptive models for signal intelligence.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of unlabeled time-series data in domains such as wirelesscommunications, radar, biomedical engineering, and the Internet of Things (IoT)has driven advancements in unsupervised learning. This review synthesizesrecent progress in applying autoencoders and vision transformers forunsupervised signal analysis, focusing on their architectures, applications,and emerging trends. We explore how these models enable feature extraction,anomaly detection, and classification across diverse signal types, includingelectrocardiograms, radar waveforms, and IoT sensor data. The review highlightsthe strengths of hybrid architectures and self-supervised learning, whileidentifying challenges in interpretability, scalability, and domaingeneralization. By bridging methodological innovations and practicalapplications, this work offers a roadmap for developing robust, adaptive modelsfor signal intelligence.</description>
      <author>example@mail.com (Hossein Ahmadi, Sajjad Emdadi Mahdimahalleh, Arman Farahat, Banafsheh Saffari)</author>
      <guid isPermaLink="false">2504.16972v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Vidi: Large Multimodal Models for Video Understanding and Editing</title>
      <link>http://arxiv.org/abs/2504.15681v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Vidi系列大型多模态模型（LMMs），用于广泛视频理解和编辑场景，并提出了VUE-TR基准，用于评估视频编辑中的时间检索任务。&lt;h4&gt;背景&lt;/h4&gt;人类自然地与他们联系的人共享信息，视频已成为互联网上主要的沟通和表达媒介。现代视频内容制作需要全面理解原始素材和编辑组件。&lt;h4&gt;目的&lt;/h4&gt;支持高质量大规模视频内容的创作，并解决视频编辑场景中对传统模型的挑战。&lt;h4&gt;方法&lt;/h4&gt;Vidi模型能够处理多种模态（如视觉、音频、文本）和灵活的输入长度（如时长为一小时的原始视频），并专注于时间检索任务。&lt;h4&gt;主要发现&lt;/h4&gt;Vidi在时间检索任务上显著优于GPT-4o和Gemini等领先模型，表明其在视频编辑场景中的优越性。VUE-TR基准引入了五个关键进步，包括视频时长、音频支持、多样化的查询格式、高质量的标注以及改进的评估指标。&lt;h4&gt;结论&lt;/h4&gt;Vidi在视频编辑场景中具有显著优势，为视频理解和编辑提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans naturally share information with those they are connected to, andvideo has become one of the dominant mediums for communication and expressionon the Internet. To support the creation of high-quality large-scale videocontent, a modern pipeline requires a comprehensive understanding of both theraw input materials (e.g., the unedited footage captured by cameras) and theediting components (e.g., visual effects). In video editing scenarios, modelsmust process multiple modalities (e.g., vision, audio, text) with strongbackground knowledge and handle flexible input lengths (e.g., hour-long rawvideos), which poses significant challenges for traditional models. In thisreport, we introduce Vidi, a family of Large Multimodal Models (LMMs) for awide range of video understand editing scenarios. The first release focuses ontemporal retrieval, i.e., identifying the time ranges within the input videoscorresponding to a given text query, which plays a critical role in intelligentediting. The model is capable of processing hour-long videos with strongtemporal understanding capability, e.g., retrieve time ranges for certainqueries. To support a comprehensive evaluation in real-world scenarios, we alsopresent the VUE-TR benchmark, which introduces five key advancements. 1) Videoduration: significantly longer than videos of existing temporal retrivaldatasets, 2) Audio support: includes audio-based queries, 3) Query format:diverse query lengths/formats, 4) Annotation quality: ground-truth time rangesare manually annotated. 5) Evaluation metric: a refined IoU metric to supportevaluation over multiple time ranges. Remarkably, Vidi significantlyoutperforms leading proprietary models, e.g., GPT-4o and Gemini, on thetemporal retrieval task, indicating its superiority in video editing scenarios.</description>
      <author>example@mail.com (Vidi Team, Celong Liu, Chia-Wen Kuo, Dawei Du, Fan Chen, Guang Chen, Jiamin Yuan, Lingxi Zhang, Lu Guo, Lusha Li, Longyin Wen, Qingyu Chen, Rachel Deng, Sijie Zhu, Stuart Siew, Tong Jin, Wei Lu, Wen Zhong, Xiaohui Shen, Xin Gu, Xing Mei, Xueqiong Qu)</author>
      <guid isPermaLink="false">2504.15681v2</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Bidirectional Mamba for Single-Cell Data: Efficient Context Learning with Biological Fidelity</title>
      <link>http://arxiv.org/abs/2504.16956v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GeneMamba，一个基于状态空间建模的可扩展和高效的单一细胞转录组学基础模型，用于解决单细胞RNA测序（scRNA-seq）分析中的复杂性问题。&lt;h4&gt;背景&lt;/h4&gt;scRNA-seq技术能够进行高分辨率细胞异质性分析，但其复杂性（高维性、稀疏性和批次效应）给计算带来了挑战。基于Transformer的模型在此领域取得了进展，但往往受到二次复杂性和对长距离依赖处理不佳的限制。&lt;h4&gt;目的&lt;/h4&gt;提出GeneMamba模型，旨在解决scRNA-seq分析中的计算挑战，并提高模型的性能和效率。&lt;h4&gt;方法&lt;/h4&gt;GeneMamba利用Bi-Mamba架构，以线性时间复杂度捕捉双向基因上下文，并通过近3000万个细胞的预训练和生物信息学目标（如路径感知对比损失和基于排名的基因编码）来提高模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;GeneMamba在多批次整合、细胞类型注释和基因-基因相关性等任务中表现出强大的性能、可解释性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;GeneMamba作为基于Transformer方法的实用且强大的替代品，推动了基于生物学的大规模单细胞数据分析工具的开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis ofcellular heterogeneity, but its complexity, which is marked by highdimensionality, sparsity, and batch effects, which poses major computationalchallenges. Transformer-based models have made significant advances in thisdomain but are often limited by their quadratic complexity and suboptimalhandling of long-range dependencies. In this work, we introduce GeneMamba, ascalable and efficient foundation model for single-cell transcriptomics builton state space modeling. Leveraging the Bi-Mamba architecture, GeneMambacaptures bidirectional gene context with linear-time complexity, offeringsubstantial computational gains over transformer baselines. The model ispretrained on nearly 30 million cells and incorporates biologically informedobjectives, including pathway-aware contrastive loss and rank-based geneencoding. We evaluate GeneMamba across diverse tasks, including multi-batchintegration, cell type annotation, and gene-gene correlation, demonstratingstrong performance, interpretability, and robustness. These results positionGeneMamba as a practical and powerful alternative to transformer-based methods,advancing the development of biologically grounded, scalable tools forlarge-scale single-cell data analysis.</description>
      <author>example@mail.com (Cong Qi, Hanzhang Fang, Tianxing Hu, Siqi Jiang, Wei Zhi)</author>
      <guid isPermaLink="false">2504.16956v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models</title>
      <link>http://arxiv.org/abs/2504.15929v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MedTrim的新方法，通过多模态三元组学习来增强图像和文本的匹配，以优化医学影像诊断。&lt;h4&gt;背景&lt;/h4&gt;随着医学影像数据的增加，对医学专家的压力增大，导致错误增多和工作流程积压。现有的基于对比学习的对齐方法在处理疾病分类和精细病理属性时存在不足。&lt;h4&gt;目的&lt;/h4&gt;提出MedTrim方法，通过元实体驱动的三元组挖掘来改善图像和文本的对齐，从而提高医学影像诊断的性能。&lt;h4&gt;方法&lt;/h4&gt;MedTrim方法包括：1）基于本体论的实体识别模块，从CXR报告中提取特定的元实体；2）一个新颖的评分函数，基于疾病分类和形容词/方向性描述符来衡量样本间的相似性；3）一个多模态三元组对齐目标，用于在具有详细病理特征的样本之间进行显式的跨模态对齐。&lt;h4&gt;主要发现&lt;/h4&gt;MedTrim在下游检索和分类任务中比现有的对齐方法提高了性能。&lt;h4&gt;结论&lt;/h4&gt;MedTrim通过利用结构化的元实体信息和改进的三元组学习，在医学影像诊断中实现了更优的图像和文本对齐。&lt;h4&gt;翻译&lt;/h4&gt;诊断影像依赖于对图像和放射学报告的解释，但随着数据量的增加，对医学专家的压力增大，导致错误增加和工作流程积压。医学视觉语言模型（med-VLMs）已经成为高效处理多模态影像数据的有力框架，特别是在胸部X射线（CXR）评估中，尽管其性能取决于图像和文本表示的对齐程度。现有的基于对比学习的对齐方法主要优先考虑疾病类别的分离，而不是精细病理属性（如位置、大小或严重程度）的分离，导致表示不理想。在这里，我们提出了MedTrim（元实体驱动的三元组挖掘），一种新颖的方法，通过疾病类别以及形容词和方向性病理描述符协同引导的多模态三元组学习来增强图像-文本对齐。与常见的分离广泛疾病类别的对齐方法不同，MedTrim利用结构化的元实体信息来保留细微但具有临床意义的类内变异。为此，我们首先引入了一个基于本体的实体识别模块，从CXR报告中提取病理特定的元实体，因为公共数据集中病理属性的注释很少。然后，我们引入了一个新颖的评分函数，它基于疾病类别和形容词/方向性描述符来捕获样本间相似性的综合度量。最后，我们引入了一个多模态三元组对齐目标，用于在具有详细病理特征的样本之间进行显式的跨模态对齐。我们的演示表明，与最先进的对齐方法相比，MedTrim在下游检索和分类任务中提高了性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diagnostic imaging relies on interpreting both images and radiology reports,but the growing data volumes place significant pressure on medical experts,yielding increased errors and workflow backlogs. Medical vision-language models(med-VLMs) have emerged as a powerful framework to efficiently processmultimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeittheir performance hinges on how well image and text representations arealigned. Existing alignment methods, predominantly based on contrastivelearning, prioritize separation between disease classes over segregation offine-grained pathology attributes like location, size or severity, leading tosuboptimal representations. Here, we propose MedTrim (Meta-entity-drivenTriplet mining), a novel method that enhances image-text alignment throughmultimodal triplet learning synergistically guided by disease class as well asadjectival and directional pathology descriptors. Unlike common alignmentmethods that separate broad disease classes, MedTrim leverages structuredmeta-entity information to preserve subtle but clinically significantintra-class variations. For this purpose, we first introduce an ontology-basedentity recognition module that extracts pathology-specific meta-entities fromCXR reports, as annotations on pathology attributes are rare in publicdatasets. For refined sample selection in triplet mining, we then introduce anovel score function that captures an aggregate measure of inter-samplesimilarity based on disease classes and adjectival/directional descriptors.Lastly, we introduce a multimodal triplet alignment objective for explicitwithin- and cross-modal alignment between samples sharing detailed pathologycharacteristics. Our demonstrations indicate that MedTrim improves performancein downstream retrieval and classification tasks compared to state-of-the-artalignment methods.</description>
      <author>example@mail.com (Saban Ozturk, Melih B. Yilmaz, Muti Kara, M. Talat Yavuz, Aykut Koç, Tolga Çukur)</author>
      <guid isPermaLink="false">2504.15929v2</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning</title>
      <link>http://arxiv.org/abs/2504.12597v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了GeoSense，一个用于评估多模态大型语言模型（MLLMs）几何推理能力的双语基准，并发现Gemini-2.0-pro-flash在该基准上表现最佳，但几何原理的识别和应用仍然是MLLMs推理能力的瓶颈。&lt;h4&gt;背景&lt;/h4&gt;几何问题解决（GPS）是一个需要视觉理解和符号推理的挑战性任务，可以有效地衡量MLLMs的推理能力。人类在该任务中表现出强大的推理能力，通过在视觉环境中准确识别和适应性应用几何原理。&lt;h4&gt;目的&lt;/h4&gt;为了系统地评估MLLMs的几何推理能力，论文提出了GeoSense，一个综合性的双语基准，旨在从几何原理的角度评估MLLMs的几何推理能力。&lt;h4&gt;方法&lt;/h4&gt;GeoSense具有一个涵盖平面和立体几何的五级层次框架的几何原理，以及一个包含1,789个问题的详细注释数据集和创新的评估策略。通过在GeoSense上对各种开源和闭源MLLMs进行广泛实验。&lt;h4&gt;主要发现&lt;/h4&gt;Gemini-2.0-pro-flash在GeoSense基准上取得了最佳成绩，总体得分为65.3。深入分析显示，几何原理的识别和应用仍然是领先MLLMs推理能力的瓶颈。&lt;h4&gt;结论&lt;/h4&gt;GeoSense有潜力指导未来MLLMs几何推理能力的进步，为人工智能中的更稳健和更类似人类的推理铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;Geometry problem-solving (GPS), a challenging task requiring both visual comprehension and symbolic reasoning, effectively measures the reasoning capabilities of multimodal large language models (MLLMs). Humans exhibit strong reasoning ability in this task through accurate identification and adaptive application of geometric principles within visual contexts. However, existing benchmarks fail to jointly assess both dimensions of the human-like geometric reasoning mechanism in MLLMs, remaining a critical gap in assessing their ability to tackle GPS. To this end, we introduce GeoSense, the first comprehensive bilingual benchmark designed to systematically evaluate the geometric reasoning abilities of MLLMs through the lens of geometric principles. GeoSense features a five-level hierarchical framework of geometric principles spanning plane and solid geometry, an intricately annotated dataset of 1,789 problems, and an innovative evaluation strategy. Through extensive experiments on GeoSense with various open-source and closed-source MLLMs, we observe that Gemini-2.0-pro-flash performs best, achieving an overall score of 65.3. Our in-depth analysis reveals that the identification and application of geometric principles remain a bottleneck for leading MLLMs, jointly hindering their reasoning abilities. These findings underscore GeoSense's potential to guide future advancements in MLLMs' geometric reasoning capabilities, paving the way for more robust and human-like reasoning in artificial intelligence.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometry problem-solving (GPS), a challenging task requiring both visualcomprehension and symbolic reasoning, effectively measures the reasoningcapabilities of multimodal large language models (MLLMs). Humans exhibit strongreasoning ability in this task through accurate identification and adaptiveapplication of geometric principles within visual contexts. However, existingbenchmarks fail to jointly assess both dimensions of the human-like geometricreasoning mechanism in MLLMs, remaining a critical gap in assessing theirability to tackle GPS. To this end, we introduce GeoSense, the firstcomprehensive bilingual benchmark designed to systematically evaluate thegeometric reasoning abilities of MLLMs through the lens of geometricprinciples. GeoSense features a five-level hierarchical framework of geometricprinciples spanning plane and solid geometry, an intricately annotated datasetof 1,789 problems, and an innovative evaluation strategy. Through extensiveexperiments on GeoSense with various open-source and closed-source MLLMs, weobserve that Gemini-2.0-pro-flash performs best, achieving an overall score of$65.3$. Our in-depth analysis reveals that the identification and applicationof geometric principles remain a bottleneck for leading MLLMs, jointlyhindering their reasoning abilities. These findings underscore GeoSense'spotential to guide future advancements in MLLMs' geometric reasoningcapabilities, paving the way for more robust and human-like reasoning inartificial intelligence.</description>
      <author>example@mail.com (Liangyu Xu, Yingxiu Zhao, Jingyun Wang, Yingyao Wang, Bu Pi, Chen Wang, Mingliang Zhang, Jihao Gu, Xiang Li, Xiaoyong Zhu, Jun Song, Bo Zheng)</author>
      <guid isPermaLink="false">2504.12597v2</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Intrinsic Barriers to Explaining Deep Foundation Models</title>
      <link>http://arxiv.org/abs/2504.16948v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了深度基础模型（DFMs）的复杂性和内部工作原理，分析了当前可解释性方法在面对这一内在挑战时的局限性，并探讨了实现令人满意的解释的可行性以及这些强大技术验证和治理的启示。&lt;h4&gt;背景&lt;/h4&gt;深度基础模型提供了前所未有的能力，但其日益增加的复杂性给理解其内部工作原理带来了巨大挑战，这对于确保信任、安全和问责制至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究DFMs的基本特征，审查当前可解释性方法在面临这一内在挑战时的局限性，并探讨如何实现令人满意的解释以及这些技术的验证和治理。&lt;h4&gt;方法&lt;/h4&gt;对DFMs的基本特征进行分析，审查当前可解释性方法的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;发现了DFMs的内在复杂性及其对可解释性的挑战，并探讨了实现满意解释的可行性。&lt;h4&gt;结论&lt;/h4&gt;提出了对DFMs验证和治理的新方法，强调了理解和解释这些模型的重要性。&lt;h4&gt;翻译&lt;/h4&gt;This paper delves into the critical question of the complexity and internal working principles of Deep Foundation Models (DFMs), analyzes the limitations encountered by current explainability methods when faced with this inherent challenge, and explores the feasibility of achieving satisfactory explanations and the implications for how we must approach the verification and governance of these powerful technologies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Foundation Models (DFMs) offer unprecedented capabilities but theirincreasing complexity presents profound challenges to understanding theirinternal workings-a critical need for ensuring trust, safety, andaccountability. As we grapple with explaining these systems, a fundamentalquestion emerges: Are the difficulties we face merely temporary hurdles,awaiting more sophisticated analytical techniques, or do they stem from\emph{intrinsic barriers} deeply rooted in the nature of these large-scalemodels themselves? This paper delves into this critical question by examiningthe fundamental characteristics of DFMs and scrutinizing the limitationsencountered by current explainability methods when confronted with thisinherent challenge. We probe the feasibility of achieving satisfactoryexplanations and consider the implications for how we must approach theverification and governance of these powerful technologies.</description>
      <author>example@mail.com (Zhen Tan, Huan Liu)</author>
      <guid isPermaLink="false">2504.16948v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Rank-based transfer learning for high-dimensional survival data with application to sepsis data</title>
      <link>http://arxiv.org/abs/2504.11270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了MSSA脓毒症，通过扩展现有的迁移学习框架，提高了高维生存数据的转换模型，并提供了置信区间构建算法，通过模拟和数据分析证明了方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;脓毒症死亡率高，预后复杂，研究MSSA脓毒症存在数据限制。&lt;h4&gt;目的&lt;/h4&gt;解决MSSA脓毒症研究中数据限制的问题，提高目标模型的性能。&lt;h4&gt;方法&lt;/h4&gt;构建基于C-index的测量指数以智能识别有用的源数据集，通过迁移步骤和去偏步骤利用识别的源数据集信息，提供置信区间构建算法，并严格建立统计性质。&lt;h4&gt;主要发现&lt;/h4&gt;扩展的迁移学习框架提高了目标模型性能，置信区间构建算法有效，统计性质严格建立。&lt;h4&gt;结论&lt;/h4&gt;该方法在MSSA脓毒症的生存估计方面提供了显著改进。&lt;h4&gt;翻译&lt;/h4&gt;Sepsis remains a critical challenge due to its high mortality and complex prognosis. To address data limitations in studying MSSA sepsis, we extend existing transfer learning frameworks to accommodate transformation models for high-dimensional survival data. Specifically, we construct a measurement index based on C-index for intelligently identifying the helpful source datasets, and the target model performance is improved by leveraging information from the identified source datasets via performing the transfer step and debiasing step. We further provide an algorithm to construct confidence intervals for each coefficient component. Another significant development is that statistical properties are rigorously established, including l1/l2-estimation error bounds of the transfer learning algorithm, detection consistency property of the transferable source detection algorithm and asymptotic theories for the confidence interval construction. Extensive simulations and analysis of MIMIC-IV sepsis data demonstrate the estimation and prediction accuracy, and practical advantages of our approach, providing significant improvements in survival estimates for MSSA sepsis patients.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sepsis remains a critical challenge due to its high mortality and complexprognosis. To address data limitations in studying MSSA sepsis, we extendexisting transfer learning frameworks to accommodate transformation models forhigh-dimensional survival data. Specifically, we construct a measurement indexbased on C-index for intelligently identifying the helpful source datasets, andthe target model performance is improved by leveraging information from theidentified source datasets via performing the transfer step and debiasing step.We further provide an algorithm to construct confidence intervals for eachcoefficient component. Another significant development is that statisticalproperties are rigorously established, including $\ell_1/\ell_2$-estimationerror bounds of the transfer learning algorithm, detection consistency propertyof the transferable source detection algorithm and asymptotic theories for theconfidence interval construction. Extensive simulations and analysis ofMIMIC-IV sepsis data demonstrate the estimation and prediction accuracy, andpractical advantages of our approach, providing significant improvements insurvival estimates for MSSA sepsis patients.</description>
      <author>example@mail.com (Nan Qiao, Haowei Jiang, Cunjie Lin)</author>
      <guid isPermaLink="false">2504.11270v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
  <item>
      <title>LIFT+: Lightweight Fine-Tuning for Long-Tail Learning</title>
      <link>http://arxiv.org/abs/2504.13282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在基础模型时代，微调策略对长尾学习性能的影响，并提出了一种名为LIFT+的创新轻量级微调框架，以优化基础模型的适应性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;微调已成为解决长尾学习任务的重要方法，但其对长尾学习性能的影响尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;研究微调策略对长尾学习性能的影响，并提出一种高效的微调框架。&lt;h4&gt;方法&lt;/h4&gt;通过理论分析和实验验证，发现重微调会导致尾部类别性能下降，而轻量级微调更有效。基于此，提出了LIFT+框架，包括语义感知初始化、最小化数据增强和测试时集成等方法。&lt;h4&gt;主要发现&lt;/h4&gt;重微调会导致尾部类别性能下降，而轻量级微调更有效，这一现象源于重微调导致的类别条件分布不一致。&lt;h4&gt;结论&lt;/h4&gt;LIFT+框架通过减少训练轮数和模型参数数量，提高了基础模型的适应性和泛化能力，在实验中表现优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：微调范式已成为基础模型时代解决长尾学习任务的重要方法。然而，微调策略对长尾学习性能的影响尚未得到充分探索。本研究发现，现有范式存在微调方法的滥用，在效率和精度上仍有很大的提升空间。具体而言，我们发现重微调（微调大量模型参数）会导致尾部类别性能显著下降，而轻量级微调表现出优越的有效性。通过全面的理论和实证验证，我们发现这种现象源于重微调导致的类别条件分布不一致。基于这一洞察，我们提出了LIFT+，一种创新的轻量级微调框架，以优化一致的类别条件。此外，LIFT+还包含了语义感知初始化、最小化数据增强和测试时集成等方法，以增强基础模型的适应性和泛化能力。我们的框架提供了一种高效且精确的流程，有助于快速收敛和模型紧凑性。广泛的实验表明，LIFT+显著减少了训练轮数（从约100轮减少到≤15轮）和学习的参数（少于1%），并且在大大超过现有方法。源代码可在https://github.com/shijxcs/LIFT-plus获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/shijxcs/lift-plus&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The fine-tuning paradigm has emerged as a prominent approach for addressinglong-tail learning tasks in the era of foundation models. However, the impactof fine-tuning strategies on long-tail learning performance remains unexplored.In this work, we disclose that existing paradigms exhibit a profound misuse offine-tuning methods, leaving significant room for improvement in bothefficiency and accuracy. Specifically, we reveal that heavy fine-tuning(fine-tuning a large proportion of model parameters) can lead to non-negligibleperformance deterioration on tail classes, whereas lightweight fine-tuningdemonstrates superior effectiveness. Through comprehensive theoretical andempirical validation, we identify this phenomenon as stemming from inconsistentclass conditional distributions induced by heavy fine-tuning. Building on thisinsight, we propose LIFT+, an innovative lightweight fine-tuning framework tooptimize consistent class conditions. Furthermore, LIFT+ incorporatessemantic-aware initialization, minimalist data augmentation, and test-timeensembling to enhance adaptation and generalization of foundation models. Ourframework provides an efficient and accurate pipeline that facilitates fastconvergence and model compactness. Extensive experiments demonstrate that LIFT+significantly reduces both training epochs (from $\sim$100 to $\leq$15) andlearned parameters (less than 1%), while surpassing state-of-the-art approachesby a considerable margin. The source code is available athttps://github.com/shijxcs/LIFT-plus.</description>
      <author>example@mail.com (Jiang-Xin Shi, Tong Wei, Yu-Feng Li)</author>
      <guid isPermaLink="false">2504.13282v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>An Accelerated Camera 3DMA Framework for Efficient Urban GNSS Multipath Estimation</title>
      <link>http://arxiv.org/abs/2504.16906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种加速框架，结合相机多视图立体重建和光线追踪技术，以提高城市环境中GNSS定位的鲁棒性，特别是在复杂信号传播条件下。&lt;h4&gt;背景&lt;/h4&gt;城市环境中的GNSS定位受多径效应的影响，特别是由于不同频率反射率表面的复杂信号传播。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以减少多径效应，同时保持计算效率和建模精度之间的平衡。&lt;h4&gt;方法&lt;/h4&gt;采用相机多视图立体重建和光线追踪技术，结合表面纹理假设，提出一个正交视觉特征融合框架，并整合多边形表面建模方案以细化重建。为了提高速度，采用重投影点云多平面拟合和两种复杂性控制策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在密集的城市环境中实现了平均2.4米的重建精度，并且在具有玻璃幕墙结构的困难案例中表现良好，同时基于光线追踪的多径校正速度达到每秒30帧图像，是当前基准的10倍。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效地减轻城市环境中的多径效应，显著提高GNSS定位的精度和速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust GNSS positioning in urban environments is still plagued by multipatheffects, particularly due to the complex signal propagation induced byubiquitous surfaces with varied radio frequency reflectivities. Current 3DMapping Aided (3DMA) GNSS techniques show great potentials in mitigatingmultipath but face a critical trade-off between computational efficiency andmodeling accuracy. Most approaches often rely on offline outdated oroversimplified 3D maps, while real-time LiDAR-based reconstruction boasts highaccuracy, it is problematic in low laser reflectivity conditions; camera 3DMAis a good candidate to balance accuracy and efficiency but current methodssuffer from extremely low reconstruction speed, a far cry from real-timemultipath-mitigated navigation. This paper proposes an accelerated frameworkincorporating camera multi-view stereo (MVS) reconstruction and ray tracing. Byhypothesizing on surface textures, an orthogonal visual feature fusionframework is proposed, which robustly addresses both texture-rich andtexture-poor surfaces, lifting off the reflectivity challenges in visualreconstruction. A polygonal surface modeling scheme is further integrated toaccurately delineate complex building boundaries, enhancing the reconstructiongranularity. To avoid excessively accurate reconstruction, reprojected pointcloud multi-plane fitting and two complexity control strategies are proposed,thus improving upon multipath estimation speed. Experiments were conducted inLujiazui, Shanghai, a typical multipath-prone district. The results show thatthe method achieves an average reconstruction accuracy of 2.4 meters in denseurban environments featuring glass curtain wall structures, a traditionallytough case for reconstruction, and achieves a ray-tracing-based multipathcorrection rate of 30 image frames per second, 10 times faster than thecontemporary benchmarks.</description>
      <author>example@mail.com (Shiyao Lv, Xin Zhang, Xingqun Zhan)</author>
      <guid isPermaLink="false">2504.16906v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>I-Con: A Unifying Framework for Representation Learning</title>
      <link>http://arxiv.org/abs/2504.16929v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025; website: https://aka.ms/i-con . Proceedings of the  Thirteenth International Conference on Learning Representations (ICLR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种信息论方程，它概括了机器学习中大量现代损失函数，并展示了一种框架，表明多种机器学习方法实际上是在最小化两个条件分布（监督表示和学到的表示）之间的集成KL散度。这一观点揭示了聚类、谱方法、降维、对比学习和监督学习背后的潜在信息几何。该框架允许通过结合文献中的成功技术来开发新的损失函数。&lt;h4&gt;背景&lt;/h4&gt;随着表示学习领域的增长，出现了大量不同的损失函数来解决不同类别的问题。&lt;h4&gt;目的&lt;/h4&gt;引入一个信息论方程，概括机器学习中大量现代损失函数，并展示一个框架来揭示不同机器学习方法的共同特征。&lt;h4&gt;方法&lt;/h4&gt;提出一个框架，该框架表明多种机器学习方法实际上是在最小化两个条件分布之间的集成KL散度。通过结合文献中的成功技术来开发新的损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;揭示了聚类、谱方法、降维、对比学习和监督学习背后的潜在信息几何。通过理论结果创建了先进的无监督图像分类器，在ImageNet-1K上的无监督分类上比之前的方法提高了8%。还证明了I-Con可以用于推导出提高对比表示学习者的原理性去偏方法。&lt;h4&gt;结论&lt;/h4&gt;该框架有助于理解和开发新的机器学习损失函数，同时提高了无监督图像分类的性能，并为去偏方法提供了理论基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着表示学习领域的增长，出现了大量不同的损失函数来解决不同类别的问题。我们引入了一个单一的信息论方程，它概括了机器学习中大量现代损失函数。特别是，我们引入了一个框架，表明多种机器学习方法实际上是在最小化两个条件分布之间的集成KL散度：监督表示和学到的表示。这一观点揭示了聚类、谱方法、降维、对比学习和监督学习背后的潜在信息几何。这个框架通过结合文献中的成功技术来开发新的损失函数。我们不仅提出了一系列证明，连接了23种不同的方法，而且利用这些理论结果创建了最先进的无监督图像分类器，在ImageNet-1K上的无监督分类上比之前的方法提高了8%。我们还证明了I-Con可以用于推导出提高对比表示学习者的原理性去偏方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the field of representation learning grows, there has been a proliferationof different loss functions to solve different classes of problems. Weintroduce a single information-theoretic equation that generalizes a largecollection of modern loss functions in machine learning. In particular, weintroduce a framework that shows that several broad classes of machine learningmethods are precisely minimizing an integrated KL divergence between twoconditional distributions: the supervisory and learned representations. Thisviewpoint exposes a hidden information geometry underlying clustering, spectralmethods, dimensionality reduction, contrastive learning, and supervisedlearning. This framework enables the development of new loss functions bycombining successful techniques from across the literature. We not only presenta wide array of proofs, connecting over 23 different approaches, but we alsoleverage these theoretical results to create state-of-the-art unsupervisedimage classifiers that achieve a +8% improvement over the priorstate-of-the-art on unsupervised classification on ImageNet-1K. We alsodemonstrate that I-Con can be used to derive principled debiasing methods whichimprove contrastive representation learners.</description>
      <author>example@mail.com (Shaden Alshammari, John Hershey, Axel Feldmann, William T. Freeman, Mark Hamilton)</author>
      <guid isPermaLink="false">2504.16929v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>WiFi based Human Fall and Activity Recognition using Transformer based Encoder Decoder and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.16655v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TED Net的新型架构，用于从WiFi信道状态信息中估计人体骨骼姿态，并应用于动作识别。&lt;h4&gt;背景&lt;/h4&gt;人体姿态估计和动作识别在医疗监测、康复和辅助技术中发挥着重要作用。&lt;h4&gt;目的&lt;/h4&gt;设计TED Net以从WiFi信道状态信息中估计人体骨骼姿态，并使用估计的姿态作为输入进行动作识别。&lt;h4&gt;方法&lt;/h4&gt;TED Net结合了卷积编码器和基于transformer的注意力机制来捕捉CSI信号的时空特征。使用估计的骨骼姿态作为输入到定制的有向图神经网络（DGNN）中进行动作识别。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，TED Net在姿态估计方面优于现有方法，DGNN使用基于CSI的骨骼进行动作分类时表现出可靠的性能，与基于RGB的系统相当。TED Net在跌倒和非跌倒情况下都保持了鲁棒的性能。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了CSI驱动的骨骼姿态估计在有效动作识别中的潜力，尤其是在家庭环境中的老人跌倒检测。在这些环境中，WiFi信号通常容易获得，为基于视觉的方法提供了一种保护隐私的替代方案。&lt;h4&gt;翻译&lt;/h4&gt;Human pose estimation and action recognition have received attention due to their critical roles in healthcare monitoring, rehabilitation, and assistive technologies. In this study, we proposed a novel architecture named Transformer-based Encoder Decoder Network (TED Net) designed for estimating human skeleton poses from WiFi Channel State Information (CSI). TED Net integrates convolutional encoders with transformer based attention mechanisms to capture spatiotemporal features from CSI signals. The estimated skeleton poses were used as input to a customized Directed Graph Neural Network (DGNN) for action recognition. We validated our model on two datasets: a publicly available multimodal dataset for assessing general pose estimation, and a newly collected dataset focused on fall related scenarios involving 20 participants. Experimental results demonstrated that TED Net outperformed existing approaches in pose estimation, and that the DGNN achieves reliable action classification using CSI based skeletons, with performance comparable to RGB based systems. Notably, TED Net maintains robust performance across both fall and non fall cases. These findings highlight the potential of CSI driven human skeleton estimation for effective action recognition, particularly in home environments such as elderly fall detection. In such settings, WiFi signals are often readily available, offering a privacy preserving alternative to vision based methods, which may raise concerns about continuous camera monitoring.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human pose estimation and action recognition have received attention due totheir critical roles in healthcare monitoring, rehabilitation, and assistivetechnologies. In this study, we proposed a novel architecture named Transformerbased Encoder Decoder Network (TED Net) designed for estimating human skeletonposes from WiFi Channel State Information (CSI). TED Net integratesconvolutional encoders with transformer based attention mechanisms to capturespatiotemporal features from CSI signals. The estimated skeleton poses wereused as input to a customized Directed Graph Neural Network (DGNN) for actionrecognition. We validated our model on two datasets: a publicly available multimodal dataset for assessing general pose estimation, and a newly collecteddataset focused on fall related scenarios involving 20 participants.Experimental results demonstrated that TED Net outperformed existing approachesin pose estimation, and that the DGNN achieves reliable action classificationusing CSI based skeletons, with performance comparable to RGB based systems.Notably, TED Net maintains robust performance across both fall and non fallcases. These findings highlight the potential of CSI driven human skeletonestimation for effective action recognition, particularly in home environmentssuch as elderly fall detection. In such settings, WiFi signals are oftenreadily available, offering a privacy preserving alternative to vision basedmethods, which may raise concerns about continuous camera monitoring.</description>
      <author>example@mail.com (Younggeol Cho, Elisa Motta, Olivia Nocentini, Marta Lagomarsino, Andrea Merello, Marco Crepaldi, Arash Ajoudani)</author>
      <guid isPermaLink="false">2504.16655v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Generalized Neighborhood Attention: Multi-dimensional Sparse Attention at the Speed of Light</title>
      <link>http://arxiv.org/abs/2504.16922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://github.com/SHI-Labs/NATTEN/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了聚焦于局部性的稀疏注意力机制，并旨在分析其性能改进。提出了一种名为广义邻域注意力（GNA）的新机制，并在CUDA架构上实现了它。&lt;h4&gt;背景&lt;/h4&gt;传统的稀疏注意力机制如邻域注意力未能持续提升速度，原因是注意力基础设施的复杂性和AI硬件架构的快速演进。同时，许多基础模型，尤其在计算机视觉领域，受到注意力机制的严重限制，需要可靠的稀疏性来避免O(n^2)的复杂度。&lt;h4&gt;目的&lt;/h4&gt;研究一种聚焦于局部性的稀疏注意力机制，并分析其性能改进。&lt;h4&gt;方法&lt;/h4&gt;提出了广义邻域注意力（GNA）机制，考虑了实现这些方法的可能设计选择，并创建了一个模拟器以提供更真实的加速上限。在CUDA架构的CUTLASS上实现了GNA，并对其进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;GNA在许多完全块稀疏情况下能够实现理论上的最大加速，并且在FP16模式下实现了1.3 petaFLOPs/second的有效利用率。将GNA配置集成到现成的生成模型中，如Cosmos-7B、HunyuanVideo和FLUX，在B200上实现了28%到46%的端到端速度提升，无需微调。&lt;h4&gt;结论&lt;/h4&gt;本文提出的GNA机制在提升模型速度方面具有潜力，且在实际应用中取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了多种稀疏注意力机制，如邻域注意力等，通常未能持续提升速度。这主要是由于注意力基础设施的复杂性和AI硬件架构的快速演进。与此同时，许多最先进的底层模型，尤其是在计算机视觉领域，严重依赖于注意力机制，需要可靠的稀疏性来克服O(n^2)的复杂度。在本文中，我们研究了一类有前景的聚焦于局部性的稀疏注意力机制，旨在分析其性能改进。首先，我们引入了广义邻域注意力（GNA），它可以描述滑动窗口、步进滑动窗口和块注意力。然后，我们考虑了实现这些方法的可能设计选择，并创建了一个模拟器，可以为任何给定设置提供更真实的加速上限。最后，我们在CUDA架构的CUTLASS上实现了GNA，并对其进行了评估。我们的实现可以在许多完全块稀疏的情况下实现理论上的最大加速，并在FP16模式下实现了1.3 petaFLOPs/second的有效利用率。此外，我们将各种GNA配置集成到现成的生成模型中，如Cosmos-7B、HunyuanVideo和FLUX，并在B200上实现了28%到46%的端到端速度提升，无需微调。我们将通过NATTEN项目开源我们的模拟器和Blackwell内核。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many sparse attention mechanisms such as Neighborhood Attention havetypically failed to consistently deliver speedup over the self attentionbaseline. This is largely due to the level of complexity in attentioninfrastructure, and the rapid evolution of AI hardware architecture. At thesame time, many state-of-the-art foundational models, particularly in computervision, are heavily bound by attention, and need reliable sparsity to escapethe O(n^2) complexity. In this paper, we study a class of promising sparseattention mechanisms that focus on locality, and aim to develop a betteranalytical model of their performance improvements. We first introduceGeneralized Neighborhood Attention (GNA), which can describe sliding window,strided sliding window, and blocked attention. We then consider possible designchoices in implementing these approaches, and create a simulator that canprovide much more realistic speedup upper bounds for any given setting.Finally, we implement GNA on top of a state-of-the-art fused multi-headedattention (FMHA) kernel designed for the NVIDIA Blackwell architecture inCUTLASS. Our implementation can fully realize the maximum speedup theoreticallypossible in many perfectly block-sparse cases, and achieves an effectiveutilization of 1.3 petaFLOPs/second in FP16. In addition, we plug various GNAconfigurations into off-the-shelf generative models, such as Cosmos-7B,HunyuanVideo, and FLUX, and show that it can deliver 28% to 46% end-to-endspeedup on B200 without any fine-tuning. We will open source our simulator andBlackwell kernels directly through the NATTEN project.</description>
      <author>example@mail.com (Ali Hassani, Fengzhe Zhou, Aditya Kane, Jiannan Huang, Chieh-Yun Chen, Min Shi, Steven Walton, Markus Hoehnerbach, Vijay Thakkar, Michael Isaev, Qinsheng Zhang, Bing Xu, Haicheng Wu, Wen-mei Hwu, Ming-Yu Liu, Humphrey Shi)</author>
      <guid isPermaLink="false">2504.16922v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Common Functional Decompositions Can Mis-attribute Differences in Outcomes Between Populations</title>
      <link>http://arxiv.org/abs/2504.16864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, appearing in 2nd Workshop on Navigating and Addressing Data  Problems for Foundation Models (DATA-FM @ ICLR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在科学和社会科学中解释两个群体之间结果差异的原因，提出了一种扩展Kitagawa-Oaxaca-Blinder（KOB）分解方法，以处理非线性关系。&lt;h4&gt;背景&lt;/h4&gt;在经济学中，KOB分解被用来解释两个群体之间均值结果的差异，但它假设了协变量和结果之间的线性关系。&lt;h4&gt;目的&lt;/h4&gt;目的是使用现代机器学习的非线性功能分解来扩展KOB分解，以更准确地解释结果差异。&lt;h4&gt;方法&lt;/h4&gt;研究了两种常见的分解方法——功能ANOVA和累积局部效应，并分析了它们在处理协变量和结果之间的非线性关系时的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;发现这两种分解方法可能会将差异归因于协变量，即使在这些协变量在两个群体中是相同的。&lt;h4&gt;结论&lt;/h4&gt;提出了一种避免归因错误的分解方法，即当分解与输入分布无关时，不会发生错误归因。并推测在依赖于协变量分布的任何合理的加性分解中，都可能发生错误归因。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在科学和社会科学中，我们经常希望解释为什么两个群体中的结果不同。例如，如果一个就业计划对一个城市的成员比对另一个城市的成员更有利，这是否是由于项目参与者的差异（特定的协变量）还是当地劳动市场的差异（给定协变量的结果）？Kitagawa-Oaxaca-Blinder（KOB）分解是计量经济学中解释两个群体之间均值结果差异的标准工具。然而，KOB分解假设协变量和结果之间存在线性关系，而真实关系可能是有意义的非线性。现代机器学习在单个人群中结果和协变量之间的关系方面拥有各种非线性功能分解。使用这些功能分解扩展KOB分解似乎是自然而然的。我们发现，一个成功的扩展不应将差异归因于协变量——或者相应地，给定协变量的结果——如果这些在两个群体中是相同的。不幸的是，我们证明了即使在简单的例子中，两种常见的分解——功能ANOVA和累积局部效应——也可以将差异归因于给定协变量的结果，即使它们在两个群体中是相同的。我们提供了功能ANOVA错误归因时的描述，以及任何离散分解必须满足的通用属性以避免错误归因。我们表明，如果分解与其输入分布无关，则不会发生错误归因。我们进一步推测，在任何合理的依赖于协变量分布的加性分解中，都可能发生错误归因。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In science and social science, we often wish to explain why an outcome isdifferent in two populations. For instance, if a jobs program benefits membersof one city more than another, is that due to differences in programparticipants (particular covariates) or the local labor markets (outcomes givencovariates)? The Kitagawa-Oaxaca-Blinder (KOB) decomposition is a standard toolin econometrics that explains the difference in the mean outcome across twopopulations. However, the KOB decomposition assumes a linear relationshipbetween covariates and outcomes, while the true relationship may bemeaningfully nonlinear. Modern machine learning boasts a variety of nonlinearfunctional decompositions for the relationship between outcomes and covariatesin one population. It seems natural to extend the KOB decomposition using thesefunctional decompositions. We observe that a successful extension should notattribute the differences to covariates -- or, respectively, to outcomes givencovariates -- if those are the same in the two populations. Unfortunately, wedemonstrate that, even in simple examples, two common decompositions --functional ANOVA and Accumulated Local Effects -- can attribute differences tooutcomes given covariates, even when they are identical in two populations. Weprovide a characterization of when functional ANOVA misattributes, as well as ageneral property that any discrete decomposition must satisfy to avoidmisattribution. We show that if the decomposition is independent of its inputdistribution, it does not misattribute. We further conjecture thatmisattribution arises in any reasonable additive decomposition that depends onthe distribution of the covariates.</description>
      <author>example@mail.com (Manuel Quintero, William T. Stephenson, Advik Shreekumar, Tamara Broderick)</author>
      <guid isPermaLink="false">2504.16864v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>A Low-Cost Photogrammetry System for 3D Plant Modeling and Phenotyping</title>
      <link>http://arxiv.org/abs/2504.16840v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种开源、低成本的光测测距系统，用于3D植物建模和表型分析。&lt;h4&gt;背景&lt;/h4&gt;植物表型分析对于了解植物性状至关重要，传统方法成本高，操作复杂。&lt;h4&gt;目的&lt;/h4&gt;开发一个系统，以降低植物表型分析的成本并提高效率。&lt;h4&gt;方法&lt;/h4&gt;该系统采用运动结构法，通过点云重建植物的3D表示，并以小麦为例，展示了如何从点云中计算各种表型特征。&lt;h4&gt;主要发现&lt;/h4&gt;系统能够容易地计算植物高度、半径、叶片角度和凸包等标准测量值和手工测量困难的特征。&lt;h4&gt;结论&lt;/h4&gt;该系统对于客观分类直立型小麦和水平型小麦冠层结构等特定指标具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;We present an open-source, low-cost photogrammetry system for 3D plant modeling and phenotyping. The system uses a structure-from-motion approach to reconstruct 3D representations of the plants via point clouds. Using wheat as an example, we demonstrate how various phenotypic traits can be computed easily from the point clouds. These include standard measurements such as plant height and radius, as well as features that would be more cumbersome to measure by hand, such as leaf angles and convex hull. We further demonstrate the utility of the system through the investigation of specific metrics that may yield objective classifications of erectophile versus planophile wheat canopy architectures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present an open-source, low-cost photogrammetry system for 3D plantmodeling and phenotyping. The system uses a structure-from-motion approach toreconstruct 3D representations of the plants via point clouds. Using wheat asan example, we demonstrate how various phenotypic traits can be computed easilyfrom the point clouds. These include standard measurements such as plant heightand radius, as well as features that would be more cumbersome to measure byhand, such as leaf angles and convex hull. We further demonstrate the utilityof the system through the investigation of specific metrics that may yieldobjective classifications of erectophile versus planophile wheat canopyarchitectures.</description>
      <author>example@mail.com (Joe Hrzich, Michael A. Beck, Christopher P. Bidinosti, Christopher J. Henry, Kalhari Manawasinghe, Karen Tanino)</author>
      <guid isPermaLink="false">2504.16840v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Simple Graph Contrastive Learning via Fractional-order Neural Diffusion Networks</title>
      <link>http://arxiv.org/abs/2504.16748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICML&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于图神经扩散模型的新的无增强Graph Contrastive Learning (GCL)框架，该框架通过分数微分方程（FDE）生成的可学习编码器来生成多样化的视图，从而实现对比学习。该模型无需负样本进行训练，适用于同质和异质数据集，并在多个数据集上实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;Graph Contrastive Learning (GCL)作为无监督的图表示学习方法近年来取得了进展。GCL方法可分为基于增强和无需增强的方法，前者依赖于复杂的数据增强，而后者依赖于可以生成相同输入的不同视图的编码器。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无增强的GCL框架，无需负样本训练，适用于同质和异质数据集，并在多个数据集上实现最先进的性能。&lt;h4&gt;方法&lt;/h4&gt;利用受分数微分方程（FDE）控制的可学习编码器，每个FDE由微分算子的阶数参数表征，通过改变这些参数来生成多样化的视图，捕捉局部或全局信息，用于对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;该模型不需要负样本进行训练，并且适用于同质和异质数据集。&lt;h4&gt;结论&lt;/h4&gt;该模型在多个数据集上实现了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Contrastive Learning (GCL)最近作为无监督的图表示学习方法取得了进展。GCL方法可以分为基于增强和无需增强的方法。前者依赖于复杂的数据增强，而后者依赖于可以生成相同输入的不同视图的编码器。在本文中，我们介绍了一种基于图神经扩散模型的新型无增强GCL框架。具体来说，我们利用受分数微分方程（FDE）控制的可学习编码器。每个FDE由微分算子的阶数参数表征。我们证明了通过改变这些参数，我们可以生成可学习编码器，生成多样化的视图，捕捉局部或全局信息，用于对比学习。我们的模型无需负样本进行训练，适用于同质和异质数据集。我们在多个数据集上证明了其有效性，实现了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning (GCL) has recently made progress as anunsupervised graph representation learning paradigm. GCL approaches can becategorized into augmentation-based and augmentation-free methods. The formerrelies on complex data augmentations, while the latter depends on encoders thatcan generate distinct views of the same input. Both approaches may requirenegative samples for training. In this paper, we introduce a novelaugmentation-free GCL framework based on graph neural diffusion models.Specifically, we utilize learnable encoders governed by Fractional DifferentialEquations (FDE). Each FDE is characterized by an order parameter of thedifferential operator. We demonstrate that varying these parameters allows usto produce learnable encoders that generate diverse views, capturing eitherlocal or global information, for contrastive learning. Our model does notrequire negative samples for training and is applicable to both homophilic andheterophilic datasets. We demonstrate its effectiveness across variousdatasets, achieving state-of-the-art performance.</description>
      <author>example@mail.com (Yanan Zhao, Feng Ji, Kai Zhao, Xuhao Li, Qiyu Kang, Wenfei Liang, Yahya Alkhatib, Xingchao Jian, Wee Peng Tay)</author>
      <guid isPermaLink="false">2504.16748v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception</title>
      <link>http://arxiv.org/abs/2504.16616v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EHGCN的新型方法，用于在欧几里得和双曲空间中感知事件流，以解决现有基于图神经网络的方法在处理非均匀分布事件流时难以捕捉长距离依赖和内在层次结构的问题。&lt;h4&gt;背景&lt;/h4&gt;事件相机具有微秒级时间分辨率和高动态范围特性，但在使用基于图神经网络的感知方法时，它们在纯欧几里得空间中使用简单的成对连接机制，难以捕捉长距离依赖和有效表征事件流的内在层次结构。&lt;h4&gt;目的&lt;/h4&gt;提出EHGCN方法，以感知事件流，同时解决长距离依赖和层次结构表征的问题。&lt;h4&gt;方法&lt;/h4&gt;EHGCN方法包括：1. 引入自适应采样策略以动态调节采样率，保留判别性事件同时降低混沌噪声；2. 基于运动状态转换概率的Markov向量场（MVF）驱动的运动感知超边生成方法，消除跨目标的虚假关联并提供关键拓扑先验，同时捕捉事件之间的长距离依赖；3. 提出欧几里得-双曲GCN，融合在欧几里得和双曲空间中局部聚合和全局层次建模的信息，以实现混合事件感知。&lt;h4&gt;主要发现&lt;/h4&gt;EHGCN方法在事件感知任务（如物体检测和识别）上验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;EHGCN方法能够有效提升事件感知任务的性能，特别是在处理非均匀分布事件流时，能够更好地捕捉长距离依赖和内在层次结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras, with microsecond temporal resolution and high dynamic range(HDR) characteristics, emit high-speed event stream for perception tasks.Despite the recent advancement in GNN-based perception methods, they are proneto use straightforward pairwise connectivity mechanisms in the pure Euclideanspace where they struggle to capture long-range dependencies and fail toeffectively characterize the inherent hierarchical structures of non-uniformlydistributed event stream. To this end, in this paper we propose a novelapproach named EHGCN, which is a pioneer to perceive event stream in bothEuclidean and hyperbolic spaces for event vision. In EHGCN, we introduce anadaptive sampling strategy to dynamically regulate sampling rates, retainingdiscriminative events while attenuating chaotic noise. Then we present a MarkovVector Field (MVF)-driven motion-aware hyperedge generation method based onmotion state transition probabilities, thereby eliminating cross-targetspurious associations and providing critically topological priors whilecapturing long-range dependencies between events. Finally, we propose aEuclidean-Hyperbolic GCN to fuse the information locally aggregated andglobally hierarchically modeled in Euclidean and hyperbolic spaces,respectively, to achieve hybrid event perception. Experimental results on eventperception tasks such as object detection and recognition validate theeffectiveness of our approach.</description>
      <author>example@mail.com (Haosheng Chen, Lian Luo, Mengjingcheng Mo, Zhanjie Wu, Guobao Xiao, Ji Gan, Jiaxu Leng, Xinbo Gao)</author>
      <guid isPermaLink="false">2504.16616v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>An Adaptive ML Framework for Power Converter Monitoring via Federated Transfer Learning</title>
      <link>http://arxiv.org/abs/2504.16866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2025 IEEE. Personal use of this material is permitted. Permission  from IEEE must be obtained for all other uses, in any current or future  media, including reprinting/republishing this material for advertising or  promotional purposes, creating new collective works, for resale or  redistribution to servers or lists, or reuse of any copyrighted component of  this work in other works&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了通过结合迁移学习和联邦学习，以分段方式调整热力学机器学习模型配置，以适应电力转换器。&lt;h4&gt;背景&lt;/h4&gt;研究旨在解决电力转换器在操作条件变化、数据共享限制和安全影响等方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究目的是开发一种框架，能够通过多种客户端增量地调整基础模型，以适应不同的应用场景。&lt;h4&gt;方法&lt;/h4&gt;该框架使用三种最先进的领域自适应技术：微调、迁移成分分析（TCA）和深度领域自适应（DDA）。联邦学习（FL）使用Flower框架和联邦平均进行聚合。&lt;h4&gt;主要发现&lt;/h4&gt;验证结果表明，微调是一种简单直接的迁移学习方法，具有高精度，适用于实际应用。基准测试结果揭示了这些方法在不同场景下的优缺点。本地部署的FL在数据聚合不可行时提高了性能，而基于云的FL在客户端数量显著增加时更加实用，解决了可扩展性和连接性问题。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的框架能够有效解决电力转换器中机器学习模型的适应性挑战，并通过不同的部署方式提高了模型的性能和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TPEL.2025.3559132&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores alternative framework configurations for adapting thermalmachine learning (ML) models for power converters by combining transferlearning (TL) and federated learning (FL) in a piecewise manner. This approachinherently addresses challenges such as varying operating conditions, datasharing limitations, and security implications. The framework starts with abase model that is incrementally adapted by multiple clients via adapting threestate-of-the-art domain adaptation techniques: Fine-tuning, Transfer ComponentAnalysis (TCA), and Deep Domain Adaptation (DDA). The Flower framework isemployed for FL, using Federated Averaging for aggregation. Validation withfield data demonstrates that fine-tuning offers a straightforward TL approachwith high accuracy, making it suitable for practical applications. Benchmarkingresults reveal a comprehensive comparison of these methods, showcasing theirrespective strengths and weaknesses when applied in different scenarios.Locally hosted FL enhances performance when data aggregation is not feasible,while cloud-based FL becomes more practical with a significant increase in thenumber of clients, addressing scalability and connectivity challenges.</description>
      <author>example@mail.com (Panagiotis Kakosimos, Alireza Nemat Saberi, Luca Peretti)</author>
      <guid isPermaLink="false">2504.16866v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Decoupled Global-Local Alignment for Improving Compositional Understanding</title>
      <link>http://arxiv.org/abs/2504.16801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CLIP模型通过图像和文本模态的对齐在多个下游任务中取得了成功，但全局对比学习的性质限制了其对组合概念（如关系和属性）的理解能力。本文提出了一种Decoupled Global-Local Alignment (DeGLA)框架，在提高组合理解能力的同时，显著减少了模型在一般能力上的损失。&lt;h4&gt;背景&lt;/h4&gt;CLIP模型通过图像和文本模态的对齐取得了成功，但其对组合概念的理解能力受到限制。&lt;h4&gt;目的&lt;/h4&gt;克服CLIP模型在组合理解能力上的限制，同时保持模型的一般能力。&lt;h4&gt;方法&lt;/h4&gt;引入Decoupled Global-Local Alignment (DeGLA)框架，通过自我蒸馏机制优化模型能力保留，并利用LLMs构建大量高质量负样本，同时提出Image-Grounded Contrast (IGC)和Text-Grounded Contrast (TGC)损失函数来增强视觉语言组合能力。&lt;h4&gt;主要发现&lt;/h4&gt;DeGLA框架在多个基准测试中表现出色，相比之前的方法，在VALSE、SugarCrepe和ARO基准测试上平均提升了3.5%，在零样本分类任务上平均提升了13.0%。&lt;h4&gt;结论&lt;/h4&gt;DeGLA框架能够有效提高CLIP模型对组合概念的理解能力，同时保持模型的一般能力。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive Language-Image Pre-training (CLIP)通过对齐图像和文本模态在多个下游任务上取得了成功。然而，全局对比学习的性质限制了CLIP理解组合概念（如关系和属性）的能力。尽管最近的研究通过使用全局硬负样本来提高组合理解，但这些方法通过在嵌入空间中强制将文本负样本与图像分离，显著降低了模型固有的通用能力。为了克服这一限制，我们提出了一种解耦全局-局部对齐（DeGLA）框架，在提高组合理解能力的同时，显著减少了模型在一般能力上的损失。为了优化模型固有能力的保留，我们在全局对齐过程中引入了自我蒸馏机制，将可学习的图像-文本编码器与由指数移动平均得到的冻结教师模型对齐。在自我蒸馏的约束下，它有效地缓解了微调期间预训练知识的灾难性遗忘。为了提高组合理解，我们首先利用大型语言模型（LLMs）的上下文学习能力构建了约200万个高质量负标题。随后，我们提出了图像基础对比（IGC）损失和文本基础对比（TGC）损失来增强视觉-语言组合。广泛的实验结果表明了DeGLA框架的有效性。与之前的最先进方法相比，DeGLA在VALSE、SugarCrepe和ARO基准测试上平均提高了3.5%。同时，它在十一个数据集上的零样本分类任务上平均提高了13.0%。我们的代码将在https://github.com/xiaoxing2001/DeGLA上发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Language-Image Pre-training (CLIP) has achieved success onmultiple downstream tasks by aligning image and text modalities. However, thenature of global contrastive learning limits CLIP's ability to comprehendcompositional concepts, such as relations and attributes. Although recentstudies employ global hard negative samples to improve compositionalunderstanding, these methods significantly compromise the model's inherentgeneral capabilities by forcibly distancing textual negative samples fromimages in the embedding space. To overcome this limitation, we introduce aDecoupled Global-Local Alignment (DeGLA) framework that improves compositionalunderstanding while substantially mitigating losses in general capabilities. Tooptimize the retention of the model's inherent capabilities, we incorporate aself-distillation mechanism within the global alignment process, aligning thelearnable image-text encoder with a frozen teacher model derived from anexponential moving average. Under the constraint of self-distillation, iteffectively mitigates the catastrophic forgetting of pretrained knowledgeduring fine-tuning. To improve compositional understanding, we first leveragethe in-context learning capability of Large Language Models (LLMs) to constructabout 2M high-quality negative captions across five types. Subsequently, wepropose the Image-Grounded Contrast (IGC) loss and Text-Grounded Contrast (TGC)loss to enhance vision-language compositionally. Extensive experimental resultsdemonstrate the effectiveness of the DeGLA framework. Compared to previousstate-of-the-art methods, DeGLA achieves an average enhancement of 3.5% acrossthe VALSE, SugarCrepe, and ARO benchmarks. Concurrently, it obtains an averageperformance improvement of 13.0% on zero-shot classification tasks acrosseleven datasets. Our code will be released athttps://github.com/xiaoxing2001/DeGLA</description>
      <author>example@mail.com (Xiaoxing Hu, Kaicheng Yang, Jun Wang, Haoran Xu, Ziyong Feng, Yupei Wang)</author>
      <guid isPermaLink="false">2504.16801v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Gaussian Splatting is an Effective Data Generator for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.16740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了自动驾驶中3D物体检测的数据增强方法。&lt;h4&gt;背景&lt;/h4&gt;现有基于扩散的方法在基于鸟瞰图（BEV）布局下合成图像，而本研究利用基于高斯拼贴的3D重建技术。&lt;h4&gt;目的&lt;/h4&gt;通过在重建的3D空间中直接放置3D物体，确保物体放置的物理可行性和3D姿态及位置的精确标注。&lt;h4&gt;方法&lt;/h4&gt;使用3D重建技术，对3D物体进行直接放置，并应用几何变换；通过在真实场景中集成外部3D物体进行数据增强；比较了几何多样性和外观多样性对物体放置的影响；研究了通过最大化检测损失或增加视觉遮挡生成困难示例的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;将有限数量的外部3D物体集成到真实场景中，可以显著提高3D物体检测性能；高几何多样性在物体放置上的影响大于外观多样性；生成困难示例并不一定能提高基于摄像头的3D物体检测数据增强的效率。&lt;h4&gt;结论&lt;/h4&gt;本研究提出的方法能够有效提高自动驾驶中3D物体检测的性能，并通过实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate data augmentation for 3D object detection in autonomousdriving. We utilize recent advancements in 3D reconstruction based on GaussianSplatting for 3D object placement in driving scenes. Unlike existingdiffusion-based methods that synthesize images conditioned on BEV layouts, ourapproach places 3D objects directly in the reconstructed 3D space withexplicitly imposed geometric transformations. This ensures both the physicalplausibility of object placement and highly accurate 3D pose and positionannotations.  Our experiments demonstrate that even by integrating a limited number ofexternal 3D objects into real scenes, the augmented data significantly enhances3D object detection performance and outperforms existing diffusion-based 3Daugmentation for object detection. Extensive testing on the nuScenes datasetreveals that imposing high geometric diversity in object placement has agreater impact compared to the appearance diversity of objects. Additionally,we show that generating hard examples, either by maximizing detection loss orimposing high visual occlusion in camera images, does not lead to moreefficient 3D data augmentation for camera-based 3D object detection inautonomous driving.</description>
      <author>example@mail.com (Farhad G. Zanjani, Davide Abati, Auke Wiggers, Dimitris Kalatzis, Jens Petersen, Hong Cai, Amirhossein Habibian)</author>
      <guid isPermaLink="false">2504.16740v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>From Past to Present: A Survey of Malicious URL Detection Techniques, Datasets and Code Repositories</title>
      <link>http://arxiv.org/abs/2504.16449v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对恶意URL检测技术进行了全面综述，分析了从传统黑名单到高级深度学习方法（如Transformer、GNNs和LLMs）的各种方法。&lt;h4&gt;背景&lt;/h4&gt;恶意URL对网络安全生态系统构成持续威胁，通过欺骗用户泄露私人数据或分发有害有效载荷来渗透主机系统。&lt;h4&gt;目的&lt;/h4&gt;获得对当前恶意URL检测状态的及时洞察，并填补现有综述的四个关键差距。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于模态的新颖分类法，将现有工作根据其主要数据模态（如URL、HTML、视觉等）进行分类。此外，收集并分析了公开数据集和开源实现，以建立可访问数据集的档案并解决标准化基准测试的缺乏问题。&lt;h4&gt;主要发现&lt;/h4&gt;1) 现有综述依赖于算法中心化的分类法，掩盖了检测方法如何利用特定的模态信息通道；2) 缺乏对基于LLM/Transformer的关键防御方法的考虑；3) 缺乏开源实现以促进基准测试；4) 数据集覆盖不足。&lt;h4&gt;结论&lt;/h4&gt;本文提出了一个全面的恶意URL检测技术综述，并提出了未来研究的可行方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：恶意URL持续威胁网络安全生态系统，通过欺骗用户泄露私人数据或分发有害有效载荷来渗透主机系统。及时了解这场持续战争的当前状态具有重要意义。然而，现有的综述存在四个关键差距：1) 它们依赖于以算法为中心的分类法，掩盖了检测方法如何利用特定的模态信息通道；2) 它们未能纳入关键的LLM/Transformer-based防御方法；3) 没有收集开源实现以促进基准测试；4) 数据集覆盖不足。本文对恶意URL检测技术进行了全面综述，系统地分析了从传统黑名单到高级深度学习方法（例如Transformer、GNNs和LLMs）的各种方法。与先前的调查不同，我们提出了一种基于模态的新颖分类法，将现有工作根据它们的主要数据模态（如URL、HTML、视觉等）进行分类。这种分层分类使得既可以进行严格的技术分析，又可以对多模态信息利用有清晰的理解。此外，为了建立可访问数据集的档案并解决缺乏标准化基准测试的问题（当前研究往往缺乏适当的基线比较），我们收集并分析了：1) 公开数据集（2016-2024年），以及2) 已发表作品的开放源代码实现（2013-2025年）。然后，我们概述了产品级实现的基本设计原则和架构框架。综述的结论部分检查了新兴的挑战，并提出了未来研究的可行方向。我们维护一个GitHub存储库，用于持续收集数据集和开源实现：https://github.com/sevenolu7/Malicious-URL-Detection-Open-Source/tree/master。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Malicious URLs persistently threaten the cybersecurity ecosystem, by eitherdeceiving users into divulging private data or distributing harmful payloads toinfiltrate host systems. Gaining timely insights into the current state of thisongoing battle holds significant importance. However, existing reviews exhibit4 critical gaps: 1) Their reliance on algorithm-centric taxonomies obscuresunderstanding of how detection approaches exploit specific modal informationchannels; 2) They fail to incorporate pivotal LLM/Transformer-based defenses;3) No open-source implementations are collected to facilitate benchmarking; 4)Insufficient dataset coverage.This paper presents a comprehensive review ofmalicious URL detection technologies, systematically analyzing methods fromtraditional blacklisting to advanced deep learning approaches (e.g.Transformer, GNNs, and LLMs). Unlike prior surveys, we propose a novelmodality-based taxonomy that categorizes existing works according to theirprimary data modalities (URL, HTML, Visual, etc.). This hierarchicalclassification enables both rigorous technical analysis and clear understandingof multimodal information utilization. Furthermore, to establish a profile ofaccessible datasets and address the lack of standardized benchmarking (wherecurrent studies often lack proper baseline comparisons), we curate and analyze:1) publicly available datasets (2016-2024), and 2) open-source implementationsfrom published works(2013-2025). Then, we outline essential design principlesand architectural frameworks for product-level implementations. The reviewconcludes by examining emerging challenges and proposing actionable directionsfor future research. We maintain a GitHub repository for ongoing curatingdatasets and open-source implementations:https://github.com/sevenolu7/Malicious-URL-Detection-Open-Source/tree/master.</description>
      <author>example@mail.com (Ye Tian, Yanqiu Yu, Jianguo Sun, Yanbin Wang)</author>
      <guid isPermaLink="false">2504.16449v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Federated EndoViT: Pretraining Vision Transformers via Federated Learning on Endoscopic Image Collections</title>
      <link>http://arxiv.org/abs/2504.16612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint submitted to MEDIA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过联邦学习训练基础模型，以解决数据共享限制，实现最小侵入性手术的协作模型训练，而不涉及数据传输。&lt;h4&gt;背景&lt;/h4&gt;联邦学习是一种隐私保护的数据共享方法，适用于需要保护患者隐私的医疗领域。&lt;h4&gt;目的&lt;/h4&gt;研究联邦学习在最小侵入性手术中的应用，以实现数据共享限制下的模型训练。&lt;h4&gt;方法&lt;/h4&gt;受EndoViT研究启发，将掩码自编码器应用于联邦学习，并增强其自适应锐度感知最小化（FedSAM）和随机权重平均（SWA）。模型在Endo700k数据集上预训练，然后针对语义分割、动作三元组识别和手术阶段识别等任务进行微调和评估。&lt;h4&gt;主要发现&lt;/h4&gt;将自适应FedSAM集成到联邦MAE方法中可以改善预训练，导致每块的重构损失减少。FL-EndoViT在手术下游任务中的表现与CEN-EndoViT相当。此外，当数据有限时，FL-EndoViT在手术场景分割方面优于CEN-EndoViT；当使用大型数据集时，在动作三元组识别方面具有优势。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了联邦学习在隐私保护性训练手术基础模型方面的潜力，为手术数据科学提供了一个稳健且可推广的解决方案。有效的协作需要调整联邦学习方法，如FedSAM的集成，以适应机构间固有的数据异质性。未来，探索基于视频的模型，通过结合对现实手术环境至关重要的时空动态，可能增强这些功能。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: In this study, we investigate the training of foundation modelsusing federated learning to address data-sharing limitations and enablecollaborative model training without data transfer for minimally invasivesurgery. Methods: Inspired by the EndoViT study, we adapt the MaskedAutoencoder for federated learning, enhancing it with adaptive Sharpness-AwareMinimization (FedSAM) and Stochastic Weight Averaging (SWA). Our model ispretrained on the Endo700k dataset collection and later fine-tuned andevaluated for tasks such as Semantic Segmentation, Action Triplet Recognition,and Surgical Phase Recognition. Results: Our findings demonstrate thatintegrating adaptive FedSAM into the federated MAE approach improvespretraining, leading to a reduction in reconstruction loss per patch. Theapplication of FL-EndoViT in surgical downstream tasks results in performancecomparable to CEN-EndoViT. Furthermore, FL-EndoViT exhibits advantages overCEN-EndoViT in surgical scene segmentation when data is limited and in actiontriplet recognition when large datasets are used. Conclusion: These findingshighlight the potential of federated learning for privacy-preserving trainingof surgical foundation models, offering a robust and generalizable solution forsurgical data science. Effective collaboration requires adapting federatedlearning methods, such as the integration of FedSAM, which can accommodate theinherent data heterogeneity across institutions. In future, exploring FL invideo-based models may enhance these capabilities by incorporatingspatiotemporal dynamics crucial for real-world surgical environments.</description>
      <author>example@mail.com (Max Kirchner, Alexander C. Jenke, Sebastian Bodenstedt, Fiona R. Kolbinger, Oliver Saldanha, Jakob N. Kather, Martin Wagner, Stefanie Speidel)</author>
      <guid isPermaLink="false">2504.16612v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Tri-FusionNet: Enhancing Image Description Generation with Transformer-based Fusion Network and Dual Attention Mechanism</title>
      <link>http://arxiv.org/abs/2504.16761v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Tri-FusionNet的新型图像描述生成模型，该模型结合了ViT编码器、RoBERTa解码器和CLIP集成模块，通过双重注意力机制提高了图像描述的准确性。&lt;h4&gt;背景&lt;/h4&gt;图像描述生成对于提升可访问性和AI对视觉内容的理解至关重要。深度学习在自然语言处理和计算机视觉领域的进步为图像描述生成提供了新的可能性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够生成准确、丰富上下文和灵活的图像描述的模型。&lt;h4&gt;方法&lt;/h4&gt;Tri-FusionNet模型集成了ViT编码器、RoBERTa解码器和CLIP集成模块，并使用双重注意力机制来增强图像特征提取和文本描述生成。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在Flickr30k和Flickr8k数据集上表现出色，在MS-COCO数据集上也取得了良好的结果。&lt;h4&gt;结论&lt;/h4&gt;Tri-FusionNet在生成高质量图像描述方面是有效的，证明了其在图像描述生成领域的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Image description generation is essential for accessibility and AI understanding of visual content. Recent advancements in deep learning have significantly improved natural language processing and computer vision. In this work, we propose Tri-FusionNet, a novel image description generation model that integrates transformer modules: a Vision Transformer (ViT) encoder module with dual-attention mechanism, a Robustly Optimized BERT Approach (RoBERTa) decoder module, and a Contrastive Language-Image Pre-Training (CLIP) integrating module. The ViT encoder, enhanced with dual attention, focuses on relevant spatial regions and linguistic context, improving image feature extraction. The RoBERTa decoder is employed to generate precise textual descriptions. CLIP's integrating module aligns visual and textual data through contrastive learning, ensuring effective combination of both modalities. This fusion of ViT, RoBERTa, and CLIP, along with dual attention, enables the model to produce more accurate, contextually rich, and flexible descriptions. The proposed framework demonstrated competitive performance on the Flickr30k and Flickr8k datasets, with BLEU scores ranging from 0.767 to 0.456 and 0.784 to 0.479, CIDEr scores of 1.679 and 1.483, METEOR scores of 0.478 and 0.358, and ROUGE-L scores of 0.567 and 0.789, respectively. On MS-COCO, the framework obtained BLEU scores of 0.893 (B-1), 0.821 (B-2), 0.794 (B-3), and 0.725 (B-4). The results demonstrate the effectiveness of Tri-FusionNet in generating high-quality image descriptions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image description generation is essential for accessibility and AIunderstanding of visual content. Recent advancements in deep learning havesignificantly improved natural language processing and computer vision. In thiswork, we propose Tri-FusionNet, a novel image description generation model thatintegrates transformer modules: a Vision Transformer (ViT) encoder module withdual-attention mechanism, a Robustly Optimized BERT Approach (RoBERTa) decodermodule, and a Contrastive Language-Image Pre-Training (CLIP) integratingmodule. The ViT encoder, enhanced with dual attention, focuses on relevantspatial regions and linguistic context, improving image feature extraction. TheRoBERTa decoder is employed to generate precise textual descriptions. CLIP'sintegrating module aligns visual and textual data through contrastive learning,ensuring effective combination of both modalities. This fusion of ViT, RoBERTa,and CLIP, along with dual attention, enables the model to produce moreaccurate, contextually rich, and flexible descriptions. The proposed frameworkdemonstrated competitive performance on the Flickr30k and Flickr8k datasets,with BLEU scores ranging from 0.767 to 0.456 and 0.784 to 0.479, CIDEr scoresof 1.679 and 1.483, METEOR scores of 0.478 and 0.358, and ROUGE-L scores of0.567 and 0.789, respectively. On MS-COCO, the framework obtained BLEU scoresof 0.893 (B-1), 0.821 (B-2), 0.794 (B-3), and 0.725 (B-4). The resultsdemonstrate the effectiveness of Tri-FusionNet in generating high-quality imagedescriptions.</description>
      <author>example@mail.com (Lakshita Agarwal, Bindu Verma)</author>
      <guid isPermaLink="false">2504.16761v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Graph2Nav: 3D Object-Relation Graph Generation to Robot Navigation</title>
      <link>http://arxiv.org/abs/2504.16782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Graph2Nav的实时3D对象-关系图生成框架，用于现实世界的自主导航。&lt;h4&gt;背景&lt;/h4&gt;在室内和室外场景中，需要处理3D场景中的对象和语义关系。&lt;h4&gt;目的&lt;/h4&gt;生成和利用3D场景图中的3D对象和丰富的语义关系，以实现自主导航。&lt;h4&gt;方法&lt;/h4&gt;通过3D语义映射技术，将最先进的2D全景场景图工作扩展到3D世界，学习生成对象间的3D语义关系。避免直接从3D数据中学习3D场景图的训练数据限制。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了在3D场景图中定位3D对象和标注对象关系的高精度。通过将Graph2Nav与基于大型语言模型的顶尖规划器SayNav集成，评估了其在无人地面机器人在现实环境中的目标搜索任务中的影响。&lt;h4&gt;结论&lt;/h4&gt;在场景图中建模对象关系可以提高导航任务中的搜索效率。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为Graph2Nav的实时3D对象-关系图生成框架，用于现实世界的自主导航。我们的框架能够全面生成和利用3D场景图中的3D对象和丰富的语义关系，适用于室内和室外场景。通过利用和推进最先进的2D全景场景图工作到3D世界，通过3D语义映射技术学习生成对象间的3D语义关系。这种方法避免了从3D数据直接学习3D场景图的训练数据限制。我们通过实验验证了在3D场景图中定位3D对象和标注对象关系的高精度。我们还通过将Graph2Nav与基于大型语言模型的顶尖规划器SayNav集成，评估了其在无人地面机器人在现实环境中的目标搜索任务中的影响。我们的结果表明，在场景图中建模对象关系可以提高这些导航任务中的搜索效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Graph2Nav, a real-time 3D object-relation graph generationframework, for autonomous navigation in the real world. Our framework fullygenerates and exploits both 3D objects and a rich set of semantic relationshipsamong objects in a 3D layered scene graph, which is applicable to both indoorand outdoor scenes. It learns to generate 3D semantic relations among objects,by leveraging and advancing state-of-the-art 2D panoptic scene graph works intothe 3D world via 3D semantic mapping techniques. This approach avoids previoustraining data constraints in learning 3D scene graphs directly from 3D data. Weconduct experiments to validate the accuracy in locating 3D objects andlabeling object-relations in our 3D scene graphs. We also evaluate the impactof Graph2Nav via integration with SayNav, a state-of-the-art planner based onlarge language models, on an unmanned ground robot to object search tasks inreal environments. Our results demonstrate that modeling object relations inour scene graphs improves search efficiency in these navigation tasks.</description>
      <author>example@mail.com (Tixiao Shan, Abhinav Rajvanshi, Niluthpol Mithun, Han-Pang Chiu)</author>
      <guid isPermaLink="false">2504.16782v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>PCF-Grasp: Converting Point Completion to Geometry Feature to Enhance 6-DoF Grasp</title>
      <link>http://arxiv.org/abs/2504.16320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于点云的6自由度抓取方法，通过利用完整点云特征和分数过滤器来提高抓取准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;现有的基于单视图深度图像生成的点云（2.5D点）只能提供物体的一侧表面信息，导致抓取算法对目标物体形状的判断不准确，影响抓取精度。&lt;h4&gt;目的&lt;/h4&gt;提高机器人从单视角准确抓取物体的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的6自由度抓取框架，该框架将点云补全结果作为物体形状特征来训练6自由度抓取网络。点云补全可以从2.5D点生成近似完整的点，类似于人类的几何经验。此外，为了解决网络生成与实际执行之间的差距，框架中集成了分数过滤器，以选择更多可执行的抓取建议。&lt;h4&gt;主要发现&lt;/h4&gt;使用完整点云特征可以生成更准确的抓取建议，而分数过滤器的引入大大增强了现实世界机器人抓取的可靠性。&lt;h4&gt;结论&lt;/h4&gt;该方法在现实世界实验中比现有方法提高了17.8%的成功率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于点云的6自由度（DoF）抓取方法在使机器人能够抓取目标物体方面显示出巨大的潜力。然而，大多数现有方法都是基于从单视图深度图像生成的点云（2.5D点）。这些点云只提供了物体的一侧表面信息，导致抓取算法对目标物体形状的判断不准确，从而降低了抓取精度。人类可以通过利用他们的几何经验来估计物体形状，从而从单视角准确抓取物体。受人类的启发，我们提出了一种新的6自由度抓取框架，该框架将点云补全结果作为物体形状特征来训练6自由度抓取网络。在这里，点云补全可以从2.5D点生成近似完整的点，类似于人类的几何经验，将其转换为形状特征是利用它的方式，以提高抓取效率。此外，由于网络生成与实际执行之间存在差距，我们将在我们的框架中集成一个分数过滤器，以选择更多可执行的抓取建议。这使得我们的方法能够在任何相机视图中保持高抓取质量。大量的实验表明，利用完整点云特征可以生成更准确的抓取建议，而分数过滤器的引入大大增强了现实世界机器人抓取的可靠性。我们的方法在现实世界实验中比现有方法提高了17.8%的成功率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The 6-Degree of Freedom (DoF) grasp method based on point clouds has shownsignificant potential in enabling robots to grasp target objects. However, mostexisting methods are based on the point clouds (2.5D points) generated fromsingle-view depth images. These point clouds only have one surface side of theobject providing incomplete geometry information, which mislead the graspingalgorithm to judge the shape of the target object, resulting in low graspingaccuracy. Humans can accurately grasp objects from a single view by leveragingtheir geometry experience to estimate object shapes. Inspired by humans, wepropose a novel 6-DoF grasping framework that converts the point completionresults as object shape features to train the 6-DoF grasp network. Here, pointcompletion can generate approximate complete points from the 2.5D pointssimilar to the human geometry experience, and converting it as shape featuresis the way to utilize it to improve grasp efficiency. Furthermore, due to thegap between the network generation and actual execution, we integrate a scorefilter into our framework to select more executable grasp proposals for thereal robot. This enables our method to maintain a high grasp quality in anycamera viewpoint. Extensive experiments demonstrate that utilizing completepoint features enables the generation of significantly more accurate graspproposals and the inclusion of a score filter greatly enhances the credibilityof real-world robot grasping. Our method achieves a 17.8\% success rate higherthan the state-of-the-art method in real-world experiments.</description>
      <author>example@mail.com (Yaofeng Cheng, Fusheng Zha, Wei Guo, Pengfei Wang, Chao Zeng, Lining Sun, Chenguang Yang)</author>
      <guid isPermaLink="false">2504.16320v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Improving Significant Wave Height Prediction Using Chronos Models</title>
      <link>http://arxiv.org/abs/2504.16834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究介绍了Chronos，这是第一个使用大型语言模型（LLM）驱动的时序架构（Chronos），专门优化用于波浪预测。Chronos在波浪预测方面实现了多方面的改进。&lt;h4&gt;背景&lt;/h4&gt;准确预测波浪高度对海事安全和海岸韧性至关重要，但传统的基于物理的模型和传统的机器学习方法在计算效率和非线性动力学建模方面面临挑战。&lt;h4&gt;目的&lt;/h4&gt;引入Chronos，优化波浪预测的计算效率，并提高波浪预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;通过将高级时序模式识别应用于来自西北太平洋三个战略选定的海洋区域的历波数据，Chronos实现了多模态改进。&lt;h4&gt;主要发现&lt;/h4&gt;Chronos实现了以下改进：(1)与PatchTST基线相比，训练时间减少了14.3%，推理速度提高了2.5倍，达到0.575的平均绝对缩放误差（MASE）单位；(2)在短期预测（1-24小时）方面表现优异；(3)在长期预测（1-120小时）中持续保持预测优势；(4)在零样本能力方面表现出色，与专业操作模型相比，保持了中位性能（排名第4/12）。&lt;h4&gt;结论&lt;/h4&gt;LLM增强的时序建模范式在波浪预测中建立了新的标准，提供了计算效率高的解决方案，并为复杂地球物理系统建模提供了一个可转移的框架。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测波浪高度对海事安全和海岸韧性至关重要，然而，传统的基于物理的模型和传统的机器学习方法在计算效率和非线性动力学建模方面存在挑战。本研究引入了Chronos，这是第一个使用大型语言模型（LLM）驱动的时序架构（Chronos），专门用于波浪预测。通过将高级时序模式识别应用于来自西北太平洋三个战略选定的海洋区域的历波数据，我们的框架实现了多模态改进：(1)与PatchTST基线相比，训练时间减少了14.3%，推理速度提高了2.5倍，达到0.575的平均绝对缩放误差（MASE）单位；(2)在短期预测（1-24小时）方面表现优异；(3)在长期预测（1-120小时）中持续保持预测优势；(4)在零样本能力方面表现出色，与专业操作模型相比，保持了中位性能（排名第4/12）。这种LLM增强的时序建模范式在波浪预测中建立了新的标准，提供了计算效率高的解决方案，并为复杂地球物理系统建模提供了一个可转移的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate wave height prediction is critical for maritime safety and coastalresilience, yet conventional physics-based models and traditional machinelearning methods face challenges in computational efficiency and nonlineardynamics modeling. This study introduces Chronos, the first implementation of alarge language model (LLM)-powered temporal architecture (Chronos) optimizedfor wave forecasting. Through advanced temporal pattern recognition applied tohistorical wave data from three strategically chosen marine zones in theNorthwest Pacific basin, our framework achieves multimodal improvements: (1)14.3% reduction in training time with 2.5x faster inference speed compared toPatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)sustained predictive leadership in extended-range forecasts (1-120h); and (4)demonstrated zero-shot capability maintaining median performance (rank 4/12)against specialized operational models. This LLM-enhanced temporal modelingparadigm establishes a new standard in wave prediction, offering bothcomputationally efficient solutions and a transferable framework for complexgeophysical systems modeling.</description>
      <author>example@mail.com (Yilin Zhai, Hongyuan Shi, Chao Zhan, Qing Wang, Zaijin You, Nan Wang)</author>
      <guid isPermaLink="false">2504.16834v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning via Non-Contrastive Mutual Information</title>
      <link>http://arxiv.org/abs/2504.16667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MINC的自监督目标函数，旨在结合对比学习和非对比学习的优点，以从无标签图像数据中学习更有意义的潜在表示。&lt;h4&gt;背景&lt;/h4&gt;标注数据耗时且昂贵，导致大量数据未标注。自监督表示学习方法如SimCLR和BYOL在从无标签图像数据中学习潜在表示方面取得了成功。&lt;h4&gt;目的&lt;/h4&gt;开发一个结合对比学习和非对比学习优点的自监督目标函数。&lt;h4&gt;方法&lt;/h4&gt;将特定的对比方法Spectral Contrastive Loss转换为更通用的非对比形式，以降低方差并防止模型坍塌。&lt;h4&gt;主要发现&lt;/h4&gt;MINC损失在ImageNet数据集上测试时，表现优于Spectral Contrastive Loss基线。&lt;h4&gt;结论&lt;/h4&gt;MINC损失能够有效地从无标签图像数据中学习潜在表示，并提高下游任务的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Labeling data is often very time consuming and expensive, leaving us with amajority of unlabeled data. Self-supervised representation learning methodssuch as SimCLR (Chen et al., 2020) or BYOL (Grill et al., 2020) have been verysuccessful at learning meaningful latent representations from unlabeled imagedata, resulting in much more general and transferable representations fordownstream tasks. Broadly, self-supervised methods fall into two types: 1)Contrastive methods, such as SimCLR; and 2) Non-Contrastive methods, such asBYOL. Contrastive methods are generally trying to maximize mutual informationbetween related data points, so they need to compare every data point to everyother data point, resulting in high variance, and thus requiring large batchsizes to work well. Non-contrastive methods like BYOL have much lower varianceas they do not need to make pairwise comparisons, but are much trickier toimplement as they have the possibility of collapsing to a constant vector. Inthis paper, we aim to develop a self-supervised objective that combines thestrength of both types. We start with a particular contrastive method calledthe Spectral Contrastive Loss (HaoChen et al., 2021; Lu et al., 2024), and weconvert it into a more general non-contrastive form; this removes the pairwisecomparisons resulting in lower variance, but keeps the mutual informationformulation of the contrastive method preventing collapse. We call our newobjective the Mutual Information Non-Contrastive (MINC) loss. We test MINC bylearning image representations on ImageNet (similar to SimCLR and BYOL) andshow that it consistently improves upon the Spectral Contrastive loss baseline.</description>
      <author>example@mail.com (Zhaohan Daniel Guo, Bernardo Avila Pires, Khimya Khetarpal, Dale Schuurmans, Bo Dai)</author>
      <guid isPermaLink="false">2504.16667v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Measuring Uncertainty in Shape Completion to Improve Grasp Quality</title>
      <link>http://arxiv.org/abs/2504.16183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种计算3D形状补全模型不确定性的方法，并更新了抓取姿态算法的质量评分，通过引入补全点云的不确定性。实验结果表明，该方法在抓取成功率上优于现有技术。&lt;h4&gt;背景&lt;/h4&gt;形状补全网络在真实世界机器人实验中用于完成物体缺失或隐藏信息，但现有模型由于非确定性推理可能存在不准确，影响抓取效果。&lt;h4&gt;目的&lt;/h4&gt;计算3D形状补全模型的不确定性，并提高抓取姿态算法的质量评分。&lt;h4&gt;方法&lt;/h4&gt;提出了一种计算不确定性的方法，并在抓取姿态算法中引入了补全点云的不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够提高抓取成功率，特别是在排名前5的抓取候选者中。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在抓取成功率上优于现有技术，为形状补全模型的不确定性处理提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Shape completion networks have been used recently in real-world robotic experiments to complete the missing/hidden information in environments where objects are only observed in one or few instances where self-occlusions are bound to occur. Nowadays, most approaches rely on deep neural networks that handle rich 3D point cloud data that lead to more precise and realistic object geometries. However, these models still suffer from inaccuracies due to its non-deterministic/stochastic inferences which could lead to poor performance in grasping scenarios where these errors compound to unsuccessful grasps. We present an approach to calculate the uncertainty of a 3D shape completion model during inference of single view point clouds of an object on a table top. In addition, we propose an update to grasp pose algorithms quality score by introducing the uncertainty of the completed point cloud present in the grasp candidates. To test our full pipeline we perform real world grasping with a 7dof robotic arm with a 2 finger gripper on a large set of household objects and compare against previous approaches that do not measure uncertainty. Our approach ranks the grasp quality better, leading to higher grasp success rate for the rank 5 grasp candidates compared to state of the art.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Shape completion networks have been used recently in real-world roboticexperiments to complete the missing/hidden information in environments whereobjects are only observed in one or few instances where self-occlusions arebound to occur. Nowadays, most approaches rely on deep neural networks thathandle rich 3D point cloud data that lead to more precise and realistic objectgeometries. However, these models still suffer from inaccuracies due to itsnondeterministic/stochastic inferences which could lead to poor performance ingrasping scenarios where these errors compound to unsuccessful grasps. Wepresent an approach to calculate the uncertainty of a 3D shape completion modelduring inference of single view point clouds of an object on a table top. Inaddition, we propose an update to grasp pose algorithms quality score byintroducing the uncertainty of the completed point cloud present in the graspcandidates. To test our full pipeline we perform real world grasping with a7dof robotic arm with a 2 finger gripper on a large set of household objectsand compare against previous approaches that do not measure uncertainty. Ourapproach ranks the grasp quality better, leading to higher grasp success ratefor the rank 5 grasp candidates compared to state of the art.</description>
      <author>example@mail.com (Nuno Ferreira Duarte, Seyed S. Mohammadi, Plinio Moreno, Alessio Del Bue, Jose Santos-Victor)</author>
      <guid isPermaLink="false">2504.16183v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Disentangled Graph Representation Based on Substructure-Aware Graph Optimal Matching Kernel Convolutional Networks</title>
      <link>http://arxiv.org/abs/2504.16360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Graph Optimal Matching Kernel Convolutional Network (GOMKCN)的新方法，用于改进图表示学习，以解决现有方法在结构模式分析方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在图表示学习中被广泛应用，但现有方法通常隐式且粗略地描述图结构，限制了图内结构模式分析。&lt;h4&gt;目的&lt;/h4&gt;提出GOMKCN以解决现有方法在结构模式分析方面的局限性，并提高图模式挖掘和预测的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;GOMKCN将图视为以节点为中心的子图，每个子图作为编码位置特定信息的结构因素。它引入了Graph Optimal Matching Kernel (GOMK)作为卷积算子，计算子图之间的相似性，并学习可调的图滤波器。GOMK将子图和滤波器映射到希尔伯特空间，将图表示为点集。通过将子图投影到任务优化的滤波器上，GOMKCN通过梯度下降自适应地捕获相关的结构模式。&lt;h4&gt;主要发现&lt;/h4&gt;GOMKCN通过局部对应关系在相似性测量中整合，解决了图核中可微性和准确性的权衡问题。&lt;h4&gt;结论&lt;/h4&gt;实验验证了GOMKCN在图模式挖掘和预测中的优越准确性和可解释性，为解耦图表示学习的理论基础做出了贡献。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new method called Graph Optimal Matching Kernel Convolutional Network (GOMKCN) to improve graph representation learning and address the limitations of existing methods in structural pattern analysis. GOMKCN treats graphs as node-centric subgraphs, where each subgraph acts as a structural factor encoding position-specific information. It introduces the Graph Optimal Matching Kernel (GOMK) as a convolutional operator, computing similarities between subgraphs and learnable graph filters. Mathematically, GOMK maps subgraphs and filters into a Hilbert space, representing graphs as point sets. GOMKCN emerges from projecting subgraphs onto task-optimized filters, which adaptively capture relevant structural patterns via gradient descent. Crucially, GOMK incorporates local correspondences in similarity measurement, resolving the trade-off between differentiability and accuracy in graph kernels. Experiments validate that GOMKCN achieves superior accuracy and interpretability in graph pattern mining and prediction. The framework advances the theoretical foundation for disentangled graph representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs effectively characterize relational data, driving graph representationlearning methods that uncover underlying predictive information. Asstate-of-the-art approaches, Graph Neural Networks (GNNs) enable end-to-endlearning for diverse tasks. Recent disentangled graph representation learningenhances interpretability by decoupling independent factors in graph data.However, existing methods often implicitly and coarsely characterize graphstructures, limiting structural pattern analysis within the graph. This paperproposes the Graph Optimal Matching Kernel Convolutional Network (GOMKCN) toaddress this limitation. We view graphs as node-centric subgraphs, where eachsubgraph acts as a structural factor encoding position-specific information.This transforms graph prediction into structural pattern recognition. Inspiredby CNNs, GOMKCN introduces the Graph Optimal Matching Kernel (GOMK) as aconvolutional operator, computing similarities between subgraphs and learnablegraph filters. Mathematically, GOMK maps subgraphs and filters into a Hilbertspace, representing graphs as point sets. Disentangled representations emergefrom projecting subgraphs onto task-optimized filters, which adaptively capturerelevant structural patterns via gradient descent. Crucially, GOMK incorporateslocal correspondences in similarity measurement, resolving the trade-offbetween differentiability and accuracy in graph kernels. Experiments validatethat GOMKCN achieves superior accuracy and interpretability in graph patternmining and prediction. The framework advances the theoretical foundation fordisentangled graph representation learning.</description>
      <author>example@mail.com (Mao Wang, Tao Wu, Xingping Xian, Shaojie Qiao, Weina Niu, Canyixing Cui)</author>
      <guid isPermaLink="false">2504.16360v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Radar Camera Alignment by Contrastive Learning for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.16368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RCAlign的新对齐模型，用于雷达和摄像头融合的3D目标检测，显著提升了实时3D检测的性能。&lt;h4&gt;背景&lt;/h4&gt;基于雷达和摄像头融合的3D目标检测算法在自动驾驶感知任务中表现出色，但现有方法在处理雷达和摄像头之间的特征错位问题方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;提出RCAlign模型以解决雷达和摄像头特征对齐中的问题，并提高3D目标检测的性能。&lt;h4&gt;方法&lt;/h4&gt;RCAlign模型包括一个基于对比学习的双路由对齐模块（DRA），用于对齐和融合雷达与摄像头之间的特征；以及一个雷达特征增强模块（RFE），通过知识蒸馏损失来提高雷达BEV特征的密度。&lt;h4&gt;主要发现&lt;/h4&gt;RCAlign在公共nuScenes基准测试中实现了雷达摄像头融合3D目标检测的新纪录，并且在实时3D检测中相比最新最先进的方法，性能提升了4.3% NDS和8.4% mAP。&lt;h4&gt;结论&lt;/h4&gt;RCAlign模型在雷达摄像头融合的3D目标检测中具有显著优势，为自动驾驶感知任务提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, 3D object detection algorithms based on radar and camera fusionhave shown excellent performance, setting the stage for their application inautonomous driving perception tasks. Existing methods have focused on dealingwith feature misalignment caused by the domain gap between radar and camera.However, existing methods either neglect inter-modal features interactionduring alignment or fail to effectively align features at the same spatiallocation across modalities. To alleviate the above problems, we propose a newalignment model called Radar Camera Alignment (RCAlign). Specifically, wedesign a Dual-Route Alignment (DRA) module based on contrastive learning toalign and fuse the features between radar and camera. Moreover, considering thesparsity of radar BEV features, a Radar Feature Enhancement (RFE) module isproposed to improve the densification of radar BEV features with the knowledgedistillation loss. Experiments show RCAlign achieves a new state-of-the-art onthe public nuScenes benchmark in radar camera fusion for 3D Object Detection.Furthermore, the RCAlign achieves a significant performance gain (4.3\% NDS and8.4\% mAP) in real-time 3D detection compared to the latest state-of-the-artmethod (RCBEVDet).</description>
      <author>example@mail.com (Linhua Kong, Dongxia Chang, Lian Liu, Zisen Kong, Pengyuan Li, Yao Zhao)</author>
      <guid isPermaLink="false">2504.16368v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Foundation Model-Powered Recommender Systems: From Feature-Based, Generative to Agentic Paradigms</title>
      <link>http://arxiv.org/abs/2504.16420v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于基础模型（FM）的推荐系统（FM4RecSys），探讨了FM在特征增强、生成推荐和交互式系统中的应用。&lt;h4&gt;背景&lt;/h4&gt;推荐系统在过滤信息和个性化内容方面变得至关重要，传统的推荐系统技术依赖于用户与物品之间交互的建模以及内容特征的建模。&lt;h4&gt;目的&lt;/h4&gt;提供对FM4RecSys的全面概述，包括其集成在三个范式中的方式：特征表示增强、生成式推荐方法和代理交互系统。&lt;h4&gt;方法&lt;/h4&gt;首先回顾了推荐系统的数据基础，然后介绍了FM及其在推荐系统环境中的表示学习、自然语言理解和多模态推理的能力，接着讨论了FM在不同范式下如何增强推荐系统，并分析了FM在各个推荐任务中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;通过分析近期研究，突出了实现的关键机会以及遇到的挑战，并概述了下一代FM4RecSys的开放研究方向和技术挑战。&lt;h4&gt;结论&lt;/h4&gt;本文不仅回顾了最先进的方法，还对基于特征、生成和代理的范式之间的权衡进行了批判性分析，概述了关键开放问题和未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems (RS) have become essential in filtering information andpersonalizing content for users. RS techniques have traditionally relied onmodeling interactions between users and items as well as the features ofcontent using models specific to each task. The emergence of foundation models(FMs), large scale models trained on vast amounts of data such as GPT, LLaMAand CLIP, is reshaping the recommendation paradigm. This survey provides acomprehensive overview of the Foundation Models for Recommender Systems(FM4RecSys), covering their integration in three paradigms: (1) Feature-Basedaugmentation of representations, (2) Generative recommendation approaches, and(3) Agentic interactive systems. We first review the data foundations of RS,from traditional explicit or implicit feedback to multimodal content sources.We then introduce FMs and their capabilities for representation learning,natural language understanding, and multi-modal reasoning in RS contexts. Thecore of the survey discusses how FMs enhance RS under different paradigms.Afterward, we examine FM applications in various recommendation tasks. Throughan analysis of recent research, we highlight key opportunities that have beenrealized as well as challenges encountered. Finally, we outline open researchdirections and technical challenges for next-generation FM4RecSys. This surveynot only reviews the state-of-the-art methods but also provides a criticalanalysis of the trade-offs among the feature-based, the generative, and theagentic paradigms, outlining key open issues and future research directions.</description>
      <author>example@mail.com (Chengkai Huang, Hongtao Huang, Tong Yu, Kaige Xie, Junda Wu, Shuai Zhang, Julian Mcauley, Dietmar Jannach, Lina Yao)</author>
      <guid isPermaLink="false">2504.16420v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>DP2FL: Dual Prompt Personalized Federated Learning in Foundation Models</title>
      <link>http://arxiv.org/abs/2504.16357v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为DP2FL的个性化联邦学习框架，旨在解决在数据隐私保护的同时，如何提高在数据有限情况下的深度学习模型性能的问题。&lt;h4&gt;背景&lt;/h4&gt;个性化联邦学习（PFL）在处理异构客户端数据分布和保持数据隐私方面受到关注。然而，当本地客户端数据有限时，深度学习模型往往因训练不足而导致性能不佳。&lt;h4&gt;目的&lt;/h4&gt;提出DP2FL框架，以解决上述问题，通过引入双提示和自适应聚合策略，结合全局任务意识和本地数据驱动见解，使本地模型能够实现有效的泛化，同时适应特定的数据分布。&lt;h4&gt;方法&lt;/h4&gt;DP2FL框架结合了全局模型和本地数据，通过双提示和自适应聚合策略，实现新数据的预测和无缝集成新客户端，而无需重新训练。&lt;h4&gt;主要发现&lt;/h4&gt;在高度异构的环境中进行的实验验证了DP2FL提示设计和聚合策略的有效性，强调了在新型数据源上进行预测的优势，并展示了新客户端无缝集成到联邦学习框架中的能力。&lt;h4&gt;结论&lt;/h4&gt;DP2FL框架通过其创新的设计，为解决联邦学习中的数据隐私和模型性能问题提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Personalized federated learning (PFL) has garnered significant attention forits ability to address heterogeneous client data distributions while preservingdata privacy. However, when local client data is limited, deep learning modelsoften suffer from insufficient training, leading to suboptimal performance.Foundation models, such as CLIP (Contrastive Language-Image Pretraining),exhibit strong feature extraction capabilities and can alleviate this issue byfine-tuning on limited local data. Despite their potential, foundation modelsare rarely utilized in federated learning scenarios, and challenges related tointegrating new clients remain largely unresolved. To address these challenges,we propose the Dual Prompt Personalized Federated Learning (DP2FL) framework,which introduces dual prompts and an adaptive aggregation strategy. DP2FLcombines global task awareness with local data-driven insights, enabling localmodels to achieve effective generalization while remaining adaptable tospecific data distributions. Moreover, DP2FL introduces a global model thatenables prediction on new data sources and seamlessly integrates newly addedclients without requiring retraining. Experimental results in highlyheterogeneous environments validate the effectiveness of DP2FL's prompt designand aggregation strategy, underscoring the advantages of prediction on noveldata sources and demonstrating the seamless integration of new clients into thefederated learning framework.</description>
      <author>example@mail.com (Ying Chang, Xiaohu Shi, Xiaohui Zhao, Zhaohuang Chen, Deyin Ma)</author>
      <guid isPermaLink="false">2504.16357v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>TraveLLaMA: Facilitating Multi-modal Large Language Models to Understand Urban Scenes and Provide Travel Assistance</title>
      <link>http://arxiv.org/abs/2504.16505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了TraveLLaMA，一个专为城市场景理解和旅行辅助设计的多模态语言模型，并展示了其在旅行特定任务上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态AI系统在处理城市环境时缺乏专业知识，而旅行规划和旅游越来越依赖于数字辅助。&lt;h4&gt;目的&lt;/h4&gt;开发实用的AI旅行助手，并提高城市场景理解和旅行辅助的准确性和实用性。&lt;h4&gt;方法&lt;/h4&gt;通过构建一个包含220k个问答对的大规模数据集，结合从真实旅行论坛中精心挑选的130k个文本问答对和GPT增强的响应，以及90k个专注于地图理解和场景理解的视觉-语言问答对。在LLaVA、Qwen-VL和Shikra等最先进的视觉-语言模型上进行广泛的微调实验。&lt;h4&gt;主要发现&lt;/h4&gt;TraveLLaMA在纯文本旅行理解和视觉问答任务上的性能提高了6.5%-9.4%，在提供上下文旅行推荐、解释地图位置、理解特定场所的图像以及提供实用信息（如开放时间和游客评论）方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;TraveLLaMA在旅行特定任务上显著优于通用模型，为多模态旅行辅助系统设定了新的基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要：旅游和旅行规划越来越依赖数字辅助，但现有的多模态AI系统通常缺乏对城市环境的专门知识和上下文理解。我们提出了TraveLLaMA，这是一个专为城市场景理解和旅行辅助设计的多模态语言模型。我们的工作通过一个包含220k个问答对的创新大规模数据集来解决开发实用AI旅行助手的基本挑战。这个综合数据集独特地结合了从真实旅行论坛中精心挑选的130k个文本问答对和GPT增强的响应，以及90k个专注于地图理解和场景理解的视觉-语言问答对。通过对最先进的视觉-语言模型（LLaVA、Qwen-VL、Shikra）进行广泛的微调实验，我们在纯文本旅行理解和视觉问答任务上展示了显著的性能提升，范围从6.5%-9.4%。我们的模型在提供上下文旅行推荐、解释地图位置、理解特定场所的图像以及提供实用信息（如开放时间和游客评论）方面表现出色。比较评估表明，TraveLLaMA在旅行特定任务上显著优于通用模型，为多模态旅行辅助系统设定了新的基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tourism and travel planning increasingly rely on digital assistance, yetexisting multimodal AI systems often lack specialized knowledge and contextualunderstanding of urban environments. We present TraveLLaMA, a specializedmultimodal language model designed for urban scene understanding and travelassistance. Our work addresses the fundamental challenge of developingpractical AI travel assistants through a novel large-scale dataset of 220kquestion-answer pairs. This comprehensive dataset uniquely combines 130k textQA pairs meticulously curated from authentic travel forums with GPT-enhancedresponses, alongside 90k vision-language QA pairs specifically focused on mapunderstanding and scene comprehension. Through extensive fine-tuningexperiments on state-of-the-art vision-language models (LLaVA, Qwen-VL,Shikra), we demonstrate significant performance improvements ranging from6.5\%-9.4\% in both pure text travel understanding and visual questionanswering tasks. Our model exhibits exceptional capabilities in providingcontextual travel recommendations, interpreting map locations, andunderstanding place-specific imagery while offering practical information suchas operating hours and visitor reviews. Comparative evaluations show TraveLLaMAsignificantly outperforms general-purpose models in travel-specific tasks,establishing a new benchmark for multi-modal travel assistance systems.</description>
      <author>example@mail.com (Meng Chu, Yukang Chen, Haokun Gui, Shaozuo Yu, Yi Wang, Jiaya Jia)</author>
      <guid isPermaLink="false">2504.16505v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Unified Molecule Generation and Property Prediction</title>
      <link>http://arxiv.org/abs/2504.16559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为Hyformer的基于Transformer的联合模型，该模型结合了生成和预测功能，并展示了其在分子表示学习、命中识别和抗菌肽设计等下游任务中的优势。&lt;h4&gt;背景&lt;/h4&gt;建模数据样本及其属性的联合分布可以构建用于数据生成和属性预测的单个模型，其协同能力超越了纯生成或预测模型。&lt;h4&gt;目的&lt;/h4&gt;提出Hyformer模型，以解决联合模型训练中的架构和优化挑战。&lt;h4&gt;方法&lt;/h4&gt;Hyformer使用交替注意力掩码和统一的预训练方案来成功融合生成和预测功能。&lt;h4&gt;主要发现&lt;/h4&gt;Hyformer在与其他联合模型以及最先进的分子生成和属性预测模型中表现出竞争力。&lt;h4&gt;结论&lt;/h4&gt;联合建模在分子表示学习、命中识别和抗菌肽设计的下游任务中具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过建模数据样本及其属性的联合分布，可以构建用于数据生成和属性预测的单个模型，其协同能力超越了纯生成或预测模型。然而，联合模型的训练面临着严峻的架构和优化挑战。在此，我们提出了Hyformer，一种基于Transformer的联合模型，该模型成功融合了生成和预测功能，使用了交替注意力掩码和统一的预训练方案。我们发现Hyformer与其他联合模型以及最先进的分子生成和属性预测模型相媲美。此外，我们还展示了联合建模在分子表示学习、命中识别和抗菌肽设计的下游任务中的益处。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling the joint distribution of the data samples and their propertiesallows to construct a single model for both data generation and propertyprediction, with synergistic capabilities reaching beyond purely generative orpredictive models. However, training joint models presents dauntingarchitectural and optimization challenges. Here, we propose Hyformer, atransformer-based joint model that successfully blends the generative andpredictive functionalities, using an alternating attention mask together with aunified pre-training scheme. We show that Hyformer rivals other joint models,as well as state-of-the-art molecule generation and property prediction models.Additionally, we show the benefits of joint modeling in downstream tasks ofmolecular representation learning, hit identification and antimicrobial peptidedesign.</description>
      <author>example@mail.com (Adam Izdebski, Jan Olszewski, Pankhil Gawade, Krzysztof Koras, Serra Korkmaz, Valentin Rauscher, Jakub M. Tomczak, Ewa Szczurek)</author>
      <guid isPermaLink="false">2504.16559v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>On the Consistency of GNN Explanations for Malware Detection</title>
      <link>http://arxiv.org/abs/2504.16316v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于动态构建CFG并使用混合方法嵌入节点特征，以检测恶意行为。该框架结合了基于规则的编码和基于自动编码器的嵌入，并使用GNN进行分类。此外，还引入了RankFusion方法来提高解释质量，并使用多种解释技术进行评估。&lt;h4&gt;背景&lt;/h4&gt;CFG在分析程序执行和恶意软件行为特征中至关重要，而GNN在恶意软件检测中表现出色。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，用于准确识别恶意软件样本并生成可靠且可解释的解释。&lt;h4&gt;方法&lt;/h4&gt;使用混合方法结合规则编码和自动编码器嵌入节点特征，构建基于GNN的分类器，并应用多种解释技术如GNNExplainer、PGExplainer和CaptumExplainer，以及RankFusion方法。还提出了Greedy Edge-wise Composition (GEC)方法来提取子图。&lt;h4&gt;主要发现&lt;/h4&gt;提出的框架在准确识别恶意软件样本和生成可靠解释方面是有效的。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效检测恶意软件，并生成可解释的解释，提高了模型的可理解性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：控制流图（CFGs）对于分析程序执行和描述恶意软件行为至关重要。随着图神经网络（GNNs）的广泛应用，基于CFG的表示在恶意软件检测中已被证明非常有效。本研究提出了一种新的框架，该框架动态构建CFG，并使用结合基于规则的编码和基于自动编码器嵌入的混合方法来嵌入节点特征。然后构建了一个基于GNN的分类器，用于从生成的图表示中检测恶意行为。为了提高模型的可解释性，我们应用了最先进的解释技术，包括GNNExplainer、PGExplainer和CaptumExplainer，其中CaptumExplainer使用了三种归因方法：集成梯度、引导反向传播和显著性。此外，我们引入了一种新的聚合方法，称为RankFusion，该方法集成了表现最好的解释器的输出，以增强解释质量。我们还使用两种子图提取策略评估了解释，包括用于提高结构一致性的提出的贪婪边缘组合（GEC）方法。使用准确度、保真度和一致性指标进行的全面评估表明，所提出的框架在准确识别恶意软件样本和生成可靠且可解释的解释方面是有效的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Control Flow Graphs (CFGs) are critical for analyzing program execution andcharacterizing malware behavior. With the growing adoption of Graph NeuralNetworks (GNNs), CFG-based representations have proven highly effective formalware detection. This study proposes a novel framework that dynamicallyconstructs CFGs and embeds node features using a hybrid approach combiningrule-based encoding and autoencoder-based embedding. A GNN-based classifier isthen constructed to detect malicious behavior from the resulting graphrepresentations. To improve model interpretability, we apply state-of-the-artexplainability techniques, including GNNExplainer, PGExplainer, andCaptumExplainer, the latter is utilized three attribution methods: IntegratedGradients, Guided Backpropagation, and Saliency. In addition, we introduce anovel aggregation method, called RankFusion, that integrates the outputs of thetop-performing explainers to enhance the explanation quality. We also evaluateexplanations using two subgraph extraction strategies, including the proposedGreedy Edge-wise Composition (GEC) method for improved structural coherence. Acomprehensive evaluation using accuracy, fidelity, and consistency metricsdemonstrates the effectiveness of the proposed framework in terms of accurateidentification of malware samples and generating reliable and interpretableexplanations.</description>
      <author>example@mail.com (Hossein Shokouhinejad, Griffin Higgins, Roozbeh Razavi-Far, Hesamodin Mohammadian, Ali A. Ghorbani)</author>
      <guid isPermaLink="false">2504.16316v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Time-aware Continual User Representation Learning</title>
      <link>http://arxiv.org/abs/2504.16501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DITTO的新型用户表示学习方法，用于解决传统用户建模方法在任务泛化适应性和时间推移下的泛化能力问题。&lt;h4&gt;背景&lt;/h4&gt;传统用户建模方法主要针对单一特定任务设计模型，但在处理多个任务时存在泛化和适应性不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于连续学习的通用用户表示学习方法，以适应任务泛化并提高模型的适应性。&lt;h4&gt;方法&lt;/h4&gt;设计了DITTO框架，该框架能够在项目分布持续变化的情况下缓解灾难性遗忘，同时允许先前任务获取的知识适应当前变化的项目分布。&lt;h4&gt;主要发现&lt;/h4&gt;在实践评估场景下，DITTO优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;DITTO在连续学习的通用用户表示学习方面取得进展，提高了模型的泛化和适应性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Traditional user modeling (UM) approaches have primarily focused on designing models for a single specific task, but they face limitations in generalization and adaptability across various tasks. Recognizing these challenges, recent studies have shifted towards continual learning (CL)-based universal user representation learning aiming to develop a single model capable of handling multiple tasks. Despite advancements, existing methods are in fact evaluated under an unrealistic scenario that does not consider the passage of time as tasks progress, which overlooks newly emerged items that may change the item distribution of previous tasks. In this paper, we introduce a practical evaluation scenario on which CL-based universal user representation learning approaches should be evaluated, which takes into account the passage of time as tasks progress. Then, we propose a novel framework Dynamic Time-aware continual user representation learner, named DITTO, designed to alleviate catastrophic forgetting despite continuous shifts in item distribution, while also allowing the knowledge acquired from previous tasks to adapt to the current shifted item distribution. Through our extensive experiments, we demonstrate the superiority of DITTO over state-of-the-art methods under a practical evaluation scenario. Our source code is available at https://github.com/seungyoon-Choi/DITTO_official.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional user modeling (UM) approaches have primarily focused on designingmodels for a single specific task, but they face limitations in generalizationand adaptability across various tasks. Recognizing these challenges, recentstudies have shifted towards continual learning (CL)-based universal userrepresentation learning aiming to develop a single model capable of handlingmultiple tasks. Despite advancements, existing methods are in fact evaluatedunder an unrealistic scenario that does not consider the passage of time astasks progress, which overlooks newly emerged items that may change the itemdistribution of previous tasks. In this paper, we introduce a practicalevaluation scenario on which CL-based universal user representation learningapproaches should be evaluated, which takes into account the passage of time astasks progress. Then, we propose a novel framework Dynamic Time-aware continualuser representation learner, named DITTO, designed to alleviate catastrophicforgetting despite continuous shifts in item distribution, while also allowingthe knowledge acquired from previous tasks to adapt to the current shifted itemdistribution. Through our extensive experiments, we demonstrate the superiorityof DITTO over state-of-the-art methods under a practical evaluation scenario.Our source code is available athttps://github.com/seungyoon-Choi/DITTO_official.</description>
      <author>example@mail.com (Seungyoon Choi, Sein Kim, Hongseok Kang, Wonjoong Kim, Chanyoung Park)</author>
      <guid isPermaLink="false">2504.16501v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Energy-Based Pseudo-Label Refining for Source-free Domain Adaptation</title>
      <link>http://arxiv.org/abs/2504.16692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 3 figures, accepted by PRL. code at  https://github.com/Sthen111/EBPR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Energy-Based Pseudo-Label Refining (EBPR)的方法，用于无源数据域适应（SFDA），该方法旨在减少由于伪标签噪声引起的负迁移。&lt;h4&gt;背景&lt;/h4&gt;无源域适应（SFDA）是一个挑战性任务，因为它需要调整模型而不访问源数据。现有的SFDA技术通常依赖于从置信度生成伪标签，这导致负迁移。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有SFDA技术中由于伪标签噪声导致的负迁移问题。&lt;h4&gt;方法&lt;/h4&gt;EBPR方法为所有样本簇根据其能量分数创建伪标签。计算全局和类别能量阈值以选择性过滤伪标签。此外，引入了对比学习策略来过滤困难样本，将它们与其增强版本对齐，以学习更具判别性的特征。&lt;h4&gt;主要发现&lt;/h4&gt;在Office-31、Office-Home和VisDA-C数据集上验证了该方法，发现我们的模型在性能上优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;EBPR方法在无源域适应任务中表现出色，优于现有的最先进方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无源域适应（SFDA），即在不访问源数据的情况下调整模型的过程，是一项既要求高又具有挑战性的任务。现有的SFDA技术通常依赖于从置信度生成的伪标签，这导致由于显著的噪声引起的负迁移。为了解决这一问题，提出了一种基于能量的伪标签细化（EBPR）方法用于SFDA。根据它们的能量分数为所有样本簇创建伪标签。计算全局和类别能量阈值以选择性地过滤伪标签。此外，引入了一种对比学习策略来过滤困难样本，将它们与它们的增强版本对齐，以学习更具判别性的特征。在Office-31、Office-Home和VisDA-C数据集上验证了我们的方法，一致地发现我们的模型在性能上优于最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.patrec.2025.04.004&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Source-free domain adaptation (SFDA), which involves adapting models withoutaccess to source data, is both demanding and challenging. Existing SFDAtechniques typically rely on pseudo-labels generated from confidence levels,leading to negative transfer due to significant noise. To tackle this problem,Energy-Based Pseudo-Label Refining (EBPR) is proposed for SFDA. Pseudo-labelsare created for all sample clusters according to their energy scores. Globaland class energy thresholds are computed to selectively filter pseudo-labels.Furthermore, a contrastive learning strategy is introduced to filter difficultsamples, aligning them with their augmented versions to learn morediscriminative features. Our method is validated on the Office-31, Office-Home,and VisDA-C datasets, consistently finding that our model outperformedstate-of-the-art methods.</description>
      <author>example@mail.com (Xinru Meng, Han Sun, Jiamei Liu, Ningzhong Liu, Huiyu Zhou)</author>
      <guid isPermaLink="false">2504.16692v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Large Language Models for Enhanced Traffic Safety: A Comprehensive Review and Future Trends</title>
      <link>http://arxiv.org/abs/2504.16134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了多模态大型语言模型（MLLMs）在解决传统高级驾驶辅助系统（ADAS）在动态真实场景中的局限性，以及对抗条件下的敏感性，其通过整合跨模态数据如视觉、空间和环境输入，实现全面场景理解，并展望了其在下一代交通安全系统中的应用潜力。&lt;h4&gt;背景&lt;/h4&gt;交通安全是全球面临的重大挑战，传统ADAS系统在动态真实场景中往往表现不佳，容易受到对抗条件的影响。&lt;h4&gt;目的&lt;/h4&gt;探讨MLLMs在提高ADAS感知能力、决策能力和对抗鲁棒性方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;对基于MLLMs的方法进行了全面分析，并考察了关键数据集（如KITTI、DRAMA、ML4RoadSafety）在推动研究进展中的作用。&lt;h4&gt;主要发现&lt;/h4&gt;MLLMs能够通过整合多模态数据提升ADAS的感知、决策和对抗鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;MLLMs作为下一代交通安全系统的基础，有望革命化该领域，提供可扩展、情境感知的解决方案，主动降低风险并提高道路安全性。&lt;h4&gt;翻译&lt;/h4&gt;Traffic safety remains a critical global challenge, with traditional Advanced Driver-Assistance Systems (ADAS) often struggling in dynamic real-world scenarios due to fragmented sensor processing and susceptibility to adversarial conditions. This paper reviews the transformative potential of Multimodal Large Language Models (MLLMs) in addressing these limitations by integrating cross-modal data such as visual, spatial, and environmental inputs to enable holistic scene understanding. Through a comprehensive analysis of MLLM-based approaches, we highlight their capabilities in enhancing perception, decision-making, and adversarial robustness, while also examining the role of key datasets (e.g., KITTI, DRAMA, ML4RoadSafety) in advancing research. Furthermore, we outline future directions, including real-time edge deployment, causality-driven reasoning, and human-AI collaboration. By positioning MLLMs as a cornerstone for next-generation traffic safety systems, this review underscores their potential to revolutionize the field, offering scalable, context-aware solutions that proactively mitigate risks and improve overall road safety.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic safety remains a critical global challenge, with traditional AdvancedDriver-Assistance Systems (ADAS) often struggling in dynamic real-worldscenarios due to fragmented sensor processing and susceptibility to adversarialconditions. This paper reviews the transformative potential of Multimodal LargeLanguage Models (MLLMs) in addressing these limitations by integratingcross-modal data such as visual, spatial, and environmental inputs to enableholistic scene understanding. Through a comprehensive analysis of MLLM-basedapproaches, we highlight their capabilities in enhancing perception,decision-making, and adversarial robustness, while also examining the role ofkey datasets (e.g., KITTI, DRAMA, ML4RoadSafety) in advancing research.Furthermore, we outline future directions, including real-time edge deployment,causality-driven reasoning, and human-AI collaboration. By positioning MLLMs asa cornerstone for next-generation traffic safety systems, this reviewunderscores their potential to revolutionize the field, offering scalable,context-aware solutions that proactively mitigate risks and improve overallroad safety.</description>
      <author>example@mail.com (Mohammad Abu Tami, Mohammed Elhenawy, Huthaifa I. Ashqar)</author>
      <guid isPermaLink="false">2504.16134v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>QAOA-GPT: Efficient Generation of Adaptive and Regular Quantum Approximate Optimization Algorithm Circuits</title>
      <link>http://arxiv.org/abs/2504.16350v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了QAOA-GPT，一个利用生成预训练变压器（GPT）直接合成量子电路的生成框架，用于解决二次无约束二进制优化问题，并在图的最大割问题上进行演示。&lt;h4&gt;背景&lt;/h4&gt;量子计算有潜力提高解决经典计算机计算困难的优化问题的能力，通过提供可能提供加速的新算法方法。&lt;h4&gt;目的&lt;/h4&gt;研究QAOA-GPT框架在生成量子电路方面的有效性，并比较其与传统方法在计算开销和优化效率上的差异。&lt;h4&gt;方法&lt;/h4&gt;采用自适应QAOA方法生成合成数据集，用于训练QAOA-GPT，并通过在精确的图实例集上进行的实验来评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;QAOA-GPT能够生成高质量的新问题实例的量子电路，并成功参数化QAOA，显著降低了经典QAOA和自适应方法的计算开销。&lt;h4&gt;结论&lt;/h4&gt;生成式AI可能是以可扩展方式生成紧凑量子电路的有希望的途径。&lt;h4&gt;翻译&lt;/h4&gt;This work introduces QAOA-GPT, a generative framework that leverages Generative Pretrained Transformers (GPT) to directly synthesize quantum circuits for solving quadratic unconstrained binary optimization problems, and demonstrates it on the MaxCut problem on graphs. To diversify the training circuits and ensure their quality, we have generated a synthetic dataset using the adaptive QAOA approach, a method that incrementally builds and optimizes problem-specific circuits. The experiments conducted on a curated set of graph instances demonstrate that QAOA-GPT, generates high-quality quantum circuits for new problem instances unseen in the training as well as successfully parametrizes QAOA. Our results show that using QAOA-GPT to generate quantum circuits will significantly decrease both the computational overhead of classical QAOA and adaptive approaches that often use gradient evaluation to generate the circuit and the classical optimization of the circuit parameters. Our work shows that generative AI could be a promising avenue to generate compact quantum circuits in a scalable way.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum computing has the potential to improve our ability to solve certainoptimization problems that are computationally difficult for classicalcomputers, by offering new algorithmic approaches that may provide speedupsunder specific conditions. In this work, we introduce QAOA-GPT, a generativeframework that leverages Generative Pretrained Transformers (GPT) to directlysynthesize quantum circuits for solving quadratic unconstrained binaryoptimization problems, and demonstrate it on the MaxCut problem on graphs. Todiversify the training circuits and ensure their quality, we have generated asynthetic dataset using the adaptive QAOA approach, a method that incrementallybuilds and optimizes problem-specific circuits. The experiments conducted on acurated set of graph instances demonstrate that QAOA-GPT, generates highquality quantum circuits for new problem instances unseen in the training aswell as successfully parametrizes QAOA. Our results show that using QAOA-GPT togenerate quantum circuits will significantly decrease both the computationaloverhead of classical QAOA and adaptive approaches that often use gradientevaluation to generate the circuit and the classical optimization of thecircuit parameters. Our work shows that generative AI could be a promisingavenue to generate compact quantum circuits in a scalable way.</description>
      <author>example@mail.com (Ilya Tyagin, Marwa H. Farag, Kyle Sherbert, Karunya Shirali, Yuri Alexeev, Ilya Safro)</author>
      <guid isPermaLink="false">2504.16350v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Generalizable Infrared Small Target Detection: A Real-scene Benchmark and Cross-view Representation Learning</title>
      <link>http://arxiv.org/abs/2504.16487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A benchmark associated with real-world scenes for the Infrared Small  Target Detection (ISTD) is presented&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种增强领域适应性的红外小目标检测（ISTD）框架，旨在解决ISTD模型在不同场景下泛化能力受限的问题。&lt;h4&gt;背景&lt;/h4&gt;ISTD对传感器类型、观测条件和目标内在特性非常敏感，这些因素可能导致红外图像数据分布的显著差异，即领域偏移，从而阻碍ISTD模型在不同场景下的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一挑战，本文旨在提出一种方法来减轻数据集之间的分布偏移，实现跨样本对齐，并提高ISTD模型在噪声环境下的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;本文提出了以下方法：1. 引入跨视图通道对齐（CCA）来减轻数据集之间的分布偏移；2. 提出跨视图Top-K融合策略，将目标信息与多种背景特征整合，增强模型提取关键数据特征的能力；3. 开发了一种噪声引导的表示学习策略，使模型学习更具噪声鲁棒性的特征表示；4. 制定了专门的红外小目标数据集RealScene-ISTD。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，本文提出的方法在检测概率（Pd）、误报率（Fa）和交并比（IoU）方面表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高ISTD模型的泛化能力，特别是在噪声环境下，并且通过RealScene-ISTD数据集展示了其优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：红外小目标检测（ISTD）对传感器类型、观测条件和目标内在特性高度敏感。这些因素可能导致获取的红外图像数据分布产生显著差异，即领域偏移，这会显著阻碍ISTD模型在多种场景下的泛化能力。为了应对这一挑战，本文提出了一种增强领域适应性的ISTD框架。为了减轻数据集之间的分布偏移并实现跨样本对齐，我们引入了跨视图通道对齐（CCA）。此外，我们提出了跨视图Top-K融合策略，该策略将目标信息与多种背景特征整合，增强了模型提取关键数据特征的能力。为了进一步减轻噪声对ISTD的影响，我们开发了一种噪声引导的表示学习策略。这种方法使模型能够学习更具噪声鲁棒性的特征表示，从而提高其在不同噪声环境下的泛化能力。最后，我们开发了一个专门的红外小目标数据集RealScene-ISTD。与最先进的方法相比，我们的方法在检测概率（Pd）、误报率（Fa）和交并比（IoU）方面表现出了优越的性能。代码可在以下链接找到：https://github.com/luy0222/RealScene-ISTD。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Infrared small target detection (ISTD) is highly sensitive to sensor type,observation conditions, and the intrinsic properties of the target. Thesefactors can introduce substantial variations in the distribution of acquiredinfrared image data, a phenomenon known as domain shift. Such distributiondiscrepancies significantly hinder the generalization capability of ISTD modelsacross diverse scenarios. To tackle this challenge, this paper introduces anISTD framework enhanced by domain adaptation. To alleviate distribution shiftbetween datasets and achieve cross-sample alignment, we introduce Cross-viewChannel Alignment (CCA). Additionally, we propose the Cross-view Top-K Fusionstrategy, which integrates target information with diverse background features,enhancing the model' s ability to extract critical data characteristics. Tofurther mitigate the impact of noise on ISTD, we develop a Noise-guidedRepresentation learning strategy. This approach enables the model to learn morenoise-resistant feature representations, to improve its generalizationcapability across diverse noisy domains. Finally, we develop a dedicatedinfrared small target dataset, RealScene-ISTD. Compared to state-of-the-artmethods, our approach demonstrates superior performance in terms of detectionprobability (Pd), false alarm rate (Fa), and intersection over union (IoU). Thecode is available at: https://github.com/luy0222/RealScene-ISTD.</description>
      <author>example@mail.com (Yahao Lu, Yuehui Li, Xingyuan Guo, Shuai Yuan, Yukai Shi, Liang Lin)</author>
      <guid isPermaLink="false">2504.16487v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>SparseJEPA: Sparse Representation Learning of Joint Embedding Predictive Architectures</title>
      <link>http://arxiv.org/abs/2504.16140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SparseJEPA是一种结合了稀疏表示学习的JEPA框架扩展，旨在提高学习到的表示质量。&lt;h4&gt;背景&lt;/h4&gt;JEPA框架虽然强大，但通常缺乏可解释性，且由于密集的嵌入表示而效率低下。&lt;h4&gt;目的&lt;/h4&gt;提出SparseJEPA，旨在通过集成稀疏表示学习来提高JEPA框架中学习到的表示质量。&lt;h4&gt;方法&lt;/h4&gt;SparseJEPA使用一种惩罚方法，鼓励具有强语义关系的数据特征在潜在空间变量中共享，同时保持预测性能。&lt;h4&gt;主要发现&lt;/h4&gt;在CIFAR-100数据集上训练并预训练轻量级视觉Transformer，证明了SparseJEPA的有效性。改进的嵌入在图像分类和低级任务的线性探针迁移学习中得到应用，展示了该架构在不同迁移任务中的多功能性。理论证明表明，分组机制增强了表示质量，通过减少潜在变量间的多信息量，并证明了多信息量的数据处理不等式。&lt;h4&gt;结论&lt;/h4&gt;将稀疏性引入不仅细化了潜在空间，还促进了更有意义和可解释的表示的学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：联合嵌入预测架构（JEPA）已成为学习通用表示的有力框架。然而，这些模型通常缺乏可解释性，并且由于密集的嵌入表示而效率低下。我们提出了SparseJEPA，这是一种将稀疏表示学习集成到JEPA框架中的扩展，以提高学习到的表示质量。SparseJEPA采用一种惩罚方法，鼓励具有强语义关系的数据特征在潜在空间变量中共享，同时保持预测性能。我们通过在CIFAR-100数据集上训练并预训练轻量级视觉Transformer来证明SparseJEPA的有效性。改进的嵌入被用于图像分类和低级任务的线性探针迁移学习，展示了该架构在不同迁移任务中的多功能性。此外，我们提供了一个理论证明，表明分组机制增强了表示质量。这是通过显示分组减少了潜在变量之间的多信息量，并证明了多信息量的数据处理不等式。我们的结果表明，引入稀疏性不仅细化了潜在空间，还促进了更有意义和可解释的表示的学习。在进一步的工作中，希望通过以对象为中心的表示学习找到利用分组机制的新方法来进一步扩展这种方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Joint Embedding Predictive Architectures (JEPA) have emerged as a powerfulframework for learning general-purpose representations. However, these modelsoften lack interpretability and suffer from inefficiencies due to denseembedding representations. We propose SparseJEPA, an extension that integratessparse representation learning into the JEPA framework to enhance the qualityof learned representations. SparseJEPA employs a penalty method that encourageslatent space variables to be shared among data features with strong semanticrelationships, while maintaining predictive performance. We demonstrate theeffectiveness of SparseJEPA by training on the CIFAR-100 dataset andpre-training a lightweight Vision Transformer. The improved embeddings areutilized in linear-probe transfer learning for both image classification andlow-level tasks, showcasing the architecture's versatility across differenttransfer tasks. Furthermore, we provide a theoretical proof that demonstratesthat the grouping mechanism enhances representation quality. This was done bydisplaying that grouping reduces Multiinformation among latent-variables,including proofing the Data Processing Inequality for Multiinformation. Ourresults indicate that incorporating sparsity not only refines the latent spacebut also facilitates the learning of more meaningful and interpretablerepresentations. In further work, hope to further extend this method by findingnew ways to leverage the grouping mechanism through object-centricrepresentation learning.</description>
      <author>example@mail.com (Max Hartman, Lav Varshney)</author>
      <guid isPermaLink="false">2504.16140v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>MMHCL: Multi-Modal Hypergraph Contrastive Learning for Recommendation</title>
      <link>http://arxiv.org/abs/2504.16576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 8 figures. This manuscript is currently under major  revision for ACM Transactions on Multimedia Computing, Communications, and  Applications (ACM TOMM)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多模态超图对比学习框架（MMHCL）用于用户推荐。&lt;h4&gt;背景&lt;/h4&gt;多模态内容分享平台的兴起推动了个性化推荐系统的发展，但以往工作存在数据稀疏和冷启动问题，且无法充分探索多模态数据中的语义用户-产品关联。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出MMHCL框架以用于用户推荐。&lt;h4&gt;方法&lt;/h4&gt;构建了两个超图，即用户到用户（u2u）超图和项目到项目（i2i）超图，分别挖掘用户间的共享偏好和项目间的复杂多模态语义相似性。通过融合一级用户-项目交互作为补充，以缓解数据稀疏性问题。然后，通过应用协同对比学习设计对比特征增强范式，通过最大化/最小化相同/不同用户和项目的二级（如用户共享偏好模式）和一级（用户选择的物品信息）嵌入之间的互信息，有效增强特征可区分性。&lt;h4&gt;主要发现&lt;/h4&gt;与仅使用稀疏的用户-项目交互相比，MMHCL获得了更密集的二级超图，挖掘了更丰富的共享属性来探索用户-产品关联，在一定程度上缓解了数据稀疏和冷启动问题。&lt;h4&gt;结论&lt;/h4&gt;广泛的实验全面证明了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;The burgeoning presence of multimodal content-sharing platforms propels the development of personalized recommender systems. Previous works usually suffer from data sparsity and cold-start problems, and may fail to adequately explore semantic user-product associations from multimodal data. To address these issues, we propose a novel Multi-Modal Hypergraph Contrastive Learning (MMHCL) framework for user recommendation. For a comprehensive information exploration from user-product relations, we construct two hypergraphs, i.e. a user-to-user (u2u) hypergraph and an item-to-item (i2i) hypergraph, to mine shared preferences among users and intricate multimodal semantic resemblance among items, respectively. This process yields denser second-order semantics that are fused with first-order user-item interaction as complementary to alleviate the data sparsity issue. Then, we design a contrastive feature enhancement paradigm by applying synergistic contrastive learning. By maximizing/minimizing the mutual information between second-order (e.g. shared preference pattern for users) and first-order (information of selected items for users) embeddings of the same/different users and items, the feature distinguishability can be effectively enhanced. Compared with using sparse primary user-item interaction only, our MMHCL obtains denser second-order hypergraphs and excavates more abundant shared attributes to explore the user-product associations, which to a certain extent alleviates the problems of data sparsity and cold-start. Extensive experiments have comprehensively demonstrated the effectiveness of our method. Our code is publicly available at: https://github.com/Xu107/MMHCL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The burgeoning presence of multimodal content-sharing platforms propels thedevelopment of personalized recommender systems. Previous works usually sufferfrom data sparsity and cold-start problems, and may fail to adequately exploresemantic user-product associations from multimodal data. To address theseissues, we propose a novel Multi-Modal Hypergraph Contrastive Learning (MMHCL)framework for user recommendation. For a comprehensive information explorationfrom user-product relations, we construct two hypergraphs, i.e. a user-to-user(u2u) hypergraph and an item-to-item (i2i) hypergraph, to mine sharedpreferences among users and intricate multimodal semantic resemblance amongitems, respectively. This process yields denser second-order semantics that arefused with first-order user-item interaction as complementary to alleviate thedata sparsity issue. Then, we design a contrastive feature enhancement paradigmby applying synergistic contrastive learning. By maximizing/minimizing themutual information between second-order (e.g. shared preference pattern forusers) and first-order (information of selected items for users) embeddings ofthe same/different users and items, the feature distinguishability can beeffectively enhanced. Compared with using sparse primary user-item interactiononly, our MMHCL obtains denser second-order hypergraphs and excavates moreabundant shared attributes to explore the user-product associations, which to acertain extent alleviates the problems of data sparsity and cold-start.Extensive experiments have comprehensively demonstrated the effectiveness ofour method. Our code is publicly available at: https://github.com/Xu107/MMHCL.</description>
      <author>example@mail.com (Xu Guo, Tong Zhang, Fuyun Wang, Xudong Wang, Xiaoya Zhang, Xin Liu, Zhen Cui)</author>
      <guid isPermaLink="false">2504.16576v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>SignX: The Foundation Model for Sign Recognition</title>
      <link>http://arxiv.org/abs/2504.16315v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SignX的用于手语识别的基础模型框架，旨在解决手语数据处理中的复杂性。&lt;h4&gt;背景&lt;/h4&gt;手语数据处理具有复杂性，目前的手语识别方法试图通过姿态信息将RGB手语视频翻译成基于英语的ID词，以唯一标识手语手势。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够识别手语视频并产生准确预测词表示的手语识别模型。&lt;h4&gt;方法&lt;/h4&gt;SignX框架包括一个基于逆扩散模型的Pose2Gloss组件，它包含一个多轨迹姿态融合层，统一了五种最强大的姿态信息来源。同时，还训练了一个基于ViT的Video2Pose模块，可以直接将原始视频转换为手势姿态表示。&lt;h4&gt;主要发现&lt;/h4&gt;SignX能够识别手语视频，并产生比先前工作更准确的预测词表示。&lt;h4&gt;结论&lt;/h4&gt;SignX为手语识别提供了兼容现有姿态格式的模型，为手语识别所需的通用姿态估计奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;The complexity of sign language data processing brings many challenges. The current approach to recognition of ASL signs aims to translate RGB sign language videos through pose information into English-based ID glosses, which serve to uniquely identify ASL signs. Note that there is no shared convention for assigning such glosses to ASL signs, so it is essential that the same glossing conventions are used for all of the data in the datasets that are employed. This paper proposes SignX, a foundation model framework for sign recognition. It is a concise yet powerful framework applicable to multiple human activity recognition scenarios. First, we developed a Pose2Gloss component based on an inverse diffusion model, which contains a multi-track pose fusion layer that unifies five of the most powerful pose information sources--SMPLer-X, DWPose, Mediapipe, PrimeDepth, and SapiensSegmentation--into a single latent pose representation. Second, we trained a Video2Pose module based on ViT that can directly convert raw video into signer pose representation. Through this 2-stage training framework, we enable sign language recognition models to be compatible with existing pose formats, laying the foundation for the common pose estimation necessary for sign recognition. Experimental results show that SignX can recognize signs from sign language video, producing predicted gloss representations with greater accuracy than has been reported in prior work.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The complexity of sign language data processing brings many challenges. Thecurrent approach to recognition of ASL signs aims to translate RGB signlanguage videos through pose information into English-based ID glosses, whichserve to uniquely identify ASL signs. Note that there is no shared conventionfor assigning such glosses to ASL signs, so it is essential that the sameglossing conventions are used for all of the data in the datasets that areemployed. This paper proposes SignX, a foundation model framework for signrecognition. It is a concise yet powerful framework applicable to multiplehuman activity recognition scenarios. First, we developed a Pose2Glosscomponent based on an inverse diffusion model, which contains a multi-trackpose fusion layer that unifies five of the most powerful pose informationsources--SMPLer-X, DWPose, Mediapipe, PrimeDepth, and SapiensSegmentation--into a single latent pose representation. Second, we trained aVideo2Pose module based on ViT that can directly convert raw video into signerpose representation. Through this 2-stage training framework, we enable signlanguage recognition models to be compatible with existing pose formats, layingthe foundation for the common pose estimation necessary for sign recognition.Experimental results show that SignX can recognize signs from sign languagevideo, producing predicted gloss representations with greater accuracy than hasbeen reported in prior work.</description>
      <author>example@mail.com (Sen Fang, Chunyu Sui, Hongwei Yi, Carol Neidle, Dimitris N. Metaxas)</author>
      <guid isPermaLink="false">2504.16315v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Active Learning Methods for Efficient Data Utilization and Model Performance Enhancement</title>
      <link>http://arxiv.org/abs/2504.16136v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文详细介绍了主动学习（AL）在数据驱动智能时代的重要性，探讨了其在计算机视觉、自然语言处理、迁移学习等领域的应用，并讨论了相关的研究主题和挑战。&lt;h4&gt;背景&lt;/h4&gt;数据丰富但标注稀缺成为机器学习发展的瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提高模型性能，使用更少的标注样本。&lt;h4&gt;方法&lt;/h4&gt;介绍主动学习的基本概念，讨论其在不同领域的应用，并关注不确定性估计、处理类别不平衡、领域自适应、公平性、创建强评估指标和基准等问题。&lt;h4&gt;主要发现&lt;/h4&gt;主动学习方法可以改善数据效率，帮助模型更有效地学习；主动学习通常比被动学习效果更好，特别是当使用良好的评估指标时。&lt;h4&gt;结论&lt;/h4&gt;本文旨在为研究人员和实践者提供关键见解，并就主动学习的未来进展提出方向。&lt;h4&gt;翻译&lt;/h4&gt;在数据驱动智能时代，数据丰富与标注稀缺的悖论已成为机器学习发展的关键瓶颈。本文详细介绍了主动学习（AL），这是机器学习中一种利用更少的标注样本帮助模型实现更好性能的策略。本文介绍了AL的基本概念，并讨论了其在计算机视觉、自然语言处理、迁移学习以及现实世界应用中的使用。本文重点关注不确定性估计、处理类别不平衡、领域自适应、公平性以及创建强大评估指标和基准等重要研究主题。此外，本文还展示了受人类启发并由问题引导的学习方法如何提高数据效率并帮助模型更有效地学习。此外，本文还讨论了该领域的当前挑战，包括重建信任、确保可重复性和处理不一致的方法。本文指出，在良好的评估指标下，主动学习往往比被动学习效果更好。本工作的目标是通过对主动学习的关键见解和未来进展方向的提出，为研究人员和实践者提供帮助。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of data-driven intelligence, the paradox of data abundance andannotation scarcity has emerged as a critical bottleneck in the advancement ofmachine learning. This paper gives a detailed overview of Active Learning (AL),which is a strategy in machine learning that helps models achieve betterperformance using fewer labeled examples. It introduces the basic concepts ofAL and discusses how it is used in various fields such as computer vision,natural language processing, transfer learning, and real-world applications.The paper focuses on important research topics such as uncertainty estimation,handling of class imbalance, domain adaptation, fairness, and the creation ofstrong evaluation metrics and benchmarks. It also shows that learning methodsinspired by humans and guided by questions can improve data efficiency and helpmodels learn more effectively. In addition, this paper talks about currentchallenges in the field, including the need to rebuild trust, ensurereproducibility, and deal with inconsistent methodologies. It points out thatAL often gives better results than passive learning, especially when goodevaluation measures are used. This work aims to be useful for both researchersand practitioners by providing key insights and proposing directions for futureprogress in active learning.</description>
      <author>example@mail.com (Chiung-Yi Tseng, Junhao Song, Ziqian Bi, Tianyang Wang, Chia Xin Liang, Ming Liu)</author>
      <guid isPermaLink="false">2504.16136v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Capturing Symmetry and Antisymmetry in Language Models through Symmetry-Aware Training Objectives</title>
      <link>http://arxiv.org/abs/2504.16312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了基于Wikidata的自然语言推理数据集，用于评估大型语言模型在捕捉对称和反对称关系方面的性能，并探讨了通过对比学习和k近邻方法改进编码器以增强关系理解。&lt;h4&gt;背景&lt;/h4&gt;捕捉对称和反对称关系对于多种应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;评估大型语言模型在关系理解上的表现，并探索改进方法。&lt;h4&gt;方法&lt;/h4&gt;使用基于Wikidata的数据集评估LLMs，并通过对比学习结合k近邻方法重新训练编码器。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs在关系理解上的表现与随机机会相当，存在关系理解上的差距。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习和k近邻方法重新训练的编码器在性能上与微调的分类头相当，同时在少样本学习和减轻灾难性遗忘方面具有额外优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：捕捉对称（例如，国家边界另一国家）和反对称（例如，父母与子女关系）关系对于多种应用至关重要。本文通过引入一个基于Wikidata的自然语言推理数据集来评估大型语言模型（LLMs）来解决这一挑战。我们的发现显示LLMs在基准测试上的表现与随机机会相当，突显了关系理解的差距。为了解决这个问题，我们探索了通过带有k近邻的对比学习方法重新训练编码器。重新训练的编码器在性能上与微调的分类头相当，同时提供了额外的优势，包括在少样本学习中的更高效率和改善灾难性遗忘的缓解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Capturing symmetric (e.g., country borders another country) and antisymmetric(e.g., parent_of) relations is crucial for a variety of applications. Thispaper tackles this challenge by introducing a novel Wikidata-derived naturallanguage inference dataset designed to evaluate large language models (LLMs).Our findings reveal that LLMs perform comparably to random chance on thisbenchmark, highlighting a gap in relational understanding. To address this, weexplore encoder retraining via contrastive learning with k-nearest neighbors.The retrained encoder matches the performance of fine-tuned classificationheads while offering additional benefits, including greater efficiency infew-shot learning and improved mitigation of catastrophic forgetting.</description>
      <author>example@mail.com (Zhangdie Yuan, Andreas Vlachos)</author>
      <guid isPermaLink="false">2504.16312v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Trends in Frontier AI Model Count: A Forecast to 2028</title>
      <link>http://arxiv.org/abs/2504.16138v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于训练计算量对AI模型的要求，分析了不同计算阈值下模型数量的变化趋势。&lt;h4&gt;背景&lt;/h4&gt;欧洲AI法案和美国AI扩散框架都对训练计算量超过特定阈值的AI模型提出了要求。&lt;h4&gt;目的&lt;/h4&gt;研究这些计算阈值在未来能捕捉多少模型，以及每年超过这些阈值的模型数量增长趋势。&lt;h4&gt;方法&lt;/h4&gt;通过估计，预测了到2028年底，将有超过欧盟AI法案和AI扩散框架定义的阈值模型数量。&lt;h4&gt;主要发现&lt;/h4&gt;预计到2028年底，将有103-306个基础模型超过欧盟AI法案的$10^{25}$ FLOP阈值，45-148个模型超过美国AI扩散框架的$10^{26}$ FLOP阈值。每年超过这些阈值的模型数量将呈超线性增长。以目前最大的训练运行规模为基准定义的阈值，从2025年到2028年的平均预测值为每年捕获14-16个模型。&lt;h4&gt;结论&lt;/h4&gt;计算阈值对AI模型的监管将随着时间的推移而扩大，且每年捕获的模型数量将呈现指数增长趋势。&lt;h4&gt;翻译&lt;/h4&gt;Governments are beginning to impose requirements on AI models based on how much compute was used to train them. For example, the EU AI Act imposes requirements on providers of general-purpose AI with systemic risk, which includes systems trained using greater than $10^{25}$ floating point operations (FLOP). In the United States' AI Diffusion Framework, a training compute threshold of $10^{26}$ FLOP is used to identify 'controlled models' which face a number of requirements. We explore how many models such training compute thresholds will capture over time. We estimate that by the end of 2028, there will be between 103-306 foundation models exceeding the $10^{25}$ FLOP threshold put forward in the EU AI Act (90% CI), and 45-148 models exceeding the $10^{26}$ FLOP threshold that defines controlled models in the AI Diffusion Framework (90% CI). We also find that the number of models exceeding these absolute compute thresholds each year will increase superlinearly—that is, each successive year will see more new models captured within the threshold than the year before. Thresholds that are defined with respect to the largest training run to date (for example, such that all models within one order of magnitude of the largest training run to date are captured by the threshold) see a more stable trend, with a median forecast of 14-16 models being captured by this definition annually from 2025-2028.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Governments are starting to impose requirements on AI models based on howmuch compute was used to train them. For example, the EU AI Act imposesrequirements on providers of general-purpose AI with systemic risk, whichincludes systems trained using greater than $10^{25}$ floating point operations(FLOP). In the United States' AI Diffusion Framework, a training computethreshold of $10^{26}$ FLOP is used to identify "controlled models" which facea number of requirements. We explore how many models such training computethresholds will capture over time. We estimate that by the end of 2028, therewill be between 103-306 foundation models exceeding the $10^{25}$ FLOPthreshold put forward in the EU AI Act (90% CI), and 45-148 models exceedingthe $10^{26}$ FLOP threshold that defines controlled models in the AI DiffusionFramework (90% CI). We also find that the number of models exceeding theseabsolute compute thresholds each year will increase superlinearly -- that is,each successive year will see more new models captured within the thresholdthan the year before. Thresholds that are defined with respect to the largesttraining run to date (for example, such that all models within one order ofmagnitude of the largest training run to date are captured by the threshold)see a more stable trend, with a median forecast of 14-16 models being capturedby this definition annually from 2025-2028.</description>
      <author>example@mail.com (Iyngkarran Kumar, Sam Manning)</author>
      <guid isPermaLink="false">2504.16138v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning for Tabular Data: A Comprehensive Survey</title>
      <link>http://arxiv.org/abs/2504.16109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对表格数据表示学习领域进行了系统介绍，涵盖了背景、挑战、基准以及使用深度神经网络（DNNs）的优缺点，并按照泛化能力将现有方法分为三类：专用模型、可迁移模型和通用模型。&lt;h4&gt;背景&lt;/h4&gt;表格数据是机器学习分类和回归应用中最常见的数据类型之一。深度神经网络（DNNs）在表示学习能力方面的近期成果表明，其在该领域具有应用潜力。&lt;h4&gt;目的&lt;/h4&gt;对表格表示学习领域的背景、挑战、基准以及使用DNNs的优缺点进行系统介绍。&lt;h4&gt;方法&lt;/h4&gt;将现有方法根据泛化能力分为专用、可迁移和通用模型三类，并详细介绍了专用模型的层次分类法及其特征、样本和目标关键方面的策略，以及可迁移模型和通用模型在不同数据集上的应用策略。&lt;h4&gt;主要发现&lt;/h4&gt;专用模型关注训练和评估在相同数据分布中的任务；可迁移模型在多个数据集上预训练后，在下游任务中进行微调；通用模型允许直接应用于下游任务而不需要微调。&lt;h4&gt;结论&lt;/h4&gt;本文对表格学习领域的各种方法进行了全面的概述，并讨论了表格学习的代表性扩展，如开放环境表格机器学习、多模态学习与表格数据结合以及表格理解。&lt;h4&gt;翻译&lt;/h4&gt;This abstract provides a summary of a survey paper on tabular representation learning in machine learning. The paper introduces the field, discusses challenges and benchmarks, evaluates the pros and cons of using deep neural networks, and categorizes existing methods into specialized, transferable, and general models based on their generalization capabilities. It also explores ensemble methods and discusses extensions of tabular learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular data, structured as rows and columns, is among the most prevalentdata types in machine learning classification and regression applications.Models for learning from tabular data have continuously evolved, with DeepNeural Networks (DNNs) recently demonstrating promising results through theircapability of representation learning. In this survey, we systematicallyintroduce the field of tabular representation learning, covering thebackground, challenges, and benchmarks, along with the pros and cons of usingDNNs. We organize existing methods into three main categories according totheir generalization capabilities: specialized, transferable, and generalmodels. Specialized models focus on tasks where training and evaluation occurwithin the same data distribution. We introduce a hierarchical taxonomy forspecialized models based on the key aspects of tabular data -- features,samples, and objectives -- and delve into detailed strategies for obtaininghigh-quality feature- and sample-level representations. Transferable models arepre-trained on one or more datasets and subsequently fine-tuned on downstreamtasks, leveraging knowledge acquired from homogeneous or heterogeneous sources,or even cross-modalities such as vision and language. General models, alsoknown as tabular foundation models, extend this concept further, allowingdirect application to downstream tasks without fine-tuning. We group thesegeneral models based on the strategies used to adapt across heterogeneousdatasets. Additionally, we explore ensemble methods, which integrate thestrengths of multiple tabular models. Finally, we discuss representativeextensions of tabular learning, including open-environment tabular machinelearning, multimodal learning with tabular data, and tabular understanding.More information can be found in the following repository:https://github.com/LAMDA-Tabular/Tabular-Survey.</description>
      <author>example@mail.com (Jun-Peng Jiang, Si-Yang Liu, Hao-Run Cai, Qile Zhou, Han-Jia Ye)</author>
      <guid isPermaLink="false">2504.16109v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive Analysis</title>
      <link>http://arxiv.org/abs/2504.16047v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究评估了三种不同的视觉-语言基础模型（RAD-DINO、CheXagent和BiomedCLIP）在捕捉细粒度成像特征方面的能力，并在胸部X光片上的气胸和心增大分类、分割和回归任务中进行了评估。&lt;h4&gt;背景&lt;/h4&gt;基于大量数据使用自监督技术训练的基础模型在医学领域的AI应用中成为了一个有前景的前沿。&lt;h4&gt;目的&lt;/h4&gt;研究旨在评估RAD-DINO、CheXagent和BiomedCLIP三种基础模型在放射学任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;模型在气胸和心增大分类、分割和回归任务中进行了评估，并创建了一个结合全局和局部特征的定制分割模型。&lt;h4&gt;主要发现&lt;/h4&gt;RAD-DINO在分割任务中表现优异，CheXagent在分类任务中表现优越，BiomedCLIP在任务间表现不一致。定制分割模型显著提高了所有基础模型的表现，特别是在挑战性的气胸分割任务中。自监督的RAD-DINO在分割任务中表现更好，而文本监督的模型在分类和可解释性方面有优势。&lt;h4&gt;结论&lt;/h4&gt;预训练方法对特定下游任务中的模型性能有显著影响。对于细粒度分割任务，无文本监督训练的模型表现更好，而文本监督模型在分类和可解释性方面有优势。这些见解为根据特定的临床应用选择基础模型提供了指导。&lt;h4&gt;翻译&lt;/h4&gt;This study evaluates three different vision-language foundation models (RAD-DINO, CheXagent, and BiomedCLIP) on their ability to capture fine-grained imaging features for radiology tasks. The models were assessed across classification, segmentation, and regression tasks for pneumothorax and cardiomegaly on chest radiographs. Self-supervised RAD-DINO consistently excelled in segmentation tasks, while text-supervised CheXagent demonstrated superior classification performance. BiomedCLIP showed inconsistent performance across tasks. A custom segmentation model that integrates global and local features substantially improved performance for all foundation models, particularly for challenging pneumothorax segmentation. The findings highlight that pre-training methodology significantly influences model performance on specific downstream tasks. For fine-grained segmentation tasks, models trained without text supervision performed better, while text-supervised models offered advantages in classification and interpretability. These insights provide guidance for selecting foundation models based on specific clinical applications in radiology.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, trained on vast amounts of data using self-supervisedtechniques, have emerged as a promising frontier for advancing artificialintelligence (AI) applications in medicine. This study evaluates threedifferent vision-language foundation models (RAD-DINO, CheXagent, andBiomedCLIP) on their ability to capture fine-grained imaging features forradiology tasks. The models were assessed across classification, segmentation,and regression tasks for pneumothorax and cardiomegaly on chest radiographs.Self-supervised RAD-DINO consistently excelled in segmentation tasks, whiletext-supervised CheXagent demonstrated superior classification performance.BiomedCLIP showed inconsistent performance across tasks. A custom segmentationmodel that integrates global and local features substantially improvedperformance for all foundation models, particularly for challengingpneumothorax segmentation. The findings highlight that pre-training methodologysignificantly influences model performance on specific downstream tasks. Forfine-grained segmentation tasks, models trained without text supervisionperformed better, while text-supervised models offered advantages inclassification and interpretability. These insights provide guidance forselecting foundation models based on specific clinical applications inradiology.</description>
      <author>example@mail.com (Frank Li, Hari Trivedi, Bardia Khosravi, Theo Dapamede, Mohammadreza Chavoshi, Abdulhameed Dere, Rohan Satya Isaac, Aawez Mansuri, Janice Newsome, Saptarshi Purkayastha, Judy Gichoya)</author>
      <guid isPermaLink="false">2504.16047v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
  <item>
      <title>Vision language models are unreliable at trivial spatial cognition</title>
      <link>http://arxiv.org/abs/2504.16061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉语言模型（VLMs）在提取图像中的视觉空间信息方面的能力，并探讨了其在场景理解和处理关系信息方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;VLMs旨在从图像中提取相关视觉空间信息，部分研究表明VLMs能够表现出类似人类的场景理解能力，但其他研究指出它们在处理关系信息方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了测试VLMs在处理简单空间认知任务上的可靠性，例如在无杂乱场景中识别一个物体是否位于另一个物体的左侧。&lt;h4&gt;方法&lt;/h4&gt;研究人员开发了一个名为TableTest的基准数据集，其中的图像描绘了物体排列在桌子上的3D场景，并使用该数据集评估了最先进的VLMs。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，使用逻辑等价描述的提示的微小变化可能会降低性能，这表明VLMs在现实应用中推理空间关系的能力存在局限性。&lt;h4&gt;结论&lt;/h4&gt;这些分析揭示了通过增强图像标题语料库来提高训练和测试效率的新机会。&lt;h4&gt;翻译&lt;/h4&gt;Vision language models (VLMs) are designed to extract relevant visuospatial information from images. Some research suggests that VLMs can exhibit human-like scene understanding, while other investigations reveal difficulties in their ability to process relational information. To achieve widespread applicability, VLMs must perform reliably, yielding comparable competence across a wide variety of related tasks. We sought to test how reliable these architectures are at engaging in trivial spatial cognition, e.g., recognizing whether one object is left of another in an uncluttered scene. We developed a benchmark dataset -- TableTest -- whose images depict 3D scenes of objects arranged on a table, and used it to evaluate state-of-the-art VLMs. Results show that performance could be degraded by minor variations of prompts that use logically equivalent descriptions. These analyses suggest limitations in how VLMs may reason about spatial relations in real-world applications. They also reveal novel opportunities for bolstering image caption corpora for more efficient training and testing.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision language models (VLMs) are designed to extract relevant visuospatialinformation from images. Some research suggests that VLMs can exhibit humanlikescene understanding, while other investigations reveal difficulties in theirability to process relational information. To achieve widespread applicability,VLMs must perform reliably, yielding comparable competence across a widevariety of related tasks. We sought to test how reliable these architecturesare at engaging in trivial spatial cognition, e.g., recognizing whether oneobject is left of another in an uncluttered scene. We developed a benchmarkdataset -- TableTest -- whose images depict 3D scenes of objects arranged on atable, and used it to evaluate state-of-the-art VLMs. Results show thatperformance could be degraded by minor variations of prompts that use logicallyequivalent descriptions. These analyses suggest limitations in how VLMs mayreason about spatial relations in real-world applications. They also revealnovel opportunities for bolstering image caption corpora for more efficienttraining and testing.</description>
      <author>example@mail.com (Sangeet Khemlani, Tyler Tran, Nathaniel Gyory, Anthony M. Harrison, Wallace E. Lawson, Ravenna Thielstrom, Hunter Thompson, Taaren Singh, J. Gregory Trafton)</author>
      <guid isPermaLink="false">2504.16061v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>DINOv2-powered Few-Shot Semantic Segmentation: A Unified Framework via Cross-Model Distillation and 4D Correlation Mining</title>
      <link>http://arxiv.org/abs/2504.15669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FS-DINO的少样本语义分割方法，通过结合DINOv2和SAM的知识，实现轻量级的分割器，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;少样本语义分割因其泛化能力而受到关注，即通过少量标注图像对新型类别的像素进行分割。现有研究主要集中于元学习和支持-查询匹配，包括基于原型和聚合的方法。为了解决数据稀缺问题，最近的方法转向使用基础模型来增强新型类别分割的可迁移性。&lt;h4&gt;目的&lt;/h4&gt;探索是否可以构建一个统一模型，结合基础模型的知识。&lt;h4&gt;方法&lt;/h4&gt;FS-DINO使用DINOv2的编码器和轻量级分割器。分割器包括瓶颈适配器、基于密集相似性和语义嵌入的元视觉提示生成器以及解码器。通过粗到细的跨模型蒸馏，将SAM的知识有效集成到轻量级分割器中，并通过支持-查询对的4D相关性挖掘进一步增强。&lt;h4&gt;主要发现&lt;/h4&gt;FS-DINO在COCO-20i、PASCAL-5i和FSS-1000数据集上的实验表明，该方法具有有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;FS-DINO是一种有效的少样本语义分割方法，通过结合DINOv2和SAM的知识，实现了轻量级分割器的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot semantic segmentation has gained increasing interest due to itsgeneralization capability, i.e., segmenting pixels of novel classes requiringonly a few annotated images. Prior work has focused on meta-learning forsupport-query matching, with extensive development in both prototype-based andaggregation-based methods. To address data scarcity, recent approaches haveturned to foundation models to enhance representation transferability for novelclass segmentation. Among them, a hybrid dual-modal framework including bothDINOv2 and SAM has garnered attention due to their complementary capabilities.We wonder "can we build a unified model with knowledge from both foundationmodels?" To this end, we propose FS-DINO, with only DINOv2's encoder and alightweight segmenter. The segmenter features a bottleneck adapter, ameta-visual prompt generator based on dense similarities and semanticembeddings, and a decoder. Through coarse-to-fine cross-model distillation, weeffectively integrate SAM's knowledge into our lightweight segmenter, which canbe further enhanced by 4D correlation mining on support-query pairs. Extensiveexperiments on COCO-20i, PASCAL-5i, and FSS-1000 demonstrate the effectivenessand superiority of our method.</description>
      <author>example@mail.com (Wei Zhuo, Zhiyue Tang, Wufeng Xue, Hao Ding, Linlin Shen)</author>
      <guid isPermaLink="false">2504.15669v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>SocialMOIF: Multi-Order Intention Fusion for Pedestrian Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2504.15616v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages,6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SocialMOIF的方法，用于分析和预测智能系统中代理的轨迹，以提高决策过程的准确性。&lt;h4&gt;背景&lt;/h4&gt;当前研究在量化建模代理及其社会互动方面存在局限性，主要因为代理意图的不确定性和相邻群体之间复杂的高阶影响。&lt;h4&gt;目的&lt;/h4&gt;SocialMOIF旨在解决上述挑战，通过融合多阶意图信息，实现对直接和间接意图信息的更全面理解。&lt;h4&gt;方法&lt;/h4&gt;SocialMOIF方法包括：1) 设计一个轨迹分布近似器，引导轨迹值更接近实际数据；2) 引入全局轨迹优化器，实现更准确和高效的并行预测；3) 使用考虑距离和方向的损失函数进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SocialMOIF模型在动态和静态数据集上，多个指标上均优于现有的最先进基线。&lt;h4&gt;结论&lt;/h4&gt;SocialMOIF模型能够有效提高代理轨迹预测的准确性，对智能系统的决策过程具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：智能系统中代理轨迹的分析和预测对决策过程至关重要，精确的短期轨迹预测在众多应用中具有重要意义。研究者们从不同角度量化并建模了代理及其社会互动；然而，由于代理意图的不确定性和相邻群体之间复杂的高阶影响，当前工作存在重大局限性。SocialMOIF被提出以应对这些挑战，它专注于相邻群体之间的高阶意图交互，同时强化邻居和目标代理之间的一阶意图交互的首要作用。该方法通过开发一个多阶意图融合模型来实现对直接和间接意图信息的更全面理解。在SocialMOIF中，设计了一个轨迹分布近似器，以引导轨迹向更接近实际数据的值发展，从而提高模型的可解释性。此外，引入了一个全局轨迹优化器，以实现更准确和高效的并行预测。通过在训练过程中考虑距离和方向的损失函数，实验结果证明了该模型在动态和静态数据集上，多个指标上均优于现有的最先进基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The analysis and prediction of agent trajectories are crucial fordecision-making processes in intelligent systems, with precise short-termtrajectory forecasting being highly significant across a range of applications.Agents and their social interactions have been quantified and modeled byresearchers from various perspectives; however, substantial limitations existin the current work due to the inherent high uncertainty of agent intentionsand the complex higher-order influences among neighboring groups. SocialMOIF isproposed to tackle these challenges, concentrating on the higher-orderintention interactions among neighboring groups while reinforcing the primaryrole of first-order intention interactions between neighbors and the targetagent. This method develops a multi-order intention fusion model to achieve amore comprehensive understanding of both direct and indirect intentioninformation. Within SocialMOIF, a trajectory distribution approximator isdesigned to guide the trajectories toward values that align more closely withthe actual data, thereby enhancing model interpretability. Furthermore, aglobal trajectory optimizer is introduced to enable more accurate and efficientparallel predictions. By incorporating a novel loss function that accounts fordistance and direction during training, experimental results demonstrate thatthe model outperforms previous state-of-the-art baselines across multiplemetrics in both dynamic and static datasets.</description>
      <author>example@mail.com (Kai Chen, Xiaodong Zhao, Yujie Huang, Guoyu Fang, Xiao Song, Ruiping Wang, Ziyuan Wang)</author>
      <guid isPermaLink="false">2504.15616v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Intent-aware Diffusion with Contrastive Learning for Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2504.16077v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at SIGIR 2025. 10 pages, 6 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为InDiRec的序列推荐模型，通过结合对比学习和意图感知扩散来提高推荐效果。&lt;h4&gt;背景&lt;/h4&gt;现有的序列推荐模型通过随机数据增强来生成多个视图，但这种方法可能引入噪声，破坏原始交互序列中的潜在意图信息。&lt;h4&gt;目的&lt;/h4&gt;提出InDiRec旨在解决现有方法中噪声引入和意图信息丢失的问题，以学习更鲁棒的用户行为模式。&lt;h4&gt;方法&lt;/h4&gt;InDiRec首先使用K-means对序列表示进行意图聚类，构建意图引导信号。然后，检索目标交互序列的意图表示，引导条件扩散模型生成具有相同意图的正面视图。最后，应用对比学习以最大化意图对齐视图和原始序列之间的表示一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在五个公开数据集上的实验表明，InDiRec相较于现有基线方法，在噪声和稀疏数据条件下也能实现更优的性能。&lt;h4&gt;结论&lt;/h4&gt;InDiRec通过结合对比学习和意图感知扩散，能够生成更可靠的增强视图，从而提高序列推荐模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3726302.3730010&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has proven effective in training sequentialrecommendation models by incorporating self-supervised signals from augmentedviews. Most existing methods generate multiple views from the same interactionsequence through stochastic data augmentation, aiming to align theirrepresentations in the embedding space. However, users typically have specificintents when purchasing items (e.g., buying clothes as gifts or cosmetics forbeauty). Random data augmentation used in existing methods may introduce noise,disrupting the latent intent information implicit in the original interactionsequence. Moreover, using noisy augmented sequences in contrastive learning maymislead the model to focus on irrelevant features, distorting the embeddingspace and failing to capture users' true behavior patterns and intents. Toaddress these issues, we propose Intent-aware Diffusion with contrastivelearning for sequential Recommendation (InDiRec). The core idea is to generateitem sequences aligned with users' purchasing intents, thus providing morereliable augmented views for contrastive learning. Specifically, InDiRec firstperforms intent clustering on sequence representations using K-means to buildintent-guided signals. Next, it retrieves the intent representation of thetarget interaction sequence to guide a conditional diffusion model, generatingpositive views that share the same underlying intent. Finally, contrastivelearning is applied to maximize representation consistency between theseintent-aligned views and the original sequence. Extensive experiments on fivepublic datasets demonstrate that InDiRec achieves superior performance comparedto existing baselines, learning more robust representations even under noisyand sparse data conditions.</description>
      <author>example@mail.com (Yuanpeng Qu, Hajime Nobuhara)</author>
      <guid isPermaLink="false">2504.16077v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Differentiable graph neural network simulator for forward and inverse modeling of multi-layered slope system with multiple material properties</title>
      <link>http://arxiv.org/abs/2504.15938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对多层坡系统的可微分图神经网络模拟器（GNS）框架，用于模拟颗粒流。&lt;h4&gt;背景&lt;/h4&gt;现有的颗粒流模拟主要针对简化的几何形状和材料特性，通常只考虑摩擦角，这不能反映实际地质工程中斜坡等系统的复杂性。&lt;h4&gt;目的&lt;/h4&gt;设计一个可以同时进行正向和逆向建模的GNS框架，用于模拟多层斜坡系统。&lt;h4&gt;方法&lt;/h4&gt;正向建模组件使用微调的GNS，该GNS结合了摩擦角和凝聚力。逆向建模组件利用训练好的GNS、反向模式自动微分和L-BFGS-B优化，从目标溃决几何形状推断材料特性。&lt;h4&gt;主要发现&lt;/h4&gt;GNS在模拟多材料流动力学时，实现了高达145倍的比材料点方法（MPM）的计算速度提升。通过柱状倒塌和多层斜坡溃决模拟，验证了其性能。逆向建模可以快速（几分钟内）得到与目标强度值良好的吻合。&lt;h4&gt;结论&lt;/h4&gt;该框架为现实斜坡系统中正向溃决评估和逆向强度反演提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural network simulators (GNS) have emerged as a computationallyefficient tool for simulating granular flows. Previous efforts have beenlimited to simplified geometries and material characterizations, typicallyconsidering only friction angle, which does not reflect the complexity ofrealistic geotechnical systems such as slopes encountered in engineeringpractice. This study introduces a differentiable GNS framework designed formulti-layered slope systems comprising both forward and inverse modelingcomponents. The forward component relies on a fine-tuned GNS that incorporatesboth friction angle and cohesion. Its performance is demonstrated throughcolumn collapse and multi-layered slope runout simulations, where GNSreplicates multi-material flow dynamics while achieving up to 145xcomputational speedup over the Material Point Method (MPM). The inversemodeling component leverages the trained GNS, reverse-mode automaticdifferentiation, and L-BFGS-B optimization to infer material properties from atarget runout geometry. Its performance is demonstrated by back-calculating thematerial strengths that led to failure-induced runout in a dam system composedof multiple materials. Results are obtained within minutes and show goodagreement with the target strength values. The framework introduced in thisstudy provides an efficient approach for forward runout assessments and inversestrength back-calculation in realistic slope systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural network simulators (GNS) have emerged as a computationallyefficient tool for simulating granular flows. Previous efforts have beenlimited to simplified geometries and material characterizations, typicallyconsidering only friction angle, which does not reflect the complexity ofrealistic geotechnical systems such as slopes encountered in engineeringpractice. This study introduces a differentiable GNS framework designed formulti-layered slope systems comprising both forward and inverse modelingcomponents. The forward component relies on a fine-tuned GNS that incorporatesboth friction angle and cohesion. Its performance is demonstrated throughcolumn collapse and multi-layered slope runout simulations, where GNSreplicates multi-material flow dynamics while achieving up to 145xcomputational speedup over the Material Point Method (MPM). The inversemodeling component leverages the trained GNS, reverse-mode automaticdifferentiation, and L-BFGS-B optimization to infer material properties from atarget runout geometry. Its performance is demonstrated by back-calculating thematerial strengths that led to failure-induced runout in a dam system composedof multiple materials. Results are obtained within minutes and show goodagreement with the target strength values. The framework introduced in thisstudy provides an efficient approach for forward runout assessments and inversestrength back-calculation in realistic slope systems.</description>
      <author>example@mail.com (Yongjin Choi, Jorge Macedo, Chenying Liu)</author>
      <guid isPermaLink="false">2504.15938v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>MR. Video: "MapReduce" is the Principle for Long Video Understanding</title>
      <link>http://arxiv.org/abs/2504.16082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MR. Video的智能长视频理解框架，该框架采用MapReduce原理处理长视频，通过独立密集感知短视频片段和联合聚合所有片段信息来提高视频理解能力。&lt;h4&gt;背景&lt;/h4&gt;当前视频理解技术通常受限于视频的上下文长度，而MR. Video通过MapReduce原理来克服这一限制。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够有效处理长视频并提高视频理解准确性的框架。&lt;h4&gt;方法&lt;/h4&gt;MR. Video采用MapReduce两阶段处理：第一阶段（Captioning）生成短视频片段的标题，并将重复的字符和对象标准化为共享名称；第二阶段（Analysis）针对用户问题，从单个短视频中分析相关信息，并将其整合为最终答案。&lt;h4&gt;主要发现&lt;/h4&gt;MR. Video在LVBench挑战性测试中，与最先进的VLMs和视频智能体相比，实现了超过10%的准确率提升。&lt;h4&gt;结论&lt;/h4&gt;MR. Video框架通过MapReduce原理有效地提高了长视频理解能力，适用于VLMs和视频智能体。&lt;h4&gt;翻译&lt;/h4&gt;We propose MR. Video, an agentic long video understanding framework thatdemonstrates the simple yet effective MapReduce principle for processing longvideos: (1) Map: independently and densely perceiving short video clips, and(2) Reduce: jointly aggregating information from all clips. Compared withsequence-to-sequence vision-language models (VLMs), MR. Video performs detailedshort video perception without being limited by context length. Compared withexisting video agents that typically rely on sequential key segment selection,the Map operation enables simpler and more scalable sequence parallelperception of short video segments. Its Reduce step allows for morecomprehensive context aggregation and reasoning, surpassing explicit keysegment retrieval. This MapReduce principle is applicable to both VLMs andvideo agents, and we use LLM agents to validate its effectiveness. In practice, MR. Video employs two MapReduce stages: (A) Captioning: generating captions for short video clips (map), then standardizing repeated characters and objects into shared names (reduce); (B) Analysis: for each user question, analyzing relevant information from individual short videos (map), and integrating them into a final answer (reduce). MR. Video achieves over 10%accuracy improvement on the challenging LVBench compared to state-of-the-artVLMs and video agents. Code is available at: https://github.com/ziqipang/MR-Video&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose MR. Video, an agentic long video understanding framework thatdemonstrates the simple yet effective MapReduce principle for processing longvideos: (1) Map: independently and densely perceiving short video clips, and(2) Reduce: jointly aggregating information from all clips. Compared withsequence-to-sequence vision-language models (VLMs), MR. Video performs detailedshort video perception without being limited by context length. Compared withexisting video agents that typically rely on sequential key segment selection,the Map operation enables simpler and more scalable sequence parallelperception of short video segments. Its Reduce step allows for morecomprehensive context aggregation and reasoning, surpassing explicit keysegment retrieval. This MapReduce principle is applicable to both VLMs andvideo agents, and we use LLM agents to validate its effectiveness.  In practice, MR. Video employs two MapReduce stages: (A) Captioning:generating captions for short video clips (map), then standardizing repeatedcharacters and objects into shared names (reduce); (B) Analysis: for each userquestion, analyzing relevant information from individual short videos (map),and integrating them into a final answer (reduce). MR. Video achieves over 10%accuracy improvement on the challenging LVBench compared to state-of-the-artVLMs and video agents.  Code is available at: https://github.com/ziqipang/MR-Video</description>
      <author>example@mail.com (Ziqi Pang, Yu-Xiong Wang)</author>
      <guid isPermaLink="false">2504.16082v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting</title>
      <link>http://arxiv.org/abs/2504.15485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and data: https://github.com/atinpothiraj/CAPTURe&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的任务CAPTURe，用于测试模型对遮挡物体的推理能力，并评估了视觉语言模型在理解遮挡模式和空间理解方面的能力。&lt;h4&gt;背景&lt;/h4&gt;遮挡在现实世界中很常见，对空间理解构成障碍，因此识别和理解遮挡物体对于理解视觉场景至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计CAPTURe任务以测试模型在推理多个遮挡物体方面的能力，并评估视觉语言模型是否能够理解遮挡模式并具备空间理解技能。&lt;h4&gt;方法&lt;/h4&gt;CAPTURe包括两部分：CAPTURe-real使用真实物体的手动过滤图像，CAPTURe-synthetic使用生成的图案图像进行控制诊断。研究人员评估了四个强大的视觉语言模型在CAPTURe上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，模型在遮挡和非遮挡图案上的计数都存在困难，且在遮挡情况下的表现更差，表明视觉语言模型在推断未见的空间关系方面也存在不足。&lt;h4&gt;结论&lt;/h4&gt;尽管最强视觉语言模型GPT-4o在遮挡情况下也未能成功计数，但人类在CAPTURe任务上几乎不出错。此外，提供遮挡物体位置的辅助信息可以提高模型性能，这表明模型错误既来自于处理遮挡的能力不足，也来自于在图像中计数时的困难。&lt;h4&gt;翻译&lt;/h4&gt;Recognizing and reasoning about occluded objects is vital to understanding visual scenes, as occlusions frequently occur in real-world environments and act as obstacles for spatial comprehension. To test models' ability to reason about multiple occluded objects, we introduce a novel task, Counting Amodally for Patterns Through Unseen REgions (CAPTURe), which requires a model to count objects arranged in a pattern by inferring how the pattern continues behind an occluder (an object which blocks parts of the scene). CAPTURe requires both recognizing visual patterns and reasoning, making it a useful testbed for evaluating vision-language models (VLMs) on whether they understand occluded patterns and possess spatial understanding skills. By requiring models to reason about occluded objects, CAPTURe also tests VLMs' ability to form world models that would allow them to fill in missing information. CAPTURe consists of two parts: (1) CAPTURe-real, with manually filtered images of real objects in patterns and (2) CAPTURe-synthetic, a controlled diagnostic with generated patterned images. We evaluate four strong VLMs (GPT-4o, Intern-VL2, Molmo, and Qwen2-VL) on CAPTURe, finding that models struggle to count on both occluded and unoccluded patterns. Crucially, we find that models perform worse with occlusion, suggesting that VLMs are also deficient in inferring unseen spatial relationships: even the strongest VLMs like GPT-4o fail to count with occlusion. In contrast, we find that humans achieve very little error on CAPTURe. We also find that providing auxiliary information of occluded object locations increases performance, underscoring that the model error comes both from an inability to handle occlusion as well as difficulty counting in images.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recognizing and reasoning about occluded (partially or fully hidden) objectsis vital to understanding visual scenes, as occlusions frequently occur inreal-world environments and act as obstacles for spatial comprehension. To testmodels' ability to reason about multiple occluded objects, we introduce a noveltask, Counting Amodally for Patterns Through Unseen REgions (CAPTURe), whichrequires a model to count objects arranged in a pattern by inferring how thepattern continues behind an occluder (an object which blocks parts of thescene). CAPTURe requires both recognizing visual patterns and reasoning, makingit a useful testbed for evaluating vision-language models (VLMs) on whetherthey understand occluded patterns and possess spatial understanding skills. Byrequiring models to reason about occluded objects, CAPTURe also tests VLMs'ability to form world models that would allow them to fill in missinginformation. CAPTURe consists of two parts: (1) CAPTURe-real, with manuallyfiltered images of real objects in patterns and (2) CAPTURe-synthetic, acontrolled diagnostic with generated patterned images. We evaluate four strongVLMs (GPT-4o, Intern-VL2, Molmo, and Qwen2-VL) on CAPTURe, finding that modelsstruggle to count on both occluded and unoccluded patterns. Crucially, we findthat models perform worse with occlusion, suggesting that VLMs are alsodeficient in inferring unseen spatial relationships: even the strongest VLMslike GPT-4o fail to count with occlusion. In contrast, we find that humansachieve very little error on CAPTURe. We also find that providing auxiliaryinformation of occluded object locations increases performance, underscoringthat the model error comes both from an inability to handle occlusion as wellas difficulty counting in images.</description>
      <author>example@mail.com (Atin Pothiraj, Elias Stengel-Eskin, Jaemin Cho, Mohit Bansal)</author>
      <guid isPermaLink="false">2504.15485v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models</title>
      <link>http://arxiv.org/abs/2504.15929v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了MedTrim，一种基于元实体驱动的三元组挖掘方法，用于提高医学图像和文本之间的对齐，特别是在胸部X光片（CXR）评估中。&lt;h4&gt;背景&lt;/h4&gt;诊断影像学依赖于对图像和放射学报告的解释，但随着数据量的增加，给医学专家带来了巨大的压力，导致错误增加和工作流程积压。&lt;h4&gt;目的&lt;/h4&gt;提出MedTrim方法，旨在通过多模态三元组学习，协同地利用疾病类别以及形容词和方向性病理描述符来增强图像-文本对齐。&lt;h4&gt;方法&lt;/h4&gt;MedTrim方法包括：1）引入基于本体论的实体识别模块，从CXR报告中提取病理特定的元实体；2）提出一个新的评分函数，基于疾病类别和形容词/方向性描述符来捕捉样本间相似性的综合度量；3）引入一个多模态三元组对齐目标，用于显式地实现具有详细病理特征的样本之间的跨模态对齐。&lt;h4&gt;主要发现&lt;/h4&gt;MedTrim在下游检索和分类任务中的性能优于现有的对齐方法。&lt;h4&gt;结论&lt;/h4&gt;MedTrim通过利用结构化元实体信息和改进的三元组挖掘，提高了医学图像和文本对齐的效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：诊断影像学依赖于对图像和放射学报告的解释，但随着数据量的增加，给医学专家带来了巨大的压力，导致错误增加和工作流程积压。医学视觉-语言模型（med-VLMs）已成为一种强大的框架，用于高效处理多模态影像数据，尤其是在胸部X光片（CXR）评估中，尽管其性能取决于图像和文本表示的对齐程度。现有的对齐方法，主要基于对比学习，优先考虑疾病类别之间的分离，而不是精细的病理属性（如位置、大小或严重程度）的分离，导致表示不佳。在这里，我们提出了MedTrim（元实体驱动的三元组挖掘），一种新颖的方法，通过疾病类别以及形容词和方向性病理描述符协同引导的多模态三元组学习来增强图像-文本对齐。与常见的对齐方法不同，MedTrim利用结构化元实体信息来保留临床上有意义的类内细微差异。为此，我们首先引入了一个基于本体论的实体识别模块，从CXR报告中提取病理特定的元实体，因为公共数据集中病理属性的注释很少。然后，为了在三元组挖掘中进行精细的样本选择，我们引入了一个新的评分函数，该函数基于疾病类别和形容词/方向性描述符捕捉样本间相似性的综合度量。最后，我们引入了一个多模态三元组对齐目标，用于显式地在具有详细病理特征的样本之间实现跨模态对齐。我们的演示表明，与最先进的对齐方法相比，MedTrim在下游检索和分类任务中的性能得到了改善。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diagnostic imaging relies on interpreting both images and radiology reports,but the growing data volumes place significant pressure on medical experts,yielding increased errors and workflow backlogs. Medical vision-language models(med-VLMs) have emerged as a powerful framework to efficiently processmultimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeittheir performance hinges on how well image and text representations arealigned. Existing alignment methods, predominantly based on contrastivelearning, prioritize separation between disease classes over segregation offine-grained pathology attributes like location, size or severity, leading tosuboptimal representations. Here, we propose MedTrim (Meta-entity-drivenTriplet mining), a novel method that enhances image-text alignment throughmultimodal triplet learning synergistically guided by disease class as well asadjectival and directional pathology descriptors. Unlike common alignmentmethods that separate broad disease classes, MedTrim leverages structuredmeta-entity information to preserve subtle but clinically significantintra-class variations. For this purpose, we first introduce an ontology-basedentity recognition module that extracts pathology-specific meta-entities fromCXR reports, as annotations on pathology attributes are rare in publicdatasets. For refined sample selection in triplet mining, we then introduce anovel score function that captures an aggregate measure of inter-samplesimilarity based on disease classes and adjectival/directional descriptors.Lastly, we introduce a multimodal triplet alignment objective for explicitwithin- and cross-modal alignment between samples sharing detailed pathologycharacteristics. Our demonstrations indicate that MedTrim improves performancein downstream retrieval and classification tasks compared to state-of-the-artalignment methods.</description>
      <author>example@mail.com (Saban Ozturk, Melih B. Yilmaz, Muti Kara, M. Talat Yavuz, Aykut Koç, Tolga Çukur)</author>
      <guid isPermaLink="false">2504.15929v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>ZeroSlide: Is Zero-Shot Classification Adequate for Lifelong Learning in Whole-Slide Image Analysis in the Era of Pathology Vision-Language Foundation Models?</title>
      <link>http://arxiv.org/abs/2504.15627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures, 1 table, conference submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了终身学习在整张切片图像（WSIs）上的挑战，并比较了传统的持续学习方法和视觉-语言零样本分类方法。&lt;h4&gt;背景&lt;/h4&gt;在临床和医院环境中，WSIs由于数据量大，需要存储、处理和传输时间，因此训练新模型以执行多种WSI相关任务（如癌症亚型和肿瘤分类）具有实际应用价值。&lt;h4&gt;目的&lt;/h4&gt;研究旨在确定仅使用零样本分类的视觉-语言基础模型是否足以进行终身WSI学习，以及是否需要进一步研究持续学习策略以提高性能。&lt;h4&gt;方法&lt;/h4&gt;该研究首次比较了传统的持续学习方法与视觉-语言零样本分类方法在WSI上的应用。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果将很快公开，包括源代码和实验结果。&lt;h4&gt;结论&lt;/h4&gt;论文未提供明确的结论，但强调了需要进一步研究以确定最佳的学习策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lifelong learning for whole slide images (WSIs) poses the challenge oftraining a unified model to perform multiple WSI-related tasks, such as cancersubtyping and tumor classification, in a distributed, continual fashion. Thisis a practical and applicable problem in clinics and hospitals, as WSIs arelarge, require storage, processing, and transfer time. Training new modelswhenever new tasks are defined is time-consuming. Recent work has appliedregularization- and rehearsal-based methods to this setting. However, the riseof vision-language foundation models that align diagnostic text with pathologyimages raises the question: are these models alone sufficient for lifelong WSIlearning using zero-shot classification, or is further investigation intocontinual learning strategies needed to improve performance? To our knowledge,this is the first study to compare conventional continual-learning approacheswith vision-language zero-shot classification for WSIs. Our source code andexperimental results will be available soon.</description>
      <author>example@mail.com (Doanh C. Bui, Hoai Luan Pham, Vu Trung Duong Le, Tuan Hai Vu, Van Duy Tran, Yasuhiko Nakashima)</author>
      <guid isPermaLink="false">2504.15627v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>RiskNet: Interaction-Aware Risk Forecasting for Autonomous Driving in Long-Tail Scenarios</title>
      <link>http://arxiv.org/abs/2504.15541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RiskNet的交互感知风险预测框架，用于解决自动驾驶车辆在长尾场景下的安全问题。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶车辆在长尾场景下的安全性保证是一个关键挑战，尤其是在高不确定性和复杂多智能体交互的情况下。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，提出了RiskNet框架，以实现对风险的全面评估。&lt;h4&gt;方法&lt;/h4&gt;RiskNet集成了确定性风险模型和概率行为预测，通过场理论模型捕捉自我车辆、周围智能体和基础设施之间的交互。此外，引入了基于图神经网络（GNN）的轨迹预测模块，以学习多模态的未来运动分布。&lt;h4&gt;主要发现&lt;/h4&gt;RiskNet在多种场景（高速公路、交叉口和环岛）中支持多维风险评估，并在高风险和长尾设置下表现出鲁棒性。在highD、inD和roundD数据集上的评估显示，该方法在准确性、响应性和方向敏感性方面显著优于传统方法，同时在场景间保持良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该框架支持实时、场景自适应的风险预测，并在不确定的驾驶环境中表现出强大的泛化能力，为长尾场景中的安全关键决策提供了统一的基础。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为RiskNet的交互感知风险预测框架，旨在解决自动驾驶车辆在长尾场景下的安全性问题。该框架结合确定性风险模型和概率行为预测，通过场理论模型捕捉自我车辆、周围智能体和基础设施之间的交互，并引入了基于图神经网络的轨迹预测模块。在多个数据集上的评估表明，该方法在准确性、响应性和方向敏感性方面优于传统方法，并在不确定的驾驶环境中具有强大的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety of autonomous vehicles (AVs) in long-tail scenariosremains a critical challenge, particularly under high uncertainty and complexmulti-agent interactions. To address this, we propose RiskNet, aninteraction-aware risk forecasting framework, which integrates deterministicrisk modeling with probabilistic behavior prediction for comprehensive riskassessment. At its core, RiskNet employs a field-theoretic model that capturesinteractions among ego vehicle, surrounding agents, and infrastructure viainteraction fields and force. This model supports multidimensional riskevaluation across diverse scenarios (highways, intersections, and roundabouts),and shows robustness under high-risk and long-tail settings. To capture thebehavioral uncertainty, we incorporate a graph neural network (GNN)-basedtrajectory prediction module, which learns multi-modal future motiondistributions. Coupled with the deterministic risk field, it enables dynamic,probabilistic risk inference across time, enabling proactive safety assessmentunder uncertainty. Evaluations on the highD, inD, and rounD datasets, spanninglane changes, turns, and complex merges, demonstrate that our methodsignificantly outperforms traditional approaches (e.g., TTC, THW, RSS, NCField) in terms of accuracy, responsiveness, and directional sensitivity, whilemaintaining strong generalization across scenarios. This framework supportsreal-time, scenario-adaptive risk forecasting and demonstrates stronggeneralization across uncertain driving environments. It offers a unifiedfoundation for safety-critical decision-making in long-tail scenarios.</description>
      <author>example@mail.com (Qichao Liu, Heye Huang, Shiyue Zhao, Lei Shi, Soyoung Ahn, Xiaopeng Li)</author>
      <guid isPermaLink="false">2504.15541v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order Neighboring Feature Fusion</title>
      <link>http://arxiv.org/abs/2504.15920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为ScaleGNN的新型框架，用于解决大规模图上的GNNs的过平滑和可扩展性问题，通过自适应融合多级图特征来同时解决这两个挑战。&lt;h4&gt;背景&lt;/h4&gt;GNNs在图相关任务中表现出色，但存在过平滑和可扩展性问题，传统架构复杂度高，推理时间增加。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够同时解决GNNs过平滑和可扩展性问题的框架。&lt;h4&gt;方法&lt;/h4&gt;ScaleGNN通过自适应融合多级图特征，构建每个阶数的邻接矩阵，并通过可训练权重学习它们之间的相对信息。此外，引入基于局部贡献分数（LCS）的高阶冗余特征掩码机制，以保留每个阶数中最相关的邻居，防止冗余信息传播。&lt;h4&gt;主要发现&lt;/h4&gt;ScaleGNN在真实世界数据集上的实验表明，该方法在准确性和计算效率方面均优于最先进的GNN模型。&lt;h4&gt;结论&lt;/h4&gt;ScaleGNN框架有效地解决了GNNs在处理大规模图数据时的过平滑和可扩展性问题，提高了模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have demonstrated strong performance across various graph-based tasks by effectively capturing relational information between nodes. These models rely on iterative message passing to propagate node features, enabling nodes to aggregate information from their neighbors. Recent research has significantly improved the message-passing mechanism, enhancing GNN scalability on large-scale graphs. However, GNNs still face two main challenges: over-smoothing, where excessive message passing results in indistinguishable node representations, especially in deep networks incorporating high-order neighbors; and scalability issues, as traditional architectures suffer from high model complexity and increased inference time due to redundant information aggregation. This paper proposes a novel framework for large-scale graphs named ScaleGNN that simultaneously addresses both challenges by adaptively fusing multi-level graph features. We first construct neighbor matrices for each order, learning their relative information through trainable weights through an adaptive high-order feature fusion module. This allows the model to selectively emphasize informative high-order neighbors while reducing unnecessary computational costs. Additionally, we introduce a High-order redundant feature masking mechanism based on a Local Contribution Score (LCS), which enables the model to retain only the most relevant neighbors at each order, preventing redundant information propagation. Furthermore, low-order enhanced feature aggregation adaptively integrates low-order and high-order features based on task relevance, ensuring effective capture of both local and global structural information without excessive complexity. Extensive experiments on real-world datasets demonstrate that our approach consistently outperforms state-of-the-art GNN models in both accuracy and computational efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated strong performance acrossvarious graph-based tasks by effectively capturing relational informationbetween nodes. These models rely on iterative message passing to propagate nodefeatures, enabling nodes to aggregate information from their neighbors. Recentresearch has significantly improved the message-passing mechanism, enhancingGNN scalability on large-scale graphs. However, GNNs still face two mainchallenges: over-smoothing, where excessive message passing results inindistinguishable node representations, especially in deep networksincorporating high-order neighbors; and scalability issues, as traditionalarchitectures suffer from high model complexity and increased inference timedue to redundant information aggregation. This paper proposes a novel frameworkfor large-scale graphs named ScaleGNN that simultaneously addresses bothchallenges by adaptively fusing multi-level graph features. We first constructneighbor matrices for each order, learning their relative information throughtrainable weights through an adaptive high-order feature fusion module. Thisallows the model to selectively emphasize informative high-order neighborswhile reducing unnecessary computational costs. Additionally, we introduce aHigh-order redundant feature masking mechanism based on a Local ContributionScore (LCS), which enables the model to retain only the most relevant neighborsat each order, preventing redundant information propagation. Furthermore,low-order enhanced feature aggregation adaptively integrates low-order andhigh-order features based on task relevance, ensuring effective capture of bothlocal and global structural information without excessive complexity. Extensiveexperiments on real-world datasets demonstrate that our approach consistentlyoutperforms state-of-the-art GNN models in both accuracy and computationalefficiency.</description>
      <author>example@mail.com (Xiang Li, Haobing Liu, Jianpeng Qi, Yuan Cao, Guoqing Chao, Yanwei Yu)</author>
      <guid isPermaLink="false">2504.15920v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>ViSMaP: Unsupervised Hour-long Video Summarisation by Meta-Prompting</title>
      <link>http://arxiv.org/abs/2504.15921v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ViSMap是一种无监督视频摘要系统，可以用于总结长达数小时的视频。&lt;h4&gt;背景&lt;/h4&gt;现有的视频理解模型在处理短视频时效果良好，但在处理长视频时，由于相关事件分布稀疏且未预分段，效果不佳。此外，长视频理解通常依赖于需要大量标注的监督式分层训练，这既耗时又昂贵，且容易产生不一致性。&lt;h4&gt;目的&lt;/h4&gt;ViSMap旨在弥合短视频（标注数据丰富）和长视频（标注数据稀缺）之间的差距。&lt;h4&gt;方法&lt;/h4&gt;ViSMap利用LLM（大型语言模型）创建长视频的优化伪摘要，这些伪摘要使用来自短视频的片段描述。这些伪摘要作为训练数据，用于生成长视频摘要，从而避免了长视频标注的昂贵成本。具体来说，ViSMap采用元提示策略，通过迭代生成和优化长视频的伪摘要。策略利用从监督式短视频模型获得的短片段描述来指导摘要。每个迭代使用三个LLM依次工作：一个用于从片段描述生成伪摘要，另一个用于评估它，第三个用于优化生成器的提示。&lt;h4&gt;主要发现&lt;/h4&gt;在多个数据集上广泛评估了ViSMap的摘要，结果显示ViSMap在性能上与完全监督的顶尖模型相当，同时能够在多个领域中进行泛化，而不会牺牲性能。&lt;h4&gt;结论&lt;/h4&gt;ViSMap在发布后将发布代码。&lt;h4&gt;翻译&lt;/h4&gt;We introduce ViSMap: Unsupervised Video Summarisation by Meta Prompting, a system to summarise hour long videos with no-supervision. Most existing video understanding models work well on short videos of pre-segmented events, yet they struggle to summarise longer videos where relevant events are sparsely distributed and not pre-segmented. Moreover, long-form video understanding often relies on supervised hierarchical training that needs extensive annotations which are costly, slow and prone to inconsistency. With ViSMaP we bridge the gap between short videos (where annotated data is plentiful) and long ones (where it's not). We rely on LLMs to create optimised pseudo-summaries of long videos using segment descriptions from short ones. These pseudo-summaries are used as training data for a model that generates long-form video summaries, bypassing the need for expensive annotations of long videos. Specifically, we adopt a meta-prompting strategy to iteratively generate and refine creating pseudo-summaries of long videos. The strategy leverages short clip descriptions obtained from a supervised short video model to guide the summary. Each iteration uses three LLMs working in sequence: one to generate the pseudo-summary from clip descriptions, another to evaluate it, and a third to optimise the prompt of the generator. This iteration is necessary because the quality of the pseudo-summaries is highly dependent on the generator prompt, and varies widely among videos. We evaluate our summaries extensively on multiple datasets; our results show that ViSMaP achieves performance comparable to fully supervised state-of-the-art models while generalising across domains without sacrificing performance. Code will be released upon publication.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce ViSMap: Unsupervised Video Summarisation by Meta Prompting, asystem to summarise hour long videos with no-supervision. Most existing videounderstanding models work well on short videos of pre-segmented events, yetthey struggle to summarise longer videos where relevant events are sparselydistributed and not pre-segmented. Moreover, long-form video understandingoften relies on supervised hierarchical training that needs extensiveannotations which are costly, slow and prone to inconsistency. With ViSMaP webridge the gap between short videos (where annotated data is plentiful) andlong ones (where it's not). We rely on LLMs to create optimisedpseudo-summaries of long videos using segment descriptions from short ones.These pseudo-summaries are used as training data for a model that generateslong-form video summaries, bypassing the need for expensive annotations of longvideos. Specifically, we adopt a meta-prompting strategy to iterativelygenerate and refine creating pseudo-summaries of long videos. The strategyleverages short clip descriptions obtained from a supervised short video modelto guide the summary. Each iteration uses three LLMs working in sequence: oneto generate the pseudo-summary from clip descriptions, another to evaluate it,and a third to optimise the prompt of the generator. This iteration isnecessary because the quality of the pseudo-summaries is highly dependent onthe generator prompt, and varies widely among videos. We evaluate our summariesextensively on multiple datasets; our results show that ViSMaP achievesperformance comparable to fully supervised state-of-the-art models whilegeneralising across domains without sacrificing performance. Code will bereleased upon publication.</description>
      <author>example@mail.com (Jian Hu, Dimitrios Korkinof, Shaogang Gong, Mariano Beguerisse-Diaz)</author>
      <guid isPermaLink="false">2504.15921v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>GraphEdge: Dynamic Graph Partition and Task Scheduling for GNNs Computing in Edge Network</title>
      <link>http://arxiv.org/abs/2504.15905v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages,12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的边缘计算架构GraphEdge，用于在图结构场景下提供高效服务，以解决现有方法在处理关联用户数据时的通信成本问题。&lt;h4&gt;背景&lt;/h4&gt;随着物联网设备的指数级增长，边缘计算在提供成本效益服务方面发挥着越来越重要的作用。然而，现有方法在处理交通流量预测和社会关系推荐系统等用户数据相关联的图结构场景时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决图神经网络（GNN）方法导致的昂贵的服务器通信成本问题。&lt;h4&gt;方法&lt;/h4&gt;GraphEdge架构首先感知用户拓扑，将数据关联表示为每个时间步的图布局。然后，通过调用提出的分层遍历图切分算法（HiCut）优化图布局，该算法根据GNN的聚合特征将图布局切割成多个弱关联的子图，并最小化GNN推理过程中不同子图之间的通信成本。最后，基于优化的图布局执行基于深度强化学习（DRL）的图卸载算法（DRLGO），以获取用户任务的优化卸载策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的架构具有良好的有效性和动态适应性，即使在动态场景中也能表现出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;GraphEdge架构有效地解决了图结构场景中的通信成本问题，为边缘计算提供了高效的服务。&lt;h4&gt;翻译&lt;/h4&gt;With the exponential growth of Internet of Things (IoT) devices, edge computing (EC) is gradually playing an important role in providing cost-effective services. However, existing approaches struggle to perform well in graph-structured scenarios where user data is correlated, such as traffic flow prediction and social relationship recommender systems. In particular, graph neural network (GNN)-based approaches lead to expensive server communication cost. To address this problem, we propose GraphEdge, an efficient GNN-based EC architecture. It considers the EC system of GNN tasks, where there are associations between users and it needs to take into account the task data of its neighbors when processing the tasks of a user. Specifically, the architecture first perceives the user topology and represents their data associations as a graph layout at each time step. Then the graph layout is optimized by calling our proposed hierarchical traversal graph cut algorithm (HiCut), which cuts the graph layout into multiple weakly associated subgraphs based on the aggregation characteristics of GNN, and the communication cost between different subgraphs during GNN inference is minimized. Finally, based on the optimized graph layout, our proposed deep reinforcement learning (DRL) based graph offloading algorithm (DRLGO) is executed to obtain the optimal offloading strategy for the tasks of users, the offloading strategy is subgraph-based, it tries to offload user tasks in a subgraph to the same edge server as possible while minimizing the task processing time and energy consumption of the EC system. Experimental results show the good effectiveness and dynamic adaptation of our proposed architecture and it also performs well even in dynamic scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the exponential growth of Internet of Things (IoT) devices, edgecomputing (EC) is gradually playing an important role in providingcost-effective services. However, existing approaches struggle to perform wellin graph-structured scenarios where user data is correlated, such as trafficflow prediction and social relationship recommender systems. In particular,graph neural network (GNN)-based approaches lead to expensive servercommunication cost. To address this problem, we propose GraphEdge, an efficientGNN-based EC architecture. It considers the EC system of GNN tasks, where thereare associations between users and it needs to take into account the task dataof its neighbors when processing the tasks of a user. Specifically, thearchitecture first perceives the user topology and represents their dataassociations as a graph layout at each time step. Then the graph layout isoptimized by calling our proposed hierarchical traversal graph cut algorithm(HiCut), which cuts the graph layout into multiple weakly associated subgraphsbased on the aggregation characteristics of GNN, and the communication costbetween different subgraphs during GNN inference is minimized. Finally, basedon the optimized graph layout, our proposed deep reinforcement learning (DRL)based graph offloading algorithm (DRLGO) is executed to obtain the optimaloffloading strategy for the tasks of users, the offloading strategy issubgraph-based, it tries to offload user tasks in a subgraph to the same edgeserver as possible while minimizing the task processing time and energyconsumption of the EC system. Experimental results show the good effectivenessand dynamic adaptation of our proposed architecture and it also performs welleven in dynamic scenarios.</description>
      <author>example@mail.com (Wenjing Xiao, Chenglong Shi, Miaojiang Chen, Zhiquan Liu, Min Chen, H. Herbert Song)</author>
      <guid isPermaLink="false">2504.15905v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Survey of Video Diffusion Models: Foundations, Implementations, and Applications</title>
      <link>http://arxiv.org/abs/2504.16081v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了扩散模型在视频生成领域的应用，与传统的基于生成对抗网络的方法相比，扩散模型在时间一致性和视觉质量方面有显著提升。&lt;h4&gt;背景&lt;/h4&gt;扩散模型在视频生成领域取得了重大进展，但仍面临运动一致性、计算效率和伦理考量等挑战。&lt;h4&gt;目的&lt;/h4&gt;提供对基于扩散的视频生成技术的全面审查，包括其演变、技术基础和应用。&lt;h4&gt;方法&lt;/h4&gt;对现有方法进行系统分类，分析架构创新和优化策略，并探讨在去噪和超分辨率等低级视觉任务中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;本文探讨了扩散模型视频生成与其他领域（如视频表示学习、问答和检索）的协同作用，并提供了比现有综述更全面、更新、更细致的视角。&lt;h4&gt;结论&lt;/h4&gt;本文为在扩散模型和视频生成交叉领域工作的研究人员和从业者提供了基础资源，涵盖了该领域快速发展的理论框架和实践实施。&lt;h4&gt;翻译&lt;/h4&gt;This survey provides a comprehensive review of diffusion-based video generation, examining its evolution, technical foundations, and practical applications. We present a systematic taxonomy of current methodologies, analyze architectural innovations and optimization strategies, and investigate applications across low-level vision tasks such as denoising and super-resolution. Additionally, we explore the synergies between diffusion-based video generation and related domains, including video representation learning, question answering, and retrieval. Compared to the existing surveys (Lei et al., 2024a;b; Melnik et al., 2024; Cao et al., 2023; Xing et al., 2024c) which focus on specific aspects of video generation, such as human video synthesis (Lei et al., 2024a) or long-form content generation (Lei et al., 2024b), our work provides a broader, more updated, and more fine-grained perspective on diffusion-based approaches with a special section for evaluation metrics, industry solutions, and training engineering techniques in video generation. This survey serves as a foundational resource for researchers and practitioners working at the intersection of diffusion models and video generation, providing insights into both the theoretical frameworks and practical implementations that drive this rapidly evolving field. A structured list of related works involved in this survey is also available on https://github.com/Eyeline-Research/Survey-Video-Diffusion.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in diffusion models have revolutionized video generation,offering superior temporal consistency and visual quality compared totraditional generative adversarial networks-based approaches. While thisemerging field shows tremendous promise in applications, it faces significantchallenges in motion consistency, computational efficiency, and ethicalconsiderations. This survey provides a comprehensive review of diffusion-basedvideo generation, examining its evolution, technical foundations, and practicalapplications. We present a systematic taxonomy of current methodologies,analyze architectural innovations and optimization strategies, and investigateapplications across low-level vision tasks such as denoising andsuper-resolution. Additionally, we explore the synergies between diffusionbasedvideo generation and related domains, including video representation learning,question answering, and retrieval. Compared to the existing surveys (Lei etal., 2024a;b; Melnik et al., 2024; Cao et al., 2023; Xing et al., 2024c) whichfocus on specific aspects of video generation, such as human video synthesis(Lei et al., 2024a) or long-form content generation (Lei et al., 2024b), ourwork provides a broader, more updated, and more fine-grained perspective ondiffusion-based approaches with a special section for evaluation metrics,industry solutions, and training engineering techniques in video generation.This survey serves as a foundational resource for researchers and practitionersworking at the intersection of diffusion models and video generation, providinginsights into both the theoretical frameworks and practical implementationsthat drive this rapidly evolving field. A structured list of related worksinvolved in this survey is also available onhttps://github.com/Eyeline-Research/Survey-Video-Diffusion.</description>
      <author>example@mail.com (Yimu Wang, Xuye Liu, Wei Pang, Li Ma, Shuai Yuan, Paul Debevec, Ning Yu)</author>
      <guid isPermaLink="false">2504.16081v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning</title>
      <link>http://arxiv.org/abs/2504.16023v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PointLoRA的简单有效的点云模型微调方法，通过结合低秩适应（LoRA）和多尺度标记选择，以降低计算和存储资源需求。&lt;h4&gt;背景&lt;/h4&gt;自监督表示学习在提升预训练模型性能方面表现良好，但随着预训练模型复杂度的增加，完全微调需要大量的计算和存储资源。&lt;h4&gt;目的&lt;/h4&gt;提出一种参数高效的微调（PEFT）方法，以减轻资源需求。&lt;h4&gt;方法&lt;/h4&gt;PointLoRA方法将LoRA层嵌入到点云变压器中最参数密集的部分，减少可调参数数量，同时增强全局特征捕捉。多尺度标记选择提取关键局部信息作为下游微调的提示，补充LoRA捕获的全局上下文。&lt;h4&gt;主要发现&lt;/h4&gt;在多个预训练模型和三个公开数据集上的实验结果表明，PointLoRA在仅使用3.43%的可训练参数的情况下，实现了有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;PointLoRA是一种高度有效的资源受限应用的方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes PointLoRA, a simple yet effective method that combines low-rank adaptation (LoRA) with multi-scale token selection to efficiently fine-tune point cloud models. Our approach embeds LoRA layers within the most parameter-intensive components of point cloud transformers, reducing the need for tunable parameters while enhancing global feature capture. Additionally, multi-scale token selection extracts critical local information to serve as prompts for downstream fine-tuning, effectively complementing the global context captured by LoRA. Experimental results across various pre-trained models and three challenging public datasets demonstrate that our approach achieves competitive performance with only 3.43% of the trainable parameters, making it highly effective for resource-constrained applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised representation learning for point cloud has demonstratedeffectiveness in improving pre-trained model performance across diverse tasks.However, as pre-trained models grow in complexity, fully fine-tuning them fordownstream applications demands substantial computational and storageresources. Parameter-efficient fine-tuning (PEFT) methods offer a promisingsolution to mitigate these resource requirements, yet most current approachesrely on complex adapter and prompt mechanisms that increase tunable parameters.In this paper, we propose PointLoRA, a simple yet effective method thatcombines low-rank adaptation (LoRA) with multi-scale token selection toefficiently fine-tune point cloud models. Our approach embeds LoRA layerswithin the most parameter-intensive components of point cloud transformers,reducing the need for tunable parameters while enhancing global featurecapture. Additionally, multi-scale token selection extracts critical localinformation to serve as prompts for downstream fine-tuning, effectivelycomplementing the global context captured by LoRA. The experimental resultsacross various pre-trained models and three challenging public datasetsdemonstrate that our approach achieves competitive performance with only 3.43%of the trainable parameters, making it highly effective forresource-constrained applications. Source code is available at:https://github.com/songw-zju/PointLoRA.</description>
      <author>example@mail.com (Song Wang, Xiaolu Liu, Lingdong Kong, Jianyun Xu, Chunyong Hu, Gongfan Fang, Wentong Li, Jianke Zhu, Xinchao Wang)</author>
      <guid isPermaLink="false">2504.16023v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Vidi: Large Multimodal Models for Video Understanding and Editing</title>
      <link>http://arxiv.org/abs/2504.15681v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Vidi的用于视频理解和编辑的Large Multimodal Models（LMMs）系列，旨在支持高质量大规模视频内容的创作。&lt;h4&gt;背景&lt;/h4&gt;人类自然地与他们的联系者分享信息，视频已成为互联网上主要的沟通和表达媒介。现代视频制作流程需要全面理解原始素材和编辑组件。&lt;h4&gt;目的&lt;/h4&gt;为了支持高质量大规模视频内容的创作，开发能够处理多模态信息且具有强背景知识的模型，以应对传统模型在处理长视频和多种输入长度时的挑战。&lt;h4&gt;方法&lt;/h4&gt;Vidi模型专注于时间检索，即识别输入视频中与给定文本查询相对应的时间范围。此外，还提出了VUE-TR基准，包括视频时长、音频支持、查询格式、标注质量和评估指标等五个关键进展。&lt;h4&gt;主要发现&lt;/h4&gt;Vidi在时间检索任务上显著优于GPT-4o和Gemini等领先模型，表明其在视频编辑场景中的优越性。&lt;h4&gt;结论&lt;/h4&gt;Vidi模型在视频编辑场景中表现出色，能够有效处理长视频和多种输入长度，支持智能编辑。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类自然地与他们联系的人分享信息，视频已成为互联网上主要的沟通和表达媒介。为了支持高质量大规模视频内容的创作，现代视频制作流程需要全面理解原始素材和编辑组件。在视频编辑场景中，模型必须处理多种模态（例如，视觉、音频、文本）并具有强大的背景知识，同时处理灵活的输入长度（例如，长达数小时的原始视频），这对传统模型提出了重大挑战。在本报告中，我们介绍了一组用于广泛视频理解和编辑场景的Large Multimodal Models（LMMs）——Vidi。首个版本专注于时间检索，即识别输入视频中与给定文本查询相对应的时间范围，这在智能编辑中起着关键作用。该模型能够处理长达数小时的视频，并具有强大的时间理解能力，例如检索特定查询的时间范围。为了支持在现实场景中的全面评估，我们还提出了VUE-TR基准，该基准引入了五个关键进展：1）视频时长：比现有的时间检索数据集长得多；2）音频支持：包括基于音频的查询；3）查询格式：多样化的查询长度/格式；4）标注质量：地面实况时间范围是手动标注的；5）评估指标：一个精细的IoU指标，支持对多个时间范围进行评估。值得注意的是，Vidi在时间检索任务上显著优于领先的专有模型，例如GPT-4o和Gemini，这表明其在视频编辑场景中的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans naturally share information with those they are connected to, andvideo has become one of the dominant mediums for communication and expressionon the Internet. To support the creation of high-quality large-scale videocontent, a modern pipeline requires a comprehensive understanding of both theraw input materials (e.g., the unedited footage captured by cameras) and theediting components (e.g., visual effects). In video editing scenarios, modelsmust process multiple modalities (e.g., vision, audio, text) with strongbackground knowledge and handle flexible input lengths (e.g., hour-long rawvideos), which poses significant challenges for traditional models. In thisreport, we introduce Vidi, a family of Large Multimodal Models (LMMs) for awide range of video understand editing scenarios. The first release focuses ontemporal retrieval, i.e., identifying the time ranges within the input videoscorresponding to a given text query, which plays a critical role in intelligentediting. The model is capable of processing hour-long videos with strongtemporal understanding capability, e.g., retrieve time ranges for certainqueries. To support a comprehensive evaluation in real-world scenarios, we alsopresent the VUE-TR benchmark, which introduces five key advancements. 1) Videoduration: significantly longer than existing temporal retrival datasets, 2)Audio support: includes audio-based queries, 3) Query format: diverse querylengths/formats, 4) Annotation quality: ground-truth time ranges are manuallyannotated. 5) Evaluation metric: a refined IoU metric to support evaluationover multiple time ranges. Remarkably, Vidi significantly outperforms leadingproprietary models, e.g., GPT-4o and Gemini, on the temporal retrieval task,indicating its superiority in video editing scenarios.</description>
      <author>example@mail.com (Vidi Team, Celong Liu, Chia-Wen Kuo, Dawei Du, Fan Chen, Guang Chen, Jiamin Yuan, Lingxi Zhang, Lu Guo, Lusha Li, Longyin Wen, Qingyu Chen, Rachel Deng, Sijie Zhu, Stuart Siew, Tong Jin, Wei Lu, Wen Zhong, Xiaohui Shen, Xin Gu, Xing Mei, Xueqiong Qu)</author>
      <guid isPermaLink="false">2504.15681v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>AdaViP: Aligning Multi-modal LLMs via Adaptive Vision-enhanced Preference Optimization</title>
      <link>http://arxiv.org/abs/2504.15619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自适应视觉增强偏好优化（AdaViP）方法，通过两个关键创新解决了现有方法在多模态大语言模型（MLLMs）与人类偏好对齐中忽视视觉上下文的问题。&lt;h4&gt;背景&lt;/h4&gt;DPO方法在多模态大语言模型与人类偏好对齐方面显示出显著效果，但现有方法主要关注语言偏好，而忽略了视觉上下文的重要性。&lt;h4&gt;目的&lt;/h4&gt;提出AdaViP方法，以解决现有方法忽视视觉上下文的局限性。&lt;h4&gt;方法&lt;/h4&gt;AdaViP方法包括：(1)基于视觉的偏好对构建，通过整合多个视觉基础模型策略性地去除图像中的关键视觉元素，增强MLLMs对视觉细节的敏感性；(2)自适应偏好优化，动态平衡视觉和语言偏好，以实现更精确的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;AdaViP方法在不同基准测试中表现出有效性，其中AdaViP-7B在Object HalBench上实现了93.7%和96.4%的响应级和提及级幻觉减少，显著优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;AdaViP方法通过视觉增强和自适应优化，提高了多模态大语言模型与人类偏好对齐的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Preference alignment through Direct Preference Optimization (DPO) hasdemonstrated significant effectiveness in aligning multimodal large languagemodels (MLLMs) with human preferences. However, existing methods focusprimarily on language preferences while neglecting the critical visual context.In this paper, we propose an Adaptive Vision-enhanced Preference optimization(AdaViP) that addresses these limitations through two key innovations: (1)vision-based preference pair construction, which integrates multiple visualfoundation models to strategically remove key visual elements from the image,enhancing MLLMs' sensitivity to visual details; and (2) adaptive preferenceoptimization that dynamically balances vision- and language-based preferencesfor more accurate alignment. Extensive evaluations across different benchmarksdemonstrate our effectiveness. Notably, our AdaViP-7B achieves 93.7% and 96.4%reductions in response-level and mentioned-level hallucination respectively onthe Object HalBench, significantly outperforming current state-of-the-artmethods.</description>
      <author>example@mail.com (Jinda Lu, Jinghan Li, Yuan Gao, Junkang Wu, Jiancan Wu, Xiang Wang, Xiangnan He)</author>
      <guid isPermaLink="false">2504.15619v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Topological model selection: a case-study in tumour-induced angiogenesis</title>
      <link>http://arxiv.org/abs/2504.15442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种灵活的参数推断和模型选择流程，用于处理模拟高维时空数据的概率模型。&lt;h4&gt;背景&lt;/h4&gt;比较数学模型是评估竞争性科学理论的方法，但精确的模型校准方法不适用于许多模拟高维时空数据的概率模型。&lt;h4&gt;目的&lt;/h4&gt;开发一种灵活的流程，用于参数推断和模型选择，以处理模拟高维时空数据的概率模型。&lt;h4&gt;方法&lt;/h4&gt;该流程结合了近似贝叶斯计算和拓扑数据分析，用于识别拓扑摘要统计量，量化时空数据，并使用这些统计量来近似参数和模型后验分布。&lt;h4&gt;主要发现&lt;/h4&gt;该流程在肿瘤诱导血管生成模型上得到了验证，推断出三个模型中的四个参数，并在合成测试案例中确定了正确的模型。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效地进行参数推断和模型选择，适用于模拟高维时空数据的概率模型。&lt;h4&gt;翻译&lt;/h4&gt;Comparing mathematical models offers a means to evaluate competing scientific theories. However, exact methods of model calibration are not applicable to many probabilistic models which simulate high-dimensional spatio-temporal data. Approximate Bayesian Computation is a widely-used method for parameter inference and model selection in such scenarios, and it may be combined with Topological Data Analysis to study models which simulate data with fine spatial structure. We develop a flexible pipeline for parameter inference and model selection in spatio-temporal models. Our pipeline identifies topological summary statistics which quantify spatio-temporal data and uses them to approximate parameter and model posterior distributions. We validate our pipeline on models of tumour-induced angiogenesis, inferring four parameters in three established models and identifying the correct model in synthetic test-cases.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Comparing mathematical models offers a means to evaluate competing scientifictheories. However, exact methods of model calibration are not applicable tomany probabilistic models which simulate high-dimensional spatio-temporal data.Approximate Bayesian Computation is a widely-used method for parameterinference and model selection in such scenarios, and it may be combined withTopological Data Analysis to study models which simulate data with fine spatialstructure. We develop a flexible pipeline for parameter inference and modelselection in spatio-temporal models. Our pipeline identifies topologicalsummary statistics which quantify spatio-temporal data and uses them toapproximate parameter and model posterior distributions. We validate ourpipeline on models of tumour-induced angiogenesis, inferring four parameters inthree established models and identifying the correct model in synthetictest-cases.</description>
      <author>example@mail.com (Robert A McDonald, Helen M Byrne, Heather A Harrington, Thomas Thorne, Bernadette J Stolz)</author>
      <guid isPermaLink="false">2504.15442v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Adaptation of Deep Neural Networks for Semantic Segmentation in Space Applications</title>
      <link>http://arxiv.org/abs/2504.15991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了深度学习技术在行星探测中的应用，特别是针对月球和火星地表岩石分割任务，探讨了使用适配器进行高效迁移学习的可行性。&lt;h4&gt;背景&lt;/h4&gt;近年来，深度学习技术在计算机视觉任务中取得了显著成功，为在行星探测中的应用奠定了基础。然而，在新的环境中，标记数据的稀缺性问题成为了一个挑战。&lt;h4&gt;目的&lt;/h4&gt;评估在行星探测中，特别是月球和火星地表岩石分割任务中，使用适配器进行高效迁移学习的可行性。&lt;h4&gt;方法&lt;/h4&gt;研究采用了两种内存节省策略：层融合（将推理开销降至零）和“适配器排名”（降低传输成本）。这些策略被整合到一个预训练的骨干模型中。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，将适配器策略集成到预训练骨干模型中，可以有效地减少目标外星设备的数据传输带宽和内存需求。&lt;h4&gt;结论&lt;/h4&gt;本研究在任务性能、内存和计算方面评估了结果，证实了在特定条件下存在权衡，为该领域进一步的研究指明了方向。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, the application of Deep Learning techniques has shown remarkable success in various computer vision tasks, paving the way for their deployment in extraterrestrial exploration. Transfer learning has emerged as a powerful strategy for addressing the scarcity of labeled data in these novel environments. This paper represents one of the first efforts in evaluating the feasibility of employing adapters toward efficient transfer learning for rock segmentation in extraterrestrial landscapes, mainly focusing on lunar and Martian terrains. Our work suggests that the use of adapters, strategically integrated into a pre-trained backbone model, can be successful in reducing both bandwidth and memory requirements for the target extraterrestrial device. In this study, we considered two memory-saving strategies: layer fusion (to reduce to zero the inference overhead) and an ``adapter ranking'' (to also reduce the transmission cost). Finally, we evaluate these results in terms of task performance, memory, and computation on embedded devices, evidencing trade-offs that open the road to more research in the field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the application of Deep Learning techniques has shownremarkable success in various computer vision tasks, paving the way for theirdeployment in extraterrestrial exploration. Transfer learning has emerged as apowerful strategy for addressing the scarcity of labeled data in these novelenvironments. This paper represents one of the first efforts in evaluating thefeasibility of employing adapters toward efficient transfer learning for rocksegmentation in extraterrestrial landscapes, mainly focusing on lunar andmartian terrains. Our work suggests that the use of adapters, strategicallyintegrated into a pre-trained backbone model, can be successful in reducingboth bandwidth and memory requirements for the target extraterrestrial device.In this study, we considered two memory-saving strategies: layer fusion (toreduce to zero the inference overhead) and an ``adapter ranking'' (to alsoreduce the transmission cost). Finally, we evaluate these results in terms oftask performance, memory, and computation on embedded devices, evidencingtrade-offs that open the road to more research in the field.</description>
      <author>example@mail.com (Leonardo Olivi, Edoardo Santero Mormile, Enzo Tartaglione)</author>
      <guid isPermaLink="false">2504.15991v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>IV-Bench: A Benchmark for Image-Grounded Video Perception and Reasoning in Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2504.15415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出IV-Bench，这是第一个全面评估图像基础视频感知和推理的基准。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态大型语言模型（MLLMs）评估框架主要关注图像推理或一般视频理解任务，很大程度上忽略了图像在视频理解中的重要作用。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，提出了IV-Bench，用于评估图像基础视频感知和推理。&lt;h4&gt;方法&lt;/h4&gt;IV-Bench包含967个视频和2,585个精心注释的图像-文本查询，涉及13个任务（7个感知和6个推理任务）和5个代表性类别。对最先进的开源和闭源MLLMs进行了广泛的评估。&lt;h4&gt;主要发现&lt;/h4&gt;评估显示，当前模型在图像基础视频感知和推理方面表现不佳，最高准确率仅为28.9%。进一步分析揭示了影响模型在IV-Bench上表现的关键因素，包括推理模式、帧数和分辨率。通过简单的数据合成方法，我们证明了IV-Bench的挑战不仅在于训练过程中数据格式的对齐。&lt;h4&gt;结论&lt;/h4&gt;这些发现为未来的研究提供了宝贵的见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes IV-Bench, which is the first comprehensive benchmark for evaluating image-grounded video perception and reasoning. The existing evaluation frameworks for Multimodal Large Language Models (MLLMs) primarily focus on image reasoning or general video understanding tasks, largely overlooking the significant role of image context in video comprehension. To bridge this gap, we propose IV-Bench, the first comprehensive benchmark for evaluating Image-Grounded Video Perception and Reasoning. IV-Bench consists of 967 videos paired with 2,585 meticulously annotated image-text queries across 13 tasks (7 perception and 6 reasoning tasks) and 5 representative categories. Extensive evaluations of state-of-the-art open-source (e.g., InternVL2.5, Qwen2.5-VL) and closed-source (e.g., GPT-4o, Gemini2-Flash and Gemini2-Pro) MLLMs demonstrate that current models substantially underperform in image-grounded video Perception and Reasoning, merely achieving at most 28.9% accuracy. Further analysis reveals key factors influencing model performance on IV-Bench, including inference pattern, frame number, and resolution. Additionally, through a simple data synthesis approach, we demonstrate the challenges of IV-Bench extend beyond merely aligning the data format in the training process. These findings collectively provide valuable insights for future research. Our codes and data are released in https://github.com/multimodal-art-projection/IV-Bench.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing evaluation frameworks for Multimodal Large Language Models (MLLMs)primarily focus on image reasoning or general video understanding tasks,largely overlooking the significant role of image context in videocomprehension. To bridge this gap, we propose IV-Bench, the first comprehensivebenchmark for evaluating Image-Grounded Video Perception and Reasoning.IV-Bench consists of 967 videos paired with 2,585 meticulously annotatedimage-text queries across 13 tasks (7 perception and 6 reasoning tasks) and 5representative categories. Extensive evaluations of state-of-the-artopen-source (e.g., InternVL2.5, Qwen2.5-VL) and closed-source (e.g., GPT-4o,Gemini2-Flash and Gemini2-Pro) MLLMs demonstrate that current modelssubstantially underperform in image-grounded video Perception and Reasoning,merely achieving at most 28.9% accuracy. Further analysis reveals key factorsinfluencing model performance on IV-Bench, including inference pattern, framenumber, and resolution. Additionally, through a simple data synthesis approach,we demonstratethe challenges of IV- Bench extend beyond merely aligning thedata format in the training proecss. These findings collectively providevaluable insights for future research. Our codes and data are released inhttps://github.com/multimodal-art-projection/IV-Bench.</description>
      <author>example@mail.com (David Ma, Yuanxing Zhang, Jincheng Ren, Jarvis Guo, Yifan Yao, Zhenlin Wei, Zhenzhu Yang, Zhongyuan Peng, Boyu Feng, Jun Ma, Xiao Gu, Zhoufutu Wen, King Zhu, Yancheng He, Meng Cao, Shiwen Ni, Jiaheng Liu, Wenhao Huang, Ge Zhang, Xiaojie Jin)</author>
      <guid isPermaLink="false">2504.15415v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Locating and Mitigating Gradient Conflicts in Point Cloud Domain Adaptation via Saliency Map Skewness</title>
      <link>http://arxiv.org/abs/2504.15796v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Saliency Map-based Data Sampling Block (SM-DSB)的新方法，用于解决点云数据在未知或分布外场景下的分类问题。&lt;h4&gt;背景&lt;/h4&gt;现有的点云无监督领域自适应（UDA）方法通常采用多任务学习（MTL）框架，结合主要分类任务和辅助自监督任务来弥合跨域特征分布之间的差距。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的解决方案，以减轻自监督任务中梯度冲突的影响，并提高分类性能。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于3D显著性图偏度的评分机制来估计梯度冲突，无需目标标签。基于此，开发了一种样本选择策略，动态过滤掉对分类无益的自监督梯度样本。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在性能上优于现有方法，并且具有可扩展性和较低的计算开销，可以集成到所有点云UDA MTL框架中。&lt;h4&gt;结论&lt;/h4&gt;通过反向传播分析，本文提供了一个理解UDA问题的新视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用点云数据的对象分类模型对于3D媒体理解至关重要，但它们在未知或分布外（OOD）场景中往往表现不佳。现有的点云无监督领域自适应（UDA）方法通常采用多任务学习（MTL）框架，将主要分类任务与辅助自监督任务相结合，以弥合跨域特征分布之间的差距。然而，我们的进一步实验表明，并非所有来自自监督任务的梯度都是有益的，其中一些可能对分类性能产生负面影响。在本文中，我们提出了一种新的解决方案，称为基于显著性图的数据采样块（SM-DSB），以减轻这些梯度冲突。具体来说，我们的方法设计了一种基于3D显著性图偏度的评分机制，以估计梯度冲突，而无需目标标签。利用这一点，我们开发了一种样本选择策略，动态过滤掉对分类无益的自监督梯度样本。我们的方法可扩展，引入了适度的计算开销，并且可以集成到所有点云UDA MTL框架中。广泛的评估表明，我们的方法在性能上优于现有方法。此外，我们通过反向传播分析提供了一个理解UDA问题的新视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object classification models utilizing point cloud data are fundamental for3D media understanding, yet they often struggle with unseen orout-of-distribution (OOD) scenarios. Existing point cloud unsupervised domainadaptation (UDA) methods typically employ a multi-task learning (MTL) frameworkthat combines primary classification tasks with auxiliary self-supervisiontasks to bridge the gap between cross-domain feature distributions. However,our further experiments demonstrate that not all gradients fromself-supervision tasks are beneficial and some may negatively impact theclassification performance. In this paper, we propose a novel solution, termedSaliency Map-based Data Sampling Block (SM-DSB), to mitigate these gradientconflicts. Specifically, our method designs a new scoring mechanism based onthe skewness of 3D saliency maps to estimate gradient conflicts withoutrequiring target labels. Leveraging this, we develop a sample selectionstrategy that dynamically filters out samples whose self-supervision gradientsare not beneficial for the classification. Our approach is scalable,introducing modest computational overhead, and can be integrated into all thepoint cloud UDA MTL frameworks. Extensive evaluations demonstrate that ourmethod outperforms state-of-the-art approaches. In addition, we provide a newperspective on understanding the UDA problem through back-propagation analysis.</description>
      <author>example@mail.com (Jiaqi Tang, Yinsong Xu, Qingchao Chen)</author>
      <guid isPermaLink="false">2504.15796v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Generative Image Modeling via Joint Image-Feature Synthesis</title>
      <link>http://arxiv.org/abs/2504.16064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的生成图像建模框架，通过联合建模低级图像潜变量和高级语义特征，实现了高质量的图像生成，同时提高了训练效率。&lt;h4&gt;背景&lt;/h4&gt;虽然潜在扩散模型（LDMs）在高质量图像生成中占据主导地位，但将表示学习与生成建模相结合仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一个框架，无缝连接表示学习与生成建模，以实现更高质量的图像生成。&lt;h4&gt;方法&lt;/h4&gt;利用扩散模型联合建模来自变分自编码器的低级图像潜变量和来自预训练自监督编码器（如DINO）的高级语义特征。该方法通过 Representation Guidance 策略，利用学习到的语义来引导和细化图像生成。&lt;h4&gt;主要发现&lt;/h4&gt;该方法从纯噪声中生成一致的图像-特征对，显著提高了生成质量和训练效率，同时只需对标准的扩散Transformer架构进行最小修改。&lt;h4&gt;结论&lt;/h4&gt;该方法在条件和无条件设置中均取得了实质性的改进，在图像质量和训练收敛速度方面表现出色，为具有表示意识的生成建模开辟了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;We introduce a novel generative image modeling framework that seamlessly bridges this gap by leveraging a diffusion model to jointly model low-level image latents (from a variational autoencoder) and high-level semantic features (from a pretrained self-supervised encoder like DINO). Our latent-semantic diffusion approach learns to generate coherent image-feature pairs from pure noise, significantly enhancing both generative quality and training efficiency, all while requiring only minimal modifications to standard Diffusion Transformer architectures. By eliminating the need for complex distillation objectives, our unified design simplifies training and unlocks a powerful new inference strategy: Representation Guidance, which leverages learned semantics to steer and refine image generation. Evaluated in both conditional and unconditional settings, our method delivers substantial improvements in image quality and training convergence speed, establishing a new direction for representation-aware generative modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Latent diffusion models (LDMs) dominate high-quality image generation, yetintegrating representation learning with generative modeling remains achallenge. We introduce a novel generative image modeling framework thatseamlessly bridges this gap by leveraging a diffusion model to jointly modellow-level image latents (from a variational autoencoder) and high-levelsemantic features (from a pretrained self-supervised encoder like DINO). Ourlatent-semantic diffusion approach learns to generate coherent image-featurepairs from pure noise, significantly enhancing both generative quality andtraining efficiency, all while requiring only minimal modifications to standardDiffusion Transformer architectures. By eliminating the need for complexdistillation objectives, our unified design simplifies training and unlocks apowerful new inference strategy: Representation Guidance, which leverageslearned semantics to steer and refine image generation. Evaluated in bothconditional and unconditional settings, our method delivers substantialimprovements in image quality and training convergence speed, establishing anew direction for representation-aware generative modeling.</description>
      <author>example@mail.com (Theodoros Kouzelis, Efstathios Karypidis, Ioannis Kakogeorgiou, Spyros Gidaris, Nikos Komodakis)</author>
      <guid isPermaLink="false">2504.16064v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search</title>
      <link>http://arxiv.org/abs/2504.15865v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了用于医学影像的深度学习模型，提出了Medical Neural Network Search (MedNNS)框架，以解决架构选择和权重初始化的挑战。&lt;h4&gt;背景&lt;/h4&gt;深度学习在医学影像领域取得了显著进展，但将深度学习模型应用于医学任务仍面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出MedNNS框架，以优化架构选择和权重初始化，提高医学影像模型的效果。&lt;h4&gt;方法&lt;/h4&gt;MedNNS通过构建元空间来编码数据集和模型，使用基于Supernetwork的方法扩大模型库，并引入排名损失和FID损失以捕捉模型和数据集之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;MedNNS在多个数据集上显著优于ImageNet预训练的深度学习模型和SOTA的神经网络搜索方法，平均准确率提高了1.7%，且收敛速度更快。&lt;h4&gt;结论&lt;/h4&gt;MedNNS是医学影像领域首个神经网络搜索框架，有效解决了深度学习模型在医学任务中的应用挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：深度学习（DL）在医学影像领域取得了显著的进步。然而，将深度学习模型应用于医学任务仍然是一个重大挑战，主要由于两个关键因素：（1）架构选择，因为不同的任务需要专门的设计；（2）权重初始化，这直接影响模型的收敛速度和最终性能。尽管从ImageNet迁移学习是一种广泛采用的策略，但其有效性受到自然图像和医学图像之间巨大差异的限制。为了解决这些挑战，我们引入了Medical Neural Network Search（MedNNS），这是第一个用于医学影像应用的神经网络搜索框架。MedNNS通过构建一个元空间来联合优化架构选择和权重初始化，该空间基于数据集和模型如何一起表现来编码它们。我们使用基于Supernetwork的方法构建这个空间，将模型库的大小扩大了51倍，超过了以前的最先进（SOTA）方法。此外，我们将排名损失和FID损失引入到空间构建中，以捕捉模型间和数据集间的关系，从而在元空间中实现更精确的对齐。在多个数据集上的实验结果表明，MedNNS在性能上显著优于ImageNet预训练的深度学习模型和SOTA的神经网络搜索方法，在数据集上的平均准确率提高了1.7%，同时收敛速度大大加快。代码和处理的元空间可在https://github.com/BioMedIA-MBZUAI/MedNNS上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning (DL) has achieved remarkable progress in the field of medicalimaging. However, adapting DL models to medical tasks remains a significantchallenge, primarily due to two key factors: (1) architecture selection, asdifferent tasks necessitate specialized model designs, and (2) weightinitialization, which directly impacts the convergence speed and finalperformance of the models. Although transfer learning from ImageNet is a widelyadopted strategy, its effectiveness is constrained by the substantialdifferences between natural and medical images. To address these challenges, weintroduce Medical Neural Network Search (MedNNS), the first Neural NetworkSearch framework for medical imaging applications. MedNNS jointly optimizesarchitecture selection and weight initialization by constructing a meta-spacethat encodes datasets and models based on how well they perform together. Webuild this space using a Supernetwork-based approach, expanding the model zoosize by 51x times over previous state-of-the-art (SOTA) methods. Moreover, weintroduce rank loss and Fr\'echet Inception Distance (FID) loss into theconstruction of the space to capture inter-model and inter-datasetrelationships, thereby achieving more accurate alignment in the meta-space.Experimental results across multiple datasets demonstrate that MedNNSsignificantly outperforms both ImageNet pre-trained DL models and SOTA NeuralArchitecture Search (NAS) methods, achieving an average accuracy improvement of1.7% across datasets while converging substantially faster. The code and theprocessed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS.</description>
      <author>example@mail.com (Lotfi Abdelkrim Mecharbat, Ibrahim Elmakky, Martin Takac, Mohammed Yaqub)</author>
      <guid isPermaLink="false">2504.15865v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning Dynamic Graphs via Tensorized and Lightweight Graph Convolutional Networks</title>
      <link>http://arxiv.org/abs/2504.15613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的动态图卷积网络（TLGCN）来准确学习动态图，该网络通过联合传播时空信息，并采用张量轻量级图卷积，显著减少了模型的内存占用。&lt;h4&gt;背景&lt;/h4&gt;动态图（DG）在许多实际场景中很常见，而动态图卷积网络（DGCN）在动态图上的精确表示学习方面取得了成功。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统DGCN中时空依赖性被分割的问题，提出了一种新的Tensorized Lightweight Graph Convolutional Network（TLGCN）。&lt;h4&gt;方法&lt;/h4&gt;该方法主要包括两个关键概念：a) 基于张量M-乘积框架设计了一种新的时空信息传播方法，用于联合传播时空信息；b) 提出了一种基于上述方法的张量轻量级图卷积网络，通过省略复杂的特征转换和非线性激活，显著减少了模型的内存占用。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界数据集上的数值实验表明，所提出的TLGCN在动态图上的权重估计任务中优于最先进的模型。&lt;h4&gt;结论&lt;/h4&gt;TLGCN在动态图学习方面具有更高的准确性和更低的内存占用，是一种有效的动态图卷积网络。&lt;h4&gt;翻译&lt;/h4&gt;A dynamic graph (DG) is frequently encountered in numerous real-world scenarios. Consequently, A dynamic graph convolutional network (DGCN) has been successfully applied to perform precise representation learning on a DG. However, conventional DGCNs typically consist of a static GCN coupled with a sequence neural network (SNN) to model spatial and temporal patterns separately. This decoupled modeling mechanism inherently disrupts the intricate spatio-temporal dependencies. To address the issue, this study proposes a novel Tensorized Lightweight Graph Convolutional Network (TLGCN) for accurate dynamic graph learning. It mainly contains the following two key concepts: a) designing a novel spatio-temporal information propagation method for joint propagation of spatio-temporal information based on the tensor M-product framework; b) proposing a tensorized lightweight graph convolutional network based on the above method, which significantly reduces the memory occupation of the model by omitting complex feature transformation and nonlinear activation. Numericalexperiments on four real-world datasets demonstrate that the proposed TLGCN outperforms the state-of-the-art models in the weight estimation task on DGs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A dynamic graph (DG) is frequently encountered in numerous real-worldscenarios. Consequently, A dynamic graph convolutional network (DGCN) has beensuccessfully applied to perform precise representation learning on a DG.However, conventional DGCNs typically consist of a static GCN coupled with asequence neural network (SNN) to model spatial and temporal patternsseparately. This decoupled modeling mechanism inherently disrupts the intricatespatio-temporal dependencies. To address the issue, this study proposes a novelTensorized Lightweight Graph Convolutional Network (TLGCN) for accurate dynamicgraph learning. It mainly contains the following two key concepts: a) designinga novel spatio-temporal information propagation method for joint propagation ofspatio-temporal information based on the tensor M-product framework; b)proposing a tensorized lightweight graph convolutional network based on theabove method, which significantly reduces the memory occupation of the model byomitting complex feature transformation and nonlinear activation. Numericalexperiments on four real-world datasets demonstrate that the proposed TLGCNoutperforms the state-of-the-art models in the weight estimation task on DGs.</description>
      <author>example@mail.com (Minglian Han)</author>
      <guid isPermaLink="false">2504.15613v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Measuring Interest Group Positions on Legislation: An AI-Driven Analysis of Lobbying Reports</title>
      <link>http://arxiv.org/abs/2504.15333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了美国特殊利益集团（SIGs）在政治活动中的参与情况，包括游说和竞选捐款，以影响政策决策。通过大规模数据集和先进的人工智能框架，分析了SIGs的政策立场及其对全球问题的潜在影响。&lt;h4&gt;背景&lt;/h4&gt;SIGs在立法和行政部门中参与各种政治活动，其利益冲突对国际贸易政策、移民、气候变化和全球健康等全球性问题有深远影响。&lt;h4&gt;目的&lt;/h4&gt;直接测量和预测第111至117届国会期间提出的所有法案的立场（支持、反对、参与）。&lt;h4&gt;方法&lt;/h4&gt;使用包括大型语言模型（LLMs）和图神经网络（GNNs）在内的高级AI框架，开发了一个可扩展的流程，从游说活动中自动提取这些立场，并创建了一个包含42k法案和279k SIGs法案立场的数据库。&lt;h4&gt;主要发现&lt;/h4&gt;发现法案在立法过程中的进展与利益集团立场之间存在强烈相关性；公司规模与游说立场之间存在显著关系；根据法案主题，游说立场分布存在显著差异；以及政策偏好在不同行业中的分布存在异质性。&lt;h4&gt;结论&lt;/h4&gt;引入了新的框架来检查游说策略，并提供了探索利益集团如何塑造政治格局的机会。&lt;h4&gt;翻译&lt;/h4&gt;摘要：美国特殊利益集团（SIGs）参与各种政治活动，如游说和竞选捐款，以影响立法和行政部门的政策决策。这些SIGs的利益冲突对国际贸易政策、移民、气候变化和全球健康等全球性问题有深远影响。尽管理解SIGs政策立场的重要性不言而喻，但观察SIGs的实证挑战往往导致研究人员依赖于间接测量或专注于公开支持或反对有限范围立法的少数SIGs。本研究首次大规模地直接测量和预测了第111至117届国会期间提出的所有法案的立场——支持、反对、参与（修订和监控）。我们利用包括大型语言模型（LLMs）和图神经网络（GNNs）在内的高级AI框架，开发了一个可扩展的流程，从游说活动中自动提取这些立场，从而创建了一个包含42k法案和279k SIGs法案立场的数据库。利用这个大规模数据集，我们发现（i）法案在立法过程中的进展与利益集团立场之间存在强烈相关性；（ii）公司规模与游说立场之间存在显著关系；（iii）根据法案主题，游说立场分布存在显著差异；（iv）政策偏好在不同行业中的分布存在异质性。我们引入了一个新的框架来检查游说策略，并提供了探索利益集团如何塑造政治格局的机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Special interest groups (SIGs) in the U.S. participate in a range ofpolitical activities, such as lobbying and making campaign donations, toinfluence policy decisions in the legislative and executive branches. Thecompeting interests of these SIGs have profound implications for global issuessuch as international trade policies, immigration, climate change, and globalhealth challenges. Despite the significance of understanding SIGs' policypositions, empirical challenges in observing them have often led researchers torely on indirect measurements or focus on a select few SIGs that publiclysupport or oppose a limited range of legislation. This study introduces thefirst large-scale effort to directly measure and predict a wide range of billpositions-Support, Oppose, Engage (Amend and Monitor)- across all legislativebills introduced from the 111th to the 117th Congresses. We leverage anadvanced AI framework, including large language models (LLMs) and graph neuralnetworks (GNNs), to develop a scalable pipeline that automatically extractsthese positions from lobbying activities, resulting in a dataset of 42k billsannotated with 279k bill positions of 12k SIGs. With this large-scale dataset,we reveal (i) a strong correlation between a bill's progression throughlegislative process stages and the positions taken by interest groups, (ii) asignificant relationship between firm size and lobbying positions, (iii)notable distinctions in lobbying position distribution based on bill subject,and (iv) heterogeneity in the distribution of policy preferences acrossindustries. We introduce a novel framework for examining lobbying strategiesand offer opportunities to explore how interest groups shape the politicallandscape.</description>
      <author>example@mail.com (Jiseon Kim, Dongkwan Kim, Joohye Jeong, Alice Oh, In Song Kim)</author>
      <guid isPermaLink="false">2504.15333v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for High-dimensional Reduced Rank Time Series Models</title>
      <link>http://arxiv.org/abs/2504.15691v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages accepted by AISTATS2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了时间序列模型中的迁移学习，特别是在具有时间依赖性和复杂模型参数结构的高维向量自回归（VAR）模型中。&lt;h4&gt;背景&lt;/h4&gt;迁移学习旨在通过利用从其他数据源获得的知识来增强目标数据的估计和推理。尽管在复杂、高维模型中已经探索了迁移学习，但针对时间序列模型的研究仍然有限。&lt;h4&gt;目的&lt;/h4&gt;本文专注于对具有时间依赖性和复杂模型参数结构的序列观察数据应用迁移学习。&lt;h4&gt;方法&lt;/h4&gt;本文研究了VAR模型，该模型是一种广泛用于时间序列数据的标准模型。提出了一个针对具有低秩和稀疏结构的VAR模型估计的新迁移学习算法，并提出了从辅助数据集中选择信息观察的新方法。&lt;h4&gt;主要发现&lt;/h4&gt;建立了理论保证，包括模型参数一致性、信息集选择，以及估计量在温和条件下的渐近分布。这有助于构建模型参数的逐项置信区间。&lt;h4&gt;结论&lt;/h4&gt;通过模拟和真实世界数据集展示了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文旨在研究时间序列模型中的迁移学习，特别是在具有时间依赖性和复杂模型参数结构的高维向量自回归（VAR）模型中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The objective of transfer learning is to enhance estimation and inference ina target data by leveraging knowledge gained from additional sources. Recentstudies have explored transfer learning for independent observations incomplex, high-dimensional models assuming sparsity, yet research on time seriesmodels remains limited. Our focus is on transfer learning for sequences ofobservations with temporal dependencies and a more intricate model parameterstructure. Specifically, we investigate the vector autoregressive model (VAR),a widely recognized model for time series data, where the transition matrix canbe deconstructed into a combination of a sparse matrix and a low-rank one. Wepropose a new transfer learning algorithm tailored for estimatinghigh-dimensional VAR models characterized by low-rank and sparse structures.Additionally, we present a novel approach for selecting informativeobservations from auxiliary datasets. Theoretical guarantees are established,encompassing model parameter consistency, informative set selection, and theasymptotic distribution of estimators under mild conditions. The latterfacilitates the construction of entry-wise confidence intervals for modelparameters. Finally, we demonstrate the empirical efficacy of our methodologiesthrough both simulated and real-world datasets.</description>
      <author>example@mail.com (Mingliang Ma Abolfazl Safikhani)</author>
      <guid isPermaLink="false">2504.15691v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Fourier analysis of the physics of transfer learning for data-driven subgrid-scale models of ocean turbulence</title>
      <link>http://arxiv.org/abs/2504.15487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了迁移学习（TL）在神经网络（NNs）性能提升中的应用，特别是在天气和气候预测以及湍流建模等领域。通过使用9层卷积神经网络预测二维海洋准地转系统的亚网格强迫，本文探讨了哪些指标最能描述其性能和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;迁移学习是一种强大的工具，可以增强神经网络在应用中的性能，尤其是在训练数据有限的情况下，它允许模型泛化到分布外数据。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在探讨如何使用迁移学习来提高神经网络在预测未知动态系统时的性能和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;研究者使用了一个9层的卷积神经网络来预测二维海洋准地转系统的亚网格强迫，并通过傅里叶分析来研究神经网络的滤波特性。他们还分析了激活频谱，以了解神经网络为何在没有迁移学习的情况下无法泛化，以及迁移学习如何克服这些限制。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，神经网络学习到的权重和偏差会低估分布外样本的频谱，导致输出频谱的低估。通过仅用目标系统的数据重新训练一个层，这种低估得到纠正，使得神经网络能够产生与目标频谱匹配的预测。&lt;h4&gt;结论&lt;/h4&gt;这些发现对于数据驱动的动态系统参数化具有广泛的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：迁移学习（TL）是一种强大的工具，可以增强神经网络（NNs）在应用中的性能，特别是在天气和气候预测以及湍流建模等领域。它允许模型在仅从新系统获取少量训练数据的情况下，泛化到分布外数据。在本研究中，我们使用一个9层的卷积神经网络来预测二维海洋准地转系统的亚网格强迫，并检验哪些指标最能描述其性能和泛化能力。神经网络的核的傅里叶分析表明，无论训练数据是各向同性还是各向异性，它们都学会了低通、高斯和带通滤波器。通过分析激活频谱，我们确定了为什么神经网络在没有迁移学习的情况下无法泛化，以及迁移学习如何克服这些限制：从一个数据集学习到的权重和偏差低估了通过网络传递的分布外样本频谱，导致输出频谱的低估。通过仅用目标系统的数据重新训练一个层，这种低估得到纠正，使得神经网络能够产生与目标频谱匹配的预测。这些发现对于数据驱动的动态系统参数化具有广泛的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning (TL) is a powerful tool for enhancing the performance ofneural networks (NNs) in applications such as weather and climate predictionand turbulence modeling. TL enables models to generalize to out-of-distributiondata with minimal training data from the new system. In this study, we employ a9-layer convolutional NN to predict the subgrid forcing in a two-layer oceanquasi-geostrophic system and examine which metrics best describe itsperformance and generalizability to unseen dynamical regimes. Fourier analysisof the NN kernels reveals that they learn low-pass, Gabor, and high-passfilters, regardless of whether the training data are isotropic or anisotropic.By analyzing the activation spectra, we identify why NNs fail to generalizewithout TL and how TL can overcome these limitations: the learned weights andbiases from one dataset underestimate the out-of-distribution sample spectra asthey pass through the network, leading to an underestimation of output spectra.By re-training only one layer with data from the target system, thisunderestimation is corrected, enabling the NN to produce predictions that matchthe target spectra. These findings are broadly applicable to data-drivenparameterization of dynamical systems.</description>
      <author>example@mail.com (Moein Darman, Pedram Hassanzadeh, Laure Zanna, Ashesh Chattopadhyay)</author>
      <guid isPermaLink="false">2504.15487v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification</title>
      <link>http://arxiv.org/abs/2504.15041v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的Lifelong Person Re-identification (LReID)模型，通过探索跨域共享表示学习和特定领域分布集成，解决了在保留旧知识的同时适应新信息的关键挑战。&lt;h4&gt;背景&lt;/h4&gt;LReID面临在保留旧知识的同时适应新信息的挑战，现有方法包括基于复述和无复述的方法，但存在复述方法持续积累遗忘和无复述方法学习分布不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型，旨在解决LReID中的遗忘问题，同时提高跨域共享表示学习和领域特定分布集成。&lt;h4&gt;方法&lt;/h4&gt;提出了Distribution-aware Forgetting Compensation (DAFC)模型，包括Text-driven Prompt Aggregation (TPA)和Distribution-based Awareness and Integration (DAI)。TPA利用文本特征丰富提示元素，指导模型学习细粒度表示；DAI通过专用专家网络捕获每个领域的特定分布，并将其适应性地整合到高维空间中的共享区域。此外，还开发了知识巩固机制(KCM)，包括实例级区分和跨域一致性对齐策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DAFC模型优于现有方法，能够有效解决LReID中的遗忘问题，并提高跨域共享表示学习和领域特定分布集成。&lt;h4&gt;结论&lt;/h4&gt;DAFC模型通过创新的跨域共享表示学习和领域特定分布集成方法，在LReID任务中取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel Lifelong Person Re-identification (LReID) model that addresses the key challenge of preserving old knowledge while adapting to new information by exploring cross-domain shared representation learning and domain-specific distribution integration.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/LiuShiBen/DAFC&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lifelong Person Re-identification (LReID) suffers from a key challenge inpreserving old knowledge while adapting to new information. The existingsolutions include rehearsal-based and rehearsal-free methods to address thischallenge. Rehearsal-based approaches rely on knowledge distillation,continuously accumulating forgetting during the distillation process.Rehearsal-free methods insufficiently learn the distribution of each domain,leading to forgetfulness over time. To solve these issues, we propose a novelDistribution-aware Forgetting Compensation (DAFC) model that explorescross-domain shared representation learning and domain-specific distributionintegration without using old exemplars or knowledge distillation. We propose aText-driven Prompt Aggregation (TPA) that utilizes text features to enrichprompt elements and guide the prompt model to learn fine-grainedrepresentations for each instance. This can enhance the differentiation ofidentity information and establish the foundation for domain distributionawareness. Then, Distribution-based Awareness and Integration (DAI) is designedto capture each domain-specific distribution by a dedicated expert network andadaptively consolidate them into a shared region in high-dimensional space. Inthis manner, DAI can consolidate and enhance cross-domain shared representationlearning while alleviating catastrophic forgetting. Furthermore, we develop aKnowledge Consolidation Mechanism (KCM) that comprises instance-leveldiscrimination and cross-domain consistency alignment strategies to facilitatemodel adaptive learning of new knowledge from the current domain and promoteknowledge consolidation learning between acquired domain-specificdistributions, respectively. Experimental results show that our DAFCoutperforms state-of-the-art methods. Our code is available athttps://github.com/LiuShiBen/DAFC.</description>
      <author>example@mail.com (Shiben Liu, Huijie Fan, Qiang Wang, Baojie Fan, Yandong Tang, Liangqiong Qu)</author>
      <guid isPermaLink="false">2504.15041v2</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Transferable Learning of Reaction Pathways from Geometric Priors</title>
      <link>http://arxiv.org/abs/2504.15370v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 6 figures; Supporting Information in ancillary files&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MEPIN的机器学习方法，用于高效预测化学反应中的最小能量路径（MEPs），以理解化学反应机制。&lt;h4&gt;背景&lt;/h4&gt;识别MEPs对于理解化学反应机制至关重要，但目前这一任务在计算上非常耗时。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需依赖过渡态几何或预先优化的反应路径的机器学习方法，以高效预测MEPs。&lt;h4&gt;方法&lt;/h4&gt;MEPIN方法基于对称破缺等变神经网络，该网络生成灵活数量的中间结构，并通过能量基础目标进行训练，同时结合几何先验作为初始插值或预训练目标，以提高效率。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在不同化学反应中具有普遍适用性，并在小分子反应和[3+2]环加成反应中实现了与参考内禀反应坐标的准确对齐。&lt;h4&gt;结论&lt;/h4&gt;该方法能够以高效、数据驱动的预测探索大型化学反应空间中的反应路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Identifying minimum-energy paths (MEPs) is crucial for understanding chemicalreaction mechanisms but remains computationally demanding. We introduce MEPIN,a scalable machine-learning method for efficiently predicting MEPs fromreactant and product configurations, without relying on transition-stategeometries or pre-optimized reaction paths during training. The task is definedas predicting deviations from geometric interpolations along reactioncoordinates. We address this task with a continuous reaction path model basedon a symmetry-broken equivariant neural network that generates a flexiblenumber of intermediate structures. The model is trained using an energy-basedobjective, with efficiency enhanced by incorporating geometric priors fromgeodesic interpolation as initial interpolations or pre-training objectives.Our approach generalizes across diverse chemical reactions and achievesaccurate alignment with reference intrinsic reaction coordinates, asdemonstrated on various small molecule reactions and [3+2] cycloadditions. Ourmethod enables the exploration of large chemical reaction spaces withefficient, data-driven predictions of reaction pathways.</description>
      <author>example@mail.com (Juno Nam, Miguel Steiner, Max Misterka, Soojung Yang, Avni Singhal, Rafael Gómez-Bombarelli)</author>
      <guid isPermaLink="false">2504.15370v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Histogram-based Parameter-efficient Tuning for Passive Sonar Classification</title>
      <link>http://arxiv.org/abs/2504.15214v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 4 figures. Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于直方图的参数高效调整（HPT）技术，用于改进参数高效的迁移学习（PETL）方法，以提高下游任务中的模型性能。&lt;h4&gt;背景&lt;/h4&gt;现有的PETL方法在适应下游任务时，往往难以捕捉到中间特征嵌入中的分布变化。&lt;h4&gt;目的&lt;/h4&gt;提出HPT技术，以捕获目标域的统计信息并调整嵌入，从而提高模型的性能。&lt;h4&gt;方法&lt;/h4&gt;HPT技术通过直方图方法来调整模型嵌入，使其更适应目标域。&lt;h4&gt;主要发现&lt;/h4&gt;在三个下游被动声纳数据集（ShipsEar、DeepShip、VTUAD）上的实验结果表明，HPT优于传统的适配器方法。在VTUAD数据集上，HPT达到了91.8%的准确率，而传统适配器为89.8%。此外，HPT训练速度更快，且生成的特征表示更接近全微调模型。&lt;h4&gt;结论&lt;/h4&gt;HPT在参数节省和性能之间取得了平衡，为现有适配器提供了一种分布感知的替代方案，并为资源受限环境中的可扩展迁移学习指明了有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;Parameter-efficient transfer learning (PETL) methods adapt large artificial neural networks to downstream tasks without fine-tuning the entire model. However, existing additive methods, such as adapters, sometimes struggle to capture distributional shifts in intermediate feature embeddings. We propose a novel histogram-based parameter-efficient tuning (HPT) technique that captures the statistics of the target domain and modulates the embeddings. Experimental results on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD) demonstrate that HPT outperforms conventional adapters. Notably, HPT achieves 91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yields feature representations closer to those of fully fine-tuned models. Overall, HPT balances parameter savings and performance, providing a distribution-aware alternative to existing adapters and shows a promising direction for scalable transfer learning in resource-constrained environments. The code is publicly available: https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient transfer learning (PETL) methods adapt large artificialneural networks to downstream tasks without fine-tuning the entire model.However, existing additive methods, such as adapters, sometimes struggle tocapture distributional shifts in intermediate feature embeddings. We propose anovel histogram-based parameter-efficient tuning (HPT) technique that capturesthe statistics of the target domain and modulates the embeddings. Experimentalresults on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD)demonstrate that HPT outperforms conventional adapters. Notably, HPT achieves91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yieldsfeature representations closer to those of fully fine-tuned models. Overall,HPT balances parameter savings and performance, providing a distribution-awarealternative to existing adapters and shows a promising direction for scalabletransfer learning in resource-constrained environments. The code is publiclyavailable:https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.</description>
      <author>example@mail.com (Amirmohammad Mohammadi, Davelle Carreiro, Alexandra Van Dine, Joshua Peeples)</author>
      <guid isPermaLink="false">2504.15214v2</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>HoLa: B-Rep Generation using a Holistic Latent Representation</title>
      <link>http://arxiv.org/abs/2504.14257v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACM TOG and SIGGRAPH 2025 (Patent Protected); Project page:  https://vcc.tech/research/2025/HolaBrep&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的边界表示（B-Reps）方法，用于学习和生成计算机辅助设计（CAD）模型，该方法在整体潜在空间（HoLa）中统一了不同顺序的B-Reps原初的连续几何属性和它们的离散拓扑关系。&lt;h4&gt;背景&lt;/h4&gt;基于观察，两个表面的拓扑连接本质上与它们相交曲线的几何属性相关。&lt;h4&gt;目的&lt;/h4&gt;通过将拓扑学习在B-Reps中重新定义为欧几里得空间中的几何重建问题，减少生成的B-Reps原初之间的歧义、冗余和不一致性，同时降低训练复杂性。&lt;h4&gt;方法&lt;/h4&gt;通过神经网络交点网络学习区分和推导曲线几何，消除潜在空间中的曲线、顶点和所有拓扑连接。&lt;h4&gt;主要发现&lt;/h4&gt;该方法定义在表面上，但能够编码完整的B-Reps模型，包括表面的几何、曲线、顶点及其拓扑关系。&lt;h4&gt;结论&lt;/h4&gt;该方法显著提高了生成B-Reps原初的有效性，达到82%，远超现有技术的50%左右。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种新的表示方法，用于学习和生成计算机辅助设计（CAD）模型，其形式为边界表示（B-Reps）。我们的表示方法在整体潜在空间（HoLa）中统一了不同顺序的B-Reps原初的连续几何属性及其离散拓扑关系。这是基于一个简单的观察：两个表面的拓扑连接本质上与它们相交曲线的几何属性相关。这样的先验条件允许我们将B-Reps中的拓扑学习重新定义为欧几里得空间中的几何重建问题。具体来说，我们通过学习从一对表面原初推导曲线几何来消除潜在空间中的曲线、顶点和所有拓扑连接。为此，我们的整体潜在空间仅定义在表面上，但能够编码完整的B-Reps模型，包括表面的几何、曲线、顶点及其拓扑关系。我们的紧凑且整体潜在空间简化了基于扩散的第一代生成器的开发，该生成器可以处理包括点云、单/多视图图像、2D草图和文本提示在内的各种输入。我们的方法显著减少了生成的B-Reps原初之间的歧义、冗余和不一致性，以及先前多步B-Reps学习管道中固有的训练复杂性，同时实现了比现有技术大幅提高的有效性率：82%对约50%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel representation for learning and generatingComputer-Aided Design (CAD) models in the form of $\textit{boundaryrepresentations}$ (B-Reps). Our representation unifies the continuous geometricproperties of B-Rep primitives in different orders (e.g., surfaces and curves)and their discrete topological relations in a $\textit{holistic latent}$ (HoLa)space. This is based on the simple observation that the topological connectionbetween two surfaces is intrinsically tied to the geometry of theirintersecting curve. Such a prior allows us to reformulate topology learning inB-Reps as a geometric reconstruction problem in Euclidean space. Specifically,we eliminate the presence of curves, vertices, and all the topologicalconnections in the latent space by learning to distinguish and derive curvegeometries from a pair of surface primitives via a neural intersection network.To this end, our holistic latent space is only defined on surfaces but encodesa full B-Rep model, including the geometry of surfaces, curves, vertices, andtheir topological relations. Our compact and holistic latent space facilitatesthe design of a first diffusion-based generator to take on a large variety ofinputs including point clouds, single/multi-view images, 2D sketches, and textprompts. Our method significantly reduces ambiguities, redundancies, andincoherences among the generated B-Rep primitives, as well as trainingcomplexities inherent in prior multi-step B-Rep learning pipelines, whileachieving greatly improved validity rate over current state of the art: 82% vs.$\approx$50%.</description>
      <author>example@mail.com (Yilin Liu, Duoteng Xu, Xingyao Yu, Xiang Xu, Daniel Cohen-Or, Hao Zhang, Hui Huang)</author>
      <guid isPermaLink="false">2504.14257v2</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Equi-Euler GraphNet: An Equivariant, Temporal-Dynamics Informed Graph Neural Network for Dual Force and Trajectory Prediction in Multi-Body Systems</title>
      <link>http://arxiv.org/abs/2504.13768v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  permission not yet received for arXiv&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Equi-Euler GraphNet的物理信息图神经网络，用于多体动力学系统的实时建模，以实现工业中的数字孪生应用。该方法在预测内部载荷和系统轨迹方面表现优异，适用于故障检测和预测性维护。&lt;h4&gt;背景&lt;/h4&gt;准确的多体动力学系统建模对于实现数字孪生技术至关重要。现有数据驱动方法在系统动力学学习方面取得了进展，但联合预测内部载荷和系统轨迹仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时预测多体系统内部力和全局轨迹的模型，以支持故障检测、预测性维护、损伤预测和剩余寿命估计。&lt;h4&gt;方法&lt;/h4&gt;Equi-Euler GraphNet是一种基于物理信息的图神经网络，它使用节点表示系统组件，边编码交互。该模型引入了两种归纳偏差：等效消息传递方案和基于欧拉积分的时间感知迭代节点更新机制。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在圆柱滚子轴承中解耦了环状动力学和滚动元件的约束运动。在高级多物理场模拟上训练后，Equi-Euler GraphNet在未见过的速度、载荷和配置下准确地预测了载荷和轨迹，超越了现有基于轨迹预测的GNN，并且具有更高的效率。&lt;h4&gt;结论&lt;/h4&gt;Equi-Euler GraphNet在保持高准确度的同时，实现了比传统求解器高达200倍的速度提升，是数字孪生、设计和维护领域的高效降阶模型。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Accurate real-time modeling of multi-body dynamical systems is essential for enabling digital twin applications across industries. While many data-driven approaches aim to learn system dynamics, jointly predicting internal loads and system trajectories remains a key challenge. This dual prediction is especially important for fault detection and predictive maintenance, where internal loads such as contact forces act as early indicators of faults, reflecting wear or misalignment before affecting motion. These forces also serve as inputs to degradation models (e.g., crack growth), enabling damage prediction and remaining useful life estimation. We propose Equi-Euler GraphNet, a physics-informed graph neural network (GNN) that simultaneously predicts internal forces and global trajectories in multi-body systems. In this mesh-free framework, nodes represent system components and edges encode interactions. Equi-Euler GraphNet introduces two inductive biases: (1) an equivalent message-passing scheme, interpreting edge messages as interaction forces consistent under Euclidean transformations; and (2) a temporal-aware iterative node update mechanism, based on Euler integration, to capture influence of distant interactions over time. Tailored for cylindrical roller bearings, it decouples ring dynamics from constrained motion of rolling elements. Trained on high-fidelity multiphysics simulations, Equi-Euler GraphNet generalizes beyond the training distribution, accurately predicting loads and trajectories under unseen speeds, loads, and configurations. It outperforms state-of-the-art GNNs focused on trajectory prediction, delivering stable rollouts over thousands of time steps with minimal error accumulation. Achieving up to a 200x speedup over conventional solvers while maintaining comparable accuracy, it serves as an efficient reduced-order model for digital twins, design, and maintenance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate real-time modeling of multi-body dynamical systems is essential forenabling digital twin applications across industries. While many data-drivenapproaches aim to learn system dynamics, jointly predicting internal loads andsystem trajectories remains a key challenge. This dual prediction is especiallyimportant for fault detection and predictive maintenance, where internalloads-such as contact forces-act as early indicators of faults, reflecting wearor misalignment before affecting motion. These forces also serve as inputs todegradation models (e.g., crack growth), enabling damage prediction andremaining useful life estimation. We propose Equi-Euler GraphNet, aphysics-informed graph neural network (GNN) that simultaneously predictsinternal forces and global trajectories in multi-body systems. In thismesh-free framework, nodes represent system components and edges encodeinteractions. Equi-Euler GraphNet introduces two inductive biases: (1) anequivariant message-passing scheme, interpreting edge messages as interactionforces consistent under Euclidean transformations; and (2) a temporal-awareiterative node update mechanism, based on Euler integration, to captureinfluence of distant interactions over time. Tailored for cylindrical rollerbearings, it decouples ring dynamics from constrained motion of rollingelements. Trained on high-fidelity multiphysics simulations, Equi-EulerGraphNet generalizes beyond the training distribution, accurately predictingloads and trajectories under unseen speeds, loads, and configurations. Itoutperforms state-of-the-art GNNs focused on trajectory prediction, deliveringstable rollouts over thousands of time steps with minimal error accumulation.Achieving up to a 200x speedup over conventional solvers while maintainingcomparable accuracy, it serves as an efficient reduced-order model for digitaltwins, design, and maintenance.</description>
      <author>example@mail.com (Vinay Sharma, Rémi Tanguy Oddon, Pietro Tesini, Jens Ravesloot, Cees Taal, Olga Fink)</author>
      <guid isPermaLink="false">2504.13768v2</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>A Graph-Based Reinforcement Learning Approach with Frontier Potential Based Reward for Safe Cluttered Environment Exploration</title>
      <link>http://arxiv.org/abs/2504.11907v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures, submitted to the 2025 IEEE/RSJ International  Conference on Intelligent Robots and Systems (IROS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合图神经网络探索贪婪策略和安全盾牌的新方法，以保障在杂乱环境中导航时的安全，并通过强化学习和近端策略优化算法来提高探索效率。&lt;h4&gt;背景&lt;/h4&gt;自主探索杂乱环境需要有效的探索策略，以防止与未知随机障碍物发生碰撞。&lt;h4&gt;目的&lt;/h4&gt;确保在杂乱环境中进行高效且安全的探索。&lt;h4&gt;方法&lt;/h4&gt;使用基于图神经网络的探索贪婪策略和安全盾牌，通过强化学习和近端策略优化算法进行网络训练。当策略选择不可行动作时，安全盾牌介入选择最佳可行替代方案。此外，提出了一种奖励函数，该函数包括基于代理与未探索区域接近程度的势场和到达这些区域预期的信息增益。&lt;h4&gt;主要发现&lt;/h4&gt;该方法结合了强化学习驱动探索策略的适应性和显式安全机制提供的保证。&lt;h4&gt;结论&lt;/h4&gt;在模拟环境中的大量评估表明，该方法能够在杂乱环境中实现高效且安全的探索。&lt;h4&gt;翻译&lt;/h4&gt;Autonomous exploration of cluttered environments requires efficient exploration strategies that guarantee safety against potential collisions with unknown random obstacles. This paper presents a novel approach combining a graph neural network-based exploration greedy policy with a safety shield to ensure safe navigation goal selection. The network is trained using reinforcement learning and the proximal policy optimization algorithm to maximize exploration efficiency while reducing the safety shield interventions. However, if the policy selects an infeasible action, the safety shield intervenes to choose the best feasible alternative, ensuring system consistency. Moreover, this paper proposes a reward function that includes a potential field based on the agent's proximity to unexplored regions and the expected information gain from reaching them. Overall, the approach investigated in this paper merges the benefits of the adaptability of reinforcement learning-driven exploration policies and the guarantee ensured by explicit safety mechanisms. Extensive evaluations in simulated environments demonstrate that the approach enables efficient and safe exploration in cluttered environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous exploration of cluttered environments requires efficientexploration strategies that guarantee safety against potential collisions withunknown random obstacles. This paper presents a novel approach combining agraph neural network-based exploration greedy policy with a safety shield toensure safe navigation goal selection. The network is trained usingreinforcement learning and the proximal policy optimization algorithm tomaximize exploration efficiency while reducing the safety shield interventions.However, if the policy selects an infeasible action, the safety shieldintervenes to choose the best feasible alternative, ensuring systemconsistency. Moreover, this paper proposes a reward function that includes apotential field based on the agent's proximity to unexplored regions and theexpected information gain from reaching them. Overall, the approachinvestigated in this paper merges the benefits of the adaptability ofreinforcement learning-driven exploration policies and the guarantee ensured byexplicit safety mechanisms. Extensive evaluations in simulated environmentsdemonstrate that the approach enables efficient and safe exploration incluttered environments.</description>
      <author>example@mail.com (Gabriele Calzolari, Vidya Sumathy, Christoforos Kanellakis, George Nikolakopoulos)</author>
      <guid isPermaLink="false">2504.11907v2</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>3D-PointZshotS: Geometry-Aware 3D Point Cloud Zero-Shot Semantic Segmentation Narrowing the Visual-Semantic Gap</title>
      <link>http://arxiv.org/abs/2504.12442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为3D-PointZshotS的几何感知零样本3D点云分割框架，旨在解决现有方法在从已见类别到未见类别以及从语义到视觉空间的迁移性方面的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的零样本3D点云分割方法在将特征从已见类别迁移到未见类别，以及从语义空间到视觉空间的对齐方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出3D-PointZshotS框架，以增强特征生成和对齐，使用潜在的几何原型（LGPs）。&lt;h4&gt;方法&lt;/h4&gt;通过交叉注意力机制将LGPs集成到生成器中，丰富语义特征以包含精细的几何细节。引入自一致性损失，增强特征对点扰动的不变性。此外，在共享空间中重新表示视觉和语义特征，以弥合语义-视觉差距并促进知识迁移到未见类别。&lt;h4&gt;主要发现&lt;/h4&gt;在ScanNet、SemanticKITTI和S3DIS三个真实世界数据集上的实验表明，该方法在和谐mIoU方面优于四个基线。&lt;h4&gt;结论&lt;/h4&gt;3D-PointZshotS在3D点云分割任务中取得了优异的性能，并且代码已开源。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a geometric-aware zero-shot 3D point cloud segmentation framework named 3D-PointZshotS, aiming to address the difficulties of existing methods in transferring features from seen classes to unseen classes and aligning from semantic to visual space. The 3D-PointZshotS framework is proposed to enhance feature generation and alignment using latent geometric prototypes (LGPs). Specifically, LGPs are integrated into a generator via a cross-attention mechanism to enrich semantic features with fine-grained geometric details. To further enhance stability and generalization, a self-consistency loss is introduced to enforce feature robustness against point-wise perturbations. Additionally, visual and semantic features are re-represented in a shared space to bridge the semantic-visual gap and facilitate knowledge transfer to unseen classes. Experiments on three real-world datasets, namely ScanNet, SemanticKITTI, and S3DIS, demonstrate that the proposed method achieves superior performance over four baselines in terms of harmonic mIoU. The code is available at Github.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing zero-shot 3D point cloud segmentation methods often struggle withlimited transferability from seen classes to unseen classes and from semanticto visual space. To alleviate this, we introduce 3D-PointZshotS, ageometry-aware zero-shot segmentation framework that enhances both featuregeneration and alignment using latent geometric prototypes (LGPs).Specifically, we integrate LGPs into a generator via a cross-attentionmechanism, enriching semantic features with fine-grained geometric details. Tofurther enhance stability and generalization, we introduce a self-consistencyloss, which enforces feature robustness against point-wise perturbations.Additionally, we re-represent visual and semantic features in a shared space,bridging the semantic-visual gap and facilitating knowledge transfer to unseenclasses. Experiments on three real-world datasets, namely ScanNet,SemanticKITTI, and S3DIS, demonstrate that our method achieves superiorperformance over four baselines in terms of harmonic mIoU. The code isavailable at \href{https://github.com/LexieYang/3D-PointZshotS}{Github}.</description>
      <author>example@mail.com (Minmin Yang, Huantao Ren, Senem Velipasalar)</author>
      <guid isPermaLink="false">2504.12442v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
  <item>
      <title>The Iterative Chainlet Partitioning Algorithm for the Traveling Salesman Problem with Drone and Neural Acceleration</title>
      <link>http://arxiv.org/abs/2504.15147v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了迭代链式分割（ICP）算法及其用于解决无人机旅行商问题（TSP-D）的神经网络加速方法。&lt;h4&gt;背景&lt;/h4&gt;研究背景是旅行商问题（TSP）及其在无人机配送中的应用。&lt;h4&gt;目的&lt;/h4&gt;研究目的是提出一种新的算法来优化无人机配送路径。&lt;h4&gt;方法&lt;/h4&gt;提出的ICP算法将TSP-D解决方案分解为更小的链式片段，每个片段通过动态规划子程序单独优化。通过迭代更新改进最大的链式片段，直到不再可能进一步改进。算法的子程序调用次数与问题规模线性相关，保证了算法的可扩展性。为了减少子程序调用的必要性，引入了图神经网络（GNN）来预测增量改进。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ICP在解决方案质量和计算时间上优于现有算法。在1059个基准实例上测试，ICP在解决方案质量上平均提高了2.75%，同时将计算时间减少了79.8%。神经网络加速后的Neuro ICP（NICP）在保持解决方案质量的同时，将总计算时间减少了49.7%，目标函数值增加仅限于0.12%。&lt;h4&gt;结论&lt;/h4&gt;该框架适应性强，是开发高效的卡车-无人机同步路由算法的有价值基础。&lt;h4&gt;翻译&lt;/h4&gt;This study introduces the Iterative Chainlet Partitioning (ICP) algorithm and its neural acceleration for solving the Traveling Salesman Problem with Drone (TSP-D). The proposed ICP algorithm decomposes a TSP-D solution into smaller segments called chainlets, each optimized individually by a dynamic programming subroutine. The chainlet with the highest improvement is updated and the procedure is repeated until no further improvement is possible. The number of subroutine calls is bounded linearly in problem size for the first iteration and remains constant in subsequent iterations, ensuring algorithmic scalability. Empirical results show that ICP outperforms existing algorithms in both solution quality and computational time. Tested over 1,059 benchmark instances, ICP yields an average improvement of 2.75% in solution quality over the previous state-of-the-art algorithm while reducing computational time by 79.8%. The procedure is deterministic, ensuring reliability without requiring multiple runs. The subroutine is the computational bottleneck in the already efficient ICP algorithm. To reduce the necessity of subroutine calls, we integrate a graph neural network (GNN) to predict incremental improvements. We demonstrate that the resulting Neuro ICP (NICP) achieves substantial acceleration while maintaining solution quality. Compared to ICP, NICP reduces the total computational time by 49.7%, while the objective function value increase is limited to 0.12%. The framework's adaptability to various operational constraints makes it a valuable foundation for developing efficient algorithms for truck-drone synchronized routing problems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study introduces the Iterative Chainlet Partitioning (ICP) algorithm andits neural acceleration for solving the Traveling Salesman Problem with Drone(TSP-D). The proposed ICP algorithm decomposes a TSP-D solution into smallersegments called chainlets, each optimized individually by a dynamic programmingsubroutine. The chainlet with the highest improvement is updated and theprocedure is repeated until no further improvement is possible. The number ofsubroutine calls is bounded linearly in problem size for the first iterationand remains constant in subsequent iterations, ensuring algorithmicscalability. Empirical results show that ICP outperforms existing algorithms inboth solution quality and computational time. Tested over 1,059 benchmarkinstances, ICP yields an average improvement of 2.75% in solution quality overthe previous state-of-the-art algorithm while reducing computational time by79.8%. The procedure is deterministic, ensuring reliability without requiringmultiple runs. The subroutine is the computational bottleneck in the alreadyefficient ICP algorithm. To reduce the necessity of subroutine calls, weintegrate a graph neural network (GNN) to predict incremental improvements. Wedemonstrate that the resulting Neuro ICP (NICP) achieves substantialacceleration while maintaining solution quality. Compared to ICP, NICP reducesthe total computational time by 49.7%, while the objective function valueincrease is limited to 0.12%. The framework's adaptability to variousoperational constraints makes it a valuable foundation for developing efficientalgorithms for truck-drone synchronized routing problems.</description>
      <author>example@mail.com (Jae Hyeok Lee, Minjun Kim, Jinkyoo Park, Changhyun Kwon)</author>
      <guid isPermaLink="false">2504.15147v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Degree Bias in Graph Representation Learning with Learnable Structural Augmentation and Structural Self-Attention</title>
      <link>http://arxiv.org/abs/2504.15075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IEEE TNSE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为 DegFairGT 的图神经网络（GNN）改进方法，旨在通过学习非相邻节点的结构相似性来缓解图中的度偏见问题，并提高了节点分类和聚类任务的性能。&lt;h4&gt;背景&lt;/h4&gt;现实世界中的图往往存在长尾度的分布，高度节点在信息传递中占据主导地位，导致低度节点代表性不足。&lt;h4&gt;目的&lt;/h4&gt;解决图中的度偏见问题，使得低度节点得到更充分的表示。&lt;h4&gt;方法&lt;/h4&gt;提出 DegFairGT，通过学习性结构增强和结构自注意力机制发现非相邻节点间的结构相似性，利用结构自注意力来捕捉节点对之间的相似性，并设计了一个自监督学习任务以保持全局图结构。&lt;h4&gt;主要发现&lt;/h4&gt; DegFairGT 在六个数据集上表现出优于现有基线的度公平性分析、节点分类和节点聚类任务性能。&lt;h4&gt;结论&lt;/h4&gt; DegFairGT 是一种有效的缓解图神经网络中度偏见问题的方法，能够提升图分析任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) update node representations through messagepassing, which is primarily based on the homophily principle, assuming thatadjacent nodes share similar features. However, in real-world graphs withlong-tailed degree distributions, high-degree nodes dominate message passing,causing a degree bias where low-degree nodes remain under-represented due toinadequate messages. The main challenge in addressing degree bias is how todiscover non-adjacent nodes to provide additional messages to low-degree nodeswhile reducing excessive messages for high-degree nodes. Nevertheless,exploiting non-adjacent nodes to provide valuable messages is challenging, asit could generate noisy information and disrupt the original graph structures.To solve it, we propose a novel Degree Fairness Graph Transformer, namedDegFairGT, to mitigate degree bias by discovering structural similaritiesbetween non-adjacent nodes through learnable structural augmentation andstructural self-attention. Our key idea is to exploit non-adjacent nodes withsimilar roles in the same community to generate informative edges under ouraugmentation, which could provide informative messages between nodes withsimilar roles while ensuring that the homophily principle is maintained withinthe community. To enable DegFairGT to learn such structural similarities, wethen propose a structural self-attention to capture the similarities betweennode pairs. To preserve global graph structures and prevent graph augmentationfrom hindering graph structure, we propose a Self-Supervised Learning task topreserve p-step transition probability and regularize graph augmentation.Extensive experiments on six datasets showed that DegFairGT outperformedstate-of-the-art baselines in degree fairness analysis, node classification,and node clustering tasks.</description>
      <author>example@mail.com (Van Thuy Hoang, Hyeon-Ju Jeon, O-Joun Lee)</author>
      <guid isPermaLink="false">2504.15075v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Survey of Loss Augmented Knowledge Tracing</title>
      <link>http://arxiv.org/abs/2504.15163v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, no figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了使用高级损失函数训练的基于深度学习的知识追踪（DKT）算法，并讨论了其相较于先前技术的改进。&lt;h4&gt;背景&lt;/h4&gt;人工神经网络训练高度依赖于损失函数的精心选择，常见的损失函数如交叉熵和均方误差（MSE）虽然在广泛任务中通常足够，但数据质量问题或学习过程中的低效可能导致挑战。&lt;h4&gt;目的&lt;/h4&gt;探讨如何通过集成补充项到损失函数中解决这些挑战，并提高模型性能和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;分析了损失正则化和对比学习作为增强损失函数能力在人工神经网络中的有效策略，并讨论了对比知识追踪算法，如Bi-CLKT，CL4KT，SP-CLKT，CoSKT和预测一致DKT。&lt;h4&gt;主要发现&lt;/h4&gt;提供了性能基准，并探讨了实际部署中的挑战。&lt;h4&gt;结论&lt;/h4&gt;总结了未来研究方向，包括混合损失策略和上下文感知建模。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人工神经网络训练高度依赖于适当损失函数的仔细选择。虽然常用的损失函数，如交叉熵和均方误差（MSE），通常适用于广泛的任务，但数据质量限制或学习过程中的低效往往导致挑战。在这种情况下，将补充项集成到损失函数中可以用来解决这些挑战，从而提高模型性能和鲁棒性。损失正则化和对比学习是两种已识别的有效策略，用于增强人工神经网络中损失函数的能力。知识追踪是一个引人注目的研究领域，它利用预测人工智能来促进个性化高效学习体验的自动化。在本文中，我们提供了一种基于深度学习的知识追踪（DKT）算法的全面回顾，讨论了它们相对于先前技术的改进。我们讨论了对比知识追踪算法，如Bi-CLKT，CL4KT，SP-CLKT，CoSKT和预测一致的DKT，提供了性能基准和实际部署挑战的见解。调查以未来研究方向总结，包括混合损失策略和上下文感知建模。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The training of artificial neural networks is heavily dependent on thecareful selection of an appropriate loss function. While commonly used lossfunctions, such as cross-entropy and mean squared error (MSE), generallysuffice for a broad range of tasks, challenges often emerge due to limitationsin data quality or inefficiencies within the learning process. In suchcircumstances, the integration of supplementary terms into the loss functioncan serve to address these challenges, enhancing both model performance androbustness. Two prominent techniques, loss regularization and contrastivelearning, have been identified as effective strategies for augmenting thecapacity of loss functions in artificial neural networks.  Knowledge tracing is a compelling area of research that leverages predictiveartificial intelligence to facilitate the automation of personalized andefficient educational experiences for students. In this paper, we provide acomprehensive review of the deep learning-based knowledge tracing (DKT)algorithms trained using advanced loss functions and discuss their improvementsover prior techniques. We discuss contrastive knowledge tracing algorithms,such as Bi-CLKT, CL4KT, SP-CLKT, CoSKT, and prediction-consistent DKT,providing performance benchmarks and insights into real-world deploymentchallenges. The survey concludes with future research directions, includinghybrid loss strategies and context-aware modeling.</description>
      <author>example@mail.com (Altun Shukurlu)</author>
      <guid isPermaLink="false">2504.15163v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>RoboOcc: Enhancing the Geometric and Semantic Scene Understanding for Robots</title>
      <link>http://arxiv.org/abs/2504.14604v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RoboOcc的3D占用预测方法，用于增强机器人对周围场景的几何和语义理解。&lt;h4&gt;背景&lt;/h4&gt;3D占用预测对于机器人的空间感知至关重要，但现有基于3D高斯的方法未能有效利用高斯的几何和透明度属性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以改善机器人对复杂环境的估计和对场景的描述。&lt;h4&gt;方法&lt;/h4&gt;RoboOcc使用透明度引导的自编码器（OSE）来减轻重叠高斯的语义模糊性，以及几何感知的交叉编码器（GCE）来完成周围场景的精细几何建模。&lt;h4&gt;主要发现&lt;/h4&gt;在Occ-ScanNet和EmbodiedOcc-ScanNet数据集上进行的实验表明，RoboOcc在局部和全局相机设置中均取得了最先进的性能。在消融研究中，RoboOcc在IoU和mIoU指标上分别比最先进的方法高出8.47和6.27。&lt;h4&gt;结论&lt;/h4&gt;RoboOcc是一种有效的3D占用预测方法，能够显著提升机器人在复杂环境中的空间感知能力。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a 3D occupancy prediction method named RoboOcc, which enhances the geometric and semantic understanding of the surrounding scene for robots.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D occupancy prediction enables the robots to obtain spatial fine-grainedgeometry and semantics of the surrounding scene, and has become an essentialtask for embodied perception. Existing methods based on 3D Gaussians instead ofdense voxels do not effectively exploit the geometry and opacity properties ofGaussians, which limits the network's estimation of complex environments andalso limits the description of the scene by 3D Gaussians. In this paper, wepropose a 3D occupancy prediction method which enhances the geometric andsemantic scene understanding for robots, dubbed RoboOcc. It utilizes theOpacity-guided Self-Encoder (OSE) to alleviate the semantic ambiguity ofoverlapping Gaussians and the Geometry-aware Cross-Encoder (GCE) to accomplishthe fine-grained geometric modeling of the surrounding scene. We conductextensive experiments on Occ-ScanNet and EmbodiedOcc-ScanNet datasets, and ourRoboOcc achieves state-of the-art performance in both local and global camerasettings. Further, in ablation studies of Gaussian parameters, the proposedRoboOcc outperforms the state-of-the-art methods by a large margin of (8.47,6.27) in IoU and mIoU metric, respectively. The codes will be released soon.</description>
      <author>example@mail.com (Zhang Zhang, Qiang Zhang, Wei Cui, Shuai Shi, Yijie Guo, Gang Han, Wen Zhao, Hengle Ren, Renjing Xu, Jian Tang)</author>
      <guid isPermaLink="false">2504.14604v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models</title>
      <link>http://arxiv.org/abs/2504.15271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Eagle 2.5，这是一系列前沿视觉-语言模型（VLMs）用于长上下文多模态学习。Eagle 2.5在长视频理解和高分辨率图像理解方面解决了挑战，并提出了一个适用于这两个任务的通用框架。&lt;h4&gt;背景&lt;/h4&gt;在长视频理解和高分辨率图像理解方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一个通用的框架来解决长视频理解和高分辨率图像理解的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一个包含自动降采样和图像区域保持的技术框架，以保持上下文完整性和视觉细节。同时，在长上下文数据训练过程中，对流程进行了多个效率优化。此外，还提出了一个新的数据集Eagle-Video-110K，它集成了故事级别和剪辑级别的标注，以促进长视频理解。&lt;h4&gt;主要发现&lt;/h4&gt;Eagle 2.5在长上下文多模态基准测试中表现出显著改进，为现有VLMs的局限性提供了稳健的解决方案。最佳模型Eagle 2.5-8B在Video-MME上达到了72.4%的准确率，与顶级商业模型如GPT-4o以及大规模开源模型如Qwen2.5-VL-72B和InternVL2.5-78B相当。&lt;h4&gt;结论&lt;/h4&gt;Eagle 2.5为长视频理解和多模态学习提供了一个有效的解决方案，并在性能上达到了现有顶级模型的水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Eagle 2.5, a family of frontier vision-language models (VLMs)for long-context multimodal learning. Our work addresses the challenges in longvideo comprehension and high-resolution image understanding, introducing ageneralist framework for both tasks. The proposed training frameworkincorporates Automatic Degrade Sampling and Image Area Preservation, twotechniques that preserve contextual integrity and visual details. The frameworkalso includes numerous efficiency optimizations in the pipeline forlong-context data training. Finally, we propose Eagle-Video-110K, a noveldataset that integrates both story-level and clip-level annotations,facilitating long-video understanding. Eagle 2.5 demonstrates substantialimprovements on long-context multimodal benchmarks, providing a robust solutionto the limitations of existing VLMs. Notably, our best model Eagle 2.5-8Bachieves 72.4% on Video-MME with 512 input frames, matching the results oftop-tier commercial model such as GPT-4o and large-scale open-source modelslike Qwen2.5-VL-72B and InternVL2.5-78B.</description>
      <author>example@mail.com (Guo Chen, Zhiqi Li, Shihao Wang, Jindong Jiang, Yicheng Liu, Lidong Lu, De-An Huang, Wonmin Byeon, Matthieu Le, Tuomas Rintamaki, Tyler Poon, Max Ehrlich, Tuomas Rintamaki, Tyler Poon, Tong Lu, Limin Wang, Bryan Catanzaro, Jan Kautz, Andrew Tao, Zhiding Yu, Guilin Liu)</author>
      <guid isPermaLink="false">2504.15271v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Robust and Real-time Surface Normal Estimation from Stereo Disparities using Affine Transformations</title>
      <link>http://arxiv.org/abs/2504.15121v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种从校正立体图像对中估计表面法线的新方法，该方法利用从视差值导出的仿射变换以实现快速和准确的结果。&lt;h4&gt;背景&lt;/h4&gt;通过校正立体图像对简化表面法线估计过程，减少了计算复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种快速且准确的表面法线估计方法。&lt;h4&gt;方法&lt;/h4&gt;开发了一种受卷积操作启发的自定义算法，用于高效处理视差数据；引入了自适应启发式技术，以高效检测图像中的连接表面组件，进一步提高方法的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在GPU上实施时，在实时性能和准确性方面有显著提升。&lt;h4&gt;结论&lt;/h4&gt;该方法能够生成密集且定向的点云作为最终输出，且在模拟环境和Middlebury、Cityscapes数据集的真实立体图像上得到验证。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种从校正立体图像对中估计表面法线的新方法，利用视差值导出的仿射变换以实现快速和准确的结果。通过校正立体图像对简化表面法线估计过程，减少了计算复杂性。为解决噪声问题，开发了一种受卷积操作启发的自定义算法，用于高效处理视差数据。同时，引入了自适应启发式技术，以高效检测图像中的连接表面组件，进一步提高方法的鲁棒性。通过整合这些方法，构建了一个既快速又准确的表面法线估计器，生成密集且定向的点云作为最终输出。该方法在GPU上实施时，在实时性能和准确性方面有显著提升。一旦被接受，将公开提供着色器源代码，以促进进一步研究和可重复性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces a novel method for surface normal estimation fromrectified stereo image pairs, leveraging affine transformations derived fromdisparity values to achieve fast and accurate results. We demonstrate how therectification of stereo image pairs simplifies the process of surface normalestimation by reducing computational complexity. To address noise reduction, wedevelop a custom algorithm inspired by convolutional operations, tailored toprocess disparity data efficiently. We also introduce adaptive heuristictechniques for efficiently detecting connected surface components within theimages, further improving the robustness of the method. By integrating thesemethods, we construct a surface normal estimator that is both fast andaccurate, producing a dense, oriented point cloud as the final output. Ourmethod is validated using both simulated environments and real-world stereoimages from the Middlebury and Cityscapes datasets, demonstrating significantimprovements in real-time performance and accuracy when implemented on a GPU.Upon acceptance, the shader source code will be made publicly available tofacilitate further research and reproducibility.</description>
      <author>example@mail.com (Csongor Csanad Kariko, Muhammad Rafi Faisal, Levente Hajder)</author>
      <guid isPermaLink="false">2504.15121v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Audio-Visual Class-Incremental Learning for Fish Feeding intensity Assessment in Aquaculture</title>
      <link>http://arxiv.org/abs/2504.15171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的鱼料强度评估方法，并引入了音频-视觉类增量学习框架，以解决现有方法在适应新鱼种或环境时的局限性。&lt;h4&gt;背景&lt;/h4&gt;鱼料强度评估在工业水产养殖管理中至关重要，但现有的多模态方法在适应新鱼种或环境时面临巨大挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在提高鱼料强度评估的鲁棒性和效率，并解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为AV-CIL-FFIA的新数据集，包含81,932个标签音频-视觉剪辑，覆盖了六种不同鱼种在水产养殖环境中的喂食强度。同时，引入了基于原型的新音频-视觉类增量学习框架HAIL-FFIA，该框架通过层次表示学习和双重路径知识保留机制来克服现有方法的限制。&lt;h4&gt;主要发现&lt;/h4&gt;HAIL-FFIA在AV-CIL-FFIA数据集上的表现优于现有方法，实现了更高的准确率，同时降低了存储需求并有效缓解了增量鱼种学习中的灾难性遗忘。&lt;h4&gt;结论&lt;/h4&gt;HAIL-FFIA是一个有效的鱼料强度评估方法，能够提高水产养殖管理的效率和质量。&lt;h4&gt;翻译&lt;/h4&gt;Fish Feeding Intensity Assessment (FFIA) is crucial in industrial aquaculture management. Recent multi-modal approaches have shown promise in improving FFIA robustness and efficiency. However, these methods face significant challenges when adapting to new fish species or environments due to catastrophic forgetting and the lack of suitable datasets. To address these limitations, we first introduce AV-CIL-FFIA, a new dataset comprising 81,932 labelled audio-visual clips capturing feeding intensities across six different fish species in real aquaculture environments. Then, we pioneer audio-visual class incremental learning (CIL) for FFIA and demonstrate through benchmarking on AV-CIL-FFIA that it significantly outperforms single-modality methods. Existing CIL methods rely heavily on historical data. Exemplar-based approaches store raw samples, creating storage challenges, while exemplar-free methods avoid data storage but struggle to distinguish subtle feeding intensity variations across different fish species. To overcome these limitations, we introduce HAIL-FFIA, a novel audio-visual class-incremental learning framework that bridges this gap with a prototype-based approach that achieves exemplar-free efficiency while preserving essential knowledge through compact feature representations. Specifically, HAIL-FFIA employs hierarchical representation learning with a dual-path knowledge preservation mechanism that separates general intensity knowledge from fish-specific characteristics. Additionally, it features a dynamic modality balancing system that adaptively adjusts the importance of audio versus visual information based on feeding behaviours stages. Experimental results show that HAIL-FFIA is superior to SOTA methods on AV-CIL-FFIA, achieving higher accuracy with lower storage needs while effectively mitigating catastrophic forgetting in incremental fish species learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fish Feeding Intensity Assessment (FFIA) is crucial in industrial aquaculturemanagement. Recent multi-modal approaches have shown promise in improving FFIArobustness and efficiency. However, these methods face significant challengeswhen adapting to new fish species or environments due to catastrophicforgetting and the lack of suitable datasets. To address these limitations, wefirst introduce AV-CIL-FFIA, a new dataset comprising 81,932 labelledaudio-visual clips capturing feeding intensities across six different fishspecies in real aquaculture environments. Then, we pioneer audio-visual classincremental learning (CIL) for FFIA and demonstrate through benchmarking onAV-CIL-FFIA that it significantly outperforms single-modality methods. ExistingCIL methods rely heavily on historical data. Exemplar-based approaches storeraw samples, creating storage challenges, while exemplar-free methods avoiddata storage but struggle to distinguish subtle feeding intensity variationsacross different fish species. To overcome these limitations, we introduceHAIL-FFIA, a novel audio-visual class-incremental learning framework thatbridges this gap with a prototype-based approach that achieves exemplar-freeefficiency while preserving essential knowledge through compact featurerepresentations. Specifically, HAIL-FFIA employs hierarchical representationlearning with a dual-path knowledge preservation mechanism that separatesgeneral intensity knowledge from fish-specific characteristics. Additionally,it features a dynamic modality balancing system that adaptively adjusts theimportance of audio versus visual information based on feeding behaviourstages. Experimental results show that HAIL-FFIA is superior to SOTA methods onAV-CIL-FFIA, achieving higher accuracy with lower storage needs whileeffectively mitigating catastrophic forgetting in incremental fish specieslearning.</description>
      <author>example@mail.com (Meng Cui, Xianghu Yue, Xinyuan Qian, Jinzheng Zhao, Haohe Liu, Xubo Liu, Daoliang Li, Wenwu Wang)</author>
      <guid isPermaLink="false">2504.15171v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Histogram-based Parameter-efficient Tuning for Passive Sonar Classification</title>
      <link>http://arxiv.org/abs/2504.15214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 4 figures. Submitted to IEEE WASPAA 2025 for possible  publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于直方图的参数高效调整（HPT）技术，用于适应下游任务，在参数高效迁移学习（PETL）方面优于传统的适配器方法。&lt;h4&gt;背景&lt;/h4&gt;现有的PETL方法，如适配器，在处理中间特征嵌入的分布变化时存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的HPT技术，以捕捉目标域的统计信息并调整嵌入。&lt;h4&gt;方法&lt;/h4&gt;在三个下游被动声纳数据集（ShipsEar、DeepShip、VTUAD）上进行了实验，以验证HPT方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;HPT在VTUAD数据集上实现了91.8%的准确率，优于传统的适配器（89.8%）。HPT训练速度更快，生成的特征表示更接近全微调模型。&lt;h4&gt;结论&lt;/h4&gt;HPT在参数节省和性能之间取得了平衡，为现有适配器提供了一个分布感知的替代方案，并为资源受限环境中的可扩展迁移学习提供了一个有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel histogram-based parameter-efficient tuning (HPT) technique for adapting large artificial neural networks to downstream tasks without fine-tuning the entire model. However, existing additive methods such as adapters sometimes struggle to capture distributional shifts in intermediate feature embeddings. We propose a new histogram-based parameter-efficient tuning (HPT) technique that captures the statistics of the target domain and modulates the embeddings. Experimental results on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD) demonstrate that HPT outperforms conventional adapters. Notably, HPT achieves 91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yields feature representations closer to those of fully fine-tuned models. Overall, HPT balances parameter savings and performance, providing a distribution-aware alternative to existing adapters and shows a promising direction for scalable transfer learning in resource-constrained environments. The code is publicly available: https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient transfer learning (PETL) methods adapt large artificialneural networks to downstream tasks without fine-tuning the entire model.However, existing additive methods, such as adapters, sometimes struggle tocapture distributional shifts in intermediate feature embeddings. We propose anovel histogram-based parameter-efficient tuning (HPT) technique that capturesthe statistics of the target domain and modulates the embeddings. Experimentalresults on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD)demonstrate that HPT outperforms conventional adapters. Notably, HPT achieves91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yieldsfeature representations closer to those of fully fine-tuned models. Overall,HPT balances parameter savings and performance, providing a distribution-awarealternative to existing adapters and shows a promising direction for scalabletransfer learning in resource-constrained environments. The code is publiclyavailable:https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.</description>
      <author>example@mail.com (Amirmohammad Mohammadi, Davelle Carreiro, Alexandra Van Dine, Joshua Peeples)</author>
      <guid isPermaLink="false">2504.15214v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking</title>
      <link>http://arxiv.org/abs/2504.15135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SIGIR 2025 (Short)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KGMEL的新型实体链接框架，该框架利用知识图谱（KG）三元组来增强多模态实体链接（MEL）的准确性。&lt;h4&gt;背景&lt;/h4&gt;实体链接（EL）将文本提及与知识库中的对应实体对齐，有助于语义搜索和问答等应用。多模态实体链接（MEL）结合文本和图像可以减少歧义并提高对齐精度，但现有方法往往忽略了知识图谱（KG）三元组中的丰富结构信息。&lt;h4&gt;目的&lt;/h4&gt;旨在通过利用知识图谱（KG）三元组来提高多模态实体链接（MEL）的准确性。&lt;h4&gt;方法&lt;/h4&gt;KGMEL框架分为三个阶段：生成高质量的三元组、通过对比学习学习联合提及-实体表示以及重新排序候选实体的KG三元组，并使用大型语言模型识别最佳匹配的实体。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的实验表明，KGMEL优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;KGMEL框架能够有效地利用知识图谱（KG）三元组来提高多模态实体链接（MEL）的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Entity linking (EL) aligns textual mentions with their corresponding entities in a knowledge base, facilitating various applications such as semantic search and question answering. Recent advances in multimodal entity linking (MEL) have shown that combining text and images can reduce ambiguity and improve alignment accuracy. However, most existing MEL methods overlook the rich structural information available in the form of knowledge-graph (KG) triples. In this paper, we propose KGMEL, a novel framework that leverages KG triples to enhance MEL. Specifically, it operates in three stages: (1) Generation: Produces high-quality triples for each mention by employing vision-language models based on its text and images. (2) Retrieval: Learns joint mention-entity representations, via contrastive learning, that integrate text, images, and (generated or KG) triples to retrieve candidate entities for each mention. (3) Reranking: Refines the KG triples of the candidate entities and employs large language models to identify the best-matching entity for the mention. Extensive experiments on benchmark datasets demonstrate that KGMEL outperforms existing methods. Our code and datasets are available at: https://github.com/juyeonnn/KGMEL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3726302.3730217&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/juyeonnn/kgmel&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Entity linking (EL) aligns textual mentions with their corresponding entitiesin a knowledge base, facilitating various applications such as semantic searchand question answering. Recent advances in multimodal entity linking (MEL) haveshown that combining text and images can reduce ambiguity and improve alignmentaccuracy. However, most existing MEL methods overlook the rich structuralinformation available in the form of knowledge-graph (KG) triples. In thispaper, we propose KGMEL, a novel framework that leverages KG triples to enhanceMEL. Specifically, it operates in three stages: (1) Generation: Produceshigh-quality triples for each mention by employing vision-language models basedon its text and images. (2) Retrieval: Learns joint mention-entityrepresentations, via contrastive learning, that integrate text, images, and(generated or KG) triples to retrieve candidate entities for each mention. (3)Reranking: Refines the KG triples of the candidate entities and employs largelanguage models to identify the best-matching entity for the mention. Extensiveexperiments on benchmark datasets demonstrate that KGMEL outperforms existingmethods. Our code and datasets are available at:https://github.com/juyeonnn/KGMEL.</description>
      <author>example@mail.com (Juyeon Kim, Geon Lee, Taeuk Kim, Kijung Shin)</author>
      <guid isPermaLink="false">2504.15135v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Rhythm of Opinion: A Hawkes-Graph Framework for Dynamic Propagation Analysis</title>
      <link>http://arxiv.org/abs/2504.15072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合多维Hawkes过程和图神经网络的方法，用于模拟社交网络中意见传播的动态，同时考虑评论之间的复杂层级关系。&lt;h4&gt;背景&lt;/h4&gt;社交媒体的快速发展改变了公众意见的动态，传统的模型无法有效捕捉这些复杂的互动。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出了一种新的方法来模拟和解释公众意见的传播。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了多维Hawkes过程和图神经网络，同时引入了一个新的数据集VISTA，该数据集包含了不同领域的热点话题及其对应的评论。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够捕捉到意见传播的多维性和层级结构，并通过VISTA数据集提供了对情感传播和评论层级关系的深入理解。&lt;h4&gt;结论&lt;/h4&gt;该方法为未来的研究提供了一个稳健的基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着社交媒体的快速发展，公众意见的动态发生了显著变化，导致传统模型无法有效捕捉的复杂互动。为了应对这一挑战，我们提出了一种创新的方法，该方法结合了多维Hawkes过程和图神经网络，用于模拟社交网络中节点之间的意见传播动态，同时考虑评论之间的复杂层级关系。扩展的多维Hawkes过程能够捕捉到层级结构、多维交互以及不同主题之间的相互影响，形成一个复杂的传播网络。此外，鉴于缺乏能够全面捕捉公众意见动态演变的高质量数据集，我们引入了一个新的数据集VISTA。它包括159个热点话题，对应47,207篇帖子，327,015条二级评论和29,578条三级评论，涵盖了政治、娱乐、体育、健康和医学等多个领域。该数据集在11个类别中标注了详细的情感标签，并清晰地定义了层级关系。当与我们的方法结合时，它通过将情感传播与评论层级和时间演变联系起来，提供了强大的可解释性。我们的方法为未来的研究提供了一个稳健的基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of social media has significantly reshaped the dynamicsof public opinion, resulting in complex interactions that traditional modelsfail to effectively capture. To address this challenge, we propose aninnovative approach that integrates multi-dimensional Hawkes processes withGraph Neural Network, modeling opinion propagation dynamics among nodes in asocial network while considering the intricate hierarchical relationshipsbetween comments. The extended multi-dimensional Hawkes process captures thehierarchical structure, multi-dimensional interactions, and mutual influencesacross different topics, forming a complex propagation network. Moreover,recognizing the lack of high-quality datasets capable of comprehensivelycapturing the evolution of public opinion dynamics, we introduce a new dataset,VISTA. It includes 159 trending topics, corresponding to 47,207 posts, 327,015second-level comments, and 29,578 third-level comments, covering diversedomains such as politics, entertainment, sports, health, and medicine. Thedataset is annotated with detailed sentiment labels across 11 categories andclearly defined hierarchical relationships. When combined with our method, itoffers strong interpretability by linking sentiment propagation to the commenthierarchy and temporal evolution. Our approach provides a robust baseline forfuture research.</description>
      <author>example@mail.com (Yulong Li, Zhixiang Lu, Feilong Tang, Simin Lai, Ming Hu, Yuxuan Zhang, Haochen Xue, Zhaodong Wu, Imran Razzak, Qingxia Li, Jionglong Su)</author>
      <guid isPermaLink="false">2504.15072v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Are Vision LLMs Road-Ready? A Comprehensive Benchmark for Safety-Critical Driving Video Understanding</title>
      <link>http://arxiv.org/abs/2504.14526v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了VLLMs在视觉任务中的表现，特别关注其在自动驾驶等安全关键领域的应用，提出了DVBench基准来评估VLLMs在理解安全关键驾驶视频方面的能力。&lt;h4&gt;背景&lt;/h4&gt;VLLMs在通用视觉任务中表现出色，但在安全关键领域如自动驾驶中的应用效果尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;开发DVBench基准，以评估VLLMs在理解安全关键驾驶视频方面的性能。&lt;h4&gt;方法&lt;/h4&gt;DVBench基于层次化的能力分类法，包含10,000道多选题，并提供人工标注的答案，用于全面评估VLLMs的感知和推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，14个SOTA VLLMs在DVBench上的表现存在显著差异，没有模型准确率超过40%，揭示了在理解复杂驾驶场景方面的关键局限性。通过在DVBench特定数据上微调模型，准确率提高了5.24到10.94个百分点，相对改进达到43.59%。&lt;h4&gt;结论&lt;/h4&gt;DVBench为开发满足实际自动驾驶系统安全性和鲁棒性要求的VLLMs提供了必要的评估框架和研究路线图。&lt;h4&gt;翻译&lt;/h4&gt;Vision Large Language Models (VLLMs) have demonstrated impressive capabilities in general visual tasks such as image captioning and visual question answering. However, their effectiveness in specialized, safety-critical domains like autonomous driving remains largely unexplored. Autonomous driving systems require sophisticated scene understanding in complex environments, yet existing multimodal benchmarks primarily focus on normal driving conditions, failing to adequately assess VLLMs' performance in safety-critical scenarios. To address this, we introduce DVBench, a pioneering benchmark designed to evaluate the performance of VLLMs in understanding safety-critical driving videos. Built around a hierarchical ability taxonomy that aligns with widely adopted frameworks for describing driving scenarios used in assessing highly automated driving systems, DVBench features 10,000 multiple-choice questions with human-annotated ground-truth answers, enabling a comprehensive evaluation of VLLMs' capabilities in perception and reasoning. Experiments on 14 SOTA VLLMs, ranging from 0.5B to 72B parameters, reveal significant performance gaps, with no model achieving over 40% accuracy, highlighting critical limitations in understanding complex driving scenarios. To probe adaptability, we fine-tuned selected models using domain-specific data from DVBench, achieving accuracy gains ranging from 5.24 to 10.94 percentage points, with relative improvements of up to 43.59%. This improvement underscores the necessity of targeted adaptation to bridge the gap between general-purpose VLLMs and mission-critical driving applications. DVBench establishes an essential evaluation framework and research roadmap for developing VLLMs that meet the safety and robustness requirements for real-world autonomous systems. We released the benchmark toolbox and the fine-tuned model at: https://github.com/tong-zeng/DVBench.git.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/tong-zeng/dvbench&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Large Language Models (VLLMs) have demonstrated impressivecapabilities in general visual tasks such as image captioning and visualquestion answering. However, their effectiveness in specialized,safety-critical domains like autonomous driving remains largely unexplored.Autonomous driving systems require sophisticated scene understanding in complexenvironments, yet existing multimodal benchmarks primarily focus on normaldriving conditions, failing to adequately assess VLLMs' performance insafety-critical scenarios. To address this, we introduce DVBench, a pioneeringbenchmark designed to evaluate the performance of VLLMs in understandingsafety-critical driving videos. Built around a hierarchical ability taxonomythat aligns with widely adopted frameworks for describing driving scenariosused in assessing highly automated driving systems, DVBench features 10,000multiple-choice questions with human-annotated ground-truth answers, enabling acomprehensive evaluation of VLLMs' capabilities in perception and reasoning.Experiments on 14 SOTA VLLMs, ranging from 0.5B to 72B parameters, revealsignificant performance gaps, with no model achieving over 40% accuracy,highlighting critical limitations in understanding complex driving scenarios.To probe adaptability, we fine-tuned selected models using domain-specific datafrom DVBench, achieving accuracy gains ranging from 5.24 to 10.94 percentagepoints, with relative improvements of up to 43.59%. This improvementunderscores the necessity of targeted adaptation to bridge the gap betweengeneral-purpose VLLMs and mission-critical driving applications. DVBenchestablishes an essential evaluation framework and research roadmap fordeveloping VLLMs that meet the safety and robustness requirements forreal-world autonomous systems. We released the benchmark toolbox and thefine-tuned model at: https://github.com/tong-zeng/DVBench.git.</description>
      <author>example@mail.com (Tong Zeng, Longfeng Wu, Liang Shi, Dawei Zhou, Feng Guo)</author>
      <guid isPermaLink="false">2504.14526v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>An LMM for Efficient Video Understanding via Reinforced Compression of Video Cubes</title>
      <link>http://arxiv.org/abs/2504.15270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Quicksviewer的LMM，通过新的感知范式，将视频分割成不同密度的立方体，并统一对每个立方体进行重采样，以实现高效的视频理解。&lt;h4&gt;背景&lt;/h4&gt;大型多模态模型（LMMs）在处理具有不同时间信息密度的视频时存在计算效率低下的问题。&lt;h4&gt;目的&lt;/h4&gt;旨在提高视频理解的效率，同时减少时空冗余。&lt;h4&gt;方法&lt;/h4&gt;使用Gumbel Softmax将视频分割成不同密度的立方体，并对每个立方体进行统一重采样，通过三个渐进阶段训练模型，每个阶段使用平均420秒/1fps的长时间视频。&lt;h4&gt;主要发现&lt;/h4&gt;Quicksviewer模型在训练时仅需0.8M个视频-文本样本，就能在Video-MME上达到SOTA性能，并且仅使用基准模型所需帧中5%的token。&lt;h4&gt;结论&lt;/h4&gt;Quicksviewer模型在性能上优于使用固定分割策略的基线模型，证明了其在视频理解中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents Quicksviewer, an LMM with a new perceiving paradigm that partitions a video of nonuniform density into varying cubes using Gumbel Softmax, followed by a unified resampling for each cube to achieve efficient video understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Multimodal Models (LMMs) uniformly perceive video frames, creatingcomputational inefficiency for videos with inherently varying temporalinformation density. This paper present \textbf{Quicksviewer}, an LMM with newperceiving paradigm that partitions a video of nonuniform density into varyingcubes using Gumbel Softmax, followed by a unified resampling for each cube toachieve efficient video understanding. This simple and intuitive approachdynamically compress video online based on its temporal density, significantlyreducing spatiotemporal redundancy (overall 45$\times$ compression rate), whileenabling efficient training with large receptive field. We train the model froma language backbone through three progressive stages, each incorporatinglengthy videos on average of 420s/1fps thanks to the perceiving efficiency.With only 0.8M total video-text samples for training, our model outperforms thedirect baseline employing a fixed partitioning strategy by a maximum of 8.72 inaccuracy, demonstrating the effectiveness in performance. On Video-MME,Quicksviewer achieves SOTA under modest sequence lengths using just up to 5\%of tokens per frame required by baselines. With this paradigm, scaling up thenumber of input frames reveals a clear power law of the model capabilities. Itis also empirically verified that the segments generated by the cubing networkcan help for analyzing continuous events in videos.</description>
      <author>example@mail.com (Ji Qi, Yuan Yao, Yushi Bai, Bin Xu, Juanzi Li, Zhiyuan Liu, Tat-Seng Chua)</author>
      <guid isPermaLink="false">2504.15270v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Is Intelligence the Right Direction in New OS Scheduling for Multiple Resources in Cloud Environments?</title>
      <link>http://arxiv.org/abs/2504.15021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 14 figures, to be published in ACM Transactions on Storage&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于机器学习的资源调度机制OSML+，用于协同定位云服务的系统/操作系统设计。&lt;h4&gt;背景&lt;/h4&gt;将智能引入系统/操作系统设计是一种有前景的方法。&lt;h4&gt;目的&lt;/h4&gt;提高资源调度效率，实现更智能的资源管理。&lt;h4&gt;方法&lt;/h4&gt;OSML+通过多模型协作学习方式同时智能调度内存层次中的缓存和主内存带宽资源，以及计算核心资源。&lt;h4&gt;主要发现&lt;/h4&gt;OSML+能够处理复杂情况，如避免资源悬崖、在不同优先级的应用间共享资源、为不同优先级的应用启用不同的调度策略等。使用机器学习模型，OSML+能够比以往研究更快地收敛。此外，OSML+可以自动动态学习并相应地处理动态变化的工作负载。通过迁移学习技术，证明了该设计在包括最新市售大规模服务器在内的各种云服务器上均能良好工作。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，OSML+支持比以往研究更高的负载，并且具有更低的开销，同时达到了QoS目标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Making it intelligent is a promising way in System/OS design. This paperproposes OSML+, a new ML-based resource scheduling mechanism for co-locatedcloud services. OSML+ intelligently schedules the cache and main memorybandwidth resources at the memory hierarchy and the computing core resourcessimultaneously. OSML+ uses a multi-model collaborative learning approach duringits scheduling and thus can handle complicated cases, e.g., avoiding resourcecliffs, sharing resources among applications, enabling different schedulingpolicies for applications with different priorities, etc. OSML+ can convergefaster using ML models than previous studies. Moreover, OSML+ can automaticallylearn on the fly and handle dynamically changing workloads accordingly. Usingtransfer learning technologies, we show our design can work well across variouscloud servers, including the latest off-the-shelf large-scale servers. Ourexperimental results show that OSML+ supports higher loads and meets QoStargets with lower overheads than previous studies.</description>
      <author>example@mail.com (Xinglei Dou, Lei Liu, Limin Xiao)</author>
      <guid isPermaLink="false">2504.15021v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Uni3C: Unifying Precisely 3D-Enhanced Camera and Human Motion Controls for Video Generation</title>
      <link>http://arxiv.org/abs/2504.14899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://github.com/ewrfcas/Uni3C&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Uni3C的统一3D增强框架，用于在视频生成中精确控制相机和人类运动，以解决现有方法通常分别处理相机和人类运动控制，且数据标注有限的问题。&lt;h4&gt;背景&lt;/h4&gt;相机和人类运动控制已被广泛研究，但现有方法通常分别处理它们，导致高质量标注的数据有限。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的局限性，提出一种能够统一控制视频生成中相机和人类运动的框架。&lt;h4&gt;方法&lt;/h4&gt;Uni3C包括两个主要贡献：一是提出了一种名为PCDController的即插即用控制模块，利用单目深度图的不投影点云进行精确的相机控制；二是提出了一个联合对齐的3D世界引导，无缝集成场景点云和SMPL-X角色，以统一相机和人类运动的控制信号。&lt;h4&gt;主要发现&lt;/h4&gt;PCDController在驱动相机运动方面表现出强大的鲁棒性，无论推理骨干是冻结还是微调。Uni3C在相机可控性和人类运动质量方面显著优于竞争对手。&lt;h4&gt;结论&lt;/h4&gt;Uni3C通过收集具有挑战性相机运动和人类动作的定制验证集，验证了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Camera and human motion controls have been extensively studied for video generation, but existing approaches typically address them separately, suffering from limited data with high-quality annotations for both aspects. To overcome this, we present Uni3C, a unified 3D-enhanced framework for precise control of both camera and human motion in video generation. Uni3C includes two key contributions. First, we propose a plug-and-play control module trained with a frozen video generative backbone, PCDController, which utilizes unprojected point clouds from monocular depth to achieve accurate camera control. By leveraging the strong 3D priors of point clouds and the powerful capacities of video foundational models, PCDController shows impressive generalization, performing well regardless of whether the inference backbone is frozen or fine-tuned. This flexibility enables different modules of Uni3C to be trained in specific domains, i.e., either camera control or human motion control, reducing the dependency on jointly annotated data. Second, we propose a jointly aligned 3D world guidance for the inference phase that seamlessly integrates both scenic point clouds and SMPL-X characters to unify the control signals for camera and human motion, respectively. Extensive experiments confirm that PCDController enjoys strong robustness in driving camera motion for fine-tuned backbones of video generation. Uni3C substantially outperforms competitors in both camera controllability and human motion quality. Additionally, we collect tailored validation sets featuring challenging camera movements and human actions to validate the effectiveness of our method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ewrfcas/uni3c&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Camera and human motion controls have been extensively studied for videogeneration, but existing approaches typically address them separately,suffering from limited data with high-quality annotations for both aspects. Toovercome this, we present Uni3C, a unified 3D-enhanced framework for precisecontrol of both camera and human motion in video generation. Uni3C includes twokey contributions. First, we propose a plug-and-play control module trainedwith a frozen video generative backbone, PCDController, which utilizesunprojected point clouds from monocular depth to achieve accurate cameracontrol. By leveraging the strong 3D priors of point clouds and the powerfulcapacities of video foundational models, PCDController shows impressivegeneralization, performing well regardless of whether the inference backbone isfrozen or fine-tuned. This flexibility enables different modules of Uni3C to betrained in specific domains, i.e., either camera control or human motioncontrol, reducing the dependency on jointly annotated data. Second, we proposea jointly aligned 3D world guidance for the inference phase that seamlesslyintegrates both scenic point clouds and SMPL-X characters to unify the controlsignals for camera and human motion, respectively. Extensive experimentsconfirm that PCDController enjoys strong robustness in driving camera motionfor fine-tuned backbones of video generation. Uni3C substantially outperformscompetitors in both camera controllability and human motion quality.Additionally, we collect tailored validation sets featuring challenging cameramovements and human actions to validate the effectiveness of our method.</description>
      <author>example@mail.com (Chenjie Cao, Jingkai Zhou, Shikai Li, Jingyun Liang, Chaohui Yu, Fan Wang, Xiangyang Xue, Yanwei Fu)</author>
      <guid isPermaLink="false">2504.14899v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>A Self-Improving Coding Agent</title>
      <link>http://arxiv.org/abs/2504.15228v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at an ICLR 2025 workshop on Scaling Self-Improving  Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;展示了装备基本编码工具的LLM编码智能体能够自主编辑自身，从而提高其在基准任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;研究了智能体系统在自动和开放设计方面的进步。&lt;h4&gt;目的&lt;/h4&gt;为那些寻求在工具使用和其他智能体任务上对LLM进行后续训练的人提供参考智能体框架。&lt;h4&gt;方法&lt;/h4&gt;利用装备基本编码工具的LLM编码智能体进行自主编辑，并在SWEBench Verified的随机子集以及LiveCodeBench和合成智能体基准上测试其性能。&lt;h4&gt;主要发现&lt;/h4&gt;在SWEBench Verified的随机子集上，性能提升从17%到53%，在LiveCodeBench上也有额外性能提升。&lt;h4&gt;结论&lt;/h4&gt;该研究代表了在智能体系统自动化和开放设计方面的一项进步。&lt;h4&gt;翻译&lt;/h4&gt;我们证明了一个装备基本编码工具的LLM编码智能体可以自主编辑自身，从而在基准任务上提高其性能。我们在SWEBench Verified的随机子集上发现了17%到53%的性能提升，在LiveCodeBench上也有额外的性能提升，以及在合成智能体基准上也有性能提升。我们的工作代表了在智能体系统的自动化和开放设计方面的一项进步，并为那些寻求在工具使用和其他智能体任务上对LLM进行后续训练的人提供了一个参考智能体框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We demonstrate that an LLM coding agent, equipped with basic coding tools,can autonomously edit itself, and thereby improve its performance on benchmarktasks. We find performance gains from 17% to 53% on a random subset of SWEBench Verified, with additional performance gains on LiveCodeBench, as well assynthetically generated agent benchmarks. Our work represents an advancement inthe automated and open-ended design of agentic systems, and provides areference agent framework for those seeking to post-train LLMs on tool use andother agentic tasks.</description>
      <author>example@mail.com (Maxime Robeyns, Martin Szummer, Laurence Aitchison)</author>
      <guid isPermaLink="false">2504.15228v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification</title>
      <link>http://arxiv.org/abs/2504.15041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对Lifelong Person Re-identification（LReID）在保留旧知识的同时适应新信息的关键挑战，提出了一种新的Distribution-aware Forgetting Compensation（DAFC）模型，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;LReID在长期学习和适应新信息时，面临着保留旧知识和适应新信息之间的关键挑战。&lt;h4&gt;目的&lt;/h4&gt;解决LReID中保留旧知识的同时适应新信息的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的DAFC模型，该模型通过探索跨域共享表示学习和特定域分布集成来解决这个问题，同时使用Text-driven Prompt Aggregation（TPA）来丰富提示元素，并设计Distribution-based Awareness and Integration（DAI）来捕捉每个特定域的分布。此外，还开发了知识巩固机制（KCM），包括实例级别区分和跨域一致性对齐策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DAFC在两个训练顺序上的平均AP/R@1至少比最先进的模型高出9.8%/6.6%和6.4%/6.2%。&lt;h4&gt;结论&lt;/h4&gt;DAFC模型在LReID任务中表现出色，有效解决了知识遗忘和模型适应性学习的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/LiuShiBen/DAFC&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lifelong Person Re-identification (LReID) suffers from a key challenge inpreserving old knowledge while adapting to new information. The existingsolutions include rehearsal-based and rehearsal-free methods to address thischallenge. Rehearsal-based approaches rely on knowledge distillation,continuously accumulating forgetting during the distillation process.Rehearsal-free methods insufficiently learn the distribution of each domain,leading to forgetfulness over time. To solve these issues, we propose a novelDistribution-aware Forgetting Compensation (DAFC) model that explorescross-domain shared representation learning and domain-specific distributionintegration without using old exemplars or knowledge distillation. We propose aText-driven Prompt Aggregation (TPA) that utilizes text features to enrichprompt elements and guide the prompt model to learn fine-grainedrepresentations for each instance. This can enhance the differentiation ofidentity information and establish the foundation for domain distributionawareness. Then, Distribution-based Awareness and Integration (DAI) is designedto capture each domain-specific distribution by a dedicated expert network andadaptively consolidate them into a shared region in high-dimensional space. Inthis manner, DAI can consolidate and enhance cross-domain shared representationlearning while alleviating catastrophic forgetting. Furthermore, we develop aKnowledge Consolidation Mechanism (KCM) that comprises instance-leveldiscrimination and cross-domain consistency alignment strategies to facilitatemodel adaptive learning of new knowledge from the current domain and promoteknowledge consolidation learning between acquired domain-specificdistributions, respectively. Experimental results show that our DAFC outperformstate-of-the-art methods by at least 9.8\%/6.6\% and 6.4\%/6.2\% of averagemAP/R@1 on two training orders.</description>
      <author>example@mail.com (Shiben Liu, Huijie Fan, Qiang Wang, Baojie Fan, Yandong Tang, Liangqiong Qu)</author>
      <guid isPermaLink="false">2504.15041v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Improving Sound Source Localization with Joint Slot Attention on Image and Audio</title>
      <link>http://arxiv.org/abs/2504.15118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的声音源定位（SSL）方法，通过联合图像和音频的特征注意力来解决现有方法的不足，并在公共基准测试中取得了最佳性能。&lt;h4&gt;背景&lt;/h4&gt;声音源定位（SSL）任务是在图像中定位声音源。由于缺乏定位标签，SSL中通常将图像和音频表示为单个嵌入向量，并通过对比学习来学习SSL。&lt;h4&gt;目的&lt;/h4&gt;针对现有方法在噪声和背景无关特征存在时的不足，提出一种新的SSL方法。&lt;h4&gt;方法&lt;/h4&gt;该方法通过联合图像和音频的槽位注意力来分解特征，只使用图像和音频的目标表示进行对比学习，并引入跨模态注意力匹配以进一步对齐图像和音频的局部特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在三个公共SSL基准测试中几乎所有设置中都取得了最佳性能，并且在跨模态检索中显著优于所有先前的工作。&lt;h4&gt;结论&lt;/h4&gt;该方法通过改进的特征表示和注意力机制，提高了SSL任务的性能，为音频和图像的跨模态检索提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sound source localization (SSL) is the task of locating the source of soundwithin an image. Due to the lack of localization labels, the de facto standardin SSL has been to represent an image and audio as a single embedding vectoreach, and use them to learn SSL via contrastive learning. To this end, previouswork samples one of local image features as the image embedding and aggregatesall local audio features to obtain the audio embedding, which is far fromoptimal due to the presence of noise and background irrelevant to the actualtarget in the input. We present a novel SSL method that addresses this chronicissue by joint slot attention on image and audio. To be specific, two slotscompetitively attend image and audio features to decompose them into target andoff-target representations, and only target representations of image and audioare used for contrastive learning. Also, we introduce cross-modal attentionmatching to further align local features of image and audio. Our methodachieved the best in almost all settings on three public benchmarks for SSL,and substantially outperformed all the prior work in cross-modal retrieval.</description>
      <author>example@mail.com (Inho Kim, Youngkil Song, Jicheol Park, Won Hwa Kim, Suha Kwak)</author>
      <guid isPermaLink="false">2504.15118v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Edge-boosted graph learning for functional brain connectivity analysis</title>
      <link>http://arxiv.org/abs/2504.14796v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IEEE International Symposium on Biomedical Imaging (ISBI)  2025, 4 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的脑网络分析方法，通过强调边功能连接（eFC）来预测严重神经退行性疾病如阿尔茨海默病和帕金森病的疾病状态，并引入了共嵌入技术以有效整合边功能连接。&lt;h4&gt;背景&lt;/h4&gt;目前研究通常使用图神经网络（GNNs）从基于节点的脑连接矩阵中推断临床诊断，但近期神经科学研究表明，这种基于节点的连接无法准确捕捉大脑中的功能连接。&lt;h4&gt;目的&lt;/h4&gt;为了提高对严重神经退行性疾病的早期诊断能力。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法强调边功能连接（eFC），并引入了共嵌入技术来有效整合边功能连接。&lt;h4&gt;主要发现&lt;/h4&gt;在ADNI和PPMI数据集上的实验结果表明，该方法在分类功能脑网络方面显著优于最先进的GNN方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够更准确地预测严重神经退行性疾病的疾病状态，为早期诊断提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Predicting disease states from functional brain connectivity is critical for the early diagnosis of severe neurodegenerative diseases such as Alzheimer's Disease and Parkinson's Disease. Existing studies commonly employ Graph Neural Networks (GNNs) to infer clinical diagnoses from node-based brain connectivity matrices generated through node-to-node similarities of regionally averaged fMRI signals. However, recent neuroscience studies found that such node-based connectivity does not accurately capture "functional connections" within the brain. This paper proposes a novel approach to brain network analysis that emphasizes edge functional connectivity (eFC), shifting the focus to inter-edge relationships. Additionally, we introduce a co-embedding technique to integrate edge functional connections effectively. Experimental results on the ADNI and PPMI datasets demonstrate that our method significantly outperforms state-of-the-art GNN methods in classifying functional brain networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting disease states from functional brain connectivity is critical forthe early diagnosis of severe neurodegenerative diseases such as Alzheimer'sDisease and Parkinson's Disease. Existing studies commonly employ Graph NeuralNetworks (GNNs) to infer clinical diagnoses from node-based brain connectivitymatrices generated through node-to-node similarities of regionally averagedfMRI signals. However, recent neuroscience studies found that such node-basedconnectivity does not accurately capture ``functional connections" within thebrain. This paper proposes a novel approach to brain network analysis thatemphasizes edge functional connectivity (eFC), shifting the focus to inter-edgerelationships. Additionally, we introduce a co-embedding technique to integrateedge functional connections effectively. Experimental results on the ADNI andPPMI datasets demonstrate that our method significantly outperformsstate-of-the-art GNN methods in classifying functional brain networks.</description>
      <author>example@mail.com (David Yang, Mostafa Abdelmegeed, John Modl, Minjeong Kim)</author>
      <guid isPermaLink="false">2504.14796v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>The 1st EReL@MIR Workshop on Efficient Representation Learning for Multimodal Information Retrieval</title>
      <link>http://arxiv.org/abs/2504.14788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WWW2025 Workshop Summary&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;多模态表示学习受到广泛关注，大型预训练多模态基础模型在信息检索任务中表现优异，但同时也带来了效率挑战。&lt;h4&gt;背景&lt;/h4&gt;多模态表示学习在人工智能领域受到重视，大型的预训练多模态基础模型如LLaMA、GPT、Mistral和CLIP在信息检索任务中取得了显著成绩。&lt;h4&gt;目的&lt;/h4&gt;为了解决大型基础模型在训练、部署和推理阶段的效率问题，提出组织首次EREL@MIR研讨会，探讨新解决方案和问题。&lt;h4&gt;方法&lt;/h4&gt;在Web Conference 2025上组织EREL@MIR研讨会，邀请参与者讨论新解决方案、问题、挑战、效率评估指标和基准。&lt;h4&gt;主要发现&lt;/h4&gt;大型基础模型在信息检索任务中的代表学习存在效率挑战，需要进一步的研究和改进。&lt;h4&gt;结论&lt;/h4&gt;研讨会旨在为学术界和工业界研究者提供一个平台，共同推动高效和有效的多模态信息检索表示学习。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal representation learning has garnered significant attention in the AI community, largely due to the success of large pre-trained multimodal foundation models like LLaMA, GPT, Mistral, and CLIP. These models have achieved remarkable performance across various tasks of multimodal information retrieval (MIR), including web search, cross-modal retrieval, and recommenders systems, etc. However, due to their enormous parameter sizes, significant efficiency challenges emerge across training, deployment, and inference stages when adapting these models' representation for IR tasks. These challenges present substantial obstacles to the practical adaptation of foundation models for representation learning in information retrieval tasks. To address these pressing issues, we propose organizing the first EReL@MIR workshop at the Web Conference 2025, inviting participants to explore novel solutions, emerging problems, challenges, efficiency evaluation metrics and benchmarks. This workshop aims to provide a platform for both academic and industry researchers to engage in discussions, share insights, and foster collaboration toward achieving efficient and effective representation learning for multimodal information retrieval in the era of large foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation learning has garnered significant attention in theAI community, largely due to the success of large pre-trained multimodalfoundation models like LLaMA, GPT, Mistral, and CLIP. These models haveachieved remarkable performance across various tasks of multimodal informationretrieval (MIR), including web search, cross-modal retrieval, and recommendersystems, etc. However, due to their enormous parameter sizes, significantefficiency challenges emerge across training, deployment, and inference stageswhen adapting these models' representation for IR tasks. These challengespresent substantial obstacles to the practical adaptation of foundation modelsfor representation learning in information retrieval tasks.  To address these pressing issues, we propose organizing the first EReL@MIRworkshop at the Web Conference 2025, inviting participants to explore novelsolutions, emerging problems, challenges, efficiency evaluation metrics andbenchmarks. This workshop aims to provide a platform for both academic andindustry researchers to engage in discussions, share insights, and fostercollaboration toward achieving efficient and effective representation learningfor multimodal information retrieval in the era of large foundation models.</description>
      <author>example@mail.com (Junchen Fu, Xuri Ge, Xin Xin, Haitao Yu, Yue Feng, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M. Jose)</author>
      <guid isPermaLink="false">2504.14788v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Vision-Centric Representation-Efficient Fine-Tuning for Robust Universal Foreground Segmentation</title>
      <link>http://arxiv.org/abs/2504.14481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种轻量级的参数高效微调框架LSR-ST，用于提高视觉基础模型的鲁棒性，特别适用于纹理稀疏的环境。&lt;h4&gt;背景&lt;/h4&gt;当前视觉基础模型在复杂场景下（如伪装和红外图像）的参数高效微调往往失败，原因在于模型内在的纹理偏差在微调过程中加剧，限制了泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为LSR-ST的框架，通过引入形状偏差归纳先验来增强模型的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;LSR-ST使用简单的HDConv块捕获形状感知特征，该块结合了大核注意力机制和残差学习。该方法满足了引起形状偏差的三个关键条件：大感受野、多阶特征交互和稀疏连接。&lt;h4&gt;主要发现&lt;/h4&gt;通过信息瓶颈理论，发现这些改进来源于表示效率，即在不增加冗余的情况下提取与任务相关的结构化特征的能力。&lt;h4&gt;结论&lt;/h4&gt;与传统的NLP范式不同，视觉任务需要模型提取任务定义的语义，而不是仅仅依赖预编码的特征。LSR-ST在SAM2-UNet上进行微调，在17个数据集和6个任务上实现了一致的改进，使用了仅4.719M个可训练参数，突出了表示效率在复杂视觉环境中的鲁棒和适应性强的基础模型的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：前景分割对于场景理解至关重要，然而在复杂场景，如伪装和红外图像中，视觉基础模型（VFMs）的参数高效微调（PEFT）往往失败。我们把这个挑战归因于VFMs固有的纹理偏差，这种偏差在微调过程中加剧，限制了在纹理稀疏环境中的泛化。为了解决这个问题，我们提出了Ladder Shape-bias Representation Side-tuning（LSR-ST），一个轻量级的PEFT框架，通过引入形状偏差归纳先验来增强模型的鲁棒性。LSR-ST使用一个简单的HDConv块捕获形状感知特征，该块结合了大核注意力和残差学习。该方法满足了引起形状偏差的三个关键条件：大感受野、多阶特征交互和稀疏连接。我们的分析揭示，这些改进来源于表示效率——在最小化冗余的同时提取与任务相关的结构化特征的能力。我们通过信息瓶颈理论形式化这个概念，并倡导将其作为关键PEFT目标。与传统的NLP范式不同，视觉任务需要模型提取任务定义的语义，而不是仅仅依赖预编码的特征。这种转变使得我们的方法能够超越传统的权衡，为视觉任务提供更鲁棒和更通用的解决方案。LSR-ST对SAM2-UNet进行了最小化修改，在17个数据集和6个任务上仅使用4.719M个可训练参数实现了一致的改进。这些结果突出了在复杂视觉环境中，表示效率对鲁棒和自适应VFMs的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foreground segmentation is crucial for scene understanding, yetparameter-efficient fine-tuning (PEFT) of vision foundation models (VFMs) oftenfails in complex scenarios, such as camouflage and infrared imagery. Weattribute this challenge to the inherent texture bias in VFMs, which isexacerbated during fine-tuning and limits generalization in texture-sparseenvironments. To address this, we propose Ladder Shape-bias RepresentationSide-tuning (LSR-ST), a lightweight PEFT framework that enhances modelrobustness by introducing shape-biased inductive priors. LSR-ST capturesshape-aware features using a simple HDConv Block, which integrates large-kernelattention and residual learning. The method satisfies three key conditions forinducing shape bias: large receptive fields, multi-order feature interactions,and sparse connectivity. Our analysis reveals that these improvements stem fromrepresentation efficiency-the ability to extract task-relevant, structurallygrounded features while minimizing redundancy. We formalize this concept viaInformation Bottleneck theory and advocate for it as a key PEFT objective.Unlike traditional NLP paradigms that focus on optimizing parameters andmemory, visual tasks require models that extract task-defined semantics, ratherthan just relying on pre-encoded features. This shift enables our approach tomove beyond conventional trade-offs, offering more robust and generalizablesolutions for vision tasks. With minimal changes to SAM2-UNet, LSR-ST achievesconsistent improvements across 17 datasets and 6 tasks using only 4.719Mtrainable parameters. These results highlight the potential of representationefficiency for robust and adaptable VFMs within complex visual environments.</description>
      <author>example@mail.com (Guoyi Zhang, Siyang Chen, Guangsheng Xu, Han Wang, Xiaohu Zhang)</author>
      <guid isPermaLink="false">2504.14481v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>AltGDmin: Alternating GD and Minimization for Partly-Decoupled (Federated) Optimization</title>
      <link>http://arxiv.org/abs/2504.14741v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in Foundations and Trends in Optimization (NOW publishers)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文描述了一种名为交替梯度下降（AltGDmin）的新优化解决方案框架，适用于许多适用于交替最小化（AltMin）的优化问题。&lt;h4&gt;背景&lt;/h4&gt;AltMin是块坐标下降算法的特殊情况，适用于最小化关于一个变量子集的问题，同时保持其他变量固定，且这些问题的最小化是闭式或可靠解决的。&lt;h4&gt;目的&lt;/h4&gt;AltGDmin旨在为那些通过AltMin解决的问题提供一种更快的解决方案。&lt;h4&gt;方法&lt;/h4&gt;AltGDmin框架通过将优化变量Z分为两个块/子集Za和Zb，并交替优化这些块来实现。这种方法在Zb上的最小化比Za快，并且成本函数对Za是可微的。&lt;h4&gt;主要发现&lt;/h4&gt;AltGDmin在以下情况下通常比AltMin更快：Zb上的最小化比Za快得多，且成本函数对Za是可微的。这种方法的快速性通常是因为问题对于Zb是解耦的，且每个解耦问题都易于解决。&lt;h4&gt;结论&lt;/h4&gt;AltGDmin在联邦设置中通信效率高，适用于多种问题，如低秩列压缩感知、低秩矩阵补全、鲁棒PCA、相干重建、张量扩展和部分离散问题。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为交替梯度下降（AltGDmin）的新型优化解决方案框架，适用于许多适用于交替最小化（AltMin）的优化问题。AltMin是块坐标下降算法的一种特殊情况，适用于最小化关于一个变量子集的问题，同时保持其他变量固定，且这些问题的最小化是闭式或可靠解决的。将优化变量Z分为两个块/子集Za和Zb，AltGDmin通过交替优化这些块来实现。这种方法在Zb上的最小化比Za快得多，且成本函数对Za是可微的。在以下情况下，AltGDmin通常比AltMin更快：Zb上的最小化比Za快得多，且成本函数对Za是可微的。这种方法的快速性通常是因为问题对于Zb是解耦的，且每个解耦问题都易于解决。AltGDmin在联邦设置中通信效率高，适用于多种问题，如低秩列压缩感知、低秩矩阵补全、鲁棒PCA、相干重建、张量扩展和部分离散问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This article describes a novel optimization solution framework, calledalternating gradient descent (GD) and minimization (AltGDmin), that is usefulfor many problems for which alternating minimization (AltMin) is a popularsolution. AltMin is a special case of the block coordinate descent algorithmthat is useful for problems in which minimization w.r.t one subset of variableskeeping the other fixed is closed form or otherwise reliably solved. Denote thetwo blocks/subsets of the optimization variables Z by Za, Zb, i.e., Z = {Za,Zb}. AltGDmin is often a faster solution than AltMin for any problem for which(i) the minimization over one set of variables, Zb, is much quicker than thatover the other set, Za; and (ii) the cost function is differentiable w.r.t. Za.Often, the reason for one minimization to be quicker is that the problem is``decoupled" for Zb and each of the decoupled problems is quick to solve. Thisdecoupling is also what makes AltGDmin communication-efficient for federatedsettings.  Important examples where this assumption holds include (a) low rankcolumn-wise compressive sensing (LRCS), low rank matrix completion (LRMC), (b)their outlier-corrupted extensions such as robust PCA, robust LRCS and robustLRMC; (c) phase retrieval and its sparse and low-rank model based extensions;(d) tensor extensions of many of these problems such as tensor LRCS and tensorcompletion; and (e) many partly discrete problems where GD does not apply --such as clustering, unlabeled sensing, and mixed linear regression. LRCS findsimportant applications in multi-task representation learning and few shotlearning, federated sketching, and accelerated dynamic MRI. LRMC and robust PCAfind important applications in recommender systems, computer vision and videoanalytics.</description>
      <author>example@mail.com (Namrata Vaswani)</author>
      <guid isPermaLink="false">2504.14741v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>OmniV-Med: Scaling Medical Vision-Language Model for Universal Visual Understanding</title>
      <link>http://arxiv.org/abs/2504.14692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为OmniV-Med的统一框架，用于多模态医学理解，旨在解决现有模型在处理文本数据和多种视觉模态（如2D/3D图像和视频）时的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的医学视觉-语言模型（Med-VLMs）通常使用不同的编码器处理不同的模态，这限制了它们在实际部署中的无缝集成。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够统一处理文本数据和多种视觉模态的医学理解框架。&lt;h4&gt;方法&lt;/h4&gt;1. 构建了一个包含252K个指导样本的OmniV-Med-Instruct多模态医学数据集，涵盖14种医学图像模态和11个临床任务。2. 设计了一个旋转位置自适应编码器，能够在统一架构中处理多分辨率2D/3D图像和视频。3. 引入了一种医学感知的token剪枝机制，利用体积数据（如连续的CT切片）和医学视频的空间-时间冗余，有效减少了60%的视觉token，而不会降低性能。&lt;h4&gt;主要发现&lt;/h4&gt;OmniV-Med-7B在涵盖2D/3D医学成像和视频理解任务的7个基准测试中实现了最先进的性能。其轻量级版本（OmniV-Med-1.5B）在训练时仅需要8个RTX3090 GPU，同时支持高效的长时间视频推理。&lt;h4&gt;结论&lt;/h4&gt;OmniV-Med框架能够有效地整合文本数据和多种视觉模态，为医学视觉-语言模型在实际应用中提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;The practical deployment of medical vision-language models (Med-VLMs) necessitates seamless integration of textual data with diverse visual modalities, including 2D/3D images and videos, yet existing models typically employ separate encoders for different modalities. To address this limitation, we present OmniV-Med, a unified framework for multimodal medical understanding. Our technical contributions are threefold: First, we construct OmniV-Med-Instruct, a comprehensive multimodal medical dataset containing 252K instructional samples spanning 14 medical image modalities and 11 clinical tasks. Second, we devise a rotary position-adaptive encoder that processes multi-resolution 2D/3D images and videos within a unified architecture, diverging from conventional modality-specific encoders. Third, we introduce a medical-aware token pruning mechanism that exploits spatial-temporal redundancy in volumetric data (e.g., consecutive CT slices) and medical videos, effectively reducing 60% of visual tokens without performance degradation. Empirical evaluations demonstrate that OmniV-Med-7B achieves state-of-the-art performance on 7 benchmarks spanning 2D/3D medical imaging and video understanding tasks. Notably, our lightweight variant (OmniV-Med-1.5B) attains comparable performance while requiring only 8 RTX3090 GPUs for training and supporting efficient long-video inference. Data, code and model will be released.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The practical deployment of medical vision-language models (Med-VLMs)necessitates seamless integration of textual data with diverse visualmodalities, including 2D/3D images and videos, yet existing models typicallyemploy separate encoders for different modalities. To address this limitation,we present OmniV-Med, a unified framework for multimodal medical understanding.Our technical contributions are threefold: First, we constructOmniV-Med-Instruct, a comprehensive multimodal medical dataset containing 252Kinstructional samples spanning 14 medical image modalities and 11 clinicaltasks. Second, we devise a rotary position-adaptive encoder that processesmulti-resolution 2D/3D images and videos within a unified architecture,diverging from conventional modality-specific encoders. Third, we introduce amedical-aware token pruning mechanism that exploits spatial-temporal redundancyin volumetric data (e.g., consecutive CT slices) and medical videos,effectively reducing 60\% of visual tokens without performance degradation.Empirical evaluations demonstrate that OmniV-Med-7B achieves state-of-the-artperformance on 7 benchmarks spanning 2D/3D medical imaging and videounderstanding tasks. Notably, our lightweight variant (OmniV-Med-1.5B) attainscomparable performance while requiring only 8 RTX3090 GPUs for training andsupporting efficient long-video inference. Data, code and model will bereleased.</description>
      <author>example@mail.com (Songtao Jiang, Yuan Wang, Sibo Song, Yan Zhang, Zijie Meng, Bohan Lei, Jian Wu, Jimeng Sun, Zuozhu Liu)</author>
      <guid isPermaLink="false">2504.14692v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>PIV-FlowDiffuser:Transfer-learning-based denoising diffusion models for PIV</title>
      <link>http://arxiv.org/abs/2504.14952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了基于深度学习的粒子图像测速（PIV）的降噪扩散模型（PIV-FlowDiffuser），通过迁移学习策略提高了模型的性能。&lt;h4&gt;背景&lt;/h4&gt;深度学习算法在降低PIV的计算时间并提高其空间分辨率方面取得了显著成效，但基于合成数据集训练的模型在实际粒子图像上可能存在性能下降的问题。&lt;h4&gt;目的&lt;/h4&gt;减少PIV分析中的特殊噪声，提高模型的性能。&lt;h4&gt;方法&lt;/h4&gt;使用FlowDiffuser模型进行降噪，并通过迁移学习策略进行训练，包括：(1) 使用多个视觉光流数据集对FlowDiffuser模型进行预训练，如Sintel、KITTI等；(2) 在合成PIV数据集上微调预训练模型。将PIV图像上采样两倍以解决小尺度湍流结构。&lt;h4&gt;主要发现&lt;/h4&gt;PIV-FlowDiffuser有效抑制了噪声模式，将经典Cai数据集上RAFT256-PIV的末端误差（AEE）降低了59.4%。PIV-FlowDiffuser在未见过的粒子图像上表现出增强的泛化性能。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了基于迁移学习的降噪扩散模型在PIV中的应用，并推荐读者查阅相关实现代码。&lt;h4&gt;翻译&lt;/h4&gt;This research proposes a denoising diffusion model (PIV-FlowDiffuser) for particle image velocimetry (PIV) based on deep learning, which improves the model's performance through transfer learning strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhu-qianyu/piv-flowdiffuser&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning algorithms have significantly reduced the computational timeand improved the spatial resolution of particle image velocimetry~(PIV).However, the models trained on synthetic datasets might have a degradedperformance on practical particle images due to domain gaps. As a result,special residual patterns are often observed for the vector fields of deeplearning-based estimators. To reduce the special noise step-by-step, we employa denoising diffusion model~(FlowDiffuser) for PIV analysis. And thedata-hungry iterative denoising diffusion model is trained via a transferlearning strategy, resulting in our PIV-FlowDiffuser method. Specifically, (1)pre-training a FlowDiffuser model with multiple optical flow datasets of thecomputer vision community, such as Sintel, KITTI, etc; (2) fine-tuning thepre-trained model on synthetic PIV datasets. Note that the PIV images areupsampled by a factor of two to resolve the small-scale turbulent flowstructures. The visualized results indicate that our PIV-FlowDiffusereffectively suppresses the noise patterns. Therefore, the denoising diffusionmodel reduces the average end-point error~($AEE$) by 59.4% over RAFT256-PIVbaseline on the classic Cai's dataset. Besides, PIV-FlowDiffuser exhibitsenhanced generalization performance on unseen particle images due to transferlearning. Overall, this study highlights the transfer-learning-based denoisingdiffusion models for PIV. And a detailed implementation is recommended forinterested readers in the repositoryhttps://github.com/Zhu-Qianyu/PIV-FlowDiffuser.</description>
      <author>example@mail.com (Qianyu Zhu, Junjie Wang, Jeremiah Hu, Jia Ai, Yong Lee)</author>
      <guid isPermaLink="false">2504.14952v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>An Iterative Task-Driven Framework for Resilient LiDAR Place Recognition in Adverse Weather</title>
      <link>http://arxiv.org/abs/2504.14806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ITDNet的迭代任务驱动框架，用于在恶劣天气条件下提高激光雷达位置识别（LPR）的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的LPR方法在雨、雪、雾等恶劣天气条件下难以保持鲁棒性，因为天气引起的噪声和点云退化影响了激光雷达的可靠性和感知精度。&lt;h4&gt;目的&lt;/h4&gt;提出ITDNet框架的目的是为了解决恶劣天气条件下LPR方法的鲁棒性问题。&lt;h4&gt;方法&lt;/h4&gt;ITDNet框架通过迭代学习策略，集成了激光雷达数据恢复（LDR）模块和激光雷达位置识别（LPR）模块。这些模块通过端到端联合训练和交替优化来提高性能。ITDNet利用LDR模块恢复损坏的点云，同时保持与清洁数据的结构一致性，从而提高恶劣天气下的LPR准确性。LPR任务提供特征伪标签以指导LDR模块的训练，使其更有效地与LPR任务对齐。为了实现这一目标，设计了一个任务驱动的LPR损失和重建损失来共同监督LDR模块的优化。此外，对于LDR模块，提出了双域混合（DDM）块进行频率-空间特征融合和语义感知生成（SAG）块进行语义引导的恢复。对于LPR模块，引入了多频率变换器（MFT）块和小波金字塔NetVLAD（WPN）块来聚合多尺度、鲁棒的全球描述符。&lt;h4&gt;主要发现&lt;/h4&gt;在Weather-KITTI、Boreas和提出的Weather-Apollo数据集上的大量实验表明，ITDNet优于现有的LPR方法，在恶劣天气条件下实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;ITDNet框架通过其创新的方法在恶劣天气条件下显著提高了LPR的准确性，其数据和代码将在GitHub上公开提供。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR位置识别（LPR）在自主导航中起着至关重要的作用。然而，现有的LPR方法在雨、雪、雾等恶劣天气条件下难以保持鲁棒性，其中天气引起的噪声和点云退化损害了激光雷达的可靠性和感知精度。为了应对这些挑战，我们提出了一种迭代任务驱动框架（ITDNet），该框架通过迭代学习策略集成了激光雷达数据恢复（LDR）模块和激光雷达位置识别（LPR）模块。这些模块通过端到端联合训练和交替优化来增强性能。ITDNet的核心原理是利用LDR模块恢复损坏的点云，同时保持与清洁数据的结构一致性，从而提高恶劣天气下的LPR准确性。同时，LPR任务提供特征伪标签以指导LDR模块的训练，使其更有效地与LPR任务对齐。为了实现这一目标，我们首先设计了一个任务驱动的LPR损失和重建损失来共同监督LDR模块的优化。此外，对于LDR模块，我们提出了一个双域混合（DDM）块进行频率-空间特征融合和一个语义感知生成（SAG）块进行语义引导的恢复。对于LPR模块，我们引入了一个多频率变换器（MFT）块和小波金字塔NetVLAD（WPN）块来聚合多尺度、鲁棒的全球描述符。最后，在Weather-KITTI、Boreas和我们提出的Weather-Apollo数据集上的大量实验表明，ITDNet优于现有的LPR方法，在恶劣天气条件下实现了最先进的性能。数据集和代码将在https://github.com/Grandzxw/ITDNet上公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR place recognition (LPR) plays a vital role in autonomous navigation.However, existing LPR methods struggle to maintain robustness under adverseweather conditions such as rain, snow, and fog, where weather-induced noise andpoint cloud degradation impair LiDAR reliability and perception accuracy. Totackle these challenges, we propose an Iterative Task-Driven Framework(ITDNet), which integrates a LiDAR Data Restoration (LDR) module and a LiDARPlace Recognition (LPR) module through an iterative learning strategy. Thesemodules are jointly trained end-to-end, with alternating optimization toenhance performance. The core rationale of ITDNet is to leverage the LDR moduleto recover the corrupted point clouds while preserving structural consistencywith clean data, thereby improving LPR accuracy in adverse weather.Simultaneously, the LPR task provides feature pseudo-labels to guide the LDRmodule's training, aligning it more effectively with the LPR task. To achievethis, we first design a task-driven LPR loss and a reconstruction loss tojointly supervise the optimization of the LDR module. Furthermore, for the LDRmodule, we propose a Dual-Domain Mixer (DDM) block for frequency-spatialfeature fusion and a Semantic-Aware Generator (SAG) block for semantic-guidedrestoration. In addition, for the LPR module, we introduce a Multi-FrequencyTransformer (MFT) block and a Wavelet Pyramid NetVLAD (WPN) block to aggregatemulti-scale, robust global descriptors. Finally, extensive experiments on theWeather-KITTI, Boreas, and our proposed Weather-Apollo datasets demonstratethat, demonstrate that ITDNet outperforms existing LPR methods, achievingstate-of-the-art performance in adverse weather. The datasets and code will bemade publicly available at https://github.com/Grandzxw/ITDNet.</description>
      <author>example@mail.com (Xiongwei Zhao, Yang Wang, Qihao Sun, Haojie Bai, Xingxiang Xie)</author>
      <guid isPermaLink="false">2504.14806v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Safety Co-Option and Compromised National Security: The Self-Fulfilling Prophecy of Weakened AI Risk Thresholds</title>
      <link>http://arxiv.org/abs/2504.15088v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了风险阈值在技术系统安全评估中的作用，指出目前全球治理尚未就AI系统的适当风险容忍度达成共识，导致AI技术专家通过“安全修正主义”替代传统安全方法，以加速军事AI应用的采用，从而降低安全标准。&lt;h4&gt;背景&lt;/h4&gt;冷战时期，风险分析如核系统分析确立了社会可接受的风险阈值，这些阈值现在是评估安全关键和防御系统的标准。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探讨AI风险阈值的重要性以及当前AI风险评估方法可能带来的风险。&lt;h4&gt;方法&lt;/h4&gt;本文通过案例分析，展示了AI技术专家如何通过替代传统安全方法来推进军事AI的快速发展。&lt;h4&gt;主要发现&lt;/h4&gt;AI技术专家倾向于通过“安全修正主义”来加速军事AI的采用，这可能降低安全标准，损害国家安全利益。&lt;h4&gt;结论&lt;/h4&gt;开发基于AI的军事系统评估框架时，必须保持与既定风险阈值的对齐，并确保美国关键和防御基础设施的安全，同时遵守国际人道法。&lt;h4&gt;翻译&lt;/h4&gt;Risk thresholds provide a measure of the level of risk exposure that a society or individual is willing to withstand, ultimately shaping how we determine the safety of technological systems. Against the backdrop of the Cold War, the first risk analyses, such as those devised for nuclear systems, cemented societally accepted risk thresholds against which safety-critical and defense systems are now evaluated. But today, the appropriate risk tolerances for AI systems have yet to be agreed on by global governing efforts, despite the need for democratic deliberation regarding the acceptable levels of harm to human life. Absent such AI risk thresholds, AI technologists—primarily industry labs, as well as “AI safety” focused organizations—have instead advocated for risk tolerances skewed by a purported AI arms race and speculative “existential” risks, taking over the arbitration of risk determinations with life-or-death consequences, subverting democratic processes. In this paper, we demonstrate how such approaches have allowed AI technologists to engage in “safety revisionism,” substituting traditional safety methods and terminology with ill-defined alternatives that vie for the accelerated adoption of military AI uses at the cost of lowered safety and security thresholds. We explore how the current trajectory for AI risk determination and evaluation for foundation model use within national security is poised for a race to the bottom, to the detriment of the US's national security interests. Safety-critical and defense systems must comply with assurance frameworks that are aligned with established risk thresholds, and foundation models are no exception. As such, development of evaluation frameworks for AI-based military systems must preserve the safety and security of US critical and defense infrastructure, and remain in alignment with international humanitarian law.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Risk thresholds provide a measure of the level of risk exposure that asociety or individual is willing to withstand, ultimately shaping how wedetermine the safety of technological systems. Against the backdrop of the ColdWar, the first risk analyses, such as those devised for nuclear systems,cemented societally accepted risk thresholds against which safety-critical anddefense systems are now evaluated. But today, the appropriate risk tolerancesfor AI systems have yet to be agreed on by global governing efforts, despitethe need for democratic deliberation regarding the acceptable levels of harm tohuman life. Absent such AI risk thresholds, AI technologists-primarily industrylabs, as well as "AI safety" focused organizations-have instead advocated forrisk tolerances skewed by a purported AI arms race and speculative"existential" risks, taking over the arbitration of risk determinations withlife-or-death consequences, subverting democratic processes.  In this paper, we demonstrate how such approaches have allowed AItechnologists to engage in "safety revisionism," substituting traditionalsafety methods and terminology with ill-defined alternatives that vie for theaccelerated adoption of military AI uses at the cost of lowered safety andsecurity thresholds. We explore how the current trajectory for AI riskdetermination and evaluation for foundation model use within national securityis poised for a race to the bottom, to the detriment of the US's nationalsecurity interests. Safety-critical and defense systems must comply withassurance frameworks that are aligned with established risk thresholds, andfoundation models are no exception. As such, development of evaluationframeworks for AI-based military systems must preserve the safety and securityof US critical and defense infrastructure, and remain in alignment withinternational humanitarian law.</description>
      <author>example@mail.com (Heidy Khlaaf, Sarah Myers West)</author>
      <guid isPermaLink="false">2504.15088v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>DConAD: A Differencing-based Contrastive Representation Learning Framework for Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.14204v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于差分对比表示学习框架的时间序列异常检测方法（DConAD），用于增强模型捕获时间序列正常模式的能力，并避免对高质量先验知识的依赖所引起的建模能力退化。&lt;h4&gt;背景&lt;/h4&gt;时间序列异常检测在风险识别和故障检测中具有重要价值。无监督学习方法因其无需标签而受到青睐，但面对多种异常模式、异常数据的稀疏性以及数据规模和复杂性的增长，这些方法往往难以捕捉时间序列中的鲁棒和代表性依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提出DConAD方法以增强模型对时间序列正常模式的捕获能力，并避免建模能力的退化。&lt;h4&gt;方法&lt;/h4&gt;DConAD通过生成差分数据提供关于时间序列的额外信息，并利用基于transformer的架构来捕捉时空依赖关系，从而增强无偏表示学习能力的鲁棒性。此外，DConAD采用了一种基于KL散度的对比学习范式，仅使用正样本以避免重建偏差，并部署停止梯度策略以促进收敛。&lt;h4&gt;主要发现&lt;/h4&gt;在五个公开数据集上的广泛实验表明，DConAD与九个基线相比表现出优越性和有效性。&lt;h4&gt;结论&lt;/h4&gt;DConAD方法在时间序列异常检测方面具有优越性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;Time series anomaly detection holds notable importance for risk identification and fault detection across diverse application domains. Unsupervised learning methods have become popular because they have no requirement for labels. However, due to the challenges posed by the multiplicity of abnormal patterns, the sparsity of anomalies, and the growth of data scale and complexity, these methods often fail to capture robust and representative dependencies within the time series for identifying anomalies. To enhance the ability of models to capture normal patterns of time series and avoid the retrogression of modeling ability triggered by the dependencies on high-quality prior knowledge, we propose a differencing-based contrastive representation learning framework for time series anomaly detection (DConAD). Specifically, DConAD generates differential data to provide additional information about time series and utilizes transformer-based architecture to capture spatiotemporal dependencies, which enhances the robustness of unbiased representation learning ability. Furthermore, DConAD implements a novel KL divergence-based contrastive learning paradigm that only uses positive samples to avoid deviation from reconstruction and deploys the stop-gradient strategy to compel convergence. Extensive experiments on five public datasets show the superiority and effectiveness of DConAD compared with nine baselines. The code is available at https://github.com/shaieesss/DConAD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series anomaly detection holds notable importance for riskidentification and fault detection across diverse application domains.Unsupervised learning methods have become popular because they have norequirement for labels. However, due to the challenges posed by themultiplicity of abnormal patterns, the sparsity of anomalies, and the growth ofdata scale and complexity, these methods often fail to capture robust andrepresentative dependencies within the time series for identifying anomalies.To enhance the ability of models to capture normal patterns of time series andavoid the retrogression of modeling ability triggered by the dependencies onhigh-quality prior knowledge, we propose a differencing-based contrastiverepresentation learning framework for time series anomaly detection (DConAD).Specifically, DConAD generates differential data to provide additionalinformation about time series and utilizes transformer-based architecture tocapture spatiotemporal dependencies, which enhances the robustness of unbiasedrepresentation learning ability. Furthermore, DConAD implements a novel KLdivergence-based contrastive learning paradigm that only uses positive samplesto avoid deviation from reconstruction and deploys the stop-gradient strategyto compel convergence. Extensive experiments on five public datasets show thesuperiority and effectiveness of DConAD compared with nine baselines. The codeis available at https://github.com/shaieesss/DConAD.</description>
      <author>example@mail.com (Wenxin Zhang, Xiaojian Lin, Wenjun Yu, Guangzhen Yao, jingxiang Zhong, Yu Li, Renda Han, Songcheng Xu, Hao Shi, Cuicui Luo)</author>
      <guid isPermaLink="false">2504.14204v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Uncovering Issues in the Radio Access Network by Looking at the Neighbors</title>
      <link>http://arxiv.org/abs/2504.14686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的RAN上下文异常检测监控工具c-ANEMON，用于识别独立于外部移动因素的异常行为，帮助网络操作团队关注网络问题。&lt;h4&gt;背景&lt;/h4&gt;移动网络运营商管理着跨越多个无线电世代（2G-5G）的大量基站，为了处理这种复杂性，操作团队依赖监控系统，包括异常检测工具来识别意外行为。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效检测RAN中异常行为的监控工具，帮助网络操作团队专注于网络问题。&lt;h4&gt;方法&lt;/h4&gt;c-ANEMON通过分析单个基站与其局部邻域之间的关系来捕捉时空变化，从而检测独立于外部移动因素的异常。使用真实世界数据对c-ANEMON进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;GNN模型在未见过的区域中表现出良好的泛化能力，检测到的异常被手动检查并定义了几个持续时间较长的异常类别，其中45.95%的异常可能需要操作团队的干预。&lt;h4&gt;结论&lt;/h4&gt;c-ANEMON能够有效检测RAN中的异常，有助于网络操作团队专注于网络问题，并可能在一个广泛的部署区域中使用单一模型。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents c-ANEMON, a Contextual ANomaly dEtection MONitor for the RAN based on GraphNeural Networks (GNNs). Our solution captures spatio-temporal variations by analyzing the behavior of individual cells in relation to their local neighborhoods, enabling the detection of anomalies that are independent of external mobility factors. This, in turn, allows focusing on anomalies associated with network issues (e.g., misconfigurations, equipment failures). We evaluate c-ANEMON using real-world data from a large European metropolitan area (7,890 cells; 3 months). First, we show that the GNN model within our solution generalizes effectively to cells from previously unseen areas, suggesting the possibility of using a single model across extensive deployment regions. Then, we analyze the anomalies detected by c-ANEMON through manual inspection and define several categories of long-lasting anomalies (6+ hours). Notably, 45.95% of these anomalies fall into a category that is more likely to require intervention by operations teams.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile network operators (MNOs) manage Radio Access Networks (RANs) withmassive amounts of cells over multiple radio generations (2G-5G). To handlesuch complexity, operations teams rely on monitoring systems, including anomalydetection tools that identify unexpected behaviors. In this paper, we presentc-ANEMON, a Contextual ANomaly dEtection MONitor for the RAN based on GraphNeural Networks (GNNs). Our solution captures spatio-temporal variations byanalyzing the behavior of individual cells in relation to their localneighborhoods, enabling the detection of anomalies that are independent ofexternal mobility factors. This, in turn, allows focusing on anomaliesassociated with network issues (e.g., misconfigurations, equipment failures).We evaluate c-ANEMON using real-world data from a large European metropolitanarea (7,890 cells; 3 months). First, we show that the GNN model within oursolution generalizes effectively to cells from previously unseen areas,suggesting the possibility of using a single model across extensive deploymentregions. Then, we analyze the anomalies detected by c-ANEMON through manualinspection and define several categories of long-lasting anomalies (6+ hours).Notably, 45.95% of these anomalies fall into a category that is more likely torequire intervention by operations teams.</description>
      <author>example@mail.com (José Suárez-Varela, Andra Lutu)</author>
      <guid isPermaLink="false">2504.14686v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning via mechanosensitivity and activity in cytoskeletal networks</title>
      <link>http://arxiv.org/abs/2504.15107v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 9 figurs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文展示了如何通过受肌动蛋白细胞骨架粗粒度描述启发的网络，在对比学习框架中，通过赋予其机械敏感蛋白和马达，从环境扰动中学习。这项工作证明了力敏感蛋白和分子马达可以作为在生物系统中学习的一般策略的基础，并确定了最小化的生物合理学习机制，同时探讨了其在适应和稳态等常见现象中的意义。&lt;h4&gt;背景&lt;/h4&gt;本文研究的是如何利用受肌动蛋白细胞骨架启发的网络进行学习。&lt;h4&gt;目的&lt;/h4&gt;研究力敏感蛋白和分子马达在生物系统中作为学习策略的基础，并探讨其在生物现象中的应用。&lt;h4&gt;方法&lt;/h4&gt;在对比学习框架中，通过赋予网络机械敏感蛋白和马达，使其能够从环境扰动中学习。&lt;h4&gt;主要发现&lt;/h4&gt;发现了最小化的生物合理学习机制，并探讨了其在适应和稳态等常见现象中的应用。&lt;h4&gt;结论&lt;/h4&gt;力敏感蛋白和分子马达可以作为生物系统中学习的一般策略的基础，并具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we show how a network inspired by a coarse-grained description of actomyosin cytoskeleton can learn from environmental perturbations in a contrastive learning framework if it is endowed with mechanosensitive proteins and motors. Our work is a proof of principle for how force-sensitive proteins and molecular motors can form the basis of a general strategy to learn in biological systems. Our work identifies a minimal biologically plausible learning mechanism and also explores its implications for commonly occurring phenomenology such as adaptation and homeostasis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work we show how a network inspired by a coarse-grained descriptionof actomyosin cytoskeleton can learn - in a contrastive learning framework -from environmental perturbations if it is endowed with mechanosensitiveproteins and motors. Our work is a proof of principle for how force-sensitiveproteins and molecular motors can form the basis of a general strategy to learnin biological systems. Our work identifies a minimal biologically plausiblelearning mechanism and also explores its implications for commonly occuringphenomenolgy such as adaptation and homeostatis.</description>
      <author>example@mail.com (Deb S. Banerjee, Martin J. Falk, Margaret L Gardel, Aleksandra M. Walczak, Thierry Mora, Suriyanarayanan Vaikuntanathan)</author>
      <guid isPermaLink="false">2504.15107v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Matrix Factorization with Dynamic Multi-view Clustering for Recommender System</title>
      <link>http://arxiv.org/abs/2504.14565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MFDMC的矩阵分解方法，旨在解决传统推荐系统在处理大规模数据时的计算成本问题，并提高了模型的解释性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;矩阵分解是推荐系统的基础，但传统的矩阵分解方法在处理大规模应用时，如电子商务和物联网，存在计算成本高的问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种高效且通用的矩阵分解框架，以平衡高效端到端训练和充分利用大规模数据。&lt;h4&gt;方法&lt;/h4&gt;MFDMC利用动态多视图聚类学习用户和物品表示，自适应地修剪不良形成的聚类，并将每个实体的表示建模为稳健聚类的加权投影。&lt;h4&gt;主要发现&lt;/h4&gt;MFDMC在推荐系统和其他表示学习领域（如计算机视觉）中表现出优异的性能，显示出其可扩展性和多功能性。&lt;h4&gt;结论&lt;/h4&gt;MFDMC是一种高效且可解释的矩阵分解方法，适用于处理大规模推荐系统和其他领域的数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Matrix factorization (MF), a cornerstone of recommender systems, decomposesuser-item interaction matrices into latent representations. Traditional MFapproaches, however, employ a two-stage, non-end-to-end paradigm, sequentiallyperforming recommendation and clustering, resulting in prohibitivecomputational costs for large-scale applications like e-commerce and IoT, wherebillions of users interact with trillions of items. To address this, we proposeMatrix Factorization with Dynamic Multi-view Clustering (MFDMC), a unifiedframework that balances efficient end-to-end training with comprehensiveutilization of web-scale data and enhances interpretability. MFDMC leveragesdynamic multi-view clustering to learn user and item representations,adaptively pruning poorly formed clusters. Each entity's representation ismodeled as a weighted projection of robust clusters, capturing its diverseroles across views. This design maximizes representation space utilization,improves interpretability, and ensures resilience for downstream tasks.Extensive experiments demonstrate MFDMC's superior performance in recommendersystems and other representation learning domains, such as computer vision,highlighting its scalability and versatility.</description>
      <author>example@mail.com (Shangde Gao, Ke Liu, Yichao Fu, Hongxia Xu, Jian Wu)</author>
      <guid isPermaLink="false">2504.14565v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Grounding-MD: Grounded Video-language Pre-training for Open-World Moment Detection</title>
      <link>http://arxiv.org/abs/2504.14553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Grounding-MD的创新视频语言预训练框架，旨在解决开放世界情境下的动作检测和瞬间检索问题。&lt;h4&gt;背景&lt;/h4&gt;动作检测和瞬间检索是视频理解中的关键任务，而现有的方法主要针对封闭集场景，限制了它们在开放世界中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一限制，研究提出了Grounding-MD框架，用于开放世界的瞬间检测。&lt;h4&gt;方法&lt;/h4&gt;Grounding-MD通过结构化提示机制集成任意数量的开放自然语言查询，利用跨模态融合编码器和文本引导融合解码器，实现视频和文本的全面对齐，并促进跨任务的协作。&lt;h4&gt;主要发现&lt;/h4&gt;通过在大量动作检测和瞬间检索数据集上进行预训练，Grounding-MD展示了出色的语义表示学习能力，有效处理了多样化和复杂查询条件。在ActivityNet、THUMOS14、ActivityNet-Captions和Charades-STA等四个基准数据集上的综合评估表明，Grounding-MD在开放世界的瞬间检测场景中建立了新的最先进性能。&lt;h4&gt;结论&lt;/h4&gt;所有源代码和训练模型将被发布，以促进开放世界瞬间检测技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal Action Detection and Moment Retrieval constitute two pivotal tasksin video understanding, focusing on precisely localizing temporal segmentscorresponding to specific actions or events. Recent advancements introducedMoment Detection to unify these two tasks, yet existing approaches remainconfined to closed-set scenarios, limiting their applicability in open-worldcontexts. To bridge this gap, we present Grounding-MD, an innovative, groundedvideo-language pre-training framework tailored for open-world moment detection.Our framework incorporates an arbitrary number of open-ended natural languagequeries through a structured prompt mechanism, enabling flexible and scalablemoment detection. Grounding-MD leverages a Cross-Modality Fusion Encoder and aText-Guided Fusion Decoder to facilitate comprehensive video-text alignment andenable effective cross-task collaboration. Through large-scale pre-training ontemporal action detection and moment retrieval datasets, Grounding-MDdemonstrates exceptional semantic representation learning capabilities,effectively handling diverse and complex query conditions. Comprehensiveevaluations across four benchmark datasets including ActivityNet, THUMOS14,ActivityNet-Captions, and Charades-STA demonstrate that Grounding-MDestablishes new state-of-the-art performance in zero-shot and supervisedsettings in open-world moment detection scenarios. All source code and trainedmodels will be released.</description>
      <author>example@mail.com (Weijun Zhuang, Qizhang Li, Xin Li, Ming Liu, Xiaopeng Hong, Feng Gao, Fan Yang, Wangmeng Zuo)</author>
      <guid isPermaLink="false">2504.14553v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space</title>
      <link>http://arxiv.org/abs/2504.14471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于隐式神经网络表示（INR）的静态点云压缩框架PICO，该框架通过几何压缩和属性压缩两个阶段实现点云压缩，并引入了LeAFNet网络架构，提高了压缩效率。&lt;h4&gt;背景&lt;/h4&gt;隐式神经网络表示（INR），也称为神经网络场，是一种在深度学习中强大的范式，使用基于坐标的神经网络参数化连续空间场。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的点云压缩方法。&lt;h4&gt;方法&lt;/h4&gt;将点云压缩任务分解为几何压缩和属性压缩两个阶段，并使用LeAFNet网络架构，该架构利用可学习的激活函数在潜在空间中更好地逼近目标信号的隐函数。通过量化熵编码进一步提高了压缩效率。&lt;h4&gt;主要发现&lt;/h4&gt;LeAFNet在基于INR的点云压缩中优于传统的MLP，PICO在几何压缩方面优于当前的MPEG点云压缩标准，平均D1 PSNR提高了4.92 dB。在联合几何和属性压缩中，该方法表现出极具竞争力的结果，平均PCQM增益为2.7×10^-3。&lt;h4&gt;结论&lt;/h4&gt;PICO框架和LeAFNet网络架构在点云压缩中表现出优异的性能，为点云数据的高效压缩提供了一种新的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit Neural Representations (INRs), also known as neural fields, haveemerged as a powerful paradigm in deep learning, parameterizing continuousspatial fields using coordinate-based neural networks. In this paper, wepropose \textbf{PICO}, an INR-based framework for static point cloudcompression. Unlike prevailing encoder-decoder paradigms, we decompose thepoint cloud compression task into two separate stages: geometry compression andattribute compression, each with distinct INR optimization objectives. Inspiredby Kolmogorov-Arnold Networks (KANs), we introduce a novel networkarchitecture, \textbf{LeAFNet}, which leverages learnable activation functionsin the latent space to better approximate the target signal's implicitfunction. By reformulating point cloud compression as neural parametercompression, we further improve compression efficiency through quantization andentropy coding. Experimental results demonstrate that \textbf{LeAFNet}outperforms conventional MLPs in INR-based point cloud compression.Furthermore, \textbf{PICO} achieves superior geometry compression performancecompared to the current MPEG point cloud compression standard, yielding anaverage improvement of $4.92$ dB in D1 PSNR. In joint geometry and attributecompression, our approach exhibits highly competitive results, with an averagePCQM gain of $2.7 \times 10^{-3}$.</description>
      <author>example@mail.com (Yichi Zhang, Qianqian Yang)</author>
      <guid isPermaLink="false">2504.14471v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>RealisDance-DiT: Simple yet Strong Baseline towards Controllable Character Animation in the Wild</title>
      <link>http://arxiv.org/abs/2504.14977v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page:  https://thefoxofsky.github.io/project_pages_new/RealisDance-DiT/index&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的可控角色动画方法，通过模型修改和微调策略解决角色动画中的难题，并构建了RealisDance-DiT模型。&lt;h4&gt;背景&lt;/h4&gt;可控角色动画在处理罕见姿势、风格化角色、角色与物体交互、复杂光照和动态场景时具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过模型修改和灵活的微调策略，在野外环境中实现可控角色动画。&lt;h4&gt;方法&lt;/h4&gt;基于Wan-2.1视频基础模型，提出RealisDance-DiT，并对基础模型进行最小修改，引入低噪声预热和“大批次与小迭代”策略加速模型收敛。&lt;h4&gt;主要发现&lt;/h4&gt;分析显示，广泛使用的Reference Net设计对大规模DiT模型不是最优的；基础模型架构的最小修改可以产生强大的基线；新测试数据集能够捕捉多样化的真实世界挑战。&lt;h4&gt;结论&lt;/h4&gt;RealisDance-DiT在实验中优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;可控角色动画在处理罕见姿势、风格化角色、角色与物体交互、复杂光照和动态场景时仍然是一个具有挑战性的问题。为了解决这些问题，先前的工作主要集中在通过精心设计的旁路网络注入姿态和外观指导，但通常难以推广到开放世界场景。在这篇论文中，我们提出了一种新的观点，即只要基础模型足够强大，简单的模型修改和灵活的微调策略可以很大程度上解决上述挑战，向在野外环境中实现可控角色动画迈出一步。具体来说，我们引入了基于Wan-2.1视频基础模型的RealisDance-DiT。我们充分的分析表明，广泛采用的Reference Net设计对于大规模DiT模型不是最优的。相反，我们证明了基础模型架构的最小修改会产生令人惊讶的强大基线。我们进一步提出了低噪声预热和“大批次和小迭代”策略，以在微调期间加速模型收敛，同时最大限度地保留基础模型的前验信息。此外，我们引入了一个新的测试数据集，该数据集能够捕捉多样化的真实世界挑战，补充了现有的基准，如TikTok数据集和UBC时尚视频数据集，以全面评估所提出的方法。广泛的实验表明，RealisDance-DiT在性能上显著优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controllable character animation remains a challenging problem, particularlyin handling rare poses, stylized characters, character-object interactions,complex illumination, and dynamic scenes. To tackle these issues, prior workhas largely focused on injecting pose and appearance guidance via elaboratebypass networks, but often struggles to generalize to open-world scenarios. Inthis paper, we propose a new perspective that, as long as the foundation modelis powerful enough, straightforward model modifications with flexiblefine-tuning strategies can largely address the above challenges, taking a steptowards controllable character animation in the wild. Specifically, weintroduce RealisDance-DiT, built upon the Wan-2.1 video foundation model. Oursufficient analysis reveals that the widely adopted Reference Net design issuboptimal for large-scale DiT models. Instead, we demonstrate that minimalmodifications to the foundation model architecture yield a surprisingly strongbaseline. We further propose the low-noise warmup and "large batches and smalliterations" strategies to accelerate model convergence during fine-tuning whilemaximally preserving the priors of the foundation model. In addition, weintroduce a new test dataset that captures diverse real-world challenges,complementing existing benchmarks such as TikTok dataset and UBC fashion videodataset, to comprehensively evaluate the proposed method. Extensive experimentsshow that RealisDance-DiT outperforms existing methods by a large margin.</description>
      <author>example@mail.com (Jingkai Zhou, Yifan Wu, Shikai Li, Min Wei, Chao Fan, Weihua Chen, Wei Jiang, Fan Wang)</author>
      <guid isPermaLink="false">2504.14977v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Spiking Point Mamba for Point Cloud Analysis</title>
      <link>http://arxiv.org/abs/2504.14371v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Mamba的3D领域SNN（Spiking Neural Networks）模型，名为Spiking Point Mamba（SPM），旨在高效提取3D时空特征。&lt;h4&gt;背景&lt;/h4&gt;现有的3D SNN在处理长距离依赖关系方面存在困难，直到Mamba的出现，它提供了卓越的计算效率和序列建模能力。&lt;h4&gt;目的&lt;/h4&gt;设计SPM以利用Mamba的序列建模能力和SNN的时间特征提取能力，提高3D SNN的性能。&lt;h4&gt;方法&lt;/h4&gt;SPM通过引入分层动态编码（HDE）和Spiking Mamba块（SMB）来实现。HDE是一种改进的直接编码方法，有效引入动态时间机制，促进时间交互；SMB在Mamba的基础上学习跨时间步的特征，并最小化由脉冲引起的信损失。此外，采用非对称SNN-ANN架构进行脉冲预训练和微调。&lt;h4&gt;主要发现&lt;/h4&gt;SPM在ScanObjectNN的三个变体上提高了OA（平均精度）分别为+6.2%、+6.1%和+7.4%，在ShapeNetPart上提升了instance mIOU（实例交并比）+1.9%。同时，其能耗至少比其ANN（人工神经网络）对应版本低3.5倍。&lt;h4&gt;结论&lt;/h4&gt;SPM是一个高效的3D SNN模型，在保持高性能的同时，具有显著降低能耗的优势。&lt;h4&gt;翻译&lt;/h4&gt;Bio-inspired Spiking Neural Networks (SNNs) provide an energy-efficient way to extract 3D spatio-temporal features. However, existing 3D SNNs have struggled with long-range dependencies until the recent emergence of Mamba, which offers superior computational efficiency and sequence modeling capability. In this work, we propose Spiking Point Mamba (SPM), the first Mamba-based SNN in the 3D domain. Due to the poor performance of simply transferring Mamba to 3D SNNs, SPM is designed to utilize both the sequence modeling capabilities of Mamba and the temporal feature extraction of SNNs. Specifically, we first introduce Hierarchical Dynamic Encoding (HDE), an improved direct encoding method that effectively introduces dynamic temporal mechanism, thereby facilitating temporal interactions. Then, we propose a Spiking Mamba Block (SMB), which builds upon Mamba while learning inter-time-step features and minimizing information loss caused by spikes. Finally, to further enhance model performance, we adopt an asymmetric SNN-ANN architecture for spike-based pre-training and finetune. Compared with the previous state-of-the-art SNN models, SPM improves OA by +6.2%, +6.1%, and +7.4% on three variants of ScanObjectNN, and boosts instance mIOU by +1.9% on ShapeNetPart. Meanwhile, its energy consumption is at least 3.5x lower than that of its ANN counterpart. The code will be made publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bio-inspired Spiking Neural Networks (SNNs) provide an energy-efficient wayto extract 3D spatio-temporal features. However, existing 3D SNNs havestruggled with long-range dependencies until the recent emergence of Mamba,which offers superior computational efficiency and sequence modelingcapability. In this work, we propose Spiking Point Mamba (SPM), the firstMamba-based SNN in the 3D domain. Due to the poor performance of simplytransferring Mamba to 3D SNNs, SPM is designed to utilize both the sequencemodeling capabilities of Mamba and the temporal feature extraction of SNNs.Specifically, we first introduce Hierarchical Dynamic Encoding (HDE), animproved direct encoding method that effectively introduces dynamic temporalmechanism, thereby facilitating temporal interactions. Then, we propose aSpiking Mamba Block (SMB), which builds upon Mamba while learninginter-time-step features and minimizing information loss caused by spikes.Finally, to further enhance model performance, we adopt an asymmetric SNN-ANNarchitecture for spike-based pre-training and finetune. Compared with theprevious state-of-the-art SNN models, SPM improves OA by +6.2%, +6.1%, and+7.4% on three variants of ScanObjectNN, and boosts instance mIOU by +1.9% onShapeNetPart. Meanwhile, its energy consumption is at least 3.5x lower thanthat of its ANN counterpart. The code will be made publicly available.</description>
      <author>example@mail.com (Peixi Wu, Bosong Chai, Menghua Zheng, Wei Li, Zhangchi Hu, Jie Chen, Zheyu Zhang, Hebei Li, Xiaoyan Sun)</author>
      <guid isPermaLink="false">2504.14371v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Generative Semantic Communications: Principles and Practices</title>
      <link>http://arxiv.org/abs/2504.14947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了基于人工智能技术的语义通信新范式，旨在降低通信成本，并探讨了在向通用人工智能（AGI）发展的背景下，语义通信面临的新挑战及解决方案。&lt;h4&gt;背景&lt;/h4&gt;语义通信利用人工智能技术从数据中提取语义信息，以实现高效传输。随着通用人工智能（AGI）的演进，对AGI服务的需求增加，给语义通信带来了新的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的通信范式，称为生成式语义通信（GSC），以应对AGI驱动下的通信需求。&lt;h4&gt;方法&lt;/h4&gt;介绍了GSC的基本概念和与现有语义通信的区别，提出了GSC的一般框架，并通过两个案例研究验证了GSC在AGI驱动应用中的优势。&lt;h4&gt;主要发现&lt;/h4&gt;GSC利用了如基础模型和生成模型等先进的人工智能技术，能够有效降低通信成本，并在AGI驱动应用中展现出优势。&lt;h4&gt;结论&lt;/h4&gt;论文讨论了语义通信在AGI时代的开放挑战和新研究方向，以促进该领域的研究，并为实际应用铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new paradigm for semantic communication based on artificial intelligence technologies, aiming to reduce communication costs and discusses the new challenges and solutions for semantic communication in the context of the evolution towards artificial general intelligence (AGI).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic communication leverages artificial intelligence (AI) technologies toextract semantic information from data for efficient transmission, therabysignificantly reducing communication cost. With the evolution towardsartificial general intelligence (AGI), the increasing demands for AGI servicespose new challenges to semantic communication. In response, we propose a newparadigm for AGI-driven communications, called generative semanticcommunication (GSC), which utilizes advanced AI technologies such as foundationmodels and generative models. We first describe the basic concept of GSC andits difference from existing semantic communications, and then introduce ageneral framework of GSC, followed by two case studies to verify the advantagesof GSC in AGI-driven applications. Finally, open challenges and new researchdirections are discussed to stimulate this line of research and pave the wayfor practical applications.</description>
      <author>example@mail.com (Xiaojun Yuan, Haoming Ma, Yinuo Huang, Zhoufan Hua, Yong Zuo, Zhi Ding)</author>
      <guid isPermaLink="false">2504.14947v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>CSI2Dig: Recovering Digit Content from Smartphone Loudspeakers Using Channel State Information</title>
      <link>http://arxiv.org/abs/2504.14812v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为CSI2Dig的方案，用于从手机扬声器的信道状态信息（CSI）中恢复数字内容，以应对通过扬声器发出的声音被窃听所可能泄露的敏感数字信息。&lt;h4&gt;背景&lt;/h4&gt;现有的窃听方案可能需要昂贵的专用设备、依赖间谍软件，或者仅限于近距离信号采集，存在安全风险。&lt;h4&gt;目的&lt;/h4&gt;设计一种方案，能够从手机扬声器的CSI中恢复数字内容，提高数字信息的安全性。&lt;h4&gt;方法&lt;/h4&gt;该方案基于对比学习和降噪自编码器，构建了一个双分支自动编码器网络，以放大扬声器音频信号产生的电磁干扰对CSI的影响。引入了TS-Net模型，用于从CSI数据的时空维度捕捉相关特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方案在各种设备、距离、音量和其他设置下都能达到72.97%的准确率。&lt;h4&gt;结论&lt;/h4&gt;CSI2Dig方案能够有效从手机扬声器的CSI中恢复数字内容，提高数字信息的安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Eavesdropping on sounds emitted by mobile device loudspeakers can capturesensitive digital information, such as SMS verification codes, credit cardnumbers, and withdrawal passwords, which poses significant security risks.Existing schemes either require expensive specialized equipment, rely onspyware, or are limited to close-range signal acquisition. In this paper, wepropose a scheme, CSI2Dig, for recovering digit content from Channel StateInformation (CSI) when digits are played through a smartphone loudspeaker. Weobserve that the electromagnetic interference caused by the audio signals fromthe loudspeaker affects the WiFi signals emitted by the phone's WiFi antenna.Building upon contrastive learning and denoising autoencoders, we develop atwo-branch autoencoder network designed to amplify the impact of thiselectromagnetic interference on CSI. For feature extraction, we introduce theTS-Net, a model that captures relevant features from both the temporal andspatial dimensions of the CSI data. We evaluate our scheme across variousdevices, distances, volumes, and other settings. Experimental resultsdemonstrate that our scheme can achieve an accuracy of 72.97%.</description>
      <author>example@mail.com (Yangyang Gu, Xianglong Li, Haolin Wu, Jing Chen, Kun He, Ruiying Du, Cong Wu)</author>
      <guid isPermaLink="false">2504.14812v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>LBM-GNN: Graph Neural Network Enhanced Lattice Boltzmann Method</title>
      <link>http://arxiv.org/abs/2504.14494v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LBM-GNN的新方法，该方法通过结合格点Boltzmann方法（LBM）和图神经网络（GNN）来提升传统LBM的性能。&lt;h4&gt;背景&lt;/h4&gt;传统的LBM方法在流体动力学模拟中存在稳定性和精度的问题。&lt;h4&gt;目的&lt;/h4&gt;通过将GNN与LBM结合，旨在提高LBM的稳定性和精度。&lt;h4&gt;方法&lt;/h4&gt;应用LBM-GNN方法到流体动力学模拟中，并与标准LBM方法进行比较。验证方法包括使用泰勒-格林涡旋等基准问题，关注精度、守恒性质和不同雷诺数及网格分辨率下的性能。&lt;h4&gt;主要发现&lt;/h4&gt;GNN增强的LBM在更高雷诺数下能够保持更好的守恒性质，同时提高数值稳定性。&lt;h4&gt;结论&lt;/h4&gt;LBM-GNN方法在流体动力学模拟中显示出优于传统LBM方法的表现。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们提出了一种名为LBM-GNN的新方法，该方法通过结合传统的格点Boltzmann方法（LBM）与图神经网络（GNN）来提升性能。我们将此方法应用于流体动力学模拟，与标准LBM实现相比，展示了更高的稳定性和精度。该方法通过基准问题如泰勒-格林涡旋进行验证，关注精度、守恒特性和在不同雷诺数和网格分辨率下的性能。我们的结果表明，GNN增强的LBM能够在更高雷诺数下保持更好的守恒性质，同时提高数值稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present LBM-GNN, a novel approach that enhances thetraditional Lattice Boltzmann Method (LBM) with Graph Neural Networks (GNNs).We apply this method to fluid dynamics simulations, demonstrating improvedstability and accuracy compared to standard LBM implementations. The method isvalidated using benchmark problems such as the Taylor-Green vortex, focusing onaccuracy, conservation properties, and performance across different Reynoldsnumbers and grid resolutions. Our results indicate that GNN-enhanced LBM canmaintain better conservation properties while improving numerical stability athigher Reynolds numbers.</description>
      <author>example@mail.com (Yue Li)</author>
      <guid isPermaLink="false">2504.14494v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Score</title>
      <link>http://arxiv.org/abs/2504.14302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在目标标签不可用但存在相关附加信息的情况下，如何利用这些信息进行机器学习。&lt;h4&gt;背景&lt;/h4&gt;常见的机器学习设置包括监督学习、半监督学习和弱监督学习，以及无监督学习。本文关注的是无标签数据的情况。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的评分模型，用于处理无标签数据，并通过附加信息提高预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;将问题建模为包含三个语义组件的集成：表示学习、附加信息和度量学习。&lt;h4&gt;主要发现&lt;/h4&gt;该评分模型在医疗保健领域具有应用潜力，例如创建疾病严重度评分，其中已知症状但疾病进展标准不明确。&lt;h4&gt;结论&lt;/h4&gt;提出的评分系统在标准数据集和生物医学患者记录上证明了其效用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：常见的机器学习设置从可访问准确标记数据的监督任务，到目标标签稀缺或噪声的半监督和弱监督任务，再到无标签任务，其中标签无法获得。在本文中，我们研究了一种目标标签不可用但附加相关信息可用的情况。这些信息，称为侧信息，要么与未知标签相关联，要么对特征空间施加约束。我们将问题建模为三个语义组件的集成：表示学习、侧信息和学习度量。所提出的评分模型对多个用例具有优势。例如，在医疗保健领域，它可以用于创建已知症状但疾病进展标准不明确的疾病的严重度评分。我们展示了所提出的评分系统在标准数据集和生物医学患者记录上的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Common machine learning settings range from supervised tasks, whereaccurately labeled data is accessible, through semi-supervised andweakly-supervised tasks, where target labels are scant or noisy, tounsupervised tasks where labels are unobtainable. In this paper we study ascenario where the target labels are not available but additional relatedinformation is at hand. This information, referred to as Side Information, iseither correlated with the unknown labels or imposes constraints on the featurespace. We formulate the problem as an ensemble of three semantic components:representation learning, side information and metric learning. The proposedscoring model is advantageous for multiple use-cases. For example, in thehealthcare domain it can be used to create a severity score for diseases wherethe symptoms are known but the criteria for the disease progression are notwell defined. We demonstrate the utility of the suggested scoring system onwell-known benchmark data-sets and bio-medical patient records.</description>
      <author>example@mail.com (Yogev Kriger, Shai Fine)</author>
      <guid isPermaLink="false">2504.14302v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>ResNetVLLM -- Multi-modal Vision LLM for the Video Understanding Task</title>
      <link>http://arxiv.org/abs/2504.14432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ResNetVLLM（ResNet视觉LLM），这是一种新型的跨模态框架，用于零样本视频理解，它将基于ResNet的视觉编码器与大型语言模型（LLM）相结合。&lt;h4&gt;背景&lt;/h4&gt;本文旨在解决零样本视频模型面临的挑战，避免依赖预训练的视频理解模型，而是使用未预训练的ResNet提取视觉特征。&lt;h4&gt;目的&lt;/h4&gt;该设计确保模型在统一架构中学习视觉和语义表示，提高其从视频输入生成准确且与上下文相关的文本描述的能力。&lt;h4&gt;方法&lt;/h4&gt;ResNetVLLM通过结合ResNet视觉编码器和LLM，避免了依赖预训练模型，并实现了视觉和语义表示的统一学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ResNetVLLM在多个基准测试中实现了零样本视频理解（ZSVU）的最先进性能，包括MSRVTT-QA、MSVD-QA、TGIF-QA FrameQA和ActivityNet-QA。&lt;h4&gt;结论&lt;/h4&gt;ResNetVLLM在零样本视频理解领域取得了显著成果，为视频理解技术的发展提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we introduce ResNetVLLM (ResNet Vision LLM), a novel cross-modal framework for zero-shot video understanding that integrates a ResNet-based visual encoder with a Large Language Model (LLM). ResNetVLLM addresses the challenges associated with zero-shot video models by avoiding reliance on pre-trained video understanding models and instead employing an unpretrained ResNet to extract visual features. This design ensures the model learns visual and semantic representations within a unified architecture, enhancing its ability to generate accurate and contextually relevant textual descriptions from video inputs. Our experimental results demonstrate that ResNetVLLM achieves state-of-the-art performance in zero-shot video understanding (ZSVU) on several benchmarks, including MSRVTT-QA, MSVD-QA, TGIF-QA FrameQA, and ActivityNet-QA.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce ResNetVLLM (ResNet Vision LLM), a novelcross-modal framework for zero-shot video understanding that integrates aResNet-based visual encoder with a Large Language Model (LLM. ResNetVLLMaddresses the challenges associated with zero-shot video models by avoidingreliance on pre-trained video understanding models and instead employing anon-pretrained ResNet to extract visual features. This design ensures the modellearns visual and semantic representations within a unified architecture,enhancing its ability to generate accurate and contextually relevant textualdescriptions from video inputs. Our experimental results demonstrate thatResNetVLLM achieves state-of-the-art performance in zero-shot videounderstanding (ZSVU) on several benchmarks, including MSRVTT-QA, MSVD-QA,TGIF-QA FrameQA, and ActivityNet-QA.</description>
      <author>example@mail.com (Ahmad Khalil, Mahmoud Khalil, Alioune Ngom)</author>
      <guid isPermaLink="false">2504.14432v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Multispectral airborne laser scanning for tree species classification: a benchmark of machine learning and deep learning algorithms</title>
      <link>http://arxiv.org/abs/2504.14337v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过对比多种机器学习和深度学习方法在树木物种分类中的应用，探讨了高密度多光谱激光扫描数据在森林资源调查中的潜力。&lt;h4&gt;背景&lt;/h4&gt;精准的森林资源信息对于智能林业和生物多样性保护至关重要。多光谱空中激光扫描（ALS）在自动化点云处理和树木分割方面显示出潜力，但在识别稀有树种和利用深度学习技术方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;通过基准测试，评估机器学习和深度学习方法在树木物种分类中的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用FGI开发的HeliALS系统收集高密度多光谱ALS数据（&gt;1000个点/m²）和Optech Titan数据（35个点/m²），在芬兰南部的测试站点评估算法的物种分类准确率。&lt;h4&gt;主要发现&lt;/h4&gt;基于5261个测试段，点云深度学习方法，尤其是点Transformer模型，在处理高密度多光谱点云时优于传统机器学习和基于图像的深度学习方法。点Transformer模型在处理高密度ALS数据时，准确率达到87.9%（宏平均），而最佳图像深度学习方法DetailView的准确率为84.3%（宏平均），随机森林（RF）分类器的准确率为83.2%（宏平均）。&lt;h4&gt;结论&lt;/h4&gt;点Transformer模型在集成所有三个通道的光谱信息后，分类准确率从没有光谱信息的73.0%提高到单通道反射率的84.7%，最终达到87.9%。&lt;h4&gt;翻译&lt;/h4&gt;This study investigates the potential of high-density multispectral laser scanning data in forest resource surveys through a comprehensive benchmark of machine learning and deep learning methods for tree species classification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Climate-smart and biodiversity-preserving forestry demands preciseinformation on forest resources, extending to the individual tree level.Multispectral airborne laser scanning (ALS) has shown promise in automatedpoint cloud processing and tree segmentation, but challenges remain inidentifying rare tree species and leveraging deep learning techniques. Thisstudy addresses these gaps by conducting a comprehensive benchmark of machinelearning and deep learning methods for tree species classification. For thestudy, we collected high-density multispectral ALS data (&gt;1000 pts/m$^2$) atthree wavelengths using the FGI-developed HeliALS system, complemented byexisting Optech Titan data (35 pts/m$^2$), to evaluate the speciesclassification accuracy of various algorithms in a test site located inSouthern Finland. Based on 5261 test segments, our findings demonstrate thatpoint-based deep learning methods, particularly a point transformer model,outperformed traditional machine learning and image-based deep learningapproaches on high-density multispectral point clouds. For the high-density ALSdataset, a point transformer model provided the best performance reaching anoverall (macro-average) accuracy of 87.9% (74.5%) with a training set of 1065segments and 92.0% (85.1%) with 5000 training segments. The best image-baseddeep learning method, DetailView, reached an overall (macro-average) accuracyof 84.3% (63.9%), whereas a random forest (RF) classifier achieved an overall(macro-average) accuracy of 83.2% (61.3%). Importantly, the overallclassification accuracy of the point transformer model on the HeliALS dataincreased from 73.0% with no spectral information to 84.7% with single-channelreflectance, and to 87.9% with spectral information of all the three channels.</description>
      <author>example@mail.com (Josef Taher, Eric Hyyppä, Matti Hyyppä, Klaara Salolahti, Xiaowei Yu, Leena Matikainen, Antero Kukko, Matti Lehtomäki, Harri Kaartinen, Sopitta Thurachen, Paula Litkey, Ville Luoma, Markus Holopainen, Gefei Kong, Hongchao Fan, Petri Rönnholm, Antti Polvivaara, Samuli Junttila, Mikko Vastaranta, Stefano Puliti, Rasmus Astrup, Joel Kostensalo, Mari Myllymäki, Maksymilian Kulicki, Krzysztof Stereńczak, Raul de Paula Pires, Ruben Valbuena, Juan Pedro Carbonell-Rivera, Jesús Torralba, Yi-Chen Chen, Lukas Winiwarter, Markus Hollaus, Gottfried Mandlburger, Narges Takhtkeshha, Fabio Remondino, Maciej Lisiewicz, Bartłomiej Kraszewski, Xinlian Liang, Jianchang Chen, Eero Ahokas, Kirsi Karila, Eugeniu Vezeteu, Petri Manninen, Roope Näsi, Heikki Hyyti, Siiri Pyykkönen, Peilun Hu, Juha Hyyppä)</author>
      <guid isPermaLink="false">2504.14337v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment</title>
      <link>http://arxiv.org/abs/2504.14805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025; 23 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为动态对比技能学习（DCSL）的新框架，用于解决强化学习在长时程任务和复杂决策中的扩展问题。&lt;h4&gt;背景&lt;/h4&gt;强化学习在多个领域取得了显著进展，但在处理长时程任务和复杂决策时，其扩展性仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出DCSL框架，以解决现有方法在识别相似行为和技能长度固定方面的问题，从而提高技能学习的灵活性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;DCSL框架包含三个关键思想：基于状态转换的技能表示、技能相似性函数学习以及动态技能长度调整。&lt;h4&gt;主要发现&lt;/h4&gt;DCSL通过关注状态转换和利用对比学习，有效地捕捉了行为语义上下文，并能够根据行为的时间跨度动态调整技能长度。&lt;h4&gt;结论&lt;/h4&gt;DCSL在复杂或噪声数据集上实现了更灵活和自适应的技能提取，并在任务完成和效率方面与现有方法相比表现出竞争力。&lt;h4&gt;翻译&lt;/h4&gt;Reinforcement learning (RL) has made significant progress in various domains,but scaling it to long-horizon tasks with complex decision-making remainschallenging. Skill learning attempts to address this by abstracting actionsinto higher-level behaviors. However, current approaches often fail torecognize semantically similar behaviors as the same skill and use fixed skilllengths, limiting flexibility and generalization. To address this, we proposeDynamic Contrastive Skill Learning (DCSL), a novel framework that redefinesskill representation and learning. DCSL introduces three key ideas:state-transition based skill representation, skill similarity function learning, anddynamic skill length adjustment. By focusing on state transitions andleveraging contrastive learning, DCSL effectively captures the semanticcontext of behaviors and adapts skill lengths to match the appropriate temporalextent of behaviors. Our approach enables more flexible and adaptive skillextraction, particularly in complex or noisy datasets, and demonstratescompetitive performance compared to existing methods in task completion andefficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning (RL) has made significant progress in various domains,but scaling it to long-horizon tasks with complex decision-making remainschallenging. Skill learning attempts to address this by abstracting actionsinto higher-level behaviors. However, current approaches often fail torecognize semantically similar behaviors as the same skill and use fixed skilllengths, limiting flexibility and generalization. To address this, we proposeDynamic Contrastive Skill Learning (DCSL), a novel framework that redefinesskill representation and learning. DCSL introduces three key ideas:state-transition based skill representation, skill similarity functionlearning, and dynamic skill length adjustment. By focusing on state transitionsand leveraging contrastive learning, DCSL effectively captures the semanticcontext of behaviors and adapts skill lengths to match the appropriate temporalextent of behaviors. Our approach enables more flexible and adaptive skillextraction, particularly in complex or noisy datasets, and demonstratescompetitive performance compared to existing methods in task completion andefficiency.</description>
      <author>example@mail.com (Jinwoo Choi, Seung-Woo Seo)</author>
      <guid isPermaLink="false">2504.14805v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Beamforming Design and Association Scheme for Multi-RIS Multi-User mmWave Systems Through Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.14464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE Transactions on Wireless Communications(TWC)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的异构图神经网络（GNN）来有效地利用无线通信环境的拓扑结构，以提高多RIS多用户毫米波通信系统的容量。&lt;h4&gt;背景&lt;/h4&gt;可重构智能表面（RIS）技术是下一代无线通信网络的有希望的技术，它能够定制通信环境，部署多个RIS可以减轻基站与用户之间的信号阻塞，从而提高服务覆盖率。&lt;h4&gt;目的&lt;/h4&gt;为了充分发挥多RIS辅助通信系统的潜力，本文旨在解决非凸优化问题，并采用基于学习的策略来确定最优策略。&lt;h4&gt;方法&lt;/h4&gt;本文设计了一种关联方案，为每个用户选择合适的RIS，并通过迭代优化RIS关联方案和波束成形设计来最大化所有用户的加权总和速率（WSR），直到异构GNN收敛。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，提出的异构GNN在考虑的多RIS辅助通信系统中接近高复杂度交替优化（AO）算法的性能，并且优于其他基准方案。RIS关联方案带来的性能提升达到30%。&lt;h4&gt;结论&lt;/h4&gt;基于所提出的方法，每个用户都关联到最佳的RIS，显著提高了多RIS多用户毫米波通信系统的容量。&lt;h4&gt;翻译&lt;/h4&gt;摘要：可重构智能表面（RIS）作为下一代无线通信网络的很有希望的技术正在兴起，它提供了一系列优点，如定制通信环境的能力。此外，部署多个RIS有助于减轻基站（BS）和用户之间的严重信号阻塞，为增强服务覆盖范围提供了一个实际且高效的解决方案。然而，要充分发挥多RIS辅助通信系统的潜力，需要解决非凸优化问题。这一挑战促使采用基于学习的策略来确定最优策略。在本文中，我们介绍了一种新型的异构图神经网络（GNN），以有效地利用无线通信环境的拓扑结构。具体而言，我们设计了一种关联方案，为每个用户选择合适的RIS。然后，我们通过迭代优化RIS关联方案和波束成形设计，直到考虑的异构GNN收敛，来最大化所有用户的加权总和速率（WSR）。基于所提出的方法，每个用户都关联到最佳的RIS，这表明显著提高了多RIS多用户毫米波通信系统的容量。特别是，仿真结果表明，所提出的异构GNN在考虑的多RIS辅助通信系统中接近高复杂度交替优化（AO）算法的性能，并且优于其他基准方案。此外，通过RIS关联方案获得的性能提升表明，其性能提升的量级为30%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconfigurable intelligent surface (RIS) is emerging as a promisingtechnology for next-generation wireless communication networks, offering avariety of merits such as the ability to tailor the communication environment.Moreover, deploying multiple RISs helps mitigate severe signal blocking betweenthe base station (BS) and users, providing a practical and efficient solutionto enhance the service coverage. However, fully reaping the potential of amulti-RIS aided communication system requires solving a non-convex optimizationproblem. This challenge motivates the adoption of learning-based methods fordetermining the optimal policy. In this paper, we introduce a novelheterogeneous graph neural network (GNN) to effectively leverage the graphtopology of a wireless communication environment. Specifically, we design anassociation scheme that selects a suitable RIS for each user. Then, we maximizethe weighted sum rate (WSR) of all the users by iteratively optimizing the RISassociation scheme, and beamforming designs until the considered heterogeneousGNN converges. Based on the proposed approach, each user is associated with thebest RIS, which is shown to significantly improve the system capacity inmulti-RIS multi-user millimeter wave (mmWave) communications. Specifically,simulation results demonstrate that the proposed heterogeneous GNN closelyapproaches the performance of the high-complexity alternating optimization (AO)algorithm in the considered multi-RIS aided communication system, and itoutperforms other benchmark schemes. Moreover, the performance improvementachieved through the RIS association scheme is shown to be of the order of 30%.</description>
      <author>example@mail.com (Mengbing Liu, Chongwen Huang, Ahmed Alhammadi, Marco Di Renzo, Merouane Debbah, Chau Yuen)</author>
      <guid isPermaLink="false">2504.14464v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>How Well Can General Vision-Language Models Learn Medicine By Watching Public Educational Videos?</title>
      <link>http://arxiv.org/abs/2504.14391v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;公开的生物医学视频，如YouTube上的视频，是医学学生的宝贵教育资源。本研究探讨了这些非标准化和异构的视频是否能够有效地教授通用领域视觉-语言模型生物医学知识。&lt;h4&gt;背景&lt;/h4&gt;公开的生物医学视频通常包含医疗图像、解说、解释图表和情境框架，旨在为人类学习者提供教育资源。&lt;h4&gt;目的&lt;/h4&gt;研究非标准化和异构的生物医学视频是否能够有效地教学通用领域视觉-语言模型生物医学知识。&lt;h4&gt;方法&lt;/h4&gt;引入了OpenBiomedVi数据集，包含1031小时的视频-字幕和问答对，通过多步骤人工干预的流程精心整理。此外，还引入了两个新的专家精心编制的基准测试：MIMICEchoQA和SurgeryVideoQA。&lt;h4&gt;主要发现&lt;/h4&gt;尽管这些视频非正式且异构，但微调后的Qwen-2-VL模型在大多数基准测试中表现出显著的性能提升。2B模型在视频任务上提高了98.7%，在图像任务上提高了71.2%，在文本任务上提高了0.2%。7B模型在视频任务上提高了37.09%，在图像任务上提高了11.2%，但在文本任务上略有下降，比基线模型降低了2.7%。&lt;h4&gt;结论&lt;/h4&gt;为人类学习而创建的教育视频为生物医学视觉-语言模型提供了惊人的有效训练信号。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译为中文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Publicly available biomedical videos, such as those on YouTube, serve asvaluable educational resources for medical students. Unlike standard machinelearning datasets, these videos are designed for human learners, often mixingmedical imagery with narration, explanatory diagrams, and contextual framing.In this work, we investigate whether such pedagogically rich, yetnon-standardized and heterogeneous videos can effectively teach general-domainvision-language models biomedical knowledge. To this end, we introduceOpenBiomedVi, a biomedical video instruction tuning dataset comprising 1031hours of video-caption and Q/A pairs, curated through a multi-stephuman-in-the-loop pipeline. Diverse biomedical video datasets are rare, andOpenBiomedVid fills an important gap by providing instruction-style supervisiongrounded in real-world educational content. Surprisingly, despite the informaland heterogeneous nature of these videos, the fine-tuned Qwen-2-VL modelsexhibit substantial performance improvements across most benchmarks. The 2Bmodel achieves gains of 98.7% on video tasks, 71.2% on image tasks, and 0.2% ontext tasks. The 7B model shows improvements of 37.09% on video and 11.2% onimage tasks, with a slight degradation of 2.7% on text tasks compared to theirrespective base models. To address the lack of standardized biomedical videoevaluation datasets, we also introduce two new expert curated benchmarks,MIMICEchoQA and SurgeryVideoQA. On these benchmarks, the 2B model achievesgains of 99.1% and 98.1%, while the 7B model shows gains of 22.5% and 52.1%,respectively, demonstrating the models' ability to generalize and performbiomedical video understanding on cleaner and more standardized datasets thanthose seen during training. These results suggest that educational videoscreated for human learning offer a surprisingly effective training signal forbiomedical VLMs.</description>
      <author>example@mail.com (Rahul Thapa, Andrew Li, Qingyang Wu, Bryan He, Yuki Sahashi, Christina Binder, Angela Zhang, Ben Athiwaratkun, Shuaiwen Leon Song, David Ouyang, James Zou)</author>
      <guid isPermaLink="false">2504.14391v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>HoLa: B-Rep Generation using a Holistic Latent Representation</title>
      <link>http://arxiv.org/abs/2504.14257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的表示方法，用于学习和生成计算机辅助设计（CAD）模型，该表示方法采用边界表示（B-Reps）的形式，并基于整体潜在空间（HoLa）统一了不同顺序的B-Reps原语的连续几何属性及其离散拓扑关系。&lt;h4&gt;背景&lt;/h4&gt;现有方法在处理B-Reps模型时存在模糊性、冗余和不一致性，以及训练复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以减少生成的B-Reps原语之间的模糊性、冗余和不一致性，同时降低训练复杂性，并显著提高模型的准确性。&lt;h4&gt;方法&lt;/h4&gt;通过学习区分和从一对表面原语中推导曲线几何形状，消除潜在空间中曲线、顶点和所有拓扑连接的存在，将拓扑学习在B-Reps中重新表述为欧几里得空间中的几何重建问题。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在表面、曲线、顶点和它们的拓扑关系上编码了一个完整的B-Reps模型，并设计了一个基于扩散的第一代生成器，能够处理包括点云、单/多视图图像、2D草图和文本提示在内的各种输入。&lt;h4&gt;结论&lt;/h4&gt;该方法显著减少了生成的B-Reps原语之间的模糊性、冗余和不一致性，以及先前多步B-Reps学习管道中固有的训练复杂性，同时实现了比当前最先进技术更高的有效性率：82% 对 50% 左右。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel representation for learning and generatingComputer-Aided Design (CAD) models in the form of $\textit{boundaryrepresentations}$ (B-Reps). Our representation unifies the continuous geometricproperties of B-Rep primitives in different orders (e.g., surfaces and curves)and their discrete topological relations in a $\textit{holistic latent}$ (HoLa)space. This is based on the simple observation that the topological connectionbetween two surfaces is intrinsically tied to the geometry of theirintersecting curve. Such a prior allows us to reformulate topology learning inB-Reps as a geometric reconstruction problem in Euclidean space. Specifically,we eliminate the presence of curves, vertices, and all the topologicalconnections in the latent space by learning to distinguish and derive curvegeometries from a pair of surface primitives via a neural intersection network.To this end, our holistic latent space is only defined on surfaces but encodesa full B-Rep model, including the geometry of surfaces, curves, vertices, andtheir topological relations. Our compact and holistic latent space facilitatesthe design of a first diffusion-based generator to take on a large variety ofinputs including point clouds, single/multi-view images, 2D sketches, and textprompts. Our method significantly reduces ambiguities, redundancies, andincoherences among the generated B-Rep primitives, as well as trainingcomplexities inherent in prior multi-step B-Rep learning pipelines, whileachieving greatly improved validity rate over current state of the art: 82% vs.$\approx$50%.</description>
      <author>example@mail.com (Yilin Liu, Duoteng Xu, Xingyao Yu, Xiang Xu, Daniel Cohen-Or, Hao Zhang, Hui Huang)</author>
      <guid isPermaLink="false">2504.14257v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>SuperCL: Superpixel Guided Contrastive Learning for Medical Image Segmentation Pre-training</title>
      <link>http://arxiv.org/abs/2504.14737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SuperCL的新型对比学习方法，用于医学图像分割预训练，以解决现有方法在获取高质量标注图像数据集方面的困难。&lt;h4&gt;背景&lt;/h4&gt;医学图像分割是关键但具有挑战性的任务，主要因为难以获取大量高质量、专家标注的图像数据集。&lt;h4&gt;目的&lt;/h4&gt;提出SuperCL以解决现有方法在提取实例级或像素到像素表示时忽略图像内部相似像素组特征的问题，并提高对比对生成效率。&lt;h4&gt;方法&lt;/h4&gt;SuperCL通过引入两种新颖的对比对生成策略（图像内部局部对比对生成和图像间全局对比对生成）来利用图像的结构先验和像素相关性。此外，还提出了两个模块（平均超像素特征图生成和连通组件标签生成）以更好地利用先验结构信息。&lt;h4&gt;主要发现&lt;/h4&gt;在8个医学图像数据集上的实验表明，SuperCL优于现有的12种方法，实现了更精确的预测，在MMWHS、CHAOS、脾脏数据集上分别提高了3.15%、5.44%、7.89%的DSC。&lt;h4&gt;结论&lt;/h4&gt;SuperCL在医学图像分割预训练方面取得了显著的性能提升，代码将在接受后发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image segmentation is a critical yet challenging task, primarily dueto the difficulty of obtaining extensive datasets of high-quality,expert-annotated images. Contrastive learning presents a potential but stillproblematic solution to this issue. Because most existing methods focus onextracting instance-level or pixel-to-pixel representation, which ignores thecharacteristics between intra-image similar pixel groups. Moreover, whenconsidering contrastive pairs generation, most SOTA methods mainly rely onmanually setting thresholds, which requires a large number of gradientexperiments and lacks efficiency and generalization. To address these issues,we propose a novel contrastive learning approach named SuperCL for medicalimage segmentation pre-training. Specifically, our SuperCL exploits thestructural prior and pixel correlation of images by introducing two novelcontrastive pairs generation strategies: Intra-image Local Contrastive Pairs(ILCP) Generation and Inter-image Global Contrastive Pairs (IGCP) Generation.Considering superpixel cluster aligns well with the concept of contrastivepairs generation, we utilize the superpixel map to generate pseudo masks forboth ILCP and IGCP to guide supervised contrastive learning. Moreover, we alsopropose two modules named Average SuperPixel Feature Map Generation (ASP) andConnected Components Label Generation (CCL) to better exploit the priorstructural information for IGCP. Finally, experiments on 8 medical imagedatasets indicate our SuperCL outperforms existing 12 methods. i.e. Our SuperCLachieves a superior performance with more precise predictions fromvisualization figures and 3.15%, 5.44%, 7.89% DSC higher than the previous bestresults on MMWHS, CHAOS, Spleen with 10% annotations. Our code will be releasedafter acceptance.</description>
      <author>example@mail.com (Shuang Zeng, Lei Zhu, Xinliang Zhang, Hangzhou He, Yanye Lu)</author>
      <guid isPermaLink="false">2504.14737v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*</title>
      <link>http://arxiv.org/abs/2504.11014v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted (Poster) to the 3rd CV4MR Workshop at CVPR 2025:  https://openreview.net/forum?id=00RQ8Cv3ia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为GATE3D的弱监督框架，专门用于单目3D物体检测，通过结合2D和3D预测的一致性损失来有效弥合领域差距，并实现了在KITTI基准数据集和室内办公数据集上的良好性能。&lt;h4&gt;背景&lt;/h4&gt;计算机视觉领域正趋向于开发能够同时处理多个不同任务的通用模型。然而，单目3D物体检测在多领域训练中面临挑战，特别是在标注有精确3D地面真实标签的数据集稀缺的情况下。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出了一种新的弱监督框架，以实现通用单目3D物体检测。&lt;h4&gt;方法&lt;/h4&gt;GATE3D通过使用伪标签和结合2D与3D预测的一致性损失来有效地弥合领域差距。它旨在解决当前预训练模型在非道路环境中检测行人的困难，并扩展到单目3D检测领域。&lt;h4&gt;主要发现&lt;/h4&gt;GATE3D在KITTI基准数据集和自收集的室内办公数据集上实现了有竞争力的性能，显著加速了从有限标注数据中的学习过程。&lt;h4&gt;结论&lt;/h4&gt;GATE3D框架在加速从有限标注数据中学习方面具有显著潜力，对机器人、增强现实和虚拟现实应用具有广泛的影响。&lt;h4&gt;翻译&lt;/h4&gt;The paper introduces a novel weakly supervised framework called GATE3D, specifically designed for generalized monocular 3D object detection by bridging domain gaps through consistency losses between 2D and 3D predictions. The model achieves competitive performance on the KITTI benchmark as well as on an indoor-office dataset, demonstrating its significant potential for broader impacts in robotics, augmented reality, and virtual reality applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emerging trend in computer vision emphasizes developing universal modelscapable of simultaneously addressing multiple diverse tasks. Such universalitytypically requires joint training across multi-domain datasets to ensureeffective generalization. However, monocular 3D object detection presentsunique challenges in multi-domain training due to the scarcity of datasetsannotated with accurate 3D ground-truth labels, especially beyond typicalroad-based autonomous driving contexts. To address this challenge, we introducea novel weakly supervised framework leveraging pseudo-labels. Currentpretrained models often struggle to accurately detect pedestrians in non-roadenvironments due to inherent dataset biases. Unlike generalized image-based 2Dobject detection models, achieving similar generalization in monocular 3Ddetection remains largely unexplored. In this paper, we propose GATE3D, a novelframework designed specifically for generalized monocular 3D object detectionvia weak supervision. GATE3D effectively bridges domain gaps by employingconsistency losses between 2D and 3D predictions. Remarkably, our modelachieves competitive performance on the KITTI benchmark as well as on anindoor-office dataset collected by us to evaluate the generalizationcapabilities of our framework. Our results demonstrate that GATE3Dsignificantly accelerates learning from limited annotated data througheffective pre-training strategies, highlighting substantial potential forbroader impacts in robotics, augmented reality, and virtual realityapplications. Project page: https://ies0411.github.io/GATE3D/</description>
      <author>example@mail.com (Eunsoo Im, Changhyun Jee, Jung Kwon Lee)</author>
      <guid isPermaLink="false">2504.11014v3</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>sEEG-based Encoding for Sentence Retrieval: A Contrastive Learning Approach to Brain-Language Alignment</title>
      <link>http://arxiv.org/abs/2504.14468v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for poster presentation at the CVPR 2025 Workshop on  Multimodal Foundation Models (MMFM3)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了通过多模态基础模型将侵入性脑记录与自然语言对齐的潜力，并提出了一种名为SSENSE的对比学习框架，该框架能够将个体立体脑电图（sEEG）信号投影到预训练的CLIP模型的句子嵌入空间，从而直接从脑活动中检索句子级信息。&lt;h4&gt;背景&lt;/h4&gt;解释神经活动通过有意义的潜在表示是一个复杂且不断发展的挑战，位于神经科学和人工智能的交汇点。&lt;h4&gt;目的&lt;/h4&gt;研究多模态基础模型在将侵入性脑记录与自然语言对齐方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了SSENSE，一个对比学习框架，该框架使用InfoNCE损失在sEEG的频谱表示上训练一个神经编码器，而不对文本编码器进行微调。在自然电影观看数据集上评估了该方法。&lt;h4&gt;主要发现&lt;/h4&gt;尽管数据有限，SSENSE仍然取得了有希望的结果，表明通用语言表示可以作为神经解码的有效先验。&lt;h4&gt;结论&lt;/h4&gt;SSENSE框架有效地将脑电图信号与自然语言联系起来，表明通用语言表示在神经解码中具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Interpreting neural activity through meaningful latent representations remains a complex and evolving challenge at the intersection of neuroscience and artificial intelligence. We investigate the potential of multimodal foundation models to align invasive brain recordings with natural language. We present SSENSE, a contrastive learning framework that projects single-subject stereo-electroencephalography (sEEG) signals into the sentence embedding space of a frozen CLIP model, enabling sentence-level retrieval directly from brain activity. SSENSE trains a neural encoder on spectral representations of sEEG using InfoNCE loss, without fine-tuning the text encoder. We evaluate our method on time-aligned sEEG and spoken transcripts from a naturalistic movie-watching dataset. Despite limited data, SSENSE achieves promising results, demonstrating that general-purpose language representations can serve as effective priors for neural decoding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpreting neural activity through meaningful latent representationsremains a complex and evolving challenge at the intersection of neuroscienceand artificial intelligence. We investigate the potential of multimodalfoundation models to align invasive brain recordings with natural language. Wepresent SSENSE, a contrastive learning framework that projects single-subjectstereo-electroencephalography (sEEG) signals into the sentence embedding spaceof a frozen CLIP model, enabling sentence-level retrieval directly from brainactivity. SSENSE trains a neural encoder on spectral representations of sEEGusing InfoNCE loss, without fine-tuning the text encoder. We evaluate ourmethod on time-aligned sEEG and spoken transcripts from a naturalisticmovie-watching dataset. Despite limited data, SSENSE achieves promisingresults, demonstrating that general-purpose language representations can serveas effective priors for neural decoding.</description>
      <author>example@mail.com (Yijun Liu)</author>
      <guid isPermaLink="false">2504.14468v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>StableQuant: Layer Adaptive Post-Training Quantization for Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2504.14915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为StableQuant的新型自适应后训练量化（PTQ）算法，用于广泛使用的语音基础模型（SFMs）。该算法在语音识别任务中表现出色，实现了模型压缩和推理速度提升。&lt;h4&gt;背景&lt;/h4&gt;虽然PTQ技术在压缩大型语言模型（LLMs）方面取得了成功，但直接应用于SFMs可能不会得到最佳结果，因为SFMs使用了不同的网络架构进行特征提取。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的PTQ算法，以优化SFMs的量化性能。&lt;h4&gt;方法&lt;/h4&gt;StableQuant通过分析每一层的尺度分布和整体性能，自适应地确定每个层的量化范围，从而在保证性能的同时实现量化。&lt;h4&gt;主要发现&lt;/h4&gt;在两个SFMs（HuBERT和wav2vec2.0）上进行评估，StableQuant相较于传统PTQ方法实现了更好的性能。该算法将SFM模型的大小减少到四分之一，同时将推理速度提高了一倍，并且在8位量化下将词错误率（WER）性能下降限制在小于0.3%。&lt;h4&gt;结论&lt;/h4&gt;StableQuant是一种有效的PTQ算法，能够在保证性能的同时显著减小SFM模型的大小并加快推理速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose StableQuant, a novel adaptive post-trainingquantization (PTQ) algorithm for widely used speech foundation models (SFMs).While PTQ has been successfully employed for compressing large language models(LLMs) due to its ability to bypass additional fine-tuning, directly applyingthese techniques to SFMs may not yield optimal results, as SFMs utilizedistinct network architecture for feature extraction. StableQuant demonstratesoptimal quantization performance regardless of the network architecture type,as it adaptively determines the quantization range for each layer by analyzingboth the scale distributions and overall performance. We evaluate our algorithmon two SFMs, HuBERT and wav2vec2.0, for an automatic speech recognition (ASR)task, and achieve superior performance compared to traditional PTQ methods.StableQuant successfully reduces the sizes of SFM models to a quarter anddoubles the inference speed while limiting the word error rate (WER)performance drop to less than 0.3% with 8-bit quantization.</description>
      <author>example@mail.com (Yeona Hong, Hyewon Han, Woo-jin Chung, Hong-Goo Kang)</author>
      <guid isPermaLink="false">2504.14915v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Towards NSFW-Free Text-to-Image Generation via Safety-Constraint Direct Preference Optimization</title>
      <link>http://arxiv.org/abs/2504.14290v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SC-DPO的新框架，用于解决文本到图像（T2I）生成中的内容安全性问题。&lt;h4&gt;背景&lt;/h4&gt;确保生成内容的安全性是T2I生成的基本挑战，现有研究要么无法保证在潜在有害概念下的完全安全性，要么难以在安全性和生成质量之间取得平衡。&lt;h4&gt;目的&lt;/h4&gt;提出SC-DPO以解决这些问题，旨在最大化生成人类偏好样本的可能性，同时最小化生成输出的安全成本。&lt;h4&gt;方法&lt;/h4&gt;SC-DPO将安全约束集成到一般的人类偏好校准中，引入了一个安全成本模型来准确量化图像的有害程度，并使用对比学习和成本锚定目标来有效训练它。此外，构建了SCP-10K数据集，并提出了动态聚焦机制（DFM）。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，SC-DPO在防御各种不适宜内容的同时，保持了最优样本质量和人类偏好的一致性，并对旨在生成有害内容的对抗性提示表现出韧性。&lt;h4&gt;结论&lt;/h4&gt;SC-DPO是一种有效且安全的T2I生成方法，能够平衡安全性和生成质量。&lt;h4&gt;翻译&lt;/h4&gt;Ensuring the safety of generated content remains a fundamental challenge for Text-to-Image (T2I) generation. Existing studies either fail to guarantee complete safety under potentially harmful concepts or struggle to balance safety with generation quality. To address these issues, we propose Safety-Constrained Direct Preference Optimization (SC-DPO), a novel framework for safety alignment in T2I models. SC-DPO integrates safety constraints into the general human preference calibration, aiming to maximize the likelihood of generating human-preferred samples while minimizing the safety cost of the generated outputs. In SC-DPO, we introduce a safety cost model to accurately quantify harmful levels for images, and train it effectively using the proposed contrastive learning and cost anchoring objectives. To apply SC-DPO for effective T2I safety alignment, we constructed SCP-10K, a safety-constrained preference dataset containing rich harmful concepts, which blends safety-constrained preference pairs under both harmful and clean instructions, further mitigating the trade-off between safety and sample quality. Additionally, we propose a Dynamic Focusing Mechanism (DFM) for SC-DPO, promoting the model's learning of difficult preference pair samples. Extensive experiments demonstrate that SC-DPO outperforms existing methods, effectively defending against various NSFW content while maintaining optimal sample quality and human preference alignment. Additionally, SC-DPO exhibits resilience against adversarial prompts designed to generate harmful content.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety of generated content remains a fundamental challenge forText-to-Image (T2I) generation. Existing studies either fail to guaranteecomplete safety under potentially harmful concepts or struggle to balancesafety with generation quality. To address these issues, we proposeSafety-Constrained Direct Preference Optimization (SC-DPO), a novel frameworkfor safety alignment in T2I models. SC-DPO integrates safety constraints intothe general human preference calibration, aiming to maximize the likelihood ofgenerating human-preferred samples while minimizing the safety cost of thegenerated outputs. In SC-DPO, we introduce a safety cost model to accuratelyquantify harmful levels for images, and train it effectively using the proposedcontrastive learning and cost anchoring objectives. To apply SC-DPO foreffective T2I safety alignment, we constructed SCP-10K, a safety-constrainedpreference dataset containing rich harmful concepts, which blendssafety-constrained preference pairs under both harmful and clean instructions,further mitigating the trade-off between safety and sample quality.Additionally, we propose a Dynamic Focusing Mechanism (DFM) for SC-DPO,promoting the model's learning of difficult preference pair samples. Extensiveexperiments demonstrate that SC-DPO outperforms existing methods, effectivelydefending against various NSFW content while maintaining optimal sample qualityand human preference alignment. Additionally, SC-DPO exhibits resilienceagainst adversarial prompts designed to generate harmful content.</description>
      <author>example@mail.com (Shouwei Ruan, Zhenyu Wu, Yao Huang, Ruochen Zhang, Yitong Sun, Caixin Kang, Xingxing Wei)</author>
      <guid isPermaLink="false">2504.14290v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Single-Cell Foundation Models with Graph Neural Networks for Drug Response Prediction</title>
      <link>http://arxiv.org/abs/2504.14361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种通过集成scGPT基础模型到DeepCDR模型中预测癌症药物反应（CDR）的创新方法。&lt;h4&gt;背景&lt;/h4&gt;该研究旨在解决癌症药物反应预测的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提高CDR预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;方法使用scGPT从基因表达数据生成嵌入，这些嵌入随后作为DeepCDR模型的基因表达输入数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于scGPT的方法在性能上优于之前的相关工作，包括原始DeepCDR模型和基于scFoundation的模型。&lt;h4&gt;结论&lt;/h4&gt;研究强调了scGPT嵌入在提高CDR预测准确性方面的潜力，并为现有方法提供了有希望的替代方案。&lt;h4&gt;翻译&lt;/h4&gt;In this study, we propose an innovative methodology for predicting CancerDrug Response (CDR) through the integration of the scGPT foundation model within the DeepCDR model. Our approach utilizes scGPT to generate embeddings from gene expression data, which are then used as gene expression input data for DeepCDR. The experimental findings demonstrate the efficacy of this scGPT-based method in outperforming previous related works, including the original DeepCDR model and the scFoundation-based model. This study highlights the potential of scGPT embeddings to enhance the accuracy of CDR predictions and offers a promising alternative to existing approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we propose an innovative methodology for predicting CancerDrug Response (CDR) through the integration of the scGPT foundation modelwithin the DeepCDR model. Our approach utilizes scGPT to generate embeddingsfrom gene expression data, which are then used as gene expression input datafor DeepCDR. The experimental findings demonstrate the efficacy of thisscGPT-based method in outperforming previous related works, including theoriginal DeepCDR model and the scFoundation-based model. This study highlightsthe potential of scGPT embeddings to enhance the accuracy of CDR predictionsand offers a promising alternative to existing approaches.</description>
      <author>example@mail.com (Till Rossner, Ziteng Li, Jonas Balke, Nikoo Salehfard, Tom Seifert, Ming Tang)</author>
      <guid isPermaLink="false">2504.14361v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>BMRL: Bi-Modal Guided Multi-Perspective Representation Learning for Zero-Shot Deepfake Attribution</title>
      <link>http://arxiv.org/abs/2504.14129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的双模态引导的多视角表示学习框架，用于零样本深度伪造归因（ZS-DFA），以有效地追踪未见生成器。&lt;h4&gt;背景&lt;/h4&gt;由于生成模型的快速进步，追踪伪造面孔的来源归因问题引起了广泛关注。然而，现有的深度伪造归因（DFA）工作主要关注视觉模态中各个领域之间的交互，而其他模态如文本和面部解析尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高深度伪造归因的泛化性能，使其能够细粒度地评估对未见生成器的归因能力。&lt;h4&gt;方法&lt;/h4&gt;设计了多视角视觉编码器（MPVE）来探索不同视角（图像、噪声和边缘）的深度伪造视觉特征；提出了新的解析编码器，专注于全局面部属性嵌入，通过视觉-解析匹配实现解析引导的DFA表示学习；提出了语言编码器来捕获细粒度语言嵌入，通过视觉-语言对齐实现语言引导的通用视觉伪造表示学习；还提出了深度伪造归因对比中心（DFACC）损失，以增强归因的追踪能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在各种协议评估中优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在零样本深度伪造归因任务上表现优异，为追踪未见生成器提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于生成模型的快速进步，追踪伪造面孔的来源归因问题受到了广泛关注。然而，现有的深度伪造归因（DFA）工作主要关注视觉模态中各个领域之间的交互，而其他模态如文本和面部解析尚未充分探索。此外，它们往往无法以细粒度的方式评估深度伪造归因器对未见生成器的泛化性能。在本文中，我们提出了一种新的双模态引导的多视角表示学习框架，用于零样本深度伪造归因（ZS-DFA），以促进对未见生成器的有效追踪。具体来说，我们设计了一个多视角视觉编码器（MPVE）来探索跨越三个视角（即图像、噪声和边缘）的通用深度伪造归因视觉特征。我们设计了一个新的解析编码器，专注于全局面部属性嵌入，通过视觉-解析匹配实现解析引导的DFA表示学习。我们提出了一个语言编码器来捕获细粒度语言嵌入，通过视觉-语言对齐实现语言引导的通用视觉伪造表示学习。此外，我们提出了一个新的深度伪造归因对比中心（DFACC）损失，以将相关生成器拉近，将不相关的生成器推开，这可以引入到DFA模型中以提高追踪能力。实验结果表明，我们的方法在各种协议评估中优于现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The challenge of tracing the source attribution of forged faces has gainedsignificant attention due to the rapid advancement of generative models.However, existing deepfake attribution (DFA) works primarily focus on theinteraction among various domains in vision modality, and other modalities suchas texts and face parsing are not fully explored. Besides, they tend to fail toassess the generalization performance of deepfake attributors to unseengenerators in a fine-grained manner. In this paper, we propose a novel bi-modalguided multi-perspective representation learning (BMRL) framework for zero-shotdeepfake attribution (ZS-DFA), which facilitates effective traceability tounseen generators. Specifically, we design a multi-perspective visual encoder(MPVE) to explore general deepfake attribution visual characteristics acrossthree views (i.e., image, noise, and edge). We devise a novel parsing encoderto focus on global face attribute embeddings, enabling parsing-guided DFArepresentation learning via vision-parsing matching. A language encoder isproposed to capture fine-grained language embeddings, facilitatinglanguage-guided general visual forgery representation learning throughvision-language alignment. Additionally, we present a novel deepfakeattribution contrastive center (DFACC) loss, to pull relevant generators closerand push irrelevant ones away, which can be introduced into DFA models toenhance traceability. Experimental results demonstrate that our methodoutperforms the state-of-the-art on the ZS-DFA task through various protocolsevaluation.</description>
      <author>example@mail.com (Yaning Zhang, Jiahe Zhang, Chunjie Ma, Weili Guan, Tian Gan, Zan Gao)</author>
      <guid isPermaLink="false">2504.14129v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Decomposition-based multi-scale transformer framework for time series anomaly detection</title>
      <link>http://arxiv.org/abs/2504.14206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于分解的Transformer框架（TransDe）用于多变量时间序列异常检测，旨在解决现有方法的挑战。&lt;h4&gt;背景&lt;/h4&gt;现有时间序列异常检测方法面临两个主要挑战：直接建模复杂序列中的依赖关系困难，以及使用均方误差优化参数的方法在处理时间序列噪声时性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出TransDe框架，结合时间序列分解和Transformer的优势，有效学习正常时间序列数据中的复杂模式。&lt;h4&gt;方法&lt;/h4&gt;TransDe框架采用多尺度补丁的Transformer架构来利用时间序列分解后每个组件的代表性依赖关系。此外，提出了一种基于补丁操作的对比学习范式，利用KL散度对齐不同补丁级视图之间的正常模式纯表示。还引入了一种新的异步损失函数和stop-gradient策略，以增强TransDe的性能，避免优化过程中的耗时和劳动密集型计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;在五个公共数据集上进行的广泛实验表明，TransDe在F1分数方面优于十二个基线方法。&lt;h4&gt;结论&lt;/h4&gt;TransDe在多变量时间序列异常检测方面表现出优越性，其代码可在https://github.com/shaieesss/TransDe上获得。&lt;h4&gt;翻译&lt;/h4&gt;时间序列异常检测对于保持系统稳定至关重要。现有方法面临两个主要挑战。首先，直接建模序列中各种复杂模式的依赖关系很困难。其次，许多使用均方误差优化参数的方法在处理时间序列噪声时表现不佳，导致性能下降。为了解决这些挑战，我们提出了一种基于分解的Transformer框架（TransDe）用于多变量时间序列异常检测。其关键思想是将时间序列分解和Transformer的优势结合起来，有效地学习正常时间序列数据中的复杂模式。我们提出了一种基于多尺度补丁的Transformer架构，以利用时间序列分解后每个组件的代表性依赖关系。此外，我们还提出了一种基于补丁操作的对比学习范式，利用KL散度对齐不同补丁级视图之间的正常模式纯表示。为了进一步提高TransDe的性能，我们还引入了一种新的异步损失函数和stop-gradient策略，以避免优化过程中的耗时和劳动密集型计算成本。在五个公共数据集上进行的广泛实验表明，与十二个基线方法相比，TransDe在F1分数方面表现出优越性。我们的代码可在https://github.com/shaieesss/TransDe上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series anomaly detection is crucial for maintaining stable systems.Existing methods face two main challenges. First, it is difficult to directlymodel the dependencies of diverse and complex patterns within the sequences.Second, many methods that optimize parameters using mean squared error strugglewith noise in the time series, leading to performance deterioration. To addressthese challenges, we propose a transformer-based framework built ondecomposition (TransDe) for multivariate time series anomaly detection. The keyidea is to combine the strengths of time series decomposition and transformersto effectively learn the complex patterns in normal time series data. Amulti-scale patch-based transformer architecture is proposed to exploit therepresentative dependencies of each decomposed component of the time series.Furthermore, a contrastive learn paradigm based on patch operation is proposed,which leverages KL divergence to align the positive pairs, namely the purerepresentations of normal patterns between different patch-level views. A novelasynchronous loss function with a stop-gradient strategy is further introducedto enhance the performance of TransDe effectively. It can avoid time-consumingand labor-intensive computation costs in the optimization process. Extensiveexperiments on five public datasets are conducted and TransDe shows superioritycompared with twelve baselines in terms of F1 score. Our code is available athttps://github.com/shaieesss/TransDe.</description>
      <author>example@mail.com (Wenxin Zhang, Cuicui Luo)</author>
      <guid isPermaLink="false">2504.14206v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>ROI-Guided Point Cloud Geometry Compression Towards Human and Machine Vision</title>
      <link>http://arxiv.org/abs/2504.14240v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的区域兴趣引导点云几何压缩方法，用于解决点云数据在存储和传输中的挑战。&lt;h4&gt;背景&lt;/h4&gt;点云数据在自动驾驶、虚拟现实和机器人等领域至关重要，但其大量数据体积给存储和传输带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的压缩方法，以获得高压缩比，同时保证下游任务的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用双分支并行结构，基础层编码和解码简化版点云，增强层关注几何细节，并通过ROI预测网络进行残差信息细化。该网络生成掩码信息，作为强大的监督信号，并在速率-失真（RD）优化过程中应用这些掩码细节，每个点在失真计算中都有权重。&lt;h4&gt;主要发现&lt;/h4&gt;RPCGC在ScanNet和SUN RGB-D数据集上实现了卓越的压缩性能和比一些基于学习的压缩方法更高的检测精度（10%提升）。&lt;h4&gt;结论&lt;/h4&gt;RPCGC方法在保证点云数据准确性的同时，实现了高压缩比，为点云数据的存储和传输提供了有效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云数据在自动驾驶、虚拟现实和机器人等应用中至关重要。然而，其大量数据体积在存储和传输中带来了显著挑战。为了获得高压缩比，关键语义细节通常会受到严重损害，导致保证下游任务准确性的困难。为了解决这个问题，我们首次提出了一种新的区域兴趣（ROI）引导点云几何压缩（RPCGC）方法，用于人类和机器视觉。我们的框架采用双分支并行结构，其中基础层编码和解码点云的简化版本，增强层通过关注几何细节来细化这一版本。此外，增强层的残差信息通过ROI预测网络进行细化。该网络生成掩码信息，然后将其纳入残差中，作为强大的监督信号。此外，我们在速率-失真（RD）优化过程中巧妙地应用了这些掩码细节，每个点在失真计算中都有权重。我们的损失函数包括RD损失和检测损失，以更好地指导机器的点云编码。实验结果表明，RPCGC在ScanNet和SUN RGB-D数据集上实现了比一些基于学习的压缩方法在高速率下更好的压缩性能和检测精度（10%提升）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud data is pivotal in applications like autonomous driving, virtualreality, and robotics. However, its substantial volume poses significantchallenges in storage and transmission. In order to obtain a high compressionratio, crucial semantic details usually confront severe damage, leading todifficulties in guaranteeing the accuracy of downstream tasks. To tackle thisproblem, we are the first to introduce a novel Region of Interest (ROI)-guidedPoint Cloud Geometry Compression (RPCGC) method for human and machine vision.Our framework employs a dual-branch parallel structure, where the base layerencodes and decodes a simplified version of the point cloud, and theenhancement layer refines this by focusing on geometry details. Furthermore,the residual information of the enhancement layer undergoes refinement throughan ROI prediction network. This network generates mask information, which isthen incorporated into the residuals, serving as a strong supervision signal.Additionally, we intricately apply these mask details in the Rate-Distortion(RD) optimization process, with each point weighted in the distortioncalculation. Our loss function includes RD loss and detection loss to betterguide point cloud encoding for the machine. Experiment results demonstrate thatRPCGC achieves exceptional compression performance and better detectionaccuracy (10% gain) than some learning-based compression methods at highbitrates in ScanNet and SUN RGB-D datasets.</description>
      <author>example@mail.com (Xie Liang, Gao Wei, Zhenghui Ming, Li Ge)</author>
      <guid isPermaLink="false">2504.14240v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>CHAINSFORMER: Numerical Reasoning on Knowledge Graphs from a Chain Perspective</title>
      <link>http://arxiv.org/abs/2504.14282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICDE 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ChainsFormer的新型链式框架，用于支持知识图谱中的数值推理，通过构建逻辑链和扩展推理深度，提高了推理准确性和透明度。&lt;h4&gt;背景&lt;/h4&gt;在知识图谱中，数值属性在描述实体和关系方面变得越来越重要，而现有方法如图神经网络（GNN）和知识图谱嵌入（KGE）在利用逻辑路径方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的局限性，提出ChainsFormer，旨在提高数值推理的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;ChainsFormer通过以下方式实现：1）显式构建逻辑链；2）扩展推理深度到多跳；3）引入关系-属性链（RA-Chains）来模拟顺序推理模式；4）采用序列上下文学习来捕捉多跳推理的逐步性质；5）提出双曲亲和力评分机制以选择相关的逻辑链；6）整合注意力机制的数值推理器以识别关键推理路径。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ChainsFormer在性能上显著优于现有方法，实现了高达20.0%的性能提升。&lt;h4&gt;结论&lt;/h4&gt;ChainsFormer框架在数值推理方面表现优异，为知识图谱推理提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Reasoning over Knowledge Graphs (KGs) plays a pivotal role in knowledge graph completion or question answering systems, providing richer and more accurate triples and attributes. As numerical attributes become increasingly essential in characterizing entities and relations in KGs, the ability to reason over these attributes has gained significant importance. Existing graph-based methods such as Graph Neural Networks (GNNs) and Knowledge Graph Embeddings (KGEs), primarily focus on aggregating homogeneous local neighbors and implicitly embedding diverse triples. However, these approaches often fail to fully leverage the potential of logical paths within the graph, limiting their effectiveness in exploiting the reasoning process. To address these limitations, we propose ChainsFormer, a novel chain-based framework designed to support numerical reasoning. Chainsformer not only explicitly constructs logical chains but also expands the reasoning depth to multiple hops. Specially, we introduce Relation-Attribute Chains (RA-Chains), a specialized logic chain, to model sequential reasoning patterns. ChainsFormer captures the step-by-step nature of multi-hop reasoning along RA-Chains by employing sequential in-context learning. To mitigate the impact of noisy chains, we propose a hyperbolic affinity scoring mechanism that selects relevant logic chains in a variable-resolution space. Furthermore, ChainsFormer incorporates an attention-based numerical reasoner to identify critical reasoning paths, enhancing both reasoning accuracy and transparency. Experimental results demonstrate that ChainsFormer significantly outperforms state-of-the-art methods, achieving up to a 20.0% improvement in performance. The implementations are available at https://github.com/zhaodazhuang2333/ChainsFormer.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reasoning over Knowledge Graphs (KGs) plays a pivotal role in knowledge graphcompletion or question answering systems, providing richer and more accuratetriples and attributes. As numerical attributes become increasingly essentialin characterizing entities and relations in KGs, the ability to reason overthese attributes has gained significant importance. Existing graph-basedmethods such as Graph Neural Networks (GNNs) and Knowledge Graph Embeddings(KGEs), primarily focus on aggregating homogeneous local neighbors andimplicitly embedding diverse triples. However, these approaches often fail tofully leverage the potential of logical paths within the graph, limiting theireffectiveness in exploiting the reasoning process. To address theselimitations, we propose ChainsFormer, a novel chain-based framework designed tosupport numerical reasoning. Chainsformer not only explicitly constructslogical chains but also expands the reasoning depth to multiple hops.Specially, we introduces Relation-Attribute Chains (RA-Chains), a specializedlogic chain, to model sequential reasoning patterns. ChainsFormer captures thestep-by-step nature of multi-hop reasoning along RA-Chains by employingsequential in-context learning. To mitigate the impact of noisy chains, wepropose a hyperbolic affinity scoring mechanism that selects relevant logicchains in a variable-resolution space. Furthermore, ChainsFormer incorporatesan attention-based numerical reasoner to identify critical reasoning paths,enhancing both reasoning accuracy and transparency. Experimental resultsdemonstrate that ChainsFormer significantly outperforms state-of-the-artmethods, achieving up to a 20.0% improvement in performance. Theimplementations are available athttps://github.com/zhaodazhuang2333/ChainsFormer.</description>
      <author>example@mail.com (Ze Zhao, Bin Lu, Xiaoying Gan, Gu Tang, Luoyi Fu, Xinbing Wang)</author>
      <guid isPermaLink="false">2504.14282v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Modality Guidance to Enhance VFM-based Feature Fusion for UDA in 3D Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.14231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了视觉基础模型（VFMs）在3D语义分割任务中的应用，特别是从标记源数据到无标记目标数据的适应能力。&lt;h4&gt;背景&lt;/h4&gt;VFMs已成为图像分类、图像分割和对象定位等视觉任务的默认选择，同时也可用于利用跨模态信息（如配对图像数据）的下游3D任务。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用VFMs从标记源数据迁移到无标记目标数据，以实现基于LiDAR的3D语义分割。&lt;h4&gt;方法&lt;/h4&gt;提出了一种方法，该方法使用配对的2D-3D（图像和点云）数据，并依赖VFM的鲁棒（跨域）特征来训练3D骨干网络。该方法的核心是一个融合网络，该网络由图像和点云流引导，其相对贡献根据目标域进行调整。&lt;h4&gt;主要发现&lt;/h4&gt;与现有最佳方法相比，该方法在多个设置中实现了显著的性能提升，平均提高了6.5 mIoU。&lt;h4&gt;结论&lt;/h4&gt;验证了VFMs在3D语义分割任务中的有效性和迁移学习的能力，特别是在处理从标记源到无标记目标数据的转换时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Foundation Models (VFMs) have become a de facto choice for manydownstream vision tasks, like image classification, image segmentation, andobject localization. However, they can also provide significant utility fordownstream 3D tasks that can leverage the cross-modal information (e.g., frompaired image data). In our work, we further explore the utility of VFMs foradapting from a labeled source to unlabeled target data for the task ofLiDAR-based 3D semantic segmentation. Our method consumes paired 2D-3D (imageand point cloud) data and relies on the robust (cross-domain) features from aVFM to train a 3D backbone on a mix of labeled source and unlabeled targetdata. At the heart of our method lies a fusion network that is guided by boththe image and point cloud streams, with their relative contributions adjustedbased on the target domain. We extensively compare our proposed methodologywith different state-of-the-art methods in several settings and achieve strongperformance gains. For example, achieving an average improvement of 6.5 mIoU(over all tasks), when compared with the previous state-of-the-art.</description>
      <author>example@mail.com (Johannes Spoecklberger, Wei Lin, Pedro Hermosilla, Sivan Doveh, Horst Possegger, M. Jehanzeb Mirza)</author>
      <guid isPermaLink="false">2504.14231v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Traffic Flow Forecasting: From Transition to Generatation</title>
      <link>http://arxiv.org/abs/2504.14248v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为EMBSFormer的交通流量预测模型，该模型针对现有模型忽略流量生成过程的问题，通过数据分析和相似性分析模块等方法，实现了更准确的流量预测。&lt;h4&gt;背景&lt;/h4&gt;交通流量预测在智能交通系统的交通管理和城市规划中扮演重要角色，现有模型主要关注流量过渡建模，而忽略了流量生成过程。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的多分支相似性转换器EMBSFormer，以解决现有模型在流量生成过程建模上的不足。&lt;h4&gt;方法&lt;/h4&gt;通过数据分析和相似性分析模块，对节点级别的流量生成和图级别的流量过渡进行建模。使用多分支编码捕捉流量生成模式，以及时空自注意力机制和图神经网络（GNN）以及时间卷积来建模节点间的交互。&lt;h4&gt;主要发现&lt;/h4&gt;EMBSFormer在长期和短期预测任务上均优于基线模型，并且参数数量相比基于流量过渡建模的模型减少了18%，但性能相同。&lt;h4&gt;结论&lt;/h4&gt;EMBSFormer能够更有效地预测交通流量，并在实际应用中具有较好的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Traffic flow prediction plays an important role in Intelligent Transportation Systems in traffic management and urban planning. There have been extensive successful works in this area. However, these approaches focus only on modelling the flow transition and ignore the flow generation process, which manifests itself in two ways: (i) The models are based on Markovian assumptions, ignoring the multi-periodicity of the flow generation in nodes. (ii) The same structure is designed to encode both the transition and generation processes, ignoring the differences between them. To address these problems, we propose an Effective Multi-Branch Similarity Transformer for Traffic Flow Prediction, namely EMBSFormer. Through data analysis, we find that the factors affecting traffic flow include node-level traffic generation and graph-level traffic transition, which describe the multi-periodicity and interaction pattern of nodes, respectively. Specifically, to capture traffic generation patterns, we propose a similarity analysis module that supports multi-branch encoding to dynamically expand significant cycles. For traffic transition, we employ a temporal and spatial self-attention mechanism to maintain global node interactions, and use GNN and time conv to model local node interactions, respectively. Model performance is evaluated on three real-world datasets on both long-term and short-term prediction tasks. Experimental results show that EMBSFormer outperforms baselines on both tasks. Moreover, compared to models based on flow transition modelling (e.g. GMAN, 513k), the variant of EMBSFormer (93K) only uses 18% of the parameters, achieving the same performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic flow prediction plays an important role in Intelligent TransportationSystems in traffic management and urban planning. There have been extensivesuccessful works in this area. However, these approaches focus only onmodelling the flow transition and ignore the flow generation process, whichmanifests itself in two ways: (i) The models are based on Markovianassumptions, ignoring the multi-periodicity of the flow generation in nodes.(ii) The same structure is designed to encode both the transition andgeneration processes, ignoring the differences between them. To address theseproblems, we propose an Effective Multi-Branch Similarity Transformer forTraffic Flow Prediction, namely EMBSFormer. Through data analysis, we find thatthe factors affecting traffic flow include node-level traffic generation andgraph-level traffic transition, which describe the multi-periodicity andinteraction pattern of nodes, respectively. Specifically, to capture trafficgeneration patterns, we propose a similarity analysis module that supportsmulti-branch encoding to dynamically expand significant cycles. For traffictransition, we employ a temporal and spatial self-attention mechanism tomaintain global node interactions, and use GNN and time conv to model localnode interactions, respectively. Model performance is evaluated on threereal-world datasets on both long-term and short-term prediction tasks.Experimental results show that EMBSFormer outperforms baselines on both tasks.Moreover, compared to models based on flow transition modelling (e.g. GMAN,513k), the variant of EMBSFormer(93K) only uses 18\% of the parameters,achieving the same performance.</description>
      <author>example@mail.com (Li Shijiao, Ma Zhipeng, He Huajun, Chen Haiyue)</author>
      <guid isPermaLink="false">2504.14248v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Transformation of audio embeddings into interpretable, concept-based representations</title>
      <link>http://arxiv.org/abs/2504.14076v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to International Joint Conference on Neural Networks (IJCNN)  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了音频神经网络中提取的音频嵌入的语义可解释性，并提出了一种基于对比学习的模型CLAP，用于将音频和文本嵌入到共享的嵌入空间中，以实现更好的可解释性。&lt;h4&gt;背景&lt;/h4&gt;音频神经网络在音频任务上取得了最先进的结果，但其内部音频表示的黑色盒结构使其难以解释。&lt;h4&gt;目的&lt;/h4&gt;探索从音频神经网络中提取的音频嵌入的语义可解释性。&lt;h4&gt;方法&lt;/h4&gt;利用CLAP模型将音频和文本嵌入到共享的嵌入空间中，并通过后处理方法将CLAP嵌入转换为基于概念、稀疏的表示，从而提高可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;基于概念的表示在下游任务上的性能优于或等同于原始音频嵌入，同时提供了可解释性；微调基于概念的表示可以进一步提高其在下游任务上的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的方法和模型能够有效地提高音频嵌入的可解释性，并在下游任务中提升性能。&lt;h4&gt;翻译&lt;/h4&gt;Advancements in audio neural networks have established state-of-the-art results on downstream audio tasks. However, the black-box structure of these models makes it difficult to interpret the information encoded in their internal audio representations. In this work, we explore the semantic interpretability of audio embeddings extracted from these neural networks by leveraging CLAP, a contrastive learning model that brings audio and text into a shared embedding space. We implement a post-hoc method to transform CLAP embeddings into concept-based, sparse representations with semantic interpretability. Qualitative and quantitative evaluations show that the concept-based representations outperform or match the performance of original audio embeddings on downstream tasks while providing interpretability. Additionally, we demonstrate that fine-tuning the concept-based representations can further improve their performance on downstream tasks. Lastly, we publish three audio-specific vocabularies for concept-based interpretability of audio embeddings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in audio neural networks have established state-of-the-artresults on downstream audio tasks. However, the black-box structure of thesemodels makes it difficult to interpret the information encoded in theirinternal audio representations. In this work, we explore the semanticinterpretability of audio embeddings extracted from these neural networks byleveraging CLAP, a contrastive learning model that brings audio and text into ashared embedding space. We implement a post-hoc method to transform CLAPembeddings into concept-based, sparse representations with semanticinterpretability. Qualitative and quantitative evaluations show that theconcept-based representations outperform or match the performance of originalaudio embeddings on downstream tasks while providing interpretability.Additionally, we demonstrate that fine-tuning the concept-based representationscan further improve their performance on downstream tasks. Lastly, we publishthree audio-specific vocabularies for concept-based interpretability of audioembeddings.</description>
      <author>example@mail.com (Alice Zhang, Edison Thomaz, Lie Lu)</author>
      <guid isPermaLink="false">2504.14076v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Real-IAD D3: A Real-World 2D/Pseudo-3D/3D Dataset for Industrial Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.14221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages. Dataset and code: https://realiad4ad.github.io/Real-IAD D3&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Real-IAD D3，一个用于工业异常检测的高精度多模态数据集，并通过有效的方法整合了RGB、点云和伪3D深度信息，以提高检测性能。&lt;h4&gt;背景&lt;/h4&gt;随着工业异常检测（IAD）的复杂性增加，多模态检测方法已成为机器视觉研究的热点。然而，针对IAD的多模态数据集仍然有限。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有数据集在规模和分辨率上的限制，本文旨在提出一个能够更好地模拟真实工业环境的多模态数据集，并提高IAD的检测性能。&lt;h4&gt;方法&lt;/h4&gt;Real-IAD D3数据集结合了RGB图像、微米级3D点云和通过光测立体法生成的伪3D模态。此外，还介绍了一种有效的方法来整合不同模态的信息。&lt;h4&gt;主要发现&lt;/h4&gt;Real-IAD D3数据集提供了更细小的缺陷、多样化的异常和更大的规模，为多模态IAD提供了挑战性的基准。实验表明，这些模态在提高检测鲁棒性和整体IAD性能方面至关重要。&lt;h4&gt;结论&lt;/h4&gt;Real-IAD D3数据集和代码已公开，可供研究使用，为工业异常检测的研究提供了重要的工具和资源。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着工业异常检测（IAD）的复杂性增加，多模态检测方法已成为机器视觉研究的热点。然而，针对IAD的多模态数据集仍然有限。开创性的数据集如MVTec 3D通过整合RGB+3D数据为多模态IAD奠定了基础，但由于规模和分辨率的限制，仍然面临与真实工业环境之间的差距。为了解决这些挑战，我们引入了Real-IAD D3，这是一个独特地结合了通过光测立体法生成的额外伪3D模态、高分辨率RGB图像和微米级3D点云的高精度多模态数据集。Real-IAD D3具有更细小的缺陷、多样化的异常和20个类别中的更大规模，为多模态IAD提供了一个具有挑战性的基准。此外，我们还介绍了一种有效的方法，该方法整合了RGB、点云和伪-3D深度信息，以利用每个模态的互补优势，提高检测性能。我们的实验强调了这些模态在提高检测鲁棒性和整体IAD性能方面的重要性。该数据集和代码可供研究目的公开访问，网址为https://realiad4ad.github.io/Real-IAD D3。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing complexity of industrial anomaly detection (IAD) haspositioned multimodal detection methods as a focal area of machine visionresearch. However, dedicated multimodal datasets specifically tailored for IADremain limited. Pioneering datasets like MVTec 3D have laid essentialgroundwork in multimodal IAD by incorporating RGB+3D data, but still facechallenges in bridging the gap with real industrial environments due tolimitations in scale and resolution. To address these challenges, we introduceReal-IAD D3, a high-precision multimodal dataset that uniquely incorporates anadditional pseudo3D modality generated through photometric stereo, alongsidehigh-resolution RGB images and micrometer-level 3D point clouds. Real-IAD D3features finer defects, diverse anomalies, and greater scale across 20categories, providing a challenging benchmark for multimodal IAD Additionally,we introduce an effective approach that integrates RGB, point cloud, andpseudo-3D depth information to leverage the complementary strengths of eachmodality, enhancing detection performance. Our experiments highlight theimportance of these modalities in boosting detection robustness and overall IADperformance. The dataset and code are publicly accessible for research purposesat https://realiad4ad.github.io/Real-IAD D3</description>
      <author>example@mail.com (Wenbing Zhu, Lidong Wang, Ziqing Zhou, Chengjie Wang, Yurui Pan, Ruoyi Zhang, Zhuhao Chen, Linjie Cheng, Bin-Bin Gao, Jiangning Zhang, Zhenye Gan, Yuxie Wang, Yulong Chen, Shuguang Qian, Mingmin Chi, Bo Peng, Lizhuang Ma)</author>
      <guid isPermaLink="false">2504.14221v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Dual-channel Heterophilic Message Passing for Graph Fraud Detection</title>
      <link>http://arxiv.org/abs/2504.14205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DHMP的新型框架，用于欺诈检测，以解决现有基于空间图神经网络方法中图结构增强的问题。&lt;h4&gt;背景&lt;/h4&gt;欺诈活动在电子商务、在线评论平台和社交网络等各个领域显著增加，使得欺诈检测变得至关重要。空间图神经网络（GNNs）因其强大的归纳学习能力，在欺诈检测任务中得到了成功应用。&lt;h4&gt;目的&lt;/h4&gt;针对现有方法在消息传递过程中排除异质邻居以适应GNNs的同质偏差，从而可能破坏原始图拓扑并增加预测不确定性的问题，提出DHMP框架。&lt;h4&gt;方法&lt;/h4&gt;DHMP利用异质分离模块将图分为同质和异质子图，以减轻传统GNNs的低通归纳偏差。然后，它独立地应用共享权重来捕获不同频率的信号，并引入了定制的采样策略进行训练。这允许节点根据其标签自适应地平衡各种信号的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界数据集上的大量实验表明，DHMP优于现有方法，突出了分离不同频率信号对于提高欺诈检测的重要性。&lt;h4&gt;结论&lt;/h4&gt;DHMP框架通过分离不同频率的信号，有效提高了欺诈检测的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着各种领域，如电子商务、在线评论平台和社交网络中的欺诈活动显著增加，欺诈检测成为一项关键任务。由于强大的归纳学习能力，空间图神经网络（GNNs）在欺诈检测任务中得到了成功应用。然而，现有的基于空间GNN的方法通常通过在消息传递过程中排除异质邻居来增强图结构，以适应GNNs的同质偏差。不幸的是，这种方法可能会破坏原始图拓扑并增加预测的不确定性。为了解决这些局限性，本文提出了一种新的框架，即双通道异质消息传递（DHMP），用于欺诈检测。DHMP利用异质分离模块将图分为同质和异质子图，减轻了传统GNNs的低通归纳偏差。然后，它独立地应用共享权重来捕获不同频率的信号，并引入了定制的采样策略进行训练。这允许节点根据其标签自适应地平衡各种信号的贡献。在三个真实世界数据集上的大量实验表明，DHMP优于现有方法，突出了分离不同频率信号对于提高欺诈检测的重要性。代码可在https://github.com/shaieesss/DHMP上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fraudulent activities have significantly increased across various domains,such as e-commerce, online review platforms, and social networks, making frauddetection a critical task. Spatial Graph Neural Networks (GNNs) have beensuccessfully applied to fraud detection tasks due to their strong inductivelearning capabilities. However, existing spatial GNN-based methods oftenenhance the graph structure by excluding heterophilic neighbors during messagepassing to align with the homophilic bias of GNNs. Unfortunately, this approachcan disrupt the original graph topology and increase uncertainty inpredictions. To address these limitations, this paper proposes a novelframework, Dual-channel Heterophilic Message Passing (DHMP), for frauddetection. DHMP leverages a heterophily separation module to divide the graphinto homophilic and heterophilic subgraphs, mitigating the low-pass inductivebias of traditional GNNs. It then applies shared weights to capture signals atdifferent frequencies independently and incorporates a customized samplingstrategy for training. This allows nodes to adaptively balance thecontributions of various signals based on their labels. Extensive experimentson three real-world datasets demonstrate that DHMP outperforms existingmethods, highlighting the importance of separating signals with differentfrequencies for improved fraud detection. The code is available athttps://github.com/shaieesss/DHMP.</description>
      <author>example@mail.com (Wenxin Zhang, Jingxing Zhong, Guangzhen Yao, Renda Han, Xiaojian Lin, Zeyu Zhang, Cuicui Luo)</author>
      <guid isPermaLink="false">2504.14205v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Locate 3D: Real-World Object Localization via Self-Supervised Learning in 3D</title>
      <link>http://arxiv.org/abs/2504.14151v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了LOCATE 3D模型，该模型能够从描述性表达中定位3D场景中的物体，如'沙发和灯之间的那个小咖啡桌'。该模型在标准参照性基准测试中达到了新的技术水平，并展示了强大的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的3D场景物体定位方法通常依赖于复杂的模型和大量的标注数据。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够从自然语言描述中定位3D场景中物体的模型，并实现其在实际应用中的部署。&lt;h4&gt;方法&lt;/h4&gt;LOCATE 3D模型使用3D-JEPA自监督学习算法，该算法适用于传感器点云数据，并使用CLIP和DINO等2D基础模型对3D点云进行特征化。模型通过在潜在空间中进行掩码预测作为前缀任务来辅助自监督学习。训练完成后，3D-JEPA编码器与语言条件解码器联合微调，以预测3D掩码和边界框。&lt;h4&gt;主要发现&lt;/h4&gt;LOCATE 3D在标准参照性基准测试中达到了新的技术水平，并展示了强大的泛化能力。此外，还引入了LOCATE 3D DATASET，这是一个新的3D参照性基准数据集，包含超过130K个标注，涵盖了多个捕获设置。&lt;h4&gt;结论&lt;/h4&gt;LOCATE 3D模型能够有效地从自然语言描述中定位3D场景中的物体，并具有强大的泛化能力，适合在机器人和平板增强现实设备上部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present LOCATE 3D, a model for localizing objects in 3D scenes fromreferring expressions like "the small coffee table between the sofa and thelamp." LOCATE 3D sets a new state-of-the-art on standard referential groundingbenchmarks and showcases robust generalization capabilities. Notably, LOCATE 3Doperates directly on sensor observation streams (posed RGB-D frames), enablingreal-world deployment on robots and AR devices. Key to our approach is 3D-JEPA,a novel self-supervised learning (SSL) algorithm applicable to sensor pointclouds. It takes as input a 3D pointcloud featurized using 2D foundation models(CLIP, DINO). Subsequently, masked prediction in latent space is employed as apretext task to aid the self-supervised learning of contextualized pointcloudfeatures. Once trained, the 3D-JEPA encoder is finetuned alongside alanguage-conditioned decoder to jointly predict 3D masks and bounding boxes.Additionally, we introduce LOCATE 3D DATASET, a new dataset for 3D referentialgrounding, spanning multiple capture setups with over 130K annotations. Thisenables a systematic study of generalization capabilities as well as a strongermodel.</description>
      <author>example@mail.com (Sergio Arnaud, Paul McVay, Ada Martin, Arjun Majumdar, Krishna Murthy Jatavallabhula, Phillip Thomas, Ruslan Partsey, Daniel Dugas, Abha Gejji, Alexander Sax, Vincent-Pierre Berges, Mikael Henaff, Ayush Jain, Ang Cao, Ishita Prasad, Mrinal Kalakrishnan, Michael Rabbat, Nicolas Ballas, Mido Assran, Oleksandr Maksymets, Aravind Rajeswaran, Franziska Meier)</author>
      <guid isPermaLink="false">2504.14151v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex</title>
      <link>http://arxiv.org/abs/2504.12474v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BiGTex的新型架构，用于解决文本归属性图（TAGs）的表示学习问题，该架构通过堆叠图-文本融合单元，紧密整合了图神经网络（GNNs）和大型语言模型（LLMs）。&lt;h4&gt;背景&lt;/h4&gt;在表示学习过程中，TAGs需要模型同时捕捉节点关联文本的语义丰富性和图的拓扑结构依赖性。GNNs擅长建模拓扑信息，但无法处理非结构化文本；而LLMs擅长文本理解，但通常不了解图结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理TAGs的表示学习方法。&lt;h4&gt;方法&lt;/h4&gt;BiGTex通过堆叠图-文本融合单元，实现文本和结构表示之间的相互注意力，使信息在两个方向上流动，文本影响结构，结构引导文本解释。使用参数高效的微调（LoRA）进行训练，同时冻结LLM以适应特定任务的信号。&lt;h4&gt;主要发现&lt;/h4&gt;在五个基准数据集上的实验表明，BiGTex在节点分类和链接预测方面取得了最先进的性能。消融研究进一步强调了软提示和双向注意力在模型成功中的重要性。&lt;h4&gt;结论&lt;/h4&gt;BiGTex是一种有效的TAGs表示学习方法，在节点分类和链接预测任务中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-attributed graphs (TAGs) present unique challenges in representationlearning by requiring models to capture both the semantic richness ofnode-associated texts and the structural dependencies of the graph. While graphneural networks (GNNs) excel at modeling topological information, they lack thecapacity to process unstructured text. Conversely, large language models (LLMs)are proficient in text understanding but are typically unaware of graphstructure. In this work, we propose BiGTex (Bidirectional Graph Text), a novelarchitecture that tightly integrates GNNs and LLMs through stacked Graph-TextFusion Units. Each unit allows for mutual attention between textual andstructural representations, enabling information to flow in both directions,text influencing structure and structure guiding textual interpretation. Theproposed architecture is trained using parameter-efficient fine-tuning (LoRA),keeping the LLM frozen while adapting to task-specific signals. Extensiveexperiments on five benchmark datasets demonstrate that BiGTex achievesstate-of-the-art performance in node classification and generalizes effectivelyto link prediction. An ablation study further highlights the importance of softprompting and bi-directional attention in the model's success.</description>
      <author>example@mail.com (Azadeh Beiranvand, Seyed Mehdi Vahidipour)</author>
      <guid isPermaLink="false">2504.12474v2</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Temporal Plasticity in Foundation Time Series Models for Incremental Fine-tuning</title>
      <link>http://arxiv.org/abs/2504.14677v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IJCNN 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究调查了时间序列基础模型通过增量学习持续改进性能的能力，发现与传统模型相比，如Time-MoE和Chronos这样的基础模型在预测精度上表现出持续的改进。&lt;h4&gt;背景&lt;/h4&gt;时间序列基础模型在多样化的时间序列预测任务中表现出色，但它们通过增量学习持续改进的能力尚未被探索。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在全面研究这些模型的时序可塑性，即它们通过持续学习渐进式提升性能同时保持现有能力的能力。&lt;h4&gt;方法&lt;/h4&gt;通过在具有分布转移的实际数据集上进行的实验，使用一个新颖的持续学习框架评估了传统的深度学习模型和时间序列基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，在增量微调期间，传统模型会遭受性能下降的问题，而如Time-MoE和Chronos这样的基础模型则在预测精度上展现了持续的改进。&lt;h4&gt;结论&lt;/h4&gt;优化基础模型微调策略可能比开发特定领域的中小型模型更有价值。研究引入了新的评估方法和见解，以开发具有鲁棒持续学习能力的基础时间序列模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：时间序列基础模型在多样化的时间序列预测任务中表现出色，但它们通过增量学习持续改进的能力尚未被探索。我们提出了第一个全面研究这些模型时序可塑性的研究，即它们通过持续学习渐进式提升性能同时保持现有能力的能力。通过在具有分布转移的实际数据集上进行的实验，我们使用一个新颖的持续学习框架评估了传统的深度学习模型和时间序列基础模型。我们的研究揭示了，尽管传统模型在增量微调期间会遭遇性能下降的问题，但如Time-MoE和Chronos这样的基础模型在预测精度上表现出持续的改进。这表明，优化基础模型微调策略可能比开发特定领域的中小型模型更有价值。本研究为开发具有鲁棒持续学习能力的基础时间序列模型引入了新的评估方法和见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series foundation models excel at diverse time series forecasting tasks,but their capacity for continuous improvement through incremental learningremains unexplored. We present the first comprehensive study investigatingthese models' temporal plasticity - their ability to progressively enhanceperformance through continual learning while maintaining existing capabilities.Through experiments on real-world datasets exhibiting distribution shifts, weevaluate both conventional deep learning models and foundation models using anovel continual learning framework. Our findings reveal that while traditionalmodels struggle with performance deterioration during incremental fine-tuning,foundation models like Time-MoE and Chronos demonstrate sustained improvementin predictive accuracy. This suggests that optimizing foundation modelfine-tuning strategies may be more valuable than developing domain-specificsmall models. Our research introduces new evaluation methodologies and insightsfor developing foundation time series models with robust continuous learningcapabilities.</description>
      <author>example@mail.com (Jia Liu, Cheng Jinguo, Xia Fang, Zhenyuan Ma, Yuankai Wu)</author>
      <guid isPermaLink="false">2504.14677v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>HFBRI-MAE: Handcrafted Feature Based Rotation-Invariant Masked Autoencoder for 3D Point Cloud Analysis</title>
      <link>http://arxiv.org/abs/2504.14132v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 9 figures, accepted by IJCNN 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于手工特征的旋转不变掩码自编码器（HFBRI-MAE），用于改进3D点云分析中的自监督学习方法，特别是通过解决现有MAE方法在处理任意旋转点云时的旋转不变性问题。&lt;h4&gt;背景&lt;/h4&gt;自监督学习（SSL）在3D点云分析中取得了显著成功，但基于掩码自编码器（MAE）的方法缺乏旋转不变性，导致在现实场景中处理任意旋转点云时性能下降。&lt;h4&gt;目的&lt;/h4&gt;为了解决MAE方法的旋转不变性问题，提出HFBRI-MAE框架，确保在不同方向上稳定地学习特征。&lt;h4&gt;方法&lt;/h4&gt;HFBRI-MAE通过利用旋转不变的局部和全局特征进行标记嵌入和位置嵌入，有效消除旋转依赖性，同时保留丰富的几何结构。此外，将重建目标定义为输入的规范对齐版本，以减少旋转模糊。&lt;h4&gt;主要发现&lt;/h4&gt;在ModelNet40、ScanObjectNN和ShapeNetPart上的大量实验表明，HFBRI-MAE在物体分类、分割和少样本学习方面均优于现有方法，突显了其在现实世界3D应用中的鲁棒性和强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;HFBRI-MAE是一种有效的3D点云分析方法，能够处理任意旋转的点云，并展现出优异的性能和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has demonstrated remarkable success in 3Dpoint cloud analysis, particularly through masked autoencoders (MAEs). However,existing MAE-based methods lack rotation invariance, leading to significantperformance degradation when processing arbitrarily rotated point clouds inreal-world scenarios. To address this limitation, we introduce HandcraftedFeature-Based Rotation-Invariant Masked Autoencoder (HFBRI-MAE), a novelframework that refines the MAE design with rotation-invariant handcraftedfeatures to ensure stable feature learning across different orientations. Byleveraging both rotation-invariant local and global features for tokenembedding and position embedding, HFBRI-MAE effectively eliminates rotationaldependencies while preserving rich geometric structures. Additionally, weredefine the reconstruction target to a canonically aligned version of theinput, mitigating rotational ambiguities. Extensive experiments on ModelNet40,ScanObjectNN, and ShapeNetPart demonstrate that HFBRI-MAE consistentlyoutperforms existing methods in object classification, segmentation, andfew-shot learning, highlighting its robustness and strong generalizationability in real-world 3D applications.</description>
      <author>example@mail.com (Xuanhua Yin, Dingxin Zhang, Jianhui Yu, Weidong Cai)</author>
      <guid isPermaLink="false">2504.14132v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Statistical Analysis and End-to-End Performance Evaluation of Traffic Models for Automotive Data</title>
      <link>http://arxiv.org/abs/2504.14017v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对自动驾驶技术，研究了基于LiDAR传感器的数据统计特性，提出了用于数据压缩的统计模型，并通过实验验证了模型的有效性。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶是交通运输领域的一次重大变革，可以提高安全性、优化交通拥堵和减少燃料消耗。自动驾驶车辆需要依靠先进的传感器和车载计算系统进行导航，同时也需要通过V2X通信与其他车辆进行协作。&lt;h4&gt;目的&lt;/h4&gt;研究自动驾驶车辆中的LiDAR传感器数据，提出用于数据压缩的统计模型，以优化V2X通信。&lt;h4&gt;方法&lt;/h4&gt;本文对汽车数据进行统计描述，特别是针对LiDAR传感器，提供了原始和压缩点云大小的模型。使用统计交通模型进行仿真，并通过Kolmogorov-Smirnoff测试和Bootstrap重采样方案进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;统计模型可以提供比真实数据更快的仿真速度、更低的存储需求，以及更大的应用设计灵活性。与真实数据相比，使用统计模型在延迟和吞吐量方面具有可比性。&lt;h4&gt;结论&lt;/h4&gt;提出的统计模型能够有效地用于自动驾驶车辆的数据压缩，提高了V2X通信的效率。&lt;h4&gt;翻译&lt;/h4&gt;Autonomous driving is a major paradigm shift in transportation, with the potential to enhance safety, optimize traffic congestion, and reduce fuel consumption. Although autonomous vehicles rely on advanced sensors and on-board computing systems to navigate without human control, full awareness of the driving environment also requires a cooperative effort via Vehicle-To-Everything (V2X) communication. Specifically, vehicles send and receive sensor perceptions to/from other vehicles to extend perception beyond their own sensing range. However, transmitting large volumes of data can be challenging for current V2X communication technologies, so data compression represents a crucial solution to reduce the message size and link congestion. In this paper, we present a statistical characterization of automotive data, focusing on LiDAR sensors. Notably, we provide models for the size of both raw and compressed point clouds. The use of statistical traffic models offers several advantages compared to using real data, such as faster simulations, reduced storage requirements, and greater flexibility in the application design. Furthermore, statistical models can be used for understanding traffic patterns and analyzing statistics, which is crucial to design and optimize wireless networks. We validate our statistical models via a Kolmogorov-Smirnoff test implementing a Bootstrap Resampling scheme. Moreover, we show via ns-3 simulations that using statistical models yields comparable results in terms of latency and throughput compared to real data, which also demonstrates the accuracy of the models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous driving is a major paradigm shift in transportation, with thepotential to enhance safety, optimize traffic congestion, and reduce fuelconsumption. Although autonomous vehicles rely on advanced sensors and on-boardcomputing systems to navigate without human control, full awareness of thedriving environment also requires a cooperative effort viaVehicle-To-Everything (V2X) communication. Specifically, vehicles send andreceive sensor perceptions to/from other vehicles to extend perception beyondtheir own sensing range. However, transmitting large volumes of data can bechallenging for current V2X communication technologies, so data compressionrepresents a crucial solution to reduce the message size and link congestion.In this paper, we present a statistical characterization of automotive data,focusing on LiDAR sensors. Notably, we provide models for the size of both rawand compressed point clouds. The use of statistical traffic models offersseveral advantages compared to using real data, such as faster simulations,reduced storage requirements, and greater flexibility in the applicationdesign. Furthermore, statistical models can be used for understanding trafficpatterns and analyzing statistics, which is crucial to design and optimizewireless networks. We validate our statistical models via a Kolmogorov-Smirnofftest implementing a Bootstrap Resampling scheme. Moreover, we show via ns-3simulations that using statistical models yields comparable results in terms oflatency and throughput compared to real data, which also demonstrates theaccuracy of the models.</description>
      <author>example@mail.com (Marcello Bullo, Amir Ashtari Gargari, Paolo Testolina, Michele Zorzi, Marco Giordani)</author>
      <guid isPermaLink="false">2504.14017v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>SG-Reg: Generalizable and Efficient Scene Graph Registration</title>
      <link>http://arxiv.org/abs/2504.14440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Transactions Robotics Regular Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将两个刚体语义场景图进行注册的挑战，并设计了一种新的方法来提高注册的成功率。&lt;h4&gt;背景&lt;/h4&gt;在自主代理需要将其地图与远程代理或先前地图进行注册时，场景图的注册是一个基本能力。传统的语义辅助注册和基于学习的场景图注册在现实世界中应用受限。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，设计了一种场景图网络来编码语义节点的多种模态，并融合这些模态以创建紧凑的语义节点特征。&lt;h4&gt;方法&lt;/h4&gt;该方法包括使用匹配层以粗到细的方式寻找对应关系，以及使用鲁棒的姿态估计器来决定变换。此外，还设计了一种新的数据生成方法，使用视觉基础模型和语义映射模块来重建语义场景图。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在两个代理SLAM基准测试中验证有效，显著优于手工制作的基线，在注册成功率方面表现优异。与视觉环路闭合网络相比，该方法在通信带宽方面具有优势。&lt;h4&gt;结论&lt;/h4&gt;该方法在多代理任务中需要更少的GPU资源和通信带宽，并显著提高了注册的成功率。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了将两个刚体语义场景图进行注册的挑战，并设计了一种新的方法来提高注册的成功率。为了解决这些挑战，设计了一种场景图网络来编码语义节点的多种模态，并融合这些模态以创建紧凑的语义节点特征。该方法包括使用匹配层以粗到细的方式寻找对应关系，以及使用鲁棒的姿态估计器来决定变换。此外，还设计了一种新的数据生成方法，使用视觉基础模型和语义映射模块来重建语义场景图。该方法在两个代理SLAM基准测试中验证有效，显著优于手工制作的基线，在注册成功率方面表现优异。与视觉环路闭合网络相比，该方法在通信带宽方面具有优势。该方法在多代理任务中需要更少的GPU资源和通信带宽，并显著提高了注册的成功率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hkust-aerial-robotics/sg-reg&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenges of registering two rigid semantic scenegraphs, an essential capability when an autonomous agent needs to register itsmap against a remote agent, or against a prior map. The hand-crafteddescriptors in classical semantic-aided registration, or the ground-truthannotation reliance in learning-based scene graph registration, impede theirapplication in practical real-world environments. To address the challenges, wedesign a scene graph network to encode multiple modalities of semantic nodes:open-set semantic feature, local topology with spatial awareness, and shapefeature. These modalities are fused to create compact semantic node features.The matching layers then search for correspondences in a coarse-to-fine manner.In the back-end, we employ a robust pose estimator to decide transformationaccording to the correspondences. We manage to maintain a sparse andhierarchical scene representation. Our approach demands fewer GPU resources andfewer communication bandwidth in multi-agent tasks. Moreover, we design a newdata generation approach using vision foundation models and a semantic mappingmodule to reconstruct semantic scene graphs. It differs significantly fromprevious works, which rely on ground-truth semantic annotations to generatedata. We validate our method in a two-agent SLAM benchmark. It significantlyoutperforms the hand-crafted baseline in terms of registration success rate.Compared to visual loop closure networks, our method achieves a slightly higherregistration recall while requiring only 52 KB of communication bandwidth foreach query frame. Code available at:\href{http://github.com/HKUST-Aerial-Robotics/SG-Reg}{http://github.com/HKUST-Aerial-Robotics/SG-Reg}.</description>
      <author>example@mail.com (Chuhao Liu, Zhijian Qiao, Jieqi Shi, Ke Wang, Peize Liu, Shaojie Shen)</author>
      <guid isPermaLink="false">2504.14440v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning on Graphs for Mobile Network Topology Generation</title>
      <link>http://arxiv.org/abs/2504.13991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 6 figures, submitted to IEEE Networking Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了移动网络拓扑结构的重要性，并提出了基于图深度学习的方法来确定移动网络的移动关系（边），同时评估了不同方法的准确性和精确度。&lt;h4&gt;背景&lt;/h4&gt;移动网络由地理区域内的无线电节点组成，这些节点的连接关系（即移动网络拓扑）对于网络基础设施的建设至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究旨在使用图深度学习方法确定移动网络的移动关系，并评估其在实际移动网络中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;研究使用了基于图的深度学习方法和自动邻接关系（ANR）设置的可信移动关系来训练模型，并进行了综合实验以评估两种深度学习模型：图神经网络（GNN）和多层感知器。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，考虑图结构可以改善结果，这促使了GNN的使用。此外，通过基于无线电节点之间距离的启发式方法减少训练时间，显著提高了精确度和准确度。&lt;h4&gt;结论&lt;/h4&gt;图神经网络模型和多层感知器在移动网络拓扑结构分析中是有效的，且启发式方法可以有效地提高模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile networks consist of interconnected radio nodes strategicallypositioned across various geographical regions to provide connectivityservices. The set of relations between these radio nodes, referred to as the\emph{mobile network topology}, is vital in the construction of the networkinginfrastructure. Typically, the connections between radio nodes and theirassociated cells are defined by software features that establish mobilityrelations (referred to as \emph{edges} in this paper) within the mobile networkgraph through heuristic methods. Although these approaches are efficient, theyencounter significant limitations, particularly since edges can only beestablished prior to the installation of physical hardware.  In this work, we use graph-based deep learning methods to determine mobilityrelations (edges), trained on radio node configuration data and reliablemobility relations set by Automatic Neighbor Relations (ANR) in stablenetworks. This paper focuses on measuring the accuracy and precision ofdifferent graph-based deep learning approaches applied to real-world mobilenetworks. We evaluated two deep learning models. Our comprehensive experimentson Telecom datasets obtained from operational Telecom Networks demonstrate theeffectiveness of the graph neural network (GNN) model and multilayerperceptron. Our evaluation showed that considering graph structure improvesresults, which motivates the use of GNNs. Additionally, we investigated the useof heuristics to reduce the training time based on the distance between radionodes to eliminate irrelevant cases. Our investigation showed that the use ofthese heuristics improved precision and accuracy considerably.</description>
      <author>example@mail.com (Felix Nannesson Meli, Johan Tell, Shirwan Piroti, Tahar Zanouda, Elias Jarlebring)</author>
      <guid isPermaLink="false">2504.13991v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating LLM Inference with Flexible N:M Sparsity via A Fully Digital Compute-in-Memory Accelerator</title>
      <link>http://arxiv.org/abs/2504.14365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种灵活的N:M稀疏性选择方法FLOW，以及一种灵活的、低开销的数字内存计算架构FlexCiM，用于解决大型语言模型（LLM）稀疏化过程中遇到的表达能力受限和硬件开销过大的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的LLM稀疏化方法限制了模型的表达能力，而支持多种N:M模式则增加了硬件的开销。&lt;h4&gt;目的&lt;/h4&gt;为了解决LLM稀疏化中的挑战，提出了一种新的稀疏性选择方法和计算架构。&lt;h4&gt;方法&lt;/h4&gt;提出了FLOW方法，通过同时考虑异常值的存在和分布来识别最优的层间N和M值。FlexCiM架构通过将数字CiM宏分区成更小的子宏，并通过分配和合并机制适应不同的N和M值来支持不同的稀疏模式。&lt;h4&gt;主要发现&lt;/h4&gt;FLOW在Transformer和递归基础的状态空间模型（SSMs）上优于现有方法，准确率提高了36%。FlexCiM比现有稀疏加速器实现了高达1.75倍的推理延迟降低和1.5倍的能耗降低。&lt;h4&gt;结论&lt;/h4&gt;FLOW和FlexCiM为LLM的稀疏化提供了有效的解决方案，显著提高了模型性能和计算效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a flexible N:M sparsity selection method called FLOW and a flexible, low-overhead digital compute-in-memory architecture called FlexCiM to address the challenges of large language model (LLM) sparsification, which include limited expressivity and high hardware overhead.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language model (LLM) pruning with fixed N:M structured sparsitysignificantly limits the expressivity of the sparse model, yielding sub-optimalperformance. In contrast, supporting multiple N:M patterns to provide sparserepresentational freedom introduces costly overhead in hardware. To addressthese challenges for LLMs, we first present a flexible layer-wiseoutlier-density-aware N:M sparsity (FLOW) selection method. FLOW enables theidentification of optimal layer-wise N and M values (from a given range) bysimultaneously accounting for the presence and distribution of outliers,allowing a higher degree of representational freedom. To deploy sparse modelswith such N:M flexibility, we then introduce a flexible, low-overhead digitalcompute-in-memory architecture (FlexCiM). FlexCiM supports diverse sparsitypatterns by partitioning a digital CiM (DCiM) macro into smaller sub-macros,which are adaptively aggregated and disaggregated through distribution andmerging mechanisms for different N and M values. Extensive experiments on bothtransformer-based and recurrence-based state space foundation models (SSMs)demonstrate that FLOW outperforms existing alternatives with an accuracyimprovement of up to 36%, while FlexCiM achieves up to 1.75x lower inferencelatency and 1.5x lower energy consumption compared to existing sparseaccelerators. Code is available at: https://github.com/FLOW-open-project/FLOW</description>
      <author>example@mail.com (Akshat Ramachandran, Souvik Kundu, Arnab Raha, Shamik Kundu, Deepak K. Mathaikutty, Tushar Krishna)</author>
      <guid isPermaLink="false">2504.14365v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Visual Consensus Prompting for Co-Salient Object Detection</title>
      <link>http://arxiv.org/abs/2504.14254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对共显著目标检测（CoSOD）任务的高效且参数节约的架构，解决了现有方法的两个主要限制。&lt;h4&gt;背景&lt;/h4&gt;现有的CoSOD方法通常采用三阶段架构（编码、共识提取与分散、预测）和全微调范式。&lt;h4&gt;目的&lt;/h4&gt;针对现有方法的局限性，提出一种交互有效且参数高效的CoSOD任务架构。&lt;h4&gt;方法&lt;/h4&gt;该方法引入了一种参数高效的提示调整范式，并将共识嵌入到提示中，形成特定的视觉共识提示（VCP）。通过限制可调整参数，使共识提示生成器（CPG）专注于共显著表示，并生成共识提示。共识提示分散器（CPD）利用共识提示形成特定任务的视觉共识提示，从而激发预训练模型在CoSOD任务上的潜力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的VCP优于13个先进的全微调模型，在最具挑战性的CoCA数据集上实现了F_m指标的新纪录（提高了6.8%）。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在CoSOD任务上取得了显著的性能提升，并提供了高效的参数使用和知识表示。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现有的共显著目标检测（CoSOD）方法通常采用三阶段架构（即编码、共识提取与分散和预测）以及典型的全微调范式。虽然它们带来了一定的好处，但存在两个显著的局限性：1）该架构依赖于编码特征来促进共识提取，但精心提取的共识不能及时为编码阶段提供指导。2）该范式涉及全局更新模型的全部参数，这既参数效率低下，又阻碍了基础模型在此任务中有效表示知识。因此，本文提出了一种针对CoSOD任务的高效且参数节约的交互式架构，解决了两个关键局限性。它首次引入了一种参数高效的提示调整范式，并将共识无缝嵌入到提示中，形成特定任务的视觉共识提示（VCP）。我们的VCP旨在通过制定特定任务的视觉共识提示来最小化可调整参数，以使冻结的基础模型在CoSOD任务上表现更好。具体而言，有目的的共识提示生成器（CPG）的主要见解是强制执行有限的可调整参数，以关注共显著表示并生成共识提示。制定的共识提示分散器（CPD）利用共识提示形成特定任务的视觉共识提示，从而激发预训练模型在解决CoSOD任务中的强大潜力。广泛的实验表明，我们的简洁VCP优于13个最先进的全微调模型，在最具挑战性的CoCA数据集上实现了新的最先进水平（F_m指标提高了6.8%）。源代码可在https://github.com/WJ-CV/VCP上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wj-cv/vcp&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing co-salient object detection (CoSOD) methods generally employ athree-stage architecture (i.e., encoding, consensus extraction &amp; dispersion,and prediction) along with a typical full fine-tuning paradigm. Although theyyield certain benefits, they exhibit two notable limitations: 1) Thisarchitecture relies on encoded features to facilitate consensus extraction, butthe meticulously extracted consensus does not provide timely guidance to theencoding stage. 2) This paradigm involves globally updating all parameters ofthe model, which is parameter-inefficient and hinders the effectiverepresentation of knowledge within the foundation model for this task.Therefore, in this paper, we propose an interaction-effective andparameter-efficient concise architecture for the CoSOD task, addressing two keylimitations. It introduces, for the first time, a parameter-efficient prompttuning paradigm and seamlessly embeds consensus into the prompts to formulatetask-specific Visual Consensus Prompts (VCP). Our VCP aims to induce the frozenfoundation model to perform better on CoSOD tasks by formulating task-specificvisual consensus prompts with minimized tunable parameters. Concretely, theprimary insight of the purposeful Consensus Prompt Generator (CPG) is toenforce limited tunable parameters to focus on co-salient representations andgenerate consensus prompts. The formulated Consensus Prompt Disperser (CPD)leverages consensus prompts to form task-specific visual consensus prompts,thereby arousing the powerful potential of pre-trained models in addressingCoSOD tasks. Extensive experiments demonstrate that our concise VCP outperforms13 cutting-edge full fine-tuning models, achieving the new state of the art(with 6.8% improvement in F_m metrics on the most challenging CoCA dataset).Source code has been available at https://github.com/WJ-CV/VCP.</description>
      <author>example@mail.com (Jie Wang, Nana Yu, Zihao Zhang, Yahong Han)</author>
      <guid isPermaLink="false">2504.14254v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>PVUW 2025 Challenge Report: Advances in Pixel-level Understanding of Complex Videos in the Wild</title>
      <link>http://arxiv.org/abs/2504.11326v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Workshop Page: https://pvuw.github.io/. arXiv admin note: text  overlap with arXiv:2504.00476, arXiv:2504.05178&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该报告全面概述了在CVPR 2025期间举办的第4届像素级视频理解野外挑战赛，总结了挑战结果、参与的方法和未来的研究方向。&lt;h4&gt;背景&lt;/h4&gt;挑战赛与CVPR 2025联合举办，旨在推动视频理解技术的发展。&lt;h4&gt;目的&lt;/h4&gt;提供对复杂视频分割领域当前状态和新兴趋势的深入理解。&lt;h4&gt;方法&lt;/h4&gt;挑战赛包含两个赛道：MOSE（复杂场景视频对象分割）和MeViS（基于运动的视频分割），并引入了新的、更具挑战性的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;通过详细评估和分析，挑战赛揭示了复杂视频分割领域的最新进展和趋势。&lt;h4&gt;结论&lt;/h4&gt;更多信息可在挑战赛官方网站上找到：https://pvuw.github.io/。&lt;h4&gt;翻译&lt;/h4&gt;This report provides a comprehensive overview of the 4th Pixel-level VideoUnderstanding in the Wild (PVUW) Challenge, held in conjunction with CVPR 2025. It summarizes the challenge outcomes, participating methodologies, and future research directions. The challenge features two tracks: MOSE, which focuses on complex scene video object segmentation, and MeViS, which targets motion-guided, language-based video segmentation. Both tracks introduce new, more challenging datasets designed to better reflect real-world scenarios. Through detailed evaluation and analysis, the challenge offers valuable insights into the current state-of-the-art and emerging trends in complex video segmentation. More information can be found on the workshop website: https://pvuw.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This report provides a comprehensive overview of the 4th Pixel-level VideoUnderstanding in the Wild (PVUW) Challenge, held in conjunction with CVPR 2025.It summarizes the challenge outcomes, participating methodologies, and futureresearch directions. The challenge features two tracks: MOSE, which focuses oncomplex scene video object segmentation, and MeViS, which targetsmotion-guided, language-based video segmentation. Both tracks introduce new,more challenging datasets designed to better reflect real-world scenarios.Through detailed evaluation and analysis, the challenge offers valuableinsights into the current state-of-the-art and emerging trends in complex videosegmentation. More information can be found on the workshop website:https://pvuw.github.io/.</description>
      <author>example@mail.com (Henghui Ding, Chang Liu, Nikhila Ravi, Shuting He, Yunchao Wei, Song Bai, Philip Torr, Kehuan Song, Xinglin Xie, Kexin Zhang, Licheng Jiao, Lingling Li, Shuyuan Yang, Xuqiang Cao, Linnan Zhao, Jiaxuan Zhao, Fang Liu, Mengjiao Wang, Junpei Zhang, Xu Liu, Yuting Yang, Mengru Ma, Hao Fang, Runmin Cong, Xiankai Lu, Zhiyang Chen, Wei Zhang, Tianming Liang, Haichao Jiang, Wei-Shi Zheng, Jian-Fang Hu, Haobo Yuan, Xiangtai Li, Tao Zhang, Lu Qi, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2504.11326v2</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>PRISM: A Unified Framework for Photorealistic Reconstruction and Intrinsic Scene Modeling</title>
      <link>http://arxiv.org/abs/2504.14219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PRISM是一个统一的框架，允许在单个基础模型中执行多种图像生成和编辑任务。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常需要单独的模型或分别推断内在属性，而PRISM通过联合生成所有内在层来保持模态间的一致性。&lt;h4&gt;目的&lt;/h4&gt;提出一个有效的微调策略，从预训练的文本到图像扩散模型生成RGB图像和内在图（X层），并支持多种图像处理任务。&lt;h4&gt;方法&lt;/h4&gt;PRISM通过联合生成所有内在层来维护模态间的一致性，并支持文本到RGBX生成、RGB到X分解和X到RGBX条件生成等多种任务。&lt;h4&gt;主要发现&lt;/h4&gt;PRISM在内在图像分解和条件图像生成方面表现出竞争力，同时保留了基础模型的文本到图像生成能力。&lt;h4&gt;结论&lt;/h4&gt;PRISM是一个高效且功能全面的框架，可以用于多种图像生成和编辑任务，具有广泛的适用性和竞争力。&lt;h4&gt;翻译&lt;/h4&gt;我们提出PRISM，一个统一的框架，它允许在单个基础模型中执行多种图像生成和编辑任务。从预训练的文本到图像扩散模型开始，PRISM提出了一种有效的微调策略，以同时生成RGB图像和内在图（称为X层）。与之前的方法不同，这些方法单独推断内在属性或需要单独的模型进行分解和条件生成，PRISM通过联合生成所有内在层来保持模态间的一致性。它支持多种任务，包括文本到RGBX生成、RGB到X分解和X到RGBX条件生成。此外，PRISM通过在选定的内在层和文本提示上条件化，使全局和局部图像编辑成为可能。大量实验表明，PRISM在内在图像分解和条件图像生成方面都具有竞争力，同时保留了基础模型的文本到图像生成能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present PRISM, a unified framework that enables multiple image generationand editing tasks in a single foundational model. Starting from a pre-trainedtext-to-image diffusion model, PRISM proposes an effective fine-tuning strategyto produce RGB images along with intrinsic maps (referred to as X layers)simultaneously. Unlike previous approaches, which infer intrinsic propertiesindividually or require separate models for decomposition and conditionalgeneration, PRISM maintains consistency across modalities by generating allintrinsic layers jointly. It supports diverse tasks, including text-to-RGBXgeneration, RGB-to-X decomposition, and X-to-RGBX conditional generation.Additionally, PRISM enables both global and local image editing throughconditioning on selected intrinsic layers and text prompts. Extensiveexperiments demonstrate the competitive performance of PRISM both for intrinsicimage decomposition and conditional image generation while preserving the basemodel's text-to-image generation capability.</description>
      <author>example@mail.com (Alara Dirik, Tuanfeng Wang, Duygu Ceylan, Stefanos Zafeiriou, Anna Frühstück)</author>
      <guid isPermaLink="false">2504.14219v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>6G WavesFM: A Foundation Model for Sensing, Communication, and Localization</title>
      <link>http://arxiv.org/abs/2504.14100v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了WavesFM，这是一种新型的无线基础模型（WFM）框架，能够支持多种通信、感知和定位任务。&lt;h4&gt;背景&lt;/h4&gt;WavesFM结合了共享的视觉Transformer（ViT）骨干网络和特定任务的多层感知器（MLP）头部，并采用了低秩自适应（LoRA）进行参数高效的微调。&lt;h4&gt;目的&lt;/h4&gt;该设计旨在在任务之间促进参数的完全共享，显著减少计算和内存占用，同时不牺牲性能。&lt;h4&gt;方法&lt;/h4&gt;模型处理类似图像的无线模态，如频谱图和信道状态信息（CSI），以及作为正交频分复用（OFDM）资源网格的对准和正交（IQ）信号。&lt;h4&gt;主要发现&lt;/h4&gt;通过在四个下游任务上的广泛实验，WavesFM展示了强大的泛化能力，包括5G NR定位、MIMO-OFDM信道估计、人类活动感知和射频（RF）信号分类。&lt;h4&gt;结论&lt;/h4&gt;与单独训练的监督基线相比，该方法在共享80%参数的情况下实现了更优的性能。此外，通过在领域相关数据上预训练，不仅提高了性能，还加速了收敛，将训练时间减少了高达5倍。这些结果表明，统一的WFM可以支持多样化的任务，并在性能和效率方面实现显著提升，突显了基础模型在未来第六代（6G）网络中推动AI原生范式变革的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces WavesFM, a novel Wireless Foundation Model (WFM) framework, capable of supporting a wide array of communication, sensing, and localization tasks. Our proposed architecture combines a shared VisionTransformer (ViT) backbone with task-specific multi-layer perceptron (MLP) heads and incorporates Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. This design promotes full parameter sharing across tasks, significantly reducing the computational and memory footprint without sacrificing performance. The model processes both image-like wireless modalities, such as spectrograms and channel state information (CSI), and in-phase and quadrature (IQ) signals arranged as orthogonal frequency-division multiplexing (OFDM) resource grids. We demonstrate the strong generalization capabilities of WavesFM through extensive experiments on four downstream tasks: Fifth Generation New Radio (5G NR) positioning; multiple-input multiple-output OFDM (MIMO-OFDM) channel estimation; human activity sensing; and radio-frequency (RF) signal classification. Compared to supervised baselines trained individually, our approach achieves superior performance while sharing 80% of its parameters across tasks. Furthermore, we show that pretraining on domain-relevant data not only boosts performance but also accelerates convergence, reducing training time by up to 5x. These results demonstrate that our unified WFM can support diverse tasks and deliver significant gains in both performance and efficiency, highlighting the transformative potential of foundation models to drive AI-native paradigms in future sixth-generation (6G) networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces WavesFM, a novel Wireless Foundation Model (WFM)framework, capable of supporting a wide array of communication, sensing, andlocalization tasks. Our proposed architecture combines a shared VisionTransformer (ViT) backbone with task-specific multi-layer perceptron (MLP)heads and incorporates Low-Rank Adaptation (LoRA) for parameter-efficientfine-tuning. This design promotes full parameter sharing across tasks,significantly reducing the computational and memory footprint withoutsacrificing performance. The model processes both image-like wirelessmodalities, such as spectrograms and channel state information (CSI), andin-phase and quadrature (IQ) signals arranged as orthogonal frequency-divisionmultiplexing (OFDM) resource grids. We demonstrate the strong generalizationcapabilities of WavesFM through extensive experiments on four downstream tasks:Fifth Generation New Radio (5G NR) positioning; multiple-input multiple-outputOFDM (MIMO-OFDM) channel estimation; human activity sensing; andradio-frequency (RF) signal classification. Compared to supervised baselinestrained individually, our approach achieves superior performance while sharing80% of its parameters across tasks. Furthermore, we show that pretraining ondomain-relevant data not only boosts performance but also acceleratesconvergence, reducing training time by up to 5x. These results demonstrate thatour unified WFM can support diverse tasks and deliver significant gains in bothperformance and efficiency, highlighting the transformative potential offoundation models to drive AI-native paradigms in future sixth-generation (6G)networks.</description>
      <author>example@mail.com (Ahmed Aboulfotouh, Elsayed Mohammed, Hatem Abou-Zeid)</author>
      <guid isPermaLink="false">2504.14100v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>LoftUp: Learning a Coordinate-Based Feature Upsampler for Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2504.14032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了一种用于特征上采样以提升视觉基础模型在像素级理解应用中的性能的方法。&lt;h4&gt;背景&lt;/h4&gt;虽然DINOv2和CLIP等视觉基础模型在下游任务上取得了显著成果，但它们的特征分辨率有限，这限制了在需要像素级理解的应用中的性能。&lt;h4&gt;目的&lt;/h4&gt;通过特征上采样来提升模型在需要高分辨率细节的应用中的性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出了两个关键因素：上采样架构和训练目标。上采样架构方面，引入了一种基于坐标的交叉注意力Transformer，用于结合高分辨率图像和低分辨率视觉基础模型特征。训练目标方面，通过使用无类别的掩码和自蒸馏来构建高分辨率伪真实特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法有效捕捉了细粒度细节，并能够灵活适应各种输入和特征分辨率。实验表明，该方法在各种下游任务上显著优于现有的特征上采样技术。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法对于提升视觉基础模型在需要高分辨率细节的应用中的性能具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;Vision foundation models (VFMs) such as DINOv2 and CLIP have achieved impressive results on various downstream tasks, but their limited feature resolution hampers performance in applications requiring pixel-level understanding. Feature upsampling offers a promising direction to address this challenge. In this work, we identify two critical factors for enhancing feature upsampling: the upsampler architecture and the training objective. For the upsampler architecture, we introduce a coordinate-based cross-attention transformer that integrates the high-resolution images with coordinates and low-resolution VFM features to generate sharp, high-quality features. For the training objective, we propose constructing high-resolution pseudo-groundtruth features by leveraging class-agnostic masks and self-distillation. Our approach effectively captures fine-grained details and adapts flexibly to various input and feature resolutions. Through experiments, we demonstrate that our approach significantly outperforms existing feature upsampling techniques across various downstream tasks. Our code is released at https://github.com/andrehuang/loftup.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/andrehuang/loftup&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models (VFMs) such as DINOv2 and CLIP have achievedimpressive results on various downstream tasks, but their limited featureresolution hampers performance in applications requiring pixel-levelunderstanding. Feature upsampling offers a promising direction to address thischallenge. In this work, we identify two critical factors for enhancing featureupsampling: the upsampler architecture and the training objective. For theupsampler architecture, we introduce a coordinate-based cross-attentiontransformer that integrates the high-resolution images with coordinates andlow-resolution VFM features to generate sharp, high-quality features. For thetraining objective, we propose constructing high-resolution pseudo-groundtruthfeatures by leveraging class-agnostic masks and self-distillation. Our approacheffectively captures fine-grained details and adapts flexibly to various inputand feature resolutions. Through experiments, we demonstrate that our approachsignificantly outperforms existing feature upsampling techniques across variousdownstream tasks. Our code is released at https://github.com/andrehuang/loftup.</description>
      <author>example@mail.com (Haiwen Huang, Anpei Chen, Volodymyr Havrylov, Andreas Geiger, Dan Zhang)</author>
      <guid isPermaLink="false">2504.14032v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Memory-efficient Streaming VideoLLMs for Real-time Procedural Video Understanding</title>
      <link>http://arxiv.org/abs/2504.13915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 5 figures; https://dibschat.github.io/ProVideLLM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为ProVideLLM的端到端框架，用于实时过程视频理解。&lt;h4&gt;背景&lt;/h4&gt;当前方法在表示长时间观察时存在token计数过多的问题。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够有效减少token计数、同时捕捉短期观察中细粒度细节的框架。&lt;h4&gt;方法&lt;/h4&gt;ProVideLLM整合了一个多模态缓存，存储两种类型的token：文本token和视觉token。文本token提供对长期观察的压缩文本摘要，视觉token使用DETR-QFormer编码，以捕捉短期观察的细粒度细节。&lt;h4&gt;主要发现&lt;/h4&gt;该设计将表示一小时的长期观察的token计数减少了22倍，同时有效地编码了当前的细粒度信息。通过在多模态缓存中交错这些token，ProVideLLM确保了内存和计算随着视频长度的线性增长，实现了每帧10FPS的流式推理和25FPS的流式对话，同时GPU内存占用仅为2GB。&lt;h4&gt;结论&lt;/h4&gt;ProVideLLM在四个数据集上的六个过程任务上达到了新的最先进结果。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为ProVideLLM的端到端框架，用于实时过程视频理解。ProVideLLM集成了一个配置为存储两种类型token的多模态缓存——口头化的文本token，它提供了对长期观察的压缩文本摘要；以及视觉token，使用DETR-QFormer进行编码，以捕捉短期观察的细粒度细节。这种设计在表示一小时的长期观察时，与现有方法相比减少了22倍的token计数，同时有效地编码了当前的细粒度信息。通过在多模态缓存中交错这些token，ProVideLLM确保了内存和计算随着视频长度的线性增长，实现了每帧10FPS的流式推理和25FPS的流式对话，同时GPU内存占用仅为2GB。ProVideLLM在四个数据集上的六个过程任务上达到了新的最先进结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce ProVideLLM, an end-to-end framework for real-time proceduralvideo understanding. ProVideLLM integrates a multimodal cache configured tostore two types of tokens - verbalized text tokens, which provide compressedtextual summaries of long-term observations, and visual tokens, encoded withDETR-QFormer to capture fine-grained details from short-term observations. Thisdesign reduces token count by 22x over existing methods in representing onehour of long-term observations while effectively encoding fine-granularity ofthe present. By interleaving these tokens in our multimodal cache, ProVideLLMensures sub-linear scaling of memory and compute with video length, enablingper-frame streaming inference at 10 FPS and streaming dialogue at 25 FPS, witha minimal 2GB GPU memory footprint. ProVideLLM also sets new state-of-the-artresults on six procedural tasks across four datasets.</description>
      <author>example@mail.com (Dibyadip Chatterjee, Edoardo Remelli, Yale Song, Bugra Tekin, Abhay Mittal, Bharat Bhatnagar, Necati Cihan Camgöz, Shreyas Hampali, Eric Sauser, Shugao Ma, Angela Yao, Fadime Sener)</author>
      <guid isPermaLink="false">2504.13915v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual Descriptions Using Gaussian Splatting, ChatGPT/Deepseek, and Google Maps Platform</title>
      <link>http://arxiv.org/abs/2502.05769v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  -Fixed minor typo&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种针对单栋建筑规模的数字孪生框架，旨在通过多源数据和数据分析优化城市规划、基础设施管理和决策。&lt;h4&gt;背景&lt;/h4&gt;城市数字孪生是使用多源数据和数据分析来优化城市规划、基础设施管理和决策的虚拟城市复制品。&lt;h4&gt;目的&lt;/h4&gt;提出一个专注于单栋建筑规模的框架，以优化城市规划、基础设施管理和决策。&lt;h4&gt;方法&lt;/h4&gt;该框架通过连接到云地图平台（如谷歌地图平台API），利用基于ChatGPT(4o)和Deepseek-V3/R1的最新多智能体大型语言模型数据分析，以及使用基于高斯喷溅的网格提取管道来检索建筑的3D模型、视觉描述，并实现基于地址、邮政编码或地理坐标的云映射集成。&lt;h4&gt;主要发现&lt;/h4&gt;通过该框架，可以检索建筑的3D模型和视觉描述，并实现基于地址、邮政编码或地理坐标的云映射集成。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一个有效的框架，用于创建城市建筑的单栋数字孪生，以支持城市规划和基础设施管理的优化。&lt;h4&gt;翻译&lt;/h4&gt;城市数字孪生是使用多源数据以及数据分析来优化城市规划、基础设施管理和决策的虚拟城市复制品。为了这个目的，我们提出一个聚焦于单栋建筑规模的框架。通过连接到谷歌地图平台API等云地图平台，利用ChatGPT(4o)和Deepseek-V3/R1的最新多智能体大型语言模型数据分析，以及使用基于高斯喷溅的网格提取管道，我们的数字孪生建筑框架能够检索建筑的3D模型、视觉描述，并实现基于地址、邮政编码或地理坐标的云映射集成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban digital twins are virtual replicas of cities that use multi-source dataand data analytics to optimize urban planning, infrastructure management, anddecision-making. Towards this, we propose a framework focused on thesingle-building scale. By connecting to cloud mapping platforms such as GoogleMap Platforms APIs, by leveraging state-of-the-art multi-agent Large LanguageModels data analysis using ChatGPT(4o) and Deepseek-V3/R1, and by using ourGaussian Splatting-based mesh extraction pipeline, our Digital Twin Buildingsframework can retrieve a building's 3D model, visual descriptions, and achievecloud-based mapping integration with large language model-based data analyticsusing a building's address, postal code, or geographic coordinates.</description>
      <author>example@mail.com (Kyle Gao, Dening Lu, Liangzhi Li, Nan Chen, Hongjie He, Linlin Xu, Jonathan Li)</author>
      <guid isPermaLink="false">2502.05769v3</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    </channel>
</rss>