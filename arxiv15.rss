<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 25 Jul 2025 14:19:57 +0800</lastBuildDate>
    <item>
      <title>On the Interaction of Compressibility and Adversarial Robustness</title>
      <link>http://arxiv.org/abs/2507.17725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了神经网络的压缩性和鲁棒性之间的关系，分析了不同形式的压缩如何影响对抗鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现代神经网络需要同时满足多个优良特性，如对训练数据的准确拟合、对未见输入的泛化能力、参数和计算效率以及对抗干扰的鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;建立一种原理性的框架来分析不同形式的压缩（如神经元层面的稀疏性和频谱压缩性）如何影响对抗鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;通过分析压缩如何诱导表示空间中少数高度敏感的方向，这些方向可以被对手利用来构建有效的干扰。&lt;h4&gt;主要发现&lt;/h4&gt;压缩可以导致表示空间中的敏感方向增加，从而降低鲁棒性。这些风险与压缩实现的方式无关。&lt;h4&gt;结论&lt;/h4&gt;压缩性和鲁棒性之间存在根本性的紧张关系，研究结果为设计既高效又安全的模型提供了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;Modern neural networks are expected to simultaneously satisfy a host of desirable properties: accurate fitting to training data, generalization to unseen inputs, parameter and computational efficiency, and robustness to adversarial perturbations. While compressibility and robustness have each been studied extensively, a unified understanding of their interaction still remains elusive. In this work, we develop a principled framework to analyze how different forms of compressibility - such as neuron-level sparsity and spectral compressibility - affect adversarial robustness. We show that these forms of compression can induce a small number of highly sensitive directions in the representation space, which adversaries can exploit to construct effective perturbations. Our analysis yields a simple yet instructive robustness bound, revealing how neuron and spectral compressibility impact L_∞ and L_2 robustness via their effects on the learned representations. Crucially, the vulnerabilities we identify arise irrespective of how compression is achieved - whether via regularization, architectural bias, or implicit learning dynamics. Through empirical evaluations across synthetic and realistic tasks, we confirm our theoretical predictions, and further demonstrate that these vulnerabilities persist under adversarial training and transfer learning, and contribute to the emergence of universal adversarial perturbations. Our findings show a fundamental tension between structured compressibility and robustness, and suggest new pathways for designing models that are both efficient and secure.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern neural networks are expected to simultaneously satisfy a host ofdesirable properties: accurate fitting to training data, generalization tounseen inputs, parameter and computational efficiency, and robustness toadversarial perturbations. While compressibility and robustness have each beenstudied extensively, a unified understanding of their interaction still remainselusive. In this work, we develop a principled framework to analyze howdifferent forms of compressibility - such as neuron-level sparsity and spectralcompressibility - affect adversarial robustness. We show that these forms ofcompression can induce a small number of highly sensitive directions in therepresentation space, which adversaries can exploit to construct effectiveperturbations. Our analysis yields a simple yet instructive robustness bound,revealing how neuron and spectral compressibility impact $L_\infty$ and $L_2$robustness via their effects on the learned representations. Crucially, thevulnerabilities we identify arise irrespective of how compression is achieved -whether via regularization, architectural bias, or implicit learning dynamics.Through empirical evaluations across synthetic and realistic tasks, we confirmour theoretical predictions, and further demonstrate that these vulnerabilitiespersist under adversarial training and transfer learning, and contribute to theemergence of universal adversarial perturbations. Our findings show afundamental tension between structured compressibility and robustness, andsuggest new pathways for designing models that are both efficient and secure.</description>
      <author>example@mail.com (Melih Barsbey, Antônio H. Ribeiro, Umut Şimşekli, Tolga Birdal)</author>
      <guid isPermaLink="false">2507.17725v1</guid>
      <pubDate>Fri, 25 Jul 2025 14:19:57 +0800</pubDate>
    </item>
  <item>
      <title>STQE: Spatial-Temporal Quality Enhancement for G-PCC Compressed Dynamic Point Clouds</title>
      <link>http://arxiv.org/abs/2507.17522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STQE的网络，用于提升压缩动态点云的质量，通过利用空间和时间相关性来改善G-PCC压缩动态点云的视觉质量。&lt;h4&gt;背景&lt;/h4&gt;目前很少有研究关注压缩动态点云的质量提升，特别是空间时间相关性在点云帧之间的有效利用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提升压缩动态点云的视觉质量。&lt;h4&gt;方法&lt;/h4&gt;STQE网络包括：基于重着色的运动补偿模块、通道感知的时间注意力模块、高斯引导的邻域特征聚合模块，以及基于皮尔逊相关系数的联合损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;STQE在最新的G-PCC测试模型上实现了0.855 dB、0.682 dB和0.828 dB的delta PSNR提升，以及Luma、Cb和Cr分量的BD-rate分别降低了25.2%、31.6%和32.5%。&lt;h4&gt;结论&lt;/h4&gt;STQE网络能够有效提升压缩动态点云的质量，并在多个方面取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;本研究提出了一种名为STQE的网络，用于提高压缩动态点云的质量。该网络利用空间和时间相关性来改善G-PCC压缩动态点云的视觉效果。通过实验，STQE在最新的G-PCC测试模型上实现了显著的性能提升，包括delta PSNR的提升和BD-rate的降低。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Very few studies have addressed quality enhancement for compressed dynamicpoint clouds. In particular, the effective exploitation of spatial-temporalcorrelations between point cloud frames remains largely unexplored. Addressingthis gap, we propose a spatial-temporal attribute quality enhancement (STQE)network that exploits both spatial and temporal correlations to improve thevisual quality of G-PCC compressed dynamic point clouds. Our contributionsinclude a recoloring-based motion compensation module that remaps referenceattribute information to the current frame geometry to achieve preciseinter-frame geometric alignment, a channel-aware temporal attention module thatdynamically highlights relevant regions across bidirectional reference frames,a Gaussian-guided neighborhood feature aggregation module that efficientlycaptures spatial dependencies between geometry and color attributes, and ajoint loss function based on the Pearson correlation coefficient, designed toalleviate over-smoothing effects typical of point-wise mean squared erroroptimization. When applied to the latest G-PCC test model, STQE achievedimprovements of 0.855 dB, 0.682 dB, and 0.828 dB in delta PSNR, withBj{\o}ntegaard Delta rate (BD-rate) reductions of -25.2%, -31.6%, and -32.5%for the Luma, Cb, and Cr components, respectively.</description>
      <author>example@mail.com (Tian Guo, Hui Yuan, Xiaolong Mao, Shiqi Jiang, Raouf Hamzaoui, Sam Kwong)</author>
      <guid isPermaLink="false">2507.17522v1</guid>
      <pubDate>Fri, 25 Jul 2025 14:19:57 +0800</pubDate>
    </item>
    <item>
      <title>Audio-Vision Contrastive Learning for Phonological Class Recognition</title>
      <link>http://arxiv.org/abs/2507.17682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  conference to TSD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合实时磁共振成像和语音信号的多模态深度学习框架，用于对三种关键发音维度进行分类，并取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;准确的发音-语音特征分类对理解人类语音产生和发展鲁棒的语音技术至关重要，尤其在临床环境中，有助于提高疾病诊断准确性和个性化康复。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，结合实时磁共振成像和语音信号，对发音方式、发音位置和浊音进行分类，并评估系统在不同配置下的性能。&lt;h4&gt;方法&lt;/h4&gt;采用15个语音类别进行分类，评估了四种音频/视觉配置：单模态实时磁共振成像、单模态音频信号、多模态中融合和基于对比学习的音频-视觉融合。&lt;h4&gt;主要发现&lt;/h4&gt;在USC-TIMIT数据集上的实验结果表明，基于对比学习的方法实现了最先进的性能，平均F1分数为0.81，比单模态基线提高了0.23。&lt;h4&gt;结论&lt;/h4&gt;对比表示学习对于多模态发音分析是有效的，相关代码和处理后的数据集将公开提供以支持未来的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确分类发音-语音特征在理解人类语音产生和发展鲁棒的语音技术中起着至关重要的作用，尤其是在临床环境中，有针对性的音素分析和治疗可以提高疾病诊断的准确性并实现个性化的康复。在本研究中，我们提出了一种多模态深度学习框架，该框架结合了实时磁共振成像（rtMRI）和语音信号，用于对三种关键的发音维度进行分类：发音方式、发音位置和浊音。我们对由上述发音维度派生的15个语音类别进行了分类，并使用四种音频/视觉配置评估了系统：单模态rtMRI、单模态音频信号、多模态中融合和基于对比学习的音频-视觉融合。在USC-TIMIT数据集上的实验结果表明，我们的基于对比学习的方法实现了最先进的性能，平均F1分数为0.81，比单模态基线提高了0.23。这些结果证实了对比表示学习对于多模态发音分析的有效性。我们的代码和处理的语料库将公开提供在https://github.com/DaE-plz/AC_Contrastive_Phonology上，以支持未来的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate classification of articulatory-phonological features plays a vitalrole in understanding human speech production and developing robust speechtechnologies, particularly in clinical contexts where targeted phonemicanalysis and therapy can improve disease diagnosis accuracy and personalizedrehabilitation. In this work, we propose a multimodal deep learning frameworkthat combines real-time magnetic resonance imaging (rtMRI) and speech signalsto classify three key articulatory dimensions: manner of articulation, place ofarticulation, and voicing. We perform classification on 15 phonological classesderived from the aforementioned articulatory dimensions and evaluate the systemwith four audio/vision configurations: unimodal rtMRI, unimodal audio signals,multimodal middle fusion, and contrastive learning-based audio-vision fusion.Experimental results on the USC-TIMIT dataset show that our contrastivelearning-based approach achieves state-of-the-art performance, with an averageF1-score of 0.81, representing an absolute increase of 0.23 over the unimodalbaseline. The results confirm the effectiveness of contrastive representationlearning for multimodal articulatory analysis. Our code and processed datasetwill be made publicly available athttps://github.com/DaE-plz/AC_Contrastive_Phonology to support future research.</description>
      <author>example@mail.com (Daiqi Liu, Tomás Arias-Vergara, Jana Hutter, Andreas Maier, Paula Andrea Pérez-Toro)</author>
      <guid isPermaLink="false">2507.17682v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
  <item>
      <title>From Atoms to Dynamics: Learning the Committor Without Collective Variables</title>
      <link>http://arxiv.org/abs/2507.17700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages (including supplementary information with 13 pages), 15  figures (5 figures in the main text and 10 figures in the supplementary  information)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于几何向量感知器的图神经网络架构，可以直接从原子坐标预测承诺函数，无需手工设计集体变量（CVs）。该方法在原子级别具有可解释性，能够准确指出复杂转变中的关键原子，而不依赖先验假设。&lt;h4&gt;背景&lt;/h4&gt;传统方法需要手工设计集体变量来预测承诺函数，这限制了模型的解释性和适用性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，直接从原子坐标预测承诺函数，提高模型的解释性和准确性。&lt;h4&gt;方法&lt;/h4&gt;构建基于几何向量感知器的图神经网络架构，从原子坐标预测承诺函数，无需手工设计集体变量。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多种分子系统中准确推断承诺函数，并突出了每个重原子在转变机制中的重要性。同时，它还提供了底层过程的速率常数的精确估计。&lt;h4&gt;结论&lt;/h4&gt;该方法为理解和建模复杂动力学开辟了新的途径，通过实现无CV学习和自动识别复杂分子过程的物理上有意义的反应坐标。&lt;h4&gt;翻译&lt;/h4&gt;This Brief Communication introduces a graph-neural-network architecture built on geometric vector perceptrons to predict the committor function directly from atomic coordinates, bypassing the need for hand-crafted collective variables (CVs). The method offers atom-level interpretability, pinpointing the key atomic players in complex transitions without relying on prior assumptions. Applied across diverse molecular systems, the method accurately infers the committor function and highlights the importance of each heavy atom in the transition mechanism. It also yields precise estimates of the rate constants for the underlying processes. The proposed approach opens new avenues for understanding and modeling complex dynamics, by enabling CV-free learning and automated identification of physically meaningful reaction coordinates of complex molecular processes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This Brief Communication introduces a graph-neural-network architecture builton geometric vector perceptrons to predict the committor function directly fromatomic coordinates, bypassing the need for hand-crafted collective variables(CVs). The method offers atom-level interpretability, pinpointing the keyatomic players in complex transitions without relying on prior assumptions.Applied across diverse molecular systems, the method accurately infers thecommittor function and highlights the importance of each heavy atom in thetransition mechanism. It also yields precise estimates of the rate constantsfor the underlying processes. The proposed approach opens new avenues forunderstanding and modeling complex dynamics, by enabling CV-free learning andautomated identification of physically meaningful reaction coordinates ofcomplex molecular processes.</description>
      <author>example@mail.com (Sergio Contreras Arredondo, Chenyu Tang, Radu A. Talmazan, Alberto Megías, Cheng Giuseppe Chen, Christophe Chipot)</author>
      <guid isPermaLink="false">2507.17700v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Perspective-Invariant 3D Object Detection</title>
      <link>http://arxiv.org/abs/2507.17665v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025; 46 pages, 18 figures, 22 tables; Project Page at  https://pi3det.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Pi3DET，一个包含多平台LiDAR数据和3D边界框标注的基准数据集，以及一个用于跨平台适应性的新框架。&lt;h4&gt;背景&lt;/h4&gt;LiDAR-based 3D object detection在学术界和工业界受到关注，但现有数据和方法的关注点主要在车载平台上。&lt;h4&gt;目的&lt;/h4&gt;填补这一空白，促进非车载平台和跨平台3D检测的研究。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于Pi3DET的跨平台适应性框架，通过几何和特征级别的鲁棒对齐实现视角不变3D检测，并建立了一个基准来评估3D检测器在跨平台场景中的鲁棒性和稳健性。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了该方法在具有挑战性的跨平台任务中的有效性，比现有适应性方法有显著提升。&lt;h4&gt;结论&lt;/h4&gt;该工作为在多样化和复杂环境中构建可泛化和统一的3D感知系统铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;随着机器人的兴起，基于LiDAR的3D目标检测在学术界和工业界受到了广泛关注。然而，现有的数据集和方法主要关注车载平台，而对其他自主平台的研究不足。为了填补这一空白，我们引入了Pi3DET，这是第一个包含来自多个平台（车辆、四足和无人机）的LiDAR数据和3D边界框标注的基准数据集，从而促进了非车载平台以及跨平台3D检测的研究。基于Pi3DET，我们提出了一种新的跨平台适应性框架，该框架将来自研究良好的车载平台的知识迁移到其他平台。该框架通过几何和特征级别的鲁棒对齐实现了视角不变的3D检测。此外，我们建立了一个基准来评估当前3D检测器在跨平台场景中的鲁棒性和稳健性，为开发适应性3D感知系统提供了宝贵的见解。广泛的实验验证了我们的方法在具有挑战性的跨平台任务中的有效性，与现有的适应性方法相比，取得了显著的提升。我们希望这项工作为在多样化和复杂环境中构建可泛化和统一的3D感知系统铺平道路。我们的Pi3DET数据集、跨平台基准套件和标注工具包已经公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rise of robotics, LiDAR-based 3D object detection has garneredsignificant attention in both academia and industry. However, existing datasetsand methods predominantly focus on vehicle-mounted platforms, leaving otherautonomous platforms underexplored. To bridge this gap, we introduce Pi3DET,the first benchmark featuring LiDAR data and 3D bounding box annotationscollected from multiple platforms: vehicle, quadruped, and drone, therebyfacilitating research in 3D object detection for non-vehicle platforms as wellas cross-platform 3D detection. Based on Pi3DET, we propose a novelcross-platform adaptation framework that transfers knowledge from thewell-studied vehicle platform to other platforms. This framework achievesperspective-invariant 3D detection through robust alignment at both geometricand feature levels. Additionally, we establish a benchmark to evaluate theresilience and robustness of current 3D detectors in cross-platform scenarios,providing valuable insights for developing adaptive 3D perception systems.Extensive experiments validate the effectiveness of our approach on challengingcross-platform tasks, demonstrating substantial gains over existing adaptationmethods. We hope this work paves the way for generalizable and unified 3Dperception systems across diverse and complex environments. Our Pi3DET dataset,cross-platform benchmark suite, and annotation toolkit have been made publiclyavailable.</description>
      <author>example@mail.com (Ao Liang, Lingdong Kong, Dongyue Lu, Youquan Liu, Jian Fang, Huaici Zhao, Wei Tsang Ooi)</author>
      <guid isPermaLink="false">2507.17665v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Confidence Calibration in Vision-Language-Action Models</title>
      <link>http://arxiv.org/abs/2507.17383v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34 pages, 19 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在视觉-语言-动作（VLA）基础模型中，如何通过系统性地校准置信度来提高机器人行为的可靠性。&lt;h4&gt;背景&lt;/h4&gt;高水平的任务成功和机器人能够可靠地量化成功概率是可信机器人行为的关键。&lt;h4&gt;目的&lt;/h4&gt;对VLA基础模型中的置信度校准进行系统研究，以提升机器人的可靠性和可信度。&lt;h4&gt;方法&lt;/h4&gt;通过广泛的基准测试来理解任务成功与校准误差之间的关系，引入基于贝叶斯启发式的prompt ensembles算法，并分析置信度随任务时间的变化，以及提出针对动作维度的差异校准方法。&lt;h4&gt;主要发现&lt;/h4&gt;任务性能和校准之间不存在冲突；置信度在任务进行一段时间后最为可靠；不同动作维度存在差异校准。&lt;h4&gt;结论&lt;/h4&gt;本研究旨在开发工具和概念理解，以通过可靠的置信度量化使VLA既高性能又可信。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种系统性的置信度校准方法，以提高视觉-语言-动作（VLA）基础模型的可靠性。通过基准测试发现，任务成功与校准误差之间不存在矛盾，置信度在任务进行一段时间后最为可靠，并针对不同动作维度提出了差异校准方法。研究旨在开发工具和概念理解，以实现VLA的高性能和高可信度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trustworthy robot behavior requires not only high levels of task success butalso that the robot can reliably quantify how likely it is to succeed. To thisend, we present the first systematic study of confidence calibration invision-language-action (VLA) foundation models, which map visual observationsand natural-language instructions to low-level robot motor commands. We beginwith extensive benchmarking to understand the critical relationship betweentask success and calibration error across multiple datasets and VLA variants,finding that task performance and calibration are not in tension. Next, weintroduce prompt ensembles for VLAs, a lightweight, Bayesian-inspired algorithmthat averages confidence across paraphrased instructions and consistentlyimproves calibration. We further analyze calibration over the task timehorizon, showing that confidence is often most reliable after making someprogress, suggesting natural points for risk-aware intervention. Finally, wereveal differential miscalibration across action dimensions and proposeaction-wise Platt scaling, a method to recalibrate each action dimensionindependently to produce better confidence estimates. Our aim in this study isto begin to develop the tools and conceptual understanding necessary to renderVLAs both highly performant and highly trustworthy via reliable uncertaintyquantification.</description>
      <author>example@mail.com (Thomas P Zollo, Richard Zemel)</author>
      <guid isPermaLink="false">2507.17383v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning</title>
      <link>http://arxiv.org/abs/2507.17482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了LTLZinc，一个用于生成覆盖多种不同问题的数据集的基准框架，可以用于评估神经符号和持续学习方法在时间和约束驱动维度上的表现。&lt;h4&gt;背景&lt;/h4&gt;神经符号人工智能旨在结合神经网络架构和符号方法，以人类可解释的形式表示知识。持续学习关注的是随着时间扩展其知识、提高技能同时避免忘记先前学习概念的人工智能代理。&lt;h4&gt;目的&lt;/h4&gt;提出LTLZinc框架，用于生成可以评估神经符号和持续学习方法在时间和约束驱动维度上的表现的数据集。&lt;h4&gt;方法&lt;/h4&gt;LTLZinc框架从MiniZinc约束的线性时态逻辑规格和任意图像分类数据集中生成表达式的时态推理和持续学习任务。细粒度注释允许在相同生成的数据集上进行多种神经和神经符号训练设置。&lt;h4&gt;主要发现&lt;/h4&gt;在LTLZinc生成的六个神经符号序列分类和四个类持续学习任务上的实验表明，时态学习和推理具有挑战性，并突出了当前最先进方法的局限性。&lt;h4&gt;结论&lt;/h4&gt;LTLZinc生成器和十个可用的任务被发布给神经符号和持续学习社区，希望促进统一时态学习和推理框架的研究。&lt;h4&gt;翻译&lt;/h4&gt;神经符号人工智能旨在结合神经网络架构与符号方法，以人类可解释的形式表示知识。持续学习关注的是智能体随着时间的推移扩展其知识，提高其技能，同时避免忘记先前学到的概念。大多数现有的神经符号人工智能方法仅应用于静态场景，而需要沿着时间维度进行推理的具有挑战性的设置则很少被探索。在这项工作中，我们引入了LTLZinc，这是一个基准框架，可以用于生成覆盖各种不同问题的数据集，神经符号和持续学习方法可以在此框架中沿着时间和约束驱动的维度进行评估。我们的框架从MiniZinc约束的线性时态逻辑规格和任意图像分类数据集中生成表达式的时态推理和持续学习任务。细粒度注释允许在相同生成的数据集上进行多种神经和神经符号训练设置。在LTLZinc生成的六个神经符号序列分类和四个类持续学习任务上的实验表明，时态学习和推理具有挑战性，并突出了当前最先进方法的局限性。我们发布了LTLZinc生成器和十个可用的任务，希望促进向统一时态学习和推理框架的研究发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuro-symbolic artificial intelligence aims to combine neural architectureswith symbolic approaches that can represent knowledge in a human-interpretableformalism. Continual learning concerns with agents that expand their knowledgeover time, improving their skills while avoiding to forget previously learnedconcepts. Most of the existing approaches for neuro-symbolic artificialintelligence are applied to static scenarios only, and the challenging settingwhere reasoning along the temporal dimension is necessary has been seldomexplored. In this work we introduce LTLZinc, a benchmarking framework that canbe used to generate datasets covering a variety of different problems, againstwhich neuro-symbolic and continual learning methods can be evaluated along thetemporal and constraint-driven dimensions. Our framework generates expressivetemporal reasoning and continual learning tasks from a linear temporal logicspecification over MiniZinc constraints, and arbitrary image classificationdatasets. Fine-grained annotations allow multiple neural and neuro-symbolictraining settings on the same generated datasets. Experiments on sixneuro-symbolic sequence classification and four class-continual learning tasksgenerated by LTLZinc, demonstrate the challenging nature of temporal learningand reasoning, and highlight limitations of current state-of-the-art methods.We release the LTLZinc generator and ten ready-to-use tasks to theneuro-symbolic and continual learning communities, in the hope of fosteringresearch towards unified temporal learning and reasoning frameworks.</description>
      <author>example@mail.com (Luca Salvatore Lorello, Nikolaos Manginas, Marco Lippi, Stefano Melacci)</author>
      <guid isPermaLink="false">2507.17482v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception</title>
      <link>http://arxiv.org/abs/2507.17445v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IndoorBEV的新型基于掩码的鸟瞰图（BEV）方法，用于解决复杂室内3D点云中多样物体检测的挑战。&lt;h4&gt;背景&lt;/h4&gt;在复杂室内环境中，检测多样物体对机器人感知提出了重大挑战，特别是当物体形状多样、存在杂乱环境和静态与动态元素共存时，传统的边界框方法往往失效。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了一种新的室内BEV方法，用于室内移动机器人的物体检测。&lt;h4&gt;方法&lt;/h4&gt;IndoorBEV方法将3D场景投影到一个2D的BEV网格中，处理自然遮挡并提供一致的俯视图，帮助区分静态障碍物和动态元素。该方法使用轴紧凑编码器和基于窗口的主干网络从BEV图中提取丰富的空间特征。然后，一个基于查询的解码器头使用学习到的物体查询在BEV空间中同时预测物体类别和实例掩码。&lt;h4&gt;主要发现&lt;/h4&gt;这种基于掩码的公式能够有效地捕捉到静态和动态物体的足迹，无论它们的形状如何，为边界框回归提供了一种鲁棒的替代方案。&lt;h4&gt;结论&lt;/h4&gt;通过在一个包含多种静态物体和动态元素（如机器人和杂项物品）的定制室内数据集上进行的实验，证明了IndoorBEV在鲁棒室内场景理解方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在复杂室内3D点云中检测多样化物体对机器人感知构成了重大挑战，尤其是在物体形状多样、杂乱以及静态和动态元素共存的情况下，传统的边界框方法效果不佳。为了解决这些限制，我们提出了室内BEV，这是一种新颖的基于掩码的鸟瞰图（BEV）方法，用于室内移动机器人。在BEV方法中，将3D场景投影到一个2D的BEV网格中，这可以自然地处理遮挡并提供一致的俯视图，有助于区分静态障碍物和动态元素。得到的2D BEV结果可以直接用于下游的机器人任务，如导航、运动预测和规划。我们的架构利用轴紧凑编码器和基于窗口的主干网络从BEV图中提取丰富的空间特征。然后，一个基于查询的解码器头使用学习到的物体查询在BEV空间中同时预测物体类别和实例掩码。这种基于掩码的公式有效地捕捉了静态和动态物体的足迹，无论它们的形状如何，为边界框回归提供了一种鲁棒的替代方案。我们在一个包含多种静态物体和动态元素（如机器人和杂项物品）的定制室内数据集上展示了IndoorBEV的有效性，展示了其在鲁棒室内场景理解方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting diverse objects within complex indoor 3D point clouds presentssignificant challenges for robotic perception, particularly with varied objectshapes, clutter, and the co-existence of static and dynamic elements wheretraditional bounding box methods falter. To address these limitations, wepropose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoormobile robots.  In a BEV method, a 3D scene is projected into a 2D BEV grid which handlesnaturally occlusions and provides a consistent top-down view aiding todistinguish static obstacles from dynamic agents. The obtained 2D BEV resultsis directly usable to downstream robotic tasks like navigation, motionprediction, and planning. Our architecture utilizes an axis compact encoder anda window-based backbone to extract rich spatial features from this BEV map. Aquery-based decoder head then employs learned object queries to concurrentlypredict object classes and instance masks in the BEV space. This mask-centricformulation effectively captures the footprint of both static and dynamicobjects regardless of their shape, offering a robust alternative to boundingbox regression. We demonstrate the effectiveness of IndoorBEV on a customindoor dataset featuring diverse object classes including static objects  and dynamic elements like robots and miscellaneous items, showcasing itspotential for robust indoor scene understanding.</description>
      <author>example@mail.com (Haichuan Li, Changda Tian, Panos Trahanias, Tomi Westerlund)</author>
      <guid isPermaLink="false">2507.17445v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Mammo-Mamba: A Hybrid State-Space and Transformer Architecture with Sequential Mixture of Experts for Multi-View Mammography</title>
      <link>http://arxiv.org/abs/2507.17662v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Mammo-Mamba的新型框架，旨在解决现有乳腺癌CAD系统中多视图乳腺摄影的准确和高效解释问题。&lt;h4&gt;背景&lt;/h4&gt;尽管计算机辅助诊断（CAD）系统在乳腺癌诊断中取得了进展，但乳腺癌仍然是女性癌症相关死亡的主要原因。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一个高效的乳腺癌CAD模型，以实现多视图乳腺摄影的准确解读，从而提高早期检测的能力。&lt;h4&gt;方法&lt;/h4&gt;Mammo-Mamba结合了选择性状态空间模型（SSMs）、基于Transformer的注意力机制和专家驱动的特征优化，并通过自定义的SecMamba模块引入了顺序混合专家（SeqMoE）机制。&lt;h4&gt;主要发现&lt;/h4&gt;SecMamba模块通过内容自适应特征优化增强了MambaVision主干网络在高清乳腺影像中的表征学习能力，并在CBIS-DDSM数据集上实现了优异的分类性能。&lt;h4&gt;结论&lt;/h4&gt;Mammo-Mamba在保持计算效率的同时，实现了优于传统Transformer模型的关键性能指标。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管近年来计算机辅助诊断（CAD）系统在乳腺癌诊断中取得了进展，但乳腺癌仍然是女性癌症相关死亡的主要原因。准确和高效的多视图乳腺摄影解释对于早期检测至关重要，这推动了人工智能（AI）驱动的CAD模型的热潮。虽然最先进的多视图乳腺摄影分类模型大多基于Transformer架构，但其计算复杂度随着图像块数量的增加而呈二次方增长，这突出了对更有效替代方案的需求。为了应对这一挑战，我们提出了一种名为Mammo-Mamba的新型框架，该框架将选择性状态空间模型（SSMs）、基于Transformer的注意力机制和专家驱动的特征优化整合到一个统一的架构中。Mammo-Mamba通过其定制的SecMamba块引入了顺序混合专家（SeqMoE）机制，从而扩展了MambaVision骨干网络。SecMamba是一个修改后的MambaVision块，通过启用内容自适应特征优化来增强高分辨率乳腺影像中的表征学习。这些模块集成到MambaVision的更深阶段，使模型能够通过动态专家门控逐步调整特征重点，有效缓解了传统Transformer模型的限制。在CBIS-DDSM基准数据集上评估Mammo-Mamba在所有关键指标上都实现了优越的分类性能，同时保持了计算效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Breast cancer (BC) remains one of the leading causes of cancer-relatedmortality among women, despite recent advances in Computer-Aided Diagnosis(CAD) systems. Accurate and efficient interpretation of multi-view mammogramsis essential for early detection, driving a surge of interest in ArtificialIntelligence (AI)-powered CAD models. While state-of-the-art multi-viewmammogram classification models are largely based on Transformer architectures,their computational complexity scales quadratically with the number of imagepatches, highlighting the need for more efficient alternatives. To address thischallenge, we propose Mammo-Mamba, a novel framework that integrates SelectiveState-Space Models (SSMs), transformer-based attention, and expert-drivenfeature refinement into a unified architecture. Mammo-Mamba extends theMambaVision backbone by introducing the Sequential Mixture of Experts (SeqMoE)mechanism through its customized SecMamba block. The SecMamba is a modifiedMambaVision block that enhances representation learning in high-resolutionmammographic images by enabling content-adaptive feature refinement. Theseblocks are integrated into the deeper stages of MambaVision, allowing the modelto progressively adjust feature emphasis through dynamic expert gating,effectively mitigating the limitations of traditional Transformer models.Evaluated on the CBIS-DDSM benchmark dataset, Mammo-Mamba achieves superiorclassification performance across all key metrics while maintainingcomputational efficiency.</description>
      <author>example@mail.com (Farnoush Bayatmakou, Reza Taleei, Nicole Simone, Arash Mohammadi)</author>
      <guid isPermaLink="false">2507.17662v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal Multi-task Pre-training for Improved Point Cloud Understanding</title>
      <link>http://arxiv.org/abs/2507.17533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了多模态预训练方法在3D表示学习中的有效性，提出了MMPT多模态多任务预训练框架，以增强点云理解能力。&lt;h4&gt;背景&lt;/h4&gt;现有多模态预训练框架主要依赖单一预训练任务收集多模态数据，限制了模型获取其他相关任务提供的信息，可能影响其在下游任务中的表现。&lt;h4&gt;目的&lt;/h4&gt;提出MMPT框架，旨在通过多任务预训练提高点云理解能力。&lt;h4&gt;方法&lt;/h4&gt;MMPT框架包括三个预训练任务：(i) 令牌级重建(TLR)，用于恢复掩码点令牌；(ii) 点级重建(PLR)，直接预测掩码点位置；(iii) 多模态对比学习(MCL)，结合跨模态特征对应关系，以自监督方式从3D点云和2D图像模态中构建丰富的学习信号。&lt;h4&gt;主要发现&lt;/h4&gt;MMPT框架无需3D标注即可运行，且训练的编码器可以有效地迁移到各种下游任务。&lt;h4&gt;结论&lt;/h4&gt;MMPT框架在广泛使用的基准测试中，与最先进的方法相比，在判别和生成应用中表现出良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in multi-modal pre-training methods have shown promising effectiveness in learning 3D representations by aligning multi-modal features between 3D shapes and their corresponding 2D counterparts. However, existing multi-modal pre-training frameworks primarily rely on a single pre-training task to gather multi-modal data in 3D applications. This limitation prevents the models from obtaining the abundant information provided by other relevant tasks, which can hinder their performance in downstream tasks, particularly in complex and diverse domains. In order to tackle this issue, we propose MMPT, a Multi-modal Multi-task Pre-training framework designed to enhance point cloud understanding. Specifically, three pre-training tasks are devised: (i) Token-level reconstruction (TLR) aims to recover masked point tokens, endowing the model with representative learning abilities. (ii) Point-level reconstruction (PLR) is integrated to predict the masked point positions directly, and the reconstructed point cloud can be considered as a transformed point cloud used in the subsequent task. (iii) Multi-modal contrastive learning (MCL) combines feature correspondences within and across modalities, thus assembling a rich learning signal from both 3D point cloud and 2D image modalities in a self-supervised manner. Moreover, this framework operates without requiring any 3D annotations, making it scalable for use with large datasets. The trained encoder can be effectively transferred to various downstream tasks. To demonstrate its effectiveness, we evaluated its performance compared to state-of-the-art methods in various discriminant and generative applications under widely-used benchmarks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in multi-modal pre-training methods have shown promisingeffectiveness in learning 3D representations by aligning multi-modal featuresbetween 3D shapes and their corresponding 2D counterparts. However, existingmulti-modal pre-training frameworks primarily rely on a single pre-trainingtask to gather multi-modal data in 3D applications. This limitation preventsthe models from obtaining the abundant information provided by other relevanttasks, which can hinder their performance in downstream tasks, particularly incomplex and diverse domains. In order to tackle this issue, we propose MMPT, aMulti-modal Multi-task Pre-training framework designed to enhance point cloudunderstanding. Specifically, three pre-training tasks are devised: (i)Token-level reconstruction (TLR) aims to recover masked point tokens, endowingthe model with representative learning abilities. (ii) Point-levelreconstruction (PLR) is integrated to predict the masked point positionsdirectly, and the reconstructed point cloud can be considered as a transformedpoint cloud used in the subsequent task. (iii) Multi-modal contrastive learning(MCL) combines feature correspondences within and across modalities, thusassembling a rich learning signal from both 3D point cloud and 2D imagemodalities in a self-supervised manner. Moreover, this framework operateswithout requiring any 3D annotations, making it scalable for use with largedatasets. The trained encoder can be effectively transferred to variousdownstream tasks. To demonstrate its effectiveness, we evaluated itsperformance compared to state-of-the-art methods in various discriminant andgenerative applications under widely-used benchmarks.</description>
      <author>example@mail.com (Liwen Liu, Weidong Yang, Lipeng Ma, Ben Fei)</author>
      <guid isPermaLink="false">2507.17533v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Clustering-based hard negative sampling for supervised contrastive speaker verification</title>
      <link>http://arxiv.org/abs/2507.17540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to INTERSPEECH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CHNS的基于聚类的硬负样本采样方法，用于监督对比学习下的说话人表征学习，实验结果表明其性能优于多种基准方法。&lt;h4&gt;背景&lt;/h4&gt;在说话人验证中，对比学习方法逐渐替代传统的基于分类的方法，而硬负样本的有效使用可以提高对比方法的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的硬负样本采样方法CHNS，以提高监督对比学习在说话人验证任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;CHNS通过聚类相似说话人的嵌入，并调整批处理组成以在对比损失计算中获得最佳的硬负样本与易负样本的比例。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CHNS在VoxCeleb数据集上使用两种轻量级模型架构，与带有或不带有基于损失的硬负样本采样的基线监督对比方法，以及最先进的基于分类的方法相比，在EER和minDCF指标上分别提高了18%。&lt;h4&gt;结论&lt;/h4&gt;CHNS方法能够有效提高说话人验证任务的性能，是一个具有潜力的新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In speaker verification, contrastive learning is gaining popularity as analternative to the traditionally used classification-based approaches.Contrastive methods can benefit from an effective use of hard negative pairs,which are different-class samples particularly challenging for a verificationmodel due to their similarity. In this paper, we propose CHNS - aclustering-based hard negative sampling method, dedicated for supervisedcontrastive speaker representation learning. Our approach clusters embeddingsof similar speakers, and adjusts batch composition to obtain an optimal ratioof hard and easy negatives during contrastive loss calculation. Experimentalevaluation shows that CHNS outperforms a baseline supervised contrastiveapproach with and without loss-based hard negative sampling, as well as astate-of-the-art classification-based approach to speaker verification by asmuch as 18 % relative EER and minDCF on the VoxCeleb dataset using twolightweight model architectures.</description>
      <author>example@mail.com (Piotr Masztalski, Michał Romaniuk, Jakub Żak, Mateusz Matuszewski, Konrad Kowalczyk)</author>
      <guid isPermaLink="false">2507.17540v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Towards Effective Open-set Graph Class-incremental Learning</title>
      <link>http://arxiv.org/abs/2507.17687v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by 33rd ACM International Conference on Multimedia (MM 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的开放集图类增量学习（OGCIL）框架，旨在解决传统GCIL方法在开放集场景下的灾难性遗忘和开放集识别不足的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的GCIL方法主要基于闭集假设，限制了其在未知类别自然出现而训练数据中不存在的实际场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;解决开放集场景下的灾难性遗忘和开放集识别不足的问题，以使图神经网络（GNNs）能够适应不断发展的图分析任务。&lt;h4&gt;方法&lt;/h4&gt;OGCIL框架通过伪样本嵌入生成来缓解灾难性遗忘，并利用基于混合的策略生成异常值样本以检测未知类别。此外，还提出了一个新型的原型超球面分类损失函数，以实现鲁棒的开放集识别。&lt;h4&gt;主要发现&lt;/h4&gt;OGCIL框架在五个基准数据集上的实验表明，它在开放集识别方面优于现有的GCIL和开放集GNN方法。&lt;h4&gt;结论&lt;/h4&gt;OGCIL框架能够有效地解决开放集图类增量学习中的挑战，为GNNs在动态图分析任务中的应用提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Graph class-incremental learning (GCIL) allows graph neural networks (GNNs) to adapt to evolving graph analytical tasks by incrementally learning new class knowledge while retaining knowledge of old classes. Existing GCIL methods primarily focus on a closed-set assumption, where all test samples are presumed to belong to previously known classes. Such an assumption restricts their applicability in real-world scenarios, where unknown classes naturally emerged during inference, and are absent during training. In this paper, we explore a more challenging open-set graph class-incremental learning scenario with two intertwined challenges: catastrophic forgetting of old classes, which impairs the detection of unknown classes, and inadequate open-set recognition, which destabilizes the retention of learned knowledge. To address the above problems, a novel OGCIL framework is proposed, which utilizes pseudo-sample embedding generation to effectively mitigate catastrophic forgetting and enable robust detection of unknown classes. To be specific, a prototypical conditional variational autoencoder is designed to synthesize node embeddings for old classes, enabling knowledge replay without storing raw graph data. To handle unknown classes, we employ a mixing-based strategy to generate out-of-distribution (OOD) samples from pseudo in-distribution and current node embeddings. A novel prototypical hypersphere classification loss is further proposed, which anchors in-distribution embeddings to their respective class prototypes, while repelling OOD embeddings away. Instead of assigning all unknown samples into one cluster, our proposed objective function explicitly models them as outliers through prototype-aware rejection regions, ensuring a robust open-set recognition. Extensive experiments on five benchmarks demonstrate the effectiveness of OGCIL over existing GCIL and open-set GNN methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph class-incremental learning (GCIL) allows graph neural networks (GNNs)to adapt to evolving graph analytical tasks by incrementally learning new classknowledge while retaining knowledge of old classes. Existing GCIL methodsprimarily focus on a closed-set assumption, where all test samples are presumedto belong to previously known classes. Such an assumption restricts theirapplicability in real-world scenarios, where unknown classes naturally emergeduring inference, and are absent during training. In this paper, we explore amore challenging open-set graph class-incremental learning scenario with twointertwined challenges: catastrophic forgetting of old classes, which impairsthe detection of unknown classes, and inadequate open-set recognition, whichdestabilizes the retention of learned knowledge. To address the above problems,a novel OGCIL framework is proposed, which utilizes pseudo-sample embeddinggeneration to effectively mitigate catastrophic forgetting and enable robustdetection of unknown classes. To be specific, a prototypical conditionalvariational autoencoder is designed to synthesize node embeddings for oldclasses, enabling knowledge replay without storing raw graph data. To handleunknown classes, we employ a mixing-based strategy to generateout-of-distribution (OOD) samples from pseudo in-distribution and current nodeembeddings. A novel prototypical hypersphere classification loss is furtherproposed, which anchors in-distribution embeddings to their respective classprototypes, while repelling OOD embeddings away. Instead of assigning allunknown samples into one cluster, our proposed objective function explicitlymodels them as outliers through prototype-aware rejection regions, ensuring arobust open-set recognition. Extensive experiments on five benchmarksdemonstrate the effectiveness of OGCIL over existing GCIL and open-set GNNmethods.</description>
      <author>example@mail.com (Jiazhen Chen, Zheng Ma, Sichao Fu, Mingbin Feng, Tony S. Wirjanto, Weihua Ou)</author>
      <guid isPermaLink="false">2507.17687v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding</title>
      <link>http://arxiv.org/abs/2507.17585v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the OpenSUN3D Workshop, CVPR 2025. This workshop paper is  not included in the official CVPR proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种有效利用现实世界3D场景扫描及其注释的方法，并通过两个下游应用展示了其有效性。&lt;h4&gt;背景&lt;/h4&gt;现实世界3D场景扫描具有真实感，可以提高下游应用的现实世界泛化能力，但数据量、多样化的注释格式和工具兼容性问题限制了其使用。&lt;h4&gt;目的&lt;/h4&gt;提出一种统一注释集成方法，以有效地利用这些扫描和其注释。&lt;h4&gt;方法&lt;/h4&gt;使用USD进行统一注释集成，并针对特定应用提出USD的特定版本。识别利用整体现实世界扫描数据集的挑战，并提出缓解策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过两个下游应用验证了方法的有效性：基于LLM的场景编辑，实现了LLM对数据的理解和适应（成功率为80%），以及机器人模拟，在策略学习中的成功率为87%。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效利用现实世界3D场景扫描，并通过实际应用验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Real-world 3D scene-level scans offer realism and can enable better real-world generalizability for downstream applications. However, challenges such as data volume, diverse annotation formats, and tool compatibility limit their use. This paper demonstrates a methodology to effectively leverage these scans and their annotations. We propose a unified annotation integration using USD, with application-specific USD flavors. We identify challenges in utilizing holistic real-world scan datasets and present mitigation strategies. The efficacy of our approach is demonstrated through two downstream applications: LLM-based scene editing, enabling effective LLM understanding and adaptation of the data (80% success), and robotic simulation, achieving an 87% success rate in policy learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world 3D scene-level scans offer realism and can enable betterreal-world generalizability for downstream applications. However, challengessuch as data volume, diverse annotation formats, and tool compatibility limittheir use. This paper demonstrates a methodology to effectively leverage thesescans and their annotations. We propose a unified annotation integration usingUSD, with application-specific USD flavors. We identify challenges in utilizingholistic real-world scan datasets and present mitigation strategies. Theefficacy of our approach is demonstrated through two downstream applications:LLM-based scene editing, enabling effective LLM understanding and adaptation ofthe data (80% success), and robotic simulation, achieving an 87% success ratein policy learning.</description>
      <author>example@mail.com (Anna-Maria Halacheva, Jan-Nico Zaech, Sombit Dey, Luc Van Gool, Danda Pani Paudel)</author>
      <guid isPermaLink="false">2507.17585v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network Approach to Predicting Magnetization in Quasi-One-Dimensional Ising Systems</title>
      <link>http://arxiv.org/abs/2507.17509v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图的深度学习框架，用于预测准一维伊辛自旋系统的磁性。&lt;h4&gt;背景&lt;/h4&gt;利用图神经网络（GNN）处理晶格几何，并在此基础上使用全连接层。&lt;h4&gt;目的&lt;/h4&gt;通过蒙特卡洛模拟数据训练模型，以准确重现磁化曲线的关键特征。&lt;h4&gt;方法&lt;/h4&gt;模型训练于蒙特卡洛模拟数据，并能够捕捉局部模式和全局对称性。&lt;h4&gt;主要发现&lt;/h4&gt;GNN可以直接从结构连通性推断出磁性行为，且能够高效预测磁化而不需要额外的蒙特卡洛模拟。&lt;h4&gt;结论&lt;/h4&gt;该方法为磁化预测提供了一种高效且无需额外蒙特卡洛模拟的方法。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种基于图的深度学习框架，用于预测准一维伊辛自旋系统的磁性。晶格几何被编码为图，并通过图神经网络（GNN）处理，随后接入全连接层。该模型在蒙特卡洛模拟数据上训练，并精确地再现了磁化曲线的关键特征，包括平台期、临界转变点和几何挫折效应。它捕捉了局部模式和全局对称性，表明GNN可以直接从结构连通性推断出磁性行为。所提出的方法使得在无需额外蒙特卡洛模拟的情况下高效预测磁化成为可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a graph-based deep learning framework for predicting the magneticproperties of quasi-one-dimensional Ising spin systems. The lattice geometry isencoded as a graph and processed by a graph neural network (GNN) followed byfully connected layers. The model is trained on Monte Carlo simulation data andaccurately reproduces key features of the magnetization curve, includingplateaus, critical transition points, and the effects of geometric frustration.It captures both local motifs and global symmetries, demonstrating that GNNscan infer magnetic behavior directly from structural connectivity. The proposedapproach enables efficient prediction of magnetization without the need foradditional Monte Carlo simulations.</description>
      <author>example@mail.com (V. Slavin, O. Kryvchikov, D. Laptev)</author>
      <guid isPermaLink="false">2507.17509v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>RoadBench: A Vision-Language Foundation Model and Benchmark for Road Damage Understanding</title>
      <link>http://arxiv.org/abs/2507.17353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了RoadBench，一个用于全面理解道路损坏的多模态基准数据集，以及基于CLIP的RoadCLIP视觉语言模型，旨在提高道路损坏检测的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的仅基于视觉的道路损坏数据集和模型缺乏对文本信息的丰富上下文理解，这限制了道路损坏检测的准确性。&lt;h4&gt;目的&lt;/h4&gt;提出RoadBench和RoadCLIP，以解决现有方法的局限性，提高道路损坏检测的准确性。&lt;h4&gt;方法&lt;/h4&gt;RoadBench结合了高分辨率道路损坏图像和详细的文本描述，RoadCLIP通过集成特定领域的增强来改进CLIP模型，包括疾病感知的位置编码和注入道路条件先验的机制。此外，使用GPT驱动的数据生成管道来扩展RoadBench中的图像到文本对。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，RoadCLIP在道路损坏识别任务上达到了最先进的性能，比现有的仅视觉模型提高了19.2%。&lt;h4&gt;结论&lt;/h4&gt;这些结果强调了结合视觉和文本信息进行道路状况分析的优势，为该领域设定了新的基准，并为通过多模态学习更有效地监测基础设施铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Accurate road damage detection is crucial for timely infrastructure maintenance and public safety, but existing vision-only datasets and models lack the rich contextual understanding that textual information can provide. To address this limitation, we introduce RoadBench, the first multimodal benchmark for comprehensive road damage understanding. This dataset pairs high resolution images of road damages with detailed textual descriptions, providing a richer context for model training. We also present RoadCLIP, a novel vision language model that builds upon CLIP by integrating domain specific enhancements. It includes a disease aware positional encoding that captures spatial patterns of road defects and a mechanism for injecting road-condition priors to refine the model's understanding of road damages. We further employ a GPT driven data generation pipeline to expand the image to text pairs in RoadBench, greatly increasing data diversity without exhaustive manual annotation. Experiments demonstrate that RoadCLIP achieves state of the art performance on road damage recognition tasks, significantly outperforming existing vision-only models by 19.2%. These results highlight the advantages of integrating visual and textual information for enhanced road condition analysis, setting new benchmarks for the field and paving the way for more effective infrastructure monitoring through multimodal learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate road damage detection is crucial for timely infrastructuremaintenance and public safety, but existing vision-only datasets and modelslack the rich contextual understanding that textual information can provide. Toaddress this limitation, we introduce RoadBench, the first multimodal benchmarkfor comprehensive road damage understanding. This dataset pairs high resolutionimages of road damages with detailed textual descriptions, providing a richercontext for model training. We also present RoadCLIP, a novel vision languagemodel that builds upon CLIP by integrating domain specific enhancements. Itincludes a disease aware positional encoding that captures spatial patterns ofroad defects and a mechanism for injecting road-condition priors to refine themodel's understanding of road damages. We further employ a GPT driven datageneration pipeline to expand the image to text pairs in RoadBench, greatlyincreasing data diversity without exhaustive manual annotation. Experimentsdemonstrate that RoadCLIP achieves state of the art performance on road damagerecognition tasks, significantly outperforming existing vision-only models by19.2%. These results highlight the advantages of integrating visual and textualinformation for enhanced road condition analysis, setting new benchmarks forthe field and paving the way for more effective infrastructure monitoringthrough multimodal learning.</description>
      <author>example@mail.com (Xi Xiao, Yunbei Zhang, Janet Wang, Lin Zhao, Yuxiang Wei, Hengjia Li, Yanshu Li, Xiao Wang, Swalpa Kumar Roy, Hao Xu, Tianyang Wang)</author>
      <guid isPermaLink="false">2507.17353v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Few-Shot Learning in Video and 3D Object Detection: A Survey</title>
      <link>http://arxiv.org/abs/2507.17079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review in ACM Computing Surveys&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文调查了针对视频和3D目标检测的Few-shot learning (FSL)的最新进展，旨在减少昂贵的标注数据需求。&lt;h4&gt;背景&lt;/h4&gt;FSL允许目标检测模型在仅有少量标注示例的情况下识别新的类别，这对于视频和3D对象检测尤为重要，因为相较于静态图像，对视频帧中对象进行标注更加耗时。&lt;h4&gt;目的&lt;/h4&gt;本文的目的是分析FSL在视频和3D对象检测中的最近进展，并探讨其在减少标注需求和提高实际应用中的潜力。&lt;h4&gt;方法&lt;/h4&gt;对于视频，通过跨帧传递信息，如管状候选框和时间匹配网络等技术，可以从少量示例中检测新类别，有效地利用时空结构。对于3D检测，将FSL与专用的点云网络和针对类别不平衡定制的损失函数相结合，以应对稀疏性和纹理缺乏等挑战。&lt;h4&gt;主要发现&lt;/h4&gt;FSL在视频和3D检测中都显示出潜力，能够在减少标注需求的同时，通过有效利用特征、时间和数据模态的信息，实现现实世界的应用。核心问题包括平衡泛化能力和过拟合、集成原型匹配以及处理数据模态特性。&lt;h4&gt;结论&lt;/h4&gt;FSL有望通过有效地利用特征、时间和数据模态的信息来减少标注需求，并实现视频、3D和其他现实世界应用的部署。本文通过全面调查最近的进展，展示了FSL在减少监督需求方面的潜力，并使其在视频、3D和其他实际应用中得以部署。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了Few-shot learning（FSL）在视频和3D目标检测方面的最新进展，旨在减少昂贵的标注数据需求。FSL能够使目标检测模型在仅提供少量标注示例的情况下识别新类别，这对于视频和3D对象检测尤为重要，因为标注视频帧中的对象比标注静态图像更耗时。本文旨在分析FSL在视频和3D对象检测中的最近进展，并探讨其在减少标注需求和提高实际应用潜力方面的作用。对于视频，通过跨帧传递信息，如管状候选框和时间匹配网络等技术，可以从少量示例中检测新类别，有效地利用时空结构。对于3D检测，将FSL与专用的点云网络和针对类别不平衡定制的损失函数相结合，以应对稀疏性和纹理缺乏等挑战。FSL在视频和3D检测中都显示出潜力，能够在减少标注需求的同时，通过有效利用特征、时间和数据模态的信息，实现现实世界的应用。在两个领域中的核心问题包括平衡泛化能力和过拟合、集成原型匹配以及处理数据模态特性。总的来说，FSL有望通过有效地利用特征、时间和数据模态的信息来减少标注需求，并实现视频、3D和其他现实世界应用的部署。本文通过全面调查最近的进展，展示了FSL在减少监督需求方面的潜力，并使其在视频、3D和其他实际应用中得以部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot learning (FSL) enables object detection models to recognize novelclasses given only a few annotated examples, thereby reducing expensive manualdata labeling. This survey examines recent FSL advances for video and 3D objectdetection. For video, FSL is especially valuable since annotating objectsacross frames is more laborious than for static images. By propagatinginformation across frames, techniques like tube proposals and temporal matchingnetworks can detect new classes from a couple examples, efficiently leveragingspatiotemporal structure. FSL for 3D detection from LiDAR or depth data faceschallenges like sparsity and lack of texture. Solutions integrate FSL withspecialized point cloud networks and losses tailored for class imbalance.Few-shot 3D detection enables practical autonomous driving deployment byminimizing costly 3D annotation needs. Core issues in both domains includebalancing generalization and overfitting, integrating prototype matching, andhandling data modality properties. In summary, FSL shows promise for reducingannotation requirements and enabling real-world video, 3D, and otherapplications by efficiently leveraging information across feature, temporal,and data modalities. By comprehensively surveying recent advancements, thispaper illuminates FSL's potential to minimize supervision needs and enabledeployment across video, 3D, and other real-world applications.</description>
      <author>example@mail.com (Md Meftahul Ferdaus, Kendall N. Niles, Joe Tom, Mahdi Abdelguerfi, Elias Ioup)</author>
      <guid isPermaLink="false">2507.17079v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>HLFormer: Enhancing Partially Relevant Video Retrieval with Hyperbolic Learning</title>
      <link>http://arxiv.org/abs/2507.17402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV'25. 13 pages, 6 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HLFormer的基于双曲空间学习的部分相关视频检索（PRVR）方法，用于解决只描述视频部分内容的文本查询与未剪辑视频匹配的问题。&lt;h4&gt;背景&lt;/h4&gt;现有方法在欧几里得空间中存在几何扭曲，有时会错误地表示视频的内在层次结构，并忽略了某些层次语义，最终导致次优的时间建模。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的方法，即利用双曲空间学习来补偿欧几里得空间在层次建模方面的不足。&lt;h4&gt;方法&lt;/h4&gt;HLFormer集成了洛伦兹注意力块和欧几里得注意力块，以混合空间编码视频嵌入，并使用平均引导自适应交互模块动态融合特征。此外，还引入了部分顺序保持损失，通过洛伦兹锥约束强制执行“文本 &lt; 视频”的层次结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，HLFormer在跨模态匹配方面进一步增强了部分相关性，并优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;HLFormer是一个有效的PRVR框架，能够提高视频检索的准确性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel method named HLFormer, a hyperbolic space learning-based Partially Relevant Video Retrieval (PRVR) framework, to address the problem of matching untrimmed videos with text queries describing only partial content.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partially Relevant Video Retrieval (PRVR) addresses the critical challenge ofmatching untrimmed videos with text queries describing only partial content.Existing methods suffer from geometric distortion in Euclidean space thatsometimes misrepresents the intrinsic hierarchical structure of videos andoverlooks certain hierarchical semantics, ultimately leading to suboptimaltemporal modeling. To address this issue, we propose the first hyperbolicmodeling framework for PRVR, namely HLFormer, which leverages hyperbolic spacelearning to compensate for the suboptimal hierarchical modeling capabilities ofEuclidean space. Specifically, HLFormer integrates the Lorentz Attention Blockand Euclidean Attention Block to encode video embeddings in hybrid spaces,using the Mean-Guided Adaptive Interaction Module to dynamically fuse features.Additionally, we introduce a Partial Order Preservation Loss to enforce "text &lt;video" hierarchy through Lorentzian cone constraints. This approach furtherenhances cross-modal matching by reinforcing partial relevance between videocontent and text queries. Extensive experiments show that HLFormer outperformsstate-of-the-art methods. Code is released athttps://github.com/lijun2005/ICCV25-HLFormer.</description>
      <author>example@mail.com (Li Jun, Wang Jinpeng, Tan Chaolei, Lian Niu, Chen Long, Zhang Min, Wang Yaowei, Xia Shu-Tao, Chen Bin)</author>
      <guid isPermaLink="false">2507.17402v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>How Should We Meta-Learn Reinforcement Learning Algorithms?</title>
      <link>http://arxiv.org/abs/2507.17668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted paper at Reinforcement Learning Conference (RLC) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过实证比较不同元学习算法，研究了元学习在强化学习（RL）中的应用，并提出了优化未来RL算法的指导原则。&lt;h4&gt;背景&lt;/h4&gt;元学习算法越来越受到欢迎，因为它可以从数据中学习算法，而不是依赖于人工设计，这有助于提高机器学习系统的性能。元学习在强化学习领域显示出特别的前景，尽管从监督或无监督学习中改编的算法对于RL来说可能不是最优的。&lt;h4&gt;目的&lt;/h4&gt;对比不同元学习算法在强化学习中的应用效果，并研究元学习算法的可解释性、样本成本和训练时间等因素。&lt;h4&gt;方法&lt;/h4&gt;本文进行了一系列实证比较，涉及多种针对RL不同部分的元学习算法，并分析了元训练和元测试性能，以及其他相关因素。&lt;h4&gt;主要发现&lt;/h4&gt;通过比较发现，不同的元学习算法在性能和效率方面存在差异，同时考虑可解释性、样本成本和训练时间等因素对算法性能有重要影响。&lt;h4&gt;结论&lt;/h4&gt;根据研究结果，提出了优化元学习新RL算法的指导原则，以确保未来学习的算法尽可能高效。&lt;h4&gt;翻译&lt;/h4&gt;Meta-learning algorithms from data, instead of relying on manual design, are growing in popularity as a paradigm for improving the performance of machine learning systems. Meta-learning shows particular promise for reinforcement learning (RL), where algorithms are often adapted from supervised or unsupervised learning despite their suboptimality for RL. However, until now there has been a severe lack of comparison between different meta-learning algorithms, such as using evolution to optimise over black-box functions or LLMs to propose code. In this paper, we carry out this empirical comparison of the different approaches when applied to a range of meta-learned algorithms which target different parts of the RL pipeline. In addition to meta-train and meta-test performance, we also investigate factors including the interpretability, sample cost and train time for each meta-learning algorithm. Based on these findings, we propose several guidelines for meta-learning new RL algorithms which will help ensure that future learned algorithms are as performant as possible.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The process of meta-learning algorithms from data, instead of relying onmanual design, is growing in popularity as a paradigm for improving theperformance of machine learning systems. Meta-learning shows particular promisefor reinforcement learning (RL), where algorithms are often adapted fromsupervised or unsupervised learning despite their suboptimality for RL.However, until now there has been a severe lack of comparison between differentmeta-learning algorithms, such as using evolution to optimise over black-boxfunctions or LLMs to propose code. In this paper, we carry out this empiricalcomparison of the different approaches when applied to a range of meta-learnedalgorithms which target different parts of the RL pipeline. In addition tometa-train and meta-test performance, we also investigate factors including theinterpretability, sample cost and train time for each meta-learning algorithm.Based on these findings, we propose several guidelines for meta-learning new RLalgorithms which will help ensure that future learned algorithms are asperformant as possible.</description>
      <author>example@mail.com (Alexander David Goldie, Zilin Wang, Jakob Nicolaus Foerster, Shimon Whiteson)</author>
      <guid isPermaLink="false">2507.17668v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Citation Recommendation using Deep Canonical Correlation Analysis</title>
      <link>http://arxiv.org/abs/2507.17603v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 6 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的引用推荐算法，通过应用深度相关分析（DCCA）来改进传统的线性相关分析（CCA）方法，从而提高了推荐准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的引用推荐方法通过多视角表示学习来整合学术文献中的各种模态，但需要融合技术来捕捉互补信息并保留每种模态的独特特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的引用推荐算法，通过应用DCCA来提高推荐准确性。&lt;h4&gt;方法&lt;/h4&gt;算法基于DCCA，这是一种神经网络扩展，能够捕捉科学文章分布式文本和基于图表示之间的复杂、非线性关系。&lt;h4&gt;主要发现&lt;/h4&gt;在DBLP引用网络数据集上的实验表明，该方法优于基于CCA的现有方法，在平均平均精度@10、精度@10和召回率@10方面分别提高了超过11%、5%和7%。&lt;h4&gt;结论&lt;/h4&gt;DCCA的非线性变换比CCA的线性投影产生了更具表达力的潜在表示，从而提高了推荐的相关性和排名质量。&lt;h4&gt;翻译&lt;/h4&gt;近期在引用推荐领域的研究进展通过利用多视角表示学习来提高准确性。然而，有效地结合多个数据视图需要融合技术来捕捉互补信息并保留每种模态的独特特征。本文提出了一种新的引用推荐算法，通过应用深度相关分析（DCCA）来改进传统的线性相关分析（CCA）方法。在大型DBLP（数字文献与图书馆项目）引用网络数据集上的实验表明，该方法在平均平均精度@10、精度@10和召回率@10方面均优于现有方法，实现了超过11%、5%和7%的相对改进。这些改进反映了更相关的引用推荐和增强的排名质量，表明DCCA的非线性变换比CCA的线性投影产生了更具表达力的潜在表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in citation recommendation have improved accuracy byleveraging multi-view representation learning to integrate the variousmodalities present in scholarly documents. However, effectively combiningmultiple data views requires fusion techniques that can capture complementaryinformation while preserving the unique characteristics of each modality. Wepropose a novel citation recommendation algorithm that improves upon linearCanonical Correlation Analysis (CCA) methods by applying Deep CCA (DCCA), aneural network extension capable of capturing complex, non-linear relationshipsbetween distributed textual and graph-based representations of scientificarticles. Experiments on the large-scale DBLP (Digital Bibliography &amp; LibraryProject) citation network dataset demonstrate that our approach outperformsstate-of-the-art CCA-based methods, achieving relative improvements of over 11%in Mean Average Precision@10, 5% in Precision@10, and 7% in Recall@10. Thesegains reflect more relevant citation recommendations and enhanced rankingquality, suggesting that DCCA's non-linear transformations yield moreexpressive latent representations than CCA's linear projections.</description>
      <author>example@mail.com (Conor McNamara, Effirul Ramlan)</author>
      <guid isPermaLink="false">2507.17603v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>When and Where Localization Fails: An Analysis of the Iterative Closest Point in Evolving Environment</title>
      <link>http://arxiv.org/abs/2507.17531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 7 figures, proceedings in European Conference on Mobile  Robots (ECMR) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了动态户外环境中3D激光雷达辅助的鲁棒重定位问题，提出了一个高分辨率、短期多时相数据集，并使用ICP算法评估了扫描与地图对齐的准确性。&lt;h4&gt;背景&lt;/h4&gt;动态户外环境中的短期环境变化对自主系统来说是一个关键挑战，尽管长期定位已经得到广泛研究，但短期环境变化的研究还相对较少。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一研究空白，本文旨在提供一种评估短期定位鲁棒性的结构化数据集，以及分析扫描与地图对齐的框架。&lt;h4&gt;方法&lt;/h4&gt;收集了2025年2月至4月期间每周从自然和半城市环境中收集的高分辨率、短期多时相数据集，包括高密度点云图、360度全景图像和轨迹数据。使用点云图生成的投影激光扫描，并考虑传感器精确的遮挡建模，通过两种ICP变体（点对点和点对平面）评估对齐精度。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，点对平面ICP在特征稀疏或植被密集的区域提供了更稳定和准确的对齐。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了局部几何和环境可变性对定位成功的影响，为设计更鲁棒的机器人系统提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;Robust relocalization in dynamic outdoor environments remains a key challenge for autonomous systems relying on 3D lidar. While long-term localization has been widely studied, short-term environmental changes, occurring over days or weeks, remain underexplored despite their practical significance. To address this gap, we present a high-resolution, short-term multi-temporal dataset collected weekly from February to April 2025 across natural and semi-urban settings. Each session includes high-density point cloud maps, 360 deg panoramic images, and trajectory data. Projected lidar scans, derived from the point cloud maps and modeled with sensor-accurate occlusions, are used to evaluate alignment accuracy against the ground truth using two Iterative Closest Point (ICP) variants: Point-to-Point and Point-to-Plane. Results show that Point-to-Plane offers significantly more stable and accurate registration, particularly in areas with sparse features or dense vegetation. This study provides a structured dataset for evaluating short-term localization robustness, a reproducible framework for analyzing scan-to-map alignment under noise, and a comparative evaluation of ICP performance in evolving outdoor environments. Our analysis underscores how local geometry and environmental variability affect localization success, offering insights for designing more resilient robotic systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust relocalization in dynamic outdoor environments remains a key challengefor autonomous systems relying on 3D lidar. While long-term localization hasbeen widely studied, short-term environmental changes, occurring over days orweeks, remain underexplored despite their practical significance. To addressthis gap, we present a highresolution, short-term multi-temporal datasetcollected weekly from February to April 2025 across natural and semi-urbansettings. Each session includes high-density point cloud maps, 360 degpanoramic images, and trajectory data. Projected lidar scans, derived from thepoint cloud maps and modeled with sensor-accurate occlusions, are used toevaluate alignment accuracy against the ground truth using two IterativeClosest Point (ICP) variants: Point-to-Point and Point-to-Plane. Results showthat Point-to-Plane offers significantly more stable and accurate registration,particularly in areas with sparse features or dense vegetation. This studyprovides a structured dataset for evaluating short-term localizationrobustness, a reproducible framework for analyzing scan-to-map alignment undernoise, and a comparative evaluation of ICP performance in evolving outdoorenvironments. Our analysis underscores how local geometry and environmentalvariability affect localization success, offering insights for designing moreresilient robotic systems.</description>
      <author>example@mail.com (Abdel-Raouf Dannaoui, Johann Laconte, Christophe Debain, Francois Pomerleau, Paul Checchin)</author>
      <guid isPermaLink="false">2507.17531v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery</title>
      <link>http://arxiv.org/abs/2507.17209v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HypoChainer的协作可视化框架，旨在通过整合人类专业知识、LLM驱动的推理和知识图谱来增强假设生成和验证，以应对现代科学发现中的挑战。&lt;h4&gt;背景&lt;/h4&gt;现代科学发现面临整合大量异质知识以实现生物医学和药物开发突破的挑战。传统假设驱动研究受限于人类认知限制、生物系统复杂性和实验的高成本。&lt;h4&gt;目的&lt;/h4&gt;提出HypoChainer框架，以解决传统研究方法的局限性，提高假设生成和验证的效率和可靠性。&lt;h4&gt;方法&lt;/h4&gt;HypoChainer框架包括三个阶段：探索和情境化、假设链形成、验证优先级。使用RAGs和降维技术导航大规模GNN预测，并通过交互式解释辅助；专家迭代检查KG关系和语义相关实体，利用LLM和KG建议细化假设；基于KG支持的证据过滤假设，识别高优先级实验候选，并通过可视化分析加强推理中的薄弱环节。&lt;h4&gt;主要发现&lt;/h4&gt;通过案例研究和专家访谈，证明了HypoChainer在两个领域的有效性，突出了其在支持可解释、可扩展和基于知识的科学发现方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;HypoChainer框架能够有效支持科学发现，通过结合人类专业知识、LLM和知识图谱，提高假设生成和验证的效率和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern scientific discovery faces growing challenges in integrating vast andheterogeneous knowledge critical to breakthroughs in biomedicine and drugdevelopment. Traditional hypothesis-driven research, though effective, isconstrained by human cognitive limits, the complexity of biological systems,and the high cost of trial-and-error experimentation. Deep learning models,especially graph neural networks (GNNs), have accelerated predictiongeneration, but the sheer volume of outputs makes manual selection forvalidation unscalable. Large language models (LLMs) offer promise in filteringand hypothesis generation, yet suffer from hallucinations and lack grounding instructured knowledge, limiting their reliability. To address these issues, wepropose HypoChainer, a collaborative visualization framework that integrateshuman expertise, LLM-driven reasoning, and knowledge graphs (KGs) to enhancehypothesis generation and validation. HypoChainer operates in three stages:First, exploration and contextualization -- experts use retrieval-augmentedLLMs (RAGs) and dimensionality reduction to navigate large-scale GNNpredictions, assisted by interactive explanations. Second, hypothesis chainformation -- experts iteratively examine KG relationships around predictionsand semantically linked entities, refining hypotheses with LLM and KGsuggestions. Third, validation prioritization -- refined hypotheses arefiltered based on KG-supported evidence to identify high-priority candidatesfor experimentation, with visual analytics further strengthening weak links inreasoning. We demonstrate HypoChainer's effectiveness through case studies intwo domains and expert interviews, highlighting its potential to supportinterpretable, scalable, and knowledge-grounded scientific discovery.</description>
      <author>example@mail.com (Haoran Jiang, Shaohan Shi, Yunjie Yao, Chang Jiang, Quan Li)</author>
      <guid isPermaLink="false">2507.17209v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>CartoonAlive: Towards Expressive Live2D Modeling from Single Portraits</title>
      <link>http://arxiv.org/abs/2507.17327v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为CartoonAlive的创新方法，用于从单个输入肖像图像生成高质量的Live2D数字人类。&lt;h4&gt;背景&lt;/h4&gt;随着大型基础模型、AIGC、云渲染和实时动作捕捉技术的快速发展，数字人类能够实现同步的面部表情和身体动作，进行智能对话，并快速创建个性化头像。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种高效且富有表现力的解决方案，用于创建交互式2D卡通角色。&lt;h4&gt;方法&lt;/h4&gt;CartoonAlive利用3D面建模中常用的形状基概念来构建适合Live2D的面部混合形状，并基于从输入图像中检测到的面部关键点来推断相应的混合形状权重。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法可以在不到半分钟内快速生成一个高度表达和视觉准确的Live2D模型，该模型与输入肖像非常相似。&lt;h4&gt;结论&lt;/h4&gt;CartoonAlive为创建交互式2D卡通角色提供了一种实用且可扩展的解决方案，为数字内容创作和虚拟角色动画开辟了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了CartoonAlive，一种从单个输入肖像图像生成高质量Live2D数字人类的新方法。该方法结合了3D面建模的形状基概念，通过快速生成与输入肖像高度相似的Live2D模型，为创建交互式2D卡通角色提供了实用且可扩展的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancement of large foundation models, AIGC, cloud rendering,and real-time motion capture technologies, digital humans are now capable ofachieving synchronized facial expressions and body movements, engaging inintelligent dialogues driven by natural language, and enabling the fastcreation of personalized avatars. While current mainstream approaches todigital humans primarily focus on 3D models and 2D video-based representations,interactive 2D cartoon-style digital humans have received relatively lessattention. Compared to 3D digital humans that require complex modeling and highrendering costs, and 2D video-based solutions that lack flexibility andreal-time interactivity, 2D cartoon-style Live2D models offer a more efficientand expressive alternative. By simulating 3D-like motion through layeredsegmentation without the need for traditional 3D modeling, Live2D enablesdynamic and real-time manipulation. In this technical report, we presentCartoonAlive, an innovative method for generating high-quality Live2D digitalhumans from a single input portrait image. CartoonAlive leverages the shapebasis concept commonly used in 3D face modeling to construct facial blendshapessuitable for Live2D. It then infers the corresponding blendshape weights basedon facial keypoints detected from the input image. This approach allows for therapid generation of a highly expressive and visually accurate Live2D model thatclosely resembles the input portrait, within less than half a minute. Our workprovides a practical and scalable solution for creating interactive 2D cartooncharacters, opening new possibilities in digital content creation and virtualcharacter animation. The project homepage ishttps://human3daigc.github.io/CartoonAlive_webpage/.</description>
      <author>example@mail.com (Chao He, Jianqiang Ren, Jianjing Xiang, Xiejie Shen)</author>
      <guid isPermaLink="false">2507.17327v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>IONext: Unlocking the Next Era of Inertial Odometry</title>
      <link>http://arxiv.org/abs/2507.17089v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于CNN的惯性里程计模块，通过结合大核卷积和Transformer启发式设计，提高了全局运动感知能力，并通过实验证明了其在多个数据集上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型在惯性里程计中应用广泛，但其在局部运动变化敏感度和归纳偏置方面的不足限制了定位精度和泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的CNN模块，旨在提高惯性里程计的定位精度和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;设计了一种名为DADM的模块，能够自适应地捕捉全局和局部运动特征；引入了STGU单元，用于在时间域中提取代表性的运动特征；构建了基于DADM和STGU的CNN惯性里程计模型IONext。&lt;h4&gt;主要发现&lt;/h4&gt;IONext在六个公开数据集上优于现有的基于Transformer和CNN的方法，例如在RNIN数据集上平均ATE降低了10%，平均RTE降低了12%。&lt;h4&gt;结论&lt;/h4&gt;DADM和STGU模块有效地提高了惯性里程计的性能，IONext模型在多个数据集上实现了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：研究人员越来越多地采用基于Transformer的模型进行惯性里程计。虽然Transformer在建模长距离依赖关系方面表现出色，但它们对局部、精细的运动变化的敏感性有限，以及缺乏固有的归纳偏置，通常阻碍了定位精度和泛化能力。最近的研究表明，将大核卷积和Transformer启发的架构设计纳入CNN中可以有效地扩展感受野，从而提高全局运动感知。受这些见解的启发，我们提出了一种新的基于CNN的模块，称为双翼自适应动态混合器（DADM），该模块能够自适应地从动态输入中捕捉全局运动模式和局部、精细的运动特征。该模块根据输入动态生成选择权重，从而实现高效的多尺度特征聚合。为了进一步提高时间建模，我们引入了时空门控单元（STGU），该单元在时间域中选择性地提取代表性的和与任务相关的运动特征。该单元解决了现有CNN方法中观察到的时间建模的局限性。基于DADM和STGU，我们提出了一种新的基于CNN的惯性里程计主干网络，称为下一代惯性里程计（IONext）。在六个公开数据集上的大量实验表明，IONext在性能上始终优于最先进的（SOTA）基于Transformer和CNN的方法。例如，在RNIN数据集上，与代表性模型iMOT相比，IONext将平均ATE降低了10%，平均RTE降低了12%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Researchers have increasingly adopted Transformer-based models for inertialodometry. While Transformers excel at modeling long-range dependencies, theirlimited sensitivity to local, fine-grained motion variations and lack ofinherent inductive biases often hinder localization accuracy andgeneralization. Recent studies have shown that incorporating large-kernelconvolutions and Transformer-inspired architectural designs into CNN caneffectively expand the receptive field, thereby improving global motionperception. Motivated by these insights, we propose a novel CNN-based modulecalled the Dual-wing Adaptive Dynamic Mixer (DADM), which adaptively capturesboth global motion patterns and local, fine-grained motion features fromdynamic inputs. This module dynamically generates selective weights based onthe input, enabling efficient multi-scale feature aggregation. To furtherimprove temporal modeling, we introduce the Spatio-Temporal Gating Unit (STGU),which selectively extracts representative and task-relevant motion features inthe temporal domain. This unit addresses the limitations of temporal modelingobserved in existing CNN approaches. Built upon DADM and STGU, we present a newCNN-based inertial odometry backbone, named Next Era of Inertial Odometry(IONext). Extensive experiments on six public datasets demonstrate that IONextconsistently outperforms state-of-the-art (SOTA) Transformer- and CNN-basedmethods. For instance, on the RNIN dataset, IONext reduces the average ATE by10% and the average RTE by 12% compared to the representative model iMOT.</description>
      <author>example@mail.com (Shanshan Zhang, Siyue Wang, Tianshui Wen, Qi Zhang, Ziheng Zhou, Lingxiang Zheng, Yu Yang)</author>
      <guid isPermaLink="false">2507.17089v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>The Early Bird Identifies the Worm: You Can't Beat a Head Start in Long-Term Body Re-ID (ECHO-BID)</title>
      <link>http://arxiv.org/abs/2507.17640v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ECHO-BID的长时程重识别模型，用于在非约束环境中进行人员识别。该模型在长时程重识别任务上取得了最先进的成果，特别是在处理服装变化数据时表现突出。&lt;h4&gt;背景&lt;/h4&gt;在非约束环境中进行人员识别面临距离、视角、成像条件和服装变化等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出ECHO-BID模型，旨在解决非约束环境中的人员识别问题。&lt;h4&gt;方法&lt;/h4&gt;ECHO-BID基于预训练的EVA-02大型骨干网络，通过迁移学习与9个其他模型进行了比较。模型在约束、非约束和遮挡场景的基准数据集上进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;ECHO-BID在长时程重识别任务上取得了最先进的成果，特别是在处理服装变化数据时。模型大小和预训练期间的掩码图像建模是ECHO-BID性能强大的原因。选择正确的预训练骨干架构和迁移学习协议可以显著提高长时程重识别的性能。&lt;h4&gt;结论&lt;/h4&gt;ECHO-BID模型在非约束环境中的人员识别任务中表现优异，特别是在处理服装变化和遮挡场景时，为长时程重识别领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在非约束视图中进行人员识别由于距离、视角、成像条件和服装的变化而面临重大挑战。我们引入了Eva Clothes-Change from Hidden Objects - Body Identification（ECHO-BID），这是一类基于对象预训练的EVA-02大型骨干网络构建的长时程重识别模型。我们将ECHO-BID与9个其他模型进行了比较，这些模型在骨干架构、模型大小、对象分类预训练的规模和迁移学习协议方面存在系统性的差异。这些模型在约束、非约束和遮挡设置下的基准数据集上进行了评估。ECHO-BID在最具挑战性的服装变化数据上实现了迁移学习，在长时程重识别上取得了最先进的成果——显著优于其他方法。ECHO-BID在遮挡视图场景中也以很大的优势超过了其他方法。模型大小增加和预训练期间的掩码图像建模是ECHO-BID在长时程重识别上表现强大的基础。值得注意的是，一个较小但更具挑战性的迁移学习数据集比一个更大但更具挑战性的数据集在数据集之间推广得更好。然而，包含额外微调步骤的较大数据集在最具挑战性的数据上表现最佳。选择正确的预训练骨干架构和迁移学习协议可以在长时程重识别性能上带来实质性的提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Person identification in unconstrained viewing environments presentssignificant challenges due to variations in distance, viewpoint, imagingconditions, and clothing. We introduce $\textbf{E}$va $\textbf{C}$lothes-Changefrom $\textbf{H}$idden $\textbf{O}$bjects - $\textbf{B}$ody$\textbf{ID}$entification (ECHO-BID), a class of long-term re-id models builton object-pretrained EVA-02 Large backbones. We compare ECHO-BID to 9 othermodels that vary systematically in backbone architecture, model size, scale ofobject classification pretraining, and transfer learning protocol. Models wereevaluated on benchmark datasets across constrained, unconstrained, and occludedsettings. ECHO-BID, with transfer learning on the most challengingclothes-change data, achieved state-of-the-art results on long-term re-id --substantially outperforming other methods. ECHO-BID also surpassed othermethods by a wide margin in occluded viewing scenarios. A combination ofincreased model size and Masked Image Modeling during pretraining underlieECHO-BID's strong performance on long-term re-id. Notably, a smaller, but morechallenging transfer learning dataset, generalized better across datasets thana larger, less challenging one. However, the larger dataset with an additionalfine-tuning step proved best on the most difficult data. Selecting the correctpretrained backbone architecture and transfer learning protocols can drivesubstantial gains in long-term re-id performance.</description>
      <author>example@mail.com (Thomas M. Metz, Matthew Q. Hill, Alice J. O'Toole)</author>
      <guid isPermaLink="false">2507.17640v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Toward Scalable Video Narration: A Training-free Approach Using Multimodal Large Language Models</title>
      <link>http://arxiv.org/abs/2507.17050v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVAM Workshop at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VideoNarrator，一种新型的无需训练的流水线设计，用于生成密集的视频字幕，这些字幕提供了视频内容的结构化快照。这些字幕包含详细的叙述和精确的时间戳，捕捉视频每个片段的细微差别。&lt;h4&gt;背景&lt;/h4&gt;尽管在视频理解的多模态大型语言模型（MLLMs）方面取得了进展，但这些模型在时间对齐的叙述方面往往存在困难，并且容易在陌生场景中产生幻觉。&lt;h4&gt;目的&lt;/h4&gt;VideoNarrator通过利用灵活的流水线来解决这些挑战，其中现成的MLLMs和视觉语言模型（VLMs）可以作为字幕生成器、上下文提供者或字幕验证器。&lt;h4&gt;方法&lt;/h4&gt;实验结果表明，这些组件的协同作用显著提高了视频叙述的质量和准确性，有效减少了幻觉并改善了时间对齐。&lt;h4&gt;主要发现&lt;/h4&gt;这种结构化方法不仅增强了视频理解，还促进了视频摘要和视频问答等下游任务，并且可以潜在地扩展到广告和营销应用。&lt;h4&gt;结论&lt;/h4&gt;VideoNarrator通过其创新的流水线设计，为视频字幕生成提供了一种高效且准确的方法，有助于提升视频内容的理解和应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce VideoNarrator, a novel training-free pipelinedesigned to generate dense video captions that offer a structured snapshot ofvideo content. These captions offer detailed narrations with precisetimestamps, capturing the nuances present in each segment of the video. Despiteadvancements in multimodal large language models (MLLMs) for videocomprehension, these models often struggle with temporally aligned narrationsand tend to hallucinate, particularly in unfamiliar scenarios. VideoNarratoraddresses these challenges by leveraging a flexible pipeline whereoff-the-shelf MLLMs and visual-language models (VLMs) can function as captiongenerators, context providers, or caption verifiers. Our experimental resultsdemonstrate that the synergistic interaction of these components significantlyenhances the quality and accuracy of video narrations, effectively reducinghallucinations and improving temporal alignment. This structured approach notonly enhances video understanding but also facilitates downstream tasks such asvideo summarization and video question answering, and can be potentiallyextended for advertising and marketing applications.</description>
      <author>example@mail.com (Tz-Ying Wu, Tahani Trigui, Sharath Nittur Sridhar, Anand Bodas, Subarna Tripathi)</author>
      <guid isPermaLink="false">2507.17050v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Exposure Correction</title>
      <link>http://arxiv.org/abs/2507.17252v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种创新的非监督曝光校正（UEC）方法，解决了当前曝光校正方法的三个挑战：劳动密集型配对数据标注、泛化能力有限以及在低级计算机视觉任务中的性能下降。&lt;h4&gt;背景&lt;/h4&gt;当前曝光校正方法存在三个挑战：劳动密集型的配对数据标注、泛化能力有限以及在低级计算机视觉任务中的性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要手动标注、提高泛化能力并增强低级下游任务性能的非监督曝光校正方法。&lt;h4&gt;方法&lt;/h4&gt;模型使用来自模拟图像信号处理（ISP）管道的免费配对数据进行训练。此外，还开发了一个大规模的辐射度校正数据集，特别强调曝光变化，以促进无监督学习。还开发了一个转换函数，它保留了图像细节，并优于最先进的监督方法，同时仅使用其0.01%的参数。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在边缘检测等下游任务中进一步研究了曝光校正的更广泛影响，表明其能够减轻曝光不良对低级特征的不利影响。&lt;h4&gt;结论&lt;/h4&gt;本文提出的UEC方法有效解决了现有曝光校正方法的挑战，并提供了公开的源代码和数据集。&lt;h4&gt;翻译&lt;/h4&gt;Current exposure correction methods have three challenges, labor-intensive paired data annotation, limited generalizability, and performance degradation in low-level computer vision tasks. In this work, we introduce an innovative Unsupervised Exposure Correction (UEC) method that eliminates the need for manual annotations, offers improved generalizability, and enhances performance in low-level downstream tasks. Our model is trained using freely available paired data from an emulated Image Signal Processing (ISP) pipeline. This approach does not need expensive manual annotations, thereby minimizing individual style biases from the annotation and consequently improving its generalizability. Furthermore, we present a large-scale Radiometry Correction Dataset, specifically designed to emphasize exposure variations, to facilitate unsupervised learning. In addition, we develop a transformation function that preserves image details and outperforms state-of-the-art supervised methods [12], while utilizing only 0.01% of their parameters. Our work further investigates the broader impact of exposure correction on downstream tasks, including edge detection, demonstrating its effectiveness in mitigating the adverse effects of poor exposure on low-level features. The source code and dataset are publicly available at https://github.com/BeyondHeaven/uec_code.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current exposure correction methods have three challenges, labor-intensivepaired data annotation, limited generalizability, and performance degradationin low-level computer vision tasks. In this work, we introduce an innovativeUnsupervised Exposure Correction (UEC) method that eliminates the need formanual annotations, offers improved generalizability, and enhances performancein low-level downstream tasks. Our model is trained using freely availablepaired data from an emulated Image Signal Processing (ISP) pipeline. Thisapproach does not need expensive manual annotations, thereby minimizingindividual style biases from the annotation and consequently improving itsgeneralizability. Furthermore, we present a large-scale Radiometry CorrectionDataset, specifically designed to emphasize exposure variations, to facilitateunsupervised learning. In addition, we develop a transformation function thatpreserves image details and outperforms state-of-the-art supervised methods[12], while utilizing only 0.01% of their parameters. Our work furtherinvestigates the broader impact of exposure correction on downstream tasks,including edge detection, demonstrating its effectiveness in mitigating theadverse effects of poor exposure on low-level features. The source code anddataset are publicly available at https://github.com/BeyondHeaven/uec_code.</description>
      <author>example@mail.com (Ruodai Cui, Li Niu, Guosheng Hu)</author>
      <guid isPermaLink="false">2507.17252v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>DFDNet: Dynamic Frequency-Guided De-Flare Network</title>
      <link>http://arxiv.org/abs/2507.17489v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的动态频率引导去噪网络（DFDNet），用于去除夜间摄影中强光源产生的光晕，提高图像质量和下游任务性能。&lt;h4&gt;背景&lt;/h4&gt;夜间摄影中强光源常导致图像出现光晕，严重影响视觉效果和后续处理。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的方法来去除大范围光晕伪影和修复光源附近的结构损伤。&lt;h4&gt;方法&lt;/h4&gt;DFDNet主要由全局动态频率域引导模块（GDFG）和局部细节引导模块（LDGM）组成。GDFG模块通过动态优化全局频率域特征，使网络能够感知光晕伪影的频率特性，从而有效分离光晕信息和内容信息。LDGM模块通过对比学习策略，使光源的局部特征与参考图像对齐，减少光晕去除过程中的局部细节损伤，并提高图像的精细修复。&lt;h4&gt;主要发现&lt;/h4&gt;DFDNet在频率域中比在空间域中更能显著地识别出光晕伪影与参考图像的差异。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，DFDNet在性能上优于现有的最先进方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a novel dynamic frequency-guided deflare network (DFDNet) for removing the flares produced by strong light sources in nighttime photography, improving image quality and the performance of downstream tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Strong light sources in nighttime photography frequently produce flares inimages, significantly degrading visual quality and impacting the performance ofdownstream tasks. While some progress has been made, existing methods continueto struggle with removing large-scale flare artifacts and repairing structuraldamage in regions near the light source. We observe that these challengingflare artifacts exhibit more significant discrepancies from the referenceimages in the frequency domain compared to the spatial domain. Therefore, thispaper presents a novel dynamic frequency-guided deflare network (DFDNet) thatdecouples content information from flare artifacts in the frequency domain,effectively removing large-scale flare artifacts. Specifically, DFDNet consistsmainly of a global dynamic frequency-domain guidance (GDFG) module and a localdetail guidance module (LDGM). The GDFG module guides the network to perceivethe frequency characteristics of flare artifacts by dynamically optimizingglobal frequency domain features, effectively separating flare information fromcontent information. Additionally, we design an LDGM via a contrastive learningstrategy that aligns the local features of the light source with the referenceimage, reduces local detail damage from flare removal, and improvesfine-grained image restoration. The experimental results demonstrate that theproposed method outperforms existing state-of-the-art methods in terms ofperformance. The code is available at\href{https://github.com/AXNing/DFDNet}{https://github.com/AXNing/DFDNet}.</description>
      <author>example@mail.com (Minglong Xue, Aoxiang Ning, Shivakumara Palaiahnakote, Mingliang Zhou)</author>
      <guid isPermaLink="false">2507.17489v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Model Compression Engine for Wearable Devices Skin Cancer Diagnosis</title>
      <link>http://arxiv.org/abs/2507.17125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于AI的诊断工具，用于皮肤癌的早期检测，特别是在资源有限的地区，该工具通过优化模型在嵌入式系统上的性能和能耗来解决这个问题。&lt;h4&gt;背景&lt;/h4&gt;皮肤癌是一种常见且可预防的癌症，但早期检测仍然是一个挑战，特别是在那些难以获得专业医疗保健的资源有限地区。&lt;h4&gt;目的&lt;/h4&gt;开发一个AI驱动的诊断工具，针对嵌入式系统进行优化，以解决皮肤癌早期检测的难题。&lt;h4&gt;方法&lt;/h4&gt;使用MobileNetV2架构和迁移学习进行模型训练，对皮肤病变进行二分类（皮肤癌和其他）。利用TensorRT框架对模型进行压缩和优化，以便在NVIDIA Jetson Orin Nano上部署。通过多个基准进行综合评估，包括模型大小、推理速度、吞吐量和功耗。&lt;h4&gt;主要发现&lt;/h4&gt;优化后的模型在性能上保持稳定，F1分数达到87.18%，精确度为93.18%，召回率为81.91%。模型压缩后，大小减少了0.41，推理速度和吞吐量有所提高，INT8精度下的能耗降低了0.93。&lt;h4&gt;结论&lt;/h4&gt;该研究验证了在资源受限的边缘设备上部署高性能、节能的诊断工具的可行性。此外，研究中的方法在其他医疗诊断和需要可访问、高效AI解决方案的领域有更广泛的应用。这表明优化后的AI系统有可能革新医疗诊断，从而弥合先进技术与未受服务地区之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要：皮肤癌是最常见且可预防的癌症类型之一，但其早期检测仍然是一个挑战，特别是在资源有限的环境中，获取专业医疗保健的机会很少。本研究提出了一种针对嵌入式系统优化的AI驱动诊断工具，以解决这一差距。使用MobileNetV2架构和迁移学习，该模型被调整为对皮肤病变进行二分类，即“皮肤癌”和“其他”。TensorRT框架被用于压缩和优化模型，以便在NVIDIA Jetson Orin Nano上部署，在性能和能耗之间取得平衡。在多个基准上进行了综合评估，包括模型大小、推理速度、吞吐量和功耗。优化后的模型保持了其性能，实现了87.18%的F1分数，精确度为93.18%，召回率为81.91%。压缩后的结果表明，模型大小减少了最多0.41，推理速度和吞吐量有所提高，INT8精度下的能耗降低了最多0.93。这些发现验证了在资源受限的边缘设备上部署高性能、节能的诊断工具的可行性。除了皮肤癌检测之外，本研究中应用的方法在其他医疗诊断和需要可访问、高效AI解决方案的领域有更广泛的应用。这项研究强调了优化AI系统革新医疗诊断的潜力，从而弥合了先进技术与未受服务地区之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Skin cancer is one of the most prevalent and preventable types of cancer, yetits early detection remains a challenge, particularly in resource-limitedsettings where access to specialized healthcare is scarce. This study proposesan AI-driven diagnostic tool optimized for embedded systems to address thisgap. Using transfer learning with the MobileNetV2 architecture, the model wasadapted for binary classification of skin lesions into "Skin Cancer" and"Other." The TensorRT framework was employed to compress and optimize the modelfor deployment on the NVIDIA Jetson Orin Nano, balancing performance withenergy efficiency. Comprehensive evaluations were conducted across multiplebenchmarks, including model size, inference speed, throughput, and powerconsumption. The optimized models maintained their performance, achieving anF1-Score of 87.18% with a precision of 93.18% and recall of 81.91%.Post-compression results showed reductions in model size of up to 0.41, alongwith improvements in inference speed and throughput, and a decrease in energyconsumption of up to 0.93 in INT8 precision. These findings validate thefeasibility of deploying high-performing, energy-efficient diagnostic tools onresource-constrained edge devices. Beyond skin cancer detection, themethodologies applied in this research have broader applications in othermedical diagnostics and domains requiring accessible, efficient AI solutions.This study underscores the potential of optimized AI systems to revolutionizehealthcare diagnostics, thereby bridging the divide between advanced technologyand underserved regions.</description>
      <author>example@mail.com (Jacob M. Delgado-López, Andrea P. Seda-Hernandez, Juan D. Guadalupe-Rosado, Luis E. Fernandez Ramirez, Miguel Giboyeaux-Camilo, Wilfredo E. Lugo-Beauchamp)</author>
      <guid isPermaLink="false">2507.17125v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>SRMambaV2: Biomimetic Attention for Sparse Point Cloud Upsampling in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2507.17479v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为SRMambaV2的新方法，用于提高自动驾驶场景中稀疏LiDAR点云的插值准确性，同时保持几何重建的整体质量。&lt;h4&gt;背景&lt;/h4&gt;由于LiDAR点云数据的稀疏性和复杂的三维结构，在自动驾驶场景中对点云进行上采样是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出SRMambaV2方法，以解决稀疏区域点云上采样中的准确性问题。&lt;h4&gt;方法&lt;/h4&gt;SRMambaV2通过以下方式实现：1. 设计了一种仿生2D选择性扫描自注意力机制（2DSSA）来模拟远距离稀疏区域的特征分布。2. 引入双分支网络架构以增强稀疏特征的表达。3. 引入渐进自适应损失（PAL）函数以在插值过程中进一步细化细节的重建。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SRMambaV2在定性和定量评估中均表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;SRMambaV2在自动驾驶场景中的稀疏点云上采样任务中表现出有效性和实际价值。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel method named SRMambaV2 to enhance the upsampling accuracy of sparse LiDAR point clouds in autonomous driving scenarios while preserving the overall geometric reconstruction quality. The method includes designing a biomimetic 2D selective scanning self-attention (2DSSA) mechanism to model the feature distribution in distant sparse areas, introducing a dual-branch network architecture to enhance the representation of sparse features, and using a progressive adaptive loss (PAL) function to refine the reconstruction of fine-grained details during the upsampling process. Experimental results demonstrate the superior performance of SRMambaV2 in both qualitative and quantitative evaluations, highlighting its effectiveness and practical value in automotive sparse point cloud upsampling tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Upsampling LiDAR point clouds in autonomous driving scenarios remains asignificant challenge due to the inherent sparsity and complex 3D structures ofthe data. Recent studies have attempted to address this problem by convertingthe complex 3D spatial scenes into 2D image super-resolution tasks. However,due to the sparse and blurry feature representation of range images, accuratelyreconstructing detailed and complex spatial topologies remains a majordifficulty. To tackle this, we propose a novel sparse point cloud upsamplingmethod named SRMambaV2, which enhances the upsampling accuracy in long-rangesparse regions while preserving the overall geometric reconstruction quality.Specifically, inspired by human driver visual perception, we design abiomimetic 2D selective scanning self-attention (2DSSA) mechanism to model thefeature distribution in distant sparse areas. Meanwhile, we introduce adual-branch network architecture to enhance the representation of sparsefeatures. In addition, we introduce a progressive adaptive loss (PAL) functionto further refine the reconstruction of fine-grained details during theupsampling process. Experimental results demonstrate that SRMambaV2 achievessuperior performance in both qualitative and quantitative evaluations,highlighting its effectiveness and practical value in automotive sparse pointcloud upsampling tasks.</description>
      <author>example@mail.com (Chuang Chen, Xiaolin Qin, Jing Hu, Wenyi Ge)</author>
      <guid isPermaLink="false">2507.17479v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Transferability and Consistency in Cross-Domain Recommendations via Supervised Disentanglement</title>
      <link>http://arxiv.org/abs/2507.17112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DGCDR的跨领域推荐方法，通过解耦表示学习来缓解数据稀疏性问题，并通过增强编码器-解码器框架和锚点监督策略来提高推荐系统的鲁棒性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;跨领域推荐旨在通过跨域知识迁移来缓解数据稀疏问题，而解耦表示学习可以有效地分离用户偏好中的域共享和域特定特征，提高模型的鲁棒性和可解释性。&lt;h4&gt;目的&lt;/h4&gt;提出DGCDR方法，旨在解决基于解耦表示的跨领域推荐方法中存在的两个关键挑战：特征预分离策略引入的噪声和缺乏任务特定指导的解耦目标。&lt;h4&gt;方法&lt;/h4&gt;DGCDR方法首先使用图神经网络（GNN）提取高阶协作信号，然后编码器动态地将特征解耦为域共享和域特定空间，同时解码器引入基于锚点的监督，利用层次特征关系增强域内一致性和跨域对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界数据集上的实验表明，DGCDR在关键指标上实现了最先进的性能，改进幅度高达11.59%。定性分析进一步验证了其优越的解耦质量和迁移能力。&lt;h4&gt;结论&lt;/h4&gt;DGCDR方法通过解决现有方法的挑战，显著提高了跨领域推荐系统的性能，并且其源代码和数据集已公开，便于进一步比较。&lt;h4&gt;翻译&lt;/h4&gt;Cross-domain recommendation (CDR) aims to alleviate the data sparsity by transferring knowledge across domains. Disentangled representation learning provides an effective solution to model complex user preferences by separating intra-domain features (domain-shared and domain-specific features), thereby enhancing robustness and interpretability. However, disentanglement-based CDR methods employing generative modeling or GNNs with contrastive objectives face two key challenges: (i) pre-separation strategies decouple features before extracting collaborative signals, disrupting intra-domain interactions and introducing noise; (ii) unsupervised disentanglement objectives lack explicit task-specific guidance, resulting in limited consistency and suboptimal alignment. To address these challenges, we propose DGCDR, a GNN-enhanced encoder-decoder framework. To handle challenge (i), DGCDR first applies GNN to extract high-order collaborative signals, providing enriched representations as a robust foundation for disentanglement. The encoder then dynamically disentangles features into domain-shared and -specific spaces, preserving collaborative information during the separation process. To handle challenge (ii), the decoder introduces an anchor-based supervision that leverages hierarchical feature relationships to enhance intra-domain consistency and cross-domain alignment. Extensive experiments on real-world datasets demonstrate that DGCDR achieves state-of-the-art performance, with improvements of up to 11.59% across key metrics. Qualitative analyses further validate its superior disentanglement quality and transferability. Our source code and datasets are available on GitHub for further comparison.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3705328.3748044&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-domain recommendation (CDR) aims to alleviate the data sparsity bytransferring knowledge across domains. Disentangled representation learningprovides an effective solution to model complex user preferences by separatingintra-domain features (domain-shared and domain-specific features), therebyenhancing robustness and interpretability. However, disentanglement-based CDRmethods employing generative modeling or GNNs with contrastive objectives facetwo key challenges: (i) pre-separation strategies decouple features beforeextracting collaborative signals, disrupting intra-domain interactions andintroducing noise; (ii) unsupervised disentanglement objectives lack explicittask-specific guidance, resulting in limited consistency and suboptimalalignment. To address these challenges, we propose DGCDR, a GNN-enhancedencoder-decoder framework. To handle challenge (i), DGCDR first applies GNN toextract high-order collaborative signals, providing enriched representations asa robust foundation for disentanglement. The encoder then dynamicallydisentangles features into domain-shared and -specific spaces, preservingcollaborative information during the separation process. To handle challenge(ii), the decoder introduces an anchor-based supervision that leverageshierarchical feature relationships to enhance intra-domain consistency andcross-domain alignment. Extensive experiments on real-world datasetsdemonstrate that DGCDR achieves state-of-the-art performance, with improvementsof up to 11.59% across key metrics. Qualitative analyses further validate itssuperior disentanglement quality and transferability. Our source code anddatasets are available on GitHub for further comparison.</description>
      <author>example@mail.com (Yuhan Wang, Qing Xie, Zhifeng Bao, Mengzi Tang, Lin Li, Yongjian Liu)</author>
      <guid isPermaLink="false">2507.17112v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Robust Five-Class and binary Diabetic Retinopathy Classification Using Transfer Learning and Data Augmentation</title>
      <link>http://arxiv.org/abs/2507.17121v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 1 Figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种鲁棒的深度学习框架，用于对糖尿病视网膜病变（DR）进行二分类和五分类，利用迁移学习和数据增强来应对类别不平衡和训练数据有限的问题。&lt;h4&gt;背景&lt;/h4&gt;糖尿病视网膜病变是全球导致失明的主要原因，通过自动化视网膜图像分析进行早期诊断可以显著降低失明的风险。&lt;h4&gt;目的&lt;/h4&gt;开发一种准确且高效的深度学习模型，用于DR的早期诊断和分类。&lt;h4&gt;方法&lt;/h4&gt;研究者在APTOS 2019数据集上评估了多种预训练卷积神经网络架构，包括ResNet和EfficientNet的变体，并利用迁移学习和数据增强技术来提高模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;在二分类任务中，提出的模型达到了98.9%的准确率，精度为98.6%，召回率为99.3%，F1分数为98.9%，AUC为99.4%。在更具挑战性的五分类严重程度分类任务中，模型获得了84.6%的准确率和94.1%的AUC，优于几种现有方法。 EfficientNet-B0和ResNet34在两个任务中提供了准确性和计算效率之间的最佳平衡。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，结合类别平衡增强和迁移学习对于高性能DR诊断是有效的。提出的框架为DR筛查提供了一种可扩展且准确的解决方案，具有在现实世界临床环境中部署的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Diabetic retinopathy (DR) is a leading cause of vision loss worldwide, and early diagnosis through automated retinal image analysis can significantly reduce the risk of blindness. This paper presents a robust deep learning framework for both binary and five-class DR classification, leveraging transfer learning and extensive data augmentation to address the challenges of class imbalance and limited training data. We evaluate a range of pretrained convolutional neural network architectures, including variants of ResNet and EfficientNet, on the APTOS 2019 dataset. For binary classification, our proposed model achieves a state-of-the-art accuracy of 98.9%, with a precision of 98.6%, recall of 99.3%, F1-score of 98.9%, and an AUC of 99.4%. In the more challenging five-class severity classification task, our model obtains a competitive accuracy of 84.6% and an AUC of 94.1%, outperforming several existing approaches. Our findings also demonstrate that EfficientNet-B0 and ResNet34 offer optimal trade-offs between accuracy and computational efficiency across both tasks. These results underscore the effectiveness of combining class-balanced augmentation with transfer learning for high-performance DR diagnosis. The proposed framework provides a scalable and accurate solution for DR screening, with potential for deployment in real-world clinical environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diabetic retinopathy (DR) is a leading cause of vision loss worldwide, andearly diagnosis through automated retinal image analysis can significantlyreduce the risk of blindness. This paper presents a robust deep learningframework for both binary and five-class DR classification, leveraging transferlearning and extensive data augmentation to address the challenges of classimbalance and limited training data. We evaluate a range of pretrainedconvolutional neural network architectures, including variants of ResNet andEfficientNet, on the APTOS 2019 dataset.  For binary classification, our proposed model achieves a state-of-the-artaccuracy of 98.9%, with a precision of 98.6%, recall of 99.3%, F1-score of98.9%, and an AUC of 99.4%. In the more challenging five-class severityclassification task, our model obtains a competitive accuracy of 84.6% and anAUC of 94.1%, outperforming several existing approaches. Our findings alsodemonstrate that EfficientNet-B0 and ResNet34 offer optimal trade-offs betweenaccuracy and computational efficiency across both tasks.  These results underscore the effectiveness of combining class-balancedaugmentation with transfer learning for high-performance DR diagnosis. Theproposed framework provides a scalable and accurate solution for DR screening,with potential for deployment in real-world clinical environments.</description>
      <author>example@mail.com (Faisal Ahmed, Mohammad Alfrad Nobel Bhuiyan)</author>
      <guid isPermaLink="false">2507.17121v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Application of Whisper in Clinical Practice: the Post-Stroke Speech Assessment during a Naming Task</title>
      <link>http://arxiv.org/abs/2507.17326v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究评估了Whisper ASR模型在卒中后语言障碍评估中的应用效果，发现经过微调后，模型在语音转录和语言功能预测方面表现良好，但仍存在跨领域泛化方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;卒中后的语言障碍评估是一个复杂且耗时的工作，目前缺乏有效的自动评估方法。&lt;h4&gt;目的&lt;/h4&gt;研究Whisper ASR模型在卒中后患者图片命名任务中的转录和分析能力，以评估其对语言功能的预测能力。&lt;h4&gt;方法&lt;/h4&gt;研究者使用Whisper模型对卒中患者和健康人的语音进行转录，并评估其转录准确性和对语言功能的预测能力。&lt;h4&gt;主要发现&lt;/h4&gt;Whisper模型在单词语音转录方面表现不佳，但经过微调后转录准确性显著提高，同时模型能够准确预测语音质量。然而，在未见过的数据集上测试发现模型的泛化能力有限。&lt;h4&gt;结论&lt;/h4&gt;Whisper模型在经过适当微调后，在自动语音和语言评估及康复方面具有潜力，但仍需针对特定临床人群进行模型调整，以提高其泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;This study evaluates the application of the Whisper ASR model in the assessment of language impairment following stroke. The results show that, after fine-tuning, the model performs well in speech transcription and prediction of language function, although it still faces challenges in cross-domain generalization. Fine-tuning the model can significantly improve transcription accuracy and enable accurate prediction of speech quality, but further adaptation to specific clinical populations is needed to enhance its generalization ability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detailed assessment of language impairment following stroke remains acognitively complex and clinician-intensive task, limiting timely and scalablediagnosis. Automatic Speech Recognition (ASR) foundation models offer apromising pathway to augment human evaluation through intelligent systems, buttheir effectiveness in the context of speech and language impairment remainsuncertain. In this study, we evaluate whether Whisper, a state-of-the-art ASRfoundation model, can be applied to transcribe and analyze speech from patientswith stroke during a commonly used picture-naming task. We assess both verbatimtranscription accuracy and the model's ability to support downstream predictionof language function, which has major implications for outcomes after stroke.Our results show that the baseline Whisper model performs poorly on single-wordspeech utterances. Nevertheless, fine-tuning Whisper significantly improvestranscription accuracy (reducing Word Error Rate by 87.72% in healthy speechand 71.22% in speech from patients). Further, learned representations from themodel enable accurate prediction of speech quality (average F1 Macro of 0.74for healthy, 0.75 for patients). However, evaluations on an unseen (TORGO)dataset reveal limited generalizability, highlighting the inability of Whisperto perform zero-shot transcription of single-word utterances on out-of-domainclinical speech and emphasizing the need to adapt models to specific clinicalpopulations. While challenges remain in cross-domain generalization, thesefindings highlight the potential of foundation models, when appropriatelyfine-tuned, to advance automated speech and language assessment andrehabilitation for stroke-related impairments.</description>
      <author>example@mail.com (Milena Davudova, Ziyuan Cai, Valentina Giunchiglia, Dragos C. Gruia, Giulia Sanguedolce, Adam Hampshire, Fatemeh Geranmayeh)</author>
      <guid isPermaLink="false">2507.17326v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>C3RL: Rethinking the Combination of Channel-independence and Channel-mixing from Representation Learning</title>
      <link>http://arxiv.org/abs/2507.17454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为C3RL的新型表示学习框架，用于多变量时间序列预测，旨在解决现有方法中混合策略的局限性和不足。&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列预测因其实际应用的重要性而受到越来越多的关注。现有方法通常采用通道混合（CM）或通道独立（CI）策略，但每种策略都有其局限性。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的不足，本文提出C3RL框架，旨在同时模型CM和CI策略，以实现更好的表示学习和预测性能。&lt;h4&gt;方法&lt;/h4&gt;C3RL框架受到计算机视觉中对比学习的启发，将两种策略的输入视为转置视图，并构建了一个Siamese网络架构。一种策略作为主干，另一种策略进行补充。通过联合优化对比和预测损失，并采用自适应加权，C3RL平衡了表示和预测性能。&lt;h4&gt;主要发现&lt;/h4&gt;在七个模型上的大量实验表明，C3RL将基于CI策略的模型的最佳性能率提升至81.4%，而基于CM策略的模型提升至76.3%，显示出强大的泛化能力和有效性。&lt;h4&gt;结论&lt;/h4&gt;C3RL框架能够有效提升多变量时间序列预测的性能，其代码将在论文被接受后提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series forecasting has drawn increasing attention due toits practical importance. Existing approaches typically adopt eitherchannel-mixing (CM) or channel-independence (CI) strategies. CM strategy cancapture inter-variable dependencies but fails to discern variable-specifictemporal patterns. CI strategy improves this aspect but fails to fully exploitcross-variable dependencies like CM. Hybrid strategies based on feature fusionoffer limited generalization and interpretability. To address these issues, wepropose C3RL, a novel representation learning framework that jointly modelsboth CM and CI strategies. Motivated by contrastive learning in computervision, C3RL treats the inputs of the two strategies as transposed views andbuilds a siamese network architecture: one strategy serves as the backbone,while the other complements it. By jointly optimizing contrastive andprediction losses with adaptive weighting, C3RL balances representation andforecasting performance. Extensive experiments on seven models show that C3RLboosts the best-case performance rate to 81.4\% for models based on CI strategyand to 76.3\% for models based on CM strategy, demonstrating stronggeneralization and effectiveness. The code will be available once the paper isaccepted.</description>
      <author>example@mail.com (Shusen Ma, Yun-Bo Zhao, Yu Kang)</author>
      <guid isPermaLink="false">2507.17454v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Controllable Hybrid Captioner for Improved Long-form Video Understanding</title>
      <link>http://arxiv.org/abs/2507.17047v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于文本的视频内容摘要方法，通过视频字幕生成和视觉语言模型来丰富记忆，提高视频理解系统的性能。&lt;h4&gt;背景&lt;/h4&gt;视频数据密度高、维度大，基于文本的摘要可以更紧凑地表示内容，且易于大型语言模型处理。&lt;h4&gt;目的&lt;/h4&gt;解决视频内容理解问题，通过文本摘要和视觉语言模型来丰富记忆，提高视频理解系统的性能。&lt;h4&gt;方法&lt;/h4&gt;使用视频字幕生成器对视频进行分段处理，并利用视觉语言模型来增加静态场景描述，结合LaViLa视频字幕生成器和大型语言模型来回答视频相关问题。&lt;h4&gt;主要发现&lt;/h4&gt;通过将静态场景描述融入字幕生成流程，提高了字幕日志的详细度和完整性，扩展了可回答问题的范围。同时，通过微调LaViLa视频字幕生成器，实现了动作和场景字幕的生成，提高了字幕生成效率。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有效提高了视频理解系统的性能，并通过控制混合字幕生成器实现了不同类型字幕的交替生成。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a text-based video content summarization method, enriching the memory with the help of video captioning and Vision Language Models (VLMs) to improve the performance of video understanding systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video data, especially long-form video, is extremely dense andhigh-dimensional. Text-based summaries of video content offer a way torepresent query-relevant content in a much more compact manner than raw video.In addition, textual representations are easily ingested by state-of-the-artlarge language models (LLMs), which enable reasoning over video content toanswer complex natural language queries. To solve this issue, we rely on theprogressive construction of a text-based memory by a video captioner operatingon shorter chunks of the video, where spatio-temporal modeling iscomputationally feasible. We explore ways to improve the quality of theactivity log comprised solely of short video captions. Because the videocaptions tend to be focused on human actions, and questions may pertain toother information in the scene, we seek to enrich the memory with static scenedescriptions using Vision Language Models (VLMs). Our video understandingsystem relies on the LaViLa video captioner in combination with a LLM to answerquestions about videos. We first explored different ways of partitioning thevideo into meaningful segments such that the textual descriptions moreaccurately reflect the structure of the video content. Furthermore, weincorporated static scene descriptions into the captioning pipeline using LLaVAVLM, resulting in a more detailed and complete caption log and expanding thespace of questions that are answerable from the textual memory. Finally, wehave successfully fine-tuned the LaViLa video captioner to produce both actionand scene captions, significantly improving the efficiency of the captioningpipeline compared to using separate captioning models for the two tasks. Ourmodel, controllable hybrid captioner, can alternate between different types ofcaptions according to special input tokens that signals scene changes detectedin the video.</description>
      <author>example@mail.com (Kuleen Sasse, Efsun Sarioglu Kayi, Arun Reddy)</author>
      <guid isPermaLink="false">2507.17047v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>PyG 2.0: Scalable Learning on Real World Graphs</title>
      <link>http://arxiv.org/abs/2507.16991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PyG自发布以来发展迅速，已成为图神经网络的主要框架。本文介绍了PyG 2.0及其后续版本，这是一个全面的更新，引入了显著的扩展性和实际应用能力改进。&lt;h4&gt;背景&lt;/h4&gt;PyG自发布以来，在图神经网络领域取得了显著进展，并逐渐成为该领域的领先框架。&lt;h4&gt;目的&lt;/h4&gt;本文旨在详细描述PyG 2.0的增强架构，包括对异构和时序图的支持、可扩展的特征/图存储以及各种优化，以帮助研究人员和从业者高效地处理大规模图学习问题。&lt;h4&gt;方法&lt;/h4&gt;通过引入新的架构和优化，PyG 2.0及其后续版本在扩展性和实际应用能力方面进行了全面更新。&lt;h4&gt;主要发现&lt;/h4&gt;PyG近年在多个应用领域支持图学习，包括关系深度学习和大型语言模型等重要领域。&lt;h4&gt;结论&lt;/h4&gt;PyG 2.0及其后续版本通过增强的架构和优化，为处理大规模图学习问题提供了高效的方法，并在多个应用领域得到了广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：PyG（PyTorch Geometric）自首次发布以来已经发生了显著的变化，确立了其在图神经网络领域的主导地位。在这篇论文中，我们介绍了PyG 2.0（及其后续的小版本），这是一个全面的更新，引入了在可扩展性和实际应用能力方面的重大改进。我们详细介绍了框架的增强架构，包括对异构和时序图的支持、可扩展的特征/图存储以及各种优化，使研究人员和从业者能够高效地处理大规模图学习问题。在过去的几年中，PyG已经在各种应用领域支持图学习，我们将对此进行总结，同时深入探讨关系深度学习和大型语言模型等重要领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; PyG (PyTorch Geometric) has evolved significantly since its initial release,establishing itself as a leading framework for Graph Neural Networks. In thispaper, we present Pyg 2.0 (and its subsequent minor versions), a comprehensiveupdate that introduces substantial improvements in scalability and real-worldapplication capabilities. We detail the framework's enhanced architecture,including support for heterogeneous and temporal graphs, scalable feature/graphstores, and various optimizations, enabling researchers and practitioners totackle large-scale graph learning problems efficiently. Over the recent years,PyG has been supporting graph learning in a large variety of application areas,which we will summarize, while providing a deep dive into the important areasof relational deep learning and large language modeling.</description>
      <author>example@mail.com (Matthias Fey, Jinu Sunil, Akihiro Nitta, Rishi Puri, Manan Shah, Blaž Stojanovič, Ramona Bendias, Alexandria Barghi, Vid Kocijan, Zecheng Zhang, Xinwei He, Jan Eric Lenssen, Jure Leskovec)</author>
      <guid isPermaLink="false">2507.16991v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Understanding Prompt Programming Tasks and Questions</title>
      <link>http://arxiv.org/abs/2507.17264v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了提示编程的过程和工具，通过构建一个任务和问题的分类体系，分析了提示编程中存在的问题和机遇。&lt;h4&gt;背景&lt;/h4&gt;提示编程是一种将提示嵌入到软件中的方法，使大型语言模型能够实现新的AI功能，但当前提示编程工具的支持不足。&lt;h4&gt;目的&lt;/h4&gt;为了解决提示编程中存在的问题，本文旨在通过开发任务和问题的分类体系，分析提示编程中的需求，并探讨改进机会。&lt;h4&gt;方法&lt;/h4&gt;本文通过访谈、观察和调查，收集了16位提示编程者、8位开发者的行为数据，并与48款研究和商业工具进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;发现提示编程没有得到充分的工具支持，大部分任务需要手动完成，且51个问题中的16个，包括多数重要问题尚未得到解答。&lt;h4&gt;结论&lt;/h4&gt;本文提出了提示编程工具的重要改进机会，为后续研究和开发提供了指导方向。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies the process and tools of prompting programming, by developing a classification system for tasks and questions, analyzes the problems and opportunities in prompting programming.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prompting foundation models (FMs) like large language models (LLMs) haveenabled new AI-powered software features (e.g., text summarization) thatpreviously were only possible by fine-tuning FMs. Now, developers are embeddingprompts in software, known as prompt programs. The process of promptprogramming requires the developer to make many changes to their prompt. Yet,the questions developers ask to update their prompt is unknown, despite theanswers to these questions affecting how developers plan their changes. Withthe growing number of research and commercial prompt programming tools, it isunclear whether prompt programmers' needs are being adequately addressed. Weaddress these challenges by developing a taxonomy of 25 tasks promptprogrammers do and 51 questions they ask, measuring the importance of each taskand question. We interview 16 prompt programmers, observe 8 developers makeprompt changes, and survey 50 developers. We then compare the taxonomy with 48research and commercial tools. We find that prompt programming is notwell-supported: all tasks are done manually, and 16 of the 51 questions --including a majority of the most important ones -- remain unanswered. Based onthis, we outline important opportunities for prompt programming tools.</description>
      <author>example@mail.com (Jenny T. Liang, Chenyang Yang, Agnia Sergeyuk, Travis D. Breaux, Brad A. Myers)</author>
      <guid isPermaLink="false">2507.17264v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>PointLAMA: Latent Attention meets Mamba for Efficient Point Cloud Pretraining</title>
      <link>http://arxiv.org/abs/2507.17296v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PointLAMA是一种点云预训练框架，旨在解决Mamba在捕捉3D数据中细粒度几何结构方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;Mamba作为点云建模的骨干模型，虽然具有高效的全球序列建模能力，但缺乏局部归纳偏置，限制了其捕捉3D数据中细粒度几何结构的能力。&lt;h4&gt;目的&lt;/h4&gt;提出PointLAMA框架，以增强点云模型的局部结构捕捉能力。&lt;h4&gt;方法&lt;/h4&gt;PointLAMA结合了任务感知的点云序列化、混合编码器（集成潜在注意力和Mamba块）以及基于Mamba骨干的条件扩散机制。具体包括：使用Hilbert/Trans-Hilbert空间填充曲线和轴排序来结构化对齐点标记，以适应分类和分割任务；轻量级的潜在注意力块包含点-wise多头潜在注意力（PMLA）模块，以增强局部上下文建模；在预训练期间引入条件扩散机制，以去噪扰动的特征序列。&lt;h4&gt;主要发现&lt;/h4&gt;PointLAMA在多个基准数据集上实现了有竞争力的性能，同时参数数量和浮点运算次数（FLOPs）最小。&lt;h4&gt;结论&lt;/h4&gt;PointLAMA验证了其在高效点云预训练方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Mamba最近作为点云建模的骨干模型受到广泛关注，它利用状态空间架构实现了具有线性复杂度的有效全局序列建模。然而，其缺乏局部归纳偏置限制了其在3D数据中捕捉细粒度几何结构的能力。为了解决这一局限性，我们提出了PointLAMA，一种结合任务感知的点云序列化、混合编码器（集成潜在注意力和Mamba块）以及基于Mamba骨干的条件扩散机制的点云预训练框架。具体来说，任务感知的点云序列化采用Hilbert/Trans-Hilbert空间填充曲线和轴排序来结构化对齐点标记，分别用于分类和分割任务。我们轻量级的潜在注意力块包含点-wise多头潜在注意力（PMLA）模块，该模块专门设计为与Mamba架构相匹配，通过利用PMLA和Mamba共享的潜在空间特征。这增强了局部上下文建模，同时保持了整体效率。为了进一步增强表示学习，我们在预训练期间引入了条件扩散机制，该机制在不依赖于显式点-wise重建的情况下去噪扰动的特征序列。实验结果表明，PointLAMA在多个基准数据集上实现了有竞争力的性能，同时参数数量和浮点运算次数（FLOPs）最小，验证了其在高效点云预训练方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mamba has recently gained widespread attention as a backbone model for pointcloud modeling, leveraging a state-space architecture that enables efficientglobal sequence modeling with linear complexity. However, its lack of localinductive bias limits its capacity to capture fine-grained geometric structuresin 3D data. To address this limitation, we propose \textbf{PointLAMA}, a pointcloud pretraining framework that combines task-aware point cloud serialization,a hybrid encoder with integrated Latent Attention and Mamba blocks, and aconditional diffusion mechanism built upon the Mamba backbone. Specifically,the task-aware point cloud serialization employs Hilbert/Trans-Hilbertspace-filling curves and axis-wise sorting to structurally align point tokensfor classification and segmentation tasks, respectively. Our lightweight LatentAttention block features a Point-wise Multi-head Latent Attention (PMLA)module, which is specifically designed to align with the Mamba architecture byleveraging the shared latent space characteristics of PMLA and Mamba. Thisenables enhanced local context modeling while preserving overall efficiency. Tofurther enhance representation learning, we incorporate a conditional diffusionmechanism during pretraining, which denoises perturbed feature sequenceswithout relying on explicit point-wise reconstruction. Experimental resultsdemonstrate that PointLAMA achieves competitive performance on multiplebenchmark datasets with minimal parameter count and FLOPs, validating itseffectiveness for efficient point cloud pretraining.</description>
      <author>example@mail.com (Xuanyu Lin, Xiaona Zeng, Xianwei Zheng, Xutao Li)</author>
      <guid isPermaLink="false">2507.17296v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>ViRN: Variational Inference and Distribution Trilateration for Long-Tailed Continual Representation Learning</title>
      <link>http://arxiv.org/abs/2507.17368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ViRN的持续学习框架，用于解决长尾数据分布下的持续学习挑战，该框架通过结合变分推断和分布三角定位来实现鲁棒的长尾学习。&lt;h4&gt;背景&lt;/h4&gt;在现实世界的AI系统中，持续学习（CL）是一个关键挑战，模型需要在适应新类别的同时保持对旧类别的知识，尽管存在严重的类别不平衡。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，本文旨在提出一种能够平衡稳定性和可塑性的新方法，以应对极端样本稀缺的情况。&lt;h4&gt;方法&lt;/h4&gt;ViRN框架首先通过变分自动编码器来建模类条件分布，以减轻对头部类别的偏差。其次，通过基于Wasserstein距离的邻域检索和几何融合来重建尾部类别的分布，从而实现尾部类别表示的高效对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在六个长尾分类基准测试中，包括语音（例如，罕见声学事件、口音）和图像任务，ViRN在平均准确率上比最先进的方法提高了10.24%。&lt;h4&gt;结论&lt;/h4&gt;ViRN框架在长尾学习方面表现出色，为解决现实世界AI系统中的持续学习问题提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：持续学习（CL）在长尾数据分布下仍然是一个关键的挑战，对于现实世界的AI系统来说，模型必须在适应新类别的同时保留对旧类别的知识，尽管存在严重的类别不平衡。现有的方法在平衡稳定性和可塑性方面存在困难，经常在极端样本稀缺的情况下崩溃。为了解决这个问题，我们提出了ViRN，这是一种新的CL框架，它将变分推断（VI）与分布三角定位相结合，以实现鲁棒的长尾学习。首先，我们通过变分自动编码器来建模类条件分布，以减轻对头部类别的偏差。其次，我们通过基于Wasserstein距离的邻域检索和几何融合来重建尾部类别的分布，从而实现尾部类别表示的高效对齐。在包括语音（例如，罕见声学事件、口音）和图像任务在内的六个长尾分类基准测试中评估，ViRN比最先进的方法实现了10.24%的平均准确率提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning (CL) with long-tailed data distributions remains acritical challenge for real-world AI systems, where models must sequentiallyadapt to new classes while retaining knowledge of old ones, despite severeclass imbalance. Existing methods struggle to balance stability and plasticity,often collapsing under extreme sample scarcity. To address this, we proposeViRN, a novel CL framework that integrates variational inference (VI) withdistributional trilateration for robust long-tailed learning. First, we modelclass-conditional distributions via a Variational Autoencoder to mitigate biastoward head classes. Second, we reconstruct tail-class distributions viaWasserstein distance-based neighborhood retrieval and geometric fusion,enabling sample-efficient alignment of tail-class representations. Evaluated onsix long-tailed classification benchmarks, including speech (e.g., rareacoustic events, accents) and image tasks, ViRN achieves a 10.24% averageaccuracy gain over state-of-the-art methods.</description>
      <author>example@mail.com (Hao Dai, Chong Tang, Jagmohan Chauhan)</author>
      <guid isPermaLink="false">2507.17368v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>MaskedCLIP: Bridging the Masked and CLIP Space for Semi-Supervised Medical Vision-Language Pre-training</title>
      <link>http://arxiv.org/abs/2507.17239v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to MedAGI 2025 (Oral)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了半监督视觉-语言预训练任务，旨在充分利用配对和未配对图像数据，提出了一种名为MaskedCLIP的框架，用于学习更具泛化能力的图像特征。&lt;h4&gt;背景&lt;/h4&gt;目前最先进的医学图像分析方法依赖于配对图像-文本数据或未配对图像数据来学习具有泛化能力的图像特征，但仅使用一种数据类型限制了模型学习更丰富和全面的图像特征的能力。&lt;h4&gt;目的&lt;/h4&gt;提出半监督视觉-语言预训练方法，旨在充分利用配对和未配对图像数据，提高基础模型学习图像特征的全面性。&lt;h4&gt;方法&lt;/h4&gt;提出MaskedCLIP框架，该框架结合了掩码图像建模和对比语言-图像预训练，通过桥接Transformer连接掩码特征空间和CLIP特征空间，并使用掩码知识蒸馏损失来提高特征提取的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验证明，该方法在视网膜图像分析任务中表现出有效性和数据效率。&lt;h4&gt;结论&lt;/h4&gt;MaskedCLIP框架能够有效利用配对和未配对图像数据，学习更具泛化能力的图像特征，从而提高下游任务性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have recently gained tremendous popularity in medical imageanalysis. State-of-the-art methods leverage either paired image-text data viavision-language pre-training or unpaired image data via self-supervisedpre-training to learn foundation models with generalizable image features toboost downstream task performance. However, learning foundation modelsexclusively on either paired or unpaired image data limits their ability tolearn richer and more comprehensive image features. In this paper, weinvestigate a novel task termed semi-supervised vision-language pre-training,aiming to fully harness the potential of both paired and unpaired image datafor foundation model learning. To this end, we propose MaskedCLIP, asynergistic masked image modeling and contrastive language-image pre-trainingframework for semi-supervised vision-language pre-training. The key challengein combining paired and unpaired image data for learning a foundation modellies in the incompatible feature spaces derived from these two types of data.To address this issue, we propose to connect the masked feature space with theCLIP feature space with a bridge transformer. In this way, the more semanticspecific CLIP features can benefit from the more general masked features forsemantic feature extraction. We further propose a masked knowledge distillationloss to distill semantic knowledge of original image features in CLIP featurespace back to the predicted masked image features in masked feature space. Withthis mutually interactive design, our framework effectively leverages bothpaired and unpaired image data to learn more generalizable image features fordownstream tasks. Extensive experiments on retinal image analysis demonstratethe effectiveness and data efficiency of our method.</description>
      <author>example@mail.com (Lei Zhu, Jun Zhou, Rick Siow Mong Goh, Yong Liu)</author>
      <guid isPermaLink="false">2507.17239v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Deformable Cluster Manipulation via Whole-Arm Policy Learning</title>
      <link>http://arxiv.org/abs/2507.17085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于学习无需模型的策略，通过结合三维点云和本体感觉指标，实现对变形物体的全身体操感知操控。该框架通过分布状态表示和核均值嵌入，提高了训练效率和实时推理能力。此外，还提出了一个与上下文无关的遮挡启发式算法，用于去除目标区域的变形物体。在输电线清理场景中，该框架能够生成利用多臂链的创意策略。最后，实现了从仿真到现实的无样本策略迁移。&lt;h4&gt;背景&lt;/h4&gt;操控变形物体具有广泛的应用前景，但需要丰富的接触式全臂交互，面临着现实模型合成能力有限、感知高不确定性、缺乏有效空间抽象等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，用于解决操控变形物体的问题，提高训练效率，实现实时推理，并能够去除目标区域的遮挡。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了三维点云和本体感觉指标，使用分布状态表示和核均值嵌入进行学习，并提出了一种遮挡启发式算法。&lt;h4&gt;主要发现&lt;/h4&gt;在输电线清理场景中，该框架能够生成创意策略，并实现从仿真到现实的无样本策略迁移。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架能够有效地操控变形物体，具有实际应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;We propose a novel framework for learning model-free policies integrating two modalities: 3D point clouds and proprioceptive touch indicators, emphasizing manipulation with full body contact awareness, going beyond traditional end-effector modes. Our reinforcement learning framework leverages a distributional state representation, aided by kernel mean embeddings, to achieve improved training efficiency and real-time inference. Furthermore, we propose a novel context-agnostic occlusion heuristic to clear deformables from a target region for exposure tasks. We deploy the framework in a power line clearance scenario and observe that the agent generates creative strategies leveraging multiple arm links for de-occlusion. Finally, we perform zero-shot sim-to-real policy transfer, allowing the arm to clear real branches with unknown occlusion patterns, unseen topology, and uncertain dynamics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Manipulating clusters of deformable objects presents a substantial challengewith widespread applicability, but requires contact-rich whole-arminteractions. A potential solution must address the limited capacity forrealistic model synthesis, high uncertainty in perception, and the lack ofefficient spatial abstractions, among others. We propose a novel framework forlearning model-free policies integrating two modalities: 3D point clouds andproprioceptive touch indicators, emphasising manipulation with full bodycontact awareness, going beyond traditional end-effector modes. Ourreinforcement learning framework leverages a distributional staterepresentation, aided by kernel mean embeddings, to achieve improved trainingefficiency and real-time inference. Furthermore, we propose a novelcontext-agnostic occlusion heuristic to clear deformables from a target regionfor exposure tasks. We deploy the framework in a power line clearance scenarioand observe that the agent generates creative strategies leveraging multiplearm links for de-occlusion. Finally, we perform zero-shot sim-to-real policytransfer, allowing the arm to clear real branches with unknown occlusionpatterns, unseen topology, and uncertain dynamics.</description>
      <author>example@mail.com (Jayadeep Jacob, Wenzheng Zhang, Houston Warren, Paulo Borges, Tirthankar Bandyopadhyay, Fabio Ramos)</author>
      <guid isPermaLink="false">2507.17085v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>PIG-Nav: Key Insights for Pretrained Image Goal Navigation Models</title>
      <link>http://arxiv.org/abs/2507.17220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了PIG-Nav，一种基于预训练模型进行视觉机器人导航的新方法，该方法在多个环境中的导航性能得到提升，并减少了需要微调的数据量。&lt;h4&gt;背景&lt;/h4&gt;近期研究探讨了预训练模型在视觉机器人导航中的应用，旨在实现不同环境下的通用导航和正迁移，并提高在未知设置中的零样本性能。&lt;h4&gt;目的&lt;/h4&gt;进一步研究视觉导航模型的预训练策略，并在两个关键领域做出贡献：模型设计和数据集处理。&lt;h4&gt;方法&lt;/h4&gt;模型设计方面，通过以下两种策略提升预训练导航模型的性能：(1) 整合早期融合网络结构，利用预训练的Vision Transformer图像编码器结合视觉观察和目标图像；(2) 引入适当的辅助任务，增强全局导航表示学习。数据集处理方面，提出了一种新的数据预处理流程，用于高效标注大规模游戏视频数据集。&lt;h4&gt;主要发现&lt;/h4&gt;PIG-Nav在两个复杂模拟环境和真实世界中，相较于现有视觉导航基础模型，在零样本和微调设置下分别提高了22.6%和37.5%的性能。&lt;h4&gt;结论&lt;/h4&gt;PIG-Nav在减少需要微调数据量的同时，保持了有竞争力的性能，具有在现实世界中应用的最小标记监督潜力。&lt;h4&gt;翻译&lt;/h4&gt;Recent studies have explored pretrained (foundation) models for vision-based robotic navigation, aiming to achieve generalizable navigation and positive transfer across diverse environments while enhancing zero-shot performance in unseen settings. In this work, we introduce PIG-Nav (Pretrained Image-Goal Navigation), a new approach that further investigates pretraining strategies for vision-based navigation models and contributes in two key areas. Model-wise, we identify two critical design choices that consistently improve the performance of pretrained navigation models: (1) integrating an early-fusion network structure to combine visual observations and goal images via appropriately pretrained Vision Transformer (ViT) image encoder, and (2) introducing suitable auxiliary tasks to enhance global navigation representation learning, thus further improving navigation performance. Dataset-wise, we propose a novel data preprocessing pipeline for efficiently labeling large-scale game video datasets for navigation model training. We demonstrate that augmenting existing open navigation datasets with diverse gameplay videos improves model performance. Our model achieves an average improvement of 22.6% in zero-shot settings and a 37.5% improvement in fine-tuning settings over existing visual navigation foundation models in two complex simulated environments and one real-world environment. These results advance the state-of-the-art in pretrained image-goal navigation models. Notably, our model maintains competitive performance while requiring significantly less fine-tuning data, highlighting its potential for real-world deployment with minimal labeled supervision.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies have explored pretrained (foundation) models for vision-basedrobotic navigation, aiming to achieve generalizable navigation and positivetransfer across diverse environments while enhancing zero-shot performance inunseen settings. In this work, we introduce PIG-Nav (Pretrained Image-GoalNavigation), a new approach that further investigates pretraining strategiesfor vision-based navigation models and contributes in two key areas.Model-wise, we identify two critical design choices that consistently improvethe performance of pretrained navigation models: (1) integrating anearly-fusion network structure to combine visual observations and goal imagesvia appropriately pretrained Vision Transformer (ViT) image encoder, and (2)introducing suitable auxiliary tasks to enhance global navigationrepresentation learning, thus further improving navigation performance.Dataset-wise, we propose a novel data preprocessing pipeline for efficientlylabeling large-scale game video datasets for navigation model training. Wedemonstrate that augmenting existing open navigation datasets with diversegameplay videos improves model performance. Our model achieves an averageimprovement of 22.6% in zero-shot settings and a 37.5% improvement infine-tuning settings over existing visual navigation foundation models in twocomplex simulated environments and one real-world environment. These resultsadvance the state-of-the-art in pretrained image-goal navigation models.Notably, our model maintains competitive performance while requiringsignificantly less fine-tuning data, highlighting its potential for real-worlddeployment with minimal labeled supervision.</description>
      <author>example@mail.com (Jiansong Wan, Chengming Zhou, Jinkua Liu, Xiangge Huang, Xiaoyu Chen, Xiaohan Yi, Qisen Yang, Baiting Zhu, Xin-Qiang Cai, Lixing Liu, Rushuai Yang, Chuheng Zhang, Sherif Abdelfattah, Hayong Shin, Pushi Zhang, Li Zhao, Jiang Bian)</author>
      <guid isPermaLink="false">2507.17220v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Principled Multimodal Representation Learning</title>
      <link>http://arxiv.org/abs/2507.17343v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages, 9 figures, 10 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Principled Multimodal Representation Learning (PMRL)的新框架，旨在通过同时无锚依赖地对齐多种模态来提高多模态理解。&lt;h4&gt;背景&lt;/h4&gt;传统的多模态表示学习方法依赖于成对对比学习，并依赖于预定义的锚模态，限制了跨所有模态的对齐。&lt;h4&gt;目的&lt;/h4&gt;解决固定锚点限制和优化奇异值乘积引起的不稳定性等挑战。&lt;h4&gt;方法&lt;/h4&gt;PMRL框架基于理论洞察，即完全对齐对应于秩-1的Gram矩阵，通过优化表示矩阵的主奇异值来实现模态沿共享的主方向对齐。此外，使用基于softmax的损失函数，将奇异值视为logits，优先考虑最大的奇异值，并通过对主特征向量的实例对比正则化来保持实例间分离性，防止表示坍缩。&lt;h4&gt;主要发现&lt;/h4&gt;在多种任务上的广泛实验表明，PMRL相比基线方法具有优越性。&lt;h4&gt;结论&lt;/h4&gt;PMRL是一个稳定的框架，能够同时无锚依赖地对齐多种模态，提高了多模态理解的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态表示学习旨在通过整合不同的数据模态来创建一个统一的表示空间，以改善多模态理解。传统方法通常依赖于成对对比学习，这依赖于预定义的锚模态，限制了所有模态之间的对齐。最近的研究探索了同时对齐多种模态，但仍存在一些挑战，例如固定锚点带来的限制和优化奇异值乘积引起的不稳定性。为了解决这些挑战，本文提出了一种名为原理性多模态表示学习（PMRL）的新框架，以一种更稳定的方式在不依赖于锚点的情况下实现多种模态的同时对齐。具体而言，基于完全对齐对应于秩-1的Gram矩阵的理论洞察，PMRL通过优化表示矩阵的主奇异值来沿共享的主方向对齐模态。此外，基于softmax的损失函数将奇异值视为logits，以优先考虑最大的奇异值。另外，对主特征向量的实例对比正则化保持了实例间的分离性，并防止了表示的坍缩。在多种任务上的广泛实验表明，PMRL相比基线方法具有优越性。源代码将公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation learning seeks to create a unified representationspace by integrating diverse data modalities to improve multimodalunderstanding. Traditional methods often depend on pairwise contrastivelearning, which relies on a predefined anchor modality, restricting alignmentacross all modalities. Recent advances have investigated the simultaneousalignment of multiple modalities, yet several challenges remain, such aslimitations imposed by fixed anchor points and instability arising fromoptimizing the product of singular values. To address the challenges, in thispaper, we propose Principled Multimodal Representation Learning (PMRL), a novelframework that achieves simultaneous alignment of multiple modalities withoutanchor dependency in a more stable manner. Specifically, grounded in thetheoretical insight that full alignment corresponds to a rank-1 Gram matrix,PMRL optimizes the dominant singular value of the representation matrix toalign modalities along a shared leading direction. We propose a softmax-basedloss function that treats singular values as logits to prioritize the largestsingular value. Besides, instance-wise contrastive regularization on theleading eigenvectors maintains inter-instance separability and preventsrepresentation collapse. Extensive experiments across diverse tasks demonstratePMRL's superiority compared to baseline methods. The source code will bepublicly available.</description>
      <author>example@mail.com (Xiaohao Liu, Xiaobo Xia, See-Kiong Ng, Tat-Seng Chua)</author>
      <guid isPermaLink="false">2507.17343v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Can LLMs Write CI? A Study on Automatic Generation of GitHub Actions Configurations</title>
      <link>http://arxiv.org/abs/2507.17165v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 41st IEEE International Conference on Software  Maintenance and Evolution 2025 (ICSME'25)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了六种大型语言模型（LLMs）在生成GitHub Actions配置方面的能力，并分析了LLMs在CI配置生成中的局限性。&lt;h4&gt;背景&lt;/h4&gt;虽然CI服务如GitHub Actions越来越受欢迎，但开发者需要编写YAML配置，这既繁琐又容易出错。同时，LLMs在软件工程任务自动化中的应用逐渐增加，但其在生成CI配置方面的能力尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;评估六种LLMs从自然语言描述中生成GitHub Actions配置的能力。&lt;h4&gt;方法&lt;/h4&gt;评估了三种通用基础模型（GPT-4o、Llama和Gemma）和三种代码预训练模型（GPT-4.1、CodeLlama和CodeGemma）。同时，引入了首个此类标签数据集，该数据集由GitHub Actions文档构建，将描述与相应的最佳实践YAML配置配对。&lt;h4&gt;主要发现&lt;/h4&gt;零样本提示达到与真实值的69%相似度，仅有3%完全匹配。代码预训练模型在基于YAML的CI任务中略逊于通用模型，揭示了LLMs在CI配置生成方面的局限性。分析GPT-4o的输出揭示了步骤缺失或重命名、描述误解和添加不必要的步骤等问题，这可能会影响结构和上下文正确性，表明生成质量和可执行CI配置所需的精度之间存在差距。&lt;h4&gt;结论&lt;/h4&gt;研究为改进LLMs与配置语言的匹配度以及指导CI自动化和工具支持的未来努力提供了见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continuous Integration (CI) services, such as GitHub Actions, requiredevelopers to write YAML-based configurations, which can be tedious anderror-prone. Despite the increasing use of Large Language Models (LLMs) toautomate software engineering tasks, their ability to generate CIconfigurations remains underexplored. This paper presents a preliminary studyevaluating six LLMs for generating GitHub Actions configurations from naturallanguage descriptions. We assess three general-purpose foundation models(GPT-4o, Llama, and Gemma) and three code-pretrained models (GPT-4.1, CodeLlama, and CodeGemma). We also introduce the first labeled dataset of its kind,constructed from GitHub Actions documentation, pairing descriptions withcorresponding best-practice YAML configurations. Zero-shot prompting achievesup to 69% similarity with the ground truth, with only 3% perfect matches.Code-pretrained models slightly underperform compared to general-purpose onesin YAML-based CI tasks, revealing LLM limitations for CI configurationgeneration. Analyzing GPT-4o outputs reveals issues like missing or renamedsteps, misinterpreted descriptions, and unnecessary additions that may affectstructural and contextual correctness, indicating a gap between generationquality and the precision required for executable CI configurations. Ourresearch offers insights for improving LLM alignment with configurationlanguages and guiding future efforts on CI automation and tooling support.</description>
      <author>example@mail.com (Taher A. Ghaleb, Dulina Rathnayake)</author>
      <guid isPermaLink="false">2507.17165v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>EndoFinder: Online Lesion Retrieval for Explainable Colorectal Polyp Diagnosis Leveraging Latent Scene Representations</title>
      <link>http://arxiv.org/abs/2507.17323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EndoFinder的在线息肉检索框架，用于解释性和可扩展的大肠癌诊断。&lt;h4&gt;背景&lt;/h4&gt;大肠癌是癌症相关死亡的主要原因，及时检测和诊断息肉至关重要。深度学习模型在光学辅助诊断方面有所改进，但通常需要大量标记数据集，并产生难以解释的“黑盒”输出。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够进行解释性和可扩展的大肠癌诊断的在线息肉检索框架。&lt;h4&gt;方法&lt;/h4&gt;1. 开发了一个息肉感知图像编码器，结合对比学习和重建任务，由息肉分割掩码引导。2. 将每个息肉视为一个三维“场景”，并引入了一个场景表示转换器，将息肉的多个视图融合成一个单一的潜在表示。3. 通过哈希层对这种表示进行离散化，EndoFinder能够从历史息肉病例数据库中实现实时检索。&lt;h4&gt;主要发现&lt;/h4&gt;EndoFinder在准确率上优于现有方法，同时为临床决策提供了基于检索的透明见解。&lt;h4&gt;结论&lt;/h4&gt;EndoFinder通过贡献一个新颖的数据集和一个可扩展、可解释的框架，解决了息肉诊断中的关键挑战，并为更高效的AI驱动结肠镜检查工作流程提供了有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：结直肠癌（CRC）仍然是癌症相关死亡的主要原因，这强调了及时检测和诊断息肉的重要性。虽然深度学习模型已经改进了光学辅助诊断，但它们通常需要大量的标记数据集，并产生难以解释的“黑盒”输出。在本文中，我们提出了一种名为EndoFinder的在线息肉检索框架，该框架利用多视图场景表示进行可解释和可扩展的大肠癌诊断。首先，我们开发了一个息肉感知图像编码器，通过结合对比学习和重建任务，由息肉分割掩码引导。这种自监督方法捕获了鲁棒特征，而不依赖于大规模标注数据。接下来，我们将每个息肉视为一个三维“场景”，并引入了一个场景表示转换器，将息肉的多个视图融合成一个单一的潜在表示。通过哈希层对这种表示进行离散化，EndoFinder能够从历史息肉病例数据库中实现实时检索，其中诊断信息作为新查询的可解释参考。我们在公共和新建的息肉数据集上对EndoFinder进行了再识别和病理分类的评估。结果表明，EndoFinder在准确率上优于现有方法，同时为临床决策提供了基于检索的透明见解。通过贡献一个新颖的数据集和一个可扩展、可解释的框架，我们的工作解决了息肉诊断中的关键挑战，并为更高效的AI驱动结肠镜检查工作流程提供了有希望的方向。源代码可在https://github.com/ku262/EndoFinder-Scene上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Colorectal cancer (CRC) remains a leading cause of cancer-related mortality,underscoring the importance of timely polyp detection and diagnosis. While deeplearning models have improved optical-assisted diagnostics, they often demandextensive labeled datasets and yield "black-box" outputs with limitedinterpretability. In this paper, we propose EndoFinder, an online polypretrieval framework that leverages multi-view scene representations forexplainable and scalable CRC diagnosis. First, we develop a Polyp-aware ImageEncoder by combining contrastive learning and a reconstruction task, guided bypolyp segmentation masks. This self-supervised approach captures robustfeatures without relying on large-scale annotated data. Next, we treat eachpolyp as a three-dimensional "scene" and introduce a Scene RepresentationTransformer, which fuses multiple views of the polyp into a single latentrepresentation. By discretizing this representation through a hashing layer,EndoFinder enables real-time retrieval from a compiled database of historicalpolyp cases, where diagnostic information serves as interpretable referencesfor new queries. We evaluate EndoFinder on both public and newly collectedpolyp datasets for re-identification and pathology classification. Results showthat EndoFinder outperforms existing methods in accuracy while providingtransparent, retrieval-based insights for clinical decision-making. Bycontributing a novel dataset and a scalable, explainable framework, our workaddresses key challenges in polyp diagnosis and offers a promising directionfor more efficient AI-driven colonoscopy workflows. The source code isavailable at https://github.com/ku262/EndoFinder-Scene.</description>
      <author>example@mail.com (Ruijie Yang, Yan Zhu, Peiyao Fu, Yizhe Zhang, Zhihua Wang, Quanlin Li, Pinghong Zhou, Xian Yang, Shuo Wang)</author>
      <guid isPermaLink="false">2507.17323v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>ReMeREC: Relation-aware and Multi-entity Referring Expression Comprehension</title>
      <link>http://arxiv.org/abs/2507.16877v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架ReMeREC，用于在图像中根据自然语言描述定位多个实体，并建模它们之间的关系。&lt;h4&gt;背景&lt;/h4&gt;现有方法在处理单实体定位时效果较好，但在处理多实体场景中的复杂实体关系时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在处理多实体场景中复杂关系和缺乏高质量标注数据集的问题。&lt;h4&gt;方法&lt;/h4&gt;1. 构建了关系感知的多实体REC数据集ReMeX，包含详细的关系和文本标注。2. 提出ReMeREC框架，联合利用视觉和文本线索定位多个实体。3. 引入文本自适应多实体感知器TMP，动态推断实体的数量和范围。4. 提出实体间关系推理器EIR，增强关系推理和全局场景理解。5. 构建了小规模辅助数据集EntityText，用于提高对细粒度提示的语言理解。&lt;h4&gt;主要发现&lt;/h4&gt;ReMeREC在多实体接地和关系预测方面实现了最先进的性能，显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;ReMeREC框架能够有效提高多实体场景中的REC性能，对未来的研究具有指导意义。&lt;h4&gt;翻译&lt;/h4&gt;Referring Expression Comprehension (REC) aims to localize specified entities or regions in an image based on natural language descriptions. While existing methods handle single-entity localization, they often ignore complex inter-entity relationships in multi-entity scenes, limiting their accuracy and reliability. Additionally, the lack of high-quality datasets with fine-grained, paired image-text-relation annotations hinders further progress. To address this challenge, we first construct a relation-aware, multi-entity REC dataset called ReMeX, which includes detailed relationship and textual annotations. We then propose ReMeREC, a novel framework that jointly leverages visual and textual cues to localize multiple entities while modeling their inter-relations. To address the semantic ambiguity caused by implicit entity boundaries in language, we introduce the Text-adaptive Multi-entity Perceptron (TMP), which dynamically infers both the quantity and span of entities from fine-grained textual cues, producing distinctive representations. Additionally, our Entity Inter-relationship Reasoner (EIR) enhances relational reasoning and global scene understanding. To further improve language comprehension for fine-grained prompts, we also construct a small-scale auxiliary dataset, EntityText, generated using large language models. Experiments on four benchmark datasets show that ReMeREC achieves state-of-the-art performance in multi-entity grounding and relation prediction, outperforming existing approaches by a large margin.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Referring Expression Comprehension (REC) aims to localize specified entitiesor regions in an image based on natural language descriptions. While existingmethods handle single-entity localization, they often ignore complexinter-entity relationships in multi-entity scenes, limiting their accuracy andreliability. Additionally, the lack of high-quality datasets with fine-grained,paired image-text-relation annotations hinders further progress. To addressthis challenge, we first construct a relation-aware, multi-entity REC datasetcalled ReMeX, which includes detailed relationship and textual annotations. Wethen propose ReMeREC, a novel framework that jointly leverages visual andtextual cues to localize multiple entities while modeling theirinter-relations. To address the semantic ambiguity caused by implicit entityboundaries in language, we introduce the Text-adaptive Multi-entity Perceptron(TMP), which dynamically infers both the quantity and span of entities fromfine-grained textual cues, producing distinctive representations. Additionally,our Entity Inter-relationship Reasoner (EIR) enhances relational reasoning andglobal scene understanding. To further improve language comprehension forfine-grained prompts, we also construct a small-scale auxiliary dataset,EntityText, generated using large language models. Experiments on fourbenchmark datasets show that ReMeREC achieves state-of-the-art performance inmulti-entity grounding and relation prediction, outperforming existingapproaches by a large margin.</description>
      <author>example@mail.com (Yizhi Hu, Zezhao Tian, Xingqun Qi, Chen Su, Bingkun Yang, Junhui Yin, Muyi Sun, Man Zhang, Zhenan Sun)</author>
      <guid isPermaLink="false">2507.16877v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study</title>
      <link>http://arxiv.org/abs/2507.17118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了人工智能（AI）在自动驾驶系统（ADS）和机器人等安全关键领域的应用，分析了最近自主系统趋向于端到端（E2E）的单一架构，如大型语言模型（LLMs）和视觉语言模型（VLMs）。文章回顾了不同的架构解决方案，评估了常见的安全分析方法如故障模式和影响分析（FMEA）和故障树分析（FTA）的有效性，并展示了如何改进这些技术以适应基础模型复杂性的特点。此外，介绍了HySAFE-AI，这是一个混合框架，用于评估AI系统的安全性，并提出了未来工作方向和AI安全标准的建议。&lt;h4&gt;背景&lt;/h4&gt;AI已成为自动驾驶系统和机器人等安全关键领域的核心部分，这些系统的架构趋向于采用端到端（E2E）的单一架构，如大型语言模型（LLMs）和视觉语言模型（VLMs）。&lt;h4&gt;目的&lt;/h4&gt;评估AI系统的安全性，并提出改进现有安全分析技术的方案。&lt;h4&gt;方法&lt;/h4&gt;回顾不同的架构解决方案，评估故障模式和影响分析（FMEA）和故障树分析（FTA）的有效性，并介绍HySAFE-AI混合框架。&lt;h4&gt;主要发现&lt;/h4&gt;这些技术可以改进以适应基础模型的复杂性，尤其是它们如何形成和使用潜在表示。&lt;h4&gt;结论&lt;/h4&gt;HySAFE-AI是一个混合框架，可以用于评估AI系统的安全性，并提出了未来AI安全标准的建议。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了人工智能在自动驾驶系统（ADS）和机器人等安全关键领域的应用，讨论了最近自主系统趋向于端到端（E2E）的单一架构，如大型语言模型（LLMs）和视觉语言模型（VLMs）。在本文中，我们回顾了不同的架构解决方案，评估了常见的安全分析方法，如故障模式和影响分析（FMEA）和故障树分析（FTA）的有效性。我们展示了如何改进这些技术以适应基础模型的复杂特性，尤其是它们如何形成和使用潜在表示。我们介绍了HySAFE-AI，一个用于评估AI系统安全性的混合框架。最后，我们提出了未来工作的暗示和建议，以指导未来AI安全标准的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AI has become integral to safety-critical areas like autonomous drivingsystems (ADS) and robotics. The architecture of recent autonomous systems aretrending toward end-to-end (E2E) monolithic architectures such as largelanguage models (LLMs) and vision language models (VLMs). In this paper, wereview different architectural solutions and then evaluate the efficacy ofcommon safety analyses such as failure modes and effect analysis (FMEA) andfault tree analysis (FTA). We show how these techniques can be improved for theintricate nature of the foundational models, particularly in how they form andutilize latent representations. We introduce HySAFE-AI, Hybrid SafetyArchitectural Analysis Framework for AI Systems, a hybrid framework that adaptstraditional methods to evaluate the safety of AI systems. Lastly, we offerhints of future work and suggestions to guide the evolution of future AI safetystandards.</description>
      <author>example@mail.com (Mandar Pitale, Jelena Frtunikj, Abhinaw Priyadershi, Vasu Singh, Maria Spence)</author>
      <guid isPermaLink="false">2507.17118v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Spikes</title>
      <link>http://arxiv.org/abs/2507.17224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为HuiduRep的鲁棒自监督表示学习框架，用于从细胞外神经元的尖峰波形中提取有判别性和通用性的特征，并展示了其在尖峰排序和细胞外记录处理中的潜力。&lt;h4&gt;背景&lt;/h4&gt;细胞外记录是神经科学中解码大脑活动的基础，尖峰排序是关键步骤，但在低信噪比、电极漂移和跨会话变化的情况下具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出HuiduRep框架，以实现从细胞外尖峰波形中提取鲁棒特征，并开发一个无监督的尖峰排序流程。&lt;h4&gt;方法&lt;/h4&gt;结合对比学习和降噪自编码器，HuiduRep学习对噪声和漂移鲁棒的潜在表示，并在此基础上开发了一个尖峰排序流程。&lt;h4&gt;主要发现&lt;/h4&gt;HuiduRep在混合和真实世界数据集上表现出了强大的鲁棒性，其排序流程的性能与KiloSort4和MountainSort5等最先进的工具相当或更优。&lt;h4&gt;结论&lt;/h4&gt;自监督尖峰表示学习在处理细胞外记录方面具有成为鲁棒和通用工具的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extracellular recordings are brief voltage fluctuations recorded nearneurons, widely used in neuroscience as the basis for decoding brain activityat single-neuron resolution. Spike sorting, which assigns each spike to itssource neuron, is a critical step in brain sensing pipelines. However, itremains challenging under low signal-to-noise ratio (SNR), electrode drift, andcross-session variability. In this paper, we propose HuiduRep, a robustself-supervised representation learning framework that extracts discriminativeand generalizable features from extracellular spike waveforms. By combiningcontrastive learning with a denoising autoencoder, HuiduRep learns latentrepresentations that are robust to noise and drift. Built on HuiduRep, wedevelop a spike sorting pipeline that clusters spike representations withoutsupervision. Experiments on hybrid and real-world datasets demonstrate thatHuiduRep achieves strong robustness and the pipeline matches or outperformsstate-of-the-art tools such as KiloSort4 and MountainSort5. These findingsdemonstrate the potential of self-supervised spike representation learning as afoundational tool for robust and generalizable processing of extracellularrecordings.</description>
      <author>example@mail.com (Feng Cao, Zishuo Feng)</author>
      <guid isPermaLink="false">2507.17224v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Risk In Context: Benchmarking Privacy Leakage of Foundation Models in Synthetic Tabular Data Generation</title>
      <link>http://arxiv.org/abs/2507.17066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Agentic &amp; GenAI Evaluation KDD2025, poster presentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用大型预训练模型生成合成表格数据在低数据环境下的隐私风险，并通过基准测试和实验评估了不同模型的性能。&lt;h4&gt;背景&lt;/h4&gt;合成表格数据对于机器学习工作流程至关重要，尤其是在数据集小或不平衡以及需要隐私保护的数据共享时。然而，目前最先进的生成模型需要大量数据。&lt;h4&gt;目的&lt;/h4&gt;评估使用大型预训练模型生成合成表格数据的隐私风险，并提出改进方法。&lt;h4&gt;方法&lt;/h4&gt;对三个基础模型（GPT-4o-mini、LLaMA 3.3 70B、TabPFN v2）与四个基线在35个来自健康、金融和政策领域的真实世界表格上进行了基准测试，评估了统计保真度、下游效用和成员推理泄露。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型具有最高的隐私风险，其中LLaMA 3.3 70B在1% FPR下的真阳性率比最安全的基线高出54个百分点。通过实验发现，三种零成本的提示调整（小批量大小、低温度、使用摘要统计）可以降低最坏情况下的AUC值14点，并减少罕见类别泄露高达39点，同时保持超过90%的保真度。&lt;h4&gt;结论&lt;/h4&gt;本文提供了一个实际指南，用于使用基础模型进行更安全的低数据合成，并提出了降低隐私风险的策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Synthetic tabular data is essential for machine learning workflows,especially for expanding small or imbalanced datasets and enablingprivacy-preserving data sharing. However, state-of-the-art generative models(GANs, VAEs, diffusion models) rely on large datasets with thousands ofexamples. In low-data settings, often the primary motivation for syntheticdata, these models can overfit, leak sensitive records, and require frequentretraining. Recent work uses large pre-trained transformers to generate rowsvia in-context learning (ICL), which needs only a few seed examples and noparameter updates, avoiding retraining. But ICL repeats seed rows verbatim,introducing a new privacy risk that has only been studied in text. The severityof this risk in tabular synthesis-where a single row may identify aperson-remains unclear. We address this gap with the first benchmark of threefoundation models (GPT-4o-mini, LLaMA 3.3 70B, TabPFN v2) against fourbaselines on 35 real-world tables from health, finance, and policy. We evaluatestatistical fidelity, downstream utility, and membership inference leakage.Results show foundation models consistently have the highest privacy risk.LLaMA 3.3 70B reaches up to 54 percentage points higher true-positive rate at1% FPR than the safest baseline. GPT-4o-mini and TabPFN are also highlyvulnerable. We plot the privacy-utility frontier and show that CTGAN andGPT-4o-mini offer better tradeoffs. A factorial study finds that threezero-cost prompt tweaks-small batch size, low temperature, and using summarystatistics-can reduce worst-case AUC by 14 points and rare-class leakage by upto 39 points while maintaining over 90% fidelity. Our benchmark offers apractical guide for safer low-data synthesis with foundation models.</description>
      <author>example@mail.com (Jessup Byun, Xiaofeng Lin, Joshua Ward, Guang Cheng)</author>
      <guid isPermaLink="false">2507.17066v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>StreamME: Simplify 3D Gaussian Avatar within Live Stream</title>
      <link>http://arxiv.org/abs/2507.17029v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 15 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;StreamME是一种专注于快速3D角色重建的方法，能够从实时视频流中同步记录和重建头部角色形象，无需预存数据，并能将重建的外观无缝集成到下游应用中。&lt;h4&gt;背景&lt;/h4&gt;传统方法依赖于预缓存数据和复杂的机器学习模型，导致重建速度慢且效率低下。&lt;h4&gt;目的&lt;/h4&gt;提高3D角色重建的速度和效率，实现实时重建和隐私保护。&lt;h4&gt;方法&lt;/h4&gt;StreamME基于3D高斯分层（3DGS）技术，通过仅依赖几何信息来消除可变形3DGS中对MLP的依赖，并引入基于主点的简化策略，优化点云分布以提高渲染效率。&lt;h4&gt;主要发现&lt;/h4&gt;StreamME实现了快速重建，通过优化点云分布和简化训练策略，显著提高了适应面部表情的速度，同时保护了面部隐私并减少了VR系统或在线会议中的通信带宽。&lt;h4&gt;结论&lt;/h4&gt;StreamME可以直接应用于动画、卡通化、重光照等下游应用，提供了快速、高效、隐私保护的3D角色重建解决方案。&lt;h4&gt;翻译&lt;/h4&gt;We propose StreamME, a method focuses on fast 3D avatar reconstruction. The StreamME synchronously records and reconstructs a head avatar from live videostreams without any pre-cached data, enabling seamless integration of the reconstructed appearance into downstream applications. This exceptionally fast training strategy, which we refer to as on-the-fly training, is central to our approach. Our method is built upon 3D Gaussian Splatting (3DGS), eliminating the reliance on MLPs in deformable 3DGS and relying solely on geometry, which significantly improves the adaptation speed to facial expression. To further ensure high efficiency in on-the-fly training, we introduced a simplification strategy based on primary points, which distributes the point clouds more sparsely across the facial surface, optimizing points number while maintaining rendering quality. Leveraging the on-the-fly training capabilities, our method protects the facial privacy and reduces communication bandwidth in VR system or online conference. Additionally, it can be directly applied to downstream application such as animation, toonify, and relighting. Please refer to our project page for more details: https://songluchuan.github.io/StreamME/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose StreamME, a method focuses on fast 3D avatar reconstruction. TheStreamME synchronously records and reconstructs a head avatar from live videostreams without any pre-cached data, enabling seamless integration of thereconstructed appearance into downstream applications. This exceptionally fasttraining strategy, which we refer to as on-the-fly training, is central to ourapproach. Our method is built upon 3D Gaussian Splatting (3DGS), eliminatingthe reliance on MLPs in deformable 3DGS and relying solely on geometry, whichsignificantly improves the adaptation speed to facial expression. To furtherensure high efficiency in on-the-fly training, we introduced a simplificationstrategy based on primary points, which distributes the point clouds moresparsely across the facial surface, optimizing points number while maintainingrendering quality. Leveraging the on-the-fly training capabilities, our methodprotects the facial privacy and reduces communication bandwidth in VR system oronline conference. Additionally, it can be directly applied to downstreamapplication such as animation, toonify, and relighting. Please refer to ourproject page for more details: https://songluchuan.github.io/StreamME/.</description>
      <author>example@mail.com (Luchuan Song, Yang Zhou, Zhan Xu, Yi Zhou, Deepali Aneja, Chenliang Xu)</author>
      <guid isPermaLink="false">2507.17029v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning</title>
      <link>http://arxiv.org/abs/2507.16802v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Agentar-Fin-R1系列金融大语言模型，这些模型基于Qwen3基础模型，旨在提升金融应用中的推理能力、可靠性和领域专业化。&lt;h4&gt;背景&lt;/h4&gt;现有的金融大语言模型在需要复杂推理、严格可靠性和适应特定领域要求的情况下存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提升金融大语言模型在金融应用中的推理能力、可靠性和领域专业化。&lt;h4&gt;方法&lt;/h4&gt;采用高质量、系统的金融任务标签系统与多层次的可靠性保证框架，包括高质量的可信知识工程、多代理可信数据合成和严格的数据验证治理。通过标签引导的自动化难度感知优化、两阶段训练流程和动态属性系统，提高了训练效率。&lt;h4&gt;主要发现&lt;/h4&gt;Agentar-Fin-R1在主流金融基准测试（如Fineva、FinEval和FinanceIQ）以及通用推理数据集（如MATH-500和GPQA-diamond）上表现出色。创新性地提出了Finova评估基准，专注于代理级别的金融推理和合规性验证。&lt;h4&gt;结论&lt;/h4&gt;Agentar-Fin-R1不仅在金融任务上达到最先进的性能，还展现出卓越的通用推理能力，验证了其在高风险金融应用中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) exhibit considerable promise in financial applications; however, prevailing models frequently demonstrate limitations when confronted with scenarios that necessitate sophisticated reasoning capabilities, stringent trustworthiness criteria, and efficient adaptation to domain-specific requirements. We introduce the Agentar-Fin-R1 series of financial large language models (8B and 32B parameters), specifically engineered based on the Qwen3 foundation model to enhance reasoning capabilities, reliability, and domain specialization for financial applications. Our optimization approach integrates a high-quality, systematic financial task label system with a comprehensive multi-layered trustworthiness assurance framework. This framework encompasses high-quality trustworthy knowledge engineering, multi-agent trustworthy data synthesis, and rigorous data validation governance. Through label-guided automated difficulty-aware optimization, two-stage training pipeline, and dynamic attribution systems, we achieve substantial improvements in training efficiency. Our models undergo comprehensive evaluation on mainstream financial benchmarks including Fineva, FinEval, and FinanceIQ, as well as general reasoning datasets such as MATH-500 and GPQA-diamond. To thoroughly assess real-world deployment capabilities, we innovatively propose the Finova evaluation benchmark, which focuses on agent-level financial reasoning and compliance verification. Experimental results demonstrate that Agentar-Fin-R1 not only achieves state-of-the-art performance on financial tasks but also exhibits exceptional general reasoning capabilities, validating its effectiveness as a trustworthy solution for high-stakes financial applications. The Finova bench is available at https://github.com/antgroup/Finova.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) exhibit considerable promise in financialapplications; however, prevailing models frequently demonstrate limitationswhen confronted with scenarios that necessitate sophisticated reasoningcapabilities, stringent trustworthiness criteria, and efficient adaptation todomain-specific requirements. We introduce the Agentar-Fin-R1 series offinancial large language models (8B and 32B parameters), specificallyengineered based on the Qwen3 foundation model to enhance reasoningcapabilities, reliability, and domain specialization for financialapplications. Our optimization approach integrates a high-quality, systematicfinancial task label system with a comprehensive multi-layered trustworthinessassurance framework. This framework encompasses high-quality trustworthyknowledge engineering, multi-agent trustworthy data synthesis, and rigorousdata validation governance. Through label-guided automated difficulty-awareoptimization, tow-stage training pipeline, and dynamic attribution systems, weachieve substantial improvements in training efficiency. Our models undergocomprehensive evaluation on mainstream financial benchmarks including Fineva,FinEval, and FinanceIQ, as well as general reasoning datasets such as MATH-500and GPQA-diamond. To thoroughly assess real-world deployment capabilities, weinnovatively propose the Finova evaluation benchmark, which focuses onagent-level financial reasoning and compliance verification. Experimentalresults demonstrate that Agentar-Fin-R1 not only achieves state-of-the-artperformance on financial tasks but also exhibits exceptional general reasoningcapabilities, validating its effectiveness as a trustworthy solution forhigh-stakes financial applications. The Finova bench is available athttps://github.com/antgroup/Finova.</description>
      <author>example@mail.com (Yanjun Zheng, Xiyang Du, Longfei Liao, Xiaoke Zhao, Zhaowen Zhou, Bo Zhang, Jiawei Liu, Xiang Qi, Zhe Li, Zhiqiang Zhang, Wei Wang, Peng Zhang)</author>
      <guid isPermaLink="false">2507.16802v2</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Should Bias Always be Eliminated? A Principled Framework to Use Data Bias for OOD Generation</title>
      <link>http://arxiv.org/abs/2507.17001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的模型自适应方法，该方法在推理过程中战略性地利用偏差来补充不变性表示，以应对分布外域的挑战。&lt;h4&gt;背景&lt;/h4&gt;现有方法大多依赖于不变性表示学习来消除偏差特征的影响，但作者提出质疑：偏差是否应该总是被消除，以及何时应该保留偏差并如何利用它。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文首先进行了理论分析，探讨了在什么条件下可以识别和有效利用偏差特征，然后提出了一种新的框架。&lt;h4&gt;方法&lt;/h4&gt;该框架包括两个关键组件：(1) 使用不变性作为指导来从偏差中提取预测因素；(2) 利用识别出的偏差来估计环境条件，然后使用它来探索适当的偏差感知预测器以缓解环境差距。&lt;h4&gt;主要发现&lt;/h4&gt;通过在合成数据集和标准领域泛化基准上的实验验证了该方法的有效性，结果表明该方法优于现有方法，证明了其鲁棒性和适应性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过有效地利用偏差特征，在处理分布外域的数据时展现出优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most existing methods for adapting models to out-of-distribution (OOD)domains rely on invariant representation learning to eliminate the influence ofbiased features. However, should bias always be eliminated -- and if not, whenshould it be retained, and how can it be leveraged? To address these questions,we first present a theoretical analysis that explores the conditions underwhich biased features can be identified and effectively utilized. Building onthis theoretical foundation, we introduce a novel framework that strategicallyleverages bias to complement invariant representations during inference. Theframework comprises two key components that leverage bias in both direct andindirect ways: (1) using invariance as guidance to extract predictiveingredients from bias, and (2) exploiting identified bias to estimate theenvironmental condition and then use it to explore appropriate bias-awarepredictors to alleviate environment gaps. We validate our approach throughexperiments on both synthetic datasets and standard domain generalizationbenchmarks. Results consistently demonstrate that our method outperformsexisting approaches, underscoring its robustness and adaptability.</description>
      <author>example@mail.com (Yan Li, Guangyi Chen, Yunlong Deng, Zijian Li, Zeyu Tang, Anpeng Wu, Kun Zhang)</author>
      <guid isPermaLink="false">2507.17001v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Confidence Optimization for Probabilistic Encoding</title>
      <link>http://arxiv.org/abs/2507.16881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种置信度优化概率编码（CPE）方法，用于提高神经网络中概率编码的距离可靠性，增强表示学习，并显著提升自然语言分类任务中的性能和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;概率编码通过引入高斯噪声到神经网络中，使网络从确定性状态平滑过渡到不确定性状态，从而增强泛化能力。然而，高斯噪声的随机性会扭曲分类任务中的基于点的距离测量。&lt;h4&gt;目的&lt;/h4&gt;提出CPE方法以减轻高斯噪声对距离测量的扭曲，提高距离可靠性，并增强表示学习。&lt;h4&gt;方法&lt;/h4&gt;CPE方法通过以下两个关键策略进行概率编码的优化：1. 引入一个置信度感知机制来调整距离计算，确保在概率编码分类任务中的一致性和可靠性；2. 用简单的L2正则化项替换传统的基于KL散度的方差正则化，以直接约束方差。&lt;h4&gt;主要发现&lt;/h4&gt;该方法对模型无依赖性，在BERT和RoBERTa模型上的自然语言分类任务中，CPE方法显著提高了性能和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;CPE方法能够有效提升神经网络在自然语言处理任务中的性能和泛化能力，为概率编码提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Probabilistic encoding introduces Gaussian noise into neural networks, enabling a smooth transition from deterministic to uncertain states and enhancing generalization ability. However, the randomness of Gaussian noise distorts point-based distance measurements in classification tasks. To mitigate this issue, we propose a confidence optimization probabilistic encoding (CPE) method that improves distance reliability and enhances representation learning. Specifically, we refine probabilistic encoding with two key strategies: First, we introduce a confidence-aware mechanism to adjust distance calculations, ensuring consistency and reliability in probabilistic encoding classification tasks. Second, we replace the conventional KL divergence-based variance regularization, which relies on unreliable prior assumptions, with a simpler L2 regularization term to directly constrain variance. The method we proposed is model-agnostic, and extensive experiments on natural language classification tasks demonstrate that our method significantly improves performance and generalization on both the BERT and the RoBERTa model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Probabilistic encoding introduces Gaussian noise into neural networks,enabling a smooth transition from deterministic to uncertain states andenhancing generalization ability. However, the randomness of Gaussian noisedistorts point-based distance measurements in classification tasks. To mitigatethis issue, we propose a confidence optimization probabilistic encoding (CPE)method that improves distance reliability and enhances representation learning.Specifically, we refine probabilistic encoding with two key strategies: First,we introduce a confidence-aware mechanism to adjust distance calculations,ensuring consistency and reliability in probabilistic encoding classificationtasks. Second, we replace the conventional KL divergence-based varianceregularization, which relies on unreliable prior assumptions, with a simpler L2regularization term to directly constrain variance. The method we proposed ismodel-agnostic, and extensive experiments on natural language classificationtasks demonstrate that our method significantly improves performance andgeneralization on both the BERT and the RoBERTa model.</description>
      <author>example@mail.com (Pengjiu Xia, Yidian Huang, Wenchao Wei, Yuwen Tan)</author>
      <guid isPermaLink="false">2507.16881v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>CompLeak: Deep Learning Model Compression Exacerbates Privacy Leakage</title>
      <link>http://arxiv.org/abs/2507.16872v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CompLeak的隐私风险评估框架，用于评估深度学习模型压缩过程中产生的隐私风险。&lt;h4&gt;背景&lt;/h4&gt;模型压缩对于减少内存存储和加速深度学习模型（包括大型语言模型）的推理至关重要。然而，压缩过程中引入的隐私风险常被忽视。&lt;h4&gt;目的&lt;/h4&gt;通过成员推理攻击（MIA）的视角，提出CompLeak，旨在评估三种常用压缩配置（剪枝、量化和权重聚类）的隐私风险。&lt;h4&gt;方法&lt;/h4&gt;CompLeak有三个变体，根据压缩模型和原始模型的数量提供不同的评估方式。CompLeakNR通过攻击单个压缩模型来识别不同压缩模型对成员和非成员的影响。CompLeakSR利用压缩模型作为原始模型的信息，通过结合模型的元信息来揭示更多隐私。CompLeakMR利用多个压缩版本的隐私泄露信息来显著标识总体隐私泄露。&lt;h4&gt;主要发现&lt;/h4&gt;实验在七个不同的模型架构和六个图像及文本基准数据集上进行了，揭示了压缩模型对隐私泄露的影响。&lt;h4&gt;结论&lt;/h4&gt;CompLeak框架为评估深度学习模型压缩过程中的隐私风险提供了一个有效的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：模型压缩对于减少深度学习（DL）模型（包括最近的基础模型如大型语言模型（LLM））的内存存储和加速推理至关重要。用户可以根据其资源和预算访问不同的压缩模型版本。然而，现有的压缩操作主要关注优化资源效率和模型性能之间的权衡，而压缩过程中引入的隐私风险却被忽视且理解不足。在这项工作中，通过成员推理攻击（MIA）的视角，我们提出了CompLeak，这是第一个评估三个广泛使用的压缩配置（剪枝、量化和权重聚类）的隐私风险框架，这些配置由Google的TensorFlow-Lite（TF-Lite）和Facebook的PyTorch Mobile的商业模型压缩框架支持。CompLeak有三个变体，根据可用的压缩模型数量和原始模型数量。CompLeakNR首先采用现有的MIA方法攻击单个压缩模型，并发现不同的压缩模型对成员和非成员的影响不同。当原始模型和单个压缩模型可用时，CompLeakSR利用压缩模型作为原始模型的参考，并通过结合来自两个模型的元信息（例如，置信向量）来揭示更多隐私。当多个压缩模型（有/无访问原始模型）可用时，CompLeakMR创新性地利用多个压缩版本的隐私泄露信息，显著标识总体隐私泄露。我们在七个不同的模型架构（从ResNet到BERT和GPT-2的基础模型）和六个图像和文本基准数据集上进行了广泛的实验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model compression is crucial for minimizing memory storage and acceleratinginference in deep learning (DL) models, including recent foundation models likelarge language models (LLMs). Users can access different compressed modelversions according to their resources and budget. However, while existingcompression operations primarily focus on optimizing the trade-off betweenresource efficiency and model performance, the privacy risks introduced bycompression remain overlooked and insufficiently understood.  In this work, through the lens of membership inference attack (MIA), wepropose CompLeak, the first privacy risk evaluation framework examining threewidely used compression configurations that are pruning, quantization, andweight clustering supported by the commercial model compression framework ofGoogle's TensorFlow-Lite (TF-Lite) and Facebook's PyTorch Mobile. CompLeak hasthree variants, given available access to the number of compressed models andoriginal model. CompLeakNR starts by adopting existing MIA methods to attack asingle compressed model, and identifies that different compressed modelsinfluence members and non-members differently. When the original model and onecompressed model are available, CompLeakSR leverages the compressed model as areference to the original model and uncovers more privacy by combining metainformation (e.g., confidence vector) from both models. When multiplecompressed models are available with/without accessing the original model,CompLeakMR innovatively exploits privacy leakage info from multiple compressedversions to substantially signify the overall privacy leakage. We conductextensive experiments on seven diverse model architectures (from ResNet tofoundation models of BERT and GPT-2), and six image and textual benchmarkdatasets.</description>
      <author>example@mail.com (Na Li, Yansong Gao, Hongsheng Hu, Boyu Kuang, Anmin Fu)</author>
      <guid isPermaLink="false">2507.16872v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>CLAMP: Contrastive Learning with Adaptive Multi-loss and Progressive Fusion for Multimodal Aspect-Based Sentiment Analysis</title>
      <link>http://arxiv.org/abs/2507.16854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为CLAMP的多模态基于方面的情感分析框架，用于识别图像-文本数据中的方面术语及其细粒度情感极性。&lt;h4&gt;背景&lt;/h4&gt;现有方法在跨模态对齐噪声和细粒度表示的连贯性方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一个端到端的对比学习框架CLAMP，以解决现有方法的限制。&lt;h4&gt;方法&lt;/h4&gt;CLAMP框架包括三个创新模块：渐进式注意力融合网络、多任务对比学习和自适应多损失聚合。渐进式注意力融合网络通过分层、多阶段的跨模态交互增强了文本特征与图像区域之间的细粒度对齐，有效地抑制了无关视觉噪声。多任务对比学习结合了全局模态对比和局部粒度对齐以增强跨模态表示的连贯性。自适应多损失聚合使用基于动态不确定性的加权机制来校准损失贡献，根据每个任务的不确定性进行调整，从而减轻梯度干扰。&lt;h4&gt;主要发现&lt;/h4&gt;在标准公共基准上的评估表明，CLAMP在一致性上优于大多数现有最先进方法。&lt;h4&gt;结论&lt;/h4&gt;CLAMP框架有效地解决了多模态基于方面的情感分析中的挑战，并显著提高了情感分析的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal aspect-based sentiment analysis(MABSA) seeks to identify aspectterms within paired image-text data and determine their fine grained sentimentpolarities, representing a fundamental task for improving the effectiveness ofapplications such as product review systems and public opinion monitoring.Existing methods face challenges such as cross modal alignment noise andinsufficient consistency in fine-grained representations. While global modalityalignment methods often overlook the connection between aspect terms and theircorresponding local visual regions, bridging the representation gap betweentext and images remains a challenge. To address these limitations, this paperintroduces an end to end Contrastive Learning framework with AdaptiveMulti-loss and Progressive Attention Fusion(CLAMP). The framework is composedof three novel modules: Progressive Attention Fusion network, Multi-taskContrastive Learning, and Adaptive Multi-loss Aggregation. The ProgressiveAttention Fusion network enhances fine-grained alignment between textualfeatures and image regions via hierarchical, multi-stage cross modalinteractions, effectively suppressing irrelevant visual noise. Secondly,multi-task contrastive learning combines global modal contrast and localgranularity alignment to enhance cross modal representation consistency.Adaptive Multi-loss Aggregation employs a dynamic uncertainty based weightingmechanism to calibrate loss contributions according to each task's uncertainty,thereby mitigating gradient interference. Evaluation on standard publicbenchmarks demonstrates that CLAMP consistently outperforms the vast majorityof existing state of the art methods.</description>
      <author>example@mail.com (Xiaoqiang He)</author>
      <guid isPermaLink="false">2507.16854v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Controllable Video Generation: A Survey</title>
      <link>http://arxiv.org/abs/2507.16869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  project page:  https://github.com/mayuelala/Awesome-Controllable-Video-Generation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了可控视频生成领域，包括理论基础和最新进展。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能生成内容（AIGC）的快速发展，视频生成已成为其最具活力和影响力的子领域之一。&lt;h4&gt;目的&lt;/h4&gt;为了更精确地反映用户意图，研究可控视频生成方法的需求日益增长。&lt;h4&gt;方法&lt;/h4&gt;通过整合非文本条件，如相机运动、深度图和人体姿态，扩展预训练的视频生成模型，实现更可控的视频合成。&lt;h4&gt;主要发现&lt;/h4&gt;现有的基础模型多针对文本到视频生成，而文本提示通常不足以表达复杂的、多模态的和精细的用户需求。&lt;h4&gt;结论&lt;/h4&gt;本文对可控视频生成进行了系统回顾，并基于所利用的控制信号类型对现有方法进行了分类。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着人工智能生成内容（AIGC）的快速发展，视频生成已成为其最具活力和影响力的子领域之一。特别是视频生成基础模型的进步，导致了对可控视频生成方法的需求增长，这些方法能够更精确地反映用户意图。大多数现有基础模型是为文本到视频生成而设计的，单独的文本提示通常不足以表达复杂的、多模态的和精细的用户需求。这种限制使得用户难以使用当前模型精确控制地生成视频。为了解决这个问题，最近的研究探索了将额外的非文本条件，如相机运动、深度图和人体姿态的整合，以扩展预训练的视频生成模型并实现更可控的视频合成。这些方法旨在提高AIGC驱动的视频生成系统的灵活性和实用性。在本调查中，我们对可控视频生成提供了系统的回顾，涵盖了该领域的理论基础和最新进展。我们首先介绍了关键概念和常用的开源视频生成模型。然后，我们关注视频扩散模型中的控制机制，分析了如何将不同类型的条件纳入去噪过程以引导生成。最后，我们根据所利用的控制信号类型对现有方法进行了分类，包括单条件生成、多条件生成和通用可控生成。有关可控视频生成文献的完整列表，请访问我们的整理仓库https://github.com/mayuelala/Awesome-Controllable-Video-Generation。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of AI-generated content (AIGC), video generationhas emerged as one of its most dynamic and impactful subfields. In particular,the advancement of video generation foundation models has led to growing demandfor controllable video generation methods that can more accurately reflect userintent. Most existing foundation models are designed for text-to-videogeneration, where text prompts alone are often insufficient to express complex,multi-modal, and fine-grained user requirements. This limitation makes itchallenging for users to generate videos with precise control using currentmodels. To address this issue, recent research has explored the integration ofadditional non-textual conditions, such as camera motion, depth maps, and humanpose, to extend pretrained video generation models and enable more controllablevideo synthesis. These approaches aim to enhance the flexibility and practicalapplicability of AIGC-driven video generation systems. In this survey, weprovide a systematic review of controllable video generation, covering boththeoretical foundations and recent advances in the field. We begin byintroducing the key concepts and commonly used open-source video generationmodels. We then focus on control mechanisms in video diffusion models,analyzing how different types of conditions can be incorporated into thedenoising process to guide generation. Finally, we categorize existing methodsbased on the types of control signals they leverage, including single-conditiongeneration, multi-condition generation, and universal controllable generation.For a complete list of the literature on controllable video generationreviewed, please visit our curated repository athttps://github.com/mayuelala/Awesome-Controllable-Video-Generation.</description>
      <author>example@mail.com (Yue Ma, Kunyu Feng, Zhongyuan Hu, Xinyu Wang, Yucheng Wang, Mingzhe Zheng, Xuanhua He, Chenyang Zhu, Hongyu Liu, Yingqing He, Zeyu Wang, Zhifeng Li, Xiu Li, Wei Liu, Dan Xu, Linfeng Zhang, Qifeng Chen)</author>
      <guid isPermaLink="false">2507.16869v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion</title>
      <link>http://arxiv.org/abs/2506.15610v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://lanlan96.github.io/BoxFusion/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的无重建在线3D目标检测框架，旨在实现内存高效和实时检测。&lt;h4&gt;背景&lt;/h4&gt;Open-vocabulary 3D目标检测在自动驾驶和具身AI等领域有重要应用，但现有方法依赖密集点云重建，导致计算和内存开销大，难以实时部署。&lt;h4&gt;目的&lt;/h4&gt;提出一种内存高效和实时3D检测的方法。&lt;h4&gt;方法&lt;/h4&gt;使用Cubify Anything作为预训练的视觉基础模型进行单视图3D目标检测，结合CLIP捕获检测物体的开放词汇语义。通过关联模块进行多视图对应，优化模块融合多视图中预测的同一实例的3D边界框。关联模块使用3D非极大值抑制(NMS)和框对应匹配模块，优化模块使用基于粒子滤波的IoU引导高效随机优化技术，以最小化计算复杂度并确保多视图一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在ScanNetV2和CA-1M数据集上的实验表明，该方法在在线方法中取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在多种场景中表现出良好的泛化能力，即使在超过1000平方米的环境中也能实现实时感知。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is summarized as follows: Open-vocabulary 3D object detection has gained significant interest due to its critical applications in autonomous driving and embodied AI. Existing detection methods, whether offline or online, typically rely on dense point cloud reconstruction, which imposes substantial computational overhead and memory constraints, hindering real-time deployment in downstream tasks. To address this, we propose a novel reconstruction-free online framework tailored for memory-efficient and real-time 3D detection. Specifically, given streaming posed RGB-D video input, we leverage Cubify Anything as a pre-trained visual foundation model (VFM) for single-view 3D object detection by bounding boxes, coupled with CLIP to capture open-vocabulary semantics of detected objects. To fuse all detected bounding boxes across different views into a unified one, we employ an association module for correspondences of multi-views and an optimization module to fuse the 3D bounding boxes of the same instance predicted in multi-views. The association module utilizes 3D Non-Maximum Suppression (NMS) and a box correspondence matching module, while the optimization module uses an IoU-guided efficient random optimization technique based on particle filtering to enforce multi-view consistency of the 3D bounding boxes while minimizing computational complexity. Extensive experiments on ScanNetV2 and CA-1M datasets demonstrate that our method achieves state-of-the-art performance among online methods. Benefiting from this novel reconstruction-free paradigm for 3D object detection, our method exhibits great generalization abilities in various scenarios, enabling real-time perception even in environments exceeding 1000 square meters.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary 3D object detection has gained significant interest due toits critical applications in autonomous driving and embodied AI. Existingdetection methods, whether offline or online, typically rely on dense pointcloud reconstruction, which imposes substantial computational overhead andmemory constraints, hindering real-time deployment in downstream tasks. Toaddress this, we propose a novel reconstruction-free online framework tailoredfor memory-efficient and real-time 3D detection. Specifically, given streamingposed RGB-D video input, we leverage Cubify Anything as a pre-trained visualfoundation model (VFM) for single-view 3D object detection by bounding boxes,coupled with CLIP to capture open-vocabulary semantics of detected objects. Tofuse all detected bounding boxes across different views into a unified one, weemploy an association module for correspondences of multi-views and anoptimization module to fuse the 3D bounding boxes of the same instancepredicted in multi-views. The association module utilizes 3D Non-MaximumSuppression (NMS) and a box correspondence matching module, while theoptimization module uses an IoU-guided efficient random optimization techniquebased on particle filtering to enforce multi-view consistency of the 3Dbounding boxes while minimizing computational complexity. Extensive experimentson ScanNetV2 and CA-1M datasets demonstrate that our method achievesstate-of-the-art performance among online methods. Benefiting from this novelreconstruction-free paradigm for 3D object detection, our method exhibits greatgeneralization abilities in various scenarios, enabling real-time perceptioneven in environments exceeding 1000 square meters.</description>
      <author>example@mail.com (Yuqing Lan, Chenyang Zhu, Zhirui Gao, Jiazhao Zhang, Yihan Cao, Renjiao Yi, Yijie Wang, Kai Xu)</author>
      <guid isPermaLink="false">2506.15610v2</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>CASPER: Contrastive Approach for Smart Ponzi Scheme Detecter with More Negative Samples</title>
      <link>http://arxiv.org/abs/2507.16840v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为CASPER的新颖对比学习方法，用于检测区块链交易中的智能庞氏骗局。该方法能够使用少量标注数据有效检测庞氏骗局。&lt;h4&gt;背景&lt;/h4&gt;数字货币交易的发展促进了区块链技术的整合，但也引发了创新和智能庞氏骗局的涌现。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效且成本效益高的方法来检测智能庞氏骗局。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于对比学习的框架CASPER，通过使用无标注数据集学习智能合同源代码的有效表示来提高庞氏骗局检测。&lt;h4&gt;主要发现&lt;/h4&gt;在XBlock数据集上，与基线模型相比，CASPER在使用100%标注数据时F1分数提高了2.3%。即使在只有25%标注数据的情况下，CASPER的F1分数也比基线高近20%。&lt;h4&gt;结论&lt;/h4&gt;CASPER在检测智能庞氏骗局方面具有潜力，为未来的可扩展欺诈检测解决方案铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;The rapid evolution of digital currency trading, fueled by the integration of blockchain technology, has led to both innovation and the emergence of smart Ponzi schemes. A smart Ponzi scheme is a fraudulent investment operation in smart contract that uses funds from new investors to pay returns to earlier investors. Traditional Ponzi scheme detection methods based on deep learning typically rely on fully supervised models, which require large amounts of labeled data. However, such data is often scarce, hindering effective model training. To address this challenge, we propose a novel contrastive learning framework, CASPER (Contrastive Approach for Smart Ponzi detectER with more negative samples), designed to enhance smart Ponzi scheme detection in blockchain transactions. By leveraging contrastive learning techniques, CASPER can learn more effective representations of smart contract source code using unlabeled datasets, significantly reducing both operational costs and system complexity. We evaluate CASPER on the XBlock dataset, where it outperforms the baseline by 2.3% in F1 score when trained with 100% labeled data. More impressively, with only 25% labeled data, CASPER achieves an F1 score nearly 20% higher than the baseline under identical experimental conditions. These results highlight CASPER's potential for effective and cost-efficient detection of smart Ponzi schemes, paving the way for scalable fraud detection solutions in the future.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid evolution of digital currency trading, fueled by the integration ofblockchain technology, has led to both innovation and the emergence of smartPonzi schemes. A smart Ponzi scheme is a fraudulent investment operation insmart contract that uses funds from new investors to pay returns to earlierinvestors. Traditional Ponzi scheme detection methods based on deep learningtypically rely on fully supervised models, which require large amounts oflabeled data. However, such data is often scarce, hindering effective modeltraining. To address this challenge, we propose a novel contrastive learningframework, CASPER (Contrastive Approach for Smart Ponzi detectER with morenegative samples), designed to enhance smart Ponzi scheme detection inblockchain transactions. By leveraging contrastive learning techniques, CASPERcan learn more effective representations of smart contract source code usingunlabeled datasets, significantly reducing both operational costs and systemcomplexity. We evaluate CASPER on the XBlock dataset, where it outperforms thebaseline by 2.3% in F1 score when trained with 100% labeled data. Moreimpressively, with only 25% labeled data, CASPER achieves an F1 score nearly20% higher than the baseline under identical experimental conditions. Theseresults highlight CASPER's potential for effective and cost-efficient detectionof smart Ponzi schemes, paving the way for scalable fraud detection solutionsin the future.</description>
      <author>example@mail.com (Weijia Yang, Tian Lan, Leyuan Liu, Wei Chen, Tianqing Zhu, Sheng Wen, Xiaosong Zhang)</author>
      <guid isPermaLink="false">2507.16840v1</guid>
      <pubDate>Thu, 24 Jul 2025 14:36:42 +0800</pubDate>
    </item>
    <item>
      <title>Direct Vertex Reconstruction of $Λ$ Baryons from Hits in CLAS12 using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.01868v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文报道了在高能和核物理学数据分析中使用图神经网络（GNN）来直接从CLAS12实验中跟踪探测器中的碰撞点重建Λ超子的衰变顶点。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在数据分析中被广泛使用，特别是在高能和核物理学领域。&lt;h4&gt;目的&lt;/h4&gt;研究使用GNN直接从碰撞点重建Λ超子的衰变顶点，并与基于轨迹的标准算法进行比较。&lt;h4&gt;方法&lt;/h4&gt;在JLab的CLAS12实验中使用GNN进行顶点重建，并与基于轨迹的标准算法进行对比。&lt;h4&gt;主要发现&lt;/h4&gt;GNN在模拟中的顶点重建性能优于基于轨迹的算法，这为进一步研究提供了依据。&lt;h4&gt;结论&lt;/h4&gt;尽管当前研究受限于可用的训练资源，但该研究提出了一种有趣的可能性，即通过神经网络直接将碰撞点映射到顶点，从而避免在复杂磁场中进行轨迹拟合。&lt;h4&gt;翻译&lt;/h4&gt;摘要：机器学习技术，包括图神经网络（GNN），在高能和核物理学的数据分析中被广泛使用。在此，我们报告了在杰弗逊实验室（JLab）的CLAS12实验中，使用GNN直接从跟踪探测器中的碰撞点重建Λ超子的衰变顶点的情况。我们表明，与基于轨迹的标准算法相比，我们可以在模拟中改进顶点重建。我们认为这值得进一步研究。当前的研究受限于可用的训练资源，但指出了通过将碰撞点到顶点的映射编码在神经网络中来避免在复杂磁场中进行轨迹拟合的直接方法的一个有趣可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning techniques, including Graph Neural Networks (GNNs), havebeen used extensively for data analysis in high energy and nuclear physics.Here we report on the use of a GNN to reconstruct decay vertices of $\Lambda$hyperons directly from hits in the tracking detector at the CLAS12 experimentat Jefferson Laboratory (JLab). We show that we can improve the vertexreconstruction in simulation compared to the standard, track based, algorithm.We believe this warrants further study. The current study is limited byavailable training resources but points to an interesting possibility to forgovertex reconstruction by track fitting in a complicated magnetic field for amore direct approach where the hit to vertex mapping is encoded in a neuralnetwork.</description>
      <author>example@mail.com (Keegan Menkce, Matthew McEneaney, Anselm Vossen)</author>
      <guid isPermaLink="false">2507.01868v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
  <item>
      <title>ParaStudent: Generating and Evaluating Realistic Student Code by Teaching LLMs to Struggle</title>
      <link>http://arxiv.org/abs/2507.12674v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究基于大型语言模型（LLMs）的“学生式”代码生成，旨在通过系统性的实验评估LLMs在编程任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在编程任务上表现出色，但它们能否生成像真实学生一样的不完美、迭代且风格多样的代码尚不明确。&lt;h4&gt;目的&lt;/h4&gt;研究LLMs在编程课程中生成类似学生风格的代码的能力。&lt;h4&gt;方法&lt;/h4&gt;利用多学期学生提交的带时间戳的数据集，设计了低分辨率和高分辨率实验来模拟学生进度并从语义、功能和风格维度评估代码输出。&lt;h4&gt;主要发现&lt;/h4&gt;微调显著提高了与真实学生轨迹的对齐度，并更忠实地捕捉了错误模式、渐进式改进和风格变化。&lt;h4&gt;结论&lt;/h4&gt;建模真实学生代码需要通过上下文感知生成、时间建模和多维度评估来捕捉学习动态。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了基于大型语言模型（LLMs）的“学生式”代码生成，旨在通过系统性的实验评估LLMs在编程任务中的表现。研究背景是LLMs在编程任务上表现出色，但它们能否生成像真实学生一样的不完美、迭代且风格多样的代码尚不明确。研究目的是研究LLMs在编程课程中生成类似学生风格的代码的能力。研究方法是通过利用多学期学生提交的带时间戳的数据集，设计了低分辨率和高分辨率实验来模拟学生进度并从语义、功能和风格维度评估代码输出。主要发现是微调显著提高了与真实学生轨迹的对齐度，并更忠实地捕捉了错误模式、渐进式改进和风格变化。结论是建模真实学生代码需要通过上下文感知生成、时间建模和多维度评估来捕捉学习动态。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have shown strong performance on programmingtasks, but can they generate student-like code like real students - imperfect,iterative, and stylistically diverse? We present ParaStudent, a systematicstudy of LLM-based "student-like" code generation in an introductoryprogramming course setting. Using a dataset of timestamped student submissionsacross multiple semesters, we design low- and high-resolution experiments tomodel student progress and evaluate code outputs along semantic, functional,and stylistic dimensions. Our results show that fine-tuning significantlyimproves alignment with real student trajectories and captures error patterns,incremental improvements, and stylistic variations more faithfully. This studyshows that modeling realistic student code requires capturing learning dynamicsthrough context-aware generation, temporal modeling, and multi-dimensionalevaluation. Code for experiments and evaluation is available athttps://github.com/mmiroyan/ParaStudent.</description>
      <author>example@mail.com (Mihran Miroyan, Rose Niousha, Joseph E. Gonzalez, Gireeja Ranade, Narges Norouzi)</author>
      <guid isPermaLink="false">2507.12674v2</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox</title>
      <link>http://arxiv.org/abs/2507.16413v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE International Conference on Intelligent Rail Transportation  (ICIRT) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，对自动列车运行的兴趣显著增加，但铁路行业缺乏公开的标注数据集，这使得测试和验证新的感知解决方案变得困难。&lt;h4&gt;背景&lt;/h4&gt;自动列车运行技术需要鲁棒的基于视觉的算法来感知和理解周围环境，而铁路行业缺乏可用于测试和验证这些算法的公开数据集。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，研究引入了SynDRA-BBox，一个用于支持在现实铁路场景中执行对象检测和其他视觉任务的合成数据集。&lt;h4&gt;方法&lt;/h4&gt;SynDRA-BBox是专门为铁路领域的2D和3D对象检测设计的第一个合成数据集，公开可在https://syndra.retis.santannapisa.it获取。在评估中，一种最初为汽车感知开发的最先进半监督域适应方法被调整用于铁路环境，以实现合成数据在3D对象检测中的可迁移性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，合成数据集和域适应技术在提高铁路环境感知能力方面具有显著效果。&lt;h4&gt;结论&lt;/h4&gt;SynDRA-BBox合成数据集和域适应技术有望推动铁路环境感知能力的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, interest in automatic train operations has significantlyincreased. To enable advanced functionalities, robust vision-based algorithmsare essential for perceiving and understanding the surrounding environment.However, the railway sector suffers from a lack of publicly availablereal-world annotated datasets, making it challenging to test and validate newperception solutions in this domain. To address this gap, we introduceSynDRA-BBox, a synthetic dataset designed to support object detection and othervision-based tasks in realistic railway scenarios. To the best of ourknowledge, is the first synthetic dataset specifically tailored for 2D and 3Dobject detection in the railway domain, the dataset is publicly available athttps://syndra.retis.santannapisa.it. In the presented evaluation, astate-of-the-art semi-supervised domain adaptation method, originally developedfor automotive perception, is adapted to the railway context, enabling thetransferability of synthetic data to 3D object detection. Experimental resultsdemonstrate promising performance, highlighting the effectiveness of syntheticdatasets and domain adaptation techniques in advancing perception capabilitiesfor railway environments.</description>
      <author>example@mail.com (Xavier Diaz, Gianluca D'Amico, Raul Dominguez-Sanchez, Federico Nesti, Max Ronecker, Giorgio Buttazzo)</author>
      <guid isPermaLink="false">2507.16413v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning</title>
      <link>http://arxiv.org/abs/2507.16802v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Agentar-Fin-R1系列金融大型语言模型在金融领域展现出巨大潜力，通过增强推理能力、可靠性和领域专业化，实现了在金融任务上的突破性表现。&lt;h4&gt;背景&lt;/h4&gt;现有的大型语言模型在需要强大推理能力、严格可靠性和高效适应特定需求的情况下表现不足。&lt;h4&gt;目的&lt;/h4&gt;开发一种针对金融应用的金融大型语言模型，以增强推理能力、可靠性和领域专业化。&lt;h4&gt;方法&lt;/h4&gt;模型基于Qwen3基础模型构建，采用高质量的金融任务分类和多层次的可信度保障框架，包括可信知识工程、多智能体可信数据合成和严格的数据验证治理。通过标签引导的自动化难度感知优化、两阶段学习过程和详细的归因系统来提高训练效率。&lt;h4&gt;主要发现&lt;/h4&gt;Agentar-Fin-R1在主流金融基准测试和通用推理数据集上均取得了最先进的性能，并通过创新的Finova评估基准测试了其现实部署能力。&lt;h4&gt;结论&lt;/h4&gt;Agentar-Fin-R1不仅在金融任务上达到了最先进的性能，而且表现出卓越的通用推理能力，验证了其在高风险金融应用中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型语言模型（LLMs）在金融领域展现出巨大的潜力，然而现有的模型在需要强大推理能力、严格可靠性要求以及高效适应特定任务需求的情况下往往表现不足。我们介绍了Agentar-Fin-R1系列金融大型语言模型（8B和32B参数），该系列模型基于Qwen3基础模型构建，旨在增强金融应用的推理能力、可靠性和领域专业化。我们的优化方法结合了高质量、系统的金融任务分类和全面的多层可信度保障框架。该框架包括高质量的可信知识工程、多智能体可信数据合成和严格的数据验证治理。通过标签引导的自动化难度感知优化、两阶段学习过程和详细的归因系统，我们实现了训练效率的显著提升。我们的模型在包括FinEva、FinEval和FinanceIQ在内的主流金融基准测试以及MATH-500和GPQA等通用推理数据集上进行了全面评估。为了彻底评估现实部署能力，我们创新性地提出了Finova评估基准，该基准重点关注智能体层面的金融推理和合规性验证。实验结果表明，Agentar-Fin-R1不仅在金融任务上实现了最先进的性能，而且展现出卓越的通用推理能力，验证了其在高风险金融应用中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) demonstrate tremendous potential in thefinancial domain, yet existing models often fall short in scenarios demandingrobust reasoning capabilities, stringent trustworthiness requirements, andefficient adaptation to task-specific needs. We introduce the Agentar-Fin-R1series of financial large language models (8B and 32B parameters), specificallyengineered based on the Qwen3 foundation model to enhance reasoningcapabilities, reliability, and domain specialization for financialapplications. Our optimization approach integrates a high-quality, systematicfinancial task taxonomy with a comprehensive multi-layered trustworthinessassurance framework. This framework encompasses high-quality trustworthyknowledge engineering, multi-agent trustworthy data synthesis, and rigorousdata validation governance. Through label-guided automated difficulty-awareoptimization, tow-stage learning processes, and detailed attribution systems,we achieve substantial improvements in training efficiency. Our models undergocomprehensive evaluation on mainstream financial benchmarks including FinEva,FinEval, and FinanceIQ, as well as general reasoning datasets such as MATH-500and GPQA. To thoroughly assess real-world deployment capabilities, weinnovatively propose the Finova evaluation benchmark, which focuses onagent-level financial reasoning and compliance verification. Experimentalresults demonstrate that Agentar-Fin-R1 not only achieves state-of-the-artperformance on financial tasks but also exhibits exceptional general reasoningcapabilities, validating its effectiveness as a trustworthy solution forhigh-stakes financial applications.</description>
      <author>example@mail.com (Yanjun Zheng, Xiyang Du, Longfei Liao, Xiaoke Zhao, Zhaowen Zhou, Bo Zhang, Jiawei Liu, Xiang Qi, Zhe Li, Zhiqiang Zhang, Wang Wei, Peng Zhang)</author>
      <guid isPermaLink="false">2507.16802v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>The Sweet Danger of Sugar: Debunking Representation Learning for Encrypted Traffic Classification</title>
      <link>http://arxiv.org/abs/2507.16438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted at ACM SIGCOMM 2025. It will appear in  the proceedings with DOI 10.1145/3718958.3750498&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于BERT等语言模型的表示学习模型在加密流量分类中的应用进行了批判性评估，并提出了Pcap-Encoder模型，同时强调了数据准备和模型训练的重要性。&lt;h4&gt;背景&lt;/h4&gt;近年来，受BERT等语言模型启发的表示学习模型在加密流量分类中表现出色，但实际应用中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过分析，揭示这些模型成功背后的数据准备问题，并提出改进的方法。&lt;h4&gt;方法&lt;/h4&gt;通过对现有模型进行广泛分析，并引入Pcap-Encoder模型，评估其在实际场景中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;现有模型的成功很大程度上依赖于数据准备问题，这些模型在微调过程中找到了易于实现的捷径，导致其性能被不切实际地提升。Pcap-Encoder提供了有效的流量分类表示，但其复杂性限制了其实际应用。&lt;h4&gt;结论&lt;/h4&gt;数据准备和模型训练存在问题，需要改进测试设计，并提出正确的评估方法和严格的基准测试。&lt;h4&gt;翻译&lt;/h4&gt;最近，我们见证了受BERT等语言模型启发的表示学习模型在创建流量表示方面的爆炸式增长。所有这些模型都承诺在加密流量分类中表现出惊人的性能（高达98%的准确率）。在本文中，以网络专家的心态，我们对其性能进行了批判性评估。通过广泛的分析，我们证明了所报告的成功在很大程度上受到数据准备问题的影响，这些问题使得这些模型在微调期间找到了容易的捷径——特征与标签之间的虚假相关性——从而不切实际地提高了它们的性能。当这些捷径不存在时——正如现实场景中——这些模型的表现很差。我们还引入了Pcap-Encoder，这是一个基于LM的表示学习模型，我们专门设计它来从协议头部提取特征。Pcap-Encoder似乎是唯一提供流量分类工具性表示的模型。然而，它的复杂性对其在实际环境中的应用提出了质疑。我们的发现揭示了数据准备和模型训练中的缺陷，呼吁更好的、更有意识的测试设计。我们提出了正确的评估方法，并强调了严格基准测试的需要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3718958.3750498&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently we have witnessed the explosion of proposals that, inspired byLanguage Models like BERT, exploit Representation Learning models to createtraffic representations. All of them promise astonishing performance inencrypted traffic classification (up to 98% accuracy). In this paper, with anetworking expert mindset, we critically reassess their performance. Throughextensive analysis, we demonstrate that the reported successes are heavilyinfluenced by data preparation problems, which allow these models to find easyshortcuts - spurious correlation between features and labels - duringfine-tuning that unrealistically boost their performance. When such shortcutsare not present - as in real scenarios - these models perform poorly. We alsointroduce Pcap-Encoder, an LM-based representation learning model that wespecifically design to extract features from protocol headers. Pcap-Encoderappears to be the only model that provides an instrumental representation fortraffic classification. Yet, its complexity questions its applicability inpractical settings. Our findings reveal flaws in dataset preparation and modeltraining, calling for a better and more conscious test design. We propose acorrect evaluation methodology and stress the need for rigorous benchmarking.</description>
      <author>example@mail.com (Yuqi Zhao, Giovanni Dettori, Matteo Boffa, Luca Vassio, Marco Mellia)</author>
      <guid isPermaLink="false">2507.16438v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Denoising-While-Completing Network (DWCNet): Robust Point Cloud Completion Under Corruption</title>
      <link>http://arxiv.org/abs/2507.16743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for Computers and Graphics and EG Symposium on 3D Object  Retrieval 2025 (3DOR'25)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DWCNet的完成框架，用于处理受多种同时性退化影响的严重损坏的局部点云数据，旨在解决点云补全问题。&lt;h4&gt;背景&lt;/h4&gt;点云补全对于自动驾驶、增强现实和机器人等3D计算机视觉任务至关重要，但获取干净完整的点云在现实环境中由于噪声和遮挡而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究目的是开发一种能够有效完成和去噪受多种退化影响的点云的算法。&lt;h4&gt;方法&lt;/h4&gt;提出了DWCNet框架，该框架包含一个噪声管理模块（NMM），利用对比学习和自注意力机制来抑制噪声和模型结构关系。&lt;h4&gt;主要发现&lt;/h4&gt;DWCNet在干净和损坏的、合成和真实世界的数据集上均实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的CPCCD数据集突出了当前方法在多样化损坏下的局限性，DWCNet框架为点云补全提供了一种有效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云补全是自动驾驶、增强现实和机器人等3D计算机视觉任务中的关键。然而，由于噪声和遮挡，从现实环境中获取干净和完整的点云具有挑战性。因此，大多数现有的基于合成数据训练的完成网络在处理现实世界的退化方面存在困难。在本研究中，我们解决了完成和去噪受多种同时性退化影响的严重损坏的局部点云数据的问题。为了评估鲁棒性，我们引入了损坏点云补全数据集（CPCCD），该数据集突出了当前方法在多样化损坏下的局限性。基于这些洞察，我们提出了DWCNet（去噪-同时补全网络），这是一个包含噪声管理模块（NMM）的增强型完成框架，该模块利用对比学习和自注意力来抑制噪声和模型结构关系。DWCNet在干净和损坏的、合成和真实世界的数据集上均达到了最先进的性能。数据集和代码将公开可在https://github.com/keneniwt/DWCNET-Robust-Point-Cloud-Completion-against-Corruptions上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud completion is crucial for 3D computer vision tasks in autonomousdriving, augmented reality, and robotics. However, obtaining clean and completepoint clouds from real-world environments is challenging due to noise andocclusions. Consequently, most existing completion networks -- trained onsynthetic data -- struggle with real-world degradations. In this work, wetackle the problem of completing and denoising highly corrupted partial pointclouds affected by multiple simultaneous degradations. To benchmark robustness,we introduce the Corrupted Point Cloud Completion Dataset (CPCCD), whichhighlights the limitations of current methods under diverse corruptions.Building on these insights, we propose DWCNet (Denoising-While-CompletingNetwork), a completion framework enhanced with a Noise Management Module (NMM)that leverages contrastive learning and self-attention to suppress noise andmodel structural relationships. DWCNet achieves state-of-the-art performance onboth clean and corrupted, synthetic and real-world datasets. The dataset andcode will be publicly available athttps://github.com/keneniwt/DWCNET-Robust-Point-Cloud-Completion-against-Corruptions</description>
      <author>example@mail.com (Keneni W. Tesema, Lyndon Hill, Mark W. Jones, Gary K. L. Tam)</author>
      <guid isPermaLink="false">2507.16743v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Temporally-Constrained Video Reasoning Segmentation and Automated Benchmark Construction</title>
      <link>http://arxiv.org/abs/2507.16718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了传统视频分割方法的局限性，并提出了基于推理的视频分割方法，旨在解决传统方法在处理复杂场景和动态变化的对象时的不足。&lt;h4&gt;背景&lt;/h4&gt;传统的视频分割方法局限于预定义的对象类别，无法识别词汇表外的对象，更无法处理在复杂文本查询中仅被间接提及的对象。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的视频分割方法，能够处理复杂和变化场景中的视频分割问题，特别是在手术室视频分析等场景中，需要灵活的视频分析解决方案。&lt;h4&gt;方法&lt;/h4&gt;1. 引入时间约束视频推理分割，要求模型根据包含时间推理的文本查询隐式推断目标对象何时变得上下文相关。2. 提出了一种创新的方法来自动构建时间约束视频推理分割数据集的基准。3. 提出了TCVideoRSBenchmark，这是一个包含52个样本的时间约束视频推理分割数据集，使用MVOR数据集中的视频。&lt;h4&gt;主要发现&lt;/h4&gt;时间约束视频推理分割能够有效处理动态变化的对象，并且通过自动基准构建方法提高了数据集的可扩展性。&lt;h4&gt;结论&lt;/h4&gt;时间约束视频推理分割是一种有效的视频分割方法，能够处理复杂场景中的动态对象识别问题，并通过自动化方法提高了数据集的可用性。&lt;h4&gt;翻译&lt;/h4&gt;Traditional approaches to video segmentation are confined to predefined object categories and cannot identify out-of-vocabulary objects, let alone objects that are not identified explicitly but only referred to implicitly in complex text queries. This shortcoming limits the utility for video segmentation in complex and variable scenarios, where a closed set of object categories is difficult to define and where users may not know the exact object category that will appear in the video. Such scenarios can arise in operating room video analysis, where different health systems may use different workflows and instrumentation, requiring flexible solutions for video analysis. Reasoning segmentation (RS) now offers promise towards such a solution, enabling natural language text queries as interaction for identifying object to segment. However, existing video RS formulation assume that target objects remain contextually relevant throughout entire video sequences. This assumption is inadequate for real-world scenarios in which objects of interest appear, disappear or change relevance dynamically based on temporal context, such as surgical instruments that become relevant only during specific procedural phases or anatomical structures that gain importance at particular moments during surgery. Our first contribution is the introduction of temporally-constrained video reasoning segmentation, a novel task formulation that requires models to implicitly infer when target objects become contextually relevant based on text queries that incorporate temporal reasoning. Since manual annotation of temporally-constrained video RS datasets would be expensive and limit scalability, our second contribution is an innovative automated benchmark construction method. Finally, we present TCVideoRSBenchmark, a temporally-constrained video RS dataset containing 52 samples using the videos from the MVOR dataset.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conventional approaches to video segmentation are confined to predefinedobject categories and cannot identify out-of-vocabulary objects, let aloneobjects that are not identified explicitly but only referred to implicitly incomplex text queries. This shortcoming limits the utility for videosegmentation in complex and variable scenarios, where a closed set of objectcategories is difficult to define and where users may not know the exact objectcategory that will appear in the video. Such scenarios can arise in operatingroom video analysis, where different health systems may use different workflowsand instrumentation, requiring flexible solutions for video analysis. Reasoningsegmentation (RS) now offers promise towards such a solution, enabling naturallanguage text queries as interaction for identifying object to segment.However, existing video RS formulation assume that target objects remaincontextually relevant throughout entire video sequences. This assumption isinadequate for real-world scenarios in which objects of interest appear,disappear or change relevance dynamically based on temporal context, such assurgical instruments that become relevant only during specific proceduralphases or anatomical structures that gain importance at particular momentsduring surgery. Our first contribution is the introduction oftemporally-constrained video reasoning segmentation, a novel task formulationthat requires models to implicitly infer when target objects becomecontextually relevant based on text queries that incorporate temporalreasoning. Since manual annotation of temporally-constrained video RS datasetswould be expensive and limit scalability, our second contribution is aninnovative automated benchmark construction method. Finally, we presentTCVideoRSBenchmark, a temporally-constrained video RS dataset containing 52samples using the videos from the MVOR dataset.</description>
      <author>example@mail.com (Yiqing Shen, Chenjia Li, Chenxiao Fan, Mathias Unberath)</author>
      <guid isPermaLink="false">2507.16718v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Improving U-Net Confidence on TEM Image Data with L2-Regularization, Transfer Learning, and Deep Fine-Tuning</title>
      <link>http://arxiv.org/abs/2507.16779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted into the ICCV 2025 CV4MS Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用迁移学习提高透射电子显微镜（TEM）图像中纳米级缺陷识别的自动化方法。&lt;h4&gt;背景&lt;/h4&gt;随着数据量的不断增加，开发自动化方法识别TEM图像中的纳米级缺陷变得至关重要。然而，TEM图像中的纳米级缺陷由于复杂的对比度机制和复杂的缺陷结构，其特征与常规照片中的特征相比具有更大的变化，这导致了标签数据的减少和标注错误的增加，对提高机器学习模型在TEM图像分析中的性能构成了重大障碍。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些限制，本文通过利用用于自然图像的大规模预训练模型来研究迁移学习。&lt;h4&gt;方法&lt;/h4&gt;本文通过使用预训练的编码器和L2正则化，证明了通过忽略语义复杂的特征，转而使用更简单、更可靠的线索，可以显著提高模型性能。此外，本文引入了新的评估指标，这些指标不依赖于标注的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;以UO2 TEM图像中的晶界检测作为案例研究，发现该方法使缺陷检测率提高了57%，这是一个对模型性能的稳健和全面衡量。&lt;h4&gt;结论&lt;/h4&gt;通过迁移学习和对非常深层的学习进行微调，模型的自信心才能得到实现。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着数据量的不断增长，开发自动化方法以识别透射电子显微镜（TEM）图像中的纳米级缺陷变得至关重要。然而，与常规照片中的特征相比，TEM图像中的纳米级缺陷由于复杂的对比度机制和复杂的缺陷结构，表现出更大的变化。这些挑战通常导致标签数据减少和标注错误率提高，这对提高机器学习模型在TEM图像分析中的性能构成了重大障碍。为了解决这些限制，我们通过利用用于自然图像的大规模预训练模型来研究迁移学习。我们证明了通过使用预训练的编码器和L2正则化，可以忽略语义复杂的特征，转而使用更简单、更可靠的线索，从而显著提高模型性能。然而，这种改进无法通过传统的评估指标（如F1分数）来捕捉，因为这些指标可能受到将人类标注错误作为真实情况处理的偏差。相反，我们引入了新的评估指标，这些指标不依赖于标注的准确性。以UO2 TEM图像中的晶界检测作为案例研究，我们发现我们的方法使缺陷检测率提高了57%，这是对模型性能的稳健和全面衡量。最后，我们表明，模型的自信心只有通过迁移学习和对非常深层的学习进行微调才能实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With ever-increasing data volumes, it is essential to develop automatedapproaches for identifying nanoscale defects in transmission electronmicroscopy (TEM) images. However, compared to features in conventionalphotographs, nanoscale defects in TEM images exhibit far greater variation dueto the complex contrast mechanisms and intricate defect structures. Thesechallenges often result in much less labeled data and higher rates ofannotation errors, posing significant obstacles to improving machine learningmodel performance for TEM image analysis. To address these limitations, weexamined transfer learning by leveraging large, pre-trained models used fornatural images.  We demonstrated that by using the pre-trained encoder and L2-regularization,semantically complex features are ignored in favor of simpler, more reliablecues, substantially improving the model performance. However, this improvementcannot be captured by conventional evaluation metrics such as F1-score, whichcan be skewed by human annotation errors treated as ground truth. Instead, weintroduced novel evaluation metrics that are independent of the annotationaccuracy. Using grain boundary detection in UO2 TEM images as a case study, wefound that our approach led to a 57% improvement in defect detection rate,which is a robust and holistic measure of model performance on the TEM datasetused in this work. Finally, we showed that model self-confidence is onlyachieved through transfer learning and fine-tuning of very deep layers.</description>
      <author>example@mail.com (Aiden Ochoa, Xinyuan Xu, Xing Wang)</author>
      <guid isPermaLink="false">2507.16779v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Deep Unfolding Network for Nonlinear Multi-Frequency Electrical Impedance Tomography</title>
      <link>http://arxiv.org/abs/2507.16678v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于变分网络的mfEIT成像方法，该方法结合了经典迭代重建的优势和深度学习的强大能力，通过整合图神经网络（GNN）和Proximal Regularized Gauss Newton（PRGN）框架，实现了对组织电导率的估计。&lt;h4&gt;背景&lt;/h4&gt;多频电阻抗断层扫描（mfEIT）是一种有潜力的生物医学成像技术，能够在不同频率下估计组织电导率。&lt;h4&gt;目的&lt;/h4&gt;解决在mfEIT中估计组织电导率的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于变分网络的方法，该方法将图神经网络（GNN）集成到迭代Proximal Regularized Gauss Newton（PRGN）框架中，并通过展开PRGN算法，利用非线性模型拟合的物理洞察力和GNN捕捉跨频率相关性的能力。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过保持非线性前向模型中使用的非规则三角形网格结构，能够准确重建重叠的组织分数浓度。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了一种结合深度学习和经典迭代重建的mfEIT成像新方法，该方法具有更高的准确性和可解释性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多频电阻抗断层扫描（mfEIT）代表了一种有潜力的生物医学成像技术，它能够在一系列频率上估计组织电导率。为了应对这一挑战，我们提出了一种新的变分网络，这是一种基于模型的学习范式，它战略性地结合了经典迭代重建的优势和深度学习的强大能力。这种方法将图神经网络（GNN）整合到了迭代近端正则化高斯牛顿（PRGN）框架中。通过展开PRGN算法，其中每个迭代对应一个网络层，我们利用了非线性模型拟合的物理洞察力以及GNN捕捉跨频率相关性的能力。值得注意的是，GNN架构保留了用于非线性前向模型求解的非规则三角形网格结构，从而实现了重叠组织分数浓度的准确重建。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-frequency Electrical Impedance Tomography (mfEIT) represents apromising biomedical imaging modality that enables the estimation of tissueconductivities across a range of frequencies. Addressing this challenge, wepresent a novel variational network, a model-based learning paradigm thatstrategically merges the advantages and interpretability of classical iterativereconstruction with the power of deep learning. This approach integrates graphneural networks (GNNs) within the iterative Proximal Regularized Gauss Newton(PRGN) framework. By unrolling the PRGN algorithm, where each iterationcorresponds to a network layer, we leverage the physical insights of nonlinearmodel fitting alongside the GNN's capacity to capture inter-frequencycorrelations. Notably, the GNN architecture preserves the irregular triangularmesh structure used in the solution of the nonlinear forward model, enablingaccurate reconstruction of overlapping tissue fraction concentrations.</description>
      <author>example@mail.com (Giovanni S. Alberti, Damiana Lazzaro, Serena Morigi, Luca Ratti, Matteo Santacesaria)</author>
      <guid isPermaLink="false">2507.16678v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory</title>
      <link>http://arxiv.org/abs/2507.16713v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ExpTeach的框架，用于将视觉语言模型（VLMs）与物理机器人进行关联，通过构建自生成的现实世界经验记忆来实现这一目标。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉语言模型在机器人领域被广泛采用，但将最初在互联网数据上训练的VLMs应用于多样的现实世界机器人仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个框架，将VLMs与物理机器人关联，并使其能够进行自主规划、验证结果、反思失败和适应机器人行为。&lt;h4&gt;方法&lt;/h4&gt;ExpTeach通过自动规划动作、验证结果、反思失败和适应机器人行为的方式，在闭环中处理自生成的经验，并将这些经验总结为长期记忆，通过检索增强生成（RAG）来指导未来的任务。此外，ExpTeach还通过按需图像注释模块增强了VLMs的空间理解。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，反思将四个具有挑战性的机器人任务的成功率从36%提高到84%，并观察到智能物体交互的出现，包括创造性工具的使用。在12个现实世界场景（包括8个未见过的场景）的广泛测试中，使用长期记忆进行关联将单次尝试的成功率从22%提高到80%，证明了ExpTeach的有效性和通用性。&lt;h4&gt;结论&lt;/h4&gt;ExpTeach框架通过增强VLMs与物理机器人的关联，显著提高了机器人任务的成功率，并展示了其在现实世界场景中的有效性和通用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models (VLMs) have been widely adopted in robotics to enableautonomous planning. However, grounding VLMs, originally trained on internetdata, to diverse real-world robots remains a challenge. This paper presentsExpTeach, a framework that grounds VLMs to physical robots by building aself-generated memory of real-world experiences. In ExpTeach, the VLMautonomously plans actions, verifies outcomes, reflects on failures, and adaptsrobot behaviors in a closed loop. The self-generated experiences during thisprocess are then summarized into a long-term memory, enabling retrieval oflearned knowledge to guide future tasks via retrieval-augmented generation(RAG). Additionally, ExpTeach enhances the spatial understanding of VLMs withan on-demand image annotation module. In experiments, we show that reflectionimproves success rates from 36% to 84% on four challenging robotic tasks andobserve the emergence of intelligent object interactions, including creativetool use. Across extensive tests on 12 real-world scenarios (including eightunseen ones), we find that grounding with long-term memory boosts single-trialsuccess rates from 22% to 80%, demonstrating the effectiveness andgeneralizability of ExpTeach.</description>
      <author>example@mail.com (Guowei Lan, Kaixian Qu, René Zurbrügg, Changan Chen, Christopher E. Mower, Haitham Bou-Ammar, Marco Hutter)</author>
      <guid isPermaLink="false">2507.16713v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>CMP: A Composable Meta Prompt for SAM-Based Cross-Domain Few-Shot Segmentation</title>
      <link>http://arxiv.org/abs/2507.16753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Composable Meta-Prompt (CMP)的框架，用于解决跨域少量样本分割（CD-FSS）问题，通过三个关键模块实现语义扩展、元提示自动合成和域差异缓解，在四个跨域数据集上取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;CD-FSS由于数据有限和域偏移而具有挑战性，而现有的SegmentAnything Model (SAM)在一般分割任务中表现出零样本泛化能力，但在CD-FSS中存在依赖手动提示和跨域能力有限的问题。&lt;h4&gt;目的&lt;/h4&gt;提出CMP框架以解决SAM在CD-FSS中的局限性，实现自动化的跨域少量样本分割。&lt;h4&gt;方法&lt;/h4&gt;CMP框架包括三个关键模块：(i) 参考补充和转换（RCT）模块用于语义扩展；(ii) 可组合元提示生成（CMPG）模块用于自动化元提示合成；(iii) 频率感知交互（FAI）模块用于缓解域差异。&lt;h4&gt;主要发现&lt;/h4&gt;CMP在四个跨域数据集上实现了最先进的性能，在1样本和5样本场景下分别达到了71.8%和74.5%的mIoU。&lt;h4&gt;结论&lt;/h4&gt;CMP框架有效地解决了SAM在CD-FSS中的问题，为跨域少量样本分割提供了一种新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-Domain Few-Shot Segmentation (CD-FSS) remains challenging due tolimited data and domain shifts. Recent foundation models like the SegmentAnything Model (SAM) have shown remarkable zero-shot generalization capabilityin general segmentation tasks, making it a promising solution for few-shotscenarios. However, adapting SAM to CD-FSS faces two critical challenges:reliance on manual prompt and limited cross-domain ability. Therefore, wepropose the Composable Meta-Prompt (CMP) framework that introduces three keymodules: (i) the Reference Complement and Transformation (RCT) module forsemantic expansion, (ii) the Composable Meta-Prompt Generation (CMPG) modulefor automated meta-prompt synthesis, and (iii) the Frequency-Aware Interaction(FAI) module for domain discrepancy mitigation. Evaluations across fourcross-domain datasets demonstrate CMP's state-of-the-art performance, achieving71.8\% and 74.5\% mIoU in 1-shot and 5-shot scenarios respectively.</description>
      <author>example@mail.com (Shuai Chen, Fanman Meng, Chunjin Yang, Haoran Wei, Chenhao Wu, Qingbo Wu, Hongliang Li)</author>
      <guid isPermaLink="false">2507.16753v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Quality Text, Robust Vision: The Role of Language in Enhancing Visual Robustness of Vision-Language Models</title>
      <link>http://arxiv.org/abs/2507.16257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACMMM 2025 Accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对预训练视觉语言模型（VLMs）如CLIP的对抗攻击防御问题进行研究，提出了质量文本引导的对抗微调（QT-AFT）方法，旨在提升视觉模型的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;预训练视觉语言模型在零样本任务中应用广泛，如图像分类。现有对抗训练方法在增强视觉鲁棒性方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;提出QT-AFT方法，利用高质量描述来引导对抗示例，从而提高视觉编码器在对抗噪声下的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;QT-AFT方法利用高质量描述来避免过拟合，并克服了传统对抗训练方法的不足。&lt;h4&gt;主要发现&lt;/h4&gt;QT-AFT方法在16个零样本数据集上实现了最先进的零样本对抗鲁棒性和清洁准确率，揭示了语言在增强视觉鲁棒性中的关键作用。&lt;h4&gt;结论&lt;/h4&gt;QT-AFT方法为未来工作提供了方向，即在高质量语言监督下进行鲁棒的视觉表示学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Defending pre-trained vision-language models (VLMs), such as CLIP, againstadversarial attacks is crucial, as these models are widely used in diversezero-shot tasks, including image classification. However, existing adversarialtraining (AT) methods for robust fine-tuning largely overlook the role oflanguage in enhancing visual robustness. Specifically, (1) supervised ATmethods rely on short texts (e.g., class labels) to generate adversarialperturbations, leading to overfitting to object classes in the training data,and (2) unsupervised AT avoids this overfitting but remains suboptimal againstpractical text-guided adversarial attacks due to its lack of semantic guidance.To address these limitations, we propose Quality Text-guided AdversarialFine-Tuning (QT-AFT), which leverages high-quality captions during training toguide adversarial examples away from diverse semantics present in images. Thisenables the visual encoder to robustly recognize a broader range of imagefeatures even under adversarial noise, thereby enhancing robustness acrossdiverse downstream tasks. QT-AFT overcomes the key weaknesses of prior methods-- overfitting in supervised AT and lack of semantic awareness in unsupervisedAT -- achieving state-of-the-art zero-shot adversarial robustness and cleanaccuracy, evaluated across 16 zero-shot datasets. Furthermore, ourcomprehensive study uncovers several key insights into the role of language inenhancing vision robustness; for example, describing object properties inaddition to object names further enhances zero-shot robustness. Our findingspoint to an urgent direction for future work -- centering high-qualitylinguistic supervision in robust visual representation learning.</description>
      <author>example@mail.com (Futa Waseda, Saku Sugawara, Isao Echizen)</author>
      <guid isPermaLink="false">2507.16257v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Explicit Context Reasoning with Supervision for Visual Tracking</title>
      <link>http://arxiv.org/abs/2507.16191v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RSTrack的视觉跟踪算法，通过三种核心机制来显式建模和监督上下文推理，以增强跨帧建模的时间一致性。&lt;h4&gt;背景&lt;/h4&gt;主流跟踪算法通常通过简单堆叠历史信息来关联上下文，但没有显式监督关联过程，这使得难以有效建模目标的动态变化。&lt;h4&gt;目的&lt;/h4&gt;提出RSTrack算法以解决上述问题，提高视觉跟踪的时序一致性。&lt;h4&gt;方法&lt;/h4&gt;RSTrack采用三种机制：1) 构建目标状态推理管道；2) 利用真实目标特征作为锚点进行前向监督；3) 采用压缩-重建机制进行高效状态建模。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，RSTrack在多个基准数据集上实现了最先进的性能，同时保持了实时运行速度。&lt;h4&gt;结论&lt;/h4&gt;RSTrack有效地解决了传统时序建模中上下文关联发散的问题，为视觉跟踪提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Contextual reasoning with constraints is crucial for enhancing temporal consistency in cross-frame modeling for visual tracking. However, mainstream tracking algorithms typically associate context by merely stacking historical information without explicitly supervising the association process, making it difficult to effectively model the target's evolving dynamics. To alleviate this problem, we propose RSTrack, which explicitly models and supervises context reasoning via three core mechanisms. 1) Context Reasoning Mechanism: Constructs a target state reasoning pipeline, converting unconstrained contextual associations into a temporal reasoning process that predicts the current representation based on historical target states, thereby enhancing temporal consistency. 2) Forward Supervision Strategy: Utilizes true target features as anchors to constrain the reasoning pipeline, guiding the predicted output toward the true target distribution and suppressing drift in the context reasoning process. 3) Efficient State Modeling: Employs a compression-reconstruction mechanism to extract the core features of the target, removing redundant information across frames and preventing ineffective contextual associations. These three mechanisms collaborate to effectively alleviate the issue of contextual association divergence in traditional temporal modeling. Experimental results show that RSTrack achieves state-of-the-art performance on multiple benchmark datasets while maintaining real-time running speeds. Our code is available at https://github.com/GXNU-ZhongLab/RSTrack.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contextual reasoning with constraints is crucial for enhancing temporalconsistency in cross-frame modeling for visual tracking. However, mainstreamtracking algorithms typically associate context by merely stacking historicalinformation without explicitly supervising the association process, making itdifficult to effectively model the target's evolving dynamics. To alleviatethis problem, we propose RSTrack, which explicitly models and supervisescontext reasoning via three core mechanisms. \textit{1) Context ReasoningMechanism}: Constructs a target state reasoning pipeline, convertingunconstrained contextual associations into a temporal reasoning process thatpredicts the current representation based on historical target states, therebyenhancing temporal consistency. \textit{2) Forward Supervision Strategy}:Utilizes true target features as anchors to constrain the reasoning pipeline,guiding the predicted output toward the true target distribution andsuppressing drift in the context reasoning process. \textit{3) Efficient StateModeling}: Employs a compression-reconstruction mechanism to extract the corefeatures of the target, removing redundant information across frames andpreventing ineffective contextual associations. These three mechanismscollaborate to effectively alleviate the issue of contextual associationdivergence in traditional temporal modeling. Experimental results show thatRSTrack achieves state-of-the-art performance on multiple benchmark datasetswhile maintaining real-time running speeds. Our code is available athttps://github.com/GXNU-ZhongLab/RSTrack.</description>
      <author>example@mail.com (Fansheng Zeng, Bineng Zhong, Haiying Xia, Yufei Tan, Xiantao Hu, Liangtao Shi, Shuxiang Song)</author>
      <guid isPermaLink="false">2507.16191v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>An empirical study for the early detection of Mpox from skin lesion images using pretrained CNN models leveraging XAI technique</title>
      <link>http://arxiv.org/abs/2507.15915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究评估了预训练的CNN模型在猴痘早期检测中的应用效果，并探讨了XAI技术在模型可解释性方面的价值。&lt;h4&gt;背景&lt;/h4&gt;猴痘是一种由猴痘病毒引起的动物源性疾病，其与其它皮肤条件相似，使得早期诊断具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究旨在评估预训练CNN模型（VGG16、VGG19、InceptionV3、MobileNetV2）在二元和多类数据集上早期检测猴痘的有效性，并利用Grad-CAM增强模型的可解释性。&lt;h4&gt;方法&lt;/h4&gt;使用MSLD和MSLD v2.0两个数据集进行训练和验证。通过迁移学习技术微调预训练的CNN模型，冻结初始层并添加自定义层以适应猴痘检测任务，避免过拟合。使用准确率、精确率、召回率、F1分数和ROC等指标评估模型性能。Grad-CAM用于可视化关键特征。&lt;h4&gt;主要发现&lt;/h4&gt;InceptionV3在二元数据集上表现最佳，准确率为95%；MobileNetV2在多类数据集上表现最佳，准确率为93%。Grad-CAM成功突出了关键图像区域。尽管准确率高，但一些模型显示出过拟合趋势，训练和验证损失之间的差异证明了这一点。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了预训练CNN模型在猴痘检测中的潜力以及XAI技术的价值。未来的工作应解决数据集的限制，整合多模态数据，并探索额外的可解释性技术以提高诊断可靠性和模型透明度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Context: Mpox is a zoonotic disease caused by the Mpox virus, which sharessimilarities with other skin conditions, making accurate early diagnosischallenging. Artificial intelligence (AI), especially Deep Learning (DL), has astrong tool for medical image analysis; however, pre-trained models like CNNsand XAI techniques for mpox detection is underexplored. Objective: This studyaims to evaluate the effectiveness of pre-trained CNN models (VGG16, VGG19,InceptionV3, MobileNetV2) for the early detection of monkeypox using binary andmulti-class datasets. It also seeks to enhance model interpretability usingGrad-CAM an XAI technique. Method: Two datasets, MSLD and MSLD v2.0, were usedfor training and validation. Transfer learning techniques were applied tofine-tune pre-trained CNN models by freezing initial layers and adding customlayers for adapting the final features for mpox detection task and avoidoverfitting. Models performance were evaluated using metrics such as accuracy,precision, recall, F1-score and ROC. Grad-CAM was utilized for visualizingcritical features. Results: InceptionV3 demonstrated the best performance onthe binary dataset with an accuracy of 95%, while MobileNetV2 outperformed onthe multi-class dataset with an accuracy of 93%. Grad-CAM successfullyhighlighted key image regions. Despite high accuracy, some models showedoverfitting tendencies, as videnced by discrepancies between training andvalidation losses. Conclusion: This study underscores the potential ofpre-trained CNN models in monkeypox detection and the value of XAI techniques.Future work should address dataset limitations, incorporate multimodal data,and explore additional interpretability techniques to improve diagnosticreliability and model transparency</description>
      <author>example@mail.com (Mohammad Asifur Rahim, Muhammad Nazmul Arefin, Md. Mizanur Rahman, Md Ali Hossain, Ahmed Moustafa)</author>
      <guid isPermaLink="false">2507.15915v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>DFR: A Decompose-Fuse-Reconstruct Framework for Multi-Modal Few-Shot Segmentation</title>
      <link>http://arxiv.org/abs/2507.16736v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了DFR（分解、融合和重建）框架，该框架解决了几次分割（FSS）中有效利用多模态引导的根本挑战。&lt;h4&gt;背景&lt;/h4&gt;现有的方法主要依赖于视觉支持样本或文本描述，它们的单模态或双模态范式限制了在现实场景中利用丰富的感知信息。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一限制，提出的方法利用Segment Anything Model（SAM）系统地整合视觉、文本和音频模态以增强语义理解。&lt;h4&gt;方法&lt;/h4&gt;DFR框架引入了三个关键创新：1）多模态分解：一种分层分解方案，通过SAM提取视觉区域提案，将文本语义扩展到细粒度描述符，并处理音频特征以进行上下文丰富；2）多模态对比融合：一种融合策略，采用对比学习来保持视觉、文本和音频模态之间的一致性，同时允许前景和背景特征之间的动态语义交互；3）双路径重建：一种自适应集成机制，结合来自三模态融合标记的语义引导和多模态位置先验的几何线索。&lt;h4&gt;主要发现&lt;/h4&gt;在视觉、文本和音频模态下，无论是在合成还是真实设置中，广泛的实验表明DFR在性能上显著优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;DFR框架在多模态引导的几次分割任务中取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents DFR (Decompose, Fuse and Reconstruct), a novel frameworkthat addresses the fundamental challenge of effectively utilizing multi-modalguidance in few-shot segmentation (FSS). While existing approaches primarilyrely on visual support samples or textual descriptions, their single ordual-modal paradigms limit exploitation of rich perceptual informationavailable in real-world scenarios. To overcome this limitation, the proposedapproach leverages the Segment Anything Model (SAM) to systematically integratevisual, textual, and audio modalities for enhanced semantic understanding. TheDFR framework introduces three key innovations: 1) Multi-modal Decompose: ahierarchical decomposition scheme that extracts visual region proposals viaSAM, expands textual semantics into fine-grained descriptors, and processesaudio features for contextual enrichment; 2) Multi-modal Contrastive Fuse: afusion strategy employing contrastive learning to maintain consistency acrossvisual, textual, and audio modalities while enabling dynamic semanticinteractions between foreground and background features; 3) Dual-pathReconstruct: an adaptive integration mechanism combining semantic guidance fromtri-modal fused tokens with geometric cues from multi-modal location priors.Extensive experiments across visual, textual, and audio modalities under bothsynthetic and real settings demonstrate DFR's substantial performanceimprovements over state-of-the-art methods.</description>
      <author>example@mail.com (Shuai Chen, Fanman Meng, Xiwei Zhang, Haoran Wei, Chenhao Wu, Qingbo Wu, Hongliang Li)</author>
      <guid isPermaLink="false">2507.16736v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Comparative validation of surgical phase recognition, instrument keypoint estimation, and instrument instance segmentation in endoscopy: Results of the PhaKIR 2024 challenge</title>
      <link>http://arxiv.org/abs/2507.16559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A challenge report pre-print containing 36 pages, 15 figures, and 13  tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于手术器械在腔镜视频记录中可靠识别和定位的方法，旨在提高计算机和机器人辅助微创手术（RAMIS）中的手术训练、技能评估和自主辅助的效率。&lt;h4&gt;背景&lt;/h4&gt;在现实条件下的稳健性能是一个重大挑战，而结合手术背景，如当前手术阶段，被认为是提高鲁棒性和可解释性的有希望策略。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，作者组织了Surgical Procedure Phase, Keypoint, and Instrument Recognition (PhaKIR)子挑战，作为MICCAI 2024年腔镜视觉（EndoVis）挑战的一部分。&lt;h4&gt;方法&lt;/h4&gt;作者引入了一个新的多中心数据集，包含来自三个不同医疗机构的十三段完整腹腔镜胆囊切除术视频，对三个相互关联的任务进行了统一标注：手术阶段识别、器械关键点估计和器械实例分割。&lt;h4&gt;主要发现&lt;/h4&gt;与现有数据集不同，该数据集允许在同一数据中联合研究器械定位和手术背景，同时支持在整个手术过程中整合时间信息。&lt;h4&gt;结论&lt;/h4&gt;PhaKIR子挑战通过提供一个独特的基准，推动了RAMIS中时间感知、以上下文驱动的开发方法，并为支持未来手术场景理解的研究提供了高质量的资源。&lt;h4&gt;翻译&lt;/h4&gt;可靠识别和定位手术器械在腔镜视频记录中对于计算机和机器人辅助微创手术（RAMIS）的广泛应用（包括手术训练、技能评估和自主辅助）是基础性的。然而，在现实条件下的稳健性能仍然是一个重大挑战。结合手术背景（如当前手术阶段）已被证明是一种提高鲁棒性和可解释性的有希望策略。为了应对这些挑战，我们将Surgical Procedure Phase, Keypoint, and Instrument Recognition (PhaKIR)子挑战作为MICCAI 2024年腔镜视觉（EndoVis）挑战的一部分。我们引入了一个新的多中心数据集，包含来自三个不同医疗机构的十三段完整腹腔镜胆囊切除术视频，对三个相互关联的任务进行了统一标注：手术阶段识别、器械关键点估计和器械实例分割。与现有数据集不同，我们的数据集允许在同一数据中联合研究器械定位和手术背景，同时支持在整个手术过程中整合时间信息。我们按照BIAS指南报告了结果和发现。PhaKIR子挑战通过提供一个独特的基准，推动了RAMIS中时间感知、以上下文驱动的开发方法，并为支持未来手术场景理解的研究提供了高质量的资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable recognition and localization of surgical instruments in endoscopicvideo recordings are foundational for a wide range of applications in computer-and robot-assisted minimally invasive surgery (RAMIS), including surgicaltraining, skill assessment, and autonomous assistance. However, robustperformance under real-world conditions remains a significant challenge.Incorporating surgical context - such as the current procedural phase - hasemerged as a promising strategy to improve robustness and interpretability.  To address these challenges, we organized the Surgical Procedure Phase,Keypoint, and Instrument Recognition (PhaKIR) sub-challenge as part of theEndoscopic Vision (EndoVis) challenge at MICCAI 2024. We introduced a novel,multi-center dataset comprising thirteen full-length laparoscopiccholecystectomy videos collected from three distinct medical institutions, withunified annotations for three interrelated tasks: surgical phase recognition,instrument keypoint estimation, and instrument instance segmentation. Unlikeexisting datasets, ours enables joint investigation of instrument localizationand procedural context within the same data while supporting the integration oftemporal information across entire procedures.  We report results and findings in accordance with the BIAS guidelines forbiomedical image analysis challenges. The PhaKIR sub-challenge advances thefield by providing a unique benchmark for developing temporally aware,context-driven methods in RAMIS and offers a high-quality resource to supportfuture research in surgical scene understanding.</description>
      <author>example@mail.com (Tobias Rueckert, David Rauber, Raphaela Maerkl, Leonard Klausmann, Suemeyye R. Yildiran, Max Gutbrod, Danilo Weber Nunes, Alvaro Fernandez Moreno, Imanol Luengo, Danail Stoyanov, Nicolas Toussaint, Enki Cho, Hyeon Bae Kim, Oh Sung Choo, Ka Young Kim, Seong Tae Kim, Gonçalo Arantes, Kehan Song, Jianjun Zhu, Junchen Xiong, Tingyi Lin, Shunsuke Kikuchi, Hiroki Matsuzaki, Atsushi Kouno, João Renato Ribeiro Manesco, João Paulo Papa, Tae-Min Choi, Tae Kyeong Jeong, Juyoun Park, Oluwatosin Alabi, Meng Wei, Tom Vercauteren, Runzhi Wu, Mengya Xu, An Wang, Long Bai, Hongliang Ren, Amine Yamlahi, Jakob Hennighausen, Lena Maier-Hein, Satoshi Kondo, Satoshi Kasai, Kousuke Hirasawa, Shu Yang, Yihui Wang, Hao Chen, Santiago Rodríguez, Nicolás Aparicio, Leonardo Manrique, Juan Camilo Lyons, Olivia Hosie, Nicolás Ayobi, Pablo Arbeláez, Yiping Li, Yasmina Al Khalil, Sahar Nasirihaghighi, Stefanie Speidel, Daniel Rueckert, Hubertus Feussner, Dirk Wilhelm, Christoph Palm)</author>
      <guid isPermaLink="false">2507.16559v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Predictability-Aware Motion Prediction for Edge XR via High-Order Error-State Kalman Filtering</title>
      <link>http://arxiv.org/abs/2507.13179v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;随着6G网络的开发和定义，XR应用的卸载成为新的重要用例之一。6G的低延迟结合边缘处理基础设施将首次在蜂窝网络中提供将计算密集型功能（包括渲染）从用户设备迁移到网络的现实卸载场景。这样做的主要优势是降低用户设备的电池需求，并有可能设计出体积更小的设备。&lt;h4&gt;背景&lt;/h4&gt;6G网络的开发中，XR应用的卸载成为新的用例，这依赖于6G的低延迟和边缘处理基础设施。&lt;h4&gt;目的&lt;/h4&gt;降低用户设备的电池需求，设计体积更小的设备，并解决卸载过程中引入的延迟问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于上下文感知的错误状态卡尔曼滤波器（ESKF）预测框架，用于预测用户的头部运动轨迹，以补偿远程XR中的运动到光子（MTP）延迟。同时，集成了一个运动分类器，根据头部运动的可预测性对头部运动进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;优化后的ESKF在位置和方向精度上超过了传统的卡尔曼滤波器，并表现出对包丢失的增强鲁棒性和弹性。&lt;h4&gt;结论&lt;/h4&gt;通过引入上下文感知的错误状态卡尔曼滤波器预测框架，可以有效地降低远程XR中的MTP延迟，提高用户体验。&lt;h4&gt;翻译&lt;/h4&gt;As 6G networks are developed and defined, offloading of XR applications is emerging as one of the strong new use cases. The reduced 6G latency coupled with edge processing infrastructure will for the first time provide a realistic offloading scenario in cellular networks where several computationally intensive functions, including rendering, can migrate from the user device and into the network. A key advantage of doing so is the lowering of the battery needs in the user devices and the possibility to design new devices with smaller form factors. However, offloading introduces increased delays compared to local execution, primarily due to network transmission latency and queuing delays at edge servers, especially under multi-user concurrency. Despite the computational power of edge platforms, the resulting motion-to-photon (MTP) latency negatively impacts user experience. To mitigate this, motion prediction has been proposed to offset delays. Existing approaches build on either deep learning or Kalman filtering. Deep learning techniques face scalability limitations at the resource-constrained edge, as their computational expense intensifies with increasing user concurrency, while Kalman filtering suffers from poor handling of complex movements and fragility to packet loss inherent in 6G's high-frequency radio interfaces. In this work, we introduce a context-aware error-state Kalman filter (ESKF) prediction framework, which forecasts the user's head motion trajectory to compensate for MTP latency in remote XR. By integrating a motion classifier that categorizes head motions based on their predictability, our algorithm demonstrates reduced prediction error across different motion classes. Our findings demonstrate that the optimized ESKF not only surpasses traditional Kalman filters in positional and orientational accuracy but also exhibits enhanced robustness and resilience to packet loss.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As 6G networks are developed and defined, offloading of XR applications isemerging as one of the strong new use cases. The reduced 6G latency coupledwith edge processing infrastructure will for the first time provide a realisticoffloading scenario in cellular networks where several computationallyintensive functions, including rendering, can migrate from the user device andinto the network. A key advantage of doing so is the lowering of the batteryneeds in the user devices and the possibility to design new devices withsmaller form factors. However, offloading introduces increased delays comparedto local execution, primarily due to network transmission latency and queuingdelays at edge servers, especially under multi-user concurrency. Despite thecomputational power of edge platforms, the resulting motion-to-photon (MTP)latency negatively impacts user experience. To mitigate this, motion predictionhas been proposed to offset delays. Existing approaches build on either deeplearning or Kalman filtering. Deep learning techniques face scalabilitylimitations at the resource-constrained edge, as their computational expenseintensifies with increasing user concurrency, while Kalman filtering suffersfrom poor handling of complex movements and fragility to packet loss inherentin 6G's high-frequency radio interfaces. In this work, we introduce acontext-aware error-state Kalman filter (ESKF) prediction framework, whichforecasts the user's head motion trajectory to compensate for MTP latency inremote XR. By integrating a motion classifier that categorizes head motionsbased on their predictability, our algorithm demonstrates reduced predictionerror across different motion classes. Our findings demonstrate that theoptimized ESKF not only surpasses traditional Kalman filters in positional andorientational accuracy but also exhibits enhanced robustness and resilience topacket loss.</description>
      <author>example@mail.com (Ziyu Zhong, Björn Landfeldt, Günter Alce, Hector A Caltenco)</author>
      <guid isPermaLink="false">2507.13179v2</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Sparse-View 3D Reconstruction: Recent Advances and Open Challenges</title>
      <link>http://arxiv.org/abs/2507.16406v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了稀疏视图3D重建的最新进展，包括基于神经隐式模型、显式点云方法和混合框架的研究。&lt;h4&gt;背景&lt;/h4&gt;稀疏视图3D重建在机器人、增强/虚拟现实和自主系统等应用中至关重要，因为这些场景下密集图像采集不切实际。&lt;h4&gt;目的&lt;/h4&gt;本文旨在分析如何通过几何正则化、显式形状建模和生成推理来减轻稀疏视图设置中的伪影和姿态模糊。&lt;h4&gt;方法&lt;/h4&gt;本文对基于几何的、基于神经隐式的和基于生成的（基于扩散的）方法进行了综合分析，并比较了标准基准上的重建精度、效率和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;研究揭示了重建精度、效率和泛化能力之间的关键权衡，并强调了在领域泛化和无姿态重建方面存在的持续挑战。&lt;h4&gt;结论&lt;/h4&gt;本文提供了一个统一视角，概述了未来开发3D原生生成先验和实现实时、无约束稀疏视图重建的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：稀疏视图3D重建对于机器人、增强/虚拟现实（AR/VR）和自主系统等应用场景至关重要，因为这些场景下密集图像采集不切实际。在这些设置中，最小图像重叠阻碍了可靠的对应匹配，导致传统的结构从运动（SfM）和多视图立体（MVS）方法失败。本文综述了基于神经隐式模型（例如NeRF及其正则化版本）、基于显式点云方法（例如3D高斯分层）和利用扩散和视觉基础模型（VFMs）先验的混合框架的最新进展。我们分析了如何使用几何正则化、显式形状建模和生成推理来减轻稀疏视图设置中的伪影和姿态模糊。在标准基准上的比较结果表明，重建精度、效率和泛化能力之间存在关键权衡。与以前的综述不同，我们的综述提供了一个基于几何、基于神经隐式和基于生成（基于扩散的）方法的统一视角。我们强调了在领域泛化和无姿态重建方面的持续挑战，并概述了开发3D原生生成先验和实现实时、无约束稀疏视图重建的未来方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sparse-view 3D reconstruction is essential for applications in which denseimage acquisition is impractical, such as robotics, augmented/virtual reality(AR/VR), and autonomous systems. In these settings, minimal image overlapprevents reliable correspondence matching, causing traditional methods, such asstructure-from-motion (SfM) and multiview stereo (MVS), to fail. This surveyreviews the latest advances in neural implicit models (e.g., NeRF and itsregularized versions), explicit point-cloud-based approaches (e.g., 3D GaussianSplatting), and hybrid frameworks that leverage priors from diffusion andvision foundation models (VFMs).We analyze how geometric regularization,explicit shape modeling, and generative inference are used to mitigateartifacts such as floaters and pose ambiguities in sparse-view settings.Comparative results on standard benchmarks reveal key trade-offs between thereconstruction accuracy, efficiency, and generalization. Unlike previousreviews, our survey provides a unified perspective on geometry-based, neuralimplicit, and generative (diffusion-based) methods. We highlight the persistentchallenges in domain generalization and pose-free reconstruction and outlinefuture directions for developing 3D-native generative priors and achievingreal-time, unconstrained sparse-view reconstruction.</description>
      <author>example@mail.com (Tanveer Younis, Zhanglin Cheng)</author>
      <guid isPermaLink="false">2507.16406v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge-aware Diffusion-Enhanced Multimedia Recommendation</title>
      <link>http://arxiv.org/abs/2507.16396v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为KDiffE的知识感知扩散增强架构，用于多媒体推荐，旨在通过对比学习范式增强历史用户-项目交互信息。&lt;h4&gt;背景&lt;/h4&gt;多媒体推荐旨在利用丰富的多媒体内容来增强历史用户-项目交互信息，不仅能够指示项目之间的内容相关性，还能揭示用户更细粒度的偏好。&lt;h4&gt;目的&lt;/h4&gt;提出KDiffE架构，用于多媒体推荐，以改进推荐系统的性能。&lt;h4&gt;方法&lt;/h4&gt;利用原始用户-项目图构建一个注意力感知矩阵，并将其集成到图神经网络中，学习用户和项目之间的重要性。采用随机游走带重启动策略来构建注意力感知矩阵，并引入一个引导扩散模型生成与任务高度相关的知识图谱，用于增强项目的语义信息。&lt;h4&gt;主要发现&lt;/h4&gt;在三个多媒体数据集上的实验表明，KDiffE及其组件在多种最先进的推荐方法上表现出了有效性。&lt;h4&gt;结论&lt;/h4&gt;KDiffE在多媒体推荐方面是有效的，并提供了源代码供进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a Knowledge-aware Diffusion-Enhanced architecture (KDiffE) using contrastive learning paradigms for multimedia recommendations, aiming to enhance historical user-item interaction information.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimedia recommendations aim to use rich multimedia content to enhancehistorical user-item interaction information, which can not only indicate thecontent relatedness among items but also reveal finer-grained preferences ofusers. In this paper, we propose a Knowledge-aware Diffusion-Enhancedarchitecture using contrastive learning paradigms (KDiffE) for multimediarecommendations. Specifically, we first utilize original user-item graphs tobuild an attention-aware matrix into graph neural networks, which can learn theimportance between users and items for main view construction. Theattention-aware matrix is constructed by adopting a random walk with a restartstrategy, which can preserve the importance between users and items to generateaggregation of attention-aware node features. Then, we propose a guideddiffusion model to generate strongly task-relevant knowledge graphs with lessnoise for constructing a knowledge-aware contrastive view, which utilizes userembeddings with an edge connected to an item to guide the generation ofstrongly task-relevant knowledge graphs for enhancing the item's semanticinformation. We perform comprehensive experiments on three multimedia datasetsthat reveal the effectiveness of our KDiffE and its components on variousstate-of-the-art methods. Our source codes are availablehttps://github.com/1453216158/KDiffE.</description>
      <author>example@mail.com (Xian Mo, Fei Liu, Rui Tang, Jintao, Gao, Hao Liu)</author>
      <guid isPermaLink="false">2507.16396v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Optimization of DNN-based HSI Segmentation FPGA-based SoC for ADS: A Practical Approach</title>
      <link>http://arxiv.org/abs/2507.16556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在自主导航中使用HSI（高光谱成像）技术的潜力，旨在提高基于视觉传感器的检测、跟踪和场景理解系统的准确性和鲁棒性。文章还讨论了将深度神经网络（DNN）等高级计算算法与小型快照HSI相机结合，以及将这些系统的工作负载转移到边缘平台的重要性。&lt;h4&gt;背景&lt;/h4&gt;HSI技术在描绘目标的物理特性，如光谱反射率和同色异谱现象方面，克服了灰度和RGB成像的固有局限性。然而，对于安全关键系统如自动驾驶系统（ADS），对延迟、资源消耗和安全性的严格要求推动了机器学习工作负载向边缘平台的迁移。&lt;h4&gt;目的&lt;/h4&gt;目的是优化基于DNN的HSI分割处理器在FPGA基于的SoC上的部署，以实现实时边缘部署。&lt;h4&gt;方法&lt;/h4&gt;研究了一系列优化技术，包括功能软件/硬件任务分配、硬件感知预处理、机器学习模型压缩和完整的流水线部署。&lt;h4&gt;主要发现&lt;/h4&gt;应用压缩技术显著降低了设计的DNN的复杂度，将原始操作复杂度降低了24.34%，参数数量降低了1.02%，在保持分割精度不下降的情况下，推理任务速度提高了2.86倍。&lt;h4&gt;结论&lt;/h4&gt;这些优化技术有助于提高HSI技术在边缘平台上的性能，对于ADS等安全关键系统具有重要的实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3748722&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The use of HSI for autonomous navigation is a promising research field aimedat improving the accuracy and robustness of detection, tracking, and sceneunderstanding systems based on vision sensors. Combining advanced computeralgorithms, such as DNNs, with small-size snapshot HSI cameras enhances thereliability of these systems. HSI overcomes intrinsic limitations of greyscaleand RGB imaging in depicting physical properties of targets, particularlyregarding spectral reflectance and metamerism. Despite promising results inHSI-based vision developments, safety-critical systems like ADS demand strictconstraints on latency, resource consumption, and security, motivating theshift of ML workloads to edge platforms. This involves a thoroughsoftware/hardware co-design scheme to distribute and optimize the tasksefficiently among the limited resources of computing platforms. With respect toinference, the over-parameterized nature of DNNs poses significantcomputational challenges for real-time on-the-edge deployment. In addition, theintensive data preprocessing required by HSI, which is frequently overlooked,must be carefully managed in terms of memory arrangement and inter-taskcommunication to enable an efficient integrated pipeline design on a SoC. Thiswork presents a set of optimization techniques for the practical co-design of aDNN-based HSI segmentation processor deployed on a FPGA-based SoC targeted atADS, including key optimizations such as functional software/hardware taskdistribution, hardware-aware preprocessing, ML model compression, and acomplete pipelined deployment. Applied compression techniques significantlyreduce the complexity of the designed DNN to 24.34% of the original operationsand to 1.02% of the original number of parameters, achieving a 2.86x speed-upin the inference task without noticeable degradation of the segmentationaccuracy.</description>
      <author>example@mail.com (Jon Gutiérrez-Zaballa, Koldo Basterretxea, Javier Echanobe)</author>
      <guid isPermaLink="false">2507.16556v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>SALM: Spatial Audio Language Model with Structured Embeddings for Understanding and Editing</title>
      <link>http://arxiv.org/abs/2507.16724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SALM的新型框架，用于处理空间音频并理解语言，通过多模态对比学习将空间音频与语言联系起来。&lt;h4&gt;背景&lt;/h4&gt;现有的音频语言模型在处理空间音频和感知空间声景方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效处理空间音频并理解语言的模型。&lt;h4&gt;方法&lt;/h4&gt;SALM包括一个文本编码器和双分支音频编码器，通过结构化音频嵌入将空间声音分解为语义和空间组件。&lt;h4&gt;主要发现&lt;/h4&gt;SALM能够无缝对齐空间和文本表示，分别和联合提取空间和语义信息，实现零样本方向分类，并支持空间音频编辑。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，SALM能够有效地捕捉和校准跨模态表示，并支持使用文本嵌入改变方向音频的高级编辑功能。&lt;h4&gt;翻译&lt;/h4&gt;空间音频理解对于准确感知和解释声学环境至关重要。然而，现有的音频语言模型在处理空间音频和感知空间声景方面存在困难。我们引入了一种名为空间音频语言模型（SALM）的新框架，该框架通过多模态对比学习将空间音频与语言联系起来。SALM由一个文本编码器和双分支音频编码器组成，通过结构化音频嵌入将空间声音分解为语义和空间组件。SALM的关键特性包括空间和文本表示的无缝对齐、空间和语义信息的分别和联合提取、零样本方向分类以及对空间音频编辑的鲁棒支持。实验结果表明，SALM能够有效地捕捉和校准跨模态表示。此外，它还支持使用文本嵌入改变方向音频的高级编辑功能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial audio understanding is essential for accurately perceiving andinterpreting acoustic environments. However, existing audio-language modelsstruggle with processing spatial audio and perceiving spatial acoustic scenes.We introduce the Spatial Audio Language Model (SALM), a novel framework thatbridges spatial audio and language via multi-modal contrastive learning. SALMconsists of a text encoder and a dual-branch audio encoder, decomposing spatialsound into semantic and spatial components through structured audio embeddings.Key features of SALM include seamless alignment of spatial and textrepresentations, separate and joint extraction of spatial and semanticinformation, zero-shot direction classification and robust support for spatialaudio editing. Experimental results demonstrate that SALM effectively capturesand aligns cross-modal representations. Furthermore, it supports advancedediting capabilities, such as altering directional audio using text-basedembeddings.</description>
      <author>example@mail.com (Jinbo Hu, Yin Cao, Ming Wu, Feiran Yang, Jun Yang)</author>
      <guid isPermaLink="false">2507.16724v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Remote Sensing Vision-Language Models Through MLLM and LLM-Based High-Quality Image-Text Dataset Generation</title>
      <link>http://arxiv.org/abs/2507.16716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SUBMIT TO IEEE TRANSACTIONS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为MpGI的多视角生成与集成方法，用于生成高质量的遥感图像文本描述，并创建了一个包含约210,000张图像和1.3百万个描述的HQRS-IT-210K数据集，提升了VLFMs在遥感图像下游任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;VLFMs在遥感图像分析中具有优势，但高质量的图像-文本配对训练数据稀缺，现有数据集因描述生成方法简单，质量欠佳，需要大量训练数据，但性能提升有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，生成高质量的文本描述，以提高遥感图像下游任务中VLFMs的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 使用Rule-MLLM和MLLMsgeneration方法从不同视角生成独特的详细描述。2. 利用大型语言模型（LLMs）将多种描述集成到全面的描述中。3. 创建了HQRS-IT-210K数据集，包含约210,000张遥感图像和1.3百万个描述。4. 使用该数据集微调了两个VLFMs：CLIP和CoCa。&lt;h4&gt;主要发现&lt;/h4&gt;生成的HQRS-CLIP模型在多个下游任务中超过了之前的SOTA RS CLIP模型，同时仅使用了4.2%的训练数据。RS-CoCa在基准数据集上优于其他高级方法，能够生成与手动标注相媲美甚至超越的遥感图像描述。&lt;h4&gt;结论&lt;/h4&gt;MpGI方法有效地提高了遥感图像描述的质量，从而提升了VLFMs在遥感图像分析任务中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The application of Vision-language foundation models (VLFMs) to remotesensing (RS) imagery has garnered significant attention due to their superiorcapability in various downstream tasks. A key challenge lies in the scarcity ofhigh-quality, large-scale, image-text paired training data. Recently, severalworks introduced extensive image-text datasets for RS and trained their VLFMs.However, due to the rudimentary methods used for generating captions, thequality of datasets is suboptimal, requiring larger volumes of training data,while only yielding modest performance improvements. In this paper, we proposea two-stage method named MpGI(Multi-Perspective Generation and Integration) forgenerating high-quality text captions for RS images. Firstly, we generatedistinct and detailed descriptions from different perspectives usingRule-MLLM(Multimodal Large Language Model) Relay Generation and MLLMsgeneration methods. Next, we utilize Large Language Models (LLMs) to integratethese diverse descriptions into comprehensive captions, capturing details frommultiple perspectives. Finally, we have created the HQRS-IT-210K dataset,including about 210,000 RS images and 1.3 million captions. We fine-tuned twoVLFMs using our dataset: CLIP, a discriminative model, and CoCa, animage-to-text generative model. This process resulted in our proposed HQRS-CLIPand RS-CoCa models. Experimental results demonstrate that HQRS-CLIP surpassedthe previous SOTA RS CLIP model in various downstream tasks while using only4.2\% of the training data. RS-CoCa outperforms other advanced approachesacross benchmark datasets and can generate captions for RS images that rival oreven exceed manual annotations. Dataset, pre-trained models, and codes will bereleased at https://github.com/YiguoHe/HQRS-210K-and-HQRS-CLIP.</description>
      <author>example@mail.com (Yiguo He, Junjie Zhu, Yiying Li, Xiaoyu Zhang, Chunping Qiu, Jun Wang, Qiangjuan Huang, Ke Yang)</author>
      <guid isPermaLink="false">2507.16716v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>SPACT18: Spiking Human Action Recognition Benchmark Dataset with Complementary RGB and Thermal Modalities</title>
      <link>http://arxiv.org/abs/2507.16151v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于脉冲摄像机的视频动作识别（VAR）数据集，结合同步的RGB和热成像模态，用于Spiking Neural Networks（SNNs）的综合基准测试。&lt;h4&gt;背景&lt;/h4&gt;脉冲摄像机通过在每个像素处累积光强度来异步产生脉冲，提供超高能量效率和卓越的时间分辨率，与记录光强度变化以捕捉运动的事件摄像机不同，脉冲摄像机提供更精细的空间时间分辨率和更精确的连续变化表示。&lt;h4&gt;目的&lt;/h4&gt;引入脉冲摄像机视频动作识别数据集，以促进高效、超低功耗的视频理解研究，特别是使用基于脉冲的数据进行动作识别任务。&lt;h4&gt;方法&lt;/h4&gt;提出使用脉冲摄像机、同步RGB和热成像模态的数据集，以探索多模态视频理解，并作为比较脉冲、热和RGB模态的有价值资源。&lt;h4&gt;主要发现&lt;/h4&gt;该研究提供了第一个使用脉冲摄像机的VAR数据集，并展示了脉冲数据在多模态视频理解中的潜力。&lt;h4&gt;结论&lt;/h4&gt;该工作为能量高效、超低功耗的视频理解研究做出了贡献，特别是对于使用脉冲数据进行动作识别任务的研究。&lt;h4&gt;翻译&lt;/h4&gt;Spike cameras, bio-inspired vision sensors, asynchronously fire spikes by accumulating light intensities at each pixel, offering ultra-high energy efficiency and exceptional temporal resolution. Unlike event cameras, which record changes in light intensity to capture motion, spike cameras provide even finer spatiotemporal resolution and a more precise representation of continuous changes. In this paper, we introduce the first video action recognition (VAR) dataset using spike camera, alongside synchronized RGB and thermal modalities, to enable comprehensive benchmarking for Spiking Neural Networks (SNNs). By preserving the inherent sparsity and temporal precision of spiking data, our three datasets offer a unique platform for exploring multimodal video understanding and serve as a valuable resource for directly comparing spiking, thermal, and RGB modalities. This work contributes a novel dataset that will drive research in energy-efficient, ultra-low-power video understanding, specifically for action recognition tasks using spike-based data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spike cameras, bio-inspired vision sensors, asynchronously fire spikes byaccumulating light intensities at each pixel, offering ultra-high energyefficiency and exceptional temporal resolution. Unlike event cameras, whichrecord changes in light intensity to capture motion, spike cameras provide evenfiner spatiotemporal resolution and a more precise representation of continuouschanges. In this paper, we introduce the first video action recognition (VAR)dataset using spike camera, alongside synchronized RGB and thermal modalities,to enable comprehensive benchmarking for Spiking Neural Networks (SNNs). Bypreserving the inherent sparsity and temporal precision of spiking data, ourthree datasets offer a unique platform for exploring multimodal videounderstanding and serve as a valuable resource for directly comparing spiking,thermal, and RGB modalities. This work contributes a novel dataset that willdrive research in energy-efficient, ultra-low-power video understanding,specifically for action recognition tasks using spike-based data.</description>
      <author>example@mail.com (Yasser Ashraf, Ahmed Sharshar, Velibor Bojkovic, Bin Gu)</author>
      <guid isPermaLink="false">2507.16151v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>LDRFusion: A LiDAR-Dominant multimodal refinement framework for 3D object detection</title>
      <link>http://arxiv.org/abs/2507.16224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LDRFusion的新型激光雷达-相机融合框架，用于多传感器融合的3D物体检测，通过两个阶段的精炼框架和层次化的伪点云残差编码模块，提高了检测结果的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的激光雷达-相机融合方法在3D物体检测中取得了良好的效果，但点云的稀疏性问题和伪点引入的噪声可能导致预测不准确。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的激光雷达主导的两阶段精炼框架，以解决上述问题，并提高检测的准确性。&lt;h4&gt;方法&lt;/h4&gt;第一阶段仅使用激光雷达生成准确定位的候选框，第二阶段引入伪点云以检测具有挑战性的实例，并将两个阶段的实例级结果合并。同时，提出了一种层次化的伪点云残差编码模块，使用特征和位置残差对邻域集进行编码。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI数据集上的实验表明，该框架在多个类别和难度级别上均取得了优异的性能。&lt;h4&gt;结论&lt;/h4&gt;LDRFusion框架能够有效提高3D物体检测的准确性，是一种有效的多传感器融合方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing LiDAR-Camera fusion methods have achieved strong results in 3Dobject detection. To address the sparsity of point clouds, previous approachestypically construct spatial pseudo point clouds via depth completion asauxiliary input and adopts a proposal-refinement framework to generatedetection results. However, introducing pseudo points inevitably brings noise,potentially resulting in inaccurate predictions. Considering the differingroles and reliability levels of each modality, we propose LDRFusion, a novelLidar-dominant two-stage refinement framework for multi-sensor fusion. Thefirst stage soley relies on LiDAR to produce accurately localized proposals,followed by a second stage where pseudo point clouds are incorporated to detectchallenging instances. The instance-level results from both stages aresubsequently merged. To further enhance the representation of local structuresin pseudo point clouds, we present a hierarchical pseudo point residualencoding module, which encodes neighborhood sets using both feature andpositional residuals. Experiments on the KITTI dataset demonstrate that ourframework consistently achieves strong performance across multiple categoriesand difficulty levels.</description>
      <author>example@mail.com (Jijun Wang, Yan Wu, Yujian Mo, Junqiao Zhao, Jun Yan, Yinghao Hu)</author>
      <guid isPermaLink="false">2507.16224v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>ApproxGNN: A Pretrained GNN for Parameter Prediction in Design Space Exploration for Approximate Computing</title>
      <link>http://arxiv.org/abs/2507.16379v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear at ICCAD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ApproxGNN的预训练图神经网络模型，用于预测近似加速器的QoR和HW成本，从而提高近似计算在容错应用中的能效。&lt;h4&gt;背景&lt;/h4&gt;近似计算在错误容忍应用中具有能效优势，但寻找最佳近似需要大量设计空间探索，且预测近似组件电路的准确性困难，现有的机器学习方法需要为每个新电路配置重新训练，导致计算成本高且耗时。&lt;h4&gt;目的&lt;/h4&gt;提出ApproxGNN，旨在自动化近似组件到加速器操作的设计空间探索任务，并提高预测近似错误准确性的效率。&lt;h4&gt;方法&lt;/h4&gt;ApproxGNN使用库中的近似加法器预测近似加速器的QoR和HW成本，通过学习嵌入而非传统误差指标进行新颖的组件特征提取，从而提高对未见电路的迁移性。模型支持少量近似组件训练，能够迁移到多个预测任务，利用预计算的嵌入提高效率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与常规方法相比，所提出的嵌入将预测精度（均方误差）提高了50%。此外，整体预测精度比未微调的统计机器学习方法高30%，微调后更高达54%。&lt;h4&gt;结论&lt;/h4&gt;ApproxGNN通过提高预测精度和效率，为近似计算中的设计空间探索提供了有效的工具，尤其是在处理未见电路时表现突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Approximate computing offers promising energy efficiency benefits forerror-tolerant applications, but discovering optimal approximations requiresextensive design space exploration (DSE). Predicting the accuracy of circuitscomposed of approximate components without performing complete synthesisremains a challenging problem. Current machine learning approaches used toautomate this task require retraining for each new circuit configuration,making them computationally expensive and time-consuming. This paper presentsApproxGNN, a construction methodology for a pre-trained graph neural networkmodel predicting QoR and HW cost of approximate accelerators employingapproximate adders from a library. This approach is applicable in DSE forassignment of approximate components to operations in accelerator. Our approachintroduces novel component feature extraction based on learned embeddingsrather than traditional error metrics, enabling improved transferability tounseen circuits. ApproxGNN models can be trained with a small number ofapproximate components, supports transfer to multiple prediction tasks,utilizes precomputed embeddings for efficiency, and significantly improvesaccuracy of the prediction of approximation error. On a set of imageconvolutional filters, our experimental results demonstrate that the proposedembeddings improve prediction accuracy (mean square error) by 50% compared toconventional methods. Furthermore, the overall prediction accuracy is 30%better than statistical machine learning approaches without fine-tuning and 54%better with fast finetuning.</description>
      <author>example@mail.com (Ondrej Vlcek, Vojtech Mrazek)</author>
      <guid isPermaLink="false">2507.16379v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>DenseSR: Image Shadow Removal as Dense Prediction</title>
      <link>http://arxiv.org/abs/2507.16472v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper accepted to ACMMM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DenseSR的单图像阴影去除方法，旨在克服传统方法在处理复杂间接光照条件下的阴影去除难题。&lt;h4&gt;背景&lt;/h4&gt;阴影是影响图像质量的一个常见因素，在单图像阴影去除过程中，特别是在复杂间接光照条件下，由于内容退化不均匀和固有的模糊性，传统方法往往无法同时恢复阴影内部的细节并保持清晰的边界。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些限制，提出了一种名为DenseSR的方法，从密集预测的角度来强调恢复质量。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了两种关键策略：(1) 通过几何-语义先验引导的深度场景理解来消除模糊性和隐式定位阴影；(2) 通过解码器中的新型密集融合块（DFB）实现高保真恢复。DFB使用自适应组件处理，包括自适应内容平滑模块（ACSM）以实现一致的外观和纹理边界恢复模块（TBRM）以实现精细纹理和清晰边界。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有方法相比，该方法具有优势。&lt;h4&gt;结论&lt;/h4&gt;DenseSR方法能够有效地解决阴影去除中的不一致恢复和模糊问题，并提供了优化的特征表示，同时保持一致性和保真度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：阴影是降低图像质量的常见因素。在具有挑战性的间接照明条件下，单图像阴影去除（SR）受到非均匀内容退化和固有模糊性的阻碍。因此，传统方法往往无法同时恢复阴影内部的细节并保持清晰的边界，导致不一致的恢复和模糊，这对下游应用和整体观看体验都有负面影响。为了克服这些限制，我们从密集预测的角度提出了一种名为DenseSR的方法，强调恢复质量。该框架独特地结合了两种关键策略：(1) 通过几何-语义先验引导的深度场景理解来消除模糊性和隐式定位阴影；(2) 通过解码器中的新型密集融合块（DFB）实现高保真恢复。DFB采用自适应组件处理，使用自适应内容平滑模块（ACSM）以实现一致的外观和纹理边界恢复模块（TBRM）以实现精细纹理和清晰边界，从而直接解决不一致的恢复和模糊问题。这些经过有意处理的组件被有效地融合，从而产生一个优化的特征表示，同时保持一致性和保真度。广泛的实验结果表明，与现有方法相比，我们的方法具有优势。我们的代码可在https://github.com/VanLinLin/DenseSR上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Shadows are a common factor degrading image quality. Single-image shadowremoval (SR), particularly under challenging indirect illumination, is hamperedby non-uniform content degradation and inherent ambiguity. Consequently,traditional methods often fail to simultaneously recover intra-shadow detailsand maintain sharp boundaries, resulting in inconsistent restoration andblurring that negatively affect both downstream applications and the overallviewing experience. To overcome these limitations, we propose the DenseSR,approaching the problem from a dense prediction perspective to emphasizerestoration quality. This framework uniquely synergizes two key strategies: (1)deep scene understanding guided by geometric-semantic priors to resolveambiguity and implicitly localize shadows, and (2) high-fidelity restorationvia a novel Dense Fusion Block (DFB) in the decoder. The DFB employs adaptivecomponent processing-using an Adaptive Content Smoothing Module (ACSM) forconsistent appearance and a Texture-Boundary Recuperation Module (TBRM) forfine textures and sharp boundaries-thereby directly tackling the inconsistentrestoration and blurring issues. These purposefully processed components areeffectively fused, yielding an optimized feature representation preserving bothconsistency and fidelity. Extensive experimental results demonstrate the meritsof our approach over existing methods. Our code can be available onhttps://github$.$com/VanLinLin/DenseSR</description>
      <author>example@mail.com (Yu-Fan Lin, Chia-Ming Lee, Chih-Chung Hsu)</author>
      <guid isPermaLink="false">2507.16472v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Aligned Manifold Property and Topology Point Clouds for Learning Molecular Properties</title>
      <link>http://arxiv.org/abs/2507.16223v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AMPTCR的分子表面表示方法，用于分子性质预测，该方法结合了局部量子场和自定义拓扑描述符，并通过对齐点云格式实现，以提高学习效率。&lt;h4&gt;背景&lt;/h4&gt;现有的分子性质预测模型通常依赖于忽略表面局部现象的表示，如SMILES字符串和分子图。基于3D的方法往往简化表面细节或需要复杂的SE(3)等变架构来处理空间变化。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些限制，提出AMPTCR方法，旨在提供一种更有效的分子表面表示。&lt;h4&gt;方法&lt;/h4&gt;AMPTCR结合了局部量子场和自定义拓扑描述符，在对齐点云格式中实现，每个表面点包含一个具有化学意义的标量、几何导出的拓扑向量和转换到规范参考系中的坐标。&lt;h4&gt;主要发现&lt;/h4&gt;使用DGCNN框架在分子量和细菌生长抑制两个任务上评估AMPTCR。在分子量任务中，AMPTCR编码了有物理意义的数据，验证R^2为0.87。在细菌抑制任务中，AMPTCR使用双重福居函数作为电子描述符和摩根指纹作为辅助数据，实现了分类和直接回归，分类任务的ROC AUC为0.912，回归任务的R^2为0.54。&lt;h4&gt;结论&lt;/h4&gt;AMPTCR提供了一种紧凑、表达性强且架构无关的表示方法，可以用于建模表面介导的分子性质。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分子性质预测的机器学习模型通常依赖于表示，如SMILES字符串和分子图，这些表示忽略了驱动分子行为的表面局部现象。基于3D的方法通常简化表面细节或需要计算上昂贵的SE(3)等变架构来处理空间变化。为了克服这些限制，本研究引入了AMPTCR（对齐流形属性和拓扑云表示），这是一种分子表面表示，它结合了局部量子场和自定义拓扑描述符，并在对齐点云格式内实现。每个表面点包括一个具有化学意义的标量、几何导出的拓扑向量和转换到规范参考系中的坐标，这使得使用传统的SE(3)敏感架构进行高效学习成为可能。AMPTCR使用DGCNN框架在两个任务上进行了评估：分子量和细菌生长抑制。对于分子量，结果证实AMPTCR编码了有物理意义的数据，验证R^2为0.87。在细菌抑制任务中，AMPTCR使用双重福居函数作为电子描述符和摩根指纹作为辅助数据，实现了分类和直接回归，分类任务的ROC AUC为0.912，回归任务的R^2为0.54。这些结果有助于证明AMPTCR提供了一种紧凑、表达性强且架构无关的表示方法，可以用于建模表面介导的分子性质。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning models for molecular property prediction generally rely onrepresentations -- such as SMILES strings and molecular graphs -- that overlookthe surface-local phenomena driving intermolecular behavior. 3D-basedapproaches often reduce surface detail or require computationally expensiveSE(3)-equivariant architectures to manage spatial variance. To overcome theselimitations, this work introduces AMPTCR (Aligned Manifold Property andTopology Cloud Representation), a molecular surface representation thatcombines local quantum-derived scalar fields and custom topological descriptorswithin an aligned point cloud format. Each surface point includes a chemicallymeaningful scalar, geodesically derived topology vectors, and coordinatestransformed into a canonical reference frame, enabling efficient learning withconventional SE(3)-sensitive architectures. AMPTCR is evaluated using a DGCNNframework on two tasks: molecular weight and bacterial growth inhibition. Formolecular weight, results confirm that AMPTCR encodes physically meaningfuldata, with a validation R^2 of 0.87. In the bacterial inhibition task, AMPTCRenables both classification and direct regression of E. coli inhibition valuesusing Dual Fukui functions as the electronic descriptor and Morgan Fingerprintsas auxiliary data, achieving an ROC AUC of 0.912 on the classification task,and an R^2 of 0.54 on the regression task. These results help demonstrate thatAMPTCR offers a compact, expressive, and architecture-agnostic representationfor modeling surface-mediated molecular properties.</description>
      <author>example@mail.com (Alexander Mihalcea)</author>
      <guid isPermaLink="false">2507.16223v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>DeSamba: Decoupled Spectral Adaptive Framework for 3D Multi-Sequence MRI Lesion Classification</title>
      <link>http://arxiv.org/abs/2507.15487v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 figures, 3 tables, submitted to AAAI2026&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DeSamba的新框架，用于从多序列MRI数据中提取解耦表示并自适应融合空间和频谱特征，以提高3D病变分类的准确性。&lt;h4&gt;背景&lt;/h4&gt;MRI序列提供了丰富的空间和频谱域信息，这对于医学成像中的病变分类至关重要。然而，有效地整合多序列MRI数据以进行稳健的3D病变分类仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出DeSamba框架，以实现多序列MRI数据的有效整合，提高3D病变分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;DeSamba框架包含一个解耦表示学习模块（DRLM），用于通过自重建和交叉重建解耦不同MRI序列的特征，以及一个频谱自适应调制块（SAMB），允许基于病变特征动态融合频谱和空间信息。&lt;h4&gt;主要发现&lt;/h4&gt;在两个临床相关3D数据集上评估DeSamba，其在六个类别的脊柱转移数据集上取得了62.10%的Top-1准确率，63.62%的F1分数，87.71%的AUC，以及93.55%的Top-3准确率。在涉及具有挑战性的二元分类任务的强直性脊柱炎数据集上，DeSamba在内部和外部验证集上分别实现了70.00%/64.52%的准确率和74.75/73.88的AUC。消融研究表明，DRLM和SAMB对整体性能有显著贡献，与基线相比，相对改进超过10%。&lt;h4&gt;结论&lt;/h4&gt;DeSamba作为一种可推广且有效的解决方案，具有在多序列医学成像中进行3D病变分类的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Magnetic Resonance Imaging (MRI) sequences provide rich spatial and frequencydomain information, which is crucial for accurate lesion classification inmedical imaging. However, effectively integrating multi-sequence MRI data forrobust 3D lesion classification remains a challenge. In this paper, we proposeDeSamba (Decoupled Spectral Adaptive Network and Mamba-Based Model), a novelframework designed to extract decoupled representations and adaptively fusespatial and spectral features for lesion classification. DeSamba introduces aDecoupled Representation Learning Module (DRLM) that decouples features fromdifferent MRI sequences through self-reconstruction and cross-reconstruction,and a Spectral Adaptive Modulation Block (SAMB) within the proposed SAMNet,enabling dynamic fusion of spectral and spatial information based on lesioncharacteristics. We evaluate DeSamba on two clinically relevant 3D datasets. Ona six-class spinal metastasis dataset (n=1,448), DeSamba achieves 62.10% Top-1accuracy, 63.62% F1-score, 87.71% AUC, and 93.55% Top-3 accuracy on an externalvalidation set (n=372), outperforming all state-of-the-art (SOTA) baselines. Ona spondylitis dataset (n=251) involving a challenging binary classificationtask, DeSamba achieves 70.00%/64.52% accuracy and 74.75/73.88 AUC on internaland external validation sets, respectively. Ablation studies demonstrate thatboth DRLM and SAMB significantly contribute to overall performance, with over10% relative improvement compared to the baseline. Our results highlight thepotential of DeSamba as a generalizable and effective solution for 3D lesionclassification in multi-sequence medical imaging.</description>
      <author>example@mail.com (Dezhen Wang, Sheng Miao, Rongxin Chai, Jiufa Cui)</author>
      <guid isPermaLink="false">2507.15487v2</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>FISHER: A Foundation Model for Multi-Modal Industrial Signal Comprehensive Representation</title>
      <link>http://arxiv.org/abs/2507.16696v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FISHER的基础模型，用于多模态工业信号的综合表示，旨在有效分析工业信号并检测异常状态。&lt;h4&gt;背景&lt;/h4&gt;随着SCADA系统的快速部署，如何有效分析工业信号和检测异常状态成为行业迫切需要解决的问题。&lt;h4&gt;目的&lt;/h4&gt;针对工业信号异质性强的问题（M5问题），本文旨在提出一种统一的建模方法，以利用模态间的协同作用和强大的缩放规律。&lt;h4&gt;方法&lt;/h4&gt;FISHER模型采用STFT子带作为建模单元，并采用教师-学生SSL框架进行预训练，以支持任意采样率。此外，还开发了RMIS基准，用于评估M5工业信号在多个健康管理任务上的表示。&lt;h4&gt;主要发现&lt;/h4&gt;FISHER模型在多个SSL模型中表现出色，性能提升高达5.03%，并且具有更高效的缩放曲线。同时，对下游任务的缩放规律进行了研究，并提出了未来工作的潜在方向。&lt;h4&gt;结论&lt;/h4&gt;FISHER模型能够有效处理工业信号，并具有广泛的应用潜力，现已开源。&lt;h4&gt;翻译&lt;/h4&gt;With the rapid deployment of SCADA systems, how to effectively analyze industrial signals and detect abnormal states is an urgent need for the industry. Due to the significant heterogeneity of these signals, which we summarize as the M5 problem, previous works only focus on small sub-problems and employ specialized models, failing to utilize the synergies between modalities and the powerful scaling law. However, we argue that the M5 signals can be modeled in a unified manner due to the intrinsic similarity. As a result, we propose FISHER, a Foundation model for multi-modal Industrial Signal com-preHEnsive Representation. To support arbitrary sampling rates, FISHER considers the increment of sampling rate as the concatenation of sub-band information. Specifically, FISHER takes the STFT sub-band as the modeling unit and adopts a teacher student SSL framework for pre-training. We also develop the RMIS benchmark, which evaluates the representations of M5 industrial signals on multiple health management tasks. Compared with top SSL models, FISHER showcases versatile and outstanding capabilities with a general performance gain up to 5.03%, along with much more efficient scaling curves. We also investigate the scaling law on downstream tasks and derive potential avenues for future works. FISHER is now open-sourced on https://github.com/jianganbai/FISHER.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid deployment of SCADA systems, how to effectively analyzeindustrial signals and detect abnormal states is an urgent need for theindustry. Due to the significant heterogeneity of these signals, which wesummarize as the M5 problem, previous works only focus on small sub-problemsand employ specialized models, failing to utilize the synergies betweenmodalities and the powerful scaling law. However, we argue that the M5 signalscan be modeled in a unified manner due to the intrinsic similarity. As aresult, we propose FISHER, a Foundation model for multi-modal Industrial SignalcompreHEnsive Representation. To support arbitrary sampling rates, FISHERconsiders the increment of sampling rate as the concatenation of sub-bandinformation. Specifically, FISHER takes the STFT sub-band as the modeling unitand adopts a teacher student SSL framework for pre-training. We also developthe RMIS benchmark, which evaluates the representations of M5 industrialsignals on multiple health management tasks. Compared with top SSL models,FISHER showcases versatile and outstanding capabilities with a generalperformance gain up to 5.03%, along with much more efficient scaling curves. Wealso investigate the scaling law on downstream tasks and derive potentialavenues for future works. FISHER is now open-sourced onhttps://github.com/jianganbai/FISHER</description>
      <author>example@mail.com (Pingyi Fan, Anbai Jiang, Shuwei Zhang, Zhiqiang Lv, Bing Han, Xinhu Zheng, Wenrui Liang, Junjie Li, Wei-Qiang Zhang, Yanmin Qian, Xie Chen, Cheng Lu, Jia Liu)</author>
      <guid isPermaLink="false">2507.16696v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>PUSA V1.0: Surpassing Wan-I2V with $500 Training Cost by Vectorized Timestep Adaptation</title>
      <link>http://arxiv.org/abs/2507.16116v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code is open-sourced at https://github.com/Yaofang-Liu/Pusa-VidGen&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Pusa的新颖视频扩散模型，它通过向量化时间步长调整（VTA）实现了精细的时间控制，克服了传统时间步长变量的刚性同步限制。Pusa模型在效率、性能和多功能性方面取得了显著成果。&lt;h4&gt;背景&lt;/h4&gt;视频扩散模型的快速发展受到时间建模基本限制的阻碍，特别是传统标量时间步长变量强加的帧演化的刚性同步。&lt;h4&gt;目的&lt;/h4&gt;提出Pusa模型，以解决视频扩散模型在时间建模方面的限制，实现高效、灵活的视频生成。&lt;h4&gt;方法&lt;/h4&gt;Pusa模型利用向量化时间步长调整（VTA）技术，通过微调SOTAWan2.1-T2V-14B模型来提高效率。&lt;h4&gt;主要发现&lt;/h4&gt;Pusa模型在训练成本和数据集大小上显著优于Wan-I2V-14B模型，同时实现了零样本多任务能力，如起始帧和视频扩展，且无需特定任务训练。此外，Pusa模型还能执行文本到视频的生成。&lt;h4&gt;结论&lt;/h4&gt;Pusa模型为下一代视频合成提供了一个可扩展、高效且通用的范式，为研究和工业界的高保真视频生成提供了民主化途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频扩散模型的快速发展受到时间建模基本限制的阻碍，特别是传统标量时间步长变量强加的帧演化的刚性同步。虽然针对特定任务的自适应和自回归模型试图解决这些挑战，但它们仍然受到计算效率低下、灾难性遗忘或适用性狭窄的限制。在本工作中，我们提出了Pusa，这是一种利用向量化时间步长调整（VTA）来在统一的视频扩散框架内实现精细时间控制的突破性范例。此外，VTA是一种非破坏性调整，这意味着它完全保留了基模型的 capability。通过使用VTA微调SOTAWan2.1-T2V-14B模型，我们实现了前所未有的效率——超过Wan-I2V-14B的性能，其训练成本降低至1/200（500美元对≥100,000美元）和数据集大小降低至1/2500（4K对≥10M样本）。Pusa不仅为图像到视频（I2V）生成设定了新的标准，实现了VBench-I2V总分为87.32%（Wan-I2V-14B为86.86%），而且还解锁了许多零样本多任务能力，如起始帧和视频扩展——所有这些都不需要特定任务的训练。同时，Pusa仍然能够执行文本到视频的生成。机制分析表明，我们的方法在保持基础模型生成先验的同时，巧妙地注入了时间动态，避免了向量化时间步长固有的组合爆炸。这项工作为下一代视频合成建立了一个可扩展、高效和通用的范式，为研究和工业界的高保真视频生成提供了民主化途径。代码已在https://github.com/Yaofang-Liu/Pusa-VidGen上开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of video diffusion models has been hindered byfundamental limitations in temporal modeling, particularly the rigidsynchronization of frame evolution imposed by conventional scalar timestepvariables. While task-specific adaptations and autoregressive models havesought to address these challenges, they remain constrained by computationalinefficiency, catastrophic forgetting, or narrow applicability. In this work,we present Pusa, a groundbreaking paradigm that leverages vectorized timestepadaptation (VTA) to enable fine-grained temporal control within a unified videodiffusion framework. Besides, VTA is a non-destructive adaptation, which meansit fully preserves the capabilities of the base model. By finetuning the SOTAWan2.1-T2V-14B model with VTA, we achieve unprecedented efficiency --surpassing the performance of Wan-I2V-14B with $\leq$ 1/200 of the trainingcost (\$500 vs. $\geq$ \$100,000) and $\leq$ 1/2500 of the dataset size (4K vs.$\geq$ 10M samples). Pusa not only sets a new standard for image-to-video (I2V)generation, achieving a VBench-I2V total score of 87.32\% (vs. 86.86\% ofWan-I2V-14B), but also unlocks many zero-shot multi-task capabilities such asstart-end frames and video extension -- all without task-specific training.Meanwhile, Pusa can still perform text-to-video generation. Mechanisticanalyses reveal that our approach preserves the foundation model's generativepriors while surgically injecting temporal dynamics, avoiding the combinatorialexplosion inherent to vectorized timesteps. This work establishes a scalable,efficient, and versatile paradigm for next-generation video synthesis,democratizing high-fidelity video generation for research and industry alike.Code is open-sourced at https://github.com/Yaofang-Liu/Pusa-VidGen</description>
      <author>example@mail.com (Yaofang Liu, Yumeng Ren, Aitor Artola, Yuxuan Hu, Xiaodong Cun, Xiaotong Zhao, Alan Zhao, Raymond H. Chan, Suiyun Zhang, Rui Liu, Dandan Tu, Jean-Michel Morel)</author>
      <guid isPermaLink="false">2507.16116v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Personalized PageRank and Higher-Order Topological Structures for Heterophily Mitigation in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.16347v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, accepted at IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HPGNN是一种结合了高阶个性化PageRank和图神经网络的模型，用于解决异质图中的节点分类问题。&lt;h4&gt;背景&lt;/h4&gt;现有的图神经网络模型在处理异质图时，通常假设节点间具有同质性，而忽略了异质图的实际情况，导致性能不佳。&lt;h4&gt;目的&lt;/h4&gt;提出HPGNN模型，以解决异质图中节点分类任务中的挑战，如忽略多尺度信息和噪声问题。&lt;h4&gt;方法&lt;/h4&gt;HPGNN引入了高效的高阶PageRank近似方法来捕捉长距离和多尺度节点交互，并将高阶结构信息嵌入到卷积网络中。&lt;h4&gt;主要发现&lt;/h4&gt;HPGNN在基准数据集上的实验表明，该模型在异质图上的性能优于五种最先进的方法，同时在同质图上也能保持竞争力。&lt;h4&gt;结论&lt;/h4&gt;HPGNN能够平衡多尺度信息并具有对噪声的鲁棒性，是解决现实世界图学习挑战的通用解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) excel in node classification tasks but often assume homophily, where connected nodes share similar labels. This assumption does not hold in many real-world heterophilic graphs. Existing models for heterophilic graphs primarily rely on pairwise relationships, overlooking multi-scale information from higher-order structures. This leads to suboptimal performance, particularly under noise from conflicting class information across nodes. To address these challenges, we propose HPGNN, a novel model integrating Higher-order Personalized PageRank with Graph Neural Networks. HPGNN introduces an efficient high-order approximation of Personalized PageRank (PPR) to capture long-range and multi-scale node interactions. This approach reduces computational complexity and mitigates noise from surrounding information. By embedding higher-order structural information into convolutional networks, HPGNN effectively models key interactions across diverse graph dimensions. Extensive experiments on benchmark datasets demonstrate HPGNN's effectiveness. The model achieves better performance than five out of seven state-of-the-art methods on heterophilic graphs in downstream tasks while maintaining competitive performance on homophilic graphs. HPGNN's ability to balance multi-scale information and robustness to noise makes it a versatile solution for real-world graph learning challenges. Codes are available at https://github.com/streetcorner/HPGNN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) excel in node classification tasks but oftenassume homophily, where connected nodes share similar labels. This assumptiondoes not hold in many real-world heterophilic graphs. Existing models forheterophilic graphs primarily rely on pairwise relationships, overlookingmulti-scale information from higher-order structures. This leads to suboptimalperformance, particularly under noise from conflicting class information acrossnodes. To address these challenges, we propose HPGNN, a novel model integratingHigher-order Personalized PageRank with Graph Neural Networks. HPGNN introducesan efficient high-order approximation of Personalized PageRank (PPR) to capturelong-range and multi-scale node interactions. This approach reducescomputational complexity and mitigates noise from surrounding information. Byembedding higher-order structural information into convolutional networks,HPGNN effectively models key interactions across diverse graph dimensions.Extensive experiments on benchmark datasets demonstrate HPGNN's effectiveness.The model achieves better performance than five out of seven state-of-the-artmethods on heterophilic graphs in downstream tasks while maintainingcompetitive performance on homophilic graphs. HPGNN's ability to balancemulti-scale information and robustness to noise makes it a versatile solutionfor real-world graph learning challenges. Codes are available athttps://github.com/streetcorner/HPGNN.</description>
      <author>example@mail.com (Yumeng Wang, Zengyi Wo, Wenjun Wang, Xingcheng Fu, Minglai Shao)</author>
      <guid isPermaLink="false">2507.16347v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>The Ever-Evolving Science Exam</title>
      <link>http://arxiv.org/abs/2507.16514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Ever-EvolvingScience Exam（EESE），一个动态基准，旨在可靠地评估基础模型在科学领域的科学能力。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型的能力和部署迅速增长，评估其科学理解变得越来越重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有科学基准面临的数据泄露风险和评估效率低下的问题。&lt;h4&gt;方法&lt;/h4&gt;EESE包括两个组成部分：1）一个非公开的EESE-Pool，包含超过10万个由专家构建的科学实例（问题-答案对），涵盖5个学科和500多个子领域；2）一个定期更新的500实例子集EESE，经过采样和验证，以实现泄漏鲁棒性和低开销的评估。&lt;h4&gt;主要发现&lt;/h4&gt;在32个开源和闭源模型上的实验表明，EESE能够有效地区分模型在科学领域和认知维度的优势和劣势。&lt;h4&gt;结论&lt;/h4&gt;EESE为科学基准设计提供了一个稳健、可扩展且向前兼容的解决方案，提供了对基础模型处理科学问题的现实衡量。&lt;h4&gt;翻译&lt;/h4&gt;As foundation models grow rapidly in capability and deployment, evaluating their scientific understanding becomes increasingly critical. Existing science benchmarks have made progress towards broad Range, wide Reach, and high Rigor, yet they often face two major challenges: data leakage risks that compromise benchmarking validity, and evaluation inefficiency due to large-scale testing. To address these issues, we introduce the Ever-EvolvingScience Exam (EESE), a dynamic benchmark designed to reliably assess scientific capabilities in foundation models. Our approach consists of two components: 1) a non-public EESE-Pool with over 100K expertly constructed science instances (question-answer pairs) across 5 disciplines and 500+ subfields, built through a multi-stage pipeline ensuring Range, Reach, and Rigor, 2) a periodically updated 500-instance subset EESE, sampled and validated to enable leakage-resilient, low-overhead evaluations. Experiments on 32 open- and closed-source models demonstrate that EESE effectively differentiates the strengths and weaknesses of models in scientific fields and cognitive dimensions. Overall, EESE provides a robust, scalable, and forward-compatible solution for science benchmark design, offering a realistic measure of how well foundation models handle science questions. The project page is at: https://github.com/aiben-ch/EESE.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As foundation models grow rapidly in capability and deployment, evaluatingtheir scientific understanding becomes increasingly critical. Existing sciencebenchmarks have made progress towards broad **Range**, wide **Reach**, and high**Rigor**, yet they often face two major challenges: **data leakage risks**that compromise benchmarking validity, and **evaluation inefficiency** due tolarge-scale testing. To address these issues, we introduce the **Ever-EvolvingScience Exam (EESE)**, a dynamic benchmark designed to reliably assessscientific capabilities in foundation models. Our approach consists of twocomponents: 1) a non-public **EESE-Pool** with over 100K expertly constructedscience instances (question-answer pairs) across 5 disciplines and 500+subfields, built through a multi-stage pipeline ensuring **Range**, **Reach**,and **Rigor**, 2) a periodically updated 500-instance subset **EESE**, sampledand validated to enable leakage-resilient, low-overhead evaluations.Experiments on 32 open- and closed-source models demonstrate that EESEeffectively differentiates the strengths and weaknesses of models in scientificfields and cognitive dimensions. Overall, EESE provides a robust, scalable, andforward-compatible solution for science benchmark design, offering a realisticmeasure of how well foundation models handle science questions. The projectpage is at: https://github.com/aiben-ch/EESE.</description>
      <author>example@mail.com (Junying Wang, Zicheng Zhang, Yijin Guo, Farong Wen, Ye Shen, Yingji Liang, Yalun Wu, Wenzhe Li, Chunyi Li, Zijian Chen, Qi Jia, Guangtao Zhai)</author>
      <guid isPermaLink="false">2507.16514v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Nonlinear Framework for Speech Bandwidth Extension</title>
      <link>http://arxiv.org/abs/2507.15970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为NDSI-BWE的宽带扩展（BWE）框架，用于恢复因带宽限制而丢失的高频成分。&lt;h4&gt;背景&lt;/h4&gt;恢复因带宽限制而丢失的高频成分对于从电信到有限资源上的高保真音频等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的BWE框架，以恢复高频率成分。&lt;h4&gt;方法&lt;/h4&gt;NDSI-BWE框架利用四个新的判别器，这些判别器受到非线性动力学系统的启发，以捕捉不同的时间行为，包括MRLD、MS-RD、MSDFA、MR-PPD、MPD、MRAD和MRPD。此外，框架使用了深度卷积，并在每个判别器中实现了参数减少。生成器使用复值ConformerNeXt和双流Lattice-Net架构来同时细化幅度和相位。&lt;h4&gt;主要发现&lt;/h4&gt;NDSI-BWE通过深度卷积实现了参数的八倍减少，并使用多个判别器引导生成器进行幅度和相位的细化。&lt;h4&gt;结论&lt;/h4&gt;在六个客观评估指标和基于五位人类评判者的主观文本测试中，NDSI-BWE在BWE领域建立了新的SoTA（最先进的技术水平）。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为NDSI-BWE的新宽带扩展（BWE）框架，该框架利用四个新的判别器，这些判别器受到非线性动力学系统的启发，以捕捉不同的时间行为：用于捕捉确定性混沌对初始条件敏感性的多分辨率李亚普诺夫判别器（MRLD）、用于捕捉自相似回溯动力学的多尺度回溯判别器（MS-RD）、用于捕捉长距离慢变尺度不变关系的多尺度去趋势分形分析判别器（MSDFA）、用于捕捉隐藏潜在空间关系的多分辨率庞加莱图判别器（MR-PPD）、用于捕捉周期性模式的多元周期判别器（MPD）、用于捕捉复杂幅度-相位转换统计的多分辨率幅度判别器（MRAD）和多分辨率相位判别器（MRPD）。通过在每个判别器核心使用深度卷积，NDSI-BWE实现了参数的八倍减少。这些七个判别器引导一个基于复值ConformerNeXt的生成器，该生成器具有基于双流Lattice-Net的架构，用于同时细化幅度和相位。生成器利用基于transformer的conformer的全局依赖建模能力和ConvNeXt块的局部时间建模能力。在六个客观评估指标和基于五位人类评判者的主观文本测试中，NDSI-BWE在BWE领域建立了新的SoTA。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recovering high-frequency components lost to bandwidth constraints is crucialfor applications ranging from telecommunications to high-fidelity audio onlimited resources. We introduce NDSI-BWE, a new adversarial Band WidthExtension (BWE) framework that leverage four new discriminators inspired bynonlinear dynamical system to capture diverse temporal behaviors: aMulti-Resolution Lyapunov Discriminator (MRLD) for determining sensitivity toinitial conditions by capturing deterministic chaos, a Multi-Scale RecurrenceDiscriminator (MS-RD) for self-similar recurrence dynamics, a Multi-ScaleDetrended Fractal Analysis Discriminator (MSDFA) for long range slow variantscale invariant relationship, a Multi-Resolution Poincar\'e Plot Discriminator(MR-PPD) for capturing hidden latent space relationship, a Multi-PeriodDiscriminator (MPD) for cyclical patterns, a Multi-Resolution AmplitudeDiscriminator (MRAD) and Multi-Resolution Phase Discriminator (MRPD) forcapturing intricate amplitude-phase transition statistics. By using depth-wiseconvolution at the core of the convolutional block with in each discriminators,NDSI-BWE attains an eight-times parameter reduction. These seven discriminatorsguide a complex-valued ConformerNeXt based genetor with a dual streamLattice-Net based architecture for simultaneous refinement of magnitude andphase. The genertor leverage the transformer based conformer's globaldependency modeling and ConvNeXt block's local temporal modeling capability.Across six objective evaluation metrics and subjective based texts comprises offive human judges, NDSI-BWE establishes a new SoTA in BWE.</description>
      <author>example@mail.com (Tarikul Islam Tamiti, Nursad Mamun, Anomadarshi Barua)</author>
      <guid isPermaLink="false">2507.15970v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Enhanced Reranking for Complementary Product Recommendation</title>
      <link>http://arxiv.org/abs/2507.16237v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于大型语言模型（LLM）的无模型方法，用于增强互补产品推荐的再排序，有效平衡了准确性多样性。&lt;h4&gt;背景&lt;/h4&gt;互补产品推荐在电子商务中是一个关键但具有挑战性的任务，现有的图神经网络（GNN）方法在捕捉复杂产品关系方面取得了进展，但通常难以在准确性多样性和长尾商品之间取得平衡。&lt;h4&gt;目的&lt;/h4&gt;旨在通过LLM增强互补产品推荐的再排序，提高推荐系统的准确性和多样性。&lt;h4&gt;方法&lt;/h4&gt;该方法不依赖于模型重训练，而是直接将基于LLM的提示策略应用于从现有推荐模型检索到的候选项目。&lt;h4&gt;主要发现&lt;/h4&gt;在公共数据集上的广泛实验表明，该方法在互补产品推荐中有效地平衡了准确性和多样性，平均至少提高了50%的准确性指标和2%的多样性指标。&lt;h4&gt;结论&lt;/h4&gt;LLM辅助的互补产品推荐再排序方法能够有效提升推荐系统的性能，对电子商务领域具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complementary product recommendation, which aims to suggest items that areused together to enhance customer value, is a crucial yet challenging task ine-commerce. While existing graph neural network (GNN) approaches have madesignificant progress in capturing complex product relationships, they oftenstruggle with the accuracy-diversity tradeoff, particularly for long-tailitems. This paper introduces a model-agnostic approach that leverages LargeLanguage Models (LLMs) to enhance the reranking of complementary productrecommendations. Unlike previous works that use LLMs primarily for datapreprocessing and graph augmentation, our method applies LLM-based promptingstrategies directly to rerank candidate items retrieved from existingrecommendation models, eliminating the need for model retraining. Throughextensive experiments on public datasets, we demonstrate that our approacheffectively balances accuracy and diversity in complementary productrecommendations, with at least 50% lift in accuracy metrics and 2% lift indiversity metrics on average for the top recommended items across datasets.</description>
      <author>example@mail.com (Zekun Xu, Yudi Zhang)</author>
      <guid isPermaLink="false">2507.16237v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Fast Task Planning with Neuro-Symbolic Relaxation</title>
      <link>http://arxiv.org/abs/2507.15975v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了Flax，一种结合神经重要性预测和符号扩展的NeSy放松策略，以提高复杂环境中的长时域任务规划的速度和可靠性。&lt;h4&gt;背景&lt;/h4&gt;现实世界中的任务规划需要对大量具有复杂关系和属性的实体进行长时域推理，这导致了传统符号规划器在组合爆炸方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;为了实现快速和可靠的规划，旨在减少搜索空间并避免简化任务中遗漏关键实体。&lt;h4&gt;方法&lt;/h4&gt;Flax方法包括：首先使用图神经网络预测实体重要性，创建简化任务并使用符号规划器解决；然后解决规则放松的任务以获得快速初步计划；最后将所有引用的实体重新集成到简化任务中，以恢复任何被忽视但必要的元素，并应用补充规则以细化更新后的任务。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实世界迷宫导航基准测试中，Flax将平均成功率提高了20.82%，并将平均规划时间减少了17.65%，优于现有的NeSy基线。&lt;h4&gt;结论&lt;/h4&gt;Flax为在复杂环境中实现快速、可扩展的长时域任务规划提供了一个实用路径。&lt;h4&gt;翻译&lt;/h4&gt;The paper introduces Flax, a NeSy relaxation strategy that combines neural importance prediction with symbolic expansion to improve the speed and reliability of task planning in complex environments. In real-world task planning, long-horizon reasoning over large sets of entities with complex relationships and attributes leads to combinatorial explosion for classical symbolic planners. To achieve fast and reliable planning, the purpose is to reduce the search space and avoid omitting critical entities in simplified tasks. The Flax method includes: first using a graph neural network to predict entity importance to create a simplified task and solve it with a symbolic planner; then solving a rule-relaxed task to obtain a quick preliminary plan; finally, reintegrating all referenced entities into the simplified task to recover any overlooked but essential elements, and applying complementary rules to refine the updated task. In both synthetic and real-world maze navigation benchmarks where a robot must traverse through a maze and interact with movable objects, Flax has increased the average success rate by 20.82% and reduced the mean wall-clock planning time by 17.65% compared with the state-of-the-art NeSy baseline. It is expected that Flax provides a practical approach to fast, scalable, long-horizon task planning in complex environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world task planning requires long-horizon reasoning over large sets ofentities with complex relationships and attributes, leading to a combinatorialexplosion for classical symbolic planners. To prune the search space, recentmethods prioritize searching on a simplified task only containing a few"important" entities predicted by a neural network. However, such a simpleneuro-symbolic (NeSy) integration risks omitting critical entities and wastingresources on unsolvable simplified tasks. To enable Fast and reliable planning,we introduce a NeSy relaxation strategy (Flax), combining neural importanceprediction with symbolic expansion. Specifically, we first learn a graph neuralnetwork to predict entity importance to create a simplified task and solve itwith a symbolic planner. Then, we solve a rule-relaxed task to obtain a quickrough plan, and reintegrate all referenced entities into the simplified task torecover any overlooked but essential elements. Finally, we apply complementaryrules to refine the updated task, keeping it both reliable and compact.Extensive experiments are conducted on both synthetic and real-world mazenavigation benchmarks where a robot must traverse through a maze and interactwith movable objects. The results show that Flax boosts the average successrate by 20.82% and cuts mean wall-clock planning time by 17.65% compared withthe state-of-the-art NeSy baseline. We expect that Flax offers a practical pathtoward fast, scalable, long-horizon task planning in complex environments.</description>
      <author>example@mail.com (Qiwei Du, Bowen Li, Yi Du, Shaoshu Su, Taimeng Fu, Zitong Zhan, Zhipeng Zhao, Chen Wang)</author>
      <guid isPermaLink="false">2507.15975v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>VGGT-Long: Chunk it, Loop it, Align it -- Pushing VGGT's Limits on Kilometer-scale Long RGB Sequences</title>
      <link>http://arxiv.org/abs/2507.16443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为VGGT-Long的简单而有效的系统，用于解决大规模RGB流3D重建的挑战，并在千米级无边界户外环境中实现了单目3D重建。&lt;h4&gt;背景&lt;/h4&gt;现有的3D视觉基础模型在3D感知方面表现出色，但将其扩展到大规模RGB流3D重建仍然面临内存限制的挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在通过VGGT-Long系统克服现有模型的可扩展性瓶颈，实现高精度的单目3D重建。&lt;h4&gt;方法&lt;/h4&gt;VGGT-Long采用基于块的处理策略，结合重叠对齐和轻量级闭环优化来解决可扩展性问题，且无需相机标定、深度监督或模型重训练。&lt;h4&gt;主要发现&lt;/h4&gt;VGGT-Long在KITTI、Waymo和Virtual KITTI数据集上进行了评估，结果显示该方法在长RGB序列中成功运行，并产生了在各种条件下准确且一致的几何信息。&lt;h4&gt;结论&lt;/h4&gt;VGGT-Long展示了利用基础模型进行可扩展单目3D场景重建的潜力，特别是在自动驾驶场景中。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a simple yet effective system called VGGT-Long to address the challenge of large-scale RGB stream 3D reconstruction and achieve monocular 3D reconstruction in kilometer-scale, unbounded outdoor environments. The system overcomes the scalability bottlenecks of existing models through a chunk-based processing strategy combined with overlapping alignment and lightweight loop closure optimization. VGGT-Long achieves trajectory and reconstruction performance comparable to traditional methods without requiring camera calibration, depth supervision, or model retraining. The method has been evaluated on KITTI, Waymo, and Virtual KITTI datasets, showing successful operation in long RGB sequences and producing accurate and consistent geometry across various conditions. The results highlight the potential of leveraging foundation models for scalable monocular 3D scene reconstruction in real-world settings, especially for autonomous driving scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models for 3D vision have recently demonstrated remarkablecapabilities in 3D perception. However, extending these models to large-scaleRGB stream 3D reconstruction remains challenging due to memory limitations. Inthis work, we propose VGGT-Long, a simple yet effective system that pushes thelimits of monocular 3D reconstruction to kilometer-scale, unbounded outdoorenvironments. Our approach addresses the scalability bottlenecks of existingmodels through a chunk-based processing strategy combined with overlappingalignment and lightweight loop closure optimization. Without requiring cameracalibration, depth supervision or model retraining, VGGT-Long achievestrajectory and reconstruction performance comparable to traditional methods. Weevaluate our method on KITTI, Waymo, and Virtual KITTI datasets. VGGT-Long notonly runs successfully on long RGB sequences where foundation models typicallyfail, but also produces accurate and consistent geometry across variousconditions. Our results highlight the potential of leveraging foundation modelsfor scalable monocular 3D scene in real-world settings, especially forautonomous driving scenarios. Code is available athttps://github.com/DengKaiCQ/VGGT-Long.</description>
      <author>example@mail.com (Kai Deng, Zexin Ti, Jiawei Xu, Jian Yang, Jin Xie)</author>
      <guid isPermaLink="false">2507.16443v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Feature Construction Using Network Control Theory and Rank Encoding for Graph Machine Learning</title>
      <link>http://arxiv.org/abs/2507.15195v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文利用图中的平均可控性概念和一种新颖的秩编码方法，以提高图神经网络（GNNs）在社交网络分类任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;GNNs在基于网络的学习应用中表现出色，但它们的性能受节点特征的表达能力影响很大。在社交网络中，由于隐私限制或缺乏固有属性，节点特征往往不可用，这使得GNNs难以达到最佳性能。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一局限性，本文提出了两种构建具有表现力的节点特征的方法。&lt;h4&gt;方法&lt;/h4&gt;首先，引入平均可控性以及其他中心性度量（记为NCT-EFA）作为节点级度量，以捕捉网络拓扑的关键方面。在此基础上，开发了一种秩编码方法，将平均可控性或其他图论度量转换为固定维度的特征空间，从而改进特征表示。然后，使用六个基准GNN模型在四个社交网络数据集上进行了广泛的数值评估，以比较不同的节点特征构建方法。&lt;h4&gt;主要发现&lt;/h4&gt;将平均可控性纳入特征空间可以显著提高GNN的性能。此外，所提出的秩编码方法优于传统的one-hot度编码，在GitHub Stargazers数据集上使用GraphSAGE将ROC AUC从68.7%提高到73.9%，突出了其在生成具有表现力和高效节点表示方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;平均可控性和秩编码方法能够有效提升GNN在社交网络分类任务中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this article, we utilize the concept of average controllability in graphs,along with a novel rank encoding method, to enhance the performance of GraphNeural Networks (GNNs) in social network classification tasks. GNNs have provenhighly effective in various network-based learning applications and requiresome form of node features to function. However, their performance is heavilyinfluenced by the expressiveness of these features. In social networks, nodefeatures are often unavailable due to privacy constraints or the absence ofinherent attributes, making it challenging for GNNs to achieve optimalperformance. To address this limitation, we propose two strategies forconstructing expressive node features. First, we introduce averagecontrollability along with other centrality metrics (denoted as NCT-EFA) asnode-level metrics that capture critical aspects of network topology. Buildingon this, we develop a rank encoding method that transforms averagecontrollability or any other graph-theoretic metric into a fixed-dimensionalfeature space, thereby improving feature representation. We conduct extensivenumerical evaluations using six benchmark GNN models across four social networkdatasets to compare different node feature construction methods. Our resultsdemonstrate that incorporating average controllability into the feature spacesignificantly improves GNN performance. Moreover, the proposed rank encodingmethod outperforms traditional one-hot degree encoding, improving the ROC AUCfrom 68.7% to 73.9% using GraphSAGE on the GitHub Stargazers dataset,underscoring its effectiveness in generating expressive and efficient noderepresentations.</description>
      <author>example@mail.com (Anwar Said, Yifan Wei, Obaid Ullah Ahmad, Mudassir Shabbir, Waseem Abbas, Xenofon Koutsoukos)</author>
      <guid isPermaLink="false">2507.15195v2</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Are Foundation Models All You Need for Zero-shot Face Presentation Attack Detection?</title>
      <link>http://arxiv.org/abs/2507.16393v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at FG 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了面对面部识别系统易受攻击的问题，并提出了零样本攻击检测（PAD）方法以解决传统方法在未知攻击工具或数据库上的泛化能力不足的问题。&lt;h4&gt;背景&lt;/h4&gt;尽管面部识别技术在过去十年中取得了显著进步，但它们容易受到攻击演示（AP）的攻击。这些攻击易于创建，攻击者可以通过针对系统的捕获设备执行它们来冒充授权主体，从而访问后者的信息。&lt;h4&gt;目的&lt;/h4&gt;为了保护面部识别方案免受攻击演示攻击，本文旨在通过零样本攻击检测（PAD）方法来减轻上述问题。&lt;h4&gt;方法&lt;/h4&gt;首先评估了基础模型在已建立和具有挑战性的实验场景中的有效性和泛化能力，然后提出了一种简单但有效的零样本攻击检测框架。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，这些模型能够在困难场景中实现性能，且所需的努力比更先进的攻击检测机制少，这些机制主要使用包含AP和真实演示的训练集来优化其权重。&lt;h4&gt;结论&lt;/h4&gt;性能最好的基础模型在SiW-Mv2数据库上优于最先进的方法，该数据库包含具有挑战性的未知2D和3D攻击。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管面部识别系统在过去十年中经历了令人印象深刻的进化，但这些技术容易受到攻击演示（AP）的攻击。这些攻击大多易于创建，攻击者通过针对系统的捕获设备执行它们，可以冒充授权主体，从而获取后者的信息（例如，金融交易）。为了保护面部识别方案免受攻击演示攻击，最先进的深度学习攻击检测（PAD）方法需要大量数据以产生可靠的检测性能，即便如此，它们在未知攻击工具（PAI）或数据库（训练期间未看到的信息）上的性能也会降低，即它们缺乏泛化能力。为了缓解上述问题，本文重点研究了零样本攻击检测（PAD）。为此，我们首先评估了基础模型在已建立和具有挑战性的实验场景中的有效性和泛化能力，然后提出了一种简单但有效的零样本攻击检测框架。实验结果表明，这些模型能够在困难场景中实现性能，且所需的努力比更先进的攻击检测机制少，这些机制主要使用包含AP和真实演示的训练集来优化其权重。性能最好的基础模型在SiW-Mv2数据库上优于最先进的方法，该数据库包含具有挑战性的未知2D和3D攻击。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although face recognition systems have undergone an impressive evolution inthe last decade, these technologies are vulnerable to attack presentations(AP). These attacks are mostly easy to create and, by executing them againstthe system's capture device, the malicious actor can impersonate an authorisedsubject and thus gain access to the latter's information (e.g., financialtransactions). To protect facial recognition schemes against presentationattacks, state-of-the-art deep learning presentation attack detection (PAD)approaches require a large amount of data to produce reliable detectionperformances and even then, they decrease their performance for unknownpresentation attack instruments (PAI) or database (information not seen duringtraining), i.e. they lack generalisability. To mitigate the above problems,this paper focuses on zero-shot PAD. To do so, we first assess theeffectiveness and generalisability of foundation models in established andchallenging experimental scenarios and then propose a simple but effectiveframework for zero-shot PAD. Experimental results show that these models areable to achieve performance in difficult scenarios with minimal effort of themore advanced PAD mechanisms, whose weights were optimised mainly with trainingsets that included APs and bona fide presentations. The top-performingfoundation model outperforms by a margin the best from the state of the artobserved with the leaving-one-out protocol on the SiW-Mv2 database, whichcontains challenging unknown 2D and 3D attacks</description>
      <author>example@mail.com (Lazaro Janier Gonzalez-Sole, Juan E. Tapia, Christoph Busch)</author>
      <guid isPermaLink="false">2507.16393v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Towards Accurate and Efficient 3D Object Detection for Autonomous Driving: A Mixture of Experts Computing System on Edge</title>
      <link>http://arxiv.org/abs/2507.04123v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了基于边缘的混合专家（MoE）协作计算（EMC2）系统，该系统专为自动驾驶汽车设计，旨在同时实现低延迟和高精度的3D目标检测。&lt;h4&gt;背景&lt;/h4&gt;传统方法在边缘平台上进行3D目标检测时存在低延迟和高精度难以兼顾的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在边缘平台上高效进行3D目标检测的系统，以满足自动驾驶汽车的需求。&lt;h4&gt;方法&lt;/h4&gt;EMC2系统采用了一种场景感知的MoE架构，有效融合了激光雷达和摄像头数据，并使用自适应的多模态数据桥进行多尺度预处理。此外，它还采用了一种场景感知的路由机制，动态地将特征分配给专门的专家模型。系统还集成了硬件-软件优化，以确保在资源受限的边缘设备上实现高效和实时的推理。&lt;h4&gt;主要发现&lt;/h4&gt;在公开数据集上的实验表明，EMC2在低延迟和高精度3D目标检测方面优于15个基线方法，实现了平均精度提高3.58%和推理速度提高159.06%，同时在nuScenes数据集上也取得了相似的性能提升。&lt;h4&gt;结论&lt;/h4&gt;EMC2是一个先进的端到端系统，能够有效推进自动驾驶汽车中可靠、实时的3D目标检测任务。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于边缘的混合专家（MoE）协作计算（EMC2）系统，旨在为自动驾驶汽车提供低延迟和高精度的3D目标检测。该系统采用了场景感知的MoE架构，融合了激光雷达和摄像头数据，并进行了自适应的多模态数据预处理和场景感知的路由机制。实验表明，EMC2在多个数据集上均优于基线方法，展示了其在资源受限的边缘设备上高效进行3D目标检测的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents Edge-based Mixture of Experts (MoE) CollaborativeComputing (EMC2), an optimal computing system designed for autonomous vehicles(AVs) that simultaneously achieves low-latency and high-accuracy 3D objectdetection. Unlike conventional approaches, EMC2 incorporates a scenario-awareMoE architecture specifically optimized for edge platforms. By effectivelyfusing LiDAR and camera data, the system leverages the complementary strengthsof sparse 3D point clouds and dense 2D images to generate robust multimodalrepresentations. To enable this, EMC2 employs an adaptive multimodal databridge that performs multi-scale preprocessing on sensor inputs, followed by ascenario-aware routing mechanism that dynamically dispatches features todedicated expert models based on object visibility and distance. In addition,EMC2 integrates joint hardware-software optimizations, including hardwareresource utilization optimization and computational graph simplification, toensure efficient and real-time inference on resource-constrained edge devices.Experiments on open-source benchmarks clearly show the EMC2 advancements as anend-to-end system. On the KITTI dataset, it achieves an average accuracyimprovement of 3.58% and a 159.06% inference speedup compared to 15 baselinemethods on Jetson platforms, with similar performance gains on the nuScenesdataset, highlighting its capability to advance reliable, real-time 3D objectdetection tasks for AVs. The official implementation is available athttps://github.com/LinshenLiu622/EMC2.</description>
      <author>example@mail.com (Linshen Liu, Boyan Su, Junyue Jiang, Guanlin Wu, Cong Guo, Ceyu Xu, Hao Frank Yang)</author>
      <guid isPermaLink="false">2507.04123v2</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>One Polyp Identifies All: One-Shot Polyp Segmentation with SAM via Cascaded Priors and Iterative Prompt Evolution</title>
      <link>http://arxiv.org/abs/2507.16337v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by ICCV2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Segment Anything Model（SAM）的OP-SAM单次息肉分割框架，用于解决传统方法在形态变化和域转换方面的难题，并减少对大规模标注的依赖。&lt;h4&gt;背景&lt;/h4&gt;传统的全监督息肉分割方法在形态变异和域转换问题上表现不佳，且依赖大规模标注，导致训练频繁且标注过程耗时费力。&lt;h4&gt;目的&lt;/h4&gt;提出一种自动从单个标注图像生成提示的OP-SAM框架，确保准确且可泛化的分割，同时减少标注负担。&lt;h4&gt;方法&lt;/h4&gt;OP-SAM引入了基于相关性的先验生成（CPG）用于语义标签转移和分级缩放先验融合（SPF）以适应息肉大小变化，并过滤掉噪声转移。通过欧几里得提示进化（EPE）对提示进行迭代优化，逐步提升分割质量。&lt;h4&gt;主要发现&lt;/h4&gt;在五个数据集上的广泛评估验证了OP-SAM的有效性，在Kvasir数据集上达到了76.93%的IoU，超越了现有技术的11.44%。&lt;h4&gt;结论&lt;/h4&gt;OP-SAM是一种有效且准确的单次息肉分割框架，能够解决传统方法的局限性，并通过自动提示生成和迭代优化技术减少了标注工作量和提高了分割质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Polyp segmentation is vital for early colorectal cancer detection, yettraditional fully supervised methods struggle with morphological variabilityand domain shifts, requiring frequent retraining. Additionally, reliance onlarge-scale annotations is a major bottleneck due to the time-consuming anderror-prone nature of polyp boundary labeling. Recently, vision foundationmodels like Segment Anything Model (SAM) have demonstrated stronggeneralizability and fine-grained boundary detection with sparse prompts,effectively addressing key polyp segmentation challenges. However, SAM'sprompt-dependent nature limits automation in medical applications, sincemanually inputting prompts for each image is labor-intensive andtime-consuming. We propose OP-SAM, a One-shot Polyp segmentation frameworkbased on SAM that automatically generates prompts from a single annotatedimage, ensuring accurate and generalizable segmentation without additionalannotation burdens. Our method introduces Correlation-based Prior Generation(CPG) for semantic label transfer and Scale-cascaded Prior Fusion (SPF) toadapt to polyp size variations as well as filter out noisy transfers. Insteadof dumping all prompts at once, we devise Euclidean Prompt Evolution (EPE) foriterative prompt refinement, progressively enhancing segmentation quality.Extensive evaluations across five datasets validate OP-SAM's effectiveness.Notably, on Kvasir, it achieves 76.93% IoU, surpassing the state-of-the-art by11.44%.</description>
      <author>example@mail.com (Xinyu Mao, Xiaohan Xing, Fei Meng, Jianbang Liu, Fan Bai, Qiang Nie, Max Meng)</author>
      <guid isPermaLink="false">2507.16337v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>M-SpecGene: Generalized Foundation Model for RGBT Multispectral Vision</title>
      <link>http://arxiv.org/abs/2507.16318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by ICCV2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为M-SpecGene的通用RGBT多光谱基础模型，旨在通过自监督方式从大规模数据中学习模态不变表示，以解决现有RGBT任务中的人工归纳偏差、模态偏差和数据瓶颈问题。&lt;h4&gt;背景&lt;/h4&gt;RGB-T多光谱视觉在复杂环境中的感知至关重要，但大多数RGBT任务依赖于手动定制的模型，这限制了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;构建一个通用的RGBT多光谱基础模型（M-SpecGene），以学习模态不变表示，并解决现有RGBT任务中的限制。&lt;h4&gt;方法&lt;/h4&gt;M-SpecGene通过自监督方式学习，引入了跨模态结构稀疏度（CMSS）指标来量化信息密度，并开发了GMM-CMSS渐进式掩码策略以实现灵活的预训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;M-SpecGene在11个数据集上对四个RGBT下游任务的泛化能力进行了验证，并提供了新的多光谱融合见解。&lt;h4&gt;结论&lt;/h4&gt;M-SpecGene模型能够有效解决RGBT任务中的限制，并在多个数据集上表现出良好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a generalized RGBT multispectral foundation model named M-SpecGene, which aims to learn modality-invariant representations from large-scale broad data in a self-supervised manner to address the limitations of existing RGBT tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; RGB-Thermal (RGBT) multispectral vision is essential for robust perception incomplex environments. Most RGBT tasks follow a case-by-case research paradigm,relying on manually customized models to learn task-oriented representations.Nevertheless, this paradigm is inherently constrained by artificial inductivebias, modality bias, and data bottleneck. To address these limitations, we makethe initial attempt to build a Generalized RGBT MultiSpectral foundation model(M-SpecGene), which aims to learn modality-invariant representations fromlarge-scale broad data in a self-supervised manner. M-SpecGene provides newinsights into multispectral fusion and integrates prior case-by-case studiesinto a unified paradigm. Considering the unique characteristic of informationimbalance in RGBT data, we introduce the Cross-Modality Structural Sparsity(CMSS) metric to quantify the information density across two modalities. Thenwe develop the GMM-CMSS progressive masking strategy to facilitate a flexible,easy-to-hard, and object-centric pre-training process. Comprehensiveexperiments validate M-SpecGene's generalizability across eleven datasets forfour RGBT downstream tasks. The code will be available athttps://github.com/CalayZhou/M-SpecGene.</description>
      <author>example@mail.com (Kailai Zhou, Fuqiang Yang, Shixian Wang, Bihan Wen, Chongde Zi, Linsen Chen, Qiu Shen, Xun Cao)</author>
      <guid isPermaLink="false">2507.16318v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Dens3R: A Foundation Model for 3D Geometry Prediction</title>
      <link>http://arxiv.org/abs/2507.16290v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://g-1nonly.github.io/Dens3R/, Code:  https://github.com/G-1nOnly/Dens3R&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Dens3R，一个用于联合几何密集预测的3D基础模型，该模型在多种密集3D预测任务中表现出色。&lt;h4&gt;背景&lt;/h4&gt;尽管密集3D重建取得了显著进展，但精确的统一几何预测仍然是一个主要挑战。大多数现有方法仅限于从输入图像中预测单个几何量，而几何量如深度、表面法线和点云图之间天然相关。&lt;h4&gt;目的&lt;/h4&gt;旨在探索一个统一的框架，该框架明确地建模不同几何属性之间的结构耦合，以实现联合回归。&lt;h4&gt;方法&lt;/h4&gt;Dens3R采用两阶段训练框架，逐步构建既通用又内在不变的点云图表示。它设计了一个轻量级的共享编码器-解码器骨干网络，并引入了位置插值旋转位置编码来保持表达能力并增强对高分辨率输入的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;Dens3R通过整合图像对匹配特征和内在不变性建模，能够准确回归多个几何量，如表面法线和深度，从单视图到多视图输入实现一致的几何感知。&lt;h4&gt;结论&lt;/h4&gt;广泛的实验表明，Dens3R在各种密集3D预测任务中表现出优异的性能，并突出了其在更广泛应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in dense 3D reconstruction have led to significant progress, yet achieving accurate unified geometric prediction remains a major challenge. Most existing methods are limited to predicting a single geometry quantity from input images. However, geometric quantities such as depth, surface normals, and point maps are inherently correlated, and estimating them in isolation often fails to ensure consistency, thereby limiting both accuracy and practical applicability. This motivates us to explore a unified framework that explicitly models the structural coupling among different geometric properties to enable joint regression. In this paper, we present Dens3R, a 3D foundation model designed for joint geometric dense prediction and adaptable to a wide range of downstream tasks. Dens3R adopts a two-stage training framework to progressively build a pointmap representation that is both generalizable and intrinsically invariant. Specifically, we design a lightweight shared encoder-decoder backbone and introduce position-interpolated rotary positional encoding to maintain expressive power while enhancing robustness to high-resolution inputs. By integrating image-pair matching features with intrinsic invariance modeling, Dens3R accurately regresses multiple geometric quantities such as surface normals and depth, achieving consistent geometry perception from single-view to multi-view inputs. Additionally, we propose a post-processing pipeline that supports geometrically consistent multi-view inference. Extensive experiments demonstrate the superior performance of Dens3R across various dense 3D prediction tasks and highlight its potential for broader applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in dense 3D reconstruction have led to significant progress,yet achieving accurate unified geometric prediction remains a major challenge.Most existing methods are limited to predicting a single geometry quantity frominput images. However, geometric quantities such as depth, surface normals, andpoint maps are inherently correlated, and estimating them in isolation oftenfails to ensure consistency, thereby limiting both accuracy and practicalapplicability. This motivates us to explore a unified framework that explicitlymodels the structural coupling among different geometric properties to enablejoint regression. In this paper, we present Dens3R, a 3D foundation modeldesigned for joint geometric dense prediction and adaptable to a wide range ofdownstream tasks. Dens3R adopts a two-stage training framework to progressivelybuild a pointmap representation that is both generalizable and intrinsicallyinvariant. Specifically, we design a lightweight shared encoder-decoderbackbone and introduce position-interpolated rotary positional encoding tomaintain expressive power while enhancing robustness to high-resolution inputs.By integrating image-pair matching features with intrinsic invariance modeling,Dens3R accurately regresses multiple geometric quantities such as surfacenormals and depth, achieving consistent geometry perception from single-view tomulti-view inputs. Additionally, we propose a post-processing pipeline thatsupports geometrically consistent multi-view inference. Extensive experimentsdemonstrate the superior performance of Dens3R across various dense 3Dprediction tasks and highlight its potential for broader applications.</description>
      <author>example@mail.com (Xianze Fang, Jingnan Gao, Zhe Wang, Zhuo Chen, Xingyu Ren, Jiangjing Lyu, Qiaomu Ren, Zhonglei Yang, Xiaokang Yang, Yichao Yan, Chengfei Lyu)</author>
      <guid isPermaLink="false">2507.16290v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning</title>
      <link>http://arxiv.org/abs/2507.14468v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Bioinformatics on July 11th&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了BioGraphFusion，一个用于深度协同语义和结构学习的创新框架，通过实验证明了其在生物医学知识图谱中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;生物医学知识图谱在药物发现和疾病理解中至关重要，但其完成和推理具有挑战性。知识嵌入（KE）方法和图神经网络（GNN）在处理语义和结构学习方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;解决生物医学知识图谱中语义理解和结构学习之间的协同进化问题。&lt;h4&gt;方法&lt;/h4&gt;BioGraphFusion通过张量分解建立全局语义基础，并使用LSTM机制动态优化关系嵌入，结合查询引导的子图构建和混合评分机制。&lt;h4&gt;主要发现&lt;/h4&gt;在三个关键生物医学任务上的实验表明，BioGraphFusion的性能优于现有的KE、GNN和集成模型，并在皮肤恶性黑色素瘤1（CMM1）案例研究中揭示了生物学上有意义的通路。&lt;h4&gt;结论&lt;/h4&gt;BioGraphFusion在生物医学知识图谱中实现了语义理解和结构学习的深度协同，为药物发现和疾病理解提供了新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：动机：生物医学知识图谱（KGs）对于药物发现和疾病理解至关重要，但其完成和推理具有挑战性。知识嵌入（KE）方法在捕捉全局语义方面表现出色，但在动态结构集成方面存在困难，而图神经网络（GNNs）在局部性能上表现出色，但通常缺乏语义理解。即使包括利用语言模型的集成方法，也往往无法实现语义理解和结构学习之间的深度、自适应和协同进化。解决在复杂生物医学KG中促进这两个方面之间连续、相互优化的关键差距至关重要。结果：我们引入了BioGraphFusion，这是一个用于深度协同语义和结构学习的创新框架。BioGraphFusion通过张量分解建立全局语义基础，指导LSTM驱动的机制在图传播过程中动态优化关系嵌入。这促进了语义理解和结构学习之间的自适应交互，并通过查询引导的子图构建和混合评分机制进一步增强。在三个关键生物医学任务上的实验表明，BioGraphFusion的性能优于现有的KE、GNN和集成模型。一个关于皮肤恶性黑色素瘤1（CMM1）的案例研究突出了其揭示生物学上有意义通路的能力。可用性和实现：源代码和所有训练数据可在https://github.com/Y-TARL/BioGraphFusion免费下载。补充信息：补充数据可在Bioinformatics online上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1093/bioinformatics/btaf408&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discoveryand disease understanding, yet their completion and reasoning are challenging.Knowledge Embedding (KE) methods capture global semantics but struggle withdynamic structural integration, while Graph Neural Networks (GNNs) excellocally but often lack semantic understanding. Even ensemble approaches,including those leveraging language models, often fail to achieve a deep,adaptive, and synergistic co-evolution between semantic comprehension andstructural learning. Addressing this critical gap in fostering continuous,reciprocal refinement between these two aspects in complex biomedical KGs isparamount.  Results: We introduce BioGraphFusion, a novel framework for deeplysynergistic semantic and structural learning. BioGraphFusion establishes aglobal semantic foundation via tensor decomposition, guiding an LSTM-drivenmechanism to dynamically refine relation embeddings during graph propagation.This fosters adaptive interplay between semantic understanding and structurallearning, further enhanced by query-guided subgraph construction and a hybridscoring mechanism. Experiments across three key biomedical tasks demonstrateBioGraphFusion's superior performance over state-of-the-art KE, GNN, andensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1)highlights its ability to unveil biologically meaningful pathways.  Availability and Implementation: Source code and all training data are freelyavailable for download at https://github.com/Y-TARL/BioGraphFusion.  Supplementary information: Supplementary data are available at Bioinformaticsonline.</description>
      <author>example@mail.com (Yitong Lin, Jiaying He, Jiahe Chen, Xinnan Zhu, Jianwei Zheng, Tao Bo)</author>
      <guid isPermaLink="false">2507.14468v2</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models and Transformers for Anomaly Detection: A Survey</title>
      <link>http://arxiv.org/abs/2507.15905v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文调查了Transformer和基础模型在视觉异常检测（VAD）中的变革性作用，探讨了这些架构如何解决长距离依赖建模、上下文建模和数据稀缺等挑战。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习的发展，Transformer和基础模型在VAD领域的应用逐渐受到关注。&lt;h4&gt;目的&lt;/h4&gt;本文旨在综合审查Transformer和基础模型在VAD中的应用，包括其优势、局限性和新兴趋势。&lt;h4&gt;方法&lt;/h4&gt;本文将VAD方法分为基于重建、基于特征和零/少样本方法，并分析了Transformer和基础模型如何通过集成注意力机制和利用大规模预训练来实现更鲁棒、可解释和可扩展的异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;Transformer和基础模型通过全局感受野和适应性解决了VAD中的挑战，并带来了范式转变。&lt;h4&gt;结论&lt;/h4&gt;本文提供了对Transformer和基础模型在VAD中应用的全面审查，揭示了这些架构在提高异常检测性能方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;In line with the development of deep learning, this survey examines the transformative role of Transformers and foundation models in advancing visual anomaly detection (VAD). We explore how these architectures, with their global receptive fields and adaptability, address challenges such as long-range dependency modeling, contextual modeling and data scarcity. The survey categorizes VAD methods into reconstruction-based, feature-based and zero/few-shot approaches, highlighting the paradigm shift brought about by foundation models. By integrating attention mechanisms and leveraging large-scale pre-training, Transformers and foundation models enable more robust, interpretable, and scalable anomaly detection solutions. This work provides a comprehensive review of state-of-the-art techniques, their strengths, limitations, and emerging trends in leveraging these architectures for VAD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.inffus.2025.103517&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In line with the development of deep learning, this survey examines thetransformative role of Transformers and foundation models in advancing visualanomaly detection (VAD). We explore how these architectures, with their globalreceptive fields and adaptability, address challenges such as long-rangedependency modeling, contextual modeling and data scarcity. The surveycategorizes VAD methods into reconstruction-based, feature-based andzero/few-shot approaches, highlighting the paradigm shift brought about byfoundation models. By integrating attention mechanisms and leveraginglarge-scale pre-training, Transformers and foundation models enable morerobust, interpretable, and scalable anomaly detection solutions. This workprovides a comprehensive review of state-of-the-art techniques, theirstrengths, limitations, and emerging trends in leveraging these architecturesfor VAD.</description>
      <author>example@mail.com (Mouïn Ben Ammar, Arturo Mendoza, Nacim Belkhir, Antoine Manzanera, Gianni Franchi)</author>
      <guid isPermaLink="false">2507.15905v1</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>Assessing Adaptive World Models in Machines with Novel Games</title>
      <link>http://arxiv.org/abs/2507.12821v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了人类智能在陌生环境中的快速适应和有效解决问题的能力，认为这种适应性与其构建和优化环境内部表示（世界模型）的效率密切相关。文章提出了一个基于认知科学研究的观点，并呼吁为评估AI中的自适应世界模型建立新的评估框架。&lt;h4&gt;背景&lt;/h4&gt;人类智能展现出在陌生环境中快速适应和有效解决问题的能力，这种能力与高效构建和优化环境内部表示（世界模型）密切相关。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的评估框架，以评估AI中的自适应世界模型，并推动发展具有人类类似快速适应能力和鲁棒泛化能力的AI系统。&lt;h4&gt;方法&lt;/h4&gt;基于认知科学的研究，设计了一系列具有真实、深刻和持续新颖性的游戏，作为新的基准测试范式，并提出了构建这些游戏的关键要求和评估指标。&lt;h4&gt;主要发现&lt;/h4&gt;提出了世界模型诱导的概念，并强调了在AI中评估自适应世界模型的重要性。&lt;h4&gt;结论&lt;/h4&gt;新的评估框架将激励未来对AI世界模型的评估工作，并为开发具有人类类似快速适应能力和鲁棒泛化能力的AI系统提供关键步骤。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类智能在陌生环境中表现出惊人的快速适应和有效解决问题的能力。我们认为这种深刻的适应性从根本上与高效构建和优化环境内部表示（通常称为世界模型）有关，我们将这种适应性机制称为世界模型诱导。然而，目前对人工智能（AI）中世界模型的理解和评估仍然很狭窄，通常集中在从大量数据语料库中学习到的静态表示上，而不是通过在新型环境中的交互和探索来学习和这些表示的效率。在这篇观点文章中，我们提供了一个基于几十年来认知科学关于人类如何高效学习和适应的研究的世界模型诱导的观点；然后我们呼吁为评估AI中的自适应世界模型建立一个新的评估框架。具体来说，我们提出了一种基于精心设计的游戏集的新基准测试范式，这些游戏在底层游戏结构中具有真实、深刻和持续的新颖性——我们将这类游戏称为新型游戏。我们详细阐述了构建这些游戏的关键要求，并提出了适当的指标来明确挑战和评估代理的快速世界模型诱导能力。我们希望这个新的评估框架将激励未来对AI世界模型的评估工作，并为开发具有人类类似快速适应能力和鲁棒泛化能力的AI系统提供关键步骤——这是人工通用智能的一个关键组成部分。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human intelligence exhibits a remarkable capacity for rapid adaptation andeffective problem-solving in novel and unfamiliar contexts. We argue that thisprofound adaptability is fundamentally linked to the efficient construction andrefinement of internal representations of the environment, commonly referred toas world models, and we refer to this adaptation mechanism as world modelinduction. However, current understanding and evaluation of world models inartificial intelligence (AI) remains narrow, often focusing on staticrepresentations learned from training on massive corpora of data, instead ofthe efficiency and efficacy in learning these representations throughinteraction and exploration within a novel environment. In this Perspective, weprovide a view of world model induction drawing on decades of research incognitive science on how humans learn and adapt so efficiently; we then callfor a new evaluation framework for assessing adaptive world models in AI.Concretely, we propose a new benchmarking paradigm based on suites of carefullydesigned games with genuine, deep and continually refreshing novelty in theunderlying game structures -- we refer to this class of games as novel games.We detail key desiderata for constructing these games and propose appropriatemetrics to explicitly challenge and evaluate the agent's ability for rapidworld model induction. We hope that this new evaluation framework will inspirefuture evaluation efforts on world models in AI and provide a crucial steptowards developing AI systems capable of human-like rapid adaptation and robustgeneralization -- a critical component of artificial general intelligence.</description>
      <author>example@mail.com (Lance Ying, Katherine M. Collins, Prafull Sharma, Cedric Colas, Kaiya Ivy Zhao, Adrian Weller, Zenna Tavares, Phillip Isola, Samuel J. Gershman, Jacob D. Andreas, Thomas L. Griffiths, Francois Chollet, Kelsey R. Allen, Joshua B. Tenenbaum)</author>
      <guid isPermaLink="false">2507.12821v2</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>VRU-Accident: A Vision-Language Benchmark for Video Question Answering and Dense Captioning for Accident Scene Understanding</title>
      <link>http://arxiv.org/abs/2507.09815v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 11 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出VRU-Accident，一个用于评估多模态大型语言模型在涉及脆弱道路使用者（VRU）的高风险交通场景中推理能力的大规模视觉语言基准。&lt;h4&gt;背景&lt;/h4&gt;确保脆弱道路使用者（如行人和骑自行车的人）的安全是自动驾驶系统的一个关键挑战，因为涉及VRU的碰撞往往导致严重或致命的后果。&lt;h4&gt;目的&lt;/h4&gt;为了解决当前缺乏标准化基准来定量评估多模态大型语言模型（MLLMs）在涉及VRU的复杂、安全关键场景中的推理能力的问题。&lt;h4&gt;方法&lt;/h4&gt;VRU-Accident包括1K个现实世界的行车记录仪事故视频，以及6K个多选题问答对，涵盖六个安全关键类别，每个类别有24K个候选选项和3.4K个独特答案选项，还有1K个密集场景描述。此外，对17个最先进的模型进行了综合评估，以评估它们在多选题问答任务和密集描述任务上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;MLLMs在视觉基础属性上表现良好，但在推理和描述事故原因、类型和可预防性方面面临重大挑战。&lt;h4&gt;结论&lt;/h4&gt;VRU-Accident基准为评估MLLMs在涉及VRU的高风险场景中的推理能力提供了一个有价值的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：确保脆弱道路使用者（VRUs），如行人和骑自行车的人的安全，是自动驾驶系统的一个关键挑战，因为涉及VRUs的碰撞往往会导致严重或致命的后果。虽然多模态大型语言模型（MLLMs）在增强自动驾驶车辆的场景理解和决策方面显示出希望，但目前还没有标准化的基准来定量评估它们在涉及VRUs的复杂、安全关键场景中的推理能力。为了解决这一差距，我们提出了VRU-Accident，这是一个用于评估MLLMs在涉及VRU的高风险交通场景中推理能力的大规模视觉语言基准。VRU-Accident包括1K个现实世界的行车记录仪事故视频，以及6K个多选题问答对，涵盖六个安全关键类别（每个类别有24K个候选选项和3.4K个独特答案选项），以及1K个密集场景描述。与先前的工作不同，我们的基准明确关注VRU-车辆事故，提供了丰富的、细粒度的注释，捕捉了事故的空间-时间动态和因果关系语义。为了评估MLLMs的现状，我们对17个最先进的模型在多选题问答任务和密集描述任务上进行了综合评估。我们的发现表明，尽管MLLMs在视觉基础属性上表现良好，但在推理和描述事故原因、类型和可预防性方面面临重大挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety of vulnerable road users (VRUs), such as pedestrians andcyclists, is a critical challenge for autonomous driving systems, as crashesinvolving VRUs often result in severe or fatal consequences. While multimodallarge language models (MLLMs) have shown promise in enhancing sceneunderstanding and decision making in autonomous vehicles, there is currently nostandardized benchmark to quantitatively evaluate their reasoning abilities incomplex, safety-critical scenarios involving VRUs. To address this gap, wepresent VRU-Accident, a large-scale vision-language benchmark designed toevaluate MLLMs in high-risk traffic scenarios involving VRUs. VRU-Accidentcomprises 1K real-world dashcam accident videos, annotated with 6Kmultiple-choice question-answer pairs across six safety-critical categories(with 24K candidate options and 3.4K unique answer choices), as well as 1Kdense scene descriptions. Unlike prior works, our benchmark focuses explicitlyon VRU-vehicle accidents, providing rich, fine-grained annotations that captureboth spatial-temporal dynamics and causal semantics of accidents. To assess thecurrent landscape of MLLMs, we conduct a comprehensive evaluation of 17state-of-the-art models on the multiple-choice VQA task and on the densecaptioning task. Our findings reveal that while MLLMs perform reasonably wellon visually grounded attributes, they face significant challenges in reasoningand describing accident causes, types, and preventability.</description>
      <author>example@mail.com (Younggun Kim, Ahmed S. Abdelrahman, Mohamed Abdel-Aty)</author>
      <guid isPermaLink="false">2507.09815v2</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs</title>
      <link>http://arxiv.org/abs/2507.10183v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to MLoG-GenAI Workshop @ KDD 2025 (Oral)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了动态图学习方法在建模随时间演变的关联数据方面的应用，并通过实验评估了当前时间图神经网络（TGNNs）在捕捉核心时间模式方面的能力。&lt;h4&gt;背景&lt;/h4&gt;尽管动态图学习方法在建模时间演变数据方面取得了进展，但关于当前TGNNs是否能够有效地捕捉周期性、因果关系和长距离依赖等核心时间模式尚不明确。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过提出时间图推理基准（T-GRAB）来系统地检验TGNNs在时间推理方面的能力。&lt;h4&gt;方法&lt;/h4&gt;T-GRAB提供了一系列合成任务，旨在隔离关键时间技能，包括计数/记忆周期性重复、推断延迟因果效应以及捕捉空间和时间维度上的长距离依赖。研究人员评估了11种时间图学习方法在这些任务上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，这些方法在泛化时间模式方面存在根本性的不足。&lt;h4&gt;结论&lt;/h4&gt;这些发现为当前模型的局限性提供了可操作的见解，突出了传统真实世界基准所隐藏的挑战，并激励了具有更强时间推理能力的架构的开发。&lt;h4&gt;翻译&lt;/h4&gt;Dynamic graph learning methods have recently emerged as powerful tools for modelling relational data evolving through time. However, despite extensive benchmarking efforts, it remains unclear whether current Temporal Graph Neural Networks (TGNNs) effectively capture core temporal patterns such as periodicity, cause-and-effect, and long-range dependencies. In this work, we introduce the Temporal Graph Reasoning Benchmark (T-GRAB), a comprehensive set of synthetic tasks designed to systematically probe the capabilities of TGNNs to reason across time. T-GRAB provides controlled, interpretable tasks that isolate key temporal skills: counting/memorizing periodic repetitions, inferring delayed causal effects, and capturing long-range dependencies over both spatial and temporal dimensions. We evaluate 11 temporal graph learning methods on these tasks, revealing fundamental shortcomings in their ability to generalize temporal patterns. Our findings offer actionable insights into the limitations of current models, highlight challenges hidden by traditional real-world benchmarks, and motivate the development of architectures with stronger temporal reasoning abilities. The code for T-GRAB can be found at: https://github.com/alirezadizaji/T-GRAB.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic graph learning methods have recently emerged as powerful tools formodelling relational data evolving through time. However, despite extensivebenchmarking efforts, it remains unclear whether current Temporal Graph NeuralNetworks (TGNNs) effectively capture core temporal patterns such asperiodicity, cause-and-effect, and long-range dependencies. In this work, weintroduce the Temporal Graph Reasoning Benchmark (T-GRAB), a comprehensive setof synthetic tasks designed to systematically probe the capabilities of TGNNsto reason across time. T-GRAB provides controlled, interpretable tasks thatisolate key temporal skills: counting/memorizing periodic repetitions,inferring delayed causal effects, and capturing long-range dependencies overboth spatial and temporal dimensions. We evaluate 11 temporal graph learningmethods on these tasks, revealing fundamental shortcomings in their ability togeneralize temporal patterns. Our findings offer actionable insights into thelimitations of current models, highlight challenges hidden by traditionalreal-world benchmarks, and motivate the development of architectures withstronger temporal reasoning abilities. The code for T-GRAB can be found at:https://github.com/alirezadizaji/T-GRAB.</description>
      <author>example@mail.com (Alireza Dizaji, Benedict Aaron Tjandra, Mehrab Hamidi, Shenyang Huang, Guillaume Rabusseau)</author>
      <guid isPermaLink="false">2507.10183v2</guid>
      <pubDate>Wed, 23 Jul 2025 14:26:16 +0800</pubDate>
    </item>
    <item>
      <title>DLBAcalib: Robust Extrinsic Calibration for Non-Overlapping LiDARs Based on Dual LBA</title>
      <link>http://arxiv.org/abs/2507.09176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages,14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的无目标外场标定框架，用于多激光雷达系统的精确外场标定，该框架不依赖于重叠的视场或精确的初始参数估计。&lt;h4&gt;背景&lt;/h4&gt;精确的多激光雷达外场标定对于提高三维地图重建系统的基本性能至关重要。&lt;h4&gt;目的&lt;/h4&gt;提高三维地图重建系统的准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法通过整合激光雷达光束调整（LBA）优化和鲁棒迭代细化，构建了一个统一的优化框架。它通过连续扫描目标激光雷达和滑动窗口激光雷达光束调整来构建准确的参考点云地图，并将外场标定作为联合LBA优化问题来处理。&lt;h4&gt;主要发现&lt;/h4&gt;该方法有效地减轻了累积映射误差，并通过自适应加权机制实现了对异常值具有鲁棒性的参数估计。在CARLA仿真环境和现实场景中的广泛评估表明，该方法在准确性和鲁棒性方面优于最先进的标定技术。&lt;h4&gt;结论&lt;/h4&gt;对于非重叠的传感器配置，该框架实现了平均平移误差为5毫米和旋转误差为0.2度的结果，初始误差容忍度高达0.4米/30度。此外，标定过程无需专用基础设施或手动参数调整。代码是开源的，可在GitHub上找到。&lt;h4&gt;翻译&lt;/h4&gt;Accurate extrinsic calibration of multiple LiDARs is crucial for improving the foundational performance of three-dimensional (3D) map reconstruction systems. This paper presents a novel targetless extrinsic calibration framework for multi-LiDAR systems that does not rely on overlapping fields of view or precise initial parameter estimates. Unlike conventional calibration methods that require manual annotations or specific reference patterns, our approach introduces a unified optimization framework by integrating LiDAR bundle adjustment (LBA) optimization with robust iterative refinement. The proposed method constructs an accurate reference point cloud map via continuous scanning from the target LiDAR and sliding-window LiDAR bundle adjustment, while formulating extrinsic calibration as a joint LBA optimization problem. This method effectively mitigates cumulative mapping errors and achieves outlier-resistant parameter estimation through an adaptive weighting mechanism. Extensive evaluations in both the CARLA simulation environment and real-world scenarios demonstrate that our method outperforms state-of-the-art calibration techniques in both accuracy and robustness. Experimental results show that for non-overlapping sensor configurations, our framework achieves an average translational error of 5 mm and a rotational error of 0.2{\deg}, with an initial error tolerance of up to 0.4 m/30{\deg}. Moreover, the calibration process operates without specialized infrastructure or manual parameter tuning. The code is open source and available on GitHub (https://github.com/Silentbarber/DLBAcalib).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate extrinsic calibration of multiple LiDARs is crucial for improvingthe foundational performance of three-dimensional (3D) map reconstructionsystems. This paper presents a novel targetless extrinsic calibration frameworkfor multi-LiDAR systems that does not rely on overlapping fields of view orprecise initial parameter estimates. Unlike conventional calibration methodsthat require manual annotations or specific reference patterns, our approachintroduces a unified optimization framework by integrating LiDAR bundleadjustment (LBA) optimization with robust iterative refinement. The proposedmethod constructs an accurate reference point cloud map via continuous scanningfrom the target LiDAR and sliding-window LiDAR bundle adjustment, whileformulating extrinsic calibration as a joint LBA optimization problem. Thismethod effectively mitigates cumulative mapping errors and achievesoutlier-resistant parameter estimation through an adaptive weighting mechanism.Extensive evaluations in both the CARLA simulation environment and real-worldscenarios demonstrate that our method outperforms state-of-the-art calibrationtechniques in both accuracy and robustness. Experimental results show that fornon-overlapping sensor configurations, our framework achieves an averagetranslational error of 5 mm and a rotational error of 0.2{\deg}, with aninitial error tolerance of up to 0.4 m/30{\deg}. Moreover, the calibrationprocess operates without specialized infrastructure or manual parameter tuning.The code is open source and available on GitHub(\underline{https://github.com/Silentbarber/DLBAcalib})</description>
      <author>example@mail.com (Han Ye, Yuqiang Jin, Jinyuan Liu, Tao Li, Wen-An Zhang, Minglei Fu)</author>
      <guid isPermaLink="false">2507.09176v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
  <item>
      <title>Counting $D_4$-field extensions by multi-invariants</title>
      <link>http://arxiv.org/abs/2507.12342v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, comments welcome&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究Galois扩展M/Q的数量，其中Galois群固定为D_4，并按照Gundlach引入的多不变量进行排序。&lt;h4&gt;背景&lt;/h4&gt;研究基于Gundlach版本的马勒猜想预测的渐近行为。&lt;h4&gt;目的&lt;/h4&gt;验证Gundlach版本的马勒猜想预测的渐近行为。&lt;h4&gt;方法&lt;/h4&gt;通过比较Gundlach版本的马勒猜想预测和Loughran与Santens的最新预测，研究Galois扩展的数量。&lt;h4&gt;主要发现&lt;/h4&gt;发现了Galois扩展数量的渐近行为，并与Loughran和Santens的预测进行了比较。&lt;h4&gt;结论&lt;/h4&gt;验证了Gundlach版本的马勒猜想预测的渐近行为，并提出了与Loughran和Santens预测的比较。&lt;h4&gt;翻译&lt;/h4&gt;计算具有固定Galois群D_4的Galois扩展M/Q的数量，这些扩展按Gundlach引入的多不变量排序。验证了Gundlach的马勒猜想版本的预测渐近行为。将主导常数与Loughran和Santens的最新预测进行了比较。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We count the number of Galois extensions $M/\mathbb{Q}$ with fixed Galoisgroup $\text{Gal}(M/\mathbb{Q})=D_4$ ordered by multi-invariants introduced byGundlach. We verify the asymptotic behavior predicted by Gundlach's version ofMalle's conjecture. We compare the leading constant to recent predictions byLoughran and Santens.</description>
      <author>example@mail.com (Willem Hansen, Anna Zanoli)</author>
      <guid isPermaLink="false">2507.12342v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Decision PCR: Decision version of the Point Cloud Registration task</title>
      <link>http://arxiv.org/abs/2507.14965v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对低重叠点云配准（PCR）的挑战，提出了一种基于深度学习的数据驱动方法，以提高注册质量。&lt;h4&gt;背景&lt;/h4&gt;在3D视觉中，低重叠点云配准是一个重要挑战，传统评估指标在极低内点比情况下失效。&lt;h4&gt;目的&lt;/h4&gt;重新审视配准结果评估问题，并提出通过深度学习框架解决决策版PCR任务的方法。&lt;h4&gt;方法&lt;/h4&gt;首先，基于3DMatch数据集构建了一个相应数据集；其次，训练了一个深度学习分类器来可靠地评估注册质量；最后，将此分类器整合到标准的PCR流程中。&lt;h4&gt;主要发现&lt;/h4&gt;将所提出的方法与现有的最先进PCR方法结合使用，显著提高了注册性能。例如，与GeoTransformer结合在3DLoMatch基准测试中实现了新的SOTA注册召回率86.97%。该方法在未见过的户外ETH数据集上也表现出强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高低重叠点云配准的性能，并通过深度学习框架实现了对注册质量的综合评估。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-overlap point cloud registration (PCR) remains a significant challenge in3D vision. Traditional evaluation metrics, such as Maximum Inlier Count, becomeineffective under extremely low inlier ratios. In this paper, we revisit theregistration result evaluation problem and identify the Decision version of thePCR task as the fundamental problem. To address this Decision PCR task, wepropose a data-driven approach. First, we construct a corresponding datasetbased on the 3DMatch dataset. Then, a deep learning-based classifier is trainedto reliably assess registration quality, overcoming the limitations oftraditional metrics. To our knowledge, this is the first comprehensive study toaddress this task through a deep learning framework. We incorporate thisclassifier into standard PCR pipelines. When integrated with our approach,existing state-of-the-art PCR methods exhibit significantly enhancedregistration performance. For example, combining our framework withGeoTransformer achieves a new SOTA registration recall of 86.97\% on thechallenging 3DLoMatch benchmark. Our method also demonstrates stronggeneralization capabilities on the unseen outdoor ETH dataset.</description>
      <author>example@mail.com (Yaojie Zhang, Tianlun Huang, Weijun Wang, Wei Feng)</author>
      <guid isPermaLink="false">2507.14965v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression</title>
      <link>http://arxiv.org/abs/2507.15686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于隐式神经网络表示的无损点云几何压缩方法LINR-PCGC，通过设计点云级编码框架和轻量级编码网络，提高了压缩效率和速度。&lt;h4&gt;背景&lt;/h4&gt;现有的AI点云压缩方法依赖于特定的训练数据分布，限制了其在现实世界中的应用。隐式神经网络表示（INR）方法通过将过拟合网络参数编码到比特流中，提高了分布无关性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于INR的无损点云几何压缩方法，以提高压缩效率和编码速度。&lt;h4&gt;方法&lt;/h4&gt;设计了一个点云级编码框架和有效的网络初始化策略，以减少编码时间；提出了一种基于多尺度稀疏卷积的轻量级编码网络，包括尺度上下文提取、子节点预测和模型压缩模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在MVUB数据集上的收敛时间比G-PCC TMC13v23和SparsePCGC分别减少了21.21%和21.95%。&lt;h4&gt;结论&lt;/h4&gt;LINR-PCGC方法在无损点云几何压缩方面优于传统和基于AI的方法。&lt;h4&gt;翻译&lt;/h4&gt;Existing AI-based point cloud compression methods struggle with dependence on specific training data distributions, which limits their real-world deployment. Implicit Neural Representation (INR) methods solve the above problem by encoding overfitted network parameters to the bitstream, resulting in more distribution-agnostic results. However, due to the limitation of encoding time and decoder size, current INR based methods only consider lossy geometry compression. In this paper, we propose the first INR based lossless point cloud geometry compression method called Lossless Implicit Neural Representations for Point Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we design a group of point clouds level coding framework with an effective network initialization strategy, which can reduce around 60% encoding time. A lightweight coding network based on multiscale SparseConv, consisting of scale context extraction, child node prediction, and model compression modules, is proposed to realize fast inference and compact decoder size. Experimental results show that our method consistently outperforms traditional and AI-based methods: for example, with the convergence time in the MVUB dataset, our method reduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and 21.95% compared to SparsePCGC. Our project can be seen on https://huangwenjie2023.github.io/LINR-PCGC/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing AI-based point cloud compression methods struggle with dependence onspecific training data distributions, which limits their real-world deployment.Implicit Neural Representation (INR) methods solve the above problem byencoding overfitted network parameters to the bitstream, resulting in moredistribution-agnostic results. However, due to the limitation of encoding timeand decoder size, current INR based methods only consider lossy geometrycompression. In this paper, we propose the first INR based lossless point cloudgeometry compression method called Lossless Implicit Neural Representations forPoint Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, wedesign a group of point clouds level coding framework with an effective networkinitialization strategy, which can reduce around 60% encoding time. Alightweight coding network based on multiscale SparseConv, consisting of scalecontext extraction, child node prediction, and model compression modules, isproposed to realize fast inference and compact decoder size. Experimentalresults show that our method consistently outperforms traditional and AI-basedmethods: for example, with the convergence time in the MVUB dataset, our methodreduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and21.95% compared to SparsePCGC. Our project can be seen onhttps://huangwenjie2023.github.io/LINR-PCGC/.</description>
      <author>example@mail.com (Wenjie Huang, Qi Yang, Shuting Xia, He Huang, Zhu Li, Yiling Xu)</author>
      <guid isPermaLink="false">2507.15686v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction</title>
      <link>http://arxiv.org/abs/2507.15803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何利用预训练的基础分割模型解决像素级视觉任务中的标签稀缺问题，提出了一种名为ConformalSAM的半监督语义分割框架。&lt;h4&gt;背景&lt;/h4&gt;像素级视觉任务如语义分割需要大量高质量的标注数据，而半监督语义分割方法通过利用标注数据和未标注数据减轻了标注负担。&lt;h4&gt;目的&lt;/h4&gt;探索基础分割模型作为未标注图像标注者的效果，以解决像素级视觉任务中的标签稀缺问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为ConformalSAM的框架，该框架首先使用目标域的标注数据校准基础模型，然后过滤掉未标注数据中的不可靠像素标签，仅使用高置信度标签作为监督。ConformalSAM利用了符合性预测（CP）技术来通过不确定性校准调整基础模型以适应目标数据，并采用后续的自依赖训练策略以减轻后期训练中对SEEM生成掩膜的过度拟合。&lt;h4&gt;主要发现&lt;/h4&gt;在三个标准的SSSS基准测试中，ConformalSAM相较于最近的SSSS方法实现了更好的性能，并且作为插件提升了这些方法的表现。&lt;h4&gt;结论&lt;/h4&gt;ConformalSAM能够有效地利用基础分割模型的能力，在像素级视觉任务的半监督语义分割中取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pixel-level vision tasks, such as semantic segmentation, require extensiveand high-quality annotated data, which is costly to obtain. Semi-supervisedsemantic segmentation (SSSS) has emerged as a solution to alleviate thelabeling burden by leveraging both labeled and unlabeled data throughself-training techniques. Meanwhile, the advent of foundational segmentationmodels pre-trained on massive data, has shown the potential to generalizeacross domains effectively. This work explores whether a foundationalsegmentation model can address label scarcity in the pixel-level vision task asan annotator for unlabeled images. Specifically, we investigate the efficacy ofusing SEEM, a Segment Anything Model (SAM) variant fine-tuned for textualinput, to generate predictive masks for unlabeled data. To address theshortcomings of using SEEM-generated masks as supervision, we proposeConformalSAM, a novel SSSS framework which first calibrates the foundationmodel using the target domain's labeled data and then filters out unreliablepixel labels of unlabeled data so that only high-confidence labels are used assupervision. By leveraging conformal prediction (CP) to adapt foundation modelsto target data through uncertainty calibration, ConformalSAM exploits thestrong capability of the foundational segmentation model reliably whichbenefits the early-stage learning, while a subsequent self-reliance trainingstrategy mitigates overfitting to SEEM-generated masks in the later trainingstage. Our experiment demonstrates that, on three standard benchmarks of SSSS,ConformalSAM achieves superior performance compared to recent SSSS methods andhelps boost the performance of those methods as a plug-in.</description>
      <author>example@mail.com (Danhui Chen, Ziquan Liu, Chuxi Yang, Dan Wang, Yan Yan, Yi Xu, Xiangyang Ji)</author>
      <guid isPermaLink="false">2507.15803v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Graph Attention Specialized Expert Fusion Model for Node Classification: Based on Cora and Pubmed Datasets</title>
      <link>http://arxiv.org/abs/2507.15784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为WR-EFM的图节点分类模型，通过Wasserstein-Rubinstein距离增强专家融合方法，解决了PubMed引文网络数据集中分类难度不均的问题，提高了分类准确率。&lt;h4&gt;背景&lt;/h4&gt;图节点分类是图神经网络中的基本任务，但在PubMed引文网络数据集中，不同类别的分类难度存在显著差异。&lt;h4&gt;目的&lt;/h4&gt;提高PubMed引文网络数据集中节点分类的准确率，特别是Category 2的准确率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种Wasserstein-Rubinstein距离增强的专家融合模型（WR-EFM），为Category 0/1训练专门的GNN模型，并使用多跳图注意力网络（GAT）处理Category 2。模型使用自适应融合策略，并根据类别特定的性能动态加权模型。&lt;h4&gt;主要发现&lt;/h4&gt;WR-EFM在所有类别上实现了平衡的准确率，且比单一模型和标准融合方法表现更好。WR-EFM的类别准确率变异性（CV）低于GCN，表明其具有更好的稳定性。与GCN相比，WR-EFM提高了Category 2的准确率。&lt;h4&gt;结论&lt;/h4&gt;WR-EFM为处理类别不平衡的图分类任务提供了一种新的范式，并通过实验验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图节点分类是图神经网络（GNN）中的基本任务，旨在为节点分配预定义的类别标签。在PubMed引文网络数据集上，我们观察到显著的分类难度差异，传统GCN在Category 2上仅达到74.4%的准确率，比Category 1低7.5%。为了解决这个问题，我们提出了一个Wasserstein-Rubinstein（WR）距离增强的专家融合模型（WR-EFM），为Category 0/1训练专门的GNN模型（具有层归一化和残差连接）和针对Category 2的多跳图注意力网络（GAT）。WR距离度量优化了模型之间的表示相似性，特别是关注提高Category 2的性能。我们的自适应融合策略根据类别特定的性能动态加权模型，将Category 2分配给GAT的权重为0.8。WR距离进一步通过测量模型表示之间的分布差异来指导融合过程，从而实现更原则性的互补特征集成。实验结果表明，WR-EFM在所有类别上实现了平衡的准确率：Category 0为77.8%，Category 1为78.0%，Category 2为79.9%，优于单一模型和标准融合方法。WR-EFM的类别准确率变异性（CV）为0.013，比GCN的0.058低77.6%，表明其具有更好的稳定性。值得注意的是，与GCN相比，WR-EFM提高了Category 2的准确率5.5%，验证了WR引导的融合在捕捉复杂结构模式方面的有效性。这项工作为处理类别不平衡的图分类任务提供了一种新的范式。为了促进研究社区，我们在https://github.com/s010m00n/GASEM4NC上发布了我们的项目。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph node classification is a fundamental task in graph neural networks(GNNs), aiming to assign predefined class labels to nodes. On the PubMedcitation network dataset, we observe significant classification difficultydisparities, with Category 2 achieving only 74.4% accuracy in traditional GCN,7.5% lower than Category 1. To address this, we propose aWasserstein-Rubinstein (WR) distance enhanced Expert Fusion Model (WR-EFM),training specialized GNN models for Categories 0/1 (with layer normalizationand residual connections) and Multi-hop Graph Attention Networks (GAT) forCategory 2. The WR distance metric optimizes representation similarity betweenmodels, particularly focusing on improving Category 2 performance. Our adaptivefusion strategy dynamically weights models based on category-specificperformance, with Category 2 assigned a GAT weight of 0.8. WR distance furtherguides the fusion process by measuring distributional differences between modelrepresentations, enabling more principled integration of complementaryfeatures.  Experimental results show WR-EFM achieves balanced accuracy acrosscategories: 77.8% (Category 0), 78.0% (Category 1), and 79.9% (Category 2),outperforming both single models and standard fusion approaches. Thecoefficient of variation (CV) of WR-EFM's category accuracies is 0.013, 77.6%lower than GCN's 0.058, demonstrating superior stability. Notably, WR-EFMimproves Category 2 accuracy by 5.5% compared to GCN, verifying theeffectiveness of WR-guided fusion in capturing complex structural patterns.This work provides a novel paradigm for handling class-imbalanced graphclassification tasks. To promote the research community, we release our projectat https://github.com/s010m00n/GASEM4NC.</description>
      <author>example@mail.com (Zihang Ma, Qitian Yin)</author>
      <guid isPermaLink="false">2507.15784v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Label tree semantic losses for rich multi-class medical image segmentation</title>
      <link>http://arxiv.org/abs/2507.15777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2506.21150&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于树结构的语义损失函数，用于医学图像分割，以解决传统方法在处理复杂标签时的不足。&lt;h4&gt;背景&lt;/h4&gt;准确的医学图像分割对于术前规划、术中导航和术后评估至关重要，但现有方法未能有效利用标签空间中的类间语义。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过利用标签的层次组织结构，提高医学图像分割的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;提出了两种基于树的语义损失函数，并将其应用于带有稀疏、无背景注释的训练中，以扩展方法的应用范围。&lt;h4&gt;主要发现&lt;/h4&gt;在头MRI全脑分割和神经外科高光谱成像场景理解两个任务上，该方法达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了所提出的方法在医学图像分割任务中具有显著的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rich and accurate medical image segmentation is poised to underpin the nextgeneration of AI-defined clinical practice by delineating critical anatomy forpre-operative planning, guiding real-time intra-operative navigation, andsupporting precise post-operative assessment. However, commonly used learningmethods for medical and surgical imaging segmentation tasks penalise all errorsequivalently and thus fail to exploit any inter-class semantics in the labelsspace. This becomes particularly problematic as the cardinality and richness oflabels increases to include subtly different classes. In this work, we proposetwo tree-based semantic loss functions which take advantage of a hierarchicalorganisation of the labels. We further incorporate our losses in a recentlyproposed approach for training with sparse, background-free annotations toextend the applicability of our proposed losses. Extensive experiments arereported on two medical and surgical image segmentation tasks, namely head MRIfor whole brain parcellation (WBP) with full supervision and neurosurgicalhyperspectral imaging (HSI) for scene understanding with sparse annotations.Results demonstrate that our proposed method reaches state-of-the-artperformance in both cases.</description>
      <author>example@mail.com (Junwen Wang, Oscar MacCormac, William Rochford, Aaron Kujawa, Jonathan Shapey, Tom Vercauteren)</author>
      <guid isPermaLink="false">2507.15777v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Dissociating model architectures from inference computations</title>
      <link>http://arxiv.org/abs/2507.15776v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Parr等人（2025年）研究了自回归和深度时间模型在处理非马尔可夫序列建模方面的差异。&lt;h4&gt;背景&lt;/h4&gt;本文基于对自回归和深度时间模型的研究，强调了在推理过程中区分模型架构（即预测分布如何分解）和所涉及的计算的重要性。&lt;h4&gt;目的&lt;/h4&gt;目的是通过实验证明深度时间计算可以通过自回归模型在迭代推理过程中模拟，并展示在迭代推理中诱导分层时间分解如何保持预测能力同时减少计算量。&lt;h4&gt;方法&lt;/h4&gt;使用在下一个标记预测上训练的Transformer模型，通过结构化迭代推理中的上下文访问来模拟深度时间计算。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，在迭代推理中诱导分层时间分解可以保持预测能力，同时实例化更少的计算。&lt;h4&gt;结论&lt;/h4&gt;结论指出，构建和改进预测的过程并不一定受其底层模型架构的限制。&lt;h4&gt;翻译&lt;/h4&gt;Parr等人（2025年）考察了自回归和深度时间模型在处理非马尔可夫序列建模方面的差异。在此基础上，我们强调了区分模型架构（即预测分布如何分解）与推理中涉及的计算的需要。我们通过在迭代推理中结构化上下文访问来证明深度时间计算可以通过自回归模型模拟。使用在下一个标记预测上训练的Transformer模型，我们展示了在迭代推理中诱导分层时间分解可以保持预测能力，同时实例化更少的计算。这强调了构建和改进预测的过程并不一定受其底层模型架构的限制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1080/17588928.2025.2532604&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parr et al., 2025 examines how auto-regressive and deep temporal modelsdiffer in their treatment of non-Markovian sequence modelling. Building onthis, we highlight the need for dissociating model architectures, i.e., how thepredictive distribution factorises, from the computations invoked at inference.We demonstrate that deep temporal computations are mimicked by autoregressivemodels by structuring context access during iterative inference. Using atransformer trained on next-token prediction, we show that inducinghierarchical temporal factorisation during iterative inference maintainspredictive capacity while instantiating fewer computations. This emphasisesthat processes for constructing and refining predictions are not necessarilybound to their underlying model architectures.</description>
      <author>example@mail.com (Noor Sajid, Johan Medrano)</author>
      <guid isPermaLink="false">2507.15776v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2507.14452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 4 figures. Accepted to IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GPI-Net的新型算法，用于基于特征点云配准，旨在通过Gestalt原理和并行交互网络提高高质量匹配的识别准确性。&lt;h4&gt;背景&lt;/h4&gt;特征点云配准中，准确识别高质量匹配是关键任务，但由于特征冗余和复杂的空间关系，融合局部和全局特征极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出GPI-Net的目的是利用Gestalt原理促进局部与全局信息之间的互补交流，并优化匹配结果。&lt;h4&gt;方法&lt;/h4&gt;GPI-Net采用正交几何一致性原则，通过引入正交整合策略减少冗余信息，并生成更紧凑的全局结构。同时，使用Gestalt特征关注块捕捉几何特征，并通过混合自注意力和交叉注意力机制。为了促进局部细节信息与全局结构的融合，设计了一种创新的双路径多粒度并行交互聚合块（DMG）。&lt;h4&gt;主要发现&lt;/h4&gt;在多个具有挑战性的任务上的广泛实验表明，GPI-Net相比现有方法表现出更优的性能。&lt;h4&gt;结论&lt;/h4&gt;GPI-Net是一种有效的算法，可以显著提高特征点云配准中高质量匹配的识别准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：准确识别高质量匹配是特征点云配准的先决任务。然而，由于特征冗余和复杂的空间关系，处理局部和全局特征的融合极为具有挑战性。鉴于Gestalt原则在分析局部和全局关系中的关键优势，本文提出了一种基于正交几何一致性的新型Gestalt引导并行交互网络（GPI-Net）。它利用Gestalt原理促进局部和全局信息之间的互补通信。具体来说，我们引入了一种正交整合策略，以最佳方式减少冗余信息，并为高质量匹配生成更紧凑的全局结构。为了捕捉匹配中的几何特征，我们利用Gestalt特征关注（GFA）块通过混合自注意力和交叉注意力机制。此外，为了促进局部细节信息与全局结构的集成，我们设计了一种创新的双路径多粒度并行交互聚合（DMG）块，以促进不同粒度之间的信息交换。在多个具有挑战性的任务上的广泛实验表明，与我们提出的方法相比，我们的GPI-Net具有优越的性能。代码将在https://github.com/gwk/GPI-Net上发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accurate identification of high-quality correspondences is a prerequisitetask in feature-based point cloud registration. However, it is extremelychallenging to handle the fusion of local and global features due to featureredundancy and complex spatial relationships. Given that Gestalt principlesprovide key advantages in analyzing local and global relationships, we proposea novel Gestalt-guided Parallel Interaction Network via orthogonal geometricconsistency (GPI-Net) in this paper. It utilizes Gestalt principles tofacilitate complementary communication between local and global information.Specifically, we introduce an orthogonal integration strategy to optimallyreduce redundant information and generate a more compact global structure forhigh-quality correspondences. To capture geometric features in correspondences,we leverage a Gestalt Feature Attention (GFA) block through a hybridutilization of self-attention and cross-attention mechanisms. Furthermore, tofacilitate the integration of local detail information into the globalstructure, we design an innovative Dual-path Multi-Granularity parallelinteraction aggregation (DMG) block to promote information exchange acrossdifferent granularities. Extensive experiments on various challenging tasksdemonstrate the superior performance of our proposed GPI-Net in comparison toexisting methods. The code will be released at https://github.com/gwk/GPI-Net.</description>
      <author>example@mail.com (Weikang Gu, Mingyue Han, Li Xue, Heng Dong, Changcai Yang, Riqing Chen, Lifang Wei)</author>
      <guid isPermaLink="false">2507.14452v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Graph Information Bottleneck for Multi-Behavior Recommendation</title>
      <link>http://arxiv.org/abs/2507.15395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by RecSys2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的模型无关的分层图信息瓶颈（HGIB）框架，用于多行为推荐，以有效解决行为分布差异和辅助行为噪声引起的负迁移效应问题。&lt;h4&gt;背景&lt;/h4&gt;在实际推荐场景中，用户通过多种行为与平台互动。多行为推荐算法旨在利用各种辅助用户行为来增强对主要目标行为（如购买）的预测，从而克服目标行为记录数据稀疏性带来的性能限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，以解决多行为推荐中的两个关键挑战：行为间的严重分布差异和辅助行为噪声引起的负迁移效应。&lt;h4&gt;方法&lt;/h4&gt;该框架遵循信息瓶颈原则，优化学习紧凑且充分的表示，同时消除与任务无关的冗余。为了进一步减轻交互噪声，引入了图细化编码器（GRE），通过可学习的边缘dropout机制动态修剪冗余边。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界公共数据集上进行了综合实验，证明了该框架的优越有效性。此外，在几个真实工业场景中进行了评估，并通过在线A/B测试展示了多行为推荐的显著改进。&lt;h4&gt;结论&lt;/h4&gt;HGIB框架在多行为推荐中表现出显著的效果，为解决数据稀疏性和噪声问题提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3705328.3748073&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world recommendation scenarios, users typically engage with platformsthrough multiple types of behavioral interactions. Multi-behaviorrecommendation algorithms aim to leverage various auxiliary user behaviors toenhance prediction for target behaviors of primary interest (e.g., buy),thereby overcoming performance limitations caused by data sparsity in targetbehavior records. Current state-of-the-art approaches typically employhierarchical design following either cascading (e.g.,view$\rightarrow$cart$\rightarrow$buy) or parallel(unified$\rightarrow$behavior$\rightarrow$specific components) paradigms, tocapture behavioral relationships. However, these methods still face twocritical challenges: (1) severe distribution disparities across behaviors, and(2) negative transfer effects caused by noise in auxiliary behaviors. In thispaper, we propose a novel model-agnostic Hierarchical Graph InformationBottleneck (HGIB) framework for multi-behavior recommendation to effectivelyaddress these challenges. Following information bottleneck principles, ourframework optimizes the learning of compact yet sufficient representations thatpreserve essential information for target behavior prediction while eliminatingtask-irrelevant redundancies. To further mitigate interaction noise, weintroduce a Graph Refinement Encoder (GRE) that dynamically prunes redundantedges through learnable edge dropout mechanisms. We conduct comprehensiveexperiments on three real-world public datasets, which demonstrate the superioreffectiveness of our framework. Beyond these widely used datasets in theacademic community, we further expand our evaluation on several real industrialscenarios and conduct an online A/B testing, showing again a significantimprovement in multi-behavior recommendations. The source code of our proposedHGIB is available at https://github.com/zhy99426/HGIB.</description>
      <author>example@mail.com (Hengyu Zhang, Chunxu Shen, Xiangguo Sun, Jie Tan, Yanchao Tan, Yu Rong, Hong Cheng, Lingling Yi)</author>
      <guid isPermaLink="false">2507.15395v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Streaming with Latency-Driven Implicit Adaptation using MoQ</title>
      <link>http://arxiv.org/abs/2507.15673v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于点云的视频表示方法，用于虚拟和增强现实中的下一代多媒体体验。该方法通过利用Media Over QUIC协议中的交付超时功能，实现了基于应用延迟目标的隐式服务器端适应，从而在降低延迟的同时优化视频质量。&lt;h4&gt;背景&lt;/h4&gt;点云数据具有高比特率的特点，限制了其在直播系统中的应用可行性。传统的基于HTTP协议的点云流媒体传输方法依赖于客户端的显式适应来维持低延迟。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过服务器端适应来优化点云数据的直播传输，以满足不同应用对延迟和视频质量的不同需求。&lt;h4&gt;方法&lt;/h4&gt;通过实验测试了不同的发布者和网络配置，验证了基于Media Over QUIC协议的交付超时功能在实现隐式服务器端适应方面的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该系统可以根据每个客户端的延迟需求，实现视频质量和延迟之间的独特权衡：对延迟要求较低的应用将获得较低质量的视频，而对延迟要求较宽松的应用将获得较高质量的视频。&lt;h4&gt;结论&lt;/h4&gt;基于Media Over QUIC协议的点云直播传输方法能够有效平衡视频质量和延迟，为不同应用提供灵活的传输解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point clouds are a promising video representation for next-generationmultimedia experiences in virtual and augmented reality. Point clouds arenotoriously high-bitrate, however, which limits the feasibility of livestreaming systems. Prior methods have adopted traditional HTTP-based protocolsfor point cloud streaming, but they rely on explicit client-side adaptation tomaintain low latency under congestion. In this work, we leverage the deliverytimeout feature within the Media Over QUIC protocol to perform implicitserver-side adaptation based on an application's latency target. Throughexperimentation with several publisher and network configurations, wedemonstrate that our system unlocks a unique trade-off on a per-client basis:applications with lower latency requirements will receive lower-quality video,while applications with more relaxed latency requirements will receivehigher-quality video.</description>
      <author>example@mail.com (Andrew Freeman, Michael Rudolph, Amr Rizk)</author>
      <guid isPermaLink="false">2507.15673v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation</title>
      <link>http://arxiv.org/abs/2507.15793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于医学图像分割的参数高效微调（PEFT）新方法，该方法可以动态调整适应过程中的内在秩。&lt;h4&gt;背景&lt;/h4&gt;参数高效的预训练基础模型微调在医学图像领域受到关注，其中低秩适应（LoRA）是一种基于低维子空间适应假设的方法。&lt;h4&gt;目的&lt;/h4&gt;为了解决LoRA方法中固定秩选择困难的问题，本文旨在引入一种动态调整秩的方法。&lt;h4&gt;方法&lt;/h4&gt;本文将可训练权重矩阵的低秩表示视为奇异值分解，并在损失函数中引入l_1稀疏正则化器，使用近端优化器进行求解。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在真实场景的少样本微调设置中显著提高了性能，并且对次优秩初始化具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在医学图像分割任务中表现出高效和鲁棒的特点。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is increasingly attracting interest in medical imaging due to its effectiveness and computational efficiency. Among these methods, Low-Rank Adaptation (LoRA) is a notable approach based on the assumption that the adaptation inherently occurs in a low-dimensional subspace. While it has shown good performance, its implementation requires a fixed and unalterable rank, which might be challenging to select given the unique complexities and requirements of each medical imaging downstream task. Inspired by advancements in natural image processing, we introduce a novel approach for medical image segmentation that dynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank representation of the trainable weight matrices as a singular value decomposition, we introduce an l_1 sparsity regularizer to the loss function, and tackle it with a proximal optimizer. The regularizer could be viewed as a penalty on the decomposition rank. Hence, its minimization enables to find task-adapted ranks automatically. Our method is evaluated in a realistic few-shot fine-tuning setting, where we compare it first to the standard LoRA and then to several other PEFT methods across two distinguishable tasks: base organs and novel organs. Our extensive experiments demonstrate the significant performance improvements driven by our method, highlighting its efficiency and robustness against suboptimal rank initialization. Our code is publicly available: https://github.com/ghassenbaklouti/ARENA&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models isincreasingly attracting interest in medical imaging due to its effectivenessand computational efficiency. Among these methods, Low-Rank Adaptation (LoRA)is a notable approach based on the assumption that the adaptation inherentlyoccurs in a low-dimensional subspace. While it has shown good performance, itsimplementation requires a fixed and unalterable rank, which might bechallenging to select given the unique complexities and requirements of eachmedical imaging downstream task. Inspired by advancements in natural imageprocessing, we introduce a novel approach for medical image segmentation thatdynamically adjusts the intrinsic rank during adaptation. Viewing the low-rankrepresentation of the trainable weight matrices as a singular valuedecomposition, we introduce an l_1 sparsity regularizer to the loss function,and tackle it with a proximal optimizer. The regularizer could be viewed as apenalty on the decomposition rank. Hence, its minimization enables to findtask-adapted ranks automatically. Our method is evaluated in a realisticfew-shot fine-tuning setting, where we compare it first to the standard LoRAand then to several other PEFT methods across two distinguishable tasks: baseorgans and novel organs. Our extensive experiments demonstrate the significantperformance improvements driven by our method, highlighting its efficiency androbustness against suboptimal rank initialization. Our code is publiclyavailable: https://github.com/ghassenbaklouti/ARENA</description>
      <author>example@mail.com (Ghassen Baklouti, Julio Silva-Rodríguez, Jose Dolz, Houda Bahig, Ismail Ben Ayed)</author>
      <guid isPermaLink="false">2507.15793v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Context for Multimodal Fallacy Classification in Political Debates</title>
      <link>http://arxiv.org/abs/2507.15641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12th Workshop on Argument Mining (ArgMining 2025) @ ACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了作者在MM-ArgFallacy2025共享任务中的提交，该任务旨在推进多模态论证挖掘研究，重点关注政治辩论中的逻辑谬误。&lt;h4&gt;背景&lt;/h4&gt;研究多模态论证挖掘，特别是关注政治辩论中的逻辑谬误。&lt;h4&gt;目的&lt;/h4&gt;提升多模态论证挖掘的研究水平，特别是针对政治辩论中的逻辑谬误。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的Transformer模型，并提出多种利用上下文的方法。&lt;h4&gt;主要发现&lt;/h4&gt;在谬误分类子任务中，模型在文本、音频和多媒体模态上分别实现了0.4444、0.3559和0.4403的宏F1分数。多模态模型的表现与仅文本模型相当，显示出改进的潜力。&lt;h4&gt;结论&lt;/h4&gt;多模态模型在政治辩论中的逻辑谬误分类方面具有与仅文本模型相当的性能，预示着进一步改进的可能性。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们提出了我们对MM-ArgFallacy2025共享任务的贡献，该任务旨在推进多模态论证挖掘的研究，重点关注政治辩论中的逻辑谬误。我们的方法使用了预训练的基于Transformer的模型，并提出了几种利用上下文的方法。在谬误分类子任务中，我们的模型在文本、音频和多模态上分别实现了0.4444、0.3559和0.4403的宏F1分数。我们的多模态模型表现与仅文本模型相当，表明了改进的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present our submission to the MM-ArgFallacy2025 sharedtask, which aims to advance research in multimodal argument mining, focusing onlogical fallacies in political debates. Our approach uses pretrainedTransformer-based models and proposes several ways to leverage context. In thefallacy classification subtask, our models achieved macro F1-scores of 0.4444(text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showedperformance comparable to the text-only model, suggesting potential forimprovements.</description>
      <author>example@mail.com (Alessio Pittiglio)</author>
      <guid isPermaLink="false">2507.15641v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>TrajLens: Visual Analysis for Constructing Cell Developmental Trajectories in Cross-Sample Exploration</title>
      <link>http://arxiv.org/abs/2507.15620v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个基于图神经网络（GNN）的模型，用于预测跨样本的细胞发育轨迹，并开发了TrajLens系统，辅助生物学家探索和优化细胞发育轨迹。&lt;h4&gt;背景&lt;/h4&gt;在单细胞RNA测序（scRNA-seq）分析中，构建细胞发育轨迹对于推断细胞可能的进化路径至关重要。然而，当前的方法只能处理单个样本中的细胞发育轨迹，需要生物学家手动链接样本间的细胞来构建考虑空间动态的跨样本进化轨迹，这个过程非常耗时。&lt;h4&gt;目的&lt;/h4&gt;提出一个自动化模型，用于预测跨样本细胞发育轨迹，并开发一个视觉分析系统以支持生物学家进行探索和优化。&lt;h4&gt;方法&lt;/h4&gt;开发了一个基于GNN的模型，并设计了一个名为TrajLens的视觉分析系统。系统中的可视化集成多样本中细胞的分布和发育方向特征，并提供轨迹沿线的细胞种群空间进化模式概述。同时，在原始细胞分布数据上叠加了等高线图，以便生物学家直观探索。&lt;h4&gt;主要发现&lt;/h4&gt;该系统通过两个案例研究和专家访谈证明了其模型的有效性和实用性。&lt;h4&gt;结论&lt;/h4&gt;所提出的模型和系统为生物学家在scRNA-seq分析中构建细胞发育轨迹提供了自动化和可视化的支持，提高了分析效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Constructing cell developmental trajectories is a critical task insingle-cell RNA sequencing (scRNA-seq) analysis, enabling the inference ofpotential cellular progression paths. However, current automated methods arelimited to establishing cell developmental trajectories within individualsamples, necessitating biologists to manually link cells across samples toconstruct complete cross-sample evolutionary trajectories that considercellular spatial dynamics. This process demands substantial human effort due tothe complex spatial correspondence between each pair of samples. To addressthis challenge, we first proposed a GNN-based model to predict cross-samplecell developmental trajectories. We then developed TrajLens, a visual analyticssystem that supports biologists in exploring and refining the celldevelopmental trajectories based on predicted links. Specifically, we designedthe visualization that integrates features on cell distribution anddevelopmental direction across multiple samples, providing an overview of thespatial evolutionary patterns of cell populations along trajectories.Additionally, we included contour maps superimposed on the original celldistribution data, enabling biologists to explore them intuitively. Todemonstrate our system's performance, we conducted quantitative evaluations ofour model with two case studies and expert interviews to validate itsusefulness and effectiveness.</description>
      <author>example@mail.com (Qipeng Wang, Shaolun Ruan, Rui Sheng, Yong Wang, Min Zhu, Huamin Qu)</author>
      <guid isPermaLink="false">2507.15620v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model's Capability of Emotion Perception using Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.15714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SemEval-2025任务11，这是一个涵盖28种语言的文本情感检测挑战，旨在探索更高级的方法来应对情感表达多样性和背景变化的挑战。&lt;h4&gt;背景&lt;/h4&gt;该挑战包括两个赛道：多标签分类（Track A）和情感强度预测（Track B），覆盖了愤怒、恐惧、喜悦、悲伤、惊讶和厌恶六种情感类别。&lt;h4&gt;目的&lt;/h4&gt;研究旨在系统地探索两种对比学习方法的益处：基于样本的对比学习（Contrastive Reasoning Calibration）和基于生成的对比学习（DPO, SimPO）。&lt;h4&gt;方法&lt;/h4&gt;所有模型都是基于LLaMa3-Instruct-8B进行微调。样本对比学习方法通过比较两个样本来训练模型，生成更可靠的预测；生成对比学习方法通过区分正确和错误的生成来训练模型，从而提高预测的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在Track A中获得了第9名，在Track B中获得了第6名（针对英语），在其他语言中表现也位于顶尖水平。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习方法，该系统在多语言情感检测任务中取得了良好的成绩，为情感检测领域提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The SemEval-2025 Task 11, Bridging the Gap in Text-Based Emotion Detection,introduces an emotion recognition challenge spanning over 28 languages. Thiscompetition encourages researchers to explore more advanced approaches toaddress the challenges posed by the diversity of emotional expressions andbackground variations. It features two tracks: multi-label classification(Track A) and emotion intensity prediction (Track B), covering six emotioncategories: anger, fear, joy, sadness, surprise, and disgust. In our work, wesystematically explore the benefits of two contrastive learning approaches:sample-based (Contrastive Reasoning Calibration) and generation-based (DPO,SimPO) contrastive learning. The sample-based contrastive approach trains themodel by comparing two samples to generate more reliable predictions. Thegeneration-based contrastive approach trains the model to differentiate betweencorrect and incorrect generations, refining its prediction. All models arefine-tuned from LLaMa3-Instruct-8B. Our system achieves 9th place in Track Aand 6th place in Track B for English, while ranking among the top-tierperforming systems for other languages.</description>
      <author>example@mail.com (Tian Li, Yujian Sun, Huizhi Liang)</author>
      <guid isPermaLink="false">2507.15714v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Sufficiency-principled Transfer Learning via Model Averaging</title>
      <link>http://arxiv.org/abs/2507.15416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  36 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于充分性原则的迁移学习框架，通过统一模型平均算法，结合个体和组合相似性，以提高迁移学习效果。&lt;h4&gt;背景&lt;/h4&gt;现有的迁移学习方法忽视了充分性原则，并且依赖于限制性的单相似性假设，导致性能不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一个基于充分性原则的迁移学习框架。&lt;h4&gt;方法&lt;/h4&gt;该方法通过统一模型平均算法，结合个体和组合相似性，并理论上建立了多源线性回归模型在参数数量无限增加时的渐近最优性、高概率最优性、增强收敛速度和渐近正态性。&lt;h4&gt;主要发现&lt;/h4&gt;实验模拟和北京住房租赁数据实证分析表明，该方法在性能上优于传统方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的迁移学习框架在增强迁移学习效果方面具有潜力。&lt;h4&gt;翻译&lt;/h4&gt;当可转移集合不可知时，尽可能多地转移有信息量的知识——我们称之为充分性原则——对于提高迁移学习效果变得至关重要。然而，现有的迁移学习方法不仅忽视了充分性原则，而且依赖于限制性的单相似性假设（例如个体或组合相似性），导致性能不佳。为了解决这些限制，我们通过统一模型平均算法提出了一种基于充分性原则的迁移学习框架，同时容纳个体和组合相似性。理论上，我们为具有无限参数数量的多源线性回归模型建立了渐近最优性/高概率最优性、增强收敛速度和渐近正态性，实现了充分性、对负迁移的鲁棒性、隐私保护和可行的统计推断。广泛的模拟和北京住房租赁数据的实证分析表明，我们的框架在性能上优于传统替代方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When the transferable set is unknowable, transfering informative knowledge asmuch as possible\textemdash a principle we refer to as \emph{sufficiency},becomes crucial for enhancing transfer learning effectiveness. However,existing transfer learning methods not only overlook the sufficiency principle,but also rely on restrictive single-similarity assumptions (\eg individual orcombinatorial similarity), leading to suboptimal performance. To address theselimitations, we propose a sufficiency-principled transfer learning frameworkvia unified model averaging algorithms, accommodating both individual andcombinatorial similarities. Theoretically, we establish theasymptotic/high-probability optimality, enhanced convergence rate andasymptotic normality for multi-source linear regression models with a divergingnumber of parameters, achieving sufficiency, robustness to negative transfer,privacy protection and feasible statistical inference. Extensive simulationsand an empirical data analysis of Beijing housing rental data demonstrate thepromising superiority of our framework over conventional alternatives.</description>
      <author>example@mail.com (Xiyuan Zhang, Huihang Liu, Xinyu Zhang)</author>
      <guid isPermaLink="false">2507.15416v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Towards Holistic Surgical Scene Graph</title>
      <link>http://arxiv.org/abs/2507.15541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图的方法来理解和表示手术场景，强调了工具-动作-目标组合和操作工具的手的身份在手术场景中的重要性。&lt;h4&gt;背景&lt;/h4&gt;手术场景理解对于计算机辅助干预系统至关重要，需要视觉理解手术场景中的各种元素，如手术工具、解剖结构和它们之间的相互作用。&lt;h4&gt;目的&lt;/h4&gt;为了有效地表示手术场景中的复杂信息，本文提出了Endoscapes-SG201数据集和SSG-Com方法，旨在整合工具-动作-目标组合和手身份等关键元素。&lt;h4&gt;方法&lt;/h4&gt;Endoscapes-SG201数据集包含工具-动作-目标组合和手身份的注释，SSG-Com是一种基于图的方法，用于学习和表示这些关键元素。&lt;h4&gt;主要发现&lt;/h4&gt;通过在下游任务（如安全评估和动作三元组识别）上的实验，证明了整合这些关键场景图组件的重要性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对手术场景理解有重要贡献，代码和数据集可在https://github.com/ailab-kyunghee/SSG-Com获取。&lt;h4&gt;翻译&lt;/h4&gt;Surgical scene understanding is crucial for computer-assisted interventionsystems, requiring visual comprehension of surgical scenes that involvesdiverse elements such as surgical tools, anatomical structures, and theirinteractions. To effectively represent the complex information in surgicalscenes, graph-based approaches have been explored to structurally modelsurgical entities and their relationships. Previous surgical scene graphstudies have demonstrated the feasibility of representing surgical scenes usinggraphs. However, certain aspects of surgical scenes-such as diversecombinations of tool-action-target and the identity of the hand operating thetool-remain underexplored in graph-based representations, despite theirimportance. To incorporate these aspects into graph representations, we proposeEndoscapes-SG201 dataset, which includes annotations for tool-action-targetcombinations and hand identity. We also introduce SSG-Com, a graph-based methoddesigned to learn and represent these critical elements. Through experiments ondownstream tasks such as critical view of safety assessment and action tripletrecognition, we demonstrated the importance of integrating these essentialscene graph components, highlighting their significant contribution to surgicalscene understanding. The code and dataset are available athttps://github.com/ailab-kyunghee/SSG-Com&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgical scene understanding is crucial for computer-assisted interventionsystems, requiring visual comprehension of surgical scenes that involvesdiverse elements such as surgical tools, anatomical structures, and theirinteractions. To effectively represent the complex information in surgicalscenes, graph-based approaches have been explored to structurally modelsurgical entities and their relationships. Previous surgical scene graphstudies have demonstrated the feasibility of representing surgical scenes usinggraphs. However, certain aspects of surgical scenes-such as diversecombinations of tool-action-target and the identity of the hand operating thetool-remain underexplored in graph-based representations, despite theirimportance. To incorporate these aspects into graph representations, we proposeEndoscapes-SG201 dataset, which includes annotations for tool-action-targetcombinations and hand identity. We also introduce SSG-Com, a graph-based methoddesigned to learn and represent these critical elements. Through experiments ondownstream tasks such as critical view of safety assessment and action tripletrecognition, we demonstrated the importance of integrating these essentialscene graph components, highlighting their significant contribution to surgicalscene understanding. The code and dataset are available athttps://github.com/ailab-kyunghee/SSG-Com</description>
      <author>example@mail.com (Jongmin Shin, Enki Cho, Ka Yong Kim, Jung Yong Kim, Seong Tae Kim, Namkee Oh)</author>
      <guid isPermaLink="false">2507.15541v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization</title>
      <link>http://arxiv.org/abs/2507.15765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACM MM'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HDF的动态面部表情识别框架，旨在解决现有方法在样本异质性和个体表情变化下的性能退化问题。&lt;h4&gt;背景&lt;/h4&gt;动态面部表情识别在情感计算和人与计算机交互中扮演着重要角色，但现有方法在处理多源数据和个体表情变化时，往往会出现性能下降。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出了HDF框架，旨在提高识别准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;HDF框架包括两个模块：时间-频率分布注意力模块（DAM）和分布感知缩放模块（DSM）。DAM通过双分支注意力设计捕捉时间和频率的鲁棒性，提高对序列不一致性和视觉风格变化的容忍度。DSM基于梯度敏感性和信息瓶颈原理，动态平衡分类和对比损失，实现更稳定和有区分性的表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;在DFEW和FERV39k两个数据集上的实验表明，HDF显著提高了识别准确性和鲁棒性，并在不同场景和平衡情况下保持了强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;HDF方法在加权平均召回率（WAR）和无加权平均召回率（UAR）方面取得了优异的成绩，同时具有强大的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Dynamic Facial Expression Recognition (DFER) plays a critical role in affective computing and human-computer interaction. Although existing methods achieve comparable performance, they inevitably suffer from performance degradation under sample heterogeneity caused by multi-source data and individual expression variability. To address these challenges, we propose a novel framework, called Heterogeneity-aware Distributional Framework (HDF), and design two plug-and-play modules to enhance time-frequency modeling and mitigate optimization imbalance caused by hard samples. Specifically, the Time-Frequency Distributional Attention Module (DAM) captures both temporal consistency and frequency robustness through a dual-branch attention design, improving tolerance to sequence inconsistency and visual style shifts. Then, based on gradient sensitivity and information bottleneck principles, an adaptive optimization module Distribution-aware Scaling Module (DSM) is introduced to dynamically balance classification and contrastive losses, enabling more stable and discriminative representation learning. Extensive experiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF significantly improves both recognition accuracy and robustness. Our method achieves superior weighted average recall (WAR) and unweighted average recall (UAR) while maintaining strong generalization across diverse and imbalanced scenarios. Codes are released at https://github.com/QIcita/HDF_DFER.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic Facial Expression Recognition (DFER) plays a critical role inaffective computing and human-computer interaction. Although existing methodsachieve comparable performance, they inevitably suffer from performancedegradation under sample heterogeneity caused by multi-source data andindividual expression variability. To address these challenges, we propose anovel framework, called Heterogeneity-aware Distributional Framework (HDF), anddesign two plug-and-play modules to enhance time-frequency modeling andmitigate optimization imbalance caused by hard samples. Specifically, theTime-Frequency Distributional Attention Module (DAM) captures both temporalconsistency and frequency robustness through a dual-branch attention design,improving tolerance to sequence inconsistency and visual style shifts. Then,based on gradient sensitivity and information bottleneck principles, anadaptive optimization module Distribution-aware Scaling Module (DSM) isintroduced to dynamically balance classification and contrastive losses,enabling more stable and discriminative representation learning. Extensiveexperiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDFsignificantly improves both recognition accuracy and robustness. Our methodachieves superior weighted average recall (WAR) and unweighted average recall(UAR) while maintaining strong generalization across diverse and imbalancedscenarios. Codes are released at https://github.com/QIcita/HDF_DFER.</description>
      <author>example@mail.com (Feng-Qi Cui, Anyang Tong, Jinyang Huang, Jie Zhang, Dan Guo, Zhi Liu, Meng Wang)</author>
      <guid isPermaLink="false">2507.15765v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>DynImg: Key Frames with Visual Prompts are Good Representation for Multi-Modal Video Understanding</title>
      <link>http://arxiv.org/abs/2507.15569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Dynamic-Image（DynImg）的创新视频表示方法，用于视频理解任务，以有效整合时间信息，并通过实验证明其有效性。&lt;h4&gt;背景&lt;/h4&gt;近年来，多模态大型语言模型（MLLMs）在视频理解任务中的应用越来越普遍，但如何有效整合时间信息仍然是一个关键的研究焦点。&lt;h4&gt;目的&lt;/h4&gt;提出DynImg方法以解决传统方法在处理快速移动对象时难以准确表示空间信息的问题，从而提高视频理解的准确性。&lt;h4&gt;方法&lt;/h4&gt; DynImg方法通过引入一系列非关键帧作为时间提示来突出快速移动对象所在的空间区域，并在视觉特征提取过程中引导模型对这些区域的细粒度空间特征给予更多关注。同时，使用4D视频旋转位置嵌入来保持DynImg的正确顺序，以帮助MLLM理解组合格式中的时空顺序。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估显示，DynImg在多个视频理解基准测试中超越了现有方法，提高了约2%，证明了时间提示在增强视频理解方面的有效性。&lt;h4&gt;结论&lt;/h4&gt; DynImg方法能够有效提升视频理解性能，为视频理解任务提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, the introduction of Multi-modal Large Language Models (MLLMs) into video understanding tasks has become increasingly prevalent. However, how to effectively integrate temporal information remains a critical research focus. Traditional approaches treat spatial and temporal information separately. Due to issues like motion blur, it is challenging to accurately represent the spatial information of rapidly moving objects. This can lead to temporally important regions being underemphasized during spatial feature extraction, which in turn hinders accurate spatio-temporal interaction and video understanding. To address this limitation, we propose an innovative video representation method called Dynamic-Image (DynImg). Specifically, we introduce a set of non-key frames as temporal prompts to highlight the spatial areas containing fast-moving objects. During the process of visual feature extraction, these prompts guide the model to pay additional attention to the fine-grained spatial features corresponding to these regions. Moreover, to maintain the correct sequence for DynImg, we employ a corresponding 4D video Rotary Position Embedding. This retains both the temporal and spatial adjacency of DynImg, helping MLLM understand the spatio-temporal order within this combined format. Experimental evaluations reveal that DynImg surpasses the state-of-the-art methods by approximately 2% across multiple video understanding benchmarks, proving the effectiveness of our temporal prompts in enhancing video comprehension.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the introduction of Multi-modal Large Language Models(MLLMs) into video understanding tasks has become increasingly prevalent.However, how to effectively integrate temporal information remains a criticalresearch focus. Traditional approaches treat spatial and temporal informationseparately. Due to issues like motion blur, it is challenging to accuratelyrepresent the spatial information of rapidly moving objects. This can lead totemporally important regions being underemphasized during spatial featureextraction, which in turn hinders accurate spatio-temporal interaction andvideo understanding. To address this limitation, we propose an innovative videorepresentation method called Dynamic-Image (DynImg). Specifically, we introducea set of non-key frames as temporal prompts to highlight the spatial areascontaining fast-moving objects. During the process of visual featureextraction, these prompts guide the model to pay additional attention to thefine-grained spatial features corresponding to these regions. Moreover, tomaintain the correct sequence for DynImg, we employ a corresponding 4D videoRotary Position Embedding. This retains both the temporal and spatial adjacencyof DynImg, helping MLLM understand the spatio-temporal order within thiscombined format. Experimental evaluations reveal that DynImg surpasses thestate-of-the-art methods by approximately 2% across multiple videounderstanding benchmarks, proving the effectiveness of our temporal prompts inenhancing video comprehension.</description>
      <author>example@mail.com (Xiaoyi Bao, Chenwei Xie, Hao Tang, Tingyu Weng, Xiaofeng Wang, Yun Zheng, Xingang Wang)</author>
      <guid isPermaLink="false">2507.15569v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion</title>
      <link>http://arxiv.org/abs/2507.14485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基于检索增强的点云补全框架，用于从不完全的点云中完成整个3D结构。&lt;h4&gt;背景&lt;/h4&gt;完成基于不完全点云的整个3D结构是一个具有挑战性的任务，特别是当剩余点云缺乏典型结构特征时。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过引入实例图像来辅助结构特征学习，以克服现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个结构共享特征编码器（SSFE）来联合提取跨模态特征并重建参考特征作为先验信息。此外，还提出了一种渐进式检索增强生成器（PRAG），它采用分层特征融合机制来整合全局到局部的参考先验信息。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在生成细粒度点云方面表现出有效性，并且具有处理稀疏数据和未见类别的一般化能力。&lt;h4&gt;结论&lt;/h4&gt;该检索增强的点云补全框架能够有效地从不完全点云中恢复3D结构，并具有较好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Based on the incomplete point cloud, this paper proposes a novel retrieval-augmented point cloud completion framework to recover the 3D structure effectively, with good generalization ability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Completing the whole 3D structure based on an incomplete point cloud is achallenging task, particularly when the residual point cloud lacks typicalstructural characteristics. Recent methods based on cross-modal learningattempt to introduce instance images to aid the structure feature learning.However, they still focus on each particular input class, limiting theirgeneration abilities. In this work, we propose a novel retrieval-augmentedpoint cloud completion framework. The core idea is to incorporate cross-modalretrieval into completion task to learn structural prior information fromsimilar reference samples. Specifically, we design a Structural Shared FeatureEncoder (SSFE) to jointly extract cross-modal features and reconstructreference features as priors. Benefiting from a dual-channel control gate inthe encoder, relevant structural features in the reference sample are enhancedand irrelevant information interference is suppressed. In addition, we proposea Progressive Retrieval-Augmented Generator (PRAG) that employs a hierarchicalfeature fusion mechanism to integrate reference prior information with inputfeatures from global to local. Through extensive evaluations on multipledatasets and real-world scenes, our method shows its effectiveness ingenerating fine-grained point clouds, as well as its generalization capabilityin handling sparse data and unseen categories.</description>
      <author>example@mail.com (Hongye Hou, Liu Zhan, Yang Yang)</author>
      <guid isPermaLink="false">2507.14485v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Universal crystal material property prediction via multi-view geometric fusion in graph transformers</title>
      <link>http://arxiv.org/abs/2507.15303v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MGT的多视角图变换框架，用于晶体结构的高精度和全面表示，以推动大规模晶体材料模拟中的机器学习发展。&lt;h4&gt;背景&lt;/h4&gt;准确和全面地表示晶体结构对于推进大规模晶体材料模拟中的机器学习至关重要，但有效地捕捉和利用晶体结构的复杂几何和拓扑特征是现有方法中的一个核心且长期存在的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出MGT框架，通过融合SE3不变和SO3等变图表示，分别捕捉晶体几何中的旋转平移不变性和旋转等变性。&lt;h4&gt;方法&lt;/h4&gt;在MGT中采用轻量级的专家路由器，根据特定目标任务自适应地调整分配给SE3和SO3嵌入的权重。通过多任务自监督预训练与之前的最先进模型相比，MGT在晶体性质预测任务上减少了高达21%的平均绝对误差。&lt;h4&gt;主要发现&lt;/h4&gt;消融实验和可解释性研究证实了框架中每个技术的有效性。在迁移学习场景中，包括晶体催化剂吸附能量和钙钛矿能带间隙预测，MGT比现有基线提高了高达58%的性能，证明了其在不同应用领域的领域无关可扩展性。&lt;h4&gt;结论&lt;/h4&gt;MGT可以作为晶体材料性质预测的有用模型，为新型材料的发现提供了一种有价值的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately and comprehensively representing crystal structures is criticalfor advancing machine learning in large-scale crystal materials simulations,however, effectively capturing and leveraging the intricate geometric andtopological characteristics of crystal structures remains a core, long-standingchallenge for most existing methods in crystal property prediction. Here, wepropose MGT, a multi-view graph transformer framework that synergisticallyfuses SE3 invariant and SO3 equivariant graph representations, whichrespectively captures rotation-translation invariance and rotation equivariancein crystal geometries. To strategically incorporate these complementarygeometric representations, we employ a lightweight mixture of experts router inMGT to adaptively adjust the weight assigned to SE3 and SO3 embeddings based onthe specific target task. Compared with previous state-of-the-art models, MGTreduces the mean absolute error by up to 21% on crystal property predictiontasks through multi-task self-supervised pretraining. Ablation experiments andinterpretable investigations confirm the effectiveness of each techniqueimplemented in our framework. Additionally, in transfer learning scenariosincluding crystal catalyst adsorption energy and hybrid perovskite bandgapprediction, MGT achieves performance improvements of up to 58% over existingbaselines, demonstrating domain-agnostic scalability across diverse applicationdomains. As evidenced by the above series of studies, we believe that MGT canserve as useful model for crystal material property prediction, providing avaluable tool for the discovery of novel materials.</description>
      <author>example@mail.com (Liang Zhang, Kong Chen, Yuen Wu)</author>
      <guid isPermaLink="false">2507.15303v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Data augmentation enables label-specific generation of homologous protein sequences</title>
      <link>http://arxiv.org/abs/2507.15651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对蛋白质家族的半监督功能注释和条件序列生成方法，通过结合自监督学习和轻量级监督，有效地解决了蛋白质功能预测和设计中数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;在蛋白质家族中，由于注释序列稀缺且结构变异小，准确注释和控制蛋白质功能是一个主要挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种两阶段方法，用于蛋白质家族的半监督功能注释和条件序列生成。&lt;h4&gt;方法&lt;/h4&gt;第一阶段，通过在大规模和多样化的序列数据集上预训练蛋白质语言模型，并通过对比学习进行微调，以获得能够稳健地捕获精细功能特异性的嵌入。第二阶段，使用推断的注释来训练一个生成概率模型，即一个具有注释意识的受限玻尔兹曼机，能够产生具有指定功能标签的合成序列。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个蛋白质家族中实现了高度准确的功能注释质量，并支持生成功能上连贯的序列。&lt;h4&gt;结论&lt;/h4&gt;研究强调了将自监督学习与轻量级监督相结合的强大能力，以克服蛋白质功能预测和设计中的数据稀缺问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately annotating and controlling protein function from sequence dataremains a major challenge, particularly within homologous families whereannotated sequences are scarce and structural variation is minimal. We presenta two-stage approach for semi-supervised functional annotation and conditionalsequence generation in protein families using representation learning. First,we demonstrate that protein language models, pretrained on large and diversesequence datasets and possibly finetuned via contrastive learning, provideembeddings that robustly capture fine-grained functional specificities, evenwith limited labeled data. Second, we use the inferred annotations to train agenerative probabilistic model, an annotation-aware Restricted BoltzmannMachine, capable of producing synthetic sequences with prescribed functionallabels. Across several protein families, we show that this approach achieveshighly accurate annotation quality and supports the generation of functionallycoherent sequences. Our findings underscore the power of combiningself-supervised learning with light supervision to overcome data scarcity inprotein function prediction and design.</description>
      <author>example@mail.com (Lorenzo Rosset, Martin Weigt, Francesco Zamponi)</author>
      <guid isPermaLink="false">2507.15651v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images</title>
      <link>http://arxiv.org/abs/2507.15496v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新型的激光雷达-视觉里程计框架，用于自动驾驶系统的自定位和导航。&lt;h4&gt;背景&lt;/h4&gt;里程计对于自动驾驶系统的自定位和导航至关重要。&lt;h4&gt;目的&lt;/h4&gt;实现准确和鲁棒的位姿估计。&lt;h4&gt;方法&lt;/h4&gt;该方法利用点云和图像通过深度完成估计密集深度图，并采用具有注意力机制的多尺度特征提取网络，实现自适应深度感知表示。此外，利用密集深度信息优化光流估计并减轻遮挡区域的误差。分层位姿优化模块逐步优化运动估计，确保对动态环境和尺度模糊性的鲁棒预测。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI里程计基准测试上，该方法与最先进的视觉和激光雷达里程计方法相比，实现了相似或更高的精度和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在自动驾驶系统的自定位和导航中具有显著的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：里程计是自动驾驶系统进行自定位和导航的关键任务。我们提出了一种新型的激光雷达-视觉里程计框架，该框架整合了激光雷达点云和图像，用于实现准确和鲁棒的位姿估计。我们的方法利用点云和图像通过深度完成估计的密集深度图，并集成了具有注意力机制的多尺度特征提取网络，实现了自适应深度感知表示。此外，我们利用密集深度信息优化光流估计并减轻遮挡区域的误差。我们的分层位姿优化模块逐步优化运动估计，确保对动态环境和尺度模糊性的鲁棒预测。在KITTI里程计基准测试上进行的全面实验表明，与最先进的视觉和激光雷达里程计方法相比，我们的方法实现了相似或更高的精度和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Odometry is a critical task for autonomous systems for self-localization andnavigation. We propose a novel LiDAR-Visual odometry framework that integratesLiDAR point clouds and images for accurate and robust pose estimation. Ourmethod utilizes a dense-depth map estimated from point clouds and imagesthrough depth completion, and incorporates a multi-scale feature extractionnetwork with attention mechanisms, enabling adaptive depth-awarerepresentations. Furthermore, we leverage dense depth information to refineflow estimation and mitigate errors in occlusion-prone regions. Ourhierarchical pose refinement module optimizes motion estimation progressively,ensuring robust predictions against dynamic environments and scale ambiguities.Comprehensive experiments on the KITTI odometry benchmark demonstrate that ourapproach achieves similar or superior accuracy and robustness compared tostate-of-the-art visual and LiDAR odometry methods.</description>
      <author>example@mail.com (JunYing Huang, Ao Xu, DongSun Yong, KeRen Li, YuanFeng Wang, Qi Qin)</author>
      <guid isPermaLink="false">2507.15496v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>ROBAD: Robust Adversary-aware Local-Global Attended Bad Actor Detection Sequential Model</title>
      <link>http://arxiv.org/abs/2507.15067v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为ROBAD的基于Transformer的分类模型，用于检测网络平台上的不良行为者。该模型能够识别潜在输入修改，并对对抗攻击具有鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;检测不良行为者是确保互联网平台安全和完整性的关键。现有的基于深度学习的检测模型对输入序列的微小变化敏感，不足以抵御对抗攻击。&lt;h4&gt;目的&lt;/h4&gt;提高模型对输入序列的理解能力，并增强模型知识，使其能够识别潜在输入修改。&lt;h4&gt;方法&lt;/h4&gt;ROBAD模型通过以下步骤实现目标：(1) 使用Transformer编码器块双向编码每篇帖子，构建帖子嵌入以捕获帖子层面的局部信息；(2) 使用Transformer解码器块和注意力机制建模帖子嵌入中的序列模式，生成序列嵌入以获取序列层面的全局信息；(3) 通过将模拟攻击者的修改序列嵌入输入到对比学习增强的分类层，丰富模型知识。&lt;h4&gt;主要发现&lt;/h4&gt;ROBAD能够有效检测不良行为者，即使在最先进的对抗攻击下。&lt;h4&gt;结论&lt;/h4&gt;ROBAD模型通过捕捉局部和全局信息以及利用训练中不良行为者的模拟行为，能够对对抗攻击具有鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：检测不良行为者是确保互联网平台安全和完整性的关键。已经开发了几个基于深度学习的模型来识别这样的用户。这些模型不仅需要准确检测不良行为者，而且需要抵御旨在逃避检测的对攻击的鲁棒性。然而，过去基于深度学习的检测模型没有满足鲁棒性的要求，因为它们对输入序列的微小变化非常敏感。为了解决这个问题，我们专注于（1）提高模型的理解能力，（2）增强模型的知识，以便模型在做出预测时能够识别潜在输入修改。为了实现这些目标，我们创建了一个名为ROBAD（鲁棒的局部-全局关注的不良行为者检测模型）的新型基于Transformer的分类模型，该模型使用用户帖子序列生成用户嵌入以检测不良行为者。特别是，ROBAD首先利用Transformer编码器块双向编码每篇帖子，从而构建帖子嵌入以捕获帖子层面的局部信息。接下来，它采用Transformer解码器块通过使用注意力机制来建模帖子嵌入中的序列模式，生成序列嵌入以获取序列层面的全局信息。最后，为了丰富模型的知识，将模拟攻击者的修改序列嵌入输入到对比学习增强的分类层以进行序列预测。本质上，通过捕捉局部和全局信息（即帖子信息和序列信息）以及利用训练中不良行为者的模拟行为，ROBAD可以对抗攻击具有鲁棒性。在Yelp和Wikipedia数据集上的大量实验表明，ROBAD在受到最先进的对抗攻击时可以有效地检测不良行为者。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting bad actors is critical to ensure the safety and integrity ofinternet platforms. Several deep learning-based models have been developed toidentify such users. These models should not only accurately detect bad actors,but also be robust against adversarial attacks that aim to evade detection.However, past deep learning-based detection models do not meet the robustnessrequirement because they are sensitive to even minor changes in the inputsequence. To address this issue, we focus on (1) improving the modelunderstanding capability and (2) enhancing the model knowledge such that themodel can recognize potential input modifications when making predictions. Toachieve these goals, we create a novel transformer-based classification model,called ROBAD (RObust adversary-aware local-global attended Bad Actor Detectionmodel), which uses the sequence of user posts to generate user embedding todetect bad actors. Particularly, ROBAD first leverages the transformer encoderblock to encode each post bidirectionally, thus building a post embedding tocapture the local information at the post level. Next, it adopts thetransformer decoder block to model the sequential pattern in the postembeddings by using the attention mechanism, which generates the sequenceembedding to obtain the global information at the sequence level. Finally, toenrich the knowledge of the model, embeddings of modified sequences by mimickedattackers are fed into a contrastive-learning-enhanced classification layer forsequence prediction. In essence, by capturing the local and global information(i.e., the post and sequence information) and leveraging the mimicked behaviorsof bad actors in training, ROBAD can be robust to adversarial attacks.Extensive experiments on Yelp and Wikipedia datasets show that ROBAD caneffectively detect bad actors when under state-of-the-art adversarial attacks.</description>
      <author>example@mail.com (Bing He, Mustaque Ahamad, Srijan Kumar)</author>
      <guid isPermaLink="false">2507.15067v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>PDEformer-2: A Versatile Foundation Model for Two-Dimensional Partial Differential Equations</title>
      <link>http://arxiv.org/abs/2507.15409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了PDEformer-2，一个用于二维偏微分方程（PDEs）的通用基础模型，它能够快速生成高精度的解。&lt;h4&gt;背景&lt;/h4&gt;偏微分方程在描述许多物理现象中起着核心作用，而各种科学和工程应用都需要一个灵活且可微分的PDE求解器，以快速生成足够精确的解。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够解决不同形式的PDEs，包括不同的符号形式、域形状、边界条件、变量数量和时间依赖性的PDE求解器。&lt;h4&gt;方法&lt;/h4&gt;PDEformer-2通过计算图表示接收PDE形式作为网络输入，可以编码大多数常见的PDEs，并且可以在任意时空坐标下直接查询无网格预测解。它使用了一个大型（40TB）多样化数据集进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;PDEformer-2能够同时处理不同符号形式的PDEs，且对与预训练相似的PDEs可以进行零样本预测。在适应新的未见过PDEs时，PDEformer-2比许多专业模型学习更快，并且在有限样本（少于100个）的情况下具有更小的误差。&lt;h4&gt;结论&lt;/h4&gt;PDEformer-2因其快速和可微分的特性，可以应用于逆问题，并在实验中产生了合理的系数标量和PDE场的恢复结果。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of the paper is summarized as follows: This paper introduces PDEformer-2, a versatile foundation model for two-dimensional PDEs. Based on our previous one-dimensional PDEformer-1 model, PDEformer-2 receives the PDE form as network input via computational graph representation, which has the flexibility to encode most common PDEs. The mesh-free predicted solutions can be directly queried at arbitrary spatio-temporal coordinates. A large (40TB) diverse dataset is employed to pretrain the current model, making it capable of simultaneously addressing PDEs with different symbolic forms, domain shapes, boundary conditions, number of variables, and time-dependency. Accurate zero-shot prediction is allowed for PDEs that resemble the pretraining ones. When adapted to new unseen PDEs, PDEformer-2 demonstrates faster learning than many specialized models, and has smaller errors given limited (less than 100) samples. Additionally, PDEformer-2 can be employed in inverse problems thanks to its fast and differentiable nature and produces reasonable results in our experiments to recover coefficient scalars and fields of a PDE.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partial differential equations (PDEs) play a central role in describing manyphysical phenomena. Various scientific and engineering applications demand aversatile and differentiable PDE solver that can quickly generate solutionswith adequate accuracy, and limitations of the traditional solvers andspecialized neural operators motivate the development of foundation models forsolving PDEs. This paper introduces PDEformer-2, a versatile foundation modelfor two-dimensional PDEs. Based on our previous one-dimensional PDEformer-1model, PDEformer-2 receives the PDE form as network input via computationalgraph representation, which has the flexibility to encode most common PDEs. Themesh-free predicted solutions can be directly queried at arbitraryspatio-temporal coordinates. A large (40TB) diverse dataset is employed topretrain the current model, making it capable of simultaneously addressing PDEswith different symbolic forms, domain shapes, boundary conditions, number ofvariables, and time-dependency. Accurate zero-shot prediction is allowed forPDEs that resemble the pretraining ones. When adapted to new unseen PDEs,PDEformer-2 demonstrates faster learning than many specialized models, and hassmaller errors given limited (less than 100) samples. Additionally, PDEformer-2can be employed in the inverse problems thanks to its fast and differentiablenature and produces reasonable results in our experiments to recovercoefficient scalars and fields of a PDE.</description>
      <author>example@mail.com (Zhanhong Ye, Zining Liu, Bingyang Wu, Hongjie Jiang, Leheng Chen, Minyan Zhang, Xiang Huang, Qinghe Meng. Jingyuan Zou, Hongsheng Liu, Bin Dong)</author>
      <guid isPermaLink="false">2507.15409v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Hypergraph modelling of wave scattering to speed-up material design</title>
      <link>http://arxiv.org/abs/2507.15329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文利用超图模型描述波-物质相互作用，以加速材料设计。&lt;h4&gt;背景&lt;/h4&gt;超图是一种通用的框架，可以理解复杂系统中的多阶群交互，超越了传统的成对交互。&lt;h4&gt;目的&lt;/h4&gt;通过使用超图模型，简化描述耦合振荡器、图神经网络和纠缠量子比特中多个元素之间的同时交互。&lt;h4&gt;方法&lt;/h4&gt;设计了多粒子系统的集合运算，开发了超图模型，通过不同阶数的超边紧凑地描述散射事件中多粒子之间的波干涉。&lt;h4&gt;主要发现&lt;/h4&gt;该模型具有O(N1/2)的时间复杂度和近似精度，可以设计出比传统O(N)缩放方法更优越的隐形超均匀材料。&lt;h4&gt;结论&lt;/h4&gt;通过将超图进化与传统的集体坐标方法相结合，可以保持原始精度，同时在接近最优解时实现显著加速，为可扩展的材料设计和大规模多粒子系统的紧凑解释铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：超图提供了一种通用的框架来理解复杂系统，涵盖了超越传统成对交互的不同阶数的群交互。这种建模允许简化描述耦合振荡器、图神经网络和纠缠量子比特中多个元素之间的同时交互。在这里，我们采用这种通用框架来描述波-物质相互作用以加速材料设计。通过设计多粒子系统的集合运算，我们开发了超图模型，通过不同阶数的超边紧凑地描述散射事件中多粒子之间的波干涉。这种紧凑性使得进化算法具有O(N1/2)的时间复杂度和近似精度，可以设计出比传统O(N)缩放方法更优越的隐形超均匀材料。通过将我们的超图进化与传统的集体坐标方法相结合，我们在接近最优解时实现了显著的加速，同时保持了原始精度。我们的结果为可扩展的材料设计和大规模多粒子系统的紧凑解释铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hypergraphs offer a generalized framework for understanding complex systems,covering group interactions of different orders beyond traditional pairwiseinteractions. This modelling allows for the simplified description ofsimultaneous interactions among multiple elements in coupled oscillators, graphneural networks, and entangled qubits. Here, we employ this generalizedframework to describe wave-matter interactions for material designacceleration. By devising the set operations for multiparticle systems, wedevelop the hypergraph model, which compactly describes wave interferencesamong multiparticles in scattering events by hyperedges of different orders.This compactness enables an evolutionary algorithm with O(N1/2) time complexityand approximated accuracy for designing stealthy hyperuniform materials, whichis superior to traditional methods of O(N) scaling. By hybridizing ourhypergraph evolutions to the conventional collective-coordinate method, wepreserve the original accuracy, while achieving substantial speed-up inapproaching near the optimum. Our result paves the way toward scalable materialdesign and compact interpretations of large-scale multiparticle systems.</description>
      <author>example@mail.com (Kunwoo Park, Ikbeom Lee, Seungmok Youn, Gitae Lee, Namkyoo Park, Sunkyu Yu)</author>
      <guid isPermaLink="false">2507.15329v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2507.15454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ObjectGS的对象感知框架，该框架将3D场景重建与语义理解相结合，提升了3D Gaussian Splatting技术在物体级别感知上的能力。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting技术以其高保真重建和实时新颖视图合成而闻名，但其缺乏语义理解限制了物体级别的感知。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入语义理解来提升3D场景重建的物体级别感知能力。&lt;h4&gt;方法&lt;/h4&gt;ObjectGS框架将场景中的个体对象建模为局部锚点，生成神经高斯并共享对象ID，实现精确的物体级别重建。在训练过程中，动态增长或修剪这些锚点并优化其特征，同时使用one-hot ID编码和分类损失来强制执行清晰的语义约束。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验表明，ObjectGS不仅在开放词汇和全景分割任务上优于现有技术，而且可以无缝集成到如网格提取和场景编辑等应用中。&lt;h4&gt;结论&lt;/h4&gt;ObjectGS框架有效地结合了3D场景重建与语义理解，为物体级别的感知提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D高斯散布因其高保真重建和实时新颖视图合成而著称，但其缺乏语义理解限制了物体级别的感知。在本研究中，我们提出了ObjectGS，一个对象感知框架，它将3D场景重建与语义理解统一起来。ObjectGS将场景中的个体对象建模为局部锚点，生成神经高斯并共享对象ID，以实现精确的物体级别重建。在训练过程中，我们动态增长或修剪这些锚点并优化其特征，同时使用one-hot ID编码和分类损失强制执行清晰的语义约束。通过大量实验，我们表明ObjectGS不仅在开放词汇和全景分割任务上优于现有技术，而且可以无缝集成到如网格提取和场景编辑等应用中。项目页面：https://ruijiezhu94.github.io/ObjectGS_page&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting is renowned for its high-fidelity reconstructions andreal-time novel view synthesis, yet its lack of semantic understanding limitsobject-level perception. In this work, we propose ObjectGS, an object-awareframework that unifies 3D scene reconstruction with semantic understanding.Instead of treating the scene as a unified whole, ObjectGS models individualobjects as local anchors that generate neural Gaussians and share object IDs,enabling precise object-level reconstruction. During training, we dynamicallygrow or prune these anchors and optimize their features, while a one-hot IDencoding with a classification loss enforces clear semantic constraints. Weshow through extensive experiments that ObjectGS not only outperformsstate-of-the-art methods on open-vocabulary and panoptic segmentation tasks,but also integrates seamlessly with applications like mesh extraction and sceneediting. Project page: https://ruijiezhu94.github.io/ObjectGS_page</description>
      <author>example@mail.com (Ruijie Zhu, Mulin Yu, Linning Xu, Lihan Jiang, Yixuan Li, Tianzhu Zhang, Jiangmiao Pang, Bo Dai)</author>
      <guid isPermaLink="false">2507.15454v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Visual Planning with Auxiliary Tasks and Multi-token Prediction</title>
      <link>http://arxiv.org/abs/2507.15130v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Visual Planning for Assistance (VPA)旨在通过分析用户视频进度预测完成特定目标所需的一系列用户动作。论文提出了解决长期视觉规划的两个挑战，并介绍了相应的解决方案。&lt;h4&gt;背景&lt;/h4&gt;虽然多模态大型语言模型(MLLMs)在视频理解方面取得了进展，但长期视觉规划仍然是一个难题。&lt;h4&gt;目的&lt;/h4&gt;解决在训练大型MLLMs进行视频规划任务时遇到的挑战，包括程序性标注的稀缺和预测目标的不效率。&lt;h4&gt;方法&lt;/h4&gt;引入了辅助任务增强和多令牌预测方法。通过设计相关辅助任务来增强模型规划能力，并利用多令牌预测来更明确地建模视觉规划任务的有序动作空间。&lt;h4&gt;主要发现&lt;/h4&gt;提出的VideoPlan方法在COIN和CrossTask数据集上实现了最先进的VPA性能，在预测3个未来动作时分别超越了之前的方法7.3%和3.4%。此外，该方法在Ego4D长期动作预测任务中也表现良好，不使用专门的自传式特征。&lt;h4&gt;结论&lt;/h4&gt;通过辅助任务增强和多令牌预测，VideoPlan方法在视觉规划任务中取得了显著成果，并在多个数据集上超越了现有方法。&lt;h4&gt;翻译&lt;/h4&gt;视觉规划辅助（VPA）旨在根据展示用户进展的视频预测完成指定目标所需的一系列用户动作。尽管多模态大型语言模型（MLLMs）在视频理解方面取得了令人鼓舞的成果，但长期视觉规划仍然是一个挑战。我们确定了在训练大型MLLMs进行基于视频的规划任务时的两个挑战：（1）程序性标注的稀缺，限制了模型有效地学习程序性任务动态的能力；（2）与自由形式的自然语言相比，下一个令牌预测目标在明确捕捉视觉规划的有序动作空间方面的低效。为了解决数据稀缺问题，我们引入了辅助任务增强。我们设计并训练了我们的模型，以与长期基于视频的规划相关的辅助任务（例如，目标预测）来增强模型的规划能力。为了更明确地建模视觉规划任务特有的有序动作空间，我们利用了多令牌预测，通过在训练期间使用多个头来预测多个未来的令牌来扩展传统的下一个令牌预测。我们的方法，VideoPlan，在COIN和CrossTask数据集上实现了最先进的VPA性能，在预测3个未来动作时分别超过了之前的方法7.3%和3.4%。我们进一步将我们的方法扩展到具有挑战性的Ego4D长期动作预测任务，并表明即使不使用专门的自传式特征，它也处于最先进方法之列。代码将提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Planning for Assistance (VPA) aims to predict a sequence of useractions required to achieve a specified goal based on a video showing theuser's progress. Although recent advances in multimodal large language models(MLLMs) have shown promising results in video understanding, long-horizonvisual planning remains a challenging problem. We identify two challenges intraining large MLLMs for video-based planning tasks: (1) scarcity of proceduralannotations, limiting the model's ability to learn procedural task dynamicseffectively, and (2) inefficiency of next-token prediction objective toexplicitly capture the structured action space for visual planning whencompared to free-form, natural language. To tackle data scarcity, we introduceAuxiliary Task Augmentation. We design and train our model on auxiliary tasksrelevant to long-horizon video-based planning (e.g., goal prediction) toaugment the model's planning ability. To more explicitly model the structuredaction space unique to visual planning tasks, we leverage Multi-tokenPrediction, extending traditional next-token prediction by using multiple headsto predict multiple future tokens during training. Our approach, VideoPlan,achieves state-of-the-art VPA performance on the COIN and CrossTask datasets,surpassing prior methods by 7.3% and 3.4%, respectively, when predicting 3future actions. We further extend our method to the challenging Ego4D Long-termAction Anticipation task, and show that it is on par with the state-of-the-artapproaches despite not using specialized egocentric features. Code will be madeavailable.</description>
      <author>example@mail.com (Ce Zhang, Yale Song, Ruta Desai, Michael Louis Iuzzolino, Joseph Tighe, Gedas Bertasius, Satwik Kottur)</author>
      <guid isPermaLink="false">2507.15130v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?</title>
      <link>http://arxiv.org/abs/2507.15321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Webpage: https://zhyever.github.io/benchdepth&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基准BenchDepth，用于评估深度学习中的深度基础模型（DFMs），通过五个下游代理任务来评估DFMs的实际应用价值。&lt;h4&gt;背景&lt;/h4&gt;深度估计是计算机视觉中的基本任务，深度学习在深度基础模型方面取得了进展，但其评估因现有协议的不一致性而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的基准BenchDepth，以评估DFMs的实际应用价值，避免传统评估协议中的偏差和问题。&lt;h4&gt;方法&lt;/h4&gt;BenchDepth通过五个下游代理任务（深度补全、立体匹配、单目前向3D场景重建、SLAM和视觉语言空间理解）来评估DFMs。&lt;h4&gt;主要发现&lt;/h4&gt;对八个最先进的DFMs进行了基准测试，并深入分析了关键发现和观察结果。&lt;h4&gt;结论&lt;/h4&gt;希望这项工作能激发社区对深度模型评估最佳实践的进一步讨论，并为未来深度估计的研究和进步铺平道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth estimation is a fundamental task in computer vision with diverseapplications. Recent advancements in deep learning have led to powerful depthfoundation models (DFMs), yet their evaluation remains challenging due toinconsistencies in existing protocols. Traditional benchmarks rely onalignment-based metrics that introduce biases, favor certain depthrepresentations, and complicate fair comparisons. In this work, we proposeBenchDepth, a new benchmark that evaluates DFMs through five carefully selecteddownstream proxy tasks: depth completion, stereo matching, monocularfeed-forward 3D scene reconstruction, SLAM, and vision-language spatialunderstanding. Unlike conventional evaluation protocols, our approach assessesDFMs based on their practical utility in real-world applications, bypassingproblematic alignment procedures. We benchmark eight state-of-the-art DFMs andprovide an in-depth analysis of key findings and observations. We hope our worksparks further discussion in the community on best practices for depth modelevaluation and paves the way for future research and advancements in depthestimation.</description>
      <author>example@mail.com (Zhenyu Li, Haotong Lin, Jiashi Feng, Peter Wonka, Bingyi Kang)</author>
      <guid isPermaLink="false">2507.15321v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Disentangling Homophily and Heterophily in Multimodal Graph Clustering</title>
      <link>http://arxiv.org/abs/2507.15253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Appear in ACM Multimedia 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Disentangled Multimodal Graph Clustering (DMGC)的新框架，用于多模态图聚类，以解决多模态图中混合邻域模式的问题。&lt;h4&gt;背景&lt;/h4&gt;多模态图结合了非结构化异构数据和结构化连接，具有实际应用价值，但在无监督学习中尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;研究多模态图聚类，填补这一关键差距。&lt;h4&gt;方法&lt;/h4&gt;提出DMGC框架，将混合图分解为两个互补视图：一个增强同质性的图，捕获跨模态类的一致性；一个异质性感知的图，保留模态特定的类间差异。引入多模态双频度融合机制，通过双遍历策略联合过滤这些分解图，实现有效的多模态集成并减轻类别混淆。使用自监督对齐目标指导学习过程，无需标签。&lt;h4&gt;主要发现&lt;/h4&gt;DMGC在多模态和多关系图数据集上的实验表明，它实现了最先进的性能，突出了其在不同设置下的有效性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;DMGC是一种有效的多模态图聚类方法，在多种数据集上表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal graphs, which integrate unstructured heterogeneous data withstructured interconnections, offer substantial real-world utility but remaininsufficiently explored in unsupervised learning. In this work, we initiate thestudy of multimodal graph clustering, aiming to bridge this critical gap.Through empirical analysis, we observe that real-world multimodal graphs oftenexhibit hybrid neighborhood patterns, combining both homophilic andheterophilic relationships. To address this challenge, we propose a novelframework -- \textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- whichdecomposes the original hybrid graph into two complementary views: (1) ahomophily-enhanced graph that captures cross-modal class consistency, and (2)heterophily-aware graphs that preserve modality-specific inter-classdistinctions. We introduce a \emph{Multimodal Dual-frequency Fusion} mechanismthat jointly filters these disentangled graphs through a dual-pass strategy,enabling effective multimodal integration while mitigating category confusion.Our self-supervised alignment objectives further guide the learning processwithout requiring labels. Extensive experiments on both multimodal andmulti-relational graph datasets demonstrate that DMGC achieves state-of-the-artperformance, highlighting its effectiveness and generalizability across diversesettings. Our code is available at https://github.com/Uncnbb/DMGC.</description>
      <author>example@mail.com (Zhaochen Guo, Zhixiang Shen, Xuanting Xie, Liangjian Wen, Zhao Kang)</author>
      <guid isPermaLink="false">2507.15253v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Blended Point Cloud Diffusion for Localized Text-guided Shape Editing</title>
      <link>http://arxiv.org/abs/2507.15399v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025. Project Page:  https://tau-vailab.github.io/BlendedPC/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图像修复的框架，用于对以点云表示的3D形状进行局部编辑，通过引入结构引导和坐标混合算法，实现了对3D形状的精细编辑，同时保证了形状的全局一致性和对文本描述的遵循。&lt;h4&gt;背景&lt;/h4&gt;现有技术在进行局部修改3D形状时难以保持全局一致性。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，在局部修改3D形状的同时保持其全局一致性，并遵循文本描述。&lt;h4&gt;方法&lt;/h4&gt;利用3D扩散模型实现局部形状编辑，通过部分条件形状提供结构指导；在推理过程中采用坐标混合算法平衡形状重建和噪声修复。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个指标上优于其他技术，包括对原始形状的保真度和对文本描述的遵循。&lt;h4&gt;结论&lt;/h4&gt;提出的框架能够有效实现3D形状的精细编辑，同时保持形状的全局一致性和对文本描述的遵循，避免了复杂的逆运算过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Natural language offers a highly intuitive interface for enabling localizedfine-grained edits of 3D shapes. However, prior works face challenges inpreserving global coherence while locally modifying the input 3D shape. In thiswork, we introduce an inpainting-based framework for editing shapes representedas point clouds. Our approach leverages foundation 3D diffusion models forachieving localized shape edits, adding structural guidance in the form of apartial conditional shape, ensuring that other regions correctly preserve theshape's identity. Furthermore, to encourage identity preservation also withinthe local edited region, we propose an inference-time coordinate blendingalgorithm which balances reconstruction of the full shape with inpainting at aprogression of noise levels during the inference process. Our coordinateblending algorithm seamlessly blends the original shape with its editedversion, enabling a fine-grained editing of 3D shapes, all while circumventingthe need for computationally expensive and often inaccurate inversion.Extensive experiments show that our method outperforms alternative techniquesacross a wide range of metrics that evaluate both fidelity to the originalshape and also adherence to the textual description.</description>
      <author>example@mail.com (Etai Sella, Noam Atia, Ron Mokady, Hadar Averbuch-Elor)</author>
      <guid isPermaLink="false">2507.15399v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>DeSamba: Decoupled Spectral Adaptive Framework for 3D Multi-Sequence MRI Lesion Classification</title>
      <link>http://arxiv.org/abs/2507.15487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 figures, 3 tables, submitted to AAAI2026&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DeSamba的框架，用于提取分离表示并自适应融合空间和频谱特征，以提高多序列MRI数据在医学图像中3D病变分类的准确性。&lt;h4&gt;背景&lt;/h4&gt;MRI序列提供了丰富的空间和频谱域信息，对于医学图像中病变的准确分类至关重要。然而，有效地整合多序列MRI数据以进行稳健的3D病变分类仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架DeSamba，旨在通过提取分离表示和自适应融合空间和频谱特征来提高病变分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;DeSamba包括一个分离表示学习模块（DRLM）和一个频谱自适应调制块（SAMB）。DRLM通过自我重建和交叉重建分离不同MRI序列的特征，而SAMB允许根据病变特征动态融合频谱和空间信息。&lt;h4&gt;主要发现&lt;/h4&gt;DeSamba在两个临床相关3D数据集上进行了评估。在包含6类脊柱转移的648个样本数据集上，DeSamba在外部验证集上实现了62.10%的Top-1准确率、63.62%的F1分数、87.71%的AUC和93.55%的Top-3准确率。在包含251个样本的脊柱炎数据集上，DeSamba在内部和外部验证集上分别实现了70.00%/64.52%的准确率和74.75/73.88的AUC。消融研究显示，DRLM和SAMB都对整体性能有显著贡献，与基线相比有超过10%的相对改进。&lt;h4&gt;结论&lt;/h4&gt;DeSamba被证明是一种通用的有效解决方案，可用于多序列医学图像中的3D病变分类。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Magnetic Resonance Imaging (MRI) sequences provide rich spatial and frequency domain information, which is crucial for accurate lesion classification in medical imaging. However, effectively integrating multi-sequence MRI data for robust 3D lesion classification remains a challenge. In this paper, we propose DeSamba (Decoupled Spectral Adaptive Network and Mamba-Based Model), a novel framework designed to extract decoupled representations and adaptively fuse spatial and spectral features for lesion classification. DeSamba introduces a Decoupled Representation Learning Module (DRLM) that decouples features from different MRI sequences through self-reconstruction and cross-reconstruction, and a Spectral Adaptive Modulation Block (SAMB) within the proposed SAMNet, enabling dynamic fusion of spectral and spatial information based on lesion characteristics. We evaluate DeSamba on two clinically relevant 3D datasets. On a six-class spinal metastasis dataset (n=1,448), DeSamba achieves 62.10% Top-1 accuracy, 63.62% F1-score, 87.71% AUC, and 93.55% Top-3 accuracy on an external validation set (n=372), outperforming all state-of-the-art (SOTA) baselines. On a spondylitis dataset (n=251) involving a challenging binary classification task, DeSamba achieves 70.00%/64.52% accuracy and 74.75/73.88 AUC on internal and external validation sets, respectively. Ablation studies demonstrate that both DRLM and SAMB significantly contribute to overall performance, with over 10% relative improvement compared to the baseline. Our results highlight the potential of DeSamba as a generalizable and effective solution for 3D lesion classification in multi-sequence medical imaging.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Magnetic Resonance Imaging (MRI) sequences provide rich spatial and frequencydomain information, which is crucial for accurate lesion classification inmedical imaging. However, effectively integrating multi-sequence MRI data forrobust 3D lesion classification remains a challenge. In this paper, we proposeDeSamba (Decoupled Spectral Adaptive Network and Mamba-Based Model), a novelframework designed to extract decoupled representations and adaptively fusespatial and spectral features for lesion classification. DeSamba introduces aDecoupled Representation Learning Module (DRLM) that decouples features fromdifferent MRI sequences through self-reconstruction and cross-reconstruction,and a Spectral Adaptive Modulation Block (SAMB) within the proposed SAMNet,enabling dynamic fusion of spectral and spatial information based on lesioncharacteristics. We evaluate DeSamba on two clinically relevant 3D datasets. Ona six-class spinal metastasis dataset (n=1,448), DeSamba achieves 62.10% Top-1accuracy, 63.62% F1-score, 87.71% AUC, and 93.55% Top-3 accuracy on an externalvalidation set (n=372), outperforming all state-of-the-art (SOTA) baselines. Ona spondylitis dataset (n=251) involving a challenging binary classificationtask, DeSamba achieves 70.00%/64.52% accuracy and 74.75/73.88 AUC on internaland external validation sets, respectively. Ablation studies demonstrate thatboth DRLM and SAMB significantly contribute to overall performance, with over10% relative improvement compared to the baseline. Our results highlight thepotential of DeSamba as a generalizable and effective solution for 3D lesionclassification in multi-sequence medical imaging.</description>
      <author>example@mail.com (Dezhen Wang, Sheng Miao, Rongxin Chai, Jiufa Cui)</author>
      <guid isPermaLink="false">2507.15487v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving</title>
      <link>http://arxiv.org/abs/2507.15266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为VLM-UDMC的视觉语言模型增强的统一决策与运动控制框架，用于城市自动驾驶中的场景理解和风险感知注意力，以提高驾驶决策的安全性和有效性。&lt;h4&gt;背景&lt;/h4&gt;场景理解和风险感知注意力对于人类驾驶员做出安全有效的驾驶决策至关重要。&lt;h4&gt;目的&lt;/h4&gt;模仿人类驾驶员的认知能力，在确保透明度和可解释性的同时，提高城市自动驾驶的安全性。&lt;h4&gt;方法&lt;/h4&gt;VLM-UDMC框架结合场景推理和风险感知洞察，动态重构下游快速系统的最优运动规划。使用上下文感知势函数对实时环境变化进行编码，并采用两步推理策略和检索增强生成（RAG）来处理多模态输入并检索上下文知识，同时使用轻量级多核分解LSTM进行实时轨迹预测。&lt;h4&gt;主要发现&lt;/h4&gt;VLM-UDMC框架通过场景理解和注意力分解有效地支持了合理的驾驶决策，从而提高了城市驾驶的整体性能。&lt;h4&gt;结论&lt;/h4&gt;VLM-UDMC框架在模拟和真实世界实验中验证了其有效性，并可通过GitHub上的开源项目获取。&lt;h4&gt;翻译&lt;/h4&gt;Scene understanding and risk-aware attentions are crucial for human drivers to make safe and effective driving decisions. To imitate this cognitive ability in urban autonomous driving while ensuring the transparency and interpretability, we propose a vision-language model (VLM)-enhanced unified decision-making and motion control framework, named VLM-UDMC. This framework incorporates scene reasoning and risk-aware insights into an upper-level slow system, which dynamically reconfigures the optimal motion planning for the downstream fast system. The reconfiguration is based on real-time environmental changes, which are encoded through context-aware potential functions. More specifically, the upper-level slow system employs a two-step reasoning policy with Retrieval-Augmented Generation (RAG), leveraging foundation models to process multimodal inputs and retrieve contextual knowledge, thereby generating risk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTM provides real-time trajectory predictions for heterogeneous traffic participants by extracting smoother trend representations for short-horizon trajectory prediction. The effectiveness of the proposed VLM-UDMC framework is verified via both simulations and real-world experiments with a full-size autonomous vehicle. It is demonstrated that the presented VLM-UDMC effectively leverages scene understanding and attention decomposition for rational driving decisions, thus improving the overall urban driving performance. Our open-source project is available at https://github.com/henryhcliu/vlmudmc.git.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scene understanding and risk-aware attentions are crucial for human driversto make safe and effective driving decisions. To imitate this cognitive abilityin urban autonomous driving while ensuring the transparency andinterpretability, we propose a vision-language model (VLM)-enhanced unifieddecision-making and motion control framework, named VLM-UDMC. This frameworkincorporates scene reasoning and risk-aware insights into an upper-level slowsystem, which dynamically reconfigures the optimal motion planning for thedownstream fast system. The reconfiguration is based on real-time environmentalchanges, which are encoded through context-aware potential functions. Morespecifically, the upper-level slow system employs a two-step reasoning policywith Retrieval-Augmented Generation (RAG), leveraging foundation models toprocess multimodal inputs and retrieve contextual knowledge, thereby generatingrisk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTMprovides real-time trajectory predictions for heterogeneous trafficparticipants by extracting smoother trend representations for short-horizontrajectory prediction. The effectiveness of the proposed VLM-UDMC framework isverified via both simulations and real-world experiments with a full-sizeautonomous vehicle. It is demonstrated that the presented VLM-UDMC effectivelyleverages scene understanding and attention decomposition for rational drivingdecisions, thus improving the overall urban driving performance. Ouropen-source project is available at https://github.com/henryhcliu/vlmudmc.git.</description>
      <author>example@mail.com (Haichao Liu, Haoren Guo, Pei Liu, Benshan Ma, Yuxiang Zhang, Jun Ma, Tong Heng Lee)</author>
      <guid isPermaLink="false">2507.15266v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script</title>
      <link>http://arxiv.org/abs/2507.15142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在阿姆哈拉语自然语言处理（NLP）中对同音字进行规范化的影响，并提出了在模型预测后进行规范化的方法。&lt;h4&gt;背景&lt;/h4&gt;同音字规范化在阿姆哈拉语NLP中被用作预处理步骤，可能会提升自动指标报告的性能，但导致模型难以理解同一种语言的多种书写形式。&lt;h4&gt;目的&lt;/h4&gt;研究规范化对使用古吉兹文字语言的影响，并探索在模型预测后应用规范化以提升模型性能。&lt;h4&gt;方法&lt;/h4&gt;进行单语种训练和跨语言迁移实验，并提出了在模型预测后应用规范化的干预措施。&lt;h4&gt;主要发现&lt;/h4&gt;采用后推理规范化方案，在保持训练语言特征的同时，可以实现BLEU评分提升至1.03。&lt;h4&gt;结论&lt;/h4&gt;本研究有助于更广泛的技术促进语言变化讨论，并呼吁更多的语言意识干预措施。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Homophone normalization, where characters that have the same sound in a writing script are mapped to one character, is a pre-processing step applied in Amharic Natural Language Processing (NLP) literature. While this may improve performance reported by automatic metrics, it also results in models that are not able to understand different forms of writing in a single language. Further, there might be impacts in transfer learning, where models trained on normalized data do not generalize well to other languages. In this paper, we experiment with monolingual training and cross-lingual transfer to understand the impacts of normalization on languages that use the Ge'ez script. We then propose a post-inference intervention in which normalization is applied to model predictions instead of training data. With our simple scheme of post-inference normalization, we show that we can achieve an increase in BLEU score of up to 1.03 while preserving language features in training. Our work contributes to the broader discussion on technology-facilitated language change and calls for more language-aware interventions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Homophone normalization, where characters that have the same sound in awriting script are mapped to one character, is a pre-processing step applied inAmharic Natural Language Processing (NLP) literature. While this may improveperformance reported by automatic metrics, it also results in models that arenot able to understand different forms of writing in a single language.Further, there might be impacts in transfer learning, where models trained onnormalized data do not generalize well to other languages. In this paper, weexperiment with monolingual training and cross-lingual transfer to understandthe impacts of normalization on languages that use the Ge'ez script. We thenpropose a post-inference intervention in which normalization is applied tomodel predictions instead of training data. With our simple scheme ofpost-inference normalization, we show that we can achieve an increase in BLEUscore of up to 1.03 while preserving language features in training. Our workcontributes to the broader discussion on technology-facilitated language changeand calls for more language-aware interventions.</description>
      <author>example@mail.com (Hellina Hailu Nigatu, Atnafu Lambebo Tonja, Henok Biadglign Ademtew, Hizkel Mitiku Alemayehu, Negasi Haile Abadi, Tadesse Destaw Belay, Seid Muhie Yimam)</author>
      <guid isPermaLink="false">2507.15142v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Open-set Cross Modal Generalization via Multimodal Unified Representation</title>
      <link>http://arxiv.org/abs/2507.14935v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文扩展了跨模态泛化（CMG）到开放集环境，提出了更具挑战性的开放集跨模态泛化（OSCMG）任务。&lt;h4&gt;背景&lt;/h4&gt;现有的跨模态统一表示工作未考虑开放集环境，且之前的封闭集跨模态评估存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出OSCMG任务，以评估开放集条件下的多模态统一表示，并解决跨模态知识迁移和未见过的新模态类别上的鲁棒泛化问题。&lt;h4&gt;方法&lt;/h4&gt;提出了MICU，包括两个关键组件：细粒度-粗粒度掩码多模态InfoNCE（FCMI）和跨模态统一拼图（CUJP）。FCMI通过在整体语义和时序级别应用对比学习以及引入掩码来增强多模态对齐。CUJP通过结合模态无关的特征选择和自监督学习来增强特征多样性和模型不确定性，从而加强模型处理开放集任务中未知类别的能力。&lt;h4&gt;主要发现&lt;/h4&gt;在CMG和提出的OSCMG上的广泛实验验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对于处理开放集环境中的跨模态统一表示问题具有显著效果，并通过实验证明了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;This paper extends Cross Modal Generalization (CMG) to open-set environments by proposing the more challenging Open-set Cross Modal Generalization (OSCMG) task. This task evaluates multimodal unified representations in open-set conditions, addressing the limitations of prior closed-set cross-modal evaluations. OSCMG requires not only cross-modal knowledge transfer but also robust generalization to unseen classes within new modalities, a scenario frequently encountered in real-world applications. Existing multimodal unified representation work lacks consideration for open-set environments. To tackle this, we propose MICU, comprising two key components: Fine-Coarse Masked multimodal InfoNCE (FCMI) and Cross modal Unified Jigsaw Puzzles (CUJP). FCMI enhances multimodal alignment by applying contrastive learning at both holistic semantic and temporal levels, incorporating masking to enhance generalization. CUJP enhances feature diversity and model uncertainty by integrating modality-agnostic feature selection with self-supervised learning, thereby strengthening the model's ability to handle unknown categories in open-set tasks. Extensive experiments on CMG and the newly proposed OSCMG validate the effectiveness of our approach. The code is available at https://github.com/haihuangcode/CMG.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper extends Cross Modal Generalization (CMG) to open-set environmentsby proposing the more challenging Open-set Cross Modal Generalization (OSCMG)task. This task evaluates multimodal unified representations in open-setconditions, addressing the limitations of prior closed-set cross-modalevaluations. OSCMG requires not only cross-modal knowledge transfer but alsorobust generalization to unseen classes within new modalities, a scenariofrequently encountered in real-world applications. Existing multimodal unifiedrepresentation work lacks consideration for open-set environments. To tacklethis, we propose MICU, comprising two key components: Fine-Coarse Maskedmultimodal InfoNCE (FCMI) and Cross modal Unified Jigsaw Puzzles (CUJP). FCMIenhances multimodal alignment by applying contrastive learning at both holisticsemantic and temporal levels, incorporating masking to enhance generalization.CUJP enhances feature diversity and model uncertainty by integratingmodality-agnostic feature selection with self-supervised learning, therebystrengthening the model's ability to handle unknown categories in open-settasks. Extensive experiments on CMG and the newly proposed OSCMG validate theeffectiveness of our approach. The code is available athttps://github.com/haihuangcode/CMG.</description>
      <author>example@mail.com (Hai Huang, Yan Xia, Shulei Wang, Hanting Wang, Minghui Fang, Shengpeng Ji, Sashuai Zhou, Tao Jin, Zhou Zhao)</author>
      <guid isPermaLink="false">2507.14935v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>MinCD-PnP: Learning 2D-3D Correspondences with Approximate Blind PnP</title>
      <link>http://arxiv.org/abs/2507.15257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于近似盲PnP的对应学习新方法，用于解决图像到点云（I2P）配准问题，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;图像到点云配准是计算机视觉中的基本问题，涉及图像和点云之间的2D-3D对应关系建立。传统的基于PnP的方法对噪声和异常值敏感，影响了对应学习的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出一种鲁棒的对应学习方法，以解决传统方法对噪声和异常值敏感的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种简化的近似盲PnP方法（MinCD-PnP），通过最小化学习到的2D和3D关键点之间的Chamfer距离来实现。设计了一个轻量级的多任务学习模块MinCD-Net，可以轻松集成到现有的I2P注册架构中。&lt;h4&gt;主要发现&lt;/h4&gt;MinCD-Net在7-Scenes、RGBD-V2、ScanNet和自收集数据集上的实验表明，该方法优于现有方法，并在跨场景和跨数据集设置中实现了更高的内点比（IR）和配准召回率（RR）。&lt;h4&gt;结论&lt;/h4&gt;MinCD-Net是一种有效的I2P注册方法，能够提高配准的鲁棒性和准确性。&lt;h4&gt;翻译&lt;/h4&gt;Image-to-point-cloud (I2P) registration is a fundamental problem in computervision, focusing on establishing 2D-3D correspondences between an image and a point cloud. The differential perspective-n-point (PnP) has been widely used to supervise I2P registration networks by enforcing the projective constraints on 2D-3D correspondences. However, differential PnP is highly sensitive to noise and outliers in the predicted correspondences. This issue hinders the effectiveness of correspondence learning. Inspired by the robustness of blind PnP against noise and outliers in correspondences, we propose an approximated blind PnP based correspondence learning approach. To mitigate the high computational cost of blind PnP, we simplify blind PnP to an amenable task of minimizing Chamfer distance between learned 2D and 3D keypoints, called MinCD-PnP. To effectively solve MinCD-PnP, we design a lightweight multi-task learning module, named as MinCD-Net, which can be easily integrated into the existing I2P registration architectures. Extensive experiments on 7-Scenes, RGBD-V2, ScanNet, and self-collected datasets demonstrate that MinCD-Net outperforms state-of-the-art methods and achieves a higher inlier ratio (IR) and registration recall (RR) in both cross-scene and cross-dataset settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-to-point-cloud (I2P) registration is a fundamental problem in computervision, focusing on establishing 2D-3D correspondences between an image and apoint cloud. The differential perspective-n-point (PnP) has been widely used tosupervise I2P registration networks by enforcing the projective constraints on2D-3D correspondences. However, differential PnP is highly sensitive to noiseand outliers in the predicted correspondences. This issue hinders theeffectiveness of correspondence learning. Inspired by the robustness of blindPnP against noise and outliers in correspondences, we propose an approximatedblind PnP based correspondence learning approach. To mitigate the highcomputational cost of blind PnP, we simplify blind PnP to an amenable task ofminimizing Chamfer distance between learned 2D and 3D keypoints, calledMinCD-PnP. To effectively solve MinCD-PnP, we design a lightweight multi-tasklearning module, named as MinCD-Net, which can be easily integrated into theexisting I2P registration architectures. Extensive experiments on 7-Scenes,RGBD-V2, ScanNet, and self-collected datasets demonstrate that MinCD-Netoutperforms state-of-the-art methods and achieves a higher inlier ratio (IR)and registration recall (RR) in both cross-scene and cross-dataset settings.</description>
      <author>example@mail.com (Pei An, Jiaqi Yang, Muyao Peng, You Yang, Qiong Liu, Xiaolin Wu, Liangliang Nan)</author>
      <guid isPermaLink="false">2507.15257v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>DAViD: Data-efficient and Accurate Vision Models from Synthetic Data</title>
      <link>http://arxiv.org/abs/2507.15365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在小型高保真合成数据集上训练模型的方法，这种方法在保持准确度的同时提高了效率。&lt;h4&gt;背景&lt;/h4&gt;目前，以人为中心的计算机视觉技术在高精度和鲁棒性方面取得了显著进展，但这些模型通常需要庞大的数据集、昂贵的训练和计算密集型的推理。&lt;h4&gt;目的&lt;/h4&gt;证明在小型但高保真的合成数据集上训练模型是可行的，且不会损失准确度。&lt;h4&gt;方法&lt;/h4&gt;使用合成训练数据，提供详细程度高且标签完美的数据，同时确保数据来源、使用权利和用户同意的明确保证。通过程序性数据合成，可以显式控制数据多样性，以解决模型训练中的不公平性。&lt;h4&gt;主要发现&lt;/h4&gt;在真实输入图像上的大量定量评估表明，模型在三个密集预测任务（深度估计、表面法线估计和软前景分割）中均保持了高精度。与相似精度的基础模型相比，我们的模型在训练和推理成本上只需极小的一部分。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法可以有效地在小型合成数据集上训练模型，为以人为中心的计算机视觉领域提供了一种新的高效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：目前以人为中心的计算机视觉技术在多样化的任务中实现了高精度和鲁棒性。在此领域中最有效的模型拥有数十亿个参数，因此需要极其庞大的数据集、昂贵的训练机制和计算密集型的推理。本文展示了在小型但高保真的合成数据集上训练模型是可能的，且不会降低准确度。使用合成训练数据为我们提供了卓越的细节水平和完美的标签，同时提供了对数据来源、使用权利和用户同意的强大保证。程序性数据合成还为我们提供了对数据多样性的显式控制，我们可以利用它来解决我们训练的模型中的不公平性。在真实输入图像上的大量定量评估显示了我们在三个密集预测任务（深度估计、表面法线估计和软前景分割）中的模型精度。与相似精度的基础模型相比，我们的模型在训练和推理成本上只需极小的一部分。我们的人为中心的合成数据集和训练模型可在https://aka.ms/DAViD获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The state of the art in human-centric computer vision achieves high accuracyand robustness across a diverse range of tasks. The most effective models inthis domain have billions of parameters, thus requiring extremely largedatasets, expensive training regimes, and compute-intensive inference. In thispaper, we demonstrate that it is possible to train models on much smaller buthigh-fidelity synthetic datasets, with no loss in accuracy and higherefficiency. Using synthetic training data provides us with excellent levels ofdetail and perfect labels, while providing strong guarantees for dataprovenance, usage rights, and user consent. Procedural data synthesis alsoprovides us with explicit control on data diversity, that we can use to addressunfairness in the models we train. Extensive quantitative assessment on realinput images demonstrates accuracy of our models on three dense predictiontasks: depth estimation, surface normal estimation, and soft foregroundsegmentation. Our models require only a fraction of the cost of training andinference when compared with foundational models of similar accuracy. Ourhuman-centric synthetic dataset and trained models are available athttps://aka.ms/DAViD.</description>
      <author>example@mail.com (Fatemeh Saleh, Sadegh Aliakbarian, Charlie Hewitt, Lohit Petikam, Xiao-Xian, Antonio Criminisi, Thomas J. Cashman, Tadas Baltrušaitis)</author>
      <guid isPermaLink="false">2507.15365v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Spatio-Temporal Demand Prediction for Food Delivery Using Attention-Driven Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.15246v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于注意力机制的图神经网络框架，用于捕捉食品配送环境中的时空依赖关系，以提高食品配送平台的效率和响应能力。&lt;h4&gt;背景&lt;/h4&gt;食品配送平台的效率与响应能力受到订单量在空间和时间上的异质性和波动性的直接影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种模型来准确预测未来订单量，以支持食品配送平台的运营决策。&lt;h4&gt;方法&lt;/h4&gt;构建了一个将食品配送环境建模为图的框架，节点代表城市配送区域，边代表历史数据中得出的空间邻近性和区域间订单流动模式。采用注意力机制动态权衡邻近区域的影响，并联合学习时空趋势。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界食品配送数据集上的实验表明，所提出的模型在预测未来订单量方面具有较高的准确性。&lt;h4&gt;结论&lt;/h4&gt;该框架为城市食品配送运营中的主动车队定位、资源分配和调度优化提供了一个可扩展和自适应的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Accurate demand forecasting is critical for enhancing the efficiency and responsiveness of food delivery platforms, where spatial heterogeneity and temporal fluctuations in order volumes directly influence operational decisions. This paper proposes an attention-based Graph Neural Network framework that captures spatial-temporal dependencies by modeling the food delivery environment as a graph. In this graph, nodes represent urban delivery zones, while edges reflect spatial proximity and inter-regional order flow patterns derived from historical data. The attention mechanism dynamically weighs the influence of neighboring zones, enabling the model to focus on the most contextually relevant areas during prediction. Temporal trends are jointly learned alongside spatial interactions, allowing the model to adapt to evolving demand patterns. Extensive experiments on real-world food delivery datasets demonstrate the superiority of the proposed model in forecasting future order volumes with high accuracy. The framework offers a scalable and adaptive solution to support proactive fleet positioning, resource allocation, and dispatch optimization in urban food delivery operations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate demand forecasting is critical for enhancing the efficiency andresponsiveness of food delivery platforms, where spatial heterogeneity andtemporal fluctuations in order volumes directly influence operationaldecisions. This paper proposes an attention-based Graph Neural Networkframework that captures spatial-temporal dependencies by modeling the fooddelivery environment as a graph. In this graph, nodes represent urban deliveryzones, while edges reflect spatial proximity and inter-regional order flowpatterns derived from historical data. The attention mechanism dynamicallyweighs the influence of neighboring zones, enabling the model to focus on themost contextually relevant areas during prediction. Temporal trends are jointlylearned alongside spatial interactions, allowing the model to adapt to evolvingdemand patterns. Extensive experiments on real-world food delivery datasetsdemonstrate the superiority of the proposed model in forecasting future ordervolumes with high accuracy. The framework offers a scalable and adaptivesolution to support proactive fleet positioning, resource allocation, anddispatch optimization in urban food delivery operations.</description>
      <author>example@mail.com (Rabia Latief Bhat, Iqra Altaf Gillani)</author>
      <guid isPermaLink="false">2507.15246v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding</title>
      <link>http://arxiv.org/abs/2507.15028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025; Project page: https://zhangyuanhan-ai.github.io/video-tt/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了视频思维测试（Video-TT），旨在评估视频大型语言模型（video LLMs）在视频理解方面的能力，特别是其与人类智能在保持正确性和鲁棒性方面的差距。&lt;h4&gt;背景&lt;/h4&gt;视频理解需要正确性和鲁棒性，而正确性是鲁棒性的基础。尽管视频大型语言模型取得了进展，但现有的基准测试未能充分反映这些模型在视频理解上与人类智能之间的差距。&lt;h4&gt;目的&lt;/h4&gt;通过Video-TT测试，评估video LLMs在处理真实世界视频时的有效性，并评估其理解复杂视觉叙事和应对自然对抗问题的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;Video-TT包括1,000个YouTube Shorts视频，每个视频附带一个开放式问题和四个对抗性问题，以测试视觉和叙事的复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果显示，video LLMs与人类在视频理解方面的表现之间存在显著差距。&lt;h4&gt;结论&lt;/h4&gt;该研究指出，现有的video LLMs在视频理解方面仍存在与人类智能相比的不足，特别是在处理复杂视觉叙事和应对对抗性问题时。&lt;h4&gt;翻译&lt;/h4&gt;Human intelligence requires correctness and robustness, with the former being foundational for the latter. In video understanding, correctness ensures the accurate interpretation of visual content, and robustness maintains consistent performance in challenging conditions. Despite advances in video large languagemodels (video LLMs), existing benchmarks inadequately reflect the gap between these models and human intelligence in maintaining correctness and robustness in video interpretation. We introduce the Video Thinking Test (Video-TT), to assess if video LLMs can interpret real-world videos as effectively as humans. Video-TT reflects genuine gaps in understanding complex visual narratives, and evaluates robustness against natural adversarial questions. Video-TT comprises 1,000 YouTube Shorts videos, each with one open-ended question and four adversarial questions that probe visual and narrative complexity. Our evaluation shows a significant gap between video LLMs and human performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human intelligence requires correctness and robustness, with the former beingfoundational for the latter. In video understanding, correctness ensures theaccurate interpretation of visual content, and robustness maintains consistentperformance in challenging conditions. Despite advances in video large languagemodels (video LLMs), existing benchmarks inadequately reflect the gap betweenthese models and human intelligence in maintaining correctness and robustnessin video interpretation. We introduce the Video Thinking Test (Video-TT), toassess if video LLMs can interpret real-world videos as effectively as humans.Video-TT reflects genuine gaps in understanding complex visual narratives, andevaluates robustness against natural adversarial questions. Video-TT comprises1,000 YouTube Shorts videos, each with one open-ended question and fouradversarial questions that probe visual and narrative complexity. Ourevaluation shows a significant gap between video LLMs and human performance.</description>
      <author>example@mail.com (Yuanhan Zhang, Yunice Chew, Yuhao Dong, Aria Leo, Bo Hu, Ziwei Liu)</author>
      <guid isPermaLink="false">2507.15028v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper</title>
      <link>http://arxiv.org/abs/2507.15062v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  More videos can be found on our  website:https://binghao-huang.github.io/touch_in_the_wild/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种便携、轻量级的带有集成触觉传感器的手爪，能够同步收集不同环境中的视觉和触觉数据，并开发了一个跨模态表示学习框架，通过视觉和触觉信号的整合，实现可解释的表示，支持基于多模态反馈的精确机器人操作。&lt;h4&gt;背景&lt;/h4&gt;便携式手爪在收集人类演示中越来越受欢迎，但现有设计大多缺乏触觉传感功能，而触觉反馈在精确操作中扮演着关键角色。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同步收集视觉和触觉数据的手爪，并设计一个能够整合视觉和触觉信号的学习框架。&lt;h4&gt;方法&lt;/h4&gt;设计了一种带有触觉传感器的手爪，并提出了一个跨模态表示学习框架，用于整合和解析视觉和触觉信号。&lt;h4&gt;主要发现&lt;/h4&gt;该框架允许产生专注于物理交互相关接触区域的可解释表示，有助于下游操作任务中的策略学习，并提高了在测试管插入和移液管液体转移等精细任务中的准确性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了所提出的方法在外部干扰下能够提高机器人操作的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;A portable, lightweight gripper with integrated tactile sensors is presented that enables synchronized collection of visual and tactile data in diverse real-world settings. A cross-modal representation learning framework that integrates visual and tactile signals while preserving their distinct characteristics is proposed. The learning procedure allows the emergence of interpretable representations that consistently focus on contacting regions relevant for physical interactions. When used for downstream manipulation tasks, these representations enable more efficient and effective policy learning, supporting precise robotic manipulation based on multimodal feedback. The approach is validated on fine-grained tasks such as test tube insertion and pipette-based fluid transfer, demonstrating improved accuracy and robustness under external disturbances.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Handheld grippers are increasingly used to collect human demonstrations dueto their ease of deployment and versatility. However, most existing designslack tactile sensing, despite the critical role of tactile feedback in precisemanipulation. We present a portable, lightweight gripper with integratedtactile sensors that enables synchronized collection of visual and tactile datain diverse, real-world, and in-the-wild settings. Building on this hardware, wepropose a cross-modal representation learning framework that integrates visualand tactile signals while preserving their distinct characteristics. Thelearning procedure allows the emergence of interpretable representations thatconsistently focus on contacting regions relevant for physical interactions.When used for downstream manipulation tasks, these representations enable moreefficient and effective policy learning, supporting precise roboticmanipulation based on multimodal feedback. We validate our approach onfine-grained tasks such as test tube insertion and pipette-based fluidtransfer, demonstrating improved accuracy and robustness under externaldisturbances. Our project page is available athttps://binghao-huang.github.io/touch_in_the_wild/ .</description>
      <author>example@mail.com (Xinyue Zhu, Binghao Huang, Yunzhu Li)</author>
      <guid isPermaLink="false">2507.15062v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Mammo-SAE: Interpreting Breast Cancer Concept Learning with Sparse Autoencoders</title>
      <link>http://arxiv.org/abs/2507.15227v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出基于稀疏自动编码器（SAE）的可解释性在医学影像等高风险领域的应用，通过分析Mammo-CLIP模型，识别和探究与临床相关的乳腺癌概念。&lt;h4&gt;背景&lt;/h4&gt;医学影像领域对模型的解释性至关重要，因为理解模型决策对于临床应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;引入SAE的可解释性来分析乳腺影像，并识别与临床相关的乳腺癌概念。&lt;h4&gt;方法&lt;/h4&gt;在Mammo-CLIP上训练一个patch级别的Mammo-SAE，以识别和探究与临床相关概念（如肿块和可疑钙化）相关的潜在特征。&lt;h4&gt;主要发现&lt;/h4&gt;SAE中激活最高的潜在神经元往往与真实区域一致，同时揭示了影响模型决策过程的几个混杂因素。此外，还分析了模型在下游微调过程中所依赖的潜在神经元。&lt;h4&gt;结论&lt;/h4&gt;这项研究突出了可解释的SAE潜在表示在深入了解基础模型内部工作方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：在医学影像等高风险领域，可解释性至关重要，因为理解模型决策对于临床应用至关重要。在这项工作中，我们通过分析大规模乳腺影像-报告对预训练的视觉-语言基础模型Mammo-CLIP，引入了基于稀疏自动编码器（SAE）的可解释性来分析乳腺影像。我们在Mammo-CLIP上训练了一个patch级别的Mammo-SAE，以识别和探究与临床相关概念（如肿块和可疑钙化）相关的潜在特征。我们的发现表明，SAE潜在空间中激活最高的潜在神经元往往与真实区域一致，并揭示了影响模型决策过程的几个混杂因素。此外，我们还分析了模型在下游微调过程中所依赖的潜在神经元。这项研究突出了可解释的SAE潜在表示在深入了解基础模型内部工作方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretability is critical in high-stakes domains such as medical imaging,where understanding model decisions is essential for clinical adoption. In thiswork, we introduce Sparse Autoencoder (SAE)-based interpretability to breastimaging by analyzing {Mammo-CLIP}, a vision--language foundation modelpretrained on large-scale mammogram image--report pairs. We train a patch-level\texttt{Mammo-SAE} on Mammo-CLIP to identify and probe latent featuresassociated with clinically relevant breast concepts such as \textit{mass} and\textit{suspicious calcification}. Our findings reveal that top activated classlevel latent neurons in the SAE latent space often tend to align with groundtruth regions, and also uncover several confounding factors influencing themodel's decision-making process. Additionally, we analyze which latent neuronsthe model relies on during downstream finetuning for improving the breastconcept prediction. This study highlights the promise of interpretable SAElatent representations in providing deeper insight into the internal workingsof foundation models at every layer for breast imaging.</description>
      <author>example@mail.com (Krishna Kanth Nakka)</author>
      <guid isPermaLink="false">2507.15227v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF</title>
      <link>http://arxiv.org/abs/2507.14596v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICCV'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DiSCO-3D的新方法，用于解决3D开放词汇子概念发现的问题，旨在提供能够适应场景和用户查询的3D语义分割。&lt;h4&gt;背景&lt;/h4&gt;3D语义分割在机器人、自主系统等领域中提供高级场景理解。传统方法要么针对特定任务目标（开放词汇分割），要么针对场景内容（无监督语义分割）。&lt;h4&gt;目的&lt;/h4&gt;DiSCO-3D旨在解决3D开放词汇子概念发现的问题，提供适应场景和用户查询的3D语义分割。&lt;h4&gt;方法&lt;/h4&gt;DiSCO-3D基于神经网络场表示，结合无监督分割与弱开放词汇指导。&lt;h4&gt;主要发现&lt;/h4&gt;DiSCO-3D在开放词汇子概念发现中表现出有效性能，并在开放词汇和无监督分割的边缘案例中展现出最先进的结果。&lt;h4&gt;结论&lt;/h4&gt;DiSCO-3D是一种有效的3D语义分割方法，适用于开放词汇和无监督分割的边缘案例。&lt;h4&gt;翻译&lt;/h4&gt;3D语义分割为机器人、自主系统等应用提供了高级场景理解。传统方法专门适应于特定任务目标（开放词汇分割）或场景内容（无监督语义分割）。我们提出了DiSCO-3D，这是第一个解决更广泛的3D开放词汇子概念发现问题的方法，旨在提供适应场景和用户查询的3D语义分割。我们基于神经网络场表示构建了DiSCO-3D，结合无监督分割和弱开放词汇指导。我们的评估表明，DiSCO-3D在开放词汇子概念发现中实现了有效性能，并在开放词汇和无监督分割的边缘案例中显示出最先进的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D semantic segmentation provides high-level scene understanding forapplications in robotics, autonomous systems, \textit{etc}. Traditional methodsadapt exclusively to either task-specific goals (open-vocabulary segmentation)or scene content (unsupervised semantic segmentation). We propose DiSCO-3D, thefirst method addressing the broader problem of 3D Open-Vocabulary Sub-conceptsDiscovery, which aims to provide a 3D semantic segmentation that adapts to boththe scene and user queries. We build DiSCO-3D on Neural Fields representations,combining unsupervised segmentation with weak open-vocabulary guidance. Ourevaluations demonstrate that DiSCO-3D achieves effective performance inOpen-Vocabulary Sub-concepts Discovery and exhibits state-of-the-art results inthe edge cases of both open-vocabulary and unsupervised segmentation.</description>
      <author>example@mail.com (Doriand Petit, Steve Bourgeois, Vincent Gay-Bellile, Florian Chabot, Loïc Barthe)</author>
      <guid isPermaLink="false">2507.14596v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards</title>
      <link>http://arxiv.org/abs/2507.14783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Omni-Think的强化学习框架，用于提升通用人工智能在多样化任务中的表现，并通过实验验证了该方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;目前，通用人工智能的进步依赖于在各种任务上表现优异的通用语言模型（LLMs），但后训练方法如监督微调（SFT）往往在泛化能力上存在挑战，更倾向于记忆而非迁移学习。&lt;h4&gt;目的&lt;/h4&gt;目的是提出一种方法，通过结合基于规则的验证奖励和通过LLM作为评判者的生成偏好信号，来提升LLMs在各种任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;Omni-Think框架结合了规则基础的可验证奖励和通过LLM作为评判者的生成偏好信号，并通过课程学习策略进行任务排序，从而优化训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于课程的学习方法比联合训练提高了5.2%，比模型合并提高了9.1%，证明了任务感知采样和混合监督在扩展基于RL的后训练对于通用LLMs的重要性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过任务感知采样和混合监督有效地提升了通用LLMs的后训练性能，为LLMs在各种任务上的应用提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;The advancement of general-purpose artificial intelligence relies on large language models (LLMs) that excel across a wide range of tasks, from structured reasoning to creative generation. However, post-training methods like Supervised Fine-Tuning (SFT) often struggle with generalization, favoring memorization over transferable learning. In this work, we introduce Omni-Think, a unified reinforcement learning (RL) framework that enhances LLM performance across diverse tasks by combining rule-based verifiable rewards with generative preference signals via LLM-as-a-Judge evaluations. Our approach enables consistent optimization across task types and scales RL-based training to subjective domains. We further investigate training strategies, demonstrating that a curriculum-based progression that orders tasks from structured to open-ended improves performance and reduces forgetting. Experimental results across four domains reveal that curriculum learning improves performance by 5.2% over joint training and 9.1% over model merging. These results highlight the importance of task-aware sampling and hybrid supervision in scaling RL-based post-training for general-purpose LLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advancement of general-purpose artificial intelligence relies on largelanguage models (LLMs) that excel across a wide range of tasks, from structuredreasoning to creative generation. However, post-training methods likeSupervised Fine-Tuning (SFT) often struggle with generalization, favoringmemorization over transferable learning. In this work, we introduce Omni-Think,a unified reinforcement learning (RL) framework that enhances LLM performanceacross diverse tasks by combining rule-based verifiable rewards with generativepreference signals via LLM-as-a-Judge evaluations. Our approach enablesconsistent optimization across task types and scales RL-based training tosubjective domains. We further investigate training strategies, demonstratingthat a curriculum-based progression that orders tasks from structured toopen-ended improves performance and reduces forgetting. Experimental resultsacross four domains reveal that curriculum learning improves performance by5.2\% over joint training and 9.1\% over model merging. These results highlightthe importance of task-aware sampling and hybrid supervision in scalingRL-based post-training for general-purpose LLMs.</description>
      <author>example@mail.com (Derek Li, Jiaming Zhou, Amirreza Kazemi, Qianyi Sun, Abbas Ghaddar, Mohammad Ali Alomrani, Liheng Ma, Yu Luo, Dong Li, Feng Wen, Jianye Hao, Mark Coates, Yingxue Zhang)</author>
      <guid isPermaLink="false">2507.14783v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>U-MARVEL: Unveiling Key Factors for Universal Multimodal Retrieval via Embedding Learning with MLLMs</title>
      <link>http://arxiv.org/abs/2507.14902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report (in progress)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了使用多模态语言模型（MLLM）进行通用多模态检索（UMR）的有效嵌入学习方法，并提出了U-MARVEL框架，在多个任务上取得了优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;UMR旨在解决查询和候选对象跨越多种模态的复杂检索任务，MLLM的兴起显著推动了UMR的发展。&lt;h4&gt;目的&lt;/h4&gt;揭示驱动MLLM在UMR中有效嵌入学习的关键因素，并提出一个统一的框架。&lt;h4&gt;方法&lt;/h4&gt;实现了基于MLLM的通用嵌入学习流程，并系统地分析了高性能UMR系统的贡献因素，包括渐进过渡、硬负样本挖掘和再排序蒸馏等技术。&lt;h4&gt;主要发现&lt;/h4&gt;发现了一些经常被忽视的因素对模型性能有显著影响。&lt;h4&gt;结论&lt;/h4&gt;U-MARVEL框架在M-BEIR基准测试中优于现有方法，并在多个任务上表现出强大的零样本性能，证明了其在各种基于嵌入的检索任务中的泛化潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通用多模态检索（UMR）旨在解决查询和候选对象跨越多种模态的复杂检索任务。MLLM的出现显著推动了UMR的发展。尽管文献中基于MLLM的先进方法主要采用对比学习原则，但它们的特定训练方法存在差异。尽管它们取得了成功，但它们检索能力的潜在机制仍 largely 未被探索，这可能导致性能不佳和泛化能力有限。为了解决这些问题，我们进行了一项全面的研究，旨在揭示驱动MLLM在UMR中有效嵌入学习的关键因素。我们首先实现了一个通用的基于MLLM的嵌入学习流程，并系统地分析了高性能通用检索系统的贡献因素。在此基础上，我们探讨了嵌入生成和训练策略的各个方面，包括渐进过渡、硬负样本挖掘和再排序蒸馏。值得注意的是，我们的发现揭示了通常被忽视的因素对模型性能有重大影响。基于这些发现，我们引入了一个称为U-MARVEL（通用多模态检索通过嵌入学习）的统一框架，在监督设置中，该框架在M-BEIR基准测试中优于现有方法，并在多个任务（如组合图像检索和文本到视频检索）上表现出强大的零样本性能。这些结果强调了我们的框架在基于嵌入的各种检索任务中的泛化潜力。代码可在https://github.com/chaxjli/U-MARVEL获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Universal multimodal retrieval (UMR), which aims to address complex retrievaltasks where both queries and candidates span diverse modalities, has beensignificantly advanced by the emergence of MLLMs. While state-of-the-artMLLM-based methods in the literature predominantly adopt contrastive learningprinciples, they often differ in their specific training recipes. Despite theirsuccess, the mechanisms underlying their retrieval capabilities remain largelyunexplored, potentially resulting in suboptimal performance and limitedgeneralization ability. To address these issues, we present a comprehensivestudy aimed at uncovering the key factors that drive effective embeddinglearning for UMR using MLLMs. We begin by implementing a general MLLM-basedembedding learning pipeline, and systematically analyze the primarycontributors to high-performing universal retrieval systems. Based on this, weexplore various aspects of the details in embedding generation and trainingstrategies, including progressive transition, hard negative mining andre-ranker distillation. Notably, our findings reveal that often-overlookedfactors can have a substantial impact on model performance. Building on thesediscoveries, we introduce a unified framework termed U-MARVEL(\textbf{U}niversal \textbf{M}ultimod\textbf{A}l \textbf{R}etrie\textbf{V}alvia \textbf{E}mbedding \textbf{L}earning), which outperforms state-of-the-artcompetitors on the M-BEIR benchmark by a large margin in supervised settings,and also exihibits strong zero-shot performance on several tasks such ascomposed image retrieval and text-to-video retrieval. These results underscorethe generalization potential of our framework across various embedding-basedretrieval tasks. Code is available at https://github.com/chaxjli/U-MARVEL</description>
      <author>example@mail.com (Xiaojie Li, Chu Li, Shi-Zhe Chen, Xi Chen)</author>
      <guid isPermaLink="false">2507.14902v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation</title>
      <link>http://arxiv.org/abs/2507.15205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by the 28th European Conference on Artificial Intelligence  (ECAI 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LSDGNN的新颖的多模态方法，用于情感识别在对话中的应用。&lt;h4&gt;背景&lt;/h4&gt;情感识别在对话中是一个实用且具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种多模态方法来提高情感识别在对话中的准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法基于有向无环图（DAG）构建了长距离图神经网络和短距离图神经网络，分别获取远程和附近话语的多模态特征。使用差分正则化器并引入双仿射模块以促进特征交互，同时提出了改进的课程学习（ICL）来解决数据不平衡问题。&lt;h4&gt;主要发现&lt;/h4&gt;通过计算不同情绪之间的相似性来强调相似情绪的变化，设计了“加权情绪变化”指标，并开发了难度度量器，以实现优先学习容易样本然后再学习困难样本的训练过程。&lt;h4&gt;结论&lt;/h4&gt;在IEMOCAP和MELD数据集上的实验结果表明，该方法优于现有的基准。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为LSDGNN的新颖的多模态方法，用于情感识别在对话中的应用。该方法基于有向无环图（DAG）构建了长距离图神经网络和短距离图神经网络，分别获取远程和附近话语的多模态特征。为使长距离和短距离特征在表示上尽可能区分，同时允许两个模块之间相互影响，采用了差分正则化器，并引入了双仿射模块以促进特征交互。此外，还提出了改进的课程学习（ICL）来解决数据不平衡问题。通过计算不同情绪之间的相似性，强调相似情绪的变化，设计了“加权情绪变化”指标，并开发了难度度量器，以实现优先学习容易样本然后再学习困难样本的训练过程。在IEMOCAP和MELD数据集上的实验结果表明，该方法优于现有的基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emotion Recognition in Conversation (ERC) is a practical and challengingtask. This paper proposes a novel multimodal approach, the Long-Short DistanceGraph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), itconstructs a long-distance graph neural network and a short-distance graphneural network to obtain multimodal features of distant and nearby utterances,respectively. To ensure that long- and short-distance features are as distinctas possible in representation while enabling mutual influence between the twomodules, we employ a Differential Regularizer and incorporate a BiAffine Moduleto facilitate feature interaction. In addition, we propose an ImprovedCurriculum Learning (ICL) to address the challenge of data imbalance. Bycomputing the similarity between different emotions to emphasize the shifts insimilar emotions, we design a "weighted emotional shift" metric and develop adifficulty measurer, enabling a training process that prioritizes learning easysamples before harder ones. Experimental results on the IEMOCAP and MELDdatasets demonstrate that our model outperforms existing benchmarks.</description>
      <author>example@mail.com (Xinran Li, Xiujuan Xu, Jiaqi Qiao)</author>
      <guid isPermaLink="false">2507.15205v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Descrip3D: Enhancing Large Language Model-based 3D Scene Understanding with Object-Level Text Descriptions</title>
      <link>http://arxiv.org/abs/2507.14555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Descrip3D的新型框架，用于理解和描述3D场景中的对象关系。&lt;h4&gt;背景&lt;/h4&gt;理解3D场景不仅需要识别对象，还需要推理对象之间的空间和语义关系。&lt;h4&gt;目的&lt;/h4&gt;解决当前3D场景语言模型在处理对象关系理解方面的困难。&lt;h4&gt;方法&lt;/h4&gt;Descrip3D通过自然语言明确编码对象之间的关系，并结合2D和3D嵌入进行模型增强，同时通过双重层次整合来整合关系线索。&lt;h4&gt;主要发现&lt;/h4&gt;Descrip3D在多个基准数据集上表现优于强基线模型，证明了语言引导的关系表示在理解复杂室内场景中的有效性。&lt;h4&gt;结论&lt;/h4&gt;Descrip3D框架能够有效提升3D场景理解的能力，尤其在处理对象关系方面具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;Understanding 3D scenes goes beyond simply recognizing objects; it requires reasoning about the spatial and semantic relationships between them. Current 3D scene-language models often struggle with this relational understanding, particularly when visual embeddings alone do not adequately convey the roles and interactions of objects. In this paper, we introduce Descrip3D, a novel and powerful framework that explicitly encodes the relationships between objects using natural language. Unlike previous methods that rely only on 2D and 3D embeddings, Descrip3D enhances each object with a textual description that captures both its intrinsic attributes and contextual relationships. These relational cues are incorporated into the model through a dual-level integration: embedding fusion and prompt-level injection. This allows for unified reasoning across various tasks such as grounding, captioning, and question answering, all without the need for task-specific heads or additional supervision. When evaluated on five benchmark datasets, including ScanRefer, Multi3DRefer, ScanQA, SQA3D, and Scan2Cap, Descrip3D consistently outperforms strong baseline models, demonstrating the effectiveness of language-guided relational representation for understanding complex indoor scenes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding 3D scenes goes beyond simply recognizing objects; it requiresreasoning about the spatial and semantic relationships between them. Current 3Dscene-language models often struggle with this relational understanding,particularly when visual embeddings alone do not adequately convey the rolesand interactions of objects. In this paper, we introduce Descrip3D, a novel andpowerful framework that explicitly encodes the relationships between objectsusing natural language. Unlike previous methods that rely only on 2D and 3Dembeddings, Descrip3D enhances each object with a textual description thatcaptures both its intrinsic attributes and contextual relationships. Theserelational cues are incorporated into the model through a dual-levelintegration: embedding fusion and prompt-level injection. This allows forunified reasoning across various tasks such as grounding, captioning, andquestion answering, all without the need for task-specific heads or additionalsupervision. When evaluated on five benchmark datasets, including ScanRefer,Multi3DRefer, ScanQA, SQA3D, and Scan2Cap, Descrip3D consistently outperformsstrong baseline models, demonstrating the effectiveness of language-guidedrelational representation for understanding complex indoor scenes.</description>
      <author>example@mail.com (Jintang Xue, Ganning Zhao, Jie-En Yao, Hong-En Chen, Yue Hu, Meida Chen, Suya You, C. -C. Jay Kuo)</author>
      <guid isPermaLink="false">2507.14555v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation</title>
      <link>http://arxiv.org/abs/2507.14693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript has been submitted to the IEEE Journal of Biomedical  and Health Informatics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了自杀意念检测在实时自杀预防中的重要性，并提出了解决语言覆盖范围有限和标注实践不可靠两个挑战的方法。&lt;h4&gt;背景&lt;/h4&gt;目前大多数自杀意念检测数据集为英文，高质量人工标注数据稀缺，且缺乏其他语言的数据集，限制了自杀预防的全球实现。&lt;h4&gt;目的&lt;/h4&gt;构建一个基于社交媒体帖子的土耳其语自杀意念语料库，并引入一个高效的标注框架，以及评估标注可靠性和模型一致性。&lt;h4&gt;方法&lt;/h4&gt;使用三个标注者和两个大型语言模型（LLMs）进行标注，并通过八个预训练的情绪和情感分类器进行双向评估。&lt;h4&gt;主要发现&lt;/h4&gt;强调了在心理健康自然语言处理（NLP）中需要更严格和语言包容的标注和评估方法，并揭示了使用零样本迁移学习时流行模型的性能问题。&lt;h4&gt;结论&lt;/h4&gt;倡导在心理健康NLP中模型训练和数据集构建的透明度，优先考虑数据和模型的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Suicidal ideation detection is critical for real-time suicide prevention, yetits progress faces two under-explored challenges: limited language coverage andunreliable annotation practices. Most available datasets are in English, buteven among these, high-quality, human-annotated data remains scarce. As aresult, many studies rely on available pre-labeled datasets without examiningtheir annotation process or label reliability. The lack of datasets in otherlanguages further limits the global realization of suicide prevention viaartificial intelligence (AI). In this study, we address one of these gaps byconstructing a novel Turkish suicidal ideation corpus derived from social mediaposts and introducing a resource-efficient annotation framework involving threehuman annotators and two large language models (LLMs). We then address theremaining gaps by performing a bidirectional evaluation of label reliabilityand model consistency across this dataset and three popular English suicidalideation detection datasets, using transfer learning through eight pre-trainedsentiment and emotion classifiers. These transformers help assess annotationconsistency and benchmark model performance against manually labeled data. Ourfindings underscore the need for more rigorous, language-inclusive approachesto annotation and evaluation in mental health natural language processing (NLP)while demonstrating the questionable performance of popular models withzero-shot transfer learning. We advocate for transparency in model training anddataset construction in mental health NLP, prioritizing data and modelreliability.</description>
      <author>example@mail.com (Amina Dzafic, Merve Kavut, Ulya Bayram)</author>
      <guid isPermaLink="false">2507.14693v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP</title>
      <link>http://arxiv.org/abs/2507.14904v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的2D预训练多模态网络，用于处理RGB图像、文本和点云三种模态，简化了架构，并提高了模型的可适应性和性能。&lt;h4&gt;背景&lt;/h4&gt;现有的3D视觉定位方法通常依赖于不同模态的独立编码器，导致模型复杂且训练效率低。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，减少模型复杂度，提高训练效率，并实现跨模态的深度理解。&lt;h4&gt;方法&lt;/h4&gt;提出了一种统一的2D预训练多模态网络，使用基于适配器的微调，融合了点云和图像的几何多尺度特征，并引入了多模态解码器。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在3D检测任务上提高了6.52%，在3D视觉定位任务上提高了6.25%，同时减少了约58%的可训练参数。&lt;h4&gt;结论&lt;/h4&gt;该方法通过统一的特征提取和融合，实现了端到端的3D视觉定位模型，提高了效率和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D visual grounding allows an embodied agent to understand visual informationin real-world 3D environments based on human instructions, which is crucial forembodied intelligence. Existing 3D visual grounding methods typically rely onseparate encoders for different modalities (e.g., RGB images, text, and 3Dpoint clouds), resulting in large and complex models that are inefficient totrain. While some approaches use pre-trained 2D multi-modal models like CLIPfor 3D tasks, they still struggle with aligning point cloud data to 2Dencoders. As a result, these methods continue to depend on 3D encoders forfeature extraction, further increasing model complexity and traininginefficiency. In this paper, we propose a unified 2D pre-trained multi-modalnetwork to process all three modalities (RGB images, text, and point clouds),significantly simplifying the architecture. By leveraging a 2D CLIP bi-modalmodel with adapter-based fine-tuning, this framework effectively adapts to thetri-modal setting, improving both adaptability and performance acrossmodalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) moduleis designed to fuse geometric multi-scale features from point clouds andimages. We then integrate textual features for final modality fusion andintroduce a multi-modal decoder to facilitate deep cross-modal understanding.Together, our method achieves unified feature extraction and fusion across thethree modalities, enabling an end-to-end 3D visual grounding model. Compared tothe baseline, our method reduces the number of trainable parameters byapproximately 58\%, while achieving a 6.52\% improvement in the 3D detectiontask and a 6.25\% improvement in the 3D visual grounding task.</description>
      <author>example@mail.com (Fan Li, Zanyi Wang, Zeyi Huang, Guang Dai, Jingdong Wang, Mengmeng Wang)</author>
      <guid isPermaLink="false">2507.14904v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025</title>
      <link>http://arxiv.org/abs/2507.14544v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to ImageCLEF 2025, to be published in the lab proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了作者在ImageCLEFmed MEDVQA2025挑战赛Subtask 1中的方法，该挑战赛旨在解决胃肠内窥镜的视觉问答问题。作者采用Florence模型作为VQA流程的主干，结合强大的视觉编码器和文本编码器来解析内窥镜图像并生成临床相关的答案。通过应用特定领域的增强技术来提高泛化能力，同时保持医学特征。在KASVIR数据集上的实验表明，微调Florence模型在官方挑战指标上得到准确响应。研究结果突出了大型多模态模型在医学VQA中的潜力，并为未来关于可解释性、鲁棒性和临床整合的研究提供了强大的基准。&lt;h4&gt;背景&lt;/h4&gt;本文针对胃肠内窥镜的视觉问答问题进行研究。&lt;h4&gt;目的&lt;/h4&gt;提高胃肠内窥镜视觉问答的准确性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;采用Florence模型作为主干，结合视觉编码器和文本编码器，并应用特定领域的增强技术。&lt;h4&gt;主要发现&lt;/h4&gt;在KASVIR数据集上，微调Florence模型在官方挑战指标上表现出准确性。&lt;h4&gt;结论&lt;/h4&gt;大型多模态模型在医学VQA中具有潜力，为未来研究提供了基准。&lt;h4&gt;翻译&lt;/h4&gt;This paper describes our approach to Subtask 1 of the ImageCLEFmed MEDVQA2025 Challenge, which targets visual question answering (VQA) for gastrointestinal endoscopy. We adopt the Florence model-a large-scale multimodal foundation model-as the backbone of our VQA pipeline, pairing a powerful vision encoder with a text encoder to interpret endoscopic images and produce clinically relevant answers. To improve generalization, we apply domain-specific augmentations that preserve medical features while increasing training diversity. Experiments on the KASVIR dataset show that fine-tuning Florence yields accurate responses on the official challenge metrics. Our results highlight the potential of large multimodal models in medical VQA and provide a strong baseline for future work on explainability, robustness, and clinical integration. The code is publicly available at: https://github.com/TiwariLaxuu/VQA-Florence.git&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper describes our approach to Subtask 1 of the ImageCLEFmed MEDVQA2025 Challenge, which targets visual question answering (VQA) forgastrointestinal endoscopy. We adopt the Florence model-a large-scalemultimodal foundation model-as the backbone of our VQA pipeline, pairing apowerful vision encoder with a text encoder to interpret endoscopic images andproduce clinically relevant answers. To improve generalization, we applydomain-specific augmentations that preserve medical features while increasingtraining diversity. Experiments on the KASVIR dataset show that fine-tuningFlorence yields accurate responses on the official challenge metrics. Ourresults highlight the potential of large multimodal models in medical VQA andprovide a strong baseline for future work on explainability, robustness, andclinical integration. The code is publicly available at:https://github.com/TiwariLaxuu/VQA-Florence.git</description>
      <author>example@mail.com (Sujata Gaihre, Amir Thapa Magar, Prasuna Pokharel, Laxmi Tiwari)</author>
      <guid isPermaLink="false">2507.14544v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Time-Aware Attention for Enhanced Electronic Health Records Modeling</title>
      <link>http://arxiv.org/abs/2507.14847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TALE-EHR是一个基于Transformer的框架，通过新型时间感知注意力机制有效建模EHR，解决数据异质性和复杂时间模式问题，提高了疾病进展预测等任务的表现。&lt;h4&gt;背景&lt;/h4&gt;EHR中包含宝贵的临床信息，但建模EHR需要解决数据异质性和复杂时间模式的问题，标准方法在处理不规则时间间隔的临床事件时往往表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出TALE-EHR框架，以提高EHR分析的效果。&lt;h4&gt;方法&lt;/h4&gt;TALE-EHR包含一个时间感知注意力机制，以捕获细粒度序列动态；同时利用预训练的大语言模型（LLM）提取的嵌入来提供强大的语义表示。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC-IV和PIC数据集上的实验表明，TALE-EHR在疾病进展预测等任务上优于现有最佳基线。&lt;h4&gt;结论&lt;/h4&gt;TALE-EHR强调了将显式、连续的时间建模与强大的语义表示相结合的益处，为推进EHR分析提供了一种强大的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：电子健康记录（EHR）包含有价值的临床信息，可用于预测患者结果和指导医疗决策。然而，有效地建模电子健康记录（EHR）需要解决数据异质性和复杂的时间模式。标准方法通常难以处理临床事件之间不规则的时间间隔。我们提出了TALE-EHR，这是一种基于Transformer的框架，具有一种新颖的时间感知注意力机制，可以显式地建模连续的时间间隔，以捕获细粒度序列动态。为了与这种时间建模相结合的强大语义，TALE-EHR利用从标准化代码描述中提取的嵌入，并使用预训练的大语言模型（LLM），为理解临床概念提供了一个坚实的基础。在MIMIC-IV和PIC数据集上的实验表明，我们的方法在疾病进展预测等任务上优于现有的基线。TALE-EHR强调了将显式、连续的时间建模与强大的语义表示相结合的益处，为推进EHR分析提供了一种强大的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electronic Health Records (EHR) contain valuable clinical information forpredicting patient outcomes and guiding healthcare decisions. However,effectively modeling Electronic Health Records (EHRs) requires addressing dataheterogeneity and complex temporal patterns. Standard approaches often strugglewith irregular time intervals between clinical events. We propose TALE-EHR, aTransformer-based framework featuring a novel time-aware attention mechanismthat explicitly models continuous temporal gaps to capture fine-grainedsequence dynamics. To complement this temporal modeling with robust semantics,TALE-EHR leverages embeddings derived from standardized code descriptions usinga pre-trained Large Language Model (LLM), providing a strong foundation forunderstanding clinical concepts. Experiments on the MIMIC-IV and PIC datasetdemonstrate that our approach outperforms state-of-the-art baselines on taskssuch as disease progression forecasting. TALE-EHR underscores the benefit ofintegrating explicit, continuous temporal modeling with strong semanticrepresentations provides a powerful solution for advancing EHR analysis.</description>
      <author>example@mail.com (Junhan Yu, Zhunyi Feng, Junwei Lu, Tianxi Cai, Doudou Zhou)</author>
      <guid isPermaLink="false">2507.14847v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Depthwise-Dilated Convolutional Adapters for Medical Object Tracking and Segmentation Using the Segment Anything Model 2</title>
      <link>http://arxiv.org/abs/2507.14613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DD-SAM2的适应框架，用于改进医学影像分割，该框架基于SAM2并加入了深度卷积适配器，以提高多尺度特征提取效率，适用于有限训练数据的医学视频分割和跟踪。&lt;h4&gt;背景&lt;/h4&gt;现有的医学影像分割方法大多依赖于特定的模态设计，难以适应动态的医学影像场景，并且存在计算成本高和易忘性风险的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的方法来适应SAM2模型，使其能够在有限的训练数据上对医学视频进行有效分割和跟踪。&lt;h4&gt;方法&lt;/h4&gt;DD-SAM2通过深度卷积适配器（DD-Adapter）增强了SAM2的多尺度特征提取能力，并充分利用SAM2的流式内存机制，以适应医学视频对象跟踪和分割的需求。&lt;h4&gt;主要发现&lt;/h4&gt;在TrackRad2025（肿瘤分割）和EchoNet-Dynamic（左心室跟踪）数据集上进行了评估，DD-SAM2实现了0.93和0.97的Dice分数，表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;DD-SAM2为基于适配器的SAM2在医学视频分割和跟踪中的应用提供了一个系统性的探索，相关代码、数据集和模型将公开提供。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in medical image segmentation have been driven by deep learning; however, most existing methods remain limited by modality-specific designs and exhibit poor adaptability to dynamic medical imaging scenarios. The Segment Anything Model 2 (SAM2) and its related variants, which introduce a streaming memory mechanism for real-time video segmentation, present new opportunities for prompt-based, generalizable solutions. Nevertheless, adapting these models to medical video scenarios typically requires large-scale datasets for retraining or transfer learning, leading to high computational costs and the risk of catastrophic forgetting. To address these challenges, we propose DD-SAM2, an efficient adaptation framework for SAM2 that incorporates a Depthwise-Dilated Adapter (DD-Adapter) to enhance multi-scale feature extraction with minimal parameter overhead. This design enables effective fine-tuning of SAM2 on medical videos with limited training data. Unlike existing adapter-based methods focused solely on static images, DD-SAM2 fully exploits SAM2's streaming memory for medical video object tracking and segmentation. Comprehensive evaluations on TrackRad2025 (tumor segmentation) and EchoNet-Dynamic (left ventricle tracking) datasets demonstrate superior performance, achieving Dice scores of 0.93 and 0.97, respectively. To the best of our knowledge, this work provides an initial attempt at systematically exploring adapter-based SAM2 fine-tuning for medical video segmentation and tracking. Code, datasets, and models will be publicly available at https://github.com/apple1986/DD-SAM2.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in medical image segmentation have been driven by deeplearning; however, most existing methods remain limited by modality-specificdesigns and exhibit poor adaptability to dynamic medical imaging scenarios. TheSegment Anything Model 2 (SAM2) and its related variants, which introduce astreaming memory mechanism for real-time video segmentation, present newopportunities for prompt-based, generalizable solutions. Nevertheless, adaptingthese models to medical video scenarios typically requires large-scale datasetsfor retraining or transfer learning, leading to high computational costs andthe risk of catastrophic forgetting. To address these challenges, we proposeDD-SAM2, an efficient adaptation framework for SAM2 that incorporates aDepthwise-Dilated Adapter (DD-Adapter) to enhance multi-scale featureextraction with minimal parameter overhead. This design enables effectivefine-tuning of SAM2 on medical videos with limited training data. Unlikeexisting adapter-based methods focused solely on static images, DD-SAM2 fullyexploits SAM2's streaming memory for medical video object tracking andsegmentation. Comprehensive evaluations on TrackRad2025 (tumor segmentation)and EchoNet-Dynamic (left ventricle tracking) datasets demonstrate superiorperformance, achieving Dice scores of 0.93 and 0.97, respectively. To the bestof our knowledge, this work provides an initial attempt at systematicallyexploring adapter-based SAM2 fine-tuning for medical video segmentation andtracking. Code, datasets, and models will be publicly available athttps://github.com/apple1986/DD-SAM2.</description>
      <author>example@mail.com (Guoping Xu, Christopher Kabat, You Zhang)</author>
      <guid isPermaLink="false">2507.14613v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Towards Geometric and Textural Consistency 3D Scene Generation via Single Image-guided Model Generation and Layout Optimization</title>
      <link>http://arxiv.org/abs/2507.14841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures, Project page: https://xdlbw.github.io/sing3d/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，3D生成在学术界和工业界都取得了显著进展。然而，从单张RGB图像生成3D场景仍然是一个重大挑战，因为现有方法往往难以在多对象场景中确保对象生成质量和场景连贯性。&lt;h4&gt;背景&lt;/h4&gt;3D生成技术近年来发展迅速，但单张图像生成3D场景仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些限制，我们提出了一种新的三阶段框架，通过单图像引导模型生成和空间布局优化，实现具有显式几何表示和高质量纹理细节的3D场景生成。&lt;h4&gt;方法&lt;/h4&gt;该方法包括图像实例分割和修复阶段，以恢复遮挡对象的缺失细节，从而实现前景3D资产的完整生成。接着，通过构建伪立体视点进行相机参数估计和场景深度推断，捕获参考图像的空间几何形状，并采用模型选择策略确保前一步生成的3D资产与输入的最佳对齐。最后，通过模型参数化和最小化3D和2D空间中点云之间的Chamfer距离，优化布局参数，生成与输入引导图像精确对齐的显式3D场景表示。&lt;h4&gt;主要发现&lt;/h4&gt;在多对象场景图像集上的大量实验表明，该方法不仅在几何精度和纹理保真度方面优于现有方法，而且在场景布局合成方面也有显著优势。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在3D场景生成方面取得了显著进展，为解决从单张图像生成3D场景的挑战提供了一种有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, 3D generation has made great strides in both academia andindustry. However, generating 3D scenes from a single RGB image remains asignificant challenge, as current approaches often struggle to ensure bothobject generation quality and scene coherence in multi-object scenarios. Toovercome these limitations, we propose a novel three-stage framework for 3Dscene generation with explicit geometric representations and high-qualitytextural details via single image-guided model generation and spatial layoutoptimization. Our method begins with an image instance segmentation andinpainting phase, which recovers missing details of occluded objects in theinput images, thereby achieving complete generation of foreground 3D assets.Subsequently, our approach captures the spatial geometry of reference image byconstructing pseudo-stereo viewpoint for camera parameter estimation and scenedepth inference, while employing a model selection strategy to ensure optimalalignment between the 3D assets generated in the previous step and the input.Finally, through model parameterization and minimization of the Chamferdistance between point clouds in 3D and 2D space, our approach optimizes layoutparameters to produce an explicit 3D scene representation that maintainsprecise alignment with input guidance image. Extensive experiments onmulti-object scene image sets have demonstrated that our approach not onlyoutperforms state-of-the-art methods in terms of geometric accuracy and texturefidelity of individual generated 3D models, but also has significant advantagesin scene layout synthesis.</description>
      <author>example@mail.com (Xiang Tang, Ruotong Li, Xiaopeng Fan)</author>
      <guid isPermaLink="false">2507.14841v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Semantic-Aware Representation Learning for Multi-label Image Classification</title>
      <link>http://arxiv.org/abs/2507.14918v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SARL的语义感知表示学习方法，用于多标签图像分类，并在PASCAL VOC 2007和MS-COCO数据集上展示了其优越性。&lt;h4&gt;背景&lt;/h4&gt;多标签图像分类是计算机视觉领域的一个重要研究方向，旨在识别图像中的多个标签或概念。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法中图像表示可能包含噪声且定位不准确的问题。&lt;h4&gt;方法&lt;/h4&gt;首先，利用标签语义相关特征学习模块提取语义相关特征；其次，设计基于最优传输的注意力机制以获得语义对齐的图像表示；最后，采用区域得分聚合策略进行多标签预测。&lt;h4&gt;主要发现&lt;/h4&gt;SARL在PASCAL VOC 2007和MS-COCO数据集上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;SARL是一种有效的多标签图像分类方法，能够提高分类的准确性和精确性。&lt;h4&gt;翻译&lt;/h4&gt;Multi-label image classification, an important research area in computer vision, focuses on identifying multiple labels or concepts within an image. Existing approaches often employ attention mechanisms or graph convolutional networks (GCNs) to learn image representation. However, this representation may contain noise and may not locate objects precisely. Therefore, this paper proposes a Semantic-Aware Representation Learning (SARL) for multi-label image classification. First, a label semantic-related feature learning module is utilized to extract semantic-related features. Then, an optimal transport-based attention mechanism is designed to obtain semantically aligned image representation. Finally, a regional score aggregation strategy is used for multi-label prediction. Experimental results on two benchmark datasets, PASCAL VOC 2007 and MS-COCO, demonstrate the superiority of SARL over existing methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-label image classification, an important research area in computervision, focuses on identifying multiple labels or concepts within an image.Existing approaches often employ attention mechanisms or graph convolutionalnetworks (GCNs) to learn image representation. However, this representation maycontain noise and may not locate objects precisely. Therefore, this paperproposes a Semantic-Aware Representation Learning (SARL) for multi-label imageclassification. First, a label semantic-related feature learning module isutilized to extract semantic-related features. Then, an optimal transport-basedattention mechanism is designed to obtain semantically aligned imagerepresentation. Finally, a regional score aggregation strategy is used formulti-label prediction. Experimental results on two benchmark datasets, PASCALVOC 2007 and MS-COCO, demonstrate the superiority of SARL over existingmethods.</description>
      <author>example@mail.com (Ren-Dong Xie, Zhi-Fen He, Bo Li, Bin Liu, Jin-Yan Hu)</author>
      <guid isPermaLink="false">2507.14918v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>CRAFT: A Neuro-Symbolic Framework for Visual Functional Affordance Grounding</title>
      <link>http://arxiv.org/abs/2507.14426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeSy 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为CRAFT的神经符号框架，用于可解释的情境基础识别，它能够识别场景中能够实现特定动作（如“切割”）的对象。&lt;h4&gt;背景&lt;/h4&gt;情境基础识别是一个在特定环境中理解并执行动作的能力，本文提出的CRAFT框架旨在提高这一能力。&lt;h4&gt;目的&lt;/h4&gt;提高情境基础识别的准确性和可解释性，为构建鲁棒且可信的场景理解提供一步。&lt;h4&gt;方法&lt;/h4&gt;CRAFT框架整合了来自ConceptNet的结构化常识先验和语言模型，以及来自CLIP的视觉证据，通过基于能量的推理循环迭代地细化预测。&lt;h4&gt;主要发现&lt;/h4&gt;在多对象、无标签的环境中进行的实验表明，CRAFT提高了准确性的同时增强了可解释性。&lt;h4&gt;结论&lt;/h4&gt;CRAFT框架是向构建鲁棒和可信的场景理解迈出的一步。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了CRAFT，这是一种用于可解释情境基础识别的神经符号框架，它识别场景中能够实现给定动作（例如，“切割”）的对象。CRAFT整合了来自ConceptNet的结构化常识先验和语言模型，以及来自CLIP的视觉证据，使用基于能量的推理循环迭代地细化预测。这个过程产生了透明、以目标为导向的决定，以基础符号和感知结构。在多对象、无标签设置中的实验表明，CRAFT提高了准确性，同时提高了可解释性，为构建鲁棒和可信的场景理解迈出了第一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce CRAFT, a neuro-symbolic framework for interpretable affordancegrounding, which identifies the objects in a scene that enable a given action(e.g., "cut"). CRAFT integrates structured commonsense priors from ConceptNetand language models with visual evidence from CLIP, using an energy-basedreasoning loop to refine predictions iteratively. This process yieldstransparent, goal-driven decisions to ground symbolic and perceptualstructures. Experiments in multi-object, label-free settings demonstrate thatCRAFT enhances accuracy while improving interpretability, providing a steptoward robust and trustworthy scene understanding.</description>
      <author>example@mail.com (Zhou Chen, Joe Lin, Sathyanarayanan N. Aakur)</author>
      <guid isPermaLink="false">2507.14426v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Towards a Proactive Autoscaling Framework for Data Stream Processing at the Edge using GRU and Transfer Learning</title>
      <link>http://arxiv.org/abs/2507.14597v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种针对边缘流处理自动缩放的解决方案，以应对高速数据处理的挑战。&lt;h4&gt;背景&lt;/h4&gt;随着数字经济产生大量数据，高速数据处理变得至关重要。边缘计算和流处理是当前及时数据处理的主要范式。&lt;h4&gt;目的&lt;/h4&gt;解决边缘流处理中快速的工作负载波动问题，优化资源分配。&lt;h4&gt;方法&lt;/h4&gt;提出的三步解决方案包括：使用GRU神经网络预测上游负载，通过迁移学习框架将预测模型集成到在线流处理系统中，以及一个水平自动缩放模块动态调整操作并行度。&lt;h4&gt;主要发现&lt;/h4&gt;GRU模型在真实数据集上记录了1.3%的SMAPE值，在SMAPE和RMSE评估指标上优于CNN、ARIMA和Prophet，且训练时间低于计算密集型的强化学习模型。&lt;h4&gt;结论&lt;/h4&gt;该方法通过预测和动态调整，有效提高了边缘流处理的性能和资源利用率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Processing data at high speeds is becoming increasingly critical as digitaleconomies generate enormous data. The current paradigms for timely dataprocessing are edge computing and data stream processing (DSP). Edge computingplaces resources closer to where data is generated, while stream processinganalyzes the unbounded high-speed data in motion. However, edge streamprocessing faces rapid workload fluctuations, complicating resourceprovisioning. Inadequate resource allocation leads to bottlenecks, whereasexcess allocation results in wastage. Existing reactive methods, such asthreshold-based policies and queuing theory scale only after performancedegrades, potentially violating SLAs. Although reinforcement learning (RL)offers a proactive approach through agents that learn optimal runtimeadaptation policies, it requires extensive simulation. Furthermore, predictivemachine learning models face online distribution and concept drift thatminimize their accuracy. We propose a three-step solution to the proactive edgestream processing autoscaling problem. Firstly, a GRU neural network forecaststhe upstream load using real-world and synthetic DSP datasets. Secondly, atransfer learning framework integrates the predictive model into an onlinestream processing system using the DTW algorithm and joint distributionadaptation to handle the disparities between offline and online domains.Finally, a horizontal autoscaling module dynamically adjusts the degree ofoperator parallelism, based on predicted load while considering edge resourceconstraints. The lightweight GRU model for load predictions recorded up to1.3\% SMAPE value on a real-world data set. It outperformed CNN, ARIMA, andProphet on the SMAPE and RMSE evaluation metrics, with lower training time thanthe computationally intensive RL models.</description>
      <author>example@mail.com (Eugene Armah, Linda Amoako Bannning)</author>
      <guid isPermaLink="false">2507.14597v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Parameter-Efficient Fine-Tuning of Foundation Models for CLP Speech Classification</title>
      <link>http://arxiv.org/abs/2507.14898v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种参数高效的微调（PEFT）方法，用于基于基础模型进行唇腭裂（CLP）检测和严重程度分类。&lt;h4&gt;背景&lt;/h4&gt;在CLP中，由于口腔和鼻腔之间的异常通道，随着严重程度的增加，鼻化程度也会增加；这导致口腔停止被声门停止所取代，并改变共振峰轨迹和元音空间。&lt;h4&gt;目的&lt;/h4&gt;通过在特定领域数据上微调，提高基础模型对CLP严重程度的区分能力。&lt;h4&gt;方法&lt;/h4&gt;在两个数据集（英语NMCPC和卡纳达语AIISH）上进行了实验，使用自监督模型Wav2Vec2和WavLM，以及弱监督的Whisper，与SVM分类器结合，并与传统的手工特征eGeMAPS和ComParE进行比较。最后，使用PEFT技术（低秩适配器LoRA和解耦低秩适配器DoRA）对表现最好的Whisper模型进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;在NMCPC数据集上，与最佳基础模型和手工特征基线相比，该方法在宏观平均F1分数上实现了26.4%和63.4%的相对改进；在AIISH数据集上，分别实现了6.1%和52.9%的改进。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在NMCPC和AIISH数据集上均优于基础模型和手工特征基线，证明了PEFT在CLP检测和严重程度分类中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose the use of parameter-efficient fine-tuning (PEFT) of foundationmodels for cleft lip and palate (CLP) detection and severity classification. InCLP, nasalization increases with severity due to the abnormal passage betweenthe oral and nasal tracts; this causes oral stops to be replaced by glottalstops and alters formant trajectories and vowel space. Since foundation modelsare trained for grapheme prediction or long-term quantized representationprediction, they may better discriminate CLP severity when fine-tuned ondomain-specific data. We conduct experiments on two datasets: English (NMCPC)and Kannada (AIISH). We perform a comparative analysis using embeddings fromself-supervised models Wav2Vec2 and WavLM, and the weakly supervised Whisper,each paired with SVM classifiers, and compare them with traditional handcraftedfeatures eGeMAPS and ComParE. Finally, we fine-tune the best-performing Whispermodel using PEFT techniques: Low-Rank Adapter (LoRA) and Decomposed Low-RankAdapter (DoRA). Our results demonstrate that the proposed approach achievesrelative improvements of 26.4% and 63.4% in macro-average F1 score over thebest foundation model and handcrafted feature baselines on the NMCPC dataset,and improvements of 6.1% and 52.9% on the AIISH dataset, respectively.</description>
      <author>example@mail.com (Susmita Bhattacharjee, Jagabandhu Mishra, H. S. Shekhawat, S. R. Mahadeva Prasanna)</author>
      <guid isPermaLink="false">2507.14898v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>BeatFormer: Efficient motion-robust remote heart rate estimation through unsupervised spectral zoomed attention filters</title>
      <link>http://arxiv.org/abs/2507.14885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BeatFormer的轻量级光谱注意力模型，用于远程光电容积描记图（rPPG）估计，并介绍了光谱对比学习（SCL）方法，以实现无标签训练。实验结果表明，BeatFormer在运动场景下的跨数据集评估中表现出良好的鲁棒性和性能。&lt;h4&gt;背景&lt;/h4&gt;rPPG技术通过面部视频捕捉心脏信号，在多个领域有广泛应用。深度学习在rPPG估计方面取得了进展，但需要大量数据集。手工方法利用生理先验，在未见过的场景下（如运动）保持计算效率，但线性假设限制了复杂条件下的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合深度学习和手工方法优势的轻量级模型，以实现高效且鲁棒的rPPG估计。&lt;h4&gt;方法&lt;/h4&gt;BeatFormer模型整合了放大的正交归一复数注意力和频率域能量测量，引入了SCL方法，实现无标签训练。&lt;h4&gt;主要发现&lt;/h4&gt;BeatFormer在PURE、UBFC-rPPG和MMPD数据集上进行了验证，证明了其在运动场景下的跨数据集评估中的鲁棒性和性能。&lt;h4&gt;结论&lt;/h4&gt;BeatFormer模型结合了深度学习和手工方法的优点，能够实现高效且鲁棒的rPPG估计，特别适用于运动场景下的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remote photoplethysmography (rPPG) captures cardiac signals from facialvideos and is gaining attention for its diverse applications. While deeplearning has advanced rPPG estimation, it relies on large, diverse datasets foreffective generalization. In contrast, handcrafted methods utilizephysiological priors for better generalization in unseen scenarios like motionwhile maintaining computational efficiency. However, their linear assumptionslimit performance in complex conditions, where deep learning provides superiorpulsatile information extraction. This highlights the need for hybridapproaches that combine the strengths of both methods. To address this, wepresent BeatFormer, a lightweight spectral attention model for rPPG estimation,which integrates zoomed orthonormal complex attention and frequency-domainenergy measurement, enabling a highly efficient model. Additionally, weintroduce Spectral Contrastive Learning (SCL), which allows BeatFormer to betrained without any PPG or HR labels. We validate BeatFormer on the PURE,UBFC-rPPG, and MMPD datasets, demonstrating its robustness and performance,particularly in cross-dataset evaluations under motion scenarios.</description>
      <author>example@mail.com (Joaquim Comas, Federico Sukno)</author>
      <guid isPermaLink="false">2507.14885v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Feature Construction Using Network Control Theory and Rank Encoding for Graph Machine Learning</title>
      <link>http://arxiv.org/abs/2507.15195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文利用图中的平均可控性概念和一种新的秩编码方法来提高图神经网络（GNNs）在社会网络分类任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;GNNs在基于网络的机器学习应用中表现出色，但它们的性能受节点特征的表达性影响很大。在社会网络中，由于隐私限制或缺乏固有属性，节点特征往往不可用，这给GNNs的性能优化带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一局限性，本文提出了两种构建表达性节点特征的战略。&lt;h4&gt;方法&lt;/h4&gt;首先，引入平均可控性以及其他中心性指标（称为NCT-EFA）作为节点级指标，以捕捉网络拓扑的关键方面。在此基础上，开发了一种秩编码方法，将平均可控性或其他图论指标转换为固定维度的特征空间，从而提高特征表示。然后，通过六个基准GNN模型在四个社会网络数据集上进行了广泛的数值评估，以比较不同的节点特征构建方法。&lt;h4&gt;主要发现&lt;/h4&gt;将平均可控性纳入特征空间显著提高了GNN的性能。此外，所提出的秩编码方法优于传统的one-hot度编码，在GitHub Stargazers数据集上使用GraphSAGE将ROC AUC从68.7%提高到73.9%，突显了其在生成表达性和高效节点表示方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有效地提高了GNN在社会网络分类任务中的性能，为解决节点特征缺失的问题提供了一种新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this article, we utilize the concept of average controllability in graphs,along with a novel rank encoding method, to enhance the performance of GraphNeural Networks (GNNs) in social network classification tasks. GNNs have provenhighly effective in various network-based learning applications and requiresome form of node features to function. However, their performance is heavilyinfluenced by the expressiveness of these features. In social networks, nodefeatures are often unavailable due to privacy constraints or the absence ofinherent attributes, making it challenging for GNNs to achieve optimalperformance. To address this limitation, we propose two strategies forconstructing expressive node features. First, we introduce averagecontrollability along with other centrality metrics (denoted as NCT-EFA) asnode-level metrics that capture critical aspects of network topology. Buildingon this, we develop a rank encoding method that transforms averagecontrollability or any other graph-theoretic metric into a fixed-dimensionalfeature space, thereby improving feature representation. We conduct extensivenumerical evaluations using six benchmark GNN models across four social networkdatasets to compare different node feature construction methods. Our resultsdemonstrate that incorporating average controllability into the feature spacesignificantly improves GNN performance. Moreover, the proposed rank encodingmethod outperforms traditional one-hot degree encoding, improving the ROC AUCfrom 68.7% to 73.9% using GraphSAGE on the GitHub Stargazers dataset,underscoring its effectiveness in generating expressive and efficient noderepresentations.</description>
      <author>example@mail.com (Anwar Said, Yifan Wei, Ubaid Ullah Ahmad, Mudassir Shabbir, Waseem Abbas, Xenofon Koutsoukos)</author>
      <guid isPermaLink="false">2507.15195v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>eMargin: Revisiting Contrastive Learning with Margin-Based Separation</title>
      <link>http://arxiv.org/abs/2507.14828v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  LDD'25: Learning from Difficult Data Workshop (ECAI 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文重新审视了之前的对比学习框架，研究在时间序列表示学习中引入自适应边缘到对比损失函数的影响。&lt;h4&gt;背景&lt;/h4&gt;之前的研究中，对比学习框架被用于时间序列表示学习。&lt;h4&gt;目的&lt;/h4&gt;研究自适应边缘（eMargin）对相邻但不同时间步的分离效果，以及它是否能在下游任务中提高性能。&lt;h4&gt;方法&lt;/h4&gt;通过在三个基准数据集上评估修改对聚类性能和分类的影响，比较了eMargin添加到InfoNCE后的表现。&lt;h4&gt;主要发现&lt;/h4&gt;eMargin在无监督聚类指标上优于现有基线，但在下游分类任务中表现不佳。&lt;h4&gt;结论&lt;/h4&gt;虽然eMargin在无监督聚类指标上表现出色，但并不保证在下游任务中学习到的嵌入是有意义或有效的。&lt;h4&gt;翻译&lt;/h4&gt;We revisit previous contrastive learning frameworks to investigate the effect of introducing an adaptive margin into the contrastive loss function for time series representation learning. Specifically, we explore whether an adaptive margin (eMargin), adjusted based on a predefined similarity threshold, can improve the separation between adjacent but dissimilar time steps and subsequently lead to better performance in downstream tasks. Our study evaluates the impact of this modification on clustering performance and classification in three benchmark datasets. Our findings, however, indicate that achieving high scores on unsupervised clustering metrics does not necessarily imply that the learned embeddings are meaningful or effective in downstream tasks. To be specific, eMargin added to InfoNCE consistently outperforms state-of-the-art baselines in unsupervised clustering metrics, but struggles to achieve competitive results in downstream classification with linear probing. The source code is publicly available at https://github.com/sfi-norwai/eMargin.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We revisit previous contrastive learning frameworks to investigate the effectof introducing an adaptive margin into the contrastive loss function for timeseries representation learning. Specifically, we explore whether an adaptivemargin (eMargin), adjusted based on a predefined similarity threshold, canimprove the separation between adjacent but dissimilar time steps andsubsequently lead to better performance in downstream tasks. Our studyevaluates the impact of this modification on clustering performance andclassification in three benchmark datasets. Our findings, however, indicatethat achieving high scores on unsupervised clustering metrics does notnecessarily imply that the learned embeddings are meaningful or effective indownstream tasks. To be specific, eMargin added to InfoNCE consistentlyoutperforms state-of-the-art baselines in unsupervised clustering metrics, butstruggles to achieve competitive results in downstream classification withlinear probing. The source code is publicly available athttps://github.com/sfi-norwai/eMargin.</description>
      <author>example@mail.com (Abdul-Kazeem Shamba, Kerstin Bach, Gavin Taylor)</author>
      <guid isPermaLink="false">2507.14828v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City</title>
      <link>http://arxiv.org/abs/2507.15143v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在沙特阿拉伯NEOM地区提出的170公里线性智能城市The Line中人类移动的可行性。&lt;h4&gt;背景&lt;/h4&gt;The Line是一个前所未有的城市拓扑结构，研究其居民是否可以自由移动具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;为了评估居民在The Line中的移动自由度，研究人员开发了一个混合仿真框架。&lt;h4&gt;方法&lt;/h4&gt;该仿真框架集成了基于代理的建模、强化学习、监督学习和图神经网络，并使用合成数据和来自高密度城市的真实世界轨迹来模拟50个垂直层次和不同密度场景的多模式交通行为。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在完全集成的AI架构下，代理的平均通勤时间为7.8到8.4分钟，满意度超过89%，可达性指数超过91%，即使在高峰拥堵期间也是如此。消融研究表明，移除强化学习或图神经网络等智能模块会显著降低性能，通勤时间增加高达85%，可达性下降至70%以下。环境建模进一步表明，当优先考虑电动模式时，能耗低且CO2排放量最小。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，在The Line中实现移动自由不仅是概念上可行的，而且在有自适应AI系统、可持续基础设施和实时反馈循环的支持下，在操作上也是现实的。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the feasibility of human mobility in The Line, a proposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess whether citizens can move freely within this unprecedented urban topology, we develop a hybrid simulation framework that integrates agent-based modeling, reinforcement learning, supervised learning, and graph neural networks. The simulation captures multi-modal transportation behaviors across 50 vertical levels and varying density scenarios using both synthetic data and real-world traces from high-density cities. Our experiments reveal that with the full AI-integrated architecture, agents achieved an average commute time of 7.8 to 8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index of over 91 percent, even during peak congestion periods. Ablation studies confirmed that the removal of intelligent modules such as reinforcement learning or graph neural networks significantly degrades performance, with commute times increasing by up to 85 percent and reachability falling below 70 percent. Environmental modeling further demonstrated low energy consumption and minimal CO2 emissions when electric modes are prioritized. The findings suggest that freedom of movement is not only conceptually achievable in The Line, but also operationally realistic if supported by adaptive AI systems, sustainable infrastructure, and real-time feedback loops.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the feasibility of human mobility in The Line, aproposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assesswhether citizens can move freely within this unprecedented urban topology, wedevelop a hybrid simulation framework that integrates agent-based modeling,reinforcement learning, supervised learning, and graph neural networks. Thesimulation captures multi-modal transportation behaviors across 50 verticallevels and varying density scenarios using both synthetic data and real-worldtraces from high-density cities. Our experiments reveal that with the fullAI-integrated architecture, agents achieved an average commute time of 7.8 to8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability indexof over 91 percent, even during peak congestion periods. Ablation studiesconfirmed that the removal of intelligent modules such as reinforcementlearning or graph neural networks significantly degrades performance, withcommute times increasing by up to 85 percent and reachability falling below 70percent. Environmental modeling further demonstrated low energy consumption andminimal CO2 emissions when electric modes are prioritized. The findings suggestthat freedom of movement is not only conceptually achievable in The Line, butalso operationally realistic if supported by adaptive AI systems, sustainableinfrastructure, and real-time feedback loops.</description>
      <author>example@mail.com (Abderaouf Bahi, Amel Ourici)</author>
      <guid isPermaLink="false">2507.15143v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning</title>
      <link>http://arxiv.org/abs/2507.14820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的抓取网络KGN-Pro，该网络在保持高效率和细粒度物体抓取的同时，通过概率PnP层直接进行3D优化。&lt;h4&gt;背景&lt;/h4&gt;高级机器人操作任务需要灵活的6自由度抓取估计作为基本功能。现有的方法要么直接从点云数据生成抓取，面临小物体和传感器噪声的挑战，要么从RGB图像中推断3D信息，这引入了昂贵的标注需求和离散化问题。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有方法的局限性，如非可微性质和对2D监督的依赖，从而更好地利用丰富的3D信息。&lt;h4&gt;方法&lt;/h4&gt;KGN-Pro通过编码成对的RGB-D图像来生成关键点图，并进一步输出一个2D置信度图，以在重投影误差最小化过程中加权关键点贡献。通过概率地建模加权平方重投影误差之和，网络有效地将3D监督传递到其2D关键点预测，实现端到端学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，KGN-Pro在抓取覆盖率和成功率方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;KGN-Pro通过结合直接3D优化和端到端学习，在机器人抓取任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel grasping network KGN-Pro that preserves the efficiency and fine-grained object grasping of previous KGNs while integrating direct 3D optimization through probabilistic PnP layers. KGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further outputs a 2D confidence map to weight keypoint contributions during re-projection error minimization. By modeling the weighted sum of squared re-projection errors probabilistically, the network effectively transmits 3D supervision to its 2D keypoint predictions, enabling end-to-end learning. Experiments on both simulated and real-world platforms demonstrate that KGN-Pro outperforms existing methods in terms of grasp cover rate and success rate.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-level robotic manipulation tasks demand flexible 6-DoF grasp estimationto serve as a basic function. Previous approaches either directly generategrasps from point-cloud data, suffering from challenges with small objects andsensor noise, or infer 3D information from RGB images, which introducesexpensive annotation requirements and discretization issues. Recent methodsmitigate some challenges by retaining a 2D representation to estimate graspkeypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoFposes. However, these methods are limited by their non-differentiable natureand reliance solely on 2D supervision, which hinders the full exploitation ofrich 3D information. In this work, we present KGN-Pro, a novel grasping networkthat preserves the efficiency and fine-grained object grasping of previous KGNswhile integrating direct 3D optimization through probabilistic PnP layers.KGN-Pro encodes paired RGB-D images to generate Keypoint Map, and furtheroutputs a 2D confidence map to weight keypoint contributions duringre-projection error minimization. By modeling the weighted sum of squaredre-projection errors probabilistically, the network effectively transmits 3Dsupervision to its 2D keypoint predictions, enabling end-to-end learning.Experiments on both simulated and real-world platforms demonstrate that KGN-Prooutperforms existing methods in terms of grasp cover rate and success rate.</description>
      <author>example@mail.com (Bingran Chen, Baorun Li, Jian Yang, Yong Liu, Guangyao Zhai)</author>
      <guid isPermaLink="false">2507.14820v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>LPS-GNN : Deploying Graph Neural Networks on Graphs with 100-Billion Edges</title>
      <link>http://arxiv.org/abs/2507.14570v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为LPS-GNN的可扩展、低成本、灵活且高效的图神经网络框架，用于解决大规模图中的邻域爆炸问题。&lt;h4&gt;背景&lt;/h4&gt;现有的可扩展图神经网络解决方案难以平衡执行效率和预测精度。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够在大规模图上进行表示学习的GNN框架，并提高用户获取场景下的性能。&lt;h4&gt;方法&lt;/h4&gt;设计了一种名为LPMetis的图分区算法，并提出了子图增强策略来提高模型预测性能。&lt;h4&gt;主要发现&lt;/h4&gt;LPS-GNN能够在10小时内使用单个GPU完成1000亿图的表示学习，在用户获取场景下提高了13.8%的性能。LPMetis在多个评估指标上优于现有最佳方法。子图增强策略使框架与各种GNN算法兼容。在腾讯平台上成功部署，LPS-GNN在公共和实际数据集上实现了8.24%到13.89%的性能提升。&lt;h4&gt;结论&lt;/h4&gt;LPS-GNN框架能够有效解决大规模图上的邻域爆炸问题，并显著提高图神经网络在现实世界应用中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as powerful tools for various graphmining tasks, yet existing scalable solutions often struggle to balanceexecution efficiency with prediction accuracy. These difficulties stem fromiterative message-passing techniques, which place significant computationaldemands and require extensive GPU memory, particularly when dealing with theneighbor explosion issue inherent in large-scale graphs. This paper introducesa scalable, low-cost, flexible, and efficient GNN framework called LPS-GNN,which can perform representation learning on 100 billion graphs with a singleGPU in 10 hours and shows a 13.8% improvement in User Acquisition scenarios. Weexamine existing graph partitioning methods and design a superior graphpartition algorithm named LPMetis. In particular, LPMetis outperforms currentstate-of-the-art (SOTA) approaches on various evaluation metrics. In addition,our paper proposes a subgraph augmentation strategy to enhance the model'spredictive performance. It exhibits excellent compatibility, allowing theentire framework to accommodate various GNN algorithms. Successfully deployedon the Tencent platform, LPS-GNN has been tested on public and real-worlddatasets, achieving performance lifts of 8. 24% to 13. 89% over SOTA models inonline applications.</description>
      <author>example@mail.com (Xu Cheng, Liang Yao, Feng He, Yukuo Cen, Yufei He, Chenhui Zhang, Wenzheng Feng, Hongyun Cai, Jie Tang)</author>
      <guid isPermaLink="false">2507.14570v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Semantic Segmentation based Scene Understanding in Autonomous Vehicles</title>
      <link>http://arxiv.org/abs/2507.14303v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  74 pages, 35 figures, Master's Thesis, Institute for Advanced Studies  in Basic Sciences (IASBS), Zanjan, Iran, 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用深度学习（DL）进行场景理解，特别是通过语义分割，以提高自动驾驶汽车的性能。&lt;h4&gt;背景&lt;/h4&gt;人工智能（AI）的概念在解决复杂任务中显示出巨大潜力，使得在某些领域的人类专业知识可能不再必要。&lt;h4&gt;目的&lt;/h4&gt;提出高效的模型来研究场景理解，并使用BDD100k数据集进行验证。&lt;h4&gt;方法&lt;/h4&gt;使用深度学习技术，特别是语义分割，以及多个Backbones作为模型的编码器。&lt;h4&gt;主要发现&lt;/h4&gt;选择适当的Backbone对模型性能有显著影响，并且语义分割性能的提升有助于更好地理解场景和环境。&lt;h4&gt;结论&lt;/h4&gt;通过准确度、平均IoU和损失函数等指标分析，验证了所提出模型的有效性。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, the concept of artificial intelligence (AI) has become a prominent keyword because it is promising in solving complex tasks. The need for human expertise in specific areas may no longer be needed because machines have achieved successful results using artificial intelligence and can make the right decisions in critical situations. This process is possible with the help of deep learning (DL), one of the most popular artificial intelligence technologies. One of the areas in which the use of DL is used is in the development of self-driving cars, which is very effective and important. In this work, we propose several efficient models to investigate scene understanding through semantic segmentation. We use the BDD100k dataset to investigate these models. Another contribution of this work is the usage of several Backbones as encoders for models. The obtained results show that choosing the appropriate backbone has a great effect on the performance of the model for semantic segmentation. Better performance in semantic segmentation allows us to understand better the scene and the environment around the agent. In the end, we analyze and evaluate the proposed models in terms of accuracy, mean IoU, and loss function, and the results show that these metrics are improved.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the concept of artificial intelligence (AI) has become aprominent keyword because it is promising in solving complex tasks. The needfor human expertise in specific areas may no longer be needed because machineshave achieved successful results using artificial intelligence and can make theright decisions in critical situations. This process is possible with the helpof deep learning (DL), one of the most popular artificial intelligencetechnologies. One of the areas in which the use of DL is used is in thedevelopment of self-driving cars, which is very effective and important. Inthis work, we propose several efficient models to investigate sceneunderstanding through semantic segmentation. We use the BDD100k dataset toinvestigate these models. Another contribution of this work is the usage ofseveral Backbones as encoders for models. The obtained results show thatchoosing the appropriate backbone has a great effect on the performance of themodel for semantic segmentation. Better performance in semantic segmentationallows us to understand better the scene and the environment around the agent.In the end, we analyze and evaluate the proposed models in terms of accuracy,mean IoU, and loss function, and the results show that these metrics areimproved.</description>
      <author>example@mail.com (Ehsan Rassekh)</author>
      <guid isPermaLink="false">2507.14303v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With Graphs</title>
      <link>http://arxiv.org/abs/2507.14874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Graph Tsetlin Machine (GraphTM)通过使用简明和扁平的AND规则进行模式识别，使得Tsetlin Machine既有可解释性又高效，同时其自动化能力在越来越多的数据集上达到与深度学习相当的准确性。&lt;h4&gt;背景&lt;/h4&gt;Tsetlin Machine通过AND规则进行模式识别，但传统的Tsetlin Machine在处理复杂输入时效率不高。&lt;h4&gt;目的&lt;/h4&gt;引入Graph Tsetlin Machine以从图结构输入中学习可解释的深度子句。&lt;h4&gt;方法&lt;/h4&gt;GraphTM通过消息传递构建嵌套的深度子句，以识别子图模式，支持序列、网格、关系和多模态输入，并且比传统的Tsetlin Machine使用更少的子句。&lt;h4&gt;主要发现&lt;/h4&gt;GraphTM在图像分类任务上比卷积Tsetlin Machine准确率高3.86%，在跟踪动作共指任务中比其他强化学习方法高出20.6%，在推荐系统上容忍噪声的能力比Graph Convolutional Neural Network强，对于病毒基因组序列数据，准确率与BiLSTM-CNN和GCN相当，但训练速度快2.5倍。&lt;h4&gt;结论&lt;/h4&gt;GraphTM的应用展示了图表示学习和深度子句为Tsetlin Machine学习带来了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine(TM) both interpretable and efficient, while the power of Tsetlin automataenables accuracy comparable to deep learning on an increasing number ofdatasets. We introduce the Graph Tsetlin Machine (GraphTM) for learninginterpretable deep clauses from graph-structured input. Moving beyond flat,fixed-length input, the GraphTM gets more versatile, supporting sequences,grids, relations, and multimodality. Through message passing, the GraphTMbuilds nested deep clauses to recognize sub-graph patterns with exponentiallyfewer clauses, increasing both interpretability and data utilization. For imageclassification, GraphTM preserves interpretability and achieves 3.86%-pointshigher accuracy on CIFAR-10 than a convolutional TM. For tracking actioncoreference, faced with increasingly challenging tasks, GraphTM outperformsother reinforcement learning methods by up to 20.6%-points. In recommendationsystems, it tolerates increasing noise to a greater extent than a GraphConvolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtainsaccuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequencedata, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training2.5x faster than GCN. The GraphTM's application to these varied fieldsdemonstrates how graph representation learning and deep clauses bring newpossibilities for TM learning.</description>
      <author>example@mail.com (Ole-Christoffer Granmo, Youmna Abdelwahab, Per-Arne Andersen, Paul F. A. Clarke, Kunal Dumbre, Ylva Grønninsæter, Vojtech Halenka, Runar Helin, Lei Jiao, Ahmed Khalid, Rebekka Omslandseter, Rupsa Saha, Mayur Shende, Xuan Zhang)</author>
      <guid isPermaLink="false">2507.14874v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Parameter-transfer in spatial autoregressive models via model averaging</title>
      <link>http://arxiv.org/abs/2507.14453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Mallows模型平均的参数传递方法，用于改进空间自回归模型的预测精度。&lt;h4&gt;背景&lt;/h4&gt;空间自回归模型在实际应用中常因样本数据不足而面临挑战，如国家层面的传染病空间分析。&lt;h4&gt;目的&lt;/h4&gt;提出一种参数传递方法，利用具有相似空间溢出效应的地区或领域信息，以提高目标数据的分析准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法不需要共享多源空间数据，可以与最大似然估计和两阶段最小二乘法等多种参数估计方法相结合。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，该方法达到渐近最优，并确保了权重收敛以及具有明确收敛率的权重收敛。&lt;h4&gt;结论&lt;/h4&gt;通过模拟研究和非洲感染计数预测的应用，进一步证明了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a parameter-transfer approach based on Mallows model averaging for spatial autoregressive models to improve prediction accuracy. The background is that spatial autoregressive models often face challenges due to insufficient sample data in practice, such as spatial analysis of infectious diseases at the national level. The purpose is to propose a parameter-transfer method that leverages information from regions or domains with similar spatial spillover effects to improve the accuracy of the analysis of the target data. The method does not require sharing multi-source spatial data and can be combined with various parameter estimation methods such as maximum likelihood and two-stage least squares. Theoretical analysis demonstrates that the method achieves asymptotic optimality and ensures weight convergence with an explicit convergence rate. Simulation studies and the application of infection count prediction in Africa further demonstrate the effectiveness of the approach.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Econometric modeling in spatial autoregressive models often suffers frominsufficient samples in practice, such as spatial analysis of infectiousdiseases at the country level with limited data. Transfer learning offers apromising solution by leveraging information from regions or domains withsimilar spatial spillover effects to improve the analysis of the target data.In this paper, we propose a parameter-transfer approach based on Mallows modelaveraging for spatial autoregressive models to improve the prediction accuracy.Our approach does not require sharing multi-source spatial data and can becombined with various parameter estimation methods, such as the maximumlikelihood and the two-stage least squares. Theoretical analyses demonstratethat our method achieves asymptotic optimality and ensures weight convergencewith an explicit convergence rate. Simulation studies and the application ofinfection count prediction in Africa further demonstrate the effectiveness ofour approach.</description>
      <author>example@mail.com (Fen Jiang, Wenhui Li, Xinyu Zhang)</author>
      <guid isPermaLink="false">2507.14453v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>An Evaluation of DUSt3R/MASt3R/VGGT 3D Reconstruction on Photogrammetric Aerial Blocks</title>
      <link>http://arxiv.org/abs/2507.14798v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 6 figures, this manuscript has been submitted to  Geo-spatial Information Science for consideration&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对DUSt3R、MASt3R和VGGT等最新3D重建基础模型在处理稀疏、无序图像集方面的能力进行了综合评估。&lt;h4&gt;背景&lt;/h4&gt;当前先进的3D计算机视觉算法在处理稀疏、无序图像集方面取得了进展。DUSt3R、MASt3R和VGGT等模型因其处理非常稀疏图像重叠的能力而受到关注。&lt;h4&gt;目的&lt;/h4&gt;评估这些模型在处理典型航拍图像时的表现，特别是处理极低图像重叠、立体遮挡和纹理缺失区域的能力。&lt;h4&gt;方法&lt;/h4&gt;在UseGeo数据集的航拍块上对预训练的DUSt3R、MASt3R和VGGT模型进行评估，用于姿态估计和密集3D重建。&lt;h4&gt;主要发现&lt;/h4&gt;这些方法可以从非常稀疏的图像集（少于10张图像，分辨率高达518像素）中准确地重建密集点云，比COLMAP的完整性增益高达+50%。VGGT还展示了更高的计算效率、可扩展性和更可靠的相机姿态估计。&lt;h4&gt;结论&lt;/h4&gt;尽管基于transformer的方法不能完全取代传统的SfM和MVS，但它们在具有挑战性、低分辨率和稀疏场景中作为补充方法具有前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：State-of-the-art 3D computer vision algorithms continue to advance in handling sparse, unordered image sets. Recently developed foundational models for 3D reconstruction, such as Dense and Unconstrained Stereo 3D Reconstruction (DUSt3R), Matching and Stereo 3D Reconstruction (MASt3R), and Visual Geometry Grounded Transformer (VGGT), have attracted attention due to their ability to handle very sparse image overlaps. Evaluating DUSt3R/MASt3R/VGGT on typical aerial images matters, as these models may handle extremely low image overlaps, stereo occlusions, and textureless regions. For redundant collections, they can accelerate 3D reconstruction by using extremely sparsified image sets. Despite tests on various computer vision benchmarks, their potential on photogrammetric aerial blocks remains unexplored. This paper conducts a comprehensive evaluation of the pre-trained DUSt3R/MASt3R/VGGT models on the aerial blocks of the UseGeo dataset for pose estimation and dense 3D reconstruction. Results show these methods can accurately reconstruct dense point clouds from very sparse image sets (fewer than 10 images, up to 518 pixels resolution), with completeness gains up to +50% over COLMAP. VGGT also demonstrates higher computational efficiency, scalability, and more reliable camera pose estimation. However, all exhibit limitations with high-resolution images and large sets, as pose reliability declines with more images and geometric complexity. These findings suggest transformer-based methods cannot fully replace traditional SfM and MVS, but offer promise as complementary approaches, especially in challenging, low-resolution, and sparse scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State-of-the-art 3D computer vision algorithms continue to advance inhandling sparse, unordered image sets. Recently developed foundational modelsfor 3D reconstruction, such as Dense and Unconstrained Stereo 3D Reconstruction(DUSt3R), Matching and Stereo 3D Reconstruction (MASt3R), and Visual GeometryGrounded Transformer (VGGT), have attracted attention due to their ability tohandle very sparse image overlaps. Evaluating DUSt3R/MASt3R/VGGT on typicalaerial images matters, as these models may handle extremely low image overlaps,stereo occlusions, and textureless regions. For redundant collections, they canaccelerate 3D reconstruction by using extremely sparsified image sets. Despitetests on various computer vision benchmarks, their potential on photogrammetricaerial blocks remains unexplored. This paper conducts a comprehensiveevaluation of the pre-trained DUSt3R/MASt3R/VGGT models on the aerial blocks ofthe UseGeo dataset for pose estimation and dense 3D reconstruction. Resultsshow these methods can accurately reconstruct dense point clouds from verysparse image sets (fewer than 10 images, up to 518 pixels resolution), withcompleteness gains up to +50% over COLMAP. VGGT also demonstrates highercomputational efficiency, scalability, and more reliable camera poseestimation. However, all exhibit limitations with high-resolution images andlarge sets, as pose reliability declines with more images and geometriccomplexity. These findings suggest transformer-based methods cannot fullyreplace traditional SfM and MVS, but offer promise as complementary approaches,especially in challenging, low-resolution, and sparse scenarios.</description>
      <author>example@mail.com (Xinyi Wu, Steven Landgraf, Markus Ulrich, Rongjun Qin)</author>
      <guid isPermaLink="false">2507.14798v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Region-aware Depth Scale Adaptation with Sparse Measurements</title>
      <link>http://arxiv.org/abs/2507.14879v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于稀疏深度测量的非学习型方法，用于将基础模型的相对尺度深度预测转换为绝对尺度深度，该方法无需重新训练或微调，既保留了基础模型的强泛化能力，又使其能够产生绝对尺度深度。&lt;h4&gt;背景&lt;/h4&gt;近年来，深度预测的基础模型在零样本单目深度估计方面取得了显著进展，但这些模型的输出通常是相对尺度而非绝对尺度，这在实际应用中存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，使基础模型能够生成绝对尺度深度，同时不牺牲其泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于稀疏深度测量的非学习型方法，该方法不需要重新训练或微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法有效，能够在不增加计算成本或牺牲泛化能力的情况下，在相对和绝对深度之间架起桥梁。&lt;h4&gt;结论&lt;/h4&gt;该方法具有将基础模型的相对尺度预测转换为绝对尺度深度预测的潜力，同时保持模型的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the emergence of foundation models for depth prediction hasled to remarkable progress, particularly in zero-shot monocular depthestimation. These models generate impressive depth predictions; however, theiroutputs are often in relative scale rather than metric scale. This limitationposes challenges for direct deployment in real-world applications. To addressthis, several scale adaptation methods have been proposed to enable foundationmodels to produce metric depth. However, these methods are typically costly, asthey require additional training on new domains and datasets. Moreover,fine-tuning these models often compromises their original generalizationcapabilities, limiting their adaptability across diverse scenes. In this paper,we introduce a non-learning-based approach that leverages sparse depthmeasurements to adapt the relative-scale predictions of foundation models intometric-scale depth. Our method requires neither retraining nor fine-tuning,thereby preserving the strong generalization ability of the original foundationmodels while enabling them to produce metric depth. Experimental resultsdemonstrate the effectiveness of our approach, high-lighting its potential tobridge the gap between relative and metric depth without incurring additionalcomputational costs or sacrificing generalization ability.</description>
      <author>example@mail.com (Rizhao Fan, Tianfang Ma, Zhigen Li, Ning An, Jian Cheng)</author>
      <guid isPermaLink="false">2507.14879v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark</title>
      <link>http://arxiv.org/abs/2507.14449v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures. This paper is accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了IRGPT，这是第一个针对真实世界红外图像的多模态大型语言模型，旨在解决现有方法依赖于合成红外图像的问题。&lt;h4&gt;背景&lt;/h4&gt;真实世界红外图像对视觉语言模型来说具有独特的挑战，因为缺乏对齐的文本数据和领域特定特征。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出IRGPT模型，并构建了包含超过260K个真实图像-文本对的大规模红外-文本数据集（IR-TD）。&lt;h4&gt;方法&lt;/h4&gt;IR-TD数据集通过两种互补过程手工制作文本：LLM生成的可见图像描述和基于规则的注释描述。同时，引入了双向跨模态课程迁移学习策略，通过考虑红外-可见和红外-文本的难度分数，系统地将知识从可见域迁移到红外域。&lt;h4&gt;主要发现&lt;/h4&gt;在9个基准任务（如识别、定位）上评估IRGPT，即使与更大规模的模型相比，也实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;IRGPT通过解决合成红外图像的局限性，提高了真实世界红外图像处理的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world infrared imagery presents unique challenges for vision-languagemodels due to the scarcity of aligned text data and domain-specificcharacteristics. Although existing methods have advanced the field, theirreliance on synthetic infrared images generated through style transfer fromvisible images, which limits their ability to capture the uniquecharacteristics of the infrared modality. To address this, we propose IRGPT,the first multi-modal large language model for real-world infrared images,built upon a large-scale InfraRed-Text Dataset (IR-TD) comprising over 260Kauthentic image-text pairs. The proposed IR-TD dataset contains real infraredimages paired with meticulously handcrafted texts, where the initial draftsoriginated from two complementary processes: (1) LLM-generated descriptions ofvisible images, and (2) rule-based descriptions of annotations. Furthermore, weintroduce a bi-cross-modal curriculum transfer learning strategy thatsystematically transfers knowledge from visible to infrared domains byconsidering the difficulty scores of both infrared-visible and infrared-text.Evaluated on a benchmark of 9 tasks (e.g., recognition, grounding), IRGPTachieves state-of-the-art performance even compared with larger-scale models.</description>
      <author>example@mail.com (Zhe Cao, Jin Zhang, Ruiheng Zhang)</author>
      <guid isPermaLink="false">2507.14449v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>MultiRetNet: A Multimodal Vision Model and Deferral System for Staging Diabetic Retinopathy</title>
      <link>http://arxiv.org/abs/2507.14738v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为MultiRetNet的新方法，旨在通过结合视网膜成像、社会经济因素和合并症资料来提高糖尿病视网膜病变（DR）的分期准确性，并集成临床转诊系统以实现临床人机交互的实施。&lt;h4&gt;背景&lt;/h4&gt;糖尿病视网膜病变是全球导致可预防失明的主要原因，影响超过一亿人。在美国，低收入社区的个体面临更高的风险，在诊断前就进入晚期阶段，这主要是因为有限的筛查机会。合并症进一步加速疾病进展。&lt;h4&gt;目的&lt;/h4&gt;提高DR分期准确性，并通过临床转诊系统实现临床人机交互的实施。&lt;h4&gt;方法&lt;/h4&gt;实验了三种多模态融合方法，并确定通过全连接层融合是最灵活的方法。合成对抗性和低质量图像，并使用对比学习来训练转诊系统，引导模型识别需要临床医生审查的异常样本。&lt;h4&gt;主要发现&lt;/h4&gt;系统在次优图像上保持诊断准确性，并整合关键健康数据，可以改善早期检测，特别是在医疗服务不足的人群中，这些人群通常首先识别出晚期DR。&lt;h4&gt;结论&lt;/h4&gt;这种方法可能降低医疗保健成本，提高早期检测率，并解决获取护理方面的差异，促进医疗保健公平。&lt;h4&gt;翻译&lt;/h4&gt;摘要：糖尿病视网膜病变（DR）是导致可预防失明的主要原因，影响全球超过一亿人。在美国，来自低收入社区的个体面临更高的风险，在诊断前就进入晚期阶段，这主要是因为有限的筛查机会。合并症进一步加速疾病进展。我们提出了MultiRetNet，这是一种结合视网膜成像、社会经济因素和合并症资料的新型管道，以提高DR分期准确性，并与临床转诊系统集成，以实现临床人机交互的实施。我们实验了三种多模态融合方法，并通过全连接层融合确定了最灵活的方法。我们合成对抗性和低质量图像，并使用对比学习来训练转诊系统，引导模型识别需要临床医生审查的异常样本。通过在次优图像上保持诊断准确性和整合关键健康数据，我们的系统可以改善早期检测，特别是在医疗服务不足的人群中，这些人群通常首先识别出晚期DR。这种方法可能降低医疗保健成本，提高早期检测率，并解决获取护理方面的差异，促进医疗保健公平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diabetic retinopathy (DR) is a leading cause of preventable blindness,affecting over 100 million people worldwide. In the United States, individualsfrom lower-income communities face a higher risk of progressing to advancedstages before diagnosis, largely due to limited access to screening. Comorbidconditions further accelerate disease progression. We propose MultiRetNet, anovel pipeline combining retinal imaging, socioeconomic factors, andcomorbidity profiles to improve DR staging accuracy, integrated with a clinicaldeferral system for a clinical human-in-the-loop implementation. We experimentwith three multimodal fusion methods and identify fusion through a fullyconnected layer as the most versatile methodology. We synthesize adversarial,low-quality images and use contrastive learning to train the deferral system,guiding the model to identify out-of-distribution samples that warrantclinician review. By maintaining diagnostic accuracy on suboptimal images andintegrating critical health data, our system can improve early detection,particularly in underserved populations where advanced DR is often firstidentified. This approach may reduce healthcare costs, increase early detectionrates, and address disparities in access to care, promoting healthcare equity.</description>
      <author>example@mail.com (Jeannie She, Katie Spivakovsky)</author>
      <guid isPermaLink="false">2507.14738v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>ReDiSC: A Reparameterized Masked Diffusion Model for Scalable Node Classification with Structured Predictions</title>
      <link>http://arxiv.org/abs/2507.14484v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，图神经网络（GNN）在节点分类任务中取得了显著的成功。本文提出了一种名为ReDiSC的新方法，用于结构化节点分类，以解决现有方法在优化目标中对节点标签条件独立性的假设与图结构中节点标签相关性的矛盾。&lt;h4&gt;背景&lt;/h4&gt;虽然GNN内蕴编码了特定的归纳偏差（如作为低通或高通滤波器），但大多数现有方法在优化目标中隐式地假设节点标签之间存在条件独立性。这种假设对于传统的分类任务如图像识别是合适的，但它与节点标签在图结构中仍然相关的直观观察相矛盾。&lt;h4&gt;目的&lt;/h4&gt;为了对节点标签进行结构化预测，本文提出了一种名为ReDiSC的新方法。&lt;h4&gt;方法&lt;/h4&gt;ReDiSC使用重新参数化的掩码扩散模型来估计节点标签的联合分布，并通过变分期望最大化（EM）框架进行学习。该方法在E步骤中比基于流形约束扩散模型的最先进模型DPM-SNC具有效率优势，并将其M步骤目标与流行的GNN和标签传播混合方法联系起来。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，ReDiSC在节点分类任务中实现了优于或与最先进的GNN、标签传播和基于扩散的基线相当的性能，且在具有不同规模的同质和异质图上均有效。&lt;h4&gt;结论&lt;/h4&gt;ReDiSC在结构化节点分类任务中具有显著的实用优势，尤其是在处理大规模数据集时，其有效扩展能力使得之前由于计算限制而失败的基于结构的扩散方法得以克服。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, graph neural networks (GNN) have achieved unprecedented successes in node classification tasks. Although GNNs inherently encode specific inductive biases (e.g., acting as low-pass or high-pass filters), most existing methods implicitly assume conditional independence among node labels in their optimization objectives. While this assumption is suitable for traditional classification tasks such as image recognition, it contradicts the intuitive observation that node labels in graphs remain correlated, even after conditioning on the graph structure. To make structured predictions for node labels, we propose ReDiSC, namely, Reparameterized masked Diffusion model for Structured node Classification. ReDiSC estimates the joint distribution of node labels using a reparameterized masked diffusion model, which is learned through the variational expectation-maximization (EM) framework. Our theoretical analysis shows the efficiency advantage of ReDiSC in the E-step compared to DPM-SNC, a state-of-the-art model that relies on a manifold-constrained diffusion model in continuous domain. Meanwhile, we explicitly link ReDiSC's M-step objective to popular GNN and label propagation hybrid approaches. Extensive experiments demonstrate that ReDiSC achieves superior or highly competitive performance compared to state-of-the-art GNN, label propagation, and diffusion-based baselines across both homophilic and heterophilic graphs of varying sizes. Notably, ReDiSC scales effectively to large-scale datasets on which previous structured diffusion methods fail due to computational constraints, highlighting its significant practical advantage in structured node classification tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, graph neural networks (GNN) have achieved unprecedentedsuccesses in node classification tasks. Although GNNs inherently encodespecific inductive biases (e.g., acting as low-pass or high-pass filters), mostexisting methods implicitly assume conditional independence among node labelsin their optimization objectives. While this assumption is suitable fortraditional classification tasks such as image recognition, it contradicts theintuitive observation that node labels in graphs remain correlated, even afterconditioning on the graph structure. To make structured predictions for nodelabels, we propose ReDiSC, namely, Reparameterized masked Diffusion model forStructured node Classification. ReDiSC estimates the joint distribution of nodelabels using a reparameterized masked diffusion model, which is learned throughthe variational expectation-maximization (EM) framework. Our theoreticalanalysis shows the efficiency advantage of ReDiSC in the E-step compared toDPM-SNC, a state-of-the-art model that relies on a manifold-constraineddiffusion model in continuous domain. Meanwhile, we explicitly link ReDiSC'sM-step objective to popular GNN and label propagation hybrid approaches.Extensive experiments demonstrate that ReDiSC achieves superior or highlycompetitive performance compared to state-of-the-art GNN, label propagation,and diffusion-based baselines across both homophilic and heterophilic graphs ofvarying sizes. Notably, ReDiSC scales effectively to large-scale datasets onwhich previous structured diffusion methods fail due to computationalconstraints, highlighting its significant practical advantage in structurednode classification tasks.</description>
      <author>example@mail.com (Yule Li, Yifeng Lu, Zhen Wang, Zhewei Wei, Yaliang Li, Bolin Ding)</author>
      <guid isPermaLink="false">2507.14484v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Extrinsic Dexterity for Occluded Grasping on Grasp Constraining Walls</title>
      <link>http://arxiv.org/abs/2507.14721v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了遮挡抓取问题，提出了一种基于分层强化学习（RL）的框架来解决由于环境遮挡导致物体主要抓取配置不可用的问题。&lt;h4&gt;背景&lt;/h4&gt;简单平行夹爪由于灵活性和驱动限制，在处理遮挡抓取任务时往往表现不佳。以往的研究探索了通过利用物体与环境特征（如墙壁）之间的外接触来旋转物体姿态的方法，但这些方法通常假设存在一个短墙壁，而在现实场景中这一假设可能并不总是成立。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一种分层强化学习框架，旨在通过结合不同类型的动作来成功抓取物体。&lt;h4&gt;方法&lt;/h4&gt;使用Q-learning训练一个高级策略，该策略选择预期产生最高奖励的动作类型。选定的低级技能在连续空间中采样特定的机器人动作。为了引导机器人到执行所选动作的适当位置，采用条件变分自编码器（CVAE），通过条件化CVAE以物体点云和技能ID，使其能够根据物体几何形状和所选技能推断出合适的位置。为了促进泛化，在训练低级技能时应用领域随机化。强化学习策略在模拟环境中使用箱形物体进行训练，并在现实世界中的六个物体上部署。进行了实验以评估该方法，并展示了其泛化能力和有希望的现实世界迁移性能。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出的方法能够有效地解决遮挡抓取问题，并且在模拟和现实世界中的实验中均取得了成功。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在解决遮挡抓取问题上具有很好的应用前景，能够提高机器人在复杂环境中的抓取能力。&lt;h4&gt;翻译&lt;/h4&gt;本研究针对遮挡抓取问题进行了研究，提出了一种基于分层强化学习的框架来解决由于环境遮挡导致物体主要抓取配置不可用的问题。简单平行夹爪由于灵活性和驱动限制，在处理遮挡抓取任务时往往表现不佳。以往的研究探索了通过利用物体与环境特征（如墙壁）之间的外接触来旋转物体姿态的方法，但这些方法通常假设存在一个短墙壁，而在现实场景中这一假设可能并不总是成立。为了解决上述问题，本文提出了一种分层强化学习框架，旨在通过结合不同类型的动作来成功抓取物体。使用Q-learning训练一个高级策略，该策略选择预期产生最高奖励的动作类型。选定的低级技能在连续空间中采样特定的机器人动作。为了引导机器人到执行所选动作的适当位置，采用条件变分自编码器（CVAE），通过条件化CVAE以物体点云和技能ID，使其能够根据物体几何形状和所选技能推断出合适的位置。为了促进泛化，在训练低级技能时应用领域随机化。强化学习策略在模拟环境中使用箱形物体进行训练，并在现实世界中的六个物体上部署。进行了实验以评估该方法，并展示了其泛化能力和有希望的现实世界迁移性能。本文提出的方法能够有效地解决遮挡抓取问题，并且在模拟和现实世界中的实验中均取得了成功。本文提出的方法在解决遮挡抓取问题上具有很好的应用前景，能够提高机器人在复杂环境中的抓取能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study addresses the problem of occluded grasping, where primary graspconfigurations of an object are not available due to occlusion withenvironment. Simple parallel grippers often struggle with such tasks due tolimited dexterity and actuation constraints. Prior works have explored objectpose reorientation such as pivoting by utilizing extrinsic contacts between anobject and an environment feature like a wall, to make the object graspable.However, such works often assume the presence of a short wall, and thisassumption may not always hold in real-world scenarios. If the wall availablefor interaction is too large or too tall, the robot may still fail to grasp theobject even after pivoting, and the robot must combine different types ofactions to grasp. To address this, we propose a hierarchical reinforcementlearning (RL) framework. We use Q-learning to train a high-level policy thatselects the type of action expected to yield the highest reward. The selectedlow-level skill then samples a specific robot action in continuous space. Toguide the robot to an appropriate location for executing the selected action,we adopt a Conditional Variational Autoencoder (CVAE). We condition the CVAE onthe object point cloud and the skill ID, enabling it to infer a suitablelocation based on the object geometry and the selected skill. To promotegeneralization, we apply domain randomization during the training of low-levelskills. The RL policy is trained entirely in simulation with a box-like objectand deployed to six objects in real world. We conduct experiments to evaluateour method and demonstrate both its generalizability and robust sim-to-realtransfer performance with promising success rates.</description>
      <author>example@mail.com (Keita Kobashi, Masayoshi Tomizuka)</author>
      <guid isPermaLink="false">2507.14721v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning</title>
      <link>http://arxiv.org/abs/2507.14468v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Bioinformatics on July 11th&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为BioGraphFusion的新框架，用于深度协同语义和结构学习，以解决生物医学知识图谱中语义理解和结构学习之间的挑战。&lt;h4&gt;背景&lt;/h4&gt;生物医学知识图谱在药物发现和疾病理解中至关重要，但其补全和推理具有挑战性。知识嵌入方法在捕获全局语义方面表现良好，但难以处理动态结构整合；图神经网络在局部表现优秀，但往往缺乏语义理解。即使包括利用语言模型的集成方法，也往往无法实现语义理解和结构学习之间的深度、自适应和协同进化。&lt;h4&gt;目的&lt;/h4&gt;解决生物医学知识图谱中语义理解和结构学习之间的关键差距，以促进这两个方面的持续、相互的优化。&lt;h4&gt;方法&lt;/h4&gt;BioGraphFusion通过张量分解建立全局语义基础，并引导LSTM驱动的机制在图传播过程中动态优化关系嵌入。此外，还通过查询引导的子图构建和混合评分机制进一步增强了语义理解和结构学习之间的交互。&lt;h4&gt;主要发现&lt;/h4&gt;在三个关键生物医学任务上的实验表明，BioGraphFusion在性能上优于现有的知识嵌入、图神经网络和集成模型。对皮肤恶性黑色素瘤1（CMM1）的研究案例突出了其揭示生物意义途径的能力。&lt;h4&gt;结论&lt;/h4&gt;BioGraphFusion框架能够有效地解决生物医学知识图谱中的语义理解和结构学习问题，为药物发现和疾病理解提供了有力的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：动机：生物医学知识图谱（KGs）对于药物发现和疾病理解至关重要，但其补全和推理具有挑战性。知识嵌入（KE）方法在捕获全局语义方面表现良好，但难以处理动态结构整合，而图神经网络（GNNs）在局部表现优秀，但往往缺乏语义理解。即使是集成方法，包括那些利用语言模型的，也往往无法实现语义理解和结构学习之间的深度、自适应和协同进化。解决促进复杂生物医学KG中这两个方面之间持续、相互优化的关键差距至关重要。结果：我们引入了BioGraphFusion，这是一种用于深度协同语义和结构学习的新框架。BioGraphFusion通过张量分解建立全局语义基础，并通过LSTM驱动的机制在图传播过程中动态优化关系嵌入。这促进了语义理解和结构学习之间的自适应交互，并通过查询引导的子图构建和混合评分机制进一步增强。在三个关键生物医学任务上的实验表明，BioGraphFusion在性能上优于现有的KE、GNN和集成模型。CMM1（皮肤恶性黑色素瘤1）的研究案例突出了其揭示生物意义途径的能力。可用性和实现：源代码和所有训练数据均可从https://github.com/Y-TARL/BioGraphFusion免费下载。联系方式：zjw@zjut.edu.cn, botao666666@126.com。补充信息：补充数据可在Bioinformatics online获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1093/bioinformatics/btaf408&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discoveryand disease understanding, yet their completion and reasoning are challenging.Knowledge Embedding (KE) methods capture global semantics but struggle withdynamic structural integration, while Graph Neural Networks (GNNs) excellocally but often lack semantic understanding. Even ensemble approaches,including those leveraging language models, often fail to achieve a deep,adaptive, and synergistic co-evolution between semantic comprehension andstructural learning. Addressing this critical gap in fostering continuous,reciprocal refinement between these two aspects in complex biomedical KGs isparamount.  Results: We introduce BioGraphFusion, a novel framework for deeplysynergistic semantic and structural learning. BioGraphFusion establishes aglobal semantic foundation via tensor decomposition, guiding an LSTM-drivenmechanism to dynamically refine relation embeddings during graph propagation.This fosters adaptive interplay between semantic understanding and structurallearning, further enhanced by query-guided subgraph construction and a hybridscoring mechanism. Experiments across three key biomedical tasks demonstrateBioGraphFusion's superior performance over state-of-the-art KE, GNN, andensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1)highlights its ability to unveil biologically meaningful pathways.  Availability and Implementation: Source code and all training data are freelyavailable for download at https://github.com/Y-TARL/BioGraphFusion.  Contact: zjw@zjut.edu.cn, botao666666@126.com.  Supplementary information: Supplementary data are available at Bioinformaticsonline.</description>
      <author>example@mail.com (Yitong Lin, Jiaying He, Jiahe Chen, Xinnan Zhu, Jianwei Zheng, Tao Bo)</author>
      <guid isPermaLink="false">2507.14468v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Grounding Degradations in Natural Language for All-In-One Video Restoration</title>
      <link>http://arxiv.org/abs/2507.14851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全功能的视频恢复框架，通过基础模型在自然语言中构建视频帧的降级感知语义上下文，提供可解释和灵活的指导。&lt;h4&gt;背景&lt;/h4&gt;与现有技术不同，该方法在训练或测试时不需要降级知识，并学习对这种知识的近似，以便在推理过程中安全地分解基础模型，不增加额外成本。&lt;h4&gt;目的&lt;/h4&gt;呼吁全功能视频恢复中基准测试的标准化，并提出了两个多降级设置下的基准：三任务（3D）和四任务（4D），以及两个时变复合降级基准；后者之一是本文提出的具有变化雪强度的数据集，模拟天气降级对视频的自然影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种视频恢复方法，该方法不需要降级知识，并使用基础模型进行语义上下文的构建。&lt;h4&gt;主要发现&lt;/h4&gt;与先前工作相比，该方法在所有基准测试上报告了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在视频恢复领域具有显著的优势，并推动了该领域基准测试的标准化。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we propose an all-in-one video restoration framework that grounds degradation-aware semantic context of video frames in natural language via foundation models, offering interpretable and flexible guidance. Unlike prior art, our method assumes no degradation knowledge in train or test time and learns an approximation to the grounded knowledge such that the foundation model can be safely disentangled during inference adding no extra cost. Further, we call for standardization of benchmarks in all-in-one video restoration, and propose two benchmarks in multi-degradation setting, three-task (3D) and four-task (4D), and two time-varying composite degradation benchmarks; one of the latter being our proposed dataset with varying snow intensity, simulating how weather degradations affect videos naturally. We compare our method with prior works and report state-of-the-art performance on all benchmarks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we propose an all-in-one video restoration framework thatgrounds degradation-aware semantic context of video frames in natural languagevia foundation models, offering interpretable and flexible guidance. Unlikeprior art, our method assumes no degradation knowledge in train or test timeand learns an approximation to the grounded knowledge such that the foundationmodel can be safely disentangled during inference adding no extra cost.Further, we call for standardization of benchmarks in all-in-one videorestoration, and propose two benchmarks in multi-degradation setting,three-task (3D) and four-task (4D), and two time-varying composite degradationbenchmarks; one of the latter being our proposed dataset with varying snowintensity, simulating how weather degradations affect videos naturally. Wecompare our method with prior works and report state-of-the-art performance onall benchmarks.</description>
      <author>example@mail.com (Muhammad Kamran Janjua, Amirhosein Ghasemabadi, Kunlin Zhang, Mohammad Salameh, Chao Gao, Di Niu)</author>
      <guid isPermaLink="false">2507.14851v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Transaction Profiling and Address Role Inference in Tokenized U.S. Treasuries</title>
      <link>http://arxiv.org/abs/2507.14808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于美国国债的RWAs进行了定量和功能层面的分析，特别是BUIDL、BENJI和USDY等代币，研究了它们在多链网络（主要是以太坊和Layer-2s）中的交易行为。&lt;h4&gt;背景&lt;/h4&gt;Tokenized U.S. Treasuries已成为现实世界资产的一个重要子类别，它们通过加密手段提供收益，并以主权债务作为抵押，部署在多个区块链网络上。&lt;h4&gt;目的&lt;/h4&gt;对Tokenized U.S. Treasuries的交易行为进行实证分析，特别是分析机构投资者和零售用户之间的行为差异。&lt;h4&gt;方法&lt;/h4&gt;通过分析编码的合约调用，区分发行、赎回、转让和桥接活动等核心功能原语，并引入Poincaré嵌入和基于流动性的图特征表示学习框架来建模地址级别的经济角色。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，机构投资者和零售用户在行为上存在差异，并提出的方法在角色推断任务上优于基线模型，并且可以推广到异常检测和钱包分类等下游任务。&lt;h4&gt;结论&lt;/h4&gt;这些发现为交易层面的Tokenized Treasury提供了结构化的理解，为链上金融化研究提供了新的实证证据。&lt;h4&gt;翻译&lt;/h4&gt;Tokenized U.S. Treasuries作为现实世界资产的一个显著子类别，提供基于加密的收益工具，以主权债务作为抵押，并在多个区块链网络上部署。尽管市场迅速扩张，但关于交易层面的实证分析仍然有限。本文对包括BUIDL、BENJI和USDY在内的美国国债支持的RWAs进行了定量和功能层面的剖析，研究范围覆盖了多链网络，主要是以太坊和Layer-2s。通过分析编码的合约调用，我们区分了发行、赎回、转让和桥接等核心功能原语，揭示了机构参与者与零售用户之间的行为分割。为了建模地址级别的经济角色，我们引入了一个使用Poincaré嵌入和基于流动性的图特征表示学习框架。我们的方法在RWAs国债数据集上的角色推断任务上优于基线模型，并且可以推广到更广泛的区块链交易网络中的异常检测和钱包分类等下游任务。这些发现为交易层面的Tokenized Treasury提供了结构化的理解，为链上金融化研究提供了新的实证证据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tokenized U.S. Treasuries have emerged as a prominent subclass of real-worldassets (RWAs), offering cryptographically enforced, yield-bearing instrumentscollateralized by sovereign debt and deployed across multiple blockchainnetworks. While the market has expanded rapidly, empirical analyses oftransaction-level behaviour remain limited. This paper conducts a quantitative,function-level dissection of U.S. Treasury-backed RWA tokens including BUIDL,BENJI, and USDY, across multi-chain: mostly Ethereum and Layer-2s. We analyzedecoded contract calls to isolate core functional primitives such as issuance,redemption, transfer, and bridge activity, revealing segmentation in behaviourbetween institutional actors and retail users. To model address-level economicroles, we introduce a curvature-aware representation learning framework usingPoincar\'e embeddings and liquidity-based graph features. Our methodoutperforms baseline models on our RWA Treasury dataset in role inference andgeneralizes to downstream tasks such as anomaly detection and walletclassification in broader blockchain transaction networks. These findingsprovide a structured understanding of functional heterogeneity and participantroles in tokenized Treasury in a transaction-level perspective, contributingnew empirical evidence to the study of on-chain financialization.</description>
      <author>example@mail.com (Junliang Luo, Katrin Tinn, Samuel Ferreira Duran, Di Wu, Xue Liu)</author>
      <guid isPermaLink="false">2507.14808v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Language Models as Ontology Encoders</title>
      <link>http://arxiv.org/abs/2507.14334v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的本体嵌入方法OnT，用于在Web本体语言OWL中有效地结合文本标签，同时保留描述逻辑EL的类层次和其他逻辑关系。&lt;h4&gt;背景&lt;/h4&gt;OWL本体在复杂知识表示和语义推理方面被广泛采用。然而，现有的本体嵌入方法存在局限性，如忽略文本信息或无法保留逻辑结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过几何建模在双曲空间中调整预训练语言模型，以有效地结合文本标签并保留逻辑结构。&lt;h4&gt;方法&lt;/h4&gt;OnT方法通过在双曲空间中对预训练语言模型进行微调，结合文本标签和描述逻辑EL的逻辑结构。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界本体上的实验表明，OnT在预测和公理推理任务上均优于基线方法，包括最先进的基线。&lt;h4&gt;结论&lt;/h4&gt;OnT方法在真实世界应用中显示出强大的潜力，具有鲁棒的迁移学习能力和在构建新本体方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new ontology embedding method OnT, which effectively integrates textual labels and preserves the logical structure of Description Logic EL by tuning a Pretrained Language Model (PLM) via geometric modeling in a hyperbolic space. Experiments on four real-world ontologies show that OnT consistently outperforms the baselines, including the state-of-the-art, across both tasks of prediction and inference of axioms. OnT also demonstrates strong potential in real-world applications, indicated by its robust transfer learning abilities and effectiveness in real cases of constructing a new ontology from SNOMED CT. Data and code are available at https://github.com/HuiYang1997/OnT.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; OWL (Web Ontology Language) ontologies which are able to formally representcomplex knowledge and support semantic reasoning have been widely adoptedacross various domains such as healthcare and bioinformatics. Recently,ontology embeddings have gained wide attention due to its potential to inferplausible new knowledge and approximate complex reasoning. However, existingmethods face notable limitations: geometric model-based embeddings typicallyoverlook valuable textual information, resulting in suboptimal performance,while the approaches that incorporate text, which are often based on languagemodels, fail to preserve the logical structure. In this work, we propose a newontology embedding method OnT, which tunes a Pretrained Language Model (PLM)via geometric modeling in a hyperbolic space for effectively incorporatingtextual labels and simultaneously preserving class hierarchies and otherlogical relationships of Description Logic EL. Extensive experiments on fourreal-world ontologies show that OnT consistently outperforms the baselinesincluding the state-of-the-art across both tasks of prediction and inference ofaxioms. OnT also demonstrates strong potential in real-world applications,indicated by its robust transfer learning abilities and effectiveness in realcases of constructing a new ontology from SNOMED CT. Data and code areavailable at https://github.com/HuiYang1997/OnT.</description>
      <author>example@mail.com (Hui Yang, Jiaoyan Chen, Yuan He, Yongsheng Gao, Ian Horrocks)</author>
      <guid isPermaLink="false">2507.14334v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>DCHM: Depth-Consistent Human Modeling for Multiview Detection</title>
      <link>http://arxiv.org/abs/2507.14505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  multi-view detection, sparse-view reconstruction&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Depth-Consistent Human Modeling (DCHM)的框架，用于在全局坐标系中进行一致深度估计和多视角融合，以实现行人检测中的高质量人类建模。&lt;h4&gt;背景&lt;/h4&gt;多视角行人检测通常包括人类建模和行人定位两个阶段。人类建模通过融合多视角信息在3D空间中表征行人，其质量对检测精度至关重要。然而，现有方法往往引入噪声且精度较低。&lt;h4&gt;目的&lt;/h4&gt;消除对人工标注的依赖，并准确地建模行人。&lt;h4&gt;方法&lt;/h4&gt;DCHM采用超像素级别的高斯分层技术，在稀疏视图、大尺度、拥挤场景中实现多视角深度一致性，为行人定位生成精确的点云。&lt;h4&gt;主要发现&lt;/h4&gt;DCHM显著减少了人类建模过程中的噪声，优于现有的最佳基线方法。此外，据我们所知，DCHM是第一个在这样的挑战性设置下重建行人和执行多视角分割的方法。&lt;h4&gt;结论&lt;/h4&gt;DCHM在多视角行人检测中提供了高质量的人类建模，有效提高了检测精度，并且无需依赖人工标注。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多视角行人检测通常涉及两个阶段：人类建模和行人定位。人类建模通过融合多视角信息在3D空间中表征行人，其质量对检测精度至关重要。然而，现有方法往往引入噪声且精度较低。虽然一些方法通过拟合昂贵的多视角3D标注来减少噪声，但它们往往难以泛化到不同的场景。为了消除对人工标注的依赖并准确建模行人，我们提出了深度一致的人类建模（DCHM），这是一个设计用于在全局坐标系中进行一致深度估计和多视角融合的框架。具体来说，我们提出的管道通过超像素级别的高斯分层技术，在稀疏视图、大尺度、拥挤场景中实现了多视角深度一致性，为行人定位生成了精确的点云。大量的验证表明，我们的方法在人类建模过程中显著减少了噪声，优于现有的最佳基线。此外，据我们所知，DCHM是第一个在这样的挑战性设置下重建行人和执行多视角分割的方法。代码可在项目页面https://jiahao-ma.github.io/DCHM/上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiview pedestrian detection typically involves two stages: human modelingand pedestrian localization. Human modeling represents pedestrians in 3D spaceby fusing multiview information, making its quality crucial for detectionaccuracy. However, existing methods often introduce noise and have lowprecision. While some approaches reduce noise by fitting on costly multiview 3Dannotations, they often struggle to generalize across diverse scenes. Toeliminate reliance on human-labeled annotations and accurately model humans, wepropose Depth-Consistent Human Modeling (DCHM), a framework designed forconsistent depth estimation and multiview fusion in global coordinates.Specifically, our proposed pipeline with superpixel-wise Gaussian Splattingachieves multiview depth consistency in sparse-view, large-scaled, and crowdedscenarios, producing precise point clouds for pedestrian localization.Extensive validations demonstrate that our method significantly reduces noiseduring human modeling, outperforming previous state-of-the-art baselines.Additionally, to our knowledge, DCHM is the first to reconstruct pedestriansand perform multiview segmentation in such a challenging setting. Code isavailable on the \href{https://jiahao-ma.github.io/DCHM/}{project page}.</description>
      <author>example@mail.com (Jiahao Ma, Tianyu Wang, Miaomiao Liu, David Ahmedt-Aristizabal, Chuong Nguyen)</author>
      <guid isPermaLink="false">2507.14505v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Collaborative Indirect Influencing and Control on Graphs using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.14409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2503.15360&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种解决网络系统中间接影响问题的创新方法，该方法中合作节点需要调节具有不确定动态的目标节点以跟随期望轨迹。&lt;h4&gt;背景&lt;/h4&gt;网络系统中，节点需要实时学习未知的目标动态。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于图神经网络（GNN）的回溯控制策略，并确保其稳定性。&lt;h4&gt;方法&lt;/h4&gt;利用图神经网络的消息传递结构，使节点能够集体学习未知的目标动态。通过基于李雅普诺夫的分析推导出形式上的稳定性保证。&lt;h4&gt;主要发现&lt;/h4&gt;包括数值模拟以展示所开发控制器的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效解决网络系统中的间接影响问题，并通过数值模拟验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种解决网络系统中间接影响问题的创新方法，该方法中合作节点需要调节具有不确定动态的目标节点以跟随期望轨迹。我们利用图神经网络（GNN）的消息传递结构，允许节点实时集体学习未知的目标动态。我们开发了一种基于GNN的回溯控制策略，并从基于李雅普诺夫的分析中推导出形式上的稳定性保证。包括数值模拟以展示所开发控制器的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel approach to solving the indirect influenceproblem in networked systems, in which cooperative nodes must regulate a targetnode with uncertain dynamics to follow a desired trajectory. We leverage themessage-passing structure of a graph neural network (GNN), allowing nodes tocollectively learn the unknown target dynamics in real time. We develop a novelGNN-based backstepping control strategy with formal stability guaranteesderived from a Lyapunov-based analysis. Numerical simulations are included todemonstrate the performance of the developed controller.</description>
      <author>example@mail.com (Max L. Gardenswartz, Brandon C. Fallin, Cristian F. Nino, Warren E. Dixon)</author>
      <guid isPermaLink="false">2507.14409v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Training Self-Supervised Depth Completion Using Sparse Measurements and a Single Image</title>
      <link>http://arxiv.org/abs/2507.14845v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的自监督深度补全方法，旨在从稀疏深度测量中恢复密集深度图。&lt;h4&gt;背景&lt;/h4&gt;深度补全是一个重要的视觉任务，尽管已有许多努力提高稀疏深度测量生成的深度图质量，但训练模型从稀疏测量中恢复密集深度仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决获取密集标注成本高和多帧依赖限制自监督方法在静态或单帧场景中应用的问题，本文提出了一种新的自监督深度补全范式。&lt;h4&gt;方法&lt;/h4&gt;该方法仅需要稀疏深度测量及其对应图像进行训练，通过利用深度分布的特性，设计新的损失函数，有效地将深度信息从观测点传播到未观测区域。此外，还结合了由视觉基础模型生成的分割图来进一步优化深度估计。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在深度补全任务中是有效的。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为从稀疏深度测量中恢复密集深度提供了一种新的解决方案，并显示出其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth completion is an important vision task, and many efforts have been madeto enhance the quality of depth maps from sparse depth measurements. Despitesignificant advances, training these models to recover dense depth from sparsemeasurements remains a challenging problem. Supervised learning methods rely ondense depth labels to predict unobserved regions, while self-supervisedapproaches require image sequences to enforce geometric constraints andphotometric consistency between frames. However, acquiring dense annotations iscostly, and multi-frame dependencies limit the applicability of self-supervisedmethods in static or single-frame scenarios. To address these challenges, wepropose a novel self-supervised depth completion paradigm that requires onlysparse depth measurements and their corresponding image for training. Unlikeexisting methods, our approach eliminates the need for dense depth labels oradditional images captured from neighboring viewpoints. By leveraging thecharacteristics of depth distribution, we design novel loss functions thateffectively propagate depth information from observed points to unobservedregions. Additionally, we incorporate segmentation maps generated by visionfoundation models to further enhance depth estimation. Extensive experimentsdemonstrate the effectiveness of our proposed method.</description>
      <author>example@mail.com (Rizhao Fan, Zhigen Li, Heping Li, Ning An)</author>
      <guid isPermaLink="false">2507.14845v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks</title>
      <link>http://arxiv.org/abs/2507.14679v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的垃圾文本检测框架GCC-Spam，用于应对互联网上垃圾文本的指数增长，解决垃圾邮件发送者使用的对抗策略和数据标注稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;随着互联网上垃圾文本数量的激增，需要强大的检测机制来减轻信息泄露和社会不稳定等风险。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决垃圾邮件发送者使用的对抗策略和数据标注稀缺这两个主要挑战。&lt;h4&gt;方法&lt;/h4&gt;提出的GCC-Spam框架包含三个核心创新：1）字符相似性网络捕捉字符和发音特征以对抗字符混淆攻击，并生成句子嵌入用于下游分类；2）对比学习通过优化潜在空间中垃圾文本和正常文本之间的距离来增强区分度；3）生成对抗网络（GAN）生成逼真的伪垃圾文本样本，以缓解数据稀缺问题，同时提高模型鲁棒性和分类精度。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界数据集上的实验表明，GCC-Spam模型优于基线方法，在标记样本显著减少的情况下实现了更高的检测率。&lt;h4&gt;结论&lt;/h4&gt;GCC-Spam框架能够有效地检测垃圾文本，提高了检测率和模型的鲁棒性，对于减轻信息泄露和社会不稳定等风险具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：互联网上垃圾文本的指数增长需要强大的检测机制来减轻信息泄露和社会不稳定等风险。本研究针对垃圾邮件发送者使用的对抗策略和数据标注稀缺问题，提出了一种新的垃圾文本检测框架GCC-Spam，该框架集成了三个核心创新：一是字符相似性网络捕捉字符和发音特征以对抗字符混淆攻击，并生成句子嵌入用于下游分类；二是对比学习通过优化潜在空间中垃圾文本和正常文本之间的距离来增强区分度；三是生成对抗网络（GAN）生成逼真的伪垃圾文本样本，以缓解数据稀缺问题，同时提高模型鲁棒性和分类精度。在真实世界数据集上的实验表明，GCC-Spam模型优于基线方法，在标记样本显著减少的情况下实现了更高的检测率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The exponential growth of spam text on the Internet necessitates robustdetection mechanisms to mitigate risks such as information leakage and socialinstability. This work addresses two principal challenges: adversarialstrategies employed by spammers and the scarcity of labeled data. We propose anovel spam-text detection framework GCC-Spam, which integrates three coreinnovations. First, a character similarity network captures orthographic andphonetic features to counter character-obfuscation attacks and furthermoreproduces sentence embeddings for downstream classification. Second, contrastivelearning enhances discriminability by optimizing the latent-space distancebetween spam and normal texts. Third, a Generative Adversarial Network (GAN)generates realistic pseudo-spam samples to alleviate data scarcity whileimproving model robustness and classification accuracy. Extensive experimentson real-world datasets demonstrate that our model outperforms baselineapproaches, achieving higher detection rates with significantly fewer labeledexamples.</description>
      <author>example@mail.com (Zixin Xu, Zhijie Wang, Zhiyuan Pan)</author>
      <guid isPermaLink="false">2507.14679v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2507.14748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了强化学习中的自监督特征学习和预训练方法，特别是基于互信息技能学习（MISL）的方法。通过对比成功者特征（CSF）方法，文章证明了CSF能够恢复环境特征，并分析了不同互信息目标的影响和熵正则化器的缺点。&lt;h4&gt;背景&lt;/h4&gt;自监督特征学习和预训练方法在强化学习中常用，基于信息论原理的MISL方法旨在学习环境表示并激励探索。&lt;h4&gt;目的&lt;/h4&gt;研究MISL方法中表示学习和互信息参数化的作用，并解释不同互信息目标的影响。&lt;h4&gt;方法&lt;/h4&gt;通过对比成功者特征（CSF）方法，对MISL进行理论分析。&lt;h4&gt;主要发现&lt;/h4&gt;证明了CSF能够恢复环境特征，并揭示了不同互信息目标和熵正则化器的优缺点。&lt;h4&gt;结论&lt;/h4&gt;CSF能够有效地恢复环境特征，为理解MISL提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates self-supervised feature learning and pretraining methods in reinforcement learning (RL), especially the method based on mutual information skill learning (MISL). By focusing on the Contrastive Successor Features (CSF) method, the paper proves that CSF can recover the environmental features and analyzes the implications of different mutual information objectives and the downsides of entropy regularizers.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised feature learning and pretraining methods in reinforcementlearning (RL) often rely on information-theoretic principles, termed mutualinformation skill learning (MISL). These methods aim to learn a representationof the environment while also incentivizing exploration thereof. However, therole of the representation and mutual information parametrization in MISL isnot yet well understood theoretically. Our work investigates MISL through thelens of identifiable representation learning by focusing on the ContrastiveSuccessor Features (CSF) method. We prove that CSF can provably recover theenvironment's ground-truth features up to a linear transformation due to theinner product parametrization of the features and skill diversity in adiscriminative sense. This first identifiability guarantee for representationlearning in RL also helps explain the implications of different mutualinformation objectives and the downsides of entropy regularizers. Weempirically validate our claims in MuJoCo and DeepMind Control and show how CSFprovably recovers the ground-truth features both from states and pixels.</description>
      <author>example@mail.com (Patrik Reizinger, Bálint Mucsányi, Siyuan Guo, Benjamin Eysenbach, Bernhard Schölkopf, Wieland Brendel)</author>
      <guid isPermaLink="false">2507.14748v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>MP-GCAN: a highly accurate classifier for $α$-helical membrane proteins and $β$-barrel proteins</title>
      <link>http://arxiv.org/abs/2507.14269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8pages,4figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MP-GCAN的新颖图神经网络模型，用于膜蛋白分类，通过结合空间和序列特征，显著提高了分类准确性和F1分数。&lt;h4&gt;背景&lt;/h4&gt;膜蛋白分类在结构生物信息学中至关重要，对理解蛋白质功能和加速药物发现具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图神经网络的膜蛋白分类模型，以提高分类准确率。&lt;h4&gt;方法&lt;/h4&gt;MP-GCAN模型结合了GCN、GAT和GIN层，从3D蛋白质图中捕获层次结构表示，该图由高分辨率PDB文件中的α碳坐标和残基类型构建。通过AlphaFold的pLDDT分数和DeepTMHMM模型进行基准比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MP-GCAN在两种类别上都显著优于基准模型，实现了96%的准确率和强大的F1分数。&lt;h4&gt;结论&lt;/h4&gt;将预训练的GNN架构与特定领域的结构数据相结合，对于提高膜蛋白分类性能至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要：膜蛋白分类是结构生物信息学中的基本任务，对于理解蛋白质功能和加速药物发现至关重要。在本研究中，我们提出了一种名为MP-GCAN的新型基于图的分类模型，该模型利用了蛋白质的空间和序列特征。MP-GCAN结合了GCN、GAT和GIN层，从3D蛋白质图中捕获层次结构表示，这些图是由包含α碳坐标和残基类型的高分辨率PDB文件构建的。为了评估性能，我们创建了一个包含500个膜蛋白和500个非膜蛋白的高质量数据集，并将MP-GCAN与两种基线进行了比较：一种基于结构置信度的SGD分类器，利用AlphaFold的pLDDT分数，以及DeepTMHMM，一个基于序列的深度学习模型。我们的实验表明，MP-GCAN在两种类别上都显著优于基线，实现了96%的准确率和强大的F1分数。结果表明，将预训练的GNN架构与特定领域的结构数据相结合对于提高膜蛋白分类性能至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Membrane protein classification is a fundamental task in structuralbioinformatics, critical to understanding protein functions and acceleratingdrug discovery. In this study, we propose MP-GCAN, a novel graph-basedclassification model that leverages both spatial and sequential features ofproteins. MP-GCAN combines GCN, GAT, and GIN layers to capture hierarchicalstructural representations from 3D protein graphs, constructed fromhigh-resolution PDB files with $\alpha$-carbon coordinates and residue types.To evaluate performance, we curated a high-quality dataset of 500 membrane and500 non-membrane proteins, and compared MP-GCAN with two baselines: astructure-confidence-based SGD classifier utilizing AlphaFold's pLDDT scores,and DeepTMHMM, a sequence-based deep learning model. Our experimentsdemonstrate that MP-GCAN significantly outperforms baselines, achieving anaccuracy of 96% and strong F1-scores on both classes. The results highlight theimportance of integrating pretrained GNN architectures with domain-specificstructural data to enhance membrane protein classification.</description>
      <author>example@mail.com (Kunyang Li, Hongfu Lou, Dinan Peng)</author>
      <guid isPermaLink="false">2507.14269v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey</title>
      <link>http://arxiv.org/abs/2507.14501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A project page associated with this survey is available at  https://fnzhan.com/projects/Feed-Forward-3D&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于深度学习的3D重建和视图合成的feed-forward技术，讨论了其在计算机视觉、图形学以及增强现实、虚拟现实和数字孪生等领域的应用。&lt;h4&gt;背景&lt;/h4&gt;3D重建和视图合成是计算机视觉、图形学和沉浸式技术的基础问题，传统方法计算量大，迭代优化复杂，限制了其在现实场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;本文旨在全面回顾feed-forward技术在3D重建和视图合成中的应用，并讨论其未来研究方向。&lt;h4&gt;方法&lt;/h4&gt;本文根据底层表示架构对feed-forward技术进行了分类，包括点云、3D高斯分裂（3DGS）、神经辐射场（NeRF）等，并考察了关键任务如自由姿态重建、动态3D重建和3D感知图像与视频合成。&lt;h4&gt;主要发现&lt;/h4&gt;本文对常用的数据集进行了详细统计，并提供了各种下游任务的评估协议，同时讨论了开放的研究挑战和未来工作的前景。&lt;h4&gt;结论&lt;/h4&gt;本文强调了feed-forward方法在推进3D视觉领域的最新进展中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D reconstruction and view synthesis are foundational problems in computervision, graphics, and immersive technologies such as augmented reality (AR),virtual reality (VR), and digital twins. Traditional methods rely oncomputationally intensive iterative optimization in a complex chain, limitingtheir applicability in real-world scenarios. Recent advances in feed-forwardapproaches, driven by deep learning, have revolutionized this field by enablingfast and generalizable 3D reconstruction and view synthesis. This survey offersa comprehensive review of feed-forward techniques for 3D reconstruction andview synthesis, with a taxonomy according to the underlying representationarchitectures including point cloud, 3D Gaussian Splatting (3DGS), NeuralRadiance Fields (NeRF), etc. We examine key tasks such as pose-freereconstruction, dynamic 3D reconstruction, and 3D-aware image and videosynthesis, highlighting their applications in digital humans, SLAM, robotics,and beyond. In addition, we review commonly used datasets with detailedstatistics, along with evaluation protocols for various downstream tasks. Weconclude by discussing open research challenges and promising directions forfuture work, emphasizing the potential of feed-forward approaches to advancethe state of the art in 3D vision.</description>
      <author>example@mail.com (Jiahui Zhang, Yuelei Li, Anpei Chen, Muyu Xu, Kunhao Liu, Jianyuan Wang, Xiao-Xiao Long, Hanxue Liang, Zexiang Xu, Hao Su, Christian Theobalt, Christian Rupprecht, Andrea Vedaldi, Hanspeter Pfister, Shijian Lu, Fangneng Zhan)</author>
      <guid isPermaLink="false">2507.14501v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Foundation Models with Multimodal Public Electronic Health Records</title>
      <link>http://arxiv.org/abs/2507.14824v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究评估了基础模型在处理电子健康记录（EHRs）方面的性能、公平性和可解释性，并开发了标准化数据处理流程，以支持多模态人工智能系统在临床应用中的发展。&lt;h4&gt;背景&lt;/h4&gt;基础模型已成为处理EHRs的有效方法，能够灵活处理不同医学数据模态。&lt;h4&gt;目的&lt;/h4&gt;评估基础模型在作为单模态编码器和多模态学习者的性能、公平性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;使用MIMIC-IV数据库，开发标准化数据处理流程，比较了包括单模态和多模态模型在内的八种基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;结合多种数据模态可以提高预测性能，而不会引入额外的偏差。&lt;h4&gt;结论&lt;/h4&gt;该基准旨在支持开发有效的、值得信赖的多模态人工智能系统，以用于现实世界的临床应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型已成为处理电子健康记录（EHRs）的一种强大方法，它提供了处理各种医学数据模态的灵活性。在这项研究中，我们提出一个全面的基准，用于评估基础模型作为单模态编码器和多模态学习者的性能、公平性和可解释性，使用了公开可用的MIMIC-IV数据库。为了支持一致和可重复的评估，我们开发了一个标准化数据处理流程，将异构的临床记录统一为分析格式。我们系统地比较了包括单模态和多模态模型以及特定领域和通用变体在内的八种基础模型。我们的结果表明，结合多种数据模态可以一致地提高预测性能，而不会引入额外的偏差。通过这个基准，我们旨在支持开发有效的和值得信赖的多模态人工智能系统，用于现实世界的临床应用。我们的代码可在https://github.com/nliulab/MIMIC-Multimodal上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have emerged as a powerful approach for processingelectronic health records (EHRs), offering flexibility to handle diversemedical data modalities. In this study, we present a comprehensive benchmarkthat evaluates the performance, fairness, and interpretability of foundationmodels, both as unimodal encoders and as multimodal learners, using thepublicly available MIMIC-IV database. To support consistent and reproducibleevaluation, we developed a standardized data processing pipeline thatharmonizes heterogeneous clinical records into an analysis-ready format. Wesystematically compared eight foundation models, encompassing both unimodal andmultimodal models, as well as domain-specific and general-purpose variants. Ourfindings demonstrate that incorporating multiple data modalities leads toconsistent improvements in predictive performance without introducingadditional bias. Through this benchmark, we aim to support the development ofeffective and trustworthy multimodal artificial intelligence (AI) systems forreal-world clinical applications. Our code is available athttps://github.com/nliulab/MIMIC-Multimodal.</description>
      <author>example@mail.com (Kunyu Yu, Rui Yang, Jingchi Liao, Siqi Li, Huitao Li, Irene Li, Yifan Peng, Rishikesan Kamaleswaran, Nan Liu)</author>
      <guid isPermaLink="false">2507.14824v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Graph Contrastive Learning on Anomaly Detection: A Structural Imbalance Perspective</title>
      <link>http://arxiv.org/abs/2507.14677v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAAI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AD-GCL的新型图对比学习（GCL）框架，用于异常检测，旨在解决现有GCL模型在结构不平衡和异常节点检测方面的不足。&lt;h4&gt;背景&lt;/h4&gt;现有的GCL模型在异常检测任务中往往过于注重整体检测性能，而忽视了对抗结构不平衡的鲁棒性，这在许多遵循幂律度分布的现实网络中可能成为问题。&lt;h4&gt;目的&lt;/h4&gt;旨在提高当前异常检测算法的安全性、鲁棒性，并使其适用于多种现实的高风险场景。&lt;h4&gt;方法&lt;/h4&gt;AD-GCL采用邻居剪枝策略过滤噪声边，从头部节点到伪造尾部节点对齐，以便检测真正的尾部节点。此外，它通过异常引导的邻居完成来主动探索潜在邻居以扩大尾部节点的感受野。还引入了原始和增强图的内部和外部视图一致性损失，以增强表示。&lt;h4&gt;主要发现&lt;/h4&gt;在多个数据集上对整个、头部和尾部节点的性能评估验证了AD-GCL在检测头部和尾部异常方面的综合优越性。&lt;h4&gt;结论&lt;/h4&gt;AD-GCL框架在检测异常方面表现出色，能够有效地解决现有GCL模型的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The superiority of graph contrastive learning (GCL) has prompted itsapplication to anomaly detection tasks for more powerful risk warning systems.Unfortunately, existing GCL-based models tend to excessively prioritize overalldetection performance while neglecting robustness to structural imbalance,which can be problematic for many real-world networks following power-lawdegree distributions. Particularly, GCL-based methods may fail to capture tailanomalies (abnormal nodes with low degrees). This raises concerns about thesecurity and robustness of current anomaly detection algorithms and thereforehinders their applicability in a variety of realistic high-risk scenarios. Tothe best of our knowledge, research on the robustness of graph anomalydetection to structural imbalance has received little scrutiny. To address theabove issues, this paper presents a novel GCL-based framework named AD-GCL. Itdevises the neighbor pruning strategy to filter noisy edges for head nodes andfacilitate the detection of genuine tail nodes by aligning from head nodes toforged tail nodes. Moreover, AD-GCL actively explores potential neighbors toenlarge the receptive field of tail nodes through anomaly-guided neighborcompletion. We further introduce intra- and inter-view consistency loss of theoriginal and augmentation graph for enhanced representation. The performanceevaluation of the whole, head, and tail nodes on multiple datasets validatesthe comprehensive superiority of the proposed AD-GCL in detecting both headanomalies and tail anomalies.</description>
      <author>example@mail.com (Yiming Xu, Zhen Peng, Bin Shi, Xu Hua, Bo Dong, Song Wang, Chen Chen)</author>
      <guid isPermaLink="false">2507.14677v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Fraud is Not Just Rarity: A Causal Prototype Attention Approach to Realistic Synthetic Oversampling</title>
      <link>http://arxiv.org/abs/2507.14706v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的欺诈信用卡交易检测方法，旨在解决现实数据中类别不平衡和欺诈与合法活动之间微妙模式的问题。&lt;h4&gt;背景&lt;/h4&gt;检测欺诈信用卡交易是一个重大挑战，因为现实数据中存在极端的类别不平衡，且欺诈与合法活动之间的模式往往微妙。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的分类器，即因果原型注意力分类器（CPAC），以促进类感知聚类和改进潜在空间结构，并通过VAE-GAN的编码器结合，以实现更好的聚类分离。&lt;h4&gt;方法&lt;/h4&gt;CPAC通过原型基础上的注意力机制来促进类感知聚类和改进潜在空间结构，并与VAE-GAN的编码器结合使用。同时，将CPAC增强模型与传统的过采样方法（如SMOTE）以及最先进的生成模型进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;CPAC引导的潜在形状在检测欺诈方面表现出优异的性能，实现了93.14%的F1分数和90.18%的召回率，并提高了潜在聚类分离。&lt;h4&gt;结论&lt;/h4&gt;CPAC增强模型在欺诈检测方面优于传统的过采样方法和最先进的生成模型，并且对分类器驱动的表示学习在欺诈检测中的优势和局限性提供了深入的见解。&lt;h4&gt;翻译&lt;/h4&gt;Detecting fraudulent credit card transactions remains a significant challenge, due to the extreme class imbalance in real-world data and the often subtle patterns that separate fraud from legitimate activity. Existing research commonly attempts to address this by generating synthetic samples for the minority class using approaches such as GANs, VAEs, or hybrid generative models. However, these techniques, particularly when applied only to minority-class data, tend to result in overconfident classifiers and poor latent cluster separation, ultimately limiting real-world detection performance. In this study, we propose the Causal Prototype Attention Classifier (CPAC), an interpretable architecture that promotes class-aware clustering and improved latent space structure through prototype-based attention mechanisms and we will couple it with the encoder in a VAE-GAN allowing it to offer a better cluster separation moving beyond post-hoc sample augmentation. We compared CPAC-augmented models to traditional oversamplers, such as SMOTE, as well as to state-of-the-art generative models, both with and without CPAC-based latent classifiers. Our results show that classifier-guided latent shaping with CPAC delivers superior performance, achieving an F1-score of 93.14% percent and recall of 90.18%, along with improved latent cluster separation. Further ablation studies and visualizations provide deeper insight into the benefits and limitations of classifier-driven representation learning for fraud detection. The codebase for this work will be available at final submission.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting fraudulent credit card transactions remains a significantchallenge, due to the extreme class imbalance in real-world data and the oftensubtle patterns that separate fraud from legitimate activity. Existing researchcommonly attempts to address this by generating synthetic samples for theminority class using approaches such as GANs, VAEs, or hybrid generativemodels. However, these techniques, particularly when applied only tominority-class data, tend to result in overconfident classifiers and poorlatent cluster separation, ultimately limiting real-world detectionperformance. In this study, we propose the Causal Prototype AttentionClassifier (CPAC), an interpretable architecture that promotes class-awareclustering and improved latent space structure through prototype-basedattention mechanisms and we will couple it with the encoder in a VAE-GANallowing it to offer a better cluster separation moving beyond post-hoc sampleaugmentation. We compared CPAC-augmented models to traditional oversamplers,such as SMOTE, as well as to state-of-the-art generative models, both with andwithout CPAC-based latent classifiers. Our results show that classifier-guidedlatent shaping with CPAC delivers superior performance, achieving an F1-scoreof 93.14\% percent and recall of 90.18\%, along with improved latent clusterseparation. Further ablation studies and visualizations provide deeper insightinto the benefits and limitations of classifier-driven representation learningfor fraud detection. The codebase for this work will be available at finalsubmission.</description>
      <author>example@mail.com (Claudio Giusti, Luca Guarnera, Mirko Casu, Sebastiano Battiato)</author>
      <guid isPermaLink="false">2507.14706v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing POI Recommendation through Global Graph Disentanglement with POI Weighted Module</title>
      <link>http://arxiv.org/abs/2507.14612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GDPW的下一代兴趣点推荐框架，用于预测用户的未来活动。该框架旨在解决现有方法在处理兴趣点类别和时间关系、时间信息的连续性以及兴趣点权重信息方面的不足。&lt;h4&gt;背景&lt;/h4&gt;兴趣点推荐系统依赖于用户的签到数据，但现有方法通常没有充分考虑到不同兴趣点类别的时间分布以及时间信息的连续性和兴趣点的权重。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的兴趣点推荐框架，能够同时考虑兴趣点类别信息和多个兴趣点权重因素，提高推荐精度。&lt;h4&gt;方法&lt;/h4&gt;提出的GDPW框架通过全局类别图和全局类别-时间图学习类别和时间表示，然后通过对比学习分离类别和时间信息。预测后，根据兴趣点之间的转换权重和距离关系对预测结果进行加权，以获得最终的兴趣点推荐。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的GDPW在两个真实世界数据集上的性能优于其他现有模型，性能提高了3%到11%。&lt;h4&gt;结论&lt;/h4&gt;GDPW框架通过有效处理兴趣点类别和时间信息以及兴趣点权重，提高了兴趣点推荐的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Next point of interest (POI) recommendation primarily predicts futureactivities based on users' past check-in data and current status, providingsignificant value to users and service providers. We observed that the popularcheck-in times for different POI categories vary. For example, coffee shops arecrowded in the afternoon because people like to have coffee to refresh aftermeals, while bars are busy late at night. However, existing methods rarelyexplore the relationship between POI categories and time, which may result inthe model being unable to fully learn users' tendencies to visit certain POIcategories at different times. Additionally, existing methods for modeling timeinformation often convert it into time embeddings or calculate the timeinterval and incorporate it into the model, making it difficult to capture thecontinuity of time. Finally, during POI prediction, various weightinginformation is often ignored, such as the popularity of each POI, thetransition relationships between POIs, and the distances between POIs, leadingto suboptimal performance. To address these issues, this paper proposes a novelnext POI recommendation framework called Graph Disentangler with POI WeightedModule (GDPW). This framework aims to jointly consider POI category informationand multiple POI weighting factors. Specifically, the proposed GDPW learnscategory and time representations through the Global Category Graph and theGlobal Category-Time Graph. Then, we disentangle category and time informationthrough contrastive learning. After prediction, the final POI recommendationfor users is obtained by weighting the prediction results based on thetransition weights and distance relationships between POIs. We conductedexperiments on two real-world datasets, and the results demonstrate that theproposed GDPW outperforms other existing models, improving performance by 3% to11%.</description>
      <author>example@mail.com (Pei-Xuan Li, Wei-Yun Liang, Fandel Lin, Hsun-Ping Hsieh)</author>
      <guid isPermaLink="false">2507.14612v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition</title>
      <link>http://arxiv.org/abs/2507.14686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MIPD的新框架，通过从教师MLLM中迁移知识到小型GSR模型，增强了模型的泛化能力和零样本能力，从而引入了开放词汇的地面情况识别（Ov-GSR）任务。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态大型语言模型在零样本能力方面表现强劲，但在复杂地面情况识别（GSR）方面存在困难，且对边缘设备的部署资源密集。传统的GSR模型通常泛化能力不足，在识别未见和罕见情况时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;通过将教师MLLM的知识迁移到小型GSR模型，提高其泛化能力和零样本能力，解决GSR模型在识别未见和罕见情况时的不足。&lt;h4&gt;方法&lt;/h4&gt;MIPD框架首先利用基于LLM的判断性理由生成器（JRG）构建带有上下文语义信息的正负视角和注视理由。然后，通过负引导的多模态提示对齐（NMPA）模块引入场景感知和实例感知提示，与MLLM教师模型中的视觉信息对齐，有效捕捉整体和多模态感知知识。最后，将对齐的多模态知识蒸馏到学生Ov-GSR模型中。&lt;h4&gt;主要发现&lt;/h4&gt;MIPD在Ov-SWiG数据集上进行了评估，在已见、罕见和未见情况下均取得了优异的性能，并在HICO-DET数据集上进一步展示了改进的未见检测能力。&lt;h4&gt;结论&lt;/h4&gt;MIPD框架能够有效提升Ov-GSR模型在地面情况识别方面的性能，特别是在处理未见和罕见情况时，提高了模型的泛化能力和预测准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent Multimodal Large Language Models (MLLMs) exhibit strong zero-shotabilities but struggle with complex Grounded Situation Recognition (GSR) andare resource-intensive for edge device deployment. Meanwhile, conventional GSRmodels often lack generalization ability, falling short in recognizing unseenand rare situations. In this paper, we exploit transferring knowledge from ateacher MLLM to a small GSR model to enhance its generalization and zero-shotabilities, thereby introducing the task of Open-vocabulary Grounded SituationRecognition (Ov-GSR). To achieve this, we propose Multimodal Interactive PromptDistillation (MIPD), a novel framework that distills enriched multimodalknowledge from the foundation model, enabling the student Ov-GSR model torecognize unseen situations and be better aware of rare situations.Specifically, the MIPD framework first leverages the LLM-based JudgmentalRationales Generator (JRG) to construct positive and negative glimpse and gazerationales enriched with contextual semantic information. The proposedscene-aware and instance-perception prompts are then introduced to alignrationales with visual information from the MLLM teacher via theNegative-Guided Multimodal Prompting Alignment (NMPA) module, effectivelycapturing holistic and perceptual multimodal knowledge. Finally, the alignedmultimodal knowledge is distilled into the student Ov-GSR model, providing astronger foundation for generalization that enhances situation understanding,bridges the gap between seen and unseen scenarios, and mitigates predictionbias in rare cases. We evaluate MIPD on the refined Ov-SWiG dataset, achievingsuperior performance on seen, rare, and unseen situations, and furtherdemonstrate improved unseen detection on the HICO-DET dataset.</description>
      <author>example@mail.com (Chen Cai, Tianyi Liu, Jianjun Gao, Wenyang Liu, Kejun Wu, Ruoyu Wang, Yi Wang, Soo Chin Liew)</author>
      <guid isPermaLink="false">2507.14686v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning</title>
      <link>http://arxiv.org/abs/2507.14516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为信号Dice相似系数（SDSC）的结构感知度量函数，用于时间序列自监督表示学习，并探讨了其在预测和分类基准测试中的性能。&lt;h4&gt;背景&lt;/h4&gt;大多数自监督学习（SSL）方法对于信号通常采用基于距离的目标函数，如均方误差（MSE），这些方法对幅度敏感、对波形极性不变且尺度无界，这阻碍了语义对齐并降低了可解释性。&lt;h4&gt;目的&lt;/h4&gt;提出SDSC以量化基于时间信号的结构的同意，通过Dice相似系数（DSC）得到的符号幅度来衡量。&lt;h4&gt;方法&lt;/h4&gt;SDSC被定义为一种结构感知度量，但可以通过减去1并应用Heaviside函数的微分近似来用作损失函数。此外，还提出了一种混合损失公式，将SDSC与MSE结合，以提高稳定性并保留必要的幅度。&lt;h4&gt;主要发现&lt;/h4&gt;基于SDSC的预训练在预测和分类基准测试中实现了与MSE相当或更好的性能，尤其是在领域内和低资源场景中。&lt;h4&gt;结论&lt;/h4&gt;信号表示中的结构保真度增强了语义表示质量，支持将结构感知度量作为传统基于距离方法的可行替代方案。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为信号Dice相似系数（SDSC）的结构感知度量函数，用于时间序列自监督表示学习。大多数自监督学习（SSL）方法对于信号通常采用基于距离的目标函数，如均方误差（MSE），这些方法对幅度敏感、对波形极性不变且尺度无界。这些性质阻碍了语义对齐并降低了可解释性。SDSC通过量化基于时间信号的结构的同意来解决这一问题，它基于Dice相似系数（DSC）得到的符号幅度。虽然SDSC被定义为一种结构感知度量，但它可以通过减去1并应用Heaviside函数的微分近似来用作损失函数。此外，还提出了一种混合损失公式，将SDSC与MSE结合，以提高稳定性并保留必要的幅度。在预测和分类基准测试中的实验表明，基于SDSC的预训练在领域内和低资源场景中实现了与MSE相当或更好的性能。这些结果表明，信号表示中的结构保真度增强了语义表示质量，支持将结构感知度量作为传统基于距离方法的可行替代方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose the Signal Dice Similarity Coefficient (SDSC), a structure-awaremetric function for time series self-supervised representation learning. MostSelf-Supervised Learning (SSL) methods for signals commonly adoptdistance-based objectives such as mean squared error (MSE), which are sensitiveto amplitude, invariant to waveform polarity, and unbounded in scale. Theseproperties hinder semantic alignment and reduce interpretability. SDSCaddresses this by quantifying structural agreement between temporal signalsbased on the intersection of signed amplitudes, derived from the DiceSimilarity Coefficient (DSC).Although SDSC is defined as a structure-awaremetric, it can be used as a loss by subtracting from 1 and applying adifferentiable approximation of the Heaviside function for gradient-basedoptimization. A hybrid loss formulation is also proposed to combine SDSC withMSE, improving stability and preserving amplitude where necessary. Experimentson forecasting and classification benchmarks demonstrate that SDSC-basedpre-training achieves comparable or improved performance over MSE, particularlyin in-domain and low-resource scenarios. The results suggest that structuralfidelity in signal representations enhances the semantic representationquality, supporting the consideration of structure-aware metrics as viablealternatives to conventional distance-based methods.</description>
      <author>example@mail.com (Jeyoung Lee, Hochul Kang)</author>
      <guid isPermaLink="false">2507.14516v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Fiduciary AI for the Future of Brain-Technology Interactions</title>
      <link>http://arxiv.org/abs/2507.14339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了脑基础模型在人工智能领域的新进展，提出了将信托责任嵌入脑-机接口（BCI）集成脑基础模型中的技术设计，以确保这些系统在用户最佳利益下运行。&lt;h4&gt;背景&lt;/h4&gt;脑基础模型能够处理来自脑电图（EEG）、功能性磁共振成像（fMRI）等神经技术的实时神经信号，与BCI结合后，可以实现从思维控制设备到神经假肢的变革性应用。&lt;h4&gt;目的&lt;/h4&gt;提出将忠诚、关怀和保密等信托责任直接嵌入BCI集成脑基础模型，以确保这些系统在用户最佳利益下运行。&lt;h4&gt;方法&lt;/h4&gt;借鉴法律传统和人工智能对齐技术的最新进展，本文概述了可实施的建筑和治理机制。&lt;h4&gt;主要发现&lt;/h4&gt;脑基础模型存在前所未有的风险，包括潜意识神经信号的利用和认知自由的侵蚀，用户难以观察或控制其脑信号的解释，导致权力不对称，易受操纵。&lt;h4&gt;结论&lt;/h4&gt;将脑基础模型置于信托基础上对于实现其潜力而不会损害自我决定至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要：脑基础模型代表了人工智能领域的新前沿：这些模型不是处理文本或图像，而是解释来自脑电图（EEG）、功能性磁共振成像（fMRI）和其他神经技术的实时神经信号。当与脑-机接口（BCI）集成时，它们可能通过在毫秒内解释和行动来启用变革性应用——从思维控制设备到神经假肢。然而，这些相同的系统带来了前所未有的风险，包括潜意识神经信号的利用和认知自由的侵蚀。用户无法轻易观察或控制其脑信号的解释，这导致了易受操纵的权力不对称。本文提出通过技术设计将信托责任（忠诚、关怀和保密）直接嵌入BCI集成脑基础模型。借鉴法律传统和人工智能对齐技术的最新进展，我们概述了可实施的建筑和治理机制，以确保这些系统在用户最佳利益下运行。将脑基础模型置于信托基础上对于实现其潜力而不会损害自我决定至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain foundation models represent a new frontier in AI: instead of processingtext or images, these models interpret real-time neural signals from EEG, fMRI,and other neurotechnologies. When integrated with brain-computer interfaces(BCIs), they may enable transformative applications-from thought controlleddevices to neuroprosthetics-by interpreting and acting on brain activity inmilliseconds. However, these same systems pose unprecedented risks, includingthe exploitation of subconscious neural signals and the erosion of cognitiveliberty. Users cannot easily observe or control how their brain signals areinterpreted, creating power asymmetries that are vulnerable to manipulation.This paper proposes embedding fiduciary duties-loyalty, care, andconfidentiality-directly into BCI-integrated brain foundation models throughtechnical design. Drawing on legal traditions and recent advancements in AIalignment techniques, we outline implementable architectural and governancemechanisms to ensure these systems act in users' best interests. Placing brainfoundation models on a fiduciary footing is essential to realizing theirpotential without compromising self-determination.</description>
      <author>example@mail.com (Abhishek Bhattacharjee, Jack Pilkington, Nita Farahany)</author>
      <guid isPermaLink="false">2507.14339v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation</title>
      <link>http://arxiv.org/abs/2507.14239v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为CCL-XCoT的两种阶段微调框架，用于减少多语言大型语言模型（MLLMs）在低资源语言中的幻觉问题，显著降低了幻觉率并提高了跨语言的事实知识迁移。&lt;h4&gt;背景&lt;/h4&gt;尽管MLLMs在跨语言泛化方面表现出色，但它们在低资源语言中容易产生幻觉，这在特定领域的生成任务中尤其成问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决MLLMs在低资源语言中容易产生幻觉的问题。&lt;h4&gt;方法&lt;/h4&gt;CCL-XCoT框架包括两个阶段：首先通过基于课程的对比学习和在继续预训练期间的下一个标记预测来增强跨语言语义对齐；其次，在指令微调阶段引入跨语言思维链（XCoT）提示策略，引导模型在高资源语言中推理后再在目标低资源语言中生成答案。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CCL-XCoT可以将幻觉率降低高达62%，并且显著提高了跨语言对的事实知识迁移，而不依赖于外部检索或多模型集成。&lt;h4&gt;结论&lt;/h4&gt;CCL-XCoT是一种有效的减少MLLMs幻觉的方法，可以显著提高其在低资源语言中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multilingual Large Language Models(MLLMs) demonstrate strong generalizationacross languages, yet they remain prone to hallucinations, especially inlow-resource languages, due to training data imbalances. These hallucinations,which include inaccurate or fabricated outputs, are particularly problematic indomain-specific generation tasks (Chataigner et al., 2024). To address thischallenge, we propose CCL-XCoT(Curriculum-based Contrastive Learning-basedCross-lingual Chain-of-Thought), a two-stage fine-tuning framework formitigating hallucination in MLLMs. Our approach first enhances cross-lingualsemantic alignment through curriculum-based contrastive learning combined withnext-token prediction during continued pre-training. Building on thisfoundation, we then introduce a cross-lingual Chain-of-Thought (XCoT) promptingstrategy during instruction fine-tuning, which guides the model to reason in ahigh-resource language before generating answers in the target low-resourcelanguage. Experimental results show that CCL-XCoT reduces hallucination ratesby up to 62% and substantially improves factual knowledge transfer acrosslanguage pairs, without relying on external retrieval or multi-model ensembles.</description>
      <author>example@mail.com (Weihua Zheng, Roy Ka-Wei Lee, Zhengyuan Liu, Kui Wu, AiTi Aw, Bowei Zou)</author>
      <guid isPermaLink="false">2507.14239v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>A million-scale dataset and generalizable foundation model for nanomaterial-protein interactions</title>
      <link>http://arxiv.org/abs/2507.14245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NanoPro-3M的大规模纳米材料-蛋白质相互作用数据集，并基于此开发了一个名为NanoProFormer的基础模型，用于预测纳米材料与蛋白质之间的亲和力。该模型通过多模态表示学习展现出了强大的泛化能力，能够处理缺失特征和未知纳米材料或蛋白质，显著优于单一模态方法，并识别了冠形成的关键决定因素。此外，通过零样本推理和微调，该模型在下游任务中表现出良好的适用性，为高性能和泛化预测纳米材料-蛋白质相互作用终点奠定了基础，减少了实验依赖并加速了体外应用。&lt;h4&gt;背景&lt;/h4&gt;纳米材料在医学和环境科学领域的应用潜力巨大，但对其与蛋白质相互作用的理解受限，导致AI在相关领域的应用受限。&lt;h4&gt;目的&lt;/h4&gt;提出并构建NanoPro-3M数据集，开发NanoProFormer模型，以预测纳米材料与蛋白质之间的亲和力，并评估模型在下游任务中的应用。&lt;h4&gt;方法&lt;/h4&gt;构建了包含超过320万个样本和37000种独特蛋白质的NanoPro-3M数据集，并开发了一个基于多模态表示学习的NanoProFormer模型。&lt;h4&gt;主要发现&lt;/h4&gt;NanoProFormer模型展现了强大的泛化能力，能够处理缺失特征和未知纳米材料或蛋白质，显著优于单一模态方法，并识别了冠形成的关键决定因素。&lt;h4&gt;结论&lt;/h4&gt;NanoPro-3M数据集和NanoProFormer模型为高性能和泛化预测纳米材料-蛋白质相互作用终点提供了坚实的基础，有助于减少实验依赖并加速体外应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：解锁纳米材料在医学和环境科学中的潜力，关键在于理解它们与蛋白质的相互作用，这是一个复杂的决策空间，AI有望在此领域产生变革性影响。然而，由于数据集有限和现有模型的泛化能力受限，进展受到了阻碍。在此，我们提出了迄今为止最大的纳米材料-蛋白质相互作用数据集NanoPro-3M，包含超过320万个样本和37000种独特的蛋白质。利用这一数据集，我们提出了NanoProFormer基础模型，通过多模态表示学习预测纳米材料-蛋白质亲和力，展现了强大的泛化能力、处理缺失特征和未知纳米材料或蛋白质的能力。我们表明，多模态建模显著优于单一模态方法，并识别了冠形成的关键决定因素。此外，我们通过零样本推理和微调展示了其在下游任务中的适用性。总之，这项工作为高性能和泛化预测纳米材料-蛋白质相互作用终点奠定了坚实的基础，减少了实验依赖并加速了体外应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unlocking the potential of nanomaterials in medicine and environmentalscience hinges on understanding their interactions with proteins, a complexdecision space where AI is poised to make a transformative impact. However,progress has been hindered by limited datasets and the restrictedgeneralizability of existing models. Here, we propose NanoPro-3M, the largestnanomaterial-protein interaction dataset to date, comprising over 3.2 millionsamples and 37,000 unique proteins. Leveraging this, we present NanoProFormer,a foundational model that predicts nanomaterial-protein affinities throughmultimodal representation learning, demonstrating strong generalization,handling missing features, and unseen nanomaterials or proteins. We show thatmultimodal modeling significantly outperforms single-modality approaches andidentifies key determinants of corona formation. Furthermore, we demonstrateits applicability to a range of downstream tasks through zero-shot inferenceand fine-tuning. Together, this work establishes a solid foundation forhigh-performance and generalized prediction of nanomaterial-protein interactionendpoints, reducing experimental reliance and accelerating various in vitroapplications.</description>
      <author>example@mail.com (Hengjie Yu, Kenneth A. Dawson, Haiyun Yang, Shuya Liu, Yan Yan, Yaochu Jin)</author>
      <guid isPermaLink="false">2507.14245v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>Supporting SENCOTEN Language Documentation Efforts with Automatic Speech Recognition</title>
      <link>http://arxiv.org/abs/2507.10827v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ComputEL-8&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了如何利用自动语音识别技术（ASR）支持SENCOTEN语言的复兴，并介绍了基于ASR的文档化流程。&lt;h4&gt;背景&lt;/h4&gt;SENCOTEN语言在温哥华岛南部萨尼奇半岛上使用，由于殖民语言政策导致的语言流失，该语言正处于语言复兴的努力中。&lt;h4&gt;目的&lt;/h4&gt;为了支持这些地面努力，社区正在转向数字技术，特别是ASR技术，以加速语言文档和教育资源的创建。&lt;h4&gt;方法&lt;/h4&gt;由于SENCOTEN语言的词汇多样性和合成结构，开发ASR系统面临挑战。为此，提出了一个ASR驱动的文档流程，该流程利用文本到语音（TTS）系统的增强语音数据和跨语言迁移学习与语音基础模型（SFMs）。此外，通过浅层融合或n-best恢复方法结合n-gram语言模型，以最大化使用现有数据。&lt;h4&gt;主要发现&lt;/h4&gt;在SENCOTEN数据集上的实验显示，测试集的词错误率（WER）为19.34%，字符错误率（CER）为5.09%，其中57.02%的词汇为未知词汇。过滤掉与小撇相关的错误后，WER降至14.32%（在未见词汇上的错误率为26.48%），CER降至3.45%，证明了ASR驱动流程支持SENCOTEN语言文档的潜力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的ASR驱动流程有潜力支持SENCOTEN语言的文档工作，为语言复兴提供技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The SENCOTEN language, spoken on the Saanich peninsula of southern VancouverIsland, is in the midst of vigorous language revitalization efforts to turn thetide of language loss as a result of colonial language policies. To supportthese on-the-ground efforts, the community is turning to digital technology.Automatic Speech Recognition (ASR) technology holds great promise foraccelerating language documentation and the creation of educational resources.However, developing ASR systems for SENCOTEN is challenging due to limited dataand significant vocabulary variation from its polysynthetic structure andstress-driven metathesis. To address these challenges, we propose an ASR-drivendocumentation pipeline that leverages augmented speech data from atext-to-speech (TTS) system and cross-lingual transfer learning with SpeechFoundation Models (SFMs). An n-gram language model is also incorporated viashallow fusion or n-best restoring to maximize the use of available data.Experiments on the SENCOTEN dataset show a word error rate (WER) of 19.34% anda character error rate (CER) of 5.09% on the test set with a 57.02%out-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors, WERimproves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating thepotential of our ASR-driven pipeline to support SENCOTEN languagedocumentation.</description>
      <author>example@mail.com (Mengzhe Geng, Patrick Littell, Aidan Pine, PENÁĆ, Marc Tessier, Roland Kuhn)</author>
      <guid isPermaLink="false">2507.10827v2</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>UWB Radar-based Heart Rate Monitoring: A Transfer Learning Approach</title>
      <link>http://arxiv.org/abs/2507.14195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 11 tables, 9 figures, 14 supplementary tables, 4  supplementary figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了雷达技术在心率监测中的应用潜力，并通过迁移学习技术实现了不同雷达系统之间的心率监测模型共享。&lt;h4&gt;背景&lt;/h4&gt;雷达技术在心率监测方面具有潜力，但由于雷达系统多样化和缺乏标准化，需要大量数据集进行训练。&lt;h4&gt;目的&lt;/h4&gt;通过迁移学习技术，实现不同雷达系统（FMCW和IR-UWB）之间的心率监测模型共享，以加速其在消费电子产品中的应用。&lt;h4&gt;方法&lt;/h4&gt;使用2D+1D ResNet架构进行心率监测，并分别对FMCW雷达和IR-UWB雷达系统进行数据收集和模型训练。&lt;h4&gt;主要发现&lt;/h4&gt;FMCW雷达和IR-UWB雷达系统均能实现心率监测，且迁移学习方法有效降低了MAE和MAPE，提高了模型的召回率。&lt;h4&gt;结论&lt;/h4&gt;迁移学习技术为雷达心率监测在消费电子产品中的应用提供了新的可能性，有助于加速其商业化进程。&lt;h4&gt;翻译&lt;/h4&gt;Radar technology presents untapped potential for continuous, contactless, and passive heart rate monitoring via consumer electronics like mobile phones. However, the variety of available radar systems and lack of standardization means that a large new paired dataset collection is required for each radar system. This study demonstrates transfer learning between frequency-modulated continuous wave (FMCW) and impulse-radio ultra-wideband (IR-UWB) radar systems, both increasingly integrated into consumer devices. FMCW radar utilizes a continuous chirp, while IR-UWB radar employs short pulses. Our mm-wave FMCW radar operated at 60 GHz with a 5.5 GHz bandwidth (2.7 cm resolution, 3 receiving antennas [Rx]), and our IR-UWB radar at 8 GHz with a 500 MHz bandwidth (30 cm resolution, 2 Rx). Using a novel 2D+1D ResNet architecture we achieved a mean absolute error (MAE) of 0.85 bpm and a mean absolute percentage error (MAPE) of 1.42% for heart rate monitoring with FMCW radar (N=119 participants, an average of 8 hours per participant). This model maintained performance (under 5 MAE/10% MAPE) across various body positions and heart rate ranges, with a 98.9% recall. We then fine-tuned a variant of this model, trained on single-antenna and single-range bin FMCW data, using a small (N=376, avg 6 minutes per participant) IR-UWB dataset. This transfer learning approach yielded a model with MAE 4.1 bpm and MAPE 6.3% (97.5% recall), a 25% MAE reduction over the IR-UWB baseline. This demonstration of transfer learning between radar systems for heart rate monitoring has the potential to accelerate its introduction into existing consumer devices.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radar technology presents untapped potential for continuous, contactless, andpassive heart rate monitoring via consumer electronics like mobile phones.However the variety of available radar systems and lack of standardizationmeans that a large new paired dataset collection is required for each radarsystem. This study demonstrates transfer learning between frequency-modulatedcontinuous wave (FMCW) and impulse-radio ultra-wideband (IR-UWB) radar systems,both increasingly integrated into consumer devices. FMCW radar utilizes acontinuous chirp, while IR-UWB radar employs short pulses. Our mm-wave FMCWradar operated at 60 GHz with a 5.5 GHz bandwidth (2.7 cm resolution, 3receiving antennas [Rx]), and our IR-UWB radar at 8 GHz with a 500 MHzbandwidth (30 cm resolution, 2 Rx). Using a novel 2D+1D ResNet architecture weachieved a mean absolute error (MAE) of 0.85 bpm and a mean absolute percentageerror (MAPE) of 1.42% for heart rate monitoring with FMCW radar (N=119participants, an average of 8 hours per participant). This model maintainedperformance (under 5 MAE/10% MAPE) across various body positions and heart rateranges, with a 98.9% recall. We then fine-tuned a variant of this model,trained on single-antenna and single-range bin FMCW data, using a small (N=376,avg 6 minutes per participant) IR-UWB dataset. This transfer learning approachyielded a model with MAE 4.1 bpm and MAPE 6.3% (97.5% recall), a 25% MAEreduction over the IR-UWB baseline. This demonstration of transfer learningbetween radar systems for heart rate monitoring has the potential to accelerateits introduction into existing consumer devices.</description>
      <author>example@mail.com (Elzbieta Gruzewska, Pooja Rao, Sebastien Baur, Matthew Baugh, Mathias M. J. Bellaiche, Sharanya Srinivas, Octavio Ponce, Matthew Thompson, Pramod Rudrapatna, Michael A. Sanchez, Lawrence Z. Cai, Timothy JA Chico, Robert F. Storey, Emily Maz, Umesh Telang, Shravya Shetty, Mayank Daswani)</author>
      <guid isPermaLink="false">2507.14195v1</guid>
      <pubDate>Tue, 22 Jul 2025 14:37:52 +0800</pubDate>
    </item>
    <item>
      <title>MS-DGCNN++: A Multi-Scale Fusion Dynamic Graph Neural Network with Biological Knowledge Integration for LiDAR Tree Species Classification</title>
      <link>http://arxiv.org/abs/2507.12602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MS-DGCNN++的树种分类方法，通过在局部、分支和冠层尺度上进行语义有意义的特征提取，实现了多尺度融合的动态图卷积网络。该方法在树种分类和标准3D物体识别任务中均表现出色，且参数量和复杂度低于现有先进方法。&lt;h4&gt;背景&lt;/h4&gt;从地面LiDAR点云中分类树种具有挑战性，因为森林环境中的树结构具有复杂的多尺度几何结构。现有的多尺度动态图卷积神经网络（MS-DGCNN）方法由于并行多尺度处理，无法捕捉树结构层级之间的语义关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效捕捉树结构语义关系的树种分类方法。&lt;h4&gt;方法&lt;/h4&gt;MS-DGCNN++使用语义有意义的特征提取，包括局部尺度的标准几何特征、分支尺度的归一化相对向量和冠层尺度的距离信息。该方法通过层次化处理代替了均匀并行处理，与自然树结构对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在STPCTL数据集上，MS-DGCNN++的准确率达到94.96%，优于DGCNN、MS-DGCNN和最先进的PPT模型。在FOR-species20K数据集上，准确率达到67.25%，比MS-DGCNN提高了6.1%。在标准3D物体识别任务中，该方法在ModelNet40和ModelNet10上的准确率分别为93.15%和94.05%，优于DGCNN和MS-DGCNN。&lt;h4&gt;结论&lt;/h4&gt;MS-DGCNN++是一种适用于资源受限应用的树种分类方法，同时保持了较高的准确率。该方法还可推广到标准3D物体识别任务，成为点云处理应用的通用解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从地面LiDAR点云中进行树种分类是一项挑战，因为森林环境中的树结构具有复杂的多尺度几何结构。现有的使用多尺度动态图卷积神经网络（MS-DGCNN）的方法由于并行多尺度处理，无法捕捉树结构层级之间的语义关系。我们提出了一种名为MS-DGCNN++的层次化多尺度融合动态图卷积网络，它使用在局部、分支和冠层尺度上的语义有意义的特征提取以及跨尺度信息传播。我们的方法采用特定于尺度的特征工程，包括局部尺度的标准几何特征、分支尺度的归一化相对向量和冠层尺度的距离信息。这种层次化方法用语义区分的表示代替了均匀的并行处理，与自然树结构对齐。在相同的树种数据增强策略下，MS-DGCNN++在STPCTL上达到了94.96%的准确率，优于DGCNN、MS-DGCNN和最先进的PPT模型。在FOR-species20K上，它达到了67.25%的准确率（比MS-DGCNN提高了6.1%）。在标准3D物体识别中，我们的方法在ModelNet40和ModelNet10上的整体准确率分别为93.15%和94.05%，优于DGCNN和MS-DGCNN。与最先进的转换器方法相比，我们的方法具有更低的参数量和更低的复杂度，适合资源受限的应用，同时保持了有竞争力的准确率。除了树分类之外，该方法还推广到标准3D物体识别，确立其为点云处理应用的多用途解决方案。实现代码在https://github.com/said-ohamouddou/MS-DGCNN2上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tree species classification from terrestrial LiDAR point clouds ischallenging because of the complex multi-scale geometric structures in forestenvironments. Existing approaches using multi-scale dynamic graph convolutionalneural networks (MS-DGCNN) employ parallel multi-scale processing, which failsto capture the semantic relationships between the hierarchical levels of thetree architecture. We present MS-DGCNN++, a hierarchical multiscale fusiondynamic graph convolutional network that uses semantically meaningful featureextraction at local, branch, and canopy scales with cross-scale informationpropagation. Our method employs scale-specific feature engineering, includingstandard geometric features for the local scale, normalized relative vectorsfor the branch scale, and distance information for the canopy scale. Thishierarchical approach replaces uniform parallel processing with semanticallydifferentiated representations that are aligned with the natural treestructure. Under the same proposed tree species data augmentation strategy forall experiments, MS-DGCNN++ achieved an accuracy of 94.96 \% on STPCTLS,outperforming DGCNN, MS-DGCNN, and the state-of-the-art model PPT. OnFOR-species20K, it achieves 67.25\% accuracy (6.1\% improvement compared toMS-DGCNN). For standard 3D object recognition, our method outperformed DGCNNand MS-DGCNN with overall accuracies of 93.15\% on ModelNet40 and 94.05\% onModelNet10. With lower parameters and reduced complexity compared tostate-of-the-art transformer approaches, our method is suitable forresource-constrained applications while maintaining a competitive accuracy.Beyond tree classification, the method generalizes to standard 3D objectrecognition, establishing it as a versatile solution for diverse point cloudprocessing applications. The implementation code is publicly available athttps://github.com/said-ohamouddou/MS-DGCNN2.</description>
      <author>example@mail.com (Said Ohamouddou, Abdellatif El Afia, Hanaa El Afia, Raddouane Chiheb)</author>
      <guid isPermaLink="false">2507.12602v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
  <item>
      <title>D2IP: Deep Dynamic Image Prior for 3D Time-sequence Pulmonary Impedance Imaging</title>
      <link>http://arxiv.org/abs/2507.14046v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Deep Dynamic Image Prior (D2IP)的新框架，用于加速3D时间序列成像，并在模拟和临床数据集上显示出优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;无监督学习如Deep Image Prior (DIP)在断层扫描成像中有潜力，但高计算成本限制了其实际应用。&lt;h4&gt;目的&lt;/h4&gt;提出D2IP框架以克服高计算成本问题，提高3D时间序列断层扫描成像的效率。&lt;h4&gt;方法&lt;/h4&gt;D2IP采用三种策略：无监督参数预热启动（UPWS）、时间参数传播（TPP）和定制轻量级重建骨干网络3D-FastResUNet。&lt;h4&gt;主要发现&lt;/h4&gt;D2IP在模拟和临床数据集上实现了快速准确的3D时间序列电导抗断层扫描（tsEIT）重建，相比现有基准，图像质量提升，计算时间显著减少。&lt;h4&gt;结论&lt;/h4&gt;D2IP具有提高3D时间序列断层扫描成像效率的潜力，特别是在临床动态肺成像领域。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel framework named Deep Dynamic Image Prior (D2IP) for accelerating 3D time-sequence imaging, which shows superior performance over existing methods on both simulated and clinical datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised learning methods, such as Deep Image Prior (DIP), have showngreat potential in tomographic imaging due to their training-data-free natureand high generalization capability. However, their reliance on numerous networkparameter iterations results in high computational costs, limiting theirpractical application, particularly in complex 3D or time-sequence tomographicimaging tasks. To overcome these challenges, we propose Deep Dynamic ImagePrior (D2IP), a novel framework for 3D time-sequence imaging. D2IP introducesthree key strategies - Unsupervised Parameter Warm-Start (UPWS), TemporalParameter Propagation (TPP), and a customized lightweight reconstructionbackbone, 3D-FastResUNet - to accelerate convergence, enforce temporalcoherence, and improve computational efficiency. Experimental results on bothsimulated and clinical pulmonary datasets demonstrate that D2IP enables fastand accurate 3D time-sequence Electrical Impedance Tomography (tsEIT)reconstruction. Compared to state-of-the-art baselines, D2IP delivers superiorimage quality, with a 24.8% increase in average MSSIM and an 8.1% reduction inERR, alongside significantly reduced computational time (7.1x faster),highlighting its promise for clinical dynamic pulmonary imaging.</description>
      <author>example@mail.com (Hao Fang, Hao Yu, Sihao Teng, Tao Zhang, Siyi Yuan, Huaiwu He, Zhe Liu, Yunjie Yang)</author>
      <guid isPermaLink="false">2507.14046v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation</title>
      <link>http://arxiv.org/abs/2507.13857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Depth3DLane是一种新的双路径框架，用于单目3D车道检测，旨在解决现有方法的限制。&lt;h4&gt;背景&lt;/h4&gt;单目3D车道检测对于自动驾驶至关重要，但由于缺乏显式的空间信息而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出Depth3DLane，以解决现有方法对深度传感器的依赖、对地面真实深度数据的依赖以及假设相机参数可用的问题。&lt;h4&gt;方法&lt;/h4&gt;Depth3DLane集成了自监督单目深度估计，通过自监督深度网络获取场景的点云表示，并使用鸟瞰视图路径提取显式空间信息，同时使用前视图路径提取丰富的语义信息。然后，使用3D车道锚点从两个路径中采样特征，并推断准确的3D车道几何形状。此外，该框架扩展到预测每帧的相机参数，并引入了一种理论上的拟合过程来增强每段的稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;Depth3DLane在OpenLane基准数据集上实现了具有竞争力的性能，并且使用学习到的参数而不是地面真实参数，使得Depth3DLane可以在相机校准不可行的情况下应用，与以前的方法不同。&lt;h4&gt;结论&lt;/h4&gt;Depth3DLane为单目3D车道检测提供了一种新的解决方案，克服了现有方法的限制，并提高了自动驾驶系统的可靠性。&lt;h4&gt;翻译&lt;/h4&gt;Monocular 3D lane detection is essential for autonomous driving, but challenging due to the inherent lack of explicit spatial information. Multi-modal approaches rely on expensive depth sensors, while methods incorporating fully-supervised depth networks rely on ground-truth depth data that is impractical to collect at scale. Additionally, existing methods assume that camera parameters are available, limiting their applicability in scenarios like crowdsourced high-definition (HD) lane mapping. To address these limitations, we propose Depth3DLane, a novel dual-pathway framework that integrates self-supervised monocular depth estimation to provide explicit structural information, without the need for expensive sensors or additional ground-truth depth data. Leveraging a self-supervised depth network to obtain a point cloud representation of the scene, our bird's-eye view pathway extracts explicit spatial information, while our front view pathway simultaneously extracts rich semantic information. Depth3DLane then uses 3D lane anchors to sample features from both pathways and infer accurate 3D lane geometry. Furthermore, we extend the framework to predict camera parameters on a per-frame basis and introduce a theoretically motivated fitting procedure to enhance stability on a per-segment basis. Extensive experiments demonstrate that Depth3DLane achieves competitive performance on the OpenLane benchmark dataset. Furthermore, experimental results show that using learned parameters instead of ground-truth parameters allows Depth3DLane to be applied in scenarios where camera calibration is infeasible, unlike previous methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D lane detection is essential for autonomous driving, butchallenging due to the inherent lack of explicit spatial information.Multi-modal approaches rely on expensive depth sensors, while methodsincorporating fully-supervised depth networks rely on ground-truth depth datathat is impractical to collect at scale. Additionally, existing methods assumethat camera parameters are available, limiting their applicability in scenarioslike crowdsourced high-definition (HD) lane mapping. To address theselimitations, we propose Depth3DLane, a novel dual-pathway framework thatintegrates self-supervised monocular depth estimation to provide explicitstructural information, without the need for expensive sensors or additionalground-truth depth data. Leveraging a self-supervised depth network to obtain apoint cloud representation of the scene, our bird's-eye view pathway extractsexplicit spatial information, while our front view pathway simultaneouslyextracts rich semantic information. Depth3DLane then uses 3D lane anchors tosample features from both pathways and infer accurate 3D lane geometry.Furthermore, we extend the framework to predict camera parameters on aper-frame basis and introduce a theoretically motivated fitting procedure toenhance stability on a per-segment basis. Extensive experiments demonstratethat Depth3DLane achieves competitive performance on the OpenLane benchmarkdataset. Furthermore, experimental results show that using learned parametersinstead of ground-truth parameters allows Depth3DLane to be applied inscenarios where camera calibration is infeasible, unlike previous methods.</description>
      <author>example@mail.com (Max van den Hoven, Kishaan Jeeveswaran, Pieter Piscaer, Thijs Wensveen, Elahe Arani, Bahram Zonooz)</author>
      <guid isPermaLink="false">2507.13857v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning</title>
      <link>http://arxiv.org/abs/2507.14137v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Franca，这是一个完全开源的视觉基础模型，其性能在许多情况下超过了最先进的专有模型，如DINOv2、CLIP、SigLIPv2等。Franca采用了透明的训练流程，并使用公开数据，同时解决了SSL聚类方法的关键局限性。&lt;h4&gt;背景&lt;/h4&gt;Franca是一个开源的视觉基础模型，旨在提供高性能且透明的解决方案。&lt;h4&gt;目的&lt;/h4&gt;建立一个新的标准，为透明、高性能的视觉模型提供参考，并促进更可重复和通用的基础模型的发展。&lt;h4&gt;方法&lt;/h4&gt; Franca采用了基于Web-SSL的透明训练流程，并使用ImageNet-21K和ReLAION-2B的部分数据集。同时，提出了一种参数高效的、多头的聚类投影器，以及一个新颖的位置解耦策略。&lt;h4&gt;主要发现&lt;/h4&gt;Franca在性能和内存效率方面都有所提升，解决了SSL聚类方法中的局限性，并通过新的位置解耦策略改善了语义内容的编码。&lt;h4&gt;结论&lt;/h4&gt;Franca为透明、高性能的视觉模型树立了新标准，并为AI社区提供了更可重复和通用的基础模型。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了Franca（发音为Fran-ka）：自由之一；第一个完全开源的（数据、代码、权重）视觉基础模型，在许多情况下匹配并超过了最先进的专有模型，例如DINOv2、CLIP、SigLIPv2等。我们的方法基于一个透明的训练流程，灵感来自Web-SSL，并使用公开数据：ImageNet-21K和ReLAION-2B的一个子集。除了模型发布之外，我们还解决了SSL聚类方法中的关键局限性。虽然现代模型依赖于通过如Sinkhorn-Knopp等聚类算法将图像特征分配给大型代码簿，但它们未能考虑聚类语义中的固有歧义。为了解决这个问题，我们引入了一种基于嵌套套娃表示的参数高效的、多头的聚类投影器。这种设计在不增加模型尺寸的情况下，逐步细化特征到越来越精细的聚类中，从而提高了性能和内存效率。此外，我们还提出了一种新的位置解耦策略，该策略明确地从密集表示中移除位置偏差，从而改善了语义内容的编码。这导致在多个下游基准测试中取得了一致性的提升，证明了更清洁特征空间的有用性。我们的贡献建立了一个新的标准，用于透明、高性能的视觉模型，并为更可重复和通用的基础模型开辟了道路，这对于更广泛的AI社区是有益的。代码和模型检查点可在https://github.com/valeoai/Franca上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Franca (pronounced Fran-ka): free one; the first fully open-source(data, code, weights) vision foundation model that matches and in many casessurpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,CLIP, SigLIPv2, etc. Our approach is grounded in a transparent trainingpipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K anda subset of ReLAION-2B. Beyond model release, we tackle critical limitations inSSL clustering methods. While modern models rely on assigning image features tolarge codebooks via clustering algorithms like Sinkhorn-Knopp, they fail toaccount for the inherent ambiguity in clustering semantics. To address this, weintroduce a parameter-efficient, multi-head clustering projector based onnested Matryoshka representations. This design progressively refines featuresinto increasingly fine-grained clusters without increasing the model size,enabling both performance and memory efficiency. Additionally, we propose anovel positional disentanglement strategy that explicitly removes positionalbiases from dense representations, thereby improving the encoding of semanticcontent. This leads to consistent gains on several downstream benchmarks,demonstrating the utility of cleaner feature spaces. Our contributionsestablish a new standard for transparent, high-performance vision models andopen a path toward more reproducible and generalizable foundation models forthe broader AI community. The code and model checkpoints are available athttps://github.com/valeoai/Franca.</description>
      <author>example@mail.com (Shashanka Venkataramanan, Valentinos Pariza, Mohammadreza Salehi, Lukas Knobel, Spyros Gidaris, Elias Ramzi, Andrei Bursuc, Yuki M. Asano)</author>
      <guid isPermaLink="false">2507.14137v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation</title>
      <link>http://arxiv.org/abs/2507.13628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 15 figures, RA-L submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FoELS的方法，用于从运动摄像机视点分离移动和静态对象，以提高三维重建、自主导航和场景理解在机器人技术中的应用。&lt;h4&gt;背景&lt;/h4&gt;在复杂、结构化的场景中，涉及摄像机运动时，现有的方法主要依赖光流技术，而光流技术在检测移动对象方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;针对光流技术的局限性，提出FoELS方法，旨在有效地处理复杂结构场景、旋转摄像机运动和平行运动等挑战。&lt;h4&gt;方法&lt;/h4&gt;FoELS方法结合了光流和纹理信息，通过计算光流中的扩展焦点（FoE）并从FoE计算中的异常值推导出初始运动似然，然后将该似然与基于分割的先验信息融合，以估计最终的移动概率。&lt;h4&gt;主要发现&lt;/h4&gt;在DAVIS 2016数据集和真实世界交通视频中进行的全面评估表明，FoELS方法在处理复杂结构场景、旋转摄像机运动和平行运动等方面表现出色，并达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;FoELS方法在从运动摄像机视点分离移动和静态对象方面具有显著优势，为三维重建、自主导航和场景理解提供了有效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Separating moving and static objects from a moving camera viewpoint is essential for 3D reconstruction, autonomous navigation, and scene understanding in robotics. Existing approaches often rely primarily on optical flow, which struggles to detect moving objects in complex, structured scenes involving camera motion. To address this limitation, we propose Focus of Expansion Likelihood and Segmentation (FoELS), a method based on the core idea of integrating both optical flow and texture information. FoELS computes the focus of expansion (FoE) from optical flow and derives an initial motion likelihood from the outliers of the FoE computation. This likelihood is then fused with a segmentation-based prior to estimate the final moving probability. The method effectively handles challenges including complex structured scenes, rotational camera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016 dataset and real-world traffic videos demonstrate its effectiveness and state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Separating moving and static objects from a moving camera viewpoint isessential for 3D reconstruction, autonomous navigation, and scene understandingin robotics. Existing approaches often rely primarily on optical flow, whichstruggles to detect moving objects in complex, structured scenes involvingcamera motion. To address this limitation, we propose Focus of ExpansionLikelihood and Segmentation (FoELS), a method based on the core idea ofintegrating both optical flow and texture information. FoELS computes the focusof expansion (FoE) from optical flow and derives an initial motion likelihoodfrom the outliers of the FoE computation. This likelihood is then fused with asegmentation-based prior to estimate the final moving probability. The methodeffectively handles challenges including complex structured scenes, rotationalcamera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016dataset and real-world traffic videos demonstrate its effectiveness andstate-of-the-art performance.</description>
      <author>example@mail.com (Masahiro Ogawa, Qi An, Atsushi Yamashita)</author>
      <guid isPermaLink="false">2507.13628v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Dual-Center Graph Clustering with Neighbor Distribution</title>
      <link>http://arxiv.org/abs/2507.13765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECAI-2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于邻域分布特性的新型双中心图聚类（DCGC）方法，通过利用邻域分布作为监督信号和双中心优化来提高聚类效果。&lt;h4&gt;背景&lt;/h4&gt;图聚类在揭示复杂数据结构方面至关重要，但由于其无监督性质，存在显著挑战。现有的目标导向聚类技术利用伪标签，但伪标签作为监督信号不可靠。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的聚类方法，解决现有方法中伪标签不可靠和仅使用特征进行单中心优化导致的指导不完整和不可靠的问题。&lt;h4&gt;方法&lt;/h4&gt;采用邻域分布作为监督信号，在对比学习中挖掘硬负样本，并引入邻域分布中心与特征中心共同构建双目标分布进行双中心优化。&lt;h4&gt;主要发现&lt;/h4&gt;实验和分析表明，该方法在性能和有效性方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过利用邻域分布特性提高了图聚类的效果，为解决现有聚类方法中的问题提供了一种新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph clustering is crucial for unraveling intricate data structures, yet itpresents significant challenges due to its unsupervised nature. Recently,goal-directed clustering techniques have yielded impressive results, withcontrastive learning methods leveraging pseudo-label garnering considerableattention. Nonetheless, pseudo-label as a supervision signal is unreliable andexisting goal-directed approaches utilize only features to construct asingle-target distribution for single-center optimization, which lead toincomplete and less dependable guidance. In our work, we propose a novelDual-Center Graph Clustering (DCGC) approach based on neighbor distributionproperties, which includes representation learning with neighbor distributionand dual-center optimization. Specifically, we utilize neighbor distribution asa supervision signal to mine hard negative samples in contrastive learning,which is reliable and enhances the effectiveness of representation learning.Furthermore, neighbor distribution center is introduced alongside featurecenter to jointly construct a dual-target distribution for dual-centeroptimization. Extensive experiments and analysis demonstrate superiorperformance and effectiveness of our proposed method.</description>
      <author>example@mail.com (Enhao Cheng, Shoujia Zhang, Jianhua Yin, Li Jin, Liqiang Nie)</author>
      <guid isPermaLink="false">2507.13765v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2507.13899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度先验的方法，利用DepthAnything模型预测的深度信息来增强LiDAR数据在3D物体检测中的应用，从而提高检测精度。&lt;h4&gt;背景&lt;/h4&gt;近年来，基础模型在3D感知领域取得了显著进展。DepthAnything可以从单目RGB图像中提取密集且可靠的几何先验，但在LiDAR-based 3D物体检测中，这些先验尚未得到充分利用。&lt;h4&gt;目的&lt;/h4&gt;针对原始LiDAR点特征表达能力有限，尤其是反射属性的可区分能力较弱的问题，提出了一种融合深度先验的方法。&lt;h4&gt;方法&lt;/h4&gt;1. 引入DepthAnything预测的深度先验与原始LiDAR属性融合，丰富每个点的表示；2. 设计一个点特征提取模块；3. 采用双路径ROI特征提取框架，包括基于体素的分支和基于点的分支；4. 引入双向门控ROI特征融合模块，平衡全局和局部线索。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI数据集上的实验表明，该方法能显著提高检测精度。&lt;h4&gt;结论&lt;/h4&gt;将视觉基础模型先验融入LiDAR-based 3D物体检测，有助于提高检测精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近期在基础模型方面的进展为增强3D感知开辟了新的可能性。特别是，DepthAnything能够从单目RGB图像中提供密集且可靠的几何先验，这在自动驾驶场景中可以补充稀疏的LiDAR数据。然而，这样的先验在基于LiDAR的3D物体检测中仍未得到充分利用。在本文中，我们通过引入DepthAnything预测的深度先验来解决原始LiDAR点特征的有限表达能力，特别是反射属性的低可区分能力。这些先验与原始LiDAR属性融合，以丰富每个点的表示。为了利用增强的点特征，我们提出一个点特征提取模块。然后，采用一个双路径ROI特征提取框架，包括一个基于体素的分支用于全局语义上下文和一个基于点的分支用于细粒度结构细节。为了有效地整合互补的ROI特征，我们引入了一个双向门控ROI特征融合模块，平衡全局和局部线索。在KITTI基准数据集上的大量实验表明，我们的方法能持续提高检测精度，证明了将视觉基础模型先验融入基于LiDAR的3D物体检测的价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in foundation models have opened up new possibilities forenhancing 3D perception. In particular, DepthAnything offers dense and reliablegeometric priors from monocular RGB images, which can complement sparse LiDARdata in autonomous driving scenarios. However, such priors remain underutilizedin LiDAR-based 3D object detection. In this paper, we address the limitedexpressiveness of raw LiDAR point features, especially the weak discriminativecapability of the reflectance attribute, by introducing depth priors predictedby DepthAnything. These priors are fused with the original LiDAR attributes toenrich each point's representation. To leverage the enhanced point features, wepropose a point-wise feature extraction module. Then, a Dual-Path RoI featureextraction framework is employed, comprising a voxel-based branch for globalsemantic context and a point-based branch for fine-grained structural details.To effectively integrate the complementary RoI features, we introduce abidirectional gated RoI feature fusion module that balances global and localcues. Extensive experiments on the KITTI benchmark show that our methodconsistently improves detection accuracy, demonstrating the value ofincorporating visual foundation model priors into LiDAR-based 3D objectdetection.</description>
      <author>example@mail.com (Yujian Mo, Yan Wu, Junqiao Zhao, Jijun Wang, Yinghao Hu, Jun Yan)</author>
      <guid isPermaLink="false">2507.13899v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Toward Practical Fluid Antenna Systems: Co-Optimizing Hardware and Software for Port Selection and Beamforming</title>
      <link>http://arxiv.org/abs/2507.14035v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对流体天线系统（FASs）的硬件-软件协同设计方法，以高效优化波束成形和端口选择。&lt;h4&gt;背景&lt;/h4&gt;文章首先对流体天线（FA）赋能的下行多小区多输入多输出（MIMO）网络进行了建模，并建立了加权求和速率（WSR）最大化问题。&lt;h4&gt;目的&lt;/h4&gt;旨在通过联合优化波束成形和端口选择，同时评估随机选择的优势和局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了将图神经网络（GNNs）与随机端口选择（RPS）相结合的方法，并开发了基于现场可编程门阵列（FPGA）的指令驱动深度学习加速器，以最小化推理延迟。此外，引入了调度算法以减少冗余计算并最小化计算核心的空闲时间。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，提出的GNN-RPS方法实现了具有竞争力的通信性能。实验评估表明，基于FPGA的加速器在执行多个端口选择的波束成形推理时，同时保持了低延迟。&lt;h4&gt;结论&lt;/h4&gt;该方法在流体天线系统中有效地优化了波束成形和端口选择，提高了通信性能，并实现了低延迟的加速器执行。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a hardware-software co-design approach to efficientlyoptimize beamforming and port selection in fluid antenna systems (FASs). Tobegin with, a fluid-antenna (FA)-enabled downlink multi-cell multiple-inputmultiple-output (MIMO) network is modeled, and a weighted sum-rate (WSR)maximization problem is formulated. Second, a method that integrates graphneural networks (GNNs) with random port selection (RPS) is proposed to jointlyoptimize beamforming and port selection, while also assessing the benefits andlimitations of random selection. Third, an instruction-driven deep learningaccelerator based on a field-programmable gate array (FPGA) is developed tominimize inference latency. To further enhance efficiency, a schedulingalgorithm is introduced to reduce redundant computations and minimize the idletime of computing cores. Simulation results demonstrate that the proposedGNN-RPS approach achieves competitive communication performance. Furthermore,experimental evaluations indicate that the FPGA-based accelerator maintains lowlatency while simultaneously executing beamforming inference for multiple portselections.</description>
      <author>example@mail.com (Sai Xu, Kai-Kit Wong, Yanan Du, Hanjiang Hong, Chan-Byoung Chae, Baiyang Liu, Kin-Fai Tong)</author>
      <guid isPermaLink="false">2507.14035v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction</title>
      <link>http://arxiv.org/abs/2507.13719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对博物馆环境的创新增强现实流程，旨在通过识别艺术品并从单张图像生成精确的3D模型。&lt;h4&gt;背景&lt;/h4&gt;该流程通过整合两种互补的预训练深度估计模型，即GLPN用于捕捉全局场景结构，Depth-Anything用于详细局部重建。&lt;h4&gt;目的&lt;/h4&gt;目的是生成能够有效表示复杂艺术特征的优化深度图。&lt;h4&gt;方法&lt;/h4&gt;方法将深度图转换为高质量点云和网格，从而实现沉浸式AR体验。该方法利用最先进的神经网络架构和高级计算机视觉技术，克服了艺术品中不规则轮廓和多变纹理带来的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在重建精度和视觉真实感方面有显著提高。&lt;h4&gt;结论&lt;/h4&gt;该系统成为博物馆通过互动数字内容增强游客参与度的高度鲁棒工具。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents an innovative augmented reality pipeline tailored formuseum environments, aimed at recognizing artworks and generating accurate 3Dmodels from single images. By integrating two complementary pre-trained depthestimation models, i.e., GLPN for capturing global scene structure andDepth-Anything for detailed local reconstruction, the proposed approachproduces optimized depth maps that effectively represent complex artisticfeatures. These maps are then converted into high-quality point clouds andmeshes, enabling the creation of immersive AR experiences. The methodologyleverages state-of-the-art neural network architectures and advanced computervision techniques to overcome challenges posed by irregular contours andvariable textures in artworks. Experimental results demonstrate significantimprovements in reconstruction accuracy and visual realism, making the system ahighly robust tool for museums seeking to enhance visitor engagement throughinteractive digital content.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an innovative augmented reality pipeline tailored formuseum environments, aimed at recognizing artworks and generating accurate 3Dmodels from single images. By integrating two complementary pre-trained depthestimation models, i.e., GLPN for capturing global scene structure andDepth-Anything for detailed local reconstruction, the proposed approachproduces optimized depth maps that effectively represent complex artisticfeatures. These maps are then converted into high-quality point clouds andmeshes, enabling the creation of immersive AR experiences. The methodologyleverages state-of-the-art neural network architectures and advanced computervision techniques to overcome challenges posed by irregular contours andvariable textures in artworks. Experimental results demonstrate significantimprovements in reconstruction accuracy and visual realism, making the system ahighly robust tool for museums seeking to enhance visitor engagement throughinteractive digital content.</description>
      <author>example@mail.com (Daniele Pannone, Alessia Castronovo, Maurizio Mancini, Gian Luca Foresti, Claudio Piciarelli, Rossana Gabrieli, Muhammad Yasir Bilal, Danilo Avola)</author>
      <guid isPermaLink="false">2507.13719v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits</title>
      <link>http://arxiv.org/abs/2507.14079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了DENSE系统，该系统旨在从散乱的证据中整理出患者病情的演变过程、治疗方案和护理决策，以提高临床文档的质量。&lt;h4&gt;背景&lt;/h4&gt;进步记录是电子健康记录中的重要组成部分，但在大型EHR数据集中占比极低，如MIMIC-III数据集中仅占8.56%。&lt;h4&gt;目的&lt;/h4&gt;DENSE系统旨在模拟医生在撰写进度记录时如何引用既往病历，并利用临床信息检索策略来识别相关内容，从而生成连贯的进度记录。&lt;h4&gt;方法&lt;/h4&gt;DENSE系统包括细粒度笔记分类和时序对齐机制，通过检索策略识别相关内容，并使用大型语言模型生成进度记录。&lt;h4&gt;主要发现&lt;/h4&gt;DENSE系统在患者多访视和完整进度记录的数据集上进行了评估，生成的笔记具有强大的纵向一致性，时间对齐比率为1.089，超过了原始记录。&lt;h4&gt;结论&lt;/h4&gt;DENSE系统有助于恢复文档的连贯性，支持下游任务如总结、预测建模和临床决策支持，为实际医疗环境中的LLM驱动的笔记合成提供了一个可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了DENSE系统，这是一个旨在从分散的证据中整理患者病情发展、治疗方案和护理决策的系统，以提高临床文档的质量。背景是，进步记录是电子健康记录中的重要组成部分，但在大型EHR数据集中占比极低，如MIMIC-III数据集中仅占8.56%。DENSE系统的目的是模拟医生在撰写进度记录时如何引用既往病历，并利用临床信息检索策略来识别相关内容，从而生成连贯的进度记录。DENSE系统包括细粒度笔记分类和时序对齐机制，通过检索策略识别相关内容，并使用大型语言模型生成进度记录。主要发现是在患者多访视和完整进度记录的数据集上进行了评估，生成的笔记具有强大的纵向一致性，时间对齐比率为1.089，超过了原始记录。结论是DENSE系统有助于恢复文档的连贯性，支持下游任务如总结、预测建模和临床决策支持，为实际医疗环境中的LLM驱动的笔记合成提供了一个可扩展的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Progress notes are among the most clinically meaningful artifacts in anElectronic Health Record (EHR), offering temporally grounded insights into apatient's evolving condition, treatments, and care decisions. Despite theirimportance, they are severely underrepresented in large-scale EHR datasets. Forinstance, in the widely used Medical Information Mart for Intensive Care III(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progressnotes, leaving gaps in longitudinal patient narratives. In contrast, thedataset contains a diverse array of other note types, each capturing differentaspects of care.  We present DENSE (Documenting Evolving Progress Notes from ScatteredEvidence), a system designed to align with clinical documentation workflows bysimulating how physicians reference past encounters while drafting progressnotes. The system introduces a fine-grained note categorization and a temporalalignment mechanism that organizes heterogeneous notes across visits intostructured, chronological inputs. At its core, DENSE leverages a clinicallyinformed retrieval strategy to identify temporally and semantically relevantcontent from both current and prior visits. This retrieved evidence is used toprompt a large language model (LLM) to generate clinically coherent andtemporally aware progress notes.  We evaluate DENSE on a curated cohort of patients with multiple visits andcomplete progress note documentation. The generated notes demonstrate stronglongitudinal fidelity, achieving a temporal alignment ratio of $1.089$,surpassing the continuity observed in original notes. By restoring narrativecoherence across fragmented documentation, our system supports improveddownstream tasks such as summarization, predictive modeling, and clinicaldecision support, offering a scalable solution for LLM-driven note synthesis inreal-world healthcare settings.</description>
      <author>example@mail.com (Garapati Keerthana, Manik Gupta)</author>
      <guid isPermaLink="false">2507.14079v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Toward Temporal Causal Representation Learning with Tensor Decomposition</title>
      <link>http://arxiv.org/abs/2507.14126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了时间因果表示学习在分析高维、长度不定的不规则张量数据中的应用，提出了一种新的因果表示学习方法。&lt;h4&gt;背景&lt;/h4&gt;时间因果表示学习在观察性研究中揭示复杂模式非常有用，但实际应用中的数据通常是高维和不规则的。&lt;h4&gt;目的&lt;/h4&gt;为了分析这类数据，本文提出了一个结合时间因果表示学习和不规则张量分解的联合学习框架。&lt;h4&gt;方法&lt;/h4&gt;首先，提出了一种新的因果表示学习方法；其次，构建了名为CaRTeD的联合学习框架；最后，通过理论证明和实验验证了该方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够有效地提取数据中的意义聚类，并提供了对因果表示的更灵活的正则化设计。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法在模拟潜在结构和提取因果信息方面优于现有技术，并提高了因果表示的可解释性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：时间因果表示学习是一种在观察性研究中揭示复杂模式的有力工具，这些模式通常表示为低维时间序列。然而，在许多实际应用中，数据是高维的，具有不同的输入长度，并且自然地以不规则张量的形式存在。为了分析这类数据，不规则张量分解对于提取有意义聚类以捕捉关键信息至关重要。在本文中，我们专注于基于转换信息建模因果表示学习。首先，我们提出了一套潜在聚类的新的因果公式。然后，我们提出了CaRTeD，一个结合时间因果表示学习与不规则张量分解的联合学习框架。值得注意的是，我们的框架为使用学习到的张量因子进行下游任务提供了蓝图，例如建模潜在结构和提取因果信息，并提供了更灵活的正则化设计以增强张量分解。从理论上讲，我们证明了我们的算法收敛到一个稳态点。更重要的是，我们的结果填补了最先进的不规则张量分解收敛理论保证的空白。在合成和真实世界电子健康记录（EHR）数据集（MIMIC-III）上的实验结果，从表型和网络恢复的角度进行了广泛的基准测试，表明我们提出的方法优于现有技术，并提高了因果表示的可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal causal representation learning is a powerful tool for uncoveringcomplex patterns in observational studies, which are often represented aslow-dimensional time series. However, in many real-world applications, data arehigh-dimensional with varying input lengths and naturally take the form ofirregular tensors. To analyze such data, irregular tensor decomposition iscritical for extracting meaningful clusters that capture essential information.In this paper, we focus on modeling causal representation learning based on thetransformed information. First, we present a novel causal formulation for a setof latent clusters. We then propose CaRTeD, a joint learning framework thatintegrates temporal causal representation learning with irregular tensordecomposition. Notably, our framework provides a blueprint for downstream tasksusing the learned tensor factors, such as modeling latent structures andextracting causal information, and offers a more flexible regularization designto enhance tensor decomposition. Theoretically, we show that our algorithmconverges to a stationary point. More importantly, our results fill the gap intheoretical guarantees for the convergence of state-of-the-art irregular tensordecomposition. Experimental results on synthetic and real-world electronichealth record (EHR) datasets (MIMIC-III), with extensive benchmarks from bothphenotyping and network recovery perspectives, demonstrate that our proposedmethod outperforms state-of-the-art techniques and enhances the explainabilityof causal representations.</description>
      <author>example@mail.com (Jianhong Chen, Meng Zhao, Mostafa Reisi Gahrooei, Xubo Yue)</author>
      <guid isPermaLink="false">2507.14126v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track</title>
      <link>http://arxiv.org/abs/2507.14096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过PLABA挑战赛评估了使用大型语言模型将生物医学文献转换为平实语言系统的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管语言模型在处理生物医学文献方面有潜力，但其不确定性和潜在危害需要严格的评估。&lt;h4&gt;目的&lt;/h4&gt;该研究的目的是激发对该领域的研究，并为最有前景的系统提供高质量的评估。&lt;h4&gt;方法&lt;/h4&gt;研究在2023年和2024年文本检索会议中举办了PLABA挑战赛，包括完整句子的重写（任务1）和识别并替换难懂术语（任务2）。对任务1的自动评估使用了四个专业编写的参考集合，两个任务都接受了生物医学专家的详细人工评估。&lt;h4&gt;主要发现&lt;/h4&gt;12个来自12个国家的团队参加了比赛，模型范围从多层感知器到大型预训练变压器。在任务1的人工评估中，表现最好的模型在事实准确性和完整性上与人类水平相当，但在简洁性和简洁度上不如人类。自动评估指标通常与人工评估结果不相关。在任务2中，系统在识别难懂术语和分类替换方式上表现不佳，但在生成替换词时，基于LLM的系统在人工评估的准确性、完整性和简洁性方面表现良好。&lt;h4&gt;结论&lt;/h4&gt;PLABA挑战赛显示了使用大型语言模型将生物医学文献适应于公众的潜力，同时也突显了它们的不足和改进自动基准测试工具的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Objective: Recent advances in language models have shown potential to adaptprofessional-facing biomedical literature to plain language, making itaccessible to patients and caregivers. However, their unpredictability,combined with the high potential for harm in this domain, means rigorousevaluation is necessary. Our goals with this track were to stimulate researchand to provide high-quality evaluation of the most promising systems.  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks includedcomplete, sentence-level, rewriting of abstracts (Task 1) as well asidentifying and replacing difficult terms (Task 2). For automatic evaluation ofTask 1, we developed a four-fold set of professionally-written references.Submissions for both Tasks 1 and 2 were provided extensive manual evaluationfrom biomedical experts.  Results: Twelve teams spanning twelve countries participated in the track,with models from multilayer perceptrons to large pretrained transformers. Inmanual judgments of Task 1, top-performing models rivaled human levels offactual accuracy and completeness, but not simplicity or brevity. Automatic,reference-based metrics generally did not correlate well with manual judgments.In Task 2, systems struggled with identifying difficult terms and classifyinghow to replace them. When generating replacements, however, LLM-based systemsdid well in manually judged accuracy, completeness, and simplicity, though notin brevity.  Conclusion: The PLABA track showed promise for using Large Language Models toadapt biomedical literature for the general public, while also highlightingtheir deficiencies and the need for improved automatic benchmarking tools.</description>
      <author>example@mail.com (Brian Ondov, William Xia, Kush Attal, Ishita Unde, Jerry He, Hoa Dang, Ian Soboroff, Dina Demner-Fushman)</author>
      <guid isPermaLink="false">2507.14096v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework</title>
      <link>http://arxiv.org/abs/2507.13659v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于事件相机的行人重识别方法，并构建了一个大规模的RGB-事件行人重识别数据集EvReID，用于评估和促进该领域的研究。&lt;h4&gt;背景&lt;/h4&gt;研究人员提出使用事件相机进行行人重识别，因其性能优越且在隐私保护方面表现良好，因此吸引了广泛关注。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在数据稀缺和模型泛化能力评估上的问题。&lt;h4&gt;方法&lt;/h4&gt;构建了包含118,988个图像对的大规模数据集EvReID，评估了15种最先进的行人重识别算法，并提出了一个名为TriPro-ReID的行人属性引导的对比学习框架。&lt;h4&gt;主要发现&lt;/h4&gt;TriPro-ReID框架有效地探索了RGB帧和事件流中的视觉特征，并充分利用了行人属性作为中级语义特征。&lt;h4&gt;结论&lt;/h4&gt;在EvReID和MARS数据集上的实验充分验证了所提出的方法的有效性，相关数据集和源代码将在指定网站上发布。&lt;h4&gt;翻译&lt;/h4&gt;近期研究人员提出利用事件相机进行行人重识别（ReID），由于其在性能和隐私保护方面的良好平衡，基于事件相机的人脸重识别已引起了广泛关注。目前，主流的事件相机人脸重识别算法主要关注融合可见光和事件流，以及保护隐私。尽管取得了重大进展，但这些方法通常在小型或模拟的事件相机数据集上训练和评估，这使得难以评估它们的实际识别性能和泛化能力。为了解决数据稀缺的问题，本文引入了一个大规模的RGB-事件人脸重识别数据集，称为EvReID。该数据集包含118,988个图像对，涵盖了1200个行人身份，数据跨越了多个季节、场景和光照条件。我们还评估了15种最先进的人脸重识别算法，为数据收集和基准测试方面奠定了坚实的基础。基于我们新构建的数据集，本文进一步提出了一种行人属性引导的对比学习框架，用于增强人脸重识别的特征学习，称为TriPro-ReID。该框架不仅有效地探索了RGB帧和事件流中的视觉特征，还充分利用了行人属性作为中级语义特征。在EvReID数据集和MARS数据集上的大量实验充分验证了我们所提出的人脸重识别框架的有效性。基准数据集和源代码将发布在https://github.com/Event-AHU/Neuromorphic_ReID上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent researchers have proposed using event cameras for personre-identification (ReID) due to their promising performance and better balancein terms of privacy protection, event camera-based person ReID has attractedsignificant attention. Currently, mainstream event-based person ReID algorithmsprimarily focus on fusing visible light and event stream, as well as preservingprivacy. Although significant progress has been made, these methods aretypically trained and evaluated on small-scale or simulated event cameradatasets, making it difficult to assess their real identification performanceand generalization ability. To address the issue of data scarcity, this paperintroduces a large-scale RGB-event based person ReID dataset, called EvReID.The dataset contains 118,988 image pairs and covers 1200 pedestrian identities,with data collected across multiple seasons, scenes, and lighting conditions.We also evaluate 15 state-of-the-art person ReID algorithms, laying a solidfoundation for future research in terms of both data and benchmarking. Based onour newly constructed dataset, this paper further proposes a pedestrianattribute-guided contrastive learning framework to enhance feature learning forperson re-identification, termed TriPro-ReID. This framework not onlyeffectively explores the visual features from both RGB frames and eventstreams, but also fully utilizes pedestrian attributes as mid-level semanticfeatures. Extensive experiments on the EvReID dataset and MARS datasets fullyvalidated the effectiveness of our proposed RGB-Event person ReID framework.The benchmark dataset and source code will be released onhttps://github.com/Event-AHU/Neuromorphic_ReID</description>
      <author>example@mail.com (Xiao Wang, Qian Zhu, Shujuan Wu, Bo Jiang, Shiliang Zhang, Yaowei Wang, Yonghong Tian, Bin Luo)</author>
      <guid isPermaLink="false">2507.13659v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.13992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的脑结构连接体（SC）数据统一框架，旨在解决神经影像学中小样本量限制生物标志物开发的问题，特别是在结构连接体（SC）研究中。&lt;h4&gt;背景&lt;/h4&gt;神经影像学中，特别是结构连接体（SC）研究，由于样本量小，统计能力、可靠性和普遍性受限，难以开发可靠的生物标志物。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要详细元数据和旅行参与者（TS）的站点条件深度统一框架，以解决现有方法依赖详细元数据或TS、忽略SC的图拓扑结构等问题。&lt;h4&gt;方法&lt;/h4&gt;在基于人类连接体数据集的模拟场景中测试了该框架，并比较了三种深度架构（全连接自动编码器（AE）、卷积AE和图卷积AE）与线性回归（LR）基线。&lt;h4&gt;主要发现&lt;/h4&gt;图AE在拓扑结构和个体层面保持方面表现优于非图模型，尽管LR基线在数值性能上最佳，但缺乏实际应用。&lt;h4&gt;结论&lt;/h4&gt;模型架构在SC统一性能中起着关键作用，基于图的深度学习方法特别适合于大规模多站点SC研究中的结构感知和领域通用SC统一。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Small sample sizes in neuroimaging, particularly in structural connectome (SC) studies, limit the development of reliable biomarkers for neurological and psychiatric disorders such as Alzheimer's disease and schizophrenia by reducing statistical power, reliability, and generalizability. Large-scale multi-site studies exist, but they have acquisition-related biases due to scanner heterogeneity, compromising imaging consistency and downstream analyses. While existing SC harmonization methods such as linear regression (LR), ComBat, and deep learning techniques mitigate these biases, they often rely on detailed metadata, traveling subjects (TS), or overlook the graph-topology of SCs. To address these limitations, we propose a site-conditioned deep harmonization framework that harmonizes SCs across diverse acquisition sites without requiring metadata or TS, which we test in a simulated scenario based on the Human Connectome Dataset. Within this framework, we benchmark three deep architectures - a fully connected autoencoder (AE), a convolutional AE, and a graph convolutional AE - against a top-performing LR baseline. While non-graph models excel in edge-weight prediction and edge existence detection, the graph AE demonstrates superior preservation of topological structure and subject-level individuality, as reflected by graph metrics and fingerprinting accuracy, respectively. Although the LR baseline achieves the highest numerical performance by explicitly modeling acquisition parameters, it lacks applicability to real-world multi-site use cases as detailed acquisition metadata is often unavailable. Our results highlight the critical role of model architecture in SC harmonization performance and demonstrate that graph-based approaches are particularly well-suited for structure-aware, domain-generalizable SC harmonization in large-scale multi-site SC studies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small sample sizes in neuroimaging in general, and in structural connectome(SC) studies in particular limit the development of reliable biomarkers forneurological and psychiatric disorders - such as Alzheimer's disease andschizophrenia - by reducing statistical power, reliability, andgeneralizability. Large-scale multi-site studies have exist, but they haveacquisition-related biases due to scanner heterogeneity, compromising imagingconsistency and downstream analyses. While existing SC harmonization methods -such as linear regression (LR), ComBat, and deep learning techniques - mitigatethese biases, they often rely on detailed metadata, traveling subjects (TS), oroverlook the graph-topology of SCs. To address these limitations, we propose asite-conditioned deep harmonization framework that harmonizes SCs acrossdiverse acquisition sites without requiring metadata or TS that we test in asimulated scenario based on the Human Connectome Dataset. Within thisframework, we benchmark three deep architectures - a fully connectedautoencoder (AE), a convolutional AE, and a graph convolutional AE - against atop-performing LR baseline. While non-graph models excel in edge-weightprediction and edge existence detection, the graph AE demonstrates superiorpreservation of topological structure and subject-level individuality, asreflected by graph metrics and fingerprinting accuracy, respectively. Althoughthe LR baseline achieves the highest numerical performance by explicitlymodeling acquisition parameters, it lacks applicability to real-worldmulti-site use cases as detailed acquisition metadata is often unavailable. Ourresults highlight the critical role of model architecture in SC harmonizationperformance and demonstrate that graph-based approaches are particularlywell-suited for structure-aware, domain-generalizable SC harmonization inlarge-scale multi-site SC studies.</description>
      <author>example@mail.com (Jagruti Patel, Thomas A. W. Bolton, Mikkel Schöttner, Anjali Tarun, Sebastien Tourbier, Yasser Alemàn-Gòmez, Jonas Richiardi, Patric Hagmann)</author>
      <guid isPermaLink="false">2507.13992v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Spacecraft Safe Robust Control Using Implicit Neural Representation for Geometrically Complex Targets in Proximity Operations</title>
      <link>http://arxiv.org/abs/2507.13672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 18 figures, submitted to TAES&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种确保航天器近距离操作安全的控制框架，重点关注在存在干扰的情况下，追踪航天器与复杂几何形状目标航天器之间的碰撞避免。&lt;h4&gt;背景&lt;/h4&gt;航天器近距离操作面临碰撞风险，需要有效的控制方法来确保安全。&lt;h4&gt;目的&lt;/h4&gt;确保航天器近距离操作的安全性，尤其是在存在干扰和复杂目标几何形状的情况下。&lt;h4&gt;方法&lt;/h4&gt;提出了一个利用隐式神经表示的安全鲁棒控制框架。通过点云数据学习神经符号距离函数（SDF），并采用增强的隐式几何正则化方法，结合过逼近策略来创建一个保守的、以安全为优先的边界。SDF的零水平集隐式定义目标表面，其值和梯度为安全控制器设计提供关键信息。&lt;h4&gt;主要发现&lt;/h4&gt;该框架由两层层次结构组成：安全速度生成层和安全鲁棒控制器层。第一层通过二阶锥规划生成安全保证的参考速度，并引入循环不等式来减轻控制屏障函数（CBF）方法中常见的局部最小问题。第二层包含一个集成的扰动观察器和光滑的安全滤波器，以显式补偿估计误差，提高对外部干扰的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;广泛的数值模拟和蒙特卡洛分析验证了该框架的有效性，显示出与传统的CBF方法相比，具有显著提高的安全边际和避免局部最小值的能力。&lt;h4&gt;翻译&lt;/h4&gt;本研究针对确保航天器近距离操作安全性的挑战进行了研究，重点关注在存在干扰的情况下，追踪航天器与复杂几何形状目标航天器之间的碰撞避免。为了确保这种场景下的安全性，提出了一种利用隐式神经表示的安全鲁棒控制框架。为了处理不需要显式建模的任意目标几何形状，通过增强的隐式几何正则化方法从点云数据中学习神经符号距离函数（SDF），该正则化方法结合了过逼近策略来创建一个保守的、以安全为优先的边界。目标表面由学习到的神经SDF的零水平集隐式定义，其值和梯度为安全控制器设计提供关键信息。该神经SDF表示支持一个两层的层次结构安全鲁棒控制框架：一个安全速度生成层和一个安全鲁棒控制器层。在第一层中，通过二阶锥规划生成安全保证的参考速度，并通过显式结合下逼近误差界限。此外，引入了循环不等式来减轻控制屏障函数（CBF）方法中常见的局部最小问题。第二层包含一个集成的扰动观察器和光滑的安全滤波器，以显式补偿估计误差，增强对外部干扰的鲁棒性。广泛的数值模拟和蒙特卡洛分析验证了所提出框架的有效性，显示出与传统的CBF方法相比，具有显著提高的安全边际和避免局部最小值的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study addresses the challenge of ensuring safe spacecraft proximityoperations, focusing on collision avoidance between a chaser spacecraft and acomplex-geometry target spacecraft under disturbances. To ensure safety in suchscenarios, a safe robust control framework is proposed that leverages implicitneural representations. To handle arbitrary target geometries without explicitmodeling, a neural signed distance function (SDF) is learned from point clouddata via a enhanced implicit geometric regularization method, whichincorporates an over-apporximation strategy to create a conservative,safety-prioritized boundary. The target's surface is implicitly defined by thezero-level set of the learned neural SDF, while the values and gradientsprovide critical information for safety controller design. This neural SDFrepresentation underpins a two-layer hierarchcial safe robust controlframework: a safe velocity generation layer and a safe robust controller layer.In the first layer, a second-order cone program is formulated to generatesafety-guaranteed reference velocity by explicitly incorporating theunder-approximation error bound. Furthermore, a circulation inequality isintroduced to mitigate the local minimum issues commonly encountered in controlbarrier function (CBF) methods. The second layer features an integrateddisturbance observer and a smooth safety filter explicitly compensating forestimation error, bolstering robustness to external disturbances. Extensivenumerical simulations and Monte Carlo analysis validate the proposed framework,demonstrating significantly improved safety margins and avoidance of localminima compared to conventional CBF approaches.</description>
      <author>example@mail.com (Hang Zhou, Tao Meng, Kun Wang, Chengrui Shi, Renhao Mao, Weijia Wang, Jiakun Lei)</author>
      <guid isPermaLink="false">2507.13672v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Towards Constraint Temporal Answer Set Programming</title>
      <link>http://arxiv.org/abs/2507.13958v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种针对动态系统的细粒度时间和数值推理的新方法，该方法扩展了Here-and-There逻辑及其非单调均衡扩展，并针对ASP（答案集编程）进行了优化。&lt;h4&gt;背景&lt;/h4&gt;逻辑方法如ASP在处理具有细粒度时间和数值分辨率的动态系统时面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的时态和约束扩展的Here-and-There逻辑，以解决ASP在处理动态系统时的挑战。&lt;h4&gt;方法&lt;/h4&gt;通过结合线性时间逻辑的Here-and-There和带有约束的Here-and-There逻辑，实现了一种表达性强的时间推理系统。&lt;h4&gt;主要发现&lt;/h4&gt;该系统为在ASP范式内处理具有高分辨率的复杂动态系统提供了基础逻辑框架。&lt;h4&gt;结论&lt;/h4&gt;这种方法为ASP在处理动态系统方面提供了新的思路和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reasoning about dynamic systems with a fine-grained temporal and numericresolution presents significant challenges for logic-based approaches likeAnswer Set Programming (ASP). To address this, we introduce and elaborate upona novel temporal and constraint-based extension of the logic of Here-and-Thereand its nonmonotonic equilibrium extension, representing, to the best of ourknowledge, the first approach to nonmonotonic temporal reasoning withconstraints specifically tailored for ASP. This expressive system is achievedby a synergistic combination of two foundational ASP extensions: thelinear-time logic of Here-and-There, providing robust nonmonotonic temporalreasoning capabilities, and the logic of Here-and-There with constraints,enabling the direct integration and manipulation of numeric constraints, amongothers. This work establishes the foundational logical framework for tacklingcomplex dynamic systems with high resolution within the ASP paradigm.</description>
      <author>example@mail.com (Pedro Cabalar, Martín Diéguez, François Olivier, Torsten Schaub, Igor Stéphan)</author>
      <guid isPermaLink="false">2507.13958v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Generalist Forecasting with Frozen Video Models via Latent Diffusion</title>
      <link>http://arxiv.org/abs/2507.13942v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉模型感知能力与其在短期内的通用预测性能之间的强相关性。&lt;h4&gt;背景&lt;/h4&gt;预测未来的能力对于在不同抽象层次上规划或行动的通用系统至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究视觉模型感知能力与其预测性能之间的关系。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的通用预测框架，该框架在冻结的视觉骨干网络上运行，通过训练潜在扩散模型来预测未来特征，然后通过轻量级、特定任务的读取输出进行解码。&lt;h4&gt;主要发现&lt;/h4&gt;发现视觉模型的感知能力与其短期预测性能之间存在强相关性，这一趋势适用于多种预训练模型，包括生成性训练的模型，以及从原始像素到深度、点轨迹和物体运动等多个抽象层次。&lt;h4&gt;结论&lt;/h4&gt;强调了将表示学习与生成建模相结合对于时间基础视频理解的价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预测未来是通用系统在不同抽象层次上规划或行动的关键技能。在本文中，我们确定了视觉模型的感知能力与其在短期内的通用预测性能之间的强相关性。这一趋势适用于包括那些经过生成性训练的在内的多种预训练模型，并且适用于从原始像素到深度、点轨迹和物体运动等多个抽象层次。这一结果是通过一个新型通用预测框架实现的，该框架可以在任何冻结的视觉骨干网络上运行：我们训练潜在扩散模型来预测冻结表示空间中的未来特征，然后通过轻量级、特定任务的读取输出进行解码。为了在不同任务中实现一致的评估，我们引入了分布性指标，这些指标直接在下游任务的领域中比较分布属性，并将此框架应用于九种模型和四种任务。我们的结果突出了将表示学习与生成建模相结合对于时间基础视频理解的价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forecasting what will happen next is a critical skill for general-purposesystems that plan or act in the world at different levels of abstraction. Inthis paper, we identify a strong correlation between a vision model'sperceptual ability and its generalist forecasting performance over short timehorizons. This trend holds across a diverse set of pretrained models-includingthose trained generatively-and across multiple levels of abstraction, from rawpixels to depth, point tracks, and object motion. The result is made possibleby a novel generalist forecasting framework that operates on any frozen visionbackbone: we train latent diffusion models to forecast future features in thefrozen representation space, which are then decoded via lightweight,task-specific readouts. To enable consistent evaluation across tasks, weintroduce distributional metrics that compare distributional propertiesdirectly in the space of downstream tasks and apply this framework to ninemodels and four tasks. Our results highlight the value of bridgingrepresentation learning and generative modeling for temporally grounded videounderstanding.</description>
      <author>example@mail.com (Jacob C Walker, Pedro Vélez, Luisa Polania Cabrera, Guangyao Zhou, Rishabh Kabra, Carl Doersch, Maks Ovsjanikov, João Carreira, Shiry Ginosar)</author>
      <guid isPermaLink="false">2507.13942v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision</title>
      <link>http://arxiv.org/abs/2507.13595v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为NoiseSDF2NoiseSDF的新方法，用于从低质量扫描设备捕获的含有大量噪声的点云中重建准确的隐式曲面表示。&lt;h4&gt;背景&lt;/h4&gt;重建准确的隐式曲面表示是一项具有挑战性的任务，特别是在使用低质量扫描设备捕捉数据时，点云通常含有大量噪声，导致表面重建不准确。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了NoiseSDF2NoiseSDF方法，目的是从噪声点云中直接学习干净的神经SDF（隐式曲面表示），并通过最小化噪声SDF表示之间的均方误差损失来实现。&lt;h4&gt;方法&lt;/h4&gt;该方法受到2D图像中的Noise2Noise范式的启发，将这一概念扩展到3D神经场。通过噪声监督，Network能够隐式地降噪并细化表面估计。&lt;h4&gt;主要发现&lt;/h4&gt;在ShapeNet、ABC、Famous和Real数据集等基准测试中，实验结果表明，该框架在从噪声输入中重建表面质量方面有显著提升。&lt;h4&gt;结论&lt;/h4&gt;NoiseSDF2NoiseSDF方法在处理低质量扫描设备生成的噪声点云并重建高质量的表面表示方面表现出色。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为NoiseSDF2NoiseSDF的新方法，旨在从低质量扫描设备捕获的含有大量噪声的点云中重建准确的隐式曲面表示。受2D图像中的Noise2Noise范式启发，该方法通过噪声监督，直接从噪声点云学习干净的神经SDF，并通过最小化噪声SDF表示之间的均方误差损失，实现隐式降噪和表面估计的细化。在ShapeNet、ABC、Famous和Real数据集等基准测试中，实验结果表明，该框架在从噪声输入中重建表面质量方面有显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing accurate implicit surface representations from point cloudsremains a challenging task, particularly when data is captured usinglow-quality scanning devices. These point clouds often contain substantialnoise, leading to inaccurate surface reconstructions. Inspired by theNoise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novelmethod designed to extend this concept to 3D neural fields. Our approachenables learning clean neural SDFs directly from noisy point clouds throughnoisy supervision by minimizing the MSE loss between noisy SDF representations,allowing the network to implicitly denoise and refine surface estimations. Weevaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including theShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate thatour framework significantly improves surface reconstruction quality from noisyinputs.</description>
      <author>example@mail.com (Tengkai Wang, Weihao Li, Ruikai Cui, Shi Qiu, Nick Barnes)</author>
      <guid isPermaLink="false">2507.13595v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models as Class-Incremental Learners for Dermatological Image Classification</title>
      <link>http://arxiv.org/abs/2507.14050v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the MICCAI EMERGE 2025 workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究在皮肤病学疾病分类中，使用预训练的大型皮肤病变数据集的冻结基础模型（FM）进行增量学习（CIL）的方法。&lt;h4&gt;背景&lt;/h4&gt;增量学习（CIL）旨在随着时间的推移学习新类别而不忘记先前获取的知识。预训练的基础模型（FM）为CIL提供了丰富的可迁移表示，但在皮肤病学中应用增量学习的潜力尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;系统地评估冻结的FM在皮肤病学疾病分类中进行CIL的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种简单而有效的方法，其中骨干网络保持冻结，并为每个任务训练了一个轻量级的MLP（多层感知器）。通过冻结骨干网络和增量训练轻量级MLP，该方法实现了最先进的性能，并优于正则化、重放和基于架构的方法。此外，还研究了零训练场景，使用来自FM嵌入的原型进行最近平均分类器。&lt;h4&gt;主要发现&lt;/h4&gt;冻结的FM在皮肤病学中进行持续学习表现出强大的能力，并且原型基于的变体也能实现具有竞争力的结果。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，冻结的FM在皮肤病学中的应用潜力巨大，并支持其在现实世界医疗应用中的更广泛采用。&lt;h4&gt;翻译&lt;/h4&gt;Class-Incremental Learning (CIL) aims to learn new classes over time without forgetting previously acquired knowledge. The emergence of foundation models(FM) pretrained on large datasets presents new opportunities for CIL by offering rich, transferable representations. However, their potential for enabling incremental learning in dermatology remains largely unexplored. In this paper, we systematically evaluate frozen FMs pretrained on large-scale skin lesion datasets for CIL in dermatological disease classification. We propose a simple yet effective approach where the backbone remains frozen, and a lightweight MLP is trained incrementally for each task. This setup achieves state-of-the-art performance without forgetting, outperforming regularization, replay, and architecture based methods. To further explore the capabilities of frozen FMs, we examine zero training scenarios using nearest mean classifiers with prototypes derived from their embeddings. Through extensive ablation studies, we demonstrate that this prototype based variant can also achieve competitive results. Our findings highlight the strength of frozen FMs for continual learning in dermatology and support their broader adoption in real-world medical applications. Our code and datasets are available here.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Class-Incremental Learning (CIL) aims to learn new classes over time withoutforgetting previously acquired knowledge. The emergence of foundation models(FM) pretrained on large datasets presents new opportunities for CIL byoffering rich, transferable representations. However, their potential forenabling incremental learning in dermatology remains largely unexplored. Inthis paper, we systematically evaluate frozen FMs pretrained on large-scaleskin lesion datasets for CIL in dermatological disease classification. Wepropose a simple yet effective approach where the backbone remains frozen, anda lightweight MLP is trained incrementally for each task. This setup achievesstate-of-the-art performance without forgetting, outperforming regularization,replay, and architecture based methods. To further explore the capabilities offrozen FMs, we examine zero training scenarios using nearest mean classifierswith prototypes derived from their embeddings. Through extensive ablationstudies, we demonstrate that this prototype based variant can also achievecompetitive results. Our findings highlight the strength of frozen FMs forcontinual learning in dermatology and support their broader adoption in realworld medical applications. Our code and datasets are available here.</description>
      <author>example@mail.com (Mohamed Elkhayat, Mohamed Mahmoud, Jamil Fayyad, Nourhan Bayasi)</author>
      <guid isPermaLink="false">2507.14050v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Robust Anomaly Detection with Graph Neural Networks using Controllability</title>
      <link>http://arxiv.org/abs/2507.13954v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  conference paper published in IEEE CAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于平均可控性的异常检测方法，旨在解决复杂域中异常检测的挑战。&lt;h4&gt;背景&lt;/h4&gt;异常检测在复杂领域中存在挑战，主要是因为需要大量的标记数据和异常样本与良性样本之间的固有不平衡性。&lt;h4&gt;目的&lt;/h4&gt;通过将节点的影响（通过平均可控性量化）整合到图中，以提高异常检测的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了两种将平均可控性集成到图框架中的新方法：(1)将平均可控性作为边权重，(2)将其编码为one-hot边属性向量。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界和合成网络上进行的严格评估中，提出的方法在识别异常方面表现出了改进，强调了可控性度量在增强图机器学习模型性能中的关键作用。&lt;h4&gt;结论&lt;/h4&gt;本研究强调了将平均可控性作为额外指标集成以解决稀疏和不平衡数据集中异常检测挑战的潜力。&lt;h4&gt;翻译&lt;/h4&gt;在复杂领域中，异常检测面临重大挑战，因为需要大量标记数据，以及异常样本与良性样本之间固有的不平衡性。基于图的学习模型作为一种解决方案，结合属性和关系数据以揭示复杂模式。然而，异常数据的稀缺加剧了这一挑战，需要创新策略来提高模型在有限信息下的学习效果。本文假设将节点的影响（通过平均可控性量化）纳入图中可以显著提高异常检测的性能。提出了两种将平均可控性集成到图框架中的新方法：(1)将平均可控性作为边权重，(2)将其编码为one-hot边属性向量。通过在真实世界和合成网络上对六种最先进的基线进行严格评估，提出的方法在识别异常方面表现出改进，突出了可控性度量在增强图机器学习模型性能中的关键作用。这项工作强调了将平均可控性作为额外指标集成的潜力，以解决稀疏和不平衡数据集中异常检测的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection in complex domains poses significant challenges due to theneed for extensive labeled data and the inherently imbalanced nature ofanomalous versus benign samples. Graph-based machine learning models haveemerged as a promising solution that combines attribute and relational data touncover intricate patterns. However, the scarcity of anomalous data exacerbatesthe challenge, which requires innovative strategies to enhance model learningwith limited information. In this paper, we hypothesize that the incorporationof the influence of the nodes, quantified through average controllability, cansignificantly improve the performance of anomaly detection. We propose twonovel approaches to integrate average controllability into graph-basedframeworks: (1) using average controllability as an edge weight and (2)encoding it as a one-hot edge attribute vector. Through rigorous evaluation onreal-world and synthetic networks with six state-of-the-art baselines, ourproposed methods demonstrate improved performance in identifying anomalies,highlighting the critical role of controllability measures in enhancing theperformance of graph machine learning models. This work underscores thepotential of integrating average controllability as additional metrics toaddress the challenges of anomaly detection in sparse and imbalanced datasets.</description>
      <author>example@mail.com (Yifan Wei, Anwar Said, Waseem Abbas, Xenofon Koutsoukos)</author>
      <guid isPermaLink="false">2507.13954v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation</title>
      <link>http://arxiv.org/abs/2507.13486v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 9 figures, this manuscript has been submitted to ISPRS  Journal of Photogrammetry and Remote Sensing for consideration&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种不确定性量化框架，用于提高点云的每点精度证书，特别针对基于摄影测量的点云，该框架解决了MVS阶段的不确定性估计问题。&lt;h4&gt;背景&lt;/h4&gt;与空基激光雷达相比，摄影测量点云的精度高度依赖于场景，因为其依赖于算法生成的测量（如立体或多视角立体）。目前，SfM阶段的不确定性估计已有研究，但MVS阶段的不确定性估计仍不成熟。&lt;h4&gt;目的&lt;/h4&gt;提出一个不确定性量化框架，以解决MVS阶段的不确定性估计问题，并提高点云的精度。&lt;h4&gt;方法&lt;/h4&gt;该框架通过为每个点关联一个误差协方差矩阵，来考虑摄影测量过程的两个步骤：SfM与BA，然后是MVS。为了估计MVS阶段的不确定性，提出了一种新的自校准方法，使用可靠的n视图点（n&gt;=6）来回归视差不确定性，利用MVS阶段的高度相关线索（如匹配成本值）。&lt;h4&gt;主要发现&lt;/h4&gt;该方法使用自包含、可靠的3D点，直接从MVS过程中提取，具有自监督和自然遵循摄影测量过程错误传播路径的优点，从而在各种场景中提供稳健和可验证的不确定性量化。&lt;h4&gt;结论&lt;/h4&gt;通过使用公开的空基和无人机图像数据集评估该框架，结果表明，该方法在实现高边界率的同时，不会高估不确定性，优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：摄影测量过程的不确定性量化对于提供点云的每点精度证书至关重要。与通常在各种场景中提供一致精度的空基激光雷达不同，摄影测量点云的精度高度依赖于场景，因为它依赖于算法生成的测量（即立体或多视角立体）。一般来说，摄影测量点云的错误通过两个步骤传播：运动结构（SfM）与捆绑调整（BA），然后是多视角立体（MVS）。尽管SfM阶段的不确定性估计已经通过重投影误差函数的一阶统计得到了很好的研究，但MVS阶段的不确定性估计仍然很大程度上未解决且不规范，这主要是由于其非可微性和多模态性质（即从像素值到几何形状）。在本文中，我们提出了一种不确定性量化框架，通过为每个点关联一个误差协方差矩阵来填补这一差距，以考虑这一摄影测量过程的两个步骤。具体来说，为了估计MVS阶段的不确定性，我们提出了一种新的自校准方法，通过使用每个视图中的可靠n视图点（n&gt;=6）来回归视差不确定性，并使用MVS阶段的高度相关线索（如匹配成本值）。与现有方法相比，我们的方法使用自包含、可靠的3D点，直接从MVS过程中提取，具有自监督和自然遵循摄影测量过程错误传播路径的优点，从而在各种场景中提供稳健和可验证的不确定性量化。我们使用各种公开的空基和无人机图像数据集评估了该框架。结果表明，我们的方法通过实现高边界率而不会高估不确定性，优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Uncertainty quantification of the photogrammetry process is essential forproviding per-point accuracy credentials of the point clouds. Unlike airborneLiDAR, which typically delivers consistent accuracy across various scenes, theaccuracy of photogrammetric point clouds is highly scene-dependent, since itrelies on algorithm-generated measurements (i.e., stereo or multi-view stereo).Generally, errors of the photogrammetric point clouds propagate through atwo-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfMstage has been well studied using the first-order statistics of thereprojection error function, that in the MVS stage remains largely unsolved andnon-standardized, primarily due to its non-differentiable and multi-modalnature (i.e., from pixel values to geometry). In this paper, we present anuncertainty quantification framework closing this gap by associating an errorcovariance matrix per point accounting for this two-step photogrammetryprocess. Specifically, to estimate the uncertainty in the MVS stage, we proposea novel, self-calibrating method by taking reliable n-view points (n&gt;=6)per-view to regress the disparity uncertainty using highly relevant cues (suchas matching cost values) from the MVS stage. Compared to existing approaches,our method uses self-contained, reliable 3D points extracted directly from theMVS process, with the benefit of being self-supervised and naturally adheringto error propagation path of the photogrammetry process, thereby providing arobust and certifiable uncertainty quantification across diverse scenes. Weevaluate the framework using a variety of publicly available airborne and UAVimagery datasets. Results demonstrate that our method outperforms existingapproaches by achieving high bounding rates without overestimating uncertainty.</description>
      <author>example@mail.com (Debao Huang, Rongjun Qin)</author>
      <guid isPermaLink="false">2507.13486v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation</title>
      <link>http://arxiv.org/abs/2507.13957v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DUALRec的新型推荐系统，它结合了LSTM网络的时间建模能力和经过微调的大型语言模型的语义推理能力，旨在解决传统推荐系统在捕捉用户动态偏好和上下文信息方面的不足。&lt;h4&gt;背景&lt;/h4&gt;现代推荐系统面临挑战，需要建模和预测动态且丰富的用户偏好。传统方法在捕捉时间模式和用户意图方面存在困难，而大型语言模型和LSTM模型各有优势但也存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够结合LSTM和大型语言模型优势的推荐系统，以更准确地预测用户偏好。&lt;h4&gt;方法&lt;/h4&gt;DUALRec模型利用LSTM网络通过用户的观看历史捕捉用户不断变化的偏好，同时利用微调的大型语言模型来生成用户可能喜欢的下一部电影。&lt;h4&gt;主要发现&lt;/h4&gt;在MovieLens-1M数据集上的实验结果表明，DUALRec模型在命中率（HR@k）、归一化折现累积增益（NDCG@k）和类型相似度指标方面优于多种基线模型。&lt;h4&gt;结论&lt;/h4&gt;DUALRec模型通过弥合时间序列建模和语义推理之间的差距，为开发更智能和上下文感知的推荐系统提供了有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of the paper is summarized as follows: This paper proposes a novel recommender system named DUALRec, which combines the temporal modeling ability of LSTM networks with the semantic reasoning power of fine-tuned large language models to address the challenges of traditional recommendation systems in capturing dynamic and context-rich user preferences. The DUALRec model utilizes the LSTM network to capture the evolving preferences of users through their viewing history, while leveraging the fine-tuned large language models to generate movies that users might enjoy. Experimental results on the MovieLens-1M dataset show that the DUALRec model outperforms a wide range of baseline models in terms of Hit Rate (HR@k), Normalized Discounted Cumulative Gain (NDCG@k), and genre similarity metrics. This research proposes a novel architecture that bridges the gap between temporal sequence modeling and semantic reasoning, and offers a promising direction for developing more intelligent and context-aware recommenders.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The modern recommender systems are facing an increasing challenge ofmodelling and predicting the dynamic and context-rich user preferences.Traditional collaborative filtering and content-based methods often struggle tocapture the temporal patternings and evolving user intentions. While LargeLanguage Models (LLMs) have gained gradual attention in recent years, by theirstrong semantic understanding and reasoning abilities, they are not inherentlydesigned to model chronologically evolving user preference and intentions. Onthe other hand, for sequential models like LSTM (Long-Short-Term-Memory) whichis good at capturing the temporal dynamics of user behaviour and evolving userpreference over time, but still lacks a rich semantic understanding forcomprehensive recommendation generation. In this study, we propose DUALRec(Dynamic User-Aware Language-based Recommender), a novel recommender thatleverages the complementary strength of both models, which combines thetemporal modelling abilities of LSTM networks with semantic reasoning power ofthe fine-tuned Large Language Models. The LSTM component will capture usersevolving preference through their viewing history, while the fine-tuned LLMvariants will leverage these temporal user insights to generate next moviesthat users might enjoy. Experimental results on MovieLens-1M dataset shows thatthe DUALRec model outperforms a wide range of baseline models, withcomprehensive evaluation matrices of Hit Rate (HR@k), Normalized DiscountedCumulative Gain (NDCG@k), and genre similarity metrics. This research proposesa novel architecture that bridges the gap between temporal sequence modelingand semantic reasoning, and offers a promising direction for developing moreintelligent and context-aware recommenders.</description>
      <author>example@mail.com (Yitong Li, Raoul Grasman)</author>
      <guid isPermaLink="false">2507.13957v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Reframing attention as a reinforcement learning problem for causal discovery</title>
      <link>http://arxiv.org/abs/2507.13920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的因果过程框架，用于表示关于因果结构的动态假设，并提出了一种相应的因果过程模型。该模型将注意力机制应用于强化学习环境中，以从视觉观察中推断可解释的因果过程。&lt;h4&gt;背景&lt;/h4&gt;形式化的因果性框架与深度强化学习（RL）的发展趋势并行，但大多数神经因果模型都假设静态的因果图，忽略了因果交互的动态性。&lt;h4&gt;目的&lt;/h4&gt;在强化学习（RL）环境中，使用注意力机制来推断可解释的因果过程，并通过建立因果图假设实现。&lt;h4&gt;方法&lt;/h4&gt;提出因果过程框架，作为表示动态因果结构的理论；实现因果过程模型，并将其应用于强化学习环境中；利用强化学习代理来建立类似于Transformer注意力机制的单元链接，形成因果图假设。&lt;h4&gt;主要发现&lt;/h4&gt;在强化学习环境中，该方法在因果表示学习和代理性能方面优于现有替代方案，并能独特地恢复动态因果过程的图。&lt;h4&gt;结论&lt;/h4&gt;因果过程框架和模型为在强化学习环境中推断可解释的因果过程提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Formal frameworks of causality have operated largely parallel to moderntrends in deep reinforcement learning (RL). However, there has been a revivalof interest in formally grounding the representations learned by neuralnetworks in causal concepts. Yet, most attempts at neural models of causalityassume static causal graphs and ignore the dynamic nature of causalinteractions. In this work, we introduce Causal Process framework as a noveltheory for representing dynamic hypotheses about causal structure. Furthermore,we present Causal Process Model as an implementation of this framework. Thisallows us to reformulate the attention mechanism popularized by Transformernetworks within an RL setting with the goal to infer interpretable causalprocesses from visual observations. Here, causal inference corresponds toconstructing a causal graph hypothesis which itself becomes an RL task nestedwithin the original RL problem. To create an instance of such hypothesis, weemploy RL agents. These agents establish links between units similar to theoriginal Transformer attention mechanism. We demonstrate the effectiveness ofour approach in an RL environment where we outperform current alternatives incausal representation learning and agent performance, and uniquely recovergraphs of dynamic causal processes.</description>
      <author>example@mail.com (Turan Orujlu, Christian Gumbsch, Martin V. Butz, Charley M Wu)</author>
      <guid isPermaLink="false">2507.13920v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Pathology Foundation Models for Panoptic Segmentation of Melanoma in H&amp;E Images</title>
      <link>http://arxiv.org/abs/2507.13974v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MIUA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新型深度学习网络，用于黑色素瘤H&amp;E图像中五种组织类的分割，以提高病理诊断的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;黑色素瘤是一种具有快速进展和高转移潜能的皮肤癌。准确描述组织形态对预后和治疗计划至关重要，但手动分割H&amp;E染色的全切片图像（WSIs）既耗时又容易受到观察者间差异的影响。&lt;h4&gt;目的&lt;/h4&gt;开发一种可靠且高效的自动化组织分割方法，以减少手动分割的劳动强度和观察者间差异。&lt;h4&gt;方法&lt;/h4&gt;本研究采用Virchow2病理基础模型作为特征提取器，结合原始RGB图像，并通过编码器-解码器分割网络（Efficient-UNet）进行处理，生成准确的分割图。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型在PUMA Grand Challenge的组织分割任务中取得了第一名，证明了其稳健的性能和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;将病理基础模型纳入分割网络中具有潜力，可以有效加速计算病理学工作流程。&lt;h4&gt;翻译&lt;/h4&gt;黑色素瘤是一种侵袭性皮肤癌，具有快速进展和高转移潜能。准确描述组织形态对预后和治疗计划至关重要。然而，从H&amp;E染色的全切片图像（WSIs）中手动分割组织区域既耗时又容易受到观察者间差异的影响，这促使了开发可靠自动化组织分割方法的需求。在本研究中，我们提出了一种用于黑色素瘤H&amp;E图像中五种组织类分割的新型深度学习网络。我们的方法利用Virchow2病理基础模型作为特征提取器，该模型在310万张组织病理学图像上训练。这些特征与原始RGB图像融合，然后通过编码器-解码器分割网络（Efficient-UNet）处理，以生成准确的分割图。所提出的模型在PUMA Grand Challenge的组织分割任务中取得了第一名，证明了其稳健的性能和泛化能力。我们的结果表明，将病理基础模型纳入分割网络中具有潜力和有效性，可以加速计算病理学工作流程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Melanoma is an aggressive form of skin cancer with rapid progression and highmetastatic potential. Accurate characterisation of tissue morphology inmelanoma is crucial for prognosis and treatment planning. However, manualsegmentation of tissue regions from haematoxylin and eosin (H&amp;E) stainedwhole-slide images (WSIs) is labour-intensive and prone to inter-observervariability, this motivates the need for reliable automated tissue segmentationmethods. In this study, we propose a novel deep learning network for thesegmentation of five tissue classes in melanoma H&amp;E images. Our approachleverages Virchow2, a pathology foundation model trained on 3.1 millionhistopathology images as a feature extractor. These features are fused with theoriginal RGB images and subsequently processed by an encoder-decodersegmentation network (Efficient-UNet) to produce accurate segmentation maps.The proposed model achieved first place in the tissue segmentation task of thePUMA Grand Challenge, demonstrating robust performance and generalizability.Our results show the potential and efficacy of incorporating pathologyfoundation models into segmentation networks to accelerate computationalpathology workflows.</description>
      <author>example@mail.com (Jiaqi Lv, Yijie Zhu, Carmen Guadalupe Colin Tenorio, Brinder Singh Chohan, Mark Eastwood, Shan E Ahmed Raza)</author>
      <guid isPermaLink="false">2507.13974v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction</title>
      <link>http://arxiv.org/abs/2507.13825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted in 2024. Accepted in 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EAGLE的轻量级框架，用于动态图中的时序链接预测，解决了现有T-GNNs在可扩展性和效率方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;时序链接预测在社交网络、推荐系统和电子商务平台等领域具有广泛应用。现有的T-GNNs通过复杂的架构来建模时序和结构依赖，但存在可扩展性和效率问题。&lt;h4&gt;目的&lt;/h4&gt;提出EAGLE框架，以解决现有T-GNNs的可扩展性和效率问题。&lt;h4&gt;方法&lt;/h4&gt;EAGLE框架包含一个时间感知模块和一个结构感知模块。时间感知模块从节点的最近邻居中聚合信息，反映其即时偏好；结构感知模块利用时序个性化PageRank来捕捉全局重要节点的影响。EAGLE采用自适应加权机制来动态调整这些属性的贡献，并消除复杂的多跳消息传递或内存密集型机制。&lt;h4&gt;主要发现&lt;/h4&gt;EAGLE在七个真实世界时序图上的实验表明，它在有效性和效率方面均优于最先进的T-GNNs，比有效的基于transformer的T-GNNs快50倍以上。&lt;h4&gt;结论&lt;/h4&gt;EAGLE是一种有效的时序链接预测方法，能够显著提高动态图中的链接预测性能和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal link prediction in dynamic graphs is a critical task withapplications in diverse domains such as social networks, recommendationsystems, and e-commerce platforms. While existing Temporal Graph NeuralNetworks (T-GNNs) have achieved notable success by leveraging complexarchitectures to model temporal and structural dependencies, they often sufferfrom scalability and efficiency challenges due to high computational overhead.In this paper, we propose EAGLE, a lightweight framework that integratesshort-term temporal recency and long-term global structural patterns. EAGLEconsists of a time-aware module that aggregates information from a node's mostrecent neighbors to reflect its immediate preferences, and a structure-awaremodule that leverages temporal personalized PageRank to capture the influenceof globally important nodes. To balance these attributes, EAGLE employs anadaptive weighting mechanism to dynamically adjust their contributions based ondata characteristics. Also, EAGLE eliminates the need for complex multi-hopmessage passing or memory-intensive mechanisms, enabling significantimprovements in efficiency. Extensive experiments on seven real-world temporalgraphs demonstrate that EAGLE consistently achieves superior performanceagainst state-of-the-art T-GNNs in both effectiveness and efficiency,delivering more than a 50x speedup over effective transformer-based T-GNNs.</description>
      <author>example@mail.com (Haoyang Li, Yuming Xu, Yiming Li, Hanmo Liu, Darian Li, Chen Jason Zhang, Lei Chen, Qing Li)</author>
      <guid isPermaLink="false">2507.13825v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Multiresolution local smoothness detection in non-uniformly sampled multivariate signals</title>
      <link>http://arxiv.org/abs/2507.13480v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于小波系数衰减行为的边缘检测算法，用于检测非均匀采样多元信号的局部规律性。&lt;h4&gt;背景&lt;/h4&gt;受小波系数衰减行为边缘检测的启发，结合Jaffard提出的微局部分支空间框架。&lt;h4&gt;目的&lt;/h4&gt;量化非均匀采样多元信号中的规律性。&lt;h4&gt;方法&lt;/h4&gt;使用快速样本变换（一个针对散布数据的分布小波变换）作为分析的核心工具，建立样本t系数衰减与多元信号点值规律性之间的联系。&lt;h4&gt;主要发现&lt;/h4&gt;得到属于经典H"older空间和Sobolev-Slobodeckij空间函数的衰减估计；样本t在低维结构数据中的规律性检测效果与传统小波相当，甚至在更高维和散布数据中表现出更强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过大量数值研究，展示了该算法在一维、二维和三维信号中的局部规律性检测能力，包括非均匀采样时间序列、图像分割和点云中的边缘检测。&lt;h4&gt;翻译&lt;/h4&gt;受小波系数衰减行为的边缘检测启发，我们提出了一种（近似）线性时间算法，用于检测非均匀采样多元信号的局部规律性。我们的方法在Jaffard提出的微局部分支空间框架内量化规律性。我们分析中的核心工具是快速样本变换，这是一种针对散布数据的分布小波变换。我们建立了样本t系数衰减与多元信号点值规律性之间的联系。作为副产品，我们得到了属于经典H"older空间和Sobolev-Slobodeckij空间函数的衰减估计。虽然传统小波在低维结构数据中的规律性检测是有效的，但样本t即使在更高维和散布数据中也能表现出鲁棒的性能。为了说明我们的理论发现，我们展示了大量数值研究，检测了一维、二维和三维信号的局部规律性，包括非均匀采样时间序列、图像分割以及点云中的边缘检测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inspired by edge detection based on the decay behavior of waveletcoefficients, we introduce a (near) linear-time algorithm for detecting thelocal regularity in non-uniformly sampled multivariate signals. Our approachquantifies regularity within the framework of microlocal spaces introduced byJaffard. The central tool in our analysis is the fast samplet transform, adistributional wavelet transform tailored to scattered data. We establish aconnection between the decay of samplet coefficients and the pointwiseregularity of multivariate signals. As a by product, we derive decay estimatesfor functions belonging to classical H\"older spaces and Sobolev-Slobodeckijspaces. While traditional wavelets are effective for regularity detection inlow-dimensional structured data, samplets demonstrate robust performance evenfor higher dimensional and scattered data. To illustrate our theoreticalfindings, we present extensive numerical studies detecting local regularity ofone-, two- and three-dimensional signals, ranging from non-uniformly sampledtime series over image segmentation to edge detection in point clouds.</description>
      <author>example@mail.com (Sara Avesani, Gianluca Giacchi, Michael Multerer)</author>
      <guid isPermaLink="false">2507.13480v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>An Enhanced Model-based Approach for Short Text Clustering</title>
      <link>http://arxiv.org/abs/2507.13793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对短文本聚类的解决方案，以应对社交媒体平台上的数据挑战。&lt;h4&gt;背景&lt;/h4&gt;随着社交媒体的流行，短文本聚类变得尤为重要。现有的方法主要分为基于主题模型和基于深度表示学习两种范式。&lt;h4&gt;目的&lt;/h4&gt;为了解决短文本数据稀疏、大规模和高维的特点，以及表示学习计算量大导致运行时间长的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于Dirichlet多项式混合模型（GSDMM）的折叠Gibbs抽样算法，并在此基础上提出了改进的GSDMM+方法，通过减少初始化噪声、自适应调整词权重和策略性地合并聚类来优化性能。&lt;h4&gt;主要发现&lt;/h4&gt;GSDMM+能够有效处理短文本的稀疏性和高维性，同时识别每个聚类的代表性词汇，并通过熵调整词权重实现更精细的聚类。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法在效率和有效性方面优于经典和最先进的聚类方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着社交媒体如Twitter、Google+和Facebook的普及，短文本聚类变得越来越重要。现有的方法可以大致分为两大类：基于主题模型的方法和基于深度表示学习的方法。由于短文本数据具有稀疏、大规模和高维的特点，这项任务本质上是具有挑战性的。此外，表示学习所需的计算强度显著增加了运行时间。为了解决这些问题，我们提出了一种针对Dirichlet多项式混合模型（GSDMM）的折叠Gibbs抽样算法（GSDMM），该算法能够有效地处理短文本的稀疏性和高维性，同时识别每个聚类的代表性词汇。基于GSDMM的几个需要进一步改进的方面，我们提出了一种改进的方法，即GSDMM+，旨在进一步提高其性能。GSDMM+减少了初始化噪声，并根据熵自适应地调整词权重，实现了更精细的聚类，揭示了更多与主题相关的信息。此外，还采用了策略性的聚类合并来细化聚类粒度，更好地将预测分布与真实类别分布对齐。我们进行了广泛的实验，比较了我们的方法与经典和最先进的方法。实验结果表明，我们的方法在效率和有效性方面具有优势。我们模型的源代码在https://github.com/chehaoa/VEMC上公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Short text clustering has become increasingly important with the popularityof social media like Twitter, Google+, and Facebook. Existing methods can bebroadly categorized into two paradigms: topic model-based approaches and deeprepresentation learning-based approaches. This task is inherently challengingdue to the sparse, large-scale, and high-dimensional characteristics of theshort text data. Furthermore, the computational intensity required byrepresentation learning significantly increases the running time. To addressthese issues, we propose a collapsed Gibbs Sampling algorithm for the DirichletMultinomial Mixture model (GSDMM), which effectively handles the sparsity andhigh dimensionality of short texts while identifying representative words foreach cluster. Based on several aspects of GSDMM that warrant furtherrefinement, we propose an improved approach, GSDMM+, designed to furtheroptimize its performance. GSDMM+ reduces initialization noise and adaptivelyadjusts word weights based on entropy, achieving fine-grained clustering thatreveals more topic-related information. Additionally, strategic cluster mergingis employed to refine clustering granularity, better aligning the predicteddistribution with the true category distribution. We conduct extensiveexperiments, comparing our methods with both classical and state-of-the-artapproaches. The experimental results demonstrate the efficiency andeffectiveness of our methods. The source code for our model is publiclyavailable at https://github.com/chehaoa/VEMC.</description>
      <author>example@mail.com (Enhao Cheng, Shoujia Zhang, Jianhua Yin, Xuemeng Song, Tian Gan, Liqiang Nie)</author>
      <guid isPermaLink="false">2507.13793v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Efficient and Scalable Self-Healing Databases Using Meta-Learning and Dependency-Driven Recovery</title>
      <link>http://arxiv.org/abs/2507.13757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了利用元学习和强化学习技术开发的数据库自愈框架。&lt;h4&gt;背景&lt;/h4&gt;在动态工作负载环境中，数据库的自适应性和最小化再训练是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;该研究的目的是解决动态工作负载环境中的实时适应性和最小化再训练的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出的方法结合了模型无关的元学习（MAML）和强化学习，以实现快速适应不断变化的数据库条件下的异常检测和纠正措施。在修复过程中，使用了多目标优化来平衡性能、资源利用和成本效率。通过图神经网络（GNNs）建模数据库组件之间的相互依赖性，确保整体恢复策略。通过合成任务增强和自监督学习提高了数据效率，在稀疏数据环境下实现有效训练。为了促进信任和透明度，集成了可解释人工智能技术，提供对异常检测和修复动作的易解释洞察。联邦元学习进一步实现了在分布式数据库环境中的隐私保护适应性。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在适应性、效率和可靠性方面取得了显著改进，为数据库管理和自愈系统的发展做出了贡献。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的数据库自愈框架有效解决了动态环境中的挑战，提高了数据库系统的性能和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explored the development of a novel self-healing framework fordatabases using meta-learning and reinforcement learning techniques. Theprimary objective was to address the challenges of real-time adaptability andminimal retraining in dynamic workload environments. The proposed approachintegrated Model-Agnostic Meta-Learning (MAML) with reinforcement learning toenable anomaly detection and corrective actions that adapted swiftly toevolving database conditions. Multi-objective optimization was employed tobalance performance, resource utilization, and cost efficiency during thehealing process. Graph Neural Networks (GNNs) were incorporated to modelinterdependencies within database components, ensuring holistic recoverystrategies. Data efficiency was enhanced through synthetic task augmentationand self-supervised learning, enabling effective training in sparse dataregimes. To promote trust and transparency, explainable AI techniques wereintegrated to provide interpretable insights into anomaly detection and healingactions. Federated meta-learning further enabled privacy-preservingadaptability in distributed database environments. The framework demonstratedsignificant improvements in adaptability, efficiency, and reliability,contributing to advancements in database management and self-healing systems.</description>
      <author>example@mail.com (Joydeep Chandra, Prabal Manhas)</author>
      <guid isPermaLink="false">2507.13757v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing</title>
      <link>http://arxiv.org/abs/2507.13812v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SkySense V2是一个统一的MM-RSFM，通过使用单个transformer骨干网络处理多个模态，显著提高了地球观测任务如城市规划、环境监测和自然灾害管理的效率。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态遥感方法通常需要为每种数据模态训练单独的骨干网络，导致冗余和参数利用效率低下。此外，现有的预训练方法通常使用来自自然图像的自监督学习（SSL）技术，而没有充分考虑到遥感图像的特性，如单个遥感图像中的复杂语义分布。&lt;h4&gt;目的&lt;/h4&gt;提出SkySense V2，旨在解决现有方法中存在的冗余和参数效率问题，并更好地适应遥感图像的特性。&lt;h4&gt;方法&lt;/h4&gt;SkySense V2采用单个transformer骨干网络，并使用针对遥感数据特性的新型SSL策略进行预训练。它还包括一个创新的自适应补丁合并模块和可学习的模态提示标记，以解决不同分辨率和模态之间特征多样性有限的问题。此外，还集成了混合专家（MoE）模块以进一步提高基础模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;SkySense V2在涉及16个数据集和7个任务的广泛评估中表现出令人印象深刻的泛化能力，平均比SkySense高出1.8个点。&lt;h4&gt;结论&lt;/h4&gt;SkySense V2通过其创新的设计和高效的预训练策略，在多模态遥感任务中实现了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;The multi-modal remote sensing foundation model (MM-RSFM) has significantly advanced various Earth observation tasks, such as urban planning, environmental monitoring, and natural disaster management. However, most existing approaches generally require the training of separate backbone networks for each data modality, leading to redundancy and inefficient parameter utilization. Moreover, prevalent pre-training methods typically apply self-supervised learning (SSL) techniques from natural images without adequately accommodating the characteristics of remote sensing (RS) images, such as the complicated semantic distribution within a single RS image. In this work, we present SkySense V2, a unified MM-RSFM that employs a single transformer backbone to handle multiple modalities. This backbone is pre-trained with a novel SSL strategy tailored to the distinct traits of RS data. In particular, SkySense V2 incorporates an innovative adaptive patch merging module and learnable modality prompt tokens to address challenges related to varying resolutions and limited feature diversity across modalities. In addition, we incorporate the mixture of experts (MoE) module to further enhance the performance of the foundation model. SkySense V2 demonstrates impressive generalization abilities through an extensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense by an average of 1.8 points.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The multi-modal remote sensing foundation model (MM-RSFM) has significantlyadvanced various Earth observation tasks, such as urban planning, environmentalmonitoring, and natural disaster management. However, most existing approachesgenerally require the training of separate backbone networks for each datamodality, leading to redundancy and inefficient parameter utilization.Moreover, prevalent pre-training methods typically apply self-supervisedlearning (SSL) techniques from natural images without adequately accommodatingthe characteristics of remote sensing (RS) images, such as the complicatedsemantic distribution within a single RS image. In this work, we presentSkySense V2, a unified MM-RSFM that employs a single transformer backbone tohandle multiple modalities. This backbone is pre-trained with a novel SSLstrategy tailored to the distinct traits of RS data. In particular, SkySense V2incorporates an innovative adaptive patch merging module and learnable modalityprompt tokens to address challenges related to varying resolutions and limitedfeature diversity across modalities. In additional, we incorporate the mixtureof experts (MoE) module to further enhance the performance of the foundationmodel. SkySense V2 demonstrates impressive generalization abilities through anextensive evaluation involving 16 datasets over 7 tasks, outperforming SkySenseby an average of 1.8 points.</description>
      <author>example@mail.com (Yingying Zhang, Lixiang Ru, Kang Wu, Lei Yu, Lei Liang, Yansheng Li, Jingdong Chen)</author>
      <guid isPermaLink="false">2507.13812v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach</title>
      <link>http://arxiv.org/abs/2507.13805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了基于贝叶斯神经网络方法对基础模型进行微调，并实现自动调整模型以维持指定精度，同时检测并提高对罕见事件如过渡态的采样率。&lt;h4&gt;背景&lt;/h4&gt;由于从第一性原理评估原子间力的计算复杂性，原子间机器学习力场的创建已成为一个高度活跃的研究领域。&lt;h4&gt;目的&lt;/h4&gt;减少达到所需精度所需的训练数据量，特别是对于具有罕见事件和没有广泛机器学习背景的最终用户。&lt;h4&gt;方法&lt;/h4&gt;引入基于贝叶斯神经网络方法的微调方法，并实现一个在飞行学习工作流程，该流程在模拟过程中使用模型不确定性来决定模型是否足够准确。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法可以克服在微调过程中评估模型不确定性的挑战，即使大多数基础模型缺乏任何形式的不确定性量化。&lt;h4&gt;结论&lt;/h4&gt;该方法可以自动微调模型，同时维持预指定的精度，并能检测到罕见事件如过渡态，并提高其采样率。&lt;h4&gt;翻译&lt;/h4&gt;由于评估原子间力的计算复杂性，原子间机器学习力场的创建已成为一个高度活跃的研究领域。然而，生成足够大小和样本多样性的训练数据集本身也带来了计算负担，这使得这种方法对于模拟罕见事件或具有大配置空间的系统来说不切实际。在预训练大规模材料或分子数据库的基础上微调基础模型为减少达到所需精度所需的训练数据量提供了一个有希望的机会。然而，即使这种方法总体上需要更少的训练数据，创建一个合适的训练数据集仍然是一个极具挑战性的问题，特别是对于具有罕见事件和对于没有广泛机器学习背景的最终用户来说。在即时学习过程中，可以通过使用模拟过程中的模型不确定性来决定模型是否足够准确或是否需要用经典方法重新计算结构并用于更新模型，从而在很大程度上自动化训练数据集的创建。将这种主动学习方法应用于基础模型的微调的一个关键挑战是如何在微调过程中评估这些模型的不确定性，尽管大多数基础模型缺乏任何形式的不确定性量化。在本文中，我们通过引入基于贝叶斯神经网络方法的微调方法以及随后的即时工作流程来克服这一挑战，该工作流程在微调过程中自动调整模型，同时保持预指定的精度，并能检测到罕见事件，如过渡态，并相对于其发生频率以更高的速率对其进行采样。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the computational complexity of evaluating interatomic forces fromfirst principles, the creation of interatomic machine learning force fields hasbecome a highly active field of research. However, the generation of trainingdatasets of sufficient size and sample diversity itself comes with acomputational burden that can make this approach impractical for modeling rareevents or systems with a large configuration space. Fine-tuning foundationmodels that have been pre-trained on large-scale material or moleculardatabases offers a promising opportunity to reduce the amount of training datanecessary to reach a desired level of accuracy. However, even if this approachrequires less training data overall, creating a suitable training dataset canstill be a very challenging problem, especially for systems with rare eventsand for end-users who don't have an extensive background in machine learning.In on-the-fly learning, the creation of a training dataset can be largelyautomated by using model uncertainty during the simulation to decide if themodel is accurate enough or if a structure should be recalculated withclassical methods and used to update the model. A key challenge for applyingthis form of active learning to the fine-tuning of foundation models is how toassess the uncertainty of those models during the fine-tuning process, eventhough most foundation models lack any form of uncertainty quantification. Inthis paper, we overcome this challenge by introducing a fine-tuning approachbased on Bayesian neural network methods and a subsequent on-the-fly workflowthat automatically fine-tunes the model while maintaining a pre-specifiedaccuracy and can detect rare events such as transition states and sample themat an increased rate relative to their occurrence.</description>
      <author>example@mail.com (Tim Rensmeyer, Denis Kramer, Oliver Niggemann)</author>
      <guid isPermaLink="false">2507.13805v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Team of One: Cracking Complex Video QA with Model Synergy</title>
      <link>http://arxiv.org/abs/2507.13820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的开放式视频问答框架，该框架增强了在复杂真实场景中的推理深度和鲁棒性，并在CVRR-ES数据集上进行了基准测试。&lt;h4&gt;背景&lt;/h4&gt;现有的视频-大型的多模态模型（Video-LMMs）通常表现出有限的环境理解、薄弱的时间建模以及对模糊或组合查询的泛化能力不足。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，引入了一种提示和响应集成机制，通过结构化的思维链协调多个异构的视频语言模型（VLMs），每个模型针对不同的推理路径进行定制。&lt;h4&gt;方法&lt;/h4&gt;外部大型语言模型（LLM）作为评估者和集成者，选择并融合最可靠的响应。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，该方法在所有评估指标上显著优于现有基线，展示了优越的泛化能力和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该方法提供了一种轻量级、可扩展的策略，用于推进多模态推理，而无需重新训练模型，为未来的Video-LMM发展奠定了坚实的基础。&lt;h4&gt;翻译&lt;/h4&gt;We propose a novel framework for open-ended video question answering that enhances reasoning depth and robustness in complex real-world scenarios, as benchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models (Video-LMMs) often exhibit limited contextual understanding, weak temporal modeling, and poor generalization to ambiguous or compositional queries. To address these challenges, we introduce a prompting-and-response integration mechanism that coordinates multiple heterogeneous Video-Language Models (VLMs) via structured chains of thought, each tailored to distinct reasoning pathways. An external Large Language Model (LLM) serves as an evaluator and integrator, selecting and fusing the most reliable responses. Extensive experiments demonstrate that our method significantly outperforms existing baselines across all evaluation metrics, showcasing superior generalization and robustness. Our approach offers a lightweight, extensible strategy for advancing multimodal reasoning without requiring model retraining, setting a strong foundation for future Video-LMM development.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel framework for open-ended video question answering thatenhances reasoning depth and robustness in complex real-world scenarios, asbenchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models(Video-LMMs) often exhibit limited contextual understanding, weak temporalmodeling, and poor generalization to ambiguous or compositional queries. Toaddress these challenges, we introduce a prompting-and-response integrationmechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)via structured chains of thought, each tailored to distinct reasoning pathways.An external Large Language Model (LLM) serves as an evaluator and integrator,selecting and fusing the most reliable responses. Extensive experimentsdemonstrate that our method significantly outperforms existing baselines acrossall evaluation metrics, showcasing superior generalization and robustness. Ourapproach offers a lightweight, extensible strategy for advancing multimodalreasoning without requiring model retraining, setting a strong foundation forfuture Video-LMM development.</description>
      <author>example@mail.com (Jun Xie, Zhaoran Zhao, Xiongjun Guan, Yingjian Zhu, Hongzhu Yi, Xinming Wang, Feng Chen, Zhepeng Wang)</author>
      <guid isPermaLink="false">2507.13820v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training</title>
      <link>http://arxiv.org/abs/2507.13673v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 8 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MaskHOI的预训练框架，用于增强3D手-物体交互中的姿态估计，通过解决RGB图像的几何模糊性和交互过程中的遮挡问题。&lt;h4&gt;背景&lt;/h4&gt;在3D手-物体交互任务中，从单目RGB输入中估计手和物体的精确关节姿态非常具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出MaskHOI框架，旨在通过MAE（掩码自动编码器）的预训练方法来提高手-物体交互姿态估计的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 利用MAE的掩码-重建策略，鼓励特征编码器推断缺失的空间和结构信息；2. 引入区域特定的掩码比率分配，包括区域特定的掩码分配和骨骼驱动的手部掩码指导；3. 提出掩码签名距离场（SDF）驱动的多模态学习机制，通过自掩码3D SDF预测，使编码器能够感知手和物体的全局几何结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在姿态估计方面显著优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;MaskHOI框架能够有效提高3D手-物体交互姿态估计的准确性，为相关领域的研究提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In 3D hand-object interaction (HOI) tasks, estimating precise joint poses ofhands and objects from monocular RGB input remains highly challenging due tothe inherent geometric ambiguity of RGB images and the severe mutual occlusionsthat occur during interaction.To address these challenges, we propose MaskHOI,a novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOIpose estimation. Our core idea is to leverage the masking-then-reconstructionstrategy of MAE to encourage the feature encoder to infer missing spatial andstructural information, thereby facilitating geometric-aware andocclusion-robust representation learning. Specifically, based on ourobservation that human hands exhibit far greater geometric complexity thanrigid objects, conventional uniform masking fails to effectively guide thereconstruction of fine-grained hand structures. To overcome this limitation, weintroduce a Region-specific Mask Ratio Allocation, primarily comprising theregion-specific masking assignment and the skeleton-driven hand maskingguidance. The former adaptively assigns lower masking ratios to hand regionsthan to rigid objects, balancing their feature learning difficulty, while thelatter prioritizes masking critical hand parts (e.g., fingertips or entirefingers) to realistically simulate occlusion patterns in real-worldinteractions. Furthermore, to enhance the geometric awareness of the pretrainedencoder, we introduce a novel Masked Signed Distance Field (SDF)-drivenmultimodal learning mechanism. Through the self-masking 3D SDF prediction, thelearned encoder is able to perceive the global geometric structure of hands andobjects beyond the 2D image plane, overcoming the inherent limitations ofmonocular input and alleviating self-occlusion issues. Extensive experimentsdemonstrate that our method significantly outperforms existing state-of-the-artapproaches.</description>
      <author>example@mail.com (Yuechen Xie, Haobo Jiang, Jian Yang, Yigong Zhang, Jin Xie)</author>
      <guid isPermaLink="false">2507.13673v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification</title>
      <link>http://arxiv.org/abs/2507.13741v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SamGoG的基于采样的图图（GoG）学习框架，用于有效缓解图分类任务中的类别不平衡和图大小不平衡问题，通过实验证明其性能优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在图分类任务中表现出色，但现实世界的图往往存在类别不平衡和图大小不平衡的问题，这些问题会影响学习过程和模型性能。&lt;h4&gt;目的&lt;/h4&gt;提出SamGoG框架，旨在有效缓解类别不平衡和图大小不平衡，提高模型性能。&lt;h4&gt;方法&lt;/h4&gt;SamGoG通过基于重要性的采样机制构建多个GoG，并依次在这些GoG上进行训练。采样机制结合可学习的成对相似性和自适应GoG节点度，增强边同质性，从而提高下游模型质量。&lt;h4&gt;主要发现&lt;/h4&gt;SamGoG能够无缝集成各种下游GNN，使它们能够高效地适应图分类任务。在基准数据集上的实验表明，SamGoG实现了最先进的性能，相比现有方法，准确率提高了15.66%，训练速度提高了6.7倍。&lt;h4&gt;结论&lt;/h4&gt;SamGoG是一种有效的图分类学习方法，能够显著提高模型性能，并具有广泛的适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have shown remarkable success in graphclassification tasks by capturing both structural and feature-basedrepresentations. However, real-world graphs often exhibit two critical forms ofimbalance: class imbalance and graph size imbalance. These imbalances can biasthe learning process and degrade model performance. Existing methods typicallyaddress only one type of imbalance or incur high computational costs. In thiswork, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learningframework that effectively mitigates both class and graph size imbalance.SamGoG constructs multiple GoGs through an efficient importance-based samplingmechanism and trains on them sequentially. This sampling mechanism incorporatesthe learnable pairwise similarity and adaptive GoG node degree to enhance edgehomophily, thus improving downstream model quality. SamGoG can seamlesslyintegrate with various downstream GNNs, enabling their efficient adaptation forgraph classification tasks. Extensive experiments on benchmark datasetsdemonstrate that SamGoG achieves state-of-the-art performance with up to a15.66% accuracy improvement with 6.7$\times$ training acceleration.</description>
      <author>example@mail.com (Shangyou Wang, Zezhong Ding, Xike Xie)</author>
      <guid isPermaLink="false">2507.13741v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning</title>
      <link>http://arxiv.org/abs/2507.13482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于可穿戴惯性传感器的活动识别（HAR）方法，用于远程健康监测，特别是在运动障碍患者的家中环境检测异常运动，以优化治疗并提醒护理者。&lt;h4&gt;背景&lt;/h4&gt;HAR在远程健康监测中起着关键作用，尤其是在运动障碍患者中，能够检测异常运动对于治疗优化和护理提醒至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有基于IMU数据的HAR方法在通用性和对不同环境或人群数据的泛化能力上的不足，本文提出了一种新的跨模态自监督预训练方法。&lt;h4&gt;方法&lt;/h4&gt;该方法从大规模未标记的IMU-视频数据中学习表示，并在分布外的IMU数据集上展示了改进的泛化能力，包括来自帕金森病患者的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，所提出的跨模态预训练方法在零样本和少样本评估中优于当前最先进的IMU-视频预训练方法和仅IMU预训练方法。&lt;h4&gt;结论&lt;/h4&gt;研究提供了证据，表明在高度动态的数据模态（如IMU信号）中，跨模态预训练可能是一个学习通用数据表示的有用工具。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a Human Activity Recognition (HAR) method based on wearable inertial sensors for remote health monitoring, especially in detecting abnormal movements in the home environment of patients with movement disorders, for treatment optimization and caregiver alerting. To address the limitations of existing HAR methods using IMU data, which lack generalizability to data collected in different environments or populations, a new cross-modal self-supervised pretraining approach is proposed. This method learns representations from large-scale unlabeled IMU-video data and demonstrates improved generalizability on out-of-distribution (OOD) IMU datasets, including a dataset collected from patients with Parkinson's disease. The results indicate that the proposed cross-modal pretraining approach outperforms the current state-of-the-art IMU-video pretraining approach and IMU-only pretraining under zero-shot and few-shot evaluations. The study provides evidence that cross-modal pretraining may be a useful tool for learning generalizable data representations in highly dynamic data modalities such as IMU signals.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human Activity Recognition (HAR) based on wearable inertial sensors plays acritical role in remote health monitoring. In patients with movement disorders,the ability to detect abnormal patient movements in their home environments canenable continuous optimization of treatments and help alert caretakers asneeded. Machine learning approaches have been proposed for HAR tasks usingInertial Measurement Unit (IMU) data; however, most rely onapplication-specific labels and lack generalizability to data collected indifferent environments or populations. To address this limitation, we propose anew cross-modal self-supervised pretraining approach to learn representationsfrom large-sale unlabeled IMU-video data and demonstrate improvedgeneralizability in HAR tasks on out of distribution (OOD) IMU datasets,including a dataset collected from patients with Parkinson's disease.Specifically, our results indicate that the proposed cross-modal pretrainingapproach outperforms the current state-of-the-art IMU-video pretrainingapproach and IMU-only pretraining under zero-shot and few-shot evaluations.Broadly, our study provides evidence that in highly dynamic data modalities,such as IMU signals, cross-modal pretraining may be a useful tool to learngeneralizable data representations. Our software is available athttps://github.com/scheshmi/IMU-Video-OOD-HAR.</description>
      <author>example@mail.com (Seyyed Saeid Cheshmi, Buyao Lyu, Thomas Lisko, Rajesh Rajamani, Robert A. McGovern, Yogatheesan Varatharajah)</author>
      <guid isPermaLink="false">2507.13482v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop</title>
      <link>http://arxiv.org/abs/2507.13363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于2D视觉-语言模型进行开放词汇3D物体检测的方法，无需人工标注3D标签，通过自然语言提示支持开放词汇检测。&lt;h4&gt;背景&lt;/h4&gt;现代3D物体检测数据集受限于狭窄的分类体系和昂贵的手动标注，限制了其在开放世界环境中的扩展能力。&lt;h4&gt;目的&lt;/h4&gt;利用2D基础模型的成熟度和类别多样性，实现无需人工标注的开放词汇3D物体检测。&lt;h4&gt;方法&lt;/h4&gt;使用2D视觉-语言检测器生成文本条件下的候选框，通过相机几何和激光雷达或单目伪深度将其分割并投影到3D空间。引入基于DBSCAN聚类和旋转卡尺的几何膨胀策略来推断3D边界框。为了模拟现实世界的恶劣条件，构建了伪nuScenes数据集。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在各种设置中实现了有竞争力的定位性能，包括基于激光雷达和纯RGB-D输入，同时保持训练自由和开放词汇。&lt;h4&gt;结论&lt;/h4&gt;2D基础模型在可扩展的3D感知方面具有未被充分利用的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a method for open-vocabulary 3D object detection based on 2D vision-language models, which does not require any human-annotated 3D labels and supports open-vocabulary detection via natural language prompts.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern 3D object detection datasets are constrained by narrow classtaxonomies and costly manual annotations, limiting their ability to scale toopen-world settings. In contrast, 2D vision-language models trained onweb-scale image-text pairs exhibit rich semantic understanding and supportopen-vocabulary detection via natural language prompts. In this work, weleverage the maturity and category diversity of 2D foundation models to performopen-vocabulary 3D object detection without any human-annotated 3D labels.  Our pipeline uses a 2D vision-language detector to generate text-conditionedproposals, which are segmented with SAM and back-projected into 3D using camerageometry and either LiDAR or monocular pseudo-depth. We introduce a geometricinflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3Dbounding boxes without training. To simulate adverse real-world conditions, weconstruct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenesdataset.  Experiments demonstrate that our method achieves competitive localizationperformance across multiple settings, including LiDAR-based and purely RGB-Dinputs, all while remaining training-free and open-vocabulary. Our resultshighlight the untapped potential of 2D foundation models for scalable 3Dperception. We open-source our code and resources athttps://github.com/atharv0goel/open-world-3D-det.</description>
      <author>example@mail.com (Atharv Goel, Mehar Khurana)</author>
      <guid isPermaLink="false">2507.13363v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion</title>
      <link>http://arxiv.org/abs/2507.13721v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的混合特征融合框架，用于构建故障模式的图结构数据集，以解决自主货船（ACS）组件故障引起的级联反应和紧急决策的不确定性。&lt;h4&gt;背景&lt;/h4&gt;自主货船的组件故障可能导致级联反应，而在紧急情况下，决策的不确定性是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来提高文献检索效率，并构建一个用于故障分析的数据集。&lt;h4&gt;方法&lt;/h4&gt;采用改进的布谷鸟搜索算法（HN-CSA）提高文献检索效率，构建了一个分层特征融合框架，使用Word2Vec编码子系统/组件特征，BERT-KPCA处理故障模式/原因，Sentence-BERT量化故障影响与紧急决策之间的语义关联。&lt;h4&gt;主要发现&lt;/h4&gt;GATE-GNN模型在分类任务上达到了0.735的分类准确率，与现有基准相当；特征区分度高， silhouette系数为0.641；基于Shore的气象服务系统在标签预测结果中达到了0.93的F1分数。&lt;h4&gt;结论&lt;/h4&gt;该方法为自主货船的故障分析提供了一个坚实的基础，并为故障诊断、风险评估和智能决策系统提供了可靠的支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要：为了解决由自主货船（ACS）组件故障引起的级联反应和紧急决策的不确定性带来的挑战，本文提出了一种新的混合特征融合框架，用于构建故障模式的图结构数据集。通过采用改进的布谷鸟搜索算法（HN-CSA），显著提高了文献检索效率，与NSGA-II和CSA搜索算法相比，分别提高了7.1%和3.4%。构建了一个分层特征融合框架，使用Word2Vec编码子系统/组件特征，BERT-KPCA处理故障模式/原因，Sentence-BERT量化故障影响与紧急决策之间的语义关联。数据集覆盖12个系统，1,262种故障模式和6,150条传播路径。验证结果表明，GATE-GNN模型达到了0.735的分类准确率，与现有基准相当。此外，silhouette系数为0.641，表明特征区分度高。在标签预测结果中，基于Shore的气象服务系统达到了0.93的F1分数，显示了高预测准确性。本文不仅为自主货船的故障分析提供了一个坚实的基础，还为故障诊断、风险评估和智能决策系统提供了可靠的支持。数据集链接为https://github.com/wojiufukele/Graph-Structured-about-CSA。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To address the challenges posed by cascading reactions caused by componentfailures in autonomous cargo ships (ACS) and the uncertainties in emergencydecision-making, this paper proposes a novel hybrid feature fusion frameworkfor constructing a graph-structured dataset of failure modes. By employing animproved cuckoo search algorithm (HN-CSA), the literature retrieval efficiencyis significantly enhanced, achieving improvements of 7.1% and 3.4% compared tothe NSGA-II and CSA search algorithms, respectively. A hierarchical featurefusion framework is constructed, using Word2Vec encoding to encodesubsystem/component features, BERT-KPCA to process failure modes/reasons, andSentence-BERT to quantify the semantic association between failure impact andemergency decision-making. The dataset covers 12 systems, 1,262 failure modes,and 6,150 propagation paths. Validation results show that the GATE-GNN modelachieves a classification accuracy of 0.735, comparable to existing benchmarks.Additionally, a silhouette coefficient of 0.641 indicates that the features arehighly distinguishable. In the label prediction results, the Shore-basedMeteorological Service System achieved an F1 score of 0.93, demonstrating highprediction accuracy. This paper not only provides a solid foundation forfailure analysis in autonomous cargo ships but also offers reliable support forfault diagnosis, risk assessment, and intelligent decision-making systems. Thelink to the dataset ishttps://github.com/wojiufukele/Graph-Structured-about-CSA.</description>
      <author>example@mail.com (Zizhao Zhang, Tianxiang Zhao, Yu Sun, Liping Sun, Jichuan Kang)</author>
      <guid isPermaLink="false">2507.13721v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Towards channel foundation models (CFMs): Motivations, methodologies and opportunities</title>
      <link>http://arxiv.org/abs/2507.13637v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的通道基础模型（CFM），旨在解决传统AI模型在无线通信系统中的局限性。&lt;h4&gt;背景&lt;/h4&gt;人工智能（AI）已成为下一代无线通信系统的重要推动力，但传统AI模型存在依赖标记数据、泛化能力有限和任务特定设计等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文提出了通道基础模型（CFM）的概念，通过预训练的通用通道特征提取器来处理各种与通道相关的任务。&lt;h4&gt;方法&lt;/h4&gt;CFM利用先进的AI架构和自监督学习技术，能够在无需大量手动标注的情况下，有效地利用大规模未标记数据。文章还分析了AI方法的发展历程，从监督学习、多任务学习到自监督学习，并强调自监督学习在促进CFM发展中的优势。此外，对现有自我监督学习研究进行了综述，并分为生成性、判别性和结合范式。&lt;h4&gt;主要发现&lt;/h4&gt;CFM能够有效地处理多种通道相关任务，并且在自我监督学习方面的应用具有显著优势。&lt;h4&gt;结论&lt;/h4&gt;尽管CFM的研究还处于早期阶段，但仍具有广阔的应用前景，未来的研究方向包括模型架构创新和高质量、多样化的通道数据集构建。&lt;h4&gt;翻译&lt;/h4&gt;Artificial intelligence (AI) has emerged as a pivotal enabler for next-generation wireless communication systems. However, conventional AI-based models encounter several limitations, such as heavy reliance on labeled data, limited generalization capability, and task-specific design. To address these challenges, this paper introduces, for the first time, the concept of channel foundation models (CFMs)-a novel and unified framework designed to tackle a wide range of channel-related tasks through a pretrained, universal channel feature extractor. By leveraging advanced AI architectures and self-supervised learning techniques, CFMs are capable of effectively exploiting large-scale unlabeled data without the need for extensive manual annotation. We further analyze the evolution of AI methodologies, from supervised learning and multi-task learning to self-supervised learning, emphasizing the distinct advantages of the latter in facilitating the development of CFMs. Additionally, we provide a comprehensive review of existing studies on self-supervised learning in this domain, categorizing them into generative, discriminative and the combined paradigms. Given that the research on CFMs is still at an early stage, we identify several promising future research directions, focusing on model architecture innovation and the construction of high-quality, diverse channel datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has emerged as a pivotal enabler fornext-generation wireless communication systems. However, conventional AI-basedmodels encounter several limitations, such as heavy reliance on labeled data,limited generalization capability, and task-specific design. To address thesechallenges, this paper introduces, for the first time, the concept of channelfoundation models (CFMs)-a novel and unified framework designed to tackle awide range of channel-related tasks through a pretrained, universal channelfeature extractor. By leveraging advanced AI architectures and self-supervisedlearning techniques, CFMs are capable of effectively exploiting large-scaleunlabeled data without the need for extensive manual annotation. We furtheranalyze the evolution of AI methodologies, from supervised learning andmulti-task learning to self-supervised learning, emphasizing the distinctadvantages of the latter in facilitating the development of CFMs. Additionally,we provide a comprehensive review of existing studies on self-supervisedlearning in this domain, categorizing them into generative, discriminative andthe combined paradigms. Given that the research on CFMs is still at an earlystage, we identify several promising future research directions, focusing onmodel architecture innovation and the construction of high-quality, diversechannel datasets.</description>
      <author>example@mail.com (Jun Jiang, Yuan Gao, Xinyi Wu, Shugong Xu)</author>
      <guid isPermaLink="false">2507.13637v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Bi-GRU Based Deception Detection using EEG Signals</title>
      <link>http://arxiv.org/abs/2507.13718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种利用深度学习技术，特别是双向门控循环单元（Bi-GRU）神经网络，对欺骗和真实行为进行分类的方法。该方法使用了来自“Bag-of-Lies”数据集的脑电图（EEG）信号，该数据集是为自然、随机的欺骗场景设计的多模态语料库。&lt;h4&gt;背景&lt;/h4&gt;欺骗检测在安全、心理学和法医学等领域是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;研究目的是开发一种能够有效分类欺骗和真实行为的模型。&lt;h4&gt;方法&lt;/h4&gt;研究人员使用Bi-GRU神经网络对EEG样本进行二元分类，并在“Bag-of-Lies”数据集上训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在测试中达到了97%的准确率，并且对于两类行为都表现出了高精密度、召回率和F1分数。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，使用双向时间建模进行基于EEG的欺骗检测是有效的，并暗示了在实时应用和探索更先进的神经网络架构方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：欺骗检测是安全、心理学和法医学等领域的一个重大挑战。本研究提出了一种利用深度学习技术，特别是双向门控循环单元（Bi-GRU）神经网络，对欺骗和真实行为进行分类的方法。该方法使用了来自“Bag-of-Lies”数据集的脑电图（EEG）信号，该数据集是为自然、随机的欺骗场景设计的多模态语料库。研究人员使用Bi-GRU神经网络对EEG样本进行二元分类，并在“Bag-of-Lies”数据集上训练模型。该模型在测试中达到了97%的准确率，并且对于两类行为都表现出了高精密度、召回率和F1分数。这些结果表明，使用双向时间建模进行基于EEG的欺骗检测是有效的，并暗示了在实时应用和探索更先进的神经网络架构方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deception detection is a significant challenge in fields such as security,psychology, and forensics. This study presents a deep learning approach forclassifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)signals from the Bag-of-Lies dataset, a multimodal corpus designed fornaturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit(Bi-GRU) neural network was trained to perform binary classification of EEGsamples. The model achieved a test accuracy of 97\%, along with high precision,recall, and F1-scores across both classes. These results demonstrate theeffectiveness of using bidirectional temporal modeling for EEG-based deceptiondetection and suggest potential for real-time applications and futureexploration of advanced neural architectures.</description>
      <author>example@mail.com (Danilo Avola, Muhammad Yasir Bilal, Emad Emam, Cristina Lakasz, Daniele Pannone, Amedeo Ranaldi)</author>
      <guid isPermaLink="false">2507.13718v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Learning Deformable Body Interactions With Adaptive Spatial Tokenization</title>
      <link>http://arxiv.org/abs/2507.13707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自适应空间标记（AST）方法，用于高效地表示物理状态，并在模拟可变形体交互方面取得了显著的成果。&lt;h4&gt;背景&lt;/h4&gt;模拟可变形体交互在材料科学、机械设计和机器人等领域至关重要。尽管基于学习的方法，如图神经网络（GNNs），在解决复杂物理系统方面很有效，但在模拟可变形体交互时遇到了可扩展性问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决可扩展性问题，本文旨在提出一种新的方法，能够高效地表示物理状态并实现可扩展的模拟。&lt;h4&gt;方法&lt;/h4&gt;本文通过将模拟空间划分为单元格网格，并将非结构化网格映射到这个结构化网格上，将相邻的网格节点自然分组。然后，应用交叉注意力模块将稀疏单元格映射为紧凑的固定长度嵌入，作为整个物理状态的标记。在潜在空间中，使用自注意力模块来预测这些标记的下一个状态。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在模拟可变形体交互方面显著优于现有方法，并且在处理超过10万个节点的网格时依然有效，而现有方法因计算限制而受到阻碍。&lt;h4&gt;结论&lt;/h4&gt;AST方法通过结合标记化和注意力机制的优势，实现了准确和可扩展的模拟结果，并为未来研究提供了大量数据集。&lt;h4&gt;翻译&lt;/h4&gt;摘要：模拟可变形体的交互在材料科学、机械设计和机器人等领域至关重要。虽然基于学习的方法，如图神经网络（GNNs），在解决复杂物理系统方面非常有效，但在模拟可变形体交互时遇到了可扩展性问题。为了克服这些挑战，借鉴几何表示的见解，我们提出了一种自适应空间标记（AST）方法，用于高效表示物理状态。通过将模拟空间划分为单元格网格，并将非结构化网格映射到这个结构化网格上，我们的方法自然地将相邻的网格节点分组。然后，我们应用交叉注意力模块将稀疏单元格映射为紧凑的固定长度嵌入，作为整个物理状态的标记。在潜在空间中，使用自注意力模块来预测这些标记的下一个状态。这个框架利用了标记化的效率和注意力机制的表达能力，以实现准确和可扩展的模拟结果。大量的实验表明，我们的方法在模拟可变形体交互方面显著优于最先进的方法。值得注意的是，它对超过10万个节点的网格的大型模拟仍然有效，而现有方法因计算限制而受到阻碍。此外，我们还贡献了一个包含广泛可变形体交互的新的大规模数据集，以支持该领域的未来研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulating interactions between deformable bodies is vital in fields likematerial science, mechanical design, and robotics. While learning-based methodswith Graph Neural Networks (GNNs) are effective at solving complex physicalsystems, they encounter scalability issues when modeling deformable bodyinteractions. To model interactions between objects, pairwise global edges haveto be created dynamically, which is computationally intensive and impracticalfor large-scale meshes. To overcome these challenges, drawing on insights fromgeometric representations, we propose an Adaptive Spatial Tokenization (AST)method for efficient representation of physical states. By dividing thesimulation space into a grid of cells and mapping unstructured meshes onto thisstructured grid, our approach naturally groups adjacent mesh nodes. We thenapply a cross-attention module to map the sparse cells into a compact,fixed-length embedding, serving as tokens for the entire physical state.Self-attention modules are employed to predict the next state over these tokensin latent space. This framework leverages the efficiency of tokenization andthe expressive power of attention mechanisms to achieve accurate and scalablesimulation results. Extensive experiments demonstrate that our methodsignificantly outperforms state-of-the-art approaches in modeling deformablebody interactions. Notably, it remains effective on large-scale simulationswith meshes exceeding 100,000 nodes, where existing methods are hindered bycomputational limitations. Additionally, we contribute a novel large-scaledataset encompassing a wide range of deformable body interactions to supportfuture research in this area.</description>
      <author>example@mail.com (Hao Wang, Yu Liu, Daniel Biggs, Haoru Wang, Jiandong Yu, Ping Huang)</author>
      <guid isPermaLink="false">2507.13707v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Apple Intelligence Foundation Language Models: Tech Report 2025</title>
      <link>http://arxiv.org/abs/2507.13575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了两种多语言、多模态的基础语言模型，用于支持苹果设备和服务中的苹果智能功能。&lt;h4&gt;背景&lt;/h4&gt;苹果公司为了增强其设备和服务中的智能功能，开发了这两种基础语言模型。&lt;h4&gt;目的&lt;/h4&gt;开发出能够在苹果设备和服务中提供高质量、高效能的语言处理能力的模型。&lt;h4&gt;方法&lt;/h4&gt;这两种模型分别是一种优化的设备端模型和一种基于新型并行跟踪混合专家PT-MoE变换器的可扩展服务器模型。它们都在大规模多语言和多模态数据集上训练，并通过监督微调和强化学习进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;两种模型在公开基准和人类评估中均达到了或超过了同等规模的开放基线，支持多种额外语言，并能理解图像和执行工具调用。&lt;h4&gt;结论&lt;/h4&gt;这些模型的最新进展基于苹果公司负责任的AI方法，包括内容过滤、地域特定评估和隐私保护创新，如私有云计算。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了两种支持苹果智能功能的跨苹果设备和服务的基础语言模型：一是针对苹果硅优化的具有a3B参数的设备端模型，通过如KV缓存共享和2位量化感知训练等架构创新进行优化；二是建立在新型并行跟踪混合专家PT-MoE变换器之上的可扩展服务器模型，该变换器结合了跟踪并行性、混合专家稀疏计算和交错全局-局部注意力，在苹果私有云计算平台上实现了高质量与竞争力成本。两种模型都基于通过负责任网络爬取、许可语料库和高质量合成数据源收集的大规模多语言和多模态数据集进行训练，然后通过新的异步平台上的监督微调和强化学习进一步优化。这些模型支持多种额外语言，同时理解图像和执行工具调用。在公开基准和人类评估中，服务器模型和设备端模型均达到或超过了同等规模的开放基线。以Swift为中心的基础模型框架暴露了引导生成、受限工具调用和LoRA适配器微调功能，允许开发人员通过几行代码将这些功能集成到应用程序中。苹果智能模型的最新进展基于我们的负责任AI方法，包括内容过滤、地域特定评估以及我们通过私有云计算等创新来保护用户隐私的承诺。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce two multilingual, multimodal foundation language models thatpower Apple Intelligence features across Apple devices and services: i a3B-parameter on-device model optimized for Apple silicon through architecturalinnovations such as KV-cache sharing and 2-bit quantization-aware training; andii a scalable server model built on a novel Parallel-Track Mixture-of-ExpertsPT-MoE transformer that combines track parallelism, mixture-of-experts sparsecomputation, and interleaved global-local attention to deliver high qualitywith competitive cost on Apple's Private Cloud Compute platform. Both modelsare trained on large-scale multilingual and multimodal datasets sourced viaresponsible web crawling, licensed corpora, and high-quality synthetic data,then further refined with supervised fine-tuning and reinforcement learning ona new asynchronous platform. The resulting models support several additionallanguages while understanding images and executing tool calls. In publicbenchmarks and human evaluations, both the server model and the on-device modelmatch or surpass comparably sized open baselines.  A new Swift-centric Foundation Models framework exposes guided generation,constrained tool calling, and LoRA adapter fine-tuning, allowing developers tointegrate these capabilities with a few lines of code. The latest advancementsin Apple Intelligence models are grounded in our Responsible AI approach withsafeguards like content filtering and locale-specific evaluation, as well asour commitment to protecting our users' privacy with innovations like PrivateCloud Compute.</description>
      <author>example@mail.com (Hanzhi Zhou, Erik Hornberger, Pengsheng Guo, Xiyou Zhou, Saiwen Wang, Xin Wang, Yifei He, Xuankai Chang, Rene Rauch, Louis D'hauwe, John Peebles, Alec Doane, Kohen Chia, Jenna Thibodeau, Zi-Yi Dou, Yuanyang Zhang, Ruoming Pang, Reed Li, Zhifeng Chen, Jeremy Warner, Zhaoyang Xu, Sophy Lee, David Mizrahi, Ramsey Tantawi, Chris Chaney, Kelsey Peterson, Jun Qin, Alex Dombrowski, Mira Chiang, Aiswarya Raghavan, Gerard Casamayor, Qibin Chen, Aonan Zhang, Nathalie Tran, Jianyu Wang, Hang Su, Thomas Voice, Alessandro Pappalardo, Brycen Wershing, Prasanth Yadla, Rui Li, Priyal Chhatrapati, Ismael Fernandez, Yusuf Goren, Xin Zheng, Forrest Huang, Tao Lei, Eray Yildiz, Alper Kokmen, Gokul Santhanam, Areeba Kamal, Kaan Elgin, Dian Ang Yap, Jeremy Liu, Peter Gray, Howard Xing, Kieran Liu, Matteo Ronchi, Moritz Schwarzer-Becker, Yun Zhu, Mandana Saebi, Jeremy Snow, David Griffiths, Guillaume Tartavel, Erin Feldman, Simon Lehnerer, Fernando Bermúdez-Medina, Hans Han, Joe Zhou, Xiaoyi Ren, Sujeeth Reddy, Zirui Wang, Tom Gunter, Albert Antony, Yuanzhi Li, John Dennison, Tony Sun, Yena Han, Yi Qin, Sam Davarnia, Jeffrey Bigham, Wayne Shan, Hannah Gillis Coleman, Guillaume Klein, Peng Liu, Muyang Yu, Jack Cackler, Yuan Gao, Crystal Xiao, Binazir Karimzadeh, Zhengdong Zhang, Felix Bai, Albin Madappally Jose, Feng Nan, Nazir Kamaldin, Dong Yin, Hans Hao, Yanchao Sun, Yi Hua, Charles Maalouf, Alex Guillen Garcia, Guoli Yin, Lezhi Li, Mohana Prasad Sathya Moorthy, Hongbin Gao, Jay Tang, Joanna Arreaza-Taylor, Faye Lao, Carina Peng, Josh Shaffer, Dan Masi, Sushma Rao, Tommi Vehvilainen, Senyu Tong, Dongcai Shen, Yang Zhao, Chris Bartels, Peter Fu, Qingqing Cao, Christopher Neubauer, Ethan Li, Mingfei Gao, Rebecca Callahan, Richard Wei, Patrick Dong, Alex Braunstein, Sachin Ravi, Adolfo Lopez Mendez, Kaiwei Huang, Kun Duan, Haoshuo Huang, Rui Qian, Stefano Ligas, Jordan Huffaker, Dongxu Li, Bailin Wang, Nanzhu Wang, Anuva Agarwal, Tait Madsen, Josh Newnham, Abhishek Sharma, Zhile Ren, Deepak Gopinath, Erik Daxberger, Saptarshi Guha, Oron Levy, Jing Lu, Nan Dun, Marc Kirchner, Yinfei Yang, Manjot Bilkhu, Dave Nelson, Anthony Spalvieri-Kruse, Juan Lao Tebar, Yang Xu, Phani Mutyala, Gabriel Jacoby-Cooper, Yingbo Wang, Karla Vega, Vishaal Mahtani, Darren Botten, Eric Wang, Hanli Li, Matthias Paulik, Haoran Yan, Navid Shiee, Yihao Qian, Bugu Wu, Qi Zhu, Ob Adaranijo, Bhuwan Dhingra, Zhe Gan, Nicholas Seidl, Grace Duanmu, Rong Situ, Yiping Ma, Yin Xia, David Riazati, Vasileios Saveris, Anh Nguyen, Michael, Lee, Patrick Sonnenberg, Chinguun Erdenebileg, Yanghao Li, Vivian Ma, James Chou, Isha Garg, Mark Lee, Keen You, Yuhong Li, Ransen Niu, Nandhitha Raghuram, Pulkit Agrawal, Henry Mason, Sumeet Singh, Keyu He, Hong-You Chen, Lucas Guibert, Shiyu Li, Varsha Paidi, Narendran Raghavan, Mingze Xu, Yuli Yang, Sergiu Sima, Irina Belousova, Sprite Chu, Afshin Dehghan, Philipp Dufter, David Haldimann, Zhen Yang, Margit Bowler, Chang Liu, Ying-Chang Cheng, Vivek Rathod, Syd Evans, Wilson Tsao, Dustin Withers, Haitian Sun, Biyao Wang, Peter Grasch, Walker Cheng, Yihao Feng, Vivek Kumar, Frank Chu, Victoria MönchJuan Haladjian, Doug Kang, Jiarui Lu, Ciro Sannino, Max Lam, Floris Weers, Bowen Pan, Kenneth Jung, Dhaval Doshi, Fangping Shi, Olli Saarikivi, Alp Aygar, Josh Elman, Cheng Leong, Eshan Verma, Matthew Lei, Jeff Nichols, Jiulong Shan, Donald Zhang, Lawrence Zhou, Stephen Murphy, Xianzhi Du, Chang Lan, Ankur Jain, Elmira Amirloo, Marcin Eichner, Naomy Sabo, Anupama Mann Anupama, David Qiu, Zhao Meng, Michael FitzMaurice, Peng Zhang, Simon Yeung, Chen Chen, Marco Zuliani, Andrew Hansen, Yang Lu, Brent Ramerth, Ziyi Zhong, Parsa Mazaheri, Matthew Hopkins, Mengyu Li, Simon Wang, David Chen, Farzin Rasteh, Chong Wang, Josh Gardner, Asaf Liberman, Haoxuan You, Andrew Walkingshaw, Xingyu Zhou, Jinhao Lei, Yan Meng, Quentin Keunebroek, Sam Wiseman, Anders Boesen Lindbo Larsen, Yi Zhang, Zaid Ahmed, Haiming Gang, Aaron Franklin, Kelvin Zou, Guillaume Seguin, Jonathan Janke, Rachel Burger, Co Giang, Cheng Shen, Jen Liu, Sanskruti Shah, Xiang Kong, Yiran Fei, TJ Collins, Chen Zhang, Zhiyun Lu, Michael Booker, Qin Ba, Yasutaka Tanaka, Andres Romero Mier Y Teran, Federico Scozzafava, Regan Poston, Jane Li, Eduardo Jimenez, Bas Straathof, Karanjeet Singh, Lindsay Hislop, Rajat Arora, Deepa Seshadri, Boyue Li, Colorado Reed, Zhen Li, TJ Lu, Yi Wang, Kaelen Haag, Nicholas Lusskin, Raunak Sinha, Rahul Nair, Eldon Schoop, Mary Beth Kery, Mehrdad Farajtbar, Brenda Yang, George Horrell, Shiwen Zhao, Dhruti Shah, Cha Chen, Bowen Zhang, Chang Gao, Devi Krishna, Jennifer Mallalieu, Javier Movellan, Di Feng, Emily Zhang, Sam Xu, Junting Pan, Dominik Moritz, Suma Jayaram, Kevin Smith, Dongseong Hwang, Daniel Parilla, Jiaming Hu, You-Cyuan Jhang, Emad Soroush, Fred Hohman, Nan Du, Emma Wang, Sam Dodge, Pragnya Sridhar, Joris Pelemans, Wei Fang, Nina Wenzel, Joseph Yitan Cheng, Hadas Kotek, Chung-Cheng Chiu, Meng Cao, Haijing Fu, Ruixuan Hou, Ke Ye, Diane Zhu, Nikhil Bhendawade, Joseph Astrauskas, Jian Liu, Sai Aitharaju, Wentao Wu, Artsiom Peshko, Hyunjik Kim, Nilesh Shahdadpuri, Andy De Wang, Qi Shan, Piotr Maj, Raul Rea Menacho, Justin Lazarow, Eric Liang Yang, Arsalan Farooq, Donghan Yu, David Güera, Minsik Cho, Kavya Nerella, Yongqiang Wang, Tao Jia, John Park, Jeff Lai, Haotian Zhang, Futang Peng, Daniele Molinari, Aparna Rajamani, Tyler Johnson, Lauren Gardiner, Chao Jia, Violet Yao, Wojciech Kryscinski, Xiujun Li, Shang-Chen Wu)</author>
      <guid isPermaLink="false">2507.13575v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks</title>
      <link>http://arxiv.org/abs/2507.13609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CoTasks的新框架，旨在通过将复杂的视频问题分解为四个实体级别的基础任务，提高视频大语言模型（VideoLLMs）的思考链（CoT）推理能力。&lt;h4&gt;背景&lt;/h4&gt;尽管视频大语言模型（VideoLLMs）近年来取得了进展，但如何让模型具备基于细粒度对象级别视频理解的思考链（CoT）推理能力仍然是关键挑战。现有的指令调整模型，如Qwen和LLaVA系列，通常在高级视频-文本对上进行训练，往往缺乏结构化的注释，这不利于组合性和分步骤推理。&lt;h4&gt;目的&lt;/h4&gt;提出CoTasks框架，旨在提高视频大语言模型的CoT推理能力，并通过分解复杂视频问题，使其能够进行对象中心的空间时间推理。&lt;h4&gt;方法&lt;/h4&gt;CoTasks将现有的复杂视频问题分解为四个实体级别的基础任务：帧定位、实体跟踪、空间和时间关系提取。通过将这些中间的CoT式推理步骤嵌入到输入中，CoTasks使模型能够明确地执行对象中心的空间时间推理。&lt;h4&gt;主要发现&lt;/h4&gt;在NeXT-QA基准上的实验表明，CoTasks显著提高了推理性能：LLaVA-video-7B的平均GPT-4评估分数提高了+3.3分，而Qwen2.5-VL-3B提高了+17.4分，在因果（+14.6）、时间（+10.9）和描述（+48.1）子类别中都有大幅提升。&lt;h4&gt;结论&lt;/h4&gt;CoTasks作为一个结构化的CoT式监督框架，对于提高组合性视频推理是有效的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent progress in video large language models (VideoLLMs), a keyopen challenge remains: how to equip models with chain-of-thought (CoT)reasoning abilities grounded in fine-grained object-level video understanding.Existing instruction-tuned models, such as the Qwen and LLaVA series, aretrained on high-level video-text pairs, often lacking structured annotationsnecessary for compositional, step-by-step reasoning. We propose CoTasks:Chain-of-Thought based Video Instruction Tuning Tasks, a new framework thatdecomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)into four entity-level foundational tasks: frame localization, entity tracking,spatial and temporal relation extraction. By embedding these intermediateCoT-style reasoning steps into the input, CoTasks enables models to explicitlyperform object-centric spatiotemporal reasoning. Experiments on the NeXT-QAbenchmark show that CoTasks significantly enhance inference performance:LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, andQwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal(+10.9), and descriptive (+48.1) subcategories. These results demonstrate theeffectiveness of CoTasks as a structured CoT-style supervision framework forimproving compositional video reasoning.</description>
      <author>example@mail.com (Yanan Wang, Julio Vizcarra, Zhi Li, Hao Niu, Mori Kurokawa)</author>
      <guid isPermaLink="false">2507.13609v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Binarizing Physics-Inspired GNNs for Combinatorial Optimization</title>
      <link>http://arxiv.org/abs/2507.13703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the 28th European Conference on Artificial Intelligence  (ECAI 2025). This archival version includes supplementary appendices&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于物理的图神经网络（PI-GNNs）在解决编码特定图结构和损失的组合优化问题中的应用，并分析了其在高密度图结构下的性能表现。&lt;h4&gt;背景&lt;/h4&gt;PI-GNNs作为一种有效的无监督框架，在解决各种组合优化问题中显示出良好的结果。&lt;h4&gt;目的&lt;/h4&gt;研究PI-GNNs在高密度图结构下的性能，并提出改进方法。&lt;h4&gt;方法&lt;/h4&gt;通过分析PI-GNNs的训练动态，提出基于模糊逻辑和二值化神经网络的替代策略。&lt;h4&gt;主要发现&lt;/h4&gt;PI-GNNs在高密度图结构下的性能会显著下降，存在与问题解决方案的二值值之间的差异。&lt;h4&gt;结论&lt;/h4&gt;提出的改进方法能显著提高PI-GNNs在高密度设置下的性能。&lt;h4&gt;翻译&lt;/h4&gt;Physics-inspired graph neural networks (PI-GNNs) have been utilized as an efficient unsupervised framework for relaxing combinatorial optimization problems encoded through a specific graph structure and loss, reflecting dependencies between the problem's variables. While the framework has yielded promising results in various combinatorial problems, we show that the performance of PI-GNNs systematically plummets with an increasing density of the combinatorial problem graphs. Our analysis reveals an interesting phase transition in the PI-GNNs' training dynamics, associated with degenerate solutions for the denser problems, highlighting a discrepancy between the relaxed, real-valued model outputs and the binary-valued problem solutions. To address the discrepancy, we propose principled alternatives to the naive strategy used in PI-GNNs by building on insights from fuzzy logic and binarized neural networks. Our experiments demonstrate that the portfolio of proposed methods significantly improves the performance of PI-GNNs in increasingly dense settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-inspired graph neural networks (PI-GNNs) have been utilized as anefficient unsupervised framework for relaxing combinatorial optimizationproblems encoded through a specific graph structure and loss, reflectingdependencies between the problem's variables. While the framework has yieldedpromising results in various combinatorial problems, we show that theperformance of PI-GNNs systematically plummets with an increasing density ofthe combinatorial problem graphs. Our analysis reveals an interesting phasetransition in the PI-GNNs' training dynamics, associated with degeneratesolutions for the denser problems, highlighting a discrepancy between therelaxed, real-valued model outputs and the binary-valued problem solutions. Toaddress the discrepancy, we propose principled alternatives to the naivestrategy used in PI-GNNs by building on insights from fuzzy logic and binarizedneural networks. Our experiments demonstrate that the portfolio of proposedmethods significantly improves the performance of PI-GNNs in increasingly densesettings.</description>
      <author>example@mail.com (Martin Krutský, Gustav Šír, Vyacheslav Kungurtsev, Georgios Korpas)</author>
      <guid isPermaLink="false">2507.13703v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Adaptation of Pre-trained Foundation Models for Music Structure Analysis</title>
      <link>http://arxiv.org/abs/2507.13572v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to WASPAA 2025. Project Page:  https://sites.google.com/view/temporal-adaptation-for-msa/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对音乐结构分析的时序自适应方法，通过扩展音频窗口和低分辨率适应策略，提高了音乐基础模型的效率。&lt;h4&gt;背景&lt;/h4&gt;音乐结构分析在音乐信息检索中是一个关键任务，但由于音乐形式的复杂性和变化性，这一任务仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提高音乐基础模型在音乐结构分析任务中的效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种时序自适应方法，包括音频窗口扩展和低分辨率适应策略，以实现单次前向传递中全长度歌曲的高效分析。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在Harmonix Set和RWC-Pop数据集上显著提高了边界检测和结构功能预测的准确性，同时保持了可比较的内存使用和推理速度。&lt;h4&gt;结论&lt;/h4&gt;时序自适应方法能够有效提高音乐基础模型在音乐结构分析任务中的性能。&lt;h4&gt;翻译&lt;/h4&gt;Audio-based music structure analysis (MSA) is an essential task in MusicInformation Retrieval that remains challenging due to the complexity and variability of musical form. Recent advances highlight the potential of fine-tuning pre-trained music foundation models for MSA tasks. However, these models are typically trained with high temporal feature resolution and short audio windows, which limits their efficiency and introduces bias when applied to long-form audio. This paper presents a temporal adaptation approach for fine-tuning music foundation models tailored to MSA. Our method enables efficient analysis of full-length songs in a single forward pass by incorporating two key strategies: (1) audio window extension and (2) low-resolution adaptation. Experiments on the Harmonix Set and RWC-Pop datasets show that our method significantly improves both boundary detection and structural function prediction, while maintaining comparable memory usage and inference speed.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-based music structure analysis (MSA) is an essential task in MusicInformation Retrieval that remains challenging due to the complexity andvariability of musical form. Recent advances highlight the potential offine-tuning pre-trained music foundation models for MSA tasks. However, thesemodels are typically trained with high temporal feature resolution and shortaudio windows, which limits their efficiency and introduces bias when appliedto long-form audio. This paper presents a temporal adaptation approach forfine-tuning music foundation models tailored to MSA. Our method enablesefficient analysis of full-length songs in a single forward pass byincorporating two key strategies: (1) audio window extension and (2)low-resolution adaptation. Experiments on the Harmonix Set and RWC-Pop datasetsshow that our method significantly improves both boundary detection andstructural function prediction, while maintaining comparable memory usage andinference speed.</description>
      <author>example@mail.com (Yixiao Zhang, Haonan Chen, Ju-Chiang Wang, Jitong Chen)</author>
      <guid isPermaLink="false">2507.13572v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network Surrogates for Contacting Deformable Bodies with Necessary and Sufficient Contact Detection</title>
      <link>http://arxiv.org/abs/2507.13459v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的架构，用于快速推断非线性边界值问题，并应用于机械工程领域。该方法特别适用于涉及可变形体接触的复杂几何形状问题，并首次将适用于软体可变形体接触的充分条件纳入其中。&lt;h4&gt;背景&lt;/h4&gt;现有的代理模型在处理可变形体接触，尤其是几何形状变化时，效果不佳。现有方法通常局限于刚体接触或刚体与软体物体的接触，且使用的接触或碰撞检测过滤器仅满足必要条件而非充分条件。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效模拟可变形体接触，特别是在几何形状变化情况下的代理模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的图神经网络架构，该架构利用连续碰撞检测，并首次将适用于软体可变形体接触的充分条件纳入其中。在两个基准测试中验证了其性能，包括预测生物瓣膜的闭合状态。&lt;h4&gt;主要发现&lt;/h4&gt;增加额外的接触项到损失函数中，对网络产生了正则化效果，提高了网络的泛化能力。这种方法适用于简单接触和复杂接触，并且能够处理变化的参考几何形状。然而，这种方法的训练成本较高，导致了一定的计算成本与性能之间的权衡。&lt;h4&gt;结论&lt;/h4&gt;该图神经网络架构在推断基准问题上实现了高达千倍的速度提升，为非线性边界值问题的快速推断提供了一种有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Surrogate models for the rapid inference of nonlinear boundary value problems in mechanics are helpful in a broad range of engineering applications. However, effective surrogate modeling of applications involving the contact of deformable bodies, especially in the context of varying geometries, is still an open issue. In particular, existing methods are confined to rigid body contact or, at best, contact between rigid and soft objects with well-defined contact planes. Furthermore, they employ contact or collision detection filters that serve as a rapid test but use only the necessary and not sufficient conditions for detection. In this work, we present a graph neural network architecture that utilizes continuous collision detection and, for the first time, incorporates sufficient conditions designed for contact between soft deformable bodies. We test its performance on two benchmarks, including a problem in soft tissue mechanics of predicting the closed state of a bioprosthetic aortic valve. We find a regularizing effect on adding additional contact terms to the loss function, leading to better generalization of the network. These benefits hold for simple contact at similar planes and element normal angles, and complex contact at differing planes and element normal angles. We also demonstrate that the framework can handle varying reference geometries. However, such benefits come with high computational costs during training, resulting in a trade-off that may not always be favorable. We quantify the training cost and the resulting inference speedups on various hardware architectures. Importantly, our graph neural network implementation results in up to a thousand-fold speedup for our benchmark problems at inference.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surrogate models for the rapid inference of nonlinear boundary value problemsin mechanics are helpful in a broad range of engineering applications. However,effective surrogate modeling of applications involving the contact ofdeformable bodies, especially in the context of varying geometries, is still anopen issue. In particular, existing methods are confined to rigid body contactor, at best, contact between rigid and soft objects with well-defined contactplanes. Furthermore, they employ contact or collision detection filters thatserve as a rapid test but use only the necessary and not sufficient conditionsfor detection. In this work, we present a graph neural network architecturethat utilizes continuous collision detection and, for the first time,incorporates sufficient conditions designed for contact between soft deformablebodies. We test its performance on two benchmarks, including a problem in softtissue mechanics of predicting the closed state of a bioprosthetic aorticvalve. We find a regularizing effect on adding additional contact terms to theloss function, leading to better generalization of the network. These benefitshold for simple contact at similar planes and element normal angles, andcomplex contact at differing planes and element normal angles. We alsodemonstrate that the framework can handle varying reference geometries.However, such benefits come with high computational costs during training,resulting in a trade-off that may not always be favorable. We quantify thetraining cost and the resulting inference speedups on various hardwarearchitectures. Importantly, our graph neural network implementation results inup to a thousand-fold speedup for our benchmark problems at inference.</description>
      <author>example@mail.com (Vijay K. Dubey, Collin E. Haese, Osman Gültekin, David Dalton, Manuel K. Rausch, Jan N. Fuhg)</author>
      <guid isPermaLink="false">2507.13459v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling</title>
      <link>http://arxiv.org/abs/2507.13207v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10th Workshop on Advanced Analytics and Learning on Temporal Data  (AALTD), ECML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，时间序列基础模型在预测任务上受到广泛关注，但域外缺失值填充这一关键问题仍被较少研究。本文提出了一种基于隐式神经网络表示（INRs）的方法，旨在填补这一空白。&lt;h4&gt;背景&lt;/h4&gt;时间序列基础模型在特定分布下表现出色，但在分布变化时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出MoTM（时间流模型混合）作为时间序列缺失值填充的基础模型，以提高域内和域外泛化能力。&lt;h4&gt;方法&lt;/h4&gt;MoTM结合了独立于不同时间序列家族训练的INRs基础和适应推断时观察到的上下文的岭回归器。&lt;h4&gt;主要发现&lt;/h4&gt;MoTM在多种缺失值场景（如块状和点状缺失，可变采样率）中表现出鲁棒的域内和域外泛化能力。&lt;h4&gt;结论&lt;/h4&gt;MoTM为适应性基础缺失值填充模型铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent years have witnessed a growing interest for time series foundationmodels, with a strong emphasis on the forecasting task. Yet, the crucial taskof out-of-domain imputation of missing values remains largely underexplored. Wepropose a first step to fill this gap by leveraging implicit neuralrepresentations (INRs). INRs model time series as continuous functions andnaturally handle various missing data scenarios and sampling rates. While theyhave shown strong performance within specific distributions, they struggleunder distribution shifts. To address this, we introduce MoTM (Mixture ofTimeflow Models), a step toward a foundation model for time series imputation.Building on the idea that a new time series is a mixture of previously seenpatterns, MoTM combines a basis of INRs, each trained independently on adistinct family of time series, with a ridge regressor that adapts to theobserved context at inference. We demonstrate robust in-domain andout-of-domain generalization across diverse imputation scenarios (e.g., blockand pointwise missingness, variable sampling rates), paving the way foradaptable foundation imputation models.</description>
      <author>example@mail.com (Etienne Le Naour, Tahar Nabil, Ghislain Agoua)</author>
      <guid isPermaLink="false">2507.13207v2</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity</title>
      <link>http://arxiv.org/abs/2507.13423v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Author Accepted Manuscript version of paper at the AIAA AVIATION  Forum 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种可解释的图神经网络（GNN）框架，用于实时评估近程空中交通管制员（ATCO）的任务需求，以应对日益拥挤的空域中的挑战。&lt;h4&gt;背景&lt;/h4&gt;在日益拥挤的空域中，现有的复杂度指标往往无法捕捉到超出简单飞机计数之外的细微操作驱动因素。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够更准确地预测ATCO任务需求的模型。&lt;h4&gt;方法&lt;/h4&gt;引入了一种基于注意力的模型，通过静态交通场景中的交互来预测即将到来的放行数量和ATCO对飞机发布的指令。通过系统地移除飞机并测量对模型预测的影响，得出了每架飞机的任务需求分数。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在性能上显著优于基于ATCO启发式的方法，并且比现有的基线更可靠地估计场景的复杂性。&lt;h4&gt;结论&lt;/h4&gt;该工具可以将任务需求分配给特定的飞机，为管制员培训和空域重新设计中的应用提供了一种新的分析和理解复杂驱动因素的方法。&lt;h4&gt;翻译&lt;/h4&gt;实时评估近期空中交通管制员（ATCO）的任务需求是一个关键挑战，因为在日益拥挤的空域中，现有的复杂度指标往往无法捕捉到超出简单飞机计数之外的细微操作驱动因素。本研究提出了一种可解释的图神经网络（GNN）框架来解决这个问题。我们的基于注意力的模型通过静态交通场景中的交互来预测即将到来的放行数量和ATCO对飞机发布的指令。关键的是，我们通过系统地移除飞机并测量对模型预测的影响，得出了每架飞机的任务需求分数。我们的框架在性能上显著优于基于ATCO启发式的方法，并且比现有的基线更可靠地估计场景的复杂性。由此产生的工具可以将任务需求分配给特定的飞机，为管制员培训和空域重新设计中的应用提供了一种新的分析和理解复杂驱动因素的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.2514/6.2025-3590&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-time assessment of near-term Air Traffic Controller (ATCO) task demandis a critical challenge in an increasingly crowded airspace, as existingcomplexity metrics often fail to capture nuanced operational drivers beyondsimple aircraft counts. This work introduces an interpretable Graph NeuralNetwork (GNN) framework to address this gap. Our attention-based model predictsthe number of upcoming clearances, the instructions issued to aircraft byATCOs, from interactions within static traffic scenarios. Crucially, we derivean interpretable, per-aircraft task demand score by systematically ablatingaircraft and measuring the impact on the model's predictions. Our frameworksignificantly outperforms an ATCO-inspired heuristic and is a more reliableestimator of scenario complexity than established baselines. The resulting toolcan attribute task demand to specific aircraft, offering a new way to analyseand understand the drivers of complexity for applications in controllertraining and airspace redesign.</description>
      <author>example@mail.com (Edward Henderson, Dewi Gould, Richard Everson, George De Ath, Nick Pepper)</author>
      <guid isPermaLink="false">2507.13423v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction</title>
      <link>http://arxiv.org/abs/2507.13387v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究如何利用大规模二值占用数据来提高3D语义占用预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;精确感知周围环境对于安全自动驾驶至关重要。3D占用预测对于不依赖激光雷达传感器的视觉中心自动驾驶系统尤为重要。然而，3D语义占用预测需要标注的激光雷达点云数据，这使得数据获取成本高昂。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过两种方法——预训练和基于学习的自动标注——探索利用大规模二值占用数据的潜力。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种基于二值占用的新颖框架，该框架将预测过程分解为二值占用模块和语义占用模块，以有效地利用二值占用数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的框架在预训练和自动标注任务中都优于现有方法，突显了其在增强3D语义占用预测方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;通过利用大规模二值占用数据，可以显著提高3D语义占用预测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Accurate perception of the surrounding environment is essential for safe autonomous driving. 3D occupancy prediction, which estimates detailed 3D structures of roads, buildings, and other objects, is particularly important for vision-centric autonomous driving systems that do not rely on LiDAR sensors. However, in 3D semantic occupancy prediction -- where each voxel is assigned a semantic label -- annotated LiDAR point clouds are required, making data acquisition costly. In contrast, large-scale binary occupancy data, which only indicate occupied or free space without semantic labels, can be collected at a lower cost. Despite their availability, the potential of leveraging such data remains unexplored. In this study, we investigate the utilization of large-scale binary occupancy data from two perspectives: (1) pre-training and (2) learning-based auto-labeling. We propose a novel binary occupancy-based framework that decomposes the prediction process into binary and semantic occupancy modules, enabling effective use of binary occupancy data. Our experimental results demonstrate that the proposed framework outperforms existing methods in both pre-training and auto-labeling tasks, highlighting its effectiveness in enhancing 3D semantic occupancy prediction. The code is available at https://github.com/ToyotaInfoTech/b2s-occupancy&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate perception of the surrounding environment is essential for safeautonomous driving. 3D occupancy prediction, which estimates detailed 3Dstructures of roads, buildings, and other objects, is particularly importantfor vision-centric autonomous driving systems that do not rely on LiDARsensors. However, in 3D semantic occupancy prediction -- where each voxel isassigned a semantic label -- annotated LiDAR point clouds are required, makingdata acquisition costly. In contrast, large-scale binary occupancy data, whichonly indicate occupied or free space without semantic labels, can be collectedat a lower cost. Despite their availability, the potential of leveraging suchdata remains unexplored. In this study, we investigate the utilization oflarge-scale binary occupancy data from two perspectives: (1) pre-training and(2) learning-based auto-labeling. We propose a novel binary occupancy-basedframework that decomposes the prediction process into binary and semanticoccupancy modules, enabling effective use of binary occupancy data. Ourexperimental results demonstrate that the proposed framework outperformsexisting methods in both pre-training and auto-labeling tasks, highlighting itseffectiveness in enhancing 3D semantic occupancy prediction. The code isavailable at https://github.com/ToyotaInfoTech/b2s-occupancy</description>
      <author>example@mail.com (Chihiro Noguchi, Takaki Yamamoto)</author>
      <guid isPermaLink="false">2507.13387v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning</title>
      <link>http://arxiv.org/abs/2507.13396v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DyG-RAG是一种新颖的事件中心动态图检索增强生成框架，旨在捕捉和处理无结构文本中嵌入的时间知识，以解决现有图RAG方法在时间推理上的困难。&lt;h4&gt;背景&lt;/h4&gt;现有的图RAG方法在时间推理上存在挑战，因为它们无法模拟现实世界中事件的演变结构和顺序。&lt;h4&gt;目的&lt;/h4&gt;提出DyG-RAG框架，以捕捉和处理时间知识，从而实现更准确和有解释性的时间感知检索。&lt;h4&gt;方法&lt;/h4&gt;DyG-RAG提出动态事件单元（DEUs），它们明确编码语义内容和精确的时间锚点。此外，它通过链接共享实体和时间上接近的DEUs来构建事件图，以捕捉事件之间的时序和因果关系。&lt;h4&gt;主要发现&lt;/h4&gt;DyG-RAG显著提高了三种典型时间推理问题的准确率和召回率，证明了其在时间感知生成方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;DyG-RAG为更忠实于时间感知的生成铺平了道路，并可在https://github.com/RingBDStack/DyG-RAG获取。&lt;h4&gt;翻译&lt;/h4&gt;Graph Retrieval-Augmented Generation has emerged as a powerful paradigm for grounding large language models with external structured knowledge. However, existing Graph RAG methods struggle with temporal reasoning, due to their inability to model the evolving structure and order of real-world events. In this work, we introduce DyG-RAG, a novel event-centric dynamic graph retrieval-augmented generation framework designed to capture and reason over temporal knowledge embedded in unstructured text. To eliminate temporal ambiguity in traditional retrieval units, DyG-RAG proposes Dynamic Event Units (DEUs) that explicitly encode both semantic content and precise temporal anchors, enabling accurate and interpretable time-aware retrieval. To capture temporal and causal dependencies across events, DyG-RAG constructs an event graph by linking DEUs that share entities and occur close in time, supporting efficient and meaningful multi-hop reasoning. To ensure temporally consistent generation, DyG-RAG introduces an event timeline retrieval pipeline that retrieves event sequences via time-aware traversal, and proposes a TimeChain-of-Thought strategy for temporally grounded answer generation. This unified pipeline enables DyG-RAG to retrieve coherent, temporally ordered event sequences and to answer complex, time-sensitive queries that standard RAG systems cannot resolve. Extensive experiments on temporal QA benchmarks demonstrate that DyG-RAG significantly improves the accuracy and recall of three typical types of temporal reasoning questions, paving the way for more faithful and temporal-aware generation. DyG-RAG is available at https://github.com/RingBDStack/DyG-RAG.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Retrieval-Augmented Generation has emerged as a powerful paradigm forgrounding large language models with external structured knowledge. However,existing Graph RAG methods struggle with temporal reasoning, due to theirinability to model the evolving structure and order of real-world events. Inthis work, we introduce DyG-RAG, a novel event-centric dynamic graphretrieval-augmented generation framework designed to capture and reason overtemporal knowledge embedded in unstructured text. To eliminate temporalambiguity in traditional retrieval units, DyG-RAG proposes Dynamic Event Units(DEUs) that explicitly encode both semantic content and precise temporalanchors, enabling accurate and interpretable time-aware retrieval. To capturetemporal and causal dependencies across events, DyG-RAG constructs an eventgraph by linking DEUs that share entities and occur close in time, supportingefficient and meaningful multi-hop reasoning. To ensure temporally consistentgeneration, DyG-RAG introduces an event timeline retrieval pipeline thatretrieves event sequences via time-aware traversal, and proposes a TimeChain-of-Thought strategy for temporally grounded answer generation. Thisunified pipeline enables DyG-RAG to retrieve coherent, temporally ordered eventsequences and to answer complex, time-sensitive queries that standard RAGsystems cannot resolve. Extensive experiments on temporal QA benchmarksdemonstrate that DyG-RAG significantly improves the accuracy and recall ofthree typical types of temporal reasoning questions, paving the way for morefaithful and temporal-aware generation. DyG-RAG is available athttps://github.com/RingBDStack/DyG-RAG.</description>
      <author>example@mail.com (Qingyun Sun, Jiaqi Yuan, Shan He, Xiao Guan, Haonan Yuan, Xingcheng Fu, Jianxin Li, Philip S. Yu)</author>
      <guid isPermaLink="false">2507.13396v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>PARAM-1 BharatGen 2.9B Model</title>
      <link>http://arxiv.org/abs/2507.13390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为PARAM-1的2.9B参数语言模型，该模型专门针对印度语言多样性进行训练，旨在解决LLMs发展中存在的英语中心主义问题。&lt;h4&gt;背景&lt;/h4&gt;LLMs在以英语为中心的数据、架构和优化范式驱动下发展，导致像印度这样的语言多样区域被结构性低估。&lt;h4&gt;目的&lt;/h4&gt;通过开发一个专注于印度多样性的语言模型，以实现语言公平表示，并作为印度应用领域的基础。&lt;h4&gt;方法&lt;/h4&gt;PARAM-1是在包含印度语种（主要是印地语和英语）的双语数据集上从头训练的，数据集侧重于事实丰富的内容。它遵循三个核心原则：25%语料库分配确保印度语言的公平代表、SentencePiece分词器适应印度形态结构以及跨多种评估基准的跨文化一致评价。&lt;h4&gt;主要发现&lt;/h4&gt;PARAM-1通过在预训练阶段嵌入多样性，而不是推迟到后续对齐，为公平的基础建模提供了一个设计优先的蓝图。结果显示，该模型既能胜任通用模型的角色，也能作为针对印度应用的稳健基准。&lt;h4&gt;结论&lt;/h4&gt;PARAM-1在提升印度语言在LLMs中的代表性方面具有重要意义，同时也为开发其他多元文化环境下的语言模型提供了范例。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have emerged as powerful general-purposereasoning systems, yet their development remains dominated by English-centricdata, architectures, and optimization paradigms. This exclusionary designresults in structural under-representation of linguistically diverse regionssuch as India, where over 20 official languages and 100+ dialects coexistalongside phenomena like code-switching and diglossia. We introduce PARAM-1, a2.9B parameter decoder-only, text-only language model trained from scratch withan explicit architectural and linguistic focus on Indian diversity. PARAM-1 istrained on a bilingual dataset consisting of only Hindi and English,constructed with a strong focus on fact-rich, high-quality content. It isguided by three core principles: equitable representation of Indic languagesthrough a 25% corpus allocation; tokenization fairness via a SentencePiecetokenizer adapted to Indian morphological structures; and culturally alignedevaluation benchmarks across IndicQA, code-mixed reasoning, andsocio-linguistic robustness tasks. By embedding diversity at the pretraininglevel-rather than deferring it to post-hoc alignment-PARAM-1 offers adesign-first blueprint for equitable foundation modeling. Our resultsdemonstrate that it serves as both a competent general-purpose model and arobust baseline for India-centric applications.</description>
      <author>example@mail.com (Kundeshwar Pundalik, Piyush Sawarkar, Nihar Sahoo, Abhishek Shinde, Prateek Chanda, Vedant Goswami, Ajay Nagpal, Atul Singh, Viraj Thakur, Vijay Dewane, Aamod Thakur, Bhargav Patel, Smita Gautam, Bhagwan Panditi, Shyam Pawar, Madhav Kotcha, Suraj Racha, Saral Sureka, Pankaj Singh, Rishi Bal, Rohit Saluja, Ganesh Ramakrishnan)</author>
      <guid isPermaLink="false">2507.13390v1</guid>
      <pubDate>Mon, 21 Jul 2025 14:24:58 +0800</pubDate>
    </item>
    <item>
      <title>MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling</title>
      <link>http://arxiv.org/abs/2507.13207v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10th Workshop on Advanced Analytics and Learning on Temporal Data  (AALTD), ECML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，时间序列基础模型在预测任务方面受到越来越多的关注，但域外缺失值填充这一关键任务却很少被探索。本文提出了一种利用隐式神经网络表示（INRs）的方法来填补这一空白，并介绍了一种名为MoTM（时间流模型混合）的模型，用于时间序列的填充。MoTM结合了基于INRs的基和能够适应推断时观察到的上下文的岭回归器，展示了在多种填充场景中的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;时间序列基础模型在预测任务方面受到越来越多的关注，但域外缺失值填充这一关键任务却很少被探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来填补时间序列域外缺失值填充的空白，并展示其在多种场景中的有效性。&lt;h4&gt;方法&lt;/h4&gt;利用隐式神经网络表示（INRs）模型时间序列，结合INRs的基和岭回归器构建MoTM模型，用于时间序列的填充。&lt;h4&gt;主要发现&lt;/h4&gt;MoTM模型在多种填充场景（如块缺失、点缺失、可变采样率）中展示了鲁棒的域内和域外泛化能力。&lt;h4&gt;结论&lt;/h4&gt;MoTM是一种适用于时间序列填充的适应性强的基础模型。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, there has been an increasing interest in time series foundation models, with a strong emphasis on the forecasting task. However, the crucial task of out-of-domain imputation of missing values remains largely underexplored. We propose a first step to fill this gap by leveraging implicit neural representations (INRs). INRs model time series as continuous functions and naturally handle various missing data scenarios and sampling rates. While they have shown strong performance within specific distributions, they struggle under distribution shifts. To address this, we introduce MoTM (Mixture of Timeflow Models), a step toward a foundation model for time series imputation. Building on the idea that a new time series is a mixture of previously seen patterns, MoTM combines a basis of INRs, each trained independently on a distinct family of time series, with a ridge regressor that adapts to the observed context at inference. We demonstrate robust in-domain and out-of-domain generalization across diverse imputation scenarios (e.g., block and pointwise missingness, variable sampling rates), paving the way for adaptable foundation imputation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent years have witnessed a growing interest for time series foundationmodels, with a strong emphasis on the forecasting task. Yet, the crucial taskof out-of-domain imputation of missing values remains largely underexplored. Wepropose a first step to fill this gap by leveraging implicit neuralrepresentations (INRs). INRs model time series as continuous functions andnaturally handle various missing data scenarios and sampling rates. While theyhave shown strong performance within specific distributions, they struggleunder distribution shifts. To address this, we introduce MoTM (Mixture ofTimeflow Models), a step toward a foundation model for time series imputation.Building on the idea that a new time series is a mixture of previously seenpatterns, MoTM combines a basis of INRs, each trained independently on adistinct family of time series, with a ridge regressor that adapts to theobserved context at inference. We demonstrate robust in-domain andout-of-domain generalization across diverse imputation scenarios (e.g., blockand pointwise missingness, variable sampling rates), paving the way foradaptable foundation imputation models.</description>
      <author>example@mail.com (Etienne Le Naour, Tahar Nabil, Ghislain Agoua)</author>
      <guid isPermaLink="false">2507.13207v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
  <item>
      <title>VideoITG: Multimodal Video Understanding with Instructed Temporal Grounding</title>
      <link>http://arxiv.org/abs/2507.13353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Instructed Temporal Grounding for Videos (VideoITG)的新方法，旨在通过选择具有信息性和相关性的视频帧来提高视频大语言模型（Video-LLMs）的性能。&lt;h4&gt;背景&lt;/h4&gt;目前的方法主要通过减少帧间冗余、使用独立的图像-文本相关性评估模型或利用时间视频定位来解决长视频理解中的复杂场景，但这些方法在处理复杂场景时存在困难。&lt;h4&gt;目的&lt;/h4&gt;旨在通过VideoITG方法显著提高Video-LLMs在视频理解方面的性能。&lt;h4&gt;方法&lt;/h4&gt;VideoITG的核心是VidThinker管道，这是一个自动化的注释框架，模仿了人类注释过程。它首先根据指令生成详细的片段级字幕，然后通过指令引导的推理检索相关视频片段，最后执行细粒度的帧选择以确定最具有信息性的视觉证据。利用VidThinker构建了包含40K视频和500K指令性时间定位注释的VideoITG-40K数据集。然后设计了一个可插入的VideoITG模型，该模型利用Video-LLMs的视觉语言对齐和推理能力，以区分方式进行有效的帧选择。&lt;h4&gt;主要发现&lt;/h4&gt;VideoITG与Video-LLMs结合，在多个多模态视频理解基准测试中实现了持续的性能提升，显示了其在视频理解中的优越性和巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;VideoITG方法在视频理解方面具有显著优势，并展示了其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies have revealed that selecting informative and relevant videoframes can significantly improve the performance of Video Large Language Models(Video-LLMs). Current methods, such as reducing inter-frame redundancy,employing separate models for image-text relevance assessment, or utilizingtemporal video grounding for event localization, substantially adoptunsupervised learning paradigms, whereas they struggle to address the complexscenarios in long video understanding. We propose Instructed Temporal Groundingfor Videos (VideoITG), featuring customized frame sampling aligned with userinstructions. The core of VideoITG is the VidThinker pipeline, an automatedannotation framework that explicitly mimics the human annotation process.First, it generates detailed clip-level captions conditioned on theinstruction; then, it retrieves relevant video segments throughinstruction-guided reasoning; finally, it performs fine-grained frame selectionto pinpoint the most informative visual evidence. Leveraging VidThinker, weconstruct the VideoITG-40K dataset, containing 40K videos and 500K instructedtemporal grounding annotations. We then design a plug-and-play VideoITG model,which takes advantage of visual language alignment and reasoning capabilitiesof Video-LLMs, for effective frame selection in a discriminative manner.Coupled with Video-LLMs, VideoITG achieves consistent performance improvementsacross multiple multimodal video understanding benchmarks, showing itssuperiority and great potentials for video understanding.</description>
      <author>example@mail.com (Shihao Wang, Guo Chen, De-an Huang, Zhiqi Li, Minghan Li, Guilin Li, Jose M. Alvarez, Lei Zhang, Zhiding Yu)</author>
      <guid isPermaLink="false">2507.13353v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Team Modeling through Tempo-Relational Representation Learning</title>
      <link>http://arxiv.org/abs/2507.13305v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TRENN的新颖团队建模方法，旨在解决人工智能和社会科学交叉领域的团队建模难题。&lt;h4&gt;背景&lt;/h4&gt;团队建模在人工智能和社会科学领域是一个基本挑战。社会科学研究强调需要同时建模动态和关系，而实际应用则要求能够同时推断多个团队结构，提供可解释的见解和可操作的推荐来提高团队性能。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法无法满足这些实际需求的问题，本文提出了TRENN，旨在为团队建模提供一个新的解决方案。&lt;h4&gt;方法&lt;/h4&gt;TRENN集成了以下四个部分：(i) 自动时间图提取器，(ii) 时间关系编码器，(iii) 团队结构预测解码器，和(iv) 两个互补的可解释性模块。此外，还提出了MT-TRENN，它通过替换解码器为多任务头部，使模型能够学习共享的社会嵌入并同时预测多个团队结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，TRENN在仅依赖时间或关系信息的模型上显著表现更好。此外，MT-TRENN中集成的可解释性模块提供了可解释的见解和可操作的推荐，以支持团队改进。&lt;h4&gt;结论&lt;/h4&gt;TRENN及其扩展MT-TRENN为团队建模提供了一个强大的基础，特别适用于以人为中心的AI应用，如高风险协作环境中的智能决策支持系统。&lt;h4&gt;翻译&lt;/h4&gt;摘要：团队建模仍然是人工智能和社会科学交叉领域的根本挑战。社会科学研究强调需要联合建模动态和关系，而实际应用要求能够同时推断多个团队结构，提供可解释的见解和可操作的推荐来提高团队性能。然而，现有工作并未满足这些实际需求。为了弥合这一差距，我们提出了TRENN，这是一种新颖的时间关系架构，它集成了：(i) 自动时间图提取器，(ii) 时间关系编码器，(iii) 团队结构预测解码器，和(iv) 两个互补的可解释性模块。TRENN联合捕捉关系和时间团队动态，为MT-TRENN提供了坚实的基础，MT-TRENN通过替换解码器为多任务头部，使模型能够学习共享的社会嵌入并同时预测多个团队结构，包括涌现领导力、领导风格和团队合作成分。实验结果表明，我们的方法在仅依赖时间或关系信息的模型上显著优于。此外，实验评估表明，MT-TRENN中集成的可解释性模块产生了可解释的见解和可操作的建议，以支持团队改进。这些能力使我们的方法特别适用于以人为中心的AI应用，如高风险协作环境中的智能决策支持系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Team modeling remains a fundamental challenge at the intersection ofArtificial Intelligence and the Social Sciences. Social Science researchemphasizes the need to jointly model dynamics and relations, while practicalapplications demand unified models capable of inferring multiple teamconstructs simultaneously, providing interpretable insights and actionablerecommendations to enhance team performance. However, existing works do notmeet these practical demands. To bridge this gap, we present TRENN, a noveltempo-relational architecture that integrates: (i) an automatic temporal graphextractor, (ii) a tempo-relational encoder, (iii) a decoder for team constructprediction, and (iv) two complementary explainability modules. TRENN jointlycaptures relational and temporal team dynamics, providing a solid foundationfor MT-TRENN, which extends TReNN by replacing the decoder with a multi-taskhead, enabling the model to learn shared Social Embeddings and simultaneouslypredict multiple team constructs, including Emergent Leadership, LeadershipStyle, and Teamwork components. Experimental results demonstrate that ourapproach significantly outperforms approaches that rely exclusively on temporalor relational information. Additionally, experimental evaluation has shown thatthe explainability modules integrated in MT-TRENN yield interpretable insightsand actionable suggestions to support team improvement. These capabilities makeour approach particularly well-suited for Human-Centered AI applications, suchas intelligent decision-support systems in high-stakes collaborativeenvironments.</description>
      <author>example@mail.com (Vincenzo Marco De Luca, Giovanna Varni, Andrea Passerini)</author>
      <guid isPermaLink="false">2507.13305v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos</title>
      <link>http://arxiv.org/abs/2507.07393v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 2 figures,&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为KeyRe-ID的视频人物重识别框架，该框架利用关键点进行时空表示学习，包含全局和局部分支。&lt;h4&gt;背景&lt;/h4&gt;针对视频人物重识别问题，提出了一种基于关键点引导的视频人物重识别框架。&lt;h4&gt;目的&lt;/h4&gt;通过利用关键点，增强时空表示学习，以提升人物重识别的性能。&lt;h4&gt;方法&lt;/h4&gt;全局分支通过基于Transformer的时间聚合捕捉整体身份语义；局部分支根据关键点动态分割身体区域，生成细粒度、部分感知的特征。&lt;h4&gt;主要发现&lt;/h4&gt;在MARS和iLIDS-VID基准测试中，该方法实现了最先进的性能，在MARS上达到了91.73%的mAP和97.32%的Rank-1准确率，在iLIDS-VID上达到了96.00%的Rank-1和100.0%的Rank-5准确率。&lt;h4&gt;结论&lt;/h4&gt;该方法的代码将在论文发表后公开在GitHub上。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为KeyRe-ID的关键点引导的视频人物重识别框架，该框架包含全局和局部分支，利用人类关键点进行增强的时空表示学习。全局分支通过基于Transformer的时间聚合捕捉整体身份语义，而局部分支根据关键点动态分割身体区域，生成细粒度、部分感知的特征。在MARS和iLIDS-VID基准测试中，该方法展现了最先进的性能，在MARS上实现了91.73%的mAP和97.32%的Rank-1准确率，在iLIDS-VID上实现了96.00%的Rank-1和100.0%的Rank-5准确率。该工作的代码将在论文发表后公开在GitHub上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose \textbf{KeyRe-ID}, a keypoint-guided video-based personre-identification framework consisting of global and local branches thatleverage human keypoints for enhanced spatiotemporal representation learning.The global branch captures holistic identity semantics throughTransformer-based temporal aggregation, while the local branch dynamicallysegments body regions based on keypoints to generate fine-grained, part-awarefeatures. Extensive experiments on MARS and iLIDS-VID benchmarks demonstratestate-of-the-art performance, achieving 91.73\% mAP and 97.32\% Rank-1 accuracyon MARS, and 96.00\% Rank-1 and 100.0\% Rank-5 accuracy on iLIDS-VID. The codefor this work will be publicly available on GitHub upon publication.</description>
      <author>example@mail.com (Jinseong Kim, Jeonghoon Song, Gyeongseon Baek, Byeongjoon Noh)</author>
      <guid isPermaLink="false">2507.07393v3</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>SGCL: Unifying Self-Supervised and Supervised Learning for Graph Recommendation</title>
      <link>http://arxiv.org/abs/2507.13336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in RecSys 2025. arXiv admin note: substantial text overlap  with arXiv:2404.15954&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SGCL（Supervised Graph Contrastive Learning）的推荐系统框架，旨在解决现有推荐系统中由于不同损失函数导致的梯度方向不一致和训练时间延长的问题。&lt;h4&gt;背景&lt;/h4&gt;推荐系统对于在线平台至关重要，通过利用用户-物品二分图的高阶协同过滤信号，为用户提供个性化的信息推荐。&lt;h4&gt;目的&lt;/h4&gt;提高推荐系统的训练效率和性能。&lt;h4&gt;方法&lt;/h4&gt;SGCL将推荐训练和自监督对比损失训练结合为一个统一的监督对比学习损失，以实现快速训练。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界数据集上的实验表明，SGCL在准确性和效率方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;SGCL是一种有效且高效的推荐系统框架，能够显著提升推荐系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;Recommender systems (RecSys) are essential for online platforms, providing personalized suggestions to users within a vast sea of information. Self-supervised graph learning seeks to harness high-order collaborative filtering signals through unsupervised augmentation on the user-item bipartite graph, primarily leveraging a multi-task learning framework that includes both supervised recommendation loss and self-supervised contrastive loss. However, this separate design introduces additional graph convolution processes and creates inconsistencies in gradient directions due to disparate losses, resulting in prolonged training times and sub-optimal performance. In this study, we introduce a unified framework of Supervised Graph Contrastive Learning for recommendation (SGCL) to address these issues. SGCL uniquely combines the training of recommendation and unsupervised contrastive losses into a cohesive supervised contrastive learning loss, aligning both tasks within a single optimization direction for exceptionally fast training. Extensive experiments on three real-world datasets show that SGCL outperforms state-of-the-art methods, achieving superior accuracy and efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems (RecSys) are essential for online platforms, providingpersonalized suggestions to users within a vast sea of information.Self-supervised graph learning seeks to harness high-order collaborativefiltering signals through unsupervised augmentation on the user-item bipartitegraph, primarily leveraging a multi-task learning framework that includes bothsupervised recommendation loss and self-supervised contrastive loss. However,this separate design introduces additional graph convolution processes andcreates inconsistencies in gradient directions due to disparate losses,resulting in prolonged training times and sub-optimal performance. In thisstudy, we introduce a unified framework of Supervised Graph ContrastiveLearning for recommendation (SGCL) to address these issues. SGCL uniquelycombines the training of recommendation and unsupervised contrastive lossesinto a cohesive supervised contrastive learning loss, aligning both taskswithin a single optimization direction for exceptionally fast training.Extensive experiments on three real-world datasets show that SGCL outperformsstate-of-the-art methods, achieving superior accuracy and efficiency.</description>
      <author>example@mail.com (Weizhi Zhang, Liangwei Yang, Zihe Song, Henrry Peng Zou, Ke Xu, Yuanjie Zhu, Philip S. Yu)</author>
      <guid isPermaLink="false">2507.13336v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>3DKeyAD: High-Resolution 3D Point Cloud Anomaly Detection via Keypoint-Guided Point Clustering</title>
      <link>http://arxiv.org/abs/2507.13110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于注册的异常检测框架，用于在工业检测中检测高分辨率3D点云中的细微结构异常。&lt;h4&gt;背景&lt;/h4&gt;高分辨率3D点云在工业检测中非常有效，但它们的密集和不规则性质带来了高计算成本、对空间错位敏感以及捕捉局部结构差异困难等挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够精确定位3D异常的异常检测框架。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了多原型对齐和聚类差异分析，首先将测试样本注册到多个正常原型以进行直接结构比较。然后，在点云上执行聚类，并计算测试样本特征与每个聚类内原型之间的相似度。采用关键点引导策略，选择几何信息丰富的点作为质心，确保聚类中心在特征丰富的区域，从而实现更有意义和稳定的基于距离的比较。&lt;h4&gt;主要发现&lt;/h4&gt;在Real3D-AD基准测试上进行的广泛实验表明，该方法在物体级别和点级别异常检测中均达到了最先进的性能，即使仅使用原始特征。&lt;h4&gt;结论&lt;/h4&gt;该方法在工业检测中有效检测3D点云的细微结构异常，具有较高的准确性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-resolution 3D point clouds are highly effective for detecting subtlestructural anomalies in industrial inspection. However, their dense andirregular nature imposes significant challenges, including high computationalcost, sensitivity to spatial misalignment, and difficulty in capturinglocalized structural differences. This paper introduces a registration-basedanomaly detection framework that combines multi-prototype alignment withcluster-wise discrepancy analysis to enable precise 3D anomaly localization.Specifically, each test sample is first registered to multiple normalprototypes to enable direct structural comparison. To evaluate anomalies at alocal level, clustering is performed over the point cloud, and similarity iscomputed between features from the test sample and the prototypes within eachcluster. Rather than selecting cluster centroids randomly, a keypoint-guidedstrategy is employed, where geometrically informative points are chosen ascentroids. This ensures that clusters are centered on feature-rich regions,enabling more meaningful and stable distance-based comparisons. Extensiveexperiments on the Real3D-AD benchmark demonstrate that the proposed methodachieves state-of-the-art performance in both object-level and point-levelanomaly detection, even using only raw features.</description>
      <author>example@mail.com (Zi Wang, Katsuya Hotta, Koichiro Kamide, Yawen Zou, Chao Zhang, Jun Yu)</author>
      <guid isPermaLink="false">2507.13110v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model</title>
      <link>http://arxiv.org/abs/2507.13145v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures. Accepted for publication in IEEE Robotics and  Automation Letters (RA-L), July 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于DINOv2视觉基础模型的特征视觉里程计系统DINO-VO，该系统通过优化特征匹配和姿态估计，提高了视觉里程计在复杂环境中的鲁棒性、泛化能力和效率。&lt;h4&gt;背景&lt;/h4&gt;现有的基于学习的单目视觉里程计系统面临着鲁棒性、泛化能力和效率的挑战，尽管视觉基础模型如DINOv2在视觉任务中表现出色，但其在视觉里程计中的集成受到粗粒度特征的限制。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效集成DINOv2视觉基础模型到视觉里程计中，提高系统的鲁棒性、泛化能力和效率的视觉里程计系统。&lt;h4&gt;方法&lt;/h4&gt;提出了一种针对DINOv2粗粒度特征的显著关键点检测器，并与细粒度几何特征相结合，以获得更可定位的表示。此外，采用基于Transformer的匹配器和可微的姿态估计层，通过学习良好的匹配来精确估计相机运动。&lt;h4&gt;主要发现&lt;/h4&gt;DINO-VO在挑战性环境中表现出比现有检测器-描述符网络如SuperPoint更高的鲁棒性。与独立的DINOv2粗粒度特征相比，提出的特征描述符在准确性和泛化能力上表现出优势。在TartanAir和KITTI数据集上优于先前的帧间视觉里程计方法，在EuRoC数据集上具有竞争力，同时以72 FPS的帧率和小于1GB的内存使用在单个GPU上高效运行。在户外驾驶场景中，DINO-VO与视觉SLAM系统具有竞争力，展示了其泛化能力。&lt;h4&gt;结论&lt;/h4&gt;DINO-VO通过改进特征匹配和姿态估计，在视觉里程计领域取得了显著的进步，为提高系统的性能提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning-based monocular visual odometry (VO) poses robustness,generalization, and efficiency challenges in robotics. Recent advances invisual foundation models, such as DINOv2, have improved robustness andgeneralization in various vision tasks, yet their integration in VO remainslimited due to coarse feature granularity. In this paper, we present DINO-VO, afeature-based VO system leveraging DINOv2 visual foundation model for itssparse feature matching. To address the integration challenge, we propose asalient keypoints detector tailored to DINOv2's coarse features. Furthermore,we complement DINOv2's robust-semantic features with fine-grained geometricfeatures, resulting in more localizable representations. Finally, atransformer-based matcher and differentiable pose estimation layer enableprecise camera motion estimation by learning good matches. Against priordetector-descriptor networks like SuperPoint, DINO-VO demonstrates greaterrobustness in challenging environments. Furthermore, we show superior accuracyand generalization of the proposed feature descriptors against standaloneDINOv2 coarse features. DINO-VO outperforms prior frame-to-frame VO methods onthe TartanAir and KITTI datasets and is competitive on EuRoC dataset, whilerunning efficiently at 72 FPS with less than 1GB of memory usage on a singleGPU. Moreover, it performs competitively against Visual SLAM systems on outdoordriving scenarios, showcasing its generalization capabilities.</description>
      <author>example@mail.com (Maulana Bisyir Azhari, David Hyunchul Shim)</author>
      <guid isPermaLink="false">2507.13145v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Dual LiDAR-Based Traffic Movement Count Estimation at a Signalized Intersection: Deployment, Data Collection, and Preliminary Analysis</title>
      <link>http://arxiv.org/abs/2507.13073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 Pages, 8 Figures. This paper has been accepted for publication at  the 2025 IEEE ITSC. Copyright IEEE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了利用双激光雷达系统在加利福尼亚州里尔托市交叉路口进行交通流量计数（TMC）的尝试。&lt;h4&gt;背景&lt;/h4&gt;传统的TMC方法，如人工计数、环状检测器、气密道路管道和基于摄像头的识别，在恶劣天气和夜间光照不足的情况下容易产生不准确。&lt;h4&gt;目的&lt;/h4&gt;研究旨在开发、部署和评估一个双激光雷达系统，以提高TMC估计的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用两个激光雷达的3D边界框检测来分类车辆计数，根据交通方向、车辆运动和车辆类别进行。&lt;h4&gt;主要发现&lt;/h4&gt;研究讨论了估计的TMC结果，并提供了观察到的趋势和异常情况的见解。&lt;h4&gt;结论&lt;/h4&gt;提出了可能的改进，这些改进不仅可以提高TMC估计，还可以增强交叉路口的轨迹预测和意图预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic Movement Count (TMC) at intersections is crucial for optimizingsignal timings, assessing the performance of existing traffic control measures,and proposing efficient lane configurations to minimize delays, reducecongestion, and promote safety. Traditionally, methods such as manual counting,loop detectors, pneumatic road tubes, and camera-based recognition have beenused for TMC estimation. Although generally reliable, camera-based TMCestimation is prone to inaccuracies under poor lighting conditions during harshweather and nighttime. In contrast, Light Detection and Ranging (LiDAR)technology is gaining popularity in recent times due to reduced costs and itsexpanding use in 3D object detection, tracking, and related applications. Thispaper presents the authors' endeavor to develop, deploy and evaluate adual-LiDAR system at an intersection in the city of Rialto, California, for TMCestimation. The 3D bounding box detections from the two LiDARs are used toclassify vehicle counts based on traffic directions, vehicle movements, andvehicle classes. This work discusses the estimated TMC results and providesinsights into the observed trends and irregularities. Potential improvementsare also discussed that could enhance not only TMC estimation, but alsotrajectory forecasting and intent prediction at intersections.</description>
      <author>example@mail.com (Saswat Priyadarshi Nayak, Guoyuan Wu, Kanok Boriboonsomsin, Matthew Barth)</author>
      <guid isPermaLink="false">2507.13073v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Spectral Bellman Method: Unifying Representation and Exploration in RL</title>
      <link>http://arxiv.org/abs/2507.13181v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Spectral Bellman Representation的新型框架，旨在提高基于值函数的强化学习中的表示学习效果。&lt;h4&gt;背景&lt;/h4&gt;尽管表示学习在强化学习中已经得到理论和实证的成功，但现有的方法主要从模型学习方面诱导，与强化学习任务的需求不符。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，以解决现有表示学习与强化学习任务不匹配的问题。&lt;h4&gt;方法&lt;/h4&gt;引入Spectral Bellman Representation，基于Inherent Bellman Error条件，直接针对值函数空间的Bellman更新基本结构。&lt;h4&gt;主要发现&lt;/h4&gt;发现了一个基本的谱关系：在零Inherent Bellman Error条件下，通过Bellman算子转换的值函数分布与特征协方差结构本质上相关联。&lt;h4&gt;结论&lt;/h4&gt;该方法通过将特征协方差与Bellman动态对齐，实现了结构化的探索，并在具有挑战性的硬探索和长视野信用分配任务中提高了整体性能。Spectral Bellman Representation为学习更强大和结构合理的表示提供了原则性和有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;The effect of representation has been demonstrated in reinforcement learning,from both theoretical and empirical successes. However, the existingrepresentation learning mainly induced from model learning aspects, misaligningwith our RL tasks. This work introduces Spectral Bellman Representation, anovel framework derived from the Inherent Bellman Error (IBE) condition, whichaligns with the fundamental structure of Bellman updates across a space ofpossible value functions, therefore, directly towards value-based RL. Our keyinsight is the discovery of a fundamental spectral relationship: under thezero-IBE condition, the transformation of a distribution of value functions bythe Bellman operator is intrinsically linked to the feature covariancestructure. This spectral connection yields a new, theoretically-groundedobjective for learning state-action features that inherently capture thisBellman-aligned covariance. Our method requires a simple modification toexisting algorithms. We demonstrate that our learned representations enablestructured exploration, by aligning feature covariance with Bellman dynamics,and improve overall performance, particularly in challenging hard-explorationand long-horizon credit assignment tasks. Our framework naturally extends topowerful multi-step Bellman operators, further broadening its impact. SpectralBellman Representation offers a principled and effective path toward learningmore powerful and structurally sound representations for value-basedreinforcement learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The effect of representation has been demonstrated in reinforcement learning,from both theoretical and empirical successes. However, the existingrepresentation learning mainly induced from model learning aspects, misaligningwith our RL tasks. This work introduces Spectral Bellman Representation, anovel framework derived from the Inherent Bellman Error (IBE) condition, whichaligns with the fundamental structure of Bellman updates across a space ofpossible value functions, therefore, directly towards value-based RL. Our keyinsight is the discovery of a fundamental spectral relationship: under thezero-IBE condition, the transformation of a distribution of value functions bythe Bellman operator is intrinsically linked to the feature covariancestructure. This spectral connection yields a new, theoretically-groundedobjective for learning state-action features that inherently capture thisBellman-aligned covariance. Our method requires a simple modification toexisting algorithms. We demonstrate that our learned representations enablestructured exploration, by aligning feature covariance with Bellman dynamics,and improve overall performance, particularly in challenging hard-explorationand long-horizon credit assignment tasks. Our framework naturally extends topowerful multi-step Bellman operators, further broadening its impact. SpectralBellman Representation offers a principled and effective path toward learningmore powerful and structurally sound representations for value-basedreinforcement learning.</description>
      <author>example@mail.com (Ofir Nabati, Bo Dai, Shie Mannor, Guy Tennenholtz)</author>
      <guid isPermaLink="false">2507.13181v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Complex Wide-Area Scene Understanding with Hierarchical Coresets Selection</title>
      <link>http://arxiv.org/abs/2507.13061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于复杂广泛场景理解的层次核心集选择（HCS）机制，以改进视觉-语言模型（VLMs）的适应性。&lt;h4&gt;背景&lt;/h4&gt;场景理解是计算机视觉的核心任务之一，旨在从图像中提取语义信息以识别物体、场景类别及其相互关系。&lt;h4&gt;目的&lt;/h4&gt;解决现有VLMs在适应未见过的复杂广泛场景时面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;HCS机制通过一个理论上保证的重要性函数逐步细化所选区域，该函数考虑了效用、代表性、鲁棒性和协同作用。&lt;h4&gt;主要发现&lt;/h4&gt;HCS不需要额外的微调，使VLMs能够使用最小可解释区域快速理解未见过的场景，同时缓解了特征密度不足的问题。&lt;h4&gt;结论&lt;/h4&gt;实验表明，HCS在各种任务中实现了优越的性能和通用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：场景理解是计算机视觉的核心任务之一，旨在从图像中提取语义信息以识别物体、场景类别及其相互关系。尽管视觉-语言模型（VLMs）在推动该领域进展方面取得了进展，但现有的VLMs在适应未见过的复杂广泛场景时仍面临挑战。为了解决这些挑战，本文提出了一种层次核心集选择（HCS）机制来推进VLMs在复杂广泛场景理解中的适应性。它基于提出的一个理论上保证的重要性函数，逐步细化所选区域，该函数考虑了效用、代表性、鲁棒性和协同作用。无需额外的微调，HCS使VLMs能够使用最小可解释区域快速理解任何尺度的未见过的场景，同时缓解了特征密度不足的问题。HCS是一种即插即用方法，与任何VLM兼容。实验表明，HCS在各种任务中实现了优越的性能和通用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scene understanding is one of the core tasks in computer vision, aiming toextract semantic information from images to identify objects, scene categories,and their interrelationships. Although advancements in Vision-Language Models(VLMs) have driven progress in this field, existing VLMs still face challengesin adaptation to unseen complex wide-area scenes. To address the challenges,this paper proposes a Hierarchical Coresets Selection (HCS) mechanism toadvance the adaptation of VLMs in complex wide-area scene understanding. Itprogressively refines the selected regions based on the proposed theoreticallyguaranteed importance function, which considers utility, representativeness,robustness, and synergy. Without requiring additional fine-tuning, HCS enablesVLMs to achieve rapid understandings of unseen scenes at any scale usingminimal interpretable regions while mitigating insufficient feature density.HCS is a plug-and-play method that is compatible with any VLM. Experimentsdemonstrate that HCS achieves superior performance and universality in varioustasks.</description>
      <author>example@mail.com (Jingyao Wang, Yiming Chen, Lingyu Si, Changwen Zheng)</author>
      <guid isPermaLink="false">2507.13061v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>A Spectral Interpretation of Redundancy in a Graph Reservoir</title>
      <link>http://arxiv.org/abs/2507.12963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for presentation at the 3rd  International Workshop on Reservoir Computing (RC 2025) at ICANN 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了在多分辨率水库图神经网络（MRGNN）中，通过引入计算机图形学中表面设计领域的Fairing算法，以解决图神经网络训练过程中的过平滑问题。&lt;h4&gt;背景&lt;/h4&gt;水库计算在图上被成功应用作为预处理方法以提升图神经网络（GNNs）的训练效率，但反复应用层运算符于图时会出现过平滑问题，即图信号收敛到图拉普拉斯算子的低频分量。&lt;h4&gt;目的&lt;/h4&gt;重新审视MRGNN中水库的定义，并基于Fairing算法提出一种新方法，以解决过平滑问题，提高图神经网络在任务如图分类中的性能。&lt;h4&gt;方法&lt;/h4&gt;提出的方法利用Fairing算法提供一个带通频谱滤波器，允许平滑而不缩小，并且可以通过拉普拉斯算子适应图设置。通过随机游走视角对算法进行理论分析，特别展示了如何通过调整频谱系数来调节冗余随机游走的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;该方法自然地与GNN架构相结合，对平滑任务（如图分类）有潜在应用价值。实验表明，这种方法有希望，并为未来研究提供了方向。&lt;h4&gt;结论&lt;/h4&gt;该论文通过理论分析和实验验证，提出了一种新的方法来应对图神经网络训练过程中的过平滑问题，为GNN的性能提升提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reservoir computing has been successfully applied to graphs as apreprocessing method to improve the training efficiency of Graph NeuralNetworks (GNNs). However, a common issue that arises when repeatedly applyinglayer operators on graphs is over-smoothing, which consists in the convergenceof graph signals toward low-frequency components of the graph Laplacian. Thiswork revisits the definition of the reservoir in the Multiresolution ReservoirGraph Neural Network (MRGNN), a spectral reservoir model, and proposes avariant based on a Fairing algorithm originally introduced in the field ofsurface design in computer graphics. This algorithm provides a pass-bandspectral filter that allows smoothing without shrinkage, and it can be adaptedto the graph setting through the Laplacian operator. Given its spectralformulation, this method naturally connects to GNN architectures for taskswhere smoothing, when properly controlled, can be beneficial,such as graphclassification. The core contribution of the paper lies in the theoreticalanalysis of the algorithm from a random walks perspective. In particular, itshows how tuning the spectral coefficients can be interpreted as modulating thecontribution of redundant random walks. Exploratory experiments based on theMRGNN architecture illustrate the potential of this approach and suggestpromising directions for future research.</description>
      <author>example@mail.com (Anna Bison, Alessandro Sperduti)</author>
      <guid isPermaLink="false">2507.12963v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Predictability-Aware Motion Prediction for Edge XR via High-Order Error-State Kalman Filtering</title>
      <link>http://arxiv.org/abs/2507.13179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;随着6G网络的发展和定义，XR应用的卸载成为一个新的重要用例。6G的低延迟结合边缘处理基础设施将首次在蜂窝网络中提供一种现实的可卸载场景，其中多个计算密集型功能，包括渲染，可以从用户设备迁移到网络。这样做的一个关键优势是降低用户设备的电池需求，并有可能设计出尺寸更小的设备。&lt;h4&gt;背景&lt;/h4&gt;6G网络的发展及XR应用的卸载需求。&lt;h4&gt;目的&lt;/h4&gt;探讨6G网络中XR应用卸载的可能性及其优势。&lt;h4&gt;方法&lt;/h4&gt;分析6G网络特性，结合边缘处理基础设施，探讨卸载场景。&lt;h4&gt;主要发现&lt;/h4&gt;6G的低延迟和边缘处理基础设施为XR应用卸载提供了现实场景，降低了用户设备电池需求，并可能设计出小型化设备。&lt;h4&gt;结论&lt;/h4&gt;6G网络的特性为XR应用卸载提供了新的可能性，有助于提升用户体验。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As 6G networks are developed and defined, offloading of XR applications isemerging as one of the strong new use cases. The reduced 6G latency coupledwith edge processing infrastructure will for the first time provide a realisticoffloading scenario in cellular networks where several computationallyintensive functions, including rendering, can migrate from the user device andinto the network. A key advantage of doing so is the lowering of the batteryneeds in the user devices and the possibility to design new devices withsmaller form factors.</description>
      <author>example@mail.com (Ziyu Zhong, Hector A Caltenco, Björn Landfeldt, Günter Alce)</author>
      <guid isPermaLink="false">2507.13179v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>A Translation of Probabilistic Event Calculus into Markov Decision Processes</title>
      <link>http://arxiv.org/abs/2507.12989v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了将概率事件演算（PEC）领域转换为马尔可夫决策过程（MDP）的正式翻译方法，以增强PEC在不确定环境中的推理能力。&lt;h4&gt;背景&lt;/h4&gt;PEC是一种用于处理不确定环境中动作及其效果的逻辑框架，适用于表示概率叙述和计算时间投影，但在目标导向推理方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;开发一种将PEC领域转换为MDP的方法，以保留PEC灵活的动作语义，并使MDP的相关算法和理论工具可用于PEC的叙述领域。&lt;h4&gt;方法&lt;/h4&gt;通过引入“动作实施情况”的概念，将PEC域转换为MDP，并开发将学习到的策略映射回可读PEC表示的方法。&lt;h4&gt;主要发现&lt;/h4&gt;转换后的PEC-MDP形式使得MDP的算法和理论工具能够应用于PEC的叙述领域，同时支持时间推理任务和目标驱动规划。&lt;h4&gt;结论&lt;/h4&gt;该方法在保持可解释性的同时扩展了PEC的能力，为处理不确定环境中的动作和效果提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了将概率事件演算（PEC）领域转换为马尔可夫决策过程（MDP）的正式翻译方法，以增强PEC在不确定环境中的推理能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Probabilistic Event Calculus (PEC) is a logical framework for reasoning aboutactions and their effects in uncertain environments, which enables therepresentation of probabilistic narratives and computation of temporalprojections. The PEC formalism offers significant advantages ininterpretability and expressiveness for narrative reasoning. However, it lacksmechanisms for goal-directed reasoning. This paper bridges this gap bydeveloping a formal translation of PEC domains into Markov Decision Processes(MDPs), introducing the concept of "action-taking situations" to preserve PEC'sflexible action semantics. The resulting PEC-MDP formalism enables theextensive collection of algorithms and theoretical tools developed for MDPs tobe applied to PEC's interpretable narrative domains. We demonstrate how thetranslation supports both temporal reasoning tasks and objective-drivenplanning, with methods for mapping learned policies back into human-readablePEC representations, maintaining interpretability while extending PEC'scapabilities.</description>
      <author>example@mail.com (Lyris Xu, Fabio Aurelio D'Asaro, Luke Dickens)</author>
      <guid isPermaLink="false">2507.12989v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals</title>
      <link>http://arxiv.org/abs/2507.13318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的多模态数据集和任务，旨在匹配用户描述与振动触觉信号，并解决了两个主要挑战：数据集标注困难和现有任务及模型的描述能力有限。&lt;h4&gt;背景&lt;/h4&gt;触觉信号在智能手机振动和虚拟现实触觉反馈中能够有效地传达信息并增强现实感，但设计能够与用户产生共鸣的信号具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了促进这一领域的发展，本文提出了HapticCap，这是第一个完全由人类标注的触觉字幕数据集，并基于此数据集提出了触觉字幕检索任务。&lt;h4&gt;方法&lt;/h4&gt;HapticCap包含92,070个触觉-文本对，用于描述振动的感觉、情感和联想属性。基于HapticCap，本文采用监督对比学习框架进行触觉字幕检索任务，结合了特定类别内的文本表示和振动。&lt;h4&gt;主要发现&lt;/h4&gt;语言模型T5和音频模型AST的结合在触觉字幕检索任务中表现最佳，特别是在针对每个描述类别分别训练的情况下。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和数据集为设计触觉信号提供了新的思路，有助于提高触觉信号与现实感的匹配度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Haptic signals, from smartphone vibrations to virtual reality touch feedback,can effectively convey information and enhance realism, but designing signalsthat resonate meaningfully with users is challenging. To facilitate this, weintroduce a multimodal dataset and task, of matching user descriptions tovibration haptic signals, and highlight two primary challenges: (1) lack oflarge haptic vibration datasets annotated with textual descriptions ascollecting haptic descriptions is time-consuming, and (2) limited capability ofexisting tasks and models to describe vibration signals in text. To advancethis area, we create HapticCap, the first fully human-annotatedhaptic-captioned dataset, containing 92,070 haptic-text pairs for userdescriptions of sensory, emotional, and associative attributes of vibrations.Based on HapticCap, we propose the haptic-caption retrieval task and presentthe results of this task from a supervised contrastive learning framework thatbrings together text representations within specific categories and vibrations.Overall, the combination of language model T5 and audio model AST yields thebest performance in the haptic-caption retrieval task, especially whenseparately trained for each description category.</description>
      <author>example@mail.com (Guimin Hu, Daniel Hershcovich, Hasti Seifi)</author>
      <guid isPermaLink="false">2507.13318v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>A Conceptual Framework for Requirements Engineering of Pretrained-Model-Enabled Systems</title>
      <link>http://arxiv.org/abs/2507.13095v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了预训练模型在软件系统中的应用及其带来的挑战，提出了一个针对预训练模型软件系统需求工程的概念框架，并指出了几个有前景的研究方向。&lt;h4&gt;背景&lt;/h4&gt;大型预训练模型在软件系统中的应用日益广泛，其特性如能力边界模糊、行为依赖上下文和持续进化等，对需求工程的传统假设提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;重新思考现有的需求工程方法论，为预训练模型软件系统的需求工程提供指导。&lt;h4&gt;方法&lt;/h4&gt;提出一个概念框架，并概述了框架内的几个研究方向。&lt;h4&gt;主要发现&lt;/h4&gt;预训练模型软件系统的特性如能力边界模糊、行为依赖上下文和持续进化等，对需求工程的传统假设提出了挑战。&lt;h4&gt;结论&lt;/h4&gt;预训练模型的应用对需求工程领域提出了新的挑战，需要重新思考和调整现有的方法论。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in large pretrained models have led to their widespread integration as core components in modern software systems. The trend is expected to continue in the foreseeable future. Unlike traditional software systems governed by deterministic logic, systems powered by pretrained models exhibit distinctive and emergent characteristics, such as ambiguous capability boundaries, context-dependent behavior, and continuous evolution. These properties fundamentally challenge long-standing assumptions in requirements engineering, including functional decomposability and behavioral predictability. This paper investigates this problem and advocates for a rethinking of existing requirements engineering methodologies. We propose a conceptual framework tailored to requirements engineering of pretrained-model-enabled software systems and outline several promising research directions within this framework. This vision helps provide a guide for researchers and practitioners to tackle the emerging challenges in requirements engineering of pretrained-model-enabled systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large pretrained models have led to their widespreadintegration as core components in modern software systems. The trend isexpected to continue in the foreseeable future. Unlike traditional softwaresystems governed by deterministic logic, systems powered by pretrained modelsexhibit distinctive and emergent characteristics, such as ambiguous capabilityboundaries, context-dependent behavior, and continuous evolution. Theseproperties fundamentally challenge long-standing assumptions in requirementsengineering, including functional decomposability and behavioralpredictability. This paper investigates this problem and advocates for arethinking of existing requirements engineering methodologies. We propose aconceptual framework tailored to requirements engineering ofpretrained-model-enabled software systems and outline several promisingresearch directions within this framework. This vision helps provide a guidefor researchers and practitioners to tackle the emerging challenges inrequirements engineering of pretrained-model-enabled systems.</description>
      <author>example@mail.com (Dongming Jin, Zhi Jin, Linyu Li, Xiaohong Chen)</author>
      <guid isPermaLink="false">2507.13095v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Argus: Leveraging Multiview Images for Improved 3-D Scene Understanding With Large Language Models</title>
      <link>http://arxiv.org/abs/2507.12916v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TNNLS2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Argus的3D多模态框架，利用多视图图像增强3D场景理解。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型的发展，LLMs在3D场景理解任务中展现出强大能力，但传统的3D点云重建方法存在信息丢失和细节扭曲的问题。&lt;h4&gt;目的&lt;/h4&gt;设计一个框架，能够利用多视图图像和3D点云，提高LLMs对3D场景的理解能力。&lt;h4&gt;方法&lt;/h4&gt;Argus框架融合多视图图像和相机姿态，形成场景特征，并与3D特征交互，生成全面的3D感知场景嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;Argus能够补偿3D点云重建中的信息丢失，并帮助LLMs更好地理解3D世界。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，Argus在下游任务中优于现有的3D-LMMs。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes an Argus 3D multimodal framework that utilizes multi-view images to enhance 3D scene understanding. With the development of foundation models, LLMs have shown remarkable capabilities in tackling 3D scene understanding tasks. However, traditional 3D point cloud reconstruction methods often suffer from information loss and detail distortion. The goal of this framework is to design a system that can effectively utilize multi-view images and 3D point clouds to improve the understanding ability of LLMs in 3D scenes. The Argus framework fuses multi-view images and camera poses to form scene features, which interact with 3D features to create comprehensive and detailed 3D-aware scene embeddings. This approach compensates for information loss during 3D point cloud reconstruction and helps LLMs better understand the 3D world. Extensive experiments demonstrate that our method outperforms existing 3D-LMMs in various downstream tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TNNLS.2025.3581411&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in foundation models have made it possible to conductapplications in various downstream tasks. Especially, the new era has witnesseda remarkable capability to extend Large Language Models (LLMs) for tacklingtasks of 3D scene understanding. Current methods rely heavily on 3D pointclouds, but the 3D point cloud reconstruction of an indoor scene often resultsin information loss. Some textureless planes or repetitive patterns are proneto omission and manifest as voids within the reconstructed 3D point clouds.Besides, objects with complex structures tend to introduce distortion ofdetails caused by misalignments between the captured images and the densereconstructed point clouds. 2D multi-view images present visual consistencywith 3D point clouds and provide more detailed representations of scenecomponents, which can naturally compensate for these deficiencies. Based onthese insights, we propose Argus, a novel 3D multimodal framework thatleverages multi-view images for enhanced 3D scene understanding with LLMs. Ingeneral, Argus can be treated as a 3D Large Multimodal Foundation Model(3D-LMM) since it takes various modalities as input(text instructions, 2Dmulti-view images, and 3D point clouds) and expands the capability of LLMs totackle 3D tasks. Argus involves fusing and integrating multi-view images andcamera poses into view-as-scene features, which interact with the 3D featuresto create comprehensive and detailed 3D-aware scene embeddings. Our approachcompensates for the information loss while reconstructing 3D point clouds andhelps LLMs better understand the 3D world. Extensive experiments demonstratethat our method outperforms existing 3D-LMMs in various downstream tasks.</description>
      <author>example@mail.com (Yifan Xu, Chao Zhang, Hanqi Jiang, Xiaoyan Wang, Ruifei Ma, Yiwei Li, Zihao Wu, Zeju Li, Xiangde Liu)</author>
      <guid isPermaLink="false">2507.12916v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Unleashing Vision Foundation Models for Coronary Artery Segmentation: Parallel ViT-CNN Encoding and Variational Fusion</title>
      <link>http://arxiv.org/abs/2507.12938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于视觉基础模型（VFMs）的冠状动脉分割框架，通过并行编码架构提高了分割精度。&lt;h4&gt;背景&lt;/h4&gt;准确分割冠状动脉对于计算机辅助诊断冠状动脉疾病（CAD）至关重要，但由于尺寸小、形态复杂、与周围组织对比度低，分割仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一个利用视觉Transformer（ViT）编码器捕获全局结构特征并增强局部细节的方法。&lt;h4&gt;方法&lt;/h4&gt;使用ViT编码器提取全局特征，并集成注意力引导增强（AGE）模块和CNN编码器提取局部细节。采用交叉分支变分融合（CVF）模块融合这些特征，并通过证据理论量化不确定性和使用多尺度特征聚合及注意力机制进行不确定性区域细化。&lt;h4&gt;主要发现&lt;/h4&gt;在内部和两个公共数据集上的广泛评估表明，该框架在准确分割冠状动脉方面显著优于现有方法，并显示出跨多个数据集的强大泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该框架提高了冠状动脉分割的精度，并在多个数据集上展示了优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Accurate coronary artery segmentation is critical for computer-aided diagnosis of coronary artery disease (CAD), yet it remains challenging due to the small size, complex morphology, and low contrast with surrounding tissues. To address these challenges, we propose a novel segmentation framework that leverages the power of vision foundation models (VFMs) through a parallel encoding architecture. Specifically, a vision transformer (ViT) encoder within the VFM captures global structural features, enhanced by the activation of the final two ViT blocks and the integration of an attention-guided enhancement (AGE) module, while a convolutional neural network (CNN) encoder extracts local details. These complementary features are adaptively fused using a cross-branch variational fusion (CVF) module, which models latent distributions and applies variational attention to assign modality-specific weights. Additionally, we introduce an evidential-learning uncertainty refinement (EUR) module, which quantifies uncertainty using evidence theory and refines uncertain regions by incorporating multi-scale feature aggregation and attention mechanisms, further enhancing segmentation accuracy. Extensive evaluations on one in-house and two public datasets demonstrate that the proposed framework significantly outperforms state-of-the-art methods, achieving superior performance in accurate coronary artery segmentation and showcasing strong generalization across multiple datasets. The code is available at https://github.com/d1c2x3/CAseg.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate coronary artery segmentation is critical for computeraided diagnosisof coronary artery disease (CAD), yet it remains challenging due to the smallsize, complex morphology, and low contrast with surrounding tissues. To addressthese challenges, we propose a novel segmentation framework that leverages thepower of vision foundation models (VFMs) through a parallel encodingarchitecture. Specifically, a vision transformer (ViT) encoder within the VFMcaptures global structural features, enhanced by the activation of the finaltwo ViT blocks and the integration of an attention-guided enhancement (AGE)module, while a convolutional neural network (CNN) encoder extracts localdetails. These complementary features are adaptively fused using a cross-branchvariational fusion (CVF) module, which models latent distributions and appliesvariational attention to assign modality-specific weights. Additionally, weintroduce an evidential-learning uncertainty refinement (EUR) module, whichquantifies uncertainty using evidence theory and refines uncertain regions byincorporating multi-scale feature aggregation and attention mechanisms, furtherenhancing segmentation accuracy. Extensive evaluations on one in-house and twopublic datasets demonstrate that the proposed framework significantlyoutperforms state-of-the-art methods, achieving superior performance inaccurate coronary artery segmentation and showcasing strong generalizationacross multiple datasets. The code is available athttps://github.com/d1c2x3/CAseg.</description>
      <author>example@mail.com (Caixia Dong, Duwei Dai, Xinyi Han, Fan Liu, Xu Yang, Zongfang Li, Songhua Xu)</author>
      <guid isPermaLink="false">2507.12938v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning</title>
      <link>http://arxiv.org/abs/2507.12795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对室外大规模场景理解中的局限性，构建了一个名为SVM-City的多领域感知室外场景理解数据集，并提出了City-VLM模型，实现了多模态数据的融合，提高了室外场景理解的能力。&lt;h4&gt;背景&lt;/h4&gt;现有的视觉-语言模型主要针对室内场景理解，在室外大规模场景理解中存在局限性，如环境规模大、多视角和多模态数据融合困难。&lt;h4&gt;目的&lt;/h4&gt;解决现有视觉-语言模型在室外场景理解中的局限性，提高室外场景理解的能力。&lt;h4&gt;方法&lt;/h4&gt;构建了SVM-City数据集，包含多尺度、多视角和多模态的指令数据；提出了City-VLM模型，通过构建联合概率分布空间实现多模态数据融合。&lt;h4&gt;主要发现&lt;/h4&gt;City-VLM在室外场景理解任务中取得了优于现有模型的性能，证明了该方法在多个室外场景中的实用性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和模型有效提高了室外场景理解的能力，为智能代理的环境理解提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper addresses the limitations of existing visual-language models in outdoor large-scale scene understanding, constructs a multi-domain perception outdoor scene understanding dataset named SVM-City, and proposes the City-VLM model to realize the fusion of multi-modal data. The experimental results show that City-VLM achieves better performance than existing models in outdoor scene understanding tasks, demonstrating the practicality and generalization ability of the proposed method across multiple outdoor scenes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scene understanding enables intelligent agents to interpret and comprehendtheir environment. While existing large vision-language models (LVLMs) forscene understanding have primarily focused on indoor household tasks, they facetwo significant limitations when applied to outdoor large-scale sceneunderstanding. First, outdoor scenarios typically encompass larger-scaleenvironments observed through various sensors from multiple viewpoints (e.g.,bird view and terrestrial view), while existing indoor LVLMs mainly analyzesingle visual modalities within building-scale contexts from humanoidviewpoints. Second, existing LVLMs suffer from missing multidomain perceptionoutdoor data and struggle to effectively integrate 2D and 3D visualinformation. To address the aforementioned limitations, we build the firstmultidomain perception outdoor scene understanding dataset, named\textbf{\underline{SVM-City}}, deriving from multi\textbf{\underline{S}}calescenarios with multi\textbf{\underline{V}}iew andmulti\textbf{\underline{M}}odal instruction tuning data. It contains $420$kimages and $4, 811$M point clouds with $567$k question-answering pairs fromvehicles, low-altitude drones, high-altitude aerial planes, and satellite. Toeffectively fuse the multimodal data in the absence of one modality, weintroduce incomplete multimodal learning to model outdoor scene understandingand design the LVLM named \textbf{\underline{City-VLM}}. Multimodal fusion isrealized by constructing a joint probabilistic distribution space rather thanimplementing directly explicit fusion operations (e.g., concatenation).Experimental results on three typical outdoor scene understanding tasks showCity-VLM achieves $18.14 \%$ performance surpassing existing LVLMs inquestion-answering tasks averagely. Our method demonstrates pragmatic andgeneralization performance across multiple outdoor scenes.</description>
      <author>example@mail.com (Penglei Sun, Yaoxian Song, Xiangru Zhu, Xiang Liu, Qiang Wang, Yue Liu, Changqun Xia, Tiefeng Li, Yang Yang, Xiaowen Chu)</author>
      <guid isPermaLink="false">2507.12795v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>SMART: Relation-Aware Learning of Geometric Representations for Knowledge Graphs</title>
      <link>http://arxiv.org/abs/2507.13001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种评估不同几何变换如何适应知识图谱中各个关系的方法，并基于此为每个关系分配最佳匹配的变换或采用多数投票选择一个变换类型应用于所有关系。&lt;h4&gt;背景&lt;/h4&gt;知识图谱嵌入（KGE）模型通常通过几何变换表示知识图谱中的关系，但当前大多数KGE模型仅使用基本的几何变换，且未考虑关系特定的变换。&lt;h4&gt;目的&lt;/h4&gt;提高知识图谱嵌入模型在表示关系时的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种框架，通过注意力机制学习单个关系特定的几何变换，并利用关系与几何变换之间的相关性进行关系嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;通过在三个基准知识图谱和一个真实世界的金融知识图谱上的综合评估，证明了模型的有效性，性能与领先模型相当。&lt;h4&gt;结论&lt;/h4&gt;该模型能够通过学习关系特定的几何变换来提高知识图谱嵌入模型的表现。&lt;h4&gt;翻译&lt;/h4&gt;摘要：知识图谱表示学习方法将知识图谱（KG）中符号知识的三元组形式与它们的特征向量进行映射。知识图谱嵌入（KGE）模型通常将KG中的关系表示为几何变换。大多数最先进的（SOTA）KGE模型是从基本的几何变换（EGTs）中衍生出来的，如平移、缩放、旋转和反射，或它们的组合。这些几何变换使模型能够有效地保留KG的特定结构和关系模式。然而，当前KGE中使用EGTs的方法在未考虑关系特定变换的情况下仍然不足。尽管最近的模型试图通过不同的方式组合SOTA基线模型来解决这个问题，但这样的基线仅使用单一或组合版本的几何变换来表示所有关系。在本文中，我们提出了一种框架，以评估每个关系与不同几何变换的匹配程度。基于这种排名，模型可以：（1）为每个关系分配最佳匹配的变换，或者（2）使用多数投票来选择一个变换类型应用于所有关系。也就是说，模型通过注意力机制在低维向量空间中学习单个关系特定的EGT。此外，我们使用在低维空间中学习到的关系与EGT之间的相关性，在多维向量空间中进行关系嵌入。通过在三个基准KG以及一个真实世界的金融KG上的综合评估，证明了我们模型的有效性，其性能与领先模型相当。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge graph representation learning approaches provide a mapping betweensymbolic knowledge in the form of triples in a knowledge graph (KG) and theirfeature vectors. Knowledge graph embedding (KGE) models often representrelations in a KG as geometric transformations. Most state-of-the-art (SOTA)KGE models are derived from elementary geometric transformations (EGTs), suchas translation, scaling, rotation, and reflection, or their combinations. Thesegeometric transformations enable the models to effectively preserve specificstructural and relational patterns of the KG. However, the current use of EGTsby KGEs remains insufficient without considering relation-specifictransformations. Although recent models attempted to address this problem byensembling SOTA baseline models in different ways, only a single or compositeversion of geometric transformations are used by such baselines to representall the relations. In this paper, we propose a framework that evaluates howwell each relation fits with different geometric transformations. Based on thisranking, the model can: (1) assign the best-matching transformation to eachrelation, or (2) use majority voting to choose one transformation type to applyacross all relations. That is, the model learns a single relation-specific EGTin low dimensional vector space through an attention mechanism. Furthermore, weuse the correlation between relations and EGTs, which are learned in a lowdimension, for relation embeddings in a high dimensional vector space. Theeffectiveness of our models is demonstrated through comprehensive evaluationson three benchmark KGs as well as a real-world financial KG, witnessing aperformance comparable to leading models</description>
      <author>example@mail.com (Kossi Amouzouvi, Bowen Song, Andrea Coletta, Luigi Bellomarini, Jens Lehmann, Sahar Vahdati)</author>
      <guid isPermaLink="false">2507.13001v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Channel Graph Neural Network for Financial Risk Prediction of NEEQ Enterprises</title>
      <link>http://arxiv.org/abs/2507.12787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures. Submitted for conference review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多通道深度学习框架，用于综合预测中小企业在多层次资本市场中的财务风险。&lt;h4&gt;背景&lt;/h4&gt;中国多层次资本市场不断发展，新三板（NEEQ）成为中小企业的重要融资平台，但许多NEEQ上市公司面临财务困境风险。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，研究提出了一个多通道深度学习框架，旨在提高财务风险预测的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个三通道图同构网络（GIN），分别处理数值、文本和基于图的数据输入，并通过注意力机制和门控单元融合这些模态特定的表示。&lt;h4&gt;主要发现&lt;/h4&gt;在7,731家实际NEEQ公司数据上的实验结果表明，该模型在AUC、精确率、召回率和F1分数方面显著优于传统机器学习和单模态基线。&lt;h4&gt;结论&lt;/h4&gt;本研究为中小企业风险建模提供了理论和实践见解，并为金融监管机构和投资者提供了一个数据驱动的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着中国多层次资本市场的持续发展，国家股转系统（NEEQ），也称为“新三板”，已成为中小企业的重要融资平台。然而，由于规模和财务韧性有限，许多NEEQ上市公司面临财务困境的高风险。为了解决这个问题，我们提出了一种多通道深度学习框架，该框架结合了结构化金融指标、文本披露和企业关系数据，以进行全面的财务风险预测。具体来说，我们设计了一个三通道图同构网络（GIN），分别处理数值、文本和基于图的数据输入。这些模态特定的表示通过注意力机制融合，随后使用门控单元以增强鲁棒性和预测精度。在7,731家真实NEEQ公司数据上的实验结果表明，我们的模型在AUC、精确率、召回率和F1分数方面显著优于传统机器学习和单模态基线。这项工作为中小企业风险建模提供了理论和实践见解，并为金融监管机构和投资者提供了一个数据驱动的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the continuous evolution of China's multi-level capital market, theNational Equities Exchange and Quotations (NEEQ), also known as the "New ThirdBoard," has become a critical financing platform for small and medium-sizedenterprises (SMEs). However, due to their limited scale and financialresilience, many NEEQ-listed companies face elevated risks of financialdistress. To address this issue, we propose a multi-channel deep learningframework that integrates structured financial indicators, textual disclosures,and enterprise relationship data for comprehensive financial risk prediction.Specifically, we design a Triple-Channel Graph Isomorphism Network (GIN) thatprocesses numeric, textual, and graph-based inputs separately. Thesemodality-specific representations are fused using an attention-based mechanismfollowed by a gating unit to enhance robustness and prediction accuracy.Experimental results on data from 7,731 real-world NEEQ companies demonstratethat our model significantly outperforms traditional machine learning methodsand single-modality baselines in terms of AUC, Precision, Recall, and F1 Score.This work provides theoretical and practical insights into risk modeling forSMEs and offers a data-driven tool to support financial regulators andinvestors.</description>
      <author>example@mail.com (Jianyu Zhu)</author>
      <guid isPermaLink="false">2507.12787v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>World Model-Based End-to-End Scene Generation for Accident Anticipation in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2507.12762v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种结合生成场景增强和自适应时间推理的综合框架，以解决自动驾驶系统中可靠预测交通事故的挑战。&lt;h4&gt;背景&lt;/h4&gt;交通事故可靠预测对于推进自动驾驶系统至关重要，但受限于高质量训练数据的稀缺和因环境干扰或传感器缺陷导致的对象级线索的频繁缺失。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效处理上述问题的框架，提高交通事故预测的准确性和提前量。&lt;h4&gt;方法&lt;/h4&gt;创建了一个视频生成流程，使用受领域提示引导的世界模型来生成高分辨率、统计一致的驾驶场景，并构建了一个动态预测模型，通过加强图卷积和扩张时间算子编码时空关系。&lt;h4&gt;主要发现&lt;/h4&gt;该框架提高了事故预测的准确性和提前量，并发布了一个新的基准数据集，更好地捕捉现实世界的驾驶风险。&lt;h4&gt;结论&lt;/h4&gt;该框架为自动驾驶应用中的安全和关键数据建模限制提供了一种稳健的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable anticipation of traffic accidents is essential for advancingautonomous driving systems. However, this objective is limited by twofundamental challenges: the scarcity of diverse, high-quality training data andthe frequent absence of crucial object-level cues due to environmentaldisruptions or sensor deficiencies. To tackle these issues, we propose acomprehensive framework combining generative scene augmentation with adaptivetemporal reasoning. Specifically, we develop a video generation pipeline thatutilizes a world model guided by domain-informed prompts to createhigh-resolution, statistically consistent driving scenarios, particularlyenriching the coverage of edge cases and complex interactions. In parallel, weconstruct a dynamic prediction model that encodes spatio-temporal relationshipsthrough strengthened graph convolutions and dilated temporal operators,effectively addressing data incompleteness and transient visual noise.Furthermore, we release a new benchmark dataset designed to better capturediverse real-world driving risks. Extensive experiments on public and newlyreleased datasets confirm that our framework enhances both the accuracy andlead time of accident anticipation, offering a robust solution to current dataand modeling limitations in safety-critical autonomous driving applications.</description>
      <author>example@mail.com (Yanchen Guan, Haicheng Liao, Chengyue Wang, Xingcheng Liu, Jiaxun Zhang, Zhenning Li)</author>
      <guid isPermaLink="false">2507.12762v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Disentangling coincident cell events using deep transfer learning and compressive sensing</title>
      <link>http://arxiv.org/abs/2507.13176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种结合全卷积神经网络（FCN）和压缩感知（CS）的混合框架，用于分析一维传感器数据中的重叠事件，提高单细胞分析的准确性。&lt;h4&gt;背景&lt;/h4&gt;准确的单细胞分析对于诊断、免疫监测和细胞治疗至关重要，但传感器区域中细胞的重叠事件会严重影响信号准确性。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来处理重叠事件，从而提高单细胞分析的准确性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;研究者开发了一种结合FCN和CS的混合框架，该框架在珠子衍生的数据集上训练，并能够泛化到全血中的免疫磁标记CD4+和CD14+细胞，而无需重新训练。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够准确地估计重叠事件的计数，并通过CS模块以高保真度重建单个信号成分，从而精确地恢复单细胞特征，如速度、幅度和流体动力学直径。与传统状态机算法相比，该框架在恢复事件和分类准确性方面表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;该混合框架为下一代非光学单细胞传感平台奠定了基础，这些平台是自动化的、可泛化的，能够解析重叠事件，从而扩大流式细胞术在转化医学和精准诊断中的应用，例如细胞相互作用研究。&lt;h4&gt;翻译&lt;/h4&gt;准确的单细胞分析对诊断、免疫监测和细胞治疗至关重要，但多个细胞在传感器区域重叠的事件会严重影响信号的准确性。我们提出了一种结合全卷积神经网络（FCN）和压缩感知（CS）的混合框架，用于从一维传感器数据中分离这种重叠事件。FCN在珠子衍生的数据集上训练，能够准确估计重叠事件的计数，并无需重新训练即可泛化到全血中的免疫磁标记CD4+和CD14+细胞。利用这个计数，CS模块能够以高保真度重建单个信号成分，从而精确地恢复单细胞特征，包括速度、幅度和流体动力学直径。与传统状态机算法的基准测试表明，该框架在恢复事件和分类准确性方面具有优越性能——恢复的事件数最多可增加21%，分类准确性超过97%。通过类激活图和参数化高斯模板拟合的可解释性确保了透明性和临床可解释性。该框架已通过磁流式细胞术（MFC）进行验证，并与其他波形生成模式兼容，包括阻抗细胞术、纳米孔和电阻脉冲传感。这项工作为下一代非光学单细胞传感平台奠定了基础，这些平台是自动化的、可泛化的，能够解析重叠事件，从而扩大流式细胞术在转化医学和精准诊断中的应用，例如细胞相互作用研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate single-cell analysis is critical for diagnostics, immunomonitoring,and cell therapy, but coincident events - where multiple cells overlap in asensing zone - can severely compromise signal fidelity. We present a hybridframework combining a fully convolutional neural network (FCN) with compressivesensing (CS) to disentangle such overlapping events in one-dimensional sensordata. The FCN, trained on bead-derived datasets, accurately estimatescoincident event counts and generalizes to immunomagnetically labeled CD4+ andCD14+ cells in whole blood without retraining. Using this count, the CS modulereconstructs individual signal components with high fidelity, enabling preciserecovery of single-cell features, including velocity, amplitude, andhydrodynamic diameter. Benchmarking against conventional state-machinealgorithms shows superior performance - recovering up to 21% more events andimproving classification accuracy beyond 97%. Explinability via classactivation maps and parameterized Gaussian template fitting ensurestransparency and clinical interpretability. Demonstrated with magnetic flowcytometry (MFC), the framework is compatible with other waveform-generatingmodalities, including impedance cytometry, nanopore, and resistive pulsesensing. This work lays the foundation for next-generation non-opticalsingle-cell sensing platforms that are automated, generalizable, and capable ofresolving overlapping events, broadening the utility of cytometry intranslational medicine and precision diagnostics, e.g. cell-interactionstudies.</description>
      <author>example@mail.com (Moritz Leuthner, Rafael Vorländer, Oliver Hayden)</author>
      <guid isPermaLink="false">2507.13176v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management</title>
      <link>http://arxiv.org/abs/2507.13275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了自然语言处理和大型语言模型在人力资源管理系统中的应用，特别强调了基于语言技术的智能系统在人才招聘、技能提升和劳动力规划中的重要性。&lt;h4&gt;背景&lt;/h4&gt;随着自然语言处理和大型语言模型的发展，人力资源管理系统正在经历重大变革，对基于语言技术的智能系统产生了浓厚的兴趣。&lt;h4&gt;目的&lt;/h4&gt;为了解决该领域缺乏可靠和公平的模型的问题，提出了TalentCLEF 2025评估活动，旨在评估技能和职位名称智能。&lt;h4&gt;方法&lt;/h4&gt;TalentCLEF包含两个任务：任务A是多语言职位名称匹配，涉及英语、西班牙语、德语和中文；任务B是基于职位名称的技能预测，使用英语。数据来自真实的职位申请，经过匿名化和人工标注，以反映现实劳动力市场数据的复杂性和多样性。&lt;h4&gt;主要发现&lt;/h4&gt;TalentCLEF吸引了76个注册团队，提交了280多个作品。大多数系统依赖于基于多语言编码器模型的对比学习技术，其中一些系统还整合了大型语言模型进行数据增强或重排序。结果显示，训练策略对模型效果的影响大于模型本身的大小。&lt;h4&gt;结论&lt;/h4&gt;TalentCLEF为该领域提供了第一个公开基准，并鼓励开发出稳健、公平且可迁移的语言技术，以适应劳动力市场。&lt;h4&gt;翻译&lt;/h4&gt;The abstract discusses the application of natural language processing and large language models in Human Capital Management, emphasizing the importance of language technology-based smart systems in talent acquisition, upskilling strategies, and workforce planning. It addresses the gap in the development of reliable and fair models in this domain by introducing TalentCLEF 2025, an evaluation campaign focused on skill and job title intelligence. The campaign consists of two tasks, covering multilingual job title matching and job title-based skill prediction. TalentCLEF attracted 76 registered teams with over 280 submissions, highlighting the effectiveness of training strategies over model size alone. The results encourage the development of robust, fair, and transferable language technologies for the labor market.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in natural language processing and large language models are drivinga major transformation in Human Capital Management, with a growing interest inbuilding smart systems based on language technologies for talent acquisition,upskilling strategies, and workforce planning. However, the adoption andprogress of these technologies critically depend on the development of reliableand fair models, properly evaluated on public data and open benchmarks, whichhave so far been unavailable in this domain.  To address this gap, we present TalentCLEF 2025, the first evaluationcampaign focused on skill and job title intelligence. The lab consists of twotasks: Task A - Multilingual Job Title Matching, covering English, Spanish,German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.Both corpora were built from real job applications, carefully anonymized, andmanually annotated to reflect the complexity and diversity of real-world labormarket data, including linguistic variability and gender-marked expressions.  The evaluations included monolingual and cross-lingual scenarios and coveredthe evaluation of gender bias.  TalentCLEF attracted 76 registered teams with more than 280 submissions. Mostsystems relied on information retrieval techniques built with multilingualencoder-based models fine-tuned with contrastive learning, and several of themincorporated large language models for data augmentation or re-ranking. Theresults show that the training strategies have a larger effect than the size ofthe model alone. TalentCLEF provides the first public benchmark in this fieldand encourages the development of robust, fair, and transferable languagetechnologies for the labor market.</description>
      <author>example@mail.com (Luis Gasco, Hermenegildo Fabregat, Laura García-Sardiña, Paula Estrella, Daniel Deniz, Alvaro Rodrigo, Rabih Zbib)</author>
      <guid isPermaLink="false">2507.13275v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts</title>
      <link>http://arxiv.org/abs/2507.13105v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SemCSE的无监督学习方法，用于学习科学文本的语义嵌入。&lt;h4&gt;背景&lt;/h4&gt;基于文本嵌入的对比学习最近取得了进展。&lt;h4&gt;目的&lt;/h4&gt;通过使用LLM生成的摘要来训练模型，确保语义相关的摘要在嵌入空间中更靠近。&lt;h4&gt;方法&lt;/h4&gt;与基于引用的传统方法不同，SemCSE通过一个新基准来评估模型理解和编码科学文本语义内容的能力。&lt;h4&gt;主要发现&lt;/h4&gt;SemCSE在SciRepEval基准测试中取得了最先进的性能，证明了语义专注训练方法的益处。&lt;h4&gt;结论&lt;/h4&gt;SemCSE强制在嵌入空间中实现更强的语义分离，优于其他类似规模的方法。&lt;h4&gt;翻译&lt;/h4&gt;We introduce SemCSE, an unsupervised method for learning semantic embeddings of scientific texts. Building on recent advances in contrastive learning for text embeddings, our approach leverages LLM-generated summaries of scientific abstracts to train a model that positions semantically related summaries closer together in the embedding space. This resulting objective ensures that the model captures the true semantic content of a text, in contrast to traditional citation-based approaches that do not necessarily reflect semantic similarity. To validate this, we propose a novel benchmark designed to assess a model's ability to understand and encode the semantic content of scientific texts, demonstrating that our method enforces a stronger semantic separation within the embedding space. Additionally, we evaluate SemCSE on the comprehensive SciRepEval benchmark for scientific text embeddings, where it achieves state-of-the-art performance among models of its size, thus highlighting the benefits of a semantically focused training approach.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce SemCSE, an unsupervised method for learning semantic embeddingsof scientific texts. Building on recent advances in contrastive learning fortext embeddings, our approach leverages LLM-generated summaries of scientificabstracts to train a model that positions semantically related summaries closertogether in the embedding space. This resulting objective ensures that themodel captures the true semantic content of a text, in contrast to traditionalcitation-based approaches that do not necessarily reflect semantic similarity.To validate this, we propose a novel benchmark designed to assess a model'sability to understand and encode the semantic content of scientific texts,demonstrating that our method enforces a stronger semantic separation withinthe embedding space. Additionally, we evaluate SemCSE on the comprehensiveSciRepEval benchmark for scientific text embeddings, where it achievesstate-of-the-art performance among models of its size, thus highlighting thebenefits of a semantically focused training approach.</description>
      <author>example@mail.com (Marc Brinner, Sina Zarriess)</author>
      <guid isPermaLink="false">2507.13105v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>NeuraLeaf: Neural Parametric Leaf Models with Shape and Deformation Disentanglement</title>
      <link>http://arxiv.org/abs/2507.12714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE/CVF International Conference on Computer Vision (ICCV 2025),  Project: https://neuraleaf-yang.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究开发了一种用于植物建模和重建的3D叶子的神经网络参数模型，该模型对于农业和计算机图形学至关重要。&lt;h4&gt;背景&lt;/h4&gt;虽然神经网络参数模型在人类和动物建模方面得到了积极研究，但植物叶子由于其多样的形状和可变形性，给建模带来了独特的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出了一种名为NeuraLeaf的神经网络参数模型，以解决植物叶子建模的挑战。&lt;h4&gt;方法&lt;/h4&gt;NeuraLeaf通过将叶子的形状分解为二维基本形状和三维变形来建模。利用二维平面近似扁平的叶子形状，并从二维叶子图像数据集中学习基本形状。同时，模型可以学习与几何形状一致的纹理。为了建模三维变形，提出了一种无骨骼的皮肤模型，并创建了一个新的3D叶子数据集DeformLeaf。&lt;h4&gt;主要发现&lt;/h4&gt;NeuraLeaf能够生成各种形状的叶子，并具有变形，能够准确地对3D观察结果如深度图和点云进行建模。&lt;h4&gt;结论&lt;/h4&gt;NeuraLeaf模型和DeformLeaf数据集已公开发布。&lt;h4&gt;翻译&lt;/h4&gt;我们开发了一种用于植物建模和重建的3D叶子的神经网络参数模型，该模型对于农业和计算机图形学至关重要。虽然神经网络参数模型在人类和动物建模方面得到了积极研究，但植物叶子由于其多样的形状和可变形性，给建模带来了独特的挑战。为了解决这一问题，我们引入了一种名为NeuraLeaf的神经网络参数模型。利用扁平叶子形状可以近似为二维平面的事实，NeuraLeaf将叶子的几何形状分解为其二维基本形状和三维变形。这种表示方法允许从丰富的二维叶子图像数据集中学习基本形状，并且具有同时学习与几何形状一致的纹理的优点。为了建模三维变形，我们提出了一种新颖的无骨骼皮肤模型，并创建了一个新的3D叶子数据集称为DeformLeaf。我们发现NeuraLeaf成功地生成了各种形状的叶子，并具有变形，从而实现了对3D观察结果如深度图和点云的准确建模。我们的实现和数据集可在https://neuraleaf-yang.github.io/找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We develop a neural parametric model for 3D leaves for plant modeling andreconstruction that are essential for agriculture and computer graphics. Whileneural parametric models are actively studied for humans and animals, plantleaves present unique challenges due to their diverse shapes and flexibledeformation. To this problem, we introduce a neural parametric model forleaves, NeuraLeaf. Capitalizing on the fact that flattened leaf shapes can beapproximated as a 2D plane, NeuraLeaf disentangles the leaves' geometry intotheir 2D base shapes and 3D deformations. This representation allows learningfrom rich sources of 2D leaf image datasets for the base shapes, and also hasthe advantage of simultaneously learning textures aligned with the geometry. Tomodel the 3D deformation, we propose a novel skeleton-free skinning model andcreate a newly captured 3D leaf dataset called DeformLeaf. We show thatNeuraLeaf successfully generates a wide range of leaf shapes with deformation,resulting in accurate model fitting to 3D observations like depth maps andpoint clouds. Our implementation and dataset are available athttps://neuraleaf-yang.github.io/.</description>
      <author>example@mail.com (Yang Yang, Dongni Mao, Hiroaki Santo, Yasuyuki Matsushita, Fumio Okura)</author>
      <guid isPermaLink="false">2507.12714v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Differential-informed Sample Selection Accelerates Multimodal Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.12998v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DISSect的新方法，用于加速对比学习多模态模型的训练过程，该方法能够有效地识别噪声对应关系。&lt;h4&gt;背景&lt;/h4&gt;基于对比学习的多模态模型在大型数据集上训练时取得了显著的成功，但样本选择作为加速训练的有效途径，目前的方法要么依赖于在线选择，要么依赖于离线选择，都存在一定的局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的样本选择方法，以加速对比学习多模态模型的训练，同时提高对噪声对应关系的处理能力。&lt;h4&gt;方法&lt;/h4&gt;DISSect方法通过分析当前模型和历史模型的预测相关性差异来识别样本质量，并构建了一个基于差异的样本选择框架。&lt;h4&gt;主要发现&lt;/h4&gt;DISSect方法在三个基准数据集和多种下游任务上的实验表明，该方法在性能上优于现有的最佳方法。&lt;h4&gt;结论&lt;/h4&gt;DISSect方法为加速对比学习多模态模型的训练提供了一种有效的解决方案，并通过实验验证了其优越性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Contrastive-learning-based multimodal models have achieved remarkable success due to training on increasingly large datasets with expensive compute consumption. Sample selection as an alternative efficient paradigm plays an important role in accelerating the training process. However, recent advances on sample selection either mostly rely on an oracle model to offline select a high-quality coreset, which is limited in the cold-start scenarios, or focus on online selection based on real-time model predictions, which has not sufficiently or efficiently considered the noisy correspondence. To address this dilemma, we propose a novel Differential-Informed Sample Selection (DISSect) method, which accurately and efficiently discriminates the noisy correspondence for training acceleration. Specifically, we rethink the impact of noisy correspondence on contrastive learning and propose that the difference between the predicted correlation of the current model and that of a historical model is more informative to characterize sample quality. Based on this, we construct a robust differential-based sample selection and analyze its theoretical insights. Extensive experiments on three benchmark datasets and various downstream tasks demonstrate the consistent superiority of DISSect over current state-of-the-art methods. Source code is available at: https://github.com/MediaBrain-SJTU/DISSect.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The remarkable success of contrastive-learning-based multimodal models hasbeen greatly driven by training on ever-larger datasets with expensive computeconsumption. Sample selection as an alternative efficient paradigm plays animportant direction to accelerate the training process. However, recentadvances on sample selection either mostly rely on an oracle model to offlineselect a high-quality coreset, which is limited in the cold-start scenarios, orfocus on online selection based on real-time model predictions, which has notsufficiently or efficiently considered the noisy correspondence. To addressthis dilemma, we propose a novel Differential-Informed Sample Selection(DISSect) method, which accurately and efficiently discriminates the noisycorrespondence for training acceleration. Specifically, we rethink the impactof noisy correspondence on contrastive learning and propose that thedifferential between the predicted correlation of the current model and that ofa historical model is more informative to characterize sample quality. Based onthis, we construct a robust differential-based sample selection and analyze itstheoretical insights. Extensive experiments on three benchmark datasets andvarious downstream tasks demonstrate the consistent superiority of DISSect overcurrent state-of-the-art methods. Source code is available at:https://github.com/MediaBrain-SJTU/DISSect.</description>
      <author>example@mail.com (Zihua Zhao, Feng Hong, Mengxi Chen, Pengyi Chen, Benyuan Liu, Jiangchao Yao, Ya Zhang, Yanfeng Wang)</author>
      <guid isPermaLink="false">2507.12998v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Class-Token Transformer for Multitask Self-supervised Music Information Retrieval</title>
      <link>http://arxiv.org/abs/2507.12996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合对比学习和等变学习的方法，用于音乐信息检索（MIR）中的自监督学习（SSL）。该方法通过同时训练两种预训练任务，提高了音乐信息检索的性能。&lt;h4&gt;背景&lt;/h4&gt;对比学习和等变学习在音频内容分析中的自监督学习中非常有效，但在音乐信息检索中的应用存在困境：对比学习在标签任务（如乐器识别）上更有效，而在结构预测任务（如调性估计）上效果较差；等变学习在特定任务上可以与监督学习方法相媲美，但泛化能力较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的架构，通过同时训练两种预训练任务来提高音乐信息检索的性能。&lt;h4&gt;方法&lt;/h4&gt;采用了一种“两者兼得”的方法，训练一个深度神经网络同时进行两种预训练任务。提出的新架构是具有1-D频谱图补丁的视觉Transformer（ViT-1D），配备两个类别标记，分别针对不同的自监督预训练任务进行优化，但通过同一模型进行优化，因此称为自监督多类别标记多任务（MT2）。一个类别标记优化了五度循环上的交叉功率谱密度（CPSD）以进行等变学习，而另一个类别标记优化了归一化温度缩放交叉熵（NT-Xent）以进行对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;MT2结合了两种预训练任务的优势，在多个任务上均优于仅使用对比学习或等变学习的单类别标记ViT-1D模型。对两个类别标记进行平均进一步提高了在多个任务上的性能，突出了每个类别标记学习到的表示的互补性。此外，使用相同的单线性层探针方法对最后一层的特征进行测试，MT2在所有任务上均优于MERT，除了节拍跟踪；得益于其多任务能力，参数数量减少了18倍。&lt;h4&gt;结论&lt;/h4&gt;我们的SSL基准证明了我们的多类别标记多任务学习方法在音乐信息检索应用中的多功能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning and equivariant learning are effective methods forself-supervised learning (SSL) for audio content analysis. Yet, theirapplication to music information retrieval (MIR) faces a dilemma: the former ismore effective on tagging (e.g., instrument recognition) but less effective onstructured prediction (e.g., tonality estimation); The latter can matchsupervised methods on the specific task it is designed for, but it does notgeneralize well to other tasks. In this article, we adopt a best-of-both-worldsapproach by training a deep neural network on both kinds of pretext tasks atonce. The proposed new architecture is a Vision Transformer with 1-Dspectrogram patches (ViT-1D), equipped with two class tokens, which arespecialized to different self-supervised pretext tasks but optimized throughthe same model: hence the qualification of self-supervised multi-class-tokenmultitask (MT2). The former class token optimizes cross-power spectral density(CPSD) for equivariant learning over the circle of fifths, while the latteroptimizes normalized temperature-scaled cross-entropy (NT-Xent) for contrastivelearning. MT2 combines the strengths of both pretext tasks and outperformsconsistently both single-class-token ViT-1D models trained with eithercontrastive or equivariant learning. Averaging the two class tokens furtherimproves performance on several tasks, highlighting the complementary nature ofthe representations learned by each class token. Furthermore, using the samesingle-linear-layer probing method on the features of last layer, MT2outperforms MERT on all tasks except for beat tracking; achieving this with 18xfewer parameters thanks to its multitasking capabilities. Our SSL benchmarkdemonstrates the versatility of our multi-class-token multitask learningapproach for MIR applications.</description>
      <author>example@mail.com (Yuexuan Kong, Vincent Lostanlen, Romain Hennequin, Mathieu Lagrange, Gabriel Meseguer-Brocal)</author>
      <guid isPermaLink="false">2507.12996v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>ParaStudent: Generating and Evaluating Realistic Student Code by Teaching LLMs to Struggle</title>
      <link>http://arxiv.org/abs/2507.12674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于大型语言模型（LLMs）生成类似学生代码的能力，并提出了一种名为ParaStudent的系统研究方法。&lt;h4&gt;背景&lt;/h4&gt;尽管LLMs在编程任务上表现出色，但它们能否生成像真实学生一样的不完美、迭代和风格多样的代码仍有待研究。&lt;h4&gt;目的&lt;/h4&gt;评估LLMs在生成类似学生代码方面的能力，并设计实验来模拟学生进度并评估代码输出。&lt;h4&gt;方法&lt;/h4&gt;使用多学期时间戳学生提交的数据集，设计低分辨率和高分辨率实验来模拟学生进度，并从语义、功能和风格维度评估代码输出。&lt;h4&gt;主要发现&lt;/h4&gt;微调显著提高了与真实学生轨迹的对齐度，并能更忠实地表征错误模式、渐进改进和风格变化。&lt;h4&gt;结论&lt;/h4&gt;要模拟真实学生代码，需要通过上下文感知生成、时间建模和多维度评估来捕捉学习动态。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型语言模型（LLMs）在编程任务上表现出色，但它们能否生成类似真实学生的代码——不完美、迭代且风格多样？我们提出了一种名为ParaStudent的系统研究方法，用于在入门编程课程环境中研究基于LLMs的“类似学生”代码生成。我们使用多学期时间戳学生提交的数据集，设计了低分辨率和高分辨率实验来模拟学生进度并评估代码输出在语义、功能和风格维度上的表现。我们的结果表明，微调显著提高了与真实学生轨迹的对齐度，并能更忠实地表征错误模式、渐进改进和风格变化。这项研究表明，要模拟真实学生代码，需要通过上下文感知生成、时间建模和多维度评估来捕捉学习动态。实验和评估的代码可在https://github.com/mmiroyan/ParaStudent处获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have shown strong performance on programmingtasks, but can they generate student-like code like real students - imperfect,iterative, and stylistically diverse? We present ParaStudent, a systematicstudy of LLM-based "student-like" code generation in an introductoryprogramming course setting. Using a dataset of timestamped student submissionsacross multiple semesters, we design low- and high-resolution experiments tomodel student progress and evaluate code outputs along semantic, functional,and stylistic dimensions. Our results show that fine-tuning significantlyimproves alignment with real student trajectories and captures error patterns,incremental improvements, and stylistic variations more faithfully. This studyshows that modeling realistic student code requires capturing learning dynamicsthrough context-aware generation, temporal modeling, and multi-dimensionalevaluation. Code for experiments and evaluation is available at\href{https://github.com/mmiroyan/ParaStudent}{\texttt{github.com/mmiroyan/ParaStudent}}.</description>
      <author>example@mail.com (Mihran Miroyan, Rose Niousha, Joseph E. Gonzalez, Gireeja Ranade, Narges Norouzi)</author>
      <guid isPermaLink="false">2507.12674v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Improving Diagnostic Accuracy of Pigmented Skin Lesions With CNNs: an Application on the DermaMNIST Dataset</title>
      <link>http://arxiv.org/abs/2507.12961v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于MedMNIST v2数据集和DermaMNIST数据集，利用ResNet-50和EfficientNetV2L模型进行皮肤病变的多分类分类，通过迁移学习和不同的层配置，发现了一种配置能够达到或超过现有方法的性能，并提出了卷积神经网络在生物医学图像分析中的进步。&lt;h4&gt;背景&lt;/h4&gt;色素性皮肤病变可能指示严重的疾病如黑色素瘤，这是皮肤癌死亡的主要原因。MedMNIST v2数据集是为了推动生物医学图像研究而设计的，其中包含DermaMNIST数据集，用于基于HAM10000数据集对色素性病变进行分类。&lt;h4&gt;目的&lt;/h4&gt;评估ResNet-50和EfficientNetV2L模型在DermaMNIST数据集上进行多分类分类的性能，并探讨迁移学习和不同层配置在其中的作用。&lt;h4&gt;方法&lt;/h4&gt;采用迁移学习技术，对ResNet-50和EfficientNetV2L模型进行多类分类，并尝试了不同的层配置。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，一种特定的层配置能够达到或超过现有方法的结果。&lt;h4&gt;结论&lt;/h4&gt;卷积神经网络在生物医学图像分析中具有推动作用，可以显著提高诊断准确性。&lt;h4&gt;翻译&lt;/h4&gt;Pigmented skin lesions represent localized areas of increased melanin and can indicate serious conditions like melanoma, a major contributor to skin cancer mortality. The MedMNIST v2 dataset, inspired by MNIST, was recently introduced to advance research in biomedical imaging and includes DermaMNIST, a dataset for classifying pigmented lesions based on the HAM10000 dataset. This study assesses ResNet-50 and EfficientNetV2L models for multi-class classification using DermaMNIST, employing transfer learning and various layer configurations. One configuration achieves results that match or surpass existing methods. This study suggests that convolutional neural networks (CNNs) can drive progress in biomedical image analysis, significantly enhancing diagnostic accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pigmented skin lesions represent localized areas of increased melanin and canindicate serious conditions like melanoma, a major contributor to skin cancermortality. The MedMNIST v2 dataset, inspired by MNIST, was recently introducedto advance research in biomedical imaging and includes DermaMNIST, a datasetfor classifying pigmented lesions based on the HAM10000 dataset. This studyassesses ResNet-50 and EfficientNetV2L models for multi-class classificationusing DermaMNIST, employing transfer learning and various layer configurations.One configuration achieves results that match or surpass existing methods. Thisstudy suggests that convolutional neural networks (CNNs) can drive progress inbiomedical image analysis, significantly enhancing diagnostic accuracy.</description>
      <author>example@mail.com (Nerma Kadric, Amila Akagic, Medina Kapo)</author>
      <guid isPermaLink="false">2507.12961v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>A Bayesian Spatio-Temporal Model of Temperature- and Humidity-Related Mortality Using High-Resolution Climate Data</title>
      <link>http://arxiv.org/abs/2507.12643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究介绍了一种新型的贝叶斯时空疾病映射模型的扩展，该模型明确考虑了气象暴露对性别特定效应的影响，并利用奥地利（2002至2019年）的精细尺度周死亡率和高分辨率气候数据，评估了温度、湿度、年龄和性别之间的相互作用如何影响死亡率模式。&lt;h4&gt;背景&lt;/h4&gt;本研究基于贝叶斯时空疾病映射模型，旨在扩展模型以考虑性别特定效应，并利用奥地利的数据进行实证分析。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过分析温度、湿度、年龄和性别之间的相互作用，评估它们对死亡率模式的影响，并为公共卫生监测提供新的见解。&lt;h4&gt;方法&lt;/h4&gt;研究采用了一种超越传统模型的方法，通过在空间-时间、空间-年龄和年龄-时间维度上捕捉结构化相互作用，来捕捉复杂的依赖关系。使用了奥地利（2002至2019年）的精细尺度周死亡率和高分辨率气候数据。&lt;h4&gt;主要发现&lt;/h4&gt;分析确定了地区层面的死亡率模式，并按周量化了与气候相关的风险。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了对死亡率模式的新见解，对公共卫生监测具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;In this study, we introduce a novel and comprehensive extension of a Bayesianspatio-temporal disease mapping model that explicitly accounts forgender-specific effects of meteorological exposures. Leveraging fine-scaleweekly mortality and high-resolution climate data from Austria (2002 to 2019),we assess how interactions between temperature, humidity, age, and genderinfluence mortality patterns. Our approach goes beyond conventional modellingby capturing complex dependencies through structured interactions acrossspace-time, space-age, and age-time dimensions, allowing us to capture complexdemographic and environmental dependencies. The analysis identifiesdistrict-level mortality patterns and quantifies climate-related risks on aweekly basis, offering new insights for public health surveillance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we introduce a novel and comprehensive extension of a Bayesianspatio-temporal disease mapping model that explicitly accounts forgender-specific effects of meteorological exposures. Leveraging fine-scaleweekly mortality and high-resolution climate data from Austria (2002 to 2019),we assess how interactions between temperature, humidity, age, and genderinfluence mortality patterns. Our approach goes beyond conventional modellingby capturing complex dependencies through structured interactions acrossspace-time, space-age, and age-time dimensions, allowing us to capture complexdemographic and environmental dependencies. The analysis identifiesdistrict-level mortality patterns and quantifies climate-related risks on aweekly basis, offering new insights for public health surveillance.</description>
      <author>example@mail.com (Corinna Perchtold, Julia Eisenberg, Philipp Otto)</author>
      <guid isPermaLink="false">2507.12643v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Generalist Bimanual Manipulation via Foundation Video Diffusion Models</title>
      <link>http://arxiv.org/abs/2507.12898v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为VIDAR的框架，用于解决双臂机器人操作中的挑战，该框架通过大规模视频预训练和新型掩码逆动力学模型进行动作预测。&lt;h4&gt;背景&lt;/h4&gt;尽管通用操作取得了进展，但数据稀缺和实体异质性仍然是双臂操作进一步扩展的障碍。&lt;h4&gt;目的&lt;/h4&gt;提出VIDAR框架，以实现可扩展和通用的机器人操作。&lt;h4&gt;方法&lt;/h4&gt;VIDAR采用两阶段框架，第一阶段使用基于扩散的大规模视频预训练，第二阶段使用新型掩码逆动力学模型进行动作预测。该模型在750K多视角视频中预训练，并使用统一的观察空间来编码机器人、相机、任务和场景上下文。&lt;h4&gt;主要发现&lt;/h4&gt;VIDAR在未见的机器人平台上仅使用20分钟的人类演示（仅为典型数据需求的1%）即可泛化到未见过的任务和背景，并具有强大的语义理解能力，超越了现有方法。&lt;h4&gt;结论&lt;/h4&gt;视频基础模型与掩码动作预测的结合，有望在多样化的真实世界场景中实现可扩展和通用的机器人操作。&lt;h4&gt;翻译&lt;/h4&gt;摘要：双臂机器人操作，涉及两个机器人臂的协调控制，是解决挑战性任务的基础。尽管通用操作取得了进展，但数据稀缺和实体异质性仍然是双臂操作进一步扩展的严重障碍。在本文中，我们介绍了用于动作推理的视频扩散（VIDAR），这是一种两阶段框架，它利用基于扩散的大规模视频预训练和用于动作预测的新颖掩码逆动力学模型。我们在750K多视角视频上预训练了视频扩散模型，这些视频来自三个真实世界的双臂机器人平台，使用一个统一的观察空间来编码机器人、相机、任务和场景上下文。我们的掩码逆动力学模型学习掩码，从生成的轨迹中提取与动作相关的信息，而不需要像素级标签，并且这些掩码可以有效地泛化到未见过的背景。我们的实验表明，仅使用20分钟的人演示在未见的机器人平台上（仅为典型数据需求的1%），VIDAR就能泛化到未见过的任务和背景，并具有强大的语义理解能力，超越了现有方法。我们的发现强调了视频基础模型与掩码动作预测相结合的潜力，以实现可扩展和通用的机器人操作在多样化的真实世界场景中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bimanual robotic manipulation, which involves the coordinated control of tworobotic arms, is foundational for solving challenging tasks. Despite recentprogress in general-purpose manipulation, data scarcity and embodimentheterogeneity remain serious obstacles to further scaling up in bimanualsettings. In this paper, we introduce VIdeo Diffusion for Action Reasoning(VIDAR), a two-stage framework that leverages large-scale, diffusion-basedvideo pre-training and a novel masked inverse dynamics model for actionprediction. We pre-train the video diffusion model on 750K multi-view videosfrom three real-world bimanual robot platforms, utilizing a unified observationspace that encodes robot, camera, task, and scene contexts. Our masked inversedynamics model learns masks to extract action-relevant information fromgenerated trajectories without requiring pixel-level labels, and the masks caneffectively generalize to unseen backgrounds. Our experiments demonstrate thatwith only 20 minutes of human demonstrations on an unseen robot platform (only1% of typical data requirements), VIDAR generalizes to unseen tasks andbackgrounds with strong semantic understanding, surpassing state-of-the-artmethods. Our findings highlight the potential of video foundation models,coupled with masked action prediction, to enable scalable and generalizablerobotic manipulation in diverse real-world settings.</description>
      <author>example@mail.com (Yao Feng, Hengkai Tan, Xinyi Mao, Guodong Liu, Shuhe Huang, Chendong Xiang, Hang Su, Jun Zhu)</author>
      <guid isPermaLink="false">2507.12898v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>RGB Pre-Training Enhanced Unobservable Feature Latent Diffusion Model for Spectral Reconstruction</title>
      <link>http://arxiv.org/abs/2507.12967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于不可观测特征的光谱重建方法，通过扩展RGB预训练的潜在扩散模型，有效构建光谱-空间联合分布，以实现从RGB图像到高光谱图像的重建。&lt;h4&gt;背景&lt;/h4&gt;光谱重建是图像处理中的关键问题，需要从对应的RGB图像重建高光谱图像。估计不可观测特征是SR的一个难点，该特征包含由RGB成像传感器未捕捉到的显著光谱信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过学习光谱-空间联合分布来重建高光谱图像，并减少冗余光谱信息。&lt;h4&gt;方法&lt;/h4&gt;本文将RGB预训练的潜在扩散模型（RGB-LDM）扩展为不可观测特征LDM（ULDM）以进行SR。通过两阶段流程实现，第一阶段训练光谱不可观测特征自动编码器（SpeUAE）来提取和压缩不可观测特征；第二阶段，分别通过SpeUAE和空间自动编码器（SpaAE）对光谱和空间结构进行编码。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在SR和下游重光照任务上达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过有效地学习光谱-空间联合分布，提高了光谱重建的性能，为高光谱图像重建提供了一种新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spectral reconstruction (SR) is a crucial problem in image processing thatrequires reconstructing hyperspectral images (HSIs) from the corresponding RGBimages. A key difficulty in SR is estimating the unobservable feature, whichencapsulates significant spectral information not captured by RGB imagingsensors. The solution lies in effectively constructing the spectral-spatialjoint distribution conditioned on the RGB image to complement the unobservablefeature. Since HSIs share a similar spatial structure with the correspondingRGB images, it is rational to capitalize on the rich spatial knowledge in RGBpre-trained models for spectral-spatial joint distribution learning. To thisend, we extend the RGB pre-trained latent diffusion model (RGB-LDM) to anunobservable feature LDM (ULDM) for SR. As the RGB-LDM and its correspondingspatial autoencoder (SpaAE) already excel in spatial knowledge, the ULDM canfocus on modeling spectral structure. Moreover, separating the unobservablefeature from the HSI reduces the redundant spectral information and empowersthe ULDM to learn the joint distribution in a compact latent space.Specifically, we propose a two-stage pipeline consisting of spectral structurerepresentation learning and spectral-spatial joint distribution learning totransform the RGB-LDM into the ULDM. In the first stage, a spectralunobservable feature autoencoder (SpeUAE) is trained to extract and compressthe unobservable feature into a 3D manifold aligned with RGB space. In thesecond stage, the spectral and spatial structures are sequentially encoded bythe SpeUAE and the SpaAE, respectively. The ULDM is then acquired to model thedistribution of the coded unobservable feature with guidance from thecorresponding RGB images. Experimental results on SR and downstream relightingtasks demonstrate that our proposed method achieves state-of-the-artperformance.</description>
      <author>example@mail.com (Keli Deng, Jie Nie, Yuntao Qian)</author>
      <guid isPermaLink="false">2507.12967v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Funnel-HOI: Top-Down Perception for Zero-Shot HOI Detection</title>
      <link>http://arxiv.org/abs/2507.12628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Funnel-HOI的端到端Transformer模型，用于解决人类-物体交互检测（HOID）问题，通过在编码器阶段提前考虑HOI特定线索，提高了场景理解能力。&lt;h4&gt;背景&lt;/h4&gt;由于可能存在指数级的物体-动作组合，标记数据有限，导致长尾分布问题。近期，零样本学习成为解决方案，基于Transformer的物体检测器在HOID中取得成功。&lt;h4&gt;目的&lt;/h4&gt;构建一个能够从图像中定位交互式人类-物体对并识别交互的模型，提高长尾分布问题下的交互检测性能。&lt;h4&gt;方法&lt;/h4&gt;Funnel-HOI框架通过先检测图像中的物体（明确概念），然后检测与物体相关的动作（抽象概念），利用多模态信息和零样本能力，通过不对称共注意力机制在编码器级别生成更强的交互表示。此外，设计了一种新的损失函数，考虑物体-动作的相关性并调节误分类惩罚。&lt;h4&gt;主要发现&lt;/h4&gt;在HICO-DET和V-COCO数据集上的实验表明，Funnel-HOI在监督学习和六种零样本设置下均取得了最先进的性能，对于未见和罕见的HOI类别分别提高了12.4%和8.4%。&lt;h4&gt;结论&lt;/h4&gt;Funnel-HOI通过在编码器阶段考虑HOI特定线索，有效提高了HOID的性能，为长尾分布问题提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类-物体交互检测（HOID）指的是在图像中定位交互的人类-物体对并识别交互。由于可能存在指数级的物体-动作组合，标记数据有限，导致长尾分布问题。最近，零样本学习成为解决方案，基于端到端Transformer的物体检测器在HOID中成为成功的框架。然而，它们的主要焦点是设计改进的解码器来学习纠缠或解纠缠的交互解释。我们主张在编码器阶段本身就必须考虑到HOI特定的线索，以获得更强的场景解释。因此，我们构建了一个名为Funnel-HOI的从上到下的框架，这是受人类倾向于首先掌握明确的概念，然后在场景理解期间将它们与抽象概念相关联的人类倾向的启发。我们首先探测图像中是否存在物体（明确的概念），然后探测与它们相关的动作（抽象概念）。一种新的非对称共注意力机制利用这些线索，利用多模态信息（结合零样本能力），在编码器级别产生更强的交互表示。此外，设计了一种新的损失函数，考虑了物体-动作的相关性，并比现有损失函数更好地调节了误分类惩罚。在HICO-DET和V-COCO数据集上进行的广泛实验，在完全监督和六个零样本设置中，揭示了我们的最先进性能，对于未见和罕见的HOI类别分别提高了12.4%和8.4%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-object interaction detection (HOID) refers to localizing interactivehuman-object pairs in images and identifying the interactions. Since therecould be an exponential number of object-action combinations, labeled data islimited - leading to a long-tail distribution problem. Recently, zero-shotlearning emerged as a solution, with end-to-end transformer-based objectdetectors adapted for HOID becoming successful frameworks. However, theirprimary focus is designing improved decoders for learning entangled ordisentangled interpretations of interactions. We advocate that HOI-specificcues must be anticipated at the encoder stage itself to obtain a stronger sceneinterpretation. Consequently, we build a top-down framework named Funnel-HOIinspired by the human tendency to grasp well-defined concepts first and thenassociate them with abstract concepts during scene understanding. We firstprobe an image for the presence of objects (well-defined concepts) and thenprobe for actions (abstract concepts) associated with them. A novel asymmetricco-attention mechanism mines these cues utilizing multimodal information(incorporating zero-shot capabilities) and yields stronger interactionrepresentations at the encoder level. Furthermore, a novel loss is devised thatconsiders objectaction relatedness and regulates misclassification penaltybetter than existing loss functions for guiding the interaction classifier.Extensive experiments on the HICO-DET and V-COCO datasets acrossfully-supervised and six zero-shot settings reveal our state-of-the-artperformance, with up to 12.4% and 8.4% gains for unseen and rare HOIcategories, respectively.</description>
      <author>example@mail.com (Sandipan Sarma, Agney Talwarr, Arijit Sur)</author>
      <guid isPermaLink="false">2507.12628v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Rel-HNN: Split Parallel Hypergraph Neural Network for Learning on Relational Databases</title>
      <link>http://arxiv.org/abs/2507.12562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于超图的框架rel-HNN，用于处理关系数据库中的数据，以解决深度学习模型在处理关系数据时面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;关系数据库在企业和实际应用中广泛使用，但传统的深度学习模型难以处理固定大小的输入表示来捕捉关系数据的结构化特性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以更好地捕捉关系数据中的语义和结构。&lt;h4&gt;方法&lt;/h4&gt;rel-HNN将每个唯一的属性值对建模为一个节点，将每个元组建模为一个超边，从而捕捉元组内部的细粒度关系。该方法通过学习多级表示来处理属性值、元组和表级别的数据。为了解决大规模关系数据库的扩展性问题，还引入了一种分并行训练算法，利用多GPU执行来提高超图学习的效率。&lt;h4&gt;主要发现&lt;/h4&gt;rel-HNN在分类和回归任务中显著优于现有方法，其分并行训练算法在关系数据学习和超图学习方面实现了显著的加速，学习速度分别提高了3.18倍和2.94倍。&lt;h4&gt;结论&lt;/h4&gt;rel-HNN是一种有效的框架，可以用于处理关系数据库中的数据，并显著提高深度学习模型在处理关系数据时的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：关系数据库（RDBs）在企业和现实世界中无处不在。将数据库扁平化对依赖于固定大小输入表示以从关系数据的结构化性质中捕获关系语义的深度学习模型提出了挑战。图神经网络（GNNs）已被提出以解决此问题，但它们通常通过将所有元组建模为单一节点并忽略元组内部关联来过度简化关系结构。在这项工作中，我们提出了一种新颖的超图框架，我们称之为rel-HNN，它将每个唯一的属性值对建模为一个节点，将每个元组建模为一个超边，从而能够捕捉元组内部的细粒度关系。我们的方法学习跨属性值、元组和表级别的显式多级表示。为了解决由大型RDBs提出的可扩展性挑战，我们进一步引入了一种分并行训练算法，该算法利用多GPU执行以提高超图学习的效率。在真实世界和基准数据集上的大量实验表明，rel-HNN在分类和回归任务中显著优于现有方法。此外，我们的分并行训练实现了实质性的加速——在关系数据学习上达到3.18倍，在超图学习上达到2.94倍，与传统的单GPU执行相比。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Relational databases (RDBs) are ubiquitous in enterprise and real-worldapplications. Flattening the database poses challenges for deep learning modelsthat rely on fixed-size input representations to capture relational semanticsfrom the structured nature of relational data. Graph neural networks (GNNs)have been proposed to address this, but they often oversimplify relationalstructures by modeling all the tuples as monolithic nodes and ignoringintra-tuple associations. In this work, we propose a novel hypergraph-basedframework, that we call rel-HNN, which models each unique attribute-value pairas a node and each tuple as a hyperedge, enabling the capture of fine-grainedintra-tuple relationships. Our approach learns explicit multi-levelrepresentations across attribute-value, tuple, and table levels. To address thescalability challenges posed by large RDBs, we further introduce asplit-parallel training algorithm that leverages multi-GPU execution forefficient hypergraph learning. Extensive experiments on real-world andbenchmark datasets demonstrate that rel-HNN significantly outperforms existingmethods in both classification and regression tasks. Moreover, oursplit-parallel training achieves substantial speedups -- up to 3.18x forlearning on relational data and up to 2.94x for hypergraph learning -- comparedto conventional single-GPU execution.</description>
      <author>example@mail.com (Md. Tanvir Alam, Md. Ahasanul Alam, Md Mahmudur Rahman, Md. Mosaddek Khan)</author>
      <guid isPermaLink="false">2507.12562v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Learning Robust Negation Text Representations</title>
      <link>http://arxiv.org/abs/2507.12782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种提高文本编码器否定鲁棒性的策略，通过使用大语言模型的多样化否定和保留模式的数据进行提取。&lt;h4&gt;背景&lt;/h4&gt;尽管自回归大型语言模型被广泛采用，但较小的文本编码器在需要丰富上下文表示的文本理解任务中仍然发挥着重要作用。否定是一个重要的语义功能，目前尚未被这些方法正确捕捉，这影响了依赖于文本嵌入的许多下游应用。&lt;h4&gt;目的&lt;/h4&gt;提高文本编码器在处理否定内容时的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;采用标准对比学习策略微调基于BERT的强大模型，并使用多样化否定和保留模式的数据从大型语言模型中提取信息。&lt;h4&gt;主要发现&lt;/h4&gt;观察到了在否定理解能力上的显著提升，同时在一般基准测试中保持了有竞争力的性能。此外，该方法还可以应用于大型语言模型，从而在否定基准测试中提高性能。&lt;h4&gt;结论&lt;/h4&gt;提出的策略能够有效提高文本编码器对否定的理解能力，并在实际应用中展现出良好的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite rapid adoption of autoregressive large language models, smaller textencoders still play an important role in text understanding tasks that requirerich contextualized representations. Negation is an important semantic functionthat is still not properly captured by such methods, affecting many downstreamapplications relying on text embeddings. We propose a strategy to improvenegation robustness of text encoders, by distilling data from large languagemodels using diverse patterns of negation and hedging. We adopt a standardcontrastive learning strategy to finetune a strong BERT-based model, andobserve large improvement in negation understanding capabilities whilemaintaining competitive performance on general benchmarks. In addition, we alsoshow that our method can be adapted to LLMs, leading to improved performance onnegation benchmarks.</description>
      <author>example@mail.com (Thinh Hung Truong, Karin Verspoor, Trevor Cohn, Timothy Baldwin)</author>
      <guid isPermaLink="false">2507.12782v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>IDS-Net: A novel framework for few-shot photovoltaic power prediction with interpretable dynamic selection and feature information fusion</title>
      <link>http://arxiv.org/abs/2507.12745v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于特征信息融合的动态选择网络（IDS-Net），用于实现光伏电站的准确少样本预测。&lt;h4&gt;背景&lt;/h4&gt;随着对可再生能源需求的增长，各国正在加快光伏电站的建设。然而，由于数据有限，准确预测新建设光伏电站的电力数据极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种新的方法，以实现光伏电站的准确少样本预测。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法主要包括两个阶段：第一阶段，在大型数据集上预训练，使用最大均值差异（MMD）选择与目标域数据分布最相似的源域数据集，并利用ReliefF算法进行特征选择，减少特征冗余的影响，同时使用Hampel Identifier（HI）进行训练数据集异常值修正。在IDS-Net模型中，首先从一组预测模型中提取初始特征，然后使用两个独立的加权通道确定每个子模型和自适应选择结果的解释性权重。接着，将每个子模型提取的特征与其对应的权重相乘并求和，得到加权提取特征。然后对附加特征进行交叉嵌入，并将其与提取的加权特征融合。融合后的信息通过MLP（多层感知器）层进行预测。第二阶段，设计端到端自适应迁移学习策略，以在目标数据集上获得最终预测结果。&lt;h4&gt;主要发现&lt;/h4&gt;使用河北省的两个光伏电力数据集验证了迁移学习过程，证明了本文框架和迁移学习策略的有效性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的IDS-Net模型能够有效地实现光伏电站的少样本预测，为光伏电站的电力数据预测提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing demand for renewable energy, countries are accelerating theconstruction of photovoltaic (PV) power stations. However, accuratelyforecasting power data for newly constructed PV stations is extremelychallenging due to limited data availability. To this end, we propose a novelinterpretable dynamic selection network (IDS-Net) based on feature informationfusion to achieve accurate few-shot prediction. This transfer learningframework primarily consists of two parts. In the first stage, we pre-train onthe large dataset, utilizing Maximum Mean Discrepancy (MMD) to select thesource domain dataset most similar to the target domain data distribution.Subsequently, the ReliefF algorithm is utilized for feature selection, reducingthe influence of feature redundancy. Then, the Hampel Identifier (HI) is usedfor training dataset outlier correction. In the IDS-Net model, we first obtainthe initial extracted features from a pool of predictive models. Followingthis, two separate weighting channels are utilized to determine theinterpretable weights for each sub-model and the adaptive selection outcomes,respectively. Subsequently, the extracted feature results from each sub-modelare multiplied by their corresponding weights and then summed to obtain theweighted extracted features. Then, we perform cross-embedding on the additionalfeatures and fuse them with the extracted weighted features. This fusedinformation is then passed through the MLP (Multi-Layer Perceptron) layer toobtain predictions. In the second stage, we design an end-to-end adaptivetransfer learning strategy to obtain the final prediction results on the targetdataset. We validate the transfer learning process using two PV power datasetsfrom Hebei province, China, to demonstrate the effectiveness and generalizationof our framework and transfer learning strategy.</description>
      <author>example@mail.com (Hang Fan, Weican Liu, Zuhan Zhang, Ying Lu, Wencai Run, Dunnan Liu)</author>
      <guid isPermaLink="false">2507.12745v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Assessing adaptive world models in machines with novel games</title>
      <link>http://arxiv.org/abs/2507.12821v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了人类智能的快速适应和有效解决问题的能力，将其与构建和优化环境内部表示（世界模型）的机制联系起来，并提出了世界模型诱导这一概念。文章指出，当前人工智能领域对世界模型的理解和评估较为局限，主要关注静态表示，而忽略了模型在新型环境中的学习和探索效率。作者提出了一种新的评估框架，基于精心设计的游戏来评估自适应世界模型，并提出了构建这些游戏的关键要求和评价指标。&lt;h4&gt;背景&lt;/h4&gt;人类智能在陌生环境中的快速适应和有效问题解决能力表现出色。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的评估框架来评估人工智能中的自适应世界模型。&lt;h4&gt;方法&lt;/h4&gt;基于认知科学的研究，设计了一系列具有真实、深度和持续创新性的新游戏，作为评估基准。&lt;h4&gt;主要发现&lt;/h4&gt;现有的世界模型评估方法过于局限，忽略了模型在新型环境中的学习和探索效率。&lt;h4&gt;结论&lt;/h4&gt;新的评估框架将激励未来对世界模型的评估工作，并有助于开发出具有人类类似快速适应和稳健泛化能力的人工智能系统。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类智能在陌生和新型环境中的快速适应和有效问题解决能力令人瞩目。我们认为，这种深刻的适应性本质上与高效构建和优化环境内部表示（通常称为世界模型）的机制密切相关，我们将这种适应性机制称为世界模型诱导。然而，当前对人工智能（AI）中世界模型的理解和评估仍然很狭窄，通常集中在从大量数据中学习到的静态表示上，而不是模型在新型环境中通过交互和探索学习这些表示的效率和效果。在这篇观点文章中，我们借鉴了数十年来认知科学关于人类如何高效学习和适应的研究，然后呼吁为评估AI中的自适应世界模型制定一个新的评估框架。具体来说，我们提出了一种基于一系列精心设计的游戏的新基准范式，这些游戏具有真实、深度和不断更新的新颖性——我们将这类游戏称为新型游戏。我们详细阐述了构建这些游戏的关键要求，并提出了适当的指标来明确挑战和评估代理的快速世界模型诱导能力。我们希望这个新的评估框架将激励未来对世界模型的评估工作，并为开发具有人类类似快速适应和稳健泛化能力的人工智能系统提供关键一步——这是通用人工智能的一个关键组成部分。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human intelligence exhibits a remarkable capacity for rapid adaptation andeffective problem-solving in novel and unfamiliar contexts. We argue that thisprofound adaptability is fundamentally linked to the efficient construction andrefinement of internal representations of the environment, commonly referred toas world models, and we refer to this adaptation mechanism as world modelinduction. However, current understanding and evaluation of world models inartificial intelligence (AI) remains narrow, often focusing on staticrepresentations learned from training on a massive corpora of data, instead ofthe efficiency and efficacy of models in learning these representations throughinteraction and exploration within a novel environment. In this Perspective, weprovide a view of world model induction drawing on decades of research incognitive science on how humans learn and adapt so efficiently; we then callfor a new evaluation framework for assessing adaptive world models in AI.Concretely, we propose a new benchmarking paradigm based on suites of carefullydesigned games with genuine, deep and continually refreshing novelty in theunderlying game structures -- we refer to this kind of games as novel games. Wedetail key desiderata for constructing these games and propose appropriatemetrics to explicitly challenge and evaluate the agent's ability for rapidworld model induction. We hope that this new evaluation framework will inspirefuture evaluation efforts on world models in AI and provide a crucial steptowards developing AI systems capable of the human-like rapid adaptation androbust generalization -- a critical component of artificial generalintelligence.</description>
      <author>example@mail.com (Lance Ying, Katherine M. Collins, Prafull Sharma, Cedric Colas, Kaiya Ivy Zhao, Adrian Weller, Zenna Tavares, Phillip Isola, Samuel J. Gershman, Jacob D. Andreas, Thomas L. Griffiths, Francois Chollet, Kelsey R. Allen, Joshua B. Tenenbaum)</author>
      <guid isPermaLink="false">2507.12821v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Reconstruction of Dark Matter and Baryon Density From Galaxies: A Comparison of Linear, Halo Model and Machine Learning-Based Methods</title>
      <link>http://arxiv.org/abs/2507.12530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  All comments are welcome, 27+4 pages, 18 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统比较了不同方法从银河系数据重建暗物质和重子，发现结合GNN-CNN方法效果最佳，并对物质、重子、晕和银河系的关系进行了分析和可视化以解释结果。&lt;h4&gt;背景&lt;/h4&gt;在宇宙学中，为了分析暗物质或重子等未观测场，通常需要从观测到的发光迹标重建这些场的可能分布。&lt;h4&gt;目的&lt;/h4&gt;比较不同方法重建暗物质和重子的效果，并分析物质、重子、晕和银河系之间的关系。&lt;h4&gt;方法&lt;/h4&gt;使用CAMELS模拟进行系统比较，包括传统的晕模型和基于机器学习的方法，特别是GNN-CNN方法。&lt;h4&gt;主要发现&lt;/h4&gt;发现结合GNN-CNN的方法在重建暗物质和重子方面效果最佳。&lt;h4&gt;结论&lt;/h4&gt;结合GNN-CNN的方法在从银河系数据重建暗物质和重子方面具有显著优势，并对相关宇宙学问题提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;本文对宇宙学中从观测到的发光迹标重建未观测场（如暗物质或重子）的方法进行了系统比较，并提出了新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For many analyses in cosmology it is necessary to reconstruct the likelydistribution of unobserved fields, such as dark matter or baryons, fromobserved luminous tracers. The dominant approach in cosmology has been to usethe so-called halo model, which assumes radially symmetric profiles centeredaround luminous tracers such as galaxies. More recently, field-level machinelearning methods have been proposed that can learn to estimate the unobservedfield after being trained on simulations. However, it is unclear whethermachine learning methods indeed significantly improve over linear methods orthe halo model. In this paper we make a systematic comparison of differentapproaches to reconstruct dark matter and baryons from galaxy data using theCAMELS simulations. We find the best results using a combined GNN-CNN approach.We also provide a general analysis and visualization of the relationship ofmatter, baryons, halos and galaxies in these simulations to interpret ourresults.</description>
      <author>example@mail.com (Jordan Krywonos, Yurii Kvasiuk, Matthew C. Johnson, Moritz Münchmeyer)</author>
      <guid isPermaLink="false">2507.12530v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Improving physics-informed neural network extrapolation via transfer learning and adaptive activation functions</title>
      <link>http://arxiv.org/abs/2507.12659v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 16 figures, 7 tables Accepted to ICANN 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的Physics-Informed Neural Networks（PINNs）模型，通过迁移学习（TL）方法和自适应激活函数来提高PINNs在训练域外的预测能力和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;PINNs通过将物理定律融入学习过程，在解决复杂科学和工程问题时表现出色，但其在训练域外的外推性能较差，且对激活函数的选择非常敏感。&lt;h4&gt;目的&lt;/h4&gt;提高PINNs的外推能力，使其在训练域外也能保持良好的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 在扩展的训练域内应用迁移学习（TL）方法，使用少量精心选择的节点。2. 提出一种自适应激活函数，该函数是标准激活函数的线性组合，以增强模型的鲁棒性和准确性。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验证明，该方法在外推域中平均降低了40%的相对L2误差和50%的平均绝对误差，同时没有显著增加计算成本。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效提高PINNs的外推性能，是一种有效的改进PINNs模型的方法。&lt;h4&gt;翻译&lt;/h4&gt;Physics-Informed Neural Networks (PINNs) are deep learning models that incorporate the governing physical laws of a system into the learning process, making them well-suited for solving complex scientific and engineering problems. Recently, PINNs have gained widespread attention as a powerful framework for combining physical principles with data-driven modeling to improve prediction accuracy. Despite their successes, however, PINNs often exhibit poor extrapolation performance outside the training domain and are highly sensitive to the choice of activation functions (AFs). In this paper, we introduce a transfer learning (TL) method to improve the extrapolation capability of PINNs. Our approach applies transfer learning (TL) within an extended training domain, using only a small number of carefully selected collocation points. Additionally, we propose an adaptive AF that takes the form of a linear combination of standard AFs, which improves both the robustness and accuracy of the model. Through a series of experiments, we demonstrate that our method achieves an average of 40% reduction in relative L2 error and an average of 50% reduction in mean absolute error in the extrapolation domain, all without a significant increase in computational cost. The code is available at https://github.com/LiuzLab/PINN-extrapolation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-Informed Neural Networks (PINNs) are deep learning models thatincorporate the governing physical laws of a system into the learning process,making them well-suited for solving complex scientific and engineeringproblems. Recently, PINNs have gained widespread attention as a powerfulframework for combining physical principles with data-driven modeling toimprove prediction accuracy. Despite their successes, however, PINNs oftenexhibit poor extrapolation performance outside the training domain and arehighly sensitive to the choice of activation functions (AFs). In this paper, weintroduce a transfer learning (TL) method to improve the extrapolationcapability of PINNs. Our approach applies transfer learning (TL) within anextended training domain, using only a small number of carefully selectedcollocation points. Additionally, we propose an adaptive AF that takes the formof a linear combination of standard AFs, which improves both the robustness andaccuracy of the model. Through a series of experiments, we demonstrate that ourmethod achieves an average of 40% reduction in relative L2 error and an averageof 50% reduction in mean absolute error in the extrapolation domain, allwithout a significant increase in computational cost. The code is available athttps://github.com/LiuzLab/PINN-extrapolation .</description>
      <author>example@mail.com (Athanasios Papastathopoulos-Katsaros, Alexandra Stavrianidi, Zhandong Liu)</author>
      <guid isPermaLink="false">2507.12659v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>AnyCap Project: A Unified Framework, Dataset, and Benchmark for Controllable Omni-modal Captioning</title>
      <link>http://arxiv.org/abs/2507.12841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了AnyCap项目，一个涵盖模型、数据集和评估的集成解决方案，旨在提高可控字幕的准确性和可控制性。&lt;h4&gt;背景&lt;/h4&gt;现有的可控字幕模型通常缺乏细粒度控制和可靠的评估协议。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了AnyCap项目。&lt;h4&gt;方法&lt;/h4&gt;AnyCap项目包括AnyCap模型（ACM），这是一个轻量级的框架，可以在不重新训练基模型的情况下增强现有基模型的多模态字幕的可控性；AnyCap数据集（ACD），覆盖三种模态、28种用户指令类型和30万条高质量数据条目；以及AnyCap评估（AnyCapEval），一个新的基准，通过解耦内容准确性和风格忠实度来提供更可靠的评估指标。&lt;h4&gt;主要发现&lt;/h4&gt;ACM在AnyCapEval上的基模型上显著提高了字幕质量。ACM-8B将GPT-4o的内容得分提高了45%，风格得分提高了12%，并在MIA-Bench和VidCapBench等广泛使用的基准上取得了实质性进展。&lt;h4&gt;结论&lt;/h4&gt;AnyCap项目为可控字幕提供了一种有效的方法，显著提高了字幕的质量和可控制性。&lt;h4&gt;翻译&lt;/h4&gt;Controllable captioning is essential for precise multimodal alignment and instruction following, yet existing models often lack fine-grained control and reliable evaluation protocols. To address this gap, we present the AnyCap Project, an integrated solution spanning model, dataset, and evaluation. We introduce AnyCapModel (ACM), a lightweight plug-and-play framework that enhances the controllability of existing foundation models for omni-modal captioning without retraining the base model. ACM reuses the original captions from base models while incorporating user instructions and modality features to generate improved captions. To remedy the data scarcity in controllable multimodal captioning, we build AnyCapDataset (ACD), covering three modalities, 28 user-instruction types, and 300k high-quality data entries. We further propose AnyCapEval, a new benchmark that provides more reliable evaluation metrics for controllable captioning by decoupling content accuracy and stylistic fidelity. ACM markedly improves caption quality across a diverse set of base models on AnyCapEval. Notably, ACM-8B raises GPT-4o's content scores by 45% and style scores by 12%, and it also achieves substantial gains on widely used benchmarks such as MIA-Bench and VidCapBench.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controllable captioning is essential for precise multimodal alignment andinstruction following, yet existing models often lack fine-grained control andreliable evaluation protocols. To address this gap, we present the AnyCapProject, an integrated solution spanning model, dataset, and evaluation. Weintroduce AnyCapModel (ACM), a lightweight plug-and-play framework thatenhances the controllability of existing foundation models for omni-modalcaptioning without retraining the base model. ACM reuses the original captionsfrom base models while incorporating user instructions and modality features togenerate improved captions. To remedy the data scarcity in controllablemultimodal captioning, we build AnyCapDataset (ACD), covering three modalities,28 user-instruction types, and 300\,k high-quality data entries. We furtherpropose AnyCapEval, a new benchmark that provides more reliable evaluationmetrics for controllable captioning by decoupling content accuracy andstylistic fidelity. ACM markedly improves caption quality across a diverse setof base models on AnyCapEval. Notably, ACM-8B raises GPT-4o\'s content scoresby 45\% and style scores by 12\%, and it also achieves substantial gains onwidely used benchmarks such as MIA-Bench and VidCapBench.</description>
      <author>example@mail.com (Yiming Ren, Zhiqiang Lin, Yu Li, Gao Meng, Weiyun Wang, Junjie Wang, Zicheng Lin, Jifeng Dai, Yujiu Yang, Wenhai Wang, Ruihang Chu)</author>
      <guid isPermaLink="false">2507.12841v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Best Practices for Large-Scale, Pixel-Wise Crop Mapping and Transfer Learning Workflows</title>
      <link>http://arxiv.org/abs/2507.12590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A review article. 41 pages, 22 figures. Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对大规模、像素级的作物映射工作流程进行了全面综述，包括传统的监督方法和新兴的迁移学习方法。&lt;h4&gt;背景&lt;/h4&gt;作物映射涉及使用空间数据识别和分类作物类型，这些数据主要来自遥感影像。&lt;h4&gt;目的&lt;/h4&gt;为了确定最佳的监督作物映射工作流程，进行了系统实验，比较了六种广泛采用的卫星图像预处理方法和十一种监督像素级分类模型。&lt;h4&gt;方法&lt;/h4&gt;评估了不同训练样本大小和变量组合的协同影响，并确定了针对不同领域偏移量的最佳迁移学习技术。评估最佳方法是在五个不同的农业地点进行的，主要卫星数据源为Landsat 8，标签来自CDL可信像素和实地调查。&lt;h4&gt;主要发现&lt;/h4&gt;1. 精细间隔预处理与Transformer模型相结合，在监督和可迁移的工作流程中均表现出最佳性能。2. 迁移学习技术增强了工作流程的适应性，UDA对同质作物类别有效，微调在多种场景下依然稳健。3. 工作流程的选择在很大程度上取决于标记样本的可用性。&lt;h4&gt;结论&lt;/h4&gt;在有足够样本量的情况下，监督训练通常提供更准确和可推广的结果。在低于一定阈值的情况下，匹配领域偏移水平的迁移学习是实现作物映射的可行替代方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：作物映射涉及使用空间数据识别和分类作物类型，这些数据主要来自遥感影像。本研究对大规模、像素级的作物映射工作流程进行了首次全面综述，包括传统的监督方法和新兴的迁移学习方法。为了确定最佳的监督作物映射工作流程，我们进行了系统实验，比较了六种广泛采用的卫星图像预处理方法和十一种监督像素级分类模型。此外，我们还评估了不同训练样本大小和变量组合的协同影响。此外，我们确定了针对不同领域偏移量的最佳迁移学习技术。最佳方法的评估是在五个不同的农业地点进行的。Landsat 8作为主要卫星数据源。标签来自CDL可信像素和实地调查。我们的发现揭示了三个关键见解。首先，精细间隔预处理与Transformer模型相结合，在监督和可迁移的工作流程中均表现出最佳性能。RF在传统监督学习和直接转移到相似领域方面提供了快速训练和具有竞争力的性能。其次，迁移学习技术增强了工作流程的适应性，UDA对同质作物类别有效，微调在多种场景下依然稳健。最后，工作流程的选择在很大程度上取决于标记样本的可用性。在有足够样本量的情况下，监督训练通常提供更准确和可推广的结果。在低于一定阈值的情况下，匹配领域偏移水平的迁移学习是实现作物映射的可行替代方案。存储库：大规模像素级作物映射和迁移学习工作流程的最佳实践&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Crop mapping involves identifying and classifying crop types using spatialdata, primarily derived from remote sensing imagery. This study presents thefirst comprehensive review of large-scale, pixel-wise crop mapping workflows,encompassing both conventional supervised methods and emerging transferlearning approaches. To identify the optimal supervised crop mapping workflows,we conducted systematic experiments, comparing six widely adopted satelliteimage-based preprocessing methods, alongside eleven supervised pixel-wiseclassification models. Additionally, we assessed the synergistic impact ofvaried training sample sizes and variable combinations. Moreover, we identifiedoptimal transfer learning techniques for different magnitudes of domain shift.The evaluation of best methods was conducted across five diverse agriculturalsites. Landsat 8 served as the primary satellite data source. Labels come fromCDL trusted pixels and field surveys.  Our findings reveal three key insights. First, fine-scale intervalpreprocessing paired with Transformer models consistently delivered optimalperformance for both supervised and transferable workflows. RF offered rapidtraining and competitive performance in conventional supervised learning anddirect transfer to similar domains. Second, transfer learning techniquesenhanced workflow adaptability, with UDA being effective for homogeneous cropclasses while fine-tuning remains robust across diverse scenarios. Finally,workflow choice depends heavily on the availability of labeled samples. With asufficient sample size, supervised training typically delivers more accurateand generalizable results. Below a certain threshold, transfer learning thatmatches the level of domain shift is a viable alternative to achieve cropmapping. Repository:Best-Practices-for-Large-Scale-Pixel-Wise-Crop-Mapping-and-Transfer-Learning-Workflows</description>
      <author>example@mail.com (Judy Long, Tao Liu, Sean Alexander Woznicki, Miljana Marković, Oskar Marko, Molly Sears)</author>
      <guid isPermaLink="false">2507.12590v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Semantic-guided Fine-tuning of Foundation Model for Long-tailed Visual Recognition</title>
      <link>http://arxiv.org/abs/2507.12807v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Sage的新方法，用于长尾视觉识别中的语义引导微调，以解决长尾场景中样本大小差异导致的性能下降问题。&lt;h4&gt;背景&lt;/h4&gt;在长尾场景中，类别样本大小差异大，导致低频类别性能下降。预训练模型具有通用性，但在微调时往往只调整视觉编码器，忽略了文本编码器的语义信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过将文本模态的语义指导融入视觉微调过程，以增强视觉和文本模态之间的对齐。&lt;h4&gt;方法&lt;/h4&gt;引入了SG-Adapter，将类别描述作为语义指导，引导视觉编码器的微调。同时，提出了一种分布不匹配感知补偿因子，以纠正由忽略的不一致分布引起的预测偏差。&lt;h4&gt;主要发现&lt;/h4&gt;Sage方法通过注意力机制使模型更关注语义相关内容，增强了视觉和文本模态之间的对齐。补偿因子有效解决了预测偏差问题。&lt;h4&gt;结论&lt;/h4&gt;在基准数据集上的实验表明，Sage方法在长尾学习中提高了性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在长尾场景中，类别样本大小的差异往往导致低频类别的性能下降。幸运的是，在大量开放世界数据集上预训练的基础模型，由于它们的通用性表示，对于这项任务具有强大的潜力，这促进了在长尾学习中对预训练模型的适应性策略的发展。高级微调方法通常调整视觉编码器，而忽略了从冻结的文本编码器中得到的语义，忽略了视觉和文本的对齐。为了加强这种对齐，我们提出了一种新颖的方法，即针对长尾视觉识别的基础模型的语义引导微调（Sage），该方法将来自文本模态的语义指导融入视觉微调过程。具体来说，我们引入了一个SG-Adapter，它将类别描述作为语义指导，以引导视觉编码器的微调。引入的指导通过注意力机制传递，使模型能够更多地关注语义相关内容，增强了视觉和文本模态之间的对齐。由于现有损失函数忽略了不一致的类别条件分布，因此即使增强了多模态对齐，结果预测偏差也会导致尾部类别的性能提升小于头部类别。为了解决这个挑战，我们提出了一种新的分布不匹配感知补偿因子，该因子是根据我们的理论分析专门设计的，以纠正由忽略的不一致分布引起的预测偏差，并且无缝集成到损失函数中。在基准数据集上的大量实验证明了所提出的Sage在增强长尾学习性能方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The variance in class-wise sample sizes within long-tailed scenarios oftenresults in degraded performance in less frequent classes. Fortunately,foundation models, pre-trained on vast open-world datasets, demonstrate strongpotential for this task due to their generalizable representation, whichpromotes the development of adaptive strategies on pre-trained models inlong-tailed learning. Advanced fine-tuning methods typically adjust visualencoders while neglecting the semantics derived from the frozen text encoder,overlooking the visual and textual alignment. To strengthen this alignment, wepropose a novel approach, Semantic-guided fine-tuning of foundation model forlong-tailed visual recognition (Sage), which incorporates semantic guidancederived from textual modality into the visual fine-tuning process.Specifically, we introduce an SG-Adapter that integrates class descriptions assemantic guidance to guide the fine-tuning of the visual encoder. Theintroduced guidance is passesed through the attention mechanism and enables themodel to focus more on semantically relevant content, strengthening thealignment between the visual and textual modalities. Due to the inconsistentclass-conditional distributions neglected by the existing loss function, theresulting prediction bias causes performance improvements for the tail classless than for the head class, even when the multi-modal alignment is enhanced.To address this challenge, we propose a novel distribution mismatch-awarecompensation factor, which is specifically designed to rectify the predictionbias caused by the ignored inconsistent distribution based on our theoreticalanalysis, and is seamlessly integrated into the loss function. Extensiveexperiments on benchmark datasets demonstrate the effectiveness of the proposedSage in enhancing performance in long-tailed learning.</description>
      <author>example@mail.com (Yufei Peng, Yonggang Zhang, Yiu-ming Cheung)</author>
      <guid isPermaLink="false">2507.12807v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Are encoders able to learn landmarkers for warm-starting of Hyperparameter Optimization?</title>
      <link>http://arxiv.org/abs/2507.12604v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了两种针对特定元任务——warm-starting Bayesian Hyperparameter Optimization的表格数据表示学习方法。&lt;h4&gt;背景&lt;/h4&gt;当前对于异构表格数据集的有效表示仍然是元学习中的一个开放问题，以往的方法依赖于通用的表示。&lt;h4&gt;目的&lt;/h4&gt;提出两种新的表格表示学习方法，以适应特定的元任务，并确保表示能够捕捉到landarkers的特性。&lt;h4&gt;方法&lt;/h4&gt;第一种方法涉及深度度量学习，第二种方法基于landarkers的重构。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的编码器能够有效地学习与landarkers对齐的表示，但它们可能不会直接转化为HPO warm-starting元任务中的显著性能提升。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在特定元任务中有效，但在性能提升方面可能有限。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively representing heterogeneous tabular datasets for meta-learningpurposes is still an open problem. Previous approaches rely on representationsthat are intended to be universal. This paper proposes two novel methods fortabular representation learning tailored to a specific meta-task -warm-starting Bayesian Hyperparameter Optimization. Both follow the specificrequirement formulated by ourselves that enforces representations to capturethe properties of landmarkers. The first approach involves deep metriclearning, while the second one is based on landmarkers reconstruction. Weevaluate the proposed encoders in two ways. Next to the gain in the targetmeta-task, we also use the degree of fulfillment of the proposed requirement asthe evaluation metric. Experiments demonstrate that while the proposed encoderscan effectively learn representations aligned with landmarkers, they may notdirectly translate to significant performance gains in the meta-task of HPOwarm-starting.</description>
      <author>example@mail.com (Antoni Zajko, Katarzyna Woźnica)</author>
      <guid isPermaLink="false">2507.12604v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Catching Bid-rigging Cartels with Graph Attention Neural Networks</title>
      <link>http://arxiv.org/abs/2507.12369v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图注意力网络（GATs）的深度学习算法，用于检测串谋行为，并在多个市场数据集上进行了测试。&lt;h4&gt;背景&lt;/h4&gt;利用先前研究提出的预测特征，将GATs应用于检测串谋行为。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效检测串谋行为的深度学习算法。&lt;h4&gt;方法&lt;/h4&gt;使用GATs在部分市场数据集上训练预测模型，并在其他市场进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;GATs模型在不同市场间具有可迁移性，准确率在80%至90%之间，最佳配置在瑞士和冲绳地区市场预测的平均准确率为91%，在12个市场上的平均准确率为84%，优于传统机器学习集成方法。&lt;h4&gt;结论&lt;/h4&gt;基于GATs的检测方法为竞争监管机构筛选潜在卡特尔活动提供了有希望的工具。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新型应用图注意力网络（GATs）的方法，这是一种增强注意力机制的图神经网络，用于开发一种深度学习算法，以利用先前研究中提出的预测特征来检测串谋行为。我们在涵盖七个国家13个市场的庞大数据集上测试了我们的方法。我们的结果表明，基于GATs的预测模型，在部分市场数据集上训练，可以有效地迁移到其他市场，准确率在80%至90%之间，具体取决于超参数设置。表现最佳配置，应用于瑞士和冲绳地区的八个市场，对于跨市场预测的平均准确率为91%。当扩展到12个市场时，该方法保持了强大的性能，平均准确率为84%，超过了传统的机器学习集成方法。这些结果表明，基于GATs的检测方法为竞争监管机构筛选市场潜在卡特尔活动提供了有希望的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel application of graph attention networks (GATs), a type ofgraph neural network enhanced with attention mechanisms, to develop a deeplearning algorithm for detecting collusive behavior, leveraging predictivefeatures suggested in prior research. We test our approach on a large datasetcovering 13 markets across seven countries. Our results show that predictivemodels based on GATs, trained on a subset of the markets, can be effectivelytransferred to other markets, achieving accuracy rates between 80% and 90%,depending on the hyperparameter settings. The best-performing configuration,applied to eight markets from Switzerland and the Japanese region of Okinawa,yields an average accuracy of 91% for cross-market prediction. When extended to12 markets, the method maintains a strong performance with an average accuracyof 84%, surpassing traditional ensemble approaches in machine learning. Theseresults suggest that GAT-based detection methods offer a promising tool forcompetition authorities to screen markets for potential cartel activity.</description>
      <author>example@mail.com (David Imhof, Emanuel W Viklund, Martin Huber)</author>
      <guid isPermaLink="false">2507.12369v2</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Wavelet-GS: 3D Gaussian Splatting with Wavelet Decomposition</title>
      <link>http://arxiv.org/abs/2507.12498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的3D Gaussian Splatting优化框架，通过结合小波分解和二维采样，解决了现有方法在复杂场景重建中存在的问题，提高了渲染质量、效率和速度。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting在3D场景重建中具有重要意义，但现有方法在复杂场景中存在输出不完整、局部光照效果不清等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的优化框架，同时解决现有方法在复杂场景重建中的问题。&lt;h4&gt;方法&lt;/h4&gt;通过将小波分解集成到3D Gaussian Splatting和二维采样中，对点云进行高频和低频分解，分别进行优化。低频分量捕捉全局结构轮廓并管理高斯分布，高频分量恢复几何和纹理细节，并加入重光照模块以减少光照伪影，提高渲染的真实感。此外，对训练图像应用二维小波分解，模拟辐射变化，为高频细节重建提供指导。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个数据集上的实验表明，在各种指标上均达到了最先进的性能，超越了现有方法，推动了3D场景重建领域的发展。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了3D场景重建的质量和效率，为该领域的研究提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;3D高斯溅射（3DGS）彻底改变了3D场景重建，有效地平衡了渲染质量、效率和速度。然而，现有的3DGS方法通常生成合理的输出，但在复杂场景重建中面临着重大挑战，表现为不完整的整体结构轮廓和不清的局部光照效果。为了同时解决这些问题，我们提出了一种新颖的解耦优化框架，该框架将小波分解集成到3D高斯溅射和二维采样中。技术上，通过3D小波分解，我们的方法将点云分解为高频和低频分量，使每个分量都能进行针对性的优化。低频分量捕捉全局结构轮廓并通过体素化管理高斯分布。相反，高频分量恢复复杂的几何和纹理细节，同时结合重光照模块以减少光照伪影并提高逼真渲染。此外，还对训练图像应用二维小波分解，模拟辐射变化。这为高频细节重建提供了关键指导，确保了细节与全局结构的无缝集成。在具有挑战性的数据集上进行的广泛实验表明，我们的方法在各种指标上实现了最先进的性能，超过了现有方法，推动了3D场景重建领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) has revolutionized 3D scene reconstruction,which effectively balances rendering quality, efficiency, and speed. However,existing 3DGS approaches usually generate plausible outputs and facesignificant challenges in complex scene reconstruction, manifesting asincomplete holistic structural outlines and unclear local lighting effects. Toaddress these issues simultaneously, we propose a novel decoupled optimizationframework, which integrates wavelet decomposition into 3D Gaussian Splattingand 2D sampling. Technically, through 3D wavelet decomposition, our approachdivides point clouds into high-frequency and low-frequency components, enablingtargeted optimization for each. The low-frequency component captures globalstructural outlines and manages the distribution of Gaussians throughvoxelization. In contrast, the high-frequency component restores intricategeometric and textural details while incorporating a relight module to mitigatelighting artifacts and enhance photorealistic rendering. Additionally, a 2Dwavelet decomposition is applied to the training images, simulating radiancevariations. This provides critical guidance for high-frequency detailreconstruction, ensuring seamless integration of details with the globalstructure. Extensive experiments on challenging datasets demonstrate our methodachieves state-of-the-art performance across various metrics, surpassingexisting approaches and advancing the field of 3D scene reconstruction.</description>
      <author>example@mail.com (Beizhen Zhao, Yifan Zhou, Sicheng Yu, Zijian Wang, Hao Wang)</author>
      <guid isPermaLink="false">2507.12498v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models</title>
      <link>http://arxiv.org/abs/2507.12774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了人工智能在医疗保健领域的应用，特别是电子健康记录（EHR）的分析和建模，以及深度学习、大型语言模型（LLM）和EHR建模的交叉领域。&lt;h4&gt;背景&lt;/h4&gt;EHR数据具有异质性、时间不规则性和特定领域性质，这给数据分析带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提供人工智能驱动的EHR建模和临床决策支持的路线图。&lt;h4&gt;方法&lt;/h4&gt;提出了一个包含五个关键设计维度的统一分类法：数据为中心的方法、神经架构设计、学习导向策略、多模态学习和基于LLM的建模系统。&lt;h4&gt;主要发现&lt;/h4&gt;包括数据质量提升、结构和时间表示、自监督学习和与临床知识的整合等方法。&lt;h4&gt;结论&lt;/h4&gt;强调了基准测试、可解释性、临床一致性以及跨不同临床环境的泛化等开放性挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人工智能（AI）在通过分析和建模电子健康记录（EHR）以转变医疗保健方面显示出巨大的潜力。然而，EHR数据固有的异质性、时间不规则性和特定领域性质提出了独特的挑战，这些挑战与视觉和自然语言任务中的挑战在本质上有所不同。本文综述了深度学习、大型语言模型（LLMs）和EHR建模交叉领域的最新进展。我们引入了一个涵盖五个关键设计维度的统一分类法：数据为中心的方法、神经架构设计、学习导向策略、多模态学习和基于LLM的建模系统。在每个维度内，我们回顾了针对数据质量提升、结构和时间表示、自监督学习和与临床知识整合的代表性方法。我们进一步突出了新兴趋势，如基础模型、由LLM驱动的临床代理以及用于下游推理的EHR到文本翻译。最后，我们讨论了基准测试、可解释性、临床一致性和跨不同临床环境的泛化等开放性挑战。本综述旨在为推进人工智能驱动的EHR建模和临床决策支持提供结构化路线图。欲获取EHR相关方法的全面列表，请参阅https://survey-on-tabular-data.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has demonstrated significant potential intransforming healthcare through the analysis and modeling of electronic healthrecords (EHRs). However, the inherent heterogeneity, temporal irregularity, anddomain-specific nature of EHR data present unique challenges that differfundamentally from those in vision and natural language tasks. This surveyoffers a comprehensive overview of recent advancements at the intersection ofdeep learning, large language models (LLMs), and EHR modeling. We introduce aunified taxonomy that spans five key design dimensions: data-centricapproaches, neural architecture design, learning-focused strategies, multimodallearning, and LLM-based modeling systems. Within each dimension, we reviewrepresentative methods addressing data quality enhancement, structural andtemporal representation, self-supervised learning, and integration withclinical knowledge. We further highlight emerging trends such as foundationmodels, LLM-driven clinical agents, and EHR-to-text translation for downstreamreasoning. Finally, we discuss open challenges in benchmarking, explainability,clinical alignment, and generalization across diverse clinical settings. Thissurvey aims to provide a structured roadmap for advancing AI-driven EHRmodeling and clinical decision support. For a comprehensive list of EHR-relatedmethods, kindly refer to https://survey-on-tabular-data.github.io/.</description>
      <author>example@mail.com (Weijieying Ren, Jingxi Zhu, Zehao Liu, Tianxiang Zhao, Vasant Honavar)</author>
      <guid isPermaLink="false">2507.12774v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>How does Labeling Error Impact Contrastive Learning? A Perspective from Data Dimensionality Reduction</title>
      <link>http://arxiv.org/abs/2507.11161v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as ICML2025 poster. The arXiv version is a modified version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了标签错误对对比学习下游分类性能的影响，并提出了一种使用数据降维和适度增强策略来提高模型性能的方法。&lt;h4&gt;背景&lt;/h4&gt;近年来，对比学习在自监督表征学习领域取得了显著的性能。许多研究尝试解释对比学习成功背后的理论，但大多基于标签一致性假设，这一假设在实际中可能不成立，因为像随机裁剪等常见增强策略具有强度和随机性。&lt;h4&gt;目的&lt;/h4&gt;研究标签错误对对比学习下游分类性能的理论影响，并提出缓解标签错误影响的策略。&lt;h4&gt;方法&lt;/h4&gt;使用数据降维方法（如奇异值分解，SVD）来减少错误样本，并对方法进行理论和实证评估。同时，探讨了SVD可能对下游分类精度产生负面影响的潜在原因。&lt;h4&gt;主要发现&lt;/h4&gt;标签错误对下游分类风险有显著的负面影响；SVD作为一种双刃剑，可能在降低增强图连通性的同时，导致下游分类精度的下降。&lt;h4&gt;结论&lt;/h4&gt;为了确保大型图的连通性和小的标签错误，从而提高模型性能，建议使用适中的嵌入维度、数据膨胀、弱增强和SVD。&lt;h4&gt;翻译&lt;/h4&gt;近年来，对比学习在自监督表征学习领域取得了最先进的性能。许多先前的工作试图提供对比学习成功背后的理论理解。几乎所有这些工作都依赖于一个默认假设，即标签一致性假设，由于常见增强策略（如随机裁剪）的强度和随机性，这一假设在实际情况中可能不成立（标签错误发生的概率）。本文研究了标签错误对对比学习下游分类性能的理论影响。首先，揭示了标签错误对下游分类风险的几个重要负面影响。为了减轻这些影响，我们首先在原始数据上应用数据降维方法（例如，奇异值分解，SVD）以减少错误样本，并建立理论和实证评估。此外，还发现SVD是一种双刃剑，它可能会因为增强图的连通性降低而导致下游分类精度的下降。基于上述观察，我们给出了增强建议：我们应该使用一些适度的嵌入维度（例如，在我们的实验中的512，1024），数据膨胀，弱增强和SVD，以确保大型图的连通性和小的标签错误，以改善模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, contrastive learning has achieved state-of-the-artperformance in the territory of self-supervised representation learning. Manyprevious works have attempted to provide the theoretical understandingunderlying the success of contrastive learning. Almost all of them rely on adefault assumption, i.e., the label consistency assumption, which may not holdin practice (the probability of failure is called labeling error) due to thestrength and randomness of common augmentation strategies, such as randomresized crop (RRC). This paper investigates the theoretical impact of labelingerror on the downstream classification performance of contrastive learning. Wefirst reveal several significant negative impacts of labeling error ondownstream classification risk. To mitigate these impacts, data dimensionalityreduction method (e.g., singular value decomposition, SVD) is applied onoriginal data to reduce false positive samples, and establish both theoreticaland empirical evaluations. Moreover, it is also found that SVD acts as adouble-edged sword, which may lead to the deterioration of downstreamclassification accuracy due to the reduced connectivity of the augmentationgraph. Based on the above observations, we give the augmentation suggestionthat we should use some moderate embedding dimension (such as $512, 1024$ inour experiments), data inflation, weak augmentation, and SVD to ensure largegraph connectivity and small labeling error to improve model performance.</description>
      <author>example@mail.com (Jun Chen, Hong Chen, Yonghua Yu, Yiming Ying)</author>
      <guid isPermaLink="false">2507.11161v2</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal-Guided Dynamic Dataset Pruning for Robust and Efficient Data-Centric Learning</title>
      <link>http://arxiv.org/abs/2507.12750v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种动态数据集剪枝框架，旨在提高训练效率和模型性能，同时增强鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现代深度模型在大型真实世界数据集上训练，数据质量参差不齐且存在冗余。&lt;h4&gt;目的&lt;/h4&gt;通过自适应选择训练样本，结合任务驱动的难度和跨模态语义一致性，提高训练效率和模型性能。&lt;h4&gt;方法&lt;/h4&gt;引入动态数据集剪枝框架，利用预训练的多模态基础模型进行监督，捕捉训练动态并过滤无信息样本。&lt;h4&gt;主要发现&lt;/h4&gt;跨模态对齐在鲁棒样本选择中具有潜力，推动了以数据为中心的学习向更高效和鲁棒的实践发展。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了跨模态对齐在数据集中鲁棒样本选择中的潜力，为数据驱动学习提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Modern deep models are trained on large real-world datasets, where data quality varies and redundancy is common. Data-centric approaches such as dataset pruning have shown promise in improving training efficiency and model performance. However, most existing methods rely on static heuristics or task-specific metrics, limiting their robustness and generalizability across domains. In this work, we introduce a dynamic dataset pruning framework that adaptively selects training samples based on both task-driven difficulty and cross-modality semantic consistency. By incorporating supervision from pretrained multimodal foundation models, our approach captures training dynamics while effectively filtering out uninformative samples. Our work highlights the potential of integrating cross-modality alignment for robust sample selection, advancing data-centric learning toward more efficient and robust practices across application domains.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern deep models are trained on large real-world datasets, where dataquality varies and redundancy is common. Data-centric approaches such asdataset pruning have shown promise in improving training efficiency and modelperformance. However, most existing methods rely on static heuristics ortask-specific metrics, limiting their robustness and generalizability acrossdomains. In this work, we introduce a dynamic dataset pruning framework thatadaptively selects training samples based on both task-driven difficulty andcross-modality semantic consistency. By incorporating supervision frompretrained multimodal foundation models, our approach captures trainingdynamics while effectively filtering out uninformative samples. Our workhighlights the potential of integrating cross-modality alignment for robustsample selection, advancing data-centric learning toward more efficient androbust practices across application domains.</description>
      <author>example@mail.com (Suorong Yang, Peijia Li, Yujie Liu, Zhiming Xu, Peng Ye, Wanli Ouyang, Furao Shen, Dongzhan Zhou)</author>
      <guid isPermaLink="false">2507.12750v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform</title>
      <link>http://arxiv.org/abs/2507.12704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  RecSys 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PinFM的基础模型，用于理解亿级视觉发现平台上的用户活动序列。该模型通过预训练和微调的方法，有效结合现有模型，并解决了工业推荐系统中遇到的挑战。&lt;h4&gt;背景&lt;/h4&gt;用户活动序列已成为推荐系统中的重要信号，但在工业推荐系统中应用预训练和微调方法面临诸多挑战。&lt;h4&gt;目的&lt;/h4&gt;构建一个能够理解和处理大规模用户活动序列的基础模型，以支持工业推荐系统。&lt;h4&gt;方法&lt;/h4&gt;预训练一个包含20B+参数的Transformer模型，使用大量的用户活动数据，然后针对特定应用进行微调。同时，开发创新技术来应对规模、成本和延迟等挑战。&lt;h4&gt;主要发现&lt;/h4&gt;PinFM能够通过改变输入序列来学习用户序列与候选项目之间的交互，从而提高对新项目的参与度，并在Pinterest内部数据上提高了600%的吞吐量。&lt;h4&gt;结论&lt;/h4&gt;PinFM已经部署到多个应用中，帮助改善超过5亿用户的体验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; User activity sequences have emerged as one of the most important signals inrecommender systems. We present a foundational model, PinFM, for understandinguser activity sequences across multiple applications at a billion-scale visualdiscovery platform. We pretrain a transformer model with 20B+ parameters usingextensive user activity data, then fine-tune it for specific applications,efficiently coupling it with existing models. While thispretraining-and-fine-tuning approach has been popular in other domains, such asVision and NLP, its application in industrial recommender systems presentsnumerous challenges. The foundational model must be scalable enough to scoremillions of items every second while meeting tight cost and latency constraintsimposed by these systems. Additionally, it should capture the interactionsbetween user activities and other features and handle new items that were notpresent during the pretraining stage.  We developed innovative techniques to address these challenges. Ourinfrastructure and algorithmic optimizations, such as the DeduplicatedCross-Attention Transformer (DCAT), improved our throughput by 600% onPinterest internal data. We demonstrate that PinFM can learn interactionsbetween user sequences and candidate items by altering input sequences, leadingto a 20% increase in engagement with new items. PinFM is now deployed to helpimprove the experience of more than a half billion users across variousapplications.</description>
      <author>example@mail.com (Xiangyi Chen, Kousik Rajesh, Matthew Lawhon, Zelun Wang, Hanyu Li, Haomiao Li, Saurabh Vishwas Joshi, Pong Eksombatchai, Jaewon Yang, Yi-Ping Hsu, Jiajing Xu, Charles Rosenberg)</author>
      <guid isPermaLink="false">2507.12704v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Pixel Perfect MegaMed: A Megapixel-Scale Vision-Language Foundation Model for Generating High Resolution Medical Images</title>
      <link>http://arxiv.org/abs/2507.12698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Pixel Perfect MegaMed是一种用于医学图像合成的视觉-语言基础模型，能够在1024x1024的高分辨率下生成图像，通过多尺度变换架构和视觉-语言对齐技术，实现了全局解剖背景和局部图像细节的保留。&lt;h4&gt;背景&lt;/h4&gt;医学图像合成在临床环境中由于需要高分辨率细节而具有独特挑战。传统的生成对抗网络（GANs）或变分自编码器（VAEs）在生成高分辨率图像方面表现出潜力，但难以保留对准确诊断至关重要的细粒度细节。&lt;h4&gt;目的&lt;/h4&gt;提出Pixel Perfect MegaMed以解决传统方法在保留细粒度细节方面的不足。&lt;h4&gt;方法&lt;/h4&gt;Pixel Perfect MegaMed采用专门为超高分辨率医学图像生成设计的多尺度变换架构，并利用针对医学术语和成像模态的视觉-语言对齐技术。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在CheXpert数据集上应用，能够从文本提示生成临床可信的胸部X光片。高分辨率合成图像在下游任务如分类中表现出价值，特别是在数据量较少的情况下，使用数据增强时性能提升明显。&lt;h4&gt;结论&lt;/h4&gt;Pixel Perfect MegaMed通过其独特的架构和对齐技术，在医学图像合成领域取得了显著进展，为临床应用提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Medical image synthesis presents unique challenges due to the inherent complexity and high-resolution details required in clinical contexts. Traditional generative architectures such as Generative Adversarial Networks (GANs) or Variational Auto Encoder (VAEs) have shown great promise for high-resolution image generation but struggle with preserving fine-grained details that are key for accurate diagnosis. To address this issue, we introduce Pixel Perfect MegaMed, the first vision-language foundation model to synthesize images at resolutions of 1024x1024. Our method deploys a multi-scale transformer architecture designed specifically for ultra-high resolution medical image generation, enabling the preservation of both global anatomical context and local image-level details. By leveraging vision-language alignment techniques tailored to medical terminology and imaging modalities, PixelPerfect MegaMed bridges the gap between textual descriptions and visual representations at unprecedented resolution levels. We apply our model to the CheXpert dataset and demonstrate its ability to generate clinically faithful chest X-rays from text prompts. Beyond visual quality, these high-resolution synthetic images prove valuable for downstream tasks such as classification, showing measurable performance gains when used for data augmentation, particularly in low-data regimes. Our code is accessible through the project website - https://tehraninasab.github.io/pixelperfect-megamed.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image synthesis presents unique challenges due to the inherentcomplexity and high-resolution details required in clinical contexts.Traditional generative architectures such as Generative Adversarial Networks(GANs) or Variational Auto Encoder (VAEs) have shown great promise forhigh-resolution image generation but struggle with preserving fine-graineddetails that are key for accurate diagnosis. To address this issue, weintroduce Pixel Perfect MegaMed, the first vision-language foundation model tosynthesize images at resolutions of 1024x1024. Our method deploys a multi-scaletransformer architecture designed specifically for ultra-high resolutionmedical image generation, enabling the preservation of both global anatomicalcontext and local image-level details. By leveraging vision-language alignmenttechniques tailored to medical terminology and imaging modalities, PixelPerfect MegaMed bridges the gap between textual descriptions and visualrepresentations at unprecedented resolution levels. We apply our model to theCheXpert dataset and demonstrate its ability to generate clinically faithfulchest X-rays from text prompts. Beyond visual quality, these high-resolutionsynthetic images prove valuable for downstream tasks such as classification,showing measurable performance gains when used for data augmentation,particularly in low-data regimes. Our code is accessible through the projectwebsite - https://tehraninasab.github.io/pixelperfect-megamed.</description>
      <author>example@mail.com (Zahra TehraniNasab, Amar Kumar, Tal Arbel)</author>
      <guid isPermaLink="false">2507.12698v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>VLMgineer: Vision Language Models as Robotic Toolsmiths</title>
      <link>http://arxiv.org/abs/2507.12644v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Website: https://vlmgineer.github.io/release&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了工具设计和使用在理解及操控物理世界方面的作用，将其视为衡量物种智能的指标。研究提出了一种名为VLMgineer的框架，该框架结合视觉语言模型和进化搜索来协同设计工具和操作它们的行动计划，以执行任务。&lt;h4&gt;背景&lt;/h4&gt;工具设计和使用反映了通过创造力、规划和前瞻性理解并操控物理世界的能力，这些能力常被视为衡量生物物种智能的可衡量指标。&lt;h4&gt;目的&lt;/h4&gt;研究旨在探讨现有的基础模型是否能够提供有用的先验知识来自动设计和有效使用这类工具。&lt;h4&gt;方法&lt;/h4&gt;VLMgineer框架结合了视觉语言模型的代码生成能力和进化搜索，以迭代方式协同设计物理工具和操作它们的行动计划。&lt;h4&gt;主要发现&lt;/h4&gt;VLMgineer在一系列日常操作场景中表现出色，能够发现更有效和创新性的工具和政策来解决问题，并且在这些场景中优于由人类指定和人类制作的工具。&lt;h4&gt;结论&lt;/h4&gt;VLMgineer能够将具有挑战性的机器人问题转化为简单的执行，并且为未来自动化工具发明的研究提供了基准和代码。&lt;h4&gt;翻译&lt;/h4&gt;摘要：工具设计和使用反映了通过创造力、规划、前瞻性理解和操控物理世界的能力。这些能力通常被视为衡量生物物种智能的可衡量指标。因此，今天的机器人智能研究主要集中在生成更好的控制器，而发明更智能的工具则提供了另一种形式的物理智能：将解决问题的责任转移到工具的设计上。鉴于今天的基础模型在常识、推理和创造性能力方面的广泛和令人印象深刻，我们研究了这些模型是否能够提供有用的先验知识来自动设计和有效使用这类工具？我们提出了VLMgineer框架，该框架利用视觉语言模型（VLMs）的代码生成能力以及进化搜索来迭代地协同设计物理工具及其操作任务的行动计划。我们在需要创造性工具设计和使用的多样化新基准上评估了VLMgineer。在这个套件中，VLMgineer一致地发现了解决任务更有效和创新性的工具和政策，将具有挑战性的机器人问题转化为简单的执行。它还优于由人类指定和现有人类制作的日常任务的VLM生成的设计。为了促进未来自动化工具发明的研究，我们将发布我们的基准和代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tool design and use reflect the ability to understand and manipulate thephysical world through creativity, planning, and foresight. As such, thesecapabilities are often regarded as measurable indicators of intelligence acrossbiological species. While much of today's research on robotic intelligencefocuses on generating better controllers, inventing smarter tools offers acomplementary form of physical intelligence: shifting the onus ofproblem-solving onto the tool's design. Given the vast and impressivecommon-sense, reasoning, and creative capabilities of today's foundationmodels, we investigate whether these models can provide useful priors toautomatically design and effectively wield such tools? We present VLMgineer, aframework that harnesses the code generation abilities of vision languagemodels (VLMs) together with evolutionary search to iteratively co-designphysical tools and the action plans that operate them to perform a task. Weevaluate VLMgineer on a diverse new benchmark of everyday manipulationscenarios that demand creative tool design and use. Across this suite,VLMgineer consistently discovers tools and policies that solve tasks moreeffectively and innovatively, transforming challenging robotics problems intostraightforward executions. It also outperforms VLM-generated designs fromhuman specifications and existing human-crafted tools for everyday tasks. Tofacilitate future research on automated tool invention, we will release ourbenchmark and code.</description>
      <author>example@mail.com (George Jiayuan Gao, Tianyu Li, Junyao Shi, Yihan Li, Zizhe Zhang, Nadia Figueroa, Dinesh Jayaraman)</author>
      <guid isPermaLink="false">2507.12644v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation</title>
      <link>http://arxiv.org/abs/2507.10917v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于大型语言模型（LLM）的双层多兴趣建模框架，以更有效地进行推荐。&lt;h4&gt;背景&lt;/h4&gt;现有方法在建模用户多兴趣时往往依赖于启发式假设，未能准确捕捉用户在现实场景中的多兴趣。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决LLM在多兴趣分析中的两个关键挑战：兴趣粒度不明确和数据稀疏性导致的个人用户分析局限性。&lt;h4&gt;方法&lt;/h4&gt;在用户个体层面，利用LLM将用户参与的项目灵活地分配到不同的语义簇中，表示他们的多样化和独特的兴趣。通过自适应地将这些语义簇分配给用户从全局用户-项目交互中学习到的协同多兴趣，以自动调整粒度。在用户群体层面，将用户小团体聚合为具有丰富行为的合成用户，以进行更全面的多兴趣分析。通过对比学习来解耦不同兴趣中的项目表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在真实世界数据集上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效地捕捉用户的多兴趣，并提高了推荐的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, much effort has been devoted to modeling users' multi-interestsbased on their behaviors or auxiliary signals. However, existing methods oftenrely on heuristic assumptions, e.g., co-occurring items indicate the sameinterest of users, failing to capture user multi-interests aligning withreal-world scenarios. While large language models (LLMs) show significantpotential for multi-interest analysis due to their extensive knowledge andpowerful reasoning capabilities, two key challenges remain. First, thegranularity of LLM-driven multi-interests is agnostic, possibly leading tooverly fine or coarse interest grouping. Second, individual user analysisprovides limited insights due to the data sparsity issue. In this paper, wepropose an LLM-driven dual-level multi-interest modeling framework for moreeffective recommendation. At the user-individual level, we exploit LLMs toflexibly allocate items engaged by users into different semantic clusters,indicating their diverse and distinct interests. To alleviate the agnosticgeneration of LLMs, we adaptively assign these semantic clusters to users'collaborative multi-interests learned from global user-item interactions,allowing the granularity to be automatically adjusted according to the user'sbehaviors using an alignment module. To alleviate the limited insights derivedfrom individual users' behaviors, at the user-crowd level, we proposeaggregating user cliques into synthesized users with rich behaviors for morecomprehensive LLM-driven multi-interest analysis. We formulate a max coveringproblem to ensure the compactness and representativeness of synthesized users'behaviors, and then conduct contrastive learning based on their LLM-drivenmulti-interests to disentangle item representations among different interests.Experiments on real-world datasets show the superiority of our approach againststate-of-the-art methods.</description>
      <author>example@mail.com (Ziyan Wang, Yingpeng Du, Zhu Sun, Jieyi Bi, Haoyan Chua, Tianjun Wei, Jie Zhang)</author>
      <guid isPermaLink="false">2507.10917v2</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing In-Domain and Out-Domain EmoFake Detection via Cooperative Multilingual Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2507.12595v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了情感伪造检测（EFD），提出多语言语音基础模型（SFMs）在EFD中可能特别有效，因为它们在多种语言上的预训练能够细致理解音调、音色和强度的变化。&lt;h4&gt;背景&lt;/h4&gt;多语言语音基础模型（SFMs）在多种语言上的预训练使得它们在理解语言差异方面具有优势。&lt;h4&gt;目的&lt;/h4&gt;验证多语言SFMs在EFD中的有效性，并提出一种名为THAMA的基础模型融合方法。&lt;h4&gt;方法&lt;/h4&gt;进行了对现有SFMs的全面比较分析，并提出了THAMA方法，该方法结合了 Tucker 分解和 Hadamard 积，以实现有效的模型融合。&lt;h4&gt;主要发现&lt;/h4&gt;多语言SFMs在相同语言（域内）和跨语言（域外）评估中均表现出优越性。&lt;h4&gt;结论&lt;/h4&gt;THAMA方法与协作的多语言SFMs结合，在域内和域外设置中实现了最佳性能，优于单个FM、基线融合技术和先前的方法。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们解决了情感伪造检测（EFD）问题。我们假设由于多语言语音基础模型（SFMs）在多种语言上的预训练，它们在EFD中将特别有效，这使它们能够细致地理解音调、音色和强度的变化。为了验证这一点，我们对最先进的（SOTA）SFMs进行了全面的比较分析。我们的结果表明，多语言SFMs在相同语言（域内）以及跨语言（域外）评估中都表现出优越性。为了我们的目的，我们还提出了一种名为THAMA的基础模型融合方法，该方法受相关研究启发，其中结合FM已被证明可以提高性能。THAMA利用了Tucker分解和Hadamard积的互补结合来实现有效的融合。与THAMA结合，合作的多语言SFMs在域内和域外设置中实现了最佳性能，优于单个FM、基线融合技术和先前的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we address EmoFake Detection (EFD). We hypothesize thatmultilingual speech foundation models (SFMs) will be particularly effective forEFD due to their pre-training across diverse languages, enabling a nuancedunderstanding of variations in pitch, tone, and intensity. To validate this, weconduct a comprehensive comparative analysis of state-of-the-art (SOTA) SFMs.Our results shows the superiority of multilingual SFMs for same language(in-domain) as well as cross-lingual (out-domain) evaluation. To our end, wealso propose, THAMA for fusion of foundation models (FMs) motivated by relatedresearch where combining FMs have shown improved performance. THAMA leveragesthe complementary conjunction of tucker decomposition and hadamard product foreffective fusion. With THAMA, synergized with cooperative multilingual SFMsachieves topmost performance across in-domain and out-domain settings,outperforming individual FMs, baseline fusion techniques, and prior SOTAmethods.</description>
      <author>example@mail.com (Orchid Chetia Phukan, Mohd Mujtaba Akhtar, Girish, Arun Balaji Buduru)</author>
      <guid isPermaLink="false">2507.12595v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>Quantum Transfer Learning to Boost Dementia Detection</title>
      <link>http://arxiv.org/abs/2507.12485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了量子机器学习（QML）在阿尔茨海默病（痴呆症）预测中的应用，特别是量子迁移学习（QTL）在提高弱经典深度学习模型性能方面的潜力。&lt;h4&gt;背景&lt;/h4&gt;痴呆症对个人、家庭和医疗体系有深远的影响。早期且准确的痴呆症检测对于及时干预和改善患者预后至关重要。传统的机器学习和深度学习方法在处理高维生物医学数据和大规模数据集时，往往遇到计算和性能的局限性。&lt;h4&gt;目的&lt;/h4&gt;本文旨在展示量子迁移学习（QTL）在提高弱经典深度学习模型对痴呆症进行二元分类任务性能的潜力，并展示基于QTL方法受噪声影响的效果，研究其可靠性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;使用OASIS 2数据集，研究通过量子技术将次优的古典模型转化为更有效的生物医学图像分类解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;量子技术在痴呆症检测中表现出提高经典模型性能的潜力，并且对噪声的敏感性和鲁棒性得到了研究。&lt;h4&gt;结论&lt;/h4&gt;量子技术在生物医学图像分类和痴呆症预测方面具有潜在的应用价值，可能对医疗技术的进步产生重大影响。&lt;h4&gt;翻译&lt;/h4&gt;This paper explores the application of quantum machine learning (QML) in the prediction of Alzheimer's disease (dementia), especially the potential of quantum transfer learning (QTL) to enhance the performance of a weak classical deep learning model in binary classification tasks for dementia detection. Using the OASIS 2 dataset, the study shows how quantum techniques can transform a suboptimal classical model into a more effective solution for biomedical image classification, highlighting their potential impact on advancing healthcare technology.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dementia is a devastating condition with profound implications forindividuals, families, and healthcare systems. Early and accurate detection ofdementia is critical for timely intervention and improved patient outcomes.While classical machine learning and deep learning approaches have beenexplored extensively for dementia prediction, these solutions often strugglewith high-dimensional biomedical data and large-scale datasets, quicklyreaching computational and performance limitations. To address this challenge,quantum machine learning (QML) has emerged as a promising paradigm, offeringfaster training and advanced pattern recognition capabilities. This work aimsto demonstrate the potential of quantum transfer learning (QTL) to enhance theperformance of a weak classical deep learning model applied to a binaryclassification task for dementia detection. Besides, we show the effect ofnoise on the QTL-based approach, investigating the reliability and robustnessof this method. Using the OASIS 2 dataset, we show how quantum techniques cantransform a suboptimal classical model into a more effective solution forbiomedical image classification, highlighting their potential impact onadvancing healthcare technology.</description>
      <author>example@mail.com (Sounak Bhowmik, Talita Perciano, Himanshu Thapliyal)</author>
      <guid isPermaLink="false">2507.12485v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>FOUNDER: Grounding Foundation Models in World Models for Open-Ended Embodied Decision Making</title>
      <link>http://arxiv.org/abs/2507.12496v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Forty-Second International Conference on Machine Learning  (ICML 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FOUNDER的框架，该框架结合了可迁移知识嵌入在基础模型（FMs）中的能力和动态建模能力世界模型（WMs），以实现无奖励的开放式任务解决。&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）和世界模型（WMs）在不同层次上为任务泛化提供了互补的优势。&lt;h4&gt;目的&lt;/h4&gt;旨在通过FOUNDER框架在具身环境中实现无奖励的开放式任务解决。&lt;h4&gt;方法&lt;/h4&gt;学习一个映射函数，将FM表示与WM状态空间中的状态相对应，从而从外部观察中推断出代理在模拟世界中的物理状态。这种方法通过行为学习中的想象来学习条件策略，映射的任务作为目标状态。利用预测的目标状态时间距离作为信息丰富的奖励信号。&lt;h4&gt;主要发现&lt;/h4&gt;FOUNDER在多种多任务离线视觉控制基准测试中表现出色，特别是在涉及复杂观察或领域差距的情景中，这些是先前方法难以处理的。此外，学习到的奖励函数与真实奖励的一致性也得到了经验验证。&lt;h4&gt;结论&lt;/h4&gt;FOUNDER在捕获由文本或视频指定的任务深层语义方面表现出色，尤其是在复杂观察或领域差距的情景中，并且学习到的奖励函数与真实奖励的一致性得到了验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models (FMs) and World Models (WMs) offer complementary strengthsin task generalization at different levels. In this work, we propose FOUNDER, aframework that integrates the generalizable knowledge embedded in FMs with thedynamic modeling capabilities of WMs to enable open-ended task solving inembodied environments in a reward-free manner. We learn a mapping function thatgrounds FM representations in the WM state space, effectively inferring theagent's physical states in the world simulator from external observations. Thismapping enables the learning of a goal-conditioned policy through imaginationduring behavior learning, with the mapped task serving as the goal state. Ourmethod leverages the predicted temporal distance to the goal state as aninformative reward signal. FOUNDER demonstrates superior performance on variousmulti-task offline visual control benchmarks, excelling in capturing thedeep-level semantics of tasks specified by text or videos, particularly inscenarios involving complex observations or domain gaps where prior methodsstruggle. The consistency of our learned reward function with the ground-truthreward is also empirically validated. Our project website ishttps://sites.google.com/view/founder-rl.</description>
      <author>example@mail.com (Yucen Wang, Rui Yu, Shenghua Wan, Le Gan, De-Chuan Zhan)</author>
      <guid isPermaLink="false">2507.12496v1</guid>
      <pubDate>Fri, 18 Jul 2025 14:25:16 +0800</pubDate>
    </item>
    <item>
      <title>UniLGL: Learning Uniform Place Recognition for FOV-limited/Panoramic LiDAR Global Localization</title>
      <link>http://arxiv.org/abs/2507.12194v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的三维激光扫描定位与建图（LGL）方法，称为UniLGL，该方法同时实现了空间、材料和传感器类型的均匀性。&lt;h4&gt;背景&lt;/h4&gt;现有的LGL方法通常只考虑部分信息（如几何特征）或针对同质激光传感器设计，忽略了LGL的均匀性。&lt;h4&gt;目的&lt;/h4&gt;提出UniLGL方法，旨在同时实现空间、材料和传感器类型的均匀性。&lt;h4&gt;方法&lt;/h4&gt;将包含几何和材料信息的完整点云编码成一对BEV图像（即空间BEV图像和强度BEV图像），并设计了一个端到端的多BEV融合网络来提取均匀特征。引入了视角不变性假设，以实现传感器类型的均匀性。基于二维BEV图像上的局部特征与点云之间的映射，导出了一个鲁棒的全球姿态估计器。&lt;h4&gt;主要发现&lt;/h4&gt;UniLGL在真实世界环境中进行了广泛的基准测试，结果表明，与现有的最先进LGL方法相比，UniLGL具有显著的竞争力。&lt;h4&gt;结论&lt;/h4&gt;UniLGL已经在包括全尺寸卡车和敏捷微型无人机（MAV）在内的多种平台上部署，实现了高精度的定位和建图以及多MAV协作探索，证明了UniLGL在工业和现场场景中的适用性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Existing LGL methods typically consider only partial information (e.g., geometric features) from LiDAR observations or are designed for homogeneous LiDAR sensors, overlooking the uniformity in LGL. In this work, a uniform LGL method is proposed, termed UniLGL, which simultaneously achieves spatial and material uniformity, as well as sensor-type uniformity. The key idea of the proposed method is to encode the complete point cloud, which contains both geometric and material information, into a pair of BEV images (i.e., a spatial BEV image and an intensity BEV image). An end-to-end multi-BEV fusion network is designed to extract uniform features, equipping UniLGL with spatial and material uniformity. To ensure robust LGL across heterogeneous LiDAR sensors, a viewpoint invariance hypothesis is introduced, which replaces the conventional translation equivariance assumption commonly used in existing LPR networks and supervises UniLGL to achieve sensor-type uniformity in both global descriptors and local feature representations. Finally, based on the mapping between local features on the 2D BEV image and the point cloud, a robust global pose estimator is derived that determines the global minimum of the global pose on SE(3) without requiring additional registration. To validate the effectiveness of the proposed uniform LGL, extensive benchmarks are conducted in real-world environments, and the results show that the proposed UniLGL is demonstratively competitive compared to other State-of-the-Art LGL methods. Furthermore, UniLGL has been deployed on diverse platforms, including full-size trucks and agile Micro Aerial Vehicles (MAVs), to enable high-precision localization and mapping as well as multi-MAV collaborative exploration in port and forest environments, demonstrating the applicability of UniLGL in industrial and field scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing LGL methods typically consider only partial information (e.g.,geometric features) from LiDAR observations or are designed for homogeneousLiDAR sensors, overlooking the uniformity in LGL. In this work, a uniform LGLmethod is proposed, termed UniLGL, which simultaneously achieves spatial andmaterial uniformity, as well as sensor-type uniformity. The key idea of theproposed method is to encode the complete point cloud, which contains bothgeometric and material information, into a pair of BEV images (i.e., a spatialBEV image and an intensity BEV image). An end-to-end multi-BEV fusion networkis designed to extract uniform features, equipping UniLGL with spatial andmaterial uniformity. To ensure robust LGL across heterogeneous LiDAR sensors, aviewpoint invariance hypothesis is introduced, which replaces the conventionaltranslation equivariance assumption commonly used in existing LPR networks andsupervises UniLGL to achieve sensor-type uniformity in both global descriptorsand local feature representations. Finally, based on the mapping between localfeatures on the 2D BEV image and the point cloud, a robust global poseestimator is derived that determines the global minimum of the global pose onSE(3) without requiring additional registration. To validate the effectivenessof the proposed uniform LGL, extensive benchmarks are conducted in real-worldenvironments, and the results show that the proposed UniLGL is demonstrativelycompetitive compared to other State-of-the-Art LGL methods. Furthermore, UniLGLhas been deployed on diverse platforms, including full-size trucks and agileMicro Aerial Vehicles (MAVs), to enable high-precision localization and mappingas well as multi-MAV collaborative exploration in port and forest environments,demonstrating the applicability of UniLGL in industrial and field scenarios.</description>
      <author>example@mail.com (Hongming Shen, Xun Chen, Yulin Hui, Zhenyu Wu, Wei Wang, Qiyang Lyu, Tianchen Deng, Danwei Wang)</author>
      <guid isPermaLink="false">2507.12194v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
  <item>
      <title>HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing</title>
      <link>http://arxiv.org/abs/2507.11971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的3D层次代理节点表示方法，旨在解决当前3D表示方法如网格、体素、点云和基于NeRF的神经隐式场在重构、生成、编辑和驱动方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的3D表示方法如网格、NeRF等在精度、渲染质量和编辑性等方面存在不足，且数据复杂性与保真度之间存在权衡。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的3D表示方法，以克服现有方法的局限性，实现高效的表达、高质量的渲染和易于编辑。&lt;h4&gt;方法&lt;/h4&gt;该方法通过使用稀疏的层次化组织（树结构）的代理节点来表示物体的形状和纹理，每个节点存储局部形状和纹理信息，并通过高效的神经网络插值和轻量级解码来查询3D坐标属性。&lt;h4&gt;主要发现&lt;/h4&gt;该框架提供了高度紧凑的表示，节点与局部语义对齐，支持直接拖拽编辑操作，并具有可伸缩的质量-复杂度控制能力。&lt;h4&gt;结论&lt;/h4&gt;通过在3D重构和编辑方面的广泛实验，验证了该方法在表达效率、高保真渲染质量和编辑性方面的优越性。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel 3D Hierarchical Proxy Node representation to address the limitations of current 3D representations like meshes, voxels, point clouds, and NeRF-based neural implicit fields in reconstruction, generation, editing, and driving. The existing 3D representation methods such as meshes and NeRFs have shortcomings in terms of precision, rendering quality, and editability, and there is a trade-off between data complexity and fidelity. The proposed method uses a sparse set of hierarchically organized (tree-structured) proxy nodes to represent the shape and texture of objects, with each node storing local shape and texture information. The properties of any 3D coordinate are queried through efficient neural interpolation and lightweight decoding from relevant nearby and parent nodes. This framework provides a highly compact representation where nodes align with local semantics, enabling direct drag-and-edit manipulation, and offers scalable quality-complexity control. Extensive experiments across 3D reconstruction and editing demonstrate the expressive efficiency, high-fidelity rendering quality, and superior editability of the proposed method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current 3D representations like meshes, voxels, point clouds, and NeRF-basedneural implicit fields exhibit significant limitations: they are oftentask-specific, lacking universal applicability across reconstruction,generation, editing, and driving. While meshes offer high precision, theirdense vertex data complicates editing; NeRFs deliver excellent rendering butsuffer from structural ambiguity, hindering animation and manipulation; allrepresentations inherently struggle with the trade-off between data complexityand fidelity. To overcome these issues, we introduce a novel 3D HierarchicalProxy Node representation. Its core innovation lies in representing an object'sshape and texture via a sparse set of hierarchically organized(tree-structured) proxy nodes distributed on its surface and interior. Eachnode stores local shape and texture information (implicitly encoded by a smallMLP) within its neighborhood. Querying any 3D coordinate's properties involvesefficient neural interpolation and lightweight decoding from relevant nearbyand parent nodes. This framework yields a highly compact representation wherenodes align with local semantics, enabling direct drag-and-edit manipulation,and offers scalable quality-complexity control. Extensive experiments across 3Dreconstruction and editing demonstrate our method's expressive efficiency,high-fidelity rendering quality, and superior editability.</description>
      <author>example@mail.com (Tielong Wang, Yuxuan Xiong, Jinfan Liu, Zhifan Zhang, Ye Chen, Yue Shi, Bingbing Ni)</author>
      <guid isPermaLink="false">2507.11971v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Generating Actionable Robot Knowledge Bases by Combining 3D Scene Graphs with Robot Ontologies</title>
      <link>http://arxiv.org/abs/2507.11770v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures, IEEE/RSJ International Conference on Intelligent  Robots and Systems (IROS2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法，通过开发统一的场景图模型，将多种格式（如MJCF、URDF和SDF）标准化为通用场景描述（USD）格式，以解决机器人环境中数据集成的问题。&lt;h4&gt;背景&lt;/h4&gt;由于场景描述中常用的数据格式（如MJCF、URDF、SDF）的多样性和不兼容性，机器人环境中数据的有效集成一直是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，以标准化不同数据格式，并使复杂的环境数据能够转换为可操作的知识，这对于认知机器人控制至关重要。&lt;h4&gt;方法&lt;/h4&gt;创建了统一的场景图模型，将不同格式的数据标准化为USD格式，并通过语义报告将这些场景图与机器人本体论集成，同时开发了基于Web的可视化工具来支持语义映射过程。&lt;h4&gt;主要发现&lt;/h4&gt;通过将程序化的3D环境转换为USD格式，并对其进行语义标注和知识图谱转换，可以有效地回答能力问题，证明了该方法在实时机器人决策中的应用价值。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法有效地解决了机器人环境中数据集成的问题，为认知机器人控制提供了可操作的知识基础。&lt;h4&gt;翻译&lt;/h4&gt;在机器人领域，由于场景描述中常用的数据格式（如MJCF、URDF、SDF）的多样性和不兼容性，将环境数据有效集成到可操作知识中仍然是一个重大挑战。本文提出了一种新方法，通过开发统一的场景图模型，将这些多样的格式标准化为通用场景描述（USD）格式。这种标准化促进了这些场景图与机器人本体论通过语义报告的集成，使得复杂的环境数据可以转换为认知机器人控制所需的可操作知识。我们通过将程序化的3D环境转换为USD格式并对其进行语义标注，然后将其转换为知识图谱来评估我们的方法，以有效地回答能力问题，展示了其在实时机器人决策中的实用性。此外，我们还开发了一个基于Web的可视化工具，以支持语义映射过程，为用户提供了一个直观的界面来管理3D环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In robotics, the effective integration of environmental data into actionableknowledge remains a significant challenge due to the variety andincompatibility of data formats commonly used in scene descriptions, such asMJCF, URDF, and SDF. This paper presents a novel approach that addresses thesechallenges by developing a unified scene graph model that standardizes thesevaried formats into the Universal Scene Description (USD) format. Thisstandardization facilitates the integration of these scene graphs with robotontologies through semantic reporting, enabling the translation of complexenvironmental data into actionable knowledge essential for cognitive roboticcontrol. We evaluated our approach by converting procedural 3D environmentsinto USD format, which is then annotated semantically and translated into aknowledge graph to effectively answer competency questions, demonstrating itsutility for real-time robotic decision-making. Additionally, we developed aweb-based visualization tool to support the semantic mapping process, providingusers with an intuitive interface to manage the 3D environment.</description>
      <author>example@mail.com (Giang Nguyen, Mihai Pomarlan, Sascha Jongebloed, Nils Leusmann, Minh Nhat Vu, Michael Beetz)</author>
      <guid isPermaLink="false">2507.11770v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Neural Co-state Regulator: A Data-Driven Paradigm for Real-time Optimal Control with Input Constraints</title>
      <link>http://arxiv.org/abs/2507.12259v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的无监督学习框架，用于实时解决具有输入约束的非线性最优控制问题。&lt;h4&gt;背景&lt;/h4&gt;现有的非线性最优控制问题解决方案往往需要依赖专家非线性控制求解器，这些求解器可能不是最优的。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够预测最优共态轨迹的神经网络，从而实现对系统的实时最优控制。&lt;h4&gt;方法&lt;/h4&gt;使用神经网络学习根据庞特里亚金最小原理（PMP）预测最优共态轨迹，并通过求解二次规划（QP）来满足输入约束和最优条件。&lt;h4&gt;主要发现&lt;/h4&gt;神经网络共态调节器（NCR）在收敛误差和输入轨迹平滑度方面优于专家非线性模型预测控制（MPC）求解器，即使在系统条件超出其原始训练域的情况下。&lt;h4&gt;结论&lt;/h4&gt;NCR在计算时间上比非线性MPC快两个数量级，并且能够提供更好的控制性能。&lt;h4&gt;翻译&lt;/h4&gt;We propose a novel unsupervised learning framework for solving nonlinear optimal control problems (OCPs) with input constraints in real-time. In this framework, a neural network (NN) learns to predict the optimal co-state trajectory that minimizes the control Hamiltonian for a given system, at any system's state, based on the Pontryagin's Minimum Principle (PMP). Specifically, the NN is trained to find the norm-optimal co-state solution that simultaneously satisfies the nonlinear system dynamics and minimizes a quadratic regulation cost. The control input is then extracted from the predicted optimal co-state trajectory by solving a quadratic program (QP) to satisfy input constraints and optimality conditions. We coin the term neural co-state regulator (NCR) to describe the combination of the co-state NN and control input QP solver. To demonstrate the effectiveness of the NCR, we compare its feedback control performance with that of an expert nonlinear model predictive control (MPC) solver on a unicycle model. Because the NCR's training does not rely on expert nonlinear control solvers which are often suboptimal, the NCR is able to produce solutions that outperform the nonlinear MPC solver in terms of convergence error and input trajectory smoothness even for system conditions that are outside its original training domain. At the same time, the NCR offers two orders of magnitude less computational time than the nonlinear MPC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel unsupervised learning framework for solving nonlinearoptimal control problems (OCPs) with input constraints in real-time. In thisframework, a neural network (NN) learns to predict the optimal co-statetrajectory that minimizes the control Hamiltonian for a given system, at anysystem's state, based on the Pontryagin's Minimum Principle (PMP).Specifically, the NN is trained to find the norm-optimal co-state solution thatsimultaneously satisfies the nonlinear system dynamics and minimizes aquadratic regulation cost. The control input is then extracted from thepredicted optimal co-state trajectory by solving a quadratic program (QP) tosatisfy input constraints and optimality conditions. We coin the term neuralco-state regulator (NCR) to describe the combination of the co-state NN andcontrol input QP solver. To demonstrate the effectiveness of the NCR, wecompare its feedback control performance with that of an expert nonlinear modelpredictive control (MPC) solver on a unicycle model. Because the NCR's trainingdoes not rely on expert nonlinear control solvers which are often suboptimal,the NCR is able to produce solutions that outperform the nonlinear MPC solverin terms of convergence error and input trajectory smoothness even for systemconditions that are outside its original training domain. At the same time, theNCR offers two orders of magnitude less computational time than the nonlinearMPC.</description>
      <author>example@mail.com (Lihan Lian, Yuxin Tong, Uduak Inyang-Udoh)</author>
      <guid isPermaLink="false">2507.12259v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>CytoSAE: Interpretable Cell Embeddings for Hematology</title>
      <link>http://arxiv.org/abs/2507.12464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CytoSAE的稀疏自编码器，用于医学影像领域，特别是血液学分析，以解释基于transformer的基础模型的推断。&lt;h4&gt;背景&lt;/h4&gt;稀疏自编码器（SAEs）在解释基于transformer的基础模型方面显示出潜力，但用于医学影像的工具仍然不足。&lt;h4&gt;目的&lt;/h4&gt;展示SAEs在血液学领域的适用性，并开发一种能够解释细胞图像中概念的工具。&lt;h4&gt;方法&lt;/h4&gt;CytoSAE在超过40,000张外周血单细胞图像上训练，并能够泛化到不同的数据集，包括骨髓细胞学数据集。它通过医学专家验证识别出形态学相关的概念，并能够生成针对特定患者和疾病的特定概念。&lt;h4&gt;主要发现&lt;/h4&gt;CytoSAE能够检测出具有诊断意义的细胞和局部细胞异常，并在患者级别的急性髓系白血病（AML）亚型分类任务中达到与现有技术相当的性能，同时提供亚细胞级别的可解释性。&lt;h4&gt;结论&lt;/h4&gt;CytoSAE为医学影像提供了可解释性，并在血液学分析中显示出潜力。&lt;h4&gt;翻译&lt;/h4&gt;Sparse autoencoders (SAEs) emerged as a promising tool for mechanistic interpretability of transformer-based foundation models. Very recently, SAEs were also adopted for the visual domain, enabling the discovery of visual concepts and their patch-wise attribution to tokens in the transformer model. While a growing number of foundation models emerged for medical imaging, tools for explaining their inferences are still lacking. In this work, we show the applicability of SAEs for hematology. We propose CytoSAE, a sparse autoencoder which is trained on over 40,000 peripheral blood single-cell images. CytoSAE generalizes to diverse and out-of-domain datasets, including bone marrow cytology, where it identifies morphologically relevant concepts which we validated with medical experts. Furthermore, we demonstrate scenarios in which CytoSAE can generate patient-specific and disease-specific concepts, enabling the detection of pathognomonic cells and localized cellular abnormalities at the patch level. We quantified the effect of concepts on a patient-level AML subtype classification task and show that CytoSAE concepts reach performance comparable to the state-of-the-art, while offering explainability on the sub-cellular level. Source code and model weights are available at https://github.com/dynamical-inference/cytosae.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sparse autoencoders (SAEs) emerged as a promising tool for mechanisticinterpretability of transformer-based foundation models. Very recently, SAEswere also adopted for the visual domain, enabling the discovery of visualconcepts and their patch-wise attribution to tokens in the transformer model.While a growing number of foundation models emerged for medical imaging, toolsfor explaining their inferences are still lacking. In this work, we show theapplicability of SAEs for hematology. We propose CytoSAE, a sparse autoencoderwhich is trained on over 40,000 peripheral blood single-cell images. CytoSAEgeneralizes to diverse and out-of-domain datasets, including bone marrowcytology, where it identifies morphologically relevant concepts which wevalidated with medical experts. Furthermore, we demonstrate scenarios in whichCytoSAE can generate patient-specific and disease-specific concepts, enablingthe detection of pathognomonic cells and localized cellular abnormalities atthe patch level. We quantified the effect of concepts on a patient-level AMLsubtype classification task and show that CytoSAE concepts reach performancecomparable to the state-of-the-art, while offering explainability on thesub-cellular level. Source code and model weights are available athttps://github.com/dynamical-inference/cytosae.</description>
      <author>example@mail.com (Muhammed Furkan Dasdelen, Hyesu Lim, Michele Buck, Katharina S. Götze, Carsten Marr, Steffen Schneider)</author>
      <guid isPermaLink="false">2507.12464v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Cluster Contrast for Unsupervised Visual Representation Learning</title>
      <link>http://arxiv.org/abs/2507.12359v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICIP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CueCo是一种新的无监督视觉表示学习方法，结合了对立学习和聚类方法的优点，旨在同时分散和对齐特征空间中的特征表示。&lt;h4&gt;背景&lt;/h4&gt;CueCo受到最近研究进展的启发，旨在提高无监督视觉表示学习的效果。&lt;h4&gt;目的&lt;/h4&gt;CueCo旨在同时实现特征表示的分散和对齐，以增强类间分离和类内紧凑性。&lt;h4&gt;方法&lt;/h4&gt;CueCo使用两个神经网络，一个查询网络和一个键网络，键网络通过查询输出的慢速移动平均进行更新。该方法采用对比损失来推动不同特征分离，并使用聚类目标来聚集同一簇的特征。&lt;h4&gt;主要发现&lt;/h4&gt;CueCo在CIFAR-10上达到了91.40%的top-1分类准确率，在CIFAR-100上达到了68.56%，在ImageNet-100上达到了78.65%，使用ResNet-18作为骨干网络进行线性评估。&lt;h4&gt;结论&lt;/h4&gt;通过结合对比学习和聚类，CueCo为推进无监督视觉表示学习开辟了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Cluster Contrast (CueCo), a novel approach to unsupervisedvisual representation learning that effectively combines the strengths ofcontrastive learning and clustering methods. Inspired by recent advancements,CueCo is designed to simultaneously scatter and align feature representationswithin the feature space. This method utilizes two neural networks, a query anda key, where the key network is updated through a slow-moving average of thequery outputs. CueCo employs a contrastive loss to push dissimilar featuresapart, enhancing inter-class separation, and a clustering objective to pulltogether features of the same cluster, promoting intra-class compactness. Ourmethod achieves 91.40% top-1 classification accuracy on CIFAR-10, 68.56% onCIFAR-100, and 78.65% on ImageNet-100 using linear evaluation with a ResNet-18backbone. By integrating contrastive learning with clustering, CueCo sets a newdirection for advancing unsupervised visual representation learning.</description>
      <author>example@mail.com (Nikolaos Giakoumoglou, Tania Stathaki)</author>
      <guid isPermaLink="false">2507.12359v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval</title>
      <link>http://arxiv.org/abs/2507.12416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图像检索方法，称为QuRe，通过硬负采样策略优化奖励模型目标，减少错误否定，提高图像检索的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的图像检索方法，如Composed Image Retrieval (CIR)，在检索目标图像时，往往忽略了其他图像的相关性，导致检索结果不准确。&lt;h4&gt;目的&lt;/h4&gt;提出QuRe方法，以解决现有CIR方法中存在的忽略其他图像相关性的问题，提高检索准确性。&lt;h4&gt;方法&lt;/h4&gt;QuRe方法通过以下方式实现：1. 优化奖励模型目标以减少错误否定；2. 引入硬负采样策略，选择位于目标图像后相关性分数急剧下降的图像作为负样本，从而有效过滤错误否定。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，QuRe在FashionIQ和CIRR数据集上取得了最先进的性能，同时在HP-FashionIQ数据集上与人类偏好表现出最强的对齐。&lt;h4&gt;结论&lt;/h4&gt;QuRe方法在图像检索方面取得了显著的改进，提高了检索的准确性和用户满意度。&lt;h4&gt;翻译&lt;/h4&gt;Composed Image Retrieval (CIR) retrieves relevant images based on a reference image and accompanying text describing desired modifications. However, existing CIR methods only focus on retrieving the target image and disregard the relevance of other images. This limitation arises because most methods employing contrastive learning-which treats the target image as positive and all other images in the batch as negatives-can inadvertently include false negatives. This may result in retrieving irrelevant images, reducing user satisfaction even when the target image is retrieved. To address this issue, we propose Query-Relevant Retrieval through Hard Negative Sampling (QuRe), which optimizes a reward model objective to reduce false negatives. Additionally, we introduce a hard negative sampling strategy that selects images positioned between two steep drops in relevance scores following the target image, to effectively filter false negatives. In order to evaluate CIR models on their alignment with human satisfaction, we create Human-Preference FashionIQ (HP-FashionIQ), a new dataset that explicitly captures user preferences beyond target retrieval. Extensive experiments demonstrate that QuRe achieves state-of-the-art performance on FashionIQ and CIRR datasets while exhibiting the strongest alignment with human preferences on the HP-FashionIQ dataset. The source code is available at https://github.com/jackwaky/QuRe.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Composed Image Retrieval (CIR) retrieves relevant images based on a referenceimage and accompanying text describing desired modifications. However, existingCIR methods only focus on retrieving the target image and disregard therelevance of other images. This limitation arises because most methodsemploying contrastive learning-which treats the target image as positive andall other images in the batch as negatives-can inadvertently include falsenegatives. This may result in retrieving irrelevant images, reducing usersatisfaction even when the target image is retrieved. To address this issue, wepropose Query-Relevant Retrieval through Hard Negative Sampling (QuRe), whichoptimizes a reward model objective to reduce false negatives. Additionally, weintroduce a hard negative sampling strategy that selects images positionedbetween two steep drops in relevance scores following the target image, toeffectively filter false negatives. In order to evaluate CIR models on theiralignment with human satisfaction, we create Human-Preference FashionIQ(HP-FashionIQ), a new dataset that explicitly captures user preferences beyondtarget retrieval. Extensive experiments demonstrate that QuRe achievesstate-of-the-art performance on FashionIQ and CIRR datasets while exhibitingthe strongest alignment with human preferences on the HP-FashionIQ dataset. Thesource code is available at https://github.com/jackwaky/QuRe.</description>
      <author>example@mail.com (Jaehyun Kwak, Ramahdani Muhammad Izaaz Inhar, Se-Young Yun, Sung-Ju Lee)</author>
      <guid isPermaLink="false">2507.12416v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior Understanding</title>
      <link>http://arxiv.org/abs/2507.12463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个名为MMHU的大型基准数据集，用于分析人类行为，旨在评估自动驾驶系统中对人类行为理解的程度。&lt;h4&gt;背景&lt;/h4&gt;人类是交通生态系统的重要组成部分，了解人类行为对开发安全驾驶系统至关重要。尽管已有研究探索了人类行为的不同方面，但缺乏一个全面的标准来评估人类行为理解。&lt;h4&gt;目的&lt;/h4&gt;提出一个大规模基准数据集MMHU，用于分析人类行为，以促进自动驾驶系统中对人类行为的理解。&lt;h4&gt;方法&lt;/h4&gt;MMHU数据集包含57k个人类运动片段和1.73M帧画面，来源于多种渠道，包括Waymo等已建立的驾驶数据集、YouTube上的自然视频以及自收集数据。采用人类参与式的标注流程生成丰富的人类行为描述。&lt;h4&gt;主要发现&lt;/h4&gt;MMHU数据集提供了从运动预测到运动生成和人类行为问答的多种任务，为人类行为的全面评估提供了一个广泛的评价套件。&lt;h4&gt;结论&lt;/h4&gt;MMHU为评估自动驾驶系统中对人类行为理解提供了重要的工具，有助于推动自动驾驶技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;Humans are integral components of the transportation ecosystem, and understanding their behaviors is crucial to facilitating the development of safe driving systems. Although recent progress has explored various aspects of human behavior – such as motion, trajectories, and intention – a comprehensive benchmark for evaluating human behavior understanding in autonomous driving remains unavailable. In this work, we propose MMHU, a large-scale benchmark for human behavior analysis featuring rich annotations, such as human motion and trajectories, text description for human motions, human intention, and critical behavior labels relevant to driving safety. Our dataset encompasses 57k human motion clips and 1.73M frames gathered from diverse sources, including established driving datasets such as Waymo, in-the-wild videos from YouTube, and self-collected data. A human-in-the-loop annotation pipeline is developed to generate rich behavior captions. We provide a thorough dataset analysis and benchmark multiple tasks – ranging from motion prediction to motion generation and human behavior question answering – thereby offering a broad evaluation suite. Project page: https://MMHU-Benchmark.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans are integral components of the transportation ecosystem, andunderstanding their behaviors is crucial to facilitating the development ofsafe driving systems. Although recent progress has explored various aspects ofhuman behavior$\unicode{x2014}$such as motion, trajectories, andintention$\unicode{x2014}$a comprehensive benchmark for evaluating humanbehavior understanding in autonomous driving remains unavailable. In this work,we propose $\textbf{MMHU}$, a large-scale benchmark for human behavior analysisfeaturing rich annotations, such as human motion and trajectories, textdescription for human motions, human intention, and critical behavior labelsrelevant to driving safety. Our dataset encompasses 57k human motion clips and1.73M frames gathered from diverse sources, including established drivingdatasets such as Waymo, in-the-wild videos from YouTube, and self-collecteddata. A human-in-the-loop annotation pipeline is developed to generate richbehavior captions. We provide a thorough dataset analysis and benchmarkmultiple tasks$\unicode{x2014}$ranging from motion prediction to motiongeneration and human behavior question answering$\unicode{x2014}$therebyoffering a broad evaluation suite. Project page :https://MMHU-Benchmark.github.io.</description>
      <author>example@mail.com (Renjie Li, Ruijie Ye, Mingyang Wu, Hao Frank Yang, Zhiwen Fan, Hezhen Hu, Zhengzhong Tu)</author>
      <guid isPermaLink="false">2507.12463v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>A Multi-Level Similarity Approach for Single-View Object Grasping: Matching, Planning, and Fine-Tuning</title>
      <link>http://arxiv.org/abs/2507.11938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE T-RO&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从单一视角抓取未知物体的新方法，通过相似性匹配和优化抓取质量来提高抓取的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;抓取未知物体在机器人领域是一个具有挑战性的话题，因为部分观察的不确定性。&lt;h4&gt;目的&lt;/h4&gt;为了解决基于学习的抓取方法对感知噪声和环境变化的敏感性，提出了一种新的抓取方法。&lt;h4&gt;方法&lt;/h4&gt;方法包括三个步骤：1) 利用观察到的物体的视觉特征与包含各种物体模型的现有数据库进行相似性匹配；2) 使用具有预存在抓取知识的候选模型来规划未知目标物体的模仿抓取；3) 通过局部微调过程优化抓取质量。此外，提出了一个多级相似性匹配框架，整合语义、几何和尺寸特征，并引入了C-FPFH描述符来提高匹配精度。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出的方法通过相似性匹配和优化抓取质量，能够鲁棒地从单一视角抓取未知物体。&lt;h4&gt;结论&lt;/h4&gt;该方法通过引入新的相似性匹配框架和优化技术，提高了抓取的鲁棒性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Grasping unknown objects from a single view has remained a challenging topic in robotics due to the uncertainty of partial observation. Recent advances in large-scale models have led to benchmark solutions such as GraspNet-1Billion. However, such learning-based approaches still face a critical limitation in performance robustness for their sensitivity to sensing noise and environmental changes. To address this bottleneck in achieving highly generalized grasping, we abandon the traditional learning framework and introduce a new perspective: similarity matching, where similar known objects are utilized to guide the grasping of unknown target objects. We newly propose a method that robustly achieves unknown-object grasping from a single viewpoint through three key steps: 1) Leverage the visual features of the observed object to perform similarity matching with an existing database containing various object models, identifying potential candidates with high similarity; 2) Use the candidate models with pre-existing grasping knowledge to plan imitative grasps for the unknown target object; 3) Optimize the grasp quality through a local fine-tuning process. To address the uncertainty caused by partial and noisy observation, we propose a multi-level similarity matching framework that integrates semantic, geometric, and dimensional features for comprehensive evaluation. Especially, we introduce a novel point cloud geometric descriptor, the C-FPFH descriptor, which facilitates accurate similarity assessment between partial point clouds of observed objects and complete point clouds of database models. In addition, we incorporate the use of large language models, introduce the semi-oriented bounding box, and develop a novel point cloud registration approach based on plane detection to enhance matching accuracy under single-view conditions. Videos are available at https://youtu.be/qQDIELMhQmk.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TRO.2025.3588720&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasping unknown objects from a single view has remained a challenging topicin robotics due to the uncertainty of partial observation. Recent advances inlarge-scale models have led to benchmark solutions such as GraspNet-1Billion.However, such learning-based approaches still face a critical limitation inperformance robustness for their sensitivity to sensing noise and environmentalchanges. To address this bottleneck in achieving highly generalized grasping,we abandon the traditional learning framework and introduce a new perspective:similarity matching, where similar known objects are utilized to guide thegrasping of unknown target objects. We newly propose a method that robustlyachieves unknown-object grasping from a single viewpoint through three keysteps: 1) Leverage the visual features of the observed object to performsimilarity matching with an existing database containing various object models,identifying potential candidates with high similarity; 2) Use the candidatemodels with pre-existing grasping knowledge to plan imitative grasps for theunknown target object; 3) Optimize the grasp quality through a localfine-tuning process. To address the uncertainty caused by partial and noisyobservation, we propose a multi-level similarity matching framework thatintegrates semantic, geometric, and dimensional features for comprehensiveevaluation. Especially, we introduce a novel point cloud geometric descriptor,the C-FPFH descriptor, which facilitates accurate similarity assessment betweenpartial point clouds of observed objects and complete point clouds of databasemodels. In addition, we incorporate the use of large language models, introducethe semi-oriented bounding box, and develop a novel point cloud registrationapproach based on plane detection to enhance matching accuracy undersingle-view conditions. Videos are available at https://youtu.be/qQDIELMhQmk.</description>
      <author>example@mail.com (Hao Chen, Takuya Kiyokawa, Zhengtao Hu, Weiwei Wan, Kensuke Harada)</author>
      <guid isPermaLink="false">2507.11938v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Calisthenics Skills Temporal Video Segmentation</title>
      <link>http://arxiv.org/abs/2507.12245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures, In Proceedings of the 19th International Joint  Conference on Computer Vision, Imaging and Computer Graphics Theory and  Applications - Volume 2&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对健美操技能时间分割的自动工具，并构建了一个包含运动员静态健美操技能视频及其时间分割的数据集。&lt;h4&gt;背景&lt;/h4&gt;健美操是一项快速发展的体重训练项目，包含多种技能类别，其中一种专注于技能训练。目前，缺乏能够从视频中识别等长技能并估计其持续时间的自动化工具。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在为健美操领域自动化工具的实施提供初步步骤，并通过提出一种基于身体姿态分析的动作识别方法来推进相关知识。&lt;h4&gt;方法&lt;/h4&gt;研究者构建了一个包含静态健美操技能视频及其时间分割的数据集，并报告了在所提出的数据集上实现技能时间分割的基线方法的结果。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果突出了所提出问题的可行性，但也表明仍有改进的空间。&lt;h4&gt;结论&lt;/h4&gt;本研究为健美操技能时间分割的自动化工具提供了初步方案，并为进一步的研究奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.5220/0012400600003660&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Calisthenics is a fast-growing bodyweight discipline that consists ofdifferent categories, one of which is focused on skills. Skills in calisthenicsencompass both static and dynamic elements performed by athletes. Theevaluation of static skills is based on their difficulty level and the durationof the hold. Automated tools able to recognize isometric skills from a video bysegmenting them to estimate their duration would be desirable to assistathletes in their training and judges during competitions. Although the videounderstanding literature on action recognition through body pose analysis isrich, no previous work has specifically addressed the problem of calisthenicsskill temporal video segmentation. This study aims to provide an initial steptowards the implementation of automated tools within the field of Calisthenics.To advance knowledge in this context, we propose a dataset of video footage ofstatic calisthenics skills performed by athletes. Each video is annotated witha temporal segmentation which determines the extent of each skill. We hencereport the results of a baseline approach to address the problem of skilltemporal segmentation on the proposed dataset. The results highlight thefeasibility of the proposed problem, while there is still room for improvement.</description>
      <author>example@mail.com (Antonio Finocchiaro, Giovanni Maria Farinella, Antonino Furnari)</author>
      <guid isPermaLink="false">2507.12245v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Heat Kernel Goes Topological</title>
      <link>http://arxiv.org/abs/2507.12380v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的拓扑神经网络框架，该框架通过在组合复形上引入拉普拉斯算子，实现了高效的热核计算，从而作为节点描述符。该方法捕捉多尺度信息，并支持置换等变表示，便于集成到现代基于transformer的架构中。&lt;h4&gt;背景&lt;/h4&gt;拓扑神经网络作为图神经网络的继任者，在处理复杂结构的数据时表现出强大的能力。然而，传统拓扑神经网络通常涉及高阶消息传递，导致计算成本高昂。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效且具有表达能力的拓扑神经网络框架，以降低计算成本并提高性能。&lt;h4&gt;方法&lt;/h4&gt;在组合复形上引入拉普拉斯算子，实现热核的高效计算，并捕捉多尺度信息，支持置换等变表示。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在理论上具有最大表达能力，能够区分任意非同构的组合复形；在实证上，该方法在计算效率上显著优于现有拓扑方法，并在标准分子数据集上与最先进的描述符相比具有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;该工作通过提供具有表达力和可扩展性的表示，推动了拓扑深度学习的发展，为分子分类和性质预测任务开辟了新的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;拓扑神经网络已经成为图神经网络的强大继任者。然而，它们通常涉及高阶消息传递，这导致了显著的计算开销。我们通过引入一个新的拓扑框架来规避这个问题，该框架在组合复形（CCs）上引入了拉普拉斯算子，从而实现了热核的高效计算，这些热核可以作为节点描述符。我们的方法捕捉了多尺度信息，并允许进行置换等变表示，这使得它们可以轻松集成到现代基于transformer的架构中。从理论上看，所提出的方法具有最大的表达能力，因为它可以区分任意非同构的组合复形。从实证上看，它在计算效率方面显著优于现有的拓扑方法。除了在标准分子数据集上与最先进的描述符具有竞争力的性能外，它还在拓扑基准测试中表现出区分复杂拓扑结构并避免盲点的优越能力。总的来说，这项工作通过提供具有表达力和可扩展性的表示，推动了拓扑深度学习的发展，从而为分子分类和性质预测任务开辟了令人兴奋的新途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Topological neural networks have emerged as powerful successors of graphneural networks. However, they typically involve higher-order message passing,which incurs significant computational expense. We circumvent this issue with anovel topological framework that introduces a Laplacian operator oncombinatorial complexes (CCs), enabling efficient computation of heat kernelsthat serve as node descriptors. Our approach captures multiscale informationand enables permutation-equivariant representations, allowing easy integrationinto modern transformer-based architectures.  Theoretically, the proposed method is maximally expressive because it candistinguish arbitrary non-isomorphic CCs. Empirically, it significantlyoutperforms existing topological methods in terms of computational efficiency.Besides demonstrating competitive performance with the state-of-the-artdescriptors on standard molecular datasets, it exhibits superior capability indistinguishing complex topological structures and avoiding blind spots ontopological benchmarks. Overall, this work advances topological deep learningby providing expressive yet scalable representations, thereby opening upexciting avenues for molecular classification and property prediction tasks.</description>
      <author>example@mail.com (Maximilian Krahn, Vikas Garg)</author>
      <guid isPermaLink="false">2507.12380v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis</title>
      <link>http://arxiv.org/abs/2507.11730v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在现实条件下准确验证户外广告牌文本可见性的挑战，并比较了多模态视觉语言模型（VLMs）和传统光学字符识别（OCR）在识别户外场景文本方面的性能。&lt;h4&gt;背景&lt;/h4&gt;户外广告是现代营销的重要媒介，但在实际条件下验证广告牌文本的可见性仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究旨在评估多模态视觉语言模型（VLMs）在户外场景文本识别方面的能力，并与传统的CNN-based OCR基准进行比较。&lt;h4&gt;方法&lt;/h4&gt;本研究系统性地评估了包括Qwen 2.5 VL 3B、InternVL3和SmolVLM2在内的代表性VLMs，在两个公共数据集（ICDAR 2015和SVT）上，通过与合成天气扭曲相结合，模拟真实退化情况，与轻量级的CNN-based OCR基准（PaddleOCRv4）进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;虽然一些VLMs在整体场景推理方面表现出色，但轻量级的CNN管道在以极低的计算成本下仍然能够实现有竞争力的识别精度，这对于边缘部署来说是一个重要的考虑因素。&lt;h4&gt;结论&lt;/h4&gt;为了促进未来的研究，本文公开了天气增强的基准和评估代码。&lt;h4&gt;翻译&lt;/h4&gt;Outdoor advertisements remain a critical medium for modern marketing, yet accurately verifying billboard text visibility under real-world conditions is still challenging. Traditional Optical Character Recognition (OCR) pipelines excel at cropped text recognition but often struggle with complex outdoorscenes, varying fonts, and weather-induced visual noise. Recently, multimodal Vision-Language Models (VLMs) have emerged as promising alternatives, offering end-to-end scene understanding with no explicit detection step. This work systematically benchmarks representative VLMs - including Qwen 2.5 VL 3B, InternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline (PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented with synthetic weather distortions to simulate realistic degradation. Our results reveal that while selected VLMs excel at holistic scene reasoning, lightweight CNN pipelines still achieve competitive accuracy for cropped text at a fraction of the computational cost-an important consideration for edge deployment. To foster future research, we release our weather-augmented benchmark and evaluation code publicly.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Outdoor advertisements remain a critical medium for modern marketing, yetaccurately verifying billboard text visibility under real-world conditions isstill challenging. Traditional Optical Character Recognition (OCR) pipelinesexcel at cropped text recognition but often struggle with complex outdoorscenes, varying fonts, and weather-induced visual noise. Recently, multimodalVision-Language Models (VLMs) have emerged as promising alternatives, offeringend-to-end scene understanding with no explicit detection step. This worksystematically benchmarks representative VLMs - including Qwen 2.5 VL 3B,InternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline(PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented withsynthetic weather distortions to simulate realistic degradation. Our resultsreveal that while selected VLMs excel at holistic scene reasoning, lightweightCNN pipelines still achieve competitive accuracy for cropped text at a fractionof the computational cost-an important consideration for edge deployment. Tofoster future research, we release our weather-augmented benchmark andevaluation code publicly.</description>
      <author>example@mail.com (Maciej Szankin, Vidhyananth Venkatasamy, Lihang Ying)</author>
      <guid isPermaLink="false">2507.11730v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>PRISM: Distributed Inference for Foundation Models at Edge</title>
      <link>http://arxiv.org/abs/2507.12145v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PRISM是一种用于边缘设备的分布式Transformer推理的通信高效和计算感知策略。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型在众多应用中取得了显著成功，但其在边缘部署时面临着重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种将基础模型部署到边缘环境中的实用和高效的策略。&lt;h4&gt;方法&lt;/h4&gt;PRISM利用Segment Means表示来近似中间输出特征，显著减少了设备间的通信。它重构了自注意力机制，消除了位置分区内每个设备Key/Value计算的冗余计算，并设计了一种适用于自回归模型的分区感知因果掩码方案。&lt;h4&gt;主要发现&lt;/h4&gt;PRISM在ViT、BERT和GPT-2上进行了评估，结果显示通信开销大幅减少（BERT的压缩率为CR = 128时，减少到99.2%），每个设备的计算量也减少了51.24%，同时只有轻微的精度下降。&lt;h4&gt;结论&lt;/h4&gt;PRISM为在分布式资源受限环境中部署基础模型提供了一个可扩展且实用的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) have achieved remarkable success across a wide rangeof applications, from image classification to natural langurage processing, butpose significant challenges for deployment at edge. This has sparked growinginterest in developing practical and efficient strategies for bringingfoundation models to edge environments. In this work, we propose PRISM, acommunication-efficient and compute-aware strategy for distributed Transformerinference on edge devices. Our method leverages a Segment Means representationto approximate intermediate output features, drastically reducing inter-devicecommunication. Additionally, we restructure the self-attention mechanism toeliminate redundant computations caused by per-device Key/Value calculation inposition-wise partitioning and design a partition-aware causal masking schemetailored for autoregressive models. We evaluate PRISM on ViT, BERT, and GPT-2across diverse datasets, namely CIFAR-10, CIFAR-100, ImageNet-1k, GLUE, andCBT. Our results demonstrate substantial reductions in communication overhead(up to 99.2% for BERT at compression rate CR = 128) and per-device computation(51.24% for BERT at the same setting), with only minor accuracy degradation.This method offers a scalable and practical solution for deploying foundationmodels in distributed resource-constrained environments.</description>
      <author>example@mail.com (Muhammad Azlan Qazi, Alexandros Iosifidis, Qi Zhang)</author>
      <guid isPermaLink="false">2507.12145v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification</title>
      <link>http://arxiv.org/abs/2507.12177v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的双集成框架，用于提高脑肿瘤诊断的准确性。&lt;h4&gt;背景&lt;/h4&gt;MRI是检测肿瘤的可靠工具，但人工诊断的准确性可能因疲劳、专业知识有限和图像细节不足而受损。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题并提高诊断精度，本研究提出了一种新的双集成框架，包括用于特征提取的集成预训练深度学习模型和用于分类的集成微调超参数机器学习模型。&lt;h4&gt;方法&lt;/h4&gt;该方法包括大量的预处理和增强，通过利用各种预训练的深度卷积神经网络和视觉Transformer网络从脑MRI中提取深度特征，并微调机器学习分类器的超参数。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的特征融合和分类器融合优于现有技术，而超参数微调提供了对集成方法的显著增强。此外，消融研究说明了每个组件对准确脑肿瘤分类的贡献。&lt;h4&gt;结论&lt;/h4&gt;所提出的双集成框架有效地提高了脑肿瘤分类的准确性，并通过超参数微调进一步增强了诊断性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Magnetic Resonance Imaging (MRI) is widely recognized as the most reliabletool for detecting tumors due to its capability to produce detailed images thatreveal their presence. However, the accuracy of diagnosis can be compromisedwhen human specialists evaluate these images. Factors such as fatigue, limitedexpertise, and insufficient image detail can lead to errors. For example, smalltumors might go unnoticed, or overlap with healthy brain regions could resultin misidentification. To address these challenges and enhance diagnosticprecision, this study proposes a novel double ensembling framework, consistingof ensembled pre-trained deep learning (DL) models for feature extraction andensembled fine-tuned hyperparameter machine learning (ML) models to efficientlyclassify brain tumors. Specifically, our method includes extensivepreprocessing and augmentation, transfer learning concepts by utilizing variouspre-trained deep convolutional neural networks and vision transformer networksto extract deep features from brain MRI, and fine-tune hyperparameters of MLclassifiers. Our experiments utilized three different publicly available KaggleMRI brain tumor datasets to evaluate the pre-trained DL feature extractormodels, ML classifiers, and the effectiveness of an ensemble of deep featuresalong with an ensemble of ML classifiers for brain tumor classification. Ourresults indicate that the proposed feature fusion and classifier fusion improveupon the state of the art, with hyperparameter fine-tuning providing asignificant enhancement over the ensemble method. Additionally, we present anablation study to illustrate how each component contributes to accurate braintumor classification.</description>
      <author>example@mail.com (Zahid Ullah, Dragan Pamucar, Jihie Kim)</author>
      <guid isPermaLink="false">2507.12177v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Incorporating Fairness Constraints into Archetypal Analysis</title>
      <link>http://arxiv.org/abs/2507.12021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了公平原型分析（FairAA）和公平核原型分析（FairKernelAA），用于解决Archetypal Analysis（AA）在数据中编码敏感属性导致的不公平问题。&lt;h4&gt;背景&lt;/h4&gt;AA是一种无监督学习方法，能够以可解释和低维度的形式表示数据。然而，AA可能无意中编码敏感属性，引发公平性问题。&lt;h4&gt;目的&lt;/h4&gt;提出公平AA和公平核AA，以降低敏感群体信息对学习投影的影响，同时保持原型的结构和可解释性。&lt;h4&gt;方法&lt;/h4&gt;在FairAA中，引入了公平正则化项；在FairKernelAA中，采用非线性扩展来处理更复杂的数据分布。&lt;h4&gt;主要发现&lt;/h4&gt;FairAA和FairKernelAA在合成数据集上评估良好，能够降低群体可分性，同时不显著降低解释方差。在现实世界的数据集上也验证了其鲁棒性和实用性。&lt;h4&gt;结论&lt;/h4&gt;FairAA在效用和公平性之间取得了良好的平衡，是负责的学习表示的有前途的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：原型分析（AA）是一种无监督学习方法，将数据表示为称为原型的极端模式的凸组合。虽然AA提供了可解释的且低维度的表示，但它可能无意中编码敏感属性，导致公平性问题。在本工作中，我们提出了公平原型分析（FairAA），这是一种修改后的公式，明确减少了敏感群体信息在学习的投影中的影响。我们还引入了公平核AA，这是一种非线性扩展，用于解决更复杂的数据分布中的公平性问题。我们的方法结合了公平正则化项，同时保持了原型的结构和可解释性。我们在包括线性、非线性和多组场景的合成数据集上评估了FairAA和FairKernelAA，证明了它们降低群体可分性的能力——通过平均最大差异和线性可分性来衡量——而不显著牺牲解释方差。我们还在现实世界的ANSUR I数据集上进一步验证了我们的方法，证实了它们的鲁棒性和实用性。结果表明，FairAA在效用和公平性之间实现了良好的权衡，使其成为敏感应用中负责的学习表示的有前途的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Archetypal Analysis (AA) is an unsupervised learning method that representsdata as convex combinations of extreme patterns called archetypes. While AAprovides interpretable and low-dimensional representations, it caninadvertently encode sensitive attributes, leading to fairness concerns. Inthis work, we propose Fair Archetypal Analysis (FairAA), a modified formulationthat explicitly reduces the influence of sensitive group information in thelearned projections. We also introduce FairKernelAA, a nonlinear extension thataddresses fairness in more complex data distributions. Our approachincorporates a fairness regularization term while preserving the structure andinterpretability of the archetypes. We evaluate FairAA and FairKernelAA onsynthetic datasets, including linear, nonlinear, and multi-group scenarios,demonstrating their ability to reduce group separability -- as measured by meanmaximum discrepancy and linear separability -- without substantiallycompromising explained variance. We further validate our methods on thereal-world ANSUR I dataset, confirming their robustness and practical utility.The results show that FairAA achieves a favorable trade-off between utility andfairness, making it a promising tool for responsible representation learning insensitive applications.</description>
      <author>example@mail.com (Aleix Alcacer, Irene Epifanio)</author>
      <guid isPermaLink="false">2507.12021v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Catching Bid-rigging Cartels with Graph Attention Neural Networks</title>
      <link>http://arxiv.org/abs/2507.12369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于图注意力网络（GATs）的深度学习算法，用于检测合谋行为，并在多个市场数据集上进行了测试。&lt;h4&gt;背景&lt;/h4&gt;合谋行为是市场竞争中的一个问题，需要有效的检测方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的算法，利用先前研究中的预测特征，来检测合谋行为。&lt;h4&gt;方法&lt;/h4&gt;使用GATs在部分市场数据集上训练预测模型，并将模型应用于其他市场，以检测合谋行为。&lt;h4&gt;主要发现&lt;/h4&gt;基于GATs的模型在不同市场间具有可迁移性，准确率在80%到90%之间，最佳配置在瑞士和冲绳市场达到91%的平均准确率。该方法在12个市场的测试中保持了高准确率（平均84%），超越了传统的集成学习方法。&lt;h4&gt;结论&lt;/h4&gt;GATs基础上的检测方法为竞争监管机构筛选潜在卡特尔活动提供了有希望的工具。&lt;h4&gt;翻译&lt;/h4&gt;We propose a novel application of graph attention networks (GATs), a type of graph neural network enhanced with attention mechanisms, to develop a deep learning algorithm for detecting collusive behavior, leveraging predictive features suggested in prior research. We test our approach on a large dataset covering 13 markets across seven countries. Our results show that predictive models based on GATs, trained on a subset of the markets, can be effectively transferred to other markets, achieving accuracy rates between 80% and 90%, depending on the hyperparameter settings. The best-performing configuration, applied to eight markets from Switzerland and the Japanese region of Okinawa, yields an average accuracy of 91% for cross-market prediction. When extended to 12 markets, the method maintains a strong performance with an average accuracy of 84%, surpassing traditional ensemble approaches in machine learning. These results suggest that GAT-based detection methods offer a promising tool for competition authorities to screen markets for potential cartel activity.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel application of graph attention networks (GATs), a type ofgraph neural network enhanced with attention mechanisms, to develop a deeplearning algorithm for detecting collusive behavior, leveraging predictivefeatures suggested in prior research. We test our approach on a large datasetcovering 13 markets across seven countries. Our results show that predictivemodels based on GATs, trained on a subset of the markets, can be effectivelytransferred to other markets, achieving accuracy rates between 80\% and 90\%,depending on the hyperparameter settings. The best-performing configuration,applied to eight markets from Switzerland and the Japanese region of Okinawa,yields an average accuracy of 91% for cross-market prediction. When extended to12 markets, the method maintains a strong performance with an average accuracyof 84\%, surpassing traditional ensemble approaches in machine learning. Theseresults suggest that GAT-based detection methods offer a promising tool forcompetition authorities to screen markets for potential cartel activity.</description>
      <author>example@mail.com (David Imhof, Emanuel W Viklund, Martin Huber)</author>
      <guid isPermaLink="false">2507.12369v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph</title>
      <link>http://arxiv.org/abs/2507.12123v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 5 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为OVIGo-3DHSG的方法，用于室内环境中对象的开放词汇定位，该方法基于3D分层场景图，通过处理RGB-D帧序列，结合开放词汇基础模型和传感器数据。&lt;h4&gt;背景&lt;/h4&gt;室内环境的理解和对象定位对于需要空间推理和室内环境理解的应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效理解场景和实现鲁棒对象定位的方法。&lt;h4&gt;方法&lt;/h4&gt;OVIGo-3DHSG方法使用分层场景图来明确建模楼层、房间、位置和对象之间的空间关系，并集成大型语言模型以进行多步推理，以处理涉及其他对象空间参考的复杂查询。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Habitat Matterport 3D语义多楼层场景上研究了分层表示的语义和几何精度，与现有方法相比，在场景理解和对象定位方面表现出高效和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;OVIGo-3DHSG在需要空间推理和室内环境理解的应用中展现出强大的潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为OVIGo-3DHSG的方法——基于3D分层场景图的开放词汇室内对象定位。OVIGo-3DHSG代表了一个基于RGB-D帧序列的广泛室内环境，通过使用一组开放词汇基础模型和传感器数据处理而得到。分层表示明确地建模了楼层、房间、位置和对象之间的空间关系。为了有效地处理涉及对其他对象空间引用的复杂查询，我们将分层场景图与大型语言模型相结合进行多步推理。这种集成利用了层间连接（例如，房间到对象）和层内连接（例如，对象到对象），增强了空间上下文理解。我们在Habitat Matterport 3D语义多楼层场景上研究了分层表示的语义和几何精度。与现有方法相比，我们的方法在场景理解和对象定位方面表现出高效和鲁棒性。总体而言，OVIGo-3DHSG在需要空间推理和室内环境理解的应用中展现出强大的潜力。相关材料可在https://github.com/linukc/OVIGo-3DHSG找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose OVIGo-3DHSG method - Open-Vocabulary Indoor Grounding of objectsusing 3D Hierarchical Scene Graph. OVIGo-3DHSG represents an extensive indoorenvironment over a Hierarchical Scene Graph derived from sequences of RGB-Dframes utilizing a set of open-vocabulary foundation models and sensor dataprocessing. The hierarchical representation explicitly models spatial relationsacross floors, rooms, locations, and objects. To effectively address complexqueries involving spatial reference to other objects, we integrate thehierarchical scene graph with a Large Language Model for multistep reasoning.This integration leverages inter-layer (e.g., room-to-object) and intra-layer(e.g., object-to-object) connections, enhancing spatial contextualunderstanding. We investigate the semantic and geometry accuracy ofhierarchical representation on Habitat Matterport 3D Semantic multi-floorscenes. Our approach demonstrates efficient scene comprehension and robustobject grounding compared to existing methods. Overall OVIGo-3DHSG demonstratesstrong potential for applications requiring spatial reasoning and understandingof indoor environments. Related materials can be found athttps://github.com/linukc/OVIGo-3DHSG.</description>
      <author>example@mail.com (Sergey Linok, Gleb Naumov)</author>
      <guid isPermaLink="false">2507.12123v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery</title>
      <link>http://arxiv.org/abs/2507.11570v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发并评估了机器学习模型以预测择期脊柱手术的住院时间（LOS），重点关注时间建模和模型可解释性的益处。&lt;h4&gt;背景&lt;/h4&gt;研究比较了传统的机器学习模型（如线性回归、随机森林、支持向量机（SVM）和XGBoost）与开发的SurgeryLSTM模型，该模型是一种具有注意力的掩码双向长短期记忆（BiLSTM），并使用结构化围手术期电子健康记录（EHR）数据。&lt;h4&gt;目的&lt;/h4&gt;开发并评估机器学习模型，以预测择期脊柱手术的住院时间，并关注时间建模和模型可解释性的益处。&lt;h4&gt;方法&lt;/h4&gt;使用结构化围手术期电子健康记录（EHR）数据，比较了传统的机器学习模型与SurgeryLSTM模型，并使用决定系数（R2）评估性能，使用可解释人工智能（AI）识别关键预测因子。&lt;h4&gt;主要发现&lt;/h4&gt;SurgeryLSTM模型实现了最高的预测准确性（R2=0.86），优于XGBoost（R2 = 0.85）和基线模型。注意力机制通过动态识别术前临床序列中的关键时间段，提高了可解释性，并确定了骨疾病、慢性肾病和腰椎融合是影响住院时间的关键预测因子。&lt;h4&gt;结论&lt;/h4&gt;SurgeryLSTM模型为择期脊柱手术的住院时间预测提供了一个有效且可解释的AI解决方案，支持将时间、可解释的机器学习方法集成到临床决策支持系统中，以提高出院准备和个性化患者护理。&lt;h4&gt;翻译&lt;/h4&gt;Objective: To develop and evaluate machine learning (ML) models for predicting length of stay (LOS) in elective spine surgery, with a focus on the benefits of temporal modeling and model interpretability. Materials and Methods: We compared traditional ML models (e.g., linear regression, random forest, support vector machine (SVM), and XGBoost) with our developed model, SurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an attention, using structured perioperative electronic health records (EHR) data. Performance was evaluated using the coefficient of determination (R2), and key predictors were identified using explainable AI. Results: SurgeryLSTM achieved the highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85) and baseline models. The attention mechanism improved interpretability by dynamically identifying influential temporal segments within preoperative clinical sequences, allowing clinicians to trace which events or features most contributed to each LOS prediction. Key predictors of LOS included bonedisorder, chronic kidney disease, and lumbar fusion identified as the most impactful predictors of LOS. Discussion: Temporal modeling with attention mechanisms significantly improves LOS prediction by capturing the sequential nature of patient data. Unlike static models, SurgeryLSTM provides both higher accuracy and greater interpretability, which are critical for clinical adoption. These results highlight the potential of integrating attention-based temporal models into hospital planning workflows. Conclusion: SurgeryLSTM presents an effective and interpretable AI solution for LOS prediction in elective spine surgery. Our findings support the integration of temporal, explainable ML approaches into clinical decision support systems to enhance discharge readiness and individualized patient care.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1093/jamiaopen/ooaf079&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Objective: To develop and evaluate machine learning (ML) models forpredicting length of stay (LOS) in elective spine surgery, with a focus on thebenefits of temporal modeling and model interpretability. Materials andMethods: We compared traditional ML models (e.g., linear regression, randomforest, support vector machine (SVM), and XGBoost) with our developed model,SurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with anattention, using structured perioperative electronic health records (EHR) data.Performance was evaluated using the coefficient of determination (R2), and keypredictors were identified using explainable AI. Results: SurgeryLSTM achievedthe highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85)and baseline models. The attention mechanism improved interpretability bydynamically identifying influential temporal segments within preoperativeclinical sequences, allowing clinicians to trace which events or features mostcontributed to each LOS prediction. Key predictors of LOS included bonedisorder, chronic kidney disease, and lumbar fusion identified as the mostimpactful predictors of LOS. Discussion: Temporal modeling with attentionmechanisms significantly improves LOS prediction by capturing the sequentialnature of patient data. Unlike static models, SurgeryLSTM provides both higheraccuracy and greater interpretability, which are critical for clinicaladoption. These results highlight the potential of integrating attention-basedtemporal models into hospital planning workflows. Conclusion: SurgeryLSTMpresents an effective and interpretable AI solution for LOS prediction inelective spine surgery. Our findings support the integration of temporal,explainable ML approaches into clinical decision support systems to enhancedischarge readiness and individualized patient care.</description>
      <author>example@mail.com (Ha Na Cho, Sairam Sutari, Alexander Lopez, Hansen Bow, Kai Zheng)</author>
      <guid isPermaLink="false">2507.11570v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning</title>
      <link>http://arxiv.org/abs/2507.12079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was accepted for the special issue AI for Education by the  IEEE Signal Processing Magazine journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种结合苏格拉底方法、思维链推理、简化游戏化和形成性反馈的干预研究，旨在探讨这些方法对大学学生数学学习的影响，特别是由大型语言模型（LLMs）驱动的数学学习。&lt;h4&gt;背景&lt;/h4&gt;许多学生在数学学习中遇到困难，因此避免与数学相关的学科，尽管数学在许多领域，包括信号处理中都非常重要。这些问题往往源于教学方法不当。&lt;h4&gt;目的&lt;/h4&gt;研究结合的干预方法（MEGA）对提高大学学生数学学习效果的有效性。&lt;h4&gt;方法&lt;/h4&gt;将MEGA方法与传统的逐步思维链（CoT）方法进行比较。随机分配问题给参与者（大学学生），并从GSM8K和MATH数据集中抽取样本（n=60）用于评估两个LLMs（GPT4o和Claude 3.5 Sonnet）的能力。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，学生在大多数情况下认为MEGA方法比CoT方法更适合学习。在更困难的MATH数据集中，MEGA（47.5%）的表现甚至优于CoT（26.67%），表明MEGA在解释复杂的数学问题方面表现更佳。&lt;h4&gt;结论&lt;/h4&gt;MEGA方法在帮助学生理解和学习复杂的数学问题方面比传统的CoT方法更有效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an intervention study on the effects of the combinedmethods of (1) the Socratic method, (2) Chain of Thought (CoT) reasoning, (3)simplified gamification and (4) formative feedback on university students'Maths learning driven by large language models (LLMs). We call our approachMathematics Explanations through Games by AI LLMs (MEGA). Some studentsstruggle with Maths and as a result avoid Math-related discipline or subjectsdespite the importance of Maths across many fields, including signalprocessing. Oftentimes, students' Maths difficulties stem from suboptimalpedagogy. We compared the MEGA method to the traditional step-by-step (CoT)method to ascertain which is better by using a within-group design afterrandomly assigning questions for the participants, who are university students.Samples (n=60) were randomly drawn from each of the two test sets of the GradeSchool Math 8K (GSM8K) and Mathematics Aptitude Test of Heuristics (MATH)datasets, based on the error margin of 11%, the confidence level of 90%, and amanageable number of samples for the student evaluators. These samples wereused to evaluate two capable LLMs at length (Generative Pretrained Transformer4o (GPT4o) and Claude 3.5 Sonnet) out of the initial six that were tested forcapability. The results showed that students agree in more instances that theMEGA method is experienced as better for learning for both datasets. It is evenmuch better than the CoT (47.5% compared to 26.67%) in the more difficult MATHdataset, indicating that MEGA is better at explaining difficult Maths problems.</description>
      <author>example@mail.com (Tosin Adewumi, Foteini Simistira Liwicki, Marcus Liwicki, Viktor Gardelli, Lama Alkhaled, Hamam Mokayed)</author>
      <guid isPermaLink="false">2507.12079v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>DeepShade: Enable Shade Simulation by Text-conditioned Image Generation</title>
      <link>http://arxiv.org/abs/2507.12103v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7pages, 4 figures. Accepted to IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对热浪对公共健康构成的威胁，以及现有路线系统无法整合阴影信息的问题，提出了一种新的方法来学习和合成阴影变化。&lt;h4&gt;背景&lt;/h4&gt;热浪对公共健康构成重大威胁，而全球变暖加剧了这一问题。目前，由于从噪声卫星图像中直接估计阴影的困难以及生成模型训练数据的有限可用性，现有路线系统（如在线地图）无法整合阴影信息。&lt;h4&gt;目的&lt;/h4&gt;解决上述挑战，提高路线系统中阴影信息的整合能力。&lt;h4&gt;方法&lt;/h4&gt;1. 构建了一个覆盖不同经纬度区域、建筑密度水平和城市布局的广泛数据集。利用基于Blender的3D模拟和建筑轮廓，捕捉全年不同太阳高度角和一天中不同时间段的建筑阴影。2. 提出了一种名为DeepShade的基于扩散的模型，用于学习和合成随时间变化的阴影变化。该模型通过结合RGB和Canny边缘层来强调边缘特征的细微差别，并采用对比学习来捕捉阴影的时变规则。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟阴影并与卫星图像对齐，为学习阴影模式提供了丰富的资源。DeepShade模型能够有效地生成阴影图像，并在实际的路线规划中提供了阴影预测。&lt;h4&gt;结论&lt;/h4&gt;本研究有助于城市规划和极端高温天气下的参考，并在环境保护中具有潜在的实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：热浪对公共健康构成了重大威胁，尤其是在全球变暖加剧的情况下。然而，由于直接从噪声卫星图像中估计阴影的困难以及生成模型训练数据的有限可用性，当前的路线系统（例如在线地图）无法整合阴影信息。在本文中，我们通过以下两个主要贡献来应对这些挑战。首先，我们构建了一个涵盖不同经纬度区域、不同建筑密度水平和不同城市布局的广泛数据集。利用基于Blender的3D模拟和建筑轮廓，我们捕捉了全年不同太阳高度角和一天中不同时间段的建筑阴影。这些模拟阴影与卫星图像对齐，为学习阴影模式提供了丰富的资源。其次，我们提出了一种名为DeepShade的基于扩散的模型，旨在学习和合成随时间变化的阴影变化。该模型通过结合RGB和Canny边缘层来强调边缘特征的细微差别，并采用对比学习来捕捉阴影的时变规则。然后，通过基于已知条件（例如一天中的时间，太阳角度）的文本描述进行条件化，我们的框架在生成阴影图像方面提供了改进的性能。我们通过使用我们的阴影预测来计算亚利桑那州图森市实际路线规划中的阴影比率，展示了我们方法的有效性。我们相信这项工作将通过为极端高温天气的城市规划提供参考，并在环境保护中具有潜在的实际应用价值而造福社会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heatwaves pose a significant threat to public health, especially as globalwarming intensifies. However, current routing systems (e.g., online maps) failto incorporate shade information due to the difficulty of estimating shadesdirectly from noisy satellite imagery and the limited availability of trainingdata for generative models. In this paper, we address these challenges throughtwo main contributions. First, we build an extensive dataset covering diverselongitude-latitude regions, varying levels of building density, and differenturban layouts. Leveraging Blender-based 3D simulations alongside buildingoutlines, we capture building shadows under various solar zenith anglesthroughout the year and at different times of day. These simulated shadows arealigned with satellite images, providing a rich resource for learning shadepatterns. Second, we propose the DeepShade, a diffusion-based model designed tolearn and synthesize shade variations over time. It emphasizes the nuance ofedge features by jointly considering RGB with the Canny edge layer, andincorporates contrastive learning to capture the temporal change rules ofshade. Then, by conditioning on textual descriptions of known conditions (e.g.,time of day, solar angles), our framework provides improved performance ingenerating shade images. We demonstrate the utility of our approach by usingour shade predictions to calculate shade ratios for real-world route planningin Tempe, Arizona. We believe this work will benefit society by providing areference for urban planning in extreme heat weather and its potentialpractical applications in the environment.</description>
      <author>example@mail.com (Longchao Da, Xiangrui Liu, Mithun Shivakoti, Thirulogasankar Pranav Kutralingam, Yezhou Yang, Hua Wei)</author>
      <guid isPermaLink="false">2507.12103v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection</title>
      <link>http://arxiv.org/abs/2507.11997v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MLED的多层次LLM增强图欺诈检测框架，通过利用LLM提取文本信息中的外部知识来增强图欺诈检测方法，并实现了图结构信息和文本嵌入的多模态融合。&lt;h4&gt;背景&lt;/h4&gt;图欺诈检测受到广泛关注，GNN在建模多模态数据中的复杂关系方面表现出有效性。然而，现有的图欺诈检测方法通常使用预处理的节点嵌入和预定义的图结构来揭示欺诈者，忽略了原始文本信息中包含的丰富语义线索。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够融合处理后的文本嵌入与图结构的框架，以增强图欺诈检测的能力。&lt;h4&gt;方法&lt;/h4&gt;MLED框架使用LLM提取文本信息中的外部知识，并设计了多级LLM增强框架，包括类型级增强器和关系级增强器，以增强欺诈者与良性实体之间的差异，以及欺诈者在不同关系中的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界数据集上的实验表明，MLED作为通用框架，在图欺诈检测中实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;MLED框架能够有效地提高图欺诈检测的性能，为现有的方法提供了一种有效的增强手段。&lt;h4&gt;翻译&lt;/h4&gt;Graph fraud detection has garnered significant attention as Graph Neural Networks (GNNs) have proven effective in modeling complex relationships within multimodal data. However, existing graph fraud detection methods typically use preprocessed node embeddings and predefined graph structures to reveal fraudsters, which ignore the rich semantic cues contained in raw textual information. Although Large Language Models (LLMs) exhibit powerful capabilities in processing textual information, it remains a significant challenge to perform multimodal fusion of processed textual embeddings with graph structures. In this paper, we propose a Multi-level LLM Enhanced Graph Fraud Detection framework called MLED. In MLED, we utilize LLMs to extract external knowledge from textual information to enhance graph fraud detection methods. To integrate LLMs with graph structure information and enhance the ability to distinguish fraudsters, we design a multi-level LLM enhanced framework including type-level enhancer and relation-level enhancer. One is to enhance the difference between the fraudsters and the benign entities, the other is to enhance the importance of the fraudsters in different relations. The experiments on four real-world datasets show that MLED achieves state-of-the-art performance in graph fraud detection as a generalized framework that can be applied to existing methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph fraud detection has garnered significant attention as Graph NeuralNetworks (GNNs) have proven effective in modeling complex relationships withinmultimodal data. However, existing graph fraud detection methods typically usepreprocessed node embeddings and predefined graph structures to revealfraudsters, which ignore the rich semantic cues contained in raw textualinformation. Although Large Language Models (LLMs) exhibit powerfulcapabilities in processing textual information, it remains a significantchallenge to perform multimodal fusion of processed textual embeddings withgraph structures. In this paper, we propose a \textbf{M}ulti-level \textbf{L}LM\textbf{E}nhanced Graph Fraud \textbf{D}etection framework called MLED. InMLED, we utilize LLMs to extract external knowledge from textual information toenhance graph fraud detection methods. To integrate LLMs with graph structureinformation and enhance the ability to distinguish fraudsters, we design amulti-level LLM enhanced framework including type-level enhancer andrelation-level enhancer. One is to enhance the difference between thefraudsters and the benign entities, the other is to enhance the importance ofthe fraudsters in different relations. The experiments on four real-worlddatasets show that MLED achieves state-of-the-art performance in graph frauddetection as a generalized framework that can be applied to existing methods.</description>
      <author>example@mail.com (Tairan Huang, Yili Wang)</author>
      <guid isPermaLink="false">2507.11997v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Dual form Complementary Masking for Domain-Adaptive Image Segmentation</title>
      <link>http://arxiv.org/abs/2507.12008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MaskTwins的UDA框架，通过将掩码重建视为稀疏信号重建问题，并证明互补掩码的共轭形式在提取域无关图像特征方面具有优越能力，从而在自然和生物图像分割任务中展现出优于基线方法的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，Masked Image Modeling（MIM）与一致性正则化在无监督领域自适应（UDA）中的应用被相关研究探讨，但这些研究仅将掩码视为输入图像的一种特殊变形形式，忽略了理论分析，导致对掩码重建的浅显理解和对潜在能力利用不足。&lt;h4&gt;目的&lt;/h4&gt;提出MaskTwins框架，将掩码重建直接集成到主训练流程中，以增强特征提取和表示学习，并实现端到端的域泛化。&lt;h4&gt;方法&lt;/h4&gt;将掩码重建视为稀疏信号重建问题，理论上证明了互补掩码的共轭形式在提取域无关图像特征方面的优越性，并基于此提出MaskTwins框架。&lt;h4&gt;主要发现&lt;/h4&gt;MaskTwins通过强制执行以互补方式掩码的图像预测之间的一致性，揭示了在不同域中持续存在的内在结构模式，从而实现了域泛化。&lt;h4&gt;结论&lt;/h4&gt;MaskTwins在提取域不变特征方面展现出显著优势，无需单独预训练，为领域自适应分割提供了一种新的范式。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究将掩码图像建模（MIM）与无监督领域自适应（UDA）中的一致性正则化相关联。然而，他们仅仅将掩码视为输入图像的一种特殊变形形式，忽略了理论分析，这导致了掩码重建的表面理解和对潜在能力利用不足。在本文中，我们将掩码重建重新构造成一个稀疏信号重建问题，并从理论上证明了互补掩码的共轭形式在提取域无关图像特征方面具有优越能力。基于这一有力的见解，我们提出了MaskTwins，一个简单而有效的UDA框架，它将掩码重建直接集成到主训练流程中。MaskTwins通过强制执行以互补方式掩码的图像预测之间的一致性，揭示了在不同域中持续存在的内在结构模式，从而实现了端到端的域泛化。大量的实验验证了MaskTwins在自然和生物图像分割任务中优于基线方法的性能。这些结果证明了MaskTwins在提取域不变特征方面的显著优势，无需单独预训练，为领域自适应分割提供了一种新的范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent works have correlated Masked Image Modeling (MIM) with consistencyregularization in Unsupervised Domain Adaptation (UDA). However, they merelytreat masking as a special form of deformation on the input images and neglectthe theoretical analysis, which leads to a superficial understanding of maskedreconstruction and insufficient exploitation of its potential in enhancingfeature extraction and representation learning. In this paper, we reframemasked reconstruction as a sparse signal reconstruction problem andtheoretically prove that the dual form of complementary masks possessessuperior capabilities in extracting domain-agnostic image features. Based onthis compelling insight, we propose MaskTwins, a simple yet effective UDAframework that integrates masked reconstruction directly into the main trainingpipeline. MaskTwins uncovers intrinsic structural patterns that persist acrossdisparate domains by enforcing consistency between predictions of images maskedin complementary ways, enabling domain generalization in an end-to-end manner.Extensive experiments verify the superiority of MaskTwins over baseline methodsin natural and biological image segmentation. These results demonstrate thesignificant advantages of MaskTwins in extracting domain-invariant featureswithout the need for separate pre-training, offering a new paradigm fordomain-adaptive segmentation.</description>
      <author>example@mail.com (Jiawen Wang, Yinda Chen, Xiaoyu Liu, Che Liu, Dong Liu, Jianqing Gao, Zhiwei Xiong)</author>
      <guid isPermaLink="false">2507.12008v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Enhancements to the IceCube Extremely High Energy Neutrino Selection using Graph &amp; Transformer Based Neural Networks</title>
      <link>http://arxiv.org/abs/2507.11774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 39th International Cosmic Ray Conference (ICRC2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过机器学习技术提高对高能中微子事件的高能大气μ子背景排斥和方向重建，以改善10 PeV以上的漫射测量。&lt;h4&gt;背景&lt;/h4&gt;KM3NeT最近报告检测到了一个非常高的能量中微子事件，而IceCube之前设定了超过100 PeV的中微子通量上限，但尚未观察到与KM3NeT检测能量相当的中微子事件。&lt;h4&gt;目的&lt;/h4&gt;提高对10 PeV以上漫射中微子测量的准确度。&lt;h4&gt;方法&lt;/h4&gt;应用机器学习技术，使用图神经网络（GNN）进行分类任务，区分中微子和高能大气μ子，并利用基于Transformer的神经网络进行方向重建。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够在不依赖方向重建作为先验的情况下，排斥来自侧向扩散、低能μ子的早期事件，并实现了改进的背景排斥和重建性能。&lt;h4&gt;结论&lt;/h4&gt;通过机器学习技术实现了背景排斥和重建性能的提升，并讨论了未来超高能（EHE）选择发展的应用。&lt;h4&gt;翻译&lt;/h4&gt;This paper improves the accuracy of diffuse neutrino measurements above 10 PeV by applying machine learning techniques to enhance atmospheric muon background rejection and directional reconstruction. The graph neural network (GNN) is used for classification tasks to distinguish neutrinos from high-energy atmospheric muons, and a Transformer-based neural network is implemented for directional reconstruction. Unlike previous likelihood-based rapid reconstruction algorithms that assume a single muon track, this method makes no prior assumptions about the event topology of the particle inside the detector, demonstrating improved background rejection and reconstruction performance. The application of this technique to the development of future Extremely High Energy (EHE) selections is also discussed.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; KM3NeT has recently reported the detection of a very high-energy neutrinoevent, while IceCube has previously set upper limits on the differentialneutrino flux above 100 PeV but has yet to observe a neutrino event with anenergy comparable to that of the KM3NeT detection. To improve diffusemeasurements above 10 PeV, we apply machine learning techniques to enhanceatmospheric muon background rejection and directional reconstruction. Weutilize a Graph Neural Network (GNN) to perform a classification task thatdistinguishes neutrinos from high-energy atmospheric muons. The method allowsfor the rejection of early hits from laterally spread, lower-energy muons incosmic ray showers without relying on directional reconstruction as a prior.Additionally, a Transformer-based Neural Network is implemented for directionalreconstruction. Unlike previous likelihood-based rapid reconstructionalgorithms that assume a single muon track, this method makes no priorassumptions about event topology of the particle inside the detector. Wedemonstrate improved background rejection and reconstruction performance usingmachine learning techniques. Applications to the development of futureExtremely High Energy (EHE) selections are also discussed.</description>
      <author>example@mail.com (Maxwell Nakos, Aske Rosted, Lu Lu)</author>
      <guid isPermaLink="false">2507.11774v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering</title>
      <link>http://arxiv.org/abs/2507.12026v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为3D-MoRe的新范式，用于生成大规模的3D语言数据集，以应对室内场景任务的需求，并展示了其在问答和密集描述任务中的有效性。&lt;h4&gt;背景&lt;/h4&gt;室内场景任务，如问答和密集描述，对多样化和可扩展的数据有日益增长的需求。&lt;h4&gt;目的&lt;/h4&gt;通过利用基础模型的优势，提出3D-MoRe范式，以生成大规模3D语言数据集。&lt;h4&gt;方法&lt;/h4&gt;框架集成了多模态嵌入、跨模态交互和语言模型解码器等关键组件，以处理自然语言指令和3D场景数据。&lt;h4&gt;主要发现&lt;/h4&gt;使用ScanNet 3D场景数据集和ScanQA、ScanRefer的文本注释，3D-MoRe生成了62,000个问答对和73,000个物体描述。实验表明，3D-MoRe在ScanQA上的CIDEr分数提高了2.15%，在ScanRefer上的CIDEr@0.5提高了1.84%。&lt;h4&gt;结论&lt;/h4&gt;3D-MoRe在问答和密集描述任务中均显著优于现有基准，其代码和生成的数据集将公开发布。&lt;h4&gt;翻译&lt;/h4&gt;With the growing need for diverse and scalable data in indoor scene tasks, such as question answering and dense captioning, we propose 3D-MoRe, a novel paradigm designed to generate large-scale 3D-language datasets by leveraging the strengths of foundational models. The framework integrates key components, including multi-modal embedding, cross-modal interaction, and a language model decoder, to process natural language instructions and 3D scene data. This approach facilitates enhanced reasoning and response generation in complex 3D environments. Using the ScanNet 3D scene dataset, along with text annotations from ScanQA and ScanRefer, 3D-MoRe generates 62,000 question-answer (QA) pairs and 73,000 object descriptions across 1,513 scenes. We also employ various data augmentation techniques and implement semantic filtering to ensure high-quality data. Experiments on ScanQA demonstrate that 3D-MoRe significantly outperforms state-of-the-art baselines, with the CIDEr score improving by 2.15%. Similarly, on ScanRefer, our approach achieves a notable increase in CIDEr@0.5 by 1.84%, highlighting its effectiveness in both tasks. Our code and generated datasets will be publicly released to benefit the community, and both can be accessed on https://3D-MoRe.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing need for diverse and scalable data in indoor scene tasks,such as question answering and dense captioning, we propose 3D-MoRe, a novelparadigm designed to generate large-scale 3D-language datasets by leveragingthe strengths of foundational models. The framework integrates key components,including multi-modal embedding, cross-modal interaction, and a language modeldecoder, to process natural language instructions and 3D scene data. Thisapproach facilitates enhanced reasoning and response generation in complex 3Denvironments. Using the ScanNet 3D scene dataset, along with text annotationsfrom ScanQA and ScanRefer, 3D-MoRe generates 62,000 question-answer (QA) pairsand 73,000 object descriptions across 1,513 scenes. We also employ various dataaugmentation techniques and implement semantic filtering to ensure high-qualitydata. Experiments on ScanQA demonstrate that 3D-MoRe significantly outperformsstate-of-the-art baselines, with the CIDEr score improving by 2.15\%.Similarly, on ScanRefer, our approach achieves a notable increase in CIDEr@0.5by 1.84\%, highlighting its effectiveness in both tasks. Our code and generateddatasets will be publicly released to benefit the community, and both can beaccessed on the https://3D-MoRe.github.io.</description>
      <author>example@mail.com (Rongtao Xu, Han Gao, Mingming Yu, Dong An, Shunpeng Chen, Changwei Wang, Li Guo, Xiaodan Liang, Shibiao Xu)</author>
      <guid isPermaLink="false">2507.12026v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>BlockBPE: Parallel BPE Tokenization</title>
      <link>http://arxiv.org/abs/2507.11941v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ES-FoMo III: 3rd Workshop on Efficient Systems for Foundation Models  (ICML 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BlockBPE的并行GPU实现的字节对编码（BPE），它在实际假设下实现近线性时间复杂度，并针对高吞吐量批量推理进行了优化。&lt;h4&gt;背景&lt;/h4&gt;在大型语言模型流程中，分词是关键的前处理步骤，但广泛使用的实现仍然是CPU绑定的，并且在GPU上的批量推理工作流程中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;旨在提供一个并行GPU实现的BPE，以优化批量推理工作流程中的分词过程。&lt;h4&gt;方法&lt;/h4&gt;提出了BlockBPE，它消除了基于Rust的分词器（如HuggingFace Tokenizers和OpenAI的tiktoken）中的正则表达式预分词，从而在高吞吐量批量推理中实现高效的并行化。&lt;h4&gt;主要发现&lt;/h4&gt;BlockBPE通过消除正则表达式预分词，减少了生成质量的小损失，并实现了线程块内的并行化分词合并，将整体复杂度降低到O(nd)，其中d远小于n。在高批量推理工作负载中，BlockBPE的吞吐量比tiktoken高2倍，比HuggingFace Tokenizers高2.5倍。&lt;h4&gt;结论&lt;/h4&gt;BlockBPE是一种高效的并行GPU分词器，可以显著提高大型语言模型在GPU上的批量推理性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tokenization is a critical preprocessing step in large language modelpipelines, yet widely-used implementations remain CPU-bound and suboptimal forbatch inference workflows on GPU. We present BlockBPE, a parallel GPUimplementation of byte-pair encoding (BPE) that achieves near linear-timecomplexity under realistic assumptions and is optimized for high-throughput,batch inference. Unlike existing Rust-based tokenizers such as HuggingFaceTokenizers or OpenAI's tiktoken-whose runtimes are dominated by Regexpre-tokenization and exhibit $O(n \log n)$ runtime-BlockBPE eliminates theRegex pre-tokenization which leads to small loss in generation quality, butenables highly parallelized token merges within thread blocks, reducing overallcomplexity to $O(nd)$ where $d \ll n$. On high-batch inference workloads,BlockBPE achieves up to 2x higher throughput than tiktoken and 2.5x overHuggingFace Tokenizers.</description>
      <author>example@mail.com (Amos You)</author>
      <guid isPermaLink="false">2507.11941v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos</title>
      <link>http://arxiv.org/abs/2507.11967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为LG-CAV-MAE的语言引导对比音频-视觉掩码自编码器，用于提升音频-视觉表示学习，并在音频-视觉检索和分类任务中取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;现有音频-视觉表示学习方法存在表示学习效果不理想的问题。&lt;h4&gt;目的&lt;/h4&gt;通过整合预训练文本编码器和对比音频-视觉掩码自编码器，提升音频-视觉表示学习。&lt;h4&gt;方法&lt;/h4&gt;引入了自动生成音频-视觉-文本三元组的自动方法，使用图像字幕模型生成帧级字幕，并应用CLAP-based过滤技术确保音频和字幕之间的强对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在音频-视觉检索任务中，LG-CAV-MAE相较于现有方法，召回率@10提高了5.6%，在音频-视觉分类任务中提高了3.2%。&lt;h4&gt;结论&lt;/h4&gt;LG-CAV-MAE在音频-视觉表示学习中表现出色，显著提升了相关任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose Language-Guided Contrastive Audio-Visual MaskedAutoencoders (LG-CAV-MAE) to improve audio-visual representation learning.LG-CAV-MAE integrates a pretrained text encoder into contrastive audio-visualmasked autoencoders, enabling the model to learn across audio, visual and textmodalities. To train LG-CAV-MAE, we introduce an automatic method to generateaudio-visual-text triplets from unlabeled videos. We first generate frame-levelcaptions using an image captioning model and then apply CLAP-based filtering toensure strong alignment between audio and captions. This approach yieldshigh-quality audio-visual-text triplets without requiring manual annotations.We evaluate LG-CAV-MAE on audio-visual retrieval tasks, as well as anaudio-visual classification task. Our method significantly outperforms existingapproaches, achieving up to a 5.6% improvement in recall@10 for retrieval tasksand a 3.2% improvement for the classification task.</description>
      <author>example@mail.com (Yuchi Ishikawa, Shota Nakada, Hokuto Munakata, Kazuhiro Saito, Tatsuya Komatsu, Yoshimitsu Aoki)</author>
      <guid isPermaLink="false">2507.11967v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Similarity-Guided Diffusion for Contrastive Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2507.11866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散模型的相似性引导对比学习方法，用于序列推荐系统中的数据增强，以提高推荐性能。&lt;h4&gt;背景&lt;/h4&gt;在序列推荐系统中，数据增强和对比学习技术近期通过扩散模型被引入，以实现鲁棒的表示学习。然而，大多数现有方法使用随机增强，这可能会破坏原始序列的上下文信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以避免随机增强带来的问题，同时提高推荐系统的性能。&lt;h4&gt;方法&lt;/h4&gt;该方法利用物品嵌入向量之间的相似性来生成语义上一致的噪声，并在去噪过程中使用高置信度分数来选择增强位置。这种方法比随机位置的增强更有效地反映了上下文和结构信息。&lt;h4&gt;主要发现&lt;/h4&gt;与随机增强相比，该增强技术提供了更具区分性的正负样本，同时提高了训练效率和推荐性能。&lt;h4&gt;结论&lt;/h4&gt;在五个基准数据集上的实验结果表明，SimDiffRec优于现有的基线模型。&lt;h4&gt;翻译&lt;/h4&gt;在序列推荐系统中，最近引入了基于扩散模型的数据增强和对比学习技术，以实现鲁棒的表示学习。然而，大多数现有方法使用随机增强，这可能会损害原始序列的上下文信息。因此，我们提出了一个用于对比序列推荐的相似性引导扩散方法。我们的方法利用物品嵌入向量之间的相似性来生成语义上一致的噪声。此外，我们在去噪过程中利用高置信度分数来选择我们的增强位置。与随机位置的增强相比，这种方法更有效地反映了上下文和结构信息。从对比学习的角度来看，所提出的增强技术提供了更具区分性的正负样本，同时提高了训练效率和推荐性能。在五个基准数据集上的实验结果表明，SimDiffRec优于现有的基线模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In sequential recommendation systems, data augmentation and contrastivelearning techniques have recently been introduced using diffusion models toachieve robust representation learning. However, most of the existingapproaches use random augmentation, which risk damaging the contextualinformation of the original sequence. Accordingly, we propose aSimilarity-Guided Diffusion for Contrastive Sequential Recommendation. Ourmethod leverages the similarity between item embedding vectors to generatesemantically consistent noise. Moreover, we utilize high confidence score inthe denoising process to select our augmentation positions. This approach moreeffectively reflects contextual and structural information compared toaugmentation at random positions. From a contrastive learning perspective, theproposed augmentation technique provides more discriminative positive andnegative samples, simultaneously improving training efficiency andrecommendation performance. Experimental results on five benchmark datasetsshow that SimDiffRec outperforms the existing baseline models.</description>
      <author>example@mail.com (Jinkyeong Choi, Yejin Noh, Donghyeon Park)</author>
      <guid isPermaLink="false">2507.11866v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction</title>
      <link>http://arxiv.org/abs/2507.11757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，利用转导学习和归纳学习的优势，以有效地整合药物、靶点和它们之间相互作用的多样特征，从而提高药物-靶点相互作用（DTI）的预测准确性。&lt;h4&gt;背景&lt;/h4&gt;尽管基于图神经网络（GNN）的机器学习方法在DTI预测中取得了显著成功，但许多方法在有效整合药物、靶点和它们之间相互作用的多样特征方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述限制，提出了一种新的框架，旨在利用转导学习和归纳学习的优势，以更好地预测药物-靶点相互作用。&lt;h4&gt;方法&lt;/h4&gt;该方法包含一个基于GNN的模型，称为Graph-in-Graph（GiG），该模型将药物和靶点分子结构的图表示为药物-靶点相互作用图中的元节点，从而允许详细探索它们复杂的关系。为了评估所提出的模型，还编制了一个包含药物SMILES、蛋白质序列及其相互作用数据的特殊基准。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GiG模型在所有评估指标上都显著优于现有方法，这突出了整合不同学习范式和相互作用数据的益处。&lt;h4&gt;结论&lt;/h4&gt;GiG模型在药物-靶点相互作用预测方面具有显著优势，为药物发现和靶点验证技术的进步提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;准确预测药物-靶点相互作用（DTI）对于推进药物发现和靶点验证技术至关重要。尽管包括基于图神经网络（GNN）在内的机器学习方法在DTI预测中取得了显著成功，但许多方法在有效整合药物、靶点和它们之间相互作用的多样特征方面存在困难。为了解决这一限制，我们引入了一种新框架，以利用转导学习和归纳学习的优势，从而可以充分利用分子层面的特征和药物-靶点相互作用网络层面的特征。在该框架中，有一个基于GNN的模型，称为Graph-in-Graph（GiG），该模型将药物和靶点分子结构的图表示为药物-靶点相互作用图中的元节点，从而允许详细探索它们复杂的关系。为了评估所提出的模型，我们编制了一个包含药物SMILES、蛋白质序列及其相互作用数据的特殊基准。我们的实验结果表明，GiG模型在所有评估指标上都显著优于现有方法，这突出了整合不同学习范式和相互作用数据的益处。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting drug-target interactions (DTIs) is pivotal foradvancing drug discovery and target validation techniques. While machinelearning approaches including those that are based on Graph Neural Networks(GNN) have achieved notable success in DTI prediction, many of them havedifficulties in effectively integrating the diverse features of drugs, targetsand their interactions. To address this limitation, we introduce a novelframework to take advantage of the power of both transductive learning andinductive learning so that features at molecular level and drug-targetinteraction network level can be exploited. Within this framework is aGNN-based model called Graph-in-Graph (GiG) that represents graphs of drug andtarget molecular structures as meta-nodes in a drug-target interaction graph,enabling a detailed exploration of their intricate relationships. To evaluatethe proposed model, we have compiled a special benchmark comprising drugSMILES, protein sequences, and their interaction data, which is interesting inits own right. Our experimental results demonstrate that the GiG modelsignificantly outperforms existing approaches across all evaluation metrics,highlighting the benefits of integrating different learning paradigms andinteraction data.</description>
      <author>example@mail.com (Yuehua Song, Yong Gao)</author>
      <guid isPermaLink="false">2507.11757v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions</title>
      <link>http://arxiv.org/abs/2507.11783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 5 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对早期脑电图基础模型（EEG-FMs）进行了系统性的综述，分析了其方法论、实证发现和未解决的问题，并提出了未来EEG-FM发展的关键方向。&lt;h4&gt;背景&lt;/h4&gt;脑电图（EEG）记录的脑电活动模式对科学和临床研究具有重要价值。然而，传统的监督式EEG编码器难以学习鲁棒的EEG模式，并且过度依赖昂贵的信号标注，这促使研究者转向通用的自监督EEG编码器。&lt;h4&gt;目的&lt;/h4&gt;为了理解当前EEG-FM的状态-of-the-art和识别未来EEG-FM的关键发展方向，本文对10个早期EEG-FM进行了综述。&lt;h4&gt;方法&lt;/h4&gt;本文通过回顾10个早期EEG-FM，对它们的方法论、实证发现和未解决的问题进行了批判性的综合分析。&lt;h4&gt;主要发现&lt;/h4&gt;大多数EEG-FM采用基于序列的建模方案，依赖于基于Transformer的骨干网络和掩码序列的重构进行自监督。然而，模型评估存在异质性和局限性，难以评估其实际应用价值。&lt;h4&gt;结论&lt;/h4&gt;未来工作应采用标准化和现实主义的评估方法，展示更显著的扩展效果，并在EEG表示学习流程中做出原则性和值得信赖的选择。通过与领域专家合作开发基准、软件工具、技术方法和应用，可以进一步推进EEG-FM的转化应用和实际应用。&lt;h4&gt;翻译&lt;/h4&gt;The study reviews 10 early EEG-FMs and presents a critical synthesis of their methodology, empirical findings, and outstanding research gaps. We find that most EEG-FMs adopt a sequence-based modeling scheme that relies on transformer-based backbones and the reconstruction of masked sequences for self-supervision. However, model evaluations remain heterogeneous and largely limited, making it challenging to assess their practical off-the-shelf utility. In addition to adopting standardized and realistic evaluations, future work should demonstrate more substantial scaling effects and make principled and trustworthy choices throughout the EEG representation learning pipeline. We believe that developing benchmarks, software tools, technical methodologies, and applications in collaboration with domain experts may further advance the translational utility and real-world adoption of EEG-FMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patterns of electrical brain activity recorded via electroencephalography(EEG) offer immense value for scientific and clinical investigations. Theinability of supervised EEG encoders to learn robust EEG patterns and theirover-reliance on expensive signal annotations have sparked a transition towardsgeneral-purpose self-supervised EEG encoders, i.e., EEG foundation models(EEG-FMs), for robust and scalable EEG feature extraction. However, thereal-world readiness of early EEG-FMs and the rubric for long-term researchprogress remain unclear. A systematic and comprehensive review offirst-generation EEG-FMs is therefore necessary to understand the currentstate-of-the-art and identify key directions for future EEG-FMs. To that end,this study reviews 10 early EEG-FMs and presents a critical synthesis of theirmethodology, empirical findings, and outstanding research gaps. We find thatmost EEG-FMs adopt a sequence-based modeling scheme that relies ontransformer-based backbones and the reconstruction of masked sequences forself-supervision. However, model evaluations remain heterogeneous and largelylimited, making it challenging to assess their practical off-the-shelf utility.In addition to adopting standardized and realistic evaluations, future workshould demonstrate more substantial scaling effects and make principled andtrustworthy choices throughout the EEG representation learning pipeline. Webelieve that developing benchmarks, software tools, technical methodologies,and applications in collaboration with domain experts may further advance thetranslational utility and real-world adoption of EEG-FMs.</description>
      <author>example@mail.com (Gayal Kuruppu, Neeraj Wagh, Yogatheesan Varatharajah)</author>
      <guid isPermaLink="false">2507.11783v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>JSQA: Speech Quality Assessment with Perceptually-Inspired Contrastive Pretraining Based on JND Audio Pairs</title>
      <link>http://arxiv.org/abs/2507.11636v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to WASPAA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了JSQA，一种用于语音质量评估（SQA）的两阶段框架，通过感知指导的对比学习预训练音频编码器，并用于MOS预测。&lt;h4&gt;背景&lt;/h4&gt;语音质量评估通常用于将高维输入空间映射到表示感知语音质量平均意见得分（MOS）的标量值。由于感知和实验设计差异，MOS表现出很高的内在变异性。&lt;h4&gt;目的&lt;/h4&gt;提出JSQA框架，以解决现有方法未能充分结合感知因素的问题，从而提高SQA的性能。&lt;h4&gt;方法&lt;/h4&gt;JSQA框架包括两个阶段：首先使用可察觉差异（JND）对音频数据进行对比学习以预训练编码器，然后对MOS预测进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与从头开始训练的网络相比，感知启发的对比预训练显著提高了模型性能。&lt;h4&gt;结论&lt;/h4&gt;将感知因素纳入预训练对于提高SQA性能具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语音质量评估（SQA）通常用于从高维输入空间学习到表示感知语音质量平均意见得分（MOS）的标量值的映射。学习这样的映射具有挑战性，主要是因为MOS由于感知和实验设计差异表现出很高的内在变异性。已经提出了许多解决方案，但许多方法没有在其学习算法（超出MOS标签）中适当地结合感知因素，这可能导致不满意的结果。为此，我们提出了JSQA，一个两阶段框架，使用感知引导的对比学习预训练音频编码器，然后进行MOS预测的微调。我们首先在JND级别内生成音频数据对，然后使用这些数据对预训练编码器，以利用感知质量相似信息并将其映射到嵌入空间。JND对来自纯净的LibriSpeech语音，这些语音与来自CHiME-3的背景噪声混合，在不同的信噪比（SNR）下。编码器随后使用NISQA数据集中的音频样本进行微调以进行MOS预测。实验结果表明，与从头开始训练的网络相比，感知启发的对比预训练在通过各种指标评估模型性能时显著提高了。这些发现表明，将感知因素纳入预训练对于提高SQA性能具有重大贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech quality assessment (SQA) is often used to learn a mapping from ahigh-dimensional input space to a scalar that represents the mean opinion score(MOS) of the perceptual speech quality. Learning such a mapping is challengingfor many reasons, but largely because MOS exhibits high levels of inherentvariance due to perceptual and experimental-design differences. Many solutionshave been proposed, but many approaches do not properly incorporate perceptualfactors into their learning algorithms (beyond the MOS label), which could leadto unsatisfactory results. To this end, we propose JSQA, a two-stage frameworkthat pretrains an audio encoder using perceptually-guided contrastive learningon just noticeable difference (JND) pairs, followed by fine-tuning for MOSprediction. We first generate pairs of audio data within JND levels, which arethen used to pretrain an encoder to leverage perceptual quality similarityinformation and map it into an embedding space. The JND pairs come from cleanLibriSpeech utterances that are mixed with background noise from CHiME-3, atdifferent signal-to-noise ratios (SNRs). The encoder is later fine-tuned withaudio samples from the NISQA dataset for MOS prediction. Experimental resultssuggest that perceptually-inspired contrastive pretraining significantlyimproves the model performance evaluated by various metrics when comparedagainst the same network trained from scratch without pretraining. Thesefindings suggest that incorporating perceptual factors into pretraining greatlycontributes to the improvement in performance for SQA.</description>
      <author>example@mail.com (Junyi Fan, Donald Williamson)</author>
      <guid isPermaLink="false">2507.11636v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning</title>
      <link>http://arxiv.org/abs/2507.11732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于统计方法的图神经网络（GNN）初始节点特征生成方法，即one-hot图编码嵌入（GEE），并展示了其在节点聚类和分类任务中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;GNN在节点级图学习任务中表现出强大的能力，但其性能常受限于初始特征表示的随机性或信息不足，导致收敛速度慢和结果不理想。&lt;h4&gt;目的&lt;/h4&gt;旨在通过GEE方法生成高质量的初始节点特征，以提升GNN的训练效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为GEE-powered GNN（GG）的集成框架，通过GEE生成初始节点特征，并在无监督和监督设置下进行仿真和实验。&lt;h4&gt;主要发现&lt;/h4&gt;GG在节点聚类任务中实现了最先进的性能，在所有评估的真实世界数据集上排名第一，且收敛速度比标准GNN快。GG的增强变体GG-C在节点分类任务中优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;GEE方法的重要性得到了证实，该方法在实现GNN的潜力方面起到了关键作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have emerged as a powerful framework for a widerange of node-level graph learning tasks. However, their performance is oftenconstrained by reliance on random or minimally informed initial featurerepresentations, which can lead to slow convergence and suboptimal solutions.In this paper, we leverage a statistically grounded method, one-hot graphencoder embedding (GEE), to generate high-quality initial node features thatenhance the end-to-end training of GNNs. We refer to this integrated frameworkas the GEE-powered GNN (GG), and demonstrate its effectiveness throughextensive simulations and real-world experiments across both unsupervised andsupervised settings. In node clustering, GG consistently achievesstate-of-the-art performance, ranking first across all evaluated real-worlddatasets, while exhibiting faster convergence compared to the standard GNN. Fornode classification, we further propose an enhanced variant, GG-C, whichconcatenates the outputs of GG and GEE and outperforms competing baselines.These results confirm the importance of principled, structure-aware featureinitialization in realizing the full potential of GNNs.</description>
      <author>example@mail.com (Shiyu Chen, Cencheng Shen, Youngser Park, Carey E. Priebe)</author>
      <guid isPermaLink="false">2507.11732v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>What cat is that? A re-id model for feral cats</title>
      <link>http://arxiv.org/abs/2507.11575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Master's project&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了利用图像识别技术监控流浪猫的方法，并提出了一种名为PPGNet-Cat的模型，用于在野外识别个体流浪猫。&lt;h4&gt;背景&lt;/h4&gt;流浪猫对澳大利亚野生动物造成了严重损害，被视为全球最危险的入侵物种之一。&lt;h4&gt;目的&lt;/h4&gt;为了减少流浪猫的影响，需要对其进行密切监控。&lt;h4&gt;方法&lt;/h4&gt;研究利用图像识别技术中的再识别（re-ID）方法，通过摄像头捕捉的图像来监控流浪猫。研究人员修改了PPGNet模型，以适应流浪猫图像的特点，并进行了各种实验，特别是探索了对比学习技术如ArcFace损失。&lt;h4&gt;主要发现&lt;/h4&gt;PPGNet-Cat模型在识别流浪猫方面表现出色，平均精度（mAP）达到0.86，排名1的准确率达到0.95。&lt;h4&gt;结论&lt;/h4&gt;PPGNet-Cat模型在再识别领域内是一个具有竞争力的模型。&lt;h4&gt;翻译&lt;/h4&gt;Feral cats exert a substantial and detrimental impact on Australian wildlife, placing them among the most dangerous invasive species worldwide. Therefore, closely monitoring these cats is essential labor in minimizing their effects. In this context, the potential application of Re-Identification (re-ID) emerges to enhance monitoring activities for these animals, utilizing images captured by camera traps. This project explores different CV approaches to create a re-ID model able to identify individual feral cats in the wild. The main approach consists of modifying a part-pose guided network (PPGNet) model, initially used in the re-ID of Amur tigers, to be applicable for feral cats. This adaptation, resulting in PPGNet-Cat, which incorporates specific modifications to suit the characteristics of feral cats images. Additionally, various experiments were conducted, particularly exploring contrastive learning approaches such as ArcFace loss. The main results indicate that PPGNet-Cat excels in identifying feral cats, achieving high performance with a mean Average Precision (mAP) of 0.86 and a rank-1 accuracy of 0.95. These outcomes establish PPGNet-Cat as a competitive model within the realm of re-ID.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Feral cats exert a substantial and detrimental impact on Australian wildlife,placing them among the most dangerous invasive species worldwide. Therefore,closely monitoring these cats is essential labour in minimising their effects.In this context, the potential application of Re-Identification (re-ID) emergesto enhance monitoring activities for these animals, utilising images capturedby camera traps. This project explores different CV approaches to create are-ID model able to identify individual feral cats in the wild. The mainapproach consists of modifying a part-pose guided network (PPGNet) model,initially used in the re-ID of Amur tigers, to be applicable for feral cats.This adaptation, resulting in PPGNet-Cat, which incorporates specificmodifications to suit the characteristics of feral cats images. Additionally,various experiments were conducted, particularly exploring contrastive learningapproaches such as ArcFace loss. The main results indicate that PPGNet-Catexcels in identifying feral cats, achieving high performance with a meanAverage Precision (mAP) of 0.86 and a rank-1 accuracy of 0.95. These outcomesestablish PPGNet-Cat as a competitive model within the realm of re-ID.</description>
      <author>example@mail.com (Victor Caquilpan)</author>
      <guid isPermaLink="false">2507.11575v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification</title>
      <link>http://arxiv.org/abs/2507.11845v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in ChinaMM and recommended to Displays&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ProtoConNet的开放集小样本图像分类方法，旨在通过少量标注数据训练模型，使其在面对未知环境时具有良好的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有方法主要利用单张图像的视觉信息来学习类别表示，区分已知和未知类别，但往往忽略了整合丰富上下文信息的好处。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一种原型增强和对齐方法，以增强特征空间的多样性，打破小样本场景中上下文与图像主题之间的虚假关联。&lt;h4&gt;方法&lt;/h4&gt;ProtoConNet包含三个主要模块：基于聚类的数据选择（CDS）模块挖掘多样化的数据模式同时保留核心特征；上下文增强语义细化（CSR）模块构建上下文词典以整合到图像表示中，增强模型在各种场景下的鲁棒性；原型对齐（PA）模块减少图像表示与类别原型之间的差距，放大已知和未知类别的特征距离。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ProtoConNet增强了小样本场景中表征学习的效果，并能够识别开放集样本，使其优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;ProtoConNet在小样本图像分类任务中表现出色，能够有效提高模型的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-set few-shot image classification aims to train models using a smallamount of labeled data, enabling them to achieve good generalization whenconfronted with unknown environments. Existing methods mainly use visualinformation from a single image to learn class representations to distinguishknown from unknown categories. However, these methods often overlook thebenefits of integrating rich contextual information. To address this issue,this paper proposes a prototypical augmentation and alignment method, termedProtoConNet, which incorporates background information from different samplesto enhance the diversity of the feature space, breaking the spuriousassociations between context and image subjects in few-shot scenarios.Specifically, it consists of three main modules: the clustering-based dataselection (CDS) module mines diverse data patterns while preserving corefeatures; the contextual-enhanced semantic refinement (CSR) module builds acontext dictionary to integrate into image representations, which boosts themodel's robustness in various scenarios; and the prototypical alignment (PA)module reduces the gap between image representations and class prototypes,amplifying feature distances for known and unknown classes. Experimentalresults from two datasets verified that ProtoConNet enhances the effectivenessof representation learning in few-shot scenarios and identifies open-setsamples, making it superior to existing methods.</description>
      <author>example@mail.com (Kexuan Shi, Zhuang Qi, Jingjing Zhu, Lei Meng, Yaochen Zhang, Haibei Huang, Xiangxu Meng)</author>
      <guid isPermaLink="false">2507.11845v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>SToFM: a Multi-scale Foundation Model for Spatial Transcriptomics</title>
      <link>http://arxiv.org/abs/2507.11588v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accpeted by ICML 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SToFM的多尺度空间转录组基础模型，用于分析空间转录组数据，并通过构建SToCorpus-88M预训练语料库，在组织区域语义分割和细胞类型注释等下游任务中展现出卓越性能。&lt;h4&gt;背景&lt;/h4&gt;空间转录组（ST）技术通过保留细胞的时空背景，为生物学家提供了单细胞生物学的丰富见解。然而，由于需要从包含大量细胞的组织切片中提取多尺度信息，因此对ST数据进行建模具有内在的挑战性。&lt;h4&gt;目的&lt;/h4&gt;旨在解决ST数据建模的挑战，并提出一种能够有效处理多尺度信息的方法。&lt;h4&gt;方法&lt;/h4&gt;SToFM首先对每个ST切片进行多尺度信息提取，构建包含宏观、微观和基因尺度信息的ST子切片集。然后使用SE(2)Transformer从子切片中获得高质量的细胞表示。此外，还构建了SToCorpus-88M，这是最大的高分辨率空间转录组语料库，用于预训练。&lt;h4&gt;主要发现&lt;/h4&gt;SToFM在多种下游任务中表现出色，如组织区域语义分割和细胞类型注释，证明了其对ST数据的全面理解。&lt;h4&gt;结论&lt;/h4&gt;SToFM模型通过多尺度信息提取和预训练语料库，有效提升了空间转录组数据的分析能力，为生物学家提供了新的研究视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial Transcriptomics (ST) technologies provide biologists with richinsights into single-cell biology by preserving spatial context of cells.Building foundational models for ST can significantly enhance the analysis ofvast and complex data sources, unlocking new perspectives on the intricacies ofbiological tissues. However, modeling ST data is inherently challenging due tothe need to extract multi-scale information from tissue slices containing vastnumbers of cells. This process requires integrating macro-scale tissuemorphology, micro-scale cellular microenvironment, and gene-scale geneexpression profile. To address this challenge, we propose SToFM, a multi-scaleSpatial Transcriptomics Foundation Model. SToFM first performs multi-scaleinformation extraction on each ST slice, to construct a set of ST sub-slicesthat aggregate macro-, micro- and gene-scale information. Then an SE(2)Transformer is used to obtain high-quality cell representations from thesub-slices. Additionally, we construct \textbf{SToCorpus-88M}, the largesthigh-resolution spatial transcriptomics corpus for pretraining. SToFM achievesoutstanding performance on a variety of downstream tasks, such as tissue regionsemantic segmentation and cell type annotation, demonstrating its comprehensiveunderstanding of ST data</description>
      <author>example@mail.com (Suyuan Zhao, Yizhen Luo, Ganbo Yang, Yan Zhong, Hao Zhou, Zaiqing Nie)</author>
      <guid isPermaLink="false">2507.11588v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Subgraph Generation for Generalizing on Out-of-Distribution Links</title>
      <link>http://arxiv.org/abs/2507.11710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FLEX的图生成模型框架，用于提升链接预测任务中的性能，特别是在分布外（OOD）场景下。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在链接预测任务上表现出色，但这些模型通常依赖于所有数据样本来自同一分布。此外，图生成模型（GGMs）在生成新图方面有显著的能力，但其应用主要限于特定领域。&lt;h4&gt;目的&lt;/h4&gt;为了弥合这一差距，提出FLEX框架，旨在提升链接预测在分布外场景下的性能。&lt;h4&gt;方法&lt;/h4&gt;FLEX利用两种机制：结构化条件图生成和自编码器与GNN之间的对抗性共训练。这确保了样本分布之间的结构对齐，以增强链接预测性能。&lt;h4&gt;主要发现&lt;/h4&gt;FLEX在合成和真实世界的分布外设置中进行了大量实验，证明了其性能提升能力，并对图数据增强对链接结构的影响进行了进一步分析。&lt;h4&gt;结论&lt;/h4&gt;FLEX不需要专家知识即可在不同分布外场景下工作，并且其源代码已公开。&lt;h4&gt;翻译&lt;/h4&gt;Graphs Neural Networks (GNNs) demonstrate high-performance on the linkprediction (LP) task. However, these models often rely on all dataset samples being drawn from the same distribution. In addition, graph generative models(GGMs) show a pronounced ability to generate novel output graphs. Despite this,GGM applications remain largely limited to domain-specific tasks. To bridgethis gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)structurally-conditioned graph generation, and (2) adversarial co-training between an auto-encoder and GNN. As such, FLEX ensures structural-alignmentbetween sample distributions to enhance link-prediction performance inout-of-distribution (OOD) scenarios. Notably, FLEX does not require expertknowledge to function in different OOD scenarios. Numerous experiments areconducted in synthetic and real-world OOD settings to demonstrate FLEX'sperformance-enhancing ability, with further analysis for understanding theeffects of graph data augmentation on link structures. The source code isavailable here: https://github.com/revolins/FlexOOD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs Neural Networks (GNNs) demonstrate high-performance on the linkprediction (LP) task. However, these models often rely on all dataset samplesbeing drawn from the same distribution. In addition, graph generative models(GGMs) show a pronounced ability to generate novel output graphs. Despite this,GGM applications remain largely limited to domain-specific tasks. To bridgethis gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)structurally-conditioned graph generation, and (2) adversarial co-trainingbetween an auto-encoder and GNN. As such, FLEX ensures structural-alignmentbetween sample distributions to enhance link-prediction performance inout-of-distribution (OOD) scenarios. Notably, FLEX does not require expertknowledge to function in different OOD scenarios. Numerous experiments areconducted in synthetic and real-world OOD settings to demonstrate FLEX'sperformance-enhancing ability, with further analysis for understanding theeffects of graph data augmentation on link structures. The source code isavailable here: https://github.com/revolins/FlexOOD.</description>
      <author>example@mail.com (Jay Revolinsky, Harry Shomer, Jiliang Tang)</author>
      <guid isPermaLink="false">2507.11710v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training</title>
      <link>http://arxiv.org/abs/2507.11683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in the 2025 International Conference for High  Performance Computing, Networking, Storage, and Analysis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了PyTorch Geometric Temporal Index (PGT-I)，这是一种针对时空数据的扩展，它通过分布式数据并行训练和两种新策略（索引批处理和分布式索引批处理）来克服ST-GNN在大型数据集上的应用限制。&lt;h4&gt;背景&lt;/h4&gt;Spatiotemporal graph neural networks (ST-GNNs)在建模时空数据依赖方面非常强大，但由于内存限制，其应用主要限于小型数据集。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，使得ST-GNN能够在大型数据集上进行有效训练，同时降低内存使用和提高计算效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为PGT-I的扩展，它利用索引技术动态构建运行时的快照，显著降低内存开销，并通过分布式索引批处理支持跨多个GPU的可扩展处理。&lt;h4&gt;主要发现&lt;/h4&gt;PGT-I使ST-GNN能够在整个PeMS数据集上无图分区进行首次训练，将峰值内存使用量降低了高达89%，并且在使用128个GPU的情况下，比标准的分布式数据并行（DDP）快了13.1倍。&lt;h4&gt;结论&lt;/h4&gt;PGT-I扩展了ST-GNN在大型时空数据集上的应用能力，通过创新的索引技术和分布式处理策略，显著提高了模型的训练效率和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatiotemporal graph neural networks (ST-GNNs) are powerful tools formodeling spatial and temporal data dependencies. However, their applicationshave been limited primarily to small-scale datasets because of memoryconstraints. While distributed training offers a solution, current frameworkslack support for spatiotemporal models and overlook the properties ofspatiotemporal data. Informed by a scaling study on a large-scale workload, wepresent PyTorch Geometric Temporal Index (PGT-I), an extension to PyTorchGeometric Temporal that integrates distributed data parallel training and twonovel strategies: index-batching and distributed-index-batching. Our indextechniques exploit spatiotemporal structure to construct snapshots dynamicallyat runtime, significantly reducing memory overhead, whiledistributed-index-batching extends this approach by enabling scalableprocessing across multiple GPUs. Our techniques enable the first-ever trainingof an ST-GNN on the entire PeMS dataset without graph partitioning, reducingpeak memory usage by up to 89\% and achieving up to a 13.1x speedup overstandard DDP with 128 GPUs.</description>
      <author>example@mail.com (Seth Ockerman, Amal Gueroudji, Tanwi Mallick, Yixuan He, Line Pouchard, Robert Ross, Shivaram Venkataraman)</author>
      <guid isPermaLink="false">2507.11683v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting</title>
      <link>http://arxiv.org/abs/2507.11558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ST-VFM的新框架，用于通用时空预测，该框架通过重新编程视觉基础模型（VFMs）来增强其时空建模能力。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型在自然语言处理和计算机视觉领域取得了显著成功，但现有的语言模型在处理时空数据时存在局限性，难以捕捉丰富的时空相关性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效建模时空关系的框架，用于时空预测。&lt;h4&gt;方法&lt;/h4&gt;ST-VFM采用双分支架构，结合原始时空输入和辅助时空流输入，并引入两个专门的重新编程阶段：预-VFM重新编程阶段和后-VFM重新编程阶段。预-VFM重新编程阶段使用时间感知令牌适配器嵌入时间上下文并使两个分支适应VFM兼容的特征空间。后-VFM重新编程阶段引入双边交叉提示协调模块，通过基于提示的条件化实现分支间的动态交互。&lt;h4&gt;主要发现&lt;/h4&gt;在多个时空数据集上的实验表明，ST-VFM优于现有基线，证明了其在不同VFM骨干网络（如DINO、CLIP、DEIT）上的有效性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;ST-VFM是一个强大的通用框架，适用于时空预测，能够有效处理时空数据并提高预测准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型在自然语言处理和计算机视觉领域取得了显著的成功，展示了在建模复杂模式方面的强大能力。尽管最近的研究探索了将大型语言模型（LLMs）应用于时间序列预测，但LLMs主要捕捉一维的序列依赖关系，难以建模对于准确时空预测至关重要的丰富时空（ST）相关性。在本文中，我们提出了一种名为ST-VFM的新型框架，该框架系统地重新编程视觉基础模型（VFMs）以进行通用时空预测。虽然VFMs提供了强大的空间先验，但在应用于时空任务时存在两个关键挑战：（1）缺乏固有的时间建模能力；（2）视觉和时空数据之间的模态差距。为了解决这些问题，ST-VFM采用了一种双分支架构，该架构结合了原始时空输入和辅助时空流输入，其中流编码了可解释为动态空间线索的轻量级时间差异信号。为了有效地处理这些双分支输入，ST-VFM引入了两个专门的重新编程阶段。预-VFM重新编程阶段应用了时间感知令牌适配器以嵌入时间上下文并将两个分支对齐到VFM兼容的特征空间。后-VFM重新编程阶段引入了一个双边交叉提示协调模块，通过基于提示的条件化实现了分支之间的动态交互，从而丰富了联合表示学习，而不修改冻结的VFM骨干。在数十个时空数据集上的大量实验表明，ST-VFM优于最先进的基线，证明了其在不同VFM骨干网络（例如DINO、CLIP、DEIT）和消融研究中的有效性和鲁棒性，确立了其在时空预测中的强大通用框架地位。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have achieved remarkable success in natural languageprocessing and computer vision, demonstrating strong capabilities in modelingcomplex patterns. While recent efforts have explored adapting large languagemodels (LLMs) for time-series forecasting, LLMs primarily captureone-dimensional sequential dependencies and struggle to model the richerspatio-temporal (ST) correlations essential for accurate ST forecasting. Inthis paper, we present \textbf{ST-VFM}, a novel framework that systematicallyreprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporalforecasting. While VFMs offer powerful spatial priors, two key challenges arisewhen applying them to ST tasks: (1) the lack of inherent temporal modelingcapacity and (2) the modality gap between visual and ST data. To address these,ST-VFM adopts a \emph{dual-branch architecture} that integrates raw ST inputswith auxiliary ST flow inputs, where the flow encodes lightweight temporaldifference signals interpretable as dynamic spatial cues. To effectivelyprocess these dual-branch inputs, ST-VFM introduces two dedicated reprogrammingstages. The \emph{pre-VFM reprogramming} stage applies a Temporal-Aware TokenAdapter to embed temporal context and align both branches into VFM-compatiblefeature spaces. The \emph{post-VFM reprogramming} stage introduces a BilateralCross-Prompt Coordination module, enabling dynamic interaction between branchesthrough prompt-based conditioning, thus enriching joint representation learningwithout modifying the frozen VFM backbone. Extensive experiments on tenspatio-temporal datasets show that ST-VFM outperforms state-of-the-artbaselines, demonstrating effectiveness and robustness across VFM backbones(e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a stronggeneral framework for spatio-temporal forecasting.</description>
      <author>example@mail.com (Changlu Chen, Yanbin Liu, Chaoxi Niu, Ling Chen, Tianqing Zhu)</author>
      <guid isPermaLink="false">2507.11558v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>2.5D Object Detection for Intelligent Roadside Infrastructure</title>
      <link>http://arxiv.org/abs/2507.03564v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at 2025 IEEE 28th International Conference on Intelligent  Transportation Systems (ITSC)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对路边安装的摄像头进行2.5D物体检测的框架，用于解决自动驾驶车辆中传感器受限的问题。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶车辆的传感器可能会受到遮挡或视野限制，而路边智能基础设施感知系统可以通过V2X通信为自动驾驶车辆提供补充信息。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够适应顶部视角和陡峭相机角度的3D物体检测算法，以改善自动驾驶车辆的驾驶决策。&lt;h4&gt;方法&lt;/h4&gt;提出了一种2.5D物体检测框架，通过预测方法在图像帧中将车辆地面平面检测为平行四边形，以保留物体的平面位置、大小和方向，同时忽略高度信息。使用真实世界和合成场景进行训练，并在不同的视角和天气条件下进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在检测精度、跨视角泛化能力和对多样光照和天气条件的鲁棒性方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;该2.5D物体检测框架能够有效提高自动驾驶车辆在复杂环境下的感知能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：自动驾驶车辆的车载传感器可能会受到遮挡、遮挡或视野限制，从而复杂化下游的驾驶决策。安装在高位点的智能路边基础设施感知系统可以提供广泛的、无遮挡的交叉覆盖，通过车辆到一切（V2X）通信为自动驾驶车辆提供补充信息流。然而，传统的3D物体检测算法在由顶部视角和陡峭的相机角度引入的领域转移下难以泛化。我们介绍了一种针对路边安装的摄像头定制的2.5D物体检测框架。与传统的2D或3D物体检测不同，我们采用了一种预测方法来检测图像帧中车辆的地面平面为平行四边形。平行四边形保留了物体的平面位置、大小和方向，同时省略了高度，这对于大多数下游应用来说是不必要的。为了训练，结合了真实世界和合成场景。我们在训练集之外的摄像机视角和没有出现在训练集中的恶劣天气场景中评估了泛化能力。我们的结果表明，检测精度高，具有强大的跨视角泛化能力，并且对不同的光照和天气条件具有鲁棒性。模型权重和推理代码可在以下链接找到：https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; On-board sensors of autonomous vehicles can be obstructed, occluded, orlimited by restricted fields of view, complicating downstream drivingdecisions. Intelligent roadside infrastructure perception systems, installed atelevated vantage points, can provide wide, unobstructed intersection coverage,supplying a complementary information stream to autonomous vehicles viavehicle-to-everything (V2X) communication. However, conventional 3Dobject-detection algorithms struggle to generalize under the domain shiftintroduced by top-down perspectives and steep camera angles. We introduce a2.5D object detection framework, tailored specifically for infrastructureroadside-mounted cameras. Unlike conventional 2D or 3D object detection, weemploy a prediction approach to detect ground planes of vehicles asparallelograms in the image frame. The parallelogram preserves the planarposition, size, and orientation of objects while omitting their height, whichis unnecessary for most downstream applications. For training, a mix ofreal-world and synthetically generated scenes is leveraged. We evaluategeneralizability on a held-out camera viewpoint and in adverse-weatherscenarios absent from the training set. Our results show high detectionaccuracy, strong cross-viewpoint generalization, and robustness to diverselighting and weather conditions. Model weights and inference code are providedat: https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection</description>
      <author>example@mail.com (Nikolai Polley, Yacin Boualili, Ferdinand Mütsch, Maximilian Zipfl, Tobias Fleck, J. Marius Zöllner)</author>
      <guid isPermaLink="false">2507.03564v2</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>CosmoFlow: Scale-Aware Representation Learning for Cosmology with Flow Matching</title>
      <link>http://arxiv.org/abs/2507.11842v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了生成机器学习模型在处理冷暗物质（CDM）模拟数据方面的能力，特别是模型在不监督的情况下学习紧凑且语义丰富的潜在表示。&lt;h4&gt;背景&lt;/h4&gt;生成机器学习模型在保留数据信息方面已证明其有效性，能够学习低维数据表示。&lt;h4&gt;目的&lt;/h4&gt;验证基于流匹配的生成模型在不监督的情况下能否学习CDM模拟数据的紧凑、语义丰富的潜在表示。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为CosmoFlow的模型，该模型学习到的表示比原始字段数据小32倍，可用于字段级重建、合成数据生成和参数推断。&lt;h4&gt;主要发现&lt;/h4&gt;CosmoFlow模型能够学习到可解释的表示，其中不同的潜在通道对应于不同宇宙尺度上的特征。&lt;h4&gt;结论&lt;/h4&gt;CosmoFlow模型在不监督的情况下成功学习了CDM模拟数据的紧凑且语义丰富的潜在表示，具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;生成机器学习模型已经证明能够学习数据的低维表示，这些表示保留了下游任务所需的信息。在这项工作中，我们证明了基于流匹配的生成模型能够在不监督的情况下学习字段级冷暗物质（CDM）模拟数据的紧凑、语义丰富的潜在表示。我们的模型CosmoFlow学习到的表示比原始字段数据小32倍，可用于字段级重建、合成数据生成和参数推断。我们的模型还学习到了可解释的表示，其中不同的潜在通道对应于不同宇宙尺度上的特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative machine learning models have been demonstrated to be able to learnlow dimensional representations of data that preserve information required fordownstream tasks. In this work, we demonstrate that flow matching basedgenerative models can learn compact, semantically rich latent representationsof field level cold dark matter (CDM) simulation data without supervision. Ourmodel, CosmoFlow, learns representations 32x smaller than the raw field data,usable for field level reconstruction, synthetic data generation, and parameterinference. Our model also learns interpretable representations, in whichdifferent latent channels correspond to features at different cosmologicalscales.</description>
      <author>example@mail.com (Sidharth Kannan, Tian Qiu, Carolina Cuesta-Lazaro, Haewon Jeong)</author>
      <guid isPermaLink="false">2507.11842v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Are Vision Foundation Models Ready for Out-of-the-Box Medical Image Registration?</title>
      <link>http://arxiv.org/abs/2507.11569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3 figures, 9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于基础模型的乳腺MRI图像配准算法，评估了五种预训练编码器在乳腺图像配准中的性能。&lt;h4&gt;背景&lt;/h4&gt;基础模型在图像注册方面显示出潜力，但主要在刚性或较简单结构上测试，其能否处理更具挑战性的变形解剖结构尚不明确。&lt;h4&gt;目的&lt;/h4&gt;全面评估基于基础模型的乳腺MRI图像配准算法，并探索改进全局对齐和精细结构准确性的策略。&lt;h4&gt;方法&lt;/h4&gt;评估了DINO-v2、SAM、MedSAM、SSLSAM和MedCLIP五种预训练编码器，针对不同年份、序列、模态和患者疾病状态进行了四个关键任务的乳腺注册。&lt;h4&gt;主要发现&lt;/h4&gt;基于基础模型的算法如SAM在总体乳腺对齐方面优于传统注册基线，但在捕捉纤维腺体组织的精细细节方面存在困难。额外在医学或乳腺特定图像上进行预训练或微调并不总是提高配准性能。&lt;h4&gt;结论&lt;/h4&gt;需要进一步研究特定领域训练对配准的影响，并探索改进全局对齐和精细结构准确性的针对性策略。&lt;h4&gt;翻译&lt;/h4&gt;Foundation models, pre-trained on large image datasets and capable of capturing rich feature representations, have recently shown potential for zero-shot image registration. However, their performance has mostly been tested in the context of rigid or less complex structures, such as the brain or abdominal organs, and it remains unclear whether these models can handle more challenging, deformable anatomy. Breast MRI registration is particularly difficult due to significant anatomical variation between patients, deformation caused by patient positioning, and the presence of thin and complex internal structure of fibroglandular tissue, where accurate alignment is crucial. Whether foundation model-based registration algorithms can address this level of complexity remains an open question. In this study, we provide a comprehensive evaluation of foundation model-based registration algorithms for breast MRI. We assess five pre-trained encoders, including DINO-v2, SAM, MedSAM, SSLSAM, and MedCLIP, across four key breast registration tasks that capture variations in different years and dates, sequences, modalities, and patient disease status (lesion versus no lesion). Our results show that foundation model-based algorithms such as SAM outperform traditional registration baselines for overall breast alignment, especially under large domain shifts, but struggle with capturing fine details of fibroglandular tissue. Interestingly, additional pre-training or fine-tuning on medical or breast-specific images in MedSAM and SSLSAM, does not improve registration performance and may even decrease it in some cases. Further work is needed to understand how domain-specific training influences registration and to explore targeted strategies that improve both global alignment and fine structure accuracy. We also publicly release our code at Github.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, pre-trained on large image datasets and capable ofcapturing rich feature representations, have recently shown potential forzero-shot image registration. However, their performance has mostly been testedin the context of rigid or less complex structures, such as the brain orabdominal organs, and it remains unclear whether these models can handle morechallenging, deformable anatomy. Breast MRI registration is particularlydifficult due to significant anatomical variation between patients, deformationcaused by patient positioning, and the presence of thin and complex internalstructure of fibroglandular tissue, where accurate alignment is crucial.Whether foundation model-based registration algorithms can address this levelof complexity remains an open question. In this study, we provide acomprehensive evaluation of foundation model-based registration algorithms forbreast MRI. We assess five pre-trained encoders, including DINO-v2, SAM,MedSAM, SSLSAM, and MedCLIP, across four key breast registration tasks thatcapture variations in different years and dates, sequences, modalities, andpatient disease status (lesion versus no lesion). Our results show thatfoundation model-based algorithms such as SAM outperform traditionalregistration baselines for overall breast alignment, especially under largedomain shifts, but struggle with capturing fine details of fibroglandulartissue. Interestingly, additional pre-training or fine-tuning on medical orbreast-specific images in MedSAM and SSLSAM, does not improve registrationperformance and may even decrease it in some cases. Further work is needed tounderstand how domain-specific training influences registration and to exploretargeted strategies that improve both global alignment and fine structureaccuracy. We also publicly release our code at\href{https://github.com/mazurowski-lab/Foundation-based-reg}{Github}.</description>
      <author>example@mail.com (Hanxue Gu, Yaqian Chen, Nicholas Konz, Qihang Li, Maciej A. Mazurowski)</author>
      <guid isPermaLink="false">2507.11569v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Beyond-mean-field fluctuations for the solution of constraint satisfaction problems</title>
      <link>http://arxiv.org/abs/2507.10360v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了约束满足问题（CSPs），这是复杂性理论的核心，并在密码学和遗传学等多个领域有广泛应用。传统方法使用Hopfield网络寻找近似解，而现代机器学习技术如图神经网络也变得越来越流行。研究利用了MAX-2-SAT这类CSPs到统计物理学中自旋玻璃系统的映射，并使用Glauber动力学来近似寻找其基态，这对应于问题的最优解。研究发现Glauber动力学优于传统的Hopfield网络方法，并能与最先进的求解器相竞争。理论分析揭示了随机波动在寻找CSP解中的作用：即使在$T=0$无热波动的情况下，部分自旋（对应于CSP变量）达到有效的非零温度。这些自旋形成一个子空间，在其中随机Glauber动力学持续进行翻转以找到更好的解。这是因为在自由自旋空间中，自旋翻转不需要能量。理论分析导致了新的确定性求解器，这些求解器有效地考虑了这种波动，从而达到了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;CSPs是复杂性理论的核心，广泛应用于密码学和遗传学等多个领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决CSPs，并证明其性能优于传统方法。&lt;h4&gt;方法&lt;/h4&gt;将MAX-2-SAT这类CSPs映射到自旋玻璃系统，使用Glauber动力学来寻找基态，从而找到问题的最优解。&lt;h4&gt;主要发现&lt;/h4&gt;Glauber动力学在解决CSPs方面优于传统Hopfield网络方法，并能与最先进的求解器相竞争。&lt;h4&gt;结论&lt;/h4&gt;通过理论分析揭示了随机波动在寻找CSP解中的作用，并提出了新的确定性求解器，有效地考虑了波动，从而提高了求解器的性能。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Constraint Satisfaction Problems (CSPs) lie at the heart of complexity theory and find application in a plethora of prominent tasks ranging from cryptography to genetics. Classical approaches use Hopfield networks to find approximate solutions while recently, modern machine-learning techniques like graph neural networks have become popular for this task. In this study, we employ the known mapping of MAX-2-SAT, a class of CSPs, to a spin-glass system from statistical physics, and use Glauber dynamics to approximately find its ground state, which corresponds to the optimal solution of the underlying problem. We show that Glauber dynamics outperforms the traditional Hopfield-network approach and can compete with state-of-the-art solvers. A systematic theoretical analysis uncovers the role of stochastic fluctuations in finding CSP solutions: even in the absence of thermal fluctuations at $T=0$ a significant portion of spins, which correspond to the CSP variables, attains an effective spin-dependent non-zero temperature. These spins form a subspace in which the stochastic Glauber dynamics continuously performs flips to eventually find better solutions. This is possible since the energy is degenerate, such that spin flips in this free-spin space do not require energy. Our theoretical analysis leads to new deterministic solvers that effectively account for such fluctuations, thereby reaching state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Constraint Satisfaction Problems (CSPs) lie at the heart of complexity theoryand find application in a plethora of prominent tasks ranging from cryptographyto genetics. Classical approaches use Hopfield networks to find approximatesolutions while recently, modern machine-learning techniques like graph neuralnetworks have become popular for this task. In this study, we employ the knownmapping of MAX-2-SAT, a class of CSPs, to a spin-glass system from statisticalphysics, and use Glauber dynamics to approximately find its ground state, whichcorresponds to the optimal solution of the underlying problem. We show thatGlauber dynamics outperforms the traditional Hopfield-network approach and cancompete with state-of-the-art solvers. A systematic theoretical analysisuncovers the role of stochastic fluctuations in finding CSP solutions: even inthe absense of thermal fluctuations at $T=0$ a significant portion of spins,which correspond to the CSP variables, attains an effective spin-dependentnon-zero temperature. These spins form a subspace in which the stochasticGlauber dynamics continuously performs flips to eventually find bettersolutions. This is possible since the energy is degenerate, such that spinflips in this free-spin space do not require energy. Our theoretical analysisleads to new deterministic solvers that effectively account for suchfluctuations, thereby reaching state-of-the-art performance.</description>
      <author>example@mail.com (Niklas Foos, Bastian Epping, Jannik Grundler, Alexandru Ciobanu, Ajainderpal Singh, Tim Bode, Moritz Helias, David Dahmen)</author>
      <guid isPermaLink="false">2507.10360v2</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction</title>
      <link>http://arxiv.org/abs/2507.11550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Deformable Dynamic Convolution Network (DDCN)的新方法，用于准确且高效地进行时空交通预测。&lt;h4&gt;背景&lt;/h4&gt;时空交通预测在智能交通系统中扮演重要角色，但目前的方法在处理不同地区和时间段的交通模式变化以及大规模数据时存在效率和准确性问题。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的局限性，提出一种新的网络结构，以实现准确且高效的交通预测。&lt;h4&gt;方法&lt;/h4&gt;DDCN通过动态应用基于偏移量的可变形滤波器来克服传统卷积神经网络在建模非欧几里得空间结构和时空异质性方面的限制。该方法将变换器风格的卷积神经网络分解为编码器-解码器结构，并应用了新的方法来强调编码器中的空间和时空注意力块中的重要特征。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界数据集上的综合实验表明，DDCN实现了有竞争力的性能，强调了基于CNN的时空交通预测方法的潜力和有效性。&lt;h4&gt;结论&lt;/h4&gt;DDCN是一种有效的时空交通预测方法，具有准确性和效率的双重优势，为智能交通系统的发展提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Spatio-temporal traffic prediction plays a key role in intelligent transportation systems by enabling accurate prediction in complex urban areas. Although not only accuracy but also efficiency for scalability is important, some previous methods struggle to capture heterogeneity such as varying traffic patterns across regions and time periods. Moreover, Graph Neural Networks (GNNs), which are the mainstream of traffic prediction, not only require predefined adjacency matrix, but also limit scalability to large-scale data containing many nodes due to their inherent complexity. To overcome these limitations, we propose Deformable Dynamic Convolution Network (DDCN) for accurate yet efficient traffic prediction. Traditional Convolutional Neural Networks (CNNs) are limited in modeling non-Euclidean spatial structures and spatio-temporal heterogeneity, DDCN overcomes these challenges by dynamically applying deformable filters based on offset. Specifically, DDCN decomposes transformer-style CNN to encoder-decoder structure, and applies proposed approaches to the spatial and spatio-temporal attention blocks of the encoder to emphasize important features. The decoder, composed of feed-forward module, complements the output of the encoder. This novel structure make DDCN can perform accurate yet efficient traffic prediction. In comprehensive experiments on four real-world datasets, DDCN achieves competitive performance, emphasizing the potential and effectiveness of CNN-based approaches for spatio-temporal traffic prediction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatio-temporal traffic prediction plays a key role in intelligenttransportation systems by enabling accurate prediction in complex urban areas.Although not only accuracy but also efficiency for scalability is important,some previous methods struggle to capture heterogeneity such as varying trafficpatterns across regions and time periods. Moreover, Graph Neural Networks(GNNs), which are the mainstream of traffic prediction, not only requirepredefined adjacency matrix, but also limit scalability to large-scale datacontaining many nodes due to their inherent complexity. To overcome theselimitations, we propose Deformable Dynamic Convolution Network (DDCN) foraccurate yet efficient traffic prediction. Traditional Convolutional NeuralNetworks (CNNs) are limited in modeling non-Euclidean spatial structures andspatio-temporal heterogeneity, DDCN overcomes these challenges by dynamicallyapplying deformable filters based on offset. Specifically, DDCN decomposestransformer-style CNN to encoder-decoder structure, and applies proposedapproaches to the spatial and spatio-temporal attention blocks of the encoderto emphasize important features. The decoder, composed of feed-forward module,complements the output of the encoder. This novel structure make DDCN canperform accurate yet efficient traffic prediction. In comprehensive experimentson four real-world datasets, DDCN achieves competitive performance, emphasizingthe potential and effectiveness of CNN-based approaches for spatio-temporaltraffic prediction.</description>
      <author>example@mail.com (Hyeonseok Jin, Geonmin Kim, Kyungbaek Kim)</author>
      <guid isPermaLink="false">2507.11550v1</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Dual Dimensions Geometric Representation Learning Based Document Dewarping</title>
      <link>http://arxiv.org/abs/2507.08492v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为D2Dewarp的精细变形感知模型，旨在提高文档图像的校正效果。&lt;h4&gt;背景&lt;/h4&gt;尽管现有方法通过利用文本行意识有所改进，但它们通常只关注单一的水平维度。&lt;h4&gt;目的&lt;/h4&gt;提出一个关注文档水平-垂直线的双重维度，以感知不同方向上的扭曲趋势。&lt;h4&gt;方法&lt;/h4&gt;设计了一个基于X和Y坐标的有效融合模块，以结合水平和垂直粒度特征，并提出了一个自动精细标注方法，用于构建新的大规模扭曲训练数据集。&lt;h4&gt;主要发现&lt;/h4&gt;在公开的中文和英文基准测试中，该方法在定量和定性结果上均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该模型和数据集将公开可用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在深度学习时代，文档图像去畸变仍然是一个具有挑战性的任务。虽然现有方法通过利用文本行意识得到了改进，但它们通常只关注单一的水平维度。在本文中，我们提出了一种关注文档水平-垂直线双重维度的精细变形感知模型，称为D2Dewarp。它可以感知文档细节中不同方向上的扭曲趋势。为了结合水平和垂直粒度特征，我们设计了一个基于X和Y坐标的有效融合模块，以促进两个维度之间的交互和约束，实现特征互补。由于当前公开的去畸变数据集中缺乏标注的行特征，我们还提出了一种使用公共文档纹理图像和自动渲染引擎的自动精细标注方法，以构建一个新的大规模扭曲训练数据集。代码和数据集将公开发布。在公开的中文和英文基准测试中，定性和定量结果均表明，与现有方法相比，我们的方法实现了更好的校正结果。数据集可在https://github.com/xiaomore/DocDewarpHV上公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Document image dewarping remains a challenging task in the deep learning era.While existing methods have improved by leveraging text line awareness, theytypically focus only on a single horizontal dimension. In this paper, wepropose a fine-grained deformation perception model that focuses on DualDimensions of document horizontal-vertical-lines to improve document Dewarpingcalled D2Dewarp. It can perceive distortion trends in different directionsacross document details. To combine the horizontal and vertical granularityfeatures, an effective fusion module based on X and Y coordinate is designed tofacilitate interaction and constraint between the two dimensions for featurecomplementarity. Due to the lack of annotated line features in current publicdewarping datasets, we also propose an automatic fine-grained annotation methodusing public document texture images and an automatic rendering engine to builda new large-scale distortion training dataset. The code and dataset will bepublicly released. On public Chinese and English benchmarks, both quantitativeand qualitative results show that our method achieves better rectificationresults compared with the state-of-the-art methods. The dataset will bepublicly available at https://github.com/xiaomore/DocDewarpHV</description>
      <author>example@mail.com (Heng Li, Qingcai Chen, Xiangping Wu)</author>
      <guid isPermaLink="false">2507.08492v2</guid>
      <pubDate>Thu, 17 Jul 2025 14:19:39 +0800</pubDate>
    </item>
    <item>
      <title>Improving Multimodal Learning via Imbalanced Learning</title>
      <link>http://arxiv.org/abs/2507.10203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Asymmetric Representation Learning（ARL）的策略，用于解决多模态学习中的欠优化问题，并通过不平衡优化来辅助多模态学习。&lt;h4&gt;背景&lt;/h4&gt;多模态学习往往遇到欠优化的问题，可能比单模态学习表现更差。现有方法将这个问题归因于模态之间的不平衡学习，并倾向于通过梯度平衡来解决。&lt;h4&gt;目的&lt;/h4&gt;证明平衡学习不是多模态学习的最佳设置，并提出ARL策略以实现最优性能。&lt;h4&gt;方法&lt;/h4&gt;通过偏差-方差分析，证明了每个模态的不平衡依赖关系遵循其方差的倒数比例，有助于最优性能。ARL为每个模态编码器引入辅助正则化器来计算其预测方差，并通过单模态方差计算系数来重新加权每个模态的优化。此外，为了最小化泛化误差，ARL进一步引入了每个模态的预测偏差，并与多模态损失联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;ARL策略通过引入辅助正则化器，不增加额外参数，且独立于多模态模型的结构和融合方法。&lt;h4&gt;结论&lt;/h4&gt;在多个数据集上的广泛实验验证了ARL策略的有效性和通用性。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal learning often encounters the under-optimized problem and may perform worse than unimodal learning. Existing approaches attribute this issue to imbalanced learning across modalities and tend to address it through gradient balancing. However, this paper argues that balanced learning is not the optimal setting for multimodal learning. With bias-variance analysis, we prove that imbalanced dependency on each modality obeying the inverse ratio of their variances contributes to optimal performance. To this end, we propose the Asymmetric Representation Learning (ARL) strategy to assist multimodal learning via imbalanced optimization. ARL introduces auxiliary regularizers for each modality encoder to calculate their prediction variance. ARL then calculates coefficients via the unimodal variance to re-weight the optimization of each modality, forcing the modality dependence ratio to be inversely proportional to the modality variance ratio. Moreover, to minimize the generalization error, ARL further introduces the prediction bias of each modality and jointly optimizes them with multimodal loss. Notably, all auxiliary regularizers share parameters with the multimodal model and rely only on the modality representation. Thus the proposed ARL strategy introduces no extra parameters and is independent of the structures and fusion methods of the multimodal model. Finally, extensive experiments on various datasets validate the effectiveness and versatility of ARL. Code is available at https://github.com/shicaiwei123/ICCV2025-ARL&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning often encounters the under-optimized problem and mayperform worse than unimodal learning. Existing approaches attribute this issueto imbalanced learning across modalities and tend to address it throughgradient balancing. However, this paper argues that balanced learning is notthe optimal setting for multimodal learning. With bias-variance analysis, weprove that imbalanced dependency on each modality obeying the inverse ratio oftheir variances contributes to optimal performance. To this end, we propose theAsymmetric Representation Learning(ARL) strategy to assist multimodal learningvia imbalanced optimization. ARL introduces auxiliary regularizers for eachmodality encoder to calculate their prediction variance. ARL then calculatescoefficients via the unimodal variance to re-weight the optimization of eachmodality, forcing the modality dependence ratio to be inversely proportional tothe modality variance ratio. Moreover, to minimize the generalization error,ARL further introduces the prediction bias of each modality and jointlyoptimizes them with multimodal loss. Notably, all auxiliary regularizers shareparameters with the multimodal model and rely only on the modalityrepresentation. Thus the proposed ARL strategy introduces no extra parametersand is independent of the structures and fusion methods of the multimodalmodel. Finally, extensive experiments on various datasets validate theeffectiveness and versatility of ARL. Code is available at\href{https://github.com/shicaiwei123/ICCV2025-ARL}{https://github.com/shicaiwei123/ICCV2025-ARL}</description>
      <author>example@mail.com (Shicai Wei, Chunbo Luo, Yang Luo)</author>
      <guid isPermaLink="false">2507.10203v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
  <item>
      <title>How does Labeling Error Impact Contrastive Learning? A Perspective from Data Dimensionality Reduction</title>
      <link>http://arxiv.org/abs/2507.11161v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML2025 as a poster&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了标签错误对对比学习下游分类性能的理论影响，并提出了一些缓解标签错误影响的方法。&lt;h4&gt;背景&lt;/h4&gt;近年来，对比学习在自监督表示学习领域取得了卓越表现。然而，由于常见的增强策略如随机裁剪（RRC）的强度和随机性，标签一致性假设可能不成立，导致标签错误。&lt;h4&gt;目的&lt;/h4&gt;研究标签错误对对比学习下游分类性能的理论影响，并提出缓解方法。&lt;h4&gt;方法&lt;/h4&gt;首先揭示了标签错误对下游分类风险的几个负面影响。为了缓解这些影响，对原始数据应用数据降维方法（如奇异值分解，SVD）以减少误报样本，并建立了理论性和实证性评估。此外，还发现SVD可能因为减少了增强图的连通性而导致下游分类准确性的下降。&lt;h4&gt;主要发现&lt;/h4&gt;标签错误对下游分类风险有显著的负面影响，SVD在增强图连通性和分类准确性之间起到双重作用。&lt;h4&gt;结论&lt;/h4&gt;提出了使用适度嵌入维度、数据膨胀、弱增强和SVD等方法，以确保大图连通性和小标签错误，从而提高模型性能。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, contrastive learning has achieved state-of-the-art performance in the territory of self-supervised representation learning. Many previous works have attempted to provide the theoretical understanding underlying the success of contrastive learning. Almost all of them rely on a default assumption, i.e., the label consistency assumption, which may not hold in practice (the probability of failure is called labeling error) due to the strength and randomness of common augmentation strategies, such as random resized crop (RRC). This paper investigates the theoretical impact of labeling error on the downstream classification performance of contrastive learning. We first reveal several significant negative impacts of labeling error on downstream classification risk. To mitigate these impacts, data dimensionality reduction method (e.g., singular value decomposition, SVD) is applied on original data to reduce false positive samples, and establish both theoretical and empirical evaluations. Moreover, it is also found that SVD acts as a double-edged sword, which may lead to the deterioration of downstream classification accuracy due to the reduced connectivity of the augmentation graph. Based on the above observations, we give the augmentation suggestion that we should use some moderate embedding dimension (such as $512, 1024$ in our experiments), data inflation, weak augmentation, and SVD to ensure large graph connectivity and small labeling error to improve model performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, contrastive learning has achieved state-of-the-artperformance in the territory of self-supervised representation learning. Manyprevious works have attempted to provide the theoretical understandingunderlying the success of contrastive learning. Almost all of them rely on adefault assumption, i.e., the label consistency assumption, which may not holdin practice (the probability of failure is called labeling error) due to thestrength and randomness of common augmentation strategies, such as randomresized crop (RRC). This paper investigates the theoretical impact of labelingerror on the downstream classification performance of contrastive learning. Wefirst reveal several significant negative impacts of labeling error ondownstream classification risk. To mitigate these impacts, data dimensionalityreduction method (e.g., singular value decomposition, SVD) is applied onoriginal data to reduce false positive samples, and establish both theoreticaland empirical evaluations. Moreover, it is also found that SVD acts as adouble-edged sword, which may lead to the deterioration of downstreamclassification accuracy due to the reduced connectivity of the augmentationgraph. Based on the above observations, we give the augmentation suggestionthat we should use some moderate embedding dimension (such as $512, 1024$ inour experiments), data inflation, weak augmentation, and SVD to ensure largegraph connectivity and small labeling error to improve model performance.</description>
      <author>example@mail.com (Jun Chen, Hong Chen, Yonghua Yu, Yiming Ying)</author>
      <guid isPermaLink="false">2507.11161v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>A Multi-View High-Resolution Foot-Ankle Complex Point Cloud Dataset During Gait for Occlusion-Robust 3D Completion</title>
      <link>http://arxiv.org/abs/2507.11037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 10 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一个名为FootGait3D的多视角数据集，用于分析足踝复合体在行走过程中的运动学。该数据集提供了高分辨率足踝表面点云，旨在促进生物力学研究和临床评估。&lt;h4&gt;背景&lt;/h4&gt;由于行走过程中足部遮挡和视角限制，从足踝收集准确表面几何数据具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;通过FootGait3D数据集，旨在提供足踝区域的高精度运动数据，以支持形状补全任务，并促进生物力学和多段足建模的研究。&lt;h4&gt;方法&lt;/h4&gt;FootGait3D由46个受试者使用定制五摄像头深度感知系统采集的8,403个点云帧组成。每个帧包括足踝的完整5视图重建（作为真实值）和仅从四个、三个或两个视角获得的局部点云。&lt;h4&gt;主要发现&lt;/h4&gt;FootGait3D数据集有助于在变化的遮挡水平和视角下评估3D点云补全方法，并为形状补全任务提供了基准。&lt;h4&gt;结论&lt;/h4&gt;FootGait3D具有推动生物力学和多段足建模研究的潜力，对于临床步态分析、假肢设计和需要足部动态3D模型的机器人应用具有重要价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了足踝复合体在步态过程中的运动学分析对于推进生物力学研究和临床评估的重要性。由于行走时足部遮挡和观察限制，从足踝在动态步态条件下收集准确的表面几何数据固有的具有挑战性。因此，本文引入了FootGait3D，这是一个在自然步态过程中捕获的高分辨率踝足表面点云的新颖多视角数据集。与通常针对全身或下肢运动的现有步态数据集不同，FootGait3D专门针对踝足区域的详细建模，提供了更细粒度的运动数据。为了解决这个问题，FootGait3D由使用定制五摄像头深度感知系统从46个受试者收集的8,403个点云帧组成。每个帧包括足踝的完整5视图重建（作为真实值）以及仅从四个、三个或两个视图获得的局部点云。这种结构化的变化使得可以在不同的遮挡水平和视角下严格评估3D点云补全方法。我们的数据集旨在进行形状补全任务，便于在恢复遮挡输入的完整足部几何形状的挑战上，对最先进的单模态（例如，PointTr，SnowflakeNet，Anchorformer）和多模态（例如，SVDFormer，PointSea，CSDN）补全网络进行基准测试。FootGait3D具有推进生物力学和多段足建模研究的潜力，为临床步态分析、假肢设计和需要运动中足部详细3D模型的机器人应用提供了一个宝贵的测试平台。该数据集现在可在https://huggingface.co/datasets/ljw285/FootGait3D获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The kinematics analysis of foot-ankle complex during gait is essential foradvancing biomechanical research and clinical assessment. Collecting accuratesurface geometry data from the foot and ankle during dynamic gait conditions isinherently challenging due to swing foot occlusions and viewing limitations.Thus, this paper introduces FootGait3D, a novel multi-view dataset ofhigh-resolution ankle-foot surface point clouds captured during natural gait.Different from existing gait datasets that typically target whole-body orlower-limb motion, FootGait3D focuses specifically on the detailed modeling ofthe ankle-foot region, offering a finer granularity of motion data. To addressthis, FootGait3D consists of 8,403 point cloud frames collected from 46subjects using a custom five-camera depth sensing system. Each frame includes acomplete 5-view reconstruction of the foot and ankle (serving as ground truth)along with partial point clouds obtained from only four, three, or two views.This structured variation enables rigorous evaluation of 3D point cloudcompletion methods under varying occlusion levels and viewpoints. Our datasetis designed for shape completion tasks, facilitating the benchmarking ofstate-of-the-art single-modal (e.g., PointTr, SnowflakeNet, Anchorformer) andmulti-modal (e.g., SVDFormer, PointSea, CSDN) completion networks on thechallenge of recovering the full foot geometry from occluded inputs. FootGait3Dhas significant potential to advance research in biomechanics and multi-segmentfoot modeling, offering a valuable testbed for clinical gait analysis,prosthetic design, and robotics applications requiring detailed 3D models ofthe foot during motion. The dataset is now available athttps://huggingface.co/datasets/ljw285/FootGait3D.</description>
      <author>example@mail.com (Jie-Wen Li, Zi-Han Ye, Qingyuan Zhou, Jiayi Song, Ying He, Ben Fei, Wen-Ming Chen)</author>
      <guid isPermaLink="false">2507.11037v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Modeling Code: Is Text All You Need?</title>
      <link>http://arxiv.org/abs/2507.11467v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了结合代码作为文本和更结构化形式建模的新方法。&lt;h4&gt;背景&lt;/h4&gt;近期，代码语言模型（Code LLMs）在源代码建模方面变得非常流行，应用于代码生成、翻译和摘要等任务。然而，基于transformer的模型在推理代码的结构化和分析属性（如控制和数据流）方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，以结合现代大型语言模型（LLMs）的生成能力和对代码结构化属性的建模能力。&lt;h4&gt;方法&lt;/h4&gt;论文探索了将代码作为文本和更结构化的形式相结合的方法，以弥补现有方法的不足。&lt;h4&gt;主要发现&lt;/h4&gt;新方法结合了代码作为文本和结构化数据的建模优势。&lt;h4&gt;结论&lt;/h4&gt;通过结合代码文本和结构化形式，新方法有望提升代码建模的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;近期，代码语言模型（Code LLMs）因其能够对源代码进行建模而在多种任务中变得非常流行，如生成、翻译和摘要等。然而，基于transformer的模型在推理代码的结构化和分析属性，如控制和数据流方面存在局限性。先前的研究已经探讨了使用结构化数据和图神经网络来建模这些属性。然而，这些方法缺乏现代LLMs的生成能力和规模。在本研究中，我们介绍了一种新的方法来结合将代码作为文本和更结构化形式建模的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Code LLMs have become extremely popular recently for modeling source codeacross a variety of tasks, such as generation, translation, and summarization.However, transformer-based models are limited in their capabilities to reasonthrough structured, analytical properties of code, such as control and dataflow. Previous work has explored the modeling of these properties withstructured data and graph neural networks. However, these approaches lack thegenerative capabilities and scale of modern LLMs. In this work, we introduce anovel approach to combine the strengths of modeling both code as text and morestructured forms.</description>
      <author>example@mail.com (Daniel Nichols, Konstantinos Parasyris, Harshitha Menon, Brian R. Bartoldson, Giorgis Georgakoudis, Tal Ben-Nun, Abhinav Bhatele)</author>
      <guid isPermaLink="false">2507.11467v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander</title>
      <link>http://arxiv.org/abs/2507.11079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉语言模型和轻量级大型语言模型的指挥官模型，用于解决自主对抗中的智能感知到决策推理问题。&lt;h4&gt;背景&lt;/h4&gt;在多无人地面车辆对抗中，自主演化的多智能体战术决策从态势感知中仍然是一个重大挑战。传统的基于规则的手工方法在复杂和瞬变的战场环境中变得脆弱，而当前的强化学习方法由于缺乏可解释性，主要关注动作操作而不是战略决策。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决自主对抗中的智能感知到决策推理问题。&lt;h4&gt;方法&lt;/h4&gt;该方法整合了视觉语言模型进行场景理解和轻量级大型语言模型进行战略推理，在共享语义空间内实现统一的感知和决策，具有强大的适应性和可解释性。与基于规则搜索和强化学习方法不同，两个模块的结合建立了一个全链过程，反映了人类指挥官的认知过程。&lt;h4&gt;主要发现&lt;/h4&gt;仿真和消融实验验证了所提出的方法与基线模型相比，实现了超过80%的胜率。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在自主对抗中表现出色，能够有效提高无人地面车辆的战术决策能力。&lt;h4&gt;翻译&lt;/h4&gt;In multiple unmanned ground vehicle confrontations, autonomously evolving multi-agent tactical decisions from situational awareness remain a significant challenge. Traditional handcraft rule-based methods become vulnerable in the complicated and transient battlefield environment, and current reinforcement learning methods mainly focus on action manipulation instead of strategic decisions due to lack of interpretability. Here, we propose a vision-language model-based commander to address the issue of intelligent perception-to-decision reasoning in autonomous confrontations. Our method integrates a vision language model for scene understanding and a lightweight large language model for strategic reasoning, achieving unified perception and decision within a shared semantic space, with strong adaptability and interpretability. Unlike rule-based search and reinforcement learning methods, the combination of the two modules establishes a full-chain process, reflecting the cognitive process of human commanders. Simulation and ablation experiments validate that the proposed approach achieves a win rate of over 80% compared with baseline models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In multiple unmanned ground vehicle confrontations, autonomously evolvingmulti-agent tactical decisions from situational awareness remain a significantchallenge. Traditional handcraft rule-based methods become vulnerable in thecomplicated and transient battlefield environment, and current reinforcementlearning methods mainly focus on action manipulation instead of strategicdecisions due to lack of interpretability. Here, we propose a vision-languagemodel-based commander to address the issue of intelligentperception-to-decision reasoning in autonomous confrontations. Our methodintegrates a vision language model for scene understanding and a lightweightlarge language model for strategic reasoning, achieving unified perception anddecision within a shared semantic space, with strong adaptability andinterpretability. Unlike rule-based search and reinforcement learning methods,the combination of the two modules establishes a full-chain process, reflectingthe cognitive process of human commanders. Simulation and ablation experimentsvalidate that the proposed approach achieves a win rate of over 80% comparedwith baseline models.</description>
      <author>example@mail.com (Li Wang, Qizhen Wu, Lei Chen)</author>
      <guid isPermaLink="false">2507.11079v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network</title>
      <link>http://arxiv.org/abs/2507.11333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MonoMVSNet是一种新型的单目特征和深度引导的多视图立体（MVS）网络，它通过整合单目基础模型中的强大先验知识到多视图几何中，实现了在纹理缺失区域和反射表面等挑战区域的鲁棒深度估计。&lt;h4&gt;背景&lt;/h4&gt;现有的MVS方法在处理如纹理缺失区域和反射表面等复杂区域时，往往因为特征匹配失败而遇到困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有MVS方法在挑战区域的问题，MonoMVSNet旨在提供一种鲁棒的深度估计方法。&lt;h4&gt;方法&lt;/h4&gt;MonoMVSNet通过以下步骤实现：1. 使用注意力机制和新的交叉视图位置编码将参考视图的单目特征集成到源视图特征中；2. 在采样过程中，将参考视图的单目深度与边缘区域的深度候选对齐，以动态更新深度候选；3. 基于单目深度设计相对一致性损失来监督深度预测。&lt;h4&gt;主要发现&lt;/h4&gt;MonoMVSNet在DTU和Tanks-and-Temples数据集上实现了最先进的性能，在Tanks-and-Temples Intermediate和Advanced基准测试中排名第一。&lt;h4&gt;结论&lt;/h4&gt;MonoMVSNet是一种有效的MVS方法，能够提高在纹理缺失和反射表面等挑战区域的深度估计的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;学习型多视图立体（MVS）方法旨在预测一系列校准图像的深度图以恢复密集点云。然而，现有的MVS方法在处理如无纹理区域和反射表面等挑战区域时，往往因为特征匹配失败而遇到困难。相比之下，单目深度估计内在地不需要特征匹配，因此能够在这些区域实现鲁棒的相对深度估计。为了弥合这一差距，我们提出了MonoMVSNet，这是一种新颖的单目特征和深度引导的MVS网络，它将单目基础模型中的强大先验知识整合到多视图几何中。首先，通过具有新设计的交叉视图位置编码的注意力机制将参考视图的单目特征集成到源视图特征中。然后，在采样过程中将参考视图的单目深度与边缘区域的深度候选对齐，以动态更新深度候选。最后，基于单目深度进一步设计了相对一致性损失来监督深度预测。大量实验表明，MonoMVSNet在DTU和Tanks-and-Temples数据集上实现了最先进的性能，在Tanks-and-Temples Intermediate和Advanced基准测试中排名第一。源代码可在https://github.com/JianfeiJ/MonoMVSNet上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning-based Multi-View Stereo (MVS) methods aim to predict depth maps fora sequence of calibrated images to recover dense point clouds. However,existing MVS methods often struggle with challenging regions, such astextureless regions and reflective surfaces, where feature matching fails. Incontrast, monocular depth estimation inherently does not require featurematching, allowing it to achieve robust relative depth estimation in theseregions. To bridge this gap, we propose MonoMVSNet, a novel monocular featureand depth guided MVS network that integrates powerful priors from a monocularfoundation model into multi-view geometry. Firstly, the monocular feature ofthe reference view is integrated into source view features by the attentionmechanism with a newly designed cross-view position encoding. Then, themonocular depth of the reference view is aligned to dynamically update thedepth candidates for edge regions during the sampling procedure. Finally, arelative consistency loss is further designed based on the monocular depth tosupervise the depth prediction. Extensive experiments demonstrate thatMonoMVSNet achieves state-of-the-art performance on the DTU andTanks-and-Temples datasets, ranking first on the Tanks-and-Temples Intermediateand Advanced benchmarks. The source code is available athttps://github.com/JianfeiJ/MonoMVSNet.</description>
      <author>example@mail.com (Jianfei Jiang, Qiankun Liu, Haochen Yu, Hongyuan Liu, Liyong Wang, Jiansheng Chen, Huimin Ma)</author>
      <guid isPermaLink="false">2507.11333v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Latent Space Consistency for Sparse-View CT Reconstruction</title>
      <link>http://arxiv.org/abs/2507.11152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACMMM2025 Accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为CLS-DM的CT重建方法，通过对比学习实现了2D X射线图像到3D CT图像的有效转换。&lt;h4&gt;背景&lt;/h4&gt;CT扫描在临床中广泛应用，但传统的CT扫描方法耗时且辐射量高。基于稀疏视图的CT重建方法受到关注，但现有的Latent Diffusion Model在处理2D和3D模态的转换时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效转换2D X射线图像到3D CT图像的方法，减少CT扫描的时间和辐射。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Consistent Latent Space Diffusion Model (CLS-DM)的方法，它通过跨模态特征对比学习从2D X射线图像中提取3D信息，并在潜在空间中实现模态间的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;CLS-DM在LIDC-IDRI和CTSpine1K数据集上的标准体素级指标（PSNR、SSIM）优于经典和最先进的生成模型。&lt;h4&gt;结论&lt;/h4&gt;CLS-DM不仅提高了稀疏X射线重建CT的有效性和经济可行性，还可以推广到其他跨模态转换任务，如文本到图像合成。&lt;h4&gt;翻译&lt;/h4&gt;Computed Tomography (CT)是一种广泛应用于临床的成像方法。利用密集获取的旋转X射线阵列，CT可以捕获3D空间特征。然而，它面临着耗时长和辐射暴露高的挑战。基于稀疏视图X射线图像的CT重建方法已经引起研究者的广泛关注，因为它们提供了一种降低成本和风险的方法。近年来，扩散模型，特别是潜在的扩散模型（LDM），在3D CT重建领域显示出了有希望的潜力。然而，由于X射线模态的2D潜在表示与CT模态的3D潜在表示之间存在显著差异，传统的LDM无法在潜在空间内实现有效的对齐。为了解决这个问题，我们提出了一个名为一致的潜在空间扩散模型（CLS-DM）的模型，该模型通过跨模态特征对比学习有效地从2D X射线图像中提取潜在3D信息，并实现模态间的潜在空间对齐。实验结果表明，CLS-DM在LIDC-IDRI和CTSpine1K数据集上的标准体素级指标（PSNR、SSIM）方面优于经典和最先进的生成模型。这种方法不仅有助于提高稀疏X射线重建CT的有效性和经济可行性，还可以推广到其他跨模态转换任务，例如文本到图像合成。我们已在https://anonymous.4open.science/r/CLS-DM-50D6/上公开我们的代码，以促进其他领域的研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computed Tomography (CT) is a widely utilized imaging modality in clinicalsettings. Using densely acquired rotational X-ray arrays, CT can capture 3Dspatial features. However, it is confronted with challenged such as significanttime consumption and high radiation exposure. CT reconstruction methods basedon sparse-view X-ray images have garnered substantial attention fromresearchers as they present a means to mitigate costs and risks. In recentyears, diffusion models, particularly the Latent Diffusion Model (LDM), havedemonstrated promising potential in the domain of 3D CT reconstruction.Nonetheless, due to the substantial differences between the 2D latentrepresentation of X-ray modalities and the 3D latent representation of CTmodalities, the vanilla LDM is incapable of achieving effective alignmentwithin the latent space. To address this issue, we propose the ConsistentLatent Space Diffusion Model (CLS-DM), which incorporates cross-modal featurecontrastive learning to efficiently extract latent 3D information from 2D X-rayimages and achieve latent space alignment between modalities. Experimentalresults indicate that CLS-DM outperforms classical and state-of-the-artgenerative models in terms of standard voxel-level metrics (PSNR, SSIM) on theLIDC-IDRI and CTSpine1K datasets. This methodology not only aids in enhancingthe effectiveness and economic viability of sparse X-ray reconstructed CT butcan also be generalized to other cross-modal transformation tasks, such astext-to-image synthesis. We have made our code publicly available athttps://anonymous.4open.science/r/CLS-DM-50D6/ to facilitate further researchand applications in other domains.</description>
      <author>example@mail.com (Duoyou Chen, Yunqing Chen, Can Zhang, Zhou Wang, Cheng Chen, Ruoxiu Xiao)</author>
      <guid isPermaLink="false">2507.11152v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Urban delineation through the lens of commute networks: Leveraging graph embeddings to distinguish socioeconomic groups in cities</title>
      <link>http://arxiv.org/abs/2507.11057v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究利用通勤网络进行城市区域划分，通过图神经网络（GNN）建模，提取城市区域的低维表示，并聚类节点以识别城市区域中的空间社区，从而捕捉社区间的社会经济差异。&lt;h4&gt;背景&lt;/h4&gt;城市研究者关注城市区域划分，以了解由人口动态变化形成的城市边界，这在城市科学中有广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出使用来自人口普查的通勤网络进行城市划分，并评估图神经网络（GNN）在构建城市区域有意义表示中的效用。&lt;h4&gt;方法&lt;/h4&gt;使用GNN对通勤网络进行建模，提取城市区域的低维表示，并通过聚类节点识别城市区域中的空间社区。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，网络嵌入在捕捉不同城市社区间的显著社会经济差异方面有效，特别是在中位家庭收入等指标上。同时，强调了人口普查移动数据在区域划分中的作用，并证明了GNN在城市社区检测中的实用性。&lt;h4&gt;结论&lt;/h4&gt;通勤网络对城市区域有广泛影响，GNN在构建城市区域的有意义表示方面是一种强大的替代方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Delineating areas within metropolitan regions stands as an important focusamong urban researchers, shedding light on the urban perimeters shaped byevolving population dynamics. Applications to urban science are numerous, fromfacilitating comparisons between delineated districts and administrativedivisions to informing policymakers of the shifting economic and laborlandscapes. In this study, we propose using commute networks sourced from thecensus for the purpose of urban delineation, by modeling them with a GraphNeural Network (GNN) architecture. We derive low-dimensional representations ofgranular urban areas (nodes) using GNNs. Subsequently, nodes' embeddings areclustered to identify spatially cohesive communities in urban areas. Ourexperiments across the U.S. demonstrate the effectiveness of network embeddingsin capturing significant socioeconomic disparities between communities invarious cities, particularly in factors such as median household income. Therole of census mobility data in regional delineation is also noted, and weestablish the utility of GNNs in urban community detection, as a powerfulalternative to existing methods in this domain. The results offer insights intothe wider effects of commute networks and their use in building meaningfulrepresentations of urban regions.</description>
      <author>example@mail.com (Devashish Khulbe, Stanislav Sobolevsky)</author>
      <guid isPermaLink="false">2507.11057v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Tune Like an Expert: Interpretable and Scene-Aware Navigation via MLLM Reasoning and CVAE-Based Adaptation</title>
      <link>http://arxiv.org/abs/2507.11001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为LE-Nav的导航框架，用于解决服务机器人在动态环境中的导航问题，并展示了其在实际应用中的优势。&lt;h4&gt;背景&lt;/h4&gt;服务机器人在不同环境中使用，物理布局和社会环境随时间和地点变化，传统导航系统在无结构环境中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一个可解释、场景感知的导航框架，以提高服务机器人在动态环境中的导航能力。&lt;h4&gt;方法&lt;/h4&gt;LE-Nav利用多模态大型语言模型推理和条件变分自动编码器来自适应调整规划器的超参数。通过使用一次性示例和思维链提示策略实现零样本场景理解，并通过条件变分自动编码器将自然语言指令与导航超参数之间的映射。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LE-Nav能够在不同规划和场景中生成达到人类水平调优的超参数。实际导航试验和智能轮椅平台上的用户研究表明，它在成功率、效率、安全性和舒适性等定量指标上优于现有方法，并且在感知安全和社会接受度方面获得更高的主观评分。&lt;h4&gt;结论&lt;/h4&gt;LE-Nav是一种有效提高服务机器人在动态环境中导航能力的框架，具有可解释性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：服务机器人在多样化和动态环境中得到越来越多地部署，这些环境中的物理布局和社会情境随时间和地点变化。在这些无结构环境中，依赖于固定参数的传统导航系统往往无法在不同场景中泛化，导致性能下降和社交接受度降低。尽管最近的方法利用强化学习来增强传统规划器，但这些方法由于泛化能力差和模拟多样性有限，在现实世界的部署中往往失败，阻碍了从模拟到现实的迁移。为了解决这些问题，我们提出了一种可解释和场景感知的导航框架LE-Nav，该框架利用多模态大型语言模型推理和条件变分自动编码器来自适应调整规划器的超参数。为了实现零样本场景理解，我们利用了一次性示例和思维链提示策略。此外，条件变分自动编码器捕捉了自然语言指令与导航超参数之间的映射，实现了专家级的调整。实验表明，LE-Nav可以生成在不同规划和场景中达到人类水平调优的超参数。实际导航试验和智能轮椅平台上的用户研究表明，它在成功率、效率、安全性和舒适性等定量指标上优于现有方法，并且在感知安全和社会接受度方面获得更高的主观评分。代码可在https://github.com/Cavendish518/LE-Nav获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Service robots are increasingly deployed in diverse and dynamic environments,where both physical layouts and social contexts change over time and acrosslocations. In these unstructured settings, conventional navigation systems thatrely on fixed parameters often fail to generalize across scenarios, resultingin degraded performance and reduced social acceptance. Although recentapproaches have leveraged reinforcement learning to enhance traditionalplanners, these methods often fail in real-world deployments due to poorgeneralization and limited simulation diversity, which hampers effectivesim-to-real transfer. To tackle these issues, we present LE-Nav, aninterpretable and scene-aware navigation framework that leverages multi-modallarge language model reasoning and conditional variational autoencoders toadaptively tune planner hyperparameters. To achieve zero-shot sceneunderstanding, we utilize one-shot exemplars and chain-of-thought promptingstrategies. Additionally, a conditional variational autoencoder captures themapping between natural language instructions and navigation hyperparameters,enabling expert-level tuning. Experiments show that LE-Nav can generatehyperparameters achieving human-level tuning across diverse planners andscenarios. Real-world navigation trials and a user study on a smart wheelchairplatform demonstrate that it outperforms state-of-the-art methods onquantitative metrics such as success rate, efficiency, safety, and comfort,while receiving higher subjective scores for perceived safety and socialacceptance. Code is available at https://github.com/Cavendish518/LE-Nav.</description>
      <author>example@mail.com (Yanbo Wang, Zipeng Fang, Lei Zhao, Weidong Chen)</author>
      <guid isPermaLink="false">2507.11001v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Physics-Informed Transfer Learning for Data-Driven Sound Source Reconstruction in Near-Field Acoustic Holography</title>
      <link>http://arxiv.org/abs/2507.11070v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to appear in IEEE WASPAA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于迁移学习的近场声全息（NAH）声音源重建框架，该框架通过物理信息方法将经过良好训练的数据驱动模型从一个声源类型迁移到另一个声源类型。&lt;h4&gt;背景&lt;/h4&gt;近场声全息（NAH）技术中声音源重建是关键问题。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够提高声音源重建精度的迁移学习框架。&lt;h4&gt;方法&lt;/h4&gt;该框架分为两个阶段：第一阶段在大型数据集上对复值卷积神经网络（CV-CNN）进行监督预训练；第二阶段基于Kirchhoff-Helmholtz积分对单个数据样本进行物理信息细调。&lt;h4&gt;主要发现&lt;/h4&gt;将预训练模型从矩形板数据集迁移到小提琴顶板数据集，提高了重建精度，并达到与压缩等效源方法（C-ESM）相当的性能。对于成功模式，细调模型在精度上优于预训练模型和C-ESM。&lt;h4&gt;结论&lt;/h4&gt;该方法通过物理信息方法实现了迁移学习，在不同数据集之间提高了泛化能力，并有效提升了声音源重建的精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a transfer learning framework for sound source reconstruction inNear-field Acoustic Holography (NAH), which adapts a well-trained data-drivenmodel from one type of sound source to another using a physics-informedprocedure. The framework comprises two stages: (1) supervised pre-training of acomplex-valued convolutional neural network (CV-CNN) on a large dataset, and(2) purely physics-informed fine-tuning on a single data sample based on theKirchhoff-Helmholtz integral. This method follows the principles of transferlearning by enabling generalization across different datasets throughphysics-informed adaptation. The effectiveness of the approach is validated bytransferring a pre-trained model from a rectangular plate dataset to a violintop plate dataset, where it shows improved reconstruction accuracy compared tothe pre-trained model and delivers performance comparable to that ofCompressive-Equivalent Source Method (C-ESM). Furthermore, for successfulmodes, the fine-tuned model outperforms both the pre-trained model and C-ESM inaccuracy.</description>
      <author>example@mail.com (Xinmeng Luan, Mirco Pezzoli, Fabio Antonacci, Augusto Sarti)</author>
      <guid isPermaLink="false">2507.11070v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>A Generalizable Physics-Enhanced State Space Model for Long-Term Dynamics Forecasting in Complex Environments</title>
      <link>http://arxiv.org/abs/2507.10792v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures, accepted in ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Phy-SSM的方法，用于解决复杂环境中长期动态预测问题，该方法通过将部分物理知识整合到状态空间模型中，以提高预测性能。&lt;h4&gt;背景&lt;/h4&gt;复杂环境中的长期动态预测问题，数据通常是噪声的且采样不规则，现有的方法在处理长期外推任务时仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;克服长期外推任务的挑战，提高复杂环境中的长期动态预测性能。&lt;h4&gt;方法&lt;/h4&gt;Phy-SSM方法将部分已知物理知识整合到状态空间模型中，将部分已知系统动力学分解为已知和未知状态矩阵，并引入物理状态正则化项来增强长期预测性能。&lt;h4&gt;主要发现&lt;/h4&gt;Phy-SSM在车辆运动预测、无人机状态预测和COVID-19流行病学预测等三个真实世界应用中，在长期插值和外推任务上都表现出比基线方法更优越的性能。&lt;h4&gt;结论&lt;/h4&gt;Phy-SSM是一种有效的长期动态预测方法，在复杂环境中具有较好的泛化能力和预测性能。&lt;h4&gt;翻译&lt;/h4&gt;本研究旨在解决复杂环境中数据噪声且采样不规则的长期动态预测问题。尽管最近的研究已经引入了一些提高预测性能的方法，但这些方法在处理此类复杂场景下的长期外推任务时仍然面临重大挑战。为了克服这一挑战，我们提出了Phy-SSM，一种将部分物理知识集成到状态空间模型（SSMs）中以进行复杂环境中长期动态预测的通用方法。我们的动机是，SSMs可以有效地捕捉序列数据中的长距离依赖关系并建模连续动力系统，而物理知识的融入提高了泛化能力。关键挑战在于如何无缝地将部分已知物理知识集成到SSMs中。为了实现这一点，我们将部分已知系统动力学分解为已知和未知状态矩阵，并将它们集成到Phy-SSM单元中。为了进一步增强长期预测性能，我们引入了一个物理状态正则化项，以使估计的潜在状态与系统动力学相一致。此外，我们对我们方法解的唯一性进行了理论分析。在包括车辆运动预测、无人机状态预测和COVID-19流行病学预测在内的三个真实世界应用上的大量实验表明，Phy-SSM在长期插值和外推任务上均优于基线方法。代码可在https://github.com/511205787/Phy_SSM-ICML2025上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work aims to address the problem of long-term dynamic forecasting incomplex environments where data are noisy and irregularly sampled. While recentstudies have introduced some methods to improve prediction performance, theseapproaches still face a significant challenge in handling long-termextrapolation tasks under such complex scenarios. To overcome this challenge,we propose Phy-SSM, a generalizable method that integrates partial physicsknowledge into state space models (SSMs) for long-term dynamics forecasting incomplex environments. Our motivation is that SSMs can effectively capturelong-range dependencies in sequential data and model continuous dynamicalsystems, while the incorporation of physics knowledge improves generalizationability. The key challenge lies in how to seamlessly incorporate partiallyknown physics into SSMs. To achieve this, we decompose partially known systemdynamics into known and unknown state matrices, which are integrated into aPhy-SSM unit. To further enhance long-term prediction performance, we introducea physics state regularization term to make the estimated latent states alignwith system dynamics. Besides, we theoretically analyze the uniqueness of thesolutions for our method. Extensive experiments on three real-worldapplications, including vehicle motion prediction, drone state prediction, andCOVID-19 epidemiology forecasting, demonstrate the superior performance ofPhy-SSM over the baselines in both long-term interpolation and extrapolationtasks. The code is available at https://github.com/511205787/Phy_SSM-ICML2025.</description>
      <author>example@mail.com (Yuchen Wang, Hongjue Zhao, Haohong Lin, Enze Xu, Lifang He, Huajie Shao)</author>
      <guid isPermaLink="false">2507.10792v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>UGC-VideoCaptioner: An Omni UGC Video Detail Caption Model and New Benchmarks</title>
      <link>http://arxiv.org/abs/2507.11336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基准和模型框架UGC-VideoCap，用于对短形式用户生成视频进行详细的全方位字幕标注，以解决现有视频字幕基准和模型主要关注视觉内容而忽视音频内容的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的视频字幕基准和模型主要关注视觉内容，忽视了音频在传达场景动态、说话人意图和叙事背景中的关键作用。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出UGC-VideoCap，一个专门设计用于对短形式用户生成视频进行详细全方位字幕标注的基准和模型框架。&lt;h4&gt;方法&lt;/h4&gt;UGC-VideoCap包括1000个TikTok视频，通过一个结构化的三阶段人工标注流程进行标注，涵盖音频、视觉和联合音频视觉语义。同时，还包括4000个精心制作的QA对，用于探测单模态和跨模态理解。此外，提出了UGC-VideoCaptioner(3B)模型，该模型从Gemini 2.5 Flash中提取，并采用了一种新颖的两阶段训练策略，包括监督微调和组相对策略优化（GRPO）。&lt;h4&gt;主要发现&lt;/h4&gt;UGC-VideoCap强调音频和视觉模态的平衡集成，并通过QA对测试了单模态和跨模态理解。&lt;h4&gt;结论&lt;/h4&gt;UGC-VideoCap和UGC-VideoCaptioner(3B)为在不受约束的真实世界用户生成内容（UGC）环境中推进全方位视频字幕标注提供了一个高质量的基础和数据高效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现实世界中的用户生成视频，尤其是在TikTok等平台上，通常包含丰富且交织的视听内容。然而，现有的视频字幕基准和模型主要关注视觉内容，忽视了音频在传达场景动态、说话人意图和叙事背景中的关键作用。这种缺乏全方位数据集和轻量级、功能强大的模型阻碍了细粒度、多模态视频理解的发展。为了解决这些挑战，我们引入了UGC-VideoCap，这是一个专门为短形式用户生成视频的详细全方位字幕标注而设计的基准和模型框架。与先前的数据集不同，UGC-VideoCap强调音频和视觉模态的平衡集成，包含通过结构化的三阶段人工标注流程（涵盖音频、视觉和联合音频视觉语义）标注的1000个TikTok视频。基准还包括4000个精心制作的QA对，用于探测单模态和跨模态理解。与数据集一起，我们提出了UGC-VideoCaptioner(3B)模型，该模型从Gemini 2.5 Flash中提取，并采用了一种新颖的两阶段训练策略，包括监督微调和组相对策略优化（GRPO）。我们的方法使从有限数据中高效适应成为可能，同时保持了有竞争力的性能。共同，我们的基准和模型为在不受约束的真实世界用户生成内容（UGC）环境中推进全方位视频字幕标注提供了一个高质量的基础和数据高效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world user-generated videos, especially on platforms like TikTok, oftenfeature rich and intertwined audio visual content. However, existing videocaptioning benchmarks and models remain predominantly visual centric,overlooking the crucial role of audio in conveying scene dynamics, speakerintent, and narrative context. This lack of omni datasets and lightweight,capable models hampers progress in fine grained, multimodal videounderstanding. To address these challenges, we introduce UGC-VideoCap, a newbenchmark and model framework specifically designed for detailed omnimodalcaptioning of short form user-generated videos. Unlike prior datasets,UGC-VideoCap emphasizes balanced integration of audio and visual modalities,featuring 1000 TikTok videos annotated through a structured three stagehuman-in-the-loop pipeline covering audio only, visual only, and joint audiovisual semantics. The benchmark also includes 4000 carefully crafted QA pairsprobing both unimodal and cross modal understanding. Alongside the dataset, wepropose UGC-VideoCaptioner(3B), a 3B parameter captioning model distilled fromGemini 2.5 Flash. Using a novel two-stage training strategy supervised finetuning followed by Group Relative Policy Optimization (GRPO), our approachenables efficient adaptation from limited data while maintaining competitiveperformance. Together, our benchmark and model offer a high-quality foundationand a data-efficient solution for advancing omnimodal video captioning inunconstrained real-world UGC settings.</description>
      <author>example@mail.com (Peiran Wu, Yunze Liu, Zhengdong Zhu, Enmin Zhou, Shawn Shen)</author>
      <guid isPermaLink="false">2507.11336v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>A Mixed-Primitive-based Gaussian Splatting Method for Surface Reconstruction</title>
      <link>http://arxiv.org/abs/2507.11321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的Gaussian Splatting（GS）框架，用于提高三维物体表面重建的质量。&lt;h4&gt;背景&lt;/h4&gt;现有的GS方法仅限于使用单一类型的Gaussian椭圆或Gaussian椭球来表示物体表面，这对于复杂的真实世界三维物体来说是不够的。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，能够将多种类型的（几何）原语纳入GS的表面重建过程中，以获得高质量的表面表示。&lt;h4&gt;方法&lt;/h4&gt;提出了一种组合式Splatting策略，允许在GS流程中渲染不同类型的原语。此外，还设计了基于混合原语的初始化策略和顶点修剪机制，以促进不同类型原语的应用。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的框架有效，并且能够实现准确的表面重建。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够显著提高GS在表面重建方面的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Gaussian Splatting (GS) has received a lot of attention in surfacereconstruction. However, while 3D objects can be of complex and diverse shapesin the real world, existing GS-based methods only limitedly use a single typeof splatting primitive (Gaussian ellipse or Gaussian ellipsoid) to representobject surfaces during their reconstruction. In this paper, we highlight thatthis can be insufficient for object surfaces to be represented in high quality.Thus, we propose a novel framework that, for the first time, enables GaussianSplatting to incorporate multiple types of (geometrical) primitives during itssurface reconstruction process. Specifically, in our framework, we firstpropose a compositional splatting strategy, enabling the splatting andrendering of different types of primitives in the Gaussian Splatting pipeline.In addition, we also design our framework with a mixed-primitive-basedinitialization strategy and a vertex pruning mechanism to further promote itssurface representation learning process to be well executed leveragingdifferent types of primitives. Extensive experiments show the efficacy of ourframework and its accurate surface reconstruction performance.</description>
      <author>example@mail.com (Haoxuan Qu, Yujun Cai, Hossein Rahmani, Ajay Kumar, Junsong Yuan, Jun Liu)</author>
      <guid isPermaLink="false">2507.11321v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation</title>
      <link>http://arxiv.org/abs/2507.11540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了深度学习在深度估计领域的应用，分析了深度学习架构和范式在单目、立体、多视图和单目视频设置下的演变，探讨了这些模型解决现有挑战的潜力，并概述了可以促进其发展的大规模数据集。&lt;h4&gt;背景&lt;/h4&gt;深度估计是3D计算机视觉的基础任务，对于3D重建、自由视点渲染、机器人、自动驾驶和AR/VR技术等应用至关重要。传统的基于硬件传感器的方法（如LiDAR）成本高、分辨率低、对环境敏感，限制了其在现实世界中的应用。&lt;h4&gt;目的&lt;/h4&gt;通过识别关键架构和训练策略，旨在突出稳健的深度基础模型的发展路径，为未来的研究和应用提供见解。&lt;h4&gt;方法&lt;/h4&gt;本文调查了深度学习架构和范式在深度估计领域的演变，并探索了这些模型解决现有挑战的潜力。&lt;h4&gt;主要发现&lt;/h4&gt;近年来，基于视觉的方法提供了有希望的替代方案，但它们面临着泛化性和稳定性的挑战，这要么是由于模型架构的低容量，要么是由于依赖于特定领域和小规模数据集。&lt;h4&gt;结论&lt;/h4&gt;深度学习在深度估计领域的应用具有巨大潜力，通过开发深度基础模型，可以解决现有挑战并促进该领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：深度估计是3D计算机视觉的基本任务，对于3D重建、自由视点渲染、机器人、自动驾驶和AR/VR技术等应用至关重要。传统的基于硬件传感器的方法（如LiDAR）往往受限于高昂的成本、低分辨率和对环境的敏感性，限制了它们在实际场景中的应用。近年来，基于视觉的方法提供了有希望的替代方案，但它们面临着泛化性和稳定性的挑战，这要么是由于模型架构的低容量，要么是由于依赖于特定领域和小规模数据集。其他领域出现的大规模数据集和基础模型启发了一种新的深度模型——深度基础模型。本文调查了深度学习架构和范式在深度估计领域的演变，并探讨了这些模型解决现有挑战的潜力，提供了可以促进其发展的大规模数据集的概述。通过识别关键架构和训练策略，我们旨在突出稳健的深度基础模型的发展路径，为未来的研究和应用提供见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth estimation is a fundamental task in 3D computer vision, crucial forapplications such as 3D reconstruction, free-viewpoint rendering, robotics,autonomous driving, and AR/VR technologies. Traditional methods relying onhardware sensors like LiDAR are often limited by high costs, low resolution,and environmental sensitivity, limiting their applicability in real-worldscenarios. Recent advances in vision-based methods offer a promisingalternative, yet they face challenges in generalization and stability due toeither the low-capacity model architectures or the reliance on domain-specificand small-scale datasets. The emergence of scaling laws and foundation modelsin other domains has inspired the development of "depth foundation models":deep neural networks trained on large datasets with strong zero-shotgeneralization capabilities. This paper surveys the evolution of deep learningarchitectures and paradigms for depth estimation across the monocular, stereo,multi-view, and monocular video settings. We explore the potential of thesemodels to address existing challenges and provide a comprehensive overview oflarge-scale datasets that can facilitate their development. By identifying keyarchitectures and training strategies, we aim to highlight the path towardsrobust depth foundation models, offering insights into their future researchand applications.</description>
      <author>example@mail.com (Zhen Xu, Hongyu Zhou, Sida Peng, Haotong Lin, Haoyu Guo, Jiahao Shao, Peishan Yang, Qinglin Yang, Sheng Miao, Xingyi He, Yifan Wang, Yue Wang, Ruizhen Hu, Yiyi Liao, Xiaowei Zhou, Hujun Bao)</author>
      <guid isPermaLink="false">2507.11540v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation</title>
      <link>http://arxiv.org/abs/2507.10917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于大型语言模型（LLM）的双层多兴趣建模框架，用于更有效的推荐。&lt;h4&gt;背景&lt;/h4&gt;现有的多兴趣建模方法通常依赖于启发式假设，如共同出现的项目表示用户有相同兴趣，这无法捕捉到与真实世界场景相符合的用户多兴趣。&lt;h4&gt;目的&lt;/h4&gt;解决LLM在多兴趣分析中的两个关键挑战：兴趣组分的粒度不可知，以及由于数据稀疏性导致的对个体用户分析有限。&lt;h4&gt;方法&lt;/h4&gt;在用户个体层面，利用LLM将用户参与的项目灵活地分配到不同的语义集群中，以表明他们的多样化和独特兴趣。通过一个对齐模块自适应地将这些语义集群分配给用户从全局用户-物品交互中学习的协作多兴趣，从而根据用户的行为自动调整粒度。在用户群体层面，将用户的小团体聚合为具有丰富行为的合成用户，以进行更全面的LLM驱动多兴趣分析。通过最大覆盖问题确保合成用户行为的紧凑性和代表性，然后基于LLM驱动的多兴趣进行对比学习，以解开不同兴趣之间的物品表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与最先进的方法相比，该方法在真实世界数据集上具有优越性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够更有效地建模用户的多兴趣，并提高推荐的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, much effort has been devoted to modeling users' multi-interestsbased on their behaviors or auxiliary signals. However, existing methods oftenrely on heuristic assumptions, e.g., co-occurring items indicate the sameinterest of users, failing to capture user multi-interests aligning withreal-world scenarios. While large language models (LLMs) show significantpotential for multi-interest analysis due to their extensive knowledge andpowerful reasoning capabilities, two key challenges remain. First, thegranularity of LLM-driven multi-interests is agnostic, possibly leading tooverly fine or coarse interest grouping. Second, individual user analysisprovides limited insights due to the data sparsity issue. In this paper, wepropose an LLM-driven dual-level multi-interest modeling framework for moreeffective recommendation. At the user-individual level, we exploit LLMs toflexibly allocate items engaged by users into different semantic clusters,indicating their diverse and distinct interests. To alleviate the agnosticgeneration of LLMs, we adaptively assign these semantic clusters to users'collaborative multi-interests learned from global user-item interactions,allowing the granularity to be automatically adjusted according to the user'sbehaviors using an alignment module. To alleviate the limited insights derivedfrom individual users' behaviors, at the user-crowd level, we proposeaggregating user cliques into synthesized users with rich behaviors for morecomprehensive LLM-driven multi-interest analysis. We formulate a max coveringproblem to ensure the compactness and representativeness of synthesized users'behaviors, and then conduct contrastive learning based on their LLM-drivenmulti-interests to disentangle item representations among different interests.Experiments on real-world datasets show the superiority of our approach againststate-of-the-art methods.</description>
      <author>example@mail.com (Ziyan Wang, Yingpeng Du, Zhu Sun, Jieyi Bi, Haoyan Chua, Tianjun Wei, Jie Zhang)</author>
      <guid isPermaLink="false">2507.10917v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces</title>
      <link>http://arxiv.org/abs/2507.11352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种神经符号框架，结合自然语言对话的易用性和对目标解释的可验证保证，以提高复杂物流决策的可靠性。&lt;h4&gt;背景&lt;/h4&gt;物流操作员在面临紧急情况时需要快速且连续的重新规划，传统方法如整数规划速度慢且不适用于不确定环境，而大型语言模型虽然能处理不确定性，但存在误解释和幻觉风险。&lt;h4&gt;目的&lt;/h4&gt;开发一种神经符号框架，以提高物流决策的实时性、可靠性和用户适应性。&lt;h4&gt;方法&lt;/h4&gt;该框架将用户请求转化为结构化规划规范，量化自身的不确定性，并在信心低于自适应阈值时进行交互式澄清。&lt;h4&gt;主要发现&lt;/h4&gt;在仅用100个不确定性过滤示例进行微调后，该轻量级模型在零样本性能上超过了GPT-4.1，同时将推理延迟减少了近50%。&lt;h4&gt;结论&lt;/h4&gt;该研究为构建可验证、实时和用户对齐的复杂物流决策提供了一个实用路径。&lt;h4&gt;翻译&lt;/h4&gt;Logistics operators, from battlefield coordinators rerouting airlifts ahead of a storm to warehouse managers juggling late trucks, often face life-critical decisions that demand both domain expertise and rapid and continuous replanning. While popular methods like integer programming yield logistics plans that satisfy user-defined logical constraints, they are slow and assume an idealized mathematical model of the environment that does not account for uncertainty. On the other hand, large language models (LLMs) can handle uncertainty and promise to accelerate replanning while lowering the barrier to entry by translating free-form utterances into executable plans, yet they remain prone to misinterpretations and hallucinations that jeopardize safety and cost. We introduce a neurosymbolic framework that pairs the accessibility of natural-language dialogue with verifiable guarantees on goal interpretation. It converts user requests into structured planning specifications, quantifies its own uncertainty at the field and token level, and invokes an interactive clarification loop whenever confidence falls below an adaptive threshold. A lightweight model, fine-tuned on just 100 uncertainty-filtered examples, surpasses the zero-shot performance of GPT-4.1 while cutting inference latency by nearly 50%. These preliminary results highlight a practical path toward certifiable, real-time, and user-aligned decision-making for complex logistics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Logistics operators, from battlefield coordinators rerouting airlifts aheadof a storm to warehouse managers juggling late trucks, often face life-criticaldecisions that demand both domain expertise and rapid and continuousreplanning. While popular methods like integer programming yield logisticsplans that satisfy user-defined logical constraints, they are slow and assumean idealized mathematical model of the environment that does not account foruncertainty. On the other hand, large language models (LLMs) can handleuncertainty and promise to accelerate replanning while lowering the barrier toentry by translating free-form utterances into executable plans, yet theyremain prone to misinterpretations and hallucinations that jeopardize safetyand cost. We introduce a neurosymbolic framework that pairs the accessibilityof natural-language dialogue with verifiable guarantees on goal interpretation.It converts user requests into structured planning specifications, quantifiesits own uncertainty at the field and token level, and invokes an interactiveclarification loop whenever confidence falls below an adaptive threshold. Alightweight model, fine-tuned on just 100 uncertainty-filtered examples,surpasses the zero-shot performance of GPT-4.1 while cutting inference latencyby nearly 50%. These preliminary results highlight a practical path towardcertifiable, real-time, and user-aligned decision-making for complex logistics.</description>
      <author>example@mail.com (Yunhao Yang, Neel P. Bhatt, Christian Ellis, Alvaro Velasquez, Zhangyang Wang, Ufuk Topcu)</author>
      <guid isPermaLink="false">2507.11352v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices</title>
      <link>http://arxiv.org/abs/2507.11053v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GATE的新型室内定位框架，通过构建自适应图表示指纹向量，并保留室内状态空间拓扑，以缓解环境噪声和设备异质性问题。&lt;h4&gt;背景&lt;/h4&gt;精确的室内定位对于实现智能环境中的空间上下文和导航系统至关重要。Wi-Fi RSS指纹识别技术因其与移动嵌入式设备的兼容性而广泛应用，但深度学习模型在定位任务中的准确性受限于假设指纹向量存在于欧几里得空间，未能考虑空间关系和现实世界中RSS噪声的非均匀分布。&lt;h4&gt;目的&lt;/h4&gt;提出GATE框架，以解决传统深度学习模型在异构移动设备上的泛化能力差，以及GNN在密集接入点环境中精度下降的问题。&lt;h4&gt;方法&lt;/h4&gt;GATE通过以下方法改进定位精度：1）引入了注意力超空间向量（AHV）以增强消息传递；2）提出了多维超空间向量（MDHV）以减轻GNN盲点问题；3）引入了实时边构造（RTEC）方法以适应动态图。&lt;h4&gt;主要发现&lt;/h4&gt;GATE在多个具有不同路径长度、接入点密度和异构设备的室内空间中进行的大量真实世界评估表明，其平均定位误差比最先进的室内定位框架降低了1.6倍至4.72倍，最坏情况下的误差降低了1.85倍至4.57倍。&lt;h4&gt;结论&lt;/h4&gt;GATE框架在室内定位方面取得了显著的性能提升，为解决传统方法的局限性提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate indoor localization is crucial for enabling spatial context in smartenvironments and navigation systems. Wi-Fi Received Signal Strength (RSS)fingerprinting is a widely used indoor localization approach due to itscompatibility with mobile embedded devices. Deep Learning (DL) models improveaccuracy in localization tasks by learning RSS variations across locations, butthey assume fingerprint vectors exist in a Euclidean space, failing toincorporate spatial relationships and the non-uniform distribution ofreal-world RSS noise. This results in poor generalization across heterogeneousmobile devices, where variations in hardware and signal processing distort RSSreadings. Graph Neural Networks (GNNs) can improve upon conventional DL modelsby encoding indoor locations as nodes and modeling their spatial and signalrelationships as edges. However, GNNs struggle with non-Euclidean noisedistributions and suffer from the GNN blind spot problem, leading to degradedaccuracy in environments with dense access points (APs). To address thesechallenges, we propose GATE, a novel framework that constructs an adaptivegraph representation of fingerprint vectors while preserving an indoorstate-space topology, modeling the non-Euclidean structure of RSS noise tomitigate environmental noise and address device heterogeneity. GATE introduces1) a novel Attention Hyperspace Vector (AHV) for enhanced message passing, 2) anovel Multi-Dimensional Hyperspace Vector (MDHV) to mitigate the GNN blindspot, and 3) an new Real-Time Edge Construction (RTEC) approach for dynamicgraph adaptation. Extensive real-world evaluations across multiple indoorspaces with varying path lengths, AP densities, and heterogeneous devicesdemonstrate that GATE achieves 1.6x to 4.72x lower mean localization errors and1.85x to 4.57x lower worst-case errors compared to state-of-the-art indoorlocalization frameworks.</description>
      <author>example@mail.com (Danish Gufran, Sudeep Pasricha)</author>
      <guid isPermaLink="false">2507.11053v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Static or Temporal? Semantic Scene Simplification to Aid Wayfinding in Immersive Simulations of Bionic Vision</title>
      <link>http://arxiv.org/abs/2507.10813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉神经假体（仿生眼）在极端分辨率和带宽限制下通过预处理技术改善场景理解的方法。&lt;h4&gt;背景&lt;/h4&gt;视觉神经假体旨在通过将相机输入转换为电刺激模式来恢复基本的视觉能力。&lt;h4&gt;目的&lt;/h4&gt;为了在复杂环境中提高场景理解，研究比较了两种语义预处理方法：SemanticEdges和SemanticRaster。&lt;h4&gt;方法&lt;/h4&gt;使用基于生物视觉的模拟，18名视力正常的参与者在不同条件下进行动态城市环境中的寻路任务。&lt;h4&gt;主要发现&lt;/h4&gt;两种语义策略均优于基线条件，SemanticEdges提高了成功的可能性，而SemanticRaster提高了无碰撞完成任务的几率。&lt;h4&gt;结论&lt;/h4&gt;自适应语义预处理对假体视觉有价值，并且可能为低带宽视觉界面设计提供参考。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉神经假体（仿生眼）旨在通过将相机输入转换为电刺激模式来恢复基本的视觉形式。为了在极端分辨率和带宽限制下改善场景理解，先前的工作已经探索了计算机视觉技术，如语义分割和深度估计。然而，在杂乱的环境中同时呈现所有与任务相关的信息可能会使用户感到不知所措。我们比较了两种沉浸式虚拟现实中的互补语义预处理方法：SemanticEdges，它同时突出显示所有相关对象，以及SemanticRaster，它通过时间错开来减少视觉杂乱。使用基于假体视觉的生物基础模拟，18名视力正常的参与者在三种条件下在动态城市环境中执行寻路任务：基于边缘的基线（控制）、SemanticEdges和SemanticRaster。两种语义策略相对于基线提高了性能和用户体验，每种策略都提供了不同的权衡：SemanticEdges增加了成功的几率，而SemanticRaster提高了无碰撞完成任务的几率。这些发现强调了自适应语义预处理对假体视觉的价值，并且更广泛地，可能为必须平衡信息密度、任务相关性和感知清晰度的XR中的低带宽视觉界面设计提供信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual neuroprostheses (bionic eye) aim to restore a rudimentary form ofvision by translating camera input into patterns of electrical stimulation. Toimprove scene understanding under extreme resolution and bandwidth constraints,prior work has explored computer vision techniques such as semanticsegmentation and depth estimation. However, presenting all task-relevantinformation simultaneously can overwhelm users in cluttered environments. Wecompare two complementary approaches to semantic preprocessing in immersivevirtual reality: SemanticEdges, which highlights all relevant objects at once,and SemanticRaster, which staggers object categories over time to reduce visualclutter. Using a biologically grounded simulation of prosthetic vision, 18sighted participants performed a wayfinding task in a dynamic urban environmentacross three conditions: edge-based baseline (Control), SemanticEdges, andSemanticRaster. Both semantic strategies improved performance and userexperience relative to the baseline, with each offering distinct trade-offs:SemanticEdges increased the odds of success, while SemanticRaster boosted thelikelihood of collision-free completions. These findings underscore the valueof adaptive semantic preprocessing for prosthetic vision and, more broadly, mayinform the design of low-bandwidth visual interfaces in XR that must balanceinformation density, task relevance, and perceptual clarity.</description>
      <author>example@mail.com (Justin M. Kasowski, Apurv Varshney, Michael Beyeler)</author>
      <guid isPermaLink="false">2507.10813v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>HEIMDALL: a grapH-based sEIsMic Detector And Locator for microseismicity</title>
      <link>http://arxiv.org/abs/2507.10850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的深度学习模型，用于微地震监测，该模型利用地震站记录之间的连续时空关系，形成一个端到端的地震目录创建流程。&lt;h4&gt;背景&lt;/h4&gt;全球范围内，为了减少碳排放，绿色能源转型背景下，对增强型地热系统的利用越来越受到关注。&lt;h4&gt;目的&lt;/h4&gt;提高微地震事件的检测能力，减少人工干预，降低对模型调优的需求。&lt;h4&gt;方法&lt;/h4&gt;使用图理论和最先进的图神经网络架构，在滚动窗口中对相位拾取、关联和事件定位进行同时处理。&lt;h4&gt;主要发现&lt;/h4&gt;在冰岛Hengill地区的复杂地热区域使用公开数据测试，模型在事件检测方面表现出显著提高，包括2018年12月的一个4.0级地震序列和2019年2月的一天内地震序列。&lt;h4&gt;结论&lt;/h4&gt;该方法验证了一个鲁棒的监测工具，可以补充现有系统，并在地热能源开发过程中降低运营风险。&lt;h4&gt;翻译&lt;/h4&gt;在此工作中，我们提出了一种新的深度学习模型，用于微地震监测，该模型利用地震站记录之间的连续时空关系，形成一个端到端的地震目录创建流程。在冰岛Hengill地区的复杂地热区域使用公开数据测试，模型在事件检测方面表现出显著提高，包括2018年12月的一个4.0级地震序列和2019年2月的一天内地震序列。我们的方法减少了虚假事件，最小化了人工审查，并减少了管道或深度学习模型迁移学习的大量调整。总的来说，它验证了一个用于地热地震区域的鲁棒监测工具，补充了现有系统，并在地热能源开发过程中增强了运营风险缓解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we present a new deep-learning model for microseismicitymonitoring that utilizes continuous spatiotemporal relationships betweenseismic station recordings, forming an end-to-end pipeline for seismic catalogcreation. It employs graph theory and state-of-the-art graph neural networkarchitectures to perform phase picking, association, and event locationsimultaneously over rolling windows, making it suitable for both playback andnear-real-time monitoring. As part of the global strategy to reduce carbonemissions within the broader context of a green-energy transition, there hasbeen growing interest in exploiting enhanced geothermal systems. Tested in thecomplex geothermal area of Iceland's Hengill region using open-access data froma temporary experiment, our model was trained and validated using both manuallyrevised and automatic seismic catalogs. Results showed a significant increasein event detection compared to previously published automatic systems andreference catalogs, including a $4 M_w$ seismic sequence in December 2018 and asingle-day sequence in February 2019. Our method reduces false events,minimizes manual oversight, and decreases the need for extensive tuning ofpipelines or transfer learning of deep-learning models. Overall, it validates arobust monitoring tool for geothermal seismic regions, complementing existingsystems and enhancing operational risk mitigation during geothermal energyexploitation.</description>
      <author>example@mail.com (Matteo Bagagli, Francesco Grigoli, Davide Bacciu)</author>
      <guid isPermaLink="false">2507.10850v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion-Based Imaginative Coordination for Bimanual Manipulation</title>
      <link>http://arxiv.org/abs/2507.11296v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, including 10 figures and 16 tables. Accepted at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散的视频和动作预测的统一框架，用于优化双臂操作中的视频和动作预测。&lt;h4&gt;背景&lt;/h4&gt;双臂操作在机器人领域至关重要，但高维动作空间和复杂的协调要求带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;探索视频预测在增强双臂协调方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种多帧潜在预测策略，用于压缩潜在空间中未来状态的编码，并引入了单向注意力机制，其中视频预测基于动作，而动作预测独立于视频预测。&lt;h4&gt;主要发现&lt;/h4&gt;在两个模拟基准和一个现实世界设置中的实验表明，与强大的基线ACT相比，该方法在成功率上有了显著提高，在ALOHA上提高了24.9%，在RoboTwin上提高了11.1%，在现实世界实验中提高了32.5%。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提高双臂操作的成功率。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于扩散的视频和动作预测的统一框架，用于优化双臂操作中的视频和动作预测。双臂操作在机器人领域至关重要，但高维动作空间和复杂的协调要求带来了挑战。为了探索视频预测在增强双臂协调方面的潜力，本文提出了一种多帧潜在预测策略，用于压缩潜在空间中未来状态的编码，并引入了单向注意力机制，其中视频预测基于动作，而动作预测独立于视频预测。在两个模拟基准和一个现实世界设置中的实验表明，与强大的基线ACT相比，该方法在成功率上有了显著提高，在ALOHA上提高了24.9%，在RoboTwin上提高了11.1%，在现实世界实验中提高了32.5%。该方法能够有效提高双臂操作的成功率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bimanual manipulation is crucial in robotics, enabling complex tasks inindustrial automation and household services. However, it poses significantchallenges due to the high-dimensional action space and intricate coordinationrequirements. While video prediction has been recently studied forrepresentation learning and control, leveraging its ability to capture richdynamic and behavioral information, its potential for enhancing bimanualcoordination remains underexplored. To bridge this gap, we propose a unifieddiffusion-based framework for the joint optimization of video and actionprediction. Specifically, we propose a multi-frame latent prediction strategythat encodes future states in a compressed latent space, preservingtask-relevant features. Furthermore, we introduce a unidirectional attentionmechanism where video prediction is conditioned on the action, while actionprediction remains independent of video prediction. This design allows us toomit video prediction during inference, significantly enhancing efficiency.Experiments on two simulated benchmarks and a real-world setting demonstrate asignificant improvement in the success rate over the strong baseline ACT usingour method, achieving a \textbf{24.9\%} increase on ALOHA, an \textbf{11.1\%}increase on RoboTwin, and a \textbf{32.5\%} increase in real-world experiments.Our models and code are publicly available athttps://github.com/return-sleep/Diffusion_based_imaginative_Coordination.</description>
      <author>example@mail.com (Huilin Xu, Jian Ding, Jiakun Xu, Ruixiang Wang, Jun Chen, Jinjie Mai, Yanwei Fu, Bernard Ghanem, Feng Xu, Mohamed Elhoseiny)</author>
      <guid isPermaLink="false">2507.11296v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>RefModel: Detecting Refactorings using Foundation Models</title>
      <link>http://arxiv.org/abs/2507.11346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Brazilian Symposium on Software Engineering (SBES 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用基础模型进行重构检测的可行性，并介绍了一种名为RefModel的工具。&lt;h4&gt;背景&lt;/h4&gt;重构是提高代码质量的一种常见软件工程实践，但现有的自动检测工具依赖于复杂的规则定义和静态分析，难以扩展到其他编程语言。&lt;h4&gt;目的&lt;/h4&gt;评估使用基础模型进行重构检测的可行性，并比较其与传统工具的性能。&lt;h4&gt;方法&lt;/h4&gt;在包含858个单操作变换的Java程序数据集上评估Phi4-14B和Claude 3.5 Sonnet，并扩展评估到44个来自开源项目的真实重构案例，使用Gemini 2.5 Pro和o4-mini-high进行性能评估。&lt;h4&gt;主要发现&lt;/h4&gt;RefModel在性能上与传统的工具相当，甚至在某些情况下优于它们。在现实世界中，Claude 3.5 Sonnet和Gemini 2.5 Pro联合识别了97%的所有重构，超过了基于静态分析的最好工具。模型在Python和Golang上表现出令人鼓舞的泛化能力，并提供自然语言解释，定义每个重构类型只需一句话。&lt;h4&gt;结论&lt;/h4&gt;基础模型在重构检测方面具有可行性，并且在某些情况下优于传统工具，具有良好的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Refactoring is a common software engineering practice that improves codequality without altering program behavior. Although tools like ReExtractor+,RefactoringMiner, and RefDiff have been developed to detect refactoringsautomatically, they rely on complex rule definitions and static analysis,making them difficult to extend and generalize to other programming languages.In this paper, we investigate the viability of using foundation models forrefactoring detection, implemented in a tool named RefModel. We evaluatePhi4-14B, and Claude 3.5 Sonnet on a dataset of 858 single-operationtransformations applied to artificially generated Java programs, coveringwidely-used refactoring types. We also extend our evaluation by includingGemini 2.5 Pro and o4-mini-high, assessing their performance on 44 real-worldrefactorings extracted from four open-source projects. These models arecompared against RefactoringMiner, RefDiff, and ReExtractor+. RefModel iscompetitive with, and in some cases outperform, traditional tools. Inreal-world settings, Claude 3.5 Sonnet and Gemini 2.5 Pro jointly identified97% of all refactorings, surpassing the best-performing static-analysis-basedtools. The models showed encouraging generalization to Python and Golang. Theyprovide natural language explanations and require only a single sentence todefine each refactoring type.</description>
      <author>example@mail.com (Pedro Simões, Rohit Gheyi, Rian Melo, Jonhnanthan Oliveira, Márcio Ribeiro, Wesley K. G. Assunção)</author>
      <guid isPermaLink="false">2507.11346v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive-KAN: A Semi-Supervised Intrusion Detection Framework for Cybersecurity with scarce Labeled Data</title>
      <link>http://arxiv.org/abs/2507.10808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于半监督对比学习框架的实时入侵检测系统，旨在解决工业物联网和工业物联网环境中网络安全和入侵检测的挑战。&lt;h4&gt;背景&lt;/h4&gt;在第四次工业革命时代，网络安全和入侵检测系统对于物联网和工业物联网环境的可靠运行至关重要。数据不平衡和高标注成本是机器学习模型有效训练的关键挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种基于Kolmogorov-Arnold网络（KAN）的半监督对比学习框架，以有效区分正常和攻击行为。&lt;h4&gt;方法&lt;/h4&gt;该方法利用大量未标记数据，在三个基准数据集（UNSW-NB15、BoT-IoT和Gas Pipeline）上进行了验证，分别使用了2.20%、1.28%和8%的标记样本来模拟真实世界条件。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法优于现有的基于对比学习的方法，KAN在检测准确性和鲁棒性方面均优于传统的多层感知器（MLP）。KAN能够建模复杂关系，其可学习的激活函数也提供了可解释性和潜在的规则提取能力。&lt;h4&gt;结论&lt;/h4&gt;该方法支持多类分类，并在可靠性至关重要的安全关键环境中证明有效。&lt;h4&gt;翻译&lt;/h4&gt;在第四次工业革命时代，网络安全和入侵检测系统对于物联网和工业物联网环境的可靠运行至关重要。在此领域，一个关键挑战是标记的网络安全攻击数据的稀缺，因为大多数工业系统在正常条件下运行。这种数据不平衡，加上标注的高成本，阻碍了机器学习模型的有效训练。此外，快速检测攻击对于防止大规模中断至关重要。为了解决这些挑战，我们提出了一种基于Kolmogorov-Arnold网络（KAN）的半监督对比学习框架的实时入侵检测系统。我们的方法利用大量未标记数据来有效区分正常和攻击行为。我们在三个基准数据集（UNSW-NB15、BoT-IoT和Gas Pipeline）上验证了我们的方法，分别使用了2.20%、1.28%和8%的标记样本来模拟真实世界条件。实验结果表明，我们的方法优于现有的基于对比学习的方法。我们进一步比较了KAN与传统多层感知器（MLP），表明KAN在有限的监督下在检测准确性和鲁棒性方面均表现出优越性能。KAN建模复杂关系的能力及其可学习的激活函数也得到了探索和可视化，提供了可解释性和潜在的规则提取能力。该方法支持多类分类，并在可靠性至关重要的安全关键环境中证明有效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of the Fourth Industrial Revolution, cybersecurity and intrusiondetection systems are vital for the secure and reliable operation of IoT andIIoT environments. A key challenge in this domain is the scarcity of labeledcyber-attack data, as most industrial systems operate under normal conditions.This data imbalance, combined with the high cost of annotation, hinders theeffective training of machine learning models. Moreover, rapid detection ofattacks is essential, especially in critical infrastructure, to preventlarge-scale disruptions. To address these challenges, we propose a real-timeintrusion detection system based on a semi-supervised contrastive learningframework using the Kolmogorov-Arnold Network (KAN). Our method leveragesabundant unlabeled data to distinguish between normal and attack behaviorseffectively. We validate our approach on three benchmark datasets: UNSW-NB15,BoT-IoT, and Gas Pipeline, using only 2.20 percent, 1.28 percent, and 8 percentof labeled samples, respectively, to simulate real-world conditions.Experimental results show that our method outperforms existing contrastivelearning-based approaches. We further compare KAN with a traditional multilayerperceptron (MLP), demonstrating KAN's superior performance in both detectionaccuracy and robustness under limited supervision. KAN's ability to modelcomplex relationships and its learnable activation functions are also exploredand visualized, offering interpretability and potential for rule extraction.The method supports multi-class classification and proves effective insafety-critical environments where reliability is paramount.</description>
      <author>example@mail.com (Mohammad Alikhani, Reza Kazemi)</author>
      <guid isPermaLink="false">2507.10808v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Graph-based Fingerprint Update Using Unlabelled WiFi Signals</title>
      <link>http://arxiv.org/abs/2507.11038v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Proceedings of the ACM on Interactive, Mobile, Wearable  and Ubiquitous Technologies, Volume 9, Issue 1, Article No. 3, Pages 1 - 26&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何利用新收集的未标记WiFi信号有效地更新现有的WiFi指纹数据库，以提高指纹的适应性。&lt;h4&gt;背景&lt;/h4&gt;WiFi接收信号强度（RSS）环境因接入点（APs）的移动、功率调整、AP的安装和移除等因素而随时间变化。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法，使用可能包含新AP的未标记信号更新现有的WiFi指纹数据库。&lt;h4&gt;方法&lt;/h4&gt;提出了GUFU，一种基于图的新型有效方法，使用未标记信号和可能的新的AP更新WiFi指纹。GUFU利用图神经网络（GNN）和链接预测算法，基于相似信号向量暗示物理邻近性的观察，对增量网络进行重新训练，并在重新训练后更新指定位置的信号向量。&lt;h4&gt;主要发现&lt;/h4&gt;通过在四个大型代表性场所的大量实验，GUFU与现有的最先进方法相比，在指纹适应性方面表现出显著提高，RSS值和位置预测的错误分别减少了21.4%和29.8%。&lt;h4&gt;结论&lt;/h4&gt;GUFU方法在更新WiFi指纹数据库方面是有效的，可以显著提高指纹的适应性。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies how to effectively update an existing database of fingerprints, defined as the RSS values of APs at designated locations, using a batch of newly collected unlabelled (possibly crowdsourced) WiFi signals. Prior art either estimates the locations of the new signals without updating the existing fingerprints or filters out the new APs without sufficiently embracing their features. To address that, we propose GUFU, a novel effective graph-based approach to update WiFi fingerprints using unlabelled signals with possibly new APs. Based on the observation that similar signal vectors likely imply physical proximity, GUFU employs a graph neural network (GNN) and a link prediction algorithm to retrain an incremental network given the new signals and APs. After the retraining, it then updates the signal vectors at the designated locations. Through extensive experiments in four large representative sites, GUFU is shown to achieve remarkably higher fingerprint adaptivity as compared with other state-of-the-art approaches, with error reduction of 21.4% and 29.8% in RSS values and location prediction, respectively.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3712277&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; WiFi received signal strength (RSS) environment evolves over time due tomovement of access points (APs), AP power adjustment, installation and removalof APs, etc. We study how to effectively update an existing database offingerprints, defined as the RSS values of APs at designated locations, using abatch of newly collected unlabelled (possibly crowdsourced) WiFi signals. Priorart either estimates the locations of the new signals without updating theexisting fingerprints or filters out the new APs without sufficiently embracingtheir features. To address that, we propose GUFU, a novel effective graph-basedapproach to update WiFi fingerprints using unlabelled signals with possibly newAPs. Based on the observation that similar signal vectors likely imply physicalproximity, GUFU employs a graph neural network (GNN) and a link predictionalgorithm to retrain an incremental network given the new signals and APs.After the retraining, it then updates the signal vectors at the designatedlocations. Through extensive experiments in four large representative sites,GUFU is shown to achieve remarkably higher fingerprint adaptivity as comparedwith other state-of-the-art approaches, with error reduction of 21.4% and 29.8%in RSS values and location prediction, respectively.</description>
      <author>example@mail.com (Ka Ho Chiu, Handi Yin, Weipeng Zhuo, Chul-Ho Lee, S. -H. Gary Chan)</author>
      <guid isPermaLink="false">2507.11038v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Warehouse Spatial Question Answering with LLM Agent</title>
      <link>http://arxiv.org/abs/2507.10778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  1st Place Solution of the 9th AI City Challenge Track 3&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种数据高效的方法，用于增强多模态大型语言模型（MLLM）的空间理解能力，以解决复杂室内仓库场景中的空间问答任务。&lt;h4&gt;背景&lt;/h4&gt;空间理解对于现有的多模态大型语言模型（MLLMs）是一个挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一个具有强大和高级空间推理能力的LLM智能体系统，用于解决复杂室内仓库场景中的空间问答任务。&lt;h4&gt;方法&lt;/h4&gt;该系统集成了多个工具，使LLM智能体能够进行空间推理和API工具交互来回答复杂的空间问题。&lt;h4&gt;主要发现&lt;/h4&gt;在2025年AI城市挑战赛物理AI空间智能仓库数据集上的广泛评估表明，该系统在物体检索、计数和距离估计等任务中实现了高精度和效率。&lt;h4&gt;结论&lt;/h4&gt;系统代码可在https://github.com/hsiangwei0903/SpatialAgent处获取。&lt;h4&gt;翻译&lt;/h4&gt;摘要：空间理解一直是现有多模态大型语言模型（MLLMs）面临的挑战。以前的方法利用大规模的MLLM微调来增强MLLM的空间理解能力。在本文中，我们提出了一种数据高效的方法。我们提出了一种具有强大和高级空间推理能力的LLM智能体系统，该系统可用于解决复杂室内仓库场景中的挑战性空间问答任务。我们的系统集成了多个工具，允许LLM智能体进行空间推理和API工具交互来回答给定的问题。在2025年AI城市挑战赛物理AI空间智能仓库数据集上的广泛评估表明，我们的系统在物体检索、计数和距离估计等任务中实现了高精度和效率。代码可在：https://github.com/hsiangwei0903/SpatialAgent处获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial understanding has been a challenging task for existing Multi-modalLarge Language Models~(MLLMs). Previous methods leverage large-scale MLLMfinetuning to enhance MLLM's spatial understanding ability. In this paper, wepresent a data-efficient approach. We propose a LLM agent system with strongand advanced spatial reasoning ability, which can be used to solve thechallenging spatial question answering task in complex indoor warehousescenarios. Our system integrates multiple tools that allow the LLM agent toconduct spatial reasoning and API tools interaction to answer the givencomplicated spatial question. Extensive evaluations on the 2025 AI CityChallenge Physical AI Spatial Intelligence Warehouse dataset demonstrate thatour system achieves high accuracy and efficiency in tasks such as objectretrieval, counting, and distance estimation. The code is available at:https://github.com/hsiangwei0903/SpatialAgent</description>
      <author>example@mail.com (Hsiang-Wei Huang, Jen-Hao Cheng, Kuang-Ming Chen, Cheng-Yen Yang, Bahaa Alattar, Yi-Ru Lin, Pyongkun Kim, Sangwon Kim, Kwangju Kim, Chung-I Huang, Jenq-Neng Hwang)</author>
      <guid isPermaLink="false">2507.10778v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Supporting SENĆOTEN Language Documentation Efforts with Automatic Speech Recognition</title>
      <link>http://arxiv.org/abs/2507.10827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ComputEL-8&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了如何使用自动语音识别技术来加速SEN'COTEN语言的文档记录和教育工作。&lt;h4&gt;背景&lt;/h4&gt;SEN'COTEN语言位于加拿大不列颠哥伦比亚省的桑尼什半岛，正处于语言复兴过程中，以应对殖民语言政策导致的语言丧失。&lt;h4&gt;目的&lt;/h4&gt;支持SEN'COTEN语言的复兴，提高语言文档记录和教育工作效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于ASR的文档流程，利用文本到语音系统增强语音数据，以及跨语言迁移学习和语音基础模型（SFMs）来解决数据有限和词汇多样性的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该ASR流程在测试集上的词错误率为19.34%，字符错误率为5.09%，且词汇外错误率为57.02%。经过过滤小写变音符号相关错误后，词错误率降低至14.32%，字符错误率降至3.45%。&lt;h4&gt;结论&lt;/h4&gt;该ASR驱动流程有潜力支持SEN'COTEN语言的文档记录。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了如何利用自动语音识别技术加速SEN'COTEN语言的文档记录和教育资源创建。SEN'COTEN语言在加拿大不列颠哥伦比亚省的桑尼什半岛使用，目前正经历语言复兴以对抗由于殖民语言政策造成的语言丧失。为了支持这些现场努力，社区正在转向数字技术。为了解决由于数据有限和其多合成结构和受重音驱动的音变而引起的词汇变化问题，我们提出了一种利用文本到语音系统增强语音数据和跨语言迁移学习以及语音基础模型（SFMs）的ASR驱动文档流程。此外，通过浅层融合或n-best恢复纳入n-gram语言模型，以最大化使用可用数据。在SEN'COTEN数据集上的实验表明，在测试集上的词错误率为19.34%，字符错误率为5.09%，词汇外错误率为57.02%。经过过滤小写变音符号相关错误后，词错误率降至14.32%（在未见单词上的词错误率为26.48%），字符错误率降至3.45%，这表明我们的ASR驱动流程有潜力支持SEN'COTEN语言的文档记录。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The SEN\'{C}OTEN language, spoken on the Saanich peninsula of southernVancouver Island, is in the midst of vigorous language revitalization effortsto turn the tide of language loss as a result of colonial language policies. Tosupport these on-the-ground efforts, the community is turning to digitaltechnology. Automatic Speech Recognition (ASR) technology holds great promisefor accelerating language documentation and the creation of educationalresources. However, developing ASR systems for SEN\'{C}OTEN is challenging dueto limited data and significant vocabulary variation from its polysyntheticstructure and stress-driven metathesis. To address these challenges, we proposean ASR-driven documentation pipeline that leverages augmented speech data froma text-to-speech (TTS) system and cross-lingual transfer learning with SpeechFoundation Models (SFMs). An n-gram language model is also incorporated viashallow fusion or n-best restoring to maximize the use of available data.Experiments on the SEN\'{C}OTEN dataset show a word error rate (WER) of 19.34%and a character error rate (CER) of 5.09% on the test set with a 57.02%out-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors, WERimproves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating thepotential of our ASR-driven pipeline to support SEN\'{C}OTEN languagedocumentation.</description>
      <author>example@mail.com (Mengzhe Geng, Patrick Littell, Aidan Pine, PENÁĆ, Marc Tessier, Roland Kuhn)</author>
      <guid isPermaLink="false">2507.10827v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Clustering-Guided Multi-Layer Contrastive Representation Learning for Citrus Disease Classification</title>
      <link>http://arxiv.org/abs/2507.11171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的计算机视觉算法，用于柑橘病害的检测和分类，通过引入新的设计优化了算法性能。&lt;h4&gt;背景&lt;/h4&gt;柑橘是全球最重要的水果作物之一，但各种疾病会导致严重的产量下降。准确检测和分类是实施针对性控制措施的关键。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的聚类引导的自监督多层对比表示学习（CMCRL）算法，以优化柑橘病害检测和分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法通过引入两个关键设计：与聚类中心对比和多层对比训练（MCT）范式，优化了大规模未标注样本的使用，并有效适应了不同柑橘病害的症状相似性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在公共柑橘图像集CDD上取得了最先进的性能，比现有方法提高了4.5%-30.1%的准确率，并且对类别不平衡挑战具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该方法在分类准确性、F1分数、精确率和召回率等评估指标上均表现出色，缩小了与全监督方法的性能差距。&lt;h4&gt;翻译&lt;/h4&gt;Citrus, as one of the most economically important fruit crops globally, suffers severe yield depressions due to various diseases. Accurate disease detection and classification serve as critical prerequisites for implementing targeted control measures. Recent advancements in artificial intelligence, particularly deep learning-based computer vision algorithms, have substantially decreased time and labor requirements while maintaining the accuracy of detection and classification. Nevertheless, these methods predominantly rely on massive, high-quality annotated training examples to attain promising performance. By introducing two key designs: contrasting with cluster centroids and a multi-layer contrastive training (MCT) paradigm, this paper proposes a novel clustering-guided self-supervised multi-layer contrastive representation learning (CMCRL) algorithm. The proposed method demonstrates several advantages over existing counterparts: (1) optimizing with massive unannotated samples; (2) effective adaptation to the symptom similarity across distinct citrus diseases; (3) hierarchical feature representation learning. The proposed method achieves state-of-the-art performance on the public citrus image set CDD, outperforming existing methods by 4.5%-30.1% accuracy. Remarkably, our method narrows the performance gap with fully supervised counterparts (all samples are labeled). Beyond classification accuracy, our method shows great performance on other evaluation metrics (F1 score, precision, and recall), highlighting the robustness against the class imbalance challenge.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Citrus, as one of the most economically important fruit crops globally,suffers severe yield depressions due to various diseases. Accurate diseasedetection and classification serve as critical prerequisites for implementingtargeted control measures. Recent advancements in artificial intelligence,particularly deep learning-based computer vision algorithms, have substantiallydecreased time and labor requirements while maintaining the accuracy ofdetection and classification. Nevertheless, these methods predominantly rely onmassive, high-quality annotated training examples to attain promisingperformance. By introducing two key designs: contrasting with cluster centroidsand a multi-layer contrastive training (MCT) paradigm, this paper proposes anovel clustering-guided self-supervised multi-layer contrastive representationlearning (CMCRL) algorithm. The proposed method demonstrates several advantagesover existing counterparts: (1) optimizing with massive unannotated samples;(2) effective adaptation to the symptom similarity across distinct citrusdiseases; (3) hierarchical feature representation learning. The proposed methodachieves state-of-the-art performance on the public citrus image set CDD,outperforming existing methods by 4.5\%-30.1\% accuracy. Remarkably, our methodnarrows the performance gap with fully supervised counterparts (all samples arelabeled). Beyond classification accuracy, our method shows great performance onother evaluation metrics (F1 score, precision, and recall), highlighting therobustness against the class imbalance challenge.</description>
      <author>example@mail.com (Jun Chen, Yonghua Yu, Weifu Li, Yaohui Chen, Hong Chen)</author>
      <guid isPermaLink="false">2507.11171v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Biological Processing Units: Leveraging an Insect Connectome to Pioneer Biofidelic Neural Architectures</title>
      <link>http://arxiv.org/abs/2507.10951v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to AGI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了果蝇幼虫大脑的完整连接组，探讨了生物进化电路是否能够支持人工智能。通过将连接图转换为生物处理单元（BPU），一个直接从突触连接性派生的固定循环网络，实现了在MNIST和CIFAR-10数据集上的高准确率，并超越了同尺寸的多层感知器。通过结构化连接组扩展对BPU进行扩展，进一步提高了CIFAR-10的性能，并通过特定模态的缩减揭示了不同感觉子系统的贡献不均匀。在ChessBench数据集上，一个轻量级的GNN-BPU模型在仅训练了10,000场比赛后，达到了60%的走棋准确率，远超任何同尺寸的Transformer。此外，具有约200万个参数的CNN-BPU模型优于参数匹配的Transformer，并在推理时使用深度6的最小-最大搜索，达到了91.7%的准确率，甚至超过了9M参数的Transformer基线。&lt;h4&gt;背景&lt;/h4&gt;果蝇幼虫大脑的完整连接组为研究生物进化电路支持人工智能提供了独特的机会。&lt;h4&gt;目的&lt;/h4&gt;研究生物进化电路是否能够支持人工智能，并探索其在大脑结构中的应用。&lt;h4&gt;方法&lt;/h4&gt;将果蝇幼虫大脑的连接图转换为生物处理单元（BPU），并通过结构化连接组扩展对BPU进行扩展。&lt;h4&gt;主要发现&lt;/h4&gt;未修改的BPU在MNIST和CIFAR-10数据集上实现了高准确率，通过结构化连接组扩展进一步提高了CIFAR-10的性能。在ChessBench数据集上，轻量级的GNN-BPU模型在仅训练了10,000场比赛后，达到了60%的走棋准确率。CNN-BPU模型在推理时使用深度6的最小-最大搜索，达到了91.7%的准确率。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，生物相似性神经网络架构在支持复杂认知任务方面具有潜力，并激励未来工作扩展到更大和更智能的连接组。&lt;h4&gt;翻译&lt;/h4&gt;摘要：果蝇幼虫大脑的完整连接组为研究生物进化电路是否能够支持人工智能提供了独特的机会。我们将这个连接图转换为生物处理单元（BPU），这是一个直接从突触连接性派生的固定循环网络。尽管其规模适中（3,000个神经元和65,000个之间的权重），未经修改的BPU在MNIST上实现了98%的准确率，在CIFAR-10上实现了58%的准确率，超过了同尺寸的多层感知器。通过结构化连接组扩展对BPU进行扩展，进一步提高了CIFAR-10的性能，而特定模态的缩减揭示了不同感觉子系统的贡献不均匀。在ChessBench数据集上，一个轻量级的GNN-BPU模型在仅训练了10,000场比赛后，达到了60%的走棋准确率，几乎比任何同尺寸的Transformer都要好10倍。此外，具有约200万个参数的CNN-BPU模型优于参数匹配的Transformer，并在推理时使用深度6的最小-最大搜索，达到了91.7%的准确率，甚至超过了9M参数的Transformer基线。这些结果表明，生物相似性神经网络架构在支持复杂认知任务方面具有潜力，并激励未来工作扩展到更大和更智能的连接组。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The complete connectome of the Drosophila larva brain offers a uniqueopportunity to investigate whether biologically evolved circuits can supportartificial intelligence. We convert this wiring diagram into a BiologicalProcessing Unit (BPU), a fixed recurrent network derived directly from synapticconnectivity. Despite its modest size 3,000 neurons and 65,000 weights betweenthem), the unmodified BPU achieves 98% accuracy on MNIST and 58% on CIFAR-10,surpassing size-matched MLPs. Scaling the BPU via structured connectomeexpansions further improves CIFAR-10 performance, while modality-specificablations reveal the uneven contributions of different sensory subsystems. Onthe ChessBench dataset, a lightweight GNN-BPU model trained on only 10,000games achieves 60% move accuracy, nearly 10x better than any size transformer.Moreover, CNN-BPU models with ~2M parameters outperform parameter-matchedTransformers, and with a depth-6 minimax search at inference, reach 91.7%accuracy, exceeding even a 9M-parameter Transformer baseline. These resultsdemonstrate the potential of biofidelic neural architectures to support complexcognitive tasks and motivate scaling to larger and more intelligent connectomesin future work.</description>
      <author>example@mail.com (Siyu Yu, Zihan Qin, Tingshan Liu, Beiya Xu, R. Jacob Vogelstein, Jason Brown, Joshua T. Vogelstein)</author>
      <guid isPermaLink="false">2507.10951v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Focus on Texture: Rethinking Pre-training in Masked Autoencoders for Medical Image Classification</title>
      <link>http://arxiv.org/abs/2507.10869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于GLCM特征的新型MAE预训练框架，用于医学图像中的自监督表示学习，并在多个医学图像分类任务中取得了优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;MAEs在自然图像的自监督表示学习中表现优异，但在医学图像分类中，由于纹理特征的重要性，传统MAE方法失效。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的MAE预训练框架，以改善医学图像分类任务的表现。&lt;h4&gt;方法&lt;/h4&gt;1. 使用基于GLCM的重建损失来训练模型；2. 将匹配的GLCM矩阵转换为可微分的损失函数；3. 在医学图像上进行无监督预训练。&lt;h4&gt;主要发现&lt;/h4&gt;使用GLCM-MAE预训练的医学图像在胆囊癌、乳腺癌、肺炎和COVID检测四个任务上均优于现有方法，分别提高了2.1%、3.1%、0.5%和0.6%。&lt;h4&gt;结论&lt;/h4&gt;GLCM-MAE预训练框架能够有效提升医学图像分类任务的性能，为医学图像分析提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：掩码自动编码器（MAEs）已成为自然图像自监督表示学习的主导策略，模型通过最小化原始图像和重建图像之间的像素级均方误差（MSE）来预训练重建被遮挡的图像块。我们观察到MSE鼓励模糊图像重建，但对于自然图像仍然有效，因为它保留了主要边缘。然而，在医学图像中，当纹理特征对于视觉异常的分类更重要时，这种策略失效。受放射组学研究中灰度级共现矩阵（GLCM）特征灵感的启发，我们提出了一种基于匹配GLCM的重建损失的新MAE预训练框架，称为GLCM-MAE，它有助于保留形态学特征。此外，我们提出了一种将匹配的GLCM矩阵转换为可微分损失函数的新方法。我们证明，使用所提出的GLCM损失在医学图像上进行无监督预训练可以改善下游任务的表现。GLCM-MAE在四个任务上优于当前最先进的方法——超声图像中的胆囊癌检测提高了2.1%，超声图像中的乳腺癌检测提高了3.1%，X射线中的肺炎检测提高了0.5%，以及CT图像中的COVID检测提高了0.6%。源代码和预训练模型可在以下网址获得：https://github.com/ChetanMadan/GLCM-MAE。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked Autoencoders (MAEs) have emerged as a dominant strategy forself-supervised representation learning in natural images, where models arepre-trained to reconstruct masked patches with a pixel-wise mean squared error(MSE) between original and reconstructed RGB values as the loss. We observethat MSE encourages blurred image re-construction, but still works for naturalimages as it preserves dominant edges. However, in medical imaging, when thetexture cues are more important for classification of a visual abnormality, thestrategy fails. Taking inspiration from Gray Level Co-occurrence Matrix (GLCM)feature in Radiomics studies, we propose a novel MAE based pre-trainingframework, GLCM-MAE, using reconstruction loss based on matching GLCM. GLCMcaptures intensity and spatial relationships in an image, hence proposed losshelps preserve morphological features. Further, we propose a novel formulationto convert matching GLCM matrices into a differentiable loss function. Wedemonstrate that unsupervised pre-training on medical images with the proposedGLCM loss improves representations for downstream tasks. GLCM-MAE outperformsthe current state-of-the-art across four tasks - gallbladder cancer detectionfrom ultrasound images by 2.1%, breast cancer detection from ultrasound by3.1%, pneumonia detection from x-rays by 0.5%, and COVID detection from CT by0.6%. Source code and pre-trained models are available at:https://github.com/ChetanMadan/GLCM-MAE.</description>
      <author>example@mail.com (Chetan Madan, Aarjav Satia, Soumen Basu, Pankaj Gupta, Usha Dutta, Chetan Arora)</author>
      <guid isPermaLink="false">2507.10869v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning</title>
      <link>http://arxiv.org/abs/2507.10899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于SAM2的物体中心方法，用于移动操作中的模仿学习，以解决移动操作框架中导航与操作分离的问题，并提高操作的通用性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;移动操作中的模仿学习是一个关键挑战，当前框架通常在到达特定位置后执行操作，导致导航不精确时性能下降。&lt;h4&gt;目的&lt;/h4&gt;实现移动操作机器人从不同方向执行相同任务，以提高通用性。&lt;h4&gt;方法&lt;/h4&gt;该方法基于SAM2，将操作方向信息融入模型，以实现从不同方向对同一任务的持续理解。&lt;h4&gt;主要发现&lt;/h4&gt;与使用来自不同接近角度的演示进行训练的Action Chunking Transformer相比，该模型在处理不同方向时保持了优越的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;这项工作显著提高了基于模仿学习的移动操作系统的泛化能力和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning for mobile manipulation is a key challenge in the field ofrobotic manipulation. However, current mobile manipulation frameworks typicallydecouple navigation and manipulation, executing manipulation only afterreaching a certain location. This can lead to performance degradation whennavigation is imprecise, especially due to misalignment in approach angles. Toenable a mobile manipulator to perform the same task from diverse orientations,an essential capability for building general-purpose robotic models, we proposean object-centric method based on SAM2, a foundation model towards solvingpromptable visual segmentation in images, which incorporates manipulationorientation information into our model. Our approach enables consistentunderstanding of the same task from different orientations. We deploy the modelon a custom-built mobile manipulator and evaluate it on a pick-and-place taskunder varied orientation angles. Compared to Action Chunking Transformer, ourmodel maintains superior generalization when trained with demonstrations fromvaried approach angles. This work significantly enhances the generalization androbustness of imitation learning-based mobile manipulation systems.</description>
      <author>example@mail.com (Wang Zhicheng, Satoshi Yagi, Satoshi Yamamori, Jun Morimoto)</author>
      <guid isPermaLink="false">2507.10899v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>GALDS: A Graph-Autoencoder-based Latent Dynamics Surrogate model to predict neurite material transport</title>
      <link>http://arxiv.org/abs/2507.10871v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于图自动编码器的潜在动力学代理（GALDS）模型，用于简化神经树中物质传输的模拟，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;神经元网络具有复杂的几何结构，这对信号传递和营养物质的运输至关重要。精确模拟这些网络中的物质传输对理解这些生物现象至关重要，但传统的模拟方法由于涉及的复杂树状结构而具有计算上的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的模型来模拟神经树中物质传输的过程，同时减少计算资源的需求。&lt;h4&gt;方法&lt;/h4&gt;提出了GALDS模型，该模型使用图自动编码器来编码网络的几何形状、速度场和浓度分布的潜在表示，然后使用这些表示在潜在空间中进行系统动力学的预测。&lt;h4&gt;主要发现&lt;/h4&gt;GALDS模型在八个未见过的几何形状和四个异常传输示例中证明了其有效性，平均相对误差为3%，最大相对误差小于8%，与之前的代理模型方法相比，速度提高了10倍。&lt;h4&gt;结论&lt;/h4&gt;GALDS模型通过优化神经网络的结构和动力学预测，为神经树中物质传输的模拟提供了有效的解决方案，同时减少了计算资源和时间的需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经元在其突起网络中表现出复杂的几何形状，这些形状在信号传递和营养物质运输等过程中起着至关重要的作用。准确模拟这些网络中的物质传输对于理解这些生物现象至关重要，但由于涉及的复杂树状结构，这提出了重大的计算挑战。传统的模拟方法耗时且资源密集，然而，神经元树的本质特性，即主要由具有稳态抛物线速度分布和分支的管道组成，为计算优化提供了机会。为了解决这些挑战，我们提出了一种基于图自动编码器的潜在动力学代理（GALDS）模型，该模型专门设计用于简化神经树中物质传输的模拟。GALDS使用图自动编码器对网络的几何形状、速度场和浓度分布的潜在表示进行编码。然后，将这些潜在空间表示组装成全局图，随后使用受神经网络常微分方程（Neural ODEs）概念启发的训练好的图潜在空间系统动力学模型在潜在空间中预测系统动力学。自动编码器的集成允许使用具有减少的培训数据需求的小型图神经网络模型。此外，神经网络常微分方程组件有效地减轻了在循环神经网络中常见的误差累积问题。通过在八个未见过的几何形状和四个异常传输示例上的结果，我们证明了GALDS模型的有效性，我们的方法实现了3%的平均相对误差，最大相对误差小于8%，与之前的代理模型方法相比，速度提高了10倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neurons exhibit intricate geometries within their neurite networks, whichplay a crucial role in processes such as signaling and nutrient transport.Accurate simulation of material transport in the networks is essential forunderstanding these biological phenomena but poses significant computationalchallenges because of the complex tree-like structures involved. Traditionalapproaches are time-intensive and resource-demanding, yet the inherentproperties of neuron trees, which consists primarily of pipes with steady-stateparabolic velocity profiles and bifurcations, provide opportunities forcomputational optimization. To address these challenges, we propose aGraph-Autoencoder-based Latent Dynamics Surrogate (GALDS) model, which isspecifically designed to streamline the simulation of material transport inneural trees. GALDS employs a graph autoencoder to encode latentrepresentations of the network's geometry, velocity fields, and concentrationprofiles. These latent space representations are then assembled into a globalgraph, which is subsequently used to predict system dynamics in the latentspace via a trained graph latent space system dynamic model, inspired by theNeural Ordinary Differential Equations (Neural ODEs) concept. The integrationof an autoencoder allows for the use of smaller graph neural network modelswith reduced training data requirements. Furthermore, the Neural ODE componenteffectively mitigates the issue of error accumulation commonly encountered inrecurrent neural networks. The effectiveness of the GALDS model is demonstratedthrough results on eight unseen geometries and four abnormal transportexamples, where our approach achieves mean relative error of 3% with maximumrelative error &lt;8% and demonstrates a 10-fold speed improvement compared toprevious surrogate model approaches.</description>
      <author>example@mail.com (Tsung Yeh Hsieh, Yongjie Jessica Zhang)</author>
      <guid isPermaLink="false">2507.10871v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>WhisperKit: On-device Real-time ASR with Billion-Scale Transformers</title>
      <link>http://arxiv.org/abs/2507.10860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 - On-Device Learning for Foundational Models Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了WhisperKit，这是一个针对实时语音识别（ASR）的优化设备端推理系统，其在准确性和延迟方面显著优于领先的云端系统。&lt;h4&gt;背景&lt;/h4&gt;实时自动语音识别（ASR）是许多机器学习商业应用的基础，如实时字幕、语音听写、会议记录和医疗转录。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一个优化的设备端推理系统，以解决实时ASR中的准确性和延迟问题。&lt;h4&gt;方法&lt;/h4&gt;研究人员对包括前沿模型（OpenAI gpt-4o-transcribe）、专有模型（Deepgram nova-3）和开源模型（Fireworks large-v3-turbo）在内的多种服务器端系统进行了基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;WhisperKit在0.46秒的最低延迟下实现了最高的准确率，达到了2.2%的词错误率（WER）。&lt;h4&gt;结论&lt;/h4&gt;本文详细描述了WhisperKit系统背后的优化方法，该系统在实时ASR中具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：实时自动语音识别（ASR）是许多机器学习商业应用的基础模块，包括实时字幕、语音听写、会议记录和医疗转录。准确性和延迟是公司在选择部署系统时最重要的因素。我们提出了WhisperKit，这是一个针对实时ASR的优化设备端推理系统，其性能显著优于领先的云端系统。我们将其与部署了多种模型的客户端系统进行了基准测试，包括前沿模型（OpenAI gpt-4o-transcribe）、专有模型（Deepgram nova-3）和开源模型（Fireworks large-v3-turbo）。我们的结果显示，WhisperKit在0.46秒的最低延迟下实现了最高的准确率，达到了2.2%的词错误率（WER）。本文详细描述了WhisperKit系统背后的优化方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-time Automatic Speech Recognition (ASR) is a fundamental building blockfor many commercial applications of ML, including live captioning, dictation,meeting transcriptions, and medical scribes. Accuracy and latency are the mostimportant factors when companies select a system to deploy. We presentWhisperKit, an optimized on-device inference system for real-time ASR thatsignificantly outperforms leading cloud-based systems. We benchmark againstserver-side systems that deploy a diverse set of models, including a frontiermodel (OpenAI gpt-4o-transcribe), a proprietary model (Deepgram nova-3), and anopen-source model (Fireworks large-v3-turbo).Our results show that WhisperKitmatches the lowest latency at 0.46s while achieving the highest accuracy 2.2%WER. The optimizations behind the WhisperKit system are described in detail inthis paper.</description>
      <author>example@mail.com (Atila Orhon, Arda Okan, Berkin Durmus, Zach Nagengast, Eduardo Pacheco)</author>
      <guid isPermaLink="false">2507.10860v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>CLA: Latent Alignment for Online Continual Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2507.10434v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CoLLAs 2025 conference (oral)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Continual Latent Alignment（CLA）的新的自监督学习策略，用于在线连续学习（Online CL）场景，旨在通过将当前模型学习到的表示与过去的表示对齐来减轻遗忘现象。&lt;h4&gt;背景&lt;/h4&gt;现有的自监督学习方法在在线连续学习场景中应用较少，这种场景中数据以小批量的形式到来，模型必须遵守固定的计算预算，且没有任务边界。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督学习策略，以改善在线连续学习中的模型表现，并减轻模型在训练过程中的遗忘问题。&lt;h4&gt;方法&lt;/h4&gt;引入了Continual Latent Alignment（CLA）策略，该策略通过对齐当前模型与过去模型学习到的表示来减少遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;CLA能够加速在线场景下的训练过程收敛，在相同的计算预算下优于现有方法。此外，发现将CLA作为预训练协议的早期阶段，相比于完全独立同分布（i.i.d.）预训练，可以带来更好的最终性能。&lt;h4&gt;结论&lt;/h4&gt;CLA是一种有效的自监督学习策略，适用于在线连续学习，能够提高模型在训练过程中的表现并减轻遗忘问题。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning (SSL) is able to build latent representations that generalize well to unseen data. However, only a few SSL techniques exist for the online CL setting, where data arrives in small minibatches, the model must comply with a fixed computational budget, and task boundaries are absent. We introduce Continual Latent Alignment (CLA), a novel SSL strategy for Online CL that aligns the representations learned by the current model with past representations to mitigate forgetting. We found that our CLA is able to speed up the convergence of the training process in the online scenario, outperforming state-of-the-art approaches under the same computational budget. Surprisingly, we also discovered that using CLA as a pretraining protocol in the early stages of pretraining leads to a better final performance when compared to a full i.i.d. pretraining.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) is able to build latent representations thatgeneralize well to unseen data. However, only a few SSL techniques exist forthe online CL setting, where data arrives in small minibatches, the model mustcomply with a fixed computational budget, and task boundaries are absent. Weintroduce Continual Latent Alignment (CLA), a novel SSL strategy for Online CLthat aligns the representations learned by the current model with pastrepresentations to mitigate forgetting. We found that our CLA is able to speedup the convergence of the training process in the online scenario,outperforming state-of-the-art approaches under the same computational budget.Surprisingly, we also discovered that using CLA as a pretraining protocol inthe early stages of pretraining leads to a better final performance whencompared to a full i.i.d. pretraining.</description>
      <author>example@mail.com (Giacomo Cignoni, Andrea Cossu, Alexandra Gomez-Villa, Joost van de Weijer, Antonio Carta)</author>
      <guid isPermaLink="false">2507.10434v2</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>REAL-IoT: Characterizing GNN Intrusion Detection Robustness under Practical Adversarial Attack</title>
      <link>http://arxiv.org/abs/2507.10836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为REAL-IoT的综合框架，用于评估基于图神经网络（GNN）的网络入侵检测系统（NIDS）在物联网环境中的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的基于GNN的NIDS通常在单一数据集上评估，限制了其泛化能力，并且其对抗鲁棒性通常使用缺乏现实性的合成扰动来评估，导致对其鲁棒性的高估。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出REAL-IoT框架，旨在评估GNN-based NIDS在物联网环境中的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;REAL-IoT框架通过创建一个统一的数据集来评估泛化能力，并包含一个从物理物联网测试床收集的入侵数据集，以捕捉现实世界环境下的网络流量和攻击场景。此外，使用LLMs分析网络数据，并通过过滤可疑流量来减轻对抗样本的影响。&lt;h4&gt;主要发现&lt;/h4&gt;使用REAL-IoT进行评估发现，GNN模型的表现与标准基准测试结果相比有所下降，量化了其对漂移和现实攻击的敏感性。同时，LLM基于的过滤增强了鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;这些发现强调了进行现实威胁建模和严格的测量实践对于开发具有鲁棒性的物联网入侵检测系统的必要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于图神经网络（GNN）的网络入侵检测系统（NIDS）通常在单一数据集上进行评估，这限制了它们在分布漂移下的泛化能力。此外，它们的对抗鲁棒性通常使用缺乏现实性的合成扰动来评估，这导致了对基于GNN的NIDS鲁棒性的高估。为了解决这些局限性，我们提出了REAL-IoT，这是一个用于评估基于GNN的NIDS在物联网环境中鲁棒性的综合框架。我们的框架提出了一种方法，通过从规范数据集中创建统一的数据集来评估漂移下的泛化能力。此外，它还包含了一个从物理物联网测试床收集的入侵数据集，该数据集捕捉了现实世界环境下的网络流量和攻击场景。此外，使用REAL-IoT，我们探讨了使用大型语言模型（LLMs）来分析网络数据，并通过过滤可疑流量来减轻对抗样本的影响。使用REAL-IoT进行的评估揭示了与标准基准测试结果相比，GNN模型性能的下降，量化了其对漂移和现实攻击的敏感性。我们还展示了基于LLM的过滤增强鲁棒性的潜力。这些发现强调了进行现实威胁建模和严格的测量实践对于开发具有鲁棒性的物联网入侵检测系统的必要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Network (GNN)-based network intrusion detection systems (NIDS)are often evaluated on single datasets, limiting their ability to generalizeunder distribution drift. Furthermore, their adversarial robustness istypically assessed using synthetic perturbations that lack realism. Thismeasurement gap leads to an overestimation of GNN-based NIDS resilience. Toaddress the limitations, we propose \textbf{REAL-IoT}, a comprehensiveframework for robustness evaluation of GNN-based NIDS in IoT environments. Ourframework presents a methodology that creates a unified dataset from canonicaldatasets to assess generalization under drift. In addition, it features a novelintrusion dataset collected from a physical IoT testbed, which captures networktraffic and attack scenarios under real-world settings. Furthermore, usingREAL-IoT, we explore the usage of Large Language Models (LLMs) to analyzenetwork data and mitigate the impact of adversarial examples by filteringsuspicious flows. Our evaluations using REAL-IoT reveal performance drops inGNN models compared to results from standard benchmarks, quantifying theirsusceptibility to drift and realistic attacks. We also demonstrate thepotential of LLM-based filtering to enhance robustness. These findingsemphasize the necessity of realistic threat modeling and rigorous measurementpractices for developing resilient IoT intrusion detection systems.</description>
      <author>example@mail.com (Zhonghao Zhan, Huichi Zhou, Hamed Haddadi)</author>
      <guid isPermaLink="false">2507.10836v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers</title>
      <link>http://arxiv.org/abs/2507.10787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACL 2025 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MISS-QA，这是第一个专门设计来评估模型在科学文献中解释原理图能力的基准。该基准包含1500个专家标注的例子，涵盖465篇科学论文。&lt;h4&gt;背景&lt;/h4&gt;在科学文献中，原理图是理解研究概述和回答相关问题的重要工具。&lt;h4&gt;目的&lt;/h4&gt;评估模型在解释原理图和理解科学文献方面的能力。&lt;h4&gt;方法&lt;/h4&gt;MISS-QA包含1500个专家标注的例子，模型需要解释原理图并基于论文的广泛背景回答相关问题。研究人员评估了18个前沿的多模态基础模型的表现。&lt;h4&gt;主要发现&lt;/h4&gt;这些模型在MISS-QA上与人类专家之间存在显著的性能差距。对无法回答的问题的分析和详细错误分析进一步突出了当前模型的优点和局限性。&lt;h4&gt;结论&lt;/h4&gt;这些发现为提高模型理解多模态科学文献的能力提供了关键见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces MISS-QA, the first benchmark specifically designed toevaluate the ability of models to interpret schematic diagrams withinscientific literature. MISS-QA comprises 1,500 expert-annotated examples over465 scientific papers. In this benchmark, models are tasked with interpretingschematic diagrams that illustrate research overviews and answeringcorresponding information-seeking questions based on the broader context of thepaper. We assess the performance of 18 frontier multimodal foundation models,including o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significantperformance gap between these models and human experts on MISS-QA. Our analysisof model performance on unanswerable questions and our detailed error analysisfurther highlight the strengths and limitations of current models, offering keyinsights to enhance models in comprehending multimodal scientific literature.</description>
      <author>example@mail.com (Yilun Zhao, Chengye Wang, Chuhan Li, Arman Cohan)</author>
      <guid isPermaLink="false">2507.10787v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Quantize and Precode in Massive MIMO Systems for Energy Reduction: a Graph Neural Network Approach</title>
      <link>http://arxiv.org/abs/2507.10634v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了粗量化下行大规模MIMO系统中的非线性预编码问题，提出了一种基于图神经网络的方法，以降低硬件复杂度和功耗。&lt;h4&gt;背景&lt;/h4&gt;大规模MIMO系统正朝着增加射频链路数量、提高载波频率和更大带宽的方向发展，导致数字到模拟转换器（DAC）成为硬件复杂度和功耗的瓶颈。&lt;h4&gt;目的&lt;/h4&gt;研究粗量化下行大规模MIMO系统中的非线性预编码方法，以提高系统性能并降低功耗。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于图神经网络（GNN）的方法，该方法直接输出基于信道矩阵和期望传输符号的预编码量化向量。模型通过自监督方式训练，直接最大化可实现的速率。为了克服由于非可微分的DAC函数引入的目标函数的非可微性，提出了直通Gumbel-softmax梯度估计。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在粗量化下实现了可实现的总速率的显著提高。例如，在单用户情况下，与使用3比特的MRT相比，该方法可以使用1比特DAC实现相同的总速率。这减少了DAC的功耗，对于基带DAC和射频DAC分别减少了4-7倍和3倍。然而，这以增加数字信号处理功耗为代价。考虑这一点后，对于基带DAC，系统带宽高达3.5 MHz时，整体功耗降低；而对于射频DAC，在更高带宽下可以维持2.9的功耗降低。&lt;h4&gt;结论&lt;/h4&gt;虽然数字信号处理功耗增加，但该方法在基带DAC和射频DAC上均实现了显著的功耗降低，特别是在较高带宽下。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies the non-linear precoding for coarse quantized downlink massive MIMO systems. A graph neural network (GNN) method is proposed that directly outputs the precoded quantized vector based on the channel matrix and the intended transmit symbols. The model is trained in a self-supervised manner, by directly maximizing the achievable rate. To overcome the non-differentiability of the objective function introduced due to the non-differentiable DAC functions, a straight-through Gumbel-softmax gradient estimation is proposed. The proposed method achieves a significant increase in achievable sum rate under coarse quantization. For instance, in the single-user case, the proposed method can achieve the same sum rate as maximum ratio transmission (MRT) by using one-bit DAC's as compared to 3 bits for MRT. This reduces the DAC's power consumption by a factor of 4-7 and 3 for baseband and RF DACs respectively. However, this comes at the cost of increased digital signal processing power consumption. When accounting for this, the reduction in overall power consumption holds for a system bandwidth up to 3.5 MHz for baseband DACs, while the RF DACs can maintain a power reduction of 2.9 for higher bandwidths. Notably, indirect effects, which further reduce the power consumption, such as reduced fronthaul consumption and reduction in other components, are not considered in this analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Massive MIMO systems are moving toward increased numbers of radio frequencychains, higher carrier frequencies and larger bandwidths. As such,digital-to-analog converters (DACs) are becoming a bottleneck in terms ofhardware complexity and power consumption. In this work, non-linear precodingfor coarsely quantized downlink massive MIMO is studied. Given the NP-hardnature of this problem, a graph neural network (GNN) is proposed that directlyoutputs the precoded quantized vector based on the channel matrix and theintended transmit symbols. The model is trained in a self-supervised manner, bydirectly maximizing the achievable rate. To overcome the non-differentiabilityof the objective function, introduced due to the non-differentiable DACfunctions, a straight-through Gumbel-softmax estimation of the gradient isproposed. The proposed method achieves a significant increase in achievable sumrate under coarse quantization. For instance, in the single-user case, theproposed method can achieve the same sum rate as maximum ratio transmission(MRT) by using one-bit DAC's as compared to 3 bits for MRT. This reduces theDAC's power consumption by a factor 4-7 and 3 for baseband and RF DACsrespectively. This, however, comes at the cost of increased digital signalprocessing power consumption. When accounting for this, the reduction inoverall power consumption holds for a system bandwidth up to 3.5 MHz forbaseband DACs, while the RF DACs can maintain a power reduction of 2.9 forhigher bandwidths. Notably, indirect effects, which further reduce the powerconsumption, such as a reduced fronthaul consumption and reduction in othercomponents, are not considered in this analysis.</description>
      <author>example@mail.com (Thomas Feys, Liesbet Van der Perre, François Rottenberg)</author>
      <guid isPermaLink="false">2507.10634v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding</title>
      <link>http://arxiv.org/abs/2507.10776v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, IROS 2025, Interactive Perception, Segmentation, Robotics,  Computer Vision&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为rt-RISeg的实时交互式感知框架，用于解决机器人抓取等操作任务中未见过对象实例分割（UOIS）的问题。&lt;h4&gt;背景&lt;/h4&gt;在新的环境中执行灵活的机器人操作任务，如抓取，依赖于从背景和其他物体中高效地分割未见过对象的能力。以往的研究在大型数据集上训练模型，往往导致对静态视觉特征的过拟合，导致在分布外场景下泛化性能差。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一限制，基于视觉本质上是交互式且随时间发生的原理，重新思考了UOIS任务。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为rt-RISeg的实时交互式感知框架，通过机器人交互和分析设计的人体参考系不变特征（BFIF）来连续分割未见过对象。展示了随机采样的身体参考系的相对旋转和线性速度，可以用于识别对象，而无需任何学习的分割模型。这个完全自包含的分割管道在每次机器人交互期间生成和更新对象分割掩码，无需等待动作完成。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的交互式感知方法通过实现平均对象分割准确率比最先进的UOIS方法高出27.5%，证明了其有效性。此外，虽然rt-RISeg是一个独立框架，但自主生成的分割掩码可以用作视觉基础模型的提示，以显著提高性能。&lt;h4&gt;结论&lt;/h4&gt;rt-RISeg框架在UOIS任务中提供了更高的准确性和泛化能力，并展示了其在机器人抓取等任务中的实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Successful execution of dexterous robotic manipulation tasks in newenvironments, such as grasping, depends on the ability to proficiently segmentunseen objects from the background and other objects. Previous works in unseenobject instance segmentation (UOIS) train models on large-scale datasets, whichoften leads to overfitting on static visual features. This dependency resultsin poor generalization performance when confronted with out-of-distributionscenarios. To address this limitation, we rethink the task of UOIS based on theprinciple that vision is inherently interactive and occurs over time. Wepropose a novel real-time interactive perception framework, rt-RISeg, thatcontinuously segments unseen objects by robot interactions and analysis of adesigned body frame-invariant feature (BFIF). We demonstrate that the relativerotational and linear velocities of randomly sampled body frames, resultingfrom selected robot interactions, can be used to identify objects without anylearned segmentation model. This fully self-contained segmentation pipelinegenerates and updates object segmentation masks throughout each robotinteraction without the need to wait for an action to finish. We showcase theeffectiveness of our proposed interactive perception method by achieving anaverage object segmentation accuracy rate 27.5% greater than state-of-the-artUOIS methods. Furthermore, although rt-RISeg is a standalone framework, we showthat the autonomously generated segmentation masks can be used as prompts tovision foundation models for significantly improved performance.</description>
      <author>example@mail.com (Howard H. Qian, Yiting Chen, Gaotian Wang, Podshara Chanrungmaneekul, Kaiyu Hang)</author>
      <guid isPermaLink="false">2507.10776v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines</title>
      <link>http://arxiv.org/abs/2507.10737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的框架，通过整合外部生物学知识到现有的预训练策略中，来增强显微镜图像分析模型，以提高对新型细胞系的鲁棒性筛选。&lt;h4&gt;背景&lt;/h4&gt;高通量筛选技术在药物发现和生物医学研究中起着关键作用。然而，由于新型细胞系之间形态和生物学异质性的显著差异，对新型细胞系的鲁棒性筛选仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，研究提出了一种新的框架，该框架通过使用外部生物学信息来显式分离出特定于扰动和特定于细胞系的表示。&lt;h4&gt;方法&lt;/h4&gt;该方法构建了一个知识图谱，利用STRING和Hetionet数据库中的蛋白质相互作用数据来引导模型在预训练期间关注特定于扰动的特征。此外，还结合了单细胞基础模型中的转录组特征来捕获细胞系特定的表示。&lt;h4&gt;主要发现&lt;/h4&gt;通过学习这些分离的特征，该方法提高了成像模型对新型细胞系的泛化能力。实验结果表明，该方法在RxRx数据库上通过一次调整和RxRx19a数据集上的少量调整进行了评估，证明了其在基于表型的药物发现应用中的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法增强了新型细胞系的显微镜图像分析，突显了其在实际药物发现应用中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-throughput screening techniques, such as microscopy imaging of cellularresponses to genetic and chemical perturbations, play a crucial role in drugdiscovery and biomedical research. However, robust perturbation screening for\textit{de novo} cell lines remains challenging due to the significantmorphological and biological heterogeneity across cell lines. To address this,we propose a novel framework that integrates external biological knowledge intoexisting pretraining strategies to enhance microscopy image profiling models.Our approach explicitly disentangles perturbation-specific and cellline-specific representations using external biological information.Specifically, we construct a knowledge graph leveraging protein interactiondata from STRING and Hetionet databases to guide models towardperturbation-specific features during pretraining. Additionally, we incorporatetranscriptomic features from single-cell foundation models to capture cellline-specific representations. By learning these disentangled features, ourmethod improves the generalization of imaging models to \textit{de novo} celllines. We evaluate our framework on the RxRx database through one-shotfine-tuning on an RxRx1 cell line and few-shot fine-tuning on cell lines fromthe RxRx19a dataset. Experimental results demonstrate that our method enhancesmicroscopy image profiling for \textit{de novo} cell lines, highlighting itseffectiveness in real-world phenotype-based drug discovery applications.</description>
      <author>example@mail.com (Jiayuan Chen, Thai-Hoang Pham, Yuanlong Wang, Ping Zhang)</author>
      <guid isPermaLink="false">2507.10737v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Brains and Machines: A Unified Frontier in Neuroscience, Artificial Intelligence, and Neuromorphic Systems</title>
      <link>http://arxiv.org/abs/2507.10722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了神经科学、通用人工智能（AGI）和神经形态计算的融合趋势，提出了一个统一的研究范式。&lt;h4&gt;背景&lt;/h4&gt;文章以脑生理学为基础，强调了突触可塑性、稀疏脉冲通信和多模态关联为下一代AGI系统设计提供的设计原则。&lt;h4&gt;目的&lt;/h4&gt;通过分析从早期连接主义模型到最先进的语言模型的发展，文章旨在展示关键创新如变压器注意力、基础模型预训练和多代理架构如何反映神经生物学过程。&lt;h4&gt;方法&lt;/h4&gt;文章回顾了这一演变过程，并讨论了能够突破冯·诺伊曼瓶颈、在硅芯片上实现脑规模效率的新兴物理基础，如忆阻交叉阵列、内存计算阵列以及新兴的量子光子设备。&lt;h4&gt;主要发现&lt;/h4&gt;文章指出了四个关键挑战：1）将脉冲动力学与基础模型集成；2）在不发生灾难性遗忘的情况下维持终身可塑性；3）在具身智能体中将语言与感觉运动学习统一；4）在高级神经形态自主系统中实施伦理保障。&lt;h4&gt;结论&lt;/h4&gt;跨神经科学、计算和硬件的综合视角为这些领域提供了综合议程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This position and survey paper identifies the emerging convergence ofneuroscience, artificial general intelligence (AGI), and neuromorphic computingtoward a unified research paradigm. Using a framework grounded in brainphysiology, we highlight how synaptic plasticity, sparse spike-basedcommunication, and multimodal association provide design principles fornext-generation AGI systems that potentially combine both human and machineintelligences. The review traces this evolution from early connectionist modelsto state-of-the-art large language models, demonstrating how key innovationslike transformer attention, foundation-model pre-training, and multi-agentarchitectures mirror neurobiological processes like cortical mechanisms,working memory, and episodic consolidation. We then discuss emerging physicalsubstrates capable of breaking the von Neumann bottleneck to achievebrain-scale efficiency in silicon: memristive crossbars, in-memory computearrays, and emerging quantum and photonic devices. There are four criticalchallenges at this intersection: 1) integrating spiking dynamics withfoundation models, 2) maintaining lifelong plasticity without catastrophicforgetting, 3) unifying language with sensorimotor learning in embodied agents,and 4) enforcing ethical safeguards in advanced neuromorphic autonomoussystems. This combined perspective across neuroscience, computation, andhardware offers an integrative agenda for in each of these fields.</description>
      <author>example@mail.com (Sohan Shankar, Yi Pan, Hanqi Jiang, Zhengliang Liu, Mohammad R. Darbandi, Agustin Lorenzo, Junhao Chen, Md Mehedi Hasan, Arif Hassan Zidan, Eliana Gelman, Joshua A. Konfrst, Jillian Y. Russell, Katelyn Fernandes, Tianze Yang, Yiwei Li, Huaqin Zhao, Afrar Jahin, Triparna Ganguly, Shair Dinesha, Yifan Zhou, Zihao Wu, Xinliang Li, Lokesh Adusumilli, Aziza Hussein, Sagar Nookarapu, Jixin Hou, Kun Jiang, Jiaxi Li, Brenden Heinel, XianShen Xi, Hailey Hubbard, Zayna Khan, Levi Whitaker, Ivan Cao, Max Allgaier, Andrew Darby, Lin Zhao, Lu Zhang, Xiaoqiao Wang, Xiang Li, Wei Zhang, Xiaowei Yu, Dajiang Zhu, Yohannes Abate, Tianming Liu)</author>
      <guid isPermaLink="false">2507.10722v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Machine-learning inference of stellar properties using integrated photometric and spectroscopic data</title>
      <link>http://arxiv.org/abs/2507.10666v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to ApJ&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DESA（双重嵌入模型），一个用于天体物理学的新颖的多模态基础模型，该模型整合了光变曲线和光谱数据，以学习统一的、具有物理意义的星体潜在空间。&lt;h4&gt;背景&lt;/h4&gt;天体物理学依赖于多种观测方法，如光变曲线和光谱数据，而机器学习在分析单个模态方面取得了进展，但跨模态之间的互补信息尚未充分利用。&lt;h4&gt;目的&lt;/h4&gt;提出DESA模型，旨在利用光变曲线和光谱数据，通过多模态融合来提高天体物理学的分析能力。&lt;h4&gt;方法&lt;/h4&gt;DESA首先使用混合监督/自监督方案训练单独的模态特定编码器，然后通过DualFormer模块进行跨模态集成。DualFormer结合了交叉和自注意力机制，一个新的双重投影对齐损失，以及投影空间特征分解，以产生物理结构的嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;DESA在各种任务上显著优于领先的单一模态和自监督基线。在零样本和少样本设置中，DESA的学习表示可以以高精度恢复星体的颜色-光度图和赫罗图。在完全微调的情况下，DESA在双星检测和恒星年龄预测方面达到了最先进的准确度。&lt;h4&gt;结论&lt;/h4&gt;DESA为多模态、数据驱动的星群分析提供了一个强大的新框架，既能够进行准确预测，也能实现新的发现，例如自然区分同步双星和年轻恒星，这两者在光变曲线上几乎相同，但通过嵌入UMAP空间的位置就可以区分开来。&lt;h4&gt;翻译&lt;/h4&gt;摘要：恒星天体物理学依赖于多种观测方法——主要是光变曲线和光谱数据——从中可以推断出基本恒星属性。虽然机器学习（ML）在分析单个模态方面取得了进展，但跨模态之间编码的互补信息在很大程度上仍未得到充分利用。我们提出了DESA（用于恒星天体物理学的双重嵌入模型），这是一种新颖的多模态基础模型，它整合了光变曲线和光谱数据，以学习统一的、具有物理意义的恒星潜在空间。DESA首先使用混合监督/自监督方案训练单独的模态特定编码器，然后通过DualFormer，一个针对天体数据定制的基于Transformer的跨模态集成模块，对它们进行对齐。DualFormer结合了交叉和自注意力机制，一种新的双重投影对齐损失，以及投影空间特征分解，从而产生具有物理结构的嵌入。我们证明了DESA在各种任务上显著优于领先的单一模态和自监督基线。在零样本和少样本设置中，DESA的学习表示可以以高精度恢复恒星的颜色-光度图和赫罗图（光度回归的R² = 0.92）。在完全微调的情况下，DESA在双星检测和恒星年龄预测方面达到了最先进的准确度（AUC = 0.99，AP = 1.00）和RMSE = 0.94 Gyr。作为一个令人信服的案例，DESA能够自然地根据其在UMAP空间中的嵌入位置区分同步双星和年轻恒星，这两个种群在光变曲线上几乎相同，无需外部运动学或亮度信息。因此，DESA为多模态、数据驱动的星群分析提供了一个强大的新框架，既能够进行准确预测，也能实现新的发现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stellar astrophysics relies on diverse observational modalities-primarilyphotometric light curves and spectroscopic data-from which fundamental stellarproperties are inferred. While machine learning (ML) has advanced analysiswithin individual modalities, the complementary information encoded acrossmodalities remains largely underexploited. We present DESA (Dual Embeddingmodel for Stellar Astrophysics), a novel multi-modal foundation model thatintegrates light curves and spectra to learn a unified, physically meaningfullatent space for stars. DESA first trains separate modality-specific encodersusing a hybrid supervised/self-supervised scheme, and then aligns them throughDualFormer, a transformer-based cross-modal integration module tailored forastrophysical data. DualFormer combines cross- and self-attention, a noveldual-projection alignment loss, and a projection-space eigendecomposition thatyields physically structured embeddings. We demonstrate that DESA significantlyoutperforms leading unimodal and self-supervised baselines across a range oftasks. In zero- and few-shot settings, DESA's learned representations recoverstellar color-magnitude and Hertzsprung-Russell diagrams with high fidelity($R^2 = 0.92$ for photometric regressions). In full fine-tuning, DESA achievesstate-of-the-art accuracy for binary star detection (AUC = $0.99$, AP = $1.00$)and stellar age prediction (RMSE = $0.94$ Gyr). As a compelling case, DESAnaturally separates synchronized binaries from young stars, two populationswith nearly identical light curves, purely from their embedded positions inUMAP space, without requiring external kinematic or luminosity information.DESA thus offers a powerful new framework for multimodal, data-driven stellarpopulation analysis, enabling both accurate prediction and novel discovery.</description>
      <author>example@mail.com (Ilay Kamai, Alex M. Bronstein, Hagai B. Perets)</author>
      <guid isPermaLink="false">2507.10666v1</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>RoboBrain 2.0 Technical Report</title>
      <link>http://arxiv.org/abs/2507.02029v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了RoboBrain 2.0，这是新一代的具身视觉-语言基础模型，旨在统一感知、推理和规划，以应对物理环境中的复杂具身任务。&lt;h4&gt;背景&lt;/h4&gt;RoboBrain 2.0包括两个版本：一个轻量级7B模型和一个全规模32B模型，具有异构架构，包括视觉编码器和语言模型。&lt;h4&gt;目的&lt;/h4&gt;通过RoboBrain 2.0实现空间理解（如可及性预测、空间指称、轨迹预测）和时序决策（如闭环交互、多智能体长期规划、场景图更新）等关键现实世界具身AI能力。&lt;h4&gt;方法&lt;/h4&gt;详细介绍了模型架构、数据构建、多阶段训练策略、基础设施和实际应用。&lt;h4&gt;主要发现&lt;/h4&gt;32B版本在空间和时序基准测试中取得了领先结果，超越了先前开源和专有模型。&lt;h4&gt;结论&lt;/h4&gt;RoboBrain 2.0有望推动具身AI研究，并为构建通用具身智能体提供一个实际步骤。&lt;h4&gt;翻译&lt;/h4&gt;We introduce RoboBrain 2.0, our latest generation of embodied vision-language foundation models, designed to unify perception, reasoning, and planning for complex embodied tasks in physical environments. It comes in two variants: a lightweight 7B model and a full-scale 32B model, featuring a heterogeneous architecture with a vision encoder and a language model. Despite its compact size, RoboBrain 2.0 achieves strong performance across a wide spectrum of embodied reasoning tasks. On both spatial and temporal benchmarks, the 32B variant achieves leading results, surpassing prior open-source and proprietary models. In particular, it supports key real-world embodied AI capabilities, including spatial understanding (e.g., affordance prediction, spatial referring, trajectory forecasting) and temporal decision-making (e.g., closed-loop interaction, multi-agent long-horizon planning, and scene graph updating). This report details the model architecture, data construction, multi-stage training strategies, infrastructure and practical applications. We hope RoboBrain 2.0 advances embodied AI research and serves as a practical step toward building generalist embodied agents. The code, checkpoint and benchmark are available at https://superrobobrain.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce RoboBrain 2.0, our latest generation of embodied vision-languagefoundation models, designed to unify perception, reasoning, and planning forcomplex embodied tasks in physical environments. It comes in two variants: alightweight 7B model and a full-scale 32B model, featuring a heterogeneousarchitecture with a vision encoder and a language model. Despite its compactsize, RoboBrain 2.0 achieves strong performance across a wide spectrum ofembodied reasoning tasks. On both spatial and temporal benchmarks, the 32Bvariant achieves leading results, surpassing prior open-source and proprietarymodels. In particular, it supports key real-world embodied AI capabilities,including spatial understanding (e.g., affordance prediction, spatialreferring, trajectory forecasting) and temporal decision-making (e.g.,closed-loop interaction, multi-agent long-horizon planning, and scene graphupdating). This report details the model architecture, data construction,multi-stage training strategies, infrastructure and practical applications. Wehope RoboBrain 2.0 advances embodied AI research and serves as a practical steptoward building generalist embodied agents. The code, checkpoint and benchmarkare available at https://superrobobrain.github.io.</description>
      <author>example@mail.com (BAAI RoboBrain Team, Mingyu Cao, Huajie Tan, Yuheng Ji, Minglan Lin, Zhiyu Li, Zhou Cao, Pengwei Wang, Enshen Zhou, Yi Han, Yingbo Tang, Xiangqi Xu, Wei Guo, Yaoxu Lyu, Yijie Xu, Jiayu Shi, Mengfei Du, Cheng Chi, Mengdi Zhao, Xiaoshuai Hao, Junkai Zhao, Xiaojie Zhang, Shanyu Rong, Huaihai Lyu, Zhengliang Cai, Yankai Fu, Ning Chen, Bolun Zhang, Lingfeng Zhang, Shuyi Zhang, Dong Liu, Xi Feng, Songjing Wang, Xiaodan Liu, Yance Jiao, Mengsi Lyu, Zhuo Chen, Chenrui He, Yulong Ao, Xue Sun, Zheqi He, Jingshu Zheng, Xi Yang, Donghai Shi, Kunchang Xie, Bochao Zhang, Shaokai Nie, Chunlei Men, Yonghua Lin, Zhongyuan Wang, Tiejun Huang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2507.02029v3</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Learning and Transferring Better with Depth Information in Visual Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2507.09180v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉Transformer的视觉骨干网络，用于融合RGB和深度模态信息，以增强泛化能力。&lt;h4&gt;背景&lt;/h4&gt;深度信息对场景外观变化具有鲁棒性，并且天然地包含3D空间细节。&lt;h4&gt;目的&lt;/h4&gt;提高样本效率，并实现从模拟到现实的学习迁移。&lt;h4&gt;方法&lt;/h4&gt;首先，不同的模态通过独立的CNN主干进行处理；然后，将结合的卷积特征输入到可扩展的视觉Transformer中获取视觉表示；此外，设计了一种对比无监督学习方案，使用掩码和无掩码标记来加速强化学习过程中的样本效率；最后，为了实现从模拟到现实的学习迁移，开发了一种灵活的课程学习计划，以在训练过程中部署领域随机化。&lt;h4&gt;主要发现&lt;/h4&gt;视觉Transformer在融合RGB和深度模态信息方面表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效提高样本效率，并实现从模拟到现实的有效迁移。&lt;h4&gt;翻译&lt;/h4&gt;Depth信息对场景外观变化具有鲁棒性，并且天然地包含3D空间细节。在本文中，提出了一种基于视觉Transformer的视觉骨干网络，用于融合RGB和深度模态信息，以增强泛化。首先，不同的模态通过独立的CNN主干进行处理，然后，将结合的卷积特征输入到可扩展的视觉Transformer中获取视觉表示。此外，设计了一种对比无监督学习方案，使用掩码和无掩码标记来加速强化学习过程中的样本效率。对于从模拟到现实的学习迁移，开发了一种灵活的课程学习计划，以在训练过程中部署领域随机化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth information is robust to scene appearance variations and inherentlycarries 3D spatial details. In this paper, a visual backbone based on thevision transformer is proposed to fuse RGB and depth modalities for enhancinggeneralization. Different modalities are first processed by separate CNN stems,and the combined convolutional features are delivered to the scalable visiontransformer to obtain visual representations. Moreover, a contrastiveunsupervised learning scheme is designed with masked and unmasked tokens toaccelerate the sample efficiency during the reinforcement learning progress.For sim2real transfer, a flexible curriculum learning schedule is developed todeploy domain randomization over training processes.</description>
      <author>example@mail.com (Zichun Xu, Yuntao Li, Zhaomin Wang, Lei Zhuang, Guocai Yang, Jingdong Zhao)</author>
      <guid isPermaLink="false">2507.09180v2</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning</title>
      <link>http://arxiv.org/abs/2507.08730v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICSE 2026&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;现代可配置软件系统需要学习配置和性能之间的关联模型。然而，在动态环境中，工作负载变化、硬件更改和系统更新将不可避免地在不同级别引入概念漂移——全局漂移，它重塑整个配置空间的性能景观；以及局部漂移，它仅影响该空间的部分子区域。因此，现有的离线和迁移学习方法难以适应这些实时发生的隐性和不可预测的变化，使得配置性能学习变得具有挑战性。&lt;h4&gt;背景&lt;/h4&gt;现代软件系统在动态环境中需要学习配置和性能之间的关联模型，但工作负载变化、硬件更改和系统更新会导致不同级别的概念漂移，使得现有的学习方法难以适应。&lt;h4&gt;目的&lt;/h4&gt;为了解决动态环境中配置性能学习的问题，提出了DHDA，一个在线配置性能学习框架，旨在捕获和适应不同级别的漂移。&lt;h4&gt;方法&lt;/h4&gt;DHDA通过双重分层适应机制来适应局部和全局漂移：在高级别，当需要时，将数据重新划分为不同的部分，在每个部分中重新训练局部模型以处理全局漂移；在低级别，部分局部模型可以检测局部漂移并异步地适应自己。为了平衡响应性和效率，DHDA结合增量更新和定期全面重新训练，以在未检测到漂移时最小化冗余计算。&lt;h4&gt;主要发现&lt;/h4&gt;通过评估八个软件系统和与最先进的方法相比，DHDA实现了显著更好的准确性，并且可以有效地适应漂移，改善局部模型处理概念漂移的能力，同时具有合理的开销。&lt;h4&gt;结论&lt;/h4&gt;DHDA是一个有效的在线配置性能学习框架，能够有效地适应动态环境中的概念漂移，提高了配置性能学习的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern configurable software systems need to learn models that correlateconfiguration and performance. However, when the system operates in dynamicenvironments, the workload variations, hardware changes, and system updateswill inevitably introduce concept drifts at different levels - global drifts,which reshape the performance landscape of the entire configuration space; andlocal drifts, which only affect certain sub-regions of that space. As such,existing offline and transfer learning approaches can struggle to adapt tothese implicit and unpredictable changes in real-time, rendering configurationperformance learning challenging. To address this, we propose DHDA, an onlineconfiguration performance learning framework designed to capture and adapt tothese drifts at different levels. The key idea is that DHDA adapts to both thelocal and global drifts using dually hierarchical adaptation: at the upperlevel, we redivide the data into different divisions, within each of which thelocal model is retrained, to handle global drifts only when necessary. At thelower level, the local models of the divisions can detect local drifts andadapt themselves asynchronously. To balance responsiveness and efficiency, DHDAcombines incremental updates with periodic full retraining to minimizeredundant computation when no drifts are detected. Through evaluating eightsoftware systems and against state-of-the-art approaches, we show that DHDAachieves considerably better accuracy and can effectively adapt to drifts withup to 2x improvements, while incurring reasonable overhead and is able toimprove different local models in handling concept drift.</description>
      <author>example@mail.com (Zezhen Xiang, Jingzhi Gong, Tao Chen)</author>
      <guid isPermaLink="false">2507.08730v3</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>(Almost) Free Modality Stitching of Foundation Models</title>
      <link>http://arxiv.org/abs/2507.10015v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Pre-print&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Hypernetwork Model Alignment (Hyma)，这是一种利用超网络进行最优单模态模型选择和连接器训练的新方法，以解决大规模网络数据集上训练连接器的复杂性和计算需求。&lt;h4&gt;背景&lt;/h4&gt;多模态模型的构建通常通过将多个预训练的单模态模型拼接而成，这一拼接过程需要训练连接器模块来对齐单模态模型的表现空间以达成多模态目标。然而，在庞大的网络数据集上训练这些连接器以及选择合适的单模态模型组合计算成本极高。&lt;h4&gt;目的&lt;/h4&gt;解决单模态模型选择和连接器模块训练的高计算需求问题。&lt;h4&gt;方法&lt;/h4&gt;提出Hyma，通过利用超网络的参数预测能力来获得适用于$N imes M$种单模态模型组合的联合训练连接器模块。&lt;h4&gt;主要发现&lt;/h4&gt;Hyma降低了搜索最佳性能的单模态模型对的成本10倍，并且通过多样化的多模态基准测试与网格搜索得到的排名和训练的连接器性能相匹配。&lt;h4&gt;结论&lt;/h4&gt;Hyma为优化单模态模型选择和连接器训练提供了一个有效的解决方案，显著减少了计算成本并提高了模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation multi-modal models are often designed by stitching of multipleexisting pretrained uni-modal models: for example, an image classifier with antext model. This stitching process is performed by training a connector modulethat aims to align the representation spaces of these uni-modal models towardsa multi-modal objective. However, given the complexity of training suchconnectors on large scale web-based datasets coupled with the ever-increasingnumber of available pretrained uni-modal models, the task of uni-modal modelsselection and subsequent connector module training becomes computationallydemanding. To address this under-studied critical problem, we proposeHypernetwork Model Alignment (Hyma), a novel all-in-one solution for optimaluni-modal model selection and connector training by leveraging hypernetworks.Specifically, our framework utilizes the parameter prediction capability of ahypernetwork to obtain jointly trained connector modules for $N \times M$combinations of uni-modal models. In our experiments, Hyma reduces the cost ofsearching for the best performing uni-modal model pair by $10\times$, whilematching the ranking and trained connector performance obtained via grid searchacross a suite of diverse multi-modal benchmarks.</description>
      <author>example@mail.com (Jaisidh Singh, Diganta Misra, Boris Knyazev, Antonio Orvieto)</author>
      <guid isPermaLink="false">2507.10015v2</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>What Demands Attention in Urban Street Scenes? From Scene Understanding towards Road Safety: A Survey of Vision-driven Datasets and Studies</title>
      <link>http://arxiv.org/abs/2507.06513v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  45 pages, 52 figures, 2 large tables (divided into 5), 73 datatsets,  35 tasks&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统地分类了交通场景中需要关注的要素，并全面分析了现有的基于视觉的任务和数据集，旨在促进基于视觉的传感器和计算机视觉算法在道路安全中的应用。&lt;h4&gt;背景&lt;/h4&gt;视觉传感器和计算机视觉算法在交通场景分析和理解方面取得了显著进步。&lt;h4&gt;目的&lt;/h4&gt;为了利用这些进步提高道路安全，系统地分类交通场景中的关键要素，并全面分析基于视觉的任务和数据集。&lt;h4&gt;方法&lt;/h4&gt;建立了两个主要类别，异常和正常但关键的交通实体，包含十个类别和二十个子类别。提出了一个统一的分析框架，并分析了35个基于视觉的任务和73个数据集。&lt;h4&gt;主要发现&lt;/h4&gt;对35个基于视觉的任务进行了分析，并对73个数据集进行了全面考察和可视化。跨领域调查涵盖了每个基准的优缺点，旨在提供标准化和资源优化的信息。&lt;h4&gt;结论&lt;/h4&gt;本文系统地讨论了现有弱点，强调了从不同角度的潜在影响和有希望解决方案。整合的分类法、全面分析和总结表为该快速发展领域提供了有价值的贡献，为研究人员提供了全面概述，指导战略资源选择，并突出了关键的研究差距。&lt;h4&gt;翻译&lt;/h4&gt;This paper systematically categorizes the critical elements that demand attention in traffic scenarios and comprehensively analyzes the available vision-driven tasks and datasets, aiming to promote the application of vision-based sensors and computer vision algorithms in road safety.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in vision-based sensors and computer vision algorithms havesignificantly improved the analysis and understanding of traffic scenarios. Tofacilitate the use of these improvements for road safety, this surveysystematically categorizes the critical elements that demand attention intraffic scenarios and comprehensively analyzes available vision-driven tasksand datasets. Compared to existing surveys that focus on isolated domains, ourtaxonomy categorizes attention-worthy traffic entities into two main groupsthat are anomalies and normal but critical entities, integrating ten categoriesand twenty subclasses. It establishes connections between inherently relatedfields and provides a unified analytical framework. Our survey highlights theanalysis of 35 vision-driven tasks and comprehensive examinations andvisualizations of 73 available datasets based on the proposed taxonomy. Thecross-domain investigation covers the pros and cons of each benchmark with theaim of providing information on standards unification and resourceoptimization. Our article concludes with a systematic discussion of theexisting weaknesses, underlining the potential effects and promising solutionsfrom various perspectives. The integrated taxonomy, comprehensive analysis, andrecapitulatory tables serve as valuable contributions to this rapidly evolvingfield by providing researchers with a holistic overview, guiding strategicresource selection, and highlighting critical research gaps.</description>
      <author>example@mail.com (Yaoqi Huang, Julie Stephany Berrio, Mao Shan, Stewart Worrall)</author>
      <guid isPermaLink="false">2507.06513v2</guid>
      <pubDate>Wed, 16 Jul 2025 14:20:57 +0800</pubDate>
    </item>
    <item>
      <title>Advancements in the IceAct Energy Spectrum Analysis</title>
      <link>http://arxiv.org/abs/2507.08779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 39th International Cosmic Ray Conference (ICRC2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了IceAct望远镜在IceCube中用于观测宇宙射线的进展。&lt;h4&gt;背景&lt;/h4&gt;IceAct望远镜是安装在地理南极的成像空气切伦科夫望远镜，作为IceCube中子观测站的一部分。&lt;h4&gt;目的&lt;/h4&gt;通过分析IceAct望远镜的数据，研究宇宙射线的能量谱。&lt;h4&gt;方法&lt;/h4&gt;使用61像素相机进行观测，并采用保守估计的10%的工作周期。运用图神经网络重建基本空气 shower特性，如几何和初级能量。&lt;h4&gt;主要发现&lt;/h4&gt;自2019年以来，两台望远镜已开始收集数据，用于分析宇宙射线的能量谱。&lt;h4&gt;结论&lt;/h4&gt;本文聚焦于利用IceAct数据在分析宇宙射线能量谱方面的当前进展。&lt;h4&gt;翻译&lt;/h4&gt;The IceAct telescopes are Imaging Air Cherenkov telescopes installed as partof the IceCube Neutrino Observatory at the geographic South Pole. They consistof a 61 pixel camera and are small and robust to withstand the harshenvironmental conditions. IceAct detects Cherenkov light produced by cosmic-rayparticles with energies above approximately 10 TeV interacting inside theatmosphere, which is complementary to the measurement of the air shower at thesurface by IceTop and the high-energy muons in the deep ice. Two telescopeshave been taking data since 2019 with a conservative estimated duty cycle ofaround 10%. A graph neural network is used to reconstruct the basic air showerproperties, like geometry and primary energy. This work focuses on the currentprogress in analyzing the energy spectrum of cosmic rays using IceAct data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The IceAct telescopes are Imaging Air Cherenkov telescopes installed as partof the IceCube Neutrino Observatory at the geographic South Pole. They consistof a 61 pixel camera and are small and robust to withstand the harshenvironmental conditions. IceAct detects Cherenkov light produced by cosmic-rayparticles with energies above approximately 10\,TeV interacting inside theatmosphere, which is complementary to the measurement of the air shower at thesurface by IceTop and the high-energy muons in the deep ice. Two telescopeshave been taking data since 2019 with a conservative estimated duty cycle ofaround 10\%. A graph neural network is used to reconstruct the basic air showerproperties, like geometry and primary energy. This work focuses on the currentprogress in analyzing the energy spectrum of cosmic rays using IceAct data.</description>
      <author>example@mail.com (Larissa Paul)</author>
      <guid isPermaLink="false">2507.08779v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
  <item>
      <title>Graph World Model</title>
      <link>http://arxiv.org/abs/2507.10539v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为图世界模型（GWM）的新型世界模型，能够处理非结构化和图结构化的状态，支持多模态信息，并将不同任务表示为动作。&lt;h4&gt;背景&lt;/h4&gt;现有的世界模型主要关注非结构化数据，无法利用数字世界中普遍存在的结构化数据（如图）。虽然已有多种图基础模型被提出，但它们主要关注图学习任务，无法扩展到多模态数据和跨学科任务。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种名为图世界模型（GWM）的新模型，旨在支持非结构化和图结构化的状态，并处理多模态信息。&lt;h4&gt;方法&lt;/h4&gt;GWM的核心是一个通用的消息传递算法，用于聚合结构化信息。该算法可以通过将多模态数据转换为文本（GWM-T）或通过模态特定的编码器（GWM-E）在统一的多模态嵌入空间中工作。GWM还引入了动作节点来支持不同任务，动作节点通过直接引用或相似度计算与其他节点相连。&lt;h4&gt;主要发现&lt;/h4&gt;在六个不同领域（包括多模态生成和匹配、推荐、图预测、多智能体、检索增强生成和规划与优化）的实验中，GWM在大多数情况下优于或匹配了特定领域的基线模型，并从多跳结构中受益。GWM还显示出在未见过的任务上的强大零样本/少样本能力。&lt;h4&gt;结论&lt;/h4&gt;GWM是一种有效处理多种任务的世界模型，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new type of world model called Graph World Model (GWM), which can handle both unstructured and graph-structured states, support multi-modal information, and represent various tasks as actions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; World models (WMs) demonstrate strong capabilities in prediction, generation,and planning tasks. Existing WMs primarily focus on unstructured data andcannot leverage the ubiquitous structured data, often represented as graphs, inthe digital world. While multiple graph foundation models have been proposed,they focus on graph learning tasks and cannot extend to diverse multi-modaldata and interdisciplinary tasks. To address these challenges, we propose theGraph World Model (GWM), a world model that supports both unstructured andgraph-structured states with multi-modal information and represents diversetasks as actions. The core of a GWM is a generic message-passing algorithm toaggregate structured information, either over a unified multi-modal token spaceby converting multi-modal data into text (GWM-T) or a unified multi-modalembedding space by modality-specific encoders (GWM-E). Notably, GWM introducesaction nodes to support diverse tasks, where action nodes are linked to othernodes via direct reference or similarity computation. Extensive experiments onsix tasks from diverse domains, including multi-modal generation and matching,recommendation, graph prediction, multi-agent, retrieval-augmented generation,and planning and optimization, show that the same GWM outperforms or matchesdomain-specific baselines' performance, benefits from multi-hop structures, anddemonstrates strong zero-shot/few-shot capabilities on unseen new tasks. Ourcode for GWM is released at https://github.com/ulab-uiuc/GWM.</description>
      <author>example@mail.com (Tao Feng, Yexin Wu, Guanyu Lin, Jiaxuan You)</author>
      <guid isPermaLink="false">2507.10539v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>EmbRACE-3K: Embodied Reasoning and Action in Complex Environments</title>
      <link>http://arxiv.org/abs/2507.10548v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://mxllc.github.io/EmbRACE-3K/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的视觉-语言模型（VLM）的评估数据集EmRACE-3K，用于评估VLM在实体环境中的推理能力。&lt;h4&gt;背景&lt;/h4&gt;现有的VLM在被动、离线图像和视频理解任务上表现出色，但在需要在线交互和主动场景理解的实体环境中表现有限。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，研究人员引入了EmRACE-3K数据集，用于评估VLM在探索、动态空间语义推理和多阶段目标执行三个关键维度上的实体推理能力。&lt;h4&gt;方法&lt;/h4&gt;EmRACE-3K包含3000多个在多样化、逼真的环境中进行的语言指导任务，这些环境使用Unreal Engine和UnrealCV-Zoo框架构建。每个任务都是多步骤轨迹，结合第一人称视觉观察、高级指令、基于动作的自然语言理由，以及每一步中代理的意图表达。&lt;h4&gt;主要发现&lt;/h4&gt;在零样本设置下，所有模型的成功率均低于20%，这突显了该基准的挑战性和VLM在交互式环境中当前的限制。&lt;h4&gt;结论&lt;/h4&gt;通过在EmRACE-3K上对Qwen2.5-VL-7B进行微调和强化学习，研究人员展示了数据集在使VLM发展实体推理能力方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent advanced vision-language models (VLMs) have demonstrated strong performance on passive, offline image and video understanding tasks. However, their effectiveness in embodied settings, which require online interaction and active scene understanding, remains limited. In such scenarios, an agent perceives the environment from a first-person perspective, with each action dynamically shaping subsequent observations. Even state-of-the-art models such as GPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro struggle in open-environment interactions, exhibiting clear limitations in spatial reasoning and long-horizon planning. To address this gap, we introduce EmRACE-3K, a dataset of over 3,000 language-guided tasks situated in diverse, photorealistic environments constructed using Unreal Engine and the UnrealCV-Zoo framework. The tasks encompass a wide range of embodied challenges, including navigation, object manipulation, and multi-stage goal execution. Each task unfolds as a multi-step trajectory, pairing first-person visual observations with high-level instructions, grounded actions, and natural language rationales that express the agent's intent at every step. Using EmRACE-3K, we establish a benchmark to evaluate the embodied reasoning capabilities of VLMs across three key dimensions: Exploration, Dynamic Spatial-Semantic Reasoning, and Multi-stage Goal Execution. In zero-shot settings, all models achieve success rates below 20%, underscoring the challenge posed by our benchmark and the current limitations of VLMs in interactive environments. To demonstrate the utility of EmRACE-3K, we further fine-tune Qwen2.5-VL-7B using supervised learning followed by reinforcement learning. This approach yields substantial improvements across all three challenge categories, highlighting the dataset's effectiveness in enabling the development of embodied reasoning capabilities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advanced vision-language models(VLMs) have demonstrated strongperformance on passive, offline image and video understanding tasks. However,their effectiveness in embodied settings, which require online interaction andactive scene understanding remains limited. In such scenarios, an agentperceives the environment from a first-person perspective, with each actiondynamically shaping subsequent observations. Even state-of-the-art models suchas GPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro struggle in open-environmentinteractions, exhibiting clear limitations in spatial reasoning andlong-horizon planning. To address this gap, we introduce EmRACE-3K, a datasetof over 3,000 language-guided tasks situated in diverse, photorealisticenvironments constructed using Unreal Engine and the UnrealCV-Zoo framework.The tasks encompass a wide range of embodied challenges, including navigation,object manipulation, and multi-stage goal execution. Each task unfolds as amulti-step trajectory, pairing first-person visual observations with high-levelinstructions, grounded actions, and natural language rationales that expressthe agent's intent at every step. Using EmRACE-3K, we establish a benchmark toevaluate the embodied reasoning capabilities of VLMs across three keydimensions: Exploration, Dynamic Spatial-Semantic Reasoning, and Multi-stageGoal Execution. In zero-shot settings, all models achieve success rates below20%, underscoring the challenge posed by our benchmark and the currentlimitations of VLMs in interactive environments. To demonstrate the utility ofEmRACE-3K, we further fine-tune Qwen2.5-VL-7B using supervised learningfollowed by reinforcement learning. This approach yields substantialimprovements across all three challenge categories, highlighting the dataset'seffectiveness in enabling the development of embodied reasoning capabilities.</description>
      <author>example@mail.com (Mingxian Lin, Wei Huang, Yitang Li, Chengjie Jiang, Kui Wu, Fangwei Zhong, Shengju Qian, Xin Wang, Xiaojuan Qi)</author>
      <guid isPermaLink="false">2507.10548v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>National level satellite-based crop field inventories in smallholder landscapes</title>
      <link>http://arxiv.org/abs/2507.10499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过高空间分辨率的地球观测数据和深度迁移学习，在国家级别对复杂农业系统中的农田进行了界定，同时保持最小参考数据需求并增强迁移性，为莫桑比克提供了首个包含2100万个单个农田的全国级数据集，推动了复杂小规模农户系统中大面积农田界定的技术水平。&lt;h4&gt;背景&lt;/h4&gt;改善小农户农业的可持续性受到对基本系统属性（如活动耕地的空间分布和农田规模）有限理解的影响。&lt;h4&gt;目的&lt;/h4&gt;利用高空间分辨率的地球观测数据和深度迁移学习，在国家级别界定复杂农业系统中的农田，同时减少参考数据需求并增强迁移性。&lt;h4&gt;方法&lt;/h4&gt;整合非常高的空间分辨率（1.5米）地球观测数据和深度迁移学习，推导农田界线，并为莫桑比克提供全国级数据集。&lt;h4&gt;主要发现&lt;/h4&gt;所提供的地图将活动耕地与非农业用地分离，整体准确率为93%，并平衡了遗漏和误报错误。农田级别空间一致性达到了中值交集与并集（IoU）分数0.81。这些农田地图捕捉到了尚未在全球土地覆盖或耕地地图中识别的碎片化农村地区，这些地区大多位于农业前沿地区，占莫桑比克人口的7-9%。莫桑比克的农田规模整体较小，一半的农田面积小于0.16公顷，83%的农田面积小于0.5公顷。在聚合空间分辨率（0.05度）下，平均农田规模为0.32公顷，但它在可及性、人口密度和净森林覆盖率变化梯度上差异很大。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，农田规模是关系到农业社会经济和环境影响的关键指标，包括粮食生产、生计、森林砍伐和生物多样性，以及它们的权衡。&lt;h4&gt;翻译&lt;/h4&gt;本研究通过整合高空间分辨率的地球观测数据和深度迁移学习，在国家尺度上对复杂农业系统中的农田进行界定，同时保持最小的参考数据需求，并提高迁移性。为莫桑比克提供了涵盖约800,000平方公里面积和2023年数据的2100万个单个农田的全国级数据集。我们的地图将活动耕地与非农业用地分离，整体准确率为93%，并且平衡了遗漏和误报错误。农田级别的空间一致性达到了中值交集与并集（IoU）分数0.81，推进了在复杂小农户系统中的大面积农田界定技术水平。这些农田地图捕捉到了在全球土地覆盖或耕地地图中尚未识别的碎片化农村地区。这些地区主要位于农业前沿地区，占莫桑比克人口的7-9%。莫桑比克的农田规模总体较小，一半的农田面积小于0.16公顷，83%的农田面积小于0.5公顷。在聚合空间分辨率（0.05度）下，平均农田规模为0.32公顷，但它在可及性、人口密度和净森林覆盖率变化梯度上差异很大。这种变化反映了从半自给自足的小农户农场到中规模商业农业以及大规模农业运营的各种参与者。研究结果强调了农田规模是关系到农业社会经济和环境影响的关键指标，包括粮食生产、生计、森林砍伐和生物多样性，以及它们的权衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The design of science-based policies to improve the sustainability ofsmallholder agriculture is challenged by a limited understanding of fundamentalsystem properties, such as the spatial distribution of active cropland andfield size. We integrate very high spatial resolution (1.5 m) Earth observationdata and deep transfer learning to derive crop field delineations in complexagricultural systems at the national scale, while maintaining minimum referencedata requirements and enhancing transferability. We provide the firstnational-level dataset of 21 million individual fields for Mozambique (covering~800,000 km2) for 2023. Our maps separate active cropland from non-agriculturalland use with an overall accuracy of 93% and balanced omission and commissionerrors. Field-level spatial agreement reached median intersection over union(IoU) scores of 0.81, advancing the state-of-the-art in large-area fielddelineation in complex smallholder systems. The active cropland maps capturefragmented rural regions with low cropland shares not yet identified in globalland cover or cropland maps. These regions are mostly located in agriculturalfrontier regions which host 7-9% of the Mozambican population. Field size inMozambique is very low overall, with half of the fields being smaller than 0.16ha, and 83% smaller than 0.5 ha. Mean field size at aggregate spatialresolution (0.05{\deg}) is 0.32 ha, but it varies strongly across gradients ofaccessibility, population density, and net forest cover change. This variationreflects a diverse set of actors, ranging from semi-subsistence smallholderfarms to medium-scale commercial farming, and large-scale farming operations.Our results highlight that field size is a key indicator relating tosocio-economic and environmental outcomes of agriculture (e.g., foodproduction, livelihoods, deforestation, biodiversity), as well as theirtrade-offs.</description>
      <author>example@mail.com (Philippe Rufin, Pauline Lucie Hammer, Leon-Friedrich Thomas, Sá Nogueira Lisboa, Natasha Ribeiro, Almeida Sitoe, Patrick Hostert, Patrick Meyfroidt)</author>
      <guid isPermaLink="false">2507.10499v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Beyond-mean-field fluctuations for the solution of constraint satisfaction problems</title>
      <link>http://arxiv.org/abs/2507.10360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了约束满足问题（CSPs），并探讨了其在复杂理论和多个领域的应用。通过将MAX-2-SAT问题映射到统计物理中的自旋玻璃系统，并使用Glauber动力学来寻找其基态，从而近似求解问题。研究结果表明，Glauber动力学在性能上优于传统的Hopfield网络方法，并能与最先进的求解器相媲美。&lt;h4&gt;背景&lt;/h4&gt;约束满足问题（CSPs）是复杂理论的核心，并在密码学、遗传学等多个领域有广泛应用。&lt;h4&gt;目的&lt;/h4&gt;通过将MAX-2-SAT问题映射到自旋玻璃系统，并使用Glauber动力学寻找其基态，以近似求解约束满足问题。&lt;h4&gt;方法&lt;/h4&gt;采用MAX-2-SAT问题到自旋玻璃系统的映射，并使用Glauber动力学来寻找基态。&lt;h4&gt;主要发现&lt;/h4&gt;Glauber动力学在性能上优于传统的Hopfield网络方法，并能与最先进的求解器相媲美。理论分析揭示了随机波动在寻找CSP解中的作用，即使在$T=0$时没有热波动，也有相当一部分自旋（对应于CSP变量）达到有效的自旋依赖非零温度。&lt;h4&gt;结论&lt;/h4&gt;本文提出的新确定性求解器能够有效考虑这种波动，从而达到最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：约束满足问题（CSPs）位于复杂理论的核心，并在从密码学到遗传学的众多重要任务中找到应用。经典方法使用Hopfield网络来寻找近似解，而最近，现代机器学习技术如图神经网络已开始流行于这项任务。在本研究中，我们采用已知的MAX-2-SAT，一类CSPs，到统计物理中的自旋玻璃系统的映射，并使用Glauber动力学来近似找到其基态，这对应于基本问题的最优解。我们表明，Glauber动力学优于传统的Hopfield网络方法，并能与最先进的求解器相竞争。系统的理论分析揭示了随机波动在寻找CSP解中的作用：即使在$T=0$时没有热波动，也有相当一部分自旋（对应于CSP变量）达到有效的自旋依赖非零温度。这些自旋形成一个子空间，其中随机Glauber动力学持续进行翻转，最终找到更好的解。这是可能的，因为能量是退化的，这样在这个自由自旋空间中的自旋翻转不需要能量。我们的理论分析导致新的确定性求解器，这些求解器能够有效地考虑这种波动，从而达到最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Constraint Satisfaction Problems (CSPs) lie at the heart of complexity theoryand find application in a plethora of prominent tasks ranging from cryptographyto genetics. Classical approaches use Hopfield networks to find approximatesolutions while recently, modern machine-learning techniques like graph neuralnetworks have become popular for this task. In this study, we employ the knownmapping of MAX-2-SAT, a class of CSPs, to a spin-glass system from statisticalphysics, and use Glauber dynamics to approximately find its ground state, whichcorresponds to the optimal solution of the underlying problem. We show thatGlauber dynamics outperforms the traditional Hopfield-network approach and cancompete with state-of-the-art solvers. A systematic theoretical analysisuncovers the role of stochastic fluctuations in finding CSP solutions: even inthe absense of thermal fluctuations at $T=0$ a significant portion of spins,which correspond to the CSP variables, attains an effective spin-dependentnon-zero temperature. These spins form a subspace in which the stochasticGlauber dynamics continuously performs flips to eventually find bettersolutions. This is possible since the energy is degenerate, such that spinflips in this free-spin space do not require energy. Our theoretical analysisleads to new deterministic solvers that effectively account for suchfluctuations, thereby reaching state-of-the-art performance.</description>
      <author>example@mail.com (Niklas Foos, Bastian Epping, Jannik Grundler, Alexandru Ciobanu, Ajainderpal Singh, Tim Bode, Moritz Helias, David Dahmen)</author>
      <guid isPermaLink="false">2507.10360v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>MP1: Mean Flow Tames Policy Learning in 1-step for Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2507.10543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MP1的机器人操作学习方法，该方法通过结合3D点云输入和MeanFlow范式，在单次网络函数评估（1-NFE）中生成动作轨迹，避免了额外的保持一致性约束，并提高了轨迹的可控性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;在机器人操作中，机器人学习成为了一种主流方法，但生成模型在此领域面临着扩散模型缓慢迭代采样和基于Flow的快速方法的架构约束之间的基本权衡。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出MP1方法，旨在在单次网络函数评估中生成动作轨迹，同时避免额外的保持一致性约束。&lt;h4&gt;方法&lt;/h4&gt;MP1方法通过直接学习间隔平均速度来避免任何额外的保持一致性约束，并使用CFG来提高轨迹的可控性。此外，引入了轻量级的Dispersive Loss，在训练过程中推开状态嵌入，以增强泛化能力而不减慢推理速度。&lt;h4&gt;主要发现&lt;/h4&gt;在Adroit和Meta-World基准测试以及真实世界场景中，MP1实现了优越的平均任务成功率，比DP3高出10.2%，比FlowPolicy高出7.3%。其平均推理时间仅为6.8 ms，比DP3快19倍，比FlowPolicy快近2倍。&lt;h4&gt;结论&lt;/h4&gt;MP1方法在保持快速推理的同时，提高了机器人操作学习的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;在机器人操作中，机器人学习已经成为一种主流方法。然而，这一领域的生成模型面临着扩散模型缓慢迭代采样和基于Flow的快速方法架构约束之间的基本权衡。为了解决这些局限性，我们引入了MP1，该方法将3D点云输入与MeanFlow范式配对，在单次网络函数评估（1-NFE）中生成动作轨迹。通过通过直接学习间隔平均速度，我们的策略避免了任何额外的保持一致性约束。这种公式消除了推理过程中的数值ODE求解器错误，从而产生了更精确的轨迹。MP1还通过保留1-NFE推理而不重新引入结构约束，进一步采用了CFG来提高轨迹的可控性。由于场景上下文的变化对机器人学习至关重要，特别是在少样本学习的情况下，我们在训练过程中引入了轻量级的Dispersive Loss，以在增强泛化能力的同时不减缓推理速度。我们在Adroit和Meta-World基准以及现实世界场景中验证了我们的方法。实验结果表明，MP1实现了优越的平均任务成功率，比DP3高出10.2%，比FlowPolicy高出7.3%。其平均推理时间仅为6.8 ms，比DP3快19倍，比FlowPolicy快近2倍。我们的代码可在https://mp1-2254.github.io/找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In robot manipulation, robot learning has become a prevailing approach.However, generative models within this field face a fundamental trade-offbetween the slow, iterative sampling of diffusion models and the architecturalconstraints of faster Flow-based methods, which often rely on explicitconsistency losses. To address these limitations, we introduce MP1, which pairs3D point-cloud inputs with the MeanFlow paradigm to generate actiontrajectories in one network function evaluation (1-NFE). By directly learningthe interval-averaged velocity via the MeanFlow Identity, our policy avoids anyadditional consistency constraints. This formulation eliminates numericalODE-solver errors during inference, yielding more precise trajectories. MP1further incorporates CFG for improved trajectory controllability whileretaining 1-NFE inference without reintroducing structural constraints. Becausesubtle scene-context variations are critical for robot learning, especially infew-shot learning, we introduce a lightweight Dispersive Loss that repels stateembeddings during training, boosting generalization without slowing inference.We validate our method on the Adroit and Meta-World benchmarks, as well as inreal-world scenarios. Experimental results show MP1 achieves superior averagetask success rates, outperforming DP3 by 10.2% and FlowPolicy by 7.3%. Itsaverage inference time is only 6.8 ms-19x faster than DP3 and nearly 2x fasterthan FlowPolicy. Our code is available at https://mp1-2254.github.io/.</description>
      <author>example@mail.com (Juyi Sheng, Ziyi Wang, Peiming Li, Mengyuan Liu)</author>
      <guid isPermaLink="false">2507.10543v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Multi-Person Motion Prediction by Lightweight Spatial and Temporal Interactions</title>
      <link>http://arxiv.org/abs/2507.09446v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种计算效率高的多人动作预测模型，通过简化空间和时间交互来降低计算成本。&lt;h4&gt;背景&lt;/h4&gt;多人动作预测任务复杂，依赖于个体过去动作和代理之间的交互，且有效建模这些交互通常伴随着高昂的计算成本。&lt;h4&gt;目的&lt;/h4&gt;开发一个高效的多人动作预测模型。&lt;h4&gt;方法&lt;/h4&gt;设计轻量级双重分支来学习个体和多个人物的局部和全局表示。引入新型跨级别交互块来整合来自两个分支的空间和时间表示。通过引入空间人际距离嵌入来增强交互建模。&lt;h4&gt;主要发现&lt;/h4&gt;在CMU-Mocap、MuPoTS-3D和3DPW的标准数据集上，该方法在多个指标上取得了最先进的性能，同时显著降低了计算成本。&lt;h4&gt;结论&lt;/h4&gt;模型在多个数据集上表现出色，同时实现了高效的计算。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D多人动作预测是一个高度复杂的任务，主要由于依赖于个体过去的动作和代理之间的交互。此外，有效地建模这些交互通常会带来高昂的计算成本。在本研究中，我们通过简化空间和时间交互，提出了一种计算效率高的多人动作预测模型。我们的方法从设计轻量级双重分支开始，这些分支分别学习个体和多个人物的局部和全局表示。此外，我们引入了一种新颖的跨级别交互块，以整合来自两个分支的空间和时间表示。为了进一步增强交互建模，我们明确地结合了空间人际距离嵌入。通过上述高效的时空设计，我们在CMU-Mocap、MuPoTS-3D和3DPW的标准数据集上，在多个指标上实现了最先进的性能，同时显著降低了计算成本。代码可在https://github.com/Yuanhong-Zheng/EMPMP上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D multi-person motion prediction is a highly complex task, primarily due tothe dependencies on both individual past movements and the interactions betweenagents. Moreover, effectively modeling these interactions often incurssubstantial computational costs. In this work, we propose a computationallyefficient model for multi-person motion prediction by simplifying spatial andtemporal interactions. Our approach begins with the design of lightweight dualbranches that learn local and global representations for individual andmultiple persons separately. Additionally, we introduce a novel cross-levelinteraction block to integrate the spatial and temporal representations fromboth branches. To further enhance interaction modeling, we explicitlyincorporate the spatial inter-person distance embedding. With above efficienttemporal and spatial design, we achieve state-of-the-art performance formultiple metrics on standard datasets of CMU-Mocap, MuPoTS-3D, and 3DPW, whilesignificantly reducing the computational cost. Code is available athttps://github.com/Yuanhong-Zheng/EMPMP.</description>
      <author>example@mail.com (Yuanhong Zheng, Ruixuan Yu, Jian Sun)</author>
      <guid isPermaLink="false">2507.09446v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>GT-Loc: Unifying When and Where in Images Through a Joint Embedding Space</title>
      <link>http://arxiv.org/abs/2507.10473v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in ICCV2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉信息的时间戳预测方法，该方法名为GT-Loc，可以联合预测图像的拍摄时间和地理位置。该方法使用单独的编码器处理图像、时间和位置，并在共享的高维特征空间中对齐它们的嵌入。通过建模时间差异，提出了一种新的时间度量学习目标，并展示了其在时间预测和地理位置预测任务中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;时间戳预测对于图像的元数据校正、检索和数字取证等应用具有重要意义。在户外场景中，时间估计依赖于亮度、色调和阴影位置等视觉线索，而季节变化和天气则用于日期估计。&lt;h4&gt;目的&lt;/h4&gt;为了解决视觉线索与地理环境的紧密联系，本文旨在提出一种同时预测图像拍摄时间和地理位置的方法。&lt;h4&gt;方法&lt;/h4&gt;GT-Loc方法使用独立的编码器处理图像、时间和位置，并在共享的高维特征空间中对齐它们的嵌入。此外，本文提出了一种新的时间度量学习目标，通过建模时间差异在循环圆盘面上提供软目标。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GT-Loc在时间预测任务中优于现有的方法，即使在推理时使用真实地理位置作为输入。此外，该方法在标准地理位置预测任务中也取得了具有竞争力的结果。&lt;h4&gt;结论&lt;/h4&gt;GT-Loc方法在时间预测和地理位置预测任务中均表现出优越的性能，并促进了基于组合和文本的图像检索。&lt;h4&gt;翻译&lt;/h4&gt;时间戳预测旨在仅使用视觉信息来确定图像的拍摄时间，支持元数据校正、检索和数字取证等应用。在户外场景中，小时估计依赖于亮度、色调和阴影位置等线索，而季节变化和天气用于日期估计。然而，这些视觉线索显著依赖于地理环境，将时间戳预测与地理定位紧密联系起来。为了解决这种相互依赖性，我们引入了GT-Loc，一种基于检索的新方法，可以联合预测图像的拍摄时间（小时和月份）和地理位置（GPS坐标）。我们的方法使用单独的编码器处理图像、时间和位置，并将它们的嵌入对齐到共享的高维特征空间中。认识到时间的周期性，我们提出了一个时间度量学习目标，通过在循环圆盘面上建模成对的时间差异来提供软目标。我们提出了新的基准，表明我们的联合优化超过了以前的时间预测方法，甚至那些在推理时使用真实地理位置作为输入的方法。此外，我们的方法在标准地理位置预测任务中也取得了具有竞争力的结果，并且统一的嵌入空间促进了基于组合和文本的图像检索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Timestamp prediction aims to determine when an image was captured using onlyvisual information, supporting applications such as metadata correction,retrieval, and digital forensics. In outdoor scenarios, hourly estimates relyon cues like brightness, hue, and shadow positioning, while seasonal changesand weather inform date estimation. However, these visual cues significantlydepend on geographic context, closely linking timestamp prediction togeo-localization. To address this interdependence, we introduce GT-Loc, a novelretrieval-based method that jointly predicts the capture time (hour and month)and geo-location (GPS coordinates) of an image. Our approach employs separateencoders for images, time, and location, aligning their embeddings within ashared high-dimensional feature space. Recognizing the cyclical nature of time,instead of conventional contrastive learning with hard positives and negatives,we propose a temporal metric-learning objective providing soft targets bymodeling pairwise time differences over a cyclical toroidal surface. We presentnew benchmarks demonstrating that our joint optimization surpasses previoustime prediction methods, even those using the ground-truth geo-location as aninput during inference. Additionally, our approach achieves competitive resultson standard geo-localization tasks, and the unified embedding space facilitatescompositional and text-based image retrieval.</description>
      <author>example@mail.com (David G. Shatwell, Ishan Rajendrakumar Dave, Sirnam Swetha, Mubarak Shah)</author>
      <guid isPermaLink="false">2507.10473v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>CLA: Latent Alignment for Online Continual Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2507.10434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CoLLAs 2025 conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为Continual Latent Alignment（CLA）的新型自监督学习策略，用于在线持续学习（Online CL）场景，该策略能够通过将当前模型学习到的表示与过去表示对齐来减轻遗忘问题。&lt;h4&gt;背景&lt;/h4&gt;当前自监督学习方法在在线持续学习场景中应用有限，因为数据以小批量形式到来，模型必须遵守固定的计算预算，且没有任务边界。&lt;h4&gt;目的&lt;/h4&gt;提出CLA策略的目的是为了提高在线持续学习场景下的模型性能，减少遗忘问题。&lt;h4&gt;方法&lt;/h4&gt;CLA策略通过将当前模型学习到的表示与过去表示对齐，以实现持续学习。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，CLA策略能够加速在线场景下的训练过程收敛速度，在相同的计算预算下优于现有方法。此外，将CLA作为预训练协议的早期阶段，相比于完全独立同分布（i.i.d.）预训练，最终性能更好。&lt;h4&gt;结论&lt;/h4&gt;CLA策略在在线持续学习场景中表现优异，能够有效提高模型性能并减少遗忘问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) is able to build latent representations thatgeneralize well to unseen data. However, only a few SSL techniques exist forthe online CL setting, where data arrives in small minibatches, the model mustcomply with a fixed computational budget, and task boundaries are absent. Weintroduce Continual Latent Alignment (CLA), a novel SSL strategy for Online CLthat aligns the representations learned by the current model with pastrepresentations to mitigate forgetting. We found that our CLA is able to speedup the convergence of the training process in the online scenario,outperforming state-of-the-art approaches under the same computational budget.Surprisingly, we also discovered that using CLA as a pretraining protocol inthe early stages of pretraining leads to a better final performance whencompared to a full i.i.d. pretraining.</description>
      <author>example@mail.com (Giacomo Cignoni, Andrea Cossu, Alexandra Gomez-Villa, Joost van de Weijer, Antonio Carta)</author>
      <guid isPermaLink="false">2507.10434v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Chat with AI: The Surprising Turn of Real-time Video Communication from Human to AI</title>
      <link>http://arxiv.org/abs/2507.10510v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Artic的AI实时通信框架，旨在解决AI视频聊天中的延迟问题，并提高交互的直观性。&lt;h4&gt;背景&lt;/h4&gt;AI视频聊天是一种新的实时通信范式，其中一方是AI的多模态大型语言模型（MLLM），这使得人类与AI的交互更加直观，但同时也带来了延迟的挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决延迟问题，本文旨在探索网络需求从“人类观看视频”到“AI理解视频”的转变。&lt;h4&gt;方法&lt;/h4&gt;本文提出了以下方法：1. 上下文感知视频流，以降低比特率同时保持MLLM的准确性；2. 损失鲁棒的自适应帧率，利用先前帧替代丢失或延迟的帧；3. 构建了首个名为DeViBench的降级视频理解基准。&lt;h4&gt;主要发现&lt;/h4&gt;通过上述方法，本文提出了一种降低比特率的同时保持MLLM准确性的上下文感知视频流，以及一种避免比特率浪费的自适应帧率。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和基准有助于提高AI视频聊天的质量和交互的直观性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为Artic的AI实时通信框架，旨在解决AI视频聊天中的延迟问题，并提高交互的直观性。背景是AI视频聊天是一种新的实时通信范式，其中一方是AI的多模态大型语言模型（MLLM），这使得人类与AI的交互更加直观，但同时也带来了延迟的挑战。为了解决延迟问题，本文旨在探索网络需求从“人类观看视频”到“AI理解视频”的转变。本文提出了以下方法：1. 上下文感知视频流，以降低比特率同时保持MLLM的准确性；2. 损失鲁棒的自适应帧率，利用先前帧替代丢失或延迟的帧；3. 构建了首个名为DeViBench的降级视频理解基准。通过上述方法，本文提出了一种降低比特率的同时保持MLLM准确性的上下文感知视频流，以及一种避免比特率浪费的自适应帧率。本文提出的方法和基准有助于提高AI视频聊天的质量和交互的直观性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AI Video Chat emerges as a new paradigm for Real-time Communication (RTC),where one peer is not a human, but a Multimodal Large Language Model (MLLM).This makes interaction between humans and AI more intuitive, as if chattingface-to-face with a real person. However, this poses significant challenges tolatency, because the MLLM inference takes up most of the response time, leavingvery little time for video streaming. Due to network uncertainty andinstability, transmission latency becomes a critical bottleneck preventing AIfrom being like a real person. To address this, we propose Artic, anAI-oriented Real-time Communication framework, exploring the networkrequirement shift from "humans watching video" to "AI understanding video". Toreduce bitrate dramatically while maintaining MLLM accuracy, we proposeContext-Aware Video Streaming that recognizes the importance of each videoregion for chat and allocates bitrate almost exclusively to chat-importantregions. To avoid packet retransmission, we propose Loss-Resilient AdaptiveFrame Rate that leverages previous frames to substitute for lost/delayed frameswhile avoiding bitrate waste. To evaluate the impact of video streaming qualityon MLLM accuracy, we build the first benchmark, named Degraded VideoUnderstanding Benchmark (DeViBench). Finally, we discuss some open questionsand ongoing solutions for AI Video Chat.</description>
      <author>example@mail.com (Jiangkai Wu, Zhiyuan Ren, Liming Liu, Xinggong Zhang)</author>
      <guid isPermaLink="false">2507.10510v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Test-Time Canonicalization by Foundation Models for Robust Perception</title>
      <link>http://arxiv.org/abs/2507.10375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FOCAL是一个基于数据驱动的实时框架，通过利用基础模型中的互联网规模视觉先验，实现了对多样化变换的不变性，从而增强了感知的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的视觉感知方法依赖于特定的架构或预定义的增强训练，这限制了它们的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出FOCAL框架，以在不重新训练或改变架构的情况下提高感知的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;FOCAL通过生成和优化候选变换，使图像达到视觉上典型的“规范”视图，从而增强了鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，FOCAL在包括2D/3D旋转、光照变化（对比度和颜色）以及昼夜变化在内的挑战性变换中，提高了CLIP和SAM的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;FOCAL挑战了特定变换训练必要的假设，提供了一个通向不变性的可扩展路径，并具有在主动视觉中的潜在应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现实世界的视觉感知需要对各种变换保持不变性，然而，当前的方法严重依赖于特定的架构或预定义的增强训练，这限制了泛化能力。我们提出FOCAL，一个基于数据的实时框架，通过利用基础模型中的互联网规模视觉先验，实现了鲁棒的感知。通过生成和优化候选变换以趋向视觉上典型的‘规范’视图，FOCAL增强了鲁棒性，而无需重新训练或架构变更。我们的实验表明，在包括2D/3D旋转、光照变化（对比度和颜色）和昼夜变化在内的挑战性变换中，FOCAL提高了CLIP和SAM的鲁棒性。我们还强调了在主动视觉中的潜在应用。我们的方法挑战了特定变换训练必要的假设，提供了一条通向不变性的可扩展路径。我们的代码可在以下链接找到：https://github.com/sutkarsh/focal。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world visual perception requires invariance to diverse transformations,yet current methods rely heavily on specialized architectures or training onpredefined augmentations, limiting generalization. We propose FOCAL, atest-time, data-driven framework that achieves robust perception by leveraginginternet-scale visual priors from foundation models. By generating andoptimizing candidate transformations toward visually typical, "canonical"views, FOCAL enhances robustness without re-training or architectural changes.Our experiments demonstrate improved robustness of CLIP and SAM acrosschallenging transformations, including 2D/3D rotations, illumination shifts(contrast and color), and day-night variations. We also highlight potentialapplications in active vision. Our approach challenges the assumption thattransform-specific training is necessary, instead offering a scalable path toinvariance. Our code is available at: https://github.com/sutkarsh/focal.</description>
      <author>example@mail.com (Utkarsh Singhal, Ryan Feng, Stella X. Yu, Atul Prakash)</author>
      <guid isPermaLink="false">2507.10375v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Polaritonic Machine Learning for Graph-based Data Analysis</title>
      <link>http://arxiv.org/abs/2507.10415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  v1, to be updated&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于极化子系统的机器学习方法，用于解决基于图的数据问题，并展示了其在特征工程和模式识别方面的优势。&lt;h4&gt;背景&lt;/h4&gt;光子系统和极化子系统为基于物理的计算加速机器学习提供了快速有效的平台。&lt;h4&gt;目的&lt;/h4&gt;为了获得计算优势，极化子系统需要利用非线性光学处理的特点，解决计算难题，并将光子处理集成到更广泛的机器学习流程中。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于极化子的机器学习算法，用于处理点云数据集中的关系和拓扑信息，并将其整合到基于卷积神经网络（CNN）的模式识别流程中。&lt;h4&gt;主要发现&lt;/h4&gt;该算法在贝蒂数分类和团检测任务中实现了超过90%的准确率，显著优于纯CNN的35%准确率。&lt;h4&gt;结论&lt;/h4&gt;这项研究引入了一种使用光子系统作为快速特征工程工具的独特方法，同时构建在高效数字机器学习之上。&lt;h4&gt;翻译&lt;/h4&gt;摘要：光子系统和极化子系统为通过基于物理的计算加速机器学习提供了一个快速有效的平台。然而，为了获得计算优势，极化子系统必须：（1）利用特别有利于非线性光学处理的特点；（2）解决与这些特点相关的计算难题；（3）将光子处理集成到更广泛的机器学习流程中。在这封信中，我们提出了一种用于解决基于图的数据问题的极化子机器学习方法。我们展示了凝聚态晶格如何有效地嵌入点云数据集的关系和拓扑信息。然后，将这些信息整合到一个基于卷积神经网络（CNN）的模式识别工作流程中，与物理无关的方法相比，显著提高了学习性能。我们的广泛基准测试表明，光子机器学习在贝蒂数分类和团检测任务中实现了超过90%的准确率——这比纯CNN的35%准确率有显著提高。我们的研究引入了一种使用光子系统作为快速特征工程工具的独特方法，同时构建在高效数字机器学习之上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Photonic and polaritonic systems offer a fast and efficient platform foraccelerating machine learning (ML) through physics-based computing. To gain acomputational advantage, however, polaritonic systems must: (1) exploitfeatures that specifically favor nonlinear optical processing; (2) addressproblems that are computationally hard and depend on these features; (3)integrate photonic processing within broader ML pipelines. In this letter, wepropose a polaritonic machine learning approach for solving graph-based dataproblems. We demonstrate how lattices of condensates can efficiently embedrelational and topological information from point cloud datasets. Thisinformation is then incorporated into a pattern recognition workflow based onconvolutional neural networks (CNNs), leading to significantly improvedlearning performance compared to physics-agnostic methods. Our extensivebenchmarking shows that photonic machine learning achieves over 90\% accuracyfor Betti number classification and clique detection tasks - a substantialimprovement over the 35\% accuracy of bare CNNs. Our study introduces adistinct way of using photonic systems as fast tools for feature engineering,while building on top of high-performing digital machine learning.</description>
      <author>example@mail.com (Yuan Wang, Stefano Scali, Oleksandr Kyriienko)</author>
      <guid isPermaLink="false">2507.10415v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Average Sensitivity of Hierarchical $k$-Median Clustering</title>
      <link>http://arxiv.org/abs/2507.10296v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了层次聚类在处理大数据集时的敏感性问题，并提出了一种高效的层次k中值聚类算法，验证了其鲁棒性和有效性。&lt;h4&gt;背景&lt;/h4&gt;层次聚类在无监督学习中应用广泛，但在处理现代算法中的大数据集时，对数据集的小扰动敏感，影响了算法的可用性。&lt;h4&gt;目的&lt;/h4&gt;研究层次k中值聚类问题，提高聚类算法的鲁棒性和聚类质量。&lt;h4&gt;方法&lt;/h4&gt;通过测量随机删除数据点时输出期望的变化来分析算法的平均敏感性，并提出了一个高效的层次k中值聚类算法。&lt;h4&gt;主要发现&lt;/h4&gt;层次k中值聚类算法具有低平均敏感性和高聚类质量，而单链接聚类和CLNSS算法的确定性变体表现出高平均敏感性，稳定性较差。&lt;h4&gt;结论&lt;/h4&gt;提出的算法在实验中验证了其鲁棒性和有效性，适用于处理大数据集。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了层次聚类在处理大数据集时的敏感性问题，并提出了一种高效的层次k中值聚类算法，验证了其鲁棒性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hierarchical clustering is a widely used method for unsupervised learningwith numerous applications. However, in the application of modern algorithms,the datasets studied are usually large and dynamic. If the hierarchicalclustering is sensitive to small perturbations of the dataset, the usability ofthe algorithm will be greatly reduced. In this paper, we focus on thehierarchical $k$ -median clustering problem, which bridges hierarchical andcentroid-based clustering while offering theoretical appeal, practical utility,and improved interpretability. We analyze the average sensitivity of algorithmsfor this problem by measuring the expected change in the output when a randomdata point is deleted. We propose an efficient algorithm for hierarchical$k$-median clustering and theoretically prove its low average sensitivity andhigh clustering quality. Additionally, we show that single linkage clusteringand a deterministic variant of the CLNSS algorithm exhibit high averagesensitivity, making them less stable. Finally, we validate the robustness andeffectiveness of our algorithm through experiments.</description>
      <author>example@mail.com (Shijie Li, Weiqiang He, Ruobing Bai, Pan Peng)</author>
      <guid isPermaLink="false">2507.10296v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs</title>
      <link>http://arxiv.org/abs/2507.10183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to MLoG-GenAI Workshop @ KDD 2025 (Oral)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;动态图学习方法在建模随时间演化的关系数据方面显示出强大的潜力。然而，当前时间图神经网络（TGNNs）是否有效捕捉核心时间模式（如周期性、因果关系和长距离依赖）尚不清楚。&lt;h4&gt;背景&lt;/h4&gt;尽管进行了广泛的基准测试，但当前时间图神经网络（TGNNs）是否能够有效捕捉核心时间模式（如周期性、因果关系和长距离依赖）仍然是一个未解决的问题。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过提出时间图推理基准（T-GRAB），一个旨在系统地检测TGNNs推理时间能力的综合合成任务集，来评估TGNNs的这种能力。&lt;h4&gt;方法&lt;/h4&gt;T-GRAB提供了一系列受控的、可解释的任务，以隔离关键的时间技能：计数/记忆周期性重复、推断延迟因果关系以及捕捉空间和时间维度上的长距离依赖。研究评估了11种时间图学习方法在这些任务上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，当前模型在泛化时间模式方面存在基本缺陷，提供了关于当前模型局限性的有操作性的见解，并突出了传统真实世界基准所掩盖的挑战。&lt;h4&gt;结论&lt;/h4&gt;研究结果推动了具有更强时间推理能力的架构的发展，并提供了关于当前模型局限性和时间推理挑战的深刻理解。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Dynamic graph learning methods have recently emerged as powerful tools for modelling relational data evolving through time. However, despite extensive benchmarking efforts, it remains unclear whether current Temporal Graph Neural Networks (TGNNs) effectively capture core temporal patterns such as periodicity, cause-and-effect, and long-range dependencies. In this work, we introduce the Temporal Graph Reasoning Benchmark (T-GRAB), a comprehensive set of synthetic tasks designed to systematically probe the capabilities of TGNNs to reason across time. T-GRAB provides controlled, interpretable tasks that isolate key temporal skills: counting/memorizing periodic repetitions, inferring delayed causal effects, and capturing long-range dependencies over both spatial and temporal dimensions. We evaluate 11 temporal graph learning methods on these tasks, revealing fundamental shortcomings in their ability to generalize temporal patterns. Our findings offer actionable insights into the limitations of current models, highlight challenges hidden by traditional real-world benchmarks, and motivate the development of architectures with stronger temporal reasoning abilities. The code for T-GRAB can be found at: https://github.com/alirezadizaji/T-GRAB.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic graph learning methods have recently emerged as powerful tools formodelling relational data evolving through time. However, despite extensivebenchmarking efforts, it remains unclear whether current Temporal Graph NeuralNetworks (TGNNs) effectively capture core temporal patterns such asperiodicity, cause-and-effect, and long-range dependencies. In this work, weintroduce the Temporal Graph Reasoning Benchmark (T-GRAB), a comprehensive setof synthetic tasks designed to systematically probe the capabilities of TGNNsto reason across time. T-GRAB provides controlled, interpretable tasks thatisolate key temporal skills: counting/memorizing periodic repetitions,inferring delayed causal effects, and capturing long-range dependencies overboth spatial and temporal dimensions. We evaluate 11 temporal graph learningmethods on these tasks, revealing fundamental shortcomings in their ability togeneralize temporal patterns. Our findings offer actionable insights into thelimitations of current models, highlight challenges hidden by traditionalreal-world benchmarks, and motivate the development of architectures withstronger temporal reasoning abilities. The code for T-GRAB can be found at:https://github.com/alirezadizaji/T-GRAB.</description>
      <author>example@mail.com (Alireza Dizaji, Benedict Aaron Tjandra, Mehrab Hamidi, Shenyang Huang, Guillaume Rabusseau)</author>
      <guid isPermaLink="false">2507.10183v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>VRU-Accident: A Vision-Language Benchmark for Video Question Answering and Dense Captioning for Accident Scene Understanding</title>
      <link>http://arxiv.org/abs/2507.09815v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 11 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了VRU-Accident，一个用于评估多模态大型语言模型在涉及易受伤害道路使用者（VRU）的复杂、高风险交通场景中推理能力的视觉语言基准。&lt;h4&gt;背景&lt;/h4&gt;确保易受伤害道路使用者（如行人和骑自行车的人）的安全是自动驾驶系统的一个关键挑战，因为涉及VRU的事故往往导致严重或致命后果。&lt;h4&gt;目的&lt;/h4&gt;为了填补现有标准的空白，论文提出了VRU-Accident，一个大规模视觉语言基准，用于评估多模态大型语言模型在涉及VRU的高风险交通场景中的推理能力。&lt;h4&gt;方法&lt;/h4&gt;VRU-Accident包括1K个真实世界的行车记录仪事故视频，这些视频被标注了6K个多选题问答题对，涵盖了六个安全关键类别（共有24K个候选选项和3.4K个独特答案选项），以及1K个密集场景描述。此外，对17个最先进的模型进行了全面评估，包括多项选择题问答任务和密集字幕任务。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，尽管MLLM在视觉基础属性方面表现良好，但在推理事故原因、类型和可预防性方面面临重大挑战。&lt;h4&gt;结论&lt;/h4&gt;VRU-Accident基准为评估MLLM在涉及VRU的复杂场景中的推理能力提供了一个新的标准，并揭示了当前MLLM在处理这类任务时的局限性。&lt;h4&gt;翻译&lt;/h4&gt;Ensuring the safety of vulnerable road users (VRUs), such as pedestrians and cyclists, is a critical challenge for autonomous driving systems, as crashes involving VRUs often result in severe or fatal consequences. While multimodal large language models (MLLMs) have shown promise in enhancing scene understanding and decision making in autonomous vehicles, there is currently no standardized benchmark to quantitatively evaluate their reasoning abilities in complex, safety-critical scenarios involving VRUs. To address this gap, we present VRU-Accident, a large-scale vision-language benchmark designed to evaluate MLLMs in high-risk traffic scenarios involving VRUs. VRU-Accident comprises 1K real-world dashcam accident videos, annotated with 6K multiple-choice question-answer pairs across six safety-critical categories (with 24K candidate options and 3.4K unique answer choices), as well as 1K dense scene descriptions. Unlike prior works, our benchmark focuses explicitly on VRU-vehicle accidents, providing rich, fine-grained annotations that capture both spatial-temporal dynamics and causal semantics of accidents. To assess the current landscape of MLLMs, we conduct a comprehensive evaluation of 17 state-of-the-art models on the multiple-choice VQA task and on the dense captioning task. Our findings reveal that while MLLMs perform reasonably well on visually grounded attributes, they face significant challenges in reasoning and describing accident causes, types, and preventability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety of vulnerable road users (VRUs), such as pedestrians andcyclists, is a critical challenge for autonomous driving systems, as crashesinvolving VRUs often result in severe or fatal consequences. While multimodallarge language models (MLLMs) have shown promise in enhancing sceneunderstanding and decision making in autonomous vehicles, there is currently nostandardized benchmark to quantitatively evaluate their reasoning abilities incomplex, safety-critical scenarios involving VRUs. To address this gap, wepresent VRU-Accident, a large-scale vision-language benchmark designed toevaluate MLLMs in high-risk traffic scenarios involving VRUs. VRU-Accidentcomprises 1K real-world dashcam accident videos, annotated with 6Kmultiple-choice question-answer pairs across six safety-critical categories(with 24K candidate options and 3.4K unique answer choices), as well as 1Kdense scene descriptions. Unlike prior works, our benchmark focuses explicitlyon VRU-vehicle accidents, providing rich, fine-grained annotations that captureboth spatial-temporal dynamics and causal semantics of accidents. To assess thecurrent landscape of MLLMs, we conduct a comprehensive evaluation of 17state-of-the-art models on the multiple-choice VQA task and on the densecaptioning task. Our findings reveal that while MLLMs perform reasonably wellon visually grounded attributes, they face significant challenges in reasoningand describing accident causes, types, and preventability.</description>
      <author>example@mail.com (Younggun Kim, Ahmed S. Abdelrahman, Mohamed Abdel-Aty)</author>
      <guid isPermaLink="false">2507.09815v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Mind the Gap: Aligning Vision Foundation Models to Image Feature Matching</title>
      <link>http://arxiv.org/abs/2507.10318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IMD的图像特征匹配框架，用于解决将视觉基础模型引入特征匹配时出现的错位问题，并显著提高了多实例特征匹配的性能。&lt;h4&gt;背景&lt;/h4&gt;虽然利用视觉基础模型已成为提高图像特征匹配性能的主流范式，但先前的研究忽略了在引入基础模型时可能出现的错位问题。&lt;h4&gt;目的&lt;/h4&gt;旨在解决由于基础模型在单图理解和跨图理解要求之间的差异而导致的错位问题，从而提高图像特征匹配的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为IMD的框架，该框架包含两部分：1) 使用基于扩散模型的生成模型来捕获实例级别的细节，而不是强调全局语义的对比学习基础模型；2) 利用生成模型中的提示机制，提出了一种新的跨图像交互提示模块，以促进图像对之间的双向信息交互。&lt;h4&gt;主要发现&lt;/h4&gt;1) 常用基础模型提取的嵌入与特征匹配所需的最佳嵌入存在差异；2) 缺乏有效的机制将单图理解能力转化为跨图理解能力。&lt;h4&gt;结论&lt;/h4&gt;IMD框架在常用基准测试中建立了新的最先进水平，IMIM基准测试中12%的优越提升表明该方法有效地缓解了错位问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用视觉基础模型已成为提高图像特征匹配性能的主流范式。然而，先前的研究忽略了在引入基础模型时可能出现的错位问题。这种错位源于专注于单图理解的模型与特征匹配所需的跨图理解要求之间的差异。具体来说，1) 常用基础模型提取的嵌入与特征匹配所需的最佳嵌入存在差异；2) 缺乏有效的机制将单图理解能力转化为跨图理解能力。这种错位的显著后果是它们在解决多实例特征匹配问题时存在困难。为了解决这个问题，我们引入了一个简单但有效的框架，称为IMD（使用预训练扩散模型的图像特征匹配），包含两个部分：1) 与强调全局语义的基于对比学习的占主导地位的基础模型解决方案不同，我们整合了基于生成的扩散模型来有效地捕获实例级别的细节；2) 我们利用生成模型中的提示机制作为自然隧道，提出了一种新的跨图像交互提示模块，以促进图像对之间的双向信息交互。为了更准确地测量错位，我们提出了一种新的基准，称为IMIM，它专注于多实例场景。我们提出的IMD在常用基准测试中建立了新的最先进水平，IMIM基准测试中12%的优越提升表明我们的方法有效地缓解了错位。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging the vision foundation models has emerged as a mainstream paradigmthat improves the performance of image feature matching. However, previousworks have ignored the misalignment when introducing the foundation models intofeature matching. The misalignment arises from the discrepancy between thefoundation models focusing on single-image understanding and the cross-imageunderstanding requirement of feature matching. Specifically, 1) the embeddingsderived from commonly used foundation models exhibit discrepancies with theoptimal embeddings required for feature matching; 2) lacking an effectivemechanism to leverage the single-image understanding ability into cross-imageunderstanding. A significant consequence of the misalignment is they strugglewhen addressing multi-instance feature matching problems. To address this, weintroduce a simple but effective framework, called IMD (Image feature Matchingwith a pre-trained Diffusion model) with two parts: 1) Unlike the dominantsolutions employing contrastive-learning based foundation models that emphasizeglobal semantics, we integrate the generative-based diffusion models toeffectively capture instance-level details. 2) We leverage the prompt mechanismin generative model as a natural tunnel, propose a novel cross-imageinteraction prompting module to facilitate bidirectional informationinteraction between image pairs. To more accurately measure the misalignment,we propose a new benchmark called IMIM, which focuses on multi-instancescenarios. Our proposed IMD establishes a new state-of-the-art in commonlyevaluated benchmarks, and the superior improvement 12% in IMIM indicates ourmethod efficiently mitigates the misalignment.</description>
      <author>example@mail.com (Yuhan Liu, Jingwen Fu, Yang Wu, Kangyi Wu, Pengna Li, Jiayi Wu, Sanping Zhou, Jingmin Xin)</author>
      <guid isPermaLink="false">2507.10318v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>High-throughput prediction of thermodynamically stable 1D magnetic transition-metal chalcogenides and halides</title>
      <link>http://arxiv.org/abs/2507.10370v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过高吞吐量、第一性原理计算，对一维过渡金属硫化物和卤化物进行了广泛的研究，以寻找具有异质物理性质的新型一维材料。&lt;h4&gt;背景&lt;/h4&gt;寻找具有异质物理性质的一维材料对于推进纳米电子学和自旋电子学至关重要。&lt;h4&gt;目的&lt;/h4&gt;探索一维过渡金属硫化物和卤化物的广泛领域，以寻找具有潜在应用价值的新型一维材料。&lt;h4&gt;方法&lt;/h4&gt;从6,832个候选结构中筛选出210个稳定的1D磁链，通过比较1D链的形成能与竞争的2D相，模拟成核过程中的热力学选择性。&lt;h4&gt;主要发现&lt;/h4&gt;发现了210个稳定的1D磁链，揭示了化学计量比和非金属元素的电子亲和力是决定一维稳定性的关键因素。稳定的材料表现出丰富的性质，包括不同的磁序（铁磁、反铁磁）和Luttinger补偿反铁磁。发现了20个铁弹性链，其中FeTe显示出巨大的磁致伸缩系数为-5.57%。还发现了FeTe和NiSe中的电荷密度波（CDW）链。预测了在铁磁CrCl2链和超导NbSe2衬底上实现马约拉纳零模。&lt;h4&gt;结论&lt;/h4&gt;本研究为量子应用提供了具体平台，如预测在超导衬底上实现马约拉纳零模。&lt;h4&gt;翻译&lt;/h4&gt;摘要：寻找具有异质物理性质的新型一维（1D）材料对于推进纳米电子学和自旋电子学至关重要。在此，我们进行了一项全面的高吞吐量、第一性原理研究，以探索一维过渡金属硫化物和卤化物的广阔领域。从由28种金属和8种非金属组成的6,832个候选结构开始，我们系统地评估了它们的动力学稳定性，通过比较1D链的形成能与竞争的2D相，模拟成核过程中的热力学选择性。这种筛选确定了210个稳定的1D磁链。此外，表示学习模型揭示了化学计量比和非金属元素的电子亲和力是控制1D稳定性的关键因素。稳定的材料表现出丰富的性质，包括不同的磁序（铁磁，反铁磁）和MnTe中的Luttinger补偿反铁磁。我们发现了20个铁弹性链，其中FeTe显示出巨大的磁致伸缩系数为-5.57%。其他新兴现象包括FeTe和NiSe中的电荷密度波（CDW）链。最后，我们的发现为量子应用提出了具体平台，如预测在铁磁CrCl2链和超导NbSe2衬底上实现马约拉纳零模。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The search for novel one-dimensional (1D) materials with exotic physicalproperties is crucial for advancing nanoelectronics and spintronics. Here, weperform a comprehensive high-throughput, first-principles study to explore thevast landscape of 1D transition-metal chalcogenides and halides. Starting with6,832 candidate structures derived from 28 metals and 8 non-metals, wesystematically evaluated their thermodynamic stability by comparing theformation energies of 1D chains against competing 2D phases, mimickingthermodynamic selectivity during nucleation. This screening identified 210stable 1D magnetic chains. Furthermore, representation learning models revealedthat chemical stoichiometry and the electron affinity of the non-metal elementare key factors governing 1D stability. The stable materials exhibit a richspectrum of properties, including diverse magnetic orders (FM, AFM) andLuttinger compensated antiferromagnetism in MnTe. We discovered 20 ferroelasticchains, with FeTe showing a giant magnetostriction of -5.57%. Other emergentphenomena include Charge Density Wave (CDW) chains in FeTe and NiSe. Finally,our findings propose concrete platforms for quantum applications, such as thepredicted realization of Majorana zero modes in a ferromagnetic CrCl2 chain ona superconducting NbSe2 substrate.</description>
      <author>example@mail.com (Canbo Zong, Deping Guo, Renhong Wang, Weihan Zhang, Jiaqi Dai, Zhongqin Zhang, Cong Wang, Xianghua Kong, Wei Ji)</author>
      <guid isPermaLink="false">2507.10370v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>DisCo: Towards Distinct and Coherent Visual Encapsulation in Video MLLMs</title>
      <link>http://arxiv.org/abs/2507.10302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DisCo的新型视觉封装方法，用于视频多模态大型语言模型（video MLLMs），以提高语义区分度和时间一致性。&lt;h4&gt;背景&lt;/h4&gt;在视频MLLMs中，视觉封装过程对于将视频内容转换为LLM输入的代表性标记至关重要。线性投影器虽然广泛应用，但会导致语义模糊和时间不连贯。&lt;h4&gt;目的&lt;/h4&gt;为了解决线性投影器带来的问题，提出DisCo方法，旨在生成语义明确和时间一致的视觉标记。&lt;h4&gt;方法&lt;/h4&gt;DisCo包含两个关键模块：(1)视觉概念判别器（VCD）模块，通过将视觉标记与视频中的判别性概念配对，为视觉标记分配唯一语义；(2)时间焦点校准器（TFC）模块，确保视觉标记在每一帧视频中对视频元素保持一致的时间焦点。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多个视频MLLM框架上的广泛实验，DisCo在多种视频理解基准测试中显著优于现有最先进的方法，并通过减少语义模糊性实现了更高的标记效率。&lt;h4&gt;结论&lt;/h4&gt;DisCo是一种有效的视觉封装方法，可以显著提高视频MLLMs的性能。&lt;h4&gt;翻译&lt;/h4&gt;In video Multimodal Large Language Models (video MLLMs), the visual encapsulation process plays a pivotal role in converting video contents into representative tokens for LLM input. While linear projectors are widely employed for encapsulation, they introduce semantic indistinctness and temporal incoherence when applied to videos. Conversely, the structure of resamplers shows promise in tackling these challenges, but an effective solution remains unexplored. Drawing inspiration from resampler structures, we introduce DisCo, a novel visual encapsulation method designed to yield semantically distinct and temporally coherent visual tokens for video MLLMs. DisCo integrates two key components: (1) A Visual Concept Discriminator (VCD) module, assigning unique semantics for visual tokens by associating them in pair with discriminative concepts in the video. (2) A Temporal Focus Calibrator (TFC) module, ensuring consistent temporal focus of visual tokens to video elements across every video frame. Through extensive experiments on multiple video MLLM frameworks, we demonstrate that DisCo remarkably outperforms previous state-of-the-art methods across a variety of video understanding benchmarks, while also achieving higher token efficiency thanks to the reduction of semantic indistinctness. The code: https://github.com/ZJHTerry18/DisCo.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In video Multimodal Large Language Models (video MLLMs), the visualencapsulation process plays a pivotal role in converting video contents intorepresentative tokens for LLM input. While linear projectors are widelyemployed for encapsulation, they introduce semantic indistinctness and temporalincoherence when applied to videos. Conversely, the structure of resamplersshows promise in tackling these challenges, but an effective solution remainsunexplored. Drawing inspiration from resampler structures, we introduce DisCo,a novel visual encapsulation method designed to yield semantically distinct andtemporally coherent visual tokens for video MLLMs. DisCo integrates two keycomponents: (1) A Visual Concept Discriminator (VCD) module, assigning uniquesemantics for visual tokens by associating them in pair with discriminativeconcepts in the video. (2) A Temporal Focus Calibrator (TFC) module, ensuringconsistent temporal focus of visual tokens to video elements across every videoframe. Through extensive experiments on multiple video MLLM frameworks, wedemonstrate that DisCo remarkably outperforms previous state-of-the-art methodsacross a variety of video understanding benchmarks, while also achieving highertoken efficiency thanks to the reduction of semantic indistinctness. The code:https://github.com/ZJHTerry18/DisCo.</description>
      <author>example@mail.com (Jiahe Zhao, Rongkun Zheng, Yi Wang, Helin Wang, Hengshuang Zhao)</author>
      <guid isPermaLink="false">2507.10302v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>FIX-CLIP: Dual-Branch Hierarchical Contrastive Learning via Synthetic Captions for Better Understanding of Long Text</title>
      <link>http://arxiv.org/abs/2507.10095v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FIX-CLIP模型通过改进CLIP在处理长文本输入时的性能，在长文本和短文本检索基准测试中实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;CLIP在许多短文本任务中表现出色，但在处理长文本输入时受到文本编码器输入长度限制的影响。&lt;h4&gt;目的&lt;/h4&gt;提出FIX-CLIP模型以解决CLIP在长文本任务上的性能限制。&lt;h4&gt;方法&lt;/h4&gt;FIX-CLIP包括三个新颖模块：(1) 双分支训练流程，分别将短文本和长文本与掩码图像和原始图像对齐，以提升长文本表示能力同时保持短文本能力；(2) 在Transformer层中使用可学习的区域提示和单向掩码进行区域信息提取；(3) 中间编码器层中的层次特征对齐模块，以促进多尺度特征的连贯性。此外，收集了3000万张图片，并利用现有的MLLM生成长文本描述进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，FIX-CLIP在长文本和短文本检索基准测试中均取得了最先进的性能，并且其文本编码器为具有长文本输入的扩散模型提供了即插即用的良好性能。&lt;h4&gt;结论&lt;/h4&gt;FIX-CLIP通过改进CLIP模型，有效提升了其在长文本任务上的性能，为下游应用提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; CLIP has shown promising performance across many short-text tasks in azero-shot manner. However, limited by the input length of the text encoder,CLIP struggles on under-stream tasks with long-text inputs (&gt;77 tokens). Toremedy this issue, we propose FIX-CLIP which includes three novel modules: (1)A dual-branch training pipeline that aligns short and long texts with maskedand raw images respectively, which boosts the long-text representation whilepreserving the short-text ability. (2) Multiple learnable regional prompts withunidirectional masks in Transformer layers for regional information extraction.(3) A hierarchical feature alignment module in the intermediate encoder layersto promote the consistency of multi-scale features. Furthermore, we collect 30Mimages and utilize existing MLLMs to synthesize long-text captions fortraining. Extensive experiments show that FIX-CLIP achieves state-of-the-artperformance on both long-text and short-text retrieval benchmarks. Fordownstream applications, we reveal that FIX-CLIP's text encoder deliverspromising performance in a plug-and-play manner for diffusion models withlong-text input.</description>
      <author>example@mail.com (Bingchao Wang, Zhiwei Ning, Jianyu Ding, Xuanang Gao, Yin Li, Dongsheng Jiang, Jie Yang, Wei Liu)</author>
      <guid isPermaLink="false">2507.10095v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>LifelongPR: Lifelong knowledge fusion for point cloud place recognition based on replay and prompt learning</title>
      <link>http://arxiv.org/abs/2507.10034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LifelongPR是一个用于点云定位识别的持续学习框架，旨在解决现有模型在适应新环境或传感器类型时的灾难性遗忘问题。&lt;h4&gt;背景&lt;/h4&gt;点云定位识别在摄影测量和机器人应用中扮演重要角色，但在实际部署中，模型需要持续学习和适应多样化的动态环境。&lt;h4&gt;目的&lt;/h4&gt;提出LifelongPR框架，解决PCPR模型在适应新环境或传感器类型时的性能退化问题，提高模型的可扩展性和实用性。&lt;h4&gt;方法&lt;/h4&gt;1. 提出一种重放样本选择方法，动态分配样本大小并根据信息量选择代表性样本。2. 设计一个基于提示学习的持续学习框架，包括轻量级提示模块和两阶段训练策略，以最小化遗忘并适应特定领域。&lt;h4&gt;主要发现&lt;/h4&gt;在大型公开和自收集数据集上进行的实验表明，与最先进的方法相比，该方法在mIR@1、mR@1和F指标上分别提高了6.50%、7.96%和降低了8.95%。&lt;h4&gt;结论&lt;/h4&gt;LifelongPR框架有效提高了PCPR模型在持续学习环境中的性能，具有更好的可扩展性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;点云位置识别（PCPR）在摄影测量和机器人应用，如自动驾驶、智能交通和增强现实等领域发挥着至关重要的作用。在现实世界中大规模部署定位系统时，PCPR模型必须持续获取、更新和积累知识以适应多样化的动态环境，即所谓的持续学习（CL）。然而，现有的PCPR模型往往遭受灾难性遗忘，导致在适应新环境或传感器类型时，先前学习的场景性能显著下降。这导致了模型的可扩展性差、维护成本增加和系统部署困难，削弱了PCPR的实际应用价值。为了解决这些问题，我们提出了LifelongPR，一个用于PCPR的新的持续学习框架，它有效地从顺序点云数据中提取和融合知识。首先，为了减轻知识损失，我们提出了一种重放样本选择方法，该方法根据每个数据集的信息量动态分配样本大小，并选择空间上多样化的样本以实现最大代表性。其次，为了处理领域变化，我们设计了一个基于提示学习的CL框架，包括一个轻量级提示模块和两阶段训练策略，这允许领域特定的特征适应同时最小化遗忘。在大规模公开和自收集数据集上进行了综合实验，以验证所提出方法的有效性。与最先进的方法相比，我们的方法在mIR@1、mR@1和F指标上分别提高了6.50%、7.96%和降低了8.95%。代码和预训练模型可在https://github.com/zouxianghong/LifelongPR公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud place recognition (PCPR) plays a crucial role in photogrammetryand robotics applications such as autonomous driving, intelligenttransportation, and augmented reality. In real-world large-scale deployments ofa positioning system, PCPR models must continuously acquire, update, andaccumulate knowledge to adapt to diverse and dynamic environments, i.e., theability known as continual learning (CL). However, existing PCPR models oftensuffer from catastrophic forgetting, leading to significant performancedegradation in previously learned scenes when adapting to new environments orsensor types. This results in poor model scalability, increased maintenancecosts, and system deployment difficulties, undermining the practicality ofPCPR. To address these issues, we propose LifelongPR, a novel continuallearning framework for PCPR, which effectively extracts and fuses knowledgefrom sequential point cloud data. First, to alleviate the knowledge loss, wepropose a replay sample selection method that dynamically allocates samplesizes according to each dataset's information quantity and selects spatiallydiverse samples for maximal representativeness. Second, to handle domainshifts, we design a prompt learning-based CL framework with a lightweightprompt module and a two-stage training strategy, enabling domain-specificfeature adaptation while minimizing forgetting. Comprehensive experiments onlarge-scale public and self-collected datasets are conducted to validate theeffectiveness of the proposed method. Compared with state-of-the-art (SOTA)methods, our method achieves 6.50% improvement in mIR@1, 7.96% improvement inmR@1, and an 8.95% reduction in F. The code and pre-trained models are publiclyavailable at https://github.com/zouxianghong/LifelongPR.</description>
      <author>example@mail.com (Xianghong Zou, Jianping Li, Zhe Chen, Zhen Cao, Zhen Dong, Qiegen Liu, Bisheng Yang)</author>
      <guid isPermaLink="false">2507.10034v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>A Transfer Learning-Based Method for Water Body Segmentation in Remote Sensing Imagery: A Case Study of the Zhada Tulin Area</title>
      <link>http://arxiv.org/abs/2507.10084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 6 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出并验证了一种基于SegFormer模型的两个阶段的迁移学习策略，用于解决遥感图像水体分割中的领域差异和小样本问题。&lt;h4&gt;背景&lt;/h4&gt;遥感图像水体分割在领域差异和小样本情况下存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种策略以解决领域差异和小样本问题，提高水体分割的精度。&lt;h4&gt;方法&lt;/h4&gt;首先在多样化的资源域上训练基础分割模型，然后在目标域的数据上进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;在西藏的扎达土林地区，该策略将水体分割任务的IoU从25.50%提升到64.84%，有效解决了模型性能下降的问题，并为数据稀缺和环境独特的遥感场景提供了有效的技术范式。&lt;h4&gt;结论&lt;/h4&gt;该策略不仅有效解决了模型性能下降的问题，还为高精度主题信息提取提供了技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To address the prevalent challenges of domain shift and small sample sizes inremote sensing image water body segmentation, this study proposes and validatesa two-stage transfer learning strategy based on the SegFormer model. Theapproach begins by training a foundational segmentation model on a diversesource domain, where it achieves an Intersection over Union (IoU) of 68.80% onits validation set, followed by fine-tuning on data from the distinct targetdomain. Focusing on the Zhada Tulin area in Tibet -- a region characterized byhighly complex topography and spectral features -- the experimental resultsdemonstrate that this strategy significantly boosts the IoU for the water bodysegmentation task from 25.50% (for direct transfer) to 64.84%. This not onlyeffectively resolves the model performance degradation caused by domaindiscrepancy but also provides an effective technical paradigm forhigh-precision thematic information extraction in data-scarce andenvironmentally unique remote sensing scenarios.</description>
      <author>example@mail.com (Haonan Chen, Xin Tong)</author>
      <guid isPermaLink="false">2507.10084v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised Pretraining for Integrated Prediction and Planning of Automated Vehicles</title>
      <link>http://arxiv.org/abs/2507.09537v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Plan-MAE的统一预训练框架，用于预测和规划，该框架利用掩码自编码器融合关键情境理解，通过重构掩码道路网络、代理轨迹和导航路线来学习空间相关性、社交互动和目的地意图，并在大型数据集上显示出优于现有方法的规划指标。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶车辆需要预测周围代理的未来并规划安全、目标导向的轨迹。当前方法通常依赖于模仿学习来优化与真实情况的指标，而忽略了情境理解如何实现更全面的轨迹。&lt;h4&gt;目的&lt;/h4&gt;提出Plan-MAE框架，旨在通过预训练来提高自动驾驶车辆的预测和规划能力。&lt;h4&gt;方法&lt;/h4&gt;Plan-MAE通过三个专用任务融合关键情境理解：重构掩码道路网络学习空间相关性，代理轨迹建模社交互动，导航路线捕捉目的地意图。此外，还引入了预测自我车辆近期轨迹段的任务，以进一步协调车辆动力学和安全约束。&lt;h4&gt;主要发现&lt;/h4&gt;在大型数据集上的实验表明，Plan-MAE在规划指标上优于现有方法，并且可以作为基于学习的学习运动规划器的重要预训练步骤。&lt;h4&gt;结论&lt;/h4&gt;Plan-MAE是一种有效的预训练框架，可以提高自动驾驶车辆的预测和规划能力，对未来的自动驾驶研究具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting the future of surrounding agents and accordingly planning a safe,goal-directed trajectory are crucial for automated vehicles. Current methodstypically rely on imitation learning to optimize metrics against the groundtruth, often overlooking how scene understanding could enable more holistictrajectories. In this paper, we propose Plan-MAE, a unified pretrainingframework for prediction and planning that capitalizes on masked autoencoders.Plan-MAE fuses critical contextual understanding via three dedicated tasks:reconstructing masked road networks to learn spatial correlations, agenttrajectories to model social interactions, and navigation routes to capturedestination intents. To further align vehicle dynamics and safety constraints,we incorporate a local sub-planning task predicting the ego-vehicle's near-termtrajectory segment conditioned on earlier segment. This pretrained model issubsequently fine-tuned on downstream tasks to jointly generate the predictionand planning trajectories. Experiments on large-scale datasets demonstrate thatPlan-MAE outperforms current methods on the planning metrics by a large marginand can serve as an important pre-training step for learning-based motionplanner.</description>
      <author>example@mail.com (Yangang Ren, Guojian Zhan, Chen Lv, Jun Li, Fenghua Liang, Keqiang Li)</author>
      <guid isPermaLink="false">2507.09537v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Forecasting Coccidioidomycosis (Valley Fever) in Arizona: A Graph Neural Network Approach</title>
      <link>http://arxiv.org/abs/2507.10014v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究开发了一种用于预测亚利桑那州山谷热（球孢子菌病）发病率的第一个图神经网络（GNN）模型，该模型结合了病例数据和环境预测因子，并通过图结构捕捉疾病传播的影响因素。&lt;h4&gt;背景&lt;/h4&gt;山谷热在美西南部的流行地区是一个重要的公共卫生问题。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够预测亚利桑那州山谷热发病率的图神经网络模型。&lt;h4&gt;方法&lt;/h4&gt;模型整合了病例数据与环境预测因子，包括土壤条件、大气变量、农业指标和空气质量指标，并利用图结构探索变量间的相关性关系。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够有效地模拟山谷热趋势，并揭示了疾病发病率的关键环境驱动因素。&lt;h4&gt;结论&lt;/h4&gt;这些发现可以为高风险地区的早期预警系统和疾病预防资源的分配提供信息。&lt;h4&gt;翻译&lt;/h4&gt;摘要：球孢子菌病，通常称为山谷热，在美国西南部流行地区仍是一个重要的公共卫生问题。本研究开发了第一个用于预测亚利桑那州山谷热发病率的图神经网络（GNN）模型。该模型整合了病例数据与环境预测因子，使用图结构，包括土壤条件、大气变量、农业指标和空气质量指标。我们的方法探索了影响疾病传播的变量之间的相关性关系。该模型通过滞后效应捕捉疾病进展中的关键延迟，增强了其反映疾病生态学中复杂时间依赖性的能力。结果表明，GNN架构有效地模拟了山谷热趋势，并提供了关于疾病发病率关键环境驱动因素的了解。这些发现可以为高风险地区的早期预警系统和疾病预防工作的资源分配提供信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Coccidioidomycosis, commonly known as Valley Fever, remains a significantpublic health concern in endemic regions of the southwestern United States.This study develops the first graph neural network (GNN) model for forecastingValley Fever incidence in Arizona. The model integrates surveillance case datawith environmental predictors using graph structures, including soilconditions, atmospheric variables, agricultural indicators, and air qualitymetrics. Our approach explores correlation-based relationships among variablesinfluencing disease transmission. The model captures critical delays in diseaseprogression through lagged effects, enhancing its capacity to reflect complextemporal dependencies in disease ecology. Results demonstrate that the GNNarchitecture effectively models Valley Fever trends and provides insights intokey environmental drivers of disease incidence. These findings can inform earlywarning systems and guide resource allocation for disease prevention efforts inhigh-risk areas.</description>
      <author>example@mail.com (Ali Sarabi, Arash Sarabi, Hao Yan, Beckett Sterner, Petar Jevtić)</author>
      <guid isPermaLink="false">2507.10014v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Synthesizing Near-Boundary OOD Samples for Out-of-Distribution Detection</title>
      <link>http://arxiv.org/abs/2507.10225v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为SynOOD的新方法，该方法利用基础模型生成合成、具有挑战性的OOD数据，用于微调CLIP模型，从而增强InD和OOD样本之间的边界级别区分能力。&lt;h4&gt;背景&lt;/h4&gt;预训练的视觉-语言模型在检测OOD样本方面表现出色，但对于接近InD数据的某些挑战性OOD样本，仍然可能导致误分类。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，利用基础模型生成合成OOD数据，以增强CLIP模型对InD和OOD样本的区分能力。&lt;h4&gt;方法&lt;/h4&gt;SynOOD方法使用MLLM的上下文提示引导的迭代in-painting过程来生成细微、边界对齐的OOD样本。这些样本通过基于能量分数等OOD分数梯度的噪声调整进行细化，从而有效地从InD/OOD边界进行采样。然后，使用这些精心合成的图像微调CLIP图像编码器和从文本编码器中提取的负标签特征。&lt;h4&gt;主要发现&lt;/h4&gt;SynOOD在ImageNet基准测试中实现了最先进的性能，参数和运行时间增加最小。它显著优于现有方法，AUROC提高了2.80%，FPR95降低了11.13%。&lt;h4&gt;结论&lt;/h4&gt;SynOOD方法通过生成具有挑战性的OOD数据来增强CLIP模型的OOD检测能力，在保持参数和运行时间增加最小的同时，显著提高了性能。&lt;h4&gt;翻译&lt;/h4&gt;Pre-trained vision-language models have exhibited remarkable abilities in detecting out-of-distribution (OOD) samples. However, some challenging OOD samples, which lie close to in-distribution (InD) data in image feature space, can still lead to misclassification. The emergence of foundation models like diffusion models and multimodal large language models (MLLMs) offers a potential solution to this issue. In this work, we propose SynOOD, a novel approach that harnesses foundation models to generate synthetic, challenging OOD data for fine-tuning CLIP models, thereby enhancing boundary-level discrimination between InD and OOD samples. Our method uses an iterative in-painting process guided by contextual prompts from MLLMs to produce nuanced, boundary-aligned OOD samples. These samples are refined through noise adjustments based on gradients from OOD scores like the energy score, effectively sampling from the InD/OOD boundary. With these carefully synthesized images, we fine-tune the CLIP image encoder and negative label features derived from the text encoder to strengthen connections between near-boundary OOD samples and a set of negative labels. Finally, SynOOD achieves state-of-the-art performance on the large-scale ImageNet benchmark, with minimal increases in parameters and runtime. Our approach significantly surpasses existing methods, improving AUROC by 2.80% and reducing FPR95 by 11.13%. Codes are available in https://github.com/Jarvisgivemeasuit/SynOOD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-trained vision-language models have exhibited remarkable abilities indetecting out-of-distribution (OOD) samples. However, some challenging OODsamples, which lie close to in-distribution (InD) data in image feature space,can still lead to misclassification. The emergence of foundation models likediffusion models and multimodal large language models (MLLMs) offers apotential solution to this issue. In this work, we propose SynOOD, a novelapproach that harnesses foundation models to generate synthetic, challengingOOD data for fine-tuning CLIP models, thereby enhancing boundary-leveldiscrimination between InD and OOD samples. Our method uses an iterativein-painting process guided by contextual prompts from MLLMs to produce nuanced,boundary-aligned OOD samples. These samples are refined through noiseadjustments based on gradients from OOD scores like the energy score,effectively sampling from the InD/OOD boundary. With these carefullysynthesized images, we fine-tune the CLIP image encoder and negative labelfeatures derived from the text encoder to strengthen connections betweennear-boundary OOD samples and a set of negative labels. Finally, SynOODachieves state-of-the-art performance on the large-scale ImageNet benchmark,with minimal increases in parameters and runtime. Our approach significantlysurpasses existing methods, improving AUROC by 2.80% and reducing FPR95 by11.13%. Codes are available in https://github.com/Jarvisgivemeasuit/SynOOD.</description>
      <author>example@mail.com (Jinglun Li, Kaixun Jiang, Zhaoyu Chen, Bo Lin, Yao Tang, Weifeng Ge, Wenqiang Zhang)</author>
      <guid isPermaLink="false">2507.10225v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Swin Transformer for enhanced diagnosis of Alzheimer's disease using multi-shell diffusion MRI</title>
      <link>http://arxiv.org/abs/2507.09996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究旨在利用多壳扩散磁共振成像（dMRI）数据中的微结构信息，通过基于视觉转换器的深度学习框架来支持阿尔茨海默病的早期诊断和淀粉样蛋白积累的检测。&lt;h4&gt;背景&lt;/h4&gt;该研究涉及阿尔茨海默病的诊断和淀粉样蛋白的检测。&lt;h4&gt;目的&lt;/h4&gt;研究目标是提高阿尔茨海默病的早期诊断效率和淀粉样蛋白积累的检测能力。&lt;h4&gt;方法&lt;/h4&gt;研究采用了基于SwinTransformer的分层视觉转换器模型，在多壳dMRI数据上进行阿尔茨海默病和淀粉样蛋白存在的分类。同时提取了DTI和NODDI的关键指标，并将其投影到2D平面上，以实现与ImageNet预训练模型的迁移学习。为了有效地适应有限的标注神经影像数据，集成了低秩适应技术。评估了框架在诊断组预测（认知正常、轻度认知障碍、阿尔茨海默病痴呆）和淀粉样状态分类中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在多壳dMRI基于特征的范围内部达到了具有竞争力的分类结果，使用NODDI指标将认知正常个体与阿尔茨海默病痴呆患者区分开的最佳平衡准确率达到95.2%。在淀粉样蛋白检测方面，将淀粉样蛋白阳性的轻度认知障碍/阿尔茨海默病痴呆患者与淀粉样蛋白阴性的认知正常患者区分开的平衡准确率达到77.2%，在认知正常个体中识别淀粉样蛋白阳性的个体的准确率达到67.9%。基于Grad-CAM的解释性分析确定了与临床相关的脑区，如副海马回和海马，作为模型预测的关键贡献者。&lt;h4&gt;结论&lt;/h4&gt;该研究表明，扩散磁共振成像和基于转换器的架构在早期检测阿尔茨海默病和淀粉样蛋白病理方面具有潜力，支持数据有限生物医学环境中的生物标志物驱动诊断。&lt;h4&gt;翻译&lt;/h4&gt;This study aims to support early diagnosis of Alzheimer's disease and detection of amyloid accumulation by leveraging the microstructural information available in multi-shell diffusion MRI (dMRI) data, using a vision transformer-based deep learning framework. Methods: We present a classification pipeline that employs the SwinTransformer, a hierarchical vision transformer model, on multi-shell dMRI data for the classification of Alzheimer's disease and amyloid presence. Key metrics from DTI and NODDI were extracted and projected onto 2D planes to enable transfer learning with ImageNet-pretrained models. To efficiently adapt the transformer to limited labeled neuroimaging data, we integrated Low-Rank Adaptation. We assessed the framework on diagnostic group prediction (cognitively normal, mild cognitive impairment, Alzheimer's disease dementia) and amyloid status classification. Results: The framework achieved competitive classification results within the scope of multi-shell dMRI-based features, with the best balanced accuracy of 95.2% for distinguishing cognitively normal individuals from those with Alzheimer's disease dementia using NODDI metrics. For amyloid detection, it reached 77.2% balanced accuracy in distinguishing amyloid-positive mild cognitive impairment/Alzheimer's disease dementia subjects from amyloid-negative cognitively normal subjects, and 67.9% for identifying amyloid-positive individuals among cognitively normal subjects. Grad-CAM-based explainability analysis identified clinically relevant brain regions, including the parahippocampal gyrus and hippocampus, as key contributors to model predictions. Conclusion: This study demonstrates the promise of diffusion MRI and transformer-based architectures for early detection of Alzheimer's disease and amyloid pathology, supporting biomarker-driven diagnostics in data-limited biomedical settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Objective: This study aims to support early diagnosis of Alzheimer's diseaseand detection of amyloid accumulation by leveraging the microstructuralinformation available in multi-shell diffusion MRI (dMRI) data, using a visiontransformer-based deep learning framework.  Methods: We present a classification pipeline that employs the SwinTransformer, a hierarchical vision transformer model, on multi-shell dMRI datafor the classification of Alzheimer's disease and amyloid presence. Key metricsfrom DTI and NODDI were extracted and projected onto 2D planes to enabletransfer learning with ImageNet-pretrained models. To efficiently adapt thetransformer to limited labeled neuroimaging data, we integrated Low-RankAdaptation. We assessed the framework on diagnostic group prediction(cognitively normal, mild cognitive impairment, Alzheimer's disease dementia)and amyloid status classification.  Results: The framework achieved competitive classification results within thescope of multi-shell dMRI-based features, with the best balanced accuracy of95.2% for distinguishing cognitively normal individuals from those withAlzheimer's disease dementia using NODDI metrics. For amyloid detection, itreached 77.2% balanced accuracy in distinguishing amyloid-positive mildcognitive impairment/Alzheimer's disease dementia subjects fromamyloid-negative cognitively normal subjects, and 67.9% for identifyingamyloid-positive individuals among cognitively normal subjects. Grad-CAM-basedexplainability analysis identified clinically relevant brain regions, includingthe parahippocampal gyrus and hippocampus, as key contributors to modelpredictions.  Conclusion: This study demonstrates the promise of diffusion MRI andtransformer-based architectures for early detection of Alzheimer's disease andamyloid pathology, supporting biomarker-driven diagnostics in data-limitedbiomedical settings.</description>
      <author>example@mail.com (Quentin Dessain, Nicolas Delinte, Bernard Hanseeuw, Laurence Dricot, Benoît Macq)</author>
      <guid isPermaLink="false">2507.09996v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Effects of structural properties of neural networks on machine learning performance</title>
      <link>http://arxiv.org/abs/2507.10005v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于图的结构机器学习技术进行了综合研究，特别是神经网络的图结构和其预测性能之间的关系，并探讨了社区结构对网络性能的影响。&lt;h4&gt;背景&lt;/h4&gt;近年来，图神经网络等图学习技术在机器学习领域受到广泛关注。虽然一些研究开始探讨神经网络结构与预测性能之间的关系，但往往局限于模型网络的狭窄范围，缺乏社区等中尺度结构。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过对具有异构度分布和社区结构的真实网络结构的更全面调查，来推进这一领域的发展。&lt;h4&gt;方法&lt;/h4&gt;研究采用了随机网络、无标度网络等模型网络，并与生物神经网络及其子集进行了比较，以更详细地分析这些结构属性对图像分类任务性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，具有连贯、密集互连的社区的网络显示出增强的学习能力，与生物神经网络的比较强调了这些发现与真实世界结构的关联性。&lt;h4&gt;结论&lt;/h4&gt;本研究对网络科学和机器学习做出了重要贡献，为设计更具有生物启发性的神经网络提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, graph-based machine learning techniques, such as reinforcement learning and graph neural networks, have garnered significant attention. While some recent studies have started to explore the relationship between the graph structure of neural networks and their predictive performance, they often limit themselves to a narrow range of model networks, particularly lacking mesoscale structures such as communities. Our work advances this area by conducting a more comprehensive investigation, incorporating realistic network structures characterized by heterogeneous degree distributions and community structures, which are typical characteristics of many real networks. These community structures offer an nuanced perspective on network architecture. Our analysis employs model networks such as random and scale-free networks, alongside a comparison with a biological neural network and its subsets for more detailed analysis. We examine the impact of these structural attributes on the performance of image classification tasks. Our findings reveal that structural properties do affect performance to some extent. Specifically, networks featuring coherent, densely interconnected communities demonstrate enhanced learning capabilities. The comparison with the biological neural network emphasizes the relevance of our findings to real-world structures, suggesting an intriguing connection worth further exploration. This study contributes meaningfully to network science and machine learning, providing insights that could inspire the design of more biologically informed neural networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, graph-based machine learning techniques, such asreinforcement learning and graph neural networks, have garnered significantattention. While some recent studies have started to explore the relationshipbetween the graph structure of neural networks and their predictiveperformance, they often limit themselves to a narrow range of model networks,particularly lacking mesoscale structures such as communities. Our workadvances this area by conducting a more comprehensive investigation,incorporating realistic network structures characterized by heterogeneousdegree distributions and community structures, which are typicalcharacteristics of many real networks. These community structures offer anuanced perspective on network architecture. Our analysis employs modelnetworks such as random and scale-free networks, alongside a comparison with abiological neural network and its subsets for more detailed analysis. Weexamine the impact of these structural attributes on the performance of imageclassification tasks. Our findings reveal that structural properties do affectperformance to some extent. Specifically, networks featuring coherent, denselyinterconnected communities demonstrate enhanced learning capabilities. Thecomparison with the biological neural network emphasizes the relevance of ourfindings to real-world structures, suggesting an intriguing connection worthfurther exploration. This study contributes meaningfully to network science andmachine learning, providing insights that could inspire the design of morebiologically informed neural networks.</description>
      <author>example@mail.com (Yash Arya, Sang Hoon Lee)</author>
      <guid isPermaLink="false">2507.10005v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>EventHunter: Dynamic Clustering and Ranking of Security Events from Hacker Forum Discussions</title>
      <link>http://arxiv.org/abs/2507.09762v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication at the 28th International Symposium on  Research in Attacks, Intrusions, and Defenses (RAID 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种无监督框架，用于从黑客论坛的未结构化和嘈杂内容中自动检测、聚类和优先排序安全事件。&lt;h4&gt;背景&lt;/h4&gt;黑客论坛提供了关于新兴网络安全威胁的关键早期预警信号，但从中提取可操作情报仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，能够自动识别、聚类和优先排序黑客论坛帖子中讨论的安全事件。&lt;h4&gt;方法&lt;/h4&gt;该方法利用基于Transformer的嵌入，通过对比学习进行微调，将相关讨论分组到不同的安全事件聚类中，识别零日披露或恶意软件发布等事件，而不依赖于预定义的关键词。框架还包含一个每日排名机制，使用可量化指标来优先排序识别的事件，这些指标反映了时效性、来源可信度、信息完整性和相关性。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界黑客论坛数据上的实验评估表明，该方法有效地减少了噪声，并突显了高优先级威胁，使安全分析师能够采取主动响应。&lt;h4&gt;结论&lt;/h4&gt;通过将不同的黑客论坛讨论转化为结构化和可操作情报，这项工作解决了自动化威胁检测和分析中的基本挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：黑客论坛为新兴网络安全威胁提供了关键的早期预警信号，但从其非结构化和嘈杂的内容中提取可操作的情报仍然是一个重大的挑战。本文提出了一种无监督框架，该框架能够自动检测、聚类和优先排序黑客论坛帖子中讨论的安全事件。该方法利用基于Transformer的嵌入，通过对比学习进行微调，将相关讨论分组到不同的安全事件聚类中，识别出如零日披露或恶意软件发布等事件，而不依赖于预定义的关键词。该框架还包含一个每日排名机制，通过使用反映时效性、来源可信度、信息完整性和相关性的可量化指标来优先排序识别的事件。在真实世界黑客论坛数据上的实验评估表明，该方法有效地减少了噪声，并突显了高优先级威胁，使安全分析师能够采取主动响应。通过将不同的黑客论坛讨论转化为结构化和可操作情报，我们的工作解决了自动化威胁检测和分析中的基本挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hacker forums provide critical early warning signals for emergingcybersecurity threats, but extracting actionable intelligence from theirunstructured and noisy content remains a significant challenge. This paperpresents an unsupervised framework that automatically detects, clusters, andprioritizes security events discussed across hacker forum posts. Our approachleverages Transformer-based embeddings fine-tuned with contrastive learning togroup related discussions into distinct security event clusters, identifyingincidents like zero-day disclosures or malware releases without relying onpredefined keywords. The framework incorporates a daily ranking mechanism thatprioritizes identified events using quantifiable metrics reflecting timeliness,source credibility, information completeness, and relevance. Experimentalevaluation on real-world hacker forum data demonstrates that our methodeffectively reduces noise and surfaces high-priority threats, enabling securityanalysts to mount proactive responses. By transforming disparate hacker forumdiscussions into structured, actionable intelligence, our work addressesfundamental challenges in automated threat detection and analysis.</description>
      <author>example@mail.com (Yasir Ech-Chammakhy, Anas Motii, Anass Rabii, Jaafar Chbili)</author>
      <guid isPermaLink="false">2507.09762v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Abstraction Enables Human-Like 3D Object Recognition in Deep Learning Models</title>
      <link>http://arxiv.org/abs/2507.09830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了人类和深度学习模型在识别由稀疏视觉信息（如点云）表示的3D形状方面的能力，并比较了不同模型在人类表现上的表现。&lt;h4&gt;背景&lt;/h4&gt;人类和深度学习模型都能从3D形状中识别对象，但这些模型是否形成了与人类视觉相似的3D形状表示尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;研究训练3D形状是否能使模型形成局部几何结构的表示，并探讨不同深度学习模型在识别3D形状方面的表现。&lt;h4&gt;方法&lt;/h4&gt;通过两个实验系统地操纵点密度、物体方向和局部几何结构，比较了基于卷积神经网络（DGCNN）和视觉转换器（点转换器）的深度学习模型与人类的表现。&lt;h4&gt;主要发现&lt;/h4&gt;人类在所有实验条件下都表现良好，点转换器模型在解释人类表现方面优于基于卷积的模型，这主要归因于点转换器模型中支持3D形状分层抽象的机制。&lt;h4&gt;结论&lt;/h4&gt;点转换器模型在识别3D形状方面优于基于卷积的模型，这表明其能够更好地模拟人类的视觉过程。&lt;h4&gt;翻译&lt;/h4&gt;Both humans and deep learning models can recognize objects from 3D shapes depicted with sparse visual information, such as a set of points randomly sampled from the surfaces of 3D objects (termed a point cloud). Although deep learning models achieve human-like performance in recognizing objects from 3D shapes, it remains unclear whether these models develop 3D shape representations similar to those used by human vision for object recognition. We hypothesize that training with 3D shapes enables models to form representations of local geometric structures in 3D shapes. However, their representations of global 3D object shapes may be limited. We conducted two human experiments systematically manipulating point density and object orientation (Experiment 1), and local geometric structure (Experiment 2). Humans consistently performed well across all experimental conditions. We compared two types of deep learning models, one based on a convolutional neural network (DGCNN) and the other on visual transformers (point transformer), with human performance. We found that the point transformer model provided a better account of human performance than the convolution-based model. The advantage mainly results from the mechanism in the point transformer model that supports hierarchical abstraction of 3D shapes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Both humans and deep learning models can recognize objects from 3D shapesdepicted with sparse visual information, such as a set of points randomlysampled from the surfaces of 3D objects (termed a point cloud). Although deeplearning models achieve human-like performance in recognizing objects from 3Dshapes, it remains unclear whether these models develop 3D shaperepresentations similar to those used by human vision for object recognition.We hypothesize that training with 3D shapes enables models to formrepresentations of local geometric structures in 3D shapes. However, theirrepresentations of global 3D object shapes may be limited. We conducted twohuman experiments systematically manipulating point density and objectorientation (Experiment 1), and local geometric structure (Experiment 2).Humans consistently performed well across all experimental conditions. Wecompared two types of deep learning models, one based on a convolutional neuralnetwork (DGCNN) and the other on visual transformers (point transformer), withhuman performance. We found that the point transformer model provided a betteraccount of human performance than the convolution-based model. The advantagemainly results from the mechanism in the point transformer model that supportshierarchical abstraction of 3D shapes.</description>
      <author>example@mail.com (Shuhao Fu, Philip J. Kellman, Hongjing Lu)</author>
      <guid isPermaLink="false">2507.09830v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>ViTCoT: Video-Text Interleaved Chain-of-Thought for Boosting Video Understanding in Large Language Models</title>
      <link>http://arxiv.org/abs/2507.09876v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACM MM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的视频推理范式，即视频-文本交织的思考链（ViTCoT），以促进更直观和认知上对齐的推理。&lt;h4&gt;背景&lt;/h4&gt;视频理解在连接低级视觉信号和高级认知推理中扮演着关键角色，对自动驾驶、具身AI和更广泛的通用人工智能（AGI）的追求至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过引入ViTCoT范式，旨在提高视频推理能力，并使其更接近人类的推理过程。&lt;h4&gt;方法&lt;/h4&gt;首先构建了视频-文本交织基准（ViTIB），该基准使用多语言模型进行关键视频选择，并经过人工验证。接着，广泛探索了ViTCoT范式在视频理解领域的潜力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与传统的仅文本的思考链范式相比，ViTCoT显著提高了性能，并且有效地激活了多语言模型中的更多神经元。&lt;h4&gt;结论&lt;/h4&gt;ViTCoT范式在视频理解领域具有显著优势，能够促进更高效和直观的视频推理过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding plays a vital role in bridging low-level visual signalswith high-level cognitive reasoning, and is fundamental to applications such asautonomous driving, embodied AI, and the broader pursuit of AGI. The rapiddevelopment of large language models (LLMs), particularly those utilizingChain-of-Thought (CoT) technology, has significantly advanced video reasoningcapabilities. However, current approaches primarily depend on textualinformation for reasoning, overlooking the visual modality in the actual videoreasoning process. In contrast, humans naturally re-examine visual contentwhile reasoning. Motivated by this, we introduce a novel video reasoningparadigm: Video-Text Interleaved CoT (ViTCoT), which facilitates more intuitiveand cognitively aligned reasoning. To the end, first, we construct theVideo-Text Interleaved Benchmark (ViTIB), which is created using MLLMs forkey-video selection and manually verified. Furthermore, we extensively explorethe potential of the ViTCoT paradigm in the video understanding field.Extensive experiments demonstrate that ViTCoT significantly enhancesperformance compared to the traditional text-only CoT paradigm and effectivelyactivates more neuron values in MLLMs.</description>
      <author>example@mail.com (Yongheng Zhang, Xu Liu, Ruihan Tao, Qiguang Chen, Hao Fei, Wanxiang Che, Libo Qin)</author>
      <guid isPermaLink="false">2507.09876v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images</title>
      <link>http://arxiv.org/abs/2507.10202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR 2025 Workshop on Emergent Visual Abilities and  Limits of Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为ECP的框架，旨在提升MLLM在处理高分辨率图像时的性能。&lt;h4&gt;背景&lt;/h4&gt;MLLM在视觉-语言理解、推理和生成方面表现出色，但在需要精细定位和推理的任务上表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出ECP框架，以解决MLLM在高分辨率图像上的性能问题。&lt;h4&gt;方法&lt;/h4&gt;ECP是一个无需训练、任务无关的两阶段框架，通过先识别候选区域，然后基于候选区域预测最终输出，以保留精细细节并减轻高分辨率数据带来的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;在4K GUI grounding和4K、8K MLLM感知任务上，ECP框架相较于基线分别实现了+21.3%、+5.8%、+5.2%的绝对性能提升。&lt;h4&gt;结论&lt;/h4&gt;ECP框架有效提升了MLLM在高分辨率图像上的性能。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in vision-language understanding, reasoning, and generation. However, they struggle with tasks requiring fine-grained localization and reasoning in high-resolution images. This constraint stems from the fact that MLLMs are fine-tuned with fixed image resolution to align with the pre-trained image encoder used in MLLM. Consequently, feeding high-resolution images directly into MLLMs leads to poor generalization due to a train-test resolution discrepancy, while downsampling these images - although ensuring consistency - compromises fine-grained visual details and ultimately degrades performance. To address this challenge, we propose Extract Candidate then Predict (ECP), a novel training-free, task-agnostic two-stage framework designed to enhance MLLM performance on high-resolution images. The key intuition behind ECP is that while MLLMs struggle with high-resolution images, their predictions on downsampled images still contain implicit localization cues. By first identifying candidate region using the coarse prediction and then predicting the final output based on candidate region, ECP effectively preserves fine-grained details while mitigating the challenges posed by high-resolution data. We validate our framework on 4K GUI grounding and 4K, 8K MLLM perception, achieving +21.3%, +5.8%, +5.2% absolute improvement compared to baseline respectively, demonstrating its effectiveness. Code is available at https://github.com/yenncye/ECP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have demonstrated remarkablecapabilities in vision-language understanding, reasoning, and generation.However, they struggle with tasks requiring fine-grained localization andreasoning in high-resolution images. This constraint stems from the fact thatMLLMs are fine-tuned with fixed image resolution to align with the pre-trainedimage encoder used in MLLM. Consequently, feeding high-resolution imagesdirectly into MLLMs leads to poor generalization due to a train-test resolutiondiscrepancy, while downsampling these images-although ensuringconsistency-compromises fine-grained visual details and ultimately degradesperformance. To address this challenge, we propose Extract Candidate thenPredict (ECP), a novel training-free, task-agnostic two-stage frameworkdesigned to enhance MLLM performance on high-resolution images. The keyintuition behind ECP is that while MLLMs struggle with high-resolution images,their predictions on downsampled images still contain implicit localizationcues. By first identifying candidate region using the coarse prediction andthen predicting the final output based on candidate region, ECP effectivelypreserves fine-grained details while mitigating the challenges posed byhigh-resolution data. We validate our framework on 4K GUI grounding and 4K, 8KMLLM perception, achieving +21.3%, +5.8%, +5.2% absolute improvement comparedto baseline respectively, demonstrating its effectiveness. Code is available athttps://github.com/yenncye/ECP.</description>
      <author>example@mail.com (Jaeseong Lee, Yeeun Choi, Heechan Choi, Hanjung Kim, Seonjoo Kim)</author>
      <guid isPermaLink="false">2507.10202v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised pretraining of vision transformers for animal behavioral analysis and neural encoding</title>
      <link>http://arxiv.org/abs/2507.09513v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BEAST的新框架，用于神经行为分析，通过预训练视觉Transformer来解决视频数据分析中的挑战。&lt;h4&gt;背景&lt;/h4&gt;现代神经科学研究强调通过行为来理解大脑，但视频数据分析通常需要大量标记数据，存在技术挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需大量标记数据即可进行神经行为分析的框架。&lt;h4&gt;方法&lt;/h4&gt;BEAST结合了掩码自编码和时序对比学习，以有效利用未标记的视频数据，并预训练特定于实验的视觉Transformer。&lt;h4&gt;主要发现&lt;/h4&gt;在多个物种的全面评估中，BEAST在三个关键神经行为任务中表现出改进性能：提取与神经活动相关的行为特征，以及单和多动物环境中的姿态估计和动作分割。&lt;h4&gt;结论&lt;/h4&gt;BEAST建立了一个强大且通用的骨干模型，加速了在标记数据稀缺的场景中的行为分析。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过行为来全面理解大脑是现代神经科学研究的一个指导原则，尽管这带来了显著的技术挑战。许多研究使用摄像头捕捉行为，但视频分析方法通常依赖于需要大量标记数据的专用模型。我们通过BEAST（通过Transformer的自监督预训练进行行为分析）解决了这一局限性，这是一个新颖且可扩展的框架，用于为不同的神经行为分析预训练特定于实验的视觉Transformer。BEAST结合了掩码自编码和时序对比学习，以有效地利用未标记的视频数据。通过跨多个物种的全面评估，我们在三个关键的神经行为任务中证明了性能的提高：提取与神经活动相关的行为特征，以及在单和多动物环境中的姿态估计和动作分割。我们的方法建立了一个强大且通用的骨干模型，加速了在标记数据稀缺的场景中的行为分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The brain can only be fully understood through the lens of the behavior itgenerates -- a guiding principle in modern neuroscience research thatnevertheless presents significant technical challenges. Many studies capturebehavior with cameras, but video analysis approaches typically rely onspecialized models requiring extensive labeled data. We address this limitationwith BEAST (BEhavioral Analysis via Self-supervised pretraining ofTransformers), a novel and scalable framework that pretrainsexperiment-specific vision transformers for diverse neuro-behavior analyses.BEAST combines masked autoencoding with temporal contrastive learning toeffectively leverage unlabeled video data. Through comprehensive evaluationacross multiple species, we demonstrate improved performance in three criticalneuro-behavioral tasks: extracting behavioral features that correlate withneural activity, and pose estimation and action segmentation in both thesingle- and multi-animal settings. Our method establishes a powerful andversatile backbone model that accelerates behavioral analysis in scenarioswhere labeled data remains scarce.</description>
      <author>example@mail.com (Yanchen Wang, Han Yu, Ari Blau, Yizi Zhang, The International Brain Laboratory, Liam Paninski, Cole Hurwitz, Matt Whiteway)</author>
      <guid isPermaLink="false">2507.09513v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>ViSP: A PPO-Driven Framework for Sarcasm Generation with Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.09482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为M2SaG的多模态讽刺生成数据集和一种名为ViSP的生成框架，用于提高讽刺文本生成的质量。&lt;h4&gt;背景&lt;/h4&gt;讽刺是一种复杂的情绪表达，目前讽刺生成研究主要依赖文本模式，忽视视觉线索，并且现有数据集中图像内容和讽刺意图不匹配。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了M2SaG数据集和ViSP生成框架。&lt;h4&gt;方法&lt;/h4&gt;M2SaG包含4,970个样本，每个样本包含一个图像、一段讽刺文本和讽刺目标。ViSP框架结合了近端策略优化（PPO）和对比学习，使用DIP的奖励分数引导生成讽刺文本。&lt;h4&gt;主要发现&lt;/h4&gt;ViSP在五个指标集中超越了所有基线，包括大型语言模型，表明这些模型在讽刺生成方面存在局限性。生成的文本在讽刺得分和事实不协调度上均高于原始数据集。&lt;h4&gt;结论&lt;/h4&gt;M2SaG和ViSP有助于提高讽刺文本生成的质量，并揭示了大型语言模型在讽刺生成方面的局限性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类情感复杂，讽刺是一种微妙且独特的表达形式。尽管讽刺研究取得进展，但讽刺生成仍被低估，这主要归因于对文本模式的过度依赖、忽视视觉线索以及现有数据集中图像内容与讽刺意图的不匹配。在本文中，我们引入了M2SaG，这是一个包含4,970个样本的多模态讽刺生成数据集，每个样本包含一个图像、一段讽刺文本和讽刺目标。为了评估M2SaG，我们提出了ViSP，一个集成近端策略优化（PPO）和对比学习的生成框架。PPO利用DIP的奖励分数来引导讽刺文本的生成，而对比学习鼓励模型倾向于产生更高奖励分数的输出。这些策略提高了整体生成质量，并产生了更具讽刺意图的文本。我们在五个指标集中评估了ViSP，发现它超越了所有基线，包括大型语言模型，这表明这些模型在讽刺生成方面存在局限性。此外，我们还分析了M2SaG和ViSP生成的文本的讽刺得分和事实不协调度的分布。生成的文本表现出更高的平均讽刺得分（0.898 vs. 0.770）和事实不协调度（0.768 vs. 0.739），这表明ViSP生成的讽刺内容质量高于原始数据集。数据集和代码将在https://github.com/wclapply/ViSP公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human emotions are complex, with sarcasm being a subtle and distinctive form.Despite progress in sarcasm research, sarcasm generation remains underexplored,primarily due to the overreliance on textual modalities and the neglect ofvisual cues, as well as the mismatch between image content and sarcastic intentin existing datasets. In this paper, we introduce M2SaG, a multimodal sarcasmgeneration dataset with 4,970 samples, each containing an image, a sarcastictext, and a sarcasm target. To benchmark M2SaG, we propose ViSP, a generationframework that integrates Proximal Policy Optimization (PPO) and contrastivelearning. PPO utilizes reward scores from DIP to steer the generation ofsarcastic texts, while contrastive learning encourages the model to favoroutputs with higher reward scores. These strategies improve overall generationquality and produce texts with more pronounced sarcastic intent. We evaluateViSP across five metric sets and find it surpasses all baselines, includinglarge language models, underscoring their limitations in sarcasm generation.Furthermore, we analyze the distributions of Sarcasm Scores and FactualIncongruity for both M2SaG and the texts generated by ViSP. The generated textsexhibit higher mean Sarcasm Scores (0.898 vs. 0.770) and Factual Incongruity(0.768 vs. 0.739), demonstrating that ViSP produces higher-quality sarcasticcontent than the original dataset. % The dataset and code will be publiclyavailable. Our dataset and code will be released at\textit{https://github.com/wclapply/ViSP}.</description>
      <author>example@mail.com (Changli Wang, Rui Wu, Fang Yin)</author>
      <guid isPermaLink="false">2507.09482v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Fast3D: Accelerating 3D Multi-modal Large Language Models for Efficient 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2507.09334v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACM MM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Fast3D，一个针对3D MLLMs的视觉token剪枝框架，旨在解决3D MLLMs部署中的计算效率问题。&lt;h4&gt;背景&lt;/h4&gt;3D MLLMs在场景理解方面表现出色，但计算效率低是其实际部署面临的关键挑战，主要瓶颈在于处理过多的对象中心视觉token。&lt;h4&gt;目的&lt;/h4&gt;通过剪枝技术提高3D MLLMs的计算效率。&lt;h4&gt;方法&lt;/h4&gt;提出了Fast3D框架，包括全球注意力预测（GAP）和样本自适应视觉token剪枝（SAP）两个技术创新。&lt;h4&gt;主要发现&lt;/h4&gt;（1）3D对象级token表示中存在显著冗余，类似于2D系统中的patch级冗余；（2）全局注意力模式对识别3D场景中的非必需token具有强大的预测能力。&lt;h4&gt;结论&lt;/h4&gt;Fast3D在五个基准测试中验证了其有效性，尤其是在高视觉token剪枝比例下。&lt;h4&gt;翻译&lt;/h4&gt;尽管3D多模态大型语言模型（MLLMs）展示了令人瞩目的场景理解能力，但由于计算效率低下，其实际部署面临重大挑战。主要瓶颈来自于为全面表示3D场景而必须处理的过多的以对象为中心的视觉token。尽管视觉token剪枝在加速2D MLLMs方面已显示出前景，但由于token结构的根本差异，其在3D领域的适用性仍未得到充分探索。在本文中，我们揭示了两个关键见解：（1）在3D对象级token表示中存在显著的冗余，类似于2D系统中的patch级冗余；（2）全局注意力模式对识别3D上下文中的非必要token具有强大的预测能力。基于这些观察，我们提出了Fast3D，一个适用于3D MLLMs的即插即用视觉token剪枝框架，具有两个技术创新：（1）全球注意力预测（GAP），其中轻量级神经网络学习预测目标模型的全球注意力分布，从而实现高效的token重要性估计，为精确剪枝提供指导；（2）样本自适应视觉token剪枝（SAP），它通过基于注意力的复杂性评估引入动态token预算，根据输入特征自动调整层间剪枝比例。这两个技术都不会修改目标模型的参数。在五个基准测试中进行的广泛评估验证了Fast3D的有效性，特别是在高视觉token剪枝比例下。代码可在https://github.com/wencan25/Fast3D获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While 3D Multi-modal Large Language Models (MLLMs) demonstrate remarkablescene understanding capabilities, their practical deployment faces criticalchallenges due to computational inefficiency. The key bottleneck stems fromprocessing excessive object-centric visual tokens required for comprehensive 3Dscene representation. Although visual token pruning has shown promise inaccelerating 2D MLLMs, its applicability to 3D domains remains largelyunexplored due to fundamental disparities in token structures. In this paper,we reveal two critical insights: (1) Significant redundancy exists inobject-level 3D token representations, analogous to patch-level redundancy in2D systems; (2) Global attention patterns exhibit strong predictive power foridentifying non-essential tokens in 3D contexts. Building on theseobservations, we propose Fast3D, a plug-and-play visual token pruning frameworkfor 3D MLLMs featuring two technical innovations: (1) Global AttentionPrediction (GAP), where a lightweight neural network learns to predict theglobal attention distributions of the target model, enabling efficient tokenimportance estimation for precise pruning guidance; (2) Sample-Adaptive visualtoken Pruning (SAP), which introduces dynamic token budgets throughattention-based complexity assessment, automatically adjusting layer-wisepruning ratios based on input characteristics. Both of these two techniquesoperate without modifying the parameters of the target model. Extensiveevaluations across five benchmarks validate the effectiveness of Fast3D,particularly under high visual token pruning ratios. Code is available athttps://github.com/wencan25/Fast3D</description>
      <author>example@mail.com (Wencan Huang, Daizong Liu, Wei Hu)</author>
      <guid isPermaLink="false">2507.09334v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Learning Private Representations through Entropy-based Adversarial Training</title>
      <link>http://arxiv.org/abs/2507.10194v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种对抗性表示学习方法，用于从学习到的表示中净化敏感内容，同时保持用户隐私。&lt;h4&gt;背景&lt;/h4&gt;研究如何在学习表示时保持高预测力和用户隐私。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，能够在保护用户隐私的同时学习具有高预测力的表示。&lt;h4&gt;方法&lt;/h4&gt;引入了一种熵的变体——焦点熵，以减少现有基于熵的方法潜在的信息泄露。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准测试中展示了方法的可行性，结果表明在适度的隐私泄露下具有高的目标效用。&lt;h4&gt;结论&lt;/h4&gt;该方法在保持用户隐私的同时，实现了高预测力的表示学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：我们如何在学习具有高预测力的表示的同时保护用户隐私？我们提出了一种对抗性表示学习方法，用于从学习到的表示中净化敏感内容。具体来说，我们引入了一种熵的变体——焦点熵，以缓解现有基于熵的方法潜在的信息泄露。我们在多个基准测试中展示了其可行性。结果表明，在适度的隐私泄露下，具有高的目标效用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How can we learn a representation with high predictive power while preservinguser privacy? We present an adversarial representation learning method forsanitizing sensitive content from the learned representation. Specifically, weintroduce a variant of entropy - focal entropy, which mitigates the potentialinformation leakage of the existing entropy-based approaches. We showcasefeasibility on multiple benchmarks. The results suggest high target utility atmoderate privacy leakage.</description>
      <author>example@mail.com (Tassilo Klein, Moin Nabi)</author>
      <guid isPermaLink="false">2507.10194v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Low-Rank Adaptation of Deep Prior Neural Networks For Room Impulse Response Reconstruction</title>
      <link>http://arxiv.org/abs/2507.09806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to appear in IEEE WASPAA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了Deep Prior框架，这是一种强大的生成工具，可以从少量的稀疏压力测量中重建环境中的声场。论文提出了通过低秩自适应（LoRA）进行迁移学习，以提高Deep Prior的适应新声学配置的能力，从而减少了重新训练的必要。&lt;h4&gt;背景&lt;/h4&gt;Deep Prior框架在重建声场方面表现出色，但其局限性在于无法泛化到新的声学配置，如声源位置的变化，需要重新训练网络。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过迁移学习改进Deep Prior框架，使其能够适应新的测量集，减少重新训练的时间和计算成本。&lt;h4&gt;方法&lt;/h4&gt;使用LoRA技术对预训练的神经网络进行微调，通过引入可训练参数的低秩分解，实现网络对新测量集的适应。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，通过完全微调或LoRA微调，当声源位置是唯一变化的参数时，可以保持高物理保真度，证明了迁移学习在声学应用中的价值。&lt;h4&gt;结论&lt;/h4&gt;LoRA是一种有效的迁移学习方法，可以显著提高Deep Prior框架的适应新声学配置的能力，减少重新训练的需要。&lt;h4&gt;翻译&lt;/h4&gt;The Deep Prior framework has emerged as a powerful generative tool which can be used for reconstructing sound fields in an environment from few sparse pressure measurements. It employs a neural network that is trained solely on a limited set of available data and acts as an implicit prior which guides the solution of the underlying optimization problem. However, a significant limitation of the Deep Prior approach is its inability to generalize to new acoustic configurations, such as changes in the position of a sound source. As a consequence, the network must be retrained from scratch for every new setup, which is both computationally intensive and time-consuming. To address this, we investigate transfer learning in Deep Prior via Low-Rank Adaptation (LoRA), which enables efficient fine-tuning of a pre-trained neural network by introducing a low-rank decomposition of trainable parameters, thus allowing the network to adapt to new measurement sets with minimal computational overhead. We embed LoRA into a MultiResUNet-based Deep Prior model and compare its adaptation performance against full fine-tuning of all parameters as well as classical retraining, particularly in scenarios where only a limited number of microphones are used. The results indicate that fine-tuning, whether done completely or via LoRA, is especially advantageous when the source location is the sole changing parameter, preserving high physical fidelity, and highlighting the value of transfer learning for acoustics applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Deep Prior framework has emerged as a powerful generative tool which canbe used for reconstructing sound fields in an environment from few sparsepressure measurements. It employs a neural network that is trained solely on alimited set of available data and acts as an implicit prior which guides thesolution of the underlying optimization problem. However, a significantlimitation of the Deep Prior approach is its inability to generalize to newacoustic configurations, such as changes in the position of a sound source. Asa consequence, the network must be retrained from scratch for every new setup,which is both computationally intensive and time-consuming. To address this, weinvestigate transfer learning in Deep Prior via Low-Rank Adaptation (LoRA),which enables efficient fine-tuning of a pre-trained neural network byintroducing a low-rank decomposition of trainable parameters, thus allowing thenetwork to adapt to new measurement sets with minimal computational overhead.We embed LoRA into a MultiResUNet-based Deep Prior model and compare itsadaptation performance against full fine-tuning of all parameters as well asclassical retraining, particularly in scenarios where only a limited number ofmicrophones are used. The results indicate that fine-tuning, whether donecompletely or via LoRA, is especially advantageous when the source location isthe sole changing parameter, preserving high physical fidelity, andhighlighting the value of transfer learning for acoustics applications.</description>
      <author>example@mail.com (Mirco Pezzoli, Federico Miotello, Shoichi Koyama, Fabio Antonacci)</author>
      <guid isPermaLink="false">2507.09806v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Ambiguity-Aware and High-Order Relation Learning for Multi-Grained Image-Text Matching</title>
      <link>http://arxiv.org/abs/2507.09256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by the Knowledge-Based Systems(KBS), 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AAHR的图像-文本匹配框架，旨在解决现有方法在处理高阶关联和语义模糊性方面的挑战，并通过实验证明其在多个数据集上优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;图像-文本匹配对于弥合计算机视觉和自然语言处理之间的语义鸿沟至关重要，但现有方法在处理高阶关联和语义模糊性方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出AAHR框架，以解决图像-文本匹配中的高阶关联和语义模糊性问题。&lt;h4&gt;方法&lt;/h4&gt;AAHR通过动态聚类原型对比学习构建统一表示空间，引入全局和局部特征提取机制以及自适应聚合网络，并使用GNN增强实例间的语义交互，同时整合动量对比学习以扩展负样本集。&lt;h4&gt;主要发现&lt;/h4&gt;AAHR在Flickr30K、MSCOCO和ECCV Caption数据集上优于现有方法，显著提高了图像-文本匹配的准确性和效率。&lt;h4&gt;结论&lt;/h4&gt;AAHR框架能够有效提高图像-文本匹配的性能。&lt;h4&gt;翻译&lt;/h4&gt;Image-text matching is crucial for bridging the semantic gap between computer vision and natural language processing. However, existing methods still face challenges in handling high-order associations and semantic ambiguities among similar instances. These ambiguities arise from subtle differences between soft positive samples (semantically similar but incorrectly labeled) and soft negative samples (locally matched but globally inconsistent), creating matching uncertainties. Furthermore, current methods fail to fully utilize the neighborhood relationships among semantically similar instances within training batches, limiting the model's ability to learn high-order shared knowledge. This paper proposes the Ambiguity-Aware and High-order Relation learning framework (AAHR) to address these issues. AAHR constructs a unified representation space through dynamic clustering prototype contrastive learning, effectively mitigating the soft positive sample problem. The framework introduces global and local feature extraction mechanisms and an adaptive aggregation network, significantly enhancing full-grained semantic understanding capabilities. Additionally, AAHR employs intra-modal and inter-modal correlation matrices to investigate neighborhood relationships among sample instances thoroughly. It incorporates GNN to enhance semantic interactions between instances. Furthermore, AAHR integrates momentum contrastive learning to expand the negative sample set. These combined strategies significantly improve the model's ability to discriminate between features. Experimental results demonstrate that AAHR outperforms existing state-of-the-art methods on Flickr30K, MSCOCO, and ECCV Caption datasets, considerably improving the accuracy and efficiency of image-text matching. The code and model checkpoints for this research are available at https://github.com/Image-Text-Matching/AAHR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.knosys.2025.113355&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-text matching is crucial for bridging the semantic gap between computervision and natural language processing. However, existing methods still facechallenges in handling high-order associations and semantic ambiguities amongsimilar instances. These ambiguities arise from subtle differences between softpositive samples (semantically similar but incorrectly labeled) and softnegative samples (locally matched but globally inconsistent), creating matchinguncertainties. Furthermore, current methods fail to fully utilize theneighborhood relationships among semantically similar instances within trainingbatches, limiting the model's ability to learn high-order shared knowledge.This paper proposes the Ambiguity-Aware and High-order Relation learningframework (AAHR) to address these issues. AAHR constructs a unifiedrepresentation space through dynamic clustering prototype contrastive learning,effectively mitigating the soft positive sample problem. The frameworkintroduces global and local feature extraction mechanisms and an adaptiveaggregation network, significantly enhancing full-grained semanticunderstanding capabilities. Additionally, AAHR employs intra-modal andinter-modal correlation matrices to investigate neighborhood relationshipsamong sample instances thoroughly. It incorporates GNN to enhance semanticinteractions between instances. Furthermore, AAHR integrates momentumcontrastive learning to expand the negative sample set. These combinedstrategies significantly improve the model's ability to discriminate betweenfeatures. Experimental results demonstrate that AAHR outperforms existingstate-of-the-art methods on Flickr30K, MSCOCO, and ECCV Caption datasets,considerably improving the accuracy and efficiency of image-text matching. Thecode and model checkpoints for this research are available athttps://github.com/Image-Text-Matching/AAHR .</description>
      <author>example@mail.com (Junyu Chen, Yihua Gao, Mingyuan Ge, Mingyong Li)</author>
      <guid isPermaLink="false">2507.09256v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Soft Graph Clustering for single-cell RNA Sequencing Data</title>
      <link>http://arxiv.org/abs/2507.09890v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了scSGC，一种用于单细胞RNA测序数据软图聚类的算法，旨在更准确地描述细胞之间的连续相似性，以提高聚类准确性和细胞类型注释的效率。&lt;h4&gt;背景&lt;/h4&gt;聚类分析是单细胞RNA测序数据分析中阐明细胞异质性和多样性的基本方法。现有的基于图的单细胞RNA测序聚类方法，特别是图神经网络（GNNs），在处理高维、高稀疏和频繁的dropout事件方面取得了显著进展，但这些方法依赖于由阈值相似性矩阵导出的硬图构造，存在局限性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述局限性，scSGC旨在通过非二进制边权重更准确地描述细胞之间的连续相似性，从而减轻刚性数据结构的限制。&lt;h4&gt;方法&lt;/h4&gt;scSGC框架包括三个核心组件：(i)基于零膨胀负二项分布（ZINB）的特征自动编码器；(ii)双通道切信息软图嵌入模块；(iii)基于最优传输的聚类优化模块。&lt;h4&gt;主要发现&lt;/h4&gt;在十个数据集上的广泛实验表明，scSGC在聚类准确度、细胞类型注释和计算效率方面优于13个最先进的聚类模型。&lt;h4&gt;结论&lt;/h4&gt;scSGC具有显著潜力推动单细胞RNA测序数据分析，并深化我们对细胞异质性的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Clustering analysis is fundamental in single-cell RNA sequencing (scRNA-seq)data analysis for elucidating cellular heterogeneity and diversity. Recentgraph-based scRNA-seq clustering methods, particularly graph neural networks(GNNs), have significantly improved in tackling the challenges ofhigh-dimension, high-sparsity, and frequent dropout events that lead toambiguous cell population boundaries. However, their reliance on hard graphconstructions derived from thresholded similarity matrices presentschallenges:(i) The simplification of intercellular relationships into binaryedges (0 or 1) by applying thresholds, which restricts the capture ofcontinuous similarity features among cells and leads to significant informationloss.(ii) The presence of significant inter-cluster connections within hardgraphs, which can confuse GNN methods that rely heavily on graph structures,potentially causing erroneous message propagation and biased clusteringoutcomes. To tackle these challenges, we introduce scSGC, a Soft GraphClustering for single-cell RNA sequencing data, which aims to more accuratelycharacterize continuous similarities among cells through non-binary edgeweights, thereby mitigating the limitations of rigid data structures. The scSGCframework comprises three core components: (i) a zero-inflated negativebinomial (ZINB)-based feature autoencoder; (ii) a dual-channel cut-informedsoft graph embedding module; and (iii) an optimal transport-based clusteringoptimization module. Extensive experiments across ten datasets demonstrate thatscSGC outperforms 13 state-of-the-art clustering models in clustering accuracy,cell type annotation, and computational efficiency. These results highlight itssubstantial potential to advance scRNA-seq data analysis and deepen ourunderstanding of cellular heterogeneity.</description>
      <author>example@mail.com (Ping Xu, Pengfei Wang, Zhiyuan Ning, Meng Xiao, Min Wu, Yuanchun Zhou)</author>
      <guid isPermaLink="false">2507.09890v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>SegVec3D: A Method for Vector Embedding of 3D Objects Oriented Towards Robot manipulation</title>
      <link>http://arxiv.org/abs/2507.09459v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Undergraduate Theis; 12 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了SegVec3D，这是一种新型的3D点云实例分割框架，集成了注意力机制、嵌入学习和跨模态对齐。&lt;h4&gt;背景&lt;/h4&gt;针对3D点云实例分割问题，提出了一种新的方法。&lt;h4&gt;目的&lt;/h4&gt;实现高效且具有实际应用性的3D点云实例分割。&lt;h4&gt;方法&lt;/h4&gt;构建了一个分层特征提取器，以增强几何结构建模，并通过对比聚类实现无监督实例分割。此外，将3D数据与自然语言查询对齐到共享语义空间中，支持零样本检索。&lt;h4&gt;主要发现&lt;/h4&gt;与Mask3D和ULIP等最近的方法相比，该方法独特地统一了实例分割和多模态理解，最小化监督需求且具有实际部署能力。&lt;h4&gt;结论&lt;/h4&gt;SegVec3D框架在3D点云实例分割方面提供了新的解决方案，具有良好的性能和应用前景。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为SegVec3D的新型框架，用于3D点云实例分割，该框架集成了注意力机制、嵌入学习和跨模态对齐。该方法构建了一个分层特征提取器，以增强几何结构建模，并允许通过对比聚类进行无监督实例分割。此外，它进一步将3D数据与自然语言查询对齐到共享语义空间中，以支持零样本检索。与最近的方法（如Mask3D和ULIP）相比，我们的方法独特地将实例分割和多模态理解统一起来，具有最少的监督需求和实际部署性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose SegVec3D, a novel framework for 3D point cloud instancesegmentation that integrates attention mechanisms, embedding learning, andcross-modal alignment. The approach builds a hierarchical feature extractor toenhance geometric structure modeling and enables unsupervised instancesegmentation via contrastive clustering. It further aligns 3D data with naturallanguage queries in a shared semantic space, supporting zero-shot retrieval.Compared to recent methods like Mask3D and ULIP, our method uniquely unifiesinstance segmentation and multimodal understanding with minimal supervision andpractical deployability.</description>
      <author>example@mail.com (Zhihan Kang, Boyu Wang)</author>
      <guid isPermaLink="false">2507.09459v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>DEARLi: Decoupled Enhancement of Recognition and Localization for Semi-supervised Panoptic Segmentation</title>
      <link>http://arxiv.org/abs/2507.10118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025 Findings Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的半监督全景分割方法，通过两个专门的基础模型来应对标签稀缺的问题，显著提高了半监督语义分割的性能。&lt;h4&gt;背景&lt;/h4&gt;像素级标注既昂贵又耗时，半监督分割方法通过在少量标注图像和大量未标注图像上学习模型来解决这个问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的半监督全景分割方法，以应对标签稀缺的挑战。&lt;h4&gt;方法&lt;/h4&gt;该方法包括两个专门的基础模型，通过增强识别和定位能力来提高分割效果。具体来说，通过补充无监督掩码转换器一致性以及零样本分类CLIP特征来增强识别，通过基于SAM伪标签的无类别解码器预热来增强定位。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在具有大量分类和有限标注数据的具有挑战性的半监督场景中表现出色，同时在半监督语义分割方面超越了现有技术，同时所需的GPU内存减少了8倍。&lt;h4&gt;结论&lt;/h4&gt;该方法在ADE20K数据集上，仅使用158个标注图像就实现了29.9 PQ和38.9 mIoU，证明了其在减少资源需求的同时，显著提升了分割性能。&lt;h4&gt;翻译&lt;/h4&gt;Pixel-level annotation is expensive and time-consuming. Semi-supervised segmentation methods address this challenge by learning models on few labeled images alongside a large corpus of unlabeled images. Although foundation models could further account for label scarcity, effective mechanisms for their exploitation remain underexplored. We address this by devising a novel semi-supervised panoptic approach fueled by two dedicated foundation models. We enhance recognition by complementing unsupervised mask-transformer consistency with zero-shot classification of CLIP features. We enhance localization by class-agnostic decoder warm-up with respect to SAM pseudo-labels. The resulting decoupled enhancement of recognition and localization (DEARLi) particularly excels in the most challenging semi-supervised scenarios with large taxonomies and limited labeled data. Moreover, DEARLi outperforms the state of the art in semi-supervised semantic segmentation by a large margin while requiring 8x less GPU memory, in spite of being trained only for the panoptic objective. We observe 29.9 PQ and 38.9 mIoU on ADE20K with only 158 labeled images. The source code is available at https://github.com/helen1c/DEARLi.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pixel-level annotation is expensive and time-consuming. Semi-supervisedsegmentation methods address this challenge by learning models on few labeledimages alongside a large corpus of unlabeled images. Although foundation modelscould further account for label scarcity, effective mechanisms for theirexploitation remain underexplored. We address this by devising a novelsemi-supervised panoptic approach fueled by two dedicated foundation models. Weenhance recognition by complementing unsupervised mask-transformer consistencywith zero-shot classification of CLIP features. We enhance localization byclass-agnostic decoder warm-up with respect to SAM pseudo-labels. The resultingdecoupled enhancement of recognition and localization (DEARLi) particularlyexcels in the most challenging semi-supervised scenarios with large taxonomiesand limited labeled data. Moreover, DEARLi outperforms the state of the art insemi-supervised semantic segmentation by a large margin while requiring 8x lessGPU memory, in spite of being trained only for the panoptic objective. Weobserve 29.9 PQ and 38.9 mIoU on ADE20K with only 158 labeled images. Thesource code is available at https://github.com/helen1c/DEARLi.</description>
      <author>example@mail.com (Ivan Martinović, Josip Šarić, Marin Oršić, Matej Kristan, Siniša Šegvić)</author>
      <guid isPermaLink="false">2507.10118v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Continental scale habitat modelling with artificial intelligence and multimodal earth observation</title>
      <link>http://arxiv.org/abs/2507.09732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了如何利用高分辨率遥感数据和人工智能工具改善大型地理范围内细粒度主题分辨率下的栖息地分类。&lt;h4&gt;背景&lt;/h4&gt;栖息地地图对于有效保护和恢复生态系统至关重要，但由于需要同时处理多个相互排斥的栖息地类型和严重的数据不平衡问题，现有地图在主题或空间分辨率上存在不足。&lt;h4&gt;目的&lt;/h4&gt;评估高分辨率遥感数据和人工智能工具在大型地理范围内细粒度主题分辨率下的栖息地分类效果。&lt;h4&gt;方法&lt;/h4&gt;使用欧洲植被档案中的植被样地，对欧洲的3级EUNIS栖息地进行建模，并对比多种建模策略对独立验证数据集的评估结果。&lt;h4&gt;主要发现&lt;/h4&gt;利用栖息地命名学的层次结构可以解决分类歧义，特别是在破碎化的景观中。集成多光谱和合成孔径雷达图像，尤其是通过地球观测基金会模型，提高了内部特征辨别和整体性能。集成机器学习进一步提高了准确率。&lt;h4&gt;结论&lt;/h4&gt;该方法论框架适用于欧洲以外的地区，并可根据其他分类系统进行调整。未来研究应进一步推进动态栖息地的时空建模，扩展到栖息地分割和质量评估，并利用下一代地球观测数据与高质量实地观测相结合。&lt;h4&gt;翻译&lt;/h4&gt;The abstract discusses how to improve habitat classification over large geographic extents at fine thematic resolution by using high-resolution remote sensing data and Artificial Intelligence (AI) tools. Background: Habitat maps are crucial for effective conservation and restoration of ecosystems, but existing maps often fall short in thematic or spatial resolution due to the need to handle multiple mutually exclusive habitat types and severe data imbalance issues. Aim: To evaluate the effectiveness of high-resolution remote sensing data and AI tools in habitat classification at fine thematic resolution over large geographic extents. Methods: Using vegetation plots from the European Vegetation Archive, the 3rd level EUNIS habitats across Europe were modeled, and the performance of various modeling strategies was assessed against independent validation datasets. Key Findings: Utilizing the hierarchical nature of habitat nomenclatures resolved classification ambiguities, especially in fragmented landscapes. Integrating multi-spectral and synthetic aperture radar imagery, particularly through Earth Observation Foundation models, enhanced within-formation discrimination and overall performance. Ensemble machine learning that corrects class imbalance further boosted accuracy. Conclusion: The methodology framework is applicable beyond Europe and adaptable to other classification systems. Future research should further advance temporal modeling of dynamic habitats, extend to habitat segmentation and quality assessment, and exploit next-generation EO data paired with higher-quality in-situ observations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Habitats integrate the abiotic conditions and biophysical structures thatsupport biodiversity and sustain nature's contributions to people. As theseecosystems face mounting pressure from human activities, accurate,high-resolution habitat maps are essential for effective conservation andrestoration. Yet current maps often fall short in thematic or spatialresolution because they must (1) model several mutually exclusive habitat typesthat co-occur across landscapes and (2) cope with severe class imbalance thatcomplicate multi-class training. Here, we evaluated how high-resolution remotesensing (RS) data and Artificial Intelligence (AI) tools can improve habitatclassification over large geographic extents at fine thematic resolution. Usingvegetation plots from the European Vegetation Archive, we modelled Level 3EUNIS habitats across Europe and assessed multiple modelling strategies againstindependent validation datasets. Strategies that exploited the hierarchicalnature of habitat nomenclatures resolved classification ambiguities, especiallyin fragmented landscapes. Integrating multi-spectral (MSI) and syntheticaperture radar (SAR) imagery, particularly through Earth Observation Foundationmodels, enhanced within-formation discrimination and overall performance.Finally, ensemble machine learning that corrects class imbalance boostedaccuracy further. Our methodological framework is transferable beyond Europeand adaptable to other classification systems. Future research should advancetemporal modelling of dynamic habitats, extend to habitat segmentation andquality assessment, and exploit next-generation EO data paired withhigher-quality in-situ observations.</description>
      <author>example@mail.com (Sara Si-Moussi, Stephan Hennekens, Sander Mucher, Stan Los, Wilfried Thuiller)</author>
      <guid isPermaLink="false">2507.09732v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Pre-trained Under Noise: A Framework for Robust Bone Fracture Detection in Medical Imaging</title>
      <link>http://arxiv.org/abs/2507.09731v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了预训练深度学习模型在X射线图像中分类骨骨折的鲁棒性，旨在通过技术手段解决全球医疗健康差异。&lt;h4&gt;背景&lt;/h4&gt;医学影像被认定为诊断不同骨骼相关疾病，尤其是骨折的关键工具。&lt;h4&gt;目的&lt;/h4&gt;探讨不同深度学习模型在X射线图像质量退化情况下的性能变化，以及噪声对骨骨折检测的影响。&lt;h4&gt;方法&lt;/h4&gt;测试了三种深度学习模型（ResNet50、VGG16和EfficientNetv2）在不同模拟设备质量条件下的性能，通过逐渐添加噪声来退化图像。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，通过迁移学习和控制噪声增强，可以评估AI模型退化，并提供了关于不同预训练深度学习计算机视觉模型在不同情境下鲁棒性和泛化能力的实际见解。&lt;h4&gt;结论&lt;/h4&gt;本文建立了评估AI模型退化的方法论框架，有助于复制全球医疗影像技术人员面临的现实挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical Imagings are considered one of the crucial diagnostic tools fordifferent bones-related diseases, especially bones fractures. This paperinvestigates the robustness of pre-trained deep learning models for classifyingbone fractures in X-ray images and seeks to address global healthcare disparitythrough the lens of technology. Three deep learning models have been testedunder varying simulated equipment quality conditions. ResNet50, VGG16 andEfficientNetv2 are the three pre-trained architectures which are compared.These models were used to perform bone fracture classification as images wereprogressively degraded using noise. This paper specifically empirically studieshow the noise can affect the bone fractures detection and how the pre-trainedmodels performance can be changes due to the noise that affect the quality ofthe X-ray images. This paper aims to help replicate real world challengesexperienced by medical imaging technicians across the world. Thus, this paperestablishes a methodological framework for assessing AI model degradation usingtransfer learning and controlled noise augmentation. The findings providepractical insight into how robust and generalizable different pre-trained deeplearning powered computer vision models can be when used in different contexts.</description>
      <author>example@mail.com (Robby Hoover, Nelly Elsayed, Zag ElSayed, Chengcheng Li)</author>
      <guid isPermaLink="false">2507.09731v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>A Scalable and Efficient Signal Integration System for Job Matching</title>
      <link>http://arxiv.org/abs/2507.09797v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  KDD2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LinkedIn在构建职位匹配推荐系统时面临冷启动、过滤泡和候选人与职位匹配偏见等建模挑战。&lt;h4&gt;背景&lt;/h4&gt;LinkedIn是全球最大的职业社交平台之一，在构建职位匹配推荐系统时遇到多种建模难题。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，开发了STAR系统，该系统结合了大型语言模型（LLM）和图神经网络（GNN）的优势。&lt;h4&gt;方法&lt;/h4&gt;STAR系统利用LLM在理解文本数据方面的优势，以及GNN在网络效应中缓解冷启动问题的能力。它通过工业规模的范式，包括自适应采样和版本管理，集成了多样化的信号。&lt;h4&gt;主要发现&lt;/h4&gt;STAR系统提供了一种构建大规模推荐系统中嵌入物的端到端解决方案，包括一个在工业应用中构建嵌入物的稳健方法论，一个用于高性能推荐的可扩展GNN-LLM集成，以及实际部署模型时的实用见解。&lt;h4&gt;结论&lt;/h4&gt;STAR系统为LinkedIn的职位匹配推荐系统提供了有效的解决方案，有助于提高推荐质量和用户体验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737185&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LinkedIn, one of the world's largest platforms for professional networkingand job seeking, encounters various modeling challenges in buildingrecommendation systems for its job matching product, including cold-start,filter bubbles, and biases affecting candidate-job matching. To address these,we developed the STAR (Signal Integration for Talent And Recruiters) system,leveraging the combined strengths of Large Language Models (LLMs) and GraphNeural Networks (GNNs). LLMs excel at understanding textual data, such asmember profiles and job postings, while GNNs capture intricate relationshipsand mitigate cold-start issues through network effects. STAR integrates diversesignals by uniting LLM and GNN capabilities with industrial-scale paradigmsincluding adaptive sampling and version management. It provides an end-to-endsolution for developing and deploying embeddings in large-scale recommendersystems. Our key contributions include a robust methodology for buildingembeddings in industrial applications, a scalable GNN-LLM integration forhigh-performing recommendations, and practical insights for real-world modeldeployment.</description>
      <author>example@mail.com (Ping Liu, Rajat Arora, Xiao Shi, Benjamin Le, Qianqi Shen, Jianqiang Shen, Chengming Jiang, Nikita Zhiltsov, Priya Bannur, Yidan Zhu, Liming Dong, Haichao Wei, Qi Guo, Luke Simon, Liangjie Hong, Wenjing Zhang)</author>
      <guid isPermaLink="false">2507.09797v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model Driven Robotics: A Comprehensive Review</title>
      <link>http://arxiv.org/abs/2507.10087v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基础模型，特别是大型语言模型（LLMs）和视觉-语言模型（VLMs）在机器人领域的快速发展和应用，探讨了这些模型在语义理解、高级推理和跨模态泛化方面的能力，以及它们对感知、规划、控制和人机交互的推动作用。&lt;h4&gt;背景&lt;/h4&gt;基础模型的快速发展，尤其是LLMs和VLMs，为机器人领域带来了变革性的范式。&lt;h4&gt;目的&lt;/h4&gt;对基础模型在机器人领域的应用进行结构化综述，评估其在现实环境中的实际可行性。&lt;h4&gt;方法&lt;/h4&gt;对仿真驱动设计、开放世界执行、模拟到现实迁移和适应性机器人等应用进行分类，并讨论了程序场景生成、策略泛化和多模态推理等关键趋势，以及局限性，如有限的实体、缺乏多模态数据、安全风险和计算约束。&lt;h4&gt;主要发现&lt;/h4&gt;识别了基于基础模型的机器人的架构优势和关键局限性，包括实时操作、接地、弹性和信任等方面的开放挑战。&lt;h4&gt;结论&lt;/h4&gt;提出了一个未来研究方向，旨在通过更稳健、可解释和具身化的模型来弥合语义推理和物理智能之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;The rapid emergence of foundation models, particularly Large Language Models(LLMs) and Vision-Language Models (VLMs), has introduced a transformative paradigm in robotics. These models offer powerful capabilities in semantic understanding, high-level reasoning, and cross-modal generalization, enabling significant advances in perception, planning, control, and human-robot interaction. This critical review provides a structured synthesis of recent developments, categorizing applications across simulation-driven design, open-world execution, sim-to-real transfer, and adaptable robotics. Unlike existing surveys that emphasize isolated capabilities, this work highlights integrated, system-level strategies and evaluates their practical feasibility in real-world environments. Key enabling trends such as procedural scenegeneration, policy generalization, and multimodal reasoning are discussed alongside core bottlenecks, including limited embodiment, lack of multimodal data, safety risks, and computational constraints. Through this lens, this paper identifies both the architectural strengths and critical limitations of foundation model-based robotics, highlighting open challenges in real-time operation, grounding, resilience, and trust. The review concludes with a roadmap for future research aimed at bridging semantic reasoning and physical intelligence through more robust, interpretable, and embodied models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid emergence of foundation models, particularly Large Language Models(LLMs) and Vision-Language Models (VLMs), has introduced a transformativeparadigm in robotics. These models offer powerful capabilities in semanticunderstanding, high-level reasoning, and cross-modal generalization, enablingsignificant advances in perception, planning, control, and human-robotinteraction. This critical review provides a structured synthesis of recentdevelopments, categorizing applications across simulation-driven design,open-world execution, sim-to-real transfer, and adaptable robotics. Unlikeexisting surveys that emphasize isolated capabilities, this work highlightsintegrated, system-level strategies and evaluates their practical feasibilityin real-world environments. Key enabling trends such as procedural scenegeneration, policy generalization, and multimodal reasoning are discussedalongside core bottlenecks, including limited embodiment, lack of multimodaldata, safety risks, and computational constraints. Through this lens, thispaper identifies both the architectural strengths and critical limitations offoundation model-based robotics, highlighting open challenges in real-timeoperation, grounding, resilience, and trust. The review concludes with aroadmap for future research aimed at bridging semantic reasoning and physicalintelligence through more robust, interpretable, and embodied models.</description>
      <author>example@mail.com (Muhammad Tayyab Khan, Ammar Waheed)</author>
      <guid isPermaLink="false">2507.10087v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>THYME: Temporal Hierarchical-Cyclic Interactivity Modeling for Video Scene Graphs in Aerial Footage</title>
      <link>http://arxiv.org/abs/2507.09200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为THYME的方法，用于动态场景理解，并介绍了AeroEye-v1.0数据集，旨在解决视频应用中场景图生成的挑战。&lt;h4&gt;背景&lt;/h4&gt;随着自动驾驶、监控和运动分析等应用中视频的快速普及，对动态场景理解的需求日益增加。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法在捕捉细粒度空间细节和长期时间依赖性方面的不足，提出了THYME方法，并构建了AeroEye-v1.0数据集。&lt;h4&gt;方法&lt;/h4&gt;THYME方法结合了分层特征聚合和循环时间细化，有效建模多尺度空间上下文，并强制执行帧间的时序一致性。&lt;h4&gt;主要发现&lt;/h4&gt;THYME方法在ASPIRe和AeroEye-v1.0数据集上进行了大量实验，结果表明该方法优于现有方法，在地面和空中场景中提供了更准确的场景理解。&lt;h4&gt;结论&lt;/h4&gt;THYME方法为动态场景图生成提供了有效的解决方案，并展示了在多种场景下的优越性能。&lt;h4&gt;翻译&lt;/h4&gt;The rapid proliferation of video in applications such as autonomous driving, surveillance, and sports analytics necessitates robust methods for dynamicscene understanding. Despite advances in static scene graph generation and early attempts at video scene graph generation, previous methods often sufferfrom fragmented representations, failing to capture fine-grained spatial details and long-range temporal dependencies simultaneously. To address these limitations, we introduce the Temporal Hierarchical Cyclic Scene Graph (THYME) approach, which synergistically integrates hierarchical feature aggregation with cyclic temporal refinement to address these limitations. In particular, THYME effectively models multi-scale spatial context and enforces temporal consistency across frames, yielding more accurate and coherent scene graphs. In addition, we present AeroEye-v1.0, a novel aerial video dataset enriched with five types of interactivity that overcome the constraints of existing datasets and provide a comprehensive benchmark for dynamic scene graph generation. Empirically, extensive experiments on ASPIRe and AeroEye-v1.0 demonstrate that the proposed THYME approach outperforms state-of-the-art methods, offering improved scene understanding in ground-view and aerial scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid proliferation of video in applications such as autonomous driving,surveillance, and sports analytics necessitates robust methods for dynamicscene understanding. Despite advances in static scene graph generation andearly attempts at video scene graph generation, previous methods often sufferfrom fragmented representations, failing to capture fine-grained spatialdetails and long-range temporal dependencies simultaneously. To address theselimitations, we introduce the Temporal Hierarchical Cyclic Scene Graph (THYME)approach, which synergistically integrates hierarchical feature aggregationwith cyclic temporal refinement to address these limitations. In particular,THYME effectively models multi-scale spatial context and enforces temporalconsistency across frames, yielding more accurate and coherent scene graphs. Inaddition, we present AeroEye-v1.0, a novel aerial video dataset enriched withfive types of interactivity that overcome the constraints of existing datasetsand provide a comprehensive benchmark for dynamic scene graph generation.Empirically, extensive experiments on ASPIRe and AeroEye-v1.0 demonstrate thatthe proposed THYME approach outperforms state-of-the-art methods, offeringimproved scene understanding in ground-view and aerial scenarios.</description>
      <author>example@mail.com (Trong-Thuan Nguyen, Pha Nguyen, Jackson Cothren, Alper Yilmaz, Minh-Triet Tran, Khoa Luu)</author>
      <guid isPermaLink="false">2507.09200v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Fusing Large Language Models with Temporal Transformers for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2507.10098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的基于Transformer的架构，旨在结合大型语言模型（LLMs）和普通Transformer模型，以提升时间序列预测（TSF）的准确性。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型在多种任务中表现出强大的能力，并被应用于时间序列预测任务中。然而，LLMs在处理连续数值时间序列数据方面存在不足，而普通Transformer模型在学习高级语义模式上存在困难。&lt;h4&gt;目的&lt;/h4&gt;设计一种方法，将LLMs学习的高级语义表示与时间序列Transformer编码的时序信息相结合，以提高时间序列预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种融合LLMs和Transformer表示的新架构，通过混合表示结合历史时序动态和语义变化模式。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在基准数据集上提高了时间序列预测的准确性。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法有效地结合了LLMs和普通Transformer模型的优势，为时间序列预测提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;最近，大型语言模型（LLMs）在执行各种任务方面展现出强大的能力，因此最近的研究将其应用于时间序列预测（TSF）任务，该任务使用给定的历史时间序列预测未来值。现有的基于LLMs的方法通过提示或微调策略将文本数据中学习到的知识转移到时间序列预测中。然而，LLMs擅长推理离散标记和语义模式，但最初并非设计用于建模连续数值时间序列数据。文本和时间序列数据之间的差距导致LLMs的性能劣于直接在TSF数据上训练的普通Transformer模型。然而，普通的Transformer往往难以学习高级语义模式。在本文中，我们设计了一种新型的基于Transformer的架构，互补地利用LLMs和普通Transformer，以便将LLMs学习的高级语义表示整合到时间序列Transformer编码的时序信息中，通过融合LLMs和Transformer的表示获得混合表示。所得到的融合表示包含历史时序动态和语义变化模式，使我们的模型能够预测更准确的未来值。在基准数据集上的实验证明了所提出方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, large language models (LLMs) have demonstrated powerfulcapabilities in performing various tasks and thus are applied by recent studiesto time series forecasting (TSF) tasks, which predict future values with thegiven historical time series. Existing LLM-based approaches transfer knowledgelearned from text data to time series prediction using prompting or fine-tuningstrategies. However, LLMs are proficient at reasoning over discrete tokens andsemantic patterns but are not initially designed to model continuous numericaltime series data. The gaps between text and time series data lead LLMs toachieve inferior performance to a vanilla Transformer model that is directlytrained on TSF data. However, the vanilla Transformers often struggle to learnhigh-level semantic patterns. In this paper, we design a novelTransformer-based architecture that complementarily leverages LLMs and vanillaTransformers, so as to integrate the high-level semantic representationslearned by LLMs into the temporal information encoded by time seriesTransformers, where a hybrid representation is obtained by fusing therepresentations from the LLM and the Transformer. The resulting fusedrepresentation contains both historical temporal dynamics and semanticvariation patterns, allowing our model to predict more accurate future values.Experiments on benchmark datasets demonstrate the effectiveness of the proposedapproach.</description>
      <author>example@mail.com (Chen Su, Yuanhe Tian, Qinyu Liu, Jun Zhang, Yan Song)</author>
      <guid isPermaLink="false">2507.10098v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Towards Spatial Audio Understanding via Question Answering</title>
      <link>http://arxiv.org/abs/2507.09195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过问答（QA）范式进行空间音频理解的新框架，旨在扩展声事件定位和检测（SELD）的范围，使其能够理解和推理空间场景。&lt;h4&gt;背景&lt;/h4&gt;当前的研究主要集中在声事件定位和检测，而本文旨在通过引入语言指导的方法，实现空间场景的理解和推理。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理第一阶环绕声（FOA）信号和自然语言问题的空间音频问答模型，并评估其性能。&lt;h4&gt;方法&lt;/h4&gt;1. 使用规则方法对STARSS23数据集进行细粒度时空文本描述的整理和发布。2. 利用大型语言模型（LLM）进行语言多样化增强。3. 创建与STARSS23场景对齐的QA数据集，涵盖事件存在、定位、空间和时间关系等方面。4. 使用LLM为每个问题生成多个重述。5. 开发一个基于FOA信号和自然语言问题的空间音频问答模型。6. 模型以分类任务的形式提供有关场景中声音事件发生的答案。&lt;h4&gt;主要发现&lt;/h4&gt;尽管仅使用场景级别的问答监督进行训练，该模型在性能上与使用帧级别时空注释进行训练的完全监督声事件定位和检测模型相当。&lt;h4&gt;结论&lt;/h4&gt;语言指导的方法在空间音频理解中具有潜力，并为将语言监督集成到空间场景分析中开辟了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we introduce a novel framework for spatial audio understanding of first-order ambisonic (FOA) signals through a question answering (QA) paradigm, aiming to extend the scope of sound event localization and detection (SELD) towards spatial scene understanding and reasoning. First, we curate and release fine-grained spatio-temporal textual descriptions for the STARSS23 dataset using a rule-based approach, and further enhance linguistic diversity using large language model (LLM)-based rephrasing. We also introduce a QAdataset aligned with the STARSS23 scenes, covering various aspects such as event presence, localization, spatial, and temporal relationships. To increase language variety, we again leverage LLMs to generate multiple rephrasings per question. Finally, we develop a baseline spatial audio QA model that takes FOA signals and natural language questions as input and provides answers regarding various occurrences, temporal, and spatial relationships of sound events in the scene formulated as a classification task. Despite being trained solely with scene-level question answering supervision, our model achieves performance that is comparable to a fully supervised sound event localization and detection model trained with frame-level spatiotemporal annotations. The results highlight the potential of language-guided approaches for spatial audio understanding and open new directions for integrating linguistic supervision into spatial scene analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce a novel framework for spatial audio understandingof first-order ambisonic (FOA) signals through a question answering (QA)paradigm, aiming to extend the scope of sound event localization and detection(SELD) towards spatial scene understanding and reasoning. First, we curate andrelease fine-grained spatio-temporal textual descriptions for the STARSS23dataset using a rule-based approach, and further enhance linguistic diversityusing large language model (LLM)-based rephrasing. We also introduce a QAdataset aligned with the STARSS23 scenes, covering various aspects such asevent presence, localization, spatial, and temporal relationships. To increaselanguage variety, we again leverage LLMs to generate multiple rephrasings perquestion. Finally, we develop a baseline spatial audio QA model that takes FOAsignals and natural language questions as input and provides answers regardingvarious occurrences, temporal, and spatial relationships of sound events in thescene formulated as a classification task. Despite being trained solely withscene-level question answering supervision, our model achieves performance thatis comparable to a fully supervised sound event localization and detectionmodel trained with frame-level spatiotemporal annotations. The resultshighlight the potential of language-guided approaches for spatial audiounderstanding and open new directions for integrating linguistic supervisioninto spatial scene analysis.</description>
      <author>example@mail.com (Parthasaarathy Sudarsanam, Archontis Politis)</author>
      <guid isPermaLink="false">2507.09195v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>CLIProv: A Contrastive Log-to-Intelligence Multimodal Approach for Threat Detection and Provenance Analysis</title>
      <link>http://arxiv.org/abs/2507.09133v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CLIProv，一种用于检测主机系统中威胁行为的新方法，以解决将高级攻击模式转换为可操作安全策略的挑战。&lt;h4&gt;背景&lt;/h4&gt;随着网络攻击的日益复杂，威胁情报的前瞻性在威胁检测和溯源分析中变得至关重要。然而，将高级攻击模式描述转换为可操作的安全策略是一个重大挑战，这源于高级威胁情报与低级溯源日志之间的语义差距。&lt;h4&gt;目的&lt;/h4&gt;提出CLIProv，旨在解决将高级攻击模式转换为可操作安全策略的挑战，并有效关联系统入侵活动与攻击模式。&lt;h4&gt;方法&lt;/h4&gt;CLIProv采用了一种多模态框架，利用对比学习来对齐溯源日志与威胁情报的语义，将威胁检测作为语义搜索问题，通过搜索与日志序列最语义相似的威胁情报来识别攻击行为。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估表明，CLIProv在系统溯源日志中有效地识别攻击行为，提供了宝贵的参考，并且与现有方法相比，CLIProv实现了更高的精确度和显著提高的检测效率。&lt;h4&gt;结论&lt;/h4&gt;CLIProv是一个有效的威胁检测方法，能够帮助安全专家更好地理解和应对复杂的网络攻击，提高网络安全防护能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing complexity of cyberattacks, the proactive andforward-looking nature of threat intelligence has become more crucial forthreat detection and provenance analysis. However, translating high-levelattack patterns described in Tactics, Techniques, and Procedures (TTP)intelligence into actionable security policies remains a significant challenge.This challenge arises from the semantic gap between high-level threatintelligence and low-level provenance log. To address this issue, this paperintroduces CLIProv, a novel approach for detecting threat behaviors in a hostsystem. CLIProv employs a multimodal framework that leverages contrastivelearning to align the semantics of provenance logs with threat intelligence,effectively correlating system intrusion activities with attack patterns.Furthermore, CLIProv formulates threat detection as a semantic search problem,identifying attack behaviors by searching for threat intelligence that is mostsemantically similar to the log sequence. By leveraging attack patterninformation in threat intelligence, CLIProv identifies TTPs and generatescomplete and concise attack scenarios. Experimental evaluations on standarddatasets show that CLIProv effectively identifies attack behaviors in systemprovenance logs, offering valuable references for potential techniques.Compared to state-of-the-art methods, CLIProv achieves higher precision andsignificantly improved detection efficiency.</description>
      <author>example@mail.com (Jingwen Li, Ru Zhang, Jianyi Liu, Wanguo Zhao)</author>
      <guid isPermaLink="false">2507.09133v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Generative Modeling with Noise-Conditioned Graph Networks</title>
      <link>http://arxiv.org/abs/2507.09391v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为噪声条件图网络（NCGNs）的图神经网络，该网络能够根据噪声水平动态调整其架构，从而在生成具有空间结构的图时提高模型的表达能力。&lt;h4&gt;背景&lt;/h4&gt;在计算机图形和空间基因组学等领域，具有空间结构的图的生成建模至关重要。现有的基于流的生成模型通过逐步添加和去除噪声来取得显著成果，但它们使用的图神经网络架构与噪声水平无关，限制了其表达能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的问题，本文旨在提出一种能够根据噪声水平动态调整架构的图神经网络，以提高生成具有空间结构图的模型的表达能力。&lt;h4&gt;方法&lt;/h4&gt;本文提出了噪声条件图网络（NCGNs），这是一种能够根据噪声水平动态修改其架构的图神经网络。基于这一概念，本文还开发了动态消息传递（DMP），这是一种NCGNs的具体实现，它根据噪声水平调整消息传递的范围和分辨率。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析和实证研究表明，随着噪声的增加，图需要从越来越远的邻居处获取信息，并且可以在较低的分辨率下有效地表示。&lt;h4&gt;结论&lt;/h4&gt;DMP在包括3D点云、时空转录组学和图像在内的多个领域上，一致优于与噪声无关的架构。&lt;h4&gt;翻译&lt;/h4&gt;摘要：具有空间结构的图的生成建模对于许多应用至关重要，从计算机图形到空间基因组学。最近基于流的生成模型通过逐步添加和去除噪声取得了令人印象深刻的成果。然而，现有的模型使用与噪声水平无关的图神经网络架构，限制了其表达能力。为了解决这个问题，我们引入了噪声条件图网络（NCGNs），一类在生成过程中根据噪声水平动态修改其架构的图神经网络。我们的理论和实证分析表明，随着噪声的增加，图需要从越来越远的邻居处获取信息，并且可以在较低的分辨率下有效地表示。基于这些见解，我们开发了动态消息传递（DMP），这是NCGNs的一个具体实例，它根据噪声水平调整消息传递的范围和分辨率。DMP在各种领域上，包括3D点云、时空转录组学和图像，一致优于与噪声无关的架构。代码可在https://github.com/peterpaohuang/ncgn上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative modeling of graphs with spatial structure is essential across manyapplications from computer graphics to spatial genomics. Recent flow-basedgenerative models have achieved impressive results by gradually adding and thenlearning to remove noise from these graphs. Existing models, however, use graphneural network architectures that are independent of the noise level, limitingtheir expressiveness. To address this issue, we introduce\textit{Noise-Conditioned Graph Networks} (NCGNs), a class of graph neuralnetworks that dynamically modify their architecture according to the noiselevel during generation. Our theoretical and empirical analysis reveals that asnoise increases, (1) graphs require information from increasingly distantneighbors and (2) graphs can be effectively represented at lower resolutions.Based on these insights, we develop Dynamic Message Passing (DMP), a specificinstantiation of NCGNs that adapts both the range and resolution of messagepassing to the noise level. DMP consistently outperforms noise-independentarchitectures on a variety of domains including $3$D point clouds,spatiotemporal transcriptomics, and images. Code is available athttps://github.com/peterpaohuang/ncgn.</description>
      <author>example@mail.com (Peter Pao-Huang, Mitchell Black, Xiaojie Qiu)</author>
      <guid isPermaLink="false">2507.09391v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Quantum-Classical Generative Adversarial Networks with Transfer Learning</title>
      <link>http://arxiv.org/abs/2507.09706v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 24 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过在生成对抗网络（GANs）中结合量子计算原理，探讨了量子与经典计算的结合如何提高图像合成质量。&lt;h4&gt;背景&lt;/h4&gt;尽管GANs在图像合成方面具有巨大潜力，但关于如何通过量子计算提升其表示和计算能力的问题仍待解决。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过在生成器和判别器中引入变分量子电路（VQCs）来探究其对GAN性能的影响，并与纯经典模型进行比较。&lt;h4&gt;方法&lt;/h4&gt;论文研究了结合转移学习的混合量子-经典GAN架构，并对不同架构下VQCs的引入效果进行了系统性比较。&lt;h4&gt;主要发现&lt;/h4&gt;在生成器和判别器中都引入VQCs的混合模型在图像质量和定量指标上均优于纯经典模型；生成器中的VQCs加速了早期特征学习，而判别器中的VQCs虽然初期收敛较慢，但最终促进了更精细的合成输出；在数据集规模大幅减少的情况下，模型仍保持接近的性能，表明转移学习和量子增强缓解了数据稀缺问题。&lt;h4&gt;结论&lt;/h4&gt;精心整合量子计算与经典对抗训练以及预训练特征提取可以显著丰富基于GAN的图像合成；这些发现为未来在更高分辨率任务、替代量子电路设计以及新兴量子硬件上的实验提供了方向。&lt;h4&gt;翻译&lt;/h4&gt;Generative Adversarial Networks (GANs) have demonstrated immense potential in synthesizing diverse and high-fidelity images. However, critical questions remain unanswered regarding how quantum principles might best enhance their representational and computational capacity. In this paper, we investigate hybrid quantum-classical GAN architectures supplemented by transfer learning to systematically examine whether incorporating Variational Quantum Circuits (VQCs) into the generator, the discriminator, or both improves performance over a fully classical baseline. Our findings indicate that fully hybrid models, which incorporate VQCs in both the generator and the discriminator, consistently produce images of higher visual quality and achieve more favorable quantitative metrics compared to their fully classical counterparts. In particular, VQCs in the generator accelerate early feature learning, whereas those in the discriminator, despite exhibiting slower initial convergence, ultimately facilitate more refined synthetic outputs. Moreover, the model sustains near-comparable performance even when the dataset size is drastically reduced, suggesting that transfer learning and quantum enhancements mitigate the problem of data scarcity. Overall, the results underscore that carefully integrating quantum computing with classical adversarial training and pretrained feature extraction can considerably enrich GAN-based image synthesis. These insights open avenues for future work on higher-resolution tasks, alternative quantum circuit designs, and experimentation with emerging quantum hardware.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative Adversarial Networks (GANs) have demonstrated immense potential insynthesizing diverse and high-fidelity images. However, critical questionsremain unanswered regarding how quantum principles might best enhance theirrepresentational and computational capacity. In this paper, we investigatehybrid quantum-classical GAN architectures supplemented by transfer learning tosystematically examine whether incorporating Variational Quantum Circuits(VQCs) into the generator, the discriminator, or both improves performance overa fully classical baseline. Our findings indicate that fully hybrid models,which incorporate VQCs in both the generator and the discriminator,consistently produce images of higher visual quality and achieve more favorablequantitative metrics compared to their fully classical counterparts. Inparticular, VQCs in the generator accelerate early feature learning, whereasthose in the discriminator, despite exhibiting slower initial convergence,ultimately facilitate more refined synthetic outputs. Moreover, the modelsustains near-comparable performance even when the dataset size is drasticallyreduced, suggesting that transfer learning and quantum enhancements mitigatethe problem of data scarcity. Overall, the results underscore that carefullyintegrating quantum computing with classical adversarial training andpretrained feature extraction can considerably enrich GAN-based imagesynthesis. These insights open avenues for future work on higher-resolutiontasks, alternative quantum circuit designs, and experimentation with emergingquantum hardware.</description>
      <author>example@mail.com (Asma Al-Othni, Saif Al-Kuwari, Mohammad Mahdi Nasiri Fatmehsari, Kamila Zaman, Ebrahim Ardeshir Larijani)</author>
      <guid isPermaLink="false">2507.09706v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>ExpStar: Towards Automatic Commentary Generation for Multi-discipline Scientific Experiments</title>
      <link>http://arxiv.org/abs/2507.09693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACM MM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了实验注释生成任务，并提出了一种名为ExpStar的自动实验注释生成模型，以及一个名为ExpInstruct的实验注释生成数据集。&lt;h4&gt;背景&lt;/h4&gt;实验注释对于描述实验流程、深入科学原理和融入相关安全指南至关重要。人类教师在准备此类注释时依赖于特定领域的专业知识，并投入大量时间。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，本文旨在自动生成多学科科学实验的注释。&lt;h4&gt;方法&lt;/h4&gt;本文提出了以下贡献：(i) 构建了ExpInstruct数据集，包括21个科学主题的超过7K个步骤级注释；(ii) 提出了ExpStar模型，该模型利用检索增强机制自适应地访问、评估和利用外部知识；(iii) 通过实验证明了ExpStar在性能上显著优于14个领先的LMMs。&lt;h4&gt;主要发现&lt;/h4&gt;ExpStar在实验注释生成任务中表现出色，显著优于其他模型，这突显了数据集和模型的优势。&lt;h4&gt;结论&lt;/h4&gt;ExpStar模型在AI辅助科学实验指导方面具有很大的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：实验注释对于描述实验程序、深入科学原理以及融入相关安全指南至关重要。在实践中，人类教师高度依赖特定领域的专业知识，并投入大量时间准备此类注释。为了应对这一挑战，我们提出了跨多学科科学实验的自动注释生成任务。尽管近期大型多模态模型（LMMs）在视频理解和推理方面取得了令人鼓舞的进展，但它们在生成精细和有洞察力的实验注释方面的能力仍鲜有探索。在本文中，我们做出了以下贡献：(i) 我们构建了ExpInstruct，这是第一个针对实验注释生成的数据集，包含来自3个核心学科（即科学、医疗保健和工程）的21个科学主题的超过7K个步骤级注释。每个样本都包括程序描述、可能的科学原理（例如化学方程式和物理定律）以及安全指南；(ii) 我们提出了ExpStar，这是一种自动实验注释生成模型，它利用检索增强机制来自适应地访问、评估和利用外部知识；(iii) 广泛的实验表明，我们的ExpStar在性能上显著优于14个领先的LMMs，这突显了我们的数据集和模型的优势。我们相信ExpStar在推进AI辅助科学实验指导方面具有很大的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Experiment commentary is crucial in describing the experimental procedures,delving into underlying scientific principles, and incorporatingcontent-related safety guidelines. In practice, human teachers rely heavily onsubject-specific expertise and invest significant time preparing suchcommentary. To address this challenge, we introduce the task of automaticcommentary generation across multi-discipline scientific experiments. Whilerecent progress in large multimodal models (LMMs) has demonstrated promisingcapabilities in video understanding and reasoning, their ability to generatefine-grained and insightful experiment commentary remains largelyunderexplored. In this paper, we make the following contributions: (i) Weconstruct \textit{ExpInstruct}, the first dataset tailored for experimentcommentary generation, featuring over 7\textit{K} step-level commentariesacross 21 scientific subjects from 3 core disciplines (\ie, science, healthcareand engineering). Each sample includes procedural descriptions along withpotential scientific principles (\eg, chemical equations and physical laws) andsafety guidelines. (ii) We propose ExpStar, an automatic experiment commentarygeneration model that leverages a retrieval-augmented mechanism to adaptivelyaccess, evaluate, and utilize external knowledge. (iii) Extensive experimentsshow that our ExpStar substantially outperforms 14 leading LMMs, whichhighlights the superiority of our dataset and model. We believe that ExpStarholds great potential for advancing AI-assisted scientific experimentinstruction.</description>
      <author>example@mail.com (Jiali Chen, Yujie Jia, Zihan Wu, Jinyu Yang, Jianpeng Chen, Xusen Hei, Jiayuan Xie, Yi Cai, Qing Li)</author>
      <guid isPermaLink="false">2507.09693v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>On the Fragility of Multimodal Perception to Temporal Misalignment in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2507.09095v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DejaVu攻击，该攻击利用网络延迟在传感器流之间创建微妙的时序错位，严重损害基于多模态融合（MMF）的感知任务。同时，提出了AION防御方案，通过跨模态时序一致性监控时序对齐，有效防御此类攻击。&lt;h4&gt;背景&lt;/h4&gt;多模态融合在自动驾驶感知中至关重要，但其对精确时序同步的依赖使其面临新的脆弱性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的攻击方法，并设计相应的防御机制，以提升多模态融合系统的安全性。&lt;h4&gt;方法&lt;/h4&gt;引入DejaVu攻击，通过网络延迟造成传感器流时序错位；设计AION防御方案，利用多模态共享表示学习和动态时间扭曲进行时序对齐和异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;不同传感器对任务的敏感度不同，对象检测过度依赖LiDAR输入，而对象跟踪高度依赖相机输入。攻击者可以通过延迟传感器数据来显著降低检测和跟踪的准确性。&lt;h4&gt;结论&lt;/h4&gt;AION防御方案能够有效检测和防御时序错位攻击，具有较高的准确性和较低的误报率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态融合（MMF）在自动驾驶感知中扮演着关键角色，它主要融合摄像头和激光雷达流以实现全面高效的场景理解。然而，它对精确时序同步的严格依赖使其面临新的脆弱性。在本文中，我们介绍了一种名为DejaVu的新攻击，该攻击利用网络诱导的延迟在传感器流之间创建微妙的时序错位，严重损害基于多模态融合（MMF）的感知任务。我们对不同模型和数据集的全面攻击分析揭示了这些传感器的特定任务不平衡敏感性：对象检测过度依赖于激光雷达输入，而对象跟踪高度依赖于相机输入。因此，在单个激光雷达延迟的情况下，攻击者可以将车辆检测mAP降低高达88.5%，而在三个帧的相机延迟的情况下，车辆跟踪的多目标跟踪精度（MOTA）将下降73%。为了检测此类攻击，我们提出了AION，一种可以与现有感知模型协同工作的防御补丁，通过跨模态时序一致性监控时序对齐。AION利用多模态共享表示学习和动态时间扭曲来确定时序对齐路径并基于对齐计算异常分数。我们对AION的全面评估表明，它在数据集和模型架构上实现了0.92-0.98的AUROC分数，具有低误报率，证明了它是一种针对时序错位攻击的稳健且通用的防御措施。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal fusion (MMF) plays a critical role in the perception of autonomousdriving, which primarily fuses camera and LiDAR streams for a comprehensive andefficient scene understanding. However, its strict reliance on precise temporalsynchronization exposes it to new vulnerabilities. In this paper, we introduceDejaVu, a novel attack that exploits network-induced delays to create subtletemporal misalignments across sensor streams, severely degrading downstreamMMF-based perception tasks. Our comprehensive attack analysis across differentmodels and datasets reveals these sensors' task-specific imbalancedsensitivities: object detection is overly dependent on LiDAR inputs whileobject tracking is highly reliant on the camera inputs. Consequently, with asingle-frame LiDAR delay, an attacker can reduce the car detection mAP by up to88.5%, while with a three-frame camera delay, multiple object tracking accuracy(MOTA) for car drops by 73%. To detect such attacks, we propose AION, a defensepatch that can work alongside the existing perception model to monitor temporalalignment through cross-modal temporal consistency. AION leverages multimodalshared representation learning and dynamic time warping to determine the pathof temporal alignment and calculate anomaly scores based on the alignment. Ourthorough evaluation of AION shows it achieves AUROC scores of 0.92-0.98 withlow false positives across datasets and model architectures, demonstrating itas a robust and generalized defense against the temporal misalignment attacks.</description>
      <author>example@mail.com (Md Hasan Shahriar, Md Mohaimin Al Barat, Harshavardhan Sundar, Naren Ramakrishnan, Y. Thomas Hou, Wenjing Lou)</author>
      <guid isPermaLink="false">2507.09095v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Do we need equivariant models for molecule generation?</title>
      <link>http://arxiv.org/abs/2507.09753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了非等变卷积神经网络（CNNs）在分子发现中的应用，探讨了通过旋转增强训练能否使CNN学习到等变性并匹配等变模型的表现。&lt;h4&gt;背景&lt;/h4&gt;深度生成模型在分子发现中的应用日益增加，而最新的方法依赖于等变图神经网络（GNNs），假设显式的等变性对于生成高质量的3D分子至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究非等变CNN通过旋转增强训练是否能够学习到等变性，并达到等变模型的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了一种损失分解方法，将预测误差与等变性误差分开，并评估了模型大小、数据集大小和训练时长对去噪、分子生成和性质预测性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;这是首次研究在生成任务中分析学习到的等变性。&lt;h4&gt;结论&lt;/h4&gt;非等变CNN经过旋转增强训练后，能够学习到等变性并匹配等变模型的表现。&lt;h4&gt;翻译&lt;/h4&gt;摘要：深度生成模型在分子发现中越来越被使用，最近的方法依赖于等变图神经网络（GNNs），假设显式的等变性对于生成高质量的3D分子是必要的。然而，这些模型复杂，难以训练，并且扩展性不好。我们研究了非等变卷积神经网络（CNNs）通过旋转增强训练是否能够学习到等变性，并匹配等变模型的表现。我们推导了一种损失分解，将预测误差与等变性误差分开，并评估了模型大小、数据集大小和训练时长对去噪、分子生成和性质预测性能的影响。据我们所知，这是首次研究在生成任务中分析学习到的等变性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep generative models are increasingly used for molecular discovery, withmost recent approaches relying on equivariant graph neural networks (GNNs)under the assumption that explicit equivariance is essential for generatinghigh-quality 3D molecules. However, these models are complex, difficult totrain, and scale poorly.  We investigate whether non-equivariant convolutional neural networks (CNNs)trained with rotation augmentations can learn equivariance and match theperformance of equivariant models. We derive a loss decomposition thatseparates prediction error from equivariance error, and evaluate how modelsize, dataset size, and training duration affect performance across denoising,molecule generation, and property prediction. To our knowledge, this is thefirst study to analyze learned equivariance in generative tasks.</description>
      <author>example@mail.com (Ewa M. Nowara, Joshua Rackers, Patricia Suriana, Pan Kessel, Max Shen, Andrew Martin Watkins, Michael Maser)</author>
      <guid isPermaLink="false">2507.09753v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Free-running vs. Synchronous: Single-Photon Lidar for High-flux 3D Imaging</title>
      <link>http://arxiv.org/abs/2507.09386v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 15 figures, to be presented at the International Conference  on Computer Vision (ICCV) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个用于自由运行单光子激光雷达（SPL）的联合最大似然估计器，用于估计信号通量、背景通量和深度，并引入了正则化框架以改进估计精度。&lt;h4&gt;背景&lt;/h4&gt;传统观点认为单光子激光雷达（SPL）应在低光条件下运行以最小化死时间效应，许多方法已开发用于减轻同步SPL系统中的这些效应，但自由运行SPL的解决方案仍然有限。&lt;h4&gt;目的&lt;/h4&gt;为了提高自由运行SPL的准确性，提出了一个计算高效的联合最大似然估计器，并引入了正则化框架。&lt;h4&gt;方法&lt;/h4&gt;使用仅直方图的方法估计信号通量、背景通量和深度，并结合一个包含学习到的点云评分模型作为先验的正则化框架。&lt;h4&gt;主要发现&lt;/h4&gt;仿真和实验表明，在相同条件下，自由运行SPL的估计误差低于其同步对应物，并且我们的正则化进一步提高了精度。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法可以有效地提高自由运行SPL的估计精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统观念认为单光子激光雷达（SPL）应在低光条件下运行以最小化死时间效应。许多方法已经开发出来以减轻同步SPL系统中的这些效应。然而，尽管减少了死时间带来的直方图失真，自由运行SPL的解决方案仍然有限。为了提高自由运行SPL的准确性，我们提出了一种仅使用直方图计算信号通量、背景通量和深度的联合最大似然估计器，并引入了一种正则化框架，该框架结合了一个学习到的点云评分模型作为先验。仿真和实验表明，在相同条件下，自由运行SPL的估计误差低于其同步对应物，并且我们的正则化进一步提高了精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conventional wisdom suggests that single-photon lidar (SPL) should operate inlow-light conditions to minimize dead-time effects. Many methods have beendeveloped to mitigate these effects in synchronous SPL systems. However,solutions for free-running SPL remain limited despite the advantage of reducedhistogram distortion from dead times. To improve the accuracy of free-runningSPL, we propose a computationally efficient joint maximum likelihood estimatorof the signal flux, the background flux, and the depth using only histograms,along with a complementary regularization framework that incorporates a learnedpoint cloud score model as a prior. Simulations and experiments demonstratethat free-running SPL yields lower estimation errors than its synchronouscounterpart under identical conditions, with our regularization furtherimproving accuracy.</description>
      <author>example@mail.com (Ruangrawee Kitichotkul, Shashwath Bharadwaj, Joshua Rapp, Yanting Ma, Alexander Mehta, Vivek K Goyal)</author>
      <guid isPermaLink="false">2507.09386v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Towards Applying Large Language Models to Complement Single-Cell Foundation Models</title>
      <link>http://arxiv.org/abs/2507.10039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了大型语言模型（LLMs）在单细胞数据分析中的应用，并提出了scMPT模型，该模型结合了scGPT和LLMs对单细胞数据的表示，以提升性能。&lt;h4&gt;背景&lt;/h4&gt;单细胞基础模型如scGPT在单细胞组学领域取得了显著进展，但在处理生物文本信息方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;研究LLMs在单细胞数据分析中的性能，并探索如何通过结合scGPT和LLMs来提升性能。&lt;h4&gt;方法&lt;/h4&gt;研究者提出了scMPT模型，该模型利用scGPT和LLMs对单细胞数据的表示，并通过实验验证了其性能。&lt;h4&gt;主要发现&lt;/h4&gt;scMPT模型在性能上优于其组成部分，且在多个数据集上表现出更强的稳定性和一致性。同时，研究还尝试了不同的融合方法，展示了将专业推理模型与scGPT结合的潜力。&lt;h4&gt;结论&lt;/h4&gt;LLMs可以作为单细胞基础模型的补充，推动单细胞分析性能的提升。&lt;h4&gt;翻译&lt;/h4&gt;This study investigates the application of large language models (LLMs) in single-cell data analysis and proposes the scMPT model, which combines scGPT and single-cell representations from LLMs to enhance performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-cell foundation models such as scGPT represent a significantadvancement in single-cell omics, with an ability to achieve state-of-the-artperformance on various downstream biological tasks. However, these models areinherently limited in that a vast amount of information in biology exists astext, which they are unable to leverage. There have therefore been severalrecent works that propose the use of LLMs as an alternative to single-cellfoundation models, achieving competitive results. However, there is littleunderstanding of what factors drive this performance, along with a strong focuson using LLMs as an alternative, rather than complementary approach tosingle-cell foundation models. In this study, we therefore investigate whatbiological insights contribute toward the performance of LLMs when applied tosingle-cell data, and introduce scMPT; a model which leverages synergiesbetween scGPT, and single-cell representations from LLMs that capture theseinsights. scMPT demonstrates stronger, more consistent performance than eitherof its component models, which frequently have large performance gaps betweeneach other across datasets. We also experiment with alternate fusion methods,demonstrating the potential of combining specialized reasoning models withscGPT to improve performance. This study ultimately showcases the potential forLLMs to complement single-cell foundation models and drive improvements insingle-cell analysis.</description>
      <author>example@mail.com (Steven Palayew, Bo Wang, Gary Bader)</author>
      <guid isPermaLink="false">2507.10039v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Navigating the Evolution of Two-dimensional Carbon Nitride Research: Integrating Machine Learning into Conventional Approaches</title>
      <link>http://arxiv.org/abs/2507.09669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;碳化氮材料研究取得显著进展，应用于光催化、储能和传感等领域。机器学习（ML）技术的应用为探索和优化碳化氮材料的潜力提供了新途径。&lt;h4&gt;背景&lt;/h4&gt;碳化氮材料因其独特的电子和结构性质在多个领域具有广泛应用，近年来，机器学习技术的发展为碳化氮材料研究带来了新的机遇。&lt;h4&gt;目的&lt;/h4&gt;本文旨在全面回顾机器学习技术在碳化氮研究中的应用，并介绍碳化氮的分类和最新进展。&lt;h4&gt;方法&lt;/h4&gt;本文讨论了在预测材料性质、优化合成条件和提升性能指标方面所采用的方法，包括监督学习、无监督学习和强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;机器学习算法可以显著减少实验中的试错过程，加速发现过程，并深入理解碳化氮的结构-性质关系。&lt;h4&gt;结论&lt;/h4&gt;机器学习与传统实验方法的结合具有协同效应，成功预测了具有增强功能性质的新的碳化氮组成。未来研究方向强调高质量数据集、先进机器学习模型和跨学科合作的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Carbon nitride research has reached a promising point in today's researchendeavours with diverse applications including photocatalysis, energy storage, and sensing due to their unique electronic and structural properties. Recent advances in machine learning (ML) have opened new avenues for exploring and optimizing the potential of these materials. This study presents a comprehensive review of the integration of ML techniques in carbon nitrideresearch with an introduction to CN classifications and recent advancements. We discuss the methodologies employed, such as supervised learning, unsupervised learning, and reinforcement learning, in predicting material properties, optimizing synthesis conditions, and enhancing performance metrics. Key findings indicate that ML algorithms can significantly reduce experimental trial-and-error, accelerate discovery processes, and provide deeper insights into the structure-property relationships of carbon nitride. The synergistic effect of combining ML with traditional experimental approaches is highlighted, showcasing studies where ML driven models have successfully predicted novel carbon nitride compositions with enhanced functional properties. Future directions in this field are also proposed, emphasizing the need for high-quality datasets, advanced ML models, and interdisciplinary collaborations to fully realize the potential of carbon nitride materials in next-generation technologies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1039/D4CP04309J&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Carbon nitride research has reached a promising point in today's researchendeavours with diverse applications including photocatalysis, energy storage,and sensing due to their unique electronic and structural properties. Recentadvances in machine learning (ML) have opened new avenues for exploring andoptimizing the potential of these materials. This study presents acomprehensive review of the integration of ML techniques in carbon nitrideresearch with an introduction to CN classifications and recent advancements. Wediscuss the methodologies employed, such as supervised learning, unsupervisedlearning, and reinforcement learning, in predicting material properties,optimizing synthesis conditions, and enhancing performance metrics. Keyfindings indicate that ML algorithms can significantly reduce experimentaltrial-and-error, accelerate discovery processes, and provide deeper insightsinto the structure-property relationships of carbon nitride. The synergisticeffect of combining ML with traditional experimental approaches is highlighted,showcasing studies where ML driven models have successfully predicted novelcarbon nitride compositions with enhanced functional properties. Futuredirections in this field are also proposed, emphasizing the need forhigh-quality datasets, advanced ML models, and interdisciplinary collaborationsto fully realize the potential of carbon nitride materials in next-generationtechnologies.</description>
      <author>example@mail.com (Deep Mondal, Sujoy Datta, Debnarayan Jana)</author>
      <guid isPermaLink="false">2507.09669v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>(Almost) Free Modality Stitching of Foundation Models</title>
      <link>http://arxiv.org/abs/2507.10015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Pre-print&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Hypernetwork Model Alignment (Hyma)的新型多模态模型，旨在解决大规模数据集上训练连接器模块以及单模态模型选择的问题。&lt;h4&gt;背景&lt;/h4&gt;多模态模型通常由多个预训练的单模态模型拼接而成，需要训练一个连接器模块来对齐这些模型的表示空间。&lt;h4&gt;目的&lt;/h4&gt;针对单模态模型选择和连接器模块训练的计算负担问题，提出了一种基于超网络的解决方案。&lt;h4&gt;方法&lt;/h4&gt;Hyma框架利用超网络的参数预测能力，为N×M组合的单模态模型生成联合训练的连接器模块。&lt;h4&gt;主要发现&lt;/h4&gt;Hyma在实验中降低了最优单模态模型对搜索成本，平均减少了10倍，同时在多样化的多模态基准测试中与网格搜索获得的排名和连接器性能相匹配。&lt;h4&gt;结论&lt;/h4&gt;Hyma为单模态模型选择和连接器训练提供了一种有效且高效的解决方案，显著提升了多模态模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation multi-modal models are often designed by stitching of multipleexisting pretrained uni-modal models: for example, an image classifier with anautoregressive text model. This stitching process is performed by training aconnector module that aims to align the representation-representation orrepresentation-input spaces of these uni-modal models. However, given thecomplexity of training such connectors on large scale web-based datasetscoupled with the ever-increasing number of available pretrained uni-modalmodels, the task of uni-modal models selection and subsequent connector moduletraining becomes computationally demanding. To address this under-studiedcritical problem, we propose Hypernetwork Model Alignment (Hyma), a novelall-in-one solution for optimal uni-modal model selection and connectortraining by leveraging hypernetworks. Specifically, our framework utilizes theparameter prediction capability of a hypernetwork to obtain jointly trainedconnector modules for $N \times M$ combinations of uni-modal models. In ourexperiments, Hyma reduces the optimal uni-modal model pair search cost by$10\times$ (averaged across all experiments), while matching the ranking andtrained connector performance obtained via grid search across a suite ofdiverse multi-modal benchmarks.</description>
      <author>example@mail.com (Jaisidh Singh, Diganta Misra, Boris Knyazev, Antonio Orvieto)</author>
      <guid isPermaLink="false">2507.10015v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Text-Driven Causal Representation Learning for Source-Free Domain Generalization</title>
      <link>http://arxiv.org/abs/2507.09961v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TDCRL的文本驱动因果表示学习方法，用于解决深度学习在训练和测试数据分布不同时的困难，通过结合因果推理和文本提示，实现了无源域泛化（SFDG），并在多个数据集上取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;深度学习在训练和测试数据分布不同时往往表现不佳，传统的域泛化方法由于数据收集和标注成本高而难以实施。现有的无源域泛化方法在处理特定域的混杂因素时存在困难，限制了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出TDCRL方法，旨在通过将因果推理集成到无源域泛化设置中，解决现有SFDG方法在处理域特定混杂因素时的局限性。&lt;h4&gt;方法&lt;/h4&gt;TDCRL通过两个步骤操作：首先，使用数据增强生成风格词向量，并结合类别信息生成文本嵌入以模拟视觉表示；其次，训练一个因果干预网络，使用混杂因素字典提取域不变特征。&lt;h4&gt;主要发现&lt;/h4&gt;基于因果学习的TDCRL方法提供了一个清晰有效的机制，以实现鲁棒的域不变特征，确保了鲁棒的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;在PACS、VLCS、OfficeHome和DomainNet等数据集上的广泛实验表明，TDCRL在无源域泛化中取得了最先进的性能，证明了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;Deep learning often struggles when training and test data distributions differ. Traditional domain generalization (DG) tackles this by including data from multiple source domains, which is impractical due to expensive data collection and annotation. Recent vision-language models like CLIP enable source-free domain generalization (SFDG) by using text prompts to simulate visual representations, reducing data demands. However, existing SFDG methods struggle with domain-specific confounders, limiting their generalization capabilities. To address this issue, we propose TDCRL (Text-Driven Causal Representation Learning), the first method to integrate causal inference into the SFDG setting. TDCRL operates in two steps: first, it employs data augmentation to generate style word vectors, combining them with class information to generate text embeddings to simulate visual representations; second, it trains a causal intervention network with a confounder dictionary to extract domain-invariant features. Grounded in causal learning, our approach offers a clear and effective mechanism to achieve robust, domain-invariant features, ensuring robust generalization. Extensive experiments on PACS, VLCS, OfficeHome, and DomainNet show state-of-the-art performance, proving TDCRL effectiveness in SFDG.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning often struggles when training and test data distributionsdiffer. Traditional domain generalization (DG) tackles this by including datafrom multiple source domains, which is impractical due to expensive datacollection and annotation. Recent vision-language models like CLIP enablesource-free domain generalization (SFDG) by using text prompts to simulatevisual representations, reducing data demands. However, existing SFDG methodsstruggle with domain-specific confounders, limiting their generalizationcapabilities. To address this issue, we propose TDCRL(\textbf{T}ext-\textbf{D}riven \textbf{C}ausal \textbf{R}epresentation\textbf{L}earning), the first method to integrate causal inference into theSFDG setting. TDCRL operates in two steps: first, it employs data augmentationto generate style word vectors, combining them with class information togenerate text embeddings to simulate visual representations; second, it trainsa causal intervention network with a confounder dictionary to extractdomain-invariant features. Grounded in causal learning, our approach offers aclear and effective mechanism to achieve robust, domain-invariant features,ensuring robust generalization. Extensive experiments on PACS, VLCS,OfficeHome, and DomainNet show state-of-the-art performance, proving TDCRLeffectiveness in SFDG.</description>
      <author>example@mail.com (Lihua Zhou, Mao Ye, Nianxin Li, Shuaifeng Li, Jinlin Wu, Xiatian Zhu, Lei Deng, Hongbin Liu, Jiebo Luo, Zhen Lei)</author>
      <guid isPermaLink="false">2507.09961v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Demonstrating the Octopi-1.5 Visual-Tactile-Language Model</title>
      <link>http://arxiv.org/abs/2507.09985v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at R:SS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Octopi-1.5的视觉-触觉-语言模型，用于展示触觉感知在机器人中的应用。&lt;h4&gt;背景&lt;/h4&gt;触觉对人类和机器人来说都非常重要，尤其在灵巧操作、材料识别和视觉遮挡场景中。&lt;h4&gt;目的&lt;/h4&gt;通过展示Octopi-1.5，旨在展示触觉感知模型在处理任务和即时学习新物体方面的能力。&lt;h4&gt;方法&lt;/h4&gt;Octopi-1.5能够处理来自多个物体部分的感觉信号，并使用简单的检索增强生成（RAG）模块来提高性能。用户可以通过一个手持式触觉界面TMI与模型交互。&lt;h4&gt;主要发现&lt;/h4&gt;Octopi-1.5可以解决触觉推理任务，如猜物游戏，并在游戏中提供处理物体的建议。此外，通过实时交互，展示了模型学习新物品的能力。&lt;h4&gt;结论&lt;/h4&gt;该演示突出了视觉-触觉-语言模型如Octopi-1.5的进展和局限性，并激发了对此领域进一步研究的兴趣。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了Octopi-1.5这一视觉-触觉-语言模型，它能够处理多部分物体的触觉信号，并使用检索增强生成（RAG）模块来提高性能。模型可通过手持触觉界面TMI与用户交互，并在猜物游戏中展示其触觉推理能力，同时能够通过实时交互学习新物品。演示突出了这类模型的进展与局限，并激发了对此领域的进一步研究兴趣。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Touch is recognized as a vital sense for humans and an equally importantmodality for robots, especially for dexterous manipulation, materialidentification, and scenarios involving visual occlusion. Building upon veryrecent work in touch foundation models, this demonstration will featureOctopi-1.5, our latest visual-tactile-language model. Compared to itspredecessor, Octopi-1.5 introduces the ability to process tactile signals frommultiple object parts and employs a simple retrieval-augmented generation (RAG)module to improve performance on tasks and potentially learn new objectson-the-fly. The system can be experienced live through a new handheldtactile-enabled interface, the TMI, equipped with GelSight and TAC-02 tactilesensors. This convenient and accessible setup allows users to interact withOctopi-1.5 without requiring a robot. During the demonstration, we willshowcase Octopi-1.5 solving tactile inference tasks by leveraging tactileinputs and commonsense knowledge. For example, in a Guessing Game, Octopi-1.5will identify objects being grasped and respond to follow-up queries about howto handle it (e.g., recommending careful handling for soft fruits). We alsoplan to demonstrate Octopi-1.5's RAG capabilities by teaching it new items.With live interactions, this demonstration aims to highlight both the progressand limitations of VTLMs such as Octopi-1.5 and to foster further interest inthis exciting field. Code for Octopi-1.5 and design files for the TMI gripperare available at https://github.com/clear-nus/octopi-1.5.</description>
      <author>example@mail.com (Samson Yu, Kelvin Lin, Harold Soh)</author>
      <guid isPermaLink="false">2507.09985v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>A Generalization Theory for Zero-Shot Prediction</title>
      <link>http://arxiv.org/abs/2507.09128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICML '25 (Oral)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种现代机器学习和人工智能中通用的泛化范式，即通过自监督和多模态对比学习预训练一个任务无关的基础模型，这些模型可以用于无标签数据的下游任务预测。&lt;h4&gt;背景&lt;/h4&gt;当前机器学习和人工智能的泛化范式通常涉及预训练一个不针对特定任务的基础模型，该模型通过自监督和多模态对比学习获得。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过理论框架更好地理解这种称为零样本预测的方法，以识别零样本预测试图学习或偶然学习的目标量以及支持其泛化能力的关键条件独立性关系。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个理论框架，用于分析零样本预测的方法，并识别相关的目标量和条件独立性关系。&lt;h4&gt;主要发现&lt;/h4&gt;本文确定了零样本预测旨在学习或偶然学习的目标量，以及支持其泛化能力的关键条件独立性关系。&lt;h4&gt;结论&lt;/h4&gt;本文的理论框架有助于深入理解零样本预测的原理，并为未来的研究提供了理论基础。&lt;h4&gt;翻译&lt;/h4&gt;A modern paradigm for generalization in machine learning and AI consists of pre-training a task-agnostic foundation model, generally obtained using self-supervised and multimodal contrastive learning. The resulting representations can be used for prediction on a downstream task for which no labeled data is available. We present a theoretical framework to better understand this approach, called zero-shot prediction. We identify the target quantities that zero-shot prediction aims to learn, or learns in passing, and the key conditional independence relationships that enable its generalization ability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A modern paradigm for generalization in machine learning and AI consists ofpre-training a task-agnostic foundation model, generally obtained usingself-supervised and multimodal contrastive learning. The resultingrepresentations can be used for prediction on a downstream task for which nolabeled data is available. We present a theoretical framework to betterunderstand this approach, called zero-shot prediction. We identify the targetquantities that zero-shot prediction aims to learn, or learns in passing, andthe key conditional independence relationships that enable its generalizationability.</description>
      <author>example@mail.com (Ronak Mehta, Zaid Harchaoui)</author>
      <guid isPermaLink="false">2507.09128v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them?</title>
      <link>http://arxiv.org/abs/2507.09491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为GLIMPSE的新视频基准，旨在评估大型视觉语言模型（LVLMs）是否能够真正理解视频内容，而不是仅仅进行表面层次的帧级分析。&lt;h4&gt;背景&lt;/h4&gt;现有的视频基准与图像基准相似，问题类型往往集中在静态图像信息上，如动作识别或颜色识别，这使得模型可以通过扫描几个关键帧就能回答问题，而无需进行深层次的时间推理。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了GLIMPSE基准，其目的是评估LVLMs是否能够真正理解视频。&lt;h4&gt;方法&lt;/h4&gt;GLIMPSE基准包含3,269个视频和超过4,342个高度视觉中心的提问，涵盖了轨迹分析、时间推理和法医检测等11个类别。所有问题都由人工标注员精心制作，需要观看整个视频并在完整的视频上下文中进行推理。&lt;h4&gt;主要发现&lt;/h4&gt;GLIMPSE在人工评估中达到了94.82%的准确率，但当前的LVLMs在处理GLIMPSE问题时面临重大挑战，即使是表现最好的模型GPT-o3也只达到了66.43%，这表明LVLMs仍然难以超越表面层次推理，真正理解视频内容。&lt;h4&gt;结论&lt;/h4&gt;GLIMPSE基准为评估LVLMs对视频内容的理解能力提供了一个新的标准，并揭示了LVLMs在处理复杂视频理解任务时的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing video benchmarks often resemble image-based benchmarks, withquestion types like "What actions does the person perform throughout thevideo?" or "What color is the woman's dress in the video?" For these, modelscan often answer by scanning just a few key frames, without deep temporalreasoning. This limits our ability to assess whether large vision-languagemodels (LVLMs) can truly think with videos rather than perform superficialframe-level analysis. To address this, we introduce GLIMPSE, a benchmarkspecifically designed to evaluate whether LVLMs can genuinely think withvideos. Unlike prior benchmarks, GLIMPSE emphasizes comprehensive videounderstanding beyond static image cues. It consists of 3,269 videos and over4,342 highly visual-centric questions across 11 categories, includingTrajectory Analysis, Temporal Reasoning, and Forensics Detection. All questionsare carefully crafted by human annotators and require watching the entire videoand reasoning over full video context-this is what we mean by thinking withvideo. These questions cannot be answered by scanning selected frames orrelying on text alone. In human evaluations, GLIMPSE achieves 94.82% accuracy,but current LVLMs face significant challenges. Even the best-performing model,GPT-o3, reaches only 66.43%, highlighting that LVLMs still struggle to movebeyond surface-level reasoning to truly think with videos.</description>
      <author>example@mail.com (Yiyang Zhou, Linjie Li, Shi Qiu, Zhengyuan Yang, Yuyang Zhao, Siwei Han, Yangfan He, Kangqi Li, Haonian Ji, Zihao Zhao, Haibo Tong, Lijuan Wang, Huaxiu Yao)</author>
      <guid isPermaLink="false">2507.09491v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Joint Access Point Activation and Power Allocation for Cell-Free Massive MIMO Aided ISAC Systems</title>
      <link>http://arxiv.org/abs/2507.09425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures, 2 tables. Accepted by IEEE TVT&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于无细胞大规模多输入多输出（MIMO）辅助的集成传感和通信（ISAC）系统，其中分布式接入点联合服务用户和传感目标。&lt;h4&gt;背景&lt;/h4&gt;在ISAC系统中，只有一部分接入点（AP）需要被激活来完成服务用户和传感目标的任务，关闭多余的AP对于节能至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了优化能源效率，提出联合激活AP选择和功率控制的方法。&lt;h4&gt;方法&lt;/h4&gt;将问题建模为混合整数非线性规划（MINLP），并提出基于模型的分支定界方法作为强基线，引导半监督异构图神经网络（HetGNN）选择最佳的激活AP和功率分配。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的HetGNN可以将功耗降低20-25%，并且比基于模型的基准快近10000倍。&lt;h4&gt;结论&lt;/h4&gt;HetGNN在优化ISAC系统的能源效率方面表现出色，能够显著降低功耗并提高效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cell-free massive multiple-input multiple-output (MIMO)-aided integratedsensing and communication (ISAC) systems are investigated where distributedaccess points jointly serve users and sensing targets. We demonstrate that onlya subset of access points (APs) has to be activated for both tasks, whiledeactivating redundant APs is essential for power savings. This motivates jointactive AP selection and power control for optimizing energy efficiency. Theresultant problem is a mixed-integer nonlinear program (MINLP). To addressthis, we propose a model-based Branch-and-Bound approach as a strong baselineto guide a semi-supervised heterogeneous graph neural network (HetGNN) forselecting the best active APs and the power allocation. Comprehensive numericalresults demonstrate that the proposed HetGNN reduces power consumption by20-25\% and runs nearly 10,000 times faster than model-based benchmarks.</description>
      <author>example@mail.com (Nguyen Xuan Tung, Le Tung Giang, Trinh Van Chien, Hoang Trong Minh, Lajos Hanzo)</author>
      <guid isPermaLink="false">2507.09425v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Adaptive Motion Planning via Point Cloud-Guided, Energy-Based Diffusion and Potential Fields</title>
      <link>http://arxiv.org/abs/2507.09383v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IEEE RA-L 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合基于能量的扩散模型和人工势场法的运动规划框架，用于在复杂环境中实现鲁棒的实时轨迹生成。&lt;h4&gt;背景&lt;/h4&gt;受追击-逃避问题的启发。&lt;h4&gt;目的&lt;/h4&gt;在复杂环境中实现鲁棒的实时轨迹生成。&lt;h4&gt;方法&lt;/h4&gt;该框架直接从点云中处理障碍物信息，无需完整的几何表示。它采用无分类器指导训练，并在采样过程中集成局部势场以增强避障。在动态场景中，系统使用扩散模型生成初始轨迹，并通过基于势场的自适应连续优化它们。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在追击-逃避场景中表现出有效性能，尤其是在部分追击者可观测的情况下。&lt;h4&gt;结论&lt;/h4&gt;该方法在复杂环境中的实时轨迹生成方面具有潜力。&lt;h4&gt;翻译&lt;/h4&gt;Motivated by the problem of pursuit-evasion, we present a motion planning framework that combines energy-based diffusion models with artificial potential fields for robust real time trajectory generation in complex environments. Our approach processes obstacle information directly from point clouds, enabling efficient planning without requiring complete geometric representations. The framework employs classifier-free guidance training and integrates local potential fields during sampling to enhance obstacle avoidance. In dynamic scenarios, the system generates initial trajectories using the diffusion model and continuously refines them through potential field-based adaptation, demonstrating effective performance in pursuit-evasion scenarios with partial pursuer observability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by the problem of pursuit-evasion, we present a motion planningframework that combines energy-based diffusion models with artificial potentialfields for robust real time trajectory generation in complex environments. Ourapproach processes obstacle information directly from point clouds, enablingefficient planning without requiring complete geometric representations. Theframework employs classifier-free guidance training and integrates localpotential fields during sampling to enhance obstacle avoidance. In dynamicscenarios, the system generates initial trajectories using the diffusion modeland continuously refines them through potential field-based adaptation,demonstrating effective performance in pursuit-evasion scenarios with partialpursuer observability.</description>
      <author>example@mail.com (Wondmgezahu Teshome, Kian Behzad, Octavia Camps, Michael Everett, Milad Siami, Mario Sznaier)</author>
      <guid isPermaLink="false">2507.09383v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Online Long-term Point Tracking in the Foundation Model Era</title>
      <link>http://arxiv.org/abs/2507.09217v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2501.18487&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对在线环境下的长期点跟踪问题进行研究，提出了一种基于Transformer的模型Track-On，实现了无需未来信息或滑动窗口的长期跟踪。&lt;h4&gt;背景&lt;/h4&gt;点跟踪旨在识别视频帧中的同一物理点，并作为运动的空间感知表示。这种表示支持从机器人学到增强现实等众多应用，通过实现对动态环境的精确建模。&lt;h4&gt;目的&lt;/h4&gt;在在线设置中解决长期点跟踪问题，即模型必须因果地运行，仅使用当前和过去帧。&lt;h4&gt;方法&lt;/h4&gt;评估视觉基础模型在跟踪任务中的适用性，发现它们可以作为有用的初始化并将其集成到跟踪管道中。提出Track-On模型，该模型将每个跟踪点作为查询，逐帧处理视频帧。&lt;h4&gt;主要发现&lt;/h4&gt;视觉基础模型可以作为有用的初始化，但为了实现在线设置中的长期跟踪，仍需要一个专门的设计。Track-On模型在七个公开基准测试中达到了新的技术水平，证明了无需未来访问进行长期跟踪的可行性。&lt;h4&gt;结论&lt;/h4&gt;Track-On模型在在线设置中的长期点跟踪方面取得了突破，为实时视频分析和人工智能应用提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了在线环境下的长期点跟踪问题，提出了一种基于Transformer的模型Track-On，实现了无需未来信息或滑动窗口的长期跟踪。通过评估视觉基础模型，发现它们可以作为有用的初始化并将其集成到跟踪管道中。Track-On模型在七个公开基准测试中达到了新的技术水平，证明了无需未来访问进行长期跟踪的可行性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point tracking aims to identify the same physical point across video framesand serves as a geometry-aware representation of motion. This representationsupports a wide range of applications, from robotics to augmented reality, byenabling accurate modeling of dynamic environments. Most existing long-termtracking approaches operate in an offline setting, where future frames areavailable to refine predictions and recover from occlusions. However,real-world scenarios often demand online predictions: the model must operatecausally, using only current and past frames. This constraint is critical instreaming video and embodied AI, where decisions must be made immediately basedon past observations. Under such constraints, viewpoint invariance becomesessential. Visual foundation models, trained on diverse large-scale datasets,offer the potential for robust geometric representations. While they lacktemporal reasoning on their own, they can be integrated into tracking pipelinesto enrich spatial features. In this thesis, we address the problem of long-termpoint tracking in an online setting, where frames are processed sequentiallywithout access to future information or sliding windows. We begin by evaluatingthe suitability of visual foundation models for this task and find that theycan serve as useful initializations and be integrated into tracking pipelines.However, to enable long-term tracking in an online setting, a dedicated designis still required. In particular, maintaining coherence over time in thiscausal regime requires memory to propagate appearance and context acrossframes. To address this, we introduce Track-On, a transformer-based model thattreats each tracked point as a query and processes video frames one at a time.Track-On sets a new state of the art across seven public benchmarks,demonstrating the feasibility of long-term tracking without future access.</description>
      <author>example@mail.com (Görkay Aydemir)</author>
      <guid isPermaLink="false">2507.09217v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing ALS Progression Tracking with Semi-Supervised ALSFRS-R Scores Estimated from Ambient Home Health Monitoring</title>
      <link>http://arxiv.org/abs/2507.09460v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 8 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;通过开发半监督回归模型，结合家庭传感器监测数据，分析了三种模型范式（个体批量学习和群体级批量与增量微调迁移学习）在功能下降评估中的应用，结果表明，将学习方法和伪标签技术匹配到功能领域的同质性-异质性特征，可以提高肌萎缩侧索硬化症（ALS）进展跟踪的预测准确性。&lt;h4&gt;背景&lt;/h4&gt;临床监测ALS患者的功能下降依赖于定期评估，但可能错过两次访问之间的关键变化。&lt;h4&gt;目的&lt;/h4&gt;开发半监督回归模型，通过针对ALSFRS-R量表轨迹，利用家庭传感器监测数据来估计病例系列队列中的下降率。&lt;h4&gt;方法&lt;/h4&gt;比较了三种模型范式（个体批量学习、群体级批量与增量微调迁移学习）在线性斜率、三次多项式和集成自注意力伪标签插值中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;群体同质性在功能领域对学习方法的响应中得到了体现，迁移学习在32个对比中的28个（平均RMSE=0.20(0.04)）提高了ALSFRS-R子量表预测误差，个体批量学习在3个中的2个（平均RMSE=3.15(1.25)）预测综合量表，自注意力插值在32个对比中的20个实现了最低的预测误差（子级模型平均RMSE=0.19(0.06)），在20个对比中优于线性和三次插值，尽管在线性插值中所有ALSFRS-R综合量表模型中证明更为稳定（平均RMSE=0.23(0.10)）。&lt;h4&gt;结论&lt;/h4&gt;识别了功能领域的不同同质性-异质性特征，呼吸和言语表现出患者特定的模式，受益于个性化的增量适应，而吞咽和穿衣功能遵循群体级轨迹，适合迁移模型。这些发现表明，将学习和伪标签技术匹配到功能领域的同质性-异质性特征，可以增强ALS进展跟踪的预测准确性。&lt;h4&gt;翻译&lt;/h4&gt;Clinical monitoring of functional decline in ALS relies on periodic assessments that may miss critical changes occurring between visits. To address this gap, semi-supervised regression models were developed to estimate rates of decline in a case series cohort by targeting ALSFRS- R scale trajectories with continuous in-home sensor monitoring data. Our analysis compared three model paradigms (individual batch learning and cohort-level batch versus incremental fine-tuned transfer learning) across linear slope, cubic polynomial, and ensemble self-attention pseudo-label interpolations. Results revealed cohort homogeneity across functional domains responding to learning methods, with transfer learning improving prediction error for ALSFRS-R subscales in 28 of 32 contrasts (mean RMSE=0.20(0.04)), and individual batch learning for predicting the composite scale (mean RMSE=3.15(1.25)) in 2 of 3. Self-attention interpolation achieved the lowest prediction error for subscale-level models (mean RMSE=0.19(0.06)), capturing complex nonlinear progression patterns, outperforming linear and cubic interpolations in 20 of 32 contrasts, though linear interpolation proved more stable in all ALSFRS-R composite scale models (mean RMSE=0.23(0.10)). We identified distinct homogeneity-heterogeneity profiles across functional domains with respiratory and speech exhibiting patient-specific patterns benefiting from personalized incremental adaptation, while swallowing and dressing functions followed cohort-level trajectories suitable for transfer models. These findings suggest that matching learning and pseudo-labeling techniques to functional domain-specific homogeneity-heterogeneity profiles enhances predictive accuracy in ALS progression tracking. Integrating adaptive model selection within sensor monitoring platforms could enable timely interventions and scalable deployment in future multi-center studies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Clinical monitoring of functional decline in ALS relies on periodicassessments that may miss critical changes occurring between visits. To addressthis gap, semi-supervised regression models were developed to estimate rates ofdecline in a case series cohort by targeting ALSFRS- R scale trajectories withcontinuous in-home sensor monitoring data. Our analysis compared three modelparadigms (individual batch learning and cohort-level batch versus incrementalfine-tuned transfer learning) across linear slope, cubic polynomial, andensembled self-attention pseudo-label interpolations. Results revealed cohorthomogeneity across functional domains responding to learning methods, withtransfer learning improving prediction error for ALSFRS-R subscales in 28 of 32contrasts (mean RMSE=0.20(0.04)), and individual batch learning for predictingthe composite scale (mean RMSE=3.15(1.25)) in 2 of 3. Self-attentioninterpolation achieved the lowest prediction error for subscale-level models(mean RMSE=0.19(0.06)), capturing complex nonlinear progression patterns,outperforming linear and cubic interpolations in 20 of 32 contrasts, thoughlinear interpolation proved more stable in all ALSFRS-R composite scale models(mean RMSE=0.23(0.10)). We identified distinct homogeneity-heterogeneityprofiles across functional domains with respiratory and speech exhibitingpatient-specific patterns benefiting from personalized incremental adaptation,while swallowing and dressing functions followed cohort-level trajectoriessuitable for transfer models. These findings suggest that matching learning andpseudo-labeling techniques to functional domain-specifichomogeneity-heterogeneity profiles enhances predictive accuracy in ALSprogression tracking. Integrating adaptive model selection within sensormonitoring platforms could enable timely interventions and scalable deploymentin future multi-center studies.</description>
      <author>example@mail.com (Noah Marchal, William E. Janes, Mihail Popescu, Xing Song)</author>
      <guid isPermaLink="false">2507.09460v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Lightweight Graph Neural Networks for Enhanced 5G NR Channel Estimation</title>
      <link>http://arxiv.org/abs/2507.09408v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in IEEE PIMRC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GraphNet的新型轻量级图神经网络GNN，旨在提高5G NR系统中的信道估计（CE）性能，尤其在传统方法难以应对的动态环境中。&lt;h4&gt;背景&lt;/h4&gt;有效的信道估计对于优化5G NR系统的性能至关重要，特别是在动态环境中，传统方法在复杂性和适应性方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;设计GraphNet，以增强5G NR系统中的信道估计性能。&lt;h4&gt;方法&lt;/h4&gt;GraphNet采用一种GNN架构，在捕捉必要特征的同时，最小化计算开销。&lt;h4&gt;主要发现&lt;/h4&gt;GraphNet在各种信道条件下表现出色，包括从慢变到高度动态的环境，并在高变化场景中显著优于已知的深度学习CE方法ChannelNet，特别是在块错误率方面。此外，GraphNet内置噪声估计功能，增强了在挑战性信道条件下的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;GraphNet以其显著更轻的计算负担，非常适合实时部署，尤其是在计算资源有限的边缘设备上。GraphNet通过强调GNN在信道估计过程中的潜力，提供了一个可扩展且鲁棒性的解决方案，满足了5G技术不断发展的需求，凸显了其作为下一代无线通信系统解决方案的效率和性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：有效的信道估计CE对于优化5G新无线电NR系统的性能至关重要，尤其是在传统方法在复杂性和适应性方面难以应对的动态环境中。本文介绍了一种名为GraphNet的新型轻量级图神经网络GNN，旨在增强5G NR系统中的CE性能。我们提出的方法利用了一种GNN架构，在捕捉必要特征的同时，最小化计算开销。我们在各种信道条件下评估了GraphNet，包括从慢变到高度动态的环境，并将其性能与已知的基于深度学习的CE方法ChannelNet进行了比较。GraphNet不仅在稳定条件下与ChannelNet的性能相当，在高变化场景中显著优于它，特别是在块错误率方面。此外，它还包含内置的噪声估计功能，增强了在挑战性信道条件下的鲁棒性。由于其显著更轻的计算负担，GraphNet非常适合实时部署，尤其是在计算资源有限的边缘设备上。通过强调GNN在信道估计过程中的潜力，GraphNet提供了一种可扩展且鲁棒性的解决方案，与5G技术不断发展的需求相一致，凸显了其作为下一代无线通信系统解决方案的效率和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective channel estimation CE is critical for optimizing the performance of5G New Radio NR systems particularly in dynamic environments where traditionalmethods struggle with complexity and adaptability This paper introducesGraphNet a novel lightweight Graph Neural Network GNNbased estimator designedto enhance CE in 5G NR Our proposed method utilizes a GNN architecture thatminimizes computational overhead while capturing essential features necessaryfor accurate CE We evaluate GraphNet across various channel conditions fromslowvarying to highly dynamic environments and compare its performance toChannelNet a wellknown deep learningbased CE method GraphNet not only matchesChannelNets performance in stable conditions but significantly outperforms itin highvariation scenarios particularly in terms of Block Error Rate It alsoincludes builtin noise estimation that enhances robustness in challengingchannel conditions Furthermore its significantly lighter computationalfootprint makes GraphNet highly suitable for realtime deployment especially onedge devices with limited computational resources By underscoring the potentialof GNNs to transform CE processes GraphNet offers a scalable and robustsolution that aligns with the evolving demands of 5G technologies highlightingits efficiency and performance as a nextgeneration solution for wirelesscommunication systems</description>
      <author>example@mail.com (Sajedeh Norouzi, Mostafa Rahmani, Yi Chu, Torsten Braun, Kaushik Chowdhury, Alister Burr)</author>
      <guid isPermaLink="false">2507.09408v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Calibrated and Robust Foundation Models for Vision-Language and Medical Image Tasks Under Distribution Shift</title>
      <link>http://arxiv.org/abs/2507.09222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为StaRFM的统一框架，旨在解决低样本迁移学习中分布偏移和置信度不匹配的问题，并在计算机视觉和医学图像分割任务中取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;基础模型如CLIP和SAM通过低样本迁移学习改变了计算机视觉和医学图像处理领域，但其部署受到了分布偏移和置信度不匹配的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出StaRFM框架，旨在解决CLIP和SAM模型在训练和测试数据之间分布偏移和置信度不匹配的问题。&lt;h4&gt;方法&lt;/h4&gt; StaRFM框架引入了Fisher信息惩罚（FIP）来减少CLIP和SAM嵌入中的协变量偏移，并扩展到3D医学数据；同时，引入置信度不匹配惩罚（CMP）来校准分割任务中的不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;StaRFM在19个视觉数据集上（如ImageNet、Office-Home）和医学分割任务（如BraTS、ATLAS）上表现出优异的性能，如提高了+3.5%的准确率，降低了28%的期望交叉熵（ECE），以及4.8mm的95% Householder距离（HD95），并且相比先前的方法降低了40%的跨域性能差距。&lt;h4&gt;结论&lt;/h4&gt;StaRFM是一个可插拔的框架，只需最小程度的架构更改即可与基础模型无缝集成，并有效解决了分布偏移和置信度不匹配的问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型如CLIP和SAM通过低样本迁移学习改变了计算机视觉和医学图像处理领域。然而，这些模型的部署受到了两个关键挑战的限制：训练和测试数据之间的分布偏移，以及导致过度自信的错误预测的置信度不匹配。这些问题在视觉语言分类和医学分割任务中表现出不同的特征，但现有的解决方案仍然是特定于领域的。我们提出了StaRFM，一个解决这两个挑战的统一框架。它引入了Fisher信息惩罚（FIP），通过分块正则化扩展到3D医学数据，以减少CLIP和SAM嵌入中的协变量偏移。此外，置信度不匹配惩罚（CMP）被重新定义为适用于体素级预测，以校准分割任务中的不确定性。我们通过PAC-Bayes界限的理论推导表明，FIP通过Fisher-Rao范数控制泛化，而CMP通过Brier分数优化最小化校准误差。StaRFM在19个视觉数据集（例如，ImageNet、Office-Home）上表现出了一致的性能，如提高了+3.5%的准确率和降低了28%的期望交叉熵（ECE），在医学分割（例如，BraTS、ATLAS）上达到了84.7%的DSC和4.8mm的95% Householder距离（HD95），与先前基准方法相比，降低了40%的跨域性能差距。该框架是可插拔的，需要最小的架构更改才能与基础模型无缝集成。代码和模型将在https://anonymous.4open.science/r/StaRFM-C0CD/README.md发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models like CLIP and SAM have transformed computer vision andmedical imaging via low-shot transfer learning. However, deployment of thesemodels hindered by two key challenges: \textit{distribution shift} betweentraining and test data, and \textit{confidence misalignment} that leads tooverconfident incorrect predictions. These issues manifest differently invision-language classification and medical segmentation tasks, yet existingsolutions remain domain-specific. We propose \textit{StaRFM}, a unifiedframework addressing both challenges. It introduces a Fisher informationpenalty (FIP), extended to 3D medical data via patch-wise regularization, toreduce covariate shift in CLIP and SAM embeddings. Additionally, a confidencemisalignment penalty (CMP), reformulated for voxel-level predictions,calibrates uncertainty in segmentation tasks. We theoretically derive PAC-Bayesbounds showing FIP controls generalization via the Fisher-Rao norm, while CMPminimizes calibration error through Brier score optimization. StaRFM showsconsistent performance like \texttt{+}3.5\% accuracy and 28\% lower ECE on 19vision datasets (e.g., ImageNet, Office-Home), 84.7\% DSC and 4.8mm HD95 inmedical segmentation (e.g., BraTS, ATLAS), and 40\% lower cross-domainperformance gap compared to prior benchmarking methods. The framework isplug-and-play, requiring minimal architectural changes for seamless integrationwith foundation models. Code and models will be released athttps://anonymous.4open.science/r/StaRFM-C0CD/README.md</description>
      <author>example@mail.com (Behraj Khan, Tahir Syed)</author>
      <guid isPermaLink="false">2507.09222v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Job Classification with Similarity Graph Integration</title>
      <link>http://arxiv.org/abs/2507.09949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的表示学习和分类模型，用于在线招聘中的职位分类，以提高推荐系统、搜索排名和劳动力市场分析的效果。&lt;h4&gt;背景&lt;/h4&gt;在线招聘领域动态变化，准确的职位分类对于优化推荐系统、搜索排名和劳动力市场分析至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统文本分类方法的不足，特别是它们无法充分利用行业类别的层次结构，本文提出了一种新的模型。&lt;h4&gt;方法&lt;/h4&gt;该模型将职位和层次行业类别嵌入到一个潜在嵌入空间中，结合了标准职业分类（SOC）系统和内部层次分类法Carotene，以捕捉图和层次关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该模型能够有效地利用层次结构和丰富的语义特征，显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;本研究为提高职位分类准确性提供了一个稳健的框架，支持招聘行业更明智的决策。&lt;h4&gt;翻译&lt;/h4&gt;在在线招聘的动态领域中，准确的职位分类对于优化职位推荐系统、搜索排名和劳动力市场分析至关重要。随着劳动力市场的演变，职位名称和描述的日益复杂需要能够有效利用职位数据中复杂关系的复杂模型。传统的文本分类方法往往不足，尤其是在无法充分利用行业类别的层次结构方面。为了解决这些限制，我们提出了一种新的表示学习和分类模型，该模型将职位和层次行业类别嵌入到一个潜在嵌入空间中。我们的模型结合了标准职业分类（SOC）系统和我们内部的层次分类法Carotene，以捕捉图和层次关系，从而提高分类准确性。通过将层次行业类别嵌入到一个共享的潜在空间中，我们解决了冷启动问题，并增强了候选人到职位机会的动态匹配。在大型职位发布数据集上的广泛实验证明了该模型利用层次结构和丰富语义特征的能力，显著优于现有方法。这项研究为提高职位分类准确性提供了一个稳健的框架，支持招聘行业更明智的决策。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the dynamic realm of online recruitment, accurate job classification isparamount for optimizing job recommendation systems, search rankings, and labormarket analyses. As job markets evolve, the increasing complexity of job titlesand descriptions necessitates sophisticated models that can effectivelyleverage intricate relationships within job data. Traditional textclassification methods often fall short, particularly due to their inability tofully utilize the hierarchical nature of industry categories. To address theselimitations, we propose a novel representation learning and classificationmodel that embeds jobs and hierarchical industry categories into a latentembedding space. Our model integrates the Standard Occupational Classification(SOC) system and an in-house hierarchical taxonomy, Carotene, to capture bothgraph and hierarchical relationships, thereby improving classificationaccuracy. By embedding hierarchical industry categories into a shared latentspace, we tackle cold start issues and enhance the dynamic matching ofcandidates to job opportunities. Extensive experimentation on a large-scaledataset of job postings demonstrates the model's superior ability to leveragehierarchical structures and rich semantic features, significantly outperformingexisting methods. This research provides a robust framework for improving jobclassification accuracy, supporting more informed decision-making in therecruitment industry.</description>
      <author>example@mail.com (Md Ahsanul Kabir, Kareem Abdelfatah, Mohammed Korayem, Mohammad Al Hasan)</author>
      <guid isPermaLink="false">2507.09949v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Tiny Reward Models</title>
      <link>http://arxiv.org/abs/2507.09973v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2025 ICML Efficient Systems for Foundation Models Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TinyRM是一系列小型双向掩码语言模型，在推理和安全性偏好建模任务上与大型模型相当，但参数量仅为4000万，且资源消耗更少。&lt;h4&gt;背景&lt;/h4&gt;大型解码器语言模型成为强化学习从人类反馈中建模奖励的占主导地位架构，但它们在测试时策略中的应用导致推理成本成为一个日益关注的问题。&lt;h4&gt;目的&lt;/h4&gt;提出TinyRM，以解决大型语言模型在推理成本方面的问题，并实现高效且可扩展的偏好建模。&lt;h4&gt;方法&lt;/h4&gt;TinyRM结合了FLAN风格的提示、方向性低秩适应（DoRA）和层冻结技术，在RewardBench上取得了强性能。&lt;h4&gt;主要发现&lt;/h4&gt;小型模型从特定领域的调优策略中受益，尤其是在推理任务中，轻量级的微调方法特别有效。&lt;h4&gt;结论&lt;/h4&gt;虽然构建通用模型和对话偏好建模仍然存在挑战，但初步结果表明，轻量级双向架构在偏好建模方面具有高效、可扩展的潜力。&lt;h4&gt;翻译&lt;/h4&gt;TinyRM is a family of small, bidirectional masked language models that rival the capabilities of models over 175 times larger on reasoning and safety preference modeling tasks, with as few as 400 million parameters and significantly fewer resource consumption. The background is that large decoder-based language models have become the dominant architecture for reward modeling in reinforcement learning from human feedback (RLHF), but their inference costs have become a growing concern when they are used in test-time strategies. The purpose of this research is to propose TinyRM to address the issue of inference costs of large language models and to achieve efficient and scalable preference modeling. The method combines FLAN-style prompting, Directional Low-Rank Adaptation (DoRA), and layer freezing techniques to achieve strong performance on the RewardBench. The main findings suggest that small models benefit from domain-specific tuning strategies, especially in reasoning tasks, where lightweight fine-tuning methods are particularly effective. Although there are still challenges in building generalist models and conversational preference modeling, the preliminary results highlight the promise of lightweight bidirectional architectures as efficient and scalable alternatives for preference modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large decoder-based language models have become the dominant architecture forreward modeling in reinforcement learning from human feedback (RLHF). However,as reward models are increasingly deployed in test-time strategies, theirinference costs become a growing concern. We present TinyRM, a family of small,bidirectional masked language models (MLMs) with as few as 400 millionparameters, that rival the capabilities of models over 175 times larger onreasoning and safety preference modeling tasks. TinyRM combines FLAN-styleprompting, Directional Low-Rank Adaptation (DoRA), and layer freezing toachieve strong performance on RewardBench, despite using significantly fewerresources. Our experiments suggest that small models benefit fromdomain-specific tuning strategies, particularly in reasoning, where lightweightfinetuning methods are especially effective. While challenges remain inbuilding generalist models and conversational preference modeling, ourpreliminary results highlight the promise of lightweight bidirectionalarchitectures as efficient, scalable alternatives for preference modeling.</description>
      <author>example@mail.com (Sarah Pan)</author>
      <guid isPermaLink="false">2507.09973v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing Text-to-Image Diffusion Models for Point Cloud Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2507.09102v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PointSD的框架，用于3D自监督学习，该框架利用了Stable Diffusion模型的能力来提升3D点云的自监督学习性能。&lt;h4&gt;背景&lt;/h4&gt;扩散模型在文本到图像生成中广泛应用，且在2D表示学习中表现出色。最近，该框架被扩展到3D自监督学习，通过构建条件点生成器来增强3D表示。&lt;h4&gt;目的&lt;/h4&gt;为了克服3D扩散模型在小型数据集上训练时的性能限制，本研究旨在探索利用大规模数据集训练的文本到图像扩散模型（如Stable Diffusion）来提升3D自监督学习的能力。&lt;h4&gt;方法&lt;/h4&gt;PointSD框架通过将Stable Diffusion模型的文本编码器替换为3D编码器，训练了一个点到图像的扩散模型。该模型能够利用点云引导渲染的噪声图像的降噪过程。接着，使用无噪声图像作为输入，点云作为条件，提取Stable Diffusion特征，并训练一个3D骨干网络，使其特征与SD特征对齐，以促进直接语义学习。&lt;h4&gt;主要发现&lt;/h4&gt;在下游点云任务和消融研究中，PointSD框架证明了Stable Diffusion模型能够增强点云自监督学习。&lt;h4&gt;结论&lt;/h4&gt;PointSD框架有效地利用了Stable Diffusion模型来提升3D自监督学习，表明大规模数据集训练的扩散模型在3D表示学习中具有潜在价值。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a framework named PointSD for 3D self-supervised learning, which utilizes the capabilities of the text-to-image diffusion model, Stable Diffusion, to enhance the performance of 3D point cloud self-supervised learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion-based models, widely used in text-to-image generation, have proveneffective in 2D representation learning. Recently, this framework has beenextended to 3D self-supervised learning by constructing a conditional pointgenerator for enhancing 3D representations. However, its performance remainsconstrained by the 3D diffusion model, which is trained on the available 3Ddatasets with limited size. We hypothesize that the robust capabilities oftext-to-image diffusion models, particularly Stable Diffusion (SD), which istrained on large-scale datasets, can help overcome these limitations. Toinvestigate this hypothesis, we propose PointSD, a framework that leverages theSD model for 3D self-supervised learning. By replacing the SD model's textencoder with a 3D encoder, we train a point-to-image diffusion model thatallows point clouds to guide the denoising of rendered noisy images. With thetrained point-to-image diffusion model, we use noise-free images as the inputand point clouds as the condition to extract SD features. Next, we train a 3Dbackbone by aligning its features with these SD features, thereby facilitatingdirect semantic learning. Comprehensive experiments on downstream point cloudtasks and ablation studies demonstrate that the SD model can enhance pointcloud self-supervised learning. Code is publicly available athttps://github.com/wdttt/PointSD.</description>
      <author>example@mail.com (Yiyang Chen, Shanshan Zhao, Lunhao Duan, Changxing Ding, Dacheng Tao)</author>
      <guid isPermaLink="false">2507.09102v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Can Contrastive Learning Improve Class-Imbalanced Diffusion Model?</title>
      <link>http://arxiv.org/abs/2507.09052v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对长尾类别图像合成中存在的类别不平衡问题，提出了一种新的对比学习方法，以提高尾类图像的多样性，同时保持头部类图像的准确性和多样性。&lt;h4&gt;背景&lt;/h4&gt;训练数据往往呈现长尾分布，尾类类别图像数量有限，导致模型容易发生模式崩溃，合成图像的多样性降低。&lt;h4&gt;目的&lt;/h4&gt;在保证头部类图像准确性和多样性的前提下，提高尾类图像的多样性。&lt;h4&gt;方法&lt;/h4&gt;引入两种简单但有效的对比损失函数：一是利用负样本的无监督InfoNCE损失来增加合成图像之间的距离或差异性，尤其是针对尾类；二是通过MSE损失在较大时间步长下对比有条件生成和无条件生成，使去噪过程对初始步骤不敏感，从而通过头部类别的知识共享丰富尾类。&lt;h4&gt;主要发现&lt;/h4&gt;对比学习框架易于实现，在CIFAR10/100-LT、PlacesLT、TinyImageNetLT和ImageNetLT等不同数据集上，均优于标准DDPM和替代方法，有效提高了类别不平衡扩散模型的性能。&lt;h4&gt;结论&lt;/h4&gt;首次将条件-无条件对齐应用于扩散模型，通过对比学习成功提高了类别不平衡扩散模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training data for class-conditional image synthesis often exhibit along-tailed distribution with limited images for tail classes. Such animbalance causes mode collapse and reduces the diversity of synthesized imagesfor tail classes. For class-conditional diffusion models trained on imbalanceddata, we aim to improve the diversity of tail class images without compromisingthe fidelity and diversity of head class images. We achieve this by introducingtwo deceptively simple but highly effective contrastive loss functions.Firstly, we employ an unsupervised InfoNCE loss utilizing negative samples toincrease the distance/dissimilarity among synthetic images, particularly fortail classes. To further enhance the diversity of tail classes, our second lossis an MSE loss that contrasts class-conditional generation with unconditionalgeneration at large timesteps. This second loss makes the denoising processinsensitive to class conditions for the initial steps, which enriches tailclasses through knowledge sharing from head classes. Conditional-unconditionalalignment has been shown to enhance the performance of long-tailed GAN. We arethe first to adapt such alignment to diffusion models. We successfullyleveraged contrastive learning for class-imbalanced diffusion models. Ourcontrastive learning framework is easy to implement and outperforms standardDDPM and alternative methods for class-imbalanced diffusion models acrossvarious datasets, including CIFAR10/100-LT, PlacesLT, TinyImageNetLT, andImageNetLT.</description>
      <author>example@mail.com (Fang Chen, Alex Villa, Gongbo Liang, Xiaoyi Lu, Meng Tang)</author>
      <guid isPermaLink="false">2507.09052v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>NMIXX: Domain-Adapted Neural Embeddings for Cross-Lingual eXploration of Finance</title>
      <link>http://arxiv.org/abs/2507.09601v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了NMIXX，一套针对金融领域定制的跨语言嵌入模型，以及KorFinSTS，一个包含新闻、公告、研究报告和法规的韩语金融STS基准，旨在解决通用句子嵌入模型在处理低资源语言（如韩语）的金融语义时遇到的困难。&lt;h4&gt;背景&lt;/h4&gt;通用句子嵌入模型在处理特定领域的金融语义时，特别是在低资源语言中，往往难以捕捉到专业术语、时间意义的变化以及不匹配的双语词汇。&lt;h4&gt;目的&lt;/h4&gt;提出NMIXX模型和KorFinSTS基准，以解决上述问题，并提高在金融领域的跨语言表示学习。&lt;h4&gt;方法&lt;/h4&gt;NMIXX模型通过使用18.8K高置信度的三元组进行微调，这些三元组包括领域内释义、来自语义变化类型的硬负例以及精确的韩英翻译。KorFinSTS基准覆盖了新闻、公告、研究报告和法规，旨在揭示通用基准未能捕捉到的细微差别。&lt;h4&gt;主要发现&lt;/h4&gt;NMIXX的多语言bge-m3变体在英语FinSTS上取得了Spearman's rho增益+0.10，在KorFinSTS上取得了+0.22，优于其预适应检查点，并大幅超越了其他模型，同时在一般STS性能上略有妥协。分析显示，具有更丰富韩语标记覆盖率的模型能更有效地适应，强调了在低资源、跨语言环境中，分词器设计的重要性。&lt;h4&gt;结论&lt;/h4&gt;通过公开提供模型和基准，本文为社区提供了强大的工具，用于在金融领域进行领域适应性的多语言表示学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; General-purpose sentence embedding models often struggle to capturespecialized financial semantics, especially in low-resource languages likeKorean, due to domain-specific jargon, temporal meaning shifts, and misalignedbilingual vocabularies. To address these gaps, we introduce NMIXX (NeuraleMbeddings for Cross-lingual eXploration of Finance), a suite of cross-lingualembedding models fine-tuned with 18.8K high-confidence triplets that pairin-domain paraphrases, hard negatives derived from a semantic-shift typology,and exact Korean-English translations. Concurrently, we release KorFinSTS, a1,921-pair Korean financial STS benchmark spanning news, disclosures, researchreports, and regulations, designed to expose nuances that general benchmarksmiss.  When evaluated against seven open-license baselines, NMIXX's multilingualbge-m3 variant achieves Spearman's rho gains of +0.10 on English FinSTS and+0.22 on KorFinSTS, outperforming its pre-adaptation checkpoint and surpassingother models by the largest margin, while revealing a modest trade-off ingeneral STS performance. Our analysis further shows that models with richerKorean token coverage adapt more effectively, underscoring the importance oftokenizer design in low-resource, cross-lingual settings. By making both modelsand the benchmark publicly available, we provide the community with robusttools for domain-adapted, multilingual representation learning in finance.</description>
      <author>example@mail.com (Hanwool Lee, Sara Yu, Yewon Hwang, Jonghyun Choi, Heejae Ahn, Sungbum Jung, Youngjae Yu)</author>
      <guid isPermaLink="false">2507.09601v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>TolerantECG: A Foundation Model for Imperfect Electrocardiogram</title>
      <link>http://arxiv.org/abs/2507.09887v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures. Accepted to ACM Multimedia 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TolerantECG的基础模型，用于增强心电图（ECG）信号的处理能力，使其在存在噪声或标准12导联记录中缺少一导或多导的情况下仍能有效地诊断心脏病。&lt;h4&gt;背景&lt;/h4&gt;心电图是诊断心脏病的重要工具，但其效果可能因噪声或缺少导联而受到影响，导致诊断错误或不确定性。&lt;h4&gt;目的&lt;/h4&gt;开发一种鲁棒的ECG信号处理模型，以解决噪声和导联缺失的问题，提高心电图诊断的准确性。&lt;h4&gt;方法&lt;/h4&gt;TolerantECG结合了对比学习和自监督学习框架，同时学习ECG信号表示、相应的文本报告描述以及被破坏或缺少导联的信号。&lt;h4&gt;主要发现&lt;/h4&gt;在PTB-XL数据集的多种ECG信号条件和类别级别中，TolerantECG的表现始终处于最佳或第二最佳水平，并在MIT-BIH心律失常数据库上取得了最高性能。&lt;h4&gt;结论&lt;/h4&gt;TolerantECG是一种有效的ECG信号处理模型，能够提高心电图诊断的准确性和可靠性，尤其是在存在噪声或导联缺失的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The electrocardiogram (ECG) is an essential and effective tool for diagnosingheart diseases. However, its effectiveness can be compromised by noise orunavailability of one or more leads of the standard 12-lead recordings,resulting in diagnostic errors or uncertainty. To address these challenges, wepropose TolerantECG, a foundation model for ECG signals that is robust to noiseand capable of functioning with arbitrary subsets of the standard 12-lead ECG.TolerantECG training combines contrastive and self-supervised learningframeworks to jointly learn ECG signal representations alongside theircorresponding knowledge-retrieval-based text report descriptions and corruptedor lead-missing signals. Comprehensive benchmarking results demonstrate thatTolerantECG consistently ranks as the best or second-best performer acrossvarious ECG signal conditions and class levels in the PTB-XL dataset, andachieves the highest performance on the MIT-BIH Arrhythmia Database.</description>
      <author>example@mail.com (Huynh Nguyen Dang, Thang Pham, Ngan Le, Van Nguyen)</author>
      <guid isPermaLink="false">2507.09887v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Continuous-Time Signal Decomposition: An Implicit Neural Generalization of PCA and ICA</title>
      <link>http://arxiv.org/abs/2507.09091v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, 1 table. MLSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通用的低秩分解问题方法，包括连续时间向量值信号的主成分分析（PCA）和独立成分分析（ICA），并提供了模型无关的隐式神经网络信号表示框架来学习问题的数值近似解。&lt;h4&gt;背景&lt;/h4&gt;低秩分解问题如PCA和ICA在处理连续时间向量值信号时存在挑战。&lt;h4&gt;目的&lt;/h4&gt;统一PCA和ICA在连续设置中的方法，并扩展到连续域，以便应用于点云和不规则采样的信号。&lt;h4&gt;方法&lt;/h4&gt;将信号建模为连续时间随机过程，通过网络损失中的对比函数项统一PCA和ICA方法，并强制学习分解中的源信号所需的统计特性（去相关、独立性）。&lt;h4&gt;主要发现&lt;/h4&gt;该方法允许将低秩分解应用于点云和不规则采样的信号，这些信号在标准技术中不可用。&lt;h4&gt;结论&lt;/h4&gt;本文提供了一种新的方法来处理连续时间信号的低秩分解问题，该方法在连续域中有效，并扩展了低秩分解的应用范围。&lt;h4&gt;翻译&lt;/h4&gt;本文推广了低秩分解问题，如连续时间向量值信号的主成分分析（PCA）和独立成分分析（ICA），并提供了一个模型无关的隐式神经网络信号表示框架来学习该问题的数值近似解。将信号建模为连续时间随机过程，我们通过网络损失中的对比函数项统一了连续设置中的PCA和ICA方法，通过在分解中学习源信号的期望统计特性（去相关、独立性）来强制这些特性。这种扩展到连续域允许将此类分解应用于点云和不规则采样的信号，这些信号在标准技术中不可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We generalize the low-rank decomposition problem, such as principal andindependent component analysis (PCA, ICA) for continuous-time vector-valuedsignals and provide a model-agnostic implicit neural signal representationframework to learn numerical approximations to solve the problem. Modelingsignals as continuous-time stochastic processes, we unify the approaches toboth the PCA and ICA problems in the continuous setting through a contrastfunction term in the network loss, enforcing the desired statistical propertiesof the source signals (decorrelation, independence) learned in thedecomposition. This extension to a continuous domain allows the application ofsuch decompositions to point clouds and irregularly sampled signals wherestandard techniques are not applicable.</description>
      <author>example@mail.com (Shayan K. Azmoodeh, Krishna Subramani, Paris Smaragdis)</author>
      <guid isPermaLink="false">2507.09091v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Infinite Video Understanding</title>
      <link>http://arxiv.org/abs/2507.09068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了在视频理解领域，尽管大语言模型和多模态扩展模型（MLLMs）取得了显著进展，但处理和理解的时长超过分钟或小时的视频内容仍然存在挑战。&lt;h4&gt;背景&lt;/h4&gt;大语言模型和MLLMs的快速发展推动了视频理解领域的进步，但处理长时间视频内容时，现有的模型仍面临计算和内存限制。&lt;h4&gt;目的&lt;/h4&gt;提出无限视频理解作为多媒体研究的下一个前沿领域，即模型能够连续处理、理解和推理任意时长，甚至可能无限的视频数据。&lt;h4&gt;方法&lt;/h4&gt;论文从长/超长视频理解和相关领域的研究中汲取灵感，概述了实现这一转型能力的关键挑战和主要研究方向。&lt;h4&gt;主要发现&lt;/h4&gt;现有的模型在处理长时间视频内容时，仍然面临计算和内存限制，以及在时间连贯性、事件追踪和细节保持方面的挑战。&lt;h4&gt;结论&lt;/h4&gt;无限视频理解是一个具有挑战性的研究目标，可以为多媒体和更广泛的AI研究社区提供创新动力，推动流媒体架构、持久内存机制、层次化和自适应表示、事件中心推理以及新评估范式等领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型语言模型（LLMs）和多模态扩展（MLLMs）的快速发展推动了视频理解领域的显著进步。然而，一个基本挑战依然存在：有效地处理和理解时长超过分钟或小时的视频内容。尽管像Video-XL-2这样的最新努力展示了新型架构解决方案以提高极端效率，以及如HoPE和VideoRoPE++等在位置编码方面的进步旨在改善在广泛背景下的时空理解，但当前最先进的模型在面临大量视觉标记的长时间序列时，仍然遭遇显著的计算和内存限制。此外，尽管在深度视频发现等代理推理系统中取得了进步，但保持时间连贯性、跟踪复杂事件以及在长时间内保持细粒度细节仍然是非常困难的挑战。本文档认为，多媒体研究的一个逻辑上虽雄心勃勃但却是必要的下一个前沿是无限视频理解——即模型能够连续处理、理解和推理任意时长，甚至可能是无限的视频数据的能力。我们认为，将无限视频理解定位为蓝 sky 研究目标为多媒体以及更广泛的AI研究社区提供了至关重要的指南，推动了对流媒体架构、持久内存机制、层次化和自适应表示、以事件为中心的推理和新评估范式等领域的创新。从长/超长视频理解以及几个密切相关领域的研究中汲取灵感，我们概述了实现这一变革性能力的关键挑战和主要研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancements in Large Language Models (LLMs) and their multimodalextensions (MLLMs) have ushered in remarkable progress in video understanding.However, a fundamental challenge persists: effectively processing andcomprehending video content that extends beyond minutes or hours. While recentefforts like Video-XL-2 have demonstrated novel architectural solutions forextreme efficiency, and advancements in positional encoding such as HoPE andVideoRoPE++ aim to improve spatio-temporal understanding over extensivecontexts, current state-of-the-art models still encounter significantcomputational and memory constraints when faced with the sheer volume of visualtokens from lengthy sequences. Furthermore, maintaining temporal coherence,tracking complex events, and preserving fine-grained details over extendedperiods remain formidable hurdles, despite progress in agentic reasoningsystems like Deep Video Discovery. This position paper posits that a logical,albeit ambitious, next frontier for multimedia research is Infinite VideoUnderstanding -- the capability for models to continuously process, understand,and reason about video data of arbitrary, potentially never-ending duration. Weargue that framing Infinite Video Understanding as a blue-sky researchobjective provides a vital north star for the multimedia, and the wider AI,research communities, driving innovation in areas such as streamingarchitectures, persistent memory mechanisms, hierarchical and adaptiverepresentations, event-centric reasoning, and novel evaluation paradigms.Drawing inspiration from recent work on long/ultra-long video understanding andseveral closely related fields, we outline the core challenges and key researchdirections towards achieving this transformative capability.</description>
      <author>example@mail.com (Dell Zhang, Xiangyu Chen, Jixiang Luo, Mengxi Jia, Changzhi Sun, Ruilong Ren, Jingren Liu, Hao Sun, Xuelong Li)</author>
      <guid isPermaLink="false">2507.09068v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>AdaBrain-Bench: Benchmarking Brain Foundation Models for Brain-Computer Interface Applications</title>
      <link>http://arxiv.org/abs/2507.09882v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AdaBrain-Bench的大规模标准化基准，用于系统评估脑基础模型在广泛非侵入性BCI任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;非侵入性脑-机接口（BCI）安全且易于访问，在家庭和临床环境中应用广泛，但高噪声水平和有限的任务特定数据限制了解码能力。&lt;h4&gt;目的&lt;/h4&gt;解决当前领域缺乏综合、实用和可扩展的基准来评估公共基础模型在多种BCI任务中的效用的问题。&lt;h4&gt;方法&lt;/h4&gt;AdaBrain-Bench包含涵盖7个关键应用的代表性BCI解码数据集，引入了与多维度评估指标和一组适配工具集成的简化任务适配流程。&lt;h4&gt;主要发现&lt;/h4&gt;AdaBrain-Bench为评估脑基础模型在关键迁移设置（包括跨个体、多个体和少样本场景）中的泛化能力提供了一个全面框架。&lt;h4&gt;结论&lt;/h4&gt;通过AdaBrain-Bench评估了一系列公开可用的脑基础模型，并提供了在各种场景中选择适当模型的实践见解，以促进稳健和泛化的神经解码解决方案的进步。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces AdaBrain-Bench, a large-scale standardized benchmark for systematically evaluating brain foundation models in widespread non-invasive BCI tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-invasive Brain-Computer Interfaces (BCI) offer a safe and accessiblemeans of connecting the human brain to external devices, with broadapplications in home and clinical settings to enhance human capabilities.However, the high noise level and limited task-specific data in non-invasivesignals constrain decoding capabilities. Recently, the adoption ofself-supervised pre-training is transforming the landscape of non-invasive BCIresearch, enabling the development of brain foundation models to capturegeneric neural representations from large-scale unlabeledelectroencephalography (EEG) signals with substantial noises. However, despitethese advances, the field currently lacks comprehensive, practical andextensible benchmarks to assess the utility of the public foundation modelsacross diverse BCI tasks, hindering their widespread adoption. To address thischallenge, we present AdaBrain-Bench, a large-scale standardized benchmark tosystematically evaluate brain foundation models in widespread non-invasive BCItasks. AdaBrain-Bench encompasses a diverse collection of representative BCIdecoding datasets spanning 7 key applications. It introduces a streamlined taskadaptation pipeline integrated with multi-dimensional evaluation metrics and aset of adaptation tools. The benchmark delivers an inclusive framework forassessing generalizability of brain foundation models across key transfersettings, including cross-subject, multi-subject, and few-shot scenarios. Weleverage AdaBrain-Bench to evaluate a suite of publicly available brainfoundation models and offer insights into practices for selecting appropriatemodels in various scenarios. We make our benchmark pipeline available to enablereproducible research and external use, offering a continuously evolvingplatform to foster progress toward robust and generalized neural decodingsolutions.</description>
      <author>example@mail.com (Jiamin Wu, Zichen Ren, Junyu Wang, Pengyu Zhu, Yonghao Song, Mianxin Liu, Qihao Zheng, Lei Bai, Wanli Ouyang, Chunfeng Song)</author>
      <guid isPermaLink="false">2507.09882v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Learning and Transferring Better with Depth Information in Visual Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2507.09180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉变压器的视觉骨干网络，用于融合RGB和深度模态，以增强泛化能力。&lt;h4&gt;背景&lt;/h4&gt;深度信息对场景外观变化具有鲁棒性，并内在地携带3D空间细节。&lt;h4&gt;目的&lt;/h4&gt;通过融合不同模态，提高视觉表示的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;首先由不同的CNN主干处理不同模态，然后将组合的卷积特征传递给可扩展的视觉变压器以获得视觉表示。此外，设计了带有遮蔽和无遮蔽标记的对比无监督学习方案，以加速强化学习过程中的样本效率。对于从模拟到现实的学习迁移，开发了灵活的课程学习计划，以在训练过程中部署域随机化。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法能够有效地融合RGB和深度信息，并提高模型的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在增强泛化能力方面是有效的，并且通过对比无监督学习和域随机化技术提高了样本效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：深度信息对场景外观变化具有鲁棒性，并内在地携带3D空间细节。在本文中，提出了一种基于视觉变压器的视觉骨干网络，用于融合RGB和深度模态，以增强泛化。首先，不同的模态由不同的CNN主干处理，然后将组合的卷积特征传递给可扩展的视觉变压器以获得视觉表示。此外，设计了一种带有遮蔽和无遮蔽标记的对比无监督学习方案，以加速强化学习过程中的样本效率。对于从模拟到现实的学习迁移，开发了一种灵活的课程学习计划，以在训练过程中部署域随机化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth information is robust to scene appearance variations and inherentlycarries 3D spatial details. In this paper, a visual backbone based on thevision transformer is proposed to fuse RGB and depth modalities for enhancinggeneralization. Different modalities are first processed by separate CNN stems,and the combined convolutional features are delivered to the scalable visiontransformer to obtain visual representations. Moreover, a contrastiveunsupervised learning scheme is designed with masked and unmasked tokens toaccelerate the sample efficiency during the reinforcement learning progress.For sim2real transfer, a flexible curriculum learning schedule is developed todeploy domain randomization over training processes.</description>
      <author>example@mail.com (Zichun Xu, Yuntao Li, Zhaomin Wang, Lei Zhuang, Guocai Yang, Jingdong Zhao)</author>
      <guid isPermaLink="false">2507.09180v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Fair CCA for Fair Representation Learning: An ADNI Study</title>
      <link>http://arxiv.org/abs/2507.09382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的公平性CCA方法，用于公平表示学习，确保投影特征与敏感属性无关，从而在不牺牲准确性的情况下提高公平性。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习中公平性的重要性日益凸显，公平CCA受到了关注。然而，先前的方法往往忽略了下游分类任务的影响，限制了其适用性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的公平CCA方法，确保投影特征独立于敏感属性，从而在不损害准确性的情况下提高公平性。&lt;h4&gt;方法&lt;/h4&gt;在合成数据和来自阿尔茨海默病神经影像学倡议（ADNI）的真实世界数据上验证了该方法，证明了其在保持高相关性分析性能的同时，提高了分类任务的公平性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在保持高相关性分析性能的同时，提高了分类任务的公平性。&lt;h4&gt;结论&lt;/h4&gt;该方法使得在神经影像学研究中实现公平的机器学习成为可能，这对于实现无偏分析至关重要。&lt;h4&gt;翻译&lt;/h4&gt;Canonical correlation analysis (CCA) is a technique for finding correlations between different data modalities and learning low-dimensional representations. As fairness becomes crucial in machine learning, fair CCA has gained attention. However, previous approaches often overlook the impact on downstream classification tasks, limiting applicability. We propose a novel fair CCA method for fair representation learning, ensuring the projected features are independent of sensitive attributes, thus enhancing fairness without compromising accuracy. We validate our method on synthetic data and real-world data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), demonstrating its ability to maintain high correlation analysis performance while improving fairness in classification tasks. Our work enables fair machine learning in neuroimaging studies where unbiased analysis is essential.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Canonical correlation analysis (CCA) is a technique for finding correlationsbetween different data modalities and learning low-dimensional representations.As fairness becomes crucial in machine learning, fair CCA has gained attention.However, previous approaches often overlook the impact on downstreamclassification tasks, limiting applicability. We propose a novel fair CCAmethod for fair representation learning, ensuring the projected features areindependent of sensitive attributes, thus enhancing fairness withoutcompromising accuracy. We validate our method on synthetic data and real-worlddata from the Alzheimer's Disease Neuroimaging Initiative (ADNI), demonstratingits ability to maintain high correlation analysis performance while improvingfairness in classification tasks. Our work enables fair machine learning inneuroimaging studies where unbiased analysis is essential.</description>
      <author>example@mail.com (Bojian Hou, Zhanliang Wang, Zhuoping Zhou, Boning Tong, Zexuan Wang, Jingxuan Bao, Duy Duong-Tran, Qi Long, Li Shen)</author>
      <guid isPermaLink="false">2507.09382v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Predictive Causal Inference via Spatio-Temporal Modeling and Penalized Empirical Likelihood</title>
      <link>http://arxiv.org/abs/2507.08896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究介绍了一种用于预测因果推断的综合框架，旨在克服传统单一模型方法固有的局限性。&lt;h4&gt;背景&lt;/h4&gt;研究指出，传统的单一模型方法在预测因果推断方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;目的是为了提高预测因果推断的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;结合了隐马尔可夫模型（HMM）进行空间健康状况估计和多重任务与多重图卷积网络（MTGCN）捕捉时间结果轨迹。该框架对时间和空间信息进行非对称处理，在结果回归中将它们视为内生变量，在倾向得分模型中将它们视为外生变量，从而扩展了标准双重稳健性治疗效果估计，以共同增强偏差校正和预测精度。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟研究来模拟潜在疾病动态并评估模型在不同条件下的性能，重点关注癌症、痴呆和帕金森病等临床领域，这些领域中的治疗效果难以直接观察。&lt;h4&gt;结论&lt;/h4&gt;提出的框架通过结构性地适应生物医学数据中常见的时空复杂性，推进了预测因果推断。&lt;h4&gt;翻译&lt;/h4&gt;本研究提出了一种综合框架，用于预测因果推断，旨在克服传统单一模型方法固有的局限性。具体而言，我们结合了隐马尔可夫模型（HMM）进行空间健康状况估计和多重任务与多重图卷积网络（MTGCN）捕捉时间结果轨迹。该框架对时间和空间信息进行非对称处理，将它们视为结果回归中的内生变量和倾向得分模型中的外生变量，从而扩展了标准双重稳健性治疗效果估计，以共同增强偏差校正和预测精度。为了证明其效用，我们重点关注癌症、痴呆和帕金森病等临床领域，这些领域中的治疗效果难以直接观察。通过模拟研究来模拟潜在疾病动态并评估模型在不同条件下的性能。总的来说，该框架通过结构性地适应生物医学数据中常见的时空复杂性，推进了预测因果推断。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study introduces an integrated framework for predictive causal inferencedesigned to overcome limitations inherent in conventional single modelapproaches. Specifically, we combine a Hidden Markov Model (HMM) for spatialhealth state estimation with a Multi Task and Multi Graph Convolutional Network(MTGCN) for capturing temporal outcome trajectories. The frameworkasymmetrically treats temporal and spatial information regarding them asendogenous variables in the outcome regression, and exogenous variables in thepropensity score model, thereby expanding the standard doubly robust treatmenteffect estimation to jointly enhance bias correction and predictive accuracy.To demonstrate its utility, we focus on clinical domains such as cancer,dementia, and Parkinson disease, where treatment effects are challenging toobserve directly. Simulation studies are conducted to emulate latent diseasedynamics and evaluate the model performance under varying conditions. Overall,the proposed framework advances predictive causal inference by structurallyadapting to spatiotemporal complexities common in biomedical data.</description>
      <author>example@mail.com (Byunghee Lee, Hye Yeon Sin, Joonsung Kang)</author>
      <guid isPermaLink="false">2507.08896v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Measuring What Matters: A Framework for Evaluating Safety Risks in Real-World LLM Applications</title>
      <link>http://arxiv.org/abs/2507.09820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种评估大型语言模型（LLM）应用层安全性的实用框架，并通过实际部署验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;目前大部分安全测试工作集中在评估基础模型，但应用层安全性的评估需求日益增长，因为系统提示、检索管道和安全防护等因素会影响LLM应用的整体安全性。&lt;h4&gt;目的&lt;/h4&gt;旨在填补AI安全理论概念与实际保护LLM应用操作现实之间的差距，为安全且可扩展的部署提供可操作指导。&lt;h4&gt;方法&lt;/h4&gt;框架包括两部分：一是开发定制化安全风险分类的原则，二是评估LLM应用中安全风险的做法。&lt;h4&gt;主要发现&lt;/h4&gt;框架已在组织内部多个用例的实际部署中得到验证，为寻求扩展安全测试工作的组织提供了参考。&lt;h4&gt;结论&lt;/h4&gt;该框架有助于评估LLM应用层安全性，为LLM的安全和可扩展部署提供指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most safety testing efforts for large language models (LLMs) today focus onevaluating foundation models. However, there is a growing need to evaluatesafety at the application level, as components such as system prompts,retrieval pipelines, and guardrails introduce additional factors thatsignificantly influence the overall safety of LLM applications. In this paper,we introduce a practical framework for evaluating application-level safety inLLM systems, validated through real-world deployment across multiple use caseswithin our organization. The framework consists of two parts: (1) principlesfor developing customized safety risk taxonomies, and (2) practices forevaluating safety risks in LLM applications. We illustrate how the proposedframework was applied in our internal pilot, providing a reference point fororganizations seeking to scale their safety testing efforts. This work aims tobridge the gap between theoretical concepts in AI safety and the operationalrealities of safeguarding LLM applications in practice, offering actionableguidance for safe and scalable deployment.</description>
      <author>example@mail.com (Jia Yi Goh, Shaun Khoo, Nyx Iskandar, Gabriel Chua, Leanne Tan, Jessica Foo)</author>
      <guid isPermaLink="false">2507.09820v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal HD Mapping for Intersections by Intelligent Roadside Units</title>
      <link>http://arxiv.org/abs/2507.08903v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ITSC'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于相机-LiDAR融合框架的HD语义映射方法，用于复杂交叉口的映射，并介绍了RS-seq数据集，用于评估HD地图生成。&lt;h4&gt;背景&lt;/h4&gt;传统基于车辆的HD语义映射方法在复杂交叉口由于遮挡和视角限制存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的相机-LiDAR融合框架，并开发RS-seq数据集，以促进HD地图生成的研究。&lt;h4&gt;方法&lt;/h4&gt;使用升高的智能路边单元（IRU）进行数据收集，提出RS-seq数据集，包括精确标记的相机图像和LiDAR点云，以及带有详细特征的矢量地图。融合框架采用两阶段过程，结合特定模态的特征提取和跨模态语义集成。&lt;h4&gt;主要发现&lt;/h4&gt;使用RS-seq数据集的定量评估表明，多模态方法在语义分割方面优于单模态方法，提高了mIoU指标。&lt;h4&gt;结论&lt;/h4&gt;本研究为基于IRU的HD语义映射建立了基线方法，并为基础设施辅助的自动驾驶系统研究提供了宝贵的数据集。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于遮挡和视角限制，传统基于车辆的复杂交叉口HD语义映射存在重大挑战。本文介绍了一种利用升高智能路边单元（IRU）的相机-LiDAR融合框架。此外，我们提出了RS-seq数据集，通过系统地增强和注释V2X-Seq数据集开发而成。RS-seq包括从路边安装收集的精确标记的相机图像和LiDAR点云，以及带有车道分隔线、人行横道和停车线的七个交叉口的矢量地图。该数据集促进了使用IRU数据生成HD地图的跨模态互补性的系统研究。所提出的融合框架采用两阶段过程，结合特定模态的特征提取和跨模态语义集成，利用相机的高分辨率纹理和LiDAR的精确几何数据。使用RS-seq数据集的定量评估表明，我们的多模态方法在语义分割方面一致优于单模态方法。具体来说，与在RS-seq数据集上评估的单模态基线相比，多模态方法将图像仅结果的mIoU提高了4%，将点云仅结果的mIoU提高了18%。本研究为基于IRU的HD语义映射建立了基线方法，并为基础设施辅助的自动驾驶系统研究提供了宝贵的数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-definition (HD) semantic mapping of complex intersections posessignificant challenges for traditional vehicle-based approaches due toocclusions and limited perspectives. This paper introduces a novel camera-LiDARfusion framework that leverages elevated intelligent roadside units (IRUs).Additionally, we present RS-seq, a comprehensive dataset developed through thesystematic enhancement and annotation of the V2X-Seq dataset. RS-seq includesprecisely labelled camera imagery and LiDAR point clouds collected fromroadside installations, along with vectorized maps for seven intersectionsannotated with detailed features such as lane dividers, pedestrian crossings,and stop lines. This dataset facilitates the systematic investigation ofcross-modal complementarity for HD map generation using IRU data. The proposedfusion framework employs a two-stage process that integrates modality-specificfeature extraction and cross-modal semantic integration, capitalizing on camerahigh-resolution texture and precise geometric data from LiDAR. Quantitativeevaluations using the RS-seq dataset demonstrate that our multimodal approachconsistently surpasses unimodal methods. Specifically, compared to unimodalbaselines evaluated on the RS-seq dataset, the multimodal approach improves themean Intersection-over-Union (mIoU) for semantic segmentation by 4\% over theimage-only results and 18\% over the point cloud-only results. This studyestablishes a baseline methodology for IRU-based HD semantic mapping andprovides a valuable dataset for future research in infrastructure-assistedautonomous driving systems.</description>
      <author>example@mail.com (Zhongzhang Chen, Miao Fan, Shengtong Xu, Mengmeng Yang, Kun Jiang, Xiangzeng Liu, Haoyi Xiong)</author>
      <guid isPermaLink="false">2507.08903v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Photon Searches with the Underground Muon Detector of the Pierre Auger Observatory</title>
      <link>http://arxiv.org/abs/2507.09287v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 39th International Cosmic Ray Conference (ICRC  2025).12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习算法的新型方法，用于在50到300PeV的能量范围内进行光子-强子区分，并讨论了未来数据量增加对探测各种扩散光流的影响。&lt;h4&gt;背景&lt;/h4&gt;超高能光子长期以来被视为宇宙中最激烈过程的示踪器，包括宇宙射线与银河物质和辐射场的相互作用，以及超重暗物质衰变等。&lt;h4&gt;目的&lt;/h4&gt;由于预期通量极低，直接探测不切实际，因此需要通过地面大型探测器阵列进行间接探测。&lt;h4&gt;方法&lt;/h4&gt;该方法依赖于皮埃ール·阿尤尔观测站的表面探测器（SD）和地下缪子探测器（UMD）的信息。SD由水-切伦科夫探测器阵列组成，用于测量地面水平的大气簇射的电磁和缪子成分。UMD由地下闪烁体模块组成，对能量高于约1GeV的大气簇射缪子敏感，从而增强了对由光子初级产生的缪子贫乏大气簇射的识别。方法将大气簇射事件表示为图，因此网络架构由图注意力层组成。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在数据子集上进行了性能评估，并讨论了完全公开当前数据集的影响，以及未来几年预期数据量增加的前景。&lt;h4&gt;结论&lt;/h4&gt;该方法有望提高对各种扩散光流的探测灵敏度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：超高能光子长期以来一直被视为宇宙中最激烈过程的示踪器。包括宇宙射线与银河物质和辐射场的相互作用，以及更奇特的情况，如超重暗物质的衰变。无论它们的起源如何，预期的通量都非常低，使得直接探测不切实际，因此需要通过广泛的地面探测器阵列进行间接探测。在这项贡献中，我们提出了一种基于深度学习算法的新型方法，用于在50到300PeV的能量范围内进行光子-强子区分。我们的方法依赖于皮埃ール·阿尤尔观测站的表面探测器（SD）和地下缪子探测器（UMD）的信息。SD由水-切伦科夫探测器阵列组成，用于测量地面水平的大气簇射的电磁和缪子成分。同时，UMD由地下闪烁体模块组成，对能量高于约1GeV的大气簇射缪子敏感，从而增强了对由光子初级产生的缪子贫乏大气簇射的识别。我们的方法将大气簇射事件表示为图，因此网络架构由图注意力层组成。我们在数据子集上评估了该方法的表现，并讨论了完全公开当前数据集的影响，以及未来几年预期数据量增加的前景，特别是在探测理论预测的各种扩散光流方面的灵敏度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ultra-high-energy photons have long been sought as tracers of the mostenergetic processes in the Universe. Several sources can contribute to adiffuse photon flux, including interactions of cosmic rays with Galactic matterand radiation fields, as well as more exotic scenarios such as the decay ofsuper-heavy dark matter. Regardless of their origin, the expected flux isextremely low, making direct detection impractical and thereby requiringindirect detection by extensive ground-based detector arrays. In thiscontribution, we present a novel method for photon-hadron discrimination in theenergy range of $50$ to $300\,\text{PeV}$ based on deep learning algorithms.Our approach relies on information from both the Surface Detector (SD) and theUnderground Muon Detector (UMD) of the Pierre Auger Observatory. The SDconsists of an array of water-Cherenkov detectors. It is used to measure theelectromagnetic and muonic components of extensive air showers at ground level.Meanwhile, the UMD is composed of buried scintillator modules. It is sensitiveto air-shower muons with energies above ${\sim}1\,\text{GeV}$, enhancing theidentification of muon-poor air showers as initiated by photon primaries. Ourmethod represents air-shower events as graphs, and consequently, the networkarchitecture is composed of graph attention layers. We assess the performanceof the method on a data subset and discuss the implications of unblinding thefull current dataset, as well as the prospects of the increasing data volumeexpected in the coming years, particularly in terms of sensitivity to variousdiffuse fluxes from theoretical predictions.</description>
      <author>example@mail.com (Ezequiel Rodriguez)</author>
      <guid isPermaLink="false">2507.09287v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>CycleGAN-Driven Transfer Learning for Electronics Response Emulation in High-Purity Germanium Detectors</title>
      <link>http://arxiv.org/abs/2507.09106v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于循环位置U-Net（CPU-Net）的神经网络架构，用于模拟高纯锗（HPGe）探测器脉冲形状，以提高对信号事件和背景的区分能力。&lt;h4&gt;背景&lt;/h4&gt;HPGe探测器是进行中微子无双β衰变和暗物质实验等稀有事件搜索的关键技术。脉冲形状与相互作用拓扑相关，对事件分类至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的脉冲形状模拟（PSS）方法，以更准确地模拟能量谱并区分信号事件和背景。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为CPU-Net的神经网络架构，利用CycleGAN框架，通过数据驱动的方式学习模拟脉冲和测量脉冲之间的映射关系，而不需要预定的响应模型。&lt;h4&gt;主要发现&lt;/h4&gt;CPU-Net能够有效地捕捉和再现关键脉冲形状特征，实现更真实的模拟，同时不需要针对特定探测器进行调整。这种方法在脉冲形状参数重建方面的分布级一致性提高了四倍。&lt;h4&gt;结论&lt;/h4&gt;CPU-Net在脉冲形状参数重建方面具有显著优势，为HPGe探测器在稀有事件搜索中的应用提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-Purity Germanium (HPGe) detectors are a key technology for rare-eventsearches such as neutrinoless double-beta decay ($0\nu\beta\beta$) and darkmatter experiments. Pulse shapes from these detectors vary with interactiontopology and thus encode information critical for event classification. Pulseshape simulations (PSS) are essential for modeling analysis cuts thatdistinguish signal events from backgrounds and for generating reliablesimulations of energy spectra. Traditional PSS methods rely on a series offirst-principles corrections to replicate the effect of readout electronics,requiring challenging fits over large parameter spaces and often failing toaccurately model the data. We present a neural network architecture, the CyclicPositional U-Net (CPU-Net), that performs translations of simulated pulses sothat they closely resemble measured detector signals. Using a Cycle GenerativeAdversarial Network (CycleGAN) framework, this Response Emulation Network (REN)learns a data-driven mapping between simulated and measured pulses with highfidelity, without requiring a predetermined response model. We use data from aHigh-Purity Germanium (HPGe) detector with an inverted-coaxial point contact(ICPC) geometry to show that CPU-Net effectively captures and reproducescritical pulse shape features, allowing more realistic simulations withoutdetector-specific tuning. CPU-Net achieves up to a factor-of-four improvementin distribution-level agreement for pulse shape parameter reconstruction, whilepreserving the topology-dependent information required for pulse-shapediscrimination.</description>
      <author>example@mail.com (Kevin Bhimani, Julieta Gruszko, Morgan Clark, John Wilkerson, Aobo Li)</author>
      <guid isPermaLink="false">2507.09106v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>AlphaVAE: Unified End-to-End RGBA Image Reconstruction and Generation with Alpha-Aware Representation Learning</title>
      <link>http://arxiv.org/abs/2507.09308v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了ALPHA，第一个全面的RGBA基准，并提出了ALPHAVAE，一个统一的RGBA VAE模型，用于高效生成高保真RGBA图像。&lt;h4&gt;背景&lt;/h4&gt;虽然隐式扩散模型在合成高保真RGB图像方面取得了显著成果，但对于生成透明或分层内容（RGBA图像）的研究仍较为有限，主要原因是缺乏大规模的基准数据。&lt;h4&gt;目的&lt;/h4&gt;提出ALPHA基准和ALPHAVAE模型，以解决RGBA图像生成的问题，并通过在标准RGB度量上扩展以适应四通道图像，实现RGBA图像的生成。&lt;h4&gt;方法&lt;/h4&gt;ALPHA通过在标准背景上使用alpha混合来调整标准RGB度量，ALPHAVAE则通过引入专用的alpha通道扩展预训练的RGB VAE。该模型使用组合目标进行训练，包括alpha混合像素重建、块级保真度、感知一致性和双KL散度约束。&lt;h4&gt;主要发现&lt;/h4&gt;与使用1M图像的传统方法相比，ALPHAVAE仅使用8K图像进行训练，在重建方面实现了PSNR +4.9 dB的改进和SSIM +3.2%的增加。此外，该模型在潜扩散框架中微调时能够生成高质量的透明图像。&lt;h4&gt;结论&lt;/h4&gt;ALPHA基准和ALPHAVAE模型为RGBA图像的生成提供了新的解决方案，并在性能上优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;近期，隐式扩散模型在利用预训练的VAE以低计算成本压缩和重建像素数据方面取得了显著成果，实现了高保真RGB图像的合成。然而，透明或分层内容（RGBA图像）的生成仍然未得到充分探索，主要因为缺乏大规模的基准。本研究中，我们提出了ALPHA，这是第一个全面的RGBA基准，它通过在标准背景上的alpha混合将标准RGB度量应用于四通道图像。我们进一步引入了ALPHAVAE，这是一个统一的端到端RGBA VAE，通过整合专用的alpha通道扩展了预训练的RGB VAE。该模型使用组合目标进行训练，结合alpha混合像素重建、块级保真度、感知一致性和双重KL散度约束，以确保在RGB和alpha表示之间保持潜在的保真度。与使用1M图像的传统方法相比，我们的RGBA VAE在仅使用8K图像的情况下，实现了PSNR +4.9 dB的改进和SSIM +3.2%的增加，在重建方面优于LayerDiffuse。该模型在潜扩散框架中微调时还能生成高质量的透明图像。我们的代码、数据和模型已发布在https://github.com/o0o0o00o0/AlphaVAE上，以确保可重复性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in latent diffusion models have achieved remarkable resultsin high-fidelity RGB image synthesis by leveraging pretrained VAEs to compressand reconstruct pixel data at low computational cost. However, the generationof transparent or layered content (RGBA image) remains largely unexplored, dueto the lack of large-scale benchmarks. In this work, we propose ALPHA, thefirst comprehensive RGBA benchmark that adapts standard RGB metrics tofour-channel images via alpha blending over canonical backgrounds. We furtherintroduce ALPHAVAE, a unified end-to-end RGBA VAE that extends a pretrained RGBVAE by incorporating a dedicated alpha channel. The model is trained with acomposite objective that combines alpha-blended pixel reconstruction,patch-level fidelity, perceptual consistency, and dual KL divergenceconstraints to ensure latent fidelity across both RGB and alpharepresentations. Our RGBA VAE, trained on only 8K images in contrast to 1M usedby prior methods, achieves a +4.9 dB improvement in PSNR and a +3.2% increasein SSIM over LayerDiffuse in reconstruction. It also enables superiortransparent image generation when fine-tuned within a latent diffusionframework. Our code, data, and models are released onhttps://github.com/o0o0o00o0/AlphaVAE for reproducibility.</description>
      <author>example@mail.com (Zile Wang, Hao Yu, Jiabo Zhan, Chun Yuan)</author>
      <guid isPermaLink="false">2507.09308v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>The Bayesian Approach to Continual Learning: An Overview</title>
      <link>http://arxiv.org/abs/2507.08922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了持续学习这一在线学习范式，它允许学习者在连续的时间步长中从不同的任务中积累知识，同时避免遗忘过去的经验，并无需从头开始重新训练。&lt;h4&gt;背景&lt;/h4&gt;持续学习与人类思维方式相似，具有序列性质，为解决当前限制深度模型应用范围的问题提供了机会。&lt;h4&gt;目的&lt;/h4&gt;本文旨在调查不同设置下的贝叶斯持续学习，包括任务增量学习和类别增量学习，并分析当前最先进的算法。&lt;h4&gt;方法&lt;/h4&gt;本文首先讨论了持续学习的定义及其贝叶斯设置，以及与领域自适应、迁移学习和元学习等相关领域的联系。接着，提出了一个算法分类法，并对一些最突出的贝叶斯持续学习算法进行了分析。此外，还探讨了持续学习与发育心理学之间的联系，并引入了两个领域的类比。&lt;h4&gt;主要发现&lt;/h4&gt;持续学习与贝叶斯推理之间存在内在一致性，贝叶斯推理为模型提供了一种在获取新数据时更新先验信念的平台，同时不遗忘旧数据中获取的知识。&lt;h4&gt;结论&lt;/h4&gt;本文讨论了当前持续学习面临的挑战，并提出了贝叶斯持续学习未来研究的潜在领域。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了持续学习这一在线学习范式，它允许学习者在连续的时间步长中从不同的任务中积累知识，同时避免遗忘过去的经验，并无需从头开始重新训练。持续学习与人类思维方式相似，具有序列性质，为解决当前限制深度模型应用范围的问题提供了机会。本文旨在调查不同设置下的贝叶斯持续学习，包括任务增量学习和类别增量学习，并分析当前最先进的算法。本文首先讨论了持续学习的定义及其贝叶斯设置，以及与领域自适应、迁移学习和元学习等相关领域的联系。接着，提出了一个算法分类法，并对一些最突出的贝叶斯持续学习算法进行了分析。此外，还探讨了持续学习与发育心理学之间的联系，并引入了两个领域的类比。本文讨论了当前持续学习面临的挑战，并提出了贝叶斯持续学习未来研究的潜在领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning is an online paradigm where a learner continuallyaccumulates knowledge from different tasks encountered over sequential timesteps. Importantly, the learner is required to extend and update its knowledgewithout forgetting about the learning experience acquired from the past, andwhile avoiding the need to retrain from scratch. Given its sequential natureand its resemblance to the way humans think, continual learning offers anopportunity to address several challenges which currently stand in the way ofwidening the range of applicability of deep models to further real-worldproblems. The continual need to update the learner with data arrivingsequentially strikes inherent congruence between continual learning andBayesian inference which provides a principal platform to keep updating theprior beliefs of a model given new data, without completely forgetting theknowledge acquired from the old data. This survey inspects different settingsof Bayesian continual learning, namely task-incremental learning andclass-incremental learning. We begin by discussing definitions of continuallearning along with its Bayesian setting, as well as the links with relatedfields, such as domain adaptation, transfer learning and meta-learning.Afterwards, we introduce a taxonomy offering a comprehensive categorization ofalgorithms belonging to the Bayesian continual learning paradigm. Meanwhile, weanalyze the state-of-the-art while zooming in on some of the most prominentBayesian continual learning algorithms to date. Furthermore, we shed some lighton links between continual learning and developmental psychology, andcorrespondingly introduce analogies between both fields. We follow that with adiscussion of current challenges, and finally conclude with potential areas forfuture research on Bayesian continual learning.</description>
      <author>example@mail.com (Tameem Adel)</author>
      <guid isPermaLink="false">2507.08922v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Geo-RepNet: Geometry-Aware Representation Learning for Surgical Phase Recognition in Endoscopic Submucosal Dissection</title>
      <link>http://arxiv.org/abs/2507.09294v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE ICIA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Geo-RepNet的几何感知卷积框架，用于手术阶段识别，旨在提高复杂手术场景下的识别性能。&lt;h4&gt;背景&lt;/h4&gt;手术阶段识别在开发智能辅助系统方面至关重要，特别是在内镜黏膜下剥离等微创手术中。然而，不同阶段的视觉相似性和RGB图像中缺乏结构线索给识别带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;通过使用深度信息，提出Geo-RepNet，以增强在复杂手术场景中的识别性能。&lt;h4&gt;方法&lt;/h4&gt;Geo-RepNet基于可重参数化的RepVGG骨干网络，结合了深度引导的几何先验生成（DGPG）模块和几何增强的多尺度注意力（GEMA）模块，以提高识别性能。&lt;h4&gt;主要发现&lt;/h4&gt;通过构建一个包含密集帧级注释的九阶段ESD数据集，实验表明Geo-RepNet在复杂和低纹理的手术环境中实现了最先进的性能，同时保持了鲁棒性和高计算效率。&lt;h4&gt;结论&lt;/h4&gt;Geo-RepNet是一种有效的手术阶段识别方法，在复杂手术场景中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgical phase recognition plays a critical role in developing intelligentassistance systems for minimally invasive procedures such as EndoscopicSubmucosal Dissection (ESD). However, the high visual similarity acrossdifferent phases and the lack of structural cues in RGB images pose significantchallenges. Depth information offers valuable geometric cues that cancomplement appearance features by providing insights into spatial relationshipsand anatomical structures. In this paper, we pioneer the use of depthinformation for surgical phase recognition and propose Geo-RepNet, ageometry-aware convolutional framework that integrates RGB image and depthinformation to enhance recognition performance in complex surgical scenes.Built upon a re-parameterizable RepVGG backbone, Geo-RepNet incorporates theDepth-Guided Geometric Prior Generation (DGPG) module that extracts geometrypriors from raw depth maps, and the Geometry-Enhanced Multi-scale Attention(GEMA) to inject spatial guidance through geometry-aware cross-attention andefficient multi-scale aggregation. To evaluate the effectiveness of ourapproach, we construct a nine-phase ESD dataset with dense frame-levelannotations from real-world ESD videos. Extensive experiments on the proposeddataset demonstrate that Geo-RepNet achieves state-of-the-art performance whilemaintaining robustness and high computational efficiency under complex andlow-texture surgical environments.</description>
      <author>example@mail.com (Rui Tang, Haochen Yin, Guankun Wang, Long Bai, An Wang, Huxin Gao, Jiazheng Wang, Hongliang Ren)</author>
      <guid isPermaLink="false">2507.09294v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning</title>
      <link>http://arxiv.org/abs/2507.08730v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICSE 2026&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了DHDA，一个在线配置性能学习框架，旨在适应动态环境中不同级别的漂移，包括全局漂移和局部漂移，以提高配置性能学习的准确性。&lt;h4&gt;背景&lt;/h4&gt;现代可配置软件系统需要在动态环境中学习配置与性能之间的模型关联，但工作负载变化、硬件更改和系统更新会导致概念漂移，使现有的离线和迁移学习方法难以适应这些实时变化。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够捕捉和适应不同级别漂移的在线配置性能学习框架。&lt;h4&gt;方法&lt;/h4&gt;DHDA采用双重分层适应策略，对全局漂移通过重新划分数据分区并在必要时重新训练局部模型来处理，对局部漂移通过异步适应局部模型来检测和适应。同时，结合增量更新和周期性全重训练以平衡响应性和效率。&lt;h4&gt;主要发现&lt;/h4&gt;通过评估八个软件系统并与最先进的方法相比，DHDA实现了显著更好的准确性，可以有效地适应漂移，且改进了处理概念漂移的不同局部模型。&lt;h4&gt;结论&lt;/h4&gt;DHDA能够有效地适应动态环境中的漂移，提高配置性能学习的准确性，同时具有合理的开销。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代可配置软件系统需要学习关联配置和性能的模型。然而，当系统在动态环境中运行时，工作负载变化、硬件更改和系统更新不可避免地会在不同级别引入概念漂移 - 全局漂移，它重塑了整个配置空间的功能景观；以及局部漂移，它仅影响该空间的一定子区域。因此，现有的离线和迁移学习方法难以适应这些不可预测的实时变化，使配置性能学习变得具有挑战性。为了解决这个问题，我们提出了DHDA，一个旨在捕捉和适应不同级别漂移的在线配置性能学习框架。其关键思想是DHDA使用双重分层适应策略来适应局部和全局漂移：在高级别，我们重新划分数据为不同的分区，在每个分区中重新训练局部模型，仅在必要时处理全局漂移。在低级别，分区的局部模型可以检测局部漂移并异步地自我适应。为了平衡响应性和效率，DHDA结合了增量更新和周期性全重训练，在未检测到漂移时最小化冗余计算。通过评估八个软件系统与最先进的方法，我们表明DHDA实现了相当好的准确性，并且可以有效地适应漂移，具有高达2倍的性能改进，同时产生合理的开销，并能够改善处理概念漂移的不同局部模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern configurable software systems need to learn models that correlateconfiguration and performance. However, when the system operates in dynamicenvironments, the workload variations, hardware changes, and system updateswill inevitably introduce concept drifts at different levels - global drifts,which reshape the performance landscape of the entire configuration space; andlocal drifts, which only affect certain sub-regions of that space. As such,existing offline and transfer learning approaches can struggle to adapt tothese implicit and unpredictable changes in real-time, rendering configurationperformance learning challenging. To address this, we propose DHDA, an onlineconfiguration performance learning framework designed to capture and adapt tothese drifts at different levels. The key idea is that DHDA adapts to both thelocal and global drifts using dually hierarchical adaptation: at the upperlevel, we redivide the data into different divisions, within each of which thelocal model is retrained, to handle global drifts only when necessary. At thelower level, the local models of the divisions can detect local drifts andadapt themselves asynchronously. To balance responsiveness and efficiency, DHDAcombines incremental updates with periodic full retraining to minimizeredundant computation when no drifts are detected. Through evaluating eightsoftware systems and against state-of-the-art approaches, we show that DHDAachieves considerably better accuracy and can effectively adapt to drifts withup to 2x improvements, while incurring reasonable overhead and is able toimprove different local models in handling concept drift.</description>
      <author>example@mail.com (Zezhen Xiang, Jingzhi Gong, Tao Chen)</author>
      <guid isPermaLink="false">2507.08730v2</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Noise Filtering Algorithm Based on Graph Neural Network for STCF Drift Chamber</title>
      <link>http://arxiv.org/abs/2507.09224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的噪声过滤算法（GNF算法），用于解决高亮度电子-正电子对撞机中带电粒子轨迹重建的挑战。&lt;h4&gt;背景&lt;/h4&gt;中国提出的下一代高亮度电子-正电子对撞机STCF面临高背景水平带来的轨迹重建挑战，尤其是在低横动量区域。&lt;h4&gt;目的&lt;/h4&gt;为了提高轨迹重建效率和降低假信号率，提出了一种基于GNN的噪声过滤算法作为预处理步骤。&lt;h4&gt;方法&lt;/h4&gt;GNF算法将探测器数据转换为图，并采用分层阈值策略将GNN的边缘分类结果映射到信号-噪声分离。&lt;h4&gt;主要发现&lt;/h4&gt;基于蒙特卡洛（MC）数据的研究表明，实施GNF算法后，在标准背景下的重建效率与无背景情况相当，而假信号率显著降低。&lt;h4&gt;结论&lt;/h4&gt;GNF算法为STCF跟踪软件提供了重要的支持。&lt;h4&gt;翻译&lt;/h4&gt;The super τ-charm facility (STCF) is a next-generation electron-positron collider with high luminosity proposed in China. The higher luminosity leads to increased background level, posing significant challenges for track reconstruction of charged particles. Particularly in the low transverse momentum region, the current track reconstruction algorithm is notably affected by background, resulting in suboptimal reconstruction efficiency and a high fake rate. To address this challenge, we propose a Graph Neural Network (GNN)-based noise filtering algorithm (GNF Algorithm) as a preprocessing step for the track reconstruction. The GNF Algorithm introduces a novel method to convert detector data into graphs and applies a tiered threshold strategy to map GNN-based edge classification results onto signal-noise separation. The study based on Monte Carlo (MC) data shows that with the implementation of the GNF Algorithm, the reconstruction efficiency with the standard background is comparable to the case without background, while the fake rate is significantly reduced. Thus, GNF Algorithm provides essential support for the STCF tracking software.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The super $\tau$-charm facility (STCF) is a next-generation electron-positroncollider with high luminosity proposed in China. The higher luminosity leads toincreased background level, posing significant challenges for trackreconstruction of charged particles. Particularly in the low transversemomentum region, the current track reconstruction algorithm is notably affectedby background, resulting in suboptimal reconstruction efficiency and a highfake rate. To address this challenge, we propose a Graph Neural Network(GNN)-based noise filtering algorithm (GNF Algorithm) as a preprocessing stepfor the track reconstruction. The GNF Algorithm introduces a novel method toconvert detector data into graphs and applies a tiered threshold strategy tomap GNN-based edge classification results onto signal-noise separation. Thestudy based on Monte Carlo (MC) data shows that with the implementation of theGNF Algorithm, the reconstruction efficiency with the standard background iscomparable to the case without background, while the fake rate is significantlyreduced. Thus, GNF Algorithm provides essential support for the STCF trackingsoftware.</description>
      <author>example@mail.com (Xiaoqian Jia, Xiaoshuai Qin, Teng Li, Xueyao Zhang, Xiaoqian Hu, Shuangbing Song, Hang Zhou, Xiaocong Ai, Jin Zhang, Xingtao Huang)</author>
      <guid isPermaLink="false">2507.09224v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Learning Diffusion Models with Flexible Representation Guidance</title>
      <link>http://arxiv.org/abs/2507.08980v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将表示指导融入扩散模型的系统框架，通过改进内部表示来提高生成质量。&lt;h4&gt;背景&lt;/h4&gt;先前研究表明，将扩散模型的内部表示与预训练模型的表示对齐可以提升生成质量。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，将表示指导融入扩散模型，以增强表示对齐并提高生成性能。&lt;h4&gt;方法&lt;/h4&gt;提出两种策略：一是通过多模态对学习联合模型；二是设计平衡表示学习和数据生成的最优训练课程。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在图像、蛋白质序列和分子生成任务中表现出优异的性能，训练速度比原始SiT-XL快23.3倍，比最先进的REPA方法快4倍。&lt;h4&gt;结论&lt;/h4&gt;该研究为扩散模型提供了有效的表示指导，显著提高了生成质量和训练效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：扩散模型可以通过对输入的有效表示进行额外指导来得到改进。确实，先前经验研究表明，将扩散模型的内部表示与预训练模型的表示对齐可以提高生成质量。在本文中，我们提出了一种将表示指导融入扩散模型的系统框架。我们提供了去噪模型的替代分解及其相关的训练标准，其中分解决定了何时以及如何将辅助表示融入其中。在我们的理论洞察的指导下，我们引入了两种增强扩散模型中表示对齐的新策略。首先，我们将示例与其目标表示配对，这些表示要么来源于自身，要么来自不同的合成模态，然后学习多模态对的联合模型。其次，我们设计了一个最优的训练课程，平衡表示学习和数据生成。我们在图像、蛋白质序列和分子生成任务上的实验表明，该方法具有优越的性能以及加速的训练。特别是，在256x256的class-conditional ImageNet基准上，我们的指导使得训练速度比原始SiT-XL快23.3倍，比最先进的REPA方法快4倍。代码可在https://github.com/ChenyuWang-Monica/REED上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models can be improved with additional guidance towards moreeffective representations of input. Indeed, prior empirical work has alreadyshown that aligning internal representations of the diffusion model with thoseof pre-trained models improves generation quality. In this paper, we present asystematic framework for incorporating representation guidance into diffusionmodels. We provide alternative decompositions of denoising models along withtheir associated training criteria, where the decompositions determine when andhow the auxiliary representations are incorporated. Guided by our theoreticalinsights, we introduce two new strategies for enhancing representationalignment in diffusion models. First, we pair examples with targetrepresentations either derived from themselves or arisen from differentsynthetic modalities, and subsequently learn a joint model over the multimodalpairs. Second, we design an optimal training curriculum that balancesrepresentation learning and data generation. Our experiments across image,protein sequence, and molecule generation tasks demonstrate superiorperformance as well as accelerated training. In particular, on theclass-conditional ImageNet $256\times 256$ benchmark, our guidance results in$23.3$ times faster training than the original SiT-XL as well as four timesspeedup over the state-of-the-art method REPA. The code is available athttps://github.com/ChenyuWang-Monica/REED.</description>
      <author>example@mail.com (Chenyu Wang, Cai Zhou, Sharut Gupta, Zongyu Lin, Stefanie Jegelka, Stephen Bates, Tommi Jaakkola)</author>
      <guid isPermaLink="false">2507.08980v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Towards Interpretable Drug-Drug Interaction Prediction: A Graph-Based Approach with Molecular and Network-Level Explanations</title>
      <link>http://arxiv.org/abs/2507.09173v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MolecBioNet是一个基于图的新型框架，用于预测药物相互作用（DDI），它通过整合分子和生物医学知识，提供对DDI的全面视角。&lt;h4&gt;背景&lt;/h4&gt;药物相互作用是药理学中的关键挑战，可能导致不良药物反应，对病人安全和医疗结果有重大影响。现有的基于图的方法虽然预测性能强，但大多数方法独立处理药物对，忽略了药物对特有的复杂、情境依赖的相互作用，并且难以整合生物相互作用网络和分子级结构以提供有意义的机制见解。&lt;h4&gt;目的&lt;/h4&gt;提出MolecBioNet，以实现稳健且可解释的DDI预测。&lt;h4&gt;方法&lt;/h4&gt;MolecBioNet将药物对建模为统一实体，通过提取生物医学知识图中的局部子图和构建分子表示的层次交互图来捕捉宏观层面的生物相互作用和微观层面的分子影响。此外，它引入了两种领域特定的池化策略：情境感知子图池化（CASPool）和注意力引导影响池化（AGIPool），并采用互信息最小化正则化来增强嵌入融合过程中的信息多样性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MolecBioNet在DDI预测方面优于现有方法，消融研究和嵌入可视化进一步验证了统一药物对建模和多尺度知识整合的优势。&lt;h4&gt;结论&lt;/h4&gt;MolecBioNet为DDI预测提供了一种有效的方法，通过整合分子和生物医学知识，提高了预测的准确性和可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737163&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug-drug interactions (DDIs) represent a critical challenge in pharmacology,often leading to adverse drug reactions with significant implications forpatient safety and healthcare outcomes. While graph-based methods have achievedstrong predictive performance, most approaches treat drug pairs independently,overlooking the complex, context-dependent interactions unique to drug pairs.Additionally, these models struggle to integrate biological interactionnetworks and molecular-level structures to provide meaningful mechanisticinsights. In this study, we propose MolecBioNet, a novel graph-based frameworkthat integrates molecular and biomedical knowledge for robust and interpretableDDI prediction. By modeling drug pairs as unified entities, MolecBioNetcaptures both macro-level biological interactions and micro-level molecularinfluences, offering a comprehensive perspective on DDIs. The frameworkextracts local subgraphs from biomedical knowledge graphs and constructshierarchical interaction graphs from molecular representations, leveragingclassical graph neural network methods to learn multi-scale representations ofdrug pairs. To enhance accuracy and interpretability, MolecBioNet introducestwo domain-specific pooling strategies: context-aware subgraph pooling(CASPool), which emphasizes biologically relevant entities, andattention-guided influence pooling (AGIPool), which prioritizes influentialmolecular substructures. The framework further employs mutual informationminimization regularization to enhance information diversity during embeddingfusion. Experimental results demonstrate that MolecBioNet outperformsstate-of-the-art methods in DDI prediction, while ablation studies andembedding visualizations further validate the advantages of unified drug pairmodeling and multi-scale knowledge integration.</description>
      <author>example@mail.com (Mengjie Chen, Ming Zhang, Cunquan Qu)</author>
      <guid isPermaLink="false">2507.09173v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Graph Prompt Learning via Adaptive Weight Pruning</title>
      <link>http://arxiv.org/abs/2507.09132v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合图提示和权重剪枝的新框架GPAWP，旨在通过使用更少的图提示来提高图提示的性能和效率。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络（GNNs）在图相关任务中取得了显著成功，但它们仍面临训练和推理时间长、难以捕捉复杂关系以及特征提取不足等挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文旨在通过优化模型和评估图提示的重要性来提高GNN的性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法结合了图提示和权重剪枝，通过重要性评估函数确定不同粒度下的正负权重，并通过分层剪枝消除负提示标签，从而实现更参数高效和具有竞争力的提示。&lt;h4&gt;主要发现&lt;/h4&gt;在三个基准数据集上的大量实验表明，GPAWP在节点分类任务中具有优越性，显著减少了参数数量。&lt;h4&gt;结论&lt;/h4&gt;GPAWP框架通过优化图提示的使用，提高了GNN的性能和效率，为图神经网络的发展提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have achieved remarkable success in various graph-based tasks (e.g., node classification or link prediction). Despite their triumphs, GNNs still face challenges such as long training and inference times, difficulty in capturing complex relationships, and insufficient feature extraction. To tackle these issues, graph pre-training and graph prompt methods have garnered increasing attention for their ability to leverage large-scale datasets for initial learning and task-specific adaptation, offering potential improvements in GNN performance. However, previous research has overlooked the potential of graph prompts in optimizing models, as well as the impact of both positive and negative graph prompts on model stability and efficiency. To bridge this gap, we propose a novel framework combining graph prompts with weight pruning, called GPAWP, which aims to enhance the performance and efficiency of graph prompts by using fewer of them. We evaluate the importance of graph prompts using an importance assessment function to determine positive and negative weights at different granularities. Through hierarchically structured pruning, we eliminate negative prompt labels, resulting in more parameter-efficient and competitively performing prompts. Extensive experiments on three benchmark datasets demonstrate the superiority of GPAWP, leading to a significant reduction in parameters in node classification tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved remarkable success in variousgraph-based tasks (e.g., node classification or link prediction). Despite theirtriumphs, GNNs still face challenges such as long training and inference times,difficulty in capturing complex relationships, and insufficient featureextraction. To tackle these issues, graph pre-training and graph prompt methodshave garnered increasing attention for their ability to leverage large-scaledatasets for initial learning and task-specific adaptation, offering potentialimprovements in GNN performance. However, previous research has overlooked thepotential of graph prompts in optimizing models, as well as the impact of bothpositive and negative graph prompts on model stability and efficiency. Tobridge this gap, we propose a novel framework combining graph prompts withweight pruning, called GPAWP, which aims to enhance the performance andefficiency of graph prompts by using fewer of them. We evaluate the importanceof graph prompts using an importance assessment function to determine positiveand negative weights at different granularities. Through hierarchicallystructured pruning, we eliminate negative prompt labels, resulting in moreparameter-efficient and competitively performing prompts. Extensive experimentson three benchmark datasets demonstrate the superiority of GPAWP, leading to asignificant reduction in parameters in node classification tasks.</description>
      <author>example@mail.com (Chu-Yuan Wei, Shun-Yao Liu, Sheng-Da Zhuo, Chang-Dong Wang, Shu-Qiang Huang, Mohsen Guizani)</author>
      <guid isPermaLink="false">2507.09132v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Prompt2DEM: High-Resolution DEMs for Urban and Open Environments from Global Prompts Using a Monocular Foundation Model</title>
      <link>http://arxiv.org/abs/2507.09681v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的新框架，用于高分辨率数字高程模型（DEM）的估计，实现了绝对全球高程映射的新范式。&lt;h4&gt;背景&lt;/h4&gt;高分辨率高程数据对于理解流域和坡面水文学、研究城市形态和动态、以及监测陆地生态系统的生长、衰退和死亡率至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来创建高分辨率DEM，以实现绝对全球高程的精确映射。&lt;h4&gt;方法&lt;/h4&gt;该框架使用低分辨率的SRTM高程数据作为提示，结合高分辨率的NAIP RGB影像，通过微调一个视觉Transformer编码器，并采用灵活的提示策略来实现DEM估计、空洞填充和更新等功能。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了100倍的分辨率提升（从30米到30厘米），相对于现有方法有数量级的提升。在美国三个不同的景观上的评估显示，该方法具有鲁棒性，相对于激光雷达数据，在小于5米的平均绝对误差（MAE）下捕捉到城市结构和精细的地形特征，相较于SRTM改进了高达18%。水文分析证实了其在灾害和环境研究中的适用性。&lt;h4&gt;结论&lt;/h4&gt;该方法可扩展到美国和以色列的大型区域，所有代码和预训练模型均公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-resolution elevation estimations are essential to understand catchmentand hillslope hydrology, study urban morphology and dynamics, and monitor thegrowth, decline, and mortality of terrestrial ecosystems. Various deep learningapproaches (e.g., super-resolution techniques, monocular depth estimation) havebeen developed to create high-resolution Digital Elevation Models (DEMs).However, super-resolution techniques are limited by the upscaling factor, andmonocular depth estimation lacks global elevation context, making itsconversion to a seamless DEM restricted. The recently introduced technique ofprompt-based monocular depth estimation has opened new opportunities to extractestimates of absolute elevation in a global context. We present here aframework for the estimation of high-resolution DEMs as a new paradigm forabsolute global elevation mapping. It is exemplified using low-resolutionShuttle Radar Topography Mission (SRTM) elevation data as prompts andhigh-resolution RGB imagery from the National Agriculture Imagery Program(NAIP). The approach fine-tunes a vision transformer encoder with LiDAR-derivedDEMs and employs a versatile prompting strategy, enabling tasks such as DEMestimation, void filling, and updating. Our framework achieves a 100xresolution gain (from 30-m to 30-cm), surpassing prior methods by an order ofmagnitude. Evaluations across three diverse U.S. landscapes show robustgeneralization, capturing urban structures and fine-scale terrain features with&lt; 5 m MAE relative to LiDAR, improving over SRTM by up to 18%. Hydrologicalanalysis confirms suitability for hazard and environmental studies. Wedemonstrate scalability by applying the framework to large regions in the U.S.and Israel. All code and pretrained models are publicly available at:https://osherr1996.github.io/prompt2dem_propage/.</description>
      <author>example@mail.com (Osher Rafaeli, Tal Svoray, Ariel Nahlieli)</author>
      <guid isPermaLink="false">2507.09681v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network Enhanced Sequential Recommendation Method for Cross-Platform Ad Campaign</title>
      <link>http://arxiv.org/abs/2507.08959v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图神经网络（GNN）的广告推荐方法，以提高跨平台广告推荐的准确性。&lt;h4&gt;背景&lt;/h4&gt;通过多维建模，分析了用户行为数据、广告内容和平台特征对用户兴趣演变和兴趣迁移路径的影响。&lt;h4&gt;目的&lt;/h4&gt;目的是提高跨平台广告推荐的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络（GNN）方法，通过多维度建模，捕捉用户兴趣在不同平台之间的迁移路径。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在三个平台的数据集上均取得了较好的效果，其中平台B的AUC值达到0.937，表现最佳。平台A和平台C的精确度和召回率略有下降，且广告标签分布不均。通过调整学习率、批量大小和嵌入维度等超参数，提高了模型在异构数据上的适应性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提高跨平台广告推荐的准确性，并在不同平台上取得了较好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In order to improve the accuracy of cross-platform advertisementrecommendation, a graph neural network (GNN)- based advertisementrecommendation method is analyzed. Through multi-dimensional modeling, userbehavior data (e.g., click frequency, active duration) reveal temporal patternsof interest evolution, ad content (e.g., type, tag, duration) influencessemantic preferences, and platform features (e.g., device type, usage context)shape the environment where interest transitions occur. These factors jointlyenable the GNN to capture the latent pathways of user interest migration acrossplatforms. The experimental results are based on the datasets of threeplatforms, and Platform B reaches 0.937 in AUC value, which is the bestperformance. Platform A and Platform C showed a slight decrease in precisionand recall with uneven distribution of ad labels. By adjusting thehyperparameters such as learning rate, batch size and embedding dimension, theadaptability and robustness of the model in heterogeneous data are furtherimproved.</description>
      <author>example@mail.com (Xiang Li, Xinyu Wang, Yifan Lin)</author>
      <guid isPermaLink="false">2507.08959v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Prompt Engineering in Segment Anything Model: Methodologies, Applications, and Emerging Challenges</title>
      <link>http://arxiv.org/abs/2507.09562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SAM通过创新的基于提示的方法革新了图像分割，但提示工程在其中的关键作用尚未得到充分探索。&lt;h4&gt;背景&lt;/h4&gt;SAM模型及其变体在图像分割领域取得了突破，但提示工程的重要性未被深入研究。&lt;h4&gt;目的&lt;/h4&gt;本文提供了对SAM及其变体中提示工程技术的全面调查，系统组织和分析了该新兴领域的快速增长的文献。&lt;h4&gt;方法&lt;/h4&gt;本文系统地组织和分析了基础方法、实际应用和关键挑战，并揭示了提示工程从简单的几何输入到复杂的多模态方法的演变。&lt;h4&gt;主要发现&lt;/h4&gt;提示工程在医学成像和遥感等不同领域实现了SAM的适应性，并识别了提示优化中的独特挑战。&lt;h4&gt;结论&lt;/h4&gt;本文通过提供一个理解和发展基础模型中提示工程的结构化框架，填补了文献中的一个重要空白。&lt;h4&gt;翻译&lt;/h4&gt;The Segment Anything Model (SAM) has revolutionized image segmentation through its innovative prompt-based approach, yet the critical role of prompt engineering in its success remains underexplored. This paper presents the first comprehensive survey focusing specifically on prompt engineering techniques for SAM and its variants. We systematically organize and analyze the rapidly growing body of work in this emerging field, covering fundamental methodologies, practical applications, and key challenges. Our review reveals how prompt engineering has evolved from simple geometric inputs to sophisticated multimodal approaches, enabling SAM's adaptation across diverse domains including medical imaging and remote sensing. We identify unique challenges in prompt optimization and discuss promising research directions. This survey fills an important gap in the literature by providing a structured framework for understanding and advancing prompt engineering in foundation models for segmentation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Segment Anything Model (SAM) has revolutionized image segmentationthrough its innovative prompt-based approach, yet the critical role of promptengineering in its success remains underexplored. This paper presents the firstcomprehensive survey focusing specifically on prompt engineering techniques forSAM and its variants. We systematically organize and analyze the rapidlygrowing body of work in this emerging field, covering fundamentalmethodologies, practical applications, and key challenges. Our review revealshow prompt engineering has evolved from simple geometric inputs tosophisticated multimodal approaches, enabling SAM's adaptation across diversedomains including medical imaging and remote sensing. We identify uniquechallenges in prompt optimization and discuss promising research directions.This survey fills an important gap in the literature by providing a structuredframework for understanding and advancing prompt engineering in foundationmodels for segmentation.</description>
      <author>example@mail.com (Yidong Jiang)</author>
      <guid isPermaLink="false">2507.09562v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>QuarterMap: Efficient Post-Training Token Pruning for Visual State Space Models</title>
      <link>http://arxiv.org/abs/2507.09514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Efficient Systems for Foundation Models Workshop at the  International Conference on Machine Learning (ICML) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了QuarterMap，一种基于VMamba的视觉骨干网络的激活剪枝方法，旨在减少空间冗余以提高效率。&lt;h4&gt;背景&lt;/h4&gt;状态空间模型（SSMs）通过线性递归减少了变压器的二次复杂性。VMamba是一种强大的基于SSM的视觉骨干网络，但其四方向扫描存在空间冗余。&lt;h4&gt;目的&lt;/h4&gt;设计一种方法，去除VMamba扫描前冗余的空间激活，并通过最近邻上采样恢复维度，以提高吞吐量。&lt;h4&gt;方法&lt;/h4&gt;QuarterMap通过激活剪枝在扫描前去除冗余的激活，然后使用最近邻上采样来恢复维度。&lt;h4&gt;主要发现&lt;/h4&gt;QuarterMap在ImageNet-1K上对VMamba实现了高达11%的速度提升，且精度下降小于0.9%。在ADE20K分割任务上也取得了相似的收益。该方法在多个医疗成像任务中也证明了有效性。&lt;h4&gt;结论&lt;/h4&gt;QuarterMap为SSMs提供了一个即插即用的工具，以提高部署时的效率而不牺牲迁移性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：状态空间模型（SSMs）通过利用线性递归减少了变压器的二次复杂性。VMamba作为基于SSM的强大视觉骨干网络，仍然受其四方向扫描的空间冗余所限制。我们提出QuarterMap，一种在扫描前去除冗余空间激活的激活剪枝方法，并通过最近邻上采样恢复维度。我们的方法在不重新训练的情况下提高了吞吐量。在ImageNet-1K上，QuarterMap在VMamba上实现了高达11%的速度提升，精度下降不到0.9%，在ADE20K分割上也取得了相似的收益。除VMamba外，我们在具有相同四方向扫描结构的领域特定模型MedMamba上验证了QuarterMap，它在不同医疗成像任务中持续提高了吞吐量，同时保持了精度。与ToMe等标记合并方法相比，QuarterMap针对SSMs进行了优化，避免了昂贵的合并-取消合并操作。我们的方法提供了一个在部署时提高效率的插件工具，而不牺牲迁移性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State space models (SSMs) reduce the quadratic complexity of transformers byleveraging linear recurrence. Recently, VMamba has emerged as a strongSSM-based vision backbone, yet remains bottlenecked by spatial redundancy inits four-directional scan. We propose QuarterMap, a post-training activationpruning method that removes redundant spatial activations before scanning andrestores dimensions via nearest-neighbor upsampling. Our method improvesthroughput without retraining. On ImageNet-1K, QuarterMap achieves up to 11%speedup on VMamba with less than 0.9% accuracy drop, and yields similar gainson ADE20K segmentation. Beyond VMamba, we validate QuarterMap on MedMamba, adomain-specific model that shares the same four-directional scanning structure,where it consistently improves throughput while preserving accuracy acrossmultiple medical imaging tasks. Compared to token merging methods like ToMe,QuarterMap is tailored for SSMs and avoids costly merge-unmerge operations. Ourmethod offers a plug-and-play tool for deployment-time efficiency withoutcompromising transferability.</description>
      <author>example@mail.com (Tien-Yu Chi, Hung-Yueh Chiang, Diana Marculescu, Kai-Chiang Wu)</author>
      <guid isPermaLink="false">2507.09514v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Transformers Don't In-Context Learn Least Squares Regression</title>
      <link>http://arxiv.org/abs/2507.09440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 16 figures, ICML 2025 Workshop on Reliable and Responsible  Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在上下文学习（ICL）中的Transformer机制，分析了其实现学习和泛化的方式。&lt;h4&gt;背景&lt;/h4&gt;尽管上下文学习（ICL）在大规模预训练Transformer中表现出了强大的能力，但ICL背后的机制仍然不明。&lt;h4&gt;目的&lt;/h4&gt;探究Transformer如何在推理时实现学习，以及它们如何通过学习实现如普通最小二乘法（OLS）回归或梯度下降等学习规则。&lt;h4&gt;方法&lt;/h4&gt;通过一系列的分布外泛化实验，研究了Transformer在ICL训练后对提示分布变化的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，用于ICL训练的Transformer在提示分布发生变化后无法泛化，这与Transformer实现如OLS算法的观念不符。此外，通过学习表示的频谱分析，强调了预训练语料库在塑造ICL行为中的作用。&lt;h4&gt;结论&lt;/h4&gt;输入与训练数据同分布时，会产生具有独特频谱特征的表现；而分布外输入则不具备这一特征，且这种特征的存在与低损失高度相关。&lt;h4&gt;翻译&lt;/h4&gt;In-context learning (ICL) has emerged as a powerful capability of large pretrained transformers, enabling them to solve new tasks implicit in example input-output pairs without any gradient updates. Despite its practical success, the mechanisms underlying ICL remain largely mysterious. In this work we study synthetic linear regression to probe how transformers implement learning at inference time. Previous works have demonstrated that transformers match the performance of learning rules such as Ordinary Least Squares (OLS) regression or gradient descent and have suggested ICL is facilitated in transformers through the learned implementation of one of these techniques. In this work, we demonstrate through a suite of out-of-distribution generalization experiments that transformers trained for ICL fail to generalize after shifts in the prompt distribution, a behaviour that is inconsistent with the notion of transformers implementing algorithms such as OLS. Finally, we highlight the role of the pretraining corpus in shaping ICL behaviour through a spectral analysis of the learned representations in the residual stream. Inputs from the same distribution as the training data produce representations with a unique spectral signature: inputs from this distribution tend to have the same top two singular vectors. This spectral signature is not shared by out-of-distribution inputs, and a metric characterizing the presence of this signature is highly correlated with low loss.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-context learning (ICL) has emerged as a powerful capability of largepretrained transformers, enabling them to solve new tasks implicit in exampleinput-output pairs without any gradient updates. Despite its practical success,the mechanisms underlying ICL remain largely mysterious. In this work we studysynthetic linear regression to probe how transformers implement learning atinference time. Previous works have demonstrated that transformers match theperformance of learning rules such as Ordinary Least Squares (OLS) regressionor gradient descent and have suggested ICL is facilitated in transformersthrough the learned implementation of one of these techniques. In this work, wedemonstrate through a suite of out-of-distribution generalization experimentsthat transformers trained for ICL fail to generalize after shifts in the promptdistribution, a behaviour that is inconsistent with the notion of transformersimplementing algorithms such as OLS. Finally, we highlight the role of thepretraining corpus in shaping ICL behaviour through a spectral analysis of thelearned representations in the residual stream. Inputs from the samedistribution as the training data produce representations with a uniquespectral signature: inputs from this distribution tend to have the same top twosingular vectors. This spectral signature is not shared by out-of-distributioninputs, and a metric characterizing the presence of this signature is highlycorrelated with low loss.</description>
      <author>example@mail.com (Joshua Hill, Benjamin Eyre, Elliot Creager)</author>
      <guid isPermaLink="false">2507.09440v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Laws for Optimal Data Mixtures</title>
      <link>http://arxiv.org/abs/2507.09404v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于缩放定律的系统方法，用于确定任何目标域的最佳数据混合比例，以提高模型性能。&lt;h4&gt;背景&lt;/h4&gt;大型基础模型通常在来自多个领域的数据上进行训练，数据混合比例对模型性能至关重要。&lt;h4&gt;目的&lt;/h4&gt;旨在为大规模预训练提供一个系统的方法来选择最佳数据混合比例，避免试错的方法。&lt;h4&gt;方法&lt;/h4&gt;使用缩放定律预测模型损失，并通过三种不同的大规模设置（大型语言模型、原生多模态模型和大型视觉模型预训练）验证缩放定律的普适性。&lt;h4&gt;主要发现&lt;/h4&gt;缩放定律能够预测不同规模和领域权重下的模型性能，且可以在小规模训练运行中准确估计参数，用于估算更大规模和未知领域权重的性能。&lt;h4&gt;结论&lt;/h4&gt;缩放定律提供了一种基于原则的方法，可以确定在给定训练预算下任何目标域的最佳领域权重，作为昂贵试错方法的替代。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型基础模型通常在多个领域的数据上进行训练，数据混合——每个领域使用的比例——在模型性能中起着关键作用。选择这种混合的标准方法依赖于试错，这对于大规模预训练来说变得不切实际。我们提出了一种系统方法，使用缩放定律来确定任何目标域的最佳数据混合比例。我们的方法可以准确预测使用特定领域权重向量h训练的具有N个标记的模型的大小N的损失。我们通过在三个不同的大规模设置中展示其预测能力来验证这些缩放定律的普适性：大型语言模型（LLM）、原生多模态模型（NMM）和大型视觉模型（LVM）预训练。我们进一步表明，这些缩放定律可以外推到新的数据混合比例和不同规模：它们的参数可以使用少量小规模训练运行来准确估计，并用于估计更大规模和未知领域权重的性能。这些缩放定律允许在给定的训练预算（N，D）下推导出任何目标域的最佳领域权重，为昂贵的试错方法提供了一种原则上的替代。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large foundation models are typically trained on data from multiple domains,with the data mixture--the proportion of each domain used--playing a criticalrole in model performance. The standard approach to selecting this mixturerelies on trial and error, which becomes impractical for large-scalepretraining. We propose a systematic method to determine the optimal datamixture for any target domain using scaling laws. Our approach accuratelypredicts the loss of a model of size $N$ trained with $D$ tokens and a specificdomain weight vector $h$. We validate the universality of these scaling laws bydemonstrating their predictive power in three distinct and large-scalesettings: large language model (LLM), native multimodal model (NMM), and largevision models (LVM) pretraining. We further show that these scaling laws canextrapolate to new data mixtures and across scales: their parameters can beaccurately estimated using a few small-scale training runs, and used toestimate the performance at larger scales and unseen domain weights. Thescaling laws allow to derive the optimal domain weights for any target domainunder a given training budget ($N$,$D$), providing a principled alternative tocostly trial-and-error methods.</description>
      <author>example@mail.com (Mustafa Shukor, Louis Bethune, Dan Busbridge, David Grangier, Enrico Fini, Alaaeldin El-Nouby, Pierre Ablin)</author>
      <guid isPermaLink="false">2507.09404v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Simplifying Traffic Anomaly Detection with Video Foundation Models</title>
      <link>http://arxiv.org/abs/2507.09338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCVW 2025 accepted. Code: https://github.com/tue-mps/simple-tad&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用简单编码器架构的ego-centric Traffic Anomaly Detection (TAD)，并探讨了预训练对TAD性能的影响。&lt;h4&gt;背景&lt;/h4&gt;目前TAD方法通常依赖于复杂的融合架构，但这种方法是否必要尚不明确。&lt;h4&gt;目的&lt;/h4&gt;研究预训练如何使简单架构的TAD模型达到或超过专业设计的性能，并提高效率。&lt;h4&gt;方法&lt;/h4&gt;采用Video Vision Transformers (Video ViTs)进行编码器-only的简单架构，并研究预训练对TAD性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;1. 强预训练使简单编码器模型能够匹配甚至超越专业TAD方法，同时效率更高；2. 弱监督和全监督预训练在标准基准上具有优势，但对于TAD效果不佳；3. 自监督Masked Video Modeling (MVM)提供了最强的信号；4. 域自适应预训练(DAPT)在不要求异常示例的情况下进一步提高了下游性能。&lt;h4&gt;结论&lt;/h4&gt;预训练对于TAD模型的重要性得到了强调，并表明可以通过最小的架构复杂性构建有效、高效且可扩展的TAD模型。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we investigate the use of a simple encoder-only architecture for ego-centric Traffic Anomaly Detection (TAD) and explore the impact of pre-training on TAD performance. The background is that current TAD methods often rely on complex fusion architectures, but it remains unclear whether such complexity is necessary. The aim is to study how pre-training enables simple architecture TAD models to reach or even exceed the performance of specialized designs while improving efficiency. The method involves using Video Vision Transformers (Video ViTs) for an encoder-only simple architecture and studying the impact of pre-training on TAD performance. The main findings are: 1. Strong pre-training enables simple encoder models to match or even exceed the performance of specialized TAD methods while being significantly more efficient; 2. Although weakly- and fully-supervised pre-training are advantageous on standard benchmarks, they are found to be less effective for TAD; 3. Self-supervised Masked Video Modeling (MVM) provides the strongest signal; 4. Domain-Adaptive Pre-Training (DAPT) on unlabeled driving videos further improves downstream performance without requiring anomalous examples. The conclusion emphasizes the importance of pre-training and shows that effective, efficient, and scalable TAD models can be built with minimal architectural complexity.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent methods for ego-centric Traffic Anomaly Detection (TAD) often rely oncomplex multi-stage or multi-representation fusion architectures, yet itremains unclear whether such complexity is necessary. Recent findings in visualperception suggest that foundation models, enabled by advanced pre-training,allow simple yet flexible architectures to outperform specialized designs.Therefore, in this work, we investigate an architecturally simple encoder-onlyapproach using plain Video Vision Transformers (Video ViTs) and study howpre-training enables strong TAD performance. We find that: (i) strongpre-training enables simple encoder-only models to match or even surpass theperformance of specialized state-of-the-art TAD methods, while also beingsignificantly more efficient; (ii) although weakly- and fully-supervisedpre-training are advantageous on standard benchmarks, we find them lesseffective for TAD. Instead, self-supervised Masked Video Modeling (MVM)provides the strongest signal; and (iii) Domain-Adaptive Pre-Training (DAPT) onunlabeled driving videos further improves downstream performance, withoutrequiring anomalous examples. Our findings highlight the importance ofpre-training and show that effective, efficient, and scalable TAD models can bebuilt with minimal architectural complexity. We release our code,domain-adapted encoders, and fine-tuned models to support future work:https://github.com/tue-mps/simple-tad.</description>
      <author>example@mail.com (Svetlana Orlova, Tommie Kerssies, Brunó B. Englert, Gijs Dubbelman)</author>
      <guid isPermaLink="false">2507.09338v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Appearance: Geometric Cues for Robust Video Instance Segmentation</title>
      <link>http://arxiv.org/abs/2507.05948v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025 Workshop LSVOS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用单目深度估计增强视频实例分割（VIS）鲁棒性的方法，通过几何感知来克服遮挡、运动模糊和外观变化等挑战。&lt;h4&gt;背景&lt;/h4&gt;视频实例分割在处理遮挡、运动模糊和外观变化等普遍挑战时存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些限制，提高VIS的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;本文系统地研究了三种不同的集成范式：扩展深度通道（EDC）方法将深度图作为输入通道添加到分割网络中；共享ViT（SV）设计了一个统一的ViT骨干网络，该网络在深度估计和分割分支之间共享；深度监督（DS）利用深度预测作为特征学习的辅助训练指南。&lt;h4&gt;主要发现&lt;/h4&gt;尽管DS的有效性有限，但基准评估表明EDC和SV显著增强了VIS的鲁棒性。使用Swin-L骨干网络时，EDC方法在OVIS基准上达到了56.2 AP，创下了新的最先进结果。&lt;h4&gt;结论&lt;/h4&gt;深度线索被确立为鲁棒视频理解的关键推动因素。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a method to enhance the robustness of Video Instance Segmentation (VIS) by leveraging monocular depth estimation and introducing geometric awareness to overcome challenges such as object occlusions, motion blur, and appearance variations. The study systematically investigates three distinct integration paradigms: Expanding Depth Channel (EDC), Sharing ViT (SV), and Depth Supervision (DS). Although DS shows limited effectiveness, benchmark evaluations demonstrate that EDC and SV significantly enhance the robustness of VIS. With the Swin-L backbone, the EDC method achieves a new state-of-the-art result of 56.2 AP on the OVIS benchmark, conclusively establishing depth cues as critical enablers for robust video understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Instance Segmentation (VIS) fundamentally struggles with pervasivechallenges including object occlusions, motion blur, and appearance variationsduring temporal association. To overcome these limitations, this workintroduces geometric awareness to enhance VIS robustness by strategicallyleveraging monocular depth estimation. We systematically investigate threedistinct integration paradigms. Expanding Depth Channel (EDC) methodconcatenates the depth map as input channel to segmentation networks; SharingViT (SV) designs a uniform ViT backbone, shared between depth estimation andsegmentation branches; Depth Supervision (DS) makes use of depth prediction asan auxiliary training guide for feature learning. Though DS exhibits limitedeffectiveness, benchmark evaluations demonstrate that EDC and SV significantlyenhance the robustness of VIS. When with Swin-L backbone, our EDC method gets56.2 AP, which sets a new state-of-the-art result on OVIS benchmark. This workconclusively establishes depth cues as critical enablers for robust videounderstanding.</description>
      <author>example@mail.com (Quanzhu Niu, Yikang Zhou, Shihao Chen, Tao Zhang, Shunping Ji)</author>
      <guid isPermaLink="false">2507.05948v2</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>XiChen: An observation-scalable fully AI-driven global weather forecasting system with 4D variational knowledge</title>
      <link>http://arxiv.org/abs/2507.09202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为XiChen的全新AI驱动全球天气预报系统，该系统能在短时间内完成从数据同化到中期预报的全过程，显示出在无需传统数值天气预报系统的情况下实现AI驱动天气预报的巨大潜力。&lt;h4&gt;背景&lt;/h4&gt;目前大多数AI驱动的天气预报模型依赖于数值天气预报系统进行初始条件准备，这一过程在超级计算机上通常需要数小时。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够快速完成数据同化和中期预报的AI驱动全球天气预报系统。&lt;h4&gt;方法&lt;/h4&gt;XiChen系统基于预训练的天气预测基础模型，通过后续微调使其既能作为观测操作员又能作为数据同化模型，并整合了四维变分知识，以实现高精度预报。&lt;h4&gt;主要发现&lt;/h4&gt;XiChen系统能在17秒内完成从数据同化到中期预报的全过程，其数据同化和中期预报的准确性可与实际运行的数值天气预报系统相媲美，预报时效超过8.25天。&lt;h4&gt;结论&lt;/h4&gt;XiChen系统展示了在不依赖数值天气预报系统的情况下实现完全AI驱动天气预报的强大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近人工智能（AI）在天气预报领域的进步显示出显著的革命潜力。然而，大多数AI驱动的模型依赖于数值天气预报（NWP）系统进行初始条件准备，这通常在超级计算机上需要数小时。在此，我们介绍了XiChen，这是第一个观测可扩展的完全AI驱动的全球天气预报系统，其整个流程，从数据同化（DA）到中期预报，只需17秒即可完成。XiChen建立在为天气预报预训练的基础模型之上。同时，此模型随后经过微调，用作观测操作员和数据同化模型，从而可扩展地同化传统和原始卫星观测。此外，四维变分知识的集成确保了XiChen的数据同化和中期预报的准确性可与实际运行的NWP系统相媲美，惊人地实现了超过8.25天的熟练预报时效。这些发现表明，XiChen在无需NWP系统的情况下实现完全AI驱动天气预报方面具有强大的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Artificial Intelligence (AI) demonstrate significantpotential to revolutionize weather forecasting. However, most AI-driven modelsrely on Numerical Weather Prediction (NWP) systems for initial conditionpreparation, which often consumes hours on supercomputers. Here we introduceXiChen, the first observation-scalable fully AI-driven global weatherforecasting system, whose entire pipeline, from Data Assimilation (DA) tomedium-range forecasting, can be accomplished within only 17 seconds. XiChen isbuilt upon a foundation model that is pre-trained for weather forecasting.Meanwhile, this model is subsequently fine-tuned to serve as both observationoperators and DA models, thereby scalably assimilating conventional and rawsatellite observations. Furthermore, the integration of four-dimensionalvariational knowledge ensures that XiChen's DA and medium-range forecastingaccuracy rivals that of operational NWP systems, amazingly achieving a skillfulforecasting lead time exceeding 8.25 days. These findings demonstrate thatXiChen holds strong potential toward fully AI-driven weather forecastingindependent of NWP systems.</description>
      <author>example@mail.com (Wuxin Wang, Weicheng Ni, Lilan Huang, Tao Hao, Ben Fei, Shuo Ma, Taikang Yuan, Yanlai Zhao, Kefeng Deng, Xiaoyong Li, Boheng Duan, Lei Bai, Kaijun Ren)</author>
      <guid isPermaLink="false">2507.09202v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>SPICE: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation</title>
      <link>http://arxiv.org/abs/2507.09108v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SPICE的自动化工具，用于为软件工程（SWE）中的SWE-bench风格数据集创建标签，旨在降低标注成本和提高标注效率。&lt;h4&gt;背景&lt;/h4&gt;高质量的标注数据集对于软件工程领域的基础模型训练和评估至关重要，但创建这样的数据集通常成本高昂且劳动密集。&lt;h4&gt;目的&lt;/h4&gt;开发一个可扩展的自动化流程（SPICE），用于对SWE-bench风格数据集进行标注，包括问题清晰度、测试覆盖率和工作量估计。&lt;h4&gt;方法&lt;/h4&gt;SPICE结合了上下文感知的代码导航、基于理由的提示和多次通过达成共识的方法，以生成接近专家标注的标签。&lt;h4&gt;主要发现&lt;/h4&gt;SPICE在SWE-bench验证数据上取得了与人工标注高度一致的结果，同时将1000个实例的标注成本从约10万美元降低到仅5.10美元。&lt;h4&gt;结论&lt;/h4&gt;SPICE具有使软件工程领域的基础模型能够以低成本、大规模创建数据集的潜力。为了支持社区，研究人员发布了SPICE工具和SPICE Bench，这是一个包含6,802个SPICE标注实例的新数据集，这些实例是从SWE-Gym中的291个开源项目中收集的，比SWE-bench验证数据集大13倍以上。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces SPICE, an automated tool designed for labeling SWE-bench-style datasets in software engineering, aiming to reduce the cost and increase the efficiency of annotation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-quality labeled datasets are crucial for training and evaluatingfoundation models in software engineering, but creating them is oftenprohibitively expensive and labor-intensive. We introduce SPICE, a scalable,automated pipeline for labeling SWE-bench-style datasets with annotations forissue clarity, test coverage, and effort estimation. SPICE combinescontext-aware code navigation, rationale-driven prompting, and multi-passconsensus to produce labels that closely approximate expert annotations.SPICE's design was informed by our own experience and frustration in labelingmore than 800 instances from SWE-Gym. SPICE achieves strong agreement withhuman-labeled SWE-bench Verified data while reducing the cost of labeling 1,000instances from around $100,000 (manual annotation) to just $5.10. These resultsdemonstrate SPICE's potential to enable cost-effective, large-scale datasetcreation for SE-focused FMs. To support the community, we release both SPICEtool and SPICE Bench, a new dataset of 6,802 SPICE-labeled instances curatedfrom 291 open-source projects in SWE-Gym (over 13x larger than SWE-benchVerified).</description>
      <author>example@mail.com (Aaditya Bhatia, Gustavo A. Oliva, Gopi Krishnan Rajbahadur, Haoxiang Zhang, Yihao Chen, Zhilong Chen, Arthur Leung, Dayi Lin, Boyuan Chen, Ahmed E. Hassan)</author>
      <guid isPermaLink="false">2507.09108v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>From Physics to Foundation Models: A Review of AI-Driven Quantitative Remote Sensing Inversion</title>
      <link>http://arxiv.org/abs/2507.09081v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统地回顾了遥感反演技术的方法论演变，从物理模型到机器学习方法，再到基础模型，并比较了每种方法的建模假设、应用场景和局限性。&lt;h4&gt;背景&lt;/h4&gt;随着遥感系统和人工智能的发展，传统的基于物理的范式正在被数据驱动和基于基础模型的方法所取代。&lt;h4&gt;目的&lt;/h4&gt;定量遥感反演旨在从卫星观测中估计连续地表变量，如生物量、植被指数和蒸散量，以支持生态系统监测、碳核算和土地管理。&lt;h4&gt;方法&lt;/h4&gt;本文对比了物理模型（如PROSPECT、SCOPE、DART）到机器学习方法（如深度学习、多模态融合），再到基础模型（如SatMAE、GFM、mmEarth）的方法论演变。&lt;h4&gt;主要发现&lt;/h4&gt;文章强调了最近在基础模型方面的进展，包括自监督预训练、多模态集成和跨任务适应，并指出了物理可解释性、领域泛化、有限监督和不确定性量化等持续挑战。&lt;h4&gt;结论&lt;/h4&gt;最后，文章展望了下一代基础模型在遥感反演中的发展，强调了统一的建模能力、跨领域泛化和物理可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantitative remote sensing inversion aims to estimate continuous surfacevariables-such as biomass, vegetation indices, and evapotranspiration-fromsatellite observations, supporting applications in ecosystem monitoring, carbonaccounting, and land management. With the evolution of remote sensing systemsand artificial intelligence, traditional physics-based paradigms are giving wayto data-driven and foundation model (FM)-based approaches. This papersystematically reviews the methodological evolution of inversion techniques,from physical models (e.g., PROSPECT, SCOPE, DART) to machine learning methods(e.g., deep learning, multimodal fusion), and further to foundation models(e.g., SatMAE, GFM, mmEarth). We compare the modeling assumptions, applicationscenarios, and limitations of each paradigm, with emphasis on recent FMadvances in self-supervised pretraining, multi-modal integration, andcross-task adaptation. We also highlight persistent challenges in physicalinterpretability, domain generalization, limited supervision, and uncertaintyquantification. Finally, we envision the development of next-generationfoundation models for remote sensing inversion, emphasizing unified modelingcapacity, cross-domain generalization, and physical interpretability.</description>
      <author>example@mail.com (Zhenyu Yu, Mohd Yamani Idna Idris, Hua Wang, Pei Wang, Junyi Chen, Kun Wang)</author>
      <guid isPermaLink="false">2507.09081v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Reconstruction of cosmic-ray properties with GNN in GRAND</title>
      <link>http://arxiv.org/abs/2507.07541v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 39th International Cosmic Ray Conference (ICRC  2025). 8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GRAND项目旨在通过观测大气中产生的无线电辐射来检测和研究超高能中微子。研究提出了一种利用机器学习技术从噪声模拟电压迹线中重建中微子到达方向和能量的方法。&lt;h4&gt;背景&lt;/h4&gt;GRAND项目使用GRANDProto300原型来演示自主检测和重建技术，这些技术将应用于中微子检测。&lt;h4&gt;目的&lt;/h4&gt;提高中微子到达方向和能量的重建精度，并减少所需训练集的大小。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络（GNN）处理触发天线作为图结构的数据输入，并将物理知识融入GNN架构和输入数据，同时采用不确定性估计方法来提高预测的可靠性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了0.14度的角分辨率和约15%的主要能量重建分辨率，并提供了方向和能量重建的置信区间。&lt;h4&gt;结论&lt;/h4&gt;研究探索了评估模型在真实数据上应用时一致性和鲁棒性的策略，旨在识别在模拟与现实中域变化时仍然可靠的预测情况。&lt;h4&gt;翻译&lt;/h4&gt;摘要：GRAND项目（大中微子无线电阵列）旨在通过观测大气中产生的无线电辐射来检测和研究超高能（UHE）中微子。本研究提出了一种利用最先进的机器学习技术从噪声模拟电压迹线中重建中微子到达方向和能量的方法。对于每个事件，我们将触发天线表示为图结构，并将其作为图神经网络（GNN）的输入。为了显著提高精度并减少所需训练集的大小，我们将物理知识融入GNN架构和输入数据。这种方法实现了0.14度的角分辨率和约15%的主要能量重建分辨率。此外，我们采用了不确定性估计方法来提高预测的可靠性。这些方法允许我们量化GNN预测的置信度，并为方向和能量重建提供置信区间。最后，我们探索了评估模型在真实数据上应用时一致性和鲁棒性的策略。我们的目标是识别在模拟与现实中域变化时仍然可靠的预测情况。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Giant Radio Array for Neutrino Detection (GRAND) aims to detect and studyultra-high-energy (UHE) neutrinos by observing the radio emissions produced inextensive air showers. The GRANDProto300 prototype primarily focuses on UHEcosmic rays to demonstrate the autonomous detection and reconstructiontechniques that will later be applied to neutrino detection. In this work, wepropose a method for reconstructing the arrival direction and energy with highprecision using state-of-the-art machine learning techniques from noisysimulated voltage traces. For each event, we represent the triggered antennasas a graph structure, which is used as input for a graph neural network (GNN).To significantly enhance precision and reduce the required training set size,we incorporate physical knowledge into both the GNN architecture and the inputdata. This approach achieves an angular resolution of 0.14{\deg} and a primaryenergy reconstruction resolution of about 15%. Additionally, we employuncertainty estimation methods to improve the reliability of our predictions.These methods allow us to quantify the confidence of the GNN predictions andprovide confidence intervals for the direction and energy reconstruction.Finally, we explore strategies to evaluate the consistency and robustness ofthe model when applied to real data. Our goal is to identify situations wherepredictions remain trustworthy despite domain shifts between simulation andreality.</description>
      <author>example@mail.com (Arsène Ferrière, Aurélien Benoit-Lévy)</author>
      <guid isPermaLink="false">2507.07541v2</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>BioAnalyst: A Foundation Model for Biodiversity</title>
      <link>http://arxiv.org/abs/2507.09080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了BioAnalyst，一个专门用于生物多样性分析和保护规划的基础模型，旨在应对生物多样性面临的威胁，如栖息地丧失、气候变化和入侵物种的增多。&lt;h4&gt;背景&lt;/h4&gt;生物多样性的加速丧失对生态研究和保护策略构成了重大挑战，保护生物多样性对于维持生态平衡和确保生态系统的可持续性至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够适应多种下游任务（如物种分布模型、栖息地适宜性评估、入侵物种检测和种群趋势预测）的基础模型，以促进生物多样性建模和解决生态挑战。&lt;h4&gt;方法&lt;/h4&gt;BioAnalyst采用基于transformer的架构，在包含物种发生记录、遥感指标、气候和环境变量的多模态数据集上进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;模型在两个下游用例上进行了评估，证明了其在数据稀缺场景下的泛化能力，并建立了新的生态预测准确率基准。&lt;h4&gt;结论&lt;/h4&gt;通过向科学界公开发布BioAnalyst及其微调工作流程，旨在促进生物多样性建模的协作努力，并推进解决紧迫生态挑战的AI驱动解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accelerating loss of biodiversity presents critical challenges forecological research and conservation strategies. The preservation ofbiodiversity is paramount for maintaining ecological balance and ensuring thesustainability of ecosystems. However, biodiversity faces numerous threats,including habitat loss, climate change, and the proliferation of invasivespecies. Addressing these and other ecology-related challenges, both at localand global scales, requires comprehensive monitoring, predictive andconservation planning capabilities. Artificial Intelligence (AI) FoundationModels (FMs) have gained significant momentum in numerous scientific domains byleveraging vast datasets to learn general-purpose representations adaptable tovarious downstream tasks. This paradigm holds immense promise for biodiversityconservation. In response, we introduce BioAnalyst, the first Foundation Modeltailored for biodiversity analysis and conservation planning. BioAnalystemploys a transformer-based architecture, pre-trained on extensive multi-modaldatasets encompassing species occurrence records, remote sensing indicators,climate and environmental variables. BioAnalyst is designed for adaptability,allowing for fine-tuning of a range of downstream tasks, such as speciesdistribution modelling, habitat suitability assessments, invasive speciesdetection, and population trend forecasting. We evaluate the model'sperformance on two downstream use cases, demonstrating its generalisabilitycompared to existing methods, particularly in data-scarce scenarios for twodistinct use-cases, establishing a new accuracy baseline for ecologicalforecasting. By openly releasing BioAnalyst and its fine-tuning workflows tothe scientific community, we aim to foster collaborative efforts inbiodiversity modelling and advance AI-driven solutions to pressing ecologicalchallenges.</description>
      <author>example@mail.com (Athanasios Trantas, Martino Mensio, Stylianos Stasinos, Sebastian Gribincea, Taimur Khan, Damian Podareanu, Aliene van der Veen)</author>
      <guid isPermaLink="false">2507.09080v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>Acquiring and Adapting Priors for Novel Tasks via Neural Meta-Architectures</title>
      <link>http://arxiv.org/abs/2507.10446v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2310.17075&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了从先前的经验中迁移知识到新任务的能力，重点在于设计架构以在大量数据不可用的情况下高效地获取先验知识。&lt;h4&gt;背景&lt;/h4&gt;迁移学习在任务适应速度和性能方面取得了巨大成功，但在数据缺乏的领域（如计算化学、计算免疫学和医学成像）中，训练大型预训练模型或基础模型是不可能的。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，本文旨在设计能够高效获取先验知识的架构。&lt;h4&gt;方法&lt;/h4&gt;本文提出使用神经网络记忆来适应非平稳分布，并通过超网络设计（一种生成另一个网络的网络）与Model Agnostic Meta-Learning（MAML）训练，以获得比标准网络更通用的先验知识。然后，将超网络应用于3D场景生成，并将其框架扩展到对有限数据的场景进行3D分割。最后，将现有的分子生成方法重新用作预训练框架，以促进分子性质预测的改进。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，使用少量样本即可通过神经网络记忆适应非平稳分布，超网络能够高效地从少量训练场景中获取先验知识，从而实现更快的文本到3D生成，并且可以从先前查看的场景中有效地转移先验知识以进行3D分割，以及通过预训练框架提高了分子性质预测。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在解决数据缺乏的领域中的迁移学习问题方面具有潜力，并展示了在计算免疫学等领域的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要：将先前的经验迁移到新任务的能力是智能代理（包括人类和计算模型）的关键能力。这一原则构成了迁移学习的基础，即通过微调大型预训练神经网络以适应下游任务。迁移学习在任务适应速度和性能方面取得了巨大成功。然而，在数据不足的领域，由于缺乏数据，无法训练这样的大型预训练模型或基础模型 - 计算化学、计算免疫学和医学成像就是例子。为了解决这些挑战，我们的工作集中在设计架构，以便在大量数据不可用的情况下高效地获取先验知识。特别是，我们证明了我们可以使用神经网络记忆来仅通过少量样本就适应非平稳分布。然后，我们证明了当与Model Agnostic Meta-Learning（MAML）一起训练时，我们的超网络设计（一种生成另一个网络的网络）可以比标准网络获得更通用的先验知识。随后，我们将超网络应用于3D场景生成，证明了它们可以从少量训练场景中有效地获取先验知识，从而实现更快的文本到3D生成。然后，我们将我们的超网络框架扩展到对有限数据的场景进行3D分割，通过有效地从先前查看的场景中转移先验知识。最后，我们将现有的分子生成方法重新用作预训练框架，以促进分子性质预测的改进，解决计算免疫学中的关键挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to transfer knowledge from prior experiences to novel tasksstands as a pivotal capability of intelligent agents, including both humans andcomputational models. This principle forms the basis of transfer learning,where large pre-trained neural networks are fine-tuned to adapt to downstreamtasks. Transfer learning has demonstrated tremendous success, both in terms oftask adaptation speed and performance. However there are several domains where,due to lack of data, training such large pre-trained models or foundationalmodels is not a possibility - computational chemistry, computationalimmunology, and medical imaging are examples. To address these challenges, ourwork focuses on designing architectures to enable efficient acquisition ofpriors when large amounts of data are unavailable. In particular, wedemonstrate that we can use neural memory to enable adaptation onnon-stationary distributions with only a few samples. Then we demonstrate thatour hypernetwork designs (a network that generates another network) can acquiremore generalizable priors than standard networks when trained with ModelAgnostic Meta-Learning (MAML). Subsequently, we apply hypernetworks to 3D scenegeneration, demonstrating that they can acquire priors efficiently on just ahandful of training scenes, thereby leading to faster text-to-3D generation. Wethen extend our hypernetwork framework to perform 3D segmentation on novelscenes with limited data by efficiently transferring priors from earlier viewedscenes. Finally, we repurpose an existing molecular generative method as apre-training framework that facilitates improved molecular property prediction,addressing critical challenges in computational immunology</description>
      <author>example@mail.com (Sudarshan Babu)</author>
      <guid isPermaLink="false">2507.10446v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>ALIGN: Prompt-based Attribute Alignment for Reliable, Responsible, and Personalized LLM-based Decision-Making</title>
      <link>http://arxiv.org/abs/2507.09037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages total (including appendix), ICML 2025 Workshop on Reliable  and Responsible Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ALIGN的系统，用于动态个性化大型语言模型（LLMs）的决策制定，通过基于提示的细粒度属性对齐，并提供了一个用户界面和模块化后端。&lt;h4&gt;背景&lt;/h4&gt;随着LLMs在决策辅助中的应用增加，用户的价值和偏好差异要求开发新的对齐和个性化方法。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够实现LLMs决策制定的动态个性化和对齐的系统。&lt;h4&gt;方法&lt;/h4&gt;ALIGN系统通过基于提示的细粒度属性对齐实现LLMs的个性化，包括稳健的配置管理、具有推理的结构化输出生成，以及可互换的LLM骨干算法实现。&lt;h4&gt;主要发现&lt;/h4&gt;系统支持LLMs的定性比较和属性对齐，后端模块化便于算法集成，并在两个不同领域进行了对齐方法的定量分析：人口统计对齐用于公众舆论调查，价值对齐用于医疗分诊决策。&lt;h4&gt;结论&lt;/h4&gt;ALIGN框架是开源的，将促进对可靠、负责任和个性化LLMs决策制定的新研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) are increasingly being used as decision aids.However, users have diverse values and preferences that can affect theirdecision-making, which requires novel methods for LLM alignment andpersonalization. Existing LLM comparison tools largely focus on benchmarkingtasks, such as knowledge-based question answering. In contrast, our proposedALIGN system focuses on dynamic personalization of LLM-based decision-makersthrough prompt-based alignment to a set of fine-grained attributes. Keyfeatures of our system include robust configuration management, structuredoutput generation with reasoning, and several algorithm implementations withswappable LLM backbones, enabling different types of analyses. Our userinterface enables a qualitative, side-by-side comparison of LLMs and theiralignment to various attributes, with a modular backend for easy algorithmintegration. Additionally, we perform a quantitative analysis comparingalignment approaches in two different domains: demographic alignment for publicopinion surveys and value alignment for medical triage decision-making. Theentire ALIGN framework is open source and will enable new research on reliable,responsible, and personalized LLM-based decision-makers.</description>
      <author>example@mail.com (Bharadwaj Ravichandran, David Joy, Paul Elliott, Brian Hu, Jadie Adams, Christopher Funk, Emily Veenhuis, Anthony Hoogs, Arslan Basharat)</author>
      <guid isPermaLink="false">2507.09037v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>DiffNMR: Diffusion Models for Nuclear Magnetic Resonance Spectra Elucidation</title>
      <link>http://arxiv.org/abs/2507.08854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DiffNMR是一种用于从NMR光谱中解析新分子结构的端到端框架，它通过条件离散扩散模型和多种预处理策略，实现了高效且鲁棒的分子分析。&lt;h4&gt;背景&lt;/h4&gt;NMR光谱是分子结构解析的关键方法，但解析NMR光谱以推断分子结构仍然具有挑战性，因为光谱数据复杂且化学空间庞大。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的NMR光谱解析框架，以实现从NMR光谱中自动解析分子结构。&lt;h4&gt;方法&lt;/h4&gt;DiffNMR使用条件离散扩散模型进行分子图迭代优化，通过扩散自动编码器（Diff-AE）和对比学习实现光谱和分子表示的对齐，并在推理过程中采用检索初始化和相似性过滤，同时使用径向基函数（RBF）编码器处理化学位移。&lt;h4&gt;主要发现&lt;/h4&gt;DiffNMR在NMR结构解析方面取得了有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;DiffNMR为自动化分子分析提供了一种高效且鲁棒的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：核磁共振(NMR)波谱学是分子结构阐明的一种核心表征方法，然而，由于光谱数据的复杂性和化学空间的广泛性，从NMR光谱中推断分子结构仍然具有挑战性。在这项工作中，我们引入了DiffNMR，这是一个新的端到端框架，它利用条件离散扩散模型从NMR光谱中进行从头分子结构阐明。DiffNMR通过基于扩散的生成过程迭代地细化分子图，确保全局一致性并减轻自回归方法中固有的错误累积。该框架集成了两阶段预训练策略，通过扩散自动编码器（Diff-AE）和对比学习对齐光谱和分子表示，在推理期间结合检索初始化和相似性过滤，并使用径向基函数（RBF）编码器对化学位移进行专门编码，以保持连续性和化学相关性。实验结果表明，DiffNMR在基于NMR的结构解析方面取得了有竞争力的性能，为自动化分子分析提供了一种高效且鲁棒的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nuclear Magnetic Resonance (NMR) spectroscopy is a central characterizationmethod for molecular structure elucidation, yet interpreting NMR spectra todeduce molecular structures remains challenging due to the complexity ofspectral data and the vastness of the chemical space. In this work, weintroduce DiffNMR, a novel end-to-end framework that leverages a conditionaldiscrete diffusion model for de novo molecular structure elucidation from NMRspectra. DiffNMR refines molecular graphs iteratively through a diffusion-basedgenerative process, ensuring global consistency and mitigating erroraccumulation inherent in autoregressive methods. The framework integrates atwo-stage pretraining strategy that aligns spectral and molecularrepresentations via diffusion autoencoder (Diff-AE) and contrastive learning,the incorporation of retrieval initialization and similarity filtering duringinference, and a specialized NMR encoder with radial basis function (RBF)encoding for chemical shifts, preserving continuity and chemical correlation.Experimental results demonstrate that DiffNMR achieves competitive performancefor NMR-based structure elucidation, offering an efficient and robust solutionfor automated molecular analysis.</description>
      <author>example@mail.com (Qingsong Yang, Binglan Wu, Xuwei Liu, Bo Chen, Wei Li, Gen Long, Xin Chen, Mingjun Xiao)</author>
      <guid isPermaLink="false">2507.08854v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>From Classical Machine Learning to Emerging Foundation Models: Review on Multimodal Data Integration for Cancer Research</title>
      <link>http://arxiv.org/abs/2507.09028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了多模态数据在癌症研究中的应用，探讨了机器学习和深度学习在癌症亚型分类、生物标志物发现、治疗指导和预后预测等方面的方法，并介绍了从传统机器学习到基础模型的多模态数据整合转变。&lt;h4&gt;背景&lt;/h4&gt;癌症研究正越来越多地依赖于基因组学、蛋白质组学、成像和临床因素等不同数据模态的整合，但从中提取有价值的见解仍然是一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;本文旨在全面回顾广泛采用的多模态数据整合策略，以促进癌症研究中数据驱动发现的计算方法的发展。&lt;h4&gt;方法&lt;/h4&gt;本文考察了机器学习和深度学习的最新趋势，包括方法论框架、验证协议和开源资源，以及从传统机器学习到基础模型的多模态整合的转变。&lt;h4&gt;主要发现&lt;/h4&gt;本文确定了最先进的模型、公开可用的多模态数据存储库和高级数据整合工具和方法，并认为当前最先进的整合方法为开发下一代大规模预训练模型提供了基础。&lt;h4&gt;结论&lt;/h4&gt;本文是首次系统地映射从传统机器学习到高级基础模型在癌症研究中多模态数据整合的转变，并将这些发展视为未来大规模AI模型在癌症研究中的基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：癌症研究正日益由多种数据模态的整合所驱动，这些数据模态包括基因组学、蛋白质组学、成像和临床因素。然而，从这些庞大且异构的数据集中提取可操作的见解仍然是一个关键挑战。基础模型（FMs）的兴起——大型深度学习模型，在大量数据上预训练，作为广泛下游任务的骨干——为发现生物标志物、改善诊断和个性化治疗提供了新的途径。本文全面回顾了广泛采用的多模态数据整合策略，以协助推进癌症研究中数据驱动发现的计算方法。我们研究了机器学习和深度学习的最新趋势，包括方法论框架、验证协议和针对癌症亚型分类、生物标志物发现、治疗指导和预后预测的开源资源。本研究还全面覆盖了从传统机器学习到FMs的多模态整合的转变。我们提出了对最近FMs进步的全面观点和整合多组学数据与高级成像数据时面临的挑战。我们确定了最先进的FMs、公开可用的多模态数据存储库和高级数据整合工具和方法。我们认为，当前最先进的整合方法为开发下一代大型规模预训练模型提供了基础。据我们所知，这是首次系统地映射从传统机器学习到高级基础模型在癌症研究中多模态数据整合的转变，同时将这些发展视为未来大规模AI模型在癌症研究中的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cancer research is increasingly driven by the integration of diverse datamodalities, spanning from genomics and proteomics to imaging and clinicalfactors. However, extracting actionable insights from these vast andheterogeneous datasets remains a key challenge. The rise of foundation models(FMs) -- large deep-learning models pretrained on extensive amounts of dataserving as a backbone for a wide range of downstream tasks -- offers newavenues for discovering biomarkers, improving diagnosis, and personalizingtreatment. This paper presents a comprehensive review of widely adoptedintegration strategies of multimodal data to assist advance the computationalapproaches for data-driven discoveries in oncology. We examine emerging trendsin machine learning (ML) and deep learning (DL), including methodologicalframeworks, validation protocols, and open-source resources targeting cancersubtype classification, biomarker discovery, treatment guidance, and outcomeprediction. This study also comprehensively covers the shift from traditionalML to FMs for multimodal integration. We present a holistic view of recent FMsadvancements and challenges faced during the integration of multi-omics withadvanced imaging data. We identify the state-of-the-art FMs, publicly availablemulti-modal repositories, and advanced tools and methods for data integration.We argue that current state-of-the-art integrative methods provide theessential groundwork for developing the next generation of large-scale,pre-trained models poised to further revolutionize oncology. To the best of ourknowledge, this is the first review to systematically map the transition fromconventional ML to advanced FM for multimodal data integration in oncology,while also framing these developments as foundational for the forthcoming eraof large-scale AI models in cancer research.</description>
      <author>example@mail.com (Amgad Muneer, Muhammad Waqas, Maliazurina B Saad, Eman Showkatian, Rukhmini Bandyopadhyay, Hui Xu, Wentao Li, Joe Y Chang, Zhongxing Liao, Cara Haymaker, Luisa Solis Soto, Carol C Wu, Natalie I Vokes, Xiuning Le, Lauren A Byers, Don L Gibbons, John V Heymach, Jianjun Zhang, Jia Wu)</author>
      <guid isPermaLink="false">2507.09028v1</guid>
      <pubDate>Tue, 15 Jul 2025 14:45:16 +0800</pubDate>
    </item>
    <item>
      <title>From One to More: Contextual Part Latents for 3D Generation</title>
      <link>http://arxiv.org/abs/2507.08772v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://hkdsc.github.io/project/copart&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CoPart的3D生成方法，该方法通过将3D对象分解为上下文化的部分潜变量来生成多部分对象，克服了现有方法的三个关键局限性。&lt;h4&gt;背景&lt;/h4&gt;3D生成技术从基于多视角的2D渲染方法转变为利用地面真实数据中几何先验的3D原生潜在扩散框架。尽管取得进展，但仍存在三个主要问题。&lt;h4&gt;目的&lt;/h4&gt;旨在解决3D生成中的三个关键限制，包括单潜在表示无法捕捉复杂多部件几何、整体潜在编码忽视部件的独立性和关系、以及全局条件机制缺乏细粒度可控性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为CoPart的部分感知扩散框架，该框架通过部件分解减少编码复杂性，并通过显式建模部件关系和部分级别条件来增强生成能力。此外，开发了一种互导策略来微调预训练的扩散模型，并构建了Partverse，一个从Objaverse中通过自动网格分割和人工验证标注得到的新型3D部件数据集。&lt;h4&gt;主要发现&lt;/h4&gt;CoPart在部件级别编辑、关节物体生成和场景组合方面表现出卓越的能力，具有前所未有的可控性。&lt;h4&gt;结论&lt;/h4&gt;CoPart是一种有效的3D生成方法，它通过部件分解、显式建模部件关系和互导策略，显著提高了3D对象生成的质量。&lt;h4&gt;翻译&lt;/h4&gt;在3D生成技术领域，最近的研究进展已经从多视角的2D渲染方法转变到了利用地面真实数据中的几何先验的3D原生潜在扩散框架。尽管取得了进步，但仍然存在三个主要的局限性：1）单潜在表示无法捕捉复杂的多部件几何，导致细节退化；2）整体潜在编码忽视了部件的独立性和关系，这对于组合设计至关重要；3）全局条件机制缺乏细粒度的可控性。受到人类3D设计工作流程的启发，我们提出了一种名为CoPart的部分感知扩散框架，该框架将3D对象分解为上下文化的部分潜变量，以实现一致的多部件生成。这种范式提供了三个优点：i）通过部件分解减少了编码复杂性；ii）允许显式建模部件关系；iii）支持部件级别的条件。我们进一步开发了一种互导策略，以微调预训练的扩散模型，确保几何一致性和基础模型先验。为了实现大规模训练，我们构建了Partverse——一个从Objaverse通过自动网格分割和人工验证标注得到的新型3D部件数据集。广泛的实验表明，CoPart在部件级别编辑、关节物体生成和场景组合方面具有卓越的能力，具有前所未有的可控性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in 3D generation have transitioned from multi-view 2Drendering approaches to 3D-native latent diffusion frameworks that exploitgeometric priors in ground truth data. Despite progress, three key limitationspersist: (1) Single-latent representations fail to capture complex multi-partgeometries, causing detail degradation; (2) Holistic latent coding neglectspart independence and interrelationships critical for compositional design; (3)Global conditioning mechanisms lack fine-grained controllability. Inspired byhuman 3D design workflows, we propose CoPart - a part-aware diffusion frameworkthat decomposes 3D objects into contextual part latents for coherent multi-partgeneration. This paradigm offers three advantages: i) Reduces encodingcomplexity through part decomposition; ii) Enables explicit part relationshipmodeling; iii) Supports part-level conditioning. We further develop a mutualguidance strategy to fine-tune pre-trained diffusion models for joint partlatent denoising, ensuring both geometric coherence and foundation modelpriors. To enable large-scale training, we construct Partverse - a novel 3Dpart dataset derived from Objaverse through automated mesh segmentation andhuman-verified annotations. Extensive experiments demonstrate CoPart's superiorcapabilities in part-level editing, articulated object generation, and scenecomposition with unprecedented controllability.</description>
      <author>example@mail.com (Shaocong Dong, Lihe Ding, Xiao Chen, Yaokun Li, Yuxin Wang, Yucheng Wang, Qi Wang, Jaehyeok Kim, Chenjian Gao, Zhanpeng Huang, Zibin Wang, Tianfan Xue, Dan Xu)</author>
      <guid isPermaLink="false">2507.08772v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
  <item>
      <title>Minimum-norm interpolation for unknown surface reconstruction</title>
      <link>http://arxiv.org/abs/2507.08632v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过隐式表面表示估计原始点云数据的几何属性，提出了基于核函数的径向基函数（RBF）插值方法，并改进了表面重建的精度。&lt;h4&gt;背景&lt;/h4&gt;原始点云数据的几何属性估计通常需要特定的目标函数，而本文提出的方法不依赖于特定的目标函数。&lt;h4&gt;目的&lt;/h4&gt;提高从原始点云数据中重建表面的精度，特别是表面法线的精确估计。&lt;h4&gt;方法&lt;/h4&gt;使用基于核函数的插值方法，将唯一可解的插值问题重新表述为一个约束优化模型，并通过引入Kolmogorov-Arnold Networks（KANs）启发的1D核基函数来增强试验空间。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的混合维数试验空间显著提高了从原始点云数据中重建表面的精度，特别是在表面法线的精确估计方面，优于传统的RBF试验空间。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅提高了原始点云数据的处理能力，而且对计算几何领域有进一步贡献的潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了通过隐式表面表示估计原始点云数据的几何属性。鉴于任何具有恒定水平集对应于表面的水平集函数都可以用于此类估计，数值方法不需要为域型插值问题指定一个唯一的目标函数。在本文中，我们专注于基于径向基函数（RBF）的核函数插值，并将唯一可解的插值问题重新表述为一个约束优化模型。该模型在强制所有插值条件的同时最小化一些用户定义的范数。为了使非平凡的可行解成为可能，我们提出使用受Kolmogorov-Arnold Networks（KANs）启发的1D核基函数来增强试验空间。数值实验表明，我们提出的混合维数试验空间显著提高了从原始点云数据中重建表面的精度。这在精确估计表面法线方面尤为明显，优于包括用于Hermite插值的传统RBF试验空间。这个框架不仅增强了原始点云数据的处理能力，而且显示出对计算几何领域有进一步贡献的潜力。我们通过一个点云处理示例来证明这一点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study algorithms to estimate geometric properties of raw point cloud datathrough implicit surface representations. Given that any level-set functionwith a constant level set corresponding to the surface can be used for suchestimations, numerical methods need not specify a unique target function forthe domain-type interpolation problems. In this paper, we focus on kernel-basedinterpolation by radial basis functions (RBF) and reformulate the uniquelysolvable interpolation problem into a constrained optimization model. Thismodel minimizes some user-defined norm while enforcing all interpolationconditions. To enable nontrivial feasible solutions, we propose to enhance thetrial space with 1D kernel basis functions inspired by Kolmogorov-ArnoldNetworks (KANs). Numerical experiments demonstrate that our proposed mixeddimensional trial space significantly improves surface reconstruction from rawpoint clouds. This is particularly evident in the precise estimation of surfacenormals, outperforming traditional RBF trial spaces including the one forHermite interpolation. This framework not only enhances processing of raw pointcloud data but also shows potential for further contributions to computationalgeometry. We demonstrate this with a point cloud processing example.</description>
      <author>example@mail.com (Alex Shiu Lun Chu, Leevan Ling, Ka Chun Cheung)</author>
      <guid isPermaLink="false">2507.08632v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>MoSAiC: Multi-Modal Multi-Label Supervision-Aware Contrastive Learning for Remote Sensing</title>
      <link>http://arxiv.org/abs/2507.08683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MoSAiC，一个针对多模态卫星图像的统一框架，通过联合优化模态内和模态间对比学习以及多标签监督对比损失，实现了在低标签和高类别重叠场景下的细粒度语义解耦和鲁棒的表征学习。&lt;h4&gt;背景&lt;/h4&gt;对比学习（CL）作为一种学习可迁移表征的方法，在计算机视觉任务中取得了最先进的成果。它在地球系统观测（ESO）领域表现出色，因为该领域中的多卫星模态提供了对同一地理区域的自然对齐视图。&lt;h4&gt;目的&lt;/h4&gt;克服ESO领域的高类别相似性、场景杂乱和模糊边界等挑战，在低标签和多标签设置中实现表征学习。&lt;h4&gt;方法&lt;/h4&gt;MoSAiC框架联合优化了模态内和模态间对比学习，并引入了多标签监督对比损失，特别针对多模态卫星图像设计。&lt;h4&gt;主要发现&lt;/h4&gt;在BigEarthNet V2.0和Sent12MS两个基准数据集上的实验表明，MoSAiC在低标签和高类别重叠场景下，在准确性、聚类一致性和泛化能力方面均优于全监督和自监督的基线。&lt;h4&gt;结论&lt;/h4&gt;MoSAiC能够有效提升多模态卫星图像的表征学习，为地球系统观测领域提供了有力的工具。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive learning (CL) has emerged as a powerful paradigm for learning transferable representations without the reliance on large labeled datasets. Its ability to capture intrinsic similarities and differences among data samples has led to state-of-the-art results in computer vision tasks. These strengths make CL particularly well-suited for Earth System Observation (ESO), where diverse satellite modalities such as optical and SAR imagery offer naturally aligned views of the same geospatial regions. However, ESO presents unique challenges, including high inter-class similarity, scene clutter, and ambiguous boundaries, which complicate representation learning -- especially in low-label, multi-label settings. Existing CL frameworks often focus on intra-modality self-supervision or lack mechanisms for multi-label alignment and semantic precision across modalities. In this work, we introduce MoSAiC, a unified framework that jointly optimizes intra- and inter-modality contrastive learning with a multi-label supervised contrastive loss. Designed specifically for multi-modal satellite imagery, MoSAiC enables finer semantic disentanglement and more robust representation learning across spectrally similar and spatially complex classes. Experiments on two benchmark datasets, BigEarthNet V2.0 and Sent12MS, show that MoSAiC consistently outperforms both fully supervised and self-supervised baselines in terms of accuracy, cluster coherence, and generalization in low-label and high-class-overlap scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning (CL) has emerged as a powerful paradigm for learningtransferable representations without the reliance on large labeled datasets.Its ability to capture intrinsic similarities and differences among datasamples has led to state-of-the-art results in computer vision tasks. Thesestrengths make CL particularly well-suited for Earth System Observation (ESO),where diverse satellite modalities such as optical and SAR imagery offernaturally aligned views of the same geospatial regions. However, ESO presentsunique challenges, including high inter-class similarity, scene clutter, andambiguous boundaries, which complicate representation learning -- especially inlow-label, multi-label settings. Existing CL frameworks often focus onintra-modality self-supervision or lack mechanisms for multi-label alignmentand semantic precision across modalities. In this work, we introduce MoSAiC, aunified framework that jointly optimizes intra- and inter-modality contrastivelearning with a multi-label supervised contrastive loss. Designed specificallyfor multi-modal satellite imagery, MoSAiC enables finer semanticdisentanglement and more robust representation learning across spectrallysimilar and spatially complex classes. Experiments on two benchmark datasets,BigEarthNet V2.0 and Sent12MS, show that MoSAiC consistently outperforms bothfully supervised and self-supervised baselines in terms of accuracy, clustercoherence, and generalization in low-label and high-class-overlap scenarios.</description>
      <author>example@mail.com (Debashis Gupta, Aditi Golder, Rongkhun Zhu, Kangning Cui, Wei Tang, Fan Yang, Ovidiu Csillik, Sarra Alaqahtani, V. Paul Pauca)</author>
      <guid isPermaLink="false">2507.08683v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning</title>
      <link>http://arxiv.org/abs/2507.08730v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICSE 2026&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为DHDA的在线配置性能学习框架，旨在适应动态环境中的概念漂移问题。&lt;h4&gt;背景&lt;/h4&gt;现代可配置软件系统需要在配置和性能之间建立模型，但在动态环境中，工作负载变化、硬件变化和系统更新会引入不同层次的概念漂移，如全局漂移和局部漂移，这对现有方法提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;解决动态环境中配置性能学习面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;DHDA框架通过双重分层适应来适应局部和全局漂移，包括重新划分数据以处理全局漂移，以及检测和异步适应局部漂移。此外，DHDA结合增量更新和定期全面重训练来减少冗余计算。&lt;h4&gt;主要发现&lt;/h4&gt;通过评估八个软件系统和与现有方法的比较，DHDA实现了显著更好的准确率，并能有效适应高达2倍改进的概念漂移，同时具有合理的开销，并能改善不同局部模型处理概念漂移的能力。&lt;h4&gt;结论&lt;/h4&gt;DHDA框架能够有效适应动态环境中的概念漂移，提高配置性能学习的准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern configurable software systems need to learn models that correlateconfiguration and performance. However, when the system operates in dynamicenvironments, the workload variations, hardware changes, and system updateswill inevitably introduce concept drifts at different levels - global drifts,which reshape the performance landscape of the entire configuration space; andlocal drifts, which only affect certain sub-regions of that space. As such,existing offline and transfer learning approaches can struggle to adapt tothese implicit and unpredictable changes in real-time, rendering configurationperformance learning challenging. To address this, we propose DHDA, an onlineconfiguration performance learning framework designed to capture and adapt tothese drifts at different levels. The key idea is that DHDA adapts to both thelocal and global drifts using dually hierarchical adaptation: at the upperlevel, we redivide the data into different divisions, within each of which thelocal model is retrained, to handle global drifts only when necessary. At thelower level, the local models of the divisions can detect local drifts andadapt themselves asynchronously. To balance responsiveness and efficiency, DHDAcombines incremental updates with periodic full retraining to minimizeredundant computation when no drifts are detected. Through evaluating eightsoftware systems and against state-of-the-art approaches, we show that DHDAachieves considerably better accuracy and can effectively adapt to drifts withup to 2x improvements, while incurring reasonable overhead and is able toimprove different local models in handling concept drift.</description>
      <author>example@mail.com (Zezhen Xiang, Jingzhi Gong, Tao Chen)</author>
      <guid isPermaLink="false">2507.08730v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos</title>
      <link>http://arxiv.org/abs/2507.07393v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 2 figures,&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为KeyRe-ID的关键点引导的视频人物重识别框架，通过全局和局部分支利用人体关键点进行增强时空表示学习。&lt;h4&gt;背景&lt;/h4&gt;目前人物重识别技术在时空表示学习方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提高人物重识别的准确性和性能。&lt;h4&gt;方法&lt;/h4&gt;全局分支通过基于Transformer的时间聚合捕捉整体身份语义，局部分支根据关键点动态分割身体区域以生成细粒度、部分感知的特征。&lt;h4&gt;主要发现&lt;/h4&gt;在MARS和iLIDS-VID基准测试中取得了最先进的性能，MARS上达到91.73%的mAP和97.32%的Rank-1准确率，iLIDS-VID上达到96.00%的Rank-1和100.0%的Rank-5准确率。&lt;h4&gt;结论&lt;/h4&gt;KeyRe-ID框架在人物重识别任务中具有显著性能提升，代码将在论文发表后公开在GitHub上。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了KeyRe-ID，一种基于关键点的视频人物重识别框架，包含全局和局部分支，利用人体关键点进行增强的时空表示学习。全局分支通过基于Transformer的时间聚合捕捉整体身份语义，而局部分支根据关键点动态分割身体区域以生成细粒度、部分感知的特征。在MARS和iLIDS-VID基准测试中，该框架实现了最先进的性能，MARS上取得了91.73%的mAP和97.32%的Rank-1准确率，iLIDS-VID上取得了96.00%的Rank-1和100.0%的Rank-5准确率。该工作的代码将在论文发表后公开在GitHub上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose \textbf{KeyRe-ID}, a keypoint-guided video-based personre-identification framework consisting of global and local branches thatleverage human keypoints for enhanced spatiotemporal representation learning.The global branch captures holistic identity semantics throughTransformer-based temporal aggregation, while the local branch dynamicallysegments body regions based on keypoints to generate fine-grained, part-awarefeatures. Extensive experiments on MARS and iLIDS-VID benchmarks demonstratestate-of-the-art performance, achieving 91.73\% mAP and 97.32\% Rank-1 accuracyon MARS, and 96.00\% Rank-1 and 100.0\% Rank-5 accuracy on iLIDS-VID. The codefor this work will be publicly available on GitHub upon publication.</description>
      <author>example@mail.com (Jinseong Kim, Junghoon Song, Gyeongseon Baek, Byeongjoon Noh)</author>
      <guid isPermaLink="false">2507.07393v2</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations</title>
      <link>http://arxiv.org/abs/2507.08262v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CL3R的3D预训练框架，旨在提高机器人操作策略的学习效果。&lt;h4&gt;背景&lt;/h4&gt;现有的机器人感知模块方法将预训练的2D基础模型融入其中，但难以捕捉3D空间信息并适应不同的摄像头视角。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在捕捉3D空间信息和适应不同摄像头视角方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;CL3R通过点云掩码自动编码器学习丰富的3D表示，同时利用对比学习将预训练的2D基础模型中的语义知识高效地迁移。此外，还提出了一个用于机器人任务的3D视觉表示预训练框架，通过统一数据集间的坐标系和随机融合多视角点云来减轻摄像头视角的模糊性，提高泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和现实世界的广泛实验中，该方法显示出其优越性，证明了其在机器人操作策略学习中的有效性。&lt;h4&gt;结论&lt;/h4&gt;CL3R框架在视觉运动策略学习方面对机器人操作具有显著效果，能够从新的视角实现鲁棒的感知。&lt;h4&gt;翻译&lt;/h4&gt;Building a robust perception module is crucial for visuomotor policy learning. While recent methods incorporate pre-trained 2D foundation models into robotic perception modules to leverage their strong semantic understanding, they struggle to capture 3D spatial information and generalize across diverse camera viewpoints. These limitations hinder the policy's effectiveness, especially in fine-grained robotic manipulation scenarios. To address these challenges, we propose CL3R, a novel 3D pre-training framework designed to enhance robotic manipulation policies. Our method integrates both spatial awareness and semantic understanding by employing a point cloud Masked Autoencoder to learn rich 3D representations while leveraging pre-trained 2D foundation models through contrastive learning for efficient semantic knowledge transfer. Additionally, we propose a 3D visual representation pre-training framework for robotic tasks. By unifying coordinate systems across datasets and introducing random fusion of multi-view point clouds, we mitigate camera view ambiguity and improve generalization, enabling robust perception from novel viewpoints at test time. Extensive experiments in both simulation and the real world demonstrate the superiority of our method, highlighting its effectiveness in visuomotor policy learning for robotic manipulation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building a robust perception module is crucial for visuomotor policylearning. While recent methods incorporate pre-trained 2D foundation modelsinto robotic perception modules to leverage their strong semanticunderstanding, they struggle to capture 3D spatial information and generalizeacross diverse camera viewpoints. These limitations hinder the policy'seffectiveness, especially in fine-grained robotic manipulation scenarios. Toaddress these challenges, we propose CL3R, a novel 3D pre-training frameworkdesigned to enhance robotic manipulation policies. Our method integrates bothspatial awareness and semantic understanding by employing a point cloud MaskedAutoencoder to learn rich 3D representations while leveraging pre-trained 2Dfoundation models through contrastive learning for efficient semantic knowledgetransfer. Additionally, we propose a 3D visual representation pre-trainingframework for robotic tasks. By unifying coordinate systems across datasets andintroducing random fusion of multi-view point clouds, we mitigate camera viewambiguity and improve generalization, enabling robust perception from novelviewpoints at test time. Extensive experiments in both simulation and the realworld demonstrate the superiority of our method, highlighting its effectivenessin visuomotor policy learning for robotic manipulation.</description>
      <author>example@mail.com (Wenbo Cui, Chengyang Zhao, Yuhui Chen, Haoran Li, Zhizheng Zhang, Dongbin Zhao, He Wang)</author>
      <guid isPermaLink="false">2507.08262v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Learning-Based Multimodal Prediction on Prosocial Behavior Intentions</title>
      <link>http://arxiv.org/abs/2507.08238v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 4 figures, published at ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于自监督学习的移动场景中亲社会行为意图预测方法，通过利用现有生理和行为数据集的多模态数据，解决了数据稀缺问题，提高了亲社会行为预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习和多模态传感技术的发展，人类状态检测和行为预测取得了显著进展。然而，在移动场景中预测亲社会行为意图，如在路上帮助他人，是一个未被充分研究的领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来克服预测亲社会行为意图的挑战，特别是在数据稀缺的情况下。&lt;h4&gt;方法&lt;/h4&gt;通过使用自监督学习，在多样化的任务上预训练模型，并使用较小规模的、人工标注的亲社会行为数据集进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;该方法显著提高了模型在亲社会行为预测方面的性能，为解决数据稀缺问题提供了一个更有效的基准。&lt;h4&gt;结论&lt;/h4&gt;该方法为提高智能车辆系统和人机交互提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着机器学习和多模态传感技术的兴起，人类状态检测和行为预测取得了显著进展。然而，在移动场景中预测亲社会行为意图，如在路上帮助他人，是一个未被充分研究的领域。当前研究面临的主要限制是没有可用于亲社会行为的庞大、标注数据集，小型数据集使得有效训练深度学习模型变得困难。为了克服这一限制，我们提出了一种利用现有生理和行为数据集的多模态数据的自监督学习方法。通过在多样化任务上预训练我们的模型，并使用较小规模的、人工标注的亲社会行为数据集进行微调，我们显著提高了其性能。这种方法解决了数据稀缺问题，为亲社会行为预测提供了一个更有效的基准，并为改善智能车辆系统和人机交互提供了有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human state detection and behavior prediction have seen significantadvancements with the rise of machine learning and multimodal sensingtechnologies. However, predicting prosocial behavior intentions in mobilityscenarios, such as helping others on the road, is an underexplored area.Current research faces a major limitation. There are no large, labeled datasetsavailable for prosocial behavior, and small-scale datasets make it difficult totrain deep-learning models effectively. To overcome this, we propose aself-supervised learning approach that harnesses multi-modal data from existingphysiological and behavioral datasets. By pre-training our model on diversetasks and fine-tuning it with a smaller, manually labeled prosocial behaviordataset, we significantly enhance its performance. This method addresses thedata scarcity issue, providing a more effective benchmark for prosocialbehavior prediction, and offering valuable insights for improving intelligentvehicle systems and human-machine interaction.</description>
      <author>example@mail.com (Abinay Reddy Naini, Zhaobo K. Zheng, Teruhisa Misu, Kumar Akash)</author>
      <guid isPermaLink="false">2507.08238v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Unreal is all you need: Multimodal ISAC Data Simulation with Only One Engine</title>
      <link>http://arxiv.org/abs/2507.08716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Great-X的单引擎多模态数据孪生平台，用于ISAC研究，并构建了一个开源、大规模、低空无人机多模态通感数据集Great-MSD，同时提出了一种基于CSI的无人机3D定位算法。&lt;h4&gt;背景&lt;/h4&gt;LLM和基础模型中的尺度定律取得了成功。&lt;h4&gt;目的&lt;/h4&gt;探索尺度定律在ISAC研究中的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出Great-X平台，该平台重构了Sionna在Unreal Engine中的光线追踪计算，并与自动驾驶工具深度融合，实现多模态数据的同步模拟，包括CSI、RGB、雷达和激光雷达。基于此平台，构建了Great-MSD数据集，并提出了基于CSI的无人机3D定位算法。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法在跨不同CSI模拟引擎中展示了可行性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;Great-X平台和基于CSI的无人机3D定位算法在多模态数据模拟和无人机定位方面具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Scaling laws have achieved success in LLM and foundation models. To explore their potential in ISAC research, we propose Great-X. This single-engine multimodal data twin platform reconstructs the ray-tracing computation of Sionna within Unreal Engine and is deeply integrated with autonomous driving tools. This enables efficient and synchronized simulation of multimodal data, including CSI, RGB, Radar, and LiDAR. Based on this platform, we construct an open-source, large-scale, low-altitude UAV multimodal synaesthesia dataset named Great-MSD, and propose a baseline CSI-based UAV 3D localization algorithm, demonstrating its feasibility and generalizability across different CSI simulation engines. The related code and dataset are publicly available at: https://github.com/hkw-xg/Great-MCD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scaling laws have achieved success in LLM and foundation models. To exploretheir potential in ISAC research, we propose Great-X. This single-enginemultimodal data twin platform reconstructs the ray-tracing computation ofSionna within Unreal Engine and is deeply integrated with autonomous drivingtools. This enables efficient and synchronized simulation of multimodal data,including CSI, RGB, Radar, and LiDAR. Based on this platform, we construct anopen-source, large-scale, low-altitude UAV multimodal synaesthesia datasetnamed Great-MSD, and propose a baseline CSI-based UAV 3D localizationalgorithm, demonstrating its feasibility and generalizability across differentCSI simulation engines. The related code and dataset are publicly available at:https://github.com/hkw-xg/Great-MCD.</description>
      <author>example@mail.com (Kongwu Huang, Shiyi Mu, Jun Jiang, Yuan Gao, Shugong Xu)</author>
      <guid isPermaLink="false">2507.08716v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Dual Dimensions Geometric Representation Learning Based Document Dewarping</title>
      <link>http://arxiv.org/abs/2507.08492v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对文档图像去畸变的模型D2Dewarp，通过感知文档水平-垂直线的双重维度，结合水平和垂直粒度特征，实现了更有效的去畸变效果。&lt;h4&gt;背景&lt;/h4&gt;文档图像去畸变在深度学习时代仍然是一个挑战，现有方法主要关注单一水平维度。&lt;h4&gt;目的&lt;/h4&gt;提高文档图像去畸变的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种细粒度变形感知模型D2Dewarp，关注文档水平-垂直线的双重维度。2. 设计了一个基于X和Y坐标的有效融合模块，以促进两个维度之间的交互和约束。3. 提出了一种自动细粒度标注方法，利用公共文档纹理图像和自动渲染引擎构建新的大规模扭曲训练数据集。&lt;h4&gt;主要发现&lt;/h4&gt;在公共中文和英文基准测试中，D2Dewarp方法在定量和定性结果上均优于现有最佳方法。&lt;h4&gt;结论&lt;/h4&gt;D2Dewarp模型通过感知文档图像的双重维度，实现了更好的去畸变效果，并提供了新的训练数据集。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a fine-grained deformation perception model called D2Dewarp for document image dewarping, which focuses on the dual dimensions of document horizontal-vertical lines to achieve more effective dewarping. The model combines horizontal and vertical granularity features and designs an effective fusion module based on X and Y coordinates. Additionally, an automatic fine-grained annotation method using public document texture images and an automatic rendering engine is proposed to build a new large-scale distortion training dataset. On public Chinese and English benchmarks, the method achieves better rectification results compared with the state-of-the-art methods. The dataset will be publicly available at https://github.com/xiaomore/DocDewarpHV.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Document image dewarping remains a challenging task in the deep learning era.While existing methods have improved by leveraging text line awareness, theytypically focus only on a single horizontal dimension. In this paper, wepropose a fine-grained deformation perception model that focuses on DualDimensions of document horizontal-vertical-lines to improve document Dewarpingcalled D2Dewarp. It can perceive distortion trends in different directionsacross document details. To combine the horizontal and vertical granularityfeatures, an effective fusion module based on X and Y coordinate is designed tofacilitate interaction and constraint between the two dimensions for featurecomplementarity. Due to the lack of annotated line features in current publicdewarping datasets, we also propose an automatic fine-grained annotation methodusing public document texture images and an automatic rendering engine to builda new large-scale distortion training dataset. The code and dataset will bepublicly released. On public Chinese and English benchmarks, both quantitativeand qualitative results show that our method achieves better rectificationresults compared with the state-of-the-art methods. The dataset will bepublicly available at https://github.com/xiaomore/DocDewarpHV</description>
      <author>example@mail.com (Heng Li, Qingcai Chen, Xiangping Wu)</author>
      <guid isPermaLink="false">2507.08492v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>MM-Gesture: Towards Precise Micro-Gesture Recognition through Multimodal Fusion</title>
      <link>http://arxiv.org/abs/2507.08344v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HFUT-VUT团队开发的MM-Gesture解决方案，该方案在IJCAI 2025的MiGA挑战赛微动作分类赛道中排名第一，性能优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;微动作（MGs）的识别是一个挑战，因为它们通常是微妙的和短时持续的。&lt;h4&gt;目的&lt;/h4&gt;提出MM-Gesture，一个专门用于识别微动作的多模态融合框架。&lt;h4&gt;方法&lt;/h4&gt;MM-Gesture集成来自关节、肢体、RGB视频、泰勒级数视频、光流视频和深度视频模态的互补线索。使用PoseConv3D和Video Swin Transformer架构，并采用新颖的模态加权集成策略，通过在更大的MA-52数据集上预训练进行迁移学习，进一步提升RGB模态的性能。&lt;h4&gt;主要发现&lt;/h4&gt;在iMiGUE基准上的广泛实验，包括不同模态的消融研究，验证了所提出方法的有效性，达到73.213%的top-1准确率。&lt;h4&gt;结论&lt;/h4&gt;MM-Gesture在微动作分类任务中表现出色，是一种有效的识别方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在本文中，我们介绍了由我们的团队HFUT-VUT开发的MM-Gesture解决方案，该方案在IJCAI 2025的MiGA挑战赛的微动作分类赛道上排名第一，与现有方法相比取得了优越的性能。MM-Gesture是一个专为识别微妙和短时微动作（MGs）而设计的多模态融合框架，集成了来自关节、肢体、RGB视频、泰勒级数视频、光流视频和深度视频模态的互补线索。利用PoseConv3D和Video Swin Transformer架构以及新颖的模态加权集成策略，我们的方法通过在更大的MA-52数据集上预训练进行迁移学习，进一步提升了RGB模态的性能。在iMiGUE基准上的广泛实验，包括不同模态的消融研究，验证了我们提出方法的有效性，达到了73.213%的top-1准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present MM-Gesture, the solution developed by our teamHFUT-VUT, which ranked 1st in the micro-gesture classification track of the 3rdMiGA Challenge at IJCAI 2025, achieving superior performance compared toprevious state-of-the-art methods. MM-Gesture is a multimodal fusion frameworkdesigned specifically for recognizing subtle and short-duration micro-gestures(MGs), integrating complementary cues from joint, limb, RGB video,Taylor-series video, optical-flow video, and depth video modalities. UtilizingPoseConv3D and Video Swin Transformer architectures with a novelmodality-weighted ensemble strategy, our method further enhances RGB modalityperformance through transfer learning pre-trained on the larger MA-52 dataset.Extensive experiments on the iMiGUE benchmark, including ablation studiesacross different modalities, validate the effectiveness of our proposedapproach, achieving a top-1 accuracy of 73.213%.</description>
      <author>example@mail.com (Jihao Gu, Fei Wang, Kun Li, Yanyan Wei, Zhiliang Wu, Dan Guo)</author>
      <guid isPermaLink="false">2507.08344v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>OnlineBEV: Recurrent Temporal Fusion in Bird's Eye View Representations for Multi-Camera 3D Perception</title>
      <link>http://arxiv.org/abs/2507.08644v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Transactions on Intelligent Transportation Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为OnlineBEV的在线3D感知方法，通过结合时间序列的BEV特征，提高了基于多视角相机的3D感知性能。&lt;h4&gt;背景&lt;/h4&gt;现有的3D感知方法通过鸟瞰图（BEV）特征实现，结合多个相机的BEV特征可以提升性能，但时间聚合的性能提升有限，因为物体运动导致BEV特征随时间动态变化。&lt;h4&gt;目的&lt;/h4&gt;提出OnlineBEV方法，通过时间序列结合BEV特征，在保证内存使用最少的同时，提高3D感知性能。&lt;h4&gt;方法&lt;/h4&gt;OnlineBEV使用循环结构结合BEV特征，并通过运动引导的BEV融合网络（MBFNet）实现时间特征对齐。MBFNet提取连续BEV帧的运动特征，并使用这些特征动态对齐历史和当前BEV特征。为了显式地强制时间特征对齐，使用时间一致性学习损失来捕捉历史和目标BEV特征之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes基准测试上，OnlineBEV在仅使用相机的3D物体检测任务中取得了最先进的性能，达到了63.9%的NDS。&lt;h4&gt;结论&lt;/h4&gt;OnlineBEV方法在3D感知任务中显著优于现有最佳方法SOLOFusion，实现了更高的性能和更好的时间特征对齐。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view camera-based 3D perception can be conducted using bird's eye view(BEV) features obtained through perspective view-to-BEV transformations.Several studies have shown that the performance of these 3D perception methodscan be further enhanced by combining sequential BEV features obtained frommultiple camera frames. However, even after compensating for the ego-motion ofan autonomous agent, the performance gain from temporal aggregation is limitedwhen combining a large number of image frames. This limitation arises due todynamic changes in BEV features over time caused by object motion. In thispaper, we introduce a novel temporal 3D perception method called OnlineBEV,which combines BEV features over time using a recurrent structure. Thisstructure increases the effective number of combined features with minimalmemory usage. However, it is critical to spatially align the features over timeto maintain strong performance. OnlineBEV employs the Motion-guided BEV FusionNetwork (MBFNet) to achieve temporal feature alignment. MBFNet extracts motionfeatures from consecutive BEV frames and dynamically aligns historical BEVfeatures with current ones using these motion features. To enforce temporalfeature alignment explicitly, we use Temporal Consistency Learning Loss, whichcaptures discrepancies between historical and target BEV features. Experimentsconducted on the nuScenes benchmark demonstrate that OnlineBEV achievessignificant performance gains over the current best method, SOLOFusion.OnlineBEV achieves 63.9% NDS on the nuScenes test set, recordingstate-of-the-art performance in the camera-only 3D object detection task.</description>
      <author>example@mail.com (Junho Koh, Youngwoo Lee, Jungho Kim, Dongyoung Lee, Jun Won Choi)</author>
      <guid isPermaLink="false">2507.08644v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>F3-Net: Foundation Model for Full Abnormality Segmentation of Medical Images with Flexible Input Modality Requirement</title>
      <link>http://arxiv.org/abs/2507.08460v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;F3-Net是一种基础模型，旨在解决临床医学图像分割中的挑战，如依赖完整的多模态输入、泛化能力有限和任务特异性狭窄等问题。&lt;h4&gt;背景&lt;/h4&gt;F3-Net旨在克服临床医学图像分割领域中的持续挑战。&lt;h4&gt;目的&lt;/h4&gt;F3-Net旨在提高医学图像分割的性能和实用性。&lt;h4&gt;方法&lt;/h4&gt;F3-Net通过灵活的合成模态训练，即使在缺失MRI序列的情况下也能保持稳健的性能。它采用零图像策略替代缺失的模态，而不依赖显式的合成网络。其统一架构支持多病理分割，无需重新训练即可实现，并优于通常需要特定疾病微调的基于CNN和transformer的模型。&lt;h4&gt;主要发现&lt;/h4&gt;F3-Net在BraTS 2021、BraTS 2024和ISLES 2022等不同数据集上进行了评估，显示出对领域变化和临床异质性的强大适应性。在整体病理数据集上，F3-Net实现了平均Dice相似系数（DSCs）为0.94、0.82、0.94和0.79。&lt;h4&gt;结论&lt;/h4&gt;F3-Net是一种多才多艺、可扩展的解决方案，它弥合了深度学习研究与实践临床部署之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; F3-Net is a foundation model designed to overcome persistent challenges inclinical medical image segmentation, including reliance on complete multimodalinputs, limited generalizability, and narrow task specificity. Through flexiblesynthetic modality training, F3-Net maintains robust performance even in thepresence of missing MRI sequences, leveraging a zero-image strategy tosubstitute absent modalities without relying on explicit synthesis networks,thereby enhancing real-world applicability. Its unified architecture supportsmulti-pathology segmentation across glioma, metastasis, stroke, and whitematter lesions without retraining, outperforming CNN-based andtransformer-based models that typically require disease-specific fine-tuning.Evaluated on diverse datasets such as BraTS 2021, BraTS 2024, and ISLES 2022,F3-Net demonstrates strong resilience to domain shifts and clinicalheterogeneity. On the whole pathology dataset, F3-Net achieves average DiceSimilarity Coefficients (DSCs) of 0.94 for BraTS-GLI 2024, 0.82 for BraTS-MET2024, 0.94 for BraTS 2021, and 0.79 for ISLES 2022. This positions it as aversatile, scalable solution bridging the gap between deep learning researchand practical clinical deployment.</description>
      <author>example@mail.com (Seyedeh Sahar Taheri Otaghsara, Reza Rahmanzadeh)</author>
      <guid isPermaLink="false">2507.08460v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features</title>
      <link>http://arxiv.org/abs/2507.08546v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RadiomicsRetrieval的三维内容检索框架，旨在支持临床决策，该框架结合了手工放射组学描述符和基于深度学习的嵌入，能够更好地利用医学图像中的空间上下文信息。&lt;h4&gt;背景&lt;/h4&gt;目前的医学图像检索方法主要支持二维图像，且需要充分标注的查询，这限制了临床的灵活性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的三维内容检索框架RadiomicsRetrieval。&lt;h4&gt;方法&lt;/h4&gt;该方法利用一个可提示的分割模型（如SAM）来推导肿瘤特定的图像嵌入，并通过对比学习与从同一肿瘤中提取的放射组学特征对齐。这些表示通过解剖位置嵌入（APE）进一步丰富。RadiomicsRetrieval允许基于形状、位置或部分特征集进行灵活查询。&lt;h4&gt;主要发现&lt;/h4&gt;在肺CT和脑MRI公共数据集上的大量实验表明，放射组学特征显著提高了检索的特异性，而APE提供了基于位置搜索所必需的全球解剖上下文。该框架只需要最小用户提示（如单个点），最小化了分割开销，并支持多种临床场景。使用图像嵌入或选定的放射组学属性进行查询的能力突出了其适应性。&lt;h4&gt;结论&lt;/h4&gt;RadiomicsRetrieval能够适应诊断、治疗规划和大规模医学影像库研究，其代码可在https://github.com/nainye/RadiomicsRetrieval上获取。&lt;h4&gt;翻译&lt;/h4&gt;Medical image retrieval is a valuable field for supporting clinical decision-making, yet current methods primarily support 2D images and require fully annotated queries, limiting clinical flexibility. To address this, we propose RadiomicsRetrieval, a 3D content-based retrieval framework bridging handcrafted radiomics descriptors with deep learning-based embeddings at the tumor level. Unlike existing 2D approaches, RadiomicsRetrieval fully exploits volumetric data to leverage richer spatial context in medical images. We employ a promptable segmentation model (e.g., SAM) to derive tumor-specific image embeddings, which are aligned with radiomics features extracted from the same tumor via contrastive learning. These representations are further enriched by anatomical positional embedding (APE). As a result, RadiomicsRetrieval enables flexible querying based on shape, location, or partial feature sets. Extensive experiments on both lung CT and brain MRI public datasets demonstrate that radiomics features significantly enhance retrieval specificity, while APE provides global anatomical context essential for location-based searches. Notably, our framework requires only minimal user prompts (e.g., a single point), minimizing segmentation overhead and supporting diverse clinical scenarios. The capability to query using either image embeddings or selected radiomics attributes highlights its adaptability, potentially benefiting diagnosis, treatment planning, and research on large-scale medical imaging repositories. Our code is available at https://github.com/nainye/RadiomicsRetrieval.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image retrieval is a valuable field for supporting clinicaldecision-making, yet current methods primarily support 2D images and requirefully annotated queries, limiting clinical flexibility. To address this, wepropose RadiomicsRetrieval, a 3D content-based retrieval framework bridginghandcrafted radiomics descriptors with deep learning-based embeddings at thetumor level. Unlike existing 2D approaches, RadiomicsRetrieval fully exploitsvolumetric data to leverage richer spatial context in medical images. We employa promptable segmentation model (e.g., SAM) to derive tumor-specific imageembeddings, which are aligned with radiomics features extracted from the sametumor via contrastive learning. These representations are further enriched byanatomical positional embedding (APE). As a result, RadiomicsRetrieval enablesflexible querying based on shape, location, or partial feature sets. Extensiveexperiments on both lung CT and brain MRI public datasets demonstrate thatradiomics features significantly enhance retrieval specificity, while APEprovides global anatomical context essential for location-based searches.Notably, our framework requires only minimal user prompts (e.g., a singlepoint), minimizing segmentation overhead and supporting diverse clinicalscenarios. The capability to query using either image embeddings or selectedradiomics attributes highlights its adaptability, potentially benefitingdiagnosis, treatment planning, and research on large-scale medical imagingrepositories. Our code is available athttps://github.com/nainye/RadiomicsRetrieval.</description>
      <author>example@mail.com (Inye Na, Nejung Rue, Jiwon Chung, Hyunjin Park)</author>
      <guid isPermaLink="false">2507.08546v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Unified People Tracking with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.08494v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一且完全可微分的多人跟踪模型，该模型通过学习将检测与轨迹关联，而不依赖于预计算的轨迹片段。该模型构建了一个动态时空图，聚合空间、上下文和时间信息，使整个序列中的信息传播无缝。为了提高遮挡处理能力，该图还可以编码特定场景信息。此外，还引入了一个包含25个部分重叠视图、详细场景重建和广泛遮挡的新大型数据集。实验表明，该模型在公共基准和新数据集上实现了最先进的性能，具有适应各种条件的能力。数据集和方法的公开发布将推动多人跟踪研究的发展。&lt;h4&gt;背景&lt;/h4&gt;多人跟踪领域需要一种无需预计算轨迹片段的跟踪模型。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多人跟踪模型，以实现高效的信息关联和轨迹跟踪。&lt;h4&gt;方法&lt;/h4&gt;构建动态时空图，聚合空间、上下文和时间信息，并引入场景特定信息处理遮挡。&lt;h4&gt;主要发现&lt;/h4&gt;模型在公共基准和新数据集上实现了最先进的性能，具有适应不同条件的能力。&lt;h4&gt;结论&lt;/h4&gt;该模型和数据集的公开发布将促进多人跟踪研究的发展。&lt;h4&gt;翻译&lt;/h4&gt;This work presents a unified, fully differentiable model for multi-peopletracking that learns to associate detections into trajectories without relyingon pre-computed tracklets. The model builds a dynamic spatiotemporal graph thataggregates spatial, contextual, and temporal information, enabling seamlessinformation propagation across entire sequences. To improve occlusion handling,the graph can also encode scene-specific information. We also introduce a newlarge-scale dataset with 25 partially overlapping views, detailed scenereconstructions, and extensive occlusions. Experiments show the model achievesstate-of-the-art performance on public benchmarks and the new dataset, withflexibility across diverse conditions. Both the dataset and approach will bepublicly released to advance research in multi-people tracking.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents a unified, fully differentiable model for multi-peopletracking that learns to associate detections into trajectories without relyingon pre-computed tracklets. The model builds a dynamic spatiotemporal graph thataggregates spatial, contextual, and temporal information, enabling seamlessinformation propagation across entire sequences. To improve occlusion handling,the graph can also encode scene-specific information. We also introduce a newlarge-scale dataset with 25 partially overlapping views, detailed scenereconstructions, and extensive occlusions. Experiments show the model achievesstate-of-the-art performance on public benchmarks and the new dataset, withflexibility across diverse conditions. Both the dataset and approach will bepublicly released to advance research in multi-people tracking.</description>
      <author>example@mail.com (Martin Engilberge, Ivan Vrkic, Friedrich Wilke Grosche, Julien Pilet, Engin Turetken, Pascal Fua)</author>
      <guid isPermaLink="false">2507.08494v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration</title>
      <link>http://arxiv.org/abs/2507.08210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了智能体如何在探索世界的同时维持对环境的控制，通过结合内在动机理论和强化学习，分析了内部表征如何协调好奇心和胜任力的平衡。&lt;h4&gt;背景&lt;/h4&gt;从儿童玩耍到科学家进行实验，智能体需要在寻求知识和掌握环境之间找到平衡。&lt;h4&gt;目的&lt;/h4&gt;研究旨在了解如何通过内部表征的演变来协调好奇心（新颖性或信息增益）和胜任力（赋能）之间的权衡。&lt;h4&gt;方法&lt;/h4&gt;比较了两种基于模型的智能体：一种是使用手工制作的州状态抽象（Tabular），另一种是学习内部世界模型（Dreamer）。&lt;h4&gt;主要发现&lt;/h4&gt;Tabular智能体表明好奇心和胜任力以不同的模式引导探索，同时优先考虑两者可以提高探索效率。Dreamer智能体揭示了探索和表征学习之间的双向互动，反映了好奇心和胜任力的发展协同进化。&lt;h4&gt;结论&lt;/h4&gt;研究结果将自适应探索形式化为追求未知和可控之间的平衡，为认知理论和高效强化学习提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;What drives an agent to explore the world while also maintaining control over the environment? From a child at play to scientists in the lab, intelligent agents must balance curiosity (the drive to seek knowledge) with competence (the drive to master and control the environment). Bridging cognitive theories of intrinsic motivation with reinforcement learning, we ask how evolving internal representations mediate the trade-off between curiosity (novelty or information gain) and competence (empowerment). We compare two model-based agents using handcrafted state abstractions (Tabular) or learning an internal world model (Dreamer). The Tabular agent shows curiosity and competence guide exploration in distinct patterns, while prioritizing both improves exploration. The Dreamer agent reveals a two-way interaction between exploration and representation learning, mirroring the developmental co-evolution of curiosity and competence. Our findings formalize adaptive exploration as a balance between pursuing the unknown and the controllable, offering insights for cognitive theories and efficient reinforcement learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; What drives an agent to explore the world while also maintaining control overthe environment? From a child at play to scientists in the lab, intelligentagents must balance curiosity (the drive to seek knowledge) with competence(the drive to master and control the environment). Bridging cognitive theoriesof intrinsic motivation with reinforcement learning, we ask how evolvinginternal representations mediate the trade-off between curiosity (novelty orinformation gain) and competence (empowerment). We compare two model-basedagents using handcrafted state abstractions (Tabular) or learning an internalworld model (Dreamer). The Tabular agent shows curiosity and competence guideexploration in distinct patterns, while prioritizing both improves exploration.The Dreamer agent reveals a two-way interaction between exploration andrepresentation learning, mirroring the developmental co-evolution of curiosityand competence. Our findings formalize adaptive exploration as a balancebetween pursuing the unknown and the controllable, offering insights forcognitive theories and efficient reinforcement learning.</description>
      <author>example@mail.com (Fryderyk Mantiuk, Hanqi Zhou, Charley M. Wu)</author>
      <guid isPermaLink="false">2507.08210v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning and Mixup for Fine-Grained Few-Shot Fungi Classification</title>
      <link>http://arxiv.org/abs/2507.08248v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了在FungiCLEF2025竞赛中使用的方法，该方法专注于使用FungiTastic Few-Shot数据集进行少样本细粒度视觉分类。&lt;h4&gt;背景&lt;/h4&gt;由于真菌物种之间有细微的变异和高度的物种内变异，准确识别真菌物种在计算机视觉中是一个独特的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究目的是在FungiCLEF2025竞赛中提出有效的真菌物种识别方法。&lt;h4&gt;方法&lt;/h4&gt;研究团队（DS@GT）试验了多种视觉Transformer模型，数据增强，加权采样，以及文本信息的融合。还探索了使用结构化提示进行零样本分类的生成性AI模型，但发现它们相对于基于视觉的模型性能显著不足。&lt;h4&gt;主要发现&lt;/h4&gt;最终模型优于竞赛基线，突出了领域特定预训练和平衡采样策略的有效性。在完成比赛后的评估中，该方法在私有测试集上排名第35/74，这表明可以在元数据选择和领域自适应的多模态学习方面进行更多工作。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，通过结合多种技术和策略，可以在真菌物种识别方面取得显著成果。&lt;h4&gt;翻译&lt;/h4&gt;This abstract summarizes a paper that presents an approach for accurately identifying fungi species in computer vision, focusing on few-shot fine-grained visual categorization using the FungiTastic Few-Shot dataset. The paper discusses the challenges in accurately identifying fungi species, the goals of the research, the methods used, key findings such as the effectiveness of domain-specific pretraining and balanced sampling strategies, and the conclusion that combining various techniques and strategies can lead to significant progress in this field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate identification of fungi species presents a unique challenge incomputer vision due to fine-grained inter-species variation and highintra-species variation. This paper presents our approach for the FungiCLEF2025 competition, which focuses on few-shot fine-grained visual categorization(FGVC) using the FungiTastic Few-Shot dataset. Our team (DS@GT) experimentedwith multiple vision transformer models, data augmentation, weighted sampling,and incorporating textual information. We also explored generative AI modelsfor zero-shot classification using structured prompting but found them tosignificantly underperform relative to vision-based models. Our final modeloutperformed both competition baselines and highlighted the effectiveness ofdomain specific pretraining and balanced sampling strategies. Our approachranked 35/74 on the private test set in post-completion evaluation, thissuggests additional work can be done on metadata selection and domain-adaptedmulti-modal learning. Our code is available athttps://github.com/dsgt-arc/fungiclef-2025.</description>
      <author>example@mail.com (Jason Kahei Tam, Murilo Gustineli, Anthony Miyaguchi)</author>
      <guid isPermaLink="false">2507.08248v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>InstaScene: Towards Complete 3D Instance Decomposition and Reconstruction from Cluttered Scenes</title>
      <link>http://arxiv.org/abs/2507.08416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025. Project page:  https://zju3dv.github.io/instascene/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了InstaScene，这是一种新的整体3D感知复杂场景的方法，旨在在不牺牲完整重建的前提下分解任意实例，并通过实验证明了其优越的分解精度和几何忠实度。&lt;h4&gt;背景&lt;/h4&gt;尽管存在高级重建技术，但赋予机器人类似于人类在杂乱环境中识别和心智补全遮挡物体的认知能力仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究的主要目标是实现复杂场景的整体3D感知，具体目标是对任意实例进行分解，同时确保完整的重建。&lt;h4&gt;方法&lt;/h4&gt;为了实现精确的分解，文章提出了一种新的空间对比学习方法，通过追踪每个实例的视图间的光栅化过程，显著增强了杂乱场景中的语义监督。为了克服有限观察带来的不完整性，引入了原地生成技术，利用有价值的观察和几何线索，有效地引导3D生成模型重建与真实世界无缝对齐的完整实例。&lt;h4&gt;主要发现&lt;/h4&gt;在复杂真实世界和合成场景的分解和物体补全实验中，该方法实现了卓越的分解精度，同时产生了几何忠实和视觉完整的物体。&lt;h4&gt;结论&lt;/h4&gt;InstaScene方法在复杂场景的整体3D感知方面取得了显著的成果，为机器人提供了类似于人类的认知能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans can naturally identify and mentally complete occluded objects incluttered environments. However, imparting similar cognitive ability torobotics remains challenging even with advanced reconstruction techniques,which models scenes as undifferentiated wholes and fails to recognize completeobject from partial observations. In this paper, we propose InstaScene, a newparadigm towards holistic 3D perception of complex scenes with a primary goal:decomposing arbitrary instances while ensuring complete reconstruction. Toachieve precise decomposition, we develop a novel spatial contrastive learningby tracing rasterization of each instance across views, significantly enhancingsemantic supervision in cluttered scenes. To overcome incompleteness fromlimited observations, we introduce in-situ generation that harnesses valuableobservations and geometric cues, effectively guiding 3D generative models toreconstruct complete instances that seamlessly align with the real world.Experiments on scene decomposition and object completion across complexreal-world and synthetic scenes demonstrate that our method achieves superiordecomposition accuracy while producing geometrically faithful and visuallyintact objects.</description>
      <author>example@mail.com (Zesong Yang, Bangbang Yang, Wenqi Dong, Chenxuan Cao, Liyuan Cui, Yuewen Ma, Zhaopeng Cui, Hujun Bao)</author>
      <guid isPermaLink="false">2507.08416v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>EvA: Evolutionary Attacks on Graphs</title>
      <link>http://arxiv.org/abs/2507.08212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于进化算法的攻击方法，用于提高图神经网络（GNNs）攻击的准确性，并减少对鲁棒性证书的有效性。&lt;h4&gt;背景&lt;/h4&gt;图结构的小扰动会导致图神经网络（GNNs）的准确性显著下降，现有攻击大多利用梯度信息来扰动边，将攻击的优化问题从离散空间转化为连续空间，导致解决方案远离最优解，并限制了攻击对非可微目标的适应性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的攻击方法，直接解决离散优化问题，提高攻击的准确性，并增强攻击对非可微目标的适应性。&lt;h4&gt;方法&lt;/h4&gt;引入基于进化算法的攻击方法（EvA），该方法与任何黑盒模型和目标兼容，无需可微代理损失，设计两种新的攻击来降低鲁棒性证书的有效性和破坏一致性集。&lt;h4&gt;主要发现&lt;/h4&gt;EvA攻击在攻击预算的内存复杂度是线性的，与最佳先前攻击相比，平均准确度降低了约11%，揭示了设计攻击的巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;EvA攻击方法能够有效提高GNNs攻击的准确性，为设计攻击提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Even a slight perturbation in the graph structure can cause a significant drop in the accuracy of graph neural networks (GNNs). Most existing attacks leverage gradient information to perturb edges. This relaxes the attack's optimization problem from a discrete to a continuous space, resulting in solutions far from optimal. It also restricts the adaptability of the attack to non-differentiable objectives. Instead, we introduce a few simple yet effective enhancements of an evolutionary-based algorithm to solve the discrete optimization problem directly. Our Evolutionary Attack (EvA) works with any black-box model and objective, eliminating the need for a differentiable proxy loss. This allows us to design two novel attacks that reduce the effectiveness of robustness certificates and break conformal sets. The memory complexity of our attack is linear in the attack budget. Among our experiments, EvA shows ~11% additional drop in accuracy on average compared to the best previous attack, revealing significant untapped potential in designing attacks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Even a slight perturbation in the graph structure can cause a significantdrop in the accuracy of graph neural networks (GNNs). Most existing attacksleverage gradient information to perturb edges. This relaxes the attack'soptimization problem from a discrete to a continuous space, resulting insolutions far from optimal. It also restricts the adaptability of the attack tonon-differentiable objectives. Instead, we introduce a few simple yet effectiveenhancements of an evolutionary-based algorithm to solve the discreteoptimization problem directly. Our Evolutionary Attack (EvA) works with anyblack-box model and objective, eliminating the need for a differentiable proxyloss. This allows us to design two novel attacks that reduce the effectivenessof robustness certificates and break conformal sets. The memory complexity ofour attack is linear in the attack budget. Among our experiments, EvA shows$\sim$11\% additional drop in accuracy on average compared to the best previousattack, revealing significant untapped potential in designing attacks.</description>
      <author>example@mail.com (Mohammad Sadegh Akhondzadeh, Soroush H. Zargarbashi, Jimin Cao, Aleksandar Bojchevski)</author>
      <guid isPermaLink="false">2507.08212v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>A document is worth a structured record: Principled inductive bias design for document recognition</title>
      <link>http://arxiv.org/abs/2507.08458v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的视角，将文档识别视为从文档到记录的转录任务，并设计了一种为机器学习端到端文档识别系统设计结构特定归纳偏置的方法。&lt;h4&gt;背景&lt;/h4&gt;现有的文档识别方法将文档识别视为纯粹的计算机视觉问题，忽略了不同文档类型的特定结构属性，导致它们依赖于次优的启发式后处理，使得许多不常见或更复杂的文档类型难以被现代文档识别技术处理。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的文档识别方法，能够处理更多种类的文档，特别是那些结构更复杂或不常见的文档类型。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种基于转录的自然分组方法，并设计了一种结构特定的归纳偏置方法，用于机器学习端到端文档识别系统，同时采用了一种适用于不同结构的基变压器架构。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验证明了所提出的方法在处理单声部乐谱、形状草图和简化工程图纸等具有复杂结构的记录时的有效性，并成功训练了第一个能够将工程图纸转录为其固有互联信息的端到端模型。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对于设计对标准OCR、OMR等不如标准文档类型理解深入的文档识别系统具有重要意义，并为未来文档基础模型的设计提供了指导。&lt;h4&gt;翻译&lt;/h4&gt;摘要：许多文档类型使用内在的、由惯例驱动的结构来编码精确和结构化的信息，如工程图纸所遵循的惯例。然而，最先进的方法将文档识别视为一个纯计算机视觉问题，忽略了这些底层文档类型特定的结构属性，使得它们依赖于次优的启发式后处理，使得许多较少见或更复杂的文档类型无法被现代文档识别。我们提出了一种新的视角，将文档识别视为从文档到记录的转录任务。这意味着根据其转录中固有的内在结构对文档进行自然分组，相关文档类型可以（并且可以学习）相似地处理。我们提出了一种方法来设计底层机器学习端到端文档识别系统的结构特定归纳偏置，以及相应的基变压器架构，我们成功地将其适应于不同的结构。我们在从单声部乐谱、形状草图和简化工程图纸等具有复杂记录结构的广泛实验中证明了所发现的归纳偏置的有效性。通过集成对无限制图结构的归纳偏置，我们训练了第一个成功将工程图纸转录为其固有互联信息的端到端模型。我们的方法对于设计对标准OCR、OMR等不如标准文档类型理解深入的文档识别系统具有重要意义，并为未来文档基础模型的设计提供了指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many document types use intrinsic, convention-driven structures that serve toencode precise and structured information, such as the conventions governingengineering drawings. However, state-of-the-art approaches treat documentrecognition as a mere computer vision problem, neglecting these underlyingdocument-type-specific structural properties, making them dependent onsub-optimal heuristic post-processing and rendering many less frequent or morecomplicated document types inaccessible to modern document recognition. Wesuggest a novel perspective that frames document recognition as a transcriptiontask from a document to a record. This implies a natural grouping of documentsbased on the intrinsic structure inherent in their transcription, where relateddocument types can be treated (and learned) similarly. We propose a method todesign structure-specific inductive biases for the underlying machine-learnedend-to-end document recognition systems, and a respective base transformerarchitecture that we successfully adapt to different structures. We demonstratethe effectiveness of the so-found inductive biases in extensive experimentswith progressively complex record structures from monophonic sheet music, shapedrawings, and simplified engineering drawings. By integrating an inductive biasfor unrestricted graph structures, we train the first-ever successfulend-to-end model to transcribe engineering drawings to their inherentlyinterlinked information. Our approach is relevant to inform the design ofdocument recognition systems for document types that are less well understoodthan standard OCR, OMR, etc., and serves as a guide to unify the design offuture document foundation models.</description>
      <author>example@mail.com (Benjamin Meyer, Lukas Tuggener, Sascha Hänzi, Daniel Schmid, Erdal Ayfer, Benjamin F. Grewe, Ahmed Abdulkadir, Thilo Stadelmann)</author>
      <guid isPermaLink="false">2507.08458v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models</title>
      <link>http://arxiv.org/abs/2507.08128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code, Datasets and Models: https://research.nvidia.com/labs/adlr/AF3/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Audio Flamingo 3（AF3），这是一个先进的开放式大型音频语言模型，它提高了语音、声音和音乐方面的推理和理解能力。&lt;h4&gt;背景&lt;/h4&gt;AF3是一个音频语言模型，旨在通过整合语音、声音和音乐三个模态的数据，提升跨模态的推理和理解能力。&lt;h4&gt;目的&lt;/h4&gt;AF3的目的是提供一个能够进行连贯思维、多轮音频对话、长音频理解和推理，并实现语音到语音交互的模型。&lt;h4&gt;方法&lt;/h4&gt;为了实现这些功能，本文提出了几个大规模训练数据集，包括AudioSkills-XL、LongAudio-XL、AF-Think和AF-Chat，并使用一种创新的五阶段课程培训策略来训练AF3。&lt;h4&gt;主要发现&lt;/h4&gt;AF3仅使用开源音频数据进行训练，在超过20个音频理解和推理基准测试中取得了新的先进水平，超越了使用更大数据集训练的开源和闭源模型。&lt;h4&gt;结论&lt;/h4&gt;AF3是一个具有多项创新功能的音频语言模型，通过开放式数据集和创新的训练策略，实现了在音频理解和推理领域的突破。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Audio Flamingo 3 (AF3), a fully open state-of-the-art (SOTA) largeaudio-language model that advances reasoning and understanding across speech,sound, and music. AF3 introduces: (i) AF-Whisper, a unified audio encodertrained using a novel strategy for joint representation learning across all 3modalities of speech, sound, and music; (ii) flexible, on-demand thinking,allowing the model to do chain-of-thought-type reasoning before answering;(iii) multi-turn, multi-audio chat; (iv) long audio understanding and reasoning(including speech) up to 10 minutes; and (v) voice-to-voice interaction. Toenable these capabilities, we propose several large-scale training datasetscurated using novel strategies, including AudioSkills-XL, LongAudio-XL,AF-Think, and AF-Chat, and train AF3 with a novel five-stage curriculum-basedtraining strategy. Trained on only open-source audio data, AF3 achieves newSOTA results on over 20+ (long) audio understanding and reasoning benchmarks,surpassing both open-weight and closed-source models trained on much largerdatasets.</description>
      <author>example@mail.com (Arushi Goel, Sreyan Ghosh, Jaehyeon Kim, Sonal Kumar, Zhifeng Kong, Sang-gil Lee, Chao-Han Huck Yang, Ramani Duraiswami, Dinesh Manocha, Rafael Valle, Bryan Catanzaro)</author>
      <guid isPermaLink="false">2507.08128v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>An Embedded Real-time Object Alert System for Visually Impaired: A Monocular Depth Estimation based Approach through Computer Vision</title>
      <link>http://arxiv.org/abs/2507.08165v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新型警报系统，旨在帮助视障人士在繁忙的街道上通勤时避免碰撞。&lt;h4&gt;背景&lt;/h4&gt;在孟加拉国的城市中，视障人士在日常生活中通勤面临诸多挑战，因为每条路径上都有大量的障碍物。&lt;h4&gt;目的&lt;/h4&gt;开发一个系统，提前警告视障人士附近存在的物体，以减少交通事故。&lt;h4&gt;方法&lt;/h4&gt;利用迁移学习训练深度估计和物体检测模型，并结合这两种模型引入新的系统。通过量化技术优化模型，使其轻量化和高效，便于在嵌入式系统上部署。&lt;h4&gt;主要发现&lt;/h4&gt;该系统实现了轻量级的实时深度估计和物体检测模型，mAP50达到了0.801。&lt;h4&gt;结论&lt;/h4&gt;该系统为视障人士在繁忙街道上的安全通勤提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visually impaired people face significant challenges in their day-to-daycommutes in the urban cities of Bangladesh due to the vast number ofobstructions on every path. With many injuries taking place through roadaccidents on a daily basis, it is paramount for a system to be developed thatcan alert the visually impaired of objects at close distance beforehand. Toovercome this issue, a novel alert system is proposed in this research toassist the visually impaired in commuting through these busy streets withoutcolliding with any objects. The proposed system can alert the individual toobjects that are present at a close distance. It utilizes transfer learning totrain models for depth estimation and object detection, and combines bothmodels to introduce a novel system. The models are optimized through theutilization of quantization techniques to make them lightweight and efficient,allowing them to be easily deployed on embedded systems. The proposed solutionachieved a lightweight real-time depth estimation and object detection modelwith an mAP50 of 0.801.</description>
      <author>example@mail.com (Jareen Anjom, Rashik Iram Chowdhury, Tarbia Hasan, Md. Ishan Arefin Hossain)</author>
      <guid isPermaLink="false">2507.08165v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>EP-GAT: Energy-based Parallel Graph Attention Neural Network for Stock Trend Classification</title>
      <link>http://arxiv.org/abs/2507.08184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCNN 2025, oral presentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于能量并行图注意力神经网络的股票预测方法，通过动态股票图和并行图注意力机制来捕捉股票间的动态依赖关系和股票内部的层次结构特征。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在预测股票走势方面表现出色，但现有方法通常依赖于静态或手动定义的因素来建模股票间的变化依赖关系，并且难以保留股票内部的层次特征。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种新的方法来预测多只股票的未来走势。&lt;h4&gt;方法&lt;/h4&gt;该方法首先利用股票间的能量差异和玻尔兹曼分布生成动态股票图，然后提出并行图注意力机制以保留股票内部的层次动态。&lt;h4&gt;主要发现&lt;/h4&gt;在五个真实世界数据集上的实验表明，EP-GAT在测试期间在各种指标上均优于五个基线方法。消融研究和超参数敏感性分析进一步验证了该方法中每个模块的有效性。&lt;h4&gt;结论&lt;/h4&gt;EP-GAT在预测股票走势方面具有显著优势，能够有效地捕捉股票间的动态依赖关系和股票内部的层次结构特征。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks have shown remarkable performance in forecasting stock movements, which arises from learning complex inter-dependencies between stocks and intra-dynamics of stocks. Existing approaches based on graph neural networks typically rely on static or manually defined factors to model changing inter-dependencies between stocks. Furthermore, these works often struggle to preserve hierarchical features within stocks. To bridge these gaps, this work presents the Energy-based Parallel Graph Attention Neural Network, a novel approach for predicting future movements for multiple stocks. First, it generates a dynamic stock graph with the energy difference between stocks and Boltzmann distribution, capturing evolving inter-dependencies between stocks. Then, a parallel graph attention mechanism is proposed to preserve the hierarchical intra-stock dynamics. Extensive experiments on five real-world datasets are conducted to validate the proposed approach, spanning from the US stock markets (NASDAQ, NYSE, SP) and UK stock markets (FTSE, LSE). The experimental results demonstrate that EP-GAT consistently outperforms competitive five baselines on test periods across various metrics. The ablation studies and hyperparameter sensitivity analysis further validate the effectiveness of each module in the proposed method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have shown remarkable performance in forecasting stockmovements, which arises from learning complex inter-dependencies between stocksand intra-dynamics of stocks. Existing approaches based on graph neuralnetworks typically rely on static or manually defined factors to model changinginter-dependencies between stocks. Furthermore, these works often struggle topreserve hierarchical features within stocks. To bridge these gaps, this workpresents the Energy-based Parallel Graph Attention Neural Network, a novelapproach for predicting future movements for multiple stocks. First, itgenerates a dynamic stock graph with the energy difference between stocks andBoltzmann distribution, capturing evolving inter-dependencies between stocks.Then, a parallel graph attention mechanism is proposed to preserve thehierarchical intra-stock dynamics. Extensive experiments on five real-worlddatasets are conducted to validate the proposed approach, spanning from the USstock markets (NASDAQ, NYSE, SP) and UK stock markets (FTSE, LSE). Theexperimental results demonstrate that EP-GAT consistently outperformscompetitive five baselines on test periods across various metrics. The ablationstudies and hyperparameter sensitivity analysis further validate theeffectiveness of each module in the proposed method.</description>
      <author>example@mail.com (Zhuodong Jiang, Pengju Zhang, Peter Martin)</author>
      <guid isPermaLink="false">2507.08184v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Distillation versus Contrastive Learning: How to Train Your Rerankers</title>
      <link>http://arxiv.org/abs/2507.08336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过实证研究对比了两种训练文本重排器的策略：对比学习和知识蒸馏，发现知识蒸馏在从更大的教师模型中提取知识时，通常比对比学习在领域内和领域外排名性能上更优。&lt;h4&gt;背景&lt;/h4&gt;训练文本重排器对于信息检索至关重要，目前广泛使用的两种策略是对比学习和知识蒸馏。&lt;h4&gt;目的&lt;/h4&gt;比较对比学习和知识蒸馏在训练跨编码器重排器时的有效性。&lt;h4&gt;方法&lt;/h4&gt;在相同的数据上，使用两种方法训练不同大小和架构的重排器，以一个强大的对比学习模型作为蒸馏教师。&lt;h4&gt;主要发现&lt;/h4&gt;知识蒸馏在从更大的教师模型中提取知识时，通常比对比学习在领域内和领域外排名性能上更优。这一发现适用于不同大小和架构的学生模型。然而，从相同容量的教师模型中提取知识并不提供相同优势，尤其是在领域外任务中。&lt;h4&gt;结论&lt;/h4&gt;如果可以访问更大的、更强大的教师模型，建议使用知识蒸馏来训练较小的重排器；如果没有，对比学习是一个强大且更可靠的替代方案。&lt;h4&gt;翻译&lt;/h4&gt;Training text rerankers is crucial for information retrieval. Two primary strategies are widely used: contrastive learning (optimizing directly on ground-truth labels) and knowledge distillation (transferring knowledge from a larger reranker). While both have been studied in the literature, a clear comparison of their effectiveness for training cross-encoder rerankers under practical conditions is needed. This paper empirically compares these strategies by training rerankers of different sizes and architectures using both methods on the same data, with a strong contrastive learning model acting as the distillation teacher. Our results show that knowledge distillation generally yields better in-domain and out-of-domain ranking performance than contrastive learning when distilling from a larger teacher model. This finding is consistent across student model sizes and architectures. However, distilling from a teacher of the same capacity does not provide the same advantage, particularly for out-of-domain tasks. These findings offer practical guidance for choosing a training strategy based on available teacher models. Therefore, we recommend using knowledge distillation to train smaller rerankers if a larger, more powerful teacher is accessible; in its absence, contrastive learning provides a strong and more reliable alternative otherwise.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training text rerankers is crucial for information retrieval. Two primarystrategies are widely used: contrastive learning (optimizing directly onground-truth labels) and knowledge distillation (transferring knowledge from alarger reranker). While both have been studied in the literature, a clearcomparison of their effectiveness for training cross-encoder rerankers underpractical conditions is needed.  This paper empirically compares these strategies by training rerankers ofdifferent sizes and architectures using both methods on the same data, with astrong contrastive learning model acting as the distillation teacher. Ourresults show that knowledge distillation generally yields better in-domain andout-of-domain ranking performance than contrastive learning when distillingfrom a larger teacher model. This finding is consistent across student modelsizes and architectures. However, distilling from a teacher of the samecapacity does not provide the same advantage, particularly for out-of-domaintasks. These findings offer practical guidance for choosing a training strategybased on available teacher models. Therefore, we recommend using knowledgedistillation to train smaller rerankers if a larger, more powerful teacher isaccessible; in its absence, contrastive learning provides a strong and morereliable alternative otherwise.</description>
      <author>example@mail.com (Zhichao Xu, Zhiqi Huang, Shengyao Zhuang, Ashim Gupta, Vivek Srikumar)</author>
      <guid isPermaLink="false">2507.08336v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Exploring substructures in the Milky Way halo Neural networks applied to Gaia and APOGEE DR 17</title>
      <link>http://arxiv.org/abs/2507.08074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 9 figures, accepted by A&amp;A. arXiv admin note: text overlap  with arXiv:2409.11429&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合化学和动力学的方法，通过神经网络系统来识别银河系晕中的恒星结构，如恒星流和合并遗迹。&lt;h4&gt;背景&lt;/h4&gt;目前识别银河系晕中的恒星结构主要依赖于恒星的动力特性，但这种方法存在局限性，因为恒星结构与其环境之间存在复杂的动态相互作用。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的聚类方法，用于识别银河系晕中积累的结构。&lt;h4&gt;方法&lt;/h4&gt;结合了Siamese神经网络（SNN）、图神经网络（GNN）、自编码器和OPTICS算法，创建了一个名为CREEK的综合程序。&lt;h4&gt;主要发现&lt;/h4&gt;CREEK在已知球状星团上进行了训练，并在数据集中成功识别了恒星流，包括80%的球状星团、多个已知的恒星流和一个潜在的新恒星流。&lt;h4&gt;结论&lt;/h4&gt;该方法为选择与恒星流和一般恒星结构相关的恒星提供了一种客观的数据驱动方法。&lt;h4&gt;翻译&lt;/h4&gt;The identification of stellar structures in the Galactic halo, including stellar streams and merger remnants, often relies on the dynamics of their constituent stars. However, this approach has limitations due to the complex dynamical interactions between these structures and their environment. Perturbations such as tidal forces exerted by the Milky Way, the potential escape of stars, and passages through the Galactic plane can result in the loss of dynamical coherence of stars in these structures. Consequently, relying solely on dynamics may be insufficient for detecting such disrupted or dispersed remnants. We combine chemistry and dynamics, integrated through a system of neural networks, to develop a clustering method for identifying accreted structures in the Galactic halo. We developed an integrated approach combining Siamese neural networks (SNNs), graph neural networks (GNNs), autoencoders, and the OPTICS algorithm to create a comprehensive procedure named CREEK. This method is designed to uncover stellar structures in the Galactic halo. Initially, CREEK was trained on known globular clusters (GCs) and then applied to the dataset to identify stellar streams. CREEK successfully recovered 80% of the GCs present in the APOGEE dataset, re-identified several known stellar streams, and identified a potential new stream. Additionally, within highly populated stellar structures, CREEK can identify substructures that exhibit distinct chemical compositions and orbital energies. This approach provides an objective data-driven method for selecting stars associated with streams and stellar structures in general.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The identification of stellar structures in the Galactic halo, includingstellar streams and merger remnants, often relies on the dynamics of theirconstituent stars. However, this approach has limitations due to the complexdynamical interactions between these structures and their environment.Perturbations such as tidal forces exerted by the Milky Way, the potentialescape of stars, and passages through the Galactic plane can result in the lossof dynamical coherence of stars in these structures. Consequently, relyingsolely on dynamics may be insufficient for detecting such disrupted ordispersed remnants. We combine chemistry and dynamics, integrated through asystem of neural networks, to develop a clustering method for identifyingaccreted structures in the Galactic halo. We developed an integrated approachcombining Siamese neural networks (SNNs), graph neural networks (GNNs),autoencoders, and the OPTICS algorithm to create a comprehensive procedurenamed CREEK. This method is designed to uncover stellar structures in theGalactic halo. Initially, CREEK was trained on known globular clusters (GCs)and then applied to the dataset to identify stellar streams. CREEK successfullyrecovered 80% of the GCs present in the APOGEE dataset, re-identified severalknown stellar streams, and identified a potential new stream. Additionally,within highly populated stellar structures, CREEK can identify substructuresthat exhibit distinct chemical compositions and orbital energies. This approachprovides an objective data-driven method for selecting stars associated withstreams and stellar structures in general.</description>
      <author>example@mail.com (L. Berni, L. Spina, L. Magrini, D. Massari, J. Schiapppacasse-Ulloa, R. E. Giribaldi)</author>
      <guid isPermaLink="false">2507.08074v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Vision Foundation Models as Effective Visual Tokenizers for Autoregressive Image Generation</title>
      <link>http://arxiv.org/abs/2507.08441v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究利用预训练的视觉基础模型强大的表示能力，探索了构建直接在这些模型之上的图像标记器的创新方向，并提出了一种名为VFMTok的图像标记器，它通过引入区域自适应量化框架和语义重建目标，显著提升了图像重建和生成质量，同时提高了标记效率。&lt;h4&gt;背景&lt;/h4&gt;传统上，预训练的视觉基础模型主要用于视觉理解。本研究旨在探索将这类模型用于图像标记器构建的新方向。&lt;h4&gt;目的&lt;/h4&gt;设计并实现一个高效的图像标记器，以提升图像重建和生成质量，并提高标记效率。&lt;h4&gt;方法&lt;/h4&gt;本研究采用以下方法：(1) 使用冻结的视觉基础模型作为标记器的编码器；(2) 引入区域自适应量化框架以减少预训练特征在常规2D网格上的冗余；(3) 提出语义重建目标，以使标记器的输出与基础模型的表示保持一致，从而保留语义保真度。&lt;h4&gt;主要发现&lt;/h4&gt;提出的图像标记器VFMTok在图像重建和生成质量上取得了显著提升，同时提高了标记效率。在ImageNet基准测试中，实现了2.07的gFID，加速了模型收敛速度，并允许在不使用无分类器指导（CFG）的情况下进行高保真度的类条件合成。&lt;h4&gt;结论&lt;/h4&gt;VFMTok是一种高效的图像标记器，能够显著提升图像处理和生成质量，同时提高效率，对图像处理社区具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Using the powerful representations of pre-trained vision foundation models, which are traditionally used for visual comprehension, we explore a new direction: building an image tokenizer directly on top of such models, a largely underexplored area. Specifically, we employ a frozen vision foundation model as the encoder of our tokenizer. To enhance its effectiveness, we introduce two key components: (1) a region-adaptive quantization framework that reduces redundancy in the pre-trained features on regular 2D grids, and (2) a semantic reconstruction objective that aligns the tokenizer's outputs with the foundation model's representations to preserve semantic fidelity. Based on these designs, our proposed image tokenizer, VFMTok, achieves substantial improvements in image reconstruction and generation quality, while also enhancing token efficiency. It further boosts autoregressive (AR) generation -- achieving a gFID of 2.07 on ImageNet benchmarks, while accelerating model convergence by three times, and enabling high-fidelity class-conditionalsynthesis without the need for classifier-free guidance (CFG). The code will be released publicly to benefit the community.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging the powerful representations of pre-trained vision foundationmodels -- traditionally used for visual comprehension -- we explore a noveldirection: building an image tokenizer directly atop such models, a largelyunderexplored area. Specifically, we employ a frozen vision foundation model asthe encoder of our tokenizer. To enhance its effectiveness, we introduce twokey components: (1) a region-adaptive quantization framework that reducesredundancy in the pre-trained features on regular 2D grids, and (2) a semanticreconstruction objective that aligns the tokenizer's outputs with thefoundation model's representations to preserve semantic fidelity. Based onthese designs, our proposed image tokenizer, VFMTok, achieves substantialimprovements in image reconstruction and generation quality, while alsoenhancing token efficiency. It further boosts autoregressive (AR) generation --achieving a gFID of 2.07 on ImageNet benchmarks, while accelerating modelconvergence by three times, and enabling high-fidelity class-conditionalsynthesis without the need for classifier-free guidance (CFG). The code will bereleased publicly to benefit the community.</description>
      <author>example@mail.com (Anlin Zheng, Xin Wen, Xuanyang Zhang, Chuofan Ma, Tiancai Wang, Gang Yu, Xiangyu Zhang, Xiaojuan Qi)</author>
      <guid isPermaLink="false">2507.08441v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>An Object-Based Deep Learning Approach for Building Height Estimation from Single SAR Images</title>
      <link>http://arxiv.org/abs/2507.08096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的自动建筑高度估计方法，利用高分辨率合成孔径雷达（SAR）图像，并在多大陆数据集上进行了训练和评估。&lt;h4&gt;背景&lt;/h4&gt;精确估计建筑高度对于城市应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于深度学习的自动建筑高度估计方法。&lt;h4&gt;方法&lt;/h4&gt;采用基于边界框检测的对象回归方法，首先进行边界框检测，然后进行高度估计。&lt;h4&gt;主要发现&lt;/h4&gt;模型在处理欧洲城市数据时表现出高度潜力，平均绝对误差（MAE）约为一层楼高（慕尼黑为2.20米），在类似场景下显著优于现有方法。尽管在其他大陆（尤其是亚洲）的数据上存在更多变异性，但该研究强调了深度学习在建筑高度估计中的跨城市和跨大陆迁移学习潜力。&lt;h4&gt;结论&lt;/h4&gt;深度学习在建筑高度估计中具有显著潜力，特别是在跨城市和跨大陆的迁移学习中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate estimation of building heights using very high resolution (VHR)synthetic aperture radar (SAR) imagery is crucial for various urbanapplications. This paper introduces a Deep Learning (DL)-based methodology forautomated building height estimation from single VHR COSMO-SkyMed images: anobject-based regression approach based on bounding box detection followed byheight estimation. This model was trained and evaluated on a uniquemulti-continental dataset comprising eight geographically diverse cities acrossEurope, North and South America, and Asia, employing a cross-validationstrategy to explicitly assess out-of-distribution (OOD) generalization. Theresults demonstrate highly promising performance, particularly on Europeancities where the model achieves a Mean Absolute Error (MAE) of approximatelyone building story (2.20 m in Munich), significantly outperforming recentstate-of-the-art methods in similar OOD scenarios. Despite the increasedvariability observed when generalizing to cities in other continents,particularly in Asia with its distinct urban typologies and prevalence ofhigh-rise structures, this study underscores the significant potential of DLfor robust cross-city and cross-continental transfer learning in buildingheight estimation from single VHR SAR data.</description>
      <author>example@mail.com (Babak Memar, Luigi Russo, Silvia Liberata Ullo, Paolo Gamba)</author>
      <guid isPermaLink="false">2507.08096v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>PanMatch: Unleashing the Potential of Large Vision Models for Unified Matching Models</title>
      <link>http://arxiv.org/abs/2507.08400v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PanMatch的通用基础模型，用于鲁棒的对应匹配。&lt;h4&gt;背景&lt;/h4&gt;以往的方法依赖于特定任务的架构和特定领域的微调来支持立体匹配、光流或特征匹配等任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，使得任何两帧的对应匹配任务都可以在二维位移估计框架中使用相同的模型权重来解决。&lt;h4&gt;方法&lt;/h4&gt;通过赋予位移估计算法前所未有的泛化能力，实现多任务集成。强调了适用于多个领域和任务的鲁棒特征提取器的重要性，并提出了利用通用特征从大型视觉模型中为匹配基线提供零样本跨视图匹配能力的特征转换管道。此外，构建了一个包含近180万个样本的跨领域数据集，用于预训练PanMatch。&lt;h4&gt;主要发现&lt;/h4&gt;PanMatch在广泛的领域和下游任务中表现出通用性，使用相同的模型权重。在跨任务评估中，该模型优于UniMatch和Flow-Anything，并在面向任务的基准测试中与大多数最先进的特定任务算法性能相当。此外，PanMatch在雨天和卫星图像等异常场景中表现出前所未有的零样本性能，而大多数现有的鲁棒算法在这些场景中无法产生有意义的结果。&lt;h4&gt;结论&lt;/h4&gt;PanMatch是一种高效且通用的基础模型，能够处理多种对应匹配任务，并在不同领域和任务中表现出优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents PanMatch, a versatile foundation model for robustcorrespondence matching. Unlike previous methods that rely on task-specificarchitectures and domain-specific fine-tuning to support tasks like stereomatching, optical flow or feature matching, our key insight is that anytwo-frame correspondence matching task can be addressed within a 2Ddisplacement estimation framework using the same model weights. Such aformulation eliminates the need for designing specialized unified architecturesor task-specific ensemble models. Instead, it achieves multi-task integrationby endowing displacement estimation algorithms with unprecedentedgeneralization capabilities. To this end, we highlight the importance of arobust feature extractor applicable across multiple domains and tasks, andpropose the feature transformation pipeline that leverage all-purpose featuresfrom Large Vision Models to endow matching baselines with zero-shot cross-viewmatching capabilities. Furthermore, we assemble a cross-domain dataset withnear 1.8 million samples from stereo matching, optical flow, and featurematching domains to pretrain PanMatch. We demonstrate the versatility ofPanMatch across a wide range of domains and downstream tasks using the samemodel weights. Our model outperforms UniMatch and Flow-Anything on cross-taskevaluations, and achieves comparable performance to most state-of-the-arttask-specific algorithms on task-oriented benchmarks. Additionally, PanMatchpresents unprecedented zero-shot performance in abnormal scenarios, such asrainy day and satellite imagery, where most existing robust algorithms fail toyield meaningful results.</description>
      <author>example@mail.com (Yongjian Zhang, Longguang Wang, Kunhong Li, Ye Zhang, Yun Wang, Liang Lin, Yulan Guo)</author>
      <guid isPermaLink="false">2507.08400v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>PUMA: Layer-Pruned Language Model for Efficient Unified Multimodal Retrieval with Modality-Adaptive Learning</title>
      <link>http://arxiv.org/abs/2507.08064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACM MM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PUMA的层剪枝语言模型，用于高效的多模态统一检索，并采用模态自适应学习方法。&lt;h4&gt;背景&lt;/h4&gt;随着多媒体内容的扩展，实际应用中对统一多模态检索（UMR）的需求增加，而现有的多模态大型语言模型（MLLMs）由于参数量大，导致训练成本高和推理效率低。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出PUMA模型，旨在通过结构优化和学习方法提高UMR的效率。&lt;h4&gt;方法&lt;/h4&gt;（1）结构上，提出层剪枝自蒸馏，通过保留浅层并从丢弃的深层中提取特征作为教师信号来剪枝MLLMs，从而减少参数量并保持表示能力；（2）在学习方面，引入模态自适应对比学习损失（MAC-Loss），根据目标模态将批内负样本分为更难的模态内和更易的模态间组，并分配不同的温度策略以提高学习效率。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在显著降低资源使用的同时，保持了强大的性能。&lt;h4&gt;结论&lt;/h4&gt;PUMA模型通过结构和学习两方面的改进，实现了高效的多模态统一检索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As multimedia content expands, the demand for unified multimodal retrieval(UMR) in real-world applications increases. Recent work leverages multimodallarge language models (MLLMs) to tackle this task. However, their largeparameter size results in high training costs and low inference efficiency. Toaddress this, we propose PUMA: a Layer-Pruned Language Model for EfficientUnified Multimodal Retrieval with Modality-Adaptive Learning. Our approachimproves UMR from both structural and learning perspectives. (1) Structurally,we propose Layer-Pruned Self-Distillation, which prunes MLLMs by keeping onlyshallow layers while distilling features from dropped deep layers as teachersignals. This reduces parameters and preserves representation capability. (2)On the learning side, we introduce Modality-Adaptive Contrastive Learning Loss(MAC-Loss), which separates in-batch negatives into harder intra-modality andeasier inter-modality groups based on the target modality, assigning differenttemperature strategies to enhance learning efficiency. Experiments show ourmethod significantly reduces resource usage while maintaining strongperformance.</description>
      <author>example@mail.com (Yibo Lyu, Rui Shao, Gongwei Chen, Yijie Zhu, Weili Guan, Liqiang Nie)</author>
      <guid isPermaLink="false">2507.08064v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Cycle Context Verification for In-Context Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2507.08357v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Cycle Context Verification (CCV) 是一种新型框架，旨在通过自我验证预测和增强上下文对齐来提高基于上下文学习的医学图像分割性能。&lt;h4&gt;背景&lt;/h4&gt;In-context learning (ICL) 是一种有前景的技术，可以实现通用医学图像分割，但它的性能对查询图像和上下文图像-掩码对之间的对齐非常敏感。&lt;h4&gt;目的&lt;/h4&gt;提出 CCV 以解决在临床场景中由于标注医学图像稀缺、计算成本高和灾难性遗忘风险，无法对上下文数据微调基础 ICL 模型的问题。&lt;h4&gt;方法&lt;/h4&gt;CCV 使用循环流程，模型首先为查询图像生成分割掩码，然后交换查询和上下文对的角色，通过预测原始上下文图像的掩码来验证其预测。查询特定提示用于改变查询图像并更新以改进测量，从而增强查询和上下文对之间的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在七个医学图像分割数据集上使用两个 ICL 基础模型评估 CCV，证明其优于现有方法，并强调了 CCV 提高基于 ICL 分割的能力。&lt;h4&gt;结论&lt;/h4&gt;CCV 是一种稳健的通用医学图像分割解决方案。&lt;h4&gt;翻译&lt;/h4&gt;In-context learning (ICL) 正逐渐成为一种实现通用医学图像分割的有前途的技术，其中可以使用单个模型对各种成像模态中的感兴趣对象进行分割。然而，其性能高度敏感于查询图像和上下文图像-掩码对之间的对齐。在临床场景中，标注医学图像的稀缺使得选择最佳上下文对变得具有挑战性，并且在上下文数据上微调基础 ICL 模型由于计算成本和灾难性遗忘的风险而不可行。为了解决这一挑战，我们提出了 Cycle Context Verification (CCV)，这是一种新的框架，通过实现预测的自我验证并相应地增强上下文对齐，从而提高了基于 ICL 的医学图像分割性能。具体来说，CCV 采用一个循环流程，其中模型最初为查询图像生成一个分割掩码。随后，交换查询和上下文对的角色，允许模型通过预测原始上下文图像的掩码来验证其预测。这个二次预测的准确性作为初始查询分割的隐式度量。引入一个查询特定提示来改变查询图像，并更新以改进度量，从而增强查询和上下文对之间的对齐。我们在七个医学图像分割数据集上使用两个 ICL 基础模型评估了 CCV，证明了其优于现有方法。我们的结果强调了 CCV 提高基于 ICL 分割的能力，使其成为通用医学图像分割的稳健解决方案。代码可在 https://github.com/ShishuaiHu/CCV 上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-context learning (ICL) is emerging as a promising technique for achievinguniversal medical image segmentation, where a variety of objects of interestacross imaging modalities can be segmented using a single model. Nevertheless,its performance is highly sensitive to the alignment between the query imageand in-context image-mask pairs. In a clinical scenario, the scarcity ofannotated medical images makes it challenging to select optimal in-contextpairs, and fine-tuning foundation ICL models on contextual data is infeasibledue to computational costs and the risk of catastrophic forgetting. To addressthis challenge, we propose Cycle Context Verification (CCV), a novel frameworkthat enhances ICL-based medical image segmentation by enablingself-verification of predictions and accordingly enhancing contextualalignment. Specifically, CCV employs a cyclic pipeline in which the modelinitially generates a segmentation mask for the query image. Subsequently, theroles of the query and an in-context pair are swapped, allowing the model tovalidate its prediction by predicting the mask of the original in-contextimage. The accuracy of this secondary prediction serves as an implicit measureof the initial query segmentation. A query-specific prompt is introduced toalter the query image and updated to improve the measure, thereby enhancing thealignment between the query and in-context pairs. We evaluated CCV on sevenmedical image segmentation datasets using two ICL foundation models,demonstrating its superiority over existing methods. Our results highlightCCV's ability to enhance ICL-based segmentation, making it a robust solutionfor universal medical image segmentation. The code will be available athttps://github.com/ShishuaiHu/CCV.</description>
      <author>example@mail.com (Shishuai Hu, Zehui Liao, Liangli Zhen, Huazhu Fu, Yong Xia)</author>
      <guid isPermaLink="false">2507.08357v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models</title>
      <link>http://arxiv.org/abs/2507.08254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 10 figures, accepted to ICML 2025. The first two authors  contributed equally&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Raptor，一种用于生成体积数据语义丰富嵌入的无监督方法，以解决体积成像数据基础模型开发中的挑战。&lt;h4&gt;背景&lt;/h4&gt;体积成像数据（如MRI）的基础模型开发面临计算复杂度高和需要足够大的数据集的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出Raptor方法，以解决上述挑战。&lt;h4&gt;方法&lt;/h4&gt;Raptor使用冻结的2D基础模型，该模型在自然图像上预训练，从医学体积的各个横截面上提取视觉标记。然后，使用随机投影对这些标记进行空间压缩，以显著降低计算复杂度并保留语义信息。&lt;h4&gt;主要发现&lt;/h4&gt;在十个不同的医学体积任务上进行的广泛实验验证了Raptor相较于最先进方法的优越性能，包括那些仅在医学体积上预训练的方法，同时避免了昂贵的训练需求。&lt;h4&gt;结论&lt;/h4&gt;Raptor作为一个基础模型，展示了其在推进基于深度学习的医学体积方法方面的有效性和多功能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current challenges in developing foundational models for volumetric imagingdata, such as magnetic resonance imaging (MRI), stem from the computationalcomplexity of training state-of-the-art architectures in high dimensions andcurating sufficiently large datasets of volumes. To address these challenges,we introduce Raptor (Random Planar Tensor Reduction), a train-free method forgenerating semantically rich embeddings for volumetric data. Raptor leverages afrozen 2D foundation model, pretrained on natural images, to extract visualtokens from individual cross-sections of medical volumes. These tokens are thenspatially compressed using random projections, significantly reducingcomputational complexity while retaining semantic information. Extensiveexperiments on ten diverse medical volume tasks verify the superior performanceof Raptor over state-of-the-art methods, including those pretrained exclusivelyon medical volumes (+3% SuPreM, +6% MISFM, +10% Merlin, +13% VoCo, and +14%SLIViT), while entirely bypassing the need for costly training. Our resultshighlight the effectiveness and versatility of Raptor as a foundation foradvancing deep learning-based methods for medical volumes.</description>
      <author>example@mail.com (Ulzee An, Moonseong Jeong, Simon A. Lee, Aditya Gorla, Yuzhe Yang, Sriram Sankararaman)</author>
      <guid isPermaLink="false">2507.08254v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction</title>
      <link>http://arxiv.org/abs/2507.08153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ALCo-FM的统一自适应长上下文基础模型，用于计算交通风险的动态上下文窗口选择和融合多模态数据，实现了高精度风险预测。&lt;h4&gt;背景&lt;/h4&gt;交通事故虽然罕见，但影响重大，需要长上下文多模态推理来准确预测风险。&lt;h4&gt;目的&lt;/h4&gt;开发一种模型，能够通过长上下文多模态推理准确预测交通风险。&lt;h4&gt;方法&lt;/h4&gt;ALCo-FM模型使用浅层交叉注意力编码和融合多模态数据，通过局部GAT层和BigBird风格的稀疏全局Transformer在H3六边形网格上处理数据，并结合蒙特卡洛dropout来提高预测的置信度。&lt;h4&gt;主要发现&lt;/h4&gt;在15个美国城市的数据上训练，并在留出城市上进行微调，ALCo-FM模型达到了0.94的准确率、0.92的F1分数和0.04的ECE，在大型城市风险预测中优于超过20个最先进的基线。&lt;h4&gt;结论&lt;/h4&gt;ALCo-FM模型在大型城市风险预测中表现出色，优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;Traffic accidents are rare, yet high-impact events that require long-context multimodal reasoning for accurate risk forecasting. In this paper, we introduce ALCo-FM, a unified adaptive long-context foundation model that computes a volatility pre-score to dynamically select context windows for input data and encodes and fuses these multimodal data via shallow cross attention. Following a local GAT layer and a BigBird-style sparse global transformer over H3 hexagonal grids, coupled with Monte Carlo dropout for confidence, the model yields superior, well-calibrated predictions. Trained on data from 15 US cities with a class-weighted loss to counter label imbalance, and fine-tuned with minimal data on held-out cities, ALCo-FM achieves 0.94 accuracy, 0.92 F1, and an ECE of 0.04, outperforming more than 20 state-of-the-art baselines in large-scale urban risk prediction. Code and dataset are available at: https://github.com/PinakiPrasad12/ALCo-FM&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic accidents are rare, yet high-impact events that require long-contextmultimodal reasoning for accurate risk forecasting. In this paper, we introduceALCo-FM, a unified adaptive long-context foundation model that computes avolatility pre-score to dynamically select context windows for input data andencodes and fuses these multimodal data via shallow cross attention. Followinga local GAT layer and a BigBird-style sparse global transformer over H3hexagonal grids, coupled with Monte Carlo dropout for confidence, the modelyields superior, well-calibrated predictions. Trained on data from 15 US citieswith a class-weighted loss to counter label imbalance, and fine-tuned withminimal data on held-out cities, ALCo-FM achieves 0.94 accuracy, 0.92 F1, andan ECE of 0.04, outperforming more than 20 state-of-the-art baselines inlarge-scale urban risk prediction. Code and dataset are available at:https://github.com/PinakiPrasad12/ALCo-FM</description>
      <author>example@mail.com (Pinaki Prasad Guha Neogi, Ahmad Mohammadshirazi, Rajiv Ramnath)</author>
      <guid isPermaLink="false">2507.08153v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>3D forest semantic segmentation using multispectral LiDAR and 3D deep learning</title>
      <link>http://arxiv.org/abs/2507.08025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了多光谱LiDAR技术在森林资源保护与决策中的潜力，通过深度学习模型实现了森林的精确语义分割。&lt;h4&gt;背景&lt;/h4&gt;森林资源保护与决策需要定期的森林清查。激光扫描系统中的光探测与测距（LiDAR）技术作为一种远程非破坏性解决方案，在森林清查中得到广泛应用。&lt;h4&gt;目的&lt;/h4&gt;研究HeliALS系统捕获的多光谱LiDAR数据在森林成分分割中的潜力，将森林分为六个部分：地面、低植被、树干、树枝、叶子和木质残留物。&lt;h4&gt;方法&lt;/h4&gt;实现了三种点云深度学习模型和一个机器学习模型，包括KPConv、superpoint transformer、point transformer V3和随机森林。对不同的几何和光谱特征向量场景进行了实验。&lt;h4&gt;主要发现&lt;/h4&gt;实验证实了KPConv模型的高精度。使用所有三个波长（1550 nm、905 nm和532 nm）作为初始特征输入深度学习模型，在平均交并比（mIoU）和平均准确率（mAcc）上分别提高了33.73%和32.35%。&lt;h4&gt;结论&lt;/h4&gt;多光谱LiDAR技术在提高森林成分分割的自动化精度方面具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;The study investigates the potential of multispectral LiDAR technology in forest resource conservation and decision-making, achieving precise forest semantic segmentation through deep learning models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conservation and decision-making regarding forest resources necessitateregular forest inventory. Light detection and ranging (LiDAR) in laser scanningsystems has gained significant attention over the past two decades as a remoteand non-destructive solution to streamline the labor-intensive andtime-consuming procedure of forest inventory. Advanced multispectral (MS) LiDARsystems simultaneously acquire three-dimensional (3D) spatial and spectralinformation across multiple wavelengths of the electromagnetic spectrum.Consequently, MS-LiDAR technology enables the estimation of both thebiochemical and biophysical characteristics of forests. Forest componentsegmentation is crucial for forest inventory. The synergistic use of spatialand spectral laser information has proven to be beneficial for achievingprecise forest semantic segmentation. Thus, this study aims to investigate thepotential of MS-LiDAR data, captured by the HeliALS system, providinghigh-density multispectral point clouds to segment forests into six components:ground, low vegetation, trunks, branches, foliage, and woody debris. Threepoint-wise 3D deep learning models and one machine learning model, includingkernel point convolution, superpoint transformer, point transformer V3, andrandom forest, are implemented. Our experiments confirm the superior accuracyof the KPConv model. Additionally, various geometric and spectral featurevector scenarios are examined. The highest accuracy is achieved by feeding allthree wavelengths (1550 nm, 905 nm, and 532 nm) as the initial features intothe deep learning model, resulting in improvements of 33.73% and 32.35% in meanintersection over union (mIoU) and in mean accuracy (mAcc), respectively. Thisstudy highlights the excellent potential of multispectral LiDAR for improvingthe accuracy in fully automated forest component segmentation.</description>
      <author>example@mail.com (Narges Takhtkeshha, Lauris Bocaux, Lassi Ruoppa, Fabio Remondino, Gottfried Mandlburger, Antero Kukko, Juha Hyyppä)</author>
      <guid isPermaLink="false">2507.08025v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos</title>
      <link>http://arxiv.org/abs/2505.11868v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种创新框架，能够从单目视频中无监督地分析3D运动，精确解析运动部分和运动属性，无需标注训练数据。&lt;h4&gt;背景&lt;/h4&gt;在动态环境中，精确分析运动部分及其运动属性对于推动如具身智能等关键领域至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法依赖密集多视角图像或详细的运动级标注的限制。&lt;h4&gt;方法&lt;/h4&gt;该方法首先结合深度估计、光流分析和点云配准方法构建场景几何，并粗略分析运动部分及其初始运动属性。然后使用2D高斯扩散进行场景表示。在此基础上，引入一个专门针对关节物体的端到端动态场景优化算法，以细化初始分析结果，确保系统可以处理'旋转'、'平移'以及更复杂的运动（'旋转+平移'），从而展示其高度灵活性和多功能性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架可以在无标注的情况下有效地分析关节物体的运动，展示了其在未来具身智能应用中的巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;该框架在无标注情况下分析3D运动的有效性，对于推进具身智能等领域具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes an innovative framework that can analyze 3D motion from monocular videos in a zero-shot manner, accurately parsing motion parts and motion attributes without the need for annotated training data. The method first constructs the scene geometry and roughly analyzes the motion parts and their initial motion attributes by combining depth estimation, optical flow analysis, and point cloud registration methods. Then, it uses 2D Gaussian splatting for scene representation. On this basis, an end-to-end dynamic scene optimization algorithm specifically designed for articulated objects is introduced to refine the initial analysis results to ensure that the system can handle 'rotation', 'translation', and even complex movements ('rotation+translation'), demonstrating high flexibility and versatility. Experimental results show that the framework can effectively analyze articulated object motions without annotations, showcasing its significant potential in future embodied intelligence applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately analyzing the motion parts and their motion attributes in dynamicenvironments is crucial for advancing key areas such as embodied intelligence.Addressing the limitations of existing methods that rely on dense multi-viewimages or detailed part-level annotations, we propose an innovative frameworkthat can analyze 3D mobility from monocular videos in a zero-shot manner. Thisframework can precisely parse motion parts and motion attributes only using amonocular video, completely eliminating the need for annotated training data.Specifically, our method first constructs the scene geometry and roughlyanalyzes the motion parts and their initial motion attributes combining depthestimation, optical flow analysis and point cloud registration method, thenemploys 2D Gaussian splatting for scene representation. Building on this, weintroduce an end-to-end dynamic scene optimization algorithm specificallydesigned for articulated objects, refining the initial analysis results toensure the system can handle 'rotation', 'translation', and even complexmovements ('rotation+translation'), demonstrating high flexibility andversatility. To validate the robustness and wide applicability of our method,we created a comprehensive dataset comprising both simulated and real-worldscenarios. Experimental results show that our framework can effectively analyzearticulated object motions in an annotation-free manner, showcasing itssignificant potential in future embodied intelligence applications.</description>
      <author>example@mail.com (Hongyi Zhou, Yulan Guo, Xiaogang Wang, Kai Xu)</author>
      <guid isPermaLink="false">2505.11868v3</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model</title>
      <link>http://arxiv.org/abs/2507.08013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MedicalBERT模型，这是一个基于预训练BERT模型并专门针对生物医学领域进行优化的模型。&lt;h4&gt;背景&lt;/h4&gt;自然语言处理在生物医学领域的应用受到挑战，因为该领域的术语具有特定性，现有的模型如Word2Vec和Bi-LSTM难以完全处理。&lt;h4&gt;目的&lt;/h4&gt;提出MedicalBERT，旨在提高生物医学自然语言处理的能力。&lt;h4&gt;方法&lt;/h4&gt;MedicalBERT是基于大量生物医学数据集预训练的BERT模型，并配备了特定领域的词汇，以增强对生物医学术语的理解。该模型经过优化和微调，以解决多种任务，包括命名实体识别、关系抽取、问答、句子相似度和文档分类。&lt;h4&gt;主要发现&lt;/h4&gt;MedicalBERT在大多数基准测试中优于其他基于BERT的模型，如BioBERT、SciBERT和ClinicalBERT，并且在所有评估的任务上平均超过了通用BERT模型5.67%。&lt;h4&gt;结论&lt;/h4&gt;这项工作强调了利用预训练BERT模型进行医学自然语言处理任务的潜力，证明了迁移学习技术在捕捉特定领域信息中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.11591/ijai.v14.i3.pp2367-2378&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in natural language processing (NLP) have been drivenbypretrained language models like BERT, RoBERTa, T5, and GPT. Thesemodels excelat understanding complex texts, but biomedical literature, withitsdomain-specific terminology, poses challenges that models likeWord2Vec andbidirectional long short-term memory (Bi-LSTM) can't fullyaddress. GPT and T5,despite capturing context, fall short in tasks needingbidirectionalunderstanding, unlike BERT. Addressing this, we proposedMedicalBERT, apretrained BERT model trained on a large biomedicaldataset and equipped withdomain-specific vocabulary that enhances thecomprehension of biomedicalterminology. MedicalBERT model is furtheroptimized and fine-tuned to addressdiverse tasks, including named entityrecognition, relation extraction, questionanswering, sentence similarity, anddocument classification. Performance metricssuch as the F1-score,accuracy, and Pearson correlation are employed to showcasethe efficiencyof our model in comparison to other BERT-based models such asBioBERT,SciBERT, and ClinicalBERT. MedicalBERT outperforms these models onmostof the benchmarks, and surpasses the general-purpose BERT model by5.67% onaverage across all the tasks evaluated respectively. This work alsounderscoresthe potential of leveraging pretrained BERT models for medicalNLP tasks,demonstrating the effectiveness of transfer learning techniques incapturingdomain-specific information.  (PDF) MedicalBERT: enhancing biomedical natural language processing usingpretrained BERT-based model. Available from:https://www.researchgate.net/publication/392489050_MedicalBERT_enhancing_biomedical_natural_language_processing_using_pretrained_BERT-based_model[accessed Jul 06 2025].</description>
      <author>example@mail.com (K. Sahit Reddy, N. Ragavenderan, Vasanth K., Ganesh N. Naik, Vishalakshi Prabhu, Nagaraja G. S)</author>
      <guid isPermaLink="false">2507.08013v1</guid>
      <pubDate>Mon, 14 Jul 2025 14:18:37 +0800</pubDate>
    </item>
    <item>
      <title>Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS</title>
      <link>http://arxiv.org/abs/2507.05999v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Transactions on Geoscience &amp; Remote Sensing. Under  reviewing now&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种在GNSS信号缺失的城市环境中进行激光雷达点云地理配准的方法，通过结合卫星图像和地形信息，实现了高精度配准。&lt;h4&gt;背景&lt;/h4&gt;在GNSS信号缺失的城市环境中，如高楼和桥梁附近，传统的依赖GNSS和IMU数据的地理配准方法面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种不需要依赖先验定位的方法，用于精确配准LiDAR点云。&lt;h4&gt;方法&lt;/h4&gt;提出的方法包括：使用预训练的Point Transformer模型分割道路点，提取点云中的道路骨架和交叉点以及目标地图进行对齐；全局刚性对齐使用交叉点完成，然后通过径向基函数（RBF）插值进行局部细化；基于SRTM数据集的地形信息对点云进行高程校正。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI数据集上，该方法在具有交叉点的序列中实现了平均平面配准标准差（STD）为0.84米，比原始数据集提高了55.3%。在缺乏GNSS信息的珀斯数据集上，平均STD为0.96米，比从Google Maps API提取的GPS数据提高了77.4%。此外，该方法在KITTI数据集上实现了30.5%的高程相关性增益，在珀斯数据集上实现了50.4%的增益。&lt;h4&gt;结论&lt;/h4&gt;该方法在GNSS信号缺失的城市环境中实现了高精度的LiDAR点云地理配准，有效提高了点云的定位精度。&lt;h4&gt;翻译&lt;/h4&gt;Accurate geo-registration of LiDAR point clouds presents significant challenges in GNSS signal denied urban areas with high-rise buildings and bridges. Existing methods typically rely on real-time GNSS and IMU data, that require pre-calibration and assume stable positioning during data collection. However, this assumption often fails in dense urban areas, resulting in localization errors. To address this, we propose a structured geo-registration and spatial correction method that aligns 3D point clouds with satellite images, enabling frame-wise recovery of GNSS information and reconstruction of city scale 3D maps without relying on prior localization. The proposed approach employs a pre-trained Point Transformer model to segment the road points and then extracts the road skeleton and intersection points from the point cloud as well as the target map for alignment. Global rigid alignment of the two is performed using the intersection points, followed by local refinement using radial basis function (RBF) interpolation. Elevation correction is then applied to the point cloud based on terrain information from SRTM dataset to resolve vertical discrepancies. The proposed method was tested on the popular KITTI benchmark and a locally collected Perth (Western Australia) CBD dataset. On the KITTI dataset, our method achieved an average planimetric alignment standard deviation (STD) of 0.84~m across sequences with intersections, representing a 55.3% improvement over the original dataset. On the Perth dataset, which lacks GNSS information, our method achieved an average STD of 0.96~m compared to the GPS data extracted from Google Maps API. This corresponds to a 77.4% improvement from the initial alignment. Our method also resulted in elevation correlation gains of 30.5% on the KITTI dataset and 50.4% on the Perth dataset.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate geo-registration of LiDAR point clouds presents significantchallenges in GNSS signal denied urban areas with high-rise buildings andbridges. Existing methods typically rely on real-time GNSS and IMU data, thatrequire pre-calibration and assume stable positioning during data collection.However, this assumption often fails in dense urban areas, resulting inlocalization errors. To address this, we propose a structured geo-registrationand spatial correction method that aligns 3D point clouds with satelliteimages, enabling frame-wise recovery of GNSS information and reconstruction ofcity scale 3D maps without relying on prior localization. The proposed approachemploys a pre-trained Point Transformer model to segment the road points andthen extracts the road skeleton and intersection points from the point cloud aswell as the target map for alignment. Global rigid alignment of the two isperformed using the intersection points, followed by local refinement usingradial basis function (RBF) interpolation. Elevation correction is then appliedto the point cloud based on terrain information from SRTM dataset to resolvevertical discrepancies. The proposed method was tested on the popular KITTIbenchmark and a locally collected Perth (Western Australia) CBD dataset. On theKITTI dataset, our method achieved an average planimetric alignment standarddeviation (STD) of 0.84~m across sequences with intersections, representing a55.3\% improvement over the original dataset. On the Perth dataset, which lacksGNSS information, our method achieved an average STD of 0.96~m compared to theGPS data extracted from Google Maps API. This corresponds to a 77.4\%improvement from the initial alignment. Our method also resulted in elevationcorrelation gains of 30.5\% on the KITTI dataset and 50.4\% on the Perthdataset.</description>
      <author>example@mail.com (Xinyu Wang, Muhammad Ibrahim, Haitian Wang, Atif Mansoor, Ajmal Mian)</author>
      <guid isPermaLink="false">2507.05999v2</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
  <item>
      <title>LOSC: LiDAR Open-voc Segmentation Consolidator</title>
      <link>http://arxiv.org/abs/2507.07605v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于图像的视觉-语言模型（VLMs）在驾驶场景中用于激光雷达扫描的开集词汇分割。提出了一种简单的方法LOSC，该方法在nuScenes和SemanticKITTI数据集上优于现有的零样本开集语义和全景分割方法。&lt;h4&gt;背景&lt;/h4&gt;传统的图像语义可以投射到3D点云上，但得到的点标签存在噪声和稀疏性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来改进激光雷达扫描的开集词汇分割，提高分割的时空一致性和对图像级增强的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;通过整合标签来确保时空一致性和鲁棒性，然后基于这些改进的标签训练一个3D网络。&lt;h4&gt;主要发现&lt;/h4&gt;LOSC方法在nuScenes和SemanticKITTI数据集上显著优于现有的零样本开集语义和全景分割方法。&lt;h4&gt;结论&lt;/h4&gt;LOSC方法是一种简单而有效的方法，可以显著提高激光雷达扫描的开集词汇分割性能。&lt;h4&gt;翻译&lt;/h4&gt;本研究探讨了在驾驶环境中使用基于图像的视觉-语言模型（VLMs）进行激光雷达扫描的开集词汇分割。传统上，图像语义可以投射到3D点云上，但得到的点标签存在噪声和稀疏。我们通过整合这些标签来确保时空一致性和对图像级增强的鲁棒性。然后，我们基于这些改进的标签训练了一个3D网络。这种方法，称为LOSC，在nuScenes和SemanticKITTI数据集上优于现有的零样本开集语义和全景分割方法，具有显著的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the use of image-based Vision-Language Models (VLMs) foropen-vocabulary segmentation of lidar scans in driving settings. Classically,image semantics can be back-projected onto 3D point clouds. Yet, resultingpoint labels are noisy and sparse. We consolidate these labels to enforce bothspatio-temporal consistency and robustness to image-level augmentations. Wethen train a 3D network based on these refined labels. This simple method,called LOSC, outperforms the SOTA of zero-shot open-vocabulary semantic andpanoptic segmentation on both nuScenes and SemanticKITTI, with significantmargins.</description>
      <author>example@mail.com (Nermin Samet, Gilles Puy, Renaud Marlet)</author>
      <guid isPermaLink="false">2507.07605v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2507.07769v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the Workshop on Computational Optimization of Buildings  (ICML CO-BUILD), 42nd International Conference on Machine Learning (ICML  2025), Vancouver, Canada&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于强化学习的建筑能源管理，分析了在不同环境和操作场景下的可扩展性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于强化学习的建筑能源管理取得了显著进展，但在模拟或受控环境中的成功难以推广到实际建筑中。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在正式描述跨环境、多目标建筑能源管理任务的泛化空间，并构建多目标情境强化学习问题。&lt;h4&gt;方法&lt;/h4&gt;本研究提供了参数化情境信息的方法，并在实际建筑控制任务中构建了一个新的基准来评估可泛化强化学习算法。&lt;h4&gt;主要发现&lt;/h4&gt;现有的多目标强化学习方法能够在冲突的目标之间实现合理的权衡，但在某些环境变化下性能会下降。&lt;h4&gt;结论&lt;/h4&gt;将动态依赖的情境信息纳入策略学习过程对于提高强化学习算法的性能至关重要。&lt;h4&gt;翻译&lt;/h4&gt;Recent years have seen significant advancements in designing reinforcement-learning (RL)-based agents for building energy management. While individual success is observed in simulated or controlled environments, the scalability of RL approaches in terms of efficiency and generalization across building dynamics and operational scenarios remains an open question. In this work, we formally characterize the generalization space for the cross-environment, multi-objective building energy management task, and formulate the multi-objective contextual RL problem. Such a formulation helps understand the challenges of transferring learned policies across varied operational contexts such as climate and heat convection dynamics under multiple control objectives such as comfort level and energy consumption. We provide a principled way to parameterize such contextual information in realistic building RL environments, and construct a novel benchmark to facilitate the evaluation of generalizable RL algorithms in practical building control tasks. Our results show that existing multi-objective RL methods are capable of achieving reasonable trade-offs between conflicting objectives. However, their performance degrades under certain environment variations, underscoring the importance of incorporating dynamics-dependent contextual information into the policy learning process.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent years have seen significant advancements in designing reinforcementlearning (RL)-based agents for building energy management. While individualsuccess is observed in simulated or controlled environments, the scalability ofRL approaches in terms of efficiency and generalization across buildingdynamics and operational scenarios remains an open question. In this work, weformally characterize the generalization space for the cross-environment,multi-objective building energy management task, and formulate themulti-objective contextual RL problem. Such a formulation helps understand thechallenges of transferring learned policies across varied operational contextssuch as climate and heat convection dynamics under multiple control objectivessuch as comfort level and energy consumption. We provide a principled way toparameterize such contextual information in realistic building RL environments,and construct a novel benchmark to facilitate the evaluation of generalizableRL algorithms in practical building control tasks. Our results show thatexisting multi-objective RL methods are capable of achieving reasonabletrade-offs between conflicting objectives. However, their performance degradesunder certain environment variations, underscoring the importance ofincorporating dynamics-dependent contextual information into the policylearning process.</description>
      <author>example@mail.com (Ruohong Liu, Jack Umenberger, Yize Chen)</author>
      <guid isPermaLink="false">2507.07769v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Geometry Forcing: Marrying Video Diffusion and 3D Representation for Consistent World Modeling</title>
      <link>http://arxiv.org/abs/2507.07982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, project page: https://GeometryForcing.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Geometry Forcing的视频扩散模型，旨在解决视频扩散模型在捕捉3D几何结构方面的不足。&lt;h4&gt;背景&lt;/h4&gt;视频数据本质上是动态3D世界的二维投影，但现有的视频扩散模型在处理原始视频数据时，往往无法有效捕捉到有意义的几何结构。&lt;h4&gt;目的&lt;/h4&gt;为了弥合视频扩散模型与物理世界3D本质之间的差距，本文提出了Geometry Forcing方法，鼓励模型内部化潜在的3D表示。&lt;h4&gt;方法&lt;/h4&gt;该方法通过将模型的中间表示与预训练的几何基础模型中的特征对齐，引导模型向几何感知结构发展。具体包括两个互补的对齐目标：角对齐和尺度对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与基线方法相比，Geometry Forcing在视觉质量和3D一致性方面有显著提升。&lt;h4&gt;结论&lt;/h4&gt;Geometry Forcing方法能够有效提高视频扩散模型的性能，使其在处理视频数据时更好地捕捉到3D几何结构。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a method called Geometry Forcing for video diffusion models, aiming to address the deficiency of capturing 3D geometric structures in existing video diffusion models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Videos inherently represent 2D projections of a dynamic 3D world. However,our analysis suggests that video diffusion models trained solely on raw videodata often fail to capture meaningful geometric-aware structure in theirlearned representations. To bridge this gap between video diffusion models andthe underlying 3D nature of the physical world, we propose Geometry Forcing, asimple yet effective method that encourages video diffusion models tointernalize latent 3D representations. Our key insight is to guide the model'sintermediate representations toward geometry-aware structure by aligning themwith features from a pretrained geometric foundation model. To this end, weintroduce two complementary alignment objectives: Angular Alignment, whichenforces directional consistency via cosine similarity, and Scale Alignment,which preserves scale-related information by regressing unnormalized geometricfeatures from normalized diffusion representation. We evaluate Geometry Forcingon both camera view-conditioned and action-conditioned video generation tasks.Experimental results demonstrate that our method substantially improves visualquality and 3D consistency over the baseline methods. Project page:https://GeometryForcing.github.io.</description>
      <author>example@mail.com (Haoyu Wu, Diankun Wu, Tianyu He, Junliang Guo, Yang Ye, Yueqi Duan, Jiang Bian)</author>
      <guid isPermaLink="false">2507.07982v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos</title>
      <link>http://arxiv.org/abs/2507.07393v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 2 figures,&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为KeyRe-ID的人体关键点引导的视频行人重识别框架。&lt;h4&gt;背景&lt;/h4&gt;该框架利用人体关键点进行时空表示学习。&lt;h4&gt;目的&lt;/h4&gt;通过全局和局部分支，提高行人重识别的性能。&lt;h4&gt;方法&lt;/h4&gt;全局分支通过基于Transformer的时间聚合捕捉整体身份语义，局部分支根据关键点动态分割身体区域，生成细粒度、部分感知的特征。&lt;h4&gt;主要发现&lt;/h4&gt;在MARS和iLIDS-VID基准测试中，该框架取得了最先进的性能，MARS上达到91.73%的平均精度（mAP）和97.32%的Rank-1准确率，iLIDS-VID上达到96.00%的Rank-1和100.0%的Rank-5准确率。&lt;h4&gt;结论&lt;/h4&gt;该框架的代码将在论文发表后公开在GitHub上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose \textbf{KeyRe-ID}, a keypoint-guided video-based personre-identification framework consisting of global and local branches thatleverage human keypoints for enhanced spatiotemporal representation learning.The global branch captures holistic identity semantics throughTransformer-based temporal aggregation, while the local branch dynamicallysegments body regions based on keypoints to generate fine-grained, part-awarefeatures. Extensive experiments on MARS and iLIDS-VID benchmarks demonstratestate-of-the-art performance, achieving 91.73\% mAP and 97.32\% Rank-1 accuracyon MARS, and 96.00\% Rank-1 and 100.0\% Rank-5 accuracy on iLIDS-VID. The codefor this work will be publicly available on GitHub upon publication.</description>
      <author>example@mail.com (Jinseong Kim, Junghoon Song, Gyeongseon Baek, Byeongjoon Noh)</author>
      <guid isPermaLink="false">2507.07393v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs</title>
      <link>http://arxiv.org/abs/2507.07990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICCV2025; Project page:  https://www.jshyun.me/projects/sttm&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STTM的无监督时空标记合并方法，用于解决视频大语言模型在视频理解中计算量随标记数量平方增长的问题。&lt;h4&gt;背景&lt;/h4&gt;视频大语言模型通过利用大量的时空标记实现强大的视频理解，但计算量随标记数量的平方增长。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督的时空标记合并方法，以减少计算量。&lt;h4&gt;方法&lt;/h4&gt;STTM首先使用粗到细的搜索在四叉树结构上对每个帧进行多粒度空间标记的转换，然后在时间维度上执行有向成对合并。&lt;h4&gt;主要发现&lt;/h4&gt;STTM在六个视频问答基准测试中优于现有的标记减少方法，实现了2倍的速度提升，而准确性仅下降0.5%，在30%的标记预算下实现了3倍的速度提升。&lt;h4&gt;结论&lt;/h4&gt;STTM是无查询相关的，允许在相同视频的不同问题之间重用KV缓存。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a unsupervised spatial-temporal token merging method named STTM to address the issue of quadratic computational scaling with token count in video large language models. STTM first transforms each frame into multi-granular spatial tokens using a coarse-to-fine search over a quadtree structure, and then performs directed pairwise merging across the temporal dimension. This decomposed merging approach outperforms existing token reduction methods across six video QA benchmarks, achieving a 2x speed-up with only a 0.5% accuracy drop under a 50% token budget, and a 3x speed-up with just a 2% drop under a 30% budget. Moreover, STTM is query-agnostic, allowing KV cache reuse across different questions for the same video.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video large language models (LLMs) achieve strong video understanding byleveraging a large number of spatio-temporal tokens, but suffer from quadraticcomputational scaling with token count. To address this, we propose atraining-free spatio-temporal token merging method, named STTM. Our key insightis to exploit local spatial and temporal redundancy in video data which hasbeen overlooked in prior work. STTM first transforms each frame intomulti-granular spatial tokens using a coarse-to-fine search over a quadtreestructure, then performs directed pairwise merging across the temporaldimension. This decomposed merging approach outperforms existing tokenreduction methods across six video QA benchmarks. Notably, STTM achieves a2$\times$ speed-up with only a 0.5% accuracy drop under a 50% token budget, anda 3$\times$ speed-up with just a 2% drop under a 30% budget. Moreover, STTM isquery-agnostic, allowing KV cache reuse across different questions for the samevideo. The project page is available at https://www.jshyun.me/projects/sttm.</description>
      <author>example@mail.com (Jeongseok Hyun, Sukjun Hwang, Su Ho Han, Taeoh Kim, Inwoong Lee, Dongyoon Wee, Joon-Young Lee, Seon Joo Kim, Minho Shim)</author>
      <guid isPermaLink="false">2507.07990v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Patient-specific vs Multi-Patient Vision Transformer for Markerless Tumor Motion Forecasting</title>
      <link>http://arxiv.org/abs/2507.07811v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究首次将Vision Transformers（ViT）架构应用于无标记的肺癌肿瘤运动预测，通过比较患者特定模型和多患者模型，发现患者特定模型在精度上表现更优，而多患者模型在临床设置中具有更好的鲁棒性和即用性。&lt;h4&gt;背景&lt;/h4&gt;精确预测肺癌肿瘤运动对于质子治疗中的精确剂量递送至关重要。尽管目前的无标记方法主要依赖深度学习，但基于transformer的架构在此领域尚未被探索。&lt;h4&gt;目的&lt;/h4&gt;本研究的目的是引入一种使用Vision Transformers（ViT）进行肺癌肿瘤运动预测的无标记预测方法，并评估两种训练策略：患者特定（PS）方法和多患者（MP）模型。&lt;h4&gt;方法&lt;/h4&gt;使用31名患者的规划4DCT扫描的数字化重建X光片（DRRs）来训练多患者模型；32号患者被保留用于评估。使用目标患者的规划数据训练患者特定模型。两个模型都使用每个输入16个DRRs，并预测1秒内的肿瘤运动。使用平均位移误差（ADE）和最终位移误差（FDE）在规划（T1）和治疗（T2）数据上评估性能。&lt;h4&gt;主要发现&lt;/h4&gt;在T1数据上，患者特定模型在所有训练集大小上优于多患者模型，特别是在较大的数据集上（高达25,000个DRRs，p &lt; 0.05）。然而，多患者模型对分数间解剖变异性具有更强的鲁棒性，在T2数据上无需重新训练即可实现可比的性能。&lt;h4&gt;结论&lt;/h4&gt;这是首次将ViT架构应用于无标记肿瘤运动预测的研究。虽然患者特定模型实现了更高的精度，但多患者模型提供了鲁棒的即用性性能，非常适合时间受限的临床环境。&lt;h4&gt;翻译&lt;/h4&gt;Background: Accurate forecasting of lung tumor motion is essential for precise dose delivery in proton therapy. While current markerless methods mostly rely on deep learning, transformer-based architectures remain unexplored in this domain, despite their proven performance in trajectory forecasting. Purpose: This work introduces a markerless forecasting approach for lung tumor motion using Vision Transformers (ViT). Two training strategies are evaluated under clinically realistic constraints: a patient-specific (PS) approach that learns individualized motion patterns, and a multi-patient (MP) model designed for generalization. The comparison explicitly accounts for the limited number of images that can be generated between planning and treatment sessions. Methods: Digitally reconstructed radiographs (DRRs) derived from planning 4DCT scans of 31 patients were used to train the MP model; a 32nd patient was held out for evaluation. PS models were trained using only the target patient's planning data. Both models used 16 DRRs per input and predicted tumor motion over a 1-second horizon. Performance was assessed using Average Displacement Error (ADE) and Final Displacement Error (FDE), on both planning (T1) and treatment (T2) data. Results: On T1 data, PS models outperformed MP models across all training set sizes, especially with larger datasets (up to 25,000 DRRs, p &lt; 0.05). However, MP models demonstrated stronger robustness to inter-fractional anatomical variability and achieved comparable performance on T2 data without retraining. Conclusions: This is the first study to apply ViT architectures to markerless tumor motion forecasting. While PS models achieve higher precision, MP models offer robust out-of-the-box performance, well-suited for time-constrained clinical settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Background: Accurate forecasting of lung tumor motion is essential forprecise dose delivery in proton therapy. While current markerless methodsmostly rely on deep learning, transformer-based architectures remain unexploredin this domain, despite their proven performance in trajectory forecasting.  Purpose: This work introduces a markerless forecasting approach for lungtumor motion using Vision Transformers (ViT). Two training strategies areevaluated under clinically realistic constraints: a patient-specific (PS)approach that learns individualized motion patterns, and a multi-patient (MP)model designed for generalization. The comparison explicitly accounts for thelimited number of images that can be generated between planning and treatmentsessions.  Methods: Digitally reconstructed radiographs (DRRs) derived from planning4DCT scans of 31 patients were used to train the MP model; a 32nd patient washeld out for evaluation. PS models were trained using only the target patient'splanning data. Both models used 16 DRRs per input and predicted tumor motionover a 1-second horizon. Performance was assessed using Average DisplacementError (ADE) and Final Displacement Error (FDE), on both planning (T1) andtreatment (T2) data.  Results: On T1 data, PS models outperformed MP models across all training setsizes, especially with larger datasets (up to 25,000 DRRs, p &lt; 0.05). However,MP models demonstrated stronger robustness to inter-fractional anatomicalvariability and achieved comparable performance on T2 data without retraining.  Conclusions: This is the first study to apply ViT architectures to markerlesstumor motion forecasting. While PS models achieve higher precision, MP modelsoffer robust out-of-the-box performance, well-suited for time-constrainedclinical settings.</description>
      <author>example@mail.com (Gauthier Rotsart de Hertaing, Dani Manjah, Benoit Macq)</author>
      <guid isPermaLink="false">2507.07811v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>NLGCL: Naturally Existing Neighbor Layers Graph Contrastive Learning for Recommendation</title>
      <link>http://arxiv.org/abs/2507.07522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by RecSys 2025 as Spotlight Oral&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NLGCL的新颖对比学习框架，用于解决推荐系统中的数据稀疏性问题，并通过实验证明其在效果和效率上优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;Graph Neural Networks (GNNs)在协同过滤中广泛应用，用于捕捉用户-物品的高阶关系。然而，推荐系统中的数据稀疏性问题限制了GNNs的效果。&lt;h4&gt;目的&lt;/h4&gt;为了解决数据稀疏性问题，提出NLGCL框架，以实现更有效的推荐。&lt;h4&gt;方法&lt;/h4&gt;NLGCL利用GNNs中相邻层之间的自然对比视图，将每个节点及其下一层的邻居视为正对，其他节点视为负对，从而避免基于增强技术的噪声，同时保持语义相关性。&lt;h4&gt;主要发现&lt;/h4&gt;NLGCL在四个公开数据集上的实验表明，其在效果和效率上均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;NLGCL是一种有效且高效的对比学习方法，适用于解决推荐系统中的数据稀疏性问题，并具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs)在协同过滤中广泛应用，用于捕捉用户-物品的高阶关系。为了解决推荐系统中的数据稀疏性问题，Graph Contrastive Learning (GCL)作为一种新兴范式，通过最大化对比视图之间的互信息来提高推荐效果。然而，现有的GCL方法依赖于引入语义无关噪声的增强技术，这导致了显著的计算和存储成本，限制了其有效性和效率。为了克服这些挑战，我们提出了NLGCL，一种新颖的对比学习框架，它利用GNNs中相邻层之间的自然对比视图。通过将每个节点及其下一层的邻居视为正对，其他节点视为负对，NLGCL避免了基于增强技术的噪声，同时保持了语义相关性。这种范式消除了昂贵的视图构建和存储，使其在计算上高效且适用于现实场景。在四个公开数据集上的大量实验表明，NLGCL在效果和效率上均优于最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are widely used in collaborative filtering tocapture high-order user-item relationships. To address the data sparsityproblem in recommendation systems, Graph Contrastive Learning (GCL) has emergedas a promising paradigm that maximizes mutual information between contrastiveviews. However, existing GCL methods rely on augmentation techniques thatintroduce semantically irrelevant noise and incur significant computational andstorage costs, limiting effectiveness and efficiency.  To overcome these challenges, we propose NLGCL, a novel contrastive learningframework that leverages naturally contrastive views between neighbor layerswithin GNNs. By treating each node and its neighbors in the next layer aspositive pairs, and other nodes as negatives, NLGCL avoids augmentation-basednoise while preserving semantic relevance. This paradigm eliminates costly viewconstruction and storage, making it computationally efficient and practical forreal-world scenarios. Extensive experiments on four public datasets demonstratethat NLGCL outperforms state-of-the-art baselines in effectiveness andefficiency.</description>
      <author>example@mail.com (Jinfeng Xu, Zheyu Chen, Shuo Yang, Jinze Li, Hewei Wang, Wei Wang, Xiping Hu, Edith Ngai)</author>
      <guid isPermaLink="false">2507.07522v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Towards High-Resolution 3D Anomaly Detection: A Scalable Dataset and Real-Time Framework for Subtle Industrial Defects</title>
      <link>http://arxiv.org/abs/2507.07435v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 8figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于生成真实且微小的3D异常的可扩展流程，并开发了MiniShift数据集，用于高分辨率3D异常检测，同时引入了Simple3D框架，该框架能够有效捕捉几何细节，实现实时推理。&lt;h4&gt;背景&lt;/h4&gt;在工业点云分析中，检测细微异常需要高分辨率空间数据，但现有的基准测试强调低分辨率输入。&lt;h4&gt;目的&lt;/h4&gt;解决高分辨率数据与低分辨率输入之间的差异。&lt;h4&gt;方法&lt;/h4&gt;提出了一个可扩展的流程来生成真实和微小的3D异常，开发了包含2,577个点云的MiniShift数据集，每个点云有500,000个点，异常占用总点数的不到1%。引入了Simple3D框架，该框架集成了多尺度邻域描述符（MSND）和局部特征空间聚合（LFSA）。&lt;h4&gt;主要发现&lt;/h4&gt;Simple3D在MiniShift和现有基准测试上进行了广泛的评估，结果显示其在准确性和速度方面都超越了最先进的方法，强调了高分辨率数据和有效特征聚合在推进实际3D异常检测中的关键作用。&lt;h4&gt;结论&lt;/h4&gt;高分辨率数据和有效的特征聚合对于提高3D异常检测的实践至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在工业点云分析中，检测细微异常需要高分辨率空间数据，然而现有的基准测试却强调低分辨率输入。为了解决这一差异，我们提出了一种可扩展的流程，用于生成真实且微小的3D异常。采用这一流程，我们开发了MiniShift，这是首个高分辨率3D异常检测数据集，包含2,577个点云，每个点云有500,000个点，异常占总点数的不到1%。我们进一步引入了Simple3D，这是一个高效的框架，集成了多尺度邻域描述符（MSND）和局部特征空间聚合（LFSA），以最小化的计算开销捕捉复杂的几何细节，实现了超过20 fps的实时推理。在MiniShift和现有基准测试上的广泛评估表明，Simple3D在准确性和速度上都超越了最先进的方法，突出了高分辨率数据和有效特征聚合在推进实际3D异常检测中的关键作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In industrial point cloud analysis, detecting subtle anomalies demandshigh-resolution spatial data, yet prevailing benchmarks emphasizelow-resolution inputs. To address this disparity, we propose a scalablepipeline for generating realistic and subtle 3D anomalies. Employing thispipeline, we developed MiniShift, the inaugural high-resolution 3D anomalydetection dataset, encompassing 2,577 point clouds, each with 500,000 pointsand anomalies occupying less than 1\% of the total. We further introduceSimple3D, an efficient framework integrating Multi-scale NeighborhoodDescriptors (MSND) and Local Feature Spatial Aggregation (LFSA) to captureintricate geometric details with minimal computational overhead, achievingreal-time inference exceeding 20 fps. Extensive evaluations on MiniShift andestablished benchmarks demonstrate that Simple3D surpasses state-of-the-artmethods in both accuracy and speed, highlighting the pivotal role ofhigh-resolution data and effective feature aggregation in advancing practical3D anomaly detection.</description>
      <author>example@mail.com (Yuqi Cheng, Yihan Sun, Hui Zhang, Weiming Shen, Yunkang Cao)</author>
      <guid isPermaLink="false">2507.07435v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding</title>
      <link>http://arxiv.org/abs/2507.07984v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, a benchmark designed to evaluate Online Spatio-Temporal  understanding from the perspective of an agent actively exploring a scene.  Project Page: https://rbler1234.github.io/OSTBench.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了多模态大型语言模型（MLLMs）在视觉和语言整合方面的最新进展，并提出了一个名为OST-Bench的新基准，用于评估在线时空理解能力。&lt;h4&gt;背景&lt;/h4&gt;现有基准主要在离线设置下使用预录制的输入来评估模型，而本文提出的OST-Bench旨在评估模型在实时探索场景时的在线时空理解能力。&lt;h4&gt;目的&lt;/h4&gt;通过引入OST-Bench，旨在更好地反映现实世界中具身感知的挑战，并评估MLLMs在复杂时空推理任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;OST-Bench基于高效的数据收集流程，包含从ScanNet、Matterport3D和ARKitScenes收集的1.4k个场景和10k个问答对。研究人员在OST-Bench上评估了多个领先的MLLMs。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，MLLMs在需要复杂时空推理的任务上表现不佳，在线设置下，随着探索范围扩大和记忆增长，其准确性下降。实验分析还揭示了模型中常见的错误模式，并指出复杂线索基础上的空间推理需求以及长期记忆检索需求显著降低了模型性能。&lt;h4&gt;结论&lt;/h4&gt;本文强调了在线具身推理的核心挑战，并提供了代码、数据集和基准，以促进该领域的研究和开发。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent advances in multimodal large language models (MLLMs) have shown remarkable capabilities in integrating vision and language for complex reasoning. While most existing benchmarks evaluate models under offline settings with a fixed set of pre-recorded inputs, we introduce OST-Bench, a benchmark designed to evaluate Online Spatio-Temporal understanding from the perspective of an agent actively exploring a scene. The Online aspect emphasizes the need to process and reason over incrementally acquired observations, while the Spatio-Temporal component requires integrating current visual inputs with historical memory to support dynamic spatial reasoning. OST-Bench better reflects the challenges of real-world embodied perception. Built on an efficient data collection pipeline, OST-Bench consists of 1.4k scenes and 10k question-answer pairs collected from ScanNet, Matterport3D, and ARKitScenes. We evaluate several leading MLLMs on OST-Bench and observe that they fall short on tasks requiring complex spatio-temporal reasoning. Under the online setting, their accuracy declines as the exploration horizon extends and the memory grows. Through further experimental analysis, we identify common error patterns across models and find that both complex clue-based spatial reasoning demands and long-term memory retrieval requirements significantly drop model performance along two separate axes, highlighting the core challenges that must be addressed to improve online embodied reasoning. To foster further research and development in the field, our codes, dataset, and benchmark are available. Our project page is: https://rbler1234.github.io/OSTBench.github.io/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in multimodal large language models (MLLMs) have shownremarkable capabilities in integrating vision and language for complexreasoning. While most existing benchmarks evaluate models under offlinesettings with a fixed set of pre-recorded inputs, we introduce OST-Bench, abenchmark designed to evaluate Online Spatio-Temporal understanding from theperspective of an agent actively exploring a scene. The Online aspectemphasizes the need to process and reason over incrementally acquiredobservations, while the Spatio-Temporal component requires integrating currentvisual inputs with historical memory to support dynamic spatial reasoning.OST-Bench better reflects the challenges of real-world embodied perception.Built on an efficient data collection pipeline, OST-Bench consists of 1.4kscenes and 10k question-answer pairs collected from ScanNet, Matterport3D, andARKitScenes. We evaluate several leading MLLMs on OST-Bench and observe thatthey fall short on tasks requiring complex spatio-temporal reasoning. Under theonline setting, their accuracy declines as the exploration horizon extends andthe memory grows. Through further experimental analysis, we identify commonerror patterns across models and find that both complex clue-based spatialreasoning demands and long-term memory retrieval requirements significantlydrop model performance along two separate axes, highlighting the corechallenges that must be addressed to improve online embodied reasoning. Tofoster further research and development in the field, our codes, dataset, andbenchmark are available. Our project page is:https://rbler1234.github.io/OSTBench.github.io/</description>
      <author>example@mail.com (JingLi Lin, Chenming Zhu, Runsen Xu, Xiaohan Mao, Xihui Liu, Tai Wang, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2507.07984v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Single-pass Adaptive Image Tokenization for Minimum Program Search</title>
      <link>http://arxiv.org/abs/2507.07995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code at: https://github.com/ShivamDuggal4/karl Keywords:  Representation Learning, Adaptive Tokenization, Compression, Algorithmic  Information Theory, Kolmogorov Complexity, Upside-Down RL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KARL的单次遍历自适应标记器，它根据图像内容的复杂度动态分配标记长度，并通过近似Kolmogorov复杂度来预测合适的标记数量。&lt;h4&gt;背景&lt;/h4&gt;大多数视觉表示学习系统使用固定长度的表示，忽略了输入数据复杂度或熟悉度的变化。&lt;h4&gt;目的&lt;/h4&gt;提出一种自适应标记器，以更有效地表示图像内容。&lt;h4&gt;方法&lt;/h4&gt;KARL通过单次前向传递预测图像的适当标记数量，并在达到近似Kolmogorov复杂度时停止。其训练过程类似于向上的强化学习范式，学习根据期望的重构质量条件性地预测标记停止。&lt;h4&gt;主要发现&lt;/h4&gt;KARL在单次遍历中匹配了最近自适应标记器的性能，并提出了KARL的扩展定律，分析了编码器/解码器大小、连续与离散标记化等因素的作用。&lt;h4&gt;结论&lt;/h4&gt;KARL通过将自适应图像标记化与算法信息理论联系起来，揭示了图像复杂度（Kolmogorov复杂度）与人类直觉之间的相关性。&lt;h4&gt;翻译&lt;/h4&gt;根据算法信息理论（AIT），智能表示将数据压缩成最短的程序，以重建其内容，展现出低的Kolmogorov复杂度（KC）。相比之下，大多数视觉表示学习系统对所有输入使用固定长度的表示，忽略了复杂度或熟悉度的变化。最近的自适应标记化方法通过分配可变长度的表示来解决这个问题，但通常需要测试时在多个编码中搜索以找到最预测的一个。受Kolmogorov复杂度原理的启发，我们提出了一种单次遍历自适应标记器KARL，它在一个前向传递中预测图像的适当标记数量，一旦达到其近似KC就停止。标记计数作为最小描述长度的代理。KARL的训练过程与向上的强化学习范式相似，因为它学习根据期望的重构质量条件性地预测标记停止。KARL在单次遍历中匹配了最近自适应标记器的性能。我们提出了KARL的扩展定律，分析了编码器/解码器大小、连续与离散标记化等因素的作用。此外，我们还提供了一项概念研究，将自适应图像标记化与算法信息理论进行比较，检查了图像复杂度（KC）在结构对噪声、在分布与不在分布的熟悉度等轴上的预测，揭示了与人类直觉的一致性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; According to Algorithmic Information Theory (AIT) -- Intelligentrepresentations compress data into the shortest possible program that canreconstruct its content, exhibiting low Kolmogorov Complexity (KC). Incontrast, most visual representation learning systems use fixed-lengthrepresentations for all inputs, ignoring variations in complexity orfamiliarity. Recent adaptive tokenization methods address this by allocatingvariable-length representations but typically require test-time search overmultiple encodings to find the most predictive one. Inspired by KolmogorovComplexity principles, we propose a single-pass adaptive tokenizer, KARL, whichpredicts the appropriate number of tokens for an image in a single forwardpass, halting once its approximate KC is reached. The token count serves as aproxy for the minimum description length. KARL's training procedure closelyresembles the Upside-Down Reinforcement Learning paradigm, as it learns toconditionally predict token halting based on a desired reconstruction quality.KARL matches the performance of recent adaptive tokenizers while operating in asingle pass. We present scaling laws for KARL, analyzing the role ofencoder/decoder size, continuous vs. discrete tokenization and more.Additionally, we offer a conceptual study drawing an analogy between AdaptiveImage Tokenization and Algorithmic Information Theory, examining the predictedimage complexity (KC) across axes such as structure vs. noise and in- vs.out-of-distribution familiarity -- revealing alignment with human intuition.</description>
      <author>example@mail.com (Shivam Duggal, Sanghyun Byun, William T. Freeman, Antonio Torralba, Phillip Isola)</author>
      <guid isPermaLink="false">2507.07995v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Credit Risk Analysis for SMEs Using Graph Neural Networks in Supply Chain</title>
      <link>http://arxiv.org/abs/2507.07854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The paper will be published on 2025 International Conference on Big  Data, Artificial Intelligence and Digital Economy&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的框架，用于分析中小企业（SMEs）的信用风险，特别是对于缺乏直接信用记录的在线贷款机构。该框架利用交易和社会数据来映射空间依赖性并预测贷款违约风险。&lt;h4&gt;背景&lt;/h4&gt;中小企业在现代经济中至关重要，但它们的信用风险评估常常面临数据稀缺的问题，尤其是对于缺乏直接信用记录的在线贷款机构。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效评估中小企业信用风险的工具。&lt;h4&gt;方法&lt;/h4&gt;该研究引入了一个基于图神经网络（GNN）的框架，利用交易和社会数据来分析中小企业之间的互动，并预测贷款违约风险。&lt;h4&gt;主要发现&lt;/h4&gt;在Discover和Ant Credit的真实数据集上进行的测试表明，该GNN框架在供应链分析和违约预测方面优于传统的和其它GNN基线，供应链分析的AUC为0.995，违约预测的AUC为0.701。此外，该框架有助于监管机构模拟供应链中断对银行的影响，准确预测因原材料短缺导致的贷款违约，并为联邦储备的压力测试提供关键数据。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法为评估中小企业信用风险提供了一个可扩展、有效的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small and Medium-sized Enterprises (SMEs) are vital to the modern economy,yet their credit risk analysis often struggles with scarce data, especially foronline lenders lacking direct credit records. This paper introduces a GraphNeural Network (GNN)-based framework, leveraging SME interactions fromtransaction and social data to map spatial dependencies and predict loandefault risks. Tests on real-world datasets from Discover and Ant Credit (23.4Mnodes for supply chain analysis, 8.6M for default prediction) show the GNNsurpasses traditional and other GNN baselines, with AUCs of 0.995 and 0.701 forsupply chain mining and default prediction, respectively. It also helpsregulators model supply chain disruption impacts on banks, accuratelyforecasting loan defaults from material shortages, and offers Federal Reservestress testers key data for CCAR risk buffers. This approach provides ascalable, effective tool for assessing SME credit risk.</description>
      <author>example@mail.com (Zizhou Zhang, Qinyan Shen, Zhuohuan Hu, Qianying Liu, Huijie Shen)</author>
      <guid isPermaLink="false">2507.07854v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Hybrid Approach for Time Series Forecasting: Period Estimation and Climate Data Analysis Using Unsupervised Learning and Spline Interpolation</title>
      <link>http://arxiv.org/abs/2507.07652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 Pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了应用于钦奈气候数据的时间序列预测的新方法。&lt;h4&gt;背景&lt;/h4&gt;该方法结合了两种不同的已建立的时间序列模型，利用它们在处理季节性和周期方面的优势。&lt;h4&gt;目的&lt;/h4&gt;通过精心设计的集成过程，结合这两种模型，实现优化的预测。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新的算法，使用无监督机器学习和样条插值技术来计算时间序列的周期。&lt;h4&gt;主要发现&lt;/h4&gt;该研究有助于推进预测技术，并为气候数据分析提供了有价值的见解。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为时间序列预测提供了新的视角，并有望提高气候数据预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This article explores a novel approach to time series forecasting applied tothe context of Chennai's climate data. Our methodology comprises two distinctestablished time series models, leveraging their strengths in handlingseasonality and periods. Notably, a new algorithm is developed to compute theperiod of the time series using unsupervised machine learning and splineinterpolation techniques. Through a meticulous ensembling process that combinesthese two models, we achieve optimized forecasts. This research contributes toadvancing forecasting techniques and offers valuable insights into climate dataanalysis.</description>
      <author>example@mail.com (Tanmay Kayal, Abhishek Das, U Saranya)</author>
      <guid isPermaLink="false">2507.07652v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Chunking for End-to-End Hierarchical Sequence Modeling</title>
      <link>http://arxiv.org/abs/2507.07955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的动态分块机制，并引入了层次网络（H-Net）模型，该模型能够在字节级别上自动学习内容依赖的分割策略，实现了真正的端到端训练，显著提高了数据效率。&lt;h4&gt;背景&lt;/h4&gt;尽管语言模型（LMs）在过去几年取得了巨大进步，但预处理步骤如分词仍然阻碍了端到端基础模型的实现。&lt;h4&gt;目的&lt;/h4&gt;提出新的技术，使模型能够自动学习内容依赖的分割策略，并实现端到端训练。&lt;h4&gt;方法&lt;/h4&gt;引入了动态分块机制，并将其与层次网络（H-Net）结合，通过多层抽象来提高模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;H-Net模型在字节级别上的性能优于基于BPE标记的强大Transformer语言模型。通过迭代层次结构，模型性能进一步提升，且在英语上表现出了显著的字符级鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;H-Net模型在弱分词机制的领域（如中文、代码或DNA序列）中表现尤为出色，显示出端到端模型从未处理数据中学习和扩展的潜力。&lt;h4&gt;翻译&lt;/h4&gt;尽管近年来语言模型（LMs）取得了惊人的进展，这主要归功于从为特定任务设计的专用模型转向基于强大架构（例如Transformer）的通用模型，这些模型从原始数据中学习一切，但预处理步骤（如分词）仍然是实现真正的端到端基础模型的障碍。我们介绍了一系列新技术，这些技术使动态分块机制成为可能，该机制能够自动学习内容-以及上下文-相关的分割策略，这些策略与模型的其他部分一起学习。将此纳入显式层次网络（H-Net）允许用单个端到端学习的模型替换（隐式层次化的）分词-语言模型-去分词管道。当计算和数据匹配时，一个层次结构阶段在字节级别上运行的H-Net比一个在BPE标记上运行的强大Transformer语言模型表现更好。将层次结构迭代到多个阶段通过建模多个抽象级别进一步提高了其性能，显示出与数据显著更好的扩展性，并匹配了其两倍大小的基于标记的Transformer。在英语上预训练的H-Nets表现出显著的字符级鲁棒性，并且在没有任何启发式方法或显式监督的情况下，定性地学习了有意义的数据依赖分块策略。最后，H-Net在分词管道上的改进在具有较弱分词启发式方法的语言和模态中得到了进一步的提高，例如中文和代码或DNA序列（在基线之上提高了近4倍的数据效率），显示出端到端模型从未处理数据中学习和扩展的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite incredible progress in language models (LMs) in recent years, largelyresulting from moving away from specialized models designed for specific tasksto general models based on powerful architectures (e.g. the Transformer) thatlearn everything from raw data, pre-processing steps such as tokenizationremain a barrier to true end-to-end foundation models. We introduce acollection of new techniques that enable a dynamic chunking mechanism whichautomatically learns content -- and context -- dependent segmentationstrategies learned jointly with the rest of the model. Incorporating this intoan explicit hierarchical network (H-Net) allows replacing the (implicitlyhierarchical) tokenization-LM-detokenization pipeline with a single modellearned fully end-to-end. When compute- and data- matched, an H-Net with onestage of hierarchy operating at the byte level outperforms a strong Transformerlanguage model operating over BPE tokens. Iterating the hierarchy to multiplestages further increases its performance by modeling multiple levels ofabstraction, demonstrating significantly better scaling with data and matchinga token-based Transformer of twice its size. H-Nets pretrained on English showsignificantly increased character-level robustness, and qualitatively learnmeaningful data-dependent chunking strategies without any heuristics orexplicit supervision. Finally, the H-Net's improvement over tokenized pipelinesis further increased in languages and modalities with weaker tokenizationheuristics, such as Chinese and code, or DNA sequences (nearly 4x improvementin data efficiency over baselines), showing the potential of true end-to-endmodels that learn and scale better from unprocessed data.</description>
      <author>example@mail.com (Sukjun Hwang, Brandon Wang, Albert Gu)</author>
      <guid isPermaLink="false">2507.07955v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>When Graph Contrastive Learning Backfires: Spectral Vulnerability and Defense in Recommendation</title>
      <link>http://arxiv.org/abs/2507.07436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了图对比学习（GCL）在增强推荐系统鲁棒性和泛化能力方面的潜力，同时揭示了其易受针对性促销攻击的脆弱性。&lt;h4&gt;背景&lt;/h4&gt;GCL通过利用大规模未标记数据来提高表示学习，在推荐系统中展现出巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;研究GCL在推荐系统中的应用，并揭示其潜在的脆弱性。&lt;h4&gt;方法&lt;/h4&gt;通过理论研究和实证验证，分析了GCL在推荐系统中的谱平滑效应及其对针对性促销攻击的影响，并提出了CLeaR攻击方法和SIM防御框架。&lt;h4&gt;主要发现&lt;/h4&gt;GCL通过对比优化产生的谱平滑效应会导致项目嵌入在表示空间中分散，无意中增强了目标项目的曝光度，从而增加了推荐系统对针对性促销攻击的易感性。&lt;h4&gt;结论&lt;/h4&gt;提出了CLeaR攻击方法和SIM防御框架，实验结果表明GCL推荐模型对CLeaR攻击更加脆弱，而SIM可以有效缓解这些脆弱性。&lt;h4&gt;翻译&lt;/h4&gt;Graph Contrastive Learning has demonstrated substantial promise in enhancing the robustness and generalization of recommender systems, particularly by enabling models to leverage large-scale unlabeled data for improved representation learning. However, in this paper, we reveal an unexpected vulnerability: the integration of GCL inadvertently increases the susceptibility of a recommender to targeted promotion attacks. Through both theoretical investigation and empirical validation, we identify the root cause as the spectral smoothing effect induced by contrastive optimization, which disperses item embeddings across the representation space and unintentionally enhances the exposure of target items. Building on this insight, we introduce CLeaR, a bi-level optimization attack method that deliberately amplifies spectral smoothness, enabling a systematic investigation of the susceptibility of GCL-based recommendation models to targeted promotion attacks. Our findings highlight the urgent need for robust countermeasures; in response, we further propose SIM, a spectral irregularity mitigation framework designed to accurately detect and suppress targeted items without compromising model performance. Extensive experiments on multiple benchmark datasets demonstrate that, compared to existing targeted promotion attacks, GCL-based recommendation models exhibit greater susceptibility when evaluated with CLeaR, while SIM effectively mitigates these vulnerabilities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning (GCL) has demonstrated substantial promise inenhancing the robustness and generalization of recommender systems,particularly by enabling models to leverage large-scale unlabeled data forimproved representation learning. However, in this paper, we reveal anunexpected vulnerability: the integration of GCL inadvertently increases thesusceptibility of a recommender to targeted promotion attacks. Through boththeoretical investigation and empirical validation, we identify the root causeas the spectral smoothing effect induced by contrastive optimization, whichdisperses item embeddings across the representation space and unintentionallyenhances the exposure of target items. Building on this insight, we introduceCLeaR, a bi-level optimization attack method that deliberately amplifiesspectral smoothness, enabling a systematic investigation of the susceptibilityof GCL-based recommendation models to targeted promotion attacks. Our findingshighlight the urgent need for robust countermeasures; in response, we furtherpropose SIM, a spectral irregularity mitigation framework designed toaccurately detect and suppress targeted items without compromising modelperformance. Extensive experiments on multiple benchmark datasets demonstratethat, compared to existing targeted promotion attacks, GCL-based recommendationmodels exhibit greater susceptibility when evaluated with CLeaR, while SIMeffectively mitigates these vulnerabilities.</description>
      <author>example@mail.com (Zongwei Wang, Min Gao, Junliang Yu, Shazia Sadiq, Hongzhi Yin, Ling Liu)</author>
      <guid isPermaLink="false">2507.07436v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>GGMotion: Group Graph Dynamics-Kinematics Networks for Human Motion Prediction</title>
      <link>http://arxiv.org/abs/2507.07515v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GGMotion的组图动力学-运动学网络，用于建模人类在三维空间中的运动，以更好地利用动力学和运动学先验信息。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常将人类姿态表示为抽象的图结构，忽略了关节之间的内在物理依赖关系，这增加了学习难度，并使模型易于生成不现实的运动。&lt;h4&gt;目的&lt;/h4&gt;通过模型来更有效地利用动力学和运动学先验信息，以生成更真实的人类运动。&lt;h4&gt;方法&lt;/h4&gt;GGMotion模型通过以下方式实现：提出一种新的径向场，用于图网络以捕捉更全面的空间时间依赖性；采用交互组模块和交互组内模块来捕捉不同尺度下关节的依赖关系；结合等变多层感知器（MLP）进行并行化的动力学-运动学传播，以更新关节位置特征；引入辅助损失来监督训练过程中的运动先验。&lt;h4&gt;主要发现&lt;/h4&gt;在三个标准基准（Human3.6M、CMU-Mocap和3DPW）上的大量实验表明，该方法在短期运动预测方面具有显著的性能优势。&lt;h4&gt;结论&lt;/h4&gt;GGMotion方法在生成更真实的人类运动方面表现出色，并且在短期运动预测任务中取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Human motion is a continuous physical process in 3D space, governed by complex dynamic and kinematic constraints. Existing methods typically represent the human pose as an abstract graph structure, neglecting the intrinsic physical dependencies between joints, which increases learning difficulty and makes the model prone to generating unrealistic motions. In this paper, we propose GGMotion, a group graph dynamics-kinematics network that models human topology in groups to better leverage dynamics and kinematics priors. To preserve the geometric equivariance in 3D space, we propose a novel radial field for the graph network that captures more comprehensive spatio-temporal dependencies by aggregating joint features through spatial and temporal edges. Inter-group and intra-group interaction modules are employed to capture the dependencies of joints at different scales. Combined with equivariant multilayer perceptrons (MLP), joint position features are updated in each group through parallelized dynamics-kinematics propagation to improve physical plausibility. Meanwhile, we introduce an auxiliary loss to supervise motion priors during training. Extensive experiments on three standard benchmarks, including Human3.6M, CMU-Mocap, and 3DPW, demonstrate the effectiveness and superiority of our approach, achieving a significant performance margin in short-term motion prediction. The code is available at https://github.com/inkcat520/GGMotion.git.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human motion is a continuous physical process in 3D space, governed bycomplex dynamic and kinematic constraints. Existing methods typically representthe human pose as an abstract graph structure, neglecting the intrinsicphysical dependencies between joints, which increases learning difficulty andmakes the model prone to generating unrealistic motions. In this paper, wepropose GGMotion, a group graph dynamics-kinematics network that models humantopology in groups to better leverage dynamics and kinematics priors. Topreserve the geometric equivariance in 3D space, we propose a novel radialfield for the graph network that captures more comprehensive spatio-temporaldependencies by aggregating joint features through spatial and temporal edges.Inter-group and intra-group interaction modules are employed to capture thedependencies of joints at different scales. Combined with equivariantmultilayer perceptrons (MLP), joint position features are updated in each groupthrough parallelized dynamics-kinematics propagation to improve physicalplausibility. Meanwhile, we introduce an auxiliary loss to supervise motionpriors during training. Extensive experiments on three standard benchmarks,including Human3.6M, CMU-Mocap, and 3DPW, demonstrate the effectiveness andsuperiority of our approach, achieving a significant performance margin inshort-term motion prediction. The code is available athttps://github.com/inkcat520/GGMotion.git.</description>
      <author>example@mail.com (Shuaijin Wan, Huaijiang Sun)</author>
      <guid isPermaLink="false">2507.07515v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning Tools for the IceCube-Gen2 Optical Array</title>
      <link>http://arxiv.org/abs/2507.07844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  For IC-Gen2 contributions: "Presented at the 39th International  Cosmic Ray Conference (ICRC2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了神经网络在IceCube-Gen2中子望远镜中的应用潜力，包括模拟光学模块的光子接受度、中微子重建以及噪声清洁。&lt;h4&gt;背景&lt;/h4&gt;IceCube-Gen2是IceCube观测站的高能扩展，将配备新的光学传感器，神经网络因其处理高维问题和快速推理时间的能力而成为潜在的应用工具。&lt;h4&gt;目的&lt;/h4&gt;研究神经网络在IceCube-Gen2中子望远镜中可能的应用，以提高数据处理效率。&lt;h4&gt;方法&lt;/h4&gt;使用神经网络模拟IceCube-Gen2光学模块的光子接受度，结合正常化流和变换器神经网络进行中微子重建，以及利用图神经网络进行噪声清洁。&lt;h4&gt;主要发现&lt;/h4&gt;神经网络能够有效地模拟光学模块的光子接受度，并在中微子重建和噪声清洁方面展现出良好的应用前景。&lt;h4&gt;结论&lt;/h4&gt;神经网络在IceCube-Gen2中具有广泛的应用潜力，有望提高数据处理效率和望远镜的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经网络（NNs）在未来的中子望远镜，如IceCube-Gen2（IceCube观测站计划中的高能扩展）中具有巨大的潜力。IceCube-Gen2将配备新的光学传感器，具有多个光电倍增管（PMTs），旨在提供全向灵敏度。神经网络擅长处理高维问题，并能够自然地融入这些新传感器的增加复杂性。此外，它们的快速推理时间使它们成为处理IceCube-Gen2预期的高事件率的理想候选者。本文贡献了神经网络在IceCube-Gen2冰中光学阵列中的潜在应用。首先，我们介绍了一种使用神经网络模拟IceCube-Gen2光学模块的光子接受度的方法，该方法利用了模块的固有对称性。其次，我们展示了基于神经网络的中微子重建工作的进展，包括结合正常化流和变换器神经网络的新型IceCube技术的应用。最后，我们描述了基于节点分类的图神经网络（GNNs）在噪声清洁应用中的当前进展，该方法已经显示出在即将到来的低能扩展IceCube-Upgrade中的良好结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural networks (NNs) have a great potential for future neutrino telescopessuch as IceCube-Gen2, the planned high-energy extension of the IceCubeobservatory. IceCube-Gen2 will feature new optical sensors with multiplephotomultiplier tubes (PMTs) designed to provide omnidirectional sensitivity.Neural networks excel at handling high-dimensional problems and can naturallyincorporate the increased complexity of these new sensors. Additionally, theirfast inference time makes them promising candidates for handling the high eventrates expected from IceCube-Gen2.  This contribution presents potential applications of neural networks in theIceCube-Gen2 in-ice optical array. First, we introduce a method to simulate theIceCube-Gen2 optical modules' photon acceptance using a NN that leverages themodules' inherent symmetries. Secondly, we present the status of neutrinoNN-based reconstruction efforts, including the adaptation of a novel IceCubetechnique that combines normalizing flows with transformer NNs. Finally, wedescribe current progress in noise cleaning applications based on nodeclassification with graph neural networks (GNNs), a method that has alreadyshown promising results for the forthcoming low-energy extension,IceCube-Upgrade.</description>
      <author>example@mail.com (Francisco Javier Vara Carbonell, Jonas Selter)</author>
      <guid isPermaLink="false">2507.07844v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes</title>
      <link>http://arxiv.org/abs/2507.07781v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为Sextsc{urprise}3D的新数据集，用于评估复杂3D场景中的语言引导空间推理分割，旨在促进空间感知AI的发展。&lt;h4&gt;背景&lt;/h4&gt;语言和3D感知的整合对于具身AI和机器人系统感知、理解和交互物理世界至关重要。空间推理在当前3D视觉-语言研究中尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，Sextsc{urprise}3D旨在评估语言引导的空间推理分割，并促进空间感知AI的发展。&lt;h4&gt;方法&lt;/h4&gt;Sextsc{urprise}3D包含超过200k个来自ScanNet++ v2的视觉语言对，涵盖了900多个详细的室内场景和超过2.8k个独特的物体类别。数据集中包含89k+个没有物体名称的人造空间查询，以减轻空间理解中的捷径偏见。&lt;h4&gt;主要发现&lt;/h4&gt;初始基准测试表明，当前最先进的专家3D视觉基础方法和3D-LLM在空间推理方面存在显著挑战，强调了我们的数据集和3D空间推理分割（3D-SRS）基准套件的重要性。&lt;h4&gt;结论&lt;/h4&gt;Sextsc{urprise}3D和3D-SRS旨在促进空间感知AI的进步，为有效的具身交互和机器人规划铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;The integration of language and 3D perception is critical for embodied AI and robotic systems to perceive, understand, and interact with the physical world. Spatial reasoning, a key capability for understanding spatial relationships between objects, remains underexplored in current 3D vision-language research. Existing datasets often mix semantic cues (e.g., object name) with spatial context, leading models to rely on superficial shortcuts rather than genuinely interpreting spatial relationships. To address this gap, we introduce Sextsc{urprise}3D, a novel dataset designed to evaluate language-guided spatial reasoning segmentation in complex 3D scenes. Sextsc{urprise}3D consists of more than 200k vision language pairs across 900+ detailed indoors scenes from ScanNet++ v2, including more than 2.8k unique object classes. The dataset contains 89k+ human-annotated spatial queries deliberately crafted without object name, thereby mitigating shortcut biases in spatial understanding. These queries comprehensively cover various spatial reasoning skills, such as relative position, narrative perspective, parametric perspective, and absolute distance reasoning. Initial benchmarks demonstrate significant challenges for current state-of-the-art expert 3D visual grounding methods and 3D-LLMs, underscoring the necessity of our dataset and the accompanying 3D Spatial Reasoning Segmentation (3D-SRS) benchmark suite. Sextsc{urprise}3D and 3D-SRS aim to facilitate advancements in spatially aware AI, paving the way for effective embodied interaction and robotic planning. The code and datasets can be found in https://github.com/liziwennba/SUPRISE.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of language and 3D perception is critical for embodied AI androbotic systems to perceive, understand, and interact with the physical world.Spatial reasoning, a key capability for understanding spatial relationshipsbetween objects, remains underexplored in current 3D vision-language research.Existing datasets often mix semantic cues (e.g., object name) with spatialcontext, leading models to rely on superficial shortcuts rather than genuinelyinterpreting spatial relationships. To address this gap, we introduceS\textsc{urprise}3D, a novel dataset designed to evaluate language-guidedspatial reasoning segmentation in complex 3D scenes. S\textsc{urprise}3Dconsists of more than 200k vision language pairs across 900+ detailed indoorscenes from ScanNet++ v2, including more than 2.8k unique object classes. Thedataset contains 89k+ human-annotated spatial queries deliberately craftedwithout object name, thereby mitigating shortcut biases in spatialunderstanding. These queries comprehensively cover various spatial reasoningskills, such as relative position, narrative perspective, parametricperspective, and absolute distance reasoning. Initial benchmarks demonstratesignificant challenges for current state-of-the-art expert 3D visual groundingmethods and 3D-LLMs, underscoring the necessity of our dataset and theaccompanying 3D Spatial Reasoning Segmentation (3D-SRS) benchmark suite.S\textsc{urprise}3D and 3D-SRS aim to facilitate advancements in spatiallyaware AI, paving the way for effective embodied interaction and roboticplanning. The code and datasets can be found inhttps://github.com/liziwennba/SUPRISE.</description>
      <author>example@mail.com (Jiaxin Huang, Ziwen Li, Hanlve Zhang, Runnan Chen, Xiao He, Yandong Guo, Wenping Wang, Tongliang Liu, Mingming Gong)</author>
      <guid isPermaLink="false">2507.07781v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Perceptual Distortions and Autonomous Representation Learning in a Minimal Robotic System</title>
      <link>http://arxiv.org/abs/2507.07845v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2 authors, 23 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了自主代理，特别是在机器人领域，如何通过感知信息来感知和导航环境，并探讨了感知扭曲对自主表示学习的影响。&lt;h4&gt;背景&lt;/h4&gt;自主代理，尤其是机器人，依赖感官信息来感知和导航环境，但这些感官输入往往是不完美的，导致代理对世界的内部表示出现扭曲。&lt;h4&gt;目的&lt;/h4&gt;通过使用一个简单的两轮机器人系统，研究感知扭曲的本质及其对自主表示学习的影响。&lt;h4&gt;方法&lt;/h4&gt;使用一个配备距离传感器和指南针的模拟两轮机器人，在简单方形环境中进行随机探索，分析机器人的传感器数据。&lt;h4&gt;主要发现&lt;/h4&gt;尽管存在感知扭曲，但研究人员在感知空间中识别出与物理环境相关联的涌现结构，揭示了机器人如何在没有明确空间信息的情况下自主学习结构化的表示以进行导航。&lt;h4&gt;结论&lt;/h4&gt;这项工作有助于理解具身认知、最小代理以及感知在自生成导航策略中的角色。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了自主代理，特别是在机器人领域，如何通过感知信息来感知和导航环境，并探讨了感知扭曲对自主表示学习的影响。背景是自主代理，尤其是机器人，依赖感官信息来感知和导航环境，但这些感官输入往往是不完美的，导致代理对世界的内部表示出现扭曲。目的是通过使用一个简单的两轮机器人系统，研究感知扭曲的本质及其对自主表示学习的影响。方法是使用一个配备距离传感器和指南针的模拟两轮机器人，在简单方形环境中进行随机探索，分析机器人的传感器数据。主要发现是尽管存在感知扭曲，但研究人员在感知空间中识别出与物理环境相关联的涌现结构，揭示了机器人如何在没有明确空间信息的情况下自主学习结构化的表示以进行导航。结论是这项工作有助于理解具身认知、最小代理以及感知在自生成导航策略中的角色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous agents, particularly in the field of robotics, rely on sensoryinformation to perceive and navigate their environment. However, these sensoryinputs are often imperfect, leading to distortions in the agent's internalrepresentation of the world. This paper investigates the nature of theseperceptual distortions and how they influence autonomous representationlearning using a minimal robotic system. We utilize a simulated two-wheeledrobot equipped with distance sensors and a compass, operating within a simplesquare environment. Through analysis of the robot's sensor data during randomexploration, we demonstrate how a distorted perceptual space emerges. Despitethese distortions, we identify emergent structures within the perceptual spacethat correlate with the physical environment, revealing how the robotautonomously learns a structured representation for navigation without explicitspatial information. This work contributes to the understanding of embodiedcognition, minimal agency, and the role of perception in self-generatednavigation strategies in artificial life.</description>
      <author>example@mail.com (David Warutumo, Ciira wa Maina)</author>
      <guid isPermaLink="false">2507.07845v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Scaling RL to Long Videos</title>
      <link>http://arxiv.org/abs/2507.07966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and models are available at https://github.com/NVlabs/Long-RL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种全栈框架，通过强化学习将视觉语言模型（VLMs）扩展到长视频推理，并解决了长视频推理的独特挑战。&lt;h4&gt;背景&lt;/h4&gt;长视频推理存在挑战，需要特殊的方法和工具来处理。&lt;h4&gt;目的&lt;/h4&gt;提高长视频推理的性能，并构建一个能够处理长视频的VLMs。&lt;h4&gt;方法&lt;/h4&gt;通过以下三个关键组件实现：(1) 创建了一个大规模数据集LongVideo-Reason，包含52K个长视频问答对，具有高质量的推理标注；(2) 开发了一个两阶段训练流程，包括思维链监督微调和强化学习；(3) 设计了名为Multi-modal Reinforcement Sequence Parallelism（MR-SP）的训练基础设施，用于长视频强化学习，利用序列并行性和基于长语言模型（LLM）的引擎，使用缓存的视频嵌入进行高效的 rollout 和预填充。&lt;h4&gt;主要发现&lt;/h4&gt;LongVILA-R1-7B在长视频问答基准测试中表现出色，优于Video-R1-7B，并在我们的LongVideo-Reason-eval基准测试中与Gemini-1.5-Pro相当。MR-SP系统在长视频强化学习训练中实现了高达2.1倍的速度提升。LongVILA-R1随着输入视频帧数的增加，表现出持续的性能提升。&lt;h4&gt;结论&lt;/h4&gt;LongVILA-R1标志着在VLMs中进行长视频推理的重要一步，同时发布的训练系统支持多种模态、模型和图像/视频生成模型的强化学习训练。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一个全栈框架，该框架利用强化学习将推理扩展到视觉语言模型（VLMs）的长视频。我们通过整合三个关键组件来解决长视频推理的独特挑战：(1) 创建了一个包含52K个长视频问答对的大规模数据集LongVideo-Reason，涵盖了体育、游戏和vlog等多样化领域的优质推理标注；(2) 开发了一个两阶段训练流程，通过思维链监督微调（CoT-SFT）和强化学习（RL）扩展VLMs；(3) 设计了一个名为多模态强化序列并行（MR-SP）的训练基础设施，用于长视频强化学习，结合序列并行性和基于长语言模型（LLM）的引擎，使用缓存的视频嵌入进行高效的 rollout 和预填充。在实验中，LongVILA-R1-7B在长视频问答基准测试中取得了优异的性能，如VideoMME。它还优于Video-R1-7B，并在我们的LongVideo-Reason-eval基准测试中在时间推理、目标和目的推理、空间推理和情节推理方面与Gemini-1.5-Pro相当。值得注意的是，我们的MR-SP系统在长视频强化学习训练中实现了高达2.1倍的速度提升。LongVILA-R1随着输入视频帧数的增加，表现出持续的性能提升。LongVILA-R1标志着在VLMs中进行长视频推理的重要一步。此外，我们还发布了我们的训练系统，该系统支持在多种模态（视频、文本和音频）、各种模型（VILA和Qwen系列）以及图像和视频生成模型上进行强化学习训练。在一个A100节点（8个GPU）上，它支持长达一小时的视频（例如，3,600帧/约256k个token）的强化学习训练。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a full-stack framework that scales up reasoning invision-language models (VLMs) to long videos, leveraging reinforcementlearning. We address the unique challenges of long video reasoning byintegrating three critical components: (1) a large-scale dataset,LongVideo-Reason, comprising 52K long video QA pairs with high-qualityreasoning annotations across diverse domains such as sports, games, and vlogs;(2) a two-stage training pipeline that extends VLMs with chain-of-thoughtsupervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) atraining infrastructure for long video RL, named Multi-modal ReinforcementSequence Parallelism (MR-SP), which incorporates sequence parallelism and avLLM-based engine tailored for long video, using cached video embeddings forefficient rollout and prefilling. In experiments, LongVILA-R1-7B achievesstrong performance on long video QA benchmarks such as VideoMME. It alsooutperforms Video-R1-7B and even matches Gemini-1.5-Pro across temporalreasoning, goal and purpose reasoning, spatial reasoning, and plot reasoning onour LongVideo-Reason-eval benchmark. Notably, our MR-SP system achieves up to2.1x speedup on long video RL training. LongVILA-R1 demonstrates consistentperformance gains as the number of input video frames scales. LongVILA-R1 marksa firm step towards long video reasoning in VLMs. In addition, we release ourtraining system for public availability that supports RL training on variousmodalities (video, text, and audio), various models (VILA and Qwen series), andeven image and video generation models. On a single A100 node (8 GPUs), itsupports RL training on hour-long videos (e.g., 3,600 frames / around 256ktokens).</description>
      <author>example@mail.com (Yukang Chen, Wei Huang, Baifeng Shi, Qinghao Hu, Hanrong Ye, Ligeng Zhu, Zhijian Liu, Pavlo Molchanov, Jan Kautz, Xiaojuan Qi, Sifei Liu, Hongxu Yin, Yao Lu, Song Han)</author>
      <guid isPermaLink="false">2507.07966v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable EEG-to-Image Generation with Semantic Prompts</title>
      <link>http://arxiv.org/abs/2507.07157v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Actionable Interpretability Workshop (non-archival) at the 42  International Conference on Machine Learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过将脑电信号与多级语义描述进行对齐，实现了从脑电信号到视觉体验的解码，为神经科学和可解释人工智能提供了新的可能性。&lt;h4&gt;背景&lt;/h4&gt;脑电图（EEG）虽然易于获取且时间分辨率高，但在空间细节上存在限制，这阻碍了图像的重建。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于文本的框架，通过将脑电信号与由大型语言模型生成的多级语义描述对齐，来实现视觉解码。&lt;h4&gt;方法&lt;/h4&gt;使用基于transformer的EEG编码器通过对比学习将脑活动映射到这些描述上；在推理过程中，通过投影头检索描述嵌入，以条件化预训练的潜在扩散模型进行图像生成。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在EEGCVPR数据集上实现了最先进的视觉解码，并且与已知的神经认知路径有可解释的对应关系。主导的EEG-描述关联反映了从感知图像中提取的不同语义层级的重要性。&lt;h4&gt;结论&lt;/h4&gt;该模型展示了结构化语义介导如何实现从EEG到认知上对齐的视觉解码。&lt;h4&gt;翻译&lt;/h4&gt;解码视觉体验的脑电信号为神经科学和可解释人工智能提供了激动人心的可能性。虽然脑电图（EEG）易于获取且时间分辨率高，但其空间细节的限制阻碍了图像重建。我们的模型通过将脑电信号与大型语言模型生成的从物体级别到抽象主题的多级语义描述对齐，绕过直接从EEG到图像生成的过程。基于transformer的EEG编码器通过对比学习将这些描述映射到脑活动上。在推理过程中，通过投影头检索的描述嵌入通过预训练的潜在扩散模型进行图像生成的条件化。这种文本介导的框架在EEGCVPR数据集上实现了最先进的视觉解码，并与已知的神经认知路径有可解释的对应关系。主导的EEG-描述关联反映了从感知图像中提取的不同语义层级的重要性。显著图和t-SNE投影揭示了头皮上的语义拓扑。我们的模型展示了结构化语义介导如何实现从EEG到认知上对齐的视觉解码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decoding visual experience from brain signals offers exciting possibilitiesfor neuroscience and interpretable AI. While EEG is accessible and temporallyprecise, its limitations in spatial detail hinder image reconstruction. Ourmodel bypasses direct EEG-to-image generation by aligning EEG signals withmultilevel semantic captions -- ranging from object-level to abstract themes --generated by a large language model. A transformer-based EEG encoder maps brainactivity to these captions through contrastive learning. During inference,caption embeddings retrieved via projection heads condition a pretrained latentdiffusion model for image generation. This text-mediated framework yieldsstate-of-the-art visual decoding on the EEGCVPR dataset, with interpretablealignment to known neurocognitive pathways. Dominant EEG-caption associationsreflected the importance of different semantic levels extracted from perceivedimages. Saliency maps and t-SNE projections reveal semantic topography acrossthe scalp. Our model demonstrates how structured semantic mediation enablescognitively aligned visual decoding from EEG.</description>
      <author>example@mail.com (Arshak Rezvani, Ali Akbari, Kosar Sanjar Arani, Maryam Mirian, Emad Arasteh, Martin J. McKeown)</author>
      <guid isPermaLink="false">2507.07157v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs</title>
      <link>http://arxiv.org/abs/2507.07595v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Context Pooling的新方法，旨在提升基于图神经网络（GNN）的模型在知识图谱（KG）中预测链接的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的基于GNN的模型在链接预测中，使用vanilla aggregation的方法对模型性能的提升没有显著影响。&lt;h4&gt;目的&lt;/h4&gt;增强GNN模型在KG中进行链接预测的能力。&lt;h4&gt;方法&lt;/h4&gt;Context Pooling是首次应用于KG的图池化方法，并能够为归纳设置生成查询特定的图。此外，该方法设计了两个指标：邻域精确度和邻域召回率，用于评估给定查询的邻居的逻辑相关性，从而在链接预测中仅识别逻辑上相关的邻居。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在48个设置中的42个中实现了最先进的性能，并在两个最先进的模型上应用于三个公开的转导和归纳数据集。&lt;h4&gt;结论&lt;/h4&gt;Context Pooling是一种通用的方法，能够显著提升GNN模型在KG中链接预测的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent investigations on the effectiveness of Graph Neural Network(GNN)-based models for link prediction in Knowledge Graphs (KGs) show thatvanilla aggregation does not significantly impact the model performance. Inthis paper, we introduce a novel method, named Context Pooling, to enhanceGNN-based models' efficacy for link predictions in KGs. To our best ofknowledge, Context Pooling is the first methodology that applies graph poolingin KGs. Additionally, Context Pooling is first-of-its-kind to enable thegeneration of query-specific graphs for inductive settings, where testingentities are unseen during training. Specifically, we devise two metrics,namely neighborhood precision and neighborhood recall, to assess the neighbors'logical relevance regarding the given queries, thereby enabling the subsequentcomprehensive identification of only the logically relevant neighbors for linkprediction. Our method is generic and assessed by being applied to twostate-of-the-art (SOTA) models on three public transductive and inductivedatasets, achieving SOTA performance in 42 out of 48 settings.</description>
      <author>example@mail.com (Zhixiang Su, Di Wang, Chunyan Miao)</author>
      <guid isPermaLink="false">2507.07595v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>MUVOD: A Novel Multi-view Video Object Segmentation Dataset and A Benchmark for 3D Segmentation</title>
      <link>http://arxiv.org/abs/2507.07519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MUVOD，一个用于在重建的真实场景中进行物体分割的多视图视频数据集。&lt;h4&gt;背景&lt;/h4&gt;基于神经网络辐射场（NeRF）和3D高斯分层（3D GS）的方法在静态场景的3D物体分割领域逐渐受到欢迎，但在动态场景的4D物体分割方面仍缺乏广泛和准确的多视图视频数据集。&lt;h4&gt;目的&lt;/h4&gt;提出MUVOD数据集，用于训练和评估多视图视频分割方法，并设立基准和评估指标。&lt;h4&gt;方法&lt;/h4&gt;MUVOD包含来自不同类型相机设备的17个场景，每个场景包含至少9个视图，最多46个视图，共计7830张RGB图像及其相应的4D运动分割掩码。此外，从MUVOD数据集中选择了一部分注释的多视图图像，用于3D物体分割任务的基准。&lt;h4&gt;主要发现&lt;/h4&gt;MUVOD数据集包含了73个类别的459个实例，可以作为多视图视频分割方法的基本基准。&lt;h4&gt;结论&lt;/h4&gt;MUVOD数据集为评估和促进多视图视频分割方法的发展提供了新的基准和评估工具，同时也为3D物体分割任务提供了一个更全面的基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经网络辐射场（NeRF）和3D高斯分层（3D GS）方法在静态场景的3D物体分割领域越来越受欢迎。这些方法在多种3D场景理解和编辑任务中显示出有效性。然而，由于缺乏足够广泛和准确的多视图视频数据集，4D动态场景的物体分割仍然是一个未被充分探索的领域。在本文中，我们提出了MUVOD，一个用于在重建的真实场景中训练和评估物体分割的新多视图视频数据集。17个选定的场景描述了各种室内或户外活动，这些场景来自不同数据集，这些数据集由不同类型的相机设备产生。每个场景至少包含9个视图，最多46个视图。我们提供了7830张RGB图像（每个视频30帧）及其相应的4D运动分割掩码，这意味着场景中的任何感兴趣的对象都可以在给定视图的时序帧之间或属于同一相机设备的不同视图之间进行跟踪。该数据集包含73个类别的459个实例，旨在作为评估多视图视频分割方法的基本基准。我们还提出了一种评估指标和基线分割方法，以鼓励和评估该演变领域的发展。此外，我们还提出了一种新的基准，该基准是从我们的MUVOD数据集中选择的注释多视图图像的子集，这些子集包含了不同场景中不同条件下50个不同对象，从而对最先进的3D物体分割方法进行了更全面的评估。我们提出的MUVOD数据集可在https://volumetric-repository.labs.b-com.com/#/muvod获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The application of methods based on Neural Radiance Fields (NeRF) and 3DGaussian Splatting (3D GS) have steadily gained popularity in the field of 3Dobject segmentation in static scenes. These approaches demonstrate efficacy ina range of 3D scene understanding and editing tasks. Nevertheless, the 4Dobject segmentation of dynamic scenes remains an underexplored field due to theabsence of a sufficiently extensive and accurately labelled multi-view videodataset. In this paper, we present MUVOD, a new multi-view video dataset fortraining and evaluating object segmentation in reconstructed real-worldscenarios. The 17 selected scenes, describing various indoor or outdooractivities, are collected from different sources of datasets originating fromvarious types of camera rigs. Each scene contains a minimum of 9 views and amaximum of 46 views. We provide 7830 RGB images (30 frames per video) withtheir corresponding segmentation mask in 4D motion, meaning that any object ofinterest in the scene could be tracked across temporal frames of a given viewor across different views belonging to the same camera rig. This dataset, whichcontains 459 instances of 73 categories, is intended as a basic benchmark forthe evaluation of multi-view video segmentation methods. We also present anevaluation metric and a baseline segmentation approach to encourage andevaluate progress in this evolving field. Additionally, we propose a newbenchmark for 3D object segmentation task with a subset of annotated multi-viewimages selected from our MUVOD dataset. This subset contains 50 objects ofdifferent conditions in different scenarios, providing a more comprehensiveanalysis of state-of-the-art 3D object segmentation methods. Our proposed MUVODdataset is available at https://volumetric-repository.labs.b-com.com/#/muvod.</description>
      <author>example@mail.com (Bangning Wei, Joshua Maraval, Meriem Outtas, Kidiyo Kpalma, Nicolas Ramin, Lu Zhang)</author>
      <guid isPermaLink="false">2507.07519v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Beyond the Linear Separability Ceiling</title>
      <link>http://arxiv.org/abs/2507.07574v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究视觉语言模型在抽象推理任务中的线性推理瓶颈，提出了解决方案。&lt;h4&gt;背景&lt;/h4&gt;目前大多数视觉语言模型在抽象推理任务中受到线性可分性的限制。&lt;h4&gt;目的&lt;/h4&gt;探究“线性推理瓶颈”并找出其根本原因。&lt;h4&gt;方法&lt;/h4&gt;引入线性可分性上限（LSC）作为评估指标，并使用后缀微调作为方法控制。&lt;h4&gt;主要发现&lt;/h4&gt;瓶颈源于语言模型推理路径的失败，而非感知问题。存在强大的潜伏推理路径，但复杂关系推理需要调整核心模型权重。&lt;h4&gt;结论&lt;/h4&gt;通过针对性的调整而非单纯的表示学习提升，可以实现稳健的推理。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大多数最先进的视觉语言模型（VLM）在抽象推理任务中似乎受到其视觉嵌入的线性可分性的限制。本研究通过引入线性可分性上限（LSC），即简单线性分类器在VLM视觉嵌入上的性能，来调查这个“线性推理瓶颈”。我们发现这个瓶颈是普遍存在的，并非源于感知能力不足，而是语言模型推理路径的失败。我们证明这是一个可解决的校准问题。然而，所需的干预措施是任务相关的：对于语义概念，激活现有路径就足够了；而对于复杂的关系推理，则需要调整核心模型权重。使用后缀微调作为方法控制，我们发现VLM中存在强大的潜伏推理路径。然而，对于需要更深层调整的复杂关系任务，尽管嵌入仍然保持良好的分离，但明确提高表示质量会导致模型在新提示格式上的失败。最终，这项工作为VLM分析提供了新的视角，表明稳健的推理是一个目标校准的问题，而不仅仅是改进表示学习的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most state-of-the-art Visual-Language Models (VLMs) are seemingly limited bythe linear separabilty of their visual embeddings on abstract reasoning tasks.This work investigates this "linear reasoning bottleneck" by introducing theLinear Separability Ceiling (LSC), the performance of a simple linearclassifier on a VLM's visual embeddings. We find this bottleneck is widespreadand stems not from poor perception, but from failures in the language model'sreasoning pathways. We demonstrate this is a solvable alignment issue. Therequired intervention, however, is task-dependent: activating existing pathwayssuffices for semantic concepts, while complex relational reasoning requiresadapting core model weights. Using postfix tuning as a methodological control,we find strong evidence for powerful, dormant reasoning pathways within VLMs.However, for complex relational tasks requiring deeper adaptation, explicitlyimproving representation quality causes the model to fail on new prompt formatsdespite its embeddings remaining well separated. Ultimately, this work providesa new lens for VLM analysis, showing that robust reasoning is a matter oftargeted alignment, not simply improved representation learning.</description>
      <author>example@mail.com (Enrico Vompa, Tanel Tammet, Mohit Vaishnav)</author>
      <guid isPermaLink="false">2507.07574v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>M$^2$-MFP: A Multi-Scale and Multi-Level Memory Failure Prediction Framework for Reliable Cloud Infrastructure</title>
      <link>http://arxiv.org/abs/2507.07144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为M$^2$-MFP的内存故障预测框架，旨在提高云基础设施的可靠性和可用性。&lt;h4&gt;背景&lt;/h4&gt;随着云计算服务在IT基础设施中的重要性日益增加，确保硬件可靠性对于维持高质量服务至关重要。内存故障对系统稳定性构成重大威胁，因此通过分析内存错误日志（即可纠正错误）进行准确的故障预测变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有内存故障预测方法的局限性，如基于规则的专家模型泛化能力有限和召回率低，以及自动特征提取方法性能不佳的问题。&lt;h4&gt;方法&lt;/h4&gt;M$^2$-MFP将可纠正错误（CEs）转换为多级二进制矩阵表示，并引入了二进制空间特征提取器（BSFE）来自动提取DIMM级和位级的特征。基于BSFE的输出，开发了一个双路径时间建模架构：1）时间片段模块，用于在观察窗口内聚合多级特征；2）时间点模块，使用在位级模式上训练的可解释规则生成树。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集和实际部署的实验中，M$^2$-MFP表现出优越性，显著优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;M$^2$-MFP是一种有效的内存故障预测框架，可以提高云基础设施的可靠性和可用性。&lt;h4&gt;翻译&lt;/h4&gt;As cloud services become increasingly integral to modern IT infrastructure,ensuring hardware reliability is essential to sustain high-quality service.Memory failures pose a significant threat to overall system stability, making accurate failure prediction through the analysis of memory error logs (i.e.,Correctable Errors) imperative. Existing memory failure prediction approaches have notable limitations: rule-based expert models suffer from limited generalizability and low recall rates, while automated feature extraction methods exhibit suboptimal performance. To address these limitations, we propose M$^2$-MFP: a Multi-scale and hierarchical memory failure prediction framework designed to enhance the reliability and availability of cloud infrastructure. M$^2$-MFP converts Correctable Errors (CEs) into multi-level binary matrix representations and introduces a Binary Spatial Feature Extractor (BSFE) to automatically extract high-order features at both DIMM-level and bit-level. Building upon the BSFE outputs, we develop a dual-path temporal modeling architecture: 1) a time-patch module that aggregates multi-level features within observation windows, and 2) a time-point module that employs interpretable rule-generation trees trained on bit-level patterns. Experiments on both benchmark datasets and real-world deployment show the superiority of M$^2$-MFP as it outperforms existing state-of-the-art methods by significant margins. Code and data are available at this repository:https://github.com/hwcloud-RAS/M2-MFP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737243&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As cloud services become increasingly integral to modern IT infrastructure,ensuring hardware reliability is essential to sustain high-quality service.Memory failures pose a significant threat to overall system stability, makingaccurate failure prediction through the analysis of memory error logs (i.e.,Correctable Errors) imperative. Existing memory failure prediction approacheshave notable limitations: rule-based expert models suffer from limitedgeneralizability and low recall rates, while automated feature extractionmethods exhibit suboptimal performance. To address these limitations, wepropose M$^2$-MFP: a Multi-scale and hierarchical memory failure predictionframework designed to enhance the reliability and availability of cloudinfrastructure. M$^2$-MFP converts Correctable Errors (CEs) into multi-levelbinary matrix representations and introduces a Binary Spatial Feature Extractor(BSFE) to automatically extract high-order features at both DIMM-level andbit-level. Building upon the BSFE outputs, we develop a dual-path temporalmodeling architecture: 1) a time-patch module that aggregates multi-levelfeatures within observation windows, and 2) a time-point module that employsinterpretable rule-generation trees trained on bit-level patterns. Experimentson both benchmark datasets and real-world deployment show the superiority ofM$^2$-MFP as it outperforms existing state-of-the-art methods by significantmargins. Code and data are available at this repository:https://github.com/hwcloud-RAS/M2-MFP.</description>
      <author>example@mail.com (Hongyi Xie, Min Zhou, Qiao Yu, Jialiang Yu, Zhenli Sheng, Hong Xie, Defu Lian)</author>
      <guid isPermaLink="false">2507.07144v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>LISTEN: Lightweight Industrial Sound-representable Transformer for Edge Notification</title>
      <link>http://arxiv.org/abs/2507.07879v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种轻量级的工业声音基础模型LISTEN，旨在解决深度学习在工业声学分析中的数据依赖问题，并实现边缘设备的实时应用。&lt;h4&gt;背景&lt;/h4&gt;深度学习在工业声学分析中的应用如异常检测和预测性维护，有助于提高制造效率和可靠性，但其依赖大量特定任务的标注数据集，限制了其广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为LISTEN的轻量级工业声音基础模型，以降低对大量标注数据集的依赖，并在边缘设备上实现实时应用。&lt;h4&gt;方法&lt;/h4&gt;通过知识蒸馏技术，将大型基础模型转换为小型模型，并使其在低成本的边缘设备上运行。&lt;h4&gt;主要发现&lt;/h4&gt;LISTEN模型在基准下游任务上的性能几乎与大型父模型相同，即使使用最小数据集和训练资源进行微调。&lt;h4&gt;结论&lt;/h4&gt;LISTEN模型可以集成到边缘设备的机器监控框架中，并在实际的制造环境中验证其性能和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;The paper introduces a lightweight industrial sound foundation model named LISTEN, aiming to address the data dependency issue in the application of deep learning in industrial acoustic analysis and to enable real-time deployment on edge devices.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based machine listening is broadening the scope of industrialacoustic analysis for applications like anomaly detection and predictivemaintenance, thereby improving manufacturing efficiency and reliability.Nevertheless, its reliance on large, task-specific annotated datasets for everynew task limits widespread implementation on shop floors. While emerging soundfoundation models aim to alleviate data dependency, they are too large andcomputationally expensive, requiring cloud infrastructure or high-end hardwarethat is impractical for on-site, real-time deployment. We address this gap withLISTEN (Lightweight Industrial Sound-representable Transformer for EdgeNotification), a kilobyte-sized industrial sound foundation model. Usingknowledge distillation, LISTEN runs in real-time on low-cost edge devices. Onbenchmark downstream tasks, it performs nearly identically to its much largerparent model, even when fine-tuned with minimal datasets and training resource.Beyond the model itself, we demonstrate its real-world utility by integratingLISTEN into a complete machine monitoring framework on an edge device with anIndustrial Internet of Things (IIoT) sensor and system, validating itsperformance and generalization capabilities on a live manufacturing shop floor.</description>
      <author>example@mail.com (Changheon Han, Yun Seok Kang, Yuseop Sim, Martin Byung-Guk Jun, Hyung Wook Park)</author>
      <guid isPermaLink="false">2507.07879v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>THUNDER: Tile-level Histopathology image UNDERstanding benchmark</title>
      <link>http://arxiv.org/abs/2507.07860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了THUNDER，一个用于数字病理学基础模型的瓷砖级别基准测试，旨在评估不同模型在多种数据集和下游任务中的性能，并比较它们的特征空间、预测的鲁棒性和不确定性。&lt;h4&gt;背景&lt;/h4&gt;在数字病理学领域，近期发布了众多基础模型用于瓷砖级别图像的特征提取，这些模型被应用于各种下游任务。评估这些方法的性能变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出THUNDER基准测试的目的是为了提供一个快速、易用、动态的基准，以便于比较多种基础模型，并评估它们在多个数据集上的表现。&lt;h4&gt;方法&lt;/h4&gt;THUNDER允许对多种模型进行直接比较，包括最先进的基础模型和用户自定义模型。论文对23个基础模型在16个不同数据集上的表现进行了全面比较。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，THUNDER能够有效地比较不同模型在多个任务上的性能，并揭示了模型之间的主要差异。&lt;h4&gt;结论&lt;/h4&gt;THUNDER为数字病理学领域提供了一个重要的基准工具，有助于推动该领域的研究进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在研究进展难以评估的情况下，特别是在短时间内提出了许多并发方法时，这种情况在数字病理学中尤为明显。最近，许多基础模型被发布作为瓷砖级别图像的特征提取器，用于各种下游任务，包括瓷砖和切片级别的任务。因此，对现有方法进行基准测试变得至关重要，以便更清晰地了解研究现状。特别是在医疗保健等关键领域，基准测试不仅应关注评估下游性能，还应提供关于方法之间主要差异的见解，并且更重要的是，考虑不确定性和鲁棒性，以确保所提出模型的可信使用。因此，我们介绍了THUNDER，一个用于数字病理学基础模型的瓷砖级别基准测试，它允许通过一系列下游任务在多种数据集上高效比较多个模型，研究它们的特征空间，并评估由它们的嵌入信息驱动的预测的鲁棒性和不确定性。THUNDER是一个快速、易用、动态的基准，目前已支持大量最先进的基础模型以及本地用户定义模型，以便直接进行基于瓷砖的比较。在这篇论文中，我们对23个基础模型在16个不同数据集上的表现进行了全面的比较。THUNDER的代码在https://github.com/MICS-Lab/thunder上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Progress in a research field can be hard to assess, in particular when manyconcurrent methods are proposed in a short period of time. This is the case indigital pathology, where many foundation models have been released recently toserve as feature extractors for tile-level images, being used in a variety ofdownstream tasks, both for tile- and slide-level problems. Benchmarkingavailable methods then becomes paramount to get a clearer view of the researchlandscape. In particular, in critical domains such as healthcare, a benchmarkshould not only focus on evaluating downstream performance, but also provideinsights about the main differences between methods, and importantly, furtherconsider uncertainty and robustness to ensure a reliable usage of proposedmodels. For these reasons, we introduce THUNDER, a tile-level benchmark fordigital pathology foundation models, allowing for efficient comparison of manymodels on diverse datasets with a series of downstream tasks, studying theirfeature spaces and assessing the robustness and uncertainty of predictionsinformed by their embeddings. THUNDER is a fast, easy-to-use, dynamic benchmarkthat can already support a large variety of state-of-the-art foundation, aswell as local user-defined models for direct tile-based comparison. In thispaper, we provide a comprehensive comparison of 23 foundation models on 16different datasets covering diverse tasks, feature analysis, and robustness.The code for THUNDER is publicly available athttps://github.com/MICS-Lab/thunder.</description>
      <author>example@mail.com (Pierre Marza, Leo Fillioux, Sofiène Boutaj, Kunal Mahatha, Christian Desrosiers, Pablo Piantanida, Jose Dolz, Stergios Christodoulidis, Maria Vakalopoulou)</author>
      <guid isPermaLink="false">2507.07860v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Reconstruction of cosmic-ray properties with GNN in GRAND</title>
      <link>http://arxiv.org/abs/2507.07541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 39th International Cosmic Ray Conference (ICRC  2025). Xy pages, X figures". Replace the X and Y with the actual numbers of  your proceeding&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了使用机器学习技术重建高能中微子到达方向和能量的方法，并应用于GRAND Proto300原型，以提高对超高能宇宙射线的检测和重建能力。&lt;h4&gt;背景&lt;/h4&gt;GRAND（巨型中微子探测射电阵列）旨在通过观测大范围大气 Shower 中产生的射电发射来探测和研究超高能中微子。&lt;h4&gt;目的&lt;/h4&gt;通过自主检测和重建技术，以展示其在中微子探测中的应用。&lt;h4&gt;方法&lt;/h4&gt;利用最先进的机器学习技术，将触发天线表示为图结构，作为图神经网络（GNN）的输入。将物理知识整合到GNN架构和输入数据中，以增强精度并减少所需训练集大小。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了0.14度的角度分辨率和约15%的主要能量重建分辨率。此外，采用了不确定性估计方法来提高预测的可靠性。&lt;h4&gt;结论&lt;/h4&gt;该方法允许量化GNN预测的置信度，并为方向和能量重建提供置信区间。还探讨了评估模型一致性和鲁棒性的策略，以确保在模拟和现实之间域迁移的情况下预测仍然可信。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型射电阵列（GRAND）旨在通过观测大范围大气 Shower 中产生的射电发射来检测和研究超高能中微子。GRAND Proto300原型主要关注超高能宇宙射线，以展示将应用于中微子探测的自主检测和重建技术。本研究提出了一种使用最先进的机器学习技术重建到达方向和能量精度方法，该方法使用噪声模拟电压轨迹。对于每个事件，将触发天线表示为图结构，作为图神经网络（GNN）的输入。为了显著提高精度并减少所需训练集大小，我们将物理知识整合到GNN架构和输入数据中。这种方法实现了0.14度的角度分辨率和大约15%的主要能量重建分辨率。此外，我们采用了不确定性估计方法来提高预测的可靠性。这些方法允许量化GNN预测的置信度，并为方向和能量重建提供置信区间。最后，我们探讨了评估模型一致性和鲁棒性的策略，目的是在模拟和现实之间域迁移的情况下，识别出预测仍然可信的情况。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Giant Radio Array for Neutrino Detection (GRAND) aims to detect and studyultra-high-energy (UHE) neutrinos by observing the radio emissions produced inextensive air showers. The GRANDProto300 prototype primarily focuses on UHEcosmic rays to demonstrate the autonomous detection and reconstructiontechniques that will later be applied to neutrino detection. In this work, wepropose a method for reconstructing the arrival direction and energy with highprecision using state-of-the-art machine learning techniques from noisysimulated voltage traces. For each event, we represent the triggered antennasas a graph structure, which is used as input for a graph neural network (GNN).To significantly enhance precision and reduce the required training set size,we incorporate physical knowledge into both the GNN architecture and the inputdata. This approach achieves an angular resolution of 0.14{\deg} and a primaryenergy reconstruction resolution of about 15%. Additionally, we employuncertainty estimation methods to improve the reliability of our predictions.These methods allow us to quantify the confidence of the GNN predictions andprovide confidence intervals for the direction and energy reconstruction.Finally, we explore strategies to evaluate the consistency and robustness ofthe model when applied to real data. Our goal is to identify situations wherepredictions remain trustworthy despite domain shifts between simulation andreality.</description>
      <author>example@mail.com (Arsène Ferrière, Aurélien Benoit-Lévy)</author>
      <guid isPermaLink="false">2507.07541v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Mix-Geneformer: Unified Representation Learning for Human and Mouse scRNA-seq Data</title>
      <link>http://arxiv.org/abs/2507.07454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Mix-Geneformer是一种基于Transformer的新型模型，它能够整合人类和鼠标单细胞RNA测序数据，通过混合自监督方法提高跨物种转录组建模的能力。&lt;h4&gt;背景&lt;/h4&gt;单细胞RNA测序（scRNA-seq）揭示了细胞异质性和稀有种群，但现有的深度学习模型如Geneformer和Mouse-Geneformer在跨物种泛化和转化应用方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理人类和鼠标scRNA-seq数据的模型，以促进转化研究和药物发现。&lt;h4&gt;方法&lt;/h4&gt;Mix-Geneformer通过结合掩码语言建模（MLM）和SimCSE对比损失，以及排名值编码方案来捕捉共享和物种特定的基因模式。&lt;h4&gt;主要发现&lt;/h4&gt;Mix-Geneformer在细胞类型分类和模拟扰动任务中，在约5000万个细胞的数据集上训练，达到了95.8%的准确率，超过了现有的最佳模型，并成功识别了关键的调控基因。&lt;h4&gt;结论&lt;/h4&gt;Mix-Geneformer为比较转录组和转化应用提供了一个强大的工具，尽管存在计算成本和零样本迁移中的可变性等局限性。&lt;h4&gt;翻译&lt;/h4&gt;Mix-Geneformer是一种基于Transformer的模型，它通过整合人类和鼠标的单细胞RNA测序数据，利用混合自监督方法，结合掩码语言建模（MLM）和基于SimCSE的对比损失，以及排名值编码方案来捕捉共享和物种特定的基因模式。该模型在处理约5000万个细胞的数据集上训练，实现了95.8%的准确率，超过了现有的最佳模型，并成功识别了关键的调控基因。尽管存在计算成本和零样本迁移中的可变性等局限性，Mix-Geneformer为比较转录组和转化应用提供了一个强大的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-cell RNA sequencing (scRNA-seq) enables single-cell transcriptomicprofiling, revealing cellular heterogeneity and rare populations. Recent deeplearning models like Geneformer and Mouse-Geneformer perform well on tasks suchas cell-type classification and in silico perturbation. However, theirspecies-specific design limits cross-species generalization and translationalapplications, which are crucial for advancing translational research and drugdiscovery. We present Mix-Geneformer, a novel Transformer-based model thatintegrates human and mouse scRNA-seq data into a unified representation via ahybrid self-supervised approach combining Masked Language Modeling (MLM) andSimCSE-based contrastive loss to capture both shared and species-specific genepatterns. A rank-value encoding scheme further emphasizes high-variance genesignals during training. Trained on about 50 million cells from diverse humanand mouse organs, Mix-Geneformer matched or outperformed state-of-the-artbaselines in cell-type classification and in silico perturbation tasks,achieving 95.8% accuracy on mouse kidney data versus 94.9% from the bestexisting model. It also successfully identified key regulatory genes validatedby in vivo studies. By enabling scalable cross-species transcriptomic modeling,Mix-Geneformer offers a powerful tool for comparative transcriptomics andtranslational applications. While our results demonstrate strong performance,we also acknowledge limitations, such as the computational cost and variabilityin zero-shot transfer.</description>
      <author>example@mail.com (Yuki Nishio, Takayoshi Yamashita, Keita Ito, Tsubasa Hirakawa, Hironobu Fujiyoshi)</author>
      <guid isPermaLink="false">2507.07454v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Towards Benchmarking Foundation Models for Tabular Data With Text</title>
      <link>http://arxiv.org/abs/2507.07829v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Foundation Models for Structured Data workshop at ICML  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要讨论了表格数据基础模型的快速发展和将文本特征扩展到这些模型中的兴趣增加。提出了将文本融入传统表格流程的策略，并通过手动收集包含有意义文本特征的表格数据集来评估最先进的表格基础模型处理文本数据的能力。&lt;h4&gt;背景&lt;/h4&gt;表格数据基础模型正在快速发展，对扩展模型以支持额外模态（如自由文本特征）的兴趣日益增加。&lt;h4&gt;目的&lt;/h4&gt;提出简单有效的策略将文本融入传统表格流程，并通过基准测试评估最先进的表格基础模型处理文本数据的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一系列消融风格的策略，并手动收集了包含有意义文本特征的表格数据集。&lt;h4&gt;主要发现&lt;/h4&gt;研究提出了将文本融入表格流程的策略，并通过基准测试发现最先进的表格基础模型在处理文本数据方面具有潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究是提高表格数据基础模型基准测试的重要步骤。&lt;h4&gt;翻译&lt;/h4&gt;摘要：表格数据的基础模型正在迅速发展，对扩展模型以支持额外的模态，如自由文本特征的兴趣正在增加。然而，现有的表格数据基准很少包括文本列，识别具有语义丰富文本特征的现实世界表格数据集是非平凡的。我们提出了一系列简单而有效的消融风格策略，用于将文本融入传统的表格流程。此外，我们通过手动整理包含有意义文本特征的现实世界表格数据集，基准测试了最先进的表格基础模型处理文本数据的能力。我们的研究是提高具有文本的表格数据基础模型基准测试的重要步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models for tabular data are rapidly evolving, with increasinginterest in extending them to support additional modalities such as free-textfeatures. However, existing benchmarks for tabular data rarely include textualcolumns, and identifying real-world tabular datasets with semantically richtext features is non-trivial. We propose a series of simple yet effectiveablation-style strategies for incorporating text into conventional tabularpipelines. Moreover, we benchmark how state-of-the-art tabular foundationmodels can handle textual data by manually curating a collection of real-worldtabular datasets with meaningful textual features. Our study is an importantstep towards improving benchmarking of foundation models for tabular data withtext.</description>
      <author>example@mail.com (Martin Mráz, Breenda Das, Anshul Gupta, Lennart Purucker, Frank Hutter)</author>
      <guid isPermaLink="false">2507.07829v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>GNN-CNN: An Efficient Hybrid Model of Convolutional and Graph Neural Networks for Text Representation</title>
      <link>http://arxiv.org/abs/2507.07414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种结合图神经网络（GNN）和卷积神经网络（CNN）的新型深度学习模型，用于处理长文本，并提高时间、成本和能源效率。&lt;h4&gt;背景&lt;/h4&gt;在深度学习（DL）中，处理长文本时，时间、成本和能源效率是关键考虑因素。目前的Transformer模型在输入长度上具有二次计算复杂度，对于扩展文档来说效率不高。&lt;h4&gt;目的&lt;/h4&gt;研究提出了一种新的模型架构，旨在提高处理长文本的效率，同时保持高速和高效。&lt;h4&gt;方法&lt;/h4&gt;该模型结合了GNN和CNN，并集成了一种实时、端到端的图生成机制。模型处理字符级输入的紧凑批次，无需填充或截断。为了提高性能，模型通过高效的字典查找，结合了大型语言模型（LLM）的信息，如token嵌入和情感极性。模型使用CNN捕获局部上下文模式，通过基于格子的图结构扩展局部感受野，并使用小世界图聚合文档级信息。&lt;h4&gt;主要发现&lt;/h4&gt;生成的图具有指示有意义的语义组织的结构特性，平均聚类系数约为0.45，平均最短路径长度在4到5之间。&lt;h4&gt;结论&lt;/h4&gt;该模型在多个文本分类任务中进行了评估，包括情感分析和新闻分类，并与最先进的模型进行了比较。实验结果证实了所提出模型的高效性和竞争力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：时间、成本和能源效率是深度学习（DL）中的关键考虑因素，尤其是在处理长文本时。代表当前最先进的技术的Transformer模型，在输入长度上具有二次计算复杂度，这使得它们在处理扩展文档时效率低下。本研究介绍了一种新的模型架构，该架构结合了图神经网络（GNN）和卷积神经网络（CNN），并集成了一种实时、端到端的图生成机制。该模型处理紧凑的字符级输入批次，无需填充或截断。为了在保持高速和效率的同时提高性能，该模型通过高效的字典查找，结合了大型语言模型（LLM）的信息，如token嵌入和情感极性。该模型使用CNN捕获局部上下文模式，通过基于格子的图结构扩展局部感受野，并使用小世界图聚合文档级信息。生成的图表现出有意义的语义组织的结构特性，平均聚类系数约为0.45，平均最短路径长度在4到5之间。该模型在多个文本分类任务中进行了评估，包括情感分析和新闻分类，并与最先进的模型进行了比较。实验结果证实了所提出模型的高效性和竞争力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time, cost, and energy efficiency are critical considerations inDeep-Learning (DL), particularly when processing long texts. Transformers,which represent the current state of the art, exhibit quadratic computationalcomplexity relative to input length, making them inefficient for extendeddocuments. This study introduces a novel model architecture that combines GraphNeural Networks (GNNs) and Convolutional Neural Networks (CNNs), integratedwith a real-time, end-to-end graph generation mechanism. The model processescompact batches of character-level inputs without requiring padding ortruncation. To enhance performance while maintaining high speed and efficiency,the model incorporates information from Large Language Models (LLMs), such astoken embeddings and sentiment polarities, through efficient dictionarylookups. It captures local contextual patterns using CNNs, expands localreceptive fields via lattice-based graph structures, and employs small-worldgraphs to aggregate document-level information. The generated graphs exhibitstructural properties indicative of meaningful semantic organization, with anaverage clustering coefficient of approximately 0.45 and an average shortestpath length ranging between 4 and 5. The model is evaluated across multipletext classification tasks, including sentiment analysis andnews-categorization, and is compared against state-of-the-art models.Experimental results confirm the proposed model's efficiency and competitiveperformance.</description>
      <author>example@mail.com (Fardin Rastakhiz)</author>
      <guid isPermaLink="false">2507.07414v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>HGMP:Heterogeneous Graph Multi-Task Prompt Learning</title>
      <link>http://arxiv.org/abs/2507.07405v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The 25th International Joint Conference on Artificial Intelligence  (IJCAI-25)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HGMP的新型多任务提示框架，用于异构图领域，通过解决预训练模型与下游任务之间的不匹配问题，提高了多任务场景下的模型性能。&lt;h4&gt;背景&lt;/h4&gt;预训练和微调方法在异构图神经网络领域受到关注，但存在预训练模型与下游任务不匹配的问题，影响应用性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决预训练模型与下游任务之间的不匹配，并提高多任务场景下的模型性能。&lt;h4&gt;方法&lt;/h4&gt;1. 将所有下游任务转化为统一的图级任务格式；2. 设计图级对比预训练策略以更好地利用异构信息；3. 引入异构特征提示以优化输入图特征的表示。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验表明，提出的HGMP方法能很好地适应各种任务，并且显著优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;HGMP方法能够有效解决异构图领域中的任务表示不匹配问题，并显著提高多任务场景下的模型性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于在预训练阶段能够利用大量未标记数据来学习丰富的结构特征，预训练和微调方法在异构图神经网络领域受到了广泛关注。然而，这些方法面临预训练模型与下游任务不匹配的问题，导致在某些应用场景中性能不佳。提示学习方法作为异构图任务的一个新方向，允许灵活地适应任务表示以解决目标不一致性。基于这一想法，本文提出了一种名为HGMP的新颖多任务提示框架，用于异构图领域。首先，为了弥合预训练模型与下游任务之间的差距，我们将所有下游任务转化为统一的图级任务格式。接下来，我们解决了现有图提示学习方法中难以在异构图领域整合对比预训练策略的局限性。我们设计了一种图级对比预训练策略，以更好地利用异构信息并提高多任务场景下的性能。最后，我们引入了异构特征提示，通过优化输入图特征的表示来提高模型性能。在公共数据集上的实验结果表明，我们提出的方法能很好地适应各种任务，并且显著优于基线方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The pre-training and fine-tuning methods have gained widespread attention inthe field of heterogeneous graph neural networks due to their ability toleverage large amounts of unlabeled data during the pre-training phase,allowing the model to learn rich structural features. However, these methodsface the issue of a mismatch between the pre-trained model and downstreamtasks, leading to suboptimal performance in certain application scenarios.Prompt learning methods have emerged as a new direction in heterogeneous graphtasks, as they allow flexible adaptation of task representations to addresstarget inconsistency. Building on this idea, this paper proposes a novelmulti-task prompt framework for the heterogeneous graph domain, named HGMP.First, to bridge the gap between the pre-trained model and downstream tasks, wereformulate all downstream tasks into a unified graph-level task format. Next,we address the limitations of existing graph prompt learning methods, whichstruggle to integrate contrastive pre-training strategies in the heterogeneousgraph domain. We design a graph-level contrastive pre-training strategy tobetter leverage heterogeneous information and enhance performance in multi-taskscenarios. Finally, we introduce heterogeneous feature prompts, which enhancemodel performance by refining the representation of input graph features.Experimental results on public datasets show that our proposed method adaptswell to various tasks and significantly outperforms baseline methods.</description>
      <author>example@mail.com (Pengfei Jiao, Jialong Ni, Di Jin, Xuan Guo, Huan Liu, Hongjiang Chen, Yanxian Bi)</author>
      <guid isPermaLink="false">2507.07405v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Where are we with calibration under dataset shift in image classification?</title>
      <link>http://arxiv.org/abs/2507.07780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code available at  https://github.com/biomedia-mira/calibration_under_shifts&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究对图像分类在真实世界数据集偏移下的校准状态进行了广泛研究，提供了关于后处理和训练中校准技术选择的见解，并为所有对偏移下稳健校准感兴趣的实践者提供了实用指南。&lt;h4&gt;背景&lt;/h4&gt;研究针对图像分类在真实世界数据集偏移下的校准状态进行了探讨。&lt;h4&gt;目的&lt;/h4&gt;旨在提供关于后处理和训练中校准技术选择的见解，并为偏移下稳健校准提供实用指南。&lt;h4&gt;方法&lt;/h4&gt;比较了各种后处理校准方法及其与常见的训练中校准策略（如标签平滑）的相互作用，涵盖了广泛的自然偏移，在多个成像领域的八个不同分类任务上进行了研究。&lt;h4&gt;主要发现&lt;/h4&gt;1. 同时应用熵正则化和标签平滑在数据集偏移下产生最佳的校准原始概率；2. 接触少量语义非分布数据（与任务无关）的后处理校准器在偏移下最为稳健；3. 针对提高偏移下校准的最近校准方法并不一定比简单的后处理校准方法有显著改进；4. 改善偏移下的校准往往以牺牲分布内校准为代价；5. 这些发现适用于随机初始化的分类器，也适用于从基础模型微调的分类器，后者相比从头训练的模型校准效果更佳。&lt;h4&gt;结论&lt;/h4&gt;应用校准在集成之前（而不是之后）对偏移下的校准更有效；对于集成，非分布数据的暴露恶化了ID偏移下的校准权衡；集成是提高校准稳健性的最有效方法之一，与从基础模型微调相结合，总体上产生最佳的校准结果。&lt;h4&gt;翻译&lt;/h4&gt;我们对图像分类在真实世界数据集偏移下的校准状态进行了广泛研究。我们的工作为后处理和训练中校准技术的选择提供了重要的见解，并为所有对偏移下稳健校准感兴趣的实践者提供了实用的指导。我们在广泛的自然偏移下比较了各种后处理校准方法，以及它们与常见的训练中校准策略（例如标签平滑）的相互作用，涵盖了多个成像领域的八个不同分类任务。我们发现，同时应用熵正则化和标签平滑可以在数据集偏移下产生最佳的校准原始概率；接触少量语义非分布数据（与任务无关）的后处理校准器在偏移下最为稳健；针对提高偏移下校准的最近校准方法并不一定比简单的后处理校准方法有显著改进；改善偏移下的校准往往以牺牲分布内校准为代价。重要的是，这些发现适用于随机初始化的分类器，也适用于从基础模型微调的分类器，后者相比从头训练的模型校准效果更佳。最后，我们对集成效应进行了深入研究，发现应用校准在集成之前（而不是之后）对偏移下的校准更有效；对于集成，非分布数据的暴露恶化了ID偏移下的校准权衡；集成是提高校准稳健性的最有效方法之一，与从基础模型微调相结合，总体上产生最佳的校准结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We conduct an extensive study on the state of calibration under real-worlddataset shift for image classification. Our work provides important insights onthe choice of post-hoc and in-training calibration techniques, and yieldspractical guidelines for all practitioners interested in robust calibrationunder shift. We compare various post-hoc calibration methods, and theirinteractions with common in-training calibration strategies (e.g., labelsmoothing), across a wide range of natural shifts, on eight differentclassification tasks across several imaging domains. We find that: (i)simultaneously applying entropy regularisation and label smoothing yield thebest calibrated raw probabilities under dataset shift, (ii) post-hoccalibrators exposed to a small amount of semantic out-of-distribution data(unrelated to the task) are most robust under shift, (iii) recent calibrationmethods specifically aimed at increasing calibration under shifts do notnecessarily offer significant improvements over simpler post-hoc calibrationmethods, (iv) improving calibration under shifts often comes at the cost ofworsening in-distribution calibration. Importantly, these findings hold forrandomly initialised classifiers, as well as for those finetuned fromfoundation models, the latter being consistently better calibrated compared tomodels trained from scratch. Finally, we conduct an in-depth analysis ofensembling effects, finding that (i) applying calibration prior to ensembling(instead of after) is more effective for calibration under shifts, (ii) forensembles, OOD exposure deteriorates the ID-shifted calibration trade-off,(iii) ensembling remains one of the most effective methods to improvecalibration robustness and, combined with finetuning from foundation models,yields best calibration results overall.</description>
      <author>example@mail.com (Mélanie Roschewitz, Raghav Mehta, Fabio de Sousa Ribeiro, Ben Glocker)</author>
      <guid isPermaLink="false">2507.07780v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>FrugalRAG: Learning to retrieve and reason for multi-hop QA</title>
      <link>http://arxiv.org/abs/2507.07634v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICML Workshop: Efficient Systems for Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究在访问大量非结构化文档语料库的情况下，如何回答复杂问题。主要关注检索增强生成（RAG）方法的改进，包括准确性、召回率等指标，并提出了提高检索搜索效率的方法。&lt;h4&gt;背景&lt;/h4&gt;目前解决复杂问题的问题通常是通过语言模型检索和推理文档，直到模型获得足够信息生成答案。改进的方法主要关注RAG指标，如准确性和召回率，分为两种类型：细调大型问答数据集和基于强化学习的细调技术。&lt;h4&gt;目的&lt;/h4&gt;研究如何提高RAG方法的效率，特别是检索搜索的效率。&lt;h4&gt;方法&lt;/h4&gt;研究提出了一种改进的ReAct管道，并使用改进的提示来提高RAG指标。同时，研究了监督学习和基于强化学习的细调技术，以降低推理时的搜索延迟。&lt;h4&gt;主要发现&lt;/h4&gt;发现大规模细调并不是提高RAG指标的必要条件，改进的ReAct管道和提示可以优于现有方法。此外，监督学习和基于强化学习的细调可以在几乎一半的搜索成本下实现具有竞争力的RAG指标，并且训练成本很小。&lt;h4&gt;结论&lt;/h4&gt;提高RAG方法的效率可以通过改进提示和细调技术实现，而不需要大规模的细调，并且可以在降低搜索成本的同时保持性能。&lt;h4&gt;翻译&lt;/h4&gt;We consider the problem of answering complex questions, given access to a large unstructured document corpus. The de facto approach to solving the problem is to leverage language models that (iteratively) retrieve and reason through the retrieved documents, until the model has sufficient information to generate an answer. Attempts at improving this approach focus on retrieval-augmented generation (RAG) metrics such as accuracy and recall and can be categorized into two types: (a) fine-tuning on large question answering (QA) datasets augmented with chain-of-thought traces, and (b) leveraging RL-based fine-tuning techniques that rely on question-document relevance signals. However, efficiency in the number of retrieval searches is an equally important metric, which has received less attention. In this work, we show that: (1) Large-scale fine-tuning is not needed to improve RAG metrics, contrary to popular claims in recent literature. Specifically, a standard ReAct pipeline with improved prompts can outperform state-of-the-art methods on benchmarks such as HotPotQA. (2) Supervised and RL-based fine-tuning can help RAG from the perspective of frugality, i.e., the latency due to number of searches at inference time. For example, we show that we can achieve competitive RAG metrics at nearly half the cost (in terms of number of searches) on popular RAG benchmarks, using the same base model, and at a small training cost (1000 examples).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of answering complex questions, given access to alarge unstructured document corpus. The de facto approach to solving theproblem is to leverage language models that (iteratively) retrieve and reasonthrough the retrieved documents, until the model has sufficient information togenerate an answer. Attempts at improving this approach focus onretrieval-augmented generation (RAG) metrics such as accuracy and recall andcan be categorized into two types: (a) fine-tuning on large question answering(QA) datasets augmented with chain-of-thought traces, and (b) leveragingRL-based fine-tuning techniques that rely on question-document relevancesignals. However, efficiency in the number of retrieval searches is an equallyimportant metric, which has received less attention. In this work, we showthat: (1) Large-scale fine-tuning is not needed to improve RAG metrics,contrary to popular claims in recent literature. Specifically, a standard ReActpipeline with improved prompts can outperform state-of-the-art methods onbenchmarks such as HotPotQA. (2) Supervised and RL-based fine-tuning can helpRAG from the perspective of frugality, i.e., the latency due to number ofsearches at inference time. For example, we show that we can achievecompetitive RAG metrics at nearly half the cost (in terms of number ofsearches) on popular RAG benchmarks, using the same base model, and at a smalltraining cost (1000 examples).</description>
      <author>example@mail.com (Abhinav Java, Srivathsan Koundinyan, Nagarajan Natarajan, Amit Sharma)</author>
      <guid isPermaLink="false">2507.07634v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>ST-GRIT: Spatio-Temporal Graph Transformer For Internal Ice Layer Thickness Prediction</title>
      <link>http://arxiv.org/abs/2507.07389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for 2025 IEEE International Conference on Image Processing  (ICIP)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为ST-GRIT的时空图变换器，用于分析雷达图像中的内部冰层厚度，以监测积雪、评估冰动力学和减少气候模型的不确定性。&lt;h4&gt;背景&lt;/h4&gt;理解雷达图像中内部冰层的厚度和可变性对于监测积雪积累、评估冰动力学以及减少气候模型的不确定性至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计ST-GRIT以处理雷达图并捕捉浅层和深层冰层之间的时空关系。&lt;h4&gt;方法&lt;/h4&gt;ST-GRIT利用归纳几何图学习框架提取局部空间特征作为特征嵌入，并使用一系列时空注意力块分别有效地建模两个维度中的长距离依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;在格陵兰冰盖的雷达图数据上的实验评估表明，ST-GRIT在实现更低的均方根误差方面，优于现有的最先进方法和其他基线图神经网络。&lt;h4&gt;结论&lt;/h4&gt;这些结果突出了在图上使用自注意力机制相对于纯图神经网络的优点，包括处理噪声、避免过度平滑和捕捉长距离依赖的能力。此外，使用独立的时空注意力块允许区分和稳健地学习空间关系和时空模式，提供了一种更全面和有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Understanding the thickness and variability of internal ice layers in radar imagery is crucial for monitoring snow accumulation, assessing ice dynamics, and reducing uncertainties in climate models. Radar sensors, capable of penetrating ice, provide detailed radargram images of these internal layers. In this work, we present ST-GRIT, a spatio-temporal graph transformer for ice layer thickness, designed to process these radargrams and capture the spatiotemporal relationships between shallow and deep ice layers. ST-GRIT leverages an inductive geometric graph learning framework to extract local spatial features as feature embeddings and employs a series of temporal and spatial attention blocks separately to model long-range dependencies effectively in both dimensions. Experimental evaluation on radargram data from the Greenland ice sheet demonstrates that ST-GRIT consistently outperforms current state-of-the-art methods and other baseline graph neural networks by achieving lower root mean-squared error. These results highlight the advantages of self-attention mechanisms on graphs over pure graph neural networks, including the ability to handle noise, avoid oversmoothing, and capture long-range dependencies. Moreover, the use of separate spatial and temporal attention blocks allows for distinct and robust learning of spatial relationships and temporal patterns, providing a more comprehensive and effective approach.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the thickness and variability of internal ice layers in radarimagery is crucial for monitoring snow accumulation, assessing ice dynamics,and reducing uncertainties in climate models. Radar sensors, capable ofpenetrating ice, provide detailed radargram images of these internal layers. Inthis work, we present ST-GRIT, a spatio-temporal graph transformer for icelayer thickness, designed to process these radargrams and capture thespatiotemporal relationships between shallow and deep ice layers. ST-GRITleverages an inductive geometric graph learning framework to extract localspatial features as feature embeddings and employs a series of temporal andspatial attention blocks separately to model long-range dependencieseffectively in both dimensions. Experimental evaluation on radargram data fromthe Greenland ice sheet demonstrates that ST-GRIT consistently outperformscurrent state-of-the-art methods and other baseline graph neural networks byachieving lower root mean-squared error. These results highlight the advantagesof self-attention mechanisms on graphs over pure graph neural networks,including the ability to handle noise, avoid oversmoothing, and capturelong-range dependencies. Moreover, the use of separate spatial and temporalattention blocks allows for distinct and robust learning of spatialrelationships and temporal patterns, providing a more comprehensive andeffective approach.</description>
      <author>example@mail.com (Zesheng Liu, Maryam Rahnemoonfar)</author>
      <guid isPermaLink="false">2507.07389v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>GRIT: Graph Transformer For Internal Ice Layer Thickness Prediction</title>
      <link>http://arxiv.org/abs/2507.07388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for 2025 IEEE International Geoscience and Remote Sensing  Symposium (IGARSS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GRIT，一种用于冰层厚度计算的图变换器，通过结合几何图学习框架和注意力机制，有效地捕捉冰层间的时空动态。&lt;h4&gt;背景&lt;/h4&gt;理解雷达图像中内部冰层的厚度和变异性对于监测雪积累、评估冰动力学过程以及减少气候模型中的不确定性至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出GRIT以更准确地预测冰层厚度。&lt;h4&gt;方法&lt;/h4&gt;GRIT集成了归纳几何图学习框架和注意力机制，以映射浅层和深层冰层之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;与基线图神经网络相比，GRIT显示出持续较低的预测误差。这些结果表明，注意力机制在捕捉冰层间的时序变化方面非常有效，而图变换器结合了transformers学习长距离依赖关系和图神经网络捕获空间模式的优势。&lt;h4&gt;结论&lt;/h4&gt;GRIT能够稳健地建模复杂的时空动态，是监测雪积累和评估冰动力学过程的潜在有效工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gaining a deeper understanding of the thickness and variability of internalice layers in Radar imagery is essential in monitoring the snow accumulation,better evaluating ice dynamics processes, and minimizing uncertainties inclimate models. Radar sensors, capable of penetrating ice, capture detailedradargram images of internal ice layers. In this work, we introduce GRIT, graphtransformer for ice layer thickness. GRIT integrates an inductive geometricgraph learning framework with an attention mechanism, designed to map therelationships between shallow and deeper ice layers. Compared to baseline graphneural networks, GRIT demonstrates consistently lower prediction errors. Theseresults highlight the attention mechanism's effectiveness in capturing temporalchanges across ice layers, while the graph transformer combines the strengthsof transformers for learning long-range dependencies with graph neural networksfor capturing spatial patterns, enabling robust modeling of complexspatiotemporal dynamics.</description>
      <author>example@mail.com (Zesheng Liu, Maryam Rahnemoonfar)</author>
      <guid isPermaLink="false">2507.07388v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>NexViTAD: Few-shot Unsupervised Cross-Domain Defect Detection via Vision Foundation Models and Multi-Task Learning</title>
      <link>http://arxiv.org/abs/2507.07579v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的少量样本跨域异常检测框架NexViTAD，基于视觉基础模型，通过创新的共享子空间投影机制和多任务学习模块有效解决了工业异常检测中的域偏移挑战。&lt;h4&gt;背景&lt;/h4&gt;工业异常检测中存在域偏移问题，传统的异常检测方法难以应对。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效解决域偏移问题的异常检测框架。&lt;h4&gt;方法&lt;/h4&gt;1. 使用分层适配模块自适应融合Hiera和DINO-v2预训练模型的互补特征，构建更鲁棒的特征表示；2. 采用共享子空间投影策略，通过瓶颈维度约束和跳跃连接机制实现有效的跨域知识迁移；3. 设计多任务学习解码器架构，支持同时处理多个源域，显著增强模型泛化能力；4. 基于Sinkhorn-K-means聚类的方法进行异常分数推断，结合高斯滤波和自适应阈值处理实现精确的像素级异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;NexViTAD在MVTec AD数据集上表现出色，AUC达到97.5%，AP达到70.4%，PRO达到95.2%，在目标域中超越了其他最近模型，标志着跨域缺陷检测的突破性进展。&lt;h4&gt;结论&lt;/h4&gt;NexViTAD是一种有效的跨域异常检测框架，在工业异常检测中具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新颖的少量样本跨域异常检测框架NexViTAD，基于视觉基础模型，通过创新的共享子空间投影机制和多任务学习模块有效解决了工业异常检测中的域偏移挑战。主要创新包括：1. 分层适配模块，自适应融合Hiera和DINO-v2预训练模型的互补特征，构建更鲁棒的特征表示；2. 共享子空间投影策略，通过瓶颈维度约束和跳跃连接机制实现有效的跨域知识迁移；3. 多任务学习解码器架构，支持同时处理多个源域，显著增强模型泛化能力；4. 基于Sinkhorn-K-means聚类的异常分数推断方法，结合高斯滤波和自适应阈值处理实现精确的像素级。在MVTec AD数据集上评估，NexViTAD在目标域中达到最先进的性能，AUC为97.5%，AP为70.4%，PRO为95.2%，超越了其他最近模型，标志着跨域缺陷检测的突破性进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel few-shot cross-domain anomaly detectionframework, Nexus Vision Transformer for Anomaly Detection (NexViTAD), based onvision foundation models, which effectively addresses domain-shift challengesin industrial anomaly detection through innovative shared subspace projectionmechanisms and multi-task learning (MTL) module. The main innovations include:(1) a hierarchical adapter module that adaptively fuses complementary featuresfrom Hiera and DINO-v2 pre-trained models, constructing more robust featurerepresentations; (2) a shared subspace projection strategy that enableseffective cross-domain knowledge transfer through bottleneck dimensionconstraints and skip connection mechanisms; (3) a MTL Decoder architecturesupports simultaneous processing of multiple source domains, significantlyenhancing model generalization capabilities; (4) an anomaly score inferencemethod based on Sinkhorn-K-means clustering, combined with Gaussian filteringand adaptive threshold processing for precise pixel level. Valuated on theMVTec AD dataset, NexViTAD delivers state-of-the-art performance with an AUC of97.5%, AP of 70.4%, and PRO of 95.2% in the target domains, surpassing otherrecent models, marking a transformative advance in cross-domain defectdetection.</description>
      <author>example@mail.com (Tianwei Mu, Feiyu Duan, Bo Zhou, Dan Xue, Manhong Huang)</author>
      <guid isPermaLink="false">2507.07579v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Atherosclerosis through Hierarchical Explainable Neural Network Analysis</title>
      <link>http://arxiv.org/abs/2507.07373v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过开发层次图神经网络框架进行亚临床动脉粥样硬化个性化分类的问题，该框架利用了患者的两种特征模态：队列中的临床特征和个体患者的分子数据。&lt;h4&gt;背景&lt;/h4&gt;现有的基于图的方法在疾病分类中检测患者特定的分子指纹，但缺乏对队列特征的一致性和理解，而队列特征是理解不同动脉粥样硬化轨迹中的致病表型所必需的。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，本文提出了ATHENA（通过层次可解释神经网络分析动脉粥样硬化），它通过集成模态学习构建了一个新的层次网络表示，随后优化了反映个体组学数据的患者特异性分子指纹，确保与队列模式的一致性。&lt;h4&gt;方法&lt;/h4&gt;ATHENA使用391名患者的临床数据集，通过将临床特征与分子相互作用模式进行异质对齐，显著提高了亚临床动脉粥样硬化分类性能，在接收者操作特征曲线（AUC）和F1分数上分别提高了高达13%和20%。&lt;h4&gt;主要发现&lt;/h4&gt;ATHENA通过可解释人工智能（XAI）驱动的子网络聚类，使机制信息化的患者亚型发现成为可能，这种新颖的集成框架加强了个性化干预策略，从而改善了动脉粥样硬化疾病进展的预测和管理其临床可行动结果。&lt;h4&gt;结论&lt;/h4&gt;ATHENA通过提供了一种新的方法来结合队列特征和个体分子数据，为亚临床动脉粥样硬化的个性化分类提供了强有力的支持，有助于提高疾病预测和管理的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we study the problem pertaining to personalized classificationof subclinical atherosclerosis by developing a hierarchical graph neuralnetwork framework to leverage two characteristic modalities of a patient:clinical features within the context of the cohort, and molecular data uniqueto individual patients. Current graph-based methods for disease classificationdetect patient-specific molecular fingerprints, but lack consistency andcomprehension regarding cohort-wide features, which are an essentialrequirement for understanding pathogenic phenotypes across diverseatherosclerotic trajectories. Furthermore, understanding patient subtypes oftenconsiders clinical feature similarity in isolation, without integration ofshared pathogenic interdependencies among patients. To address thesechallenges, we introduce ATHENA: Atherosclerosis Through HierarchicalExplainable Neural Network Analysis, which constructs a novel hierarchicalnetwork representation through integrated modality learning; subsequently, itoptimizes learned patient-specific molecular fingerprints that reflectindividual omics data, enforcing consistency with cohort-wide patterns. With aprimary clinical dataset of 391 patients, we demonstrate that thisheterogeneous alignment of clinical features with molecular interactionpatterns has significantly boosted subclinical atherosclerosis classificationperformance across various baselines by up to 13% in area under the receiveroperating curve (AUC) and 20% in F1 score. Taken together, ATHENA enablesmechanistically-informed patient subtype discovery through explainable AI(XAI)-driven subnetwork clustering; this novel integration frameworkstrengthens personalized intervention strategies, thereby improving theprediction of atherosclerotic disease progression and management of theirclinical actionable outcomes.</description>
      <author>example@mail.com (Irsyad Adam, Steven Swee, Erika Yilin, Ethan Ji, William Speier, Dean Wang, Alex Bui, Wei Wang, Karol Watson, Peipei Ping)</author>
      <guid isPermaLink="false">2507.07373v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>MAPEX: Modality-Aware Pruning of Experts for Remote Sensing Foundation Models</title>
      <link>http://arxiv.org/abs/2507.07527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MAPEX是一种基于混合模态专家的遥感基础模型，通过模态条件化标记路由机制和模态感知剪枝技术，提高了遥感数据处理的效率和模型性能。&lt;h4&gt;背景&lt;/h4&gt;遥感数据常用于洪水映射、野火检测或土地利用研究等任务，但现有的基础模型往往专注于特定模态，导致应用模态与预训练数据不匹配，且模型规模大，难以在小型数据集上进行微调。&lt;h4&gt;目的&lt;/h4&gt;提出MAPEX模型，以解决应用模态与预训练数据不匹配的问题，并简化模型的微调和部署过程。&lt;h4&gt;方法&lt;/h4&gt;MAPEX在多模态遥感数据上预训练，并采用模态条件化标记路由机制激发模态特定的专家。针对特定任务，采用模态感知剪枝技术，仅保留针对任务模态的专家。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MAPEX在多种遥感数据集上表现出比全监督训练和现有遥感基础模型更强的性能。&lt;h4&gt;结论&lt;/h4&gt;MAPEX模型有效解决了遥感数据处理中的模态不匹配问题，并提高了模型的效率和性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：遥感数据通常用于洪水测绘、野火检测或土地利用研究等任务。对于每个任务，科学家们都会仔细选择适当的模态或利用专用仪器收集的数据。最近的研究在遥感基础模型方面取得了进展，这些模型在大量的遥感数据上预先训练计算机视觉模型。这些大规模模型往往专注于特定的模态，通常是光学RGB或多光谱数据。对于许多重要应用，这引入了应用模态与预训练数据之间的不匹配。此外，基础模型的大规模使得它们成本高昂，且难以在每个任务的典型小型数据集上进行微调。我们通过MAPEX解决了这种不匹配，MAPEX是一种基于混合模态专家的遥感基础模型。MAPEX在多模态遥感数据上预训练，并采用了一种新颖的模态条件化标记路由机制，以激发模态特定的专家。为了将模型应用于特定任务，我们提出了一种模态感知剪枝技术，它只保留针对任务模态的专家。这产生了高效的模态特定模型，同时简化了针对感兴趣模态的微调和部署。我们在多种遥感数据集上对MAPEX进行了实验验证，并显示出与全监督训练和最先进的遥感基础模型相比的强大性能。代码可在https://github.com/HSG-AIML/MAPEX上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remote sensing data is commonly used for tasks such as flood mapping,wildfire detection, or land-use studies. For each task, scientists carefullychoose appropriate modalities or leverage data from purpose-built instruments.Recent work on remote sensing foundation models pre-trains computer visionmodels on large amounts of remote sensing data. These large-scale models tendto focus on specific modalities, often optical RGB or multispectral data. Formany important applications, this introduces a mismatch between the applicationmodalities and the pre-training data. Moreover, the large size of foundationmodels makes them expensive and difficult to fine-tune on typically smalldatasets for each task. We address this mismatch with MAPEX, a remote sensingfoundation model based on mixture-of-modality experts. MAPEX is pre-trained onmulti-modal remote sensing data with a novel modality-conditioned token routingmechanism that elicits modality-specific experts. To apply the model on aspecific task, we propose a modality aware pruning technique, which onlyretains experts specialized for the task modalities. This yields efficientmodality-specific models while simplifying fine-tuning and deployment for themodalities of interest. We experimentally validate MAPEX on diverse remotesensing datasets and show strong performance compared to fully supervisedtraining and state-of-the-art remote sensing foundation models. Code isavailable at https://github.com/HSG-AIML/MAPEX.</description>
      <author>example@mail.com (Joelle Hanna, Linus Scheibenreif, Damian Borth)</author>
      <guid isPermaLink="false">2507.07527v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Multilayer GNN for Predictive Maintenance and Clustering in Power Grids</title>
      <link>http://arxiv.org/abs/2507.07298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种多层图神经网络（GNN）框架，用于增强预测性维护（PdM）并实现基于弹性的变电站聚类，以减少美国经济因电网故障而造成的1500亿美元以上的年度损失。&lt;h4&gt;背景&lt;/h4&gt;不计划停电每年给美国经济造成超过1500亿美元的损失，部分原因是预测性维护模型忽略了电网故障中的空间、时间和因果关系。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过引入GNN框架来提高PdM的准确性，并实现基于弹性的变电站聚类。&lt;h4&gt;方法&lt;/h4&gt;研究使用了来自Oklahoma Gas &amp; Electric的七年事故数据（共292,830条记录，涉及347个变电站），该框架集成了图注意力网络（空间）、图卷积网络（时间）和图同构网络（因果关系），并通过注意力加权嵌入融合。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在30天的F1分数上达到了0.8935+/- 0.0258，比XGBoost和随机森林分别高出3.2%和2.7%，比单层GNN高出10到15个百分点。移除因果关系层将性能降低到0.7354 +/- 0.0418。对于弹性分析，基于分层风险GNN嵌入的HDBSCAN聚类确定了八个操作风险组。最高风险集群（Cluster 5，44个变电站）每年有388.4起事件和602.6分钟的恢复时间，而低风险组每年报告的事件少于62起。ANOVA（p &lt; 0.0001）证实了集群间的显著分离。该聚类在轮廓分数为0.626和Davies-Bouldin指数为0.527的情况下优于K-Means和谱聚类。&lt;h4&gt;结论&lt;/h4&gt;这项工作通过改进故障预测和风险感知的变电站聚类，支持了主动电网管理。&lt;h4&gt;翻译&lt;/h4&gt;This study proposes a multilayer Graph Neural Network (GNN) framework to enhance predictive maintenance (PdM) and enable resilience-based substation clustering in order to reduce the annual economic loss of over $150 billion in the US due to grid failures. The background is that unplanned power outages cost the US economy over $150 billion annually, partly due to predictive maintenance (PdM) models that overlook spatial, temporal, and causal dependencies in grid failures. The purpose of the study is to improve the accuracy of PdM and achieve resilience-based substation clustering through the introduction of a GNN framework. The study used seven years of incident data from Oklahoma Gas &amp; Electric (292,830 records across 347 substations), and the framework integrated Graph Attention Networks (spatial), Graph Convolutional Networks (temporal), and Graph Isomorphism Networks (causal), fused through attention-weighted embeddings. The model achieved a 30-day F1 score of 0.8935 +/- 0.0258, outperforming XGBoost and Random Forest by 3.2% and 2.7%, and single-layer GNNs by 10 to 15 percent. Removing the causal layer dropped performance to 0.7354 +/- 0.0418. For resilience analysis, HDBSCAN clustering on HierarchicalRiskGNN embeddings identified eight operational risk groups. The highest-risk cluster (Cluster 5, 44 substations) showed 388.4 incidents/year and 602.6-minute recovery time, while low-risk groups reported fewer than 62 incidents/year. ANOVA (p &lt; 0.0001) confirmed significant inter-cluster separation. The clustering outperformed K-Means and Spectral Clustering with a Silhouette Score of 0.626 and Davies-Bouldin index of 0.527. This work supports proactive grid management through improved failure prediction and risk-aware substation clustering.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unplanned power outages cost the US economy over $150 billion annually,partly due to predictive maintenance (PdM) models that overlook spatial,temporal, and causal dependencies in grid failures. This study introduces amultilayer Graph Neural Network (GNN) framework to enhance PdM and enableresilience-based substation clustering. Using seven years of incident data fromOklahoma Gas &amp; Electric (292,830 records across 347 substations), the frameworkintegrates Graph Attention Networks (spatial), Graph Convolutional Networks(temporal), and Graph Isomorphism Networks (causal), fused throughattention-weighted embeddings. Our model achieves a 30-day F1-score of 0.8935+/- 0.0258, outperforming XGBoost and Random Forest by 3.2% and 2.7%, andsingle-layer GNNs by 10 to 15 percent. Removing the causal layer dropsperformance to 0.7354 +/- 0.0418. For resilience analysis, HDBSCAN clusteringon HierarchicalRiskGNN embeddings identifies eight operational risk groups. Thehighest-risk cluster (Cluster 5, 44 substations) shows 388.4 incidents/year and602.6-minute recovery time, while low-risk groups report fewer than 62incidents/year. ANOVA (p &lt; 0.0001) confirms significant inter-clusterseparation. Our clustering outperforms K-Means and Spectral Clustering with aSilhouette Score of 0.626 and Davies-Bouldin index of 0.527. This work supportsproactive grid management through improved failure prediction and risk-awaresubstation clustering.</description>
      <author>example@mail.com (Muhammad Kazim, Harun Pirim, Chau Le, Trung Le, Om Prakash Yadav)</author>
      <guid isPermaLink="false">2507.07298v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>CL-Polyp: A Contrastive Learning-Enhanced Network for Accurate Polyp Segmentation</title>
      <link>http://arxiv.org/abs/2507.07154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对比学习的结肠镜图像息肉分割网络CL-Polyp，用于提高息肉分割的准确性，以辅助结直肠癌的早期诊断和治疗。&lt;h4&gt;背景&lt;/h4&gt;现有的基于深度学习的息肉分割方法通常采用编码器-解码器架构，并可能利用多任务框架以增强分割性能，但这些方法往往需要额外的标注数据，并且依赖于任务相似性，这限制了它们的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要额外标注数据，并能有效分割息肉的深度学习网络。&lt;h4&gt;方法&lt;/h4&gt;CL-Polyp网络利用对比学习通过对比来自息肉图像的正负样本对来提高编码器的特征提取能力。此外，引入了MASPP模块以实现更好的多尺度特征融合，以及CA模块以融合低级和上采样特征以改善边界重建。&lt;h4&gt;主要发现&lt;/h4&gt;在Kvasir-SEG和CVC-ClinicDB数据集上，CL-Polyp将IoU指标分别提高了0.011和0.020，证明了其在临床息肉分割任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;CL-Polyp网络在息肉分割任务中优于现有方法，有效提高了分割性能，为结直肠癌的早期诊断和治疗提供了有力支持。&lt;h4&gt;翻译&lt;/h4&gt;Accurate segmentation of polyps from colonoscopy images is crucial for the early diagnosis and treatment of colorectal cancer. Most existing deep learning-based polyp segmentation methods adopt an Encoder-Decoder architecture, and some utilize multi-task frameworks that incorporate auxiliary tasks such as classification to enhance segmentation performance. However, these approaches often require additional labeled data and rely on task similarity, which can limit their generalizability. To address these challenges, we propose CL-Polyp, a contrastive learning-enhanced polyp segmentation network. Our method leverages contrastive learning to improve the encoder's ability to extract discriminative features by contrasting positive and negative sample pairs derived from polyp images. This self-supervised strategy enhances visual representation without requiring additional annotations. In addition, we introduce two lightweight and effective modules: the Modified Atrous Spatial Pyramid Pooling (MASPP) module for better multi-scale feature fusion, and the Channel Concatenate and Element Add (CA) module to fuse low-level and upsampled features for improved boundary reconstruction. Extensive experiments on five benchmark datasets-Kvasir-SEG, CVC-ClinicDB, CVC-ColonDB, CVC-300, and ETIS-demonstrate that CL-Polyp consistently outperforms state-of-the-art methods. Specifically, it improves the IoU metric by 0.011 and 0.020 on the Kvasir-SEG and CVC-ClinicDB datasets, respectively, validating its effectiveness in clinical polyp segmentation tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate segmentation of polyps from colonoscopy images is crucial for theearly diagnosis and treatment of colorectal cancer. Most existing deeplearning-based polyp segmentation methods adopt an Encoder-Decoderarchitecture, and some utilize multi-task frameworks that incorporate auxiliarytasks such as classification to enhance segmentation performance. However,these approaches often require additional labeled data and rely on tasksimilarity, which can limit their generalizability. To address thesechallenges, we propose CL-Polyp, a contrastive learning-enhanced polypsegmentation network. Our method leverages contrastive learning to improve theencoder's ability to extract discriminative features by contrasting positiveand negative sample pairs derived from polyp images. This self-supervisedstrategy enhances visual representation without requiring additionalannotations. In addition, we introduce two lightweight and effective modules:the Modified Atrous Spatial Pyramid Pooling (MASPP) module for bettermulti-scale feature fusion, and the Channel Concatenate and Element Add (CA)module to fuse low-level and upsampled features for improved boundaryreconstruction. Extensive experiments on five benchmark datasets-Kvasir-SEG,CVC-ClinicDB, CVC-ColonDB, CVC-300, and ETIS-demonstrate that CL-Polypconsistently outperforms state-of-the-art methods. Specifically, it improvesthe IoU metric by 0.011 and 0.020 on the Kvasir-SEG and CVC-ClinicDB datasets,respectively, validating its effectiveness in clinical polyp segmentationtasks.</description>
      <author>example@mail.com (Desheng Li, Chaoliang Liu, Zhiyong Xiao)</author>
      <guid isPermaLink="false">2507.07154v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Towards Interpretable Time Series Foundation Models</title>
      <link>http://arxiv.org/abs/2507.07439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  International Conference on Machine Leaning (ICML) 2025 Workshop on  Foundation Models for Structured Data&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将时间序列推理能力蒸馏到小型、指令调整的语言模型中，作为构建可解释的时间序列基础模型的一部分。&lt;h4&gt;背景&lt;/h4&gt;通过利用一个具有系统变化趋势和噪声水平的合成时间序列数据集，使用大型多模态模型生成自然语言注释，并使用这些注释监督紧凑的Qwen模型的微调。&lt;h4&gt;目的&lt;/h4&gt;旨在构建可解释的、能够解释时间序列中自然语言模式的模型。&lt;h4&gt;方法&lt;/h4&gt;引入了评估度量标准，以评估蒸馏推理的质量，重点关注趋势方向、噪声强度和极值定位。&lt;h4&gt;主要发现&lt;/h4&gt;经过训练的模型获得了有意义的解释能力，结果表明将时间序列理解压缩到轻量级、语言能力的模型是可行的，这些模型适用于设备本地或对隐私敏感的部署。&lt;h4&gt;结论&lt;/h4&gt;本研究为开发小型、可解释的模型提供了具体的理论基础，这些模型能够以自然语言解释时间序列中的模式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we investigate the distillation of time series reasoningcapabilities into small, instruction-tuned language models as a step towardbuilding interpretable time series foundation models. Leveraging a syntheticdataset of mean-reverting time series with systematically varied trends andnoise levels, we generate natural language annotations using a large multimodalmodel and use these to supervise the fine-tuning of compact Qwen models. Weintroduce evaluation metrics that assess the quality of the distilled reasoning- focusing on trend direction, noise intensity, and extremum localization - andshow that the post-trained models acquire meaningful interpretive capabilities.Our results highlight the feasibility of compressing time series understandinginto lightweight, language-capable models suitable for on-device orprivacy-sensitive deployment. This work contributes a concrete foundationtoward developing small, interpretable models that explain temporal patterns innatural language.</description>
      <author>example@mail.com (Matthieu Boileau, Philippe Helluy, Jeremy Pawlus, Svitlana Vyetrenko)</author>
      <guid isPermaLink="false">2507.07439v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Machine learning driven reconstruction of cosmic-ray air showers for next generation radio arrays</title>
      <link>http://arxiv.org/abs/2507.07219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 39th International Cosmic Ray Conference (ICRC2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种利用图神经网络技术来重建关键大气簇射参数的方法，旨在解决宇宙射线空气簇射测量中的计算挑战。&lt;h4&gt;背景&lt;/h4&gt;表面无线电天线测量的宇宙射线空气簇射在准确重建物理可观测量方面存在显著的计算挑战，特别是簇射最大深度X_max。&lt;h4&gt;目的&lt;/h4&gt;提出一种技术，利用图神经网络重建关键大气簇射参数，特别是方向、簇射核心、能量和X_max。&lt;h4&gt;方法&lt;/h4&gt;使用CoREAS模拟库进行网络训练和测试，该库是为未来增强IceCube表面阵列而设计的。&lt;h4&gt;主要发现&lt;/h4&gt;图神经网络提供了一个可扩展的框架，用于大规模数据分析，适用于下一代天体粒子观测站，如IceCube-Gen2。&lt;h4&gt;结论&lt;/h4&gt;该方法为大型天体粒子观测站提供了一种可扩展的数据分析框架。&lt;h4&gt;翻译&lt;/h4&gt;Surface radio antenna-based measurements of cosmic-ray air showers present significant computational challenges in accurately reconstructing physics observables, in particular, the depth of shower maximum, X_max. State-of-the-art template fitting methods rely on extensive simulation libraries, limiting scalability. This work introduces a technique utilizing graph neural networks to reconstruct key air-shower parameters, in particular, direction and shower-core, energy, and X_max. For training and testing of the networks, we use a CoREAS simulation library made for a future enhancement of IceCube's surface array with radio antennas. The neural networks provide a scalable framework for large-scale data analysis for next-generation astroparticle observatories, such as IceCube-Gen2.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surface radio antenna-based measurements of cosmic-ray air showers presentsignificant computational challenges in accurately reconstructing physicsobservables, in particular, the depth of shower maximum, X$_{max}$.State-of-the-art template fitting methods rely on extensive simulationlibraries, limiting scalability. This work introduces a technique utilizinggraph neural networks to reconstruct key air-shower parameters, in particular,direction and shower-core, energy, and X$_{max}$. For training and testing ofthe networks, we use a CoREAS simulation library made for a future enhancementof IceCube's surface array with radio antennas. The neural networks provide ascalable framework for large-scale data analysis for next-generationastroparticle observatories, such as IceCube-Gen2.</description>
      <author>example@mail.com (Paras Koundal)</author>
      <guid isPermaLink="false">2507.07219v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>EPIC: Efficient Prompt Interaction for Text-Image Classification</title>
      <link>http://arxiv.org/abs/2507.07415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2401.14856&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EPIC的基于提示的多模态交互策略，用于文本-图像分类任务，旨在降低计算成本并提高效率。&lt;h4&gt;背景&lt;/h4&gt;近年来，大规模预训练的多模态模型在多模态任务中取得了显著成功，但其规模庞大导致下游任务微调的计算成本高。&lt;h4&gt;目的&lt;/h4&gt;研究基于提示的交互策略，以更有效地对齐模态。&lt;h4&gt;方法&lt;/h4&gt;利用中间层的时序提示，并通过基于相似性的提示交互整合不同模态，以实现模态间充分的信息交换。&lt;h4&gt;主要发现&lt;/h4&gt;该方法相比其他微调策略，减少了计算资源消耗和可训练参数（约为基础模型的1%），在UPMC-Food101和SNLI-VE数据集上表现出色，在MM-IMDB数据集上则实现了可比较的性能。&lt;h4&gt;结论&lt;/h4&gt;EPIC策略在降低计算成本的同时，提高了文本-图像分类任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, large-scale pre-trained multimodal models (LMMs) generallyemerge to integrate the vision and language modalities, achieving considerablesuccess in multimodal tasks, such as text-image classification. The growingsize of LMMs, however, results in a significant computational cost forfine-tuning these models for downstream tasks. Hence, prompt-based interactionstrategy is studied to align modalities more efficiently. In this context, wepropose a novel efficient prompt-based multimodal interaction strategy, namelyEfficient Prompt Interaction for text-image Classification (EPIC).Specifically, we utilize temporal prompts on intermediate layers, and integratedifferent modalities with similarity-based prompt interaction, to leveragesufficient information exchange between modalities. Utilizing this approach,our method achieves reduced computational resource consumption and fewertrainable parameters (about 1\% of the foundation model) compared to otherfine-tuning strategies. Furthermore, it demonstrates superior performance onthe UPMC-Food101 and SNLI-VE datasets, while achieving comparable performanceon the MM-IMDB dataset.</description>
      <author>example@mail.com (Xinyao Yu, Hao Sun, Zeyu Ling, Ziwei Niu, Zhenjia Bai, Rui Qin, Yen-Wei Chen, Lanfen Lin)</author>
      <guid isPermaLink="false">2507.07415v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>PacGDC: Label-Efficient Generalizable Depth Completion with Projection Ambiguity and Consistency</title>
      <link>http://arxiv.org/abs/2507.07374v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了PacGDC，一种标签高效的深度补全技术，通过最小化标注工作来增强数据多样性，从而实现通用的深度补全。&lt;h4&gt;背景&lt;/h4&gt;深度补全模型能够获取未见过环境的密集深度图，为下游任务提供鲁棒的感觉能力，但通常需要大量具有深度标签的大规模数据集，这通常是劳动密集型的。&lt;h4&gt;目的&lt;/h4&gt;开发一种标签效率高、能够通过最小标注努力增强数据多样性的深度补全技术。&lt;h4&gt;方法&lt;/h4&gt;PacGDC基于对2D到3D投影过程中物体形状和位置固有的模糊性和一致性的新见解，通过操纵对应深度图的场景尺度来合成多个伪几何形状。该方法通过使用多个深度基础模型作为尺度操作员来合成新的数据，并通过插值和重定位策略以及未标记图像来进一步多样化几何形状。&lt;h4&gt;主要发现&lt;/h4&gt;PacGDC在多个基准测试中表现出出色的泛化能力，在多样场景语义/尺度以及零样本和少样本设置下的深度稀疏/模式方面均表现卓越。&lt;h4&gt;结论&lt;/h4&gt;PacGDC通过有效利用基础模型和数据多样性策略，显著提高了深度补全模型的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;PacGDC是一种高效的深度补全方法，通过最小标注努力增强了数据多样性，为深度补全模型提供了鲁棒和泛化的感知能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalizable depth completion enables the acquisition of dense metric depthmaps for unseen environments, offering robust perception capabilities forvarious downstream tasks. However, training such models typically requireslarge-scale datasets with metric depth labels, which are often labor-intensiveto collect. This paper presents PacGDC, a label-efficient technique thatenhances data diversity with minimal annotation effort for generalizable depthcompletion. PacGDC builds on novel insights into inherent ambiguities andconsistencies in object shapes and positions during 2D-to-3D projection,allowing the synthesis of numerous pseudo geometries for the same visual scene.This process greatly broadens available geometries by manipulating scene scalesof the corresponding depth maps. To leverage this property, we propose a newdata synthesis pipeline that uses multiple depth foundation models as scalemanipulators. These models robustly provide pseudo depth labels with variedscene scales, affecting both local objects and global layouts, while ensuringprojection consistency that supports generalization. To further diversifygeometries, we incorporate interpolation and relocation strategies, as well asunlabeled images, extending the data coverage beyond the individual use offoundation models. Extensive experiments show that PacGDC achieves remarkablegeneralizability across multiple benchmarks, excelling in diverse scenesemantics/scales and depth sparsity/patterns under both zero-shot and few-shotsettings. Code: https://github.com/Wang-xjtu/PacGDC.</description>
      <author>example@mail.com (Haotian Wang, Aoran Xiao, Xiaoqin Zhang, Meng Yang, Shijian Lu)</author>
      <guid isPermaLink="false">2507.07374v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Time Series Foundation Models for Multivariate Financial Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2507.07296v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  66 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究评估了两种时间序列基础模型（Tiny Time Mixers和Chronos）在三个金融预测任务上的表现，结果表明Tiny Time Mixers在数据有限的情况下具有强大的迁移能力，且无需微调即可超越传统基准模型。&lt;h4&gt;背景&lt;/h4&gt;金融时间序列预测由于复杂的非线性关系、时间依赖性、变量相互依赖性和数据有限等问题，具有显著挑战性。&lt;h4&gt;目的&lt;/h4&gt;评估两种时间序列基础模型（Tiny Time Mixers和Chronos）在金融预测任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;在三个金融预测任务上对Tiny Time Mixers和Chronos进行评估，包括美国10年期国债收益率变化、EUR/USD波动性和股票收益率预测。&lt;h4&gt;主要发现&lt;/h4&gt;Tiny Time Mixers在数据有限的情况下比未经训练的模型表现更好，且在无需微调的情况下也能超越传统基准模型。预训练模型所需数据量比未经训练模型少3-10年，显示出显著的样本效率提升。&lt;h4&gt;结论&lt;/h4&gt;时间序列基础模型在金融预测方面具有潜力，但要实现竞争性性能可能需要特定领域的预训练和针对金融时间序列特征的架构改进。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于复杂的非线性关系、时间依赖性、变量相互依赖性和数据有限等问题，金融时间序列预测具有重大挑战。时间序列基础模型（TSFMs）通过在多样化的时间序列语料库上进行预训练，然后进行特定任务的调整，提供了一种有希望的解决方案。本研究评估了两种TSFMs（Tiny Time Mixers（TTM）和Chronos）在三个金融预测任务上的表现：美国10年期国债收益率变化、EUR/USD波动性和股票收益率预测。结果表明，TTM显示出强大的迁移能力。当对预训练的TTM版本和具有相同架构的未经训练模型进行微调时，在有限的数据上进行微调时，预训练版本的性能提高了25-50%，而在更长的数据集上进行微调时提高了15-30%。值得注意的是，TTM的零样本性能在波动性和股票收益率预测中优于朴素基准，后者表明TSFMs无需微调即可超越传统基准模型。与未经训练的模型相比，预训练模型始终需要3-10年更少的数据才能达到可比的性能水平，这表明具有显著的样本效率提升。然而，尽管TTM优于朴素基准，但在三个任务中的两个任务中，传统的专业模型的表现与TTM相当或超过了它的表现，这表明TSFMs优先考虑了广度而不是特定任务的优化。这些发现表明，尽管TSFMs仍然处于起步阶段，但它们在金融预测方面具有巨大的潜力——尤其是在噪声大、数据受限的任务中——但要实现竞争性性能可能需要特定领域的预训练和针对金融时间序列特征的架构改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Financial time series forecasting presents significant challenges due tocomplex nonlinear relationships, temporal dependencies, variableinterdependencies and limited data availability, particularly for tasksinvolving low-frequency data, newly listed instruments, or emerging marketassets. Time Series Foundation Models (TSFMs) offer a promising solutionthrough pretraining on diverse time series corpora followed by task-specificadaptation. This study evaluates two TSFMs (Tiny Time Mixers (TTM) and Chronos)across three financial forecasting tasks: US 10-year Treasury yield changes,EUR/USD volatility, and equity spread prediction. Results demonstrate that TTMexhibits strong transferability. When fine-tuning both the pretrained versionof TTM and an untrained model with the same architecture, the pretrainedversion achieved 25-50% better performance when fine-tuned on limited data and15-30% improvements even when fine-tuned on lengthier datasets. Notably, TTM'szero-shot performance outperformed naive benchmarks in volatility forecastingand equity spread prediction, with the latter demonstrating that TSFMs cansurpass traditional benchmark models without fine-tuning. The pretrained modelconsistently required 3-10 fewer years of data to achieve comparableperformance levels compared to the untrained model, demonstrating significantsample-efficiency gains. However, while TTM outperformed naive baselines,traditional specialised models matched or exceeded its performance in two ofthree tasks, suggesting TSFMs prioritise breadth over task-specificoptimisation. These findings indicate that TSFMs, though still nascent, offersubstantial promise for financial forecasting-particularly in noisy,data-constrained tasks-but achieving competitive performance likely requiresdomain-specific pretraining and architectural refinements tailored to financialtime series characteristics.</description>
      <author>example@mail.com (Ben A. Marconi)</author>
      <guid isPermaLink="false">2507.07296v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Str-GCL: Structural Commonsense Driven Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.07141v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by WWW 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了名为Str-GCL的新框架，旨在通过在图对比学习中直接整合结构常识，以提高图表示学习的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的图对比学习（GCL）方法主要关注捕捉隐式语义关系，往往忽略了图的结构和属性中嵌入的结构常识，这对于有效的表示学习至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决GCL中缺乏明确信息与指导的问题，以识别和整合图中的结构常识。&lt;h4&gt;方法&lt;/h4&gt;Str-GCL利用一阶逻辑规则来表示结构常识，并将其显式地整合到GCL框架中。它引入了拓扑和基于属性的规则，而不改变原始图，并使用表示对齐机制来引导编码器有效地捕捉这种常识。&lt;h4&gt;主要发现&lt;/h4&gt;Str-GCL是首次尝试将结构常识直接纳入GCL，实验结果表明，Str-GCL优于现有的GCL方法，为利用结构常识进行图表示学习提供了新的视角。&lt;h4&gt;结论&lt;/h4&gt;Str-GCL框架通过整合结构常识提高了图对比学习的效果，为图表示学习提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714900&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning (GCL) is a widely adopted approach inself-supervised graph representation learning, applying contrastive objectivesto produce effective representations. However, current GCL methods primarilyfocus on capturing implicit semantic relationships, often overlooking thestructural commonsense embedded within the graph's structure and attributes,which contains underlying knowledge crucial for effective representationlearning. Due to the lack of explicit information and clear guidance in generalgraph, identifying and integrating such structural commonsense in GCL poses asignificant challenge. To address this gap, we propose a novel framework calledStructural Commonsense Unveiling in Graph Contrastive Learning (Str-GCL).Str-GCL leverages first-order logic rules to represent structural commonsenseand explicitly integrates them into the GCL framework. It introducestopological and attribute-based rules without altering the original graph andemploys a representation alignment mechanism to guide the encoder ineffectively capturing this commonsense. To the best of our knowledge, this isthe first attempt to directly incorporate structural commonsense into GCL.Extensive experiments demonstrate that Str-GCL outperforms existing GCLmethods, providing a new perspective on leveraging structural commonsense ingraph representation learning.</description>
      <author>example@mail.com (Dongxiao He, Yongqi Huang, Jitao Zhao, Xiaobao Wang, Zhen Wang)</author>
      <guid isPermaLink="false">2507.07141v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2507.07197v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at 4th Conference on Lifelong Learning Agents (CoLLAs),  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Weight Sharing Attention (WSA)的新架构，用于在强化学习（RL）中结合多个预训练模型的嵌入，以形成丰富的状态表示，平衡效率与性能。&lt;h4&gt;背景&lt;/h4&gt;预训练模型在多个领域（如自然语言处理和计算机视觉）中发挥着关键作用，而强化学习（RL）通过智能体与环境交互来最大化累积奖励。然而，如何有效地结合多个预训练模型的信息在RL中仍然是一个未解决的研究问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，即Weight Sharing Attention (WSA)，以在强化学习中有效地结合和利用多个预训练模型的隐藏信息。&lt;h4&gt;方法&lt;/h4&gt;提出了WSA架构，通过比较多种组合模式，在多个Atari游戏中展示了WSA与端到端模型相比的可比性能。此外，研究了该方法的泛化能力，并分析了模型数量对训练中及训练后智能体性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;WSA在多个Atari游戏中实现了与端到端模型相当的性能，并展示了其泛化能力，以及模型数量对智能体性能的影响。&lt;h4&gt;结论&lt;/h4&gt;WSA是一种有效的强化学习架构，能够结合多个预训练模型的嵌入，在保持效率的同时提高性能。&lt;h4&gt;翻译&lt;/h4&gt;最近，预训练模型的研究和发布成为了许多领域（例如自然语言处理和计算机视觉）进步的关键组成部分。实际上，预训练模型学习到了不同的潜在嵌入，共享有洞察力的表示。另一方面，强化学习（RL）侧重于通过智能体与环境的交互来最大化累积奖励。RL智能体对世界没有任何先验知识，它们要么从头开始学习观察空间和动作空间之间的端到端映射，要么在更近期的作品中与庞大且计算成本高昂的基础模型配对。如何在强化学习中有效地同时结合和利用不同预训练模型的隐藏信息仍然是一个开放且研究不足的问题。在这项工作中，我们提出了Weight Sharing Attention (WSA)，一种新的架构，用于结合多个预训练模型的嵌入以形成丰富的状态表示，平衡效率与性能之间的权衡。我们进行了广泛的比较，展示了WSA在多个Atari游戏中的性能与端到端模型相当。此外，我们研究了这种方法的泛化能力，并分析了扩大模型数量如何影响智能体在训练中和训练后的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent focus and release of pre-trained models have been a key componentsto several advancements in many fields (e.g. Natural Language Processing andComputer Vision), as a matter of fact, pre-trained models learn disparatelatent embeddings sharing insightful representations. On the other hand,Reinforcement Learning (RL) focuses on maximizing the cumulative rewardobtained via agent's interaction with the environment. RL agents do not haveany prior knowledge about the world, and they either learn from scratch anend-to-end mapping between the observation and action spaces or, in more recentworks, are paired with monolithic and computationally expensive FoundationalModels. How to effectively combine and leverage the hidden information ofdifferent pre-trained models simultaneously in RL is still an open andunderstudied question. In this work, we propose Weight Sharing Attention (WSA),a new architecture to combine embeddings of multiple pre-trained models toshape an enriched state representation, balancing the tradeoff betweenefficiency and performance. We run an extensive comparison between severalcombination modes showing that WSA obtains comparable performance on multipleAtari games compared to end-to-end models. Furthermore, we study thegeneralization capabilities of this approach and analyze how scaling the numberof models influences agents' performance during and after training.</description>
      <author>example@mail.com (Elia Piccoli, Malio Li, Giacomo Carfì, Vincenzo Lomonaco, Davide Bacciu)</author>
      <guid isPermaLink="false">2507.07197v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>An attention-aware GNN-based input defender against multi-turn jailbreak on LLMs</title>
      <link>http://arxiv.org/abs/2507.07146v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为G-Guard的创新注意力感知GNN输入分类器，用于防御大型语言模型（LLMs）的多轮越狱攻击。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在各个应用中得到了广泛应用，但其能力可以被用于良性和有害的目的。尽管经过严格训练和微调以确保安全，LLMs仍然容易受到越狱攻击，特别是多轮攻击，这使得攻击更难以检测和缓解。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够防御多轮越狱攻击的机制，以保护LLMs的安全性。&lt;h4&gt;方法&lt;/h4&gt;G-Guard构建了一个实体图来处理多轮查询，明确捕捉有害关键词与查询之间的关系。此外，它还引入了一种注意力感知的增强机制，根据多轮对话检索最相似的单轮查询，并将其作为图中的一个标记节点，以增强GNN分类当前查询是否有害的能力。&lt;h4&gt;主要发现&lt;/h4&gt;G-Guard在所有数据集和评估指标上均优于所有基线。&lt;h4&gt;结论&lt;/h4&gt;G-Guard是一种有效的防御多轮越狱攻击的方法，能够显著提高LLMs的安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have gained widespread popularity and areincreasingly integrated into various applications. However, their capabilitiescan be exploited for both benign and harmful purposes. Despite rigoroustraining and fine-tuning for safety, LLMs remain vulnerable to jailbreakattacks. Recently, multi-turn attacks have emerged, exacerbating the issue.Unlike single-turn attacks, multi-turn attacks gradually escalate the dialogue,making them more difficult to detect and mitigate, even after they areidentified.  In this study, we propose G-Guard, an innovative attention-aware GNN-basedinput classifier designed to defend against multi-turn jailbreak attacks onLLMs. G-Guard constructs an entity graph for multi-turn queries, explicitlycapturing relationships between harmful keywords and queries even when thosekeywords appear only in previous queries. Additionally, we introduce anattention-aware augmentation mechanism that retrieves the most similarsingle-turn query based on the multi-turn conversation. This retrieved query istreated as a labeled node in the graph, enhancing the ability of GNN toclassify whether the current query is harmful. Evaluation results demonstratethat G-Guard outperforms all baselines across all datasets and evaluationmetrics.</description>
      <author>example@mail.com (Zixuan Huang, Kecheng Huang, Lihao Yin, Bowei He, Huiling Zhen, Mingxuan Yuan, Zili Shao)</author>
      <guid isPermaLink="false">2507.07146v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>CoPT: Unsupervised Domain Adaptive Segmentation using Domain-Agnostic Text Embeddings</title>
      <link>http://arxiv.org/abs/2507.07125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECCV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的无监督领域自适应（UDA）方法，用于图像分割任务，通过利用文本嵌入学习领域不变的特征，以解决标注数据收集困难的问题。&lt;h4&gt;背景&lt;/h4&gt;无监督领域自适应（UDA）在语义分割等标注数据难以收集的任务中具有重要作用。尽管近年来视觉-语言表示学习取得了进展，但UDA方法在分割任务中尚未充分利用文本的领域无关性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过利用文本嵌入学习领域不变的特征，以提高无监督领域自适应（UDA）在图像分割任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种基于协方差像素-文本损失（CoPT）的方法，该方法使用领域无关的文本嵌入来学习图像分割编码器中的领域不变特征。文本嵌入通过LLM领域模板过程生成，其中大型语言模型（LLM）用于生成源域和目标域的描述，然后与冻结的CLIP模型结合。&lt;h4&gt;主要发现&lt;/h4&gt;在四个基准测试中，使用CoPT训练的模型在UDA分割任务上达到了新的最佳性能。&lt;h4&gt;结论&lt;/h4&gt;CoPT方法在无监督领域自适应（UDA）图像分割任务中表现出色，为该领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised domain adaptation (UDA) involves learning class semantics from labeled data within a source domain that generalize to an unseen target domain. UDA methods are particularly impactful for semantic segmentation, where annotations are more difficult to collect than in image classification. Despite recent advances in large-scale vision-language representation learning, UDA methods for segmentation have not taken advantage of the domain-agnostic properties of text. To address this, we present a novel Covariance-based Pixel-Text loss, CoPT, that uses domain-agnostic text embeddings to learn domain-invariant features in an image segmentation encoder. The text embeddings are generated through our LLM Domain Template process, where an LLM is used to generate source and target domain descriptions that are fed to a frozen CLIP model and combined. In experiments on four benchmarks we show that a model trained using CoPT achieves the new state of the art performance on UDA for segmentation. The code can be found at https://github.com/cfmata/CoPT.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised domain adaptation (UDA) involves learning class semantics fromlabeled data within a source domain that generalize to an unseen target domain.UDA methods are particularly impactful for semantic segmentation, whereannotations are more difficult to collect than in image classification. Despiterecent advances in large-scale vision-language representation learning, UDAmethods for segmentation have not taken advantage of the domain-agnosticproperties of text. To address this, we present a novel Covariance-basedPixel-Text loss, CoPT, that uses domain-agnostic text embeddings to learndomain-invariant features in an image segmentation encoder. The text embeddingsare generated through our LLM Domain Template process, where an LLM is used togenerate source and target domain descriptions that are fed to a frozen CLIPmodel and combined. In experiments on four benchmarks we show that a modeltrained using CoPT achieves the new state of the art performance on UDA forsegmentation. The code can be found at https://github.com/cfmata/CoPT.</description>
      <author>example@mail.com (Cristina Mata, Kanchana Ranasinghe, Michael S. Ryoo)</author>
      <guid isPermaLink="false">2507.07125v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models</title>
      <link>http://arxiv.org/abs/2507.06952v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基础模型在序列预测中的应用，并开发了一种评估这些模型的方法，该方法通过合成数据集来检验模型是否能够适应预设的世界模型，发现基础模型在训练任务中表现出色，但在适应新任务时未能形成对底层世界模型的理解。&lt;h4&gt;背景&lt;/h4&gt;基础模型基于序列预测可以发现更深层次的领域理解，类似于开普勒预测行星运动最终导致牛顿力学被发现。然而，评估这些模型是否真正捕捉到更深层次结构仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种技术来评估基础模型，通过检验它们如何适应从一些假设的世界模型生成的合成数据集，来衡量基础模型的归纳偏差是否与世界模型一致。&lt;h4&gt;方法&lt;/h4&gt;提出了一种归纳偏差探测技术，用于评估基础模型，该技术通过合成数据集来观察模型对新任务的适应情况。&lt;h4&gt;主要发现&lt;/h4&gt;发现基础模型在多个领域内训练任务中表现出色，但适应新任务时未能形成对底层世界模型的理解，特别是在训练在轨道轨迹上的模型时，适应新物理任务时无法应用牛顿力学。进一步分析表明，这些模型似乎形成了特定任务的启发式规则，而这些规则无法泛化。&lt;h4&gt;结论&lt;/h4&gt;基础模型在训练任务中表现出色，但在适应新任务时未能形成对底层世界模型的理解，表明它们可能发展出特定任务的启发式规则，这些规则无法应用于其他领域。&lt;h4&gt;翻译&lt;/h4&gt;本文基于序列预测的基础模型，旨在评估其捕捉深层领域理解的能力。通过开发一种技术，即归纳偏差探测，研究发现在多个领域内，基础模型在训练任务中表现优异，但在适应新任务时未能形成对底层世界模型的理解。特别是，基于轨道轨迹训练的模型在适应新物理任务时无法应用牛顿力学。进一步分析表明，这些模型似乎发展出了特定任务的启发式规则，这些规则无法泛化到其他领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are premised on the idea that sequence prediction canuncover deeper domain understanding, much like how Kepler's predictions ofplanetary motion later led to the discovery of Newtonian mechanics. However,evaluating whether these models truly capture deeper structure remains achallenge. We develop a technique for evaluating foundation models thatexamines how they adapt to synthetic datasets generated from some postulatedworld model. Our technique measures whether the foundation model's inductivebias aligns with the world model, and so we refer to it as an inductive biasprobe. Across multiple domains, we find that foundation models can excel attheir training tasks yet fail to develop inductive biases towards theunderlying world model when adapted to new tasks. We particularly find thatfoundation models trained on orbital trajectories consistently fail to applyNewtonian mechanics when adapted to new physics tasks. Further analysis revealsthat these models behave as if they develop task-specific heuristics that failto generalize.</description>
      <author>example@mail.com (Keyon Vafa, Peter G. Chang, Ashesh Rambachan, Sendhil Mullainathan)</author>
      <guid isPermaLink="false">2507.06952v2</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining</title>
      <link>http://arxiv.org/abs/2507.06795v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了开放源代码大型语言模型（LLMs）在商业应用中的潜力，特别是小型LLMs（sLLMs）作为大型模型替代品的适用性，并探讨了领域自适应持续预训练（DACP）在商业应用中的效用。&lt;h4&gt;背景&lt;/h4&gt;随着开放源代码大型语言模型（LLMs）的出现，企业应用的机会得到了扩展，但许多组织缺乏部署和维护大规模模型的基础设施。&lt;h4&gt;目的&lt;/h4&gt;验证基于领域自适应持续预训练（DACP）的方法在多种基础模型和服务领域中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;通过广泛的实验和实际评估，研究了DACP应用于小型LLMs的效果。&lt;h4&gt;主要发现&lt;/h4&gt;DACP应用的小型LLMs在目标领域性能上取得了显著提升，同时保持了通用能力，为企业的部署提供了一个成本效益高且可扩展的解决方案。&lt;h4&gt;结论&lt;/h4&gt;DACP是一种有效的领域自适应方法，适用于小型LLMs在商业应用中的性能提升，为企业在资源有限的情况下部署大型语言模型提供了可行的选择。&lt;h4&gt;翻译&lt;/h4&gt;The emergence of open-source large language models (LLMs) has expanded opportunities for enterprise applications; however, many organizations still lack the infrastructure to deploy and maintain large-scale models. As a result, small LLMs (sLLMs) have become a practical alternative, despite their inherent performance limitations. While Domain Adaptive Continual Pretraining (DACP) has been previously explored as a method for domain adaptation, its utility in commercial applications remains under-examined. In this study, we validate the effectiveness of applying a DACP-based recipe across diverse foundation models and service domains. Through extensive experiments and real-world evaluations, we demonstrate that DACP-applied sLLMs achieve substantial gains in target domain performance while preserving general capabilities, offering a cost-efficient and scalable solution for enterprise-level deployment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of open-source large language models (LLMs) has expandedopportunities for enterprise applications; however, many organizations stilllack the infrastructure to deploy and maintain large-scale models. As a result,small LLMs (sLLMs) have become a practical alternative, despite their inherentperformance limitations. While Domain Adaptive Continual Pretraining (DACP) hasbeen previously explored as a method for domain adaptation, its utility incommercial applications remains under-examined. In this study, we validate theeffectiveness of applying a DACP-based recipe across diverse foundation modelsand service domains. Through extensive experiments and real-world evaluations,we demonstrate that DACP-applied sLLMs achieve substantial gains in targetdomain performance while preserving general capabilities, offering acost-efficient and scalable solution for enterprise-level deployment.</description>
      <author>example@mail.com (Seonwu Kim, Yohan Na, Kihun Kim, Hanhee Cho, Geun Lim, Mintae Kim, Seongik Park, Ki Hyun Kim, Youngsub Han, Byoung-Ki Jeon)</author>
      <guid isPermaLink="false">2507.06795v2</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>GNNs Meet Sequence Models Along the Shortest-Path: an Expressive Method for Link Prediction</title>
      <link>http://arxiv.org/abs/2507.07138v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SP4LP的链接预测框架，通过结合基于图神经网络的节点编码和最短路径上的序列建模，有效地捕捉了链接预测中的多跳关系模式，并在多个基准测试中取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的图神经网络（GNNs）在链接预测中难以捕捉到连接两个节点的重要的特定链接结构，因为它们的以节点为中心的消息传递方案忽略了连接节点的子图结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，以解决现有方法在计算成本高或依赖简单启发式方法（如共同邻居计数）的问题，这些方法无法建模多跳依赖关系。&lt;h4&gt;方法&lt;/h4&gt;SP4LP首先使用GNN计算所有节点的表示，然后提取每个候选节点对之间的最短路径，并使用序列模型处理由此产生的节点嵌入序列。&lt;h4&gt;主要发现&lt;/h4&gt;SP4LP能够以计算效率捕捉多跳关系模式，并在链接预测基准测试中实现了最先进的性能。理论上，证明了SP4LP比标准的消息传递GNN和几种最先进的结构特征方法具有更强的表达能力。&lt;h4&gt;结论&lt;/h4&gt;SP4LP是一种通用的和原则性的图链接预测方法，它在捕捉链接预测中的结构上下文方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often struggle to capture the link-specificstructural patterns crucial for accurate link prediction, as their node-centricmessage-passing schemes overlook the subgraph structures connecting a pair ofnodes. Existing methods to inject such structural context either incur highcomputational cost or rely on simplistic heuristics (e.g., common neighborcounts) that fail to model multi-hop dependencies. We introduce SP4LP (ShortestPath for Link Prediction), a novel framework that combines GNN-based nodeencodings with sequence modeling over shortest paths. Specifically, SP4LP firstapplies a GNN to compute representations for all nodes, then extracts theshortest path between each candidate node pair and processes the resultingsequence of node embeddings using a sequence model. This design enables SP4LPto capture expressive multi-hop relational patterns with computationalefficiency. Empirically, SP4LP achieves state-of-the-art performance acrosslink prediction benchmarks. Theoretically, we prove that SP4LP is strictly moreexpressive than standard message-passing GNNs and several state-of-the-artstructural features methods, establishing it as a general and principledapproach for link prediction in graphs.</description>
      <author>example@mail.com (Francesco Ferrini, Veronica Lachi, Antonio Longa, Bruno Lepri, Andrea Passerini)</author>
      <guid isPermaLink="false">2507.07138v1</guid>
      <pubDate>Fri, 11 Jul 2025 14:24:42 +0800</pubDate>
    </item>
    <item>
      <title>Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS</title>
      <link>http://arxiv.org/abs/2507.05999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Transactions on Geoscience &amp; Remote Sensing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在GNSS信号受限的城市区域进行激光雷达点云精确地理配准的方法。&lt;h4&gt;背景&lt;/h4&gt;在GNSS信号受限的城市区域，如高楼大厦和桥梁附近，现有的地理配准方法通常依赖于实时GNSS和IMU数据，这些方法需要预先校准，并假设在数据收集过程中定位稳定，但在密集的城市区域这一假设常常不成立，导致定位误差。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，本文提出了一种结构化的地理配准和空间校正方法，该方法通过将3D点云与卫星图像对齐，实现帧级GNSS信息恢复和城市尺度3D地图重建，而不依赖于先前的定位。&lt;h4&gt;方法&lt;/h4&gt;该方法使用预训练的点Transformer模型来分割道路点，然后从点云中提取道路骨架和交叉口点，以及用于对齐的目标地图。使用交叉口点进行全局刚性对齐，随后使用径向基函数（RBF）插值进行局部细化。基于SRTM数据集中的地形信息对点云进行高程校正，以解决垂直差异。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI数据集上，该方法在包含交叉口的序列中实现了平均平面配准标准差（STD）为0.84米，相比原始数据集提高了55.3%。在缺乏GNSS信息的珀斯（澳大利亚西部）CBD数据集上，该方法实现了平均STD为0.96米，与从Google Maps API提取的GPS数据相比提高了77.4%。此外，在KITTI数据集上，该方法在海拔相关性方面提高了30.5%，在珀斯数据集上提高了50.4%。&lt;h4&gt;结论&lt;/h4&gt;该方法在GNSS信号受限的城市区域中实现了高精度的激光雷达点云地理配准，有效提高了点云的定位精度。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Accurate geo-registration of LiDAR point clouds presents significant challenges in GNSS signal denied urban areas with high-rise buildings and bridges. Existing methods typically rely on real-time GNSS and IMU data, that require pre-calibration and assume stable positioning during data collection. However, this assumption often fails in dense urban areas, resulting in localization errors. To address this, we propose a structured geo-registration and spatial correction method that aligns 3D point clouds with satellite images, enabling frame-wise recovery of GNSS information and reconstruction of city scale 3D maps without relying on prior localization. The proposed approach employs a pre-trained Point Transformer model to segment the road points and then extracts the road skeleton and intersection points from the point cloud as well as the target map for alignment. Global rigid alignment of the two is performed using the intersection points, followed by local refinement using radial basis function (RBF) interpolation. Elevation correction is then applied to the point cloud based on terrain information from SRTM dataset to resolve vertical discrepancies. The proposed method was tested on the popular KITTI benchmark and a locally collected Perth (Western Australia) CBD dataset. On the KITTI dataset, our method achieved an average planimetric alignment standard deviation (STD) of 0.84~m across sequences with intersections, representing a 55.3% improvement over the original dataset. On the Perth dataset, which lacks GNSS information, our method achieved an average STD of 0.96~m compared to the GPS data extracted from Google Maps API. This corresponds to a 77.4% improvement from the initial alignment. Our method also resulted in elevation correlation gains of 30.5% on the KITTI dataset and 50.4% on the Perth dataset.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate geo-registration of LiDAR point clouds presents significantchallenges in GNSS signal denied urban areas with high-rise buildings andbridges. Existing methods typically rely on real-time GNSS and IMU data, thatrequire pre-calibration and assume stable positioning during data collection.However, this assumption often fails in dense urban areas, resulting inlocalization errors. To address this, we propose a structured geo-registrationand spatial correction method that aligns 3D point clouds with satelliteimages, enabling frame-wise recovery of GNSS information and reconstruction ofcity scale 3D maps without relying on prior localization. The proposed approachemploys a pre-trained Point Transformer model to segment the road points andthen extracts the road skeleton and intersection points from the point cloud aswell as the target map for alignment. Global rigid alignment of the two isperformed using the intersection points, followed by local refinement usingradial basis function (RBF) interpolation. Elevation correction is then appliedto the point cloud based on terrain information from SRTM dataset to resolvevertical discrepancies. The proposed method was tested on the popular KITTIbenchmark and a locally collected Perth (Western Australia) CBD dataset. On theKITTI dataset, our method achieved an average planimetric alignment standarddeviation (STD) of 0.84~m across sequences with intersections, representing a55.3\% improvement over the original dataset. On the Perth dataset, which lacksGNSS information, our method achieved an average STD of 0.96~m compared to theGPS data extracted from Google Maps API. This corresponds to a 77.4\%improvement from the initial alignment. Our method also resulted in elevationcorrelation gains of 30.5\% on the KITTI dataset and 50.4\% on the Perthdataset.</description>
      <author>example@mail.com (Xinyu Wang, Muhammad Ibrahim, Atif Mansoor, Ajmal Mian)</author>
      <guid isPermaLink="false">2507.05999v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
  <item>
      <title>Topological Sequence Analysis of Genomes: Delta Complex approaches</title>
      <link>http://arxiv.org/abs/2507.05452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于拓扑序列分析（TSA）的新方法，应用于基因组序列分析，通过构建Δ复形和分类空间，得到基因组序列上的持久同伦和持久路径同伦，并开发了基于Δ复形的持久拉普拉斯算子，以促进基因组序列的拓扑谱分析。&lt;h4&gt;背景&lt;/h4&gt;代数拓扑已被广泛应用于点云数据以捕捉几何形状和拓扑结构，但其应用于基因组序列分析仍较为罕见。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的拓扑序列分析（TSA）技术，以应用于基因组序列分析。&lt;h4&gt;方法&lt;/h4&gt;通过构建Δ复形和分类空间，得到持久同伦和持久路径同伦，并开发基于Δ复形的持久拉普拉斯算子。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的TSA方法在埃博拉病毒序列和全细菌基因组中的系统发育分析中显示出其实用性，且比早期的TSA模型（如k-mer拓扑）更高效。&lt;h4&gt;结论&lt;/h4&gt;所提出的TSA方法在基因组序列分析中具有潜在的应用价值，并且可能被应用于其他耗时的序列数据分析，如语言学、文学、音乐、媒体和社会环境中的数据分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Algebraic topology has been widely applied to point cloud data to capturegeometric shapes and topological structures. However, its application to genomesequence analysis remains rare. In this work, we propose topological sequenceanalysis (TSA) techniques by constructing $\Delta$-complexes and classifyingspaces, leading to persistent homology, and persistent path homology on genomesequences. We also develop $\Delta$-complex-based persistent Laplacians tofacilitate the topological spectral analysis of genome sequences. Finally, wedemonstrate the utility of the proposed TSA approaches in phylogenetic analysisusing Ebola virus sequences and whole bacterial genomes. The present TSAmethods are more efficient than earlier TSA model, k-mer topology, and thushave a potential to be applied to other time-consuming sequential dataanalyses, such as those in linguistics, literature, music, media, and socialcontexts.</description>
      <author>example@mail.com (Jian Liu, Li Shen, Dong Chen, Guo-Wei Wei)</author>
      <guid isPermaLink="false">2507.05452v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator</title>
      <link>http://arxiv.org/abs/2507.07073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 9 figures, submitted for publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种几何深度学习框架，用于高效预测给定CAD网格的Laplace-Beltrami（LB）谱，通过减少计算时间约5倍，同时保持高精度，证明了LB谱是可学习的。&lt;h4&gt;背景&lt;/h4&gt;Laplace-Beltrami算子的谱在几何深度学习任务中起着核心作用，它捕捉了所考虑物体形状的内在属性。基于有限元素法（FEM）的方法是目前用于估计LB算子谱的最成熟方法，其复杂度为O(Nk)，其中N是点的数量。当反复应用于CAD机械部件数据库或质量控制应用中时，FEM方法可能变得低效。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来高效预测CAD网格的LB谱，同时减少计算时间，提高处理速度。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种基于图神经网络的架构，使用包括高斯曲率、平均曲率和主曲率在内的丰富部件网格特征。此外，为了确保可重复性，我们还提供了一个大型经过精心挑选的、由公共ABC数据集衍生出的真实世界机械CAD模型数据集。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与线性FEM相比，该方法将LB谱的计算时间减少了约5倍，同时保持了有竞争力的精度。&lt;h4&gt;结论&lt;/h4&gt;LB谱是可学习的，且本文提出的方法在计算效率上具有显著优势，适用于需要快速频繁进行部件质量控制的场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The spectrum of the Laplace-Beltrami (LB) operator is central in geometricdeep learning tasks, capturing intrinsic properties of the shape of the objectunder consideration. The best established method for its estimation, from atriangulated mesh of the object, is based on the Finite Element Method (FEM),and computes the top k LB eigenvalues with a complexity of O(Nk), where N isthe number of points. This can render the FEM method inefficient whenrepeatedly applied to databases of CAD mechanical parts, or in quality controlapplications where part metrology is acquired as large meshes and decisionsabout the quality of each part are needed quickly and frequently. As a solutionto this problem, we present a geometric deep learning framework to predict theLB spectrum efficiently given the CAD mesh of a part, achieving significantcomputational savings without sacrificing accuracy, demonstrating that the LBspectrum is learnable. The proposed Graph Neural Network architecture uses arich set of part mesh features - including Gaussian curvature, mean curvature,and principal curvatures. In addition to our trained network, we makeavailable, for repeatability, a large curated dataset of real-world mechanicalCAD models derived from the publicly available ABC dataset used for trainingand testing. Experimental results show that our method reduces computation timeof the LB spectrum by approximately 5 times over linear FEM while deliveringcompetitive accuracy.</description>
      <author>example@mail.com (Yulin An, Enrique del Castillo)</author>
      <guid isPermaLink="false">2507.07073v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Pathology Foundation Models and Spatial Transcriptomics for Cellular Decomposition from Histology Images</title>
      <link>http://arxiv.org/abs/2507.07013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种轻量级且训练高效的预测细胞组成的方法，通过利用预训练病理基础模型中的信息丰富特征嵌入，直接从H&amp;E染色组织图像中预测细胞组成。&lt;h4&gt;背景&lt;/h4&gt;数字病理学和深度学习的快速发展推动了病理基础模型的出现，这些模型有望在统一模型中解决各种疾病条件下的通用病理问题。同时，空间转录组学作为一项新兴技术，使得在H&amp;E染色组织图像上对基因表达进行表征成为可能。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，可以直接从H&amp;E染色组织图像中预测细胞组成，而无需进行成本高昂的空间转录组学。&lt;h4&gt;方法&lt;/h4&gt;通过在细胞类型丰度上训练一个轻量级的多层感知器（MLP）回归器，该方法有效地从病理基础模型中提取知识，并展示出从组织图像中准确预测细胞组成的潜力。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在性能上与现有的方法如Hist2Cell相当，同时显著降低了计算复杂度。&lt;h4&gt;结论&lt;/h4&gt;该轻量级且训练高效的方法能够直接从H&amp;E染色组织图像中预测细胞组成，为病理学研究和诊断提供了新的可能性，同时降低了计算成本。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着数字病理学和现代深度学习的快速发展，病理基础模型应运而生，有望在统一模型中解决各种疾病条件下的通用病理问题，无论是否经过微调。同时，空间转录组学作为一项变革性技术，使得在H&amp;E染色组织图像上对基因表达进行表征成为可能。空间转录组学解锁了深入现有组织图像的前所未有的机会，以更细粒度、细胞级的水平进行探究。在本研究中，我们提出了一种轻量级且训练高效的方法，通过利用从预训练病理基础模型中提取的信息丰富特征嵌入，直接从H&amp;E染色组织图像中预测细胞组成。通过在细胞2位置衍生出的细胞类型丰度上训练一个轻量级的多层感知器（MLP）回归器，我们的方法有效地从病理基础模型中提取知识，并证明了从组织图像中准确预测细胞组成的潜力，无需物理执行成本高昂的空间转录组学。我们的方法在性能上与现有方法（如Hist2Cell）相当，同时显著降低了计算复杂度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of digital pathology and modern deep learning hasfacilitated the emergence of pathology foundation models that are expected tosolve general pathology problems under various disease conditions in oneunified model, with or without fine-tuning. In parallel, spatialtranscriptomics has emerged as a transformative technology that enables theprofiling of gene expression on hematoxylin and eosin (H&amp;E) stained histologyimages. Spatial transcriptomics unlocks the unprecedented opportunity to diveinto existing histology images at a more granular, cellular level. In thiswork, we propose a lightweight and training-efficient approach to predictcellular composition directly from H&amp;E-stained histology images by leveraginginformation-enriched feature embeddings extracted from pre-trained pathologyfoundation models. By training a lightweight multi-layer perceptron (MLP)regressor on cell-type abundances derived via cell2location, our methodefficiently distills knowledge from pathology foundation models anddemonstrates the ability to accurately predict cell-type compositions fromhistology images, without physically performing the costly spatialtranscriptomics. Our method demonstrates competitive performance compared toexisting methods such as Hist2Cell, while significantly reducing computationalcomplexity.</description>
      <author>example@mail.com (Yutong Sun, Sichen Zhu, Peng Qiu)</author>
      <guid isPermaLink="false">2507.07013v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>SemRaFiner: Panoptic Segmentation in Sparse and Noisy Radar Point Clouds</title>
      <link>http://arxiv.org/abs/2507.06906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in IEEE Robotics and Automation Letters  (RA-L)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对稀疏雷达点云中的全景分割问题，提出了一种名为SemRaFiner的方法，以提高场景理解能力。&lt;h4&gt;背景&lt;/h4&gt;语义场景理解对于实现自动驾驶的安全和稳健驾驶行为至关重要。相机和激光雷达常用于语义场景理解，但在恶劣天气下存在局限性，且通常不提供运动信息。雷达传感器可以直接通过测量多普勒速度提供关于运动代理的信息，但其测量结果相对稀疏且噪声较大。&lt;h4&gt;目的&lt;/h4&gt;解决稀疏雷达点云中的全景分割问题，以增强场景理解。&lt;h4&gt;方法&lt;/h4&gt;SemRaFiner方法考虑了稀疏雷达点云中的密度变化，并优化了特征提取以提高准确性。此外，还提出了一种优化的训练程序，通过结合专门的数据增强来细化实例分配。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与基于雷达的全景分割的现有方法相比，该方法表现更优。&lt;h4&gt;结论&lt;/h4&gt;SemRaFiner方法在稀疏雷达点云的全景分割方面优于现有技术，有助于提高自动驾驶场景理解能力。&lt;h4&gt;翻译&lt;/h4&gt;Semantic scene understanding, including the perception and classification of moving agents, is essential to enabling safe and robust driving behaviors of autonomous vehicles. Cameras and LiDARs are commonly used for semantic scene understanding. However, both sensor modalities face limitations in adverse weather and usually do not provide motion information. Radar sensors overcome these limitations and directly offer information about moving agents by measuring the Doppler velocity, but the measurements are comparably sparse and noisy. In this paper, we address the problem of panoptic segmentation in sparse radar point clouds to enhance scene understanding. Our approach, called SemRaFiner, accounts for changing density in sparse radar point clouds and optimizes the feature extraction to improve accuracy. Furthermore, we propose an optimized training procedure to refine instance assignments by incorporating a dedicated data augmentation. Our experiments suggest that our approach outperforms state-of-the-art methods for radar-based panoptic segmentation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2024.3502058&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic scene understanding, including the perception and classification ofmoving agents, is essential to enabling safe and robust driving behaviours ofautonomous vehicles. Cameras and LiDARs are commonly used for semantic sceneunderstanding. However, both sensor modalities face limitations in adverseweather and usually do not provide motion information. Radar sensors overcomethese limitations and directly offer information about moving agents bymeasuring the Doppler velocity, but the measurements are comparably sparse andnoisy. In this paper, we address the problem of panoptic segmentation in sparseradar point clouds to enhance scene understanding. Our approach, calledSemRaFiner, accounts for changing density in sparse radar point clouds andoptimizes the feature extraction to improve accuracy. Furthermore, we proposean optimized training procedure to refine instance assignments by incorporatinga dedicated data augmentation. Our experiments suggest that our approachoutperforms state-of-the-art methods for radar-based panoptic segmentation.</description>
      <author>example@mail.com (Matthias Zeller, Daniel Casado Herraez, Bengisu Ayan, Jens Behley, Michael Heidingsfeld, Cyrill Stachniss)</author>
      <guid isPermaLink="false">2507.06906v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Learning at the Edge: The Cost of Labeling</title>
      <link>http://arxiv.org/abs/2507.07033v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in IEEE MLSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在边缘设备上应用自监督学习（SSL）技术的可行性和效率，重点关注模型性能与能耗之间的权衡。&lt;h4&gt;背景&lt;/h4&gt;对比学习（CL）作为一种新的学习方法，可以从不结构化和未标记的数据中提取丰富的表示，但其通常需要大量的数据和计算资源，这在资源受限的边缘设备上是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;研究SSL技术在边缘学习中的可行性和效率，评估它们在资源受限环境下的学习鲁棒表示的有效性，并考虑数据标注的能源成本。&lt;h4&gt;方法&lt;/h4&gt;通过大量实验，分析不同SSL技术如何适应有限的计算、数据和能源预算，并评估半监督学习在减少训练CL模型整体能耗中的作用。&lt;h4&gt;主要发现&lt;/h4&gt;定制化的SSL策略可以在降低资源消耗高达4倍的同时实现有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;SSL技术在边缘设备上具有节能学习的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning (CL) has recently emerged as an alternative totraditional supervised machine learning solutions by enabling richrepresentations from unstructured and unlabeled data. However, CL and, morebroadly, self-supervised learning (SSL) methods often demand a large amount ofdata and computational resources, posing challenges for deployment onresource-constrained edge devices. In this work, we explore the feasibility andefficiency of SSL techniques for edge-based learning, focusing on trade-offsbetween model performance and energy efficiency. In particular, we analyze howdifferent SSL techniques adapt to limited computational, data, and energybudgets, evaluating their effectiveness in learning robust representationsunder resource-constrained settings. Moreover, we also consider the energycosts involved in labeling data and assess how semi-supervised learning mayassist in reducing the overall energy consumed to train CL models. Throughextensive experiments, we demonstrate that tailored SSL strategies can achievecompetitive performance while reducing resource consumption by up to 4X,underscoring their potential for energy-efficient learning at the edge.</description>
      <author>example@mail.com (Roberto Pereira, Fernanda Famá, Asal Rangrazi, Marco Miozzo, Charalampos Kalalas, Paolo Dini)</author>
      <guid isPermaLink="false">2507.07033v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Information Retrieval via Time-Specifier Model Merging</title>
      <link>http://arxiv.org/abs/2507.06782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TSM的新方法，旨在提升时间信息检索（TIR）的性能，同时保持非时间查询的准确性。&lt;h4&gt;背景&lt;/h4&gt;随着数字信息和知识的快速增长，信息检索（IR）的重要性日益凸显。尽管密集检索方法在语义匹配方面取得了显著进步，但在具有明确时间约束的查询上表现不佳，尤其是在包含数字表达式和时间说明的查询上。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有时间信息检索方法在时间推理上的改进和灾难性遗忘问题，从而在非时间查询上降低性能的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了时间说明模型合并（TSM）方法，该方法为单个时间说明训练专门的检索器，并将它们合并到一个统一模型中，以精确处理时间约束，同时不影响非时间检索。&lt;h4&gt;主要发现&lt;/h4&gt;在时间和非时间数据集上进行的广泛实验表明，TSM在时间约束查询上的性能显著提高，同时在非时间查询上保持强大结果，并且始终优于其他基线方法。&lt;h4&gt;结论&lt;/h4&gt;TSM是一种有效的时间信息检索方法，能够在处理时间约束查询时保持高准确性，并且适用于非时间查询。&lt;h4&gt;翻译&lt;/h4&gt;The rapid expansion of digital information and knowledge across structured and unstructured sources has heightened the importance of Information Retrieval (IR). While dense retrieval methods have substantially improved semantic matching for general queries, they consistently underperform on queries with explicit temporal constraints—often those containing numerical expressions and time specifiers such as 'in 2015.' Existing approaches to Temporal Information Retrieval (TIR) improve temporal reasoning but often suffer from catastrophic forgetting, leading to reduced performance on non-temporal queries. To address this, we propose Time-Specifier Model Merging (TSM), a novel method that enhances temporal retrieval while preserving accuracy on non-temporal queries. TSM trains specialized retrievers for individual time specifiers and merges them into a unified model, enabling precise handling of temporal constraints without compromising non-temporal retrieval. Extensive experiments on both temporal and non-temporal datasets demonstrate that TSM significantly improves performance on temporally constrained queries while maintaining strong results on non-temporal queries, consistently outperforming other baseline methods. Our code is available at https://github.com/seungyoonee/TSM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid expansion of digital information and knowledge across structuredand unstructured sources has heightened the importance of Information Retrieval(IR). While dense retrieval methods have substantially improved semanticmatching for general queries, they consistently underperform on queries withexplicit temporal constraints--often those containing numerical expressions andtime specifiers such as ``in 2015.'' Existing approaches to TemporalInformation Retrieval (TIR) improve temporal reasoning but often suffer fromcatastrophic forgetting, leading to reduced performance on non-temporalqueries. To address this, we propose Time-Specifier Model Merging (TSM), anovel method that enhances temporal retrieval while preserving accuracy onnon-temporal queries. TSM trains specialized retrievers for individual timespecifiers and merges them in to a unified model, enabling precise handling oftemporal constraints without compromising non-temporal retrieval. Extensiveexperiments on both temporal and non-temporal datasets demonstrate that TSMsignificantly improves performance on temporally constrained queries whilemaintaining strong results on non-temporal queries, consistently outperformingother baseline methods. Our code is available athttps://github.com/seungyoonee/TSM .</description>
      <author>example@mail.com (SeungYoon Han, Taeho Hwang, Sukmin Cho, Soyeong Jeong, Hoyun Song, Huije Lee, Jong C. Park)</author>
      <guid isPermaLink="false">2507.06782v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Diff$^2$I2P: Differentiable Image-to-Point Cloud Registration with Diffusion Prior</title>
      <link>http://arxiv.org/abs/2507.06651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Diff$^2$I2P是一种基于扩散模型的图像到点云注册框架，通过改进对应关系检索和PnP求解器的可微性，提高了跨模态对应关系的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的图像到点云注册方法主要利用度量学习来强制特征对齐，但忽略了图像和点云数据之间的固有模态差距，导致跨模态对应关系不准确。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来桥接图像和点云之间的模态差距，以实现更准确的跨模态对应关系。&lt;h4&gt;方法&lt;/h4&gt;Diff$^2$I2P利用了深度条件扩散模型，并引入了控制侧分数蒸馏（CSD）技术和可变形对应关系调整（DCT）模块来优化预测变换。&lt;h4&gt;主要发现&lt;/h4&gt;通过CSD技术和DCT模块，Diff$^2$I2P能够以可微的方式估计对应关系，并使用可微的PnP求解器进行变换估计，从而显著提高了注册的准确性。&lt;h4&gt;结论&lt;/h4&gt;Diff$^2$I2P在7-Scenes基准测试中，在注册召回率方面比现有方法提高了超过7%，证明了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;Learning cross-modal correspondences is essential for image-to-point cloud(I2P) registration. Existing methods achieve this mostly by utilizing metric learning to enforce feature alignment across modalities, disregarding the inherent modality gap between image and point data. Consequently, this paradigm struggles to ensure accurate cross-modal correspondences. To this end, inspired by the cross-modal generation success of recent large diffusion models, we propose Diff$^2$I2P, a fully Differentiable I2P registration framework, leveraging a novel and effective Diffusion prior for bridging the modality gap. Specifically, we propose a Control-Side Score Distillation (CSD) technique to distill knowledge from a depth-conditioned diffusion model to directly optimize the predicted transformation. However, the gradients on the transformation fail to backpropagate onto the cross-modal features due to the non-differentiability of correspondence retrieval and PnP solver. To this end, we further propose a Deformable Correspondence Tuning (DCT) module to estimate the correspondences in a differentiable way, followed by the transformation estimation using a differentiable PnP solver. With these two designs, the Diffusion model serves as a strong prior to guide the cross-modal feature learning of image and point cloud for forming robust correspondences, which significantly improves the registration. Extensive experimental results demonstrate that Diff$^2$I2P consistently outperforms SoTA I2P registration methods, achieving over 7% improvement in registration recall on the 7-Scenes benchmark.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning cross-modal correspondences is essential for image-to-point cloud(I2P) registration. Existing methods achieve this mostly by utilizing metriclearning to enforce feature alignment across modalities, disregarding theinherent modality gap between image and point data. Consequently, this paradigmstruggles to ensure accurate cross-modal correspondences. To this end, inspiredby the cross-modal generation success of recent large diffusion models, wepropose Diff$^2$I2P, a fully Differentiable I2P registration framework,leveraging a novel and effective Diffusion prior for bridging the modality gap.Specifically, we propose a Control-Side Score Distillation (CSD) technique todistill knowledge from a depth-conditioned diffusion model to directly optimizethe predicted transformation. However, the gradients on the transformation failto backpropagate onto the cross-modal features due to the non-differentiabilityof correspondence retrieval and PnP solver. To this end, we further propose aDeformable Correspondence Tuning (DCT) module to estimate the correspondencesin a differentiable way, followed by the transformation estimation using adifferentiable PnP solver. With these two designs, the Diffusion model servesas a strong prior to guide the cross-modal feature learning of image and pointcloud for forming robust correspondences, which significantly improves theregistration. Extensive experimental results demonstrate that Diff$^2$I2Pconsistently outperforms SoTA I2P registration methods, achieving over 7%improvement in registration recall on the 7-Scenes benchmark.</description>
      <author>example@mail.com (Juncheng Mu, Chengwei Ren, Weixiang Zhang, Liang Pan, Xiao-Ping Zhang, Yue Gao)</author>
      <guid isPermaLink="false">2507.06651v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement</title>
      <link>http://arxiv.org/abs/2507.06928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自适应部分发现和学习方法APL，用于在未标记图像中识别已知和新型类别，并通过比较相似图像生成一致的物体部分及其对应关系，同时不要求额外的标注。&lt;h4&gt;背景&lt;/h4&gt;现有的广义类别发现（GCD）方法依赖于自监督视觉Transformer，如DINO进行表示学习，但这种方法在可区分性和泛化性之间存在固有的权衡。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入APL方法，在不牺牲泛化性的前提下，提高对相似类别的可区分性，并促进知识迁移。&lt;h4&gt;方法&lt;/h4&gt;APL方法使用一组共享的可学习部分查询和DINO部分先验来生成不同相似图像的一致物体部分及其对应关系，并提出了一个新颖的all-min对比性损失函数来学习具有判别性和泛化性的部分表示。&lt;h4&gt;主要发现&lt;/h4&gt;APL方法可以容易地集成到不同的GCD框架中，通过替换其CLS标记特征为部分表示，在细粒度数据集上表现出显著的提升。&lt;h4&gt;结论&lt;/h4&gt;APL方法在提高GCD方法的可区分性和泛化性方面具有潜力，并且能够有效地应用于不同数据集。&lt;h4&gt;翻译&lt;/h4&gt;Generalized Category Discovery (GCD) aims to recognize unlabeled images from known and novel classes by distinguishing novel classes from known ones, while also transferring knowledge from another set of labeled images with known classes. Existing GCD methods rely on self-supervised vision transformers such as DINO for representation learning. However, focusing solely on the global representation of the DINO CLS token introduces an inherent trade-off between discriminability and generalization. In this paper, we introduce an adaptive part discovery and learning method, called APL, which generates consistent object parts and their correspondences across different similar images using a set of shared learnable part queries and DINO part priors, without requiring any additional annotations. More importantly, we propose a novel all-min contrastive loss to learn discriminative yet generalizable part representation, which adaptively highlights discriminative object parts to distinguish similar categories for enhanced discriminability while simultaneously sharing other parts to facilitate knowledge transfer for improved generalization. Our APL can easily be incorporated into different GCD frameworks by replacing their CLS token feature with our part representations, showing significant enhancements on fine-grained datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalized Category Discovery (GCD) aims to recognize unlabeled images fromknown and novel classes by distinguishing novel classes from known ones, whilealso transferring knowledge from another set of labeled images with knownclasses. Existing GCD methods rely on self-supervised vision transformers suchas DINO for representation learning. However, focusing solely on the globalrepresentation of the DINO CLS token introduces an inherent trade-off betweendiscriminability and generalization. In this paper, we introduce an adaptivepart discovery and learning method, called APL, which generates consistentobject parts and their correspondences across different similar images using aset of shared learnable part queries and DINO part priors, without requiringany additional annotations. More importantly, we propose a novel all-mincontrastive loss to learn discriminative yet generalizable part representation,which adaptively highlights discriminative object parts to distinguish similarcategories for enhanced discriminability while simultaneously sharing otherparts to facilitate knowledge transfer for improved generalization. Our APL caneasily be incorporated into different GCD frameworks by replacing their CLStoken feature with our part representations, showing significant enhancementson fine-grained datasets.</description>
      <author>example@mail.com (Qiyuan Dai, Hanzhuo Huang, Yu Wu, Sibei Yang)</author>
      <guid isPermaLink="false">2507.06928v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>PointVDP: Learning View-Dependent Projection by Fireworks Rays for 3D Point Cloud Segmentation</title>
      <link>http://arxiv.org/abs/2507.06618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为视图相关投影（VDP）的方法，用于促进点云分割，并设计了一种高效的3D到2D映射，该映射能够动态适应来自视图变化的时空几何。&lt;h4&gt;背景&lt;/h4&gt;现有的基于投影的方法利用视图无关的投影在复杂场景中，依赖于直线生成直接射线或向上曲线以减少遮挡。然而，它们的视图无关性限制了投影射线，使其局限于人为设定的预定义参数，从而限制了点的感知能力，并且未能充分捕捉不同视图平面之间的投影多样性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些限制，设计了一个VDP框架，从3D点分布生成数据驱动的投影，通过预测受烟花自适应行为启发的射线，生成高度信息化的单图像输入。&lt;h4&gt;方法&lt;/h4&gt;此外，构建了颜色正则化来优化框架，强调语义像素中的基本特征，抑制黑色像素中的非语义特征，从而在投影图像中最大化2D空间利用率。PointVDP方法通过边际计算成本实现了轻量级投影。&lt;h4&gt;主要发现&lt;/h4&gt;在S3DIS和ScanNet基准测试上的实验表明，该方法达到了具有竞争力的结果，提供了一种资源高效的语义理解解决方案。&lt;h4&gt;结论&lt;/h4&gt;PointVDP方法通过动态适应视图变化，提高了点云分割的效率和准确性，为语义理解提供了一种高效且资源节约的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose view-dependent projection (VDP) to facilitate pointcloud segmentation, designing efficient 3D-to-2D mapping that dynamicallyadapts to the spatial geometry from view variations. Existing projection-basedmethods leverage view-independent projection in complex scenes, relying onstraight lines to generate direct rays or upward curves to reduce occlusions.However, their view independence provides projection rays that are limited topre-defined parameters by human settings, restricting point awareness andfailing to capture sufficient projection diversity across different viewplanes. Although multiple projections per view plane are commonly used toenhance spatial variety, the projected redundancy leads to excessivecomputational overhead and inefficiency in image processing. To address theselimitations, we design a framework of VDP to generate data-driven projectionsfrom 3D point distributions, producing highly informative single-image inputsby predicting rays inspired by the adaptive behavior of fireworks. In addition,we construct color regularization to optimize the framework, which emphasizesessential features within semantic pixels and suppresses the non-semanticfeatures within black pixels, thereby maximizing 2D space utilization in aprojected image. As a result, our approach, PointVDP, develops lightweightprojections in marginal computation costs. Experiments on S3DIS and ScanNetbenchmarks show that our approach achieves competitive results, offering aresource-efficient solution for semantic understanding.</description>
      <author>example@mail.com (Yang Chen, Yueqi Duan, Haowen Sun, Ziwei Wang, Jiwen Lu, Yap-Peng Tan)</author>
      <guid isPermaLink="false">2507.06618v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>GNN-ViTCap: GNN-Enhanced Multiple Instance Learning with Vision Transformers for Whole Slide Image Classification and Captioning</title>
      <link>http://arxiv.org/abs/2507.07006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GNN-ViTCap的框架，用于从病理学显微镜图像中进行分类和生成描述性字幕，以提高癌症诊断和治疗中的病理图像评估准确性。&lt;h4&gt;背景&lt;/h4&gt;病理图像的微观评估对于癌症诊断和治疗至关重要。全切片图像（WSI）分类和字幕生成在计算机辅助病理学中变得至关重要，但显微镜WSI面临着如冗余切片和由于主观病理学家捕获导致的未知切片位置等挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了一种新的GNN-ViTCap框架，用于从病理学显微镜图像中进行分类和字幕生成。&lt;h4&gt;方法&lt;/h4&gt;首先，使用视觉特征提取器生成切片嵌入。然后，通过深度嵌入聚类动态地去除冗余切片，并通过标量点注意力机制选择代表性切片。通过将每个节点与其相似性矩阵中的最近邻连接来构建图，并应用图神经网络来捕捉局部和全局上下文。通过线性层将聚合的图像嵌入投影到语言模型的输入空间，并与字幕标记结合以微调大型语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;GNN-ViTCap在BreakHis和PatchGastric数据集上进行了验证，实现了0.934的F1分数和0.963的AUC（曲线下面积）的分类性能，以及0.811的BLEU-4分数和0.569的METEOR分数的字幕生成性能。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，GNN-ViTCap优于现有方法，为基于显微镜的患者诊断提供了一种可靠且高效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Microscopic assessment of histopathology images is vital for accurate cancer diagnosis and treatment. Whole Slide Image (WSI) classification and captioning have become crucial tasks in computer-aided pathology. However, microscopic WSI face challenges such as redundant patches and unknown patch positions due to subjective pathologist captures. Moreover, generating automatic pathology captions remains a significant challenge. To address these issues, we introduce a novel GNN-ViTCap framework for classification and caption generation from histopathological microscopic images. First, a visual feature extractor generates patch embeddings. Redundant patches are then removed by dynamically clustering these embeddings using deep embedded clustering and selecting representative patches via a scalar dot attention mechanism. We build a graph by connecting each node to its nearest neighbors in the similarity matrix and apply a graph neural network to capture both local and global context. The aggregated image embeddings are projected into the language model's input space through a linear layer and combined with caption tokens to fine-tune a large language model. We validate our method on the BreakHis and PatchGastric datasets. GNN-ViTCap achieves an F1 score of 0.934 and an AUC of 0.963 for classification, along with a BLEU-4 score of 0.811 and a METEOR score of 0.569 for captioning. Experimental results demonstrate that GNN-ViTCap outperforms state of the art approaches, offering a reliable and efficient solution for microscopy based patient diagnosis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Microscopic assessment of histopathology images is vital for accurate cancerdiagnosis and treatment. Whole Slide Image (WSI) classification and captioninghave become crucial tasks in computer-aided pathology. However, microscopic WSIface challenges such as redundant patches and unknown patch positions due tosubjective pathologist captures. Moreover, generating automatic pathologycaptions remains a significant challenge. To address these issues, we introducea novel GNN-ViTCap framework for classification and caption generation fromhistopathological microscopic images. First, a visual feature extractorgenerates patch embeddings. Redundant patches are then removed by dynamicallyclustering these embeddings using deep embedded clustering and selectingrepresentative patches via a scalar dot attention mechanism. We build a graphby connecting each node to its nearest neighbors in the similarity matrix andapply a graph neural network to capture both local and global context. Theaggregated image embeddings are projected into the language model's input spacethrough a linear layer and combined with caption tokens to fine-tune a largelanguage model. We validate our method on the BreakHis and PatchGastricdatasets. GNN-ViTCap achieves an F1 score of 0.934 and an AUC of 0.963 forclassification, along with a BLEU-4 score of 0.811 and a METEOR score of 0.569for captioning. Experimental results demonstrate that GNN-ViTCap outperformsstate of the art approaches, offering a reliable and efficient solution formicroscopy based patient diagnosis.</description>
      <author>example@mail.com (S M Taslim Uddin Raju, Md. Milon Islam, Md Rezwanul Haque, Hamdi Altaheri, Fakhri Karray)</author>
      <guid isPermaLink="false">2507.07006v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Token Bottleneck: One Token to Remember Dynamics</title>
      <link>http://arxiv.org/abs/2507.06543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 9 figures, 8 tables, project page:  https://token-bottleneck.github.io, code: https://github.com/naver-ai/tobo&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Token Bottleneck（ToBo）的自监督学习方法，该方法能够从动态场景中提取紧凑且时间感知的视觉表示，用于场景理解任务，如视觉跟踪和机器人操作。&lt;h4&gt;背景&lt;/h4&gt;在执行视觉跟踪和机器人操作等序列场景理解任务时，从动态场景中提取紧凑且时间感知的视觉表示至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计一个简单直观的自监督学习流程，将场景压缩成一个瓶颈标记（bottleneck token），并使用最小化的补丁作为提示来预测后续场景。&lt;h4&gt;方法&lt;/h4&gt;ToBo流程通过在挤压步骤中保守地编码参考场景到紧凑的瓶颈标记来促进序列场景表示的学习。在扩展步骤中，指导模型通过使用瓶颈标记和少数目标补丁作为提示来预测目标场景，从而捕捉时间动态。&lt;h4&gt;主要发现&lt;/h4&gt;ToBo在视频标签传播和模拟环境中的机器人操作等多样化的序列任务中，表现优于基线方法。此外，将预训练模型部署到物理机器人上，证实了其在现实世界环境中的鲁棒性和有效性。&lt;h4&gt;结论&lt;/h4&gt;ToBo在多个模型规模上验证了其可扩展性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从动态场景中提取紧凑且时间感知的视觉表示对于执行如视觉跟踪和机器人操作等序列场景理解任务至关重要。在本文中，我们介绍了一种简单的、直观的自监督学习流程——Token Bottleneck（ToBo），该流程将场景压缩成瓶颈标记，并使用最小化的补丁作为提示来预测后续场景。ToBo流程通过在挤压步骤中保守地编码参考场景到紧凑的瓶颈标记来促进序列场景表示的学习。在扩展步骤中，通过使用瓶颈标记和少数目标补丁作为提示来预测目标场景，指导模型捕捉时间动态。在视频标签传播和模拟环境中的机器人操作等多样化的序列任务中，ToBo表现优于基线方法。将预训练模型部署到物理机器人上，证实了其在现实世界环境中的鲁棒性和有效性。进一步验证了ToBo在多个模型规模上的可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deriving compact and temporally aware visual representations from dynamicscenes is essential for successful execution of sequential scene understandingtasks such as visual tracking and robotic manipulation. In this paper, weintroduce Token Bottleneck (ToBo), a simple yet intuitive self-supervisedlearning pipeline that squeezes a scene into a bottleneck token and predictsthe subsequent scene using minimal patches as hints. The ToBo pipelinefacilitates the learning of sequential scene representations by conservativelyencoding the reference scene into a compact bottleneck token during the squeezestep. In the expansion step, we guide the model to capture temporal dynamics bypredicting the target scene using the bottleneck token along with few targetpatches as hints. This design encourages the vision backbone to embed temporaldependencies, thereby enabling understanding of dynamic transitions acrossscenes. Extensive experiments in diverse sequential tasks, including videolabel propagation and robot manipulation in simulated environments demonstratethe superiority of ToBo over baselines. Moreover, deploying our pre-trainedmodel on physical robots confirms its robustness and effectiveness inreal-world environments. We further validate the scalability of ToBo acrossdifferent model scales.</description>
      <author>example@mail.com (Taekyung Kim, Dongyoon Han, Byeongho Heo, Jeongeun Park, Sangdoo Yun)</author>
      <guid isPermaLink="false">2507.06543v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Deep Brain Net: An Optimized Deep Learning Model for Brain tumor Detection in MRI Images Using EfficientNetB0 and ResNet50 with Transfer Learning</title>
      <link>http://arxiv.org/abs/2507.07011v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 14 figures, 4 tables. To be submitted to a conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Deep Brain Net的深度学习系统，用于优化脑肿瘤的自动检测和分类性能，该系统结合了EfficientNetB0和ResNet50架构的优势，并采用迁移学习来提高泛化能力和减少训练时间。&lt;h4&gt;背景&lt;/h4&gt;深度学习在脑肿瘤的MRI图像自动检测和分类方面显示出巨大潜力，但实现高准确性和计算效率仍是一大挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够优化脑肿瘤检测性能的深度学习系统。&lt;h4&gt;方法&lt;/h4&gt;Deep Brain Net模型整合了EfficientNetB0和ResNet50架构，EfficientNetB0通过使用移动倒置瓶颈块提高了模型效率，ResNet50在ImageNet等大规模数据集上预训练后，用于脑肿瘤分类，并利用残差连接来避免性能退化。&lt;h4&gt;主要发现&lt;/h4&gt;Deep Brain Net在公开的MRI数据集上进行了广泛实验，结果显示其分类准确率、精确度、召回率和计算效率均优于现有方法，准确率达到88%，加权F1分数为88.75%，宏AUC ROC分数为98.17%，显示出系统的鲁棒性和临床潜力。&lt;h4&gt;结论&lt;/h4&gt;Deep Brain Net在脑肿瘤诊断方面具有显著的临床潜力，能够帮助放射科医生进行脑肿瘤的诊断。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, deep learning has shown great promise in the automateddetection and classification of brain tumors from MRI images. However,achieving high accuracy and computational efficiency remains a challenge. Inthis research, we propose Deep Brain Net, a novel deep learning system designedto optimize performance in the detection of brain tumors. The model integratesthe strengths of two advanced neural network architectures which areEfficientNetB0 and ResNet50, combined with transfer learning to improvegeneralization and reduce training time. The EfficientNetB0 architectureenhances model efficiency by utilizing mobile inverted bottleneck blocks, whichincorporate depth wise separable convolutions. This design significantlyreduces the number of parameters and computational cost while preserving theability of models to learn complex feature representations. The ResNet50architecture, pre trained on large scale datasets like ImageNet, is fine tunedfor brain tumor classification. Its use of residual connections allows fortraining deeper networks by mitigating the vanishing gradient problem andavoiding performance degradation. The integration of these components ensuresthat the proposed system is both computationally efficient and highly accurate.Extensive experiments performed on publicly available MRI datasets demonstratethat Deep Brain Net consistently outperforms existing state of the art methodsin terms of classification accuracy, precision, recall, and computationalefficiency. The result is an accuracy of 88 percent, a weighted F1 score of88.75 percent, and a macro AUC ROC score of 98.17 percent which demonstratesthe robustness and clinical potential of Deep Brain Net in assistingradiologists with brain tumor diagnosis.</description>
      <author>example@mail.com (Daniel Onah, Ravish Desai)</author>
      <guid isPermaLink="false">2507.07011v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Graph Neural Networks for Short-term State Forecasting in Power Systems across Domains and Time Scales: A Hydroelectric Power Plant Case Study</title>
      <link>http://arxiv.org/abs/2507.06694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于异构图注意力网络的方法，用于解决现代电力系统中多物理域状态预测的挑战。&lt;h4&gt;背景&lt;/h4&gt;准确预测短期状态对于现代电力系统的稳定运行至关重要，尤其是在可再生能源和分布式能源资源带来的不确定性增加的背景下。&lt;h4&gt;目的&lt;/h4&gt;提高电力系统的短期状态预测准确性，支持控制决策，并实现传感器和机器行为的可解释性监控。&lt;h4&gt;方法&lt;/h4&gt;提出使用异构图注意力网络来建模来自两个不同物理域（液压和电气）的传感器数据之间的同域和跨域关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多域、多速率电力系统状态预测方面显著优于传统基线，平均性能提高了35.5%。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在多物理域电力系统状态预测中是有效的，并具有提高预测准确性的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate short-term state forecasting is essential for efficient and stableoperation of modern power systems, especially in the context of increasingvariability introduced by renewable and distributed energy resources. As thesesystems evolve rapidly, it becomes increasingly important to reliably predicttheir states in the short term to ensure operational stability, support controldecisions, and enable interpretable monitoring of sensor and machine behavior.Modern power systems often span multiple physical domains - includingelectrical, mechanical, hydraulic, and thermal - posing significant challengesfor modeling and prediction. Graph Neural Networks (GNNs) have emerged as apromising data-driven framework for system state estimation and stateforecasting in such settings. By leveraging the topological structure of sensornetworks, GNNs can implicitly learn inter-sensor relationships and propagateinformation across the network. However, most existing GNN-based methods aredesigned under the assumption of homogeneous sensor relationships and aretypically constrained to a single physical domain. This limitation restrictstheir ability to integrate and reason over heterogeneous sensor data commonlyencountered in real-world energy systems, such as those used in energyconversion infrastructure. In this work, we propose the use of HeterogeneousGraph Attention Networks to address these limitations. Our approach models bothhomogeneous intra-domain and heterogeneous inter-domain relationships amongsensor data from two distinct physical domains - hydraulic and electrical -which exhibit fundamentally different temporal dynamics. Experimental resultsdemonstrate that our method significantly outperforms conventional baselines onaverage by 35.5% in terms of normalized root mean square error, confirming itseffectiveness in multi-domain, multi-rate power system state forecasting.</description>
      <author>example@mail.com (Raffael Theiler, Olga Fink)</author>
      <guid isPermaLink="false">2507.06694v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Deep-Learning-Based Pre-Layout Parasitic Capacitance Prediction on SRAM Designs</title>
      <link>http://arxiv.org/abs/2507.06549v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Proceedings of GLSVLSI2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的两阶段模型，用于在预布局阶段准确预测SRAM电路中的寄生效应，以提升系统能源效率。&lt;h4&gt;背景&lt;/h4&gt;在SoC中，为了提高系统能源效率，SRAM往往被定制化。寄生效应导致预布局和后布局电路仿真之间存在显著差异，给设计参数的收敛和设计迭代带来困难。&lt;h4&gt;目的&lt;/h4&gt;研究是否能够基于预布局电路准确预测寄生效应，以进行寄生感知的预布局仿真。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结合图神经网络（GNN）分类器和多层感知器（MLP）回归器的两阶段模型，以有效地管理SRAM电路中网络寄生效应的类别不平衡。此外，采用Focal Loss来减轻大量内部网络样本的影响，并将子电路信息集成到图中以抽象原理图的层次结构。&lt;h4&gt;主要发现&lt;/h4&gt;在4个真实SRAM设计上的实验表明，该方法在寄生预测方面超越了最先进的模型，误差最大减少了19倍，并且显著提高了仿真过程，速度提升了高达598倍。&lt;h4&gt;结论&lt;/h4&gt;该模型能够有效地预测预布局阶段的寄生效应，显著提高了仿真效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To achieve higher system energy efficiency, SRAM in SoCs is often customized.The parasitic effects cause notable discrepancies between pre-layout andpost-layout circuit simulations, leading to difficulty in converging designparameters and excessive design iterations. Is it possible to well predict theparasitics based on the pre-layout circuit, so as to perform parasitic-awarepre-layout simulation? In this work, we propose a deep-learning-based 2-stagemodel to accurately predict these parasitics in pre-layout stages. The modelcombines a Graph Neural Network (GNN) classifier and Multi-Layer Perceptron(MLP) regressors, effectively managing class imbalance of the net parasitics inSRAM circuits. We also employ Focal Loss to mitigate the impact of abundantinternal net samples and integrate subcircuit information into the graph toabstract the hierarchical structure of schematics. Experiments on 4 real SRAMdesigns show that our approach not only surpasses the state-of-the-art model inparasitic prediction by a maximum of 19X reduction of error but alsosignificantly boosts the simulation process by up to 598X speedup.</description>
      <author>example@mail.com (Shan Shen, Dingcheng Yang, Yuyang Xie, Chunyan Pei, Wenjian Yu, Bei Yu)</author>
      <guid isPermaLink="false">2507.06549v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>DenoiseCP-Net: Efficient Collective Perception in Adverse Weather via Joint LiDAR-Based 3D Object Detection and Denoising</title>
      <link>http://arxiv.org/abs/2507.06976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在恶劣天气条件下基于激光雷达的集体感知，提出了一种新的多任务架构DenoiseCP-Net，以解决感知系统易受天气和环境遮挡影响的问题。&lt;h4&gt;背景&lt;/h4&gt;自动化车辆有减少交通事故的潜力，但其感知系统易受恶劣天气和环境遮挡的影响。&lt;h4&gt;目的&lt;/h4&gt;进行首次基于激光雷达的集体感知在多样化天气条件下的研究，并提出一种新的多任务架构。&lt;h4&gt;方法&lt;/h4&gt;提出DenoiseCP-Net，该架构将体素级噪声过滤和目标检测集成到统一的稀疏卷积骨干网络中，通过模拟雨、雪和雾等恶劣天气条件进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;DenoiseCP-Net在恶劣天气条件下实现了近乎完美的去噪精度，减少了带宽需求高达23.6%，同时保持了相同的检测精度，并降低了合作车辆的推理延迟。&lt;h4&gt;结论&lt;/h4&gt;DenoiseCP-Net能够有效提高恶劣天气条件下基于激光雷达的集体感知的性能，减少带宽需求和推理延迟。&lt;h4&gt;翻译&lt;/h4&gt;While automated vehicles hold the potential to significantly reduce traffic accidents, their perception systems remain vulnerable to sensor degradation caused by adverse weather and environmental occlusions. Collective perception, which enables vehicles to share information, offers a promising approach to overcoming these limitations. However, to this date collective perception in adverse weather is mostly unstudied. Therefore, we conduct the first study of LiDAR-based collective perception under diverse weather conditions and present a novel multi-task architecture for LiDAR-based collective perception under adverse weather. Adverse weather conditions can not only degrade perception capabilities, but also negatively affect bandwidth requirements and latency due to the introduced noise that is also transmitted and processed. Denoising prior to communication can effectively mitigate these issues. Therefore, we propose DenoiseCP-Net, a novel multi-task architecture for LiDAR-based collective perception under adverse weather conditions. DenoiseCP-Net integrates voxel-level noise filtering and object detection into a unified sparse convolution backbone, eliminating redundant computations associated with two-stage pipelines. This design not only reduces inference latency and computational cost but also minimizes communication overhead by removing non-informative noise. We extended the well-known OPV2V dataset by simulating rain, snow, and fog using our realistic weather simulation models. We demonstrate that DenoiseCP-Net achieves near-perfect denoising accuracy in adverse weather, reduces the bandwidth requirements by up to 23.6% while maintaining the same detection accuracy and reducing the inference latency for cooperative vehicles.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While automated vehicles hold the potential to significantly reduce trafficaccidents, their perception systems remain vulnerable to sensor degradationcaused by adverse weather and environmental occlusions. Collective perception,which enables vehicles to share information, offers a promising approach toovercoming these limitations. However, to this date collective perception inadverse weather is mostly unstudied. Therefore, we conduct the first study ofLiDAR-based collective perception under diverse weather conditions and presenta novel multi-task architecture for LiDAR-based collective perception underadverse weather. Adverse weather conditions can not only degrade perceptioncapabilities, but also negatively affect bandwidth requirements and latency dueto the introduced noise that is also transmitted and processed. Denoising priorto communication can effectively mitigate these issues. Therefore, we proposeDenoiseCP-Net, a novel multi-task architecture for LiDAR-based collectiveperception under adverse weather conditions. DenoiseCP-Net integratesvoxel-level noise filtering and object detection into a unified sparseconvolution backbone, eliminating redundant computations associated withtwo-stage pipelines. This design not only reduces inference latency andcomputational cost but also minimizes communication overhead by removingnon-informative noise. We extended the well-known OPV2V dataset by simulatingrain, snow, and fog using our realistic weather simulation models. Wedemonstrate that DenoiseCP-Net achieves near-perfect denoising accuracy inadverse weather, reduces the bandwidth requirements by up to 23.6% whilemaintaining the same detection accuracy and reducing the inference latency forcooperative vehicles.</description>
      <author>example@mail.com (Sven Teufel, Dominique Mayer, Jörg Gamerdinger, Oliver Bringmann)</author>
      <guid isPermaLink="false">2507.06976v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation</title>
      <link>http://arxiv.org/abs/2507.06992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为MCA-RG的知识驱动框架，用于提升放射学报告生成（RRG）的准确性。&lt;h4&gt;背景&lt;/h4&gt;尽管在将大型语言模型（LLMs）应用于RRG方面取得了显著进展，但临床应用仍然面临挑战，主要由于病理和解剖特征难以准确映射到对应的文本描述，以及语义无关的特征提取进一步阻碍了准确诊断报告的生成。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，论文旨在提出一种能够提高RRG准确性的方法。&lt;h4&gt;方法&lt;/h4&gt;MCA-RG框架通过将视觉特征与不同的医学概念进行显式对齐，利用两个精心构建的概念库：一个包含与病变相关的知识库，另一个包含解剖描述的解剖学库。视觉特征与这些医学概念对齐并进行定制增强。此外，还提出了一种基于解剖的对比学习程序来提高解剖特征的泛化能力，结合病理特征的匹配损失以优先考虑临床相关区域。还采用了一种特征门控机制来过滤低质量的特征。最后，视觉特征与个体医学概念相对应，并用于指导报告生成过程。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC-CXR和CheXpert Plus两个公开基准上的实验表明，MCA-RG实现了优越的性能，突显了其在RRG中的有效性。&lt;h4&gt;结论&lt;/h4&gt;MCA-RG框架能够显著提升放射学报告生成的准确性，是一种有潜力的临床应用工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite significant advancements in adapting Large Language Models (LLMs) forradiology report generation (RRG), clinical adoption remains challenging due todifficulties in accurately mapping pathological and anatomical features totheir corresponding text descriptions. Additionally, semantic agnostic featureextraction further hampers the generation of accurate diagnostic reports. Toaddress these challenges, we introduce Medical Concept Aligned Radiology ReportGeneration (MCA-RG), a knowledge-driven framework that explicitly aligns visualfeatures with distinct medical concepts to enhance the report generationprocess. MCA-RG utilizes two curated concept banks: a pathology bank containinglesion-related knowledge, and an anatomy bank with anatomical descriptions. Thevisual features are aligned with these medical concepts and undergo tailoredenhancement. We further propose an anatomy-based contrastive learning procedureto improve the generalization of anatomical features, coupled with a matchingloss for pathological features to prioritize clinically relevant regions.Additionally, a feature gating mechanism is employed to filter out low-qualityconcept features. Finally, the visual features are corresponding to individualmedical concepts, and are leveraged to guide the report generation process.Experiments on two public benchmarks (MIMIC-CXR and CheXpert Plus) demonstratethat MCA-RG achieves superior performance, highlighting its effectiveness inradiology report generation.</description>
      <author>example@mail.com (Qilong Xing, Zikai Song, Youjia Zhang, Na Feng, Junqing Yu, Wei Yang)</author>
      <guid isPermaLink="false">2507.06992v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand</title>
      <link>http://arxiv.org/abs/2507.06822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by 2025 IEEE/RSJ International Conference on Intelligent  Robots and Systems (IROS 2025). copyright 2025 IEEE. Final version to appear  in IEEE Xplore&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于分层、目标条件强化学习（GCRL）框架来提高类人机器人手使用关节工具的操作能力。&lt;h4&gt;背景&lt;/h4&gt;以往的研究很少探索使用关节工具，如镊子或剪刀，这类工具动态改变形状，对灵巧机器人手提出了独特的挑战。&lt;h4&gt;目的&lt;/h4&gt;通过研究，旨在提升机器人使用关节工具进行操作的灵活性和效率。&lt;h4&gt;方法&lt;/h4&gt;提出了两层策略：底层策略使手能够根据不同大小的物体将工具操作到不同的配置；高层策略定义工具的目标状态并控制机械臂进行抓取任务。使用编码器从输入点云中估计工具的可用状态，并利用基于优先级信息的启发式策略生成重放缓冲区。&lt;h4&gt;主要发现&lt;/h4&gt;通过真实世界的实验验证，机器人能够以70.8%的成功率有效地使用类似镊子的工具抓取不同形状和大小的物体。&lt;h4&gt;结论&lt;/h4&gt;研究强调了强化学习在提升灵巧机器人关节工具操作能力方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Manipulating articulated tools, such as tweezers or scissors, has rarely been explored in previous research. Unlike rigid tools, articulated tools change their shape dynamically, creating unique challenges for dexterous robotic hands. In this work, we present a hierarchical, goal-conditioned reinforcement learning (GCRL) framework to improve the manipulation capabilities of anthropomorphic robotic hands using articulated tools. Our framework comprises two policy layers: (1) a low-level policy that enables the dexterous hand to manipulate the tool into various configurations for objects of different sizes, and (2) a high-level policy that defines the tool's goal state and controls the robotic arm for object-picking tasks. We employ an encoder, trained on synthetic point clouds, to estimate the tool's affordance states--specifically, how different tool configurations (e.g., tweezer opening angles) enable grasping of objects of varying sizes--from input point clouds, thereby enabling precise tool manipulation. We also utilize a privilege-informed heuristic policy to generate replay buffer, improving the training efficiency of the high-level policy. We validate our approach through real-world experiments, showing that the robot can effectively manipulate a tweezer-like tool to grasp objects of diverse shapes and sizes with a 70.8% success rate. This study highlights the potential of RL to advance dexterous robotic manipulation of articulated tools.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Manipulating articulated tools, such as tweezers or scissors, has rarely beenexplored in previous research. Unlike rigid tools, articulated tools changetheir shape dynamically, creating unique challenges for dexterous robotichands. In this work, we present a hierarchical, goal-conditioned reinforcementlearning (GCRL) framework to improve the manipulation capabilities ofanthropomorphic robotic hands using articulated tools. Our framework comprisestwo policy layers: (1) a low-level policy that enables the dexterous hand tomanipulate the tool into various configurations for objects of different sizes,and (2) a high-level policy that defines the tool's goal state and controls therobotic arm for object-picking tasks. We employ an encoder, trained onsynthetic pointclouds, to estimate the tool's affordance states--specifically,how different tool configurations (e.g., tweezer opening angles) enablegrasping of objects of varying sizes--from input point clouds, thereby enablingprecise tool manipulation. We also utilize a privilege-informed heuristicpolicy to generate replay buffer, improving the training efficiency of thehigh-level policy. We validate our approach through real-world experiments,showing that the robot can effectively manipulate a tweezer-like tool to graspobjects of diverse shapes and sizes with a 70.8 % success rate. This studyhighlights the potential of RL to advance dexterous robotic manipulation ofarticulated tools.</description>
      <author>example@mail.com (Wei Xu, Yanchao Zhao, Weichao Guo, Xinjun Sheng)</author>
      <guid isPermaLink="false">2507.06822v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report</title>
      <link>http://arxiv.org/abs/2507.06968v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种系统性的指令数据构建框架，用于提高大规模预训练模型在复杂任务上的性能和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;尽管当前指令数据集已达到数百万个样本，但模型在复杂指令遵循和罕见领域的任务上仍可能存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决指令集在“覆盖”（任务类型和知识领域覆盖）和“深度”（指令复杂性）方面的局限性，构建高质量的指令数据集。&lt;h4&gt;方法&lt;/h4&gt;提出的框架包括分层标签系统、信息种子选择算法、进化数据合成过程以及带有针对性数据生成的模型缺陷诊断。&lt;h4&gt;主要发现&lt;/h4&gt;基于该框架构建的InfinityInstruct-Subject数据集包含约150万条指令，实验表明其在提高指令遵循能力方面有效。&lt;h4&gt;结论&lt;/h4&gt;InfinityInstruct-Subject相较于其他合成指令数据集，具有更广泛的覆盖面和深度，为指令数据集的有效和持续进化提供了理论和实践基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：指令调整已成为解锁大规模预训练模型能力并提高其在复杂任务上性能的基础。因此，构建高质量的指令数据集对于增强模型性能和泛化能力至关重要。尽管当前指令数据集已达到数百万个样本，但在此之上微调的模型在复杂指令遵循和罕见领域的任务上仍可能遇到困难。这主要是由于指令集在“覆盖”（任务类型和知识领域覆盖）和“深度”（指令复杂性）方面的扩展有限。为了解决这一问题，我们提出了一种系统性的指令数据构建框架，该框架集成了分层标签系统、信息种子选择算法、进化数据合成过程以及带有针对性数据生成的模型缺陷诊断。这些组件形成一个迭代闭环，以持续增强指令数据的覆盖面和深度。基于此框架，我们构建了InfinityInstruct-Subject数据集，这是一个包含约150万条指令的高质量数据集。在多个基础模型和基准任务上的实验表明，它在提高指令遵循能力方面是有效的。进一步的分析表明，与可比的合成指令数据集相比，InfinityInstruct-Subject具有更广泛的覆盖面和深度。我们的工作为指令数据集的有效、持续进化奠定了理论和实践基础，从数据数量扩展转向质量提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Instruction tuning has become a foundation for unlocking the capabilities oflarge-scale pretrained models and improving their performance on complex tasks.Thus, the construction of high-quality instruction datasets is crucial forenhancing model performance and generalizability. Although current instructiondatasets have reached tens of millions of samples, models finetuned on them maystill struggle with complex instruction following and tasks in rare domains.This is primarily due to limited expansion in both ``coverage'' (coverage oftask types and knowledge areas) and ``depth'' (instruction complexity) of theinstruction set. To address this issue, we propose a systematic instructiondata construction framework, which integrates a hierarchical labeling system,an informative seed selection algorithm, an evolutionary data synthesisprocess, and a model deficiency diagnosis with targeted data generation. Thesecomponents form an iterative closed-loop to continuously enhance the coverageand depth of instruction data. Based on this framework, we constructInfinityInstruct-Subject, a high-quality dataset containing ~1.5 millioninstructions. Experiments on multiple foundation models and benchmark tasksdemonstrate its effectiveness in improving instruction-following capabilities.Further analyses suggest that InfinityInstruct-Subject shows enlarged coverageand depth compared to comparable synthesized instruction datasets. Our worklays a theoretical and practical foundation for the efficient, continuousevolution of instruction datasets, moving from data quantity expansion toqualitative improvement.</description>
      <author>example@mail.com (Li Du, Hanyu Zhao, Yiming Ju, Tengfei Pan)</author>
      <guid isPermaLink="false">2507.06968v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Ambiguity-aware Point Cloud Segmentation by Adaptive Margin Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.06592v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This article has been accepted for publication in IEEE Transactions  on Multimedia. arXiv admin note: text overlap with arXiv:2502.04111&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对点云3D语义分割的自适应边缘对比学习方法。&lt;h4&gt;背景&lt;/h4&gt;现有方法使用等惩罚目标，忽略了来自过渡区域的每点模糊性和区分度较低的特征。&lt;h4&gt;目的&lt;/h4&gt;解决高度模糊的点可能对人类都难以区分，其手动标注标签可靠性低，对这类点的硬约束会导致次优模型的问题。&lt;h4&gt;方法&lt;/h4&gt;首先设计了AMContrast3D方法，将对比学习融入模糊度估计框架，根据模糊度水平对每个点进行自适应目标调整。此外，提出了AMContrast3D++，通过两个并行训练的分支，引入了一个新颖的模糊度预测模块，同时从生成的嵌入中学习点模糊度。还设计了一个掩码细化机制，利用预测的模糊度使模糊嵌入更加可靠，从而提高分割性能和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在3D室内场景数据集S3DIS和ScanNet上有效。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高3D语义分割的性能和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种自适应边缘对比学习方法，用于点云的3D语义分割。针对现有方法中忽略每点模糊性和过渡区域低区分度特征的问题，本文首先设计了AMContrast3D方法，将对比学习融入模糊度估计框架，根据模糊度水平对每个点进行自适应目标调整。进一步，提出了AMContrast3D++，通过并行训练的两个分支和一个新颖的模糊度预测模块，同时从生成的嵌入中学习点模糊度。此外，还设计了一个掩码细化机制，利用预测的模糊度使模糊嵌入更加可靠，从而提高分割性能和鲁棒性。在3D室内场景数据集S3DIS和ScanNet上的实验结果表明，该方法能够有效提高3D语义分割的性能和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an adaptive margin contrastive learning method for 3Dsemantic segmentation on point clouds. Most existing methods use equallypenalized objectives, which ignore the per-point ambiguities and lessdiscriminated features stemming from transition regions. However, as highlyambiguous points may be indistinguishable even for humans, their manuallyannotated labels are less reliable, and hard constraints over these pointswould lead to sub-optimal models. To address this, we first designAMContrast3D, a method comprising contrastive learning into an ambiguityestimation framework, tailored to adaptive objectives for individual pointsbased on ambiguity levels. As a result, our method promotes model training,which ensures the correctness of low-ambiguity points while allowing mistakesfor high-ambiguity points. As ambiguities are formulated based on positiondiscrepancies across labels, optimization during inference is constrained bythe assumption that all unlabeled points are uniformly unambiguous, lackingambiguity awareness. Inspired by the insight of joint training, we furtherpropose AMContrast3D++ integrating with two branches trained in parallel, wherea novel ambiguity prediction module concurrently learns point ambiguities fromgenerated embeddings. To this end, we design a masked refinement mechanism thatleverages predicted ambiguities to enable the ambiguous embeddings to be morereliable, thereby boosting segmentation performance and enhancing robustness.Experimental results on 3D indoor scene datasets, S3DIS and ScanNet,demonstrate the effectiveness of the proposed method. Code is available athttps://github.com/YangChenApril/AMContrast3D.</description>
      <author>example@mail.com (Yang Chen, Yueqi Duan, Haowen Sun, Jiwen Lu, Yap-Peng Tan)</author>
      <guid isPermaLink="false">2507.06592v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>GreenHyperSpectra: A multi-source hyperspectral dataset for global vegetation trait prediction</title>
      <link>http://arxiv.org/abs/2507.06806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了GreenHyperSpectra，一个包含真实世界跨传感器和跨生态系统样本的预训练数据集，用于基准测试植物性状预测的半监督和自监督方法。&lt;h4&gt;背景&lt;/h4&gt;植物性状（如叶片碳含量和叶片质量）是生物多样性和气候变化研究中的关键变量，但传统现场采样难以在生态意义上合理的空间尺度上覆盖性状变异。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的植物性状预测方法，利用遥感高光谱数据，解决标签稀缺和领域变化（如跨传感器、生态分布）带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;GreenHyperSpectra旨在为性状预测提供一个基准，采用包括分布内和分布外场景的评估框架，并使用多输出回归模型进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;GreenHyperSpectra在预训练标签高效的多输出回归模型方面取得了成功，这些模型优于现有的监督基线，并在学习光谱表示方面取得了显著改进。&lt;h4&gt;结论&lt;/h4&gt;GreenHyperSpectra为跨领域植物性状评估提供了方法论框架，促进了表征学习和植物功能性状评估领域的交叉研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：植物性状，如叶片碳含量和叶片质量，是生物多样性和气候变化研究中不可或缺的变量。然而，传统的现场采样难以在生态上有意义的尺度上覆盖性状变异。机器学习为跨越生态系统的植物性状预测提供了一种有价值的解决方案，它利用遥感高光谱数据。然而，从高光谱数据中预测性状受到标签稀缺和大量领域变化（例如，跨传感器、生态分布）的挑战，需要稳健的跨领域方法。在此，我们提出了GreenHyperSpectra，一个包含现实世界跨传感器和跨生态系统样本的预训练数据集，旨在用半监督和自监督方法进行性状预测基准测试。我们采用了一个包含分布内和分布外场景的评估框架。我们成功地利用GreenHyperSpectra预训练了标签高效的多元回归模型，这些模型优于最先进的监督基线。我们的实证分析表明，在性状预测方面学习光谱表示有了显著改进，建立了一个全面的方法论框架，以促进表征学习和植物功能性状评估交叉领域的研究。所有代码和数据可在以下网址找到：https://github.com/echerif18/HyspectraSSL。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Plant traits such as leaf carbon content and leaf mass are essentialvariables in the study of biodiversity and climate change. However,conventional field sampling cannot feasibly cover trait variation atecologically meaningful spatial scales. Machine learning represents a valuablesolution for plant trait prediction across ecosystems, leveraging hyperspectraldata from remote sensing. Nevertheless, trait prediction from hyperspectraldata is challenged by label scarcity and substantial domain shifts (\eg acrosssensors, ecological distributions), requiring robust cross-domain methods.Here, we present GreenHyperSpectra, a pretraining dataset encompassingreal-world cross-sensor and cross-ecosystem samples designed to benchmark traitprediction with semi- and self-supervised methods. We adopt an evaluationframework encompassing in-distribution and out-of-distribution scenarios. Wesuccessfully leverage GreenHyperSpectra to pretrain label-efficientmulti-output regression models that outperform the state-of-the-art supervisedbaseline. Our empirical analyses demonstrate substantial improvements inlearning spectral representations for trait prediction, establishing acomprehensive methodological framework to catalyze research at the intersectionof representation learning and plant functional traits assessment. All code anddata are available at: https://github.com/echerif18/HyspectraSSL.</description>
      <author>example@mail.com (Eya Cherif, Arthur Ouaknine, Luke A. Brown, Phuong D. Dao, Kyle R. Kovach, Bing Lu, Daniel Mederer, Hannes Feilhauer, Teja Kattenborn, David Rolnick)</author>
      <guid isPermaLink="false">2507.06806v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Omni-Video: Democratizing Unified Video Understanding and Generation</title>
      <link>http://arxiv.org/abs/2507.06119v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report, project page:  https://howellyoung-s.github.io/OmniVideo_project/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Omni-Video的统一视频理解和生成框架，旨在弥合当前视频理解和生成模型发展的差距。&lt;h4&gt;背景&lt;/h4&gt;当前基础模型主要关注图像处理，而视频理解和生成模型的统一发展存在不足。&lt;h4&gt;目的&lt;/h4&gt;提出Omni-Video框架，实现视频理解、生成以及基于指令的编辑。&lt;h4&gt;方法&lt;/h4&gt;1) 设计轻量级架构，在MLLMs顶部添加视觉头，在扩散解码器输入前添加适配器，前者生成视觉标记供后者使用，后者将这些标记适配到扩散解码器的条件空间；2) 采用高效的分阶段训练方案，在有限的数据和计算资源下，促进MLLMs和扩散解码器之间的快速连接。&lt;h4&gt;主要发现&lt;/h4&gt;模型在视频生成、编辑和理解任务上表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;Omni-Video框架为统一视频建模提供了有效的方法，并展示了其在视频理解和生成方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Notable breakthroughs in unified understanding and generation modeling haveled to remarkable advancements in image understanding, reasoning, productionand editing, yet current foundational models predominantly focus on processingimages, creating a gap in the development of unified models for videounderstanding and generation. This report presents Omni-Video, an efficient andeffective unified framework for video understanding, generation, as well asinstruction-based editing. Our key insight is to teach existing multimodallarge language models (MLLMs) to produce continuous visual clues that are usedas the input of diffusion decoders, which produce high-quality videosconditioned on these visual clues. To fully unlock the potential of our systemfor unified video modeling, we integrate several technical improvements: 1) alightweight architectural design that respectively attaches a vision head onthe top of MLLMs and a adapter before the input of diffusion decoders, theformer produce visual tokens for the latter, which adapts these visual tokensto the conditional space of diffusion decoders; and 2) an efficient multi-stagetraining scheme that facilitates a fast connection between MLLMs and diffusiondecoders with limited data and computational resources. We empiricallydemonstrate that our model exhibits satisfactory generalization abilitiesacross video generation, editing and understanding tasks.</description>
      <author>example@mail.com (Zhiyu Tan, Hao Yang, Luozheng Qin, Jia Gong, Mengping Yang, Hao Li)</author>
      <guid isPermaLink="false">2507.06119v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>What Demands Attention in Urban Street Scenes? From Scene Understanding towards Road Safety: A Survey of Vision-driven Datasets and Studies</title>
      <link>http://arxiv.org/abs/2507.06513v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  45 pages, 52 figures, 2 large tables (divided into 5), 73 datatsets,  35 tasks&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统性地对基于视觉的传感器和计算机视觉算法在交通场景分析中的应用进行了综述，并对相关任务和数据进行分类和分析。&lt;h4&gt;背景&lt;/h4&gt;随着视觉传感器和计算机视觉算法的进步，交通场景的分析和理解得到了显著提高。&lt;h4&gt;目的&lt;/h4&gt;为了促进这些改进在道路安全中的应用，本文系统地分类了交通场景中需要关注的要素，并全面分析了现有的视觉驱动任务和数据集。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个分类法，将值得关注的交通实体分为异常实体和正常但关键的实体两大类，并整合了十个类别和二十个子类别。通过建立的关联性，提供了一个统一的分析框架。&lt;h4&gt;主要发现&lt;/h4&gt;本文强调了35个视觉驱动任务的分析，并对基于所提出的分类法的73个数据集进行了全面考察和可视化。跨领域研究涵盖了每个基准的优缺点，旨在提供关于标准统一和资源优化的信息。&lt;h4&gt;结论&lt;/h4&gt;本文系统地讨论了现有的弱点，从不同角度强调了潜在的影响和有希望的解决方案。综合分类法、全面分析和总结表格为这一快速发展的领域提供了宝贵的贡献，为研究人员提供了全面的概述，指导战略资源选择，并突出了关键的研究空白。&lt;h4&gt;翻译&lt;/h4&gt;The paper systematically reviews the application of vision-based sensors and computer vision algorithms in traffic scene analysis and comprehensively classifies and analyzes relevant tasks and datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in vision-based sensors and computer vision algorithms havesignificantly improved the analysis and understanding of traffic scenarios. Tofacilitate the use of these improvements for road safety, this surveysystematically categorizes the critical elements that demand attention intraffic scenarios and comprehensively analyzes available vision-driven tasksand datasets. Compared to existing surveys that focus on isolated domains, ourtaxonomy categorizes attention-worthy traffic entities into two main groupsthat are anomalies and normal but critical entities, integrating ten categoriesand twenty subclasses. It establishes connections between inherently relatedfields and provides a unified analytical framework. Our survey highlights theanalysis of 35 vision-driven tasks and comprehensive examinations andvisualizations of 73 available datasets based on the proposed taxonomy. Thecross-domain investigation covers the pros and cons of each benchmark with theaim of providing information on standards unification and resourceoptimization. Our article concludes with a systematic discussion of theexisting weaknesses, underlining the potential effects and promising solutionsfrom various perspectives. The integrated taxonomy, comprehensive analysis, andrecapitulatory tables serve as valuable contributions to this rapidly evolvingfield by providing researchers with a holistic overview, guiding strategicresource selection, and highlighting critical research gaps.</description>
      <author>example@mail.com (Yaoqi Huang, Julie Stephany Berrio, Mao Shan, Stewart Worrall)</author>
      <guid isPermaLink="false">2507.06513v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>A Principled Framework for Multi-View Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.06979v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对对比学习（CL）中多视图增强方法存在的问题，提出了两种新的损失函数，以提升多视图对比学习的效果。&lt;h4&gt;背景&lt;/h4&gt;对比学习是一种自监督学习方法，通常依赖于通过增强生成的数据视图对。然而，当前方法在处理多个视图时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;解决当前对比学习方法在处理多个视图时的四个关键局限性：多个优化项导致冲突目标、未能建模所有视图和数据点之间的交互、继承了成对对比损失的局限性、未能充分利用视图多样性的优势。&lt;h4&gt;方法&lt;/h4&gt;提出了MV-InfoNCE和MV-DHEL两种新的损失函数。MV-InfoNCE通过一个数据点的一个项同时包含所有可能的视图交互；MV-DHEL解耦了视图间的对齐和均匀性，并随着视图数量的增加而扩展交互复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，这两种方法在ImageNet1K和其他三个数据集上优于现有的多视图方法，并且随着视图数量的增加而有效扩展。此外，它们可以应用于多模态数据，并且可以扩展到超过两种模态。消融研究表明，MV-DHEL在五个或更多视图中有效缓解了维度塌陷，充分利用了嵌入空间，从而实现了在监督学习中观察到的多视图优势。&lt;h4&gt;结论&lt;/h4&gt;本文提出的MV-InfoNCE和MV-DHEL损失函数为多视图对比学习提供了理论上的扩展，并通过实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Learning (CL), a leading paradigm in Self-Supervised Learning(SSL), typically relies on pairs of data views generated through augmentation.While multiple augmentations per instance (more than two) improvegeneralization in supervised learning, current CL methods handle additionalviews suboptimally by simply aggregating different pairwise objectives. Thisapproach suffers from four critical limitations: (L1) it utilizes multipleoptimization terms per data point resulting to conflicting objectives, (L2) itfails to model all interactions across views and data points, (L3) it inheritsfundamental limitations (e.g. alignment-uniformity coupling) from pairwise CLlosses, and (L4) it prevents fully realizing the benefits of increased viewmultiplicity observed in supervised settings. We address these limitationsthrough two novel loss functions: MV-InfoNCE, which extends InfoNCE toincorporate all possible view interactions simultaneously in one term per datapoint, and MV-DHEL, which decouples alignment from uniformity across viewswhile scaling interaction complexity with view multiplicity. Both approachesare theoretically grounded - we prove they asymptotically optimize foralignment of all views and uniformity, providing principled extensions tomulti-view contrastive learning. Our empirical results on ImageNet1K and threeother datasets demonstrate that our methods consistently outperform existingmulti-view approaches and effectively scale with increasing view multiplicity.We also apply our objectives to multimodal data and show that, in contrast toother contrastive objectives, they can scale beyond just two modalities. Mostsignificantly, ablation studies reveal that MV-DHEL with five or more viewseffectively mitigates dimensionality collapse by fully utilizing the embeddingspace, thereby delivering multi-view benefits observed in supervised learning.</description>
      <author>example@mail.com (Panagiotis Koromilas, Efthymios Georgiou, Giorgos Bouritsas, Theodoros Giannakopoulos, Mihalis A. Nicolaou, Yannis Panagakis)</author>
      <guid isPermaLink="false">2507.06979v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Fast Equivariant Imaging: Acceleration for Unsupervised Learning via Augmented Lagrangian and Auxiliary PnP Denoisers</title>
      <link>http://arxiv.org/abs/2507.06764v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为快速等变成像（Fast Equivariant Imaging，FEI）的新型无监督学习框架，用于高效训练深度成像网络，无需地面实况数据。&lt;h4&gt;背景&lt;/h4&gt;传统等变成像（Equivariant Imaging）需要大量地面实况数据来训练，而FEI通过改进优化方法和利用可插入的降噪器来提高效率。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的无监督学习框架，用于训练深度成像网络，减少对地面实况数据的依赖。&lt;h4&gt;方法&lt;/h4&gt;通过拉格朗日乘数法重新表述等变成像的优化问题，并利用即插即用的降噪器来提高训练效率。&lt;h4&gt;主要发现&lt;/h4&gt;PnP-FEI方案在CT100数据集上训练U-Net进行X射线CT重建时，比标准EI快一个数量级（10倍），同时提高了泛化性能。&lt;h4&gt;结论&lt;/h4&gt;FEI框架在效率性能上优于传统的等变成像方法，特别是在X射线CT重建任务中表现出显著的加速和改进的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;We propose Fast Equivariant Imaging (FEI), a novel unsupervised learning framework to efficiently train deep imaging networks without ground-truth data. From the perspective of reformulating the Equivariant Imaging based optimization problem via the method of Lagrange multipliers and utilizing plug-and-play denoisers, this novel unsupervised scheme shows superior efficiency and performance compared to vanilla Equivariant Imaging paradigm. In particular, our PnP-FEI scheme achieves an order-of-magnitude (10x) acceleration over standard EI on training U-Net with CT100 dataset for X-ray CT reconstruction, with improved generalization performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Fast Equivariant Imaging (FEI), a novel unsupervised learningframework to efficiently train deep imaging networks without ground-truth data.From the perspective of reformulating the Equivariant Imaging basedoptimization problem via the method of Lagrange multipliers and utilizingplug-and-play denoisers, this novel unsupervised scheme shows superiorefficiency and performance compared to vanilla Equivariant Imaging paradigm. Inparticular, our PnP-FEI scheme achieves an order-of-magnitude (10x)acceleration over standard EI on training U-Net with CT100 dataset for X-ray CTreconstruction, with improved generalization performance.</description>
      <author>example@mail.com (Guixian Xu, Jinglai Li, Junqi Tang)</author>
      <guid isPermaLink="false">2507.06764v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN</title>
      <link>http://arxiv.org/abs/2507.06895v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SCoRE是一种模块化和成本效益高的句子级关系抽取系统，能够与预训练的大型语言模型无缝集成，适用于低监督环境下的知识图谱丰富化。&lt;h4&gt;背景&lt;/h4&gt;随着利用外部语料库高效丰富知识图谱的需求增长，关系抽取（RE）技术，尤其是在低监督设置下的关系抽取技术，受到了越来越多的关注。&lt;h4&gt;目的&lt;/h4&gt;为了解决需要适应性强且对噪声鲁棒的关系抽取解决方案，以及这些解决方案能够与预训练的大型语言模型（PLMs）无缝集成的需求，研究者们开发了SCoRE系统。&lt;h4&gt;方法&lt;/h4&gt;SCoRE结合了监督对比学习和贝叶斯k-近邻（kNN）分类器进行多标签分类，并通过提出两个新的评价指标——相关性结构距离（CSD）和精确率在R（P@R）来提高关系抽取的评价。同时，研究者们发布了Wiki20d数据集，用于复现只有知识图谱（KG）派生注释的真实世界关系抽取条件。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，SCoRE在五个基准数据集上的表现与现有最佳方法相当或更好，同时显著降低了能耗。进一步的分析显示，模型复杂性的增加会降低性能，突出了SCoRE最小化设计的优势。&lt;h4&gt;结论&lt;/h4&gt;SCoRE通过结合效率、模块化和可扩展性，成为现实世界关系抽取应用的理想选择。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着对利用外部语料库高效丰富知识图谱需求的增长，对关系抽取（RE）技术，尤其是在低监督设置下的关系抽取技术，兴趣日益浓厚。为了解决对适应性强且对噪声鲁棒的关系抽取解决方案的需求，以及这些解决方案能够与预训练的大型语言模型（PLMs）无缝集成的需求，我们引入了SCoRE，一个模块化和成本效益高的句子级RE系统。SCoRE能够轻松切换PLM，无需微调，并能平滑地适应不同的语料库和知识图谱。通过结合监督对比学习与贝叶斯k-近邻（kNN）分类器进行多标签分类，即使在远离监督语料库的噪声注释下，它也能提供稳健的性能。为了提高RE评估，我们提出了两个新颖的指标：相关性结构距离（CSD），衡量学习到的关系模式和知识图谱结构之间的对齐；精确率在R（P@R），评估作为推荐系统的效用。我们还发布了Wiki20d，这是一个复现真实世界RE条件（其中只有KG派生的注释可用）的基准数据集。在五个基准数据集上的实验表明，SCoRE的表现与现有最佳方法相当或更好，同时显著降低了能耗。进一步的分析显示，与先前工作所见，模型复杂性的增加会降低性能，突出了SCoRE最小化设计的优势。结合效率、模块化和可扩展性，SCoRE是现实世界RE应用的理想选择。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing demand for efficient knowledge graph (KG) enrichment leveragingexternal corpora has intensified interest in relation extraction (RE),particularly under low-supervision settings. To address the need for adaptableand noise-resilient RE solutions that integrate seamlessly with pre-trainedlarge language models (PLMs), we introduce SCoRE, a modular and cost-effectivesentence-level RE system. SCoRE enables easy PLM switching, requires nofinetuning, and adapts smoothly to diverse corpora and KGs. By combiningsupervised contrastive learning with a Bayesian k-Nearest Neighbors (kNN)classifier for multi-label classification, it delivers robust performancedespite the noisy annotations of distantly supervised corpora. To improve REevaluation, we propose two novel metrics: Correlation Structure Distance (CSD),measuring the alignment between learned relational patterns and KG structures,and Precision at R (P@R), assessing utility as a recommender system. We alsorelease Wiki20d, a benchmark dataset replicating real-world RE conditions whereonly KG-derived annotations are available. Experiments on five benchmarks showthat SCoRE matches or surpasses state-of-the-art methods while significantlyreducing energy consumption. Further analyses reveal that increasing modelcomplexity, as seen in prior work, degrades performance, highlighting theadvantages of SCoRE's minimal design. Combining efficiency, modularity, andscalability, SCoRE stands as an optimal choice for real-world RE applications.</description>
      <author>example@mail.com (Luca Mariotti, Veronica Guidetti, Federica Mandreoli)</author>
      <guid isPermaLink="false">2507.06895v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2507.06469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为MimbFD的图表示学习方法，用于缓解欺诈检测中的消息不平衡问题，并通过实验证明了其在欺诈检测中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;图表示学习在欺诈检测中得到了广泛应用，但其对局部交互的过度关注导致了全局拓扑信息的不平衡传递和节点特定信息被淹没的风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来减轻欺诈检测中的消息不平衡问题，以改善图神经网络在欺诈检测中的性能。&lt;h4&gt;方法&lt;/h4&gt;本文首先总结了拓扑和类别不平衡对基于GNN的欺诈检测任务的影响，然后提出了MimbFD方法，包括拓扑消息可达性模块和局部混淆去偏置模块。&lt;h4&gt;主要发现&lt;/h4&gt;MimbFD通过设计拓扑消息可达性模块来提高节点表示学习质量，并通过局部混淆去偏置模块调整节点表示，平衡不同类别的影响。&lt;h4&gt;结论&lt;/h4&gt;在三个公开的欺诈数据集上进行的实验表明，MimbFD在欺诈检测中表现出优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph representation learning has become a mainstream method for frauddetection due to its strong expressive power, which focuses on enhancing noderepresentations through improved neighborhood knowledge capture. However, thefocus on local interactions leads to imbalanced transmission of globaltopological information and increased risk of node-specific information beingoverwhelmed during aggregation due to the imbalance between fraud and benignnodes. In this paper, we first summarize the impact of topology and classimbalance on downstream tasks in GNN-based fraud detection, as the problem ofimbalanced supervisory messages is caused by fraudsters' topological behaviorobfuscation and identity feature concealment. Based on statistical validation,we propose a novel dual-view graph representation learning method to mitigateMessage imbalance in Fraud Detection(MimbFD). Specifically, we design atopological message reachability module for high-quality node representationlearning to penetrate fraudsters' camouflage and alleviate insufficientpropagation. Then, we introduce a local confounding debiasing module to adjustnode representations, enhancing the stable association between noderepresentations and labels to balance the influence of different classes.Finally, we conducted experiments on three public fraud datasets, and theresults demonstrate that MimbFD exhibits outstanding performance in frauddetection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning has become a mainstream method for frauddetection due to its strong expressive power, which focuses on enhancing noderepresentations through improved neighborhood knowledge capture. However, thefocus on local interactions leads to imbalanced transmission of globaltopological information and increased risk of node-specific information beingoverwhelmed during aggregation due to the imbalance between fraud and benignnodes. In this paper, we first summarize the impact of topology and classimbalance on downstream tasks in GNN-based fraud detection, as the problem ofimbalanced supervisory messages is caused by fraudsters' topological behaviorobfuscation and identity feature concealment. Based on statistical validation,we propose a novel dual-view graph representation learning method to mitigateMessage imbalance in Fraud Detection(MimbFD). Specifically, we design atopological message reachability module for high-quality node representationlearning to penetrate fraudsters' camouflage and alleviate insufficientpropagation. Then, we introduce a local confounding debiasing module to adjustnode representations, enhancing the stable association between noderepresentations and labels to balance the influence of different classes.Finally, we conducted experiments on three public fraud datasets, and theresults demonstrate that MimbFD exhibits outstanding performance in frauddetection.</description>
      <author>example@mail.com (Yudan Song, Yuecen Wei, Yuhang Lu, Qingyun Sun, Minglai Shao, Li-e Wang, Chunming Hu, Xianxian Li, Xingcheng Fu)</author>
      <guid isPermaLink="false">2507.06469v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>StixelNExT++: Lightweight Monocular Scene Segmentation and Representation for Collective Perception</title>
      <link>http://arxiv.org/abs/2507.06687v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了StixelNExT++，这是一种用于单目感知系统的场景表示新方法。&lt;h4&gt;背景&lt;/h4&gt;本文基于已建立的Stixel表示，旨在提升3D Stixel单元的聚类和对象分割能力。&lt;h4&gt;目的&lt;/h4&gt;该方法旨在在保持对点云和鸟瞰图表示的适应性同时，实现场景信息的高效压缩。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一个轻量级的神经网络，该网络基于自动生成的基于LiDAR的真实数据训练，以达到实时性能，每帧计算时间低至10毫秒。&lt;h4&gt;主要发现&lt;/h4&gt;在Waymo数据集上的实验结果表明，StixelNExT++在30米范围内表现出具有竞争力的性能，突显了其在自动驾驶系统集体感知中的潜力。&lt;h4&gt;结论&lt;/h4&gt;StixelNExT++在场景表示方面具有实际应用价值，特别是在自动驾驶系统的感知功能中。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents StixelNExT++, a novel approach to scene representation for monocular perception systems. Building on the established Stixel representation, our method infers 3D Stixels and enhances object segmentation by clustering smaller 3D Stixel units. The approach achieves high compression of scene information while remaining adaptable to point cloud and bird's-eye-view representations. Our lightweight neural network, trained on automatically generated LiDAR-based ground truth, achieves real-time performance with computation times as low as 10 ms per frame. Experimental results on the Waymo dataset demonstrate competitive performance within a 30-meter range, highlighting the potential of StixelNExT++ for collective perception in autonomous systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents StixelNExT++, a novel approach to scene representationfor monocular perception systems. Building on the established Stixelrepresentation, our method infers 3D Stixels and enhances object segmentationby clustering smaller 3D Stixel units. The approach achieves high compressionof scene information while remaining adaptable to point cloud andbird's-eye-view representations. Our lightweight neural network, trained onautomatically generated LiDAR-based ground truth, achieves real-timeperformance with computation times as low as 10 ms per frame. Experimentalresults on the Waymo dataset demonstrate competitive performance within a30-meter range, highlighting the potential of StixelNExT++ for collectiveperception in autonomous systems.</description>
      <author>example@mail.com (Marcel Vosshans, Omar Ait-Aider, Youcef Mezouar, Markus Enzweiler)</author>
      <guid isPermaLink="false">2507.06687v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models</title>
      <link>http://arxiv.org/abs/2507.06952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基础模型在领域理解上的潜力，提出了一种评估方法来检验模型是否真正捕捉到深层结构，并发现模型在训练任务上表现优异，但在适应新任务时却未能形成对基础世界模型的归纳偏置。&lt;h4&gt;背景&lt;/h4&gt;基础模型基于序列预测可以揭示更深层次领域理解的理念，类似于开普勒对行星运动的预测最终导致了牛顿力学的发现。&lt;h4&gt;目的&lt;/h4&gt;开发一种评估基础模型的技术，以检验它们是否能够适应由假设世界模型生成的合成数据集，并测量模型的归纳偏置是否与世界模型一致。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为归纳偏置探测的技术，该技术通过考察模型在合成数据集上的表现来评估其归纳偏置。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，基础模型在训练任务上表现出色，但在适应新任务时未能形成对基础世界模型的归纳偏置，特别是在基于轨道轨迹训练的模型在适应新的物理任务时，未能应用牛顿力学。&lt;h4&gt;结论&lt;/h4&gt;进一步分析表明，这些模型似乎发展出了特定于任务的启发式方法，这些方法无法进行泛化。&lt;h4&gt;翻译&lt;/h4&gt;本文基于序列预测的深层领域理解理念，开发了一种评估基础模型的技术，发现模型在训练任务上表现优异，但在适应新任务时未能形成对基础世界模型的归纳偏置，特别是在基于轨道轨迹训练的模型在适应新的物理任务时，未能应用牛顿力学。进一步分析表明，这些模型似乎发展出了特定于任务的启发式方法，这些方法无法进行泛化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are premised on the idea that sequence prediction canuncover deeper domain understanding, much like how Kepler's predictions ofplanetary motion later led to the discovery of Newtonian mechanics. However,evaluating whether these models truly capture deeper structure remains achallenge. We develop a technique for evaluating foundation models thatexamines how they adapt to synthetic datasets generated from some postulatedworld model. Our technique measures whether the foundation model's inductivebias aligns with the world model, and so we refer to it as an inductive biasprobe. Across multiple domains, we find that foundation models can excel attheir training tasks yet fail to develop inductive biases towards theunderlying world model when adapted to new tasks. We particularly find thatfoundation models trained on orbital trajectories consistently fail to applyNewtonian mechanics when adapted to new physics tasks. Further analysis revealsthat these models behave as if they develop task-specific heuristics that failto generalize.</description>
      <author>example@mail.com (Keyon Vafa, Peter G. Chang, Ashesh Rambachan, Sendhil Mullainathan)</author>
      <guid isPermaLink="false">2507.06952v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>STARS: A Unified Framework for Singing Transcription, Alignment, and Refined Style Annotation</title>
      <link>http://arxiv.org/abs/2507.06670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STARS的统一框架，用于自动化的歌唱声音合成（SVS）标注，旨在解决手动标注的劳动和资源密集问题。&lt;h4&gt;背景&lt;/h4&gt;现有的自动歌唱标注方法主要针对标注流程的某个独立方面，而高质量的标注数据集对歌唱声音合成的需求日益增长。&lt;h4&gt;目的&lt;/h4&gt;STARS旨在同时解决歌唱转录、对齐和风格标注的挑战。&lt;h4&gt;方法&lt;/h4&gt;STARS采用了层次化的声学特征处理，并使用了新颖的非自回归局部声学编码器来学习结构化的分层表示。它提供了包括精确的音素-音频对齐、稳健的音符转录和定位、表现力强的嗓音技术识别以及全局风格特征（包括情感和节奏）在内的多层次标注。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证表明，与现有的标注方法相比，STARS在多个评估维度上表现出优异的性能。此外，在SVS训练中的应用表明，使用STARS标注数据的模型实现了显著提高的感知自然度和精确的风格控制。&lt;h4&gt;结论&lt;/h4&gt;STARS不仅克服了创建歌唱数据集中的关键可扩展性挑战，而且在可控歌唱声音合成的新方法方面开辟了先河。&lt;h4&gt;翻译&lt;/h4&gt;Recent breakthroughs in singing voice synthesis (SVS) have heightened the demand for high-quality annotated datasets, yet manual annotation remains prohibitively labor-intensive and resource-intensive. Existing automatic singing annotation (ASA) methods, however, primarily tackle isolated aspects of the annotation pipeline. To address this fundamental challenge, we present STARS, which is, to our knowledge, the first unified framework that simultaneously addresses singing transcription, alignment, and refined style annotation. Our framework delivers comprehensive multi-level annotations encompassing: (1) precise phoneme-audio alignment, (2) robust note transcription and temporal localization, (3) expressive vocal technique identification, and (4) global stylistic characterization including emotion and pace. The proposed architecture employs hierarchical acoustic feature processing across frame, word, phoneme, note, and sentence levels. The novel non-autoregressive local acoustic encoders enable structured hierarchical representation learning. Experimental validation confirms the framework's superior performance across multiple evaluation dimensions compared to existing annotation approaches. Furthermore, applications in SVS training demonstrate that models utilizing STARS-annotated data achieve significantly enhanced perceptual naturalness and precise style control. This work not only overcomes critical scalability challenges in the creation of singing datasets but also pioneers new methodologies for controllable singing voice synthesis. Audiosamples are available at https://gwx314.github.io/stars-demo/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent breakthroughs in singing voice synthesis (SVS) have heightened thedemand for high-quality annotated datasets, yet manual annotation remainsprohibitively labor-intensive and resource-intensive. Existing automaticsinging annotation (ASA) methods, however, primarily tackle isolated aspects ofthe annotation pipeline. To address this fundamental challenge, we presentSTARS, which is, to our knowledge, the first unified framework thatsimultaneously addresses singing transcription, alignment, and refined styleannotation. Our framework delivers comprehensive multi-level annotationsencompassing: (1) precise phoneme-audio alignment, (2) robust notetranscription and temporal localization, (3) expressive vocal techniqueidentification, and (4) global stylistic characterization including emotion andpace. The proposed architecture employs hierarchical acoustic featureprocessing across frame, word, phoneme, note, and sentence levels. The novelnon-autoregressive local acoustic encoders enable structured hierarchicalrepresentation learning. Experimental validation confirms the framework'ssuperior performance across multiple evaluation dimensions compared to existingannotation approaches. Furthermore, applications in SVS training demonstratethat models utilizing STARS-annotated data achieve significantly enhancedperceptual naturalness and precise style control. This work not only overcomescritical scalability challenges in the creation of singing datasets but alsopioneers new methodologies for controllable singing voice synthesis. Audiosamples are available at https://gwx314.github.io/stars-demo/.</description>
      <author>example@mail.com (Wenxiang Guo, Yu Zhang, Changhao Pan, Zhiyuan Zhu, Ruiqi Li, Zhetao Chen, Wenhao Xu, Fei Wu, Zhou Zhao)</author>
      <guid isPermaLink="false">2507.06670v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>MK-Pose: Category-Level Object Pose Estimation via Multimodal-Based Keypoint Learning</title>
      <link>http://arxiv.org/abs/2507.06662v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多模态的关键点学习框架MK-Pose，用于在已知类别中预测对象的姿态，解决了现有方法在物体遮挡和泛化能力上的不足。&lt;h4&gt;背景&lt;/h4&gt;类别级物体姿态估计在自动化仓库和制造业等领域至关重要，但现有方法在处理物体遮挡和不同实例、类别间的泛化问题时存在困难。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够有效预测物体姿态的方法，提高在复杂场景下的准确性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;MK-Pose框架集成了RGB图像、点云和类别级文本描述，使用自监督关键点检测模块，并结合注意力查询生成、软热图匹配和基于图的关系建模。此外，还设计了图增强特征融合模块，以整合局部几何信息和全局上下文。&lt;h4&gt;主要发现&lt;/h4&gt;MK-Pose在CAMERA25和REAL275数据集上进行了评估，并在HouseCat6D数据集上测试了跨数据集的能力，结果表明MK-Pose在IoU和平均精度方面均优于现有最佳方法，且无需形状先验。&lt;h4&gt;结论&lt;/h4&gt;MK-Pose是一种有效且具有优越性能的物体姿态估计方法，未来将在相关领域得到应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：类别级物体姿态估计，即在不了解单个实例的情况下预测已知类别中物体的姿态，在仓库自动化和制造业等应用中至关重要。现有依赖于RGB图像或点云数据的方法往往难以处理物体遮挡，以及在不同实例和类别间进行泛化。本文提出了一种基于多模态的关键点学习框架（MK-Pose），该框架集成了RGB图像、点云和类别级文本描述。该模型使用了一个增强的注意力查询生成的自监督关键点检测模块，结合了软热图匹配和基于图的关系建模。此外，还设计了一个图增强的特征融合模块，用于整合局部几何信息和全局上下文。MK-Pose在CAMERA25和REAL275数据集上进行了评估，并在HouseCat6D数据集上测试了跨数据集的能力。结果表明，MK-Pose在IoU和平均精度方面均优于现有最佳方法，无需形状先验。代码将在https://github.com/yangyifanYYF/MK-Pose处发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Category-level object pose estimation, which predicts the pose of objectswithin a known category without prior knowledge of individual instances, isessential in applications like warehouse automation and manufacturing. Existingmethods relying on RGB images or point cloud data often struggle with objectocclusion and generalization across different instances and categories. Thispaper proposes a multimodal-based keypoint learning framework (MK-Pose) thatintegrates RGB images, point clouds, and category-level textual descriptions.The model uses a self-supervised keypoint detection module enhanced withattention-based query generation, soft heatmap matching and graph-basedrelational modeling. Additionally, a graph-enhanced feature fusion module isdesigned to integrate local geometric information and global context. MK-Poseis evaluated on CAMERA25 and REAL275 dataset, and is further tested forcross-dataset capability on HouseCat6D dataset. The results demonstrate thatMK-Pose outperforms existing state-of-the-art methods in both IoU and averageprecision without shape priors. Codes will be released at\href{https://github.com/yangyifanYYF/MK-Pose}{https://github.com/yangyifanYYF/MK-Pose}.</description>
      <author>example@mail.com (Yifan Yang, Peili Song, Enfan Lan, Dong Liu, Jingtai Liu)</author>
      <guid isPermaLink="false">2507.06662v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications</title>
      <link>http://arxiv.org/abs/2507.06795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在开放源代码大型语言模型（LLMs）的背景下，小型LLMs（sLLMs）的应用及其在领域自适应连续预训练（DACP）方法下的效果。&lt;h4&gt;背景&lt;/h4&gt;开放源代码大型语言模型的出现为企业的应用提供了更多机会，但许多组织缺乏部署和维护大规模模型的基础设施。小型LLMs虽然性能有限，但已成为实际可行的替代方案。&lt;h4&gt;目的&lt;/h4&gt;验证将基于DACP的方案应用于不同的基础模型和服务领域中的有效性。&lt;h4&gt;方法&lt;/h4&gt;通过广泛的实验和实际评估，研究DACP应用于sLLMs在目标领域性能上的提升。&lt;h4&gt;主要发现&lt;/h4&gt;应用DACP的sLLMs在目标领域性能上取得了显著提升，同时保持了通用能力，为企业的部署提供了成本效益高且可扩展的解决方案。&lt;h4&gt;结论&lt;/h4&gt;DACP方法对于提高sLLMs在商业应用中的性能具有实际意义，为企业的部署提供了有效途径。&lt;h4&gt;翻译&lt;/h4&gt;The emergence of open-source large language models (LLMs) has expanded opportunities for enterprise applications; however, many organizations still lack the infrastructure to deploy and maintain large-scale models. As a result, small LLMs (sLLMs) have become a practical alternative, despite their inherent performance limitations. While Domain Adaptive Continual Pretraining (DACP) has been previously explored as a method for domain adaptation, its utility in commercial applications remains under-examined. In this study, we validate the effectiveness of applying a DACP-based recipe across diverse foundation models and service domains. Through extensive experiments and real-world evaluations, we demonstrate that DACP-applied sLLMs achieve substantial gains in target domain performance while preserving general capabilities, offering a cost-efficient and scalable solution for enterprise-level deployment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of open-source large language models (LLMs) has expandedopportunities for enterprise applications; however, many organizations stilllack the infrastructure to deploy and maintain large-scale models. As a result,small LLMs (sLLMs) have become a practical alternative, despite their inherentperformance limitations. While Domain Adaptive Continual Pretraining (DACP) hasbeen previously explored as a method for domain adaptation, its utility incommercial applications remains under-examined. In this study, we validate theeffectiveness of applying a DACP-based recipe across diverse foundation modelsand service domains. Through extensive experiments and real-world evaluations,we demonstrate that DACP-applied sLLMs achieve substantial gains in targetdomain performance while preserving general capabilities, offering acost-efficient and scalable solution for enterprise-level deployment.</description>
      <author>example@mail.com (Seonwu Kim, Yohan Na, Kihun Kim, Hanhee Cho, Geun Lim, Mintae Kim, Seongik Park, Ki Hyun Kim, Youngsub Han, Byoung-Ki Jeon)</author>
      <guid isPermaLink="false">2507.06795v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>MADPOT: Medical Anomaly Detection with CLIP Adaptation and Partial Optimal Transport</title>
      <link>http://arxiv.org/abs/2507.06733v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICIAP 2025 (this version is not peer-reviewed; it is the  submitted version). ICIAP 2025 proceedings DOI will appear here&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种结合视觉适配器和提示学习的方法，通过部分最优传输（POT）和对比学习（CL）来提高CLIP在医学图像上的适应性，尤其是在医学异常检测（AD）方面。&lt;h4&gt;背景&lt;/h4&gt;医学异常检测因图像模态多样、解剖结构变异和标注数据有限而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提高CLIP在医学图像上的适应性，尤其是用于医学异常检测。&lt;h4&gt;方法&lt;/h4&gt;方法结合了视觉适配器和提示学习，使用POT对局部特征进行对齐，以捕获微小的异常；对比学习（CL）进一步强化了类内凝聚和类间分离。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在少样本、零样本和跨数据集场景中取得了最先进的成果，无需合成数据或记忆库。&lt;h4&gt;结论&lt;/h4&gt;该方法在医学异常检测方面表现优异。&lt;h4&gt;翻译&lt;/h4&gt;Medical anomaly detection (AD) is challenging due to diverse imagingmodalities, anatomical variations, and limited labeled data. We propose a novelapproach combining visual adapters and prompt learning with Partial OptimalTransport (POT) and contrastive learning (CL) to improve CLIP's adaptability tomedical images, particularly for AD. Unlike standard prompt learning, whichoften yields a single representation, our method employs multiple promptsaligned with local features via POT to capture subtle abnormalities. CL furtherenforces intra-class cohesion and inter-class separation. Our method achievesstate-of-the-art results in few-shot, zero-shot, and cross-dataset scenarioswithout synthetic data or memory banks. The code is available athttps://github.com/mahshid1998/MADPOT.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical anomaly detection (AD) is challenging due to diverse imagingmodalities, anatomical variations, and limited labeled data. We propose a novelapproach combining visual adapters and prompt learning with Partial OptimalTransport (POT) and contrastive learning (CL) to improve CLIP's adaptability tomedical images, particularly for AD. Unlike standard prompt learning, whichoften yields a single representation, our method employs multiple promptsaligned with local features via POT to capture subtle abnormalities. CL furtherenforces intra-class cohesion and inter-class separation. Our method achievesstate-of-the-art results in few-shot, zero-shot, and cross-dataset scenarioswithout synthetic data or memory banks. The code is available athttps://github.com/mahshid1998/MADPOT.</description>
      <author>example@mail.com (Mahshid Shiri, Cigdem Beyan, Vittorio Murino)</author>
      <guid isPermaLink="false">2507.06733v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Prompt Tuning</title>
      <link>http://arxiv.org/abs/2507.06085v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了prompt tuning技术，这是一种通过在模型前添加可训练的连续向量来高效调整语言模型的方法，同时保持模型冻结。文章将现有方法分为直接提示学习和迁移学习两大类，并对每种方法的设计、创新、见解、优点和缺点进行了分析，同时通过可视化比较了不同框架。文章还识别了计算效率和训练稳定性方面的挑战，并讨论了提高训练鲁棒性和拓宽应用范围的未来方向。&lt;h4&gt;背景&lt;/h4&gt;prompt tuning是一种参数高效的语言模型调整方法，通过添加可训练的连续向量来优化模型。&lt;h4&gt;目的&lt;/h4&gt;对prompt tuning技术进行综述，分析不同方法的优缺点，并探讨未来发展方向。&lt;h4&gt;方法&lt;/h4&gt;将prompt tuning方法分为直接提示学习和迁移学习两大类，对每种方法进行详细分析。&lt;h4&gt;主要发现&lt;/h4&gt;直接提示学习和迁移学习是prompt tuning的两种主要方法，文章对它们进行了详细的分类和分析。&lt;h4&gt;结论&lt;/h4&gt;prompt tuning技术具有高效性和鲁棒性，但仍存在计算效率和训练稳定性方面的挑战，未来需要进一步研究和改进。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了prompt tuning技术，这是一种通过在模型前添加可训练的连续向量来高效调整语言模型的方法，同时保持模型冻结。我们将现有方法分为直接提示学习和迁移学习两大类，包括：一般优化方法、基于编码器的方法、分解策略和专家混合框架。对于每种方法，我们分析了方法设计、创新、见解、优点和缺点，并通过可视化比较了不同的框架。我们识别了计算效率和训练稳定性方面的挑战，并讨论了提高训练鲁棒性和拓宽应用范围的未来方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This survey reviews prompt tuning, a parameter-efficient approach foradapting language models by prepending trainable continuous vectors whilekeeping the model frozen. We classify existing approaches into two categories:direct prompt learning and transfer learning. Direct prompt learning methodsinclude: general optimization approaches, encoder-based methods, decompositionstrategies, and mixture-of-experts frameworks. Transfer learning methodsconsist of: general transfer approaches, encoder-based methods, anddecomposition strategies. For each method, we analyze method designs,innovations, insights, advantages, and disadvantages, with illustrativevisualizations comparing different frameworks. We identify challenges incomputational efficiency and training stability, and discuss future directionsin improving training robustness and broadening application scope.</description>
      <author>example@mail.com (Zongqian Li, Yixuan Su, Nigel Collier)</author>
      <guid isPermaLink="false">2507.06085v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision</title>
      <link>http://arxiv.org/abs/2507.06639v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  EXAONE Path 2.0 technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;EXAONE Path 2.0是一个病理学基础模型，通过直接在切片级别监督下学习patch-level表示，使用少量数据就能在多个生物标志物预测任务上取得最先进的平均性能。&lt;h4&gt;背景&lt;/h4&gt;由于全切片图像（WSI）的gigapixel规模，数字病理学中处理WSI通常很困难。大多数方法通过自监督学习（SSL）训练patch编码器，然后通过多个实例学习（MIL）或切片编码器聚合patch级别的嵌入来执行下游任务。&lt;h4&gt;目的&lt;/h4&gt;解决patch-level SSL可能忽略复杂领域特定特征的问题，如突变状态和分子特征，以及SSL方法相对于全监督方法在数据效率和计算资源上的不足。&lt;h4&gt;方法&lt;/h4&gt;EXAONE Path 2.0在直接切片级别监督下学习patch-level表示，使用仅37k个WSI进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;EXAONE Path 2.0在10个生物标志物预测任务上实现了最先进的平均性能，表现出显著的数据效率。&lt;h4&gt;结论&lt;/h4&gt;EXAONE Path 2.0模型在病理学领域的数据效率和性能方面取得了显著进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In digital pathology, whole-slide images (WSIs) are often difficult to handledue to their gigapixel scale, so most approaches train patch encoders viaself-supervised learning (SSL) and then aggregate the patch-level embeddingsvia multiple instance learning (MIL) or slide encoders for downstream tasks.However, patch-level SSL may overlook complex domain-specific features that areessential for biomarker prediction, such as mutation status and molecularcharacteristics, as SSL methods rely only on basic augmentations selected fornatural image domains on small patch-level area. Moreover, SSL methods remainless data efficient than fully supervised approaches, requiring extensivecomputational resources and datasets to achieve competitive performance. Toaddress these limitations, we present EXAONE Path 2.0, a pathology foundationmodel that learns patch-level representations under direct slide-levelsupervision. Using only 37k WSIs for training, EXAONE Path 2.0 achievesstate-of-the-art average performance across 10 biomarker prediction tasks,demonstrating remarkable data efficiency.</description>
      <author>example@mail.com (Myungjang Pyeon, Janghyeon Lee, Minsoo Lee, Juseung Yun, Hwanil Choi, Jonghyun Kim, Jiwon Kim, Yi Hu, Jongseong Jang, Soonyoung Lee)</author>
      <guid isPermaLink="false">2507.06639v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>DecoyDB: A Dataset for Graph Contrastive Learning in Protein-Ligand Binding Affinity Prediction</title>
      <link>http://arxiv.org/abs/2507.06366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为DecoyDB的大规模结构感知数据集，用于自监督图对比学习，以预测蛋白质-配体复合物的结合亲和力，并设计了相应的GCL框架。&lt;h4&gt;背景&lt;/h4&gt;预测蛋白质-配体复合物的结合亲和力对于药物发现至关重要，但受限于缺乏大规模和高质量结合亲和力标签。&lt;h4&gt;目的&lt;/h4&gt;提出DecoyDB数据集和GCL框架，以突破自监督学习在蛋白质-配体复合物上的应用障碍。&lt;h4&gt;方法&lt;/h4&gt;构建DecoyDB数据集，包含高分辨率真实复合物和计算生成的多种伪复合物，并设计GCL框架进行预训练和微调。&lt;h4&gt;主要发现&lt;/h4&gt;DecoyDB数据集和GCL框架能够提高模型在预测蛋白质-配体结合亲和力方面的准确性、标签效率和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;DecoyDB数据集和GCL框架为蛋白质-配体结合亲和力预测提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预测蛋白质-配体复合物的结合亲和力在药物发现中起着至关重要的作用。遗憾的是，由于缺乏大规模和高质量结合亲和力标签，进展受到了阻碍。广泛使用的PDBbind数据集包含少于20K个标记的复合物。自监督学习，尤其是图对比学习（GCL），通过基于大量未标记复合物预训练图神经网络模型并在较少标记的复合物上微调模型，为突破这一障碍提供了独特的机会。然而，该问题面临着独特的挑战，包括缺乏一个具有明确正/负复合物对的全面未标记数据集，以及需要设计能够结合此类数据独特特征的GCL算法。为了填补这一空白，我们提出了DecoyDB，这是一个专门为自监督GCL设计的蛋白质-配体复合物的大规模结构感知数据集。DecoyDB由高分辨率真实复合物（小于2.5埃）和具有从现实到次优（负对）范围的计算生成结合位点的多样化伪复合物组成。每个伪复合物都附带了与天然构象的均方根偏差（RMSD）注释。我们进一步设计了一个定制的GCL框架，用于基于DecoyDB预训练图神经网络并使用PDBbind的标签进行微调。广泛的实验证实，使用DecoyDB预训练的模型在准确性、标签效率和泛化能力方面表现出优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting the binding affinity of protein-ligand complexes plays a vitalrole in drug discovery. Unfortunately, progress has been hindered by the lackof large-scale and high-quality binding affinity labels. The widely usedPDBbind dataset has fewer than 20K labeled complexes. Self-supervised learning,especially graph contrastive learning (GCL), provides a unique opportunity tobreak the barrier by pre-training graph neural network models based on vastunlabeled complexes and fine-tuning the models on much fewer labeled complexes.However, the problem faces unique challenges, including a lack of acomprehensive unlabeled dataset with well-defined positive/negative complexpairs and the need to design GCL algorithms that incorporate the uniquecharacteristics of such data. To fill the gap, we propose DecoyDB, alarge-scale, structure-aware dataset specifically designed for self-supervisedGCL on protein-ligand complexes. DecoyDB consists of high-resolution groundtruth complexes (less than 2.5 Angstrom) and diverse decoy structures withcomputationally generated binding poses that range from realistic to suboptimal(negative pairs). Each decoy is annotated with a Root Mean Squared Deviation(RMSD) from the native pose. We further design a customized GCL framework topre-train graph neural networks based on DecoyDB and fine-tune the models withlabels from PDBbind. Extensive experiments confirm that models pre-trained withDecoyDB achieve superior accuracy, label efficiency, and generalizability.</description>
      <author>example@mail.com (Yupu Zhang, Zelin Xu, Tingsong Xiao, Gustavo Seabra, Yanjun Li, Chenglong Li, Zhe Jiang)</author>
      <guid isPermaLink="false">2507.06366v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds</title>
      <link>http://arxiv.org/abs/2507.06484v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  project website: https://ai.stanford.edu/~sunfanyun/3d-generalist/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种可扩展的方法来生成高质量的3D环境，这些环境可以作为基础模型训练的数据。该方法通过将3D环境构建重新定义为序列决策问题，使用视觉-语言模型（VLMs）作为策略来输出动作，共同设计3D环境的布局、材质、照明和资产。&lt;h4&gt;背景&lt;/h4&gt;尽管大规模预训练赋予了模型语言和视觉推理能力，但由于缺乏基于3D世界的实际数据，提高其空间推理能力仍然具有挑战性。虽然人类可以通过3D图形手动创建沉浸式和交互式的世界，如VR、游戏和机器人应用，但这个过程劳动密集型。&lt;h4&gt;目的&lt;/h4&gt;提出一种可扩展的方法，生成高质量的3D环境，作为训练数据，以增强模型的空间推理能力。&lt;h4&gt;方法&lt;/h4&gt;将3D环境构建视为一个序列决策问题，利用VLMs作为策略输出动作，共同设计3D环境的布局、材质、照明和资产。通过自我改进微调训练VLMs以生成更符合预期的3D环境。&lt;h4&gt;主要发现&lt;/h4&gt;3D-Generalist框架和提出的训练策略在生成可用于模拟的3D环境方面表现出有效性。在合成数据生成中，通过在生成的数据上预训练视觉基础模型，展示了其质量和可扩展性。在下游任务上的微调后，该模型在性能上超过了在精心制作的合成数据上预训练的模型，并且其结果接近使用真实数据达到的结果。&lt;h4&gt;结论&lt;/h4&gt;3D-Generalist方法能够生成高质量的3D环境，有效提升了模型的空间推理能力，并且在合成数据生成方面具有优越的性能和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite large-scale pretraining endowing models with language and visionreasoning capabilities, improving their spatial reasoning capability remainschallenging due to the lack of data grounded in the 3D world. While it ispossible for humans to manually create immersive and interactive worlds through3D graphics, as seen in applications such as VR, gaming, and robotics, thisprocess remains highly labor-intensive. In this paper, we propose a scalablemethod for generating high-quality 3D environments that can serve as trainingdata for foundation models. We recast 3D environment building as a sequentialdecision-making problem, employing Vision-Language-Models (VLMs) as policiesthat output actions to jointly craft a 3D environment's layout, materials,lighting, and assets. Our proposed framework, 3D-Generalist, trains VLMs togenerate more prompt-aligned 3D environments via self-improvement fine-tuning.We demonstrate the effectiveness of 3D-Generalist and the proposed trainingstrategy in generating simulation-ready 3D environments. Furthermore, wedemonstrate its quality and scalability in synthetic data generation bypretraining a vision foundation model on the generated data. After fine-tuningthe pre-trained model on downstream tasks, we show that it surpasses modelspre-trained on meticulously human-crafted synthetic data and approaches resultsachieved with real data orders of magnitude larger.</description>
      <author>example@mail.com (Fan-Yun Sun, Shengguang Wu, Christian Jacobsen, Thomas Yim, Haoming Zou, Alex Zook, Shangru Li, Yu-Hsin Chou, Ethem Can, Xunlei Wu, Clemens Eppner, Valts Blukis, Jonathan Tremblay, Jiajun Wu, Stan Birchfield, Nick Haber)</author>
      <guid isPermaLink="false">2507.06484v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>FuDoBa: Fusing Document and Knowledge Graph-based Representations with Bayesian Optimisation</title>
      <link>http://arxiv.org/abs/2507.06622v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为FuDoBa的基于贝叶斯优化的方法，用于结合大型语言模型（LLMs）和特定领域知识，以生成低维、任务相关的表示，提高分类性能。&lt;h4&gt;背景&lt;/h4&gt;LLMs在文档表示领域取得了成功，但它们生成的嵌入通常维度高、计算复杂，且对特定领域应用不够有效。&lt;h4&gt;目的&lt;/h4&gt;解决LLMs嵌入在特定领域应用中的局限性和效率问题。&lt;h4&gt;方法&lt;/h4&gt;FuDoBa方法将LLMs生成的嵌入与从本地和外部知识库（如WikiData）获取的特定领域结构化知识相结合。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在六个数据集的两个领域上展示了有效性，表明其与鲁棒的基于AutoML的分类器结合时，表现可与或优于仅使用LLMs嵌入的基线。&lt;h4&gt;结论&lt;/h4&gt;FuDoBa方法通过融合LLMs嵌入和领域知识，提高了特定领域应用的分类性能和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building on the success of Large Language Models (LLMs), LLM-basedrepresentations have dominated the document representation landscape, achievinggreat performance on the document embedding benchmarks. However, thehigh-dimensional, computationally expensive embeddings from LLMs tend to beeither too generic or inefficient for domain-specific applications. To addressthese limitations, we introduce FuDoBa a Bayesian optimisation-based methodthat integrates LLM-based embeddings with domain-specific structured knowledge,sourced both locally and from external repositories like WikiData. This fusionproduces low-dimensional, task-relevant representations while reducing trainingcomplexity and yielding interpretable early-fusion weights for enhancedclassification performance. We demonstrate the effectiveness of our approach onsix datasets in two domains, showing that when paired with robust AutoML-basedclassifiers, our proposed representation learning approach performs on parwith, or surpasses, those produced solely by the proprietary LLM-basedembedding baselines.</description>
      <author>example@mail.com (Boshko Koloski, Senja Pollak, Roberto Navigli, Blaž Škrlj)</author>
      <guid isPermaLink="false">2507.06622v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Divergence-Based Similarity Function for Multi-View Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.06560v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于差异的相似度函数（DSF），通过将每个增强视图表示为分布，并测量分布之间的差异来捕捉联合结构，从而在多个任务中提高了性能。&lt;h4&gt;背景&lt;/h4&gt;对比学习在近期取得了成功，但先前方法在损失或特征级别整合多个视图时，主要捕获成对关系，未能建模所有视图之间的联合结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以更有效地利用实例的多个增强视图。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于差异的相似度函数（DSF），该函数将每个增强视图视为一个分布，并通过分布之间的差异来衡量相似度。&lt;h4&gt;主要发现&lt;/h4&gt;DSF在包括kNN分类和线性评估在内的各种任务中一致地提高了性能，并且与其它多视图方法相比，DSF提供了更高的效率。此外，DSF与余弦相似度建立了理论联系，并且与余弦相似度不同，DSF在不需要温度超参数的情况下也能有效工作。&lt;h4&gt;结论&lt;/h4&gt;DSF是一种有效的方法，可以提高多视图学习任务中的性能，并具有更高的效率和无需温度超参数的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent success in contrastive learning has sparked growing interest in moreeffectively leveraging multiple augmented views of an instance. While priormethods incorporate multiple views at the loss or feature level, they primarilycapture pairwise relationships and fail to model the joint structure across allviews. In this work, we propose a divergence-based similarity function (DSF)that explicitly captures the joint structure by representing each set ofaugmented views as a distribution and measuring similarity as the divergencebetween distributions. Extensive experiments demonstrate that DSF consistentlyimproves performance across various tasks, including kNN classification andlinear evaluation, while also offering greater efficiency compared to othermulti-view methods. Furthermore, we establish a theoretical connection betweenDSF and cosine similarity, and show that, unlike cosine similarity, DSFoperates effectively without requiring a temperature hyperparameter.</description>
      <author>example@mail.com (Jae Hyoung Jeon, Cheolsu Lim, Myungjoo Kang)</author>
      <guid isPermaLink="false">2507.06560v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>IMPACT: Industrial Machine Perception via Acoustic Cognitive Transformer</title>
      <link>http://arxiv.org/abs/2507.06481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DINOS的大规模开放数据集和一种名为IMPACT的新型基础模型，用于工业机器声学信号分析，以解决现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;工业机器的声学信号在异常检测、预测性维护和运营效率提升方面具有价值，但现有的方法在可扩展性和泛化能力上存在不足。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，开发一个适用于工业声学信号分析的大规模数据集和基础模型。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含74,149个音频样本的大规模开放数据集DINOS，并提出了一个名为IMPACT的自监督预训练模型，该模型在DINOS上进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;IMPACT模型在30个不同的下游任务中表现出色，超过24个任务的表现优于现有模型，证明了其有效性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;DINOS和IMPACT为工业声学信号分析提供了一个新的基准，并推动了社区研究和基准测试的发展。&lt;h4&gt;翻译&lt;/h4&gt;Acoustic signals from industrial machines offer valuable insights for anomaly detection, predictive maintenance, and operational efficiency enhancement. However, existing task-specific, supervised learning methods often scale poorly and fail to generalize across diverse industrial scenarios, whose acoustic characteristics are distinct from general audio. Furthermore, the scarcity of accessible, large-scale datasets and pretrained models tailored for industrial audio impedes community-driven research and benchmarking. To address these challenges, we introduce DINOS (Diverse INdustrial Operation Sounds), a large-scale open-access dataset. DINOS comprises over 74,149 audio samples (exceeding 1,093 hours) collected from various industrial acoustic scenarios. We also present IMPACT (Industrial Machine Perception via Acoustic Cognitive Transformer), a novel foundation model for industrial machine sound analysis. IMPACT is pretrained on DINOS in a self-supervised manner. By jointly optimizing utterance and frame-level losses, it captures both global semantics and fine-grained temporal structures. This makes its representations suitable for efficient fine-tuning on various industrial downstream tasks with minimal labeled data. Comprehensive benchmarking across 30 distinct downstream tasks (spanning four machine types) demonstrates that IMPACT outperforms existing models on 24 tasks, establishing its superior effectiveness and robustness, while providing a new performance benchmark for future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Acoustic signals from industrial machines offer valuable insights for anomalydetection, predictive maintenance, and operational efficiency enhancement.However, existing task-specific, supervised learning methods often scale poorlyand fail to generalize across diverse industrial scenarios, whose acousticcharacteristics are distinct from general audio. Furthermore, the scarcity ofaccessible, large-scale datasets and pretrained models tailored for industrialaudio impedes community-driven research and benchmarking. To address thesechallenges, we introduce DINOS (Diverse INdustrial Operation Sounds), alarge-scale open-access dataset. DINOS comprises over 74,149 audio samples(exceeding 1,093 hours) collected from various industrial acoustic scenarios.We also present IMPACT (Industrial Machine Perception via Acoustic CognitiveTransformer), a novel foundation model for industrial machine sound analysis.IMPACT is pretrained on DINOS in a self-supervised manner. By jointlyoptimizing utterance and frame-level losses, it captures both global semanticsand fine-grained temporal structures. This makes its representations suitablefor efficient fine-tuning on various industrial downstream tasks with minimallabeled data. Comprehensive benchmarking across 30 distinct downstream tasks(spanning four machine types) demonstrates that IMPACT outperforms existingmodels on 24 tasks, establishing its superior effectiveness and robustness,while providing a new performance benchmark for future research.</description>
      <author>example@mail.com (Changheon Han, Yuseop Sim, Hoin Jung, Jiho Lee, Hojun Lee, Yun Seok Kang, Sucheol Woo, Garam Kim, Hyung Wook Park, Martin Byung-Guk Jun)</author>
      <guid isPermaLink="false">2507.06481v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation</title>
      <link>http://arxiv.org/abs/2507.06613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 8 figures and 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的生成模型框架，通过利用不同的β值来学习多个对应的潜在表示，以平衡解耦和重建质量，同时提高生成质量。&lt;h4&gt;背景&lt;/h4&gt;解耦和可解释的潜在表示在生成模型中通常以生成质量为代价。&lt;h4&gt;目的&lt;/h4&gt;解决解耦和重建质量之间的权衡问题，提高生成质量。&lt;h4&gt;方法&lt;/h4&gt;1. 使用新的损失函数训练单个变分自动编码器（VAE），控制每个潜在表示中保留的信息量，使得高β值优先考虑解耦而不是重建保真度。2. 引入非线性扩散模型，平滑地转换不同β值对应的潜在表示，最终得到几乎无损的表示，实现清晰的重构。3. 模型支持无输入图像的样本生成，作为一个独立的生成模型。&lt;h4&gt;主要发现&lt;/h4&gt;1. 通过不同的β值学习多个潜在表示，可以在解耦和重建质量之间取得平衡。2. 非线性扩散模型可以平滑地转换潜在表示，提高生成质量。3. 模型支持无输入图像的样本生成，且在潜在空间中β值的变化导致平滑过渡，便于一致地操作生成输出。&lt;h4&gt;结论&lt;/h4&gt;该框架在解耦和生成质量方面进行了评估，并观察到潜在空间中β值变化的平滑过渡，有助于一致地操作生成输出。&lt;h4&gt;翻译&lt;/h4&gt;在生成模型中，解耦和可解释的潜在表示通常以生成质量为代价。$eta$-VAE框架通过引入超参数$eta$来平衡解耦和重建质量，其中设置$eta &gt; 1$引入了一个信息瓶颈，优先考虑解耦而不是精确的重构。为了解决这一权衡问题，我们提出了一种新的生成模型框架，利用一系列$eta$值来学习多个相应的潜在表示。首先，通过训练单个变分自动编码器（VAE）并使用新的损失函数来控制每个潜在表示中保留的信息量，从而使得高$eta$值优先考虑解耦而不是重建保真度。然后，引入一个非线性扩散模型，平滑地转换对应不同$eta$值的潜在表示。该模型向更少解耦和更多信息的表示进行去噪，最终导致（几乎）无损的表示，从而实现清晰的重构。此外，我们的模型支持无输入图像的样本生成，作为一个独立的生成模型。我们在解耦和生成质量方面评估了我们的框架，并观察到潜在空间中与$eta$值变化相关的平滑过渡，便于一致地操作生成输出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Disentangled and interpretable latent representations in generative modelstypically come at the cost of generation quality. The $\beta$-VAE frameworkintroduces a hyperparameter $\beta$ to balance disentanglement andreconstruction quality, where setting $\beta &gt; 1$ introduces an informationbottleneck that favors disentanglement over sharp, accurate reconstructions. Toaddress this trade-off, we propose a novel generative modeling framework thatleverages a range of $\beta$ values to learn multiple corresponding latentrepresentations. First, we obtain a slew of representations by training asingle variational autoencoder (VAE), with a new loss function that controlsthe information retained in each latent representation such that the higher$\beta$ value prioritize disentanglement over reconstruction fidelity. We then,introduce a non-linear diffusion model that smoothly transitions latentrepresentations corresponding to different $\beta$ values. This model denoisestowards less disentangled and more informative representations, ultimatelyleading to (almost) lossless representations, enabling sharp reconstructions.Furthermore, our model supports sample generation without input images,functioning as a standalone generative model. We evaluate our framework interms of both disentanglement and generation quality. Additionally, we observesmooth transitions in the latent spaces with respect to changes in $\beta$,facilitating consistent manipulation of generated outputs.</description>
      <author>example@mail.com (Anshuk Uppal, Yuhta Takida, Chieh-Hsin Lai, Yuki Mitsufuji)</author>
      <guid isPermaLink="false">2507.06613v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models</title>
      <link>http://arxiv.org/abs/2507.06466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  67 pages, accepted to RLC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Foundation-Model Self-Play (FMSP)算法，旨在通过利用基础模型的能力来克服传统自我博弈算法的局限性，如解决方案的多样性和陷入局部最优的问题。&lt;h4&gt;背景&lt;/h4&gt;多智能体交互在自然界和人类社会中都促进了创新，而自我博弈算法试图通过智能体对抗不断提高的对手来利用这种动态。然而，这些算法通常无法产生多样化的解决方案，并且可能陷入局部最优的行为。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种新的方法，通过利用基础模型（FMs）的代码生成能力和广泛知识，跨越策略空间中的局部最优，以解决自我博弈算法的上述问题。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一系列方法：(1) Vanilla Foundation-Model Self-Play (vFMSP) 通过竞争性自我博弈不断改进智能体策略；(2) Novelty-Search Self-Play (NSSP) 构建多样化的策略群体，忽略性能；(3) 最有前景的变体，Quality-Diversity Self-Play (QDSP)，通过结合NSSP的多样性和vFMSP的细化来创建高质量策略的多样化集合。&lt;h4&gt;主要发现&lt;/h4&gt;在Car Tag（一个连续控制追逐-逃避设置）和Gandalf（一个简单的AI安全模拟，其中攻击者试图绕过LLM的防御）中评估了FMSP。FMSP探索了广泛的强化学习、树搜索和启发式方法。在策略质量方面，算法和vFMSP超过了强大的人造策略。在Gandalf中，FMSP可以成功地自动进行红队测试，突破并破解了六种不同、逐步增强的防御级别。此外，FMSP可以自动修补发现的漏洞。&lt;h4&gt;结论&lt;/h4&gt;FMSP代表了自我博弈与基础模型结合的新的研究前沿，为更创造性和开放式策略发现开辟了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-agent interactions have long fueled innovation, from naturalpredator-prey dynamics to the space race. Self-play (SP) algorithms try toharness these dynamics by pitting agents against ever-improving opponents,thereby creating an implicit curriculum toward learning high-quality solutions.However, SP often fails to produce diverse solutions and can get stuck inlocally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), anew direction that leverages the code-generation capabilities and vastknowledge of foundation models (FMs) to overcome these challenges by leapingacross local optima in policy space. We propose a family of approaches: (1)\textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agentpolicies via competitive self-play; (2) \textbf{Novelty-Search Self-Play(NSSP)} builds a diverse population of strategies, ignoring performance; and(3) the most promising variant, \textbf{Quality-Diveristy Self-Play (QDSP)},creates a diverse set of high-quality policies by combining the diversity ofNSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, acontinuous-control pursuer-evader setting, and in Gandalf, a simple AI safetysimulation in which an attacker tries to jailbreak an LLM's defenses. In CarTag, FMSPs explore a wide variety of reinforcement learning, tree search, andheuristic-based methods, to name just a few. In terms of discovered policyquality, \ouralgo and vFMSP surpass strong human-designed strategies. InGandalf, FMSPs can successfully automatically red-team an LLM, breaking throughand jailbreaking six different, progressively stronger levels of defense.Furthermore, FMSPs can automatically proceed to patch the discoveredvulnerabilities. Overall, FMSPs represent a promising new research frontier ofimproving self-play with foundation models, opening fresh paths toward morecreative and open-ended strategy discovery</description>
      <author>example@mail.com (Aaron Dharna, Cong Lu, Jeff Clune)</author>
      <guid isPermaLink="false">2507.06466v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>PAST: A multimodal single-cell foundation model for histopathology and spatial transcriptomics in cancer</title>
      <link>http://arxiv.org/abs/2507.06418v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PAST的跨癌症单细胞基础模型，该模型通过联合编码细胞形态和基因表达，学习到统一的跨模态表示，能够捕捉到细胞层面的空间和分子异质性。PAST模型能够从常规病理切片中准确预测单细胞基因表达、虚拟分子染色和多模态生存分析，表现出良好的泛化性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;病理基础模型在癌症图像分析中发挥了重要作用，但通常缺乏与单细胞分辨率的分子数据的整合，限制了其在精准肿瘤学中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够整合病理图像和分子数据的跨癌症单细胞基础模型，以提升癌症图像分析的准确性和实用性。&lt;h4&gt;方法&lt;/h4&gt;PAST模型在20百万对配对组织病理学图像和跨越多种肿瘤类型和组织环境的单细胞转录组数据上进行了训练。&lt;h4&gt;主要发现&lt;/h4&gt;PAST模型能够学习到细胞层面的空间和分子异质性，并实现从常规病理切片中预测单细胞基因表达、虚拟分子染色和多模态生存分析。&lt;h4&gt;结论&lt;/h4&gt;PAST模型为病理基础模型提供了一个新的范式，为高分辨率空间组学、机制发现和精准癌症研究提供了一种通用的工具。&lt;h4&gt;翻译&lt;/h4&gt;While pathology foundation models have transformed cancer image analysis, they often lack integration with molecular data at single-cell resolution, limiting their utility for precision oncology. Here, we present PAST, a pan-cancer single-cell foundation model trained on 20 million paired histopathology images and single-cell transcriptomes spanning multiple tumor types and tissue contexts. By jointly encoding cellular morphology and gene expression, PAST learns unified cross-modal representations that capture both spatial and molecular heterogeneity at the cellular level. This approach enables accurate prediction of single-cell gene expression, virtual molecular staining, and multimodal survival analysis directly from routine pathology slides. Across diverse cancers and downstream tasks, PAST consistently exceeds the performance of existing approaches, demonstrating robust generalizability and scalability. Our work establishes a new paradigm for pathology foundation models, providing a versatile tool for high-resolution spatial omics, mechanistic discovery, and precision cancer research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While pathology foundation models have transformed cancer image analysis,they often lack integration with molecular data at single-cell resolution,limiting their utility for precision oncology. Here, we present PAST, apan-cancer single-cell foundation model trained on 20 million pairedhistopathology images and single-cell transcriptomes spanning multiple tumortypes and tissue contexts. By jointly encoding cellular morphology and geneexpression, PAST learns unified cross-modal representations that capture bothspatial and molecular heterogeneity at the cellular level. This approachenables accurate prediction of single-cell gene expression, virtual molecularstaining, and multimodal survival analysis directly from routine pathologyslides. Across diverse cancers and downstream tasks, PAST consistently exceedsthe performance of existing approaches, demonstrating robust generalizabilityand scalability. Our work establishes a new paradigm for pathology foundationmodels, providing a versatile tool for high-resolution spatial omics,mechanistic discovery, and precision cancer research.</description>
      <author>example@mail.com (Changchun Yang, Haoyang Li, Yushuai Wu, Yilan Zhang, Yifeng Jiao, Yu Zhang, Rihan Huang, Yuan Cheng, Yuan Qi, Xin Guo, Xin Gao)</author>
      <guid isPermaLink="false">2507.06418v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Voltage Regulation in Distribution Systems with Data Center Loads</title>
      <link>http://arxiv.org/abs/2507.06416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code available at  https://github.com/chennnnnyize/voltage-regulation-with-data-centers&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了大型数据中心因波动性及强度变化导致的电压问题，并提出了一个利用数据中心负载调节能力的动态电压控制方案。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型和AI计算的兴起，大型数据中心的能耗和电力需求引起了广泛关注，同时电网中电压干扰现象也变得更加频繁。&lt;h4&gt;目的&lt;/h4&gt;解决数据中心集成过程中因电力需求波动导致的电压问题。&lt;h4&gt;方法&lt;/h4&gt;通过动态电压和频率缩放（DVFS）方案，在每个数据中心母线上进行本地电压测量和功率注入调整，以分布式方式维持高数据中心计算负载下的安全电压。&lt;h4&gt;主要发现&lt;/h4&gt;使用真实大型语言模型（LLM）推理负载进行的仿真验证了所提机制的有效性。&lt;h4&gt;结论&lt;/h4&gt;LLM的电力数据和提出的控制方案均已开源。&lt;h4&gt;翻译&lt;/h4&gt;Recent boom in foundation models and AI computing have raised growing concerns on the power and energy trajectories of large-scale data centers. This paper focuses on the voltage issues caused by volatile and intensity of datacenter power demand, which also aligns with recent observations of more frequent voltage disturbances in power grids. To address these data center integration challenges, we propose a dynamic voltage control scheme by harnessing data center's load regulation capabilities. By taking local voltage measurements and adjusting power injections at each data center buses through the dynamic voltage and frequency scaling (DVFS) scheme, we are able to maintain safe voltage magnitude in a distributed fashion with higher datacenter computing load. Simulations using real large language model (LLM) inference load validate the effectiveness of our proposed mechanism. Both the LLM power data and proposed control scheme are open sourced.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent boom in foundation models and AI computing have raised growingconcerns on the power and energy trajectories of large-scale data centers. Thispaper focuses on the voltage issues caused by volatile and intensity of datacenter power demand, which also aligns with recent observations of morefrequent voltage disturbances in power grids. To address these data centerintegration challenges, we propose a dynamic voltage control scheme byharnessing data center's load regulation capabilities. By taking local voltagemeasurements and adjusting power injections at each data center buses throughthe dynamic voltage and frequency scaling (DVFS) scheme, we are able tomaintain safe voltage magnitude in a distributed fashion with higher datacenter computing load. Simulations using real large language model (LLM)inference load validate the effectiveness of our proposed mechanism. Both theLLM power data and proposed control scheme are open sourced.</description>
      <author>example@mail.com (Yize Chen, Baosen Zhang)</author>
      <guid isPermaLink="false">2507.06416v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits</title>
      <link>http://arxiv.org/abs/2507.06535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCAD2025. This is the initial version. Minor changes  will be made&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为CircuitGCL的新型图对比学习框架，用于模拟混合信号(AMS)电路的表示学习，旨在解决设计数据稀缺、标签分布不均衡和电路实现多样性等问题，以提高电路表示的鲁棒性和迁移性。&lt;h4&gt;背景&lt;/h4&gt;在模拟混合信号(AMS)电路中，图表示学习对于各种下游任务（如寄生估计）至关重要，但由于设计数据稀缺、标签分布不均衡和电路实现的多样性，学习鲁棒且可迁移的电路表示存在挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出了CircuitGCL框架，旨在增强跨异构电路图的可迁移性。&lt;h4&gt;方法&lt;/h4&gt;CircuitGCL通过结合表示散射和标签重平衡，利用自监督策略学习拓扑不变的节点嵌入。同时，引入了平衡均方误差（MSE）和softmax交叉熵（bsmCE）损失，以缓解电路之间的标签分布差异。&lt;h4&gt;主要发现&lt;/h4&gt;在TSMC 28nm AMS设计中，CircuitGCL在寄生电容估计（边缘级任务）和接地电容分类（节点级任务）方面优于所有现有方法，边缘回归的$R^2$值提高了33.64%至44.20%，节点分类的F1分数提高了0.9倍至2.1倍。&lt;h4&gt;结论&lt;/h4&gt;CircuitGCL框架有效地解决了AMS电路表示学习中的挑战，显著提高了寄生估计的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Graph representation learning on Analog-Mixed Signal (AMS) circuits is crucial for various downstream tasks, e.g., parasitic estimation. However, the scarcity of design data, the unbalanced distribution of labels, and the inherent diversity of circuit implementations pose significant challenges to learning robust and transferable circuit representations. To address these limitations, we propose CircuitGCL, a novel graph contrastive learning framework that integrates representation scattering and label rebalancing to enhance transferability across heterogeneous circuit graphs. CircuitGCL employs a self-supervised strategy to learn topology-invariant node embeddings through hyperspherical representation scattering, eliminating dependency on large-scale data. Simultaneously, balanced mean squared error (MSE) and softmax cross-entropy (bsmCE) losses are introduced to mitigate label distribution disparities between circuits, enabling robust and transferable parasitic estimation. Evaluated on parasitic capacitance estimation (edge-level task) and ground capacitance classification (node-level task) across TSMC 28nm AMS designs, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the $R^2$ improvement of 33.64% ~ 44.20% for edge regression and F1-score gain of 0.9x ~ 2.1x for node classification. Our code is available at here.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning on Analog-Mixed Signal (AMS) circuits iscrucial for various downstream tasks, e.g., parasitic estimation. However, thescarcity of design data, the unbalanced distribution of labels, and theinherent diversity of circuit implementations pose significant challenges tolearning robust and transferable circuit representations. To address theselimitations, we propose CircuitGCL, a novel graph contrastive learningframework that integrates representation scattering and label rebalancing toenhance transferability across heterogeneous circuit graphs. CircuitGCL employsa self-supervised strategy to learn topology-invariant node embeddings throughhyperspherical representation scattering, eliminating dependency on large-scaledata. Simultaneously, balanced mean squared error (MSE) and softmaxcross-entropy (bsmCE) losses are introduced to mitigate label distributiondisparities between circuits, enabling robust and transferable parasiticestimation. Evaluated on parasitic capacitance estimation (edge-level task) andground capacitance classification (node-level task) across TSMC 28nm AMSdesigns, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the$R^2$ improvement of $33.64\% \sim 44.20\%$ for edge regression and F1-scoregain of $0.9\times \sim 2.1\times$ for node classification. Our code isavailable at\href{https://anonymous.4open.science/r/CircuitGCL-099B/README.md}{here}.</description>
      <author>example@mail.com (Shan Shen, Shenglu Hua, Jiajun Zou, Jiawei Liu, Jianwang Zhai, Chuan Shi, Wenjian Yu)</author>
      <guid isPermaLink="false">2507.06535v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings</title>
      <link>http://arxiv.org/abs/2507.06506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了一种将英语双关语翻译成法语的新方法，结合了先进的语言模型和专门的双关语生成技术。&lt;h4&gt;背景&lt;/h4&gt;翻译双关语对人工翻译和机器翻译系统都是一个独特的挑战，长期以来一直困扰着两者。&lt;h4&gt;目的&lt;/h4&gt;该研究的主要目的是捕捉源文本双关语的言语创造性和幽默感，而不仅仅是复制其词汇。&lt;h4&gt;方法&lt;/h4&gt;采用三阶段方法：首先，使用多个前沿的大型语言模型建立基准；其次，实施一个带有语音-语义嵌入的引导思维链流程；最后，实现一个多智能体生成-判别框架来评估和再生双关语。&lt;h4&gt;主要发现&lt;/h4&gt;研究在CLEF JOKER 2025任务2竞赛中获得第一和第二名，该竞赛由专家母语法语人士手动评估。&lt;h4&gt;结论&lt;/h4&gt;通过实施语言信息化的双关语翻译技术，本文填补了翻译研究和计算语言学之间的差距，推进了我们对语言模型如何处理语义歧义、语音相似性和成功幽默所需的隐含文化和语言意识之间复杂互动的理解。&lt;h4&gt;翻译&lt;/h4&gt;提出了一种将英语双关语翻译成法语的新方法，结合了先进的大型语言模型和专门的双关语生成技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Translating wordplay across languages presents unique challenges that havelong confounded both professional human translators and machine translationsystems. This research proposes a novel approach for translating puns fromEnglish to French by combining state-of-the-art large language models withspecialized techniques for wordplay generation.  Our methodology employs a three-stage approach. First, we establish abaseline using multiple frontier large language models with feedback based on anew contrastive learning dataset. Second, we implement a guidedchain-of-thought pipeline with combined phonetic-semantic embeddings. Third, weimplement a multi-agent generator-discriminator framework for evaluating andregenerating puns with feedback.  Moving beyond the limitations of literal translation, our methodology'sprimary objective is to capture the linguistic creativity and humor of thesource text wordplay, rather than simply duplicating its vocabulary. Our bestruns earned first and second place in the CLEF JOKER 2025 Task 2 competitionwhere they were evaluated manually by expert native French speakers.  This research addresses a gap between translation studies and computationallinguistics by implementing linguistically-informed techniques for wordplaytranslation, advancing our understanding of how language models can beleveraged to handle the complex interplay between semantic ambiguity, phoneticsimilarity, and the implicit cultural and linguistic awareness needed forsuccessful humor.</description>
      <author>example@mail.com (Russell Taylor, Benjamin Herbert, Michael Sana)</author>
      <guid isPermaLink="false">2507.06506v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Few-shot Learning on AMS Circuits and Its Application to Parasitic Capacitance Prediction</title>
      <link>http://arxiv.org/abs/2507.06538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Proceedings of DAC2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CircuitGPS的少样本学习方法，用于预测模拟/混合信号（AMS）电路中的寄生效应。&lt;h4&gt;背景&lt;/h4&gt;Graph representation learning是一种从图结构数据中提取特征的有效方法，但训练深度学习模型用于AMS设计受到集成电路设计数据稀缺的限制。&lt;h4&gt;目的&lt;/h4&gt;旨在提高AMS电路中寄生效应预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;CircuitGPS将电路网表表示为异构图，将耦合电容建模为链接。该方法在链接预测上预训练，并在边回归上进行微调。使用小跳采样技术将链接或节点转换为子图，然后使用混合图Transformer学习子图嵌入。此外，CircuitGPS集成了一种低成本的定位编码，总结了采样子图的定位和结构信息。&lt;h4&gt;主要发现&lt;/h4&gt;CircuitGPS提高了耦合存在性的准确性至少20%，与现有方法相比，减少了电容估计的MAE至少0.067。该方法显示出强大的内在可扩展性，通过零样本学习可以直接应用于不同的AMS电路设计。&lt;h4&gt;结论&lt;/h4&gt;CircuitGPS是一种有效的少样本学习方法，可以提高AMS电路中寄生效应预测的准确性，并且具有良好的可扩展性和适用性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为CircuitGPS的少样本学习方法，用于预测模拟/混合信号（AMS）电路中的寄生效应。然而，由于集成电路设计数据的稀缺，训练深度学习模型用于AMS设计受到限制。本研究提出的方法CircuitGPS，将电路网表表示为异构图，并将耦合电容建模为链接。该方法在链接预测上进行预训练，并在边回归上进行微调。通过小跳采样技术将链接或节点转换为子图，并使用混合图Transformer学习子图嵌入。此外，CircuitGPS集成了一种低成本的定位编码，总结了采样子图的定位和结构信息。与现有方法相比，CircuitGPS提高了耦合存在性的准确性至少20%，并减少了电容估计的MAE至少0.067。该方法显示出强大的内在可扩展性，通过零样本学习可以直接应用于不同的AMS电路设计。此外，消融研究为图模型在表示学习中的应用提供了有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning is a powerful method to extract features fromgraph-structured data, such as analog/mixed-signal (AMS) circuits. However,training deep learning models for AMS designs is severely limited by thescarcity of integrated circuit design data. In this work, we presentCircuitGPS, a few-shot learning method for parasitic effect prediction in AMScircuits. The circuit netlist is represented as a heterogeneous graph, with thecoupling capacitance modeled as a link. CircuitGPS is pre-trained on linkprediction and fine-tuned on edge regression. The proposed method starts with asmall-hop sampling technique that converts a link or a node into a subgraph.Then, the subgraph embeddings are learned with a hybrid graph Transformer.Additionally, CircuitGPS integrates a low-cost positional encoding thatsummarizes the positional and structural information of the sampled subgraph.CircuitGPS improves the accuracy of coupling existence by at least 20\% andreduces the MAE of capacitance estimation by at least 0.067 compared toexisting methods. Our method demonstrates strong inherent scalability, enablingdirect application to diverse AMS circuit designs through zero-shot learning.Furthermore, the ablation studies provide valuable insights into graph modelsfor representation learning.</description>
      <author>example@mail.com (Shan Shen, Yibin Zhang, Hector Rodriguez Rodriguez, Wenjian Yu)</author>
      <guid isPermaLink="false">2507.06538v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>A Wireless Foundation Model for Multi-Task Prediction</title>
      <link>http://arxiv.org/abs/2507.05938v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于无线网络多任务预测的统一基础模型，该模型能够支持不同的预测区间，并在大规模数据集上展现出良好的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;随着移动通信网络的复杂性和动态性增加，准确预测关键系统参数（如信道状态信息、用户位置和网络流量）对于物理层和介质访问控制层的多种任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;针对传统深度学习方法在泛化能力上的不足，本文旨在提出一种能够支持多样预测区间的多任务预测模型。&lt;h4&gt;方法&lt;/h4&gt;该模型通过以下方式进行改进：1. 对异构任务进行单变量分解以统一任务；2. 编码粒度以实现区间感知；3. 使用因果Transformer主干结构进行精确预测；4. 在训练过程中引入补丁掩码策略以支持任意输入长度。&lt;h4&gt;主要发现&lt;/h4&gt;经过大规模数据集训练后，该基础模型在未见过的场景中表现出强大的泛化能力，并在新任务上实现了零样本性能，超越了传统的全样本基线。&lt;h4&gt;结论&lt;/h4&gt;本文提出的统一基础模型为无线网络中的多任务预测提供了一种有效的方法，有助于提高预测的准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing complexity and dynamics of the mobile communicationnetworks, accurately predicting key system parameters, such as channel stateinformation (CSI), user location, and network traffic, has become essential fora wide range of physical (PHY)-layer and medium access control (MAC)-layertasks. Although traditional deep learning (DL)-based methods have been widelyapplied to such prediction tasks, they often struggle to generalize acrossdifferent scenarios and tasks. In response, we propose a unified foundationmodel for multi-task prediction in wireless networks that supports diverseprediction intervals. The proposed model enforces univariate decomposition tounify heterogeneous tasks, encodes granularity for interval awareness, and usesa causal Transformer backbone for accurate predictions. Additionally, weintroduce a patch masking strategy during training to support arbitrary inputlengths. After trained on large-scale datasets, the proposed foundation modeldemonstrates strong generalization to unseen scenarios and achieves zero-shotperformance on new tasks that surpass traditional full-shot baselines.</description>
      <author>example@mail.com (Yucheng Sheng, Jiacheng Wang, Xingyu Zhou, Le Liang, Hao Ye, Shi Jin, Geoffrey Ye Li)</author>
      <guid isPermaLink="false">2507.05938v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Mapping the Catacombs: An Underwater Cave Segment of the Devil's Eye System</title>
      <link>http://arxiv.org/abs/2507.06397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 2025 IEEE ICRA Workshop on Field Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种水下洞穴映射框架，用于淡水资源管理、水下考古和水文地质研究。&lt;h4&gt;背景&lt;/h4&gt;水下洞穴对于淡水资源管理、水下考古和水文地质研究至关重要。&lt;h4&gt;目的&lt;/h4&gt;旨在通过映射洞穴的轮廓和尺寸，以及创建逼真的3D地图，以更好地理解水下领域。&lt;h4&gt;方法&lt;/h4&gt;利用低成本动作相机和潜水电脑来估计相机轨迹和稀疏点云，生成洞穴通道的一维折叠图，并使用SVIn2框架观察z维度。使用COLMAP框架进行全局优化以生成密集重建。&lt;h4&gt;主要发现&lt;/h4&gt;使用动作相机可以构建洞穴地图的主要部分，通过SVIn2和COLMAP的结合，可以重建逼真的密集3D表示。&lt;h4&gt;结论&lt;/h4&gt;该研究验证了使用动作相机和SVIn2结合COLMAP进行水下洞穴映射的有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种水下洞穴映射框架。水下洞穴对于淡水资源管理、水下考古和水文地质研究至关重要。通过使用低成本动作相机和潜水电脑来估计相机轨迹和稀疏点云，生成洞穴通道的一维折叠图，并使用SVIn2框架观察z维度。同时，使用COLMAP框架进行全局优化以生成密集重建。研究发现，使用动作相机可以构建洞穴地图的主要部分，并且通过SVIn2和COLMAP的结合，可以重建逼真的密集3D表示。该研究验证了使用动作相机和SVIn2结合COLMAP进行水下洞穴映射的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a framework for mapping underwater caves. Underwatercaves are crucial for fresh water resource management, underwater archaeology,and hydrogeology. Mapping the cave's outline and dimensions, as well ascreating photorealistic 3D maps, is critical for enabling a betterunderstanding of this underwater domain. In this paper, we present the mappingof an underwater cave segment (the catacombs) of the Devil's Eye cave system atGinnie Springs, FL. We utilized a set of inexpensive action cameras inconjunction with a dive computer to estimate the trajectories of the camerastogether with a sparse point cloud. The resulting reconstructions are utilizedto produce a one-dimensional retract of the cave passages in the form of theaverage trajectory together with the boundaries (top, bottom, left, and right).The use of the dive computer enables the observability of the z-dimension inaddition to the roll and pitch in a visual/inertial framework (SVIn2). Inaddition, the keyframes generated by SVIn2 together with the estimated cameraposes for select areas are used as input to a global optimization (bundleadjustment) framework -- COLMAP -- in order to produce a dense reconstructionof those areas. The same cave segment is manually surveyed using the MNemo V2instrument, providing an additional set of measurements validating the proposedapproach. It is worth noting that with the use of action cameras, the primarycomponents of a cave map can be constructed. Furthermore, with the utilizationof a global optimization framework guided by the results of VI-SLAM packageSVIn2, photorealistic dense 3D representations of selected areas can bereconstructed.</description>
      <author>example@mail.com (Michalis Chatzispyrou, Luke Horgan, Hyunkil Hwang, Harish Sathishchandra, Monika Roznere, Alberto Quattrini Li, Philippos Mordohai, Ioannis Rekleitis)</author>
      <guid isPermaLink="false">2507.06397v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models</title>
      <link>http://arxiv.org/abs/2507.03916v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Appendix at:  https://github.com/PAMPAS-Lab/ANA-PPT-Anamation/blob/main/Appendix.pdf&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉语言模型（VLM）的幻灯片动画生成方法，通过发布首个公共数据集，并使用低秩自适应（LoRA）技术，提高了动画生成的质量。&lt;h4&gt;背景&lt;/h4&gt;现有的AI幻灯片生成工具缺乏动画支持，而现有的视觉语言模型在动画任务上存在困难，主要原因是缺乏公共数据集和有限的时序推理能力。&lt;h4&gt;目的&lt;/h4&gt;解决现有幻灯片动画生成工具的不足，提高动画生成的质量和效果。&lt;h4&gt;方法&lt;/h4&gt;发布首个公共数据集，包含12,000个自然语言描述、动画JSON文件和渲染视频，覆盖所有内置的PowerPoint效果。使用LoRA技术对Qwen-2.5-VL-7B进行微调，并在BLEU-4、ROUGE-L、SPICE和CODA指标上取得显著改进。&lt;h4&gt;主要发现&lt;/h4&gt;LoRA模型在BLEU-4、ROUGE-L和CODA-detail上分别提高了约60%、30%和显著改进，表明低秩自适应技术能够实现可靠的时序推理和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的公共数据集、LoRA增强模型和CODA指标为基于VLM的动态幻灯片生成提供了严格的标准和基础。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于视觉语言模型（VLM）的幻灯片动画生成方法，通过发布首个公共数据集，并使用低秩自适应（LoRA）技术，提高了动画生成的质量。现有的AI幻灯片生成工具缺乏动画支持，而现有的视觉语言模型在动画任务上存在困难，主要原因是缺乏公共数据集和有限的时序推理能力。解决现有幻灯片动画生成工具的不足，提高动画生成的质量和效果。发布首个公共数据集，包含12,000个自然语言描述、动画JSON文件和渲染视频，覆盖所有内置的PowerPoint效果。使用LoRA技术对Qwen-2.5-VL-7B进行微调，并在BLEU-4、ROUGE-L、SPICE和CODA指标上取得显著改进。LoRA模型在BLEU-4、ROUGE-L和CODA-detail上分别提高了约60%、30%和显著改进，表明低秩自适应技术能够实现可靠的时序推理和泛化能力。该研究提出的公共数据集、LoRA增强模型和CODA指标为基于VLM的动态幻灯片生成提供了严格的标准和基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Slide animations, such as fade-in, fly-in, and wipe, are critical foraudience engagement, efficient information delivery, and vivid visualexpression. However, most AI-driven slide-generation tools still lack nativeanimation support, and existing vision-language models (VLMs) struggle withanimation tasks due to the absence of public datasets and limitedtemporal-reasoning capabilities. To address this gap, we release the firstpublic dataset for slide-animation modeling: 12,000 triplets ofnatural-language descriptions, animation JSON files, and rendered videos,collectively covering every built-in PowerPoint effect. Using this resource, wefine-tune Qwen-2.5-VL-7B with Low-Rank Adaptation (LoRA) and achieve consistentimprovements over GPT-4.1 and Gemini-2.5-Pro in BLEU-4, ROUGE-L, SPICE, and ourCoverage-Order-Detail Assessment (CODA) metric, which evaluates actioncoverage, temporal order, and detail fidelity. On a manually created test setof slides, the LoRA model increases BLEU-4 by around 60%, ROUGE-L by 30%, andshows significant improvements in CODA-detail. This demonstrates that low-rankadaptation enables reliable temporal reasoning and generalization beyondsynthetic data. Overall, our dataset, LoRA-enhanced model, and CODA metricprovide a rigorous benchmark and foundation for future research on VLM-baseddynamic slide generation.</description>
      <author>example@mail.com (Yifan Jiang, Yibo Xue, Yukun Kang, Pin Zheng, Jian Peng, Feiran Wu, Changliang Xu)</author>
      <guid isPermaLink="false">2507.03916v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>FedDifRC: Unlocking the Potential of Text-to-Image Diffusion Models in Heterogeneous Federated Learning</title>
      <link>http://arxiv.org/abs/2507.06482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 Pages, ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为FedDifRC的新型联邦学习范式，旨在通过扩散模型的有意义指导来减轻数据异构性问题，以提高联邦学习中的模型收敛性和性能。&lt;h4&gt;背景&lt;/h4&gt;联邦学习旨在保护隐私的同时协同训练模型，但数据异构性问题是一个主要挑战，因为多个客户端的数据偏好偏差会损害模型的收敛性和性能。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用扩散表示来处理数据异构性问题，并提出一个基于扩散的联邦学习范式。&lt;h4&gt;方法&lt;/h4&gt;提出了文本驱动的扩散对比学习和噪声驱动的扩散正则化方法，以构建文本驱动的对比学习策略和噪声驱动的一致性正则化，以提供丰富的类相关语义信息和一致的收敛信号。&lt;h4&gt;主要发现&lt;/h4&gt;FedDifRC通过条件反馈和一致性正则化，在联邦学习中有效减轻了数据异构性问题，并且可以扩展为无需任何标记数据的自监督方案。&lt;h4&gt;结论&lt;/h4&gt;实验验证了FedDifRC的有效性和关键组件的效率，并提供了理论分析以确保在非凸目标下收敛。&lt;h4&gt;翻译&lt;/h4&gt;本文旨在解决联邦学习中数据异构性问题，提出了一种名为FedDifRC的新范式，通过扩散模型指导减轻数据异构性，提高模型性能。该方法结合文本驱动的对比学习和噪声驱动的正则化，实现无标记数据的自监督学习，并通过理论分析保证了收敛性。实验验证了其有效性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning aims at training models collaboratively acrossparticipants while protecting privacy. However, one major challenge for thisparadigm is the data heterogeneity issue, where biased data preferences acrossmultiple clients, harming the model's convergence and performance. In thispaper, we first introduce powerful diffusion models into the federated learningparadigm and show that diffusion representations are effective steers duringfederated training. To explore the possibility of using diffusionrepresentations in handling data heterogeneity, we propose a noveldiffusion-inspired Federated paradigm with Diffusion RepresentationCollaboration, termed FedDifRC, leveraging meaningful guidance of diffusionmodels to mitigate data heterogeneity. The key idea is to construct text-drivendiffusion contrasting and noise-driven diffusion regularization, aiming toprovide abundant class-related semantic information and consistent convergencesignals. On the one hand, we exploit the conditional feedback from thediffusion model for different text prompts to build a text-driven contrastivelearning strategy. On the other hand, we introduce a noise-driven consistencyregularization to align local instances with diffusion denoisingrepresentations, constraining the optimization region in the feature space. Inaddition, FedDifRC can be extended to a self-supervised scheme without relyingon any labeled data. We also provide a theoretical analysis for FedDifRC toensure convergence under non-convex objectives. The experiments on differentscenarios validate the effectiveness of FedDifRC and the efficiency of crucialcomponents.</description>
      <author>example@mail.com (Huan Wang, Haoran Li, Huaming Chen, Jun Yan, Jiahua Shi, Jun Shen)</author>
      <guid isPermaLink="false">2507.06482v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>ADPv2: A Hierarchical Histological Tissue Type-Annotated Dataset for Potential Biomarker Discovery of Colorectal Disease</title>
      <link>http://arxiv.org/abs/2507.05656v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CoPath（计算病理学）在提高临床病理诊断的精确性和可重复性方面的应用，并提出了一个新的数据集ADPv2，用于胃肠道病理学的研究。&lt;h4&gt;背景&lt;/h4&gt;目前，标注有详细组织类型（HTT）分类的公开CoPath数据集非常稀缺，因为需要大量的专业知识和高成本。&lt;h4&gt;目的&lt;/h4&gt;提出ADPv2数据集，专注于胃肠道病理学，以提高对特定器官疾病的研究深度。&lt;h4&gt;方法&lt;/h4&gt;构建了包含20,004个图像块的数据集，这些图像块来自健康结肠活检切片，并按照32个不同组织类型的3级层次分类进行标注。使用VMamba架构训练了一个多标签表示学习模型，并在ADPv2数据集上实现了两阶段训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;该数据集能够进行器官特定的深入研究，有助于发现潜在生物标志物。通过分析模型对不同结肠疾病影响的组织预测行为，揭示了统计模式，证实了结肠癌发展的两种病理途径。&lt;h4&gt;结论&lt;/h4&gt;ADPv2数据集为胃肠道病理学研究提供了新的资源，有助于提高结肠HTT的多标签分类性能，并支持对结肠癌发展的深入理解。&lt;h4&gt;翻译&lt;/h4&gt;Computational pathology (CoPath) uses histopathology images to enhance diagnostic precision and reproducibility in clinical pathology. However, publicly available datasets for CoPath that are annotated with extensive histological tissue type (HTT) taxonomies at a granular level remain scarce due to the significant expertise and high annotation costs required. Existing datasets, such as the Atlas of Digital Pathology (ADP), address this by offering diverse HTT annotations generalized to multiple organs, but limit the capability for in-depth studies on specific organ diseases. Building upon this foundation, we introduce ADPv2, a novel dataset focused on gastrointestinal histopathology. Our dataset comprises 20,004 image patches derived from healthy colon biopsy slides, annotated according to a hierarchical taxonomy of 32 distinct HTTs of 3 levels. Furthermore, we train a multilabel representation learning model following a two-stage training procedure on our ADPv2 dataset. We leverage the VMamba architecture and achieving a mean average precision (mAP) of 0.88 in multilabel classification of colon HTTs. Finally, we show that our dataset is capable of an organ-specific in-depth study for potential biomarker discovery by analyzing the model's prediction behavior on tissues affected by different colon diseases, which reveals statistical patterns that confirm the two pathological pathways of colon cancer development. Our dataset is publicly available at https://zenodo.org/records/15307021.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computational pathology (CoPath) leverages histopathology images to enhancediagnostic precision and reproducibility in clinical pathology. However,publicly available datasets for CoPath that are annotated with extensivehistological tissue type (HTT) taxonomies at a granular level remain scarce dueto the significant expertise and high annotation costs required. Existingdatasets, such as the Atlas of Digital Pathology (ADP), address this byoffering diverse HTT annotations generalized to multiple organs, but limit thecapability for in-depth studies on specific organ diseases. Building upon thisfoundation, we introduce ADPv2, a novel dataset focused on gastrointestinalhistopathology. Our dataset comprises 20,004 image patches derived from healthycolon biopsy slides, annotated according to a hierarchical taxonomy of 32distinct HTTs of 3 levels. Furthermore, we train a multilabel representationlearning model following a two-stage training procedure on our ADPv2 dataset.We leverage the VMamba architecture and achieving a mean average precision(mAP) of 0.88 in multilabel classification of colon HTTs. Finally, we show thatour dataset is capable of an organ-specific in-depth study for potentialbiomarker discovery by analyzing the model's prediction behavior on tissuesaffected by different colon diseases, which reveals statistical patterns thatconfirm the two pathological pathways of colon cancer development. Our datasetis publicly available at https://zenodo.org/records/15307021</description>
      <author>example@mail.com (Zhiyuan Yang, Kai Li, Sophia Ghamoshi Ramandi, Patricia Brassard, Hakim Khellaf, Vincent Quoc-Huy Trinh, Jennifer Zhang, Lina Chen, Corwyn Rowsell, Sonal Varma, Kostas Plataniotis, Mahdi S. Hosseini)</author>
      <guid isPermaLink="false">2507.05656v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework</title>
      <link>http://arxiv.org/abs/2507.05814v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于生成3D桥梁数据的系统框架，旨在解决桥梁基础设施老化与退化带来的挑战，以及传统手动检测方法的低效问题。&lt;h4&gt;背景&lt;/h4&gt;桥梁作为关键交通基础设施，面临着老化与退化的挑战，而传统的手动检测方法效率低下。3D点云技术虽然提供了新的数据驱动范式，但其应用潜力常受到现实数据不完整性的限制。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有合成数据方法中泛化不足的瓶颈，本文提出了一个系统框架，用于生成具有组件级实例注释、高保真颜色和精确法向量的完整点云。&lt;h4&gt;方法&lt;/h4&gt;该框架能够自动生成完整的点云，并可以扩展以模拟创建各种多样且物理上真实的不完整点云，以支持分割和完成网络的训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，使用本文合成的数据进行训练的PointNet++模型在现实世界桥梁语义分割中实现了平均交并比（mIoU）为84.2%。同时，经过微调的KT-Net在组件完成任务上表现出色。&lt;h4&gt;结论&lt;/h4&gt;本研究提供了一种创新的方法和基础数据集，用于桥梁结构的3D视觉分析，对基础设施的自动化管理和维护具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;As critical transportation infrastructure, bridges face escalating challenges from aging and deterioration, while traditional manual inspection methods suffer from low efficiency. Although 3D point cloud technology provides a new data-driven paradigm, its application potential is often constrained by the incompleteness of real-world data, which results from missing labels and scanning occlusions. To overcome the bottleneck of insufficient generalization in existing synthetic data methods, this paper proposes a systematic framework for generating 3D bridge data. This framework can automatically generate complete point clouds featuring component-level instance annotations, high-fidelity color, and precise normal vectors. It can be further extended to simulate the creation of diverse and physically realistic incomplete point clouds, designed to support the training of segmentation and completion networks, respectively. Experiments demonstrate that a PointNet++ model trained with our synthetic data achieves a mean Intersection over Union (mIoU) of 84.2% in real-world bridge semantic segmentation. Concurrently, a fine-tuned KT-Net exhibits superior performance on the component completion task. This research offers an innovative methodology and a foundational dataset for the 3D visual analysis of bridge structures, holding significant implications for advancing the automated management and maintenance of infrastructure.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As critical transportation infrastructure, bridges face escalating challengesfrom aging and deterioration, while traditional manual inspection methodssuffer from low efficiency. Although 3D point cloud technology provides a newdata-driven paradigm, its application potential is often constrained by theincompleteness of real-world data, which results from missing labels andscanning occlusions. To overcome the bottleneck of insufficient generalizationin existing synthetic data methods, this paper proposes a systematic frameworkfor generating 3D bridge data.  This framework can automatically generate complete point clouds featuringcomponent-level instance annotations, high-fidelity color, and precise normalvectors. It can be further extended to simulate the creation of diverse andphysically realistic incomplete point clouds, designed to support the trainingof segmentation and completion networks, respectively. Experiments demonstratethat a PointNet++ model trained with our synthetic data achieves a meanIntersection over Union (mIoU) of 84.2% in real-world bridge semanticsegmentation. Concurrently, a fine-tuned KT-Net exhibits superior performanceon the component completion task.  This research offers an innovative methodology and a foundational dataset forthe 3D visual analysis of bridge structures, holding significant implicationsfor advancing the automated management and maintenance of infrastructure.</description>
      <author>example@mail.com (Wang Wang, Mingyu Shi, Jun Jiang, Wenqian Ma, Chong Liu, Yasutaka Narazaki, Xuguang Wang)</author>
      <guid isPermaLink="false">2507.05814v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>LongAnimation: Long Animation Generation with Dynamic Global-Local Memory</title>
      <link>http://arxiv.org/abs/2507.01945v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LongAnimation的自动化长动画着色框架，旨在提高动画工业生产中着色环节的效率。&lt;h4&gt;背景&lt;/h4&gt;长动画着色在动画工业中至关重要，但手工着色成本高昂，因此自动化着色具有重大研究价值。&lt;h4&gt;目的&lt;/h4&gt;针对现有研究主要针对短时着色，且局部范式忽略全局信息的局限性，本研究旨在通过动态全局-局部范式实现长动画的理想色彩一致性。&lt;h4&gt;方法&lt;/h4&gt;LongAnimation框架主要包括SketchDiT、Dynamic Global-Local Memory (DGLM)和Color Consistency Reward模块。SketchDiT捕获混合参考特征以支持DGLM模块，DGLM模块利用长视频理解模型动态压缩全局历史特征，并自适应地与当前生成特征融合。此外，为了提高色彩一致性，引入了Color Consistency Reward，并在推理过程中提出了一种色彩一致性融合方法以平滑视频片段的过渡。&lt;h4&gt;主要发现&lt;/h4&gt;在短期（14帧）和长期（平均500帧）动画的广泛实验中，LongAnimation在保持开放域动画着色任务中的短期和长期色彩一致性方面表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;LongAnimation框架通过动态全局-局部范式，有效地提高了长动画着色的色彩一致性。&lt;h4&gt;翻译&lt;/h4&gt;Animation colorization is a crucial part of real animation industry production. Long animation colorization has high labor costs. Therefore, automated long animation colorization based on the video generation model has significant research value. Existing studies are limited to short-term colorization. These studies adopt a local paradigm, fusing overlapping features to achieve smooth transitions between local segments. However, the local paradigm neglects global information, failing to maintain long-term color consistency. In this study, we argue that ideal long-term color consistency can be achieved through a dynamic global-local paradigm, i.e., dynamically extracting global color-consistent features relevant to the current generation. Specifically, we propose LongAnimation, a novel framework, which mainly includes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a Color Consistency Reward. The SketchDiT captures hybrid reference features to support the DGLM module. The DGLM module employs a long video understanding model to dynamically compress global historical features and adaptively fuse them with the current generation features. To refine the color consistency, we introduce a Color Consistency Reward. During inference, we propose a color consistency fusion to smooth the video segment transition. Extensive experiments on both short-term (14 frames) and long-term (average 500 frames) animations show the effectiveness of LongAnimation in maintaining short-term and long-term color consistency for open-domain animation colorization task. The code can be found at https://cn-makers.github.io/long_animation_web/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Animation colorization is a crucial part of real animation industryproduction. Long animation colorization has high labor costs. Therefore,automated long animation colorization based on the video generation model hassignificant research value. Existing studies are limited to short-termcolorization. These studies adopt a local paradigm, fusing overlapping featuresto achieve smooth transitions between local segments. However, the localparadigm neglects global information, failing to maintain long-term colorconsistency. In this study, we argue that ideal long-term color consistency canbe achieved through a dynamic global-local paradigm, i.e., dynamicallyextracting global color-consistent features relevant to the current generation.Specifically, we propose LongAnimation, a novel framework, which mainlyincludes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a ColorConsistency Reward. The SketchDiT captures hybrid reference features to supportthe DGLM module. The DGLM module employs a long video understanding model todynamically compress global historical features and adaptively fuse them withthe current generation features. To refine the color consistency, we introducea Color Consistency Reward. During inference, we propose a color consistencyfusion to smooth the video segment transition. Extensive experiments on bothshort-term (14 frames) and long-term (average 500 frames) animations show theeffectiveness of LongAnimation in maintaining short-term and long-term colorconsistency for open-domain animation colorization task. The code can be foundat https://cn-makers.github.io/long_animation_web/.</description>
      <author>example@mail.com (Nan Chen, Mengqi Huang, Yihao Meng, Zhendong Mao)</author>
      <guid isPermaLink="false">2507.01945v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Tissue Concepts v2: A Supervised Foundation Model For Whole Slide Images</title>
      <link>http://arxiv.org/abs/2507.05742v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Tissue Concepts v2（TCv2）的监督式基础模型，用于分析组织病理学图像，该模型在资源密集型的训练过程中表现出了优越的性能。&lt;h4&gt;背景&lt;/h4&gt;计算病理学领域正受到基础模型（FMs）的变革性影响，这些模型通过分析组织病理学图像提供了新的方法。然而，创建FMs的过程通常需要在大数据库上训练数周，这是一个资源密集型的过程。&lt;h4&gt;目的&lt;/h4&gt;旨在通过扩展Tissue Concepts模型到全切片图像来解决这个问题，并开发一个能够高效训练的监督式基础模型。&lt;h4&gt;方法&lt;/h4&gt;TCv2采用在切片级别标签上的监督式、端到端多任务学习。其训练过程相对于自监督训练仅需使用一小部分训练资源。&lt;h4&gt;主要发现&lt;/h4&gt;TCv2在癌症亚型基准测试中展现出优于自监督训练模型的性能，且完全使用免费数据训练。此外，共享的训练注意力模块为不同任务提供了解释性的额外层次。&lt;h4&gt;结论&lt;/h4&gt;TCv2是一个高效的监督式基础模型，能够有效地处理组织病理学图像，并在资源消耗上具有优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) are transforming the field of computational pathologyby offering new approaches to analyzing histopathology images. Typicallyrelying on weeks of training on large databases, the creation of FMs is aresource-intensive process in many ways. In this paper, we introduce theextension of our supervised foundation model, Tissue Concepts, to whole slideimages, called Tissue Concepts v2 (TCv2), a supervised foundation model forwhole slide images to address the issue above. TCv2 uses supervised, end-to-endmultitask learning on slide-level labels. Training TCv2 uses a fraction of thetraining resources compared to self-supervised training. The presented modelshows superior performance compared to SSL-trained models in cancer subtypingbenchmarks and is fully trained on freely available data. Furthermore, a sharedtrained attention module provides an additional layer of explainability acrossdifferent tasks.</description>
      <author>example@mail.com (Till Nicke, Daniela Schacherer, Jan Raphael Schäfer, Natalia Artysh, Antje Prasse, André Homeyer, Andrea Schenk, Henning Höfener, Johannes Lotz)</author>
      <guid isPermaLink="false">2507.05742v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems</title>
      <link>http://arxiv.org/abs/2507.06258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Federated recommender systems (FedRec)在保护用户隐私的同时提供个性化推荐，但易受poisoning攻击。本研究提出了一种针对特定用户子组的攻击方法Spattack，通过模拟用户嵌入和优化推荐策略来操纵推荐结果。&lt;h4&gt;背景&lt;/h4&gt;现有的poisoning攻击通常针对整个用户群体，降低了攻击的隐蔽性和安全性。&lt;h4&gt;目的&lt;/h4&gt;针对现有攻击的不足，提出一种针对特定用户子组的攻击方法，以增强推荐的隐蔽性和安全性。&lt;h4&gt;方法&lt;/h4&gt;Spattack采用两阶段策略：首先通过对比学习和聚类方法模拟目标和非目标子组的用户嵌入，然后通过自适应调整优化权重和嵌入对齐策略，将目标物品推荐给目标子组。&lt;h4&gt;主要发现&lt;/h4&gt;Spattack在特定用户子组上表现出强大的操纵性能，对非目标用户影响最小，即使在只有0.1%的用户是恶意用户的情况下。同时，Spattack保持了竞争力的推荐性能，并对现有主流防御机制具有强大的抵抗力。&lt;h4&gt;结论&lt;/h4&gt;Spattack是一种有效的针对特定用户子组的攻击方法，能够在保护用户隐私的同时实现个性化的推荐。&lt;h4&gt;翻译&lt;/h4&gt;Federated推荐系统（FedRec）作为在保护用户隐私的同时提供个性化推荐的有希望解决方案，然而，最近的研究表明，它们容易受到poisoning攻击。现有的攻击通常针对整个用户群体，这会降低攻击的隐蔽性和增加被检测到的风险。相比之下，现实世界的对手可能更倾向于针对特定的用户子组，例如向老年用户提供健康补充品的推荐。受此启发，我们引入了Spattack，这是第一个旨在在联邦环境中操纵特定用户子组推荐的针对性poisoning攻击。具体来说，Spattack采用两阶段近似和提升策略，首先模拟目标/非目标子组的用户嵌入，然后将目标物品推荐给目标子组。为了增强近似阶段，我们基于对比学习将组间嵌入推开，并基于聚类增强目标组的相关物品集。为了增强提升阶段，我们进一步提出自适应调整目标和非目标子组之间优化权重的策略。此外，还提出了一种嵌入对齐策略，以对齐目标物品和相关物品之间的嵌入。我们在三个真实世界数据集上进行了全面的实验，将Spattack与七种最先进的poisoning攻击和七种代表性的防御机制进行了比较。实验结果表明，Spattack在特定用户子组上始终表现出强大的操纵性能，同时对非目标用户的影响最小，即使只有0.1%的用户是恶意用户。此外，Spattack保持了具有竞争力的整体推荐性能，并表现出对现有主流防御机制的抗性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated recommender systems (FedRec) have emerged as a promising solutionfor delivering personalized recommendations while safeguarding user privacy.However, recent studies have demonstrated their vulnerability to poisoningattacks. Existing attacks typically target the entire user group, whichcompromises stealth and increases the risk of detection. In contrast,real-world adversaries may prefer to prompt target items to specific usersubgroups, such as recommending health supplements to elderly users. Motivatedby this gap, we introduce Spattack, the first targeted poisoning attackdesigned to manipulate recommendations for specific user subgroups in thefederated setting. Specifically, Spattack adopts a two-stageapproximation-and-promotion strategy, which first simulates user embeddings oftarget/non-target subgroups and then prompts target items to the targetsubgroups. To enhance the approximation stage, we push the inter-groupembeddings away based on contrastive learning and augment the target group'srelevant item set based on clustering. To enhance the promotion stage, wefurther propose to adaptively tune the optimization weights between target andnon-target subgroups. Besides, an embedding alignment strategy is proposed toalign the embeddings between the target items and the relevant items. Weconduct comprehensive experiments on three real-world datasets, comparingSpattack against seven state-of-the-art poisoning attacks and sevenrepresentative defense mechanisms. Experimental results demonstrate thatSpattack consistently achieves strong manipulation performance on the specificuser subgroup, while incurring minimal impact on non-target users, even whenonly 0.1\% of users are malicious. Moreover, Spattack maintains competitiveoverall recommendation performance and exhibits strong resilience againstexisting mainstream defenses.</description>
      <author>example@mail.com (Bo Yan, Yurong Hao, Dingqi Liu, Huabin Sun, Pengpeng Qiao, Wei Yang Bryan Lim, Yang Cao, Chuan Shi)</author>
      <guid isPermaLink="false">2507.06258v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments</title>
      <link>http://arxiv.org/abs/2507.06564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 9 figures, has been accepted by IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了SkyVLN，一个结合视觉和语言导航（VLN）与非线性模型预测控制（NMPC）的框架，旨在提高无人机在复杂城市环境中的自主导航能力。&lt;h4&gt;背景&lt;/h4&gt;无人机因其移动性和适应性在各个领域得到了广泛应用。&lt;h4&gt;目的&lt;/h4&gt;通过引入SkyVLN，提高无人机在动态3D空间中的导航精度和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;SkyVLN利用大型语言模型（LLMs）解释自然语言指令和视觉观察，并配备精细的空间语言化器和历史路径记忆机制，以解决空间上下文歧义、处理模糊指令并在必要时回溯。此外，框架还集成了NMPC模块，用于动态避障，确保精确的轨迹跟踪和碰撞预防。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用AirSim开发的高保真3D城市模拟环境进行的实验表明，SkyVLN显著提高了导航的成功率和效率，尤其是在新和未见过的环境中。&lt;h4&gt;结论&lt;/h4&gt;SkyVLN框架能够有效提升无人机在复杂城市环境中的自主导航能力，为无人机在未知环境中的导航提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools acrossvarious sectors, driven by their mobility and adaptability. This paperintroduces SkyVLN, a novel framework integrating vision-and-language navigation(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy incomplex urban environments. Unlike traditional navigation methods, SkyVLNleverages Large Language Models (LLMs) to interpret natural languageinstructions and visual observations, enabling UAVs to navigate through dynamic3D spaces with improved accuracy and robustness. We present a multimodalnavigation agent equipped with a fine-grained spatial verbalizer and a historypath memory mechanism. These components allow the UAV to disambiguate spatialcontexts, handle ambiguous instructions, and backtrack when necessary. Theframework also incorporates an NMPC module for dynamic obstacle avoidance,ensuring precise trajectory tracking and collision prevention. To validate ourapproach, we developed a high-fidelity 3D urban simulation environment usingAirSim, featuring realistic imagery and dynamic urban elements. Extensiveexperiments demonstrate that SkyVLN significantly improves navigation successrates and efficiency, particularly in new and unseen environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools acrossvarious sectors, driven by their mobility and adaptability. This paperintroduces SkyVLN, a novel framework integrating vision-and-language navigation(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy incomplex urban environments. Unlike traditional navigation methods, SkyVLNleverages Large Language Models (LLMs) to interpret natural languageinstructions and visual observations, enabling UAVs to navigate through dynamic3D spaces with improved accuracy and robustness. We present a multimodalnavigation agent equipped with a fine-grained spatial verbalizer and a historypath memory mechanism. These components allow the UAV to disambiguate spatialcontexts, handle ambiguous instructions, and backtrack when necessary. Theframework also incorporates an NMPC module for dynamic obstacle avoidance,ensuring precise trajectory tracking and collision prevention. To validate ourapproach, we developed a high-fidelity 3D urban simulation environment usingAirSim, featuring realistic imagery and dynamic urban elements. Extensiveexperiments demonstrate that SkyVLN significantly improves navigation successrates and efficiency, particularly in new and unseen environments.</description>
      <author>example@mail.com (Tianshun Li, Tianyi Huai, Zhen Li, Yichun Gao, Haoang Li, Xinhu Zheng)</author>
      <guid isPermaLink="false">2507.06564v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    </channel>
</rss>