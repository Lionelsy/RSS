<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 21 Apr 2025 14:11:51 +0800</lastBuildDate>
    <item>
      <title>CheXWorld: Exploring Image World Modeling for Radiograph Representation Learning</title>
      <link>http://arxiv.org/abs/2504.13820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CheXWorld的自监督世界模型，旨在通过编码常识知识来建立通用机器学习模型，特别是在放射影像学领域。&lt;h4&gt;背景&lt;/h4&gt;人类能够发展内部世界模型，这些模型能够编码常识知识，告诉我们世界如何运作，并预测自己行为的后果。这一概念在建立通用机器学习模型方面展现出巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;开发CheXWorld，第一个针对放射影像的自监督世界模型，以同时模拟医疗放射科医生所需的三个关键医学知识方面。&lt;h4&gt;方法&lt;/h4&gt;CheXWorld框架同时模拟了以下三个方面：1）局部解剖结构；2）全局解剖布局；3）领域变化。通过定制的定性和定量分析，验证CheXWorld成功捕捉了这三个维度的医学知识。&lt;h4&gt;主要发现&lt;/h4&gt;CheXWorld成功捕捉了医学知识的三个维度，并在八个医学图像分类和分割基准测试中显示出优于现有自监督学习方法和大型医学基础模型的表现。&lt;h4&gt;结论&lt;/h4&gt;CheXWorld是一个强大的自监督世界模型，在放射影像学领域具有显著优势，并可通过迁移学习在多个医学图像任务中取得良好效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类可以发展内部世界模型，这些模型编码常识知识，告诉他们世界如何运作，并预测他们行为的后果。这一概念在近期初步工作中成为建立通用机器学习模型的一个有希望的途径，例如用于视觉表示学习。在这篇论文中，我们提出了CheXWorld，这是第一个针对放射影像的自监督世界模型的努力。具体来说，我们的工作开发了一个统一的框架，同时模拟了医疗放射科医生所需的三个关键医学知识方面，包括1）描述局部组织细粒度特征的局部解剖结构（例如，结构、形状和纹理）；2）描述人体全局组织的全局解剖布局（例如，器官和骨骼的布局）；3）领域变化，鼓励CheXWorld模拟放射影像不同外观领域的转变（例如，由于从不同医院、设备或患者收集放射影像而引起的清晰度、对比度和曝光度的变化）。经验上，我们设计了定制的定性和定量分析，揭示了CheXWorld成功捕捉了这些三个维度的医学知识。此外，八个医学图像分类和分割基准测试的迁移学习实验表明，CheXWorld在性能上显著优于现有的自监督学习方法和大型医学基础模型。代码和预训练模型可在https://github.com/LeapLabTHU/CheXWorld上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/LeapLabTHU/CheXWorld&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans can develop internal world models that encode common sense knowledge,telling them how the world works and predicting the consequences of theiractions. This concept has emerged as a promising direction for establishinggeneral-purpose machine-learning models in recent preliminary works, e.g., forvisual representation learning. In this paper, we present CheXWorld, the firsteffort towards a self-supervised world model for radiographic images.Specifically, our work develops a unified framework that simultaneously modelsthree aspects of medical knowledge essential for qualified radiologists,including 1) local anatomical structures describing the fine-grainedcharacteristics of local tissues (e.g., architectures, shapes, and textures);2) global anatomical layouts describing the global organization of the humanbody (e.g., layouts of organs and skeletons); and 3) domain variations thatencourage CheXWorld to model the transitions across different appearancedomains of radiographs (e.g., varying clarity, contrast, and exposure caused bycollecting radiographs from different hospitals, devices, or patients).Empirically, we design tailored qualitative and quantitative analyses,revealing that CheXWorld successfully captures these three dimensions ofmedical knowledge. Furthermore, transfer learning experiments across eightmedical image classification and segmentation benchmarks showcase thatCheXWorld significantly outperforms existing SSL methods and large-scalemedical foundation models. Code &amp; pre-trained models are available athttps://github.com/LeapLabTHU/CheXWorld.</description>
      <author>example@mail.com (Yang Yue, Yulin Wang, Chenxin Tao, Pan Liu, Shiji Song, Gao Huang)</author>
      <guid isPermaLink="false">2504.13820v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
  <item>
      <title>On the Relationship Between Robustness and Expressivity of Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.13786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at AISTAST 2025, will add DOI when available&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）对位翻转攻击（BFAs）的脆弱性，通过引入一个分析框架来研究架构特征、图属性及其相互作用的影響。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在区分非同构图的能力上具有表达性，这取决于节点邻居的编码。本文考察了用于此目的的神经多重集函数的脆弱性，并建立了正式标准来描述GNN因BFAs而失去表达性的敏感性。&lt;h4&gt;目的&lt;/h4&gt;分析同质化、图结构多样性、特征编码和激活函数对GNN鲁棒性的影响，并得出理论界限来量化在数据集上降低GNN表达性所需的位翻转数量。&lt;h4&gt;方法&lt;/h4&gt;引入分析框架，建立正式标准，进行理论分析，使用十个真实世界数据集进行实证研究。&lt;h4&gt;主要发现&lt;/h4&gt;ReLU激活的GNN在高度同质化的图上，使用低维或one-hot编码特征时，特别容易受到BFAs的影响。&lt;h4&gt;结论&lt;/h4&gt;实证结果表明，理论洞察具有统计显著性，并提供了减轻表达性关键应用中BFA风险的可行方法。&lt;h4&gt;翻译&lt;/h4&gt;We investigate the vulnerability of Graph Neural Networks (GNNs) to bit-flip attacks (BFAs) by introducing an analytical framework to study the influence of architectural features, graph properties, and their interaction. The expressivity of GNNs refers to their ability to distinguish non-isomorphic graphs and depends on the encoding of node neighborhoods. We examine the vulnerability of neural multiset functions commonly used for this purpose and establish formal criteria to characterize a GNN's susceptibility to losing expressivity due to BFAs. This enables an analysis of the impact of homophily, graph structural variety, feature encoding, and activation functions on GNN robustness. We derive theoretical bounds for the number of bit flips required to degrade GNN expressivity on a dataset, identifying ReLU-activated GNNs operating on highly homophilous graphs with low-dimensional or one-hot encoded features as particularly susceptible. Empirical results using ten real-world datasets confirm the statistical significance of our key theoretical insights and offer actionable results to mitigate BFA risks in expressivity-critical applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate the vulnerability of Graph Neural Networks (GNNs) to bit-flipattacks (BFAs) by introducing an analytical framework to study the influence ofarchitectural features, graph properties, and their interaction.  The expressivity of GNNs refers to their ability to distinguishnon-isomorphic graphs and depends on the encoding of node neighborhoods. Weexamine the vulnerability of neural multiset functions commonly used for thispurpose and establish formal criteria to characterize a GNN's susceptibility tolosing expressivity due to BFAs. This enables an analysis of the impact ofhomophily, graph structural variety, feature encoding, and activation functionson GNN robustness. We derive theoretical bounds for the number of bit flipsrequired to degrade GNN expressivity on a dataset, identifying ReLU-activatedGNNs operating on highly homophilous graphs with low-dimensional or one-hotencoded features as particularly susceptible. Empirical results using tenreal-world datasets confirm the statistical significance of our key theoreticalinsights and offer actionable results to mitigate BFA risks inexpressivity-critical applications.</description>
      <author>example@mail.com (Lorenz Kummer, Wilfried N. Gansterer, Nils M. Kriege)</author>
      <guid isPermaLink="false">2504.13786v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Towards Accurate and Interpretable Neuroblastoma Diagnosis via Contrastive Multi-scale Pathological Image Analysis</title>
      <link>http://arxiv.org/abs/2504.13754v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CMSwinKAN的病理图像分类模型，用于克服现有自动化病理图像分类方法的局限性，提高诊断准确性。&lt;h4&gt;背景&lt;/h4&gt;神经母细胞瘤是儿童最常见的实体恶性肿瘤之一，其病理诊断对于患者预后至关重要。然而，当前的诊断实践主要依赖病理医生的主观手动检查，导致准确性不一致。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于对比学习的多尺度特征融合模型CMSwinKAN，以提高病理图像分类的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;CMSwinKAN通过在SwinTransformer架构中集成核激活网络，增强其多层感知器和分类头模块，从而提高模型的可解释性和准确性。此外，还引入了一种启发式软投票机制，以指导将补丁级预测无缝桥接到全切片图像级分类。&lt;h4&gt;主要发现&lt;/h4&gt;CMSwinKAN在PpNTs数据集和BreakHis数据集上进行了验证，结果显示其性能优于基于大数据集预训练的现有最先进病理学模型。&lt;h4&gt;结论&lt;/h4&gt;CMSwinKAN能够有效提高病理图像分类的准确性和可解释性，为临床诊断提供了一种新的工具。&lt;h4&gt;翻译&lt;/h4&gt;Neuroblastoma, adrenal-derived, is among the most common pediatric solid malignancies, characterized by significant clinical heterogeneity. Timely and accurate pathological diagnosis from hematoxylin and eosin-stained whole slide images is critical for patient prognosis. However, current diagnostic practices primarily rely on subjective manual examination by pathologists, leading to inconsistent accuracy. Existing automated whole slide image classification methods encounter challenges such as poor interpretability, limited feature extraction capabilities, and high computational costs, restricting their practical clinical deployment. To overcome these limitations, we propose CMSwinKAN, a contrastive-learning-based multi-scale feature fusion model tailored for pathological image classification, which enhances the SwinTransformer architecture by integrating a Kernel Activation Network within its multi-layer perceptron and classification head modules, significantly improving both interpretability and accuracy. By fusing multi-scale features and leveraging contrastive learning strategies, CMSwinKAN mimics clinicians' comprehensive approach, effectively capturing global and local tissue characteristics. Additionally, we introduce a heuristic soft voting mechanism guided by clinical insights to seamlessly bridge patch-level predictions to whole slide image-level classifications. We validate CMSwinKAN on the PpNTs dataset, which was collaboratively established with our partner hospital and the publicly accessible BreakHis dataset. Results demonstrate that CMSwinKAN performs better than existing state-of-the-art pathology-specific models pre-trained on large datasets. Our source code is available at https://github.com/JSLiam94/CMSwinKAN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuroblastoma, adrenal-derived, is among the most common pediatric solidmalignancies, characterized by significant clinical heterogeneity. Timely andaccurate pathological diagnosis from hematoxylin and eosin-stained whole slideimages is critical for patient prognosis. However, current diagnostic practicesprimarily rely on subjective manual examination by pathologists, leading toinconsistent accuracy. Existing automated whole slide image classificationmethods encounter challenges such as poor interpretability, limited featureextraction capabilities, and high computational costs, restricting theirpractical clinical deployment. To overcome these limitations, we proposeCMSwinKAN, a contrastive-learning-based multi-scale feature fusion modeltailored for pathological image classification, which enhances the SwinTransformer architecture by integrating a Kernel Activation Network within itsmultilayer perceptron and classification head modules, significantly improvingboth interpretability and accuracy. By fusing multi-scale features andleveraging contrastive learning strategies, CMSwinKAN mimics clinicians'comprehensive approach, effectively capturing global and local tissuecharacteristics. Additionally, we introduce a heuristic soft voting mechanismguided by clinical insights to seamlessly bridge patch-level predictions towhole slide image-level classifications. We validate CMSwinKAN on the PpNTsdataset, which was collaboratively established with our partner hospital andthe publicly accessible BreakHis dataset. Results demonstrate that CMSwinKANperforms better than existing state-of-the-art pathology-specific modelspre-trained on large datasets. Our source code is available athttps://github.com/JSLiam94/CMSwinKAN.</description>
      <author>example@mail.com (Zhu Zhu, Shuo Jiang, Jingyuan Zheng, Yawen Li, Yifei Chen, Manli Zhao, Weizhong Gu, Feiwei Qin, Jinhu Wang, Gang Yu)</author>
      <guid isPermaLink="false">2504.13754v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>RefComp: A Reference-guided Unified Framework for Unpaired Point Cloud Completion</title>
      <link>http://arxiv.org/abs/2504.13788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的无配对点云补全框架，即参考引导补全（RefComp）框架，该框架在类感知和类非感知训练设置中均表现出强大的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的无配对点云补全方法具有类感知性，即每个对象类别都需要一个单独的模型，它们的泛化能力有限，在面临广泛的三维对象点云时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无配对点云补全框架，以解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;RefComp框架将无配对补全问题转化为形状转换问题，并在部分点云的潜在特征空间中解决。使用部分-完整点云对作为参考数据来指导补全过程，并使用具有共享参数的参考分支和目标分支，通过潜在形状融合模块（LSFM）进行形状融合和形状转换，以增强补全过程中的结构特征。&lt;h4&gt;主要发现&lt;/h4&gt;RefComp框架在类感知训练设置中实现了最先进的性能，在类非感知训练设置中在虚拟扫描和真实世界数据集上取得了具有竞争力的结果。&lt;h4&gt;结论&lt;/h4&gt;RefComp框架能够有效提高无配对点云补全的性能，适用于不同类型的点云数据。&lt;h4&gt;翻译&lt;/h4&gt;The unpaired point cloud completion task aims to complete a partial point cloud by using models trained with no ground truth. Existing unpaired point cloud completion methods are class-aware, i.e., a separate model is needed for each object class. Since they have limited generalization capabilities, these methods perform poorly in real-world scenarios when confronted with a wide range of point clouds of generic 3D objects. In this paper, we propose a novel unpaired point cloud completion framework, namely the Reference-guided Completion (RefComp) framework, which attains strong performance in both the class-aware and class-agnostic training settings. The RefComp framework transforms the unpaired completion problem into a shape translation problem, which is solved in the latent feature space of the partial point clouds. To this end, we introduce the use of partial-complete point cloud pairs, which are retrieved by using the partial point cloud to be completed as a template. These point cloud pairs are used as reference data to guide the completion process. Our RefComp framework uses a reference branch and a target branch with shared parameters for shape fusion and shape translation via a Latent Shape Fusion Module (LSFM) to enhance the structural features along the completion pipeline. Extensive experiments demonstrate that the RefComp framework achieves not only state-of-the-art performance in the class-aware training setting but also competitive results in the class-agnostic training setting on both virtual scans and real-world datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The unpaired point cloud completion task aims to complete a partial pointcloud by using models trained with no ground truth. Existing unpaired pointcloud completion methods are class-aware, i.e., a separate model is needed foreach object class. Since they have limited generalization capabilities, thesemethods perform poorly in real-world scenarios when confronted with a widerange of point clouds of generic 3D objects. In this paper, we propose a novelunpaired point cloud completion framework, namely the Reference-guidedCompletion (RefComp) framework, which attains strong performance in both theclass-aware and class-agnostic training settings. The RefComp frameworktransforms the unpaired completion problem into a shape translation problem,which is solved in the latent feature space of the partial point clouds. Tothis end, we introduce the use of partial-complete point cloud pairs, which areretrieved by using the partial point cloud to be completed as a template. Thesepoint cloud pairs are used as reference data to guide the completion process.Our RefComp framework uses a reference branch and a target branch with sharedparameters for shape fusion and shape translation via a Latent Shape FusionModule (LSFM) to enhance the structural features along the completion pipeline.Extensive experiments demonstrate that the RefComp framework achieves not onlystate-of-the-art performance in the class-aware training setting but alsocompetitive results in the class-agnostic training setting on both virtualscans and real-world datasets.</description>
      <author>example@mail.com (Yixuan Yang, Jinyu Yang, Zixiang Zhao, Victor Sanchez, Feng Zheng)</author>
      <guid isPermaLink="false">2504.13788v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>HAECcity: Open-Vocabulary Scene Understanding of City-Scale Point Clouds with Superpoint Graph Clustering</title>
      <link>http://arxiv.org/abs/2504.13590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication through the upcoming CVPR Workshop on open  scene understanding with foundation models (OPENSUN3D)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HAEC（Hierarchical vocab-Agnostic Expert Clustering）的3D场景理解技术，用于处理城市规模的三维数据集，并通过无标注的合成标签流程进行数据标注。&lt;h4&gt;背景&lt;/h4&gt;传统的3D场景理解技术依赖于手动标注的标签集，而近年来，一类新的开放词汇3D场景理解技术出现，尽管在小场景上取得成功，但现有方法无法高效扩展到城市规模的三维数据集。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效处理城市规模三维数据集的开放词汇场景理解技术，并实现无标注的合成标签流程。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种基于超级点图的聚类方法HAEC，其核心是一个新的混合专家图Transformer模型。该方法在Sensat Urban city-scale数据集上进行了首次应用，并展示了从原始点云中衍生出的合成标签流程。&lt;h4&gt;主要发现&lt;/h4&gt;HAEC技术能够高效处理城市规模的三维数据集，并通过合成标签流程实现了无标注的数据标注。&lt;h4&gt;结论&lt;/h4&gt;HAEC技术有助于解锁对密集城市三维场景的复杂操作，并为数字孪生的处理开辟了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统的3D场景理解技术通常基于手动标注的标签集，但近年来，一类新的开放词汇3D场景理解技术已经出现。尽管这种范式在小场景上取得了成功，但现有方法无法有效地扩展到城市规模的三维数据集。在本文中，我们提出了Hierarchical vocab-Agnostic Expert Clustering（HAEC），这是一个基于超级点图的聚类方法，它使用一个新颖的混合专家图Transformer作为其骨干。我们将这种高度可扩展的方法应用于开放词汇场景理解的首次应用，在Sensat Urban city-scale数据集上。我们还展示了一个完全由原始点云衍生出的合成标签流程，无需手动标注。我们的技术可以帮助解锁对密集城市三维场景的复杂操作，并为数字孪生的处理开辟新的道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional 3D scene understanding techniques are generally predicated onhand-annotated label sets, but in recent years a new class of open-vocabulary3D scene understanding techniques has emerged. Despite the success of thisparadigm on small scenes, existing approaches cannot scale efficiently tocity-scale 3D datasets. In this paper, we present Hierarchical vocab-AgnosticExpert Clustering (HAEC), after the latin word for 'these', a superpoint graphclustering based approach which utilizes a novel mixture of experts graphtransformer for its backbone. We administer this highly scalable approach tothe first application of open-vocabulary scene understanding on the SensatUrbancity-scale dataset. We also demonstrate a synthetic labeling pipeline which isderived entirely from the raw point clouds with no hand-annotation. Ourtechnique can help unlock complex operations on dense urban 3D scenes and opena new path forward in the processing of digital twins.</description>
      <author>example@mail.com (Alexander Rusnak, Frédéric Kaplan)</author>
      <guid isPermaLink="false">2504.13590v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration</title>
      <link>http://arxiv.org/abs/2504.13717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Personal adaptation and expansion of doctoral thesis (originally  submitted in Oct 2024, revisioned in Jan 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究旨在将深度学习与人类推理能力相结合，以实现更高效、可解释和鲁棒的医疗图像分类。研究从可解释性、因果性和生物视觉三个角度进行探索。&lt;h4&gt;背景&lt;/h4&gt;研究首先评估了神经网络的可视化技术在医学图像中的应用，并验证了一种用于乳腺肿块分类的“设计可解释”方法。接着，对XAI和因果性交叉领域的综合回顾，并介绍了一个通用的研究框架。&lt;h4&gt;目的&lt;/h4&gt;目的是使深度学习模型更符合人类的推理能力，提高图像分类的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;方法包括：提出新的模块以利用医学图像中的特征共现，提出CROCODILE框架整合因果概念、对比学习、特征解耦和先验知识，以及探索生物视觉并设计CoCoReco网络。&lt;h4&gt;主要发现&lt;/h4&gt;主要发现包括：简单激活最大化缺乏对医学图像深度学习模型的洞察；原型-部分学习有效且与放射学一致；XAI和因果机器学习紧密相连；在无需先验信息的情况下，可以利用弱因果信号来提高性能和可解释性；框架在医学领域和分布外数据中具有泛化能力；结合生物电路模式可以提高与人类一致的识别。&lt;h4&gt;结论&lt;/h4&gt;该研究为与人类对齐的深度学习做出了贡献，并指出了连接研究和临床应用的方法，对提高信任、诊断准确性和安全部署具有意义。&lt;h4&gt;翻译&lt;/h4&gt;这项工作将深度学习与人类推理能力相结合，旨在实现更高效、可解释和鲁棒的图像分类。我们从可解释性、因果性和生物视觉三个角度来探讨这个问题。在介绍和背景之后，我们首先评估了神经网络的可视化技术在医学图像中的应用，并验证了一种用于乳腺肿块分类的“设计可解释”方法。接着，我们对XAI和因果性交叉领域的综合回顾，并介绍了一个通用的研究框架。在因果关系方向上，我们提出了利用医学图像中特征共现的新模块，导致更有效和可解释的预测。我们进一步引入了CROCODILE，这是一个整合因果概念、对比学习、特征解耦和先验知识的通用框架，以增强泛化能力。最后，我们探索了生物视觉，检查人类如何识别物体，并提出了受连接性启发的网络CoCoReco，具有上下文感知的注意力机制。我们的关键发现包括：（i）简单激活最大化缺乏对医学图像深度学习模型的洞察；（ii）原型-部分学习有效且与放射学一致；（iii）XAI和因果机器学习紧密相连；（iv）在无需先验信息的情况下，可以利用弱因果信号来提高性能和可解释性；（v）我们的框架在医学领域和分布外数据中具有泛化能力；（vi）结合生物电路模式可以提高与人类一致的识别。这项工作为与人类对齐的深度学习做出了贡献，并指出了连接研究和临床应用的方法，对提高信任、诊断准确性和安全部署具有意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work aligns deep learning (DL) with human reasoning capabilities andneeds to enable more efficient, interpretable, and robust image classification.We approach this from three perspectives: explainability, causality, andbiological vision. Introduction and background open this work before divinginto operative chapters. First, we assess neural networks' visualizationtechniques for medical images and validate an explainable-by-design method forbreast mass classification. A comprehensive review at the intersection of XAIand causality follows, where we introduce a general scaffold to organize pastand future research, laying the groundwork for our second perspective. In thecausality direction, we propose novel modules that exploit featureco-occurrence in medical images, leading to more effective and explainablepredictions. We further introduce CROCODILE, a general framework thatintegrates causal concepts, contrastive learning, feature disentanglement, andprior knowledge to enhance generalization. Lastly, we explore biologicalvision, examining how humans recognize objects, and propose CoCoReco, aconnectivity-inspired network with context-aware attention mechanisms. Overall,our key findings include: (i) simple activation maximization lacks insight formedical imaging DL models; (ii) prototypical-part learning is effective andradiologically aligned; (iii) XAI and causal ML are deeply connected; (iv) weakcausal signals can be leveraged without a priori information to improveperformance and interpretability; (v) our framework generalizes across medicaldomains and out-of-distribution data; (vi) incorporating biological circuitmotifs improves human-aligned recognition. This work contributes towardhuman-aligned DL and highlights pathways to bridge the gap between research andclinical adoption, with implications for improved trust, diagnostic accuracy,and safe deployment.</description>
      <author>example@mail.com (Gianluca Carloni)</author>
      <guid isPermaLink="false">2504.13717v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Lightweight LiDAR-Camera 3D Dynamic Object Detection and Multi-Class Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2504.13647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种轻量级的多模态框架，用于3D物体检测和轨迹预测，以帮助移动机器人实时感知3D空间中的行人、车辆和骑行者。&lt;h4&gt;背景&lt;/h4&gt;移动机器人在执行任务时需要避开动态物体，但通常只有有限的计算资源。&lt;h4&gt;目的&lt;/h4&gt;开发一个轻量级的框架，以实现高精度和计算效率的3D物体检测和轨迹预测。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了激光雷达和摄像头输入，并提出了两个新型模块：Cross-Modal Deformable Transformer (CMDT) 用于物体检测，Reference Trajectory-based Multi-Class Transformer (RTMCT) 用于多类物体轨迹预测。&lt;h4&gt;主要发现&lt;/h4&gt;在CODa基准测试中，该系统在检测和轨迹预测方面优于现有方法，且在轮椅机器人上实现实时推理。&lt;h4&gt;结论&lt;/h4&gt;该系统具有出色的部署性和可重复性，相关代码和ROS推理版本已公开发布。&lt;h4&gt;翻译&lt;/h4&gt;摘要：移动服务机器人通常需要在执行任务时避开动态物体，但它们通常只有有限的计算资源。因此，我们提出了一种用于3D物体检测和轨迹预测的轻量级多模态框架。我们的系统协同整合了激光雷达和摄像头输入，以实现3D空间中行人、车辆和骑行者的实时感知。该框架提出了两个新颖的模块：1）用于高精度和可接受计算量的物体检测的跨模态可变形变换器（CMDT），2）用于多类物体高效和多样化轨迹预测的基于参考轨迹的多类变换器（RTMCT）。在CODa基准测试中的评估表明，该系统在检测（mAP提高2.03%）和轨迹预测（行人minADE5降低0.408m）方面优于现有方法。值得注意的是，该系统具有出色的部署性——当在配备入门级NVIDIA 3060 GPU的轮椅机器人上实现时，它以13.2 fps的速度实现实时推理。为了促进可重复性和实际部署，我们在https://github.com/TossherO/3D_Perception发布了该方法的相关代码，并在https://github.com/TossherO/ros_packages发布了其ROS推理版本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Service mobile robots are often required to avoid dynamic objects whileperforming their tasks, but they usually have only limited computationalresources. So we present a lightweight multi-modal framework for 3D objectdetection and trajectory prediction. Our system synergistically integratesLiDAR and camera inputs to achieve real-time perception of pedestrians,vehicles, and riders in 3D space. The framework proposes two novel modules: 1)a Cross-Modal Deformable Transformer (CMDT) for object detection with highaccuracy and acceptable amount of computation, and 2) a ReferenceTrajectory-based Multi-Class Transformer (RTMCT) for efficient and diversetrajectory prediction of mult-class objects with flexible trajectory lengths.Evaluations on the CODa benchmark demonstrate superior performance overexisting methods across detection (+2.03% in mAP) and trajectory prediction(-0.408m in minADE5 of pedestrians) metrics. Remarkably, the system exhibitsexceptional deployability - when implemented on a wheelchair robot with anentry-level NVIDIA 3060 GPU, it achieves real-time inference at 13.2 fps. Tofacilitate reproducibility and practical deployment, we release the relatedcode of the method at https://github.com/TossherO/3D_Perception and its ROSinference version at https://github.com/TossherO/ros_packages.</description>
      <author>example@mail.com (Yushen He, Lei Zhao, Tianchen Deng, Zipeng Fang, Weidong Chen)</author>
      <guid isPermaLink="false">2504.13647v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>KAN or MLP? Point Cloud Shows the Way Forward</title>
      <link>http://arxiv.org/abs/2504.13593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PointKAN的新方法，应用于点云分析，通过引入Kolmogorov-Arnold Networks (KANs)来提高特征表示的效率。&lt;h4&gt;背景&lt;/h4&gt;多层感知器（MLPs）在点云分析中是基础组件，但在处理复杂几何结构时，其固定激活函数难以有效捕捉局部几何特征，且存在参数效率低和模型冗余的问题。&lt;h4&gt;目的&lt;/h4&gt;研究KANs在点云分析中分层特征表示的有效性。&lt;h4&gt;方法&lt;/h4&gt;PointKAN包括几何仿射模块（GAM）来转换局部特征，提高模型对几何变化的鲁棒性；局部特征处理（LFP）中并行结构提取组级特征和全局上下文；全局特征处理（GFP）结合并处理这些特征；通过重复操作，感受野逐渐扩大，使模型能够捕捉点云的完整几何信息。此外，PointKAN-elite变体开发了高效的KANs（Efficient-KANs），以降低参数数量和计算复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PointKAN在基准数据集（如ModelNet40、ScanObjectNN和ShapeNetPart）上优于PointMLP，尤其在少样本学习任务中表现突出，同时显著降低了参数数量和计算复杂度。&lt;h4&gt;结论&lt;/h4&gt;PointKAN展示了基于KANs架构在3D视觉中的潜力，并为点云理解的研究开辟了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多层感知器（MLPs）已成为点云分析中的基本架构组件，由于其有效的特征学习机制。然而，当处理点云中的复杂几何结构时，MLPs的固定激活函数难以有效地捕捉局部几何特征，同时存在参数效率低和模型冗余的问题。在本文中，我们提出了PointKAN，将Kolmogorov-Arnold Networks（KANs）应用于点云分析任务，以研究其在分层特征表示中的有效性。首先，我们引入了几何仿射模块（GAM）来转换局部特征，提高了模型对几何变化的鲁棒性。其次，在局部特征处理（LFP）中，并行结构提取了组级特征和全局上下文，提供了对细粒度和整体结构的丰富表示。最后，这些特征在全局特征处理（GFP）中被结合并处理。通过重复这些操作，感受野逐渐扩大，使模型能够捕捉点云的完整几何信息。为了克服标准KANs的高参数计数和计算效率低下的问题，我们在PointKAN-elite变体中开发了高效的KANs（Efficient-KANs），显著降低了参数数量同时保持了准确性。实验结果表明，PointKAN在基准数据集（如ModelNet40、ScanObjectNN和ShapeNetPart）上优于PointMLP，尤其是在少样本学习任务中表现突出。此外，PointKAN在参数数量和计算复杂度（FLOPs）方面实现了显著降低。这项工作突出了基于KANs架构在3D视觉中的潜力，并为点云理解的研究开辟了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-Layer Perceptrons (MLPs) have become one of the fundamentalarchitectural component in point cloud analysis due to its effective featurelearning mechanism. However, when processing complex geometric structures inpoint clouds, MLPs' fixed activation functions struggle to efficiently capturelocal geometric features, while suffering from poor parameter efficiency andhigh model redundancy. In this paper, we propose PointKAN, which appliesKolmogorov-Arnold Networks (KANs) to point cloud analysis tasks to investigatetheir efficacy in hierarchical feature representation. First, we introduce aGeometric Affine Module (GAM) to transform local features, improving themodel's robustness to geometric variations. Next, in the Local FeatureProcessing (LFP), a parallel structure extracts both group-level features andglobal context, providing a rich representation of both fine details andoverall structure. Finally, these features are combined and processed in theGlobal Feature Processing (GFP). By repeating these operations, the receptivefield gradually expands, enabling the model to capture complete geometricinformation of the point cloud. To overcome the high parameter counts andcomputational inefficiency of standard KANs, we develop Efficient-KANs in thePointKAN-elite variant, which significantly reduces parameters whilemaintaining accuracy. Experimental results demonstrate that PointKANoutperforms PointMLP on benchmark datasets such as ModelNet40, ScanObjectNN,and ShapeNetPart, with particularly strong performance in Few-shot Learningtask. Additionally, PointKAN achieves substantial reductions in parametercounts and computational complexity (FLOPs). This work highlights the potentialof KANs-based architectures in 3D vision and opens new avenues for research inpoint cloud understanding.</description>
      <author>example@mail.com (Yan Shi, Qingdong He, Yijun Liu, Xiaoyu Liu, Jingyong Su)</author>
      <guid isPermaLink="false">2504.13593v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2504.13580v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Github Page: https://github.com/stefan-ainetter/SCANnotatepp&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了高级3D场景理解的重要性，并提出了使用自动检索合成CAD模型的方法来生成高质量的3D标注数据，以训练深度学习模型。&lt;h4&gt;背景&lt;/h4&gt;生成准确的3D标注数据对深度学习模型的发展是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;利用自动检索合成CAD模型的方法，将生成的数据作为训练监督深度学习模型的高质量真实数据。&lt;h4&gt;方法&lt;/h4&gt;采用与之前用于自动标注ScanNet场景中物体9D姿态和CAD模型相似的流程，应用于ScanNet++ v1数据集，该数据集之前缺乏此类标注。&lt;h4&gt;主要发现&lt;/h4&gt;不仅能够在自动获取的标注数据上训练深度学习模型，而且这些模型的表现优于在手动标注数据上训练的模型。&lt;h4&gt;结论&lt;/h4&gt;自动3D标注具有提高模型性能的潜力，同时显著降低标注成本。作者将发布他们的标注数据（SCANnotate++）和训练模型，以支持未来3D场景理解的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：高级3D场景理解在许多应用中至关重要。然而，生成准确3D标注的挑战使得深度学习模型的发展困难。我们转向最近在自动检索合成CAD模型方面的进展，并表明此类方法生成的数据可以用作训练监督深度学习模型的高质量真实数据。更确切地说，我们采用了与之前用于自动标注ScanNet场景中物体9D姿态和CAD模型相似的流程。这次，我们将其应用于之前缺乏此类标注的ScanNet++ v1数据集。我们的发现表明，不仅可以在这些自动获取的标注数据上训练深度学习模型，而且这些模型的表现优于在手动标注数据上训练的模型。我们在两个不同的任务上验证了这一点：点云补全和单视图CAD模型检索与对齐。我们的结果强调了自动3D标注提高模型性能的潜力，同时显著降低标注成本。为了支持未来3D场景理解的研究，我们将发布我们的标注数据，我们称之为SCANnotate++，以及我们的训练模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-level 3D scene understanding is essential in many applications. However,the challenges of generating accurate 3D annotations make development of deeplearning models difficult. We turn to recent advancements in automaticretrieval of synthetic CAD models, and show that data generated by such methodscan be used as high-quality ground truth for training supervised deep learningmodels. More exactly, we employ a pipeline akin to the one previously used toautomatically annotate objects in ScanNet scenes with their 9D poses and CADmodels. This time, we apply it to the recent ScanNet++ v1 dataset, whichpreviously lacked such annotations. Our findings demonstrate that it is notonly possible to train deep learning models on these automatically-obtainedannotations but that the resulting models outperform those trained on manuallyannotated data. We validate this on two distinct tasks: point cloud completionand single-view CAD model retrieval and alignment. Our results underscore thepotential of automatic 3D annotations to enhance model performance whilesignificantly reducing annotation costs. To support future research in 3D sceneunderstanding, we will release our annotations, which we call SCANnotate++,along with our trained models.</description>
      <author>example@mail.com (Yuchen Rao, Stefan Ainetter, Sinisa Stekovic, Vincent Lepetit, Friedrich Fraundorfer)</author>
      <guid isPermaLink="false">2504.13580v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Equi-Euler GraphNet: An Equivariant, Temporal-Dynamics Informed Graph Neural Network for Dual Force and Trajectory Prediction in Multi-Body Systems</title>
      <link>http://arxiv.org/abs/2504.13768v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Equi-Euler GraphNet的物理信息图神经网络，用于多体动态系统的实时建模，同时预测内部力和全局轨迹，以支持故障检测和预测性维护。&lt;h4&gt;背景&lt;/h4&gt;准确的多体动态系统实时建模对于实现跨行业的数字孪生应用至关重要。然而，联合预测内部载荷和系统轨迹仍然是一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够同时预测多体系统的内部力和全局轨迹，以支持故障检测和预测性维护。&lt;h4&gt;方法&lt;/h4&gt;Equi-Euler GraphNet是一种基于物理信息的图神经网络，它引入了两种归纳偏差：一是等变消息传递方案，二是基于欧拉积分的时间感知迭代节点更新机制。该方法适用于圆柱滚子轴承，并能够在未经训练的速度、载荷和配置下准确预测载荷和轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;Equi-Euler GraphNet在圆柱滚子轴承上表现出色，能够将环动力学与滚动元件的约束运动解耦。它在高保真多物理场仿真上训练，并在未见过的速度、载荷和配置下准确预测载荷和轨迹，优于现有的专注于轨迹预测的GNNs。&lt;h4&gt;结论&lt;/h4&gt;Equi-Euler GraphNet实现了一个高达200倍的速度提升，同时保持了与传统求解器相当的精度，为数字孪生、设计和维护提供了一个高效的降阶模型。&lt;h4&gt;翻译&lt;/h4&gt;Accurate real-time modeling of multi-body dynamical systems is essential for enabling digital twin applications across industries. While many data-driven approaches aim to learn system dynamics, jointly predicting internal loads and system trajectories remains a key challenge. This dual prediction is especially important for fault detection and predictive maintenance, where internal loads such as contact forces act as early indicators of faults, reflecting wear or misalignment before affecting motion. These forces also serve as inputs to degradation models (e.g., crack growth), enabling damage prediction and remaining useful life estimation. We propose Equi-Euler GraphNet, a physics-informed graph neural network (GNN) that simultaneously predicts internal forces and global trajectories in multi-body systems. In this mesh-free framework, nodes represent system components and edges encode interactions. Equi-Euler GraphNet introduces two inductive biases: (1) an equivariant message-passing scheme, interpreting edge messages as interaction forces consistent under Euclidean transformations; and (2) a temporal-aware iterative node update mechanism, based on Euler integration, to capture influence of distant interactions over time. Tailored for cylindrical roller bearings, it decouples ring dynamics from constrained motion of rolling elements. Trained on high-fidelity multiphysics simulations, Equi-Euler GraphNet generalizes beyond the training distribution, accurately predicting loads and trajectories under unseen speeds, loads, and configurations. It outperforms state-of-the-art GNNs focused on trajectory prediction, delivering stable rollouts over thousands of time steps with minimal error accumulation. Achieving up to a 200x speedup over conventional solvers while maintaining comparable accuracy, it serves as an efficient reduced-order model for digital twins, design, and maintenance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate real-time modeling of multi-body dynamical systems is essential forenabling digital twin applications across industries. While many data-drivenapproaches aim to learn system dynamics, jointly predicting internal loads andsystem trajectories remains a key challenge. This dual prediction is especiallyimportant for fault detection and predictive maintenance, where internalloads-such as contact forces-act as early indicators of faults, reflecting wearor misalignment before affecting motion. These forces also serve as inputs todegradation models (e.g., crack growth), enabling damage prediction andremaining useful life estimation. We propose Equi-Euler GraphNet, aphysics-informed graph neural network (GNN) that simultaneously predictsinternal forces and global trajectories in multi-body systems. In thismesh-free framework, nodes represent system components and edges encodeinteractions. Equi-Euler GraphNet introduces two inductive biases: (1) anequivariant message-passing scheme, interpreting edge messages as interactionforces consistent under Euclidean transformations; and (2) a temporal-awareiterative node update mechanism, based on Euler integration, to captureinfluence of distant interactions over time. Tailored for cylindrical rollerbearings, it decouples ring dynamics from constrained motion of rollingelements. Trained on high-fidelity multiphysics simulations, Equi-EulerGraphNet generalizes beyond the training distribution, accurately predictingloads and trajectories under unseen speeds, loads, and configurations. Itoutperforms state-of-the-art GNNs focused on trajectory prediction, deliveringstable rollouts over thousands of time steps with minimal error accumulation.Achieving up to a 200x speedup over conventional solvers while maintainingcomparable accuracy, it serves as an efficient reduced-order model for digitaltwins, design, and maintenance.</description>
      <author>example@mail.com (Vinay Sharma, Rémi Tanguy Oddon, Pietro Tesini, Jens Ravesloot, Cees Taal, Olga Fink)</author>
      <guid isPermaLink="false">2504.13768v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Pothole Detection and Characterization: Integrated Segmentation and Depth Estimation in Road Anomaly Systems</title>
      <link>http://arxiv.org/abs/2504.13648v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于YOLOv8-seg模型的公路异常检测方法，用于自动识别和表征路面坑洼，旨在提高道路维护和行车安全。&lt;h4&gt;背景&lt;/h4&gt;传统的路面坑洼检测需要人工分析，过程繁琐且耗时。现有的机器学习方法在全面表征路面坑洼方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;利用迁移学习，采用预训练的YOLOv8-seg模型，通过数字图像自动表征路面坑洼。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含图像及其对应深度图的新数据集，收集自沙特阿拉伯Al-Khobar城市和KFUPM校园的不同道路环境。方法包括坑洼检测和分割，以精确定位坑洼并计算其面积。然后将分割图像与其深度图合并，以提取坑洼的详细深度信息。&lt;h4&gt;主要发现&lt;/h4&gt;该方法的集成分割和深度数据提供了比先前基于深度学习的公路异常检测系统更全面的表征。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅能够显著提高自动驾驶导航的检测和表征能力，还有助于道路维护部门更有效地应对道路损害。&lt;h4&gt;翻译&lt;/h4&gt;摘要：道路异常检测在道路维护和增强驾驶员及车辆安全方面起着至关重要的作用。最近的道路异常检测机器学习方法克服了人工分析和异常计数繁琐耗时的过程；然而，它们往往在提供路面坑洼的完整表征方面存在不足。在本文中，我们利用迁移学习，通过采用预训练的YOLOv8-seg模型，利用仪表盘摄像头捕获的数字图像自动表征坑洼。我们的工作包括创建一个包含图像及其对应深度图的新数据集，这些图像和深度图是从沙特阿拉伯Al-Khobar城市和KFUPM校园的不同道路环境中收集的。我们的方法执行坑洼检测和分割，以精确定位坑洼并计算其面积。随后，将分割图像与其深度图合并，以提取关于坑洼的详细深度信息。这种分割和深度数据的集成提供了比先前基于深度学习的公路异常检测系统更全面的表征。总的来说，这种方法不仅有可能显著提高自动驾驶导航的检测和表征能力，还有助于道路维护部门更有效地应对道路损害。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Road anomaly detection plays a crucial role in road maintenance and inenhancing the safety of both drivers and vehicles. Recent machine learningapproaches for road anomaly detection have overcome the tedious andtime-consuming process of manual analysis and anomaly counting; however, theyoften fall short in providing a complete characterization of road potholes. Inthis paper, we leverage transfer learning by adopting a pre-trained YOLOv8-segmodel for the automatic characterization of potholes using digital imagescaptured from a dashboard-mounted camera. Our work includes the creation of anovel dataset, comprising both images and their corresponding depth maps,collected from diverse road environments in Al-Khobar city and the KFUPM campusin Saudi Arabia. Our approach performs pothole detection and segmentation toprecisely localize potholes and calculate their area. Subsequently, thesegmented image is merged with its depth map to extract detailed depthinformation about the potholes. This integration of segmentation and depth dataoffers a more comprehensive characterization compared to previous deeplearning-based road anomaly detection systems. Overall, this method not onlyhas the potential to significantly enhance autonomous vehicle navigation byimproving the detection and characterization of road hazards but also assistsroad maintenance authorities in responding more effectively to road damage.</description>
      <author>example@mail.com (Uthman Baroudi, Alala BaHamid, Yasser Elalfy, Ziad Al Alami)</author>
      <guid isPermaLink="false">2504.13648v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Consensus-aware Contrastive Learning for Group Recommendation</title>
      <link>http://arxiv.org/abs/2504.13703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CoCoRec的共识感知对比学习方法，旨在解决小组推荐中共识获取和个性化平衡的问题。&lt;h4&gt;背景&lt;/h4&gt;小组推荐旨在为用户群体提供个性化的项目建议，但如何充分反映个体成员的多样化兴趣是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在通过共识感知对比学习方法，解决小组推荐中共识获取和个性化平衡的问题。&lt;h4&gt;方法&lt;/h4&gt;CoCoRec通过对比学习来建模小组共识，使用transformer编码器共同学习用户和小组表示，以更好地模拟小组内部动态。此外，对比目标有助于减少高频用户交互引起的过拟合。&lt;h4&gt;主要发现&lt;/h4&gt;在四个基准数据集上的实验表明，CoCoRec在个人和小组推荐场景中均优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;共识感知对比学习方法在小组推荐任务中是有效的，并能够提供更稳健和有代表性的小组嵌入。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为CoCoRec的共识感知对比学习方法，旨在解决小组推荐中共识获取和个性化平衡的问题。小组推荐旨在为用户群体提供个性化的项目建议，但如何充分反映个体成员的多样化兴趣是一个挑战。旨在通过共识感知对比学习方法，解决小组推荐中共识获取和个性化平衡的问题。CoCoRec通过对比学习来建模小组共识，使用transformer编码器共同学习用户和小组表示，以更好地模拟小组内部动态。此外，对比目标有助于减少高频用户交互引起的过拟合。在四个基准数据集上的实验表明，CoCoRec在个人和小组推荐场景中均优于最先进的方法。共识感知对比学习方法在小组推荐任务中是有效的，并能够提供更稳健和有代表性的小组嵌入。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Group recommendation aims to provide personalized item suggestions to a groupof users by reflecting their collective preferences. A fundamental challenge inthis task is deriving a consensus that adequately represents the diverseinterests of individual group members. Despite advancements made by deeplearning-based models, existing approaches still struggle in two main areas:(1) Capturing consensus in small-group settings, which are more prevalent inreal-world applications, and (2) Balancing individual preferences with overallgroup performance, particularly in hypergraph-based methods that tend toemphasize group accuracy at the expense of personalization. To address thesechallenges, we introduce a Consensus-aware Contrastive Learning for GroupRecommendation (CoCoRec) that models group consensus through contrastivelearning. CoCoRec utilizes a transformer encoder to jointly learn user andgroup representations, enabling richer modeling of intra-group dynamics.Additionally, the contrastive objective helps reduce overfitting fromhigh-frequency user interactions, leading to more robust and representativegroup embeddings. Experiments conducted on four benchmark datasets show thatCoCoRec consistently outperforms state-of-the-art baselines in both individualand group recommendation scenarios, highlighting the effectiveness ofconsensus-aware contrastive learning in group recommendation tasks.</description>
      <author>example@mail.com (Soyoung Kim, Dongjun Lee, Jaekwang Kim)</author>
      <guid isPermaLink="false">2504.13703v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation</title>
      <link>http://arxiv.org/abs/2504.13614v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ALDA4Rec的推荐系统方法，旨在解决基于图神经网络的推荐系统中的噪声和静态表示问题。&lt;h4&gt;背景&lt;/h4&gt;互联网的快速发展使得个性化推荐系统变得不可或缺，但基于图神经网络的推荐系统在处理噪声和静态表示方面面临挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够有效捕获用户-项目交互复杂性的推荐系统模型，同时提高推荐的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;ALDA4Rec方法通过构建项目-项目图、通过社区检测过滤噪声并丰富用户-项目交互，使用图卷积网络学习短期表示，利用平均、GRU和注意力机制建模长期嵌入，并通过基于MLP的自适应加权策略动态优化长期用户偏好。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界数据集上的实验表明，ALDA4Rec在准确性和鲁棒性方面优于现有基线方法。&lt;h4&gt;结论&lt;/h4&gt;ALDA4Rec是一种有效的推荐系统方法，能够显著提高推荐系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;The rapid growth of the internet has made personalized recommendation systems indispensable. Graph-based sequential recommendation systems, powered by GraphNeural Networks (GNNs), effectively capture complex user-item interactions but often face challenges such as noise and static representations. In this paper, we introduce the Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation (ALDA4Rec) method, a novel model that constructs an item-item graph, filters noise through community detection, and enriches user-item interactions. Graph Convolutional Networks (GCNs) are then employed to learn short-term representations, while averaging, GRUs, and attention mechanisms are utilized to model long-term embeddings. An MLP-based adaptive weighting strategy is further incorporated to dynamically optimize long-term user preferences. Experiments conducted on four real-world datasets demonstrate that ALDA4Rec outperforms state-of-the-art baselines, delivering notable improvements in both accuracy and robustness. The source code is available at https://github.com/zahraakhlaghi/ALDA4Rec.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of the internet has made personalized recommendation systemsindispensable. Graph-based sequential recommendation systems, powered by GraphNeural Networks (GNNs), effectively capture complex user-item interactions butoften face challenges such as noise and static representations. In this paper,we introduce the Adaptive Long-term Embedding with Denoising and Augmentationfor Recommendation (ALDA4Rec) method, a novel model that constructs anitem-item graph, filters noise through community detection, and enrichesuser-item interactions. Graph Convolutional Networks (GCNs) are then employedto learn short-term representations, while averaging, GRUs, and attentionmechanisms are utilized to model long-term embeddings. An MLP-based adaptiveweighting strategy is further incorporated to dynamically optimize long-termuser preferences. Experiments conducted on four real-world datasets demonstratethat ALDA4Rec outperforms state-of-the-art baselines, delivering notableimprovements in both accuracy and robustness. The source code is available athttps://github.com/zahraakhlaghi/ALDA4Rec.</description>
      <author>example@mail.com (Zahra Akhlaghi, Mostafa Haghir Chehreghani)</author>
      <guid isPermaLink="false">2504.13614v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Designing a reliable lateral movement detector using a graph foundation model</title>
      <link>http://arxiv.org/abs/2504.13527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基础模型在网络安全领域的应用潜力，特别是通过图基础模型（GFMs）在横向移动检测中的实用性。&lt;h4&gt;背景&lt;/h4&gt;基础模型作为机器学习的新范式，通过在大规模和多样化的数据集上预训练，可以应用于各种下游任务，无需或仅需少量再训练。&lt;h4&gt;目的&lt;/h4&gt;研究GFMs在网络安全领域的可用性，特别是通过横向移动检测这一具体用例。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的GFM构建检测器，并在无需针对特定领域数据进行训练的情况下达到最先进的性能。&lt;h4&gt;主要发现&lt;/h4&gt;GFMs在横向移动检测中表现出色，证明了其在网络安全领域的潜力。&lt;h4&gt;结论&lt;/h4&gt;GFMs在网络安全领域具有应用前景，有望加速创新。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近，基础模型作为机器学习（ML）的新范式而出现。这些模型在大规模和多样化的数据集上预训练，随后可以应用于各种下游任务，无需或仅需少量再训练。这使得没有高级ML专业知识的人也能构建ML应用，从而加速了许多领域的创新。然而，由于无法有效地处理网络流量捕获或二进制可执行文件等数据，基础模型在网络安全领域的应用受到阻碍。最近引入的图基础模型（GFMs）可能带来重大差异，因为图非常适合表示这些类型的数据。我们通过一个具体用例，即横向移动检测，来研究GFMs在网络安全中的可用性。使用预训练的GFM，我们构建了一个检测器，在不要求对特定领域数据进行任何训练的情况下达到了最先进的性能。因此，这项案例研究提供了关于GFMs在网络安全领域潜力的有力证据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have recently emerged as a new paradigm in machine learning(ML). These models are pre-trained on large and diverse datasets and cansubsequently be applied to various downstream tasks with little or noretraining. This allows people without advanced ML expertise to build MLapplications, accelerating innovation across many fields. However, the adoptionof foundation models in cybersecurity is hindered by their inability toefficiently process data such as network traffic captures or binaryexecutables. The recent introduction of graph foundation models (GFMs) couldmake a significant difference, as graphs are well-suited to representing thesetypes of data. We study the usability of GFMs in cybersecurity through the lensof one specific use case, namely lateral movement detection. Using apre-trained GFM, we build a detector that reaches state-of-the-art performancewithout requiring any training on domain-specific data. This case study thusprovides compelling evidence of the potential of GFMs for cybersecurity.</description>
      <author>example@mail.com (Corentin Larroche)</author>
      <guid isPermaLink="false">2504.13527v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Weak Cube R-CNN: Weakly Supervised 3D Detection using only 2D Bounding Boxes</title>
      <link>http://arxiv.org/abs/2504.13297v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 5 figures. Accepted for 23rd Scandinavian Conference, SCIA  2025, Reykjavik, Iceland&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种弱监督的3D检测方法，用于减少数据需求，通过单目方法利用单个摄像头系统来减少昂贵的光达传感器或多摄像头设置的依赖。&lt;h4&gt;背景&lt;/h4&gt;单目3D目标检测在计算机视觉中至关重要，并在机器人和虚拟现实领域有广泛应用。然而，3D检测器通常以完全监督的方式进行训练，依赖于劳动密集且昂贵的3D标注数据。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过使用弱监督方法，降低对3D标注数据的依赖，同时提高检测精度。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种名为Weak Cube R-CNN的通用模型，该模型能够在推理时预测3D物体，仅需要2D框标注进行训练，通过利用3D立方体的二维投影之间的关系。该方法利用预训练的冻结基础2D模型来估计训练集中的深度和方向信息，并在训练过程中将这些估计值作为伪真实标签。设计损失函数时，通过结合外部模型的信息来避免3D标签。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与标注时间相等的Cube R-CNN基线相比，该方法在SUN RGB-D数据集上提高了准确性。虽然该方法在厘米级测量上不够精确，但为未来的研究提供了一个强大的基础。&lt;h4&gt;结论&lt;/h4&gt;该方法为3D检测提供了一种减少对3D标注数据依赖的新途径，为未来的研究奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D object detection is an essential task in computer vision, and ithas several applications in robotics and virtual reality. However, 3D objectdetectors are typically trained in a fully supervised way, relying extensivelyon 3D labeled data, which is labor-intensive and costly to annotate. This workfocuses on weakly-supervised 3D detection to reduce data needs using amonocular method that leverages a singlecamera system over expensive LiDARsensors or multi-camera setups. We propose a general model Weak Cube R-CNN,which can predict objects in 3D at inference time, requiring only 2D boxannotations for training by exploiting the relationship between 2D projectionsof 3D cubes. Our proposed method utilizes pre-trained frozen foundation 2Dmodels to estimate depth and orientation information on a training set. We usethese estimated values as pseudo-ground truths during training. We design lossfunctions that avoid 3D labels by incorporating information from the externalmodels into the loss. In this way, we aim to implicitly transfer knowledge fromthese large foundation 2D models without having access to 3D bounding boxannotations. Experimental results on the SUN RGB-D dataset show increasedperformance in accuracy compared to an annotation time equalized Cube R-CNNbaseline. While not precise for centimetre-level measurements, this methodprovides a strong foundation for further research.</description>
      <author>example@mail.com (Andreas Lau Hansen, Lukas Wanzeck, Dim P. Papadopoulos)</author>
      <guid isPermaLink="false">2504.13297v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Propagation of Asymmetric Feature Pyramid for Surgical Scene Segmentation</title>
      <link>http://arxiv.org/abs/2504.13440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种用于手术场景分割的新方法，旨在解决现有方法在处理静态图像限制和动态视频复杂性时的挑战。&lt;h4&gt;背景&lt;/h4&gt;手术场景分割对于机器人辅助腹腔镜手术的理解至关重要，但现有方法面临静态图像限制和动态视频复杂性的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决手术视频流中空间特征提取和忽略时间依赖性的问题。&lt;h4&gt;方法&lt;/h4&gt;该方法名为时间非对称特征传播网络，是一种双向注意力架构，允许跨帧特征传播。它包含一个时间查询传播器，用于整合多方向一致性约束以增强帧特定特征表示，以及一个聚合的非对称特征金字塔模块，用于保留解剖结构和手术器械的判别性特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在两个公共基准测试上进行了评估，结果显示其在EndoVis2018上比当前SOTA方法提高了16.4%的mIoU，在Endoscapes2023上提高了3.3%的mAP。&lt;h4&gt;结论&lt;/h4&gt;该方法通过提供时间指导和上下文推理，为手术场景理解提供了一种独特的框架，并在性能上优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgical scene segmentation is crucial for robot-assisted laparoscopicsurgery understanding. Current approaches face two challenges: (i) static imagelimitations including ambiguous local feature similarities and fine-grainedstructural details, and (ii) dynamic video complexities arising from rapidinstrument motion and persistent visual occlusions. While existing methodsmainly focus on spatial feature extraction, they fundamentally overlooktemporal dependencies in surgical video streams. To address this, we presenttemporal asymmetric feature propagation network, a bidirectional attentionarchitecture enabling cross-frame feature propagation. The proposed methodcontains a temporal query propagator that integrates multi-directionalconsistency constraints to enhance frame-specific feature representation, andan aggregated asymmetric feature pyramid module that preserves discriminativefeatures for anatomical structures and surgical instruments. Our frameworkuniquely enables both temporal guidance and contextual reasoning for surgicalscene understanding. Comprehensive evaluations on two public benchmarks showthe proposed method outperforms the current SOTA methods by a large margin,with +16.4\% mIoU on EndoVis2018 and +3.3\% mAP on Endoscapes2023. The codewill be publicly available after paper acceptance.</description>
      <author>example@mail.com (Cheng Yuan, Yutong Ban)</author>
      <guid isPermaLink="false">2504.13440v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>MetaDSE: A Few-shot Meta-learning Framework for Cross-workload CPU Design Space Exploration</title>
      <link>http://arxiv.org/abs/2504.13568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 6 figures. Accepted by DAC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的跨工作负载CPU架构设计空间探索（DSE）方法，称为MetaDSE，旨在解决现有DSE方法中存在的过拟合、数据模糊性和工作负载差异等问题。&lt;h4&gt;背景&lt;/h4&gt;现有的跨工作负载设计空间探索方法通常使用迁移学习技术，从源工作负载中利用知识，以减少目标工作负载的模拟需求。&lt;h4&gt;目的&lt;/h4&gt;通过将跨工作负载CPU DSE任务重新定义为几样本元学习问题，并引入MetaDSE，旨在提高跨工作负载CPU DSE的效率。&lt;h4&gt;方法&lt;/h4&gt;MetaDSE利用模型无关的元学习来快速适应新的目标工作负载，并引入了一种称为工作负载自适应架构掩码算法的新颖知识迁移方法，以揭示架构的固有属性。&lt;h4&gt;主要发现&lt;/h4&gt;在SPEC CPU 2017上的实验表明，与最先进的方法相比，MetaDSE将预测误差减少了44.3%。&lt;h4&gt;结论&lt;/h4&gt;MetaDSE是一种高效且准确的设计空间探索方法，其开源代码可在GitHub上获取。&lt;h4&gt;翻译&lt;/h4&gt;摘要：跨工作负载设计空间探索（DSE）在CPU架构设计中至关重要。现有的DSE方法通常采用迁移学习技术来利用源工作负载的知识，旨在最小化目标工作负载的模拟需求。然而，这些方法在过拟合、数据模糊性和工作负载差异方面存在困难。为了解决这些挑战，我们将跨工作负载CPU DSE任务重新定义为几样本元学习问题，并进一步引入MetaDSE。通过利用模型无关的元学习，MetaDSE快速适应新的目标工作负载，大大提高了跨工作负载CPU DSE的效率。此外，MetaDSE引入了一种名为工作负载自适应架构掩码算法的新颖知识迁移方法，以揭示架构的固有属性。在SPEC CPU 2017上的实验表明，与最先进的方法相比，MetaDSE将预测误差减少了44.3%。MetaDSE是开源的，可在https://anonymous.4open.science/r/Meta_DSE-02F8的匿名GitHub上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-workload design space exploration (DSE) is crucial in CPU architecturedesign. Existing DSE methods typically employ the transfer learning techniqueto leverage knowledge from source workloads, aiming to minimize the requirementof target workload simulation. However, these methods struggle withoverfitting, data ambiguity, and workload dissimilarity.  To address these challenges, we reframe the cross-workload CPU DSE task as afew-shot meta-learning problem and further introduce MetaDSE. By leveragingmodel agnostic meta-learning, MetaDSE swiftly adapts to new target workloads,greatly enhancing the efficiency of cross-workload CPU DSE. Additionally,MetaDSE introduces a novel knowledge transfer method called theworkload-adaptive architectural mask algorithm, which uncovers the inherentproperties of the architecture. Experiments on SPEC CPU 2017 demonstrate thatMetaDSE significantly reduces prediction error by 44.3\% compared to thestate-of-the-art. MetaDSE is open-sourced and available at this\href{https://anonymous.4open.science/r/Meta_DSE-02F8}{anonymous GitHub.}</description>
      <author>example@mail.com (Runzhen Xue, Hao Wu, Mingyu Yan, Ziheng Xiao, Xiaochun Ye, Dongrui Fan)</author>
      <guid isPermaLink="false">2504.13568v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>ViG3D-UNet: Volumetric Vascular Connectivity-Aware Segmentation via 3D Vision Graph Representation</title>
      <link>http://arxiv.org/abs/2504.13599v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为ViG3D-UNet的3D视觉图神经网络框架，用于血管分割，以解决现有方法在血管连续分割和端点缺失问题上的挑战。&lt;h4&gt;背景&lt;/h4&gt;精确的血管分割对于冠状动脉可视化和冠心病诊断至关重要。然而，现有的血管分割方法面临着血管连续分割不连续和端点缺失的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改进血管分割的连续性和准确性。&lt;h4&gt;方法&lt;/h4&gt;ViG3D-UNet方法结合了3D图表示和聚合在一个U型架构中，以促进连续的血管分割。ViG3D模块捕获体积血管连通性和拓扑结构，而卷积模块提取精细的血管细节。这两个分支通过通道注意力结合形成编码器特征。随后，一个纸夹形状的偏移解码器在稀疏特征空间中减少冗余计算，并将特征图尺寸恢复到原始输入尺寸。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公共数据集ASOCA和ImageCAS上的评估表明，ViG3D-UNet在保持血管分割连通性的同时，实现了高分割精度，超过了竞争方法。&lt;h4&gt;结论&lt;/h4&gt;ViG3D-UNet是一种有效的血管分割方法，能够提高血管连续分割的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;Accurate vascular segmentation is essential for coronary visualization and the diagnosis of coronary heart disease. This task involves the extraction of sparse tree-like vascular branches from the volumetric space. However, existing methods have faced significant challenges due to discontinuous vascular segmentation and missing endpoints. To address this issue, a 3D vision graph neural network framework, named ViG3D-UNet, was introduced. This method integrates 3D graph representation and aggregation within a U-shaped architecture to facilitate continuous vascular segmentation. The ViG3D module captures volumetric vascular connectivity and topology, while the convolutional module extracts fine vascular details. These two branches are combined through channel attention to form the encoder feature. Subsequently, a paperclip-shaped offset decoder minimizes redundant computations in the sparse feature space and restores the feature map size to match the original input dimensions. To evaluate the effectiveness of the proposed approach for continuous vascular segmentation, evaluations were performed on two public datasets, ASOCA and ImageCAS. The segmentation results show that the ViG3D-UNet surpassed competing methods in maintaining vascular segmentation connectivity while achieving high segmentation accuracy. Our code will be available soon.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate vascular segmentation is essential for coronary visualization andthe diagnosis of coronary heart disease. This task involves the extraction ofsparse tree-like vascular branches from the volumetric space. However, existingmethods have faced significant challenges due to discontinuous vascularsegmentation and missing endpoints. To address this issue, a 3D vision graphneural network framework, named ViG3D-UNet, was introduced. This methodintegrates 3D graph representation and aggregation within a U-shapedarchitecture to facilitate continuous vascular segmentation. The ViG3D modulecaptures volumetric vascular connectivity and topology, while the convolutionalmodule extracts fine vascular details. These two branches are combined throughchannel attention to form the encoder feature. Subsequently, a paperclip-shapedoffset decoder minimizes redundant computations in the sparse feature space andrestores the feature map size to match the original input dimensions. Toevaluate the effectiveness of the proposed approach for continuous vascularsegmentation, evaluations were performed on two public datasets, ASOCA andImageCAS. The segmentation results show that the ViG3D-UNet surpassed competingmethods in maintaining vascular segmentation connectivity while achieving highsegmentation accuracy. Our code will be available soon.</description>
      <author>example@mail.com (Bowen Liu, Chunlei Meng, Wei Lin, Hongda Zhang, Ziqing Zhou, Zhongxue Gan, Chun Ouyang)</author>
      <guid isPermaLink="false">2504.13599v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>A Reinforcement Learning Method to Factual and Counterfactual Explanations for Session-based Recommendation</title>
      <link>http://arxiv.org/abs/2504.13632v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FCESR的新型框架，用于解释会话推荐系统（SR）的预测，通过强调推荐项的充分性（事实性）和必要性（反事实性），提升推荐系统的透明度和可信度。&lt;h4&gt;背景&lt;/h4&gt;现有的会话推荐系统虽然取得了显著成功，但其复杂的“黑盒”性质往往难以解释推荐的原因，现有解释方法难以准确指出真正有影响力的因素。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架，能够揭示会话推荐系统推荐背后的真正原因，并提升推荐系统的透明度和可信度。&lt;h4&gt;方法&lt;/h4&gt;FCESR通过将解释生成视为组合优化挑战，并利用强化学习，发现影响推荐的最小但关键的商品序列。同时，创新性地利用这些事实性和反事实洞察，在对比学习范式下作为高质量的正负样本，以微调和显著提高会话推荐系统的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;FCESR框架不仅提高了推荐准确性，还显著提升了解释的质量和可解释性。&lt;h4&gt;结论&lt;/h4&gt;FCESR框架为更透明、更可信的推荐系统铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Session-based Recommendation (SR) systems have recently achieved considerable success, yet their complex, 'black box' nature often obscures why certain recommendations are made. Existing explanation methods struggle to pinpoint truly influential factors, as they frequently depend on static user profiles or fail to grasp the intricate dynamics within user sessions. In response, we introduce FCESR (Factual and Counterfactual Explanations for Session-based Recommendation), a novel framework designed to illuminate SR model predictions by emphasizing both the sufficiency (factual) and necessity (counterfactual) of recommended items. By recasting explanation generation as a combinatorial optimization challenge and leveraging reinforcement learning, our method uncovers the minimal yet critical sequence of items influencing recommendations. Moreover, recognizing the intrinsic value of robust explanations, we innovatively utilize these factual and counterfactual insights within a contrastive learning paradigm, employing them as high-quality positive and negative samples to fine-tune and significantly enhance SR accuracy. Extensive qualitative and quantitative evaluations across diverse datasets and multiple SR architectures confirm that our framework not only boosts recommendation accuracy but also markedly elevates the quality and interpretability of explanations, thereby paving the way for more transparent and trustworthy recommendation systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Session-based Recommendation (SR) systems have recently achieved considerablesuccess, yet their complex, "black box" nature often obscures why certainrecommendations are made. Existing explanation methods struggle to pinpointtruly influential factors, as they frequently depend on static user profiles orfail to grasp the intricate dynamics within user sessions. In response, weintroduce FCESR (Factual and Counterfactual Explanations for Session-basedRecommendation), a novel framework designed to illuminate SR model predictionsby emphasizing both the sufficiency (factual) and necessity (counterfactual) ofrecommended items. By recasting explanation generation as a combinatorialoptimization challenge and leveraging reinforcement learning, our methoduncovers the minimal yet critical sequence of items influencingrecommendations. Moreover, recognizing the intrinsic value of robustexplanations, we innovatively utilize these factual and counterfactual insightswithin a contrastive learning paradigm, employing them as high-quality positiveand negative samples to fine-tune and significantly enhance SR accuracy.Extensive qualitative and quantitative evaluations across diverse datasets andmultiple SR architectures confirm that our framework not only boostsrecommendation accuracy but also markedly elevates the quality andinterpretability of explanations, thereby paving the way for more transparentand trustworthy recommendation systems.</description>
      <author>example@mail.com (Han Zhou, Hui Fang, Zhu Sun, Wentao Hu)</author>
      <guid isPermaLink="false">2504.13632v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>SatelliteCalculator: A Multi-Task Vision Foundation Model for Quantitative Remote Sensing Inversion</title>
      <link>http://arxiv.org/abs/2504.13442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SatelliteCalculator，这是一种针对定量遥感反演的视觉基础模型，旨在解决遥感数据在生态变量估计中的挑战。&lt;h4&gt;背景&lt;/h4&gt;定量遥感反演在环境监测中至关重要，但视觉基础模型在物理可解释回归中的应用尚未充分探索，且遥感数据的多元光谱和地理空间异质性给泛化和迁移性带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发SatelliteCalculator，以解决遥感数据在生态变量估计中的挑战，并验证基础模型在定量反演中的应用可行性。&lt;h4&gt;方法&lt;/h4&gt;SatelliteCalculator利用物理定义的指数公式自动构建了一个包含超过一百万对样本的大型数据集，并集成了冻结的Swin Transformer骨干网络和提示引导架构，包括交叉注意力适配器和轻量级任务特定MLP解码器。&lt;h4&gt;主要发现&lt;/h4&gt;在Open-Canopy基准测试中，SatelliteCalculator在所有任务上实现了具有竞争力的准确率，同时显著降低了推理成本。&lt;h4&gt;结论&lt;/h4&gt;研究结果验证了将基础模型应用于定量反演的可行性，并为任务自适应遥感估计提供了一个可扩展的框架。&lt;h4&gt;翻译&lt;/h4&gt;摘要：定量遥感反演在环境监测中发挥着关键作用，它使得估计关键生态变量（如植被指数、冠层结构和碳储量）成为可能。尽管视觉基础模型在分类和分割任务上取得了显著的进展，但它们在物理可解释回归中的应用仍然鲜有探索。此外，遥感数据的多元光谱特性和地理空间异质性为泛化和迁移性带来了重大挑战。为了解决这些问题，我们引入了SatelliteCalculator，这是第一个针对定量遥感反演定制的视觉基础模型。通过利用物理定义的指数公式，我们自动构建了一个包含超过一百万对样本的大型数据集，涵盖了八个核心生态指标。该模型集成了冻结的Swin Transformer骨干网络和提示引导架构，包括交叉注意力适配器和轻量级任务特定MLP解码器。在Open-Canopy基准测试中进行的实验表明，SatelliteCalculator在所有任务上实现了具有竞争力的准确率，同时显著降低了推理成本。我们的结果验证了将基础模型应用于定量反演的可行性，并为任务自适应遥感估计提供了一个可扩展的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantitative remote sensing inversion plays a critical role in environmentalmonitoring, enabling the estimation of key ecological variables such asvegetation indices, canopy structure, and carbon stock. Although visionfoundation models have achieved remarkable progress in classification andsegmentation tasks, their application to physically interpretable regressionremains largely unexplored. Furthermore, the multi-spectral nature andgeospatial heterogeneity of remote sensing data pose significant challenges forgeneralization and transferability. To address these issues, we introduceSatelliteCalculator, the first vision foundation model tailored forquantitative remote sensing inversion. By leveraging physically defined indexformulas, we automatically construct a large-scale dataset of over one millionpaired samples across eight core ecological indicators. The model integrates afrozen Swin Transformer backbone with a prompt-guided architecture, featuringcross-attentive adapters and lightweight task-specific MLP decoders.Experiments on the Open-Canopy benchmark demonstrate that SatelliteCalculatorachieves competitive accuracy across all tasks while significantly reducinginference cost. Our results validate the feasibility of applying foundationmodels to quantitative inversion, and provide a scalable framework fortask-adaptive remote sensing estimation.</description>
      <author>example@mail.com (Zhenyu Yu, Mohd. Yamani Idna Idris, Pei Wang)</author>
      <guid isPermaLink="false">2504.13442v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>A Deep Learning-Based Supervised Transfer Learning Framework for DOA Estimation with Array Imperfections</title>
      <link>http://arxiv.org/abs/2504.13394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的迁移学习策略，有效缓解了阵列不完美对深度学习DOA估计性能的影响。&lt;h4&gt;背景&lt;/h4&gt;在实际场景中，传感器设计、制造和安装过程中会引入误差，传感器接收信号时也会发生相互干扰，这些缺陷称为阵列不完美，会显著降低DOA估计的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法以缓解阵列不完美对DOA估计性能的降低。&lt;h4&gt;方法&lt;/h4&gt;1. 提出基于Vision Transformer (ViT)的DOA估计方法，在低信噪比和有限快照的情景下表现优异。2. 引入迁移学习框架，将深度学习模型从理想仿真场景扩展到存在阵列不完美的复杂真实场景。3. 通过利用理想仿真数据的先验知识，显著提高存在阵列不完美时深度学习DOA估计的性能，而无需大量真实世界数据。4. 结合可视化工具和评估指标来评估DOA估计算法的性能。&lt;h4&gt;主要发现&lt;/h4&gt;1. 基于ViT的DOA估计方法在低信噪比和有限快照的情景下具有优异性能。2. 迁移学习框架显著提高了DOA估计性能。3. 可视化和评估指标有助于更全面地评估算法并验证所提出的方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于深度学习的迁移学习策略能够有效缓解阵列不完美对DOA估计性能的影响，提高了算法的实用性。&lt;h4&gt;翻译&lt;/h4&gt;In practical scenarios, processes such as sensor design, manufacturing, and installation will introduce certain errors. Furthermore, mutual interference occurs when the sensors receive signals. These defects in array systems are referred to as array imperfections, which can significantly degrade the performance of Direction of Arrival (DOA) estimation. In this study, we propose a deep-learning based transfer learning approach, which effectively mitigates the degradation of deep-learning based DOA estimation performance caused by array imperfections. In the proposed approach, we highlight three major contributions. First, we propose a Vision Transformer (ViT) based method for DOA estimation, which achieves excellent performance in scenarios with low signal-to-noise ratios (SNR) and limited snapshots. Second, we introduce a transfer learning framework that extends deep learning models from ideal simulation scenarios to complex real-world scenarios with array imperfections. By leveraging prior knowledge from ideal simulation data, the proposed transfer learning framework significantly improves deep learning-based DOA estimation performance in the presence of array imperfections, without the need for extensive real-world data. Finally, we incorporate visualization and evaluation metrics to assess the performance of DOA estimation algorithms, which allow for a more thorough evaluation of algorithms and further validate the proposed method. Our code can be accessed at https://github.com/zzb-nice/DOA_est_Master.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In practical scenarios, processes such as sensor design, manufacturing, andinstallation will introduce certain errors. Furthermore, mutual interferenceoccurs when the sensors receive signals. These defects in array systems arereferred to as array imperfections, which can significantly degrade theperformance of Direction of Arrival (DOA) estimation. In this study, we proposea deep-learning based transfer learning approach, which effectively mitigatesthe degradation of deep-learning based DOA estimation performance caused byarray imperfections.  In the proposed approach, we highlight three major contributions. First, wepropose a Vision Transformer (ViT) based method for DOA estimation, whichachieves excellent performance in scenarios with low signal-to-noise ratios(SNR) and limited snapshots. Second, we introduce a transfer learning frameworkthat extends deep learning models from ideal simulation scenarios to complexreal-world scenarios with array imperfections. By leveraging prior knowledgefrom ideal simulation data, the proposed transfer learning frameworksignificantly improves deep learning-based DOA estimation performance in thepresence of array imperfections, without the need for extensive real-worlddata. Finally, we incorporate visualization and evaluation metrics to assessthe performance of DOA estimation algorithms, which allow for a more thoroughevaluation of algorithms and further validate the proposed method. Our code canbe accessed at https://github.com/zzb-nice/DOA_est_Master.</description>
      <author>example@mail.com (Bo Zhou, Kaijie Xu, Yinghui Quan, Mengdao Xing)</author>
      <guid isPermaLink="false">2504.13394v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Mono3R: Exploiting Monocular Cues for Geometric 3D Reconstruction</title>
      <link>http://arxiv.org/abs/2504.13419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个基于单目几何估计的改进方法，以提高多视角3D重建的鲁棒性，特别是在弱纹理区域和低光照条件下。&lt;h4&gt;背景&lt;/h4&gt;近年来，数据驱动的几何多视角3D重建基础模型（如DUSt3R）在各种3D视觉任务中表现出色，得益于大规模、高质量的3D数据集的发布。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有模型在匹配原则下的局限性，特别是在具有有限匹配线索的挑战区域（如弱纹理区域和低光照条件）中的重建质量下降问题。&lt;h4&gt;方法&lt;/h4&gt;引入了一个单目引导的细化模块，该模块将单目几何先验集成到多视角重建框架中，从而增强了多视角重建系统的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个基准测试中实现了显著的改进，包括多视角相机姿态估计和点云精度。&lt;h4&gt;结论&lt;/h4&gt;通过将单目几何估计与多视角重建相结合，可以显著提高重建质量，特别是在具有挑战性的区域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in data-driven geometric multi-view 3D reconstructionfoundation models (e.g., DUSt3R) have shown remarkable performance acrossvarious 3D vision tasks, facilitated by the release of large-scale,high-quality 3D datasets. However, as we observed, constrained by theirmatching-based principles, the reconstruction quality of existing modelssuffers significant degradation in challenging regions with limited matchingcues, particularly in weakly textured areas and low-light conditions. Tomitigate these limitations, we propose to harness the inherent robustness ofmonocular geometry estimation to compensate for the inherent shortcomings ofmatching-based methods. Specifically, we introduce a monocular-guidedrefinement module that integrates monocular geometric priors into multi-viewreconstruction frameworks. This integration substantially enhances therobustness of multi-view reconstruction systems, leading to high-qualityfeed-forward reconstructions. Comprehensive experiments across multiplebenchmarks demonstrate that our method achieves substantial improvements inboth mutli-view camera pose estimation and point cloud accuracy.</description>
      <author>example@mail.com (Wenyu Li, Sidun Liu, Peng Qiao, Yong Dou)</author>
      <guid isPermaLink="false">2504.13419v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>AI-Empowered Integrated Sensing and Communications</title>
      <link>http://arxiv.org/abs/2504.13363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 10 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在集成感知与通信（ISAC）设计中应用人工智能（AI）以提升效率和降低复杂度。&lt;h4&gt;背景&lt;/h4&gt;ISAC技术有助于克服频谱有限和硬件昂贵的挑战，从而提高能源和成本效率。&lt;h4&gt;目的&lt;/h4&gt;实现ISAC的最佳性能需要高效的设计，包括统一波形和波束成形器。&lt;h4&gt;方法&lt;/h4&gt;文章强调了通过AI驱动的ISAC设计实现集成优势，重点发展统一波形、星座和波束成形策略。&lt;h4&gt;主要发现&lt;/h4&gt;案例研究表明，无监督学习和基于神经网络的优化可以有效平衡性能、复杂性和实施约束。&lt;h4&gt;结论&lt;/h4&gt;AI在ISAC设计中的应用有助于提高效率并减少复杂性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：整合感知与通信（ISAC）可以帮助克服频谱有限和硬件昂贵的挑战，从而提高能源和成本效率。虽然感知与通信之间的完全合作可以带来显著的性能提升，但要实现最佳性能，需要为联合感知和通信任务设计高效的统一波形和波束成形器。复杂的统计信号处理和多目标优化技术对于平衡联合感知和通信任务的设计要求是必要的。由于基于模型的解析方法可能是不最优的或过于复杂，深度学习作为一种强大的工具，在开发数据驱动的信号处理算法方面脱颖而出，尤其是在最优算法未知或已知算法过于复杂难以实时实现时。ISAC的统一波形和波束成形器设计问题属于此类问题，其中感知和通信性能指标之间存在基本的设计权衡，而基础模型可能是不充分或不完整的。本文探讨了在ISAC设计中应用人工智能（AI）以增强效率和降低复杂度。我们强调通过AI驱动的ISAC设计实现集成优势，优先发展统一波形、星座和波束成形策略。为了展示AI驱动的ISAC的实践潜力，我们展示了波形和波束成形设计的两个案例研究，展示了无监督学习和基于神经网络的优化如何有效地平衡性能、复杂性和实施约束。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating sensing and communication (ISAC) can help overcome the challengesof limited spectrum and expensive hardware, leading to improved energy and costefficiency. While full cooperation between sensing and communication can resultin significant performance gains, achieving optimal performance requiresefficient designs of unified waveforms and beamformers for joint sensing andcommunication. Sophisticated statistical signal processing and multi-objectiveoptimization techniques are necessary to balance the competing designrequirements of joint sensing and communication tasks. Since model-basedanalytical approaches may be suboptimal or overly complex, deep learningemerges as a powerful tool for developing data-driven signal processingalgorithms, particularly when optimal algorithms are unknown or when knownalgorithms are too complex for real-time implementation. Unified waveform andbeamformer design problems for ISAC fall into this category, where fundamentaldesign trade-offs exist between sensing and communication performance metrics,and the underlying models may be inadequate or incomplete. This articleexplores the application of artificial intelligence (AI) in ISAC designs toenhance efficiency and reduce complexity. We emphasize the integration benefitsthrough AI-driven ISAC designs, prioritizing the development of unifiedwaveforms, constellations, and beamforming strategies for both sensing andcommunication. To illustrate the practical potential of AI-driven ISAC, wepresent two case studies on waveform and beamforming design, demonstrating howunsupervised learning and neural network-based optimization can effectivelybalance performance, complexity, and implementation constraints.</description>
      <author>example@mail.com (Mojtaba Vaezi, Gayan Aruma Baduge, Esa Ollila, Sergiy A. Vorobyov)</author>
      <guid isPermaLink="false">2504.13363v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs</title>
      <link>http://arxiv.org/abs/2504.13429v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2302.02914 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出NODESAFE，通过限制节点极端分数的产生，显著提高图神经网络（GNNs）在检测节点级异常数据（OOD）方面的能力。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在现实世界应用中扮演着关键角色，并且对安全性要求高。检测异常数据是提高GNNs性能的重要问题。&lt;h4&gt;目的&lt;/h4&gt;提高GNNs检测节点级异常数据的能力。&lt;h4&gt;方法&lt;/h4&gt;通过添加两个优化项，限制负能量分数的范围并减轻logit偏移，减少节点极端分数的产生。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法显著提高了GNNs检测节点级异常数据的能力，例如在检测结构操作引起的异常数据时，FPR95指标在无（有）异常数据暴露的情景下比现有SOTA降低了28.4%（22.7%）。&lt;h4&gt;结论&lt;/h4&gt;NODESAFE方法有效地提高了GNNs检测节点级异常数据的能力，为GNNs在实际应用中的安全性提供了保障。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Given the critical role of graphs in real-world applications and theirhigh-security requirements, improving the ability of graph neural networks(GNNs) to detect out-of-distribution (OOD) data is an urgent research problem.The recent work GNNSAFE proposes a framework based on the aggregation ofnegative energy scores that significantly improves the performance of GNNs todetect node-level OOD data. However, our study finds that score aggregationamong nodes is susceptible to extreme values due to the unboundedness of thenegative energy scores and logit shifts, which severely limits the accuracy ofGNNs in detecting node-level OOD data. In this paper, we propose NODESAFE:reducing the generation of extreme scores of nodes by adding two optimizationterms that make the negative energy scores bounded and mitigate the logitshift. Experimental results show that our approach dramatically improves theability of GNNs to detect OOD data at the node level, e.g., in detecting OODdata induced by Structure Manipulation, the metric of FPR95 (lower is better)in scenarios without (with) OOD data exposure are reduced from the current SOTAby 28.4% (22.7%).</description>
      <author>example@mail.com (Shenzhi Yang, Bin Liang, An Liu, Lin Gui, Xingkai Yao, Xiaofang Zhang)</author>
      <guid isPermaLink="false">2504.13429v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>WeatherGen: A Unified Diverse Weather Generator for LiDAR Point Clouds via Spider Mamba Diffusion</title>
      <link>http://arxiv.org/abs/2504.13561v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了WeatherGen，一个统一的多样化天气LiDAR数据扩散生成框架，显著提高了生成数据的保真度。&lt;h4&gt;背景&lt;/h4&gt;3D场景感知需要大量的恶劣天气LiDAR数据，但LiDAR数据收集的成本很高，这是一个重大的扩展挑战。&lt;h4&gt;目的&lt;/h4&gt;提高LiDAR数据在恶劣天气条件下的保真度和可用性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个基于地图的数据生成器，提供大量高质量的多样化天气数据用于训练。利用扩散去噪范式构建扩散模型，提出了一种蜘蛛蟒生成器来逐步恢复被干扰的多样化天气数据。设计了潜在特征对齐器和基于对比学习的控制器，通过语言监督为天气控制信号赋予紧凑的语义知识，指导扩散模型生成更具判别性的数据。&lt;h4&gt;主要发现&lt;/h4&gt;WeatherGen显著提高了LiDAR数据在多样化天气条件下的生成质量，并构建了mini-weather数据集，促进了下游任务在恶劣天气条件下的性能。&lt;h4&gt;结论&lt;/h4&gt;WeatherGen是一个有效的工具，可以生成高质量的LiDAR数据，有助于提高恶劣天气条件下的3D场景感知性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes WeatherGen, a unified diverse-weather LiDAR data diffusion generation framework that significantly improves the fidelity of the generated data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D scene perception demands a large amount of adverse-weather LiDAR data, yetthe cost of LiDAR data collection presents a significant scaling-up challenge.To this end, a series of LiDAR simulators have been proposed. Yet, they canonly simulate a single adverse weather with a single physical model, and thefidelity of the generated data is quite limited. This paper presentsWeatherGen, the first unified diverse-weather LiDAR data diffusion generationframework, significantly improving fidelity. Specifically, we first design amap-based data producer, which can provide a vast amount of high-qualitydiverse-weather data for training purposes. Then, we utilize thediffusion-denoising paradigm to construct a diffusion model. Among them, wepropose a spider mamba generator to restore the disturbed diverse weather datagradually. The spider mamba models the feature interactions by scanning theLiDAR beam circle or central ray, excellently maintaining the physicalstructure of the LiDAR data. Subsequently, following the generator to transferreal-world knowledge, we design a latent feature aligner. Afterward, we devisea contrastive learning-based controller, which equips weather control signalswith compact semantic knowledge through language supervision, guiding thediffusion model to generate more discriminative data. Extensive evaluationsdemonstrate the high generation quality of WeatherGen. Through WeatherGen, weconstruct the mini-weather dataset, promoting the performance of the downstreamtask under adverse weather conditions. Code is available:https://github.com/wuyang98/weathergen</description>
      <author>example@mail.com (Yang Wu, Yun Zhu, Kaihua Zhang, Jianjun Qian, Jin Xie, Jian Yang)</author>
      <guid isPermaLink="false">2504.13561v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating Enhanced Rotary Position Embedding</title>
      <link>http://arxiv.org/abs/2504.12643v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本技术报告提出针对StreamPETR框架的针对性改进，旨在提高速度估计能力，这是影响NuScenes检测得分的关键因素。&lt;h4&gt;背景&lt;/h4&gt;StreamPETR在3D边界框检测方面表现出色，平均精度均值较高，但在NuScenes数据集上的速度估计分析中被识别为一个瓶颈。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一限制，提出了一种定制化的位置嵌入策略，以增强时间建模能力。&lt;h4&gt;方法&lt;/h4&gt;在NuScenes测试集上进行了实验评估，使用了ViT-L主干网络。&lt;h4&gt;主要发现&lt;/h4&gt;改进后的方法使用ViT-L主干网络实现了70.86%的NDS，达到了最先进的水平，为仅使用摄像头的3D目标检测设定了新的基准。&lt;h4&gt;结论&lt;/h4&gt;通过改进的StreamPETR框架，显著提升了速度估计的准确性，为NuScenes数据集上的3D目标检测设定了新的性能标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report introduces a targeted improvement to the StreamPETRframework, specifically aimed at enhancing velocity estimation, a criticalfactor influencing the overall NuScenes Detection Score. While StreamPETRexhibits strong 3D bounding box detection performance as reflected by its highmean Average Precision our analysis identified velocity estimation as asubstantial bottleneck when evaluated on the NuScenes dataset. To overcome thislimitation, we propose a customized positional embedding strategy tailored toenhance temporal modeling capabilities. Experimental evaluations conducted onthe NuScenes test set demonstrate that our improved approach achieves astate-of-the-art NDS of 70.86% using the ViT-L backbone, setting a newbenchmark for camera-only 3D object detection.</description>
      <author>example@mail.com (Hang Ji, Tao Ni, Xufeng Huang, Tao Luo, Xin Zhan, Junbo Chen)</author>
      <guid isPermaLink="false">2504.12643v2</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Graph Learning at Scale: Characterizing and Optimizing Pre-Propagation GNNs</title>
      <link>http://arxiv.org/abs/2504.13266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）在图学习中应用中的邻居爆炸问题，并提出了预传播GNNs（PP-GNNs）来解决此问题。通过比较PP-GNNs与基于图采样的方法，文章分析了PP-GNNs在训练效率、可扩展性和准确性方面的表现，并提出了优化方案。&lt;h4&gt;背景&lt;/h4&gt;GNNs在图学习中应用广泛，但随着层数增加，其计算和内存需求呈指数增长，导致邻居爆炸问题。图采样是目前解决该问题的主流方法，但并未完全解决。&lt;h4&gt;目的&lt;/h4&gt;本文旨在全面描述PP-GNNs，并与基于图采样的方法进行比较，以分析其在训练效率、可扩展性和准确性方面的表现。&lt;h4&gt;方法&lt;/h4&gt;本文提出了优化数据加载方案和定制训练方法，以提高PP-GNNs的训练吞吐量，并在大型图基准测试上与基于采样的GNNs进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;PP-GNNs在准确性上与基于图采样的方法相当，但数据加载成为训练效率的关键瓶颈，而输入扩展是主要的可扩展性挑战。&lt;h4&gt;结论&lt;/h4&gt;通过优化数据加载方案和定制训练方法，PP-GNNs的训练吞吐量平均提高了15倍，与基于采样的GNNs相比，在大型图基准测试上的速度提高了两个数量级。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) are widely used for learning node embeddings in graphs, typically adopting a message-passing scheme. This approach, however, leads to the neighbor explosion problem, with exponentially growing computational and memory demands as layers increase. Graph sampling has become the predominant method for scaling GNNs to large graphs, mitigating but not fully solving the issue. Pre-propagation GNNs (PP-GNNs) represent a new class of models that decouple feature propagation from training through pre-processing, addressing neighbor explosion in theory. Yet, their practical advantages and system-level optimizations remain underexplored. This paper provides a comprehensive characterization of PP-GNNs, comparing them with graph-sampling-based methods in training efficiency, scalability, and accuracy. While PP-GNNs achieve comparable accuracy, we identify data loading as the key bottleneck for training efficiency and input expansion as a major scalability challenge. To address these issues, we propose optimized data loading schemes and tailored training methods that improve PP-GNN training throughput by an average of 15 times over the PP-GNN baselines, with speedup of up to 2 orders of magnitude compared to sampling-based GNNs on large graph benchmarks. Our implementation is publicly available at https://github.com/cornell-zhang/preprop-gnn.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are widely used for learning node embeddings ingraphs, typically adopting a message-passing scheme. This approach, however,leads to the neighbor explosion problem, with exponentially growingcomputational and memory demands as layers increase. Graph sampling has becomethe predominant method for scaling GNNs to large graphs, mitigating but notfully solving the issue. Pre-propagation GNNs (PP-GNNs) represent a new classof models that decouple feature propagation from training throughpre-processing, addressing neighbor explosion in theory. Yet, their practicaladvantages and system-level optimizations remain underexplored. This paperprovides a comprehensive characterization of PP-GNNs, comparing them withgraph-sampling-based methods in training efficiency, scalability, and accuracy.While PP-GNNs achieve comparable accuracy, we identify data loading as the keybottleneck for training efficiency and input expansion as a major scalabilitychallenge. To address these issues, we propose optimized data loading schemesand tailored training methods that improve PP-GNN training throughput by anaverage of 15$\times$ over the PP-GNN baselines, with speedup of up to 2 ordersof magnitude compared to sampling-based GNNs on large graph benchmarks. Ourimplementation is publicly available athttps://github.com/cornell-zhang/preprop-gnn.</description>
      <author>example@mail.com (Zichao Yue, Chenhui Deng, Zhiru Zhang)</author>
      <guid isPermaLink="false">2504.13266v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>CytoFM: The first cytology foundation model</title>
      <link>http://arxiv.org/abs/2504.13402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了CytoFM，第一个用于细胞学的自监督基础模型，通过iBOT框架进行预训练，用于提高细胞学图像的分析能力。&lt;h4&gt;背景&lt;/h4&gt;细胞学在癌症诊断和筛查中至关重要，但数字细胞学由于样本制备方法的异质性、器官间差异以及大量多样化标注数据集的有限可用性，发展稳健的深度学习模型具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出并开发了一个通用的自监督基础模型CytoFM，用于从细胞学数据中学习鲁棒和可迁移的特征。&lt;h4&gt;方法&lt;/h4&gt;使用iBOT，一个结合掩码图像建模和自蒸馏的自监督视觉Transformer（ViT）训练框架，在多样化的细胞学数据集上预训练CytoFM。使用基于注意力的多实例学习框架评估CytoFM在乳腺癌分类和细胞类型识别等下游细胞学任务上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;CytoFM在三个下游任务中有两个比在病理学（UNI）或自然图像（iBOT-Imagenet）上预训练的现有基础模型表现更好。可视化学习到的表示表明，该模型能够关注到与细胞学相关的特征。&lt;h4&gt;结论&lt;/h4&gt;尽管预训练数据集规模较小，但CytoFM的有望结果突出了无任务预训练方法从细胞学数据中学习鲁棒和可迁移特征的能力。&lt;h4&gt;翻译&lt;/h4&gt;Cytology is essential for cancer diagnostics and screening due to its minimally invasive nature. However, the development of robust deep learning models for digital cytology is challenging due to the heterogeneity in staining and preparation methods of samples, differences across organs, and the limited availability of large, diverse, annotated datasets. Developing a task-specific model for every cytology application is impractical and non-cytology-specific foundation models struggle to generalize to tasks in this domain where the emphasis is on cell morphology. To address these challenges, we introduce CytoFM, the first cytology self-supervised foundation model. Using iBOT, a self-supervised Vision Transformer (ViT) training framework incorporating masked image modeling and self-distillation, we pretrain CytoFM on a diverse collection of cytology datasets to learn robust, transferable representations. We evaluate CytoFM on multiple downstream cytology tasks, including breast cancer classification and cell type identification, using an attention-based multiple instance learning framework. Our results demonstrate that CytoFM performs better on two out of three downstream tasks than existing foundation models pretrained on histopathology (UNI) or natural images (iBOT-Imagenet). Visualizations of learned representations demonstrate our model is able to attend to cytologically relevant features. Despite a small pre-training dataset, CytoFM's promising results highlight the ability of task-agnostic pre-training approaches to learn robust and generalizable features from cytology data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cytology is essential for cancer diagnostics and screening due to itsminimally invasive nature. However, the development of robust deep learningmodels for digital cytology is challenging due to the heterogeneity in stainingand preparation methods of samples, differences across organs, and the limitedavailability of large, diverse, annotated datasets. Developing a task-specificmodel for every cytology application is impractical and non-cytology-specificfoundation models struggle to generalize to tasks in this domain where theemphasis is on cell morphology. To address these challenges, we introduceCytoFM, the first cytology self-supervised foundation model. Using iBOT, aself-supervised Vision Transformer (ViT) training framework incorporatingmasked image modeling and self-distillation, we pretrain CytoFM on a diversecollection of cytology datasets to learn robust, transferable representations.We evaluate CytoFM on multiple downstream cytology tasks, including breastcancer classification and cell type identification, using an attention-basedmultiple instance learning framework. Our results demonstrate that CytoFMperforms better on two out of three downstream tasks than existing foundationmodels pretrained on histopathology (UNI) or natural images (iBOT-Imagenet).Visualizations of learned representations demonstrate our model is able toattend to cytologically relevant features. Despite a small pre-trainingdataset, CytoFM's promising results highlight the ability of task-agnosticpre-training approaches to learn robust and generalizable features fromcytology data.</description>
      <author>example@mail.com (Vedrana Ivezić, Ashwath Radhachandran, Ekaterina Redekop, Shreeram Athreya, Dongwoo Lee, Vivek Sant, Corey Arnold, William Speier)</author>
      <guid isPermaLink="false">2504.13402v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>PSG-MAE: Robust Multitask Sleep Event Monitoring using Multichannel PSG Reconstruction and Inter-channel Contrastive Learning</title>
      <link>http://arxiv.org/abs/2504.13229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于掩码自动编码器（MAE）的预训练框架PSG-MAE，用于自动睡眠监测和睡眠事件分析。&lt;h4&gt;背景&lt;/h4&gt;多导睡眠图（PSG）信号对研究睡眠过程和诊断睡眠障碍至关重要。使用深度神经网络（DNNs）分析PSG数据成为可能，但数据集的有限性导致模型难以泛化到新的睡眠事件。&lt;h4&gt;目的&lt;/h4&gt;提出PSG-MAE框架以解决数据集有限性和模型泛化能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;PSG-MAE通过在大量的未标记PSG数据上执行自监督学习，开发了一个鲁棒的特征提取网络，可以广泛用于各种睡眠事件监测任务。它采用多通道信号重建方法，并使用自监督跨通道对比学习（ICCL）策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PSG-MAE能够有效地从PSG信号中捕获时间细节和跨通道信息。经过预训练的编码器在下游特征分解网络中微调后，睡眠分期准确率达到83.7%，阻塞性睡眠呼吸暂停检测准确率达到90.45%。&lt;h4&gt;结论&lt;/h4&gt;PSG-MAE框架具有鲁棒性和广泛的应用性，能够提高睡眠事件监测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Polysomnography (PSG) signals are essential for studying sleep processes anddiagnosing sleep disorders. Analyzing PSG data through deep neural networks(DNNs) for automated sleep monitoring has become increasingly feasible.However, the limited availability of datasets for certain sleep events oftenleads to DNNs focusing on a single task with a single-sourced training dataset.As a result, these models struggle to transfer to new sleep events and lackrobustness when applied to new datasets. To address these challenges, wepropose PSG-MAE, a mask autoencoder (MAE) based pre-training framework. Byperforming self-supervised learning on a large volume of unlabeled PSG data,PSG-MAE develops a robust feature extraction network that can be broadlyapplied to various sleep event monitoring tasks. Unlike conventional MAEs,PSG-MAE generates complementary masks across PSG channels, integrates amultichannel signal reconstruction method, and employs a self-supervisedinter-channel contrastive learning (ICCL) strategy. This approach enables theencoder to capture temporal features from each channel while simultaneouslylearning latent relationships between channels, thereby enhancing theutilization of multichannel information. Experimental results show that PSG-MAEeffectively captures both temporal details and inter-channel information fromPSG signals. When the encoder pre-trained through PSG-MAE is fine-tuned withdownstream feature decomposition networks, it achieves an accuracy of 83.7% forsleep staging and 90.45% for detecting obstructive sleep apnea, whichhighlights the framework's robustness and broad applicability.</description>
      <author>example@mail.com (Yifei Wang, Qi Liu, Fuli Min, Honghao Wang)</author>
      <guid isPermaLink="false">2504.13229v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Non-Uniform Class-Wise Coreset Selection: Characterizing Category Difficulty for Data-Efficient Transfer Learning</title>
      <link>http://arxiv.org/abs/2504.13234v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NUCS的非均匀类-wise Coreset选择框架，用于解决迁移学习模型和数据集日益增长时，高效适应和存储优化的需求。&lt;h4&gt;背景&lt;/h4&gt;随着迁移学习模型和数据集的增大，如何高效地适应和优化存储变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出NUCS框架，以克服现有方法主要依赖实例级难度评估，忽略类别级特征和少数类代表性不足的局限性。&lt;h4&gt;方法&lt;/h4&gt;NUCS框架结合了类别级和实例级标准，根据内在类别难度自动为每个类别分配数据选择预算，并在最佳难度范围内自适应选择样本。&lt;h4&gt;主要发现&lt;/h4&gt;通过明确纳入类别特定见解，NUCS实现了更平衡和具有代表性的coreset，并解决了先前方法的关键不足。&lt;h4&gt;结论&lt;/h4&gt;理论分析和广泛实验验证了自适应预算分配和样本选择的合理性，NUCS在14个不同数据集和模型架构上的表现优于现有方法，实现了更高的准确性和计算效率。&lt;h4&gt;翻译&lt;/h4&gt;As transfer learning models and datasets grow larger, efficient adaptation and storage optimization have become critical needs. Coreset selection addresses these challenges by identifying and retaining the most informative samples, constructing a compact subset for target domain training. However, current methods primarily rely on instance-level difficulty assessments, overlooking crucial category-level characteristics and consequently under-representing minority classes. To overcome this limitation, we propose Non-Uniform Class-Wise Coreset Selection (NUCS), a novel framework that integrates both class-level and instance-level criteria. NUCS automatically allocates data selection budgets for each class based on intrinsic category difficulty and adaptively selects samples within optimal difficulty ranges. By explicitly incorporating category-specific insights, our approach achieves a more balanced and representative coreset, addressing key shortcomings of prior methods. Comprehensive theoretical analysis validates the rationale behind adaptive budget allocation and sample selection, while extensive experiments across 14 diverse datasets and model architectures demonstrate NUCS's consistent improvements over state-of-the-art methods, achieving superior accuracy and computational efficiency. Notably, on CIFAR100 and Food101, NUCS matches full-data training accuracy while retaining just 30% of samples and reducing computation time by 60%. Our work highlights the importance of characterizing category difficulty in coreset selection, offering a robust and data-efficient solution for transfer learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As transfer learning models and datasets grow larger, efficient adaptationand storage optimization have become critical needs. Coreset selectionaddresses these challenges by identifying and retaining the most informativesamples, constructing a compact subset for target domain training. However,current methods primarily rely on instance-level difficulty assessments,overlooking crucial category-level characteristics and consequentlyunder-representing minority classes. To overcome this limitation, we proposeNon-Uniform Class-Wise Coreset Selection (NUCS), a novel framework thatintegrates both class-level and instance-level criteria. NUCS automaticallyallocates data selection budgets for each class based on intrinsic categorydifficulty and adaptively selects samples within optimal difficulty ranges. Byexplicitly incorporating category-specific insights, our approach achieves amore balanced and representative coreset, addressing key shortcomings of priormethods. Comprehensive theoretical analysis validates the rationale behindadaptive budget allocation and sample selection, while extensive experimentsacross 14 diverse datasets and model architectures demonstrate NUCS'sconsistent improvements over state-of-the-art methods, achieving superioraccuracy and computational efficiency. Notably, on CIFAR100 and Food101, NUCSmatches full-data training accuracy while retaining just 30% of samples andreducing computation time by 60%. Our work highlights the importance ofcharacterizing category difficulty in coreset selection, offering a robust anddata-efficient solution for transfer learning.</description>
      <author>example@mail.com (Hanyu Zhang, Zhen Xing, Wenxuan Yang, Chenxi Ma, Weimin Tan, Bo Yan)</author>
      <guid isPermaLink="false">2504.13234v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Laws for Data-Efficient Visual Transfer Learning</title>
      <link>http://arxiv.org/abs/2504.13219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文建立了数据高效视觉迁移学习的第一个实用框架，分析了不同数据量级下的视觉任务，提出了蒸馏边界理论，揭示了蒸馏效率的关键转折点。&lt;h4&gt;背景&lt;/h4&gt;当前视觉AI模型的缩放定律主要关注大规模预训练，但对于数据受限的后台任务，其性能缩放机制的理解存在差距。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一局限，本文旨在建立数据高效视觉迁移学习的缩放定律框架，回答两个基本问题：1）当下游任务数据有限时，缩放行为如何变化？2）在如此限制下，知识蒸馏的效力由何控制？&lt;h4&gt;方法&lt;/h4&gt;通过系统分析1K到1M样本范围内的视觉任务，提出了蒸馏边界理论，并在不同模型规模（2.5M到38M参数）和数据量下进行实证验证。&lt;h4&gt;主要发现&lt;/h4&gt;1）蒸馏优势：在数据稀缺条件下，蒸馏模型显著优于非蒸馏模型，有效地利用继承的知识来补偿有限的训练样本。2）预训练主导：当预训练数据超过临界阈值时，非蒸馏模型逐渐超越蒸馏版本，表明当有足够的特定任务数据时，知识继承的回报递减。&lt;h4&gt;结论&lt;/h4&gt;本文重新定义了数据受限领域的缩放定律，弥合了大规模预训练与实际下游适应之间的知识差距，解决了理解视觉模型缩放行为和优化计算资源分配的关键障碍。&lt;h4&gt;翻译&lt;/h4&gt;This paper establishes the first practical framework for data-efficient visual transfer learning, analyzes visual tasks across different data regimes (1K-1M samples), and proposes the distillation boundary theory, revealing a critical turning point in distillation efficiency: 1) Distillation superiority: In data-scarce conditions, distilled models significantly outperform their non-distillation counterparts, efficiently leveraging inherited knowledge to compensate for limited training samples. 2) Pre-training dominance: As pre-training data increases beyond a critical threshold, non-distilled models gradually surpass distilled versions, suggesting diminishing returns from knowledge inheritance when sufficient task-specific data becomes available. Empirical validation across various model scales (2.5M to 38M parameters) and data volumes demonstrates these performance inflection points, with error difference curves transitioning from positive to negative values at critical data thresholds, confirming our theoretical predictions. This work redefines scaling laws for data-limited regimes, bridging the knowledge gap between large-scale pretraining and practical downstream adaptation, addressing a critical barrier to understanding vision model scaling behaviors and optimizing computational resource allocation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current scaling laws for visual AI models focus predominantly on large-scalepretraining, leaving a critical gap in understanding how performance scales fordata-constrained downstream tasks. To address this limitation, this paperestablishes the first practical framework for data-efficient scaling laws invisual transfer learning, addressing two fundamental questions: 1) How doscaling behaviors shift when downstream tasks operate with limited data? 2)What governs the efficacy of knowledge distillation under such constraints?Through systematic analysis of vision tasks across data regimes (1K-1Msamples), we propose the distillation boundary theory, revealing a criticalturning point in distillation efficiency: 1) Distillation superiority: Indata-scarce conditions, distilled models significantly outperform theirnon-distillation counterparts, efficiently leveraging inherited knowledge tocompensate for limited training samples. 2) Pre-training dominance: Aspre-training data increases beyond a critical threshold, non-distilled modelsgradually surpass distilled versions, suggesting diminishing returns fromknowledge inheritance when sufficient task-specific data becomes available.Empirical validation across various model scales (2.5M to 38M parameters) anddata volumes demonstrate these performance inflection points, with errordifference curves transitioning from positive to negative values at criticaldata thresholds, confirming our theoretical predictions. This work redefinesscaling laws for data-limited regimes, bridging the knowledge gap betweenlarge-scale pretraining and practical downstream adaptation, addressing acritical barrier to understanding vision model scaling behaviors and optimizingcomputational resource allocation.</description>
      <author>example@mail.com (Wenxuan Yang, Qingqu Wei, Chenxi Ma, Weimin Tan, Bo Yan)</author>
      <guid isPermaLink="false">2504.13219v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular Representations for Whole-Heart Assessment and Beyond</title>
      <link>http://arxiv.org/abs/2504.13037v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了Cardiac magnetic resonance imaging（心脏磁共振成像）在非侵入性心脏评估中的重要性，并提出了ViTa模型，该模型通过结合心脏磁共振数据和患者水平因素，提供对心脏健康和疾病风险的全面理解。&lt;h4&gt;背景&lt;/h4&gt;Cardiac magnetic resonance imaging是心脏评估的金标准，但单独使用无法捕捉到患者级别的健康因素，如人口统计学、代谢和生活方式，这些因素对心血管健康和疾病风险有显著影响。&lt;h4&gt;目的&lt;/h4&gt;为了全面理解心脏健康并准确解释个体的疾病风险，需要在一个综合框架内联合利用CMR和患者水平因素。&lt;h4&gt;方法&lt;/h4&gt;ViTa模型通过整合来自42,000名英国生物样本库参与者的数据，将3D+T cine stacks从短轴和长轴视图融合，并与详细的表格患者级别因素结合，从而实现心脏周期的完整捕捉和上下文感知洞察。&lt;h4&gt;主要发现&lt;/h4&gt;ViTa模型支持广泛的下游任务，包括心脏表型和生理特征预测、分割以及心脏和代谢疾病的分类，通过学习一个连接丰富成像特征和患者背景的共享潜在表示，超越了传统的任务特定模型。&lt;h4&gt;结论&lt;/h4&gt;ViTa模型有望提高临床应用和心脏分析的可扩展性，为心脏健康评估提供了一种新的、患者特定的理解方式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cardiac magnetic resonance imaging is the gold standard for non-invasivecardiac assessment, offering rich spatio-temporal views of the cardiac anatomyand physiology. Patient-level health factors, such as demographics, metabolic,and lifestyle, are known to substantially influence cardiovascular health anddisease risk, yet remain uncaptured by CMR alone. To holistically understandcardiac health and to enable the best possible interpretation of anindividual's disease risk, CMR and patient-level factors must be jointlyexploited within an integrated framework. Recent multi-modal approaches havebegun to bridge this gap, yet they often rely on limited spatio-temporal dataand focus on isolated clinical tasks, thereby hindering the development of acomprehensive representation for cardiac health evaluation. To overcome theselimitations, we introduce ViTa, a step toward foundation models that delivers acomprehensive representation of the heart and a precise interpretation ofindividual disease risk. Leveraging data from 42,000 UK Biobank participants,ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enablinga complete capture of the cardiac cycle. These imaging data are then fused withdetailed tabular patient-level factors, enabling context-aware insights. Thismulti-modal paradigm supports a wide spectrum of downstream tasks, includingcardiac phenotype and physiological feature prediction, segmentation, andclassification of cardiac and metabolic diseases within a single unifiedframework. By learning a shared latent representation that bridges rich imagingfeatures and patient context, ViTa moves beyond traditional, task-specificmodels toward a universal, patient-specific understanding of cardiac health,highlighting its potential to advance clinical utility and scalability incardiac analysis.</description>
      <author>example@mail.com (Yundi Zhang, Paul Hager, Che Liu, Suprosanna Shit, Chen Chen, Daniel Rueckert, Jiazhen Pan)</author>
      <guid isPermaLink="false">2504.13037v2</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>It's All Connected: A Journey Through Test-Time Memorization, Attentional Bias, Retention, and Online Optimization</title>
      <link>http://arxiv.org/abs/2504.13173v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究如何设计高效和有效的建筑背骨，以提高基础模型的能力，并引入了注意力偏差的概念来重新构思神经网络架构。&lt;h4&gt;背景&lt;/h4&gt;设计高效和有效的建筑背骨是提升基础模型能力的研究核心。&lt;h4&gt;目的&lt;/h4&gt;通过模仿人类的注意力偏差现象，将神经网络架构视为关联记忆模块，并学习使用内部目标（注意力偏差）来映射键值。&lt;h4&gt;方法&lt;/h4&gt;提出了新的注意力偏差配置及其有效近似，重新解释了深度学习架构中的遗忘机制，并提出了针对序列模型的遗忘门。建立了Miras框架，通过四种选择来设计深度学习架构：关联记忆架构、注意力偏差目标、保留门和记忆学习算法。&lt;h4&gt;主要发现&lt;/h4&gt;大多数现有序列模型使用点积相似度或L2回归目标作为注意力偏差，并提出了一系列新的注意力偏差配置以稳定训练过程。&lt;h4&gt;结论&lt;/h4&gt;Miras框架的设计选择导致了具有不同优势的模型，某些Miras实例在特定任务（如语言建模、常识推理和召回密集型任务）中表现出色，甚至超越了Transformer和其他现代线性循环模型。&lt;h4&gt;翻译&lt;/h4&gt;Designing efficient and effective architectural backbones has been in thecore of research efforts to enhance the capability of foundation models. Inspired by the human cognitive phenomenon of attentional bias-the natural tendency to prioritize certain events or stimuli-we reconceptualize neuralarchitectures, including Transformers, Titans, and modern linear recurrentneural networks as associative memory modules that learn a mapping of keys andvalues using an internal objective, referred to as attentional bias. Surprisingly, we observed that most existing sequence models leverage either (1) dot-product similarity, or (2) L2 regression objectives as their attentional bias. Going beyond these objectives, we present a set of alternative attentional bias configurations along with their effective approximations to stabilize their training procedure. We then reinterpret forgetting mechanisms in modern deep learning architectures as a form of retention regularization, providing a novel set of forget gates for sequencemodels. Building upon these insights, we present Miras, a general framework to design deep learning architectures based on four choices of: (i) associative memory architecture, (ii) attentional bias objective, (iii) retention gate, and (iv) memory learning algorithm. We present three novel sequence models-Moneta, Yaad, and Memora-that go beyond the power of existing linear RNNs while maintaining a fast parallelizable training process. Our experiments show different design choices in Miras yield models with varying strengths. For example, certain instances of Miras achieve exceptional performance in special tasks such as language modeling, commonsense reasoning, and recall intensive tasks, even outperforming Transformers and other modern linear recurrent models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Designing efficient and effective architectural backbones has been in thecore of research efforts to enhance the capability of foundation models.Inspired by the human cognitive phenomenon of attentional bias-the naturaltendency to prioritize certain events or stimuli-we reconceptualize neuralarchitectures, including Transformers, Titans, and modern linear recurrentneural networks as associative memory modules that learn a mapping of keys andvalues using an internal objective, referred to as attentional bias.Surprisingly, we observed that most existing sequence models leverage either(1) dot-product similarity, or (2) L2 regression objectives as theirattentional bias. Going beyond these objectives, we present a set ofalternative attentional bias configurations along with their effectiveapproximations to stabilize their training procedure. We then reinterpretforgetting mechanisms in modern deep learning architectures as a form ofretention regularization, providing a novel set of forget gates for sequencemodels. Building upon these insights, we present Miras, a general framework todesign deep learning architectures based on four choices of: (i) associativememory architecture, (ii) attentional bias objective, (iii) retention gate, and(iv) memory learning algorithm. We present three novel sequence models-Moneta,Yaad, and Memora-that go beyond the power of existing linear RNNs whilemaintaining a fast parallelizable training process. Our experiments showdifferent design choices in Miras yield models with varying strengths. Forexample, certain instances of Miras achieve exceptional performance in specialtasks such as language modeling, commonsense reasoning, and recall intensivetasks, even outperforming Transformers and other modern linear recurrentmodels.</description>
      <author>example@mail.com (Ali Behrouz, Meisam Razaviyayn, Peilin Zhong, Vahab Mirrokni)</author>
      <guid isPermaLink="false">2504.13173v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
  <item>
      <title>Machine Learning Methods for Gene Regulatory Network Inference</title>
      <link>http://arxiv.org/abs/2504.12610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  40 pages, 3 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于机器学习的基因调控网络（GRN）推断方法进行了全面综述，并讨论了常用的数据集和评估指标，特别强调了深度学习技术在提高推断性能方面的作用，同时探讨了改进GRN推断的未来方向。&lt;h4&gt;背景&lt;/h4&gt;基因调控网络是复杂的生物系统，响应环境和发展信号控制基因表达和调控。计算生物学和测序技术的进步显著提高了GRN推断和建模的准确性。&lt;h4&gt;目的&lt;/h4&gt;支持GRN推断在研究基因调控中的应用，以及新型机器学习方法的开发。&lt;h4&gt;方法&lt;/h4&gt;介绍了机器学习在GRN推断中的应用，包括监督学习、无监督学习、半监督学习和对比学习等，并分析了大规模组学数据以揭示调控基因相互作用。&lt;h4&gt;主要发现&lt;/h4&gt;重点介绍了深度学习技术在提高GRN推断性能方面的作用，并讨论了改进GRN推断的潜在未来方向。&lt;h4&gt;结论&lt;/h4&gt;深度学习技术在GRN推断中扮演着重要角色，未来研究应进一步探索和优化这些方法，以实现更精确的基因调控网络推断。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gene Regulatory Networks (GRNs) are intricate biological systems that controlgene expression and regulation in response to environmental and developmentalcues. Advances in computational biology, coupled with high throughputsequencing technologies, have significantly improved the accuracy of GRNinference and modeling. Modern approaches increasingly leverage artificialintelligence (AI), particularly machine learning techniques includingsupervised, unsupervised, semi-supervised, and contrastive learning to analyzelarge scale omics data and uncover regulatory gene interactions. To supportboth the application of GRN inference in studying gene regulation and thedevelopment of novel machine learning methods, we present a comprehensivereview of machine learning based GRN inference methodologies, along with thedatasets and evaluation metrics commonly used. Special emphasis is placed onthe emerging role of cutting edge deep learning techniques in enhancinginference performance. The potential future directions for improving GRNinference are also discussed.</description>
      <author>example@mail.com (Akshata Hegde, Tom Nguyen, Jianlin Cheng)</author>
      <guid isPermaLink="false">2504.12610v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>CM3AE: A Unified RGB Frame and Event-Voxel/-Frame Pre-training Framework</title>
      <link>http://arxiv.org/abs/2504.12576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CM3AE的新型预训练框架，用于RGB-Event感知，该框架旨在解决现有方法在多模态融合场景中的应用局限性。&lt;h4&gt;背景&lt;/h4&gt;事件相机因其在高动态范围、高时间分辨率、低功耗和低延迟方面的优势而受到越来越多的关注。然而，直接在事件数据上进行的预训练研究往往难以与RGB帧建立强连接，限制了其在多模态融合场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出CM3AE框架的目的是为了解决上述问题，使其能够有效支持基于事件和RGB-Event融合的后续任务。&lt;h4&gt;方法&lt;/h4&gt;CM3AE框架接受包括RGB图像、事件图像和事件体素在内的多模态/视角数据作为输入，设计了一个多模态融合重建模块，以及一个多模态对比学习策略来对齐跨模态特征表示，从而增强模型的多模态理解和捕捉全局依赖的能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过构建包含2,535,759个RGB-Event数据对的的大型数据集进行预训练，并在五个下游任务上的广泛实验充分证明了CM3AE框架的有效性。&lt;h4&gt;结论&lt;/h4&gt;CM3AE框架在多模态融合感知任务中表现出色，并将在https://github.com/Event-AHU/CM3AE上发布源代码和预训练模型。&lt;h4&gt;翻译&lt;/h4&gt;Event cameras have attracted increasing attention in recent years due to their advantages in high dynamic range, high temporal resolution, low power consumption, and low latency. Some researchers have begun exploring pre-training directly on event data. Nevertheless, these efforts often fail to establish strong connections with RGB frames, limiting their applicability in multi-modal fusion scenarios. To address these issues, we propose a novel CM3AE pre-training framework for the RGB-Event perception. This framework accepts multi-modalities/views of data as input, including RGB images, event images, and event voxels, providing robust support for both event-based and RGB-event fusion based downstream tasks. Specifically, we design a multi-modal fusion reconstruction module that reconstructs the original image from fused multi-modal features, explicitly enhancing the model's ability to aggregate cross-modal complementary information. Additionally, we employ a multi-modal contrastive learning strategy to align cross-modal feature representations in a shared latent space, which effectively enhances the model's capability for multi-modal understanding and capturing global dependencies. We construct a large-scale dataset containing 2,535,759 RGB-Event data pairs for the pre-training. Extensive experiments on five downstream tasks fully demonstrated the effectiveness of CM3AE. Source code and pre-trained models will be released on https://github.com/Event-AHU/CM3AE.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras have attracted increasing attention in recent years due totheir advantages in high dynamic range, high temporal resolution, low powerconsumption, and low latency. Some researchers have begun exploringpre-training directly on event data. Nevertheless, these efforts often fail toestablish strong connections with RGB frames, limiting their applicability inmulti-modal fusion scenarios. To address these issues, we propose a novel CM3AEpre-training framework for the RGB-Event perception. This framework acceptsmulti-modalities/views of data as input, including RGB images, event images,and event voxels, providing robust support for both event-based and RGB-eventfusion based downstream tasks. Specifically, we design a multi-modal fusionreconstruction module that reconstructs the original image from fusedmulti-modal features, explicitly enhancing the model's ability to aggregatecross-modal complementary information. Additionally, we employ a multi-modalcontrastive learning strategy to align cross-modal feature representations in ashared latent space, which effectively enhances the model's capability formulti-modal understanding and capturing global dependencies. We construct alarge-scale dataset containing 2,535,759 RGB-Event data pairs for thepre-training. Extensive experiments on five downstream tasks fully demonstratedthe effectiveness of CM3AE. Source code and pre-trained models will be releasedon https://github.com/Event-AHU/CM3AE.</description>
      <author>example@mail.com (Wentao Wu, Xiao Wang, Chenglong Li, Bo Jiang, Jin Tang, Bin Luo, Qi Liu)</author>
      <guid isPermaLink="false">2504.12576v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Digital Twin Generation from Visual Data: A Survey</title>
      <link>http://arxiv.org/abs/2504.13159v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了从视频中生成数字孪生的最新进展。&lt;h4&gt;背景&lt;/h4&gt;数字孪生可以应用于机器人技术、媒体内容创作或设计和施工工作。&lt;h4&gt;目的&lt;/h4&gt;分析各种方法，包括3D高斯分层、生成性修复、语义分割和基础模型，并讨论它们的优缺点。&lt;h4&gt;方法&lt;/h4&gt;讨论了诸如遮挡、光照变化和可扩展性等挑战，以及潜在的未来研究方向。&lt;h4&gt;结论&lt;/h4&gt;该调查旨在提供对最先进方法的全面概述及其对现实世界应用的影响。&lt;h4&gt;翻译&lt;/h4&gt;本调查探讨了从视频中生成数字孪生的最新进展。这些数字孪生可用于机器人应用、媒体内容创作或设计和施工工作。我们分析了各种方法，包括3D高斯分层、生成性修复、语义分割和基础模型，并强调了它们的优缺点。此外，我们还讨论了遮挡、光照变化和可扩展性等挑战，以及潜在的未来研究方向。本调查旨在提供一个对最先进方法的全面概述及其对现实世界应用的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This survey explores recent developments in generating digital twins fromvideos. Such digital twins can be used for robotics application, media contentcreation, or design and construction works. We analyze various approaches,including 3D Gaussian Splatting, generative in-painting, semantic segmentation,and foundation models highlighting their advantages and limitations.Additionally, we discuss challenges such as occlusions, lighting variations,and scalability, as well as potential future research directions. This surveyaims to provide a comprehensive overview of state-of-the-art methodologies andtheir implications for real-world applications. Awesome list:https://github.com/ndrwmlnk/awesome-digital-twins</description>
      <author>example@mail.com (Andrew Melnik, Benjamin Alt, Giang Nguyen, Artur Wilkowski, Maciej Stefańczyk, Qirui Wu, Sinan Harms, Helge Rhodin, Manolis Savva, Michael Beetz)</author>
      <guid isPermaLink="false">2504.13159v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>All-in-One Transferring Image Compression from Human Perception to Multi-Machine Perception</title>
      <link>http://arxiv.org/abs/2504.12997v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种不对称适配器框架，用于高效地将学习图像压缩（LIC）模型从人类感知转移到机器感知，以解决现有方法在下游任务中单任务适应的效率低、缺乏任务交互和产生多个特定任务比特流的问题。&lt;h4&gt;背景&lt;/h4&gt;在视觉中心表示学习中，将LIC模型从人类感知转移到机器感知是一个新兴的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以支持在单个模型内进行多任务适应，提高效率和任务交互性。&lt;h4&gt;方法&lt;/h4&gt;该方法引入了共享适配器来学习通用语义特征，以及特定任务的适配器来保持任务级别的区分度。通过轻量级的插件模块和冻结的基编码器，该方法在多个任务上实现了强大的性能，同时保持了压缩效率。&lt;h4&gt;主要发现&lt;/h4&gt;在PASCAL-Context基准测试中，该方法优于全微调和其他参数高效微调（PEFT）基线，验证了多视觉转移的有效性。&lt;h4&gt;结论&lt;/h4&gt;不对称适配器框架在视觉中心表示学习中提供了有效的方法，以实现LIC模型的高效跨任务适应。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficiently transferring Learned Image Compression (LIC) model from humanperception to machine perception is an emerging challenge in vision-centricrepresentation learning. Existing approaches typically adapt LIC to downstreamtasks in a single-task manner, which is inefficient, lacks task interaction,and results in multiple task-specific bitstreams. To address these limitations,we propose an asymmetric adaptor framework that supports multi-task adaptationwithin a single model. Our method introduces a shared adaptor to learn generalsemantic features and task-specific adaptors to preserve task-leveldistinctions. With only lightweight plug-in modules and a frozen base codec,our method achieves strong performance across multiple tasks while maintainingcompression efficiency. Experiments on the PASCAL-Context benchmark demonstratethat our method outperforms both Fully Fine-Tuned and other Parameter EfficientFine-Tuned (PEFT) baselines, and validating the effectiveness of multi-visiontransferring.</description>
      <author>example@mail.com (Jiancheng Zhao, Xiang Ji, Zhuoxiao Li, Zunian Wan, Weihang Ran, Mingze Ma, Muyao Niu, Yifan Zhan, Cheng-Ching Tseng, Yinqiang Zheng)</author>
      <guid isPermaLink="false">2504.12997v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>UncAD: Towards Safe End-to-end Autonomous Driving via Online Map Uncertainty</title>
      <link>http://arxiv.org/abs/2504.12826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为UncAD的新型自动驾驶范式，通过估计在线地图的不确定性来提升自动驾驶的安全性。&lt;h4&gt;背景&lt;/h4&gt;当前大多数自动驾驶方法将感知、预测和规划模块集成到一个可微分的网络中，虽然具有很好的可扩展性，但通常依赖于确定性建模的在线地图来指导或约束车辆规划，这可能导致错误的信息并危及规划安全。&lt;h4&gt;目的&lt;/h4&gt;提出UncAD范式，以解决在线地图不确定性对自动驾驶安全性的影响。&lt;h4&gt;方法&lt;/h4&gt;UncAD首先在感知模块中估计在线地图的不确定性，然后利用这种不确定性来指导运动预测和规划模块生成多模态轨迹。此外，根据在线地图的不确定性，UncAD提出了一个不确定性-碰撞感知的规划选择策略，以评估和选择最佳轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes数据集上的实验表明，将UncAD集成到最先进的端到端方法中，仅参数增加1.9%，可以降低碰撞率高达26%，降低可行驶区域冲突率高达42%。&lt;h4&gt;结论&lt;/h4&gt;UncAD通过引入在线地图不确定性，显著提升了自动驾驶的安全性。&lt;h4&gt;翻译&lt;/h4&gt;End-to-end autonomous driving aims to produce planning trajectories from raw sensors directly. Currently, most approaches integrate perception, prediction, and planning modules into a fully differentiable network, promising great scalability. However, these methods typically rely on deterministic modeling of online maps in the perception module for guiding or constraining vehicle planning, which may incorporate erroneous perception information and further compromise planning safety. To address this issue, we delve into the importance of online map uncertainty for enhancing autonomous driving safety and propose a novel paradigm named UncAD. Specifically, UncAD first estimates the uncertainty of the online map in the perception module. It then leverages the uncertainty to guide motion prediction and planning modules to produce multi-modal trajectories. Finally, to achieve safer autonomous driving, UncAD proposes an uncertainty-collision-aware planning selection strategy according to the online map uncertainty to evaluate and select the best trajectory. In this study, we incorporate UncAD into various state-of-the-art (SOTA) end-to-end methods. Experiments on the nuScenes dataset show that integrating UncAD, with only a 1.9% increase in parameters, can reduce collision rates by up to 26% and drivable area conflict rate by up to 42%. Codes, pre-trained models, and demo videos can be accessed at https://github.com/pengxuanyang/UncAD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; End-to-end autonomous driving aims to produce planning trajectories from rawsensors directly. Currently, most approaches integrate perception, prediction,and planning modules into a fully differentiable network, promising greatscalability. However, these methods typically rely on deterministic modeling ofonline maps in the perception module for guiding or constraining vehicleplanning, which may incorporate erroneous perception information and furthercompromise planning safety. To address this issue, we delve into the importanceof online map uncertainty for enhancing autonomous driving safety and propose anovel paradigm named UncAD. Specifically, UncAD first estimates the uncertaintyof the online map in the perception module. It then leverages the uncertaintyto guide motion prediction and planning modules to produce multi-modaltrajectories. Finally, to achieve safer autonomous driving, UncAD proposes anuncertainty-collision-aware planning selection strategy according to the onlinemap uncertainty to evaluate and select the best trajectory. In this study, weincorporate UncAD into various state-of-the-art (SOTA) end-to-end methods.Experiments on the nuScenes dataset show that integrating UncAD, with only a1.9% increase in parameters, can reduce collision rates by up to 26% anddrivable area conflict rate by up to 42%. Codes, pre-trained models, and demovideos can be accessed at https://github.com/pengxuanyang/UncAD.</description>
      <author>example@mail.com (Pengxuan Yang, Yupeng Zheng, Qichao Zhang, Kefei Zhu, Zebin Xing, Qiao Lin, Yun-Fu Liu, Zhiguo Su, Dongbin Zhao)</author>
      <guid isPermaLink="false">2504.12826v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning via Auxiliary Labels with Application to Cold-Hardiness Prediction</title>
      <link>http://arxiv.org/abs/2504.13142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TAL（通过辅助标签转移）的新迁移学习框架，帮助农民利用植物物候数据来预测水果作物的抗寒性，即使在缺乏抗寒性数据的情况下也能提高预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;低温会对水果作物造成冻害，抗寒性是影响冻害的关键因素，且抗寒性在休眠期会变化。目前，由于设备和专业知识的要求，抗寒性数据仅限于部分水果品种，而农民通常收集了多年的物候数据。&lt;h4&gt;目的&lt;/h4&gt;利用农民已有的物候数据，通过TAL框架预测特定作物的抗寒性，即使没有该作物的抗寒性数据。&lt;h4&gt;方法&lt;/h4&gt;TAL框架基于源任务（已知品种）的源标签（抗寒性）和辅助标签（物候），目标任务（新品种）只有辅助标签。通过模型选择和平均的方法，利用深度多任务模型进行抗寒性预测。&lt;h4&gt;主要发现&lt;/h4&gt;TAL框架在真实世界的抗寒性和物候数据上表现出色，能够提高预测准确性。&lt;h4&gt;结论&lt;/h4&gt;TAL框架为农民提供了一种有效的方法，利用物候数据预测抗寒性，即使在缺乏抗寒性数据的情况下也能提高预测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：低温可能会对水果作物造成显著的冻害，这取决于它们的抗寒性，抗寒性在休眠期会变化。这导致了预测抗寒性模型的开发，帮助农民决定何时采取昂贵的防霜措施。不幸的是，由于需要专门的设备和专业知识，用于模型训练的抗寒性数据仅适用于某些水果品种。相反，农民通常拥有多年的物候数据（例如芽萌发日期），他们定期收集这些数据用于他们的作物。在这项工作中，我们介绍了一种新的迁移学习框架，称为TAL（通过辅助标签转移），它允许农民利用物候数据来生成更准确的抗寒性预测，即使在他们的特定作物没有抗寒性数据的情况下也是如此。该框架假设一组源任务（品种）中的每个任务都有关联的源标签（抗寒性）和辅助标签（物候）。然而，目标任务（新品种）仅假设有辅助标签。TAL的目标是通过从源任务中迁移来预测目标任务的目标标签。令人惊讶的是，尽管关于迁移学习的文献浩如烟海，据我们所知，TAL的公式以前从未被解决。因此，我们提出了几种基于模型选择和平均的新TAL方法，可以利用最新的深度多任务模型进行抗寒性预测。我们在多个葡萄品种的真实世界抗寒性和物候数据上的结果表明，TAL可以利用物候数据在没有抗寒性数据的情况下提高抗寒性预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cold temperatures can cause significant frost damage to fruit crops dependingon their resilience, or cold hardiness, which changes throughout the dormancyseason. This has led to the development of predictive cold-hardiness models,which help farmers decide when to deploy expensive frost-mitigation measures.Unfortunately, cold-hardiness data for model training is only available forsome fruit cultivars due to the need for specialized equipment and expertise.Rather, farmers often do have years of phenological data (e.g. date ofbudbreak) that they regularly collect for their crops. In this work, weintroduce a new transfer-learning framework, Transfer via Auxiliary Labels(TAL), that allows farmers to leverage the phenological data to produce moreaccurate cold-hardiness predictions, even when no cold-hardiness data isavailable for their specific crop. The framework assumes a set of source tasks(cultivars) where each has associated primary labels (cold hardiness) andauxiliary labels (phenology). However, the target task (new cultivar) isassumed to only have the auxiliary labels. The goal of TAL is to predictprimary labels for the target task via transfer from the source tasks.Surprisingly, despite the vast literature on transfer learning, to ourknowledge, the TAL formulation has not been previously addressed. Thus, wepropose several new TAL approaches based on model selection and averaging thatcan leverage recent deep multi-task models for cold-hardiness prediction. Ourresults on real-world cold-hardiness and phenological data for multiple grapecultivars demonstrate that TAL can leverage the phenological data to improvecold-hardiness predictions in the absence of cold-hardiness data.</description>
      <author>example@mail.com (Kristen Goebel, Paola Pesantez-Cabrera, Markus Keller, Alan Fern)</author>
      <guid isPermaLink="false">2504.13142v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Feature Learning for Medical Point Clouds via State Space Model</title>
      <link>http://arxiv.org/abs/2504.13015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于SSM的分层特征学习框架，用于医疗点云的理解。&lt;h4&gt;背景&lt;/h4&gt;深度学习在点云建模中已得到广泛研究，但针对医疗点云的研究有限。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的框架来理解和处理医疗点云数据，以支持疾病诊断和治疗。&lt;h4&gt;方法&lt;/h4&gt;通过远点采样对输入点云进行下采样，使用KNN查询聚合多尺度结构信息，引入坐标顺序和内外扫描策略进行高效序列化，以及通过vanilla和group Point SSM块逐步计算点特征。&lt;h4&gt;主要发现&lt;/h4&gt;在MedPointS数据集上的实验表明，该方法在解剖分类、补全和分割任务中均表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法为医疗点云的理解提供了有效的解决方案，并促进了相关数据集和代码的公开。&lt;h4&gt;翻译&lt;/h4&gt;Deep learning-based point cloud modeling has been widely investigated as an indispensable component of general shape analysis. Recently, transformer and state space model (SSM) have shown promising capacities in point cloud learning. However, limited research has been conducted on medical point clouds, which have great potential in disease diagnosis and treatment. This paper presents an SSM-based hierarchical feature learning framework for medical point cloud understanding. Specifically, we down-sample input into multiple levels through the farthest point sampling. At each level, we perform a series of k-nearest neighbor (KNN) queries to aggregate multi-scale structural information. To assist SSM in processing point clouds, we introduce coordinate-order and inside-out scanning strategies for efficient serialization of irregular points. Point features are calculated progressively from short neighbor sequences and long point sequences through vanilla and group Point SSM blocks, to capture both local patterns and long-range dependencies. To evaluate the proposed method, we build a large-scale medical point cloud dataset named MedPointS for anatomy classification, completion, and segmentation. Extensive experiments conducted on MedPointS demonstrate that our method achieves superior performance across all tasks. The dataset is available at https://flemme-docs.readthedocs.io/en/latest/medpoints.html. Code is merged to a public medical imaging platform: https://github.com/wlsdzyzl/flemme.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based point cloud modeling has been widely investigated as anindispensable component of general shape analysis. Recently, transformer andstate space model (SSM) have shown promising capacities in point cloudlearning. However, limited research has been conducted on medical point clouds,which have great potential in disease diagnosis and treatment. This paperpresents an SSM-based hierarchical feature learning framework for medical pointcloud understanding. Specifically, we down-sample input into multiple levelsthrough the farthest point sampling. At each level, we perform a series ofk-nearest neighbor (KNN) queries to aggregate multi-scale structuralinformation. To assist SSM in processing point clouds, we introducecoordinate-order and inside-out scanning strategies for efficient serializationof irregular points. Point features are calculated progressively from shortneighbor sequences and long point sequences through vanilla and group Point SSMblocks, to capture both local patterns and long-range dependencies. To evaluatethe proposed method, we build a large-scale medical point cloud dataset namedMedPointS for anatomy classification, completion, and segmentation. Extensiveexperiments conducted on MedPointS demonstrate that our method achievessuperior performance across all tasks. The dataset is available athttps://flemme-docs.readthedocs.io/en/latest/medpoints.html. Code is merged toa public medical imaging platform: https://github.com/wlsdzyzl/flemme.</description>
      <author>example@mail.com (Guoqing Zhang, Jingyun Yang, Yang Li)</author>
      <guid isPermaLink="false">2504.13015v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Quorum: Zero-Training Unsupervised Anomaly Detection using Quantum Autoencoders</title>
      <link>http://arxiv.org/abs/2504.13113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Quorum的量子异常检测框架，旨在解决在金融、医疗和能源等行业中检测关键任务异常事件和数据的关键挑战。&lt;h4&gt;背景&lt;/h4&gt;量子计算作为处理机器学习任务的强大工具，但训练量子机器学习模型面临挑战，特别是在梯度计算方面。对于异常检测，无监督学习方法至关重要，但这一挑战更为严峻。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出Quorum框架，它是第一个专为无监督学习设计的量子异常检测框架，且无需任何训练。&lt;h4&gt;方法&lt;/h4&gt;Quorum框架的设计和应用。&lt;h4&gt;主要发现&lt;/h4&gt;Quorum框架能够有效解决量子机器学习模型训练中的梯度计算难题，并适用于无监督学习的异常检测。&lt;h4&gt;结论&lt;/h4&gt;Quorum框架为量子异常检测提供了一种新的解决方案，有助于推动相关领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;Detecting mission-critical anomalous events and data is a crucial challenge across various industries, including finance, healthcare, and energy. Quantum computing has recently emerged as a powerful tool for tackling several machine learning tasks, but training quantum machine learning models remains challenging, particularly due to the difficulty of gradient calculation. The challenge is even greater for anomaly detection, where unsupervised learning methods are essential to ensure practical applicability. To address these issues, we propose Quorum, the first quantum anomaly detection framework designed for unsupervised learning that operates without requiring any training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting mission-critical anomalous events and data is a crucial challengeacross various industries, including finance, healthcare, and energy. Quantumcomputing has recently emerged as a powerful tool for tackling several machinelearning tasks, but training quantum machine learning models remainschallenging, particularly due to the difficulty of gradient calculation. Thechallenge is even greater for anomaly detection, where unsupervised learningmethods are essential to ensure practical applicability. To address theseissues, we propose Quorum, the first quantum anomaly detection frameworkdesigned for unsupervised learning that operates without requiring anytraining.</description>
      <author>example@mail.com (Jason Zev Ludmir, Sophia Rebello, Jacob Ruiz, Tirthak Patel)</author>
      <guid isPermaLink="false">2504.13113v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Perception Encoder: The best visual embeddings are not at the output of the network</title>
      <link>http://arxiv.org/abs/2504.13181v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Initial Submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为感知编码器（PE）的最新图像和视频理解编码器，通过简单的视觉-语言学习进行训练。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉编码器依赖于各种预训练目标，针对特定的下游任务如分类、字幕或定位进行优化。&lt;h4&gt;目的&lt;/h4&gt;探索仅通过对比视觉-语言训练是否能够生成适用于多种下游任务的强大、通用嵌入。&lt;h4&gt;方法&lt;/h4&gt;采用精心调整的图像预训练食谱和鲁棒的视频数据引擎进行训练，并引入语言对齐和空间对齐方法以提取中间层中的嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;对比视觉-语言训练能够生成适用于多种下游任务的强大嵌入，包括零样本图像和视频分类、检索、文档、图像和视频问答以及空间任务如检测、深度估计和跟踪。&lt;h4&gt;结论&lt;/h4&gt;PE模型系列在各种任务上取得了最先进的性能，并发布了模型、代码以及一个由合成和人工标注的视频组成的新数据集，以促进进一步的研究。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为感知编码器（PE）的最新图像和视频理解编码器，它通过简单的视觉-语言学习进行训练。传统上，视觉编码器依赖于各种预训练目标，每个目标都针对特定的下游任务，如分类、字幕或定位进行优化。令人惊讶的是，在扩展我们精心调整的图像预训练食谱并使用我们鲁棒的视频数据引擎进行优化后，我们发现仅对比视觉-语言训练就能为所有这些下游任务生成强大、通用的嵌入。只有一个注意事项：这些嵌入隐藏在网络的中间层中。为了提取它们，我们引入了两种对齐方法，即用于多模态语言模型的语言对齐和用于密集预测的空间对齐。与核心对比检查点一起，我们的PE模型系列在各种任务上实现了最先进的性能，包括零样本图像和视频分类和检索；文档、图像和视频问答；以及检测、深度估计和跟踪等空间任务。为了促进进一步的研究，我们发布了我们的模型、代码以及一个由合成和人工标注的视频组成的新数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Perception Encoder (PE), a state-of-the-art encoder for imageand video understanding trained via simple vision-language learning.Traditionally, vision encoders have relied on a variety of pretrainingobjectives, each tailored to specific downstream tasks such as classification,captioning, or localization. Surprisingly, after scaling our carefully tunedimage pretraining recipe and refining with our robust video data engine, wefind that contrastive vision-language training alone can produce strong,general embeddings for all of these downstream tasks. There is only one caveat:these embeddings are hidden within the intermediate layers of the network. Todraw them out, we introduce two alignment methods, language alignment formultimodal language modeling, and spatial alignment for dense prediction.Together with the core contrastive checkpoint, our PE family of models achievesstate-of-the-art performance on a wide variety of tasks, including zero-shotimage and video classification and retrieval; document, image, and video Q&amp;A;and spatial tasks such as detection, depth estimation, and tracking. To fosterfurther research, we are releasing our models, code, and a novel dataset ofsynthetically and human-annotated videos.</description>
      <author>example@mail.com (Daniel Bolya, Po-Yao Huang, Peize Sun, Jang Hyun Cho, Andrea Madotto, Chen Wei, Tengyu Ma, Jiale Zhi, Jathushan Rajasegaran, Hanoona Rasheed, Junke Wang, Marco Monteiro, Hu Xu, Shiyu Dong, Nikhila Ravi, Daniel Li, Piotr Dollár, Christoph Feichtenhofer)</author>
      <guid isPermaLink="false">2504.13181v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Training-Free Hierarchical Scene Understanding for Gaussian Splatting with Superpoint Graphs</title>
      <link>http://arxiv.org/abs/2504.13153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种无需训练的框架，直接从高斯原语构建超点图，以解决现有方法在3D几何与自然语言结合中的效率低下和3D语义不一致问题。&lt;h4&gt;背景&lt;/h4&gt;自然语言与3D几何的结合对于灵活的、语言驱动的场景理解至关重要。虽然3D高斯分层（3DGS）在场景重建方面取得了进展，但现有方法存在效率低下和3D语义不一致的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法，以解决现有3DGS方法中存在的效率低下和3D语义不一致问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于超点图的训练免费框架，该框架直接从高斯原语构建超点图，并设计了一种高效的重新投影策略，将2D语义特征提升到超点上，避免多视图迭代训练。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了最先进的开放词汇分割性能，语义场重建速度提高了30倍以上，并支持层次化理解，在统一语义场内实现粗粒度和细粒度的开放词汇感知。&lt;h4&gt;结论&lt;/h4&gt;该方法在开放词汇分割方面取得了显著的性能提升，为自然语言与3D几何的结合提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Bridging natural language and 3D geometry is a crucial step toward flexible,language-driven scene understanding. While recent advances in 3D GaussianSplatting (3DGS) have enabled fast and high-quality scene reconstruction, research has also explored incorporating open-vocabulary understanding into 3DGS. However, most existing methods require iterative optimization over per-view 2D semantic feature maps, which not only results in inefficiencies but also leads to inconsistent 3D semantics across views. To address these limitations, we introduce a training-free framework that constructs a superpoint graph directly from Gaussian primitives. The superpoint graph partitions the scene into spatially compact and semantically coherent regions, forming view-consistent 3D entities and providing a structured foundation for open-vocabulary understanding. Based on the graph structure, we design an efficient reprojection strategy that lifts 2D semantic features onto the superpoints, avoiding costly multi-view iterative training. The resulting representation ensures strong 3D semantic coherence and naturally supports hierarchical understanding, enabling both coarse- and fine-grained open-vocabulary perception within a unified semantic field. Extensive experiments demonstrate that our method achieves state-of-the-art open-vocabulary segmentation performance, with semantic field reconstruction completed over 30 times faster. Our code will be available at https://github.com/Atrovast/THGS.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bridging natural language and 3D geometry is a crucial step toward flexible,language-driven scene understanding. While recent advances in 3D GaussianSplatting (3DGS) have enabled fast and high-quality scene reconstruction,research has also explored incorporating open-vocabulary understanding into3DGS. However, most existing methods require iterative optimization overper-view 2D semantic feature maps, which not only results in inefficiencies butalso leads to inconsistent 3D semantics across views. To address theselimitations, we introduce a training-free framework that constructs asuperpoint graph directly from Gaussian primitives. The superpoint graphpartitions the scene into spatially compact and semantically coherent regions,forming view-consistent 3D entities and providing a structured foundation foropen-vocabulary understanding. Based on the graph structure, we design anefficient reprojection strategy that lifts 2D semantic features onto thesuperpoints, avoiding costly multi-view iterative training. The resultingrepresentation ensures strong 3D semantic coherence and naturally supportshierarchical understanding, enabling both coarse- and fine-grainedopen-vocabulary perception within a unified semantic field. Extensiveexperiments demonstrate that our method achieves state-of-the-artopen-vocabulary segmentation performance, with semantic field reconstructioncompleted over $30\times$ faster. Our code will be available athttps://github.com/Atrovast/THGS.</description>
      <author>example@mail.com (Shaohui Dai, Yansong Qu, Zheyan Li, Xinyang Li, Shengchuan Zhang, Liujuan Cao)</author>
      <guid isPermaLink="false">2504.13153v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Pre-training with Combined Datasets for 3D Perception in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.12709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种利用大规模未标记数据进行3D感知预训练的方法，旨在提高自动驾驶中的3D感知模型性能。&lt;h4&gt;背景&lt;/h4&gt;基于在自然语言处理和2D视觉领域使用大量数据进行预训练模型取得的显著成果，研究者们希望探索大量数据预训练在自动驾驶3D感知中的潜力。&lt;h4&gt;目的&lt;/h4&gt;旨在通过使用来自异构数据集的大量未标记数据来预训练3D感知模型，以提升自动驾驶中的3D感知能力。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一种自监督预训练框架，从无标签数据中从头开始学习有效的3D表示，并结合基于提示适配器的领域自适应策略以减少数据集偏差。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在3D物体检测、BEV分割、3D物体跟踪和占用预测等下游任务上显著提升了模型性能，并且随着训练数据量的增加，性能持续提升，展示了3D感知模型在自动驾驶中持续受益的潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了3D感知模型在自动驾驶中的持续受益潜力，并计划发布源代码以激励社区进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;该论文提出了一种利用大规模未标记数据进行3D感知预训练的方法，旨在提高自动驾驶中的3D感知模型性能。基于在自然语言处理和2D视觉领域使用大量数据进行预训练模型取得的显著成果，研究者们希望探索大量数据预训练在自动驾驶3D感知中的潜力。旨在通过使用来自异构数据集的大量未标记数据来预训练3D感知模型，以提升自动驾驶中的3D感知能力。论文提出了一种自监督预训练框架，从无标签数据中从头开始学习有效的3D表示，并结合基于提示适配器的领域自适应策略以减少数据集偏差。该方法在3D物体检测、BEV分割、3D物体跟踪和占用预测等下游任务上显著提升了模型性能，并且随着训练数据量的增加，性能持续提升，展示了3D感知模型在自动驾驶中持续受益的潜力。该研究证明了3D感知模型在自动驾驶中的持续受益潜力，并计划发布源代码以激励社区进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The significant achievements of pre-trained models leveraging large volumesof data in the field of NLP and 2D vision inspire us to explore the potentialof extensive data pre-training for 3D perception in autonomous driving. Towardthis goal, this paper proposes to utilize massive unlabeled data fromheterogeneous datasets to pre-train 3D perception models. We introduce aself-supervised pre-training framework that learns effective 3D representationsfrom scratch on unlabeled data, combined with a prompt adapter based domainadaptation strategy to reduce dataset bias. The approach significantly improvesmodel performance on downstream tasks such as 3D object detection, BEVsegmentation, 3D object tracking, and occupancy prediction, and shows steadyperformance increase as the training data volume scales up, demonstrating thepotential of continually benefit 3D perception models for autonomous driving.We will release the source code to inspire further investigations in thecommunity.</description>
      <author>example@mail.com (Shumin Wang, Zhuoran Yang, Lidian Wang, Zhipeng Tang, Heng Li, Lehan Pan, Sha Zhang, Jie Peng, Jianmin Ji, Yanyong Zhang)</author>
      <guid isPermaLink="false">2504.12709v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Explainable Scene Understanding with Qualitative Representations and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.12817v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Workshop "Advancing Automated Driving in Highly Interactive Scenarios  through Behavior Prediction, Trustworthy AI, and Remote Operations" @ 36th  IEEE Intelligent Vehicles Symposium (IV)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将图神经网络（GNN）与定性可解释图（QXG）集成，以用于自动驾驶中的场景理解。&lt;h4&gt;背景&lt;/h4&gt;场景理解是任何进一步反应性或前瞻性决策的基础，而场景理解及相关推理本质上是解释任务，如为什么其他交通参与者会这样做，什么或谁导致了他们的行为。&lt;h4&gt;目的&lt;/h4&gt;通过结合定性表示与深度学习方法，实现自动驾驶系统中可解释的场景理解。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的GNN架构，该架构处理整个图结构以识别交通场景中的相关对象。在nuScenes数据集上评估了该方法，该数据集富含DriveLM的人类标注的相关标签。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与基线方法相比，基于GNN的方法实现了更好的性能。该模型有效地处理了相关对象识别任务中的固有类别不平衡问题，同时考虑了场景中所有对象之间的完整时空关系。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了将定性表示与深度学习方法结合用于自动驾驶系统中可解释场景理解的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the integration of graph neural networks (GNNs) withQualitative Explainable Graphs (QXGs) for scene understanding in automateddriving. Scene understanding is the basis for any further reactive or proactivedecision-making. Scene understanding and related reasoning is inherently anexplanation task: why is another traffic participant doing something, what orwho caused their actions? While previous work demonstrated QXGs' effectivenessusing shallow machine learning models, these approaches were limited toanalysing single relation chains between object pairs, disregarding the broaderscene context. We propose a novel GNN architecture that processes entire graphstructures to identify relevant objects in traffic scenes. We evaluate ourmethod on the nuScenes dataset enriched with DriveLM's human-annotatedrelevance labels. Experimental results show that our GNN-based approachachieves superior performance compared to baseline methods. The modeleffectively handles the inherent class imbalance in relevant objectidentification tasks while considering the complete spatial-temporalrelationships between all objects in the scene. Our work demonstrates thepotential of combining qualitative representations with deep learningapproaches for explainable scene understanding in autonomous driving systems.</description>
      <author>example@mail.com (Nassim Belmecheri, Arnaud Gotlieb, Nadjib Lazaar, Helge Spieker)</author>
      <guid isPermaLink="false">2504.12817v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>The Others: Naturally Isolating Out-of-Distribution Samples for Robust Open-Set Semi-Supervised Learning</title>
      <link>http://arxiv.org/abs/2504.12569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MagMatch的新框架，用于解决开放集半监督学习中的挑战，通过原型对比学习范式自然隔离异常样本，并在多个数据集上证明了其在分类准确率和异常检测方面的优越性。&lt;h4&gt;背景&lt;/h4&gt;开放集半监督学习（OSSL）旨在从可能包含分布内（ID）和未知分布外（OOD）类别的未标记数据中学习。然而，现有的OSSL方法在特征空间中形成次优结构，要么排除OOD样本，要么干扰它们，或者过度信任它们的信息。&lt;h4&gt;目的&lt;/h4&gt;提出MagMatch框架，旨在通过原型对比学习范式自然隔离OOD样本，并提高封闭集分类准确率和OOD检测AUROC。&lt;h4&gt;方法&lt;/h4&gt;MagMatch不将原型分配给OOD样本，而是使用ID-Selective Magnetic（ISM）模块选择性地将ID样本与类别原型对齐，同时允许OOD样本在特征空间中保持未对齐状态。此外，还提出了Selective Magnetic Alignment（SMA）损失函数，该函数根据样本置信度动态调整对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在多个数据集上的实验表明，MagMatch在封闭集分类准确率和OOD检测AUROC方面显著优于现有方法，特别是在泛化到未见过的OOD数据方面。&lt;h4&gt;结论&lt;/h4&gt;MagMatch框架通过有效隔离OOD样本和动态调整对齐，提高了开放集半监督学习的性能。&lt;h4&gt;翻译&lt;/h4&gt;Open-Set Semi-Supervised Learning (OSSL) addresses the practical challenge of learning from unlabeled data that may include both in-distribution (ID) and unknown out-of-distribution (OOD) classes. However, existing OSSL methods form suboptimal feature spaces by either excluding OOD samples, interfering with them, or overtrusting their information during training. In this work, we introduce MagMatch, a novel framework that naturally isolates OOD samples through a prototype-based contrastive learning paradigm. Unlike conventional methods, MagMatch does not assign any prototypes to OOD samples; instead, it selectively aligns ID samples with class prototypes using an ID-Selective Magnetic (ISM) module, while allowing OOD samples - the 'others' - to remain unaligned in the feature space. To support this process, we propose Selective Magnetic Alignment (SMA) loss for unlabeled data, which dynamically adjusts alignment based on sample confidence. Extensive experiments on diverse datasets demonstrate that MagMatch significantly outperforms existing methods in both closed-set classification accuracy and OOD detection AUROC, especially in generalizing to unseen OOD data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-Set Semi-Supervised Learning (OSSL) tackles the practical challenge oflearning from unlabeled data that may include both in-distribution (ID) andunknown out-of-distribution (OOD) classes. However, existing OSSL methods formsuboptimal feature spaces by either excluding OOD samples, interfering withthem, or overtrusting their information during training. In this work, weintroduce MagMatch, a novel framework that naturally isolates OOD samplesthrough a prototype-based contrastive learning paradigm. Unlike conventionalmethods, MagMatch does not assign any prototypes to OOD samples; instead, itselectively aligns ID samples with class prototypes using an ID-SelectiveMagnetic (ISM) module, while allowing OOD samples - the "others" - to remainunaligned in the feature space. To support this process, we propose SelectiveMagnetic Alignment (SMA) loss for unlabeled data, which dynamically adjustsalignment based on sample confidence. Extensive experiments on diverse datasetsdemonstrate that MagMatch significantly outperforms existing methods in bothclosed-set classification accuracy and OOD detection AUROC, especially ingeneralizing to unseen OOD data.</description>
      <author>example@mail.com (You Rim Choi, Subeom Park, Seojun Heo, Eunchung Noh, Hyung-Sin Kim)</author>
      <guid isPermaLink="false">2504.12569v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>AdaVid: Adaptive Video-Language Pretraining</title>
      <link>http://arxiv.org/abs/2504.12513v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPRW 2025. Project Page: https://chaitanya100100.github.io/AdaVid/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AdaVid是一种灵活的架构框架，旨在学习高效的视频编码器，能够根据可用资源动态调整其计算开销。&lt;h4&gt;背景&lt;/h4&gt;现有的对比视频语言预训练模型在计算资源受限的边缘设备上部署存在挑战，且通常只训练处理短视频片段。&lt;h4&gt;目的&lt;/h4&gt;提出AdaVid框架，以学习高效的视频编码器，并能在计算资源有限的情况下动态调整计算量。&lt;h4&gt;方法&lt;/h4&gt;AdaVid的核心是一个自适应变换器块，它能够根据Matryoshka表示学习原理在推理时调整隐藏嵌入维度。此外，还提出了一种轻量级分层网络，用于聚合短片段特征。&lt;h4&gt;主要发现&lt;/h4&gt;AdaVid-EgoVLP在Ego4D数据集上训练，使用一半的计算资源即可匹配标准EgoVLP在短视频语言基准测试上的性能，并且在相同计算资源下表现更优。在Diving48分类基准测试中，AdaVid允许使用更多帧数而不超过计算限制。&lt;h4&gt;结论&lt;/h4&gt;AdaVid在保持计算效率的同时，实现了在多个长视频基准测试中的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive video-language pretraining has demonstrated great success in learning rich and robust video representations. However, deploying such video encoders on compute-constrained edge devices remains challenging due to their high computational demands. Additionally, existing models are typically trained to process only short video clips, often limited to 4 to 64 frames. In this paper, we introduce AdaVid, a flexible architectural framework designed to learn efficient video encoders that can dynamically adapt their computational footprint based on available resources. At the heart of AdaVid is an adaptive transformer block, inspired by Matryoshka Representation Learning, which allows the model to adjust its hidden embedding dimension at inference time. We show that AdaVid-EgoVLP, trained on video-narration pairs from the large-scale Ego4D dataset, matches the performance of the standard EgoVLP on short video-language benchmarks using only half the compute, and even outperforms EgoVLP when given equal computational resources. We further explore the trade-off between frame count and compute on the challenging Diving48 classification benchmark, showing that AdaVid enables the use of more frames without exceeding computational limits. To handle longer videos, we also propose a lightweight hierarchical network that aggregates short clip features, achieving a strong balance between compute efficiency and accuracy across several long video benchmarks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive video-language pretraining has demonstrated great success inlearning rich and robust video representations. However, deploying such videoencoders on compute-constrained edge devices remains challenging due to theirhigh computational demands. Additionally, existing models are typically trainedto process only short video clips, often limited to 4 to 64 frames. In thispaper, we introduce AdaVid, a flexible architectural framework designed tolearn efficient video encoders that can dynamically adapt their computationalfootprint based on available resources. At the heart of AdaVid is an adaptivetransformer block, inspired by Matryoshka Representation Learning, which allowsthe model to adjust its hidden embedding dimension at inference time. We showthat AdaVid-EgoVLP, trained on video-narration pairs from the large-scale Ego4Ddataset, matches the performance of the standard EgoVLP on short video-languagebenchmarks using only half the compute, and even outperforms EgoVLP when givenequal computational resources. We further explore the trade-off between framecount and compute on the challenging Diving48 classification benchmark, showingthat AdaVid enables the use of more frames without exceeding computationallimits. To handle longer videos, we also propose a lightweight hierarchicalnetwork that aggregates short clip features, achieving a strong balance betweencompute efficiency and accuracy across several long video benchmarks.</description>
      <author>example@mail.com (Chaitanya Patel, Juan Carlos Niebles, Ehsan Adeli)</author>
      <guid isPermaLink="false">2504.12513v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>LLMs Meet Finance: Fine-Tuning Foundation Models for the Open FinLLM Leaderboard</title>
      <link>http://arxiv.org/abs/2504.13125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了大型语言模型（LLMs）在金融任务中的应用。&lt;h4&gt;背景&lt;/h4&gt;基于Open FinLLMLeaderboard作为基准，对基础模型进行了微调。&lt;h4&gt;目的&lt;/h4&gt;通过微调模型提升其金融能力。&lt;h4&gt;方法&lt;/h4&gt;使用了包括监督微调（SFT）、直接偏好优化（DPO）和强化学习（RL）等技术。&lt;h4&gt;主要发现&lt;/h4&gt;微调模型在多种金融任务中展现了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;工作展示了大型语言模型（LLMs）在金融应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the application of large language models (LLMs) to financial tasks. We fine-tuned foundation models using the Open FinLLMLeaderboard as a benchmark. Building on Qwen2.5 and Deepseek-R1, we employed techniques including supervised fine-tuning (SFT), direct preference optimization (DPO), and reinforcement learning (RL) to enhance their financial capabilities. The fine-tuned models demonstrated substantial performance gains across a wide range of financial tasks. Moreover, we measured the data scaling law in the financial domain. Our work demonstrates the potential of large language models (LLMs) in financial applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the application of large language models (LLMs) tofinancial tasks. We fine-tuned foundation models using the Open FinLLMLeaderboard as a benchmark. Building on Qwen2.5 and Deepseek-R1, we employedtechniques including supervised fine-tuning (SFT), direct preferenceoptimization (DPO), and reinforcement learning (RL) to enhance their financialcapabilities. The fine-tuned models demonstrated substantial performance gainsacross a wide range of financial tasks. Moreover, we measured the data scalinglaw in the financial domain. Our work demonstrates the potential of largelanguage models (LLMs) in financial applications.</description>
      <author>example@mail.com (Varun Rao, Youran Sun, Mahendra Kumar, Tejas Mutneja, Agastya Mukherjee, Haizhao Yang)</author>
      <guid isPermaLink="false">2504.13125v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>3D-PNAS: 3D Industrial Surface Anomaly Synthesis with Perlin Noise</title>
      <link>http://arxiv.org/abs/2504.12856v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Perlin噪声和表面参数化的3D异常生成方法，用于解决工业制造中3D数据表面质量检测的挑战。&lt;h4&gt;背景&lt;/h4&gt;大型预训练视觉基础模型在多种视觉任务中显示出巨大潜力，但在工业异常检测中，真实缺陷样本的稀缺限制了这些模型的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的3D异常生成方法，以解决3D数据在工业质量检测中的潜在问题。&lt;h4&gt;方法&lt;/h4&gt;使用3D-PNAS方法，通过将点云投影到二维平面，从Perlin噪声场中采样多尺度噪声值，并沿法线方向扰动点云来生成真实的3D表面异常。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过控制噪声尺度、扰动强度和八度等关键参数，可以精细控制生成的异常，从而创建从显著变形到细微表面变化的多样化缺陷模式。&lt;h4&gt;结论&lt;/h4&gt;该方法在不同物体类型上产生了一致且几何上合理的异常，适应了它们的特定表面特征，并提供了完整的代码库和可视化工具包，以促进未来的研究。&lt;h4&gt;翻译&lt;/h4&gt;Large pretrained vision foundation models have shown significant potential in various vision tasks. However, for industrial anomaly detection, the scarcity of real defect samples poses a critical challenge in leveraging these models. While 2D anomaly generation has significantly advanced with established generative models, the adoption of 3D sensors in industrial manufacturing has made leveraging 3D data for surface quality inspection an emerging trend. In contrast to 2D techniques, 3D anomaly generation remains largely unexplored, limiting the potential of 3D data in industrial quality inspection. To address this gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS, based on Perlin noise and surface parameterization. Our method generates realistic 3D surface anomalies by projecting the point cloud onto a 2D plane, sampling multi-scale noise values from a Perlin noise field, and perturbing the point cloud along its normal direction. Through comprehensive visualization experiments, we demonstrate how key parameters - including noise scale, perturbation strength, and octaves, provide fine-grained control over the generated anomalies, enabling the creation of diverse defect patterns from pronounced deformations to subtle surface variations. Additionally, our cross-category experiments show that the method produces consistent yet geometrically plausible anomalies across different object types, adapting to their specific surface characteristics. We also provide a comprehensive codebase and visualization toolkit to facilitate future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large pretrained vision foundation models have shown significant potential invarious vision tasks. However, for industrial anomaly detection, the scarcityof real defect samples poses a critical challenge in leveraging these models.While 2D anomaly generation has significantly advanced with establishedgenerative models, the adoption of 3D sensors in industrial manufacturing hasmade leveraging 3D data for surface quality inspection an emerging trend. Incontrast to 2D techniques, 3D anomaly generation remains largely unexplored,limiting the potential of 3D data in industrial quality inspection. To addressthis gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS,based on Perlin noise and surface parameterization. Our method generatesrealistic 3D surface anomalies by projecting the point cloud onto a 2D plane,sampling multi-scale noise values from a Perlin noise field, and perturbing thepoint cloud along its normal direction. Through comprehensive visualizationexperiments, we demonstrate how key parameters - including noise scale,perturbation strength, and octaves, provide fine-grained control over thegenerated anomalies, enabling the creation of diverse defect patterns frompronounced deformations to subtle surface variations. Additionally, ourcross-category experiments show that the method produces consistent yetgeometrically plausible anomalies across different object types, adapting totheir specific surface characteristics. We also provide a comprehensivecodebase and visualization toolkit to facilitate future research.</description>
      <author>example@mail.com (Yifeng Cheng, Juan Du)</author>
      <guid isPermaLink="false">2504.12856v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex</title>
      <link>http://arxiv.org/abs/2504.12474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BiGTex的新型架构，该架构通过堆叠图-文本融合单元，紧密整合了图神经网络（GNNs）和大型语言模型（LLMs），以解决在表示学习中捕获节点关联文本语义丰富性和图结构依赖性的挑战。&lt;h4&gt;背景&lt;/h4&gt;GNNs擅长建模拓扑信息，但缺乏处理非结构化文本的能力；而LLMs在文本理解方面表现优异，但通常不了解图结构。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够同时处理文本和图结构信息的模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为BiGTex的新架构，它通过堆叠图-文本融合单元将GNNs和LLMs紧密结合，并使用参数高效的微调（LoRA）进行训练，同时保持LLM冻结。&lt;h4&gt;主要发现&lt;/h4&gt;在五个基准数据集上的广泛实验表明，BiGTex在节点分类和链接预测任务中实现了最先进的性能，且能够有效泛化。消融研究表明，软提示和双向注意力在模型成功中起着重要作用。&lt;h4&gt;结论&lt;/h4&gt;BiGTex是一种有效的模型，能够同时处理文本和图结构信息，并在节点分类和链接预测任务中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-attributed graphs (TAGs) present unique challenges in representationlearning by requiring models to capture both the semantic richness ofnode-associated texts and the structural dependencies of the graph. While graphneural networks (GNNs) excel at modeling topological information, they lack thecapacity to process unstructured text. Conversely, large language models (LLMs)are proficient in text understanding but are typically unaware of graphstructure. In this work, we propose BiGTex (Bidirectional Graph Text), a novelarchitecture that tightly integrates GNNs and LLMs through stacked Graph-TextFusion Units. Each unit allows for mutual attention between textual andstructural representations, enabling information to flow in both directions,text influencing structure and structure guiding textual interpretation. Theproposed architecture is trained using parameter-efficient fine-tuning (LoRA),keeping the LLM frozen while adapting to task-specific signals. Extensiveexperiments on five benchmark datasets demonstrate that BiGTex achievesstate-of-the-art performance in node classification and generalizes effectivelyto link prediction. An ablation study further highlights the importance of softprompting and bi-directional attention in the model's success.</description>
      <author>example@mail.com (Azadeh Beiranvand, Seyed Mehdi Vahidipour)</author>
      <guid isPermaLink="false">2504.12474v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>CAGE-GS: High-fidelity Cage Based 3D Gaussian Splatting Deformation</title>
      <link>http://arxiv.org/abs/2504.12800v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于笼子的3D高斯喷射（3DGS）变形方法CAGE-GS，该方法能够将源3DGS场景与用户定义的目标形状无缝对齐，并在变形过程中保持原始细节。&lt;h4&gt;背景&lt;/h4&gt;随着3D高斯喷射作为真实场景的3D表示越来越受欢迎，如何实现用户友好的变形以创建新的场景，同时保留原始3DGS的精细细节，已成为研究热点。&lt;h4&gt;目的&lt;/h4&gt;提出CAGE-GS方法，以实现3DGS场景与用户定义的目标形状的无缝对齐，并在变形过程中保持细节。&lt;h4&gt;方法&lt;/h4&gt;CAGE-GS方法通过学习目标形状的变形笼来引导源场景的几何变换。为了保持纹理的准确性，该方法使用基于雅可比矩阵的策略来更新每个高斯函数的协方差参数。该方法灵活，可以适应多种目标形状表示，包括文本、图像、点云、网格和3DGS模型。&lt;h4&gt;主要发现&lt;/h4&gt;在公共数据集和新提出的场景上的大量实验和消融研究表明，CAGE-GS方法在效率和变形质量方面均显著优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;CAGE-GS方法为3DGS场景的变形提供了一种高效且质量优良的新方法，为创建新颖的场景提供了有力的支持。&lt;h4&gt;翻译&lt;/h4&gt;As 3D Gaussian Splatting (3DGS) gains popularity as a 3D representation of real scenes, enabling user-friendly deformation to create novel scenes while preserving fine details from the original 3DGS has attracted significant research attention. We introduce CAGE-GS, a cage-based 3DGS deformation method that seamlessly aligns a source 3DGS scene with a user-defined target shape. Our approach learns a deformation cage from the target, which guides the geometric transformation of the source scene. While the cages effectively control structural alignment, preserving the textural appearance of 3DGS remains challenging due to the complexity of covariance parameters. To address this, we employ a Jacobian matrix-based strategy to update the covariance parameters of each Gaussian, ensuring texture fidelity post-deformation. Our method is highly flexible, accommodating various target shape representations, including texts, images, point clouds, meshes and 3DGS models. Extensive experiments and ablation studies on both public datasets and newly proposed scenes demonstrate that our method significantly outperforms existing techniques in both efficiency and deformation quality.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As 3D Gaussian Splatting (3DGS) gains popularity as a 3D representation ofreal scenes, enabling user-friendly deformation to create novel scenes whilepreserving fine details from the original 3DGS has attracted significantresearch attention. We introduce CAGE-GS, a cage-based 3DGS deformation methodthat seamlessly aligns a source 3DGS scene with a user-defined target shape.Our approach learns a deformation cage from the target, which guides thegeometric transformation of the source scene. While the cages effectivelycontrol structural alignment, preserving the textural appearance of 3DGSremains challenging due to the complexity of covariance parameters. To addressthis, we employ a Jacobian matrix-based strategy to update the covarianceparameters of each Gaussian, ensuring texture fidelity post-deformation. Ourmethod is highly flexible, accommodating various target shape representations,including texts, images, point clouds, meshes and 3DGS models. Extensiveexperiments and ablation studies on both public datasets and newly proposedscenes demonstrate that our method significantly outperforms existingtechniques in both efficiency and deformation quality.</description>
      <author>example@mail.com (Yifei Tong, Runze Tian, Xiao Han, Dingyao Liu, Fenggen Yu, Yan Zhang)</author>
      <guid isPermaLink="false">2504.12800v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding</title>
      <link>http://arxiv.org/abs/2504.13180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究在完全开放和可复现的框架下构建感知语言模型（PLM），以实现图像和视频理解的透明研究。&lt;h4&gt;背景&lt;/h4&gt;许多高性能的视觉语言模型是封闭源代码的，这遮蔽了它们的数据、设计和训练方法，影响了科学进步的测量。&lt;h4&gt;目的&lt;/h4&gt;开发一个透明的研究框架，以促进图像和视频理解领域的科学进步。&lt;h4&gt;方法&lt;/h4&gt;分析标准的训练流程，不依赖从封闭模型中提取的蒸馏数据，并探索大规模合成数据来识别关键数据差距，特别是详细视频理解方面的差距。发布2.8M个精细粒度视频问答对和时空定位的视频字幕。引入PLM-VideoBench，用于评估视频理解任务，重点关注对视频中的“什么”、“哪里”、“何时”和“如何”进行推理的能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过开放和可复现的研究框架，可以识别视频理解中的关键数据差距，并通过发布标注数据集和评估工具来弥合这些差距。&lt;h4&gt;结论&lt;/h4&gt;通过提供数据、训练方法、代码和模型，使得研究工作可复现，从而推动视觉语言模型研究的透明度和科学进步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉语言模型在计算机视觉研究中至关重要，但许多高性能模型仍然是封闭源代码的，这掩盖了它们的数据、设计和训练方法。研究界通过从黑盒模型中提取蒸馏数据来标记训练数据，实现了强大的基准结果，但这也以可测量的科学进步为代价。然而，没有了解教师模型及其数据源的具体细节，科学进步仍然难以衡量。在本文中，我们研究了在完全开放和可复现的框架下构建感知语言模型（PLM），以实现图像和视频理解的透明研究。我们分析了不依赖封闭模型蒸馏数据的标准训练流程，并探索了大规模合成数据来识别关键数据差距，特别是在详细视频理解方面。为了弥合这些差距，我们发布了2.8M个精细粒度视频问答对和时空定位的视频字幕。此外，我们引入了PLM-VideoBench，一套用于评估具有挑战性的视频理解任务的工具，重点关注对视频中的“什么”、“哪里”、“何时”和“如何”进行推理的能力。通过提供数据、训练方法、代码和模型，使我们的工作完全可复现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models are integral to computer vision research, yet manyhigh-performing models remain closed-source, obscuring their data, design andtraining recipe. The research community has responded by using distillationfrom black-box models to label training data, achieving strong benchmarkresults, at the cost of measurable scientific progress. However, withoutknowing the details of the teacher model and its data sources, scientificprogress remains difficult to measure. In this paper, we study building aPerception Language Model (PLM) in a fully open and reproducible framework fortransparent research in image and video understanding. We analyze standardtraining pipelines without distillation from proprietary models and explorelarge-scale synthetic data to identify critical data gaps, particularly indetailed video understanding. To bridge these gaps, we release 2.8Mhuman-labeled instances of fine-grained video question-answer pairs andspatio-temporally grounded video captions. Additionally, we introducePLM-VideoBench, a suite for evaluating challenging video understanding tasksfocusing on the ability to reason about "what", "where", "when", and "how" of avideo. We make our work fully reproducible by providing data, training recipes,code &amp; models.</description>
      <author>example@mail.com (Jang Hyun Cho, Andrea Madotto, Effrosyni Mavroudi, Triantafyllos Afouras, Tushar Nagarajan, Muhammad Maaz, Yale Song, Tengyu Ma, Shuming Hu, Suyog Jain, Miguel Martin, Huiyu Wang, Hanoona Rasheed, Peize Sun, Po-Yao Huang, Daniel Bolya, Nikhila Ravi, Shashank Jain, Tammy Stark, Shane Moon, Babak Damavandi, Vivian Lee, Andrew Westbury, Salman Khan, Philipp Krähenbühl, Piotr Dollár, Lorenzo Torresani, Kristen Grauman, Christoph Feichtenhofer)</author>
      <guid isPermaLink="false">2504.13180v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating Enhanced Rotary Position Embedding</title>
      <link>http://arxiv.org/abs/2504.12643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本技术报告介绍了对StreamPETR框架的针对性改进，旨在提高速度估计能力，这是影响NuScenes检测评分的关键因素。&lt;h4&gt;背景&lt;/h4&gt;StreamPETR在3D边界框检测方面表现出色，平均精度较高，但在NuScenes数据集上的速度估计存在瓶颈。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一限制，提出了一种定制化的位置嵌入策略，以增强时间建模能力。&lt;h4&gt;方法&lt;/h4&gt;在NuScenes测试集上进行了实验评估，使用ViT-L骨干网络实现了70.86%的NuScenes检测评分（NDS），达到了相机仅3D目标检测的新基准。&lt;h4&gt;主要发现&lt;/h4&gt;速度估计是StreamPETR在NuScenes数据集上的一个瓶颈，通过改进方法，达到了业界领先的NDS。&lt;h4&gt;结论&lt;/h4&gt;改进的StreamPETR框架在NuScenes测试集上实现了卓越的速度估计性能，为相机仅3D目标检测设定了新标准。&lt;h4&gt;翻译&lt;/h4&gt;This technical report introduces a targeted improvement to the StreamPETR framework, specifically aimed at enhancing velocity estimation, a critical factor influencing the overall NuScenes Detection Score. While StreamPETR exhibits strong 3D bounding box detection performance as reflected by its high mean Average Precision, our analysis identified velocity estimation as a substantial bottleneck when evaluated on the NuScenes dataset. To overcome this limitation, we propose a customized positional embedding strategy tailored to enhance temporal modeling capabilities. Experimental evaluations conducted on the NuScenes test set demonstrate that our improved approach achieves a state-of-the-art NDS of 70.86% using the ViT-L backbone, setting a new benchmark for camera-only 3D object detection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report introduces a targeted improvement to the StreamPETRframework, specifically aimed at enhancing velocity estimation, a criticalfactor influencing the overall NuScenes Detection Score. While StreamPETRexhibits strong 3D bounding box detection performance as reflected by its highmean Average Precision our analysis identified velocity estimation as asubstantial bottleneck when evaluated on the NuScenes dataset. To overcome thislimitation, we propose a customized positional embedding strategy tailored toenhance temporal modeling capabilities. Experimental evaluations conducted onthe NuScenes test set demonstrate that our improved approach achieves astate-of-the-art NDS of 70.86% using the ViT-L backbone, setting a newbenchmark for camera-only 3D object detection.</description>
      <author>example@mail.com (Hang Ji, Tao Ni, Xufeng Huang, Tao Luo, Xin Zhan, Junbo Chen)</author>
      <guid isPermaLink="false">2504.12643v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Cocoa Pod Disease Classification via Transfer Learning and Ensemble Methods: Toward Robust Predictive Modeling</title>
      <link>http://arxiv.org/abs/2504.12992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于集成学习方法的可可豆病害分类方法，该方法结合了迁移学习和三种集成学习策略：Bagging、Boosting和Stacking。&lt;h4&gt;背景&lt;/h4&gt;可可豆病害是影响可可产量和质量的重要因素。&lt;h4&gt;目的&lt;/h4&gt;提高可可豆病害分类的准确性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的卷积神经网络（如VGG16、VGG19、ResNet50等）作为基础学习器，通过迁移学习和集成学习策略进行病害分类。构建了一个包含6000张可可豆图像的平衡数据集，并对图像进行了增强处理，以适应光照、方向和病害严重程度的变化。使用准确率、精确率、召回率和F1分数评估了每种集成学习方法的表现。&lt;h4&gt;主要发现&lt;/h4&gt;Bagging方法在测试中实现了100%的准确率，优于Boosting（97%）和Stacking（92%）。&lt;h4&gt;结论&lt;/h4&gt;将迁移学习与集成技术相结合可以改善模型泛化能力和可靠性，为精准农业和自动化作物病害管理提供了有前景的方向。&lt;h4&gt;翻译&lt;/h4&gt;This study presents an ensemble-based approach for cocoa pod diseaseclassification by integrating transfer learning with three ensemble learningstrategies: Bagging, Boosting, and Stacking. Pre-trained convolutional neuralnetworks, including VGG16, VGG19, ResNet50, ResNet101, InceptionV3, andXception, were fine-tuned and employed as base learners to detect three diseasecategories: Black Pod Rot, Pod Borer, and Healthy. A balanced dataset of 6,000cocoa pod images was curated and augmented to ensure robustness againstvariations in lighting, orientation, and disease severity. The performance ofeach ensemble method was evaluated using accuracy, precision, recall, andF1-score. Experimental results show that Bagging consistently achieved superiorclassification performance with a test accuracy of 100%, outperforming Boosting(97%) and Stacking (92%). The findings confirm that combining transfer learningwith ensemble techniques improves model generalization and reliability, makingit a promising direction for precision agriculture and automated crop diseasemanagement.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study presents an ensemble-based approach for cocoa pod diseaseclassification by integrating transfer learning with three ensemble learningstrategies: Bagging, Boosting, and Stacking. Pre-trained convolutional neuralnetworks, including VGG16, VGG19, ResNet50, ResNet101, InceptionV3, andXception, were fine-tuned and employed as base learners to detect three diseasecategories: Black Pod Rot, Pod Borer, and Healthy. A balanced dataset of 6,000cocoa pod images was curated and augmented to ensure robustness againstvariations in lighting, orientation, and disease severity. The performance ofeach ensemble method was evaluated using accuracy, precision, recall, andF1-score. Experimental results show that Bagging consistently achieved superiorclassification performance with a test accuracy of 100%, outperforming Boosting(97%) and Stacking (92%). The findings confirm that combining transfer learningwith ensemble techniques improves model generalization and reliability, makingit a promising direction for precision agriculture and automated crop diseasemanagement.</description>
      <author>example@mail.com (Devina Anduyan, Nyza Cabillo, Navy Gultiano, Mark Phil Pacot)</author>
      <guid isPermaLink="false">2504.12992v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>DG-MVP: 3D Domain Generalization via Multiple Views of Point Clouds for Classification</title>
      <link>http://arxiv.org/abs/2504.12456v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的3D点云域泛化方法，通过使用多个2D投影来缓解缺失点的难题，并采用了一种简单而有效的基于卷积的模型来提取特征，以应对不同点云域之间的差异。&lt;h4&gt;背景&lt;/h4&gt;虽然深度神经网络在3D点云分类中取得了显著成功，但它们依赖于大规模、标注过的点云数据集，这些数据集的构建非常耗时。与使用LiDAR传感器捕获数据并进行标注相比，从CAD模型中采样点云相对容易，但CAD模型中的点云是规则的，不包含遮挡和缺失点，这导致了与LiDAR数据之间的较大域差异。&lt;h4&gt;目的&lt;/h4&gt;针对3D点云域泛化问题，提出一种能够泛化到未见点云域的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法通过分析基于点的方法的点利用率和观察不同域的点云几何形状，发现大量点特征被基于点的通过max-pooling操作丢弃。为了解决这些问题，提出了一种新的方法，该方法使用3D点云的多个2D投影来缓解缺失点的问题，并涉及一个简单而有效的基于卷积的模型来提取特征。&lt;h4&gt;主要发现&lt;/h4&gt;基于点的3D域泛化方法通过max-pooling操作丢弃了大量点特征，这在域泛化中是一个显著的浪费，因为域泛化比监督学习更具挑战性，而点云本身就已经受到缺失点和遮挡的影响。&lt;h4&gt;结论&lt;/h4&gt;在PointDA-10和Sim-to-Real基准测试上进行的实验表明，所提出的方法是有效的，优于不同的基线，并且可以从合成域很好地迁移到现实世界域。&lt;h4&gt;翻译&lt;/h4&gt;Deep neural networks have achieved significant success in 3D point cloud classification while relying on large-scale, annotated point cloud datasets, which are labor-intensive to build. Compared to capturing data with LiDAR sensors and then performing annotation, it is relatively easier to sample point clouds from CAD models. Yet, data sampled from CAD models is regular, and does not suffer from occlusion and missing points, which are very common for LiDAR data, creating a large domain shift. Therefore, it is critical to develop methods that can generalize well across different point cloud domains. In this paper, we focus on the 3D point cloud domain generalization problem. Existing 3D domain generalization methods employ point-based backbones to extract point cloud features. Yet, by analyzing point utilization of point-based methods and observing the geometry of point clouds from different domains, we have found that a large number of point features are discarded by point-based methods through the max-pooling operation. This is a significant waste especially considering the fact that domain generalization is more challenging than supervised learning, and point clouds are already affected by missing points and occlusion to begin with. To address these issues, we propose a novel method for 3D point cloud domain generalization, which can generalize to unseen domains of point clouds. Our proposed method employs multiple 2D projections of a 3D point cloud to alleviate the issue of missing points and involves a simple yet effective convolution-based model to extract features. The experiments, performed on the PointDA-10 and Sim-to-Real benchmarks, demonstrate the effectiveness of our proposed method, which outperforms different baselines, and can transfer well from synthetic domain to real-world domain.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks have achieved significant success in 3D point cloudclassification while relying on large-scale, annotated point cloud datasets,which are labor-intensive to build. Compared to capturing data with LiDARsensors and then performing annotation, it is relatively easier to sample pointclouds from CAD models. Yet, data sampled from CAD models is regular, and doesnot suffer from occlusion and missing points, which are very common for LiDARdata, creating a large domain shift. Therefore, it is critical to developmethods that can generalize well across different point cloud domains. %In thispaper, we focus on the 3D point cloud domain generalization problem. Existing3D domain generalization methods employ point-based backbones to extract pointcloud features. Yet, by analyzing point utilization of point-based methods andobserving the geometry of point clouds from different domains, we have foundthat a large number of point features are discarded by point-based methodsthrough the max-pooling operation. This is a significant waste especiallyconsidering the fact that domain generalization is more challenging thansupervised learning, and point clouds are already affected by missing pointsand occlusion to begin with. To address these issues, we propose a novel methodfor 3D point cloud domain generalization, which can generalize to unseendomains of point clouds. Our proposed method employs multiple 2D projections ofa 3D point cloud to alleviate the issue of missing points and involves a simpleyet effective convolution-based model to extract features. The experiments,performed on the PointDA-10 and Sim-to-Real benchmarks, demonstrate theeffectiveness of our proposed method, which outperforms different baselines,and can transfer well from synthetic domain to real-world domain.</description>
      <author>example@mail.com (Huantao Ren, Minmin Yang, Senem Velipasalar)</author>
      <guid isPermaLink="false">2504.12456v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>VistaDPO: Video Hierarchical Spatial-Temporal Direct Preference Optimization for Large Video Models</title>
      <link>http://arxiv.org/abs/2504.13122v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and Data: https://github.com/HaroldChen19/VistaDPO&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VistaDPO，一个用于视频分层时空直接偏好优化的新框架，旨在解决大型视频模型在视频理解中与人类直觉不符和视频幻觉问题。&lt;h4&gt;背景&lt;/h4&gt;大型视频模型（LVMs）基于大型语言模型（LLMs）在视频理解方面有潜力，但往往存在与人类直觉不匹配和视频幻觉问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出VistaDPO框架，以提高文本-视频偏好对齐。&lt;h4&gt;方法&lt;/h4&gt;VistaDPO在三个层次上增强文本-视频偏好对齐：实例级别、时间级别和感知级别。此外，构建了VistaDPO-7k数据集，包含7.2K个问答对，并附有时间戳、关键帧和边界框等时空定位信息。&lt;h4&gt;主要发现&lt;/h4&gt;在视频幻觉、视频问答和字幕性能任务等基准测试中，VistaDPO显著提高了现有LVMs的性能，有效地缓解了视频-语言不匹配和幻觉问题。&lt;h4&gt;结论&lt;/h4&gt;VistaDPO框架和VistaDPO-7k数据集为视频理解提供了有效的方法和数据支持。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces VistaDPO, a novel framework for Video Hierarchical Spatial-Temporal Direct Preference Optimization, aiming to address the challenges of misalignment with human intuition and video hallucination in large video models (LVMs) based on large language models (LLMs). VistaDPO enhances text-video preference alignment across three hierarchical levels: instance level, temporal level, and perceptual level. In addition, the VistaDPO-7k dataset, containing 7.2K QA pairs annotated with selected and rejected responses, along with spatial-temporal grounding information such as timestamps, keyframes, and bounding boxes, has been constructed. Extensive experiments on benchmarks such as Video Hallucination, Video QA, and Captioning performance tasks demonstrate that VistaDPO significantly improves the performance of existing LVMs, effectively mitigating video-language misalignment and hallucination. The code and data are available at https://github.com/HaroldChen19/VistaDPO.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Video Models (LVMs) built upon Large Language Models (LLMs) have shownpromise in video understanding but often suffer from misalignment with humanintuition and video hallucination issues. To address these challenges, weintroduce VistaDPO, a novel framework for Video Hierarchical Spatial-TemporalDirect Preference Optimization. VistaDPO enhances text-video preferencealignment across three hierarchical levels: i) Instance Level, aligning overallvideo content with responses; ii) Temporal Level, aligning video temporalsemantics with event descriptions; and iii) Perceptive Level, aligning spatialobjects with language tokens. Given the lack of datasets for fine-grainedvideo-language preference alignment, we construct VistaDPO-7k, a dataset of7.2K QA pairs annotated with chosen and rejected responses, along withspatial-temporal grounding information such as timestamps, keyframes, andbounding boxes. Extensive experiments on benchmarks such as VideoHallucination, Video QA, and Captioning performance tasks demonstrate thatVistaDPO significantly improves the performance of existing LVMs, effectivelymitigating video-language misalignment and hallucination. The code and data areavailable at https://github.com/HaroldChen19/VistaDPO.</description>
      <author>example@mail.com (Haojian Huang, Haodong Chen, Shengqiong Wu, Meng Luo, Jinlan Fu, Xinya Du, Hanwang Zhang, Hao Fei)</author>
      <guid isPermaLink="false">2504.13122v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing the Geometric Problem-Solving Ability of Multimodal LLMs via Symbolic-Neural Integration</title>
      <link>http://arxiv.org/abs/2504.12773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GeoGen的几何问题求解方法，用于自动生成几何图的逐步推理路径，并通过GeoLogic模型增强MLLM的逻辑推理能力，以解决几何问题求解中的挑战。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型（MLLMs）在多模态数学推理方面取得了显著进展，但在几何问题求解（GPS）中应用存在挑战，如缺乏精确的逐步解决方案数据和推理过程中的幻觉问题。&lt;h4&gt;目的&lt;/h4&gt;提出GeoGen和GeoLogic模型，旨在解决几何问题求解中的挑战，提高MLLMs的推理能力和准确性。&lt;h4&gt;方法&lt;/h4&gt;GeoGen通过利用精确的符号推理生成大规模、高质量的问答对；GeoLogic则通过使用GeoGen生成的合成数据训练，作为自然语言和符号系统之间的桥梁，帮助验证MLLMs的输出。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GeoGen和GeoLogic模型能够显著提高MLLMs在几何推理任务上的性能，并通过结合LLMs和符号系统的优势，实现更可靠和可解释的GPS方法。&lt;h4&gt;结论&lt;/h4&gt;GeoGen和GeoLogic模型为几何问题求解提供了一种可靠和可解释的方法，有助于提高MLLMs的推理准确性和减少幻觉。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in Multimodal Large Language Models (MLLMs) have achieved remarkable progress in general domains and demonstrated promise in multimodal mathematical reasoning. However, applying MLLMs to geometry problem solving (GPS) remains challenging due to lack of accurate step-by-step solution data and severe hallucinations during reasoning. In this paper, we propose GeoGen, a pipeline that can automatically generates step-wise reasoning paths for geometry diagrams. By leveraging the precise symbolic reasoning, GeoGen produces large-scale, high-quality question-answer pairs. To further enhance the logical reasoning ability of MLLMs, we train GeoLogic, a Large Language Model (LLM) using synthetic data generated by GeoGen. Serving as a bridge between natural language and symbolic systems, GeoLogic enables symbolic tools to help verifying MLLM outputs, making the reasoning process more rigorous and alleviating hallucinations. Experimental results show that our approach consistently improves the performance of MLLMs, achieving remarkable results on benchmarks for geometric reasoning tasks. This improvement stems from our integration of the strengths of LLMs and symbolic systems, which enables a more reliable and interpretable approach for the GPS task. Codes are available at https://github.com/ycpNotFound/GeoGen.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Multimodal Large Language Models (MLLMs) have achievedremarkable progress in general domains and demonstrated promise in multimodalmathematical reasoning. However, applying MLLMs to geometry problem solving(GPS) remains challenging due to lack of accurate step-by-step solution dataand severe hallucinations during reasoning. In this paper, we propose GeoGen, apipeline that can automatically generates step-wise reasoning paths forgeometry diagrams. By leveraging the precise symbolic reasoning,\textbf{GeoGen} produces large-scale, high-quality question-answer pairs. Tofurther enhance the logical reasoning ability of MLLMs, we train\textbf{GeoLogic}, a Large Language Model (LLM) using synthetic data generatedby GeoGen. Serving as a bridge between natural language and symbolic systems,GeoLogic enables symbolic tools to help verifying MLLM outputs, making thereasoning process more rigorous and alleviating hallucinations. Experimentalresults show that our approach consistently improves the performance of MLLMs,achieving remarkable results on benchmarks for geometric reasoning tasks. Thisimprovement stems from our integration of the strengths of LLMs and symbolicsystems, which enables a more reliable and interpretable approach for the GPStask. Codes are available at https://github.com/ycpNotFound/GeoGen.</description>
      <author>example@mail.com (Yicheng Pan, Zhenrong Zhang, Pengfei Hu, Jiefeng Ma, Jun Du, Jianshu Zhang, Quan Liu, Jianqing Gao, Feng Ma)</author>
      <guid isPermaLink="false">2504.12773v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty Quantification in Graph Neural Networks with Shallow Ensembles</title>
      <link>http://arxiv.org/abs/2504.12627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了机器学习势（MLPs）和图神经网络（GNNs）在材料发现中的应用，通过不确定性量化技术，特别是直接传播浅层集成（DPOSE），提高了GNN在材料建模中的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;机器学习势（MLPs）和图神经网络（GNNs）在材料科学中扮演重要角色，但GNNs在处理未知领域数据时容易产生不可靠的预测。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过不确定性量化技术，特别是DPOSE，提高GNN在材料建模中的预测准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;将DPOSE集成到SchNet模型中，并在多个密度泛函理论（DFT）数据集上，如QM9、OC20和Gold Molecular Dynamics，评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;DPOSE能够有效地区分领域内和领域外样本，对于未观察到的分子和材料类别表现出更高的不确定性。&lt;h4&gt;结论&lt;/h4&gt;本文强调了轻量级不确定性量化方法在提高基于GNN的材料建模鲁棒性中的潜力，并为未来与主动学习策略的结合奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;This abstract summarizes a study on the application of machine-learned potentials (MLPs) and graph neural networks (GNNs) in materials discovery. By exploring uncertainty quantification techniques, particularly Direct Propagation of Shallow Ensembles (DPOSE), the robustness of GNN-based material modeling is improved. The study integrates DPOSE into the SchNet model and evaluates its performance on various Density Functional Theory (DFT) datasets, such as QM9, OC20, and Gold Molecular Dynamics. The main findings demonstrate that DPOSE effectively distinguishes between in-domain and out-of-domain samples, showing higher uncertainty for unobserved molecule and material classes. This work highlights the potential of lightweight uncertainty quantification methods in enhancing the robustness of GNN-based materials modeling and lays the foundation for future integration with active learning strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learned potentials (MLPs) have revolutionized materials discovery byproviding accurate and efficient predictions of molecular and materialproperties. Graph Neural Networks (GNNs) have emerged as a state-of-the-artapproach due to their ability to capture complex atomic interactions. However,GNNs often produce unreliable predictions when encountering out-of-domain dataand it is difficult to identify when that happens. To address this challenge,we explore Uncertainty Quantification (UQ) techniques, focusing on DirectPropagation of Shallow Ensembles (DPOSE) as a computationally efficientalternative to deep ensembles. By integrating DPOSE into the SchNet model, weassess its ability to provide reliable uncertainty estimates across diverseDensity Functional Theory datasets, including QM9, OC20, and Gold MolecularDynamics. Our findings often demonstrate that DPOSE successfully distinguishesbetween in-domain and out-of-domain samples, exhibiting higher uncertainty forunobserved molecule and material classes. This work highlights the potential oflightweight UQ methods in improving the robustness of GNN-based materialsmodeling and lays the foundation for future integration with active learningstrategies.</description>
      <author>example@mail.com (Tirtha Vinchurkar, Kareem Abdelmaqsoud, John R. Kitchin)</author>
      <guid isPermaLink="false">2504.12627v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>SmartFreeEdit: Mask-Free Spatial-Aware Image Editing with Complex Instruction Understanding</title>
      <link>http://arxiv.org/abs/2504.12704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SmartFreeEdit是一个集成多模态大型语言模型和超图增强修复架构的端到端框架，通过自然语言指令实现精确的无掩码图像编辑。&lt;h4&gt;背景&lt;/h4&gt;图像编辑在空间推理、精确区域分割和保持语义一致性方面仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;克服上述挑战，实现精确、无掩码的图像编辑。&lt;h4&gt;方法&lt;/h4&gt;SmartFreeEdit的关键创新包括：(1)引入区域感知标记和掩码嵌入范式，增强对复杂场景的空间理解；(2)设计推理分割流程，优化基于自然语言指令的编辑掩码生成；(3)超图增强的修复模块，确保在复杂编辑中保持结构完整性和语义连贯性。&lt;h4&gt;主要发现&lt;/h4&gt;在Reason-Edit基准测试中，SmartFreeEdit在多个评估指标上超越了现有最先进的方法，包括分割精度、指令遵循和视觉质量保持，同时解决了局部信息关注的问题，并提高了编辑图像的全局一致性。&lt;h4&gt;结论&lt;/h4&gt;SmartFreeEdit是一个有效的图像编辑框架，可在https://github.com/smileformylove/SmartFreeEdit上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in image editing have utilized large-scale multimodalmodels to enable intuitive, natural instruction-driven interactions. However,conventional methods still face significant challenges, particularly in spatialreasoning, precise region segmentation, and maintaining semantic consistency,especially in complex scenes. To overcome these challenges, we introduceSmartFreeEdit, a novel end-to-end framework that integrates a multimodal largelanguage model (MLLM) with a hypergraph-enhanced inpainting architecture,enabling precise, mask-free image editing guided exclusively by naturallanguage instructions. The key innovations of SmartFreeEdit include:(1)theintroduction of region aware tokens and a mask embedding paradigm that enhancethe spatial understanding of complex scenes;(2) a reasoning segmentationpipeline designed to optimize the generation of editing masks based on naturallanguage instructions;and (3) a hypergraph-augmented inpainting module thatensures the preservation of both structural integrity and semantic coherenceduring complex edits, overcoming the limitations of local-based imagegeneration. Extensive experiments on the Reason-Edit benchmark demonstrate thatSmartFreeEdit surpasses current state-of-the-art methods across multipleevaluation metrics, including segmentation accuracy, instruction adherence, andvisual quality preservation, while addressing the issue of local informationfocus and improving global consistency in the edited image. Our project will beavailable at https://github.com/smileformylove/SmartFreeEdit.</description>
      <author>example@mail.com (Qianqian Sun, Jixiang Luo, Dell Zhang, Xuelong Li)</author>
      <guid isPermaLink="false">2504.12704v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins</title>
      <link>http://arxiv.org/abs/2504.13059v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 Highlight. 22 pages. Project page:  https://robotwin-benchmark.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;RoboTwin是一个生成式数字孪生框架，旨在解决机器人领域双臂协调和复杂物体操作能力发展的限制，通过生成多样化的专家数据集和提供与真实世界对齐的评估平台来提升双臂机器人任务的表现。&lt;h4&gt;背景&lt;/h4&gt;在机器人领域，双臂协调和复杂物体操作是开发高级自主系统的重要能力。然而，高质量演示数据的稀缺和真实世界对齐的评估基准的缺乏严重限制了这种发展。&lt;h4&gt;目的&lt;/h4&gt;提出RoboTwin框架，以解决上述问题，促进双臂机器人任务的发展。&lt;h4&gt;方法&lt;/h4&gt;RoboTwin利用3D生成基础模型和大型语言模型来创建从单张2D图像生成的多样化物体数字孪生，生成逼真的交互式场景。同时，引入一个空间关系感知的代码生成框架，结合对象注释和大型语言模型来分解任务、确定空间约束并生成更精确的机器人运动代码。&lt;h4&gt;主要发现&lt;/h4&gt;RoboTwin提供了包含模拟和真实世界数据的全面基准，使标准化评估和模拟训练与真实世界性能之间的更好对齐成为可能。使用开源COBOT Magic Robot平台验证了该方法，在RoboTwin生成的数据上预训练并在有限的现实世界样本上进行微调的策略，与仅使用真实世界数据进行训练的模型相比，在单臂任务的成功率提高了超过70%，在双臂任务中提高了超过40%。&lt;h4&gt;结论&lt;/h4&gt;RoboTwin框架为双臂机器人操作系统提供了显著改进的潜力，通过提高成功率和更有效的训练过程，有助于推动机器人技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the rapidly advancing field of robotics, dual-arm coordination and complexobject manipulation are essential capabilities for developing advancedautonomous systems. However, the scarcity of diverse, high-qualitydemonstration data and real-world-aligned evaluation benchmarks severely limitssuch development. To address this, we introduce RoboTwin, a generative digitaltwin framework that uses 3D generative foundation models and large languagemodels to produce diverse expert datasets and provide a real-world-alignedevaluation platform for dual-arm robotic tasks. Specifically, RoboTwin createsvaried digital twins of objects from single 2D images, generating realistic andinteractive scenarios. It also introduces a spatial relation-aware codegeneration framework that combines object annotations with large languagemodels to break down tasks, determine spatial constraints, and generate preciserobotic movement code. Our framework offers a comprehensive benchmark with bothsimulated and real-world data, enabling standardized evaluation and betteralignment between simulated training and real-world performance. We validatedour approach using the open-source COBOT Magic Robot platform. Policiespre-trained on RoboTwin-generated data and fine-tuned with limited real-worldsamples demonstrate significant potential for enhancing dual-arm roboticmanipulation systems by improving success rates by over 70% for single-armtasks and over 40% for dual-arm tasks compared to models trained solely onreal-world data.</description>
      <author>example@mail.com (Yao Mu, Tianxing Chen, Zanxin Chen, Shijia Peng, Zhiqian Lan, Zeyu Gao, Zhixuan Liang, Qiaojun Yu, Yude Zou, Mingkun Xu, Lunkai Lin, Zhiqiang Xie, Mingyu Ding, Ping Luo)</author>
      <guid isPermaLink="false">2504.13059v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Geographical Context Matters: Bridging Fine and Coarse Spatial Information to Enhance Continental Land Cover Mapping</title>
      <link>http://arxiv.org/abs/2504.12368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为BRIDGE-LC的深度学习框架，用于土地覆盖分类，该框架通过整合多尺度地理空间信息来提高土地覆盖地图的准确性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;土地覆盖和土地覆盖图在可持续土地和资源管理中至关重要，而现有的机器学习和深度学习算法在分析地球观测数据时往往忽略了关键的地理空间元数据信息。&lt;h4&gt;目的&lt;/h4&gt;提出BRIDGE-LC框架，以解决现有算法忽略地理空间元数据信息的问题，并提高土地覆盖分类的准确性和可扩展性。&lt;h4&gt;方法&lt;/h4&gt;BRIDGE-LC框架通过同时利用细粒度（经纬度）和粗粒度（生物地理区域）的空间信息，在训练期间学习两种信息，但在推理时只需使用细粒度信息，从而分离特定区域和区域无关的土地覆盖特征，同时保持计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用开放获取的现场数据集和几种竞争性的分类方法，评估了该框架的质量。结果表明，整合地理空间信息提高了土地覆盖地图的性能，特别是通过联合利用细粒度和粗粒度空间信息获得的收益最大。&lt;h4&gt;结论&lt;/h4&gt;整合地理空间信息对于提高土地覆盖地图的性能至关重要，并且该框架能够有效地处理不同尺度的地理空间信息，从而提高分类的准确性和可扩展性。&lt;h4&gt;翻译&lt;/h4&gt;Land use and land cover mapping from Earth Observation (EO) data is acritical tool for sustainable land and resource management. While advancedmachine learning and deep learning algorithms excel at analyzing EO imagerydata, they often overlook crucial geospatial metadata information that couldenhance scalability and accuracy across regional, continental, and globalscales. To address this limitation, we propose BRIDGE-LC (Bi-levelRepresentation Integration for Disentangled GEospatial Land Cover), a noveldeep learning framework that integrates multi-scale geospatial information intothe land cover classification process. By simultaneously leveragingfine-grained (latitude/longitude) and coarse-grained (biogeographical region)spatial information, our lightweight multi-layer perceptron architecture learnsfrom both during training but only requires fine-grained information forinference, allowing it to disentangle region-specific from region-agnostic landcover features while maintaining computational efficiency. To assess thequality of our framework, we use an open-access in-situ dataset and adoptseveral competing classification approaches commonly considered for large-scaleland cover mapping. We evaluated all approaches through two scenarios: anextrapolation scenario in which training data encompasses samples from allbiogeographical regions, and a leave-one-region-out scenario where one regionis excluded from training. We also explore the spatial representation learnedby our model, highlighting a connection between its internal manifold and thegeographical information used during training. Our results demonstrate thatintegrating geospatial information improves land cover mapping performance,with the most substantial gains achieved by jointly leveraging both fine- andcoarse-grained spatial information.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Land use and land cover mapping from Earth Observation (EO) data is acritical tool for sustainable land and resource management. While advancedmachine learning and deep learning algorithms excel at analyzing EO imagerydata, they often overlook crucial geospatial metadata information that couldenhance scalability and accuracy across regional, continental, and globalscales. To address this limitation, we propose BRIDGE-LC (Bi-levelRepresentation Integration for Disentangled GEospatial Land Cover), a noveldeep learning framework that integrates multi-scale geospatial information intothe land cover classification process. By simultaneously leveragingfine-grained (latitude/longitude) and coarse-grained (biogeographical region)spatial information, our lightweight multi-layer perceptron architecture learnsfrom both during training but only requires fine-grained information forinference, allowing it to disentangle region-specific from region-agnostic landcover features while maintaining computational efficiency. To assess thequality of our framework, we use an open-access in-situ dataset and adoptseveral competing classification approaches commonly considered for large-scaleland cover mapping. We evaluated all approaches through two scenarios: anextrapolation scenario in which training data encompasses samples from allbiogeographical regions, and a leave-one-region-out scenario where one regionis excluded from training. We also explore the spatial representation learnedby our model, highlighting a connection between its internal manifold and thegeographical information used during training. Our results demonstrate thatintegrating geospatial information improves land cover mapping performance,with the most substantial gains achieved by jointly leveraging both fine- andcoarse-grained spatial information.</description>
      <author>example@mail.com (Babak Ghassemi, Cassio Fraga-Dantas, Raffaele Gaetano, Dino Ienco, Omid Ghorbanzadeh, Emma Izquierdo-Verdiguier, Francesco Vuolo)</author>
      <guid isPermaLink="false">2504.12368v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal single-cell foundation models via dynamic token adaptation</title>
      <link>http://arxiv.org/abs/2504.13049v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了在基因组学中应用深度学习的最新进展，包括DNA语言和单细胞基础模型，并提出了一种动态标记适应方法，以预测不同遗传背景下单细胞水平的基因调控。&lt;h4&gt;背景&lt;/h4&gt;目前深度学习在基因组学中的应用包括DNA语言和单细胞基础模型，但这些模型仅接受一种数据类型作为输入。&lt;h4&gt;目的&lt;/h4&gt;提出一种动态标记适应方法，将不同模型结合以预测不同遗传背景下单细胞水平的基因调控。&lt;h4&gt;方法&lt;/h4&gt;通过训练一个从DNA序列嵌入到单细胞基础模型标记嵌入空间的适配器，对转录因子GATA4的转录起始位点进行模拟突变，评估DNA序列变化对模型学习到的基因调控网络的影响。&lt;h4&gt;主要发现&lt;/h4&gt;动态标记适应方法能够结合不同模型预测基因调控，并通过模拟突变实验观察到模型预测的靶基因表达变化。&lt;h4&gt;结论&lt;/h4&gt;该方法具有通用性，并通过实例证明了其在预测基因调控方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in applying deep learning in genomics include DNA-language and single-cell foundation models. However, these models take only one datatype as input. We introduce dynamic token adaptation and demonstrate how it combines these models to predict gene regulation at the single-cell level in different genetic contexts. Although the method is generalisable, we focus on an illustrative example by training an adapter from DNA-sequence embeddings to a single-cell foundation model's token embedding space. As a qualitative evaluation, we assess the impact of DNA sequence changes on the model's learned gene regulatory networks by mutating the transcriptional start site of the transcription factor GATA4 in silico, observing predicted expression changes in its target genes in fetal cardiomyocytes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in applying deep learning in genomics include DNA-languageand single-cell foundation models. However, these models take only one datatype as input. We introduce dynamic token adaptation and demonstrate how itcombines these models to predict gene regulation at the single-cell level indifferent genetic contexts. Although the method is generalisable, we focus onan illustrative example by training an adapter from DNA-sequence embeddings toa single-cell foundation model's token embedding space. As a qualitativeevaluation, we assess the impact of DNA sequence changes on the model's learnedgene regulatory networks by mutating the transcriptional start site of thetranscription factor GATA4 in silico, observing predicted expression changes inits target genes in fetal cardiomyocytes.</description>
      <author>example@mail.com (Wenmin Zhao, Ana Solaguren-Beascoa, Grant Neilson, Louwai Muhammed, Liisi Laaniste, Sera Aylin Cakiroglu)</author>
      <guid isPermaLink="false">2504.13049v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Quantum Computing Supported Adversarial Attack-Resilient Autonomous Vehicle Perception Module for Traffic Sign Classification</title>
      <link>http://arxiv.org/abs/2504.12644v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究创建了混合经典-量子深度学习模型（HCQ-DL），并与经典深度学习模型（C-DL）进行了比较，以展示其在对抗攻击下的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型在自动驾驶汽车的感知模块中至关重要，而对抗攻击可能导致模型预测错误，如误分类交通标志。&lt;h4&gt;目的&lt;/h4&gt;研究HCQ-DL模型在对抗攻击下的鲁棒性，以提升自动驾驶汽车感知模块的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用迁移学习模型AlexNet和VGG-16作为特征提取器，测试了超过1000个量子电路，包括针对投影梯度下降（PGD）、快速梯度符号攻击（FGSA）和梯度攻击（GA）的测试，并在对抗攻击和无攻击场景下评估了所有模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;HCQ-DL模型在无攻击场景下保持准确率高于95%，在GA和FGSA攻击下保持准确率高于91%，而在PGD攻击中，基于AlexNet的HCQ-DL模型准确率保持在85%，而C-DL模型准确率低于21%。&lt;h4&gt;结论&lt;/h4&gt;与经典模型相比，HCQ-DL模型在对抗攻击设置下对交通标志分类的准确性有所提高。&lt;h4&gt;翻译&lt;/h4&gt;In this study, we created and compared hybrid classical-quantum deep learning (HCQ-DL) models with classical deep learning (C-DL) models to demonstrate robustness against adversarial attacks for perception modules. Before feeding them into the quantum system, we used transfer learning models, alexnet and vgg-16, as feature extractors. We tested over 1000 quantum circuits in our HCQ-DL models for projected gradient descent (PGD), fast gradient sign attack (FGSA), and gradient attack (GA), which are three well-known untargeted adversarial approaches. We evaluated the performance of all models during adversarial attacks and no-attack scenarios. Our HCQ-DL models maintain accuracy above 95% during a no-attack scenario and above 91% for GA and FGSA attacks, which is higher than C-DL models. During the PGD attack, our alexnet-based HCQ-DL model maintained an accuracy of 85% compared to C-DL models that achieved accuracies below 21%. Our results highlight that the HCQ-DL models provide improved accuracy for traffic sign classification under adversarial settings compared to their classical counterparts.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning (DL)-based image classification models are essential forautonomous vehicle (AV) perception modules since incorrect categorization mighthave severe repercussions. Adversarial attacks are widely studied cyberattacksthat can lead DL models to predict inaccurate output, such as incorrectlyclassified traffic signs by the perception module of an autonomous vehicle. Inthis study, we create and compare hybrid classical-quantum deep learning(HCQ-DL) models with classical deep learning (C-DL) models to demonstraterobustness against adversarial attacks for perception modules. Before feedingthem into the quantum system, we used transfer learning models, alexnet andvgg-16, as feature extractors. We tested over 1000 quantum circuits in ourHCQ-DL models for projected gradient descent (PGD), fast gradient sign attack(FGSA), and gradient attack (GA), which are three well-known untargetedadversarial approaches. We evaluated the performance of all models duringadversarial attacks and no-attack scenarios. Our HCQ-DL models maintainaccuracy above 95\% during a no-attack scenario and above 91\% for GA and FGSAattacks, which is higher than C-DL models. During the PGD attack, ouralexnet-based HCQ-DL model maintained an accuracy of 85\% compared to C-DLmodels that achieved accuracies below 21\%. Our results highlight that theHCQ-DL models provide improved accuracy for traffic sign classification underadversarial settings compared to their classical counterparts.</description>
      <author>example@mail.com (Reek Majumder, Mashrur Chowdhury, Sakib Mahmud Khan, Zadid Khan, Fahim Ahmad, Frank Ngeni, Gurcan Comert, Judith Mwakalonge, Dimitra Michalaka)</author>
      <guid isPermaLink="false">2504.12644v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>EventVAD: Training-Free Event-Aware Video Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.13092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EventVAD的事件感知视频异常检测框架，旨在提高视频异常检测的准确性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;传统的视频异常检测方法需要大量的训练数据，且难以泛化到未见过的异常情况。无监督方法虽然利用了大型语言模型（LLMs）的世界知识，但在定位精细的视觉转换和多样化事件方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出EventVAD框架，结合定制动态图架构和多模态LLMs，通过时间-事件推理来检测视频中的异常。&lt;h4&gt;方法&lt;/h4&gt;EventVAD首先使用动态时空图建模和时间衰减约束来捕捉事件感知的视频特征，然后通过自适应噪声滤波和信号比阈值检测事件边界。统计边界检测模块简化了处理长视频的复杂度，并通过事件一致性提高了MLLM的时间推理能力。最后，采用分层提示策略引导MLLM在做出最终决策前进行推理。&lt;h4&gt;主要发现&lt;/h4&gt;在UCF-Crime和XD-Violence数据集上进行的广泛实验表明，使用7B MLLM的EventVAD在无监督设置中达到了最先进（SOTA）的性能，超过了使用7B或更大MLLM的强基线。&lt;h4&gt;结论&lt;/h4&gt;EventVAD框架在无监督视频异常检测方面具有显著优势，能够有效提高检测准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Video Anomaly Detection (VAD) focuses on identifying anomalies within videos. Supervised methods require an amount of in-domain training data and often struggle to generalize to unseen anomalies. In contrast, training-free methods leverage the intrinsic world knowledge of large language models (LLMs) to detect anomalies but face challenges in localizing fine-grained visual transitions and diverse events. Therefore, we propose EventVAD, an event-aware video anomaly detection framework that combines tailored dynamic graph architectures and multimodal LLMs through temporal-event reasoning. Specifically, EventVAD first employs dynamic spatiotemporal graph modeling with time-decay constraints to capture event-aware video features. Then, it performs adaptive noise filtering and uses signal ratio thresholding to detect event boundaries via unsupervised statistical features. The statistical boundary detection module reduces the complexity of processing long videos for MLLMs and improves their temporal reasoning through event consistency. Finally, it utilizes a hierarchical prompting strategy to guide MLLMs in performing reasoning before determining final decisions. We conducted extensive experiments on the UCF-Crime and XD-Violence datasets. The results demonstrate that EventVAD with a 7B MLLM achieves state-of-the-art (SOTA) in training-free settings, outperforming strong baselines that use 7B or larger MLLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Anomaly Detection~(VAD) focuses on identifying anomalies within videos.Supervised methods require an amount of in-domain training data and oftenstruggle to generalize to unseen anomalies. In contrast, training-free methodsleverage the intrinsic world knowledge of large language models (LLMs) todetect anomalies but face challenges in localizing fine-grained visualtransitions and diverse events. Therefore, we propose EventVAD, an event-awarevideo anomaly detection framework that combines tailored dynamic grapharchitectures and multimodal LLMs through temporal-event reasoning.Specifically, EventVAD first employs dynamic spatiotemporal graph modeling withtime-decay constraints to capture event-aware video features. Then, it performsadaptive noise filtering and uses signal ratio thresholding to detect eventboundaries via unsupervised statistical features. The statistical boundarydetection module reduces the complexity of processing long videos for MLLMs andimproves their temporal reasoning through event consistency. Finally, itutilizes a hierarchical prompting strategy to guide MLLMs in performingreasoning before determining final decisions. We conducted extensiveexperiments on the UCF-Crime and XD-Violence datasets. The results demonstratethat EventVAD with a 7B MLLM achieves state-of-the-art (SOTA) in training-freesettings, outperforming strong baselines that use 7B or larger MLLMs.</description>
      <author>example@mail.com (Yihua Shao, Haojin He, Sijie Li, Siyu Chen, Xinwei Long, Fanhu Zeng, Yuxuan Fan, Muyang Zhang, Ziyang Yan, Ao Ma, Xiaochen Wang, Hao Tang, Yan Wang, Shuyan Li)</author>
      <guid isPermaLink="false">2504.13092v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Based Robust LiDAR Place Recognition</title>
      <link>http://arxiv.org/abs/2504.12412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted for ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在建筑工地上进行自主测绘和检查任务时，移动机器人对准确姿态估计的需求。由于存在重复特征如平整的粉刷墙壁以及由于楼层布局相似而产生的感知混淆问题，建筑工地的定位是一个特别具有挑战性的问题。&lt;h4&gt;背景&lt;/h4&gt;建筑工地的定位由于重复特征和感知混淆而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过仅使用LiDAR数据来实现对建筑精确扫描网格的机器人全局定位。&lt;h4&gt;方法&lt;/h4&gt;采用了一种基于合成LiDAR点云的方法，这些点云是通过模拟真实场景中的LiDAR在大规模网格中生成的。使用PointNet++作为骨干网络训练了一个扩散模型，从而能够从单个LiDAR点云中建模多个位置候选。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够成功预测LiDAR在封闭和复杂环境中的全局位置，即使在感知混淆的负面效应下也能做到。学习到的潜在全局位置分布可以提供多模态位置分布。&lt;h4&gt;结论&lt;/h4&gt;在五个真实世界数据集上评估了该方法，平均识别精度为77% +/-2米，在平均误差方面优于基线模型2倍。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the need for accurate pose estimation for mobile robots on construction sites to perform autonomous surveying and inspection missions. Localization in construction sites is particularly challenging due to the presence of repetitive features such as flat plastered walls and perceptual aliasing due to apartments with similar layouts inter and intra floors. In this paper, we focus on the global re-positioning of a robot with respect to an accurate scanned mesh of the building solely using LiDAR data. In our approach, a neural network is trained on synthetic LiDAR point clouds generated by simulating a LiDAR in an accurate real-life large-scale mesh. We train a diffusion model with a PointNet++ backbone, which allows us to model multiple position candidates from a single LiDAR point cloud. The resulting model can successfully predict the global position of LiDAR in confined and complex sites despite the adverse effects of perceptual aliasing. The learned distribution of potential global positions can provide multi-modal position distribution. We evaluate our approach across five real-world datasets and show the place recognition accuracy of 77% +/-2m on average while outperforming baselines at a factor of 2 in mean error.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile robots on construction sites require accurate pose estimation toperform autonomous surveying and inspection missions. Localization inconstruction sites is a particularly challenging problem due to the presence ofrepetitive features such as flat plastered walls and perceptual aliasing due toapartments with similar layouts inter and intra floors. In this paper, we focuson the global re-positioning of a robot with respect to an accurate scannedmesh of the building solely using LiDAR data. In our approach, a neural networkis trained on synthetic LiDAR point clouds generated by simulating a LiDAR inan accurate real-life large-scale mesh. We train a diffusion model with aPointNet++ backbone, which allows us to model multiple position candidates froma single LiDAR point cloud. The resulting model can successfully predict theglobal position of LiDAR in confined and complex sites despite the adverseeffects of perceptual aliasing. The learned distribution of potential globalpositions can provide multi-modal position distribution. We evaluate ourapproach across five real-world datasets and show the place recognitionaccuracy of 77% +/-2m on average while outperforming baselines at a factor of 2in mean error.</description>
      <author>example@mail.com (Benjamin Krummenacher, Jonas Frey, Turcan Tuna, Olga Vysotska, Marco Hutter)</author>
      <guid isPermaLink="false">2504.12412v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning</title>
      <link>http://arxiv.org/abs/2504.12597v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GeoSense，一个用于评估多模态大型语言模型（MLLMs）几何推理能力的双语基准。&lt;h4&gt;背景&lt;/h4&gt;几何问题解决（GPS）是一项挑战性任务，需要视觉理解和符号推理，可以有效地衡量MLLMs的推理能力。人类在此任务中表现出强大的推理能力，通过准确识别和适应视觉环境中的几何原理。&lt;h4&gt;目的&lt;/h4&gt;现有的基准未能联合评估MLLMs中类似人类几何推理机制的这两个维度，这是评估其解决GPS能力的一个关键差距。&lt;h4&gt;方法&lt;/h4&gt;GeoSense引入了一个五级层次结构的几何原理框架，涵盖了平面和立体几何，一个包含1789个问题的复杂注释数据集，以及一种创新的评估策略。&lt;h4&gt;主要发现&lt;/h4&gt;在GeoSense上进行的广泛实验表明，Gemini-2.0-pro-flash表现最佳，总分为65.3。深入分析显示，几何原理的识别和应用仍然是领先MLLMs的瓶颈，共同阻碍了它们的推理能力。&lt;h4&gt;结论&lt;/h4&gt;这些发现强调了GeoSense在指导未来MLLMs几何推理能力进步方面的潜力，为人工智能中更强大和更类似人类的推理铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Geometry problem-solving (GPS), a challenging task requiring both visual comprehension and symbolic reasoning, effectively measures the reasoning capabilities of multimodal large language models (MLLMs). Humans exhibit strong reasoning ability in this task through accurate identification and adaptive application of geometric principles within visual contexts. However, existing benchmarks fail to jointly assess both dimensions of the human-like geometric reasoning mechanism in MLLMs, remaining a critical gap in assessing their ability to tackle GPS. To this end, we introduce GeoSense, the first comprehensive bilingual benchmark designed to systematically evaluate the geometric reasoning abilities of MLLMs through the lens of geometric principles. GeoSense features a five-level hierarchical framework of geometric principles spanning plane and solid geometry, an intricately annotated dataset of 1,789 problems, and an innovative evaluation strategy. Through extensive experiments on GeoSense with various open-source and closed-source MLLMs, we observe that Gemini-2.0-pro-flash performs best, achieving an overall score of 65.3. Our in-depth analysis reveals that the identification and application of geometric principles remain a bottleneck for leading MLLMs, jointly hindering their reasoning abilities. These findings underscore GeoSense's potential to guide future advancements in MLLMs' geometric reasoning capabilities, paving the way for more robust and human-like reasoning in artificial intelligence.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometry problem-solving (GPS), a challenging task requiring both visualcomprehension and symbolic reasoning, effectively measures the reasoningcapabilities of multimodal large language models (MLLMs). Humans exhibit strongreasoning ability in this task through accurate identification and adaptiveapplication of geometric principles within visual contexts. However, existingbenchmarks fail to jointly assess both dimensions of the human-like geometricreasoning mechanism in MLLMs, remaining a critical gap in assessing theirability to tackle GPS. To this end, we introduce GeoSense, the firstcomprehensive bilingual benchmark designed to systematically evaluate thegeometric reasoning abilities of MLLMs through the lens of geometricprinciples. GeoSense features a five-level hierarchical framework of geometricprinciples spanning plane and solid geometry, an intricately annotated datasetof 1,789 problems, and an innovative evaluation strategy. Through extensiveexperiments on GeoSense with various open-source and closed-source MLLMs, weobserve that Gemini-2.0-pro-flash performs best, achieving an overall score of$65.3$. Our in-depth analysis reveals that the identification and applicationof geometric principles remain a bottleneck for leading MLLMs, jointlyhindering their reasoning abilities. These findings underscore GeoSense'spotential to guide future advancements in MLLMs' geometric reasoningcapabilities, paving the way for more robust and human-like reasoning inartificial intelligence.</description>
      <author>example@mail.com (Liangyu Xu, Yingxiu Zhao, Jingyun Wang, Yingyao Wang, Bu Pi, Chen Wang, Mingliang Zhang, Jihao Gu, Xiang Li, Xiaoyong Zhu, Jun Song, Bo Zheng)</author>
      <guid isPermaLink="false">2504.12597v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular Representations for Whole-Heart Assessment and Beyond</title>
      <link>http://arxiv.org/abs/2504.13037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ViTa，一个用于心脏健康评估的综合模型，它结合了心脏磁共振成像（CMR）数据和患者级别的健康因素，以提供对心脏健康和疾病风险的全面理解。&lt;h4&gt;背景&lt;/h4&gt;心脏磁共振成像是非侵入性心脏评估的金标准，但单独使用CMR无法捕捉到影响心血管健康和疾病风险的患者级别健康因素。&lt;h4&gt;目的&lt;/h4&gt;为了全面理解心脏健康并准确解释个体的疾病风险，需要将CMR和患者级别因素联合起来。&lt;h4&gt;方法&lt;/h4&gt;ViTa利用42,000名英国生物样本库参与者的数据，结合了3D+T cine stacks从短轴和长轴视图，并与详细的表格患者级别因素融合，以实现上下文感知洞察。&lt;h4&gt;主要发现&lt;/h4&gt;ViTa支持广泛的下游任务，包括心脏表型和生理特征预测、分割以及心脏和代谢疾病的分类。&lt;h4&gt;结论&lt;/h4&gt;ViTa通过学习连接丰富成像特征和患者背景的共享潜在表示，超越了传统的任务特定模型，向通用、个体化的心脏健康理解迈进，突出了其在心脏分析中的临床应用和可扩展性的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：心脏磁共振成像是非侵入性心脏评估的金标准，提供了丰富的时空心脏解剖和生理视图。患者级别的健康因素，如人口统计学、代谢和生活方式，已知会显著影响心血管健康和疾病风险，但单独的心脏磁共振成像无法捕捉到这些因素。为了全面理解心脏健康并使个体疾病风险的解释达到最佳，必须在综合框架内联合利用心脏磁共振成像和患者级别因素。最近的多模态方法开始弥合这一差距，但它们通常依赖于有限的时空数据，并专注于孤立的临床任务，从而阻碍了心脏健康评估的全面表示的发展。为了克服这些限制，我们引入了ViTa，这是向基础模型迈进的一步，它提供了心脏的全面表示和个体疾病风险的精确解释。利用42,000名英国生物样本库参与者的数据，ViTa结合了短轴和长轴视图的3D+T cine stacks，实现了对心脏周期的完整捕捉。然后，这些成像数据与详细的表格患者级别因素融合，以实现上下文感知洞察。这种多模态范式支持广泛的下游任务，包括心脏表型和生理特征预测、分割以及在一个单一统一框架内对心脏和代谢疾病的分类。通过学习连接丰富成像特征和患者背景的共享潜在表示，ViTa超越了传统的任务特定模型，向通用、个体化的心脏健康理解迈进，突出了其在心脏分析中的临床应用和可扩展性的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cardiac magnetic resonance imaging is the gold standard for non-invasivecardiac assessment, offering rich spatio-temporal views of the cardiac anatomyand physiology. Patient-level health factors, such as demographics, metabolic,and lifestyle, are known to substantially influence cardiovascular health anddisease risk, yet remain uncaptured by CMR alone. To holistically understandcardiac health and to enable the best possible interpretation of anindividual's disease risk, CMR and patient-level factors must be jointlyexploited within an integrated framework. Recent multi-modal approaches havebegun to bridge this gap, yet they often rely on limited spatio-temporal dataand focus on isolated clinical tasks, thereby hindering the development of acomprehensive representation for cardiac health evaluation. To overcome theselimitations, we introduce ViTa, a step toward foundation models that delivers acomprehensive representation of the heart and a precise interpretation ofindividual disease risk. Leveraging data from 42,000 UK Biobank participants,ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enablinga complete capture of the cardiac cycle. These imaging data are then fused withdetailed tabular patient-level factors, enabling context-aware insights. Thismulti-modal paradigm supports a wide spectrum of downstream tasks, includingcardiac phenotype and physiological feature prediction, segmentation, andclassification of cardiac and metabolic diseases within a single unifiedframework. By learning a shared latent representation that bridges rich imagingfeatures and patient context, ViTa moves beyond traditional, task-specificmodels toward a universal, patient-specific understanding of cardiac health,highlighting its potential to advance clinical utility and scalability incardiac analysis.</description>
      <author>example@mail.com (Yundi Zhang, Paul Hager, Che Liu, Suprosanna Shit, Chen Chen, Daniel Rueckert, Jiazhen Pan)</author>
      <guid isPermaLink="false">2504.13037v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Privacy-Preserving CNN Training with Transfer Learning: Two Hidden Layers</title>
      <link>http://arxiv.org/abs/2504.12623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用全同态加密（FHE）训练四层神经网络的方法，支持单输出和多输出分类任务，并在非交互式环境中实现。&lt;h4&gt;背景&lt;/h4&gt;在加密数据上训练神经网络是一个挑战，因为传统的加密方法不支持直接的模型训练。&lt;h4&gt;目的&lt;/h4&gt;研究如何使用全同态加密在加密数据上训练神经网络，并提高分类任务的性能。&lt;h4&gt;方法&lt;/h4&gt;使用全同态加密训练神经网络，并通过替换Softmax函数为Sigmoid函数，结合二元交叉熵（BCE）损失函数，实现有效的同态分类。同时，改进了数据编码方案Double Volley Revolver，以优化计算和内存效率。&lt;h4&gt;主要发现&lt;/h4&gt;发现使用Sigmoid和BCE损失函数可以有效地进行同态分类，并且BCE损失函数可以自然地扩展到多类设置。此外，指出了先前损失函数（如SLE损失和2019 CVPR Workshop中提出的一种）的局限性，即随着网络深度的增加，梯度消失问题。&lt;h4&gt;结论&lt;/h4&gt;全同态加密可以用于训练神经网络，并在非交互式环境中支持分类任务，同时通过改进数据编码方案，使得基于FHE的神经网络训练更加实际。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种使用全同态加密（FHE）训练四层神经网络的方法，支持单输出和多输出分类任务，并在非交互式环境中实现。我们的工作贡献在于，通过使用Sigmoid函数替换Softmax函数，并结合二元交叉熵（BCE）损失函数，为同态分类提供了一种有效且可扩展的解决方案。此外，我们展示了BCE损失函数，最初是为多输出任务设计的，可以自然地扩展到多类设置，从而使其应用范围更广。我们还强调了先前损失函数（如SLE损失和2019 CVPR Workshop中提出的一种）的局限性，这些损失函数随着网络深度的增加会遭受梯度消失问题。为了解决大规模加密数据带来的挑战，我们进一步引入了之前提出的改进版数据编码方案Double Volley Revolver，实现了计算效率和内存效率之间的更好权衡，使得基于FHE的神经网络训练更加可行。完整的、可运行的C++代码可以在以下链接找到：https://github.com/petitioner/ML.NNtraining&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present the demonstration of training a four-layer neuralnetwork entirely using fully homomorphic encryption (FHE), supporting bothsingle-output and multi-output classification tasks in a non-interactivesetting. A key contribution of our work is identifying that replacing\textit{Softmax} with \textit{Sigmoid}, in conjunction with the BinaryCross-Entropy (BCE) loss function, provides an effective and scalable solutionfor homomorphic classification. Moreover, we show that the BCE loss function,originally designed for multi-output tasks, naturally extends to themulti-class setting, thereby enabling broader applicability. We also highlightthe limitations of prior loss functions such as the SLE loss and the oneproposed in the 2019 CVPR Workshop, both of which suffer from vanishinggradients as network depth increases. To address the challenges posed bylarge-scale encrypted data, we further introduce an improved version of thepreviously proposed data encoding scheme, \textit{Double Volley Revolver},which achieves a better trade-off between computational and memory efficiency,making FHE-based neural network training more practical. The complete, runnableC++ code to implement our work can be found at:\href{https://github.com/petitioner/ML.NNtraining}{$\texttt{https://github.com/petitioner/ML.NNtraining}$}.</description>
      <author>example@mail.com (John Chiang)</author>
      <guid isPermaLink="false">2504.12623v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Prototypes are Balanced Units for Efficient and Effective Partially Relevant Video Retrieval</title>
      <link>http://arxiv.org/abs/2504.13035v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种部分相关视频检索（PRVR）框架，旨在同时提高检索的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;在检索系统中，同时实现搜索准确性和效率是一个挑战，特别是在部分相关视频检索中，引入更多样化的上下文表示可以增强准确性，但也会增加计算和内存成本。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一矛盾，本文提出了一种将视频中的多样化上下文编码为固定数量原型的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法包括：将上下文编码为原型、引入策略增强文本关联和视频理解、实现跨模态和单模态重建任务、使用视频混合技术提供弱指导以进一步对齐原型和文本表示。&lt;h4&gt;主要发现&lt;/h4&gt;在TVR、ActivityNet-Captions和QVHighlights上的广泛评估验证了该方法的有效性，且未牺牲效率。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在提高PRVR的准确性和效率方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;In a retrieval system, simultaneously achieving search accuracy and efficiency is inherently challenging. This challenge is particularly pronounced in partially relevant video retrieval (PRVR), where incorporating more diverse context representations at varying temporal scales for each video enhances accuracy but increases computational and memory costs. To address this dichotomy, we propose a prototypical PRVR framework that encodes diverse contexts within a video into a fixed number of prototypes. We then introduce several strategies to enhance text association and video understanding within the prototypes, along with an orthogonal objective to ensure that the prototypes capture a diverse range of content. To keep the prototypes searchable via text queries while accurately encoding video contexts, we implement cross- and uni-modal reconstruction tasks. The cross-modal reconstruction task aligns the prototypes with textual features within a shared space, while the uni-modal reconstruction task preserves all video contexts during encoding. Additionally, we employ a video mixing technique to provide weak guidance to further align prototypes and associated textual representations. Extensive evaluations on TVR, ActivityNet-Captions, and QVHighlights validate the effectiveness of our approach without sacrificing efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In a retrieval system, simultaneously achieving search accuracy andefficiency is inherently challenging. This challenge is particularly pronouncedin partially relevant video retrieval (PRVR), where incorporating more diversecontext representations at varying temporal scales for each video enhancesaccuracy but increases computational and memory costs. To address thisdichotomy, we propose a prototypical PRVR framework that encodes diversecontexts within a video into a fixed number of prototypes. We then introduceseveral strategies to enhance text association and video understanding withinthe prototypes, along with an orthogonal objective to ensure that theprototypes capture a diverse range of content. To keep the prototypessearchable via text queries while accurately encoding video contexts, weimplement cross- and uni-modal reconstruction tasks. The cross-modalreconstruction task aligns the prototypes with textual features within a sharedspace, while the uni-modal reconstruction task preserves all video contextsduring encoding. Additionally, we employ a video mixing technique to provideweak guidance to further align prototypes and associated textualrepresentations. Extensive evaluations on TVR, ActivityNet-Captions, andQVHighlights validate the effectiveness of our approach without sacrificingefficiency.</description>
      <author>example@mail.com (WonJun Moon, Cheol-Ho Cho, Woojin Jun, Minho Shim, Taeoh Kim, Inwoong Lee, Dongyoon Wee, Jae-Pil Heo)</author>
      <guid isPermaLink="false">2504.13035v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Sparks of Science: Hypothesis Generation Using Structured Paper Data</title>
      <link>http://arxiv.org/abs/2504.12976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures. Comments welcome&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为HypoGen的数据集，用于科学假设生成（SHG），并通过在Bit-Flip-Spark架构上微调语言模型，提高了生成假设的总体质量。&lt;h4&gt;背景&lt;/h4&gt;生成新颖且可行的科学假设是实现通用人工智能的关键。然而，现有的基础模型在生成新颖且可行的科学想法方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来系统地创建、选择和验证科学假设，并提高假设生成的质量。&lt;h4&gt;方法&lt;/h4&gt;引入了HypoGen数据集，包含约5500个结构化的问题-假设对，并采用Bit-Flip-Spark架构。通过将假设生成作为条件语言建模，并在Bit-Flip-Spark和推理过程中使用链式推理组件进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;通过在HypoGen数据集上微调，提高了生成假设的新颖性、可行性和总体质量。&lt;h4&gt;结论&lt;/h4&gt;HypoGen数据集有助于提高科学假设生成的质量，并为未来研究提供了有价值的资源。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成新颖的创造性科学假设是实现通用人工智能的基石。大型语言和推理模型有潜力帮助系统地创建、选择和验证基于科学的信息假设。然而，当前的基础模型往往难以产生既新颖又可行的科学想法。一个原因是缺乏将科学假设生成（SHG）作为自然语言生成（NLG）任务的专用数据集。在本文中，我们引入了HypoGen，这是第一个包含约5500个结构化问题-假设对的数据集，这些对是从顶级计算机科学会议中提取的，并使用Bit-Flip-Spark架构进行结构化，其中Bit是传统假设，Spark是关键洞察或概念飞跃，Flip是产生的反提案。HypoGen独特地集成了反映从Bit到Flip的智力过程的明确链式推理组件。我们表明，将假设生成作为条件语言建模，通过在Bit-Flip-Spark和链式推理（在推理时仅提供Bit）上进行微调，可以改善假设的总体质量。我们的评估采用自动指标和LLM评委排名进行总体质量评估。我们表明，通过在HypoGen数据集上微调，我们提高了生成假设的新颖性、可行性和总体质量。HypoGen数据集在huggingface.co/datasets/UniverseTBD/hypogen-dr1上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating novel and creative scientific hypotheses is a cornerstone inachieving Artificial General Intelligence. Large language and reasoning modelshave the potential to aid in the systematic creation, selection, and validationof scientifically informed hypotheses. However, current foundation models oftenstruggle to produce scientific ideas that are both novel and feasible. Onereason is the lack of a dedicated dataset that frames Scientific HypothesisGeneration (SHG) as a Natural Language Generation (NLG) task. In this paper, weintroduce HypoGen, the first dataset of approximately 5500 structuredproblem-hypothesis pairs extracted from top-tier computer science conferencesstructured with a Bit-Flip-Spark schema, where the Bit is the conventionalassumption, the Spark is the key insight or conceptual leap, and the Flip isthe resulting counterproposal. HypoGen uniquely integrates an explicitChain-of-Reasoning component that reflects the intellectual process from Bit toFlip. We demonstrate that framing hypothesis generation as conditional languagemodelling, with the model fine-tuned on Bit-Flip-Spark and theChain-of-Reasoning (and where, at inference, we only provide the Bit), leads toimprovements in the overall quality of the hypotheses. Our evaluation employsautomated metrics and LLM judge rankings for overall quality assessment. Weshow that by fine-tuning on our HypoGen dataset we improve the novelty,feasibility, and overall quality of the generated hypotheses. The HypoGendataset is publicly available athuggingface.co/datasets/UniverseTBD/hypogen-dr1.</description>
      <author>example@mail.com (Charles O'Neill, Tirthankar Ghosal, Roberta Răileanu, Mike Walmsley, Thang Bui, Kevin Schawinski, Ioana Ciucă)</author>
      <guid isPermaLink="false">2504.12976v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>DC-SAM: In-Context Segment Anything in Images and Videos via Dual Consistency</title>
      <link>http://arxiv.org/abs/2504.12080v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  V1 has been withdrawn due to a template issue, because of the arXiv  policy, we can't delete it. Please refer to the newest version v2&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DC-SAM的方法，用于图像和视频的情境分割，通过prompt-tuning技术改进了Segment Anything Models（SAM）和SAM2。&lt;h4&gt;背景&lt;/h4&gt;情境分割在视觉任务中具有重要意义，而现有的Segment Anything Models在交互式分割方面表现优异，但无法直接应用于情境分割。&lt;h4&gt;目的&lt;/h4&gt;旨在提高情境分割模型的泛化能力，并应用于图像和视频分割任务。&lt;h4&gt;方法&lt;/h4&gt;DC-SAM通过提供高质量视觉提示来增强SAM的prompt encoder特征，融合SAM特征以更好地对齐prompt encoder，并设计了一个循环一致的交叉注意力机制。此外，采用双重分支设计，并设计了一个简单的mask-tube训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;DC-SAM在图像分割任务中取得了良好的性能，并在视频分割领域进行了扩展，通过构建第一个视频分割基准IC-VOS来评估模型在情境分割方面的能力。&lt;h4&gt;结论&lt;/h4&gt;DC-SAM在多个基准数据集上实现了优异的性能，证明其在情境分割领域的有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于提示调整的双一致性SAM（DC-SAM）方法，用于图像和视频的情境分割。该方法通过提供高质量的视觉提示来增强SAM的提示编码器特征，融合SAM特征以更好地对齐提示编码器，并设计了一个循环一致的交叉注意力机制。此外，采用了双重分支设计，并设计了一个简单的mask-tube训练策略。虽然DC-SAM最初是为图像设计的，但通过SAM2的支持，可以无缝地扩展到视频领域。由于视频领域中缺乏情境分割，我们手动构建了第一个基准，名为情境视频对象分割（IC-VOS），以更好地评估模型的情境分割能力。大量实验表明，该方法在COCO-20i上实现了55.5（+1.4）mIoU，在PASCAL-5i上实现了73.0（+1.1）mIoU，在提出的IC-VOS基准上实现了71.52的J&amp;F分数。源代码和基准可在https://github.com/zaplm/DC-SAM上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Given a single labeled example, in-context segmentation aims to segmentcorresponding objects. This setting, known as one-shot segmentation in few-shotlearning, explores the segmentation model's generalization ability and has beenapplied to various vision tasks, including scene understanding and image/videoediting. While recent Segment Anything Models have achieved state-of-the-artresults in interactive segmentation, these approaches are not directlyapplicable to in-context segmentation. In this work, we propose the DualConsistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2for in-context segmentation of both images and videos. Our key insights are toenhance the features of the SAM's prompt encoder in segmentation by providinghigh-quality visual prompts. When generating a mask prior, we fuse the SAMfeatures to better align the prompt encoder. Then, we design a cycle-consistentcross-attention on fused features and initial visual prompts. Next, adual-branch design is provided by using the discriminative positive andnegative prompts in the prompt encoder. Furthermore, we design a simplemask-tube training strategy to adopt our proposed dual consistency method intothe mask tube. Although the proposed DC-SAM is primarily designed for images,it can be seamlessly extended to the video domain with the support of SAM2.Given the absence of in-context segmentation in the video domain, we manuallycurate and construct the first benchmark from existing video segmentationdatasets, named In-Context Video Object Segmentation (IC-VOS), to better assessthe in-context capability of the model. Extensive experiments demonstrate thatour method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU onPASCAL-5i, and a J&amp;F score of 71.52 on the proposed IC-VOS benchmark. Oursource code and benchmark are available at https://github.com/zaplm/DC-SAM.</description>
      <author>example@mail.com (Mengshi Qi, Pengfei Zhu, Xiangtai Li, Xiaoyang Bi, Lu Qi, Huadong Ma, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2504.12080v2</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>ReTool: Reinforcement Learning for Strategic Tool Use in LLMs</title>
      <link>http://arxiv.org/abs/2504.11536v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  fix typos&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ReTool的推理模型，旨在通过工具集成学习来增强长文本推理能力，解决强化学习模型在几何推理、简洁计算和复杂方程求解等需要结构化问题解决场景中的不足。&lt;h4&gt;背景&lt;/h4&gt;尽管使用强化学习训练的推理模型在文本推理方面表现优秀，但在需要结构化问题解决的场景中（如几何推理、简洁计算或复杂方程求解）存在困难，这些场景中计算工具（如代码解释器）显示出独特的优势。&lt;h4&gt;目的&lt;/h4&gt;提出ReTool模型，以解决上述问题，并通过工具集成学习来增强长文本推理。&lt;h4&gt;方法&lt;/h4&gt;ReTool模型包括两个关键特性：（1）在自然语言推理过程中动态交织实时代码执行；（2）一个自动化的强化学习范式，允许多轮实时代码执行的政策部署，并通过结果反馈来指导模型学习何时以及如何调用工具。ReTool采用系统化的训练框架，从合成冷启动数据生成开始，生成代码增强的长文本推理轨迹以微调基础模型。后续的强化学习训练利用任务结果作为奖励，迭代地细化模型的工具使用策略，使模型能够自主发现最优的工具调用模式。&lt;h4&gt;主要发现&lt;/h4&gt;在MATH Olympiad基准AIME上的实验表明，ReTool优于基于文本的强化学习基线。ReTool-32B模型在400个训练步骤后达到67%的准确率，在效率和性能上优于基线（40%的准确率，1080个步骤）。在扩展设置中，ReTool-32B达到72.5%的准确率，超过OpenAI的o1-preview 27.9%。进一步的分析揭示了代码自我校正等涌现行为，表明模型在自主掌握适应性工具使用时达到了“啊哈”时刻。&lt;h4&gt;结论&lt;/h4&gt;ReTool展示了结果驱动工具集成在推进复杂数学推理方面的潜力，并为混合神经符号系统提供了新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While reasoning models (e.g., DeepSeek R1) trained with reinforcementlearning (RL), excel in textual reasoning, they struggle in scenarios requiringstructured problem-solving, such as geometric reasoning, concise computation,or complex equation solving-areas where computational tools like codeinterpreters (CI) demonstrate distinct advantages. To bridge this gap, wepropose ReTool, which enhances long-form reasoning with tool-integratedlearning, including two key features: (1) dynamic interleaving of real-timecode execution within natural language reasoning processes, and (2) anautomated RL paradigm that allows policy rollouts with multi-turn real-timecode execution and teaches the model in learning when and how to invoke toolsbased on outcome feedback. ReTool employs a systematic training framework,beginning with synthetic cold-start data generation to produce code-augmentedlong-form reasoning traces for fine-tuning base models. Subsequent RL trainingleverages task outcomes as rewards to iteratively refine the model's tool usestrategy, enabling autonomous discovery of optimal tool invocation patternswithout human priors. Experiments on the challenging MATH Olympiad benchmarkAIME demonstrate ReTool's superiority: Our 32B model achieves 67% accuracy with400 training steps, outperforming text-based RL baseline (40% accuracy, 1080steps) in efficiency and performance. Remarkably, ReTool-32B attains 72.5%accuracy in extended settings, surpassing OpenAI's o1-preview by 27.9%. Furtheranalysis reveals emergent behaviors such as code self-correction, signaling an''aha moment'' in which the model autonomously masters adaptive tool use. Thesefindings highlight the promise of outcome-driven tool integration for advancingcomplex mathematical reasoning and offer new insights into hybridneuro-symbolic systems.</description>
      <author>example@mail.com (Jiazhan Feng, Shijue Huang, Xingwei Qu, Ge Zhang, Yujia Qin, Baoquan Zhong, Chengquan Jiang, Jinxin Chi, Wanjun Zhong)</author>
      <guid isPermaLink="false">2504.11536v2</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>3D Object Reconstruction with mmWave Radars</title>
      <link>http://arxiv.org/abs/2504.12348v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RFconstruct的框架，该框架利用商用毫米波雷达实现自动驾驶场景下的3D形状重建。&lt;h4&gt;背景&lt;/h4&gt;该框架解决了雷达在低角分辨率、反光和稀疏点云等方面的局限性。&lt;h4&gt;目的&lt;/h4&gt;目的是开发一个能够准确重建物体3D形状的系统，用于自动驾驶场景。&lt;h4&gt;方法&lt;/h4&gt;RFconstruct通过融合两个雷达设备捕获的数据，这些设备能够成像正交平面，然后执行里程计感知的时间融合以生成更密集的3D点云。接着，使用一个定制的编码器-解码器模型来重建物体的3D形状，该模型不需要物体边界框的先验知识。&lt;h4&gt;主要发现&lt;/h4&gt;RFconstruct的性能与配备激光雷达的深度相机提取的3D模型进行了比较，结果显示RFconstruct可以准确生成汽车、自行车和行人的3D形状。&lt;h4&gt;结论&lt;/h4&gt;RFconstruct能够有效地克服雷达的局限性，并在自动驾驶场景中实现高精度的3D形状重建。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为RFconstruct的框架，该框架利用商用毫米波雷达实现自动驾驶场景下的3D形状重建。RFconstruct通过融合两个雷达设备捕获的数据，这些设备能够成像正交平面，然后执行里程计感知的时间融合以生成更密集的3D点云。接着，使用一个定制的编码器-解码器模型来重建物体的3D形状，该模型不需要物体边界框的先验知识。RFconstruct的性能与配备激光雷达的深度相机提取的3D模型进行了比较，结果显示RFconstruct可以准确生成汽车、自行车和行人的3D形状。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents RFconstruct, a framework that enables 3D shapereconstruction using commercial off-the-shelf (COTS) mmWave radars forself-driving scenarios. RFconstruct overcomes radar limitations of low angularresolution, specularity, and sparsity in radar point clouds through a holisticsystem design that addresses hardware, data processing, and machine learningchallenges. The first step is fusing data captured by two radar devices thatimage orthogonal planes, then performing odometry-aware temporal fusion togenerate denser 3D point clouds. RFconstruct then reconstructs 3D shapes ofobjects using a customized encoder-decoder model that does not require priorknowledge of the object's bound box. The shape reconstruction performance ofRFconstruct is compared against 3D models extracted from a depth cameraequipped with a LiDAR. We show that RFconstruct can accurately generate 3Dshapes of cars, bikes, and pedestrians.</description>
      <author>example@mail.com (Samah Hussein, Junfeng Guan, Swathi Narashiman, Saurabh Gupta, Haitham Hassanieh)</author>
      <guid isPermaLink="false">2504.12348v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Stronger, Steadier &amp; Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.12753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将深度信息与视觉基金模型（VFMs）特征结合，以提高图像中的几何一致性和VFMs的泛化性能。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉基金模型在领域通用语义分割（DGSS）中表现出色，但最近的方法往往忽略了视觉线索的脆弱性和底层几何的稳定性，这使得深度信息更加鲁棒。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为DepthForge的新型微调DGSS框架，旨在通过整合深度信息和视觉特征来提高几何一致性和泛化性能。&lt;h4&gt;方法&lt;/h4&gt;DepthForge框架整合了冻结的DINOv2或EVA02的视觉线索和冻结的Depth Anything V2的深度线索。在每个VFMs层中，引入了深度感知可学习标记，以解耦领域不变的视觉和空间信息，并增强VFMs的深度感知和注意力。此外，开发了一种深度细化解码器，并将其集成到模型架构中，以自适应地细化多层的VFM特征和深度感知可学习标记。&lt;h4&gt;主要发现&lt;/h4&gt;在基于各种DGSS设置和五个不同数据集的广泛实验中，DepthForge方法在性能、视觉-空间注意力的稳定性和泛化能力方面显著优于其他方法。特别是在极端条件下（如夜晚和雪天），DepthForge表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;DepthForge是一种有效的DGSS框架，能够显著提高模型的性能和泛化能力，并且代码可在GitHub上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Foundation Models (VFMs) have delivered remarkable performance inDomain Generalized Semantic Segmentation (DGSS). However, recent methods oftenoverlook the fact that visual cues are susceptible, whereas the underlyinggeometry remains stable, rendering depth information more robust. In thispaper, we investigate the potential of integrating depth information withfeatures from VFMs, to improve the geometric consistency within an image andboost the generalization performance of VFMs. We propose a novel fine-tuningDGSS framework, named DepthForge, which integrates the visual cues from frozenDINOv2 or EVA02 and depth cues from frozen Depth Anything V2. In each layer ofthe VFMs, we incorporate depth-aware learnable tokens to continuously decoupledomain-invariant visual and spatial information, thereby enhancing depthawareness and attention of the VFMs. Finally, we develop a depth refinementdecoder and integrate it into the model architecture to adaptively refinemulti-layer VFM features and depth-aware learnable tokens. Extensiveexperiments are conducted based on various DGSS settings and five differentdatsets as unseen target domains. The qualitative and quantitative resultsdemonstrate that our method significantly outperforms alternative approacheswith stronger performance, steadier visual-spatial attention, and superiorgeneralization ability. In particular, DepthForge exhibits outstandingperformance under extreme conditions (e.g., night and snow). Code is availableat https://github.com/anonymouse-xzrptkvyqc/DepthForge.</description>
      <author>example@mail.com (Siyu Chen, Ting Han, Changshe Zhang, Xin Luo, Meiliu Wu, Guorong Cai, Jinhe Su)</author>
      <guid isPermaLink="false">2504.12753v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Post-pre-training for Modality Alignment in Vision-Language Foundation Models</title>
      <link>http://arxiv.org/abs/2504.12717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025; Code: https://github.com/yshinya6/clip-refine&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CLIP-Refine是一种改进CLIP模型的前训练方法，旨在减少模态间隙，提升零样本性能。&lt;h4&gt;背景&lt;/h4&gt;尽管CLIP在下游任务上表现出色，但多模态特征空间存在模态间隙，限制了下游任务的表现。&lt;h4&gt;目的&lt;/h4&gt;CLIP-Refine旨在在不降低零样本性能的情况下，通过小规模图像-文本数据集在预训练和微调之间的一轮训练中对齐特征空间。&lt;h4&gt;方法&lt;/h4&gt;引入了两种技术：随机特征对齐（RaFA）和混合对比蒸馏（HyCD）。RaFA通过最小化到先验分布中随机参考向量的距离来对齐图像和文本特征。HyCD通过结合真实图像-文本对标签和预训练CLIP模型的输出生成混合软标签来更新模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CLIP-Refine成功地减轻了模态间隙并提高了零样本性能。&lt;h4&gt;结论&lt;/h4&gt;CLIP-Refine是一个有效的方法，可以在不牺牲零样本性能的情况下减少模态间隙，提高下游任务的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive language image pre-training (CLIP) is an essential component ofbuilding modern vision-language foundation models. While CLIP demonstratesremarkable zero-shot performance on downstream tasks, the multi-modal featurespaces still suffer from a modality gap, which is a gap between image and textfeature clusters and limits downstream task performance. Although existingworks attempt to address the modality gap by modifying pre-training orfine-tuning, they struggle with heavy training costs with large datasets ordegradations of zero-shot performance. This paper presents CLIP-Refine, apost-pre-training method for CLIP models at a phase between pre-training andfine-tuning. CLIP-Refine aims to align the feature space with 1 epoch trainingon small image-text datasets without zero-shot performance degradations. Tothis end, we introduce two techniques: random feature alignment (RaFA) andhybrid contrastive-distillation (HyCD). RaFA aligns the image and text featuresto follow a shared prior distribution by minimizing the distance to randomreference vectors sampled from the prior. HyCD updates the model with hybridsoft labels generated by combining ground-truth image-text pair labels andoutputs from the pre-trained CLIP model. This contributes to achieving bothmaintaining the past knowledge and learning new knowledge to align features.Our extensive experiments with multiple classification and retrieval tasks showthat CLIP-Refine succeeds in mitigating the modality gap and improving thezero-shot performance.</description>
      <author>example@mail.com (Shin'ya Yamaguchi, Dewei Feng, Sekitoshi Kanai, Kazuki Adachi, Daiki Chijiwa)</author>
      <guid isPermaLink="false">2504.12717v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image</title>
      <link>http://arxiv.org/abs/2504.11230v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in CVPR 2025 (Highlight)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在机器人操作任务中关节物体的类别级姿态估计，并引入了一个新的基准数据集。&lt;h4&gt;背景&lt;/h4&gt;现有方法在类别级别估计部件姿态和大小时，通常依赖于几何线索和复杂的分阶段流程，首先从点云中分割部件，然后进行标准化部件坐标空间（NPCS）的6D姿态估计。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了一个单阶段网络CAP-Net，用于估计类别关节部件的6D姿态和尺寸。&lt;h4&gt;方法&lt;/h4&gt;CAP-Net结合RGB-D特征以端到端方式生成实例分割和NPCS表示。该网络使用统一网络同时预测点级类别标签、质心偏移和NPCS图。然后，通过基于估计的质心距离对同一预测类别的点进行聚类，以隔离每个部件。最后，将每个部件的NPCS区域与点云对齐以恢复其最终姿态和尺寸。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估表明，该方法在RGBD-Art数据集上显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;模型在机器人任务中的实际部署强调了其鲁棒性和出色的仿真到现实迁移能力，证实了其实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;本文针对机器人操作任务中关节物体的类别级姿态估计问题，引入了一个新的基准数据集。虽然近期方法在类别级别估计部件姿态和大小时，往往依赖于几何线索和复杂的分阶段流程，首先从点云中分割部件，然后进行标准化部件坐标空间（NPCS）的6D姿态估计。这些方法忽略了来自RGB图像的密集语义线索，导致精度不佳，尤其是对于部件较小的物体。为了解决这些局限性，我们提出了一种单阶段网络CAP-Net，用于估计类别关节部件的6D姿态和尺寸。该方法结合RGB-D特征以端到端方式生成实例分割和NPCS表示。CAP-Net使用统一网络同时预测点级类别标签、质心偏移和NPCS图。然后，通过基于估计的质心距离对同一预测类别的点进行聚类，以隔离每个部件。最后，将每个部件的NPCS区域与点云对齐以恢复其最终姿态和尺寸。为了缩小仿真与现实之间的差距，我们引入了RGBD-Art数据集，这是迄今为止最大的RGB-D关节数据集，具有逼真的RGB图像和从真实传感器模拟的深度噪声。在RGBD-Art数据集上的实验评估表明，我们的方法在性能上显著优于现有方法。我们模型在机器人任务中的实际部署强调了其鲁棒性和出色的仿真到现实迁移能力，证实了其实际应用价值。我们的数据集、代码和预训练模型可在项目页面上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper tackles category-level pose estimation of articulated objects inrobotic manipulation tasks and introduces a new benchmark dataset. While recentmethods estimate part poses and sizes at the category level, they often rely ongeometric cues and complex multi-stage pipelines that first segment parts fromthe point cloud, followed by Normalized Part Coordinate Space (NPCS) estimationfor 6D poses. These approaches overlook dense semantic cues from RGB images,leading to suboptimal accuracy, particularly for objects with small parts. Toaddress these limitations, we propose a single-stage Network, CAP-Net, forestimating the 6D poses and sizes of Categorical Articulated Parts. This methodcombines RGB-D features to generate instance segmentation and NPCSrepresentations for each part in an end-to-end manner. CAP-Net uses a unifiednetwork to simultaneously predict point-wise class labels, centroid offsets,and NPCS maps. A clustering algorithm then groups points of the same predictedclass based on their estimated centroid distances to isolate each part.Finally, the NPCS region of each part is aligned with the point cloud torecover its final pose and size. To bridge the sim-to-real domain gap, weintroduce the RGBD-Art dataset, the largest RGB-D articulated dataset to date,featuring photorealistic RGB images and depth noise simulated from realsensors. Experimental evaluations on the RGBD-Art dataset demonstrate that ourmethod significantly outperforms the state-of-the-art approach. Real-worlddeployments of our model in robotic tasks underscore its robustness andexceptional sim-to-real transfer capabilities, confirming its substantialpractical utility. Our dataset, code and pre-trained models are available onthe project page.</description>
      <author>example@mail.com (Jingshun Huang, Haitao Lin, Tianyu Wang, Yanwei Fu, Xiangyang Xue, Yi Zhu)</author>
      <guid isPermaLink="false">2504.11230v2</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>TransST: Transfer Learning Embedded Spatial Factor Modeling of Spatial Transcriptomics Data</title>
      <link>http://arxiv.org/abs/2504.12353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为TransST的新型迁移学习框架，用于从目标空间转录组数据中推断细胞异质性，有效识别细胞亚群和相应的驱动生物标志物。&lt;h4&gt;背景&lt;/h4&gt;空间转录组学是生物医学研究中的重要工具，但由于技术限制，如分辨率较低和测序深度不足，难以从数据中可靠地提取真实生物学信号。&lt;h4&gt;目的&lt;/h4&gt;提出TransST框架，以解决现有空间转录组学技术的局限性，提高从数据中提取真实生物学信号的能力。&lt;h4&gt;方法&lt;/h4&gt;通过迁移学习框架，自适应地利用外部来源的细胞标记信息，推断目标空间转录组数据的细胞级异质性。&lt;h4&gt;主要发现&lt;/h4&gt;在多个实际研究和模拟设置中的应用表明，TransST方法显著提高了现有技术。例如，在乳腺癌研究中，TransST成功识别了五个具有生物学意义的细胞簇，包括原位癌和侵袭性癌的亚组，并且是唯一能够从所有研究方法中区分脂肪组织和结缔组织的方法。&lt;h4&gt;结论&lt;/h4&gt;TransST方法在识别空间转录组数据中的细胞亚群和检测相应的驱动生物标志物方面既有效又稳健。&lt;h4&gt;翻译&lt;/h4&gt;Background: Spatial transcriptomics have emerged as a powerful tool inbiomedical research because of its ability to capture both the spatial contextsand abundance of the complete RNA transcript profile in organs of interest.However, limitations of the technology such as the relatively low resolutionand comparatively insufficient sequencing depth make it difficult to reliablyextract real biological signals from these data. To alleviate this challenge,we propose a novel transfer learning framework, referred to as TransST, toadaptively leverage the cell-labeled information from external sources ininferring cell-level heterogeneity of a target spatial transcriptomics data.  Results: Applications in several real studies as well as a number ofsimulation settings show that our approach significantly improves existingtechniques. For example, in the breast cancer study, TransST successfullyidentifies five biologically meaningful cell clusters, including the two subgroups of cancer in situ and invasive cancer; in addition, only TransST is able to separate the adipose tissues from the connective issues among all thestudied methods.  Conclusions: In summary, the proposed method TransST is both effective androbust in identifying cell subclusters and detecting corresponding drivingbiomarkers in spatial transcriptomics data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Background: Spatial transcriptomics have emerged as a powerful tool inbiomedical research because of its ability to capture both the spatial contextsand abundance of the complete RNA transcript profile in organs of interest.However, limitations of the technology such as the relatively low resolutionand comparatively insufficient sequencing depth make it difficult to reliablyextract real biological signals from these data. To alleviate this challenge,we propose a novel transfer learning framework, referred to as TransST, toadaptively leverage the cell-labeled information from external sources ininferring cell-level heterogeneity of a target spatial transcriptomics data.  Results: Applications in several real studies as well as a number ofsimulation settings show that our approach significantly improves existingtechniques. For example, in the breast cancer study, TransST successfullyidentifies five biologically meaningful cell clusters, including the twosubgroups of cancer in situ and invasive cancer; in addition, only TransST isable to separate the adipose tissues from the connective issues among all thestudied methods.  Conclusions: In summary, the proposed method TransST is both effective androbust in identifying cell subclusters and detecting corresponding drivingbiomarkers in spatial transcriptomics data.</description>
      <author>example@mail.com (Shuo Shuo Liu, Shikun Wang, Yuxuan Chen, Anil K. Rustgi, Ming Yuan, Jianhua Hu)</author>
      <guid isPermaLink="false">2504.12353v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Embodied-R: Collaborative Framework for Activating Embodied Spatial Reasoning in Foundation Models via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.12680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了Embodied-R，一个结合大规模视觉语言模型（VLMs）和少量语言模型（LMs）的协同框架，用于感知和推理。通过强化学习和新颖的奖励系统，该模型在有限的计算资源下实现了慢思考能力，并在多项任务中达到或超过了最先进的模型。&lt;h4&gt;背景&lt;/h4&gt;人类能通过连续视觉观察，如自视角视频流，感知和推理空间关系。然而，预训练模型如何获得这种能力，特别是高级推理能力，尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;研究预训练模型如何获得空间关系感知和高级推理能力，并开发一个能够在有限计算资源下实现慢思考能力的模型。&lt;h4&gt;方法&lt;/h4&gt;Embodied-R框架结合了大规模视觉语言模型（VLMs）进行感知和少量语言模型（LMs）进行推理。使用强化学习（RL）和考虑思考-回答逻辑一致性的新颖奖励系统来训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;在仅使用5k个具身视频样本进行训练后，Embodied-R（含3B LM）在分布内和分布外的具身空间推理任务上均达到了最先进的模型水平。Embodied-R还展现出诸如系统分析和情境整合等自发生成的思维模式。&lt;h4&gt;结论&lt;/h4&gt;Embodied-R框架为理解和实现高级推理能力提供了一种新的方法，并通过实验证明了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;Humans can perceive and reason about spatial relationships from sequential visual observations, such as egocentric video streams. However, how pretrained models acquire such abilities, especially high-level reasoning, remains unclear. This paper introduces Embodied-R, a collaborative framework combining large-scale Vision-Language Models (VLMs) for perception and small-scale Language Models (LMs) for reasoning. Using Reinforcement Learning (RL) with an novel reward system considering think-answer logical consistency, the model achieves slow-thinking capabilities with limited computational resources. After training on only 5k embodied video samples, Embodied-R with a 3B LM matches state-of-the-art multimodal reasoning models (OpenAI-o1, Gemini-2.5-pro) on both in-distribution and out-of-distribution embodied spatial reasoning tasks. Embodied-R also exhibits emergent thinking patterns such as systematic analysis and contextual integration. We further explore research questions including response length, training on VLM, strategies for reward design, and differences in model generalization after SFT (Supervised Fine-Tuning) and RL training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans can perceive and reason about spatial relationships from sequentialvisual observations, such as egocentric video streams. However, how pretrainedmodels acquire such abilities, especially high-level reasoning, remainsunclear. This paper introduces Embodied-R, a collaborative framework combininglarge-scale Vision-Language Models (VLMs) for perception and small-scaleLanguage Models (LMs) for reasoning. Using Reinforcement Learning (RL) with anovel reward system considering think-answer logical consistency, the modelachieves slow-thinking capabilities with limited computational resources. Aftertraining on only 5k embodied video samples, Embodied-R with a 3B LM matchesstate-of-the-art multimodal reasoning models (OpenAI-o1, Gemini-2.5-pro) onboth in-distribution and out-of-distribution embodied spatial reasoning tasks.Embodied-R also exhibits emergent thinking patterns such as systematic analysisand contextual integration. We further explore research questions includingresponse length, training on VLM, strategies for reward design, and differencesin model generalization after SFT (Supervised Fine-Tuning) and RL training.</description>
      <author>example@mail.com (Baining Zhao, Ziyou Wang, Jianjie Fang, Chen Gao, Fanhang Man, Jinqiang Cui, Xin Wang, Xinlei Chen, Yong Li, Wenwu Zhu)</author>
      <guid isPermaLink="false">2504.12680v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>SAM-Based Building Change Detection with Distribution-Aware Fourier Adaptation and Edge-Constrained Warping</title>
      <link>http://arxiv.org/abs/2504.12619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于SegmentAnything Model (SAM)的建筑物变化检测网络FAEWNet，用于解决建筑物变化检测中的挑战。&lt;h4&gt;背景&lt;/h4&gt;建筑物变化检测在城市发展、灾害评估和军事侦察中具有挑战性，现有的基于适配器的微调方法在建筑物分布不平衡、细微变化检测和边缘提取方面存在问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的网络FAEWNet，以解决建筑物变化检测中的挑战，包括领域差距、不平衡的建筑物分布、双时相不匹配和噪声干扰。&lt;h4&gt;方法&lt;/h4&gt;FAEWNet利用SAM编码器从遥感图像中提取丰富视觉特征，并引入分布感知傅里叶聚合适配器来关注特定地面物体，同时设计了一个新的流模块来优化建筑物边缘提取和变化建筑物的感知。&lt;h4&gt;主要发现&lt;/h4&gt;FAEWNet在LEVIR-CD、S2Looking和WHU-CD数据集上取得了最先进的检测结果。&lt;h4&gt;结论&lt;/h4&gt;FAEWNet能够有效解决建筑物变化检测中的挑战，并通过提高检测精度和边缘识别能力来提升变化检测的性能。&lt;h4&gt;翻译&lt;/h4&gt;Building change detection remains challenging for urban development, disaster assessment, and military reconnaissance. While foundation models like SegmentAnything Model (SAM) show strong segmentation capabilities, SAM is limited in the task of building change detection due to domain gap issues. Existing adapter-based fine-tuning approaches face challenges with imbalanced building distribution, resulting in poor detection of subtle changes and inaccurate edge extraction. Additionally, bi-temporal misalignment in change detection, typically addressed by optical flow, remains vulnerable to background noises. This affects the detection of building changes and compromises both detection accuracy and edge recognition. To tackle these challenges, we propose a new SAM-Based Network with Distribution-Aware Fourier Adaptation and Edge-Constrained Warping (FAEWNet) for building change detection. FAEWNet utilizes the SAM encoder to extract rich visual features from remote sensing images. To guide SAM in focusing on specific ground objects in remote sensing scenes, we propose a Distribution-Aware Fourier Aggregated Adapter to aggregate task-oriented changed information. This adapter not only effectively addresses the domain gap issue, but also pays attention to the distribution of changed buildings. Furthermore, to mitigate noise interference and misalignment in height offset estimation, we design a novel flow module that refines building edge extraction and enhances the perception of changed buildings. Our state-of-the-art results on the LEVIR-CD, S2Looking and WHU-CD datasets highlight the effectiveness of FAEWNet. The code is available at https://github.com/SUPERMAN123000/FAEWNet.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building change detection remains challenging for urban development, disasterassessment, and military reconnaissance. While foundation models like SegmentAnything Model (SAM) show strong segmentation capabilities, SAM is limited inthe task of building change detection due to domain gap issues. Existingadapter-based fine-tuning approaches face challenges with imbalanced buildingdistribution, resulting in poor detection of subtle changes and inaccurate edgeextraction. Additionally, bi-temporal misalignment in change detection,typically addressed by optical flow, remains vulnerable to background noises.This affects the detection of building changes and compromises both detectionaccuracy and edge recognition. To tackle these challenges, we propose a newSAM-Based Network with Distribution-Aware Fourier Adaptation andEdge-Constrained Warping (FAEWNet) for building change detection. FAEWNetutilizes the SAM encoder to extract rich visual features from remote sensingimages. To guide SAM in focusing on specific ground objects in remote sensingscenes, we propose a Distribution-Aware Fourier Aggregated Adapter to aggregatetask-oriented changed information. This adapter not only effectively addressesthe domain gap issue, but also pays attention to the distribution of changedbuildings. Furthermore, to mitigate noise interference and misalignment inheight offset estimation, we design a novel flow module that refines buildingedge extraction and enhances the perception of changed buildings. Ourstate-of-the-art results on the LEVIR-CD, S2Looking and WHU-CD datasetshighlight the effectiveness of FAEWNet. The code is available athttps://github.com/SUPERMAN123000/FAEWNet.</description>
      <author>example@mail.com (Yun-Cheng Li, Sen Lei, Yi-Tao Zhao, Heng-Chao Li, Jun Li, Antonio Plaza)</author>
      <guid isPermaLink="false">2504.12619v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Temporal Link Prediction</title>
      <link>http://arxiv.org/abs/2504.10925v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图上的时序链接预测问题，并提出了一种新的迁移学习方法，以增强记忆密集型模型的迁移效果。&lt;h4&gt;背景&lt;/h4&gt;链接预测在推荐系统和药物发现等领域有广泛应用。时序链接预测（TLP）是指在动态图上预测未来的链接，其复杂性在于图的动态性质。&lt;h4&gt;目的&lt;/h4&gt;开发迁移有效的时序链接预测方法，特别是针对记忆密集型模型。&lt;h4&gt;方法&lt;/h4&gt;本文受结构信号对时序链接预测任务信息量的启发，将结构映射模块添加到现有的TLP模型架构中，该模块学习从图结构（拓扑）特征到记忆嵌入的映射。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法为时序链接预测提供了一种无需记忆的模型基础。&lt;h4&gt;结论&lt;/h4&gt;本研究为时序链接预测的迁移学习提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/google-research/google-research/tree/master/fm4tlp&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction on graphs has applications spanning from recommender systemsto drug discovery. Temporal link prediction (TLP) refers to predicting futurelinks in a temporally evolving graph and adds additional complexity related tothe dynamic nature of graphs. State-of-the-art TLP models incorporate memorymodules alongside graph neural networks to learn both the temporal mechanismsof incoming nodes and the evolving graph topology. However, memory modules onlystore information about nodes seen at train time, and hence such models cannotbe directly transferred to entirely new graphs at test time and deployment. Inthis work, we study a new transfer learning task for temporal link prediction,and develop transfer-effective methods for memory-laden models. Specifically,motivated by work showing the informativeness of structural signals for the TLPtask, we augment a structural mapping module to the existing TLP modelarchitectures, which learns a mapping from graph structural (topological)features to memory embeddings. Our work paves the way for a memory-freefoundation model for TLP.</description>
      <author>example@mail.com (Ayan Chatterjee, Barbara Ikica, Babak Ravandi, John Palowitch)</author>
      <guid isPermaLink="false">2504.10925v2</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Privacy-Preserving Operating Room Workflow Analysis using Digital Twins</title>
      <link>http://arxiv.org/abs/2504.12552v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种保护隐私的手术室视频分析和事件检测的两阶段流程。&lt;h4&gt;背景&lt;/h4&gt;手术室是一个复杂的场所，优化工作流程对于降低成本和提高患者结果至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究利用计算机视觉方法自动识别围手术期事件，以识别手术室优化的瓶颈。&lt;h4&gt;方法&lt;/h4&gt;提出了一种两阶段的隐私保护手术室视频分析和事件检测流程。第一阶段利用视觉基础模型进行深度估计和语义分割，从常规RGB视频中生成去识别的数字孪生（DT）。第二阶段采用SafeOR模型，这是一种融合了两流处理分割掩码和深度图的手术室事件检测方法。&lt;h4&gt;主要发现&lt;/h4&gt;基于DT的手术室事件检测模型在检测手术室事件方面表现出与原始RGB视频模型相当甚至更好的性能。&lt;h4&gt;结论&lt;/h4&gt;数字孪生（DT）可以实现对手术室工作流程的隐私保护分析，促进去识别数据在不同机构之间的共享，并可能通过减轻特定领域的外观差异来提高模型的可泛化性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Purpose: The operating room (OR) is a complex environment where optimizing workflows is critical to reduce costs and improve patient outcomes. The use of computer vision approaches for the automatic recognition of perioperative events enables identification of bottlenecks for OR optimization. However, privacy concerns limit the use of computer vision for automated event detection from OR videos, which makes privacy-preserving approaches needed for OR workflow analysis. Methods: We propose a two-stage pipeline for privacy-preserving OR video analysis and event detection. In the first stage, we leverage vision foundation models for depth estimation and semantic segmentation to generate de-identified Digital Twins (DT) of the OR from conventional RGB videos. In the second stage, we employ the SafeOR model, a fused two-stream approach that processes segmentation masks and depth maps for OR event detection. We evaluate this method on an internal dataset of 38 simulated surgical trials with five event classes. Results: Our results indicate that this DT-based approach to the OR event detection model achieves performance on par and sometimes even better than raw RGB video-based models on detecting OR events. Conclusion: DTs enable privacy-preserving OR workflow analysis, facilitating the sharing of de-identified data across institutions and they can potentially enhance model generalizability by mitigating domain-specific appearance differences.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: The operating room (OR) is a complex environment where optimizingworkflows is critical to reduce costs and improve patient outcomes. The use ofcomputer vision approaches for the automatic recognition of perioperativeevents enables identification of bottlenecks for OR optimization. However,privacy concerns limit the use of computer vision for automated event detectionfrom OR videos, which makes privacy-preserving approaches needed for ORworkflow analysis. Methods: We propose a two-stage pipeline forprivacy-preserving OR video analysis and event detection. In the first stage,we leverage vision foundation models for depth estimation and semanticsegmentation to generate de-identified Digital Twins (DT) of the OR fromconventional RGB videos. In the second stage, we employ the SafeOR model, afused two-stream approach that processes segmentation masks and depth maps forOR event detection. We evaluate this method on an internal dataset of 38simulated surgical trials with five event classes. Results: Our resultsindicate that this DT-based approach to the OR event detection model achievesperformance on par and sometimes even better than raw RGB video-based models ondetecting OR events. Conclusion: DTs enable privacy-preserving OR workflowanalysis, facilitating the sharing of de-identified data across institutionsand they can potentially enhance model generalizability by mitigatingdomain-specific appearance differences.</description>
      <author>example@mail.com (Alejandra Perez, Han Zhang, Yu-Chun Ku, Lalithkumar Seenivasan, Roger Soberanis, Jose L. Porras, Richard Day, Jeff Jopling, Peter Najjar, Mathias Unberath)</author>
      <guid isPermaLink="false">2504.12552v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>You Don't Need All Attentions: Distributed Dynamic Fine-Tuning for Foundation Models</title>
      <link>http://arxiv.org/abs/2504.12471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为D2FT的新型分布式动态微调框架，旨在降低基础模型微调的计算成本和通信成本。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型规模的增加，在有限内存带宽的商业设备上进行微调面临挑战。&lt;h4&gt;目的&lt;/h4&gt;减少基础模型微调的计算工作量和通信成本。&lt;h4&gt;方法&lt;/h4&gt;D2FT通过观察并非所有注意力模块在微调过程中都是必要的，基于此，采用三种创新的选择策略，并利用多背包优化来优化这些策略，以实现计算工作量的平衡。&lt;h4&gt;主要发现&lt;/h4&gt;D2FT在CIFAR-10、CIFAR-100和Stanford Cars数据集上，将训练计算成本降低了40%，通信成本降低了50%，同时只降低了1%到2%的准确率。&lt;h4&gt;结论&lt;/h4&gt;D2FT框架在降低计算成本和通信成本的同时，保持了较高的准确率，并且可以扩展到LoRA等先进的参数高效微调技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning plays a crucial role in adapting models to downstream tasks withminimal training efforts. However, the rapidly increasing size of foundationmodels poses a daunting challenge for accommodating foundation modelfine-tuning in most commercial devices, which often have limited memorybandwidth. Techniques like model sharding and tensor parallelism address thisissue by distributing computation across multiple devices to meet memoryrequirements. Nevertheless, these methods do not fully leverage theirfoundation nature in facilitating the fine-tuning process, resulting in highcomputational costs and imbalanced workloads. We introduce a novel DistributedDynamic Fine-Tuning (D2FT) framework that strategically orchestrates operationsacross attention modules based on our observation that not all attentionmodules are necessary for forward and backward propagation in fine-tuningfoundation models. Through three innovative selection strategies, D2FTsignificantly reduces the computational workload required for fine-tuningfoundation models. Furthermore, D2FT addresses workload imbalances indistributed computing environments by optimizing these selection strategies viamultiple knapsack optimization. Our experimental results demonstrate that theproposed D2FT framework reduces the training computational costs by 40% andtraining communication costs by 50% with only 1% to 2% accuracy drops on theCIFAR-10, CIFAR-100, and Stanford Cars datasets. Moreover, the results showthat D2FT can be effectively extended to recent LoRA, a state-of-the-artparameter-efficient fine-tuning technique. By reducing 40% computational costor 50% communication cost, D2FT LoRA top-1 accuracy only drops 4% to 6% onStanford Cars dataset.</description>
      <author>example@mail.com (Shiwei Ding, Lan Zhang, Zhenlin Wang, Giuseppe Ateniese, Xiaoyong Yuan)</author>
      <guid isPermaLink="false">2504.12471v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Activated LoRA: Fine-tuned LLMs for Intrinsics</title>
      <link>http://arxiv.org/abs/2504.12397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2504.11704&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Activated LoRA（aLoRA）的框架，用于提高多轮对话中LoRA的效率，通过仅在aLoRA被调用后调整序列中的权重，从而避免重新计算整个轮次的KV缓存。&lt;h4&gt;背景&lt;/h4&gt;LoRA是一种高效的基础模型权重微调框架，但多轮对话中频繁切换LoRA效率低下，因为需要重新计算整个轮次的KV缓存。&lt;h4&gt;目的&lt;/h4&gt;提出aLoRA以提高多轮对话中LoRA的效率，避免重新计算KV缓存。&lt;h4&gt;方法&lt;/h4&gt;修改LoRA框架，使其仅在aLoRA被调用后调整序列中的权重，接受基础模型的KV缓存，实现即时激活。&lt;h4&gt;主要发现&lt;/h4&gt;aLoRA可以显著提高多轮对话中LoRA的效率，同时保持与标准LoRA相当的准确率，并实现显著的推理效益。&lt;h4&gt;结论&lt;/h4&gt;aLoRA是一种有效的LoRA改进方法，可以显著提高多轮对话中LoRA的效率，并保持良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;Low-Rank Adaptation (LoRA)已经成为微调大型基础模型权重的高效框架，并成为数据驱动LLM定制的首选方法。尽管具有高度定制的行为和能力，但在多轮对话中切换相关的LoRA效率非常低，因为必须在生成开始之前使用LoRA权重重新计算整个轮次的键值（KV）缓存。为了解决这个问题，我们提出了Activated LoRA（aLoRA），它修改了LoRA框架，使其仅在aLoRA被调用后调整序列中的权重。这种改变关键地允许aLoRA接受基础模型的输入字符串的KV缓存，这意味着aLoRA可以在需要时立即在链中激活，而无需重新计算缓存。这使得构建所谓的“内建”模型成为可能，即用于对输入链或对话的一部分执行定义明确的操作的非常专业的模型。我们使用aLoRA训练了一组内建模型，证明了与标准LoRA相当的准确率，同时实现了显著的推理效益。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adaptation (LoRA) has emerged as a highly efficient framework forfinetuning the weights of large foundation models, and has become the go-tomethod for data-driven customization of LLMs. Despite the promise of highlycustomized behaviors and capabilities, switching between relevant LoRAs in amultiturn setting is highly inefficient, as the key-value (KV) cache of theentire turn history must be recomputed with the LoRA weights before generationcan begin. To address this problem, we propose Activated LoRA (aLoRA), whichmodifies the LoRA framework to only adapt weights for the tokens in thesequence \emph{after} the aLoRA is invoked. This change crucially allows aLoRAto accept the base model's KV cache of the input string, meaning that aLoRA canbe instantly activated whenever needed in a chain without recomputing thecache. This enables building what we call \emph{intrinsics}, i.e. highlyspecialized models invoked to perform well-defined operations on portions of aninput chain or conversation that otherwise uses the base model by default. Weuse aLoRA to train a set of intrinsics models, demonstrating competitiveaccuracy with standard LoRA while achieving significant inference benefits.</description>
      <author>example@mail.com (Kristjan Greenewald, Luis Lastras, Thomas Parnell, Vraj Shah, Lucian Popa, Giulio Zizzo, Chulaka Gunasekara, Ambrish Rawat, David Cox)</author>
      <guid isPermaLink="false">2504.12397v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Causal integration of chemical structures improves representations of microscopy images for morphological profiling</title>
      <link>http://arxiv.org/abs/2504.09544v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文介绍了MICON（分子-图像对比学习）这一表示学习框架，用于在自监督深度学习中提高对高通量显微镜屏幕中细胞形态变化的量化能力，并探讨了将化学化合物结构信息纳入学习过程的有效性。&lt;h4&gt;背景&lt;/h4&gt;目前大多数高通量显微镜屏幕的方法仅从图像中学习，而忽略了这些屏幕的多模态特性，即既涉及化学或基因扰动，也涉及基于图像的读数。&lt;h4&gt;目的&lt;/h4&gt;提出通过在自监督预训练中整合化学化合物结构信息，来改善高通量显微镜屏幕中图像学习表示的方法。&lt;h4&gt;方法&lt;/h4&gt;设计了MICON框架，将化学化合物视为诱导细胞表型反事实变换的治疗手段，并在具有挑战性的评估环境中进行测试，该环境要求模型能够识别药物在独立复制品和数据生成中心之间的可重复效果。&lt;h4&gt;主要发现&lt;/h4&gt;MICON在识别药物效果方面显著优于CellProfiler等经典手工特征和现有的基于深度学习的表示学习方法。将化合物信息纳入学习过程提高了评估设置中的性能，并且将化合物作为治疗手段在因果框架中进行建模优于直接在单一表示空间中对齐图像和化合物的方法。&lt;h4&gt;结论&lt;/h4&gt;该研究为形态分析中的表示学习开辟了新的方向，表明方法应明确考虑显微镜筛选数据的多模态特性。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in self-supervised deep learning have improved our ability to quantify cellular morphological changes in high-throughput microscopy screens, a process known as morphological profiling. However, most current methods only learn from images, despite many screens being inherently multimodal, as they involve both a chemical or genetic perturbation as well as an image-based readout. We hypothesized that incorporating chemical compound structure during self-supervised pre-training could improve learned representations of images in high-throughput microscopy screens. We introduce a representation learning framework, MICON (Molecular-Image Contrastive Learning), that models chemical compounds as treatments that induce counterfactual transformations of cell phenotypes. MICON significantly outperforms classical hand-crafted features such as CellProfiler and existing deep-learning-based representation learning methods in challenging evaluation settings where models must identify reproducible effects of drugs across independent replicates and data-generating centers. We demonstrate that incorporating chemical compound information into the learning process provides consistent improvements in our evaluation setting and that modeling compounds specifically as treatments in a causal framework outperforms approaches that directly align images and compounds in a single representation space. Our findings point to a new direction for representation learning in morphological profiling, suggesting that methods should explicitly account for the multimodal nature of microscopy screening data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in self-supervised deep learning have improved our ability toquantify cellular morphological changes in high-throughput microscopy screens,a process known as morphological profiling. However, most current methods onlylearn from images, despite many screens being inherently multimodal, as theyinvolve both a chemical or genetic perturbation as well as an image-basedreadout. We hypothesized that incorporating chemical compound structure duringself-supervised pre-training could improve learned representations of images inhigh-throughput microscopy screens. We introduce a representation learningframework, MICON (Molecular-Image Contrastive Learning), that models chemicalcompounds as treatments that induce counterfactual transformations of cellphenotypes. MICON significantly outperforms classical hand-crafted featuressuch as CellProfiler and existing deep-learning-based representation learningmethods in challenging evaluation settings where models must identifyreproducible effects of drugs across independent replicates and data-generatingcenters. We demonstrate that incorporating chemical compound information intothe learning process provides consistent improvements in our evaluation settingand that modeling compounds specifically as treatments in a causal frameworkoutperforms approaches that directly align images and compounds in a singlerepresentation space. Our findings point to a new direction for representationlearning in morphological profiling, suggesting that methods should explicitlyaccount for the multimodal nature of microscopy screening data.</description>
      <author>example@mail.com (Yemin Yu, Neil Tenenholtz, Lester Mackey, Ying Wei, David Alvarez-Melis, Ava P. Amini, Alex X. Lu)</author>
      <guid isPermaLink="false">2504.09544v2</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Regist3R: Incremental Registration with Stereo Foundation Model</title>
      <link>http://arxiv.org/abs/2504.12356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Regist3R的新型立体基础模型，用于高效和可扩展的增量重建，解决了多视角3D重建中的计算成本高和累积误差大等问题。&lt;h4&gt;背景&lt;/h4&gt;多视角3D重建在计算机视觉领域是一个重要且具有挑战性的问题，现有的方法在扩展到多视角场景时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出Regist3R模型，旨在解决多视角3D重建中的计算成本高和累积误差大等问题。&lt;h4&gt;方法&lt;/h4&gt;Regist3R利用增量重建范式，从无序的多视角图像集中进行大规模3D重建。&lt;h4&gt;主要发现&lt;/h4&gt;Regist3R在公共数据集上的实验表明，其性能与基于优化的方法相当，同时显著提高了计算效率，并优于现有的多视角重建模型。此外，通过点云图基础模型首次实现了包含数千个视角的大规模场景重建。&lt;h4&gt;结论&lt;/h4&gt;Regist3R在多视角3D重建任务中具有潜在的应用价值，包括城市建模、航空测绘等。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view 3D reconstruction has remained an essential yet challengingproblem in the field of computer vision. While DUSt3R and its successors haveachieved breakthroughs in 3D reconstruction from unposed images, these methodsexhibit significant limitations when scaling to multi-view scenarios, includinghigh computational cost and cumulative error induced by global alignment. Toaddress these challenges, we propose Regist3R, a novel stereo foundation modeltailored for efficient and scalable incremental reconstruction. Regist3Rleverages an incremental reconstruction paradigm, enabling large-scale 3Dreconstructions from unordered and many-view image collections. We evaluateRegist3R on public datasets for camera pose estimation and 3D reconstruction.Our experiments demonstrate that Regist3R achieves comparable performance withoptimization-based methods while significantly improving computationalefficiency, and outperforms existing multi-view reconstruction models.Furthermore, to assess its performance in real-world applications, we introducea challenging oblique aerial dataset which has long spatial spans and hundredsof views. The results highlight the effectiveness of Regist3R. We alsodemonstrate the first attempt to reconstruct large-scale scenes encompassingover thousands of views through pointmap-based foundation models, showcasingits potential for practical applications in large-scale 3D reconstructiontasks, including urban modeling, aerial mapping, and beyond.</description>
      <author>example@mail.com (Sidun Liu, Wenyu Li, Peng Qiao, Yong Dou)</author>
      <guid isPermaLink="false">2504.12356v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Prototype-Guided Diffusion for Digital Pathology: Achieving Foundation Model Performance with Minimal Clinical Data</title>
      <link>http://arxiv.org/abs/2504.12351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种原型引导的扩散模型，用于生成高保真度的合成病理数据，从而在大规模的自监督学习中减少对真实患者样本的依赖，同时保持下游性能。&lt;h4&gt;背景&lt;/h4&gt;数字病理中的基础模型使用大量数据集学习复杂的组织学图像的有用紧凑特征表示，但数据集大小与性能之间的相关性透明度有限，引发了对仅通过增加数据来提高性能是否总是必要的疑问。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来生成高质量的合成病理数据，以促进自监督学习，减少对真实患者样本的依赖，并保持或提高性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种原型引导的扩散模型，在采样过程中使用组织学原型的指导，以确保生成数据的生物学和诊断意义。&lt;h4&gt;主要发现&lt;/h4&gt;在合成数据集上训练的自监督特征在数据量减少了60倍至760倍的情况下仍然取得了有竞争力的性能，并且在多个评估指标和任务上与训练在大型真实世界数据集上的模型具有统计上相当或更好的性能。&lt;h4&gt;结论&lt;/h4&gt;混合使用合成数据和真实数据的方法进一步提升了性能，在多项评估中达到了最佳结果，强调了生成式AI在为数字病理学创建引人注目的训练数据方面的潜力，显著减少了对外延广泛的临床数据集的依赖，并突出了该方法的高效性。&lt;h4&gt;翻译&lt;/h4&gt;Using a prototype-guided diffusion model, this study generates high-fidelity synthetic pathology data to enable large-scale self-supervised learning while reducing reliance on real patient samples and maintaining downstream performance. This approach, guided by histological prototypes, ensures biologically and diagnostically meaningful variations in the generated data. The results demonstrate that self-supervised features trained on the synthetic dataset achieve competitive performance with significantly less data than those trained on large real-world datasets, showing statistical equivalence or even superiority across multiple evaluation metrics and tasks. The hybrid approach using synthetic and real data enhances performance, reaching top results in several evaluations, highlighting the potential of generative AI in creating compelling training data for digital pathology and significantly reducing the reliance on extensive clinical datasets, while emphasizing the efficiency of the proposed method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models in digital pathology use massive datasets to learn usefulcompact feature representations of complex histology images. However, there islimited transparency into what drives the correlation between dataset size andperformance, raising the question of whether simply adding more data toincrease performance is always necessary. In this study, we propose aprototype-guided diffusion model to generate high-fidelity synthetic pathologydata at scale, enabling large-scale self-supervised learning and reducingreliance on real patient samples while preserving downstream performance. Usingguidance from histological prototypes during sampling, our approach ensuresbiologically and diagnostically meaningful variations in the generated data. Wedemonstrate that self-supervised features trained on our synthetic datasetachieve competitive performance despite using ~60x-760x less data than modelstrained on large real-world datasets. Notably, models trained using oursynthetic data showed statistically comparable or better performance acrossmultiple evaluation metrics and tasks, even when compared to models trained onorders of magnitude larger datasets. Our hybrid approach, combining syntheticand real data, further enhanced performance, achieving top results in severalevaluations. These findings underscore the potential of generative AI to createcompelling training data for digital pathology, significantly reducing thereliance on extensive clinical datasets and highlighting the efficiency of ourapproach.</description>
      <author>example@mail.com (Ekaterina Redekop, Mara Pleasure, Vedrana Ivezic, Zichen Wang, Kimberly Flores, Anthony Sisk, William Speier, Corey Arnold)</author>
      <guid isPermaLink="false">2504.12351v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via Scalable Conditioned Neural Fields</title>
      <link>http://arxiv.org/abs/2504.12262v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 5 main figures, 3 tables, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SCENT的新型框架，用于可扩展且基于连续性的时空表示学习。&lt;h4&gt;背景&lt;/h4&gt;时空学习因空间和时间依赖关系的复杂交互、数据的高维性和可扩展性限制而具有挑战性。在科学领域，数据的非规则分布（如传感器故障导致的缺失值）和高体积（如高保真模拟）进一步加剧了这些挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在解决时空学习中的可扩展性和连续性问题。&lt;h4&gt;方法&lt;/h4&gt;SCENT通过一个基于transformer的编码器-处理器-解码器架构统一了插值、重建和预测。它引入了可学习的查询来增强泛化能力，并采用查询级别的交叉注意力机制以有效地捕获多尺度依赖。为了确保数据规模和模型复杂度的可扩展性，SCENT集成了稀疏注意力机制，允许灵活的输出表示和高效的评价。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的模拟和真实世界实验验证了SCENT的有效性，证明了其在多个具有挑战性的任务中实现了最先进的性能，同时实现了卓越的可扩展性。&lt;h4&gt;结论&lt;/h4&gt;SCENT是一种有效的时空表示学习方法，能够处理高维和大规模数据，并在多个任务中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatiotemporal learning is challenging due to the intricate interplay betweenspatial and temporal dependencies, the high dimensionality of the data, andscalability constraints. These challenges are further amplified in scientificdomains, where data is often irregularly distributed (e.g., missing values fromsensor failures) and high-volume (e.g., high-fidelity simulations), posingadditional computational and modeling difficulties. In this paper, we presentSCENT, a novel framework for scalable and continuity-informed spatiotemporalrepresentation learning. SCENT unifies interpolation, reconstruction, andforecasting within a single architecture. Built on a transformer-basedencoder-processor-decoder backbone, SCENT introduces learnable queries toenhance generalization and a query-wise cross-attention mechanism toeffectively capture multi-scale dependencies. To ensure scalability in bothdata size and model complexity, we incorporate a sparse attention mechanism,enabling flexible output representations and efficient evaluation at arbitraryresolutions. We validate SCENT through extensive simulations and real-worldexperiments, demonstrating state-of-the-art performance across multiplechallenging tasks while achieving superior scalability.</description>
      <author>example@mail.com (David Keetae Park, Xihaier Luo, Guang Zhao, Seungjun Lee, Miruna Oprescu, Shinjae Yoo)</author>
      <guid isPermaLink="false">2504.12262v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
  <item>
      <title>FLIP Reasoning Challenge</title>
      <link>http://arxiv.org/abs/2504.12256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at First Workshop on Open Science for Foundation Models at  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了FLIP数据集，用于评估人工智能推理能力，并探讨了现有推理模型的局限性。&lt;h4&gt;背景&lt;/h4&gt;近年来，人工智能在感知和生成任务方面取得了显著进展，但在推理方面仍然面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出FLIP数据集，作为一个基于人类验证任务的基准，以评估AI的推理能力。&lt;h4&gt;方法&lt;/h4&gt;FLIP挑战要求用户从两组4张图片中识别出逻辑上连贯的一组，强调顺序推理、视觉叙事和常识。&lt;h4&gt;主要发现&lt;/h4&gt;即使是最先进的开源和闭源模型在零样本设置下的最大准确率也仅为75.5%和77.9%，而人类的表现为95.3%。图像字幕模型通过提供图像的文本描述来辅助推理模型，提高了准确率。结合15个模型的预测，准确率可提高至85.2%。&lt;h4&gt;结论&lt;/h4&gt;现有推理模型的局限性需要像FLIP这样的鲁棒的多模态基准。&lt;h4&gt;翻译&lt;/h4&gt;在过去的几年里，人工智能（AI）的进步展示了AI如何解决许多感知和生成任务，如图像分类和文本写作，但推理仍然是一个挑战。本文介绍了一个名为FLIP的数据集，它是一个基于人类在Idena区块链上进行的验证任务的AI推理能力基准。FLIP挑战向用户提供了两组4张图片的顺序，要求他们识别出逻辑上连贯的一组。通过强调顺序推理、视觉叙事和常识，FLIP为多模态AI系统提供了一个独特的测试平台。我们的实验评估了最先进的模型，利用了视觉语言模型（VLMs）和大型语言模型（LLMs）。结果表明，即使在零样本设置下，即使是最好的开源和闭源模型也仅达到75.5%和77.9%的最大准确率，而人类的准确率为95.3%。图像字幕模型通过提供图像的文本描述来辅助推理模型，比直接使用原始图像获得了更好的结果，Gemini 1.5Pro的准确率分别为69.6%和75.2%。结合15个模型的预测，准确率可提高至85.2%。这些发现突出了现有推理模型的局限性，以及像FLIP这样的鲁棒的多模态基准的需求。完整的代码库和数据集将在https://github.com/aplesner/FLIP-Reasoning-Challenge上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Over the past years, advances in artificial intelligence (AI) havedemonstrated how AI can solve many perception and generation tasks, such asimage classification and text writing, yet reasoning remains a challenge. Thispaper introduces the FLIP dataset, a benchmark for evaluating AI reasoningcapabilities based on human verification tasks on the Idena blockchain. FLIPchallenges present users with two orderings of 4 images, requiring them toidentify the logically coherent one. By emphasizing sequential reasoning,visual storytelling, and common sense, FLIP provides a unique testbed formultimodal AI systems. Our experiments evaluate state-of-the-art models,leveraging both vision-language models (VLMs) and large language models (LLMs).Results reveal that even the best open-sourced and closed-sourced modelsachieve maximum accuracies of 75.5% and 77.9%, respectively, in zero-shotsettings, compared to human performance of 95.3%. Captioning models aidreasoning models by providing text descriptions of images, yielding betterresults than when using the raw images directly, 69.6% vs. 75.2% for Gemini 1.5Pro. Combining the predictions from 15 models in an ensemble increases theaccuracy to 85.2%. These findings highlight the limitations of existingreasoning models and the need for robust multimodal benchmarks like FLIP. Thefull codebase and dataset will be available athttps://github.com/aplesner/FLIP-Reasoning-Challenge.</description>
      <author>example@mail.com (Andreas Plesner, Turlan Kuzhagaliyev, Roger Wattenhofer)</author>
      <guid isPermaLink="false">2504.12256v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Balancing Graph Embedding Smoothness in Self-Supervised Learning via Information-Theoretic Decomposition</title>
      <link>http://arxiv.org/abs/2504.12011v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the Web Conference (WWW) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图上的自监督学习（SSL），特别是在使用图神经网络（GNNs）和预处理任务方面的应用，如对比学习和特征重建。研究发现，现有方法在反映图的基本属性和邻居表示相似性方面存在差异，并提出了一种平衡图SSL中平滑性的新框架BSG，通过引入新的损失函数来提高SSL的表现。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在图上的应用引起了广泛关注，特别是在使用GNNs和预处理任务方面，如对比学习和特征重建。&lt;h4&gt;目的&lt;/h4&gt;探讨现有自监督学习方法是否有效反映图的基本属性，以及如何改进这些方法以提升表现。&lt;h4&gt;方法&lt;/h4&gt;通过信息论框架将SSL目标分解为三个部分，并提出了一种名为BSG的框架，该框架引入了新的损失函数来平衡这三个部分：邻居损失、最小损失和发散损失。&lt;h4&gt;主要发现&lt;/h4&gt;发现现有方法在反映图的基本属性和邻居表示相似性方面存在差异，并揭示了这种差异的原因是三个部分的不平衡。BSG框架能够平衡这些部分，从而在更广泛的下游任务中提高性能。&lt;h4&gt;结论&lt;/h4&gt;BSG框架通过引入新的损失函数平衡图SSL中的平滑性，实现了在节点分类和链接预测任务上的最佳性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates self-supervised learning (SSL) on graphs, particularly the application of Graph Neural Networks (GNNs) and pretext tasks initially designed for other domains, such as contrastive learning and feature reconstruction. It finds that existing methods differ in reflecting essential graph properties and neighbor representation similarity, and proposes a new framework called BSG to balance the smoothness in graph-based SSL by introducing new loss functions to improve the performance of SSL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714611&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) in graphs has garnered significant attention,particularly in employing Graph Neural Networks (GNNs) with pretext tasksinitially designed for other domains, such as contrastive learning and featurereconstruction. However, it remains uncertain whether these methods effectivelyreflect essential graph properties, precisely representation similarity withits neighbors. We observe that existing methods position opposite ends of aspectrum driven by the graph embedding smoothness, with each end correspondingto outperformance on specific downstream tasks. Decomposing the SSL objectiveinto three terms via an information-theoretic framework with a neighborrepresentation variable reveals that this polarization stems from an imbalanceamong the terms, which existing methods may not effectively maintain. Furtherinsights suggest that balancing between the extremes can lead to improvedperformance across a wider range of downstream tasks. A framework, BSG(Balancing Smoothness in Graph SSL), introduces novel loss functions designedto supplement the representation quality in graph-based SSL by balancing thederived three terms: neighbor loss, minimal loss, and divergence loss. Wepresent a theoretical analysis of the effects of these loss functions,highlighting their significance from both the SSL and graph smoothnessperspectives. Extensive experiments on multiple real-world datasets across nodeclassification and link prediction consistently demonstrate that BSG achievesstate-of-the-art performance, outperforming existing methods. Ourimplementation code is available at https://github.com/steve30572/BSG.</description>
      <author>example@mail.com (Heesoo Jung, Hogun Park)</author>
      <guid isPermaLink="false">2504.12011v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Correlation Ratio for Unsupervised Learning of Multi-modal Deformable Registration</title>
      <link>http://arxiv.org/abs/2504.12265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SPIE MI'25 ((c) SPIE). Code available at  https://github.com/junyuchen245/Correlation_Ratio&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于可微分的相关比率作为损失函数的多模态变形图像配准的深度学习方法。&lt;h4&gt;背景&lt;/h4&gt;近年来，无监督学习在变形图像配准方面成为研究热点。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以改进基于深度学习的多模态图像配准性能。&lt;h4&gt;方法&lt;/h4&gt;使用移动和固定图像对训练配准网络，并引入结合图像相似度测量和变形正则化的损失函数。使用帕累托窗函数近似扩展传统不可微分的相关比率实现，以便与深度神经网络配合进行反向传播。&lt;h4&gt;主要发现&lt;/h4&gt;提出的可微分相关比率在多模态神经影像数据集上进行了验证，并建立了一个贝叶斯训练框架来研究变形正则化器与相似度度量（包括互信息和所提出的相关比率）之间的权衡如何影响配准性能。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地提高了多模态图像配准的性能，并提供了新的见解来优化配准过程中的参数调整。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, unsupervised learning for deformable image registration hasbeen a major research focus. This approach involves training a registrationnetwork using pairs of moving and fixed images, along with a loss function thatcombines an image similarity measure and deformation regularization. Formulti-modal image registration tasks, the correlation ratio has been awidely-used image similarity measure historically, yet it has beenunderexplored in current deep learning methods. Here, we propose adifferentiable correlation ratio to use as a loss function for learning-basedmulti-modal deformable image registration. This approach extends thetraditionally non-differentiable implementation of the correlation ratio byusing the Parzen windowing approximation, enabling backpropagation with deepneural networks. We validated the proposed correlation ratio on a multi-modalneuroimaging dataset. In addition, we established a Bayesian training frameworkto study how the trade-off between the deformation regularizer and similaritymeasures, including mutual information and our proposed correlation ratio,affects the registration performance.</description>
      <author>example@mail.com (Xiaojian Chen, Yihao Liu, Shuwen Wei, Aaron Carass, Yong Du, Junyu Chen)</author>
      <guid isPermaLink="false">2504.12265v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>TacoDepth: Towards Efficient Radar-Camera Depth Estimation with One-stage Fusion</title>
      <link>http://arxiv.org/abs/2504.11773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025 (Oral Presentation)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TacoDepth的雷达-摄像头深度估计模型，旨在通过融合输入图像和雷达数据来预测密集和精确的度量深度。&lt;h4&gt;背景&lt;/h4&gt;雷达-摄像头深度估计对于自动驾驶车辆和机器人平台中的实时处理至关重要，但雷达回波稀疏性导致现有方法采用多阶段框架，效率低下且鲁棒性不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且准确的雷达-摄像头深度估计模型，以实现实时处理。&lt;h4&gt;方法&lt;/h4&gt;TacoDepth采用了一阶段融合，包括基于图的雷达结构提取器和基于金字塔的雷达融合模块，以捕获和整合雷达点云的图结构，从而提高模型效率和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;TacoDepth在深度准确性和处理速度上比现有最先进的方法提高了12.8%和91.8%，并且能够灵活适应不同的推理模式，在速度和精度之间提供更好的平衡。&lt;h4&gt;结论&lt;/h4&gt;TacoDepth为高效雷达-摄像头深度估计提供了一种新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radar-Camera depth estimation aims to predict dense and accurate metric depthby fusing input images and Radar data. Model efficiency is crucial for thistask in pursuit of real-time processing on autonomous vehicles and roboticplatforms. However, due to the sparsity of Radar returns, the prevailingmethods adopt multi-stage frameworks with intermediate quasi-dense depth, whichare time-consuming and not robust. To address these challenges, we proposeTacoDepth, an efficient and accurate Radar-Camera depth estimation model withone-stage fusion. Specifically, the graph-based Radar structure extractor andthe pyramid-based Radar fusion module are designed to capture and integrate thegraph structures of Radar point clouds, delivering superior model efficiencyand robustness without relying on the intermediate depth results. Moreover,TacoDepth can be flexible for different inference modes, providing a betterbalance of speed and accuracy. Extensive experiments are conducted todemonstrate the efficacy of our method. Compared with the previousstate-of-the-art approach, TacoDepth improves depth accuracy and processingspeed by 12.8% and 91.8%. Our work provides a new perspective on efficientRadar-Camera depth estimation.</description>
      <author>example@mail.com (Yiran Wang, Jiaqi Li, Chaoyi Hong, Ruibo Li, Liusheng Sun, Xiao Song, Zhe Wang, Zhiguo Cao, Guosheng Lin)</author>
      <guid isPermaLink="false">2504.11773v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>A Complex-valued SAR Foundation Model Based on Physically Inspired Representation Learning</title>
      <link>http://arxiv.org/abs/2504.11999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于复值合成孔径雷达（SAR）数据的遥感基础模型，用于SAR图像解释，解决了信息利用不足和可解释性差的问题。&lt;h4&gt;背景&lt;/h4&gt;遥感基础模型在下游任务中表现出优越的泛化能力，SAR提供了全天候、全天时的成像能力，对地球观测具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;建立能够有效利用信息并具有物理可解释性的SAR图像解释基础模型。&lt;h4&gt;方法&lt;/h4&gt;通过模拟极化分解过程进行预训练，将像素散射强度表示为散射基和散射系数的加权组合，构建了一系列散射查询，以与SAR特征交互并输出相应的散射系数。同时，设计了极化分解损失和功率自监督损失来指导预训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;该基础模型在六个典型下游任务上验证了其性能，实现了最先进的结果，能够提取稳定的特征表示，并在数据稀缺条件下表现出强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;提出的基础模型在SAR图像解释方面具有显著优势，为遥感领域提供了新的研究思路。&lt;h4&gt;翻译&lt;/h4&gt;Vision foundation models in remote sensing have been extensively studied due to their superior generalization on various downstream tasks. Synthetic Aperture Radar (SAR) offers all-day, all-weather imaging capabilities, providing significant advantages for Earth observation. However, establishing a foundation model for SAR image interpretation inevitably encounters the challenges of insufficient information utilization and poor interpretability. In this paper, we propose a remote sensing foundation model based on complex-valued SAR data, which simulates the polarimetric decomposition process for pre-training, i.e., characterizing pixel scattering intensity as a weighted combination of scattering bases and scattering coefficients, thereby endowing the foundation model with physical interpretability. Specifically, we construct a series of scattering queries, each representing an independent and meaningful scattering basis, which interact with SAR features in the scattering query decoder and output the corresponding scattering coefficient. To guide the pre-training process, polarimetric decomposition loss and power self-supervision loss are constructed. The former aligns the predicted coefficients with Yamaguchi coefficients, while the latter reconstructs power from the predicted coefficients and compares it to the input image's power. The performance of our foundation model is validated on six typical downstream tasks, achieving state-of-the-art results. Notably, the foundation model can extract stable feature representations and exhibits strong generalization, even in data-scarce conditions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models in remote sensing have been extensively studied dueto their superior generalization on various downstream tasks. SyntheticAperture Radar (SAR) offers all-day, all-weather imaging capabilities,providing significant advantages for Earth observation. However, establishing afoundation model for SAR image interpretation inevitably encounters thechallenges of insufficient information utilization and poor interpretability.In this paper, we propose a remote sensing foundation model based oncomplex-valued SAR data, which simulates the polarimetric decomposition processfor pre-training, i.e., characterizing pixel scattering intensity as a weightedcombination of scattering bases and scattering coefficients, thereby endowingthe foundation model with physical interpretability. Specifically, we constructa series of scattering queries, each representing an independent and meaningfulscattering basis, which interact with SAR features in the scattering querydecoder and output the corresponding scattering coefficient. To guide thepre-training process, polarimetric decomposition loss and powerself-supervision loss are constructed. The former aligns the predictedcoefficients with Yamaguchi coefficients, while the latter reconstructs powerfrom the predicted coefficients and compares it to the input image's power. Theperformance of our foundation model is validated on six typical downstreamtasks, achieving state-of-the-art results. Notably, the foundation model canextract stable feature representations and exhibits strong generalization, evenin data-scarce conditions.</description>
      <author>example@mail.com (Mengyu Wang, Hanbo Bi, Yingchao Feng, Linlin Xin, Shuo Gong, Tianqi Wang, Zhiyuan Yan, Peijin Wang, Wenhui Diao, Xian Sun)</author>
      <guid isPermaLink="false">2504.11999v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>CodingHomo: Bootstrapping Deep Homography With Video Coding</title>
      <link>http://arxiv.org/abs/2504.12165v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于视频编码的Homography估计新方法，通过利用视频中的运动矢量，提高了估计的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;Homography估计在计算机视觉中是一个基础任务，广泛应用于多个领域。深度学习在Homography估计方面的应用，尤其是无监督学习方法，已经取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;为了提高复杂运动情况下Homography的准确预测。&lt;h4&gt;方法&lt;/h4&gt;提出了CodingHomo，一个无监督的Homography估计框架，包括Mask-Guided Fusion（MGF）模块和Mask-Guided Homography Estimation（MGHE）模块，用于识别和利用运动矢量中的有益特征，并消除不希望的特征。&lt;h4&gt;主要发现&lt;/h4&gt;CodingHomo在无监督方法中表现优于现有技术，具有良好的鲁棒性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该方法通过视频编码和运动矢量的利用，为Homography估计提供了一种新的思路和解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Homography估计是计算机视觉中的一个基本任务，在多个领域有应用。近年来，深度学习在Homography估计方面的应用，尤其是无监督学习方法，已经取得了显著的进展。然而，在复杂运动情况下准确预测Homography仍然是一个挑战。为此，本研究提出了一种基于视频编码的新方法，通过利用视频中的内在运动矢量（MVs）来提高鲁棒性和泛化能力。本研究提出了CodingHomo，一个用于Homography估计的无监督框架。该框架具有一个Mask-Guided Fusion（MGF）模块，用于识别和利用MVs中的有益特征，从而提高Homography预测的准确性。此外，还提出了Mask-Guided Homography Estimation（MGHE）模块，用于在粗到细的Homography细化过程中消除不希望的特征。CodingHomo在无监督方法中优于现有技术，提供了良好的鲁棒性和泛化能力。代码和数据集可在以下链接找到：[GitHub](https://github.com/liuyike422/CodingHomo)&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TCSVT.2024.3418771&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Homography estimation is a fundamental task in computer vision withapplications in diverse fields. Recent advances in deep learning have improvedhomography estimation, particularly with unsupervised learning approaches,offering increased robustness and generalizability. However, accuratelypredicting homography, especially in complex motions, remains a challenge. Inresponse, this work introduces a novel method leveraging video coding,particularly by harnessing inherent motion vectors (MVs) present in videos. Wepresent CodingHomo, an unsupervised framework for homography estimation. Ourframework features a Mask-Guided Fusion (MGF) module that identifies andutilizes beneficial features among the MVs, thereby enhancing the accuracy ofhomography prediction. Additionally, the Mask-Guided Homography Estimation(MGHE) module is presented for eliminating undesired features in thecoarse-to-fine homography refinement process. CodingHomo outperforms existingstate-of-the-art unsupervised methods, delivering good robustness andgeneralizability. The code and dataset are available at:\href{github}{https://github.com/liuyike422/CodingHomo</description>
      <author>example@mail.com (Yike Liu, Haipeng Li, Shuaicheng Liu, Bing Zeng)</author>
      <guid isPermaLink="false">2504.12165v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>GrabS: Generative Embodied Agent for 3D Object Segmentation without Scene Supervision</title>
      <link>http://arxiv.org/abs/2504.11754v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025 Spotlight. Code and data are available at:  https://github.com/vLAR-group/GrabS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在复杂点云中进行3D物体分割的难题，提出了一种名为GrabS的两阶段流程，通过学习生成和判别性物体中心先验，并在第二阶段设计了一个具身智能体来发现多个物体，显著提升了分割性能。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督方法通常依赖于预训练的2D特征或外部信号，如运动，来分组3D点作为物体，但这些方法在识别简单物体时有限，且分割效果较差，因为缺乏物体性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无监督3D物体分割方法，以提高在复杂点云中的分割性能。&lt;h4&gt;方法&lt;/h4&gt; GrabS流程分为两个阶段：第一阶段学习生成和判别性物体中心先验；第二阶段设计具身智能体通过查询预训练的生成先验来学习发现多个物体。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界数据集和一个新创建的合成数据集上，GrabS方法展现了显著的分割性能，超越了所有现有的无监督方法。&lt;h4&gt;结论&lt;/h4&gt;GrabS方法通过学习物体中心先验和设计具身智能体，有效地解决了复杂点云中的3D物体分割问题，并显著提升了分割效果。&lt;h4&gt;翻译&lt;/h4&gt;We study the hard problem of 3D object segmentation in complex point clouds without requiring human labels of 3D scenes for supervision. By relying on the similarity of pretrained 2D features or external signals such as motion to group 3D points as objects, existing unsupervised methods are usually limited to identifying simple objects like cars or their segmented objects are often inferior due to the lack of objectness in pretrained features. In this paper, we propose a new two-stage pipeline called GrabS. The core concept of our method is to learn generative and discriminative object-centric priors as a foundation from object datasets in the first stage, and then design an embodied agent to learn to discover multiple objects by querying against the pretrained generative priors in the second stage. We extensively evaluate our method on two real-world datasets and a newly created synthetic dataset, demonstrating remarkable segmentation performance, clearly surpassing all existing unsupervised methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the hard problem of 3D object segmentation in complex point cloudswithout requiring human labels of 3D scenes for supervision. By relying on thesimilarity of pretrained 2D features or external signals such as motion togroup 3D points as objects, existing unsupervised methods are usually limitedto identifying simple objects like cars or their segmented objects are ofteninferior due to the lack of objectness in pretrained features. In this paper,we propose a new two-stage pipeline called GrabS. The core concept of ourmethod is to learn generative and discriminative object-centric priors as afoundation from object datasets in the first stage, and then design an embodiedagent to learn to discover multiple objects by querying against the pretrainedgenerative priors in the second stage. We extensively evaluate our method ontwo real-world datasets and a newly created synthetic dataset, demonstratingremarkable segmentation performance, clearly surpassing all existingunsupervised methods.</description>
      <author>example@mail.com (Zihui Zhang, Yafei Yang, Hongtao Wen, Bo Yang)</author>
      <guid isPermaLink="false">2504.11754v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Self-alignment of Large Video Language Models with Refined Regularized Preference Optimization</title>
      <link>http://arxiv.org/abs/2504.12083v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自对齐框架，帮助大型视频语言模型（LVLMs）从自身错误中学习，以解决LVLMs在细粒度时间理解、幻觉生成和简单视频问答任务中的错误问题。&lt;h4&gt;背景&lt;/h4&gt;尽管大型视频语言模型（LVLMs）近年来取得了进展，但它们在细粒度时间理解、幻觉生成和简单视频问答任务中仍然存在困难，这给它们在现实世界中的应用带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决LVLMs的这些局限性，提出了一种自对齐框架，使LVLMs能够从自己的错误中学习。&lt;h4&gt;方法&lt;/h4&gt;该框架首先获得一组首选和非首选响应对，其中非首选响应是通过结合常见的错误模式生成的，这些错误模式通常是由于时空理解不足、概念之间的虚假相关性、过度依赖语言线索而忽视视觉模态等引起的。为了促进LVLMs与构建的首选和非首选响应对的自对齐，引入了精细正则化偏好优化（RRPO），这是一种新的偏好优化方法，它使用子序列级别的精细奖励和基于标记的KL正则化来解决直接偏好优化（DPO）的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;实验和分析验证了该方法在包括视频幻觉、短视频和长视频理解以及细粒度时间推理在内的各种视频任务中的有效性，RRPO比DPO实现了更精确的对齐和更稳定的训练。&lt;h4&gt;结论&lt;/h4&gt;RRPO方法能够有效提升LVLMs的性能，使其在视频问答任务中更加可靠和安全。&lt;h4&gt;翻译&lt;/h4&gt;尽管大型视频语言模型（LVLMs）近年来取得了进展，但它们在细粒度时间理解、幻觉生成和简单视频问答任务中仍然存在困难，这给它们在现实世界中的应用带来了挑战。为了解决LVLMs的这些局限性，本文提出了一种自对齐框架，使LVLMs能够从自己的错误中学习。该框架首先获得一组首选和非首选响应对，其中非首选响应是通过结合常见的错误模式生成的，这些错误模式通常是由于时空理解不足、概念之间的虚假相关性、过度依赖语言线索而忽视视觉模态等引起的。为了促进LVLMs与构建的首选和非首选响应对的自对齐，引入了精细正则化偏好优化（RRPO），这是一种新的偏好优化方法，它使用子序列级别的精细奖励和基于标记的KL正则化来解决直接偏好优化（DPO）的局限性。实验和分析验证了该方法在包括视频幻觉、短视频和长视频理解以及细粒度时间推理在内的各种视频任务中的有效性，RRPO比DPO实现了更精确的对齐和更稳定的训练。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent advances in Large Video Language Models (LVLMs), they stillstruggle with fine-grained temporal understanding, hallucinate, and often makesimple mistakes on even simple video question-answering tasks, all of whichpose significant challenges to their safe and reliable deployment in real-worldapplications. To address these limitations, we propose a self-alignmentframework that enables LVLMs to learn from their own errors. Our proposedframework first obtains a training set of preferred and non-preferred responsepairs, where non-preferred responses are generated by incorporating commonerror patterns that often occur due to inadequate spatio-temporalunderstanding, spurious correlations between co-occurring concepts, andover-reliance on linguistic cues while neglecting the vision modality, amongothers. To facilitate self-alignment of LVLMs with the constructed preferredand non-preferred response pairs, we introduce Refined Regularized PreferenceOptimization (RRPO), a novel preference optimization method that utilizessub-sequence-level refined rewards and token-wise KL regularization to addressthe limitations of Direct Preference Optimization (DPO). We demonstrate thatRRPO achieves more precise alignment and more stable training compared to DPO.Our experiments and analysis validate the effectiveness of our approach acrossdiverse video tasks, including video hallucination, short- and long-videounderstanding, and fine-grained temporal reasoning.</description>
      <author>example@mail.com (Pritam Sarkar, Ali Etemad)</author>
      <guid isPermaLink="false">2504.12083v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>SALAD: Improving Robustness and Generalization through Contrastive Learning with Structure-Aware and LLM-Driven Augmented Data</title>
      <link>http://arxiv.org/abs/2504.12185v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NAACL 2025 main. 15 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SALAD的新方法，用于增强预训练语言模型的鲁棒性和泛化能力，通过生成结构感知和反事实增强的数据进行对比学习来解决NLP任务中的伪相关性问题。&lt;h4&gt;背景&lt;/h4&gt;在自然语言处理任务中，微调预训练语言模型时经常出现伪相关性问题，这会负面影响性能，尤其是在处理无分布数据时。&lt;h4&gt;目的&lt;/h4&gt;提出SALAD方法，旨在解决NLP任务中的伪相关性问题，提高模型的鲁棒性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;SALAD方法通过以下步骤实现：利用基于标记的方法生成结构感知的正面样本，并利用大型语言模型生成具有多样句式模式的反事实负面样本。通过对比学习，使模型专注于学习关键句子成分之间的结构关系，同时最小化对伪相关性的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;通过在情感分类、性别歧视检测和自然语言推理三个任务上的实验验证了SALAD方法的有效性，结果表明SALAD不仅提高了模型在不同环境下的鲁棒性和性能，还增强了模型对无分布数据集和跨域场景的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;SALAD方法能够有效提升预训练语言模型的鲁棒性和泛化能力，对于解决NLP任务中的伪相关性问题具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In various natural language processing (NLP) tasks, fine-tuning Pre-trainedLanguage Models (PLMs) often leads to the issue of spurious correlations, whichnegatively impacts performance, particularly when dealing without-of-distribution data. To address this problem, we propose SALAD}(StructureAware and LLM-driven Augmented Data), a novel approach designed to enhancemodel robustness and generalization by generating structure-aware andcounterfactually augmented data for contrastive learning. Our method leveragesa tagging-based approach to generate structure-aware positive samples andutilizes large language models (LLMs) to generate counterfactual negativesamples with diverse sentence patterns. By applying contrastive learning, SALADenables the model to focus on learning the structural relationships between keysentence components while minimizing reliance on spurious correlations. Wevalidate our approach through experiments on three tasks: SentimentClassification, Sexism Detection, and Natural Language Inference. The resultsdemonstrate that SALAD not only improves model robustness and performanceacross different environments but also enhances generalization toout-of-distribution datasets and cross-domain scenarios.</description>
      <author>example@mail.com (Suyoung Bae, Hyojun Kim, YunSeok Choi, Jee-Hyong Lee)</author>
      <guid isPermaLink="false">2504.12185v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*</title>
      <link>http://arxiv.org/abs/2504.11014v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9pages, 1 supple&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GATE3D的新型弱监督框架，旨在解决多领域数据集在单目3D物体检测中的训练挑战。&lt;h4&gt;背景&lt;/h4&gt;当前计算机视觉趋势强调开发能够同时处理多种不同任务的通用模型，这通常需要跨多领域数据集进行联合训练以确保有效的泛化。&lt;h4&gt;目的&lt;/h4&gt;解决单目3D物体检测在多领域训练中由于数据集标注3D地面实况标签稀缺而面临的独特挑战。&lt;h4&gt;方法&lt;/h4&gt;GATE3D通过利用2D和3D预测之间的一致性损失来有效弥合领域差距，并利用伪标签进行弱监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;GATE3D在KITTI基准数据集和自收集的室内办公数据集上实现了有竞争力的性能，显著加速了从有限标注数据中的学习过程。&lt;h4&gt;结论&lt;/h4&gt;GATE3D在机器人、增强现实和虚拟现实应用中具有广泛的潜在影响，特别是在从有限标注数据中学习方面表现突出。&lt;h4&gt;翻译&lt;/h4&gt;摘要：计算机视觉领域的最新趋势强调开发能够同时解决多种不同任务的通用模型。这种通用性通常需要跨多领域数据集进行联合训练以确保有效的泛化。然而，由于数据集标注3D地面实况标签稀缺，尤其是在典型的基于道路的自动驾驶环境之外，单目3D物体检测在多领域训练中面临着独特的挑战。为了应对这一挑战，我们引入了一种新颖的弱监督框架，利用伪标签。由于数据集固有的偏差，当前预训练模型往往难以在非道路环境中准确检测行人。与通用的基于图像的2D物体检测模型不同，在单目3D检测中实现类似的泛化仍然在很大程度上未被探索。在本文中，我们提出了一种名为GATE3D的新框架，专门用于通过弱监督进行通用的单目3D物体检测。GATE3D通过采用2D和3D预测之间的一致性损失来有效弥合领域差距。值得注意的是，我们的模型在KITTI基准数据集以及我们收集的用于评估我们框架泛化能力的室内办公数据集上实现了有竞争力的性能。我们的结果表明，GATE3D通过有效的预训练策略显著加速了从有限标注数据中的学习过程，突显了其在机器人、增强现实和虚拟现实应用中广泛的潜在影响。项目页面：https://ies0411.github.io/GATE3D/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emerging trend in computer vision emphasizes developing universal modelscapable of simultaneously addressing multiple diverse tasks. Such universalitytypically requires joint training across multi-domain datasets to ensureeffective generalization. However, monocular 3D object detection presentsunique challenges in multi-domain training due to the scarcity of datasetsannotated with accurate 3D ground-truth labels, especially beyond typicalroad-based autonomous driving contexts. To address this challenge, we introducea novel weakly supervised framework leveraging pseudo-labels. Currentpretrained models often struggle to accurately detect pedestrians in non-roadenvironments due to inherent dataset biases. Unlike generalized image-based 2Dobject detection models, achieving similar generalization in monocular 3Ddetection remains largely unexplored. In this paper, we propose GATE3D, a novelframework designed specifically for generalized monocular 3D object detectionvia weak supervision. GATE3D effectively bridges domain gaps by employingconsistency losses between 2D and 3D predictions. Remarkably, our modelachieves competitive performance on the KITTI benchmark as well as on anindoor-office dataset collected by us to evaluate the generalizationcapabilities of our framework. Our results demonstrate that GATE3Dsignificantly accelerates learning from limited annotated data througheffective pre-training strategies, highlighting substantial potential forbroader impacts in robotics, augmented reality, and virtual realityapplications. Project page: https://ies0411.github.io/GATE3D/</description>
      <author>example@mail.com (Eunsoo Im, Jung Kwon Lee, Changhyun Jee)</author>
      <guid isPermaLink="false">2504.11014v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>DC-SAM: In-Context Segment Anything in Images and Videos via Dual Consistency</title>
      <link>http://arxiv.org/abs/2504.12080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DC-SAM的新方法，用于在上下文中对图像和视频进行对象分割，并在视频分割领域构建了第一个基准IC-VOS。&lt;h4&gt;背景&lt;/h4&gt;在上下文分割中，使用单个标记示例对对象进行分割，称为少样本学习中的单次分割，用于测试分割模型的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出DC-SAM方法，以适应SAM和SAM2进行上下文分割，并评估模型在视频分割领域的性能。&lt;h4&gt;方法&lt;/h4&gt;DC-SAM通过提供高质量视觉提示来增强SAM的提示编码器特征，并在生成掩码之前融合SAM特征以更好地对齐提示编码器。此外，还设计了循环一致交叉注意力和双重分支设计，以及简单的mask-tube训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;DC-SAM在图像分割任务中取得了优异的性能，并在视频分割领域首次实现了有效的上下文分割。&lt;h4&gt;结论&lt;/h4&gt;DC-SAM方法在图像和视频分割任务中表现出色，并在提出的IC-VOS基准上取得了显著的效果。&lt;h4&gt;翻译&lt;/h4&gt;Given a single labeled example, in-context segmentation aims to segment corresponding objects. This setting, known as one-shot segmentation in few-shot learning, explores the segmentation model's generalization ability and has been applied to various vision tasks, including scene understanding and image/video editing. While recent Segment Anything Models have achieved state-of-the-art results in interactive segmentation, these approaches are not directly applicable to in-context segmentation. In this work, we propose the Dual Consistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2 for in-context segmentation of both images and videos. Our key insights are to enhance the features of the SAM's prompt encoder in segmentation by providing high-quality visual prompts. When generating a mask prior, we fuse the SAM features to better align the prompt encoder. Then, we design a cycle-consistent cross-attention on fused features and initial visual prompts. Next, a dual-branch design is provided by using the discriminative positive and negative prompts in the prompt encoder. Furthermore, we design a simple mask-tube training strategy to adopt our proposed dual consistency method into the mask tube. Although the proposed DC-SAM is primarily designed for images, it can be seamlessly extended to the video domain with the support of SAM2. Given the absence of in-context segmentation in the video domain, we manually curate and construct the first benchmark from existing video segmentation datasets, named In-Context Video Object Segmentation (IC-VOS), to better assess the in-context capability of the model. Extensive experiments demonstrate that our method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU on PASCAL-5i, and a J&amp;F score of 71.52 on the proposed IC-VOS benchmark. Our source code and benchmark are available at https://github.com/zaplm/DC-SAM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Given a single labeled example, in-context segmentation aims to segmentcorresponding objects. This setting, known as one-shot segmentation in few-shotlearning, explores the segmentation model's generalization ability and has beenapplied to various vision tasks, including scene understanding and image/videoediting. While recent Segment Anything Models have achieved state-of-the-artresults in interactive segmentation, these approaches are not directlyapplicable to in-context segmentation. In this work, we propose the DualConsistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2for in-context segmentation of both images and videos. Our key insights are toenhance the features of the SAM's prompt encoder in segmentation by providinghigh-quality visual prompts. When generating a mask prior, we fuse the SAMfeatures to better align the prompt encoder. Then, we design a cycle-consistentcross-attention on fused features and initial visual prompts. Next, adual-branch design is provided by using the discriminative positive andnegative prompts in the prompt encoder. Furthermore, we design a simplemask-tube training strategy to adopt our proposed dual consistency method intothe mask tube. Although the proposed DC-SAM is primarily designed for images,it can be seamlessly extended to the video domain with the support of SAM2.Given the absence of in-context segmentation in the video domain, we manuallycurate and construct the first benchmark from existing video segmentationdatasets, named In-Context Video Object Segmentation (IC-VOS), to better assessthe in-context capability of the model. Extensive experiments demonstrate thatour method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU onPASCAL-5i, and a J&amp;F score of 71.52 on the proposed IC-VOS benchmark. Oursource code and benchmark are available at https://github.com/zaplm/DC-SAM.</description>
      <author>example@mail.com (Mengshi Qi, Pengfei Zhu, Xiangtai Li, Xiaoyang Bi, Lu Qi, Huadong Ma, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2504.12080v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>A Graph-Based Reinforcement Learning Approach with Frontier Potential Based Reward for Safe Cluttered Environment Exploration</title>
      <link>http://arxiv.org/abs/2504.11907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures, submitted to the 2025 IEEE/RSJ International  Conference on Intelligent Robots and Systems (IROS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合图神经网络探索贪婪策略和安全性保护层的新型方法，用于在杂乱环境中进行自主探索，确保在未知随机障碍物附近的安全导航。&lt;h4&gt;背景&lt;/h4&gt;在杂乱环境中进行自主探索需要有效的探索策略，以避免与未知随机障碍物发生碰撞。&lt;h4&gt;目的&lt;/h4&gt;研究一种能够在杂乱环境中高效且安全地进行探索的方法。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络为基础的探索贪婪策略和安全性保护层，利用强化学习和近端策略优化算法进行网络训练，以最大化探索效率并减少安全性保护层的干预。同时，提出了一种奖励函数，该函数基于智能体与未探索区域的接近程度和到达这些区域的预期信息增益。&lt;h4&gt;主要发现&lt;/h4&gt;该方法结合了强化学习驱动的探索策略的适应性和显式安全机制确保的保证。&lt;h4&gt;结论&lt;/h4&gt;在模拟环境中的广泛评估表明，该方法能够实现杂乱环境中的高效和安全探索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous exploration of cluttered environments requires efficientexploration strategies that guarantee safety against potential collisions withunknown random obstacles. This paper presents a novel approach combining agraph neural network-based exploration greedy policy with a safety shield toensure safe navigation goal selection. The network is trained usingreinforcement learning and the proximal policy optimization algorithm tomaximize exploration efficiency while reducing the safety shield interventions.However, if the policy selects an infeasible action, the safety shieldintervenes to choose the best feasible alternative, ensuring systemconsistency. Moreover, this paper proposes a reward function that includes apotential field based on the agent's proximity to unexplored regions and theexpected information gain from reaching them. Overall, the approachinvestigated in this paper merges the benefits of the adaptability ofreinforcement learning-driven exploration policies and the guarantee ensured byexplicit safety mechanisms. Extensive evaluations in simulated environmentsdemonstrate that the approach enables efficient and safe exploration incluttered environments.</description>
      <author>example@mail.com (Gabriele Calzolari, Vidya Sumathy, Christoforos Kanellakis, George Nikolakopoulos)</author>
      <guid isPermaLink="false">2504.11907v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Search is All You Need for Few-shot Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.11895v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为VisionAD的简单邻近搜索框架，用于少量样本下的异常检测（FSAD），在单类和多类FSAD场景中均超越了现有方法。&lt;h4&gt;背景&lt;/h4&gt;在工业检测中，FSAD是一个关键但具有挑战性的任务，需要使用少量正常图像进行正常分布建模。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要复杂提示工程和大量手动调优的方法，用于FSAD。&lt;h4&gt;方法&lt;/h4&gt;VisionAD包括以下四个简单但关键的组件：可扩展的视觉基础模型提取通用和区分性特征；双重增强策略，包括支持增强和查询增强；多层特征集成以捕捉低频全局上下文和高频局部细节；以及一个类感知视觉记忆库，用于高效的多类检测。&lt;h4&gt;主要发现&lt;/h4&gt;在MVTec-AD、VisA和Real-IAD基准上的广泛评估表明，使用仅1个正常图像作为支持，VisionAD在图像级AUROC分数上分别达到97.4%、94.8%和70.8%，显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;VisionAD的无训练特性和卓越的少量样本能力使其在样本稀缺或获取成本高昂的实际情况中特别有吸引力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Few-shot anomaly detection (FSAD)已经成为工业检测中的一个关键且具有挑战性的任务，在这个任务中，必须仅使用少量正常图像来完成正常分布建模。尽管现有的方法通常采用结合语言和视觉模态的多模态基础模型进行提示引导的异常检测，但这些方法往往需要复杂的提示工程和大量的手动调优。在本文中，我们证明了一个简单的邻近搜索框架可以超越单类和多类FSAD场景中的最先进性能。我们提出的方法，VisionAD，由以下四个简单但关键的组件组成：（1）可扩展的视觉基础模型，提取通用和区分性特征；（2）双重增强策略——支持增强以提高特征匹配适应性，查询增强以解决单视图预测的疏漏；（3）多层特征集成，以最小的计算开销捕捉低频全局上下文和高频局部细节；（4）一个类感知视觉记忆库，实现高效的一对多多类检测。在MVTec-AD、VisA和Real-IAD基准上的广泛评估表明VisionAD的卓越性能。使用仅1个正常图像作为支持，我们的方法在图像级AUROC分数上分别达到97.4%、94.8%和70.8%，显著优于现有方法（分别高出1.6%、3.2%和1.4%）。VisionAD的无训练特性和卓越的少量样本能力使其在样本稀缺或获取成本高昂的实际情况中特别有吸引力。代码可在https://github.com/Qiqigeww/VisionAD上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot anomaly detection (FSAD) has emerged as a crucial yet challengingtask in industrial inspection, where normal distribution modeling must beaccomplished with only a few normal images. While existing approaches typicallyemploy multi-modal foundation models combining language and vision modalitiesfor prompt-guided anomaly detection, these methods often demand sophisticatedprompt engineering and extensive manual tuning. In this paper, we demonstratethat a straightforward nearest-neighbor search framework can surpassstate-of-the-art performance in both single-class and multi-class FSADscenarios. Our proposed method, VisionAD, consists of four simple yet essentialcomponents: (1) scalable vision foundation models that extract universal anddiscriminative features; (2) dual augmentation strategies - supportaugmentation to enhance feature matching adaptability and query augmentation toaddress the oversights of single-view prediction; (3) multi-layer featureintegration that captures both low-frequency global context and high-frequencylocal details with minimal computational overhead; and (4) a class-aware visualmemory bank enabling efficient one-for-all multi-class detection. Extensiveevaluations across MVTec-AD, VisA, and Real-IAD benchmarks demonstrateVisionAD's exceptional performance. Using only 1 normal images as support, ourmethod achieves remarkable image-level AUROC scores of 97.4%, 94.8%, and 70.8%respectively, outperforming current state-of-the-art approaches by significantmargins (+1.6%, +3.2%, and +1.4%). The training-free nature and superiorfew-shot capabilities of VisionAD make it particularly appealing for real-worldapplications where samples are scarce or expensive to obtain. Code is availableat https://github.com/Qiqigeww/VisionAD.</description>
      <author>example@mail.com (Qishan Wang, Jia Guo, Shuyong Gao, Haofen Wang, Li Xiong, Junjie Hu, Hanqi Guo, Wenqiang Zhang)</author>
      <guid isPermaLink="false">2504.11895v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>HyperSAT: Unsupervised Hypergraph Neural Networks for Weighted MaxSAT Problems</title>
      <link>http://arxiv.org/abs/2504.11885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HyperSAT的新型神经网络方法，用于解决加权MaxSAT问题，并通过实验证明其性能优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在解决布尔可满足性（SAT）和最大可满足性（MaxSAT）问题方面表现出色，但加权MaxSAT问题的GNN方法尚未得到充分发展。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的神经网络方法来解决加权MaxSAT问题。&lt;h4&gt;方法&lt;/h4&gt;HyperSAT采用无监督的超图神经网络模型，为加权MaxSAT实例设计了一种超图表示，并设计了一个交叉注意力机制以及共享表示约束损失函数，以捕捉超图中正负文字节点之间的逻辑交互。&lt;h4&gt;主要发现&lt;/h4&gt;在多个加权MaxSAT数据集上的实验表明，HyperSAT的性能优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;HyperSAT是一种有效的解决加权MaxSAT问题的神经网络方法，在逻辑交互捕捉方面具有优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have shown promising performance in solving bothBoolean satisfiability (SAT) and Maximum Satisfiability (MaxSAT) problems dueto their ability to efficiently model and capture the structural dependenciesbetween literals and clauses. However, GNN methods for solving Weighted MaxSATproblems remain underdeveloped. The challenges arise from the non-lineardependency and sensitive objective function, which are caused by thenon-uniform distribution of weights across clauses. In this paper, we presentHyperSAT, a novel neural approach that employs an unsupervised hypergraphneural network model to solve Weighted MaxSAT problems. We propose a hypergraphrepresentation for Weighted MaxSAT instances and design a cross-attentionmechanism along with a shared representation constraint loss function tocapture the logical interactions between positive and negative literal nodes inthe hypergraph. Extensive experiments on various Weighted MaxSAT datasetsdemonstrate that HyperSAT achieves better performance than state-of-the-artcompetitors.</description>
      <author>example@mail.com (Qiyue Chen, Shaolin Tan, Suixiang Gao, Jinhu Lü)</author>
      <guid isPermaLink="false">2504.11885v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Secure Transfer Learning: Training Clean Models Against Backdoor in (Both) Pre-trained Encoders and Downstream Datasets</title>
      <link>http://arxiv.org/abs/2504.11990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear at IEEE Symposium on Security and Privacy 2025, 20 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了在资源受限的迁移学习场景下如何减轻潜在的后门风险。&lt;h4&gt;背景&lt;/h4&gt;迁移学习在机器学习中变得至关重要，但预训练和下游自适应的结合扩大了攻击面，使模型容易受到复杂后门嵌入的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来减轻资源受限的迁移学习场景中的后门风险。&lt;h4&gt;方法&lt;/h4&gt;对现有的防御策略进行了彻底的分析，并引入了T-Core Bootstrapping框架，该框架侧重于识别干净元素。&lt;h4&gt;主要发现&lt;/h4&gt;许多现有的防御策略基于无法扩展到未知威胁、新型攻击类型或不同训练范式的假设。&lt;h4&gt;结论&lt;/h4&gt;T-Core框架在五个基准数据集上对5种编码器中毒攻击、7种数据集中毒攻击和14种基线防御进行了实证评估，证明了其在应对三种潜在后门威胁场景中的有效性和优越性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从预训练编码器中进行迁移学习在现代机器学习中变得至关重要，它使得模型能够高效地适应各种任务。然而，这种预训练和下游自适应的结合扩大了攻击面，使模型容易受到编码器和数据集级别的复杂后门嵌入的影响——这是先前研究中经常被忽视的一个领域。此外，预训练编码器用户通常可用的有限计算资源限制了通用后门防御的有效性，与从头开始端到端训练相比。在本工作中，我们研究了如何在资源受限的迁移学习场景中减轻潜在的后门风险。具体而言，我们对现有的防御策略进行了彻底的分析，发现许多策略遵循基于假设的被动工作流程，这些假设无法扩展到未知威胁、新型攻击类型或不同的训练范式。作为回应，我们引入了一种主动的心态，侧重于识别干净元素，并提出了T-Core Bootstrapping框架，该框架强调确定可信数据和神经元的重要性以增强模型的安全性。我们的实证评估证明了T-Core的有效性和优越性，特别是在五个基准数据集上对5种编码器中毒攻击、7种数据集中毒攻击和14种基线防御进行了评估，解决了三种潜在后门威胁的四种场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning from pre-trained encoders has become essential in modernmachine learning, enabling efficient model adaptation across diverse tasks.However, this combination of pre-training and downstream adaptation creates anexpanded attack surface, exposing models to sophisticated backdoor embeddingsat both the encoder and dataset levels--an area often overlooked in priorresearch. Additionally, the limited computational resources typically availableto users of pre-trained encoders constrain the effectiveness of genericbackdoor defenses compared to end-to-end training from scratch. In this work,we investigate how to mitigate potential backdoor risks in resource-constrainedtransfer learning scenarios. Specifically, we conduct an exhaustive analysis ofexisting defense strategies, revealing that many follow a reactive workflowbased on assumptions that do not scale to unknown threats, novel attack types,or different training paradigms. In response, we introduce a proactive mindsetfocused on identifying clean elements and propose the Trusted Core (T-Core)Bootstrapping framework, which emphasizes the importance of pinpointingtrustworthy data and neurons to enhance model security. Our empiricalevaluations demonstrate the effectiveness and superiority of T-Core,specifically assessing 5 encoder poisoning attacks, 7 dataset poisoningattacks, and 14 baseline defenses across five benchmark datasets, addressingfour scenarios of 3 potential backdoor threats.</description>
      <author>example@mail.com (Yechao Zhang, Yuxuan Zhou, Tianyu Li, Minghui Li, Shengshan Hu, Wei Luo, Leo Yu Zhang)</author>
      <guid isPermaLink="false">2504.11990v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Non-uniform Point Cloud Upsampling via Local Manifold Distribution</title>
      <link>http://arxiv.org/abs/2504.11701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于流形分布约束的点云上采样新方法，通过使用高斯函数的拟合能力，迭代优化高斯成分及其权重，提高处理稀疏和非均匀点云时的上采样质量。&lt;h4&gt;背景&lt;/h4&gt;现有的基于学习的点云上采样方法往往忽略了点云的内在数据分布特性，导致处理稀疏和非均匀点云时结果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的点云上采样方法，以解决现有方法在处理稀疏和非均匀点云时的不足。&lt;h4&gt;方法&lt;/h4&gt;使用高斯函数的拟合能力，通过网络迭代优化高斯成分及其权重，构建统一的统计流形对点云施加分布约束。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在处理稀疏和非均匀输入时，生成的密集点云质量更高，分布更均匀，优于现有的点云上采样技术。&lt;h4&gt;结论&lt;/h4&gt;该方法在处理稀疏和非均匀点云上采样方面具有显著优势，能够生成高质量的密集点云。&lt;h4&gt;翻译&lt;/h4&gt;An innovative approach to point cloud upsampling by imposing constraints from the perspective of manifold distributions, using the strong fitting capability of Gaussian functions to iteratively optimize Gaussian components and their weights, and constructing a unified statistical manifold to impose distribution constraints on the point cloud, which has been proven to generate higher-quality and more uniformly distributed dense point clouds compared to existing state-of-the-art techniques.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing learning-based point cloud upsampling methods often overlook theintrinsic data distribution charac?teristics of point clouds, leading tosuboptimal results when handling sparse and non-uniform point clouds. Wepropose a novel approach to point cloud upsampling by imposing constraints fromthe perspective of manifold distributions. Leveraging the strong fittingcapability of Gaussian functions, our method employs a network to iterativelyoptimize Gaussian components and their weights, accurately representing localmanifolds. By utilizing the probabilistic distribution properties of Gaussianfunctions, we construct a unified statistical manifold to impose distributionconstraints on the point cloud. Experimental results on multiple datasetsdemonstrate that our method generates higher-quality and more uniformlydistributed dense point clouds when processing sparse and non-uniform inputs,outperforming state-of-the-art point cloud upsampling techniques.</description>
      <author>example@mail.com (Yaohui Fang, Xingce Wang)</author>
      <guid isPermaLink="false">2504.11701v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Federated Spectral Graph Transformers Meet Neural Ordinary Differential Equations for Non-IID Graphs</title>
      <link>http://arxiv.org/abs/2504.11808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first two listed authors contributed equally to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于谱图神经网络（GNN）和神经常微分方程（ODE）的新型联邦学习方法，用于解决GNN训练中数据隐私和可扩展性问题。&lt;h4&gt;背景&lt;/h4&gt;由于隐私、监管和商业竞争等原因，集中化大量现实世界图数据进行GNN训练是不切实际的。&lt;h4&gt;目的&lt;/h4&gt;提出一种联邦学习方法，在保持数据隐私的同时，实现GNN的训练。&lt;h4&gt;方法&lt;/h4&gt;该方法使用谱GNN并配备ODE以更好地捕捉信息，有效处理非独立同分布（non-IID）数据，同时性能可与仅操作于独立同分布（IID）数据的现有方法相媲美。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在同质和异质图上均显示出良好的结果，尤其是在非IID异质图上的联邦学习方面取得了显著的改进。&lt;h4&gt;结论&lt;/h4&gt;该研究突出了联邦学习在多样化和具有挑战性的图环境中的潜力，并提供了开源代码。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Network (GNN) 研究由于 GNN 能够从图结构数据中学习分布式表示而迅速发展。然而，由于隐私关注、监管限制和商业竞争，集中大量现实世界图数据用于 GNN 训练往往是不切实际的。联邦学习 (FL)，一种分布式学习范式，通过协作模型训练保留数据隐私，提供了一个解决方案。尽管在训练大型视觉和语言模型方面取得了进展，但 GNN 的联邦学习仍然未得到充分探索。为了应对这一挑战，我们提出了一种基于谱 GNN 并配备神经常微分方程 (ODE) 的新型联邦学习方法，以更好地捕捉信息，在同质和异质图上显示出有希望的结果。我们的方法有效地处理了非独立同分布（non-IID）数据，同时实现了与仅操作于独立同分布（IID）数据的现有方法相当的性能。它被设计为保护隐私和优化带宽，使其适用于涉及复杂、非 IID 和异质图结构的社会网络分析、推荐系统和欺诈检测等现实世界应用。我们在非 IID 异质图上的联邦学习领域的结果表明了显著的改进，同时在同质图上也实现了更好的性能。这项工作突出了联邦学习在多样化和具有挑战性的图环境中的潜力。GitHub 上有开源代码（https://github.com/SpringWiz11/Fed-GNODEFormer）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Network (GNN) research is rapidly advancing due to GNNs'capacity to learn distributed representations from graph-structured data.However, centralizing large volumes of real-world graph data for GNN trainingis often impractical due to privacy concerns, regulatory restrictions, andcommercial competition. Federated learning (FL), a distributed learningparadigm, offers a solution by preserving data privacy with collaborative modeltraining. Despite progress in training huge vision and language models,federated learning for GNNs remains underexplored. To address this challenge,we present a novel method for federated learning on GNNs based on spectral GNNsequipped with neural ordinary differential equations (ODE) for betterinformation capture, showing promising results across both homophilic andheterophilic graphs. Our approach effectively handles non-Independent andIdentically Distributed (non-IID) data, while also achieving performancecomparable to existing methods that only operate on IID data. It is designed tobe privacy-preserving and bandwidth-optimized, making it suitable forreal-world applications such as social network analysis, recommendationsystems, and fraud detection, which often involve complex, non-IID, andheterophilic graph structures. Our results in the area of federated learning onnon-IID heterophilic graphs demonstrate significant improvements, while alsoachieving better performance on homophilic graphs. This work highlights thepotential of federated learning in diverse and challenging graph settings.Open-source code available on GitHub(https://github.com/SpringWiz11/Fed-GNODEFormer).</description>
      <author>example@mail.com (Kishan Gurumurthy, Himanshu Pal, Charu Sharma)</author>
      <guid isPermaLink="false">2504.11808v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>FedEPA: Enhancing Personalization and Modality Alignment in Multimodal Federated Learning</title>
      <link>http://arxiv.org/abs/2504.12025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FedEPA的联邦学习框架，用于多模态学习，以解决现有FL系统对单模态数据假设和数据标签不足的问题。&lt;h4&gt;背景&lt;/h4&gt;大多数FL系统假设客户端仅持有单模态数据，且缺乏标签数据，这限制了它们在实际中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出FedEPA框架，旨在解决多模态数据和标签数据不足的问题，以提高多模态学习的效果。&lt;h4&gt;方法&lt;/h4&gt;FedEPA采用个性化的局部模型聚合策略，利用客户端上的标签数据学习个性化的聚合权重，以缓解数据异质性的影响。同时，提出了一种无监督的模态对齐策略，将多模态特征分解为对齐特征和上下文特征，并通过对比学习实现跨模态特征的对齐，确保对齐特征与上下文特征在每个模态中的独立性，并促进上下文特征的多样性。此外，引入了一种多模态特征融合策略以获得联合嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在有限的标签数据条件下，FedEPA在多模态分类任务中的性能显著优于现有的FL方法。&lt;h4&gt;结论&lt;/h4&gt;FedEPA框架在处理多模态学习和标签数据不足的问题上具有显著优势，能够有效提升多模态分类任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;Federated Learning (FL) enables decentralized model training across multiple parties while preserving privacy. However, most FL systems assume clients hold only unimodal data, limiting their real-world applicability, as institutions often possess multimodal data. Moreover, the lack of labeled data further constrains the performance of most FL methods. In this work, we propose FedEPA, a novel FL framework for multimodal learning. FedEPA employs a personalized local model aggregation strategy that leverages labeled data on clients to learn personalized aggregation weights, thereby alleviating the impact of data heterogeneity. We also propose an unsupervised modality alignment strategy that works effectively with limited labeled data. Specifically, we decompose multimodal features into aligned features and context features. We then employ contrastive learning to align the aligned features across modalities, ensure the independence between aligned features and context features within each modality, and promote the diversity of context features. A multimodal feature fusion strategy is introduced to obtain a joint embedding. The experimental results show that FedEPA significantly outperforms existing FL methods in multimodal classification tasks under limited labeled data conditions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Learning (FL) enables decentralized model training across multipleparties while preserving privacy. However, most FL systems assume clients holdonly unimodal data, limiting their real-world applicability, as institutionsoften possess multimodal data. Moreover, the lack of labeled data furtherconstrains the performance of most FL methods. In this work, we propose FedEPA,a novel FL framework for multimodal learning. FedEPA employs a personalizedlocal model aggregation strategy that leverages labeled data on clients tolearn personalized aggregation weights, thereby alleviating the impact of dataheterogeneity. We also propose an unsupervised modality alignment strategy thatworks effectively with limited labeled data. Specifically, we decomposemultimodal features into aligned features and context features. We then employcontrastive learning to align the aligned features across modalities, ensurethe independence between aligned features and context features within eachmodality, and promote the diversity of context features. A multimodal featurefusion strategy is introduced to obtain a joint embedding. The experimentalresults show that FedEPA significantly outperforms existing FL methods inmultimodal classification tasks under limited labeled data conditions.</description>
      <author>example@mail.com (Yu Zhang, Qingfeng Du, Jiaqi Lv)</author>
      <guid isPermaLink="false">2504.12025v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Spatio-temporal Graph Learning for Alignment-free RGBT Video Object Detection</title>
      <link>http://arxiv.org/abs/2504.11779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MSGNet的新型多模态时空图学习网络，用于无对齐RGB-T视频目标检测问题，通过利用鲁棒的图表示学习模型，解决了传统RGB-T融合任务中依赖手动对齐多模态图像对的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的RGB视频目标检测在复杂光照条件下存在局限性，而RGB-T视频目标检测可以解决这个问题，使其在实际应用中更加实用和有效。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需对齐的RGB-T视频目标检测方法，以提高检测的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;1. 设计自适应分区层（APL）来估计热图像在RGB图像中的对应区域，实现初步的不精确对齐。2. 引入空间稀疏图学习模块（S-SGLM），在估计的不精确对齐上采用稀疏信息传递机制，以实现不同模态之间的可靠信息交互。3. 为了充分利用时间线索，引入混合结构时间建模（HSTM），包括时间稀疏图学习模块（T-SGLM）和时间星块（TSB）。T-SGLM通过在时间图上采用稀疏聚合机制来过滤相邻帧之间的冗余信息。TSB致力于实现局部空间关系的互补学习。&lt;h4&gt;主要发现&lt;/h4&gt;在VT-VOD50对齐数据集和UVT-VOD2024非对齐数据集上进行的广泛比较实验证明了所提出方法的有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在RGB-T视频目标检测任务中表现出色，将免费公开于网站供公众访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; RGB-Thermal Video Object Detection (RGBT VOD) can address the limitation oftraditional RGB-based VOD in challenging lighting conditions, making it morepractical and effective in many applications.  However, similar to most RGBT fusion tasks, it still mainly relies onmanually aligned multimodal image pairs.  In this paper, we propose a novel Multimodal Spatio-temporal Graph learningNetwork (MSGNet) for alignment-free RGBT VOD problem by leveraging the robustgraph representation learning model.  Specifically, we first design an Adaptive Partitioning Layer (APL) toestimate the corresponding regions of the Thermal image within the RGB image(high-resolution), achieving a preliminary inexact alignment.  Then, we introduce the Spatial Sparse Graph Learning Module (S-SGLM) whichemploys a sparse information passing mechanism on the estimated inexactalignment to achieve reliable information interaction between differentmodalities.  Moreover, to fully exploit the temporal cues for RGBT VOD problem, weintroduce Hybrid Structured Temporal Modeling (HSTM), which involves a TemporalSparse Graph Learning Module (T-SGLM) and Temporal Star Block (TSB). T-SGLMaims to filter out some redundant information between adjacent frames byemploying the sparse aggregation mechanism on the temporal graph. Meanwhile,TSB is dedicated to achieving the complementary learning of local spatialrelationships.  Extensive comparative experiments conducted on both the aligned datasetVT-VOD50 and the unaligned dataset UVT-VOD2024 demonstrate the effectivenessand superiority of our proposed method. Our project will be made available onour website for free public access.</description>
      <author>example@mail.com (Qishun Wang, Zhengzheng Tu, Chenglong Li, Bo Jiang)</author>
      <guid isPermaLink="false">2504.11779v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>CAGS: Open-Vocabulary 3D Scene Understanding with Context-Aware Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2504.11893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Context-Aware Gaussian Splatting (CAGS)的新框架，用于解决开放词汇3D场景理解中的跨视图粒度不一致性问题，通过引入空间上下文信息，提高了3D实例分割的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;开放词汇3D场景理解对于需要自然语言驱动的空间解释的应用至关重要，如机器人和增强现实。3D Gaussian Splatting (3DGS) 提供了一种强大的场景重建表示方法，但其与开放词汇框架的结合面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出CAGS框架，以解决3DGS在开放词汇框架中遇到的关键挑战：跨视图粒度不一致性。&lt;h4&gt;方法&lt;/h4&gt;CAGS通过以下方式解决挑战：构建局部图传播上下文特征、采用以掩码为中心的对比学习平滑来自SAM的特征、利用预计算策略减少计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;CAGS显著提高了3D实例分割的准确性，并减少了在LERF-OVS和ScanNet等数据集上的碎片化错误。&lt;h4&gt;结论&lt;/h4&gt;通过整合空间上下文，CAGS实现了鲁棒的基于语言的3D场景理解。&lt;h4&gt;翻译&lt;/h4&gt;Open-vocabulary 3D scene understanding is crucial for applications requiring natural language-driven spatial interpretation, such as robotics and augmented reality. While 3D Gaussian Splatting (3DGS) offers a powerful representation for scene reconstruction, integrating it with open-vocabulary frameworks reveals a key challenge: cross-view granularity inconsistency. This issue, stemming from 2D segmentation methods like SAM, results in inconsistent object segmentations across views (e.g., a 'coffee set' segmented as a single entity in one view but as 'cup + coffee + spoon' in another). Existing 3DGS-based methods often rely on isolated per-Gaussian feature learning, neglecting the spatial context needed for cohesive object reasoning, leading to fragmented representations. We propose Context-Aware Gaussian Splatting (CAGS), a novel framework that addresses this challenge by incorporating spatial context into 3DGS. CAGS constructs local graphs to propagate contextual features across Gaussians, reduces noise from inconsistent granularity, employs mask-centric contrastive learning to smooth SAM-derived features across views, and leverages a precomputation strategy to reduce computational cost by precomputing neighborhood relationships, enabling efficient training in large-scale scenes. By integrating spatial context, CAGS significantly improves 3D instance segmentation and reduces fragmentation errors on datasets like LERF-OVS and ScanNet, enabling robust language-guided 3D scene understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary 3D scene understanding is crucial for applications requiringnatural language-driven spatial interpretation, such as robotics and augmentedreality. While 3D Gaussian Splatting (3DGS) offers a powerful representationfor scene reconstruction, integrating it with open-vocabulary frameworksreveals a key challenge: cross-view granularity inconsistency. This issue,stemming from 2D segmentation methods like SAM, results in inconsistent objectsegmentations across views (e.g., a "coffee set" segmented as a single entityin one view but as "cup + coffee + spoon" in another). Existing 3DGS-basedmethods often rely on isolated per-Gaussian feature learning, neglecting thespatial context needed for cohesive object reasoning, leading to fragmentedrepresentations. We propose Context-Aware Gaussian Splatting (CAGS), a novelframework that addresses this challenge by incorporating spatial context into3DGS. CAGS constructs local graphs to propagate contextual features acrossGaussians, reducing noise from inconsistent granularity, employs mask-centriccontrastive learning to smooth SAM-derived features across views, and leveragesa precomputation strategy to reduce computational cost by precomputingneighborhood relationships, enabling efficient training in large-scale scenes.By integrating spatial context, CAGS significantly improves 3D instancesegmentation and reduces fragmentation errors on datasets like LERF-OVS andScanNet, enabling robust language-guided 3D scene understanding.</description>
      <author>example@mail.com (Wei Sun, Yanzhao Zhou, Jianbin Jiao, Yuan Li)</author>
      <guid isPermaLink="false">2504.11893v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>GT-SVQ: A Linear-Time Graph Transformer for Node Classification Using Spiking Vector Quantization</title>
      <link>http://arxiv.org/abs/2504.11840v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于脉冲神经网络（SNN）的线性时间图变换器（GT-SVQ），用于节点分类，旨在解决传统图变换器（GTs）在处理大规模图时的复杂性和能耗问题。&lt;h4&gt;背景&lt;/h4&gt;图变换器（GTs）在图预测任务中表现出色，但其在处理大规模图时存在复杂度和能耗问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的图变换器方法，以降低计算和存储开销，提高节点分类的效率。&lt;h4&gt;方法&lt;/h4&gt;GT-SVQ通过脉冲神经元输出重构码本，并将码本注入自注意力块中，以线性复杂度聚合全局信息。此外，脉冲向量量化（SVQ）有效缓解了码本崩溃和依赖复杂机制的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GT-SVQ在大多数数据集上取得了与最先进基准相当的性能，同时比其他GTs快130倍。&lt;h4&gt;结论&lt;/h4&gt;GT-SVQ是一种有效的节点分类方法，能够显著提高计算效率，适用于大规模图处理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs), which simultaneously integrate message-passing andself-attention mechanisms, have achieved promising empirical results in somegraph prediction tasks. Although these approaches show the potential ofTransformers in capturing long-range graph topology information, issuesconcerning the quadratic complexity and high computing energy consumptionseverely limit the scalability of GTs on large-scale graphs. Recently, asbrain-inspired neural networks, Spiking Neural Networks (SNNs), facilitate thedevelopment of graph representation learning methods with lower computationaland storage overhead through the unique event-driven spiking neurons. Inspiredby these characteristics, we propose a linear-time Graph Transformer usingSpiking Vector Quantization (GT-SVQ) for node classification. GT-SVQreconstructs codebooks based on rate coding outputs from spiking neurons, andinjects the codebooks into self-attention blocks to aggregate globalinformation in linear complexity. Besides, spiking vector quantizationeffectively alleviates codebook collapse and the reliance on complex machinery(distance measure, auxiliary loss, etc.) present in previous vectorquantization-based graph learning methods. In experiments, we compare GT-SVQwith other state-of-the-art baselines on node classification datasets rangingfrom small to large. Experimental results show that GT-SVQ has achievedcompetitive performances on most datasets while maintaining up to 130x fasterinference speed compared to other GTs.</description>
      <author>example@mail.com (Huizhe Zhang, Jintang Li, Yuchang Zhu, Liang Chen, Zibin Zheng)</author>
      <guid isPermaLink="false">2504.11840v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians</title>
      <link>http://arxiv.org/abs/2504.11218v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first large-scale 3D Gaussians Affordance Reasoning Benchmark&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D高斯散布（3DGS）的3D affordance reasoning方法，并构建了首个大规模多模态数据集3DAffordSplat，同时引入了AffordSplatNet模型，提高了affordance recognition的准确性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;3D affordance reasoning对于将人类指令与3D物体的功能区域关联起来至关重要，但现有方法依赖于稀疏的3D点云，存在泛化性和鲁棒性不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出3DAffordSplat数据集和AffordSplatNet模型，以克服现有方法的局限性，提高affordance recognition的准确性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;构建了包含23,677个高斯实例、8,354个点云实例和6,631个手动标注的affordance标签的大规模数据集3DAffordSplat。基于此数据集，设计了AffordSplatNet模型，该模型具有创新的跨模态结构对齐模块，用于对齐3D点云和3DGS表示。&lt;h4&gt;主要发现&lt;/h4&gt;3DAffordSplat数据集显著推进了3DGS领域的affordance学习，AffordSplatNet在已见和未见场景下均优于现有方法，显示出其强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;3DGS在affordance reasoning中具有巨大潜力，通过构建大规模数据集和设计特定模型，可以显著提高affordance recognition的准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D affordance reasoning is essential in associating human instructions withthe functional regions of 3D objects, facilitating precise, task-orientedmanipulations in embodied AI. However, current methods, which predominantlydepend on sparse 3D point clouds, exhibit limited generalizability androbustness due to their sensitivity to coordinate variations and the inherentsparsity of the data. By contrast, 3D Gaussian Splatting (3DGS) delivershigh-fidelity, real-time rendering with minimal computational overhead byrepresenting scenes as dense, continuous distributions. This positions 3DGS asa highly effective approach for capturing fine-grained affordance details andimproving recognition accuracy. Nevertheless, its full potential remainslargely untapped due to the absence of large-scale, 3DGS-specific affordancedatasets. To overcome these limitations, we present 3DAffordSplat, the firstlarge-scale, multi-modal dataset tailored for 3DGS-based affordance reasoning.This dataset includes 23,677 Gaussian instances, 8,354 point cloud instances,and 6,631 manually annotated affordance labels, encompassing 21 objectcategories and 18 affordance types. Building upon this dataset, we introduceAffordSplatNet, a novel model specifically designed for affordance reasoningusing 3DGS representations. AffordSplatNet features an innovative cross-modalstructure alignment module that exploits structural consistency priors to align3D point cloud and 3DGS representations, resulting in enhanced affordancerecognition accuracy. Extensive experiments demonstrate that the 3DAffordSplatdataset significantly advances affordance learning within the 3DGS domain,while AffordSplatNet consistently outperforms existing methods across both seenand unseen settings, highlighting its robust generalization capabilities.</description>
      <author>example@mail.com (Zeming Wei, Junyi Lin, Yang Liu, Weixing Chen, Jingzhou Luo, Guanbin Li, Liang Lin)</author>
      <guid isPermaLink="false">2504.11218v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Multi-View Stereo with Depth Foundation Model in the Absence of Real-World Labels</title>
      <link>http://arxiv.org/abs/2504.11845v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度基础模型的多视图立体（MVS）方法DFM-MVS，用于在缺乏真实世界标签的情况下训练网络，并显著提升了MVS的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于学习的MVS方法取得了显著进展，但如何在没有真实世界标签的情况下有效地训练网络仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的方法，利用深度基础模型生成有效的深度先验，以在没有真实世界标签的情况下提升MVS的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于深度先验的伪监督训练机制，用于模拟真实的立体对应关系，从而为MVS网络构建有效的监督。此外，还提出了一种基于深度先验的误差校正策略，以减轻粗到细网络结构中固有的误差传播问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的DFM-MVS在DTU和Tanks &amp; Temples数据集上显著优于现有的MVS方法，且无需使用真实世界标签。&lt;h4&gt;结论&lt;/h4&gt;DFM-MVS是一种有效的MVS方法，可以在没有真实世界标签的情况下显著提升MVS的性能。&lt;h4&gt;翻译&lt;/h4&gt;Based on the recent advancements of vision foundation models, this paper proposes a novel method named DFM-MVS to leverage the depth foundation model to generate effective depth prior, so as to enhance the performance of MVS in the absence of real-world labels. Specifically, a depth prior-based pseudo-supervised training mechanism is developed to simulate realistic stereo correspondences using the generated depth prior, thereby constructing effective supervision for the MVS network. Besides, a depth prior-guided error correction strategy is presented to leverage the depth prior as guidance to mitigate the error propagation problem inherent in the widely-used coarse-to-fine network structure. Experimental results on DTU and Tanks &amp; Temples datasets demonstrate that the proposed DFM-MVS significantly outperforms existing MVS methods without using real-world labels.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning-based Multi-View Stereo (MVS) methods have made remarkable progressin recent years. However, how to effectively train the network without usingreal-world labels remains a challenging problem. In this paper, driven by therecent advancements of vision foundation models, a novel method termed DFM-MVS,is proposed to leverage the depth foundation model to generate the effectivedepth prior, so as to boost MVS in the absence of real-world labels.Specifically, a depth prior-based pseudo-supervised training mechanism isdeveloped to simulate realistic stereo correspondences using the generateddepth prior, thereby constructing effective supervision for the MVS network.Besides, a depth prior-guided error correction strategy is presented toleverage the depth prior as guidance to mitigate the error propagation probleminherent in the widely-used coarse-to-fine network structure. Experimentalresults on DTU and Tanks &amp; Temples datasets demonstrate that the proposedDFM-MVS significantly outperforms existing MVS methods without using real-worldlabels.</description>
      <author>example@mail.com (Jie Zhu, Bo Peng, Zhe Zhang, Bingzheng Liu, Jianjun Lei)</author>
      <guid isPermaLink="false">2504.11845v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Towards a Universal Vibration Analysis Dataset: A Framework for Transfer Learning in Predictive Maintenance and Structural Health Monitoring</title>
      <link>http://arxiv.org/abs/2504.11581v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于振动分析的通用数据集框架，旨在通过预训练和微调提高模型性能，并推动预测维护、结构健康监测等领域的发展。&lt;h4&gt;背景&lt;/h4&gt;ImageNet在迁移学习方面取得了成功，但振动分析领域缺乏类似的大型标注数据集。&lt;h4&gt;目的&lt;/h4&gt;创建一个适用于振动分析的大规模、标注数据集，以促进振动分析领域的发展。&lt;h4&gt;方法&lt;/h4&gt;提出的数据集框架以轴承振动数据为基础，收集了来自多个公开数据集的振动信号。使用深度学习架构进行实验，展示在预训练和微调后的模型性能提升。&lt;h4&gt;主要发现&lt;/h4&gt;使用预训练和微调的模型在轴承振动数据集上表现出色，这表明该框架在振动分析领域具有与ImageNet在视觉计算领域相似的潜力。&lt;h4&gt;结论&lt;/h4&gt;该数据集有望标准化振动数据预处理、特征提取和模型训练的方法，加速预测维护、结构健康监测等领域的研究进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：ImageNet已经成为迁移学习的一个可靠资源，它使得开发高效的机器学习模型成为可能，减少了训练时间和数据需求。然而，在预测维护、结构健康监测和故障诊断中的振动分析，缺乏一个类似的大型、标注数据集来促进类似的进步。为了解决这个问题，提出了一种数据集框架，它从轴承振动数据作为创建适用于所有机械的基于振动频谱分析通用数据集的第一步。该初始框架包括来自多个公开数据集的轴承振动信号的集合。为了证明该框架的优势，使用深度学习架构进行了实验，显示在预训练于轴承振动数据并微调于较小的特定领域数据集时，模型性能得到了提高。这些发现突出了在振动分析领域与ImageNet在视觉计算领域成功并驾齐驱的潜力。对于未来的工作，这项研究将包括来自多种类型机械的更广泛的振动信号，强调基于频谱的数据表示。每个样本将根据机械类型、操作状态以及故障的存在或类型进行标记，确保其用于监督和无监督学习任务的实用性。此外，将开发一个专门针对振动数据的数据预处理、特征提取和模型训练框架。这个框架将标准化研究社区的方法，允许合作并加速预测维护、结构健康监测和相关领域的研究进展。通过模仿ImageNet在视觉计算中的成功，这个数据集有望改善工业应用中智能系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; ImageNet has become a reputable resource for transfer learning, allowing thedevelopment of efficient ML models with reduced training time and datarequirements. However, vibration analysis in predictive maintenance, structuralhealth monitoring, and fault diagnosis, lacks a comparable large-scale,annotated dataset to facilitate similar advancements. To address this, adataset framework is proposed that begins with bearing vibration data as aninitial step towards creating a universal dataset for vibration-basedspectrogram analysis for all machinery. The initial framework includes acollection of bearing vibration signals from various publicly availabledatasets. To demonstrate the advantages of this framework, experiments wereconducted using a deep learning architecture, showing improvements in modelperformance when pre-trained on bearing vibration data and fine-tuned on asmaller, domain-specific dataset. These findings highlight the potential toparallel the success of ImageNet in visual computing but for vibrationanalysis. For future work, this research will include a broader range ofvibration signals from multiple types of machinery, emphasizingspectrogram-based representations of the data. Each sample will be labeledaccording to machinery type, operational status, and the presence or type offaults, ensuring its utility for supervised and unsupervised learning tasks.Additionally, a framework for data preprocessing, feature extraction, and modeltraining specific to vibration data will be developed. This framework willstandardize methodologies across the research community, allowing forcollaboration and accelerating progress in predictive maintenance, structuralhealth monitoring, and related fields. By mirroring the success of ImageNet invisual computing, this dataset has the potential to improve the development ofintelligent systems in industrial applications.</description>
      <author>example@mail.com (Mert Sehri, Igor Varejão, Zehui Hua, Vitor Bonella, Adriano Santos, Francisco de Assis Boldt, Patrick Dumond, Flavio Miguel Varejão)</author>
      <guid isPermaLink="false">2504.11581v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Towards Forceful Robotic Foundation Models: a Literature Survey</title>
      <link>http://arxiv.org/abs/2504.11827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了机器人操作策略学习中的力整合方法，包括本体感觉和触觉感知。&lt;h4&gt;背景&lt;/h4&gt;文章回顾了力、数据收集、行为克隆、触觉表征学习和低级机器人控制等方法的比较分析。&lt;h4&gt;目的&lt;/h4&gt;明确何时以及为什么需要力，并突出提高基于触觉的机器人基础模型的学习机会。&lt;h4&gt;方法&lt;/h4&gt;进行了关于感力量、数据收集、行为克隆、触觉表征学习和低级机器人控制方法的比较分析。&lt;h4&gt;主要发现&lt;/h4&gt;尽管有如倒水、钉孔插入和搬运精细物体等任务，但模仿学习模型的性能并未达到力真正起作用的高度动态水平。&lt;h4&gt;结论&lt;/h4&gt;力和触觉是可以通过多种方式推断的抽象量，通常隐性地测量和控制。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了在机器人操作策略学习过程中，如何整合包括本体感觉和触觉感知在内的力的方法。我们对感力量、数据收集、行为克隆、触觉表征学习和低级机器人控制等多种方法进行了比较分析。通过分析，我们明确了力的需求及其原因，并强调了在向高度智能的触觉机器人基础模型发展的过程中，提高富含接触信息的通用机器人策略学习的机会。总的来说，尽管存在像倒水、钉孔插入和搬运精细物体等少数任务，但模仿学习模型的性能还没有达到力真正起作用的高度动态水平。此外，力和触觉是可以通过广泛的方式推断的抽象量，它们通常被隐性地测量和控制。我们希望通过比较当前使用的不同方法，帮助读者获得系统的理解，并激发下一代机器人基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This article reviews contemporary methods for integrating force, includingboth proprioception and tactile sensing, in robot manipulation policy learning.We conduct a comparative analysis on various approaches for sensing force, datacollection, behavior cloning, tactile representation learning, and low-levelrobot control. From our analysis, we articulate when and why forces are needed,and highlight opportunities to improve learning of contact-rich, generalistrobot policies on the path toward highly capable touch-based robot foundationmodels. We generally find that while there are few tasks such as pouring,peg-in-hole insertion, and handling delicate objects, the performance ofimitation learning models is not at a level of dynamics where force trulymatters. Also, force and touch are abstract quantities that can be inferredthrough a wide range of modalities and are often measured and controlledimplicitly. We hope that juxtaposing the different approaches currently in usewill help the reader to gain a systemic understanding and help inspire the nextgeneration of robot foundation models.</description>
      <author>example@mail.com (William Xie, Nikolaus Correll)</author>
      <guid isPermaLink="false">2504.11827v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Extended Short- and Long-Range Mesh Learning for Fast and Generalized Garment Simulation</title>
      <link>http://arxiv.org/abs/2504.11763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的新型三维服装模拟框架，通过LSDMP和GSA模块提高模拟效率。&lt;h4&gt;背景&lt;/h4&gt;3D服装模拟是生产基于布料的图形的关键组成部分，而GNN在服装模拟方面展现出潜力。&lt;h4&gt;目的&lt;/h4&gt;为了解决GNN在模拟中信息传播和接触感知的效率问题。&lt;h4&gt;方法&lt;/h4&gt;设计了一个包含LSDMP和GSA模块的GNN框架，LSDMP通过拉普拉斯特征平滑过程增强信息传播，GSA则通过引入测地距离嵌入和注意力机制来捕捉全局网格信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在减少层数和降低推理延迟的同时，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的GNN框架为高效的三维服装模拟提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D garment simulation is a critical component for producing cloth-basedgraphics. Recent advancements in graph neural networks (GNNs) offer a promisingapproach for efficient garment simulation. However, GNNs require extensivemessage-passing to propagate information such as physical forces and maintaincontact awareness across the entire garment mesh, which becomes computationallyinefficient at higher resolutions. To address this, we devise a novel GNN-basedmesh learning framework with two key components to extend the message-passingrange with minimal overhead, namely the Laplacian-Smoothed Dual Message-Passing(LSDMP) and the Geodesic Self-Attention (GSA) modules. LSDMP enhancesmessage-passing with a Laplacian features smoothing process, which efficientlypropagates the impact of each vertex to nearby vertices. Concurrently, GSAintroduces geodesic distance embeddings to represent the spatial relationshipbetween vertices and utilises attention mechanisms to capture global meshinformation. The two modules operate in parallel to ensure both short- andlong-range mesh modelling. Extensive experiments demonstrate thestate-of-the-art performance of our method, requiring fewer layers and lowerinference latency.</description>
      <author>example@mail.com (Aoran Liu, Kun Hu, Clinton Mo, Changyang Li, Zhiyong Wang)</author>
      <guid isPermaLink="false">2504.11763v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>ReTool: Reinforcement Learning for Strategic Tool Use in LLMs</title>
      <link>http://arxiv.org/abs/2504.11536v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ReTool的推理模型，该模型通过工具集成学习增强了长文本推理能力，特别适用于需要结构化问题解决的场景，如几何推理、简洁计算或复杂方程求解。&lt;h4&gt;背景&lt;/h4&gt;尽管基于强化学习的推理模型在文本推理方面表现出色，但在需要结构化问题解决的场景中表现不佳，如几何推理、简洁计算或复杂方程求解，这些场景中计算工具（如代码解释器）具有明显优势。&lt;h4&gt;目的&lt;/h4&gt;为了弥合这一差距，提出了ReTool模型，旨在通过工具集成学习提升长文本推理能力。&lt;h4&gt;方法&lt;/h4&gt;ReTool模型具有两个关键特性：(1) 在自然语言推理过程中动态交织实时代码执行；(2) 一种自动化的强化学习范式，允许进行多轮实时代码执行的政策展开，并根据结果反馈来指导模型何时以及如何调用工具。ReTool采用系统性的训练框架，从生成合成冷启动数据开始，以生产代码增强的长文本推理轨迹，用于微调基础模型。后续的RL训练利用任务结果作为奖励，迭代地改进模型的工具使用策略，使模型能够自主发现最优的工具调用模式。&lt;h4&gt;主要发现&lt;/h4&gt;在MATH奥林匹克基准AIME上的实验表明，ReTool模型优于基于文本的强化学习基线。ReTool-32B模型在400个训练步骤后达到67%的准确率，在效率和性能上优于基线（40%的准确率，1080个步骤）。在扩展设置中，ReTool-32B达到72.5%的准确率，比OpenAI的o1-preview高出27.9%。进一步的分析揭示了代码自我纠正等新兴行为，表明模型在自主掌握适应性工具使用时达到了“啊哈”时刻。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了基于结果驱动的工具集成在推进复杂数学推理方面的潜力，并为混合神经符号系统提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：虽然使用强化学习（如DeepSeek R1）训练的推理模型在文本推理方面表现出色，但在需要结构化问题解决的场景中，如几何推理、简洁计算或复杂方程求解等方面存在困难，这些领域是计算工具（如代码解释器）具有明显优势的地方。为了弥合这一差距，我们提出了ReTool，它通过工具集成学习增强了长文本推理能力，包括两个关键特性：(1) 在自然语言推理过程中动态交织实时代码执行；(2) 一种自动化的强化学习范式，允许进行多轮实时代码执行的政策展开，并根据结果反馈来指导模型何时以及如何调用工具。ReTool采用系统性的训练框架，从生成合成冷启动数据开始，以生产代码增强的长文本推理轨迹，用于微调基础模型。后续的RL训练利用任务结果作为奖励，迭代地改进模型的工具使用策略，使模型能够自主发现最优的工具调用模式。在具有挑战性的MATH奥林匹克基准AIME上的实验表明，ReTool模型优于基于文本的强化学习基线。ReTool-32B模型在400个训练步骤后达到67%的准确率，在效率和性能上优于基线（40%的准确率，1080个步骤）。在扩展设置中，ReTool-32B达到72.5%的准确率，比OpenAI的o1-preview高出27.9%。进一步的分析揭示了代码自我纠正等新兴行为，表明模型在自主掌握适应性工具使用时达到了“啊哈”时刻。这些发现突出了基于结果驱动的工具集成在推进复杂数学推理方面的潜力，并为混合神经符号系统提供了新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While reasoning models (e.g., DeepSeek R1) trained with reinforcementlearning (RL), excel in textual reasoning, they struggle in scenarios requiringstructured problem-solving, such as geometric reasoning, concise computation,or complex equation solving-areas where computational tools like codeinterpreters (CI) demonstrate distinct advantages. To bridge this gap, wepropose ReTool, which enhances long-form reasoning with tool-integratedlearning, including two key features: (1) dynamic interleaving of real-timecode execution within natural language reasoning processes, and (2) anautomated RL paradigm that allows policy rollouts with multi-turn real-timecode execution and teaches the model in learning when and how to invoke toolsbased on outcome feedback. ReTool employs a systematic training framework,beginning with synthetic cold-start data generation to produce code-augmentedlong-form reasoning traces for fine-tuning base models. Subsequent RL trainingleverages task outcomes as rewards to iteratively refine the model's tool usestrategy, enabling autonomous discovery of optimal tool invocation patternswithout human priors. Experiments on the challenging MATH Olympiad benchmarkAIME demonstrate ReTool's superiority: Our 32B model achieves 67% accuracy with400 training steps, outperforming text-based RL baseline (40% accuracy, 1080steps) in efficiency and performance. Remarkably, ReTool-32B attains 72.5%accuracy in extended settings, surpassing OpenAI's o1-preview by 27.9%. Furtheranalysis reveals emergent behaviors such as code self-correction, signaling an''aha moment'' in which the model autonomously masters adaptive tool use. Thesefindings highlight the promise of outcome-driven tool integration for advancingcomplex mathematical reasoning and offer new insights into hybridneuro-symbolic systems.</description>
      <author>example@mail.com (Jiazhan Feng, Shijue Huang, Xingwei Qu, Ge Zhang, Yujia Qin, Baoquan Zhong, Chengquan Jiang, Jinxin Chi, Wanjun Zhong)</author>
      <guid isPermaLink="false">2504.11536v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Clustering and analysis of user behaviour in blockchain: A case study of Planet IX</title>
      <link>http://arxiv.org/abs/2504.11702v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures, submitted to Blockchain: Research and  Applications&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于公共区块链的dApps的隐私问题，提出了一种用户行为分析流程，用于提取和分析用户在游戏中的行为，并使用图神经网络和聚类算法对用户行为进行分类。&lt;h4&gt;背景&lt;/h4&gt;公共区块链上的dApps具有透明性和可信性，但同时也存在隐私泄露的风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种用户行为分析流程，以识别用户在游戏中的行为模式，并评估其隐私风险。&lt;h4&gt;方法&lt;/h4&gt;1. 收集基于区块链游戏Planet IX的交易数据，包括智能合约和交易事件。2. 从数据中形成游戏动作，并形成用户流程。3. 使用扩展的用户流程展示NFT在用户行为中的应用。4. 将用户流程作为输入，使用图神经网络模型提供图嵌入。5. 利用聚类算法将用户行为聚类。6. 对比评估了多种聚类算法。7. 分析和可视化用户行为聚类。&lt;h4&gt;主要发现&lt;/h4&gt;1. 用户行为信息可以揭示用户行为模式。2. 恶意用户可能利用这些信息。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法可以有效地识别用户行为，但同时也存在隐私风险。&lt;h4&gt;翻译&lt;/h4&gt;Decentralised applications (dApps) that run on public blockchains have the benefit of trustworthiness and transparency as every activity that happens on the blockchain can be publicly traced through the transaction data. However, this introduces a potential privacy problem as this data can be tracked and analyzed, which can reveal user-behavior information. A user behavior analysis pipeline was proposed to present how this type of information can be extracted and analyzed to identify separate behavioral clusters that can describe how users behave in the game. The pipeline starts with the collection of transaction data, involving smart contracts, that is collected from a blockchain-based game called Planet IX. Both the raw transaction information and the transaction events are considered in the data collection. From this data, separate game actions can be formed and those are leveraged to present how and when the users conducted their in-game activities in the form of user flows. An extended version of these user flows also presents how the Non-Fungible Tokens (NFTs) are being leveraged in the user actions. The latter is given as input for a Graph Neural Network (GNN) model to provide graph embeddings for these flows which then can be leveraged by clustering algorithms to cluster user behaviors into separate behavioral clusters. We benchmark and compare well-known clustering algorithms as a part of the proposed method. The user behavior clusters were analyzed and visualized in a graph format. It was found that behavioral information can be extracted regarding the users that belong to these clusters. Such information can be exploited by malicious users to their advantage. To demonstrate this, a privacy threat model was also presented based on the results that correspond to multiple potentially affected areas.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decentralised applications (dApps) that run on public blockchains have thebenefit of trustworthiness and transparency as every activity that happens onthe blockchain can be publicly traced through the transaction data. However,this introduces a potential privacy problem as this data can be tracked andanalysed, which can reveal user-behaviour information. A user behaviouranalysis pipeline was proposed to present how this type of information can beextracted and analysed to identify separate behavioural clusters that candescribe how users behave in the game. The pipeline starts with the collectionof transaction data, involving smart contracts, that is collected from ablockchain-based game called Planet IX. Both the raw transaction informationand the transaction events are considered in the data collection. From thisdata, separate game actions can be formed and those are leveraged to presenthow and when the users conducted their in-game activities in the form of userflows. An extended version of these user flows also presents how theNon-Fungible Tokens (NFTs) are being leveraged in the user actions. The latteris given as input for a Graph Neural Network (GNN) model to provide graphembeddings for these flows which then can be leveraged by clustering algorithmsto cluster user behaviours into separate behavioural clusters. We benchmark andcompare well-known clustering algorithms as a part of the proposed method. Theuser behaviour clusters were analysed and visualised in a graph format. It wasfound that behavioural information can be extracted regarding the users thatbelong to these clusters. Such information can be exploited by malicious usersto their advantage. To demonstrate this, a privacy threat model was alsopresented based on the results that correspond to multiple potentially affectedareas.</description>
      <author>example@mail.com (Dorottya Zelenyanszki, Zhe Hou, Kamanashis Biswas, Vallipuram Muthukkumarasamy)</author>
      <guid isPermaLink="false">2504.11702v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>DART: Disease-aware Image-Text Alignment and Self-correcting Re-alignment for Trustworthy Radiology Report Generation</title>
      <link>http://arxiv.org/abs/2504.11786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The IEEE/CVF Conference on Computer Vision and Pattern Recognition  (CVPR) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种名为DART的框架，旨在通过自动生成放射学报告来提高报告的准确性。&lt;h4&gt;背景&lt;/h4&gt;自动生成放射学报告已成为一种减少耗时任务并准确捕捉X射线图像中疾病相关发现的有前景解决方案。&lt;h4&gt;目的&lt;/h4&gt;旨在通过确保检索的报告包含与X射线图像中相似的疾病相关发现，并改进生成的报告，进一步提高报告的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种疾病感知的图像-文本对齐和自校正重对齐方法，分为两个阶段：首先基于图像到文本的检索和疾病匹配生成初始报告，然后将报告与X射线图像重新对齐。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在两个广泛使用的基准测试中取得了最先进的结果，在报告生成和临床效度指标方面均优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;该框架增强了放射学报告的可信度，为放射学报告的自动化生成提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The automatic generation of radiology reports has emerged as a promisingsolution to reduce a time-consuming task and accurately capture criticaldisease-relevant findings in X-ray images. Previous approaches for radiologyreport generation have shown impressive performance. However, there remainssignificant potential to improve accuracy by ensuring that retrieved reportscontain disease-relevant findings similar to those in the X-ray images and byrefining generated reports. In this study, we propose a Disease-awareimage-text Alignment and self-correcting Re-alignment for Trustworthy radiologyreport generation (DART) framework. In the first stage, we generate initialreports based on image-to-text retrieval with disease-matching, embedding bothimages and texts in a shared embedding space through contrastive learning. Thisapproach ensures the retrieval of reports with similar disease-relevantfindings that closely align with the input X-ray images. In the second stage,we further enhance the initial reports by introducing a self-correction modulethat re-aligns them with the X-ray images. Our proposed framework achievesstate-of-the-art results on two widely used benchmarks, surpassing previousapproaches in both report generation and clinical efficacy metrics, therebyenhancing the trustworthiness of radiology reports.</description>
      <author>example@mail.com (Sang-Jun Park, Keun-Soo Heo, Dong-Hee Shin, Young-Han Son, Ji-Hye Oh, Tae-Eui Kam)</author>
      <guid isPermaLink="false">2504.11786v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Real-World Depth Recovery via Structure Uncertainty Modeling and Inaccurate GT Depth Fitting</title>
      <link>http://arxiv.org/abs/2504.11820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种针对真实世界RGB-D数据集中原始深度图低质量结构问题的深度恢复方法，该方法通过设计新的深度生成流程和结构不确定性模块，提高了深度恢复的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;在真实世界RGB-D数据集中，原始深度图普遍存在低质量结构，这使得深度恢复成为一项关键任务。然而，缺乏配对的原始-真实深度数据（raw-GT）数据给泛化深度恢复带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提高真实世界深度恢复的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;1. 设计新的原始深度生成流程，丰富原始深度图中结构错位多样性，避免网络对特定条件过拟合。2. 设计结构不确定性模块，明确识别输入原始深度图中的错位结构，以更好地泛化到未见过的场景。3. 训练好的深度基础模型（DFM）帮助结构不确定性模块更好地估计结构不确定性。4. 设计鲁棒的特征对齐模块，精确对齐RGB图像的准确结构，避免不准确的真实深度的影响。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个数据集上的实验表明，在各种具有挑战性的原始深度图中，该方法实现了具有竞争力的准确性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该方法通过设计新的深度生成流程和结构不确定性模块，有效地提高了真实世界深度恢复的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;The low-quality structure in raw depth maps is prevalent in real-world RGB-D datasets, which makes real-world depth recovery a critical task in recent years. However, the lack of paired raw-ground truth (raw-GT) data in the real world poses challenges for generalized depth recovery. Existing methods insufficiently consider the diversity of structure misalignment in raw depth maps, which leads to poor generalization in real-world depth recovery. Notably, random structure misalignments are not limited to raw depth data but also affect GT depth in real-world datasets. In the proposed method, we tackle the generalization problem from both input and output perspectives. For input, we enrich the diversity of structure misalignment in raw depth maps by designing a new raw depth generation pipeline, which helps the network avoid overfitting to a specific condition. Furthermore, a structure uncertainty module is designed to explicitly identify the misaligned structure for input raw depth maps to better generalize in unseen scenarios. Notably the well-trained depth foundation model (DFM) can help the structure uncertainty module estimate the structure uncertainty better. For output, a robust feature alignment module is designed to precisely align with the accurate structure of RGB images avoiding the interference of inaccurate GT depth. Extensive experiments on multiple datasets demonstrate the proposed method achieves competitive accuracy and generalization capabilities across various challenging raw depth maps.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The low-quality structure in raw depth maps is prevalent in real-world RGB-Ddatasets, which makes real-world depth recovery a critical task in recentyears. However, the lack of paired raw-ground truth (raw-GT) data in the realworld poses challenges for generalized depth recovery. Existing methodsinsufficiently consider the diversity of structure misalignment in raw depthmaps, which leads to poor generalization in real-world depth recovery. Notably,random structure misalignments are not limited to raw depth data but alsoaffect GT depth in real-world datasets. In the proposed method, we tackle thegeneralization problem from both input and output perspectives. For input, weenrich the diversity of structure misalignment in raw depth maps by designing anew raw depth generation pipeline, which helps the network avoid overfitting toa specific condition. Furthermore, a structure uncertainty module is designedto explicitly identify the misaligned structure for input raw depth maps tobetter generalize in unseen scenarios. Notably the well-trained depthfoundation model (DFM) can help the structure uncertainty module estimate thestructure uncertainty better. For output, a robust feature alignment module isdesigned to precisely align with the accurate structure of RGB images avoidingthe interference of inaccurate GT depth. Extensive experiments on multipledatasets demonstrate the proposed method achieves competitive accuracy andgeneralization capabilities across various challenging raw depth maps.</description>
      <author>example@mail.com (Delong Suzhang, Meng Yang)</author>
      <guid isPermaLink="false">2504.11820v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>H$^3$GNNs: Harmonizing Heterophily and Homophily in GNNs via Joint Structural Node Encoding and Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2504.11699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;H$^3$GNNs是一种端到端自监督学习框架，通过两种关键创新解决了GNNs在异质性和同质性问题上的挑战，并在多个基准数据集上取得了优异的性能。&lt;h4&gt;背景&lt;/h4&gt;GNNs在异质性和同质性的平衡上存在困难，特别是在自监督学习设置中。&lt;h4&gt;目的&lt;/h4&gt;提出H$^3$GNNs框架，以解决GNNs在自监督学习中的异质性和同质性问题。&lt;h4&gt;方法&lt;/h4&gt;H$^3$GNNs通过以下两种方法实现平衡：(i) 联合结构节点编码，使用加权图卷积网络结合线性和非线性特征投影以及K-hop结构表示；(ii) 使用教师-学生预测架构，并引入节点难度驱动的动态掩码策略。&lt;h4&gt;主要发现&lt;/h4&gt;在七个基准数据集（四个异质性和三个同质性数据集）上的实验证实了H$^3$GNNs的有效性和效率，在四个异质性数据集上达到了最先进的性能，在三个同质性数据集上保持了与之前最先进方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;H$^3$GNNs是一种有效的框架，可以解决GNNs在自监督学习中的异质性和同质性问题，并在多个图类型的数据集上取得了优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs)在表示学习中难以平衡异质性和同质性，这一挑战在自监督设置中进一步加剧。我们提出了H$^3$GNNs，这是一种端到端自监督学习框架，通过两种关键创新来协调这两种结构属性：(i) 联合结构节点编码。我们通过加权图卷积网络(WGCN)将节点嵌入到一个统一的空间中，该空间结合了线性和非线性特征投影以及K-hop结构表示。跨注意力机制增强了对外异质性和同质性的意识和适应性。(ii) 使用教师-学生预测架构，并采用节点难度驱动的动态掩码策略进行自监督学习。我们使用教师-学生模型，学生看到掩码输入图，并预测教师推断的节点特征，而教师看到的是联合编码空间中的完整输入图。为了提高学习难度，我们引入了两种基于节点预测难度的创新掩码策略。在七个基准（四个异质性和三个同质性数据集）上的实验证实了H$^3$GNNs在多种图类型上的有效性和效率。我们的H$^3$GNNs在四个异质性数据集上实现了整体最先进的性能，同时在三个同质性数据集上保持了与之前最先进方法相当的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) struggle to balance heterophily and homophily inrepresentation learning, a challenge further amplified in self-supervisedsettings. We propose H$^3$GNNs, an end-to-end self-supervised learningframework that harmonizes both structural properties through two keyinnovations: (i) Joint Structural Node Encoding. We embed nodes into a unifiedspace combining linear and non-linear feature projections with K-hop structuralrepresentations via a Weighted Graph Convolution Network(WGCN). Across-attention mechanism enhances awareness and adaptability to heterophilyand homophily. (ii) Self-Supervised Learning Using Teacher-Student PredictiveArchitectures with Node-Difficulty Driven Dynamic Masking Strategies. We use ateacher-student model, the student sees the masked input graph and predictsnode features inferred by the teacher that sees the full input graph in thejoint encoding space. To enhance learning difficulty, we introduce two novelnode-predictive-difficulty-based masking strategies. Experiments on sevenbenchmarks (four heterophily datasets and three homophily datasets) confirm theeffectiveness and efficiency of H$^3$GNNs across diverse graph types. OurH$^3$GNNs achieves overall state-of-the-art performance on the four heterophilydatasets, while retaining on-par performance to previous state-of-the-artmethods on the three homophily datasets.</description>
      <author>example@mail.com (Rui Xue, Tianfu Wu)</author>
      <guid isPermaLink="false">2504.11699v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Towards Interpretable Deep Generative Models via Causal Representation Learning</title>
      <link>http://arxiv.org/abs/2504.11609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文概述了因果表示学习（CRL）领域的最新进展，从统计学的角度对其进行了回顾，并强调了其与经典模型、统计和因果可识别性结果之间的联系。&lt;h4&gt;背景&lt;/h4&gt;近年来，生成式人工智能（AI）在多个领域取得了显著的进展，这得益于深度学习和生成建模等机器学习技术。然而，深度神经网络作为黑盒模型，使得其内部表示难以解释和分析。&lt;h4&gt;目的&lt;/h4&gt;构建新的可解释神经网络模型，以解决深度神经网络难以解释的问题，并推动因果表示学习（CRL）的发展。&lt;h4&gt;方法&lt;/h4&gt;CRL利用因果关系作为构建灵活、可解释和可迁移的生成AI的工具。它综合了潜在变量模型、因果图模型和深度学习等统计和机器学习技术。&lt;h4&gt;主要发现&lt;/h4&gt;论文回顾了CRL在统计视角下的最新进展，并强调了其与经典模型和统计因果可识别性结果之间的联系。&lt;h4&gt;结论&lt;/h4&gt;CRL是解决深度神经网络解释性问题的一个新兴领域，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;The paper summarizes the latest progress in the field of causal representation learning (CRL), reviews it from a statistical perspective, and highlights its connections to classical models and statistical and causal identifiability results. The background is that recent developments in generative artificial intelligence (AI) rely on machine learning techniques such as deep learning and generative modeling to achieve state-of-the-art performance across a wide range of domains. However, deep neural networks are notorious black boxes that obscure these representations, making them difficult to interpret or analyze. The goal is to build new interpretable neural network models to resolve these difficulties and promote the development of causal representation learning (CRL). CRL uses causality as a vector to build flexible, interpretable, and transferable generative AI, integrating statistical and machine learning techniques such as latent variable models, causal graphical models, and deep learning. The main findings are that the paper reviews the latest progress in CRL from a statistical perspective and highlights its connections to classical models and statistical and causal identifiability results. The conclusion is that CRL is an emerging field that addresses the interpretability problem of deep neural networks and has wide application prospects.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent developments in generative artificial intelligence (AI) rely onmachine learning techniques such as deep learning and generative modeling toachieve state-of-the-art performance across wide-ranging domains. Thesemethods' surprising performance is due in part to their ability to learnimplicit "representations'' of complex, multi-modal data. Unfortunately, deepneural networks are notoriously black boxes that obscure these representations,making them difficult to interpret or analyze. To resolve these difficulties,one approach is to build new interpretable neural network models from theground up. This is the goal of the emerging field of causal representationlearning (CRL) that uses causality as a vector for building flexible,interpretable, and transferable generative AI. CRL can be seen as a culminationof three intrinsically statistical problems: (i) latent variable models such asfactor analysis; (ii) causal graphical models with latent variables; and (iii)nonparametric statistics and deep learning. This paper reviews recent progressin CRL from a statistical perspective, focusing on connections to classicalmodels and statistical and causal identifiablity results. This review alsohighlights key application areas, implementation strategies, and openstatistical questions in CRL.</description>
      <author>example@mail.com (Gemma E. Moran, Bryon Aragam)</author>
      <guid isPermaLink="false">2504.11609v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>EgoExo-Gen: Ego-centric Video Prediction by Watching Exo-centric Videos</title>
      <link>http://arxiv.org/abs/2504.11732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了跨视图视频预测任务，提出了一种名为EgoExo-Gen的模型，用于生成第一人称视角视频的未来帧。&lt;h4&gt;背景&lt;/h4&gt;生成第一人称视角的视频在增强现实和具身智能领域有广泛的应用前景。&lt;h4&gt;目的&lt;/h4&gt;目标是给定一个外视角视频、相应内视角视频的第一帧和文本指令，生成内视角视频的未来帧。&lt;h4&gt;方法&lt;/h4&gt;EgoExo-Gen包括两个阶段：首先设计了一个跨视图手-物交互（HOI）掩码预测模型，通过建模时空内-外对应关系来预测未来内视角帧的HOI掩码；其次，使用视频扩散模型，结合文本指令和HOI掩码作为结构指导，预测未来的内视角帧。&lt;h4&gt;主要发现&lt;/h4&gt;通过Ego-Exo4D和H2O基准数据集的实验，EgoExo-Gen在视频预测性能上优于之前的模型，且HOI掩码显著提升了内视角视频中手和交互对象的生成质量。&lt;h4&gt;结论&lt;/h4&gt;EgoExo-Gen模型通过模型化手-物动态和结合HOI掩码，在跨视图视频预测任务中取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在增强现实和具身智能领域，以第一人称视角生成视频具有广泛的应用前景。在本研究中，我们探索了跨视图视频预测任务，即给定一个外视角视频、相应内视角视频的第一帧和文本指令，目标是生成内视角视频的未来帧。受内视角视频中手-物交互（HOI）代表当前演员主要意图和动作这一观点的启发，我们提出了EgoExo-Gen模型，该模型显式地建模了手-物动态以进行跨视图视频预测。EgoExo-Gen包括两个阶段。首先，我们设计了一个跨视图HOI掩码预测模型，通过建模时空内-外对应关系来预测未来内视角帧的HOI掩码。接下来，我们采用视频扩散模型，结合第一内视角帧和文本指令预测未来的内视角帧，同时将HOI掩码作为结构指导以提高预测质量。为了方便训练，我们开发了一个自动化管道，通过利用视觉基础模型生成伪HOI掩码，为内视角视频和外视角视频。广泛的实验表明，我们提出的EgoExo-Gen在Ego-Exo4D和H2O基准数据集上比之前的视频预测模型实现了更好的预测性能，且HOI掩码显著提高了内视角视频中手和交互对象的生成质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating videos in the first-person perspective has broad applicationprospects in the field of augmented reality and embodied intelligence. In thiswork, we explore the cross-view video prediction task, where given anexo-centric video, the first frame of the corresponding ego-centric video, andtextual instructions, the goal is to generate futur frames of the ego-centricvideo. Inspired by the notion that hand-object interactions (HOI) inego-centric videos represent the primary intentions and actions of the currentactor, we present EgoExo-Gen that explicitly models the hand-object dynamicsfor cross-view video prediction. EgoExo-Gen consists of two stages. First, wedesign a cross-view HOI mask prediction model that anticipates the HOI masks infuture ego-frames by modeling the spatio-temporal ego-exo correspondence. Next,we employ a video diffusion model to predict future ego-frames using the firstego-frame and textual instructions, while incorporating the HOI masks asstructural guidance to enhance prediction quality. To facilitate training, wedevelop an automated pipeline to generate pseudo HOI masks for both ego- andexo-videos by exploiting vision foundation models. Extensive experimentsdemonstrate that our proposed EgoExo-Gen achieves better prediction performancecompared to previous video prediction models on the Ego-Exo4D and H2O benchmarkdatasets, with the HOI masks significantly improving the generation of handsand interactive objects in the ego-centric videos.</description>
      <author>example@mail.com (Jilan Xu, Yifei Huang, Baoqi Pei, Junlin Hou, Qingqiu Li, Guo Chen, Yuejie Zhang, Rui Feng, Weidi Xie)</author>
      <guid isPermaLink="false">2504.11732v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Elucidating the Design Space of Multimodal Protein Language Models</title>
      <link>http://arxiv.org/abs/2504.11454v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://bytedance.github.io/dplm/dplm-2.1/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态蛋白质语言模型（PLMs）的设计空间，以克服其局限性，并显著提高了蛋白质模型、生成和设计的能力。&lt;h4&gt;背景&lt;/h4&gt;多模态PLMs结合序列和基于标记的结构信息，是蛋白质建模、生成和设计的强大基础。然而，将3D结构标记化成离散标记会导致关于细粒度结构细节和关联的保真度损失。&lt;h4&gt;目的&lt;/h4&gt;系统阐述多模态PLMs的设计空间，以克服其局限性，并提高蛋白质模型的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出的设计空间包括改进的生成建模、结构感知架构和表示学习以及数据探索。通过更细粒度的监督，证明了基于标记的多模态PLMs可以实现鲁棒的结构建模。&lt;h4&gt;主要发现&lt;/h4&gt;识别出标记化损失和PLM的结构标记预测不准确是主要瓶颈。改进的设计方法显著提高了结构生成多样性，特别是折叠能力。650M模型在PDB测试集上的RMSD从5.52降低到2.36，甚至超过了3B基线，与专门的折叠模型相当。&lt;h4&gt;结论&lt;/h4&gt;通过改进的设计方法，多模态PLMs能够实现更精确和多样化的蛋白质结构建模，显著提升了蛋白质折叠能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal protein language models (PLMs) integrate sequence and token-basedstructural information, serving as a powerful foundation for protein modeling,generation, and design. However, the reliance on tokenizing 3D structures intodiscrete tokens causes substantial loss of fidelity about fine-grainedstructural details and correlations. In this paper, we systematically elucidatethe design space of multimodal PLMs to overcome their limitations. We identifytokenization loss and inaccurate structure token predictions by the PLMs asmajor bottlenecks. To address these, our proposed design space covers improvedgenerative modeling, structure-aware architectures and representation learning,and data exploration. Our advancements approach finer-grained supervision,demonstrating that token-based multimodal PLMs can achieve robust structuralmodeling. The effective design methods dramatically improve the structuregeneration diversity, and notably, folding abilities of our 650M model byreducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3Bbaselines and on par with the specialized folding models.</description>
      <author>example@mail.com (Cheng-Yen Hsieh, Xinyou Wang, Daiheng Zhang, Dongyu Xue, Fei Ye, Shujian Huang, Zaixiang Zheng, Quanquan Gu)</author>
      <guid isPermaLink="false">2504.11454v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>FACT: Foundation Model for Assessing Cancer Tissue Margins with Mass Spectrometry</title>
      <link>http://arxiv.org/abs/2504.11519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种针对REIMS数据的专用基础模型，用于实时术中组织边缘评估，以解决手术环境中标注数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;准确分类癌症手术中的组织边缘对于确保完全切除肿瘤至关重要。快速蒸发电离质谱（REIMS）是一种实时术中边缘评估工具，但其生成的光谱需要机器学习模型来支持临床决策。&lt;h4&gt;目的&lt;/h4&gt;开发一个专门针对REIMS数据的基础模型，以解决手术环境中标注数据稀缺的问题，并推进实时术中边缘评估。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为FACT的基础模型，它是针对文本-音频关联设计的基础模型的改编，并使用基于三元组损失的监督对比预训练方法进行预训练。通过消融研究来比较所提出的模型与其他模型和预训练方法。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型显著提高了分类性能，达到了82.4% ± 0.8的AUROC，表明了所提出的预训练方法和所选骨干网络相对于自监督和半监督基线和替代模型的优势。&lt;h4&gt;结论&lt;/h4&gt;研究发现，通过使用新颖的方法进行改编和预训练的基础模型，即使在有限的标注示例下也能有效地分类REIMS数据。这突出了基础模型在数据稀缺的临床环境中增强实时术中边缘评估的可行性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：目的：在癌症手术中准确分类组织边缘对于确保完全切除肿瘤至关重要。快速蒸发电离质谱（REIMS）是一种用于实时术中边缘评估的工具，它生成需要机器学习模型来支持临床决策的光谱。然而，手术环境中标注数据的稀缺性提出了一个重大的挑战。本研究首次开发了一个专门针对REIMS数据的基础模型，解决了这一限制并推进了实时术中边缘评估。方法：我们提出了用于评估癌症组织边缘的基础模型FACT。FACT是对最初为文本-音频关联设计的基模型的改编，使用我们提出的基于三元组损失的监督对比预训练方法进行预训练。通过消融研究来比较我们提出的模型与其他模型和预训练方法。结果：我们提出的模型显著提高了分类性能，达到了82.4% ± 0.8的AUROC，表明了我们的预训练方法和所选骨干网络相对于自监督和半监督基线和替代模型的优势。结论：我们的发现表明，通过使用新颖的方法进行改编和预训练的基础模型，即使在有限的标注示例下也能有效地分类REIMS数据。这突出了基础模型在数据稀缺的临床环境中增强实时术中边缘评估的可行性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s11548-025-03355-8&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: Accurately classifying tissue margins during cancer surgeries iscrucial for ensuring complete tumor removal. Rapid Evaporative Ionization MassSpectrometry (REIMS), a tool for real-time intraoperative margin assessment,generates spectra that require machine learning models to support clinicaldecision-making. However, the scarcity of labeled data in surgical contextspresents a significant challenge. This study is the first to develop afoundation model tailored specifically for REIMS data, addressing thislimitation and advancing real-time surgical margin assessment. Methods: Wepropose FACT, a Foundation model for Assessing Cancer Tissue margins. FACT isan adaptation of a foundation model originally designed for text-audioassociation, pretrained using our proposed supervised contrastive approachbased on triplet loss. An ablation study is performed to compare our proposedmodel against other models and pretraining methods. Results: Our proposed modelsignificantly improves the classification performance, achievingstate-of-the-art performance with an AUROC of $82.4\% \pm 0.8$. The resultsdemonstrate the advantage of our proposed pretraining method and selectedbackbone over the self-supervised and semi-supervised baselines and alternativemodels. Conclusion: Our findings demonstrate that foundation models, adaptedand pretrained using our novel approach, can effectively classify REIMS dataeven with limited labeled examples. This highlights the viability of foundationmodels for enhancing real-time surgical margin assessment, particularly indata-scarce clinical environments.</description>
      <author>example@mail.com (Mohammad Farahmand, Amoon Jamzad, Fahimeh Fooladgar, Laura Connolly, Martin Kaufmann, Kevin Yi Mi Ren, John Rudan, Doug McKay, Gabor Fichtinger, Parvin Mousavi)</author>
      <guid isPermaLink="false">2504.11519v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Seedream 3.0 Technical Report</title>
      <link>http://arxiv.org/abs/2504.11346v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Seedream 3.0 Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Seedream 3.0 是一个高性能的中英双语图像生成基础模型，通过多项技术改进解决了 Seedream 2.0 中的问题，如复杂提示的匹配、精细的字体生成、视觉美感和保真度不足以及有限的图像分辨率。&lt;h4&gt;背景&lt;/h4&gt;Seedream 3.0 是在 Seedream 2.0 的基础上开发的，旨在解决其存在的挑战。&lt;h4&gt;目的&lt;/h4&gt;提高 Seedream 2.0 的性能，特别是在复杂中文字符的文本渲染、精细字体生成和图像分辨率方面。&lt;h4&gt;方法&lt;/h4&gt;Seedream 3.0 通过以下方法实现改进：数据层面采用缺陷感知训练范式和双轴协作数据采样框架，预训练阶段使用混合分辨率训练、跨模态 RoPE、表示对齐损失和分辨率感知时间步采样技术，后训练阶段使用多样化的美学标题和基于 VLM 的奖励模型，以及采用一致的噪声期望和重要性感知时间步采样以实现加速。&lt;h4&gt;主要发现&lt;/h4&gt;Seedream 3.0 在 Seedream 2.0 的基础上取得了显著改进，特别是在复杂中文字符的文本渲染和图像分辨率方面，能够生成高达 2K 分辨率的图像。&lt;h4&gt;结论&lt;/h4&gt;Seedream 3.0 是一个更加强大和高效的图像生成模型，能够满足专业字体生成和高质量图像生成的需求。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了 Seedream 3.0，一个高性能的中英双语图像生成基础模型。我们开发了多项技术改进来解决 Seedream 2.0 中存在的挑战，包括与复杂提示的对齐、精细的字体生成、视觉美感和保真度不足以及有限的图像分辨率。特别是，Seedream 3.0 的进步源于整个流程的改进，从数据构建到模型部署。在数据层，我们使用缺陷感知训练范式和双轴协作数据采样框架将数据集翻倍。此外，在预训练阶段，我们采用了混合分辨率训练、跨模态 RoPE、表示对齐损失和分辨率感知时间步采样等有效技术。在后训练阶段，我们利用多样化的美学标题进行强化学习，并采用基于 VLM 的奖励模型进行缩放，从而实现与人类偏好良好的对齐。此外，Seedream 3.0 领先采用了一种新的加速范式。通过采用一致的噪声期望和重要性感知时间步采样，我们实现了 4 到 8 倍的速度提升，同时保持了图像质量。Seedream 3.0 在 Seedream 2.0 的基础上取得了显著改进：它增强了整体能力，特别是在复杂中文字符的文本渲染方面，这对于专业字体生成非常重要。此外，它提供了原生的高分辨率输出（高达 2K），使其能够生成高质量的图像。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Seedream 3.0, a high-performance Chinese-English bilingual imagegeneration foundation model. We develop several technical improvements toaddress existing challenges in Seedream 2.0, including alignment withcomplicated prompts, fine-grained typography generation, suboptimal visualaesthetics and fidelity, and limited image resolutions. Specifically, theadvancements of Seedream 3.0 stem from improvements across the entire pipeline,from data construction to model deployment. At the data stratum, we double thedataset using a defect-aware training paradigm and a dual-axis collaborativedata-sampling framework. Furthermore, we adopt several effective techniquessuch as mixed-resolution training, cross-modality RoPE, representationalignment loss, and resolution-aware timestep sampling in the pre-trainingphase. During the post-training stage, we utilize diversified aestheticcaptions in SFT, and a VLM-based reward model with scaling, thereby achievingoutputs that well align with human preferences. Furthermore, Seedream 3.0pioneers a novel acceleration paradigm. By employing consistent noiseexpectation and importance-aware timestep sampling, we achieve a 4 to 8 timesspeedup while maintaining image quality. Seedream 3.0 demonstrates significantimprovements over Seedream 2.0: it enhances overall capabilities, in particularfor text-rendering in complicated Chinese characters which is important toprofessional typography generation. In addition, it provides nativehigh-resolution output (up to 2K), allowing it to generate images with highvisual quality.</description>
      <author>example@mail.com (Yu Gao, Lixue Gong, Qiushan Guo, Xiaoxia Hou, Zhichao Lai, Fanshi Li, Liang Li, Xiaochen Lian, Chao Liao, Liyang Liu, Wei Liu, Yichun Shi, Shiqi Sun, Yu Tian, Zhi Tian, Peng Wang, Rui Wang, Xuanda Wang, Xun Wang, Ye Wang, Guofeng Wu, Jie Wu, Xin Xia, Xuefeng Xiao, Zhonghua Zhai, Xinyu Zhang, Qi Zhang, Yuwei Zhang, Shijia Zhao, Jianchao Yang, Weilin Huang)</author>
      <guid isPermaLink="false">2504.11346v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Negate or Embrace: On How Misalignment Shapes Multimodal Representation Learning</title>
      <link>http://arxiv.org/abs/2504.10143v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态表示学习，特别是使用图像-文本对的多模态对比学习（MMCL），旨在通过跨模态对齐线索来学习强大的表示。研究指出，现实数据集中存在模态对齐问题，并提出了两种解决观点：缓解对齐错误和利用对齐错误。通过引入选择偏差和扰动偏差两种机制，作者将模态对齐问题形式化，并通过理论分析和实证研究验证了其观点。&lt;h4&gt;背景&lt;/h4&gt;多模态表示学习旨在通过跨模态对齐来学习强大的表示，但现实数据集中存在模态对齐问题。&lt;h4&gt;目的&lt;/h4&gt;寻求解决模态对齐问题的方法，并为实践者提供指导。&lt;h4&gt;方法&lt;/h4&gt;使用潜在变量模型，引入选择偏差和扰动偏差两种机制来形式化模态对齐问题，并通过理论分析和实证研究验证。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，在轻微的假设下，MMCL学习到的表示恰好捕捉了与选择和扰动偏差无关的语义变量子集的信息。&lt;h4&gt;结论&lt;/h4&gt;提供了对模态对齐问题的统一理解视角，并基于此为现实世界机器学习系统的设计提供了可操作的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态表示学习，以使用图像-文本对的多模态对比学习（MMCL）为例，旨在通过跨模态对齐线索来学习强大的表示。这种方法依赖于一个核心假设，即示例图像-文本对构成了一个相同概念的两种表示。然而，最近的研究表明，现实世界的数据集往往存在对齐错误。关于如何解决这个问题，有两种不同的观点：一种建议减轻对齐错误，另一种则利用对齐错误。在这里，我们试图调和这些看似对立的观点，并为实践者提供实用的指南。因此，我们使用潜在变量模型，通过引入两种特定的机制来形式化对齐错误：选择偏差，其中一些语义变量缺失，以及扰动偏差，其中语义变量被扭曲——两者都影响跨模态共享的潜在变量。我们的理论分析表明，在轻微的假设下，MMCL学习到的表示恰好捕捉了与选择和扰动偏差无关的语义变量子集的信息。这为理解对齐错误提供了一个统一的视角。基于此，我们进一步提供了关于如何将对齐错误纳入现实世界机器学习系统设计的可操作见解。我们通过在合成数据和真实图像-文本数据集上进行的广泛实证研究验证了我们的理论发现，揭示了对齐错误对多模态表示学习的微妙影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation learning, exemplified by multimodal contrastivelearning (MMCL) using image-text pairs, aims to learn powerful representationsby aligning cues across modalities. This approach relies on the core assumptionthat the exemplar image-text pairs constitute two representations of anidentical concept. However, recent research has revealed that real-worlddatasets often exhibit misalignment. There are two distinct viewpoints on howto address this issue: one suggests mitigating the misalignment, and the otherleveraging it. We seek here to reconcile these seemingly opposing perspectives,and to provide a practical guide for practitioners. Using latent variablemodels we thus formalize misalignment by introducing two specific mechanisms:selection bias, where some semantic variables are missing, and perturbationbias, where semantic variables are distorted -- both affecting latent variablesshared across modalities. Our theoretical analysis demonstrates that, undermild assumptions, the representations learned by MMCL capture exactly theinformation related to the subset of the semantic variables invariant toselection and perturbation biases. This provides a unified perspective forunderstanding misalignment. Based on this, we further offer actionable insightsinto how misalignment should inform the design of real-world ML systems. Wevalidate our theoretical findings through extensive empirical studies on bothsynthetic data and real image-text datasets, shedding light on the nuancedimpact of misalignment on multimodal representation learning.</description>
      <author>example@mail.com (Yichao Cai, Yuhang Liu, Erdun Gao, Tianjiao Jiang, Zhen Zhang, Anton van den Hengel, Javen Qinfeng Shi)</author>
      <guid isPermaLink="false">2504.10143v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>ProtoECGNet: Case-Based Interpretable Deep Learning for Multi-Label ECG Classification with Contrastive Learning</title>
      <link>http://arxiv.org/abs/2504.08713v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于原型学习的深度学习模型ProtoECGNet，用于可解释的多标签ECG分类，以提高临床决策的可信度。&lt;h4&gt;背景&lt;/h4&gt;深度学习在ECG分类中表现出色，但临床应用受到缺乏透明和忠实解释的阻碍。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于原型学习的深度学习模型，以实现可解释的ECG分类，并提高临床决策的透明度和可信度。&lt;h4&gt;方法&lt;/h4&gt;ProtoECGNet采用结构化的多分支架构，结合1D CNN和全局原型进行节律分类，2D CNN和时间局部原型进行形态推理，以及2D CNN和全局原型进行弥漫性异常检测。每个分支使用专门设计的原型损失进行多标签学习。&lt;h4&gt;主要发现&lt;/h4&gt;ProtoECGNet在PTB-XL数据集上对所有71个诊断标签进行了评估，与最先进的黑盒模型相比表现出竞争力，同时提供了结构化的基于案例的解释。&lt;h4&gt;结论&lt;/h4&gt;原型学习可以有效地扩展到复杂的多标签时间序列分类，为临床决策支持提供了一种透明且可信的深度学习模型。&lt;h4&gt;翻译&lt;/h4&gt;Deep learning-based electrocardiogram (ECG) classification has shown impressive performance but clinical adoption has been slowed by the lack of transparent and faithful explanations. Post hoc methods such as saliency maps may fail to reflect a model's true decision process. Prototype-based reasoning offers a more transparent alternative by grounding decisions in similarity to learned representations of real ECG segments, enabling faithful, case-based explanations. We introduce ProtoECGNet, a prototype-based deep learning model for interpretable, multi-label ECG classification. ProtoECGNet employs a structured, multi-branch architecture that reflects clinical interpretation workflows: it integrates a 1D CNN with global prototypes for rhythm classification, a 2D CNN with time-localized prototypes for morphology-based reasoning, and a 2D CNN with global prototypes for diffuse abnormalities. Each branch is trained with a prototype loss designed for multi-label learning, combining clustering, separation, diversity, and a novel contrastive loss that encourages appropriate separation between prototypes of unrelated classes while allowing clustering for frequently co-occurring diagnoses. We evaluate ProtoECGNet on all 71 diagnostic labels from the PTB-XL dataset, demonstrating competitive performance relative to state-of-the-art black-box models while providing structured, case-based explanations. To assess prototype quality, we conduct a structured clinician review of the final model's projected prototypes, finding that they are rated as representative and clear. ProtoECGNet shows that prototype learning can be effectively scaled to complex, multi-label time-series classification, offering a practical path toward transparent and trustworthy deep learning models for clinical decision support.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bbj-lab/protoecgnet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based electrocardiogram (ECG) classification has shownimpressive performance but clinical adoption has been slowed by the lack oftransparent and faithful explanations. Post hoc methods such as saliency mapsmay fail to reflect a model's true decision process. Prototype-based reasoningoffers a more transparent alternative by grounding decisions in similarity tolearned representations of real ECG segments, enabling faithful, case-basedexplanations. We introduce ProtoECGNet, a prototype-based deep learning modelfor interpretable, multi-label ECG classification. ProtoECGNet employs astructured, multi-branch architecture that reflects clinical interpretationworkflows: it integrates a 1D CNN with global prototypes for rhythmclassification, a 2D CNN with time-localized prototypes for morphology-basedreasoning, and a 2D CNN with global prototypes for diffuse abnormalities. Eachbranch is trained with a prototype loss designed for multi-label learning,combining clustering, separation, diversity, and a novel contrastive loss thatencourages appropriate separation between prototypes of unrelated classes whileallowing clustering for frequently co-occurring diagnoses. We evaluateProtoECGNet on all 71 diagnostic labels from the PTB-XL dataset, demonstratingcompetitive performance relative to state-of-the-art black-box models whileproviding structured, case-based explanations. To assess prototype quality, weconduct a structured clinician review of the final model's projectedprototypes, finding that they are rated as representative and clear.ProtoECGNet shows that prototype learning can be effectively scaled to complex,multi-label time-series classification, offering a practical path towardtransparent and trustworthy deep learning models for clinical decision support.</description>
      <author>example@mail.com (Sahil Sethi, David Chen, Thomas Statchen, Michael C. Burkhart, Nipun Bhandari, Bashar Ramadan, Brett Beaulieu-Jones)</author>
      <guid isPermaLink="false">2504.08713v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning-Enhanced Robotic Subretinal Injection with Real-Time Retinal Motion Compensation</title>
      <link>http://arxiv.org/abs/2504.03939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种完全自动化的视网膜下注射系统，该系统通过结合术中光学相干断层扫描成像和基于深度学习的运动预测，以同步针头运动与视网膜位移，从而提高视网膜微手术的安全性和准确性。&lt;h4&gt;背景&lt;/h4&gt;视网膜下注射是治疗如年龄相关性黄斑变性等视网膜疾病的关键程序。然而，由于呼吸和心跳等生理因素引起的视网膜运动，对精确针头定位产生了显著影响，增加了视网膜色素上皮（RPE）受损的风险。&lt;h4&gt;目的&lt;/h4&gt;开发一种系统，能够同步针头运动与视网膜位移，减少视网膜下注射过程中的误差。&lt;h4&gt;方法&lt;/h4&gt;该系统集成了术中光学相干断层扫描（iOCT）成像和基于长短期记忆（LSTM）神经网络的运动预测。使用LSTM神经网络预测内部限制膜（ILM）运动，并优于基于快速傅里叶变换（FFT）的基线模型。此外，一个实时注册框架将针头尖端位置与机器人的坐标系对齐，并采用动态比例速度控制策略确保针头插入的平滑和自适应。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和离体开放式猪眼实验中，该系统实现了精确的运动同步和成功的视网膜下注射。实验在插入前阶段达到了平均跟踪误差低于16.4微米。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，人工智能驱动的机器人辅助系统具有提高视网膜微手术安全性和准确性的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Subretinal injection is a critical procedure for delivering therapeuticagents to treat retinal diseases such as age-related macular degeneration(AMD). However, retinal motion caused by physiological factors such asrespiration and heartbeat significantly impacts precise needle positioning,increasing the risk of retinal pigment epithelium (RPE) damage. This paperpresents a fully autonomous robotic subretinal injection system that integratesintraoperative optical coherence tomography (iOCT) imaging and deeplearning-based motion prediction to synchronize needle motion with retinaldisplacement. A Long Short-Term Memory (LSTM) neural network is used to predictinternal limiting membrane (ILM) motion, outperforming a Fast Fourier Transform(FFT)-based baseline model. Additionally, a real-time registration frameworkaligns the needle tip position with the robot's coordinate frame. Then, adynamic proportional speed control strategy ensures smooth and adaptive needleinsertion. Experimental validation in both simulation and ex vivo open-skyporcine eyes demonstrates precise motion synchronization and successfulsubretinal injections. The experiment achieves a mean tracking error below 16.4{\mu}m in pre-insertion phases. These results show the potential of AI-drivenrobotic assistance to improve the safety and accuracy of retinal microsurgery.</description>
      <author>example@mail.com (Tianle Wu, Mojtaba Esfandiari, Peiyao Zhang, Russell H. Taylor, Peter Gehlbach, Iulian Iordachita)</author>
      <guid isPermaLink="false">2504.03939v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
  <item>
      <title>Single-Input Multi-Output Model Merging: Leveraging Foundation Models for Dense Multi-Task Learning</title>
      <link>http://arxiv.org/abs/2504.11268v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了针对多任务模型中单输入多输出（SIMO）设置的模型合并方法，通过重新对齐合并后的编码器与任务特定解码器的特征表示来提升性能。&lt;h4&gt;背景&lt;/h4&gt;现有的模型合并方法主要针对单输入单输出（SISO）设置，而忽略了多任务场景中可能存在多个任务对同一样本进行处理的情况。&lt;h4&gt;目的&lt;/h4&gt;针对SIMO设置提出一种有效的模型合并方法，以提升多任务模型性能。&lt;h4&gt;方法&lt;/h4&gt;提出两种简单的修正方法，用于在模型合并后重新对齐特征表示。通过在NYUv2、Cityscapes和Taskonomy数据集的子集上进行实验验证方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;1. 对于多任务能力，任务算术是足够的；2. 合并后的编码器生成的表示需要与任务特定的头部重新对齐；3. 所提出的架构在性能上与传统多任务学习相媲美，但通过利用任务特定模型的存在，需要更少的样本和训练步骤。&lt;h4&gt;结论&lt;/h4&gt;本文提出的SIMO设置下的模型合并方法，在保持高性能的同时，计算效率高且灵活，能够在线下方式识别任务关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model merging is a flexible and computationally tractable approach to mergesingle-task checkpoints into a multi-task model. Prior work has solely focusedon constrained multi-task settings where there is a one-to-one mapping betweena sample and a task, overlooking the paradigm where multiple tasks may operateon the same sample, e.g., scene understanding. In this paper, we focus on themulti-task setting with single-input-multiple-outputs (SIMO) and show that itqualitatively differs from the single-input-single-output model mergingsettings studied in the literature due to the existence of task-specificdecoders and diverse loss objectives. We identify that existing model mergingmethods lead to significant performance degradation, primarily due torepresentation misalignment between the merged encoder and task-specificdecoders. We propose two simple and efficient fixes for the SIMO setting tore-align the feature representation after merging. Compared to jointfine-tuning, our approach is computationally effective and flexible, and shedslight into identifying task relationships in an offline manner. Experiments onNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) taskarithmetic suffices to enable multi-task capabilities; however, therepresentations generated by the merged encoder has to be re-aligned with thetask-specific heads; (2) the proposed architecture rivals traditionalmulti-task learning in performance but requires fewer samples and trainingsteps by leveraging the existence of task-specific models.</description>
      <author>example@mail.com (Juan Garcia Giraldo, Nikolaos Dimitriadis, Ke Wang, Pascal Frossard)</author>
      <guid isPermaLink="false">2504.11268v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>PARTFIELD: Learning 3D Feature Fields for Part Segmentation and Beyond</title>
      <link>http://arxiv.org/abs/2504.11451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://research.nvidia.com/labs/toronto-ai/partfield-release/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为PartField的前馈方法，用于学习基于部分的三维特征，能够捕获部分及其层次结构的一般概念，不依赖于预定义的模板或基于文本的名称，并适用于各种模态的开放世界三维形状。&lt;h4&gt;背景&lt;/h4&gt;现有方法在三维形状的部分分解中依赖于预定义的模板或文本名称，限制了模型的通用性和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法，能够有效地学习三维形状的部分特征，同时提高模型的运行时间和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;通过从标注数据集和大型无监督数据集上的图像分割中提取二维和三维部分提议，使用对比学习公式对模型进行训练，生成连续的特征场，该特征场可以聚类以产生层次化的部分分解。&lt;h4&gt;主要发现&lt;/h4&gt;与现有的无监督部分分割方法相比，PartField在准确性和速度方面均有显著提升，最高可达20%的准确度提升和多个数量级的速度提升。&lt;h4&gt;结论&lt;/h4&gt;PartField不仅能够实现单形状的部分分解，而且学习到的特征场在不同形状之间保持一致性，这有助于实现诸如共分割和对应关系等任务，并展示了这些通用、层次化和一致的三维特征场在多个应用中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;We propose PartField, a feedforward approach for learning part-based 3D features, which captures the general concept of parts and their hierarchy without relying on predefined templates or text-based names, and can be applied to open-world 3D shapes across various modalities. PartField requires only a 3D feedforward pass at inference time, significantly improving runtime and robustness compared to prior approaches. Our model is trained by distilling 2D and 3D part proposals from a mix of labeled datasets and image segmentations on large unsupervised datasets, via a contrastive learning formulation. It produces a continuous feature field which can be clustered to yield a hierarchical part decomposition. Comparisons show that PartField is up to 20% more accurate and often orders of magnitude faster than other recent class-agnostic part-segmentation methods. Beyond single-shape part decomposition, consistency in the learned field emerges across shapes, enabling tasks such as co-segmentation and correspondence, which we demonstrate in several applications of these general-purpose, hierarchical, and consistent 3D feature fields. Check our Webpage!https://research.nvidia.com/labs/toronto-ai/partfield-release/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose PartField, a feedforward approach for learning part-based 3Dfeatures, which captures the general concept of parts and their hierarchywithout relying on predefined templates or text-based names, and can be appliedto open-world 3D shapes across various modalities. PartField requires only a 3Dfeedforward pass at inference time, significantly improving runtime androbustness compared to prior approaches. Our model is trained by distilling 2Dand 3D part proposals from a mix of labeled datasets and image segmentations onlarge unsupervised datasets, via a contrastive learning formulation. Itproduces a continuous feature field which can be clustered to yield ahierarchical part decomposition. Comparisons show that PartField is up to 20%more accurate and often orders of magnitude faster than other recentclass-agnostic part-segmentation methods. Beyond single-shape partdecomposition, consistency in the learned field emerges across shapes, enablingtasks such as co-segmentation and correspondence, which we demonstrate inseveral applications of these general-purpose, hierarchical, and consistent 3Dfeature fields. Check our Webpage!https://research.nvidia.com/labs/toronto-ai/partfield-release/</description>
      <author>example@mail.com (Minghua Liu, Mikaela Angelina Uy, Donglai Xiang, Hao Su, Sanja Fidler, Nicholas Sharp, Jun Gao)</author>
      <guid isPermaLink="false">2504.11451v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>GC-GAT: Multimodal Vehicular Trajectory Prediction using Graph Goal Conditioning and Cross-context Attention</title>
      <link>http://arxiv.org/abs/2504.11150v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于车道图的车辆运动预测模型，通过融合多个上下文元素，实现了对未来车辆轨迹的预测。&lt;h4&gt;背景&lt;/h4&gt;车辆运动预测模型依赖于所提供的上下文信息，这些信息可以是静态的（如车道、交通标志等）或动态的（如交通参与者）。&lt;h4&gt;目的&lt;/h4&gt;研究如何提高运动预测模型的准确性。&lt;h4&gt;方法&lt;/h4&gt;模型采用编码器-交互器-解码器架构，使用轻量级的门控循环单元（GRU）编码场景上下文，交互器对编码的场景特征和图目标建议应用交叉注意力，解码器通过拉普拉斯混合密度网络从聚合编码中回归多模态轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;使用基于图的目标建议的交叉注意力提供了鲁棒的轨迹估计，因为模型学会了关注未来目标相关的场景元素。&lt;h4&gt;结论&lt;/h4&gt;在nuScenes运动预测数据集上评估，该模型实现了最先进的结果。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于车道图的车辆运动预测模型，该模型首先预测基于图的目标建议，然后通过跨多个上下文元素的交叉注意力将它们融合。我们遵循著名的编码器-交互器-解码器架构，其中编码器使用轻量级的门控循环单元（GRU）编码场景上下文，交互器对编码的场景特征和图目标建议应用交叉注意力，解码器通过拉普拉斯混合密度网络从聚合编码中回归多模态轨迹。使用基于图的目标建议的交叉注意力提供了鲁棒的轨迹估计，因为模型学会了关注未来目标相关的场景元素。我们在nuScenes运动预测数据集上评估了我们的工作，实现了最先进的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting future trajectories of surrounding vehicles heavily relies on whatcontextual information is given to a motion prediction model. The contextitself can be static (lanes, regulatory elements, etc) or dynamic (trafficparticipants). This paper presents a lane graph-based motion prediction modelthat first predicts graph-based goal proposals and later fuses them with crossattention over multiple contextual elements. We follow the famousencoder-interactor-decoder architecture where the encoder encodes scene contextusing lightweight Gated Recurrent Units, the interactor applies cross-contextattention over encoded scene features and graph goal proposals, and the decoderregresses multimodal trajectories via Laplacian Mixture Density Network fromthe aggregated encodings. Using cross-attention over graph-based goal proposalsgives robust trajectory estimates since the model learns to attend to futuregoal-relevant scene elements for the intended agent. We evaluate our work onnuScenes motion prediction dataset, achieving state-of-the-art results.</description>
      <author>example@mail.com (Mahir Gulzar, Yar Muhammad, Naveed Muhammad)</author>
      <guid isPermaLink="false">2504.11150v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Safe-Construct: Redefining Construction Safety Violation Recognition as 3D Multi-View Engagement Task</title>
      <link>http://arxiv.org/abs/2504.10880v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR Workshop 2025; Project Website:  https://Safe-Construct.github.io/Safe-Construct&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为Safe-Construct的框架，用于在建筑环境中识别安全违规行为，并通过3D多视角理解和合成数据生成技术，实现了可扩展且鲁棒的安全监控。&lt;h4&gt;背景&lt;/h4&gt;当前在计算机视觉领域，建筑环境中的安全违规识别研究不足，现有的模型主要依赖于2D目标检测，无法捕捉真实违规行为的复杂性。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的不足，提出了Safe-Construct框架，旨在改进安全违规行为的识别。&lt;h4&gt;方法&lt;/h4&gt;Safe-Construct将违规识别重新定义为3D多视角参与任务，利用场景级工人-物体上下文和3D空间理解。同时，提出了合成室内建筑场地生成器（SICSG）以创建多样化的可扩展训练数据。&lt;h4&gt;主要发现&lt;/h4&gt;Safe-Construct在四种违规类型上相对于现有最佳方法提高了7.6%的性能。在接近真实的环境中进行严格评估，包括四种违规、四种工人、14种物体，以及遮挡（工人-物体、工人-工人）和多变光照（背光、过曝、日光）等挑战条件。&lt;h4&gt;结论&lt;/h4&gt;Safe-Construct通过集成3D多视角空间理解和合成数据生成，为高风险行业的安全监控设定了新的基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译为：在建筑环境中识别安全违规行为至关重要，但在计算机视觉领域中仍处于探索阶段。现有的模型主要依赖于2D目标检测，由于以下原因，无法捕捉现实违规行为的复杂性：（i）将违规识别简化为目标检测的任务定义，（ii）在现实条件下的验证不足，（iii）缺乏标准基线，（iv）由于缺乏多样化的建筑场景合成数据生成器，可扩展性有限。为了解决这些挑战，我们引入了Safe-Construct，这是第一个将违规识别重新定义为3D多视角参与任务的框架，利用场景级的工人-物体上下文和3D空间理解。我们还提出了合成室内建筑场地生成器（SICSG）来创建多样化的可扩展训练数据，克服了数据限制。Safe-Construct在四种违规类型上相对于现有最佳方法实现了7.6%的性能提升。我们在接近真实的环境中对我们的方法进行了严格的评估，包括四种违规、四种工人、14种物体以及如遮挡（工人-物体、工人-工人）和多变光照（背光、过曝、日光）等挑战条件。通过集成3D多视角空间理解和合成数据生成，Safe-Construct为高风险行业的安全监控设定了新的基准。项目网站：https://Safe-Construct.github.io/Safe-Construct&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recognizing safety violations in construction environments is critical yetremains underexplored in computer vision. Existing models predominantly rely on2D object detection, which fails to capture the complexities of real-worldviolations due to: (i) an oversimplified task formulation treating violationrecognition merely as object detection, (ii) inadequate validation underrealistic conditions, (iii) absence of standardized baselines, and (iv) limitedscalability from the unavailability of synthetic dataset generators for diverseconstruction scenarios. To address these challenges, we introduceSafe-Construct, the first framework that reformulates violation recognition asa 3D multi-view engagement task, leveraging scene-level worker-object contextand 3D spatial understanding. We also propose the Synthetic Indoor ConstructionSite Generator (SICSG) to create diverse, scalable training data, overcomingdata limitations. Safe-Construct achieves a 7.6% improvement overstate-of-the-art methods across four violation types. We rigorously evaluateour approach in near-realistic settings, incorporating four violations, fourworkers, 14 objects, and challenging conditions like occlusions (worker-object,worker-worker) and variable illumination (back-lighting, overexposure,sunlight). By integrating 3D multi-view spatial understanding and syntheticdata generation, Safe-Construct sets a new benchmark for scalable and robustsafety monitoring in high-risk industries. Project Website:https://Safe-Construct.github.io/Safe-Construct</description>
      <author>example@mail.com (Aviral Chharia, Tianyu Ren, Tomotake Furuhata, Kenji Shimada)</author>
      <guid isPermaLink="false">2504.10880v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>OpenTuringBench: An Open-Model-based Benchmark and Framework for Machine-Generated Text Detection and Attribution</title>
      <link>http://arxiv.org/abs/2504.11369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review with ARR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出OpenTuringBench，一个基于OLLMs的新基准，用于训练和评估机器生成文本检测器，并在图灵测试和作者归属问题中进行评估。&lt;h4&gt;背景&lt;/h4&gt;OLLMs在生成AI应用中越来越受欢迎，但其输出检测带来了新的挑战。&lt;h4&gt;目的&lt;/h4&gt;设计OpenTuringBench，以训练和评估机器生成文本检测器，解决OLLMs输出检测的挑战。&lt;h4&gt;方法&lt;/h4&gt;OpenTuringBench关注一组代表性的OLLMs，并包括多个具有挑战性的评估任务，如人类/机器操作文本、域外文本和来自未见模型的文本。同时提供OTBDetector，一个对比学习框架，用于检测和归因基于OLLMs的机器生成文本。&lt;h4&gt;主要发现&lt;/h4&gt;OpenTuringBench任务的相关性和难度各不相同，检测器在各个任务中表现出显著的能力，并优于大多数现有检测器。&lt;h4&gt;结论&lt;/h4&gt;OpenTuringBench是一个有效的工具，用于评估和训练机器生成文本检测器，资源可在Hugging Face仓库找到。&lt;h4&gt;翻译&lt;/h4&gt;Open Large Language Models (OLLMs) 在生成AI应用中越来越被利用，这给检测它们的输出带来了新的挑战。我们提出了基于OLLMs的新基准OpenTuringBench，用于训练和评估机器生成文本检测器在图灵测试和作者归属问题上的表现。OpenTuringBench专注于一组代表性的OLLMs，并具有一系列具有挑战性的评估任务，包括人类/机器操作文本、域外文本和来自之前未见模型的文本。我们还提供了OTBDetector，一个对比学习框架，用于检测和归因基于OLLMs的机器生成文本。结果表明，OpenTuringBench任务的相关性和难度各不相同，我们的检测器在各个任务中表现出显著的能力，并优于大多数现有检测器。资源可在Hugging Face仓库 https://huggingface.co/datasets/MLNTeam-Unical/OpenTuringBench 找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open Large Language Models (OLLMs) are increasingly leveraged in generativeAI applications, posing new challenges for detecting their outputs. We proposeOpenTuringBench, a new benchmark based on OLLMs, designed to train and evaluatemachine-generated text detectors on the Turing Test and Authorship Attributionproblems. OpenTuringBench focuses on a representative set of OLLMs, andfeatures a number of challenging evaluation tasks, includinghuman/machine-manipulated texts, out-of-domain texts, and texts from previouslyunseen models. We also provide OTBDetector, a contrastive learning framework todetect and attribute OLLM-based machine-generated texts. Results highlight therelevance and varying degrees of difficulty of the OpenTuringBench tasks, withour detector achieving remarkable capabilities across the various tasks andoutperforming most existing detectors. Resources are available on theOpenTuringBench Hugging Face repository athttps://huggingface.co/datasets/MLNTeam-Unical/OpenTuringBench</description>
      <author>example@mail.com (Lucio La Cava, Andrea Tagarelli)</author>
      <guid isPermaLink="false">2504.11369v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Remote Sensing: An Analysis of MLLMs for Object Localization</title>
      <link>http://arxiv.org/abs/2504.10727v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, CVPR MORSE Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多模态大型语言模型（MLLMs）在计算机视觉领域的应用，特别是其在地球观测（EO）图像处理任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在计算机视觉任务中取得了显著成果，尤其在零样本设置下。然而，它们在处理地球观测图像等分布外领域时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;分析最新MLLMs在地球观测对象定位任务上的表现，并探讨如何优化这些模型。&lt;h4&gt;方法&lt;/h4&gt;对特定训练以包含细粒度空间推理能力的MLLMs进行基准测试，并讨论了提示选择、地面样本距离（GSD）优化和分析失败案例。&lt;h4&gt;主要发现&lt;/h4&gt;这些模型在特定设置下表现良好，适合零样本场景。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果对评估MLLMs是否适合特定EO定位任务以及如何优化它们具有重要价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态大型语言模型（MLLMs）已经改变了计算机视觉的格局，在广泛的任务中取得了令人印象深刻的成果，尤其是在零样本设置下。不幸的是，它们的强大性能并不能总是转移到分布外领域，如地球观测（EO）图像。先前的研究表明，MLLMs在图像描述和场景理解等某些EO任务上表现出色，而在需要更细粒度空间推理的任务，如对象定位上则表现不佳。然而，MLLMs正在快速发展，见解迅速过时。在这项工作中，我们分析了最近专门训练以包括细粒度空间推理能力的MLLMs，并在EO对象定位任务上对它们进行了基准测试。我们证明了这些模型在特定设置下表现良好，使它们非常适合零样本场景。此外，我们还提供了关于提示选择、地面样本距离（GSD）优化和分析失败案例的详细讨论。我们希望这项工作将证明对其他人评估MLLM是否适合给定的EO定位任务以及如何优化它们是有价值的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal large language models (MLLMs) have altered the landscape ofcomputer vision, obtaining impressive results across a wide range of tasks,especially in zero-shot settings. Unfortunately, their strong performance doesnot always transfer to out-of-distribution domains, such as earth observation(EO) imagery. Prior work has demonstrated that MLLMs excel at some EO tasks,such as image captioning and scene understanding, while failing at tasks thatrequire more fine-grained spatial reasoning, such as object localization.However, MLLMs are advancing rapidly and insights quickly become out-dated. Inthis work, we analyze more recent MLLMs that have been explicitly trained toinclude fine-grained spatial reasoning capabilities, benchmarking them on EOobject localization tasks. We demonstrate that these models are performant incertain settings, making them well suited for zero-shot scenarios.Additionally, we provide a detailed discussion focused on prompt selection,ground sample distance (GSD) optimization, and analyzing failure cases. We hopethat this work will prove valuable as others evaluate whether an MLLM is wellsuited for a given EO localization task and how to optimize it.</description>
      <author>example@mail.com (Darryl Hannan, John Cooper, Dylan White, Timothy Doster, Henry Kvinge, Yijing Watkins)</author>
      <guid isPermaLink="false">2504.10727v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Subset-Contrastive Multi-Omics Network Embedding</title>
      <link>http://arxiv.org/abs/2504.11321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SCONE的方法，用于多组学数据的网络嵌入分析，旨在解决现有方法在单细胞数据分析中的内存和空间密集问题，并提高多组学网络分析的有效性。&lt;h4&gt;背景&lt;/h4&gt;网络分析在组学数据中应用广泛，但许多方法在单细胞数据分析中内存和空间需求大，且多组学网络分析通常依赖于基于相似性的网络，缺乏结构上离散的拓扑结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为Subset-Contrastive multi-Omics Network Embedding (SCONE)的方法，通过可扩展的子图对比学习技术在大数据集上应用对比学习技术，以实现可扩展和有效的分析。&lt;h4&gt;方法&lt;/h4&gt;SCONE方法利用网络方法中成对相似性的基础，将其转化为优势，旨在实现可扩展和有效的分析。&lt;h4&gt;主要发现&lt;/h4&gt;SCONE在细胞类型聚类中表现出协同的多组学整合能力，并在批量多组学整合场景中表现出与现有最佳方法相当的性能，尽管使用了原始数据的有限视图。&lt;h4&gt;结论&lt;/h4&gt;SCONE方法为组学数据应用子集对比方法提供了新的思路，并有望促进进一步的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Motivation: Network-based analyses of omics data are widely used, and while many of these methods have been adapted to single-cell scenarios, they often remain memory- and space-intensive. As a result, they are better suited to batch data or smaller datasets. Furthermore, the application of network-based methods in multi-omics often relies on similarity-based networks, which lack structurally-discrete topologies. This limitation may reduce the effectiveness of graph-based methods that were initially designed for topologies with better defined structures. Results: We propose Subset-Contrastive multi-Omics Network Embedding (SCONE), a method that employs contrastive learning techniques on large datasets through a scalable subgraph contrastive approach. By exploiting the pairwise similarity basis of many network-based omics methods, we transformed this characteristic into a strength, developing an approach that aims to achieve scalable and effective analysis. Our method demonstrates synergistic omics integration for cell type clustering in single-cell data. Additionally, we evaluate its performance in a bulk multi-omics integration scenario, where SCONE performs comparable to the state-of-the-art despite utilising limited views of the original data. We anticipate that our findings will motivate further research into the use of subset contrastive methods for omics data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivation: Network-based analyses of omics data are widely used, and whilemany of these methods have been adapted to single-cell scenarios, they oftenremain memory- and space-intensive. As a result, they are better suited tobatch data or smaller datasets. Furthermore, the application of network-basedmethods in multi-omics often relies on similarity-based networks, which lackstructurally-discrete topologies. This limitation may reduce the effectivenessof graph-based methods that were initially designed for topologies with betterdefined structures. Results: We propose Subset-Contrastive multi-Omics NetworkEmbedding (SCONE), a method that employs contrastive learning techniques onlarge datasets through a scalable subgraph contrastive approach. By exploitingthe pairwise similarity basis of many network-based omics methods, wetransformed this characteristic into a strength, developing an approach thataims to achieve scalable and effective analysis. Our method demonstratessynergistic omics integration for cell type clustering in single-cell data.Additionally, we evaluate its performance in a bulk multi-omics integrationscenario, where SCONE performs comparable to the state-of-the-art despiteutilising limited views of the original data. We anticipate that our findingswill motivate further research into the use of subset contrastive methods foromics data.</description>
      <author>example@mail.com (Pedro Henrique da Costa Avelar, Min Wu, Sophia Tsoka)</author>
      <guid isPermaLink="false">2504.11321v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Seedream 3.0 Technical Report</title>
      <link>http://arxiv.org/abs/2504.11346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Seedream 3.0 Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Seedream 3.0，一个高性能的中英双语图像生成基础模型。&lt;h4&gt;背景&lt;/h4&gt;Seedream 3.0是在解决Seedream 2.0中存在的问题的基础上开发的，这些问题包括复杂提示的匹配、精细的字体生成、视觉效果和真实感不理想以及有限的图像分辨率。&lt;h4&gt;目的&lt;/h4&gt;通过改进数据构建到模型部署的整个流程，提高Seedream 3.0的性能。&lt;h4&gt;方法&lt;/h4&gt;在数据层面，使用缺陷感知训练范式和双轴协作数据采样框架将数据集翻倍。在预训练阶段，采用混合分辨率训练、跨模态RoPE、表征对齐损失和分辨率感知时间步采样等有效技术。在训练后阶段，使用多样化的审美描述和基于VLM的奖励模型以及缩放功能。此外，Seedream 3.0采用了一种新的加速范式，通过使用一致的噪声预期和重要性感知时间步采样，在保持图像质量的同时实现了4到8倍的速度提升。&lt;h4&gt;主要发现&lt;/h4&gt;Seedream 3.0在Seedream 2.0的基础上实现了显著改进，特别是在复杂的中文文字渲染能力上，这对于专业字体生成非常重要。此外，它提供原生的高分辨率输出（高达2K），能够生成高视觉质量的图像。&lt;h4&gt;结论&lt;/h4&gt;Seedream 3.0在提高图像生成性能和视觉质量方面取得了重要进展，特别是在处理复杂提示和字体生成方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Seedream 3.0, a high-performance Chinese-English bilingual imagegeneration foundation model. We develop several technical improvements toaddress existing challenges in Seedream 2.0, including alignment withcomplicated prompts, fine-grained typography generation, suboptimal visualaesthetics and fidelity, and limited image resolutions. Specifically, theadvancements of Seedream 3.0 stem from improvements across the entire pipeline,from data construction to model deployment. At the data stratum, we double thedataset using a defect-aware training paradigm and a dual-axis collaborativedata-sampling framework. Furthermore, we adopt several effective techniquessuch as mixed-resolution training, cross-modality RoPE, representationalignment loss, and resolution-aware timestep sampling in the pre-trainingphase. During the post-training stage, we utilize diversified aestheticcaptions in SFT, and a VLM-based reward model with scaling, thereby achievingoutputs that well align with human preferences. Furthermore, Seedream 3.0pioneers a novel acceleration paradigm. By employing consistent noiseexpectation and importance-aware timestep sampling, we achieve a 4 to 8 timesspeedup while maintaining image quality. Seedream 3.0 demonstrates significantimprovements over Seedream 2.0: it enhances overall capabilities, in particularfor text-rendering in complicated Chinese characters which is important toprofessional typography generation. In addition, it provides nativehigh-resolution output (up to 2K), allowing it to generate images with highvisual quality.</description>
      <author>example@mail.com (Yu Gao, Lixue Gong, Qiushan Guo, Xiaoxia Hou, Zhichao Lai, Fanshi Li, Liang Li, Xiaochen Lian, Chao Liao, Liyang Liu, Wei Liu, Yichun Shi, Shiqi Sun, Yu Tian, Zhi Tian, Peng Wang, Rui Wang, Xuanda Wang, Xun Wang, Ye Wang, Guofeng Wu, Jie Wu, Xin Xia, Xuefeng Xiao, Zhonghua Zhai, Xinyu Zhang, Qi Zhang, Yuwei Zhang, Shijia Zhao, Jianchao Yang, Weilin Huang)</author>
      <guid isPermaLink="false">2504.11346v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>TMCIR: Token Merge Benefits Composed Image Retrieval</title>
      <link>http://arxiv.org/abs/2504.10995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2310.05473 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TMCIR的新框架，用于改进组合图像检索（CIR），通过两个关键创新解决了视觉和文本信息融合的挑战。&lt;h4&gt;背景&lt;/h4&gt;组合图像检索（CIR）通过结合参考图像和描述所需修改的文本进行检索，但现有的跨模态特征融合方法在意图解释上存在固有的偏差。&lt;h4&gt;目的&lt;/h4&gt;提出TMCIR框架，以解决CIR中视觉和文本信息融合的挑战，并提高检索结果的准确性。&lt;h4&gt;方法&lt;/h4&gt;TMCIR框架包括两个关键创新：1）意图感知跨模态对齐，通过使用扩散模型合成的伪目标图像来微调CLIP编码器；2）自适应标记融合，通过比较自适应标记融合特征与目标图像来进一步微调所有编码器。&lt;h4&gt;主要发现&lt;/h4&gt;在Fashion-IQ和CIRR数据集上的实验表明，TMCIR在捕捉细微用户意图方面显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;TMCIR框架通过改进意图感知和自适应融合，提高了组合图像检索的准确性，特别是在捕捉用户细微意图方面表现突出。&lt;h4&gt;翻译&lt;/h4&gt;Composed Image Retrieval (CIR) retrieves target images using a multi-modal query that combines a reference image with text describing desired modifications. The primary challenge is effectively fusing this visual and textual information. Current cross-modal feature fusion approaches for CIR exhibit an inherent bias in intention interpretation. These methods tend to disproportionately emphasize either the reference image features (visual-dominant fusion) or the textual modification intent (text-dominant fusion through image-to-text conversion). Such an imbalanced representation often fails to accurately capture and reflect the actual search intent of the user in the retrieval results. To address this challenge, we propose TMCIR, a novel framework that advances composed image retrieval through two key innovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIP encoders contrastively using intent-reflecting pseudo-target images, synthesized from reference images and textual descriptions via a diffusion model. This step enhances the encoder ability of text to capture nuanced intents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tune all encoders contrastively by comparing adaptive token-fusion features with the target image. This mechanism dynamically balances visual and textual representations within the contrastive learning pipeline, optimizing the composed feature for retrieval. Extensive experiments on Fashion-IQ and CIRR datasets demonstrate that TMCIR significantly outperforms state-of-the-art methods, particularly in capturing nuanced user intent.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Composed Image Retrieval (CIR) retrieves target images using a multi-modalquery that combines a reference image with text describing desiredmodifications. The primary challenge is effectively fusing this visual andtextual information. Current cross-modal feature fusion approaches for CIRexhibit an inherent bias in intention interpretation. These methods tend todisproportionately emphasize either the reference image features(visual-dominant fusion) or the textual modification intent (text-dominantfusion through image-to-text conversion). Such an imbalanced representationoften fails to accurately capture and reflect the actual search intent of theuser in the retrieval results. To address this challenge, we propose TMCIR, anovel framework that advances composed image retrieval through two keyinnovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIPencoders contrastively using intent-reflecting pseudo-target images,synthesized from reference images and textual descriptions via a diffusionmodel. This step enhances the encoder ability of text to capture nuancedintents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tuneall encoders contrastively by comparing adaptive token-fusion features with thetarget image. This mechanism dynamically balances visual and textualrepresentations within the contrastive learning pipeline, optimizing thecomposed feature for retrieval. Extensive experiments on Fashion-IQ and CIRRdatasets demonstrate that TMCIR significantly outperforms state-of-the-artmethods, particularly in capturing nuanced user intent.</description>
      <author>example@mail.com (Chaoyang Wang, Zeyu Zhang, Long Teng, Zijun Li, Shichao Kan)</author>
      <guid isPermaLink="false">2504.10995v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>AFiRe: Anatomy-Driven Self-Supervised Learning for Fine-Grained Representation in Radiographic Images</title>
      <link>http://arxiv.org/abs/2504.10972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AFiRe是一个用于增强放射图像分析的细粒度表示的自监督框架，它通过结合解剖一致性和Vision Transformer的独特处理方式来改进现有的自监督方法。&lt;h4&gt;背景&lt;/h4&gt;当前自监督方法如对比学习主要关注全局区分，忽视了准确放射学分析所需的细粒度解剖细节。&lt;h4&gt;目的&lt;/h4&gt;提出AFiRe框架以解决现有方法的不足，提高放射图像分析的准确性。&lt;h4&gt;方法&lt;/h4&gt;AFiRe执行两种自监督方案：(i) 基于解剖结构的token对比学习；(ii) 像素级异常去除和修复。此外，引入了合成病变掩码以增强解剖多样性。&lt;h4&gt;主要发现&lt;/h4&gt;AFiRe实现了以下发现：(i) 提供了稳健的解剖区分，与最先进的对比学习方法相比，特征聚类更紧密；(ii) 在多标签分类任务中展现出优越的泛化能力；(iii) 仅使用图像级注释即可实现精确的异常检测。&lt;h4&gt;结论&lt;/h4&gt;AFiRe能够有效地增强放射图像分析的细粒度表示，提高了解剖区分和异常检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1609/aaai.v39i18.34091&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current self-supervised methods, such as contrastive learning, predominantlyfocus on global discrimination, neglecting the critical fine-grained anatomicaldetails required for accurate radiographic analysis. To address this challenge,we propose an Anatomy-driven self-supervised framework for enhancingFine-grained Representation in radiographic image analysis (AFiRe). The coreidea of AFiRe is to align the anatomical consistency with the uniquetoken-processing characteristics of Vision Transformer. Specifically, AFiResynergistically performs two self-supervised schemes: (i) Token-wiseanatomy-guided contrastive learning, which aligns image tokens based onstructural and categorical consistency, thereby enhancing fine-grainedspatial-anatomical discrimination; (ii) Pixel-level anomaly-removalrestoration, which particularly focuses on local anomalies, thereby refiningthe learned discrimination with detailed geometrical information. Additionally,we propose Synthetic Lesion Mask to enhance anatomical diversity whilepreserving intra-consistency, which is typically corrupted by traditional dataaugmentations, such as Cropping and Affine transformations. Experimentalresults show that AFiRe: (i) provides robust anatomical discrimination,achieving more cohesive feature clusters compared to state-of-the-artcontrastive learning methods; (ii) demonstrates superior generalization,surpassing 7 radiography-specific self-supervised methods in multi-labelclassification tasks with limited labeling; and (iii) integrates fine-grainedinformation, enabling precise anomaly detection using only image-levelannotations.</description>
      <author>example@mail.com (Yihang Liu, Lianghua He, Ying Wen, Longzhen Yang, Hongzhou Chen)</author>
      <guid isPermaLink="false">2504.10972v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>How to Enhance Downstream Adversarial Robustness (almost) without Touching the Pre-Trained Foundation Model?</title>
      <link>http://arxiv.org/abs/2504.10850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 2 figures, 12 tables. Include 10 pages of appendices&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种提高下游任务鲁棒性的方法，无需更新或访问基础模型的权重。&lt;h4&gt;背景&lt;/h4&gt;随着强大基础模型的出现，预训练-微调范式越来越流行。然而，由于对抗训练的计算复杂性高，无法对基础模型进行微调以提高其在下游任务上的鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;在不更新/访问基础模型权重的情况下提高下游任务的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;从鲁棒性继承文献（Kim et al., 2020）中受到启发，通过理论调查，确定了鲁棒对比学习与监督学习的对抗鲁棒性之间的紧密关系。设计了一种简单而有效的鲁棒自动编码器作为数据预处理方法，在将数据输入基础模型之前使用。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的方法在提高下游任务的鲁棒性方面是有效的，验证了特征鲁棒性（由小的对抗对比损失隐含）与下游任务鲁棒性之间的联系。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高下游任务的鲁棒性，同时保持对基础模型的零访问。&lt;h4&gt;翻译&lt;/h4&gt;With the rise of powerful foundation models, a pre-training-fine-tuning paradigm becomes increasingly popular these days: A foundation model is pre-trained using a huge amount of data from various sources, and then the downstream users only need to fine-tune and adapt it to specific downstream tasks. However, due to the high computation complexity of adversarial training, it is not feasible to fine-tune the foundation model to improve its robustness on the downstream task. Observing the above challenge, we want to improve the downstream robustness without updating/accessing the weights in the foundation model. Inspired from existing literature in robustness inheritance (Kim et al., 2020), through theoretical investigation, we identify a close relationship between robust contrastive learning with the adversarial robustness of supervised learning. To further validate and utilize this theoretical insight, we design a simple-yet-effective robust auto-encoder as a data pre-processing method before feeding the data into the foundation model. The proposed approach has zero access to the foundation model when training the robust auto-encoder. Extensive experiments demonstrate the effectiveness of the proposed method in improving the robustness of downstream tasks, verifying the connection between the feature robustness (implied by small adversarial contrastive loss) and the robustness of the downstream task.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rise of powerful foundation models, a pre-training-fine-tuningparadigm becomes increasingly popular these days: A foundation model ispre-trained using a huge amount of data from various sources, and then thedownstream users only need to fine-tune and adapt it to specific downstreamtasks. However, due to the high computation complexity of adversarial training,it is not feasible to fine-tune the foundation model to improve its robustnesson the downstream task. Observing the above challenge, we want to improve thedownstream robustness without updating/accessing the weights in the foundationmodel. Inspired from existing literature in robustness inheritance (Kim et al.,2020), through theoretical investigation, we identify a close relationshipbetween robust contrastive learning with the adversarial robustness ofsupervised learning. To further validate and utilize this theoretical insight,we design a simple-yet-effective robust auto-encoder as a data pre-processingmethod before feeding the data into the foundation model. The proposed approachhas zero access to the foundation model when training the robust auto-encoder.Extensive experiments demonstrate the effectiveness of the proposed method inimproving the robustness of downstream tasks, verifying the connection betweenthe feature robustness (implied by small adversarial contrastive loss) and therobustness of the downstream task.</description>
      <author>example@mail.com (Meiqi Liu, Zhuoqun Huang, Yue Xing)</author>
      <guid isPermaLink="false">2504.10850v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning</title>
      <link>http://arxiv.org/abs/2504.11195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为R-TPT的鲁棒测试时提示调优方法，用于减轻视觉语言模型在推理阶段的对抗攻击影响，并通过实验证明了其有效性。&lt;h4&gt;背景&lt;/h4&gt;视觉语言模型（如CLIP）因其流行而成为基础模型，但它们存在固有脆弱性，且使用开源模型的选择有限，导致对抗攻击风险较高。&lt;h4&gt;目的&lt;/h4&gt;提出R-TPT方法，旨在在不要求标签训练数据的情况下增强对抗攻击防御，并提高推理任务的灵活性。&lt;h4&gt;方法&lt;/h4&gt;R-TPT通过重新定义边缘熵目标函数，并引入基于可靠性的可插入式加权集成策略，以增强防御能力。&lt;h4&gt;主要发现&lt;/h4&gt;R-TPT在广泛使用的基准测试和多种攻击中表现出有效性，且无需标签训练数据。&lt;h4&gt;结论&lt;/h4&gt;R-TPT是一种有效的对抗攻击防御方法，适用于视觉语言模型，且对推理任务具有高度灵活性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉语言模型（VLMs），如CLIP，作为基础模型已经获得了显著的流行度，为了提升其在下游任务上的性能，已经开发了许多微调方法。然而，由于它们固有的脆弱性和从有限的开放源代码模型中进行选择的常见做法，VLMs相对于传统的视觉模型面临更高的对抗攻击风险。现有的防御技术通常依赖于训练过程中的对抗微调，这需要标签数据和缺乏对下游任务的灵活性。为了解决这些限制，我们提出了鲁棒测试时提示调优（R-TPT），它在推理阶段减轻了对抗攻击的影响。我们首先通过消除在对抗条件下引起冲突的项，仅保留点熵最小化，重新定义了经典的边缘熵目标函数。此外，我们引入了一种基于可靠性的可插入式加权集成策略，它通过聚合可靠的增强视图中的有用信息来加强防御。R-TPT在不要求标签训练数据的同时，提高了对抗攻击防御能力，并为推理任务提供了高度灵活性。在广泛使用的基准测试和多种攻击上的大量实验证明了R-TPT的有效性。代码可在https://github.com/TomSheng21/R-TPT上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models (VLMs), such as CLIP, have gained significantpopularity as foundation models, with numerous fine-tuning methods developed toenhance performance on downstream tasks. However, due to their inherentvulnerability and the common practice of selecting from a limited set ofopen-source models, VLMs suffer from a higher risk of adversarial attacks thantraditional vision models. Existing defense techniques typically rely onadversarial fine-tuning during training, which requires labeled data and lacksof flexibility for downstream tasks. To address these limitations, we proposerobust test-time prompt tuning (R-TPT), which mitigates the impact ofadversarial attacks during the inference stage. We first reformulate theclassic marginal entropy objective by eliminating the term that introducesconflicts under adversarial conditions, retaining only the pointwise entropyminimization. Furthermore, we introduce a plug-and-play reliability-basedweighted ensembling strategy, which aggregates useful information from reliableaugmented views to strengthen the defense. R-TPT enhances defense againstadversarial attacks without requiring labeled training data while offering highflexibility for inference tasks. Extensive experiments on widely usedbenchmarks with various attacks demonstrate the effectiveness of R-TPT. Thecode is available in https://github.com/TomSheng21/R-TPT.</description>
      <author>example@mail.com (Lijun Sheng, Jian Liang, Zilei Wang, Ran He)</author>
      <guid isPermaLink="false">2504.11195v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data</title>
      <link>http://arxiv.org/abs/2504.11172v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TerraMesh是一个全球多样化的多模态数据集，结合了光学、合成孔径雷达、高程和土地覆盖模态，旨在通过利用大量未标记数据来学习灵活、高效的表示。&lt;h4&gt;背景&lt;/h4&gt;现有的公共数据集在规模、地理覆盖范围或传感器多样性方面通常有限。&lt;h4&gt;目的&lt;/h4&gt;引入TerraMesh数据集，以促进大规模预训练和鲁棒的跨模态相关性学习。&lt;h4&gt;方法&lt;/h4&gt;TerraMesh包括超过900万个样本，具有八个时空对齐的模态，并提供了详细的数据处理步骤、全面的数据统计和实证证据。&lt;h4&gt;主要发现&lt;/h4&gt;在TerraMesh上预训练的模型性能得到了提高。&lt;h4&gt;结论&lt;/h4&gt;TerraMesh数据集将以许可协议的形式公开提供。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大规模地球观测基础模型可以通过利用大量未标记数据来学习灵活、高效的表示。然而，现有的公共数据集在规模、地理覆盖范围或传感器多样性方面通常有限。我们引入了TerraMesh，这是一个新的全球多样化的多模态数据集，结合了光学、合成孔径雷达、高程和土地覆盖模态，以分析准备数据格式。TerraMesh包括超过900万个样本，具有八个时空对齐的模态，使大规模预训练成为可能，并促进了鲁棒的跨模态相关性学习。我们提供了详细的数据处理步骤、全面的数据统计和实证证据，证明了在TerraMesh上预训练的模型性能得到提高。该数据集将以许可协议的形式公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale foundation models in Earth Observation can learn versatile,label-efficient representations by leveraging massive amounts of unlabeleddata. However, existing public datasets are often limited in scale, geographiccoverage, or sensor variety. We introduce TerraMesh, a new globally diverse,multimodal dataset combining optical, synthetic aperture radar, elevation, andland-cover modalities in an Analysis-Ready Data format. TerraMesh includes over9 million samples with eight spatiotemporal aligned modalities, enablinglarge-scale pre-training and fostering robust cross-modal correlation learning.We provide detailed data processing steps, comprehensive statistics, andempirical evidence demonstrating improved model performance when pre-trained onTerraMesh. The dataset will be made publicly available with a permissivelicense.</description>
      <author>example@mail.com (Benedikt Blumenstiel, Paolo Fraccaro, Valerio Marsocci, Johannes Jakubik, Stefano Maurogiovanni, Mikolaj Czerkawski, Rocco Sedona, Gabriele Cavallaro, Thomas Brunschwiler, Juan Bernabe-Moreno, Nicolas Longépé)</author>
      <guid isPermaLink="false">2504.11172v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>TerraMind: Large-Scale Generative Multimodality for Earth Observation</title>
      <link>http://arxiv.org/abs/2504.11171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TerraMind是一种新的地球观测（EO）生成式多模态基础模型，首次实现了任意模态之间的生成。&lt;h4&gt;背景&lt;/h4&gt;目前的多模态模型在地球观测领域存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出TerraMind模型，以提升地球观测数据的处理能力。&lt;h4&gt;方法&lt;/h4&gt;TerraMind在双尺度表示上预训练，结合了跨模态的标记级和像素级数据。在标记级别，TerraMind编码高层上下文信息以学习跨模态关系；在像素级别，利用精细的表示来捕捉关键的空间细微差别。模型在包含九种地理空间模态的全球大规模数据集上进行了预训练。&lt;h4&gt;主要发现&lt;/h4&gt;TerraMind的双尺度早期融合方法为地球观测解锁了零样本和少样本应用；TerraMind引入了“Thinking-in-Modalities”（TiM）能力，在微调和推理过程中生成额外的数据以提高模型输出；TerraMind在地球观测社区标准基准（如PANGAEA）上实现了超越现有最佳性能。&lt;h4&gt;结论&lt;/h4&gt;TerraMind是一个开放源代码的项目，其预训练数据集、模型权重和代码以许可协议开放。&lt;h4&gt;翻译&lt;/h4&gt;We present TerraMind, the first any-to-any generative, multimodal foundation model for Earth observation (EO). Unlike other multimodal models, TerraMind is pretrained on dual-scale representations combining both token-level and pixel-level data across modalities. On a token level, TerraMind encodes high-level contextual information to learn cross-modal relationships, while on a pixel level, TerraMind leverages fine-grained representations to capture critical spatial nuances. We pretrained TerraMind on nine geospatial modalities of a global, large-scale dataset. In this paper, we demonstrate that (i) TerraMind's dual-scale early fusion approach unlocks a range of zero-shot and few-shot applications for Earth observation, (ii) TerraMind introduces 'Thinking-in-Modalities' (TiM) -- the capability of generating additional artificial data during finetuning and inference to improve the model output -- and (iii) TerraMind achieves beyond state-of-the-art performance in community-standard benchmarks for EO like PANGAEA. The pretraining dataset, the model weights, and our code is open-sourced under a permissive license.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present TerraMind, the first any-to-any generative, multimodal foundationmodel for Earth observation (EO). Unlike other multimodal models, TerraMind ispretrained on dual-scale representations combining both token-level andpixel-level data across modalities. On a token level, TerraMind encodeshigh-level contextual information to learn cross-modal relationships, while ona pixel level, TerraMind leverages fine-grained representations to capturecritical spatial nuances. We pretrained TerraMind on nine geospatial modalitiesof a global, large-scale dataset. In this paper, we demonstrate that (i)TerraMind's dual-scale early fusion approach unlocks a range of zero-shot andfew-shot applications for Earth observation, (ii) TerraMind introduces"Thinking-in-Modalities" (TiM) -- the capability of generating additionalartificial data during finetuning and inference to improve the model output --and (iii) TerraMind achieves beyond state-of-the-art performance incommunity-standard benchmarks for EO like PANGAEA. The pretraining dataset, themodel weights, and our code is open-sourced under a permissive license.</description>
      <author>example@mail.com (Johannes Jakubik, Felix Yang, Benedikt Blumenstiel, Erik Scheurer, Rocco Sedona, Stefano Maurogiovanni, Jente Bosmans, Nikolaos Dionelis, Valerio Marsocci, Niklas Kopp, Rahul Ramachandran, Paolo Fraccaro, Thomas Brunschwiler, Gabriele Cavallaro, Juan Bernabe-Moreno, Nicolas Longépé)</author>
      <guid isPermaLink="false">2504.11171v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Zero-Shot Whole-Body Humanoid Control via Behavioral Foundation Models</title>
      <link>http://arxiv.org/abs/2504.11054v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的无监督强化学习算法，旨在解决现有方法在复杂环境中的局限性。&lt;h4&gt;背景&lt;/h4&gt;尽管无监督强化学习取得了进展，但现有方法存在需要针对每个下游任务运行RL过程、需要高质量的数据集以及预训练策略与下游任务相关性差等问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的算法，通过模仿未标记行为数据集的轨迹来正则化无监督强化学习。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为“前向-后向表示与条件策略正则化”的方法，该方法训练前向-后向表示来嵌入未标记轨迹到与状态、奖励和政策表示相同的潜在空间，并使用一个潜在条件判别器来鼓励策略“覆盖”未标记行为数据集中的状态。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够学习到与数据集中的行为良好对齐的策略，同时保持基于奖励和模仿任务的零样本泛化能力。&lt;h4&gt;结论&lt;/h4&gt;在一个人形控制问题中，该方法通过仅利用观察数据集，训练了Meta Motivo，这是第一个可以提示解决包括运动跟踪、目标到达和奖励优化在内的各种全身任务的类人形行为基础模型。该模型能够表达类似人类的行为，并在性能上优于最先进的无监督强化学习和基于模型的基线方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的无监督强化学习算法，旨在解决现有方法在复杂环境中的局限性。尽管无监督强化学习取得了进展，但现有方法存在需要针对每个下游任务运行RL过程、需要高质量的数据集以及预训练策略与下游任务相关性差等问题。本文提出了一种名为“前向-后向表示与条件策略正则化”的方法，该方法训练前向-后向表示来嵌入未标记轨迹到与状态、奖励和政策表示相同的潜在空间，并使用一个潜在条件判别器来鼓励策略“覆盖”未标记行为数据集中的状态。该方法能够学习到与数据集中的行为良好对齐的策略，同时保持基于奖励和模仿任务的零样本泛化能力。在一个人形控制问题中，该方法通过仅利用观察数据集，训练了Meta Motivo，这是第一个可以提示解决包括运动跟踪、目标到达和奖励优化在内的各种全身任务的类人形行为基础模型。该模型能够表达类似人类的行为，并在性能上优于最先进的无监督强化学习和基于模型的基线方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised reinforcement learning (RL) aims at pre-training agents that cansolve a wide range of downstream tasks in complex environments. Despite recentadvancements, existing approaches suffer from several limitations: they mayrequire running an RL process on each downstream task to achieve a satisfactoryperformance, they may need access to datasets with good coverage orwell-curated task-specific samples, or they may pre-train policies withunsupervised losses that are poorly correlated with the downstream tasks ofinterest. In this paper, we introduce a novel algorithm regularizingunsupervised RL towards imitating trajectories from unlabeled behaviordatasets. The key technical novelty of our method, called Forward-BackwardRepresentations with Conditional-Policy Regularization, is to trainforward-backward representations to embed the unlabeled trajectories to thesame latent space used to represent states, rewards, and policies, and use alatent-conditional discriminator to encourage policies to ``cover'' the statesin the unlabeled behavior dataset. As a result, we can learn policies that arewell aligned with the behaviors in the dataset, while retaining zero-shotgeneralization capabilities for reward-based and imitation tasks. Wedemonstrate the effectiveness of this new approach in a challenging humanoidcontrol problem: leveraging observation-only motion capture datasets, we trainMeta Motivo, the first humanoid behavioral foundation model that can beprompted to solve a variety of whole-body tasks, including motion tracking,goal reaching, and reward optimization. The resulting model is capable ofexpressing human-like behaviors and it achieves competitive performance withtask-specific methods while outperforming state-of-the-art unsupervised RL andmodel-based baselines.</description>
      <author>example@mail.com (Andrea Tirinzoni, Ahmed Touati, Jesse Farebrother, Mateusz Guzek, Anssi Kanervisto, Yingchen Xu, Alessandro Lazaric, Matteo Pirotta)</author>
      <guid isPermaLink="false">2504.11054v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Defending Against Frequency-Based Attacks with Diffusion Models</title>
      <link>http://arxiv.org/abs/2504.11034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Conference on Computer Vision and Pattern Recognition Workshops  (CVPRW), 5th Workshop on Adversarial Machine Learning in Computer Vision:  Foundation Models + X&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了对抗训练和对抗净化在提高模型鲁棒性方面的应用，特别是通过扩散模型进行噪声净化以应对对抗攻击。&lt;h4&gt;背景&lt;/h4&gt;对抗训练虽然能增强模型对特定攻击类型的鲁棒性，但其泛化能力有限，难以应对未见过的攻击模型。&lt;h4&gt;目的&lt;/h4&gt;探索对抗净化方法在应对不同类型对抗攻击，特别是频谱和空间攻击方面的有效性。&lt;h4&gt;方法&lt;/h4&gt;利用生成模型进行对抗净化，独立训练净化器，以应对未见过的攻击场景。使用扩散模型进行噪声净化，不仅针对像素级对抗扰动，也应对非对抗数据偏移。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，对抗净化在处理不同频率区域的多种扭曲模式方面非常有效。&lt;h4&gt;结论&lt;/h4&gt;对抗净化是一种有效的提高模型鲁棒性的方法，特别是在应对频谱和空间对抗攻击方面具有显著效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adversarial training is a common strategy for enhancing model robustnessagainst adversarial attacks. However, it is typically tailored to the specificattack types it is trained on, limiting its ability to generalize to unseenthreat models. Adversarial purification offers an alternative by leveraging agenerative model to remove perturbations before classification. Since thepurifier is trained independently of both the classifier and the threat models,it is better equipped to handle previously unseen attack scenarios. Diffusionmodels have proven highly effective for noise purification, not only incountering pixel-wise adversarial perturbations but also in addressingnon-adversarial data shifts. In this study, we broaden the focus beyondpixel-wise robustness to explore the extent to which purification can mitigateboth spectral and spatial adversarial attacks. Our findings highlight itseffectiveness in handling diverse distortion patterns across low- tohigh-frequency regions.</description>
      <author>example@mail.com (Fatemeh Amerehi, Patrick Healy)</author>
      <guid isPermaLink="false">2504.11034v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Temporal Link Prediction</title>
      <link>http://arxiv.org/abs/2504.10925v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图上链接预测，特别是时间序列链接预测（TLP），并提出了针对记忆模块模型的迁移学习方法。&lt;h4&gt;背景&lt;/h4&gt;链接预测在推荐系统和药物发现等领域有广泛应用。TLP需要处理图随时间演变的动态特性，现有模型结合记忆模块和图神经网络学习节点的时间机制和图拓扑结构。&lt;h4&gt;目的&lt;/h4&gt;研究新的迁移学习方法，使记忆模块模型能够在测试和部署时应用于全新的图。&lt;h4&gt;方法&lt;/h4&gt;通过增强结构映射模块，将图结构特征映射到记忆嵌入中，从而提高模型在TLP任务中的信息量。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法为TLP构建了一个无需记忆的基座模型。&lt;h4&gt;结论&lt;/h4&gt;该研究为TLP领域提供了新的迁移学习策略，有助于提高模型在处理全新图数据时的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction on graphs has applications spanning from recommender systemsto drug discovery. Temporal link prediction (TLP) refers to predicting futurelinks in a temporally evolving graph and adds additional complexity related tothe dynamic nature of graphs. State-of-the-art TLP models incorporate memorymodules alongside graph neural networks to learn both the temporal mechanismsof incoming nodes and the evolving graph topology. However, memory modules onlystore information about nodes seen at train time, and hence such models cannotbe directly transferred to entirely new graphs at test time and deployment. Inthis work, we study a new transfer learning task for temporal link prediction,and develop transfer-effective methods for memory-laden models. Specifically,motivated by work showing the informativeness of structural signals for the TLPtask, we augment a structural mapping module to the existing TLP modelarchitectures, which learns a mapping from graph structural (topological)features to memory embeddings. Our work paves the way for a memory-freefoundation model for TLP.</description>
      <author>example@mail.com (Ayan Chatterjee, Barbara Ikica, Babak Ravandi, John Palowitch)</author>
      <guid isPermaLink="false">2504.10925v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Distribution Gaps in Time Series Foundation Model Pretraining with Prototype-Guided Normalization</title>
      <link>http://arxiv.org/abs/2504.10900v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在Transformer架构中应用的领域感知自适应归一化策略，以解决在大型、多样化数据集上进行预训练时由于数据分布不匹配带来的挑战，尤其是在时间序列数据上。通过实验验证，该方法在分类和预测任务上显著优于传统预训练技术，并能有效减轻预训练过程中的分布偏移带来的负面影响。&lt;h4&gt;背景&lt;/h4&gt;基础模型在多个机器学习领域取得了显著成功，但大规模预训练引入了数据分布不匹配的挑战，尤其是在时间序列数据上。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决预训练数据分布不匹配问题的方法。&lt;h4&gt;方法&lt;/h4&gt;在Transformer架构中，用原型引导的动态归一化机制（ProtoNorm）替换传统的LayerNorm，通过学习原型来封装不同的数据分布，并利用样本到原型的亲和度确定适当的归一化层。&lt;h4&gt;主要发现&lt;/h4&gt;该方法有效捕捉了时间序列特性的异质性，使预训练表示与下游任务对齐。在分类和预测任务上，该方法显著优于传统预训练技术，并能有效减轻分布偏移的负面影响。&lt;h4&gt;结论&lt;/h4&gt;通过在真实世界的时间序列基准上的广泛实验，验证了该方法在鲁棒性和泛化性方面的有效性，推动了更通用的时间序列基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过在大型、多样化的数据集上进行大规模预训练，基础模型在多个机器学习领域取得了显著的成就。然而，在如此数据集上进行预训练引入了数据分布不匹配的显著挑战，这一问题在时间序列数据上尤为突出。在本文中，我们通过在Transformer架构内提出一种领域感知的自适应归一化策略来应对这一挑战。具体来说，我们用原型引导的动态归一化机制（ProtoNorm）替换了传统的层归一化（LayerNorm），其中学习的原型封装了不同的数据分布，而样本到原型的亲和度决定了适当的归一化层。这种机制有效地捕捉了时间序列特性的异质性，使预训练表示与下游任务相匹配。通过全面的实证评估，我们证明了该方法在分类和预测任务上显著优于传统的预训练技术，同时有效地减轻了预训练过程中分布偏移的负面影响。引入ProtoNorm就像替换一行代码一样简单。在真实世界的时间序列基准上的广泛实验验证了该方法的鲁棒性和泛化性，推动了更通用的时间序列基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have achieved remarkable success across diversemachine-learning domains through large-scale pretraining on large, diversedatasets. However, pretraining on such datasets introduces significantchallenges due to substantial mismatches in data distributions, a problemparticularly pronounced with time series data. In this paper, we tackle thisissue by proposing a domain-aware adaptive normalization strategy within theTransformer architecture. Specifically, we replace the traditional LayerNormwith a prototype-guided dynamic normalization mechanism (ProtoNorm), wherelearned prototypes encapsulate distinct data distributions, andsample-to-prototype affinity determines the appropriate normalization layer.This mechanism effectively captures the heterogeneity of time seriescharacteristics, aligning pretrained representations with downstream tasks.Through comprehensive empirical evaluation, we demonstrate that our methodsignificantly outperforms conventional pretraining techniques across bothclassification and forecasting tasks, while effectively mitigating the adverseeffects of distribution shifts during pretraining. Incorporating ProtoNorm isas simple as replacing a single line of code. Extensive experiments on diversereal-world time series benchmarks validate the robustness and generalizabilityof our approach, advancing the development of more versatile time seriesfoundation models.</description>
      <author>example@mail.com (Peiliang Gong, Emadeldeen Eldele, Min Wu, Zhenghua Chen, Xiaoli Li, Daoqiang Zhang)</author>
      <guid isPermaLink="false">2504.10900v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>LVLM_CSP: Accelerating Large Vision Language Models via Clustering, Scattering, and Pruning for Reasoning Segmentation</title>
      <link>http://arxiv.org/abs/2504.10854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LVLM_CSP的新颖的视觉标记剪枝方法，用于基于大型视觉语言模型（LVLM）的推理分割任务，以降低计算开销。&lt;h4&gt;背景&lt;/h4&gt;LVLMs在视觉基础模型中用于推理分割任务表现出色，但它们的高计算开销是一个挑战，主要来源于处理大量图像标记。&lt;h4&gt;目的&lt;/h4&gt;设计一种剪枝方法，减少图像标记的数量，同时保持高分割精度。&lt;h4&gt;方法&lt;/h4&gt;LVLM_CSP包含三个阶段：聚类、散射和剪枝。首先使用选定的图像标记子集进行粗粒度视觉推理，然后进行细粒度推理，最后在最后一个阶段剪枝掉大多数视觉标记。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LVLM_CSP在图像标记推理FLOPs上实现了65%的减少，几乎没有精度下降，并且在7B LVLM上实现了70%的减少，精度仅下降了1%。&lt;h4&gt;结论&lt;/h4&gt;LVLM_CSP是一种有效的剪枝方法，能够在保持高分割精度的同时显著减少计算开销。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Vision Language Models (LVLMs) have been widely adopted to guide visionfoundation models in performing reasoning segmentation tasks, achievingimpressive performance. However, the substantial computational overheadassociated with LVLMs presents a new challenge. The primary source of thiscomputational cost arises from processing hundreds of image tokens. Therefore,an effective strategy to mitigate such overhead is to reduce the number ofimage tokens, a process known as image token pruning. Previous studies on imagetoken pruning for LVLMs have primarily focused on high level visualunderstanding tasks, such as visual question answering and image captioning. Incontrast, guiding vision foundation models to generate accurate visual masksbased on textual queries demands precise semantic and spatial reasoningcapabilities. Consequently, pruning methods must carefully control individualimage tokens throughout the LVLM reasoning process. Our empirical analysisreveals that existing methods struggle to adequately balance reductions incomputational overhead with the necessity to maintain high segmentationaccuracy. In this work, we propose LVLM_CSP, a novel training free visual tokenpruning method specifically designed for LVLM based reasoning segmentationtasks. LVLM_CSP consists of three stages: clustering, scattering, and pruning.Initially, the LVLM performs coarse-grained visual reasoning using a subset ofselected image tokens. Next, fine grained reasoning is conducted, and finally,most visual tokens are pruned in the last stage. Extensive experimentsdemonstrate that LVLM_CSP achieves a 65% reduction in image token inferenceFLOPs with virtually no accuracy degradation, and a 70% reduction with only aminor 1% drop in accuracy on the 7B LVLM.</description>
      <author>example@mail.com (Hanning Chen, Yang Ni, Wenjun Huang, Hyunwoo Oh, Yezi Liu, Tamoghno Das, Mohsen Imani)</author>
      <guid isPermaLink="false">2504.10854v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Elucidating the Design Space of Multimodal Protein Language Models</title>
      <link>http://arxiv.org/abs/2504.11454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://bytedance.github.io/dplm/dplm-2.1/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的多模态蛋白质语言模型（PLM）设计空间，以解决现有模型在3D结构细节和相关性上的精度损失问题。&lt;h4&gt;背景&lt;/h4&gt;多模态PLM整合序列和基于标记的结构信息，是蛋白质建模、生成和设计的基础，但依赖于将3D结构分割成离散标记会导致结构细节和相关性信息的损失。&lt;h4&gt;目的&lt;/h4&gt;系统地阐述多模态PLM的设计空间，以克服其局限性。&lt;h4&gt;方法&lt;/h4&gt;通过识别tokenization loss和PLM的不准确结构token预测，提出改进的生成建模、结构感知架构和表示学习方法，以及数据探索方法。&lt;h4&gt;主要发现&lt;/h4&gt;通过更精细的监督，证明了基于token的多模态PLM可以实现鲁棒的结构建模。有效的设计方法显著提高了结构生成多样性和折叠能力，将650M模型在PDB测试集上的RMSD从5.52降低到2.36，甚至优于3B基线，与专业折叠模型相当。&lt;h4&gt;结论&lt;/h4&gt;本文提出的改进设计空间能够有效提升多模态PLM的性能，使其在蛋白质结构建模方面达到新的水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal protein language models (PLMs) integrate sequence and token-basedstructural information, serving as a powerful foundation for protein modeling,generation, and design. However, the reliance on tokenizing 3D structures intodiscrete tokens causes substantial loss of fidelity about fine-grainedstructural details and correlations. In this paper, we systematically elucidatethe design space of multimodal PLMs to overcome their limitations. We identifytokenization loss and inaccurate structure token predictions by the PLMs asmajor bottlenecks. To address these, our proposed design space covers improvedgenerative modeling, structure-aware architectures and representation learning,and data exploration. Our advancements approach finer-grained supervision,demonstrating that token-based multimodal PLMs can achieve robust structuralmodeling. The effective design methods dramatically improve the structuregeneration diversity, and notably, folding abilities of our 650M model byreducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3Bbaselines and on par with the specialized folding models.</description>
      <author>example@mail.com (Cheng-Yen, Hsieh, Xinyou Wang, Daiheng Zhang, Dongyu Xue, Fei Ye, Shujian Huang, Zaixiang Zheng, Quanquan Gu)</author>
      <guid isPermaLink="false">2504.11454v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Out-of-Distribution Detection with Extended Logit Normalization</title>
      <link>http://arxiv.org/abs/2504.11434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的超参数无关的扩展Logit Normalization方法，旨在提高机器学习模型在分布外检测（OOD）方面的性能。&lt;h4&gt;背景&lt;/h4&gt;分布外检测对于机器学习模型的安全部署至关重要。尽管最近的研究在改进分类损失和表示学习方法方面取得了进展，但这些方法通常针对特定的后处理检测技术，限制了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决Logit Normalization（LogitNorm）在提高某些后处理OOD检测方法有效性方面存在的问题。&lt;h4&gt;方法&lt;/h4&gt;本文提出了Extended Logit Normalization（ELogitNorm），该方法通过将特征距离感知性融入LogitNorm，实现了比前驱方法更鲁棒的分布外分离和分布内（ID）置信度校准。&lt;h4&gt;主要发现&lt;/h4&gt;在标准基准上的广泛实验表明，该方法在OOD检测方面优于现有的训练时方法，同时在ID分类精度方面表现良好。&lt;h4&gt;结论&lt;/h4&gt;ELogitNorm方法能够显著提升后处理检测方法的性能，为机器学习模型的安全部署提供了有效的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分布外（OOD）检测对于机器学习模型的安全部署至关重要。最近的研究探索了改进分类损失和表示学习策略以提高OOD检测。然而，这些方法通常针对特定的后处理检测技术，限制了它们的泛化能力。在这项工作中，我们确定了Logit Normalization（LogitNorm）中的一个关键问题，这阻碍了它在提高某些后处理OOD检测方法有效性方面的效果。为了解决这个问题，我们提出了Extended Logit Normalization（ELogitNorm），这是一种新颖的超参数无关的公式，它显著提高了广泛的后处理检测方法的性能。通过将特征距离感知性融入LogitNorm，ELogitNorm比其前驱方法显示了更强的分布外分离和分布内（ID）置信度校准。在标准基准上的广泛实验表明，我们的方法在分布外检测方面优于最先进的方法，同时保持了强大的分布内分类精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution (OOD) detection is essential for the safe deployment ofmachine learning models. Recent advances have explored improved classificationlosses and representation learning strategies to enhance OOD detection.However, these methods are often tailored to specific post-hoc detectiontechniques, limiting their generalizability. In this work, we identify acritical issue in Logit Normalization (LogitNorm), which inhibits itseffectiveness in improving certain post-hoc OOD detection methods. To addressthis, we propose Extended Logit Normalization ($\textbf{ELogitNorm}$), a novelhyperparameter-free formulation that significantly benefits a wide range ofpost-hoc detection methods. By incorporating feature distance-awareness toLogitNorm, $\textbf{ELogitNorm}$ shows more robust OOD separability andin-distribution (ID) confidence calibration than its predecessor. Extensiveexperiments across standard benchmarks demonstrate that our approachoutperforms state-of-the-art training-time methods in OOD detection whilemaintaining strong ID classification accuracy.</description>
      <author>example@mail.com (Yifan Ding, Xixi Liu, Jonas Unger, Gabriel Eilertsen)</author>
      <guid isPermaLink="false">2504.11434v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Network Alignment</title>
      <link>http://arxiv.org/abs/2504.11367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了网络对齐研究的最新进展，包括网络对齐的特性分析和不同领域的应用进展。&lt;h4&gt;背景&lt;/h4&gt;复杂网络常用于模拟物理或虚拟复杂系统，网络对齐对于揭示不同系统间实体关系至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过网络对齐增强对复杂系统结构和行为的理解，促进理论物理研究在复杂系统领域的验证和扩展。&lt;h4&gt;方法&lt;/h4&gt;本文分析了基于结构一致性、网络嵌入和图神经网络的各种网络对齐方法，并讨论了在不同网络类型（如属性网络、异构网络、有向网络和动态网络）下的对齐方法。&lt;h4&gt;主要发现&lt;/h4&gt;不同领域的网络对齐研究存在术语和概念的不一致性，本文详细分析了各种方法的实现原理、过程和性能差异。&lt;h4&gt;结论&lt;/h4&gt;本文讨论了网络对齐领域面临的挑战和开放性问题，为未来的研究提供了方向。&lt;h4&gt;翻译&lt;/h4&gt;This paper reviews the latest advancements in network alignment research, including the analysis of network alignment characteristics and progress in various domains such as social network analysis, bioinformatics, computational linguistics, and privacy protection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.physrep.2024.11.006&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex networks are frequently employed to model physical or virtual complexsystems. When certain entities exist across multiple systems simultaneously,unveiling their corresponding relationships across the networks becomescrucial. This problem, known as network alignment, holds significantimportance. It enhances our understanding of complex system structures andbehaviours, facilitates the validation and extension of theoretical physicsresearch about studying complex systems, and fosters diverse practicalapplications across various fields. However, due to variations in thestructure, characteristics, and properties of complex networks across differentfields, the study of network alignment is often isolated within each domain,with even the terminologies and concepts lacking uniformity. This reviewcomprehensively summarizes the latest advancements in network alignmentresearch, focusing on analyzing network alignment characteristics and progressin various domains such as social network analysis, bioinformatics,computational linguistics and privacy protection. It provides a detailedanalysis of various methods' implementation principles, processes, andperformance differences, including structure consistency-based methods, networkembedding-based methods, and graph neural network-based (GNN-based) methods.Additionally, the methods for network alignment under different conditions,such as in attributed networks, heterogeneous networks, directed networks, anddynamic networks, are presented. Furthermore, the challenges and the openissues for future studies are also discussed.</description>
      <author>example@mail.com (Rui Tang, Ziyun Yong, Shuyu Jiang, Xingshu Chen, Yaofang Liu, Yi-Cheng Zhang, Gui-Quan Sun, Wei Wang)</author>
      <guid isPermaLink="false">2504.11367v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*</title>
      <link>http://arxiv.org/abs/2504.11014v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9pages, 1 supple&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GATE3D的新框架，专门用于通用单目3D目标检测，通过弱监督学习提高模型在多领域数据集上的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;计算机视觉领域正在发展通用模型，这些模型能够同时处理多种不同的任务。这种通用性通常需要跨多领域数据集的联合训练以确保有效的泛化。然而，由于缺乏标注准确的3D真实标签的数据集，特别是在典型的基于道路的自动驾驶环境之外，单目3D目标检测在多领域训练中面临着独特的挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，本文提出了一种利用伪标签的弱监督框架，旨在提高单目3D目标检测的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;本文提出的GATE3D框架通过在2D和3D预测之间应用一致性损失来有效地弥合领域差距。该框架利用了预训练策略，以加速从有限的标注数据中学习。&lt;h4&gt;主要发现&lt;/h4&gt;GATE3D在KITTI基准数据集和作者收集的室内办公数据集上均取得了有竞争力的性能，证明了该框架在泛化能力方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;GATE3D显著加速了从有限标注数据中的学习，显示出在机器人、增强现实和虚拟现实应用中的广泛潜力。&lt;h4&gt;翻译&lt;/h4&gt;The emerging trend in computer vision emphasizes developing universal models capable of simultaneously addressing multiple diverse tasks. Such universality typically requires joint training across multi-domain datasets to ensure effective generalization. However, monocular 3D object detection presents unique challenges in multi-domain training due to the scarcity of datasets annotated with accurate 3D ground-truth labels, especially beyond typical road-based autonomous driving contexts. To address this challenge, we introduce a novel weakly supervised framework leveraging pseudo-labels. Current pretrained models often struggle to accurately detect pedestrians in non-road environments due to inherent dataset biases. Unlike generalized image-based 2D object detection models, achieving similar generalization in monocular 3D detection remains largely unexplored. In this paper, we propose GATE3D, a novel framework designed specifically for generalized monocular 3D object detection via weak supervision. GATE3D effectively bridges domain gaps by employing consistency losses between 2D and 3D predictions. Remarkably, our model achieves competitive performance on the KITTI benchmark as well as on an indoor-office dataset collected by us to evaluate the generalization capabilities of our framework. Our results demonstrate that GATE3D significantly accelerates learning from limited annotated data through effective pre-training strategies, highlighting substantial potential for broader impacts in robotics, augmented reality, and virtual reality applications. Project page: https://ies0411.github.io/GATE3D/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emerging trend in computer vision emphasizes developing universal modelscapable of simultaneously addressing multiple diverse tasks. Such universalitytypically requires joint training across multi-domain datasets to ensureeffective generalization. However, monocular 3D object detection presentsunique challenges in multi-domain training due to the scarcity of datasetsannotated with accurate 3D ground-truth labels, especially beyond typicalroad-based autonomous driving contexts. To address this challenge, we introducea novel weakly supervised framework leveraging pseudo-labels. Currentpretrained models often struggle to accurately detect pedestrians in non-roadenvironments due to inherent dataset biases. Unlike generalized image-based 2Dobject detection models, achieving similar generalization in monocular 3Ddetection remains largely unexplored. In this paper, we propose GATE3D, a novelframework designed specifically for generalized monocular 3D object detectionvia weak supervision. GATE3D effectively bridges domain gaps by employingconsistency losses between 2D and 3D predictions. Remarkably, our modelachieves competitive performance on the KITTI benchmark as well as on anindoor-office dataset collected by us to evaluate the generalizationcapabilities of our framework. Our results demonstrate that GATE3Dsignificantly accelerates learning from limited annotated data througheffective pre-training strategies, highlighting substantial potential forbroader impacts in robotics, augmented reality, and virtual realityapplications. Project page: https://ies0411.github.io/GATE3D/</description>
      <author>example@mail.com (Eunsoo Im, Jung Kwon Lee, Changhyun Jee)</author>
      <guid isPermaLink="false">2504.11014v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>DeepSelective: Feature Gating and Representation Matching for Interpretable Clinical Prediction</title>
      <link>http://arxiv.org/abs/2504.11264v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DeepSelective的深度学习框架，用于利用电子健康记录（EHRs）预测患者预后，该框架结合了数据压缩技术和创新的特征选择方法，旨在提高模型的准确性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;随着电子健康记录的快速积累，传统的机器学习模型在临床预测和诊断中发挥了作用，但它们往往缺乏鲁棒的表现学习，并且高度依赖专家手工制作的特征。虽然深度学习提供了强大的解决方案，但通常因其缺乏可解释性而受到批评。&lt;h4&gt;目的&lt;/h4&gt;提出DeepSelective框架，以增强模型的可解释性，并提高使用EHR数据预测患者预后的准确性。&lt;h4&gt;方法&lt;/h4&gt;DeepSelective结合了数据压缩技术和创新的特征选择方法，包括自定义设计的模块，以改善准确性和可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，DeepSelective不仅提高了预测准确性，还显著提高了可解释性，使其成为临床决策的有价值工具。&lt;h4&gt;结论&lt;/h4&gt;DeepSelective是一种有效的深度学习框架，可用于提高基于EHR数据的患者预后预测的准确性和可解释性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：电子健康记录（EHRs）的快速积累通过提供增强临床预测和诊断的有价值数据而改变了医疗保健。虽然传统的机器学习模型已被证明是有效的，但它们通常缺乏鲁棒的表现学习，并且高度依赖于专家手工制作的特征。尽管深度学习提供了强大的解决方案，但它通常因其缺乏可解释性而受到批评。为了解决这些挑战，我们提出了一种名为DeepSelective的新型端到端深度学习框架，用于使用EHR数据预测患者预后，该框架特别强调增强模型的可解释性。DeepSelective结合了数据压缩技术与创新的特征选择方法，整合了协同工作的自定义设计模块，以提高准确性和可解释性。我们的实验表明，DeepSelective不仅提高了预测准确性，还显著提高了可解释性，使其成为临床决策的有价值工具。源代码可在http://www.healthinformaticslab.org/supp/resources.php免费获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid accumulation of Electronic Health Records (EHRs) has transformedhealthcare by providing valuable data that enhance clinical predictions anddiagnoses. While conventional machine learning models have proven effective,they often lack robust representation learning and depend heavily onexpert-crafted features. Although deep learning offers powerful solutions, itis often criticized for its lack of interpretability. To address thesechallenges, we propose DeepSelective, a novel end to end deep learningframework for predicting patient prognosis using EHR data, with a strongemphasis on enhancing model interpretability. DeepSelective combines datacompression techniques with an innovative feature selection approach,integrating custom-designed modules that work together to improve both accuracyand interpretability. Our experiments demonstrate that DeepSelective not onlyenhances predictive accuracy but also significantly improves interpretability,making it a valuable tool for clinical decision-making. The source code isfreely available at http://www.healthinformaticslab.org/supp/resources.php .</description>
      <author>example@mail.com (Ruochi Zhang, Qian Yang, Xiaoyang Wang, Haoran Wu, Qiong Zhou, Yu Wang, Kewei Li, Yueying Wang, Yusi Fan, Jiale Zhang, Lan Huang, Chang Liu, Fengfeng Zhou)</author>
      <guid isPermaLink="false">2504.11264v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Features in Long-tailed Data Using Large Vision Mode</title>
      <link>http://arxiv.org/abs/2504.10852v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究使用大型视觉模型（LVMs）或视觉基础模型（VFMs）来增强长尾数据特征，而不依赖于语言信息。&lt;h4&gt;背景&lt;/h4&gt;语言模型如大型语言模型（LLMs）或大型视觉-语言模型（LVLMs）在长尾识别中已被广泛研究，但并非所有实际任务都需要语言数据。&lt;h4&gt;目的&lt;/h4&gt;探索使用LVMs或VFMs来增强长尾数据特征，无需语言信息。&lt;h4&gt;方法&lt;/h4&gt;从LVM提取特征，与基线网络的图和潜在空间中的特征融合，获得增强特征。设计几个基于原型的损失函数在潜在空间中进一步挖掘增强特征潜力。&lt;h4&gt;主要发现&lt;/h4&gt;在ImageNet-LT和iNaturalist2018两个基准数据集上验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效地利用视觉模型增强长尾数据特征，无需语言信息。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies the use of large visual models (LVMs) or visual foundation models (VFMs) to enhance long-tailed data features without the need for linguistic information. In particular, features are extracted from the LVM and fused with features in the map and latent space of the baseline network to obtain augmented features. Additionally, several prototype-based losses are designed in the latent space to further exploit the potential of the augmented features. In the experimental section, our approach is validated on two benchmark datasets: ImageNet-LT and iNaturalist2018.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language-based foundation models, such as large language models (LLMs) orlarge vision-language models (LVLMs), have been widely studied in long-tailedrecognition. However, the need for linguistic data is not applicable to allpractical tasks. In this study, we aim to explore using large vision models(LVMs) or visual foundation models (VFMs) to enhance long-tailed data featureswithout any language information. Specifically, we extract features from theLVM and fuse them with features in the baseline network's map and latent spaceto obtain the augmented features. Moreover, we design several prototype-basedlosses in the latent space to further exploit the potential of the augmentedfeatures. In the experimental section, we validate our approach on twobenchmark datasets: ImageNet-LT and iNaturalist2018.</description>
      <author>example@mail.com (Pengxiao Han, Changkun Ye, Jinguang Tong, Cuicui Jiang, Jie Hong, Li Fang, Xuesong Li)</author>
      <guid isPermaLink="false">2504.10852v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Point Transformers for Detecting Anatomical Landmarks in Digital Dentistry</title>
      <link>http://arxiv.org/abs/2504.11418v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages + references, 3 figures, MICCAI2024 3DTeethland Challenge  submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了口腔扫描设备在临床正畸中的重要性，并提出了一种基于点云学习的Transformer架构方法，用于自动识别患者牙齿的关键地标。&lt;h4&gt;背景&lt;/h4&gt;随着口腔扫描设备的普及，其在现代临床正畸中的应用越来越重要。正畸医生利用计算机辅助设计技术创建患者专属的治疗计划，需要费力地识别诸如牙尖、近远中位置、面部轴线点和牙齿牙龈边界等关键地标。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种自动识别牙齿关键地标的方法，以解决现有方法中存在的数据集规模有限、个体间解剖学差异大以及数据几何性质带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;本文提出的实验来自2024年MICCAI的3DTeethLandGrand Challenge。方法利用最近在点云学习方面的进展，设计了一个受PointTransformer v3启发的模块，用于捕获有意义的几何和解剖特征。这些特征经过轻量级解码器处理后预测每点的距离，再通过基于图的非最小抑制进一步处理。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在识别牙齿关键地标方面取得了有希望的结果，并讨论了学习到的特征的可解释性。&lt;h4&gt;结论&lt;/h4&gt;该方法为自动识别牙齿关键地标提供了一种有效的解决方案，有助于提高临床正畸的效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;随着口腔扫描设备的日益普及，其在现代临床正畸中的应用日益重要。临床医生利用先进的计算机辅助设计技术创建患者专属的治疗计划，包括费力地识别关键地标，如牙尖、近远中位置、面部轴线点和牙齿牙龈边界。自动检测此类地标提出了挑战，包括数据集规模有限、个体间解剖学差异显著以及数据的几何性质。我们展示了我们在MICCAI 2024年3DTeethLandGrand Challenge中的实验。我们的方法利用了点云学习方面的最新进展，通过Transformer架构。我们设计了一个受PointTransformer v3启发的模块，以捕获有意义的几何和解剖特征，这些特征通过轻量级解码器处理以预测每点的距离，然后通过基于图的非最小抑制进一步处理。我们报告了有希望的结果，并讨论了学习到的特征的可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing availability of intraoral scanning devices has heightenedtheir importance in modern clinical orthodontics. Clinicians utilize advancedComputer-Aided Design techniques to create patient-specific treatment plansthat include laboriously identifying crucial landmarks such as cusps,mesial-distal locations, facial axis points, and tooth-gingiva boundaries.Detecting such landmarks automatically presents challenges, including limiteddataset sizes, significant anatomical variability among subjects, and thegeometric nature of the data. We present our experiments from the 3DTeethLandGrand Challenge at MICCAI 2024. Our method leverages recent advancements inpoint cloud learning through transformer architectures. We designed a PointTransformer v3 inspired module to capture meaningful geometric and anatomicalfeatures, which are processed by a lightweight decoder to predict per-pointdistances, further processed by graph-based non-minima suppression. We reportpromising results and discuss insights on learned feature interpretability.</description>
      <author>example@mail.com (Tibor Kubík, Oldřich Kodym, Petr Šilling, Kateřina Trávníčková, Tomáš Mojžiš, Jan Matula)</author>
      <guid isPermaLink="false">2504.11418v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>DeepMLF: Multimodal language model with learnable tokens for deep fusion in sentiment analysis</title>
      <link>http://arxiv.org/abs/2504.11082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多模态融合在多模态情感分析中的深度和容量分配问题，提出了DeepMLF模型，并通过实验验证了深度融合和融合深度对性能的影响。&lt;h4&gt;背景&lt;/h4&gt;多模态融合在多模态情感分析中已得到广泛研究，但融合深度和容量分配仍需进一步探索。&lt;h4&gt;目的&lt;/h4&gt;将融合深度、可扩展性和专用的多模态容量定位为有效融合的主要因素，并提出一种新的多模态语言模型DeepMLF。&lt;h4&gt;方法&lt;/h4&gt;DeepMLF模型利用音频视觉编码器和预训练的解码器语言模型，并在其层中集成多模态信息。模型通过可学习的标记捕获模态交互，并通过因果自注意力机制和交叉注意力机制实现融合。&lt;h4&gt;主要发现&lt;/h4&gt;DeepMLF在三个具有不同数据集特性的多模态情感分析基准测试中达到了最先进的性能，证明了更深层次的融合和适当的融合深度（5-7）优于现有方法。实验还表明，小的标记集（约20个）可以达到最佳性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和模型在多模态情感分析中具有优越性，并提供了对DeepMLF可扩展性和每个训练目标的全面考察。&lt;h4&gt;翻译&lt;/h4&gt;摘要：虽然多模态融合在多模态情感分析（MSA）中已被广泛研究，但融合深度和多模态容量分配仍被低估。在这项工作中，我们将融合深度、可扩展性和专用多模态容量定位为有效融合的主要因素。我们引入了DeepMLF，这是一种新的面向深度融合的多模态语言模型（LM），具有可学习的标记。DeepMLF利用音频视觉编码器和预训练的解码器LM，在其层中集成多模态信息。我们向LM添加可学习的标记，这些标记：1）以受控的方式捕获模态交互，2）为每个模态保留独立的信息流。这些融合标记通过LM块中的因果自注意力机制收集语言信息，并通过交叉注意力MM块与音频视觉信息集成。作为专用的多模态容量，这种设计使多个层之间的融合逐步进行，在融合过程中提供深度。我们的训练方法结合了模态特定损失和语言模型损失，解码器LM的任务是预测真实极性。在三个具有不同数据集特性的MSA基准测试中，DeepMLF实现了最先进的性能。我们的结果表明，更深层次的融合会导致更好的性能，最佳融合深度（5-7）优于现有方法。此外，我们对融合标记数量的分析表明，小的标记集（约20个）可以达到最佳性能。我们通过音频视觉编码器初始化实验检查了表示学习顺序（融合课程）的重要性。我们的消融研究表明，所提出的融合设计和门控提供了对DeepMLF可扩展性的全面考察，以及每个训练目标和嵌入正则化的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While multimodal fusion has been extensively studied in Multimodal SentimentAnalysis (MSA), the role of fusion depth and multimodal capacity allocationremains underexplored. In this work, we position fusion depth, scalability, anddedicated multimodal capacity as primary factors for effective fusion. Weintroduce DeepMLF, a novel multimodal language model (LM) with learnable tokenstailored toward deep fusion. DeepMLF leverages an audiovisual encoder and apretrained decoder LM augmented with multimodal information across its layers.We append learnable tokens to the LM that: 1) capture modality interactions ina controlled fashion and 2) preserve independent information flow for eachmodality. These fusion tokens gather linguistic information via causalself-attention in LM Blocks and integrate with audiovisual information throughcross-attention MM Blocks. Serving as dedicated multimodal capacity, thisdesign enables progressive fusion across multiple layers, providing depth inthe fusion process. Our training recipe combines modality-specific losses andlanguage modelling loss, with the decoder LM tasked to predict ground truthpolarity. Across three MSA benchmarks with varying dataset characteristics,DeepMLF achieves state-of-the-art performance. Our results confirm that deeperfusion leads to better performance, with optimal fusion depths (5-7) exceedingthose of existing approaches. Additionally, our analysis on the number offusion tokens reveals that small token sets ($\sim$20) achieve optimalperformance. We examine the importance of representation learning order (fusioncurriculum) through audiovisual encoder initialization experiments. Ourablation studies demonstrate the superiority of the proposed fusion design andgating while providing a holistic examination of DeepMLF's scalability to LLMs,and the impact of each training objective and embedding regularization.</description>
      <author>example@mail.com (Efthymios Georgiou, Vassilis Katsouros, Yannis Avrithis, Alexandros Potamianos)</author>
      <guid isPermaLink="false">2504.11082v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Accurate Machine Learning Interatomic Potentials for Polyacene Molecular Crystals: Application to Single Molecule Host-Guest Systems</title>
      <link>http://arxiv.org/abs/2504.11224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过开发一种基于图神经网络MACE架构和主动学习策略的通用机器学习原子间势（MLIP），对一系列聚芴基分子晶体（如萘、蒽、四芴和五芴）的振动动力学进行了准确描述。&lt;h4&gt;背景&lt;/h4&gt;尽管MLIP在大型材料模拟中具有潜力，但关于分子晶体振动动力学的严格测试还很少。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够准确描述分子晶体振动动力学的通用MLIP。&lt;h4&gt;方法&lt;/h4&gt;使用MACE架构和主动学习策略，对聚芴基分子晶体进行模拟，并通过仔细的错误传播验证了势能的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;这些势能能够准确描述非谐波振动特性、振动寿命和振动耦合。特别研究了基于这些分子晶体的宿主-客体系统，展示了基于分子动力学的技术能够解释和量化宿主和客体核运动之间的振动耦合。&lt;h4&gt;结论&lt;/h4&gt;本研究建立了一个理解大型复杂分子系统振动特征的平台，对于在分子环境中设计振动相互作用具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging machine learning interatomic potentials (MLIPs) offer a promisingsolution for large-scale accurate material simulations, but stringent testsrelated to the description of vibrational dynamics in molecular crystals remainscarce. Here, we develop a general MLIP by leveraging the graph neuralnetwork-based MACE architecture and active-learning strategies to accuratelycapture vibrational dynamics across a range of polyacene-based molecularcrystals, namely naphthalene, anthracene, tetracene and pentacene. Throughcareful error propagation, we show that these potentials are accurate andenable the study of anharmonic vibrational features, vibrational lifetimes, andvibrational coupling. In particular, we investigate large-scale host-guestsystems based on these molecular crystals, showing the capacity ofmolecular-dynamics-based techniques to explain and quantify vibrationalcoupling between host and guest nuclear motion. Our results establish aframework for understanding vibrational signatures in large-scale complexmolecular systems and thus represent an important step for engineeringvibrational interactions in molecular environments.</description>
      <author>example@mail.com (Burak Gurlek, Shubham Sharma, Paolo Lazzaroni, Angel Rubio, Mariana Rossi)</author>
      <guid isPermaLink="false">2504.11224v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Towards Robust Trajectory Embedding for Similarity Computation: When Triangle Inequality Violations in Distance Metrics Matter</title>
      <link>http://arxiv.org/abs/2504.10933v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于非欧几里得几何（双曲空间）的轨迹表示学习方法，以解决传统相似度函数计算复杂度高和依赖特定距离度量的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的轨迹相似度函数存在计算复杂度高和依赖于特定距离度量的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决欧几里得嵌入中三角形不等式约束的限制。&lt;h4&gt;方法&lt;/h4&gt;通过设计Lorentz距离度量，结合Cosh函数优化的投影方法，以及动态融合距离，将双曲空间嵌入到现有的表示学习流程中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过实验验证，有效地提高了多个真实世界数据集上最先进模型的轨迹相似度度量准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅解决了三角形不等式问题，还显著提高了轨迹相似度计算的精确度，在轨迹表示学习领域取得了实质性进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：轨迹相似性是轨迹数据管理和分析的基础。传统的相似度函数往往具有高计算复杂性和对特定距离度量的依赖性，这促使人们转向欧几里得空间中的深度表示学习。然而，现有的基于欧几里得空间的轨迹嵌入通常面临着由于三角形不等式约束而导致的挑战，这些约束并不适用于所有轨迹数据。为了解决这个问题，本文通过将非欧几里得几何（特别是双曲空间）引入轨迹表示学习，提出了一种新颖的方法。我们提出了首次将双曲空间整合到解决欧几里得嵌入中三角形不等式内在限制的方法。特别是，我们通过设计Lorentz距离度量来实现这一点，该度量已被证明可以克服三角形不等式约束。此外，我们设计了一个模型无关的框架LH-plugin，以无缝地将双曲嵌入集成到现有的表示学习流程中。这包括一个使用Cosh函数优化的新型投影方法，该方法具有理论基础，以防止距离的减少。此外，我们提出了一种动态融合距离，它智能地适应不同轨迹对之间三角形不等式约束的变化，通过结合洛伦兹距离和欧几里得距离来进行更稳健的相似度计算。全面的实验评估表明，我们的方法有效地提高了多个真实世界数据集上最先进模型的轨迹相似度度量的准确性。LH-plugin不仅解决了三角形不等式问题，而且显著提高了轨迹相似度计算的精确度，标志着轨迹表示学习领域的重大进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory similarity is a cornerstone of trajectory data management andanalysis. Traditional similarity functions often suffer from high computationalcomplexity and a reliance on specific distance metrics, prompting a shifttowards deep representation learning in Euclidean space. However, existingEuclidean-based trajectory embeddings often face challenges due to the triangleinequality constraints that do not universally hold for trajectory data. Toaddress this issue, this paper introduces a novel approach by incorporatingnon-Euclidean geometry, specifically hyperbolic space, into trajectoryrepresentation learning. We present the first-ever integration of hyperbolicspace to resolve the inherent limitations of the triangle inequality inEuclidean embeddings. In particular, we achieve it by designing a Lorentzdistance measure, which is proven to overcome triangle inequality constraints.Additionally, we design a model-agnostic framework LH-plugin to seamlesslyintegrate hyperbolic embeddings into existing representation learningpipelines. This includes a novel projection method optimized with the Coshfunction to prevent the diminishment of distances, supported by a theoreticalfoundation. Furthermore, we propose a dynamic fusion distance thatintelligently adapts to variations in triangle inequality constraints acrossdifferent trajectory pairs, blending Lorentzian and Euclidean distances formore robust similarity calculations. Comprehensive experimental evaluationsdemonstrate that our approach effectively enhances the accuracy of trajectorysimilarity measures in state-of-the-art models across multiple real-worlddatasets. The LH-plugin not only addresses the triangle inequality issues butalso significantly refines the precision of trajectory similarity computations,marking a substantial advancement in the field of trajectory representationlearning.</description>
      <author>example@mail.com (Jianing Si, Haitao Yuan, Nan Jiang, Minxiao Chen, Xiao Ma, Shangguang Wang)</author>
      <guid isPermaLink="false">2504.10933v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Meta-learning For Few-Shot Time Series Crop Type Classification: A Benchmark On The EuroCropsML Dataset</title>
      <link>http://arxiv.org/abs/2504.11022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 7 figures, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究对转移学习和多种元学习算法在农作物类型分类任务中的应用进行了评估。&lt;h4&gt;背景&lt;/h4&gt;作物类型数据的空间不均衡对遥感应用中的准确分类构成重大挑战。&lt;h4&gt;目的&lt;/h4&gt;评估元学习算法在现实世界应用中的性能，并建立评价转移和元学习方法的基准。&lt;h4&gt;方法&lt;/h4&gt;在EuroCropsML时间序列数据集上，对基于MAML的元学习算法（包括(FO)-MAML、ANIL和TIML）进行了基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;与简单的迁移学习方法相比，基于MAML的元学习算法在爱沙尼亚的农作物类型分类任务中取得了略微更高的准确率，但代价是更高的计算需求和训练时间。&lt;h4&gt;结论&lt;/h4&gt;不同地区间知识迁移具有挑战性，强调了在真实世界农作物类型分类任务中选择机器学习方法时准确性和计算资源需求之间的权衡。&lt;h4&gt;翻译&lt;/h4&gt;Spatial imbalances in crop type data pose significant challenges for accurate classification in remote sensing applications. Algorithms aiming at transferring knowledge from data-rich to data-scarce tasks have thus surged in popularity. However, despite their effectiveness in previous evaluations, their performance in challenging real-world applications is unclear and needs to be evaluated. This study benchmarks transfer learning and several meta-learning algorithms, including (First-Order) Model-Agnostic Meta-Learning ((FO)-MAML), Almost No Inner Loop (ANIL), and Task-Informed Meta-Learning (TIML), on the real-world EuroCropsML time series dataset, which combines farmer-reported crop data with Sentinel-2 satellite observations from Estonia, Latvia, and Portugal. Our findings indicate that MAML-based meta-learning algorithms achieve slightly higher accuracy compared to simpler transfer learning methods when applied to crop type classification tasks in Estonia after pre-training on data from Latvia. However, this improvement comes at the cost of increased computational demands and training time. Moreover, we find that the transfer of knowledge between geographically disparate regions, such as Estonia and Portugal, poses significant challenges to all investigated algorithms. These insights underscore the trade-offs between accuracy and computational resource requirements in selecting machine learning methods for real-world crop type classification tasks and highlight the difficulties of transferring knowledge between different regions of the Earth. To facilitate future research in this domain, we present the first comprehensive benchmark for evaluating transfer and meta-learning methods for crop type classification under real-world conditions. The corresponding code is publicly available at https://github.com/dida-do/eurocrops-meta-learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial imbalances in crop type data pose significant challenges for accurateclassification in remote sensing applications. Algorithms aiming attransferring knowledge from data-rich to data-scarce tasks have thus surged inpopularity. However, despite their effectiveness in previous evaluations, theirperformance in challenging real-world applications is unclear and needs to beevaluated. This study benchmarks transfer learning and several meta-learningalgorithms, including (First-Order) Model-Agnostic Meta-Learning ((FO)-MAML),Almost No Inner Loop (ANIL), and Task-Informed Meta-Learning (TIML), on thereal-world EuroCropsML time series dataset, which combines farmer-reported cropdata with Sentinel-2 satellite observations from Estonia, Latvia, and Portugal.Our findings indicate that MAML-based meta-learning algorithms achieve slightlyhigher accuracy compared to simpler transfer learning methods when applied tocrop type classification tasks in Estonia after pre-training on data fromLatvia. However, this improvement comes at the cost of increased computationaldemands and training time. Moreover, we find that the transfer of knowledgebetween geographically disparate regions, such as Estonia and Portugal, posessignificant challenges to all investigated algorithms. These insightsunderscore the trade-offs between accuracy and computational resourcerequirements in selecting machine learning methods for real-world crop typeclassification tasks and highlight the difficulties of transferring knowledgebetween different regions of the Earth. To facilitate future research in thisdomain, we present the first comprehensive benchmark for evaluating transferand meta-learning methods for crop type classification under real-worldconditions. The corresponding code is publicly available athttps://github.com/dida-do/eurocrops-meta-learning.</description>
      <author>example@mail.com (Joana Reuss, Jan Macdonald, Simon Becker, Konrad Schultka, Lorenz Richter, Marco Körner)</author>
      <guid isPermaLink="false">2504.11022v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>PVUW 2025 Challenge Report: Advances in Pixel-level Understanding of Complex Videos in the Wild</title>
      <link>http://arxiv.org/abs/2504.11326v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Workshop Page: https://pvuw.github.io/. arXiv admin note: text  overlap with arXiv:2504.00476, arXiv:2504.05178&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本报告全面概述了与CVPR 2025联合举办的第4届像素级视频理解挑战赛（PVUW），总结了挑战赛结果、参赛方法和未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;挑战赛与CVPR 2025联合举办，为像素级视频理解领域提供了一个综合性的平台。&lt;h4&gt;目的&lt;/h4&gt;报告旨在总结挑战赛成果，分析参赛方法，并指出未来研究方向。&lt;h4&gt;方法&lt;/h4&gt;挑战赛分为两个赛道：MOSE（关注复杂场景视频目标分割）和MeViS（针对运动引导、基于语言的视频分割）。两个赛道都引入了新的、更具挑战性的数据集，以更好地反映现实场景。&lt;h4&gt;主要发现&lt;/h4&gt;通过详细评估和分析，挑战赛提供了关于复杂视频分割当前最先进技术和新兴趋势的宝贵见解。&lt;h4&gt;结论&lt;/h4&gt;更多信息可在挑战赛网站（https://pvuw.github.io/）找到。&lt;h4&gt;翻译&lt;/h4&gt;This report provides a comprehensive overview of the 4th Pixel-level VideoUnderstanding in the Wild (PVUW) Challenge, held in conjunction with CVPR 2025. It summarizes the challenge outcomes, participating methodologies, and future research directions. The challenge features two tracks: MOSE, which focuses on complex scene video object segmentation, and MeViS, which targets motion-guided, language-based video segmentation. Both tracks introduce new, more challenging datasets designed to better reflect real-world scenarios. Through detailed evaluation and analysis, the challenge offers valuable insights into the current state-of-the-art and emerging trends in complex video segmentation. More information can be found on the workshop website: https://pvuw.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This report provides a comprehensive overview of the 4th Pixel-level VideoUnderstanding in the Wild (PVUW) Challenge, held in conjunction with CVPR 2025.It summarizes the challenge outcomes, participating methodologies, and futureresearch directions. The challenge features two tracks: MOSE, which focuses oncomplex scene video object segmentation, and MeViS, which targetsmotion-guided, language-based video segmentation. Both tracks introduce new,more challenging datasets designed to better reflect real-world scenarios.Through detailed evaluation and analysis, the challenge offers valuableinsights into the current state-of-the-art and emerging trends in complex videosegmentation. More information can be found on the workshop website:https://pvuw.github.io/.</description>
      <author>example@mail.com (Henghui Ding, Chang Liu, Nikhila Ravi, Shuting He, Yunchao Wei, Song Bai, Philip Torr, Kehuan Song, Xinglin Xie, Kexin Zhang, Licheng Jiao, Lingling Li, Shuyuan Yang, Xuqiang Cao, Linnan Zhao, Jiaxuan Zhao, Fang Liu, Mengjiao Wang, Junpei Zhang, Xu Liu, Yuting Yang, Mengru Ma, Hao Fang, Runmin Cong, Xiankai Lu, Zhiyang Che, Wei Zhan, Tianming Liang, Haichao Jiang, Wei-Shi Zheng, Jian-Fang Hu, Haobo Yuan, Xiangtai Li, Tao Zhang, Lu Qi, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2504.11326v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Hallucination-Aware Generative Pretrained Transformer for Cooperative Aerial Mobility Control</title>
      <link>http://arxiv.org/abs/2504.10831v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SafeGPT的两层框架，该框架将生成预训练变压器（GPT）与强化学习（RL）结合，以提高无人机（UAV）最后一公里配送的效率和可靠性。&lt;h4&gt;背景&lt;/h4&gt;无人机配送领域需要一种既能进行高效决策又能保证安全的系统。&lt;h4&gt;目的&lt;/h4&gt;开发一个既能实现高效配送又能保证安全的无人机配送系统。&lt;h4&gt;方法&lt;/h4&gt;SafeGPT框架包括一个全局GPT模块负责高级任务如区域分配，以及一个设备端GPT负责实时本地路径规划。一个基于RL的安全过滤器监控GPT的决策，并覆盖可能导致电池耗尽或重复访问的不安全行动。此外，双回放缓冲机制帮助GPT模块和RL代理随着时间的推移改进其策略。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果表明，SafeGPT相比仅使用GPT的基线，实现了更高的配送成功率，同时大幅降低了电池消耗和行驶距离。&lt;h4&gt;结论&lt;/h4&gt;将基于GPT的语义推理与正式的安全保证相结合是有效的，为鲁棒且节能的无人机物流提供了一种可行的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为SafeGPT的两层框架，该框架将生成预训练变压器（GPT）与强化学习（RL）结合，以提高无人机（UAV）最后一公里配送的效率和可靠性。在所提出的设计中，一个全局GPT模块负责分配高级任务，如区域分配，而一个设备端GPT负责实时本地路径规划。一个基于强化学习（RL）的安全过滤器监控每个GPT的决策，并覆盖可能导致电池耗尽或重复访问的不安全行动，有效地减轻了幻觉。此外，一个双回放缓冲机制帮助GPT模块和RL代理随着时间的推移改进他们的策略。模拟结果表明，与仅使用GPT的基线相比，SafeGPT实现了更高的配送成功率，同时大幅降低了电池消耗和行驶距离。这些发现验证了将基于GPT的语义推理与正式的安全保证相结合的有效性，为鲁棒且节能的无人机物流提供了一个可行的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes SafeGPT, a two-tiered framework that integratesgenerative pretrained transformers (GPTs) with reinforcement learning (RL) forefficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. Inthe proposed design, a Global GPT module assigns high-level tasks such assector allocation, while an On-Device GPT manages real-time local routeplanning. An RL-based safety filter monitors each GPT decision and overridesunsafe actions that could lead to battery depletion or duplicate visits,effectively mitigating hallucinations. Furthermore, a dual replay buffermechanism helps both the GPT modules and the RL agent refine their strategiesover time. Simulation results demonstrate that SafeGPT achieves higher deliverysuccess rates compared to a GPT-only baseline, while substantially reducingbattery consumption and travel distance. These findings validate the efficacyof combining GPT-based semantic reasoning with formal safety guarantees,contributing a viable solution for robust and energy-efficient UAV logistics.</description>
      <author>example@mail.com (Hyojun Ahn, Seungcheol Oh, Gyu Seon Kim, Soyi Jung, Soohyun Park, Joongheon Kim)</author>
      <guid isPermaLink="false">2504.10831v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Epistemic Uncertainty-aware Recommendation Systems via Bayesian Deep Ensemble Learning</title>
      <link>http://arxiv.org/abs/2504.10753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BDECF的贝叶斯深度集成协同过滤方法，旨在解决传统推荐系统在处理显式反馈和稀疏数据时的过拟合和预测中未考虑认知不确定性等问题。&lt;h4&gt;背景&lt;/h4&gt;推荐系统是一个基础任务，研究一直在努力改进。现有的许多模型使用表示学习将用户和物品映射到统一嵌入空间进行匹配评估，但存在过拟合和未考虑不确定性等局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的推荐方法，以提高模型泛化能力和预测质量，并解决过拟合和不确定性问题。&lt;h4&gt;方法&lt;/h4&gt;采用贝叶斯神经网络，结合注意力机制引入可解释的非线性匹配方法，并使用集成模型生成更稳健可靠的预测。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛实验和消融研究，验证了BDECF方法的有效性及其组成部分的重要性。&lt;h4&gt;结论&lt;/h4&gt;BDECF方法在处理显式反馈和稀疏数据时表现出色，为推荐系统领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommending items to users has long been a fundamental task, and studieshave tried to improve it ever since. Most well-known models commonly employrepresentation learning to map users and items into a unified embedding spacefor matching assessment. These approaches have primary limitations, especiallywhen dealing with explicit feedback and sparse data contexts. Two primarylimitations are their proneness to overfitting and failure to incorporateepistemic uncertainty in predictions. To address these problems, we propose anovel Bayesian Deep Ensemble Collaborative Filtering method named BDECF. Toimprove model generalization and quality, we utilize Bayesian Neural Networks,which incorporate uncertainty within their weight parameters. In addition, weintroduce a new interpretable non-linear matching approach for the user anditem embeddings, leveraging the advantages of the attention mechanism.Furthermore, we endorse the implementation of an ensemble-based supermodel togenerate more robust and reliable predictions, resulting in a more completemodel. Empirical evaluation through extensive experiments and ablation studiesacross a range of publicly accessible real-world datasets with differingsparsity characteristics confirms our proposed method's effectiveness and theimportance of its components.</description>
      <author>example@mail.com (Radin Cheraghi, Amir Mohammad Mahfoozi, Sepehr Zolfaghari, Mohammadshayan Shabani, Maryam Ramezani, Hamid R. Rabiee)</author>
      <guid isPermaLink="false">2504.10753v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image</title>
      <link>http://arxiv.org/abs/2504.11230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in CVPR 2025 (Highlight)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在机器人操作任务中关节物体的类别级姿态估计，并引入了一个新的基准数据集。&lt;h4&gt;背景&lt;/h4&gt;现有的方法在类别级别估计部分姿态和大小时，通常依赖于几何线索和复杂的多阶段流程，包括从点云中分割部分，然后进行标准化部分坐标空间（NPCS）的6D姿态估计。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，本文提出了一种名为CAP-Net的单阶段网络，用于估计类别级关节部分的6D姿态和尺寸。&lt;h4&gt;方法&lt;/h4&gt;CAP-Net结合RGB-D特征，以端到端的方式生成每个部分的实例分割和NPCS表示。该网络使用统一的网络同时预测点级类别标签、质心偏移和NPCS图。然后，基于估计的质心距离将同一预测类别的点聚类，以隔离每个部分。最后，将每个部分的NPCS区域与点云对齐，以恢复其最终姿态和尺寸。&lt;h4&gt;主要发现&lt;/h4&gt;本文引入的RGBD-Art数据集是迄今为止最大的RGB-D关节数据集，具有逼真的RGB图像和从真实传感器模拟的深度噪声。在RGBD-Art数据集上的实验评估表明，该方法显著优于现有方法。在机器人任务中的实际部署强调了该模型的鲁棒性和卓越的仿真到现实迁移能力，证实了其实际应用价值。&lt;h4&gt;结论&lt;/h4&gt;本文提出的CAP-Net方法在姿态估计方面取得了显著的性能提升，同时引入的RGBD-Art数据集为该领域提供了重要的资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper tackles category-level pose estimation of articulated objects inrobotic manipulation tasks and introduces a new benchmark dataset. While recentmethods estimate part poses and sizes at the category level, they often rely ongeometric cues and complex multi-stage pipelines that first segment parts fromthe point cloud, followed by Normalized Part Coordinate Space (NPCS) estimationfor 6D poses. These approaches overlook dense semantic cues from RGB images,leading to suboptimal accuracy, particularly for objects with small parts. Toaddress these limitations, we propose a single-stage Network, CAP-Net, forestimating the 6D poses and sizes of Categorical Articulated Parts. This methodcombines RGB-D features to generate instance segmentation and NPCSrepresentations for each part in an end-to-end manner. CAP-Net uses a unifiednetwork to simultaneously predict point-wise class labels, centroid offsets,and NPCS maps. A clustering algorithm then groups points of the same predictedclass based on their estimated centroid distances to isolate each part.Finally, the NPCS region of each part is aligned with the point cloud torecover its final pose and size. To bridge the sim-to-real domain gap, weintroduce the RGBD-Art dataset, the largest RGB-D articulated dataset to date,featuring photorealistic RGB images and depth noise simulated from realsensors. Experimental evaluations on the RGBD-Art dataset demonstrate that ourmethod significantly outperforms the state-of-the-art approach. Real-worlddeployments of our model in robotic tasks underscore its robustness andexceptional sim-to-real transfer capabilities, confirming its substantialpractical utility. Our dataset, code and pre-trained models are available onthe project page.</description>
      <author>example@mail.com (Jingshun Huang, Haitao Lin, Tianyu Wang, Yanwei Fu, Xiangyang Xue, Yi Zhu)</author>
      <guid isPermaLink="false">2504.11230v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Visual Re-Ranking with Non-Visual Side Information</title>
      <link>http://arxiv.org/abs/2504.11134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Scandinavian Conference on Image Analysis (SCIA) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了基于图神经网络的重新排序方法GCSA，用于视觉场景识别，旨在提高检索和定位任务的性能。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉场景识别方法使用全局图像描述符进行检索，并通过重新排序方法改进结果，但现有方法主要基于相同的描述符进行重新排序，这限制了额外信号的获取。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，利用除了视觉描述符之外的其他类型的信息，如传感器数据或几何属性，以提高场景识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;开发了GCSA，它利用亲和向量允许对异构多模态输入进行共享编码，并在两个大规模数据集上进行了训练和评估。&lt;h4&gt;主要发现&lt;/h4&gt;在图像检索和下游视觉定位任务上，该方法显示出显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;GCSA作为一种基于图神经网络的重新排序方法，能够有效提高视觉场景识别的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The standard approach for visual place recognition is to use global imagedescriptors to retrieve the most similar database images for a given queryimage. The results can then be further improved with re-ranking methods thatre-order the top scoring images. However, existing methods focus on re-rankingbased on the same image descriptors that were used for the initial retrieval,which we argue provides limited additional signal.  In this work we propose Generalized Contextual Similarity Aggregation (GCSA),which is a graph neural network-based re-ranking method that, in addition tothe visual descriptors, can leverage other types of available side information.This can for example be other sensor data (such as signal strength of nearbyWiFi or BlueTooth endpoints) or geometric properties such as camera poses fordatabase images. In many applications this information is already present orcan be acquired with low effort. Our architecture leverages the concept ofaffinity vectors to allow for a shared encoding of the heterogeneousmulti-modal input. Two large-scale datasets, covering both outdoor and indoorlocalization scenarios, are utilized for training and evaluation. Inexperiments we show significant improvement not only on image retrievalmetrics, but also for the downstream visual localization task.</description>
      <author>example@mail.com (Gustav Hanning, Gabrielle Flood, Viktor Larsson)</author>
      <guid isPermaLink="false">2504.11134v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians</title>
      <link>http://arxiv.org/abs/2504.11218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first large-scale 3D Gaussians Affordance Reasoning Benchmark&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了3D affordance reasoning在关联人类指令与3D物体功能区域中的重要性，并提出了3DAffordSplat和AffordSplatNet，旨在提高3DGS在 affordance reasoning 中的表现。&lt;h4&gt;背景&lt;/h4&gt;现有的3D affordance reasoning方法依赖于稀疏的3D点云，存在泛化性和鲁棒性不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于3D Gaussian Splatting (3DGS) 的 affordance reasoning 方法，并构建一个大规模的、多模态的3DGS-specific affordance dataset。&lt;h4&gt;方法&lt;/h4&gt;构建了3DAffordSplat，一个包含23,677个高斯实例、8,354个点云实例和6,631个手动标注的affordance标签的大规模数据集。提出了AffordSplatNet模型，该模型具有创新的跨模态结构对齐模块，用于对齐3D点云和3DGS表示，以提高affordance recognition的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;3DAffordSplat数据集显著推进了3DGS领域的affordance学习，AffordSplatNet在已见和未见设置中均优于现有方法，展示了其强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;3DAffordSplat和AffordSplatNet为3D affordance reasoning提供了新的解决方案，提高了affordance recognition的准确性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D affordance reasoning is essential in associating human instructions withthe functional regions of 3D objects, facilitating precise, task-orientedmanipulations in embodied AI. However, current methods, which predominantlydepend on sparse 3D point clouds, exhibit limited generalizability androbustness due to their sensitivity to coordinate variations and the inherentsparsity of the data. By contrast, 3D Gaussian Splatting (3DGS) delivershigh-fidelity, real-time rendering with minimal computational overhead byrepresenting scenes as dense, continuous distributions. This positions 3DGS asa highly effective approach for capturing fine-grained affordance details andimproving recognition accuracy. Nevertheless, its full potential remainslargely untapped due to the absence of large-scale, 3DGS-specific affordancedatasets. To overcome these limitations, we present 3DAffordSplat, the firstlarge-scale, multi-modal dataset tailored for 3DGS-based affordance reasoning.This dataset includes 23,677 Gaussian instances, 8,354 point cloud instances,and 6,631 manually annotated affordance labels, encompassing 21 objectcategories and 18 affordance types. Building upon this dataset, we introduceAffordSplatNet, a novel model specifically designed for affordance reasoningusing 3DGS representations. AffordSplatNet features an innovative cross-modalstructure alignment module that exploits structural consistency priors to align3D point cloud and 3DGS representations, resulting in enhanced affordancerecognition accuracy. Extensive experiments demonstrate that the 3DAffordSplatdataset significantly advances affordance learning within the 3DGS domain,while AffordSplatNet consistently outperforms existing methods across both seenand unseen settings, highlighting its robust generalization capabilities.</description>
      <author>example@mail.com (Zeming wei, Junyi Lin, Yang Liu, Weixing Chen, Jingzhou Luo, Guanbin Li, Liang Lin)</author>
      <guid isPermaLink="false">2504.11218v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>OmniVDiff: Omni Controllable Video Diffusion for Generation and Understanding</title>
      <link>http://arxiv.org/abs/2504.10825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Our project page: https://tele-ai.github.io/OmniVDiff/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为OmniVDiff的新型可控视频扩散框架，旨在通过单个扩散模型合成和理解多种视频视觉内容。&lt;h4&gt;背景&lt;/h4&gt;当前视频处理方法通常需要多个模型来处理不同的视觉模态，这增加了复杂性和计算成本。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在一个扩散模型中合成和理解多种视频视觉内容的框架。&lt;h4&gt;方法&lt;/h4&gt;OmniVDiff将所有视频视觉模态处理为颜色空间中的联合分布，并采用自适应控制策略，动态调整每个视觉模态在扩散过程中的角色，可以是生成模态或条件模态。&lt;h4&gt;主要发现&lt;/h4&gt;OmniVDiff支持三种关键功能：(1) 文本条件视频生成；(2) 视频理解；(3) X条件视频生成。通过将这些任务整合到一个统一的视频扩散框架中，OmniVDiff提高了可控视频扩散的灵活性和可扩展性。&lt;h4&gt;结论&lt;/h4&gt;广泛的实验证明了该方法的有效性，并突出了其在各种视频相关应用中的潜力，如视频到视频的翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel framework for controllable video diffusion,OmniVDiff, aiming to synthesize and comprehend multiple video visual content ina single diffusion model. To achieve this, OmniVDiff treats all video visualmodalities in the color space to learn a joint distribution, while employing anadaptive control strategy that dynamically adjusts the role of each visualmodality during the diffusion process, either as a generation modality or aconditioning modality. This allows flexible manipulation of each modality'srole, enabling support for a wide range of tasks. Consequently, our modelsupports three key functionalities: (1) Text-conditioned video generation:multi-modal visual video sequences (i.e., rgb, depth, canny, segmentaion) aregenerated based on the text conditions in one diffusion process; (2) Videounderstanding: OmniVDiff can estimate the depth, canny map, and semanticsegmentation across the input rgb frames while ensuring coherence with the rgbinput; and (3) X-conditioned video generation: OmniVDiff generates videosconditioned on fine-grained attributes (e.g., depth maps or segmentation maps).By integrating these diverse tasks into a unified video diffusion framework,OmniVDiff enhances the flexibility and scalability for controllable videodiffusion, making it an effective tool for a variety of downstreamapplications, such as video-to-video translation. Extensive experimentsdemonstrate the effectiveness of our approach, highlighting its potential forvarious video-related applications.</description>
      <author>example@mail.com (Dianbing Xi, Jiepeng Wang, Yuanzhi Liang, Xi Qiu, Yuchi Huo, Rui Wang, Chi Zhang, Xuelong Li)</author>
      <guid isPermaLink="false">2504.10825v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Textual Embeddings from Contrastive Learning with Generative Recommender for Enhanced Personalization</title>
      <link>http://arxiv.org/abs/2504.10545v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code available at https://www.github.com/snapfinger/HSTU-BLaIR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合生成模型和预训练语言模型的混合框架，用于改进推荐系统。&lt;h4&gt;背景&lt;/h4&gt;推荐系统在近期发展强调了生成建模和预训练语言模型的优势互补。&lt;h4&gt;目的&lt;/h4&gt;提出一种混合框架，以增强Hierarchical Sequential Transduction Unit（HSTU）生成推荐器。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了HSTU和对比文本嵌入模型BLaIR，以丰富物品表示并保留HSTU的序列建模能力。&lt;h4&gt;主要发现&lt;/h4&gt;在Amazon Reviews 2023数据集的两个领域上评估了该方法，与原始HSTU和结合OpenAI的text-embedding-3-large模型的变体相比，轻量级的BLaIR增强方法在计算高效的环境中表现出色。&lt;h4&gt;结论&lt;/h4&gt;BLaIR增强的轻量级方法在特定领域数据上预训练，能够在计算高效的环境中实现更好的性能，证明了对比文本嵌入的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in recommender systems have highlighted the complementarystrengths of generative modeling and pretrained language models. We propose ahybrid framework that augments the Hierarchical Sequential Transduction Unit(HSTU) generative recommender with BLaIR -- a contrastive text embedding model.This integration enriches item representations with semantic signals fromtextual metadata while preserving HSTU's powerful sequence modelingcapabilities.  We evaluate our method on two domains from the Amazon Reviews 2023 dataset,comparing it against the original HSTU and a variant that incorporatesembeddings from OpenAI's state-of-the-art text-embedding-3-large model. Whilethe OpenAI embedding model is likely trained on a substantially larger corpuswith significantly more parameters, our lightweight BLaIR-enhanced approach --pretrained on domain-specific data -- consistently achieves better performance,highlighting the effectiveness of contrastive text embeddings incompute-efficient settings.</description>
      <author>example@mail.com (Yijun Liu)</author>
      <guid isPermaLink="false">2504.10545v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Tabular foundation model to detect empathy from visual cues</title>
      <link>http://arxiv.org/abs/2504.10808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了从视频中检测同理心，提出使用表格基础模型进行同理心检测，实验结果表明该方法在交叉主体同理心检测精度上有显著提升。&lt;h4&gt;背景&lt;/h4&gt;由于隐私和伦理问题，视频数据集通常以提取的特征（表格数据）形式发布，而非原始视频。&lt;h4&gt;目的&lt;/h4&gt;探索使用表格基础模型从表格视觉特征中检测同理心。&lt;h4&gt;方法&lt;/h4&gt;实验中使用了TabPFN v2和TabICL两个表格基础模型，通过上下文学习和微调的方式进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;在公共人机交互基准测试中，该方法在交叉主体同理心检测精度上比多个基线模型有显著提升（精度从0.590提升到0.730；AUC从0.564提升到0.669）。&lt;h4&gt;结论&lt;/h4&gt;该方法在同理心检测上有效，且有望应用于未来同理心检测视频数据集。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从视频交互中检测同理心是研究的一个新兴领域。然而，由于隐私和伦理问题的考虑，视频数据集通常以提取的特征（即表格数据）的形式发布，而不是原始视频。先前对这类表格数据集的研究已经确定了基于树的经典机器学习方法为最佳性能模型。受文本基础模型（即大型语言模型）近期成功的影响，我们探索了在表格视觉特征中检测同理心时使用表格基础模型。我们通过上下文学习和微调设置，对两个最近的表格基础模型——TabPFN v2和TabICL进行了实验。我们在公共人机交互基准测试上的实验表明，与多个基线相比，该方法在交叉主体同理心检测精度上有显著的提升（精度：0.590 → 0.730；AUC：0.564 → 0.669）。除了性能提升外，我们还贡献了新的见解和评估设置，以确保在公共基准测试中未见过的主体上的泛化。鉴于发布视频特征作为表格数据集的做法可能因隐私限制而持续，我们的发现也将广泛适用于未来的同理心检测视频数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting empathy from video interactions is an emerging area of research.Video datasets, however, are often released as extracted features (i.e.,tabular data) rather than raw footage due to privacy and ethical concerns.Prior research on such tabular datasets established tree-based classicalmachine learning approaches as the best-performing models. Motivated by therecent success of textual foundation models (i.e., large language models), weexplore the use of tabular foundation models in empathy detection from tabularvisual features. We experiment with two recent tabular foundation models $-$TabPFN v2 and TabICL $-$ through in-context learning and fine-tuning setups.Our experiments on a public human-robot interaction benchmark demonstrate asignificant boost in cross-subject empathy detection accuracy over severalstrong baselines (accuracy: $0.590 \rightarrow 0.730$; AUC: $0.564 \rightarrow0.669$). In addition to performance improvement, we contribute novel insightsand an evaluation setup to ensure generalisation on unseen subjects in thispublic benchmark. As the practice of releasing video features as tabulardatasets is likely to persist due to privacy constraints, our findings will bewidely applicable to future empathy detection video datasets as well.</description>
      <author>example@mail.com (Md Rakibul Hasan, Shafin Rahman, Md Zakir Hossain, Aneesh Krishna, Tom Gedeon)</author>
      <guid isPermaLink="false">2504.10808v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>SDFs from Unoriented Point Clouds using Neural Variational Heat Distances</title>
      <link>http://arxiv.org/abs/2504.11212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 16 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的变分方法，用于从无向点云计算神经符号距离场（SDF）。该方法使用热方法替代常见的波动方程，将离散表面上计算距离的标准实践扩展到神经域。&lt;h4&gt;背景&lt;/h4&gt;传统的计算SDF的方法通常使用波动方程，但在神经域中计算距离时，这种方法并不适用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以计算无向点云的神经SDF，并证明该方法在表面重建和SDF梯度计算上的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用热方法替代波动方程，通过计算无向点云的加权密度作为初始数据，通过一小段时间步的热流来计算无符号距离场的神经近似梯度。然后，使用这个梯度来计算SDF的神经近似。证明了变分问题是有良好定义的。&lt;h4&gt;主要发现&lt;/h4&gt;该方法提供了最先进的表面重建和一致的SDF梯度，并且通过概念验证表明，它足够准确，可以解决零水平集上的偏微分方程。&lt;h4&gt;结论&lt;/h4&gt;该方法在计算神经SDF方面是有效的，并且对于解决零水平集上的偏微分方程是准确的。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的变分方法，用于从无向点云计算神经符号距离场（SDF）。为此，我们用热方法替换了常用的波动方程，将离散表面上计算距离的标准实践扩展到神经域。这产生了两个凸优化问题，我们使用神经网络来解决它们：我们首先通过一小段时间步的热流，使用加权点云密度作为初始数据，计算无符号距离场梯度的神经近似。然后，我们使用它来计算SDF的神经近似。我们证明了背后的变分问题是有良好定义的。通过数值实验，我们证明了我们的方法提供了最先进的表面重建和一致的SDF梯度。此外，我们在一个概念验证中表明，它足够准确，可以解决零水平集上的偏微分方程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel variational approach for computing neural Signed DistanceFields (SDF) from unoriented point clouds. To this end, we replace the commonlyused eikonal equation with the heat method, carrying over to the neural domainwhat has long been standard practice for computing distances on discretesurfaces. This yields two convex optimization problems for whose solution weemploy neural networks: We first compute a neural approximation of thegradients of the unsigned distance field through a small time step of heat flowwith weighted point cloud densities as initial data. Then we use it to computea neural approximation of the SDF. We prove that the underlying variationalproblems are well-posed. Through numerical experiments, we demonstrate that ourmethod provides state-of-the-art surface reconstruction and consistent SDFgradients. Furthermore, we show in a proof-of-concept that it is accurateenough for solving a PDE on the zero-level set.</description>
      <author>example@mail.com (Samuel Weidemaier, Florine Hartwig, Josua Sassen, Sergio Conti, Mirela Ben-Chen, Martin Rumpf)</author>
      <guid isPermaLink="false">2504.11212v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>AI-guided Antibiotic Discovery Pipeline from Target Selection to Compound Identification</title>
      <link>http://arxiv.org/abs/2504.11091v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种端到端的人工智能引导的抗生素发现流程，该流程涵盖了从靶点识别到化合物实现的整个过程。&lt;h4&gt;背景&lt;/h4&gt;抗生素耐药性成为全球性的健康危机，需要新的治疗策略来针对新型细菌机制。蛋白质结构预测和机器学习驱动的分子生成在药物发现中提供了加速的机会。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够将蛋白质结构预测和机器学习模型集成到实际流程中的抗生素发现流程。&lt;h4&gt;方法&lt;/h4&gt;利用基于结构的聚类分析，对多种病原体的预测蛋白质组进行聚类，以识别保守的、必要的、非人类同源靶点。对六种领先的3D结构感知生成模型进行系统性评估，包括扩散模型、自回归模型、图神经网络和语言模型架构，评估其可用性、化学有效性和生物学相关性。&lt;h4&gt;主要发现&lt;/h4&gt;通过严格的后期处理过滤和商业类似物搜索，将生成的超过10万个化合物减少到一个聚焦且可合成的集合。DeepBlock和TamGen在多个标准上表现出色，同时揭示了模型复杂性、可用性和输出质量之间的关键权衡。&lt;h4&gt;结论&lt;/h4&gt;本研究提供了一个比较基准和蓝图，用于在抗生素早期开发中部署人工智能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Antibiotic resistance presents a growing global health crisis, demanding newtherapeutic strategies that target novel bacterial mechanisms. Recent advancesin protein structure prediction and machine learning-driven molecule generationoffer a promising opportunity to accelerate drug discovery. However, practicalguidance on selecting and integrating these models into real-world pipelinesremains limited. In this study, we develop an end-to-end, artificialintelligence-guided antibiotic discovery pipeline that spans targetidentification to compound realization. We leverage structure-based clusteringacross predicted proteomes of multiple pathogens to identify conserved,essential, and non-human-homologous targets. We then systematically evaluatesix leading 3D-structure-aware generative models$\unicode{x2014}$spanningdiffusion, autoregressive, graph neural network, and language modelarchitectures$\unicode{x2014}$on their usability, chemical validity, andbiological relevance. Rigorous post-processing filters and commercial analoguesearches reduce over 100 000 generated compounds to a focused, synthesizableset. Our results highlight DeepBlock and TamGen as top performers acrossdiverse criteria, while also revealing critical trade-offs between modelcomplexity, usability, and output quality. This work provides a comparativebenchmark and blueprint for deploying artificial intelligence in early-stageantibiotic development.</description>
      <author>example@mail.com (Maximilian G. Schuh, Joshua Hesse, Stephan A. Sieber)</author>
      <guid isPermaLink="false">2504.11091v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Q-Cluster: Quantum Error Mitigation Through Noise-Aware Unsupervised Learning</title>
      <link>http://arxiv.org/abs/2504.10801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Q-Cluster的新型量子错误缓解(QEM)方法，通过无监督学习(聚类)重塑测量到的比特串分布，以减少预容错时代中的噪声影响，并预期将补充容错量子计算(FTQC)中的错误纠正。&lt;h4&gt;背景&lt;/h4&gt;量子错误缓解在减少预容错时代噪声影响方面至关重要，并且预计将在容错量子计算中补充错误纠正。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的量子错误缓解方法，以降低量子计算中的噪声影响。&lt;h4&gt;方法&lt;/h4&gt;Q-Cluster方法首先使用简化的比特翻转噪声模型，然后基于汉明距离对噪声测量结果（即比特串）进行聚类。每个聚类的中心通过量子比特多数投票计算得出。接着，使用贝叶斯推理调整噪声分布，同时考虑聚类结果和比特翻转错误率。为了适应复杂的噪声环境，方法中使用了Pauli旋转和ExtraTrees回归器来估计比特翻转错误率。&lt;h4&gt;主要发现&lt;/h4&gt;Q-Cluster可以在简单的比特翻转噪声模型下缓解高达40%的噪声率。在低熵基准测试中，与未经缓解的输出分布相比，Q-Cluster方案平均提高了1.46倍的保真度，并在五台不同的IBM量子机器上优于现有的QEM方法M3、Hammer和QBEEP。&lt;h4&gt;结论&lt;/h4&gt;Q-Cluster方案在提高量子计算保真度方面具有显著优势，是一种有效的量子错误缓解方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum error mitigation (QEM) is critical in reducing the impact of noise inthe pre-fault-tolerant era, and is expected to complement error correction infault-tolerant quantum computing (FTQC). In this paper, we propose a novel QEMapproach, Q-Cluster, that uses unsupervised learning (clustering) to reshapethe measured bit-string distribution. Our approach starts with a simplifiedbit-flip noise model. It first performs clustering on noisy measurementresults, i.e., bit-strings, based on the Hamming distance. The centroid of eachcluster is calculated using a qubit-wise majority vote. Next, the noisydistribution is adjusted with the clustering outcomes and the bit-flip errorrates using Bayesian inference. Our simulation results show that Q-Cluster canmitigate high noise rates (up to 40% per qubit) with the simple bit-flip noisemodel. However, real quantum computers do not fit such a simple noise model. Toaddress the problem, we (a) apply Pauli twirling to tailor the complex noisechannels to Pauli errors, and (b) employ a machine learning model, ExtraTreesregressor, to estimate an effective bit-flip error rate using a feature vectorconsisting of machine calibration data (gate &amp; measurement error rates),circuit features (number of qubits, numbers of different types of gates, etc.)and the shape of the noisy distribution (entropy). Our experimental resultsshow that our proposed Q-Cluster scheme improves the fidelity by a factor of1.46x, on average, compared to the unmitigated output distribution, for a setof low-entropy benchmarks on five different IBM quantum machines. Our approachoutperforms the state-of-art QEM approaches M3 [24], Hammer [35], and QBEEP[33] by 1.29x, 1.47x, and 2.65x, respectively.</description>
      <author>example@mail.com (Hrushikesh Pramod Patil, Dror Baron, Huiyang Zhou)</author>
      <guid isPermaLink="false">2504.10801v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Data Distribution and Kernel Performance for Efficient Training of Chemistry Foundation Models: A Case Study with MACE</title>
      <link>http://arxiv.org/abs/2504.10700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at The 34th ACM International Symposium on High-Performance  Parallel and Distributed Computing (HPDC 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了针对Chemistry Foundation Models（CFMs）的优化方法，特别是针对MACE这一先进的CFM模型，通过优化数据分布和模型训练过程，提高了CFM的训练效率。&lt;h4&gt;背景&lt;/h4&gt;利用图神经网络（GNNs）在3D分子图结构上运行的CFMs已成为计算化学家和材料科学家不可或缺的工具，它们有助于理解物质并发现新的分子和材料。&lt;h4&gt;目的&lt;/h4&gt;针对CFM训练的两个关键阶段——数据分布和模型训练，提出优化策略，以提高MACE的训练效率。&lt;h4&gt;方法&lt;/h4&gt;将数据分布中的负载平衡问题建模为多目标装箱问题，并提出一个迭代算法来优化数据分布；识别对称张量收缩为MACE的关键计算内核，并对其进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;优化后的方法显著提高了MACE的训练过程，实验结果显示，在740个GPU上使用2.6M样本数据集进行训练时，每轮执行时间从12分钟缩短到2分钟。&lt;h4&gt;结论&lt;/h4&gt;本文提出的优化方法可以显著提高CFM的训练效率，对计算化学和材料科学领域具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces optimization methods for Chemistry Foundation Models (CFMs), especially for the state-of-the-art CFM MACE, by optimizing the two critical phases of CFM training - data distribution and model training, to improve the training efficiency of CFMs. Utilizing Graph Neural Networks (GNNs) operating on 3D molecular graph structures, CFMs have become indispensable tools for computational chemists and materials scientists, which help to understand matter and discover new molecules and materials. The purpose of this paper is to optimize the two critical phases of CFM training - data distribution and model training, for the advanced CFM MACE, to improve the training efficiency. The method is to model the load balancing problem in data distribution as a multi-objective bin packing problem, and propose an iterative algorithm to optimize data distribution; identify symmetric tensor contraction as the key computational kernel in MACE, and optimize this kernel. The optimized method significantly improves the training process of MACE, and the experimental results show that the per-epoch execution time for training is reduced from 12 minutes to 2 minutes on 740 GPUs with a 2.6M sample dataset. The conclusion is that the proposed optimization methods can significantly improve the training efficiency of CFMs, which is of great significance to the fields of computational chemistry and materials science.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Chemistry Foundation Models (CFMs) that leverage Graph Neural Networks (GNNs)operating on 3D molecular graph structures are becoming indispensable tools forcomputational chemists and materials scientists. These models facilitate theunderstanding of matter and the discovery of new molecules and materials. Incontrast to GNNs operating on a large homogeneous graphs, GNNs used by CFMsprocess a large number of geometric graphs of varying sizes, requiringdifferent optimization strategies than those developed for large homogeneousGNNs. This paper presents optimizations for two critical phases of CFMtraining: data distribution and model training, targeting MACE - astate-of-the-art CFM. We address the challenge of load balancing in datadistribution by formulating it as a multi-objective bin packing problem. Wepropose an iterative algorithm that provides a highly effective, fast, andpractical solution, ensuring efficient data distribution. For the trainingphase, we identify symmetric tensor contraction as the key computational kernelin MACE and optimize this kernel to improve the overall performance. Ourcombined approach of balanced data distribution and kernel optimizationsignificantly enhances the training process of MACE. Experimental resultsdemonstrate a substantial speedup, reducing per-epoch execution time fortraining from 12 to 2 minutes on 740 GPUs with a 2.6M sample dataset.</description>
      <author>example@mail.com (Jesun Firoz, Franco Pellegrini, Mario Geiger, Darren Hsu, Jenna A. Bilbrey, Han-Yi Chou, Maximilian Stadler, Markus Hoehnerbach, Tingyu Wang, Dejun Lin, Emine Kucukbenli, Henry W. Sprueill, Ilyes Batatia, Sotiris S. Xantheas, MalSoon Lee, Chris Mundy, Gabor Csanyi, Justin S. Smith, Ponnuswamy Sadayappan, Sutanay Choudhury)</author>
      <guid isPermaLink="false">2504.10700v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian Splatting for Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2504.10331v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LL-Gaussian的新框架，用于从低光照sRGB图像中进行3D重建和增强，实现伪正常光照的新视角合成。&lt;h4&gt;背景&lt;/h4&gt;低光照场景下的新视角合成（NVS）是一个重大挑战，由于输入质量下降，存在严重噪声、低动态范围（LDR）和不稳定的初始化。&lt;h4&gt;目的&lt;/h4&gt;为了解决低光照场景下的NVS挑战，提高合成图像的质量和效率。&lt;h4&gt;方法&lt;/h4&gt;LL-Gaussian框架包含三个关键创新：1）端到端的低光照高斯初始化模块（LLGIM），利用基于学习的方法的密集先验生成高质量的初始点云；2）双分支高斯分解模型，将场景的固有属性（反射率和照明）从瞬态干扰中分离出来，实现稳定和可解释的优化；3）一种受物理约束和扩散先验指导的无监督优化策略，以联合引导分解和增强。&lt;h4&gt;主要发现&lt;/h4&gt;LL-Gaussian在极端低光照环境下收集的数据集上展示了有效性，与最先进的基于NeRF的方法相比，LL-Gaussian实现了高达2000倍的推理速度提升，并将训练时间缩短到2%，同时提供了更高质量的重建和渲染。&lt;h4&gt;结论&lt;/h4&gt;LL-Gaussian框架为低光照场景下的新视角合成提供了一种有效且高效的解决方案，显著提高了合成图像的质量和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Novel view synthesis (NVS) in low-light scenes remains a significantchallenge due to degraded inputs characterized by severe noise, low dynamicrange (LDR) and unreliable initialization. While recent NeRF-based approacheshave shown promising results, most suffer from high computational costs, andsome rely on carefully captured or pre-processed data--such as RAW sensorinputs or multi-exposure sequences--which severely limits their practicality.In contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering withcompetitive visual fidelity; however, existing 3DGS-based methods struggle withlow-light sRGB inputs, resulting in unstable Gaussian initialization andineffective noise suppression. To address these challenges, we proposeLL-Gaussian, a novel framework for 3D reconstruction and enhancement fromlow-light sRGB images, enabling pseudo normal-light novel view synthesis. Ourmethod introduces three key innovations: 1) an end-to-end Low-Light GaussianInitialization Module (LLGIM) that leverages dense priors from learning-basedMVS approach to generate high-quality initial point clouds; 2) a dual-branchGaussian decomposition model that disentangles intrinsic scene properties(reflectance and illumination) from transient interference, enabling stable andinterpretable optimization; 3) an unsupervised optimization strategy guided byboth physical constrains and diffusion prior to jointly steer decomposition andenhancement. Additionally, we contribute a challenging dataset collected inextreme low-light environments and demonstrate the effectiveness ofLL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussianachieves up to 2,000 times faster inference and reduces training time to just2%, while delivering superior reconstruction and rendering quality.</description>
      <author>example@mail.com (Hao Sun, Fenggen Yu, Huiyao Xu, Tao Zhang, Changqing Zou)</author>
      <guid isPermaLink="false">2504.10331v2</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Why am I seeing this? Towards recognizing social media recommender systems with missing recommendations</title>
      <link>http://arxiv.org/abs/2504.11000v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at RLDM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;社交媒体在塑造社会方面起着关键作用，它往往加剧了极化和传播错误信息。这些影响源于用户互动、个人特性和驱动内容选择的推荐算法的复杂动态。推荐系统对用户看到的内容和所做的决策有重大影响，为干预和监管提供了机会。然而，由于算法的不透明性和数据可用性的限制，评估其影响具有挑战性。为了有效地模拟用户决策，认识到平台采用的推荐系统至关重要。&lt;h4&gt;背景&lt;/h4&gt;社交媒体在塑造社会方面起着关键作用，但同时也加剧了极化和错误信息的传播。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图神经网络（GNN）的自动推荐识别方法，仅使用网络结构和观察到的行为来识别隐藏的推荐系统。&lt;h4&gt;方法&lt;/h4&gt;首先，使用GNN和改进的后见之明学术网络推荐器训练一个推荐中立用户模型（RNU），以减少对实际推荐器的数据依赖。然后，通过将RNU与不同的已知推荐器结合生成多个推荐假设特定合成数据集（RHSD），为测试生成真实情况。最后，在多种假设下训练推荐假设特定用户模型（RHU），并将每个候选模型与生成RHSD的原模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够准确检测隐藏的推荐系统和它们对用户行为的影响，并且与基于审计的方法不同，它直接捕捉系统行为，无需进行无法反映真实平台的临时代验。&lt;h4&gt;结论&lt;/h4&gt;本研究提供了关于推荐系统如何塑造行为的见解，有助于减少极化和错误信息。&lt;h4&gt;翻译&lt;/h4&gt;This work introduces a method for Automatic Recommender Recognition using Graph Neural Networks (GNNs), based solely on network structure and observed behavior. To infer the hidden recommender, we first train a Recommender Neutral User model (RNU) using a GNN and an adapted hindsight academic network recommender, aiming to reduce reliance on the actual recommender in the data. We then generate several Recommender Hypothesis-specific Synthetic Datasets (RHSD) by combining the RNU with different known recommenders, producing groundtruths for testing. Finally, we train Recommender Hypothesis-specific User models (RHU) under various hypotheses and compare each candidate with the original used to generate the RHSD. Our approach enables accurate detection of hidden recommenders and their influence on user behavior. Unlike audit-based methods, it captures system behavior directly, without ad hoc experiments that often fail to reflect real platforms. This study provides insights into how recommenders shape behavior, aiding efforts to reduce polarization and misinformation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Social media plays a crucial role in shaping society, often amplifyingpolarization and spreading misinformation. These effects stem from complexdynamics involving user interactions, individual traits, and recommenderalgorithms driving content selection. Recommender systems, which significantlyshape the content users see and decisions they make, offer an opportunity forintervention and regulation. However, assessing their impact is challenging dueto algorithmic opacity and limited data availability. To effectively model userdecision-making, it is crucial to recognize the recommender system adopted bythe platform.  This work introduces a method for Automatic Recommender Recognition usingGraph Neural Networks (GNNs), based solely on network structure and observedbehavior. To infer the hidden recommender, we first train a Recommender NeutralUser model (RNU) using a GNN and an adapted hindsight academic networkrecommender, aiming to reduce reliance on the actual recommender in the data.We then generate several Recommender Hypothesis-specific Synthetic Datasets(RHSD) by combining the RNU with different known recommenders, producing groundtruths for testing. Finally, we train Recommender Hypothesis-specific Usermodels (RHU) under various hypotheses and compare each candidate with theoriginal used to generate the RHSD.  Our approach enables accurate detection of hidden recommenders and theirinfluence on user behavior. Unlike audit-based methods, it captures systembehavior directly, without ad hoc experiments that often fail to reflect realplatforms. This study provides insights into how recommenders shape behavior,aiding efforts to reduce polarization and misinformation.</description>
      <author>example@mail.com (Sabrina Guidotti, Sabrina Patania, Giuseppe Vizzari, Dimitri Ognibene, Gregor Donabauer, Udo Kruschwitz, Davide Taibi)</author>
      <guid isPermaLink="false">2504.11000v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning Assisted XgBoost For Adaptable Cyberattack Detection In Battery Packs</title>
      <link>http://arxiv.org/abs/2504.10658v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于XgBoost模型的电动汽车充电过程中的传感器数据攻击检测算法，旨在确保充电安全。&lt;h4&gt;背景&lt;/h4&gt;电动汽车的充电安全依赖于电池包到云控制器的可靠传感器测量，但存在攻击者可能篡改电压传感器数据的风险。&lt;h4&gt;目的&lt;/h4&gt;实时检测传感器网络攻击，以确保电动汽车充电安全，并使检测算法能够适应不同的电池包配置。&lt;h4&gt;方法&lt;/h4&gt;使用PyBaMM和`liionpack'包中的高保真充电实验数据来训练和测试检测算法，并对两个大型电池包进行了传感器交换和重放攻击的模拟。&lt;h4&gt;主要发现&lt;/h4&gt;提出的检测算法在两种大型电池包的传感器交换和重放攻击下表现出良好的适应性和有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的检测算法能够适应电池包配置的变化，并有效检测传感器数据攻击，为电动汽车的安全充电提供了保障。&lt;h4&gt;翻译&lt;/h4&gt;摘要：电动汽车（EV）的最佳充电依赖于智能充电站电池包到云控制器的可靠传感器测量。然而，攻击者可能在传输过程中篡改电压传感器数据，这可能导致局部到广泛的干扰。因此，实时检测传感器网络攻击对于确保安全充电至关重要，并且所开发的算法必须能够适应包括包配置在内的变化。为了应对这些挑战，我们提出了基于XgBoost的电池级模型的自适应微调，使用有限的电池包级数据用于电压预测和残差生成。我们使用了来自PyBaMM和`liionpack'包的高保真充电实验中的电池单元和电池包数据来训练和测试检测算法。该算法的性能已在两个大型电池包的传感器交换和重放攻击下进行了评估。模拟结果还突出了我们提出的检测算法的适应性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimal charging of electric vehicle (EVs) depends heavily on reliable sensormeasurements from the battery pack to the cloud-controller of the smartcharging station. However, an adversary could corrupt the voltage sensor dataduring transmission, potentially causing local to wide-scale disruptions.Therefore, it is essential to detect sensor cyberattacks in real-time to ensuresecure EV charging, and the developed algorithms must be readily adaptable tovariations, including pack configurations. To tackle these challenges, wepropose adaptable fine-tuning of an XgBoost-based cell-level model usinglimited pack-level data to use for voltage prediction and residual generation.We used battery cell and pack data from high-fidelity charging experiments inPyBaMM and `liionpack' package to train and test the detection algorithm. Thealgorithm's performance has been evaluated for two large-format battery packsunder sensor swapping and replay attacks. The simulation results also highlightthe adaptability and efficacy of our proposed detection algorithm.</description>
      <author>example@mail.com (Sanchita Ghosh, Tanushree Roy)</author>
      <guid isPermaLink="false">2504.10658v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Towards A Universal Graph Structural Encoder</title>
      <link>http://arxiv.org/abs/2504.10917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该摘要介绍了一种名为GFSE的通用图结构编码器，用于在不同图域中捕获和转移结构信息，以解决现有模型在捕捉复杂图结构方面的不足。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练在下游任务中学习可泛化表示的潜力已被证明，但在图域中，由于不同图域之间拓扑模式的不同，捕获和转移结构信息仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种名为GFSE的通用图结构编码器，旨在捕捉不同领域（如分子图、社交网络和引文网络）中可转移的结构模式。&lt;h4&gt;方法&lt;/h4&gt;GFSE基于图Transformer，结合了图归纳偏差的注意力机制，能够编码多层次和细粒度的拓扑特征。它通过多个自监督学习目标进行跨域预训练。&lt;h4&gt;主要发现&lt;/h4&gt;预训练的GFSE产生了通用的和理论上有表达力的位置和结构编码，可以无缝集成到各种下游图特征编码器中，包括用于矢量化特征的图神经网络和用于文本属性图的Large Language Models。实验表明，GFSE能够显著提高模型性能，同时需要较少的任务特定微调。&lt;h4&gt;结论&lt;/h4&gt;GFSE在81.6%的评估案例中实现了最先进的性能，覆盖了多种图模型和数据集，突显了其作为强大且多用途的图结构数据编码器的潜力。&lt;h4&gt;翻译&lt;/h4&gt;In this abstract, a universal graph structural encoder called GFSE is introduced, designed to capture and transfer structural information across different graph domains, addressing the limitations of existing models in capturing complex graph structures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large-scale pre-training have shown the potential tolearn generalizable representations for downstream tasks. In the graph domain,however, capturing and transferring structural information across differentgraph domains remains challenging, primarily due to the inherent differences intopological patterns across various contexts. Additionally, most existingmodels struggle to capture the complexity of rich graph structures, leading toinadequate exploration of the embedding space. To address these challenges, wepropose GFSE, a universal graph structural encoder designed to capturetransferable structural patterns across diverse domains such as moleculargraphs, social networks, and citation networks. GFSE is the first cross-domaingraph structural encoder pre-trained with multiple self-supervised learningobjectives. Built on a Graph Transformer, GFSE incorporates attentionmechanisms informed by graph inductive bias, enabling it to encode intricatemulti-level and fine-grained topological features. The pre-trained GFSEproduces generic and theoretically expressive positional and structuralencoding for graphs, which can be seamlessly integrated with various downstreamgraph feature encoders, including graph neural networks for vectorized featuresand Large Language Models for text-attributed graphs. Comprehensive experimentson synthetic and real-world datasets demonstrate GFSE's capability tosignificantly enhance the model's performance while requiring substantiallyless task-specific fine-tuning. Notably, GFSE achieves state-of-the-artperformance in 81.6% evaluated cases, spanning diverse graph models anddatasets, highlighting its potential as a powerful and versatile encoder forgraph-structured data.</description>
      <author>example@mail.com (Jialin Chen, Haolan Zuo, Haoyu Peter Wang, Siqi Miao, Pan Li, Rex Ying)</author>
      <guid isPermaLink="false">2504.10917v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>MatterTune: An Integrated, User-Friendly Platform for Fine-Tuning Atomistic Foundation Models to Accelerate Materials Simulation and Discovery</title>
      <link>http://arxiv.org/abs/2504.10655v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，几何机器学习模型如图神经网络在化学和材料科学研究中的应用，如高通量虚拟筛选和原子模拟，取得了显著成功。然而，这些模型对数据的需求较高，限制了它们在数据稀疏问题中的应用。为了解决这一限制，预训练的机器学习模型的发展正在增加，这些模型在原子数据中学习了通用的基本几何关系，可以针对更小的特定应用数据集进行微调。为了充分利用这些基础模型，本文介绍了MatterTune，这是一个模块化和可扩展的框架，提供了高级微调能力和无缝集成原子基础模型到下游材料信息学和模拟工作流程的能力，从而降低了采用门槛并促进了材料科学中的多样化应用。&lt;h4&gt;背景&lt;/h4&gt;几何机器学习模型如图神经网络在化学和材料科学研究中取得了成功，但需要大量数据，限制了在数据稀疏问题中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了解决数据需求高的问题，提出了一种新的框架MatterTune，以降低采用门槛并促进材料科学中的多样化应用。&lt;h4&gt;方法&lt;/h4&gt;开发了一个模块化和可扩展的框架MatterTune，它支持高级微调能力和无缝集成原子基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;MatterTune支持多种先进的原子基础模型，如ORB、MatterSim、JMP和EquformerV2，并提供模块化设计、分布式和可定制的微调、广泛支持下游信息学任务等功能。&lt;h4&gt;结论&lt;/h4&gt;MatterTune框架的提出，为利用原子基础模型提供了便利，有助于推动材料科学领域的研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;Geometric machine learning models such as graph neural networks have achieved remarkable success in recent years in chemical and materials science research for applications such as high-throughput virtual screening and atomistic simulations. The success of these models can be attributed to their ability to effectively learn latent representations of atomic structures directly from the training data. Conversely, this also results in high data requirements for these models, hindering their application to problems which are data sparse which are common in this domain. To address this limitation, there is a growing development in the area of pre-trained machine learning models which have learned general, fundamental, geometric relationships in atomistic data, and which can then be fine-tuned to much smaller application-specific datasets. In particular, models which are pre-trained on diverse, large-scale atomistic datasets have shown impressive generalizability and flexibility to downstream applications, and are increasingly referred to as atomistic foundation models. To leverage the untapped potential of these foundation models, we introduce MatterTune, a modular and extensible framework that provides advanced fine-tuning capabilities and seamless integration of atomistic foundation models into downstream materials informatics and simulation workflows, thereby lowering the barriers to adoption and facilitating diverse applications in materials science. In its current state, MatterTune supports a number of state-of-the-art foundation models such as ORB, MatterSim, JMP, and EquformerV2, and hosts a wide range of features including a modular and flexible design, distributed and customizable fine-tuning, broad support for downstream informatics tasks, and more.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometric machine learning models such as graph neural networks have achievedremarkable success in recent years in chemical and materials science researchfor applications such as high-throughput virtual screening and atomisticsimulations. The success of these models can be attributed to their ability toeffectively learn latent representations of atomic structures directly from thetraining data. Conversely, this also results in high data requirements forthese models, hindering their application to problems which are data sparsewhich are common in this domain. To address this limitation, there is a growingdevelopment in the area of pre-trained machine learning models which havelearned general, fundamental, geometric relationships in atomistic data, andwhich can then be fine-tuned to much smaller application-specific datasets. Inparticular, models which are pre-trained on diverse, large-scale atomisticdatasets have shown impressive generalizability and flexibility to downstreamapplications, and are increasingly referred to as atomistic foundation models.To leverage the untapped potential of these foundation models, we introduceMatterTune, a modular and extensible framework that provides advancedfine-tuning capabilities and seamless integration of atomistic foundationmodels into downstream materials informatics and simulation workflows, therebylowering the barriers to adoption and facilitating diverse applications inmaterials science. In its current state, MatterTune supports a number ofstate-of-the-art foundation models such as ORB, MatterSim, JMP, andEquformerV2, and hosts a wide range of features including a modular andflexible design, distributed and customizable fine-tuning, broad support fordownstream informatics tasks, and more.</description>
      <author>example@mail.com (Lingyu Kong, Nima Shoghi, Guoxiang Hu, Pan Li, Victor Fung)</author>
      <guid isPermaLink="false">2504.10655v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Intelligent driving vehicle front multi-target tracking and detection based on YOLOv5 and point cloud 3D projection</title>
      <link>http://arxiv.org/abs/2504.11310v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  in Chinese language&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于YOLOv5和点云3D投影的多目标跟踪和检测方法，用于智能驾驶车辆的前方多目标跟踪和检测。&lt;h4&gt;背景&lt;/h4&gt;多目标跟踪和检测任务需要连续跟踪多个目标，如车辆、行人等，并实时更新目标状态。&lt;h4&gt;目的&lt;/h4&gt;实现智能驾驶车辆前方多目标的高精度跟踪和检测。&lt;h4&gt;方法&lt;/h4&gt;使用Retinex算法增强车辆前方环境图像，去除图像中的光干扰，并基于YOLOv5网络结构构建智能检测模型。通过特征提取和目标定位识别车辆前方的多个目标。结合点云3D投影技术，推断相邻帧图像在投影坐标系中的位置变化关系，并将连续帧图像的多目标识别结果投影到3D激光点云环境中，实现所有目标运动轨迹的有效跟踪。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在智能驾驶车辆前方多目标跟踪和检测中的应用，MOTA（跟踪精度）值超过30，显示出其优越的跟踪和检测性能。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提高智能驾驶车辆前方多目标跟踪和检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In multi-target tracking and detection tasks, it is necessary to continuouslytrack multiple targets, such as vehicles, pedestrians, etc. To achieve thisgoal, the system must be able to continuously acquire and process image framescontaining these targets. These consecutive frame images enable the algorithmto update the position and state of the target in real-time in each frame ofthe image. How to accurately associate the detected target with the target inthe previous or next frame to form a stable trajectory is a complex problem.Therefore, a multi object tracking and detection method for intelligent drivingvehicles based on YOLOv5 and point cloud 3D projection is proposed. UsingRetinex algorithm to enhance the image of the environment in front of thevehicle, remove light interference in the image, and build an intelligentdetection model based on YOLOv5 network structure. The enhanced image is inputinto the model, and multiple targets in front of the vehicle are identifiedthrough feature extraction and target localization. By combining point cloud 3Dprojection technology, the correlation between the position changes of adjacentframe images in the projection coordinate system can be inferred. Bysequentially projecting the multi-target recognition results of multipleconsecutive frame images into the 3D laser point cloud environment, effectivetracking of the motion trajectories of all targets in front of the vehicle canbe achieved. The experimental results show that the application of this methodfor intelligent driving vehicle front multi-target tracking and detectionyields a MOTA (Tracking Accuracy) value greater than 30, demonstrating itssuperior tracking and detection performance.</description>
      <author>example@mail.com (Dayong Liu, Qingrui Zhang, Zeyang Meng)</author>
      <guid isPermaLink="false">2504.11310v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Modal Hypergraph Enhanced LLM Learning for Recommendation</title>
      <link>http://arxiv.org/abs/2504.10541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HeLLM的新型框架，用于增强大型语言模型（LLM）在多模态推荐系统中的性能。该框架通过融合图级别上下文信号和序列级别行为模式，使LLM能够捕捉复杂的语义相关性。&lt;h4&gt;背景&lt;/h4&gt;现有基于LLM的方法未能充分探索推荐场景中固有的多视图图结构相关性。&lt;h4&gt;目的&lt;/h4&gt;设计一个框架，使LLM能够捕捉复杂的语义相关性。&lt;h4&gt;方法&lt;/h4&gt;1. 设计用户超图和物品超图，以揭示用户之间的共同兴趣偏好和物品之间的多模态相似性相关性。2. 引入超图卷积和协同对比学习机制，以增强学习表示的可区分性。3. 在LLM微调阶段，将学习到的图结构嵌入直接注入LLM架构，并集成捕获每个用户时间序列行为的序列特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法优于现有最佳基线，证实了在LLM中融合基于超图上下文与序列用户行为的优势。&lt;h4&gt;结论&lt;/h4&gt;HeLLM框架能够有效提升LLM在推荐系统中的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型语言模型（LLM）的日益普及正在推动个性化推荐系统的发展。大多数现有的基于LLM的方法未能充分探索推荐场景中固有的多视图图结构相关性。为此，我们提出了一种新的框架，称为Hypergraph Enhanced LLM Learning for multimodal Recommendation（HeLLM），旨在使LLM具备通过融合图级别上下文信号与序列级别行为模式来捕捉复杂高阶语义相关性的能力。在推荐预训练阶段，我们设计了用户超图以揭示用户之间的共同兴趣偏好，以及物品超图以捕捉物品之间的多模态相似性相关性。引入了超图卷积和协同对比学习机制来增强学习表示的可区分性。在LLM微调阶段，我们将学习到的图结构嵌入直接注入LLM的架构中，并集成捕获每个用户时间序列行为的序列特征。这一过程使超图能够利用图结构信息作为全局上下文，增强LLM感知复杂关系模式和整合多模态信息的能力，同时模拟局部时间动态。广泛的实验表明，我们提出的方法优于现有最佳基线，证实了在LLM中融合基于超图上下文与序列用户行为的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The burgeoning presence of Large Language Models (LLM) is propelling thedevelopment of personalized recommender systems. Most existing LLM-basedmethods fail to sufficiently explore the multi-view graph structurecorrelations inherent in recommendation scenarios. To this end, we propose anovel framework, Hypergraph Enhanced LLM Learning for multimodal Recommendation(HeLLM), designed to equip LLMs with the capability to capture intricatehigher-order semantic correlations by fusing graph-level contextual signalswith sequence-level behavioral patterns. In the recommender pre-training phase,we design a user hypergraph to uncover shared interest preferences among usersand an item hypergraph to capture correlations within multimodal similaritiesamong items. The hypergraph convolution and synergistic contrastive learningmechanism are introduced to enhance the distinguishability of learnedrepresentations. In the LLM fine-tuning phase, we inject the learnedgraph-structured embeddings directly into the LLM's architecture and integratesequential features capturing each user's chronological behavior. This processenables hypergraphs to leverage graph-structured information as global context,enhancing the LLM's ability to perceive complex relational patterns andintegrate multimodal information, while also modeling local temporal dynamics.Extensive experiments demonstrate the superiority of our proposed method overstate-of-the-art baselines, confirming the advantages of fusinghypergraph-based context with sequential user behavior in LLMs forrecommendation.</description>
      <author>example@mail.com (Xu Guo, Tong Zhang, Yuanzhi Wang, Chenxu Wang, Fuyun Wang, Xudong Wang, Xiaoya Zhang, Xin Liu, Zhen Cui)</author>
      <guid isPermaLink="false">2504.10541v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>The Code Barrier: What LLMs Actually Understand?</title>
      <link>http://arxiv.org/abs/2504.10557v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过代码混淆作为结构化测试框架，评估了大型语言模型（LLM）的语义理解能力，并引入了一种新的评估方法来衡量语言模型对代码的理解。&lt;h4&gt;背景&lt;/h4&gt;理解代码是自动化软件开发任务的核心能力。尽管基础模型如LLM在许多软件工程挑战中表现出令人印象深刻的结果，但其真正的语义理解程度，尤其是超出简单标记识别之外的程度，尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;使用代码混淆来评估LLM的语义理解能力，并建立一种新的评估方法，用于衡量语言模型对代码的理解。&lt;h4&gt;方法&lt;/h4&gt;本研究通过系统地应用受控的混淆更改到源代码中，并通过生成混淆代码的准确描述和执行去混淆任务来衡量理解能力。测试包括13个先进模型，涵盖代码专用（如StarCoder2）和通用（如GPT-4o）架构，并在由CodeNet创建的基准测试上评估，该基准测试包含250个Java编程问题和它们的解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;随着混淆复杂性的增加，性能出现统计学上的显著下降，与专注于代码的模型相比，通用模型显示出意外的弹性。虽然一些模型能够识别混淆技术，但它们重建底层程序逻辑的能力仍然受到限制，这表明它们在语义表示机制上存在局限性。&lt;h4&gt;结论&lt;/h4&gt;本研究引入了一种新的评估代码理解的方法，并建立了安全关键代码分析应用（如逆向工程和对抗性代码分析）的实证基准。&lt;h4&gt;翻译&lt;/h4&gt;Understanding code represents a core ability needed for automating software development tasks. While foundation models like LLMs show impressive results across many software engineering challenges, the extent of their true semantic understanding beyond simple token recognition remains unclear. This research uses code obfuscation as a structured testing framework to evaluate LLMs' semantic understanding capabilities. We methodically apply controlled obfuscation changes to source code and measure comprehension through two complementary tasks: generating accurate descriptions of obfuscated code and performing deobfuscation, a skill with important implications for reverse engineering applications. Our testing approach includes 13 cutting-edge models, covering both code-specialized (e.g., StarCoder2) and general-purpose (e.g., GPT-4o) architectures, evaluated on a benchmark created from CodeNet and consisting of filtered 250 Java programming problems and their solutions. Findings show a statistically significant performance decline as obfuscation complexity increases, with unexpected resilience shown by general-purpose models compared to their code-focused counterparts. While some models successfully identify obfuscation techniques, their ability to reconstruct the underlying program logic remains constrained, suggesting limitations in their semantic representation mechanisms. This research introduces a new evaluation approach for assessing code comprehension in language models and establishes empirical baselines for advancing research in security-critical code analysis applications such as reverse engineering and adversarial code analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding code represents a core ability needed for automating softwaredevelopment tasks. While foundation models like LLMs show impressive resultsacross many software engineering challenges, the extent of their true semanticunderstanding beyond simple token recognition remains unclear. This researchuses code obfuscation as a structured testing framework to evaluate LLMs'semantic understanding capabilities. We methodically apply controlledobfuscation changes to source code and measure comprehension through twocomplementary tasks: generating accurate descriptions of obfuscated code andperforming deobfuscation, a skill with important implications for reverseengineering applications.  Our testing approach includes 13 cutting-edge models, covering bothcode-specialized (e.g., StarCoder2) and general-purpose (e.g., GPT-4o)architectures, evaluated on a benchmark created from CodeNet and consisting offiltered 250 Java programming problems and their solutions. Findings show astatistically significant performance decline as obfuscation complexityincreases, with unexpected resilience shown by general-purpose models comparedto their code-focused counterparts. While some models successfully identifyobfuscation techniques, their ability to reconstruct the underlying programlogic remains constrained, suggesting limitations in their semanticrepresentation mechanisms. This research introduces a new evaluation approachfor assessing code comprehension in language models and establishes empiricalbaselines for advancing research in security-critical code analysisapplications such as reverse engineering and adversarial code analysis.</description>
      <author>example@mail.com (Serge Lionel Nikiema, Jordan Samhi, Abdoul Kader Kaboré, Jacques Klein, Tegawendé F. Bissyandé)</author>
      <guid isPermaLink="false">2504.10557v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>F$^3$Set: Towards Analyzing Fast, Frequent, and Fine-grained Events from Videos</title>
      <link>http://arxiv.org/abs/2504.08222v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025; Website URL: https://lzyandy.github.io/f3set-website/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了F$^3$Set，一个用于精确F$^3$事件检测的视频数据集基准，旨在解决视频分析和多模态LLMs中快速、频繁和精细粒度事件分析的挑战。&lt;h4&gt;背景&lt;/h4&gt;当前方法在识别满足F$^3$标准的快速、频繁和精细粒度事件时存在困难，主要因为运动模糊和细微的视觉差异等问题。&lt;h4&gt;目的&lt;/h4&gt;为了推进视频理解的研究，提出了F$^3$Set基准，以解决F$^3$事件检测的挑战。&lt;h4&gt;方法&lt;/h4&gt;F$^3$Set包含大量数据集，具有广泛规模和详细程度，通常包含超过1,000种事件类型，并支持多级粒度。论文评估了流行的时序动作理解方法在F$^3$Set上的表现，并提出了一个新的F$^3$事件检测方法F$^3$ED。&lt;h4&gt;主要发现&lt;/h4&gt;F$^3$Set揭示了现有技术存在的挑战，并提出的新方法F$^3$ED在F$^3$事件检测方面取得了优异的性能。&lt;h4&gt;结论&lt;/h4&gt;F$^3$Set和F$^3$ED方法为视频分析和多模态LLMs中的F$^3$事件检测提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Analyzing Fast, Frequent, and Fine-grained (F$^3$) events presents a significant challenge in video analytics and multi-modal LLMs. Current methods struggle to identify events that satisfy all the F$^3$ criteria with high accuracy due to challenges such as motion blur and subtle visual discrepancies. To advance research in video understanding, we introduce F$^3$Set, a benchmark that consists of video datasets for precise F$^3$ event detection. Datasets in F$^3$Set are characterized by their extensive scale and comprehensive detail, usually encompassing over 1,000 event types with precise timestamps and supporting multi-level granularity. Currently, F$^3$Set contains several sports datasets, and this framework may be extended to other applications as well. We evaluated popular temporal action understanding methods on F$^3$Set, revealing substantial challenges for existing techniques. Additionally, we propose a new method, F$^3$ED, for F$^3$ event detections, achieving superior performance. The dataset, model, and benchmark code are available at https://github.com/F3Set/F3Set.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/f3set/f3set&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Analyzing Fast, Frequent, and Fine-grained (F$^3$) events presents asignificant challenge in video analytics and multi-modal LLMs. Current methodsstruggle to identify events that satisfy all the F$^3$ criteria with highaccuracy due to challenges such as motion blur and subtle visual discrepancies.To advance research in video understanding, we introduce F$^3$Set, a benchmarkthat consists of video datasets for precise F$^3$ event detection. Datasets inF$^3$Set are characterized by their extensive scale and comprehensive detail,usually encompassing over 1,000 event types with precise timestamps andsupporting multi-level granularity. Currently, F$^3$Set contains several sportsdatasets, and this framework may be extended to other applications as well. Weevaluated popular temporal action understanding methods on F$^3$Set, revealingsubstantial challenges for existing techniques. Additionally, we propose a newmethod, F$^3$ED, for F$^3$ event detections, achieving superior performance.The dataset, model, and benchmark code are available athttps://github.com/F3Set/F3Set.</description>
      <author>example@mail.com (Zhaoyu Liu, Kan Jiang, Murong Ma, Zhe Hou, Yun Lin, Jin Song Dong)</author>
      <guid isPermaLink="false">2504.08222v2</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>FairACE: Achieving Degree Fairness in Graph Neural Networks via Contrastive and Adversarial Group-Balanced Training</title>
      <link>http://arxiv.org/abs/2504.09210v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个名为FairACE的新型图神经网络框架，旨在解决图神经网络中的公平性问题。&lt;h4&gt;背景&lt;/h4&gt;在图神经网络中，节点度的不平衡可能导致不同度数节点预测性能的不公平。&lt;h4&gt;目的&lt;/h4&gt;提出FairACE框架，通过整合非对称对比学习和对抗训练来改善节点度的不公平问题。&lt;h4&gt;方法&lt;/h4&gt;FairACE利用一跳局部邻域信息和两跳的单向相似性来创建更公平的节点表示，并采用度数公平性调节器来平衡高度数和低度数节点的性能。同时，引入了一种新颖的组平衡公平损失函数来最小化不同度数组之间的分类差异。此外，还提出了一个公平性指标——准确度分布差距（ADG），用于定量评估并确保不同度数节点组的性能均衡。&lt;h4&gt;主要发现&lt;/h4&gt;在合成数据和真实世界数据集上的实验结果表明，FairACE在显著提高度数公平性指标的同时，与最先进的图神经网络模型相比保持了竞争力。&lt;h4&gt;结论&lt;/h4&gt;FairACE是一个有效的图神经网络框架，能够提高不同度数节点之间的预测公平性，同时在准确性上保持竞争力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：公平性一直是图神经网络（GNNs）中的一个重大挑战，因为度数偏差往往会导致具有不同度数的节点预测性能不平等。现有的GNN模型侧重于预测准确性，往往忽视了不同度数组之间的公平性。为了解决这一问题，我们提出了一种名为公平感知非对称对比集成（FairACE）的新型GNN框架，该框架整合了非对称对比学习与对抗训练以改善度数公平性。FairACE捕捉了一跳局部邻域信息和两跳的单向相似性，以创建更公平的节点表示，并采用度数公平性调节器来平衡高度数和低度数节点的性能。在模型训练过程中，提出了一种新的组平衡公平损失，以最小化度数组之间的分类差异。此外，我们还提出了一种新的公平性指标——准确度分布差距（ADG），可以定量评估并确保基于不同度数的节点组的公平性能。在合成数据和真实世界数据集上的实验结果表明，与最先进的GNN模型相比，FairACE显著提高了度数公平性指标，同时在准确性上保持了竞争力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fairness has been a significant challenge in graph neural networks (GNNs)since degree biases often result in un-equal prediction performance among nodeswith varying degrees. Existing GNN models focus on prediction accuracy,frequently overlooking fairness across different degree groups. To addressthisissue, we propose a novel GNN framework, namely Fairness- Aware AsymmetricContrastive Ensemble (FairACE), which inte-grates asymmetric contrastivelearning with adversarial training to improve degree fairness. FairACE capturesone-hop local neighborhood information and two-hop monophily similarity tocreate fairer node representations and employs a degree fairness regulator tobalance performance between high-degree and low-degree nodes. During modeltraining, a novel group-balanced fairness loss is proposed to minimizeclassification disparities across degree groups. In addition, we also propose anovel fairness metric, the Accuracy Distribution Gap (ADG), which canquantitatively assess and ensure equitable performance across differentdegree-based node groups. Experimental results on both synthetic and real-worlddatasets demonstrate that FairACE significantly improves degree fairnessmetrics while maintaining competitive accuracy in comparison to thestate-of-the-art GNN models.</description>
      <author>example@mail.com (Jiaxin Liu, Xiaoqian Jiang, Xiang Li, Bohan Zhang, Jing Zhang)</author>
      <guid isPermaLink="false">2504.09210v2</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>DrivAer Transformer: A high-precision and fast prediction method for vehicle aerodynamic drag coefficient based on the DrivAerNet++ dataset</title>
      <link>http://arxiv.org/abs/2504.08217v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DrivAer Transformer (DAT)的点云学习框架，用于评估车辆空气动力学性能，旨在提高预测准确性和通用性，以推动汽车设计的进步。&lt;h4&gt;背景&lt;/h4&gt;深度学习方法在评估空气动力学性能方面表现出色，但处理复杂的三维车辆模型时，由于数据集和训练资源的缺乏，以及不同车辆模型几何形状的多样性和复杂性，预测准确性和通用性尚未达到生产要求。&lt;h4&gt;目的&lt;/h4&gt;提出DAT框架，利用Transformer模型在自然语言处理和图像处理领域的成功经验，提高点云数据处理能力，实现快速准确的空气阻力预测。&lt;h4&gt;方法&lt;/h4&gt;DAT框架使用DrivAerNet++数据集，包含工业标准三维车辆形状的高保真CFD数据，直接从三维网格中估计空气阻力，避免传统方法的限制。&lt;h4&gt;主要发现&lt;/h4&gt;DAT框架能够实现快速准确的空气阻力预测，推动空气动力学评估过程的进化，为汽车设计引入数据驱动方法奠定基础。&lt;h4&gt;结论&lt;/h4&gt;DAT框架预计将加速车辆设计过程，提高开发效率。&lt;h4&gt;翻译&lt;/h4&gt;在当前阶段，基于深度学习的方法在评估空气动力学性能方面表现出卓越的能力，显著减少了传统计算流体动力学（CFD）模拟所需的时间和成本。然而，面对处理极其复杂的三维（3D）车辆模型的任务时，由于缺乏大规模数据集和训练资源，以及不同车辆模型几何形状的固有多样性和复杂性，这些网络的预测准确性和通用性仍然没有达到当前生产所需的水平。鉴于Transformer模型在自然语言处理领域的显著成功及其在图像处理领域的强大潜力，本研究创新性地提出了一种名为DrivAer Transformer（DAT）的点云学习框架。DAT结构使用DrivAerNet++数据集，该数据集包含工业标准3D车辆形状的高保真CFD数据，能够直接从3D网格中准确估计空气阻力，从而避免了传统方法（如2D图像渲染或符号距离场（SDF））的限制。DAT能够实现快速准确的阻力预测，推动空气动力学评估过程的进化，为引入数据驱动方法到汽车设计奠定关键基础。该框架预计将加速车辆设计过程，提高开发效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; At the current stage, deep learning-based methods have demonstrated excellentcapabilities in evaluating aerodynamic performance, significantly reducing thetime and cost required for traditional computational fluid dynamics (CFD)simulations. However, when faced with the task of processing extremely complexthree-dimensional (3D) vehicle models, the lack of large-scale datasets andtraining resources, coupled with the inherent diversity and complexity of thegeometry of different vehicle models, means that the prediction accuracy andversatility of these networks are still not up to the level required forcurrent production. In view of the remarkable success of Transformer models inthe field of natural language processing and their strong potential in thefield of image processing, this study innovatively proposes a point cloudlearning framework called DrivAer Transformer (DAT). The DAT structure uses theDrivAerNet++ dataset, which contains high-fidelity CFD data ofindustrial-standard 3D vehicle shapes. enabling accurate estimation of air dragdirectly from 3D meshes, thus avoiding the limitations of traditional methodssuch as 2D image rendering or signed distance fields (SDF). DAT enables fastand accurate drag prediction, driving the evolution of the aerodynamicevaluation process and laying the critical foundation for introducing adata-driven approach to automotive design. The framework is expected toaccelerate the vehicle design process and improve development efficiency.</description>
      <author>example@mail.com (Jiaqi He, Xiangwen Luo, Yiping Wang)</author>
      <guid isPermaLink="false">2504.08217v2</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>JEPA4Rec: Learning Effective Language Representations for Sequential Recommendation via Joint Embedding Predictive Architecture</title>
      <link>http://arxiv.org/abs/2504.10512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;JEPA4Rec是一个结合了联合嵌入预测架构和物品文本描述语言建模的推荐框架，能够捕捉语义丰富且可迁移的表示，从而提高推荐性能并减少对大规模预训练数据的依赖。&lt;h4&gt;背景&lt;/h4&gt;语言表示学习在序列推荐中表现出潜力，但仍然面临数据稀疏性和对常识用户偏好理解有限的问题。&lt;h4&gt;目的&lt;/h4&gt;提出JEPA4Rec框架以解决语言表示学习在推荐任务中的局限性。&lt;h4&gt;方法&lt;/h4&gt;JEPA4Rec通过将项目表示为文本句子，并使用双向Transformer编码器及其修改后的嵌入层来编码这些句子。同时，采用掩码技术预测未掩码句子的表示，以及采用两阶段训练策略结合自监督学习损失来提高推荐性能和语言理解。&lt;h4&gt;主要发现&lt;/h4&gt;在六个真实世界数据集上的实验表明，JEPA4Rec在跨领域、跨平台和低资源场景中持续优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;JEPA4Rec框架能够有效提升推荐系统的性能，特别是在面对数据稀疏性和跨域推荐任务时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language representation learning has emerged as a promising approach forsequential recommendation, thanks to its ability to learn generalizablerepresentations. However, despite its advantages, this approach still struggleswith data sparsity and a limited understanding of common-sense userpreferences. To address these limitations, we propose $\textbf{JEPA4Rec}$, aframework that combines $\textbf{J}$oint $\textbf{E}$mbedding$\textbf{P}$redictive $\textbf{A}$rchitecture with language modeling of itemtextual descriptions. JEPA4Rec captures semantically rich and transferablerepresentations, improving recommendation performance and reducing reliance onlarge-scale pre-training data. Specifically, JEPA4Rec represents items as textsentences by flattening descriptive information such as $\textit{title,category}$, and other attributes. To encode these sentences, we employ abidirectional Transformer encoder with modified embedding layers tailored forcapturing item information in recommendation datasets. We apply masking to textsentences and use them to predict the representations of the unmaskedsentences, helping the model learn generalizable item embeddings. To furtherimprove recommendation performance and language understanding, we employ atwo-stage training strategy incorporating self-supervised learning losses.Experiments on six real-world datasets demonstrate that JEPA4Rec consistentlyoutperforms state-of-the-art methods, particularly in cross-domain,cross-platform, and low-resource scenarios.</description>
      <author>example@mail.com (Minh-Anh Nguyen, Dung D. Le)</author>
      <guid isPermaLink="false">2504.10512v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>GeoUni: A Unified Model for Generating Geometry Diagrams, Problems and Problem Solutions</title>
      <link>http://arxiv.org/abs/2504.10146v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GeoUni是一种统一的几何专家模型，能够在单个框架内生成问题解决方案和图表，创建独特和个性化的几何问题。&lt;h4&gt;背景&lt;/h4&gt;传统的机器学习处理几何问题的解决和图表生成是两个独立的任务，没有模型能够成功整合这两个功能以支持问题创建。&lt;h4&gt;目的&lt;/h4&gt;GeoUni旨在通过无缝集成解决几何问题的所有技能（从解决问题到可视化几何关系，再到定制问题）来掌握几何。&lt;h4&gt;方法&lt;/h4&gt;GeoUni使用了1.5B参数，在几何推理任务中达到了与DeepSeek-R1（671B参数）相当的性能，并且能够生成精确的几何图表，超越了文本到图像模型和统一模型，包括GPT-4o图像生成。&lt;h4&gt;主要发现&lt;/h4&gt;GeoUni是唯一能够基于特定知识点成功生成匹配图表的文本问题的模型，从而提供超越现有模型的更广泛的能力。&lt;h4&gt;结论&lt;/h4&gt;GeoUni通过整合几何问题的解决和图表生成，在几何推理和图表生成方面表现出色，并且具有创建个性化几何问题的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose GeoUni, the first unified geometry expert model capable ofgenerating problem solutions and diagrams within a single framework in a waythat enables the creation of unique and individualized geometry problems.Traditionally, solving geometry problems and generating diagrams have beentreated as separate tasks in machine learning, with no models successfullyintegrating both to support problem creation. However, we believe that masteryin geometry requires frictionless integration of all of these skills, fromsolving problems to visualizing geometric relationships, and finally, craftingtailored problems. Our extensive experiments demonstrate that GeoUni, with only1.5B parameters, achieves performance comparable to larger models such asDeepSeek-R1 with 671B parameters in geometric reasoning tasks. GeoUni alsoexcels in generating precise geometric diagrams, surpassing both text-to-imagemodels and unified models, including the GPT-4o image generation. Mostimportantly, GeoUni is the only model capable of successfully generatingtextual problems with matching diagrams based on specific knowledge points,thus offering a wider range of capabilities that extend beyond current models.</description>
      <author>example@mail.com (Jo-Ku Cheng, Zeren Zhang, Ran Chen, Jingyang Deng, Ziran Qin, Jinwen Ma)</author>
      <guid isPermaLink="false">2504.10146v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
  <item>
      <title>Foundation models for electronic health records: representation dynamics and transferability</title>
      <link>http://arxiv.org/abs/2504.10422v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于电子健康记录的基金会模型在临床预测任务中的性能，并评估了模型在不同医疗体系中的适应性和可移植性。&lt;h4&gt;背景&lt;/h4&gt;虽然基于电子健康记录的基金会模型在临床预测任务中表现出色，但将其适应到本地医疗体系中由于数据可用性和资源限制而存在挑战。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在调查这些模型学到了什么，评估在MIMIC-IV上训练的基金会模型转移到芝加哥大学医学中心机构电子健康记录数据集的可移植性。&lt;h4&gt;方法&lt;/h4&gt;研究了模型识别异常患者的能力，并考察了与未来临床结果相关的表示空间中患者轨迹。此外，还在源数据和目标数据集上评估了监督微调分类器的性能。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果提供了关于基金会模型在不同医疗体系间适应性的见解，强调了有效实施时的考虑因素，并对有助于其预测性能的潜在因素进行了实证分析。&lt;h4&gt;结论&lt;/h4&gt;本研究对基金会模型在不同医疗体系中的适应性进行了实证研究，为模型的有效实施提供了指导，并对模型预测性能背后的因素进行了深入分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) trained on electronic health records (EHRs) haveshown strong performance on a range of clinical prediction tasks. However,adapting these models to local health systems remains challenging due tolimited data availability and resource constraints. In this study, weinvestigated what these models learn and evaluated the transferability of an FMtrained on MIMIC-IV to an institutional EHR dataset at the University ofChicago Medical Center. We assessed their ability to identify outlier patientsand examined representation-space patient trajectories in relation to futureclinical outcomes. We also evaluated the performance of supervised fine-tunedclassifiers on both source and target datasets. Our findings offer insightsinto the adaptability of FMs across different healthcare systems, highlightconsiderations for their effective implementation, and provide an empiricalanalysis of the underlying factors that contribute to their predictiveperformance.</description>
      <author>example@mail.com (Michael C. Burkhart, Bashar Ramadan, Zewei Liao, Kaveri Chhikara, Juan C. Rojas, William F. Parker, Brett K. Beaulieu-Jones)</author>
      <guid isPermaLink="false">2504.10422v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Combining Forecasts using Meta-Learning: A Comparative Study for Complex Seasonality</title>
      <link>http://arxiv.org/abs/2504.08940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE 10th International Conference on Data Science and Advanced  Analytics, DSAA'23, pp. 1-10, 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过元学习结合不同类型模型生成的预测，以提高预测准确性。&lt;h4&gt;背景&lt;/h4&gt;传统的预测结合方法通常涉及简单的平均，而机器学习技术通过元学习实现了更复杂的结合方法。&lt;h4&gt;目的&lt;/h4&gt;通过元学习提高预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用线性回归、k近邻、多层感知器、随机森林和长短期记忆作为元学习器。定义了针对具有复杂季节性的时间序列的全球和局部元学习变体，并在多个预测问题上对元学习器进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;元学习器在多个预测问题上的表现优于简单的平均方法。&lt;h4&gt;结论&lt;/h4&gt;元学习在结合不同类型模型生成的预测中具有优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we investigate meta-learning for combining forecasts generated by models of different types. While typical approaches for combining forecasts involve simple averaging, machine learning techniques enable more sophisticated methods of combining through meta-learning, leading to improved forecasting accuracy. We use linear regression, $k$-nearest neighbors, multilayer perceptron, random forest, and long short-term memory as meta-learners. We define global and local meta-learning variants for time series with complex seasonality and compare meta-learners on multiple forecasting problems, demonstrating their superior performance compared to simple averaging.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/DSAA60987.2023.10302585&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we investigate meta-learning for combining forecasts generatedby models of different types. While typical approaches for combining forecastsinvolve simple averaging, machine learning techniques enable more sophisticatedmethods of combining through meta-learning, leading to improved forecastingaccuracy. We use linear regression, $k$-nearest neighbors, multilayerperceptron, random forest, and long short-term memory as meta-learners. Wedefine global and local meta-learning variants for time series with complexseasonality and compare meta-learners on multiple forecasting problems,demonstrating their superior performance compared to simple averaging.</description>
      <author>example@mail.com (Grzegorz Dudek)</author>
      <guid isPermaLink="false">2504.08940v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Long Video Modeling Based on Temporal Dynamic Context</title>
      <link>http://arxiv.org/abs/2504.10443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Temporal Dynamic Context (TDC)的动态长视频编码方法，以解决现有长视频理解模型在处理长视频时信息丢失和模态融合问题。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型（LLMs）在视频理解方面取得了显著进展，但现有的模型仍然难以处理长视频，因为LLMs的上下文长度限制和视频中的大量信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理长视频的编码方法，减少信息丢失，并融合视频和音频等多模态信息。&lt;h4&gt;方法&lt;/h4&gt;1. 将视频分割成语义上一致的场景；2. 使用视觉-音频编码器将每帧编码成标记；3. 提出一种新颖的时间上下文压缩器，以减少每个段落的标记数量；4. 使用基于查询的Transformer聚合视频、音频和指令文本标记；5. 将静态帧标记和时间上下文标记输入LLM进行视频理解；6. 提出一种无训练的思考链策略，用于处理极长视频。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在通用视频理解和音视频理解基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;Temporal Dynamic Context (TDC)方法能够有效处理长视频，并在视频理解任务中取得良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;最近，大型语言模型（LLMs）在视频理解方面的进步导致了显著的突破。然而，由于LLMs的上下文长度限制和视频中的大量信息，现有的模型在处理长视频时仍然存在困难。尽管一些最近的方法是为长视频理解设计的，但它们在标记压缩过程中通常会丢失关键信息，并且难以处理音频等附加模态。在本工作中，我们提出了一种利用帧之间时间关系的动态长视频编码方法，称为Temporal Dynamic Context（TDC）。首先，我们根据帧间的相似性将视频分割成语义上一致的场景，然后使用视觉-音频编码器将每个帧编码成标记。其次，我们提出了一种新颖的时间上下文压缩器，以减少每个段落的标记数量。具体来说，我们采用基于查询的Transformer将视频、音频和指令文本标记聚合到一组有限的时间上下文标记中。最后，我们将静态帧标记和时间上下文标记输入LLM进行视频理解。此外，为了处理极长视频，我们提出了一种无需训练的思考链策略，该策略逐步从多个视频段中提取答案。这些中间答案作为推理过程的一部分，有助于最终答案。我们在通用视频理解和音视频理解基准测试上进行了广泛的实验，我们的方法在这些实验中表现出了强大的性能。代码和模型可在https://github.com/Hoar012/TDC-Video上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Large Language Models (LLMs) have led to significantbreakthroughs in video understanding. However, existing models still strugglewith long video processing due to the context length constraint of LLMs and thevast amount of information within the video. Although some recent methods aredesigned for long video understanding, they often lose crucial informationduring token compression and struggle with additional modality like audio. Inthis work, we propose a dynamic long video encoding method utilizing thetemporal relationship between frames, named Temporal Dynamic Context (TDC).Firstly, we segment the video into semantically consistent scenes based oninter-frame similarities, then encode each frame into tokens using visual-audioencoders. Secondly, we propose a novel temporal context compressor to reducethe number of tokens within each segment. Specifically, we employ a query-basedTransformer to aggregate video, audio, and instruction text tokens into alimited set of temporal context tokens. Finally, we feed the static frametokens and the temporal context tokens into the LLM for video understanding.Furthermore, to handle extremely long videos, we propose a training-freechain-of-thought strategy that progressively extracts answers from multiplevideo segments. These intermediate answers serve as part of the reasoningprocess and contribute to the final answer. We conduct extensive experiments ongeneral video understanding and audio-video understanding benchmarks, where ourmethod demonstrates strong performance. The code and models are available athttps://github.com/Hoar012/TDC-Video.</description>
      <author>example@mail.com (Haoran Hao, Jiaming Han, Yiyuan Zhang, Xiangyu Yue)</author>
      <guid isPermaLink="false">2504.10443v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>LMFormer: Lane based Motion Prediction Transformer</title>
      <link>http://arxiv.org/abs/2504.10275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted: Autonomous Driving Workshop, CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LMFormer的路径预测网络，用于自动驾驶中的运动预测。&lt;h4&gt;背景&lt;/h4&gt;运动预测在自动驾驶中扮演着重要角色。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提供一种简单机制动态优先级排序车道，并引入网络学习行为的可解释性。&lt;h4&gt;方法&lt;/h4&gt;LMFormer使用车道连接信息学习车道结构中的长距离依赖，并提出了一种通过堆叠变换器层进行迭代精炼预测轨迹的有效方法。&lt;h4&gt;主要发现&lt;/h4&gt;LMFormer在多个指标上实现了SOTA性能，并展示了跨数据集网络性能以及LMFormer在多个数据集上训练并取得更好性能的统一能力。&lt;h4&gt;结论&lt;/h4&gt;LMFormer是一种有效的路径预测网络，在自动驾驶中具有广泛应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要：运动预测在自动驾驶中起着重要作用。本研究提出了LMFormer，一种用于轨迹预测任务的车道感知变换器网络。与先前的研究相比，我们的工作提供了一个简单的机制来动态优先级排序车道，并表明这种机制引入了网络学习行为的可解释性。此外，LMFormer使用交叉口、车道合并和车道分叉的车道连接信息，以学习车道结构中的长距离依赖。此外，我们还解决了预测轨迹的细化问题，并提出了一种通过堆叠变换器层进行迭代精炼的有效方法。为了基准测试，我们在nuScenes数据集上评估了LMFormer，并证明它在多个指标上实现了SOTA性能。此外，还使用了Deep Scenario数据集，不仅说明了跨数据集网络性能，还说明了LMFormer在多个数据集上训练并取得更好性能的统一能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion prediction plays an important role in autonomous driving. This studypresents LMFormer, a lane-aware transformer network for trajectory predictiontasks. In contrast to previous studies, our work provides a simple mechanism todynamically prioritize the lanes and shows that such a mechanism introducesexplainability into the learning behavior of the network. Additionally,LMFormer uses the lane connection information at intersections, lane merges,and lane splits, in order to learn long-range dependency in lane structure.Moreover, we also address the issue of refining the predicted trajectories andpropose an efficient method for iterative refinement through stackedtransformer layers. For benchmarking, we evaluate LMFormer on the nuScenesdataset and demonstrate that it achieves SOTA performance across multiplemetrics. Furthermore, the Deep Scenario dataset is used to not only illustratecross-dataset network performance but also the unification capabilities ofLMFormer to train on multiple datasets and achieve better performance.</description>
      <author>example@mail.com (Harsh Yadav, Maximilian Schaefer, Kun Zhao, Tobias Meisen)</author>
      <guid isPermaLink="false">2504.10275v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis</title>
      <link>http://arxiv.org/abs/2504.10352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ACM MM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的伪自回归（PAR）编解码器语言建模方法，该方法统一了自回归（AR）和非自回归（NAR）建模。通过结合AR模型的显式时间建模和NAR模型的并行生成，PAR能够在固定时间步长生成动态长度的跨度。基于PAR，提出了PALLE，一个两阶段TTS系统，利用PAR进行初始生成，随后进行NAR细化。&lt;h4&gt;背景&lt;/h4&gt;现有的零样本文本到语音（TTS）系统面临共同困境：自回归模型在生成速度上较慢且缺乏时长控制能力，而非自回归模型缺乏时间建模且通常需要复杂的设计。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的TTS系统，解决现有零样本TTS系统中自回归模型和非自回归模型的问题。&lt;h4&gt;方法&lt;/h4&gt;采用PAR codec语言建模方法，结合AR模型的显式时间建模和NAR模型的并行生成。PALLE系统包括两个阶段：第一阶段使用PAR逐步生成语音标记，每步并行预测所有位置但只保留最左侧跨度；第二阶段迭代地并行细化低置信度标记，利用全局上下文信息。&lt;h4&gt;主要发现&lt;/h4&gt;在LibriTTS上训练的PALLE系统在LibriSpeech test-clean数据集上，在语音质量、说话人相似度和可懂度方面优于使用大规模数据训练的F5-TTS、E2-TTS和MaskGCT等最先进系统，同时推理速度可达十倍。&lt;h4&gt;结论&lt;/h4&gt;PALLE系统在保持高语音质量的同时，实现了快速推理，为TTS系统提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel pseudo-autoregressive (PAR) codec language modeling approach that unifies autoregressive (AR) and non-autoregressive (NAR) modeling. By combining explicit temporal modeling from AR with parallel generation from NAR, PAR generates dynamic-length spans at fixed time steps. Based on PAR, we propose PALLE, a two-stage TTS system that leverages PAR for initial generation followed by NAR refinement. In the first stage, PAR progressively generates speech tokens along the time dimension, with each step predicting all positions in parallel but only retaining the left-most span. In the second stage, low-confidence tokens are iteratively refined in parallel, leveraging the global contextual information. Experiments demonstrate that PALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on large-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech test-clean set in terms of speech quality, speaker similarity, and intelligibility, while achieving up to ten times faster inference speed. Audio samples are available at https://anonymous-palle.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent zero-shot text-to-speech (TTS) systems face a common dilemma:autoregressive (AR) models suffer from slow generation and lack durationcontrollability, while non-autoregressive (NAR) models lack temporal modelingand typically require complex designs. In this paper, we introduce a novelpseudo-autoregressive (PAR) codec language modeling approach that unifies ARand NAR modeling. Combining explicit temporal modeling from AR with parallelgeneration from NAR, PAR generates dynamic-length spans at fixed time steps.Building on PAR, we propose PALLE, a two-stage TTS system that leverages PARfor initial generation followed by NAR refinement. In the first stage, PARprogressively generates speech tokens along the time dimension, with each steppredicting all positions in parallel but only retaining the left-most span. Inthe second stage, low-confidence tokens are iteratively refined in parallel,leveraging the global contextual information. Experiments demonstrate thatPALLE, trained on LibriTTS, outperforms state-of-the-art systems trained onlarge-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeechtest-clean set in terms of speech quality, speaker similarity, andintelligibility, while achieving up to ten times faster inference speed. Audiosamples are available at https://anonymous-palle.github.io.</description>
      <author>example@mail.com (Yifan Yang, Shujie Liu, Jinyu Li, Yuxuan Hu, Haibin Wu, Hui Wang, Jianwei Yu, Lingwei Meng, Haiyang Sun, Yanqing Liu, Yan Lu, Kai Yu, Xie Chen)</author>
      <guid isPermaLink="false">2504.10352v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation via Diffusion Model</title>
      <link>http://arxiv.org/abs/2504.10433v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MonoDiff9D是一种基于扩散的9D单目对象姿态估计方法，无需形状先验或CAD模型即可实现高精度的对象姿态估计。&lt;h4&gt;背景&lt;/h4&gt;对象姿态估计对于机器人理解和交互环境至关重要，单目方法因其只需要单个RGB相机而受到青睐。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需形状先验、CAD模型或深度传感器的单目9D对象姿态估计方法。&lt;h4&gt;方法&lt;/h4&gt;首先使用DINOv2在零样本方式下估计粗略深度并将其转换为点云；然后融合点云的全局特征和输入图像；最后，使用融合的特征和时间步长来条件化MonoDiff9D，并通过基于transformer的降噪器从高斯噪声中恢复对象姿态。&lt;h4&gt;主要发现&lt;/h4&gt;在两个流行的基准数据集上，MonoDiff9D实现了在没有形状先验或CAD模型的情况下最先进的单目9D对象姿态估计精度。&lt;h4&gt;结论&lt;/h4&gt;MonoDiff9D代码将公开在https://github.com/CNJianLiu/MonoDiff9D上。&lt;h4&gt;翻译&lt;/h4&gt;对象姿态估计是机器人理解和交互环境的核心手段。对于这一任务，单目分类级方法因其仅需单个RGB相机而具有吸引力。然而，当前方法依赖于形状先验或已知对象内类的CAD模型。我们提出了一种基于扩散的单目分类级9D对象姿态生成方法，称为MonoDiff9D。我们的动机是利用扩散模型的概率性质来减轻对形状先验、CAD模型或深度传感器对内类未知对象姿态估计的需求。我们首先以零样本方式从单目图像中估计粗略深度，并将其转换为点云。然后，我们将点云的全局特征与输入图像融合，并使用融合的特征以及编码的时间步长来条件化MonoDiff9D。最后，我们设计了一种基于transformer的降噪器，以从高斯噪声中恢复对象姿态。在两个流行基准数据集上的大量实验表明，MonoDiff9D在不需要任何阶段的形状先验或CAD模型的情况下实现了最先进的单目分类级9D对象姿态估计精度。我们的代码将公开在https://github.com/CNJianLiu/MonoDiff9D上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object pose estimation is a core means for robots to understand and interactwith their environment. For this task, monocular category-level methods areattractive as they require only a single RGB camera. However, current methodsrely on shape priors or CAD models of the intra-class known objects. We proposea diffusion-based monocular category-level 9D object pose generation method,MonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusionmodels to alleviate the need for shape priors, CAD models, or depth sensors forintra-class unknown object pose estimation. We first estimate coarse depth viaDINOv2 from the monocular image in a zero-shot manner and convert it into apoint cloud. We then fuse the global features of the point cloud with the inputimage and use the fused features along with the encoded time step to conditionMonoDiff9D. Finally, we design a transformer-based denoiser to recover theobject pose from Gaussian noise. Extensive experiments on two popular benchmarkdatasets show that MonoDiff9D achieves state-of-the-art monocularcategory-level 9D object pose estimation accuracy without the need for shapepriors or CAD models at any stage. Our code will be made public athttps://github.com/CNJianLiu/MonoDiff9D.</description>
      <author>example@mail.com (Jian Liu, Wei Sun, Hui Yang, Jin Zheng, Zichen Geng, Hossein Rahmani, Ajmal Mian)</author>
      <guid isPermaLink="false">2504.10433v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2504.10106v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SoccerNet-v3D和ISSIA-3D两个用于足球转播分析中3D场景理解的数据集，并提出了单目3D球定位方法，以及用于评估标注质量的指标和优化技术。&lt;h4&gt;背景&lt;/h4&gt;体育视频分析是计算机视觉的关键领域，通过多视图对应关系实现详细的空间理解。&lt;h4&gt;目的&lt;/h4&gt;建立新的基准，增强体育分析中的空间和时间分析。&lt;h4&gt;方法&lt;/h4&gt;提出了基于三角测量的单目3D球定位任务，并引入了基于场线摄像校准和多视图同步的扩展数据集，以及用于评估标注质量的校准和重投影指标。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入场线摄像校准和多视图同步，实现了3D物体定位；提出了单目3D球定位方法作为基线；引入了边界框优化技术以细化2D标注。&lt;h4&gt;结论&lt;/h4&gt;提出的SoccerNet-v3D和ISSIA-3D数据集为3D足球场景理解提供了新的基准，提高了体育分析中的空间和时间分析能力。&lt;h4&gt;翻译&lt;/h4&gt;Sports video analysis is a key domain in computer vision, enabling detailed spatial understanding through multi-view correspondences. In this work, we introduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasets designed for 3D scene understanding in soccer broadcast analysis. These datasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based camera calibration and multi-view synchronization, enabling 3D object localization through triangulation. We propose a monocular 3D ball localization task built upon the triangulation of ground-truth 2D ball annotations, along with several calibration and reprojection metrics to assess annotation quality on demand. Additionally, we present a single-image 3D ball localization method as a baseline, leveraging camera calibration and ball size priors to estimate the ball's position from a monocular viewpoint. To further refine 2D annotations, we introduce a bounding box optimization technique that ensures alignment with the 3D scene representation. Our proposed datasets establish new benchmarks for 3D soccer scene understanding, enhancing both spatial and temporal analysis in sports analytics. Finally, we provide code to facilitate access to our annotations and the generation pipelines for the datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sports video analysis is a key domain in computer vision, enabling detailedspatial understanding through multi-view correspondences. In this work, weintroduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasetsdesigned for 3D scene understanding in soccer broadcast analysis. Thesedatasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based cameracalibration and multi-view synchronization, enabling 3D object localizationthrough triangulation. We propose a monocular 3D ball localization task builtupon the triangulation of ground-truth 2D ball annotations, along with severalcalibration and reprojection metrics to assess annotation quality on demand.Additionally, we present a single-image 3D ball localization method as abaseline, leveraging camera calibration and ball size priors to estimate theball's position from a monocular viewpoint. To further refine 2D annotations,we introduce a bounding box optimization technique that ensures alignment withthe 3D scene representation. Our proposed datasets establish new benchmarks for3D soccer scene understanding, enhancing both spatial and temporal analysis insports analytics. Finally, we provide code to facilitate access to ourannotations and the generation pipelines for the datasets.</description>
      <author>example@mail.com (Marc Gutiérrez-Pérez, Antonio Agudo)</author>
      <guid isPermaLink="false">2504.10106v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Satellite Federated Fine-Tuning for Foundation Models in Space Computing Power Networks</title>
      <link>http://arxiv.org/abs/2504.10403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种卫星-地面协同联邦微调框架，旨在解决大型基础模型在卫星上进行微调时的计算能力不足和通信挑战。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能和低地球轨道卫星的发展，大型遥感基础模型在地面进行微调受到隐私和带宽限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种卫星-地面协同联邦微调框架，以解决卫星计算能力不足和通信挑战。&lt;h4&gt;方法&lt;/h4&gt;该框架通过合理分解和分配模型组件，减轻卫星计算能力不足的问题。在微调过程中，卫星与地面站或其他卫星交换中间结果，以应对空间传输网络中的通信挑战。此外，还引入了定制通信策略，包括并行轨道内通信策略、拓扑感知卫星-地面通信策略和最小化延迟的轨道间通信策略，以减少空间通信成本。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，采用该框架可以显著减少训练时间，提高约33%。&lt;h4&gt;结论&lt;/h4&gt;卫星-地面协同联邦微调框架能够有效解决大型基础模型在卫星上进行微调时的计算能力不足和通信挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in artificial intelligence (AI) and low-earth orbit (LEO)satellites have promoted the application of large remote sensing foundationmodels for various downstream tasks. However, direct downloading of thesemodels for fine-tuning on the ground is impeded by privacy concerns and limitedbandwidth. Satellite federated learning (FL) offers a solution by enablingmodel fine-tuning directly on-board satellites and aggregating model updateswithout data downloading. Nevertheless, for large foundation models, thecomputational capacity of satellites is insufficient to support effectiveon-board fine-tuning in traditional satellite FL frameworks. To address thesechallenges, we propose a satellite-ground collaborative federated fine-tuningframework. The key of the framework lies in how to reasonably decompose andallocate model components to alleviate insufficient on-board computationcapabilities. During fine-tuning, satellites exchange intermediate results withground stations or other satellites for forward propagation and backpropagation, which brings communication challenges due to the specialcommunication topology of space transmission networks, such as intermittentsatellite-ground communication, short duration of satellite-groundcommunication windows, and unstable inter-orbit inter-satellite links (ISLs).To reduce transmission delays, we further introduce tailored communicationstrategies that integrate both communication and computing resources.Specifically, we propose a parallel intra-orbit communication strategy, atopology-aware satellite-ground communication strategy, and alatency-minimalization inter-orbit communication strategy to reduce spacecommunication costs. Simulation results demonstrate significant reductions intraining time with improvements of approximately 33%.</description>
      <author>example@mail.com (Yan zhu, Jingyang zhu, Ting Wang, Yuanming Shi, Chunxiao Jiang, Khaled Ben Letaief)</author>
      <guid isPermaLink="false">2504.10403v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Invariance Matters: Empowering Social Recommendation via Graph Invariant Learning</title>
      <link>http://arxiv.org/abs/2504.10432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Social Graph Invariant Learning（SGIL）方法，用于解决基于图的社会推荐系统中数据稀疏性和社交网络噪声问题，以增强推荐性能。&lt;h4&gt;背景&lt;/h4&gt;基于图的社会推荐系统利用图神经网络（GNNs）捕捉用户偏好，但现有方法往往忽略社交网络的噪声和冗余关系，影响用户偏好学习的准确性。&lt;h4&gt;目的&lt;/h4&gt;提出SGIL方法，旨在从输入社交图中揭示稳定的用户偏好，从而增强基于图的社会推荐系统的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;SGIL通过图生成器模拟多个噪声社交环境，并通过最小化这些环境中的不变风险来学习环境不变的用户偏好。同时，采用对抗性训练策略以生成更多潜在的社会噪声分布，促进生成社交环境的多样性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SGIL方法有效地提高了基于图的社会推荐系统的推荐性能。&lt;h4&gt;结论&lt;/h4&gt;SGIL方法为解决社交推荐系统中的噪声问题提供了一种新的思路，有助于提高推荐系统的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;Graph-based social recommendation systems have shown significant promise in enhancing recommendation performance, particularly in addressing the issue of data sparsity in user behaviors. Typically, these systems leverage Graph Neural Networks (GNNs) to capture user preferences by incorporating high-order social influences from observed social networks. However, existing graph-based social recommendations often overlook the fact that social networks are inherently noisy, containing task-irrelevant relationships that can hinder accurate user preference learning. The removal of these redundant social relations is crucial, yet it remains challenging due to the lack of ground truth. In this paper, we approach the social denoising problem from the perspective of graph invariant learning and propose a novel method, Social Graph Invariant Learning (SGIL). Specifically, SGIL aims to uncover stable user preferences within the input social graph, thereby enhancing the robustness of graph-based social recommendation systems. To achieve this goal, SGIL first simulates multiple noisy social environments through graph generators. It then seeks to learn environment-invariant user preferences by minimizing invariant risk across these environments. To further promote diversity in the generated social environments, we employ an adversarial training strategy to simulate more potential social noisy distributions. Extensive experimental results demonstrate the effectiveness of the proposed SGIL. The code is available at https://github.com/yimutianyang/SIGIR2025-SGIL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based social recommendation systems have shown significant promise inenhancing recommendation performance, particularly in addressing the issue ofdata sparsity in user behaviors. Typically, these systems leverage Graph NeuralNetworks (GNNs) to capture user preferences by incorporating high-order socialinfluences from observed social networks. However, existing graph-based socialrecommendations often overlook the fact that social networks are inherentlynoisy, containing task-irrelevant relationships that can hinder accurate userpreference learning. The removal of these redundant social relations iscrucial, yet it remains challenging due to the lack of ground truth. In thispaper, we approach the social denoising problem from the perspective of graphinvariant learning and propose a novel method, Social Graph InvariantLearning(SGIL). Specifically,SGIL aims to uncover stable user preferenceswithin the input social graph, thereby enhancing the robustness of graph-basedsocial recommendation systems. To achieve this goal, SGIL first simulatesmultiple noisy social environments through graph generators. It then seeks tolearn environment-invariant user preferences by minimizing invariant riskacross these environments. To further promote diversity in the generated socialenvironments, we employ an adversarial training strategy to simulate morepotential social noisy distributions. Extensive experimental resultsdemonstrate the effectiveness of the proposed SGIL. The code is available athttps://github.com/yimutianyang/SIGIR2025-SGIL.</description>
      <author>example@mail.com (Yonghui Yang, Le Wu, Yuxin Liao, Zhuangzhuang He, Pengyang Shao, Richang Hong, Meng Wang)</author>
      <guid isPermaLink="false">2504.10432v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Representation Learning Techniques for Comprehensive Facial State Analysis</title>
      <link>http://arxiv.org/abs/2504.10351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICME2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全面的多模态面部状态分析方法。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型通过整合多模态信息显著提高了特征表示，适用于更广泛的应用。然而，对于理解感知的多模态面部表示研究有限。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够理解和分析面部状态（如动作单元（AU）和情感）的综合且稳健的框架，该框架能够桥接视觉和语言模态。&lt;h4&gt;方法&lt;/h4&gt;1. 编制一个新的多模态面部数据集（MFA），通过利用GPT-4生成详细的多层次语言描述，包括AU和情感描述。2. 引入一个针对AU和情感识别的新型多层次多模态面部基础模型（MF^2），该模型在面部图像的局部和全局层面上进行全面的视觉特征建模。3. 开发了一个解耦微调网络（DFN），能够高效地在不同任务和数据集上调整MF^2。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在AU和情感检测任务上表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提升多模态面部状态分析的准确性和适用性。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal foundation models have significantly improved feature representation by integrating information from multiple modalities, making them highly suitable for a broader set of applications. However, the exploration of multimodal facial representation for understanding perception has been limited. Understanding and analyzing facial states, such as Action Units (AUs) and emotions, require a comprehensive and robust framework that bridges visual and linguistic modalities. In this paper, we present a comprehensive pipeline for multimodal facial state analysis. First, we compile a new Multimodal FaceDataset (MFA) by generating detailed multilevel language descriptions of face, incorporating Action Unit (AU) and emotion descriptions, by leveraging GPT-4o. Second, we introduce a novel Multilevel Multimodal Face Foundation model (MF^2) tailored for Action Unit (AU) and emotion recognition. Our model incorporates comprehensive visual feature modeling at both local and global levels of face image, enhancing its ability to represent detailed facial appearances. This design aligns visual representations with structured AU and emotion descriptions, ensuring effective cross-modal integration. Third, we develop a Decoupled Fine-Tuning Network (DFN) that efficiently adapts MF^2 across various tasks and datasets. This approach not only reduces computational overhead but also broadens the applicability of the foundation model to diverse scenarios. Experimentation show superior performance for AU and emotion detection tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models have significantly improved featurerepresentation by integrating information from multiple modalities, making themhighly suitable for a broader set of applications. However, the exploration ofmultimodal facial representation for understanding perception has been limited.Understanding and analyzing facial states, such as Action Units (AUs) andemotions, require a comprehensive and robust framework that bridges visual andlinguistic modalities. In this paper, we present a comprehensive pipeline formultimodal facial state analysis. First, we compile a new Multimodal FaceDataset (MFA) by generating detailed multilevel language descriptions of face,incorporating Action Unit (AU) and emotion descriptions, by leveraging GPT-4o.Second, we introduce a novel Multilevel Multimodal Face Foundation model (MF^2)tailored for Action Unit (AU) and emotion recognition. Our model incorporatescomprehensive visual feature modeling at both local and global levels of faceimage, enhancing its ability to represent detailed facial appearances. Thisdesign aligns visual representations with structured AU and emotiondescriptions, ensuring effective cross-modal integration. Third, we develop aDecoupled Fine-Tuning Network (DFN) that efficiently adapts MF^2 across varioustasks and datasets. This approach not only reduces computational overhead butalso broadens the applicability of the foundation model to diverse scenarios.Experimentation show superior performance for AU and emotion detection tasks.</description>
      <author>example@mail.com (Kaiwen Zheng, Xuri Ge, Junchen Fu, Jun Peng, Joemon M. Jose)</author>
      <guid isPermaLink="false">2504.10351v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Pillar-Voxel Fusion Network for 3D Object Detection in Airborne Hyperspectral Point Clouds</title>
      <link>http://arxiv.org/abs/2504.09506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PiV-AHPC的3D目标检测网络，用于空中高光谱点云（HPCs）数据，以解决融合技术和障碍物遮挡导致的几何-光谱失真问题。&lt;h4&gt;背景&lt;/h4&gt;高光谱点云可以同时描述地面物体的3D空间和光谱信息，但目前的方法在融合高光谱图像和LiDAR点云时，容易产生几何-光谱失真，影响下游任务的表现。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的3D目标检测网络PiV-AHPC。&lt;h4&gt;方法&lt;/h4&gt;PiV-AHPC采用柱状体-体素双分支编码器，分别从HPCs中提取光谱和垂直结构特征，以及从点云中提取准确的3D空间特征。同时，设计了一种多级特征融合机制，增强两个分支之间的信息交互，实现邻域特征对齐和通道自适应选择，从而有机地整合异构特征并减轻几何失真。&lt;h4&gt;主要发现&lt;/h4&gt;在两个空中HPCs数据集上的实验表明，PiV-AHPC具有最先进的检测性能和较高的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;PiV-AHPC是首次尝试针对HPCs任务的3D目标检测网络，能够有效解决现有方法中的几何-光谱失真问题，并在空中应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Hyperspectral point clouds (HPCs) can simultaneously characterize 3D spatial and spectral information of ground objects, offering excellent 3D perception and target recognition capabilities. Current approaches for generating HPCs often involve fusion techniques with hyperspectral images and LiDAR point clouds, which inevitably lead to geometric-spectral distortions due to fusion errors and obstacle occlusions. These adverse effects limit their performance in downstream fine-grained tasks across multiple scenarios, particularly in airborne applications. To address these issues, we propose PiV-AHPC, a 3D object detection network for airborne HPCs. To the best of our knowledge, this is the first attempt at this HPCs task. Specifically, we first develop a pillar-voxel dual-branch encoder, where the former captures spectral and vertical structural features from HPCs to overcome spectral distortion, while the latter emphasizes extracting accurate 3D spatial features from point clouds. A multi-level feature fusion mechanism is devised to enhance information interaction between the two branches, achieving neighborhood feature alignment and channel-adaptive selection, thereby organically integrating heterogeneous features and mitigating geometric distortion. Extensive experiments on two airborne HPCs datasets demonstrate that PiV-AHPC possesses state-of-the-art detection performance and high generalization capability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperspectral point clouds (HPCs) can simultaneously characterize 3D spatialand spectral information of ground objects, offering excellent 3D perceptionand target recognition capabilities. Current approaches for generating HPCsoften involve fusion techniques with hyperspectral images and LiDAR pointclouds, which inevitably lead to geometric-spectral distortions due to fusionerrors and obstacle occlusions. These adverse effects limit their performancein downstream fine-grained tasks across multiple scenarios, particularly inairborne applications. To address these issues, we propose PiV-AHPC, a 3Dobject detection network for airborne HPCs. To the best of our knowledge, thisis the first attempt at this HPCs task. Specifically, we first develop apillar-voxel dual-branch encoder, where the former captures spectral andvertical structural features from HPCs to overcome spectral distortion, whilethe latter emphasizes extracting accurate 3D spatial features from pointclouds. A multi-level feature fusion mechanism is devised to enhanceinformation interaction between the two branches, achieving neighborhoodfeature alignment and channel-adaptive selection, thereby organicallyintegrating heterogeneous features and mitigating geometric distortion.Extensive experiments on two airborne HPCs datasets demonstrate that PiV-AHPCpossesses state-of-the-art detection performance and high generalizationcapability.</description>
      <author>example@mail.com (Yanze Jiang, Yanfeng Gu, Xian Li)</author>
      <guid isPermaLink="false">2504.09506v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Negate or Embrace: On How Misalignment Shapes Multimodal Representation Learning</title>
      <link>http://arxiv.org/abs/2504.10143v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态表示学习，特别是通过图像-文本对进行的多模态对比学习（MMCL），以及如何处理现实数据集中存在的模态间不匹配问题。&lt;h4&gt;背景&lt;/h4&gt;多模态表示学习旨在通过跨模态对齐线索来学习强大的表示。然而，现实数据集常常表现出模态间的不匹配。&lt;h4&gt;目的&lt;/h4&gt;旨在调和缓解和不利用不匹配的两种观点，并为从业者提供实用指南。&lt;h4&gt;方法&lt;/h4&gt;使用潜在变量模型，通过引入选择偏差和扰动偏差两种机制来形式化不匹配。选择偏差指某些语义变量缺失，扰动偏差指语义变量被扭曲，这两种偏差都影响跨模态共享的潜在变量。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，在温和的假设下，MMCL学习到的表示恰好捕捉了与不受选择和扰动偏差影响的语义变量子集相关的信息。&lt;h4&gt;结论&lt;/h4&gt;这为理解不匹配提供了一个统一的视角，并基于此提供了关于如何设计现实世界机器学习系统的可操作见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态表示学习，以多模态对比学习（MMCL）使用图像-文本对为例，旨在通过跨模态对齐线索来学习强大的表示。这种方法依赖于核心假设，即示例图像-文本对构成了一个相同概念的两种表示。然而，最近的研究表明，现实世界的数据集往往表现出不匹配。关于如何解决这个问题，有两种不同的观点：一种建议缓解不匹配，另一种则利用它。在这里，我们试图调和这些看似对立的观点，并为从业者提供实用指南。因此，我们使用潜在变量模型，通过引入两种特定的机制来形式化不匹配：选择偏差，其中一些语义变量缺失；以及扰动偏差，其中语义变量被扭曲——两者都影响跨模态共享的潜在变量。我们的理论分析表明，在温和的假设下，MMCL学习到的表示恰好捕捉了与不受选择和扰动偏差影响的语义变量子集相关的信息。这为理解不匹配提供了一个统一的视角。基于此，我们进一步提供了关于如何设计现实世界机器学习系统的可操作见解。我们通过在合成数据和真实图像-文本数据集上进行的广泛实证研究验证了我们的理论发现，揭示了不匹配对多模态表示学习的微妙影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation learning, exemplified by multimodal contrastivelearning (MMCL) using image-text pairs, aims to learn powerful representationsby aligning cues across modalities. This approach relies on the core assumptionthat the exemplar image-text pairs constitute two representations of anidentical concept. However, recent research has revealed that real-worlddatasets often exhibit misalignment. There are two distinct viewpoints on howto address this issue: one suggests mitigating the misalignment, and the otherleveraging it. We seek here to reconcile these seemingly opposing perspectives,and to provide a practical guide for practitioners. Using latent variablemodels we thus formalize misalignment by introducing two specific mechanisms:selection bias, where some semantic variables are missing, and perturbationbias, where semantic variables are distorted -- both affecting latent variablesshared across modalities. Our theoretical analysis demonstrates that, undermild assumptions, the representations learned by MMCL capture exactly theinformation related to the subset of the semantic variables invariant toselection and perturbation biases. This provides a unified perspective forunderstanding misalignment. Based on this, we further offer actionable insightsinto how misalignment should inform the design of real-world ML systems. Wevalidate our theoretical findings through extensive empirical studies on bothsynthetic data and real image-text datasets, shedding light on the nuancedimpact of misalignment on multimodal representation learning.</description>
      <author>example@mail.com (Yichao Cai, Yuhang Liu, Erdun Gao, Tianjiao Jiang, Zhen Zhang, Anton van den Hengel, Javen Qinfeng Shi)</author>
      <guid isPermaLink="false">2504.10143v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Relation-augmented Representation Generalization for Few-shot Action Recognition</title>
      <link>http://arxiv.org/abs/2504.10079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HR2G-shot是一个用于Few-shot动作识别（FSAR）的框架，旨在通过统一三种关系建模（帧间、视频间和任务间）来学习特定任务的时序模式。&lt;h4&gt;背景&lt;/h4&gt;现有的FSAR方法通常通过设计各种帧间时序建模策略独立地为每个视频学习帧级表示，但忽略了视频与任务之间的显式关系建模，因此未能捕捉视频之间的共享时序模式并重用历史任务中的时序知识。&lt;h4&gt;目的&lt;/h4&gt;提出HR2G-shot框架，以解决现有FSAR方法中忽视视频与任务关系建模的问题，从而能够学习到跨视频的共享时序模式。&lt;h4&gt;方法&lt;/h4&gt;HR2G-shot框架包括以下两个组件：i) Inter-video Semantic Correlation（ISC）以细粒度方式执行跨视频帧级交互，捕获特定任务的查询特征并学习支持特征之间的类内和类间时序相关性；ii) Inter-task Knowledge Transfer（IKT）从存储历史任务中不同时序模式的数据库中检索和聚合相关时序知识。&lt;h4&gt;主要发现&lt;/h4&gt;在五个基准数据集上的大量实验表明，HR2G-shot优于当前的顶尖FSAR方法。&lt;h4&gt;结论&lt;/h4&gt;HR2G-shot框架能够有效地提高Few-shot动作识别的性能，为FSAR领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Few-shot动作识别（FSAR）旨在通过少量示例识别新的动作类别。现有方法通常通过设计各种帧间时序建模策略独立地为每个视频学习帧级表示。然而，它们忽略了视频与任务之间的显式关系建模，因此未能捕捉视频之间的共享时序模式并重用历史任务中的时序知识。鉴于这一点，我们提出了HR2G-shot，一个用于FSAR的分层关系增强表示泛化框架，它统一了三种类型的关系建模（帧间、视频间和任务间）来从整体角度学习特定任务的时序模式。除了执行帧间时序交互之外，我们还设计了两个组件来分别探索视频间和任务间关系：i) Inter-video Semantic Correlation（ISC）以细粒度方式执行跨视频帧级交互，从而捕获特定任务的查询特征并学习支持特征之间的类内和类间时序相关性；ii) Inter-task Knowledge Transfer（IKT）从存储历史任务中不同时序模式的数据库中检索和聚合相关时序知识。在五个基准数据集上的大量实验表明，HR2G-shot优于当前的顶尖FSAR方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot action recognition (FSAR) aims to recognize novel action categorieswith few exemplars. Existing methods typically learn frame-levelrepresentations independently for each video by designing various inter-frametemporal modeling strategies. However, they neglect explicit relation modelingbetween videos and tasks, thus failing to capture shared temporal patternsacross videos and reuse temporal knowledge from historical tasks. In light ofthis, we propose HR2G-shot, a Hierarchical Relation-augmented RepresentationGeneralization framework for FSAR, which unifies three types of relationmodeling (inter-frame, inter-video, and inter-task) to learn task-specifictemporal patterns from a holistic view. In addition to conducting inter-frametemporal interactions, we further devise two components to respectively exploreinter-video and inter-task relationships: i) Inter-video Semantic Correlation(ISC) performs cross-video frame-level interactions in a fine-grained manner,thereby capturing task-specific query features and learning intra- andinter-class temporal correlations among support features; ii) Inter-taskKnowledge Transfer (IKT) retrieves and aggregates relevant temporal knowledgefrom the bank, which stores diverse temporal patterns from historical tasks.Extensive experiments on five benchmarks show that HR2G-shot outperformscurrent top-leading FSAR methods.</description>
      <author>example@mail.com (Hongyu Qu, Ling Xing, Rui Yan, Yazhou Yao, Guo-Sen Xie, Xiangbo Shu)</author>
      <guid isPermaLink="false">2504.10079v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Inferring genotype-phenotype maps using attention models</title>
      <link>http://arxiv.org/abs/2504.10388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究从基因型预测表型的遗传学挑战，提出了基于注意力机制的机器学习方法作为传统线性回归方法的替代方案。&lt;h4&gt;背景&lt;/h4&gt;传统遗传学方法通常使用线性回归分析基因型与表型之间的关系，但这种方法在处理复杂基因-环境相互作用和上位性模式时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;探讨注意力机制在预测表型方面的潜力，并评估其在遗传学中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;本研究应用注意力模型分析模拟数据和实验数据，比较了其在不同上位性复杂程度下的预测性能。&lt;h4&gt;主要发现&lt;/h4&gt;注意力模型在预测上位性环境下的表型方面表现出优于传统方法的预测能力。此外，多环境注意力模型能够通过有限的训练数据在新的环境条件下预测表型。&lt;h4&gt;结论&lt;/h4&gt;注意力机制在遗传学中预测表型具有潜力，特别是在处理复杂遗传和环境相互作用时，且能够实现跨环境的迁移学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预测表型从基因型是遗传学的核心挑战。传统的数量遗传学方法通常使用基于线性回归的方法来分析这个问题。这些方法通常假设复杂性状的遗传结构可以用加性模型来参数化，其中位点的效应是独立的，加上（在某些情况下）位点之间的成对上位性相互作用。然而，这些模型在分析更复杂的上位性模式或微妙的基因-环境相互作用方面存在困难。最近机器学习领域的进展，尤其是基于注意力的模型，提供了一个有前景的替代方案。最初为自然语言处理开发的注意力模型在捕捉上下文相关的交互方面表现出色，并在预测蛋白质结构和功能方面表现出卓越的性能。在这里，我们将注意力模型应用于数量遗传学。我们使用模拟数据分析了基于注意力的方法在预测基因型从表型方面的性能，这些数据覆盖了具有增加上位性复杂性的各种模型，并使用芽殖酵母中最近的数量性状位点映射研究的实验数据。我们发现，与标准方法相比，我们的模型在上位性环境下表现出优越的样本外预测能力。我们还探索了一个更通用的多环境注意力模型，以联合分析跨多个环境的基因型-表型映射，并显示这种架构可以用于“迁移学习”——在新环境中用有限的训练数据预测表型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting phenotype from genotype is a central challenge in genetics.Traditional approaches in quantitative genetics typically analyze this problemusing methods based on linear regression. These methods generally assume thatthe genetic architecture of complex traits can be parameterized in terms of anadditive model, where the effects of loci are independent, plus (in some cases)pairwise epistatic interactions between loci. However, these models struggle toanalyze more complex patterns of epistasis or subtle gene-environmentinteractions. Recent advances in machine learning, particularly attention-basedmodels, offer a promising alternative. Initially developed for natural languageprocessing, attention-based models excel at capturing context-dependentinteractions and have shown exceptional performance in predicting proteinstructure and function. Here, we apply attention-based models to quantitativegenetics. We analyze the performance of this attention-based approach inpredicting phenotype from genotype using simulated data across a range ofmodels with increasing epistatic complexity, and using experimental data from arecent quantitative trait locus mapping study in budding yeast. We find thatour model demonstrates superior out-of-sample predictions in epistatic regimescompared to standard methods. We also explore a more general multi-environmentattention-based model to jointly analyze genotype-phenotype maps acrossmultiple environments and show that such architectures can be used for"transfer learning" - predicting phenotypes in novel environments with limitedtraining data.</description>
      <author>example@mail.com (Krishna Rijal, Caroline M. Holmes, Samantha Petti, Gautam Reddy, Michael M. Desai, Pankaj Mehta)</author>
      <guid isPermaLink="false">2504.10388v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian Splatting for Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2504.10331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LL-Gaussian的新框架，用于从低光sRGB图像中进行3D重建和增强，实现了伪自然光的新视角合成。&lt;h4&gt;背景&lt;/h4&gt;在低光场景中进行新颖视图合成（NVS）是一个重大挑战，因为输入质量下降，具有严重的噪声、低动态范围（LDR）和不稳定的初始化。&lt;h4&gt;目的&lt;/h4&gt;旨在解决低光场景下NVS的挑战，实现快速、高质量的3D重建和渲染。&lt;h4&gt;方法&lt;/h4&gt;LL-Gaussian引入了三个关键创新：1）一个端到端的低光高斯初始化模块（LLGIM），利用基于学习的MVS方法的密集先验来生成高质量的初始点云；2）一个双分支高斯分解模型，将场景的内在属性（反射率和照明）与瞬时的干扰分离，以实现稳定和可解释的优化；3）一个由物理约束和扩散先验引导的无监督优化策略，以联合引导分解和增强。&lt;h4&gt;主要发现&lt;/h4&gt;LL-Gaussian在速度和效果上优于现有的NeRF方法，实现了高达2000倍的速度提升，并将训练时间缩短到2%，同时提供更高质量的重建和渲染。&lt;h4&gt;结论&lt;/h4&gt;LL-Gaussian框架在低光环境下实现了有效的3D重建和渲染，为低光场景下的NVS提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Novel view synthesis (NVS) in low-light scenes remains a significantchallenge due to degraded inputs characterized by severe noise, low dynamicrange (LDR) and unreliable initialization. While recent NeRF-based approacheshave shown promising results, most suffer from high computational costs, andsome rely on carefully captured or pre-processed data--such as RAW sensorinputs or multi-exposure sequences--which severely limits their practicality.In contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering withcompetitive visual fidelity; however, existing 3DGS-based methods struggle withlow-light sRGB inputs, resulting in unstable Gaussian initialization andineffective noise suppression. To address these challenges, we proposeLL-Gaussian, a novel framework for 3D reconstruction and enhancement fromlow-light sRGB images, enabling pseudo normal-light novel view synthesis. Ourmethod introduces three key innovations: 1) an end-to-end Low-Light GaussianInitialization Module (LLGIM) that leverages dense priors from learning-basedMVS approach to generate high-quality initial point clouds; 2) a dual-branchGaussian decomposition model that disentangles intrinsic scene properties(reflectance and illumination) from transient interference, enabling stable andinterpretable optimization; 3) an unsupervised optimization strategy guided byboth physical constrains and diffusion prior to jointly steer decomposition andenhancement. Additionally, we contribute a challenging dataset collected inextreme low-light environments and demonstrate the effectiveness ofLL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussianachieves up to 2,000 times faster inference and reduces training time to just2%, while delivering superior reconstruction and rendering quality.</description>
      <author>example@mail.com (Hao Sun, Fenggen Yu, Huiyao Xu, Tao Zhang, Changqing Zou)</author>
      <guid isPermaLink="false">2504.10331v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling Contrastive Learning's Capability of Neighborhood Aggregation for Collaborative Filtering</title>
      <link>http://arxiv.org/abs/2504.10113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGIR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LightCCF的个性化推荐方法，基于图对比学习，通过理论推导和实验验证，发现CL目标函数的梯度下降过程等同于图卷积，支持在交互图上的邻域聚合，并提出改进的邻域聚合目标，提高了推荐系统的训练效率和推荐准确性。&lt;h4&gt;背景&lt;/h4&gt;个性化推荐在网页应用中广泛应用，图对比学习（GCL）成为推荐系统的主要方法之一，因为它能够从原始交互数据中提取自监督信号，有效缓解数据稀疏性问题。&lt;h4&gt;目的&lt;/h4&gt;揭示GCL方法性能提升的原因，并提出改进方法以提高推荐系统的训练效率和推荐准确性。&lt;h4&gt;方法&lt;/h4&gt;通过理论推导证明CL目标函数的梯度下降过程等同于图卷积，提出LightCCF方法，引入新的邻域聚合目标，实现高质量邻域聚合。&lt;h4&gt;主要发现&lt;/h4&gt;CL目标函数的梯度下降过程等同于图卷积，支持在交互图上的邻域聚合，现有方法在正样本选择上存在误区，限制了CL目标函数的潜力。&lt;h4&gt;结论&lt;/h4&gt;LightCCF方法在三个高度稀疏的公共数据集上，有效聚合邻域信息，防止图过度平滑，在训练效率和推荐准确性方面均优于现有GCL方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：个性化推荐在网页应用中得到广泛应用，图对比学习（GCL）逐渐成为推荐系统中的主流方法，主要归功于其从原始交互数据中提取自监督信号的能力，有效缓解了数据稀疏性问题。一个典型的基于GCL的方法通常在图卷积期间进行数据增强，以生成更多的对比视图，并对这些新视图进行对比以获得丰富的自监督信号。尽管这种范式是有效的，但其性能提升背后的原因仍然是个谜。在这篇论文中，我们首先通过理论推导揭示，CL目标的梯度下降过程形式上等同于图卷积，这意味着CL目标函数本质上支持在交互图上的邻域聚合。我们进一步通过实验验证这一能力，并确定了先前方法中选择正样本的常见误区，这些误区限制了CL目标函数的潜力。基于这一发现，我们提出了Light Contrastive Collaborative Filtering（LightCCF）方法，该方法引入了一个新的邻域聚合目标，在将用户推向所有互动项目的同时，将他们推向其他正对，从而以非常低的时间复杂度实现高质量的邻域聚合。在三个高度稀疏的公共数据集上，所提出的方法有效地聚合了邻域信息，同时防止了图过度平滑，在训练效率和推荐准确性方面均优于现有的基于GCL的方法。我们的实现是公开可访问的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Personalized recommendation is widely used in the web applications, and graphcontrastive learning (GCL) has gradually become a dominant approach inrecommender systems, primarily due to its ability to extract self-supervisedsignals from raw interaction data, effectively alleviating the problem of datasparsity. A classic GCL-based method typically uses data augmentation duringgraph convolution to generates more contrastive views, and performs contrast onthese new views to obtain rich self-supervised signals. Despite this paradigmis effective, the reasons behind the performance gains remain a mystery. Inthis paper, we first reveal via theoretical derivation that the gradientdescent process of the CL objective is formally equivalent to graphconvolution, which implies that CL objective inherently supports neighborhoodaggregation on interaction graphs. We further substantiate this capabilitythrough experimental validation and identify common misconceptions in theselection of positive samples in previous methods, which limit the potential ofCL objective. Based on this discovery, we propose the Light ContrastiveCollaborative Filtering (LightCCF) method, which introduces a novelneighborhood aggregation objective to bring users closer to all interacteditems while pushing them away from other positive pairs, thus achievinghigh-quality neighborhood aggregation with very low time complexity. On threehighly sparse public datasets, the proposed method effectively aggregateneighborhood information while preventing graph over-smoothing, demonstratingsignificant improvements over existing GCL-based counterparts in both trainingefficiency and recommendation accuracy. Our implementations are publiclyaccessible.</description>
      <author>example@mail.com (Yu Zhang, Yiwen Zhang, Yi Zhang, Lei Sang, Yun Yang)</author>
      <guid isPermaLink="false">2504.10113v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>EmbodiedOcc++: Boosting Embodied 3D Occupancy Prediction with Plane Regularization and Uncertainty Sampler</title>
      <link>http://arxiv.org/abs/2504.09540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EmbodiedOcc++的在线3D占用预测框架，通过引入几何引导优化模块（GRM）和语义感知不确定性采样器（SUS）两个关键创新，提升了原始框架的性能。&lt;h4&gt;背景&lt;/h4&gt;在线3D占用预测对于理解虚拟环境具有重要意义，然而现有的EmbodiedOcc框架未能充分利用室内环境的几何特性。&lt;h4&gt;目的&lt;/h4&gt;提高EmbodiedOcc框架在室内环境占用预测中的几何一致性。&lt;h4&gt;方法&lt;/h4&gt;1. 引入GRM模块，通过平面正则化约束高斯更新，使语义高斯与平面表面准确对齐。2. 引入SUS模块，在连续帧的重叠区域进行更有效的更新。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，EmbodiedOcc++在EmbodiedOcc-ScanNet基准测试中取得了最先进的性能，提高了边缘精度并保留了更多几何细节，同时保证了计算效率。&lt;h4&gt;结论&lt;/h4&gt;EmbodiedOcc++是一种有效的在线3D占用预测方法，对于在线实体感知具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;Online 3D occupancy prediction provides a comprehensive spatial understanding of embodied environments. While the innovative EmbodiedOcc framework utilizes 3D semantic Gaussians for progressive indoor occupancy prediction, it overlooks the geometric characteristics of indoor environments, which are primarily characterized by planar structures. This paper introduces EmbodiedOcc++, enhancing the original framework with two key innovations: a Geometry-guided Refinement Module (GRM) that constrains Gaussian updates through planar regularization, along with a Semantic-aware Uncertainty Sampler (SUS) that enables more effective updates in overlapping regions between consecutive frames. GRM regularizes the position update to align with surface normals. It determines the adaptive regularization weight using curvature-based and depth-based constraints, allowing semantic Gaussians to align accurately with planar surfaces while adapting in complex regions. To effectively improve geometric consistency from different views, SUS adaptively selects proper Gaussians to update. Comprehensive experiments on the EmbodiedOcc-ScanNet benchmark demonstrate that EmbodiedOcc++ achieves state-of-the-art performance across different settings. Our method demonstrates improved edge accuracy and retains more geometric details while ensuring computational efficiency, which is essential for online embodied perception. The code will be released at: https://github.com/PKUHaoWang/EmbodiedOcc2.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Online 3D occupancy prediction provides a comprehensive spatial understandingof embodied environments. While the innovative EmbodiedOcc framework utilizes3D semantic Gaussians for progressive indoor occupancy prediction, it overlooksthe geometric characteristics of indoor environments, which are primarilycharacterized by planar structures. This paper introduces EmbodiedOcc++,enhancing the original framework with two key innovations: a Geometry-guidedRefinement Module (GRM) that constrains Gaussian updates through planeregularization, along with a Semantic-aware Uncertainty Sampler (SUS) thatenables more effective updates in overlapping regions between consecutiveframes. GRM regularizes the position update to align with surface normals. Itdetermines the adaptive regularization weight using curvature-based anddepth-based constraints, allowing semantic Gaussians to align accurately withplanar surfaces while adapting in complex regions. To effectively improvegeometric consistency from different views, SUS adaptively selects properGaussians to update. Comprehensive experiments on the EmbodiedOcc-ScanNetbenchmark demonstrate that EmbodiedOcc++ achieves state-of-the-art performanceacross different settings. Our method demonstrates improved edge accuracy andretains more geometric details while ensuring computational efficiency, whichis essential for online embodied perception. The code will be released at:https://github.com/PKUHaoWang/EmbodiedOcc2.</description>
      <author>example@mail.com (Hao Wang, Xiaobao Wei, Xiaoan Zhang, Jianing Li, Chengyu Bai, Ying Li, Ming Lu, Wenzhao Zheng, Shanghang Zhang)</author>
      <guid isPermaLink="false">2504.09540v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>UP-Person: Unified Parameter-Efficient Transfer Learning for Text-based Person Retrieval</title>
      <link>http://arxiv.org/abs/2504.10084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 figures, first submited to IEEE TCSVT on 2024 May. Under  review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为UP-Person的新型统一参数高效迁移学习方法，用于基于文本的人物检索任务，该方法通过仅微调少量参数实现了良好的性能。&lt;h4&gt;背景&lt;/h4&gt;基于文本的人物检索（TPR）是一个多模态任务，它利用CLIP等预训练模型来提取人物图像和文本特征，并在这一领域取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种参数高效的方法，用于基于文本的人物检索，以解决全量微调大模型容易过拟合且泛化能力受限的问题。&lt;h4&gt;方法&lt;/h4&gt;UP-Person方法集成了三个轻量级PETL组件：Prefix、LoRA和Adapter。Prefix和LoRA用于挖掘局部信息，Adapter用于调整全局特征表示。同时优化了S-Prefix和L-Adapter两个子模块以适应统一的TPR架构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，UP-Person在各种人物检索数据集上取得了最先进的结果，包括CUHK-PEDES、ICFG-PEDES和RSTPReid，而仅微调了4.7%的参数。&lt;h4&gt;结论&lt;/h4&gt;UP-Person方法通过微调少量参数实现了高效的人物检索，为基于文本的人物检索任务提供了一个新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Based on text, the paper proposes a novel unified parameter-efficient transfer learning method (UP-Person) for person retrieval, achieving advanced performance by merely fine-tuning a small number of parameters.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-based Person Retrieval (TPR) as a multi-modal task, which aims toretrieve the target person from a pool of candidate images given a textdescription, has recently garnered considerable attention due to the progressof contrastive visual-language pre-trained model. Prior works leveragepre-trained CLIP to extract person visual and textual features and fullyfine-tune the entire network, which have shown notable performance improvementscompared to uni-modal pre-training models. However, full-tuning a large modelis prone to overfitting and hinders the generalization ability. In this paper,we propose a novel Unified Parameter-Efficient Transfer Learning (PETL) methodfor Text-based Person Retrieval (UP-Person) to thoroughly transfer themulti-modal knowledge from CLIP. Specifically, UP-Person simultaneouslyintegrates three lightweight PETL components including Prefix, LoRA andAdapter, where Prefix and LoRA are devised together to mine local informationwith task-specific information prompts, and Adapter is designed to adjustglobal feature representations. Additionally, two vanilla submodules areoptimized to adapt to the unified architecture of TPR. For one thing, S-Prefixis proposed to boost attention of prefix and enhance the gradient propagationof prefix tokens, which improves the flexibility and performance of the vanillaprefix. For another thing, L-Adapter is designed in parallel with layernormalization to adjust the overall distribution, which can resolve conflictscaused by overlap and interaction among multiple submodules. Extensiveexperimental results demonstrate that our UP-Person achieves state-of-the-artresults across various person retrieval datasets, including CUHK-PEDES,ICFG-PEDES and RSTPReid while merely fine-tuning 4.7\% parameters. Code isavailable at https://github.com/Liu-Yating/UP-Person.</description>
      <author>example@mail.com (Yating Liu, Yaowei Li, Xiangyuan Lan, Wenming Yang, Zimo Liu, Qingmin Liao)</author>
      <guid isPermaLink="false">2504.10084v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Text To 3D Object Generation For Scalable Room Assembly</title>
      <link>http://arxiv.org/abs/2504.09328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at the ICLR 2025 Workshop on Synthetic Data&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种端到端系统，用于生成高质量的3D室内场景合成数据，以解决数据稀缺的问题，并旨在通过合成数据增强机器学习模型的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现代场景理解机器学习模型，如深度估计和物体跟踪，依赖于大量、高质量的模拟真实部署场景的数据集。&lt;h4&gt;目的&lt;/h4&gt;为了解决数据稀缺的问题，该研究旨在提出一种可扩展、高质量、可定制的3D室内场景合成数据生成系统。&lt;h4&gt;方法&lt;/h4&gt;系统通过整合和适应文本到图像和多视图扩散模型，结合基于Neural Radiance Field的网格化技术，从文本提示中生成高保真3D物体资产，并使用渲染工具将它们整合到预定义的平面图中。同时，引入了新颖的损失函数和训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;系统支持按需场景生成，旨在缓解当前可用数据的稀缺性，这些数据通常由艺术家手工制作。&lt;h4&gt;结论&lt;/h4&gt;该系统推进了合成数据在解决机器学习训练限制中的作用，使得能够开发出更鲁棒和泛化的现实应用模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代场景理解机器学习模型，如深度估计和物体跟踪，依赖于大量、高质量的模拟真实部署场景的数据集。为了解决数据稀缺问题，我们提出了一种用于生成可扩展、高质量、可定制3D室内场景合成数据的端到端系统。通过整合和适应文本到图像和多视图扩散模型与基于Neural Radiance Field的网格化，该系统从文本提示中生成高保真3D物体资产，并使用渲染工具将它们整合到预定义的平面图中。通过引入新颖的损失函数和训练策略到现有方法中，该系统支持按需场景生成，旨在缓解当前可用数据的稀缺性，这些数据通常由艺术家手工制作。该系统推进了合成数据在解决机器学习训练限制中的作用，使得能够开发出更鲁棒和泛化的现实应用模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern machine learning models for scene understanding, such as depthestimation and object tracking, rely on large, high-quality datasets that mimicreal-world deployment scenarios. To address data scarcity, we propose anend-to-end system for synthetic data generation for scalable, high-quality, andcustomizable 3D indoor scenes. By integrating and adapting text-to-image andmulti-view diffusion models with Neural Radiance Field-based meshing, thissystem generates highfidelity 3D object assets from text prompts andincorporates them into pre-defined floor plans using a rendering tool. Byintroducing novel loss functions and training strategies into existing methods,the system supports on-demand scene generation, aiming to alleviate thescarcity of current available data, generally manually crafted by artists. Thissystem advances the role of synthetic data in addressing machine learningtraining limitations, enabling more robust and generalizable models forreal-world applications.</description>
      <author>example@mail.com (Sonia Laguna, Alberto Garcia-Garcia, Marie-Julie Rakotosaona, Stylianos Moschoglou, Leonhard Helminger, Sergio Orts-Escolano)</author>
      <guid isPermaLink="false">2504.09328v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>A Model Zoo of Vision Transformers</title>
      <link>http://arxiv.org/abs/2504.10231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the ICLR Workshop on Neural Network Weights as a New Data  Modality 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了第一个视觉变压器（ViT）模型动物园，旨在扩展现有模型动物园的功能和应用范围。&lt;h4&gt;背景&lt;/h4&gt;随着“模型动物园”的出现，神经网络模型分析、表示学习以及神经网络的参数生成等下游任务得到了发展。然而，现有的模型动物园在规模和架构上有限，且忽略了当前最成功的神经网络架构之一——Transformer。&lt;h4&gt;目的&lt;/h4&gt;填补现有模型动物园的不足，引入视觉变压器（ViT）模型动物园，并开发新的模型动物园生成蓝图。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新的模型动物园生成蓝图，包括预训练和微调步骤，并发布250个独特的模型。这些模型通过大量生成因素生成，并通过权重空间和行为指标验证其多样性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的模型动物园允许研究人员将基于模型种群的方法从小型模型扩展到最先进架构。&lt;h4&gt;结论&lt;/h4&gt;该模型动物园可在github.com/ModelZoos/ViTModelZoo上获取，有助于推动神经网络模型种群方法的发展。&lt;h4&gt;翻译&lt;/h4&gt;The availability of large, structured populations of neural networks - called 'model zoos' - has led to the development of a multitude of downstream tasks ranging from model analysis, to representation learning on model weights or generative modeling of neural network parameters. However, existing model zoos are limited in size and architecture and neglect the transformer, which is among the currently most successful neural network architectures. We address this gap by introducing the first model zoo of vision transformers (ViT). To better represent recent training approaches, we develop a new blueprint for model zoo generation that encompasses both pre-training and fine-tuning steps, and publish 250 unique models. They are carefully generated with a large span of generating factors, and their diversity is validated using a thorough choice of weight-space and behavioral metrics. To further motivate the utility of our proposed dataset, we suggest multiple possible applications grounded in both extensive exploratory experiments and a number of examples from the existing literature. By extending previous lines of similar work, our model zoo allows researchers to push their model population-based methods from the small model regime to state-of-the-art architectures. We make our model zoo available at github.com/ModelZoos/ViTModelZoo.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The availability of large, structured populations of neural networks - called'model zoos' - has led to the development of a multitude of downstream tasksranging from model analysis, to representation learning on model weights orgenerative modeling of neural network parameters. However, existing model zoosare limited in size and architecture and neglect the transformer, which isamong the currently most successful neural network architectures. We addressthis gap by introducing the first model zoo of vision transformers (ViT). Tobetter represent recent training approaches, we develop a new blueprint formodel zoo generation that encompasses both pre-training and fine-tuning steps,and publish 250 unique models. They are carefully generated with a large spanof generating factors, and their diversity is validated using a thorough choiceof weight-space and behavioral metrics. To further motivate the utility of ourproposed dataset, we suggest multiple possible applications grounded in bothextensive exploratory experiments and a number of examples from the existingliterature. By extending previous lines of similar work, our model zoo allowsresearchers to push their model population-based methods from the small modelregime to state-of-the-art architectures. We make our model zoo available atgithub.com/ModelZoos/ViTModelZoo.</description>
      <author>example@mail.com (Damian Falk, Léo Meynent, Florence Pfammatter, Konstantin Schürholt, Damian Borth)</author>
      <guid isPermaLink="false">2504.10231v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>AI-Driven Code Refactoring: Using Graph Neural Networks to Enhance Software Maintainability</title>
      <link>http://arxiv.org/abs/2504.10412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了图神经网络（GNNs）在代码重构中的应用，利用抽象语法树（AST）提高软件可维护性。&lt;h4&gt;背景&lt;/h4&gt;通过分析来自CodeSearchNet的200万个代码片段和75000个文件的GitHub Python语料库，研究对比了GNNs与基于规则的SonarQube和决策树。&lt;h4&gt;目的&lt;/h4&gt;利用GNNs提高代码重构的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;使用GNNs对代码进行重构，并与SonarQube和决策树进行对比，评估了复杂度、耦合度和重构精度等指标。&lt;h4&gt;主要发现&lt;/h4&gt;GNNs在重构代码时达到了92%的准确率，将复杂度降低了35%，耦合度降低了33%，超过了SonarQube（78%，16%）和决策树（85%，25%）。预处理固定了60%的语法错误。&lt;h4&gt;结论&lt;/h4&gt;GNNs提供了一个可扩展的人工智能驱动的路径，以实现更清洁的代码库，这对于软件工程至关重要。&lt;h4&gt;翻译&lt;/h4&gt;This study explores Graph Neural Networks (GNNs) as a transformative tool for code refactoring, using abstract syntax trees (ASTs) to boost software maintainability. It analyzes a dataset of 2 million snippets from CodeSearchNet and a custom 75000-file GitHub Python corpus, comparing GNNs against rule-based SonarQube and decision trees. Metrics include cyclomatic complexity (target below 10), coupling (target below 5), and refactoring precision. GNNs achieve 92% accuracy, reducing complexity by 35% and coupling by 33%, outperforming SonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% of syntax errors. Bar graphs, tables, and AST visuals clarify results. This offers a scalable AI-driven path to cleaner codebases, which is crucial for software engineering.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores Graph Neural Networks (GNNs) as a transformative tool forcode refactoring, using abstract syntax trees (ASTs) to boost softwaremaintainability. It analyzes a dataset of 2 million snippets from CodeSearchNetand a custom 75000-file GitHub Python corpus, comparing GNNs against rule-basedSonarQube and decision trees. Metrics include cyclomatic complexity (targetbelow 10), coupling (target below 5), and refactoring precision. GNNs achieve92% accuracy, reducing complexity by 35% and coupling by 33%, outperformingSonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% ofsyntax errors. Bar graphs, tables, and AST visuals clarify results. This offersa scalable AI-driven path to cleaner codebases, which is crucial for softwareengineering.</description>
      <author>example@mail.com (Gopichand Bandarupalli)</author>
      <guid isPermaLink="false">2504.10412v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>RICCARDO: Radar Hit Prediction and Convolution for Camera-Radar 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.09086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于雷达回波分布模型的雷达-相机融合方法，以提高雷达-相机检测性能。&lt;h4&gt;背景&lt;/h4&gt;雷达回波在物体边界和内部点反射，导致雷达回波分布复杂，依赖于物体类别、大小和方向等因素。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过雷达回波分布模型辅助融合，以提高雷达-相机检测性能。&lt;h4&gt;方法&lt;/h4&gt;1. 建立模型预测基于单目检测器获得的物体属性条件下的雷达回波分布。2. 使用预测分布作为核函数匹配单目检测附近的实际测量雷达点，生成附近位置的匹配分数。3. 融合阶段结合上下文和核检测器来细化匹配分数。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在nuScenes数据集上实现了最先进的雷达-相机检测性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过雷达回波分布模型辅助融合，有效提升了雷达-相机检测性能。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is summarized as follows: This paper proposes a radar-camera fusion method based on a radar hit distribution model to improve radar-camera detection performance. Radar hits reflect from points on both the boundary and internal to object outlines, resulting in a complex distribution of radar hits that depends on factors including object category, size, and orientation. The proposed method explicitly utilizes a radar hit distribution model to assist fusion. First, a model is built to predict radar hit distributions conditioned on object properties obtained from a monocular detector. Second, the predicted distribution is used as a kernel to match actual measured radar points in the neighborhood of the monocular detections, generating matching scores at nearby positions. Finally, a fusion stage combines context with the kernel detector to refine the matching scores. The method achieves the state-of-the-art radar-camera detection performance on nuScenes. The source code is available at https://github.com/longyunf/riccardo.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radar hits reflect from points on both the boundary and internal to objectoutlines. This results in a complex distribution of radar hits that depends onfactors including object category, size, and orientation. Current radar-camerafusion methods implicitly account for this with a black-box neural network. Inthis paper, we explicitly utilize a radar hit distribution model to assistfusion. First, we build a model to predict radar hit distributions conditionedon object properties obtained from a monocular detector. Second, we use thepredicted distribution as a kernel to match actual measured radar points in theneighborhood of the monocular detections, generating matching scores at nearbypositions. Finally, a fusion stage combines context with the kernel detector torefine the matching scores. Our method achieves the state-of-the-artradar-camera detection performance on nuScenes. Our source code is available athttps://github.com/longyunf/riccardo.</description>
      <author>example@mail.com (Yunfei Long, Abhinav Kumar, Xiaoming Liu, Daniel Morris)</author>
      <guid isPermaLink="false">2504.09086v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Mavors: Multi-granularity Video Representation for Multimodal Large Language Model</title>
      <link>http://arxiv.org/abs/2504.10068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Mavors是一个针对多模态大型语言模型（MLLMs）长视频理解的新框架，旨在平衡计算效率与保留精细时空模式。&lt;h4&gt;背景&lt;/h4&gt;长视频理解在MLLMs中面临挑战，现有方法如稀疏采样、低分辨率密集采样和标记压缩在处理复杂运动或不同分辨率的视频时，会在时间动态、空间细节或微妙交互方面损失大量信息。&lt;h4&gt;目的&lt;/h4&gt;提出Mavors框架，旨在解决上述问题，实现整体长视频建模。&lt;h4&gt;方法&lt;/h4&gt;Mavors通过两个核心组件直接将原始视频内容编码成潜在表示：1) 内部块视觉编码器（IVE），通过3D卷积和视觉Transformer保留高分辨率空间特征；2) 交叉块特征聚合器（IFA），使用基于transformer的依赖建模和块级旋转位置编码建立块之间的时间一致性。此外，该框架通过将图像视为单帧视频，通过子图像分解统一图像和视频理解。&lt;h4&gt;主要发现&lt;/h4&gt;Mavors在保持空间保真度和时间连续性方面表现出优越性，在需要精细时空推理的任务中显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;Mavors框架在长视频理解中提供了一种有效的解决方案，能够平衡计算效率与时空信息保留。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在多模态大型语言模型（MLLMs）中进行长视频理解面临一个关键挑战：在保持精细时空模式的同时平衡计算效率。现有方法（例如稀疏采样、低分辨率密集采样和标记压缩）在处理复杂运动或不同分辨率的视频时，在时间动态、空间细节或微妙交互方面存在显著的信息损失。为了解决这个问题，我们提出了Mavors，这是一个用于整体长视频建模的新框架。具体来说，Mavors通过两个核心组件直接将原始视频内容编码成潜在表示：1) 内部块视觉编码器（IVE），通过3D卷积和视觉Transformer保留高分辨率空间特征；2) 交叉块特征聚合器（IFA），使用基于transformer的依赖建模和块级旋转位置编码建立块之间的时间一致性。此外，该框架通过将图像视为单帧视频，通过子图像分解统一图像和视频理解。在多个基准测试中的实验表明，Mavors在保持空间保真度和时间连续性方面具有优越性，在需要精细时空推理的任务中显著优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-context video understanding in multimodal large language models (MLLMs)faces a critical challenge: balancing computational efficiency with theretention of fine-grained spatio-temporal patterns. Existing approaches (e.g.,sparse sampling, dense sampling with low resolution, and token compression)suffer from significant information loss in temporal dynamics, spatial details,or subtle interactions, particularly in videos with complex motion or varyingresolutions. To address this, we propose $\mathbf{Mavors}$, a novel frameworkthat introduces $\mathbf{M}$ulti-gr$\mathbf{a}$nularity$\mathbf{v}$ide$\mathbf{o}$ $\mathbf{r}$epre$\mathbf{s}$entation for holisticlong-video modeling. Specifically, Mavors directly encodes raw video contentinto latent representations through two core components: 1) an Intra-chunkVision Encoder (IVE) that preserves high-resolution spatial features via 3Dconvolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator(IFA) that establishes temporal coherence across chunks using transformer-baseddependency modeling with chunk-level rotary position encodings. Moreover, theframework unifies image and video understanding by treating images assingle-frame videos via sub-image decomposition. Experiments across diversebenchmarks demonstrate Mavors' superiority in maintaining both spatial fidelityand temporal continuity, significantly outperforming existing methods in tasksrequiring fine-grained spatio-temporal reasoning.</description>
      <author>example@mail.com (Yang Shi, Jiaheng Liu, Yushuo Guan, Zhenhua Wu, Yuanxing Zhang, Zihao Wang, Weihong Lin, Jingyun Hua, Zekun Wang, Xinlong Chen, Bohan Zeng, Wentao Zhang, Fuzheng Zhang, Wenjing Yang, Di Zhang)</author>
      <guid isPermaLink="false">2504.10068v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>The topology of synergy: linking topological and information-theoretic approaches to higher-order interactions in complex systems</title>
      <link>http://arxiv.org/abs/2504.10140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了不可约高阶相互作用在复杂系统中的研究，比较了拓扑数据分析和多变量信息理论在描述多变量数据中高阶相互作用的方法。&lt;h4&gt;背景&lt;/h4&gt;高阶相互作用成为复杂系统研究的核心，拓扑数据分析和多变量信息理论是识别高阶相互作用的主要框架。&lt;h4&gt;目的&lt;/h4&gt;评估两种框架在定义“高阶结构”方面的异同。&lt;h4&gt;方法&lt;/h4&gt;通过玩具示例和自然数据（如fMRI信号）进行对比研究，并使用PCA进行降维分析。&lt;h4&gt;主要发现&lt;/h4&gt;高阶协同信息与点云中的三维洞穴相关，fMRI数据中协同信息与三维洞穴的数量和大小有强相关性，PCA倾向于表示高阶冗余，但未能保留高阶信息和拓扑结构。&lt;h4&gt;结论&lt;/h4&gt;这些结果指向了发展一个涵盖拓扑和信息理论方法，同时强调更传统方法局限性的丰富的高阶相互作用理论的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：不可约高阶相互作用的研究已成为复杂系统研究的核心主题。拓扑数据分析和多变量信息理论是识别经验数据中高阶相互作用的最发达的两种框架。尽管这两者有相似的宗旨，但它们建立在明显不同的数学基础上，并且主要是平行发展的。在本研究中，我们展示了拓扑数据分析和信息理论方法在描述多变量数据中高阶相互作用方面的直接比较；目的是评估这些框架在定义“高阶结构”方面的相似性和差异性。我们从具有已知拓扑的玩具示例开始，然后转向自然数据：从人脑收集的fMRI信号。我们发现内在的高阶协同信息与点云中的三维洞穴相关：如球体这样的形状是协同主导的。在fMRI数据中，我们发现协同信息与三维洞穴的数量和大小之间存在强相关性。此外，我们发现降维技术如PCA优先表示高阶冗余，并且很大程度上未能保留高阶信息和拓扑结构，这表明基于流形的常见方法在系统地识别数据的重要特征方面存在系统性失败。这些结果指向了发展一个涵盖拓扑和信息理论方法，同时同时强调更传统方法局限性的丰富的高阶相互作用理论的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The study of irreducible higher-order interactions has become a core topic ofstudy in complex systems. Two of the most well-developed frameworks,topological data analysis and multivariate information theory, aim to provideformal tools for identifying higher-order interactions in empirical data.Despite similar aims, however, these two approaches are built on markedlydifferent mathematical foundations and have been developed largely in parallel.In this study, we present a head-to-head comparison of topological dataanalysis and information-theoretic approaches to describing higher-orderinteractions in multivariate data; with the aim of assessing the similaritiesand differences between how the frameworks define ``higher-order structures."We begin with toy examples with known topologies, before turning tonaturalistic data: fMRI signals collected from the human brain. We find thatintrinsic, higher-order synergistic information is associated withthree-dimensional cavities in a point cloud: shapes such as spheres aresynergy-dominated. In fMRI data, we find strong correlations betweensynergistic information and both the number and size of three-dimensionalcavities. Furthermore, we find that dimensionality reduction techniques such asPCA preferentially represent higher-order redundancies, and largely fail topreserve both higher-order information and topological structure, suggestingthat common manifold-based approaches to studying high-dimensional data aresystematically failing to identify important features of the data. Theseresults point towards the possibility of developing a rich theory ofhigher-order interactions that spans topological and information-theoreticapproaches while simultaneously highlighting the profound limitations of moreconventional methods.</description>
      <author>example@mail.com (Thomas F. Varley, Pedro A. M. Mediano, Alice Patania, Josh Bongard)</author>
      <guid isPermaLink="false">2504.10140v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Robust Unsupervised Domain Adaptation for 3D Point Cloud Segmentation Under Source Adversarial Attacks</title>
      <link>http://arxiv.org/abs/2504.01659v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种对抗鲁棒的领域自适应（UDA）框架，用于3D点云语义分割模型，通过 stealthy adversarial point cloud generation attack 和 Adversarial Adaptation Framework（AAF）来增强模型在对抗扰动下的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督领域自适应（UDA）框架在干净数据上对3D点云语义分割模型具有良好的泛化能力，但忽略了当源域本身受到损害时的对抗鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;全面探索UDA框架的鲁棒性，并提出对抗鲁棒的解决方案。&lt;h4&gt;方法&lt;/h4&gt;设计了一种 stealthy adversarial point cloud generation attack，用于生成受污染的LiDAR点云数据集AdvSynLiDAR。基于此，提出了一种新的对抗自适应框架（AAF），通过扩展关键点敏感（KPS）损失到鲁棒长尾损失（RLT loss）并利用解码分支，使模型在预训练阶段关注长尾类别，并在适应阶段利用高置信度的解码点云信息来恢复点云结构。&lt;h4&gt;主要发现&lt;/h4&gt;在AdvSynLiDAR数据集上评估了AAF方法，结果表明AAF方法可以减轻3D点云分割应用中源对抗扰动下的性能下降。&lt;h4&gt;结论&lt;/h4&gt;本文提出的AAF方法能够有效提高3D点云语义分割模型在对抗扰动下的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised domain adaptation (UDA) frameworks have shown good generalization capabilities for 3D point cloud semantic segmentation models on clean data. However, existing works overlook adversarial robustness when the source domain itself is compromised. To comprehensively explore the robustness of the UDA frameworks, we first design a stealthy adversarial point cloud generation attack that can significantly contaminate datasets with only minor perturbations to the point cloud surface. Based on that, we propose a novel dataset, AdvSynLiDAR, comprising synthesized contaminated LiDAR point clouds. With the generated corrupted data, we further develop the Adversarial Adaptation Framework (AAF) as the countermeasure. Specifically, by extending the key point sensitive (KPS) loss towards the Robust Long-Tail loss (RLT loss) and utilizing a decoder branch, our approach enables the model to focus on long-tail classes during the pre-training phase and leverages high-confidence decoded point cloud information to restore point cloud structures during the adaptation phase. We evaluated our AAF method on the AdvSynLiDAR dataset, where the results demonstrate that our AAF method can mitigate performance degradation under source adversarial perturbations for UDA in the 3D point cloud segmentation application.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised domain adaptation (UDA) frameworks have shown goodgeneralization capabilities for 3D point cloud semantic segmentation models onclean data. However, existing works overlook adversarial robustness when thesource domain itself is compromised. To comprehensively explore the robustnessof the UDA frameworks, we first design a stealthy adversarial point cloudgeneration attack that can significantly contaminate datasets with only minorperturbations to the point cloud surface. Based on that, we propose a noveldataset, AdvSynLiDAR, comprising synthesized contaminated LiDAR point clouds.With the generated corrupted data, we further develop the AdversarialAdaptation Framework (AAF) as the countermeasure. Specifically, by extendingthe key point sensitive (KPS) loss towards the Robust Long-Tail loss (RLT loss)and utilizing a decoder branch, our approach enables the model to focus onlong-tail classes during the pre-training phase and leverages high-confidencedecoded point cloud information to restore point cloud structures during theadaptation phase. We evaluated our AAF method on the AdvSynLiDAR dataset, wherethe results demonstrate that our AAF method can mitigate performancedegradation under source adversarial perturbations for UDA in the 3D pointcloud segmentation application.</description>
      <author>example@mail.com (Haosheng Li, Junjie Chen, Yuecong Xu, Kemi Ding)</author>
      <guid isPermaLink="false">2504.01659v3</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>STaRFormer: Semi-Supervised Task-Informed Representation Learning via Dynamic Attention-Based Regional Masking for Sequential Data</title>
      <link>http://arxiv.org/abs/2504.10097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer的模型STaRFormer，用于处理非平稳和 irregularly sampled的时空数据，以准确预测智能设备用户在车辆周围受限区域内的意图。&lt;h4&gt;背景&lt;/h4&gt;准确预测序列时空数据对于多种应用至关重要，但现实场景中的环境因素和传感器限制导致数据非平稳和不规则采样，带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;通过使用真实世界数据，学习智能设备用户在车辆周围受限区域内的意图。&lt;h4&gt;方法&lt;/h4&gt;开发了STaRFormer模型，它是一个通用的序列建模框架，采用了一种新颖的动态注意力区域掩码方案，并结合半监督对比学习来增强特定任务的潜在表示。&lt;h4&gt;主要发现&lt;/h4&gt;在15个不同类型（包括非平稳和不规则采样的）、领域、序列长度、训练样本和应用的实验数据集上，STaRFormer展示了其有效性和实用性，并取得了比现有方法显著的改进。&lt;h4&gt;结论&lt;/h4&gt;STaRFormer代码和数据将公开提供，以供进一步研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测序列时空数据对于各种应用至关重要。利用真实世界数据，我们旨在学习智能设备用户在车辆周围受限区域内的意图。然而，在现实场景中，环境因素和传感器限制导致非平稳和不规则采样的数据，带来了重大挑战。为了解决这些问题，我们开发了一种基于Transformer的方法，即STaRFormer，它是一个用于序列建模的通用框架。STaRFormer采用了一种新颖的、基于动态注意力的区域掩码方案，并结合半监督对比学习来增强特定任务的潜在表示。在15个类型（包括非平稳和不规则采样的）、领域、序列长度、训练样本和应用不同的数据集上进行的综合实验，证明了STaRFormer的有效性和实用性。我们实现了对现有方法的显著改进。代码和数据将被公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate predictions using sequential spatiotemporal data are crucial forvarious applications. Utilizing real-world data, we aim to learn the intent ofa smart device user within confined areas of a vehicle's surroundings. However,in real-world scenarios, environmental factors and sensor limitations result innon-stationary and irregularly sampled data, posing significant challenges. Toaddress these issues, we developed a Transformer-based approach, STaRFormer,which serves as a universal framework for sequential modeling. STaRFormeremploys a novel, dynamic attention-based regional masking scheme combined withsemi-supervised contrastive learning to enhance task-specific latentrepresentations. Comprehensive experiments on 15 datasets varying in types(including non-stationary and irregularly sampled), domains, sequence lengths,training samples, and applications, demonstrate the efficacy and practicalityof STaRFormer. We achieve notable improvements over state-of-the-artapproaches. Code and data will be made available.</description>
      <author>example@mail.com (Maxmilian Forstenhäusler, Daniel Külzer, Christos Anagnostopoulos, Shameem Puthiya Parambath, Natascha Weber)</author>
      <guid isPermaLink="false">2504.10097v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Harmonize Cross-vendor X-ray Images by Non-linear Image Dynamics Correction</title>
      <link>http://arxiv.org/abs/2504.10080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了传统图像增强方法在医疗图像分析中如何提高模型鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;通过对不同供应商的图像应用常见的归一化方法，研究了这些方法对迁移学习中模型泛化的影响。&lt;h4&gt;目的&lt;/h4&gt;为了解决领域特定图像动态的非线性特性无法通过简单线性变换解决的问题。&lt;h4&gt;方法&lt;/h4&gt;将图像调和任务重新定义为曝光校正问题，并提出了一种名为全局深度曲线估计（GDCE）的方法来减少领域特定的曝光不匹配。&lt;h4&gt;主要发现&lt;/h4&gt;GDCE通过预定义的多项式函数进行增强，并利用“领域判别器”进行训练，旨在与现有的黑盒方法相比，提高下游任务中模型的透明度。&lt;h4&gt;结论&lt;/h4&gt;研究表明，通过这种方法，可以提高医疗图像分析中模型的鲁棒性和透明度。&lt;h4&gt;翻译&lt;/h4&gt;本研究探讨了如何在医疗图像分析中通过传统图像增强提高模型的鲁棒性。通过对来自不同供应商的图像应用常见的归一化方法，研究了这些方法对迁移学习中模型泛化的影响。为了解决领域特定图像动态的非线性特性无法通过简单线性变换解决的问题，将图像调和任务重新定义为曝光校正问题，并提出了一种名为全局深度曲线估计（GDCE）的方法来减少领域特定的曝光不匹配。GDCE通过预定义的多项式函数进行增强，并利用“领域判别器”进行训练，旨在与现有的黑盒方法相比，提高下游任务中模型的透明度。研究表明，通过这种方法，可以提高医疗图像分析中模型的鲁棒性和透明度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we explore how conventional image enhancement can improvemodel robustness in medical image analysis. By applying commonly usednormalization methods to images from various vendors and studying theirinfluence on model generalization in transfer learning, we show that thenonlinear characteristics of domain-specific image dynamics cannot be addressedby simple linear transforms. To tackle this issue, we reformulate the imageharmonization task as an exposure correction problem and propose a methodtermed Global Deep Curve Estimation (GDCE) to reduce domain-specific exposuremismatch. GDCE performs enhancement via a pre-defined polynomial function andis trained with the help of a ``domain discriminator'', aiming to improve modeltransparency in downstream tasks compared to existing black-box methods.</description>
      <author>example@mail.com (Yucheng Lu, Shunxin Wang, Dovile Juodelyte, Veronika Cheplygina)</author>
      <guid isPermaLink="false">2504.10080v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>CROSSAN: Towards Efficient and Effective Adaptation of Multiple Multimodal Foundation Models for Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2504.10307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为CROSSAN的跨模态侧适配网络，用于解决多模态基础模型在序列推荐任务中的高效适配问题。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在表示不同原始模态（如文本、图像、音频、视频等）方面表现出色，但其在序列推荐中的应用尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以高效且有效地适配多个多模态基础模型进行序列推荐任务。&lt;h4&gt;方法&lt;/h4&gt;CROSSAN利用完全解耦的侧适配器范式，并结合Mixture of Modality Expert Fusion (MOMEF)机制，实现跨模态学习并优化多模态融合的最终阶段。&lt;h4&gt;主要发现&lt;/h4&gt;CROSSAN在公开数据集上表现出色，能够适配四个基础模型并实现性能提升。随着适配的多模态基础模型增多，性能持续提升。&lt;h4&gt;结论&lt;/h4&gt;CROSSAN能够有效解决多模态基础模型在序列推荐任务中的适配问题，并有望促进相关领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a plug-and-play Cross-modal Side Adapter Network (CROSSAN) to address the issue of efficient adaptation of multimodal foundation models in the sequential recommendation task.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Foundation Models (MFMs) excel at representing diverse rawmodalities (e.g., text, images, audio, videos, etc.). As recommender systemsincreasingly incorporate these modalities, leveraging MFMs to generate betterrepresentations has great potential. However, their application in sequentialrecommendation remains largely unexplored. This is primarily because mainstreamadaptation methods, such as Fine-Tuning and even Parameter-EfficientFine-Tuning (PEFT) techniques (e.g., Adapter and LoRA), incur highcomputational costs, especially when integrating multiple modality encoders,thus hindering research progress. As a result, it remains unclear whether wecan efficiently and effectively adapt multiple (&gt;2) MFMs for the sequentialrecommendation task.  To address this, we propose a plug-and-play Cross-modal Side Adapter Network(CROSSAN). Leveraging the fully decoupled side adapter-based paradigm, CROSSANachieves high efficiency while enabling cross-modal learning across diversemodalities. To optimize the final stage of multimodal fusion across diversemodalities, we adopt the Mixture of Modality Expert Fusion (MOMEF) mechanism.CROSSAN achieves superior performance on the public datasets for adapting fourfoundation models with raw modalities. Performance consistently improves asmore MFMs are adapted. We will release our code and datasets to facilitatefuture research.</description>
      <author>example@mail.com (Junchen Fu, Yongxin Ni, Joemon M. Jose, Ioannis Arapakis, Kaiwen Zheng, Youhua Li, Xuri Ge)</author>
      <guid isPermaLink="false">2504.10307v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>ProtoGuard-guided PROPEL: Class-Aware Prototype Enhancement and Progressive Labeling for Incremental 3D Point Cloud Segmentation</title>
      <link>http://arxiv.org/abs/2504.01648v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对3D点云语义分割技术在现实场景中环境不断变化导致的灾难性遗忘问题，提出了ProtoGuard和PROPEL方法，显著提升了3D点云分割的mIoU值。&lt;h4&gt;背景&lt;/h4&gt;3D点云语义分割技术被广泛应用，但在实际环境中，由于环境不断变化，离线训练的分割模型可能会导致对先前类别的灾难性遗忘。&lt;h4&gt;目的&lt;/h4&gt;解决离线训练的分割模型在现实场景中可能出现的灾难性遗忘问题，并提出有效的CIL方法来提高3D点云分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了ProtoGuard和PROPEL方法。ProtoGuard在基础类别训练阶段维护每个类别的几何和语义原型，并通过注意力机制将其组合成原型特征。PROPEL在新型类别训练阶段继承基础特征提取器和分类器，基于密度分布和语义相似性指导伪标签的传播和更新。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在S3DIS和ScanNet数据集上取得了显著的效果，在S3DIS数据集的5步CIL场景下，3D点云分割的mIoU值提高了最多20.39%。&lt;h4&gt;结论&lt;/h4&gt;ProtoGuard和PROPEL方法能够有效解决3D点云语义分割中的灾难性遗忘问题，并显著提高分割性能。&lt;h4&gt;翻译&lt;/h4&gt;3D点云语义分割技术已被广泛应用。然而，在现实场景中，环境是不断演变的。因此，离线训练的分割模型可能会导致先前看到的类别的灾难性遗忘。类增量学习（CIL）旨在解决灾难性遗忘的问题。虽然点云很常见，但我们观察到不同类别之间存在高度相似性和不清晰的边界。同时，它们在类别分布上是不平衡的。这些问题导致了包括相似类别之间的误分类和长尾问题，这些问题在先前的CIL方法中尚未得到充分解决。因此，我们提出了ProtoGuard和PROPEL（伪标签的渐进式细化）。在基础类别训练阶段，ProtoGuard为每个类别维护几何和语义原型，这些原型通过注意力机制组合成原型特征。在新型类别训练阶段，PROPEL继承基础特征提取器和分类器，基于密度分布和语义相似性指导伪标签的传播和更新。大量的实验表明，我们的方法在S3DIS和ScanNet数据集上取得了显著的效果，在S3DIS数据集的5步CIL场景下，3D点云分割的mIoU值最多提高了20.39%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D point cloud semantic segmentation technology has been widely used.However, in real-world scenarios, the environment is evolving. Thus,offline-trained segmentation models may lead to catastrophic forgetting ofpreviously seen classes. Class-incremental learning (CIL) is designed toaddress the problem of catastrophic forgetting. While point clouds are common,we observe high similarity and unclear boundaries between different classes.Meanwhile, they are known to be imbalanced in class distribution. These lead toissues including misclassification between similar classes and the long-tailproblem, which have not been adequately addressed in previous CIL methods. Wethus propose ProtoGuard and PROPEL (Progressive Refinement Of PsEudo-Labels).In the base-class training phase, ProtoGuard maintains geometric and semanticprototypes for each class, which are combined into prototype features using anattention mechanism. In the novel-class training phase, PROPEL inherits thebase feature extractor and classifier, guiding pseudo-label propagation andupdates based on density distribution and semantic similarity. Extensiveexperiments show that our approach achieves remarkable results on both theS3DIS and ScanNet datasets, improving the mIoU of 3D point cloud segmentationby a maximum of 20.39% under the 5-step CIL scenario on S3DIS.</description>
      <author>example@mail.com (Haosheng Li, Yuecong Xu, Junjie Chen, Kemi Ding)</author>
      <guid isPermaLink="false">2504.01648v2</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction</title>
      <link>http://arxiv.org/abs/2504.10240v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Data will be made available on request&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的电路连接预测框架GNN-ACLP，旨在解决现有电路连接预测方法面临的三个主要挑战：拓扑模式利用不足、数据稀缺和适应不同网表格式有限。&lt;h4&gt;背景&lt;/h4&gt;电路连接预测在自动化模拟电路设计中至关重要，但现有方法存在三个主要问题：1) 在电路图中拓扑模式的利用不足；2) 由于标注复杂导致数据稀缺；3) 对不同网表格式的适应性有限。&lt;h4&gt;目的&lt;/h4&gt;提出GNN-ACLP框架，通过引入创新方法来解决上述挑战。&lt;h4&gt;方法&lt;/h4&gt;1) 引入SEAL框架，实现端口级别的电路连接预测精度；2) 提出Netlist Babel Fish工具，利用检索增强生成（RAG）和大型语言模型（LLM）增强网表格式的兼容性；3) 构建SpiceNetlist数据集，包含775个标注电路，涵盖10种不同类别的组件。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在SpiceNetlist数据集上，GNN-ACLP方法相较于现有方法提高了15.05%的准确率，在Image2Net数据集上提高了12.01%的准确率。&lt;h4&gt;结论&lt;/h4&gt;GNN-ACLP框架能够有效解决电路连接预测中的挑战，并显著提高预测精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Circuit link prediction identifying missing component connections fromincomplete netlists is crucial in automating analog circuit design. However,existing methods face three main challenges: 1) Insufficient use of topologicalpatterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due tothe complexity of annotations hinders model generalization; 3) Limitedadaptability to various netlist formats. We propose GNN-ACLP, a Graph NeuralNetworks (GNNs) based framework featuring three innovations to tackle thesechallenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributesfor Link Prediction) framework and achieve port-level accuracy in circuit linkprediction. Second, we propose Netlist Babel Fish, a netlist format conversiontool leveraging retrieval-augmented generation (RAG) with large language model(LLM) to enhance the compatibility of netlist formats. Finally, we constructSpiceNetlist, a comprehensive dataset that contains 775 annotated circuitsacross 10 different classes of components. The experimental results demonstratean improvement of 15.05% on the SpiceNetlist dataset and 12.01% on theImage2Net dataset over the existing approach.</description>
      <author>example@mail.com (Guanyuan Pan, Tiansheng Zhou, Bingtao Ma, Yaqi Wang, Jianxiang Zhao, Shuai Wang)</author>
      <guid isPermaLink="false">2504.10240v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Dual-Path Enhancements in Event-Based Eye Tracking: Augmented Robustness and Adaptive Temporal Modeling</title>
      <link>http://arxiv.org/abs/2504.09960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Camera-ready version for CVPRW 2025. Accepted for presentation at the  IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops  (CVPRW 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;基于事件的眼睛跟踪技术在增强现实和人类-计算机交互中成为一个关键技术。为了解决现实世界中的挑战，如突发的眼睛运动和环境噪声，本研究提出了两个主要进展。&lt;h4&gt;背景&lt;/h4&gt;事件驱动的眼睛跟踪技术在增强现实和人类-计算机交互领域的重要性。&lt;h4&gt;目的&lt;/h4&gt;提高模型对现实世界挑战的鲁棒性，减少误差。&lt;h4&gt;方法&lt;/h4&gt;1. 引入一个鲁棒的数据增强流程，包括时间位移、空间翻转和事件删除。2. 提出KnightPupil混合架构，结合EfficientNet-B3骨干网络、双向GRU和线性时变状态空间模块。&lt;h4&gt;主要发现&lt;/h4&gt;1. 数据增强流程减少了12%的欧几里得距离误差。2. KnightPupil架构在CVPR 2025的3ET+基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;KnightPupil架构在AR/VR系统中的实际部署方面显示出其有效性，并为神经形态视觉的未来创新提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于事件的眼睛跟踪技术已成为增强现实和人类-计算机交互的关键技术。然而，现有方法难以应对现实世界的挑战，如突然的眼动和环境噪声。基于轻量级时空网络（一种针对边缘设备优化的因果架构）的效率，我们引入了两项关键进展。首先，一个鲁棒的数据增强流程，包括时间位移、空间翻转和事件删除，提高了模型的鲁棒性，在具有挑战性的样本上减少了12%的欧几里得距离误差（从1.70到1.61）。其次，我们提出了KnightPupil，一个结合EfficientNet-B3骨干网络用于空间特征提取、双向GRU用于上下文时序建模和线性时变状态空间模块以动态适应稀疏输入和噪声的混合架构。在CVPR 2025的3ET+基准测试中评估，我们的框架在事件驱动的眼睛跟踪挑战的私有测试集上实现了1.61的欧几里得距离，证明了其在AR/VR系统中的实际部署有效性，并为神经形态视觉的未来创新提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event-based eye tracking has become a pivotal technology for augmentedreality and human-computer interaction. Yet, existing methods struggle withreal-world challenges such as abrupt eye movements and environmental noise.Building on the efficiency of the Lightweight Spatiotemporal Network-a causalarchitecture optimized for edge devices-we introduce two key advancements.First, a robust data augmentation pipeline incorporating temporal shift,spatial flip, and event deletion improves model resilience, reducing Euclideandistance error by 12% (1.61 vs. 1.70 baseline) on challenging samples. Second,we propose KnightPupil, a hybrid architecture combining an EfficientNet-B3backbone for spatial feature extraction, a bidirectional GRU for contextualtemporal modeling, and a Linear Time-Varying State-Space Module to adapt tosparse inputs and noise dynamically. Evaluated on the 3ET+ benchmark, ourframework achieved 1.61 Euclidean distance on the private test set of theEvent-based Eye Tracking Challenge at CVPR 2025, demonstrating itseffectiveness for practical deployment in AR/VR systems while providing afoundation for future innovations in neuromorphic vision.</description>
      <author>example@mail.com (Hoang M. Truong, Vinh-Thuan Ly, Huy G. Tran, Thuan-Phat Nguyen, Tram T. Doan)</author>
      <guid isPermaLink="false">2504.09960v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Object Grounding via Hierarchical Contrastive Siamese Transformers</title>
      <link>http://arxiv.org/abs/2504.10048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为H-COST的算法，用于在3D场景中根据自然语言输入定位多个对象，通过对比增强Siamese Transformer框架增强了模型对复杂点云数据的处理能力。&lt;h4&gt;背景&lt;/h4&gt;以往的多对象定位研究主要集中在单对象定位上，而现实场景中往往需要定位多个对象。&lt;h4&gt;目的&lt;/h4&gt;解决多对象定位的挑战，提高复杂语言指令的理解能力。&lt;h4&gt;方法&lt;/h4&gt;采用分层处理策略，逐步细化对象定位。引入对比增强Siamese Transformer框架，其中一个辅助网络处理来自真实标签的稳健对象关系，指导并增强第二个网络（参考网络），该网络处理分割的点云数据。&lt;h4&gt;主要发现&lt;/h4&gt;H-COST算法在多对象定位基准测试中比现有最先进的方法提升了9.5%。&lt;h4&gt;结论&lt;/h4&gt;H-COST算法在处理复杂点云数据和多对象定位方面表现出色，为解决现实世界中的多对象定位问题提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-object grounding in 3D scenes involves localizing multiple objectsbased on natural language input. While previous work has primarily focused onsingle-object grounding, real-world scenarios often demand the localization ofseveral objects. To tackle this challenge, we propose Hierarchical ContrastiveSiamese Transformers (H-COST), which employs a Hierarchical Processing strategyto progressively refine object localization, enhancing the understanding ofcomplex language instructions. Additionally, we introduce a Contrastive SiameseTransformer framework, where two networks with the identical structure areused: one auxiliary network processes robust object relations from ground-truthlabels to guide and enhance the second network, the reference network, whichoperates on segmented point-cloud data. This contrastive mechanism strengthensthe model' s semantic understanding and significantly enhances its ability toprocess complex point-cloud data. Our approach outperforms previousstate-of-the-art methods by 9.5% on challenging multi-object groundingbenchmarks.</description>
      <author>example@mail.com (Chengyi Du, Keyan Jin)</author>
      <guid isPermaLink="false">2504.10048v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>TinyLLaVA-Video-R1: Towards Smaller LMMs for Video Reasoning</title>
      <link>http://arxiv.org/abs/2504.09641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TinyLLaVA-Video-R1，一个小型视频推理模型，它通过强化学习在通用视频问答数据集上提高了推理能力，并展示了“啊哈时刻”的涌现特性。&lt;h4&gt;背景&lt;/h4&gt;目前，通过强化学习提高大型多模态模型推理能力的研究取得了进展，但这些研究大多基于高度推理密集型数据集，并使用大规模模型作为基础。&lt;h4&gt;目的&lt;/h4&gt;提出探索小型模型推理能力的重要性，并使模型能够在通用问答数据集上解释其推理过程。&lt;h4&gt;方法&lt;/h4&gt;提出TinyLLaVA-Video-R1，这是一个基于TinyLLaVA-Video的视频理解模型，该模型经过可追踪的训练，参数不超过4B，并在通用视频问答数据集上应用强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;TinyLLaVA-Video-R1在通用视频问答数据集上表现出显著的推理和思维能力提升，并展示了“啊哈时刻”的涌现特性。同时，分享了实验发现，为小型模型视频推理能力的研究提供实用见解。&lt;h4&gt;结论&lt;/h4&gt;TinyLLaVA-Video-R1证明了在小规模模型中探索推理能力的价值，并为未来研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;最近，通过强化学习提高大型多模态模型（LMMs）的推理能力取得了重大进展。然而，大多数现有工作都是基于高度推理密集型数据集，如数学和代码，研究人员通常选择大型模型作为基础。我们认为，对于计算资源有限的研究人员来说，探索小型模型的推理能力仍然具有价值。此外，使模型能够在通用问答数据集上解释其推理过程同样有意义。因此，我们提出了小型视频推理模型TinyLLaVA-Video-R1。基于TinyLLaVA-Video，这是一个参数不超过4B的可追踪训练视频理解模型，它不仅在使用强化学习后显著提高了在通用视频问答数据集上的推理和思维能力，还表现出“啊哈时刻”的涌现特性。此外，我们分享了一系列实验发现，旨在为未来探索小型模型视频推理（思考）能力提供实用见解。该模型可在https://github.com/ZhangXJ199/TinyLLaVA-Video-R1上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, improving the reasoning ability of large multimodal models (LMMs)through reinforcement learning has made great progress. However, most existingworks are based on highly reasoning-intensive datasets such as mathematics andcode, and researchers generally choose large-scale models as the foundation. Weargue that exploring small-scale models' reasoning capabilities remainsvaluable for researchers with limited computational resources. Moreover,enabling models to explain their reasoning processes on generalquestion-answering datasets is equally meaningful. Therefore, we present thesmall-scale video reasoning model TinyLLaVA-Video-R1. Based on TinyLLaVA-Video,a traceably trained video understanding model with no more than 4B parameters,it not only demonstrates significantly improved reasoning and thinkingcapabilities after using reinforcement learning on general Video-QA datasets,but also exhibits the emergent characteristic of "aha moments". Furthermore, weshare a series of experimental findings, aiming to provide practical insightsfor future exploration of video reasoning (thinking) abilities in small-scalemodels. It is available at https://github.com/ZhangXJ199/TinyLLaVA-Video-R1.</description>
      <author>example@mail.com (Xingjian Zhang, Siwei Wen, Wenjun Wu, Lei Huang)</author>
      <guid isPermaLink="false">2504.09641v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>AimTS: Augmented Series and Image Contrastive Learning for Time Series Classification</title>
      <link>http://arxiv.org/abs/2504.09993v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AimTS的预训练框架，用于时间序列分类任务，旨在解决现有方法在训练数据不足时准确率下降的问题。&lt;h4&gt;背景&lt;/h4&gt;现有时间序列分类方法主要在单一领域分别训练，当某些领域的训练样本不足时，准确性会下降。&lt;h4&gt;目的&lt;/h4&gt;提出AimTS框架，通过多源时间序列数据学习可泛化的表示，以提高时间序列分类的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;AimTS采用基于原型的高层对比学习方法，结合多种数据增强策略进行多源预训练。同时，引入图像模态补充结构信息，建立序列-图像对比学习，以增强泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AimTS在多源预训练后，在各种下游时间序列分类数据集上实现了良好的泛化性能，支持高效学习和少量样本学习。&lt;h4&gt;结论&lt;/h4&gt;AimTS是一种有效的时间序列分类预训练框架，能够提高模型在不同领域的泛化能力，适用于各种时间序列分类任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series classification (TSC) is an important task in time seriesanalysis. Existing TSC methods mainly train on each single domain separately,suffering from a degradation in accuracy when the samples for training areinsufficient in certain domains. The pre-training and fine-tuning paradigmprovides a promising direction for solving this problem. However, time seriesfrom different domains are substantially divergent, which challenges theeffective pre-training on multi-source data and the generalization ability ofpre-trained models. To handle this issue, we introduce Augmented Series andImage Contrastive Learning for Time Series Classification (AimTS), apre-training framework that learns generalizable representations frommulti-source time series data. We propose a two-level prototype-basedcontrastive learning method to effectively utilize various augmentations inmulti-source pre-training, which learns representations for TSC that can begeneralized to different domains. In addition, considering augmentations withinthe single time series modality are insufficient to fully addressclassification problems with distribution shift, we introduce the imagemodality to supplement structural information and establish a series-imagecontrastive learning to improve the generalization of the learnedrepresentations for TSC tasks. Extensive experiments show that aftermulti-source pre-training, AimTS achieves good generalization performance,enabling efficient learning and even few-shot learning on various downstreamTSC datasets.</description>
      <author>example@mail.com (Yuxuan Chen, Shanshan Huang, Yunyao Cheng, Peng Chen, Zhongwen Rao, Yang Shu, Bin Yang, Lujia Pan, Chenjuan Guo)</author>
      <guid isPermaLink="false">2504.09993v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Zero-shot Autonomous Microscopy for Scalable and Intelligent Characterization of 2D Materials</title>
      <link>http://arxiv.org/abs/2504.10281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为ATOMIC的自动实验系统，用于二维材料的自主表征，通过集成多种模型和算法，实现了无需额外训练的自动分析和图像识别。&lt;h4&gt;背景&lt;/h4&gt;原子尺度材料的表征通常需要经过长时间专业培训的专家，对于新发现的二维材料，即使是经过培训的专家也难以准确表征。&lt;h4&gt;目的&lt;/h4&gt;开发一个无需大量训练数据集即可理解研究目标的全自动实验系统，以实现二维材料的零样本自主表征。&lt;h4&gt;方法&lt;/h4&gt;ATOMIC系统集成了视觉基础模型（如Segment Anything Model）、大型语言模型（如ChatGPT）、无监督聚类和拓扑分析，通过提示工程自动化显微镜控制、样品扫描、图像分割和智能分析。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在分析典型MoS2样品时，实现了99.7%的单层识别准确率，并能检测到人眼难以识别的晶界裂缝。此外，系统在各种条件下仍保持稳健的准确性。&lt;h4&gt;结论&lt;/h4&gt;ATOMIC系统通过集成基础模型实现了自主分析，建立了一种可扩展且数据高效的表征范式，从根本上改变了纳米尺度材料研究的方法。&lt;h4&gt;翻译&lt;/h4&gt;Characterization of atomic-scale materials traditionally requires humanexperts with months to years of specialized training. Even for trained humanoperators, accurate and reliable characterization remains challenging when examining newly discovered materials such as two-dimensional (2D) structures. This bottleneck drives demand for fully autonomous experimentation systems capable of comprehending research objectives without requiring large training datasets. In this work, we present ATOMIC (Autonomous Technology for Optical Microscopy &amp; Intelligent Characterization), an end-to-end framework that integrates foundation models to enable fully autonomous, zero-shot characterization of 2D materials. Our system integrates the vision foundation model (i.e., Segment Anything Model), large language models (i.e., ChatGPT), unsupervised clustering, and topological analysis to automate microscope control, sample scanning, image segmentation, and intelligent analysis through prompt engineering, eliminating the need for additional training. When analyzing typical MoS2 samples, our approach achieves 99.7% segmentation accuracy for single layer identification, which is equivalent to that of humanexperts. In addition, the integrated model is able to detect grain boundary slits that are challenging to identify with human eyes. Furthermore, the system retains robust accuracy despite variable conditions including defocus, color temperature fluctuations, and exposure variations. It is applicable to a broadspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardlessof whether they were fabricated via chemical vapor deposition or mechanical exfoliation. This work represents the implementation of foundation models to achieve autonomous analysis, establishing a scalable and data-efficient characterization paradigm that fundamentally transforms the approach to nanoscale materials research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Characterization of atomic-scale materials traditionally requires humanexperts with months to years of specialized training. Even for trained humanoperators, accurate and reliable characterization remains challenging whenexamining newly discovered materials such as two-dimensional (2D) structures.This bottleneck drives demand for fully autonomous experimentation systemscapable of comprehending research objectives without requiring large trainingdatasets. In this work, we present ATOMIC (Autonomous Technology for OpticalMicroscopy &amp; Intelligent Characterization), an end-to-end framework thatintegrates foundation models to enable fully autonomous, zero-shotcharacterization of 2D materials. Our system integrates the vision foundationmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),unsupervised clustering, and topological analysis to automate microscopecontrol, sample scanning, image segmentation, and intelligent analysis throughprompt engineering, eliminating the need for additional training. Whenanalyzing typical MoS2 samples, our approach achieves 99.7% segmentationaccuracy for single layer identification, which is equivalent to that of humanexperts. In addition, the integrated model is able to detect grain boundaryslits that are challenging to identify with human eyes. Furthermore, the systemretains robust accuracy despite variable conditions including defocus, colortemperature fluctuations, and exposure variations. It is applicable to a broadspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardlessof whether they were fabricated via chemical vapor deposition or mechanicalexfoliation. This work represents the implementation of foundation models toachieve autonomous analysis, establishing a scalable and data-efficientcharacterization paradigm that fundamentally transforms the approach tonanoscale materials research.</description>
      <author>example@mail.com (Jingyun Yang, Ruoyan Avery Yin, Chi Jiang, Yuepeng Hu, Xiaokai Zhu, Xingjian Hu, Sutharsika Kumar, Xiao Wang, Xiaohua Zhai, Keran Rong, Yunyue Zhu, Tianyi Zhang, Zongyou Yin, Jing Kong, Neil Zhenqiang Gong, Zhichu Ren, Haozhe Wang)</author>
      <guid isPermaLink="false">2504.10281v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Progressive Transfer Learning for Multi-Pass Fundus Image Restoration</title>
      <link>http://arxiv.org/abs/2504.10025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 12 figures including appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于渐进式迁移学习（PTL）的多次迭代图像质量恢复方法，用于改善糖尿病视网膜病变（DR）图像的质量，以支持更可靠的DR筛查。&lt;h4&gt;背景&lt;/h4&gt;糖尿病视网膜病变是导致视力障碍的主要原因之一，早期通过眼底成像进行诊断对于有效治疗规划至关重要。然而，由于照明不足、噪声、模糊和其他运动伪影等因素，眼底图像质量差给DR筛查带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过PTL方法迭代增强退化眼底图像的质量，确保更可靠的DR筛查。&lt;h4&gt;方法&lt;/h4&gt;研究首先训练一个Cycle GAN模型来恢复低质量图像，然后通过PTL方法在最新恢复的输出上进行多次迭代恢复，以提高每次迭代的整体质量。该方法能够在不需要任何配对数据的情况下学习盲恢复，并通过利用渐进学习和微调策略来最小化失真并保留关键视网膜特征。&lt;h4&gt;主要发现&lt;/h4&gt;在DeepDRiD大型眼底成像数据集上进行的实验表明，PTL在多次迭代图像质量恢复方面具有最先进的性能，表明PTL是一种优于迭代图像质量恢复的先进方法。&lt;h4&gt;结论&lt;/h4&gt;PTL方法在多遍修复方面表现出色，有望成为迭代图像质量恢复的优选方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diabetic retinopathy is a leading cause of vision impairment, making itsearly diagnosis through fundus imaging critical for effective treatmentplanning. However, the presence of poor quality fundus images caused by factorssuch as inadequate illumination, noise, blurring and other motion artifactsyields a significant challenge for accurate DR screening. In this study, wepropose progressive transfer learning for multi pass restoration to iterativelyenhance the quality of degraded fundus images, ensuring more reliable DRscreening. Unlike previous methods that often focus on a single passrestoration, multi pass restoration via PTL can achieve a superior blindrestoration performance that can even improve most of the good quality fundusimages in the dataset. Initially, a Cycle GAN model is trained to restore lowquality images, followed by PTL induced restoration passes over the latestrestored outputs to improve overall quality in each pass. The proposed methodcan learn blind restoration without requiring any paired data while surpassingits limitations by leveraging progressive learning and fine tuning strategiesto minimize distortions and preserve critical retinal features. To evaluatePTL's effectiveness on multi pass restoration, we conducted experiments onDeepDRiD, a large scale fundus imaging dataset specifically curated fordiabetic retinopathy detection. Our result demonstrates state of the artperformance, showcasing PTL's potential as a superior approach to iterativeimage quality restoration.</description>
      <author>example@mail.com (Uyen Phan, Ozer Can Devecioglu, Serkan Kiranyaz, Moncef Gabbouj)</author>
      <guid isPermaLink="false">2504.10025v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence</title>
      <link>http://arxiv.org/abs/2504.09862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Radar-LLM的框架，利用大型语言模型（LLM）通过毫米波雷达进行人体运动理解，解决了毫米波雷达在语义理解上的挑战。&lt;h4&gt;背景&lt;/h4&gt;毫米波雷达在人体运动分析中提供隐私保护解决方案，但其稀疏点云对语义理解构成挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用毫米波雷达进行人体运动理解的方法，并实现隐私敏感应用中的运动理解。&lt;h4&gt;方法&lt;/h4&gt;1. 引入一个基于Aggregate VQ-VAE架构的运动引导雷达标记器，将时空点云编码为紧凑的语义标记；2. 建立雷达感知语言模型，在共享嵌入空间中实现雷达和文本之间的跨模态对齐；3. 提出一种基于物理感知的合成管道，从运动文本数据集中生成真实的雷达文本对。&lt;h4&gt;主要发现&lt;/h4&gt;Radar-LLM在合成和真实世界基准测试中实现了最先进的性能，能够将毫米波信号准确翻译成自然语言描述。&lt;h4&gt;结论&lt;/h4&gt;这一突破促进了在医疗保健和智能家居等隐私敏感应用中的全面运动理解。&lt;h4&gt;翻译&lt;/h4&gt;该框架能够将毫米波雷达信号转换为自然语言描述，为隐私敏感应用提供了有效的运动理解解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Millimeter-wave radar provides a privacy-preserving solution for human motionanalysis, yet its sparse point clouds pose significant challenges for semanticunderstanding. We present Radar-LLM, the first framework that leverages largelanguage models (LLMs) for human motion understanding using millimeter-waveradar as the sensing modality. Our approach introduces two key innovations: (1)a motion-guided radar tokenizer based on our Aggregate VQ-VAE architecture thatincorporates deformable body templates and masked trajectory modeling to encodespatiotemporal point clouds into compact semantic tokens, and (2) a radar-awarelanguage model that establishes cross-modal alignment between radar and text ina shared embedding space. To address data scarcity, we introduce aphysics-aware synthesis pipeline that generates realistic radar-text pairs frommotion-text datasets. Extensive experiments demonstrate that Radar-LLM achievesstate-of-the-art performance across both synthetic and real-world benchmarks,enabling accurate translation of millimeter-wave signals to natural languagedescriptions. This breakthrough facilitates comprehensive motion understandingin privacy-sensitive applications like healthcare and smart homes. We willrelease the full implementation to support further research onhttps://inowlzy.github.io/RadarLLM/.</description>
      <author>example@mail.com (Zengyuan Lai, Jiarui Yang, Songpengcheng Xia, Lizhou Lin, Lan Sun, Renwen Wang, Jianran Liu, Qi Wu, Ling Pei)</author>
      <guid isPermaLink="false">2504.09862v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Beamform for Cooperative Localization and Communication: A Link Heterogeneous GNN-Based Approach</title>
      <link>http://arxiv.org/abs/2504.10060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于协同感知通信（CoISAC）系统联合波束成形的方法，旨在解决CoISAC波束成形设计中的挑战。&lt;h4&gt;背景&lt;/h4&gt;集成感知和通信（ISAC）是下一代无线网络的关键使能技术，支持高精度定位和环境重建等高级应用。协同ISAC（CoISAC）通过多个基站联合优化通信和感知性能来进一步增强这些能力。&lt;h4&gt;目的&lt;/h4&gt;针对CoISAC波束成形设计面临的系统异质性、大规模问题复杂性和对参数估计误差的敏感性等挑战，提出了一种新的解决方案。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种链路异构图神经网络（LHGNN）用于CoISAC系统的联合波束成形。LHGNN将通信和感知链路建模为异构节点，并将它们的交互建模为边，以捕捉CoISAC系统的异质性和复杂交互。此外，还引入了图注意力机制，以动态调整节点和链路的重要性，提高对信道和位置估计误差的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;数值结果表明，所提出的注意力增强的LHGNN在保持感知准确性的同时，在功率约束下实现了更高的通信速率，并且对通信信道和位置估计误差具有强鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有效地解决了CoISAC波束成形设计中的挑战，为CoISAC系统的性能提升提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：集成感知与通信（ISAC）已成为下一代无线网络的关键推动力，支持高精度定位和环境重建等高级应用。协同ISAC（CoISAC）通过多个基站协同优化通信和感知性能进一步增强了这些能力。然而，CoISAC波束成形设计面临着系统异质性、大规模问题复杂性和对参数估计误差敏感性的重大挑战。传统的基于深度学习的技术未能充分利用CoISAC系统的独特结构特性，从而限制了其增强系统性能的能力。为了解决这些挑战，我们提出了一种用于CoISAC系统联合波束成形的方法——链路异构图神经网络（LHGNN）。与传统的方案不同，LHGNN将通信和感知链路建模为异构节点，并将它们的交互建模为边，从而能够捕捉CoISAC系统的异质性和复杂交互。此外，还引入了图注意力机制，以动态调整节点和链路的重要性，提高对信道和位置估计误差的鲁棒性。数值结果证明了所提出的注意力增强的LHGNN在保持感知准确性的同时，在功率约束下实现了更高的通信速率，并且对通信信道和位置估计误差具有强鲁棒性。所提出的方法也表现出对通信信道和位置估计误差的强鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrated sensing and communication (ISAC) has emerged as a key enabler fornext-generation wireless networks, supporting advanced applications such ashigh-precision localization and environment reconstruction. Cooperative ISAC(CoISAC) further enhances these capabilities by enabling multiple base stations(BSs) to jointly optimize communication and sensing performance throughcoordination. However, CoISAC beamforming design faces significant challengesdue to system heterogeneity, large-scale problem complexity, and sensitivity toparameter estimation errors. Traditional deep learning-based techniques fail toexploit the unique structural characteristics of CoISAC systems, therebylimiting their ability to enhance system performance. To address thesechallenges, we propose a Link-Heterogeneous Graph Neural Network (LHGNN) forjoint beamforming in CoISAC systems. Unlike conventional approaches, LHGNNmodels communication and sensing links as heterogeneous nodes and theirinteractions as edges, enabling the capture of the heterogeneous nature andintricate interactions of CoISAC systems. Furthermore, a graph attentionmechanism is incorporated to dynamically adjust node and link importance,improving robustness to channel and position estimation errors. Numericalresults demonstrate that the proposed attention-enhanced LHGNN achievessuperior communication rates while maintaining sensing accuracy under powerconstraints. The proposed method also exhibits strong robustness tocommunication channel and position estimation error.</description>
      <author>example@mail.com (Lixiang Lian, Chuanqi Bai, Yihan Xu, Huanyu Dong, Rui Cheng, Shunqing Zhang)</author>
      <guid isPermaLink="false">2504.10060v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Masked Autoencoder Self Pre-Training for Defect Detection in Microelectronics</title>
      <link>http://arxiv.org/abs/2504.10021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了微电子缺陷检测中，由于数据和标签成本导致卷积神经网络（CNN）依然被广泛应用，而Transformer架构较少使用的问题。&lt;h4&gt;背景&lt;/h4&gt;传统上，计算机视觉领域Transformer架构成为标准，但在微电子缺陷检测领域，由于数据和标签生成成本高，导致CNN依然占据主导地位。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种基于掩码自编码器（MAE）的视觉Transformer（ViT）预训练框架，以解决微电子缺陷检测中的数据稀疏问题。&lt;h4&gt;方法&lt;/h4&gt;作者提出对目标数据集进行自预训练，使用少于10,000张扫描声学显微镜（SAM）图像，这些图像通过瞬态热分析（TTA）进行标记。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与监督ViT、在自然图像数据集上预训练的ViT以及文献中的最先进CNN缺陷检测模型相比，该方法带来了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;自预训练的模型通过聚焦于缺陷相关特征，如焊料材料中的裂纹，提供了故障特定的特征表示，表明该方法在实际微电子缺陷检测中具有可行性。&lt;h4&gt;翻译&lt;/h4&gt;While in general computer vision, transformer-based architectures have quickly become the gold standard, microelectronics defect detection still heavily relies on convolutional neural networks (CNNs). We hypothesize that this is due to the fact that a) transformers have an increased need for data and b) labelled image generation procedures for microelectronics are costly, and labelled data is therefore sparse. Whereas in other domains, pre-training on large natural image datasets can mitigate this problem, in microelectronics transfer learning is hindered due to the dissimilarity of domain data and natural images. Therefore, we evaluate self pre-training, where models are pre-trained on the target dataset, rather than another dataset. We propose a vision transformer (ViT) pre-training framework for defect detection in microelectronics based on masked autoencoders (MAE). In MAE, a large share of image patches is masked and reconstructed by the model during pre-training. We perform pre-training and defect detection using a dataset of less than 10,000 scanning acoustic microscopy (SAM) images labelled using transient thermal analysis (TTA). Our experimental results show that our approach leads to substantial performance gains compared to a) supervised ViT, b) ViT pre-trained on natural image datasets, and c) state-of-the-art CNN-based defect detection models used in the literature. Additionally, interpretability analysis reveals that our self pre-trained models, in comparison to ViT baselines, correctly focus on defect-relevant features such as cracks in the solder material. This demonstrates that our approach yields fault-specific feature representations, making our self pre-trained models viable for real-world defect detection in microelectronics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Whereas in general computer vision, transformer-based architectures havequickly become the gold standard, microelectronics defect detection stillheavily relies on convolutional neural networks (CNNs). We hypothesize thatthis is due to the fact that a) transformers have an increased need for dataand b) labelled image generation procedures for microelectronics are costly,and labelled data is therefore sparse. Whereas in other domains, pre-trainingon large natural image datasets can mitigate this problem, in microelectronicstransfer learning is hindered due to the dissimilarity of domain data andnatural images. Therefore, we evaluate self pre-training, where models arepre-trained on the target dataset, rather than another dataset. We propose avision transformer (ViT) pre-training framework for defect detection inmicroelectronics based on masked autoencoders (MAE). In MAE, a large share ofimage patches is masked and reconstructed by the model during pre-training. Weperform pre-training and defect detection using a dataset of less than 10.000scanning acoustic microscopy (SAM) images labelled using transient thermalanalysis (TTA). Our experimental results show that our approach leads tosubstantial performance gains compared to a) supervised ViT, b) ViT pre-trainedon natural image datasets, and c) state-of-the-art CNN-based defect detectionmodels used in the literature. Additionally, interpretability analysis revealsthat our self pre-trained models, in comparison to ViT baselines, correctlyfocus on defect-relevant features such as cracks in the solder material. Thisdemonstrates that our approach yields fault-specific feature representations,making our self pre-trained models viable for real-world defect detection inmicroelectronics.</description>
      <author>example@mail.com (Nikolai Röhrich, Alwin Hoffmann, Richard Nordsieck, Emilio Zarbali, Alireza Javanmardi)</author>
      <guid isPermaLink="false">2504.10021v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Transformer-Based Representation Learning for Robust Gene Expression Modeling and Cancer Prognosis</title>
      <link>http://arxiv.org/abs/2504.09704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GexBERT是一种基于Transformer的自动编码器框架，用于基因表达数据的鲁棒性表示学习，在癌症研究中表现出色。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型在自然语言和视觉任务中取得成功，但在基因表达分析中的应用受到数据稀疏性、高维度和缺失值的影响。&lt;h4&gt;目的&lt;/h4&gt;提出GexBERT，以解决基因表达数据分析中的挑战，并提高其在癌症研究中的应用。&lt;h4&gt;方法&lt;/h4&gt;GexBERT通过在大规模转录组图谱上进行预训练，学习上下文感知的基因嵌入，并使用掩码和恢复目标来捕捉数千个基因之间的共表达关系。&lt;h4&gt;主要发现&lt;/h4&gt;GexBERT在癌症研究中三个关键任务上表现出色：泛癌症分类、癌症特异性生存预测和缺失值填补。它提高了分类准确率，改善了生存预测，并在高缺失率下优于传统填补方法。此外，其基于注意力的可解释性揭示了具有生物学意义的基因模式。&lt;h4&gt;结论&lt;/h4&gt;GexBERT是一个可扩展且有效的基因表达建模工具，在基因覆盖有限或不完整的环境中具有转化潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based models have achieved remarkable success in natural languageand vision tasks, but their application to gene expression analysis remainslimited due to data sparsity, high dimensionality, and missing values. Wepresent GexBERT, a transformer-based autoencoder framework for robustrepresentation learning of gene expression data. GexBERT learns context-awaregene embeddings by pretraining on large-scale transcriptomic profiles with amasking and restoration objective that captures co-expression relationshipsamong thousands of genes. We evaluate GexBERT across three critical tasks incancer research: pan-cancer classification, cancer-specific survivalprediction, and missing value imputation. GexBERT achieves state-of-the-artclassification accuracy from limited gene subsets, improves survival predictionby restoring expression of prognostic anchor genes, and outperformsconventional imputation methods under high missingness. Furthermore, itsattention-based interpretability reveals biologically meaningful gene patternsacross cancer types. These findings demonstrate the utility of GexBERT as ascalable and effective tool for gene expression modeling, with translationalpotential in settings where gene coverage is limited or incomplete.</description>
      <author>example@mail.com (Shuai Jiang, Saeed Hassanpour)</author>
      <guid isPermaLink="false">2504.09704v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>EthCluster: An Unsupervised Static Analysis Method for Ethereum Smart Contract</title>
      <link>http://arxiv.org/abs/2504.09977v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了智能合约的设计问题，提出了一种利用无监督学习来识别以太坊智能合约Solidity源代码中的漏洞的方法。&lt;h4&gt;背景&lt;/h4&gt;设计不当的智能合约容易受到攻击，可能被攻击者利用漏洞窃取管理的虚拟货币。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来检测智能合约中的特定漏洞。&lt;h4&gt;方法&lt;/h4&gt;使用无监督学习训练模型，从实际漏洞样本中获取数据，包括SmartBugs Curated和SolidiFI Benchmark数据集，用于开发一种健壮的无监督静态分析方法。该方法使用聚类算法来识别异常，随后将这些异常分类为有漏洞的智能合约。&lt;h4&gt;主要发现&lt;/h4&gt;检测到了五种特定漏洞：重入性、访问控制、时间戳依赖、tx.origin和未检查的低级别调用。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法，可以有效地识别和分类有漏洞的智能合约。&lt;h4&gt;翻译&lt;/h4&gt;Poorly designed smart contracts are particularly vulnerable, as they may allow attackers to exploit weaknesses and steal the virtual currency they manage. In this study, we train a model using unsupervised learning to identify vulnerabilities in the Solidity source code of Ethereum smart contracts. To address the challenges associated with real-world smart contracts, our training data is derived from actual vulnerability samples obtained from datasets such as SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us to develop a robust unsupervised static analysis method for detecting five specific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency, tx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms to identify outliers, which are subsequently classified as vulnerable smart contracts.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Poorly designed smart contracts are particularly vulnerable, as they mayallow attackers to exploit weaknesses and steal the virtual currency theymanage. In this study, we train a model using unsupervised learning to identifyvulnerabilities in the Solidity source code of Ethereum smart contracts. Toaddress the challenges associated with real-world smart contracts, our trainingdata is derived from actual vulnerability samples obtained from datasets suchas SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us todevelop a robust unsupervised static analysis method for detecting fivespecific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency,tx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms toidentify outliers, which are subsequently classified as vulnerable smartcontracts.</description>
      <author>example@mail.com (Hong-Sheng Huang, Jen-Yi Ho, Hao-Wen Chen, Hung-Min Sun)</author>
      <guid isPermaLink="false">2504.09977v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>VideoAds for Fast-Paced Video Understanding: Where Opensource Foundation Models Beat GPT-4o &amp; Gemini-1.5 Pro</title>
      <link>http://arxiv.org/abs/2504.09282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VideoAds，这是一个专门用于评估多模态大型语言模型（MLLMs）在广告视频上性能的数据集。该数据集包含经过精心挑选的广告视频和手动标注的多样化问题，涉及视觉发现、视频摘要和视觉推理三个核心任务。&lt;h4&gt;背景&lt;/h4&gt;广告视频由于其结构化的叙事和快速的场景转换，通常比同等长度的普通视频复杂得多，这对MLLMs提出了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;创建VideoAds数据集，以评估MLLMs在处理广告视频方面的性能。&lt;h4&gt;方法&lt;/h4&gt;VideoAds数据集包含复杂的广告视频和针对三个核心任务（视觉发现、视频摘要和视觉推理）的手动标注问题。还提出了一种定量方法来比较VideoAds与现有基准在视频复杂度方面的表现。&lt;h4&gt;主要发现&lt;/h4&gt;开源模型Qwen2.5-VL-72B在VideoAds上达到了73.35%的准确率，超过了GPT-4o（66.82%）和Gemini-1.5 Pro（69.66%）。在视频摘要和推理方面，两个专有模型落后于开源模型，但在视觉发现方面表现最佳。人类专家的准确率达到了94.27%。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，提高MLLMs的时间建模能力是必要的，并且VideoAds数据集可能成为未来研究理解需要高FPS采样的视频的关键基准。&lt;h4&gt;翻译&lt;/h4&gt;本文提出VideoAds数据集，旨在评估多模态大型语言模型在广告视频上的性能。数据集包含复杂广告视频和针对视觉发现、视频摘要和视觉推理的手动标注问题。实验发现，开源模型Qwen2.5-VL-72B在VideoAds上表现最佳，而人类专家的准确率高达94.27%。这强调了提升MLLMs时间建模能力的重要性，并指出VideoAds数据集作为理解高FPS采样视频的关键基准的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advertisement videos serve as a rich and valuable source of purpose-driveninformation, encompassing high-quality visual, textual, and contextual cuesdesigned to engage viewers. They are often more complex than general videos ofsimilar duration due to their structured narratives and rapid scenetransitions, posing significant challenges to multi-modal large language models(MLLMs). In this work, we introduce VideoAds, the first dataset tailored forbenchmarking the performance of MLLMs on advertisement videos. VideoAdscomprises well-curated advertisement videos with complex temporal structures,accompanied by \textbf{manually} annotated diverse questions across three coretasks: visual finding, video summary, and visual reasoning. We propose aquantitative measure to compare VideoAds against existing benchmarks in termsof video complexity. Through extensive experiments, we find thatQwen2.5-VL-72B, an opensource MLLM, achieves 73.35\% accuracy on VideoAds,outperforming GPT-4o (66.82\%) and Gemini-1.5 Pro (69.66\%); the twoproprietary models especially fall behind the opensource model in videosummarization and reasoning, but perform the best in visual finding. Notably,human experts easily achieve a remarkable accuracy of 94.27\%. These resultsunderscore the necessity of advancing MLLMs' temporal modeling capabilities andhighlight VideoAds as a potentially pivotal benchmark for future research inunderstanding video that requires high FPS sampling. The dataset and evaluationcode will be publicly available at https://videoadsbenchmark.netlify.app.</description>
      <author>example@mail.com (Zheyuan Zhang, Monica Dou, Linkai Peng, Hongyi Pan, Ulas Bagci, Boqing Gong)</author>
      <guid isPermaLink="false">2504.09282v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>IsoSEL: Isometric Structural Entropy Learning for Deep Graph Clustering in Hyperbolic Space</title>
      <link>http://arxiv.org/abs/2504.09970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to IEEE TPAMI, 33 pages, including technical appendix of 16  pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于信息理论的深度图聚类方法，旨在解决传统方法在处理不平衡图和识别少数群体时的局限性。&lt;h4&gt;背景&lt;/h4&gt;图聚类是机器学习中的一个长期研究主题。尽管深度学习方法在近年来取得了令人鼓舞的结果，但它们通常需要预先定义的聚类数量K，并且在处理不平衡图时，特别是在识别少数群体方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;研究一个既具有挑战性又实用的深度图聚类问题，即在不考虑现实中的不平衡性的情况下，不使用K值进行图聚类。&lt;h4&gt;方法&lt;/h4&gt;从信息理论的新视角（即结构信息）来解决这个问题。首先，建立了一种新的可微结构信息，将离散形式主义推广到连续领域，以便通过梯度反向传播创建最佳的分区树，揭示聚类结构。随后，提出了一种名为IsoSEL的深度图聚类框架，设计了一种双曲神经网络来学习双曲空间洛伦兹模型中的分区树，并进一步进行了洛伦兹树对比学习，同时使用等距增强。&lt;h4&gt;主要发现&lt;/h4&gt;该方法理论上证明了其在不要求K值的情况下进行聚类的能力，并在不平衡图中识别少数群体，同时将时间复杂度降低到与节点数量O(N)相关。&lt;h4&gt;结论&lt;/h4&gt;在五个基准数据集上的大量实验表明，IsoSEL的平均NMI（归一化互信息）比14个最近的基线高出+1.3%，证明了该方法的优越性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图聚类是机器学习中的一个长期研究主题。近年来，深度学习方法取得了令人鼓舞的结果，但它们仍然需要预先定义的聚类数量K，并且通常在处理不平衡图时遇到困难，特别是在识别少数群体方面。这些局限性促使我们研究一个既具有挑战性又实用的难题：在不考虑现实中的不平衡性的情况下，不使用K值的深度图聚类。我们从信息理论（即结构信息）的新视角来解决这个问题。在文献中，结构信息在深度聚类中很少被触及，经典定义在离散形式主义中存在不足，忽略了节点属性，并表现出难以承受的复杂性。在本文中，我们首先建立了一种新的可微结构信息，将离散形式主义推广到连续领域，以便通过梯度反向传播创建最佳的分区树，揭示聚类结构。从理论上讲，我们证明了其在不要求K值的情况下进行聚类的能力，并在不平衡图中识别少数群体，同时将时间复杂度降低到与节点数量O(N)相关。随后，我们提出了一种名为IsoSEL的深度图聚类框架，其中我们设计了一种双曲神经网络来学习双曲空间洛伦兹模型中的分区树，并进一步进行了洛伦兹树对比学习，同时使用等距增强。结果，分区树通过互信息最大化结合了节点属性，而聚类分配则通过所提出的树对比学习得到细化。在五个基准数据集上的大量实验表明，IsoSEL的平均NMI比14个最近的基线高出+1.3%，证明了该方法的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph clustering is a longstanding topic in machine learning. In recentyears, deep learning methods have achieved encouraging results, but they stillrequire predefined cluster numbers K, and typically struggle with imbalancedgraphs, especially in identifying minority clusters. The limitations motivateus to study a challenging yet practical problem: deep graph clustering withoutK considering the imbalance in reality. We approach this problem from a freshperspective of information theory (i.e., structural information). In theliterature, structural information has rarely been touched in deep clustering,and the classic definition falls short in its discrete formulation, neglectingnode attributes and exhibiting prohibitive complexity. In this paper, we firstestablish a new Differentiable Structural Information, generalizing thediscrete formalism to continuous realm, so that the optimal partitioning tree,revealing the cluster structure, can be created by the gradientbackpropagation. Theoretically, we demonstrate its capability in clusteringwithout requiring K and identifying the minority clusters in imbalanced graphs,while reducing the time complexity to O(N) w.r.t. the number of nodes.Subsequently, we present a novel IsoSEL framework for deep graph clustering,where we design a hyperbolic neural network to learn the partitioning tree inthe Lorentz model of hyperbolic space, and further conduct Lorentz TreeContrastive Learning with isometric augmentation. As a result, the partitioningtree incorporates node attributes via mutual information maximization, whilethe cluster assignment is refined by the proposed tree contrastive learning.Extensive experiments on five benchmark datasets show the IsoSEL outperforms 14recent baselines by an average of +1.3% in NMI.</description>
      <author>example@mail.com (Li Sun, Zhenhao Huang, Yujie Wang, Hongbo Lv, Chunyang Liu, Hao Peng, Philip S. Yu)</author>
      <guid isPermaLink="false">2504.09970v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data</title>
      <link>http://arxiv.org/abs/2504.09967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为IMAX的图像中心多标注X射线数据集，旨在通过数据构建层面增强医疗多模态大型语言模型的多任务学习能力。&lt;h4&gt;背景&lt;/h4&gt;医疗通用基础模型的出现改变了传统的特定任务模型开发范式，但近期进展过于强调简单数据扩展或架构组件增强，而忽视了从数据中心的视角重新审视多任务学习。&lt;h4&gt;目的&lt;/h4&gt;提出IMAX数据集，旨在提升医疗多模态大型语言模型的多任务学习能力。&lt;h4&gt;方法&lt;/h4&gt;IMAX具有高质量的数据整理，包含超过354K条适用于多种医疗任务的数据条目。每个X射线图像都与平均4.10个任务和7.46个训练条目相关联。与DMAX相比，IMAX在七个开源最先进的医疗MLLMs上展现出显著的性能提升。同时，研究了IMAX和DMAX训练过程中的统计模式差异，探讨了优化动态与多任务性能之间的潜在相关性，并提出了基于DMAX的优化训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;IMAX在七个开源最先进的医疗MLLMs上展现了3.20%到21.05%的显著多任务平均性能提升。IMAX和DMAX训练过程中表现出不同的统计模式，优化动态与多任务性能之间存在潜在相关性。&lt;h4&gt;结论&lt;/h4&gt;IMAX数据集能够有效提升医疗多模态大型语言模型的多任务学习能力，并通过优化训练策略解决获取高质量IMAX数据的实际困境。&lt;h4&gt;翻译&lt;/h4&gt;摘要：医疗通用基础模型的出现颠覆了传统的特定任务模型开发范式，旨在通过在大规模医疗数据集上进行联合训练更好地处理多个任务。然而，近期的进展过于强调简单数据扩展或架构组件增强，而忽视了从数据中心的视角重新审视多任务学习。关键的是，简单地汇总现有数据资源会导致图像任务对齐分散，无法培养全面图像理解或与多维图像解释的临床需求相一致。在本文中，我们介绍了图像中心的多标注X射线数据集（IMAX），这是第一次从数据构建层面尝试增强医疗多模态大型语言模型（MLLMs）的多任务学习能力。具体来说，IMAX具有以下特点：1）高质量的数据整理。包含适用于七种不同医疗任务的综合数据集，超过354K条条目。2）图像中心的密集标注。每个X射线图像与平均4.10个任务和7.46个训练条目相关联，确保每张图像的多任务表示丰富性。与通用的分散多标注X射线数据集（DMAX）相比，IMAX在七个开源最先进的医疗MLLMs上始终显示出3.20%到21.05%的显著多任务平均性能提升。此外，我们研究了IMAX和DMAX训练过程中表现出的统计模式差异，探讨了优化动态与多任务性能之间的潜在相关性。最后，利用IMAX数据构建的核心概念，我们提出了一种基于DMAX的优化训练策略，以缓解在实际场景中获取高质量IMAX数据的困境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of medical generalist foundation models has revolutionizedconventional task-specific model development paradigms, aiming to better handlemultiple tasks through joint training on large-scale medical datasets. However,recent advances prioritize simple data scaling or architectural componentenhancement, while neglecting to re-examine multi-task learning from adata-centric perspective. Critically, simply aggregating existing dataresources leads to decentralized image-task alignment, which fails to cultivatecomprehensive image understanding or align with clinical needs formulti-dimensional image interpretation. In this paper, we introduce theimage-centric multi-annotation X-ray dataset (IMAX), the first attempt toenhance the multi-task learning capabilities of medical multi-modal largelanguage models (MLLMs) from the data construction level. To be specific, IMAXis featured from the following attributes: 1) High-quality data curation. Acomprehensive collection of more than 354K entries applicable to sevendifferent medical tasks. 2) Image-centric dense annotation. Each X-ray image isassociated with an average of 4.10 tasks and 7.46 training entries, ensuringmulti-task representation richness per image. Compared to the generaldecentralized multi-annotation X-ray dataset (DMAX), IMAX consistentlydemonstrates significant multi-task average performance gains ranging from3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs.Moreover, we investigate differences in statistical patterns exhibited by IMAXand DMAX training processes, exploring potential correlations betweenoptimization dynamics and multi-task performance. Finally, leveraging the coreconcept of IMAX data construction, we propose an optimized DMAX-based trainingstrategy to alleviate the dilemma of obtaining high-quality IMAX data inpractical scenarios.</description>
      <author>example@mail.com (Xun Zhu, Fanbin Mo, Zheng Zhang, Jiaxi Wang, Yiming Shi, Ming Wu, Chuang Zhang, Miao Li, Ji Wu)</author>
      <guid isPermaLink="false">2504.09967v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>3D CoCa: Contrastive Learners are 3D Captioners</title>
      <link>http://arxiv.org/abs/2504.09518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为3D CoCa的3D场景描述方法，通过结合对比视觉-语言学习和3D字幕生成，有效描述3D场景内容。&lt;h4&gt;背景&lt;/h4&gt;由于点云的稀疏性和现有方法的跨模态对齐较弱，3D场景描述在自然语言中仍然是一个高度挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的统一框架，以解决3D场景描述中的挑战。&lt;h4&gt;方法&lt;/h4&gt;3D CoCa利用冻结的CLIP视觉-语言骨干网络提供丰富的语义先验，一个空间感知的3D场景编码器来捕获几何上下文，以及一个多模态解码器来生成描述性字幕。&lt;h4&gt;主要发现&lt;/h4&gt;与依赖于显式物体提议的前两阶段方法不同，3D CoCa在共享特征空间中联合优化对比和字幕生成目标，消除了对外部检测器或手工提议的需求。这种联合训练范式通过对齐3D和文本表示，实现了更强的空间推理和更丰富的语义基础。&lt;h4&gt;结论&lt;/h4&gt;在ScanRefer和Nr3D基准测试上，3D CoCa在CIDEr指标上分别比现有最佳方法提高了10.2%和5.76%，0.5IoU。&lt;h4&gt;翻译&lt;/h4&gt;3D字幕描述，旨在用自然语言描述3D场景的内容，由于点云固有的稀疏性和现有方法中存在的弱跨模态对齐，这仍然是一个高度具有挑战性的任务。为了解决这些挑战，我们提出了一种名为3D CoCa的新颖统一框架，该框架无缝地将对比视觉-语言学习与3D字幕生成结合到一个架构中。我们的方法利用一个冻结的CLIP视觉-语言骨干网络来提供丰富的语义先验，一个空间感知的3D场景编码器来捕获几何上下文，以及一个多模态解码器来生成描述性字幕。与依赖于显式物体提议的前两阶段方法不同，3D CoCa在共享特征空间中联合优化对比和字幕生成目标，消除了对外部检测器或手工提议的需求。这种联合训练范式通过对齐3D和文本表示，实现了更强的空间推理和更丰富的语义基础。在ScanRefer和Nr3D基准测试上，3D CoCa在CIDEr指标上分别比现有最佳方法提高了10.2%和5.76%，0.5IoU。代码可在https://github.com/AIGeeksGroup/3DCoCa上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D captioning, which aims to describe the content of 3D scenes in naturallanguage, remains highly challenging due to the inherent sparsity of pointclouds and weak cross-modal alignment in existing methods. To address thesechallenges, we propose 3D CoCa, a novel unified framework that seamlesslycombines contrastive vision-language learning with 3D caption generation in asingle architecture. Our approach leverages a frozen CLIP vision-languagebackbone to provide rich semantic priors, a spatially-aware 3D scene encoder tocapture geometric context, and a multi-modal decoder to generate descriptivecaptions. Unlike prior two-stage methods that rely on explicit objectproposals, 3D CoCa jointly optimizes contrastive and captioning objectives in ashared feature space, eliminating the need for external detectors orhandcrafted proposals. This joint training paradigm yields stronger spatialreasoning and richer semantic grounding by aligning 3D and textualrepresentations. Extensive experiments on the ScanRefer and Nr3D benchmarksdemonstrate that 3D CoCa significantly outperforms current state-of-the-arts by10.2% and 5.76% in CIDEr at 0.5IoU, respectively. Code will be available athttps://github.com/AIGeeksGroup/3DCoCa.</description>
      <author>example@mail.com (Ting Huang, Zeyu Zhang, Yemin Wang, Hao Tang)</author>
      <guid isPermaLink="false">2504.09518v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>OVERLORD: Ultimate Scaling of DataLoader for Multi-Source Large Foundation Model Training</title>
      <link>http://arxiv.org/abs/2504.09844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了现代大型基础模型（LFMs）训练框架中的数据并行范式和数据加载器，分析了其面临的挑战，并提出了一种名为OVERLORD的工业级分布式数据加载架构以解决这些问题。&lt;h4&gt;背景&lt;/h4&gt;现代框架使用数据加载器进行数据并行训练，这种设计简单但存在两个基本挑战：工作负载不平衡和资源消耗问题。&lt;h4&gt;目的&lt;/h4&gt;提高大型基础模型的训练效率和资源利用率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为OVERLORD的分布式数据加载架构，包含以下三个创新点：集中式和声明式的数据平面、分角色的源加载器和数据构造者、以及具有差异检查点的影子加载器。&lt;h4&gt;主要发现&lt;/h4&gt;OVERLORD在多千GPU的生产集群上实现了以下效果：4.5倍的端到端训练吞吐量提升，CPU内存使用量至少减少了3.6倍。&lt;h4&gt;结论&lt;/h4&gt;OVERLORD是一种有效的解决方案，能够显著提升大型基础模型的训练效率和资源利用率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern frameworks for training large foundation models (LFMs) employ dataloaders in a data parallel paradigm. While this design offers implementationsimplicity, it introduces two fundamental challenges. First, due to thequadratic computational complexity of the attention operator, the non-uniformsample distribution over data-parallel ranks leads to a significant workloadimbalance among loaders, which degrades the training efficiency. This paradigmalso impedes the implementation of data mixing algorithms (e.g., curriculumlearning) over different datasets. Second, to acquire a broad range ofcapability, LFMs training ingests data from diverse sources, each with distinctfile access states. Colocating massive datasets within loader instances caneasily exceed local pod memory capacity. Additionally, heavy sources withhigher transformation latency require larger worker pools, further exacerbatingmemory consumption.  We present OVERLORD, an industrial-grade distributed data loadingarchitecture with three innovations: (1) A centralized and declarative dataplane, which facilitates elastic data orchestration strategy, such aslong-short context, multimodal, and curriculum learning; (2) Disaggregatedmultisource preprocessing through role-specific actors, i.e., Source Loadersand Data Constructors, leveraging autoscaling for Source Loaders towardsheterogeneous and evolving source preprocessing cost; (3) Shadow Loaders withdifferential checkpointing for uninterrupted fault recovery. Deployed onproduction clusters scaling to multi-thousand GPU, OVERLORD achieves: (1) 4.5xend-to-end training throughput improvement, (2) a minimum 3.6x reduction in CPUmemory usage, with further improvements to be added in later experiments.</description>
      <author>example@mail.com (Juntao Zhao, Qi Lu, Wei Jia, Borui Wan, Lei Zuo, Junda Feng, Jianyu Jiang, Yangrui Chen, Shuaishuai Cao, Jialing He, Kaihua Jiang, Yuanzhe Hu, Yanghua Peng, Haibin Lin, Xin Liu, Chuan Wu)</author>
      <guid isPermaLink="false">2504.09844v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>COUNTER: Cluster GCN based Energy Efficient Resource Management for Sustainable Cloud Computing Environments</title>
      <link>http://arxiv.org/abs/2504.09995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint version accepted at IEEE ICDCS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为COUNTER的模型，用于可持续的云资源管理，通过集成集群图神经网络在模拟云环境中评估，旨在减少能源消耗并保持服务质量参数。&lt;h4&gt;背景&lt;/h4&gt;云计算提供了灵活的IT应用开发环境，但大型数据中心因信息通信技术组件而消耗大量电力，随着大型人工智能模型的部署增加，这一问题更加严重，对全球环境产生重大影响。&lt;h4&gt;目的&lt;/h4&gt;提出COUNTER模型，旨在减少云计算中的能源消耗，同时保持服务质量。&lt;h4&gt;方法&lt;/h4&gt;COUNTER模型与集群图神经网络集成，并在模拟云环境中进行评估，与基于门控图神经网络的、旨在实现云计算碳中性的HUNTER模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与HUNTER模型相比，COUNTER模型在资源利用率、能源消耗和成本效益方面均有改进。&lt;h4&gt;结论&lt;/h4&gt;COUNTER模型为可持续的云资源管理提供了一种有效的方法，有助于减少能源消耗并提高云服务的效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：云计算，得益于信息技术的普及，为IT应用的开发提供了一个基础环境，为企业提供了几乎无限的、按使用付费的计算资源。然而，由于信息通信技术（ICT）组件，云计算服务托管的大型数据中心每年消耗大量的电力。这一问题因大型人工智能（AI）模型的增加部署而加剧，这些模型通常依赖于分布式数据中心，从而对全球环境产生重大影响。本研究提出了一种名为COUNTER的模型，旨在实现可持续的云资源管理。COUNTER与集群图神经网络集成，并在模拟云环境中进行评估，旨在在保持服务质量参数的同时减少能源消耗。实验结果表明，与基于门控图神经网络的、旨在实现云计算碳中性的HUNTER基线模型相比，COUNTER在资源利用率、能源消耗和成本效益方面均有改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cloud computing, thanks to the pervasiveness of information technologies,provides a foundational environment for developing IT applications, offeringorganizations virtually unlimited and flexible computing resources on apay-per-use basis. However, the large data centres where cloud computingservices are hosted consume significant amounts of electricity annually due toInformation and Communication Technology (ICT) components. This issue isexacerbated by the increasing deployment of large artificial intelligence (AI)models, which often rely on distributed data centres, thereby significantlyimpacting the global environment. This study proposes the COUNTER model,designed for sustainable cloud resource management. COUNTER is integrated withcluster graph neural networks and evaluated in a simulated cloud environment,aiming to reduce energy consumption while maintaining quality of serviceparameters. Experimental results demonstrate improvements in resourceutilisation, energy consumption, and cost effectiveness compared to thebaseline model, HUNTER, which employs a gated graph neural network aimed atachieving carbon neutrality in cloud computing for modern ICT systems.</description>
      <author>example@mail.com (Han Wang, Sukhpal Singh Gill, Steve Uhlig)</author>
      <guid isPermaLink="false">2504.09995v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Causal integration of chemical structures improves representations of microscopy images for morphological profiling</title>
      <link>http://arxiv.org/abs/2504.09544v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MICON（分子-图像对比学习）框架，该框架通过将化学化合物作为诱导细胞表型反事实变换的治疗方法，在自我监督预训练中提高高通量显微镜屏幕中图像的学习表示。&lt;h4&gt;背景&lt;/h4&gt;尽管许多高通量显微镜屏幕本质上是多模态的，因为它们涉及化学或遗传扰动以及基于图像的读出，但大多数当前方法仅从图像中学习。&lt;h4&gt;目的&lt;/h4&gt;研究假设在自我监督预训练期间结合化学化合物结构可以提高高通量显微镜屏幕中图像的学习表示。&lt;h4&gt;方法&lt;/h4&gt;提出了MICON框架，该框架将化学化合物建模为诱导细胞表型反事实变换的治疗方法。&lt;h4&gt;主要发现&lt;/h4&gt;MICON在识别药物在独立重复和数据生成中心之间可重复效应的挑战性评估环境中，显著优于CellProfiler和现有的基于深度学习的表示学习方法。&lt;h4&gt;结论&lt;/h4&gt;将化学化合物信息纳入学习过程可以在评估环境中提供一致的改进，并且将化合物在因果框架中特别建模为治疗方法，优于直接在单一表示空间中对齐图像和化合物的方法。这表明了形态分析中表示学习的新方向，即方法应明确考虑显微镜筛选数据的模态性质。&lt;h4&gt;翻译&lt;/h4&gt;最近，自我监督深度学习在量化高通量显微镜屏幕中的细胞形态变化（称为形态分析）方面取得了进展。然而，大多数当前方法仅从图像中学习，尽管许多屏幕本质上是多模态的，因为它们涉及化学或遗传扰动以及基于图像的读出。我们假设在自我监督预训练期间结合化学化合物结构可以提高高通量显微镜屏幕中图像的学习表示。我们引入了一个表示学习框架，MICON（分子-图像对比学习），该框架将化学化合物建模为诱导细胞表型反事实变换的治疗方法。MICON在需要识别药物在独立重复和数据生成中心之间可重复效应的挑战性评估环境中，显著优于CellProfiler和现有的基于深度学习的表示学习方法。我们证明，将化学化合物信息纳入学习过程可以在评估环境中提供一致的改进，并且将化合物在因果框架中特别建模为治疗方法，优于直接在单一表示空间中对齐图像和化合物的方法。我们的发现指向了形态分析中表示学习的新方向，表明方法应明确考虑显微镜筛选数据的模态性质。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in self-supervised deep learning have improved our ability toquantify cellular morphological changes in high-throughput microscopy screens,a process known as morphological profiling. However, most current methods onlylearn from images, despite many screens being inherently multimodal, as theyinvolve both a chemical or genetic perturbation as well as an image-basedreadout. We hypothesized that incorporating chemical compound structure duringself-supervised pre-training could improve learned representations of images inhigh-throughput microscopy screens. We introduce a representation learningframework, MICON (Molecular-Image Contrastive Learning), that models chemicalcompounds as treatments that induce counterfactual transformations of cellphenotypes. MICON significantly outperforms classical hand-crafted featuressuch as CellProfiler and existing deep-learning-based representation learningmethods in challenging evaluation settings where models must identifyreproducible effects of drugs across independent replicates and data-generatingcenters. We demonstrate that incorporating chemical compound information intothe learning process provides consistent improvements in our evaluation settingand that modeling compounds specifically as treatments in a causal frameworkoutperforms approaches that directly align images and compounds in a singlerepresentation space. Our findings point to a new direction for representationlearning in morphological profiling, suggesting that methods should explicitlyaccount for the multimodal nature of microscopy screening data.</description>
      <author>example@mail.com (Yemin Yu, Neil Tenenholtz, Lester Mackey, Ying Wei, David Alvarez-Melis, Ava P. Amini, Alex X. Lu)</author>
      <guid isPermaLink="false">2504.09544v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Comorbidity-Informed Transfer Learning for Neuro-developmental Disorder Diagnosis</title>
      <link>http://arxiv.org/abs/2504.09463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Comorbidity-Informed Transfer Learning（CITL）的框架，用于通过fMRI诊断神经发育障碍，以提高深度学习辅助诊断（CAD）的准确性。&lt;h4&gt;背景&lt;/h4&gt;神经发育障碍表现为认知、沟通、行为和适应性的功能障碍，而基于深度学习的CAD可以缓解神经影像学方面的医疗资源压力。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效诊断神经发育障碍的CAD方法，特别是在fMRI数据上。&lt;h4&gt;方法&lt;/h4&gt;CITL框架结合了迁移学习和伪标签技术，去除fMRI时间域中的干扰模式，并使用编码器-解码器架构生成新的表示。这些新表示在结构简单的分类网络中进行训练，以获得CAD模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CITL在检测自闭症谱系障碍和注意力缺陷多动障碍方面分别达到了76.32%和73.15%的准确性，优于现有的相关迁移学习工作。&lt;h4&gt;结论&lt;/h4&gt;CITL框架在神经发育障碍的诊断中具有竞争力，并提供了跨学科的新视角。&lt;h4&gt;翻译&lt;/h4&gt;Neuro-developmental disorders are manifested as dysfunctions in cognition, communication, behavior and adaptability, and deep learning-based computer-aided diagnosis (CAD) can alleviate the increasingly strained healthcare resources on neuroimaging. However, neuroimaging such as fMRI contains complex spatio-temporal features, which makes the corresponding representations susceptible to a variety of distractions, thus leading to less effective in CAD. For the first time, we present a Comorbidity-Informed Transfer Learning (CITL) framework for diagnosing neuro-developmental disorders using fMRI. In CITL, a new reinforced representation generation network is proposed, which first combines transfer learning with pseudo-labelling to remove interfering patterns from the temporal domain of fMRI and generates new representations using encoder-decoder architecture. The new representations are then trained in an architecturally simple classification network to obtain CAD model. In particular, the framework fully considers the comorbidity mechanisms of neuro-developmental disorders and effectively integrates them with semi-supervised learning and transfer learning, providing new perspectives on interdisciplinary. Experimental results demonstrate that CITL achieves competitive accuracies of 76.32% and 73.15% for detecting autism spectrum disorder and attention deficit hyperactivity disorder, respectively, which outperforms existing related transfer learning work for 7.2% and 0.5% respectively.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuro-developmental disorders are manifested as dysfunctions in cognition,communication, behaviour and adaptability, and deep learning-basedcomputer-aided diagnosis (CAD) can alleviate the increasingly strainedhealthcare resources on neuroimaging. However, neuroimaging such as fMRIcontains complex spatio-temporal features, which makes the correspondingrepresentations susceptible to a variety of distractions, thus leading to lesseffective in CAD. For the first time, we present a Comorbidity-InformedTransfer Learning(CITL) framework for diagnosing neuro-developmental disordersusing fMRI. In CITL, a new reinforced representation generation network isproposed, which first combines transfer learning with pseudo-labelling toremove interfering patterns from the temporal domain of fMRI and generates newrepresentations using encoder-decoder architecture. The new representations arethen trained in an architecturally simple classification network to obtain CADmodel. In particular, the framework fully considers the comorbidity mechanismsof neuro-developmental disorders and effectively integrates them withsemi-supervised learning and transfer learning, providing new perspectives oninterdisciplinary. Experimental results demonstrate that CITL achievescompetitive accuracies of 76.32% and 73.15% for detecting autism spectrumdisorder and attention deficit hyperactivity disorder, respectively, whichoutperforms existing related transfer learning work for 7.2% and 0.5%respectively.</description>
      <author>example@mail.com (Xin Wen, Shijie Guo, Wenbo Ning, Rui Cao, Jie Xiang, Xiaobo Liu, Jintai Chen)</author>
      <guid isPermaLink="false">2504.09463v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>NetTAG: A Multimodal RTL-and-Layout-Aligned Netlist Foundation Model via Text-Attributed Graph</title>
      <link>http://arxiv.org/abs/2504.09260v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Design Automation Conference (DAC), 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;NetTAG是一种融合门语义与图结构的基础模型，用于网表表示学习，在电子设计自动化（EDA）领域有显著潜力。&lt;h4&gt;背景&lt;/h4&gt;电路表示学习在推进电子设计自动化（EDA）方面显示出前景，通过捕捉电路的结构和功能特性来处理各种任务。&lt;h4&gt;目的&lt;/h4&gt;为了提升网表表示学习，NetTAG旨在融合门语义与图结构，处理多样化的门类型，并支持多种功能和物理任务。&lt;h4&gt;方法&lt;/h4&gt;NetTAG将网表构造成文本属性图，门由符号逻辑表达式注解，物理特性作为文本属性。其多模态架构结合了基于LLM的文本编码器（用于门语义）和图变换器（用于全局结构）。通过门和图的自监督目标预训练，并与RTL和布局阶段对齐，NetTAG捕捉了电路的内在特性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，NetTAG在四个功能性和物理任务上持续优于每种特定任务的方法，并超越了最先进的AIG编码器，展示了其多功能性。&lt;h4&gt;结论&lt;/h4&gt;NetTAG在电子设计自动化领域展现出强大的应用潜力，特别是在网表表示学习方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Circuit representation learning has shown promise in advancing ElectronicDesign Automation (EDA) by capturing structural and functional circuitproperties for various tasks. Existing pre-trained solutions rely on graphlearning with complex functional supervision, such as truth table simulation.However, they only handle simple and-inverter graphs (AIGs), struggling tofully encode other complex gate functionalities. While large language models(LLMs) excel at functional understanding, they lack the structural awarenessfor flattened netlists. To advance netlist representation learning, we presentNetTAG, a netlist foundation model that fuses gate semantics with graphstructure, handling diverse gate types and supporting a variety of functionaland physical tasks. Moving beyond existing graph-only methods, NetTAGformulates netlists as text-attributed graphs, with gates annotated by symboliclogic expressions and physical characteristics as text attributes. Itsmultimodal architecture combines an LLM-based text encoder for gate semanticsand a graph transformer for global structure. Pre-trained with gate and graphself-supervised objectives and aligned with RTL and layout stages, NetTAGcaptures comprehensive circuit intrinsics. Experimental results show thatNetTAG consistently outperforms each task-specific method on four largelydifferent functional and physical tasks and surpasses state-of-the-art AIGencoders, demonstrating its versatility.</description>
      <author>example@mail.com (Wenji Fang, Wenkai Li, Shang Liu, Yao Lu, Hongce Zhang, Zhiyao Xie)</author>
      <guid isPermaLink="false">2504.09260v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Psychological Health Knowledge-Enhanced LLM-based Social Network Crisis Intervention Text Transfer Recognition Method</title>
      <link>http://arxiv.org/abs/2504.07983v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于大型语言模型（LLM）的文本传输识别方法，用于社交网络危机干预，该方法增强了特定领域的心理健康知识。&lt;h4&gt;背景&lt;/h4&gt;随着社交媒体平台上心理健康危机的普遍增加，识别和预防潜在伤害已成为一项紧迫的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种多层次的框架，该框架结合了使用BERT的迁移学习，并整合了心理健康知识、情感分析和行为预测技术，以提高危机检测的准确性和对细微情绪和语境变化的敏感性。&lt;h4&gt;方法&lt;/h4&gt;该方法包括一个基于真实世界事件社交媒体数据集训练的危机标注工具，使模型能够检测微妙的情感线索和识别心理危机。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在危机检测准确性方面优于传统模型，并且对细微的情感和语境变化表现出更高的敏感性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法对于识别和预防社交媒体平台上的心理健康危机具有潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the prevalence of mental health crises increases on social mediaplatforms, identifying and preventing potential harm has become an urgentchallenge. This study introduces a large language model (LLM)-based texttransfer recognition method for social network crisis intervention, enhancedwith domain-specific mental health knowledge. We propose a multi-levelframework that incorporates transfer learning using BERT, and integrates mentalhealth knowledge, sentiment analysis, and behavior prediction techniques. Theframework includes a crisis annotation tool trained on social media datasetsfrom real-world events, enabling the model to detect nuanced emotional cues andidentify psychological crises. Experimental results show that the proposedmethod outperforms traditional models in crisis detection accuracy and exhibitsgreater sensitivity to subtle emotional and contextual variations.</description>
      <author>example@mail.com (Shurui Wu, Xinyi Huang, Dingxin Lu)</author>
      <guid isPermaLink="false">2504.07983v2</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>A Confounding Factors-Inhibition Adversarial Learning Framework for Multi-site fMRI Mental Disorder Identification</title>
      <link>http://arxiv.org/abs/2504.09179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MSalNET的新型多站点对抗学习网络，用于基于fMRI的脑部疾病检测。&lt;h4&gt;背景&lt;/h4&gt;fMRI数据集的异质性通常归因于扫描程序的不同、混杂效应的存在以及多个站点之间的群体多样性，这些因素影响了表示学习和分类过程的效率。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了一种新的多站点对抗学习网络（MSalNET）来提高fMRI基于脑部疾病的检测效果。&lt;h4&gt;方法&lt;/h4&gt;首先，引入了一个具有节点信息组装（NIA）机制的表现学习模块，以更好地从功能连接（FC）中提取特征。其次，为了在不同站点之间泛化特征，提出了一种站点级特征提取模块，该模块可以从单个FC数据中学习，避免了额外的先验信息。最后，提出了一种对抗学习网络，通过引入一个新颖的损失函数来平衡个体分类和站点回归任务之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;在ABIDE和ADHD-200数据集上评估了该方法，结果表明，与相关算法相比，该方法在ABIDE和ADHD-200数据集上分别达到了75.56和68.92的准确率。此外，站点回归的结果表明，该方法从数据驱动的角度减少了站点之间的变异性。NIA揭示的最具判别性的脑区与统计发现一致，在一定程度上揭示了深度学习的‘黑盒’。&lt;h4&gt;结论&lt;/h4&gt;MSalNET在提高fMRI基于脑部疾病的检测性能方面表现出色，同时减少了站点间的数据变异性，有助于揭示深度学习的内部机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In open data sets of functional magnetic resonance imaging (fMRI), theheterogeneity of the data is typically attributed to a combination of factors,including differences in scanning procedures, the presence of confoundingeffects, and population diversities between multiple sites. These factorscontribute to the diminished effectiveness of representation learning, which inturn affects the overall efficacy of subsequent classification procedures. Toaddress these limitations, we propose a novel multi-site adversarial learningnetwork (MSalNET) for fMRI-based mental disorder detection. Firstly, arepresentation learning module is introduced with a node information assembly(NIA) mechanism to better extract features from functional connectivity (FC).This mechanism aggregates edge information from both horizontal and verticaldirections, effectively assembling node information. Secondly, to generalizethe feature across sites, we proposed a site-level feature extraction modulethat can learn from individual FC data, which circumvents additional priorinformation. Lastly, an adversarial learning network is proposed as a means ofbalancing the trade-off between individual classification and site regressiontasks, with the introduction of a novel loss function. The proposed method wasevaluated on two multi-site fMRI datasets, i.e., Autism Brain Imaging DataExchange (ABIDE) and ADHD-200. The results indicate that the proposed methodachieves a better performance than other related algorithms with the accuracyof 75.56 and 68.92 in ABIDE and ADHD-200 datasets, respectively. Furthermore,the result of the site regression indicates that the proposed method reducessite variability from a data-driven perspective. The most discriminative brainregions revealed by NIA are consistent with statistical findings, uncoveringthe "black box" of deep learning to a certain extent.</description>
      <author>example@mail.com (Xin Wen, Shijie Guo, Wenbo Ning, Rui Cao, Yan Niu, Bin Wan, Peng Wei, Xiaobo Liu, Jie Xiang)</author>
      <guid isPermaLink="false">2504.09179v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>ToolTipNet: A Segmentation-Driven Deep Learning Baseline for Surgical Instrument Tip Detection</title>
      <link>http://arxiv.org/abs/2504.09700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于深度学习的手术器械尖端检测方法，以解决机器人辅助腹腔镜根治性前列腺切除术中器械尖端定位不准确的问题。&lt;h4&gt;背景&lt;/h4&gt;在机器人辅助腹腔镜根治性前列腺切除术中，器械尖端的位置对于将超声框架与腹腔镜摄像机框架对准至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于视觉的方法，直接计算工具尖端在摄像机框架中的位置，以提高手术精确性。&lt;h4&gt;方法&lt;/h4&gt;利用深度学习技术，结合分割基础模型（Segment Anything），实现手术器械尖端的检测，并通过与手工图像处理方法进行比较实验。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在模拟和真实数据集上优于手工图像处理方法，能够有效检测小型且可动手术器械的尖端。&lt;h4&gt;结论&lt;/h4&gt;基于深度学习的手术器械尖端检测方法能够有效解决手术器械尖端定位问题，具有提高手术精度的潜力。&lt;h4&gt;翻译&lt;/h4&gt;在机器人辅助腹腔镜根治性前列腺切除术中，器械尖端位置对超声框架与腹腔镜摄像机框架的对准至关重要。现有方法中，由da Vinci API获取的器械尖端位置不准确，需要手动校正。因此，直接使用基于视觉的方法计算工具尖端在摄像机框架中的位置成为一个吸引人的解决方案。此外，手术器械尖端检测是其他任务（如手术技能评估和手术自动化）的关键组成部分。然而，由于工具尖端尺寸小且手术器械可动，这一任务具有挑战性。随着分割基础模型（Segment Anything）的出现，手术器械分割变得相对容易。基于这一进步，我们探索了基于深度学习的手术器械尖端检测方法，该方法以部分级器械分割掩码作为输入。与手工图像处理方法的比较实验表明，所提出的方法在模拟和真实数据集上均优于手工图像处理方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In robot-assisted laparoscopic radical prostatectomy (RALP), the location ofthe instrument tip is important to register the ultrasound frame with thelaparoscopic camera frame. A long-standing limitation is that the instrumenttip position obtained from the da Vinci API is inaccurate and requires hand-eyecalibration. Thus, directly computing the position of the tool tip in thecamera frame using the vision-based method becomes an attractive solution.Besides, surgical instrument tip detection is the key component of other tasks,like surgical skill assessment and surgery automation. However, this task ischallenging due to the small size of the tool tip and the articulation of thesurgical instrument. Surgical instrument segmentation becomes relatively easydue to the emergence of the Segmentation Foundation Model, i.e., SegmentAnything. Based on this advancement, we explore the deep learning-basedsurgical instrument tip detection approach that takes the part-level instrumentsegmentation mask as input. Comparison experiments with a hand-craftedimage-processing approach demonstrate the superiority of the proposed method onsimulated and real datasets.</description>
      <author>example@mail.com (Zijian Wu, Shuojue Yang, Yueming Jin, Septimiu E Salcudean)</author>
      <guid isPermaLink="false">2504.09700v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Towards Unbiased Federated Graph Learning: Label and Topology Perspectives</title>
      <link>http://arxiv.org/abs/2504.09963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FairFGL的新型框架，旨在通过细粒度图挖掘和协作学习来提高联邦图学习（FGL）中的公平性。&lt;h4&gt;背景&lt;/h4&gt;Federated Graph Learning（FGL）允许在不共享原始数据的情况下，对图神经网络进行隐私保护、分布式训练。subgraph-FL成为主流方法，但现有方法往往忽略了公平性，特别是在处理具有不利属性的节点时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了两个公平性目标：(1) 提高少数类节点的表示以实现类间公平性；(2) 减少异质连接带来的拓扑偏差以实现拓扑感知公平性。&lt;h4&gt;方法&lt;/h4&gt;FairFGL框架包括客户端和服务器端。客户端使用历史保持模块防止对主导局部类过度拟合，使用多数对齐模块细化异质多数类节点的表示，使用梯度修改模块将少数类知识从结构上优势的客户端传递以改善公平性。服务器端仅上传受影响最大的参数子集以减少通信成本，并更好地反映局部分布。基于集群的聚合策略协调冲突的更新并抑制全局多数主导。&lt;h4&gt;主要发现&lt;/h4&gt;在八个基准测试上的广泛评估表明，FairFGL显著提高了少数群体的性能，实现了高达22.62%的Macro-F1增益，同时增强了收敛性。&lt;h4&gt;结论&lt;/h4&gt;FairFGL框架通过提高少数类节点的表示和减少异质连接的拓扑偏差，有效地提升了联邦图学习中的公平性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Graph Learning (FGL) enables privacy-preserving, distributedtraining of graph neural networks without sharing raw data. Among itsapproaches, subgraph-FL has become the dominant paradigm, with most workfocused on improving overall node classification accuracy. However, thesemethods often overlook fairness due to the complexity of node features, labels,and graph structures. In particular, they perform poorly on nodes withdisadvantaged properties, such as being in the minority class within subgraphsor having heterophilous connections (neighbors with dissimilar labels ormisleading features). This reveals a critical issue: high accuracy can maskdegraded performance on structurally or semantically marginalized nodes. Toaddress this, we advocate for two fairness goals: (1) improving representationof minority class nodes for class-wise fairness and (2) mitigating topologicalbias from heterophilous connections for topology-aware fairness. We proposeFairFGL, a novel framework that enhances fairness through fine-grained graphmining and collaborative learning. On the client side, the History-PreservingModule prevents overfitting to dominant local classes, while the MajorityAlignment Module refines representations of heterophilous majority-class nodes.The Gradient Modification Module transfers minority-class knowledge fromstructurally favorable clients to improve fairness. On the server side, FairFGLuploads only the most influenced subset of parameters to reduce communicationcosts and better reflect local distributions. A cluster-based aggregationstrategy reconciles conflicting updates and curbs global majority dominance .Extensive evaluations on eight benchmarks show FairFGL significantly improvesminority-group performance , achieving up to a 22.62 percent Macro-F1 gainwhile enhancing convergence over state-of-the-art baselines.</description>
      <author>example@mail.com (Zhengyu Wu, Boyang Pang, Xunkai Li, Yinlin Zhu, Daohan Su, Bowen Fan, Rong-Hua Li, Guoren Wang, Chenghu Zhou)</author>
      <guid isPermaLink="false">2504.09963v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Mixture-of-Shape-Experts (MoSE): End-to-End Shape Dictionary Framework to Prompt SAM for Generalizable Medical Segmentation</title>
      <link>http://arxiv.org/abs/2504.09601v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025 workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的Mixture-of-Shape-Experts (MoSE)框架，用于提高医学图像分割中的单域泛化能力。&lt;h4&gt;背景&lt;/h4&gt;单域泛化（SDG）在医学图像分割中越来越受到关注，但现有的字典学习方法存在表示能力有限或过拟合的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效捕捉多样化和鲁棒形状先验的方法，以解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;MoSE框架将混合专家（MoE）训练的理念整合到字典学习中，将每个字典原子视为一个形状专家，并使用门控网络动态融合这些专家，以生成鲁棒的形状图。SAM编码用于指导稀疏激活，防止过拟合。形状图作为提示被用于SAM，实现双向集成。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个公共数据集上进行了广泛实验，证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;MoSE框架能够有效提高医学图像分割中的单域泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Single domain generalization (SDG) has recently attracted growing attention in medical image segmentation. One promising strategy for SDG is to leverage consistent semantic shape priors across different imaging protocols, scanner vendors, and clinical sites. However, existing dictionary learning methods that encode shape priors often suffer from limited representational power with a small set of offline computed shape elements, or overfitting when the dictionary size grows. Moreover, they are not readily compatible with large foundation models such as the Segment Anything Model (SAM). In this paper, we propose a novel Mixture-of-Shape-Experts (MoSE) framework that seamlessly integrates the idea of mixture-of-experts (MoE) training into dictionary learning to efficiently capture diverse and robust shape priors. Our method conceptualizes each dictionary atom as a shape expert, which specializes in encoding distinct semantic shape information. A gating network dynamically fuses these shape experts into a robust shape map, with sparse activation guided by SAM encoding to prevent overfitting. We further provide this shape map as a prompt to SAM, utilizing the powerful generalization capability of SAM through bidirectional integration. All modules, including the shape dictionary, are trained in an end-to-end manner. Extensive experiments on multiple public datasets demonstrate its effectiveness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single domain generalization (SDG) has recently attracted growing attentionin medical image segmentation. One promising strategy for SDG is to leverageconsistent semantic shape priors across different imaging protocols, scannervendors, and clinical sites. However, existing dictionary learning methods thatencode shape priors often suffer from limited representational power with asmall set of offline computed shape elements, or overfitting when thedictionary size grows. Moreover, they are not readily compatible with largefoundation models such as the Segment Anything Model (SAM). In this paper, wepropose a novel Mixture-of-Shape-Experts (MoSE) framework that seamlesslyintegrates the idea of mixture-of-experts (MoE) training into dictionarylearning to efficiently capture diverse and robust shape priors. Our methodconceptualizes each dictionary atom as a shape expert, which specializes inencoding distinct semantic shape information. A gating network dynamicallyfuses these shape experts into a robust shape map, with sparse activationguided by SAM encoding to prevent overfitting. We further provide this shapemap as a prompt to SAM, utilizing the powerful generalization capability of SAMthrough bidirectional integration. All modules, including the shape dictionary,are trained in an end-to-end manner. Extensive experiments on multiple publicdatasets demonstrate its effectiveness.</description>
      <author>example@mail.com (Jia Wei, Xiaoqi Zhao, Jonghye Woo, Jinsong Ouyang, Georges El Fakhri, Qingyu Chen, Xiaofeng Liu)</author>
      <guid isPermaLink="false">2504.09601v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Glucose-Only Assessment: Advancing Nocturnal Hypoglycemia Prediction in Children with Type 1 Diabetes</title>
      <link>http://arxiv.org/abs/2504.09299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICLR 2025 Workshop on AI for Children&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过生理数据和机器学习技术，旨在改善1型糖尿病患者夜间低血糖的预测。&lt;h4&gt;背景&lt;/h4&gt;死在床上的综合症描述了年轻1型糖尿病患者突然无征兆的死亡，这种死亡被假设与夜间低血糖有关。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过利用生理数据和机器学习技术，提高1型糖尿病儿童夜间低血糖的预测能力。&lt;h4&gt;方法&lt;/h4&gt;研究分析了来自16名1型糖尿病儿童的内部数据集，整合了可穿戴传感器的生理指标。通过特征工程、模型选择、架构和过采样来探索预测性能。为了解决数据限制，应用了从公共成人数据集的迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;研究在内部数据集上实现了AUROC为0.75 +- 0.21的结果，通过迁移学习进一步提高了到0.78 +- 0.05。&lt;h4&gt;结论&lt;/h4&gt;研究超越了仅基于血糖的预测，通过结合生理参数，展示了机器学习在增强夜间低血糖检测和改善儿童糖尿病管理临床决策中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;The dead-in-bed syndrome describes the sudden and unexplained death of young individuals with Type 1 Diabetes (T1D) without prior long-term complications. One leading hypothesis attributes this phenomenon to nocturnal hypoglycemia (NH), a dangerous drop in blood glucose during sleep. This study aims to improve NH prediction in children with T1D by leveraging physiological data and machine learning (ML) techniques. We analyze an in-house dataset collected from 16 children with T1D, integrating physiological metrics from wearable sensors. We explore predictive performance through feature engineering, model selection, architectures, and oversampling. To address data limitations, we apply transfer learning from a publicly available adult dataset. Our results achieve an AUROC of 0.75 +- 0.21 on the in-house dataset, further improving to 0.78 +- 0.05 with transfer learning. This research moves beyond glucose-only predictions by incorporating physiological parameters, showcasing the potential of ML to enhance NH detection and improve clinical decision-making for pediatric diabetes management.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The dead-in-bed syndrome describes the sudden and unexplained death of youngindividuals with Type 1 Diabetes (T1D) without prior long-term complications.One leading hypothesis attributes this phenomenon to nocturnal hypoglycemia(NH), a dangerous drop in blood glucose during sleep. This study aims toimprove NH prediction in children with T1D by leveraging physiological data andmachine learning (ML) techniques. We analyze an in-house dataset collected from16 children with T1D, integrating physiological metrics from wearable sensors.We explore predictive performance through feature engineering, model selection,architectures, and oversampling. To address data limitations, we apply transferlearning from a publicly available adult dataset. Our results achieve an AUROCof 0.75 +- 0.21 on the in-house dataset, further improving to 0.78 +- 0.05 withtransfer learning. This research moves beyond glucose-only predictions byincorporating physiological parameters, showcasing the potential of ML toenhance NH detection and improve clinical decision-making for pediatricdiabetes management.</description>
      <author>example@mail.com (Marco Voegeli, Sonia Laguna, Heike Leutheuser, Marc Pfister, Marie-Anne Burckhardt, Julia E Vogt)</author>
      <guid isPermaLink="false">2504.09299v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Predicting ulcer in H&amp;E images of inflammatory bowel disease using domain-knowledge-driven graph neural network</title>
      <link>http://arxiv.org/abs/2504.09430v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work accepted at ISBI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DomainGCN的弱监督模型，用于在炎症性肠病（IBD）中预测溃疡区域，以提高个性化治疗的选择。&lt;h4&gt;背景&lt;/h4&gt;炎症性肠病（IBD）是一种慢性炎症性疾病，其治疗常常受到副作用的影响。免疫细胞在IBD中起关键作用，而在全切片图像（WSIs）中准确识别溃疡区域对于表征这些细胞和探索潜在疗法至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够利用特定领域知识（如上皮、淋巴细胞和碎片的存在）的模型，以在IBD中预测WSI级别的溃疡区域。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为DomainGCN的模型，该模型结合了图卷积神经网络（GCN）和特定于溃疡特征的领域知识，用于WSI级别的溃疡预测。&lt;h4&gt;主要发现&lt;/h4&gt;DomainGCN在多个实例学习（MIL）方法中表现优于最先进的（SOTA）方法，并展示了领域知识带来的额外价值。&lt;h4&gt;结论&lt;/h4&gt;DomainGCN模型能够有效地利用领域知识提高IBD中溃疡区域的预测准确性，为个性化治疗提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Inflammatory bowel disease (IBD) involves chronic inflammation of the digestive tract, with treatment options often burdened by adverse effects. Identifying biomarkers for personalized treatment is crucial. While immune cells play a key role in IBD, accurately identifying ulcer regions in whole slide images (WSIs) is essential for characterizing these cells and exploring potential therapeutics. Multiple instance learning (MIL) approaches have advanced WSI analysis but they lack spatial context awareness. In this work, we propose a weakly-supervised model called DomainGCN that employs a graph convolution neural network (GCN) and incorporates domain-specific knowledge of ulcer features, specifically, the presence of epithelium, lymphocytes, and debris for WSI-level ulcer prediction in IBD. We demonstrate that DomainGCN outperforms various state-of-the-art (SOTA) MIL methods and show the added value of domain knowledge.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inflammatory bowel disease (IBD) involves chronic inflammation of thedigestive tract, with treatment options often burdened by adverse effects.Identifying biomarkers for personalized treatment is crucial. While immunecells play a key role in IBD, accurately identifying ulcer regions in wholeslide images (WSIs) is essential for characterizing these cells and exploringpotential therapeutics. Multiple instance learning (MIL) approaches haveadvanced WSI analysis but they lack spatial context awareness. In this work, wepropose a weakly-supervised model called DomainGCN that employs a graphconvolution neural network (GCN) and incorporates domain-specific knowledge ofulcer features, specifically, the presence of epithelium, lymphocytes, anddebris for WSI-level ulcer prediction in IBD. We demonstrate that DomainGCNoutperforms various state-of-the-art (SOTA) MIL methods and show the addedvalue of domain knowledge.</description>
      <author>example@mail.com (Ruiwen Ding, Lin Li, Rajath Soans, Tosha Shah, Radha Krishnan, Marc Alexander Sze, Sasha Lukyanov, Yash Deshpande, Antong Chen)</author>
      <guid isPermaLink="false">2504.09430v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Query-based Knowledge Transfer for Heterogeneous Learning Environments</title>
      <link>http://arxiv.org/abs/2504.09205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICLR'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为QKT的新型框架，用于解决在数据异质性和隐私约束下的去中心化协作学习问题。&lt;h4&gt;背景&lt;/h4&gt;在数据异质性和隐私约束下，现有的联邦学习、集成学习和迁移学习方法无法充分满足客户独特的需求，尤其是在本地数据表示有限的情况下。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，提出了QKT框架，以实现针对特定客户需求的定制化知识获取，而不需要直接交换数据。&lt;h4&gt;方法&lt;/h4&gt;QKT采用数据无关的掩码策略，以实现高效的查询焦点知识迁移，同时优化任务特定参数，以减轻知识干扰和遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;在标准基准和临床基准上的实验表明，QKT在单类别查询设置中平均优于现有协作学习方法20.91%，在多类别查询场景中平均优于14.32%。进一步的分析和消融研究显示，QKT有效地平衡了新知识和现有知识的学习，显示出其在去中心化学习中的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;QKT框架能够有效地解决数据异质性和隐私约束下的去中心化协作学习问题，具有在去中心化学习领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decentralized collaborative learning under data heterogeneity and privacyconstraints has rapidly advanced. However, existing solutions like federatedlearning, ensembles, and transfer learning, often fail to adequately serve theunique needs of clients, especially when local data representation is limited.To address this issue, we propose a novel framework called Query-basedKnowledge Transfer (QKT) that enables tailored knowledge acquisition to fulfillspecific client needs without direct data exchange. QKT employs a data-freemasking strategy to facilitate communication-efficient query-focused knowledgetransfer while refining task-specific parameters to mitigate knowledgeinterference and forgetting. Our experiments, conducted on both standard andclinical benchmarks, show that QKT significantly outperforms existingcollaborative learning methods by an average of 20.91\% points in single-classquery settings and an average of 14.32\% points in multi-class query scenarios.Further analysis and ablation studies reveal that QKT effectively balances thelearning of new and existing knowledge, showing strong potential for itsapplication in decentralized learning.</description>
      <author>example@mail.com (Norah Alballa, Wenxuan Zhang, Ziquan Liu, Ahmed M. Abdelmoniem, Mohamed Elhoseiny, Marco Canini)</author>
      <guid isPermaLink="false">2504.09205v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>FSSUAVL: A Discriminative Framework using Vision Models for Federated Self-Supervised Audio and Image Understanding</title>
      <link>http://arxiv.org/abs/2504.09516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为FSSUAVL的单个深度模型，用于解决无配对数据情况下多模态音频和图像识别的问题。&lt;h4&gt;背景&lt;/h4&gt;现有研究表明，配对的多模态音频图像表示可以有效地通过视觉模型学习。然而，在联邦学习（FL）等场景中，数据往往是去中心化、异构的，且缺乏可靠的数据配对保证。&lt;h4&gt;目的&lt;/h4&gt;旨在通过FSSUAVL模型解决无配对模态深度学习表示的挑战。&lt;h4&gt;方法&lt;/h4&gt;FSSUAVL模型在FL中通过自监督对比学习（SSL）进行预训练，不通过模态对齐，而是通过对比SSL将音频和图像投影到共同的嵌入空间中。&lt;h4&gt;主要发现&lt;/h4&gt;与使用单独深度模型进行每个模态相比，FSSUAVL在CNN和ViT上的实验表明，它在各种基于图像和音频的下游任务中显著提高了性能。&lt;h4&gt;结论&lt;/h4&gt;FSSUAVL能够学习多模态特征表示，并允许集成辅助信息以提高识别精度。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，当配对时，视觉模型可以有效地学习多模态音频-图像表示。然而，使深度模型从无配对模态中学习表示的挑战仍未解决。这个问题在联邦学习（FL）等场景中尤为重要，在这些场景中，数据通常是去中心化的、异构的，并且缺乏可靠的数据配对保证。以前的努力通过在本地客户端使用辅助预训练编码器或生成模型来解决这个问题，这不可避免地随着模态数量的增加而增加计算成本。与这些方法不同，本文旨在通过使用在FL中预训练的自监督对比学习（SSL）的单个深度模型FSSUAVL来处理无配对音频和图像识别任务。FSSUAVL通过对比SSL将音频和图像联合区分，而不是对齐它们，将它们投影到共同的嵌入空间中。这扩展了FSSUAVL在配对和无配对音频和图像识别任务中的效用。我们在CNN和ViT上的实验表明，与为每个模态使用单独的深度模型相比，FSSUAVL在各种基于图像和音频的下游任务中显著提高了性能。此外，FSSUAVL学习多模态特征表示的能力允许集成辅助信息（如果可用）以提高识别精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies have demonstrated that vision models can effectively learnmultimodal audio-image representations when paired. However, the challenge ofenabling deep models to learn representations from unpaired modalities remainsunresolved. This issue is especially pertinent in scenarios like FederatedLearning (FL), where data is often decentralized, heterogeneous, and lacks areliable guarantee of paired data. Previous attempts tackled this issue throughthe use of auxiliary pretrained encoders or generative models on local clients,which invariably raise computational cost with increasing number modalities.Unlike these approaches, in this paper, we aim to address the task of unpairedaudio and image recognition using \texttt{FSSUAVL}, a single deep modelpretrained in FL with self-supervised contrastive learning (SSL). Instead ofaligning the audio and image modalities, \texttt{FSSUAVL} jointly discriminatesthem by projecting them into a common embedding space using contrastive SSL.This extends the utility of \texttt{FSSUAVL} to paired and unpaired audio andimage recognition tasks. Our experiments with CNN and ViT demonstrate that\texttt{FSSUAVL} significantly improves performance across various image- andaudio-based downstream tasks compared to using separate deep models for eachmodality. Additionally, \texttt{FSSUAVL}'s capacity to learn multimodal featurerepresentations allows for integrating auxiliary information, if available, toenhance recognition accuracy.</description>
      <author>example@mail.com (Yasar Abbas Ur Rehman, Kin Wai Lau, Yuyang Xie, Ma Lan, JiaJun Shen)</author>
      <guid isPermaLink="false">2504.09516v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Spatially Directional Dual-Attention GAT for Spatial Fluoride Health Risk Modeling</title>
      <link>http://arxiv.org/abs/2504.09416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SDD-GAT的新型空间图神经网络，用于细粒度健康风险预测，并在贵州地区的氟化物监测样本和氟斑牙记录数据集上取得了显著效果。&lt;h4&gt;背景&lt;/h4&gt;氟化物环境暴露是公共卫生问题，特别是在氟化物浓度自然升高的地区。准确建模氟化物相关的健康风险，如牙氟斑病，需要能够捕捉地理和语义异质性的空间感知学习框架。&lt;h4&gt;目的&lt;/h4&gt;提出SDD-GAT，以实现氟化物相关健康风险的准确预测。&lt;h4&gt;方法&lt;/h4&gt;SDD-GAT引入了双图架构，将地理邻近性和属性相似性解耦，并采用方向性注意力机制将空间方向和距离显式编码到消息传递过程中。为了进一步提高空间一致性，引入了空间平滑度正则化项。&lt;h4&gt;主要发现&lt;/h4&gt;SDD-GAT在回归和分类任务中均显著优于传统模型和最先进的图神经网络，并且表现出改善的空间自相关性。&lt;h4&gt;结论&lt;/h4&gt;SDD-GAT为复杂环境设置下的空间健康风险建模和地理空间学习提供了一个可推广的基础。&lt;h4&gt;翻译&lt;/h4&gt;Environmental exposure to fluoride is a major public health concern, particularly in regions with naturally elevated fluoride concentrations. Accurate modeling of fluoride-related health risks, such as dental fluorosis, requires spatially aware learning frameworks capable of capturing both geographic and semantic heterogeneity. In this work, we propose Spatially Directional Dual-Attention Graph Attention Network (SDD-GAT), a novel spatial graph neural network designed for fine-grained health risk prediction. SDD-GAT introduces a dual-graph architecture that disentangles geographic proximity and attribute similarity, and incorporates a directional attention mechanism that explicitly encodes spatial orientation and distance into the message passing process. To further enhance spatial coherence, we introduce a spatial smoothness regularization term that enforces consistency in predictions across neighboring locations. We evaluate SDD-GAT on a large-scale dataset covering over 50,000 fluoride monitoring samples and fluorosis records across Guizhou Province, China. Results show that SDD-GAT significantly outperforms traditional models and state-of-the-art GNNs in both regression and classification tasks, while also exhibiting improved spatial autocorrelation as measured by Moran's I. Our framework provides a generalizable foundation for spatial health risk modeling and geospatial learning under complex environmental settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Environmental exposure to fluoride is a major public health concern,particularly in regions with naturally elevated fluoride concentrations.Accurate modeling of fluoride-related health risks, such as dental fluorosis,requires spatially aware learning frameworks capable of capturing bothgeographic and semantic heterogeneity. In this work, we propose SpatiallyDirectional Dual-Attention Graph Attention Network (SDD-GAT), a novel spatialgraph neural network designed for fine-grained health risk prediction. SDD-GATintroduces a dual-graph architecture that disentangles geographic proximity andattribute similarity, and incorporates a directional attention mechanism thatexplicitly encodes spatial orientation and distance into the message passingprocess. To further enhance spatial coherence, we introduce a spatialsmoothness regularization term that enforces consistency in predictions acrossneighboring locations. We evaluate SDD-GAT on a large-scale dataset coveringover 50,000 fluoride monitoring samples and fluorosis records across GuizhouProvince, China. Results show that SDD-GAT significantly outperformstraditional models and state-of-the-art GNNs in both regression andclassification tasks, while also exhibiting improved spatial autocorrelation asmeasured by Moran's I. Our framework provides a generalizable foundation forspatial health risk modeling and geospatial learning under complexenvironmental settings.</description>
      <author>example@mail.com (Da Yuan)</author>
      <guid isPermaLink="false">2504.09416v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>EasyREG: Easy Depth-Based Markerless Registration and Tracking using Augmented Reality Device for Surgical Guidance</title>
      <link>http://arxiv.org/abs/2504.09498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于增强现实（AR）设备的无标记框架，用于手术引导，通过深度传感器实现高精度和实时性能，避免了传统标记方法带来的不便。&lt;h4&gt;背景&lt;/h4&gt;传统的手术引导方法依赖外部标记物，虽然能实现高精度和实时性，但需要繁琐的校准过程，且在临床环境中部署困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种无标记的手术引导框架，以提高手术引导的准确性和实时性。&lt;h4&gt;方法&lt;/h4&gt;该框架包含两个模块：注册模块和跟踪模块。注册模块通过深度传感器误差校正、区域过滤技术和鲁棒的全球对齐来实现高精度、鲁棒的目标解剖定位。跟踪模块使用快速鲁棒的注册算法，利用注册模块的初始姿态估计实时目标姿态。&lt;h4&gt;主要发现&lt;/h4&gt;通过仿真和实际测量，该无标记系统在注册方面表现优于工业解决方案，在跟踪方面与工业解决方案相当。&lt;h4&gt;结论&lt;/h4&gt;该两模块设计使系统成为手术过程中目标解剖结构移动或静止时的全方位解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于增强现实（AR）设备的无标记框架，用于手术引导。该框架利用AR设备的深度传感器，避免了传统标记方法带来的不便。注册模块通过深度传感器误差校正、区域过滤技术和鲁棒的全球对齐来实现高精度、鲁棒的目标解剖定位。跟踪模块使用快速鲁棒的注册算法，利用注册模块的初始姿态估计实时目标姿态。通过仿真和实际测量，该无标记系统在注册方面表现优于工业解决方案，在跟踪方面与工业解决方案相当。该两模块设计使系统成为手术过程中目标解剖结构移动或静止时的全方位解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The use of Augmented Reality (AR) devices for surgical guidance has gainedincreasing traction in the medical field. Traditional registration methodsoften rely on external fiducial markers to achieve high accuracy and real-timeperformance. However, these markers introduce cumbersome calibration proceduresand can be challenging to deploy in clinical settings. While commercialsolutions have attempted real-time markerless tracking using the native RGBcameras of AR devices, their accuracy remains questionable for medicalguidance, primarily due to occlusions and significant outliers between the livesensor data and the preoperative target anatomy point cloud derived from MRI orCT scans. In this work, we present a markerless framework that relies only onthe depth sensor of AR devices and consists of two modules: a registrationmodule for high-precision, outlier-robust target anatomy localization, and atracking module for real-time pose estimation. The registration moduleintegrates depth sensor error correction, a human-in-the-loop region filteringtechnique, and a robust global alignment with curvature-aware feature sampling,followed by local ICP refinement, for markerless alignment of preoperativemodels with patient anatomy. The tracking module employs a fast and robustregistration algorithm that uses the initial pose from the registration moduleto estimate the target pose in real-time. We comprehensively evaluated theperformance of both modules through simulation and real-world measurements. Theresults indicate that our markerless system achieves superior performance forregistration and comparable performance for tracking to industrial solutions.The two-module design makes our system a one-stop solution for surgicalprocedures where the target anatomy moves or stays static during surgery.</description>
      <author>example@mail.com (Yue Yang, Christoph Leuze, Brian Hargreaves, Bruce Daniel, Fred Baik)</author>
      <guid isPermaLink="false">2504.09498v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Synthetic Aircraft Trajectory Generation Using Time-Based VQ-VAE</title>
      <link>http://arxiv.org/abs/2504.09101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was presented at the 25th Integrated Communications,  Navigation and Surveillance Conference (ICNS 2025), April 8--10, 2025,  Brussels, Belgium&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于时间向量量化变分自编码器（TimeVQVAE）的飞行轨迹合成新方法，用于解决航空交通管理中的数据稀缺、信息保护以及大规模分析等问题。&lt;h4&gt;背景&lt;/h4&gt;现代航空交通管理中，生成合成飞行轨迹已成为解决数据稀缺、保护敏感信息和支持大规模分析的有前途的解决方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的轨迹合成方法，以适应TimeVQVAE，利用时间-频率域处理、向量量化和基于transformer的先验，捕捉飞行数据的全局和局部动态。&lt;h4&gt;方法&lt;/h4&gt;通过离散化潜在空间和整合transformer先验，模型学习长程时空依赖性，并保持整个飞行路径的连贯性。使用质量、统计和分布性指标以及开源航空交通模拟器中的可飞性评估来评估改进的TimeVQVAE。&lt;h4&gt;主要发现&lt;/h4&gt;TimeVQVAE在空间精度、时间一致性和统计特性方面优于时间卷积VAE基线，生成的合成轨迹与真实飞行数据相似。模拟器评估显示，大多数生成的轨迹保持操作可行性，但偶尔的异常值强调了需要额外的特定领域约束。&lt;h4&gt;结论&lt;/h4&gt;研究强调了多尺度表示学习在捕捉复杂飞行行为中的重要性，并证明了TimeVQVAE在生成具有代表性的合成轨迹方面的潜力，可用于下游任务如模型训练、空域设计和航空交通预测。&lt;h4&gt;翻译&lt;/h4&gt;In modern air traffic management, generating synthetic flight trajectories has emerged as a promising solution for addressing data scarcity, protecting sensitive information, and supporting large-scale analyses. In this paper, we propose a novel method for trajectory synthesis by adapting the Time-Based Vector Quantized Variational Autoencoder (TimeVQVAE). Our approach leverages time-frequency domain processing, vector quantization, and transformer-based priors to capture both global and local dynamics in flight data. By discretizing the latent space and integrating transformer priors, the model learns long-range spatiotemporal dependencies and preserves coherence across entire flight paths. We evaluate the adapted TimeVQVAE using an extensive suite of quality, statistical, and distributional metrics, as well as a flyability assessment conducted in an open-source air traffic simulator. Results indicate that TimeVQVAE outperforms a temporal convolutional VAE baseline, generating synthetic trajectories that mirror real flight data in terms of spatial accuracy, temporal consistency, and statistical properties. Furthermore, the simulator-based assessment shows that most generated trajectories maintain operational feasibility, although occasional outliers underscore the potential need for additional domain-specific constraints. Overall, our findings underscore the importance of multi-scale representation learning for capturing complex flight behaviors and demonstrate the promise of TimeVQVAE in producing representative synthetic trajectories for downstream tasks such as model training, airspace design, and air traffic forecasting.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In modern air traffic management, generating synthetic flight trajectorieshas emerged as a promising solution for addressing data scarcity, protectingsensitive information, and supporting large-scale analyses. In this paper, wepropose a novel method for trajectory synthesis by adapting the Time-BasedVector Quantized Variational Autoencoder (TimeVQVAE). Our approach leveragestime-frequency domain processing, vector quantization, and transformer-basedpriors to capture both global and local dynamics in flight data. Bydiscretizing the latent space and integrating transformer priors, the modellearns long-range spatiotemporal dependencies and preserves coherence acrossentire flight paths. We evaluate the adapted TimeVQVAE using an extensive suiteof quality, statistical, and distributional metrics, as well as a flyabilityassessment conducted in an open-source air traffic simulator. Results indicatethat TimeVQVAE outperforms a temporal convolutional VAE baseline, generatingsynthetic trajectories that mirror real flight data in terms of spatialaccuracy, temporal consistency, and statistical properties. Furthermore, thesimulator-based assessment shows that most generated trajectories maintainoperational feasibility, although occasional outliers underscore the potentialneed for additional domain-specific constraints. Overall, our findingsunderscore the importance of multi-scale representation learning for capturingcomplex flight behaviors and demonstrate the promise of TimeVQVAE in producingrepresentative synthetic trajectories for downstream tasks such as modeltraining, airspace design, and air traffic forecasting.</description>
      <author>example@mail.com (Abdulmajid Murad, Massimiliano Ruocco)</author>
      <guid isPermaLink="false">2504.09101v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised learning of non-Abelian multi-gap topological phases</title>
      <link>http://arxiv.org/abs/2504.09198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近实验成功实现了具有时间反演对称性的多带非阿贝尔拓扑绝缘体。它们的拓扑分类超越了传统的十倍分类，需要使用非阿贝尔群，表现出不能用整数拓扑不变量描述的新特性。&lt;h4&gt;背景&lt;/h4&gt;非阿贝尔群的唯一非交换乘积以及同伦分类（带或不带固定基点）的独特性，使得不同非阿贝尔拓扑相的识别比阿贝尔情况下更加复杂和具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;本工作提出了一种基于扩散映射的无监督学习方法，用于分类非阿贝尔多能隙拓扑相。&lt;h4&gt;方法&lt;/h4&gt;该方法通过自动绝热路径寻找过程，能够正确对属于同一相的样本进行排序，即使这些样本在样本集中没有通过绝热路径连接。更重要的是，该方法能够以数据驱动的方式推断非阿贝尔拓扑电荷的乘法表，而不需要先验知识。此外，该算法可以提供同伦（带或不带固定基点）样本的正确分类。&lt;h4&gt;主要发现&lt;/h4&gt;该方法可以正确识别非阿贝尔拓扑相，即使它们之间没有绝热路径连接，并且可以数据驱动地推断拓扑电荷的乘法表。&lt;h4&gt;结论&lt;/h4&gt;这些结果为使用机器学习方法研究非阿贝尔相的未来研究提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent experiments have successfully realized multi-band non-Abelian topological insulators with parity-time symmetry. Their topological classification transcends the conventional ten-fold classification, necessitating the use of non-Abelian groups, manifesting novel properties that cannot be described using integer topological invariants. The unique non-commutative multiplication of non-Abelian groups, along with the distinct topological classifications in the context of homotopy with or without a fixed base point, makes the identification of different non-Abelian topological phases more nuanced and challenging than in the Abelian case. In this work, we present an unsupervised learning method based on diffusion maps to classify non-Abelian multi-gap topological phases. The automatic adiabatic pathfinding process in our method can correctly sort the samples in the same phase even though they are not connected by adiabatic paths in the sample set. Most importantly, our method can deduce the multiplication table of the non-Abelian topological charges in a data-driven manner without requiring extit{a priori} knowledge. Additionally, our algorithm can provide the correct classifications for the samples within both the homotopy with and without a fixed base point. Our results provide insights for future studies on non-Abelian phase studies using machine learning approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent experiments have successfully realized multi-band non-Abeliantopological insulators with parity-time symmetry. Their topologicalclassification transcends the conventional ten-fold classification,necessitating the use of non-Abelian groups, manifesting novel properties thatcannot be described using integer topological invariants. The uniquenon-commutative multiplication of non-Abelian groups, along with the distincttopological classifications in the context of homotopy with or without a fixedbase point, makes the identification of different non-Abelian topologicalphases more nuanced and challenging than in the Abelian case. In this work, wepresent an unsupervised learning method based on diffusion maps to classifynon-Abelian multi-gap topological phases. The automatic adiabatic pathfindingprocess in our method can correctly sort the samples in the same phase eventhough they are not connected by adiabatic paths in the sample set. Mostimportantly, our method can deduce the multiplication table of the non-Abeliantopological charges in a data-driven manner without requiring \textit{a priori}knowledge. Additionally, our algorithm can provide the correct classificationsfor the samples within both the homotopy with and without a fixed base point.Our results provide insights for future studies on non-Abelian phase studiesusing machine learning approaches.</description>
      <author>example@mail.com (Xiangxu He, Ruo-Yang Zhang, Xiaohan Cui, Lei Zhang, C. T. Chan)</author>
      <guid isPermaLink="false">2504.09198v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>FairACE: Achieving Degree Fairness in Graph Neural Networks via Contrastive and Adversarial Group-Balanced Training</title>
      <link>http://arxiv.org/abs/2504.09210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FairACE的新型图神经网络框架，旨在解决图神经网络中存在的公平性问题，通过不对称对比学习和对抗训练来提高不同度数节点的预测公平性。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）中，度数偏差经常导致不同度数节点的预测性能不平等，现有模型主要关注预测精度，而忽略了不同度数组之间的公平性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出FairACE框架，旨在提高图神经网络中不同度数节点的预测公平性。&lt;h4&gt;方法&lt;/h4&gt;FairACE通过集成不对称对比学习和对抗训练来改进度数公平性，同时捕捉一跳局部邻域信息和两跳单边相似性，并采用度数公平性调节器来平衡高度和低度节点的性能。在模型训练过程中，提出了一个新的组平衡公平损失函数，以最小化不同度数组之间的分类差异。此外，还提出了一种新的公平性度量指标——准确度分布差距（ADG），可以定量评估并确保不同度数节点组的公平性能。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实世界数据集上的实验结果表明，FairACE在提高度数公平性指标的同时，与最先进的GNN模型相比，保持了有竞争力的精度。&lt;h4&gt;结论&lt;/h4&gt;FairACE是一种有效的图神经网络框架，能够显著提高不同度数节点的预测公平性，同时保持高精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：公平性一直是图神经网络（GNNs）的一个重要挑战，因为度数偏差通常会导致不同度数节点的预测性能不平等。现有的GNN模型主要关注预测精度，常常忽略了不同度数组之间的公平性。为了解决这个问题，我们提出了一种名为Fairness-Aware Asymmetric Contrastive Ensemble（FairACE）的新颖GNN框架，该框架将不对称对比学习和对抗训练集成在一起，以提高度数公平性。FairACE捕捉了一跳局部邻域信息和两跳单边相似性，以创建更公平的节点表示，并采用度数公平性调节器来平衡高度和低度节点的性能。在模型训练期间，提出了一种新的组平衡公平损失，以最小化不同度数组之间的分类差异。此外，我们还提出了一种新的公平性度量指标，即准确度分布差距（ADG），它可以定量评估并确保不同度数节点组的公平性能。在合成和真实世界数据集上的实验结果表明，与最先进的GNN模型相比，FairACE在提高度数公平性指标的同时，保持了有竞争力的精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fairness has been a significant challenge in graph neural networks (GNNs)since degree biases often result in un-equal prediction performance among nodeswith varying degrees. Existing GNN models focus on prediction accuracy,frequently overlooking fairness across different degree groups. To addressthisissue, we propose a novel GNN framework, namely Fairness- Aware AsymmetricContrastive Ensemble (FairACE), which inte-grates asymmetric contrastivelearning with adversarial training to improve degree fairness. FairACE capturesone-hop local neighborhood information and two-hop monophily similarity tocreate fairer node representations and employs a degree fairness regulator tobalance performance between high-degree and low-degree nodes. During modeltraining, a novel group-balanced fairness loss is proposed to minimizeclassification disparities across degree groups. In addition, we also propose anovel fairness metric, the Accuracy Distribution Gap (ADG), which canquantitatively assess and ensure equitable performance across differentdegree-based node groups. Experimental results on both synthetic and real-worlddatasets demonstrate that FairACE significantly improves degree fairnessmetrics while maintaining competitive accuracy in comparison to thestate-of-the-art GNN models.</description>
      <author>example@mail.com (Jiaxin Liu, Xiaoqian Jiang, Cangqi Zhou, Jing Zhang)</author>
      <guid isPermaLink="false">2504.09210v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Graph Learning-Driven Multi-Vessel Association: Fusing Multimodal Data for Maritime Intelligence</title>
      <link>http://arxiv.org/abs/2504.09197v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图学习的多船关联（GMvA）方法，用于解决海事多模态数据融合中的挑战，如数据维度差异、目标计数不匹配、船舶规模变化、遮挡和来自AIS和CCTV等系统的异步数据流。&lt;h4&gt;背景&lt;/h4&gt;随着航道变得越来越拥挤和复杂，确保海事安全和优化交通管理需要有效的航道监控。当前方法在处理多模态数据时面临挑战，尤其是在交通密集的航道中。&lt;h4&gt;目的&lt;/h4&gt;提出GMvA方法以克服上述挑战，实现海事多模态数据的有效融合。&lt;h4&gt;方法&lt;/h4&gt;GMvA方法通过整合AIS和CCTV数据，利用时间序列学习和图神经网络来捕捉船舶轨迹的时空特征。该方法还引入了时间图注意力和时空注意力，以增强特征表示，并使用多层感知器计算鲁棒的相似度分数。此外，采用匈牙利算法确保全局一致和准确的目标匹配。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界的海事数据集上的实验表明，GMvA在多目标关联方面表现出优异的准确性和鲁棒性，即使在船舶密度高、AIS和CCTV数据不完整或不均匀分布的挑战场景中也优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;GMvA方法为海事多模态数据融合提供了一种有效的解决方案，能够提高航道监控的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;Ensuring maritime safety and optimizing traffic management in increasingly crowded and complex waterways require effective waterway monitoring. However, current methods struggle with challenges arising from multimodal data, such as dimensional disparities, mismatched target counts, vessel scale variations, occlusions, and asynchronous data streams from systems like the automatic identification system (AIS) and closed-circuit television (CCTV). Traditional multi-target association methods often struggle with these complexities, particularly in densely trafficked waterways. To overcome these issues, we propose a graph learning-driven multi-vessel association (GMvA) method tailored for maritime multimodal data fusion. By integrating AIS and CCTV data, GMvA leverages time series learning and graph neural networks to capture the spatiotemporal features of vessel trajectories effectively. To enhance feature representation, the proposed method incorporates temporal graph attention and spatiotemporal attention, effectively capturing both local and global vessel interactions. Furthermore, a multi-layer perceptron-based uncertainty fusion module computes robust similarity scores, and the Hungarian algorithm is adopted to ensure globally consistent and accurate target matching. Extensive experiments on real-world maritime datasets confirm that GMvA delivers superior accuracy and robustness in multi-target association, outperforming existing methods even in challenging scenarios with high vessel density and incomplete or unevenly distributed AIS and CCTV data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring maritime safety and optimizing traffic management in increasinglycrowded and complex waterways require effective waterway monitoring. However,current methods struggle with challenges arising from multimodal data, such asdimensional disparities, mismatched target counts, vessel scale variations,occlusions, and asynchronous data streams from systems like the automaticidentification system (AIS) and closed-circuit television (CCTV). Traditionalmulti-target association methods often struggle with these complexities,particularly in densely trafficked waterways. To overcome these issues, wepropose a graph learning-driven multi-vessel association (GMvA) method tailoredfor maritime multimodal data fusion. By integrating AIS and CCTV data, GMvAleverages time series learning and graph neural networks to capture thespatiotemporal features of vessel trajectories effectively. To enhance featurerepresentation, the proposed method incorporates temporal graph attention andspatiotemporal attention, effectively capturing both local and global vesselinteractions. Furthermore, a multi-layer perceptron-based uncertainty fusionmodule computes robust similarity scores, and the Hungarian algorithm isadopted to ensure globally consistent and accurate target matching. Extensiveexperiments on real-world maritime datasets confirm that GMvA delivers superioraccuracy and robustness in multi-target association, outperforming existingmethods even in challenging scenarios with high vessel density and incompleteor unevenly distributed AIS and CCTV data.</description>
      <author>example@mail.com (Yuxu Lu, Kaisen Yang, Dong Yang, Haifeng Ding, Jinxian Weng, Ryan Wen Liu)</author>
      <guid isPermaLink="false">2504.09197v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Embodied Chain of Action Reasoning with Multi-Modal Foundation Model for Humanoid Loco-manipulation</title>
      <link>http://arxiv.org/abs/2504.09532v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于基础模型的新框架，用于使类人机器人能够从文本指令中自主规划行动，以执行复杂的非结构化环境中的行走和操作任务。&lt;h4&gt;背景&lt;/h4&gt;在复杂、非结构化环境中使类人机器人自主执行行走和操作任务具有重大挑战，这要求机器人具备在长时间范围内规划行动的能力，并利用多模态技术来弥合高级规划和实际任务执行之间的差距。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够从文本指令中自主规划行动的方法，以帮助类人机器人在非结构化环境中执行行走和操作任务。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了类人机器人特有的思维链方法，包括详细的可用性和身体运动分析，将任务分解为一系列行走和操作动作。此外，它还整合了基于观察和目标物体属性的空间推理，以有效地导航到可能看不见或被遮挡的目标位置。&lt;h4&gt;主要发现&lt;/h4&gt;通过严格的实验设置，在现实世界环境中对物体重新排列、操作和行走和操作任务进行了评估，证明了该方法在分离上半身和下半身控制方面的有效性，并展示了机器人行动推理策略在理解人类指令方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法在提高类人机器人在复杂环境中的自主操作能力方面具有潜力，尤其是在理解人类指令并执行相应的行动方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Enabling humanoid robots to autonomously perform loco-manipulation tasks incomplex, unstructured environments poses significant challenges. This entailsequipping robots with the capability to plan actions over extended horizonswhile leveraging multi-modality to bridge gaps between high-level planning andactual task execution. Recent advancements in multi-modal foundation modelshave showcased substantial potential in enhancing planning and reasoningabilities, particularly in the comprehension and processing of semanticinformation for robotic control tasks. In this paper, we introduce a novelframework based on foundation models that applies the embodied chain of actionreasoning methodology to autonomously plan actions from textual instructionsfor humanoid loco-manipulation. Our method integrates humanoid-specific chainof thought methodology, including detailed affordance and body movementanalysis, which provides a breakdown of the task into a sequence of locomotionand manipulation actions. Moreover, we incorporate spatial reasoning based onthe observation and target object properties to effectively navigate wheretarget position may be unseen or occluded. Through rigorous experimental setupson object rearrangement, manipulations and loco-manipulation tasks on areal-world environment, we evaluate our method's efficacy on the decoupledupper and lower body control and demonstrate the effectiveness of the chain ofrobotic action reasoning strategies in comprehending human instructions.</description>
      <author>example@mail.com (Yu Hao, Geeta Chandra Raju Bethala, Niraj Pudasaini, Hao Huang, Shuaihang Yuan, Congcong Wen, Baoru Huang, Anh Nguyen, Yi Fang)</author>
      <guid isPermaLink="false">2504.09532v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>HyperCore: The Core Framework for Building Hyperbolic Foundation Models with Comprehensive Modules</title>
      <link>http://arxiv.org/abs/2504.08912v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HyperCore，一个用于构建跨多种模态的球面基础模型的全面开源框架。&lt;h4&gt;背景&lt;/h4&gt;球面神经网络成为建模跨多种模态层次数据的强大工具，研究表明球面空间比欧几里得空间更适合许多预训练和下游任务。&lt;h4&gt;目的&lt;/h4&gt;解决现有工具缺乏构建球面基础模型所需核心组件的问题，以利用最新的进展。&lt;h4&gt;方法&lt;/h4&gt;HyperCore提供核心模块，可轻松组合以开发新的球面基础模型，无需从头开始大量修改欧几里得模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LViT优于其欧几里得对应版本，并且HyperCore在球面GNNs、CNNs、Transformers和视觉Transformer中具有优势。&lt;h4&gt;结论&lt;/h4&gt;HyperCore框架可以有效地促进球面神经网络的发展和应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：双曲神经网络已成为跨多种模态建模层次数据的强大工具。近期研究表明，基础模型中的词分布表现出无标度特性，这表明球面空间比欧几里得空间更适合许多预训练和下游任务。然而，现有的工具缺乏构建球面基础模型所需的核心组件，这使得利用最新的进展变得困难。我们引入了HyperCore，这是一个全面的开源框架，它为在多个模态上构建球面基础模型提供了核心模块。HyperCore的模块可以轻松组合以开发新的球面基础模型，无需从头开始大量修改欧几里得模块，从而避免了可能的研究冗余。为了展示其多功能性，我们构建并测试了第一个完全球面的视觉Transformer（LViT）以及一个微调管道，第一个完全球面的多模态CLIP模型（L-CLIP）和一个混合的Graph RAG，它具有球面图编码器。我们的实验表明，LViT优于其欧几里得对应版本。此外，我们还对球面GNNs、CNNs、Transformers和视觉Transformer的实验进行了基准测试和重现，以突出HyperCore的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperbolic neural networks have emerged as a powerful tool for modelinghierarchical data across diverse modalities. Recent studies show that tokendistributions in foundation models exhibit scale-free properties, suggestingthat hyperbolic space is a more suitable ambient space than Euclidean space formany pre-training and downstream tasks. However, existing tools lack essentialcomponents for building hyperbolic foundation models, making it difficult toleverage recent advancements. We introduce HyperCore, a comprehensiveopen-source framework that provides core modules for constructing hyperbolicfoundation models across multiple modalities. HyperCore's modules can beeffortlessly combined to develop novel hyperbolic foundation models,eliminating the need to extensively modify Euclidean modules from scratch andpossible redundant research efforts. To demonstrate its versatility, we buildand test the first fully hyperbolic vision transformers (LViT) with afine-tuning pipeline, the first fully hyperbolic multimodal CLIP model(L-CLIP), and a hybrid Graph RAG with a hyperbolic graph encoder. Ourexperiments demonstrate that LViT outperforms its Euclidean counterpart.Additionally, we benchmark and reproduce experiments across hyperbolic GNNs,CNNs, Transformers, and vision Transformers to highlight HyperCore'sadvantages.</description>
      <author>example@mail.com (Neil He, Menglin Yang, Rex Ying)</author>
      <guid isPermaLink="false">2504.08912v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs</title>
      <link>http://arxiv.org/abs/2504.09504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE International Conference on Multimedia &amp; Expo 2025  (ICME 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MADLLM的多变量异常检测方法，通过预训练的大型语言模型来解决异常检测任务中的多变量时间序列与语言模型文本模态不匹配的问题。&lt;h4&gt;背景&lt;/h4&gt;在将预训练的大型语言模型应用于异常检测任务时，多变量时间序列（MTS）模态与语言模型的文本模态不匹配，现有方法简单地将MTS数据转换为多个单变量时间序列序列，这可能导致许多问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的三重编码技术，以将MTS模态与LLMs的文本模态对齐，从而提高异常检测的准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了传统的补丁嵌入方法以及两种新的嵌入方法：跳过嵌入和特征嵌入。跳过嵌入通过改变传统方法中补丁处理的顺序，帮助LLMs保留先前特征的知识；特征嵌入利用对比学习，使模型更好地理解不同特征之间的相关性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在各种公共异常检测数据集上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;MADLLM方法在多变量异常检测任务中表现优异，为解决LLMs在处理MTS数据时的模态不匹配问题提供了一种有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When applying pre-trained large language models (LLMs) to address anomalydetection tasks, the multivariate time series (MTS) modality of anomalydetection does not align with the text modality of LLMs. Existing methodssimply transform the MTS data into multiple univariate time series sequences,which can cause many problems. This paper introduces MADLLM, a novelmultivariate anomaly detection method via pre-trained LLMs. We design a newtriple encoding technique to align the MTS modality with the text modality ofLLMs. Specifically, this technique integrates the traditional patch embeddingmethod with two novel embedding approaches: Skip Embedding, which alters theorder of patch processing in traditional methods to help LLMs retain knowledgeof previous features, and Feature Embedding, which leverages contrastivelearning to allow the model to better understand the correlations betweendifferent features. Experimental results demonstrate that our methodoutperforms state-of-the-art methods in various public anomaly detectiondatasets.</description>
      <author>example@mail.com (Wei Tao, Xiaoyang Qu, Kai Lu, Jiguang Wan, Guokuan Li, Jianzong Wang)</author>
      <guid isPermaLink="false">2504.09504v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>MASH: Masked Anchored SpHerical Distances for 3D Shape Representation and Generation</title>
      <link>http://arxiv.org/abs/2504.09149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 11 figures, SIGGRAPH 2025 Accept - Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MASH的新颖的多视角和参数化3D形状表示方法。&lt;h4&gt;背景&lt;/h4&gt;受多视图几何的启发，并鉴于感知形状理解对学习3D形状的重要性。&lt;h4&gt;目的&lt;/h4&gt;将3D形状表示为一系列可观察的局部表面补丁的集合。&lt;h4&gt;方法&lt;/h4&gt;使用球谐函数的紧凑性来编码MASH函数，并结合具有参数化基的广义视锥体，以局部化球面函数的空间范围。&lt;h4&gt;主要发现&lt;/h4&gt;开发了一种可微优化算法，可以将任何点云转换为MASH表示，该表示能够准确近似具有任意几何和拓扑的地面真实表面。&lt;h4&gt;结论&lt;/h4&gt;MASH在多个应用中表现出优越的性能，包括表面重建、形状生成、补全和混合，这得益于其独特的表示，涵盖了隐式和显式特征。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了一种名为MASH的新颖的多视角和参数化3D形状表示方法。受多视图几何的启发，并鉴于感知形状理解对学习3D形状的重要性，MASH将3D形状表示为一系列可观察的局部表面补丁的集合。我们进一步利用球谐函数的紧凑性来编码MASH函数，并结合具有参数化基的广义视锥体，以局部化球面函数的空间范围。我们开发了一种可微优化算法，可以将任何点云转换为MASH表示，该表示能够准确近似具有任意几何和拓扑的地面真实表面。大量实验表明，MASH在多个应用中表现出优越的性能，包括表面重建、形状生成、补全和混合，这得益于其独特的表示，涵盖了隐式和显式特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Masked Anchored SpHerical Distances (MASH), a novel multi-viewand parametrized representation of 3D shapes. Inspired by multi-view geometryand motivated by the importance of perceptual shape understanding for learning3D shapes, MASH represents a 3D shape as a collection of observable localsurface patches, each defined by a spherical distance function emanating froman anchor point. We further leverage the compactness of spherical harmonics toencode the MASH functions, combined with a generalized view cone with aparameterized base that masks the spatial extent of the spherical function toattain locality. We develop a differentiable optimization algorithm capable ofconverting any point cloud into a MASH representation accurately approximatingground-truth surfaces with arbitrary geometry and topology. Extensiveexperiments demonstrate that MASH is versatile for multiple applicationsincluding surface reconstruction, shape generation, completion, and blending,achieving superior performance thanks to its unique representation encompassingboth implicit and explicit features.</description>
      <author>example@mail.com (Changhao Li, Yu Xin, Xiaowei Zhou, Ariel Shamir, Hao Zhang, Ligang Liu, Ruizhen Hu)</author>
      <guid isPermaLink="false">2504.09149v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Additive Parameter Updates of Vision Transformers for Few-Shot Continual Learning</title>
      <link>http://arxiv.org/abs/2504.08982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的FSCIL框架，通过冻结预训练的ViT参数并使用参数高效的增量更新机制，解决了增量学习中的灾难性遗忘问题。&lt;h4&gt;背景&lt;/h4&gt;在人工智能中，整合新类别信息而不丢失先前获得的知识是一个核心挑战，通常被称为灾难性遗忘。&lt;h4&gt;目的&lt;/h4&gt;解决增量学习中的灾难性遗忘问题，提出一种新的FSCIL框架。&lt;h4&gt;方法&lt;/h4&gt;冻结预训练的ViT参数，通过添加更新机制选择性地将可训练权重注入到自注意力模块中，仅更新一小部分参数以适应新类别。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在基准数据集上实现了与基线FSCIL方法相比的最优性能。&lt;h4&gt;结论&lt;/h4&gt;通过冻结ViT参数和参数高效的增量更新，该框架能够有效减少过拟合风险，同时避免覆盖先前学习到的知识。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在人工智能中，整合新类别信息而不丢失先前获得的知识仍然是一个核心挑战，通常被称为灾难性遗忘。少量样本类别增量学习（FSCIL）通过首先在基类稳健数据集上训练模型，然后在连续会话中仅使用少量每个新类别的标记示例来增量适应模型来解决此问题。然而，这种方法容易在有限的新数据上过拟合，这可能会损害整体性能并加剧遗忘。在这项工作中，我们提出了一种简单而有效的FSCIL新框架，该框架利用冻结的视觉Transformer（ViT）骨干网络，并辅以参数高效的增量更新。我们的方法冻结了预训练的ViT参数，并通过添加更新机制选择性地将可训练权重注入到自注意力模块中。这种设计仅更新一小部分参数以适应新类别，而不牺牲基会话期间学习到的表示。通过微调有限数量的参数，我们的方法在冻结的ViT中保留了可推广的特征，同时降低了过拟合的风险。此外，由于大多数参数保持不变，当引入小的新的数据批次时，模型避免了覆盖先前学习到的知识。在基准数据集上的大量实验表明，与基线FSCIL方法相比，我们的方法实现了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating new class information without losing previously acquiredknowledge remains a central challenge in artificial intelligence, oftenreferred to as catastrophic forgetting. Few-shot class incremental learning(FSCIL) addresses this by first training a model on a robust dataset of baseclasses and then incrementally adapting it in successive sessions using only afew labeled examples per novel class. However, this approach is prone tooverfitting on the limited new data, which can compromise overall performanceand exacerbate forgetting. In this work, we propose a simple yet effectivenovel FSCIL framework that leverages a frozen Vision Transformer (ViT) backboneaugmented with parameter-efficient additive updates. Our approach freezes thepre-trained ViT parameters and selectively injects trainable weights into theself-attention modules via an additive update mechanism. This design updatesonly a small subset of parameters to accommodate new classes withoutsacrificing the representations learned during the base session. By fine-tuninga limited number of parameters, our method preserves the generalizable featuresin the frozen ViT while reducing the risk of overfitting. Furthermore, as mostparameters remain fixed, the model avoids overwriting previously learnedknowledge when small novel data batches are introduced. Extensive experimentson benchmark datasets demonstrate that our approach yields state-of-the-artperformance compared to baseline FSCIL methods.</description>
      <author>example@mail.com (Kyle Stein, Andrew Arash Mahyari, Guillermo Francia III, Eman El-Sheikh)</author>
      <guid isPermaLink="false">2504.08982v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Towards On-Device Learning and Reconfigurable Hardware Implementation for Encoded Single-Photon Signal Processing</title>
      <link>http://arxiv.org/abs/2504.09028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 8 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于OSOS-ELM的在线训练算法，用于提高深度神经网络从时间分辨光子到达信号中重构关键参数的准确性和效率，同时优化了硬件资源利用。&lt;h4&gt;背景&lt;/h4&gt;传统的基于反向传播的深度神经网络在重构关键参数时对光学设置和生物样本参数非常敏感，需要频繁重新训练，且数据存储和传输引入了延迟和存储开销。&lt;h4&gt;目的&lt;/h4&gt;提出一种在线训练算法，解决传统DNNs性能依赖参数和频繁重新训练的问题，并提高硬件效率。&lt;h4&gt;方法&lt;/h4&gt;采用基于One-Sided Jacobi旋转的在线序列极端学习机（OSOS-ELM）算法，利用FPGA的异构并行处理能力，并实现了一种整体的计算原型。&lt;h4&gt;主要发现&lt;/h4&gt;OSOS-ELM和OSELM在不同网络维度上达到可比的准确度，且OSOS-ELM更具有硬件效率。通过案例研究验证了算法的有效性，并在Xilinx ZCU104 FPGA上实现了整体计算原型。&lt;h4&gt;结论&lt;/h4&gt;OSOS-ELM算法能够有效提高深度神经网络重构关键参数的性能，并通过硬件优化进一步提升了计算效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes an online training algorithm based on OSOS-ELM to improve the accuracy and efficiency of reconstructing key parameters from time-resolved photon arrival signals using deep neural networks. The algorithm addresses the issues of performance dependence on optical setup and biological sample parameters in conventional DNNs, which require frequent retraining. By leveraging the parallel processing capabilities of heterogeneous FPGAs, the proposed algorithm optimizes hardware resource utilization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks (DNNs) enhance the accuracy and efficiency ofreconstructing key parameters from time-resolved photon arrival signalsrecorded by single-photon detectors. However, the performance of conventionalbackpropagation-based DNNs is highly dependent on various parameters of theoptical setup and biological samples under examination, necessitating frequentnetwork retraining, either through transfer learning or from scratch. Newlycollected data must also be stored and transferred to a high-performance GPUserver for retraining, introducing latency and storage overhead. To addressthese challenges, we propose an online training algorithm based on a One-SidedJacobi rotation-based Online Sequential Extreme Learning Machine (OSOS-ELM). Wefully exploit parallelism in executing OSOS-ELM on a heterogeneous FPGA withintegrated ARM cores. Extensive evaluations of OSOS-ELM and OSELM demonstratethat both achieve comparable accuracy across different network dimensions(i.e., input, hidden, and output layers), while OSOS-ELM proves to be morehardware-efficient. By leveraging the parallelism of OSOS-ELM, we implement aholistic computing prototype on a Xilinx ZCU104 FPGA, which integrates amulti-core CPU and programmable logic fabric. We validate our approach throughthree case studies involving single-photon signal analysis: sensing through fogusing commercial single-photon LiDAR, fluorescence lifetime estimation in FLIM,and blood flow index reconstruction in DCS, all utilizing one-dimensional dataencoded from photonic signals. From a hardware perspective, we optimize theOSOS-ELM workload by employing multi-tasked processing on ARM CPU cores andpipelined execution on the FPGA's logic fabric. We also implement our OSOS-ELMon the NVIDIA Jetson Xavier NX GPU to comprehensively investigate its computingperformance on another type of heterogeneous computing platform.</description>
      <author>example@mail.com (Zhenya Zang, Xingda Li, David Day Uei Li)</author>
      <guid isPermaLink="false">2504.09028v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>A Constrained Optimization Approach for Gaussian Splatting from Coarsely-posed Images and Noisy Lidar Point Clouds</title>
      <link>http://arxiv.org/abs/2504.09129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于约束优化的3D Gaussian Splatting (3DGS)方法，用于同时估计相机姿态和进行3D重建，无需依赖SfM算法。&lt;h4&gt;背景&lt;/h4&gt;3DGS是一种强大的重建技术，但需要从精确的相机姿态和高保真点云中进行初始化。通常，初始化来自SfM算法，但SfM过程耗时且限制了3DGS在现实场景和大规模场景重建中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要SfM支持的3DGS初始化方法，以提高重建效率和适用性。&lt;h4&gt;方法&lt;/h4&gt;将相机姿态分解为相机到（设备）中心和（设备）中心到世界的优化序列。提出两个优化约束，根据每个参数组的敏感性来限制搜索空间。直接从噪声点云中学习场景几何，并引入几何约束以提高重建质量。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在收集的数据集和两个公开基准测试上，都显著优于现有的3DGS基线和补充COLMAP的方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效地进行3DGS的初始化，无需SfM支持，且重建质量优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) is a powerful reconstruction technique, but itneeds to be initialized from accurate camera poses and high-fidelity pointclouds. Typically, the initialization is taken from Structure-from-Motion (SfM)algorithms; however, SfM is time-consuming and restricts the application of3DGS in real-world scenarios and large-scale scene reconstruction. We introducea constrained optimization method for simultaneous camera pose estimation and3D reconstruction that does not require SfM support. Core to our approach isdecomposing a camera pose into a sequence of camera-to-(device-)center and(device-)center-to-world optimizations. To facilitate, we propose twooptimization constraints conditioned to the sensitivity of each parameter groupand restricts each parameter's search space. In addition, as we learn the scenegeometry directly from the noisy point clouds, we propose geometric constraintsto improve the reconstruction quality. Experiments demonstrate that theproposed method significantly outperforms the existing (multi-modal) 3DGSbaseline and methods supplemented by COLMAP on both our collected dataset andtwo public benchmarks.</description>
      <author>example@mail.com (Jizong Peng, Tze Ho Elden Tse, Kai Xu, Wenchao Gao, Angela Yao)</author>
      <guid isPermaLink="false">2504.09129v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>PCM-SAR: Physics-Driven Contrastive Mutual Learning for SAR Classification</title>
      <link>http://arxiv.org/abs/2504.09502v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于物理驱动的对比互学习SAR图像分类方法PCM-SAR，旨在解决现有方法在SAR数据样本生成和特征提取上的不足。&lt;h4&gt;背景&lt;/h4&gt;现有的基于对比学习的SAR图像分类方法常常依赖于为光学图像设计的样本生成策略，未能充分捕捉SAR数据的独特语义和物理特征。&lt;h4&gt;目的&lt;/h4&gt;提出PCM-SAR方法，通过结合领域特定的物理洞察力，改善样本生成和特征提取过程。&lt;h4&gt;方法&lt;/h4&gt;PCM-SAR利用灰度共生矩阵（GLCM）模拟真实的噪声模式，并应用语义检测进行无监督的局部采样，以确保生成的样本准确反映SAR成像特性。此外，采用基于互学习的多级特征融合机制，实现特征表示的协作优化。PCM-SAR通过细化SAR特征表示，显著提升了小型模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;PCM-SAR在多个数据集和SAR分类任务上，一致优于现有最先进（SOTA）的方法。&lt;h4&gt;结论&lt;/h4&gt;PCM-SAR方法有效提高了SAR图像分类的性能，尤其是在处理小型模型时，能够补偿其有限的容量。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a physics-driven contrastive mutual learning method, PCM-SAR, for SAR image classification. PCM-SAR addresses the limitations of existing methods by incorporating domain-specific physical insights to improve sample generation and feature extraction. Utilizing the gray-level co-occurrence matrix (GLCM) and semantic detection, PCM-SAR ensures that the generated samples accurately reflect SAR imaging properties. Furthermore, a multi-level feature fusion mechanism based on mutual learning refines feature representations collaboratively. Notably, PCM-SAR significantly enhances the performance of smaller models by refining SAR feature representations, compensating for their limited capacity. Experimental results demonstrate that PCM-SAR consistently outperforms state-of-the-art (SOTA) methods across diverse datasets and SAR classification tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing SAR image classification methods based on Contrastive Learning oftenrely on sample generation strategies designed for optical images, failing tocapture the distinct semantic and physical characteristics of SAR data. Toaddress this, we propose Physics-Driven Contrastive Mutual Learning for SARClassification (PCM-SAR), which incorporates domain-specific physical insightsto improve sample generation and feature extraction. PCM-SAR utilizes thegray-level co-occurrence matrix (GLCM) to simulate realistic noise patterns andapplies semantic detection for unsupervised local sampling, ensuring generatedsamples accurately reflect SAR imaging properties. Additionally, a multi-levelfeature fusion mechanism based on mutual learning enables collaborativerefinement of feature representations. Notably, PCM-SAR significantly enhancessmaller models by refining SAR feature representations, compensating for theirlimited capacity. Experimental results show that PCM-SAR consistentlyoutperforms SOTA methods across diverse datasets and SAR classification tasks.</description>
      <author>example@mail.com (Pengfei Wang, Hao Zheng, Zhigang Hu, Aikun Xu, Meiguang Zheng, Liu Yang)</author>
      <guid isPermaLink="false">2504.09502v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.06958v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了使用强化学习中的RFT（Reinforcement Fine-Tuning）和GRPO（Group Relative Policy Optimization）方法，对视频多模态大语言模型（MLLMs）进行系统性的探索，旨在提升时空感知能力的同时保持通用能力。&lt;h4&gt;背景&lt;/h4&gt;近年来，强化学习在多模态大语言模型（MLLMs）的推理能力方面取得了显著进展。然而，GRPO和基于规则的奖励机制在文本和图像领域表现出潜力，但在视频理解领域的应用仍然有限。&lt;h4&gt;目的&lt;/h4&gt;通过RFT方法，提升视频MLLMs的时空感知能力，同时保持其通用能力。&lt;h4&gt;方法&lt;/h4&gt;论文通过在时空感知目标上进行多任务RFT，并在有限的样本下进行实验，开发出VideoChat-R1，这是一种强大的视频MLLM，在时空感知任务上达到了最先进的性能，同时不牺牲聊天能力，并展现出时空推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;VideoChat-R1在时空定位（+31.8）和对象跟踪（+31.2）等任务上，相比于Qwen2.5-VL-7B提升了数倍性能。此外，它在VideoMME（+0.9）、MVBench（+1.0）和感知测试（+0.9）等通用QAbenchmarks上也显著改进。&lt;h4&gt;结论&lt;/h4&gt;RFT对于视频MLLMs的特定任务增强具有潜力，研究结果为未来视频MLLMs的RL研究提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a systematic exploration of Reinforcement Fine-Tuning (RFT) with Group Relative Policy Optimization (GRPO) for video multimodal large language models (MLLMs), aiming to enhance spatio-temporal perception while maintaining general capabilities. Our experiments reveal that RFT is highly data-efficient for task-specific improvements. Through multi-task RFT on spatio-temporal perception objectives with limited samples, we develop VideoChat-R1, a powerful video MLLM that achieves state-of-the-art performance on spatio-temporal perception tasks without sacrificing chat ability, while exhibiting emerging spatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1 boosts performance several-fold in tasks like temporal grounding (+31.8) and object tracking (+31.2). Additionally, it significantly improves on general QAbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9). Our findings underscore the potential of RFT for specialized task enhancement of Video MLLMs. We hope our work offers valuable insights for future RL research in video MLLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in reinforcement learning have significantly advanced thereasoning capabilities of multimodal large language models (MLLMs). Whileapproaches such as Group Relative Policy Optimization (GRPO) and rule-basedreward mechanisms demonstrate promise in text and image domains, theirapplication to video understanding remains limited. This paper presents asystematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for videoMLLMs, aiming to enhance spatio-temporal perception while maintaining generalcapabilities. Our experiments reveal that RFT is highly data-efficient fortask-specific improvements. Through multi-task RFT on spatio-temporalperception objectives with limited samples, we develop VideoChat-R1, a powerfulvideo MLLM that achieves state-of-the-art performance on spatio-temporalperception tasks without sacrificing chat ability, while exhibiting emergingspatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1boosts performance several-fold in tasks like temporal grounding (+31.8) andobject tracking (+31.2). Additionally, it significantly improves on general QAbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9).Our findings underscore the potential of RFT for specialized task enhancementof Video MLLMs. We hope our work offers valuable insights for future RLresearch in video MLLMs.</description>
      <author>example@mail.com (Xinhao Li, Ziang Yan, Desen Meng, Lu Dong, Xiangyu Zeng, Yinan He, Yali Wang, Yu Qiao, Yi Wang, Limin Wang)</author>
      <guid isPermaLink="false">2504.06958v3</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Federated Prototype Graph Learning</title>
      <link>http://arxiv.org/abs/2504.09493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Federated Graph Learning (FGL)在分布式训练和隐私保护方面具有显著优势，但多级FGL异构性带来了挑战。&lt;h4&gt;背景&lt;/h4&gt;FGL在图机器智能应用中具有分布式训练能力，可以缓解数据孤岛问题，但多级FGL异构性带来了模型、数据和通信层面的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出FedPG，一种通用的原型引导优化方法，以解决多级FGL异构性问题。&lt;h4&gt;方法&lt;/h4&gt;在客户端，集成多级拓扑感知原型来捕捉局部图语义；在服务器端，利用上传的原型，采用拓扑引导的对比学习和个性化技术来定制每个客户端的全局原型，并通过广播提高局部训练。&lt;h4&gt;主要发现&lt;/h4&gt;FedPG在准确率上优于现有基准，平均提高了3.57%，同时将通信成本降低了168倍。&lt;h4&gt;结论&lt;/h4&gt;FedPG是解决多级FGL异构性问题的一种有效方法，可以提高性能并降低通信成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Federated Graph Learning (FGL) has gained significantattention for its distributed training capabilities in graph-based machineintelligence applications, mitigating data silos while offering a newperspective for privacy-preserve large-scale graph learning. However,multi-level FGL heterogeneity presents various client-server collaborationchallenges: (1) Model-level: The variation in clients for expected performanceand scalability necessitates the deployment of heterogeneous models.Unfortunately, most FGL methods rigidly demand identical client models due tothe direct model weight aggregation on the server. (2) Data-level: Theintricate nature of graphs, marked by the entanglement of node profiles andtopology, poses an optimization dilemma. This implies that models obtained byfederated training struggle to achieve superior performance. (3)Communication-level: Some FGL methods attempt to increase message sharing amongclients or between clients and the server to improve training, which inevitablyleads to high communication costs. In this paper, we propose FedPG as a generalprototype-guided optimization method for the above multi-level FGLheterogeneity. Specifically, on the client side, we integrate multi-leveltopology-aware prototypes to capture local graph semantics. Subsequently, onthe server side, leveraging the uploaded prototypes, we employ topology-guidedcontrastive learning and personalized technology to tailor global prototypesfor each client, broadcasting them to improve local training. Experimentsdemonstrate that FedPG outperforms SOTA baselines by an average of 3.57\% inaccuracy while reducing communication costs by 168x.</description>
      <author>example@mail.com (Zhengyu Wu, Xunkai Li, Yinlin Zhu, Rong-Hua Li, Guoren Wang, Chenghu Zhou)</author>
      <guid isPermaLink="false">2504.09493v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Distilling and exploiting quantitative insights from Large Language Models for enhanced Bayesian optimization of chemical reactions</title>
      <link>http://arxiv.org/abs/2504.08874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了如何从大型语言模型（LLMs）中提取化学信息用于迁移学习，以加速化学反应的优化。&lt;h4&gt;背景&lt;/h4&gt;机器学习和贝叶斯优化算法可以显著加速化学反应的优化。迁移学习可以通过利用现有化学信息或与直接优化任务无关的数据来提高贝叶斯优化算法在低数据环境下的有效性。&lt;h4&gt;目的&lt;/h4&gt;考察LLM中的化学信息如何被提取并用于迁移学习，以加速通过最大化产量来优化反应条件。&lt;h4&gt;方法&lt;/h4&gt;使用调查式的提示方案和偏好学习来推断效用函数，该效用函数模型化LLM中嵌入在化学参数空间中的先前化学信息；利用效用函数来集中在参数空间的有希望的区域内，从而提高初始贝叶斯优化查询的产量并增强优化。&lt;h4&gt;主要发现&lt;/h4&gt;效用函数与实际实验测量（产量）在参数空间中显示出适度相关性，即使在零样本设置下也是如此；利用效用函数可以增强优化在6个数据集中4个数据集的优化效果。&lt;h4&gt;结论&lt;/h4&gt;这项工作将LLM中嵌入的化学知识与原理性贝叶斯优化方法加速反应优化的能力联系起来，被视为填补这一差距的一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning and Bayesian optimization (BO) algorithms can significantlyaccelerate the optimization of chemical reactions. Transfer learning canbolster the effectiveness of BO algorithms in low-data regimes by leveragingpre-existing chemical information or data outside the direct optimization task(i.e., source data). Large language models (LLMs) have demonstrated thatchemical information present in foundation training data can give them utilityfor processing chemical data. Furthermore, they can be augmented with and helpsynthesize potentially multiple modalities of source chemical data germane tothe optimization task. In this work, we examine how chemical information fromLLMs can be elicited and used for transfer learning to accelerate the BO ofreaction conditions to maximize yield. Specifically, we show that a survey-likeprompting scheme and preference learning can be used to infer a utilityfunction which models prior chemical information embedded in LLMs over achemical parameter space; we find that the utility function shows modestcorrelation to true experimental measurements (yield) over the parameter spacedespite operating in a zero-shot setting. Furthermore, we show that the utilityfunction can be leveraged to focus BO efforts in promising regions of theparameter space, improving the yield of the initial BO query and enhancingoptimization in 4 of the 6 datasets studied. Overall, we view this work as astep towards bridging the gap between the chemistry knowledge embedded in LLMsand the capabilities of principled BO methods to accelerate reactionoptimization.</description>
      <author>example@mail.com (Roshan Patel, Saeed Moayedpour, Louis De Lescure, Lorenzo Kogler-Anele, Alan Cherney, Sven Jager, Yasser Jangjou)</author>
      <guid isPermaLink="false">2504.08874v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Application of Contrastive Learning on ECG Data: Evaluating Performance in Japanese and Classification with Around 100 Labels</title>
      <link>http://arxiv.org/abs/2504.09302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 1 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了心电图（ECG）在心血管诊断中的应用，探讨了如何利用机器学习从ECG数据中提取信息，以及如何将多模态机器学习框架应用于非英语语言的临床研究。&lt;h4&gt;背景&lt;/h4&gt;ECG是心血管诊断的基本工具，具有强大且非侵入性的特点，常用于确定是否需要更详细的检查。由于用户专业水平各异，避免关键错误变得尤为重要。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过机器学习从ECG数据中提取有价值的信息，并实现多模态模型的分类，以帮助用户避免关键错误。&lt;h4&gt;方法&lt;/h4&gt;研究者使用了来自日本医院的常规患者ECG数据，并利用对比学习框架进行分类。他们使用了一个基于日本的、具有98个标签的语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;即使在只有98个标签的情况下，基于日本的语言模型在分类准确率上与之前的研究相当，这表明了多模态机器学习框架在非英语语言临床研究中的适用性。&lt;h4&gt;结论&lt;/h4&gt;该研究扩展了多模态机器学习框架在更广泛的临床研究和非英语语言中的应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：心电图（ECG）由于其强大且非侵入性的特性，是心血管诊断的基本工具。其最关键的应用之一是确定是否需要更详细的检查，用户涵盖不同专业水平。鉴于这种专业水平的多样性，帮助用户避免关键错误至关重要。近年来，机器学习研究通过从ECG数据中提取有价值信息来解决这一挑战。利用语言模型，这些研究实现了旨在根据标记术语对ECG进行分类的多模态模型。然而，类别数量有所减少，并且这种方法是否适用于英语以外的语言还不确定。为了向实际应用迈进，我们使用了来自日本医院常规患者的ECG数据，并维护了大量从实际ECG读数中获得的日本标签。使用对比学习框架，我们发现即使有98个分类标签，我们的基于日本的语模型也实现了与先前研究相当的准确率。这项研究扩展了多模态机器学习框架在更广泛的临床研究和非英语语言中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The electrocardiogram (ECG) is a fundamental tool in cardiovasculardiagnostics due to its powerful and non-invasive nature. One of the mostcritical usages is to determine whether more detailed examinations arenecessary, with users ranging across various levels of expertise. Given thisdiversity in expertise, it is essential to assist users to avoid criticalerrors. Recent studies in machine learning have addressed this challenge byextracting valuable information from ECG data. Utilizing language models, thesestudies have implemented multimodal models aimed at classifying ECGs accordingto labeled terms. However, the number of classes was reduced, and it remainsuncertain whether the technique is effective for languages other than English.To move towards practical application, we utilized ECG data from regularpatients visiting hospitals in Japan, maintaining a large number of Japaneselabels obtained from actual ECG readings. Using a contrastive learningframework, we found that even with 98 labels for classification, ourJapanese-based language model achieves accuracy comparable to previousresearch. This study extends the applicability of multimodal machine learningframeworks to broader clinical studies and non-English languages.</description>
      <author>example@mail.com (Junichiro Takahashi, JingChuan Guan, Masataka Sato, Kaito Baba, Kazuto Haruguchi, Daichi Nagashima, Satoshi Kodera, Norihiko Takeda)</author>
      <guid isPermaLink="false">2504.09302v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Artificial Intelligence Augmented Medical Imaging Reconstruction in Radiation Therapy</title>
      <link>http://arxiv.org/abs/2504.08844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一系列基于人工智能的医学影像重建框架，旨在提升放射治疗的效果。&lt;h4&gt;背景&lt;/h4&gt;高效获取和精确重建的影像对于现代放射治疗至关重要，CT和MRI是常见的治疗规划和指导/监测手段。&lt;h4&gt;目的&lt;/h4&gt;设计AI驱动的医学影像重建框架，以提升CT图像重建的质量和速度，优化双能量CT（DECT）的多材料分解（MMD），并显著加速4D MRI的采集。&lt;h4&gt;方法&lt;/h4&gt;利用人工智能技术进行医学影像的重建。&lt;h4&gt;主要发现&lt;/h4&gt;提出的框架能够改善CT图像重建质量、提高速度、优化DECT的多材料分解以及加速4D MRI的采集。&lt;h4&gt;结论&lt;/h4&gt;AI驱动的医学影像重建框架对于增强放射治疗具有显著的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Efficiently acquired and precisely reconstructed imaging are crucial to the success of modern radiation therapy (RT). Computed tomography (CT) and magnetic resonance imaging (MRI) are two common modalities for providing RT treatment planning and delivery guidance/monitoring. In recent decades, artificial intelligence (AI) has emerged as a powerful and widely adopted technique across various fields, valued for its efficiency and convenience enabled by implicit function definition and data-driven feature representation learning. Here, we present a series of AI-driven medical imaging reconstruction frameworks for enhanced radiotherapy, designed to improve CT image reconstruction quality and speed, refine dual-energy CT (DECT) multi-material decomposition (MMD), and significantly accelerate 4D MRI acquisition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficiently acquired and precisely reconstructed imaging are crucial to thesuccess of modern radiation therapy (RT). Computed tomography (CT) and magneticresonance imaging (MRI) are two common modalities for providing RT treatmentplanning and delivery guidance/monitoring. In recent decades, artificialintelligence (AI) has emerged as a powerful and widely adopted technique acrossvarious fields, valued for its efficiency and convenience enabled by implicitfunction definition and data-driven feature representation learning. Here, wepresent a series of AI-driven medical imaging reconstruction frameworks forenhanced radiotherapy, designed to improve CT image reconstruction quality andspeed, refine dual-energy CT (DECT) multi-material decomposition (MMD), andsignificantly accelerate 4D MRI acquisition.</description>
      <author>example@mail.com (Di Xu)</author>
      <guid isPermaLink="false">2504.08844v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Generation of Musical Timbres using a Text-Guided Diffusion Model</title>
      <link>http://arxiv.org/abs/2504.09219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，文本到音频系统在直接从文本描述生成完整音频片段方面取得了显著成功，但往往限制了人类创造性和有意表达。本研究提出了一种系统，允许作曲家、编曲家和表演者创建音乐创作的基本构建块：用于电子乐器和数字音频工作站的音乐音符音频。&lt;h4&gt;背景&lt;/h4&gt;文本到音频系统在音乐创作中的应用日益广泛，但现有系统往往缺乏人类创造性和有意表达。&lt;h4&gt;目的&lt;/h4&gt;开发一种系统，使作曲家、编曲家和表演者能够创建音乐创作的基本音频构建块。&lt;h4&gt;方法&lt;/h4&gt;该系统结合了潜在扩散模型和多模态对比学习，根据文本描述生成音乐音色。该方法通过联合生成频谱图的幅度和相位，消除了后续运行相位检索算法的需要。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种基于文本描述生成音乐音色的系统，该系统通过联合生成频谱图的幅度和相位，无需额外的相位检索算法。&lt;h4&gt;结论&lt;/h4&gt;该系统为音乐创作提供了新的工具，允许用户通过文本提示指定音频的音色特征。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, text-to-audio systems have achieved remarkable success, enabling the generation of complete audio segments directly from text descriptions. While these systems also facilitate music creation, the element of human creativity and deliberate expression is often limited. In contrast, the present work allows composers, arrangers, and performers to create the basic building blocks for music creation: audio of individual musical notes for use in electronic instruments and DAWs. Through text prompts, the user can specify the timbre characteristics of the audio. We introduce a system that combines a latent diffusion model and multi-modal contrastive learning to generate musical timbres conditioned on text descriptions. By jointly generating the magnitude and phase of the spectrogram, our method eliminates the need for subsequently running a phase retrieval algorithm, as related methods do. Audio examples, source code, and a web app are available at https://wxuanyuan.github.io/Musical-Note-Generation/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, text-to-audio systems have achieved remarkable success,enabling the generation of complete audio segments directly from textdescriptions. While these systems also facilitate music creation, the elementof human creativity and deliberate expression is often limited. In contrast,the present work allows composers, arrangers, and performers to create thebasic building blocks for music creation: audio of individual musical notes foruse in electronic instruments and DAWs. Through text prompts, the user canspecify the timbre characteristics of the audio. We introduce a system thatcombines a latent diffusion model and multi-modal contrastive learning togenerate musical timbres conditioned on text descriptions. By jointlygenerating the magnitude and phase of the spectrogram, our method eliminatesthe need for subsequently running a phase retrieval algorithm, as relatedmethods do.  Audio examples, source code, and a web app are available athttps://wxuanyuan.github.io/Musical-Note-Generation/</description>
      <author>example@mail.com (Weixuan Yuan, Qadeer Khan, Vladimir Golkov)</author>
      <guid isPermaLink="false">2504.09219v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Repetitive Contrastive Learning Enhances Mamba's Selectivity in Time Series Prediction</title>
      <link>http://arxiv.org/abs/2504.09185v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Repetitive Contrastive Learning (RCL)的框架，旨在增强Mamba模型在时间序列预测中的选择性能力，并通过实验证明了其在提升模型性能方面的有效性。&lt;h4&gt;背景&lt;/h4&gt;时间序列预测是长期序列预测的关键挑战，Mamba模型虽然表现出色，但存在选择性能力不足和噪声抑制不完整的问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决Mamba模型在选择性能力上的不足，提出了RCL框架，旨在增强其选择性能力，并提高时间序列预测的性能。&lt;h4&gt;方法&lt;/h4&gt;RCL通过序列增强和对比学习，使Mamba模块能够优先考虑信息丰富的时步，同时忽略噪声。具体方法包括：对Mamba块进行预训练，并将预训练参数转移到不同的骨干模型中，以及使用高斯噪声进行序列增强。&lt;h4&gt;主要发现&lt;/h4&gt;RCL显著提升了骨干模型的性能，超越了现有方法，并达到了最先进的水平。此外，还提出了两个指标来量化Mamba的选择性能力，为RCL带来的改进提供了理论、定性和定量证据。&lt;h4&gt;结论&lt;/h4&gt;RCL框架有效增强了Mamba模型的选择性能力，显著提升了时间序列预测的性能，为该领域的研究提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long sequence prediction is a key challenge in time series forecasting. WhileMamba-based models have shown strong performance due to their sequenceselection capabilities, they still struggle with insufficient focus on criticaltime steps and incomplete noise suppression, caused by limited selectiveabilities. To address this, we introduce Repetitive Contrastive Learning (RCL),a token-level contrastive pretraining framework aimed at enhancing Mamba'sselective capabilities. RCL pretrains a single Mamba block to strengthen itsselective abilities and then transfers these pretrained parameters toinitialize Mamba blocks in various backbone models, improving their temporalprediction performance. RCL uses sequence augmentation with Gaussian noise andapplies inter-sequence and intra-sequence contrastive learning to help theMamba module prioritize information-rich time steps while ignoring noisy ones.Extensive experiments show that RCL consistently boosts the performance ofbackbone models, surpassing existing methods and achieving state-of-the-artresults. Additionally, we propose two metrics to quantify Mamba's selectivecapabilities, providing theoretical, qualitative, and quantitative evidence forthe improvements brought by RCL.</description>
      <author>example@mail.com (Wenbo Yan, Hanzhong Cao, Ying Tan)</author>
      <guid isPermaLink="false">2504.09185v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Pushing the Accuracy Limit of Foundation Neural Network Models with Quantum Monte Carlo Forces and Path Integrals</title>
      <link>http://arxiv.org/abs/2504.07948v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种端到端集成策略，旨在生成高精度的量子化学合成数据集（能量和力），用于推导分子模拟的基础机器学习模型。&lt;h4&gt;背景&lt;/h4&gt;基于密度泛函理论（DFT）和大规模GPU加速软件的“雅各布楼梯”方法，在提高计算精度方面取得了进展。&lt;h4&gt;目的&lt;/h4&gt;通过Exascale计算，首次在完全基组极限下进行计算密集型量子蒙特卡罗力（QMC）的计算，以及将多态QMC能量和力与选定的配置相互作用波函数相结合。&lt;h4&gt;方法&lt;/h4&gt;利用迁移学习提高基于DFT的FeNNix-Bio1基础模型，并与路径积分自适应采样量子动力学相结合，以进行前所未有的纳米秒级反应模拟。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法展示了Exascale在深化我们对复杂生物系统内部机制理解方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法有望在分子模拟领域产生重大影响，并为理解复杂生物系统提供新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose an end-to-end integrated strategy to produce highly accuratequantum chemistry (QC) synthetic datasets (energies and forces) aimed atderiving Foundation Machine Learning models for molecular simulation. Startingfrom Density Functional Theory (DFT), a "Jacob's Ladder" approach leveragescomputationally-optimized layers of massively GPU-accelerated software withincreasing accuracy. Thanks to Exascale, this is the first time that thecomputationally intensive calculation of Quantum Monte Carlo forces (QMC), andthe combination of multi-determinant QMC energies and forces withselected-Configuration Interaction wavefunctions, are computed at such scale atthe complete basis-set limit. To bridge the gap between accurate QC andcondensed-phase Molecular Dynamics, we leverage transfer learning to improvethe DFT-based FeNNix-Bio1 foundation model. The resulting approach is coupledto path integrals adaptive sampling quantum dynamics to perform nanosecondreactive simulations at unprecedented accuracy. These results demonstrate thepromise of Exascale to deepen our understanding of the inner machinery ofcomplex biosystems.</description>
      <author>example@mail.com (Anouar Benali, Thomas Plé, Olivier Adjoua, Valay Agarawal, Thomas Applencourt, Marharyta Blazhynska, Raymond Clay III, Kevin Gasperich, Khalid Hossain, Jeongnim Kim, Christopher Knight, Jaron T. Krogel, Yvon Maday, Maxime Maria, Matthieu Montes, Ye Luo, Evgeny Posenitskiy, Corentin Villot, Venkatram Vishwanath, Louis Lagardère, Jean-Philip Piquemal)</author>
      <guid isPermaLink="false">2504.07948v3</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>GenEDA: Unleashing Generative Reasoning on Netlist via Multimodal Encoder-Decoder Aligned Foundation Model</title>
      <link>http://arxiv.org/abs/2504.09485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 9 figures, and 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GenEDA，这是一个将电路编码器与解码器在共享潜在空间中对齐的框架，旨在提高集成电路设计过程的效率。&lt;h4&gt;背景&lt;/h4&gt;现有预训练的电路模型通常仅限于作为预测任务的独立编码器或生成任务的解码器。这两种模型类型独立开发，运行在不同的电路模式上，并位于不同的潜在空间中，这限制了它们在更高级应用中相互补充的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，将电路编码器与解码器在共享潜在空间中对齐，以便在电路设计过程中提供更强大的功能。&lt;h4&gt;方法&lt;/h4&gt;提出两种范式来支持开源可训练的大语言模型和商业冻结的大语言模型。基于对齐的架构，GenEDA能够执行三种前所未有的生成推理任务，从低级别的网表中以不同粒度逆向生成高级功能。&lt;h4&gt;主要发现&lt;/h4&gt;GenEDA将基于图的电路表示与基于文本的大语言模型（LLMs）连接起来，使得它们各自的潜在空间之间能够进行通信。实验表明，GenEDA显著提升了高级LLMs（如GPT-4o和DeepSeek-V3）在所有任务上的性能。&lt;h4&gt;结论&lt;/h4&gt;GenEDA通过共享潜在空间对齐电路编码器与解码器，为集成电路设计提供了一种新的、更有效的工具，并显著提升了LLMs的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The success of foundation AI has motivated the research of circuit foundationmodels, which are customized to assist the integrated circuit (IC) designprocess. However, existing pre-trained circuit models are typically limited tostandalone encoders for predictive tasks or decoders for generative tasks.These two model types are developed independently, operate on different circuitmodalities, and reside in separate latent spaces, which restricts their abilityto complement each other for more advanced applications. In this work, wepresent GenEDA, the first framework that aligns circuit encoders with decoderswithin a shared latent space. GenEDA bridges the gap between graph-basedcircuit representations and text-based large language models (LLMs), enablingcommunication between their respective latent spaces. To achieve the alignment,we propose two paradigms that support both open-source trainable LLMs andcommercial frozen LLMs. Built on this aligned architecture, GenEDA enablesthree unprecedented generative reasoning tasks over netlists, where the modelreversely generates the high-level functionality from low-level netlists indifferent granularities. These tasks extend traditional gate-type prediction todirect generation of full-circuit functionality. Experiments demonstrate thatGenEDA significantly boosts advanced LLMs' (e.g., GPT-4o and DeepSeek-V3)performance in all tasks.</description>
      <author>example@mail.com (Wenji Fang, Jing Wang, Yao Lu, Shang Liu, Zhiyao Xie)</author>
      <guid isPermaLink="false">2504.09485v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Vision-Language Model for Object Detection and Segmentation: A Review and Evaluation</title>
      <link>http://arxiv.org/abs/2504.09480v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A Review and Evaluation about Vision-Language Model for Object  Detection and Segmentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于视觉-语言模型（VLM）的检测和分割技术进行了系统回顾，评估了VLM在不同下游任务中的效果，并分析了模型架构、任务特性和训练方法之间的关系。&lt;h4&gt;背景&lt;/h4&gt;VLM在开放词汇（OV）物体检测和分割任务中得到了广泛应用，但在传统视觉任务中的有效性尚未得到评估。&lt;h4&gt;目的&lt;/h4&gt;评估VLM在不同检测和分割任务中的表现，并分析其相关因素。&lt;h4&gt;方法&lt;/h4&gt;1）对VLM在不同检测（如封闭集检测、领域自适应、拥挤物体等）和分割（如少样本、开放世界、小物体等）场景中的表现进行了评估；2）对检测任务中的VLM在不同微调粒度（零预测、视觉微调、文本提示）下的表现进行了评估；3）基于实证研究，分析了任务特征、模型架构和训练方法之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;1）揭示了不同VLM架构在不同任务中的性能优势和局限性；2）不同微调策略对性能的影响；3）任务特征、模型架构和训练方法之间存在关联。&lt;h4&gt;结论&lt;/h4&gt;该研究为计算机视觉、多模态学习和视觉基础模型领域的模式识别专家提供了有价值的信息，并指出了未来研究的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉-语言模型（VLM）在开放词汇（OV）物体检测和分割任务中得到了广泛应用。尽管它们在OV相关任务中显示出前景，但它们在传统视觉任务中的有效性至今尚未得到评估。在这项工作中，我们进行了基于VLM的检测和分割的系统性回顾，将VLM视为基础模型，并首次对多个下游任务进行了全面评估：1）评估涵盖了八个检测场景（封闭集检测、领域自适应、拥挤物体等）和八个分割场景（少样本、开放世界、小物体等），揭示了不同VLM架构在任务中的不同性能优势和局限性。2）对于检测任务，我们在三个微调粒度下评估了VLM：零预测、视觉微调和文本提示，并进一步分析了不同的微调策略在不同任务下的性能影响。3）基于实证发现，我们对任务特征、模型架构和训练方法之间的关系进行了深入分析，为未来的VLM设计提供了见解。4）我们认为这项工作将对计算机视觉、多模态学习和视觉基础模型领域的模式识别专家有价值，通过介绍他们了解问题，熟悉当前的研究进展，并为其未来的研究提供有希望的方向。与这次回顾和评估相关的项目已在https://github.com/better-chao/perceptual_abilities_evaluation创建。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Model (VLM) have gained widespread adoption inOpen-Vocabulary (OV) object detection and segmentation tasks. Despite they haveshown promise on OV-related tasks, their effectiveness in conventional visiontasks has thus far been unevaluated. In this work, we present the systematicreview of VLM-based detection and segmentation, view VLM as the foundationalmodel and conduct comprehensive evaluations across multiple downstream tasksfor the first time: 1) The evaluation spans eight detection scenarios(closed-set detection, domain adaptation, crowded objects, etc.) and eightsegmentation scenarios (few-shot, open-world, small object, etc.), revealingdistinct performance advantages and limitations of various VLM architecturesacross tasks. 2) As for detection tasks, we evaluate VLMs under threefinetuning granularities: \textit{zero prediction}, \textit{visualfine-tuning}, and \textit{text prompt}, and further analyze how differentfinetuning strategies impact performance under varied task. 3) Based onempirical findings, we provide in-depth analysis of the correlations betweentask characteristics, model architectures, and training methodologies, offeringinsights for future VLM design. 4) We believe that this work shall be valuableto the pattern recognition experts working in the fields of computer vision,multimodal learning, and vision foundation models by introducing them to theproblem, and familiarizing them with the current status of the progress whileproviding promising directions for future research. A project associated withthis review and evaluation has been created athttps://github.com/better-chao/perceptual_abilities_evaluation.</description>
      <author>example@mail.com (Yongchao Feng, Yajie Liu, Shuai Yang, Wenrui Cai, Jinqing Zhang, Qiqi Zhan, Ziyue Huang, Hongxi Yan, Qiao Wan, Chenguang Liu, Junzhe Wang, Jiahui Lv, Ziqi Liu, Tengyuan Shi, Qingjie Liu, Yunhong Wang)</author>
      <guid isPermaLink="false">2504.09480v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Effectiveness and Interpretability of Texts in LLM-based Time Series Models</title>
      <link>http://arxiv.org/abs/2504.08808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了将文本数据融入大型语言模型（LLMs）进行时间序列预测的有效性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）被应用于时间序列预测任务，通过利用预训练的语言模型作为基础，并结合文本数据来增强LLMs的综合能力。&lt;h4&gt;目的&lt;/h4&gt;研究旨在调查文本数据融入LLMs进行时间序列预测的实际效果和可解释性。&lt;h4&gt;方法&lt;/h4&gt;通过一系列关于文本提示和文本原型的实证实验，研究者提出了新的指标——语义匹配指数（SMI），用于评估时间序列与文本之间的匹配度。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，两种模态之间存在不匹配，文本信息在许多情况下并没有显著提高时间序列预测的性能。可视化分析表明，现有框架学习到的文本表示在应用于时间序列数据时缺乏足够的可解释性。&lt;h4&gt;结论&lt;/h4&gt;研究揭示了当前时间序列LLMs中文本的不匹配和可解释性有限的问题，并希望这一研究能够提高对文本时间序列可解释性的认识。&lt;h4&gt;翻译&lt;/h4&gt;The study investigates the effectiveness and interpretability of incorporating textual data into large language models (LLMs) for time series forecasting. LLMs have been applied to time series forecasting tasks, leveraging pre-trained language models as the backbone and incorporating textual data to enhance the comprehensive capabilities of LLMs for time series. However, this study aims to investigate the actual efficacy and interpretability of such textual incorporations. Through a series of empirical experiments on textual prompts and textual prototypes, the study reveals the misalignment between two modalities and finds that textual information does not significantly improve time series forecasting performance in many cases. Visualization analysis indicates that the textual representations learned by existing frameworks lack sufficient interpretability when applied to time series data. A novel metric named Semantic Matching Index (SMI) is proposed to better evaluate the matching degree between time series and texts during the post hoc interpretability investigation. The study reveals the misalignment and limited interpretability of texts in current time-series LLMs and hopes to raise awareness of the interpretability of texts for time series. The code is available at https://github.com/zachysun/TS-Lang-Exp.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have been applied to time series forecastingtasks, leveraging pre-trained language models as the backbone and incorporatingtextual data to purportedly enhance the comprehensive capabilities of LLMs fortime series. However, are these texts really helpful for interpretation? Thisstudy seeks to investigate the actual efficacy and interpretability of suchtextual incorporations. Through a series of empirical experiments on textualprompts and textual prototypes, our findings reveal that the misalignmentbetween two modalities exists, and the textual information does notsignificantly improve time series forecasting performance in many cases.Furthermore, visualization analysis indicates that the textual representationslearned by existing frameworks lack sufficient interpretability when applied totime series data. We further propose a novel metric named Semantic MatchingIndex (SMI) to better evaluate the matching degree between time series andtexts during our post hoc interpretability investigation. Our analysis revealsthe misalignment and limited interpretability of texts in current time-seriesLLMs, and we hope this study can raise awareness of the interpretability oftexts for time series. The code is available athttps://github.com/zachysun/TS-Lang-Exp.</description>
      <author>example@mail.com (Zhengke Sun, Hangwei Qian, Ivor Tsang)</author>
      <guid isPermaLink="false">2504.08808v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>ReferGPT: Towards Zero-Shot Referring Multi-Object Tracking</title>
      <link>http://arxiv.org/abs/2504.09195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted CVPR 2025 Workshop on Distillation of Foundation Models for  Autonomous Driving&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ReferGPT的新型零样本多目标跟踪框架，该框架通过结合语言理解和目标关联实现基于文本查询的物体跟踪。&lt;h4&gt;背景&lt;/h4&gt;基于文本查询的多目标跟踪任务具有挑战性，因为它需要将语言理解与帧间的目标关联联系起来。现有的方法通常需要监督训练，且在处理开放式查询时可能存在泛化问题。&lt;h4&gt;目的&lt;/h4&gt;提出ReferGPT框架，以实现无需监督训练即可进行多目标跟踪。&lt;h4&gt;方法&lt;/h4&gt;ReferGPT使用一个多模态大型语言模型（MLLM）并赋予其空间知识，使其能够生成3D感知的描述性文本。此外，还提出了一种鲁棒的查询匹配策略，利用基于CLIP的语义编码和模糊匹配将MLLM生成的文本与用户查询关联起来。&lt;h4&gt;主要发现&lt;/h4&gt;在Refer-KITTI、Refer-KITTIv2和Refer-KITTI+数据集上的实验表明，ReferGPT在多目标跟踪任务中取得了与训练方法相当的性能，展示了其在自动驾驶场景中的鲁棒性和零样本能力。&lt;h4&gt;结论&lt;/h4&gt;ReferGPT是一种有效的零样本多目标跟踪框架，适用于无需监督训练的情境，并具有在自动驾驶等领域的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel zero-shot multi-object tracking framework called ReferGPT, which combines language understanding with object association to achieve object tracking based on textual queries.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tracking multiple objects based on textual queries is a challenging task thatrequires linking language understanding with object association across frames.Previous works typically train the whole process end-to-end or integrate anadditional referring text module into a multi-object tracker, but they bothrequire supervised training and potentially struggle with generalization toopen-set queries. In this work, we introduce ReferGPT, a novel zero-shotreferring multi-object tracking framework. We provide a multi-modal largelanguage model (MLLM) with spatial knowledge enabling it to generate 3D-awarecaptions. This enhances its descriptive capabilities and supports a moreflexible referring vocabulary without training. We also propose a robustquery-matching strategy, leveraging CLIP-based semantic encoding and fuzzymatching to associate MLLM generated captions with user queries. Extensiveexperiments on Refer-KITTI, Refer-KITTIv2 and Refer-KITTI+ demonstrate thatReferGPT achieves competitive performance against trained methods, showcasingits robustness and zero-shot capabilities in autonomous driving. The codes areavailable on https://github.com/Tzoulio/ReferGPT</description>
      <author>example@mail.com (Tzoulio Chamiti, Leandro Di Bella, Adrian Munteanu, Nikos Deligiannis)</author>
      <guid isPermaLink="false">2504.09195v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Large Self-Supervised Time-Series Models for Transferable Diagnosis in Cross-Aircraft Type Bleed Air System</title>
      <link>http://arxiv.org/abs/2504.09090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个基于自监督学习的Bleed Air System (BAS)诊断模型，该模型可以将成熟机型（如A320、A330）的诊断知识迁移到新机型（如C919），以提高系统可靠性。&lt;h4&gt;背景&lt;/h4&gt;Bleed Air System对于维持飞行安全和运营效率至关重要，但其故障（如过压、低压和过热）会带来严重风险。当前诊断方法在应用于不同机型时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文旨在开发一种能够将诊断知识从成熟机型迁移到新机型的自监督学习模型。&lt;h4&gt;方法&lt;/h4&gt;本文提出的模型利用自监督预训练学习通用特征表示，无需标注数据，从而在数据稀缺的场景下有效。此外，还引入了跨模型数据集和适用于真实飞行数据的联合基准和异常检测损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够提高异常检测和基准信号预测的准确性，从而提高系统可靠性，并确保在新机型的早期运营阶段提供稳健的支持。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为大型飞行信号模型的研究奠定了基础，并提供了在模型容量和迁移性之间关系方面的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Bleed Air System（BAS）对于维持飞行安全与运营效率至关重要，支持诸如客舱增压、空调和发动机防冰等功能。然而，BAS的故障，包括过压、低压和过热，会带来诸如客舱失压、设备故障或发动机损坏等重大风险。当前的诊断方法在应用于不同飞机类型时面临显著限制，尤其是在缺乏足够运营数据的较新型号上。为了应对这些挑战，本文提出了一种基于自监督学习的基座模型，该模型使得将诊断知识从成熟机型（例如A320、A330）迁移到新机型（例如C919）成为可能。利用自监督预训练，该模型从飞行信号中学习通用的特征表示，而无需标注数据，这使得它在数据稀缺的场景下非常有效。该模型提高了异常检测和基准信号预测，从而增强了系统可靠性。本文引入了跨模型数据集，这是一个用于BAS诊断的自监督学习框架，以及一个针对真实飞行数据的创新性联合基准和异常检测损失函数。这些创新促进了诊断知识在飞机类型间的有效迁移，确保了对新机型早期运营阶段的稳健支持。此外，本文还探讨了模型容量与迁移性之间的关系，为未来关于大规模飞行信号模型的研究提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bleed Air System (BAS) is critical for maintaining flight safety andoperational efficiency, supporting functions such as cabin pressurization, airconditioning, and engine anti-icing. However, BAS malfunctions, includingoverpressure, low pressure, and overheating, pose significant risks such ascabin depressurization, equipment failure, or engine damage. Current diagnosticapproaches face notable limitations when applied across different aircrafttypes, particularly for newer models that lack sufficient operational data. Toaddress these challenges, this paper presents a self-supervised learning-basedfoundation model that enables the transfer of diagnostic knowledge from matureaircraft (e.g., A320, A330) to newer ones (e.g., C919). Leveragingself-supervised pretraining, the model learns universal feature representationsfrom flight signals without requiring labeled data, making it effective indata-scarce scenarios. This model enhances both anomaly detection and baselinesignal prediction, thereby improving system reliability. The paper introduces across-model dataset, a self-supervised learning framework for BAS diagnostics,and a novel Joint Baseline and Anomaly Detection Loss Function tailored toreal-world flight data. These innovations facilitate efficient transfer ofdiagnostic knowledge across aircraft types, ensuring robust support for earlyoperational stages of new models. Additionally, the paper explores therelationship between model capacity and transferability, providing a foundationfor future research on large-scale flight signal models.</description>
      <author>example@mail.com (Yilin Wang, Peixuan Lei, Xuyang Wang, Liangliang Jiang, Liming Xuan, Wei Cheng, Honghua Zhao, Yuanxiang Li)</author>
      <guid isPermaLink="false">2504.09090v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal 3D Genome Pre-training</title>
      <link>http://arxiv.org/abs/2504.09060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MIX-HIC是第一个多模态3D基因组基础模型，它整合了3D基因组结构和表观基因组轨迹，并设计了跨模态交互和映射块，用于准确融合异质语义，显著提高了3D基因组知识聚合的准确性。&lt;h4&gt;背景&lt;/h4&gt;深度学习技术在计算生物学中的3D基因组分析任务中取得了显著进展，但对3D基因组知识的整体理解仍处于探索阶段。&lt;h4&gt;目的&lt;/h4&gt;提出MIX-HIC模型，以实现对3D基因组知识的统一和全面语义理解。&lt;h4&gt;方法&lt;/h4&gt;设计了跨模态交互和映射块，并引入了包含超过100万对Hi-C接触图和表观基因组轨迹样本的大规模数据集，用于高质量预训练。&lt;h4&gt;主要发现&lt;/h4&gt;MIX-HIC在多个下游任务中显著超越了现有最先进的方法，为3D基因组研究提供了宝贵资源。&lt;h4&gt;结论&lt;/h4&gt;MIX-HIC模型为3D基因组研究提供了新的方法和工具，有望推动该领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning techniques have driven significant progress in variousanalytical tasks within 3D genomics in computational biology. However, aholistic understanding of 3D genomics knowledge remains underexplored. Here, wepropose MIX-HIC, the first multimodal foundation model of 3D genome thatintegrates both 3D genome structure and epigenomic tracks, which obtainsunified and comprehensive semantics. For accurate heterogeneous semanticfusion, we design the cross-modal interaction and mapping blocks for robustunified representation, yielding the accurate aggregation of 3D genomeknowledge. Besides, we introduce the first large-scale dataset comprising over1 million pairwise samples of Hi-C contact maps and epigenomic tracks forhigh-quality pre-training, enabling the exploration of functional implicationsin 3D genomics. Extensive experiments show that MIX-HIC can significantlysurpass existing state-of-the-art methods in diverse downstream tasks. Thiswork provides a valuable resource for advancing 3D genomics research.</description>
      <author>example@mail.com (Minghao Yang, Pengteng Li, Yan Liang, Qianyi Cai, Zhihang Zheng, Shichen Zhang, Pengfei Zhang, Zhi-An Huang, Hui Xiong)</author>
      <guid isPermaLink="false">2504.09060v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Parameter-Free Fine-tuning via Redundancy Elimination for Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2504.08915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉基础模型（VFMs）中的冗余特征，并提出了一种参数免费的微调方法来解决这一问题。&lt;h4&gt;背景&lt;/h4&gt;VFMs是各种视觉任务的基础，但它们通常包含大量的特征冗余，这可能限制了它们对新任务的适应性。&lt;h4&gt;目的&lt;/h4&gt;旨在提高VFMs对新任务的适应性和微调效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于模型输出差异的通道选择算法，以识别冗余和有效的通道，并通过选择性替换冗余通道来增强预训练特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在域内和域外数据集上均表现出高效性和有效性，并且可以与现有的微调策略（如LoRA、Adapter）无缝集成，进一步提升了已微调模型的表现。&lt;h4&gt;结论&lt;/h4&gt;该方法显著降低了计算和GPU内存开销，为模型微调提供了一种新的视角。&lt;h4&gt;翻译&lt;/h4&gt;Vision foundation models (VFMs) are large pre-trained models that form the backbone of various vision tasks. Fine-tuning VFMs can further unlock their potential for downstream tasks or scenarios. However, VFMs often contain significant feature redundancy, which may limit their adaptability to new tasks. In this paper, we investigate the redundancies in the segment anything model (SAM) and then propose a parameter-free fine-tuning method to address this issue. Unlike traditional fine-tuning methods that adjust parameters, our method emphasizes selecting, reusing, and enhancing pre-trained features, offering a new perspective on model fine-tuning. Specifically, we introduce a channel selection algorithm based on the model's output difference to identify redundant and effective channels. By selectively replacing the redundant channels with more effective ones, we filter out less useful features and reuse the more relevant features to downstream tasks, thereby enhancing the task-specific feature representation. Experiments on both out-of-domain and in-domain datasets demonstrate the efficiency and effectiveness of our method. Notably, our approach can seamlessly integrate with existing fine-tuning strategies (e.g., LoRA, Adapter), further boosting the performance of already fine-tuned models. Moreover, since our channel selection involves only model inference, our method significantly reduces computational and GPU memory overhead.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models (VFMs) are large pre-trained models that form thebackbone of various vision tasks. Fine-tuning VFMs can further unlock theirpotential for downstream tasks or scenarios. However, VFMs often containsignificant feature redundancy, which may limit their adaptability to newtasks. In this paper, we investigate the redundancies in the segment anythingmodel (SAM) and then propose a parameter-free fine-tuning method to addressthis issue. Unlike traditional fine-tuning methods that adjust parameters, ourmethod emphasizes selecting, reusing, and enhancing pre-trained features,offering a new perspective on model fine-tuning. Specifically, we introduce achannel selection algorithm based on the model's output difference to identifyredundant and effective channels. By selectively replacing the redundantchannels with more effective ones, we filter out less useful features and reusethe more relevant features to downstream tasks, thereby enhancing thetask-specific feature representation. Experiments on both out-of-domain andin-domain datasets demonstrate the efficiency and effectiveness of our method.Notably, our approach can seamlessly integrate with existing fine-tuningstrategies (e.g., LoRA, Adapter), further boosting the performance of alreadyfine-tuned models. Moreover, since our channel selection involves only modelinference, our method significantly reduces computational and GPU memoryoverhead.</description>
      <author>example@mail.com (Jiahuan Long, Tingsong Jiang, Wen Yao, Yizhe Xiong, Zhengqin Xu, Shuai Jia, Chao Ma)</author>
      <guid isPermaLink="false">2504.08915v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>InfoGain Wavelets: Furthering the Design of Diffusion Wavelets for Graph-Structured Data</title>
      <link>http://arxiv.org/abs/2504.08802v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work was accepted to be presented at the Graph Signal Processing  Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于信息理论的新方法来选择扩散尺度，以从不同分辨率提取图信号信息。&lt;h4&gt;背景&lt;/h4&gt;扩散小波通过使用不同幂次的图扩散算子（称为扩散尺度）从图信号中提取信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督的方法来选择扩散尺度。&lt;h4&gt;方法&lt;/h4&gt;该方法基于信息理论，并展示了如何将其整合到基于小波的图神经网络中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够通过图分类实验整合到波let-based GNNs中。&lt;h4&gt;结论&lt;/h4&gt;该研究为图信号处理提供了一种新的无监督选择扩散尺度的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：扩散小波通过利用不同幂次的图扩散算子（称为扩散尺度）从不同分辨率提取图信号信息。传统上，扩散尺度被选为二进制整数（2^j）。在这里，我们提出了一种基于信息理论的新颖无监督方法来选择扩散尺度。然后，我们展示了该方法可以通过图分类实验整合到基于小波的图神经网络中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion wavelets extract information from graph signals at different scalesof resolution by utilizing graph diffusion operators raised to various powers,known as diffusion scales. Traditionally, the diffusion scales are chosen to bedyadic integers, $\mathbf{2^j}$. Here, we propose a novel, unsupervised methodfor selecting the diffusion scales based on ideas from information theory. Wethen show that our method can be incorporated into wavelet-based GNNs via graphclassification experiments.</description>
      <author>example@mail.com (David R. Johnson, Smita Krishnaswamy, Michael Perlmutter)</author>
      <guid isPermaLink="false">2504.08802v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Robust SAM: On the Adversarial Robustness of Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2504.08906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAAI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对Segment Anything Model (SAM)的对抗鲁棒性框架，旨在评估和增强SAM的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;SAM是一个广泛应用于图像分割、检测和跟踪等领域的视觉基础模型。然而，关于SAM鲁棒性的研究还处于早期阶段，现有攻击方法往往忽略了提示在评估SAM鲁棒性中的作用，且对防御方法的探索不足。&lt;h4&gt;目的&lt;/h4&gt;为了填补这些空白，本文提出了一个对抗鲁棒性框架，旨在评估和增强SAM的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;本文引入了一种跨提示攻击方法来提高攻击在不同提示类型之间的可迁移性。此外，还提出了一种参数适应策略来防御SAM的各种对抗攻击。为了平衡鲁棒性和准确性，使用奇异值分解（SVD）来约束可训练参数的空间，其中只有奇异值是可调整的。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的跨提示攻击方法在SAM和SAM 2上的攻击成功率优于先前的方法。通过仅调整512个参数，我们实现了至少15%的平均交并率（mIoU）的提升，对抗各种对抗攻击。与先前的方法相比，该方法在增强SAM鲁棒性的同时，最大限度地保持了其原始性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有效地提高了SAM的鲁棒性，同时保持了其性能，为SAM在实际应用中的部署提供了保障。&lt;h4&gt;翻译&lt;/h4&gt;The Segment Anything Model (SAM) is a widely used vision foundation model with diverse applications, including image segmentation, detection, and tracking. Given SAM's wide applications, understanding its robustness against adversarial attacks is crucial for real-world deployment. However, research on SAM's robustness is still in its early stages. Existing attacks often overlook the role of prompts in evaluating SAM's robustness, and there has been insufficient exploration of defense methods to balance the robustness and accuracy. To address these gaps, this paper proposes an adversarial robustness framework designed to evaluate and enhance the robustness of SAM. Specifically, we introduce a cross-prompt attack method to enhance the attack transferability across different prompt types. Besides attacking, we propose a few-parameter adaptation strategy to defend SAM against various adversarial attacks. To balance robustness and accuracy, we use the singular value decomposition (SVD) to constrain the space of trainable parameters, where only singular values are adaptable. Experiments demonstrate that our cross-prompt attack method outperforms previous approaches in terms of attack success rate on both SAM and SAM 2. By adapting only 512 parameters, we achieve at least a 15% improvement in mean intersection over union (mIoU) against various adversarial attacks. Compared to previous defense methods, our approach enhances the robustness of SAM while maximally maintaining its original performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Segment Anything Model (SAM) is a widely used vision foundation modelwith diverse applications, including image segmentation, detection, andtracking. Given SAM's wide applications, understanding its robustness againstadversarial attacks is crucial for real-world deployment. However, research onSAM's robustness is still in its early stages. Existing attacks often overlookthe role of prompts in evaluating SAM's robustness, and there has beeninsufficient exploration of defense methods to balance the robustness andaccuracy. To address these gaps, this paper proposes an adversarial robustnessframework designed to evaluate and enhance the robustness of SAM. Specifically,we introduce a cross-prompt attack method to enhance the attack transferabilityacross different prompt types. Besides attacking, we propose a few-parameteradaptation strategy to defend SAM against various adversarial attacks. Tobalance robustness and accuracy, we use the singular value decomposition (SVD)to constrain the space of trainable parameters, where only singular values areadaptable. Experiments demonstrate that our cross-prompt attack methodoutperforms previous approaches in terms of attack success rate on both SAM andSAM 2. By adapting only 512 parameters, we achieve at least a 15\% improvementin mean intersection over union (mIoU) against various adversarial attacks.Compared to previous defense methods, our approach enhances the robustness ofSAM while maximally maintaining its original performance.</description>
      <author>example@mail.com (Jiahuan Long, Zhengqin Xu, Tingsong Jiang, Wen Yao, Shuai Jia, Chao Ma, Xiaoqian Chen)</author>
      <guid isPermaLink="false">2504.08906v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Position: Beyond Euclidean -- Foundation Models Should Embrace Non-Euclidean Geometries</title>
      <link>http://arxiv.org/abs/2504.08896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了在大型语言模型和基础模型时代，欧几里得空间在机器学习架构中的应用及其局限性，并提出了非欧几里得几何在模型中的必要性。&lt;h4&gt;背景&lt;/h4&gt;在当前机器学习领域，欧几里得空间是主流的几何设置。然而，现实世界数据往往具有非欧几里得结构，如多向关系、层次结构、对称性和非各向同性尺度。&lt;h4&gt;目的&lt;/h4&gt;提出超越欧几里得几何是必要的，以维持下一代基础模型的扩展规律。&lt;h4&gt;方法&lt;/h4&gt;通过理论研究和实证调查来支持这一观点，并概述了将非欧几里得几何整合到基础模型中的路线图，包括通过微调、从头训练和混合方法构建几何基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;欧几里得空间难以有效捕捉现实世界数据中的非欧几里得结构，而采用非欧几里得几何可以更有效地利用这些结构。&lt;h4&gt;结论&lt;/h4&gt;非欧几里得几何对于下一代基础模型的发展至关重要，任务感知适应性可以进一步提高效率和表达性。&lt;h4&gt;翻译&lt;/h4&gt;In the era of foundation models and Large Language Models (LLMs), Euclideanspace has been the de facto geometric setting for machine learningarchitectures. However, recent literature has demonstrated that this choicecomes with fundamental limitations. At a large scale, real-world data oftenexhibit inherently non-Euclidean structures, such as multi-way relationships,hierarchies, symmetries, and non-isotropic scaling, in a variety of domains,such as languages, vision, and the natural sciences. It is challenging toeffectively capture these structures within the constraints of Euclideanspaces. This position paper argues that moving beyond Euclidean geometry is notmerely an optional enhancement but a necessity to maintain the scaling law forthe next-generation of foundation models. By adopting these geometries,foundation models could more efficiently leverage the aforementionedstructures. Task-aware adaptability that dynamically reconfigures embeddings tomatch the geometry of downstream applications could further enhance efficiencyand expressivity. Our position is supported by a series of theoretical andempirical investigations of prevalent foundation models.Finally, we outline aroadmap for integrating non-Euclidean geometries into foundation models,including strategies for building geometric foundation models via fine-tuning,training from scratch, and hybrid approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of foundation models and Large Language Models (LLMs), Euclideanspace has been the de facto geometric setting for machine learningarchitectures. However, recent literature has demonstrated that this choicecomes with fundamental limitations. At a large scale, real-world data oftenexhibit inherently non-Euclidean structures, such as multi-way relationships,hierarchies, symmetries, and non-isotropic scaling, in a variety of domains,such as languages, vision, and the natural sciences. It is challenging toeffectively capture these structures within the constraints of Euclideanspaces. This position paper argues that moving beyond Euclidean geometry is notmerely an optional enhancement but a necessity to maintain the scaling law forthe next-generation of foundation models. By adopting these geometries,foundation models could more efficiently leverage the aforementionedstructures. Task-aware adaptability that dynamically reconfigures embeddings tomatch the geometry of downstream applications could further enhance efficiencyand expressivity. Our position is supported by a series of theoretical andempirical investigations of prevalent foundation models.Finally, we outline aroadmap for integrating non-Euclidean geometries into foundation models,including strategies for building geometric foundation models via fine-tuning,training from scratch, and hybrid approaches.</description>
      <author>example@mail.com (Neil He, Jiahong Liu, Buze Zhang, Ngoc Bui, Ali Maatouk, Menglin Yang, Irwin King, Melanie Weber, Rex Ying)</author>
      <guid isPermaLink="false">2504.08896v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Neural Encoding and Decoding at Scale</title>
      <link>http://arxiv.org/abs/2504.08201v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为NEDS的多模态、多任务模型，旨在同时进行大规模的神经编码和解码，以更好地理解神经活动和行为之间的关系。&lt;h4&gt;背景&lt;/h4&gt;现有的大规模模型要么从行为预测神经活动（编码），要么从神经活动预测行为（解码），限制了它们捕捉神经活动和行为之间双向关系的能力。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一差距，研究引入了NEDS模型，以实现神经编码和解码的同步进行。&lt;h4&gt;方法&lt;/h4&gt;NEDS模型的核心是一个新颖的多任务掩码策略，该策略在神经、行为、同一模态和跨模态掩码之间交替。该方法在包含83只动物进行相同视觉决策任务的重复站点数据集上进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;与其它大规模模型相比，NEDS在预训练于多动物数据并在新动物上微调后，在编码和解码方面均达到了最先进的性能。此外，NEDS学习到的嵌入表现出涌现性质，即使没有明确的训练，它们也能高度预测每条记录中的大脑区域。&lt;h4&gt;结论&lt;/h4&gt;这一方法朝着构建一个能够无缝翻译神经活动和行为的脑部基础模型迈出了重要一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work has demonstrated that large-scale, multi-animal models arepowerful tools for characterizing the relationship between neural activity andbehavior. Current large-scale approaches, however, focus exclusively on eitherpredicting neural activity from behavior (encoding) or predicting behavior fromneural activity (decoding), limiting their ability to capture the bidirectionalrelationship between neural activity and behavior. To bridge this gap, weintroduce a multimodal, multi-task model that enables simultaneous NeuralEncoding and Decoding at Scale (NEDS). Central to our approach is a novelmulti-task-masking strategy, which alternates between neural, behavioral,within-modality, and cross-modality masking. We pretrain our method on theInternational Brain Laboratory (IBL) repeated site dataset, which includesrecordings from 83 animals performing the same visual decision-making task. Incomparison to other large-scale models, we demonstrate that NEDS achievesstate-of-the-art performance for both encoding and decoding when pretrained onmulti-animal data and then fine-tuned on new animals. Surprisingly, NEDS'slearned embeddings exhibit emergent properties: even without explicit training,they are highly predictive of the brain regions in each recording. Altogether,our approach is a step towards a foundation model of the brain that enablesseamless translation between neural activity and behavior.</description>
      <author>example@mail.com (Yizi Zhang, Yanchen Wang, Mehdi Azabou, Alexandre Andre, Zixuan Wang, Hanrui Lyu, The International Brain Laboratory, Eva Dyer, Liam Paninski, Cole Hurwitz)</author>
      <guid isPermaLink="false">2504.08201v2</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Meta-Learning via Coupled Ricci Flow: Unifying Knowledge Representation and Quantum Entanglement</title>
      <link>http://arxiv.org/abs/2503.19867v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, submitted to IEEE PAMI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过三项基本创新建立了将几何流与深度学习相结合的统一框架。&lt;h4&gt;背景&lt;/h4&gt;研究背景为几何流与深度学习的结合，旨在提升几何深度学习的能力。&lt;h4&gt;目的&lt;/h4&gt;目的是通过结合几何流与深度学习，提高学习效率和模型性能。&lt;h4&gt;方法&lt;/h4&gt;方法包括：1. 提出一种热力学耦合的Ricci流，动态适应参数空间几何与损失景观拓扑；2. 通过曲率爆破分析推导出显式相变阈值和临界学习率；3. 建立神经网络与共形场理论之间的AdS/CFT型全息对偶。&lt;h4&gt;主要发现&lt;/h4&gt;主要发现包括：1. 通过热力学耦合的Ricci流保留了等距知识嵌入；2. 通过曲率爆破分析实现了自动奇异点解析；3. 提供了纠缠熵界限，有助于正则化设计；4. 实验表明在保持复杂度的同时，加速了收敛速度并简化了拓扑结构。&lt;h4&gt;结论&lt;/h4&gt;理论上证明了通过结合Perelman熵与Wasserstein梯度流的新的Lyapunov函数，实现了指数稳定性，从根本上推进了几何深度学习。&lt;h4&gt;翻译&lt;/h4&gt;This paper establishes a unified framework integrating geometric flows with deep learning through three fundamental innovations. First, we propose a thermodynamically coupled Ricci flow that dynamically adapts parameter space geometry to loss landscape topology, formally proved to preserve isometric knowledge embedding (Theorem~\ref{thm:isometric}). Second, we derive explicit phase transition thresholds and critical learning rates (Theorem~\ref{thm:critical}) through curvature blowup analysis, enabling automated singularity resolution via geometric surgery (Lemma~\ref{lem:surgery}). Third, we establish an AdS/CFT-type holographic duality (Theorem~\ref{thm:ads}) between neural networks and conformal field theories, providing entanglement entropy bounds for regularization design. Experiments demonstrate 2.1\times convergence acceleration and 63% topological simplification while maintaining \(\mathcal{O}(N\log N)\) complexity, outperforming Riemannian baselines by 15.2% in few-shot accuracy. Theoretically, we prove exponential stability (Theorem~\ref{thm:converge}) through a new Lyapunov function combining Perelman entropy with Wasserstein gradient flows, fundamentally advancing geometric deep learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper establishes a unified framework integrating geometric flows withdeep learning through three fundamental innovations. First, we propose athermodynamically coupled Ricci flow that dynamically adapts parameter spacegeometry to loss landscape topology, formally proved to preserve isometricknowledge embedding (Theorem~\ref{thm:isometric}). Second, we derive explicitphase transition thresholds and critical learning rates(Theorem~\ref{thm:critical}) through curvature blowup analysis, enablingautomated singularity resolution via geometric surgery(Lemma~\ref{lem:surgery}). Third, we establish an AdS/CFT-type holographicduality (Theorem~\ref{thm:ads}) between neural networks and conformal fieldtheories, providing entanglement entropy bounds for regularization design.Experiments demonstrate 2.1$\times$ convergence acceleration and 63\%topological simplification while maintaining $\mathcal{O}(N\log N)$ complexity,outperforming Riemannian baselines by 15.2\% in few-shot accuracy.Theoretically, we prove exponential stability (Theorem~\ref{thm:converge})through a new Lyapunov function combining Perelman entropy with Wassersteingradient flows, fundamentally advancing geometric deep learning.</description>
      <author>example@mail.com (Ming Lei, Christophe Baehr)</author>
      <guid isPermaLink="false">2503.19867v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
  <item>
      <title>Variational Quantum Self-Organizing Map</title>
      <link>http://arxiv.org/abs/2504.03584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于核化Kohonen自组织图的量子神经网络架构，用于无监督学习经典和量子数据。&lt;h4&gt;背景&lt;/h4&gt;基于Kohonen自组织图，通过核化版本来处理量子数据。&lt;h4&gt;目的&lt;/h4&gt;开发一种算法，以无监督学习的方式从经典和量子数据中提取信息。&lt;h4&gt;方法&lt;/h4&gt;使用量子计算机计算量子状态之间的保真度，以识别自组织图输出神经元低维网格中的最佳匹配单元。通过调整输出神经元的变分参数来估计保真度。算法需要O(N)次电路评估，而不是量子核估计中的O(N^2)次。&lt;h4&gt;主要发现&lt;/h4&gt;算法能够从高维希尔伯特空间到低维网格点学习映射，同时保留希尔伯特空间的基本拓扑结构。在Fisher的Iris数据集上展示了算法的有效性，并在Schwinger模型上展示了量子数据的有效性。&lt;h4&gt;结论&lt;/h4&gt;该算法在无监督学习经典和量子数据方面表现出良好的效果，并且能够区分不同的数据类别。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的量子神经网络架构，用于基于核化Kohonen自组织图的无监督学习经典和量子数据。该算法的核心思想是用量子态之间的保真度代替欧几里得距离度量，以识别自组织图输出神经元低维网格中的最佳匹配单元。通过计算量子计算机上的过渡概率来估计未知量子状态与包含变分参数的量子状态之间的保真度。这些估计的保真度随后用于调整输出神经元的变分参数。与量子核估计中需要的O(N^2)次电路评估相比，我们的算法对于N个数据样本只需要O(N)次电路评估。类似于自组织图的传统版本，我们的算法学习从高维希尔伯特空间到低维网格点的映射，同时保留希尔伯特空间的基本拓扑结构。我们通过构建一个二维可视化来展示算法的有效性，该可视化能够准确区分Fisher的Iris数据集中的三种不同的花卉种类。此外，我们还通过创建一个二维映射来展示我们在量子数据上的方法的有效性，该映射保留了Schwinger模型状态空间的拓扑结构，并在θ=π时区分模型的两个不同的相。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel quantum neural network architecture for unsupervisedlearning of classical and quantum data based on the kernelized version ofKohonen's self-organizing map. The central idea behind our algorithm is toreplace the Euclidean distance metric with the fidelity between quantum statesto identify the best matching unit from the low-dimensional grid of outputneurons in the self-organizing map. The fidelities between the unknown quantumstate and the quantum states containing the variational parameters areestimated by computing the transition probability on a quantum computer. Theestimated fidelities are in turn used to adjust the variational parameters ofthe output neurons. Unlike $\mathcal{O}(N^{2})$ circuit evaluations needed inquantum kernel estimation, our algorithm requires $\mathcal{O}(N)$ circuitevaluations for $N$ data samples. Analogous to the classical version of theself-organizing map, our algorithm learns a mapping from a high-dimensionalHilbert space to a low-dimensional grid of lattice points while preserving theunderlying topology of the Hilbert space. We showcase the effectiveness of ouralgorithm by constructing a two-dimensional visualization that accuratelydifferentiates between the three distinct species of flowers in Fisher's Irisdataset. In addition, we demonstrate the efficacy of our approach on quantumdata by creating a two-dimensional map that preserves the topology of the statespace in the Schwinger model and distinguishes between the two separate phasesof the model at $\theta = \pi$.</description>
      <author>example@mail.com (Amol Deshmukh)</author>
      <guid isPermaLink="false">2504.03584v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>ModernBERT or DeBERTaV3? Examining Architecture and Data Influence on Transformer Encoder Models Performance</title>
      <link>http://arxiv.org/abs/2504.08716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文比较了DeBERTaV3和ModernBERT等预训练transformer-encoder模型，探讨了模型架构改进对性能的影响。&lt;h4&gt;背景&lt;/h4&gt;ModernBERT在多个基准测试中表现出比DeBERTaV3更好的性能，但其性能提升是否由于架构改进或训练数据差异尚不明确。&lt;h4&gt;目的&lt;/h4&gt;通过在相同数据集上预训练ModernBERT，与DeBERTaV3的French模型CamemBERTaV2进行比较，以隔离模型设计的影响。&lt;h4&gt;方法&lt;/h4&gt;进行了一个受控研究，使用相同的数据集预训练ModernBERT，并比较了模型在样本效率和基准性能方面的表现。&lt;h4&gt;主要发现&lt;/h4&gt;尽管ModernBERT在训练和推理速度上具有优势，但DeBERTaV3在样本效率和整体基准性能上仍然更优。高质量预训练数据加速了收敛，但并未显著提高最终性能，暗示了基准测试可能已经饱和。&lt;h4&gt;结论&lt;/h4&gt;在评估transformer模型时，将预训练数据与架构创新分离是很重要的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pretrained transformer-encoder models like DeBERTaV3 and ModernBERT introducearchitectural advancements aimed at improving efficiency and performance.Although the authors of ModernBERT report improved performance over DeBERTaV3on several benchmarks, the lack of disclosed training data and the absence ofcomparisons using a shared dataset make it difficult to determine whether thesegains are due to architectural improvements or differences in training data. Inthis work, we conduct a controlled study by pretraining ModernBERT on the samedataset as CamemBERTaV2, a DeBERTaV3 French model, isolating the effect ofmodel design. Our results show that the previous model generation remainssuperior in sample efficiency and overall benchmark performance, withModernBERT's primary advantage being faster training and inference speed.However, the new proposed model still provides meaningful architecturalimprovements compared to earlier models such as BERT and RoBERTa. Additionally,we observe that high-quality pre-training data accelerates convergence but doesnot significantly improve final performance, suggesting potential benchmarksaturation. These findings show the importance of disentangling pretrainingdata from architectural innovations when evaluating transformer models.</description>
      <author>example@mail.com (Wissam Antoun, Benoît Sagot, Djamé Seddah)</author>
      <guid isPermaLink="false">2504.08716v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Hypergraph Vision Transformers: Images are More than Nodes, More than Edges</title>
      <link>http://arxiv.org/abs/2504.08710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Hypergraph Vision Transformer (HgVT)的新方法，用于解决计算机视觉任务中的可扩展性、适应性和计算效率问题。&lt;h4&gt;背景&lt;/h4&gt;尽管Vision Transformers (ViTs)在计算机视觉任务中表现出良好的可扩展性，但在适应性和计算效率方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出HgVT以解决ViTs在处理高阶关系时的计算瓶颈，同时保持高效计算。&lt;h4&gt;方法&lt;/h4&gt;HgVT通过将层次双分图结构融入ViTs框架，利用人口和多样性正则化动态构建超图，无需聚类，并采用专家边缘池化来增强语义提取和图像检索。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，HgVT在图像分类和检索任务上表现出优异的性能，是一种高效的基于语义的视觉任务框架。&lt;h4&gt;结论&lt;/h4&gt;HgVT为基于语义的视觉任务提供了一种高效且有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in computer vision have highlighted the scalability ofVision Transformers (ViTs) across various tasks, yet challenges remain inbalancing adaptability, computational efficiency, and the ability to modelhigher-order relationships. Vision Graph Neural Networks (ViGs) offer analternative by leveraging graph-based methodologies but are hindered by thecomputational bottlenecks of clustering algorithms used for edge generation. Toaddress these issues, we propose the Hypergraph Vision Transformer (HgVT),which incorporates a hierarchical bipartite hypergraph structure into thevision transformer framework to capture higher-order semantic relationshipswhile maintaining computational efficiency. HgVT leverages population anddiversity regularization for dynamic hypergraph construction withoutclustering, and expert edge pooling to enhance semantic extraction andfacilitate graph-based image retrieval. Empirical results demonstrate that HgVTachieves strong performance on image classification and retrieval, positioningit as an efficient framework for semantic-based vision tasks.</description>
      <author>example@mail.com (Joshua Fixelle)</author>
      <guid isPermaLink="false">2504.08710v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>ProtoECGNet: Case-Based Interpretable Deep Learning for Multi-Label ECG Classification with Contrastive Learning</title>
      <link>http://arxiv.org/abs/2504.08713v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于原型学习的深度学习模型ProtoECGNet，用于可解释的多标签ECG分类。该模型通过结合不同的CNN架构和原型损失函数，提供了结构化的病例解释，并展现了其在临床决策支持中的应用潜力。&lt;h4&gt;背景&lt;/h4&gt;虽然深度学习在ECG分类中表现出色，但临床应用受到缺乏透明和忠实解释的阻碍。&lt;h4&gt;目的&lt;/h4&gt;开发一个原型基础的深度学习模型，以实现可解释的多标签ECG分类，并提供基于病例的解释。&lt;h4&gt;方法&lt;/h4&gt;ProtoECGNet采用结构化、多分支的架构，包括用于节律分类的1D CNN与全局原型、用于形态推理的2D CNN与时间局部原型、以及用于弥漫性异常的2D CNN与全局原型。每个分支使用原型损失函数进行训练，该损失函数结合了聚类、分离、多样性和对比损失。&lt;h4&gt;主要发现&lt;/h4&gt;ProtoECGNet在PTB-XL数据集上的所有71个诊断标签上展现了与现有黑盒模型相竞争的性能，同时提供了结构化的病例解释。通过结构化的医生评审，原型质量被评为具有代表性和清晰的。&lt;h4&gt;结论&lt;/h4&gt;原型学习可以有效地扩展到复杂的多标签时间序列分类，为临床决策支持提供了透明和值得信赖的深度学习模型的实用路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based electrocardiogram (ECG) classification has shownimpressive performance but clinical adoption has been slowed by the lack oftransparent and faithful explanations. Post hoc methods such as saliency mapsmay fail to reflect a model's true decision process. Prototype-based reasoningoffers a more transparent alternative by grounding decisions in similarity tolearned representations of real ECG segments, enabling faithful, case-basedexplanations. We introduce ProtoECGNet, a prototype-based deep learning modelfor interpretable, multi-label ECG classification. ProtoECGNet employs astructured, multi-branch architecture that reflects clinical interpretationworkflows: it integrates a 1D CNN with global prototypes for rhythmclassification, a 2D CNN with time-localized prototypes for morphology-basedreasoning, and a 2D CNN with global prototypes for diffuse abnormalities. Eachbranch is trained with a prototype loss designed for multi-label learning,combining clustering, separation, diversity, and a novel contrastive loss thatencourages appropriate separation between prototypes of unrelated classes whileallowing clustering for frequently co-occurring diagnoses. We evaluateProtoECGNet on all 71 diagnostic labels from the PTB-XL dataset, demonstratingcompetitive performance relative to state-of-the-art black-box models whileproviding structured, case-based explanations. To assess prototype quality, weconduct a structured clinician review of the final model's projectedprototypes, finding that they are rated as representative and clear.ProtoECGNet shows that prototype learning can be effectively scaled to complex,multi-label time-series classification, offering a practical path towardtransparent and trustworthy deep learning models for clinical decision support.</description>
      <author>example@mail.com (Sahil Sethi, David Chen, Thomas Statchen, Michael C. Burkhart, Nipun Bhandari, Bashar Ramadan, Brett Beaulieu-Jones)</author>
      <guid isPermaLink="false">2504.08713v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>FindAnything: Open-Vocabulary and Object-Centric Mapping for Robot Exploration in Any Environment</title>
      <link>http://arxiv.org/abs/2504.08603v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为FindAnything的开世界地图构建和探索框架，该框架将视觉-语言信息融入密集体素子图，以实现大规模未知环境的实时、开放词汇语义理解。&lt;h4&gt;背景&lt;/h4&gt;几何精确且语义丰富的地图表示对移动机器人的导航和任务规划至关重要，但实时、开放词汇语义理解仍是开放性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，将视觉-语言信息结合到地图构建中，以实现更高级别的环境理解，并允许机器人探索任何环境。&lt;h4&gt;方法&lt;/h4&gt;使用视觉-语言特征，将环境表示为一系列体素占用子图，并通过eSAM生成的片段聚合像素级视觉-语言特征，最终将这些特征集成到以对象为中心的体素子图中。&lt;h4&gt;主要发现&lt;/h4&gt;FindAnything在Replica数据集上的闭集评估中达到了最先进的语义精度，并允许机器人根据自然语言查询选择的对象或感兴趣区域进行环境探索。&lt;h4&gt;结论&lt;/h4&gt;该系统是第一个在资源受限设备（如微型飞行器）上部署的系统，利用视觉-语言信息进行现实世界的机器人任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要：几何精确且语义丰富的地图表示对于实现移动机器人的稳健和安全的导航与任务规划具有重要意义。然而，在大型未知环境中实现实时、开放词汇的语义理解仍然是一个未解决的问题。在本文中，我们提出了FindAnything，一个开放世界的地图构建和探索框架，该框架将视觉-语言信息融入密集的体素子图中。得益于视觉-语言特征的使用，FindAnything在高级别理解的同时，允许机器人无需任何外部真实姿态信息源的帮助即可探索任何环境。我们将环境表示为一系列体素占用子图，从而得到一种稳健且精确的地图表示，在SLAM系统修正其漂移时，基于姿态更新进行变形，使得子图之间具有局部一致性。从高效的SAM（eSAM）生成的片段中聚合像素级的视觉-语言特征，这些特征进而集成到以对象为中心的体素子图中，提供了一种将开放词汇查询映射到3D几何的方法，该方法在内存使用方面也是可扩展的。FindAnything的开放词汇地图表示在Replica数据集上的闭集评估中实现了最先进的语义精度。这种场景理解水平使得机器人能够根据通过自然语言查询选择的对象或感兴趣区域进行环境探索。我们的系统是第一个在其上部署的资源受限设备（如微型飞行器），利用视觉-语言信息进行现实世界的机器人任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometrically accurate and semantically expressive map representations haveproven invaluable to facilitate robust and safe mobile robot navigation andtask planning. Nevertheless, real-time, open-vocabulary semantic understandingof large-scale unknown environments is still an open problem. In this paper wepresent FindAnything, an open-world mapping and exploration framework thatincorporates vision-language information into dense volumetric submaps. Thanksto the use of vision-language features, FindAnything bridges the gap betweenpure geometric and open-vocabulary semantic information for a higher level ofunderstanding while allowing to explore any environment without the help of anyexternal source of ground-truth pose information. We represent the environmentas a series of volumetric occupancy submaps, resulting in a robust and accuratemap representation that deforms upon pose updates when the underlying SLAMsystem corrects its drift, allowing for a locally consistent representationbetween submaps. Pixel-wise vision-language features are aggregated fromefficient SAM (eSAM)-generated segments, which are in turn integrated intoobject-centric volumetric submaps, providing a mapping from open-vocabularyqueries to 3D geometry that is scalable also in terms of memory usage. Theopen-vocabulary map representation of FindAnything achieves state-of-the-artsemantic accuracy in closed-set evaluations on the Replica dataset. This levelof scene understanding allows a robot to explore environments based on objectsor areas of interest selected via natural language queries. Our system is thefirst of its kind to be deployed on resource-constrained devices, such as MAVs,leveraging vision-language information for real-world robotic tasks.</description>
      <author>example@mail.com (Sebastián Barbas Laina, Simon Boche, Sotiris Papatheodorou, Simon Schaefer, Jaehyung Jung, Stefan Leutenegger)</author>
      <guid isPermaLink="false">2504.08603v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>The Invisible EgoHand: 3D Hand Forecasting through EgoBody Pose Estimation</title>
      <link>http://arxiv.org/abs/2504.08654v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散的Transformer架构，用于从自视角视频中预测双手的3D轨迹和姿态，无论是否在视野内。&lt;h4&gt;背景&lt;/h4&gt;现有方法只关注预测手的位置，不考虑手的运动，并且仅在手在视野内时进行预测，忽略了即使手不在视野内，仍可以推断出手的大致位置。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，从自视角视频中预测双手的3D轨迹和姿态，无论手是否在视野内。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为EgoH4的基于扩散的Transformer架构，它接受观察序列和相机姿态作为输入，然后预测相机佩戴者的双手的未来3D运动和姿态。该方法利用全身姿态信息，并通过降噪和可见性预测器来提高预测的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;EgoH4在Ego-Exo4D数据集上进行了评估，该数据集结合了带有身体和手部注释的子集。在训练了156K个序列后，在34K个序列上进行了评估。EgoH4在预测手部轨迹和姿态方面分别将ADE和MPJPE的误差减少了3.4cm和5.1cm。&lt;h4&gt;结论&lt;/h4&gt;EgoH4通过提高预测准确性，为理解人类意图提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从自视角预测手部运动和姿态对于理解人类意图至关重要。然而，现有方法仅关注预测位置，不考虑手的运动，并且仅在视野内可见时进行预测。这种限制忽略了即使手不在视野内，仍可以推断出手的大致位置的事实。在本文中，我们提出了一种从自视角视频中预测双手的3D轨迹和姿态的方法，无论手是否在视野内。我们提出了一个用于自视角手部预测的基于扩散的Transformer架构，名为EgoH4，它接受观察序列和相机姿态作为输入，然后预测相机佩戴者的双手的未来3D运动和姿态。我们利用全身姿态信息，允许其他关节为手部运动提供约束。我们对手部和身体关节进行降噪，并使用手关节的可见性预测器和3D到2D重投影损失来最小化手部在视野内时的误差。我们在Ego-Exo4D数据集上评估了EgoH4，该数据集结合了带有身体和手部注释的子集。我们分别训练了156K个序列和评估了34K个序列。EgoH4在预测手部轨迹和姿态方面分别将ADE和MPJPE的误差减少了3.4cm和5.1cm。项目页面：https://masashi-hatano.github.io/EgoH4/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forecasting hand motion and pose from an egocentric perspective is essentialfor understanding human intention. However, existing methods focus solely onpredicting positions without considering articulation, and only when the handsare visible in the field of view. This limitation overlooks the fact thatapproximate hand positions can still be inferred even when they are outside thecamera's view. In this paper, we propose a method to forecast the 3Dtrajectories and poses of both hands from an egocentric video, both in and outof the field of view. We propose a diffusion-based transformer architecture forEgocentric Hand Forecasting, EgoH4, which takes as input the observationsequence and camera poses, then predicts future 3D motion and poses for bothhands of the camera wearer. We leverage full-body pose information, allowingother joints to provide constraints on hand motion. We denoise the hand andbody joints along with a visibility predictor for hand joints and a 3D-to-2Dreprojection loss that minimizes the error when hands are in-view. We evaluateEgoH4 on the Ego-Exo4D dataset, combining subsets with body and handannotations. We train on 156K sequences and evaluate on 34K sequences,respectively. EgoH4 improves the performance by 3.4cm and 5.1cm over thebaseline in terms of ADE for hand trajectory forecasting and MPJPE for handpose forecasting. Project page: https://masashi-hatano.github.io/EgoH4/</description>
      <author>example@mail.com (Masashi Hatano, Zhifan Zhu, Hideo Saito, Dima Damen)</author>
      <guid isPermaLink="false">2504.08654v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Towards Efficient and Robust Moment Retrieval System: A Unified Framework for Multi-Granularity Models and Temporal Reranking</title>
      <link>http://arxiv.org/abs/2504.08384v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，旨在通过四个关键创新来提高交互式视频检索的效果，包括集成不同模型的搜索策略、存储优化技术、时间搜索机制和时间重排序方法。&lt;h4&gt;背景&lt;/h4&gt;长视频理解对交互检索系统来说是一个挑战，因为传统方法难以高效处理大量视频内容。&lt;h4&gt;目的&lt;/h4&gt;提升交互式视频检索的准确性、效率和使用者可理解性。&lt;h4&gt;方法&lt;/h4&gt;包括：(1) 集成粗粒度（CLIP）和细粒度（BEIT3）模型的集成搜索策略；(2) 通过TransNetV2选择代表性的关键帧并去除重复内容来优化存储；(3) 使用双重查询定位视频片段的起始和结束点；(4) 利用相邻帧的上下文稳定排名。&lt;h4&gt;主要发现&lt;/h4&gt;在已知项搜索和问答任务上的评估显示，该框架在检索精度、效率和用户可理解性方面都有显著提升。&lt;h4&gt;结论&lt;/h4&gt;该框架为现实世界的交互视频检索应用提供了一种稳健的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Long-form video understanding presents significant challenges for interactive retrieval systems, as conventional methods struggle to process extensive video content efficiently. Existing approaches often rely on single models, inefficient storage, unstable temporal search, and context-agnostic reranking, limiting their effectiveness. This paper presents a novel framework to enhance interactive video retrieval through four key innovations: (1) an ensemble search strategy that integrates coarse-grained (CLIP) and fine-grained (BEIT3) models to improve retrieval accuracy, (2) a storage optimization technique that reduces redundancy by selecting representative keyframes via TransNetV2 and deduplication, (3) a temporal search mechanism that localizes video segments using dual queries for start and end points, and (4) a temporal reranking approach that leverages neighboring frame context to stabilize rankings. Evaluated on known-item search and question-answering tasks, our framework demonstrates substantial improvements in retrieval precision, efficiency, and user interpretability, offering a robust solution for real-world interactive video retrieval applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-form video understanding presents significant challenges for interactiveretrieval systems, as conventional methods struggle to process extensive videocontent efficiently. Existing approaches often rely on single models,inefficient storage, unstable temporal search, and context-agnostic reranking,limiting their effectiveness. This paper presents a novel framework to enhanceinteractive video retrieval through four key innovations: (1) an ensemblesearch strategy that integrates coarse-grained (CLIP) and fine-grained (BEIT3)models to improve retrieval accuracy, (2) a storage optimization technique thatreduces redundancy by selecting representative keyframes via TransNetV2 anddeduplication, (3) a temporal search mechanism that localizes video segmentsusing dual queries for start and end points, and (4) a temporal rerankingapproach that leverages neighboring frame context to stabilize rankings.Evaluated on known-item search and question-answering tasks, our frameworkdemonstrates substantial improvements in retrieval precision, efficiency, anduser interpretability, offering a robust solution for real-world interactivevideo retrieval applications.</description>
      <author>example@mail.com (Huu-Loc Tran, Tinh-Anh Nguyen-Nhu, Huu-Phong Phan-Nguyen, Tien-Huy Nguyen, Nhat-Minh Nguyen-Dich, Anh Dao, Huy-Duc Do, Quan Nguyen, Hoang M. Le, Quang-Vinh Dinh)</author>
      <guid isPermaLink="false">2504.08384v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Cooperative Perception Through Asynchronous Vehicle to Infrastructure Framework with Delay Mitigation for Connected and Automated Vehicles</title>
      <link>http://arxiv.org/abs/2504.08172v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 9 figures, This paper is under review of SAE Journal of  Connected and Automated Vehicles&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于单目交通摄像头的V2I框架，用于在道路交叉口检测3D对象，以提高自动驾驶车辆的感知范围和场景表示。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶车辆感知是关键组成部分，但传感器经常因为其他车辆、基础设施或周围物体造成盲区。虽然规划和控制算法的进步有助于自动驾驶车辆在低速和简单场景中应对盲区中的突发物体，但在高速和复杂交叉口仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提高自动驾驶车辆在复杂交叉口中的场景表示，为违规的敌对车辆提供足够的时间和距离进行反应。&lt;h4&gt;方法&lt;/h4&gt;提出了一种V2I框架，使用路边单元（RSU）的检测结果和车载系统进行异步晚期融合，以及一个时间延迟补偿模块来补偿RSU的处理和传输延迟。&lt;h4&gt;主要发现&lt;/h4&gt;该框架通过模拟和验证与Waymo行业报告中描述的场景相似的场景，结果表明该方法提高了场景表示和自动驾驶车辆的感知范围。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法改善了场景表示，为自动驾驶车辆提供了足够的时间和空间来应对违规的敌对车辆。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perception is a key component of Automated vehicles (AVs). However, sensorsmounted to the AVs often encounter blind spots due to obstructions from othervehicles, infrastructure, or objects in the surrounding area. While recentadvancements in planning and control algorithms help AVs react to sudden objectappearances from blind spots at low speeds and less complex scenarios,challenges remain at high speeds and complex intersections. Vehicle toInfrastructure (V2I) technology promises to enhance scene representation forAVs in complex intersections, providing sufficient time and distance to reactto adversary vehicles violating traffic rules. Most existing methods forinfrastructure-based vehicle detection and tracking rely on LIDAR, RADAR orsensor fusion methods, such as LIDAR-Camera and RADAR-Camera. Although LIDARand RADAR provide accurate spatial information, the sparsity of point clouddata limits its ability to capture detailed object contours of objects faraway, resulting in inaccurate 3D object detection results. Furthermore, theabsence of LIDAR or RADAR at every intersection increases the cost ofimplementing V2I technology. To address these challenges, this paper proposes aV2I framework that utilizes monocular traffic cameras at road intersections todetect 3D objects. The results from the roadside unit (RSU) are then combinedwith the on-board system using an asynchronous late fusion method to enhancescene representation. Additionally, the proposed framework provides a timedelay compensation module to compensate for the processing and transmissiondelay from the RSU. Lastly, the V2I framework is tested by simulating andvalidating a scenario similar to the one described in an industry report byWaymo. The results show that the proposed method improves the scenerepresentation and the AV's perception range, giving enough time and space toreact to adversary vehicles.</description>
      <author>example@mail.com (Nithish Kumar Saravanan, Varun Jammula, Yezhou Yang, Jeffrey Wishart, Junfeng Zhao)</author>
      <guid isPermaLink="false">2504.08172v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>FMLGS: Fast Multilevel Language Embedded Gaussians for Part-level Interactive Agents</title>
      <link>http://arxiv.org/abs/2504.08581v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FMLGS的方法，用于在3D Gaussian Splatting中支持部分级别的开放词汇查询，旨在解决多粒度交互的挑战。&lt;h4&gt;背景&lt;/h4&gt;语义交互辐射场长期以来是3D现实世界应用（如具身AI实现场景理解和操作）的有希望的主干。然而，由于语言的模糊性和对物体组件查询时的质量退化，多粒度交互仍然是一个具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出FMLGS方法，以支持部分级别的开放词汇查询，并构建和查询一致的对象和部分级别语义。&lt;h4&gt;方法&lt;/h4&gt;设计了基于Segment Anything Model 2（SAM2）的高效流程来构建和查询一致的对象和部分级别语义。此外，还设计了语义偏差策略来解决物体部分之间语言模糊的问题，通过插值细粒度目标的语义特征来丰富信息。&lt;h4&gt;主要发现&lt;/h4&gt;FMLGS方法不仅能够更好地定位指定的部分级别目标，而且在速度和准确性方面都取得了第一名的成绩，比LERF快98倍，比LangSplat快4倍，比LEGaussians快2.5倍。同时，FMLGS被集成为一个虚拟代理，可以交互式地导航3D场景，定位目标，并通过聊天界面响应用户需求。&lt;h4&gt;结论&lt;/h4&gt;FMLGS方法在3D场景理解和操作方面具有巨大潜力，可以进一步扩展和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The semantically interactive radiance field has long been a promisingbackbone for 3D real-world applications, such as embodied AI to achieve sceneunderstanding and manipulation. However, multi-granularity interaction remainsa challenging task due to the ambiguity of language and degraded quality whenit comes to queries upon object components. In this work, we present FMLGS, anapproach that supports part-level open-vocabulary query within 3D GaussianSplatting (3DGS). We propose an efficient pipeline for building and queryingconsistent object- and part-level semantics based on Segment Anything Model 2(SAM2). We designed a semantic deviation strategy to solve the problem oflanguage ambiguity among object parts, which interpolates the semantic featuresof fine-grained targets for enriched information. Once trained, we can queryboth objects and their describable parts using natural language. Comparisonswith other state-of-the-art methods prove that our method can not only betterlocate specified part-level targets, but also achieve first-place performanceconcerning both speed and accuracy, where FMLGS is 98 x faster than LERF, 4 xfaster than LangSplat and 2.5 x faster than LEGaussians. Meanwhile, we furtherintegrate FMLGS as a virtual agent that can interactively navigate through 3Dscenes, locate targets, and respond to user demands through a chat interface,which demonstrates the potential of our work to be further expanded and appliedin the future.</description>
      <author>example@mail.com (Xin Tan, Yuzhou Ji, He Zhu, Yuan Xie)</author>
      <guid isPermaLink="false">2504.08581v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>LGRPool: Hierarchical Graph Pooling Via Local-Global Regularisation</title>
      <link>http://arxiv.org/abs/2504.08530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  f tables, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LGRPool的分层图池化（HGP）方法，旨在解决传统图神经网络（GNN）的扁平化和多尺度不足问题。&lt;h4&gt;背景&lt;/h4&gt;传统GNN在处理图数据时缺乏对全局拓扑结构的考虑，且多尺度分析不足。&lt;h4&gt;目的&lt;/h4&gt;提出LGRPool方法，以期望最大化机器学习框架为基础，通过正则化器使全局拓扑信息与不同尺度的局部消息传递保持一致。&lt;h4&gt;方法&lt;/h4&gt;LGRPool通过在不同层级的HGP表示中，利用正则化器来强制全局拓扑信息与局部消息传递相匹配。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，LGRPool在图分类基准测试中略优于一些基线方法。&lt;h4&gt;结论&lt;/h4&gt;LGRPool是一种有效的HGP方法，能够提升图分类的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种分层图池化（HGP）方法，旨在解决传统图神经网络（GNN）的扁平化和多尺度不足问题。在机器学习的期望最大化框架下，通过正则化器使全局拓扑信息与不同尺度的局部消息传递相匹配。实验结果表明，该方法在图分类基准测试中略优于一些基线方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hierarchical graph pooling(HGP) are designed to consider the fact thatconventional graph neural networks(GNN) are inherently flat and are also notmultiscale. However, most HGP methods suffer not only from lack of consideringglobal topology of the graph and focusing on the feature learning aspect, butalso they do not align local and global features since graphs should inherentlybe analyzed in a multiscale way. LGRPool is proposed in the present paper as aHGP in the framework of expectation maximization in machine learning thataligns local and global aspects of message passing with each other using aregularizer to force the global topological information to be inline with thelocal message passing at different scales through the representations atdifferent layers of HGP. Experimental results on some graph classificationbenchmarks show that it slightly outperforms some baselines.</description>
      <author>example@mail.com (Farshad Noravesh, Reza Haffari, Layki Soon, Arghya Pal)</author>
      <guid isPermaLink="false">2504.08530v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Embodied Image Captioning: Self-supervised Learning Agents for Spatially Coherent Image Descriptions</title>
      <link>http://arxiv.org/abs/2504.08531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 8 figures, 5 tables, code and test set annotations  available at https://hsp-iit.github.io/embodied-captioning/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种自监督方法，通过主动探索通用环境来提高智能体描述任意对象的能力。该方法通过共识机制提高了现有标题模型的准确性和一致性。&lt;h4&gt;背景&lt;/h4&gt;当前模型在获取连贯图像标题方面存在困难，因为不同的摄像头视角和杂乱的环境。&lt;h4&gt;目的&lt;/h4&gt;提高智能体在描述任意对象时的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一个三阶段框架，用于微调现有的标题模型：1）智能体探索环境，收集噪声图像-标题对；2）使用大型语言模型通过共识为每个对象实例提炼一致的伪标题；3）使用对比学习对这些伪标题进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;1）训练出的策略可以挖掘出与经典基线相比具有更高不一致性的样本；2）与现有方法相比，伪标题方法结合所有策略具有更高的语义相似性；3）微调显著提高了标题的准确性和一致性。&lt;h4&gt;结论&lt;/h4&gt;该方法是有效的，可以显著提高智能体描述任意对象的能力。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种自监督方法来提高智能体在描述任意对象时的能力，同时积极探索通用环境。这是一个具有挑战性的问题，因为当前模型由于不同的摄像头视角和杂乱的环境而难以获得连贯的图像标题。我们提出了一种三阶段框架来微调现有的标题模型，通过共识机制提高了跨视图的标题准确性和一致性。首先，智能体探索环境，收集噪声图像-标题对。然后，通过共识使用大型语言模型提炼每个对象实例的一致的伪标题。最后，使用对比学习对这些伪标题进行微调。我们分析了标题模型、探索策略、伪标签方法和微调策略的组合性能，在我们的手动标注测试集上。结果表明，可以训练出一种策略，与经典基线相比，可以挖掘出具有更高不一致性的样本。我们的伪标题方法与所有策略结合，与现有方法相比具有更高的语义相似性，微调显著提高了标题的准确性和一致性。代码和测试集注释可在https://hsp-iit.github.io/embodied-captioning/获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a self-supervised method to improve an agent's abilities indescribing arbitrary objects while actively exploring a generic environment.This is a challenging problem, as current models struggle to obtain coherentimage captions due to different camera viewpoints and clutter. We propose athree-phase framework to fine-tune existing captioning models that enhancescaption accuracy and consistency across views via a consensus mechanism. First,an agent explores the environment, collecting noisy image-caption pairs. Then,a consistent pseudo-caption for each object instance is distilled via consensususing a large language model. Finally, these pseudo-captions are used tofine-tune an off-the-shelf captioning model, with the addition of contrastivelearning. We analyse the performance of the combination of captioning models,exploration policies, pseudo-labeling methods, and fine-tuning strategies, onour manually labeled test set. Results show that a policy can be trained tomine samples with higher disagreement compared to classical baselines. Ourpseudo-captioning method, in combination with all policies, has a highersemantic similarity compared to other existing methods, and fine-tuningimproves caption accuracy and consistency by a significant margin. Code andtest set annotations available athttps://hsp-iit.github.io/embodied-captioning/</description>
      <author>example@mail.com (Tommaso Galliena, Tommaso Apicella, Stefano Rosa, Pietro Morerio, Alessio Del Bue, Lorenzo Natale)</author>
      <guid isPermaLink="false">2504.08531v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Seaweed-7B: Cost-Effective Training of Video Generation Foundation Model</title>
      <link>http://arxiv.org/abs/2504.08685v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种成本效益高的策略来训练视频生成基础模型。&lt;h4&gt;背景&lt;/h4&gt;本文提出了一种名为Seaweed-7B的中型研究模型，该模型拥有约70亿参数，通过665,000小时的H100 GPU时间从头开始训练。&lt;h4&gt;目的&lt;/h4&gt;在资源受限的环境中，设计选择对模型性能至关重要，本文强调了提高中型扩散模型性能的关键设计决策。&lt;h4&gt;方法&lt;/h4&gt;通过实证研究，分析了Seaweed-7B的性能，并与在更大GPU资源上训练的更大模型进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;Seaweed-7B在有限的计算资源下达到了与更大模型相当甚至超越的性能，并且模型具有较强的泛化能力，可以通过轻量级微调或继续训练有效地适应广泛的下游应用。&lt;h4&gt;结论&lt;/h4&gt;Seaweed-7B是一种在资源受限的情况下高效训练的视频生成模型，具有良好的性能和适应性。&lt;h4&gt;翻译&lt;/h4&gt;本技术报告提出了一种成本效益高的策略来训练视频生成基础模型。我们提出了一种名为Seaweed-7B的中型研究模型，该模型拥有约70亿参数，通过665,000小时的H100 GPU时间从头开始训练。尽管使用了有限的计算资源，Seaweed-7B在性能上与更大规模的当代视频生成模型具有高度竞争力。在资源受限的环境中，设计选择对模型性能至关重要。本文强调了提高中型扩散模型性能的关键设计决策。通过实证研究，我们发现Seaweed-7B在有限的计算资源下达到了与更大模型相当甚至超越的性能，并且模型具有较强的泛化能力，可以通过轻量级微调或继续训练有效地适应广泛的下游应用。更多信息请查看项目页面https://seaweed.video/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report presents a cost-efficient strategy for training a videogeneration foundation model. We present a mid-sized research model withapproximately 7 billion parameters (7B) called Seaweed-7B trained from scratchusing 665,000 H100 GPU hours. Despite being trained with moderate computationalresources, Seaweed-7B demonstrates highly competitive performance compared tocontemporary video generation models of much larger size. Design choices areespecially crucial in a resource-constrained setting. This technical reporthighlights the key design decisions that enhance the performance of themedium-sized diffusion model. Empirically, we make two observations: (1)Seaweed-7B achieves performance comparable to, or even surpasses, larger modelstrained on substantially greater GPU resources, and (2) our model, whichexhibits strong generalization ability, can be effectively adapted across awide range of downstream applications either by lightweight fine-tuning orcontinue training. See the project page at https://seaweed.video/</description>
      <author>example@mail.com (Team Seawead, Ceyuan Yang, Zhijie Lin, Yang Zhao, Shanchuan Lin, Zhibei Ma, Haoyuan Guo, Hao Chen, Lu Qi, Sen Wang, Feng Cheng, Feilong Zuo Xuejiao Zeng, Ziyan Yang, Fangyuan Kong, Zhiwu Qing, Fei Xiao, Meng Wei, Tuyen Hoang, Siyu Zhang, Peihao Zhu, Qi Zhao, Jiangqiao Yan, Liangke Gui, Sheng Bi, Jiashi Li, Yuxi Ren, Rui Wang, Huixia Li, Xuefeng Xiao, Shu Liu, Feng Ling, Heng Zhang, Houmin Wei, Huafeng Kuang, Jerry Duncan, Junda Zhang, Junru Zheng, Li Sun, Manlin Zhang, Renfei Sun, Xiaobin Zhuang, Xiaojie Li, Xin Xia, Xuyan Chi, Yanghua Peng, Yuping Wang, Yuxuan Wang, Zhongkai Zhao, Zhuo Chen, Zuquan Song, Zhenheng Yang, Jiashi Feng, Jianchao Yang, Lu Jiang)</author>
      <guid isPermaLink="false">2504.08685v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>PNE-SGAN: Probabilistic NDT-Enhanced Semantic Graph Attention Network for LiDAR Loop Closure Detection</title>
      <link>http://arxiv.org/abs/2504.08280v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PNE-SGAN是一种用于LiDAR闭环检测（LCD）的方法，旨在提高SLAM的鲁棒性和准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的LiDAR闭环检测方法在鲁棒性和准确性方面存在挑战，如语义图方法缺乏时间鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;提出PNE-SGAN，以克服现有方法的局限性，实现更准确和鲁棒的LiDAR闭环检测。&lt;h4&gt;方法&lt;/h4&gt;PNE-SGAN通过使用NDT协方差矩阵作为几何节点特征，并通过图注意力网络（GAT）进行处理来增强语义图。它将图相似度分数整合到概率时间滤波框架中，并使用HMM/Bayes滤波器模型，同时结合不确定的里程计进行运动建模，并利用前向-后向平滑处理模糊性。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI序列上的评估表明，PNE-SGAN实现了96.2%和95.1%的平均精度，显著优于现有方法，特别是在双向闭环场景中。&lt;h4&gt;结论&lt;/h4&gt;PNE-SGAN通过结合详细的NDT几何和概率时间推理原则，为LiDAR LCD提供了一个高度准确和鲁棒的解决方案，增强了在复杂、大规模环境中的SLAM可靠性。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR闭环检测（LCD）对于一致的SLAM至关重要，但面临着鲁棒性和准确性的挑战。现有的方法，包括语义图方法，通常遭受粗略的几何表示，并且缺乏对噪声、动态和视角变化的时态鲁棒性。我们引入了PNE-SGAN，一种概率NDT增强语义图注意力网络，以克服这些限制。PNE-SGAN通过使用NDT协方差矩阵作为丰富、判别性的几何节点特征，并通过图注意力网络（GAT）进行处理来增强语义图。关键的是，它将图相似度分数整合到一个概率时间滤波框架中（建模为HMM/Bayes滤波器），结合不确定的里程计进行运动建模，并利用前向-后向平滑有效地处理模糊性。在具有挑战性的KITTI序列（00和08）上的评估表明，实现了96.2%和95.1%的平均精度，分别。PNE-SGAN显著优于现有方法，尤其是在其他方法失败的困难双向闭环场景中。通过将详细的NDT几何与原则性的概率时间推理相结合，PNE-SGAN为LiDAR LCD提供了一个高度准确和鲁棒的解决方案，增强了在复杂、大规模环境中的SLAM可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR loop closure detection (LCD) is crucial for consistent SimultaneousLocalization and Mapping (SLAM) but faces challenges in robustness andaccuracy. Existing methods, including semantic graph approaches, often sufferfrom coarse geometric representations and lack temporal robustness againstnoise, dynamics, and viewpoint changes. We introduce PNE-SGAN, a ProbabilisticNDT-Enhanced Semantic Graph Attention Network, to overcome these limitations.PNE-SGAN enhances semantic graphs by using Normal Distributions Transform (NDT)covariance matrices as rich, discriminative geometric node features, processedvia a Graph Attention Network (GAT). Crucially, it integrates graph similarityscores into a probabilistic temporal filtering framework (modeled as anHMM/Bayes filter), incorporating uncertain odometry for motion modeling andutilizing forward-backward smoothing to effectively handle ambiguities.Evaluations on challenging KITTI sequences (00 and 08) demonstratestate-of-the-art performance, achieving Average Precision of 96.2\% and 95.1\%,respectively. PNE-SGAN significantly outperforms existing methods, particularlyin difficult bidirectional loop scenarios where others falter. By synergizingdetailed NDT geometry with principled probabilistic temporal reasoning,PNE-SGAN offers a highly accurate and robust solution for LiDAR LCD, enhancingSLAM reliability in complex, large-scale environments.</description>
      <author>example@mail.com (Xiong Li, Shulei Liu, Xingning Chen, Yisong Wu, Dong Zhu)</author>
      <guid isPermaLink="false">2504.08280v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Latent Diffusion Autoencoders: Toward Efficient and Meaningful Unsupervised Representation Learning in Medical Imaging</title>
      <link>http://arxiv.org/abs/2504.08635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 9 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为LDAE的潜在扩散自动编码器，这是一种用于医学图像中高效且有意义的不监督学习的创新框架，重点关注阿尔茨海默病（AD）。&lt;h4&gt;背景&lt;/h4&gt;该研究使用来自ADNI数据库的AD患者的脑部MRI作为案例研究。&lt;h4&gt;目的&lt;/h4&gt;验证LDAE方法的有效性，并证明其在捕获与AD和老龄化相关的3D脑部MRI的有意义语义表示方面的能力，以及其在生成和重建高质量图像同时保持计算效率的能力。&lt;h4&gt;方法&lt;/h4&gt;LDAE在压缩的潜在表示中应用扩散过程，与传统的在图像空间操作的扩散自动编码器不同。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果支持以下假设：(i) LDAE能够有效地捕获与AD和老龄化相关的3D脑部MRI的有意义语义表示；(ii) LDAE在生成和重建图像方面表现出高质量，并且计算效率高；(iii) 学习到的语义表示可以进行属性操作，产生解剖学上合理的修改；(iv) 与传统的扩散自动编码器相比，LDAE显著提高了推理吞吐量（20倍更快），同时也提高了重建质量。&lt;h4&gt;结论&lt;/h4&gt;LDAE被定位为可扩展医学图像应用的有希望的框架，有潜力成为医学图像分析的基础模型。&lt;h4&gt;翻译&lt;/h4&gt;This study presents Latent Diffusion Autoencoder (LDAE), a novel encoder-decoder diffusion-based framework for efficient and meaningful unsupervised learning in medical imaging, focusing on Alzheimer disease (AD) using brain MR from the ADNI database as a case study.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study presents Latent Diffusion Autoencoder (LDAE), a novelencoder-decoder diffusion-based framework for efficient and meaningfulunsupervised learning in medical imaging, focusing on Alzheimer disease (AD)using brain MR from the ADNI database as a case study. Unlike conventionaldiffusion autoencoders operating in image space, LDAE applies the diffusionprocess in a compressed latent representation, improving computationalefficiency and making 3D medical imaging representation learning tractable. Tovalidate the proposed approach, we explore two key hypotheses: (i) LDAEeffectively captures meaningful semantic representations on 3D brain MRassociated with AD and ageing, and (ii) LDAE achieves high-quality imagegeneration and reconstruction while being computationally efficient.Experimental results support both hypotheses: (i) linear-probe evaluationsdemonstrate promising diagnostic performance for AD (ROC-AUC: 90%, ACC: 84%)and age prediction (MAE: 4.1 years, RMSE: 5.2 years); (ii) the learned semanticrepresentations enable attribute manipulation, yielding anatomically plausiblemodifications; (iii) semantic interpolation experiments show strongreconstruction of missing scans, with SSIM of 0.969 (MSE: 0.0019) for a 6-monthgap. Even for longer gaps (24 months), the model maintains robust performance(SSIM &gt; 0.93, MSE &lt; 0.004), indicating an ability to capture temporalprogression trends; (iv) compared to conventional diffusion autoencoders, LDAEsignificantly increases inference throughput (20x faster) while also enhancingreconstruction quality. These findings position LDAE as a promising frameworkfor scalable medical imaging applications, with the potential to serve as afoundation model for medical image analysis. Code available athttps://github.com/GabrieleLozupone/LDAE</description>
      <author>example@mail.com (Gabriele Lozupone, Alessandro Bria, Francesco Fontanella, Frederick J. A. Meijer, Claudio De Stefano, Henkjan Huisman)</author>
      <guid isPermaLink="false">2504.08635v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>CMIP-CIL: A Cross-Modal Benchmark for Image-Point Class Incremental Learning</title>
      <link>http://arxiv.org/abs/2504.08422v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图像点类增量学习方法，用于帮助3D视觉机器人从2D图像中持续学习类别知识，提高其在动态环境中的感知能力。&lt;h4&gt;背景&lt;/h4&gt;一些增量学习方法在处理单模态遗忘时表现良好，但在跨模态情况下失败；而另一些方法虽然处理了训练/测试数据集中的模态差异，但假设它们之间没有模态差距。&lt;h4&gt;目的&lt;/h4&gt;探索跨模态任务，提出一个基准CMIP-CIL，并解决跨模态灾难性遗忘问题。&lt;h4&gt;方法&lt;/h4&gt;在预训练阶段，采用掩码点云和渲染的多视角图像，在对比学习框架内，通过图像-点对应关系的泛化来增强视觉模型。在增量学习阶段，通过冻结主干网络并促进对象表示接近其原型，模型能够有效保留和泛化先前看到的类别知识，同时继续学习新的类别。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上进行了全面实验，实验证明该方法达到了最先进的水平，大幅优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在增量学习方面取得了显著成果，为3D视觉机器人在动态环境中的感知能力提升提供了有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-point class incremental learning helps the 3D-points-vision robotscontinually learn category knowledge from 2D images, improving their perceptualcapability in dynamic environments. However, some incremental learning methodsaddress unimodal forgetting but fail in cross-modal cases, while others handlemodal differences within training/testing datasets but assume no modal gapsbetween them. We first explore this cross-modal task, proposing a benchmarkCMIP-CIL and relieving the cross-modal catastrophic forgetting problem. Itemploys masked point clouds and rendered multi-view images within a contrastivelearning framework in pre-training, empowering the vision model with thegeneralizations of image-point correspondence. In the incremental stage, byfreezing the backbone and promoting object representations close to theirrespective prototypes, the model effectively retains and generalizes knowledgeacross previously seen categories while continuing to learn new ones. Weconduct comprehensive experiments on the benchmark datasets. Experiments provethat our method achieves state-of-the-art results, outperforming the baselinemethods by a large margin.</description>
      <author>example@mail.com (Chao Qi, Jianqin Yin, Ren Zhang)</author>
      <guid isPermaLink="false">2504.08422v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>GigaTok: Scaling Visual Tokenizers to 3 Billion Parameters for Autoregressive Image Generation</title>
      <link>http://arxiv.org/abs/2504.08736v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  project page: https://silentview.github.io/GigaTok&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GigaTok是一种新的视觉自动回归图像生成方法，旨在在扩展视觉编码器时同时提高图像重建、生成和表示学习的能力。&lt;h4&gt;背景&lt;/h4&gt;在自动回归图像生成中，视觉编码器将图像压缩为紧凑的离散潜在标记，以实现高效的下游模型训练。然而，扩展视觉编码器通常会导致生成质量下降。&lt;h4&gt;目的&lt;/h4&gt;解决在扩展视觉编码器时图像重建和生成质量之间的矛盾。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为语义正则化的方法，该方法通过将编码器的语义一致特征与编码器特征对齐，以减轻潜在空间复杂性的增长。此外，还探索了三种扩展标记器的关键实践：(1) 使用一维标记器以获得更好的可扩展性；(2) 在扩展编码器和解码器时优先扩展解码器；(3) 使用熵损失来稳定训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过扩展到30亿个参数，GigaTok在重建、下游AR生成和下游AR表示质量方面实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;GigaTok通过引入语义正则化和优化扩展策略，有效地解决了扩展视觉编码器时图像重建和生成质量之间的矛盾，实现了图像生成性能的提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In autoregressive (AR) image generation, visual tokenizers compress imagesinto compact discrete latent tokens, enabling efficient training of downstreamautoregressive models for visual generation via next-token prediction. Whilescaling visual tokenizers improves image reconstruction quality, it oftendegrades downstream generation quality -- a challenge not adequately addressedin existing literature. To address this, we introduce GigaTok, the firstapproach to simultaneously improve image reconstruction, generation, andrepresentation learning when scaling visual tokenizers. We identify the growingcomplexity of latent space as the key factor behind the reconstruction vs.generation dilemma. To mitigate this, we propose semantic regularization, whichaligns tokenizer features with semantically consistent features from apre-trained visual encoder. This constraint prevents excessive latent spacecomplexity during scaling, yielding consistent improvements in bothreconstruction and downstream autoregressive generation. Building on semanticregularization, we explore three key practices for scaling tokenizers:(1) using1D tokenizers for better scalability, (2) prioritizing decoder scaling whenexpanding both encoder and decoder, and (3) employing entropy loss to stabilizetraining for billion-scale tokenizers. By scaling to $\bf{3 \space billion}$parameters, GigaTok achieves state-of-the-art performance in reconstruction,downstream AR generation, and downstream AR representation quality.</description>
      <author>example@mail.com (Tianwei Xiong, Jun Hao Liew, Zilong Huang, Jiashi Feng, Xihui Liu)</author>
      <guid isPermaLink="false">2504.08736v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Boosting the Class-Incremental Learning in 3D Point Clouds via Zero-Collection-Cost Basic Shape Pre-Training</title>
      <link>http://arxiv.org/abs/2504.08412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对3D点云增量学习的新方法，该方法不依赖于范例，且在预训练模型的基础上，通过引入3D几何知识，显著提升了模型的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的3D点云增量学习方法依赖于范例来防止模型发生灾难性遗忘，但在没有范例的情况下，性能会大幅下降。现有的预训练模型方法在2D领域取得了最先进的成果，但由于3D领域预训练数据集有限且对细粒度几何细节关注不足，这些方法无法迁移到3D领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种不依赖范例的3D点云增量学习方法，通过引入3D几何知识，提高模型在增量学习中的性能。&lt;h4&gt;方法&lt;/h4&gt;构建了一个零收集成本的基形状数据集，用于模型预训练，使模型能够获得广泛的3D几何知识。在此基础上，提出了一种嵌入3D几何知识的增量学习框架，该框架适用于无范例设置。在增量学习阶段，通过正则化相同类别的数据表示来计算类别原型，并在学习过程中持续调整，帮助模型记住不同类别的形状特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在各种基准数据集上，无论是在无范例还是基于范例的设置下，都显著优于其他基线方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过引入3D几何知识，有效解决了3D点云增量学习中范例依赖和性能下降的问题，为3D点云增量学习提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel incremental learning method for 3D point clouds that does not rely on exemplars, and improves the performance of the model by introducing 3D geometric knowledge.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing class-incremental learning methods in 3D point clouds rely onexemplars (samples of former classes) to resist the catastrophic forgetting ofmodels, and exemplar-free settings will greatly degrade the performance. Forexemplar-free incremental learning, the pre-trained model methods have achievedstate-of-the-art results in 2D domains. However, these methods cannot bemigrated to the 3D domains due to the limited pre-training datasets andinsufficient focus on fine-grained geometric details. This paper breaks throughthese limitations, proposing a basic shape dataset with zero collection costfor model pre-training. It helps a model obtain extensive knowledge of 3Dgeometries. Based on this, we propose a framework embedded with 3D geometryknowledge for incremental learning in point clouds, compatible withexemplar-free (-based) settings. In the incremental stage, the geometryknowledge is extended to represent objects in point clouds. The class prototypeis calculated by regularizing the data representation with the same categoryand is kept adjusting in the learning process. It helps the model remember theshape features of different categories. Experiments show that our methodoutperforms other baseline methods by a large margin on various benchmarkdatasets, considering both exemplar-free (-based) settings.</description>
      <author>example@mail.com (Chao Qi, Jianqin Yin, Meng Chen, Yingchun Niu, Yuan Sun)</author>
      <guid isPermaLink="false">2504.08412v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>DSM: Building A Diverse Semantic Map for 3D Visual Grounding</title>
      <link>http://arxiv.org/abs/2504.08307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures, submitted to IROS, Project Page:  https://binicey.github.io/DSM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对机器人3D视觉定位任务的多样化语义图构建方法，利用VLMs捕捉场景中对象的潜在语义属性和关系，并通过几何滑动窗口图构建策略创建多样化语义图（DSM），以增强对定位信息的理解。&lt;h4&gt;背景&lt;/h4&gt;近年来，多模态大型语言模型（VLMs）在机器人领域的应用日益增多，但现有方法在3D视觉定位任务中往往侧重于通过几何和视觉信息获取场景信息，而忽略了从场景中提取多样化的语义信息以及理解丰富的隐含语义属性。&lt;h4&gt;目的&lt;/h4&gt;提出一种专门为机器人执行3D视觉定位任务设计的多样化语义图构建方法，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;该方法利用VLMs捕捉场景中对象的潜在语义属性和关系，通过几何滑动窗口图构建策略创建DSM，并基于DSM增强对定位信息的理解，引入了名为DSM-Grounding的新方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在语义分割和3D视觉定位等任务中优于现有方法，尤其是在与现有最佳方法相比的整体指标上表现出色。&lt;h4&gt;结论&lt;/h4&gt;该方法在导航和抓取任务上对机器人进行了部署，验证了其在导航和抓取任务中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, with the growing research and application of multimodallarge language models (VLMs) in robotics, there has been an increasing trend of utilizing VLMs for robotic scene understanding tasks. Existing approaches that use VLMs for 3D Visual Grounding tasks often focus on obtaining scene information through geometric and visual information, overlooking the extraction of diverse semantic information from the scene and the understanding of rich implicit semantic attributes, such as appearance, physics, and affordance. The 3D scene graph, which combines geometry and language, is an ideal representation method for environmental perception and is an effective carrier for language models in 3D Visual Grounding tasks. To address these issues, we propose a diverse semantic map construction method specifically designed for robotic agents performing 3D Visual Grounding tasks. This method leverages VLMs to capture the latent semantic attributes and relations of objects within the scene and creates a Diverse Semantic Map (DSM) through a geometry sliding-window map construction strategy. We enhance the understanding of grounding information based on DSM and introduce a novel approach named DSM-Grounding. Experimental results show that our method outperforms current approaches in tasks like semantic segmentation and 3D Visual Grounding, particularly excelling in overall metrics compared to the state-of-the-art. In addition, we have deployed this method on robots to validate its effectiveness in navigation and grasping tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, with the growing research and application of multimodallarge language models (VLMs) in robotics, there has been an increasing trend ofutilizing VLMs for robotic scene understanding tasks. Existing approaches thatuse VLMs for 3D Visual Grounding tasks often focus on obtaining sceneinformation through geometric and visual information, overlooking theextraction of diverse semantic information from the scene and the understandingof rich implicit semantic attributes, such as appearance, physics, andaffordance. The 3D scene graph, which combines geometry and language, is anideal representation method for environmental perception and is an effectivecarrier for language models in 3D Visual Grounding tasks. To address theseissues, we propose a diverse semantic map construction method specificallydesigned for robotic agents performing 3D Visual Grounding tasks. This methodleverages VLMs to capture the latent semantic attributes and relations ofobjects within the scene and creates a Diverse Semantic Map (DSM) through ageometry sliding-window map construction strategy. We enhance the understandingof grounding information based on DSM and introduce a novel approach namedDSM-Grounding. Experimental results show that our method outperforms currentapproaches in tasks like semantic segmentation and 3D Visual Grounding,particularly excelling in overall metrics compared to the state-of-the-art. Inaddition, we have deployed this method on robots to validate its effectivenessin navigation and grasping tasks.</description>
      <author>example@mail.com (Qinghongbing Xie, Zijian Liang, Long Zeng)</author>
      <guid isPermaLink="false">2504.08307v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Investigating Vision-Language Model for Point Cloud-based Vehicle Classification</title>
      <link>http://arxiv.org/abs/2504.08154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages,3 figures, 1 table, CVPR DriveX workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型框架，通过整合路边LiDAR点云数据与视觉语言模型（VLMs）来提高重型卡车分类的效率和准确性，以支持协同和安全的驾驶环境。&lt;h4&gt;背景&lt;/h4&gt;重型卡车由于其大型尺寸和有限的机动性，对安全构成重大挑战。传统基于LiDAR的卡车分类方法依赖大量的人工标注，既费时又昂贵。&lt;h4&gt;目的&lt;/h4&gt;为了提高协同自动驾驶的安全视角，本研究旨在通过利用大型语言模型（LLMs）的少样本学习能力，实现高效的卡车分类。&lt;h4&gt;方法&lt;/h4&gt;本研究引入了三项关键创新：(1) 利用真实世界LiDAR数据集进行模型开发；(2) 设计预处理流程以适应VLM输入，包括点云注册以实现密集3D渲染和数学形态学技术以增强特征表示；(3) 利用上下文学习和少样本提示来实现最小标注训练数据的车辆分类。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法表现出令人鼓舞的性能，并具有减少标注工作量的潜力，同时提高分类准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法在卡车分类方面具有潜力，能够减少标注工作量并提高分类准确性，对协同和安全的驾驶环境具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heavy-duty trucks pose significant safety challenges due to their large sizeand limited maneuverability compared to passenger vehicles. A deeperunderstanding of truck characteristics is essential for enhancing the safetyperspective of cooperative autonomous driving. Traditional LiDAR-based truckclassification methods rely on extensive manual annotations, which makes themlabor-intensive and costly. The rapid advancement of large language models(LLMs) trained on massive datasets presents an opportunity to leverage theirfew-shot learning capabilities for truck classification. However, existingvision-language models (VLMs) are primarily trained on image datasets, whichmakes it challenging to directly process point cloud data. This studyintroduces a novel framework that integrates roadside LiDAR point cloud datawith VLMs to facilitate efficient and accurate truck classification, whichsupports cooperative and safe driving environments. This study introduces threekey innovations: (1) leveraging real-world LiDAR datasets for modeldevelopment, (2) designing a preprocessing pipeline to adapt point cloud datafor VLM input, including point cloud registration for dense 3D rendering andmathematical morphological techniques to enhance feature representation, and(3) utilizing in-context learning with few-shot prompting to enable vehicleclassification with minimally labeled training data. Experimental resultsdemonstrate encouraging performance of this method and present its potential toreduce annotation efforts while improving classification accuracy.</description>
      <author>example@mail.com (Yiqiao Li, Jie Wei, Camille Kamga)</author>
      <guid isPermaLink="false">2504.08154v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>A Self-Supervised Framework for Space Object Behaviour Characterisation</title>
      <link>http://arxiv.org/abs/2504.06176v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对太空物体行为分析的空间安全与可持续性基础模型，利用光曲线（LCs）进行行为分析。&lt;h4&gt;背景&lt;/h4&gt;随着轨道物体数量的增加，自动化的太空物体行为分析方法对于空间安全至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够进行异常检测、运动预测和光曲线生成的太空物体行为分析模型。&lt;h4&gt;方法&lt;/h4&gt;采用Perceiver-Variational Autoencoder (VAE) 架构，在来自MMT-9观测站的227,000个光曲线上进行预训练，并通过两个独立的模拟器（CASSANDRA和GRIAL）进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;预训练模型在重建误差为0.01%的情况下识别出可能异常的光曲线。微调后，模型在异常检测和运动模式预测（如太阳对准、自旋等）中分别达到了88%和82%的准确率，ROC AUC分数分别为0.90和0.95。&lt;h4&gt;结论&lt;/h4&gt;该模型通过自监督学习实现了异常检测、运动预测和从预训练中学习到的丰富表示的合成数据生成，支持空间安全和可持续性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在大量未标记数据集上预训练，并在特定任务上进行微调的基础模型正越来越多地应用于专业领域。最近的例子包括用于气候的ClimaX和用于卫星地球观测的Clay，但尚未开发出用于太空物体行为分析的基础模型。随着轨道物体数量的增加，自动化的太空物体行为分析方法对于空间安全至关重要。我们提出了一种空间安全与可持续性基础模型，专注于使用光曲线（LCs）进行太空物体行为分析。我们实现了一个Perceiver-Variational Autoencoder (VAE) 架构，使用来自MMT-9观测站的227,000个光曲线进行预训练，并在自监督重建和掩码重建上进行预训练。VAE能够进行异常检测、运动预测和光曲线生成。我们使用两个独立的模拟器（CASSANDRA和GRIAL）对模型进行了微调，以进行异常检测和运动预测，使用了箱翼、Sentinel-3、SMOS和Starlink平台的CAD模型。我们的预训练模型达到了0.01%的重建误差，通过重建难度识别出可能异常的光曲线。在微调后，模型在异常检测和运动模式预测（如太阳对准、自旋等）中分别达到了88%和82%的准确率，ROC AUC分数分别为0.90和0.95。对高置信度异常预测的实时数据分析揭示了包括特征物体轮廓和卫星反光在内的明显模式。在这里，我们展示了如何通过自监督学习同时实现异常检测、运动预测和从预训练中学习到的丰富表示的合成数据生成。因此，我们的工作通过自动化监控和模拟能力支持空间安全和可持续性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models, pre-trained on large unlabelled datasets beforetask-specific fine-tuning, are increasingly being applied to specialiseddomains. Recent examples include ClimaX for climate and Clay for satelliteEarth observation, but a Foundation Model for Space Object Behavioural Analysishas not yet been developed. As orbital populations grow, automated methods forcharacterising space object behaviour are crucial for space safety. We presenta Space Safety and Sustainability Foundation Model focusing on space objectbehavioural analysis using light curves (LCs). We implemented aPerceiver-Variational Autoencoder (VAE) architecture, pre-trained withself-supervised reconstruction and masked reconstruction on 227,000 LCs fromthe MMT-9 observatory. The VAE enables anomaly detection, motion prediction,and LC generation. We fine-tuned the model for anomaly detection &amp; motionprediction using two independent LC simulators (CASSANDRA and GRIALrespectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlinkplatforms. Our pre-trained model achieved a reconstruction error of 0.01%,identifying potentially anomalous light curves through reconstructiondifficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90and 0.95 ROC AUC scores respectively in both anomaly detection and motion modeprediction (sun-pointing, spin, etc.). Analysis of high-confidence anomalypredictions on real data revealed distinct patterns including characteristicobject profiles and satellite glinting. Here, we demonstrate howself-supervised learning can simultaneously enable anomaly detection, motionprediction, and synthetic data generation from rich representations learned inpre-training. Our work therefore supports space safety and sustainabilitythrough automated monitoring and simulation capabilities.</description>
      <author>example@mail.com (Ian Groves, Andrew Campbell, James Fernandes, Diego Ramírez Rodríguez, Paul Murray, Massimiliano Vasile, Victoria Nockles)</author>
      <guid isPermaLink="false">2504.06176v2</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>STF-GCN: A Multi-Domain Graph Convolution Network Method for Automatic Modulation Recognition via Adaptive Correlation</title>
      <link>http://arxiv.org/abs/2504.08504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STF-GCN的自动调制识别框架，用于解决低信噪比条件下深度学习方法的特征提取问题，并通过实验验证了其性能优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;现有的基于深度学习的自动调制识别方法在低信噪比条件下难以提取判别性和鲁棒性特征，且图神经网络方法在AMR任务中存在图结构构建和计算复杂性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效提取特征并降低计算复杂性的自动调制识别方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一个以时间域为锚点的时空频谱图卷积网络（STF-GCN）框架，融合了嵌入在图结构节点中的空间和频率域特征。同时，提出了一种基于自适应相关性的邻接矩阵构建方法，增强了图结构聚合局部信息的能力。此外，还引入了PoolGAT层来粗化和压缩全局关键特征，降低计算复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，STF-GCN在RML2016.10a、RML2016.10b和RML22数据集上的识别准确率分别为64.35%、66.04%和70.95%，在低信噪比条件下的平均识别准确率分别比现有最佳模型高出1.20%、1.95%和1.83%。&lt;h4&gt;结论&lt;/h4&gt;STF-GCN框架在低信噪比条件下能够实现远超现有深度学习自动调制识别算法的性能，有效提高了识别准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic Modulation Recognition (AMR) is an essential part of IntelligentTransportation System (ITS) dynamic spectrum allocation. However, current deeplearning-based AMR (DL-AMR) methods are challenged to extract discriminativeand robust features at low signal-to-noise ratios (SNRs), where therepresentation of modulation symbols is highly interfered by noise.Furthermore, current research on GNN methods for AMR tasks generally suffersfrom issues related to graph structure construction and computationalcomplexity. In this paper, we propose a Spatial-Temporal-Frequency GraphConvolution Network (STF-GCN) framework, with the temporal domain as the anchorpoint, to fuse spatial and frequency domain features embedded in the graphstructure nodes. On this basis, an adaptive correlation-based adjacency matrixconstruction method is proposed, which significantly enhances the graphstructure's capacity to aggregate local information into individual nodes. Inaddition, a PoolGAT layer is proposed to coarsen and compress the global keyfeatures of the graph, significantly reducing the computational complexity. Theresults of the experiments confirm that STF-GCN is able to achieve recognitionperformance far beyond the state-of-the-art DL-AMR algorithms, with overallaccuracies of 64.35%, 66.04% and 70.95% on the RML2016.10a, RML2016.10b andRML22 datasets, respectively. Furthermore, the average recognition accuraciesunder low SNR conditions from -14dB to 0dB outperform the state-of-the-art(SOTA) models by 1.20%, 1.95% and 1.83%, respectively.</description>
      <author>example@mail.com (Mingyuan Shao, Zhengqiu Fu, Dingzhao Li, Fuqing Zhang, Yilin Cai, Shaohua Hong, Lin Cao, Yuan Peng, Jie Qi)</author>
      <guid isPermaLink="false">2504.08504v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>F$^3$Set: Towards Analyzing Fast, Frequent, and Fine-grained Events from Videos</title>
      <link>http://arxiv.org/abs/2504.08222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The Thirteenth International Conference on Learning Representations  (ICLR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视频分析和多模态语言模型中的F3事件分析问题，提出了一种新的基准数据集F3Set，并介绍了一种新的F3事件检测方法F3ED。&lt;h4&gt;背景&lt;/h4&gt;在视频分析和多模态语言模型中，分析快速、频繁和精细粒度的F3事件是一个重大挑战，因为运动模糊和细微的视觉差异导致现有方法难以精确识别。&lt;h4&gt;目的&lt;/h4&gt;为了推进视频理解研究，本文旨在提出一个包含精确F3事件检测的视频数据集，并评估现有方法，同时提出一种新的F3事件检测方法。&lt;h4&gt;方法&lt;/h4&gt;本文引入了F3Set基准，它包含用于精确F3事件检测的视频数据集。F3Set数据集规模庞大，细节全面，通常包含超过1000种事件类型，具有精确的时间戳和多层次粒度。本文在F3Set上评估了流行的时序动作理解方法，并提出了F3ED方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现在F3Set上，现有的时序动作理解方法面临着巨大的挑战，同时提出了的F3ED方法在F3事件检测上表现出色。&lt;h4&gt;结论&lt;/h4&gt;本文提出的F3Set数据集和F3ED方法为F3事件分析提供了新的基准和工具，有助于推动视频理解和多模态语言模型的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分析快速、频繁、精细粒度（F3）事件在视频分析和多模态语言模型中提出了重大挑战。由于运动模糊和细微的视觉差异等挑战，现有方法难以高精度地识别满足所有F3标准的事件。为了推进视频理解研究，我们引入了F3Set，一个包含用于精确F3事件检测的视频数据集的基准。F3Set数据集以其广泛规模和全面细节为特点，通常包含超过1000种事件类型，具有精确的时间戳和多层次粒度。目前，F3Set包含几个体育数据集，该框架可以扩展到其他应用。我们在F3Set上评估了流行的时序动作理解方法，揭示了现有技术的重大挑战。此外，我们提出了一种新的F3事件检测方法，F3ED，实现了优越的性能。数据集、模型和基准代码可在https://github.com/F3Set/F3Set上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Analyzing Fast, Frequent, and Fine-grained (F$^3$) events presents asignificant challenge in video analytics and multi-modal LLMs. Current methodsstruggle to identify events that satisfy all the F$^3$ criteria with highaccuracy due to challenges such as motion blur and subtle visual discrepancies.To advance research in video understanding, we introduce F$^3$Set, a benchmarkthat consists of video datasets for precise F$^3$ event detection. Datasets inF$^3$Set are characterized by their extensive scale and comprehensive detail,usually encompassing over 1,000 event types with precise timestamps andsupporting multi-level granularity. Currently, F$^3$Set contains several sportsdatasets, and this framework may be extended to other applications as well. Weevaluated popular temporal action understanding methods on F$^3$Set, revealingsubstantial challenges for existing techniques. Additionally, we propose a newmethod, F$^3$ED, for F$^3$ event detections, achieving superior performance.The dataset, model, and benchmark code are available athttps://github.com/F3Set/F3Set.</description>
      <author>example@mail.com (Zhaoyu Liu, Kan Jiang, Murong Ma, Zhe Hou, Yun Lin, Jin Song Dong)</author>
      <guid isPermaLink="false">2504.08222v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Boosting multi-demographic federated learning for chest x-ray analysis using general-purpose self-supervised representations</title>
      <link>http://arxiv.org/abs/2504.08584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了联邦学习在医疗图像分析中的应用，分析了成人胸部X光片和儿科图像数据，发现联邦学习在处理非独立同分布数据时存在挑战，并提出使用自监督图像表示来提升性能。&lt;h4&gt;背景&lt;/h4&gt;可靠的AI模型需要大量多样化的标记数据集，联邦学习提供了一种去中心化和保护隐私的训练方法，但在非独立同分布的数据集中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决联邦学习在处理非独立同分布数据时的局限性，研究分析了成人胸部X光片和儿科图像数据，以分类肺炎和无异常病例。&lt;h4&gt;方法&lt;/h4&gt;利用迁移学习，从通用自监督图像表示中学习，并使用最先进的视觉Transformer进行分类，对比分析了不同规模的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;联邦学习只在小规模成人数据集上提高了性能，在大规模数据集和儿科病例上则降低了性能。使用自监督权重显著提升了儿科病例和大多数成人数据集的性能。&lt;h4&gt;结论&lt;/h4&gt;通用自监督图像表示在解决临床联邦学习中的非独立同分布挑战方面具有潜力，有助于提高患者结果并推进儿科医疗保健。&lt;h4&gt;翻译&lt;/h4&gt;This study investigates the application of federated learning in medical image analysis, analyzes adult chest radiographs and pediatric images, and finds that federated learning has challenges in dealing with non-IID data, and proposes using self-supervised image representations to improve performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable artificial intelligence (AI) models for medical image analysis oftendepend on large and diverse labeled datasets. Federated learning (FL) offers adecentralized and privacy-preserving approach to training but struggles inhighly non-independent and identically distributed (non-IID) settings, whereinstitutions with more representative data may experience degraded performance.Moreover, existing large-scale FL studies have been limited to adult datasets,neglecting the unique challenges posed by pediatric data, which introducesadditional non-IID variability. To address these limitations, we analyzedn=398,523 adult chest radiographs from diverse institutions across multiplecountries and n=9,125 pediatric images, leveraging transfer learning fromgeneral-purpose self-supervised image representations to classify pneumonia andcases with no abnormality. Using state-of-the-art vision transformers, we foundthat FL improved performance only for smaller adult datasets (P&lt;0.001) butdegraded performance for larger datasets (P&lt;0.064) and pediatric cases(P=0.242). However, equipping FL with self-supervised weights significantlyenhanced outcomes across pediatric cases (P=0.031) and most adult datasets(P&lt;0.008), except the largest dataset (P=0.052). These findings underscore thepotential of easily deployable general-purpose self-supervised imagerepresentations to address non-IID challenges in clinical FL applications andhighlight their promise for enhancing patient outcomes and advancing pediatrichealthcare, where data scarcity and variability remain persistent obstacles.</description>
      <author>example@mail.com (Mahshad Lotfinia, Arash Tayebiarasteh, Samaneh Samiei, Mehdi Joodaki, Soroosh Tayebi Arasteh)</author>
      <guid isPermaLink="false">2504.08584v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Impact of Language Guidance: A Reproducibility Study</title>
      <link>http://arxiv.org/abs/2504.08140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了现代深度学习架构需要大量数据进行训练，以及使用自监督学习减少标注数据的需求，并提出了一种新的基于语言指导的对比学习方法，旨在提高自监督模型的性能。&lt;h4&gt;背景&lt;/h4&gt;现代深度学习架构需要大量数据来达到最佳效果，但标注这些数据既耗时又昂贵，且容易出错。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过自监督学习，特别是对比学习方法，减少对大量数据的标注需求。&lt;h4&gt;方法&lt;/h4&gt;Banani等人的研究提出了使用语言指导来采样视图对的方法，本文通过重现他们的实验来验证其观点，并发现他们的数据集RedCaps包含低质量字幕。作者使用BLIP-2图像字幕模型替换了字幕，并设计了新的评估指标来评估自监督模型的语义能力。&lt;h4&gt;主要发现&lt;/h4&gt;RedCaps数据集包含低质量字幕，通过使用BLIP-2替换字幕并设计新指标，提高了模型性能。&lt;h4&gt;结论&lt;/h4&gt;本文证明了语言指导在提高自监督学习模型的性能方面具有潜力，并指出了现有数据集可能存在的问题。&lt;h4&gt;翻译&lt;/h4&gt;本文讨论了现代深度学习架构需要大量数据进行训练，以及使用自监督学习减少标注数据的需求。最近的研究提出了使用语言指导来采样视图对的方法，本文通过重现他们的实验来验证其观点，并发现他们的数据集RedCaps包含低质量字幕。作者使用BLIP-2图像字幕模型替换了字幕，并设计了新的评估指标来评估自监督模型的语义能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern deep-learning architectures need large amounts of data to producestate-of-the-art results. Annotating such huge datasets is time-consuming,expensive, and prone to human error. Recent advances in self-supervisedlearning allow us to train huge models without explicit annotation. Contrastivelearning is a popular paradigm in self-supervised learning. Recent works likeSimCLR and CLIP rely on image augmentations or directly minimizing cross-modalloss between image and text. Banani et al. (2023) propose to use languageguidance to sample view pairs. They claim that language enables betterconceptual similarity, eliminating the effects of visual variability. Wereproduce their experiments to verify their claims and find that their dataset,RedCaps, contains low-quality captions. We use an off-the-shelf imagecaptioning model, BLIP-2, to replace the captions and improve performance, andwe also devise a new metric to evaluate the semantic capabilities ofself-supervised models based on interpretability methods.</description>
      <author>example@mail.com (Cherish Puniani, Advika Sinha, Shree Singhi, Aayan Yadav)</author>
      <guid isPermaLink="false">2504.08140v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Graph Reduction with Unsupervised Learning in Column Generation: A Routing Application</title>
      <link>http://arxiv.org/abs/2504.08401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 4 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的列生成（CG）方法，用于提高大规模组合优化（CO）问题的计算效率。&lt;h4&gt;背景&lt;/h4&gt;列生成是一种针对大规模组合优化问题提高计算效率的方法，通过解决定价问题来减少决策变量的数量。&lt;h4&gt;目的&lt;/h4&gt;为了解决大型元素最短路径问题（ESPPRC）的求解难题，本文使用GNN来减小ESPPRC的规模，使其能够通过标准求解技术进行计算。&lt;h4&gt;方法&lt;/h4&gt;本文的GNN通过无监督学习进行训练，输出一个表示在缩减后的路径问题（PP）中应保留的弧的分布。通过局部搜索找到具有大缩减成本的列，从而加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;在一系列带时间窗的容量限制车辆路径问题（CVRP）上应用该方法，与文献中的简单缩减技术相比，收敛速度有显著提高。在固定的计算预算下，对于更大的实例，目标值提高了超过9%。&lt;h4&gt;结论&lt;/h4&gt;本文的CG算法性能得到了分析，并且方法在不同类别的实例上的泛化能力得到了测试。&lt;h4&gt;翻译&lt;/h4&gt;摘要：列生成（CG）是一种流行的针对大规模组合优化（CO）问题提高计算效率的方法。它通过解决定价问题来减少问题中的决策变量数量。对于许多组合优化问题，定价问题是一个带有资源约束的元素最短路径问题（ESPPRC）。大型ESPPRC实例难以求解到接近最优解。因此，我们使用图神经网络（GNN）来减小ESPPRC的规模，使其能够通过标准求解技术进行计算。我们的GNN通过无监督学习进行训练，并输出一个表示在缩减后的路径问题（PP）中应保留的弧的分布。通过局部搜索找到具有大缩减成本的列，从而加速收敛。我们在一系列带时间窗的容量限制车辆路径问题（CVRP）上应用了我们的方法，与文献中的简单缩减技术相比，收敛速度有显著提高。在固定的计算预算下，对于更大的实例，目标值提高了超过9%。我们还分析了我们的CG算法的性能，并测试了我们的方法在训练数据之外的不同类别的实例上的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Column Generation (CG) is a popular method dedicated to enhancingcomputational efficiency in large scale Combinatorial Optimization (CO)problems. It reduces the number of decision variables in a problem by solving apricing problem. For many CO problems, the pricing problem is an ElementaryShortest Path Problem with Resource Constraints (ESPPRC). Large ESPPRCinstances are difficult to solve to near-optimality. Consequently, we use aGraph neural Network (GNN) to reduces the size of the ESPPRC such that itbecomes computationally tractable with standard solving techniques. Our GNN istrained by Unsupervised Learning and outputs a distribution for the arcs to beretained in the reduced PP. The reduced PP is solved by a local search thatfinds columns with large reduced costs and speeds up convergence. We apply ourmethod on a set of Capacitated Vehicle Routing Problems with Time Windows andshow significant improvements in convergence compared to simple reductiontechniques from the literature. For a fixed computational budget, we improvethe objective values by over 9\% for larger instances. We also analyze theperformance of our CG algorithm and test the generalization of our method todifferent classes of instances than the training data.</description>
      <author>example@mail.com (Abdo Abouelrous, Laurens Bliea, Adriana F. Gabor, Yaoxin Wu, Yingqian Zhang)</author>
      <guid isPermaLink="false">2504.08401v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>ContrastiveGaussian: High-Fidelity 3D Generation with Contrastive Learning and Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2504.08100v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code will be available at  https://github.com/YaNLlan-ljb/ContrastiveGaussian&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ContrastiveGaussian的新方法，用于从单视图图像创建3D内容，该方法通过结合对比学习和感知损失来提高3D生成的质量和纹理保真度。&lt;h4&gt;背景&lt;/h4&gt;从单视图图像创建3D内容是一个具有挑战性的问题，近年来引起了广泛关注。现有方法通常利用预训练的2D扩散模型进行分数蒸馏采样（SDS）来生成多视图3D表示，但这些方法的性能通常受到扩散模型输出视觉不一致性的限制。&lt;h4&gt;目的&lt;/h4&gt;提出ContrastiveGaussian方法，旨在通过整合对比学习来改善3D生成质量，同时提高样本区分度和对比学习的性能。&lt;h4&gt;方法&lt;/h4&gt;ContrastiveGaussian方法通过使用感知损失来区分正负样本，利用视觉不一致性来提高3D生成质量。此外，为了进一步提高样本区分度和改善对比学习，该方法引入了超分辨率模型和数量感知三元组损失，以处理训练过程中的样本分布变化。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法实现了优异的纹理保真度和改进的几何一致性。&lt;h4&gt;结论&lt;/h4&gt;ContrastiveGaussian方法在从单视图图像创建3D内容方面取得了显著的进步，为该领域提供了一个有效且高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Creating 3D content from single-view images is a challenging problem that hasattracted considerable attention in recent years. Current approaches typicallyutilize score distillation sampling (SDS) from pre-trained 2D diffusion modelsto generate multi-view 3D representations. Although some methods have madenotable progress by balancing generation speed and model quality, theirperformance is often limited by the visual inconsistencies of the diffusionmodel outputs. In this work, we propose ContrastiveGaussian, which integratescontrastive learning into the generative process. By using a perceptual loss,we effectively differentiate between positive and negative samples, leveragingthe visual inconsistencies to improve 3D generation quality. To further enhancesample differentiation and improve contrastive learning, we incorporate asuper-resolution model and introduce another Quantity-Aware Triplet Loss toaddress varying sample distributions during training. Our experimentsdemonstrate that our approach achieves superior texture fidelity and improvedgeometric consistency.</description>
      <author>example@mail.com (Junbang Liu, Enpei Huang, Dongxing Mao, Hui Zhang, Xinyuan Song, Yongxin Ni)</author>
      <guid isPermaLink="false">2504.08100v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Local Distance-Preserving Node Embeddings and Their Performance on Random Graphs</title>
      <link>http://arxiv.org/abs/2504.08216v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在图机器学习中学习节点表示的基本问题，提出了一种基于地标节点的局部距离保持节点嵌入方法，并通过理论和实验证明了其在随机图上的有效性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;现有嵌入方法在保留局部相似性方面效果良好，但往往无法捕捉全局函数如图距离。&lt;h4&gt;目的&lt;/h4&gt;研究局部距离保持节点嵌入的性能，特别是针对地标节点嵌入。&lt;h4&gt;方法&lt;/h4&gt;采用地标节点算法，通过计算从少量参考节点（即地标）到其他节点的最短路径来近似成对距离。&lt;h4&gt;主要发现&lt;/h4&gt;理论研究表明，与最坏情况图相比，随机图（如Erdős-Rényi随机图）在基于地标嵌入中需要的维度更低；实验上，基于图神经网络（GNN）的近似方法对于地标距离的泛化性能良好。&lt;h4&gt;结论&lt;/h4&gt;地标节点嵌入方法在图表示学习中具有有效性和可扩展性，为图表示学习提供了一种可行的替代方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning node representations is a fundamental problem in graph machinelearning. While existing embedding methods effectively preserve localsimilarity measures, they often fail to capture global functions like graphdistances. Inspired by Bourgain's seminal work on Hilbert space embeddings ofmetric spaces (1985), we study the performance of local distance-preservingnode embeddings. Known as landmark-based algorithms, these embeddingsapproximate pairwise distances by computing shortest paths from a small subsetof reference nodes (i.e., landmarks). Our main theoretical contribution showsthat random graphs, such as Erd\H{o}s-R\'enyi random graphs, require lowerdimensions in landmark-based embeddings compared to worst-case graphs.Empirically, we demonstrate that the GNN-based approximations for the distancesto landmarks generalize well to larger networks, offering a scalablealternative for graph representation learning.</description>
      <author>example@mail.com (My Le, Luana Ruiz, Souvik Dhara)</author>
      <guid isPermaLink="false">2504.08216v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>SN-LiDAR: Semantic Neural Fields for Novel Space-time View LiDAR Synthesis</title>
      <link>http://arxiv.org/abs/2504.08361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SN-LiDAR的新方法，用于从未见过的视角生成真实的LiDAR扫描，并实现了语义分割、几何重建和LiDAR合成的联合处理。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数LiDAR点云视图合成方法没有重建语义标签，这对于自动驾驶和机器人感知等下游应用至关重要。由于LiDAR点云缺乏大规模预训练模型，语义标注变得耗时且劳动密集。&lt;h4&gt;目的&lt;/h4&gt;提出SN-LiDAR方法，旨在解决LiDAR点云语义标注困难的问题，实现准确的语义分割、高质量的几何重建和逼真的LiDAR合成。&lt;h4&gt;方法&lt;/h4&gt;SN-LiDAR方法采用粗到细的平面网格特征表示来从多帧点云中提取全局特征，并利用基于CNN的编码器从当前帧点云中提取局部语义特征。&lt;h4&gt;主要发现&lt;/h4&gt;在SemanticKITTI和KITTI-360数据集上的实验表明，SN-LiDAR在语义和几何重建方面都表现出优越性，能够有效处理动态物体和大规模场景。&lt;h4&gt;结论&lt;/h4&gt;SN-LiDAR方法能够有效地从未见过的视角生成真实的LiDAR扫描，并在语义和几何重建方面取得了显著成果。&lt;h4&gt;翻译&lt;/h4&gt;Recent research has begun exploring novel view synthesis (NVS) for LiDAR point clouds, aiming to generate realistic LiDAR scans from unseen viewpoints. However, most existing approaches do not reconstruct semantic labels, which are crucial for many downstream applications such as autonomous driving and robotic perception. Unlike images, which benefit from powerful segmentation models, LiDAR point clouds lack such large-scale pre-trained models, making semantic annotation time-consuming and labor-intensive. To address this challenge, we propose SN-LiDAR, a method that jointly performs accurate semantic segmentation, high-quality geometric reconstruction, and realistic LiDAR synthesis. Specifically, we employ a coarse-to-fine planar-grid feature representation to extract global features from multi-frame point clouds and leverage a CNN-based encoder to extract local semantic features from the current frame point cloud. Extensive experiments on SemanticKITTI and KITTI-360 demonstrate the superiority of SN-LiDAR in both semantic and geometric reconstruction, effectively handling dynamic objects and large-scale scenes. Codes will be available on https://github.com/dtc111111/SN-Lidar.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research has begun exploring novel view synthesis (NVS) for LiDARpoint clouds, aiming to generate realistic LiDAR scans from unseen viewpoints.However, most existing approaches do not reconstruct semantic labels, which arecrucial for many downstream applications such as autonomous driving and roboticperception. Unlike images, which benefit from powerful segmentation models,LiDAR point clouds lack such large-scale pre-trained models, making semanticannotation time-consuming and labor-intensive. To address this challenge, wepropose SN-LiDAR, a method that jointly performs accurate semanticsegmentation, high-quality geometric reconstruction, and realistic LiDARsynthesis. Specifically, we employ a coarse-to-fine planar-grid featurerepresentation to extract global features from multi-frame point clouds andleverage a CNN-based encoder to extract local semantic features from thecurrent frame point cloud. Extensive experiments on SemanticKITTI and KITTI-360demonstrate the superiority of SN-LiDAR in both semantic and geometricreconstruction, effectively handling dynamic objects and large-scale scenes.Codes will be available on https://github.com/dtc111111/SN-Lidar.</description>
      <author>example@mail.com (Yi Chen, Tianchen Deng, Wentao Zhao, Xiaoning Wang, Wenqian Xi, Weidong Chen, Jingchuan Wang)</author>
      <guid isPermaLink="false">2504.08361v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models</title>
      <link>http://arxiv.org/abs/2504.08329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了电子健康记录(EHR)基础模型的局限性，并提出了一种名为MedRep的解决方案，以提高模型在处理未知医疗代码方面的表现。&lt;h4&gt;背景&lt;/h4&gt;尽管EHR基础模型在各种医疗任务中表现优异，但它们在处理不在词汇表中的未知医疗代码方面存在根本性的限制。&lt;h4&gt;目的&lt;/h4&gt;旨在通过提出MedRep来解决EHR基础模型在处理未知医疗代码方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;MedRep基于OMOP通用数据模型(CDM)，通过以下方式提高模型性能：1) 使用大型语言模型(LLM)提示丰富每个概念的信息；2) 利用OMOP词汇的图本体增强文本表示；3) 通过随机替换患者轨迹中的概念以进行数据增强。&lt;h4&gt;主要发现&lt;/h4&gt;使用MedRep训练的EHR基础模型在外部数据集中更好地保持了预测性能。&lt;h4&gt;结论&lt;/h4&gt;MedRep为EHR基础模型提供了一种有效的方法来处理未知医疗代码，并提高了模型在现实世界应用中的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：电子健康记录(EHR)基础模型已经在各种医疗任务中表现出了改进的性能，但存在一个基本限制：处理不在词汇表中的未知医疗代码。为了解决这个问题，我们基于观察性医疗结果伙伴关系(OMOP)通用数据模型(CDM)为EHR基础模型提出了MedRep，为患者轨迹提供集成医疗概念表示和基本数据增强策略。对于概念表示学习，我们通过大型语言模型(LLM)提示用最少的定义丰富每个概念的信息，并通过OMOP词汇的图本体增强文本表示。轨迹增强通过随机替换与具有密切相关表示的其他类似概念来随机替换选定的概念，使模型能够在词汇表外的概念上进行实践。最后，我们证明，使用MedRep训练的EHR基础模型在外部数据集中更好地保持了预测性能。我们的代码实现可在https://github.com/kicarussays/MedRep上公开访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electronic health record (EHR) foundation models have been an area ripe forexploration with their improved performance in various medical tasks. Despitethe rapid advances, there exists a fundamental limitation: Processing unseenmedical codes out of the vocabulary. This problem limits the generality of EHRfoundation models and the integration of models trained with differentvocabularies. To deal with this problem, we propose MedRep for EHR foundationmodels based on the observational medical outcome partnership (OMOP) commondata model (CDM), providing the integrated medical concept representations andthe basic data augmentation strategy for patient trajectories. For conceptrepresentation learning, we enrich the information of each concept with aminimal definition through large language model (LLM) prompts and enhance thetext-based representations through graph ontology of OMOP vocabulary.Trajectory augmentation randomly replaces selected concepts with other similarconcepts that have closely related representations to let the model practicewith the concepts out-of-vocabulary. Finally, we demonstrate that EHRfoundation models trained with MedRep better maintain the predictionperformance in external datasets. Our code implementation is publicly availableat https://github.com/kicarussays/MedRep.</description>
      <author>example@mail.com (Junmo Kim, Namkyeong Lee, Jiwon Kim, Kwangsoo Kim)</author>
      <guid isPermaLink="false">2504.08329v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Banana Ripeness Level Classification using a Simple CNN Model Trained with Real and Synthetic Datasets</title>
      <link>http://arxiv.org/abs/2504.08568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 7 figures, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了香蕉成熟度评估问题，提出了一种结合真实和合成数据训练的CNN模型，用于准确识别香蕉的成熟度。&lt;h4&gt;背景&lt;/h4&gt;香蕉成熟度对质量至关重要，目前工业上仍使用人工方法评估，而CNN模型有潜力解决这一问题，但数据量限制影响了模型的训练。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合真实和合成数据的方法，训练CNN模型以准确评估香蕉的成熟度。&lt;h4&gt;方法&lt;/h4&gt;创建了一个结合真实和合成数据的鲁棒数据集，设计了一个简单的CNN架构，并使用迁移学习技术进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;提出的CNN模型在多个架构和超参数配置下，实现了高达0.917的准确率和快速的执行时间。&lt;h4&gt;结论&lt;/h4&gt;所提出的CNN模型能够有效地识别香蕉的成熟度，具有较高的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：香蕉的成熟度水平对于确定其质量至关重要。为了正确估计香蕉的成熟度，需要考虑国际营销标准。然而，在工业级别评估香蕉成熟度的过程中，仍然使用人工方法。使用CNN模型是一个吸引人的工具来解决这个问题，但关于训练这些模型所需的数据充分性的限制。另一方面，在当前技术中，现有的CNN模型和可用数据报告说，在识别香蕉成熟度方面的准确率是可以接受的。因此，这项工作提出了生成一个结合真实和合成数据以不同香蕉成熟度级别的鲁棒数据集。此外，它提出了一种简单的CNN架构，该架构使用合成数据进行训练，并使用迁移学习技术，通过改进模型以分类真实数据，来管理确定香蕉的成熟度水平。所提出的CNN模型使用多个架构进行评估，然后改变超参数配置，并使用优化器。结果显示，所提出的CNN模型达到了0.917的高准确率和快速的执行时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.5220/0011654600003417&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The level of ripeness is essential in determining the quality of bananas. Tocorrectly estimate banana maturity, the metrics of international marketingstandards need to be considered. However, the process of assessing the maturityof bananas at an industrial level is still carried out using manual methods.The use of CNN models is an attractive tool to solve the problem, but there isa limitation regarding the availability of sufficient data to train thesemodels reliably. On the other hand, in the state-of-the-art, existing CNNmodels and the available data have reported that the accuracy results areacceptable in identifying banana maturity. For this reason, this work presentsthe generation of a robust dataset that combines real and synthetic data fordifferent levels of banana ripeness. In addition, it proposes a simple CNNarchitecture, which is trained with synthetic data and using the transferlearning technique, the model is improved to classify real data, managing todetermine the level of maturity of the banana. The proposed CNN model isevaluated with several architectures, then hyper-parameter configurations arevaried, and optimizers are used. The results show that the proposed CNN modelreaches a high accuracy of 0.917 and a fast execution time.</description>
      <author>example@mail.com (Luis Chuquimarca, Boris Vintimilla, Sergio Velastin)</author>
      <guid isPermaLink="false">2504.08568v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Academic Network Representation via Prediction-Sampling Incorporated Tensor Factorization</title>
      <link>http://arxiv.org/abs/2504.08323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于预测采样的张量潜在因子分解（PLFT）模型，用于解决学术网络高维和不完整（HDI）问题，以更准确地学习学术网络表示。&lt;h4&gt;背景&lt;/h4&gt;准确表示学术网络对于学术关系挖掘（如预测科学影响）具有重要意义。然而，由于学术网络的高维性和不完整性，传统的潜在因子分解（LFT）模型难以学习到准确的学术网络表示。&lt;h4&gt;目的&lt;/h4&gt;提出PLFT模型，旨在解决学术网络高维和不完整问题，提高模型对学术网络表示的学习能力。&lt;h4&gt;方法&lt;/h4&gt;PLFT模型包含两个主要思想：1）构建级联LFT架构，通过学习学术网络层次特征来增强模型表示学习能力；2）引入非线性激活结合的预测采样策略，通过逐层生成新的学术网络数据来更准确地学习网络表示。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界学术网络数据集上的实验结果表明，PLFT模型在预测网络实体间未探索的关系方面优于现有模型。&lt;h4&gt;结论&lt;/h4&gt;PLFT模型能够有效解决学术网络高维和不完整问题，提高学术网络表示的准确性，为学术关系挖掘提供了一种新的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate representation to an academic network is of great significance toacademic relationship mining like predicting scientific impact. A LatentFactorization of Tensors (LFT) model is one of the most effective models forlearning the representation of a target network. However, an academic networkis often High-Dimensional and Incomplete (HDI) because the relationships amongnumerous network entities are impossible to be fully explored, making itdifficult for an LFT model to learn accurate representation of the academicnetwork. To address this issue, this paper proposes a Prediction-sampling-basedLatent Factorization of Tensors (PLFT) model with two ideas: 1) constructing acascade LFT architecture to enhance model representation learning ability vialearning academic network hierarchical features, and 2) introducing a nonlinearactivation-incorporated predicting-sampling strategy to more accurately learnthe network representation via generating new academic network data layer bylayer. Experimental results from the three real-world academic network datasetsshow that the PLFT model outperforms existing models when predicting theunexplored relationships among network entities.</description>
      <author>example@mail.com (Chunyang Zhang, Xin Liao, Hao Wu)</author>
      <guid isPermaLink="false">2504.08323v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Graph Based Deep Reinforcement Learning Aided by Transformers for Multi-Agent Cooperation</title>
      <link>http://arxiv.org/abs/2504.08195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 7 figures, Accepted to the 2025 IEEE International  Conference on Communications Workshops (ICC Workshops)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型框架，用于解决在部分可观测、有限通信范围和不确定环境下的分布式目标点服务应用中的自主无人机编队任务规划问题。&lt;h4&gt;背景&lt;/h4&gt;任务规划在灾难响应、环境监测和监控等应用中面临挑战，特别是在存在通信限制和不确定性时，传统的路径规划算法难以适用。&lt;h4&gt;目的&lt;/h4&gt;提出的方法旨在通过集成图神经网络（GNN）、深度强化学习（DRL）和基于transformer的消息传递机制，提高多智能体协调和集体任务执行能力。&lt;h4&gt;方法&lt;/h4&gt;该方法利用GNN通过自适应图构建来模拟智能体间和智能体与目标之间的交互，实现有限通信下的高效信息聚合和决策。transformer的消息传递机制结合边缘特征增强的注意力机制，捕捉复杂的交互模式。此外，采用具有优先级经验回放的Double Deep Q-Network（Double DQN）优化智能体策略，以适应部分可观测环境。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在服务提供（90%）和网格覆盖率（100%）方面优于基准方法，同时将平均每轮的步骤数从600减少到200。&lt;h4&gt;结论&lt;/h4&gt;该框架有效提高了多智能体导航的扩展性、适应性和任务执行效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：针对涉及服务分布式目标点的应用，如灾害响应、环境监测和监控，自主无人机编队任务规划在部分可观测、有限通信范围和不确定环境下具有挑战性，特别是在先验信息不可用的情况下。为了应对这些挑战，我们提出了一种新的框架，该框架集成了图神经网络（GNN）、深度强化学习（DRL）和基于transformer的机制，以增强多智能体协调和集体任务执行。我们的方法利用GNN通过自适应图构建来模拟智能体间和智能体与目标之间的交互，从而在受限通信下实现高效的信息聚合和决策。基于transformer的消息传递机制，通过边缘特征增强的注意力机制，捕捉复杂的交互模式，同时，具有优先级经验回放的Double Deep Q-Network（Double DQN）优化了部分可观测环境中的智能体策略。这种集成被精心设计，以解决多智能体导航的特定要求，如可扩展性、适应性和高效的任务执行。实验结果表明，该方法在服务提供和网格覆盖率方面优于基准方法，同时将平均每轮的步骤数从600减少到200。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mission planning for a fleet of cooperative autonomous drones in applicationsthat involve serving distributed target points, such as disaster response,environmental monitoring, and surveillance, is challenging, especially underpartial observability, limited communication range, and uncertain environments.Traditional path-planning algorithms struggle in these scenarios, particularlywhen prior information is not available. To address these challenges, wepropose a novel framework that integrates Graph Neural Networks (GNNs), DeepReinforcement Learning (DRL), and transformer-based mechanisms for enhancedmulti-agent coordination and collective task execution. Our approach leveragesGNNs to model agent-agent and agent-goal interactions through adaptive graphconstruction, enabling efficient information aggregation and decision-makingunder constrained communication. A transformer-based message-passing mechanism,augmented with edge-feature-enhanced attention, captures complex interactionpatterns, while a Double Deep Q-Network (Double DQN) with prioritizedexperience replay optimizes agent policies in partially observableenvironments. This integration is carefully designed to address specificrequirements of multi-agent navigation, such as scalability, adaptability, andefficient task execution. Experimental results demonstrate superiorperformance, with 90% service provisioning and 100% grid coverage (nodediscovery), while reducing the average steps per episode to 200, compared to600 for benchmark methods such as particle swarm optimization (PSO), greedyalgorithms and DQN.</description>
      <author>example@mail.com (Michael Elrod, Niloufar Mehrabi, Rahul Amin, Manveen Kaur, Long Cheng, Jim Martin, Abolfazl Razi)</author>
      <guid isPermaLink="false">2504.08195v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Enabling Automatic Differentiation with Mollified Graph Neural Operators</title>
      <link>http://arxiv.org/abs/2504.08277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了 mollified graph neural operator (mGNO)，一种利用自动微分在任意几何上计算精确梯度的方法，用于学习偏微分方程（PDEs）的解算子。该方法在非规则网格和不同几何形状上的训练效率高，且能够提高物理损失的评估，从而提升泛化能力。&lt;h4&gt;背景&lt;/h4&gt;物理学信息神经网络算子结合数据和物理损失来学习PDEs的解算子。然而，计算物理损失中的导数存在挑战，传统的谱和有限差分方法由于有限分辨率而引入近似误差。&lt;h4&gt;目的&lt;/h4&gt;提出mGNO方法，以解决计算导数的挑战，并提高PDEs求解的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;mGNO结合自动微分技术，在任意几何上计算精确梯度，从而提高物理损失的评估，实现高效训练和更好的泛化。&lt;h4&gt;主要发现&lt;/h4&gt;与有限差分法相比，mGNO与autograd结合在规则网格上的PDEs求解中，将L2相对数据误差降低了20倍，尽管训练速度较慢。在非结构化点云上，mGNO求解PDEs，仅使用物理损失，在远低于有限差分法所需精度的分辨率下，误差比机器学习基线（Meta-PDE）低两个数量级，并且速度比数值求解器快一个到三个数量级。&lt;h4&gt;结论&lt;/h4&gt;mGNO可以高效地解决非规则网格和不同几何形状上的PDEs，并且对于逆设计和形状优化问题在复杂几何形状上也有应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：物理学信息神经网络算子提供了一种结合数据和物理损失的强大框架，用于学习偏微分方程（PDEs）的解算子。然而，这些物理损失依赖于导数。计算这些导数仍然具有挑战性，因为谱和有限差分方法由于有限分辨率而引入了近似误差。在这里，我们提出了mollified graph neural operator（mGNO），这是第一种利用自动微分在任意几何上计算精确梯度的方法。这种增强使得在非规则网格和变化几何形状上实现高效训练成为可能，同时允许在随机采样的点上无缝评估物理损失，以改善泛化能力。对于规则网格上的PDE示例，mGNO与autograd结合将L2相对数据误差降低了20倍，与有限差分法相比，尽管训练速度较慢。它还可以无缝地在非结构化点云上解决PDEs，仅使用物理损失，在远低于有限差分法达到足够精度的分辨率下。在这些非结构化点云上，mGNO导致比可比运行时间的机器学习基线（Meta-PDE）低两个数量级的误差，并且与数值求解器相比，在类似精度的情况下也提供了1到3个数量级的加速。mGNO还可以用于解决复杂几何形状上的逆设计和形状优化问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-informed neural operators offer a powerful framework for learningsolution operators of partial differential equations (PDEs) by combining dataand physics losses. However, these physics losses rely on derivatives.Computing these derivatives remains challenging, with spectral and finitedifference methods introducing approximation errors due to finite resolution.Here, we propose the mollified graph neural operator (mGNO), the first methodto leverage automatic differentiation and compute \emph{exact} gradients onarbitrary geometries. This enhancement enables efficient training on irregulargrids and varying geometries while allowing seamless evaluation of physicslosses at randomly sampled points for improved generalization. For a PDEexample on regular grids, mGNO paired with autograd reduced the L2 relativedata error by 20x compared to finite differences, although training was slower.It can also solve PDEs on unstructured point clouds seamlessly, using physicslosses only, at resolutions vastly lower than those needed for finitedifferences to be accurate enough. On these unstructured point clouds, mGNOleads to errors that are consistently 2 orders of magnitude lower than machinelearning baselines (Meta-PDE) for comparable runtimes, and also deliversspeedups from 1 to 3 orders of magnitude compared to the numerical solver forsimilar accuracy. mGNOs can also be used to solve inverse design and shapeoptimization problems on complex geometries.</description>
      <author>example@mail.com (Ryan Y. Lin, Julius Berner, Valentin Duruisseaux, David Pitt, Daniel Leibovici, Jean Kossaifi, Kamyar Azizzadenesheli, Anima Anandkumar)</author>
      <guid isPermaLink="false">2504.08277v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Neural Encoding and Decoding at Scale</title>
      <link>http://arxiv.org/abs/2504.08201v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为NEDS的多模态、多任务模型，用于同时进行大规模的神经编码和解码，以桥接神经活动与行为之间的双向关系。&lt;h4&gt;背景&lt;/h4&gt;现有的大规模模型要么专注于从行为预测神经活动（编码），要么专注于从神经活动预测行为（解码），这限制了它们捕捉神经活动与行为之间双向关系的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出NEDS模型，实现神经编码和解码的同步进行。&lt;h4&gt;方法&lt;/h4&gt;NEDS采用了一种新颖的多任务掩码策略，交替进行神经、行为、同模态和跨模态掩码。该模型在包含83只动物进行同一视觉决策任务的International Brain Laboratory (IBL)重复站点数据集上预训练。&lt;h4&gt;主要发现&lt;/h4&gt;与其它大规模模型相比，NEDS在基于多动物数据预训练并在新动物上微调时，在编码和解码方面均达到了最先进的性能。NEDS学习到的嵌入具有自涌现特性，即使没有明确的训练，也能高度预测每个记录的大脑区域。&lt;h4&gt;结论&lt;/h4&gt;NEDS模型是朝着构建一个能够无缝翻译神经活动和行为的脑部基础模型迈出的重要一步。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，大规模、多动物模型是表征神经活动与行为之间关系的有力工具。然而，当前的大规模方法要么专注于从行为预测神经活动（编码），要么专注于从神经活动预测行为（解码），这限制了它们捕捉神经活动与行为之间双向关系的能力。为了弥合这一差距，我们提出了一种多模态、多任务模型，称为NEDS，它能够实现大规模的神经编码和解码。我们方法的核心是一种新颖的多任务掩码策略，它交替进行神经、行为、同模态和跨模态掩码。我们在包含83只动物进行同一视觉决策任务的International Brain Laboratory (IBL)重复站点数据集上预训练了我们的方法。与其他大规模模型相比，我们证明了当在多动物数据上预训练并在新动物上微调时，NEDS在编码和解码方面均达到了最先进的性能。令人惊讶的是，NEDS学习到的嵌入具有自涌现特性：即使没有明确的训练，它们也能高度预测每个记录的大脑区域。总之，我们的方法朝着构建一个能够无缝翻译神经活动和行为的脑部基础模型迈出了重要一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work has demonstrated that large-scale, multi-animal models arepowerful tools for characterizing the relationship between neural activity andbehavior. Current large-scale approaches, however, focus exclusively on eitherpredicting neural activity from behavior (encoding) or predicting behavior fromneural activity (decoding), limiting their ability to capture the bidirectionalrelationship between neural activity and behavior. To bridge this gap, weintroduce a multimodal, multi-task model that enables simultaneous NeuralEncoding and Decoding at Scale (NEDS). Central to our approach is a novelmulti-task-masking strategy, which alternates between neural, behavioral,within-modality, and cross-modality masking. We pretrain our method on theInternational Brain Laboratory (IBL) repeated site dataset, which includesrecordings from 83 animals performing the same visual decision-making task. Incomparison to other large-scale models, we demonstrate that NEDS achievesstate-of-the-art performance for both encoding and decoding when pretrained onmulti-animal data and then fine-tuned on new animals. Surprisingly, NEDS'slearned embeddings exhibit emergent properties: even without explicit training,they are highly predictive of the brain regions in each recording. Altogether,our approach is a step towards a foundation model of the brain that enablesseamless translation between neural activity and behavior.</description>
      <author>example@mail.com (Yizi Zhang, Yanchen Wang, Mehdi Azabou, Alexandre Andre, Zixuan Wang, Hanrui Lyu, The International Brain Laboratory, Eva Dyer, Liam Paninski, Cole Hurwitz)</author>
      <guid isPermaLink="false">2504.08201v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>DrivAer Transformer: A high-precision and fast prediction method for vehicle aerodynamic drag coefficient based on the DrivAerNet++ dataset</title>
      <link>http://arxiv.org/abs/2504.08217v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DrivAer Transformer (DAT)的点云学习框架，用于评估空气动力学性能，以加速汽车设计过程和提高开发效率。&lt;h4&gt;背景&lt;/h4&gt;深度学习方法在评估空气动力学性能方面表现出色，但处理复杂的三维车辆模型时，由于缺乏大规模数据集和训练资源，以及不同车辆模型几何形状的多样性和复杂性，预测精度和灵活性仍不足以满足当前生产需求。&lt;h4&gt;目的&lt;/h4&gt;提出DrivAer Transformer框架，旨在提高对复杂三维车辆模型空气动力学性能评估的准确性和灵活性。&lt;h4&gt;方法&lt;/h4&gt;DAT框架使用DrivAerNet++数据集，该数据集包含工业标准三维车辆形状的高保真CFD数据，直接从三维网格中估计空气阻力，从而避免了传统方法（如二维图像渲染或符号距离场）的限制。&lt;h4&gt;主要发现&lt;/h4&gt;DAT框架能够实现快速且准确的阻力预测，推动了空气动力学评估过程的演变，并为将数据驱动方法引入汽车设计奠定了关键基础。&lt;h4&gt;结论&lt;/h4&gt;DAT框架预计将加速车辆设计过程，提高开发效率。&lt;h4&gt;翻译&lt;/h4&gt;在当前阶段，基于深度学习的方法在评估空气动力学性能方面表现出卓越的能力，显著降低了传统计算流体动力学（CFD）模拟所需的时间和成本。然而，面对处理极其复杂的3D车辆模型的任务时，由于缺乏大规模数据集和训练资源，加上不同车辆模型几何形状的多样性和复杂性，这些网络的预测精度和灵活性仍然达不到当前生产所需的水平。鉴于Transformer模型在自然语言处理领域的显著成功及其在图像处理领域的强大潜力，本研究创新性地提出了一种名为DrivAer Transformer（DAT）的点云学习框架。DAT结构使用DrivAerNet++数据集，该数据集包含工业标准3D车辆形状的高保真CFD数据，能够直接从3D网格中准确估计空气阻力，从而避免了传统方法（如2D图像渲染或符号距离场）的限制。DAT能够实现快速且准确的阻力预测，推动空气动力学评估过程的演变，为将数据驱动方法引入汽车设计奠定关键基础。该框架预计将加速车辆设计过程，提高开发效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; At the current stage, deep learning-based methods have demonstrated excellentcapabilities in evaluating aerodynamic performance, significantly reducing thetime and cost required for traditional computational fluid dynamics (CFD)simulations. However, when faced with the task of processing extremely complexthree-dimensional (3D) vehicle models, the lack of large-scale datasets andtraining resources, coupled with the inherent diversity and complexity of thegeometry of different vehicle models, means that the prediction accuracy andversatility of these networks are still not up to the level required forcurrent production. In view of the remarkable success of Transformer models inthe field of natural language processing and their strong potential in thefield of image processing, this study innovatively proposes a point cloudlearning framework called DrivAer Transformer (DAT). The DAT structure uses theDrivAerNet++ dataset, which contains high-fidelity CFD data ofindustrial-standard 3D vehicle shapes. enabling accurate estimation of air dragdirectly from 3D meshes, thus avoiding the limitations of traditional methodssuch as 2D image rendering or signed distance fields (SDF). DAT enables fastand accurate drag prediction, driving the evolution of the aerodynamicevaluation process and laying the critical foundation for introducing adata-driven approach to automotive design. The framework is expected toaccelerate the vehicle design process and improve development efficiency.</description>
      <author>example@mail.com (Jiaqi He, Xiangwen Luo, Yiping Wang)</author>
      <guid isPermaLink="false">2504.08217v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>II-NVM: Enhancing Map Accuracy and Consistency with Normal Vector-Assisted Mapping</title>
      <link>http://arxiv.org/abs/2504.08204v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于SLAM技术的室内定位和地图构建方法，以解决室内环境中存在的“双面映射问题”，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;室内环境中，紧密排列的墙壁、门和其他表面容易被错误地识别为单一平面，这会严重影响地图的准确性和一致性。&lt;h4&gt;目的&lt;/h4&gt;提出一种SLAM方法，确保使用法向量一致性进行精确的地图构建。&lt;h4&gt;方法&lt;/h4&gt;1. 优化体素地图结构，存储点云数据和法向量信息；2. 引入自适应半径KD树搜索方法，根据局部点云密度动态调整搜索半径；3. 实施最少使用（LRU）缓存策略，提高体素地图的增量更新效率。&lt;h4&gt;主要发现&lt;/h4&gt;该方法有效地解决了“双面映射问题”，显著提高了地图构建的精度。&lt;h4&gt;结论&lt;/h4&gt;该方法在模拟环境和真实室内场景中均得到验证，并成功开源了针对“双面映射问题”的第一个模拟和真实世界数据集。&lt;h4&gt;翻译&lt;/h4&gt;SLAM技术在内向制图和定位中起着关键作用。室内环境中的一个常见问题是“双面映射问题”，其中紧密排列的墙壁、门和其他表面被错误地识别为单一平面，这会严重阻碍地图的准确性和一致性。为了解决这个问题，本文提出了一种SLAM方法，该方法确保了使用法向量一致性进行精确的制图。我们增强了体素地图结构，以便存储点云数据和法向量信息，使系统能够在最近邻搜索和地图更新期间评估一致性。此过程区分了表面的前后两侧，防止了错误的点到平面的约束。此外，我们实现了一种自适应半径KD树搜索方法，该方法根据局部点云密度动态调整搜索半径，从而提高了法向量计算的准确性。为了进一步提高实时性能和存储效率，我们引入了最少使用（LRU）缓存策略，该策略有助于体素地图的高效增量更新。代码已作为开源软件发布，并在模拟环境和真实室内场景中得到验证。实验结果表明，这种方法有效地解决了“双面映射问题”，并显著提高了制图精度。此外，我们还开发并开源了针对“双面映射问题”的第一个模拟和真实世界数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; SLAM technology plays a crucial role in indoor mapping and localization. Acommon challenge in indoor environments is the "double-sided mapping issue",where closely positioned walls, doors, and other surfaces are mistakenlyidentified as a single plane, significantly hindering map accuracy andconsistency. To address this issue this paper introduces a SLAM approach thatensures accurate mapping using normal vector consistency. We enhance the voxelmap structure to store both point cloud data and normal vector information,enabling the system to evaluate consistency during nearest neighbor searchesand map updates. This process distinguishes between the front and back sides ofsurfaces, preventing incorrect point-to-plane constraints. Moreover, weimplement an adaptive radius KD-tree search method that dynamically adjusts thesearch radius based on the local density of the point cloud, thereby enhancingthe accuracy of normal vector calculations. To further improve realtimeperformance and storage efficiency, we incorporate a Least Recently Used (LRU)cache strategy, which facilitates efficient incremental updates of the voxelmap. The code is released as open-source and validated in both simulatedenvironments and real indoor scenarios. Experimental results demonstrate thatthis approach effectively resolves the "double-sided mapping issue" andsignificantly improves mapping precision. Additionally, we have developed andopen-sourced the first simulation and real world dataset specifically tailoredfor the "double-sided mapping issue".</description>
      <author>example@mail.com (Chengwei Zhao, Yixuan Li, Yina Jian, Jie Xu, Linji Wang, Yongxin Ma, Xinglai Jin)</author>
      <guid isPermaLink="false">2504.08204v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Detecting Credit Card Fraud via Heterogeneous Graph Neural Networks with Graph Attention</title>
      <link>http://arxiv.org/abs/2504.08183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于异构图神经网络（HGNN）的信用卡欺诈检测方法，以解决复杂交易网络中的欺诈问题。&lt;h4&gt;背景&lt;/h4&gt;传统的机器学习方法依赖于交易记录的数值特征，而本研究提出了构建异构交易图的方法。&lt;h4&gt;目的&lt;/h4&gt;提高欺诈检测的准确性和对时间相关欺诈模式敏感度。&lt;h4&gt;方法&lt;/h4&gt;1. 构建包含用户、商家和交易等多节点类型的异构交易图；2. 利用图神经网络捕捉高阶交易关系；3. 采用图注意力机制动态分配不同交易关系的权重；4. 集成时间衰减机制增强对时间相关欺诈模式敏感度；5. 应用SMOTE过采样和代价敏感学习来解决欺诈交易样本稀缺的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在IEEE-CIS欺诈检测数据集上优于现有的GNN模型，包括GCN、GAT和GraphSAGE，在准确率和OC-ROC方面均有显著提升。&lt;h4&gt;结论&lt;/h4&gt;未来研究可能探索动态图神经网络和强化学习的集成，以增强欺诈检测系统的实时适应性和为金融风险控制提供更智能的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This study proposes a credit card fraud detection method based on Heterogeneous Graph Neural Network (HGNN) to address fraud in complex transaction networks. Unlike traditional machine learning methods that rely solely on numerical features of transaction records, this approach constructs heterogeneous transaction graphs. These graphs incorporate multiple node types, including users, merchants, and transactions. By leveraging graph neural networks, the model captures higher-order transaction relationships. A GraphAttention Mechanism is employed to dynamically assign weights to different transaction relationships. Additionally, a Temporal Decay Mechanism is integrated to enhance the model's sensitivity to time-related fraud patterns. To address the scarcity of fraudulent transaction samples, this study applies SMOTE oversampling and Cost-sensitive Learning. These techniques strengthen the model's ability to identify fraudulent transactions. Experimental results demonstrate that the proposed method outperforms existing GNN models, including GCN, GAT, and GraphSAGE, on the IEEE-CIS Fraud Detection dataset. The model achieves notable improvements in both accuracy and OC-ROC. Future research may explore the integration of dynamic graph neural networks and reinforcement learning. Such advancements could enhance the real-time adaptability of fraud detection systems and provide more intelligent solutions for financial risk control.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study proposes a credit card fraud detection method based onHeterogeneous Graph Neural Network (HGNN) to address fraud in complextransaction networks. Unlike traditional machine learning methods that relysolely on numerical features of transaction records, this approach constructsheterogeneous transaction graphs. These graphs incorporate multiple node types,including users, merchants, and transactions. By leveraging graph neuralnetworks, the model captures higher-order transaction relationships. A GraphAttention Mechanism is employed to dynamically assign weights to differenttransaction relationships. Additionally, a Temporal Decay Mechanism isintegrated to enhance the model's sensitivity to time-related fraud patterns.To address the scarcity of fraudulent transaction samples, this study appliesSMOTE oversampling and Cost-sensitive Learning. These techniques strengthen themodel's ability to identify fraudulent transactions. Experimental resultsdemonstrate that the proposed method outperforms existing GNN models, includingGCN, GAT, and GraphSAGE, on the IEEE-CIS Fraud Detection dataset. The modelachieves notable improvements in both accuracy and OC-ROC. Future research mayexplore the integration of dynamic graph neural networks and reinforcementlearning. Such advancements could enhance the real-time adaptability of frauddetection systems and provide more intelligent solutions for financial riskcontrol.</description>
      <author>example@mail.com (Qiuwu Sha, Tengda Tang, Xinyu Du, Jie Liu, Yixian Wang, Yuan Sheng)</author>
      <guid isPermaLink="false">2504.08183v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Communication-Efficient Cooperative Localization: A Graph Neural Network Approach</title>
      <link>http://arxiv.org/abs/2504.08135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通信高效的协同定位方法，用于解决无线网络中节点定位的问题。&lt;h4&gt;背景&lt;/h4&gt;在通信受限的环境中，传统的协同定位方法在无线网络中遇到困难，尤其是在存在环状拓扑结构的网络中。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，旨在同时降低定位误差和通信开销。&lt;h4&gt;方法&lt;/h4&gt;提出了一种向量量化消息传递神经网络（VQ-MPNN）用于协同定位，通过端到端神经网络训练，实现节点定位和消息压缩的协同设计。&lt;h4&gt;主要发现&lt;/h4&gt;VQ-MPNN通过将节点位置和距离测量作为节点和边特征，使用图神经网络进行编码，并通过构造向量量化码本来提高效率，从而实现低通信开销。&lt;h4&gt;结论&lt;/h4&gt;数值评估表明，所提出的VQ-MPNN方法在降低通信开销的同时，定位误差与现有方法相当。&lt;h4&gt;翻译&lt;/h4&gt;摘要：协作定位利用有噪声的节点间距离测量和交换的无线消息来估计无线网络中的节点位置。然而，在通信受限的环境中，传输大量信息变得有困难。在本文中，我们提出了一种针对通信高效的协作定位的方法，解决了两个主要挑战。首先，协作定位通常需要在具有环状图拓扑结构的无线网络上执行。其次，需要设计一个算法，在同时具有低定位误差的同时，要求通信开销大大降低。现有方法无法同时解决这两个挑战。为了实现这一点，我们提出了一种用于协作定位的向量量化消息传递神经网络（VQ-MPNN）。通过端到端神经网络训练，VQ-MPNN实现了节点定位和消息压缩的协同设计。具体来说，VQ-MPNN将先验节点位置和距离测量分别作为节点和边特征，使用图神经网络将它们编码为节点和边状态。为了找到一个高效的节点状态表示，我们为所有节点状态构建了一个向量量化码本，使得每个节点只需要传输一个码字索引。数值评估表明，我们提出的VQ-MPNN方法可以在降低通信开销的同时，提供与现有方法相当定位误差。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cooperative localization leverages noisy inter-node distance measurements andexchanged wireless messages to estimate node positions in a wireless network.In communication-constrained environments, however, transmitting large messagesbecomes problematic. In this paper, we propose an approach forcommunication-efficient cooperative localization that addresses two mainchallenges. First, cooperative localization often needs to be performed overwireless networks with loopy graph topologies. Second is the need for designingan algorithm that has low localization error while simultaneously requiring amuch lower communication overhead. Existing methods fall short of addressingthese two challenges concurrently. To achieve this, we propose a vectorquantized message passing neural network (VQ-MPNN) for cooperativelocalization. Through end-to-end neural network training, VQ-MPNN enables theco-design of node localization and message compression. Specifically, VQ-MPNNtreats prior node positions and distance measurements as node and edgefeatures, respectively, which are encoded as node and edge states using a graphneural network. To find an efficient representation for the node state, weconstruct a vector quantized codebook for all node states such that instead ofsending long messages, each node only needs to transmit a codeword index.Numerical evaluations demonstrates that our proposed VQ-MPNN approach candeliver localization errors that are similar to existing approaches whilereducing the overall communication overhead by an order of magnitude.</description>
      <author>example@mail.com (Yinan Zou, Christopher G. Brinton, Vishrant Tripathi)</author>
      <guid isPermaLink="false">2504.08135v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>SynthFM: Training Modality-agnostic Foundation Models for Medical Image Segmentation without Real Medical Data</title>
      <link>http://arxiv.org/abs/2504.08177v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SynthFM的合成数据生成框架，用于解决医学图像分割问题，并评估了其在多个数据集上的性能。&lt;h4&gt;背景&lt;/h4&gt;自然图像分割模型如Segment Anything Model (SAM) 在零样本分割方面表现优异，但在医学图像分割上由于纹理、对比度和噪声的差异而表现不佳。医学图像标注成本高且需要领域专业知识，限制了大规模标注数据的可用性。&lt;h4&gt;目的&lt;/h4&gt;提出SynthFM框架以解决医学图像分割问题，使基础模型能够在没有真实医学数据的情况下进行适应。&lt;h4&gt;方法&lt;/h4&gt;使用SAM的预训练编码器，并在SynthFM的数据集上从头开始训练解码器。在11个解剖结构上使用9个数据集（CT、MRI和超声）评估了该方法。&lt;h4&gt;主要发现&lt;/h4&gt;SynthFM在多个数据集上优于零样本基线模型SAM和MedSAM，在不同提示设置和分布外数据集上均取得了优越的结果。&lt;h4&gt;结论&lt;/h4&gt;SynthFM是一种有效的合成数据生成框架，可以显著提高医学图像分割的性能，为医学图像分割领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models like the Segment Anything Model (SAM) excel in zero-shotsegmentation for natural images but struggle with medical image segmentationdue to differences in texture, contrast, and noise. Annotating medical imagesis costly and requires domain expertise, limiting large-scale annotated dataavailability. To address this, we propose SynthFM, a synthetic data generationframework that mimics the complexities of medical images, enabling foundationmodels to adapt without real medical data. Using SAM's pretrained encoder andtraining the decoder from scratch on SynthFM's dataset, we evaluated our methodon 11 anatomical structures across 9 datasets (CT, MRI, and Ultrasound).SynthFM outperformed zero-shot baselines like SAM and MedSAM, achievingsuperior results under different prompt settings and on out-of-distributiondatasets.</description>
      <author>example@mail.com (Sourya Sengupta, Satrajit Chakrabarty, Keerthi Sravan Ravi, Gopal Avinash, Ravi Soni)</author>
      <guid isPermaLink="false">2504.08177v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Laws of Graph Neural Networks for Atomistic Materials Modeling</title>
      <link>http://arxiv.org/abs/2504.08112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by DAC'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了图神经网络（GNNs）在原子材料建模中的应用，提出了一种具有数十亿参数的基础模型，并使用海量数据进行训练，旨在提升GNNs在原子材料建模中的性能。&lt;h4&gt;背景&lt;/h4&gt;原子材料建模在药物发现和材料科学等领域具有重要应用，而GNNs因其能够捕捉复杂的关联结构而成为建模的先进方法。&lt;h4&gt;目的&lt;/h4&gt;研究GNNs在原子材料建模中的扩展极限，开发一个具有数十亿参数的基础模型，并在海量数据集上训练。&lt;h4&gt;方法&lt;/h4&gt;通过结合大型语言模型（LLM）库的技术，有效管理大规模数据和模型，实现大规模GNN模型的有效训练和部署。&lt;h4&gt;主要发现&lt;/h4&gt;包括GNNs扩展定律的见解，强调模型大小、数据集体积和准确率之间的关系；一个优化用于原子材料建模的基础GNN模型；以及一个通过先进的LLM基于的训练技术增强的GNN代码库。&lt;h4&gt;结论&lt;/h4&gt;为具有数十亿参数和千兆级数据集的大规模GNNs奠定了基础，为原子材料建模的未来发展提供了一个可扩展的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Atomistic materials modeling is a critical task with wide-rangingapplications, from drug discovery to materials science, where accuratepredictions of the target material property can lead to significantadvancements in scientific discovery. Graph Neural Networks (GNNs) representthe state-of-the-art approach for modeling atomistic material data thanks totheir capacity to capture complex relational structures. While machine learningperformance has historically improved with larger models and datasets, GNNs foratomistic materials modeling remain relatively small compared to large languagemodels (LLMs), which leverage billions of parameters and terabyte-scaledatasets to achieve remarkable performance in their respective domains. Toaddress this gap, we explore the scaling limits of GNNs for atomistic materialsmodeling by developing a foundational model with billions of parameters,trained on extensive datasets in terabyte-scale. Our approach incorporatestechniques from LLM libraries to efficiently manage large-scale data andmodels, enabling both effective training and deployment of these large-scaleGNN models. This work addresses three fundamental questions in scaling GNNs:the potential for scaling GNN model architectures, the effect of dataset sizeon model accuracy, and the applicability of LLM-inspired techniques to GNNarchitectures. Specifically, the outcomes of this study include (1) insightsinto the scaling laws for GNNs, highlighting the relationship between modelsize, dataset volume, and accuracy, (2) a foundational GNN model optimized foratomistic materials modeling, and (3) a GNN codebase enhanced with advancedLLM-based training techniques. Our findings lay the groundwork for large-scaleGNNs with billions of parameters and terabyte-scale datasets, establishing ascalable pathway for future advancements in atomistic materials modeling.</description>
      <author>example@mail.com (Chaojian Li, Zhifan Ye, Massimiliano Lupo Pasini, Jong Youl Choi, Cheng Wan, Yingyan Celine Lin, Prasanna Balaprakash)</author>
      <guid isPermaLink="false">2504.08112v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Day-to-day Dynamic Tolling in Tradable Credit Schemes</title>
      <link>http://arxiv.org/abs/2504.08074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了可交易信用方案（TCS）作为拥堵定价的替代方案，通过强化学习算法解决TCS下的日常动态收费问题，并评估了算法在不同参数和需求下的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;可交易信用方案（TCS）作为一种新兴的拥堵管理工具，因其收入中立性和通过初始信用分配解决公平性问题而受到关注。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过强化学习算法解决TCS下的日常动态收费问题，并评估算法在不同条件下的性能。&lt;h4&gt;方法&lt;/h4&gt;将TCS下的日常动态收费问题建模为离散时间马尔可夫决策过程，并使用强化学习算法进行求解。&lt;h4&gt;主要发现&lt;/h4&gt;强化学习算法在旅行时间和社会福利方面与贝叶斯优化基准相当，且在不同容量和需求水平上具有良好的泛化能力。通过调整超参数和采用正则化技术，算法表现出良好的鲁棒性，并生成了在不同需求供应变化下可转移的收费策略。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效解决TCS下的日常动态收费问题，并具有在实际网络中应用的潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了可交易信用方案（TCS）作为一种替代拥堵定价的方法，考虑到其收入中立性和通过初始信用分配解决公平性问题。建模TCS以帮助未来的设计和实施涉及到用户和市场行为、供需动态和控制机制等挑战。在本文中，我们专注于后者，并解决了TCS下的日常动态收费问题，将其表述为离散时间马尔可夫决策过程，并使用强化学习（RL）算法来解决。我们的结果表明，RL算法在旅行时间和社会福利方面与贝叶斯优化基准相当，并在不同的容量和需求水平上具有泛化能力。我们进一步评估了RL在不同超参数下的鲁棒性，并应用了正则化技术来减轻动作振荡，从而生成在不同日常需求和供应变化下可转移的实际收费策略。最后，我们讨论了潜在的挑战，如扩展到大型网络，并展示了如何利用迁移学习来提高计算效率，从而促进基于RL的TCS解决方案的实用部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tradable credit schemes (TCS) are an increasingly studied alternative tocongestion pricing, given their revenue neutrality and ability to addressissues of equity through the initial credit allocation. Modeling TCS to aidfuture design and implementation is associated with challenges involving userand market behaviors, demand-supply dynamics, and control mechanisms. In thispaper, we focus on the latter and address the day-to-day dynamic tollingproblem under TCS, which is formulated as a discrete-time Markov DecisionProcess and solved using reinforcement learning (RL) algorithms. Our resultsindicate that RL algorithms achieve travel times and social welfare comparableto the Bayesian optimization benchmark, with generalization across varyingcapacities and demand levels. We further assess the robustness of RL underdifferent hyperparameters and apply regularization techniques to mitigateaction oscillation, which generates practical tolling strategies that aretransferable under day-to-day demand and supply variability. Finally, wediscuss potential challenges such as scaling to large networks, and show howtransfer learning can be leveraged to improve computational efficiency andfacilitate the practical deployment of RL-based TCS solutions.</description>
      <author>example@mail.com (Xiaoyi Wu, Ravi Seshadri, Filipe Rodrigues, Carlos Lima Azevedo)</author>
      <guid isPermaLink="false">2504.08074v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Vector Quantized-Elites: Unsupervised and Problem-Agnostic Quality-Diversity Optimization</title>
      <link>http://arxiv.org/abs/2504.08057v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 10 figures, 2 algorithms, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了VQ-Elites，一种新的质量多样性算法，该算法通过无监督学习自主构建结构化的行为空间网格，提高了传统质量多样性方法的灵活性。&lt;h4&gt;背景&lt;/h4&gt;传统的质量多样性方法如MAP-Elites依赖预定义的行为描述符和任务先验知识，限制了它们的灵活性和适用性。&lt;h4&gt;目的&lt;/h4&gt;提出VQ-Elites，旨在提高质量多样性算法的灵活性和鲁棒性，使其能够适应更广泛的任务。&lt;h4&gt;方法&lt;/h4&gt;VQ-Elites集成了矢量量化变分自动编码器，实现动态学习行为描述符并生成结构化的行为空间网格。此外，还引入了行为空间边界和协作机制以增强算法性能。&lt;h4&gt;主要发现&lt;/h4&gt;VQ-Elites能够有效地生成多样且高质量的结果，证明其在适应性、可扩展性、鲁棒性和扩展质量多样性优化到复杂领域方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;VQ-Elites是一种灵活、鲁棒且无需特定任务的优化框架，有助于解决复杂任务并扩展质量多样性优化应用范围。&lt;h4&gt;翻译&lt;/h4&gt;摘要：质量多样性算法通过优先发现多样化、高性能的解决方案而改变了优化方式。然而，传统的质量多样性方法，如MAP-Elites，严重依赖预定义的行为描述符和任务先验知识来定义行为空间网格，限制了它们的灵活性和适用性。在这项工作中，我们引入了向量量化精英（VQ-Elites），这是一种新型的质量多样性算法，它使用无监督学习自主构建结构化的行为空间网格，消除了对先验任务特定知识的需要。VQ-Elites的核心是矢量量化变分自动编码器的集成，这使得动态学习行为描述符和生成结构化的而非非结构化的行为空间网格成为可能，这是现有无监督质量多样性方法的重大进步。这种设计将VQ-Elites确立为一种灵活、鲁棒且无需特定任务的优化框架。为了进一步增强无监督质量多样性算法的性能，我们引入了两个关键组件：行为空间边界和协作机制，这些机制显著提高了收敛性和性能。我们在机器人臂姿态到达和移动机器人空间覆盖任务上验证了VQ-Elites。结果表明，它能够有效地生成多样、高质量的结果，强调了其适应性、可扩展性、对超参数的鲁棒性和将质量多样性优化扩展到复杂、以前无法访问的领域的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quality-Diversity algorithms have transformed optimization by prioritizingthe discovery of diverse, high-performing solutions over a single optimalresult. However, traditional Quality-Diversity methods, such as MAP-Elites,rely heavily on predefined behavioral descriptors and complete prior knowledgeof the task to define the behavioral space grid, limiting their flexibility andapplicability. In this work, we introduce Vector Quantized-Elites (VQ-Elites),a novel Quality-Diversity algorithm that autonomously constructs a structuredbehavioral space grid using unsupervised learning, eliminating the need forprior task-specific knowledge. At the core of VQ-Elites is the integration ofVector Quantized Variational Autoencoders, which enables the dynamic learningof behavioral descriptors and the generation of a structured, rather thanunstructured, behavioral space grid - a significant advancement over existingunsupervised Quality-Diversity approaches. This design establishes VQ-Elites asa flexible, robust, and task-agnostic optimization framework. To furtherenhance the performance of unsupervised Quality-Diversity algorithms, weintroduce two key components: behavioral space bounding and cooperationmechanisms, which significantly improve convergence and performance. Wevalidate VQ-Elites on robotic arm pose-reaching and mobile robot space-coveringtasks. The results demonstrate its ability to efficiently generate diverse,high-quality solutions, emphasizing its adaptability, scalability, robustnessto hyperparameters, and potential to extend Quality-Diversity optimization tocomplex, previously inaccessible domains.</description>
      <author>example@mail.com (Constantinos Tsakonas, Konstantinos Chatzilygeroudis)</author>
      <guid isPermaLink="false">2504.08057v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Psychological Health Knowledge-Enhanced LLM-based Social Network Crisis Intervention Text Transfer Recognition Method</title>
      <link>http://arxiv.org/abs/2504.07983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于大型语言模型（LLM）的文本转移识别方法，用于社交网络危机干预，并增强了特定领域的精神健康知识。&lt;h4&gt;背景&lt;/h4&gt;随着社交媒体平台上心理健康危机的普遍增加，识别和预防潜在危害已成为一项紧迫的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够准确检测和识别社交网络中的心理健康危机的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种多层次框架，该框架结合了使用BERT的迁移学习，并整合了精神健康知识、情感分析和行为预测技术。框架包括一个在真实世界事件的社会媒体数据集上训练的危机标注工具，使模型能够检测细微的情绪线索和识别心理危机。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在危机检测准确率方面优于传统模型，并对微妙的情绪和语境变化表现出更高的敏感性。&lt;h4&gt;结论&lt;/h4&gt;该方法为社交网络中的心理健康危机干预提供了一种有效工具。&lt;h4&gt;翻译&lt;/h4&gt;As the prevalence of mental health crises increases on social media platforms, identifying and preventing potential harm has become an urgent challenge. This study introduces a large language model (LLM)-based text transfer recognition method for social network crisis intervention, enhanced with domain-specific mental health knowledge. We propose a multi-level framework that incorporates transfer learning using BERT, and integrates mental health knowledge, sentiment analysis, and behavior prediction techniques. The framework includes a crisis annotation tool trained on social media datasets from real-world events, enabling the model to detect nuanced emotional cues and identify psychological crises. Experimental results show that the proposed method outperforms traditional models in crisis detection accuracy and exhibits greater sensitivity to subtle emotional and contextual variations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the prevalence of mental health crises increases on social mediaplatforms, identifying and preventing potential harm has become an urgentchallenge. This study introduces a large language model (LLM)-based texttransfer recognition method for social network crisis intervention, enhancedwith domain-specific mental health knowledge. We propose a multi-levelframework that incorporates transfer learning using BERT, and integrates mentalhealth knowledge, sentiment analysis, and behavior prediction techniques. Theframework includes a crisis annotation tool trained on social media datasetsfrom real-world events, enabling the model to detect nuanced emotional cues andidentify psychological crises. Experimental results show that the proposedmethod outperforms traditional models in crisis detection accuracy and exhibitsgreater sensitivity to subtle emotional and contextual variations.</description>
      <author>example@mail.com (Shurui Wu, Xinyi Huang, Dingxin Lu)</author>
      <guid isPermaLink="false">2504.07983v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Pushing the Accuracy Limit of Foundation Neural Network Models with Quantum Monte Carlo Forces and Path Integrals</title>
      <link>http://arxiv.org/abs/2504.07948v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种端到端集成策略，用于生成高度精确的量子化学合成数据集（能量和力），旨在推导用于分子模拟的基础机器学习模型。&lt;h4&gt;背景&lt;/h4&gt;从密度泛函理论（DFT）出发，采用“雅各布楼梯”方法，利用大量并行GPU加速软件的计算优化层，提高精度。&lt;h4&gt;目的&lt;/h4&gt;生成高度精确的量子化学合成数据集，用于分子模拟的基础机器学习模型。&lt;h4&gt;方法&lt;/h4&gt;利用Exascale技术，首次在完全基组极限下计算了计算密集型计算扩散量子蒙特卡罗（QMC）力，以及多确定子QMC能量和力与选择-CI波函数的结合。通过迁移学习改进FeNNix-Bio1DFT基础模型，并与路径积分自适应采样量子动力学相结合，进行纳秒级反应模拟。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在前所未有的精度下进行了纳秒级反应模拟，展示了Exascale在深化对复杂生物系统内部机制理解方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;Exascale技术在量子化学合成数据集生成和分子模拟基础模型推导方面具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;We propose an end-to-end integrated strategy to produce highly accurate quantum chemistry (QC) synthetic datasets (energies and forces) aimed at deriving Foundation Machine Learning models for molecular simulation. Starting from Density Functional Theory (DFT), a "Jacob's Ladder" approach leverages computationally-optimized layers of massively parallel GPU-accelerated software with increasing accuracy. Thanks to Exascale, this is the first time that the computationally intensive calculation of Diffusion Quantum Monte Carlo (QMC) forces, and the combination of multi-determinant QMC energies and forces with selected-CI wavefunctions, are computed at such scale at the complete basis-set-limit. To bridge the gap between accurate QC and condensed-phasemolecular dynamics, we leverage transfer learning to improve the FeNNix-Bio1DFT-based foundation model. The resulting approach is coupled to path integrals adaptive sampling quantum dynamics to perform nanosecond reactive simulations at unprecedented accuracy. These results demonstrate the promise of Exascale to deepen our understanding of the inner machinery of complex biosystems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose an end-to-end integrated strategy to produce highly accuratequantum chemistry (QC) synthetic datasets (energies and forces) aimed atderiving Foundation Machine Learning models for molecular simulation. Startingfrom Density Functional Theory (DFT), a "Jacob's Ladder" approach leveragescomputationally-optimized layers of massively parallel GPU-accelerated softwarewith increasing accuracy. Thanks to Exascale, this is the first time that thecomputationally intensive calculation of Diffusion Quantum Monte Carlo (QMC)forces, and the combination of multi-determinant QMC energies and forces withselected-CI wavefunctions, are computed at such scale at the completebasis-set-limit. To bridge the gap between accurate QC and condensed-phasemolecular dynamics, we leverage transfer learning to improve the FeNNix-Bio1DFT-based foundation model. The resulting approach is coupled to path integralsadaptive sampling quantum dynamics to perform nanosecond reactive simulationsat unprecedented accuracy. These results demonstrate the promise of Exascale todeepen our understanding of the inner machinery of complex biosystems.</description>
      <author>example@mail.com (Anouar Benali, Thomas Plé, Olivier Adjoua, Valay Agarawal, Thomas Applencourt, Marharyta Blazhynska, Raymond Clay III, Kevin Gasperich, Khalid Hossain, Jeongnim Kim, Christopher Knight, Jaron T. Krogel, Yvon Maday, Maxime Maria, Matthieu Montes, Ye Luo, Evgeny Posenitskiy, Corentin Villot, Venkat Vishwanath, Louis Lagardère, Jean-Philip Piquemal)</author>
      <guid isPermaLink="false">2504.07948v2</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis</title>
      <link>http://arxiv.org/abs/2504.06553v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AShiTA的框架，用于将高级任务分解为与环境相关的子任务，以解决将抽象高级指令与3D场景关联的挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管近年来在场景重建和理解方面取得了进展，但将抽象、高级指令与3D场景关联仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，能够将高级任务分解为与环境相关的子任务，并生成与3D场景图相关的任务层次结构。&lt;h4&gt;方法&lt;/h4&gt;AShiTA通过交替使用LLM辅助的层次任务分析和任务驱动的3D场景图构建来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AShiTA在将高级任务分解为环境相关的子任务方面显著优于LLM基线，并且能够达到与最先进方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;AShiTA是一种有效的框架，可以解决将高级指令与3D场景关联的挑战，并具有与现有方法相媲美的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While recent work in scene reconstruction and understanding has made stridesin grounding natural language to physical 3D environments, it is stillchallenging to ground abstract, high-level instructions to a 3D scene.High-level instructions might not explicitly invoke semantic elements in thescene, and even the process of breaking a high-level task into a set of moreconcrete subtasks, a process called hierarchical task analysis, isenvironment-dependent. In this work, we propose ASHiTA, the first frameworkthat generates a task hierarchy grounded to a 3D scene graph by breaking downhigh-level tasks into grounded subtasks. ASHiTA alternates LLM-assistedhierarchical task analysis, to generate the task breakdown, with task-driven 3Dscene graph construction to generate a suitable representation of theenvironment. Our experiments show that ASHiTA performs significantly betterthan LLM baselines in breaking down high-level tasks into environment-dependentsubtasks and is additionally able to achieve grounding performance comparableto state-of-the-art methods.</description>
      <author>example@mail.com (Yun Chang, Leonor Fermoselle, Duy Ta, Bernadette Bucher, Luca Carlone, Jiuguang Wang)</author>
      <guid isPermaLink="false">2504.06553v3</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Are We Done with Object-Centric Learning?</title>
      <link>http://arxiv.org/abs/2504.07092v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于对象的学习（OCL）方法，旨在学习仅编码单个对象而不受场景中其他对象或背景线索影响的表示。研究提出了一种新的无监督探针方法，并通过实验验证了基于分割的对象编码在OOD泛化方面的优势。&lt;h4&gt;背景&lt;/h4&gt;OCL方法旨在通过分离对象来学习对象中心的表示，从而实现OOD泛化、样本高效合成和结构化环境的建模。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过OCL方法分离场景中的对象，并探讨其对OOD泛化等OCL目标的贡献。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Object-Centric Classification with Applied Masks (OCCAM)的新方法，该方法通过分割图像中的对象进行编码，并与基于槽位的OCL方法进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;基于分割的对象编码在OOD对象发现基准测试中表现出色，显著优于基于槽位的OCL方法。&lt;h4&gt;结论&lt;/h4&gt;尽管OCL方法在实现对象中心表示方面取得了重大进展，但其在现实世界应用中仍存在挑战。研究为OCL社区提供了可扩展的对象中心表示工具箱，并关注实际应用和基本问题，如理解人类认知中的物体感知。&lt;h4&gt;翻译&lt;/h4&gt;摘要：以对象为中心的学习（OCL）旨在学习仅编码对象，而将对象与其他对象或场景中的背景线索隔离的表示。这种方法支持各种目标，包括分布外（OOD）泛化、样本高效合成和结构化环境的建模。大多数研究都集中在开发将对象分离到表示空间中离散槽位的无监督机制上，使用无监督对象发现进行评估。然而，随着近期样本高效的分割模型的发展，我们可以在像素空间中分离对象并独立编码它们。这在对OOD对象发现基准的零样本性能上取得了显著成果，可以扩展到基础模型，并且可以无需额外配置处理可变数量的槽位。因此，OCL方法获得对象中心表示的目标已经基本实现。尽管取得了这些进展，但一个关键问题仍然存在：在场景中分离对象的能力如何有助于更广泛的OCL目标，例如OOD泛化？我们通过OCL的视角来探讨由虚假背景线索引起的OOD泛化挑战。我们提出了一种新的、无需训练的探针，称为Object-Centric Classification with Applied Masks（OCCAM），证明了基于分割的个体对象编码在性能上显著优于基于槽位的OCL方法。然而，在现实世界的应用中仍然存在挑战。我们为OCL社区提供了可扩展的对象中心表示工具箱，并专注于实际应用和基本问题，例如理解人类认知中的物体感知。我们的代码可在以下链接找到：https://github.com/AlexanderRubinstein/OCCAM。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object-centric learning (OCL) seeks to learn representations that only encodean object, isolated from other objects or background cues in a scene. Thisapproach underpins various aims, including out-of-distribution (OOD)generalization, sample-efficient composition, and modeling of structuredenvironments. Most research has focused on developing unsupervised mechanismsthat separate objects into discrete slots in the representation space,evaluated using unsupervised object discovery. However, with recentsample-efficient segmentation models, we can separate objects in the pixelspace and encode them independently. This achieves remarkable zero-shotperformance on OOD object discovery benchmarks, is scalable to foundationmodels, and can handle a variable number of slots out-of-the-box. Hence, thegoal of OCL methods to obtain object-centric representations has been largelyachieved. Despite this progress, a key question remains: How does the abilityto separate objects within a scene contribute to broader OCL objectives, suchas OOD generalization? We address this by investigating the OOD generalizationchallenge caused by spurious background cues through the lens of OCL. Wepropose a novel, training-free probe called Object-Centric Classification withApplied Masks (OCCAM), demonstrating that segmentation-based encoding ofindividual objects significantly outperforms slot-based OCL methods. However,challenges in real-world applications remain. We provide the toolbox for theOCL community to use scalable object-centric representations, and focus onpractical applications and fundamental questions, such as understanding objectperception in human cognition. Our code is available here:https://github.com/AlexanderRubinstein/OCCAM.</description>
      <author>example@mail.com (Alexander Rubinstein, Ameya Prabhu, Matthias Bethge, Seong Joon Oh)</author>
      <guid isPermaLink="false">2504.07092v2</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Orb-v3: atomistic simulation at scale</title>
      <link>http://arxiv.org/abs/2504.06231v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Orb-v3，这是Orb家族通用原子势的下一代。该模型在性能、速度和内存方面扩展了Pareto前沿，在各种评估中提供了接近最先进技术（SoTA）的性能，同时降低了10倍以上的延迟和8倍以上的内存。&lt;h4&gt;背景&lt;/h4&gt;Orb-v3是Orb家族的一部分，旨在提高原子模拟的准确性、速度和可扩展性。&lt;h4&gt;目的&lt;/h4&gt;开发一个在准确性、延迟和系统规模可扩展性方面都表现出色的原子模拟基础模型。&lt;h4&gt;方法&lt;/h4&gt;通过系统地遍历性能、速度和内存的Pareto前沿，研究了旋转等变、保守性和图稀疏性之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;发现非等变、非保守架构可以准确地模拟物理性质，包括需要势能表面高阶导数的性质。&lt;h4&gt;结论&lt;/h4&gt;该模型发布遵循的原则是，最有价值的原子模拟基础模型应在所有方面都表现出色，这将推动一个由高通量和中等规模全原子模拟驱动的计算化学新时代。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了Orb-v3，这是Orb家族通用原子势的下一代。该家族的模型扩展了性能-速度-内存的Pareto前沿，在各种评估中提供了接近最先进技术（SoTA）的性能，同时降低了10倍以上的延迟和8倍以上的内存。我们的实验系统地遍历了这一前沿，描绘了由旋转等变、保守性和图稀疏性引起的权衡。与近期文献相反，我们发现非等变、非保守架构可以准确地模拟物理性质，包括那些需要势能表面高阶导数的性质。这一模型发布遵循的原则是，最有价值的原子模拟基础模型将在所有方面都表现出色，这将推动一个由高通量和中等规模全原子模拟驱动的计算化学新时代。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Orb-v3, the next generation of the Orb family of universalinteratomic potentials. Models in this family expand theperformance-speed-memory Pareto frontier, offering near SoTA performance acrossa range of evaluations with a &gt;10x reduction in latency and &gt; 8x reduction inmemory. Our experiments systematically traverse this frontier, charting thetrade-off induced by roto-equivariance, conservatism and graph sparsity.Contrary to recent literature, we find that non-equivariant, non-conservativearchitectures can accurately model physical properties, including those whichrequire higher-order derivatives of the potential energy surface.  This model release is guided by the principle that the most valuablefoundation models for atomic simulation will excel on all fronts: accuracy,latency and system size scalability. The reward for doing so is a new era ofcomputational chemistry driven by high-throughput and mesoscale all-atomsimulations.</description>
      <author>example@mail.com (Benjamin Rhodes, Sander Vandenhaute, Vaidotas Šimkus, James Gin, Jonathan Godwin, Tim Duignan, Mark Neumann)</author>
      <guid isPermaLink="false">2504.06231v2</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Solving the Correlation Cluster LP in Sublinear Time</title>
      <link>http://arxiv.org/abs/2503.20883v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法来解决相关聚类问题，该方法能够在多项式时间内找到近似解。&lt;h4&gt;背景&lt;/h4&gt;相关聚类是无监督学习和数据挖掘中的一个基础且广泛研究的问题，其目标是构造一个聚类，以最小化跨聚类边和缺失的内部聚类边的数量。&lt;h4&gt;目的&lt;/h4&gt;研究如何更简洁地表示相关聚类问题，并设计快速近似算法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的方法来找到集群线性规划（cluster LP）的可行解，并实现了解的近似。&lt;h4&gt;主要发现&lt;/h4&gt;在多项式时间内找到集群线性规划的可行解，目标值不超过最优解的(1+ε)倍，同时实现了快速(1.437+ε)近似算法。&lt;h4&gt;结论&lt;/h4&gt;该方法弥合了相关聚类近似算法的最新方法与快速算法之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;相关聚类是机器学习领域中的一个基本问题，其目的是通过将数据点分成不同的组来发现数据中的潜在结构。本文研究了如何用线性规划方法来解决这个问题，并提出了一种新的算法，该算法可以在多项式时间内找到近似解，从而加快了相关聚类的处理速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3717823.3718181&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Correlation Clustering is a fundamental and widely-studied problem inunsupervised learning and data mining. The input is a graph and the goal is toconstruct a clustering minimizing the number of inter-cluster edges plus thenumber of missing intra-cluster edges.  CCL+24 introduced the cluster LP for Correlation Clustering, which theyargued captures the problem much more succinctly than previous linearprogramming formulations. However, the cluster LP has exponential size, with avariable for every possible set of vertices in the input graph. Nevertheless,CCL+24 showed how to find a feasible solution for the cluster LP in time$O(n^{\text{poly}(1/\eps)})$ with objective value at most $(1+\epsilon)$ timesthe value of an optimal solution for the respective Correlation Clusteringinstance. Furthermore, they showed how to round a solution to the cluster LP,yielding a $(1.437+\eps)$-approximation algorithm for the CorrelationClustering problem.  The main technical result of this paper is a new approach to find a feasiblesolution for the cluster LP with objective value at most $(1+\epsilon)$ of theoptimum in time $\widetilde O(2^{\text{poly}(1/\eps)} n)$, where $n$ is thenumber of vertices in the graph. We also show how to implement the roundingwithin the same time bounds, thus achieving a fast $(1.437+\eps)$-approximationalgorithm for the Correlation Clustering problem. This bridges the gap betweenstate-of-the-art methods for approximating Correlation Clustering and therecent focus on fast algorithms.</description>
      <author>example@mail.com (Nairen Cao, Vincent Cohen-Addad, Shi Li, Euiwoong Lee, David Rasmussen Lolck, Alantha Newman, Mikkel Thorup, Lukas Vogl, Shuyi Yan, Hanwen Zhang)</author>
      <guid isPermaLink="false">2503.20883v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
  <item>
      <title>Detect Anything 3D in the Wild</title>
      <link>http://arxiv.org/abs/2504.07958v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DetAny3D是一种可检测任意新对象的三维检测基础模型，它利用单目输入在任意相机配置下进行检测。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习在近集三维物体检测中取得了成功，但现有的方法在处理新对象和相机配置的零样本泛化方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出DetAny3D，以解决三维检测基础模型训练中标注三维数据有限的问题，并利用预训练的二维基础模型的知识。&lt;h4&gt;方法&lt;/h4&gt;DetAny3D包含两个核心模块：2D Aggregator用于对齐不同二维基础模型的特征；3D Interpreter with Zero-Embedding Mapping用于缓解从二维到三维知识迁移中的灾难性遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DetAny3D在未见类别和新型相机配置上实现了最先进的性能，并在领域数据上超越了大多数竞争对手。&lt;h4&gt;结论&lt;/h4&gt;DetAny3D展示了三维基础模型在现实场景中多样化应用的潜力，如自动驾驶中的稀有物体检测，并预示着在开放世界环境中进一步探索以三维为中心的任务的前景。&lt;h4&gt;翻译&lt;/h4&gt;尽管深度学习在近集三维物体检测中取得了成功，但现有的方法在处理新对象和相机配置的零样本泛化方面存在困难。我们引入了DetAny3D，这是一种可提示的三维检测基础模型，它能够仅使用单目输入在任意相机配置下检测任何新对象。训练三维检测基础模型的基本限制是标注三维数据的有限可用性，这促使DetAny3D利用大量预训练的二维基础模型中嵌入的丰富先验知识来弥补这种稀缺性。为了有效地将二维知识迁移到三维，DetAny3D包含了两个核心模块：2D Aggregator，它对齐来自不同二维基础模型的特征；3D Interpreter with Zero-Embedding Mapping，它缓解了从二维到三维知识迁移中的灾难性遗忘。实验结果验证了我们的DetAny3D强大的泛化能力，它不仅在未见类别和新型相机配置上实现了最先进的性能，而且在领域数据上也超越了大多数竞争对手。DetAny3D揭示了三维基础模型在现实场景中多样化应用的潜力，例如自动驾驶中的稀有物体检测，并展示了在开放世界环境中进一步探索以三维为中心的任务的前景。更多信息可在DetAny3D项目页面上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the success of deep learning in close-set 3D object detection,existing approaches struggle with zero-shot generalization to novel objects andcamera configurations. We introduce DetAny3D, a promptable 3D detectionfoundation model capable of detecting any novel object under arbitrary cameraconfigurations using only monocular inputs. Training a foundation model for 3Ddetection is fundamentally constrained by the limited availability of annotated3D data, which motivates DetAny3D to leverage the rich prior knowledge embeddedin extensively pre-trained 2D foundation models to compensate for thisscarcity. To effectively transfer 2D knowledge to 3D, DetAny3D incorporates twocore modules: the 2D Aggregator, which aligns features from different 2Dfoundation models, and the 3D Interpreter with Zero-Embedding Mapping, whichmitigates catastrophic forgetting in 2D-to-3D knowledge transfer. Experimentalresults validate the strong generalization of our DetAny3D, which not onlyachieves state-of-the-art performance on unseen categories and novel cameraconfigurations, but also surpasses most competitors on in-domain data.DetAny3Dsheds light on the potential of the 3D foundation model for diverseapplications in real-world scenarios, e.g., rare object detection in autonomousdriving, and demonstrates promise for further exploration of 3D-centric tasksin open-world settings. More visualization results can be found at DetAny3Dproject page.</description>
      <author>example@mail.com (Hanxue Zhang, Haoran Jiang, Qingsong Yao, Yanan Sun, Renrui Zhang, Hao Zhao, Hongyang Li, Hongzi Zhu, Zetong Yang)</author>
      <guid isPermaLink="false">2504.07958v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Focal Cortical Dysplasia Type II Detection Using Cross Modality Transfer Learning and Grad-CAM in 3D-CNNs for MRI Analysis</title>
      <link>http://arxiv.org/abs/2504.07775v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了使用3D卷积神经网络（3D-CNNs）检测FCD（Focal cortical dysplasia，局灶性皮质发育不良）II型，并评估了跨模态迁移学习和可解释人工智能（XAI）技术，特别是Grad-CAM（梯度加权类激活映射）在提高诊断准确性和可解释性方面的益处。&lt;h4&gt;背景&lt;/h4&gt;FCD II型是难治性癫痫的主要原因，通常只能通过手术治愈。由于MRI检查中FCD的细微异常，其诊断非常困难，导致误诊。&lt;h4&gt;目的&lt;/h4&gt;研究使用3D-CNNs检测FCD，并评估跨模态迁移学习和XAI技术，特别是Grad-CAM在提高诊断准确性和可解释性方面的效果。&lt;h4&gt;方法&lt;/h4&gt;使用包含170个受试者（85名FCD患者和85名对照组）的数据集，其中包含T1加权和FLAIR MRI扫描，实施了ResNet架构（ResNet-18、-34和-50），并采用了使用预训练权重的迁移学习策略。&lt;h4&gt;主要发现&lt;/h4&gt;迁移学习显著提高了分类准确率（高达80.3%）和可解释性，通过一个名为Heat-Score的新度量标准来衡量，该标准评估模型对临床相关区域的关注。Heat-Score度量标准的改进强调了模型在癫痫区定位方面的能力，使AI预测和临床见解更接近。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，迁移学习，包括跨模态，以及XAI在推进基于AI的医学诊断方面的重要性，特别是对于像FCD这样的难以诊断的疾病。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Focal cortical dysplasia (FCD) type II is a major cause of drug-resistantepilepsy, often curable only by surgery. Despite its clinical importance, thediagnosis of FCD is very difficult in MRI because of subtle abnormalities,leading to misdiagnosis. This study investigates the use of 3D convolutionalneural networks (3D-CNNs) for FCD detection, using a dataset of 170 subjects(85 FCD patients and 85 controls) composed of T1-weighted and FLAIR MRI scans.In particular, it investigates the benefits obtained from cross-modalitytransfer learning and explainable artificial intelligence (XAI) techniques, inparticular Gradient-weighted Class Activation Mapping (Grad-CAM). ResNetarchitectures (ResNet-18, -34, and -50) were implemented, employing transferlearning strategies that used pre-trained weights from segmentation tasks.Results indicate that transfer learning significantly enhances classificationaccuracy (up to 80.3%) and interpretability, as measured by a novel Heat-Scoremetric, which evaluates the model's focus on clinically relevant regions.Improvements in the Heat-Score metric underscore the model's seizure zonelocalization capabilities, bringing AI predictions and clinical insights closertogether. These results highlight the importance of transfer learning,including cross-modality, and XAI in advancing AI-based medical diagnostics,especially for difficult-to-diagnose pathologies such as FCD.</description>
      <author>example@mail.com (Lorenzo Lasagni, Antonio Ciccarone, Renzo Guerrini, Matteo Lenge, Ludovico D'incerti)</author>
      <guid isPermaLink="false">2504.07775v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>GLUS: Global-Local Reasoning Unified into A Single Large Language Model for Video Segmentation</title>
      <link>http://arxiv.org/abs/2504.07962v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，利用多模态大型语言模型（MLLMs）进行参考视频对象分割（RefVOS），在MeViS和Ref-Youtube-VOS基准测试上实现了MLLMs的新突破。&lt;h4&gt;背景&lt;/h4&gt;以往基于MLLM的方法在“参考”和“视频对象分割”（VOS）之间存在困境，要么专注于理解几个关键帧（全局推理），要么在连续帧上跟踪对象（局部推理），并且依赖外部VOS或帧选择器来缓解另一方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，旨在解决MLLMs在RefVOS中的“参考”和“VOS”之间的矛盾，并提高分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出的框架GLUS将全局和局部一致性统一到单个视频分割MLLM中，使用稀疏的“上下文帧”提供全局信息，同时使用连续的“查询帧”进行局部对象跟踪。此外，通过与预训练的VOS记忆库联合训练，同时处理短程和长程时间信息。为了提高MLLMs在有限上下文窗口中的信息效率，引入了对象对比学习来区分硬性误报对象，并提出了自我精炼框架来识别关键帧并进行传播。&lt;h4&gt;主要发现&lt;/h4&gt;GLUS框架通过综合上述方法，提供了一种简单而有效的基准，在MeViS和Ref-Youtube-VOS基准测试上实现了MLLMs的新突破。&lt;h4&gt;结论&lt;/h4&gt;GLUS框架为MLLMs在RefVOS任务上提供了一个高效且准确的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的框架，利用多模态大型语言模型（MLLMs）进行参考视频对象分割（RefVOS）。以往基于MLLM的方法通常难以平衡“参考”和“视频对象分割”（VOS）之间的矛盾：它们要么专注于理解几个关键帧（全局推理），要么在连续帧上跟踪对象（局部推理），并且依赖外部VOS或帧选择器来缓解另一方面的挑战。然而，我们的框架GLUS表明，全局和局部一致性可以统一到一个视频分割MLLM中：一组稀疏的“上下文帧”提供全局信息，而连续的“查询帧”进行局部对象跟踪。这一点通过联合训练MLLM与预训练的VOS记忆库得到进一步支持，以同时处理短程和长程时间信息。为了提高MLLMs在有限上下文窗口中的信息效率，我们引入了对象对比学习来区分硬性误报对象，并提出了自我精炼框架来识别关键帧并进行传播。通过综合这些见解，我们的GLUS提供了一种简单而有效的基准，在MeViS和Ref-Youtube-VOS基准测试上实现了MLLMs的新突破。我们的项目页面在https://glus-video.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a novel framework utilizing multi-modal large languagemodels (MLLMs) for referring video object segmentation (RefVOS). PreviousMLLM-based methods commonly struggle with the dilemma between "Ref" and "VOS":they either specialize in understanding a few key frames (global reasoning) ortracking objects on continuous frames (local reasoning), and rely on externalVOS or frame selectors to mitigate the other end of the challenge. However, ourframework GLUS shows that global and local consistency can be unified into asingle video segmentation MLLM: a set of sparse "context frames" providesglobal information, while a stream of continuous "query frames" conducts localobject tracking. This is further supported by jointly training the MLLM with apre-trained VOS memory bank to simultaneously digest short-range and long-rangetemporal information. To improve the information efficiency within the limitedcontext window of MLLMs, we introduce object contrastive learning todistinguish hard false-positive objects and a self-refined framework toidentify crucial frames and perform propagation. By collectively integratingthese insights, our GLUS delivers a simple yet effective baseline, achievingnew state-of-the-art for MLLMs on the MeViS and Ref-Youtube-VOS benchmark. Ourproject page is at https://glus-video.github.io/.</description>
      <author>example@mail.com (Lang Lin, Xueyang Yu, Ziqi Pang, Yu-Xiong Wang)</author>
      <guid isPermaLink="false">2504.07962v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>WS-DETR: Robust Water Surface Object Detection through Vision-Radar Fusion with Detection Transformer</title>
      <link>http://arxiv.org/abs/2504.07441v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种鲁棒的视觉-雷达融合模型WS-DETR，用于解决无人水面舰艇在复杂水域中对象检测的挑战。&lt;h4&gt;背景&lt;/h4&gt;在复杂水域环境中，水面对象检测面临模糊边缘和多样化目标尺度的挑战。&lt;h4&gt;目的&lt;/h4&gt;为了提高模型在复杂环境中的鲁棒性，提出了一种新的视觉-雷达融合模型。&lt;h4&gt;方法&lt;/h4&gt;该方法包括：1. 引入多尺度边缘信息集成(MSEII)模块和分层特征聚合(HiFA)模块来增强边缘感知和提升多尺度目标检测能力；2. 使用自移动点表示和连续卷积及残差连接有效提取不规则点云数据下的不规则特征；3. 引入自适应特征交互融合(AFIF)模块通过几何对齐和语义融合来减少跨模态冲突。&lt;h4&gt;主要发现&lt;/h4&gt;在WaterScenes数据集上的大量实验表明，WS-DETR达到了最先进的性能，即使在恶劣的天气和光照条件下也保持着其优越性。&lt;h4&gt;结论&lt;/h4&gt;WS-DETR模型为无人水面舰艇在复杂水域中的鲁棒对象检测提供了一种有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust object detection for Unmanned Surface Vehicles (USVs) in complex waterenvironments is essential for reliable navigation and operation. Specifically,water surface object detection faces challenges from blurred edges and diverseobject scales. Although vision-radar fusion offers a feasible solution,existing approaches suffer from cross-modal feature conflicts, which negativelyaffect model robustness. To address this problem, we propose a robustvision-radar fusion model WS-DETR. In particular, we first introduce aMulti-Scale Edge Information Integration (MSEII) module to enhance edgeperception and a Hierarchical Feature Aggregator (HiFA) to boost multi-scaleobject detection in the encoder. Then, we adopt self-moving pointrepresentations for continuous convolution and residual connection toefficiently extract irregular features under the scenarios of irregular pointcloud data. To further mitigate cross-modal conflicts, an Adaptive FeatureInteractive Fusion (AFIF) module is introduced to integrate visual and radarfeatures through geometric alignment and semantic fusion. Extensive experimentson the WaterScenes dataset demonstrate that WS-DETR achieves state-of-the-art(SOTA) performance, maintaining its superiority even under adverse weather andlighting conditions.</description>
      <author>example@mail.com (Huilin Yin, Pengyu Wang, Senmao Li, Jun Yan, Daniel Watzenig)</author>
      <guid isPermaLink="false">2504.07441v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>A Pointcloud Registration Framework for Relocalization in Subterranean Environments</title>
      <link>http://arxiv.org/abs/2504.07231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种利用点云注册的鲁棒、计算友好的重定位框架，用于在地下环境中重建机器人位置，以提高导航和任务执行的准确性。&lt;h4&gt;背景&lt;/h4&gt;在地下环境中，由于外部定位信息有限、光线条件差、表面不规则以及尘埃等因素，重定位面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种适用于地下矿井和隧道中自主机器人的重定位方法。&lt;h4&gt;方法&lt;/h4&gt;该方法使用先验点云图，通过Intrinsic Shape Signatures (ISS)选择特征点，利用Fast Point Feature Histogram (FPFH)算法创建描述符，并通过匹配这些描述符来获取点云之间的对应关系。然后，使用匹配点估计3D变换，初始化Normal Distribution Transform (NDT)注册。最后，使用迭代最近点（ICP）注册算法进一步优化变换结果。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在尘土干扰和目标与源之间有显著初始变换的复杂条件下，提高了注册精度。&lt;h4&gt;结论&lt;/h4&gt;通过模拟和真实世界矿井数据集的实验验证了该框架在提高重定位方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Relocalization, the process of re-establishing a robot's position within an environment, is crucial for ensuring accurate navigation and task execution when external positioning information, such as GPS, is unavailable or has been lost. Subterranean environments present significant challenges for relocalization due to limited external positioning information, poor lighting that affects camera localization, irregular and often non-distinct surfaces, and dust, which can introduce noise and occlusion in sensor data. In this work, we propose a robust, computationally friendly framework for relocalization through point cloud registration utilizing a prior point cloud map. The framework employs Intrinsic Shape Signatures (ISS) to select feature points in both the target and prior point clouds. The Fast Point Feature Histogram (FPFH) algorithm is utilized to create descriptors for these feature points, and matching these descriptors yields correspondences between the point clouds. A 3D transformation is estimated using the matched points, which initializes a Normal Distribution Transform (NDT) registration. The transformation result from NDT is further refined using the Iterative Closest Point (ICP) registration algorithm. This framework enhances registration accuracy even in challenging conditions, such as dust interference and significant initial transformations between the target and source, making it suitable for autonomous robots operating in underground mines and tunnels. This framework was validated with experiments in simulated and real-world mine datasets, demonstrating its potential for improving relocalization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Relocalization, the process of re-establishing a robot's position within anenvironment, is crucial for ensuring accurate navigation and task executionwhen external positioning information, such as GPS, is unavailable or has beenlost. Subterranean environments present significant challenges forrelocalization due to limited external positioning information, poor lightingthat affects camera localization, irregular and often non-distinct surfaces,and dust, which can introduce noise and occlusion in sensor data. In this work,we propose a robust, computationally friendly framework for relocalizationthrough point cloud registration utilizing a prior point cloud map. Theframework employs Intrinsic Shape Signatures (ISS) to select feature points inboth the target and prior point clouds. The Fast Point Feature Histogram (FPFH)algorithm is utilized to create descriptors for these feature points, andmatching these descriptors yields correspondences between the point clouds. A3D transformation is estimated using the matched points, which initializes aNormal Distribution Transform (NDT) registration. The transformation resultfrom NDT is further refined using the Iterative Closest Point (ICP)registration algorithm. This framework enhances registration accuracy even inchallenging conditions, such as dust interference and significant initialtransformations between the target and source, making it suitable forautonomous robots operating in underground mines and tunnels. This frameworkwas validated with experiments in simulated and real-world mine datasets,demonstrating its potential for improving relocalization.</description>
      <author>example@mail.com (David Akhihiero, Jason N. Gross)</author>
      <guid isPermaLink="false">2504.07231v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal Reference Learning for Fine-grained Text-to-Image Retrieval</title>
      <link>http://arxiv.org/abs/2504.07718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  TMM25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多模态参考学习的细粒度文本到图像检索方法，旨在通过学习更鲁棒的特征表示来提高检索精度。&lt;h4&gt;背景&lt;/h4&gt;现有的文本到图像检索方法通常假设训练图像能够被其文本描述准确描绘，但文本描述可能存在歧义，无法充分描述图像中的判别性视觉细节，导致学习到的表示不准确。&lt;h4&gt;目的&lt;/h4&gt;为了缓解文本歧义的影响，提出了一种多模态参考学习方法，以学习更鲁棒的特征表示。&lt;h4&gt;方法&lt;/h4&gt;首先，提出了一种多模态参考构建模块，用于聚合同一对象的全部视觉和文本细节，形成一个全面的多模态参考。接着，提出了一种参考引导的表示学习模块，使用多模态参考来学习更准确的视觉和文本表示。此外，还引入了一种基于参考的细化方法，利用对象参考计算基于参考的相似度，以细化初始检索结果。&lt;h4&gt;主要发现&lt;/h4&gt;在五个细粒度文本到图像检索数据集上进行了广泛的实验，结果表明，该方法在检索性能上优于现有方法。例如，在RSTPReid文本到人物图像检索数据集上，该方法实现了56.2%的Rank1准确率，超过了最近提出的CFine方法5.6个百分点。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在细粒度文本到图像检索任务中表现出色，能够有效提高检索精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TMM.2025.3543066&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-grained text-to-image retrieval aims to retrieve a fine-grained targetimage with a given text query. Existing methods typically assume that eachtraining image is accurately depicted by its textual descriptions. However,textual descriptions can be ambiguous and fail to depict discriminative visualdetails in images, leading to inaccurate representation learning. To alleviatethe effects of text ambiguity, we propose a Multi-Modal Reference learningframework to learn robust representations. We first propose a multi-modalreference construction module to aggregate all visual and textual details ofthe same object into a comprehensive multi-modal reference. The multi-modalreference hence facilitates the subsequent representation learning andretrieval similarity computation. Specifically, a reference-guidedrepresentation learning module is proposed to use multi-modal references tolearn more accurate visual and textual representations. Additionally, weintroduce a reference-based refinement method that employs the objectreferences to compute a reference-based similarity that refines the initialretrieval results. Extensive experiments are conducted on five fine-grainedtext-to-image retrieval datasets for different text-to-image retrieval tasks.The proposed method has achieved superior performance over state-of-the-artmethods. For instance, on the text-to-person image retrieval dataset RSTPReid,our method achieves the Rank1 accuracy of 56.2\%, surpassing the recent CFineby 5.6\%.</description>
      <author>example@mail.com (Zehong Ma, Hao Chen, Wei Zeng, Limin Su, Shiliang Zhang)</author>
      <guid isPermaLink="false">2504.07718v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Trading Graph Neural Network</title>
      <link>http://arxiv.org/abs/2504.07923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的算法——交易图神经网络（TGNN），该算法能够结构性地估计资产特征、交易商特征和关系特征对交易网络中资产价格的影响。&lt;h4&gt;背景&lt;/h4&gt;将传统的模拟方法与最近机器学习技术——图神经网络（GNN）相结合。&lt;h4&gt;目的&lt;/h4&gt;提高预测准确性，并在具有任何结构的网络中应用，允许交易者和资产之间的异质性。&lt;h4&gt;方法&lt;/h4&gt;TGNN算法结合了模拟方法（SMM）和图神经网络（GNN）的优点。&lt;h4&gt;主要发现&lt;/h4&gt;TGNN在预测准确性上优于现有的使用网络中心度测量的降阶方法。&lt;h4&gt;结论&lt;/h4&gt;TGNN算法在处理具有不同结构的网络时表现出色，能够处理交易者和资产之间的异质性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new algorithm -- Trading Graph Neural Network (TGNN) that can structurally estimate the impact of asset features, dealer features and relationship features on asset prices in trading networks. It combines the strength of the traditional simulated method of moments (SMM) and recent machine learning techniques -- Graph Neural Network (GNN). It outperforms existing reduced-form methods with network centrality measures in prediction accuracy. The method can be used on networks with any structure, allowing for heterogeneity among both traders and assets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a new algorithm -- Trading Graph Neural Network (TGNN)that can structurally estimate the impact of asset features, dealer featuresand relationship features on asset prices in trading networks. It combines thestrength of the traditional simulated method of moments (SMM) and recentmachine learning techniques -- Graph Neural Network (GNN). It outperformsexisting reduced-form methods with network centrality measures in predictionaccuracy. The method can be used on networks with any structure, allowing forheterogeneity among both traders and assets.</description>
      <author>example@mail.com (Xian Wu)</author>
      <guid isPermaLink="false">2504.07923v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>We Are All Creators: Generative AI, Collective Knowledge, and the Path Towards Human-AI Synergy</title>
      <link>http://arxiv.org/abs/2504.07936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了生成式人工智能对传统人类独特性的挑战，特别是在创造力方面，并提出了人工智能作为一种新型智能和创造力的观点。&lt;h4&gt;背景&lt;/h4&gt;生成式人工智能通过神经网络基础模型展现出强大的内容生成能力，引发了关于作者权、版权和智能本身的激烈辩论。&lt;h4&gt;目的&lt;/h4&gt;文章旨在分析生成式人工智能的本质和影响，并探讨其与人类创造力的关系。&lt;h4&gt;方法&lt;/h4&gt;通过比较人工神经网络和生物神经网络的差异，分析了人工智能的学习过程，并从知识的角度探讨了人工智能创作的伦理问题。&lt;h4&gt;主要发现&lt;/h4&gt;生成式人工智能通过数学模式合成进行内容生成，而非生物理解或文字复制。人工智能的学习主要是从大量数据中提取统计模式。&lt;h4&gt;结论&lt;/h4&gt;文章建议人类与人工智能协同合作，利用人工智能作为辅助工具，以实现创新、民主化创造性表达和解决复杂挑战。同时，应关注人工智能工具的公平获取，以防止社会分化的加剧。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成式人工智能对传统的独特人类观念，特别是在创造力方面，提出了深刻的挑战。受基于神经网络的底层模型驱动，这些系统展示了惊人的内容生成能力，引发了关于作者权、版权和智能本身的激烈辩论。本文认为，生成式人工智能代表了一种新型的智能和创造力，它通过数学模式合成而不是生物理解或文字复制来运作。人工神经网络与生物神经网络之间的基本差异揭示了人工智能的学习主要是从大量数据中提取统计模式，这些模式是人类知识集体智慧的结晶。这种观点复杂化了版权盗窃的叙述，并突出了将人工智能输出归因于个人来源的实际挑战。我们主张追求人类与人工智能的协同合作，而不是追求可能徒劳的法律限制。通过将生成式人工智能视为人类直觉、情境和伦理判断的补充工具，社会可以解锁前所未有的创新，民主化创造性表达，并解决复杂挑战。这种基于对人工智能能力和局限性的现实理解的协作方法，提供了最有前景的前进道路。此外，将这些模型视为集体人类知识的产物，也提出了关于可访问性的伦理问题，确保这些工具的公平获取可以防止社会分歧的扩大，并充分利用它们的集体利益。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative AI presents a profound challenge to traditional notions of humanuniqueness, particularly in creativity. Fueled by neural network basedfoundation models, these systems demonstrate remarkable content generationcapabilities, sparking intense debates about authorship, copyright, andintelligence itself. This paper argues that generative AI represents analternative form of intelligence and creativity, operating through mathematicalpattern synthesis rather than biological understanding or verbatim replication.The fundamental differences between artificial and biological neural networksreveal AI learning as primarily statistical pattern extraction from vastdatasets crystallized forms of collective human knowledge scraped from theinternet. This perspective complicates copyright theft narratives andhighlights practical challenges in attributing AI outputs to individualsources. Rather than pursuing potentially futile legal restrictions, weadvocate for human AI synergy. By embracing generative AI as a complementarytool alongside human intuition, context, and ethical judgment, society canunlock unprecedented innovation, democratize creative expression, and addresscomplex challenges. This collaborative approach, grounded in realisticunderstanding of AIs capabilities and limitations, offers the most promisingpath forward. Additionally, recognizing these models as products of collectivehuman knowledge raises ethical questions about accessibility ensuring equitableaccess to these tools could prevent widening societal divides and leveragetheir full potential for collective benefit.</description>
      <author>example@mail.com (Jordi Linares-Pellicer, Juan Izquierdo-Domenech, Isabel Ferri-Molla, Carlos Aliaga-Torro)</author>
      <guid isPermaLink="false">2504.07936v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>DGOcc: Depth-aware Global Query-based Network for Monocular 3D Occupancy Prediction</title>
      <link>http://arxiv.org/abs/2504.07524v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DGOcc的深度感知全局查询网络，用于单目3D占用预测，以解决从2D图像中预测大规模室外场景的3D占用问题。&lt;h4&gt;背景&lt;/h4&gt;单目3D占用预测在3D场景理解中扮演着重要角色，但其从2D图像预测大场景3D占用的过程既不明确又资源密集。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的方法来预测单目图像中3D场景的占用和语义。&lt;h4&gt;方法&lt;/h4&gt;DGOcc网络首先利用先前的深度图提取深度上下文特征，以提供占用网络的明确几何信息。然后，提出一个全局查询模块（GQ）来充分利用深度上下文特征。此外，还设计了一种分层监督策略（HSS），以避免将高维3D体素特征上采样到全分辨率，从而降低GPU内存利用率和时间成本。&lt;h4&gt;主要发现&lt;/h4&gt;在SemanticKITTI和SSCBench-KITTI-360数据集上进行的实验表明，该方法在单目语义占用预测方面取得了最佳性能，同时减少了GPU和时间开销。&lt;h4&gt;结论&lt;/h4&gt;DGOcc网络为单目3D占用预测提供了一种高效且性能优越的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D occupancy prediction, aiming to predict the occupancy andsemantics within interesting regions of 3D scenes from only 2D images, hasgarnered increasing attention recently for its vital role in 3D sceneunderstanding. Predicting the 3D occupancy of large-scale outdoor scenes from2D images is ill-posed and resource-intensive. In this paper, we present\textbf{DGOcc}, a \textbf{D}epth-aware \textbf{G}lobal query-based network formonocular 3D \textbf{Occ}upancy prediction. We first explore prior depth mapsto extract depth context features that provide explicit geometric informationfor the occupancy network. Then, in order to fully exploit the depth contextfeatures, we propose a Global Query-based (GQ) Module. The cooperation ofattention mechanisms and scale-aware operations facilitates the featureinteraction between images and 3D voxels. Moreover, a Hierarchical SupervisionStrategy (HSS) is designed to avoid upsampling the high-dimension 3D voxelfeatures to full resolution, which mitigates GPU memory utilization and timecost. Extensive experiments on SemanticKITTI and SSCBench-KITTI-360 datasetsdemonstrate that the proposed method achieves the best performance on monocularsemantic occupancy prediction while reducing GPU and time overhead.</description>
      <author>example@mail.com (Xu Zhao, Pengju Zhang, Bo Liu, Yihong Wu)</author>
      <guid isPermaLink="false">2504.07524v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>SF2T: Self-supervised Fragment Finetuning of Video-LLMs for Fine-Grained Understanding</title>
      <link>http://arxiv.org/abs/2504.07745v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Video-LLMs在视频理解方面的进展，并提出了Self-Supervised Fragment Fine-Tuning（SF$^2$T）和FineVidBench数据集，以提升Video-LLMs的细粒度视频理解能力。&lt;h4&gt;背景&lt;/h4&gt;Video-LLMs在视频整体描述方面表现出色，但在细粒度理解方面，如视觉动态和视频细节查询上存在困难。&lt;h4&gt;目的&lt;/h4&gt;针对Video-LLMs的不足，提出新的方法来提升其细粒度视频理解能力。&lt;h4&gt;方法&lt;/h4&gt;1. 提出Self-Supervised Fragment Fine-Tuning（SF$^2$T），该方法利用视频的内在特性进行训练，同时提高Video-LLMs的细粒度理解能力，并减少对人工标注的依赖。2. 构建了FineVidBench数据集，用于严格评估Video-LLMs在场景和片段层面的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SF$^2$T方法能够提升Video-LLMs捕捉和解释时空细节的能力。&lt;h4&gt;结论&lt;/h4&gt;SF$^2$T和FineVidBench数据集为提升Video-LLMs的细粒度视频理解能力提供了有效的方法和工具。&lt;h4&gt;翻译&lt;/h4&gt;Video-based Large Language Models (Video-LLMs) have witnessed substantial advancements in recent years, propelled by the advancement in multi-modal LLMs. Although these models have demonstrated proficiency in providing the overall description of videos, they struggle with fine-grained understanding, particularly in aspects such as visual dynamics and video details inquiries. To tackle these shortcomings, we find that fine-tuning Video-LLMs on self-supervised fragment tasks, greatly improve their fine-grained video understanding abilities. Hence we propose two key contributions: (1) Self-Supervised Fragment Fine-Tuning (SF$^2$T), a novel effortless fine-tuning method, employs the rich inherent characteristics of videos for training, while unlocking more fine-grained understanding ability of Video-LLMs. Moreover, it relieves researchers from labor-intensive annotations and smartly circumvents the limitations of natural language, which often fails to capture the complex spatiotemporal variations in videos; (2) A novel benchmark dataset, namely FineVidBench, for rigorously assessing Video-LLMs' performance at both the scene and fragment levels, offering a comprehensive evaluation of their capabilities. We assessed multiple models and validated the effectiveness of SF$^2$T on them. Experimental results reveal that our approach improves their ability to capture and interpret spatiotemporal details.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video-based Large Language Models (Video-LLMs) have witnessed substantialadvancements in recent years, propelled by the advancement in multi-modal LLMs.Although these models have demonstrated proficiency in providing the overalldescription of videos, they struggle with fine-grained understanding,particularly in aspects such as visual dynamics and video details inquiries. Totackle these shortcomings, we find that fine-tuning Video-LLMs onself-supervised fragment tasks, greatly improve their fine-grained videounderstanding abilities. Hence we propose two key contributions:(1)Self-Supervised Fragment Fine-Tuning (SF$^2$T), a novel effortless fine-tuningmethod, employs the rich inherent characteristics of videos for training, whileunlocking more fine-grained understanding ability of Video-LLMs. Moreover, itrelieves researchers from labor-intensive annotations and smartly circumventsthe limitations of natural language, which often fails to capture the complexspatiotemporal variations in videos; (2) A novel benchmark dataset, namelyFineVidBench, for rigorously assessing Video-LLMs' performance at both thescene and fragment levels, offering a comprehensive evaluation of theircapabilities. We assessed multiple models and validated the effectiveness ofSF$^2$T on them. Experimental results reveal that our approach improves theirability to capture and interpret spatiotemporal details.</description>
      <author>example@mail.com (Yangliu Hu, Zikai Song, Na Feng, Yawei Luo, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang)</author>
      <guid isPermaLink="false">2504.07745v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Merging Embedded Topics with Optimal Transport for Online Topic Modeling on Data Streams</title>
      <link>http://arxiv.org/abs/2504.07711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为StreamETM的在线主题建模新方法，用于处理文本数据流。&lt;h4&gt;背景&lt;/h4&gt;随着社交媒体的快速发展，每天产生的文本数据量巨大，需要在线主题建模方法来管理这些持续流入的数据流。&lt;h4&gt;目的&lt;/h4&gt;介绍StreamETM方法，该方法基于嵌入式主题模型（ETM）并通过不平衡最优传输合并连续的文档批次模型，同时采用在线变化点检测算法来识别主题随时间的变化。&lt;h4&gt;方法&lt;/h4&gt;StreamETM方法利用不平衡最优传输合并模型，并采用在线变化点检测算法来处理数据流。&lt;h4&gt;主要发现&lt;/h4&gt;StreamETM在模拟和真实世界数据上的数值实验中表现优于竞争对手。&lt;h4&gt;结论&lt;/h4&gt;StreamETM是一种有效的在线主题建模方法，能够处理数据流并识别文本流中的重大变化。&lt;h4&gt;翻译&lt;/h4&gt;摘要：主题建模是无监督学习的关键组成部分，用于在文本数据集中识别主题。社交媒体的快速增长每天产生大量文本数据，使得在线主题建模方法对于管理这些随时间持续到达的数据流至关重要。本文介绍了一种名为StreamETM的在线主题建模新方法。该方法基于嵌入式主题模型（ETM）通过不平衡最优传输合并连续的文档批次模型。此外，还采用了一种在线变化点检测算法来识别主题随时间的变化，从而能够识别文本流动态中的重大变化。在模拟和真实世界数据上的数值实验表明，StreamETM优于竞争对手。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Topic modeling is a key component in unsupervised learning, employed toidentify topics within a corpus of textual data. The rapid growth of socialmedia generates an ever-growing volume of textual data daily, making onlinetopic modeling methods essential for managing these data streams thatcontinuously arrive over time. This paper introduces a novel approach to onlinetopic modeling named StreamETM. This approach builds on the Embedded TopicModel (ETM) to handle data streams by merging models learned on consecutivepartial document batches using unbalanced optimal transport. Additionally, anonline change point detection algorithm is employed to identify shifts intopics over time, enabling the identification of significant changes in thedynamics of text streams. Numerical experiments on simulated and real-worlddata show StreamETM outperforming competitors.</description>
      <author>example@mail.com (Federica Granese, Benjamin Navet, Serena Villata, Charles Bouveyron)</author>
      <guid isPermaLink="false">2504.07711v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Novel Diffusion Models for Multimodal 3D Hand Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2504.07375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MMTwin的新型扩散模型，用于多模态3D手部轨迹预测，旨在解决现有方法在处理多模态信息、手部运动与头部摄像机运动协同预测等方面的不足。&lt;h4&gt;背景&lt;/h4&gt;现有的手部轨迹预测方法主要针对2D自视角视频输入，缺乏对多模态环境信息的感知，且未考虑手部运动与头部摄像机运动的协同性。&lt;h4&gt;目的&lt;/h4&gt;提出MMTwin模型，旨在提高3D手部轨迹预测的性能，并使其能够处理多模态信息，同时预测手部轨迹和头部摄像机运动。&lt;h4&gt;方法&lt;/h4&gt;MMTwin模型能够整合2D RGB图像、3D点云、过去的手部轨迹点和文本提示等多模态信息作为输入。模型包含两个潜在的扩散模型，即头部摄像机运动扩散和手部轨迹预测扩散，用于同时预测头部摄像机运动和未来手部轨迹。此外，还提出了一种新的混合Mamba-Transformer模块作为手部轨迹预测扩散的降噪模型，以更好地融合多模态特征。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公开数据集和自录数据上的实验结果表明，MMTwin模型相比现有基准方法，能够预测更合理的手部轨迹，并且具有良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;MMTwin模型在3D手部轨迹预测方面取得了显著成果，并为未来研究提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预测手部运动对于理解人类意图和建立人类运动与机器人操作之间的动作空间至关重要。现有的手部轨迹预测（HTP）方法在3D空间中基于过去的自视角观察预测未来的手部路径点。然而，这些模型仅设计用于处理2D自视角视频输入。缺乏从2D和3D观察中感知多模态环境信息，阻碍了3D HTP性能的进一步改进。此外，这些模型忽略了手部运动与头部摄像机运动的协同性，要么单独预测手部轨迹，要么仅从过去帧中编码头部摄像机运动。为了解决这些限制，我们提出了用于多模态3D手部轨迹预测的新型扩散模型（MMTwin）。MMTwin被设计为吸收包括2D RGB图像、3D点云、过去的手部路径点和文本提示在内的多模态信息作为输入。此外，将两个潜在的扩散模型，即头部摄像机运动扩散和手部轨迹预测扩散作为双胞胎整合到MMTwin中，以同时预测头部摄像机运动和未来手部轨迹。我们提出了一种新的混合Mamba-Transformer模块作为手部轨迹预测扩散的降噪模型，以更好地融合多模态特征。在三个公开数据集和我们的自录数据上的实验结果表明，我们提出的MMTwin与最先进的基准相比，可以预测合理的手部轨迹，并且具有良好的泛化能力。代码和预训练模型将在https://github.com/IRMVLab/MMTwin发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting hand motion is critical for understanding human intentions andbridging the action space between human movements and robot manipulations.Existing hand trajectory prediction (HTP) methods forecast the future handwaypoints in 3D space conditioned on past egocentric observations. However,such models are only designed to accommodate 2D egocentric video inputs. Thereis a lack of awareness of multimodal environmental information from both 2D and3D observations, hindering the further improvement of 3D HTP performance. Inaddition, these models overlook the synergy between hand movements and headsetcamera egomotion, either predicting hand trajectories in isolation or encodingegomotion only from past frames. To address these limitations, we propose noveldiffusion models (MMTwin) for multimodal 3D hand trajectory prediction. MMTwinis designed to absorb multimodal information as input encompassing 2D RGBimages, 3D point clouds, past hand waypoints, and text prompt. Besides, twolatent diffusion models, the egomotion diffusion and the HTP diffusion astwins, are integrated into MMTwin to predict camera egomotion and future handtrajectories concurrently. We propose a novel hybrid Mamba-Transformer moduleas the denoising model of the HTP diffusion to better fuse multimodal features.The experimental results on three publicly available datasets and ourself-recorded data demonstrate that our proposed MMTwin can predict plausiblefuture 3D hand trajectories compared to the state-of-the-art baselines, andgeneralizes well to unseen environments. The code and pretrained models will bereleased at https://github.com/IRMVLab/MMTwin.</description>
      <author>example@mail.com (Junyi Ma, Wentao Bao, Jingyi Xu, Guanzhong Sun, Xieyuanli Chen, Hesheng Wang)</author>
      <guid isPermaLink="false">2504.07375v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Image Embeddings for E-Commerce: Evaluating Off-the Shelf Foundation Models, Fine-Tuning Strategies and Practical Trade-offs</title>
      <link>http://arxiv.org/abs/2504.07567v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at Future Technologies Conference (FTC 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究对电子商务中用于分类和检索的基础模型图像嵌入进行了基准测试，评估其在现实世界应用中的适用性。&lt;h4&gt;背景&lt;/h4&gt;研究涵盖了通过监督学习、自监督学习和文本-图像对比学习训练的预训练卷积和转换模型嵌入。&lt;h4&gt;目的&lt;/h4&gt;评估全微调和迁移学习（top-tuning）在六个不同的电子商务数据集（时尚、消费品、汽车、食品和零售）上的表现。&lt;h4&gt;方法&lt;/h4&gt;评估了全微调、迁移学习（top-tuning）和跨调优在多个数据集上的效果，并分析了不同类型嵌入的表现。&lt;h4&gt;主要发现&lt;/h4&gt;全微调表现一致良好；文本-图像和自监督嵌入可以以较少的训练量匹配其性能；监督嵌入在架构上保持稳定，而SSL和对比嵌入则因top-tuning而显著改善；top-tuning成为全微调的高效替代方案，降低了计算成本；跨调优的影响取决于数据集特征。&lt;h4&gt;结论&lt;/h4&gt;研究结果为嵌入选择和微调策略提供了实用性指导，平衡了效率和性能。&lt;h4&gt;翻译&lt;/h4&gt;本研究对电子商务中用于分类和检索的基础模型图像嵌入进行了基准测试，评估其在现实世界应用中的适用性。研究涵盖了通过监督学习、自监督学习和文本-图像对比学习训练的预训练卷积和转换模型嵌入。评估了全微调和迁移学习（top-tuning）在六个不同的电子商务数据集（时尚、消费品、汽车、食品和零售）上的表现。评估了全微调、迁移学习（top-tuning）和跨调优在多个数据集上的效果，并分析了不同类型嵌入的表现。全微调表现一致良好；文本-图像和自监督嵌入可以以较少的训练量匹配其性能；监督嵌入在架构上保持稳定，而SSL和对比嵌入则因top-tuning而显著改善；top-tuning成为全微调的高效替代方案，降低了计算成本；跨调优的影响取决于数据集特征。研究结果为嵌入选择和微调策略提供了实用性指导，平衡了效率和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We benchmark foundation models image embeddings for classification andretrieval in e-Commerce, evaluating their suitability for real-worldapplications. Our study spans embeddings from pre-trained convolutional andtransformer models trained via supervised, self-supervised, and text-imagecontrastive learning. We assess full fine-tuning and transfer learning(top-tuning) on six diverse e-Commerce datasets: fashion, consumer goods, cars,food, and retail. Results show full fine-tuning consistently performs well,while text-image and self-supervised embeddings can match its performance withless training. While supervised embeddings remain stable across architectures,SSL and contrastive embeddings vary significantly, often benefiting fromtop-tuning. Top-tuning emerges as an efficient alternative to full fine-tuning,reducing computational costs. We also explore cross-tuning, noting its impactdepends on dataset characteristics. Our findings offer practical guidelines forembedding selection and fine-tuning strategies, balancing efficiency andperformance.</description>
      <author>example@mail.com (Urszula Czerwinska, Cenk Bircanoglu, Jeremy Chamoux)</author>
      <guid isPermaLink="false">2504.07567v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Prediction of Usage Probabilities of Shopping-Mall Corridors Using Heterogeneous Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.07645v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, working manuscript with partial results&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的方法，用于预测购物中心走廊的使用概率。&lt;h4&gt;背景&lt;/h4&gt;通过分析购物中心楼层平面图，创建了走廊、商店和入口的向量层，从而构建了异构图网络。&lt;h4&gt;目的&lt;/h4&gt;该方法旨在通过商店特征和连接它们的图结构来预测使用概率。&lt;h4&gt;方法&lt;/h4&gt;使用商店的面积和类别等特征，以及通过走廊路径连接的商店、走廊交叉口和入口的图来预测使用概率。通过多层感知器（MLP）对每条边进行概率预测。&lt;h4&gt;主要发现&lt;/h4&gt;该方法适用于从实地调查或行人检测传感器获得的数据集进行训练，并通过概率模型生成合成学习数据集。&lt;h4&gt;结论&lt;/h4&gt;提出了考虑购物中心特定识别特征的图级特征，以提高模型性能。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种基于图神经网络（GNN）的方法，用于预测购物中心走廊的使用概率。通过分析购物中心楼层平面图，创建了走廊、商店和入口的向量层，从而构建了异构图网络。该方法旨在通过商店特征和连接它们的图结构来预测使用概率。使用商店的面积和类别等特征，以及通过走廊路径连接的商店、走廊交叉口和入口的图来预测使用概率。通过多层感知器（MLP）对每条边进行概率预测。该方法适用于从实地调查或行人检测传感器获得的数据集进行训练，并通过概率模型生成合成学习数据集。提出了考虑购物中心特定识别特征的图级特征，以提高模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a method based on graph neural network (GNN) for prediction ofprobabilities of usage of shopping-mall corridors. The heterogeneous graphnetwork of shops and corridor paths are obtained from floorplans of the mallsby creating vector layers for corridors, shops and entrances. These aresubsequently assimilated into nodes and edges of graphs. The prediction of theusage probability is based on the shop features, namely, the area and usagecategories they fall into, and on the graph connecting these shops, corridorjunctions and entrances by corridor paths. Though the presented method isapplicable for training on datasets obtained from a field survey or frompedestrian-detecting sensors, the target data of the supervised deep-learningwork flow in this work are obtained from a probability method. We also includea context-specific representation learning of latent features. Theusage-probability prediction is made on each edge, which is a connection by asection of corridor path between the adjacent nodes representing the shops orcorridor points. To create a feature for each edge, the hidden-layer featurevectors acquired in the message-passing GNN layers at the nodes of each edgeare averaged and concatenated with the vector obtained by their multiplication.These edge-features are then passed to multilayer perceptrons (MLP) to make thefinal prediction of usage probability on each edge. The samples of syntheticlearning dataset for each shopping mall are obtained by changing the shops'usage and area categories, and by subsequently feeding the graph into theprobability model.  When including different shopping malls in a single dataset, we also proposeto consider graph-level features to inform the model with specific identifyingfeatures of each mall.</description>
      <author>example@mail.com (Malik M Barakathullah, Immanuel Koh)</author>
      <guid isPermaLink="false">2504.07645v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing Equivariance: Modeling Turbulence with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.07741v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的湍流建模新方法，该方法将纳维-斯托克斯方程的离散旋转、反射和平移对称性嵌入到模型架构中，并推导出合适的不变输入和输出空间，使得GNN模型能够无缝嵌入到大涡模拟（LES）框架中，以获得保持对称性的模拟设置。&lt;h4&gt;背景&lt;/h4&gt;湍流建模在大型涡模拟（LES）中是一个挑战，需要考虑纳维-斯托克斯方程的对称性。&lt;h4&gt;目的&lt;/h4&gt;研究GNN在LES湍流建模中的应用，并验证其有效性和准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法基于图神经网络，并利用强化学习（RL）进行模型训练，确保模型与LES公式的离散化一致。&lt;h4&gt;主要发现&lt;/h4&gt;对于均匀各向同性湍流（HIT）和湍流通道流，GNN模型成功学习并恢复了湍流统计量和雷诺应力。在HIT案例中，基于GNN的LES方案在实际模拟中恢复了旋转和反射等变，同时稳定性和精度与未能遵守这些性质的对称性保护机器学习模型相当。GNN模型在湍流通道流中表现良好，学习到了近壁面和外部区域的区域建模策略。&lt;h4&gt;结论&lt;/h4&gt;该方法证明了GNN在湍流建模中的潜力，特别是在LES和RL的背景下。&lt;h4&gt;翻译&lt;/h4&gt;本研究提出了一种基于图神经网络（GNN）的湍流建模新方法，该方法将纳维-斯托克斯方程的离散旋转、反射和平移对称性嵌入到模型架构中。此外，推导出合适的不变输入和输出空间，使得GNN模型能够无缝嵌入到大涡模拟（LES）框架中，以获得保持对称性的模拟设置。该方法对两个典型测试案例——均匀各向同性湍流（HIT）和湍流通道流进行了研究。对于这两个案例，GNN模型都成功地通过强化学习（RL）在实际模拟中进行了训练，以确保模型与底层LES公式的离散化一致。对于HIT案例，基于GNN的LES方案在实际模拟中恢复了旋转和反射等变，精确到机器精度。同时，稳定性和精度与未能遵守这些性质的对称性保护的机器学习模型相当。相同的建模策略在湍流通道流中表现良好，GNN模型成功地学习到了更复杂的流动物理，并能够恢复湍流统计量和雷诺应力。这表明，该方法具有将区域建模策略应用于近壁面和外部区域的独特行为。因此，该方法证明了GNN在湍流建模中的潜力，特别是在大涡模拟（LES）和强化学习（RL）的背景下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes a novel methodology for turbulence modeling in Large EddySimulation (LES) based on Graph Neural Networks (GNNs), which embeds thediscrete rotational, reflectional and translational symmetries of theNavier-Stokes equations into the model architecture. In addition, suitableinvariant input and output spaces are derived that allow the GNN models to beembedded seamlessly into the LES framework to obtain a symmetry-preservingsimulation setup. The suitability of the proposed approach is investigated fortwo canonical test cases: Homogeneous Isotropic Turbulence (HIT) and turbulentchannel flow. For both cases, GNN models are trained successfully in actualsimulations using Reinforcement Learning (RL) to ensure that the models areconsistent with the underlying LES formulation and discretization. It isdemonstrated for the HIT case that the resulting GNN-based LES scheme recoversrotational and reflectional equivariance up to machine precision in actualsimulations. At the same time, the stability and accuracy remain on par withnon-symmetry-preserving machine learning models that fail to obey theseproperties. The same modeling strategy translates well to turbulent channelflow, where the GNN model successfully learns the more complex flow physics andis able to recover the turbulent statistics and Reynolds stresses. It is shownthat the GNN model learns a zonal modeling strategy with distinct behaviors inthe near-wall and outer regions. The proposed approach thus demonstrates thepotential of GNNs for turbulence modeling, especially in the context of LES andRL.</description>
      <author>example@mail.com (Marius Kurz, Andrea Beck, Benjamin Sanderse)</author>
      <guid isPermaLink="false">2504.07741v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Fast Adaptation with Behavioral Foundation Models</title>
      <link>http://arxiv.org/abs/2504.07896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种快速适应策略，以提高无监督零样本强化学习（RL）在行为基础模型（BFM）中的零样本性能，通过在线与环境的交互，在不降低性能的情况下提升模型在下游任务上的表现。&lt;h4&gt;背景&lt;/h4&gt;无监督零样本RL作为一种强大的预训练BFM的方法，允许代理通过奖励函数在零样本方式下解决各种下游任务，但零样本策略由于训练过程中的错误而常常不是最优的。&lt;h4&gt;目的&lt;/h4&gt;设计快速适应策略，在不影响性能的情况下提高BFM的零样本性能。&lt;h4&gt;方法&lt;/h4&gt;提出演员-评论家（actor-critic）和演员-only（actor-only）快速适应策略，在预训练BFM的低维任务嵌入空间中搜索，快速提高其零样本策略在下游任务上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;现有的BFM学习到一组包含比其推理过程确定的策略更优的策略，这使得它们非常适合快速适应。&lt;h4&gt;结论&lt;/h4&gt;在多个导航和运动领域上评估了快速适应策略，结果表明它们在数十个回合内实现了10-40%的性能提升，优于现有基线。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised zero-shot reinforcement learning (RL) has emerged as a powerful paradigm for pretraining behavioral foundation models (BFMs), enabling agents to solve a wide range of downstream tasks specified via reward functions in a zero-shot fashion, i.e., without additional test-time learning or planning. This is achieved by learning self-supervised task embeddings alongside corresponding near-optimal behaviors and incorporating an inference procedure to directly retrieve the latent task embedding and associated policy for any given reward function. Despite promising results, zero-shot policies are often suboptimal due to errors induced by the unsupervised training process, the embedding, and the inference procedure. In this paper, we focus on devising fast adaptation strategies to improve the zero-shot performance of BFMs in a few steps of online interaction with the environment while avoiding any performance drop during the adaptation process. Notably, we demonstrate that existing BFMs learn a set of skills containing more performant policies than those identified by their inference procedure, making them well-suited for fast adaptation. Motivated by this observation, we propose both actor-critic and actor-only fast adaptation strategies that search in the low-dimensional task-embedding space of the pre-trained BFM to rapidly improve the performance of its zero-shot policies on any downstream task. Notably, our approach mitigates the initial 'unlearning' phase commonly observed when fine-tuning pre-trained RL models. We evaluate our fast adaptation strategies on top of four state-of-the-art zero-shot RL methods in multiple navigation and locomotion domains. Our results show that they achieve 10-40% improvement over their zero-shot performance in a few tens of episodes, outperforming existing baselines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised zero-shot reinforcement learning (RL) has emerged as a powerfulparadigm for pretraining behavioral foundation models (BFMs), enabling agentsto solve a wide range of downstream tasks specified via reward functions in azero-shot fashion, i.e., without additional test-time learning or planning.This is achieved by learning self-supervised task embeddings alongsidecorresponding near-optimal behaviors and incorporating an inference procedureto directly retrieve the latent task embedding and associated policy for anygiven reward function. Despite promising results, zero-shot policies are oftensuboptimal due to errors induced by the unsupervised training process, theembedding, and the inference procedure. In this paper, we focus on devisingfast adaptation strategies to improve the zero-shot performance of BFMs in afew steps of online interaction with the environment while avoiding anyperformance drop during the adaptation process. Notably, we demonstrate thatexisting BFMs learn a set of skills containing more performant policies thanthose identified by their inference procedure, making them well-suited for fastadaptation. Motivated by this observation, we propose both actor-critic andactor-only fast adaptation strategies that search in the low-dimensionaltask-embedding space of the pre-trained BFM to rapidly improve the performanceof its zero-shot policies on any downstream task. Notably, our approachmitigates the initial "unlearning" phase commonly observed when fine-tuningpre-trained RL models. We evaluate our fast adaptation strategies on top offour state-of-the-art zero-shot RL methods in multiple navigation andlocomotion domains. Our results show that they achieve 10-40% improvement overtheir zero-shot performance in a few tens of episodes, outperforming existingbaselines.</description>
      <author>example@mail.com (Harshit Sikchi, Andrea Tirinzoni, Ahmed Touati, Yingchen Xu, Anssi Kanervisto, Scott Niekum, Amy Zhang, Alessandro Lazaric, Matteo Pirotta)</author>
      <guid isPermaLink="false">2504.07896v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>On the Temporal Question-Answering Capabilities of Large Language Models Over Anonymized Data</title>
      <link>http://arxiv.org/abs/2504.07646v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 tables, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了大型语言模型（LLMs）在处理训练数据中未出现的时间推理任务中的应用，重点关注结构化和半结构化匿名数据。&lt;h4&gt;背景&lt;/h4&gt;LLMs在时间推理任务中的应用仍是一个待探索的领域。&lt;h4&gt;目的&lt;/h4&gt;研究如何使用LLMs处理时间推理任务，并开发一种直接的方法，同时比较和深入分析不同的方法。&lt;h4&gt;方法&lt;/h4&gt;开发了直接LLMs流程，比较了各种方法，并创建了名为RATA的数据集，该数据集包含半结构化匿名数据，用于评估LLMs的性能。使用了如思维树、自我反思和代码执行等SoTA技术。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，要实现可扩展和可靠的解决方案，仅仅使用独立的LLMs是不够的，强调了集成方法的需求。&lt;h4&gt;结论&lt;/h4&gt;提出了集成方法对于实现时间推理任务的可扩展和可靠解决方案的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The applicability of Large Language Models (LLMs) in temporal reasoning tasksover data that is not present during training is still a field that remains tobe explored. In this paper we work on this topic, focusing on structured andsemi-structured anonymized data. We not only develop a direct LLM pipeline, butalso compare various methodologies and conduct an in-depth analysis. Weidentified and examined seventeen common temporal reasoning tasks in naturallanguage, focusing on their algorithmic components. To assess LLM performance,we created the \textit{Reasoning and Answering Temporal Ability} dataset(RATA), featuring semi-structured anonymized data to ensure reliance onreasoning rather than on prior knowledge. We compared several methodologies,involving SoTA techniques such as Tree-of-Thought, self-reflexion and codeexecution, tuned specifically for this scenario. Our results suggest thatachieving scalable and reliable solutions requires more than just standaloneLLMs, highlighting the need for integrated approaches.</description>
      <author>example@mail.com (Alfredo Garrachón Ruiz, Tomás de la Rosa, Daniel Borrajo)</author>
      <guid isPermaLink="false">2504.07646v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability</title>
      <link>http://arxiv.org/abs/2504.07416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了RadZero，一种用于放射学视觉-语言对齐的新颖相似性基础跨注意力框架，具有零样本多任务能力，以解决现有方法在利用复杂放射学报告、依赖低分辨率图像和注意力机制可解释性有限等方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;多模态模型在放射学视觉-语言对齐方面取得了显著进展，但现有方法存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出RadZero，旨在解决现有方法在放射学视觉-语言对齐中的挑战。&lt;h4&gt;方法&lt;/h4&gt;RadZero利用大型语言模型从放射学报告中提取最小语义句子，采用多正对比学习策略有效捕捉图像与多个相关文本描述之间的关系，并使用预训练的视觉编码器与额外的可训练Transformer层进行高效的高分辨率图像处理。通过计算文本嵌入和局部图像块特征之间的相似性，实现零样本推理，并为分类提供相似性概率，以及为定位和分割提供像素级跨模态相似性图。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，RadZero在零样本分类、定位和分割方面优于现有方法，跨模态相似性图分析突出了其在提高视觉-语言对齐可解释性方面的潜力，定性评估也证明了其在开放词汇语义分割方面的能力。&lt;h4&gt;结论&lt;/h4&gt;RadZero在放射学视觉-语言对齐方面表现出色，有效提高了医学影像中的效率和可解释性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，多模态模型在放射学视觉-语言对齐方面取得了显著进展。然而，现有方法在有效利用复杂放射学报告进行学习、依赖低分辨率图像以及提供有限的注意力机制可解释性方面存在困难。为了解决这些挑战，我们引入了RadZero，这是一种新颖的基于相似性的跨注意力框架，用于放射学的视觉-语言对齐，具有零样本多任务能力。RadZero利用大型语言模型从放射学报告中提取最小语义句子，并采用多正对比学习策略有效捕捉图像与多个相关文本描述之间的关系。它还利用预训练的视觉编码器以及额外的可训练Transformer层，以实现高效的高分辨率图像处理。通过计算文本嵌入和局部图像块特征之间的相似性，RadZero实现了零样本推理，并为分类提供了相似性概率，以及为定位和分割提供了像素级跨模态相似性图。在公共胸部X光图基准测试上的实验结果表明，RadZero在零样本分类、定位和分割方面优于现有方法。此外，跨模态相似性图分析突出了其在提高视觉-语言对齐可解释性方面的潜力。此外，定性评估也证明了RadZero在开放词汇语义分割方面的能力，进一步验证了其在医学影像中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in multi-modal models have significantly improvedvision-language alignment in radiology. However, existing approaches struggleto effectively utilize complex radiology reports for learning, rely onlow-resolution images, and offer limited interpretability in attentionmechanisms. To address these challenges, we introduce RadZero, a novelsimilarity-based cross-attention framework for vision-language alignment inradiology with zero-shot multi-task capability. RadZero leverages largelanguage models to extract minimal semantic sentences from radiology reportsand employs a multi-positive contrastive learning strategy to effectivelycapture relationships between images and multiple relevant textualdescriptions. It also utilizes a pre-trained vision encoder with additionaltrainable Transformer layers, allowing efficient high-resolution imageprocessing. By computing similarity between text embeddings and local imagepatch features, RadZero enables zero-shot inference with similarity probabilityfor classification and pixel-level cross-modal similarity maps for groundingand segmentation. Experimental results on public chest radiograph benchmarksshow that RadZero outperforms state-of-the-art methods in zero-shotclassification, grounding, and segmentation. Furthermore, cross-modalsimilarity map analysis highlights its potential for improving explainabilityin vision-language alignment. Additionally, qualitative evaluation demonstratesRadZero's capability for open-vocabulary semantic segmentation, furthervalidating its effectiveness in medical imaging.</description>
      <author>example@mail.com (Jonggwon Park, Soobum Kim, Byungmu Yoon, Kyoyun Choi)</author>
      <guid isPermaLink="false">2504.07416v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>SAMJAM: Zero-Shot Video Scene Graph Generation for Egocentric Kitchen Videos</title>
      <link>http://arxiv.org/abs/2504.07867v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAMJAM的零样本流水线，用于生成视频场景图，以解决当前VidSGG模型在动态厨房环境中的稳定性问题。&lt;h4&gt;背景&lt;/h4&gt;视频场景图生成（VidSGG）是理解动态厨房环境的一个重要话题，但现有的VidSGG模型需要大量训练才能生成场景图。&lt;h4&gt;目的&lt;/h4&gt;提出SAMJAM以解决VLMs在VidSGG中的动态性问题，并提高场景图生成的稳定性。&lt;h4&gt;方法&lt;/h4&gt;SAMJAM结合了SAM2的时间跟踪和Gemini的语义理解，首先由Gemini生成帧级场景图，然后使用匹配算法将场景图中的每个对象与SAM2生成的或传播的掩码对应，以在动态环境中生成时间上一致的场景图。&lt;h4&gt;主要发现&lt;/h4&gt;SAMJAM在EPIC-KITCHENS和EPIC-KITCHENS-100数据集上的平均召回率上比Gemini高出8.33%。&lt;h4&gt;结论&lt;/h4&gt;SAMJAM能够有效提高视频场景图生成的稳定性，在动态环境中优于现有的模型。&lt;h4&gt;翻译&lt;/h4&gt;Video Scene Graph Generation (VidSGG) is an important topic in understanding dynamic kitchen environments. Current models for VidSGG require extensive training to produce scene graphs. Recently, Vision Language Models (VLM) and Vision Foundation Models (VFM) have demonstrated impressive zero-shot capabilities in a variety of tasks. However, VLMs like Gemini struggle with the dynamics for VidSGG, failing to maintain stable object identities across frames. To overcome this limitation, we propose SAMJAM, a zero-shot pipeline that combines SAM2's temporal tracking with Gemini's semantic understanding. SAM2 also improves upon Gemini's object grounding by producing more accurate bounding boxes. In our method, we first prompt Gemini to generate a frame-level scene graph. Then, we employ a matching algorithm to map each object in the scene graph with a SAM2-generated or SAM2-propagated mask, producing a temporally-consistent scene graph in dynamic environments. Finally, we repeat this process again in each of the following frames. We empirically demonstrate that SAMJAM outperforms Gemini by 8.33% in mean recall on the EPIC-KITCHENS and EPIC-KITCHENS-100 datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Scene Graph Generation (VidSGG) is an important topic in understandingdynamic kitchen environments. Current models for VidSGG require extensivetraining to produce scene graphs. Recently, Vision Language Models (VLM) andVision Foundation Models (VFM) have demonstrated impressive zero-shotcapabilities in a variety of tasks. However, VLMs like Gemini struggle with thedynamics for VidSGG, failing to maintain stable object identities acrossframes. To overcome this limitation, we propose SAMJAM, a zero-shot pipelinethat combines SAM2's temporal tracking with Gemini's semantic understanding.SAM2 also improves upon Gemini's object grounding by producing more accuratebounding boxes. In our method, we first prompt Gemini to generate a frame-levelscene graph. Then, we employ a matching algorithm to map each object in thescene graph with a SAM2-generated or SAM2-propagated mask, producing atemporally-consistent scene graph in dynamic environments. Finally, we repeatthis process again in each of the following frames. We empirically demonstratethat SAMJAM outperforms Gemini by 8.33% in mean recall on the EPIC-KITCHENS andEPIC-KITCHENS-100 datasets.</description>
      <author>example@mail.com (Joshua Li, Fernando Jose Pena Cantu, Emily Yu, Alexander Wong, Yuchen Cui, Yuhao Chen)</author>
      <guid isPermaLink="false">2504.07867v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>DWFS-Obfuscation: Dynamic Weighted Feature Selection for Robust Malware Familial Classification under Obfuscation</title>
      <link>http://arxiv.org/abs/2504.07590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于动态加权特征选择的方法，用于提高Android恶意软件检测的鲁棒性和准确性。&lt;h4&gt;背景&lt;/h4&gt;Android操作系统的开源特性使其成为攻击者的主要目标，基于学习的方法在Android恶意软件检测领域取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;针对传统基于静态特征的检测方法难以识别混淆的恶意代码，以及依赖动态分析的方法效率低的问题，提出新的检测方法。&lt;h4&gt;方法&lt;/h4&gt;提出动态加权特征选择方法，分析特征的重要性和稳定性，计算分数以筛选最稳健的特征，并结合程序的结构信息。使用图神经网络进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;在8,664个恶意软件样本和44,940个变种上测试，该方法在未混淆数据集上达到95.56%的F1分数，在混淆数据集上达到92.28%的F1分数。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效检测混淆的恶意软件，提高了检测系统的鲁棒性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to its open-source nature, the Android operating system has consistentlybeen a primary target for attackers. Learning-based methods have madesignificant progress in the field of Android malware detection. However,traditional detection methods based on static features struggle to identifyobfuscated malicious code, while methods relying on dynamic analysis sufferfrom low efficiency. To address this, we propose a dynamic weighted featureselection method that analyzes the importance and stability of features,calculates scores to filter out the most robust features, and combines theseselected features with the program's structural information. We then utilizegraph neural networks for classification, thereby improving the robustness andaccuracy of the detection system. We analyzed 8,664 malware samples from eightmalware families and tested a total of 44,940 malware variants generated usingseven obfuscation strategies. Experiments demonstrate that our proposed methodachieves an F1-score of 95.56% on the unobfuscated dataset and 92.28% on theobfuscated dataset, indicating that the model can effectively detect obfuscatedmalware.</description>
      <author>example@mail.com (Xingyuan Wei, Zijun Cheng, Ning Li, Qiujian Lv, Ziyang Yu, Degang Sun)</author>
      <guid isPermaLink="false">2504.07590v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>VideoExpert: Augmented LLM for Temporal-Sensitive Video Understanding</title>
      <link>http://arxiv.org/abs/2504.07519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为VideoExpert的通用多模态大语言模型，适用于多种时间敏感的视频任务，通过时空专家模块协同工作，提高了时间标记的准确性。&lt;h4&gt;背景&lt;/h4&gt;视频理解的核心挑战在于感知动态内容随时间的变化，而多模态大语言模型在处理时间敏感的视频任务时存在困难，需要生成时间戳来标记特定事件的发生。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理时间敏感视频任务的通用多模态大语言模型VideoExpert。&lt;h4&gt;方法&lt;/h4&gt;VideoExpert集成了两个并行模块：时间专家和空间专家。时间专家负责建模时间序列和进行时间定位，空间专家专注于内容细节分析和指令跟随。两个专家通过特殊标记协同工作，并保持独立的参数集。此外，引入了空间压缩模块来获取空间标记。&lt;h4&gt;主要发现&lt;/h4&gt;VideoExpert通过分离时间定位和内容生成，防止了文本模式偏差，提高了时间戳预测的准确性。空间压缩模块能够有效地过滤和压缩标记，为空间专家提供紧凑且信息丰富的输入。&lt;h4&gt;结论&lt;/h4&gt;实验表明，VideoExpert在有效性和多功能性方面表现出色，适用于多种时间敏感的视频任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频理解的核心挑战在于感知随时间变化的动态内容。然而，多模态大语言模型在处理需要生成时间戳标记特定事件发生的时间敏感视频任务时存在困难。现有的策略要求MLLM直接生成绝对或相对时间戳。我们观察到，这些MLLM在生成时间戳时往往更多地依赖于语言模式而不是视觉线索，这影响了它们的性能。为了解决这个问题，我们提出了VideoExpert，这是一个通用目的的MLLM，适用于多种时间敏感的视频任务。受专家概念的启发，VideoExpert集成了两个并行模块：时间专家和空间专家。时间专家负责建模时间序列和执行时间定位。它处理高帧率且压缩的标记以捕捉视频中的动态变化，并包括一个轻量级预测头来进行精确的事件定位。空间专家专注于内容细节分析和指令跟随。它处理专门设计的空间标记和语言输入，旨在生成与内容相关的响应。这两个专家通过一个特殊标记无缝协作，确保协调的时间定位和内容生成。值得注意的是，时间和空间专家保持独立的参数集。通过将时间定位从内容生成中卸载，VideoExpert防止了时间戳预测中的文本模式偏差。此外，我们引入了空间压缩模块以获取空间标记。该模块在保留关键信息的同时过滤和压缩补丁标记，为空间专家提供紧凑但信息丰富的输入。广泛的实验证明了VideoExpert的有效性和多功能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The core challenge in video understanding lies in perceiving dynamic contentchanges over time. However, multimodal large language models struggle withtemporal-sensitive video tasks, which requires generating timestamps to markthe occurrence of specific events. Existing strategies require MLLMs togenerate absolute or relative timestamps directly. We have observed that thoseMLLMs tend to rely more on language patterns than visual cues when generatingtimestamps, affecting their performance. To address this problem, we proposeVideoExpert, a general-purpose MLLM suitable for several temporal-sensitivevideo tasks. Inspired by the expert concept, VideoExpert integrates twoparallel modules: the Temporal Expert and the Spatial Expert. The TemporalExpert is responsible for modeling time sequences and performing temporalgrounding. It processes high-frame-rate yet compressed tokens to capturedynamic variations in videos and includes a lightweight prediction head forprecise event localization. The Spatial Expert focuses on content detailanalysis and instruction following. It handles specially designed spatialtokens and language input, aiming to generate content-related responses. Thesetwo experts collaborate seamlessly via a special token, ensuring coordinatedtemporal grounding and content generation. Notably, the Temporal and SpatialExperts maintain independent parameter sets. By offloading temporal groundingfrom content generation, VideoExpert prevents text pattern biases in timestamppredictions. Moreover, we introduce a Spatial Compress module to obtain spatialtokens. This module filters and compresses patch tokens while preserving keyinformation, delivering compact yet detail-rich input for the Spatial Expert.Extensive experiments demonstrate the effectiveness and versatility of theVideoExpert.</description>
      <author>example@mail.com (Henghao Zhao, Ge-Peng Ji, Rui Yan, Huan Xiong, Zechao Li)</author>
      <guid isPermaLink="false">2504.07519v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Conditional Data Synthesis Augmentation</title>
      <link>http://arxiv.org/abs/2504.07426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CoDSA的框架，用于通过生成模型合成高质量数据，以提升多模态数据（包括表格、文本和图像数据）在监督学习任务中的模型性能。&lt;h4&gt;背景&lt;/h4&gt;现实世界的数据集通常规模有限，在关键子群体中存在代表性不足，导致预测偏差和性能下降。&lt;h4&gt;目的&lt;/h4&gt;解决数据集规模有限和代表性不足的问题，提高模型在监督学习任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;CoDSA利用生成模型（如扩散模型）合成高保真数据，重点关注欠采样或高兴趣区域。通过迁移学习，CoDSA微调预训练的生成模型，以增强合成数据的真实性和增加稀疏区域的样本密度。&lt;h4&gt;主要发现&lt;/h4&gt;CoDSA能够通过合成样本和目标区域分配来量化统计精度改进，提供其有效性的正式保证。实验表明，CoDSA在监督和未监督设置中均优于非自适应增强策略和最先进的基线。&lt;h4&gt;结论&lt;/h4&gt;CoDSA是一种有效的数据增强方法，能够显著提高模型在多模态数据上的性能，特别是在监督学习任务中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable machine learning and statistical analysis rely on diverse,well-distributed training data. However, real-world datasets are often limitedin size and exhibit underrepresentation across key subpopulations, leading tobiased predictions and reduced performance, particularly in supervised taskssuch as classification. To address these challenges, we propose ConditionalData Synthesis Augmentation (CoDSA), a novel framework that leveragesgenerative models, such as diffusion models, to synthesize high-fidelity datafor improving model performance across multimodal domains including tabular,textual, and image data. CoDSA generates synthetic samples that faithfullycapture the conditional distributions of the original data, with a focus onunder-sampled or high-interest regions. Through transfer learning, CoDSAfine-tunes pre-trained generative models to enhance the realism of syntheticdata and increase sample density in sparse areas. This process preservesinter-modal relationships, mitigates data imbalance, improves domainadaptation, and boosts generalization. We also introduce a theoreticalframework that quantifies the statistical accuracy improvements enabled byCoDSA as a function of synthetic sample volume and targeted region allocation,providing formal guarantees of its effectiveness. Extensive experimentsdemonstrate that CoDSA consistently outperforms non-adaptive augmentationstrategies and state-of-the-art baselines in both supervised and unsupervisedsettings.</description>
      <author>example@mail.com (Xinyu Tian, Xiaotong Shen)</author>
      <guid isPermaLink="false">2504.07426v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging LLMs for Multimodal Retrieval-Augmented Radiology Report Generation via Key Phrase Extraction</title>
      <link>http://arxiv.org/abs/2504.07415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于检索增强的多模态放射学报告生成方法，旨在减轻放射科医生的工作负担，并通过利用多模态检索和大型语言模型（LLMs）来生成报告，同时减轻幻觉和降低计算需求。&lt;h4&gt;背景&lt;/h4&gt;放射学报告生成（RRG）有减轻放射科医生工作负担的潜力，但近年来大型语言模型（LLMs）在胸片（CXR）报告生成方面的应用，由于多模态语言模型（MLLMs）的资源密集特性，面临数据集庞大和计算成本高的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种检索增强的生成方法，以减轻放射学报告生成的计算需求，并提高报告的准确性。&lt;h4&gt;方法&lt;/h4&gt;方法利用LLMs提取关键短语，专注于关键诊断信息，并采用有效的训练策略，包括图像编码器结构搜索、向文本嵌入添加噪声和额外的训练目标。结合互补的预训练图像编码器，采用文本和语义图像嵌入之间的对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC-CXR数据集上评估，该方法在CheXbert指标上达到最先进的结果，在RadGraph F1指标上与MLLMs具有竞争力，且无需对LLM进行微调。该方法显示出在多视图RRG上的稳健泛化能力，适用于广泛的临床应用。&lt;h4&gt;结论&lt;/h4&gt;该方法为放射学报告生成提供了一种有效的解决方案，能够减少计算成本，同时提高报告的准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated radiology report generation (RRG) holds potential to reduceradiologists' workload, especially as recent advancements in large languagemodels (LLMs) enable the development of multimodal models for chest X-ray (CXR)report generation. However, multimodal LLMs (MLLMs) are resource-intensive,requiring vast datasets and substantial computational cost for training. Toaddress these challenges, we propose a retrieval-augmented generation approachthat leverages multimodal retrieval and LLMs to generate radiology reportswhile mitigating hallucinations and reducing computational demands. Our methoduses LLMs to extract key phrases from radiology reports, effectively focusingon essential diagnostic information. Through exploring effective trainingstrategies, including image encoder structure search, adding noise to textembeddings, and additional training objectives, we combine complementarypre-trained image encoders and adopt contrastive learning between text andsemantic image embeddings. We evaluate our approach on MIMIC-CXR dataset,achieving state-of-the-art results on CheXbert metrics and competitive RadGraphF1 metric alongside MLLMs, without requiring LLM fine-tuning. Our methoddemonstrates robust generalization for multi-view RRG, making it suitable forcomprehensive clinical applications.</description>
      <author>example@mail.com (Kyoyun Choi, Byungmu Yoon, Soobum Kim, Jonggwon Park)</author>
      <guid isPermaLink="false">2504.07415v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Exploring a Patch-Wise Approach for Privacy-Preserving Fake ID Detection</title>
      <link>http://arxiv.org/abs/2504.07761v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在数字化的世界中，验证身份证件真实性的挑战，特别是针对假身份证检测的局限性。提出了一种新型的隐私保护假身份证检测方法，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;随着数字化的普及，身份证件的真伪验证成为现实应用中的关键挑战，如数字银行、加密交易、租赁等。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服假身份证检测领域的隐私和性能之间的权衡问题。&lt;h4&gt;方法&lt;/h4&gt;研究提出了一种基于匿名化和不同补丁大小配置的隐私保护假身份证检测方法，同时考虑了如Vision Transformers和Foundation Models等先进方法。实验中使用了DLC-2021数据库，并发布了包含真实和假身份证片断的公共数据库。&lt;h4&gt;主要发现&lt;/h4&gt;在DLC-2021数据库上，该方法在补丁和身份证件层面上实现了13.91%和0%的等错误率，显示出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;研究提出的方法能够有效平衡隐私保护与性能，并为假身份证检测领域提供了新的思路和工具。&lt;h4&gt;翻译&lt;/h4&gt;In an increasingly digitalized world, verifying the authenticity of ID documents has become a critical challenge for real-life applications such as digital banking, crypto-exchanges, renting, etc. This study focuses on the topic of fake ID detection, covering several limitations in the field. In particular, no publicly available data from real ID documents exists, and most studies rely on proprietary in-house databases that are not available due to privacy reasons. In order to shed some light on this critical challenge that makes difficult to advance in the field, we explore a trade-off between privacy (i.e., amount of sensitive data available) and performance, proposing a novel patch-wise approach for privacy-preserving fake ID detection. Our proposed approach explores how privacy can be enhanced through: i) two levels of anonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii) different patch size configurations, varying the amount of sensitive data visible in the patch image. Also, state-of-the-art methods such as Vision Transformers and Foundation Models are considered in the analysis. The experimental framework shows that, on an unseen database (DLC-2021), our proposal achieves 13.91% and 0% EERs at patch and ID document level, showing good generalization to other databases. In addition to this exploration, another key contribution of our study is the release of the first publicly available database that contains 48,400 patches from both real and fake ID documents, along with the experimental framework and models, which will be available in our GitHub.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In an increasingly digitalized world, verifying the authenticity of IDdocuments has become a critical challenge for real-life applications such asdigital banking, crypto-exchanges, renting, etc. This study focuses on thetopic of fake ID detection, covering several limitations in the field. Inparticular, no publicly available data from real ID documents exists, and moststudies rely on proprietary in-house databases that are not available due toprivacy reasons. In order to shed some light on this critical challenge thatmakes difficult to advance in the field, we explore a trade-off between privacy(i.e., amount of sensitive data available) and performance, proposing a novelpatch-wise approach for privacy-preserving fake ID detection. Our proposedapproach explores how privacy can be enhanced through: i) two levels ofanonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii)different patch size configurations, varying the amount of sensitive datavisible in the patch image. Also, state-of-the-art methods such as VisionTransformers and Foundation Models are considered in the analysis. Theexperimental framework shows that, on an unseen database (DLC-2021), ourproposal achieves 13.91% and 0% EERs at patch and ID document level, showing agood generalization to other databases. In addition to this exploration,another key contribution of our study is the release of the first publiclyavailable database that contains 48,400 patches from both real and fake IDdocuments, along with the experimental framework and models, which will beavailable in our GitHub.</description>
      <author>example@mail.com (Javier Muñoz-Haro, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez)</author>
      <guid isPermaLink="false">2504.07761v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>FLASH: Flexible Learning of Adaptive Sampling from History in Temporal Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.07337v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 4 figures, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FLASH的动态图链接预测方法，通过学习可适应的邻居选择机制来提高时间图神经网络（TGNNs）的性能。&lt;h4&gt;背景&lt;/h4&gt;在动态图上的未来链接预测中，从历史交互中聚合时间信号是关键步骤，但包含长期历史数据资源密集。现有的时间图神经网络（TGNNs）通常依赖于静态的邻居采样启发式方法，如均匀采样或最近邻居选择，但这些方法无法适应底层图结构。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够适应图结构的动态链接预测方法，提高TGNNs的性能。&lt;h4&gt;方法&lt;/h4&gt;提出FLASH，一种可学习的图自适应邻居选择机制，它整合到TGNNs中，并使用自监督排序损失进行端到端训练。&lt;h4&gt;主要发现&lt;/h4&gt;理论证据表明，常用的启发式方法会阻碍TGNNs的性能，因此设计了FLASH来克服这一限制。&lt;h4&gt;结论&lt;/h4&gt;在多个基准测试中，使用FLASH的TGNNs实现了一致且显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从历史交互中聚合时间信号是动态图上未来链接预测的关键步骤。然而，包含长期历史数据是资源密集型的。因此，时间图神经网络（TGNNs）通常依赖于历史邻居采样启发式方法，如均匀采样或最近邻居选择。这些启发式方法是静态的，无法适应底层图结构。我们引入了FLASH，这是一种可学习的、图自适应的邻居选择机制，它概括了现有的启发式方法。FLASH可以无缝集成到TGNNs中，并使用自监督排序损失进行端到端训练。我们提供了理论证据，表明常用的启发式方法阻碍了TGNNs的性能，这激励了我们的设计。在多个基准测试上的大量实验表明，配备FLASH的TGNNs实现了一致且显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Aggregating temporal signals from historic interactions is a key step infuture link prediction on dynamic graphs. However, incorporating long historiesis resource-intensive. Hence, temporal graph neural networks (TGNNs) often relyon historical neighbors sampling heuristics such as uniform sampling or recentneighbors selection. These heuristics are static and fail to adapt to theunderlying graph structure. We introduce FLASH, a learnable and graph-adaptiveneighborhood selection mechanism that generalizes existing heuristics. FLASHintegrates seamlessly into TGNNs and is trained end-to-end using aself-supervised ranking loss. We provide theoretical evidence that commonlyused heuristics hinders TGNNs performance, motivating our design. Extensiveexperiments across multiple benchmarks demonstrate consistent and significantperformance improvements for TGNNs equipped with FLASH.</description>
      <author>example@mail.com (Or Feldman, Krishna Sri Ipsit Mantri, Carola-Bibiane Schönlieb, Chaim Baskin, Moshe Eliasof)</author>
      <guid isPermaLink="false">2504.07337v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Beating Transformers using Synthetic Cognition</title>
      <link>http://arxiv.org/abs/2504.07619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过生成情景反应行为来发展通用人工智能的道路，并探讨了使用合成认知来发展情景反应行为的方法。&lt;h4&gt;背景&lt;/h4&gt;目前，通用人工智能的发展需要生成情景反应行为，而Transformer架构在生成情景反应行为方面被认为是最佳方案。然而，现有的方法仍然无法实现推理功能。&lt;h4&gt;目的&lt;/h4&gt;研究使用合成认知来发展情景反应行为。&lt;h4&gt;方法&lt;/h4&gt;提出了一个处理序列的机制，并将其应用于DNA序列分类任务中，以DNA基础模型为基准进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多个基准任务上的表现优于DNA基础模型，实现了在序列处理方面的扩展，并超越了Transformer架构在序列分类任务上的表现。&lt;h4&gt;结论&lt;/h4&gt;通过扩展合成认知以处理序列，并击败了Transformer架构在序列分类任务上的表现，实现了研究目标。&lt;h4&gt;翻译&lt;/h4&gt;The road to Artificial General Intelligence goes through the generation of episodic reactive behaviors, where the Transformer architecture has been proven to be the state-of-the-art. However, they still fail to develop reasoning. Recently, a novel approach for developing cognitive architectures, called Synthetic Cognition, has been proposed and implemented to develop instantaneous reactive behavior. In this study, we aim to explore the use of Synthetic Cognition to develop episodic reactive behaviors. We propose a mechanism to deal with sequences for the recent implementation of Synthetic Cognition, and test it against DNA foundation models in DNA sequence classification tasks. In our experiments, our proposal clearly outperforms the DNA foundation models, obtaining the best score on more benchmark tasks than the alternatives. Thus, we achieve two goals: expanding Synthetic Cognition to deal with sequences, and beating the Transformer architecture for sequence classification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The road to Artificial General Intelligence goes through the generation ofepisodic reactive behaviors, where the Transformer architecture has been provento be the state-of-the-art. However, they still fail to develop reasoning.Recently, a novel approach for developing cognitive architectures, calledSynthetic Cognition, has been proposed and implemented to develop instantaneousreactive behavior. In this study, we aim to explore the use of SyntheticCognition to develop episodic reactive behaviors. We propose a mechanism todeal with sequences for the recent implementation of Synthetic Cognition, andtest it against DNA foundation models in DNA sequence classification tasks. Inour experiments, our proposal clearly outperforms the DNA foundation models,obtaining the best score on more benchmark tasks than the alternatives. Thus,we achieve two goals: expanding Synthetic Cognition to deal with sequences, andbeating the Transformer architecture for sequence classification.</description>
      <author>example@mail.com (Alfredo Ibias, Miguel Rodriguez-Galindo, Hector Antona, Guillem Ramirez-Miranda, Enric Guinovart)</author>
      <guid isPermaLink="false">2504.07619v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Identifying regions of interest in whole slide images of renal cell carcinoma</title>
      <link>http://arxiv.org/abs/2504.07313v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究开发了一个全自动系统，用于检测肾细胞癌全切片图像中的感兴趣区域（ROI），以减少分析时间和辅助病理学家做出更准确的决策。&lt;h4&gt;背景&lt;/h4&gt;病理学家的诊断工作因全切片图像中包含大量信息而变得耗时且繁琐。&lt;h4&gt;目的&lt;/h4&gt;减少分析时间并辅助病理学家在肾细胞癌诊断中做出更准确的决策。&lt;h4&gt;方法&lt;/h4&gt;使用高效纹理描述符——主旋转局部二值模式（DRLBP）和颜色转换来揭示和利用显微镜高放大倍数下的巨大纹理变化。对WSI片段的颜色通道分别进行特征提取，形成直方图。使用最频繁出现的模式作为特征选择步骤，丢弃非信息性特征。在1800个肾癌片段上比较和评估了不同分类器的性能。此外，通过深度学习和微调方法使用深度特征和迁移学习对图像片段进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;实现了高识别准确率，最佳精度结果为99.17%，使用SVM达到。迁移学习模型表现良好，使用ResNet-50的最高精度达到98.50%。该方法在图像分类和识别ROI方面表现出高效性。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在图像分类和识别ROI方面表现出高效性，证明了其在肾细胞癌诊断中的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s42600-021-00178-9&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The histopathological images contain a huge amount of information, which canmake diagnosis an extremely timeconsuming and tedious task. In this study, wedeveloped a completely automated system to detect regions of interest (ROIs) inwhole slide images (WSI) of renal cell carcinoma (RCC), to reduce time analysisand assist pathologists in making more accurate decisions. The proposedapproach is based on an efficient texture descriptor named dominant rotatedlocal binary pattern (DRLBP) and color transformation to reveal and exploit theimmense texture variability at the microscopic high magnifications level.Thereby, the DRLBPs retain the structural information and utilize the magnitudevalues in a local neighborhood for more discriminative power. For theclassification of the relevant ROIs, feature extraction of WSIs patches wasperformed on the color channels separately to form the histograms. Next, weused the most frequently occurring patterns as a feature selection step todiscard non-informative features. The performances of different classifiers ona set of 1800 kidney cancer patches originating from 12 whole slide images werecompared and evaluated. Furthermore, the small size of the image dataset allowsto investigate deep learning approach based on transfer learning for imagepatches classification by using deep features and fine-tuning methods. Highrecognition accuracy was obtained and the classifiers are efficient, the bestprecision result was 99.17% achieved with SVM. Moreover, transfer learningmodels perform well with comparable performance, and the highest precisionusing ResNet-50 reached 98.50%. The proposed approach results revealed a veryefficient image classification and demonstrated efficacy in identifying ROIs.This study presents an automatic system to detect regions of interest relevantto the diagnosis of kidney cancer in whole slide histopathology images.</description>
      <author>example@mail.com (Mohammed Lamine Benomar, Nesma Settouti, Eric Debreuve, Xavier Descombes, Damien Ambrosetti)</author>
      <guid isPermaLink="false">2504.07313v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Transformer-Based Temporal Information Extraction and Application: A Review</title>
      <link>http://arxiv.org/abs/2504.07470v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于Transformer的时序信息提取（Temporal IE）进行了综述，分析了该领域的研究成果，并提出了未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;时序信息提取旨在从非结构化文本中提取结构化时序信息，揭示文本中的隐含时间线。这一技术在医疗保健、新闻报道和情报分析等领域得到应用，帮助模型进行时序推理，并使人类用户理解文本的时间结构。&lt;h4&gt;目的&lt;/h4&gt;弥补目前对基于Transformer的时序信息提取研究缺乏全面综述的不足。&lt;h4&gt;方法&lt;/h4&gt;系统地总结和分析使用Transformer进行时序信息提取的研究成果。&lt;h4&gt;主要发现&lt;/h4&gt;基于Transformer的方法在时序信息提取方面取得了显著进展，但相关研究综述不足。&lt;h4&gt;结论&lt;/h4&gt;本文通过对现有研究的总结和分析，为时序信息提取领域的未来研究提供了方向。&lt;h4&gt;翻译&lt;/h4&gt;This paper aims to bridge the gap in the comprehensive reviews of temporal information extraction (IE) using Transformers, by systematically summarizing and analyzing the existing body of work in this field while highlighting potential future research directions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal information extraction (IE) aims to extract structured temporalinformation from unstructured text, thereby uncovering the implicit timelineswithin. This technique is applied across domains such as healthcare, newswire,and intelligence analysis, aiding models in these areas to perform temporalreasoning and enabling human users to grasp the temporal structure of text.Transformer-based pre-trained language models have produced revolutionaryadvancements in natural language processing, demonstrating exceptionalperformance across a multitude of tasks. Despite the achievements garnered byTransformer-based approaches in temporal IE, there is a lack of comprehensivereviews on these endeavors. In this paper, we aim to bridge this gap bysystematically summarizing and analyzing the body of work on temporal IE usingTransformers while highlighting potential future research directions.</description>
      <author>example@mail.com (Xin Su, Phillip Howard, Steven Bethard)</author>
      <guid isPermaLink="false">2504.07470v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>How Can Objects Help Video-Language Understanding?</title>
      <link>http://arxiv.org/abs/2504.07454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态大型语言模型（MLLMs）如何感知视觉世界，并研究了对象表示和适应性问题，旨在提高视频语言理解能力。&lt;h4&gt;背景&lt;/h4&gt;目前对MLLMs如何感知视觉世界的理解有限，既有观点认为对象和关系建模可能通过归纳偏差隐式实现，也有观点指出简单的视觉字幕生成在视频理解中表现良好。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过对象帮助MLLMs进行视频语言理解。&lt;h4&gt;方法&lt;/h4&gt;从对象表示和适应性的角度，通过在五个视频问答数据集上的广泛评估，研究了表示表达性和集成难度之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;明确整合以对象为中心的表示对于视频语言理解是必要的，而符号对象可以最容易被整合且在问答任务中表现良好。&lt;h4&gt;结论&lt;/h4&gt;希望研究结果能鼓励社区探索将感知模块显式集成到MLLM设计中的方法。代码和模型将公开发布。&lt;h4&gt;翻译&lt;/h4&gt;How multimodal large language models (MLLMs) perceive the visual worldremains a mystery. To one extreme, object and relation modeling may beimplicitly implemented with inductive biases, for example by treating objectsas tokens. To the other extreme, empirical results reveal the surprisingfinding that simply performing visual captioning, which tends to ignore spatialconfiguration of the objects, serves as a strong baseline for videounderstanding. We aim to answer the question: how can objects helpvideo-language understanding in MLLMs? We tackle the question from the objectrepresentation and adaptation perspectives. Specifically, we investigate thetrade-off between representation expressiveness (e.g., distributed versusymbolic) and integration difficulty (e.g., data-efficiency when learning theadapters). Through extensive evaluations on five video question answeringdatasets, we confirm that explicit integration of object-centric representationremains necessary, and the symbolic objects can be most easily integrated whilebeing performant for question answering. We hope our findings can encouragethe community to explore the explicit integration of perception modules intoMLLM design. Our code and models will be publicly released.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How multimodal large language models (MLLMs) perceive the visual worldremains a mystery. To one extreme, object and relation modeling may beimplicitly implemented with inductive biases, for example by treating objectsas tokens. To the other extreme, empirical results reveal the surprisingfinding that simply performing visual captioning, which tends to ignore spatialconfiguration of the objects, serves as a strong baseline for videounderstanding. We aim to answer the question: how can objects helpvideo-language understanding in MLLMs? We tackle the question from the objectrepresentation and adaptation perspectives. Specifically, we investigate thetrade-off between representation expressiveness (e.g., distributed versussymbolic) and integration difficulty (e.g., data-efficiency when learning theadapters). Through extensive evaluations on five video question answeringdatasets, we confirm that explicit integration of object-centric representationremains necessary, and the symbolic objects can be most easily integrated whilebeing performant for question answering. We hope our findings can encourage thecommunity to explore the explicit integration of perception modules into MLLMdesign. Our code and models will be publicly released.</description>
      <author>example@mail.com (Zitian Tang, Shijie Wang, Junho Cho, Jaewook Yoo, Chen Sun)</author>
      <guid isPermaLink="false">2504.07454v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Data Fusion of Deep Learned Molecular Embeddings for Property Prediction</title>
      <link>http://arxiv.org/abs/2504.07297v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种改进的多任务学习模型，通过数据融合技术提高在稀疏数据集上的预测准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;深度学习方法在预测材料特性方面具有高精度和效率，但在数据稀疏的情况下，其准确性和适用性受到限制。&lt;h4&gt;目的&lt;/h4&gt;为了提高预测能力，研究提出了使用迁移学习和多任务学习等技术。&lt;h4&gt;方法&lt;/h4&gt;通过数据融合技术将多个单任务模型学习到的分子嵌入进行结合，并在这些结合的嵌入上训练多任务模型。该技术应用于量子化学数据集和实验数据集。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现标准的多任务模型在训练稀疏数据集且属性相关性较弱时表现不佳。&lt;h4&gt;结论&lt;/h4&gt;融合后的多任务模型在稀疏数据集上优于标准多任务模型，并且在数据受限的情况下，比单任务模型提供了更好的预测效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-driven approaches such as deep learning can result in predictive modelsfor material properties with exceptional accuracy and efficiency. However, inmany problems data is sparse, severely limiting their accuracy andapplicability. To improve predictions, techniques such as transfer learning andmulti-task learning have been used. The performance of multi-task learningmodels depends on the strength of the underlying correlations between tasks andthe completeness of the dataset. We find that standard multi-task models tendto underperform when trained on sparse datasets with weakly correlatedproperties. To address this gap, we use data fusion techniques to combine thelearned molecular embeddings of various single-task models and trained amulti-task model on this combined embedding. We apply this technique to awidely used benchmark dataset of quantum chemistry data for small molecules aswell as a newly compiled sparse dataset of experimental data collected fromliterature and our own quantum chemistry and thermochemical calculations. Theresults show that the fused, multi-task models outperform standard multi-taskmodels for sparse datasets and can provide enhanced prediction on data-limitedproperties compared to single-task models.</description>
      <author>example@mail.com (Robert J Appleton, Brian C Barnes, Alejandro Strachan)</author>
      <guid isPermaLink="false">2504.07297v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Automating the Path: An R&amp;D Agenda for Human-Centered AI and Visualization</title>
      <link>http://arxiv.org/abs/2504.07529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个系统框架来理解以人为本的人工智能（HCAI）如何改变可视化学科。&lt;h4&gt;背景&lt;/h4&gt;生成式AI、大型语言模型（LLMs）和基础模型的兴起正在深刻改变计算机科学，可视化也不例外。&lt;h4&gt;目的&lt;/h4&gt;设计一个框架，展示如何将HCAI的四个工具能力——放大、增强、赋权和提升——映射到可视化意义构建的四个阶段：观察、探索、建模和报告。&lt;h4&gt;方法&lt;/h4&gt;框架中，对于每个组合，本文回顾了现有工具，展望了未来的可能性，识别了挑战和陷阱，并考察了伦理考量。&lt;h4&gt;主要发现&lt;/h4&gt;该设计空间可以作为研发议程，帮助可视化研究人员和实践者将AI整合到工作中，并理解可视化如何支持HCAI研究。&lt;h4&gt;结论&lt;/h4&gt;该框架为可视化研究人员和实践者提供了一个整合AI的工具和方法的路线图，同时也强调了伦理和挑战的重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成式人工智能、大型语言模型（LLMs）和基础模型的兴起正在从根本上改变计算机科学，可视化也不例外。我们提出一个理解以人为本的人工智能（HCAI）如何改变可视化学科的系统性框架。我们的框架将四个关键HCAI工具能力——放大、增强、赋权和提升——映射到四个可视化意义构建的阶段：观察、探索、建模和报告。对于每个组合，我们回顾了现有工具，展望了未来的可能性，识别了挑战和陷阱，并考察了伦理考量。这个设计空间可以作为可视化研究人员和实践者的研发议程，以便将AI整合到他们的工作中，以及理解可视化如何支持HCAI研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of generative AI, large language models (LLMs), and foundationmodels is fundamentally reshaping computer science, and visualization andvisual analytics are no exception. We present a systematic framework forunderstanding how human-centered AI (HCAI) can transform the visualizationdiscipline. Our framework maps four key HCAI tool capabilities -- amplify,augment, empower, and enhance -- onto the four phases of visual sensemaking:view, explore, schematize, and report. For each combination, we review existingtools, envision future possibilities, identify challenges and pitfalls, andexamine ethical considerations. This design space can serve as an R\&amp;D agendafor both visualization researchers and practitioners to integrate AI into theirwork as well as understanding how visualization can support HCAI research.</description>
      <author>example@mail.com (Niklas Elmqvist, Clemens Nylandsted Klokmose)</author>
      <guid isPermaLink="false">2504.07529v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.06958v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RFT的强化学习技术，结合GRPO用于视频多模态大语言模型，以增强时空感知能力同时保持通用能力。&lt;h4&gt;背景&lt;/h4&gt;强化学习在多模态大语言模型推理能力上取得了显著进展，但在视频理解领域应用有限。&lt;h4&gt;目的&lt;/h4&gt;旨在通过RFT与GRPO的结合，提升视频MLLM的时空感知能力。&lt;h4&gt;方法&lt;/h4&gt;通过在有限的样本上进行多任务RFT，开发出VideoChat-R1，这是一个强大的视频MLLM，在时空感知任务上实现了最先进的性能。&lt;h4&gt;主要发现&lt;/h4&gt;RFT在特定任务改进上非常高效，VideoChat-R1在时空感知任务上表现优异，同时在聊天能力上并未受损。与Qwen2.5-VL-7B相比，VideoChat-R1在时间定位和对象跟踪等任务上性能提升了数倍，并在多个通用QAbenchmark上也有显著提升。&lt;h4&gt;结论&lt;/h4&gt;RFT对于提升视频MLLM的特定任务能力具有潜力，为未来视频MLLM的RL研究提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a reinforcement learning technique called RFT, combined with GRPO for video multimodal large language models, aiming to enhance spatio-temporal perception while maintaining general capabilities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in reinforcement learning have significantly advanced thereasoning capabilities of multimodal large language models (MLLMs). Whileapproaches such as Group Relative Policy Optimization (GRPO) and rule-basedreward mechanisms demonstrate promise in text and image domains, theirapplication to video understanding remains limited. This paper presents asystematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for videoMLLMs, aiming to enhance spatio-temporal perception while maintaining generalcapabilities. Our experiments reveal that RFT is highly data-efficient fortask-specific improvements. Through multi-task RFT on spatio-temporalperception objectives with limited samples, we develop VideoChat-R1, a powerfulvideo MLLM that achieves state-of-the-art performance on spatio-temporalperception tasks without sacrificing chat ability, while exhibiting emergingspatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1boosts performance several-fold in tasks like temporal grounding (+31.8) andobject tracking (+31.2). Additionally, it significantly improves on general QAbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9).Our findings underscore the potential of RFT for specialized task enhancementof Video MLLMs. We hope our work offers valuable insights for future RLresearch in video MLLMs.</description>
      <author>example@mail.com (Xinhao Li, Ziang Yan, Desen Meng, Lu Dong, Xiangyu Zeng, Yinan He, Yali Wang, Yu Qiao, Yi Wang, Limin Wang)</author>
      <guid isPermaLink="false">2504.06958v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>GPT Carry-On: Training Foundation Model for Customization Could Be Simple, Scalable and Affordable</title>
      <link>http://arxiv.org/abs/2504.07513v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，用于充分利用现有的大型语言模型（LLM）和在线服务系统，为每个用户或任务定制LLM。&lt;h4&gt;背景&lt;/h4&gt;现代大型语言模型已经进入数百万用户的日常生活，但为每个用户或任务定制LLM在计算和存储资源上存在挑战。&lt;h4&gt;目的&lt;/h4&gt;研究是否能够为每个用户或任务定制LLM，并探讨如何高效地实现这一目标。&lt;h4&gt;方法&lt;/h4&gt;在预训练LLM的最终层嵌入上训练额外的transformer分支，然后将基础模型与一个轻量级的模块合并，以形成定制的LLM。通过混合不同领域的LLM，适应特定任务。在推理节点上外包大部分训练计算，在训练节点上仅训练轻量级模块。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Qwen和DeepSeek开源模型上进行了测试，实现了更快的损失收敛。在解决数学问题时，该方法计算和模型尺寸极小，仅用1000个思维链数据样本和2层轻量级模块的1MB参数，结果令人鼓舞。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效地为每个用户或任务定制LLM，同时降低计算和存储资源的需求，具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代大型语言基础模型（LLM）现在已经进入了数百万用户的日常生活。我们提出了一个自然的问题，即是否可以为每个用户或每个任务定制LLM。从系统和工业经济角度考虑，通用的持续训练或微调仍然需要大量的训练GPU节点的计算和内存，而大多数部署中的推理节点，可能配备的是低端GPU，其配置是为了尽可能快地进行前向传播。我们提出了一种框架，以充分利用现有的LLM和在线服务系统。我们在预训练LLM的最终层嵌入上训练了一个额外的transformer分支，它是基础，然后一个延续模块将基础模型合并，以组成一个定制的LLM。我们可以混合多个层，或者混合多个不同领域如聊天、编码、数学等专业的LLM，以形成一个最适合新任务的新的LLM混合体。由于基础模型不需要更新参数，我们能够在推理节点上外包大部分的训练计算工作，仅在训练节点上训练一个轻量级的延续模块，我们在30B LLM上训练一个100M延续层时消耗的GPU内存少于1GB。我们测试了Qwen和DeepSeek开源模型进行持续预训练，并实现了更快的损失收敛。我们将其用于通过极小的计算和模型尺寸解决数学问题，使用了1000个思维链数据样本，以及2层延续模块的1MB参数，结果很有希望。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern large language foundation models (LLM) have now entered the dailylives of millions of users. We ask a natural question whether it is possible tocustomize LLM for every user or every task. From system and industrial economyconsideration, general continue-training or fine-tuning still requiresubstantial computation and memory of training GPU nodes, whereas mostinference nodes under deployment, possibly with lower-end GPUs, are configuredto make forward pass fastest possible. We propose a framework to take fulladvantages of existing LLMs and systems of online service. We train anadditional branch of transformer blocks on the final-layer embedding ofpretrained LLMs, which is the base, then a carry-on module merge the basemodels to compose a customized LLM. We can mix multiple layers, or multipleLLMs specialized in different domains such as chat, coding, math, to form a newmixture of LLM that best fit a new task. As the base model don't need to updateparameters, we are able to outsource most computation of the training job oninference nodes, and only train a lightweight carry-on on training nodes, wherewe consume less than 1GB GPU memory to train a 100M carry-on layer on 30B LLM.We tested Qwen and DeepSeek opensourced models for continue-pretraining and gotfaster loss convergence. We use it to improve solving math questions withextremely small computation and model size, with 1000 data samples ofchain-of-thoughts, and as small as 1 MB parameters of two layer layer carry-on,and the results are promising.</description>
      <author>example@mail.com (Jianqiao Wangni)</author>
      <guid isPermaLink="false">2504.07513v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>AMAD: AutoMasked Attention for Unsupervised Multivariate Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.06643v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  fix img issues&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AMAD的无监督多变量时间序列异常检测（UMTSAD）模型，该模型通过结合自动掩码机制和注意力混合模块，以及多尺度特征提取和自动相对关联建模，为UMTSAD问题提供了一种鲁棒且适应性强的解决方案。&lt;h4&gt;背景&lt;/h4&gt;UMTSAD在金融、网络和传感器系统等领域发挥着重要作用。近年来，基于Transformer和自注意力机制的深度学习模型在UMTSAD任务中取得了显著成果，但这些模型的序列异常关联假设通常局限于特定的预定义模式和场景，限制了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的局限性，提出AMAD模型，以实现更通用的异常关联表示和更好的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;AMAD模型通过以下方法实现：1. 引入基于AutoMask机制的自动掩码注意力结构；2. 结合注意力混合模块；3. 采用Max-Min训练策略和局部-全局对比学习方法；4. 结合多尺度特征提取和自动相对关联建模。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AMAD模型在各种数据集上与现有SOTA基准相比，实现了具有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;AMAD模型为UMTSAD问题提供了一种有效的解决方案，具有鲁棒性和适应性，有望在多个领域得到应用。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised multivariate time series anomaly detection (UMTSAD) plays a critical role in various domains, including finance, networks, and sensor systems. In recent years, due to the outstanding performance of deep learning in general sequential tasks, many models have been specialized for deep UMTSAD tasks and have achieved impressive results, particularly those based on the Transformer and self-attention mechanisms. However, the sequence anomaly association assumptions underlying these models are often limited to specific predefined patterns and scenarios, such as concentrated or peak anomaly patterns. These limitations hinder their ability to generalize to diverse anomaly situations, especially where the lack of labels poses significant challenges. To address these issues, we propose AMAD, which integrates AutoMasked Attention for UMTSAD scenarios. AMAD introduces a novel structure based on the AutoMask mechanism and an attention mixup module, forming a simple yet generalized anomaly association representation framework. This framework is further enhanced by a Max-Min training strategy and a Local-Global contrastive learning approach. By combining multi-scale feature extraction with automatic relative association modeling, AMAD provides a robust and adaptable solution to UMTSAD challenges. Extensive experimental results demonstrate that the proposed model achieving competitive performance results compared to SOTA benchmarks across a variety of datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised multivariate time series anomaly detection (UMTSAD) plays acritical role in various domains, including finance, networks, and sensorsystems. In recent years, due to the outstanding performance of deep learningin general sequential tasks, many models have been specialized for deep UMTSADtasks and have achieved impressive results, particularly those based on theTransformer and self-attention mechanisms. However, the sequence anomalyassociation assumptions underlying these models are often limited to specificpredefined patterns and scenarios, such as concentrated or peak anomalypatterns. These limitations hinder their ability to generalize to diverseanomaly situations, especially where the lack of labels poses significantchallenges. To address these issues, we propose AMAD, which integrates\textbf{A}uto\textbf{M}asked Attention for UMTS\textbf{AD} scenarios. AMADintroduces a novel structure based on the AutoMask mechanism and an attentionmixup module, forming a simple yet generalized anomaly associationrepresentation framework. This framework is further enhanced by a Max-Mintraining strategy and a Local-Global contrastive learning approach. Bycombining multi-scale feature extraction with automatic relative associationmodeling, AMAD provides a robust and adaptable solution to UMTSAD challenges.Extensive experimental results demonstrate that the proposed model achievingcompetitive performance results compared to SOTA benchmarks across a variety ofdatasets.</description>
      <author>example@mail.com (Tiange Huang, Yongjun Li)</author>
      <guid isPermaLink="false">2504.06643v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Objaverse++: Curated 3D Object Dataset with Quality Annotations</title>
      <link>http://arxiv.org/abs/2504.07334v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures. Accepted to CVPR 2025 Workshop on Efficient Large  Vision Models (April 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Objaverse++的数据集，它是经过人工专家详细属性标注的Objaverse子集。该研究通过提升数据质量，优化了3D生成模型。&lt;h4&gt;背景&lt;/h4&gt;Objaverse是一个包含超过800,000个3D对象的的大型数据集，但其中低质量模型较多，限制了其效用。&lt;h4&gt;目的&lt;/h4&gt;通过人工标注提高Objaverse数据集的质量，并验证其对3D生成模型性能的提升。&lt;h4&gt;方法&lt;/h4&gt;人工标注了10,000个3D对象，包括美学质量分数、纹理颜色分类、多对象组合标志、透明度特征等属性，并训练了一个神经网络来标注剩余数据。&lt;h4&gt;主要发现&lt;/h4&gt;在图像到3D生成任务中，预先训练在高质量子集上的模型表现优于在Objaverse大型数据集上训练的模型。数据质量越高，训练损失收敛速度越快。&lt;h4&gt;结论&lt;/h4&gt;精心管理和丰富标注可以弥补原始数据集的大小限制，为开发3D生成模型提供更有效的途径。发布约500,000个精选3D模型的数据集，以促进3D计算机视觉下游任务的研究。&lt;h4&gt;翻译&lt;/h4&gt;本文提出Objaverse++，这是经过人类专家详细属性标注的Objaverse子集。随着3D内容生成领域的进步，Objaverse等大规模数据集推动了这一领域的发展，其中包含从互联网收集的超过800,000个3D对象。尽管Objaverse代表了可用的最大3D资产集合，但其效用受到低质量模型的普遍存在而限制。为了解决这一限制，我们手动标注了10,000个3D对象，包括美学质量评分、纹理颜色分类、多对象组合标志、透明度特征等详细属性。然后，我们训练了一个能够标注Objaverse数据集剩余标签的神经网络。通过实验和用户研究生成结果，我们证明了在质量专注的子集上预先训练的模型在图像到3D生成任务中表现优于在Objaverse更大数据集上训练的模型。此外，通过比较由我们的标签过滤的多个训练数据子集，我们的结果表明数据质量越高，训练损失收敛速度越快。这些发现表明，精心管理和丰富标注可以弥补原始数据集的大小限制，可能为开发3D生成模型提供更有效的途径。我们发布了约500,000个精选3D模型的数据集，以促进3D计算机视觉下游任务的研究。在不久的将来，我们旨在将我们的标注扩展到覆盖整个Objaverse数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents Objaverse++, a curated subset of Objaverse enhanced withdetailed attribute annotations by human experts. Recent advances in 3D contentgeneration have been driven by large-scale datasets such as Objaverse, whichcontains over 800,000 3D objects collected from the Internet. AlthoughObjaverse represents the largest available 3D asset collection, its utility islimited by the predominance of low-quality models. To address this limitation,we manually annotate 10,000 3D objects with detailed attributes, includingaesthetic quality scores, texture color classifications, multi-objectcomposition flags, transparency characteristics, etc. Then, we trained a neuralnetwork capable of annotating the tags for the rest of the Objaverse dataset.Through experiments and a user study on generation results, we demonstrate thatmodels pre-trained on our quality-focused subset achieve better performancethan those trained on the larger dataset of Objaverse in image-to-3D generationtasks. In addition, by comparing multiple subsets of training data filtered byour tags, our results show that the higher the data quality, the faster thetraining loss converges. These findings suggest that careful curation and richannotation can compensate for the raw dataset size, potentially offering a moreefficient path to develop 3D generative models. We release our enhanced datasetof approximately 500,000 curated 3D models to facilitate further research onvarious downstream tasks in 3D computer vision. In the near future, we aim toextend our annotations to cover the entire Objaverse dataset.</description>
      <author>example@mail.com (Chendi Lin, Heshan Liu, Qunshu Lin, Zachary Bright, Shitao Tang, Yihui He, Minghao Liu, Ling Zhu, Cindy Le)</author>
      <guid isPermaLink="false">2504.07334v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning</title>
      <link>http://arxiv.org/abs/2504.06575v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种语义感知的水印算法，用于检测由大型语言模型（LLM）生成的文本，旨在提高水印文本的质量、可检测性和对去除攻击的鲁棒性，同时解决对抗仿冒攻击的挑战。&lt;h4&gt;背景&lt;/h4&gt;水印技术在检测LLM生成的文本方面显示出潜力，但目前的研究主要集中在水印文本的质量、可检测性和对去除攻击的鲁棒性上，而对仿冒攻击的防御研究较少。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效防御仿冒攻击的语义感知水印算法，同时保持水印文本的质量、可检测性和对去除攻击的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种语义感知水印算法，该算法通过后置嵌入水印，同时保留目标文本的原始意义。该方法引入了语义映射模型，指导生成绿色-红色标记列表，通过对比训练使其对语义扭曲变化敏感，对语义保留编辑不敏感。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法对去除攻击具有强大的鲁棒性，对仿冒攻击（如情感反转和有害内容插入）具有安全性，同时保持了高水印可检测性。&lt;h4&gt;结论&lt;/h4&gt;该算法为LLM提供了更安全、更语义感知的水印方法，是迈向更安全LLM水印的重要一步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：水印技术已成为检测由LLM生成的文本的有前途的技术。当前研究主要集中在三个设计标准：水印文本的高质量、高可检测性和对去除攻击的鲁棒性。然而，对仿冒攻击的安全性研究相对较少。例如，一种挂靠攻击可以恶意改变水印文本的意义——将其变成仇恨言论——同时保留原始水印，从而损害LLM提供商的声誉。我们确定了两个使防御仿冒攻击变得困难的核心挑战：（1）水印需要对语义扭曲变化敏感，同时对语义保留编辑不敏感；（2）检测全局语义变化的需求与大多数水印方案局部、自回归性质之间的矛盾。为了解决这些挑战，我们提出了一种语义感知的水印算法，该算法在保持目标文本原始意义的同时后置嵌入水印。我们的方法引入了一个语义映射模型，该模型指导生成绿色-红色标记列表，通过对比训练使其对语义扭曲变化敏感，对语义保留变化不敏感。在两个标准基准上的实验表明，该方法对去除攻击具有强大的鲁棒性，对仿冒攻击（包括情感反转和有害内容插入）具有安全性，同时保持了高水印可检测性。我们的方法为LLM提供了更安全、更语义感知的水印方法，是迈向更安全LLM水印的重要一步。我们的代码可在https://github.com/UCSB-NLP-Chang/contrastive-watermark找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Watermarking has emerged as a promising technique for detecting textsgenerated by LLMs. Current research has primarily focused on three designcriteria: high quality of the watermarked text, high detectability, androbustness against removal attack. However, the security against spoofingattacks remains relatively understudied. For example, a piggyback attack canmaliciously alter the meaning of watermarked text-transforming it into hatespeech-while preserving the original watermark, thereby damaging the reputationof the LLM provider. We identify two core challenges that make defendingagainst spoofing difficult: (1) the need for watermarks to be both sensitive tosemantic-distorting changes and insensitive to semantic-preserving edits, and(2) the contradiction between the need to detect global semantic shifts and thelocal, auto-regressive nature of most watermarking schemes. To address thesechallenges, we propose a semantic-aware watermarking algorithm that post-hocembeds watermarks into a given target text while preserving its originalmeaning. Our method introduces a semantic mapping model, which guides thegeneration of a green-red token list, contrastively trained to be sensitive tosemantic-distorting changes and insensitive to semantic-preserving changes.Experiments on two standard benchmarks demonstrate strong robustness againstremoval attacks and security against spoofing attacks, including sentimentreversal and toxic content insertion, while maintaining high watermarkdetectability. Our approach offers a significant step toward more secure andsemantically aware watermarking for LLMs. Our code is available athttps://github.com/UCSB-NLP-Chang/contrastive-watermark.</description>
      <author>example@mail.com (Li An, Yujian Liu, Yepeng Liu, Yang Zhang, Yuheng Bu, Shiyu Chang)</author>
      <guid isPermaLink="false">2504.06575v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis</title>
      <link>http://arxiv.org/abs/2504.06553v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AShiTA的框架，用于将高级任务分解为与环境相关的子任务，以实现高级指令到3D场景的映射。&lt;h4&gt;背景&lt;/h4&gt;尽管近年来在场景重建和理解方面取得了进展，但将抽象的高级指令与3D场景联系起来仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一个框架，能够将高级任务分解为与环境相关的子任务，并生成与3D场景图相关的任务层次结构。&lt;h4&gt;方法&lt;/h4&gt;AShiTA通过交替使用LLM辅助的层次任务分析和任务驱动的3D场景图构建来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AShiTA在将高级任务分解为环境相关的子任务方面优于LLM基线，并且能够达到与最先进方法相当的地基性能。&lt;h4&gt;结论&lt;/h4&gt;AShiTA是一个有效的框架，可以用于将高级指令与3D场景相关联，并有望提高相关任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While recent work in scene reconstruction and understanding has made stridesin grounding natural language to physical 3D environments, it is stillchallenging to ground abstract, high-level instructions to a 3D scene.High-level instructions might not explicitly invoke semantic elements in thescene, and even the process of breaking a high-level task into a set of moreconcrete subtasks, a process called hierarchical task analysis, isenvironment-dependent. In this work, we propose ASHiTA, the first frameworkthat generates a task hierarchy grounded to a 3D scene graph by breaking downhigh-level tasks into grounded subtasks. ASHiTA alternates LLM-assistedhierarchical task analysis, to generate the task breakdown, with task-driven 3Dscene graph construction to generate a suitable representation of theenvironment. Our experiments show that ASHiTA performs significantly betterthan LLM baselines in breaking down high-level tasks into environment-dependentsubtasks and is additionally able to achieve grounding performance comparableto state-of-the-art methods.</description>
      <author>example@mail.com (Yun Chang, Leonor Fermoselle, Duy Ta, Bernadette Bucher, Luca Carlone, Jiuguang Wang)</author>
      <guid isPermaLink="false">2504.06553v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization</title>
      <link>http://arxiv.org/abs/2504.06265v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的架构，将LLM微调重新定义为通过深度核方法进行高斯过程边缘似然优化，以提高在不确定性下的优化效率。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型（LLMs）可以在其潜在空间中编码复杂关系，但利用它们进行不确定性下的优化仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;解决在不确定性下利用LLMs进行优化的挑战。&lt;h4&gt;方法&lt;/h4&gt;引入基于LLM的深度核，与GPs联合优化，以保留LLMs提供丰富灵活的输入空间和GPs建模此空间并具有预测不确定性的优点。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Buchwald-Hartwig反应优化中几乎将高性能反应的发现率翻倍（从24%到43%），且无需特定特征即可比特定领域的表示提高14%。在19个基准测试中，该方法在各种任务、LLM架构、预训练领域和超参数设置上显示出鲁棒性、通用性和持续改进。&lt;h4&gt;结论&lt;/h4&gt;联合LLM-GP优化通过边缘似然隐式执行对比学习，对齐表示以产生更好的结构化嵌入空间、改进的不确定性校准和更有效的采样，无需任何外部损失。这项工作在样本高效优化方面提供了实际进展，并揭示了有效贝叶斯优化的关键因素。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型语言模型（LLMs）可以在其潜在空间中编码复杂关系，然而利用它们在不确定性下的优化仍然具有挑战性。我们通过一种新的架构来解决这个问题，该架构将LLM微调重新定义为通过深度核方法进行高斯过程边缘似然优化。我们引入了基于LLM的深度核，与GPs联合优化，以保留LLMs提供丰富灵活的输入空间和GPs建模此空间并具有预测不确定性的优点。应用于Buchwald-Hartwig反应优化，我们的方法将高性能反应的发现率几乎翻倍（从24%到43%），且无需特定特征即可比特定领域的表示提高14%。在19个基准测试中，从一般化学到反应和分子性质优化的广泛实证评估证明了我们方法在任务、LLM架构（编码器、解码器、编码器-解码器）、预训练领域（与化学相关的或通用目的）和超参数设置（在单个数据集上一次调整）上的鲁棒性、通用性和持续改进。最后，我们解释了这些改进：通过边缘似然隐式执行的联合LLM-GP优化执行对比学习，对齐表示以产生更好的结构化嵌入空间、改进的不确定性校准和更有效的采样，无需任何外部损失。这项工作在样本高效优化方面提供了实际进展，并揭示了有效贝叶斯优化的关键因素。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) can encode complex relationships in their latentspaces, yet harnessing them for optimization under uncertainty remainschallenging. We address this gap with a novel architecture that reframes LLMfinetuning as Gaussian process (GP) marginal likelihood optimization via deepkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPsto preserve the benefits of both - LLMs to provide a rich and flexible inputspace for Bayesian optimization and - GPs to model this space with predictiveuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reactionoptimization, our method nearly doubles the discovery rate of high-performingreactions compared to static LLM embeddings (from 24% to 43% coverage of thetop 5% reactions in just 50 optimization iterations). We also observe a 14%improvement over domain-specific representations without requiring specializedfeatures. Extensive empirical evaluation across 19 benchmarks - ranging fromgeneral chemistry to reaction and molecular property optimization -demonstrates our method's robustness, generality, and consistent improvementsacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),(3) pretraining domains (chemistry-related or general-purpose) and (4)hyperparameter settings (tuned once on a single dataset). Finally, we explainthese improvements: joint LLM-GP optimization through marginal likelihoodimplicitly performs contrastive learning, aligning representations to produce(1) better-structured embedding spaces, (2) improved uncertainty calibration,and (3) more efficient sampling - without requiring any external loss. Thiswork provides both practical advances in sample-efficient optimization andinsights into what makes effective Bayesian optimization.</description>
      <author>example@mail.com (Bojana Ranković, Philippe Schwaller)</author>
      <guid isPermaLink="false">2504.06265v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Resource-efficient Inference with Foundation Model Programs</title>
      <link>http://arxiv.org/abs/2504.07247v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种利用基础模型程序来降低大型语言和视觉模型在生产部署中的推理时间资源成本的方法。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言和视觉模型在生产部署中的应用，其推理时间的资源成本成为了一个日益严峻的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种方法，以减少这些模型在运行时的资源消耗。&lt;h4&gt;方法&lt;/h4&gt;论文提出的方法将任务转化为程序，然后学习一个资源分配策略，该策略在每个输入上为每个程序模块选择不同资源成本和性能的基础模型‘后端’。对于简单的子任务使用较小的后端，而对于更复杂的子任务则利用更大、更强大的模型。&lt;h4&gt;主要发现&lt;/h4&gt;在两个新的“流式”视觉问答任务上评估了该方法，结果表明与单一的多模态模型相比，该实现实现了高达98%的资源节约，同时精度损失最小，展示了其可扩展和资源高效的多模态推理潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法为解决大型语言和视觉模型在部署中的资源成本问题提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The inference-time resource costs of large language and vision models presenta growing challenge in production deployments. We propose the use of foundationmodel programs, i.e., programs that can invoke foundation models with varyingresource costs and performance, as an approach to this problem. Specifically,we present a method that translates a task into a program, then learns a policyfor resource allocation that, on each input, selects foundation model"backends" for each program module. The policy uses smaller, cheaper backendsto handle simpler subtasks, while allowing more complex subtasks to leveragelarger, more capable models. We evaluate the method on two new "streaming"visual question-answering tasks in which a system answers a question on asequence of inputs, receiving ground-truth feedback after each answer. Comparedto monolithic multi-modal models, our implementation achieves up to 98%resource savings with minimal accuracy loss, demonstrating its potential forscalable and resource-efficient multi-modal inference.</description>
      <author>example@mail.com (Lunyiu Nie, Zhimin Ding, Kevin Yu, Marco Cheung, Chris Jermaine, Swarat Chaudhuri)</author>
      <guid isPermaLink="false">2504.07247v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>A Multimedia Analytics Model for the Foundation Model Era</title>
      <link>http://arxiv.org/abs/2504.06138v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个针对基础模型时代的综合多媒体分析模型，旨在解决现有概念模型无法充分捕捉强大AI范式带来的复杂性。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型和代理人工智能的快速发展，多媒体分析领域正在经历变革，但现有的概念模型未能充分反映这一变化。&lt;h4&gt;目的&lt;/h4&gt;为了弥合这一差距，本文提出了一个专门为基础模型时代设计的多媒体分析模型。&lt;h4&gt;方法&lt;/h4&gt;该模型基于视觉分析、多媒体分析、知识生成、分析任务定义、混合倡议指导和人机协同强化学习等领域的现有框架，强调基于视觉分析代理的集成人机团队。&lt;h4&gt;主要发现&lt;/h4&gt;模型的核心在于专家用户与半自主分析过程之间无缝且明确可区分的交互渠道，确保用户意图与AI行为之间的持续对齐。此外，模型还解决了敏感领域如情报分析、调查性新闻等处理复杂、高风险数据的实际问题。&lt;h4&gt;结论&lt;/h4&gt;通过详细案例研究，本文展示了该模型如何促进对多媒体分析解决方案的深入理解和针对性改进。该概念框架明确捕捉了专家用户如何与AI驱动的多媒体分析系统进行最优交互和指导，为系统设计、比较和未来研究指明了方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：快速发展的基础模型和代理人工智能正在通过实现人类与分析系统之间更丰富、更复杂的交互来改变多媒体分析。然而，现有的视觉和多媒体分析概念模型并不能充分捕捉这些强大AI范式带来的复杂性。为了填补这一差距，我们提出了一种针对基础模型时代的综合多媒体分析模型。在视觉分析、多媒体分析、知识生成、分析任务定义、混合倡议指导和人机协同强化学习等现有框架的基础上，我们的模型强调基于视觉分析代理的集成人机团队。模型的核心在于专家用户与半自主分析过程之间无缝且明确可区分的交互渠道，确保用户意图与AI行为之间的持续对齐。模型解决了敏感领域如情报分析、调查性新闻等处理复杂、高风险数据的实际问题。通过详细案例研究，我们展示了我们的模型如何促进对多媒体分析解决方案的深入理解和针对性改进。通过明确捕捉专家用户如何与AI驱动的多媒体分析系统进行最优交互和指导，我们的概念框架为系统设计、比较和未来研究指明了方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advances in Foundation Models and agentic Artificial Intelligenceare transforming multimedia analytics by enabling richer, more sophisticatedinteractions between humans and analytical systems. Existing conceptual modelsfor visual and multimedia analytics, however, do not adequately capture thecomplexity introduced by these powerful AI paradigms. To bridge this gap, wepropose a comprehensive multimedia analytics model specifically designed forthe foundation model era. Building upon established frameworks from visualanalytics, multimedia analytics, knowledge generation, analytic taskdefinition, mixed-initiative guidance, and human-in-the-loop reinforcementlearning, our model emphasizes integrated human-AI teaming based on visualanalytics agents from both technical and conceptual perspectives. Central tothe model is a seamless, yet explicitly separable, interaction channel betweenexpert users and semi-autonomous analytical processes, ensuring continuousalignment between user intent and AI behavior. The model addresses practicalchallenges in sensitive domains such as intelligence analysis, investigativejournalism, and other fields handling complex, high-stakes data. We illustratethrough detailed case studies how our model facilitates deeper understandingand targeted improvement of multimedia analytics solutions. By explicitlycapturing how expert users can optimally interact with and guide AI-poweredmultimedia analytics systems, our conceptual framework sets a clear directionfor system design, comparison, and future research.</description>
      <author>example@mail.com (Marcel Worring, Jan Zahálka, Stef van den Elzen, Maximilian T. Fischer, Daniel A. Keim)</author>
      <guid isPermaLink="false">2504.06138v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>SINCon: Mitigate LLM-Generated Malicious Message Injection Attack for Rumor Detection</title>
      <link>http://arxiv.org/abs/2504.07135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SINCon的防御机制，用于提高基于Message Propagation Trees的谣言检测系统对利用大型语言模型生成和注入恶意信息的攻击的抵抗力。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型（LLMs）的快速发展，基于Message Propagation Trees（MPTs）的谣言检测系统正面临来自利用LLMs生成和注入恶意信息的对抗性攻击的威胁。&lt;h4&gt;目的&lt;/h4&gt;旨在提高模型对LLM驱动的信息注入攻击的抵抗力，同时保持对干净数据的分类准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为SINCon的防御机制，该机制通过对比学习鼓励模型学习到具有不同重要性的节点对预测具有更均匀影响的图表示。&lt;h4&gt;主要发现&lt;/h4&gt;在Twitter和Weibo数据集上的大量实验表明，SINCon不仅保持了在干净数据上的高分类准确性，而且显著增强了对抗LLM驱动的信息注入攻击的抵抗力。&lt;h4&gt;结论&lt;/h4&gt;SINCon是一种有效的防御机制，可以增强基于MPTs的谣言检测系统对LLM驱动的攻击的抵抗力，同时保持对干净数据的分类性能。&lt;h4&gt;翻译&lt;/h4&gt;在快速发展的LLMs时代，基于消息传播树（MPTs）的谣言检测系统，尤其是那些基于MPTs的系统，正面临来自利用LLMs生成和注入恶意信息的对抗性攻击的威胁。现有方法基于不同节点对预测具有不同影响程度的假设。它们将具有高预测影响度的节点定义为重要节点，并针对这些节点进行攻击。如果模型对节点预测影响度的处理更加均匀，攻击者将更难针对具有高预测影响度的节点。在本文中，我们提出了一个名为SINCon的防御机制，该机制鼓励模型学习具有不同重要性的节点对预测具有更均匀影响的图表示。在Twitter和Weibo数据集上的大量实验表明，SINCon不仅保持了在干净数据上的高分类准确性，而且显著增强了抵抗LLM驱动的信息注入攻击的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of rapidly evolving large language models (LLMs), state-of-the-artrumor detection systems, particularly those based on Message Propagation Trees(MPTs), which represent a conversation tree with the post as its root and thereplies as its descendants, are facing increasing threats from adversarialattacks that leverage LLMs to generate and inject malicious messages. Existingmethods are based on the assumption that different nodes exhibit varyingdegrees of influence on predictions. They define nodes with high predictiveinfluence as important nodes and target them for attacks. If the model treatsnodes' predictive influence more uniformly, attackers will find it harder totarget high predictive influence nodes. In this paper, we propose Similarizingthe predictive Influence of Nodes with Contrastive Learning (SINCon), a defensemechanism that encourages the model to learn graph representations where nodeswith varying importance have a more uniform influence on predictions. Extensiveexperiments on the Twitter and Weibo datasets demonstrate that SINCon not onlypreserves high classification accuracy on clean data but also significantlyenhances resistance against LLM-driven message injection attacks.</description>
      <author>example@mail.com (Mingqing Zhang, Qiang Liu, Xiang Tao, Shu Wu, Liang Wang)</author>
      <guid isPermaLink="false">2504.07135v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>LATTE: Lightweight Attention-based Traffic Accident Anticipation Engine</title>
      <link>http://arxiv.org/abs/2504.04103v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accept by Information Fusion (Elsevier)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为LATTE的轻量级注意力交通事故预测引擎，该引擎在资源受限的环境中能够准确预测实时交通事故，并具有高效的计算性能。&lt;h4&gt;背景&lt;/h4&gt;准确预测实时交通事故在自动驾驶中是一个关键挑战，尤其是在资源受限的环境中，现有的解决方案往往计算开销高或无法充分解决不断变化的交通场景的不确定性。&lt;h4&gt;目的&lt;/h4&gt;提出一种轻量级注意力交通事故预测引擎，以解决上述挑战。&lt;h4&gt;方法&lt;/h4&gt;LATTE采用高效多尺度空间聚合（EMSA）来捕捉不同尺度的空间特征，记忆注意力聚合（MAA）来增强时间建模，以及辅助自我注意力聚合（AAA）来提取扩展序列中的潜在依赖关系。此外，LATTE还集成了Flamingo警报辅助系统（FAA），利用视觉语言模型提供实时、认知可访问的口头危险警报，提高乘客对情境的认识。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集（DAD、CCD、A3D）上的评估表明，LATTE具有优越的预测能力和计算效率。在DAD基准上，LATTE达到了89.74%的平均精度（AP），比第二好的模型平均时间到事故（mTTA）高出5.4%，在80%的召回率（TTA@R80）下保持有竞争力的mTTA（4.04秒），并在不同的驾驶条件下展示了稳健的事故预测能力。其轻量级设计将浮点运算（FLOPs）减少了93.14%，参数数量减少了31.58%，在资源有限的硬件上实现实时运行而不影响性能。&lt;h4&gt;结论&lt;/h4&gt;LATTE的有效性得到了消融研究的证实，而可视化失败案例分析突出了其实际应用性和改进领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在自动驾驶中，准确预测实时交通事故是一个关键挑战，尤其是在资源受限的环境中。现有解决方案通常存在计算开销高或无法充分解决不断变化的交通场景的不确定性。本文提出了一种名为LATTE的轻量级注意力交通事故预测引擎，该引擎将计算效率与最先进的性能相结合。LATTE采用高效多尺度空间聚合（EMSA）来捕捉不同尺度的空间特征，记忆注意力聚合（MAA）来增强时间建模，以及辅助自我注意力聚合（AAA）来提取扩展序列中的潜在依赖关系。此外，LATTE还集成了Flamingo警报辅助系统（FAA），利用视觉语言模型提供实时、认知可访问的口头危险警报，提高乘客对情境的认识。在基准数据集（DAD、CCD、A3D）上的评估表明，LATTE具有优越的预测能力和计算效率。在DAD基准上，LATTE达到了89.74%的平均精度（AP），比第二好的模型平均时间到事故（mTTA）高出5.4%，在80%的召回率（TTA@R80）下保持有竞争力的mTTA（4.04秒），并在不同的驾驶条件下展示了稳健的事故预测能力。其轻量级设计将浮点运算（FLOPs）减少了93.14%，参数数量减少了31.58%，在资源有限的硬件上实现实时运行而不影响性能。消融研究证实了LATTE架构组件的有效性，而可视化失败案例分析突出了其实际应用性和改进领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting traffic accidents in real-time is a critical challengein autonomous driving, particularly in resource-constrained environments.Existing solutions often suffer from high computational overhead or fail toadequately address the uncertainty of evolving traffic scenarios. This paperintroduces LATTE, a Lightweight Attention-based Traffic Accident AnticipationEngine, which integrates computational efficiency with state-of-the-artperformance. LATTE employs Efficient Multiscale Spatial Aggregation (EMSA) tocapture spatial features across scales, Memory Attention Aggregation (MAA) toenhance temporal modeling, and Auxiliary Self-Attention Aggregation (AAA) toextract latent dependencies over extended sequences. Additionally, LATTEincorporates the Flamingo Alert-Assisted System (FAA), leveraging avision-language model to provide real-time, cognitively accessible verbalhazard alerts, improving passenger situational awareness. Evaluations onbenchmark datasets (DAD, CCD, A3D) demonstrate LATTE's superior predictivecapabilities and computational efficiency. LATTE achieves state-of-the-art89.74% Average Precision (AP) on DAD benchmark, with 5.4% higher meanTime-To-Accident (mTTA) than the second-best model, and maintains competitivemTTA at a Recall of 80% (TTA@R80) (4.04s) while demonstrating robust accidentanticipation across diverse driving conditions. Its lightweight design deliversa 93.14% reduction in floating-point operations (FLOPs) and a 31.58% decreasein parameter count (Params), enabling real-time operation on resource-limitedhardware without compromising performance. Ablation studies confirm theeffectiveness of LATTE's architectural components, while visualizations andfailure case analyses highlight its practical applicability and areas forenhancement.</description>
      <author>example@mail.com (Jiaxun Zhang, Yanchen Guan, Chengyue Wang, Haicheng Liao, Guohui Zhang, Zhenning Li)</author>
      <guid isPermaLink="false">2504.04103v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Boundary representation learning via Transformer</title>
      <link>http://arxiv.org/abs/2504.07134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为边界表示变换器（BRT）的新方法，该方法将Transformer网络应用于边界表示（B-rep）模型的学习，以解决计算机辅助设计（CAD）领域的挑战。&lt;h4&gt;背景&lt;/h4&gt;近年来，由Transformer网络驱动的生成式人工智能在自然语言处理、计算机视觉和图形领域取得了显著成功。然而，Transformer在计算机辅助设计（CAD）领域的应用，尤其是处理边界表示（B-rep）模型，还相对较少。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文提出了Boundary Representation Transformer（BRT），这是一种新的方法，用于将Transformer适应于B-rep学习。&lt;h4&gt;方法&lt;/h4&gt;BRT提出了一个连续几何嵌入方法，将B-rep表面（修剪和未修剪的）编码为贝塞尔三角形，在不进行离散化的情况下保留其形状和连续性。此外，BRT还采用了一种拓扑感知的嵌入方法，将几何嵌入组织成一个序列的离散标记，适合于Transformer，以捕获B-rep模型中的几何和拓扑特征。这使得Transformer的关注机制能够有效地学习B-rep模型中边界元素的形状模式和上下文语义。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量的实验，证明了BRT在部分分类和特征识别任务中达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;BRT为B-rep模型学习提供了一种有效的解决方案，并展示了Transformer在CAD领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent rise of generative artificial intelligence (AI), powered byTransformer networks, has achieved remarkable success in natural languageprocessing, computer vision, and graphics. However, the application ofTransformers in computer-aided design (CAD), particularly for processingboundary representation (B-rep) models, remains largely unexplored. To bridgethis gap, this paper introduces Boundary Representation Transformer (BRT), anovel method adapting Transformer for B-rep learning. B-rep models pose uniquechallenges due to their irregular topology and continuous geometricdefinitions, which are fundamentally different from the structured and discretedata Transformers are designed for. To address this, BRT proposes a continuousgeometric embedding method that encodes B-rep surfaces (trimmed and untrimmed)into B\'ezier triangles, preserving their shape and continuity withoutdiscretization. Additionally, BRT employs a topology-aware embedding methodthat organizes these geometric embeddings into a sequence of discrete tokenssuitable for Transformers, capturing both geometric and topologicalcharacteristics within B-rep models. This enables the Transformer's attentionmechanism to effectively learn shape patterns and contextual semantics ofboundary elements in a B-rep model. Extensive experiments demonstrate that BRTachieves state-of-the-art performance in part classification and featurerecognition tasks.</description>
      <author>example@mail.com (Qiang Zou, Lizhen Zhu)</author>
      <guid isPermaLink="false">2504.07134v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Are We Done with Object-Centric Learning?</title>
      <link>http://arxiv.org/abs/2504.07092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要讨论了以对象为中心的学习（OCL）方法，该方法旨在学习仅编码对象的表示，并从场景中的其他对象或背景线索中隔离出来。文章提出了OCL方法在无监督对象发现、样本高效组合和结构化环境建模等方面的应用，并介绍了一种新的无监督探测方法OCCAM，以解决现实应用中的挑战。&lt;h4&gt;背景&lt;/h4&gt;OCL方法旨在学习仅编码对象的表示，并从场景中的其他对象或背景线索中隔离出来，以支持各种目标，包括分布外（OOD）泛化、样本高效组合和结构化环境的建模。&lt;h4&gt;目的&lt;/h4&gt;OCL方法的目标是获得以对象为中心的表示，以支持OOD泛化、样本高效组合和结构化环境的建模。&lt;h4&gt;方法&lt;/h4&gt;文章提出了一种新的无监督探测方法OCCAM，该方法通过研究由虚假背景线索引起的OOD泛化挑战，证明了基于分割的对象编码在性能上优于基于槽的OCL方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，基于分割的对象编码在OOD对象发现基准测试中表现出色，且OCL方法可以扩展到基础模型，并能够处理可变数量的槽。&lt;h4&gt;结论&lt;/h4&gt;尽管OCL方法在实现对象为中心的表示方面取得了很大进展，但如何将场景中分离对象的能力与更广泛的OCL目标（如OOD泛化）联系起来仍是一个关键问题。文章提出了OCCAM方法，并提供了OCL社区的工具箱，以用于可扩展的对象为中心的表示，并关注实际应用和基本问题，如理解人类认知中的对象感知。&lt;h4&gt;翻译&lt;/h4&gt;摘要：以对象为中心的学习（OCL）旨在学习仅编码对象的表示，从场景中的其他对象或背景线索中隔离出来。这种方法支持各种目标，包括分布外（OOD）泛化、样本高效组合和结构化环境的建模。大多数研究集中在开发无监督机制，将对象分离到表示空间中的离散槽中，并通过无监督对象发现进行评估。然而，随着近期样本高效的分割模型的出现，我们可以在像素空间中分离对象并独立编码它们。这实现了在OOD对象发现基准测试上的显著零样本性能，可扩展到基础模型，并且可以开箱即用地处理可变数量的槽。因此，OCL方法获得对象为中心的表示的目标已经基本实现。尽管取得了这些进展，但一个关键问题仍然存在：在场景中分离对象的能力如何有助于更广泛的OCL目标，如OOD泛化？我们通过OCL的视角来研究由虚假背景线索引起的OOD泛化挑战。我们提出了一种新颖的无监督探测方法，称为OCCAM，证明了基于分割的个体对象编码在性能上显著优于基于槽的OCL方法。然而，现实应用中仍然存在挑战。我们为OCL社区提供了工具箱，以使用可扩展的对象为中心的表示，并专注于实际应用和基本问题，例如理解人类认知中的对象感知。我们的代码可在以下链接找到：https://github.com/AlexanderRubinstein/OCCAM&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object-centric learning (OCL) seeks to learn representations that only encodean object, isolated from other objects or background cues in a scene. Thisapproach underpins various aims, including out-of-distribution (OOD)generalization, sample-efficient composition, and modeling of structuredenvironments. Most research has focused on developing unsupervised mechanismsthat separate objects into discrete slots in the representation space,evaluated using unsupervised object discovery. However, with recentsample-efficient segmentation models, we can separate objects in the pixelspace and encode them independently. This achieves remarkable zero-shotperformance on OOD object discovery benchmarks, is scalable to foundationmodels, and can handle a variable number of slots out-of-the-box. Hence, thegoal of OCL methods to obtain object-centric representations has been largelyachieved. Despite this progress, a key question remains: How does the abilityto separate objects within a scene contribute to broader OCL objectives, suchas OOD generalization? We address this by investigating the OOD generalizationchallenge caused by spurious background cues through the lens of OCL. Wepropose a novel, training-free probe called $\textbf{Object-CentricClassification with Applied Masks (OCCAM)}$, demonstrating thatsegmentation-based encoding of individual objects significantly outperformsslot-based OCL methods. However, challenges in real-world applications remain.We provide the toolbox for the OCL community to use scalable object-centricrepresentations, and focus on practical applications and fundamental questions,such as understanding object perception in human cognition. Our code isavailable $\href{https://github.com/AlexanderRubinstein/OCCAM}{here}$.</description>
      <author>example@mail.com (Alexander Rubinstein, Ameya Prabhu, Matthias Bethge, Seong Joon Oh)</author>
      <guid isPermaLink="false">2504.07092v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
  <item>
      <title>Generalized Semantic Contrastive Learning via Embedding Side Information for Few-Shot Object Detection</title>
      <link>http://arxiv.org/abs/2504.07060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by T-PAMI (IEEE Transactions on Pattern Analysis and Machine  Intelligence)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法来解决少量样本目标检测（FSOD）问题，通过引入侧信息来缓解特征空间和样本视角带来的负面影响，并提高模型在未知场景中的适应性。&lt;h4&gt;背景&lt;/h4&gt;FSOD旨在通过少量训练样本检测新类别对象，但面临基础类别空间中数据有限的问题。&lt;h4&gt;目的&lt;/h4&gt;提高FSOD在未知场景中的检测能力。&lt;h4&gt;方法&lt;/h4&gt;1. 利用嵌入侧信息构建知识矩阵，量化基础类别和新类别之间的语义关系。2. 开发基于侧信息的上下文语义监督对比学习，增强语义相似类别之间的区分度。3. 引入侧信息引导的区域感知掩码模块，通过反事实解释找到和放弃区分相似类别的偏置信息，进一步细化判别表示空间。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入侧信息和改进的特征表示学习，模型在多个基准数据集上优于现有方法，显著提高了FSOD在多数射击/分割情况下的能力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效解决FSOD中的特征空间和样本视角问题，提高了模型在未知场景中的检测性能。&lt;h4&gt;翻译&lt;/h4&gt;The objective of few-shot object detection (FSOD) is to detect novel objects with few training samples. The core challenge of this task is how to construct a generalized feature space for novel categories with limited data on the basis of the base category space, which could adapt the learned detection model to unknown scenarios. However, limited by insufficient samples for novel categories, two issues still exist: (1) the features of the novel category are easily implicitly represented by the features of the base category, leading to inseparable classifier boundaries, (2) novel categories with fewer data are not enough to fully represent the distribution, where the model fine-tuning is prone to overfitting. To address these issues, we introduce the side information to alleviate the negative influences derived from the feature space and sample viewpoints and formulate a novel generalized feature representation learning method for FSOD. Specifically, we first utilize embedding side information to construct a knowledge matrix to quantify the semantic relationship between the base and novel categories. Then, to strengthen the discrimination between semantically similar categories, we further develop contextual semantic supervised contrastive learning which embeds side information. Furthermore, to prevent overfitting problems caused by sparse samples, a side-information guided region-aware masked module is introduced to augment the diversity of samples, which finds and abandons biased information that discriminates between similar categories via counterfactual explanation, and refines the discriminative representation space further. Extensive experiments using ResNet and ViT backbones on PASCAL VOC, MS COCO, LVIS V1, FSOD-1K, and FSVOD-500 benchmarks demonstrate that our model outperforms the previous state-of-the-art methods, significantly improving the ability of FSOD in most shots/splits.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The objective of few-shot object detection (FSOD) is to detect novel objectswith few training samples. The core challenge of this task is how to constructa generalized feature space for novel categories with limited data on the basisof the base category space, which could adapt the learned detection model tounknown scenarios. However, limited by insufficient samples for novelcategories, two issues still exist: (1) the features of the novel category areeasily implicitly represented by the features of the base category, leading toinseparable classifier boundaries, (2) novel categories with fewer data are notenough to fully represent the distribution, where the model fine-tuning isprone to overfitting. To address these issues, we introduce the sideinformation to alleviate the negative influences derived from the feature spaceand sample viewpoints and formulate a novel generalized feature representationlearning method for FSOD. Specifically, we first utilize embedding sideinformation to construct a knowledge matrix to quantify the semanticrelationship between the base and novel categories. Then, to strengthen thediscrimination between semantically similar categories, we further developcontextual semantic supervised contrastive learning which embeds sideinformation. Furthermore, to prevent overfitting problems caused by sparsesamples, a side-information guided region-aware masked module is introduced toaugment the diversity of samples, which finds and abandons biased informationthat discriminates between similar categories via counterfactual explanation,and refines the discriminative representation space further. Extensiveexperiments using ResNet and ViT backbones on PASCAL VOC, MS COCO, LVIS V1,FSOD-1K, and FSVOD-500 benchmarks demonstrate that our model outperforms theprevious state-of-the-art methods, significantly improving the ability of FSODin most shots/splits.</description>
      <author>example@mail.com (Ruoyu Chen, Hua Zhang, Jingzhi Li, Li Liu, Zhen Huang, Xiaochun Cao)</author>
      <guid isPermaLink="false">2504.07060v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>EDIT: Enhancing Vision Transformers by Mitigating Attention Sink through an Encoder-Decoder Architecture</title>
      <link>http://arxiv.org/abs/2504.06738v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EDIT（编码器-解码器图像变换器）的新型架构，旨在减轻视觉变换器模型中观察到的注意力汇聚现象。&lt;h4&gt;背景&lt;/h4&gt;注意力汇聚现象是指过多的注意力集中在[CLS]标记上，从而扭曲模型有效处理图像块的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，研究者引入了一种层对齐的编码器-解码器架构，其中编码器使用自注意力来处理图像块，而解码器则使用交叉注意力来关注[CLS]标记。&lt;h4&gt;方法&lt;/h4&gt;与传统的编码器-解码器框架不同，EDIT允许解码器从低级特征开始提取信息，并逐层逐步细化表示。&lt;h4&gt;主要发现&lt;/h4&gt;通过序列注意力图证明了EDIT的可解释性，这些图说明了逐层对关键图像特征的精细关注。&lt;h4&gt;结论&lt;/h4&gt;在ImageNet-1k和ImageNet-21k上的实验以及迁移学习任务中，EDIT在性能上超过了DeiT3模型，这些结果表明EDIT的设计在解决注意力汇聚和改进视觉特征提取方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种新的架构EDIT（编码器-解码器图像变换器），旨在缓解在视觉变换器模型中观察到的注意力汇聚现象。当注意力过多地集中在[CLS]标记上时，会发生注意力汇聚现象，这会扭曲模型有效处理图像块的能力。为了解决这个问题，我们引入了一种层对齐的编码器-解码器架构，其中编码器使用自注意力来处理图像块，而解码器则使用交叉注意力来关注[CLS]标记。与传统的编码器-解码器框架不同，EDIT允许解码器从低级特征开始提取信息，并逐层逐步细化表示。通过序列注意力图证明了EDIT的可解释性，这些图说明了逐层对关键图像特征的精细关注。在ImageNet-1k和ImageNet-21k上的实验以及迁移学习任务中，EDIT在性能上超过了DeiT3模型，这些结果表明EDIT的设计在解决注意力汇聚和改进视觉特征提取方面是有效的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose EDIT (Encoder-Decoder Image Transformer), a novelarchitecture designed to mitigate the attention sink phenomenon observed inVision Transformer models. Attention sink occurs when an excessive amount ofattention is allocated to the [CLS] token, distorting the model's ability toeffectively process image patches. To address this, we introduce alayer-aligned encoder-decoder architecture, where the encoder utilizesself-attention to process image patches, while the decoder uses cross-attentionto focus on the [CLS] token. Unlike traditional encoder-decoder framework,where the decoder depends solely on high-level encoder representations, EDITallows the decoder to extract information starting from low-level features,progressively refining the representation layer by layer. EDIT is naturallyinterpretable demonstrated through sequential attention maps, illustrating therefined, layer-by-layer focus on key image features. Experiments on ImageNet-1kand ImageNet-21k, along with transfer learning tasks, show that EDIT achievesconsistent performance improvements over DeiT3 models. These results highlightthe effectiveness of EDIT's design in addressing attention sink and improvingvisual feature extraction.</description>
      <author>example@mail.com (Wenfeng Feng, Guoying Sun)</author>
      <guid isPermaLink="false">2504.06738v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>RayFronts: Open-Set Semantic Ray Frontiers for Online Scene Understanding and Exploration</title>
      <link>http://arxiv.org/abs/2504.06994v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Open-set语义映射对开放世界机器人至关重要，现有方法在深度范围或限制性环境中仅映射超出范围的实体，无法结合近场和远场观察，且在细粒度语义和效率之间进行权衡。本文介绍了RayFronts，一种统一的表示方法，它能够实现密集和超出范围的语义映射。&lt;h4&gt;背景&lt;/h4&gt;开放世界机器人的语义映射对机器人的导航和交互能力至关重要，但目前的方法存在深度范围限制、效率与细粒度语义之间的权衡等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，实现既密集又高效的语义映射，以便机器人能够在近场和远场范围内做出明智的决策。&lt;h4&gt;方法&lt;/h4&gt;RayFronts通过编码任务无关的开集语义到近场体素和地图边界编码的远场射线，从而减少搜索体积，并在Orin AGX上以8.84 Hz的频率运行。此外，提出了一种规划无关的评估框架，以捕捉在线超出范围搜索和探索的效用。&lt;h4&gt;主要发现&lt;/h4&gt;在近场语义的基准测试中，RayFronts的细粒度图像编码提供了1.34倍的零样本3D语义分割性能，并通过16.5倍的吞吐量来提高效率。与最接近的在线基线相比，RayFronts将搜索体积减少了2.2倍。&lt;h4&gt;结论&lt;/h4&gt;RayFronts是一种有效的语义映射方法，能够在保证性能的同时提高效率，并通过新的评估框架改善了在线超出范围搜索和探索的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-set semantic mapping is crucial for open-world robots. Current mappingapproaches either are limited by the depth range or only map beyond-rangeentities in constrained settings, where overall they fail to combinewithin-range and beyond-range observations. Furthermore, these methods make atrade-off between fine-grained semantics and efficiency. We introduceRayFronts, a unified representation that enables both dense and beyond-rangeefficient semantic mapping. RayFronts encodes task-agnostic open-set semanticsto both in-range voxels and beyond-range rays encoded at map boundaries,empowering the robot to reduce search volumes significantly and make informeddecisions both within &amp; beyond sensory range, while running at 8.84 Hz on anOrin AGX. Benchmarking the within-range semantics shows that RayFronts'sfine-grained image encoding provides 1.34x zero-shot 3D semantic segmentationperformance while improving throughput by 16.5x. Traditionally, online mappingperformance is entangled with other system components, complicating evaluation.We propose a planner-agnostic evaluation framework that captures the utilityfor online beyond-range search and exploration, and show RayFronts reducessearch volume 2.2x more efficiently than the closest online baselines.</description>
      <author>example@mail.com (Omar Alama, Avigyan Bhattacharya, Haoyang He, Seungchan Kim, Yuheng Qiu, Wenshan Wang, Cherie Ho, Nikhil Keetha, Sebastian Scherer)</author>
      <guid isPermaLink="false">2504.06994v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>UAV Position Estimation using a LiDAR-based 3D Object Detection Method</title>
      <link>http://arxiv.org/abs/2504.07028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在无GPS环境中，通过深度学习方法进行3D物体检测，计算配备LiDAR传感器的无人机（UAV）与无人地面车（UGV）之间相对位置的方法。&lt;h4&gt;背景&lt;/h4&gt;在GPS信号不可用的环境中，精确定位无人机需要非GPS依赖的定位技术。&lt;h4&gt;目的&lt;/h4&gt;利用深度学习方法和3D检测算法确定无人机的相对位置。&lt;h4&gt;方法&lt;/h4&gt;通过评估LiDAR传感器数据，采用PointPillars算法结合列体素点云表示和2D卷积神经网络（CNN）生成独特的点云特征来识别无人机。定位方法利用点云分割、欧几里得聚类和预定义启发式算法获取无人机相对位置。然后，将两种方法的输出与参考真值解进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;PointPillars算法有效地用于识别无人机并计算其相对位置。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了深度学习方法和3D检测算法在无GPS环境中无人机定位的可行性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了应用深度学习方法进行3D物体检测，从配备激光雷达传感器的无人机（UAV）在无GPS环境下计算无人机与无人地面车（UGV）之间相对位置的方法。通过评估激光雷达传感器数据，采用PointPillars算法（结合列体素点云表示和2D卷积神经网络CNN）生成表示待识别物体的独特点云特征，识别无人机。当前的定位方法利用点云分割、欧几里得聚类和预定义启发式算法来获得无人机的相对位置。然后，将两种方法的结果与参考真值解进行比较。研究结果表明，PointPillars算法有效地用于识别无人机并计算其相对位置，证明了在无GPS环境中无人机定位的深度学习方法和3D检测算法的可行性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/PLANS53410.2023.10139979&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the use of applying a deep learning approach for 3Dobject detection to compute the relative position of an Unmanned Aerial Vehicle(UAV) from an Unmanned Ground Vehicle (UGV) equipped with a LiDAR sensor in aGPS-denied environment. This was achieved by evaluating the LiDAR sensor's datathrough a 3D detection algorithm (PointPillars). The PointPillars algorithmincorporates a column voxel point-cloud representation and a 2D ConvolutionalNeural Network (CNN) to generate distinctive point-cloud features representingthe object to be identified, in this case, the UAV. The current localizationmethod utilizes point-cloud segmentation, Euclidean clustering, and predefinedheuristics to obtain the relative position of the UAV. Results from the twomethods were then compared to a reference truth solution.</description>
      <author>example@mail.com (Uthman Olawoye, Jason N. Gross)</author>
      <guid isPermaLink="false">2504.07028v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>FACT: Multinomial Misalignment Classification for Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2504.06627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at SCIA 2025 (the Scandinavian Conference on Image Analysis  2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FACT的方法，用于预测注册激光雷达点云对的配准质量（即注册误差）。该方法对于大型自动注册的3D模型的质量保证非常有用。&lt;h4&gt;背景&lt;/h4&gt;目前已有研究关注于注册错误的二元配准分类，本文将这一研究推广到多项式配准分类。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效预测注册点云对配准质量的方法，并提高现有方法的性能。&lt;h4&gt;方法&lt;/h4&gt;FACT从注册的点云对中提取局部特征，并使用基于点变换器的网络对这些特征进行处理，以预测不匹配类别。该方法引入了一种自定义的回归分类损失函数，结合了交叉熵和Wasserstein损失，并证明了其优于直接回归和先前的二元分类。&lt;h4&gt;主要发现&lt;/h4&gt;FACT能够成功分类使用经典ICP和GeoTransformer注册的点云对，而其他选择，如标准点云质量指标和注册残差，在预测不匹配方面表现不佳。在CorAl方法引入的合成扰动点云任务中，FACT的性能显著优于CorAl。此外，FACT还可以帮助专家纠正不匹配的点云图。&lt;h4&gt;结论&lt;/h4&gt;FACT是一种有效的点云配准质量预测方法，能够提高现有技术的性能，并有助于专家进行点云图的校正。&lt;h4&gt;翻译&lt;/h4&gt;We present FACT, a method for predicting alignment quality (i.e., registration error) of registered lidar point cloud pairs. This is useful e.g. for quality assurance of large, automatically registered 3D models. FACT extracts local features from a registered pair and processes them with a point transformer-based network to predict a misalignment class. We generalize prior work that study binary alignment classification of registration errors, by recasting it as multinomial misalignment classification. To achieve this, we introduce a custom regression-by-classification loss function that combines the cross-entropy and Wasserstein losses, and demonstrate that it outperforms both direct regression and prior binary classification. FACT successfully classifies point-cloud pairs registered with both the classical ICP and GeoTransformer, while other choices, such as standard point-cloud-quality metrics and registration residuals are shown to be poor choices for predicting misalignment. On a synthetically perturbed point-cloud task introduced by the CorAl method, we show that FACT achieves substantially better performance than CorAl. Finally, we demonstrate how FACT can assist experts in correcting misaligned point-cloud maps. Our code is available at https://github.com/LudvigDillen/FACT_for_PCMC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present FACT, a method for predicting alignment quality (i.e.,registration error) of registered lidar point cloud pairs. This is useful e.g.for quality assurance of large, automatically registered 3D models. FACTextracts local features from a registered pair and processes them with a pointtransformer-based network to predict a misalignment class. We generalize priorwork that study binary alignment classification of registration errors, byrecasting it as multinomial misalignment classification. To achieve this, weintroduce a custom regression-by-classification loss function that combines thecross-entropy and Wasserstein losses, and demonstrate that it outperforms bothdirect regression and prior binary classification. FACT successfully classifiespoint-cloud pairs registered with both the classical ICP and GeoTransformer,while other choices, such as standard point-cloud-quality metrics andregistration residuals are shown to be poor choices for predictingmisalignment. On a synthetically perturbed point-cloud task introduced by theCorAl method, we show that FACT achieves substantially better performance thanCorAl. Finally, we demonstrate how FACT can assist experts in correctingmisaligned point-cloud maps. Our code is available athttps://github.com/LudvigDillen/FACT_for_PCMC.</description>
      <author>example@mail.com (Ludvig Dillén, Per-Erik Forssén, Johan Edstedt)</author>
      <guid isPermaLink="false">2504.06627v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.06958v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了利用强化学习提升多模态大型语言模型在视频理解方面的推理能力，特别是通过RFT（强化微调）和GRPO（分组相对策略优化）技术。&lt;h4&gt;背景&lt;/h4&gt;虽然强化学习在文本和图像领域取得进展，但在视频理解方面的应用还有限。&lt;h4&gt;目的&lt;/h4&gt;旨在通过RFT和GRPO提高视频MLLM的时空感知能力，同时保持其一般能力。&lt;h4&gt;方法&lt;/h4&gt;通过在有限的样本上对时空感知目标进行多任务RFT，开发了VideoChat-R1，这是一种强大的视频MLLM。&lt;h4&gt;主要发现&lt;/h4&gt;VideoChat-R1在时空感知任务上达到了最先进的性能，同时在聊天能力上没有牺牲，并表现出时空推理能力。与Qwen2.5-VL-7B相比，它在时间基准和对象跟踪任务上的性能提高了几倍。此外，它在一般QAbenchmarks如VideoMME、MVBench和Perception Test上的表现也显著提升。&lt;h4&gt;结论&lt;/h4&gt;RFT对于视频MLLM的特定任务增强具有潜力，希望这项工作为视频MLLM中的RL研究提供有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces the use of reinforcement learning to enhance the reasoning capabilities of multimodal large language models (MLLMs) in video understanding, particularly through the techniques of RFT (Reinforcement Fine-Tuning) and GRPO (Group Relative Policy Optimization).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in reinforcement learning have significantly advanced thereasoning capabilities of multimodal large language models (MLLMs). Whileapproaches such as Group Relative Policy Optimization (GRPO) and rule-basedreward mechanisms demonstrate promise in text and image domains, theirapplication to video understanding remains limited. This paper presents asystematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for videoMLLMs, aiming to enhance spatio-temporal perception while maintaining generalcapabilities. Our experiments reveal that RFT is highly data-efficient fortask-specific improvements. Through multi-task RFT on spatio-temporalperception objectives with limited samples, we develop VideoChat-R1, a powerfulvideo MLLM that achieves state-of-the-art performance on spatio-temporalperception tasks without sacrificing chat ability, while exhibiting emergingspatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1boosts performance several-fold in tasks like temporal grounding (+31.8) andobject tracking (+31.2). Additionally, it significantly improves on general QAbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9).Our findings underscore the potential of RFT for specialized task enhancementof Video MLLMs. We hope our work offers valuable insights for future RLresearch in video MLLMs.</description>
      <author>example@mail.com (Xinhao Li, Ziang Yan, Desen Meng, Lu Dong, Xiangyu Zeng, Yinan He, Yali Wang, Yu Qiao, Yi Wang, Limin Wang)</author>
      <guid isPermaLink="false">2504.06958v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning Approach towards Quantum Error Mitigation for Accurate Molecular Energetics</title>
      <link>http://arxiv.org/abs/2504.07077v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络和回归机器学习架构的方法，用于在量子计算机上实现分子哈密顿量的误差缓解（EM）技术，以减少噪声对计算的影响。&lt;h4&gt;背景&lt;/h4&gt;尽管在实现混合量子-经典算法方面付出了大量努力，但由于硬件噪声，这些算法主要局限于原理证明。容忍错误的实现是长期目标，但使用现有错误缓解技术通过当前的噪声中等规模量子（NISQ）设备超越小分子是一项挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法，使用统计学习方法来学习噪声及其随后的缓解，以实现分子哈密顿量的误差缓解，而无需指数级的计算开销。&lt;h4&gt;方法&lt;/h4&gt;设计了一个图神经网络和基于回归的机器学习架构，通过在精心选择的浅层子电路集合上训练，这些子电路遵循原始硬件架构。硬件连接性网络被映射到一个有向图，该图编码了原始门噪声配置文件的信息，以生成神经网络的特性。训练数据在构建基函数时即时生成，从而消除了计算开销。&lt;h4&gt;主要发现&lt;/h4&gt;在预测能量方面，对于几个强相关分子，该方法展示了数量级的改进。&lt;h4&gt;结论&lt;/h4&gt;该研究为在量子计算机上实现高效误差缓解技术提供了一种新的方法，为未来量子计算的应用奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;尽管已经付出了重大努力，但混合量子-经典算法的实现主要限于原理证明，这主要归因于硬件噪声。容忍错误的实现是长期目标。使用现有错误缓解技术通过当前的噪声中等规模量子（NISQ）设备超越小分子一直是一个挑战。然而，统计学习方法是有希望的噪声及其随后缓解的学习方法。我们设计了一个图神经网络和基于回归的机器学习架构，用于分子哈密顿量的实际误差缓解技术的实现，而无需指数级的开销。鉴于量子硬件的短暂相干时间，该机器学习模型使用理想或缓解的期望值在精心选择的浅层子电路集合上训练，这些子电路遵循原始硬件架构。硬件连接性网络被映射到一个有向图，该图编码了原始门噪声配置文件的信息，以生成神经网络的特性。训练数据在构建基函数时即时生成，从而消除了计算开销。我们证明了对于几个强相关分子，在预测能量方面有数量级的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite significant efforts, the realization of the hybrid quantum-classicalalgorithms has predominantly been confined to proof-of-principles, mainly dueto the hardware noise. With fault-tolerant implementation being a long-termgoal, going beyond small molecules with existing error mitigation (EM)techniques with current noisy intermediate scale quantum (NISQ) devices hasbeen a challenge. That being said, statistical learning methods are promisingapproaches to learning the noise and its subsequent mitigation. We devise agraph neural network and regression-based machine learning (ML) architecturefor practical realization of EM techniques for molecular Hamiltonian withoutthe requirement of the exponential overhead. Given the short coherence time ofthe quantum hardware, the ML model is trained with either ideal or mitigatedexpectation values over a judiciously chosen ensemble of shallow sub-circuitsadhering to the native hardware architecture. The hardware connectivity networkis mapped to a directed graph which encodes the information of the native gatenoise profile to generate the features for the neural network. The trainingdata is generated on-the-fly during ansatz construction thus removing thecomputational overhead. We demonstrate orders of magnitude improvements inpredicted energy over a few strongly correlated molecules.</description>
      <author>example@mail.com (Srushti Patil, Dibyendu Mondal, Rahul Maitra)</author>
      <guid isPermaLink="false">2504.07077v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Convolutional Neural Network and Graph Neural Network based Surrogate Models on a Real-World Car External Aerodynamics Dataset</title>
      <link>http://arxiv.org/abs/2504.06699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了两种代理模型方法在预测实际世界数据集上的阻力，并评估了它们在车辆开发过程中的应用。&lt;h4&gt;背景&lt;/h4&gt;空气动力学优化对于开发环保、空气动力学和时尚的汽车至关重要，但空气动力学模拟的耗时性阻碍了这一过程。&lt;h4&gt;目的&lt;/h4&gt;通过比较两种代理模型方法，评估它们在预测实际世界数据集上的阻力性能。&lt;h4&gt;方法&lt;/h4&gt;使用卷积神经网络（CNN）模型和基于图神经网络（GNN）的商业工具进行阻力预测，数据集由来自32个基线车辆几何形状的343个几何形状组成。&lt;h4&gt;主要发现&lt;/h4&gt;CNN方法平均绝对误差为2.3阻力计数，GNN方法为3.8。两种方法在预测阻力方向变化方面均达到约77%的准确性，但在捕捉基线组内部更细微的变化方面表现不一。&lt;h4&gt;结论&lt;/h4&gt;空气动力学专家可以使用这两种方法在两分钟内预测阻力，这比进行模拟快600倍以上，但在捕捉几何形状的更细微细节方面仍有改进空间。&lt;h4&gt;翻译&lt;/h4&gt;摘要：空气动力学优化对于开发环保型、空气动力学和时尚的汽车至关重要，这需要空气动力学专家和设计师之间的紧密合作，而空气动力学模拟的耗时性阻碍了这种合作。代理模型提供了一种可行的解决方案来减少这种开销，但在实际世界的空气动力学数据集中尚未得到检验。我们提出了一种对两种代理建模方法进行对比评估，以预测真实世界数据集上的阻力：一种使用有符号距离场作为输入的卷积神经网络（CNN）模型，以及一种直接处理表面网格的商业工具，基于图神经网络（GNN）。与基于参数化几何形状创建的数据集的研究相比，我们的数据集由来自五个不同汽车项目的32个基线车辆几何形状的343个几何形状组成，反映了典型车辆开发过程中遇到的多样化、自由形式的修改。我们的结果表明，基于CNN的方法实现了2.3阻力计数的平均绝对误差，而基于GNN的方法实现了3.8。两种方法在预测相对于基线几何形状的阻力方向变化方面均达到约77%的准确性。尽管两种方法有效地捕捉了基线组之间的更广泛趋势（来自单个基线几何形状的样本集），但它们在捕捉基线组内部的更细微变化方面表现不一。总之，我们的发现表明，空气动力学专家可以有效地使用这两种方法在两分钟内预测阻力，这比进行模拟快600倍以上。然而，在捕捉几何形状的更细微细节方面仍有改进空间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Aerodynamic optimization is crucial for developing eco-friendly, aerodynamic,and stylish cars, which requires close collaboration between aerodynamicistsand stylists, a collaboration impaired by the time-consuming nature ofaerodynamic simulations. Surrogate models offer a viable solution to reducethis overhead, but they are untested in real-world aerodynamic datasets. Wepresent a comparative evaluation of two surrogate modeling approaches forpredicting drag on a real-world dataset: a Convolutional Neural Network (CNN)model that uses a signed distance field as input and a commercial tool based onGraph Neural Networks (GNN) that directly processes a surface mesh. In contrastto previous studies based on datasets created from parameterized geometries,our dataset comprises 343 geometries derived from 32 baseline vehiclegeometries across five distinct car projects, reflecting the diverse, free-formmodifications encountered in the typical vehicle development process. Ourresults show that the CNN-based method achieves a mean absolute error of 2.3drag counts, while the GNN-based method achieves 3.8. Both methods achieveapproximately 77% accuracy in predicting the direction of drag change relativeto the baseline geometry. While both methods effectively capture the broadertrends between baseline groups (set of samples derived from a single baselinegeometry), they struggle to varying extents in capturing the finerintra-baseline group variations. In summary, our findings suggest thataerodynamicists can effectively use both methods to predict drag in under twominutes, which is at least 600 times faster than performing a simulation.However, there remains room for improvement in capturing the finer details ofthe geometry.</description>
      <author>example@mail.com (Sam Jacob Jacob, Markus Mrosek, Carsten Othmer, Harald Köstler)</author>
      <guid isPermaLink="false">2504.06699v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>TabKAN: Advancing Tabular Data Analysis using Kolmograv-Arnold Network</title>
      <link>http://arxiv.org/abs/2504.06559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 12 figures, 13 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为TabKAN的新框架，该框架利用Kolmogorov-Arnold Networks（KANs）对表格数据进行建模，通过引入可学习的激活函数在边上的优势，提高了可解释性和训练效率。&lt;h4&gt;背景&lt;/h4&gt;表格数据分析由于特征类型异质、缺失值和复杂交互而面临独特挑战。传统的机器学习方法通常优于深度学习方法，但近年来神经架构的进步为替代方案提供了希望。&lt;h4&gt;目的&lt;/h4&gt;提出TabKAN框架，以提升表格数据建模的性能，并提高模型的可解释性和训练效率。&lt;h4&gt;方法&lt;/h4&gt;包括：（1）引入适用于表格数据分析的模块化KAN架构；（2）开发KAN模型的迁移学习框架；（3）开发针对表格数据学习的模型特定可解释性；（4）对二元和多类分类任务中的原始监督学习进行综合评估。&lt;h4&gt;主要发现&lt;/h4&gt;TabKAN在多个公共数据集上的基准测试中表现出色，证明了其在监督学习中的优越性能，并在迁移学习场景中显著优于经典和基于Transformer的模型。&lt;h4&gt;结论&lt;/h4&gt;KAN基于的架构在跨领域高效转移知识方面具有优势，缩小了传统机器学习和深度学习在结构化数据之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要：表格数据分析由于其异质特征类型、缺失值和复杂的交互而具有独特的挑战。虽然传统的机器学习方法，如梯度提升，通常优于深度学习方法，但近年来神经架构的进步提供了有希望的替代方案。本文介绍了一种名为TabKAN的新框架，该框架利用Kolmogorov-Arnold Networks（KANs）对表格数据进行建模。与传统的深度学习模型不同，KANs通过在边上使用可学习的激活函数，提高了可解释性和训练效率。我们的贡献包括：（1）引入了针对表格数据分析的模块化KAN架构；（2）开发了KAN模型的迁移学习框架，允许在不同领域之间有效转移知识；（3）开发了针对表格数据学习的模型特定可解释性，减少了对外部分析和模型无关分析的依赖；（4）对二元和多类分类任务中的原始监督学习进行了综合评估。通过在多个公共数据集上的广泛基准测试，TabKAN在监督学习中表现出优越的性能，在迁移学习场景中显著优于经典和基于Transformer的模型。我们的发现突出了KAN基于的架构在跨领域高效转移知识方面的优势，缩小了传统机器学习和深度学习在结构化数据之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular data analysis presents unique challenges due to its heterogeneousfeature types, missing values, and complex interactions. While traditionalmachine learning methods, such as gradient boosting, often outperform deeplearning approaches, recent advancements in neural architectures offerpromising alternatives. This paper introduces TabKAN, a novel framework thatadvances tabular data modeling using Kolmogorov-Arnold Networks (KANs). Unlikeconventional deep learning models, KANs leverage learnable activation functionson edges, enhancing both interpretability and training efficiency. Ourcontributions include: (1) the introduction of modular KAN-based architecturestailored for tabular data analysis, (2) the development of a transfer learningframework for KAN models, enabling effective knowledge transfer betweendomains, (3) the development of model-specific interpretability for tabulardata learning, reducing reliance on post hoc and model-agnostic analysis, and(4) comprehensive evaluation of vanilla supervised learning across binary andmulti-class classification tasks. Through extensive benchmarking on diversepublic datasets, TabKAN demonstrates superior performance in supervisedlearning while significantly outperforming classical and Transformer-basedmodels in transfer learning scenarios. Our findings highlight the advantage ofKAN-based architectures in efficiently transferring knowledge across domains,bridging the gap between traditional machine learning and deep learning forstructured data.</description>
      <author>example@mail.com (Ali Eslamian, Alireza Afzal Aghaei, Qiang Cheng)</author>
      <guid isPermaLink="false">2504.06559v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Teaching pathology foundation models to accurately predict gene expression with parameter efficient knowledge transfer</title>
      <link>http://arxiv.org/abs/2504.07061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为PEKA的新型框架，用于从数字化病理图像中预测基因表达，并展示了其在基因表达预测方面的性能提升。&lt;h4&gt;背景&lt;/h4&gt;基因表达谱分析对于理解细胞异质性、生物过程和疾病机制至关重要。近年来，研究者对能够直接从数字化的组织病理学图像预测基因表达的计算机方法产生了浓厚兴趣。&lt;h4&gt;目的&lt;/h4&gt;提高基于图像模型的基因表达预测性能，同时降低模型的参数数量。&lt;h4&gt;方法&lt;/h4&gt;PEKA框架结合了块对齐适应、知识蒸馏和结构对齐损失来实现跨模态知识迁移。&lt;h4&gt;主要发现&lt;/h4&gt;PEKA在多个空间转录组数据集上实现了至少5%的性能提升，并优于其他参数高效的微调策略。&lt;h4&gt;结论&lt;/h4&gt;PEKA框架有助于提高基因表达预测的准确性，且参数效率高，有望在同行评审后推广使用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基因表达谱分析为理解细胞异质性、生物过程和疾病机制提供了关键见解。近年来，研究者对能够直接从数字化的组织病理学图像预测基因表达的计算机方法产生了浓厚兴趣。尽管基于图像的基础模型在多种病理下游分析中显示出希望，但它们在基因表达预测方面的表现仍然有限。明确结合转录组模型的信息可以帮助图像模型解决域偏移问题，但基础模型的微调和对齐可能成本高昂。在本文中，我们提出了一种名为Parameter Efficient Knowledge trAnsfer（PEKA）的新型框架，该框架利用块对齐适应，并集成了知识蒸馏和结构对齐损失以实现跨模态知识迁移。我们使用多个空间转录组数据集（包含206,123个图像瓷砖和匹配的基因表达谱）评估了PEKA在基因表达预测方面的表现，这些数据集涵盖了不同类型的组织。PEKA在基准基础模型上实现了至少5%的性能提升，同时也优于其他参数高效的微调策略。我们将在同行评审后发布代码、数据集和对齐模型，以促进更广泛的采用和进一步的开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gene expression profiling provides critical insights into cellularheterogeneity, biological processes and disease mechanisms. There has been anincreasing interest in computational approaches that can predict geneexpression directly from digitalized histopathology images. While imagefoundation models have shown promise in a variety of pathology downstreamanalysis, their performances on gene-expression prediction are still limited.Explicitly incorporating information from the transcriptomic models can helpimage models to address domain shift, yet the fine-tuning and alignment offoundation models can be expensive. In the work, we propose Parameter EfficientKnowledge trAnsfer (PEKA), a novel framework that leverages Block-AffineAdaptation and integrates knowledge distillation and structure alignment lossesfor cross-modal knowledge transfer. We evaluated PEKA for gene expressionprediction using multiple spatial transcriptomics datasets (comprising 206,123image tiles with matched gene expression profiles) that encompassed varioustypes of tissue. PEKA achieved at least 5\% performance improvement overbaseline foundation models while also outperforming alternativeparameter-efficient fine-tuning strategies. We will release the code, datasetsand aligned models after peer-review to facilitate broader adoption and furtherdevelopment for parameter efficient model alignment.</description>
      <author>example@mail.com (Shi Pan, Jianan Chen, Maria Secrier)</author>
      <guid isPermaLink="false">2504.07061v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Audio-visual Event Localization on Portrait Mode Short Videos</title>
      <link>http://arxiv.org/abs/2504.06884v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了用于竖屏短视频的音频-视觉事件定位（AVE-PM）数据集，并分析了现有AVEL方法在竖屏视频上的性能问题。&lt;h4&gt;背景&lt;/h4&gt;现有的AVEL数据集主要包含横向的长视频，而短视频已成为在线视频内容的主流格式，给AVEL带来了新的挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一个针对竖屏短视频的AVE-PM数据集，并研究如何改进现有方法以适应短视频的特点。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含25,335个剪辑的AVE-PM数据集，涵盖了86个细粒度类别，并进行了帧级标注。通过实证分析，研究了现有方法在竖屏视频上的性能下降问题，并提出了预处理和模型设计优化。&lt;h4&gt;主要发现&lt;/h4&gt;1) 竖屏视频的帧向空间偏差引入了不同的领域先验；2) 噪音音频组成影响了音频模态的可靠性。&lt;h4&gt;结论&lt;/h4&gt;通过优化预处理和模型设计，可以在竖屏视频上实现AVEL性能的提升，为移动视频内容时代的AVEL研究提供了基础基准和可操作的见解。&lt;h4&gt;翻译&lt;/h4&gt;Audio-visual event localization (AVEL) plays a critical role in multimodalscene understanding. While existing datasets for AVEL predominantly compriselandscape-oriented long videos with clean and simple audio context, shortvideos have become the primary format of online video content due to the theproliferation of smartphones. Short videos are characterized byportrait-oriented framing and layered audio compositions (e.g., overlappingsound effects, voiceovers, and music), which brings unique challengesunaddressed by conventional methods. To this end, we introduce AVE-PM, thefirst AVEL dataset specifically designed for portrait mode short videos,comprising 25,335 clips that span 86 fine-grained categories with frame-levelannotations. Beyond dataset creation, our empirical analysis shows thatstate-of-the-art AVEL methods suffer an average 18.66% performance drop duringcross-mode evaluation. Further analysis reveals two key challenges of differentvideo formats: 1) spatial bias from portrait-oriented framing introducesdistinct domain priors, and 2) noisy audio composition compromise thereliability of audio modality. To address these issues, we investigate optimalpreprocessing recipes and the impact of background music for AVEL on portraitmode videos. Experiments show that these methods can still benefit fromtailored preprocessing and specialized model design, thus achieving improvedperformance. This work provides both a foundational benchmark and actionableinsights for advancing AVEL research in the era of mobile-centric videocontent. Dataset and code will be released.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-visual event localization (AVEL) plays a critical role in multimodalscene understanding. While existing datasets for AVEL predominantly compriselandscape-oriented long videos with clean and simple audio context, shortvideos have become the primary format of online video content due to the theproliferation of smartphones. Short videos are characterized byportrait-oriented framing and layered audio compositions (e.g., overlappingsound effects, voiceovers, and music), which brings unique challengesunaddressed by conventional methods. To this end, we introduce AVE-PM, thefirst AVEL dataset specifically designed for portrait mode short videos,comprising 25,335 clips that span 86 fine-grained categories with frame-levelannotations. Beyond dataset creation, our empirical analysis shows thatstate-of-the-art AVEL methods suffer an average 18.66% performance drop duringcross-mode evaluation. Further analysis reveals two key challenges of differentvideo formats: 1) spatial bias from portrait-oriented framing introducesdistinct domain priors, and 2) noisy audio composition compromise thereliability of audio modality. To address these issues, we investigate optimalpreprocessing recipes and the impact of background music for AVEL on portraitmode videos. Experiments show that these methods can still benefit fromtailored preprocessing and specialized model design, thus achieving improvedperformance. This work provides both a foundational benchmark and actionableinsights for advancing AVEL research in the era of mobile-centric videocontent. Dataset and code will be released.</description>
      <author>example@mail.com (Wuyang Liu, Yi Chai, Yongpeng Yan, Yanzhen Ren)</author>
      <guid isPermaLink="false">2504.06884v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Visualisation of a multidimensional point cloud as a 3D swarm of avatars</title>
      <link>http://arxiv.org/abs/2504.06751v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Chernoff面孔图标的多维数据可视化创新方法。&lt;h4&gt;背景&lt;/h4&gt;传统投影技术和数据维度分配相结合，利用人类大脑对面部表情的自然解释能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种数据可视化技术，以帮助分析复杂的数据结构。&lt;h4&gt;方法&lt;/h4&gt;该技术作为dpVision开源图像处理平台的插件实现，允许以“图腾”的形式交互式探索数据。&lt;h4&gt;主要发现&lt;/h4&gt;基于合成测试数据和葡萄牙葡萄酒vinhoverde15维数据库的样本可视化证明了该方法的实用性。&lt;h4&gt;结论&lt;/h4&gt;该方法对复杂数据结构分析具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;The article presents an innovative approach to the visualisation of multidimensional data, using icons inspired by Chernoff faces. The approach merges classical projection techniques with the assignment of particular data dimensions to mimic features, capitalizing on the natural ability of the human brain to interpret facial expressions. The technique is implemented as a plugin to the dpVision open-source image handling platform. The plugin allows the data to be interactively explored in the form of a swarm of 'totems' whose position in hyperspace as well as facial features represent various aspects of the data. Sample visualisations, based on synthetic test data as well as the vinhoverde15-dimensional database on Portuguese wines, confirm the usefulness of our approach to the analysis of complex data structures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The article presents an innovative approach to the visualisation ofmultidimensional data, using icons inspired by Chernoff faces. The approachmerges classical projection techniques with the assignment of particular datadimensions to mimic features, capitalizing on the natural ability of the humanbrain to interpret facial expressions. The technique is implemented as a pluginto the dpVision open-source image handling platform. The plugin allows the datato be interactively explored in the form of a swarm of "totems" whose positionin hyperspace as well as facial features represent various aspects of the data.Sample visualisations, based on synthetic test data as well as the vinhoverde15-dimensional database on Portuguese wines, confirm the usefulness of ourapproach to the analysis of complex data structures.</description>
      <author>example@mail.com (Leszek Luchowski, Dariusz Pojda)</author>
      <guid isPermaLink="false">2504.06751v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>CHIME: A Compressive Framework for Holistic Interest Modeling</title>
      <link>http://arxiv.org/abs/2504.06780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为CHIME的压缩框架，用于整体兴趣建模，以改善推荐系统的性能。&lt;h4&gt;背景&lt;/h4&gt;整体用户兴趣建模对于改进推荐系统很重要，但面临着高计算成本和难以处理具有完整行为背景的多样化信息的问题。&lt;h4&gt;目的&lt;/h4&gt;旨在克服现有基于搜索的方法在行为选择中丢失关键信号的限制。&lt;h4&gt;方法&lt;/h4&gt;使用改进的大语言模型来编码带有异构输入的完整用户行为，引入多粒度对比学习目标以捕捉持久和短暂的兴趣模式，并应用残差矢量量化生成紧凑嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;CHIME在多个数据集上展示了优越的排名性能，为可扩展的整体兴趣建模提供了一种稳健的解决方案。&lt;h4&gt;结论&lt;/h4&gt;CHIME是一种有效的整体兴趣建模方法，有助于提高推荐系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：建模整体用户兴趣对于改善推荐系统至关重要，但受到高计算成本和处理具有完整行为背景的多样化信息的挑战。现有的基于搜索的方法可能在行为选择中丢失关键信号。为了克服这些限制，我们提出了CHIME：一种用于整体兴趣建模的压缩框架。它使用改进的大语言模型来编码带有异构输入的完整用户行为。我们引入了多粒度对比学习目标以捕捉持久和短暂的兴趣模式，并应用残差矢量量化生成紧凑嵌入。CHIME在各种数据集上展示了优越的排名性能，为推荐系统中的可扩展整体兴趣建模建立了一种稳健的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling holistic user interests is important for improving recommendationsystems but is challenged by high computational cost and difficulty in handlingdiverse information with full behavior context. Existing search-based methodsmight lose critical signals during behavior selection. To overcome theselimitations, we propose CHIME: A Compressive Framework for Holistic InterestModeling. It uses adapted large language models to encode complete userbehaviors with heterogeneous inputs. We introduce multi-granular contrastivelearning objectives to capture both persistent and transient interest patternsand apply residual vector quantization to generate compact embeddings. CHIMEdemonstrates superior ranking performance across diverse datasets, establishinga robust solution for scalable holistic interest modeling in recommendationsystems.</description>
      <author>example@mail.com (Yong Bai, Rui Xiang, Kaiyuan Li, Yongxiang Tang, Yanhua Cheng, Xialong Liu, Peng Jiang, Kun Gai)</author>
      <guid isPermaLink="false">2504.06780v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Self-Supervised Learning for Earth Observation via Dynamic Dataset Curation</title>
      <link>http://arxiv.org/abs/2504.06962v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR Workshop : The First Workshop on Foundation and  Large Vision Models in Remote Sensing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种动态数据集剪枝策略，旨在通过最大化数据集的多样性和平衡性来提高自监督学习（SSL）在地球观测（EO）领域的预训练效果。&lt;h4&gt;背景&lt;/h4&gt;尽管自监督学习在地球观测领域显示出强大的迁移性，但数据集的编制，特别是在平衡和多样化预训练数据集方面，仍然是一个未被充分探索的问题。在地球观测中，卫星图像中的冗余和重尾分布问题加剧了这一挑战，可能导致偏差的表示和低效的训练。&lt;h4&gt;目的&lt;/h4&gt;提出一种动态数据集剪枝策略，以提高SSL预训练的效率和模型的表现。&lt;h4&gt;方法&lt;/h4&gt;该方法通过迭代地优化训练集，而不需要预先存在的特征提取器，适用于数据集有限或不可用的领域。在Sentinel-1 WV合成孔径雷达（SAR）档案上进行了实验，该档案是一个以海洋观测为主的具有挑战性的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;在三个下游任务中，结果表明动态剪枝提高了计算效率和表示质量，从而增强了模型的迁移性。&lt;h4&gt;结论&lt;/h4&gt;动态剪枝策略能够提高SSL预训练的效果，并有助于提高模型在地球观测任务中的表现。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning (SSL) has enabled the development of vision foundation models for Earth Observation (EO), demonstrating strong transferability across diverse remote sensing tasks. While prior work has focused on network architectures and training strategies, the role of dataset curation, especially in balancing and diversifying pre-training datasets, remains underexplored. In EO, this challenge is amplified by the redundancy and heavy-tailed distributions common in satellite imagery, which can lead to biased representations and inefficient training. In this work, we propose a dynamic dataset pruning strategy designed to improve SSL pre-training by maximizing dataset diversity and balance. Our method iteratively refines the training set without requiring a pre-existing feature extractor, making it well-suited for domains where curated datasets are limited or unavailable. We demonstrate our approach on the Sentinel-1 Wave Mode (WV) Synthetic Aperture Radar (SAR) archive, a challenging dataset dominated by ocean observations. We train models from scratch on the entire Sentinel-1 WV archive spanning 10 years. Across three downstream tasks, our results show that dynamic pruning improves both computational efficiency and representation quality, leading to stronger transferability. We also release the weights of Nereus-SAR-1, the first model in the Nereus family, a series of foundation models for ocean observation and analysis using SAR imagery, at github.com/galeio-research/nereus-sar-models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has enabled the development of visionfoundation models for Earth Observation (EO), demonstrating strongtransferability across diverse remote sensing tasks. While prior work hasfocused on network architectures and training strategies, the role of datasetcuration, especially in balancing and diversifying pre-training datasets,remains underexplored. In EO, this challenge is amplified by the redundancy andheavy-tailed distributions common in satellite imagery, which can lead tobiased representations and inefficient training.  In this work, we propose a dynamic dataset pruning strategy designed toimprove SSL pre-training by maximizing dataset diversity and balance. Ourmethod iteratively refines the training set without requiring a pre-existingfeature extractor, making it well-suited for domains where curated datasets arelimited or unavailable. We demonstrate our approach on the Sentinel-1 Wave Mode(WV) Synthetic Aperture Radar (SAR) archive, a challenging dataset dominated byocean observations. We train models from scratch on the entire Sentinel-1 WVarchive spanning 10 years. Across three downstream tasks, our results show thatdynamic pruning improves both computational efficiency and representationquality, leading to stronger transferability.  We also release the weights of Nereus-SAR-1, the first model in the Nereusfamily, a series of foundation models for ocean observation and analysis usingSAR imagery, at github.com/galeio-research/nereus-sar-models/.</description>
      <author>example@mail.com (Thomas Kerdreux, Alexandre Tuel, Quentin Febvre, Alexis Mouche, Bertrand Chapron)</author>
      <guid isPermaLink="false">2504.06962v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>LVC: A Lightweight Compression Framework for Enhancing VLMs in Long Video Understanding</title>
      <link>http://arxiv.org/abs/2504.06835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为轻量级视频压缩（LVC）的新方法，旨在提高视频语言模型（VLMs）对长视频的理解能力，同时降低数据和使用计算资源的需求。&lt;h4&gt;背景&lt;/h4&gt;长视频理解是一个复杂的任务，需要同时具备空间细节和时间感知能力。虽然VLMs可以通过多帧输入获得帧级理解能力，但它们由于稀疏采样策略而存在信息损失。相比之下，视频大型语言模型（Video-LLMs）在视觉特征中捕捉时间关系，但受限于高质量视频-文本数据集的稀缺。&lt;h4&gt;目的&lt;/h4&gt;目的是将长视频理解能力转移到VLMs上，同时最小化数据和使用计算资源。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为LVC的新方法，它具有查询注意力视频压缩机制，有效地解决了VLMs中的稀疏采样问题。通过仅训练10k个短视频-文本对的对齐层，LVC显著增强了VLMs的时间推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LVC在各种模型上提供了持续的性能提升，包括InternVL2系列和Phi-3.5-Vision。特别是，InternVL2-40B-LVC在长视频理解基准MLVU和Video-MME上分别达到了68.2和65.9的分数，相对提高了14.6%和7.7%。&lt;h4&gt;结论&lt;/h4&gt;增强的模型和代码将很快公开。&lt;h4&gt;翻译&lt;/h4&gt;摘要：长视频理解是一个复杂的任务，需要空间细节和时间感知能力。虽然视觉语言模型（VLMs）通过多帧输入获得帧级理解能力，但它们由于稀疏采样策略而存在信息损失。相比之下，视频大型语言模型（Video-LLMs）在视觉特征中捕捉时间关系，但受限于高质量视频-文本数据集的稀缺。为了将长视频理解能力转移到VLMs上，同时最小化数据和使用计算资源，我们提出了轻量级视频压缩（LVC），这是一种具有查询注意力视频压缩机制的新方法，有效地解决了VLMs中的稀疏采样问题。通过仅训练10k个短视频-文本对的对齐层，LVC显著增强了VLMs的时间推理能力。广泛的实验表明，LVC在各种模型上提供了持续的性能提升，包括InternVL2系列和Phi-3.5-Vision。值得注意的是，InternVL2-40B-LVC在长视频理解基准MLVU和Video-MME上分别达到了68.2和65.9的分数，相对提高了14.6%和7.7%。增强的模型和代码将很快公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long video understanding is a complex task that requires both spatial detailand temporal awareness. While Vision-Language Models (VLMs) obtain frame-levelunderstanding capabilities through multi-frame input, they suffer frominformation loss due to the sparse sampling strategy. In contrast, Video LargeLanguage Models (Video-LLMs) capture temporal relationships within visualfeatures but are limited by the scarcity of high-quality video-text datasets.To transfer long video understanding capabilities to VLMs with minimal data andcomputational cost, we propose Lightweight Video Compression (LVC), a novelmethod featuring the Query-Attention Video Compression mechanism, whicheffectively tackles the sparse sampling problem in VLMs. By training only thealignment layer with 10k short video-text pairs, LVC significantly enhances thetemporal reasoning abilities of VLMs. Extensive experiments show that LVCprovides consistent performance improvements across various models, includingthe InternVL2 series and Phi-3.5-Vision. Notably, the InternVL2-40B-LVCachieves scores of 68.2 and 65.9 on the long video understanding benchmarksMLVU and Video-MME, respectively, with relative improvements of 14.6% and 7.7%.The enhanced models and code will be publicly available soon.</description>
      <author>example@mail.com (Ziyi Wang, Haoran Wu, Yiming Rong, Deyang Jiang, Yixin Zhang, Yunlong Zhao, Shuang Xu, Bo XU)</author>
      <guid isPermaLink="false">2504.06835v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Implementation of a Zed 2i Stereo Camera for High-Frequency Shoreline Change and Coastal Elevation Monitoring</title>
      <link>http://arxiv.org/abs/2504.06464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in IGARSS 2023 - 2023 IEEE International Geoscience and  Remote Sensing Symposium&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究通过使用低成本ZED 2i立体相机系统和近距离摄影测量法，以实现高时间分辨率和局部尺度的海岸高度和海岸线变化的监测。&lt;h4&gt;背景&lt;/h4&gt;随着沿海地区人口和财务利益的增加，对海岸高度和海岸线变化的监测需求日益增长。&lt;h4&gt;目的&lt;/h4&gt;解决现有资源缺乏所需时间分辨率的问题，以进行短期监测。&lt;h4&gt;方法&lt;/h4&gt;实施低成本ZED 2i立体相机系统，结合近距离摄影测量法，收集图像生成3D点云、海滩高度的数字表面模型（DSM）和地理校正影像。&lt;h4&gt;主要发现&lt;/h4&gt;研究的主要贡献包括：相机内在校准、获取图像和点云的地理校正和配准、海滩高度DSM的生成，以及与无人飞行器系统结构从运动摄影测量法得出的产品比较。&lt;h4&gt;结论&lt;/h4&gt;初步结果显示，尽管存在局限性，ZED 2i能够在局部和较高时间尺度上提供所需的测绘产品。系统实现了平均重投影误差0.20像素，点云配准27厘米，相对于地面实况的垂直误差37.56厘米，以及x和y方向的地理校正均方根误差分别为2.67厘米和2.81厘米。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着沿海地区人口和财政利益的增加，监测海岸高度和海岸线变化的需求也在增加。尽管有几种资源可以获取这些信息，但它们通常缺乏短期监测所需的时间分辨率（例如，每小时一次）。为了解决这个问题，本研究实施了一种低成本ZED 2i立体相机系统，并结合近距离摄影测量法收集图像以生成3D点云、海滩高度的数字表面模型（DSM）和局部尺度和高时间分辨率的地理校正影像。本研究的主要贡献包括：（i）相机内在校准，（ii）获取图像和点云的地理校正和配准，（iii）海滩高度DSM的生成，以及（iv）与无人飞行器系统结构从运动摄影测量法得出的产品进行比较。初步结果表明，尽管存在局限性，ZED 2i仍能在局部和较高时间尺度上提供所需的测绘产品。该系统实现了平均重投影误差0.20像素，点云配准27厘米，相对于地面实况的垂直误差37.56厘米，以及x和y方向的地理校正均方根误差分别为2.67厘米和2.81厘米。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IGARSS52108.2023.10283203&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing population, thus financial interests, in coastal areas haveincreased the need to monitor coastal elevation and shoreline change. Thoughseveral resources exist to obtain this information, they often lack therequired temporal resolution for short-term monitoring (e.g., every hour). Toaddress this issue, this study implements a low-cost ZED 2i stereo camerasystem and close-range photogrammetry to collect images for generating 3D pointclouds, digital surface models (DSMs) of beach elevation, and georectifiedimagery at a localized scale and high temporal resolution. The maincontributions of this study are (i) intrinsic camera calibration, (ii)georectification and registration of acquired imagery and point cloud, (iii)generation of the DSM of the beach elevation, and (iv) a comparison of derivedproducts against those from uncrewed aircraft system structure-from-motionphotogrammetry. Preliminary results show that despite its limitations, the ZED2i can provide the desired mapping products at localized and high temporalscales. The system achieved a mean reprojection error of 0.20 px, a point cloudregistration of 27 cm, a vertical error of 37.56 cm relative to ground truth,and georectification root mean square errors of 2.67 cm and 2.81 cm for x andy.</description>
      <author>example@mail.com (José A. Pilartes-Congo, Matthew Kastl, Michael J. Starek, Marina Vicens-Miquel, Philippe Tissot)</author>
      <guid isPermaLink="false">2504.06464v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Unifying Search and Recommendation: A Generative Paradigm Inspired by Information Theory</title>
      <link>http://arxiv.org/abs/2504.06714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GenSR的新颖的生成式范式，用于统一搜索和推荐任务，以提高用户建模和物品理解能力。&lt;h4&gt;背景&lt;/h4&gt;推荐系统和搜索引擎是在线平台的基础元素，前者主动提供信息，后者允许用户主动搜索信息。将这两个任务统一在一个共享模型中具有潜力，因为它可以增强用户建模和物品理解。&lt;h4&gt;目的&lt;/h4&gt;解决之前方法中梯度冲突和手动设计复杂性两个关键挑战。&lt;h4&gt;方法&lt;/h4&gt;GenSR通过使用特定任务的提示来划分模型的参数空间为子空间，从而增强互信息。具体来说，包括：(1) 双重表示学习，独立地建模协同和语义历史信息以导出有表达力的物品表示；(2) 搜索与推荐任务统一，利用对比学习和指令调整有效地生成特定任务的输出。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公开数据集上的大量实验表明，GenSR在搜索与推荐任务上优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;与之前基于判别的方法相比，GenSR引入了一种新的生成式范式，并从互信息的角度证明了其优越性。&lt;h4&gt;翻译&lt;/h4&gt;Recommender systems and search engines serve as foundational elements of online platforms, with the former delivering information proactively and the latter enabling users to seek information actively. Unifying both tasks in a shared model is promising since it can enhance user modeling and item understanding. Previous approaches mainly follow a discriminative paradigm, utilizing shared encoders to process input features and task-specific heads to perform each task. However, this paradigm encounters two key challenges: gradient conflict and manual design complexity. From the information theory perspective, these challenges potentially both stem from the same issue -- low mutual information between the input features and task-specific outputs during the optimization process. To tackle these issues, we propose GenSR, a novel generative paradigm for unifying search and recommendation (S&amp;R), which leverages task-specific prompts to partition the model's parameter space into subspaces, thereby enhancing mutual information. To construct effective subspaces for each task, GenSR first prepares informative representations for each subspace and then optimizes both subspaces in one unified model. Specifically, GenSR consists of two main modules: (1) Dual Representation Learning, which independently models collaborative and semantic historical information to derive expressive item representations; and (2) S&amp;R Task Unifying, which utilizes contrastive learning together with instruction tuning to generate task-specific outputs effectively. Extensive experiments on two public datasets show GenSR outperforms state-of-the-art methods across S&amp;R tasks. Our work introduces a new generative paradigm compared with previous discriminative methods and establishes its superiority from the mutual information perspective.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems and search engines serve as foundational elements ofonline platforms, with the former delivering information proactively and thelatter enabling users to seek information actively. Unifying both tasks in ashared model is promising since it can enhance user modeling and itemunderstanding. Previous approaches mainly follow a discriminative paradigm,utilizing shared encoders to process input features and task-specific heads toperform each task. However, this paradigm encounters two key challenges:gradient conflict and manual design complexity. From the information theoryperspective, these challenges potentially both stem from the same issue -- lowmutual information between the input features and task-specific outputs duringthe optimization process.  To tackle these issues, we propose GenSR, a novel generative paradigm forunifying search and recommendation (S&amp;R), which leverages task-specific promptsto partition the model's parameter space into subspaces, thereby enhancingmutual information. To construct effective subspaces for each task, GenSR firstprepares informative representations for each subspace and then optimizes bothsubspaces in one unified model. Specifically, GenSR consists of two mainmodules: (1) Dual Representation Learning, which independently modelscollaborative and semantic historical information to derive expressive itemrepresentations; and (2) S&amp;R Task Unifying, which utilizes contrastive learningtogether with instruction tuning to generate task-specific outputs effectively.Extensive experiments on two public datasets show GenSR outperformsstate-of-the-art methods across S&amp;R tasks. Our work introduces a new generativeparadigm compared with previous discriminative methods and establishes itssuperiority from the mutual information perspective.</description>
      <author>example@mail.com (Jujia Zhao, Wenjie Wang, Chen Xu, Xiuying Wang, Zhaochun Ren, Suzan Verberne)</author>
      <guid isPermaLink="false">2504.06714v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>UKBOB: One Billion MRI Labeled Masks for Generalizable 3D Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2504.06908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为UK Biobank Organs and Bones (UKBOB)的大规模标注数据集，用于医学影像研究，并提出了新的数据标注和模型训练方法。&lt;h4&gt;背景&lt;/h4&gt;医学影像领域面临收集大规模标注数据的挑战，包括隐私问题、物流和标注成本高。&lt;h4&gt;目的&lt;/h4&gt;开发UKBOB数据集，并利用自动标注和机器学习模型进行医学图像分割。&lt;h4&gt;方法&lt;/h4&gt;UKBOB包括51,761个3D MRI样本和超过137亿个2D器官分割掩码。使用自动标注和手动标注来验证数据质量，并提出了Entropy Test-time Adaptation (ETTA)方法来优化分割结果。基于Swin-UNetr架构训练了Swin-BOB基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;UKBOB在多个3D医学影像基准测试中取得了最先进的成果，包括BRATS脑部MRI肿瘤挑战和BTCV腹部CT扫描基准。&lt;h4&gt;结论&lt;/h4&gt;UKBOB是一个高质量的大规模医学影像数据集，其训练的模型在3D医学图像分割任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;在医学影像领域，由于隐私问题、物流和标注成本高，收集大规模标注数据是一个主要挑战。在这项工作中，我们介绍了UK Biobank器官和骨骼（UKBOB），这是最大的身体器官标注数据集，包含51,761个3D MRI样本（相当于1790万个2D图像）以及超过137亿个72个器官的2D分割掩码，所有这些数据都基于UK Biobank MRI数据集。我们利用自动标注，引入了具有器官特定过滤器的自动标签清理管道，并手动标注了300个MRI的11个腹部类别来验证质量（称为UKBOB-manual）。这种方法允许扩大数据集的收集规模，同时保持对标签的信心。我们进一步通过在过滤的UKBOB上展示训练模型的零样本泛化到其他类似领域的小型标注数据集（例如腹部MRI）来确认标签的有效性。为了进一步减轻噪声标签的影响，我们提出了一种名为Entropy Test-time Adaptation（ETTA）的新方法来优化分割输出。我们使用UKBOB来训练基于Swin-UNetr架构的3D医学图像分割基础模型Swin-BOB，在多个3D医学影像基准测试中取得了最先进的成果，包括BRATS脑部MRI肿瘤挑战（提高了0.4%）和BTCV腹部CT扫描基准（提高了1.3%）。预训练模型和代码可在https://emmanuelleb985.github.io/ukbob获取，过滤后的标签将与UK Biobank一起提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In medical imaging, the primary challenge is collecting large-scale labeleddata due to privacy concerns, logistics, and high labeling costs. In this work,we present the UK Biobank Organs and Bones (UKBOB), the largest labeled datasetof body organs, comprising 51,761 MRI 3D samples (equivalent to 17.9 million 2Dimages) and more than 1.37 billion 2D segmentation masks of 72 organs, allbased on the UK Biobank MRI dataset. We utilize automatic labeling, introducean automated label cleaning pipeline with organ-specific filters, and manuallyannotate a subset of 300 MRIs with 11 abdominal classes to validate the quality(referred to as UKBOB-manual). This approach allows for scaling up the datasetcollection while maintaining confidence in the labels. We further confirm thevalidity of the labels by demonstrating zero-shot generalization of trainedmodels on the filtered UKBOB to other small labeled datasets from similardomains (e.g., abdominal MRI). To further mitigate the effect of noisy labels,we propose a novel method called Entropy Test-time Adaptation (ETTA) to refinethe segmentation output. We use UKBOB to train a foundation model, Swin-BOB,for 3D medical image segmentation based on the Swin-UNetr architecture,achieving state-of-the-art results in several benchmarks in 3D medical imaging,including the BRATS brain MRI tumor challenge (with a 0.4% improvement) and theBTCV abdominal CT scan benchmark (with a 1.3% improvement). The pre-trainedmodels and the code are available at https://emmanuelleb985.github.io/ukbob ,and the filtered labels will be made available with the UK Biobank.</description>
      <author>example@mail.com (Emmanuelle Bourigault, Amir Jamaludin, Abdullah Hamdi)</author>
      <guid isPermaLink="false">2504.06908v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Robust and Noise-resilient Long-Term Prediction of Spatiotemporal Data Using Variational Mode Graph Neural Networks with 3D Attention</title>
      <link>http://arxiv.org/abs/2504.06660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in IJCNN, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于变分模态图卷积网络（VMGCN）和3D通道注意力机制来提高时空长期预测的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在时空长期预测中，实时数据可能受到传感器噪声的干扰，改变其分布。&lt;h4&gt;目的&lt;/h4&gt;通过引入3D通道注意力机制来提高时空长期预测的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;使用历史数据输入，将噪声建模为独立同分布的高斯噪声，并将其融入大型ST交通流量数据集中。采用变分模态分解将受干扰的信号分解成模式，然后使用包含空间、时间和通道注意力的学习流程进行预测。实施可学习的软阈值方法来排除特征向量中的不重要模式，并应用基于信噪比（SNR）的特征缩减方法。&lt;h4&gt;主要发现&lt;/h4&gt;与基线模型相比，该方法在长期预测准确性、对噪声的鲁棒性以及模式截断方面的性能有所提高。&lt;h4&gt;结论&lt;/h4&gt;该方法实现了比基线模型更高的长期预测准确性、更强的噪声鲁棒性和改进的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文重点研究了使用变分模态图卷积网络（VMGCN）通过引入3D通道注意力来提高时空长期预测的鲁棒性。该深度学习网络依赖于历史数据输入，然而，实时数据可能因传感器噪声而损坏，改变其分布。我们将这种噪声建模为独立同分布的高斯噪声，并将其纳入大型ST交通流量数据集中，产生了具有固有和加性噪声成分的数据。我们的方法包括使用变分模态分解将受干扰的信号分解成模式，然后将其输入到学习流程中进行预测。我们集成了一种包含空间、时间和通道注意力的3D注意力机制。空间和时间注意力模块学习它们各自的关联，而通道注意力机制用于抑制噪声并突出时空信号中的显著模式。此外，我们还实施了一种可学习的软阈值方法，用于从特征向量中排除不重要模式，并应用了一种基于信噪比（SNR）的特征缩减方法。我们比较了我们的方法与基线模型的性能，表明我们的方法在长期预测准确性、对噪声的鲁棒性以及与基线模型相比，在模式截断方面的性能得到了显著提高。本文的代码可在https://github.com/OsamaAhmad369/VMGCN上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper focuses on improving the robustness of spatiotemporal long-termprediction using a variational mode graph convolutional network (VMGCN) byintroducing 3D channel attention. The deep learning network for this taskrelies on historical data inputs, yet real-time data can be corrupted by sensornoise, altering its distribution. We model this noise as independent andidentically distributed (i.i.d.) Gaussian noise and incorporate it into theLargeST traffic volume dataset, resulting in data with both inherent andadditive noise components. Our approach involves decomposing the corruptedsignal into modes using variational mode decomposition, followed by feeding thedata into a learning pipeline for prediction. We integrate a 3D attentionmechanism encompassing spatial, temporal, and channel attention. The spatialand temporal attention modules learn their respective correlations, while thechannel attention mechanism is used to suppress noise and highlight thesignificant modes in the spatiotemporal signals. Additionally, a learnable softthresholding method is implemented to exclude unimportant modes from thefeature vector, and a feature reduction method based on the signal-to-noiseratio (SNR) is applied. We compare the performance of our approach againstbaseline models, demonstrating that our method achieves superior long-termprediction accuracy, robustness to noise, and improved performance with modetruncation compared to the baseline models. The code of the paper is availableat https://github.com/OsamaAhmad369/VMGCN.</description>
      <author>example@mail.com (Osama Ahmad, Zubair Khalid)</author>
      <guid isPermaLink="false">2504.06660v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Disentangle and Regularize: Sign Language Production with Articulator-Based Disentanglement and Channel-Aware Regularization</title>
      <link>http://arxiv.org/abs/2504.06610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于transformer的无词汇手语生成框架，直接将口语文本映射到手势序列。&lt;h4&gt;背景&lt;/h4&gt;目前的手语生成方法往往依赖于词汇表或预训练模型。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需词汇表或预训练模型的手语生成方法。&lt;h4&gt;方法&lt;/h4&gt;首先训练一个姿态自动编码器，使用基于发音器官的解耦策略将手势姿态编码到紧凑的潜在空间中。然后训练一个非自回归的transformer解码器，从句子级别的文本嵌入中预测这些潜在表示。通过KL散度损失，应用通道感知正则化，使预测的潜在分布与从真实编码中提取的先验对齐。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在PHOENIX14T数据集上实现了最先进的成果，并且仅使用适度大小的训练集。&lt;h4&gt;结论&lt;/h4&gt;提出的方法不依赖词汇监督或预训练模型，在数据集上取得了优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们提出了一种简单无词汇、基于transformer的手语生成（SLP）框架，它直接将口语文本映射到手势序列。首先，我们训练了一个姿态自动编码器，使用基于发音器官的解耦策略将手势姿态编码到一个紧凑的潜在空间中，其中对应于面部、右手、左手和身体的特征被分别建模，以促进结构和可解释的学习。接下来，我们训练了一个非自回归的transformer解码器，以从句子级别的文本嵌入中预测这些潜在表示。为了指导这个过程，我们通过KL散度损失，应用通道感知正则化，将预测的潜在分布与从真实编码中提取的先验对齐。每个通道对损失的贡献根据其相关的发音器官区域进行加权，使模型在训练期间能够考虑到不同发音器官的相对重要性。我们的方法不依赖于词汇监督或预训练模型，并且仅使用适度大小的训练集在PHOENIX14T数据集上实现了最先进的成果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we propose a simple gloss-free, transformer-based sign languageproduction (SLP) framework that directly maps spoken-language text to sign posesequences. We first train a pose autoencoder that encodes sign poses into acompact latent space using an articulator-based disentanglement strategy, wherefeatures corresponding to the face, right hand, left hand, and body are modeledseparately to promote structured and interpretable representation learning.Next, a non-autoregressive transformer decoder is trained to predict theselatent representations from sentence-level text embeddings. To guide thisprocess, we apply channel-aware regularization by aligning predicted latentdistributions with priors extracted from the ground-truth encodings using aKL-divergence loss. The contribution of each channel to the loss is weightedaccording to its associated articulator region, enabling the model to accountfor the relative importance of different articulators during training. Ourapproach does not rely on gloss supervision or pretrained models, and achievesstate-of-the-art results on the PHOENIX14T dataset using only a modest trainingset.</description>
      <author>example@mail.com (Sumeyye Meryem Tasyurek, Tugce Kiziltepe, Hacer Yalim Keles)</author>
      <guid isPermaLink="false">2504.06610v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>IAAO: Interactive Affordance Learning for Articulated Objects in 3D Environments</title>
      <link>http://arxiv.org/abs/2504.06827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该工作提出了一种名为IAAO的新型框架，该框架通过交互帮助智能代理理解其环境中的关节对象，并构建了一个显式的3D模型。&lt;h4&gt;背景&lt;/h4&gt;与依赖于特定任务网络和可动部分假设的先前方法不同，IAAO利用大型基础模型，在三个阶段估计交互性属性和部分关节。&lt;h4&gt;目的&lt;/h4&gt;旨在通过交互使智能代理能够理解和操纵环境中的关节对象。&lt;h4&gt;方法&lt;/h4&gt;IAAO使用3D高斯散点（3DGS）构建每个对象状态的分层特征和标签字段，通过蒸馏多视图图像中的掩码特征和视角一致的标签。然后对3D高斯原语进行对象和部分级别的查询，以识别静态和关节元素，并估计全局变换和局部关节参数以及属性。最后，基于估计的变换合并和细化不同状态的场景，实现基于属性的交互和对象的鲁棒操作。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在理解和操作关节对象方面是有效的。&lt;h4&gt;结论&lt;/h4&gt;IAAO框架为智能代理理解环境中的关节对象提供了一种有效的方法，通过交互和3D模型构建实现对象的可操纵性。&lt;h4&gt;翻译&lt;/h4&gt;这项工作提出了一种名为IAAO的新型框架，该框架通过交互帮助智能代理理解其环境中的关节对象，并构建了一个显式的3D模型。与依赖于特定任务网络和可动部分假设的先前方法不同，IAAO利用大型基础模型，在三个阶段估计交互性属性和部分关节。首先，使用3D高斯散点（3DGS）构建每个对象状态的分层特征和标签字段，通过蒸馏多视图图像中的掩码特征和视角一致的标签。然后对3D高斯原语进行对象和部分级别的查询，以识别静态和关节元素，并估计全局变换和局部关节参数以及属性。最后，基于估计的变换合并和细化不同状态的场景，实现基于属性的交互和对象的鲁棒操作。实验结果表明，该方法在理解和操作关节对象方面是有效的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents IAAO, a novel framework that builds an explicit 3D modelfor intelligent agents to gain understanding of articulated objects in theirenvironment through interaction. Unlike prior methods that rely ontask-specific networks and assumptions about movable parts, our IAAO leverageslarge foundation models to estimate interactive affordances and partarticulations in three stages. We first build hierarchical features and labelfields for each object state using 3D Gaussian Splatting (3DGS) by distillingmask features and view-consistent labels from multi-view images. We thenperform object- and part-level queries on the 3D Gaussian primitives toidentify static and articulated elements, estimating global transformations andlocal articulation parameters along with affordances. Finally, scenes fromdifferent states are merged and refined based on the estimated transformations,enabling robust affordance-based interaction and manipulation of objects.Experimental results demonstrate the effectiveness of our method.</description>
      <author>example@mail.com (Can Zhang, Gim Hee Lee)</author>
      <guid isPermaLink="false">2504.06827v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>MovSAM: A Single-image Moving Object Segmentation Framework Based on Deep Thinking</title>
      <link>http://arxiv.org/abs/2504.06863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MovSAM的单图像移动目标分割框架，通过结合多模态大型语言模型和视觉特征，实现了基于逻辑推理的移动目标分割。&lt;h4&gt;背景&lt;/h4&gt;移动目标分割在理解动态视觉环境中至关重要，但现有方法依赖于多帧图像序列，而单图像移动目标分割对于运动意图预测和应对相机帧丢失等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的单图像移动目标分割方法，以解决现有方法因缺乏时间线索而难以从单图像中分割移动目标的挑战。&lt;h4&gt;方法&lt;/h4&gt;MovSAM利用增强有思维链（CoT）提示的多模态大型语言模型（MLLM）来搜索移动目标并生成基于深度思考的文本提示，这些提示与Segment Anything Model（SAM）和Vision-Language Model（VLM）的视觉特征进行交叉融合，实现逻辑驱动的移动目标分割。分割结果经过深度思考的细化循环，使MovSAM能够通过逻辑推理迭代地提高对场景上下文和对象之间关系的理解。&lt;h4&gt;主要发现&lt;/h4&gt;MovSAM在现实世界的自动驾驶场景中得到了验证，尽管多帧方法在利用时间信息方面具有内在优势，但MovSAM在公共移动目标分割（MOS）基准测试中实现了最先进的性能，达到92.5%的准确率。&lt;h4&gt;结论&lt;/h4&gt;MovSAM是一种有效的单图像移动目标分割方法，在自动驾驶等场景中具有实际应用价值，并且性能优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：移动目标分割在理解动态视觉环境中起着至关重要的作用。虽然现有方法依赖于多帧图像序列来识别移动目标，但单图像移动目标分割对于运动意图预测和应对相机帧丢失等应用至关重要。然而，由于缺乏时间线索，从单图像中分割移动目标对现有方法来说仍然是一个挑战。为了解决这一差距，我们提出了MovSAM，这是第一个用于单图像移动目标分割的框架。MovSAM利用增强有思维链（CoT）提示的多模态大型语言模型（MLLM）来搜索移动目标并生成基于深度思考的文本提示，这些提示与Segment Anything Model（SAM）和Vision-Language Model（VLM）的视觉特征进行交叉融合，实现逻辑驱动的移动目标分割。分割结果经过深度思考的细化循环，使MovSAM能够通过逻辑推理迭代地提高对场景上下文和对象之间关系的理解。这种创新方法使MovSAM能够通过考虑场景理解来分割单图像中的移动目标。我们在现实世界中实现了MovSAM，以验证其实际应用价值和在自动驾驶场景中多帧方法失败时的有效性。此外，尽管多帧方法在利用时间信息方面具有内在优势，但MovSAM在公共移动目标分割（MOS）基准测试中实现了最先进的性能，达到92.5%的准确率。我们的实现将在https://github.com/IRMVLab/MovSAM上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Moving object segmentation plays a vital role in understanding dynamic visualenvironments. While existing methods rely on multi-frame image sequences toidentify moving objects, single-image MOS is critical for applications likemotion intention prediction and handling camera frame drops. However,segmenting moving objects from a single image remains challenging for existingmethods due to the absence of temporal cues. To address this gap, we proposeMovSAM, the first framework for single-image moving object segmentation. MovSAMleverages a Multimodal Large Language Model (MLLM) enhanced withChain-of-Thought (CoT) prompting to search the moving object and generate textprompts based on deep thinking for segmentation. These prompts are cross-fusedwith visual features from the Segment Anything Model (SAM) and aVision-Language Model (VLM), enabling logic-driven moving object segmentation.The segmentation results then undergo a deep thinking refinement loop, allowingMovSAM to iteratively improve its understanding of the scene context andinter-object relationships with logical reasoning. This innovative approachenables MovSAM to segment moving objects in single images by considering sceneunderstanding. We implement MovSAM in the real world to validate its practicalapplication and effectiveness for autonomous driving scenarios where themulti-frame methods fail. Furthermore, despite the inherent advantage ofmulti-frame methods in utilizing temporal information, MovSAM achievesstate-of-the-art performance across public MOS benchmarks, reaching 92.5\% onJ\&amp;F. Our implementation will be available athttps://github.com/IRMVLab/MovSAM.</description>
      <author>example@mail.com (Chang Nie, Yiqing Xu, Guangming Wang, Zhe Liu, Yanzi Miao, Hesheng Wang)</author>
      <guid isPermaLink="false">2504.06863v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Societal Impacts Research Requires Benchmarks for Creative Composition Tasks</title>
      <link>http://arxiv.org/abs/2504.06549v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  v1: ICLR 2025 Workshop on Bidirectional Human-AI Alignment (BiAlign)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了能够自动化认知任务的基座模型的社会影响，强调开发基于实际用例的基准的重要性，以评估这些模型可能带来的风险和影响。&lt;h4&gt;背景&lt;/h4&gt;基座模型在自动化认知任务方面具有革命性，但它们的社会影响尚不明确，可能带来合成内容泛滥、同质化和误导性等问题。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过分析语言模型用户的行为，确定需要关注的创意性任务领域，并提出改进基准的方法。&lt;h4&gt;方法&lt;/h4&gt;通过主题分析2百万个语言模型用户提示，识别创意性任务是用户寻求帮助的常见用途，并分析现有基准与实际使用模式之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现创意性任务在用户使用中很普遍，但现有基准与这些任务的实际使用模式之间存在不匹配。&lt;h4&gt;结论&lt;/h4&gt;文章主张关注创意性任务的基准，以更好地理解AI生成内容的社会影响，并呼吁提高透明度，以开发能够有效衡量模型进步和影响的基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：Foundation models capable of automating cognitive tasks represent a pivotal technological shift, yet their societal implications remain unclear. These systems promise exciting advances, yet they also risk flooding our information ecosystem with formulaic, homogeneous, and potentially misleading synthetic content. Developing benchmarks grounded in real use cases where these risks are most significant is therefore critical. Through a thematic analysis using 2 million language model user prompts, we identify creative composition tasks as a prevalent usage category where users seek help with personal tasks that require everyday creativity. Our fine-grained analysis identifies mismatches between current benchmarks and usage patterns among these tasks. Crucially, we argue that the same use cases that currently lack thorough evaluations can lead to negative downstream impacts. This position paper argues that benchmarks focused on creative composition tasks is a necessary step towards understanding the societal harms of AI-generated content. We call for greater transparency in usage patterns to inform the development of new benchmarks that can effectively measure both the progress and the impacts of models with creative capabilities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models that are capable of automating cognitive tasks represent apivotal technological shift, yet their societal implications remain unclear.These systems promise exciting advances, yet they also risk flooding ourinformation ecosystem with formulaic, homogeneous, and potentially misleadingsynthetic content. Developing benchmarks grounded in real use cases where theserisks are most significant is therefore critical. Through a thematic analysisusing 2 million language model user prompts, we identify creative compositiontasks as a prevalent usage category where users seek help with personal tasksthat require everyday creativity. Our fine-grained analysis identifiesmismatches between current benchmarks and usage patterns among these tasks.Crucially, we argue that the same use cases that currently lack thoroughevaluations can lead to negative downstream impacts. This position paper arguesthat benchmarks focused on creative composition tasks is a necessary steptowards understanding the societal harms of AI-generated content. We call forgreater transparency in usage patterns to inform the development of newbenchmarks that can effectively measure both the progress and the impacts ofmodels with creative capabilities.</description>
      <author>example@mail.com (Judy Hanwen Shen, Carlos Guestrin)</author>
      <guid isPermaLink="false">2504.06549v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>RAMBO: RL-augmented Model-based Optimal Control for Whole-body Loco-manipulation</title>
      <link>http://arxiv.org/abs/2504.06662v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了RAMBO，一个结合基于模型的反应力优化和强化学习反馈策略的混合框架，用于解决地面机器人在运动和与物体交互中的挑战。&lt;h4&gt;背景&lt;/h4&gt;地面机器人的loco-manipulation需要精确的力交互和抵抗未建模动态的鲁棒性。基于模型的控制器在规划优化方面有优势，但受限于模型的不准确性和计算成本。学习基于的方法具有鲁棒性，但在精确调节交互力方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出RAMBO框架，以实现精确的运动和交互，同时保证鲁棒和动态的运动。&lt;h4&gt;方法&lt;/h4&gt;RAMBO框架使用简化的动力学模型进行基于模型的反应力优化，并通过强化学习训练的反馈策略增强控制执行的鲁棒性。模型模块通过求解二次规划生成前馈扭矩，策略提供反馈残差以增强鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;在四足机器人的多种实际loco-manipulation任务中验证了框架的有效性，包括推动购物车、平衡盘子和握持软物体等。实验表明，RAMBO在精确操作的同时，实现了鲁棒和动态的运动，超越了使用端到端方案训练的策略。此外，该方法允许在末端执行器跟踪精度和合规性之间进行灵活权衡。&lt;h4&gt;结论&lt;/h4&gt;RAMBO框架是一个有效的解决方案，它结合了基于模型和控制学习的优点，提高了地面机器人在运动和交互中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Loco-manipulation -- coordinated locomotion and physical interaction withobjects -- remains a major challenge for legged robots due to the need for bothaccurate force interaction and robustness to unmodeled dynamics. Whilemodel-based controllers provide interpretable dynamics-level planning andoptimization, they are limited by model inaccuracies and computational cost. Incontrast, learning-based methods offer robustness while struggling with precisemodulation of interaction forces. We introduce RAMBO -- RL-AugmentedModel-Based Optimal Control -- a hybrid framework that integrates model-basedreaction force optimization using a simplified dynamics model and a feedbackpolicy trained with reinforcement learning. The model-based module generatesfeedforward torques by solving a quadratic program, while the policy providesfeedback residuals to enhance robustness in control execution. We validate ourframework on a quadruped robot across a diverse set of real-worldloco-manipulation tasks -- such as pushing a shopping cart, balancing a plate,and holding soft objects -- in both quadrupedal and bipedal walking. Ourexperiments demonstrate that RAMBO enables precise manipulation while achievingrobust and dynamic locomotion, surpassing the performance of policies trainedwith end-to-end scheme. In addition, our method enables flexible trade-offbetween end-effector tracking accuracy with compliance.</description>
      <author>example@mail.com (Jin Cheng, Dongho Kang, Gabriele Fadini, Guanya Shi, Stelian Coros)</author>
      <guid isPermaLink="false">2504.06662v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Masked Scene Modeling: Narrowing the Gap Between Supervised and Self-Supervised Learning in 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2504.06719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于评估3D场景理解中自监督特征质量的方法，并引入了一种新的自监督模型，在仅使用现成特征的情况下，其性能与监督模型相似。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在2D计算机视觉领域取得了成功，但在3D场景理解中，自监督方法通常仅作为特定任务的微调初始化步骤，限制了其在通用特征提取方面的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够评估3D场景理解中自监督特征质量的方法，并开发一种新的自监督模型，以提高其在3D场景理解中的性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个稳健的评估协议，使用分层模型的多分辨率特征采样来创建丰富的点级表示，并引入了一种基于掩码场景建模目标的新自监督方法，该方法专门针对分层3D模型。&lt;h4&gt;主要发现&lt;/h4&gt;该方法不仅达到了与监督模型相媲美的性能，而且比现有的自监督方法有显著提升。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和模型能够有效地评估和提升3D场景理解中的自监督学习。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning has transformed 2D computer vision by enabling models trained on large, unannotated datasets to provide versatile off-the-shelf features that perform similarly to models trained with labels. However, in 3D scene understanding, self-supervised methods are typically only used as a weight initialization step for task-specific fine-tuning, limiting their utility for general-purpose feature extraction. This paper addresses this shortcoming by proposing a robust evaluation protocol specifically designed to assess the quality of self-supervised features for 3D scene understanding. Our protocol uses multi-resolution feature sampling of hierarchical models to create rich point-level representations that capture the semantic capabilities of the model and, hence, are suitable for evaluation with linear probing and nearest-neighbor methods. Furthermore, we introduce the first self-supervised model that performs similarly to supervised models when only off-the-shelf features are used in a linear probing setup. In particular, our model is trained natively in 3D with a novel self-supervised approach based on a Masked Scene Modeling objective, which reconstructs deep features of masked patches in a bottom-up manner and is specifically tailored to hierarchical 3D models. Our experiments not only demonstrate that our method achieves competitive performance to supervised models, but also surpasses existing self-supervised approaches by a large margin. The model and training code can be found at our Github repository (https://github.com/phermosilla/msm).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has transformed 2D computer vision by enablingmodels trained on large, unannotated datasets to provide versatileoff-the-shelf features that perform similarly to models trained with labels.However, in 3D scene understanding, self-supervised methods are typically onlyused as a weight initialization step for task-specific fine-tuning, limitingtheir utility for general-purpose feature extraction. This paper addresses thisshortcoming by proposing a robust evaluation protocol specifically designed toassess the quality of self-supervised features for 3D scene understanding. Ourprotocol uses multi-resolution feature sampling of hierarchical models tocreate rich point-level representations that capture the semantic capabilitiesof the model and, hence, are suitable for evaluation with linear probing andnearest-neighbor methods. Furthermore, we introduce the first self-supervisedmodel that performs similarly to supervised models when only off-the-shelffeatures are used in a linear probing setup. In particular, our model istrained natively in 3D with a novel self-supervised approach based on a MaskedScene Modeling objective, which reconstructs deep features of masked patches ina bottom-up manner and is specifically tailored to hierarchical 3D models. Ourexperiments not only demonstrate that our method achieves competitiveperformance to supervised models, but also surpasses existing self-supervisedapproaches by a large margin. The model and training code can be found at ourGithub repository (https://github.com/phermosilla/msm).</description>
      <author>example@mail.com (Pedro Hermosilla, Christian Stippel, Leon Sick)</author>
      <guid isPermaLink="false">2504.06719v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>From Broadcast to Minimap: Achieving State-of-the-Art SoccerNet Game State Reconstruction</title>
      <link>http://arxiv.org/abs/2504.06357v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at the CVPR 2025 CVsports Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于单摄像头进行足球比赛状态重建（GSR）的鲁棒端到端流程，该流程在2024年SoccerNet比赛状态重建挑战赛中获得了第一名。&lt;h4&gt;背景&lt;/h4&gt;GSR在体育视频理解中至关重要，需要精确跟踪和定位场上的所有个体，包括球员、守门员、裁判等，以帮助教练和分析师优化训练策略和增强竞争优势。&lt;h4&gt;目的&lt;/h4&gt;解决使用单摄像头进行GSR的挑战，包括频繁的摄像头移动、遮挡和动态场景内容。&lt;h4&gt;方法&lt;/h4&gt;提出的方法集成了YOLOv5m对象检测、基于SegFormer的相机参数估计器和增强重识别、方向预测和球衣号码识别的DeepSORT跟踪框架。&lt;h4&gt;主要发现&lt;/h4&gt;该方法确保了空间准确性和时间一致性，实现了最先进的GSR，在2024年SoccerNet比赛状态重建挑战赛中排名第一，并且显著优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;该方法为单摄像头设置下的GSR提供了有效解决方案，有助于提升体育视频分析的准确性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Game State Reconstruction (GSR), a critical task in Sports VideoUnderstanding, involves precise tracking and localization of all individuals onthe football field-players, goalkeepers, referees, and others - in real-worldcoordinates. This capability enables coaches and analysts to derive actionableinsights into player movements, team formations, and game dynamics, ultimatelyoptimizing training strategies and enhancing competitive advantage. Achievingaccurate GSR using a single-camera setup is highly challenging due to frequentcamera movements, occlusions, and dynamic scene content. In this work, wepresent a robust end-to-end pipeline for tracking players across an entirematch using a single-camera setup. Our solution integrates a fine-tuned YOLOv5mfor object detection, a SegFormer-based camera parameter estimator, and aDeepSORT-based tracking framework enhanced with re-identification, orientationprediction, and jersey number recognition. By ensuring both spatial accuracyand temporal consistency, our method delivers state-of-the-art game statereconstruction, securing first place in the SoccerNet Game State ReconstructionChallenge 2024 and significantly outperforming competing methods.</description>
      <author>example@mail.com (Vladimir Golovkin, Nikolay Nemtsev, Vasyl Shandyba, Oleg Udin, Nikita Kasatkin, Pavel Kononov, Anton Afanasiev, Sergey Ulasen, Andrei Boiarov)</author>
      <guid isPermaLink="false">2504.06357v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Domain-Conditioned Scene Graphs for State-Grounded Task Planning</title>
      <link>http://arxiv.org/abs/2504.06661v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种更结构化的状态 grounding 框架，用于解决基于大型多模态模型（LMMs）的机器人任务规划中的 grounding 问题。&lt;h4&gt;背景&lt;/h4&gt;现有的机器人任务规划框架已经集成了大型多模态模型，如 GPT-4V，但这类模型在 grounding 方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一个更结构化的状态 grounding 框架，以解决基于 LMM 的方法在细粒度、结构化和领域特定场景理解方面的弱点。&lt;h4&gt;方法&lt;/h4&gt;该框架以领域条件化的场景图作为场景表示，该图可以直接映射到经典规划语言（如 PDDL）中的符号状态。领域条件化的场景图生成通过轻量级的视觉-语言方法实现，该方法在领域相关的对象检测之上对领域特定的谓词进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;在三个领域中的应用评估表明，与之前的基于 LMM 的方法相比，该方法实现了显著更高的状态估计准确性和任务规划成功率。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了所提出的框架在解决基于 LMM 的机器人任务规划中的 grounding 问题上的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent robotic task planning frameworks have integrated large multimodalmodels (LMMs) such as GPT-4V. To address grounding issues of such models, ithas been suggested to split the pipeline into perceptional state grounding andsubsequent state-based planning. As we show in this work, the state groundingability of LMM-based approaches is still limited by weaknesses in granular,structured, domain-specific scene understanding. To address this shortcoming,we develop a more structured state grounding framework that features adomain-conditioned scene graph as its scene representation. We show that suchrepresentation is actionable in nature as it is directly mappable to a symbolicstate in classical planning languages such as PDDL. We provide an instantiationof our state grounding framework where the domain-conditioned scene graphgeneration is implemented with a lightweight vision-language approach thatclassifies domain-specific predicates on top of domain-relevant objectdetections. Evaluated across three domains, our approach achieves significantlyhigher state estimation accuracy and task planning success rates compared tothe previous LMM-based approaches.</description>
      <author>example@mail.com (Jonas Herzog, Jiangpin Liu, Yue Wang)</author>
      <guid isPermaLink="false">2504.06661v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Attributes-aware Visual Emotion Representation Learning</title>
      <link>http://arxiv.org/abs/2504.06578v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;视觉情感分析因图像在传达丰富语义和激发人类感知情感方面的兴趣增长而受到广泛关注。本文提出了一种名为A4Net的深度表示网络，旨在通过利用亮度、色彩、场景上下文和面部表情四个关键属性来弥合情感差距，提高情感分析的效果。&lt;h4&gt;背景&lt;/h4&gt;视觉情感分析相较于传统视觉任务存在挑战，主要是因为视觉特征与不同情感状态之间的复杂关系，即情感差距。&lt;h4&gt;目的&lt;/h4&gt;A4Net旨在通过融合和联合训练属性识别和视觉情感分析的各个方面，提供对图像中情感内容的更深入理解。&lt;h4&gt;方法&lt;/h4&gt;A4Net利用亮度、色彩、场景上下文和面部表情四个关键属性来弥合情感差距，并通过深度表示学习方法提取图像的通用特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，A4Net在多个视觉情感数据集上表现出与最先进方法相竞争的性能，并且其激活图的可视化揭示了其在不同视觉情感数据集上的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;A4Net为视觉情感分析提供了一种有效的方法，能够通过考虑多个情感属性来提高情感分析的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉情感分析或识别因人们对理解图像如何传达丰富语义和激发人类感知情感的日益关注而受到广泛关注。然而，与传统的视觉任务相比，视觉情感分析提出了独特的挑战，尤其是在一般视觉特征与其引发的不同的情感状态之间的复杂关系上，这被称为情感差距。研究人员已经使用深度表示学习方法来解决从整个图像中提取通用特征这一挑战。然而，大多数现有方法忽略了诸如亮度、色彩、场景理解和面部表情等特定情感属性的重要性。通过本文，我们引入了A4Net，这是一种深度表示网络，通过利用四个关键属性：亮度（属性1）、色彩（属性2）、场景上下文（属性3）和面部表情（属性4）来弥合情感差距。通过融合和联合训练属性识别和视觉情感分析的各个方面，A4Net旨在对图像中的情感内容提供更深入的洞察。实验结果表明了A4Net的有效性，展示了与最先进方法相比在多个视觉情感数据集上的竞争性能。此外，A4Net生成的激活图的可视化揭示了其在不同视觉情感数据集上的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual emotion analysis or recognition has gained considerable attention dueto the growing interest in understanding how images can convey rich semanticsand evoke emotions in human perception. However, visual emotion analysis posesdistinctive challenges compared to traditional vision tasks, especially due tothe intricate relationship between general visual features and the differentaffective states they evoke, known as the affective gap. Researchers have useddeep representation learning methods to address this challenge of extractinggeneralized features from entire images. However, most existing methodsoverlook the importance of specific emotional attributes such as brightness,colorfulness, scene understanding, and facial expressions. Through this paper,we introduce A4Net, a deep representation network to bridge the affective gapby leveraging four key attributes: brightness (Attribute 1), colorfulness(Attribute 2), scene context (Attribute 3), and facial expressions (Attribute4). By fusing and jointly training all aspects of attribute recognition andvisual emotion analysis, A4Net aims to provide a better insight into emotionalcontent in images. Experimental results show the effectiveness of A4Net,showcasing competitive performance compared to state-of-the-art methods acrossdiverse visual emotion datasets. Furthermore, visualizations of activation mapsgenerated by A4Net offer insights into its ability to generalize acrossdifferent visual emotion datasets.</description>
      <author>example@mail.com (Rahul Singh Maharjan, Marta Romeo, Angelo Cangelosi)</author>
      <guid isPermaLink="false">2504.06578v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>GRAIN: Multi-Granular and Implicit Information Aggregation Graph Neural Network for Heterophilous Graphs</title>
      <link>http://arxiv.org/abs/2504.06649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GRAIN的新型图神经网络模型，专门用于异质图任务，以解决传统GNN在异质图任务中的不足。&lt;h4&gt;背景&lt;/h4&gt;虽然图神经网络在图表示学习方面取得了显著成功，但近期研究表明，在异质图任务中，GNN往往无法超越简单的MLP，并且现有方法很少考虑信息粒度和隐含关系。&lt;h4&gt;目的&lt;/h4&gt;提出GRAIN模型，以克服上述局限性，提高在异质图任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;GRAIN通过聚合不同粒度级别的多视图信息，并整合来自远距离非邻居节点的隐含数据来增强节点嵌入。此外，还引入了一种自适应的图信息聚合器，有效地结合多粒度和隐含数据。&lt;h4&gt;主要发现&lt;/h4&gt;GRAIN在13个数据集上进行了实验，这些数据集覆盖了不同的同质性和异质性，结果显示GRAIN在多个方面均优于12个最先进的模型。&lt;h4&gt;结论&lt;/h4&gt;GRAIN在异质图任务中表现优异，无论是在同质性还是异质性图上，均显著优于现有模型。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) have shown significant success in learning graph representations. However, recent studies reveal that GNNs often fail to outperform simple MLPs on heterophilous graph tasks, where connected nodes may differ in features or labels, challenging the homophily assumption. Existing methods addressing this issue often overlook the importance of information granularity and rarely consider implicit relationships between distant nodes. To overcome these limitations, we propose the Granular and Implicit Graph Network (GRAIN), a novel GNN model specifically designed for heterophilous graphs. GRAIN enhances node embeddings by aggregating multi-view information at various granularity levels and incorporating implicit data from distant, non-neighboring nodes. This approach effectively integrates local and global information, resulting in smoother, more accurate node representations. We also introduce an adaptive graph information aggregator that efficiently combines multi-granularity and implicit data, significantly improving node representation quality, as shown by experiments on 13 datasets covering varying homophily and heterophily. GRAIN consistently outperforms 12 state-of-the-art models, excelling on both homophilous and heterophilous graphs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have shown significant success in learning graphrepresentations. However, recent studies reveal that GNNs often fail tooutperform simple MLPs on heterophilous graph tasks, where connected nodes maydiffer in features or labels, challenging the homophily assumption. Existingmethods addressing this issue often overlook the importance of informationgranularity and rarely consider implicit relationships between distant nodes.To overcome these limitations, we propose the Granular and Implicit GraphNetwork (GRAIN), a novel GNN model specifically designed for heterophilousgraphs. GRAIN enhances node embeddings by aggregating multi-view information atvarious granularity levels and incorporating implicit data from distant,non-neighboring nodes. This approach effectively integrates local and globalinformation, resulting in smoother, more accurate node representations. We alsointroduce an adaptive graph information aggregator that efficiently combinesmulti-granularity and implicit data, significantly improving noderepresentation quality, as shown by experiments on 13 datasets covering varyinghomophily and heterophily. GRAIN consistently outperforms 12 state-of-the-artmodels, excelling on both homophilous and heterophilous graphs.</description>
      <author>example@mail.com (Songwei Zhao, Yuan Jiang, Zijing Zhang, Yang Yu, Hechang Chen)</author>
      <guid isPermaLink="false">2504.06649v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of Frequency Adaptation</title>
      <link>http://arxiv.org/abs/2504.06220v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Earth-Adapter，这是一种专门为遥感（RS）场景设计的Parameter-Efficient Fine-Tuning（PEFT）方法，用于提高基础模型在遥感任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的PEFT方法在处理遥感图像特征时，由于难以处理伪影影响，效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出Earth-Adapter，以解决PEFT方法在遥感场景中的伪影处理问题，并提高基础模型在遥感任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;Earth-Adapter引入了一种新的混合频率适应过程，结合了混合适配器（MoA）和离散傅里叶变换（DFT）。通过DFT将特征分解为不同的频率成分，精确分离伪影和原始特征。MoA动态地为每个适配器专家分配权重，允许跨不同频率域组合特征。&lt;h4&gt;主要发现&lt;/h4&gt;与基线Rein相比，Earth-Adapter在域适应（DA）和域泛化（DG）语义分割基准测试中分别提高了9.0%和3.1%的mIoU。&lt;h4&gt;结论&lt;/h4&gt;Earth-Adapter能够更有效地克服伪影的干扰，显著提高基础模型在遥感场景上的性能。&lt;h4&gt;翻译&lt;/h4&gt;Parameter-Efficient Fine-Tuning (PEFT) 是一种技术，它允许我们将强大的基础模型 (FMs) 应用于各种下游任务，同时保留并发挥其固有的能力。然而，我们观察到现有的 PEFT 方法，这些方法通常是为自然图像设计的，在应用于遥感 (RS) 场景时存在困难。这主要是因为它们无法处理伪影影响，这是一个在遥感图像特征中尤其严重的问题。为了应对这一挑战，我们引入了 Earth-Adapter，这是第一个专门为 RS 伪影征服设计的 PEFT 方法。Earth-Adapter 引入了一种新的混合频率适应过程，它结合了混合适配器 (MoA) 和离散傅里叶变换 (DFT)。通过利用 DFT，Earth-Adapter 可以将特征分解为不同的频率成分，精确地分离伪影和原始特征。然后，MoA 动态地为每个适配器专家分配权重，允许跨不同频率域组合特征。这些简单而有效的方法使 Earth-Adapter 能够比以前的方法更有效地克服伪影造成的干扰，显著提高 FMs 在 RS 场景上的性能。在域适应 (DA) 和域泛化 (DG) 语义分割基准测试上的实验展示了 Earth-Adapter 的有效性。与基线 Rein 相比，Earth-Adapter 在 DA 和 DG 基准测试中分别提高了 9.0% mIoU 和 3.1% mIoU。我们的代码将在 https://github.com/VisionXLab/Earth-Adapter 上发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-Efficient Fine-Tuning (PEFT) is a technique that allows us to adaptpowerful Foundation Models (FMs) to diverse downstream tasks while preservingand unleashing their inherent capabilities. However, we have observed thatexisting PEFT methods, which are often designed with natural imagery in mind,struggle when applied to Remote Sensing (RS) scenarios. This is primarily dueto their inability to handle artifact influences, a problem particularly severein RS image features. To tackle this challenge, we introduce Earth-Adapter, thefirst PEFT method specifically designed for RS artifacts conquering.Earth-Adapter introduces a novel Mixture of Frequency Adaptation process thatcombines a Mixture of Adapter (MoA) with Discrete Fourier Transformation (DFT).By utilizing DFT, Earth-Adapter can decompose features into different frequencycomponents, precisely separating artifacts from original features. The MoA thendynamically assigns weights to each adapter expert, allowing for thecombination of features across various frequency domains. Thesesimple-yet-effective approaches enable Earth-Adapter to more efficientlyovercome the disturbances caused by artifacts than previous PEFT methods,significantly enhancing the FMs' performance on RS scenarios. Experiments onDomain Adaptation (DA), and Domain Generalization (DG) semantic segmentationbenchmarks showcase the Earth-Adapter's effectiveness. Compared with baselineRein, Earth-Adapter significantly improves 9.0% mIoU in DA and 3.1% mIoU in DGbenchmarks. Our code will be released athttps://github.com/VisionXLab/Earth-Adapter.</description>
      <author>example@mail.com (Xiaoxing Hu, Ziyang Gong, Yupei Wang, Yuru Jia, Gen Luo, Xue Yang)</author>
      <guid isPermaLink="false">2504.06220v2</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>AMAD: AutoMasked Attention for Unsupervised Multivariate Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.06643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages,7 figures, first upload&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AMAD的无监督多变量时间序列异常检测方法，旨在解决现有模型在处理多样化异常情况时的局限性。&lt;h4&gt;背景&lt;/h4&gt;无监督多变量时间序列异常检测（UMTSAD）在金融、网络和传感器系统等领域扮演着重要角色。近年来，基于Transformer和自注意力机制的深度学习模型在UMTSAD任务中取得了显著成果，但这些模型的序列异常关联假设通常局限于特定的预定义模式和场景。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的局限性，本文提出AMAD方法，旨在提供一种更通用的异常关联表示框架，以应对多样化的异常情况。&lt;h4&gt;方法&lt;/h4&gt;AMAD方法集成了AutoMask机制和注意力mixup模块，形成了一种简单而通用的异常关联表示框架。该方法还采用了Max-Min训练策略和局部-全局对比学习方法，结合多尺度特征提取和自动相对关联建模。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有SOTA基准相比，AMAD在多个数据集上实现了具有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;AMAD提供了一种鲁棒且适应性强的方法，能够有效解决UMTSAD挑战，并在多个数据集上取得了优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised multivariate time series anomaly detection (UMTSAD) plays a critical role in various domains, including finance, networks, and sensor systems. In recent years, due to the outstanding performance of deep learning in general sequential tasks, many models have been specialized for deep UMTSAD tasks and have achieved impressive results, particularly those based on the Transformer and self-attention mechanisms. However, the sequence anomaly association assumptions underlying these models are often limited to specific predefined patterns and scenarios, such as concentrated or peak anomaly patterns. These limitations hinder their ability to generalize to diverse anomaly situations, especially where the lack of labels poses significant challenges. To address these issues, we propose AMAD, which integrates AutoMasked Attention for UMTSAD scenarios. AMAD introduces a novel structure based on the AutoMask mechanism and an attention mixup module, forming a simple yet generalized anomaly association representation framework. This framework is further enhanced by a Max-Min training strategy and a Local-Global contrastive learning approach. By combining multi-scale feature extraction with automatic relative association modeling, AMAD provides a robust and adaptable solution to UMTSAD challenges. Extensive experimental results demonstrate that the proposed model achieving competitive performance results compared to SOTA benchmarks across a variety of datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised multivariate time series anomaly detection (UMTSAD) plays acritical role in various domains, including finance, networks, and sensorsystems. In recent years, due to the outstanding performance of deep learningin general sequential tasks, many models have been specialized for deep UMTSADtasks and have achieved impressive results, particularly those based on theTransformer and self-attention mechanisms. However, the sequence anomalyassociation assumptions underlying these models are often limited to specificpredefined patterns and scenarios, such as concentrated or peak anomalypatterns. These limitations hinder their ability to generalize to diverseanomaly situations, especially where the lack of labels poses significantchallenges. To address these issues, we propose AMAD, which integrates\textbf{A}uto\textbf{M}asked Attention for UMTS\textbf{AD} scenarios. AMADintroduces a novel structure based on the AutoMask mechanism and an attentionmixup module, forming a simple yet generalized anomaly associationrepresentation framework. This framework is further enhanced by a Max-Mintraining strategy and a Local-Global contrastive learning approach. Bycombining multi-scale feature extraction with automatic relative associationmodeling, AMAD provides a robust and adaptable solution to UMTSAD challenges.Extensive experimental results demonstrate that the proposed model achievingcompetitive performance results compared to SOTA benchmarks across a variety ofdatasets.</description>
      <author>example@mail.com (Tiange Huang, Yongjun Li)</author>
      <guid isPermaLink="false">2504.06643v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning</title>
      <link>http://arxiv.org/abs/2504.06575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种语义感知的水印算法，用于检测由LLMs生成的文本，旨在提高水印质量、可检测性和抗篡改能力，同时增强对仿冒攻击的安全性。&lt;h4&gt;背景&lt;/h4&gt;水印技术被用于检测LLMs生成的文本，但当前研究主要关注水印文本的质量、可检测性和抗移除攻击的鲁棒性，而对仿冒攻击的安全性关注较少。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效防御仿冒攻击的语义感知水印算法，同时保持水印文本的高质量、高可检测性和抗移除攻击的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;算法通过引入语义映射模型，生成绿色-红色标记列表，通过对比训练使其对语义扭曲变化敏感，对语义保留编辑不敏感，从而在嵌入水印的同时保持文本的原义。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在两个标准基准测试中表现出对移除攻击的强大鲁棒性和对仿冒攻击的安全性，包括情感反转和有害内容插入，同时保持高水印可检测性。&lt;h4&gt;结论&lt;/h4&gt;该方法为LLMs提供了一种更安全、更具语义感知的水印技术，有助于提高文本生成系统的安全性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：水印技术已成为检测由LLMs生成文本的有前途的技术。当前研究主要关注三个设计标准：水印文本的高质量、高可检测性和对移除攻击的鲁棒性。然而，对仿冒攻击的安全性研究相对较少。例如，通过附加攻击恶意改变水印文本的含义——将其转变为仇恨言论，同时保留原始水印，从而损害LLMs提供者的声誉。我们确定了两个使防御仿冒攻击变得困难的核心挑战：（1）水印需要同时对语义扭曲变化敏感，对语义保留编辑不敏感；（2）检测全局语义变化的需求与大多数水印方案局部、自回归性质之间的矛盾。为了解决这些挑战，我们提出了一种语义感知的水印算法，在事后将水印嵌入到给定的目标文本中，同时保持其原始含义。我们的方法引入了一个语义映射模型，该模型指导生成一个绿色-红色标记列表，通过对比训练使其对语义扭曲变化敏感，对语义保留变化不敏感。在两个标准基准测试上的实验表明，该方法对移除攻击具有强大的鲁棒性，对仿冒攻击（包括情感反转和有害内容插入）具有安全性，同时保持高水印可检测性。我们的方法为LLMs提供了更安全、更具语义感知的水印技术的重要一步。我们的代码可在https://github.com/UCSB-NLP-Chang/contrastive-watermark上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Watermarking has emerged as a promising technique for detecting textsgenerated by LLMs. Current research has primarily focused on three designcriteria: high quality of the watermarked text, high detectability, androbustness against removal attack. However, the security against spoofingattacks remains relatively understudied. For example, a piggyback attack canmaliciously alter the meaning of watermarked text-transforming it into hatespeech-while preserving the original watermark, thereby damaging the reputationof the LLM provider. We identify two core challenges that make defendingagainst spoofing difficult: (1) the need for watermarks to be both sensitive tosemantic-distorting changes and insensitive to semantic-preserving edits, and(2) the contradiction between the need to detect global semantic shifts and thelocal, auto-regressive nature of most watermarking schemes. To address thesechallenges, we propose a semantic-aware watermarking algorithm that post-hocembeds watermarks into a given target text while preserving its originalmeaning. Our method introduces a semantic mapping model, which guides thegeneration of a green-red token list, contrastively trained to be sensitive tosemantic-distorting changes and insensitive to semantic-preserving changes.Experiments on two standard benchmarks demonstrate strong robustness againstremoval attacks and security against spoofing attacks, including sentimentreversal and toxic content insertion, while maintaining high watermarkdetectability. Our approach offers a significant step toward more secure andsemantically aware watermarking for LLMs. Our code is available athttps://github.com/UCSB-NLP-Chang/contrastive-watermark.</description>
      <author>example@mail.com (Li An, Yujian Liu, Yepeng Liu, Yang Zhang, Yuheng Bu, Shiyu Chang)</author>
      <guid isPermaLink="false">2504.06575v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>cuTeSpMM: Accelerating Sparse-Dense Matrix Multiplication using GPU Tensor Cores</title>
      <link>http://arxiv.org/abs/2504.06443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用GPU的矩阵乘法引擎（即Tensor Core Units或TCUs）来加速稀疏-密集矩阵乘法（SpMM）的性能，并提出了一种新的方法cuTeSpMM，其性能显著高于现有方法。&lt;h4&gt;背景&lt;/h4&gt;现代GPU配备了矩阵乘法引擎，能够高效执行小尺寸矩阵乘法。这些引擎已用于加速密集矩阵乘法库，如Nvidia的cuBLAS，但最近的研究兴趣在于利用这些引擎进行SpMM。&lt;h4&gt;目的&lt;/h4&gt;研究能否有效地使用密集TCUs加速来自多个应用领域的稀疏矩阵的SpMM，例如SuiteSparse矩阵集合中的矩阵。&lt;h4&gt;方法&lt;/h4&gt;开发了一种基于TCU的GPU内核cuTeSpMM，并基于稀疏矩阵的非零结构和模型化操作强度，提出了TCU协同度的概念。&lt;h4&gt;主要发现&lt;/h4&gt;cuTeSpMM在具有高TCU协同度的稀疏矩阵上表现优于现有标量核心SpMM实现，而在TCU协同度低的矩阵上仅略逊色。&lt;h4&gt;结论&lt;/h4&gt;密集TCUs可以有效地用于加速来自多个应用领域的稀疏矩阵的SpMM，并且cuTeSpMM是一种高效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many recent GPUs feature matrix multiplication engines (aka Tensor Core Unitsor TCUs) that perform small fixed-size matrix-matrix products at very highthroughput. They have been used very effectively to speed up densematrix-matrix multiplication libraries like Nvidia's cuBLAS, enablingsignificantly higher performance over use of the traditional scalar GPU cores.There also been recent interest in using these dense TCUs for the importantsparse-dense matrix-matrix multiplication (SpMM) kernel via explicitzero-filling.  However, an examination of the attainable performance of TC-GNN, thestate-of-the-art TCU-enhanced SpMM implementation, indicates that for asubstantial majority of the sparse matrices in the SuiteSparse collection, theachieved performance falls significantly short of the state-of-the-art SpMMkernels that only utilize scalar cores.  In this paper, we therefore address the question: Can dense TCUs beeffectively used to accelerate SpMM for a range of sparse matrices arising frommultiple application domains, such as those found in the SuiteSparse matrixcollection? We answer this question in the affirmative by developing a veryefficient TCU-based GPU kernel - cuTeSpMM (cuda Tensor core SpMM) that achievessubstantially higher performance over TC-GNN. We also develop a notion of theTCU-Synergy of a sparse-matrix, based on its non-zero structure and a modeledOperational Intensity. For sparse matrices with high TCU-synergy, cuTeSpMMoutperforms state-of-the-art scalar-core SpMM implementations, while achievingonly slightly lower performance on matrices with low TCU-Synergy.</description>
      <author>example@mail.com (Lizhi Xiang, Omid Asudeh, Gerald Sabin, Aravind Sukumaran-Rajam, P. Sadayappan)</author>
      <guid isPermaLink="false">2504.06443v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Domain Generalization via Discrete Codebook Learning</title>
      <link>http://arxiv.org/abs/2504.06572v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICME 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的领域泛化学习方法，称为离散领域泛化（DDG），通过将特征图量化为离散码字来减少连续表示学习中的领域差距，从而提高模型的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;当前领域泛化（DG）方法主要关注连续特征的鲁棒表示学习，但这种方法在处理连续特征的大空间时可能难以减少分布差距，且容易受到像素细节的影响。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的领域泛化方法，以减少连续特征表示学习中的领域差距，并提高模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为离散领域泛化（DDG）的新学习范式，使用码本将特征图量化为离散码字，并在一个优先考虑语义信息的共享离散表示空间中进行学习。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明了通过离散化过程可以减少连续表示学习中的领域差距，并通过实验证明了DDG相较于现有方法在多个DG基准测试中的优越性能。&lt;h4&gt;结论&lt;/h4&gt;DDG通过减少分布差距，优化表示空间的使用，提高了模型的泛化能力，具有潜在的实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：领域泛化（DG）旨在解决不同环境中的分布偏移问题，以增强模型的可泛化性。当前DG方法局限于获取具有连续特征的鲁棒表示，特别是像素级别的训练。然而，这种DG范式可能难以缓解处理连续特征大空间时的分布差距，使其容易受到表现出伪相关或噪声的像素细节的影响。在本文中，我们首先从理论上证明，通过离散化过程可以减少连续表示学习中的领域差距。基于这一启发性的发现，我们引入了一种新的领域泛化学习范式，称为离散领域泛化（DDG）。DDG提出使用码本将特征图量化为离散码字，在优先考虑语义信息的共享离散表示空间中对齐语义等效信息。通过在语义级别进行学习，DDG减少了潜在特征的数量，优化了表示空间的使用，并缓解了与连续特征宽泛空间相关的风险。在DG中广泛使用的基准测试上的大量实验表明，DDG相较于最先进的方法具有优越的性能，突显了其减少分布差距并提高模型泛化能力的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain generalization (DG) strives to address distribution shifts acrossdiverse environments to enhance model's generalizability. Current DG approachesare confined to acquiring robust representations with continuous features,specifically training at the pixel level. However, this DG paradigm maystruggle to mitigate distribution gaps in dealing with a large space ofcontinuous features, rendering it susceptible to pixel details that exhibitspurious correlations or noise. In this paper, we first theoreticallydemonstrate that the domain gaps in continuous representation learning can bereduced by the discretization process. Based on this inspiring finding, weintroduce a novel learning paradigm for DG, termed Discrete DomainGeneralization (DDG). DDG proposes to use a codebook to quantize the featuremap into discrete codewords, aligning semantic-equivalent information in ashared discrete representation space that prioritizes semantic-levelinformation over pixel-level intricacies. By learning at the semantic level,DDG diminishes the number of latent features, optimizing the utilization of therepresentation space and alleviating the risks associated with the wide-rangingspace of continuous features. Extensive experiments across widely employedbenchmarks in DG demonstrate DDG's superior performance compared tostate-of-the-art approaches, underscoring its potential to reduce thedistribution gaps and enhance the model's generalizability.</description>
      <author>example@mail.com (Shaocong Long, Qianyu Zhou, Xikun Jiang, Chenhao Ying, Lizhuang Ma, Yuan Luo)</author>
      <guid isPermaLink="false">2504.06572v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis</title>
      <link>http://arxiv.org/abs/2504.06553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ASHiTA的框架，用于将高级任务分解为与环境相关的子任务，并将其应用于场景重建和理解中。&lt;h4&gt;背景&lt;/h4&gt;尽管自然语言与物理3D环境之间的联系已经取得进展，但将抽象的高级指令与环境中的3D场景联系起来仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，能够将高级任务分解为与环境相关的子任务，并生成一个适合环境的表示。&lt;h4&gt;方法&lt;/h4&gt;ASHiTA通过交替使用LLM辅助的层次任务分析和任务驱动的3D场景图构建来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AShiTA在将高级任务分解为环境相关的子任务方面显著优于LLM基线，并且能够达到与最先进方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;AShiTA是一种有效的框架，可以用于将高级指令与环境中的3D场景联系起来，并在任务分解方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While recent work in scene reconstruction and understanding has made stridesin grounding natural language to physical 3D environments, it is stillchallenging to ground abstract, high-level instructions to a 3D scene.High-level instructions might not explicitly invoke semantic elements in thescene, and even the process of breaking a high-level task into a set of moreconcrete subtasks, a process called hierarchical task analysis, isenvironment-dependent. In this work, we propose ASHiTA, the first frameworkthat generates a task hierarchy grounded to a 3D scene graph by breaking downhigh-level tasks into grounded subtasks. ASHiTA alternates LLM-assistedhierarchical task analysis, to generate the task breakdown, with task-driven 3Dscene graph construction to generate a suitable representation of theenvironment. Our experiments show that ASHiTA performs significantly betterthan LLM baselines in breaking down high-level tasks into environment-dependentsubtasks and is additionally able to achieve grounding performance comparableto state-of-the-art methods.</description>
      <author>example@mail.com (Yun Chang, Leonor Fermoselle, Duy Ta, Bernadette Bucher, Luca Carlone, Jiuguang Wang)</author>
      <guid isPermaLink="false">2504.06553v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network-Based Distributed Optimal Control for Linear Networked Systems: An Online Distributed Training Approach</title>
      <link>http://arxiv.org/abs/2504.06439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了线性网络系统的分布式最优控制问题，提出了一种基于图循环神经网络（GRNN）的分布式最优控制方法，并实现了在线分布式训练。&lt;h4&gt;背景&lt;/h4&gt;目前大多数方法导致集中式最优控制器和离线训练过程，而网络容错性需求的增加要求控制器更加分布化和在线训练。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够在线分布式训练的分布式最优控制器，以应对网络容错性需求的增长。&lt;h4&gt;方法&lt;/h4&gt;首先，提出了一种基于GRNN的分布式最优控制方法，并将问题表述为自监督学习问题；然后，通过分布式梯度计算实现分布式在线训练，并设计了基于一致性的分布式在线训练优化器；此外，通过假设GRNN控制器的非线性激活函数具有局部扇形有界和斜率限制，提供了线性网络系统在所提GRNN控制器下的局部闭环稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过数值模拟验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的GRNN方法能够实现线性网络系统的分布式在线训练，具有良好的稳定性和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we consider the distributed optimal control problem for linearnetworked systems. In particular, we are interested in learning distributedoptimal controllers using graph recurrent neural networks (GRNNs). Most of theexisting approaches result in centralized optimal controllers with offlinetraining processes. However, as the increasing demand of network resilience,the optimal controllers are further expected to be distributed, and aredesirable to be trained in an online distributed fashion, which are also themain contributions of our work. To solve this problem, we first propose aGRNN-based distributed optimal control method, and we cast the problem as aself-supervised learning problem. Then, the distributed online training isachieved via distributed gradient computation, and inspired by the(consensus-based) distributed optimization idea, a distributed online trainingoptimizer is designed. Furthermore, the local closed-loop stability of thelinear networked system under our proposed GRNN-based controller is provided byassuming that the nonlinear activation function of the GRNN-based controller isboth local sector-bounded and slope-restricted. The effectiveness of ourproposed method is illustrated by numerical simulations using a specificallydeveloped simulator.</description>
      <author>example@mail.com (Zihao Song, Panos J. Antsaklis, Hai Lin)</author>
      <guid isPermaLink="false">2504.06439v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>S'MoRE: Structural Mixture of Residual Experts for LLM Fine-tuning</title>
      <link>http://arxiv.org/abs/2504.06426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为S'MoRE的新型框架，该框架结合了LoRA的高效性和MoE的灵活性，以实现预训练大型语言模型的微调。&lt;h4&gt;背景&lt;/h4&gt;微调预训练的大型语言模型（LLMs）面临着参数效率和模型容量之间的平衡挑战。现有的LoRA方法虽然高效，但缺乏灵活性；而MoE架构在增加模型容量的同时，也带来了更多未充分利用的参数。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的框架S'MoRE，旨在提高LLMs微调的效率。&lt;h4&gt;方法&lt;/h4&gt;S'MoRE通过层次化的低秩分解专家权重，生成不同阶数的残差，这些残差以多层结构相互连接。通过将输入标记路由到残差子树中，S'MoRE通过实例化和组装少数低秩矩阵来模拟多个专家的能力。此外，S'MoRE的层间传播被设计为一种特殊的图神经网络（GNN）。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析和实验结果表明，与传统的MoE或Mixture-of-LoRA相比，S'MoRE在相似的参数预算下，通过指数级提高了“结构灵活性”。&lt;h4&gt;结论&lt;/h4&gt;S'MoRE实现了优异的微调性能，为高效的LLMs适应提供了一种变革性的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：微调预训练的大型语言模型（LLMs）面临着参数效率和模型容量平衡的双重挑战。现有的方法如低秩适应（LoRA）虽然高效但缺乏灵活性，而混合专家（MoE）架构在增加模型容量的同时，也带来了更多未充分利用的参数。为了解决这些限制，我们提出了结构化混合残差专家（S'MoRE）这一新颖的框架，它无缝地整合了LoRA的高效性和MoE的灵活性。具体来说，S'MoRE采用专家权重的层次化低秩分解，生成不同阶数的残差，这些残差以多层结构相互连接。通过将输入标记路由到残差子树中，S'MoRE通过实例化和组装少数低秩矩阵来模拟多个专家的能力。我们还将S'MoRE的残差层间传播设计为一种特殊的图神经网络（GNN），并证明在相似的参数预算下，S'MoRE通过指数级提高了传统MoE（或Mixture-of-LoRA）的“结构灵活性”。全面的理论分析和实证结果表明，S'MoRE实现了优越的微调性能，为高效的LLMs适应提供了一种变革性的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning pre-trained large language models (LLMs) presents a dualchallenge of balancing parameter efficiency and model capacity. Existingmethods like low-rank adaptations (LoRA) are efficient but lack flexibility,while Mixture-of-Experts (MoE) architectures enhance model capacity at the costof more &amp; under-utilized parameters. To address these limitations, we proposeStructural Mixture of Residual Experts (S'MoRE), a novel framework thatseamlessly integrates the efficiency of LoRA with the flexibility of MoE.Specifically, S'MoRE employs hierarchical low-rank decomposition of expertweights, yielding residuals of varying orders interconnected in a multi-layerstructure. By routing input tokens through sub-trees of residuals, S'MoREemulates the capacity of many experts by instantiating and assembling just afew low-rank matrices. We craft the inter-layer propagation of S'MoRE'sresiduals as a special type of Graph Neural Network (GNN), and prove that undersimilar parameter budget, S'MoRE improves "structural flexibility" oftraditional MoE (or Mixture-of-LoRA) by exponential order. Comprehensivetheoretical analysis and empirical results demonstrate that S'MoRE achievessuperior fine-tuning performance, offering a transformative approach forefficient LLM adaptation.</description>
      <author>example@mail.com (Hanqing Zeng, Yinglong Xia, Zhuokai Zhao, Gilbert Jiang, Qiang Zhang, Jiayi Liu, Lizhu Zhang, Xiangjun Fan, Benyu Zhang)</author>
      <guid isPermaLink="false">2504.06426v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>DiffusionCom: Structure-Aware Multimodal Diffusion Model for Multimodal Knowledge Graph Completion</title>
      <link>http://arxiv.org/abs/2504.06543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DiffusionCom的结构感知多模态扩散模型，用于多模态知识图谱补全。该模型通过生成模型的方法来建模实体和关系之间的关联，并利用结构信息来提高知识图谱补全的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态知识图谱补全方法大多基于判别模型，这些方法在捕捉现实世界知识图谱中的复杂连接时效率较低，限制了它们的整体性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高多模态知识图谱补全的性能，尤其是通过有效利用结构信息。&lt;h4&gt;方法&lt;/h4&gt;DiffusionCom从生成模型的角度出发，将实体和关系对的关联建模为它们的联合概率分布，并将多模态知识图谱补全任务视为从噪声中逐步生成联合概率分布的过程。此外，为了充分利用知识图谱中的结构信息，提出了Structure-MKGformer，这是一种自适应的结构感知多模态知识表示学习方法，作为DiffusionCom的编码器。Structure-MKGformer通过多模态图注意力网络（MGAT）捕获丰富的结构信息，并自适应地将其与实体表示融合，从而增强这些表示的结构感知能力。&lt;h4&gt;主要发现&lt;/h4&gt;DiffusionCom通过使用生成和判别损失来训练生成器，而特征提取器仅使用判别损失进行优化。这种双重方法使DiffusionCom能够利用生成和判别模型的优点。在FB15k-237-IMG和WN18-IMG数据集上的大量实验表明，DiffusionCom优于最先进的模型。&lt;h4&gt;结论&lt;/h4&gt;DiffusionCom是一种有效的多模态知识图谱补全方法，它通过结合生成和判别模型的优势，并充分利用结构信息，显著提高了知识图谱补全的性能。&lt;h4&gt;翻译&lt;/h4&gt;Most current MKGC approaches are predominantly based on discriminative models that maximize conditional likelihood. These approaches struggle to efficiently capture the complex connections in real-world knowledge graphs, thereby limiting their overall performance. To address this issue, we propose a structure-aware multimodal Diffusion model for multimodal knowledge graph Completion (DiffusionCom). DiffusionCom innovatively approaches the problem from the perspective of generative models, modeling the association between the (head, relation) pair and candidate tail entities as their joint probability distribution p((head, relation), (tail)), and framing the MKGC task as a process of gradually generating the joint probability distribution from noise. Furthermore, to fully leverage the structural information in MKGs, we propose Structure-MKGformer, an adaptive and structure-aware multimodal knowledge representation learning method, as the encoder for DiffusionCom. Structure-MKGformer captures rich structural information through a multimodal graph attention network (MGAT) and adaptively fuses it with entity representations, thereby enhancing the structural awareness of these representations. This design effectively addresses the limitations of existing MKGC methods, particularly those based on multimodal pre-trained models, in underutilizing structural information. DiffusionCom is trained using both generative and discriminative losses for the generator, while the feature extractor is optimized exclusively with discriminative loss. This dual approach allows DiffusionCom to harness the strengths of both generative and discriminative models. Extensive experiments on the FB15k-237-IMG and WN18-IMG datasets demonstrate that DiffusionCom outperforms state-of-the-art models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most current MKGC approaches are predominantly based on discriminative modelsthat maximize conditional likelihood. These approaches struggle to efficientlycapture the complex connections in real-world knowledge graphs, therebylimiting their overall performance. To address this issue, we propose astructure-aware multimodal Diffusion model for multimodal knowledge graphCompletion (DiffusionCom). DiffusionCom innovatively approaches the problemfrom the perspective of generative models, modeling the association between the$(head, relation)$ pair and candidate tail entities as their joint probabilitydistribution $p((head, relation), (tail))$, and framing the MKGC task as aprocess of gradually generating the joint probability distribution from noise.Furthermore, to fully leverage the structural information in MKGs, we proposeStructure-MKGformer, an adaptive and structure-aware multimodal knowledgerepresentation learning method, as the encoder for DiffusionCom.Structure-MKGformer captures rich structural information through a multimodalgraph attention network (MGAT) and adaptively fuses it with entityrepresentations, thereby enhancing the structural awareness of theserepresentations. This design effectively addresses the limitations of existingMKGC methods, particularly those based on multimodal pre-trained models, inutilizing structural information. DiffusionCom is trained using both generativeand discriminative losses for the generator, while the feature extractor isoptimized exclusively with discriminative loss. This dual approach allowsDiffusionCom to harness the strengths of both generative and discriminativemodels. Extensive experiments on the FB15k-237-IMG and WN18-IMG datasetsdemonstrate that DiffusionCom outperforms state-of-the-art models.</description>
      <author>example@mail.com (Wei Huang, Meiyu Liang, Peining Li, Xu Hou, Yawen Li, Junping Du, Zhe Xue, Zeli Guan)</author>
      <guid isPermaLink="false">2504.06543v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>SemiDAViL: Semi-supervised Domain Adaptation with Vision-Language Guidance for Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.06389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的语言引导的半监督领域自适应（SSDA）方法，用于语义分割，通过利用预训练语言模型中的语义关系来增强特征表示，从而提高分割性能。&lt;h4&gt;背景&lt;/h4&gt;领域自适应（DA）和半监督学习（SSL）在半监督领域自适应（SSDA）中结合，旨在使用有限的标记目标样本和大量的未标记目标数据将知识从源域迁移到目标域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的语言引导的SSDA设置，用于解决语义分割中由于监督不足和数据分布不平衡导致的性能问题。&lt;h4&gt;方法&lt;/h4&gt;利用视觉-语言模型（VLM）的语义泛化能力，在SSDA框架内建立协同框架，并引入类平衡分割损失公式来应对长尾分布中的类不平衡挑战。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多种领域自适应场景中，与现有最先进（SoTA）方法相比，显示出显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;提出的语言引导的SSDA方法有效地提高了语义分割的性能，为解决领域自适应和半监督学习中的挑战提供了一种新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Domain Adaptation (DA) and Semi-supervised Learning (SSL) converge in Semi-supervised Domain Adaptation (SSDA), where the objective is to transfer knowledge from a source domain to a target domain using a combination of limited labeled target samples and abundant unlabeled target data. Although intuitive, a simple amalgamation of DA and SSL is suboptimal in semantic segmentation due to two major reasons: (1) previous methods, while able to learn good segmentation boundaries, are prone to confuse classes with similar visual appearance due to limited supervision; and (2) skewed and imbalanced training data distribution preferring source representation learning whereas impeding from exploring limited information about tailed classes. Language guidance can serve as a pivotal semantic bridge, facilitating robust class discrimination and mitigating visual ambiguities by leveraging the rich semantic relationships encoded in pre-trained language models to enhance feature representations across domains. Therefore, we propose the first language-guided SSDA setting for semantic segmentation in this work. Specifically, we harness the semantic generalization capabilities inherent in vision-language models (VLMs) to establish a synergistic framework within the SSDA paradigm. To address the inherent class-imbalance challenges in long-tailed distributions, we introduce class-balanced segmentation loss formulations that effectively regularize the learning process. Through extensive experimentation across diverse domain adaptation scenarios, our approach demonstrates substantial performance improvements over contemporarystate-of-the-art (SoTA) methodologies. Code is available: [GitHub](https://github.com/hritam-98/SemiDAViL).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain Adaptation (DA) and Semi-supervised Learning (SSL) converge inSemi-supervised Domain Adaptation (SSDA), where the objective is to transferknowledge from a source domain to a target domain using a combination oflimited labeled target samples and abundant unlabeled target data. Althoughintuitive, a simple amalgamation of DA and SSL is suboptimal in semanticsegmentation due to two major reasons: (1) previous methods, while able tolearn good segmentation boundaries, are prone to confuse classes with similarvisual appearance due to limited supervision; and (2) skewed and imbalancedtraining data distribution preferring source representation learning whereasimpeding from exploring limited information about tailed classes. Languageguidance can serve as a pivotal semantic bridge, facilitating robust classdiscrimination and mitigating visual ambiguities by leveraging the richsemantic relationships encoded in pre-trained language models to enhancefeature representations across domains. Therefore, we propose the firstlanguage-guided SSDA setting for semantic segmentation in this work.Specifically, we harness the semantic generalization capabilities inherent invision-language models (VLMs) to establish a synergistic framework within theSSDA paradigm. To address the inherent class-imbalance challenges inlong-tailed distributions, we introduce class-balanced segmentation lossformulations that effectively regularize the learning process. Throughextensive experimentation across diverse domain adaptation scenarios, ourapproach demonstrates substantial performance improvements over contemporarystate-of-the-art (SoTA) methodologies. Code is available:\href{https://github.com/hritam-98/SemiDAViL}{GitHub}.</description>
      <author>example@mail.com (Hritam Basak, Zhaozheng Yin)</author>
      <guid isPermaLink="false">2504.06389v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Deep spatio-temporal point processes: Advances and new directions</title>
      <link>http://arxiv.org/abs/2504.06364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了时空点过程（STPPs）在犯罪学、地震学、流行病学和社会网络等领域的重要应用。文章介绍了深度影响核方法的发展，该方法通过直接建模条件强度函数或学习灵活的数据驱动影响核来增强模型的表达能力，同时保持了统计可解释性。文章解释了开发深度核点过程的主要组成部分，包括使用函数基分解和图神经网络来编码复杂的空间或网络结构，以及使用基于似然和免似然的方法进行估计，并讨论了大规模数据的计算可扩展性。此外，还讨论了核可识别性的理论基础，并通过模拟和实际数据示例展示了其在犯罪分析、地震余震预测和脓毒症预测建模中的应用。最后，讨论了该领域的前景方向。&lt;h4&gt;背景&lt;/h4&gt;时空点过程（STPPs）用于模拟时间和空间中离散事件的分布，在犯罪学、地震学、流行病学和社会网络等领域有重要应用。&lt;h4&gt;目的&lt;/h4&gt;介绍深度影响核方法的发展及其在时空点过程中的应用。&lt;h4&gt;方法&lt;/h4&gt;开发深度核点过程，利用函数基分解和图神经网络编码复杂结构，使用基于似然和免似然的方法进行估计，并讨论计算可扩展性。&lt;h4&gt;主要发现&lt;/h4&gt;深度影响核方法增强了模型的表达能力，同时保持了统计可解释性。&lt;h4&gt;结论&lt;/h4&gt;深度影响核方法在时空点过程建模中有潜力，并在多个领域有应用。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Spatio-temporal point processes (STPPs) model discrete events distributed in time and space, with important applications in areas such as criminology, seismology, epidemiology, and social networks. Traditional models often rely on parametric kernels, limiting their ability to capture heterogeneous, nonstationary dynamics. Recent innovations integrate deep neural architectures-- either by modeling the conditional intensity function directly or by learning flexible, data-driven influence kernels, substantially broadening their expressive power. This article reviews the development of the deep influence kernel approach, which enjoys statistical explainability, since the influence kernel remains in the model to capture the spatiotemporal propagation of event influence and its impact on future events, while also possessing strong expressive power, thereby benefiting from both worlds. We explain the main components in developing deep kernel point processes, leveraging tools such as functional basis decomposition and graph neural networks to encode complex spatial or network structures, as well as estimation using both likelihood-based and likelihood-free methods, and address computational scalability for large-scale data. We also discuss the theoretical foundation of kernel identifiability. Simulated and real-data examples highlight applications to crime analysis, earthquake aftershock prediction, and sepsis prediction modeling, and we conclude by discussing promising directions for the field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatio-temporal point processes (STPPs) model discrete events distributed intime and space, with important applications in areas such as criminology,seismology, epidemiology, and social networks. Traditional models often rely onparametric kernels, limiting their ability to capture heterogeneous,nonstationary dynamics. Recent innovations integrate deep neural architectures-- either by modeling the conditional intensity function directly or bylearning flexible, data-driven influence kernels, substantially broadeningtheir expressive power. This article reviews the development of the deepinfluence kernel approach, which enjoys statistical explainability, since theinfluence kernel remains in the model to capture the spatiotemporal propagationof event influence and its impact on future events, while also possessingstrong expressive power, thereby benefiting from both worlds. We explain themain components in developing deep kernel point processes, leveraging toolssuch as functional basis decomposition and graph neural networks to encodecomplex spatial or network structures, as well as estimation using bothlikelihood-based and likelihood-free methods, and address computationalscalability for large-scale data. We also discuss the theoretical foundation ofkernel identifiability. Simulated and real-data examples highlight applicationsto crime analysis, earthquake aftershock prediction, and sepsis predictionmodeling, and we conclude by discussing promising directions for the field.</description>
      <author>example@mail.com (Xiuyuan Cheng, Zheng Dong, Yao Xie)</author>
      <guid isPermaLink="false">2504.06364v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Robo-taxi Fleet Coordination at Scale via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.06125v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 6 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种新型的决策框架，用于解决大规模的自动移动需求（AMoD）系统协调问题，通过结合数学建模和数据驱动技术，实现了系统性能、计算效率和泛化能力的提升。&lt;h4&gt;背景&lt;/h4&gt;AMoD系统，即自动移动需求系统，具有减少污染、能源消耗和城市拥堵的社会效益，但其规模化的协调是一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合数学建模和数据驱动技术的决策框架，以解决AMoD系统协调问题。&lt;h4&gt;方法&lt;/h4&gt;通过强化学习视角提出AMoD协调问题，并设计了一个基于图网络的框架，利用图表示学习、强化学习和经典运筹研究工具的优势。&lt;h4&gt;主要发现&lt;/h4&gt;在多种模拟真实性和场景中进行广泛评估，证明了该方法在系统性能、计算效率和泛化能力方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;论文提出了一个有效的AMoD系统协调框架，并公开了基准、数据集和模拟器，以及开源代码库，以促进该领域的研究民主化。&lt;h4&gt;翻译&lt;/h4&gt;The paper introduces a novel decision-making framework for addressing the coordination challenge of large-scale Autonomous Mobility-on-Demand (AMoD) systems by combining mathematical modeling with data-driven techniques. This approach, evaluated across various simulation fidelity and scenarios, demonstrates superior system performance, computational efficiency, and generalizability compared to existing methods. Motivated by the need to democratize research efforts in this area, the paper also releases publicly available benchmarks, datasets, and simulators for network-level coordination, along with an open-source codebase designed to provide accessible simulation platforms and establish a standardized validation process for comparing methodologies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fleets of robo-taxis offering on-demand transportation services, commonlyknown as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promisefor societal benefits, such as reducing pollution, energy consumption, andurban congestion. However, orchestrating these systems at scale remains acritical challenge, with existing coordination algorithms often failing toexploit the systems' full potential. This work introduces a noveldecision-making framework that unites mathematical modeling with data-driventechniques. In particular, we present the AMoD coordination problem through thelens of reinforcement learning and propose a graph network-based framework thatexploits the main strengths of graph representation learning, reinforcementlearning, and classical operations research tools. Extensive evaluations acrossdiverse simulation fidelities and scenarios demonstrate the flexibility of ourapproach, achieving superior system performance, computational efficiency, andgeneralizability compared to prior methods. Finally, motivated by the need todemocratize research efforts in this area, we release publicly availablebenchmarks, datasets, and simulators for network-level coordination alongsidean open-source codebase designed to provide accessible simulation platforms andestablish a standardized validation process for comparing methodologies. Codeavailable at: https://github.com/StanfordASL/RL4AMOD</description>
      <author>example@mail.com (Luigi Tresca, Carolin Schmidt, James Harrison, Filipe Rodrigues, Gioele Zardini, Daniele Gammelli, Marco Pavone)</author>
      <guid isPermaLink="false">2504.06125v2</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Bridging the Gap Between Contextual and Standard Stochastic Bilevel Optimization</title>
      <link>http://arxiv.org/abs/2503.19991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CSBO的上下文随机双层优化方法，通过结合上下文特定的下层问题，扩展了标准的随机双层优化方法。该方法由于上下文实化的无限约束，使得计算复杂性远高于SBO，并提出了一种新的简化框架，通过参数化将CSBO转化为等价的SBO问题，从而消除了条件采样的需求。在合理的上下文分布和下层正则性假设下，证明了CSBO的ε-稳定解可以通过近似最优的采样复杂度实现。&lt;h4&gt;背景&lt;/h4&gt;CSBO在元学习和超参数优化等应用中引入了上下文特定的下层问题，导致无限数量的约束，使得计算复杂性显著高于SBO。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决CSBO问题，提高计算效率和理论保证。&lt;h4&gt;方法&lt;/h4&gt;通过参数化将CSBO转化为等价的SBO问题，消除条件采样的需求。&lt;h4&gt;主要发现&lt;/h4&gt;在合理的上下文分布和下层正则性假设下，证明了CSBO的ε-稳定解可以通过近似最优的采样复杂度实现。&lt;h4&gt;结论&lt;/h4&gt;该方法提高了CSBO问题的实际解决能力，通过改进计算效率和理论保证。&lt;h4&gt;翻译&lt;/h4&gt;摘要：上下文随机双层优化（CSBO）通过结合上下文特定的下层问题扩展了标准的随机双层优化（SBO），这些下层问题出现在元学习和超参数优化等应用中。这种结构引入了无限数量的约束——每个上下文实现一个——使得CSBO的计算复杂性远高于SBO，因为不同上下文之间最小化器的模糊关系表明，对于每个上层迭代需要计算大量的下层解。现有的CSBO方法面临两个主要限制：与SBO相比存在显著的复杂性差距，并且依赖于不切实际的条件采样算子。我们提出了一种新的简化框架，通过参数化将下层解对上层决策和上下文的依赖解耦，从而将CSBO转化为等价的SBO问题，消除了条件采样的需求。在上下文分布和下层正则性的合理假设下，我们证明了CSBO的ε-稳定解可以通过近似最优的采样复杂度O(ε^-3)实现。我们的方法通过提高计算效率和理论保证，增强了解决CSBO问题的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contextual Stochastic Bilevel Optimization (CSBO) extends standard StochasticBilevel Optimization (SBO) by incorporating context-specific lower-levelproblems, which arise in applications such as meta-learning and hyperparameteroptimization. This structure imposes an infinite number of constraints - onefor each context realization - making CSBO significantly more challenging thanSBO as the unclear relationship between minimizers across different contextssuggests computing numerous lower-level solutions for each upper-leveliteration. Existing approaches to CSBO face two major limitations: substantialcomplexity gaps compared to SBO and reliance on impractical conditionalsampling oracles. We propose a novel reduction framework that decouples thedependence of the lower-level solution on the upper-level decision and contextthrough parametrization, thereby transforming CSBO into an equivalent SBOproblem and eliminating the need for conditional sampling. Under reasonableassumptions on the context distribution and the regularity of the lower-level,we show that an $\epsilon$-stationary solution to CSBO can be achieved with anear-optimal sampling complexity $\tilde{O}(\epsilon^{-3})$. Our approachenhances the practicality of solving CSBO problems by improving bothcomputational efficiency and theoretical guarantees.</description>
      <author>example@mail.com (Maxime Bouscary, Jiawei Zhang, Saurabh Amin)</author>
      <guid isPermaLink="false">2503.19991v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
  <item>
      <title>Towards an Optimal Bound for the Interleaving Distance on Mapper Graphs</title>
      <link>http://arxiv.org/abs/2504.03865v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究Mapper图在拓扑数据分析和可视化中的应用，提出了一种计算Mapper图交错距离的新方法，并优化了损失函数，用于估计距离。&lt;h4&gt;背景&lt;/h4&gt;Mapper图是拓扑数据分析和可视化中常用的工具，可以视为Reeb图的离散近似，用于分析复杂数据的形状和连通性。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种计算Mapper图交错距离的方法，并优化相关损失函数，以提高距离估计的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用Mapper图的范畴论表述，开发了一种计算损失函数的框架，将最佳分配问题转化为整数线性规划问题进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法可以成功匹配已知交错距离的小规模Mapper图，并在MPEG-7数据集上对图像进行了分类。&lt;h4&gt;结论&lt;/h4&gt;该方法为Mapper图距离估计提供了一种有效且实用的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Mapper图是拓扑数据分析与可视化的常用工具，可以视为Reeb图的离散近似，为复杂数据的形状和连通性提供了洞察。对于给定的具有函数f：X→R的高维点云X，mapper图提供了由f诱导的X拓扑结构的摘要，其中每个节点代表一个局部邻域，边连接对应邻域重叠的节点。本文关注的是mapper图的交错距离，它是Reeb图版本的离散化，计算复杂度为NP-hard。这种距离通过衡量它们必须“拉伸”到何种程度才能变得可比较来量化两个mapper图之间的相似性。最近的工作介绍了一个损失函数，为mapper图的交错距离提供了上界，该函数评估了给定分配距离真实交错的程度。找到损失是计算上可行的，提供了一种估计距离的实用方法。在本文中，我们采用mapper图的范畴论表述，并开发了计算相关损失函数的第一种框架。由于边界质量取决于选择的分配，我们将损失函数的优化问题表述为寻找最佳分配的整数线性规划问题。为了评估我们优化的有效性，我们将它应用于交错距离已知的小规模mapper图，证明优化后的上界在这些情况下成功地匹配了交错距离。此外，我们在MPEG-7数据集上进行了实验，计算了由图像派生的mapper图集合的成对最优损失，并利用距离边界进行图像分类。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mapper graphs are a widely used tool in topological data analysis andvisualization. They can be viewed as discrete approximations of Reeb graphs,offering insight into the shape and connectivity of complex data. Given ahigh-dimensional point cloud $\mathbb{X}$ equipped with a function $f:\mathbb{X} \to \mathbb{R}$, a mapper graph provides a summary of thetopological structure of $\mathbb{X}$ induced by $f$, where each noderepresents a local neighborhood, and edges connect nodes whose correspondingneighborhoods overlap. Our focus is the interleaving distance for mappergraphs, arising from a discretization of the version for Reeb graphs, which isNP-hard to compute. This distance quantifies the similarity between two mappergraphs by measuring the extent to which they must be ``stretched" to becomecomparable. Recent work introduced a loss function that provides an upper boundon the interleaving distance for mapper graphs, which evaluates how far a givenassignment is from being a true interleaving. Finding the loss iscomputationally tractable, offering a practical way to estimate the distance.  In this paper, we employ a categorical formulation of mapper graphs anddevelop the first framework for computing the associated loss function. Sincethe quality of the bound depends on the chosen assignment, we optimize thisloss function by formulating the problem of finding the best assignment as aninteger linear programming problem. To evaluate the effectiveness of ouroptimization, we apply it to small mapper graphs where the interleavingdistance is known, demonstrating that the optimized upper bound successfullymatches the interleaving distance in these cases. Additionally, we conduct anexperiment on the MPEG-7 dataset, computing the pairwise optimal loss on acollection of mapper graphs derived from images and leveraging the distancebound for image classification.</description>
      <author>example@mail.com (Erin Wolf Chambers, Ishika Ghosh, Elizabeth Munch, Sarah Percival, Bei Wang)</author>
      <guid isPermaLink="false">2504.03865v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>Modular Soft Wearable Glove for Real-Time Gesture Recognition and Dynamic 3D Shape Reconstruction</title>
      <link>http://arxiv.org/abs/2504.05983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于线状电极和液态金属（EGaIn）的柔性传感器，用于提高可穿戴手套在虚拟现实、医疗康复和工业自动化等领域的应用。该手套具有高灵敏度、模块化和柔韧性，能够准确识别手势和动态重建手部形态。&lt;h4&gt;背景&lt;/h4&gt;随着人机交互（HCI）需求的增加，柔性可穿戴手套在虚拟现实、医疗康复和工业自动化等领域具有巨大潜力。然而，当前技术存在灵敏度不足和耐用性有限等问题，限制了其广泛应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种高灵敏度、模块化和柔韧的可穿戴手套，以解决当前技术中的不足，提高其在各种应用中的性能。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于线状电极和液态金属的柔性电容传感器，并将其集成到一个适合人手解剖结构的传感器模块中。该系统能够独立捕获每个手指关节的弯曲信息，并记录相邻手指之间的微妙变化，从而实现准确的手势识别和动态手部形态重建。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于卷积神经网络（CNN）和多层感知器（MLP）的分类器在30种手势上实现了99.15%的准确率。同时，基于Transformer的深度神经网络（DNN）以平均距离（AD）2.076±3.231毫米的精度准确重建动态手部形状，关键点的重建准确率超过SOTA基准9.7%至64.9%。&lt;h4&gt;结论&lt;/h4&gt;该手套在手势识别和手部重建方面表现出色，具有高准确性、鲁棒性和可扩展性，是下一代人机交互系统的有前途解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着人机交互需求的增加，柔性可穿戴手套在虚拟现实、医疗康复和工业自动化等领域已成为一种有希望的解决方案。然而，现有技术仍然存在灵敏度不足和耐用性有限等问题，这阻碍了其广泛应用。本文提出了一种基于线状电极和液态金属（EGaIn）的具有高灵敏度、模块化和柔性的电容传感器，并将其集成到一个适合人手解剖结构的传感器模块中。该系统独立地捕获每个手指关节的弯曲信息，而相邻手指之间的额外测量则能够记录手指间距的微妙变化。这种设计实现了使用点云准确识别手势和动态重建复杂运动的动态手部形态。实验结果表明，我们的基于卷积神经网络（CNN）和多层感知器（MLP）的分类器在30种手势上实现了99.15%的准确率。同时，基于Transformer的深度神经网络（DNN）以平均距离（AD）2.076±3.231毫米的精度准确重建动态手部形状，关键点的重建准确率超过SOTA基准9.7%至64.9%。该手套在手势识别和手部重建方面表现出色，具有高准确性、鲁棒性和可扩展性，是下一代人机交互系统的有前途解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing demand for human-computer interaction (HCI), flexiblewearable gloves have emerged as a promising solution in virtual reality,medical rehabilitation, and industrial automation. However, the currenttechnology still has problems like insufficient sensitivity and limiteddurability, which hinder its wide application. This paper presents a highlysensitive, modular, and flexible capacitive sensor based on line-shapedelectrodes and liquid metal (EGaIn), integrated into a sensor module tailoredto the human hand's anatomy. The proposed system independently captures bendinginformation from each finger joint, while additional measurements betweenadjacent fingers enable the recording of subtle variations in inter-fingerspacing. This design enables accurate gesture recognition and dynamic handmorphological reconstruction of complex movements using point clouds.Experimental results demonstrate that our classifier based on ConvolutionNeural Network (CNN) and Multilayer Perceptron (MLP) achieves an accuracy of99.15% across 30 gestures. Meanwhile, a transformer-based Deep Neural Network(DNN) accurately reconstructs dynamic hand shapes with an Average Distance (AD)of 2.076\pm3.231 mm, with the reconstruction accuracy at individual key pointssurpassing SOTA benchmarks by 9.7% to 64.9%. The proposed glove shows excellentaccuracy, robustness and scalability in gesture recognition and handreconstruction, making it a promising solution for next-generation HCI systems.</description>
      <author>example@mail.com (Huazhi Dong, Chunpeng Wang, Mingyuan Jiang, Francesco Giorgio-Serchi, Yunjie Yang)</author>
      <guid isPermaLink="false">2504.05983v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>Turin3D: Evaluating Adaptation Strategies under Label Scarcity in Urban LiDAR Segmentation with Semi-Supervised Techniques</title>
      <link>http://arxiv.org/abs/2504.05882v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPRW2025 - USM3D&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Turin3D，一个用于点云语义分割的新的空中激光雷达数据集，并在都灵市中心区域进行了数据收集和比较。&lt;h4&gt;背景&lt;/h4&gt;3D语义分割在都市建模中扮演着关键角色，它能够使我们对城市环境有更深入的理解和映射。&lt;h4&gt;目的&lt;/h4&gt;提出Turin3D数据集，并评估其性能，同时通过半监督学习方法提高点云语义分割模型的性能。&lt;h4&gt;方法&lt;/h4&gt;数据收集过程被描述，并与文献中提出的其他数据集进行了比较。数据集的验证和测试集进行了手动标注，以确保技术评估的可靠性。&lt;h4&gt;主要发现&lt;/h4&gt;对多个点云语义分割模型在Turin3D数据集上的性能进行了基准测试，并应用半监督学习技术提高了它们的性能。&lt;h4&gt;结论&lt;/h4&gt;该数据集将公开发布，以支持户外点云分割的研究，特别是对于无地面真实标注的监督学习和半监督学习方法具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D semantic segmentation plays a critical role in urban modelling, enablingdetailed understanding and mapping of city environments. In this paper, weintroduce Turin3D: a new aerial LiDAR dataset for point cloud semanticsegmentation covering an area of around 1.43 km2 in the city centre of Turinwith almost 70M points. We describe the data collection process and compareTurin3D with others previously proposed in the literature. We did not fullyannotate the dataset due to the complexity and time-consuming nature of theprocess; however, a manual annotation process was performed on the validationand test sets, to enable a reliable evaluation of the proposed techniques. Wefirst benchmark the performances of several point cloud semantic segmentationmodels, trained on the existing datasets, when tested on Turin3D, and thenimprove their performances by applying a semi-supervised learning techniqueleveraging the unlabelled training set. The dataset will be publicly availableto support research in outdoor point cloud segmentation, with particularrelevance for self-supervised and semi-supervised learning approaches given theabsence of ground truth annotations for the training set.</description>
      <author>example@mail.com (Luca Barco, Giacomo Blanco, Gaetano Chiriaco, Alessia Intini, Luigi La Riccia, Vittorio Scolamiero, Piero Boccardo, Paolo Garza, Fabrizio Dominici)</author>
      <guid isPermaLink="false">2504.05882v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models</title>
      <link>http://arxiv.org/abs/2504.06214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效训练方法，用于构建超长上下文语言模型，并分析了相关设计选择的影响。&lt;h4&gt;背景&lt;/h4&gt;长上下文能力对于文档和视频理解、情境学习和推理时间扩展等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;目的是通过构建超长上下文语言模型，扩展上下文长度，并保持模型的指令遵循和推理能力。&lt;h4&gt;方法&lt;/h4&gt;方法包括利用高效的持续预训练策略来扩展上下文窗口，并采用有效的指令调整来维持指令遵循和推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;UltraLong-8B模型在多个长上下文基准测试中实现了最先进的性能，同时在标准基准测试中也保持了竞争力。&lt;h4&gt;结论&lt;/h4&gt;研究建立了一个稳健的框架，能够高效地扩展上下文长度，同时保持模型的通用能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：长上下文能力对于包括文档和视频理解、情境学习和推理时间扩展在内的广泛应用至关重要，这些应用都需要模型处理和推理长序列的文本和多模态数据。在本研究中，我们介绍了一种高效训练方法，用于从对齐指令模型构建超长上下文LLMs，将上下文长度的边界从128K推至1M、2M和4M个标记。我们的方法利用高效的持续预训练策略来扩展上下文窗口，并采用有效的指令调整来维持指令遵循和推理能力。基于Llama3.1-Instruct并使用我们的方法构建的UltraLong-8B在多个长上下文基准测试中实现了最先进的性能。重要的是，使用我们的方法训练的模型在标准基准测试中也保持了竞争力，这表明对于长上下文和短上下文任务都有平衡的改进。我们进一步对关键设计选择进行了深入分析，强调了扩展策略和数据组成的影响。我们的发现建立了一个稳健的框架，能够在保持通用模型能力的同时高效地扩展上下文长度。我们发布了所有模型权重：https://ultralong.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-context capabilities are essential for a wide range of applications,including document and video understanding, in-context learning, andinference-time scaling, all of which require models to process and reason overlong sequences of text and multimodal data. In this work, we introduce aefficient training recipe for building ultra-long context LLMs from alignedinstruct model, pushing the boundaries of context lengths from 128K to 1M, 2M,and 4M tokens. Our approach leverages efficient continued pretrainingstrategies to extend the context window and employs effective instructiontuning to maintain the instruction-following and reasoning abilities. OurUltraLong-8B, built on Llama3.1-Instruct with our recipe, achievesstate-of-the-art performance across a diverse set of long-context benchmarks.Importantly, models trained with our approach maintain competitive performanceon standard benchmarks, demonstrating balanced improvements for both long andshort context tasks. We further provide an in-depth analysis of key designchoices, highlighting the impacts of scaling strategies and data composition.Our findings establish a robust framework for efficiently scaling contextlengths while preserving general model capabilities. We release all modelweights at: https://ultralong.github.io/.</description>
      <author>example@mail.com (Chejian Xu, Wei Ping, Peng Xu, Zihan Liu, Boxin Wang, Mohammad Shoeybi, Bo Li, Bryan Catanzaro)</author>
      <guid isPermaLink="false">2504.06214v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>A Self-Supervised Framework for Space Object Behaviour Characterisation</title>
      <link>http://arxiv.org/abs/2504.06176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对太空物体行为分析的太空安全与可持续性基础模型，利用光曲线（LCs）进行行为分析，并通过自监督学习和迁移学习提高了异常检测和运动预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;随着轨道物体数量的增加，自动化方法对太空物体行为的特征分析对于太空安全至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够进行异常检测、运动预测和光曲线生成的太空物体行为分析模型。&lt;h4&gt;方法&lt;/h4&gt;使用光曲线（LCs）进行预训练，并采用Perceiver-Variational Autoencoder（VAE）架构，通过自监督和掩码重建进行预训练，然后使用独立的光曲线模拟器进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;预训练模型在重建误差为0.01%的情况下识别出可能异常的光曲线。微调后，模型在异常检测和运动模式预测（如太阳对准、自旋等）中分别达到了88%和82%的准确率，ROC AUC分数分别为0.90和0.95。对高置信度异常预测的分析揭示了包括特征物体轮廓和卫星反光在内的明显模式。&lt;h4&gt;结论&lt;/h4&gt;该研究通过自监督学习实现了异常检测、运动预测和合成数据生成，支持太空安全与可持续性，通过自动化监控和模拟能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在大量未标记数据集上预训练并在特定任务上进行微调的基础模型越来越多地应用于专业领域。最近的例子包括用于气候的ClimaX和用于卫星地球观测的Clay，但尚未开发用于太空物体行为分析的基础模型。随着轨道物体数量的增加，自动化方法对太空物体行为的特征分析对于太空安全至关重要。我们提出了一种专注于使用光曲线（LCs）进行太空物体行为分析的太空安全与可持续性基础模型。我们实现了一个Perceiver-Variational Autoencoder（VAE）架构，使用来自MMT-9天文台的227,000个LCs进行自监督重建和掩码重建进行预训练。VAE能够进行异常检测、运动预测和LC生成。我们使用两个独立的光曲线模拟器（CASSANDRA和GRIAL）对模型进行了微调，以进行异常检测和运动预测，使用了箱形机翼、Sentinel-3、SMOS和Starlink平台的CAD模型。我们的预训练模型在重建误差为0.01%的情况下识别出可能异常的光曲线。微调后，模型在异常检测和运动模式预测（如太阳对准、自旋等）中分别达到了88%和82%的准确率，ROC AUC分数分别为0.90和0.95。对真实数据中高置信度异常预测的分析揭示了包括特征物体轮廓和卫星反光在内的明显模式。在这里，我们展示了如何通过自监督学习同时实现从预训练中学习到的丰富表示的异常检测、运动预测和合成数据生成。因此，我们的工作通过自动化监控和模拟能力支持太空安全与可持续性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models, pre-trained on large unlabelled datasets beforetask-specific fine-tuning, are increasingly being applied to specialiseddomains. Recent examples include ClimaX for climate and Clay for satelliteEarth observation, but a Foundation Model for Space Object Behavioural Analysishas not yet been developed. As orbital populations grow, automated methods forcharacterising space object behaviour are crucial for space safety. We presenta Space Safety and Sustainability Foundation Model focusing on space objectbehavioural analysis using light curves (LCs). We implemented aPerceiver-Variational Autoencoder (VAE) architecture, pre-trained withself-supervised reconstruction and masked reconstruction on 227,000 LCs fromthe MMT-9 observatory. The VAE enables anomaly detection, motion prediction,and LC generation. We fine-tuned the model for anomaly detection &amp; motionprediction using two independent LC simulators (CASSANDRA and GRIALrespectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlinkplatforms. Our pre-trained model achieved a reconstruction error of 0.01%,identifying potentially anomalous light curves through reconstructiondifficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90and 0.95 ROC AUC scores respectively in both anomaly detection and motion modeprediction (sun-pointing, spin, etc.). Analysis of high-confidence anomalypredictions on real data revealed distinct patterns including characteristicobject profiles and satellite glinting. Here, we demonstrate howself-supervised learning can simultaneously enable anomaly detection, motionprediction, and synthetic data generation from rich representations learned inpre-training. Our work therefore supports space safety and sustainabilitythrough automated monitoring and simulation capabilities.</description>
      <author>example@mail.com (Ian Groves, Andrew Campbell, James Fernandes, Diego Rodriguez, Paul Murray, Massimiliano Vasile, Victoria Nockles)</author>
      <guid isPermaLink="false">2504.06176v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization</title>
      <link>http://arxiv.org/abs/2504.06265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的架构，将LLM微调重构成通过深度核方法优化的高斯过程边缘似然。该方法结合了LLM和GPs的优点，应用于Buchwald-Hartwig反应优化，显著提高了反应发现率。实验结果表明，该方法在多个任务和不同参数设置下均表现出鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;尽管大型语言模型（LLMs）可以编码复杂的潜在空间关系，但在不确定条件下的优化仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;填补这一空白，提出一种新的方法，将LLM微调作为高斯过程边缘似然优化的一种形式。&lt;h4&gt;方法&lt;/h4&gt;引入基于LLM的深度核，与GPs联合优化，以利用LLMs丰富的输入空间和GPs的预测不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Buchwald-Hartwig反应优化中提高了反应发现率，同时在多个基准测试中表现出鲁棒性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该方法通过边缘似然优化实现LLM和GPs的联合优化，无需外部损失，提高了样本效率优化并揭示了有效贝叶斯优化的关键因素。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) can encode complex relationships in their latentspaces, yet harnessing them for optimization under uncertainty remainschallenging. We address this gap with a novel architecture that reframes LLMfinetuning as Gaussian process (GP) marginal likelihood optimization via deepkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPsto preserve the benefits of both - LLMs to provide a rich and flexible inputspace for Bayesian optimization and - GPs to model this space with predictiveuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reactionoptimization, our method nearly doubles the discovery rate of high-performingreactions compared to static LLM embeddings (from 24% to 43% coverage of thetop 5% reactions in just 50 optimization iterations). We also observe a 14%improvement over domain-specific representations without requiring specializedfeatures. Extensive empirical evaluation across 19 benchmarks - ranging fromgeneral chemistry to reaction and molecular property optimization -demonstrates our method's robustness, generality, and consistent improvementsacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),(3) pretraining domains (chemistry-related or general-purpose) and (4)hyperparameter settings (tuned once on a single dataset). Finally, we explainthese improvements: joint LLM-GP optimization through marginal likelihoodimplicitly performs contrastive learning, aligning representations to produce(1) better-structured embedding spaces, (2) improved uncertainty calibration,and (3) more efficient sampling - without requiring any external loss. Thiswork provides both practical advances in sample-efficient optimization andinsights into what makes effective Bayesian optimization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) can encode complex relationships in their latentspaces, yet harnessing them for optimization under uncertainty remainschallenging. We address this gap with a novel architecture that reframes LLMfinetuning as Gaussian process (GP) marginal likelihood optimization via deepkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPsto preserve the benefits of both - LLMs to provide a rich and flexible inputspace for Bayesian optimization and - GPs to model this space with predictiveuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reactionoptimization, our method nearly doubles the discovery rate of high-performingreactions compared to static LLM embeddings (from 24% to 43% coverage of thetop 5% reactions in just 50 optimization iterations). We also observe a 14%improvement over domain-specific representations without requiring specializedfeatures. Extensive empirical evaluation across 19 benchmarks - ranging fromgeneral chemistry to reaction and molecular property optimization -demonstrates our method's robustness, generality, and consistent improvementsacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),(3) pretraining domains (chemistry-related or general-purpose) and (4)hyperparameter settings (tuned once on a single dataset). Finally, we explainthese improvements: joint LLM-GP optimization through marginal likelihoodimplicitly performs contrastive learning, aligning representations to produce(1) better-structured embedding spaces, (2) improved uncertainty calibration,and (3) more efficient sampling - without requiring any external loss. Thiswork provides both practical advances in sample-efficient optimization andinsights into what makes effective Bayesian optimization.</description>
      <author>example@mail.com (Bojana Ranković, Philippe Schwaller)</author>
      <guid isPermaLink="false">2504.06265v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>PRIMEDrive-CoT: A Precognitive Chain-of-Thought Framework for Uncertainty-Aware Object Interaction in Driving Scene Scenario</title>
      <link>http://arxiv.org/abs/2504.05908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at The IEEE/CVF Conference on Computer Vision and Pattern  Recognition 2025 - CVPRW&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PRIMEDrive-CoT的新型不确定性感知模型，用于解决驾驶场景中的物体交互和思维链（CoT）推理问题。&lt;h4&gt;背景&lt;/h4&gt;驾驶场景理解是一个涉及解释和关联驾驶环境中各种元素（如车辆、行人和交通信号）的关键现实问题。&lt;h4&gt;目的&lt;/h4&gt;针对现实世界中驾驶的不确定性和内在不确定性，提出一种能够处理不确定条件下的概率推理的方法。&lt;h4&gt;方法&lt;/h4&gt;结合基于LiDAR的3D物体检测和多视角RGB参考，使用贝叶斯图神经网络（BGNNs）对不确定条件下的物体交互和风险进行建模。通过CoT推理，利用物体动态和上下文线索，实现可解释的决策，并通过Grad-CAM可视化突出关注区域。&lt;h4&gt;主要发现&lt;/h4&gt;在DriveCoT数据集上的广泛评估表明，PRIMEDrive-CoT优于现有的CoT和风险感知模型。&lt;h4&gt;结论&lt;/h4&gt;PRIMEDrive-CoT模型在驾驶场景理解方面具有显著优势，能够提供可靠和可解释的驾驶场景理解。&lt;h4&gt;翻译&lt;/h4&gt;驾驶场景理解是涉及解释和关联驾驶环境中各种元素（如车辆、行人和交通信号）的关键现实问题。尽管自动驾驶技术取得了进展，但传统的管道仍然依赖于确定性的模型，这些模型无法捕捉现实世界中驾驶的概率性质和固有不确定性。为了解决这个问题，我们提出了PRIMEDrive-CoT，这是一种新的不确定性感知模型，用于驾驶场景中的物体交互和思维链（CoT）推理。特别是，我们的方法结合了基于LiDAR的3D物体检测和多视角RGB参考，以确保可解释和可靠的场景理解。使用贝叶斯图神经网络（BGNNs）对物体交互和风险进行建模，以在不确定条件下进行概率推理。通过CoT推理，利用物体动态和上下文线索，促进可解释的决策，同时Grad-CAM可视化突出了关注区域。在DriveCoT数据集上的广泛评估表明，PRIMEDrive-CoT优于现有的CoT和风险感知模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Driving scene understanding is a critical real-world problem that involvesinterpreting and associating various elements of a driving environment, such asvehicles, pedestrians, and traffic signals. Despite advancements in autonomousdriving, traditional pipelines rely on deterministic models that fail tocapture the probabilistic nature and inherent uncertainty of real-worlddriving. To address this, we propose PRIMEDrive-CoT, a novel uncertainty-awaremodel for object interaction and Chain-of-Thought (CoT) reasoning in drivingscenarios. In particular, our approach combines LiDAR-based 3D object detectionwith multi-view RGB references to ensure interpretable and reliable sceneunderstanding. Uncertainty and risk assessment, along with object interactions,are modelled using Bayesian Graph Neural Networks (BGNNs) for probabilisticreasoning under ambiguous conditions. Interpretable decisions are facilitatedthrough CoT reasoning, leveraging object dynamics and contextual cues, whileGrad-CAM visualizations highlight attention regions. Extensive evaluations onthe DriveCoT dataset demonstrate that PRIMEDrive-CoT outperformsstate-of-the-art CoT and risk-aware models.</description>
      <author>example@mail.com (Sriram Mandalika, Lalitha V, Athira Nambiar)</author>
      <guid isPermaLink="false">2504.05908v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>Orb-v3: atomistic simulation at scale</title>
      <link>http://arxiv.org/abs/2504.06231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Orb-v3，这是Orb系列通用原子势能的下一代模型。该模型在性能、速度和内存使用上取得了显著进步，在多种评估中接近当前最先进的技术水平，同时将延迟降低了10倍以上，内存降低了8倍以上。&lt;h4&gt;背景&lt;/h4&gt;Orb系列模型在性能、速度和内存使用之间寻求平衡，旨在提高原子模拟的效率。&lt;h4&gt;目的&lt;/h4&gt;开发Orb-v3模型，以在准确性、延迟和系统规模可扩展性上实现卓越性能，推动计算化学的新时代。&lt;h4&gt;方法&lt;/h4&gt;通过实验系统地跨越性能、速度和内存使用之间的平衡点，分析旋转等变、保守性和图稀疏性带来的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;与现有文献相反，发现非等变和非保守架构可以准确地模拟物理性质，包括需要势能面高阶导数的性质。&lt;h4&gt;结论&lt;/h4&gt;Orb-v3模型将推动计算化学进入一个新时代，该时代由高通量和中等规模的原子模拟驱动。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了Orb-v3，这是Orb系列通用原子势能的下一代。这个系列的模型在性能-速度-内存的帕累托前沿上取得了进展，在各种评估中提供了接近最先进技术水平的性能，同时将延迟降低了10倍以上，内存降低了8倍以上。我们的实验系统地穿越了这个前沿，描绘了由旋转等变、保守性和图稀疏性引起的权衡。与近期文献相反，我们发现非等变和非保守架构可以准确地模拟物理性质，包括那些需要势能面高阶导数的性质。这次模型发布遵循的原则是最有价值的原子模拟基础模型将在所有方面（准确性、延迟和系统规模可扩展性）表现出色。这样做的好处是推动计算化学进入一个新时代，该时代由高通量和中等规模的原子模拟驱动。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Orb-v3, the next generation of the Orb family of universalinteratomic potentials. Models in this family expand theperformance-speed-memory Pareto frontier, offering near SoTA performance acrossa range of evaluations with a &gt;10x reduction in latency and &gt; 8x reduction inmemory. Our experiments systematically traverse this frontier, charting thetrade-off induced by roto-equivariance, conservatism and graph sparsity.Contrary to recent literature, we find that non-equivariant, non-conservativearchitectures can accurately model physical properties, including those whichrequire higher-order derivatives of the potential energy surface.  This model release is guided by the principle that the most valuablefoundation models for atomic simulation will excel on all fronts: accuracy,latency and system size scalability. The reward for doing so is a new era ofcomputational chemistry driven by high-throughput and mesoscale all-atomsimulations.</description>
      <author>example@mail.com (Benjamin Rhodes, Sander Vandenhaute, Vaidotas Šimkus, James Gin, Jonathan Godwin, Tim Duignan, Mark Neumann)</author>
      <guid isPermaLink="false">2504.06231v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>UVG-VPC: Voxelized Point Cloud Dataset for Visual Volumetric Video-based Coding</title>
      <link>http://arxiv.org/abs/2504.05888v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Point cloud compression;Geometry;Visualization;Three-dimensional  displays;Video sequences;Transform coding;Media;Open dataset;point  cloud;Visual Volumetric Video-based Coding (V3C);Video-based Point Cloud  Compression (V-PCC);Extended Reality (XR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的开放数据集UVG-VPC，用于开发、评估和验证MPEG视觉体积视频编码（V3C）技术。&lt;h4&gt;背景&lt;/h4&gt;点云压缩在沉浸式视觉媒体处理和流媒体中变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;发布UVG-VPC数据集的主要目的是促进V3C技术的发展，从而塑造该领域的未来。&lt;h4&gt;方法&lt;/h4&gt;数据集包含12个具有不同运动、RGB纹理、3D几何和点表面遮挡特性的点云测试视频序列。每个序列长度为10秒，包含250帧，每秒25帧。序列以9到12位的几何精度体素化，体素颜色属性以8位RGB值表示。数据集还包括相关的法线，使其更适合评估点云压缩解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;UVG-VPC数据集包括不同特性的点云测试视频序列，适用于评估点云压缩解决方案。&lt;h4&gt;结论&lt;/h4&gt;UVG-VPC数据集的发布将促进V3C技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云压缩已成为沉浸式视觉媒体处理和流媒体的关键因素。本文提出一个新的开放数据集UVG-VPC，用于开发、评估和验证MPEG视觉体积视频编码（V3C）技术。该数据集在其自身的非商业许可下分发。它包含12个具有不同运动、RGB纹理、3D几何和点表面遮挡特性的点云测试视频序列。每个序列长度为10秒，包含250帧，每秒25帧。序列以9到12位的几何精度体素化，体素颜色属性以8位RGB值表示。数据集还包括相关的法线，使其更适合评估点云压缩解决方案。发布UVG-VPC数据集的主要目的是促进V3C技术的发展，从而塑造该领域的未来。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/QoMEX58391.2023.10178589&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud compression has become a crucial factor in immersive visual mediaprocessing and streaming. This paper presents a new open dataset called UVG-VPCfor the development, evaluation, and validation of MPEG Visual VolumetricVideo-based Coding (V3C) technology. The dataset is distributed under its ownnon-commercial license. It consists of 12 point cloud test video sequences ofdiverse characteristics with respect to the motion, RGB texture, 3D geometry,and surface occlusion of the points. Each sequence is 10 seconds long andcomprises 250 frames captured at 25 frames per second. The sequences arevoxelized with a geometry precision of 9 to 12 bits, and the voxel colorattributes are represented as 8-bit RGB values. The dataset also includesassociated normals that make it more suitable for evaluating point cloudcompression solutions. The main objective of releasing the UVG-VPC dataset isto foster the development of V3C technologies and thereby shape the future inthis field.</description>
      <author>example@mail.com (Guillaume Gautier, Alexandre Mercat, Louis Fréneau, Mikko Pitkänen, Jarno Vanne)</author>
      <guid isPermaLink="false">2504.05888v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>Heuristic Methods are Good Teachers to Distill MLPs for Graph Link Prediction</title>
      <link>http://arxiv.org/abs/2504.06193v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为EHDM（Ensemble Heuristic-Distilled MLPs）的链接预测方法，通过结合不同的教师模型和门控机制，实现了高效的链接预测。&lt;h4&gt;背景&lt;/h4&gt;链接预测是图学习中的一个关键任务，广泛应用于文献预测和产品推荐等领域。通过将图神经网络（GNN）教师模型蒸馏为多层感知器（MLP）学生模型，可以降低计算成本并提高性能。&lt;h4&gt;目的&lt;/h4&gt;研究不同教师模型对GNN到MLP蒸馏的影响，并提出一种有效的链接预测方法。&lt;h4&gt;方法&lt;/h4&gt;探索了不同教师模型（包括标准GNN、GNN4LP和启发式方法）在GNN到MLP蒸馏中的影响。提出了一种名为EHDM的方法，通过门控机制消除图依赖，并有效地整合互补信号。&lt;h4&gt;主要发现&lt;/h4&gt;发现更强的教师模型并不总是产生更强的学生模型；MLP从GNN4LP蒸馏出来的可能表现不如从更简单的GNN蒸馏出来的，而较弱的启发式方法可以教会MLP接近GNN的性能，同时显著降低训练成本。&lt;h4&gt;结论&lt;/h4&gt;EHDM方法在十个数据集上展示了平均7.93%的性能提升，并且训练时间比之前的GNN到MLP方法减少了1.95-3.32倍，证明了EHDM是一种高效且有效的链接预测方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：链接预测是图学习中的一个关键任务，其应用包括文献预测和产品推荐。将图神经网络（GNN）教师模型蒸馏为多层感知器（MLP）学生模型已证明是一种有效的方法，通过去除图依赖来降低计算成本并提高性能。然而，现有的蒸馏方法仅使用标准的GNN，忽略了其他教师模型，如用于链接预测的专用模型（GNN4LP）和启发式方法（例如共同邻居）。本文首先探讨了不同教师模型在GNN到MLP蒸馏中的影响。令人惊讶的是，我们发现更强的教师模型并不总是产生更强的学生模型：从GNN4LP蒸馏出来的MLP可能表现不如从更简单的GNN蒸馏出来的，而较弱的启发式方法可以教会MLP接近GNN的性能，同时显著降低训练成本。基于这些见解，我们提出了集成启发式蒸馏MLP（EHDM），它通过门控机制消除图依赖，并有效地整合互补信号。在十个数据集上的实验表明，与之前的GNN到MLP方法相比，EHDM的平均性能提升了7.93%，训练时间减少了1.95-3.32倍，表明EHDM是一种高效且有效的链接预测方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction is a crucial graph-learning task with applications includingcitation prediction and product recommendation. Distilling Graph NeuralNetworks (GNNs) teachers into Multi-Layer Perceptrons (MLPs) students hasemerged as an effective approach to achieve strong performance and reducingcomputational cost by removing graph dependency. However, existing distillationmethods only use standard GNNs and overlook alternative teachers such asspecialized model for link prediction (GNN4LP) and heuristic methods (e.g.,common neighbors). This paper first explores the impact of different teachersin GNN-to-MLP distillation. Surprisingly, we find that stronger teachers do notalways produce stronger students: MLPs distilled from GNN4LP can underperformthose distilled from simpler GNNs, while weaker heuristic methods can teachMLPs to near-GNN performance with drastically reduced training costs. Buildingon these insights, we propose Ensemble Heuristic-Distilled MLPs (EHDM), whicheliminates graph dependencies while effectively integrating complementarysignals via a gating mechanism. Experiments on ten datasets show an average7.93% improvement over previous GNN-to-MLP approaches with 1.95-3.32 times lesstraining time, indicating EHDM is an efficient and effective link predictionmethod.</description>
      <author>example@mail.com (Zongyue Qin, Shichang Zhang, Mingxuan Ju, Tong Zhao, Neil Shah, Yizhou Sun)</author>
      <guid isPermaLink="false">2504.06193v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>High-Resource Translation:Turning Abundance into Accessibility</title>
      <link>http://arxiv.org/abs/2504.05914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用迁移学习技术构建英泰卢语翻译模型的新方法，通过解决低资源语言的相关挑战，有效提升了模型翻译能力。&lt;h4&gt;背景&lt;/h4&gt;针对低资源语言翻译的挑战，本文研究了一种新的翻译模型构建方法。&lt;h4&gt;目的&lt;/h4&gt;旨在创建一个能够处理英语和泰卢语中多样化句子结构和语言细微差异的鲁棒翻译系统。&lt;h4&gt;方法&lt;/h4&gt;使用Bharat平行语料库（BPCC）作为主要数据集，通过迭代反向翻译生成合成平行数据，增强训练数据集，并优化训练参数以及有效使用预训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;研究强调了创新数据处理技术的意义以及迁移学习在克服低资源语言数据稀疏性限制方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究对机器翻译领域做出了贡献，并旨在改善英语和泰卢语使用者之间的实际沟通。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于迁移学习的英泰卢语翻译模型构建方法，通过使用BPCC数据集、迭代反向翻译以及优化训练参数等技术，提高了模型的翻译能力，并有助于改善英语和泰卢语使用者之间的沟通。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel approach to constructing an English-to-Telugutranslation model by leveraging transfer learning techniques and addressing thechallenges associated with low-resource languages. Utilizing the BharatParallel Corpus Collection (BPCC) as the primary dataset, the modelincorporates iterative backtranslation to generate synthetic parallel data,effectively augmenting the training dataset and enhancing the model'stranslation capabilities. The research focuses on a comprehensive strategy forimproving model performance through data augmentation, optimization of trainingparameters, and the effective use of pre-trained models. These methodologiesaim to create a robust translation system that can handle diverse sentencestructures and linguistic nuances in both English and Telugu. This workhighlights the significance of innovative data handling techniques and thepotential of transfer learning in overcoming limitations posed by sparsedatasets in low-resource languages. The study contributes to the field ofmachine translation and seeks to improve communication between English andTelugu speakers in practical contexts.</description>
      <author>example@mail.com (Abhiram Reddy Yanampally)</author>
      <guid isPermaLink="false">2504.05914v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Video Flow as Time Series: Discovering Temporal Consistency and Variability for VideoQA</title>
      <link>http://arxiv.org/abs/2504.05783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Temporal Trio Transformer（T3T）的新型架构，用于视频问答任务，旨在通过建模时间一致性和时间变异性来提高视频问答的准确性和深度。&lt;h4&gt;背景&lt;/h4&gt;视频问答是一个复杂的视频语言任务，需要深入理解视觉内容和时间动态。传统的Transformer架构在整合多模态数据方面有效，但往往通过位置编码简化时间动态，未能捕捉视频序列中的非线性交互。&lt;h4&gt;目的&lt;/h4&gt;提出T3T架构，以改善视频问答的准确性和深度。&lt;h4&gt;方法&lt;/h4&gt;T3T包含三个关键组件：时间平滑（TS）、时间差异（TD）和时间融合（TF）。TS模块使用布朗桥捕捉平滑的连续时间过渡，TD模块识别和编码视频内容中的显著时间变化和突变，TF模块将时间特征与文本线索融合，以促进更深层次的理解和回答准确性。&lt;h4&gt;主要发现&lt;/h4&gt;T3T在多个视频问答基准数据集上的广泛测试中证明了其有效性，突出了对时间建模的细致方法对于提高视频问答准确性和深度的重要性。&lt;h4&gt;结论&lt;/h4&gt;T3T架构通过建模时间动态，为视频问答任务提供了更准确的答案，并强调了在视频问答中采用细致时间建模方法的重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频问答（VideoQA）是一个复杂的视频语言任务，需要深入理解视觉内容和时间动态。传统的Transformer风格架构，虽然有效于整合多模态数据，但通常通过位置编码简化时间动态，未能捕捉视频序列中的非线性交互。在本文中，我们引入了时间三重奏Transformer（T3T），这是一种新型架构，用于建模时间一致性和时间变异性。T3T集成了三个关键组件：时间平滑（TS）、时间差异（TD）和时间融合（TF）。TS模块使用布朗桥捕捉平滑、连续的时间过渡，TD模块识别和编码视频内容中的显著时间变化和突变。随后，TF模块将这些时间特征与文本线索融合，促进更深层次的理解和回答准确性。通过在多个视频问答基准数据集上的广泛测试，T3T的有效性得到了证明。我们的结果强调了在提高视频问答的准确性和深度方面，对时间建模的细致方法的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Question Answering (VideoQA) is a complex video-language task thatdemands a sophisticated understanding of both visual content and temporaldynamics. Traditional Transformer-style architectures, while effective inintegrating multimodal data, often simplify temporal dynamics throughpositional encoding and fail to capture non-linear interactions within videosequences. In this paper, we introduce the Temporal Trio Transformer (T3T), anovel architecture that models time consistency and time variability. The T3Tintegrates three key components: Temporal Smoothing (TS), Temporal Difference(TD), and Temporal Fusion (TF). The TS module employs Brownian Bridge forcapturing smooth, continuous temporal transitions, while the TD moduleidentifies and encodes significant temporal variations and abrupt changeswithin the video content. Subsequently, the TF module synthesizes thesetemporal features with textual cues, facilitating a deeper contextualunderstanding and response accuracy. The efficacy of the T3T is demonstratedthrough extensive testing on multiple VideoQA benchmark datasets. Our resultsunderscore the importance of a nuanced approach to temporal modeling inimproving the accuracy and depth of video-based question answering.</description>
      <author>example@mail.com (Zijie Song, Zhenzhen Hu, Yixiao Ma, Jia Li, Richang Hong)</author>
      <guid isPermaLink="false">2504.05783v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>POD: Predictive Object Detection with Single-Frame FMCW LiDAR Point Cloud</title>
      <link>http://arxiv.org/abs/2504.05649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于FMCW LiDAR的3D物体检测在自动驾驶感知中的独特优势，提出了一种预测物体检测（POD）框架，以实现快速响应潜在危险。&lt;h4&gt;背景&lt;/h4&gt;LiDAR-based 3D object detection是自动驾驶领域的基本任务。&lt;h4&gt;目的&lt;/h4&gt;利用单帧FMCW点云数据，实现物体的短期未来位置和尺寸的预测。&lt;h4&gt;方法&lt;/h4&gt;将标准物体检测任务扩展为预测物体检测（POD），通过射线投射机制生成虚拟未来点，创建虚拟两帧点云，并使用稀疏4D编码器编码特征，最后将4D体素特征分离并重映射为两个鸟瞰图（BEV）特征。&lt;h4&gt;主要发现&lt;/h4&gt;FMCW LiDAR的核心优势在于与每个反射点相关的径向速度，避免使用多帧历史信息，实现更快的响应时间。&lt;h4&gt;结论&lt;/h4&gt;在内部数据集上的实验表明，所提出的POD框架在标准检测和预测检测方面均达到最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper explores the unique advantage of FrequencyModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a singleframe FMCW point cloud with radial velocity measurements, we expect that our object detector can detect the short-term future locations of objects using only the current frame sensor data and demonstrate a fast ability to respond to intermediate danger. To achieve this, we extend the standard object detection task to a novel task named predictive object detection (POD), which aims to predict the short-term future location and dimensions of objects based solely on current observations. Typically, a motion prediction task requires historical sensor information to process the temporal contexts of each object, while our detector's avoidance of multi-frame historical information enables a much faster response time to potential dangers. The core advantage of FMCW LiDAR lies in the radial velocity associated with every reflected point. We propose a novel POD framework, the core idea of which is to generate a virtual future point using a ray casting mechanism, create virtual two-frame point clouds with the current and virtual future frames, and encode these two-frame voxel features with a sparse 4D encoder. Subsequently, the 4D voxel features are separated by temporal indices and remapped into two Bird's Eye View (BEV) features: one decoded for standard current frame object detection and the other for future predictive object detection. Extensive experiments on our in-house dataset demonstrate the state-of-the-art standard and predictive detection performance of the proposed POD framework.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR-based 3D object detection is a fundamental task in the field ofautonomous driving. This paper explores the unique advantage of FrequencyModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a singleframe FMCW point cloud with radial velocity measurements, we expect that ourobject detector can detect the short-term future locations of objects usingonly the current frame sensor data and demonstrate a fast ability to respond tointermediate danger. To achieve this, we extend the standard object detectiontask to a novel task named predictive object detection (POD), which aims topredict the short-term future location and dimensions of objects based solelyon current observations. Typically, a motion prediction task requireshistorical sensor information to process the temporal contexts of each object,while our detector's avoidance of multi-frame historical information enables amuch faster response time to potential dangers. The core advantage of FMCWLiDAR lies in the radial velocity associated with every reflected point. Wepropose a novel POD framework, the core idea of which is to generate a virtualfuture point using a ray casting mechanism, create virtual two-frame pointclouds with the current and virtual future frames, and encode these two-framevoxel features with a sparse 4D encoder. Subsequently, the 4D voxel featuresare separated by temporal indices and remapped into two Bird's Eye View (BEV)features: one decoded for standard current frame object detection and the otherfor future predictive object detection. Extensive experiments on our in-housedataset demonstrate the state-of-the-art standard and predictive detectionperformance of the proposed POD framework.</description>
      <author>example@mail.com (Yining Shi, Kun Jiang, Xin Zhao, Kangan Qian, Chuchu Xie, Tuopu Wen, Mengmeng Yang, Diange Yang)</author>
      <guid isPermaLink="false">2504.05649v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>CamContextI2V: Context-aware Controllable Video Generation</title>
      <link>http://arxiv.org/abs/2504.06022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CamContextI2V的图像到视频（I2V）模型，该模型结合了多种图像条件和3D约束以及相机控制，以丰富全局语义和精细视觉细节，从而实现更连贯和情境感知的视频生成。&lt;h4&gt;背景&lt;/h4&gt;现有的I2V扩散模型在场景理解和生成质量方面表现出色，但主要对静态图像进行动画处理，未扩展到提供的上下文之外。引入额外的约束（如相机轨迹）可以增加多样性，但往往降低视觉质量，限制了其在需要忠实场景表示的任务中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出CamContextI2V模型，旨在通过结合图像条件和3D约束以及相机控制，提高视频生成的视觉质量和场景连贯性。&lt;h4&gt;方法&lt;/h4&gt;CamContextI2V模型集成了多种图像条件、3D约束和相机控制，以增强全局语义和精细视觉细节，并通过RealEstate10K数据集进行了全面研究。&lt;h4&gt;主要发现&lt;/h4&gt;CamContextI2V模型在视觉质量和相机可控性方面有所提升，证明了时间感知对于有效情境表示的必要性。&lt;h4&gt;结论&lt;/h4&gt;CamContextI2V模型能够生成更高质量和情境感知的视频，对需要忠实场景表示的任务具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;最近，图像到视频（I2V）扩散模型在场景理解和生成质量方面表现出色，结合了图像条件以引导生成。然而，这些模型主要对静态图像进行动画处理，没有扩展到它们提供的上下文之外。引入额外的约束，如相机轨迹，可以增强多样性，但往往降低视觉质量，限制了它们在需要忠实场景表示的任务中的应用。我们提出了CamContextI2V，一种将多个图像条件与3D约束以及相机控制相结合的I2V模型，以丰富全局语义和精细视觉细节。这使视频生成更加连贯和情境感知。此外，我们强调了时间感知对于有效情境表示的必要性。我们在RealEstate10K数据集上的全面研究表明，在视觉质量和相机可控性方面有所改进。我们将在https://github.com/LDenninger/CamContextI2V上公开我们的代码和模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, image-to-video (I2V) diffusion models have demonstrated impressivescene understanding and generative quality, incorporating image conditions toguide generation. However, these models primarily animate static images withoutextending beyond their provided context. Introducing additional constraints,such as camera trajectories, can enhance diversity but often degrades visualquality, limiting their applicability for tasks requiring faithful scenerepresentation. We propose CamContextI2V, an I2V model that integrates multipleimage conditions with 3D constraints alongside camera control to enrich bothglobal semantics and fine-grained visual details. This enables more coherentand context-aware video generation. Moreover, we motivate the necessity oftemporal awareness for an effective context representation. Our comprehensivestudy on the RealEstate10K dataset demonstrates improvements in visual qualityand camera controllability. We make our code and models publicly available at:https://github.com/LDenninger/CamContextI2V.</description>
      <author>example@mail.com (Luis Denninger, Sina Mokhtarzadeh Azar, Juergen Gall)</author>
      <guid isPermaLink="false">2504.06022v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>ViTaMIn: Learning Contact-Rich Tasks Through Robot-Free Visuo-Tactile Manipulation Interface</title>
      <link>http://arxiv.org/abs/2504.06156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ViTaMIn的机器人操作界面，该界面将视觉和触觉传感无缝集成到手持式抓取器中，以实现无需远程操作的数据收集。&lt;h4&gt;背景&lt;/h4&gt;触觉信息对于人类和机器人与环境交互至关重要，尤其是在需要理解接触特性的任务中。目前，解决这类灵活操作任务通常依赖于从演示数据集进行模仿学习，而这通常需要通过远程操作系统收集，耗时费力。&lt;h4&gt;目的&lt;/h4&gt;提出ViTaMIn以解决上述挑战，提高数据收集效率和策略鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;ViTaMIn使用了一种具有触觉传感的柔顺鳍状抓取器，允许操作者在操作过程中感知力反馈。此外，还提出了一种多模态表示学习策略，以获得预训练的触觉表示。&lt;h4&gt;主要发现&lt;/h4&gt;在七个涉及接触的灵活操作任务上的实验表明，ViTaMIn显著优于基线方法，证明了其在复杂操作任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;ViTaMIn作为一种无需远程操作即可进行数据收集的机器人操作界面，对于提高数据效率和策略鲁棒性具有显著效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tactile information plays a crucial role for humans and robots to interacteffectively with their environment, particularly for tasks requiring theunderstanding of contact properties. Solving such dexterous manipulation tasksoften relies on imitation learning from demonstration datasets, which aretypically collected via teleoperation systems and often demand substantial timeand effort. To address these challenges, we present ViTaMIn, an embodiment-freemanipulation interface that seamlessly integrates visual and tactile sensinginto a hand-held gripper, enabling data collection without the need forteleoperation. Our design employs a compliant Fin Ray gripper with tactilesensing, allowing operators to perceive force feedback during manipulation formore intuitive operation. Additionally, we propose a multimodal representationlearning strategy to obtain pre-trained tactile representations, improving dataefficiency and policy robustness. Experiments on seven contact-richmanipulation tasks demonstrate that ViTaMIn significantly outperforms baselinemethods, demonstrating its effectiveness for complex manipulation tasks.</description>
      <author>example@mail.com (Fangchen Liu, Chuanyu Li, Yihua Qin, Ankit Shaw, Jing Xu, Pieter Abbeel, Rui Chen)</author>
      <guid isPermaLink="false">2504.06156v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Maternal and Fetal Health Status Assessment by Using Machine Learning on Optical 3D Body Scans</title>
      <link>http://arxiv.org/abs/2504.05627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了利用3D身体扫描数据预测不良妊娠结局和估计临床参数的潜力。&lt;h4&gt;背景&lt;/h4&gt;监测孕期母婴健康对于预防不良结局至关重要。虽然超声波扫描等测试具有高准确性，但它们可能成本高且不便。&lt;h4&gt;目的&lt;/h4&gt;开发一种新型算法，利用3D身体扫描数据预测不良妊娠结局（如早产、妊娠糖尿病、妊娠高血压）并估计胎儿体重。&lt;h4&gt;方法&lt;/h4&gt;研究开发了一种具有两个并行流的新算法，用于提取身体形状特征：一个用于监督学习提取连续腹部周长信息，另一个用于无监督学习提取全局形状描述符，同时还有一个分支用于收集人口统计数据。&lt;h4&gt;主要发现&lt;/h4&gt;3D身体形状有助于预测早产、妊娠糖尿病、妊娠高血压，并在估计胎儿体重方面表现良好。与其它机器学习模型相比，该算法实现了最佳性能，预测准确率超过88%，胎儿体重估计准确率为76.74%，误差范围为10%，比传统的人体测量方法高22.22%。&lt;h4&gt;结论&lt;/h4&gt;3D身体扫描数据在预测不良妊娠结局和估计胎儿体重方面具有潜力，且该算法的性能优于传统方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monitoring maternal and fetal health during pregnancy is crucial forpreventing adverse outcomes. While tests such as ultrasound scans offer highaccuracy, they can be costly and inconvenient. Telehealth and more accessiblebody shape information provide pregnant women with a convenient way to monitortheir health. This study explores the potential of 3D body scan data, capturedduring the 18-24 gestational weeks, to predict adverse pregnancy outcomes andestimate clinical parameters. We developed a novel algorithm with two parallelstreams which are used for extract body shape features: one for supervisedlearning to extract sequential abdominal circumference information, and anotherfor unsupervised learning to extract global shape descriptors, alongside abranch for demographic data.  Our results indicate that 3D body shape can assist in predicting pretermlabor, gestational diabetes mellitus (GDM), gestational hypertension (GH), andin estimating fetal weight. Compared to other machine learning models, ouralgorithm achieved the best performance, with prediction accuracies exceeding88% and fetal weight estimation accuracy of 76.74% within a 10% error margin,outperforming conventional anthropometric methods by 22.22%.</description>
      <author>example@mail.com (Ruting Cheng, Yijiang Zheng, Boyuan Feng, Chuhui Qiu, Zhuoxin Long, Joaquin A. Calderon, Xiaoke Zhang, Jaclyn M. Phillips, James K. Hahn)</author>
      <guid isPermaLink="false">2504.05627v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>On the Importance of Conditioning for Privacy-Preserving Data Augmentation</title>
      <link>http://arxiv.org/abs/2504.05849v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了使用潜在扩散模型进行数据增广，发现其不适合作为隐私保护方法，并指出其匿名化过程容易受到黑盒攻击。&lt;h4&gt;背景&lt;/h4&gt;潜在扩散模型被用作数据增广的方法，以增强训练数据集。有研究提出将此技术用于数据匿名化。&lt;h4&gt;目的&lt;/h4&gt;评估使用条件扩散模型进行数据匿名化的可行性，并分析其安全性。&lt;h4&gt;方法&lt;/h4&gt;使用对比学习方法训练模型，以识别人群中的人。通过条件扩散模型生成匿名化图像，并分析其易受黑盒攻击的情况。&lt;h4&gt;主要发现&lt;/h4&gt;条件扩散模型生成的匿名化图像在视觉上与原始图像差异很大，但仍然可能被识别。匿名化过程容易受到黑盒攻击。&lt;h4&gt;结论&lt;/h4&gt;潜在扩散模型条件化后的匿名化方法不适合作为隐私保护手段，且存在安全风险。&lt;h4&gt;翻译&lt;/h4&gt;摘要：潜在扩散模型可以作为一种强大的增广方法，用于人工扩展数据集以增强训练。对于人类视觉来说，这些增广图像与原始图像非常不同。先前的研究建议使用这种数据增广技术进行数据匿名化。然而，我们表明，条件于深度图或边缘等特征以引导扩散过程的潜在扩散模型不适合作为隐私保护方法。我们使用对比学习方法训练了一个模型，该模型可以正确地从候选人池中识别出人。此外，我们展示了使用条件扩散模型进行匿名化容易受到黑盒攻击。我们将所述方法的成功归因于匿名化过程中的潜在扩散模型的条件化。扩散模型被指示为匿名化图像生成相似的边缘。因此，模型可以学习识别这些模式进行识别。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Latent diffusion models can be used as a powerful augmentation method toartificially extend datasets for enhanced training. To the human eye, theseaugmented images look very different to the originals. Previous work hassuggested to use this data augmentation technique for data anonymization.However, we show that latent diffusion models that are conditioned on featureslike depth maps or edges to guide the diffusion process are not suitable as aprivacy preserving method. We use a contrastive learning approach to train amodel that can correctly identify people out of a pool of candidates. Moreover,we demonstrate that anonymization using conditioned diffusion models issusceptible to black box attacks. We attribute the success of the describedmethods to the conditioning of the latent diffusion model in the anonymizationprocess. The diffusion model is instructed to produce similar edges for theanonymized images. Hence, a model can learn to recognize these patterns foridentification.</description>
      <author>example@mail.com (Julian Lorenz, Katja Ludwig, Valentin Haug, Rainer Lienhart)</author>
      <guid isPermaLink="false">2504.05849v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of Frequency Adaptation</title>
      <link>http://arxiv.org/abs/2504.06220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Earth-Adapter，这是一种针对遥感图像特征中存在的伪影问题而设计的Parameter-Efficient Fine-Tuning (PEFT)方法，旨在提高基础模型在遥感场景下的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的PEFT方法通常针对自然图像设计，在遥感场景中应用时难以处理伪影影响。&lt;h4&gt;目的&lt;/h4&gt;解决现有PEFT方法在遥感场景中处理伪影的能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;Earth-Adapter引入了一种新的频率自适应过程，结合了混合适配器（MoA）和离散傅里叶变换（DFT）。通过DFT分解特征为不同频率成分，精确分离伪影和原始特征。MoA动态分配权重给每个适配器专家，允许跨不同频率域组合特征。&lt;h4&gt;主要发现&lt;/h4&gt;Earth-Adapter在领域自适应（DA）和领域泛化（DG）语义分割基准测试中展示了其有效性，与基线Rein相比，在DA基准上提高了9.0%的mIoU，在DG基准上提高了3.1%的mIoU。&lt;h4&gt;结论&lt;/h4&gt;Earth-Adapter能够更有效地克服伪影干扰，显著提升基础模型在遥感场景下的性能。&lt;h4&gt;翻译&lt;/h4&gt;Parameter-Efficient Fine-Tuning (PEFT)是一种技术，允许我们适应强大的基础模型（FMs）以执行多样化的下游任务，同时保留并发挥其固有能力。然而，我们观察到现有的PEFT方法，这些方法通常是为了自然图像而设计的，在应用于遥感（RS）场景时遇到了困难。这主要是因为它们无法处理伪影影响，在RS图像特征中这是一个特别严重的问题。为了应对这一挑战，我们引入了Earth-Adapter，这是第一个专门为RS伪影征服设计的PEFT方法。Earth-Adapter引入了一种新颖的频率自适应过程，结合了混合适配器（MoA）和离散傅里叶变换（DFT）。通过利用DFT，Earth-Adapter可以将特征分解为不同的频率成分，精确地分离伪影和原始特征。然后，MoA动态地为每个适配器专家分配权重，允许跨不同频率域组合特征。这些简单而有效的方法使Earth-Adapter比以前的PEFT方法更有效地克服了伪影造成的干扰，显著提高了FMs在RS场景中的性能。在领域自适应（DA）和领域泛化（DG）语义分割基准测试上的实验展示了Earth-Adapter的有效性。与基线Rein相比，Earth-Adapter在DA基准上显著提高了9.0%的mIoU，在DG基准上提高了3.1%的mIoU。我们的代码将在https://github.com/VisionXLab/Earth-Adapter上发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-Efficient Fine-Tuning (PEFT) is a technique that allows us to adaptpowerful Foundation Models (FMs) to diverse downstream tasks while preservingand unleashing their inherent capabilities. However, we have observed thatexisting PEFT methods, which are often designed with natural imagery in mind,struggle when applied to Remote Sensing (RS) scenarios. This is primarily dueto their inability to handle artifact influences, a problem particularly severein RS image features. To tackle this challenge, we introduce Earth-Adapter, thefirst PEFT method specifically designed for RS artifacts conquering.Earth-Adapter introduces a novel Mixture of Frequency Adaptation process thatcombines a Mixture of Adapter (MoA) with Discrete Fourier Transformation (DFT).By utilizing DFT, Earth-Adapter can decompose features into different frequencycomponents, precisely separating artifacts from original features. The MoA thendynamically assigns weights to each adapter expert, allowing for thecombination of features across various frequency domains. Thesesimple-yet-effective approaches enable Earth-Adapter to more efficientlyovercome the disturbances caused by artifacts than previous PEFT methods,significantly enhancing the FMs' performance on RS scenarios. Experiments onDomain Adaptation (DA), and Domain Generalization (DG) semantic segmentationbenchmarks showcase the Earth-Adapter's effectiveness. Compared with baselineRein, Earth-Adapter significantly improves 9.0% mIoU in DA and 3.1% mIoU in DGbenchmarks. Our code will be released athttps://github.com/VisionXLab/Earth-Adapter.</description>
      <author>example@mail.com (Xiaoxing Hu, Ziyang Gong, Yupei Wang, Yuru Jia, Gen Luo, Xue Yang)</author>
      <guid isPermaLink="false">2504.06220v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Comparative Analysis of Classical and Quantum-Inspired Solvers: A Preliminary Study on the Weighted Max-Cut Problem</title>
      <link>http://arxiv.org/abs/2504.05989v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures, 4 tables, paper Submitted to GECCO '25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究评估了八种算法在加权最大割图上的性能，包括遗传算法、图神经网络和密度矩阵重整化群，重点分析了解决方案的质量和计算效率。&lt;h4&gt;背景&lt;/h4&gt;组合优化在众多学科中至关重要，传统元启发式算法在探索复杂解空间方面表现出色，但往往在可扩展性上存在困难。深度学习成为快速生成高质量解决方案的可行替代方案，尤其是在元启发式算法表现不佳时。&lt;h4&gt;目的&lt;/h4&gt;评估不同算法在加权最大割图上的性能，并比较它们的解决方案质量和计算效率。&lt;h4&gt;方法&lt;/h4&gt;在10到250个节点的加权最大割图上评估了遗传算法、图神经网络和密度矩阵重整化群算法。分析集中在解决方案的质量和计算效率上。&lt;h4&gt;主要发现&lt;/h4&gt;遗传算法在小图上实现接近最优的结果，但随着问题规模的增加，其计算时间显著增长。图神经网络为中等规模实例提供了平衡的解决方案，具有低内存需求和快速推理，但在大图上表现出的变异性更大。同时，张量网络方法在大型图上持续产生高近似比和高效执行，尽管内存消耗有所增加。&lt;h4&gt;结论&lt;/h4&gt;不同的算法在处理加权最大割图问题时各有优缺点，应根据具体问题选择合适的算法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Combinatorial optimization is essential across numerous disciplines.Traditional metaheuristics excel at exploring complex solution spacesefficiently, yet they often struggle with scalability. Deep learning has becomea viable alternative for quickly generating high-quality solutions,particularly when metaheuristics underperform. In recent years,quantum-inspired approaches such as tensor networks have shown promise inaddressing these challenges. Despite these advancements, a thorough comparisonof the different paradigms is missing. This study evaluates eight algorithms onWeighted Max-Cut graphs ranging from 10 to 250 nodes. Specifically, we comparea Genetic Algorithm representing metaheuristics, a Graph Neural Network fordeep learning, and the Density Matrix Renormalization Group as a tensor networkapproach. Our analysis focuses on solution quality and computational efficiency(i.e., time and memory usage). Numerical results show that the GeneticAlgorithm achieves near-optimal results for small graphs, although itscomputation time grows significantly with problem size. The Graph NeuralNetwork offers a balanced solution for medium-sized instances with low memorydemands and rapid inference, yet it exhibits more significant variability onlarger graphs. Meanwhile, the Tensor Network approach consistently yields highapproximation ratios and efficient execution on larger graphs, albeit withincreased memory consumption.</description>
      <author>example@mail.com (Aitor Morais, Eneko Osaba, Iker Pastor, Izaskun Oregui)</author>
      <guid isPermaLink="false">2504.05989v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>REEF: Relevance-Aware and Efficient LLM Adapter for Video Understanding</title>
      <link>http://arxiv.org/abs/2504.05491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPRW'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效的大型语言模型适配器，用于处理未剪辑视频的视频级理解，该适配器优先考虑时空标记的上下文相关性。&lt;h4&gt;背景&lt;/h4&gt;将视觉模型集成到大型语言模型中，特别是视频理解领域，引起了极大的兴趣。现有方法通常使用基于相似性的贪婪方法压缩视觉记忆库，这可能忽略了单个标记的上下文重要性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的方法，旨在提高视频级理解中时空标记的上下文相关性。&lt;h4&gt;方法&lt;/h4&gt;该方法利用评分网络来选择性地压缩视觉记忆库，并根据相关性过滤空间标记，使用可微分的Top-K算子进行端到端训练。&lt;h4&gt;主要发现&lt;/h4&gt;在三个关键的视频级理解任务（未剪辑视频分类、视频问答和视频字幕）上，该方法在四个大规模数据集上实现了具有竞争力的或更好的结果，同时将计算开销减少了多达34%。&lt;h4&gt;结论&lt;/h4&gt;该方法将很快在GitHub上提供代码，表明其在视频理解领域具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating vision models into large language models (LLMs) has sparkedsignificant interest in creating vision-language foundation models, especiallyfor video understanding. Recent methods often utilize memory banks to handleuntrimmed videos for video-level understanding. However, they typicallycompress visual memory using similarity-based greedy approaches, which canoverlook the contextual importance of individual tokens. To address this, weintroduce an efficient LLM adapter designed for video-level understanding ofuntrimmed videos that prioritizes the contextual relevance of spatio-temporaltokens. Our framework leverages scorer networks to selectively compress thevisual memory bank and filter spatial tokens based on relevance, using adifferentiable Top-K operator for end-to-end training. Across three keyvideo-level understanding tasks$\unicode{x2013}$ untrimmed videoclassification, video question answering, and videocaptioning$\unicode{x2013}$our method achieves competitive or superior resultson four large-scale datasets while reducing computational overhead by up to34%. The code will be available soon on GitHub.</description>
      <author>example@mail.com (Sakib Reza, Xiyun Song, Heather Yu, Zongfang Lin, Mohsen Moghaddam, Octavia Camps)</author>
      <guid isPermaLink="false">2504.05491v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Cross-functional transferability in universal machine learning interatomic potentials</title>
      <link>http://arxiv.org/abs/2504.05565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文分析了在CHGNet框架下，从低保真数据集到高保真数据集迁移学习问题的挑战，并强调了元素能量参考和适当迁移学习在创建下一代高保真uMLIPs中的重要性。&lt;h4&gt;背景&lt;/h4&gt;uMLIPs的快速发展证明了通用势能表面可推广学习的可能性。&lt;h4&gt;目的&lt;/h4&gt;分析uMLIPs迁移学习问题的挑战，并探讨如何提高其准确性。&lt;h4&gt;方法&lt;/h4&gt;在0.24百万结构的MP-r$^2$SCAN数据集上，对不同的迁移学习方法进行基准测试，比较了有和没有在低保真数据集上预训练的扩展定律。&lt;h4&gt;主要发现&lt;/h4&gt;显著的能量尺度偏移和GGA与r$^2$SCAN之间的相关性差，给uMLIPs的跨功能数据迁移带来了挑战；通过迁移学习，即使目标数据集为亚百万结构，也能实现显著的数据效率。&lt;h4&gt;结论&lt;/h4&gt;适当的迁移学习和多保真学习对于在高保真数据上创建下一代uMLIPs至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of universal machine learning interatomic potentials(uMLIPs) has demonstrated the possibility for generalizable learning of theuniversal potential energy surface. In principle, the accuracy of uMLIPs can befurther improved by bridging the model from lower-fidelity datasets tohigh-fidelity ones. In this work, we analyze the challenge of this transferlearning problem within the CHGNet framework. We show that significant energyscale shifts and poor correlations between GGA and r$^2$SCAN pose challenges tocross-functional data transferability in uMLIPs. By benchmarking differenttransfer learning approaches on the MP-r$^2$SCAN dataset of 0.24 millionstructures, we demonstrate the importance of elemental energy referencing inthe transfer learning of uMLIPs. By comparing the scaling law with and withoutthe pre-training on a low-fidelity dataset, we show that significant dataefficiency can still be achieved through transfer learning, even with a targetdataset of sub-million structures. We highlight the importance of propertransfer learning and multi-fidelity learning in creating next-generationuMLIPs on high-fidelity data.</description>
      <author>example@mail.com (Xu Huang, Bowen Deng, Peichen Zhong, Aaron D. Kaplan, Kristin A. Persson, Gerbrand Ceder)</author>
      <guid isPermaLink="false">2504.05565v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>AEGIS: Human Attention-based Explainable Guidance for Intelligent Vehicle Systems</title>
      <link>http://arxiv.org/abs/2504.05950v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AEGIS的新框架，用于提高自主智能车辆（AIVs）的决策能力。&lt;h4&gt;背景&lt;/h4&gt;尽管近年来在自主智能车辆决策能力方面取得了进展，但训练机器捕捉对全面场景理解至关重要的区域，如人类感知和推理，仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过引入AEGIS框架，利用人类注意力来引导强化学习（RL）模型识别决策的关键区域。&lt;h4&gt;方法&lt;/h4&gt;AEGIS使用从眼动追踪转换而来的人类注意力来指导RL模型识别决策的关键区域。通过收集来自20名参与者的120万帧图像，AEGIS在六个场景下预训练了一个模型，以预测人类注意力模式。&lt;h4&gt;主要发现&lt;/h4&gt;AEGIS能够有效地利用人类注意力来引导RL模型识别决策关键区域。&lt;h4&gt;结论&lt;/h4&gt;AEGIS框架为提高自主智能车辆的决策能力提供了一种新的方法。&lt;h4&gt;翻译&lt;/h4&gt;Improving decision-making capabilities in Autonomous Intelligent Vehicles (AIVs) has been a heated topic in recent years. Despite advancements, training machines to capture regions of interest for comprehensive scene understanding, like human perception and reasoning, remains a significant challenge. This study introduces a novel framework, Human Attention-based Explainable Guidance for Intelligent Vehicle Systems (AEGIS). AEGIS utilizes human attention, converted from eye-tracking, to guide reinforcement learning (RL) models to identify critical regions of interest for decision-making. AEGIS uses a pre-trained human attention model to guide RL models to identify critical regions of interest for decision-making. By collecting 1.2 million frames from 20 participants across six scenarios, AEGIS pre-trains a model to predict human attention patterns.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Improving decision-making capabilities in Autonomous Intelligent Vehicles(AIVs) has been a heated topic in recent years. Despite advancements, trainingmachines to capture regions of interest for comprehensive scene understanding,like human perception and reasoning, remains a significant challenge. Thisstudy introduces a novel framework, Human Attention-based Explainable Guidancefor Intelligent Vehicle Systems (AEGIS). AEGIS utilizes human attention,converted from eye-tracking, to guide reinforcement learning (RL) models toidentify critical regions of interest for decision-making. AEGIS uses apre-trained human attention model to guide RL models to identify criticalregions of interest for decision-making. By collecting 1.2 million frames from20 participants across six scenarios, AEGIS pre-trains a model to predict humanattention patterns.</description>
      <author>example@mail.com (Zhuoli Zhuang, Cheng-You Lu, Yu-Cheng Fred Chang, Yu-Kai Wang, Thomas Do, Chin-Teng Lin)</author>
      <guid isPermaLink="false">2504.05950v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>A Large-Scale Analysis on Contextual Self-Supervised Video Representation Learning</title>
      <link>http://arxiv.org/abs/2504.06153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR'25 Workshop: 6th Data-Efficient Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了无监督学习在视频领域的应用，提出了一个统一的基准，以促进不同方法之间的公平比较，并系统地分析了视频自监督学习的五个关键方面。&lt;h4&gt;背景&lt;/h4&gt;自监督学习作为无标签模型预训练的有力范式，在视频领域尤为重要，因为手动标注既昂贵又耗时。&lt;h4&gt;目的&lt;/h4&gt;建立统一的基准，以促进不同自监督学习方法的公平比较，并深入探究视频自监督学习的关键因素。&lt;h4&gt;方法&lt;/h4&gt;评估了六种自监督学习方法在六种网络架构上的表现，并在五个基准数据集上进行了广泛实验，同时评估了两个下游任务上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;揭示了预训练策略、数据集特征、预训练任务和模型架构之间的相互作用，并将这些发现扩展到视频基础模型（ViFMs）。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的方法，显著降低了训练数据需求，同时超越了需要10%更多预训练数据的现有方法，为未来研究提供了指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has emerged as a powerful paradigm for label-freemodel pretraining, particularly in the video domain, where manual annotation iscostly and time-intensive. However, existing self-supervised approaches employdiverse experimental setups, making direct comparisons challenging due to theabsence of a standardized benchmark. In this work, we establish a unifiedbenchmark that enables fair comparisons across different methods. Additionally,we systematically investigate five critical aspects of self-supervised learningin videos: (1) dataset size, (2) model complexity, (3) data distribution, (4)data noise, and (5) feature representations. To facilitate this study, weevaluate six self-supervised learning methods across six network architectures,conducting extensive experiments on five benchmark datasets and assessingperformance on two distinct downstream tasks. Our analysis reveals key insightsinto the interplay between pretraining strategies, dataset characteristics,pretext tasks, and model architectures. Furthermore, we extend these findingsto Video Foundation Models (ViFMs), demonstrating their relevance inlarge-scale video representation learning. Finally, leveraging these insights,we propose a novel approach that significantly reduces training datarequirements while surpassing state-of-the-art methods that rely on 10% morepretraining data. We believe this work will guide future research toward adeeper understanding of self-supervised video representation learning and itsbroader implications.</description>
      <author>example@mail.com (Akash Kumar, Ashlesha Kumar, Vibhav Vineet, Yogesh S Rawat)</author>
      <guid isPermaLink="false">2504.06153v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>DyTTP: Trajectory Prediction with Normalization-Free Transformers</title>
      <link>http://arxiv.org/abs/2504.05356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer架构的轨迹预测方法，通过集成DynamicTanh（DyT）和采用快照集成策略，提高了预测精度、推理速度和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;精确的轨迹预测对于自动驾驶系统的安全运行至关重要，而理解周围代理的动态行为是关键。Transformer架构在捕捉复杂时空依赖关系方面显示出巨大潜力，但其对归一化层的依赖可能导致计算开销和训练不稳定。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决Transformer架构在轨迹预测任务中的计算开销和训练不稳定问题。&lt;h4&gt;方法&lt;/h4&gt;1. 将DynamicTanh（DyT）集成到骨干网络中，以取代传统的层归一化，简化网络架构并提高推理稳定性。2. 采用快照集成策略，通过周期性学习率调度，在单个训练运行中捕获多个模型快照，并在推理时通过简单平均聚合这些快照，以从多样化的假设中受益而不会增加额外的计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;在Argoverse数据集上的大量实验表明，该方法显著提高了预测精度、推理速度和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文强调了无归一化Transformer设计结合轻量级集成技术在推进自动驾驶车辆轨迹预测方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;精确轨迹预测是自动驾驶系统安全运行的基础，理解周围代理的动态行为至关重要。基于Transformer的架构在捕捉复杂时空依赖关系方面展现出巨大潜力，但其对归一化层的依赖可能导致计算开销和训练不稳定。在本文中，我们提出了一种两阶段方法来应对这些挑战。首先，我们将最新方法DynamicTanh（DyT）集成到骨干网络中，取代传统的层归一化，简化了网络架构并提高了推理的稳定性。我们是最先使用DyT来解决轨迹预测任务的工作。作为补充，我们采用快照集成策略来进一步提高轨迹预测性能。通过周期性学习率调度，在单个训练运行中捕获多个模型快照。这些快照在推理时通过简单平均进行聚合，使得模型能够从多样化的假设中受益，而不会增加额外的计算成本。在Argoverse数据集上的大量实验表明，我们的结合方法显著提高了预测精度、推理速度和在不同驾驶场景中的鲁棒性。这项工作强调了无归一化Transformer设计结合轻量级集成技术在推进自动驾驶车辆轨迹预测方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate trajectory prediction is a cornerstone for the safe operation ofautonomous driving systems, where understanding the dynamic behavior ofsurrounding agents is crucial. Transformer-based architectures havedemonstrated significant promise in capturing complex spatio-temporalitydependencies. However, their reliance on normalization layers can lead tocomputation overhead and training instabilities. In this work, we present atwo-fold approach to address these challenges. First, we integrate DynamicTanh(DyT), which is the latest method to promote transformers, into the backbone,replacing traditional layer normalization. This modification simplifies thenetwork architecture and improves the stability of the inference. We are thefirst work to deploy the DyT to the trajectory prediction task. Complementingthis, we employ a snapshot ensemble strategy to further boost trajectoryprediction performance. Using cyclical learning rate scheduling, multiple modelsnapshots are captured during a single training run. These snapshots are thenaggregated via simple averaging at inference time, allowing the model tobenefit from diverse hypotheses without incurring substantial additionalcomputational cost. Extensive experiments on Argoverse datasets demonstratethat our combined approach significantly improves prediction accuracy,inference speed and robustness in diverse driving scenarios. This workunderscores the potential of normalization-free transformer designs augmentedwith lightweight ensemble techniques in advancing trajectory forecasting forautonomous vehicles.</description>
      <author>example@mail.com (Yunxiang Liu, Hongkuo Niu)</author>
      <guid isPermaLink="false">2504.05356v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Retrieval Augmented Generation with Collaborative Filtering for Personalized Text Generation</title>
      <link>http://arxiv.org/abs/2504.05731v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为CFRAG的方法，用于个性化文本生成，通过将协同过滤应用于RAG（检索增强生成）来利用用户间的协作信息。&lt;h4&gt;背景&lt;/h4&gt;个性化大型语言模型生成内容受到关注，现有的个性化RAG方法未考虑相似用户的历史可以帮助个性化当前用户的生成。&lt;h4&gt;目的&lt;/h4&gt;提出CFRAG方法，以利用用户间的协作信息，增强个性化文本生成。&lt;h4&gt;方法&lt;/h4&gt;CFRAG方法包括：1) 使用对比学习训练用户嵌入来检索相似用户并引入协作信息；2) 设计个性化检索和重新排序器来从用户历史中检索前$k$个文档；3) 考虑用户偏好进行检索和重新排序；4) 利用LLM的反馈来微调检索器和重新排序器。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明CFRAG方法有效，进一步分析确认了引入协作信息的重要性。&lt;h4&gt;结论&lt;/h4&gt;CFRAG方法通过利用用户间的协作信息，提高了个性化文本生成的效果。&lt;h4&gt;翻译&lt;/h4&gt;最近，对大型语言模型（LLM）进行个性化以生成符合个人用户偏好的内容受到了广泛关注。个性化检索增强生成（RAG），即从用户的历史中检索相关文档以反映他们的偏好并增强LLM的生成，是用于个性化的一种常用方法。然而，现有的个性化RAG方法没有考虑相似用户的历史也可以帮助对当前用户的个性化生成，这意味着用户间的协作信息也可以用于个性化生成。受推荐系统中协同过滤应用的启发，我们提出了一种名为CFRAG的方法，该方法将协同过滤应用于RAG以实现个性化文本生成。然而，这提出了两个挑战：（1）如何在不提供明确的用户相似性标签的情况下引入协作信息？（2）如何检索支持个性化LLM生成的文档？对于挑战1，我们使用对比学习来训练用户嵌入以检索相似用户并引入协作信息。对于挑战2，我们设计了一个个性化的检索器和重新排序器来从这些用户的 历史 中检索前$k$个文档。我们在检索和重新排序过程中考虑了用户的偏好。然后我们利用LLM的反馈来微调个性化的检索器和重新排序器，使它们能够检索满足LLM个性化生成需求的文档。在语言模型个性化（LaMP）基准测试上的实验结果验证了CFRAG的有效性。进一步的分析确认了引入协作信息的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, the personalization of Large Language Models (LLMs) to generatecontent that aligns with individual user preferences has garnered widespreadattention. Personalized Retrieval-Augmented Generation (RAG), which retrievesrelevant documents from the user's history to reflect their preferences andenhance LLM generation, is one commonly used approach for personalization.However, existing personalized RAG methods do not consider that the historiesof similar users can also assist in personalized generation for the currentuser, meaning that collaborative information between users can also benefitpersonalized generation. Inspired by the application of collaborative filteringin recommender systems, we propose a method called CFRAG, which adaptsCollaborative Filtering to RAG for personalized text generation. However, thispresents two challenges: (1)~how to incorporate collaborative informationwithout explicit user similarity labels? (2)~how to retrieve documents thatsupport personalized LLM generation? For Challenge 1, we use contrastivelearning to train user embeddings to retrieve similar users and introducecollaborative information. For Challenge 2, we design a personalized retrieverand reranker to retrieve the top-$k$ documents from these users' histories. Wetake into account the user's preference during retrieval and reranking. Then weleverage feedback from the LLM to fine-tune the personalized retriever andreranker, enabling them to retrieve documents that meet the personalizedgeneration needs of the LLM. Experimental results on the Language ModelPersonalization (LaMP) benchmark validate the effectiveness of CFRAG. Furtheranalysis confirms the importance of incorporating collaborative information.</description>
      <author>example@mail.com (Teng Shi, Jun Xu, Xiao Zhang, Xiaoxue Zang, Kai Zheng, Yang Song, Han Li)</author>
      <guid isPermaLink="false">2504.05731v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM</title>
      <link>http://arxiv.org/abs/2504.05786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了将大型语言模型（LLMs）与3D空间理解相结合的方法，分析了其分类、代表性方法、数据表示、架构修改和训练策略，并讨论了当前限制和未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;3D空间理解在机器人、自动驾驶、虚拟现实和医学成像等现实世界应用中至关重要。大型语言模型在多个领域取得了显著成功，并显示出在3D理解任务中超越传统计算机视觉方法的潜力。&lt;h4&gt;目的&lt;/h4&gt;对将LLMs与3D空间理解相结合的方法进行全面综述，并提出一个分类法。&lt;h4&gt;方法&lt;/h4&gt;提出一个分类法，将现有方法分为图像基于方法、点云基于方法和混合模态方法三类。系统性地回顾了这些类别中的代表性方法，包括数据表示、架构修改和训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs在3D理解任务中显示出超越传统方法的潜力，但存在数据集稀缺和计算挑战等限制。&lt;h4&gt;结论&lt;/h4&gt;本文强调了在空间感知、多模态融合和现实世界应用中的有希望的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;3D空间理解在现实世界的应用，如机器人、自动驾驶、虚拟现实和医学成像等方面至关重要。近期，大型语言模型（LLMs）在多个领域取得了显著的成功，并被用于增强3D理解任务，显示出可能超越传统计算机视觉方法的潜力。在本综述中，我们全面回顾了将LLMs与3D空间理解相结合的方法。我们提出了一种分类法，将现有方法分为三类：基于图像的方法，从二维视觉数据中推导出3D理解；基于点云的方法，直接与3D表示工作；以及混合模态方法，结合多个数据流。我们系统地回顾了这些类别中的代表性方法，包括数据表示、架构修改和连接文本和3D模态的训练策略。最后，我们讨论了当前的局限性，包括数据集稀缺和计算挑战，同时强调了在空间感知、多模态融合和现实世界应用中的有希望的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D spatial understanding is essential in real-world applications such asrobotics, autonomous vehicles, virtual reality, and medical imaging. Recently,Large Language Models (LLMs), having demonstrated remarkable success acrossvarious domains, have been leveraged to enhance 3D understanding tasks, showingpotential to surpass traditional computer vision methods. In this survey, wepresent a comprehensive review of methods integrating LLMs with 3D spatialunderstanding. We propose a taxonomy that categorizes existing methods intothree branches: image-based methods deriving 3D understanding from 2D visualdata, point cloud-based methods working directly with 3D representations, andhybrid modality-based methods combining multiple data streams. Wesystematically review representative methods along these categories, coveringdata representations, architectural modifications, and training strategies thatbridge textual and 3D modalities. Finally, we discuss current limitations,including dataset scarcity and computational challenges, while highlightingpromising research directions in spatial perception, multi-modal fusion, andreal-world applications.</description>
      <author>example@mail.com (Jirong Zha, Yuxuan Fan, Xiao Yang, Chen Gao, Xinlei Chen)</author>
      <guid isPermaLink="false">2504.05786v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>REVEAL: Relation-based Video Representation Learning for Video-Question-Answering</title>
      <link>http://arxiv.org/abs/2504.05463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为REVEAL的框架，用于视频问答任务，通过编码视觉关系信息来捕捉复杂的视觉关系变化。&lt;h4&gt;背景&lt;/h4&gt;视频问答（VideoQA）是一个挑战，即使是高级视频语言模型（VLM）也难以处理，因为需要将视觉内容表示成适合模型大小的输入。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了REVEAL框架，旨在通过编码结构化的分解表示来捕获视觉关系信息。&lt;h4&gt;方法&lt;/h4&gt;受时空场景图启发，将视频序列编码为一系列时间上的关系三元组（主语-谓语-宾语），并通过语言嵌入提取视频字幕中的显式关系。引入了多对多噪声对比估计（MM-NCE）和Q-Former架构来对齐视频导出的查询与基于文本的关系描述。在推理过程中，Q-Former生成一个高效的标记表示，可以作为VLM的输入。&lt;h4&gt;主要发现&lt;/h4&gt;在五个具有挑战性的基准测试（NeXT-QA、Intent-QA、STAR、VLEP和TVQA）上评估了提出的框架，结果显示基于查询的视频表示能够优于基于全局对齐的CLS或补丁标记表示，并在需要时间推理和关系理解的任务上与最先进模型具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;提出的框架在视频问答任务中表现出色，并且代码和模型将公开发布。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频问答（VideoQA）包括捕捉随时间变化的复杂视觉关系，即使对于高级视频语言模型（VLM）来说也是一个挑战，这主要是因为需要将这些模型的大小合理地表示为视觉内容。为了解决这个问题，我们提出了基于关系的视频表示学习（REVEAL）框架，该框架旨在通过将它们编码为结构化的分解表示来捕获视觉关系信息。具体来说，受时空场景图的启发，我们提出通过语言嵌入将视频序列编码为一系列时间上的关系三元组（主语-谓语-宾语）。为此，我们从视频字幕中提取显式关系，并引入了许多对多噪声对比估计（MM-NCE）以及Q-Former架构，以对齐由视频导出的查询与对应基于文本的关系描述。在推理过程中，生成的Q-Former产生了一个高效的标记表示，可以作为视频问答中VLM的输入。我们在五个具有挑战性的基准测试（NeXT-QA、Intent-QA、STAR、VLEP和TVQA）上评估了所提出的框架。结果显示，基于查询的视频表示能够优于基于全局对齐的CLS或补丁标记表示，并在需要时间推理和关系理解的任务上与最先进模型具有竞争力。代码和模型将公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video-Question-Answering (VideoQA) comprises the capturing of complex visualrelation changes over time, remaining a challenge even for advanced VideoLanguage Models (VLM), i.a., because of the need to represent the visualcontent to a reasonably sized input for those models. To address this problem,we propose  RElation-based Video rEpresentAtion Learning (REVEAL), a framework designedto capture visual relation information by encoding them into structured,decomposed representations. Specifically, inspired by spatiotemporal scenegraphs, we propose to encode video sequences as sets of relation triplets inthe form of (\textit{subject-predicate-object}) over time via their languageembeddings. To this end, we extract explicit relations from video captions andintroduce a Many-to-Many Noise Contrastive Estimation (MM-NCE) together with aQ-Former architecture to align an unordered set of video-derived queries withcorresponding text-based relation descriptions. At inference, the resultingQ-former produces an efficient token representation that can serve as input toa VLM for VideoQA.  We evaluate the proposed framework on five challenging benchmarks: NeXT-QA,Intent-QA, STAR, VLEP, and TVQA. It shows that the resulting query-based videorepresentation is able to outperform global alignment-based CLS or patch tokenrepresentations and achieves competitive results against state-of-the-artmodels, particularly on tasks requiring temporal reasoning and relationcomprehension. The code and models will be publicly released.</description>
      <author>example@mail.com (Sofian Chaybouti, Walid Bousselham, Moritz Wolter, Hilde Kuehne)</author>
      <guid isPermaLink="false">2504.05463v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>SEVERE++: Evaluating Benchmark Sensitivity in Generalization of Video Representation Learning</title>
      <link>http://arxiv.org/abs/2504.05706v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对现代视频自监督学习模型进行了全面评估，重点关注其在现实世界场景中的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在视频表示学习方面取得了显著进展，但视频自监督学习方法通常在狭窄的协议下进行评估，限制了对其泛化能力的理解。&lt;h4&gt;目的&lt;/h4&gt;评估现代视频自监督模型在四个关键下游因素（领域迁移、样本效率、动作粒度和任务多样性）上的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;本文分析了12种基于Transformer的方法（7种视频-only，5种视频-文本）和10种基于CNN的方法，在8个数据集和7个下游任务上进行了超过1100次实验。&lt;h4&gt;主要发现&lt;/h4&gt;尽管架构有所进步，但基于Transformer的模型对下游条件仍然敏感，没有一种方法能在所有因素上保持一致性的泛化，视频-only Transformer在领域迁移方面表现更好，CNN在细粒度任务上表现更佳，而视频-文本模型尽管进行了大规模预训练，但通常表现不佳。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果为当前视频自监督学习方法的优缺点提供了详细视角，并为评估视频表示学习中的泛化能力提供了一个统一的基准。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Continued advances in self-supervised learning have led to significant progress in video representation learning, offering a scalable alternative to supervised approaches by removing the need for manual annotations. Despite strong performance on standard action recognition benchmarks, video self-supervised learning methods are largely evaluated under narrow protocols, typically pretraining on Kinetics-400 and fine-tuning on similar datasets, limiting our understanding of their generalization in real world scenarios. In this work, we present a comprehensive evaluation of modern video self-supervised models, focusing on generalization across four key downstream factors: domain shift, sample efficiency, action granularity, and task diversity. Building on our prior work analyzing benchmark sensitivity in CNN-based contrastive learning, we extend the study to cover state-of-the-art transformer-based video-only and video-text models. Specifically, we benchmark 12 transformer-based methods (7 video-only, 5 video-text) and compare them to 10 CNN-based methods, totaling over 1100 experiments across 8 datasets and 7 downstream tasks. Our analysis shows that, despite architectural advances, transformer-based models remain sensitive to downstream conditions. No method generalizes consistently across all factors, video-only transformers perform better under domain shifts, CNNs outperform for fine-grained tasks, and video-text models often underperform despite large scale pretraining. We also find that recent transformer models do not consistently outperform earlier approaches. Our findings provide a detailed view of the strengths and limitations of current video SSL methods and offer a unified benchmark for evaluating generalization in video representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continued advances in self-supervised learning have led to significantprogress in video representation learning, offering a scalable alternative tosupervised approaches by removing the need for manual annotations. Despitestrong performance on standard action recognition benchmarks, videoself-supervised learning methods are largely evaluated under narrow protocols,typically pretraining on Kinetics-400 and fine-tuning on similar datasets,limiting our understanding of their generalization in real world scenarios. Inthis work, we present a comprehensive evaluation of modern videoself-supervised models, focusing on generalization across four key downstreamfactors: domain shift, sample efficiency, action granularity, and taskdiversity. Building on our prior work analyzing benchmark sensitivity inCNN-based contrastive learning, we extend the study to cover state-of-the-arttransformer-based video-only and video-text models. Specifically, we benchmark12 transformer-based methods (7 video-only, 5 video-text) and compare them to10 CNN-based methods, totaling over 1100 experiments across 8 datasets and 7downstream tasks. Our analysis shows that, despite architectural advances,transformer-based models remain sensitive to downstream conditions. No methodgeneralizes consistently across all factors, video-only transformers performbetter under domain shifts, CNNs outperform for fine-grained tasks, andvideo-text models often underperform despite large scale pretraining. We alsofind that recent transformer models do not consistently outperform earlierapproaches. Our findings provide a detailed view of the strengths andlimitations of current video SSL methods and offer a unified benchmark forevaluating generalization in video representation learning.</description>
      <author>example@mail.com (Fida Mohammad Thoker, Letian Jiang, Chen Zhao, Piyush Bagad, Hazel Doughty, Bernard Ghanem, Cees G. M. Snoek)</author>
      <guid isPermaLink="false">2504.05706v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Accelerated Reeds-Shepp and Under-Specified Reeds-Shepp Algorithms for Mobile Robot Path Planning</title>
      <link>http://arxiv.org/abs/2504.05921v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 27 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种简单直观的方法来加速最优Reeds-Shepp路径计算。&lt;h4&gt;背景&lt;/h4&gt;经典方法在Open Motion Planning Library中缺乏现代开源实现。&lt;h4&gt;目的&lt;/h4&gt;通过几何推理分析最优路径的行为，实现状态空间的新划分，并进一步减少可行的路径的最小集合。&lt;h4&gt;方法&lt;/h4&gt;重访和重新实现文献中的经典方法，作为评估新方法的基准。同时，解决了最终方向未指定的Reeds-Shepp规划问题。进行了全面实验以验证解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;与Open Motion Planning Library中原始Reeds-Shepp解决方案的现代C++实现相比，该方法实现了15倍的速度提升，而经典方法实现了5.79倍的速度提升。两种方法与原始解决方案相比，路径长度存在机器精度差异。&lt;h4&gt;结论&lt;/h4&gt;发布了对加速和未指定Reeds-Shepp问题的C++开源实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TRO.2025.3554406&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we present a simple and intuitive method for acceleratingoptimal Reeds-Shepp path computation. Our approach uses geometrical reasoningto analyze the behavior of optimal paths, resulting in a new partitioning ofthe state space and a further reduction in the minimal set of viable paths. Werevisit and reimplement classic methodologies from the literature, which lackcontemporary open-source implementations, to serve as benchmarks for evaluatingour method. Additionally, we address the under-specified Reeds-Shepp planningproblem where the final orientation is unspecified. We perform exhaustiveexperiments to validate our solutions. Compared to the modern C++implementation of the original Reeds-Shepp solution in the Open Motion PlanningLibrary, our method demonstrates a 15x speedup, while classic methods achieve a5.79x speedup. Both approaches exhibit machine-precision differences in pathlengths compared to the original solution. We release our proposed C++implementations for both the accelerated and under-specified Reeds-Sheppproblems as open-source code.</description>
      <author>example@mail.com (Ibrahim Ibrahim, Wilm Decré, Jan Swevers)</author>
      <guid isPermaLink="false">2504.05921v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>A Multimedia Analytics Model for the Foundation Model Era</title>
      <link>http://arxiv.org/abs/2504.06138v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对基础模型时代的综合多媒体分析模型，旨在解决现有概念模型无法充分捕捉强大AI范式复杂性带来的问题。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型和代理人工智能的快速发展，多媒体分析正经历变革，但现有的视觉和多媒体分析概念模型不足以应对这种复杂性。&lt;h4&gt;目的&lt;/h4&gt;构建一个适用于基础模型时代的多媒体分析模型，以解决现有模型在处理复杂、高风险数据（如情报分析、调查性新闻等）中的实际问题。&lt;h4&gt;方法&lt;/h4&gt;基于视觉分析、多媒体分析、知识生成、分析任务定义、混合倡议指导和人机强化学习等框架，模型强调基于视觉分析代理的集成人机团队，并强调专家用户与半自主分析过程之间的无缝且明确可分离的交互通道。&lt;h4&gt;主要发现&lt;/h4&gt;模型通过详细案例研究展示了如何促进对多媒体分析解决方案的深入理解和针对性改进，并通过明确捕捉专家用户如何与AI驱动的多媒体分析系统进行最优交互和引导，为系统设计、比较和未来研究指明了方向。&lt;h4&gt;结论&lt;/h4&gt;该模型为系统设计、比较和未来研究提供了明确的方向，并有助于解决敏感领域中的实际问题，如情报分析和调查性新闻等。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advances in Foundation Models and agentic Artificial Intelligenceare transforming multimedia analytics by enabling richer, more sophisticatedinteractions between humans and analytical systems. Existing conceptual modelsfor visual and multimedia analytics, however, do not adequately capture thecomplexity introduced by these powerful AI paradigms. To bridge this gap, wepropose a comprehensive multimedia analytics model specifically designed forthe foundation model era. Building upon established frameworks from visualanalytics, multimedia analytics, knowledge generation, analytic taskdefinition, mixed-initiative guidance, and human-in-the-loop reinforcementlearning, our model emphasizes integrated human-AI teaming based on visualanalytics agents from both technical and conceptual perspectives. Central tothe model is a seamless, yet explicitly separable, interaction channel betweenexpert users and semi-autonomous analytical processes, ensuring continuousalignment between user intent and AI behavior. The model addresses practicalchallenges in sensitive domains such as intelligence analysis, investigativejournalism, and other fields handling complex, high-stakes data. We illustratethrough detailed case studies how our model facilitates deeper understandingand targeted improvement of multimedia analytics solutions. By explicitlycapturing how expert users can optimally interact with and guide AI-poweredmultimedia analytics systems, our conceptual framework sets a clear directionfor system design, comparison, and future research.</description>
      <author>example@mail.com (Marcel Worring, Jan Zahálka, Stef van den Elzen, Maximilian Fischer, Daniel Keim)</author>
      <guid isPermaLink="false">2504.06138v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>NativQA Framework: Enabling LLMs with Native, Local, and Everyday Knowledge</title>
      <link>http://arxiv.org/abs/2504.05995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  LLMs, Native, Multilingual, Language Diversity, Contextual  Understanding, Minority Languages, Culturally Informed, Foundation Models,  Large Language Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NativQA的框架，旨在构建跨文化、跨地区的大规模问答数据集，用于评估和提升大型语言模型（LLMs）的能力。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型（LLMs）的快速发展，其在文化偏见、公平性和不同语言及地区环境中的应用引起了担忧。&lt;h4&gt;目的&lt;/h4&gt;为了提升和评估LLMs的能力，需要开发关注多语言、本地和文化背景的大规模资源。&lt;h4&gt;方法&lt;/h4&gt;NativQA框架通过用户定义的种子查询，利用搜索引擎收集特定地点的日常信息，构建大规模的问答数据集。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在24个国家的39个地点，7种语言（从低资源到高资源语言）进行了评估，生成了超过30万个问答对。&lt;h4&gt;结论&lt;/h4&gt;开发出的资源可用于LLMs的基准测试和进一步微调，且该框架已向公众开放。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：随着大型语言模型（LLMs）的快速发展，对其在文化偏见、公平性和在多样化语言及被代表不足的地区环境中的应用引发了担忧。为了提升和基准测试LLMs的能力，需要开发关注多语言、本地和文化背景的大规模资源。本研究提出了一种名为NativQA的框架，该框架能够无缝构建跨文化、跨地区的大规模、文化区域对齐的问答数据集。该框架利用用户定义的种子查询，并通过搜索引擎收集特定地点的日常信息。该框架已在24个国家的39个地点，涵盖7种语言（从极低资源到高资源语言）进行了评估，产生了超过30万个问答对。所开发资源可用于LLMs的基准测试和进一步微调。该框架已向公众开放（https://gitlab.com/nativqa/nativqa-framework）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of large language models (LLMs) has raised concernsabout cultural bias, fairness, and their applicability in diverse linguisticand underrepresented regional contexts. To enhance and benchmark thecapabilities of LLMs, there is a need to develop large-scale resources focusedon multilingual, local, and cultural contexts. In this study, we propose aframework, NativQA, that can seamlessly construct large-scale, culturally andregionally aligned QA datasets in native languages. The framework utilizesuser-defined seed queries and leverages search engines to collectlocation-specific, everyday information. It has been evaluated across 39locations in 24 countries and in 7 languages, ranging from extremelylow-resource to high-resource languages, which resulted over 300K QuestionAnswer (QA) pairs. The developed resources can be used for LLM benchmarking andfurther fine-tuning. The framework has been made publicly available for thecommunity (https://gitlab.com/nativqa/nativqa-framework).</description>
      <author>example@mail.com (Firoj Alam, Md Arid Hasan, Sahinur Rahman Laskar, Mucahid Kutlu, Shammur Absar Chowdhury)</author>
      <guid isPermaLink="false">2504.05995v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Robo-taxi Fleet Coordination at Scale via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.06125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 6 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种新的决策框架，用于解决大规模自主出行需求（AMoD）系统的协调问题，并通过公开可用的基准、数据集和模拟器以及开源代码库来促进该领域的研究民主化。&lt;h4&gt;背景&lt;/h4&gt;AMoD系统具有减少污染、能源消耗和城市拥堵的社会效益，但现有协调算法未能充分利用系统潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合数学建模和数据驱动技术的决策框架，通过强化学习和图网络方法解决AMoD系统的协调问题。&lt;h4&gt;方法&lt;/h4&gt;使用图网络框架，结合图表示学习、强化学习和经典运筹学工具，并通过多种模拟场景和仿真忠实度进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在系统性能、计算效率和泛化能力方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过提供公开的基准、数据集、模拟器和开源代码库，论文旨在推动该领域的研究，并建立标准化的方法比较过程。&lt;h4&gt;翻译&lt;/h4&gt;Fleets of robo-taxis offering on-demand transportation services, commonly known as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promise for societal benefits, such as reducing pollution, energy consumption, and urban congestion. However, orchestrating these systems at scale remains a critical challenge, with existing coordination algorithms often failing to exploit the systems' full potential. This work introduces a novel decision-making framework that unites mathematical modeling with data-driven techniques. In particular, we present the AMoD coordination problem through the lens of reinforcement learning and propose a graph network-based framework that exploits the main strengths of graph representation learning, reinforcement learning, and classical operations research tools. Extensive evaluations across diverse simulation fidelities and scenarios demonstrate the flexibility of our approach, achieving superior system performance, computational efficiency, and generalizability compared to prior methods. Finally, motivated by the need to democratize research efforts in this area, we release publicly available benchmarks, datasets, and simulators for network-level coordination alongside an open-source codebase designed to provide accessible simulation platforms and establish a standardized validation process for comparing methodologies. Code available at: https://github.com/StanfordASL/RL4AMOD&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fleets of robo-taxis offering on-demand transportation services, commonlyknown as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promisefor societal benefits, such as reducing pollution, energy consumption, andurban congestion. However, orchestrating these systems at scale remains acritical challenge, with existing coordination algorithms often failing toexploit the systems' full potential. This work introduces a noveldecision-making framework that unites mathematical modeling with data-driventechniques. In particular, we present the AMoD coordination problem through thelens of reinforcement learning and propose a graph network-based framework thatexploits the main strengths of graph representation learning, reinforcementlearning, and classical operations research tools. Extensive evaluations acrossdiverse simulation fidelities and scenarios demonstrate the flexibility of ourapproach, achieving superior system performance, computational efficiency, andgeneralizability compared to prior methods. Finally, motivated by the need todemocratize research efforts in this area, we release publicly availablebenchmarks, datasets, and simulators for network-level coordination alongsidean open-source codebase designed to provide accessible simulation platforms andestablish a standardized validation process for comparing methodologies. Codeavailable at: https://github.com/StanfordASL/RL4AMOD</description>
      <author>example@mail.com (Luigi Tresca, Carolin Schmidt, James Harrison, Filipe Rodrigues, Gioele Zardini, Daniele Gammelli, Marco Pavone)</author>
      <guid isPermaLink="false">2504.06125v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>InvNeRF-Seg: Fine-Tuning a Pre-Trained NeRF for 3D Object Segmentation</title>
      <link>http://arxiv.org/abs/2504.05751v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Invariant NeRF for Segmentation (InvNeRFSeg)，这是一种两步零变化微调策略，用于3D场景的分割。&lt;h4&gt;背景&lt;/h4&gt;NeRF广泛用于从2D RGB图像中重建高质量的3D点云，但分割这些重建的3D场景对于下游任务（如物体计数、尺寸估计和场景理解）至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以实现从2D分割到高质量3D分割的有效转换。&lt;h4&gt;方法&lt;/h4&gt;首先在RGB图像上训练标准NeRF，然后使用2D分割掩码对其进行微调，而不改变模型架构或损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;该方法直接从精炼的辐射场产生更高质量、更干净的分割点云，且计算开销和复杂性最小。场密度分析显示，语义细化一致：物体区域的密度增加，背景密度被抑制，确保分割清晰且可解释。&lt;h4&gt;结论&lt;/h4&gt;InvNeRFSeg在合成水果和真实世界的大豆数据集上，在性能上优于SA3D和FruitNeRF，有效扩展了2D分割到高质量3D分割。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural Radiance Fields (NeRF) have been widely adopted for reconstructinghigh quality 3D point clouds from 2D RGB images. However, the segmentation ofthese reconstructed 3D scenes is more essential for downstream tasks such asobject counting, size estimation, and scene understanding. While segmentationon raw 3D point clouds using deep learning requires labor intensive andtime-consuming manual annotation, directly training NeRF on binary masks alsofails due to the absence of color and shading cues essential for geometrylearning. We propose Invariant NeRF for Segmentation (InvNeRFSeg), a two step,zero change fine tuning strategy for 3D segmentation. We first train a standardNeRF on RGB images and then fine tune it using 2D segmentation masks withoutaltering either the model architecture or loss function. This approach produceshigher quality, cleaner segmented point clouds directly from the refinedradiance field with minimal computational overhead or complexity. Field densityanalysis reveals consistent semantic refinement: densities of object regionsincrease while background densities are suppressed, ensuring clean andinterpretable segmentations. We demonstrate InvNeRFSegs superior performanceover both SA3D and FruitNeRF on both synthetic fruit and real world soybeandatasets. This approach effectively extends 2D segmentation to high quality 3Dsegmentation.</description>
      <author>example@mail.com (Jiangsan Zhao, Jakob Geipel, Krzysztof Kusnierek, Xuean Cui)</author>
      <guid isPermaLink="false">2504.05751v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Substructure-Aware Expert Model for Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2504.05844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ASE-Mol是一种基于图神经网络（GNN）的分子性质预测框架，通过混合专家（MoE）方法，结合BRICS分解和显著子结构意识，动态识别正负子结构，以解决数据不平衡和分子结构多样性带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;分子性质预测对于药物发现和毒性评估等应用至关重要。然而，传统的基于GNN的方法在数据不平衡和分子结构多样性面前存在泛化能力有限的问题。&lt;h4&gt;目的&lt;/h4&gt;提出ASE-Mol框架，旨在解决GNN在分子性质预测中的泛化能力问题，提高预测的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;ASE-Mol采用MoE方法，结合BRICS分解和显著子结构意识，动态识别正负子结构，并整合MoE架构以减少负模式的影响，提高对正模式的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;在八个基准数据集上的实验结果表明，ASE-Mol在准确性和可解释性方面均取得了显著的提升，实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;ASE-Mol框架为分子性质预测提供了一种有效的方法，能够显著提高预测的准确性和可解释性，有望在药物发现和毒性评估等领域得到应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分子性质预测对于药物发现和毒性评估等应用至关重要。虽然图神经网络（GNN）通过将分子建模为分子图表现出有希望的结果，但它们依赖于数据驱动学习，限制了它们的泛化能力，特别是在数据不平衡和不同的分子子结构存在的情况下。现有方法往往忽略了不同子结构对分子性质的贡献，对它们进行统一处理。为了解决这些挑战，我们提出了一种新的基于GNN的分子性质预测框架ASE-Mol，它利用混合专家（MoE）方法。ASE-Mol结合了BRICS分解和显著子结构意识，以动态识别正负子结构。通过整合MoE架构，它减少了负模式的不利影响，同时提高了对正模式的适应性。在八个基准数据集上的实验结果表明，ASE-Mol实现了最先进的性能，在准确性和可解释性方面都有显著提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular property prediction is essential for applications such as drugdiscovery and toxicity assessment. While Graph Neural Networks (GNNs) haveshown promising results by modeling molecules as molecular graphs, theirreliance on data-driven learning limits their ability to generalize,particularly in the presence of data imbalance and diverse molecularsubstructures. Existing methods often overlook the varying contributions ofdifferent substructures to molecular properties, treating them uniformly. Toaddress these challenges, we propose ASE-Mol, a novel GNN-based framework thatleverages a Mixture-of-Experts (MoE) approach for molecular propertyprediction. ASE-Mol incorporates BRICS decomposition and significantsubstructure awareness to dynamically identify positive and negativesubstructures. By integrating a MoE architecture, it reduces the adverse impactof negative motifs while improving adaptability to positive motifs.Experimental results on eight benchmark datasets demonstrate that ASE-Molachieves state-of-the-art performance, with significant improvements in bothaccuracy and interpretability.</description>
      <author>example@mail.com (Tianyi Jiang, Zeyu Wang, Shanqing Yu, Qi Xuan)</author>
      <guid isPermaLink="false">2504.05844v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>AVP-AP: Self-supervised Automatic View Positioning in 3D cardiac CT via Atlas Prompting</title>
      <link>http://arxiv.org/abs/2504.05966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 8 figures, published to TMI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AVP-AP的新型框架，用于在3D CT体中实现自动视角定位，以解决心脏CT检查中的疾病诊断和手术规划问题。&lt;h4&gt;背景&lt;/h4&gt;自动视角定位对于心脏CT检查至关重要，但由于个体差异和庞大的3D搜索空间，这一任务极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自动视角定位方法，以减少手动标注的工作量，并提高定位的准确性。&lt;h4&gt;方法&lt;/h4&gt;AVP-AP框架首先提出了一种图集提示方法，生成3D标准图集并训练网络通过自监督方式将切片映射到图集空间中的对应位置。然后，通过图集提示在参考CT中识别目标CT体中切片的大致位置，并最终通过最大化预测切片与查询图像在基础模型特征空间中的相似度来细化位置。&lt;h4&gt;主要发现&lt;/h4&gt;AVP-AP框架在任意视角定位中平均提高了19.8%的结构相似性（SSIM），在双心室视图定位中比四名放射科医生提高了9%的SSIM。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，AVP-AP框架在心脏CT检查中的自动视角定位方面具有灵活性和高效性，并且具有很好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Automatic view positioning is crucial for cardiac computed tomography (CT) examinations, including disease diagnosis and surgical planning. However, it is highly challenging due to individual variability and large 3D search space. Existing work needs labor-intensive and time-consuming manual annotations to train view-specific models, which are limited to predicting only a fixed set of planes. However, in real clinical scenarios, the challenge of positioning semantic 2D slices with any orientation into varying coordinate space in arbitrary 3D volume remains unsolved. We thus introduce a novel framework, AVP-AP, the first to use Atlas Prompting for self-supervised Automatic View Positioning in the 3D CT volume. Specifically, this paper first proposes an atlas prompting method, which generates a 3D canonical atlas and trains a network to map slices into their corresponding positions in the atlas space via a self-supervised manner. Then, guided by atlas prompts corresponding to the given query images in a reference CT, we identify the coarse positions of slices in the target CT volume using rigid transformation between the 3D atlas and target CT volume, effectively reducing the search space. Finally, we refine the coarse positions by maximizing the similarity between the predicted slices and the query images in the feature space of a given foundation model. Our framework is flexible and efficient compared to other methods, outperforming other methods by 19.8% average structural similarity (SSIM) in arbitrary view positioning and achieving 9% SSIM in two-chamber view compared to four radiologists. Meanwhile, experiments on a public dataset validate our framework's generalizability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TMI.2025.3554785&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic view positioning is crucial for cardiac computed tomography (CT)examinations, including disease diagnosis and surgical planning. However, it ishighly challenging due to individual variability and large 3D search space.Existing work needs labor-intensive and time-consuming manual annotations totrain view-specific models, which are limited to predicting only a fixed set ofplanes. However, in real clinical scenarios, the challenge of positioningsemantic 2D slices with any orientation into varying coordinate space inarbitrary 3D volume remains unsolved. We thus introduce a novel framework,AVP-AP, the first to use Atlas Prompting for self-supervised Automatic ViewPositioning in the 3D CT volume. Specifically, this paper first proposes anatlas prompting method, which generates a 3D canonical atlas and trains anetwork to map slices into their corresponding positions in the atlas space viaa self-supervised manner. Then, guided by atlas prompts corresponding to thegiven query images in a reference CT, we identify the coarse positions ofslices in the target CT volume using rigid transformation between the 3D atlasand target CT volume, effectively reducing the search space. Finally, we refinethe coarse positions by maximizing the similarity between the predicted slicesand the query images in the feature space of a given foundation model. Ourframework is flexible and efficient compared to other methods, outperformingother methods by 19.8% average structural similarity (SSIM) in arbitrary viewpositioning and achieving 9% SSIM in two-chamber view compared to fourradiologists. Meanwhile, experiments on a public dataset validate ourframework's generalizability.</description>
      <author>example@mail.com (Xiaolin Fan, Yan Wang, Yingying Zhang, Mingkun Bao, Bosen Jia, Dong Lu, Yifan Gu, Jian Cheng, Haogang Zhu)</author>
      <guid isPermaLink="false">2504.05966v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Confidence Regularized Masked Language Modeling using Text Length</title>
      <link>http://arxiv.org/abs/2504.06037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的置信度正则化器，用于解决短文本输入时，掩码语言模型可能因过高置信单一答案而导致的准确性问题。&lt;h4&gt;背景&lt;/h4&gt;掩码语言模型是一种高效的文本表示学习方法，通过预测输入文本中随机掩码的词来学习语言表示。&lt;h4&gt;目的&lt;/h4&gt;旨在通过动态调整正则化强度来提高模型在短文本输入时的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种置信度正则化器，根据输入文本的长度动态控制正则化的强度。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在GLUE和SQuAD数据集上实现了更高的准确性和更低的期望校准误差。&lt;h4&gt;结论&lt;/h4&gt;该置信度正则化器能够有效提高短文本输入下的掩码语言模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked language modeling, which is a task to predict a randomly masked wordin the input text, is an efficient language representation learning method.Masked language modeling ignores various words which people can think of forfilling in the masked position and calculates the loss with a single word.Especially when the input text is short, the entropy of the word distributionthat can fill in the masked position can be high. This may cause the model tobe overconfident in the single answer. To address this issue, we propose anovel confidence regularizer that controls regularizing strength dynamically bythe input text length. Experiments with GLUE and SQuAD datasets showed that ourmethod achieves better accuracy and lower expected calibration error.</description>
      <author>example@mail.com (Seunghyun Ji, Soowon Lee)</author>
      <guid isPermaLink="false">2504.06037v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models Enhanced Hyperbolic Space Recommender Systems</title>
      <link>http://arxiv.org/abs/2504.05694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HyperLLM的模型无关框架，用于推荐系统，通过在双曲空间中提取和整合文本和语义数据中的层次信息，显著提升了推荐性能。&lt;h4&gt;背景&lt;/h4&gt;现有方法在推荐系统中使用欧几里得空间，难以捕捉文本和语义数据中的丰富层次信息，而层次信息对于捕捉用户偏好至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种模型无关框架，HyperLLM，以有效提取和整合文本和语义数据中的层次信息。&lt;h4&gt;方法&lt;/h4&gt;HyperLLM从结构和语义两个角度提取和整合层次信息。结构上，使用LLM生成具有层次父子关系的多级分类标签；语义上，引入新的元优化策略，从语义嵌入中提取层次信息，并桥接语义和协同空间之间的差距。&lt;h4&gt;主要发现&lt;/h4&gt;HyperLLM在推荐性能上显著优于基于双曲空间和LLM的推荐系统，性能提升超过40%。此外，HyperLLM不仅提高了推荐性能，还增强了训练稳定性。&lt;h4&gt;结论&lt;/h4&gt;层次信息在推荐系统中起着关键作用，HyperLLM通过有效利用层次信息，显著提升了推荐系统的性能和训练稳定性。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) have attracted significant attention inrecommender systems for their excellent world knowledge capabilities. However,existing methods that rely on Euclidean space struggle to capture the richhierarchical information inherent in textual and semantic data, which isessential for capturing user preferences. The geometric properties ofhyperbolic space offer a promising solution to address this issue. Nevertheless,integrating LLMs-based methods with hyperbolic space to effectively extract andincorporate diverse hierarchical information is non-trivial. To this end, we propose amodel-agnostic framework, named HyperLLM, which extracts and integrateshierarchical information from both structural and semantic perspectives. Structurally,HyperLLM uses LLMs to generate multi-level classification tags with hierarchicalparent-child relationships for each item. Then, tag-item and user-item interactionsare jointly learned and aligned through contrastive learning, thereby providing themodel with clear hierarchical information. Semantically, HyperLLM introduces a novelmeta-optimized strategy to extract hierarchical information from semantic embeddingsand bridge the gap between the semantic and collaborative spaces for seamlessintegration. Extensive experiments show that HyperLLM significantly outperformsrecommender systems based on hyperbolic space and LLMs, achieving performanceimprovements of over 40%. Furthermore, HyperLLM not only improves recommenderperformance but also enhances training stability, highlighting the critical role ofhierarchical information in recommender systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have attracted significant attention inrecommender systems for their excellent world knowledge capabilities. However,existing methods that rely on Euclidean space struggle to capture the richhierarchical information inherent in textual and semantic data, which isessential for capturing user preferences. The geometric properties ofhyperbolic space offer a promising solution to address this issue.Nevertheless, integrating LLMs-based methods with hyperbolic space toeffectively extract and incorporate diverse hierarchical information isnon-trivial. To this end, we propose a model-agnostic framework, namedHyperLLM, which extracts and integrates hierarchical information from bothstructural and semantic perspectives. Structurally, HyperLLM uses LLMs togenerate multi-level classification tags with hierarchical parent-childrelationships for each item. Then, tag-item and user-item interactions arejointly learned and aligned through contrastive learning, thereby providing themodel with clear hierarchical information. Semantically, HyperLLM introduces anovel meta-optimized strategy to extract hierarchical information from semanticembeddings and bridge the gap between the semantic and collaborative spaces forseamless integration. Extensive experiments show that HyperLLM significantlyoutperforms recommender systems based on hyperbolic space and LLMs, achievingperformance improvements of over 40%. Furthermore, HyperLLM not only improvesrecommender performance but also enhances training stability, highlighting thecritical role of hierarchical information in recommender systems.</description>
      <author>example@mail.com (Wentao Cheng, Zhida Qin, Zexue Wu, Pengzhan Zhou, Tianyu Huang)</author>
      <guid isPermaLink="false">2504.05694v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Enhancing Ensemble Forecasts of Extreme Rainfall</title>
      <link>http://arxiv.org/abs/2504.05471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted paper at ICLR 2025 - Tackling Climate Change with Machine  Learning Workshop (https://www.climatechange.ai/events/iclr2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用图神经网络后处理集合预报的方法，以改善极端降水事件的预报准确性，从而提高预报的可靠性并减轻极端降水和洪水风险。&lt;h4&gt;背景&lt;/h4&gt;气候变化导致极端降水事件增多，威胁基础设施、农业和公共安全。集合预报系统提供概率预报，但存在偏差和难以捕捉极端天气的问题。&lt;h4&gt;目的&lt;/h4&gt;提高极端降水事件的预报准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型框架，利用图神经网络后处理集合预报，特别建模了潜在分布的极端值，以捕捉空间依赖性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够捕捉空间依赖性，并提高极端事件的预报准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够提高预报的可靠性，减轻极端降水和洪水风险。&lt;h4&gt;翻译&lt;/h4&gt;Climate change is increasing the occurrence of extreme precipitation events, threatening infrastructure, agriculture, and public safety. Ensemble prediction systems provide probabilistic forecasts but exhibit biases and difficulties in capturing extreme weather. While post-processing techniques aim to enhance forecast accuracy, they rarely focus on precipitation, which exhibits complex spatial dependencies and tail behavior. Our novel framework leverages graph neural networks to post-process ensemble forecasts, specifically modeling the extremes of the underlying distribution. This allows to capture spatial dependencies and improves forecast accuracy for extreme events, thus leading to more reliable forecasts and mitigating risks of extreme precipitation and flooding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Climate change is increasing the occurrence of extreme precipitation events,threatening infrastructure, agriculture, and public safety. Ensemble predictionsystems provide probabilistic forecasts but exhibit biases and difficulties incapturing extreme weather. While post-processing techniques aim to enhanceforecast accuracy, they rarely focus on precipitation, which exhibits complexspatial dependencies and tail behavior. Our novel framework leverages graphneural networks to post-process ensemble forecasts, specifically modeling theextremes of the underlying distribution. This allows to capture spatialdependencies and improves forecast accuracy for extreme events, thus leading tomore reliable forecasts and mitigating risks of extreme precipitation andflooding.</description>
      <author>example@mail.com (Christopher Bülte, Sohir Maskey, Philipp Scholl, Jonas von Berg, Gitta Kutyniok)</author>
      <guid isPermaLink="false">2504.05471v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Decoupled Representation Learning and Regularization for Speech-Preserving Facial Expression Manipulation</title>
      <link>http://arxiv.org/abs/2504.05672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Speech-preserving facial expression manipulation (SPFEM)的技术，旨在在不改变原始语音内容口型动画的情况下，使说话头表现出特定的参考情感。&lt;h4&gt;背景&lt;/h4&gt;在SPFEM中，参考和源输入中存在的情感和内容信息可以提供直接且准确的监督信号，但说话过程中这些元素的内在交织对作为监督信号的有效性构成了挑战。&lt;h4&gt;目的&lt;/h4&gt;该工作的目的是通过学习内容与情感先验，结合对比学习，来学习解耦的内容和情感表示，从而实现更精确的情感操控。&lt;h4&gt;方法&lt;/h4&gt;论文提出了ContrastiveDecoupled Representation Learning (CDRL)算法，包括ContrastiveContent Representation Learning (CCRL)模块和ContrastiveEmotion Representation Learning (CERL)模块，分别用于学习内容先验和情感先验，并引入情感感知和情感增强的对比学习来训练这些模块。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验和评估，该算法在多个基准测试中显示出了有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够确保学习到情感独立的内容表示和内容独立的情感表示，从而在SPFEM模型训练中实现更准确的情感操控和音频唇同步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语音保留面部表情操纵（SPFEM）旨在修改一个说话头以显示特定的参考情感，同时保留源语音内容的口型动画。因此，参考和源输入中存在的情感和内容信息可以提供直接且准确的监督信号，用于SPFEM模型。然而，这些元素在说话过程中的内在交织对它们作为监督信号的有效性构成了挑战。在本工作中，我们提出通过对比学习来学习内容与情感先验，作为指导，通过创新的对比解耦表示学习（CDRL）算法来学习解耦的内容和情感表示。具体来说，设计了一个对比内容表示学习（CCRL）模块，用于学习包含主要内容信息的声音特征，作为内容先验，以指导从源输入中学习内容表示。同时，提出了一种对比情感表示学习（CERL）模块，利用预训练的视觉语言模型来学习情感先验，然后用于指导从参考输入中学习情感表示。我们进一步引入了情感感知和情感增强的对比学习来分别训练CCRL和CERL模块，确保学习到情感独立的内容表示和内容独立的情感表示。在SPFEM模型训练期间，使用解耦的内容和情感表示来监督生成过程，确保更准确的情感操控和音频唇同步。在多个基准测试上的广泛实验和评估显示了所提出算法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech-preserving facial expression manipulation (SPFEM) aims to modify atalking head to display a specific reference emotion while preserving the mouthanimation of source spoken contents. Thus, emotion and content informationexisting in reference and source inputs can provide direct and accuratesupervision signals for SPFEM models. However, the intrinsic intertwining ofthese elements during the talking process poses challenges to theireffectiveness as supervisory signals. In this work, we propose to learn contentand emotion priors as guidance augmented with contrastive learning to learndecoupled content and emotion representation via an innovative ContrastiveDecoupled Representation Learning (CDRL) algorithm. Specifically, a ContrastiveContent Representation Learning (CCRL) module is designed to learn audiofeature, which primarily contains content information, as content priors toguide learning content representation from the source input. Meanwhile, aContrastive Emotion Representation Learning (CERL) module is proposed to makeuse of a pre-trained visual-language model to learn emotion prior, which isthen used to guide learning emotion representation from the reference input. Wefurther introduce emotion-aware and emotion-augmented contrastive learning totrain CCRL and CERL modules, respectively, ensuring learningemotion-independent content representation and content-independent emotionrepresentation. During SPFEM model training, the decoupled content and emotionrepresentations are used to supervise the generation process, ensuring moreaccurate emotion manipulation together with audio-lip synchronization.Extensive experiments and evaluations on various benchmarks show theeffectiveness of the proposed algorithm.</description>
      <author>example@mail.com (Tianshui Chen, Jianman Lin, Zhijing Yang, Chumei Qing, Yukai Shi, Liang Lin)</author>
      <guid isPermaLink="false">2504.05672v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>SAP-CoPE: Social-Aware Planning using Cooperative Pose Estimation with Infrastructure Sensor Nodes</title>
      <link>http://arxiv.org/abs/2504.05727v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been submitted to the IEEE Transactions on Industrial  Electronics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAP-CoPE的社会感知规划框架，旨在解决自动驾驶系统在人口密集室内环境中感知受限和遮挡敏感等问题，以提高系统的安全性、舒适性。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶系统在室内环境中面临感知局限和遮挡问题，这给准确识别人类意图和生成舒适的社会感知轨迹带来了困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种社会感知规划框架，以解决自动驾驶系统在室内环境中的安全问题。&lt;h4&gt;方法&lt;/h4&gt;SAP-CoPE框架集成了合作基础设施、新颖的3D人体姿态估计方法和基于模型预测控制的控制器。该框架考虑了相机投影矩阵中的不确定性传播，并确保了人类关节的一致性。该框架适用于单摄像头或多摄像头配置，并能整合稀疏的LiDAR点云数据。此外，通过将基于人体姿态的人类个人空间场集成到模型预测控制器中，增强了系统的安全性和舒适性。&lt;h4&gt;主要发现&lt;/h4&gt;SAP-CoPE框架能够生成社会感知轨迹，并在模拟和现实世界环境中进行了广泛的评估，证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;SAP-CoPE框架能够有效提高自动驾驶系统在室内环境中的安全性和舒适性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Autonomous driving systems must operate safely in human-populated indoor environments, where challenges such as limited perception and occlusion sensitivity arise when relying solely on onboard sensors. These factors generate difficulties in the accurate recognition of human intentions and the generation of comfortable, socially aware trajectories. To address these issues, we propose SAP-CoPE, a social-aware planning framework that integrates cooperative infrastructure with a novel 3D human pose estimation method and a model predictive control-based controller. This real-time framework formulates an optimization problem that accounts for uncertainty propagation in the camera projection matrix while ensuring human joint coherence. The proposed method is adaptable to single- or multi-camera configurations and can incorporate sparse LiDAR point-cloud data. To enhance safety and comfort in human environments, we integrate a human personal space field based on human pose into a model predictive controller, enabling the system to navigate while avoiding discomfort zones. Extensive evaluations in both simulated and real-world settings demonstrate the effectiveness of our approach in generating socially aware trajectories for autonomous systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/HopeYless/SAP-CoPE-Project&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous driving systems must operate safely in human-populated indoorenvironments, where challenges such as limited perception and occlusionsensitivity arise when relying solely on onboard sensors. These factorsgenerate difficulties in the accurate recognition of human intentions and thegeneration of comfortable, socially aware trajectories. To address theseissues, we propose SAP-CoPE, a social-aware planning framework that integratescooperative infrastructure with a novel 3D human pose estimation method and amodel predictive control-based controller. This real-time framework formulatesan optimization problem that accounts for uncertainty propagation in the cameraprojection matrix while ensuring human joint coherence. The proposed method isadaptable to single- or multi-camera configurations and can incorporate sparseLiDAR point-cloud data. To enhance safety and comfort in human environments, weintegrate a human personal space field based on human pose into a modelpredictive controller, enabling the system to navigate while avoidingdiscomfort zones. Extensive evaluations in both simulated and real-worldsettings demonstrate the effectiveness of our approach in generating sociallyaware trajectories for autonomous systems.</description>
      <author>example@mail.com (Minghao Ning, Yufeng Yang, Shucheng Huang, Jiaming Zhong, Keqi Shu, Chen Sun, Ehsan Hashemi, Amir Khajepour)</author>
      <guid isPermaLink="false">2504.05727v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Dual Boost-Driven Graph-Level Clustering Network</title>
      <link>http://arxiv.org/abs/2504.05670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图级聚类网络DBGCN，旨在解决图学习中的图级聚类问题。&lt;h4&gt;背景&lt;/h4&gt;图级聚类在图学习中是一个关键且具有挑战性的问题。虽然深度学习与表示学习的结合带来了一定程度的性能提升，但现有方法存在噪声和特征传播过程中的噪声聚合问题，导致聚类性能不理想。&lt;h4&gt;目的&lt;/h4&gt;提出DBGCN旨在通过交替促进图级聚类和过滤干扰信息来提高图级聚类性能。&lt;h4&gt;方法&lt;/h4&gt;DBGCN在池化步骤中评估全局特征的贡献，并使用可学习的转换矩阵优化特征，以获得高质量的图级表示。此外，通过评估图级表示之间的相似性，识别并抑制对聚类有害的信息，以提供更准确的视图融合指导。&lt;h4&gt;主要发现&lt;/h4&gt;DBGCN在六个基准数据集上优于现有的图级聚类方法。&lt;h4&gt;结论&lt;/h4&gt;DBGCN是一种有效的图级聚类方法，可以显著提高聚类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-level clustering remains a pivotal yet formidable challenge in graphlearning. Recently, the integration of deep learning with representationlearning has demonstrated notable advancements, yielding performanceenhancements to a certain degree. However, existing methods suffer from atleast one of the following issues: 1. the original graph structure has noise,and 2. during feature propagation and pooling processes, noise is graduallyaggregated into the graph-level embeddings through information propagation.Consequently, these two limitations mask clustering-friendly information,leading to suboptimal graph-level clustering performance. To this end, wepropose a novel Dual Boost-Driven Graph-Level Clustering Network (DBGCN) toalternately promote graph-level clustering and filtering out interferenceinformation in a unified framework. Specifically, in the pooling step, weevaluate the contribution of features at the global and optimize them using alearnable transformation matrix to obtain high-quality graph-levelrepresentation, such that the model's reasoning capability can be improved.Moreover, to enable reliable graph-level clustering, we first identify andsuppress information detrimental to clustering by evaluating similaritiesbetween graph-level representations, providing more accurate guidance formulti-view fusion. Extensive experiments demonstrated that DBGCN outperformsthe state-of-the-art graph-level clustering methods on six benchmark datasets.</description>
      <author>example@mail.com (John Smith, Wenxuan Tu, Junlong Wu, Wenxin Zhang, Jingxin Liu, Haotian Wang, Jieren Cheng, Huajie Lei, Guangzhen Yao, Lingren Wang, Mengfei Li, Renda Han, Yu Li)</author>
      <guid isPermaLink="false">2504.05670v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>KAN-SAM: Kolmogorov-Arnold Network Guided Segment Anything Model for RGB-T Salient Object Detection</title>
      <link>http://arxiv.org/abs/2504.05878v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted by ICME2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KAN-SAM的新型基于提示学习的RGB-热显著目标检测方法，通过引入热特征和Kolmogorov-Arnold网络（KAN）适配器，有效地增强了RGB表示并提高了鲁棒性，同时通过随机掩码策略改善了泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的RGB-热显著目标检测方法在复杂场景中表现良好，但由于数据集多样性有限和多模态表示的效率问题，其泛化能力有限。&lt;h4&gt;目的&lt;/h4&gt;提高RGB-热显著目标检测方法的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;1. 使用Segment Anything Model 2（SAM2）进行RGB-T SOD，引入热特征作为指导提示；2. 通过KAN适配器高效准确地增强RGB表示；3. 引入互斥随机掩码策略以减少对RGB数据的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;KAN-SAM方法在基准测试中表现出比现有方法更优越的性能。&lt;h4&gt;结论&lt;/h4&gt;KAN-SAM方法通过结合视觉基础模型和高效的特征增强策略，显著提高了RGB-热显著目标检测的泛化能力和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing RGB-thermal salient object detection (RGB-T SOD) methods aim toidentify visually significant objects by leveraging both RGB and thermalmodalities to enable robust performance in complex scenarios, but they oftensuffer from limited generalization due to the constrained diversity ofavailable datasets and the inefficiencies in constructing multi-modalrepresentations. In this paper, we propose a novel prompt learning-based RGB-TSOD method, named KAN-SAM, which reveals the potential of visual foundationalmodels for RGB-T SOD tasks. Specifically, we extend Segment Anything Model 2(SAM2) for RGB-T SOD by introducing thermal features as guiding prompts throughefficient and accurate Kolmogorov-Arnold Network (KAN) adapters, whicheffectively enhance RGB representations and improve robustness. Furthermore, weintroduce a mutually exclusive random masking strategy to reduce reliance onRGB data and improve generalization. Experimental results on benchmarksdemonstrate superior performance over the state-of-the-art methods.</description>
      <author>example@mail.com (Xingyuan Li, Ruichao Hou, Tongwei Ren, Gangshan Wu)</author>
      <guid isPermaLink="false">2504.05878v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Point-based Instance Completion with Scene Constraints</title>
      <link>http://arxiv.org/abs/2504.05698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于点云的实例补全模型，能够鲁棒地在场景中补全任意尺度和大小的物体，并引入了场景约束以提升补全质量。&lt;h4&gt;背景&lt;/h4&gt;现有的点基于物体补全方法在场景补全方面存在局限性，如不考虑场景约束和期望输入在规范坐标系中。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的局限性，提出一种新的点云基于实例补全模型，能够考虑场景约束并提高补全质量。&lt;h4&gt;方法&lt;/h4&gt;引入了表示场景约束的点云，并通过交叉注意力机制将其整合到补全模型中。构建了新的数据集ScanWCF，用于评估实例场景补全任务。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在部分扫描的保真度、补全质量和合理性方面优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的模型能够有效地补全场景中的物体，并提高了补全质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent point-based object completion methods have demonstrated the ability toaccurately recover the missing geometry of partially observed objects. However,these approaches are not well-suited for completing objects within a scene, asthey do not consider known scene constraints (e.g., other observed surfaces) intheir completions and further expect the partial input to be in a canonicalcoordinate system, which does not hold for objects within scenes. Whileinstance scene completion methods have been proposed for completing objectswithin a scene, they lag behind point-based object completion methods in termsof object completion quality and still do not consider known scene constraintsduring completion. To overcome these limitations, we propose a pointcloud-based instance completion model that can robustly complete objects atarbitrary scales and pose in the scene. To enable reasoning at the scene level,we introduce a sparse set of scene constraints represented as point clouds andintegrate them into our completion model via a cross-attention mechanism. Toevaluate the instance scene completion task on indoor scenes, we further builda new dataset called ScanWCF, which contains labeled partial scans as well asaligned ground truth scene completions that are watertight and collision-free.Through several experiments, we demonstrate that our method achieves improvedfidelity to partial scans, higher completion quality, and greater plausibilityover existing state-of-the-art methods.</description>
      <author>example@mail.com (Wesley Khademi, Li Fuxin)</author>
      <guid isPermaLink="false">2504.05698v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>GraphPINE: Graph Importance Propagation for Interpretable Drug Response Prediction</title>
      <link>http://arxiv.org/abs/2504.05454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GraphPINE的图神经网络架构，用于药物反应预测，该架构利用领域特定的先验知识来初始化节点重要性，并在训练过程中优化。&lt;h4&gt;背景&lt;/h4&gt;可解释性对于生物医学研究中的许多任务至关重要。现有的可解释性方法主要集中在注意力、梯度和Shapley值上，但这些方法无法处理具有强烈相关先验知识的数据，并且无法根据已知预测特征之间的关系来约束可解释性结果。&lt;h4&gt;目的&lt;/h4&gt;提出GraphPINE以克服现有方法的局限性，并提高药物反应预测的可解释性。&lt;h4&gt;方法&lt;/h4&gt;GraphPINE利用类似于LSTM的顺序格式，并引入了一个重要性传播层，该层统一了特征矩阵和节点重要性的更新，并使用基于GNN的图传播特征值。这种方法允许进行有信息的特征学习和改进的图表示。&lt;h4&gt;主要发现&lt;/h4&gt;GraphPINE在癌症药物反应预测中取得了PR-AUC为0.894和ROC-AUC为0.796的结果，涵盖了952种药物。&lt;h4&gt;结论&lt;/h4&gt;GraphPINE通过结合先验知识和图神经网络技术，为药物反应预测提供了更可解释的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：可解释性对于生物医学研究中的许多任务至关重要。最近的可解释性方法主要集中在注意力、梯度和Shapley值上。这些方法不处理具有强烈相关先验知识的数据，并且无法根据已知预测特征之间的关系来约束可解释性结果。我们提出了GraphPINE，一种利用领域特定先验知识初始化节点重要性并在训练过程中优化的图神经网络架构。通常，一个手动后预测步骤检查文献（即先验知识）以了解返回的预测特征。虽然可以在预测后获得梯度和注意力的节点重要性，但这些方法中的节点重要性缺乏补充先验知识；GraphPINE试图克服这一局限性。GraphPINE与其他GNN门控方法的不同之处在于利用了类似于LSTM的顺序格式。我们引入了一个重要性传播层，该层统一了1）特征矩阵和节点重要性的更新，2）使用基于GNN的图传播特征值。这种初始化和更新机制允许进行有信息的特征学习和改进的图表示。我们将GraphPINE应用于癌症药物反应预测，使用药物筛选和基因数据，这些数据来自包含超过5000个基因节点的基因-基因图，以及用于初始重要性的药物-靶点相互作用（DTI）图。基因-基因图和DTI来自经过精选的来源，并按讨论药物和基因之间关系的文章数量进行加权。GraphPINE在952种药物上实现了PR-AUC为0.894和ROC-AUC为0.796。代码可在https://anonymous.4open.science/r/GraphPINE-40DE上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Explainability is necessary for many tasks in biomedical research. Recentexplainability methods have focused on attention, gradient, and Shapley value.These do not handle data with strong associated prior knowledge and fail toconstrain explainability results based on known relationships betweenpredictive features.  We propose GraphPINE, a graph neural network (GNN) architecture leveragingdomain-specific prior knowledge to initialize node importance optimized duringtraining for drug response prediction. Typically, a manual post-prediction stepexamines literature (i.e., prior knowledge) to understand returned predictivefeatures. While node importance can be obtained for gradient and attentionafter prediction, node importance from these methods lacks complementary priorknowledge; GraphPINE seeks to overcome this limitation. GraphPINE differs fromother GNN gating methods by utilizing an LSTM-like sequential format. Weintroduce an importance propagation layer that unifies 1) updates for featurematrix and node importance and 2) uses GNN-based graph propagation of featurevalues. This initialization and updating mechanism allows for informed featurelearning and improved graph representation.  We apply GraphPINE to cancer drug response prediction using drug screeningand gene data collected for over 5,000 gene nodes included in a gene-gene graphwith a drug-target interaction (DTI) graph for initial importance. Thegene-gene graph and DTIs were obtained from curated sources and weighted byarticle count discussing relationships between drugs and genes. GraphPINEachieves a PR-AUC of 0.894 and ROC-AUC of 0.796 across 952 drugs. Code isavailable at https://anonymous.4open.science/r/GraphPINE-40DE.</description>
      <author>example@mail.com (Yoshitaka Inoue, Tianfan Fu, Augustin Luna)</author>
      <guid isPermaLink="false">2504.05454v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>DefMamba: Deformable Visual State Space Model</title>
      <link>http://arxiv.org/abs/2504.05794v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的视觉基础模型DefMamba，通过多尺度骨干结构和可变形Mamba（DM）块，动态调整扫描路径，以提高图像结构学习和对物体细节变化的检测能力。&lt;h4&gt;背景&lt;/h4&gt;状态空间模型（SSM）特别是Mamba因其平衡计算效率和性能的能力而受到关注。然而，现有的视觉Mamba方法大多使用预定义的扫描顺序将图像平面化为1D序列，导致模型无法充分利用图像的空间结构信息。&lt;h4&gt;目的&lt;/h4&gt;提出DefMamba模型以解决上述问题，增强模型对图像空间结构信息的利用。&lt;h4&gt;方法&lt;/h4&gt;DefMamba模型包含一个多尺度骨干结构和可变形Mamba（DM）块，以及可变形扫描（DS）策略，以动态调整扫描路径并优先处理重要信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，DefMamba在图像分类、目标检测、实例分割和语义分割等视觉任务中实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;DefMamba模型通过改进图像结构和细节变化的检测能力，在视觉任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Recently, state space models (SSM), particularly Mamba, have attracted significant attention from scholars due to their ability to effectively balance computational efficiency and performance. However, most existing visual Mamba methods flatten images into 1D sequences using predefined scan orders, which results in the model being less capable of utilizing the spatial structural information of the image during the feature extraction process. To address this issue, we proposed a novel visual foundation model called DefMamba. This model includes a multi-scale backbone structure and deformable mamba (DM) blocks, which dynamically adjust the scanning path to prioritize important information, thus enhancing the capture and processing of relevant input features. By combining a deformable scanning (DS) strategy, this model significantly improves its ability to learn image structures and detects changes in object details. Numerous experiments have shown that DefMamba achieves state-of-the-art performance in various visual tasks, including image classification, object detection, instance segmentation, and semantic segmentation. The code is open source on DefMamba.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, state space models (SSM), particularly Mamba, have attractedsignificant attention from scholars due to their ability to effectively balancecomputational efficiency and performance. However, most existing visual Mambamethods flatten images into 1D sequences using predefined scan orders, whichresults the model being less capable of utilizing the spatial structuralinformation of the image during the feature extraction process. To address thisissue, we proposed a novel visual foundation model called DefMamba. This modelincludes a multi-scale backbone structure and deformable mamba (DM) blocks,which dynamically adjust the scanning path to prioritize important information,thus enhancing the capture and processing of relevant input features. Bycombining a deformable scanning(DS) strategy, this model significantly improvesits ability to learn image structures and detects changes in object details.Numerous experiments have shown that DefMamba achieves state-of-the-artperformance in various visual tasks, including image classification, objectdetection, instance segmentation, and semantic segmentation. The code is opensource on DefMamba.</description>
      <author>example@mail.com (Leiye Liu, Miao Zhang, Jihao Yin, Tingwei Liu, Wei Ji, Yongri Piao, Huchuan Lu)</author>
      <guid isPermaLink="false">2504.05794v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Approach to Linking Histology Images with DNA Methylation</title>
      <link>http://arxiv.org/abs/2504.05403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于图神经网络的弱监督学习框架，用于预测具有一致模式基因组的甲基化状态，并通过分析TCGA数据集，证明了该方法在预测甲基化状态方面的优越性。&lt;h4&gt;背景&lt;/h4&gt;DNA甲基化是一种表观遗传机制，通过向DNA添加甲基基团来调节基因表达。异常的甲基化模式与癌症发展有关。目前常用的DNA甲基化检测方法成本高、处理时间长，限制了其在临床实践中的应用。&lt;h4&gt;目的&lt;/h4&gt;探索全切片图像（WSIs）与DNA甲基化模式之间的关系，以降低检测成本和时间。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于端到端图神经网络的弱监督学习框架，并使用来自TCGA的三组数据（LGG、GBM和KIRC）进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在预测甲基化状态方面比现有方法提高了超过20%的AUROC分数，基因集富集分析显示大多数基因组在重要特征和通路中显著富集，并通过空间富集热图进一步研究了组织学模式与DNA甲基化状态之间的联系。&lt;h4&gt;结论&lt;/h4&gt;这是首次使用弱监督深度学习探索空间解析组织学模式与基因组甲基化状态之间关联的研究，为癌症的甲基化检测提供了新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：DNA甲基化是一种表观遗传机制，通过向DNA添加甲基基团来调节基因表达。异常的甲基化模式与癌症发展有关。为了量化DNA甲基化，通常使用专门的检测方法。然而，这些方法通常成本高、处理时间长，限制了它们在常规临床实践中的广泛应用。相比之下，大多数癌症患者的全切片图像（WSIs）可以更容易地获得。因此，鉴于WSIs的易于获取，有必要探索WSIs与DNA甲基化模式之间的潜在关系。为了解决这个问题，我们提出了一种基于端到端图神经网络的弱监督学习框架，用于预测表现出样本间一致模式的基因组的甲基化状态。使用来自癌症基因组图谱（TCGA）的三个队列（TCGA-LGG（脑低级别胶质瘤）、TCGA-GBM（多形性胶质母细胞瘤）和TCGA-KIRC（肾肾细胞癌））的数据，我们证明了所提出的方法在预测甲基化状态方面比最先进（SOTA）方法提高了显著更高的AUROC分数，超过20%。我们对基因组进行了基因集富集分析，并显示大多数基因组在重要特征和通路中显著富集。我们还生成了空间富集热图，以进一步研究组织学模式与DNA甲基化状态之间的联系。据我们所知，这是首次使用弱监督深度学习探索空间解析组织学模式与基因组甲基化状态之间关联的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; DNA methylation is an epigenetic mechanism that regulates gene expression byadding methyl groups to DNA. Abnormal methylation patterns can disrupt geneexpression and have been linked to cancer development. To quantify DNAmethylation, specialized assays are typically used. However, these assays areoften costly and have lengthy processing times, which limits their widespreadavailability in routine clinical practice. In contrast, whole slide images(WSIs) for the majority of cancer patients can be more readily available. Assuch, given the ready availability of WSIs, there is a compelling need toexplore the potential relationship between WSIs and DNA methylation patterns.To address this, we propose an end-to-end graph neural network based weaklysupervised learning framework to predict the methylation state of gene groupsexhibiting coherent patterns across samples. Using data from three cohorts fromThe Cancer Genome Atlas (TCGA) - TCGA-LGG (Brain Lower Grade Glioma), TCGA-GBM(Glioblastoma Multiforme) ($n$=729) and TCGA-KIRC (Kidney Renal Clear CellCarcinoma) ($n$=511) - we demonstrate that the proposed approach achievessignificantly higher AUROC scores than the state-of-the-art (SOTA) methods, bymore than $20\%$. We conduct gene set enrichment analyses on the gene groupsand show that majority of the gene groups are significantly enriched inimportant hallmarks and pathways. We also generate spatially enriched heatmapsto further investigate links between histological patterns and DNA methylationstates. To the best of our knowledge, this is the first study that exploresassociation of spatially resolved histological patterns with gene groupmethylation states across multiple cancer types using weakly supervised deeplearning.</description>
      <author>example@mail.com (Manahil Raza, Muhammad Dawood, Talha Qaiser, Nasir M. Rajpoot)</author>
      <guid isPermaLink="false">2504.05403v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>ViralQC: A Tool for Assessing Completeness and Contamination of Predicted Viral Contigs</title>
      <link>http://arxiv.org/abs/2504.05790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ViralQC的工具，用于评估病毒contigs或bins的质量。&lt;h4&gt;背景&lt;/h4&gt;病毒是地球上最丰富的生物实体，在多种生态系统中扮演着重要角色。对病毒进行分类对于理解其特性和功能至关重要。宏基因组测序已成为病毒发现的最全面方法，但它区分病毒序列与细胞来源的序列仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，开发一个准确且高效的评估病毒contigs质量的方法。&lt;h4&gt;方法&lt;/h4&gt;ViralQC通过在病毒和细胞基因组上训练的基础模型识别潜在病毒序列中的污染区域，并通过蛋白质组织对齐来估计病毒完整性。&lt;h4&gt;主要发现&lt;/h4&gt;ViralQC在多个数据集上进行了评估，并与病毒质量评估的领先工具CheckV进行了比较。ViralQC正确识别了比CheckV多38%的污染，同时保持了中值绝对误差仅为3%。此外，ViralQC对中等至高质量（&gt;50%完整性）的contigs提供了更准确的结果，证明了其在完整性估计方面的优越性能。&lt;h4&gt;结论&lt;/h4&gt;ViralQC是一个准确且高效的工具，可以用于评估病毒contigs的质量，特别是在完整性估计方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivation: Viruses represent the most abundant biological entities on theplanet and play vital roles in diverse ecosystems. Cataloging viruses acrossvarious environments is essential for understanding their properties andfunctions. Metagenomic sequencing has emerged as the most comprehensive methodfor virus discovery, enabling the sequencing of all genetic materials,including viruses, from host or environmental samples. However, distinguishingviral sequences from the vast background of cellular organism-derived reads inmetagenomic data remains a significant challenge. While several learning-basedtools, such as VirSorter2 and geNomad, have shown promise in identifying viralcontigs, they often experience varying degrees of false positive rates due tonoise in sequencing and assembly, shared genes between viruses and their hosts,and the formation of proviruses within host genomes. This highlights the urgentneed for an accurate and efficient method to evaluate the quality of viralcontigs. Results: To address these challenges, we introduce ViralQC, a tooldesigned to assess the quality of reported viral contigs or bins. ViralQCidentifies contamination regions within putative viral sequences usingfoundation models trained on viral and cellular genomes and estimates viralcompleteness through protein organization alignment. We evaluate ViralQC onmultiple datasets and compare its performance against CheckV, thestate-of-the-art in virus quality assessment. Notably, ViralQC correctlyidentifies 38% more contamination than CheckV, while maintaining a medianabsolute error of only 3%. In addition, ViralQC delivers more accurate resultsfor medium- to high-quality (&gt;50% completeness) contigs, demonstrating itssuperior performance in completeness estimation.</description>
      <author>example@mail.com (Cheng Peng, Jiayu Shang, Jiaojiao Guan, Yanni Sun)</author>
      <guid isPermaLink="false">2504.05790v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>L3GS: Layered 3D Gaussian Splats for Efficient 3D Scene Delivery</title>
      <link>http://arxiv.org/abs/2504.05517v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效的三维内容交付框架，使用3D高斯块（3DGS）作为底层数据表示，以实现高质量的三维场景实时观看。&lt;h4&gt;背景&lt;/h4&gt;传统的3D内容表示如密集点云数据量大，网络带宽消耗高；新的表示如神经辐射场渲染效率低，帧率不佳。&lt;h4&gt;目的&lt;/h4&gt;创建一个高效的3D内容交付框架，允许用户以3DGS作为数据表示观看高质量的三维场景。&lt;h4&gt;方法&lt;/h4&gt;（1）创建新的分层3DGS场景以实现高效交付；（2）调度算法决定何时下载哪些块；（3）通过佩戴虚拟现实头盔的用户进行追踪实验，评估视觉效果和延迟。&lt;h4&gt;主要发现&lt;/h4&gt;系统L3GS实现了高视觉质量，平均SSIM值比基线高16.9%，并且可以与其他压缩的3DGS表示一起工作。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在保持高视觉质量的同时，实现了高效的3D内容交付。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统三维内容表示包括密集点云，消耗大量数据和网络带宽，而新的表示如神经辐射场由于非标准的体积渲染流程而帧率不佳。三维高斯块（3DGS）可以看作是点云的推广，兼具两者之长，具有高视觉质量和高效的渲染，实现实时帧率。然而，由于高网络数据消耗（例如，单个场景1.5GB），从托管服务器向客户端设备传输3DGS场景仍然具有挑战性。本文的目标是创建一个高效的三维内容交付框架，允许用户使用3DGS作为底层数据表示查看高质量的三维场景。本文的主要贡献包括：（1）创建新的分层3DGS场景以实现高效交付；（2）调度算法以决定何时下载哪些块；（3）通过佩戴虚拟现实头盔的用户进行的追踪实验来评估视觉效果和延迟。我们的分层3D高斯块交付系统L3GS展示了高视觉质量，平均SSIM值比基线高16.9%，并且可以与其他压缩的3DGS表示一起工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional 3D content representations include dense point clouds thatconsume large amounts of data and hence network bandwidth, while newerrepresentations such as neural radiance fields suffer from poor frame rates dueto their non-standard volumetric rendering pipeline. 3D Gaussian splats (3DGS)can be seen as a generalization of point clouds that meet the best of bothworlds, with high visual quality and efficient rendering for real-time framerates. However, delivering 3DGS scenes from a hosting server to client devicesis still challenging due to high network data consumption (e.g., 1.5 GB for asingle scene). The goal of this work is to create an efficient 3D contentdelivery framework that allows users to view high quality 3D scenes with 3DGSas the underlying data representation. The main contributions of the paper are:(1) Creating new layered 3DGS scenes for efficient delivery, (2) Schedulingalgorithms to choose what splats to download at what time, and (3) Trace-drivenexperiments from users wearing virtual reality headsets to evaluate the visualquality and latency. Our system for Layered 3D Gaussian Splats delivery L3GSdemonstrates high visual quality, achieving 16.9% higher average SSIM comparedto baselines, and also works with other compressed 3DGS representations.</description>
      <author>example@mail.com (Yi-Zhen Tsai, Xuechen Zhang, Zheng Li, Jiasi Chen)</author>
      <guid isPermaLink="false">2504.05517v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Measuring Déjà vu Memorization Efficiently</title>
      <link>http://arxiv.org/abs/2504.05651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究表明，表示学习模型可能会记住其训练数据，本文提出了一种无需重新训练即可近似评估模型记忆能力的方法。&lt;h4&gt;背景&lt;/h4&gt;现有研究指出，表示学习模型可能错误地记住训练数据，例如，某些模型可以通过背景的表示正确预测前景标签。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单的方法来估计数据集级别的相关性，并用于评估预训练模型的记忆能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种无需重新训练的方法来近似评估模型的记忆能力，并通过预训练的图像和视觉语言模型进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;不同的记忆测量方法产生了非常相似的总结果，开源模型通常具有比在数据子集上训练的相似模型更低的记忆能力。&lt;h4&gt;结论&lt;/h4&gt;该方法首次允许测量预训练开源图像表示和视觉语言表示模型的记忆能力。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，表示学习模型可能会意外地记住它们的训练数据。例如， déjà vu 方法表明，对于某些表示学习模型和训练图像，有时仅通过背景的表示就可以正确预测前景标签，这比通过数据集级别的相关性更好。然而，他们的测量方法需要训练两个模型——一个用于估计数据集级别的相关性，另一个用于估计记忆。这种多模型设置对于大型开源模型来说变得不可行。在这项工作中，我们提出了替代的简单方法来估计数据集级别的相关性，并表明这些方法可以用来近似评估现成的模型的记忆能力，而无需任何重新训练。这使得我们首次能够测量预训练的开源图像表示和视觉语言表示模型的记忆能力。我们的结果表明，不同的记忆测量方法产生了非常相似的总结果。我们还发现，开源模型通常具有比在数据子集上训练的相似模型更低的记忆能力。代码对于视觉和视觉语言模型都是可用的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research has shown that representation learning models mayaccidentally memorize their training data. For example, the d\'ej\`a vu methodshows that for certain representation learning models and training images, itis sometimes possible to correctly predict the foreground label given only therepresentation of the background - better than through dataset-levelcorrelations. However, their measurement method requires training two models -one to estimate dataset-level correlations and the other to estimatememorization. This multiple model setup becomes infeasible for largeopen-source models. In this work, we propose alternative simple methods toestimate dataset-level correlations, and show that these can be used toapproximate an off-the-shelf model's memorization ability without anyretraining. This enables, for the first time, the measurement of memorizationin pre-trained open-source image representation and vision-languagerepresentation models. Our results show that different ways of measuringmemorization yield very similar aggregate results. We also find thatopen-source models typically have lower aggregate memorization than similarmodels trained on a subset of the data. The code is available both for visionand vision language models.</description>
      <author>example@mail.com (Narine Kokhlikyan, Bargav Jayaraman, Florian Bordes, Chuan Guo, Kamalika Chaudhuri)</author>
      <guid isPermaLink="false">2504.05651v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven Speech Anti-spoofing</title>
      <link>http://arxiv.org/abs/2504.05657v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript has been submitted for peer review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Nested Res2Net (Nes2Net) 是一种轻量级后端架构，用于直接处理高维特征，旨在解决高维输出特征与下游任务模型输入不匹配的问题。&lt;h4&gt;背景&lt;/h4&gt;语音基础模型在语音相关任务中取得了显著进展，但它们的高维输出特征与需要低维输入的下游任务模型之间存在不匹配。&lt;h4&gt;目的&lt;/h4&gt;提出Nes2Net以解决使用维度缩减层导致参数开销增加、计算成本上升和信息丢失的问题。&lt;h4&gt;方法&lt;/h4&gt;Nes2Net采用嵌套结构，增强多尺度特征提取，改进特征交互，并保留高维信息，直接处理高维特征。&lt;h4&gt;主要发现&lt;/h4&gt;在CtRSVDD、ASVspoof 2021、ASVspoof 5、PartialSpoof和In-the-Wild等五个数据集上测试，Nes2Net实现了22%的性能提升和87%的后端计算成本降低。&lt;h4&gt;结论&lt;/h4&gt;Nes2Net在多个数据集上表现出优异的鲁棒性和泛化能力，且其代码包和预训练模型可在GitHub上获取。&lt;h4&gt;翻译&lt;/h4&gt;语音基础模型显著推进了各种语音相关任务，但其高维输出特征常常与下游任务模型所需的低维输入不匹配。一个常见的解决方案是应用一个维度缩减（DR）层，但这会增加参数开销、计算成本，并可能导致信息丢失。为了解决这些问题，我们提出了Nested Res2Net（Nes2Net），这是一种专为直接处理高维特征而设计的轻量级后端架构。嵌套结构增强了多尺度特征提取，改善了特征交互，并保留了高维信息。我们首先在CtRSVDD（一种唱歌声音深度伪造检测数据集）上验证了Nes2Net，与最先进的基线相比，实现了22%的性能提升和87%的后端计算成本降低。此外，在ASVspoof 2021、ASVspoof 5、PartialSpoof和In-the-Wild等四个不同的数据集上进行了广泛的测试，涵盖了完全伪造的语音、对抗攻击、部分伪造和现实场景，Nes2Net的一致表现突出了其优越的鲁棒性和泛化能力。代码包和预训练模型可在https://github.com/Liu-Tianchi/Nes2Net上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech foundation models have significantly advanced various speech-relatedtasks by providing exceptional representation capabilities. However, theirhigh-dimensional output features often create a mismatch with downstream taskmodels, which typically require lower-dimensional inputs. A common solution isto apply a dimensionality reduction (DR) layer, but this approach increasesparameter overhead, computational costs, and risks losing valuable information.To address these issues, we propose Nested Res2Net (Nes2Net), a lightweightback-end architecture designed to directly process high-dimensional featureswithout DR layers. The nested structure enhances multi-scale featureextraction, improves feature interaction, and preserves high-dimensionalinformation. We first validate Nes2Net on CtrSVDD, a singing voice deepfakedetection dataset, and report a 22% performance improvement and an 87% back-endcomputational cost reduction over the state-of-the-art baseline. Additionally,extensive testing across four diverse datasets: ASVspoof 2021, ASVspoof 5,PartialSpoof, and In-the-Wild, covering fully spoofed speech, adversarialattacks, partial spoofing, and real-world scenarios, consistently highlightsNes2Net's superior robustness and generalization capabilities. The code packageand pre-trained models are available at https://github.com/Liu-Tianchi/Nes2Net.</description>
      <author>example@mail.com (Tianchi Liu, Duc-Tuan Truong, Rohan Kumar Das, Kong Aik Lee, Haizhou Li)</author>
      <guid isPermaLink="false">2504.05657v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>iEBAKER: Improved Remote Sensing Image-Text Retrieval Framework via Eliminate Before Align and Keyword Explicit Reasoning</title>
      <link>http://arxiv.org/abs/2504.05644v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为iEBAKER的RSITR方法，用于遥感图像-文本检索，通过改进消除和排序策略来优化检索效果。&lt;h4&gt;背景&lt;/h4&gt;遥感图像-文本检索是一个基于查询搜索对应目标的研究领域，其中基于基础模型的方法如CLIP已取得一定成果，但现有方法存在忽略弱相关样本对和未能充分考虑遥感文本差异的问题。&lt;h4&gt;目的&lt;/h4&gt;提出iEBAKER方法，旨在解决现有遥感图像-文本检索方法中存在的不足，实现更精准的检索。&lt;h4&gt;方法&lt;/h4&gt;iEBAKER方法包括以下创新点：1. 提出了一种新的消除策略EBA来过滤弱相关样本对；2. 从局部相似性和全局相似性的相互作用角度，引入了排序策略SAR；3. 集成了关键词显式推理模块KER来提高关键概念的区分度；4. 直接将FM应用于RSITR任务，无需在遥感数据上进行额外预训练。&lt;h4&gt;主要发现&lt;/h4&gt;在三个流行的基准数据集上进行的实验表明，iEBAKER方法在检索精度上超越了现有模型，且所需的训练数据更少。&lt;h4&gt;结论&lt;/h4&gt;iEBAKER方法为遥感图像-文本检索提供了一种有效的解决方案，具有更好的性能和更少的训练数据需求。&lt;h4&gt;翻译&lt;/h4&gt;Recent studies focus on the Remote Sensing Image-Text Retrieval (RSITR),which aims at searching for the corresponding targets based on the given query.Among these efforts, the application of Foundation Models (FMs), such as CLIP,to the domain of remote sensing has yielded encouraging outcomes. However,existing FM based methodologies neglect the negative impact of weaklycorrelated sample pairs and fail to account for the key distinctions amongremote sensing texts, leading to biased and superficial exploration of samplepairs. To address these challenges, we propose an approach named iEBAKER (anImproved Eliminate Before Align strategy with Keyword Explicit Reasoningframework) for RSITR. Specifically, we propose an innovative Eliminate BeforeAlign (EBA) strategy to filter out the weakly correlated sample pairs, therebymitigating their deviations from optimal embedding space duringalignment.Further, two specific schemes are introduced from the perspective ofwhether local similarity and global similarity affect each other. On thisbasis, we introduce an alternative Sort After Reversed Retrieval (SAR)strategy, aims at optimizing the similarity matrix via reverse retrieval.Additionally, we incorporate a Keyword Explicit Reasoning (KER) module tofacilitate the beneficial impact of subtle key concept distinctions. Withoutbells and whistles, our approach enables a direct transition from FM to RSITRtask, eliminating the need for additional pretraining on remote sensing data.Extensive experiments conducted on three popular benchmark datasets demonstratethat our proposed iEBAKER method surpasses the state-of-the-art models whilerequiring less training data. Our source code will be released athttps://github.com/zhangy0822/iEBAKER.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies focus on the Remote Sensing Image-Text Retrieval (RSITR),which aims at searching for the corresponding targets based on the given query.Among these efforts, the application of Foundation Models (FMs), such as CLIP,to the domain of remote sensing has yielded encouraging outcomes. However,existing FM based methodologies neglect the negative impact of weaklycorrelated sample pairs and fail to account for the key distinctions amongremote sensing texts, leading to biased and superficial exploration of samplepairs. To address these challenges, we propose an approach named iEBAKER (anImproved Eliminate Before Align strategy with Keyword Explicit Reasoningframework) for RSITR. Specifically, we propose an innovative Eliminate BeforeAlign (EBA) strategy to filter out the weakly correlated sample pairs, therebymitigating their deviations from optimal embedding space duringalignment.Further, two specific schemes are introduced from the perspective ofwhether local similarity and global similarity affect each other. On thisbasis, we introduce an alternative Sort After Reversed Retrieval (SAR)strategy, aims at optimizing the similarity matrix via reverse retrieval.Additionally, we incorporate a Keyword Explicit Reasoning (KER) module tofacilitate the beneficial impact of subtle key concept distinctions. Withoutbells and whistles, our approach enables a direct transition from FM to RSITRtask, eliminating the need for additional pretraining on remote sensing data.Extensive experiments conducted on three popular benchmark datasets demonstratethat our proposed iEBAKER method surpasses the state-of-the-art models whilerequiring less training data. Our source code will be released athttps://github.com/zhangy0822/iEBAKER.</description>
      <author>example@mail.com (Yan Zhang, Zhong Ji, Changxu Meng, Yanwei Pang, Jungong Han)</author>
      <guid isPermaLink="false">2504.05644v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Falcon: Fractional Alternating Cut with Overcoming Minima in Unsupervised Segmentation</title>
      <link>http://arxiv.org/abs/2504.05613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的无监督图像分割算法Falcon，通过改进算法结构和优化方法，在速度和准确度上显著提升，缩小了无监督和监督方法之间的差距。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督图像分割算法往往分割效果不佳，基于图割的现代方法依赖高维注意力图和递归计算，在速度和准确性上落后于监督方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种优化后的K-way Normalized Cut算法，在不依赖递归计算的情况下提高分割速度和准确性。&lt;h4&gt;方法&lt;/h4&gt;Falcon采用两阶段操作：(1) 通过扩展到分数二次变换实现快速K-way Normalized Cut，采用交替迭代过程和正则化以避免局部最优；(2) 使用互补的低级信息细化结果掩码，生成高质量的像素级分割。&lt;h4&gt;主要发现&lt;/h4&gt;Falcon在六个广泛认可的基准测试中平均提升了2.5%，在Cityscapes上最高提升了4.3%，并且与之前的图割方法相比，运行时间减少了约30%。&lt;h4&gt;结论&lt;/h4&gt;Falcon能够有效地利用基础模型注意力中的语义信息，通过高度并行的图割框架，为现实世界应用中的可扩展性和基于密集预测的视觉预训练铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;Falcon是一种基于优化的K-way Normalized Cut的无监督图像分割算法，通过改进算法结构和优化方法，在速度和准确度上显著提升，缩小了无监督和监督方法之间的差距。该算法分为两个阶段：第一阶段通过扩展到分数二次变换实现快速K-way Normalized Cut，采用交替迭代过程和正则化以避免局部最优；第二阶段使用互补的低级信息细化结果掩码，生成高质量的像素级分割。实验表明，Falcon在六个广泛认可的基准测试中平均提升了2.5%，在Cityscapes上最高提升了4.3%，并且与之前的图割方法相比，运行时间减少了约30%。这些发现表明，通过高度并行的图割框架，可以有效地利用基础模型注意力中的语义信息，为现实世界应用中的可扩展性和基于密集预测的视觉预训练铺平道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Today's unsupervised image segmentation algorithms often segmentsuboptimally. Modern graph-cut based approaches rely on high-dimensionalattention maps from Transformer-based foundation models, typically employing arelaxed Normalized Cut solved recursively via the Fiedler vector (theeigenvector of the second smallest eigenvalue). Consequently, they still lagbehind supervised methods in both mask generation speed and segmentationaccuracy. We present a regularized fractional alternating cut (Falcon), anoptimization-based K-way Normalized Cut without relying on recursiveeigenvector computations, achieving substantially improved speed and accuracy.Falcon operates in two stages: (1) a fast K-way Normalized Cut solved byextending into a fractional quadratic transformation, with an alternatingiterative procedure and regularization to avoid local minima; and (2)refinement of the resulting masks using complementary low-level information,producing high-quality pixel-level segmentations. Experiments show that Falconnot only surpasses existing state-of-the-art methods by an average of 2.5%across six widely recognized benchmarks (reaching up to 4.3\% improvement onCityscapes), but also reduces runtime by around 30% compared to priorgraph-based approaches. These findings demonstrate that the semanticinformation within foundation-model attention can be effectively harnessed by ahighly parallelizable graph cut framework. Consequently, Falcon can narrow thegap between unsupervised and supervised segmentation, enhancing scalability inreal-world applications and paving the way for dense prediction-based visionpre-training in various downstream tasks. The code is released inhttps://github.com/KordingLab/Falcon.</description>
      <author>example@mail.com (Xiao Zhang, Xiangyu Han, Xiwen Lai, Yao Sun, Pei Zhang, Konrad Kording)</author>
      <guid isPermaLink="false">2504.05613v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation</title>
      <link>http://arxiv.org/abs/2504.02438v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ViLaMP的视觉-语言模型，用于处理长视频，通过差分蒸馏技术，在保持计算效率的同时，保留了关键帧的完整信息，并简化了非关键帧的特征。&lt;h4&gt;背景&lt;/h4&gt;长视频处理对视觉-语言模型（VLMs）是一个挑战，因为处理长时间序列的计算成本很高。现有的剪枝和特征合并方法通常牺牲了关键的时间依赖性或稀释了语义信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够在处理长视频时，系统地保留任务相关的信息，同时减少冗余。&lt;h4&gt;方法&lt;/h4&gt;ViLaMP通过两个关键机制处理长视频：差分关键帧选择和差分特征合并。差分关键帧选择在帧级别保持时间上的独特性，同时最大化查询相关性；差分特征合并则在像素级别保留非关键帧中的显著特征。&lt;h4&gt;主要发现&lt;/h4&gt;ViLaMP在四个视频理解基准测试中表现出色，特别是在长视频内容上。它能够在单个NVIDIA A100 GPU上处理超长视频（高达10K帧），同时保持最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;ViLaMP通过创新的方法，在保持高计算效率的同时，实现了对长视频的高效处理，为视频理解领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-form video processing fundamentally challenges vision-language models(VLMs) due to the high computational costs of handling extended temporalsequences. Existing token pruning and feature merging methods often sacrificecritical temporal dependencies or dilute semantic information. We introducedifferential distillation, a principled approach that systematically preservestask-relevant information while suppressing redundancy. Based on thisprinciple, we develop ViLaMP, a hierarchical video-language model thatprocesses hour-long videos at ``mixed precision'' through two key mechanisms:(1) differential keyframe selection that maximizes query relevance whilemaintaining temporal distinctiveness at the frame level and (2) differentialfeature merging that preserves query-salient features in non-keyframes at thepatch level. Hence, ViLaMP retains full information in keyframes while reducingnon-keyframes to their most salient features, resembling mixed-precisiontraining. Extensive experiments demonstrate ViLaMP's superior performanceacross four video understanding benchmarks, particularly on long-form content.Notably, ViLaMP can process ultra-long videos (up to 10K frames) on a singleNVIDIA A100 GPU, achieving substantial computational efficiency whilemaintaining state-of-the-art performance.</description>
      <author>example@mail.com (Chuanqi Cheng, Jian Guan, Wei Wu, Rui Yan)</author>
      <guid isPermaLink="false">2504.02438v2</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Divergent Paths: Separating Homophilic and Heterophilic Learning for Enhanced Graph-level Representations</title>
      <link>http://arxiv.org/abs/2504.05344v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究针对在图级别任务中GCN在异质图上表现不佳的问题，提出了一种名为DivGNN的新方法，该方法通过结合内部分类卷积（IntraNet）和外部分类高通过滤图卷积（InterNet）来提高分类性能。&lt;h4&gt;背景&lt;/h4&gt;传统的GCN在显示同质性的图上表现良好，但在异质图上效果不佳，因为它们通常不能有效区分同质性和异质性组件。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的学习策略，以解决在图级别任务中GCN在处理异质性图时的不足。&lt;h4&gt;方法&lt;/h4&gt;将节点分为同质性和异质性组件，分别学习它们的内部分类和外部分类部分。使用IntraNet处理内部分类，它依赖于复杂的图预处理步骤和一个基于类别的图读取函数。InterNet使用高通滤波器放大节点差异，以增强高频成分的细节识别。&lt;h4&gt;主要发现&lt;/h4&gt;GCN在提取分类信息方面表现良好，但往往从异质性组件中捕获噪声。通过分别学习内部分类和外部分类元素，可以显著提高分类性能。&lt;h4&gt;结论&lt;/h4&gt;DivGNN方法通过结合IntraNet和InterNet，在图级别任务中的分类性能上优于传统的GNN基线。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图卷积网络（GCN）主要针对同质性图，即相似节点连接的图，但在异质图上往往表现不佳。采用不同的方法来从同质性和异质性组件中学习的策略已经在理论和实验上被广泛讨论并证明是有效的。然而，在图级别任务中，对此主题的研究仍然非常稀少。为了解决这一差距，我们的研究对具有节点类别ID的图进行了分析，将内部分类和跨分类组件分别作为同质性和异质性的体现。我们发现，虽然GCN在提取分类信息方面表现良好，但它们经常从跨分类组件中捕获噪声。因此，对于内部分类和跨分类元素采用不同的学习策略至关重要。为了减轻这个问题，我们通过结合内部分类卷积（IntraNet）和外部分类高通过滤图卷积（InterNet）来分别学习内部分类和跨分类部分。我们的IntraNet依赖于复杂的图预处理步骤和一个新的基于类别的图读取函数。对于InterNet，我们使用高通滤波器放大节点差异，增强高频成分的细节识别。所提出的方法，DivGNN，结合了IntraNet和InterNet以及门控机制，在图级别任务中的分类性能上显著提高，超越了传统GNN基线的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Convolutional Networks (GCNs) are predominantly tailored for graphsdisplaying homophily, where similar nodes connect, but often fail onheterophilic graphs. The strategy of adopting distinct approaches to learn fromhomophilic and heterophilic components in node-level tasks has been widelydiscussed and proven effective both theoretically and experimentally. However,in graph-level tasks, research on this topic remains notably scarce. Addressingthis gap, our research conducts an analysis on graphs with nodes' category IDavailable, distinguishing intra-category and inter-category components asembodiment of homophily and heterophily, respectively. We find while GCNs excelat extracting information within categories, they frequently capture noise frominter-category components. Consequently, it is crucial to employ distinctlearning strategies for intra- and inter-category elements. To alleviate thisproblem, we separately learn the intra- and inter-category parts by acombination of an intra-category convolution (IntraNet) and an inter-categoryhigh-pass graph convolution (InterNet). Our IntraNet is supported bysophisticated graph preprocessing steps and a novel category-based graphreadout function. For the InterNet, we utilize a high-pass filter to amplifythe node disparities, enhancing the recognition of details in thehigh-frequency components. The proposed approach, DivGNN, combines the IntraNetand InterNet with a gated mechanism and substantially improves classificationperformance on graph-level tasks, surpassing traditional GNN baselines ineffectiveness.</description>
      <author>example@mail.com (Han Lei, Jiaxing Xu, Xia Dong, Yiping Ke)</author>
      <guid isPermaLink="false">2504.05344v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>QID: Efficient Query-Informed ViTs in Data-Scarce Regimes for OCR-free Visual Document Understanding</title>
      <link>http://arxiv.org/abs/2504.02971v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, accepted by CVPR 2025 MULA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QID的新型方法，用于优化视觉编码器在文本丰富的文档图像中识别特定查询区域，特别适用于数据稀缺的微调场景。&lt;h4&gt;背景&lt;/h4&gt;在视觉文档理解任务中，使用新数据集微调预训练的视觉-语言模型时，通常难以优化视觉编码器以识别特定查询区域。&lt;h4&gt;目的&lt;/h4&gt;提出QID方法，以解决在数据稀缺情况下，直接将查询注入模型层并修改网络架构的方法难以适应新数据集的问题。&lt;h4&gt;方法&lt;/h4&gt;QID方法引入了一个双重模块框架：一个查询感知模块，用于生成独特的查询向量以精确引导模型焦点；以及一个查询无关模块，用于捕捉标记之间的位置关系，确保鲁棒的空间理解。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，使用QID方法在多个数据集上对OCR-free VLM进行了实验，特别是在处理数据稀缺环境中的文本丰富文档时，显著提高了性能。&lt;h4&gt;结论&lt;/h4&gt;QID方法通过独立于视觉注意力块的操作，促进了查询嵌入的有针对性学习，并增强了视觉语义识别，从而在视觉文档理解任务中取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In Visual Document Understanding (VDU) tasks, fine-tuning a pre-trainedVision-Language Model (VLM) with new datasets often falls short in optimizingthe vision encoder to identify query-specific regions in text-rich documentimages. Existing methods that directly inject queries into model layers bymodifying the network architecture often struggle to adapt to new datasets withlimited annotations. To address this, we introduce QID, a novel, streamlined,architecture-preserving approach that integrates query embeddings into thevision encoder, leading to notable performance gains, particularly indata-scarce fine-tuning scenarios. Specifically, our approach introduces adual-module framework: a query-aware module that generates a unique queryvector to precisely guide the model's focus, as well as a query-agnostic modulethat captures the positional relationships among tokens, ensuring robustspatial understanding. Notably, both modules operate independently of thevision attention blocks, facilitating targeted learning of query embeddings andenhancing visual semantic identification. Experiments with OCR-free VLMs acrossmultiple datasets demonstrate significant performance improvements using ourmethod, especially in handling text-rich documents in data-scarce environments.</description>
      <author>example@mail.com (Binh M. Le, Shaoyuan Xu, Jinmiao Fu, Zhishen Huang, Moyan Li, Yanhui Guo, Hongdong Li, Sameera Ramasinghe, Bryan Wang)</author>
      <guid isPermaLink="false">2504.02971v2</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>SSLFusion: Scale &amp; Space Aligned Latent Fusion Model for Multimodal 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.05170v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为SSLFusion的新型多模态3D物体检测模型，旨在解决现有方法中存在的特征尺度和对齐问题，以及计算复杂性问题。&lt;h4&gt;背景&lt;/h4&gt;多模态3D物体检测虽然取得了进展，但存在2D图像和3D点云特征之间的尺度与空间信息失配问题。&lt;h4&gt;目的&lt;/h4&gt;提高物体检测的准确性和效率，同时减少计算复杂度。&lt;h4&gt;方法&lt;/h4&gt;SSLFusion包含尺度对齐融合策略（SAF）、3D到2D空间对齐模块（SAM）和潜在跨模态融合模块（LFM）。SAF通过跨多级聚合图像和点云的特征来缓解模态间的尺度失配；SAM通过将3D坐标信息融入2D图像特征来减少模态间的差距；LFM在不使用基于QKV的注意力操作的情况下，在潜在空间中捕捉跨模态的非局部上下文。&lt;h4&gt;主要发现&lt;/h4&gt;SSLFusion在KITTI和DENSE数据集上表现优于现有方法，3D AP相比GraphAlign方法提高了2.15%。&lt;h4&gt;结论&lt;/h4&gt;SSLFusion模型有效地提高了多模态3D物体检测的准确性，同时减少了计算复杂度。&lt;h4&gt;翻译&lt;/h4&gt;Based on the provided Chinese summary, here is the JSON formatted key-value pairs extracted from the abstract:&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal 3D object detection based on deep neural networks has indeed madesignificant progress. However, it still faces challenges due to themisalignment of scale and spatial information between features extracted from2D images and those derived from 3D point clouds. Existing methods usuallyaggregate multimodal features at a single stage. However, leveragingmulti-stage cross-modal features is crucial for detecting objects of variousscales. Therefore, these methods often struggle to integrate features acrossdifferent scales and modalities effectively, thereby restricting the accuracyof detection. Additionally, the time-consuming Query-Key-Value-based(QKV-based) cross-attention operations often utilized in existing methods aidin reasoning the location and existence of objects by capturing non-localcontexts. However, this approach tends to increase computational complexity. Toaddress these challenges, we present SSLFusion, a novel Scale &amp; Space AlignedLatent Fusion Model, consisting of a scale-aligned fusion strategy (SAF), a3D-to-2D space alignment module (SAM), and a latent cross-modal fusion module(LFM). SAF mitigates scale misalignment between modalities by aggregatingfeatures from both images and point clouds across multiple levels. SAM isdesigned to reduce the inter-modal gap between features from images and pointclouds by incorporating 3D coordinate information into 2D image features.Additionally, LFM captures cross-modal non-local contexts in the latent spacewithout utilizing the QKV-based attention operations, thus mitigatingcomputational complexity. Experiments on the KITTI and DENSE datasetsdemonstrate that our SSLFusion outperforms state-of-the-art methods. Ourapproach obtains an absolute gain of 2.15% in 3D AP, compared with thestate-of-art method GraphAlign on the moderate level of the KITTI test set.</description>
      <author>example@mail.com (Bonan Ding, Jin Xie, Jing Nie, Jiale Cao)</author>
      <guid isPermaLink="false">2504.05170v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
  <item>
      <title>Cellular Network Design for UAV Corridors via Data-driven High-dimensional Bayesian Optimization</title>
      <link>http://arxiv.org/abs/2504.05176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;通过一种新的数据驱动方法，研究无人机走廊的蜂窝网络设计，评估多种高维贝叶斯优化技术，以优化天线倾斜角度和半功率波束宽度，并通过案例研究验证方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;设计适用于无人机的蜂窝网络是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来设计适用于无人机的蜂窝网络。&lt;h4&gt;方法&lt;/h4&gt;采用数据驱动方法，评估高维贝叶斯优化技术，探索模型泛化能力，实现多目标优化。&lt;h4&gt;主要发现&lt;/h4&gt;某些方法在无人机走廊中实现了超过20dB的中值SINR增益，同时地面用户性能损失可忽略。通过迁移学习，高维贝叶斯优化可以在新场景中预测最优解。多目标优化可以平衡地面数据速率和无人机覆盖可靠性。优化无人机走廊覆盖可以提高地面用户的速率。&lt;h4&gt;结论&lt;/h4&gt;该方法通过案例研究证明了其在真实世界网络中的有效性，并识别了最佳的天线配置，在3D无人机走廊中实现超过两倍的数据速率，同时地面性能损失可忽略。&lt;h4&gt;翻译&lt;/h4&gt;我们通过一种新的数据驱动方法来解决为无人机走廊设计蜂窝网络的挑战。我们评估了多种最先进的高维贝叶斯优化（HD-BO）技术来联合优化蜂窝天线的倾斜角度和半功率波束宽度。我们发现，这些方法中的一些在无人机走廊中实现了超过20dB的中值SINR增益，同时对地面用户性能的影响可忽略不计。此外，我们探索了高维贝叶斯优化在迁移学习方面的能力，即利用先前观察到的场景源数据来预测新场景目标的最优解。我们提供了迁移学习成功的场景示例以及失败的场景示例。此外，我们证明高维贝叶斯优化可以实现多目标优化，识别了地面数据速率与无人机覆盖可靠性之间的最佳设计权衡。我们观察到，旨在在整个天空中提供无人机覆盖的目标可能会降低与专门针对无人机走廊优化的设置相比的地面用户速率。最后，我们通过一个真实世界蜂窝网络的案例研究验证了我们的方法，其中高维贝叶斯优化确定了最佳且非显而易见的天线配置，这些配置在3D无人机走廊中实现了超过两倍的数据速率，同时地面性能损失可忽略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We address the challenge of designing cellular networks for uncrewed aerialvehicles (UAVs) corridors through a novel data-driven approach. We assessmultiple state-of-the-art high-dimensional Bayesian optimization (HD-BO)techniques to jointly optimize the cell antenna tilts and half-power beamwidth(HPBW). We find that some of these approaches achieve over 20dB gains in medianSINR along UAV corridors, with negligible degradation to ground userperformance. Furthermore, we explore the HD-BO's capabilities in terms of modelgeneralization via transfer learning, where data from a previously observedscenario source is leveraged to predict the optimal solution for a new scenariotarget. We provide examples of scenarios where such transfer learning issuccessful and others where it fails. Moreover, we demonstrate that HD-BOenables multi-objective optimization, identifying optimal design trade-offsbetween data rates on the ground versus UAV coverage reliability. We observethat aiming to provide UAV coverage across the entire sky can lower the ratesfor ground users compared to setups specifically optimized for UAV corridors.Finally, we validate our approach through a case study in a real-world cellularnetwork, where HD-BO identifies optimal and non-obvious antenna configurationsthat result in more than double the rates along 3D UAV corridors withnegligible ground performance loss.</description>
      <author>example@mail.com (Mohamed Benzaghta, Giovanni Geraci, David López-Pérez, Alvaro Valcarce)</author>
      <guid isPermaLink="false">2504.05176v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models</title>
      <link>http://arxiv.org/abs/2504.05258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TISER，一个增强大型语言模型（LLMs）时间推理能力的框架，通过结合时间线构建和迭代自我反思的多阶段过程，提高模型在时间推理任务上的表现。&lt;h4&gt;背景&lt;/h4&gt;LLMs在生成连贯文本、理解上下文和执行推理任务方面表现出色，但在处理时间相关信息，如事件序列、持续时间和时间关系方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出TISER框架，旨在提升LLMs在时间推理方面的能力。&lt;h4&gt;方法&lt;/h4&gt;TISER通过时间线构建与迭代自我反思相结合的多阶段过程来增强时间推理能力，并利用测试时间缩放扩展推理轨迹的长度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，TISER在多个基准测试中表现出最先进的性能，包括分布外测试集，并显示TISER使小型开源模型在具有挑战性的时间推理任务上超越了大型封闭权重模型。&lt;h4&gt;结论&lt;/h4&gt;TISER框架有效提升了LLMs的时间推理能力，为时间相关的应用提供了更准确和可追溯的推理过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have emerged as powerful tools for generatingcoherent text, understanding context, and performing reasoning tasks. However,they struggle with temporal reasoning, which requires processing time-relatedinformation such as event sequencing, durations, and inter-temporalrelationships. These capabilities are critical for applications includingquestion answering, scheduling, and historical analysis. In this paper, weintroduce TISER, a novel framework that enhances the temporal reasoningabilities of LLMs through a multi-stage process that combines timelineconstruction with iterative self-reflection. Our approach leverages test-timescaling to extend the length of reasoning traces, enabling models to capturecomplex temporal dependencies more effectively. This strategy not only boostsreasoning accuracy but also improves the traceability of the inference process.Experimental results demonstrate state-of-the-art performance across multiplebenchmarks, including out-of-distribution test sets, and reveal that TISERenables smaller open-source models to surpass larger closed-weight models onchallenging temporal reasoning tasks.</description>
      <author>example@mail.com (Adrián Bazaga, Rexhina Blloshmi, Bill Byrne, Adrià de Gispert)</author>
      <guid isPermaLink="false">2504.05258v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>PanoDreamer: Consistent Text to 360-Degree Scene Generation</title>
      <link>http://arxiv.org/abs/2504.05152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025 Workshop on Computer Vision for Metaverse&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为PanoDreamer的新框架，用于从文本描述或参考图像生成高质量、几何一致的3D场景。&lt;h4&gt;背景&lt;/h4&gt;当前方法在生成高质量纹理和一致的3D结构方面存在挑战，尤其是在超出参考图像视场范围的情况下。&lt;h4&gt;目的&lt;/h4&gt;解决当前方法在生成3D场景时存在的低质量纹理和结构不一致的问题。&lt;h4&gt;方法&lt;/h4&gt;PanoDreamer框架利用大型语言模型和变形优化流程，首先生成一组初始图像，然后将这些图像合成成360度全景图。接着，将全景图转换为3D点云，并使用多种方法生成与初始点云一致的额外图像，以扩展或细化点云。最后，利用3D高斯分层技术创建最终的3D场景。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，PanoDreamer在生成高质量、几何一致的3D场景方面是有效的。&lt;h4&gt;结论&lt;/h4&gt;PanoDreamer是一种有效的框架，能够生成高质量的3D场景，适用于虚拟现实和游戏等领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatically generating a complete 3D scene from a text description, areference image, or both has significant applications in fields like virtualreality and gaming. However, current methods often generate low-qualitytextures and inconsistent 3D structures. This is especially true whenextrapolating significantly beyond the field of view of the reference image. Toaddress these challenges, we propose PanoDreamer, a novel framework forconsistent, 3D scene generation with flexible text and image control. Ourapproach employs a large language model and a warp-refine pipeline, firstgenerating an initial set of images and then compositing them into a 360-degreepanorama. This panorama is then lifted into 3D to form an initial point cloud.We then use several approaches to generate additional images, from differentviewpoints, that are consistent with the initial point cloud and expand/refinethe initial point cloud. Given the resulting set of images, we utilize 3DGaussian Splatting to create the final 3D scene, which can then be renderedfrom different viewpoints. Experiments demonstrate the effectiveness ofPanoDreamer in generating high-quality, geometrically consistent 3D scenes.</description>
      <author>example@mail.com (Zhexiao Xiong, Zhang Chen, Zhong Li, Yi Xu, Nathan Jacobs)</author>
      <guid isPermaLink="false">2504.05152v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood Modeling</title>
      <link>http://arxiv.org/abs/2504.05216v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于大型语言模型（LLM）的密集检索模型LLM-QL，通过查询似然（QL）最大化来提升检索性能。&lt;h4&gt;背景&lt;/h4&gt;密集检索是信息检索的关键任务，LLM在语义理解方面表现出色，但在建模全局信息上存在不足。&lt;h4&gt;目的&lt;/h4&gt;充分利用LLM的生成能力，通过QL最大化来提升密集检索性能。&lt;h4&gt;方法&lt;/h4&gt;LLM-QL模型包括两个主要组件：注意力停止（AS）和输入干扰（IC）。AS在建模QL时停止对前一个token的注意力，直到文档结束。IC在预测过程中对输入文档中的部分token进行掩码。&lt;h4&gt;主要发现&lt;/h4&gt;在MSMARCO数据集上的实验表明，LLM-QL的检索性能显著优于其他基于LLM的检索器，且使用LLM-QL估计的QL进行排名的性能远超基于词的QL。&lt;h4&gt;结论&lt;/h4&gt;LLM-QL模型能够有效提升密集检索的性能，为下游任务如重排序提供了更好的基础。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Dense retrieval is a crucial task in Information Retrieval (IR) and is the foundation for downstream tasks such as re-ranking. Recently, large language models (LLMs) have shown compelling semantic understanding capabilities and are appealing to researchers studying dense retrieval. LLMs, as decoder-style generative models, are competent at language generation while falling short on modeling global information due to the lack of attention to tokens afterward. Inspired by the classical word-based language modeling approach for IR, i.e., the query likelihood (QL) model, we seek to sufficiently utilize LLMs' generative ability by QL maximization. However, instead of ranking documents with QL estimation, we introduce an auxiliary task of QL maximization to yield a better backbone for contrastively learning a discriminative retriever. We name our model as LLM-QL. To condense global document semantics to a single vector during QL modeling, LLM-QL has two major components, Attention Stop (AS) and Input Corruption (IC). AS stops the attention of predictive tokens to previous tokens until the ending token of the document. IC masks a portion of tokens in the input documents during prediction. Experiments on MSMARCO show that LLM-QL can achieve significantly better performance than other LLM-based retrievers and using QL estimated by LLM-QL for ranking outperforms word-based QL by a large margin.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dense retrieval is a crucial task in Information Retrieval (IR) and is thefoundation for downstream tasks such as re-ranking. Recently, large languagemodels (LLMs) have shown compelling semantic understanding capabilities and areappealing to researchers studying dense retrieval. LLMs, as decoder-stylegenerative models, are competent at language generation while falling short onmodeling global information due to the lack of attention to tokens afterward.Inspired by the classical word-based language modeling approach for IR, i.e.,the query likelihood (QL) model, we seek to sufficiently utilize LLMs'generative ability by QL maximization. However, instead of ranking documentswith QL estimation, we introduce an auxiliary task of QL maximization to yielda better backbone for contrastively learning a discriminative retriever. Wename our model as LLM-QL. To condense global document semantics to a singlevector during QL modeling, LLM-QL has two major components, Attention Stop (AS)and Input Corruption (IC). AS stops the attention of predictive tokens toprevious tokens until the ending token of the document. IC masks a portion oftokens in the input documents during prediction. Experiments on MSMARCO showthat LLM-QL can achieve significantly better performance than other LLM-basedretrievers and using QL estimated by LLM-QL for ranking outperforms word-basedQL by a large margin.</description>
      <author>example@mail.com (Hengran Zhang, Keping Bi, Jiafeng Guo, Xiaojie Sun, Shihao Liu, Daiting Shi, Dawei Yin, Xueqi Cheng)</author>
      <guid isPermaLink="false">2504.05216v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Sparse Optimization for Transfer Learning: A L0-Regularized Framework for Multi-Source Domain Adaptation</title>
      <link>http://arxiv.org/abs/2504.04812v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了异构多源环境中的迁移学习，针对目标域和辅助域之间的分布差异，提出了一种基于L0正则化的稀疏优化迁移学习（SOTL）框架。&lt;h4&gt;背景&lt;/h4&gt;在异构多源环境中，目标域和辅助域之间存在分布差异，这给迁移学习带来了统计偏差和计算效率的挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决统计偏差和计算效率的问题，提出了SOTL框架。&lt;h4&gt;方法&lt;/h4&gt;SOTL框架通过以下两个关键创新扩展了联合估计迁移（JETS）范式：(1) 参数空间压缩和复杂性降低的L0约束精确稀疏性；(2) 优化重点的细化，强调目标参数而非冗余参数。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，SOTL在估计精度和计算速度方面都有显著提升，尤其是在对抗性辅助域条件下。在社区和犯罪基准上的实证验证表明，SOTL方法在跨域迁移中具有统计鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;SOTL方法在异构多源环境中的迁移学习方面具有显著优势，能够有效提高估计精度和计算效率，且在跨域迁移中表现出良好的统计鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了异构多源环境中的迁移学习，针对目标域与辅助域之间的分布差异问题，提出了一种基于L0正则化的稀疏优化迁移学习（SOTL）框架。为了解决统计偏差和计算效率的挑战，该方法通过两个关键创新扩展了联合估计迁移（JETS）范式：一是参数空间压缩和复杂性降低的L0约束精确稀疏性；二是优化重点的细化，强调目标参数而非冗余参数。仿真结果表明，SOTL在估计精度和计算速度方面都有显著提升，尤其是在对抗性辅助域条件下。在社区和犯罪基准上的实证验证表明，SOTL方法在跨域迁移中具有统计鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores transfer learning in heterogeneous multi-sourceenvironments with distributional divergence between target and auxiliarydomains. To address challenges in statistical bias and computationalefficiency, we propose a Sparse Optimization for Transfer Learning (SOTL)framework based on L0-regularization. The method extends the Joint EstimationTransferred from Strata (JETS) paradigm with two key innovations: (1)L0-constrained exact sparsity for parameter space compression and complexityreduction, and (2) refining optimization focus to emphasize target parametersover redundant ones. Simulations show that SOTL significantly improves bothestimation accuracy and computational speed, especially under adversarialauxiliary domain conditions. Empirical validation on the Community and Crimebenchmarks demonstrates the statistical robustness of the SOTL method incross-domain transfer.</description>
      <author>example@mail.com (Chenqi Gong, Hu Yang)</author>
      <guid isPermaLink="false">2504.04812v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>InstructionBench: An Instructional Video Understanding Benchmark</title>
      <link>http://arxiv.org/abs/2504.05040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了InstructionBench，一个用于评估视频理解能力的基准，并评估了最新视频大语言模型（Video-LLMs）的表现。&lt;h4&gt;背景&lt;/h4&gt;尽管视频大语言模型（Video-LLMs）取得了进展，但对指导性视频理解的深入研究仍然不足。&lt;h4&gt;目的&lt;/h4&gt;提出InstructionBench基准，以挑战模型在具有严格步骤流程的指导性视频中的高级时间推理能力。&lt;h4&gt;方法&lt;/h4&gt;使用GPT-4生成开放式和多项选择题对的Q&amp;A对，评估粗粒度事件级和细粒度物体级推理。过滤策略排除了仅凭常识知识即可回答的问题，侧重于视觉感知和分析来评估Video-LLM模型。基准包含超过700个视频中的5k个问题。&lt;h4&gt;主要发现&lt;/h4&gt;在InstructionBench上评估的最新Video-LLMs中，闭源模型优于开源模型。然而，即使表现最好的模型GPT-4o，准确率也只有53.42%，表明在时间推理方面存在显著差距。&lt;h4&gt;结论&lt;/h4&gt;为了推进该领域的发展，还开发了一个包含超过19k个Q&amp;A对的综合指导性视频数据集，该数据集来自近2.5k个视频，并使用自动数据生成框架，从而丰富了社区的研究资源。&lt;h4&gt;翻译&lt;/h4&gt;尽管在视频大型语言模型（Video-LLMs）方面取得了进展，但对指导性视频理解的研究仍然不足。为了解决这个问题，我们引入了InstructionBench，一个用于指导性视频理解的基准，它挑战了模型在具有严格步骤流程的指导性视频中的高级时间推理能力。我们使用GPT-4来制定开放式和多项选择题对的问答对，以评估粗粒度事件级和细粒度物体级推理。我们的过滤策略排除了仅凭常识知识即可回答的问题，在评估视频大语言模型（Video-LLMs）时侧重于视觉感知和分析。该基准最终包含了700多个视频中的5k个问题。我们在InstructionBench上评估了最新的视频大语言模型（Video-LLMs），发现闭源模型优于开源模型。然而，即使是表现最好的模型GPT-4o，其准确率也只有53.42%，这表明在时间推理方面存在显著差距。为了推动该领域的发展，我们还开发了一个包含超过19k个问答对的综合指导性视频数据集，该数据集来自近2.5k个视频，并使用自动数据生成框架，从而丰富了社区的研究资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite progress in video large language models (Video-LLMs), research oninstructional video understanding, crucial for enhancing access toinstructional content, remains insufficient. To address this, we introduceInstructionBench, an Instructional video understanding Benchmark, whichchallenges models' advanced temporal reasoning within instructional videoscharacterized by their strict step-by-step flow. Employing GPT-4, we formulateQ\&amp;A pairs in open-ended and multiple-choice formats to assess bothCoarse-Grained event-level and Fine-Grained object-level reasoning. Ourfiltering strategies exclude questions answerable purely by common-senseknowledge, focusing on visual perception and analysis when evaluating Video-LLMmodels. The benchmark finally contains 5k questions across over 700 videos. Weevaluate the latest Video-LLMs on our InstructionBench, finding thatclosed-source models outperform open-source ones. However, even the best model,GPT-4o, achieves only 53.42\% accuracy, indicating significant gaps in temporalreasoning. To advance the field, we also develop a comprehensive instructionalvideo dataset with over 19k Q\&amp;A pairs from nearly 2.5k videos, using anautomated data generation framework, thereby enriching the community's researchresources.</description>
      <author>example@mail.com (Haiwan Wei, Yitian Yuan, Xiaohan Lan, Wei Ke, Lin Ma)</author>
      <guid isPermaLink="false">2504.05040v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Unifying Physics- and Data-Driven Modeling via Novel Causal Spatiotemporal Graph Neural Network for Interpretable Epidemic Forecasting</title>
      <link>http://arxiv.org/abs/2504.05140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages, 12 figures. Submitted to Expert Systems with Applications  and currently under review. This version includes minor revisions. The work  proposes a physics-informed deep learning framework integrating a novel  epidemic model with causal spatiotemporal graph neural networks for  interpretable forecasting&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为CSTGNN的新颖的因果时空图神经网络，用于精确预测流行病，以支持有效的疾病控制和预防。&lt;h4&gt;背景&lt;/h4&gt;传统模型难以估计时空变化的流行病参数，而深度学习模型则通常忽略了疾病传播动态，且在流行病学背景下缺乏可解释性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些限制，提出了一种结合空间接触SIR模型和图神经网络（GNNs）的混合框架，以捕捉流行病的时空传播。&lt;h4&gt;方法&lt;/h4&gt;使用自适应静态连接图来表示人类流动的稳定成分，并利用时间动态模型来捕捉这些模式中的波动。通过结合自适应静态连接图和时间动态图，构建了一个动态图，包含人类流动网络的全面属性。此外，引入了一个时间分解模型来处理时间依赖性，并将其与动态图卷积网络结合用于流行病预测。&lt;h4&gt;主要发现&lt;/h4&gt;使用中国省级和德国州级的数据集进行验证，结果表明该方法有效模拟了传染病的时空动态，为预测和干预策略提供了有价值的工具。此外，对学习到的参数的分析提供了对疾病传播机制的见解，增强了模型的可解释性和实用性。&lt;h4&gt;结论&lt;/h4&gt;CSTGNN模型为流行病预测和干预策略提供了一个有效的工具，并有助于理解疾病的传播机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate epidemic forecasting is crucial for effective disease control andprevention. Traditional compartmental models often struggle to estimatetemporally and spatially varying epidemiological parameters, while deeplearning models typically overlook disease transmission dynamics and lackinterpretability in the epidemiological context. To address these limitations,we propose a novel Causal Spatiotemporal Graph Neural Network (CSTGNN), ahybrid framework that integrates a Spatio-Contact SIR model with Graph NeuralNetworks (GNNs) to capture the spatiotemporal propagation of epidemics.Inter-regional human mobility exhibits continuous and smooth spatiotemporalpatterns, leading to adjacent graph structures that share underlying mobilitydynamics. To model these dynamics, we employ an adaptive static connectivitygraph to represent the stable components of human mobility and utilize atemporal dynamics model to capture fluctuations within these patterns. Byintegrating the adaptive static connectivity graph with the temporal dynamicsgraph, we construct a dynamic graph that encapsulates the comprehensiveproperties of human mobility networks. Additionally, to capture temporal trendsand variations in infectious disease spread, we introduce a temporaldecomposition model to handle temporal dependence. This model is thenintegrated with a dynamic graph convolutional network for epidemic forecasting.We validate our model using real-world datasets at the provincial level inChina and the state level in Germany. Extensive studies demonstrate that ourmethod effectively models the spatiotemporal dynamics of infectious diseases,providing a valuable tool for forecasting and intervention strategies.Furthermore, analysis of the learned parameters offers insights into diseasetransmission mechanisms, enhancing the interpretability and practicalapplicability of our model.</description>
      <author>example@mail.com (Shuai Han, Lukas Stelz, Thomas R. Sokolowski, Kai Zhou, Horst Stöcker)</author>
      <guid isPermaLink="false">2504.05140v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>MSA-UNet3+: Multi-Scale Attention UNet3+ with New Supervised Prototypical Contrastive Loss for Coronary DSA Image Segmentation</title>
      <link>http://arxiv.org/abs/2504.05184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MSA-UNet3+的冠状动脉DSA图像分割方法，以解决现有方法在低对比度、噪声、重叠结构、高类内方差和类别不平衡等问题。&lt;h4&gt;背景&lt;/h4&gt;精确分割冠状动脉DSA图像对于诊断和治疗冠状动脉疾病至关重要，但现有方法在处理这些挑战时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效分割冠状动脉DSA图像的深度学习模型，以支持临床诊断和治疗决策。&lt;h4&gt;方法&lt;/h4&gt;MSA-UNet3+结合了多尺度扩展瓶颈（MSD-Bottleneck）和上下文注意力融合模块（CAFM），同时引入了监督原型对比损失（SPCL）来减少类别不平衡和高类内方差。&lt;h4&gt;主要发现&lt;/h4&gt;在私有冠状动脉DSA数据集上的实验表明，MSA-UNet3+优于现有方法，实现了87.73%的Dice系数、87.78%的F1分数，以及显著降低的平均表面距离（ASD）和平均轮廓距离（ACD）。&lt;h4&gt;结论&lt;/h4&gt;MSA-UNet3+框架为临床医生提供了精确的血管分割，有助于准确识别冠状动脉狭窄，支持基于证据的诊断和治疗决策。&lt;h4&gt;翻译&lt;/h4&gt;摘要：冠状动脉数字减影血管造影（DSA）图像的精确分割对于诊断和治疗冠状动脉疾病至关重要。尽管基于深度学习的分割技术取得了进展，但低对比度、噪声、重叠结构、高类内方差和类别不平衡等挑战限制了精确的血管描绘。为了克服这些限制，我们提出了MSA-UNet3+：一种用于冠状动脉DSA图像分割的多尺度注意力增强UNet3+架构。该框架结合了多尺度扩展瓶颈（MSD-Bottleneck）和上下文注意力融合模块（CAFM），不仅增强了多尺度特征提取，还保留了细粒度细节，并提高了上下文理解。此外，我们提出了一种新的监督原型对比损失（SPCL），它结合了监督和原型对比学习，通过关注难以分类的背景样本来最小化类别不平衡和高类内方差。在私有冠状动脉DSA数据集上进行的实验表明，MSA-UNet3+优于现有方法，实现了87.73%的Dice系数、87.78%的F1分数，以及显著降低的平均表面距离（ASD）和平均轮廓距离（ACD）。该框架为临床医生提供了精确的血管分割，有助于准确识别冠状动脉狭窄，支持基于证据的诊断和治疗决策。代码将在以下GitHub链接发布：https://github.com/rayanmerghani/MSA-UNet3plus。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accurate segmentation of coronary Digital Subtraction Angiography (DSA)images is essential for diagnosing and treating coronary artery diseases.Despite advances in deep learning-based segmentation, challenges such as lowcontrast, noise, overlapping structures, high intra-class variance, and classimbalance limit precise vessel delineation. To overcome these limitations, wepropose the MSA-UNet3+: a Multi-Scale Attention enhanced UNet3+ architecturefor coronary DSA image segmentation. The framework combined Multi-Scale DilatedBottleneck (MSD-Bottleneck) with Contextual Attention Fusion Module (CAFM),which not only enhances multi-scale feature extraction but also preservefine-grained details, and improve contextual understanding. Furthermore, wepropose a new Supervised Prototypical Contrastive Loss (SPCL), which combinessupervised and prototypical contrastive learning to minimize class imbalanceand high intra-class variance by focusing on hard-to-classified backgroundsamples. Experiments carried out on a private coronary DSA dataset demonstratethat MSA-UNet3+ outperforms state-of-the-art methods, achieving a Dicecoefficient of 87.73%, an F1-score of 87.78%, and significantly reduced AverageSurface Distance (ASD) and Average Contour Distance (ACD). The developedframework provides clinicians with precise vessel segmentation, enablingaccurate identification of coronary stenosis and supporting informed diagnosticand therapeutic decisions. The code will be released at the following GitHubprofile link https://github.com/rayanmerghani/MSA-UNet3plus.</description>
      <author>example@mail.com (Rayan Merghani Ahmed, Adnan Iltaf, Bin Li, Shoujun Zhou)</author>
      <guid isPermaLink="false">2504.05184v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud Video Recognition</title>
      <link>http://arxiv.org/abs/2504.05075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为PvNeXt的框架，用于高效且有效地进行点云视频识别。&lt;h4&gt;背景&lt;/h4&gt;点云视频感知是3D视觉领域的关键任务，现有的4D表示学习技术通常涉及迭代处理和密集查询操作，导致计算冗余。&lt;h4&gt;目的&lt;/h4&gt;开发一个框架，通过个性化单次查询操作来实现点云视频的有效且高效识别。&lt;h4&gt;方法&lt;/h4&gt;PvNeXt包括两个关键模块：运动模仿器和单步运动编码器。运动模仿器用于捕获点云序列中的时间动态，生成与每帧对应的虚拟运动。单步运动编码器执行单步查询操作，将每帧的点云与其对应的虚拟运动帧关联，从而从点云序列中提取运动线索并捕捉整个序列的时间动态。&lt;h4&gt;主要发现&lt;/h4&gt;通过这两个模块的集成，PvNeXt实现了对每帧的个性化单次查询，有效消除了帧特定的循环和密集查询过程的需求。&lt;h4&gt;结论&lt;/h4&gt;在多个基准测试上的大量实验证明了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Point cloud video perception has become an essential task for the realm of 3Dvision. Current 4D representation learning techniques typically engage initerative processing coupled with dense query operations. Although effective incapturing temporal features, this approach leads to substantial computationalredundancy. In this work, we propose a framework, named as PvNeXt, foreffective yet efficient point cloud video recognition, via personalizedone-shot query operation. Specially, PvNeXt consists of two key modules, theMotion Imitator and the Single-Step Motion Encoder. The former module, theMotion Imitator, is designed to capture the temporal dynamics inherent insequences of point clouds, thus generating the virtual motion corresponding toeach frame. The Single-Step Motion Encoder performs a one-step query operation,associating point cloud of each frame with its corresponding virtual motionframe, thereby extracting motion cues from point cloud sequences and capturingtemporal dynamics across the entire sequence. Through the integration of thesetwo modules, {PvNeXt} enables personalized one-shot queries for each frame,effectively eliminating the need for frame-specific looping and intensive queryprocesses. Extensive experiments on multiple benchmarks demonstrate theeffectiveness of our method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud video perception has become an essential task for the realm of 3Dvision. Current 4D representation learning techniques typically engage initerative processing coupled with dense query operations. Although effective incapturing temporal features, this approach leads to substantial computationalredundancy. In this work, we propose a framework, named as PvNeXt, foreffective yet efficient point cloud video recognition, via personalizedone-shot query operation. Specially, PvNeXt consists of two key modules, theMotion Imitator and the Single-Step Motion Encoder. The former module, theMotion Imitator, is designed to capture the temporal dynamics inherent insequences of point clouds, thus generating the virtual motion corresponding toeach frame. The Single-Step Motion Encoder performs a one-step query operation,associating point cloud of each frame with its corresponding virtual motionframe, thereby extracting motion cues from point cloud sequences and capturingtemporal dynamics across the entire sequence. Through the integration of thesetwo modules, {PvNeXt} enables personalized one-shot queries for each frame,effectively eliminating the need for frame-specific looping and intensive queryprocesses. Extensive experiments on multiple benchmarks demonstrate theeffectiveness of our method.</description>
      <author>example@mail.com (Jie Wang, Tingfa Xu, Lihe Ding, Xinjie Zhang, Long Bai, Jianan Li)</author>
      <guid isPermaLink="false">2504.05075v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Inverse++: Vision-Centric 3D Semantic Occupancy Prediction Assisted with 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.04732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多任务学习的3D语义占用预测方法，用于自动驾驶汽车通过车载全景摄像头预测周围环境的详细几何和语义信息。&lt;h4&gt;背景&lt;/h4&gt;现有的方法主要关注复杂内部结构模块设计以提升模型性能，例如高效的特征采样和聚合过程或中间特征表示格式。&lt;h4&gt;目的&lt;/h4&gt;通过引入额外的3D监督信号，结合额外的3D目标检测辅助分支，增强模型对场景中小型动态物体的捕捉能力，特别是对易受伤害的道路使用者（VRU）的检测，以确保自动驾驶汽车的安全性。&lt;h4&gt;方法&lt;/h4&gt;在nuScenes数据集上进行了广泛的实验，包括具有挑战性的雨天和夜间场景，展示了该方法达到最先进的性能，实现了31.73%的IoU分数和20.91%的mIoU分数，并在检测易受伤害的道路使用者方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;该方法通过引入额外的3D监督信号显著提升了模型性能，尤其在检测易受伤害的道路使用者方面表现出色。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is about a 3D semantic occupancy prediction method based on multitask learning, which aims to forecast detailed geometric and semantic information of the surrounding environment for autonomous vehicles (AVs) using onboard surround-view cameras. Existing methods mainly focus on complex internal structure module designs to improve model performance, such as efficient feature sampling and aggregation processes or intermediate feature representation formats. In this paper, we explore multitask learning by introducing an additional 3D supervision signal by incorporating an additional 3D object detection auxiliary branch. This extra 3D supervision signal enhances the model's overall performance by strengthening the capability of the intermediate features to capture small dynamic objects in the scene, and these small dynamic objects often include vulnerable road users, i.e. bicycles, motorcycles, and pedestrians, whose detection is crucial for ensuring driving safety in autonomous vehicles. Extensive experiments conducted on the nuScenes datasets, including challenging rainy and nighttime scenarios, showcase that our approach achieves state-of-the-art results, achieving an IoU score of 31.73% and a mIoU score of 20.91% and excels at detecting vulnerable road users (VRU). The code will be made available at: https://github.com/DanielMing123/Inverse++&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D semantic occupancy prediction aims to forecast detailed geometric andsemantic information of the surrounding environment for autonomous vehicles(AVs) using onboard surround-view cameras. Existing methods primarily focus onintricate inner structure module designs to improve model performance, such asefficient feature sampling and aggregation processes or intermediate featurerepresentation formats. In this paper, we explore multitask learning byintroducing an additional 3D supervision signal by incorporating an additional3D object detection auxiliary branch. This extra 3D supervision signal enhancesthe model's overall performance by strengthening the capability of theintermediate features to capture small dynamic objects in the scene, and thesesmall dynamic objects often include vulnerable road users, i.e. bicycles,motorcycles, and pedestrians, whose detection is crucial for ensuring drivingsafety in autonomous vehicles. Extensive experiments conducted on the nuScenesdatasets, including challenging rainy and nighttime scenarios, showcase thatour approach attains state-of-the-art results, achieving an IoU score of 31.73%and a mIoU score of 20.91% and excels at detecting vulnerable road users (VRU).The code will be made available at:https://github.com/DanielMing123/Inverse++</description>
      <author>example@mail.com (Zhenxing Ming, Julie Stephany Berrio, Mao Shan, Stewart Worrall)</author>
      <guid isPermaLink="false">2504.04732v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>TC-MGC: Text-Conditioned Multi-Grained Contrastive Learning for Text-Video Retrieval</title>
      <link>http://arxiv.org/abs/2504.04707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为TC-MGC的文本条件多粒度对比学习框架，用于文本-视频检索，并在多个基准测试中取得了有竞争力的结果。&lt;h4&gt;背景&lt;/h4&gt;多粒度对比学习方法在文本-视频检索中取得了成功，但视频的语义范围较广，可能导致文本无关的视频表示包含误导性信息。&lt;h4&gt;目的&lt;/h4&gt;提出TC-MGC框架，以解决文本-视频检索中模态语义对应关系捕捉不准确的问题。&lt;h4&gt;方法&lt;/h4&gt;TC-MGC模型采用语言-视频注意力块生成基于帧和文本注意力权重的聚合帧和视频表示。设计相似性重组模块以识别注意力相似性并重新组织跨模态相似性向量和矩阵。引入辅助相似性去相关正则化损失以最小化匹配文本-视频对的相似性方差，促进相似性方差最小化下的合作关系利用。最后，使用线性软最大化聚合模块来明确鼓励多个相似性之间的交互并促进多粒度信息的利用。&lt;h4&gt;主要发现&lt;/h4&gt;TC-MGC在多个文本-视频检索基准测试中取得了有竞争力的结果，在MSR-VTT、DiDeMo和VATEX上分别相对于X-CLIP模型在文本到视频检索R@1上实现了+2.8%（+1.3%）、+2.2%（+1.0%）和+1.5%（+0.9%）的相对（绝对）改进。&lt;h4&gt;结论&lt;/h4&gt;TC-MGC框架有效地解决了文本-视频检索中的模态语义对应关系捕捉问题，并在多个基准测试中取得了优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by the success of coarse-grained or fine-grained contrast intext-video retrieval, there emerge multi-grained contrastive learning methodswhich focus on the integration of contrasts with different granularity.However, due to the wider semantic range of videos, the text-agnostic videorepresentations might encode misleading information not described in texts,thus impeding the model from capturing precise cross-modal semanticcorrespondence. To this end, we propose a Text-Conditioned Multi-GrainedContrast framework, dubbed TC-MGC. Specifically, our model employs alanguage-video attention block to generate aggregated frame and videorepresentations conditioned on the word's and text's attention weights overframes. To filter unnecessary similarity interactions and decrease trainableparameters in the Interactive Similarity Aggregation (ISA) module, we design aSimilarity Reorganization (SR) module to identify attentive similarities andreorganize cross-modal similarity vectors and matrices. Next, we argue that theimbalance problem among multigrained similarities may result in over- andunder-representation issues. We thereby introduce an auxiliary SimilarityDecorrelation Regularization (SDR) loss to facilitate cooperative relationshiputilization by similarity variance minimization on matching text-video pairs.Finally, we present a Linear Softmax Aggregation (LSA) module to explicitlyencourage the interactions between multiple similarities and promote the usageof multi-grained information. Empirically, TC-MGC achieves competitive resultson multiple text-video retrieval benchmarks, outperforming X-CLIP model by+2.8% (+1.3%), +2.2% (+1.0%), +1.5% (+0.9%) relative (absolute) improvements intext-to-video retrieval R@1 on MSR-VTT, DiDeMo and VATEX, respectively. Ourcode is publicly available at https://github.com/JingXiaolun/TC-MGC.</description>
      <author>example@mail.com (Xiaolun Jing, Genke Yang, Jian Chu)</author>
      <guid isPermaLink="false">2504.04707v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>RS-RAG: Bridging Remote Sensing Imagery and Comprehensive Knowledge with a Multi-Modal Dataset and Retrieval-Augmented Generation Model</title>
      <link>http://arxiv.org/abs/2504.04988v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了在遥感视觉-语言任务中，如何利用视觉语言模型（VLMs）来增强语义推理能力，特别是在复杂或依赖特定领域知识的问题上。&lt;h4&gt;背景&lt;/h4&gt;VLMs在自然图像领域展现出强大的能力，遥感社区开始尝试将其应用于遥感视觉-语言任务，如场景理解、图像描述和视觉问答。&lt;h4&gt;目的&lt;/h4&gt;解决现有遥感VLMs缺乏外部知识集成和语义推理能力的问题。&lt;h4&gt;方法&lt;/h4&gt;引入了一个多模态遥感世界知识（RSWK）数据集，并提出了一个名为RS-RAG的新框架。该框架包括两个主要组件：多模态知识向量数据库构建模块和知识检索与响应生成模块。前者将遥感图像和相关文本知识编码到统一向量空间，后者根据图像和/或文本查询检索并重新排序相关知识，并将其纳入知识增强提示以指导VLM生成上下文相关的响应。&lt;h4&gt;主要发现&lt;/h4&gt;RS-RAG在图像描述、图像分类和视觉问答等三个代表性视觉-语言任务上，显著优于现有的最先进基线。&lt;h4&gt;结论&lt;/h4&gt;RS-RAG框架有效地提高了遥感视觉-语言任务中的语义推理能力。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent progress in VLMs has demonstrated impressive capabilities across a variety of tasks in the natural image domain. Motivated by these advancements, the remote sensing community has begun to adopt VLMs for remote sensing vision-language tasks, including scene understanding, image captioning, and visual question answering. However, existing remote sensing VLMs typically rely on closed-set scene understanding and focus on generic scene descriptions, yet lack the ability to incorporate external knowledge. This limitation hinders their capacity for semantic reasoning over complex or context-dependent queries that involve domain-specific or world knowledge. To address these challenges, we first introduced a multimodal Remote Sensing World Knowledge (RSWK) dataset, which comprises high-resolution satellite imagery and detailed textual descriptions for 14,141 well-known landmarks from 175 countries, integrating both remote sensing domain knowledge and broader world knowledge. Building upon this dataset, we proposed a novel Remote Sensing Retrieval-Augmented Generation (RS-RAG) framework, which consists of two key components. The Multi-Modal Knowledge Vector Database Construction module encodes remote sensing imagery and associated textual knowledge into a unified vector space. The Knowledge Retrieval and Response Generation module retrieves and re-ranks relevant knowledge based on image and/or text queries, and incorporates the retrieved content into a knowledge-augmented prompt to guide the VLM in producing contextually grounded responses. We validated the effectiveness of our approach on three representative vision-language tasks, including image captioning, image classification, and visual question answering, where RS-RAG significantly outperformed state-of-the-art baselines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent progress in VLMs has demonstrated impressive capabilities across avariety of tasks in the natural image domain. Motivated by these advancements,the remote sensing community has begun to adopt VLMs for remote sensingvision-language tasks, including scene understanding, image captioning, andvisual question answering. However, existing remote sensing VLMs typically relyon closed-set scene understanding and focus on generic scene descriptions, yetlack the ability to incorporate external knowledge. This limitation hinderstheir capacity for semantic reasoning over complex or context-dependent queriesthat involve domain-specific or world knowledge. To address these challenges,we first introduced a multimodal Remote Sensing World Knowledge (RSWK) dataset,which comprises high-resolution satellite imagery and detailed textualdescriptions for 14,141 well-known landmarks from 175 countries, integratingboth remote sensing domain knowledge and broader world knowledge. Building uponthis dataset, we proposed a novel Remote Sensing Retrieval-Augmented Generation(RS-RAG) framework, which consists of two key components. The Multi-ModalKnowledge Vector Database Construction module encodes remote sensing imageryand associated textual knowledge into a unified vector space. The KnowledgeRetrieval and Response Generation module retrieves and re-ranks relevantknowledge based on image and/or text queries, and incorporates the retrievedcontent into a knowledge-augmented prompt to guide the VLM in producingcontextually grounded responses. We validated the effectiveness of our approachon three representative vision-language tasks, including image captioning,image classification, and visual question answering, where RS-RAG significantlyoutperformed state-of-the-art baselines.</description>
      <author>example@mail.com (Congcong Wen, Yiting Lin, Xiaokang Qu, Nan Li, Yong Liao, Hui Lin, Xiang Li)</author>
      <guid isPermaLink="false">2504.04988v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>ADA-Net: Attention-Guided Domain Adaptation Network with Contrastive Learning for Standing Dead Tree Segmentation Using Aerial Imagery</title>
      <link>http://arxiv.org/abs/2504.04271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用空中多光谱正射影像分割立枯树木的新方法，并引入了基于域适应的领域迁移方法，以解决森林遥感中标注数据集获取困难的问题。&lt;h4&gt;背景&lt;/h4&gt;立枯树木的信息对理解森林生态系统功能和恢复力至关重要，但由于气候变化导致的大规模树木死亡事件，以及数据限制，这些问题在大型地理区域内一直缺乏研究。&lt;h4&gt;目的&lt;/h4&gt;研究目的是利用现有标注数据在目标域中预训练分割网络，然后将新的研究地点（源域X）的图像转换为目标域，通过域适应进行迁移学习。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为注意力引导的域适应网络（ADA-Net）的新方法，该方法结合了增强对比学习，旨在提供比现有方法更优的域适应性能。&lt;h4&gt;主要发现&lt;/h4&gt;使用来自芬兰和美国的两个数据集进行了评估，将美国图像转换为芬兰域，结果表明合成的USA2Finland数据集具有与芬兰域图像相似的特征。&lt;h4&gt;结论&lt;/h4&gt;ADA-Net方法提供了新的最先进的域适应性能，优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;本研究提出了一种利用空中多光谱正射影像分割立枯树木的新方法，并引入了基于域适应的领域迁移方法，旨在解决森林遥感中标注数据集获取困难的问题。通过引入注意力引导的域适应网络（ADA-Net）并使用增强对比学习，实现了优于现有方法的域适应性能。评估结果显示，将美国图像转换为芬兰域后，合成的USA2Finland数据集与芬兰域图像具有相似的特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Information on standing dead trees is important for understanding forestecosystem functioning and resilience but has been lacking over large geographicregions. Climate change has caused large-scale tree mortality events that canremain undetected due to limited data. In this study, we propose a novel methodfor segmenting standing dead trees using aerial multispectral orthoimages.Because access to annotated datasets has been a significant problem in forestremote sensing due to the need for forest expertise, we introduce a method fordomain transfer by leveraging domain adaptation to learn a transformation froma source domain X to target domain Y. In this Image-to-Image translation task,we aim to utilize available annotations in the target domain by pre-training asegmentation network. When images from a new study site without annotations areintroduced (source domain X), these images are transformed into the targetdomain. Then, transfer learning is applied by inferring the pre-trained networkon domain-adapted images. In addition to investigating the feasibility ofcurrent domain adaptation approaches for this objective, we propose a novelapproach called the Attention-guided Domain Adaptation Network (ADA-Net) withenhanced contrastive learning. Accordingly, the ADA-Net approach provides newstate-of-the-art domain adaptation performance levels outperforming existingapproaches. We have evaluated the proposed approach using two datasets fromFinland and the US. The USA images are converted to the Finland domain, and weshow that the synthetic USA2Finland dataset exhibits similar characteristics tothe Finland domain images. The software implementation is shared athttps://github.com/meteahishali/ADA-Net. The data is publicly available athttps://www.kaggle.com/datasets/meteahishali/aerial-imagery-for-standing-dead-tree-segmentation.</description>
      <author>example@mail.com (Mete Ahishali, Anis Ur Rahman, Einari Heinaro, Samuli Junttila)</author>
      <guid isPermaLink="false">2504.04271v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Dual Consistent Constraint via Disentangled Consistency and Complementarity for Multi-view Clustering</title>
      <link>http://arxiv.org/abs/2504.04676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多视角聚类框架，该框架通过解耦变分自动编码器将多视角信息分为共享信息和私有信息，从而学习到一致性和互补性信息。&lt;h4&gt;背景&lt;/h4&gt;多视角聚类可以探索多个视角的共同语义，近年来受到了越来越多的关注。然而，现有的方法主要集中在表示学习的一致性上，忽略了每个视角在表示学习中的互补性贡献。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改善多视角表示学习，以同时利用一致性和互补性信息。&lt;h4&gt;方法&lt;/h4&gt;该方法通过对比学习最大化不同视角之间的互信息来学习信息丰富且一致性的表示。随后，利用一致性推理约束显式地利用互补信息，通过使用每个视角的私有和共享信息进行重构，以及使用所有视角的共享信息进行交叉重构。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法不仅有效地提高了数据表示的质量，而且易于扩展到其他场景，尤其是在复杂的多视角场景中。&lt;h4&gt;结论&lt;/h4&gt;本文的方法在多视角聚类中表现优于基线方法，并可能首次在统一的MVC理论框架中应用双重一致性约束。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel multi-view clustering framework that utilizes disentangled variational autoencoders to separate multi-view information into shared and private, thereby learning both consistency and complementarity information. The method first learns informative and consistent representations through contrastive learning, then employs consistency inference constraints to explicitly utilize complementary information by performing within-reconstruction using private and shared information of each view, and cross-reconstruction using shared information of all views. This approach effectively improves representation quality and is extendable to other scenarios. Extensive experiments demonstrate that the proposed method outperforms baseline methods, marking the first attempt to use dual consistency constraints within a unified MVC theoretical framework.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view clustering can explore common semantics from multiple views andhas received increasing attention in recent years. However, current methodsfocus on learning consistency in representation, neglecting the contribution ofeach view's complementarity aspect in representation learning. This limit posesa significant challenge in multi-view representation learning. This paperproposes a novel multi-view clustering framework that introduces a disentangledvariational autoencoder that separates multi-view into shared and privateinformation, i.e., consistency and complementarity information. We first learninformative and consistent representations by maximizing mutual informationacross different views through contrastive learning. This process will ignorecomplementary information. Then, we employ consistency inference constraints toexplicitly utilize complementary information when attempting to seek theconsistency of shared information across all views. Specifically, we perform awithin-reconstruction using the private and shared information of each view anda cross-reconstruction using the shared information of all views. The dualconsistency constraints are not only effective in improving the representationquality of data but also easy to extend to other scenarios, especially incomplex multi-view scenes. This could be the first attempt to employ dualconsistent constraint in a unified MVC theoretical framework. During thetraining procedure, the consistency and complementarity features are jointlyoptimized. Extensive experiments show that our method outperforms baselinemethods.</description>
      <author>example@mail.com (Bo Li, Jing Yun)</author>
      <guid isPermaLink="false">2504.04676v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Egocentric Video Question Answering with Multimodal Large Language Models</title>
      <link>http://arxiv.org/abs/2504.04550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文评估了多种多模态大型语言模型在以第一人称视角的Egocentric Video Question Answering任务上的表现，并引入了新的数据集QaEgo4Dv2以减少标注噪声，最终发现经过微调的Video-LLaVa-7B和Qwen2-VL-7B-Instruct模型在OpenQA和CloseQA任务上均取得了新的性能指标。&lt;h4&gt;背景&lt;/h4&gt;Egocentric Video Question Answering需要模型处理长时序推理、第一人称视角和频繁的摄像机运动等特殊挑战。&lt;h4&gt;目的&lt;/h4&gt;系统评估不同多模态大型语言模型在Egocentric Video Question Answering任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;使用零样本和微调方法评估了GPT-4o、Gemini-1.5-Pro、Video-LLaVa-7B和Qwen2-VL-7B-Instruct等四种模型，并引入了QaEgo4Dv2数据集以减少标注噪声。&lt;h4&gt;主要发现&lt;/h4&gt;经过微调的Video-LLaVa-7B和Qwen2-VL-7B-Instruct模型在OpenQA和CloseQA任务上均超越了之前的基准，其中OpenQA提升了+2.6%的ROUGE/METEOR指标，CloseQA提升了+13%的准确率。&lt;h4&gt;结论&lt;/h4&gt;模型在空间推理和细粒度物体识别方面存在困难，这些是未来改进的关键领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要：以自我为中心的视频问答（QA）要求模型处理长时序推理、第一人称视角和如频繁摄像机运动等特殊挑战。本文系统地评估了私有和开源的多模态大型语言模型（MLLMs）在QaEgo4Dv2上的表现——这是一个由QaEgo4D衍生的以自我为中心的视频的精炼数据集。使用零样本和微调方法对四种流行的MLLMs（GPT-4o、Gemini-1.5-Pro、Video-LLaVa-7B和Qwen2-VL-7B-Instruct）进行了评估，评估场景包括OpenQA和CloseQA。我们引入QaEgo4Dv2以减轻QaEgo4D中的标注噪声，从而实现更可靠的比较。我们的结果表明，经过微调的Video-LLaVa-7B和Qwen2-VL-7B-Instruct在OpenQA和CloseQA任务上实现了新的最先进性能，分别超过了之前的基准+2.6% ROUGE/METEOR（对于OpenQA）和+13%准确率（对于CloseQA）。我们还进行了一项详尽的错误分析，表明模型在空间推理和细粒度物体识别方面存在困难，这些是未来改进的关键领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Egocentric Video Question Answering (QA) requires models to handlelong-horizon temporal reasoning, first-person perspectives, and specializedchallenges like frequent camera movement. This paper systematically evaluatesboth proprietary and open-source Multimodal Large Language Models (MLLMs) onQaEgo4Dv2 - a refined dataset of egocentric videos derived from QaEgo4D. Fourpopular MLLMs (GPT-4o, Gemini-1.5-Pro, Video-LLaVa-7B and Qwen2-VL-7B-Instruct)are assessed using zero-shot and fine-tuned approaches for both OpenQA andCloseQA settings. We introduce QaEgo4Dv2 to mitigate annotation noise inQaEgo4D, enabling more reliable comparison. Our results show that fine-tunedVideo-LLaVa-7B and Qwen2-VL-7B-Instruct achieve new state-of-the-artperformance, surpassing previous benchmarks by up to +2.6% ROUGE/METEOR (forOpenQA) and +13% accuracy (for CloseQA). We also present a thorough erroranalysis, indicating the model's difficulty in spatial reasoning andfine-grained object recognition - key areas for future improvement.</description>
      <author>example@mail.com (Alkesh Patel, Vibhav Chitalia, Yinfei Yang)</author>
      <guid isPermaLink="false">2504.04550v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>TDFANet: Encoding Sequential 4D Radar Point Clouds Using Trajectory-Guided Deformable Feature Aggregation for Place Recognition</title>
      <link>http://arxiv.org/abs/2504.05103v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures. Accepted to ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究利用4D雷达进行地点识别，针对4D雷达数据稀疏、噪声大、分辨率低的特点，提出了一种基于多模态信息的方法，通过提取和聚合时空特征，实现地点识别。&lt;h4&gt;背景&lt;/h4&gt;地点识别对于自动驾驶车辆和移动机器人实现闭环或全局定位至关重要。虽然2D相机和3D激光雷达在地点识别方面取得了进展，但4D雷达作为对恶劣天气和光照条件具有鲁棒性的传感器，其在地点识别中的应用尚待探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用4D雷达进行地点识别的方法，以应对4D雷达数据的特点带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;方法包括：(1) 从速度属性中去除动态点和估计自我速度，(2) 在精炼的点云上进行鸟瞰图（BEV）特征编码，(3) 使用自我速度计算的BEV特征图运动轨迹进行特征对齐，(4) 提取和聚合对齐后的BEV特征图的多尺度时空特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在实际环境中是可行的，并展示了其在处理动态环境中的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有效解决了4D雷达在地点识别中的挑战，为自动驾驶和移动机器人领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;地点识别对于实现自动驾驶车辆和移动机器人的闭环或全局定位至关重要。尽管在利用2D相机或3D激光雷达进行地点识别方面取得了进展，但如何使用4D雷达进行地点识别——这种传感器因其对恶劣天气和光照条件的鲁棒性而越来越受欢迎——仍需进一步研究。与激光雷达点云相比，雷达数据明显稀疏、噪声大、分辨率低，这阻碍了它们有效地表示场景，为基于4D雷达的地点识别带来了重大挑战。这项工作通过利用连续4D雷达扫描的多模态信息，有效地提取和聚合时空特征来解决这些挑战。我们的方法遵循一个原则性的流程，包括：(1) 从速度属性中去除动态点和估计自我速度，(2) 在精炼的点云上进行鸟瞰图（BEV）特征编码，(3) 使用自我速度计算的BEV特征图运动轨迹进行特征对齐，(4) 提取和聚合对齐后的BEV特征图的多尺度时空特征。实际实验结果验证了所提出方法的可行性，并展示了其在处理动态环境中的鲁棒性。源代码可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Place recognition is essential for achieving closed-loop or globalpositioning in autonomous vehicles and mobile robots. Despite recentadvancements in place recognition using 2D cameras or 3D LiDAR, it remains tobe seen how to use 4D radar for place recognition - an increasingly popularsensor for its robustness against adverse weather and lighting conditions.Compared to LiDAR point clouds, radar data are drastically sparser, noisier andin much lower resolution, which hampers their ability to effectively representscenes, posing significant challenges for 4D radar-based place recognition.This work addresses these challenges by leveraging multi-modal information fromsequential 4D radar scans and effectively extracting and aggregatingspatio-temporal features.Our approach follows a principled pipeline thatcomprises (1) dynamic points removal and ego-velocity estimation from velocityproperty, (2) bird's eye view (BEV) feature encoding on the refined pointcloud, (3) feature alignment using BEV feature map motion trajectory calculatedby ego-velocity, (4) multi-scale spatio-temporal features of the aligned BEVfeature maps are extracted and aggregated.Real-world experimental resultsvalidate the feasibility of the proposed method and demonstrate its robustnessin handling dynamic environments. Source codes are available.</description>
      <author>example@mail.com (Shouyi Lu, Guirong Zhuo, Haitao Wang, Quan Zhou, Huanyu Zhou, Renbo Huang, Minqing Huang, Lianqing Zheng, Qiang Shu)</author>
      <guid isPermaLink="false">2504.05103v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>AsyReC: A Multimodal Graph-based Framework for Spatio-Temporal Asymmetric Dyadic Relationship Classification</title>
      <link>http://arxiv.org/abs/2504.05030v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AsyReC的多模态图神经网络框架，用于解决计算模型在模拟双人对称关系时面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;双人对称关系通过重复互动形成，受到共享时空经验的影响。现有的计算方法在模拟这类关系时存在三个主要问题：未能模拟不对称关系、连续互动被离散框架采样中断、无法考虑周期性行为线索。&lt;h4&gt;目的&lt;/h4&gt;提出AsyReC框架以解决上述挑战，提高双人对称关系分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;AsyReC框架包括三项创新：节点-边双重注意力机制的图神经网络、剪辑级关系学习架构、周期性时间编码器。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公开数据集上的实验表明，AsyReC框架在双人对称关系分类方面取得了最先进的性能。消融实验验证了不对称互动建模和周期性时间编码在提高现实场景中双人对称关系分类鲁棒性中的关键作用。&lt;h4&gt;结论&lt;/h4&gt;AsyReC框架为模拟双人对称关系提供了一种有效的方法，并在实际场景中显示出良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multimodal graph neural network framework named AsyReC to address the challenges faced by existing computational methods in modeling dyadic relationships. AsyReC includes three core innovations: a triplet graph neural network with node-edge dual attention, a clip-level relationship learning architecture, and a periodic temporal encoder. Experiments on two public datasets demonstrate state-of-the-art performance, and ablation studies validate the critical role of asymmetric interaction modeling and periodic temporal encoding in improving the robustness of dyadic relationship classification in real-world scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dyadic social relationships, which refer to relationships between twoindividuals who know each other through repeated interactions (or not), areshaped by shared spatial and temporal experiences. Current computationalmethods for modeling these relationships face three major challenges: (1) thefailure to model asymmetric relationships, e.g., one individual may perceivethe other as a friend while the other perceives them as an acquaintance, (2)the disruption of continuous interactions by discrete frame sampling, whichsegments the temporal continuity of interaction in real-world scenarios, and(3) the limitation to consider periodic behavioral cues, such as rhythmicvocalizations or recurrent gestures, which are crucial for inferring theevolution of dyadic relationships. To address these challenges, we proposeAsyReC, a multimodal graph-based framework for asymmetric dyadic relationshipclassification, with three core innovations: (i) a triplet graph neural networkwith node-edge dual attention that dynamically weights multimodal cues tocapture interaction asymmetries (addressing challenge 1); (ii) a clip-levelrelationship learning architecture that preserves temporal continuity, enablingfine-grained modeling of real-world interaction dynamics (addressing challenge2); and (iii) a periodic temporal encoder that projects time indices ontosine/cosine waveforms to model recurrent behavioral patterns (addressingchallenge 3). Extensive experiments on two public datasets demonstratestate-of-the-art performance, while ablation studies validate the critical roleof asymmetric interaction modeling and periodic temporal encoding in improvingthe robustness of dyadic relationship classification in real-world scenarios.Our code is publicly available at: https://github.com/tw-repository/AsyReC.</description>
      <author>example@mail.com (Wang Tang, Fethiye Irmak Dogan, Linbo Qing, Hatice Gunes)</author>
      <guid isPermaLink="false">2504.05030v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>SAFT: Structure-aware Transformers for Textual Interaction Classification</title>
      <link>http://arxiv.org/abs/2504.04861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的架构SAFT，用于有效融合文本和结构语义，以学习交互表示。&lt;h4&gt;背景&lt;/h4&gt;文本交互网络（TINs）被广泛应用于电商网站、社交网络等领域，用于建模用户与物品之间的交互，每个交互都与文本描述相关联。文本交互分类（TIC）在检测电商中的垃圾评论、金融中的欺诈交易等方面有广泛应用。&lt;h4&gt;目的&lt;/h4&gt;解决现有TIC解决方案未能捕捉丰富的文本语义和忽视TINs的二元结构和节点异质性，导致TIC性能下降的问题。&lt;h4&gt;方法&lt;/h4&gt;SAFT通过整合语言和图模块，利用行图注意力（LGA）/门控注意力单元（GAUs）和预训练语言模型（PLMs）来建模交互级别和标记级别的信号，并通过代理标记以迭代和上下文化的方式进行耦合。此外，开发了一种有效且理论基础的编码方法，将交互相关的局部和全局拓扑信息编码到结构嵌入中。&lt;h4&gt;主要发现&lt;/h4&gt;SAFT将TINs的结构特征注入到文本交互编码中，并促进了图采样策略的设计。&lt;h4&gt;结论&lt;/h4&gt;在多个真实TIN数据集上的广泛实证评估表明，SAFT在TIC准确率方面优于最先进的基线。&lt;h4&gt;翻译&lt;/h4&gt;摘要：文本交互网络（TINs）是一种无处不在的数据结构，用于模拟电子商务网站、社交网络等场景中用户与物品之间的互动，其中每个互动都与文本描述相关联。文本交互分类（TIC）在检测电子商务中的垃圾评论、金融中的欺诈交易等方面有广泛的应用。现有的TIC解决方案要么（i）由于使用上下文无关的文本嵌入而未能捕捉丰富的文本语义，要么（ii）忽视了TINs的二元结构和节点异质性，导致TIC性能下降。在本工作中，我们提出了一种新的架构SAFT，它集成了语言和图模块，用于有效地融合交互表示中的文本和结构语义。特别是，利用行图注意力（LGA）/门控注意力单元（GAUs）和预训练语言模型（PLMs）来建模交互级和标记级信号，并通过代理标记以迭代和上下文化的方式进行耦合。此外，开发了一种有效且理论基础的编码方法，将交互相关的局部和全局拓扑信息编码到结构嵌入中。得到的嵌入不仅将TINs的结构特征注入到文本交互编码中，还有助于设计图采样策略。在多个真实TIN数据集上的广泛实证评估表明，SAFT在TIC准确率方面优于最先进的基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Textual interaction networks (TINs) are an omnipresent data structure used tomodel the interplay between users and items on e-commerce websites, socialnetworks, etc., where each interaction is associated with a text description.Classifying such textual interactions (TIC) finds extensive use in detectingspam reviews in e-commerce, fraudulent transactions in finance, and so on.Existing TIC solutions either (i) fail to capture the rich text semantics dueto the use of context-free text embeddings, and/or (ii) disregard the bipartitestructure and node heterogeneity of TINs, leading to compromised TICperformance. In this work, we propose SAFT, a new architecture that integrateslanguage- and graph-based modules for the effective fusion of textual andstructural semantics in the representation learning of interactions. Inparticular, line graph attention (LGA)/gated attention units (GAUs) andpretrained language models (PLMs) are capitalized on to model theinteraction-level and token-level signals, which are further coupled via theproxy token in an iterative and contextualized fashion. Additionally, anefficient and theoretically-grounded approach is developed to encode the localand global topology information pertaining to interactions into structuralembeddings. The resulting embeddings not only inject the structural featuresunderlying TINs into the textual interaction encoding but also facilitate thedesign of graph sampling strategies. Extensive empirical evaluations onmultiple real TIN datasets demonstrate the superiority of SAFT over thestate-of-the-art baselines in TIC accuracy.</description>
      <author>example@mail.com (Hongtao Wang, Renchi Yang, Hewen Wang, Haoran Zheng, Jianliang Xu)</author>
      <guid isPermaLink="false">2504.04861v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>GAMDTP: Dynamic Trajectory Prediction with Graph Attention Mamba Network</title>
      <link>http://arxiv.org/abs/2504.04862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GAMDTP的新型图注意力网络，用于动态轨迹预测，以提高自动驾驶系统的安全性和稳定性。&lt;h4&gt;背景&lt;/h4&gt;精确的交通参与者运动预测对于自动驾驶系统的安全性和稳定性至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的网络模型，以更高效和准确地提取特征，从而提高动态轨迹预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;GAMDTP通过GAT机制融合自注意力机制和mamba-ssm的结果，并在每个图卷积层中利用这两种方法的优点。此外，还设计了一种评分机制来评估预测质量。&lt;h4&gt;主要发现&lt;/h4&gt;GAMDTP在Argoverse数据集上实现了最先进的性能，在动态轨迹预测方面具有优越的准确性。&lt;h4&gt;结论&lt;/h4&gt;GAMDTP在动态轨迹预测方面表现出色，为自动驾驶系统的安全性和稳定性提供了有效的技术支持。&lt;h4&gt;翻译&lt;/h4&gt;Accurate motion prediction of traffic agents is crucial for the safety and stability of autonomous driving systems. In this paper, we introduce GAMDTP, a novel graph attention-based network tailored for dynamic trajectory prediction. Specifically, we fuse the result of self attention and mamba-ssm through a gat mechanism, leveraging the strengths of both to extract features more efficiently and accurately, in each graph convolution layer. GAMDTP encodes the high-definition map (HD map) data and the agents' historical trajectory coordinates and decodes the network's output to generate the final prediction results. Additionally, recent approaches predominantly focus on dynamically fusing historical forecast results and rely on two-stage frameworks including proposal and refinement. To further enhance the performance of the two-stage frameworks we also design a scoring mechanism to evaluate the prediction quality during the proposal and refinement processes. Experiments on the Argoverse dataset demonstrates that GAMDTP achieves state-of-the-art performance, achieving superior accuracy in dynamic trajectory prediction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate motion prediction of traffic agents is crucial for the safety andstability of autonomous driving systems. In this paper, we introduce GAMDTP, anovel graph attention-based network tailored for dynamic trajectory prediction.Specifically, we fuse the result of self attention and mamba-ssm through a gatemechanism, leveraging the strengths of both to extract features moreefficiently and accurately, in each graph convolution layer. GAMDTP encodes thehigh-definition map(HD map) data and the agents' historical trajectorycoordinates and decodes the network's output to generate the final predictionresults. Additionally, recent approaches predominantly focus on dynamicallyfusing historical forecast results and rely on two-stage frameworks includingproposal and refinement. To further enhance the performance of the two-stageframeworks we also design a scoring mechanism to evaluate the predictionquality during the proposal and refinement processes. Experiments on theArgoverse dataset demonstrates that GAMDTP achieves state-of-the-artperformance, achieving superior accuracy in dynamic trajectory prediction.</description>
      <author>example@mail.com (Yunxiang Liu, Hongkuo Niu, Jianlin Zhu)</author>
      <guid isPermaLink="false">2504.04862v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>ZFusion: An Effective Fuser of Camera and 4D Radar for 3D Object Perception in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.03438v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 WDFM-AD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于4D雷达和视觉融合的3D物体检测方法，名为ZFusion，以提高自动驾驶中的可靠3D物体感知。&lt;h4&gt;背景&lt;/h4&gt;尽管4D雷达在所有天气条件下具有传感能力，但其提供的点云数据比LiDAR稀疏。&lt;h4&gt;目的&lt;/h4&gt;提高自动驾驶中的3D物体检测准确性。&lt;h4&gt;方法&lt;/h4&gt;ZFusion方法融合了4D雷达和视觉模态，其核心FP-DDCA（特征金字塔-双可变形交叉注意力）融合器有效地补充了雷达信息和视觉信息。FP-DDCA融合器使用特征金字塔结构，包含Transformer块，以不同尺度交互式融合多模态特征。此外，利用了4D雷达的物理特性，采用Depth-Context-Split视图变换模块。&lt;h4&gt;主要发现&lt;/h4&gt;在VoD（Delft视角）数据集等典型交通场景中，ZFusion在感兴趣区域实现了最先进的mAP（平均精度均值），在整体区域与基线方法相比具有竞争力的mAP，表现出接近LiDAR的性能，并远超仅使用摄像头的检测方法。&lt;h4&gt;结论&lt;/h4&gt;ZFusion是一种具有竞争力的替代LiDAR的方法，特别是在成本方面具有优势。&lt;h4&gt;翻译&lt;/h4&gt;Reliable 3D object perception is essential in autonomous driving. Owing to its sensing capabilities in all weather conditions, 4D radar has recently received much attention. However, compared to LiDAR, 4D radar provides much sparser point cloud. In this paper, we propose a 3D object detection method, termed ZFusion, which fuses 4D radar and vision modality. As the core of ZFusion, our proposed FP-DDCA (Feature Pyramid-Double Deformable CrossAttention) fuser complements the (sparse) radar information and (dense) vision information, effectively. Specifically, with a feature-pyramid structure, the FP-DDCA fuser packs Transformer blocks to interactively fuse multi-modal features at different scales, thus enhancing perception accuracy. In addition, we utilize the Depth-Context-Split view transformation module due to the physical properties of 4D radar. Considering that 4D radar has a much lower cost than LiDAR, ZFusion is an attractive alternative to LiDAR-based methods. In typical traffic scenarios like the VoD (View-of-Delft) dataset, experiments show that with reasonable inference speed, ZFusion achieved the state-of-the-art mAP (mean average precision) in the region of interest, while having competitive mAP in the entire area compared to the baseline methods, which demonstrates performance close to LiDAR and greatly outperforms those camera-only methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable 3D object perception is essential in autonomous driving. Owing toits sensing capabilities in all weather conditions, 4D radar has recentlyreceived much attention. However, compared to LiDAR, 4D radar provides muchsparser point cloud. In this paper, we propose a 3D object detection method,termed ZFusion, which fuses 4D radar and vision modality. As the core ofZFusion, our proposed FP-DDCA (Feature Pyramid-Double Deformable CrossAttention) fuser complements the (sparse) radar information and (dense) visioninformation, effectively. Specifically, with a feature-pyramid structure, theFP-DDCA fuser packs Transformer blocks to interactively fuse multi-modalfeatures at different scales, thus enhancing perception accuracy. In addition,we utilize the Depth-Context-Split view transformation module due to thephysical properties of 4D radar. Considering that 4D radar has a much lowercost than LiDAR, ZFusion is an attractive alternative to LiDAR-based methods.In typical traffic scenarios like the VoD (View-of-Delft) dataset, experimentsshow that with reasonable inference speed, ZFusion achieved thestate-of-the-art mAP (mean average precision) in the region of interest, whilehaving competitive mAP in the entire area compared to the baseline methods,which demonstrates performance close to LiDAR and greatly outperforms thosecamera-only methods.</description>
      <author>example@mail.com (Sheng Yang, Tong Zhan, Shichen Qiao, Jicheng Gong, Qing Yang, Jian Wang, Yanfeng Lu)</author>
      <guid isPermaLink="false">2504.03438v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Feedback-Enhanced Hallucination-Resistant Vision-Language Model for Real-Time Scene Understanding</title>
      <link>http://arxiv.org/abs/2504.04772v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将自我意识嵌入人工智能的方法，以解决实时场景理解中的幻觉问题，提高人工智能在机器人、监控和辅助工具等领域的应用。&lt;h4&gt;背景&lt;/h4&gt;实时场景理解是人工智能的关键进步，但幻觉问题仍然是一个挑战，AI系统常常误解视觉输入，检测不存在的事物或描述从未发生的事件。&lt;h4&gt;目的&lt;/h4&gt;通过将自我意识嵌入AI，提高AI系统的可靠性，特别是在安全、自主导航等对准确性至关重要的领域。&lt;h4&gt;方法&lt;/h4&gt;该方法通过实时评估AI的初始输出，动态调整置信度阈值，并在确定度低于基准时抑制不可靠的声明。结合YOLOv5的对象检测能力和VILA1.5-3B的受控语言生成，将描述与已确认的视觉数据关联。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过动态阈值调整提高了准确性，基于证据的文本减少了幻觉，并实现了每秒18帧的实时性能。&lt;h4&gt;结论&lt;/h4&gt;与传统的相比，这种方法将幻觉减少了37%，具有快速、灵活和可靠的特点，在机器人导航、安全监控等领域表现出色，使AI感知与现实相符。&lt;h4&gt;翻译&lt;/h4&gt;摘要：实时场景理解是人工智能的关键进步，增强了机器人、监控和辅助工具。然而，幻觉仍然是一个挑战。AI系统经常误解视觉输入，检测不存在的事物或描述从未发生的事件。这些错误，远非微不足道，威胁到在安全、自主导航等对准确性至关重要的关键领域的可靠性。我们的方法通过将自我意识嵌入AI来解决这个问题。我们不是信任初始输出，而是我们的框架在实时中持续评估它们，动态调整置信度阈值。当确定性低于一个明确的基准时，它抑制不可靠的声明。结合YOLOv5的对象检测强度和VILA1.5-3B的受控语言生成，我们将描述与已确认的视觉数据关联。优点包括动态阈值调整以提高准确性，基于证据的文本以减少幻觉，以及每秒18帧的实时性能。这种反馈驱动的设计将幻觉减少了37%以上。快速、灵活、可靠，它在机器人导航、安全监控等应用中表现出色，使AI感知与现实相符。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-time scene comprehension is a key advance in artificial intelligence,enhancing robotics, surveillance, and assistive tools. However, hallucinationremains a challenge. AI systems often misinterpret visual inputs, detectingnonexistent objects or describing events that never happened. These errors, farfrom minor, threaten reliability in critical areas like security and autonomousnavigation where accuracy is essential.  Our approach tackles this by embedding self-awareness into the AI. Instead oftrusting initial outputs, our framework continuously assesses them in realtime, adjusting confidence thresholds dynamically. When certainty falls below asolid benchmark, it suppresses unreliable claims. Combining YOLOv5's objectdetection strength with VILA1.5-3B's controlled language generation, we tiedescriptions to confirmed visual data. Strengths include dynamic thresholdtuning for better accuracy, evidence-based text to reduce hallucination, andreal-time performance at 18 frames per second.  This feedback-driven design cuts hallucination by 37 percent over traditionalmethods. Fast, flexible, and reliable, it excels in applications from roboticnavigation to security monitoring, aligning AI perception with reality.</description>
      <author>example@mail.com (Zahir Alsulaimawi)</author>
      <guid isPermaLink="false">2504.04772v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Data Scaling Laws for End-to-End Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.04338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 11 figures, 4 tables, CVPR 2025 Workshop on Autonomous  Driving&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了自动驾驶系统架构，对比了传统的分解方法和端到端可微分模型，并评估了不同数据集大小对系统性能的影响。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶系统通常采用分解方法，分别处理感知、预测和规划等模块，但这可能导致信息损失和计算开销。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文评估了一种简单的端到端驾驶架构在内部驾驶数据集上的性能，并研究了训练数据集大小与模型性能之间的关系。&lt;h4&gt;方法&lt;/h4&gt;在内部驾驶数据集上，通过开放循环指标和闭环模拟评估了简单端到端驾驶架构的性能，并分析了额外训练数据对性能提升的影响。&lt;h4&gt;主要发现&lt;/h4&gt;本文发现，通过增加训练数据集大小，可以实现目标性能提升，例如提高运动预测准确性的5%。&lt;h4&gt;结论&lt;/h4&gt;本文为自动驾驶开发中的数据驱动决策提供了见解，强调了数据工程在系统性能提升中的重要性。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the architecture of autonomous vehicle systems, compares the traditional decomposed approach with the end-to-end differentiable model, and evaluates the impact of different dataset sizes on system performance. The study evaluates the performance of a simple end-to-end driving architecture on internal driving datasets ranging in size from 16 to 8192 hours using open-loop metrics and closed-loop simulations, and analyzes the impact of additional training data on performance improvement. The findings show that by increasing the size of the training dataset, a targeted performance improvement, such as a 5% increase in motion prediction accuracy, can be achieved. This study provides insights for data-driven decision-making in the development of autonomous driving and emphasizes the importance of data engineering in enhancing system performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous vehicle (AV) stacks have traditionally relied on decomposedapproaches, with separate modules handling perception, prediction, andplanning. However, this design introduces information loss during inter-modulecommunication, increases computational overhead, and can lead to compoundingerrors. To address these challenges, recent works have proposed architecturesthat integrate all components into an end-to-end differentiable model, enablingholistic system optimization. This shift emphasizes data engineering oversoftware integration, offering the potential to enhance system performance bysimply scaling up training resources. In this work, we evaluate the performanceof a simple end-to-end driving architecture on internal driving datasetsranging in size from 16 to 8192 hours with both open-loop metrics andclosed-loop simulations. Specifically, we investigate how much additionaltraining data is needed to achieve a target performance gain, e.g., a 5%improvement in motion prediction accuracy. By understanding the relationshipbetween model performance and training dataset size, we aim to provide insightsfor data-driven decision-making in autonomous driving development.</description>
      <author>example@mail.com (Alexander Naumann, Xunjiang Gu, Tolga Dimlioglu, Mariusz Bojarski, Alperen Degirmenci, Alexander Popov, Devansh Bisla, Marco Pavone, Urs Müller, Boris Ivanovic)</author>
      <guid isPermaLink="false">2504.04338v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Sub-Clustering for Class Distance Recalculation in Long-Tailed Drug Classification</title>
      <link>http://arxiv.org/abs/2504.04647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了长尾数据分布下的模型学习与分类问题，特别是在药物化学领域，提出了一种新的方法来改善长尾类别的分类性能。&lt;h4&gt;背景&lt;/h4&gt;在现实世界中，长尾数据分布普遍存在，使得模型难以有效学习并分类尾部类别。然而，在药物化学领域，某些尾部类别由于独特的分子结构特征，在训练过程中表现出更高的可识别性，这与传统理解相矛盾。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有不平衡学习方法过度依赖样本数量先验的问题，提出了一种新的方法，以改善尾部类别的分类性能，同时不损害主导类别的性能。&lt;h4&gt;方法&lt;/h4&gt;该方法打破传统的基于样本大小的静态评估范式，通过使用不同类别之间的特征距离建立动态的类间可分离性度量。具体来说，采用子聚类对比学习方法来全面学习每个类别的嵌入特征，并动态计算类别嵌入之间的距离，以捕捉不同类别样本在特征空间中的相对位置演化，从而重新平衡分类损失函数的权重。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，在药物化学领域，某些尾部类别由于独特的分子结构特征，在训练过程中表现出更高的可识别性。同时，提出的方法在不牺牲主导类别性能的情况下，显著提高了尾部类别的分类准确率。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个现有的长尾药物数据集上进行了实验，并取得了有竞争力的结果，证明了其在改善尾部类别分类性能方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;In the real world, long-tailed data distributions are prevalent, making it challenging for models to effectively learn and classify tail classes. However, we discover that in the field of drug chemistry, certain tail classes exhibit higher identifiability during training due to their unique molecular structural features, a finding that significantly contrasts with the conventional understanding that tail classes are generally difficult to identify. Existing imbalance learning methods, such as resampling and cost-sensitive reweighting, overly rely on sample quantity priors, causing models to excessively focus on tail classes at the expense of head class performance. To address this issue, we propose a novel method that breaks away from the traditional static evaluation paradigm based on sample size. Instead, we establish a dynamic inter-class separability metric using feature distances between different classes. Specifically, we employ a sub-clustering contrastive learning approach to thoroughly learn the embedding features of each class, and we dynamically compute the distances between class embeddings to capture the relative positional evolution of samples from different classes in the feature space, thereby rebalancing the weights of the classification loss function. We conducted experiments on multiple existing long-tailed drug datasets and achieved competitive results by improving the accuracy of tail classes without compromising the performance of dominant classes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the real world, long-tailed data distributions are prevalent, making itchallenging for models to effectively learn and classify tail classes. However,we discover that in the field of drug chemistry, certain tail classes exhibithigher identifiability during training due to their unique molecular structuralfeatures, a finding that significantly contrasts with the conventionalunderstanding that tail classes are generally difficult to identify. Existingimbalance learning methods, such as resampling and cost-sensitive reweighting,overly rely on sample quantity priors, causing models to excessively focus ontail classes at the expense of head class performance. To address this issue,we propose a novel method that breaks away from the traditional staticevaluation paradigm based on sample size. Instead, we establish a dynamicalinter-class separability metric using feature distances between differentclasses. Specifically, we employ a sub-clustering contrastive learning approachto thoroughly learn the embedding features of each class, and we dynamicallycompute the distances between class embeddings to capture the relativepositional evolution of samples from different classes in the feature space,thereby rebalancing the weights of the classification loss function. Weconducted experiments on multiple existing long-tailed drug datasets andachieved competitive results by improving the accuracy of tail classes withoutcompromising the performance of dominant classes.</description>
      <author>example@mail.com (Yujia Su, Xinjie Li, Lionel Z. Wang)</author>
      <guid isPermaLink="false">2504.04647v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>VideoAgent2: Enhancing the LLM-Based Agent System for Long-Form Video Understanding by Uncertainty-Aware CoT</title>
      <link>http://arxiv.org/abs/2504.04471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种专门针对长视频分析的特殊思维链（CoT）过程，以应对现有方法在处理长视频时遇到的挑战。&lt;h4&gt;背景&lt;/h4&gt;长视频理解是计算机视觉中的一个越来越重要的挑战性任务，基于代理的方法因其能够处理长序列并整合各种工具来捕获细粒度信息而受到青睐。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法仅依赖大型语言模型（LLMs）的推理能力而缺乏针对长视频场景的增强推理机制，以及对外部工具错误或噪声的脆弱性问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种带有计划调整模式的CoT过程，该过程允许LLM逐步规划和调整其信息收集策略。此外，还纳入了LLM和外部工具的启发式不确定性估计，以指导CoT过程，使LLM能够评估新收集信息的可靠性，优化其收集策略，并在综合最终答案时做出更稳健的决策。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，这种不确定性感知的CoT有效地减轻了外部工具的噪声，导致更可靠的结果。&lt;h4&gt;结论&lt;/h4&gt;实现的方法在名为VideoAgent2的系统中，该系统还包括通用上下文获取和专用工具设计等额外模块。在三个专门的长视频基准测试（及其子集）上的评估表明，VideoAgent2的平均性能比以前的基于代理的方法VideoAgent高出13.1%，并且在所有零样本方法中取得了领先性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：长视频理解已成为计算机视觉中越来越重要且具有挑战性的任务。基于代理的方法因其能够处理长序列并整合各种工具来捕获细粒度信息而越来越受欢迎。然而，现有方法仍面临几个挑战：(1)它们通常仅依赖于大型语言模型（LLMs）的推理能力，而没有针对长视频场景的专门机制来增强推理；(2)它们仍然容易受到外部工具错误或噪声的影响。为了解决这些问题，我们提出了一种专门针对长视频分析的特殊思维链（CoT）过程。我们提出的带有计划调整模式的CoT过程允许LLM逐步规划和调整其信息收集策略。我们进一步纳入了LLM和外部工具的启发式不确定性估计，以指导CoT过程。这允许LLM评估新收集信息的可靠性，优化其收集策略，并在综合最终答案时做出更稳健的决策。实证实验表明，我们的不确定性感知CoT有效地减轻了外部工具的噪声，导致更可靠的结果。我们将我们的方法实现在一个名为VideoAgent2的系统中，该系统还包括通用上下文获取和专用工具设计等额外模块。在三个专门的长视频基准测试（及其子集）上的评估表明，VideoAgent2的平均性能比以前的基于代理的方法VideoAgent高出13.1%，并且在所有零样本方法中取得了领先性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long video understanding has emerged as an increasingly important yetchallenging task in computer vision. Agent-based approaches are gainingpopularity for processing long videos, as they can handle extended sequencesand integrate various tools to capture fine-grained information. However,existing methods still face several challenges: (1) they often rely solely onthe reasoning ability of large language models (LLMs) without dedicatedmechanisms to enhance reasoning in long video scenarios; and (2) they remainvulnerable to errors or noise from external tools. To address these issues, wepropose a specialized chain-of-thought (CoT) process tailored for long videoanalysis. Our proposed CoT with plan-adjust mode enables the LLM toincrementally plan and adapt its information-gathering strategy. We furtherincorporate heuristic uncertainty estimation of both the LLM and external toolsto guide the CoT process. This allows the LLM to assess the reliability ofnewly collected information, refine its collection strategy, and make morerobust decisions when synthesizing final answers. Empirical experiments showthat our uncertainty-aware CoT effectively mitigates noise from external tools,leading to more reliable outputs. We implement our approach in a system calledVideoAgent2, which also includes additional modules such as general contextacquisition and specialized tool design. Evaluation on three dedicated longvideo benchmarks (and their subsets) demonstrates that VideoAgent2 outperformsthe previous state-of-the-art agent-based method, VideoAgent, by an average of13.1% and achieves leading performance among all zero-shot approaches</description>
      <author>example@mail.com (Zhuo Zhi, Qiangqiang Wu, Minghe shen, Wenbo Li, Yinchuan Li, Kun Shao, Kaiwen Zhou)</author>
      <guid isPermaLink="false">2504.04471v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Quantum parallel information exchange (QPIE) hybrid network with transfer learning</title>
      <link>http://arxiv.org/abs/2504.04235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了量子机器学习（QML）及其在复杂模式识别和时间序列数据预测中的应用，提出了一种新的量子并行信息交换（QPIE）混合网络架构，并通过动态梯度选择方法提高了学习效率和表示能力。&lt;h4&gt;背景&lt;/h4&gt;量子机器学习通过利用量子系统模拟和利用高维潜在空间的能力，在复杂模式识别和时间序列数据预测等领域展现出巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入新的混合网络架构和优化方法，提高量子神经网络（QNN）的学习效率和表示能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的量子并行信息交换（QPIE）混合网络，通过将经典神经网络的预训练参数输入到量子电路中，并利用非克莱因参数化量子门进行模式识别和时间序列数据预测。同时，开发了一种动态梯度选择方法，结合了量子处理单元（QPUs）上的参数偏移规则和GPU上的伴随微分。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，所提出的模型在特定基准测试中表现出更高的准确率，降低了约88%的额外随机性时间序列数据的收敛率，并在CPU/GPU和IonQ QPU模拟器上展示了更无偏的费舍尔信息矩阵特征值谱。&lt;h4&gt;结论&lt;/h4&gt;量子并行信息交换（QPIE）混合网络和动态梯度选择方法能够有效提高量子神经网络的学习效率和表示能力，为量子机器学习在复杂模式识别和时间序列数据预测中的应用提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Quantum machine learning (QML) has emerged as an innovative framework with the potential to uncover complex patterns by leveraging quantum systems ability to simulate and exploit high-dimensional latent spaces, particularly in learning tasks. Quantum neural network (QNN) frameworks are inherently sensitive to the precision of gradient calculations and the computational limitations of current quantum hardware as unitary rotations introduce overhead from complex number computations, and the quantum gate operation speed remains a bottleneck for practical implementations. In this study, we introduce quantum parallel information exchange (QPIE) hybrid network, a new non-sequential hybrid classical quantum model architecture, leveraging quantum transfer learning by feeding pre-trained parameters from classical neural networks into quantum circuits, which enables efficient pattern recognition and temporal series data prediction by utilizing non-clifford parameterized quantum gates thereby enhancing both learning efficiency and representational capacity. Additionally, we develop a dynamic gradient selection method that applies the parameter shift rule on quantum processing units (QPUs) and adjoint differentiation on GPUs. Our results demonstrate model performance exhibiting higher accuracy in ad-hoc benchmarks, lowering approximately 88% convergence rate for extra stochasticity time-series data within 100-steps, and showcasing a more unbiased eigenvalue spectrum of the fisher information matrix on CPU/GPU and IonQ QPU simulators.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum machine learning (QML) has emerged as an innovative framework withthe potential to uncover complex patterns by leveraging quantum systems abilityto simulate and exploit high-dimensional latent spaces, particularly inlearning tasks. Quantum neural network (QNN) frameworks are inherentlysensitive to the precision of gradient calculations and the computationallimitations of current quantum hardware as unitary rotations introduce overheadfrom complex number computations, and the quantum gate operation speed remainsa bottleneck for practical implementations. In this study, we introduce quantumparallel information exchange (QPIE) hybrid network, a new non-sequentialhybrid classical quantum model architecture, leveraging quantum transferlearning by feeding pre-trained parameters from classical neural networks intoquantum circuits, which enables efficient pattern recognition and temporalseries data prediction by utilizing non-clifford parameterized quantum gatesthereby enhancing both learning efficiency and representational capacity.Additionally, we develop a dynamic gradient selection method that applies theparameter shift rule on quantum processing units (QPUs) and adjointdifferentiation on GPUs. Our results demonstrate model performance exhibitinghigher accuracy in ad-hoc benchmarks, lowering approximately 88% convergencerate for extra stochasticity time-series data within 100-steps, and showcasinga more unbaised eigenvalue spectrum of the fisher information matrix on CPU/GPUand IonQ QPU simulators.</description>
      <author>example@mail.com (Ziqing Guo, Alex Khan, Victor S. Sheng, Shabnam Jabeen, Ziwen Pan)</author>
      <guid isPermaLink="false">2504.04235v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>InteractVLM: 3D Interaction Reasoning from 2D Foundational Models</title>
      <link>http://arxiv.org/abs/2504.05303v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了InteractVLM方法，通过单张真实世界图像估计人体和物体上的3D接触点，实现了准确的3D人体-物体关节重建。&lt;h4&gt;背景&lt;/h4&gt;由于遮挡、深度模糊性和物体形状的广泛变化，从单张图像中估计3D接触点是一个挑战。现有的方法依赖于昂贵的动作捕捉系统收集的3D接触标注或繁琐的手动标注，限制了可扩展性和泛化能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，能够从单张真实世界图像中估计3D接触点，从而实现准确的3D人体-物体关节重建。&lt;h4&gt;方法&lt;/h4&gt;InteractVLM利用大型视觉语言模型（VLMs）的广泛视觉知识，并通过有限的3D接触数据进行微调。为了处理3D人体-物体接触的本质三维性，引入了新的模块，包括：(1) 通过多视图渲染将3D人体和物体表面嵌入2D空间，(2) 训练一个新的多视图定位模型（MV-Loc）来推断2D接触，(3) 将这些接触点提升到3D。此外，提出了一个新的任务，即语义人体接触估计，其中人体接触预测显式地依赖于物体语义，从而允许更丰富的交互建模。&lt;h4&gt;主要发现&lt;/h4&gt;InteractVLM在接触估计方面优于现有工作，并简化了从真实世界图像中进行3D重建的过程。&lt;h4&gt;结论&lt;/h4&gt;InteractVLM是一个有效的工具，可以用于从真实世界图像中估计3D接触点，并促进3D重建。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了InteractVLM，一种从单张真实图像估计人体和物体上的3D接触点的新方法，使得在3D空间中实现准确的人体-物体联合重建成为可能。这由于遮挡、深度模糊性和物体形状的极大差异而具有挑战性。现有方法依赖于通过昂贵的行为捕捉系统收集的3D接触标注或繁琐的手动标注，限制了可扩展性和泛化能力。为了克服这一点，InteractVLM利用了大型视觉语言模型（VLMs）的广泛视觉知识，并使用有限的3D接触数据进行微调。然而，直接应用这些模型是非平凡的，因为它们只能在2D空间中推理，而人体-物体接触本质上是在3D的。因此，我们引入了一个新的渲染-定位-提升模块，它：（1）通过多视图渲染将3D人体和物体表面嵌入2D空间，（2）训练一个新的多视图定位模型（MV-Loc）来推断接触点在2D中的位置，（3）将这些接触点提升到3D。（此外，我们还提出了一个新的任务，称为语义人体接触估计，其中人体接触预测明确地基于物体语义，这允许更丰富的交互建模。）InteractVLM在接触估计方面优于现有工作，并且有助于从真实图像中进行3D重建。代码和模型可在https://interactvlm.is.tue.mpg.de上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce InteractVLM, a novel method to estimate 3D contact points onhuman bodies and objects from single in-the-wild images, enabling accuratehuman-object joint reconstruction in 3D. This is challenging due to occlusions,depth ambiguities, and widely varying object shapes. Existing methods rely on3D contact annotations collected via expensive motion-capture systems ortedious manual labeling, limiting scalability and generalization. To overcomethis, InteractVLM harnesses the broad visual knowledge of large Vision-LanguageModels (VLMs), fine-tuned with limited 3D contact data. However, directlyapplying these models is non-trivial, as they reason only in 2D, whilehuman-object contact is inherently 3D. Thus we introduce a novelRender-Localize-Lift module that: (1) embeds 3D body and object surfaces in 2Dspace via multi-view rendering, (2) trains a novel multi-view localizationmodel (MV-Loc) to infer contacts in 2D, and (3) lifts these to 3D.Additionally, we propose a new task called Semantic Human Contact estimation,where human contact predictions are conditioned explicitly on object semantics,enabling richer interaction modeling. InteractVLM outperforms existing work oncontact estimation and also facilitates 3D reconstruction from an in-the wildimage. Code and models are available at https://interactvlm.is.tue.mpg.de.</description>
      <author>example@mail.com (Sai Kumar Dwivedi, Dimitrije Antić, Shashank Tripathi, Omid Taheri, Cordelia Schmid, Michael J. Black, Dimitrios Tzionas)</author>
      <guid isPermaLink="false">2504.05303v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>LATTE: Lightweight Attention-based Traffic Accident Anticipation Engine</title>
      <link>http://arxiv.org/abs/2504.04103v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accept by Information Fusion (Elsevier)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LATTE的轻量级注意力交通事故预测引擎，它在资源受限环境中准确预测实时交通事故。LATTE结合了计算效率和最先进的表现，通过高效的多尺度空间聚合、记忆注意力聚合和辅助自我注意力聚合等技术，实现了对交通事故的准确预测。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶领域，准确预测实时交通事故是一个关键挑战，特别是在资源受限的环境中。现有的解决方案往往计算开销高或未能充分解决动态交通场景的不确定性。&lt;h4&gt;目的&lt;/h4&gt;开发一种轻量级的交通事故预测引擎，能够在资源受限的环境中提供准确的事故预测。&lt;h4&gt;方法&lt;/h4&gt;LATTE采用了高效的多尺度空间聚合（EMSA）来捕获不同尺度的空间特征，记忆注意力聚合（MAA）来增强时间建模，以及辅助自我注意力聚合（AAA）来提取长序列中的潜在依赖关系。此外，LATTE集成了Flamingo Alert-Assisted System（FAA），利用视觉语言模型提供实时、认知上可访问的口头危险警报。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集（DAD、CCD、A3D）上的评估表明，LATTE具有卓越的预测能力和计算效率。它在DAD基准上达到了89.74%的平均精度（AP），比第二好的模型平均时间到事故（mTTA）高出5.4%，在80%的召回率（TTA@R80）下保持了具有竞争力的mTTA（4.04秒），并在各种驾驶条件下展示了强大的事故预测能力。&lt;h4&gt;结论&lt;/h4&gt;LATTE通过其轻量级设计实现了93.14%的浮点运算（FLOPs）减少和31.58%的参数数量减少，能够在资源有限的硬件上实时运行而不影响性能。消融研究表明LATTE架构组件的有效性，而可视化失败案例分析突出了其实际应用性和改进领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测自动驾驶环境中的实时交通事故是一个关键挑战，特别是在资源受限的环境中。现有解决方案通常计算开销高，或者未能充分解决动态交通场景的不确定性。本文提出了一种名为LATTE的轻量级注意力交通事故预测引擎，它结合了计算效率和最先进的性能。LATTE采用高效的多尺度空间聚合（EMSA）来捕捉跨尺度的空间特征，记忆注意力聚合（MAA）来增强时间建模，以及辅助自我注意力聚合（AAA）来提取长序列中的潜在依赖关系。此外，LATTE集成了Flamingo Alert-Assisted System（FAA），利用视觉语言模型提供实时、认知上可访问的口头危险警报，提高乘客对局势的认识。在基准数据集（DAD、CCD、A3D）上的评估表明，LATTE具有卓越的预测能力和计算效率。它在DAD基准上达到了89.74%的平均精度（AP），比第二好的模型平均时间到事故（mTTA）高出5.4%，在80%的召回率（TTA@R80）下保持了具有竞争力的mTTA（4.04秒），并在各种驾驶条件下展示了强大的事故预测能力。其轻量级设计实现了93.14%的浮点运算（FLOPs）减少和31.58%的参数数量减少，能够在资源有限的硬件上实时运行而不影响性能。消融研究表明LATTE架构组件的有效性，而可视化失败案例分析突出了其实际应用性和改进领域。我们的代码可在https://github.com/icypear/LATTE.git上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting traffic accidents in real-time is a critical challengein autonomous driving, particularly in resource-constrained environments.Existing solutions often suffer from high computational overhead or fail toadequately address the uncertainty of evolving traffic scenarios. This paperintroduces LATTE, a Lightweight Attention-based Traffic Accident AnticipationEngine, which integrates computational efficiency with state-of-the-artperformance. LATTE employs Efficient Multiscale Spatial Aggregation (EMSA) tocapture spatial features across scales, Memory Attention Aggregation (MAA) toenhance temporal modeling, and Auxiliary Self-Attention Aggregation (AAA) toextract latent dependencies over extended sequences. Additionally, LATTEincorporates the Flamingo Alert-Assisted System (FAA), leveraging avision-language model to provide real-time, cognitively accessible verbalhazard alerts, improving passenger situational awareness. Evaluations onbenchmark datasets (DAD, CCD, A3D) demonstrate LATTE's superior predictivecapabilities and computational efficiency. LATTE achieves state-of-the-art89.74% Average Precision (AP) on DAD benchmark, with 5.4% higher meanTime-To-Accident (mTTA) than the second-best model, and maintains competitivemTTA at a Recall of 80% (TTA@R80) (4.04s) while demonstrating robust accidentanticipation across diverse driving conditions. Its lightweight design deliversa 93.14% reduction in floating-point operations (FLOPs) and a 31.58% decreasein parameter count (Params), enabling real-time operation on resource-limitedhardware without compromising performance. Ablation studies confirm theeffectiveness of LATTE's architectural components, while visualizations andfailure case analyses highlight its practical applicability and areas forenhancement. Our codes are available at https://github.com/icypear/LATTE.git.</description>
      <author>example@mail.com (Jiaxun Zhang, Yanchen Guan, Chengyue Wang, Haicheng Liao, Guohui Zhang, Zhenning Li)</author>
      <guid isPermaLink="false">2504.04103v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Uni4D: A Unified Self-Supervised Learning Framework for Point Cloud Videos</title>
      <link>http://arxiv.org/abs/2504.04837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于自监督的稀疏策略的点云视频表示学习，提出了首个自解耦的MAE框架，用于在预训练阶段学习判别性4D表示。&lt;h4&gt;背景&lt;/h4&gt;点云视频表示学习基于自监督的稀疏策略，但进展缓慢，存在几个显著挑战。&lt;h4&gt;目的&lt;/h4&gt;提高4D任务的预训练和微调性能。&lt;h4&gt;方法&lt;/h4&gt;1. 在潜在空间中建模运动表示。2. 引入潜在标记和典型几何标记来解耦解码过程中的高级和低级特征。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在MSR-Action3D、NTU-RGBD、HOI4D、NvGesture和SHREC'17等数据集上进行了广泛的实验，验证了其有效性。预训练模型能够提高所有4D任务的微调性能，尤其在处理长视频方面表现突出。&lt;h4&gt;结论&lt;/h4&gt;自解耦学习框架可以显著提高4D任务的微调性能，预训练模型在处理长视频时表现尤为出色。&lt;h4&gt;翻译&lt;/h4&gt;Point cloud video representation learning is primarily built upon the masking strategy in a self-supervised manner. However, the progress is slow due to several significant challenges: (1) existing methods learn the motion particularly with hand-crafted designs, leading to unsatisfactory motion patterns during pre-training which are non-transferable on fine-tuning scenarios. (2) previous Masked AutoEncoder (MAE) frameworks are limited in resolving the huge representation gap inherent in 4D data. In this study, we introduce the first self-disentangled MAE for learning discriminative 4D representations in the pre-training stage. To address the first challenge, we propose to model the motion representation in a latent space. The second issue is resolved by introducing the latent tokens along with the typical geometry tokens to disentangle high-level and low-level features during decoding. Extensive experiments on MSR-Action3D, NTU-RGBD, HOI4D, NvGesture, and SHREC'17 verify this self-disentangled learning framework. We demonstrate that it can boost the fine-tuning performance on all 4D tasks, which we term Uni4D. Our pre-trained model presents discriminative and meaningful 4D representations, particularly benefits processing long videos, as Uni4D gets +3.8% segmentation accuracy on HOI4D, significantly outperforming either self-supervised or fully-supervised methods after end-to-end fine-tuning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud video representation learning is primarily built upon the maskingstrategy in a self-supervised manner. However, the progress is slow due toseveral significant challenges: (1) existing methods learn the motionparticularly with hand-crafted designs, leading to unsatisfactory motionpatterns during pre-training which are non-transferable on fine-tuningscenarios. (2) previous Masked AutoEncoder (MAE) frameworks are limited inresolving the huge representation gap inherent in 4D data. In this study, weintroduce the first self-disentangled MAE for learning discriminative 4Drepresentations in the pre-training stage. To address the first challenge, wepropose to model the motion representation in a latent space. The second issueis resolved by introducing the latent tokens along with the typical geometrytokens to disentangle high-level and low-level features during decoding.Extensive experiments on MSR-Action3D, NTU-RGBD, HOI4D, NvGesture, and SHREC'17verify this self-disentangled learning framework. We demonstrate that it canboost the fine-tuning performance on all 4D tasks, which we term Uni4D. Ourpre-trained model presents discriminative and meaningful 4D representations,particularly benefits processing long videos, as Uni4D gets $+3.8\%$segmentation accuracy on HOI4D, significantly outperforming eitherself-supervised or fully-supervised methods after end-to-end fine-tuning.</description>
      <author>example@mail.com (Zhi Zuo, Chenyi Zhuang, Zhiqiang Shen, Pan Gao, Jie Qin)</author>
      <guid isPermaLink="false">2504.04837v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Fine tuning generative adversarial networks with universal force fields: application to two-dimensional topological insulators</title>
      <link>http://arxiv.org/abs/2504.04940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6+2 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要讨论了生成式人工智能在设计特定晶体材料方面的初步应用，提出了一种通过高级图神经网络和通用力场作为判别器来微调生成晶体结构的生成对抗网络的方法。&lt;h4&gt;背景&lt;/h4&gt;尽管生成式人工智能的应用场景迅速增长，但其在设计特定晶体材料方面的能力仍处于起步阶段。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过引入高级图神经网络和通用力场作为判别器，来微调生成晶体结构的生成对抗网络，以生成目标材料。&lt;h4&gt;方法&lt;/h4&gt;使用二维拓扑绝缘体作为目标空间示例，通过训练生成对抗网络来产生晶体结构，并通过后处理来约束输出。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，这种方法可以生成新的拓扑绝缘体，尽管大多数候选化合物中拓扑保护程度的带隙大小仍然是一个问题。&lt;h4&gt;结论&lt;/h4&gt;提出的方法可以有效地生成目标材料，为生成式人工智能在晶体材料设计中的应用提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管生成式人工智能的应用场景迅速增长，但其设计特定晶体材料的能力仍处于起步阶段。目前，逆向设计通常是通过限制训练数据集或从生成器网络产生大量样本，并通过后处理来约束输出来完成的。我们展示了通过引入高级图神经网络作为判别器，包括通用力场，来微调从潜在空间生成晶体结构的生成对抗网络的方法。这通过使用二维拓扑绝缘体作为目标空间示例来证明。尽管已经预测了许多二维拓扑绝缘体，但大多数候选化合物中拓扑保护程度的带隙大小仍然是一个问题。所得到的生成网络显示出可以产生新的拓扑绝缘体。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite rapid growth in use cases for generative artificial intelligence, itsability to design purpose built crystalline materials remains in a nascentphase. At the moment inverse design is generally accomplished by eitherconstraining the training data set or producing a vast number of samples from agenerator network and constraining the output via post-processing. We show thata general adversarial network trained to produce crystal structures from alatent space can be fine tuned through the introduction of advanced graphneural networks as discriminators, including a universal force field, tointrinsically bias the network towards generation of target materials. This isexemplified utilizing two-dimensional topological insulators as a sample targetspace. While a number of two-dimensional topological insulators have beenpredicted, the size of the band-gap, a measure of topological protection,remains a concern in most candidate compounds. The resulting generative networkis shown to yield novel topological insulators.</description>
      <author>example@mail.com (Alexander C. Tyner)</author>
      <guid isPermaLink="false">2504.04940v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Bidirectional Hierarchical Protein Multi-Modal Representation Learning</title>
      <link>http://arxiv.org/abs/2504.04770v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种多模态双向分层融合框架，用于有效融合蛋白质序列和结构信息，以改进蛋白质表示学习。&lt;h4&gt;背景&lt;/h4&gt;蛋白质表示学习对于多种生物学任务至关重要。现有的基于transformer的蛋白质语言模型和基于图神经网络的模型分别擅长处理序列和结构信息，但都存在局限性。&lt;h4&gt;目的&lt;/h4&gt;旨在通过融合序列和结构信息，提高蛋白质表示学习的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个多模态双向分层融合框架，使用注意力机制和门控机制来增强pLMs生成的序列表示和GNN提取的结构特征之间的交互。&lt;h4&gt;主要发现&lt;/h4&gt;在多个蛋白质相关任务上进行了广泛实验，方法在多个基准测试中显示出优于基线和现有融合技术的改进。&lt;h4&gt;结论&lt;/h4&gt;该方法在多模态蛋白质表示学习中达到了新的水平，强调了BIHIERARCHICAL FUSION在连接序列和结构模态方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：蛋白质表示学习对于众多生物学任务至关重要。最近，在大规模蛋白质序列上预训练的大型transformer基蛋白质语言模型（pLMs）在基于序列的任务中取得了显著的成果。然而，pLMs缺乏结构信息。相反，旨在利用3D结构信息的图神经网络（GNNs）在蛋白质相关预测任务中显示出有希望的泛化能力，但它们的有效性通常受到标记结构数据稀缺的限制。认识到序列和结构表示是同一蛋白质实体的互补视角，我们提出了一种多模态双向分层融合框架，以有效地融合这些模态。我们的框架采用注意力和门控机制，以实现pLMs生成的序列表示和GNN提取的结构特征之间的有效交互，从而提高神经网络各层之间的信息交换和增强。基于该框架，我们进一步引入了带有门控的局部双分层融合和带有多头自注意力的全局双分层融合方法。通过在一系列蛋白质相关任务上的大量实验，我们的方法在各种蛋白质表示学习基准测试中显示出对强大基线和现有融合技术的持续改进，包括反应（酶/EC分类）、模型质量评估（MQA）、蛋白质-配体结合亲和力预测（LBA）、蛋白质-蛋白质结合位点预测（PPBS）和B细胞表位预测（BCEs）。我们的方法为多模态蛋白质表示学习建立了新的基准，强调了BIHIERARCHICAL FUSION在连接序列和结构模态方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Protein representation learning is critical for numerous biological tasks.Recently, large transformer-based protein language models (pLMs) pretrained onlarge scale protein sequences have demonstrated significant success insequence-based tasks. However, pLMs lack structural information. Conversely,graph neural networks (GNNs) designed to leverage 3D structural informationhave shown promising generalization in protein-related prediction tasks, buttheir effectiveness is often constrained by the scarcity of labeled structuraldata. Recognizing that sequence and structural representations arecomplementary perspectives of the same protein entity, we propose a multimodalbidirectional hierarchical fusion framework to effectively merge thesemodalities. Our framework employs attention and gating mechanisms to enableeffective interaction between pLMs-generated sequential representations andGNN-extracted structural features, improving information exchange andenhancement across layers of the neural network. Based on the framework, wefurther introduce local Bi-Hierarchical Fusion with gating and globalBi-Hierarchical Fusion with multihead self-attention approaches. Throughextensive experiments on a diverse set of protein-related tasks, our methoddemonstrates consistent improvements over strong baselines and existing fusiontechniques in a variety of protein representation learning benchmarks,including react (enzyme/EC classification), model quality assessment (MQA),protein-ligand binding affinity prediction (LBA), protein-protein binding siteprediction (PPBS), and B cell epitopes prediction (BCEs). Our methodestablishes a new state-of-the-art for multimodal protein representationlearning, emphasizing the efficacy of BIHIERARCHICAL FUSION in bridgingsequence and structural modalities.</description>
      <author>example@mail.com (Xuefeng Liu, Songhao Jiang, Chih-chan Tien, Jinbo Xu, Rick Stevens)</author>
      <guid isPermaLink="false">2504.04770v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.04701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了DFormerv2，一种新的RGBD特征表示学习方法，该方法使用深度图作为几何先验，而不是像RGB图像那样显式地使用神经网络编码深度信息。&lt;h4&gt;背景&lt;/h4&gt;在复杂条件下（如低光和过曝），深度图对场景理解有很大的帮助，特别是提供3D几何信息。&lt;h4&gt;目的&lt;/h4&gt;研究如何从深度图中提取几何线索，并将其作为几何先验用于自注意力机制中。&lt;h4&gt;方法&lt;/h4&gt;DFormerv2通过深度图和RGB图像的特征融合，不显式地使用神经网络编码深度信息，而是将深度图作为几何先验来分配注意力权重。&lt;h4&gt;主要发现&lt;/h4&gt;DFormerv2在多种RGBD语义分割基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;深度图作为几何先验在场景理解中是有效的，DFormerv2是一种强大的RGBD编码器，能够提高语义分割的性能。&lt;h4&gt;翻译&lt;/h4&gt;近期在场景理解方面的进展在很大程度上得益于深度图提供的3D几何信息，特别是在复杂条件下（如低光和过曝）。现有的方法将深度图与RGB图像编码在一起，并执行特征融合以提高预测的鲁棒性。考虑到深度可以被视为RGB图像的几何补充，一个简单的问题出现了：我们真的需要像对RGB图像那样使用神经网络显式地编码深度信息吗？基于这一洞察，本文研究了学习RGBD特征表示的新方法，并提出了DFormerv2，一个强大的RGBD编码器，它明确地使用深度图作为几何先验，而不是使用神经网络来编码深度信息。我们的目标是提取深度图和所有图像块标记之间的空间距离中的几何线索，然后将这些线索用作几何先验来在自注意力中分配注意力权重。大量的实验表明，DFormerv2在各种RGBD语义分割基准测试中表现出卓越的性能。代码可在https://github.com/VCIP-RGBD/DFormer上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in scene understanding benefit a lot from depth maps becauseof the 3D geometry information, especially in complex conditions (e.g., lowlight and overexposed). Existing approaches encode depth maps along with RGBimages and perform feature fusion between them to enable more robustpredictions. Taking into account that depth can be regarded as a geometrysupplement for RGB images, a straightforward question arises: Do we really needto explicitly encode depth information with neural networks as done for RGBimages? Based on this insight, in this paper, we investigate a new way to learnRGBD feature representations and present DFormerv2, a strong RGBD encoder thatexplicitly uses depth maps as geometry priors rather than encoding depthinformation with neural networks. Our goal is to extract the geometry cluesfrom the depth and spatial distances among all the image patch tokens, whichwill then be used as geometry priors to allocate attention weights inself-attention. Extensive experiments demonstrate that DFormerv2 exhibitsexceptional performance in various RGBD semantic segmentation benchmarks. Codeis available at: https://github.com/VCIP-RGBD/DFormer.</description>
      <author>example@mail.com (Bo-Wen Yin, Jiao-Long Cao, Ming-Ming Cheng, Qibin Hou)</author>
      <guid isPermaLink="false">2504.04701v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>DyCON: Dynamic Uncertainty-aware Consistency and Contrastive Learning for Semi-supervised Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2504.04566v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DyCON的动态不确定性感知一致性和对比学习框架，用于解决医学图像分割中的半监督学习问题，以提高分割的准确性。&lt;h4&gt;背景&lt;/h4&gt;在医学图像分割中，半监督学习方法利用未标记数据减轻标注负担。然而，现有方法面临类别不平衡和病理变化带来的高不确定性，导致3D医学图像分割不准确。&lt;h4&gt;目的&lt;/h4&gt;提出DyCON框架，以解决类别不平衡和不确定性带来的挑战，从而提高医学图像分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;DyCON框架包含两个互补的损失函数：不确定性感知一致损失（UnCL）和焦点熵感知对比损失（FeCL）。UnCL通过动态加权每个体素对一致性损失的贡献，以保持高不确定性区域。FeCL通过引入双焦点机制和自适应置信度调整来增强不平衡区域中的局部特征区分能力。&lt;h4&gt;主要发现&lt;/h4&gt;DyCON在四个不同的医学图像分割数据集（ISLES'22、BraTS'19、LA、Pancreas）上的评估表明，与现有方法相比，DyCON具有优越的性能。&lt;h4&gt;结论&lt;/h4&gt;DyCON框架通过结合不确定性感知一致性和对比学习方法，有效地提高了医学图像分割的准确性，尤其是在类别不平衡和不确定性高的场景下。&lt;h4&gt;翻译&lt;/h4&gt;Semi-supervised learning in medical image segmentation leverages unlabeled data to reduce annotation burdens through consistency learning. However, current methods struggle with class imbalance and high uncertainty from pathology variations, leading to inaccurate segmentation in 3D medical images. To address these challenges, we present DyCON, a Dynamic Uncertainty-aware Consistency and Contrastive Learning framework that enhances the generalization of consistency methods with two complementary losses: Uncertainty-aware Consistency Loss (UnCL) and Focal Entropy-aware Contrastive Loss (FeCL). UnCL enforces global consistency by dynamically weighting the contribution of each voxel to the consistency loss based on its uncertainty, preserving high-uncertainty regions instead of filtering them out. Initially, UnCL prioritizes learning from uncertain voxels with lower penalties, encouraging the model to explore challenging regions. As training progress, the penalty shifts towards confident voxels to refine predictions and ensure global consistency. Meanwhile, FeCL enhances local feature discrimination in imbalanced regions by introducing dual focal mechanisms and adaptive confidence adjustments into the contrastive principle. These mechanisms jointly prioritize hard positives and negatives while focusing on uncertain sample pairs, effectively capturing subtle lesion variations under class imbalance. Extensive evaluations on four diverse medical image segmentation datasets (ISLES'22, BraTS'19, LA, Pancreas) show DyCON's superior performance against SOTA methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semi-supervised learning in medical image segmentation leverages unlabeleddata to reduce annotation burdens through consistency learning. However,current methods struggle with class imbalance and high uncertainty frompathology variations, leading to inaccurate segmentation in 3D medical images.To address these challenges, we present DyCON, a Dynamic Uncertainty-awareConsistency and Contrastive Learning framework that enhances the generalizationof consistency methods with two complementary losses: Uncertainty-awareConsistency Loss (UnCL) and Focal Entropy-aware Contrastive Loss (FeCL). UnCLenforces global consistency by dynamically weighting the contribution of eachvoxel to the consistency loss based on its uncertainty, preservinghigh-uncertainty regions instead of filtering them out. Initially, UnCLprioritizes learning from uncertain voxels with lower penalties, encouragingthe model to explore challenging regions. As training progress, the penaltyshift towards confident voxels to refine predictions and ensure globalconsistency. Meanwhile, FeCL enhances local feature discrimination inimbalanced regions by introducing dual focal mechanisms and adaptive confidenceadjustments into the contrastive principle. These mechanisms jointlyprioritizes hard positives and negatives while focusing on uncertain samplepairs, effectively capturing subtle lesion variations under class imbalance.Extensive evaluations on four diverse medical image segmentation datasets(ISLES'22, BraTS'19, LA, Pancreas) show DyCON's superior performance againstSOTA methods.</description>
      <author>example@mail.com (Maregu Assefa, Muzammal Naseer, Iyyakutti Iyappan Ganapathi, Syed Sadaf Ali, Mohamed L Seghier, Naoufel Werghi)</author>
      <guid isPermaLink="false">2504.04566v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Training state-of-the-art pathology foundation models with orders of magnitude less data</title>
      <link>http://arxiv.org/abs/2504.05186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;计算病理学领域因现代视觉基础模型（FMs）的发展而迅速进步，通过增加训练数据集、模型大小和集成特定领域图像处理技术，可以显著提高模型在下游任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;计算病理学领域因现代视觉基础模型（FMs）的发展而迅速进步，这些模型通常在大量病理图像上训练。&lt;h4&gt;目的&lt;/h4&gt;优化病理FMs的训练，并在更高分辨率的图像上对模型进行微调，以进一步丰富嵌入中的信息。&lt;h4&gt;方法&lt;/h4&gt;对标准DINOv2框架进行修改，包括增加训练数据集和模型大小，集成特定领域图像处理技术，以及应用后训练过程进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;提出了三个新的病理FM，这些模型在训练数据量上比其他最先进的FM少一个到两个数量级，但在下游任务上表现出相当或更好的性能。即使是仅使用TCGA数据（12k WSIs）训练的模型也优于大多数现有FMs，平均而言与Virchow2相当，这是迄今为止发布的第二好的FM。&lt;h4&gt;结论&lt;/h4&gt;这表明，仍有很大潜力进一步改进用于训练病理FMs的模型和算法，以充分利用庞大的数据集。&lt;h4&gt;翻译&lt;/h4&gt;计算病理学领域因现代视觉基础模型（FMs）的发展而迅速进步，这些模型通常在大量病理图像上训练。最近的研究表明，增加训练数据集和模型大小以及集成特定领域的图像处理技术可以显著提高模型在下游任务上的性能。基于这些见解，我们的工作结合了文献中标准DINOv2框架的几个最近修改来优化病理FMs的训练。我们还应用了后训练过程，在更高分辨率的图像上对模型进行微调，以进一步丰富嵌入中的信息。我们提出了三个新的病理FM，这些模型在训练数据量上比用于训练其他最先进FM的WSI少一个到两个数量级，同时在下游任务上表现出相当或更好的性能。即使是仅使用TCGA数据（12k WSIs）训练的模型也优于大多数现有FMs，平均而言与Virchow2相当，这是迄今为止发布的第二好的FM。这表明，仍有很大潜力进一步改进用于训练病理FMs的模型和算法，以充分利用庞大的数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The field of computational pathology has recently seen rapid advances drivenby the development of modern vision foundation models (FMs), typically trainedon vast collections of pathology images. Recent studies demonstrate thatincreasing the training data set and model size and integrating domain-specificimage processing techniques can significantly enhance the model's performanceon downstream tasks. Building on these insights, our work incorporates severalrecent modifications to the standard DINOv2 framework from the literature tooptimize the training of pathology FMs. We also apply a post-training procedurefor fine-tuning models on higher-resolution images to further enrich theinformation encoded in the embeddings. We present three novel pathology FMstrained on up to two orders of magnitude fewer WSIs than those used to trainother state-of-the-art FMs while demonstrating a comparable or superiorperformance on downstream tasks. Even the model trained on TCGA alone (12kWSIs) outperforms most existing FMs and, on average, matches Virchow2, thesecond-best FM published to date. This suggests that there still remains asignificant potential for further improving the models and algorithms used totrain pathology FMs to take full advantage of the vast data collections.</description>
      <author>example@mail.com (Mikhail Karasikov, Joost van Doorn, Nicolas Känzig, Melis Erdal Cesur, Hugo Mark Horlings, Robert Berke, Fei Tang, Sebastian Otálora)</author>
      <guid isPermaLink="false">2504.05186v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Multi-resolution Score-Based Variational Graphical Diffusion for Causal Disaster System Modeling and Inference</title>
      <link>http://arxiv.org/abs/2504.04015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Temporal-SVGDM，一种基于评分的变分图扩散模型，用于处理多分辨率观测数据，旨在解决复杂系统中因果关系预测的挑战。&lt;h4&gt;背景&lt;/h4&gt;复杂系统中的因果关系复杂，难以准确预测。有效的建模需要精确的物理过程表示、整合相互依赖的因素以及结合多分辨率观测数据。&lt;h4&gt;目的&lt;/h4&gt;提高复杂系统因果关系的预测准确性，并增强对系统动态的理解。&lt;h4&gt;方法&lt;/h4&gt;Temporal-SVGDM通过构建每个变量在其原分辨率下的单个随机微分方程（SDE），并通过因果关系评分机制将这些SDE耦合起来。此外，在时间模型中，状态表示通过序列预测模型处理，以预测未来状态。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有方法相比，Temporal-SVGDM在真实世界数据集上提高了预测准确性和对因果关系的理解，并且在不同背景知识水平下表现出鲁棒的性能。&lt;h4&gt;结论&lt;/h4&gt;Temporal-SVGDM能够优雅地适应不同灾难类型，成功处理静态地震场景以及时间性的飓风和野火场景，即使在数据有限的情况下也能保持优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex systems with intricate causal dependencies challenge accurateprediction. Effective modeling requires precise physical processrepresentation, integration of interdependent factors, and incorporation ofmulti-resolution observational data. These systems manifest in both staticscenarios with instantaneous causal chains and temporal scenarios with evolvingdynamics, complicating modeling efforts. Current methods struggle tosimultaneously handle varying resolutions, capture physical relationships,model causal dependencies, and incorporate temporal dynamics, especially withinconsistently sampled data from diverse sources. We introduce Temporal-SVGDM:Score-based Variational Graphical Diffusion Model for Multi-resolutionobservations. Our framework constructs individual SDEs for each variable at itsnative resolution, then couples these SDEs through a causal score mechanismwhere parent nodes inform child nodes' evolution. This enables unified modelingof both immediate causal effects in static scenarios and evolving dependenciesin temporal scenarios. In temporal models, state representations are processedthrough a sequence prediction model to predict future states based onhistorical patterns and causal relationships. Experiments on real-worlddatasets demonstrate improved prediction accuracy and causal understandingcompared to existing methods, with robust performance under varying levels ofbackground knowledge. Our model exhibits graceful degradation across differentdisaster types, successfully handling both static earthquake scenarios andtemporal hurricane and wildfire scenarios, while maintaining superiorperformance even with limited data.</description>
      <author>example@mail.com (Xuechun Li, Shan Gao, Susu Xu)</author>
      <guid isPermaLink="false">2504.04015v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Relational Deep Learning with Pretrained Tabular Models</title>
      <link>http://arxiv.org/abs/2504.04934v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LightRDL的新方法，旨在提高关系数据库中图神经网络（GNN）的效率，使其更适合实时预测。&lt;h4&gt;背景&lt;/h4&gt;关系数据库通过主键和外键关系组织数据，预测通常涉及将数据转换为平坦的表格格式，但设计能够完全捕捉复杂关系的特征具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;通过利用现有的特征工程努力，提高GNN在关系数据库中的效率，以实现实时预测。&lt;h4&gt;方法&lt;/h4&gt;使用GNN捕获关系数据库中的复杂关系，同时使用工程化特征编码时间信息，从而避免保留整个历史图，并允许使用更小、更高效的图。&lt;h4&gt;主要发现&lt;/h4&gt;LightRDL方法不仅提高了效率，而且在RelBench基准测试中，比GNN实现了高达33%的性能提升和526倍的推理速度。&lt;h4&gt;结论&lt;/h4&gt;LightRDL方法在关系数据库中进行实时预测方面具有显著优势，为实时推理提供了高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Relational databases, organized into tables connected by primary-foreign keyrelationships, are a common format for organizing data. Making predictions onrelational data often involves transforming them into a flat tabular formatthrough table joins and feature engineering, which serve as input to tabularmethods. However, designing features that fully capture complex relationalpatterns remains challenging. Graph Neural Networks (GNNs) offer a compellingalternative by inherently modeling these relationships, but their time overheadduring inference limits their applicability for real-time scenarios. In thiswork, we aim to bridge this gap by leveraging existing feature engineeringefforts to enhance the efficiency of GNNs in relational databases.Specifically, we use GNNs to capture complex relationships within relationaldatabases, patterns that are difficult to featurize, while employing engineeredfeatures to encode temporal information, thereby avoiding the need to retainthe entire historical graph and enabling the use of smaller, more efficientgraphs. Our \textsc{LightRDL} approach not only improves efficiency, but alsooutperforms existing models. Experimental results on the RelBench benchmarkdemonstrate that our framework achieves up to $33\%$ performance improvementand a $526\times$ inference speedup compared to GNNs, making it highly suitablefor real-time inference.</description>
      <author>example@mail.com (Veronica Lachi, Antonio Longa, Beatrice Bevilacqua, Bruno Lepri, Andrea Passerini, Bruno Ribeiro)</author>
      <guid isPermaLink="false">2504.04934v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>A Unified Pairwise Framework for RLHF: Bridging Generative Reward Modeling and Policy Optimization</title>
      <link>http://arxiv.org/abs/2504.04950v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11oages,2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Pairwise-RL的强化学习框架，用于提高大型语言模型与人类偏好的对齐。该框架通过结合生成性奖励建模和成对近端策略优化（PPO）算法来解决现有RLHF方法中的限制。&lt;h4&gt;背景&lt;/h4&gt;RLHF已成为在训练后使大型语言模型（LLMs）与人类偏好对齐的重要范式。该框架通常分为两个阶段：首先在人类偏好数据上训练奖励模型，然后使用强化学习算法优化语言模型。&lt;h4&gt;目的&lt;/h4&gt;解决现有RLHF方法的两个限制：一是现有框架依赖于布拉德利-特里模型进行成对比较以分配标量奖励，这对奖励模型提出了挑战；二是奖励模型通常从生成基础模型初始化，而奖励模型执行的是判别性任务，导致不匹配。&lt;h4&gt;方法&lt;/h4&gt;Pairwise-RL框架通过结合生成性奖励建模和成对近端策略优化（PPO）算法来应对上述挑战。该框架在奖励模型训练和应用过程中采用一致的成对范式，利用生成建模技术来提高奖励模型性能和分数校准。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估表明，Pairwise-RL在内部评估数据集和标准公共基准测试中均优于传统的RLHF框架，强调了其在提高对齐和模型行为方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;Pairwise-RL是一个有效的RLHF框架，能够提高大型语言模型与人类偏好的对齐，并改进模型行为。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement Learning from Human Feedback (RLHF) has emerged as a importantparadigm for aligning large language models (LLMs) with human preferencesduring post-training. This framework typically involves two stages: first,training a reward model on human preference data, followed by optimizing thelanguage model using reinforcement learning algorithms. However, current RLHFapproaches may constrained by two limitations. First, existing RLHF frameworksoften rely on Bradley-Terry models to assign scalar rewards based on pairwisecomparisons of individual responses. However, this approach imposes significantchallenges on reward model (RM), as the inherent variability in prompt-responsepairs across different contexts demands robust calibration capabilities fromthe RM. Second, reward models are typically initialized from generativefoundation models, such as pre-trained or supervised fine-tuned models, despitethe fact that reward models perform discriminative tasks, creating a mismatch.This paper introduces Pairwise-RL, a RLHF framework that addresses thesechallenges through a combination of generative reward modeling and a pairwiseproximal policy optimization (PPO) algorithm. Pairwise-RL unifies reward modeltraining and its application during reinforcement learning within a consistentpairwise paradigm, leveraging generative modeling techniques to enhance rewardmodel performance and score calibration. Experimental evaluations demonstratethat Pairwise-RL outperforms traditional RLHF frameworks across both internalevaluation datasets and standard public benchmarks, underscoring itseffectiveness in improving alignment and model behavior.</description>
      <author>example@mail.com (Wenyuan Xu, Xiaochen Zuo, Chao Xin, Yu Yue, Lin Yan, Yonghui Wu)</author>
      <guid isPermaLink="false">2504.04950v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>EquiCPI: SE(3)-Equivariant Geometric Deep Learning for Structure-Aware Prediction of Compound-Protein Interactions</title>
      <link>http://arxiv.org/abs/2504.04654v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EquiCPI的几何深度学习框架，用于预测化合物-蛋白质相互作用，该框架结合了第一性原理结构建模和SE(3)等变神经网络，在BindingDB和DUD-E数据集上取得了与现有深度学习竞争对手相当或更好的性能。&lt;h4&gt;背景&lt;/h4&gt;准确预测化合物-蛋白质相互作用是计算药物发现中的一个关键挑战，现有的基于序列的方法忽略了结合亲和力的三维结构决定因素。&lt;h4&gt;目的&lt;/h4&gt;提出EquiCPI框架，以解决现有方法在预测化合物-蛋白质相互作用时忽视三维结构决定因素的问题。&lt;h4&gt;方法&lt;/h4&gt;EquiCPI通过ESMFold将蛋白质序列转换为3D原子坐标，通过DiffDock-L对配体进行转换。然后，采用物理引导的构象重排序和等变特征学习。核心部分使用SE(3)等变消息传递，通过球谐函数的张量积层次化编码局部相互作用模式。&lt;h4&gt;主要发现&lt;/h4&gt;EquiCPI在BindingDB（亲和力预测）和DUD-E（虚拟筛选）数据集上实现了与现有深度学习竞争对手相当或更好的性能。&lt;h4&gt;结论&lt;/h4&gt;EquiCPI框架在预测化合物-蛋白质相互作用方面具有优越的性能，为计算药物发现提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;Accurate prediction of compound-protein interactions (CPI) remains a cornerstone challenge in computational drug discovery. While existing sequence-based approaches leverage molecular fingerprints or graph representations, they critically overlook three-dimensional (3D) structural determinants of binding affinity. To bridge this gap, we present EquiCPI, an end-to-end geometric deep learning framework that synergizes first-principles structural modeling with SE(3)-equivariant neural networks. Our pipeline transforms raw sequences into 3D atomic coordinates via ESMFold for proteins and DiffDock-L for ligands, followed by physics-guided conformer re-ranking and equivariant feature learning. At its core, EquiCPI employs SE(3)-equivariant message passing over atomic point clouds, preserving symmetry under rotations, translations, and reflections, while hierarchically encoding local interaction patterns through tensor products of spherical harmonics. The proposed model is evaluated on BindingDB (affinity prediction) and DUD-E (virtual screening), EquiCPI achieves performance on par with or exceeding the state-of-the-art deep learning competitors.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of compound-protein interactions (CPI) remains acornerstone challenge in computational drug discovery. While existingsequence-based approaches leverage molecular fingerprints or graphrepresentations, they critically overlook three-dimensional (3D) structuraldeterminants of binding affinity. To bridge this gap, we present EquiCPI, anend-to-end geometric deep learning framework that synergizes first-principlesstructural modeling with SE(3)-equivariant neural networks. Our pipelinetransforms raw sequences into 3D atomic coordinates via ESMFold for proteinsand DiffDock-L for ligands, followed by physics-guided conformer re-ranking andequivariant feature learning. At its core, EquiCPI employs SE(3)-equivariantmessage passing over atomic point clouds, preserving symmetry under rotations,translations, and reflections, while hierarchically encoding local interactionpatterns through tensor products of spherical harmonics. The proposed model isevaluated on BindingDB (affinity prediction) and DUD-E (virtual screening),EquiCPI achieves performance on par with or exceeding the state-of-the-art deeplearning competitors.</description>
      <author>example@mail.com (Ngoc-Quang Nguyen)</author>
      <guid isPermaLink="false">2504.04654v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Planning Safety Trajectories with Dual-Phase, Physics-Informed, and Transportation Knowledge-Driven Large Language Models</title>
      <link>http://arxiv.org/abs/2504.04562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为LetsPi的框架，用于安全、类似人类的轨迹规划，以克服现有基础模型在自动驾驶任务中的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有基础模型在场景理解、规划和控制等驾驶相关任务中表现出强大的推理和泛化能力，但面临幻觉、不确定性和长推理延迟的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够安全、类似人类地进行轨迹规划的框架，以解决现有模型的局限性。&lt;h4&gt;方法&lt;/h4&gt; LetsPi框架集成了大语言模型（LLM）推理和基于物理的社会力动力学，并通过双阶段架构来平衡推理和计算效率。它包括记忆收集阶段和快速推理阶段，以及使用代理安全措施和基于物理的提示技术来增强LLM的知识。&lt;h4&gt;主要发现&lt;/h4&gt;在HighD数据集上的广泛实验表明，LetsPi在五个安全指标上优于基线模型。&lt;h4&gt;结论&lt;/h4&gt;LetsPi是一个有效的框架，可以用于安全的自动驾驶轨迹规划，并且优于现有的基线模型。&lt;h4&gt;翻译&lt;/h4&gt;该论文提出了一种名为LetsPi的框架，用于安全、类似人类的轨迹规划，以克服现有基础模型在自动驾驶任务中的局限性。现有基础模型在场景理解、规划和控制等驾驶相关任务中表现出强大的推理和泛化能力，但面临幻觉、不确定性和长推理延迟的挑战。为了解决这些局限性，我们引入了名为LetsPi的物理信息、双阶段、知识驱动框架，用于安全、类似人类的轨迹规划。为了防止幻觉和最小化不确定性，该混合框架集成了大语言模型（LLM）推理和基于物理的社会力动力学。LetsPi利用LLM来分析驾驶场景和历史信息，为社交力模型提供适当的参数和目标目的地（目标），然后生成未来轨迹。此外，双阶段架构通过其记忆收集阶段和快速推理阶段平衡推理和计算效率。记忆收集阶段利用基于物理的LLM通过推理、反思和记忆模块处理和优化规划结果，将安全的、高质量的驾驶经验存储在记忆库中。引入了代理安全措施和基于物理的提示技术，分别增强LLM对交通安全和物理力的知识。快速推理阶段提取类似驾驶经验的少样本示例用于新场景，同时简化输入输出要求，以实现快速轨迹规划而不牺牲安全性。在HighD数据集上的广泛实验表明，LetsPi在五个安全指标上优于基线模型。见PDF获取项目GitHub链接。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have demonstrated strong reasoning and generalizationcapabilities in driving-related tasks, including scene understanding, planning,and control. However, they still face challenges in hallucinations,uncertainty, and long inference latency. While existing foundation models havegeneral knowledge of avoiding collisions, they often lacktransportation-specific safety knowledge. To overcome these limitations, weintroduce LetsPi, a physics-informed, dual-phase, knowledge-driven frameworkfor safe, human-like trajectory planning. To prevent hallucinations andminimize uncertainty, this hybrid framework integrates Large Language Model(LLM) reasoning with physics-informed social force dynamics. LetsPi leveragesthe LLM to analyze driving scenes and historical information, providingappropriate parameters and target destinations (goals) for the social forcemodel, which then generates the future trajectory. Moreover, the dual-phasearchitecture balances reasoning and computational efficiency through its MemoryCollection phase and Fast Inference phase. The Memory Collection phaseleverages the physics-informed LLM to process and refine planning resultsthrough reasoning, reflection, and memory modules, storing safe, high-qualitydriving experiences in a memory bank. Surrogate safety measures andphysics-informed prompt techniques are introduced to enhance the LLM'sknowledge of transportation safety and physical force, respectively. The FastInference phase extracts similar driving experiences as few-shot examples fornew scenarios, while simplifying input-output requirements to enable rapidtrajectory planning without compromising safety. Extensive experiments usingthe HighD dataset demonstrate that LetsPi outperforms baseline models acrossfive safety metrics.See PDF for project Github link.</description>
      <author>example@mail.com (Rui Gan, Pei Li, Keke Long, Bocheng An, Junwei You, Keshu Wu, Bin Ran)</author>
      <guid isPermaLink="false">2504.04562v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>The Point, the Vision and the Text: Does Point Cloud Boost Spatial Reasoning of Large Language Models?</title>
      <link>http://arxiv.org/abs/2504.04540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了3D大型语言模型（LLMs）利用点云中的空间信息进行3D空间推理的能力，并提出了一个名为ScanReQA的3D问答基准来评估模型对二进制空间关系的理解。&lt;h4&gt;背景&lt;/h4&gt;3D LLMs利用点云进行3D空间推理受到了广泛关注，但点云在3D空间推理中的作用仍被低估。&lt;h4&gt;目的&lt;/h4&gt;评估和分析了这些模型，以回答是否点云真正提升了3D LLMs的空间推理能力。&lt;h4&gt;方法&lt;/h4&gt;通过替换点云为视觉和文本输入，评估了不同输入模态下LLMs的空间推理能力；提出了ScanReQA基准来评估模型对二进制空间关系的理解。&lt;h4&gt;主要发现&lt;/h4&gt;1) 没有点输入的LLMs即使在零样本情况下也能达到具有竞争力的表现；2) 现有的3D LLMs难以理解二进制空间关系；3) 3D LLMs在利用点云中的结构坐标进行细粒度空间推理方面存在局限性。&lt;h4&gt;结论&lt;/h4&gt;这些结论有助于3D LLMs的下一步发展，并为其他模态的基础模型提供见解。&lt;h4&gt;翻译&lt;/h4&gt;本研究利用3D大型语言模型（LLMs）中的空间信息进行3D空间推理，并提出了一个名为ScanReQA的3D问答基准来全面评估模型对二进制空间关系的理解。研究发现，没有点输入的LLMs即使在没有先验知识的情况下也能取得有竞争力的成绩；现有的3D LLMs在理解二进制空间关系方面存在困难；3D LLMs在利用点云中的结构坐标进行细粒度空间推理时存在限制。这些结论对3D LLMs的发展有重要意义，也为其他模态的基础模型提供了启示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Large Language Models (LLMs) leveraging spatial information in pointclouds for 3D spatial reasoning attract great attention. Despite some promisingresults, the role of point clouds in 3D spatial reasoning remainsunder-explored. In this work, we comprehensively evaluate and analyze thesemodels to answer the research question: \textit{Does point cloud truly boostthe spatial reasoning capacities of 3D LLMs?} We first evaluate the spatialreasoning capacity of LLMs with different input modalities by replacing thepoint cloud with the visual and text counterparts. We then propose a novel 3DQA (Question-answering) benchmark, ScanReQA, that comprehensively evaluatesmodels' understanding of binary spatial relationships. Our findings revealseveral critical insights: 1) LLMs without point input could even achievecompetitive performance even in a zero-shot manner; 2) existing 3D LLMsstruggle to comprehend the binary spatial relationships; 3) 3D LLMs exhibitlimitations in exploiting the structural coordinates in point clouds forfine-grained spatial reasoning. We think these conclusions can help the nextstep of 3D LLMs and also offer insights for foundation models in othermodalities. We release datasets and reproducible codes in the anonymous projectpage: https://3d-llm.xyz.</description>
      <author>example@mail.com (Weichen Zhang, Ruiying Peng, Chen Gao, Jianjie Fang, Xin Zeng, Kaiyuan Li, Ziyou Wang, Jinqiang Cui, Xin Wang, Xinlei Chen, Yong Li)</author>
      <guid isPermaLink="false">2504.04540v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Squeeze and Excitation: A Weighted Graph Contrastive Learning for Collaborative Filtering</title>
      <link>http://arxiv.org/abs/2504.04443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种加权图对比学习框架（WeightedGCL），旨在提高推荐系统的表现，特别是通过利用扰动视图的自我监督信号来减轻数据稀疏性的挑战。&lt;h4&gt;背景&lt;/h4&gt;对比学习（CL）作为一种强大的技术，在推荐系统中得到了应用，尤其是在处理数据稀疏性的问题上。&lt;h4&gt;目的&lt;/h4&gt;通过提出加权图对比学习框架，旨在解决现有GCL模型中特征注意力分配不合理的问题，从而提高模型的表现。&lt;h4&gt;方法&lt;/h4&gt;WeightedGCL采用了一种鲁棒的扰动策略，仅扰动最终GCN层的视图，并引入了squeeze and excitation网络（SENet）来动态加权扰动视图的特征。&lt;h4&gt;主要发现&lt;/h4&gt;WeightedGCL通过加强模型对关键特征的关注，减少了不相关信息的影响，实验结果表明，与基线模型相比，WeightedGCL实现了显著的准确率提升。&lt;h4&gt;结论&lt;/h4&gt;WeightedGCL框架在广泛使用的数据集上取得了显著的性能提升，证明了其有效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Learning (CL) has recently emerged as a powerful technique inrecommendation systems, particularly for its capability to harnessself-supervised signals from perturbed views to mitigate the persistentchallenge of data sparsity. The process of constructing perturbed views of theuser-item bipartite graph and performing contrastive learning between perturbedviews in a graph convolutional network (GCN) is called graph contrastivelearning (GCL), which aims to enhance the robustness of representationlearning. Although existing GCL-based models are effective, the weightassignment method for perturbed views has not been fully explored. A criticalproblem in existing GCL-based models is the irrational allocation of featureattention. This problem limits the model's ability to effectively leveragecrucial features, resulting in suboptimal performance. To address this, wepropose a Weighted Graph Contrastive Learning framework (WeightedGCL).Specifically, WeightedGCL applies a robust perturbation strategy, whichperturbs only the view of the final GCN layer. In addition, WeightedGCLincorporates a squeeze and excitation network (SENet) to dynamically weight thefeatures of the perturbed views. Our WeightedGCL strengthens the model's focuson crucial features and reduces the impact of less relevant information.Extensive experiments on widely used datasets demonstrate that our WeightedGCLachieves significant accuracy improvements compared to competitive baselines.</description>
      <author>example@mail.com (Zheyu Chen, Jinfeng Xu, Yutong Wei, Ziyue Peng)</author>
      <guid isPermaLink="false">2504.04443v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Attentional Graph Meta-Learning for Indoor Localization Using Extremely Sparse Fingerprints</title>
      <link>http://arxiv.org/abs/2504.04829v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于指纹的室内定位方法，旨在解决高精度定位和密集网格的需求带来的劳动密集型问题，通过结合注意力图神经网络和元学习框架，以及两种新的数据增强策略，实现了对稀疏指纹的有效利用。&lt;h4&gt;背景&lt;/h4&gt;现有的指纹定位方法劳动密集，且在高精度定位和稀疏指纹之间存在挑战，同时现有方法忽视了空间和环境特征的价值。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的定位方法，以减少劳动密集型工作，同时提高定位精度。&lt;h4&gt;方法&lt;/h4&gt;1) 使用注意力图神经网络（AGNN）模型学习空间邻接关系和信息聚合；2) 利用元学习框架和相似环境数据集增强模型训练；3) 引入两种数据增强策略：使用移动平台进行未标记指纹增强，以及通过环境数字孪生进行合成标记指纹增强。&lt;h4&gt;主要发现&lt;/h4&gt;AGML模型结合了AGNN模型和元学习框架的优点，能够有效地处理稀疏指纹带来的挑战，并通过实验证明了其在合成和真实世界数据集上的优越性。&lt;h4&gt;结论&lt;/h4&gt;AGML模型在稀疏指纹条件下，在多个评估指标上均优于现有的基准方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于指纹的室内定位由于需要密集网格和重复的时间和空间测量而往往劳动密集。在高稀疏指纹条件下保持高定位精度仍然是一个持续的挑战。现有的基准方法主要依赖于测量的指纹，而忽略了有价值的空间和环境特征。在本文中，我们提出了一种注意力图神经网络（AGNN）模型的系统整合，该模型能够学习空间邻接关系并聚合邻近指纹的信息，以及一个利用具有相似环境特征的数据集进行模型训练的元学习框架。为了最小化指纹收集的劳动，我们引入了两种新颖的数据增强策略：1）使用移动平台进行未标记指纹增强，这使半监督AGNN模型能够纳入未标记指纹的信息；2）通过环境数字孪生进行合成标记指纹增强，通过实际分布对齐增强了元学习框架，有效地最小化了合成和真实世界指纹之间的特征差异。通过整合这些新颖模块，我们提出了注意力图元学习（AGML）模型。这个新颖的模型结合了AGNN模型和元学习框架的优点，以解决由极端稀疏指纹带来的挑战。为了验证我们的方法，我们从消费级WiFi设备和专业设备收集了多个数据集，这些设备在多种环境中使用。在合成和真实世界数据集上进行的广泛实验表明，基于AGML模型的定位方法在所有评估指标上均一致优于使用稀疏指纹的所有基准方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fingerprint-based indoor localization is often labor-intensive due to theneed for dense grids and repeated measurements across time and space.Maintaining high localization accuracy with extremely sparse fingerprintsremains a persistent challenge. Existing benchmark methods primarily rely onthe measured fingerprints, while neglecting valuable spatial and environmentalcharacteristics. In this paper, we propose a systematic integration of anAttentional Graph Neural Network (AGNN) model, capable of learning spatialadjacency relationships and aggregating information from neighboringfingerprints, and a meta-learning framework that utilizes datasets with similarenvironmental characteristics to enhance model training. To minimize the laborrequired for fingerprint collection, we introduce two novel data augmentationstrategies: 1) unlabeled fingerprint augmentation using moving platforms, whichenables the semi-supervised AGNN model to incorporate information fromunlabeled fingerprints, and 2) synthetic labeled fingerprint augmentationthrough environmental digital twins, which enhances the meta-learning frameworkthrough a practical distribution alignment, which can minimize the featurediscrepancy between synthetic and real-world fingerprints effectively. Byintegrating these novel modules, we propose the Attentional Graph Meta-Learning(AGML) model. This novel model combines the strengths of the AGNN model and themeta-learning framework to address the challenges posed by extremely sparsefingerprints. To validate our approach, we collected multiple datasets fromboth consumer-grade WiFi devices and professional equipment across diverseenvironments. Extensive experiments conducted on both synthetic and real-worlddatasets demonstrate that the AGML model-based localization method consistentlyoutperforms all baseline methods using sparse fingerprints across all evaluatedmetrics.</description>
      <author>example@mail.com (Wenzhong Yan, Feng Yin, Jun Gao, Ao Wang, Yang Tian, Ruizhi Chen)</author>
      <guid isPermaLink="false">2504.04829v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models</title>
      <link>http://arxiv.org/abs/2504.04893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to CVPR 2025 Workshop EVAL-FoMo-2&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SCAM，这是迄今为止最大、最多样化的真实世界印刷攻击图像数据集，对视觉-语言模型（VLMs）进行了广泛基准测试，揭示了印刷攻击对模型性能的影响，并提供了对构建鲁棒和可信的多模态AI系统的见解。&lt;h4&gt;背景&lt;/h4&gt;印刷攻击利用多模态基础模型中文本和视觉内容之间的相互作用，导致误导性文本嵌入图像时出现误分类。现有数据集在规模和多样性方面存在局限性，难以研究此类漏洞。&lt;h4&gt;目的&lt;/h4&gt;研究印刷攻击对视觉-语言模型的影响，并提供一个综合资源以促进对鲁棒和可信的多模态AI系统的研究。&lt;h4&gt;方法&lt;/h4&gt;引入了SCAM数据集，对VLMs进行了基准测试，并分析了训练数据和模型架构对攻击敏感性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;印刷攻击显著降低了VLMs的性能，并发现训练数据和模型架构影响了攻击的敏感性。尽管大型语言模型（LLMs）的骨干结构有助于减轻其脆弱性，但最先进的视觉-语言模型（LVLMs）仍然容易受到攻击。合成攻击与真实世界（手写）攻击非常相似，验证了它们在研究中的使用。&lt;h4&gt;结论&lt;/h4&gt;印刷攻击是VLMs的一个重要安全漏洞，需要进一步研究以构建鲁棒的多模态AI系统。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了SCAM，这是迄今为止最大、最多样化的真实世界印刷攻击图像数据集。通过对视觉-语言模型（VLMs）进行广泛的基准测试，我们发现印刷攻击会显著降低模型性能，并确定了训练数据和模型架构对攻击敏感性的影响。我们的研究揭示了印刷攻击在LVLMs中持续存在的原因，尽管更大的LLMs骨干结构有助于减轻其脆弱性。此外，我们还证明了合成攻击与真实世界攻击非常相似，验证了它们在研究中的使用。我们的工作提供了一个综合资源，并为未来研究鲁棒和可信的多模态AI系统提供了实证见解。本文中介绍的数据集已公开发布，代码和评估工具也已在相关网站上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Typographic attacks exploit the interplay between text and visual content inmultimodal foundation models, causing misclassifications when misleading textis embedded within images. However, existing datasets are limited in size anddiversity, making it difficult to study such vulnerabilities. In this paper, weintroduce SCAM, the largest and most diverse dataset of real-world typographicattack images to date, containing 1,162 images across hundreds of objectcategories and attack words. Through extensive benchmarking of Vision-LanguageModels (VLMs) on SCAM, we demonstrate that typographic attacks significantlydegrade performance, and identify that training data and model architectureinfluence the susceptibility to these attacks. Our findings reveal thattypographic attacks persist in state-of-the-art Large Vision-Language Models(LVLMs) due to the choice of their vision encoder, though larger Large LanguageModels (LLMs) backbones help mitigate their vulnerability. Additionally, wedemonstrate that synthetic attacks closely resemble real-world (handwritten)attacks, validating their use in research. Our work provides a comprehensiveresource and empirical insights to facilitate future research toward robust andtrustworthy multimodal AI systems. We publicly release the datasets introducedin this paper under https://huggingface.co/datasets/BLISS-e-V/SCAM, along withthe code for evaluations at https://github.com/Bliss-e-V/SCAM.</description>
      <author>example@mail.com (Justus Westerhoff, Erblina Purellku, Jakob Hackstein, Leo Pinetzki, Lorenz Hufe)</author>
      <guid isPermaLink="false">2504.04893v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.04495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的弱监督视频异常检测框架，该框架利用音频-视觉协作进行鲁棒的视频异常检测，显著提高了检测准确性。&lt;h4&gt;背景&lt;/h4&gt;传统的基于视觉的视频异常检测方法在复杂环境中存在信息不足和高误报率的问题。&lt;h4&gt;目的&lt;/h4&gt;解决传统方法在复杂环境中的局限性。&lt;h4&gt;方法&lt;/h4&gt;利用Contrastive Language-Image Pretraining (CLIP)的多模态表示学习能力，引入了两种主要创新：一种高效的音频-视觉融合，通过轻量级的参数调整实现自适应跨模态集成，同时保持冻结的CLIP骨干网络；以及一种新颖的音频-视觉提示，根据音频-视觉特征与文本标签之间的语义相关性，动态增强文本嵌入，显著提高CLIP在视频异常检测任务中的泛化能力。此外，为了提高推理过程中对模态缺失的鲁棒性，开发了一个基于不确定性的特征蒸馏模块，该模块从仅视觉输入中合成音频-视觉表示，并使用基于音频-视觉特征多样性的不确定性建模来动态强调蒸馏过程中的挑战性特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个基准测试中表现出色，音频集成显著提高了各种场景下的异常检测准确率。使用不确定性驱动的蒸馏增强的单模态数据，该方法在性能上始终优于当前的单一模态视频异常检测方法。&lt;h4&gt;结论&lt;/h4&gt;该方法通过音频-视觉协作和不确定性驱动的特征蒸馏，为视频异常检测提供了一种鲁棒的解决方案，显著提高了检测准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;With the increasing adoption of video anomaly detection in intelligentsurveillance domains, conventional visual-based detection approaches often struggle with information insufficiency and high false-positive rates in complex environments. To address these limitations, we present a novel weaklysupervised framework that leverages audio-visual collaboration for robust video anomaly detection. Capitalizing on the exceptional cross-modal representation learning capabilities of Contrastive Language-Image Pretraining (CLIP) across visual, audio, and textual domains, our framework introduces two major innovations: an efficient audio-visual fusion that enables adaptive cross-modal integration through lightweight parametric adaptation while maintaining the frozen CLIP backbone, and a novel audio-visual prompt that dynamically enhances text embeddings with key multimodal information based on the semantic correlation between audio-visual features and textual labels, significantly improving CLIP's generalization for the video anomaly detection task. Moreover, to enhance robustness against modality deficiency during inference, we further develop an uncertainty-driven feature distillation module that synthesizes audio-visual representations from visual-only inputs. This module employs uncertainty modeling based on the diversity of audio-visual features to dynamically emphasize challenging features during the distillation process. Our framework demonstrates superior performance across multiple benchmarks, with audio integration significantly boosting anomaly detection accuracy in various scenarios. Notably, with unimodal data enhanced by uncertainty-driven distillation, our approach consistently outperforms current unimodal VAD methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing adoption of video anomaly detection in intelligentsurveillance domains, conventional visual-based detection approaches oftenstruggle with information insufficiency and high false-positive rates incomplex environments. To address these limitations, we present a novel weaklysupervised framework that leverages audio-visual collaboration for robust videoanomaly detection. Capitalizing on the exceptional cross-modal representationlearning capabilities of Contrastive Language-Image Pretraining (CLIP) acrossvisual, audio, and textual domains, our framework introduces two majorinnovations: an efficient audio-visual fusion that enables adaptive cross-modalintegration through lightweight parametric adaptation while maintaining thefrozen CLIP backbone, and a novel audio-visual prompt that dynamically enhancestext embeddings with key multimodal information based on the semanticcorrelation between audio-visual features and textual labels, significantlyimproving CLIP's generalization for the video anomaly detection task. Moreover,to enhance robustness against modality deficiency during inference, we furtherdevelop an uncertainty-driven feature distillation module that synthesizesaudio-visual representations from visual-only inputs. This module employsuncertainty modeling based on the diversity of audio-visual features todynamically emphasize challenging features during the distillation process. Ourframework demonstrates superior performance across multiple benchmarks, withaudio integration significantly boosting anomaly detection accuracy in variousscenarios. Notably, with unimodal data enhanced by uncertainty-drivendistillation, our approach consistently outperforms current unimodal VADmethods.</description>
      <author>example@mail.com (Peng Wu, Wanshun Su, Guansong Pang, Yujia Sun, Qingsen Yan, Peng Wang, Yanning Zhang)</author>
      <guid isPermaLink="false">2504.04495v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>3D Scene Understanding Through Local Random Access Sequence Modeling</title>
      <link>http://arxiv.org/abs/2504.03875v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project webpage: https://neuroailab.github.io/projects/lras_3d/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LRAS的自动回归生成模型，用于从单张图像中理解3D场景，旨在解决复杂场景下的对象和场景一致性维护问题。&lt;h4&gt;背景&lt;/h4&gt;3D场景理解是计算机视觉领域的关键问题，在图形、增强现实和机器人等领域有广泛的应用。尽管基于扩散的建模方法显示出潜力，但它们在保持对象和场景一致性方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出LRAS模型，旨在解决复杂场景下对象和场景一致性维护的局限性。&lt;h4&gt;方法&lt;/h4&gt;LRAS模型通过使用局部补丁量化和随机顺序序列生成，结合光流作为3D场景编辑的中间表示，实现了新颖的视角合成和3D对象操作能力。此外，通过修改序列设计，该框架还自然扩展到自监督深度估计。&lt;h4&gt;主要发现&lt;/h4&gt;LRAS在多个3D场景理解任务上表现出色，证明了其在构建下一代3D视觉模型方面的统一和有效性。&lt;h4&gt;结论&lt;/h4&gt;LRAS模型为3D场景理解提供了一种统一且有效的框架，有望推动相关技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;3D场景理解从单张图像是计算机视觉中的一个关键问题，在图形、增强现实和机器人等领域有众多下游应用。虽然基于扩散的建模方法显示出前景，但它们通常难以保持对象和场景的一致性，特别是在复杂的真实场景中。为了解决这些局限性，我们提出了一种名为局部随机访问序列（LRAS）的自动回归生成方法，该方法使用局部补丁量化和随机顺序序列生成。通过利用光流作为3D场景编辑的中间表示，我们的实验表明LRAS实现了最先进的视角合成和3D对象操作能力。此外，我们展示了通过简单修改序列设计，我们的框架自然扩展到自监督深度估计。通过在多个3D场景理解任务上实现强大性能，LRAS为构建下一代3D视觉模型提供了一个统一且有效的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D scene understanding from single images is a pivotal problem in computervision with numerous downstream applications in graphics, augmented reality,and robotics. While diffusion-based modeling approaches have shown promise,they often struggle to maintain object and scene consistency, especially incomplex real-world scenarios. To address these limitations, we propose anautoregressive generative approach called Local Random Access Sequence (LRAS)modeling, which uses local patch quantization and randomly ordered sequencegeneration. By utilizing optical flow as an intermediate representation for 3Dscene editing, our experiments demonstrate that LRAS achieves state-of-the-artnovel view synthesis and 3D object manipulation capabilities. Furthermore, weshow that our framework naturally extends to self-supervised depth estimationthrough a simple modification of the sequence design. By achieving strongperformance on multiple 3D scene understanding tasks, LRAS provides a unifiedand effective framework for building the next generation of 3D vision models.</description>
      <author>example@mail.com (Wanhee Lee, Klemen Kotar, Rahul Mysore Venkatesh, Jared Watrous, Honglin Chen, Khai Loong Aw, Daniel L. K. Yamins)</author>
      <guid isPermaLink="false">2504.03875v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Learning Conditionally Independent Transformations using Normal Subgroups in Group Theory</title>
      <link>http://arxiv.org/abs/2504.04490v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 10 figures, conference paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了利用正规子群进行条件独立变换分离的新方法，通过图像中的几何变换实验展示了该方法在无监督情况下成功对旋转和变换进行分类，揭示了通过正规子群进行群分解与表示学习中的变换分类之间的紧密联系。&lt;h4&gt;背景&lt;/h4&gt;人类通过认知能力识别物体及其变换，强调了无监督表示学习的重要性。无监督表示学习的一个基本挑战是在学习特征表示中分离不同的变换。&lt;h4&gt;目的&lt;/h4&gt;扩展当前表示学习框架，提出一种新的方法来分离条件独立变换，即使在没有交换性的情况下。&lt;h4&gt;方法&lt;/h4&gt;从伽罗瓦理论中汲取灵感，通过正规子群分解群以分析结构化变换。该方法利用正规子群来分离条件独立变换，即使在非交换情况下也能实现。&lt;h4&gt;主要发现&lt;/h4&gt;通过在图像的几何变换上的实验，证明了该方法能够无监督地对条件独立的变换进行分类。&lt;h4&gt;结论&lt;/h4&gt;该方法为表示学习中的变换分类提供了一个新的视角，表明通过正规子群进行群分解与变换分类之间存在紧密的联系。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类通过认知能力来识别物体及其变换，突出了无监督表示学习的重要性。无监督表示学习中的一个基本挑战是在学习特征表示中区分不同的变换。尽管已经探索了代数方法，但一个全面的理论框架仍然不发达。现有的方法基于代数独立性分解变换，但这些方法主要关注交换变换，并且不适用于变换条件独立但非交换的情况。为了扩展当前的表示学习框架，我们从伽罗瓦理论中汲取灵感，其中通过正规子群分解群为分析结构化变换提供了一个方法。在某种条件下，正规子群自然扩展了交换性，为变换的分类提供了基础，即使它们不交换。在本文中，我们提出了一种新颖的方法，该方法利用正规子群来实现条件独立变换的分离，即使在缺乏交换性的情况下也能实现。通过在图像几何变换上的实验，我们表明我们的方法成功地以无监督的方式对条件独立的变换进行了分类，如旋转和平移，这表明了通过正规子群进行群分解与表示学习中的变换分类之间的紧密联系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans develop certain cognitive abilities to recognize objects and theirtransformations without explicit supervision, highlighting the importance ofunsupervised representation learning. A fundamental challenge in unsupervisedrepresentation learning is to separate different transformations in learnedfeature representations. Although algebraic approaches have been explored, acomprehensive theoretical framework remains underdeveloped. Existing methodsdecompose transformations based on algebraic independence, but these methodsprimarily focus on commutative transformations and do not extend to cases wheretransformations are conditionally independent but noncommutative. To extendcurrent representation learning frameworks, we draw inspiration from Galoistheory, where the decomposition of groups through normal subgroups provides anapproach for the analysis of structured transformations. Normal subgroupsnaturally extend commutativity under certain conditions and offer a foundationfor the categorization of transformations, even when they do not commute. Inthis paper, we propose a novel approach that leverages normal subgroups toenable the separation of conditionally independent transformations, even in theabsence of commutativity. Through experiments on geometric transformations inimages, we show that our method successfully categorizes conditionallyindependent transformations, such as rotation and translation, in anunsupervised manner, suggesting a close link between group decomposition vianormal subgroups and transformation categorization in representation learning.</description>
      <author>example@mail.com (Kayato Nishitsunoi, Yoshiyuki Ohmura, Takayuki Komatsu, Yasuo Kuniyoshi)</author>
      <guid isPermaLink="false">2504.04490v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>MedGNN: Capturing the Links Between Urban Characteristics and Medical Prescriptions</title>
      <link>http://arxiv.org/abs/2504.04739v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages' main content. This is a preprint. Submitted to KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MedGNN的框架，用于研究城市社会人口和环境因素与健康之间的关系，旨在通过机器学习模型解决传统统计方法在非线性效应上的不足，以及机器学习模型在地理和拓扑效应上的不足。&lt;h4&gt;背景&lt;/h4&gt;理解城市社会人口和环境因素与健康之间的关系对于公共卫生和城市规划至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架MedGNN，以解决传统统计方法和机器学习模型在处理非线性、地理和拓扑效应时的局限性。&lt;h4&gt;方法&lt;/h4&gt;MedGNN通过构建一个2-hop空间图，将位置和定位节点嵌入与城市特征结合，以图神经网络的形式进行整合。该框架应用于包含超过150个环境和人口因素的MEDSAT数据集，覆盖伦敦4835个社区，并使用抑郁症处方作为案例研究。&lt;h4&gt;主要发现&lt;/h4&gt;MedGNN在预测准确性上比基线方法提高了25%以上。通过地理主成分分析分析了图嵌入，发现了一些与先前研究一致的结果，对当前辩论有贡献，并需要进一步研究。&lt;h4&gt;结论&lt;/h4&gt;MedGNN展示了机器学习在公共卫生研究中的潜力，尤其是在跨学科研究中的应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：理解城市社会人口和环境因素与健康之间的关系对于公共卫生和城市规划至关重要。然而，传统的统计方法难以处理非线性效应，而机器学习模型往往无法以可解释的方式捕捉地理（邻近区域更加相似）和拓扑（地点之间连接不等）效应。为了解决这个问题，我们提出了MedGNN，一个空间拓扑显式框架，它构建了一个2-hop空间图，将位置和定位节点嵌入与城市特征整合到图神经网络中。应用于覆盖超过150个环境和人口因素以及6种处方结果（抑郁症、焦虑症、糖尿病、高血压、哮喘和阿片类药物）的全面数据集MEDSAT，涵盖了伦敦4835个社区，与基线方法相比，MedGNN的平均预测准确性提高了25%以上。以抑郁症处方作为案例研究，我们通过地理主成分分析分析了图嵌入，发现了一些与先前研究一致的结果，对当前辩论有贡献，并需要进一步研究。这些结果表明，MedGNN具有潜力，更广泛地，精心应用的机器学习可以推动跨学科公共卫生研究的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding how urban socio-demographic and environmental factors relatewith health is essential for public health and urban planning. However,traditional statistical methods struggle with nonlinear effects, while machinelearning models often fail to capture geographical (nearby areas being moresimilar) and topological (unequal connectivity between places) effects in aninterpretable way. To address this, we propose MedGNN, a spatio-topologicallyexplicit framework that constructs a 2-hop spatial graph, integratingpositional and locational node embeddings with urban characteristics in a graphneural network. Applied to MEDSAT, a comprehensive dataset covering over 150environmental and socio-demographic factors and six prescription outcomes(depression, anxiety, diabetes, hypertension, asthma, and opioids) across 4,835Greater London neighborhoods, MedGNN improved predictions by over 25% onaverage compared to baseline methods. Using depression prescriptions as a casestudy, we analyzed graph embeddings via geographical principal componentanalysis, identifying findings that: align with prior research (e.g., higherantidepressant prescriptions among older and White populations), contribute toongoing debates (e.g., greenery linked to higher and NO2 to lowerprescriptions), and warrant further study (e.g., canopy evaporation correlatedwith fewer prescriptions). These results demonstrate MedGNN's potential, andmore broadly, of carefully applied machine learning, to advancetransdisciplinary public health research.</description>
      <author>example@mail.com (Minwei Zhao, Sanja Scepanovic, Stephen Law, Daniele Quercia, Ivica Obadic)</author>
      <guid isPermaLink="false">2504.04739v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Single-View 3D Gaussian Splatting using Unsupervised Hierarchical Disentangled Representation Learning</title>
      <link>http://arxiv.org/abs/2504.04190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Gaussian Splatting (GS) 在3D重建中取得了显著进展，但现有的3DGS方法在理解3D语义方面存在挑战，影响模型的可控性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;Gaussian Splatting (GS) 在3D重建中提供了快速渲染和高品质的结果，但现有的方法难以理解3D语义。&lt;h4&gt;目的&lt;/h4&gt;提出一个可解释的单视图3DGS框架3DisGS，通过分层解耦表示学习（DRL）发现粗粒度和细粒度的3D语义。&lt;h4&gt;方法&lt;/h4&gt;模型采用双分支架构，包括点云初始化分支和三平面高斯生成分支，通过分离3D几何和视觉外观特征实现粗粒度解耦。通过DRL编码器适配器进一步发现每个模态中的细粒度语义表示。&lt;h4&gt;主要发现&lt;/h4&gt;这是第一个实现无监督可解释3DGS的工作，模型在保持高质量和快速重建的同时实现了3D解耦。&lt;h4&gt;结论&lt;/h4&gt;提出的3DisGS框架能够有效解决现有3DGS方法中语义理解的问题，提高了模型的可控性和可解释性。&lt;h4&gt;翻译&lt;/h4&gt;Gaussian Splatting (GS) 近期在3D重建领域取得了显著进展，实现了快速渲染和高质量的结果。然而，现有的3DGS方法在理解底层3D语义方面存在挑战，这阻碍了模型的可控性和可解释性。为了解决这个问题，我们提出了一种可解释的单视图3DGS框架，称为3DisGS，通过分层解耦表示学习（DRL）来发现粗粒度和细粒度的3D语义。具体来说，该模型采用双分支架构，包括点云初始化分支和三平面高斯生成分支，通过分离3D几何和视觉外观特征来实现粗粒度解耦。随后，通过基于DRL的编码器适配器进一步发现每个模态中的细粒度语义表示。据我们所知，这是第一个实现无监督可解释3DGS的工作。评估结果表明，我们的模型在保持高质量和快速重建的同时实现了3D解耦。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gaussian Splatting (GS) has recently marked a significant advancement in 3Dreconstruction, delivering both rapid rendering and high-quality results.However, existing 3DGS methods pose challenges in understanding underlying 3Dsemantics, which hinders model controllability and interpretability. To addressit, we propose an interpretable single-view 3DGS framework, termed 3DisGS, todiscover both coarse- and fine-grained 3D semantics via hierarchicaldisentangled representation learning (DRL). Specifically, the model employs adual-branch architecture, consisting of a point cloud initialization branch anda triplane-Gaussian generation branch, to achieve coarse-graineddisentanglement by separating 3D geometry and visual appearance features.Subsequently, fine-grained semantic representations within each modality arefurther discovered through DRL-based encoder-adapters. To our knowledge, thisis the first work to achieve unsupervised interpretable 3DGS. Evaluationsindicate that our model achieves 3D disentanglement while preservinghigh-quality and rapid reconstruction.</description>
      <author>example@mail.com (Yuyang Zhang, Baao Xie, Hu Zhu, Qi Wang, Huanting Guo, Xin Jin, Wenjun Zeng)</author>
      <guid isPermaLink="false">2504.04190v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>NCL-CIR: Noise-aware Contrastive Learning for Composed Image Retrieval</title>
      <link>http://arxiv.org/abs/2504.04339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Has been accepted by ICASSP2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对Composed Image Retrieval (CIR)的噪声感知对比学习方法NCL-CIR，通过解决查询与目标图像不匹配的问题，提高了检索性能。&lt;h4&gt;背景&lt;/h4&gt;现有的CIR方法主要关注通过数据增强或模型设计探索查询对（图像和文本）之间的关系，但往往假设查询与目标图像完美对齐，这与实际情况不符。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决CIR中查询与目标图像不匹配导致的噪声问题，从而提高检索性能。&lt;h4&gt;方法&lt;/h4&gt;NCL-CIR包括两个关键组件：权重补偿块（WCB）和噪声对过滤块（NFB）。WCB通过不同的权重图确保多模态查询和目标图像的稳定token表示；NFB结合高斯混合模型（GMM）预测噪声对，并生成相应的软标签，设计基于软标签的噪声对比估计（NCE）损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;NCL-CIR能够有效减轻不匹配和部分匹配样本的影响，实验结果表明，NCL-CIR在基准数据集上取得了优异的性能。&lt;h4&gt;结论&lt;/h4&gt;NCL-CIR是一种有效的CIR方法，能够提高检索性能，特别是在处理不匹配和噪声数据时。&lt;h4&gt;翻译&lt;/h4&gt;Composed Image Retrieval (CIR) seeks to find a target image using a multi-modal query, which combines an image with modification text to pinpoint the target. While recent CIR methods have shown promise, they mainly focus on exploring relationships between the query pairs (image and text) through data augmentation or model design. These methods often assume perfect alignment between queries and target images, an idealized scenario rarely encountered in practice. In reality, pairs are often partially or completely mismatched due to issues like inaccurate modification texts, low-quality target images, and annotation errors. Ignoring these mismatches leads to numerous False Positive Pair (FFPs) denoted as noise pairs in the dataset, causing the model to overfit and ultimately reducing its performance. To address this problem, we propose the Noise-aware Contrastive Learning for CIR (NCL-CIR), comprising two key components: the Weight Compensation Block (WCB) and the Noise-pair Filter Block (NFB). The WCB coupled with diverse weight maps can ensure more stable token representations of multi-modal queries and target images. Meanwhile, the NFB, in conjunction with the Gaussian Mixture Model (GMM) predicts noise pairs by evaluating loss distributions, and generates soft labels correspondingly, allowing for the design of the soft-label based Noise Contrastive Estimation (NCE) loss function. Consequently, the overall architecture helps to mitigate the influence of mismatched and partially matched samples, with experimental results demonstrating that NCL-CIR achieves exceptional performance on the benchmark datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Composed Image Retrieval (CIR) seeks to find a target image using amulti-modal query, which combines an image with modification text to pinpointthe target. While recent CIR methods have shown promise, they mainly focus onexploring relationships between the query pairs (image and text) through dataaugmentation or model design. These methods often assume perfect alignmentbetween queries and target images, an idealized scenario rarely encountered inpractice. In reality, pairs are often partially or completely mismatched due toissues like inaccurate modification texts, low-quality target images, andannotation errors. Ignoring these mismatches leads to numerous False PositivePair (FFPs) denoted as noise pairs in the dataset, causing the model to overfitand ultimately reducing its performance. To address this problem, we proposethe Noise-aware Contrastive Learning for CIR (NCL-CIR), comprising two keycomponents: the Weight Compensation Block (WCB) and the Noise-pair Filter Block(NFB). The WCB coupled with diverse weight maps can ensure more stable tokenrepresentations of multi-modal queries and target images. Meanwhile, the NFB,in conjunction with the Gaussian Mixture Model (GMM) predicts noise pairs byevaluating loss distributions, and generates soft labels correspondingly,allowing for the design of the soft-label based Noise Contrastive Estimation(NCE) loss function. Consequently, the overall architecture helps to mitigatethe influence of mismatched and partially matched samples, with experimentalresults demonstrating that NCL-CIR achieves exceptional performance on thebenchmark datasets.</description>
      <author>example@mail.com (Peng Gao, Yujian Lee, Zailong Chen, Hui zhang, Xubo Liu, Yiyang Hu, Guquang Jing)</author>
      <guid isPermaLink="false">2504.04339v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>MME-Unify: A Comprehensive Benchmark for Unified Multimodal Understanding and Generation Models</title>
      <link>http://arxiv.org/abs/2504.03641v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://mme-unify.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个全面的评估框架，用于系统地评估统一多模态语言模型（U-MLLMs），并发现现有U-MLLMs在处理混合模态任务时存在性能差距。&lt;h4&gt;背景&lt;/h4&gt;现有的MLLM基准在评估U-MLLMs时面临挑战，包括缺乏标准化基准和混合模态生成基准的缺失。&lt;h4&gt;目的&lt;/h4&gt;设计一个综合的评估框架，以系统地评估U-MLLMs的性能。&lt;h4&gt;方法&lt;/h4&gt;提出的基准包括：1）标准化传统任务评估，从12个数据集中采样，涵盖10个任务和30个子任务；2）统一任务评估，引入五个测试多模态推理的新任务；3）全面模型基准测试，评估12个领先的U-MLLMs，包括Janus-Pro、EMU3、VILA-U和Gemini2-flash等。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现现有U-MLLMs在处理混合模态任务时存在显著的性能差距，突显了需要更强大的模型。&lt;h4&gt;结论&lt;/h4&gt;需要开发更强大的模型来有效处理混合模态任务。&lt;h4&gt;翻译&lt;/h4&gt;Existing MLLM benchmarks face significant challenges in evaluating UnifiedMLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditionaltasks, leading to inconsistent comparisons; 2) absence of benchmarks formixed-modality generation, which fails to assess multimodal reasoningcapabilities. We present a comprehensive evaluation framework designed tosystematically assess U-MLLMs. Our benchmark includes: Standardized TraditionalTask Evaluation. We sample from 12 datasets, covering 10 tasks with 30subtasks, ensuring consistent and fair comparisons across studies. 2. UnifiedTask Assessment. We introduce five novel tasks testing multimodal reasoning,including image editing, commonsense QA with image generation, and geometricreasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs,such as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specializedunderstanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3).Our findings reveal substantial performance gaps in existing U-MLLMs,highlighting the need for more robust models capable of handling mixed-modalitytasks effectively. The code and evaluation data can be found inhttps://mme-unify.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing MLLM benchmarks face significant challenges in evaluating UnifiedMLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditionaltasks, leading to inconsistent comparisons; 2) absence of benchmarks formixed-modality generation, which fails to assess multimodal reasoningcapabilities. We present a comprehensive evaluation framework designed tosystematically assess U-MLLMs. Our benchmark includes: Standardized TraditionalTask Evaluation. We sample from 12 datasets, covering 10 tasks with 30subtasks, ensuring consistent and fair comparisons across studies." 2. UnifiedTask Assessment. We introduce five novel tasks testing multimodal reasoning,including image editing, commonsense QA with image generation, and geometricreasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs,such as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specializedunderstanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3).Our findings reveal substantial performance gaps in existing U-MLLMs,highlighting the need for more robust models capable of handling mixed-modalitytasks effectively. The code and evaluation data can be found inhttps://mme-unify.github.io/.</description>
      <author>example@mail.com (Wulin Xie, Yi-Fan Zhang, Chaoyou Fu, Yang Shi, Bingyan Nie, Hongkai Chen, Zhang Zhang, Liang Wang, Tieniu Tan)</author>
      <guid isPermaLink="false">2504.03641v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Sparsity-Aware Communication for Distributed Graph Neural Network Training</title>
      <link>http://arxiv.org/abs/2504.04673v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的Graph Neural Networks (GNNs)训练方法，通过开发稀疏感知算法和通信避免方法，显著提高了GNN训练的效率。&lt;h4&gt;背景&lt;/h4&gt;GNNs在图数据上学习嵌入和分类非常高效，但其训练过程中通信成本成为扩展的瓶颈。&lt;h4&gt;目的&lt;/h4&gt;旨在解决GNN训练中的通信瓶颈问题。&lt;h4&gt;方法&lt;/h4&gt;1. 开发稀疏感知算法，仅传输必要的矩阵元素；2. 利用图划分模型重新排序矩阵，大幅减少传输元素的数量；3. 使用定制分区模型解决通信负载不平衡问题；4. 与通信避免方法（1.5D并行SpMM）相结合，通过复制子矩阵减少通信。&lt;h4&gt;主要发现&lt;/h4&gt;通过这些方法，实现了高达14倍的性能提升，在某些实例中甚至将通信量减少到几乎为零，实现了相对于基于通信忽略SpMM的GNN框架的通信免费并行训练。&lt;h4&gt;结论&lt;/h4&gt;提出的稀疏感知算法和通信避免方法能够有效提升GNN训练的效率，特别是在大规模并行计算环境中。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络（GNNs）是一种在图数据上学习嵌入和分类的计算高效方法。然而，GNN的训练具有低计算强度，使得通信成本成为扩展的瓶颈。稀疏矩阵与稠密矩阵乘法（SpMM）是GNN全图训练中的核心计算操作。先前的工作在并行化此操作时，主要关注无疏密感知算法，其中矩阵元素无论稀疏模式如何都会进行通信。这导致了一种可预测的通信模式，可以与计算重叠，并允许使用集体通信操作，但代价是浪费大量的带宽，通过传输不必要的数据。我们开发了稀疏感知算法，通过三种新颖的方法解决了GNN训练中的通信瓶颈。首先，我们只传输必要的矩阵元素。其次，我们利用图划分模型重新排序矩阵，大幅减少传输元素的数量。最后，我们使用定制的分区模型解决通信负载不平衡问题，最小化了总通信量和最大发送量。我们进一步将这些稀疏利用方法与通信避免方法（1.5D并行SpMM）相结合，其中子矩阵被复制以减少通信。我们探讨了这些组合优化的权衡，并在256个GPU上实现了高达14倍的性能提升，在某些实例中甚至将通信量减少到几乎为零，相对于基于通信忽略SpMM的流行GNN框架，实现了通信免费的并行训练。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are a computationally efficient method to learnembeddings and classifications on graph data. However, GNN training has lowcomputational intensity, making communication costs the bottleneck forscalability. Sparse-matrix dense-matrix multiplication (SpMM) is the corecomputational operation in full-graph training of GNNs. Previous workparallelizing this operation focused on sparsity-oblivious algorithms, wherematrix elements are communicated regardless of the sparsity pattern. This leadsto a predictable communication pattern that can be overlapped with computationand enables the use of collective communication operations at the expense ofwasting significant bandwidth by communicating unnecessary data. We developsparsity-aware algorithms that tackle the communication bottlenecks in GNNtraining with three novel approaches. First, we communicate only the necessarymatrix elements. Second, we utilize a graph partitioning model to reorder thematrix and drastically reduce the amount of communicated elements. Finally, weaddress the high load imbalance in communication with a tailored partitioningmodel, which minimizes both the total communication volume and the maximumsending volume. We further couple these sparsity-exploiting approaches with acommunication-avoiding approach (1.5D parallel SpMM) in which submatrices arereplicated to reduce communication. We explore the tradeoffs of these combinedoptimizations and show up to 14X improvement on 256 GPUs and on some instancesreducing communication to almost zero resulting in a communication-freeparallel training relative to a popular GNN framework based oncommunication-oblivious SpMM.</description>
      <author>example@mail.com (Ujjaini Mukhodopadhyay, Alok Tripathy, Oguz Selvitopi, Katherine Yelick, Aydin Buluc)</author>
      <guid isPermaLink="false">2504.04673v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Software Engineering of Cyber-Physical Systems: the Road Ahead</title>
      <link>http://arxiv.org/abs/2504.04630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  1 figure, 11 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了将基础模型，特别是大型语言模型，应用于支持各种软件工程活动，包括编码和测试。特别关注了在支持网络物理系统（CPS）的软件工程中的应用，并指出当前研究的局限性。作者提出了一个研究路线图，用于将基础模型整合到CPS软件工程的各个阶段，并强调了软件工程界面临的关键研究机会和挑战。&lt;h4&gt;背景&lt;/h4&gt;基础模型，尤其是大型语言模型，在支持软件工程活动中的应用越来越广泛。在CPS软件工程中，这些模型的应用也在增长，但相关研究仍然有限。&lt;h4&gt;目的&lt;/h4&gt;提出将基础模型，尤其是利用不同数据模态（如图像、音频）和融合多种模态的模型，整合到CPS软件工程各个阶段的研究路线图。&lt;h4&gt;方法&lt;/h4&gt;无具体的研究方法描述。&lt;h4&gt;主要发现&lt;/h4&gt;除了大型语言模型外，其他基础模型，如视觉语言模型，在支持CPS软件工程方面具有巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;软件工程界需要探索将不同类型的基础模型整合到CPS软件工程的各个阶段，并应对其中的研究机会和挑战。&lt;h4&gt;翻译&lt;/h4&gt;本文探讨了基础模型，尤其是大型语言模型，在支持各种软件工程活动中的应用，包括编码和测试。这些模型在支持网络物理系统（CPS）的软件工程中的应用也在增长。然而，这方面的研究还相对有限。作者认为，除了大型语言模型外，其他利用不同数据模态（如图像、音频）和多模态模型（融合多种模态）的基础模型，在处理多样化的数据类型时，对于支持CPS软件工程具有很大的潜力。为了解决这个问题，作者提出了一项研究路线图，用于将基础模型整合到CPS软件工程的各个阶段，并强调了软件工程界面临的关键研究机会和挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models (FMs), particularly Large Language Models (LLMs), areincreasingly used to support various software engineering activities (e.g.,coding and testing). Their applications in the software engineering ofCyber-Physical Systems (CPSs) are also growing. However, research in this arearemains limited. Moreover, existing studies have primarily focused on LLMs-onlyone type of FM-leaving ample opportunities to explore others, such asvision-language models. We argue that, in addition to LLMs, other FMs utilizingdifferent data modalities (e.g., images, audio) and multimodal models (whichintegrate multiple modalities) hold great potential for supporting CPS softwareengineering, given that these systems process diverse data types. To addressthis, we present a research roadmap for integrating FMs into various phases ofCPS software engineering, highlighting key research opportunities andchallenges for the software engineering community.</description>
      <author>example@mail.com (Chengjie Lu, Pablo Valle, Jiahui Wu, Erblin Isaku, Hassan Sartaj, Aitor Arrieta, Shaukat Ali)</author>
      <guid isPermaLink="false">2504.04630v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Graph Neural Networks for Particle Track Reconstruction</title>
      <link>http://arxiv.org/abs/2504.04670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了针对高能物理中粒子轨迹重建问题的Exa.TrkX项目，该项目通过将粒子轨迹重建转化为图上的边缘分类问题，并使用图神经网络（GNN）来生成粒子轨迹，从而减轻计算负担。然而，基于GNN的方法存在内存限制，本研究通过改进Exa.TrkX流程，提高了重建的精度和召回率，并引入了性能优化，使得实现速度提高了2倍。&lt;h4&gt;背景&lt;/h4&gt;粒子轨迹重建是高能物理中的重要问题，对于研究亚原子粒子的性质至关重要。传统的轨迹重建算法在粒子数量增加时计算效率低下。&lt;h4&gt;目的&lt;/h4&gt;提高粒子轨迹重建的计算效率，并优化GNN训练过程。&lt;h4&gt;方法&lt;/h4&gt;1. 将粒子轨迹重建转化为图上的边缘分类问题，并使用GNN生成粒子轨迹。2. 对Exa.TrkX流程进行改进，使其能够在输入粒子图的样本上训练，并提高重建的精度和召回率。3. 引入GNN训练的性能优化，以适应改进后的Exa.TrkX流程。&lt;h4&gt;主要发现&lt;/h4&gt;改进后的Exa.TrkX流程能够处理更多的粒子，提高了重建的精度和召回率，并且通过性能优化实现了2倍的速度提升。&lt;h4&gt;结论&lt;/h4&gt;通过改进Exa.TrkX流程和引入性能优化，显著提高了粒子轨迹重建的计算效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：粒子轨迹重建是高能物理（HEP）中的一个重要问题，对于研究亚原子粒子的性质是必要的。传统的轨迹重建算法在加速器内粒子数量的增加时计算效率不高。为了减轻这种计算负担，Exa.TrkX项目引入了一个将粒子轨迹重建简化为图上的边缘分类的流程，并使用图神经网络（GNN）来生成粒子轨迹。然而，这种基于GNN的方法内存限制，跳过了超过GPU内存的图。我们引入了对Exa.TrkX流程的改进，以在输入粒子图的样本上进行训练，并表明这些改进可以推广到更高的精度和召回率。此外，我们将为GNN训练引入的性能优化应用于我们增强的Exa.TrkX流程。这些优化提供了相对于我们基于PyTorch Geometric的基线实现2倍的速度提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Particle track reconstruction is an important problem in high-energy physics(HEP), necessary to study properties of subatomic particles. Traditional trackreconstruction algorithms scale poorly with the number of particles within theaccelerator. The Exa.TrkX project, to alleviate this computational burden,introduces a pipeline that reduces particle track reconstruction to edgeclassification on a graph, and uses graph neural networks (GNNs) to produceparticle tracks. However, this GNN-based approach is memory-prohibitive andskips graphs that would exceed GPU memory. We introduce improvements to theExa.TrkX pipeline to train on samples of input particle graphs, and show thatthese improvements generalize to higher precision and recall. In addition, weadapt performance optimizations, introduced for GNN training, to fit ouraugmented Exa.TrkX pipeline. These optimizations provide a $2\times$ speedupover our baseline implementation in PyTorch Geometric.</description>
      <author>example@mail.com (Alok Tripathy, Alina Lazar, Xiangyang Ju, Paolo Calafiura, Katherine Yelick, Aydin Buluc)</author>
      <guid isPermaLink="false">2504.04670v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>PIORF: Physics-Informed Ollivier-Ricci Flow for Long-Range Interactions in Mesh Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.04052v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025. Youn-Yeol Yu and Jeongwhan Choi contributed  equally to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的物理信息Ollivier-Ricci流（PIORF）方法，用于解决无结构网格上流体流动的长期依赖性问题，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;数据驱动的模拟器在无结构网格上模拟物理系统时受到长期依赖性的挑战，特别是在细化网格区域，这被称为'过度挤压'问题，阻碍了信息传播。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的重连方法，结合物理相关性和图拓扑结构，以解决流体流动中的长期依赖性问题。&lt;h4&gt;方法&lt;/h4&gt;PIORF方法利用Ollivier-Ricci曲率（ORC）识别瓶颈区域，并连接这些区域与高速度梯度节点，以实现长距离相互作用并减轻过度挤压。&lt;h4&gt;主要发现&lt;/h4&gt;PIORF在重连边方面计算效率高，可以扩展到更大规模的模拟，并且在三个流体动力学基准数据集上的实验结果显示，PIORF在性能上优于基线模型和现有的重连方法，最高提高了26.2%。&lt;h4&gt;结论&lt;/h4&gt;PIORF方法在处理流体流动中的长期依赖性方面是一种有效且高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, data-driven simulators based on graph neural networks have gainedattention in modeling physical systems on unstructured meshes. However, theystruggle with long-range dependencies in fluid flows, particularly in refinedmesh regions. This challenge, known as the 'over-squashing' problem, hindersinformation propagation. While existing graph rewiring methods address thisissue to some extent, they only consider graph topology, overlooking theunderlying physical phenomena. We propose Physics-Informed Ollivier-Ricci Flow(PIORF), a novel rewiring method that combines physical correlations with graphtopology. PIORF uses Ollivier-Ricci curvature (ORC) to identify bottleneckregions and connects these areas with nodes in high-velocity gradient nodes,enabling long-range interactions and mitigating over-squashing. Our approach iscomputationally efficient in rewiring edges and can scale to largersimulations. Experimental results on 3 fluid dynamics benchmark datasets showthat PIORF consistently outperforms baseline models and existing rewiringmethods, achieving up to 26.2 improvement.</description>
      <author>example@mail.com (Youn-Yeol Yu, Jeongwhan Choi, Jaehyeon Park, Kookjin Lee, Noseong Park)</author>
      <guid isPermaLink="false">2504.04052v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>COHESION: Composite Graph Convolutional Network with Dual-Stage Fusion for Multimodal Recommendation</title>
      <link>http://arxiv.org/abs/2504.04452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CIKM 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为COHESION的多模态推荐方法，该方法通过改进模态融合和表示学习过程来提升推荐准确度。&lt;h4&gt;背景&lt;/h4&gt;多模态推荐利用多种模态信息来应对数据稀疏性和提高推荐准确度，其中模态融合和表示学习是关键过程。&lt;h4&gt;目的&lt;/h4&gt;揭示模态融合和表示学习之间的互补性，并提高推荐系统的性能。&lt;h4&gt;方法&lt;/h4&gt;COHESION采用双阶段融合策略，在早期使用ID嵌入精炼所有模态，在晚期融合它们的表示。此外，还引入了复合图卷积网络来提取用户和物品之间的异构和同构潜在关系，并提出了一种新颖的自适应优化方法以确保跨模态的平衡和合理表示。&lt;h4&gt;主要发现&lt;/h4&gt;COHESION在处理无关信息、改善表示质量以及增强模态融合等方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;在三个广泛使用的数据集上的实验表明，COHESION在多种基线方法中具有显著的优越性。&lt;h4&gt;翻译&lt;/h4&gt;最近在多模态推荐领域的研究，利用多样化的模态信息来处理数据稀疏性并提升推荐准确性，引起了广泛关注。多模态推荐中的两个关键过程是模态融合和表示学习。以往在模态融合方面的方法通常在早期或晚期采用简单的注意力或预定义策略，未能有效处理模态间的无关信息。在表示学习方面，先前研究已经构建了包含用户-物品、用户-用户和物品-物品关系的异构和同构图结构，以更好地捕捉用户兴趣和物品特征。在以前的工作中，模态融合和表示学习被视为两个独立的过程。在本文中，我们揭示了这两个过程是互补的，并且可以相互支持。具体来说，强大的表示学习增强了模态融合，而有效的融合改善了表示质量。基于这两个过程，我们引入了一种名为COHESION的多模态推荐方法，该方法引入了双阶段融合策略以减少无关信息的影响，在早期使用ID嵌入精炼所有模态，在晚期融合它们的表示。此外，它还提出了一种复合图卷积网络，利用用户-物品、用户-用户和物品-物品图来提取用户和物品内的异构和同构潜在关系。此外，它还引入了一种新颖的自适应优化方法，以确保跨模态的平衡和合理表示。在三个广泛使用的数据集上的大量实验表明，COHESION在各种基线方法中表现出显著的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent works in multimodal recommendations, which leverage diverse modalinformation to address data sparsity and enhance recommendation accuracy, havegarnered considerable interest. Two key processes in multimodal recommendationsare modality fusion and representation learning. Previous approaches inmodality fusion often employ simplistic attentive or pre-defined strategies atearly or late stages, failing to effectively handle irrelevant informationamong modalities. In representation learning, prior research has constructedheterogeneous and homogeneous graph structures encapsulating user-item,user-user, and item-item relationships to better capture user interests anditem profiles. Modality fusion and representation learning were considered astwo independent processes in previous work. In this paper, we reveal that thesetwo processes are complementary and can support each other. Specifically,powerful representation learning enhances modality fusion, while effectivefusion improves representation quality. Stemming from these two processes, weintroduce a COmposite grapH convolutional nEtwork with dual-stage fuSION forthe multimodal recommendation, named COHESION. Specifically, it introduces adual-stage fusion strategy to reduce the impact of irrelevant information,refining all modalities using ID embedding in the early stage and fusing theirrepresentations at the late stage. It also proposes a composite graphconvolutional network that utilizes user-item, user-user, and item-item graphsto extract heterogeneous and homogeneous latent relationships within users anditems. Besides, it introduces a novel adaptive optimization to ensure balancedand reasonable representations across modalities. Extensive experiments onthree widely used datasets demonstrate the significant superiority of COHESIONover various competitive baselines.</description>
      <author>example@mail.com (Jinfeng Xu, Zheyu Chen, Wei Wang, Xiping Hu, Sang-Wook Kim, Edith C. H. Ngai)</author>
      <guid isPermaLink="false">2504.04452v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>TGraphX: Tensor-Aware Graph Neural Network for Multi-Dimensional Feature Learning</title>
      <link>http://arxiv.org/abs/2504.03953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to arXiv. Code repository:  https://github.com/arashsajjadi/TGraphX |||  https://git.cs.usask.ca/arash/tgraphx&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TGraphX通过统一卷积神经网络（CNNs）和图神经网络（GNNs）来增强视觉推理任务，实现了对空间特征提取和关系推理的桥梁。&lt;h4&gt;背景&lt;/h4&gt;传统的CNN擅长提取图像的丰富空间特征，但缺乏建模物体间关系的内在能力；而传统的GNN通常依赖于平展的节点特征，从而丢弃了重要的空间细节。&lt;h4&gt;目的&lt;/h4&gt;提出TGraphX，以克服上述限制，并提升视觉推理任务的表现。&lt;h4&gt;方法&lt;/h4&gt;TGraphX使用CNN生成多维节点特征（如(3*128*128)张量），保留局部空间语义；这些空间感知的节点参与图计算，使用1*1卷积进行消息传递，融合相邻特征的同时保持其结构；此外，使用具有残差连接的深度CNN聚合器来稳健地细化融合的消息。&lt;h4&gt;主要发现&lt;/h4&gt;TGraphX不仅连接了空间特征提取和关系推理的差距，还在物体检测细化集合推理方面表现出显著改进。&lt;h4&gt;结论&lt;/h4&gt;TGraphX为视觉推理任务提供了一种新的方法，显著提高了相关任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;TGraphX提出了一种新的深度学习范式，通过统一卷积神经网络（CNNs）和图神经网络（GNNs）来增强视觉推理任务。传统的CNN在提取图像的丰富空间特征方面表现出色，但缺乏建模物体间关系的内在能力。相反，传统的GNN通常依赖于平展的节点特征，从而丢弃了重要的空间细节。TGraphX通过使用CNN生成多维节点特征（例如（3*128*128）张量）来克服这些限制，这些节点特征保留了局部空间语义。这些空间感知的节点参与一个图，在该图中使用1*1卷积进行消息传递，融合相邻特征的同时保持其结构。此外，使用具有残差连接的深度CNN聚合器来稳健地细化融合的消息，确保稳定的梯度流和端到端的可训练性。我们的方法不仅弥合了空间特征提取和关系推理之间的差距，还在物体检测细化集合推理方面展示了显著的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; TGraphX presents a novel paradigm in deep learning by unifying convolutionalneural networks (CNNs) with graph neural networks (GNNs) to enhance visualreasoning tasks. Traditional CNNs excel at extracting rich spatial featuresfrom images but lack the inherent capability to model inter-objectrelationships. Conversely, conventional GNNs typically rely on flattened nodefeatures, thereby discarding vital spatial details. TGraphX overcomes theselimitations by employing CNNs to generate multi-dimensional node features(e.g., (3*128*128) tensors) that preserve local spatial semantics. Thesespatially aware nodes participate in a graph where message passing is performedusing 1*1 convolutions, which fuse adjacent features while maintaining theirstructure. Furthermore, a deep CNN aggregator with residual connections is usedto robustly refine the fused messages, ensuring stable gradient flow andend-to-end trainability. Our approach not only bridges the gap between spatialfeature extraction and relational reasoning but also demonstrates significantimprovements in object detection refinement and ensemble reasoning.</description>
      <author>example@mail.com (Arash Sajjadi, Mark Eramian)</author>
      <guid isPermaLink="false">2504.03953v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>MInCo: Mitigating Information Conflicts in Distracted Visual Model-based Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.04164v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MInCo的新算法，用于解决视觉MBRL中的信息冲突问题，通过使用负样本免费的对比学习，帮助学习不变表示和鲁棒策略，即使在存在任务无关的视觉干扰时也能保持性能。&lt;h4&gt;背景&lt;/h4&gt;现有的基于视觉模型的强化学习（MBRL）算法在观察重建方面往往存在信息冲突，这导致难以学习紧凑的表示，从而降低了策略的鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;揭示当前视觉MBRL算法中信息冲突的根源，并提出一种新的算法来缓解信息冲突。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的算法MInCo，通过负样本免费的对比学习来缓解信息冲突，并引入时间变化的重新加权来引导学习偏向动态建模。&lt;h4&gt;主要发现&lt;/h4&gt;信息冲突源于视觉表示学习和潜在动态建模，通过信息论视角分析得出。&lt;h4&gt;结论&lt;/h4&gt;MInCo在机器人控制任务中表现出色，能够学习对抗背景噪声的不变表示，并且优于现有的视觉MBRL方法。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Existing visual model-based reinforcement learning (MBRL) algorithms with observation reconstruction often suffer from information conflicts, making it difficult to learn compact representations and hence result in less robust policies, especially in the presence of task-irrelevant visual distractions. In this paper, we first reveal that the information conflicts in current visual MBRL algorithms stem from visual representation learning and latent dynamics modeling with an information-theoretic perspective. Based on this finding, we present a new algorithm to resolve information conflicts for visual MBRL, named MInCo, which mitigates information conflicts by leveraging negative-free contrastive learning, aiding in learning invariant representation and robust policies despite noisy observations. To prevent the dominance of visual representation learning, we introduce time-varying reweighting to bias the learning towards dynamics modeling as training proceeds. We evaluate our method on several robotic control tasks with dynamic background distractions. Our experiments demonstrate that MInCo learns invariant representations against background noise and consistently outperforms current state-of-the-art visual MBRL methods. Code is available at https://github.com/ShiguangSun/minco.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing visual model-based reinforcement learning (MBRL) algorithms withobservation reconstruction often suffer from information conflicts, making itdifficult to learn compact representations and hence result in less robustpolicies, especially in the presence of task-irrelevant visual distractions. Inthis paper, we first reveal that the information conflicts in current visualMBRL algorithms stem from visual representation learning and latent dynamicsmodeling with an information-theoretic perspective. Based on this finding, wepresent a new algorithm to resolve information conflicts for visual MBRL, namedMInCo, which mitigates information conflicts by leveraging negative-freecontrastive learning, aiding in learning invariant representation and robustpolicies despite noisy observations. To prevent the dominance of visualrepresentation learning, we introduce time-varying reweighting to bias thelearning towards dynamics modeling as training proceeds. We evaluate our methodon several robotic control tasks with dynamic background distractions. Ourexperiments demonstrate that MInCo learns invariant representations againstbackground noise and consistently outperforms current state-of-the-art visualMBRL methods. Code is available at https://github.com/ShiguangSun/minco.</description>
      <author>example@mail.com (Shiguang Sun, Hanbo Zhang, Zeyang Liu, Xinrui Yang, Lipeng Wan, Bing Yan, Xingyu Chen, Xuguang Lan)</author>
      <guid isPermaLink="false">2504.04164v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>NuScenes-SpatialQA: A Spatial Understanding and Reasoning Benchmark for Vision-Language Models in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.03164v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Vision-Language Models (VLMs) 在自动驾驶任务中有很大的潜力，但其在空间理解和推理方面的能力仍存在显著局限性。&lt;h4&gt;背景&lt;/h4&gt;目前没有系统性地评估VLMs在驾驶场景中空间推理能力的基准。&lt;h4&gt;目的&lt;/h4&gt;提出NuScenes-SpatialQA基准，专门用于评估VLMs在自动驾驶中的空间理解和推理能力。&lt;h4&gt;方法&lt;/h4&gt;在NuScenes数据集的基础上，通过自动化的3D场景图生成流程和QA生成流程构建基准。&lt;h4&gt;主要发现&lt;/h4&gt;空间增强型VLM在定性QA中表现优于其他模型，但在定量QA中不具备竞争力。&lt;h4&gt;结论&lt;/h4&gt;VLMs在空间理解和推理方面仍然面临重大挑战。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent advancements in Vision-Language Models (VLMs) have demonstrated strong potential for autonomous driving tasks. However, their spatial understanding and reasoning-key capabilities for autonomous driving-still exhibit significant limitations. Notably, none of the existing benchmarks systematically evaluate VLMs' spatial reasoning capabilities in driving scenarios. To fill this gap, we propose NuScenes-SpatialQA, the first large-scale ground-truth-based Question-Answer (QA) benchmark specifically designed to evaluate the spatial understanding and reasoning capabilities of VLMs in autonomous driving. Built upon the NuScenes dataset, the benchmark is constructed through an automated 3D scene graph generation pipeline and a QA generation pipeline. The benchmark systematically evaluates VLMs' performance in both spatial understanding and reasoning across multiple dimensions. Using this benchmark, we conduct extensive experiments on diverse VLMs, including both general and spatial-enhanced models, providing the first comprehensive evaluation of their spatial capabilities in autonomous driving. Surprisingly, the experimental results show that the spatial-enhanced VLM outperforms in qualitative QA but does not demonstrate competitiveness in quantitative QA. In general, VLMs still face considerable challenges in spatial understanding and reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Vision-Language Models (VLMs) have demonstrated strongpotential for autonomous driving tasks. However, their spatial understandingand reasoning-key capabilities for autonomous driving-still exhibit significantlimitations. Notably, none of the existing benchmarks systematically evaluateVLMs' spatial reasoning capabilities in driving scenarios. To fill this gap, wepropose NuScenes-SpatialQA, the first large-scale ground-truth-basedQuestion-Answer (QA) benchmark specifically designed to evaluate the spatialunderstanding and reasoning capabilities of VLMs in autonomous driving. Builtupon the NuScenes dataset, the benchmark is constructed through an automated 3Dscene graph generation pipeline and a QA generation pipeline. The benchmarksystematically evaluates VLMs' performance in both spatial understanding andreasoning across multiple dimensions. Using this benchmark, we conductextensive experiments on diverse VLMs, including both general andspatial-enhanced models, providing the first comprehensive evaluation of theirspatial capabilities in autonomous driving. Surprisingly, the experimentalresults show that the spatial-enhanced VLM outperforms in qualitative QA butdoes not demonstrate competitiveness in quantitative QA. In general, VLMs stillface considerable challenges in spatial understanding and reasoning.</description>
      <author>example@mail.com (Kexin Tian, Jingrui Mao, Yunlong Zhang, Jiwan Jiang, Yang Zhou, Zhengzhong Tu)</author>
      <guid isPermaLink="false">2504.03164v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Variational Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2504.04318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to NeurIPS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为VSSL（变分自监督学习）的新框架，该框架结合了变分推理和自监督学习，以实现高效的、无需解码器的表示学习。&lt;h4&gt;背景&lt;/h4&gt;传统的变分自编码器（VAEs）依赖于解码器进行输入重建，而本文提出的方法VSSL则采用不同的策略。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的学习方法，能够高效地学习数据表示，同时避免使用解码器。&lt;h4&gt;方法&lt;/h4&gt;VSSL通过耦合两个具有高斯输出的编码器，并使用动量更新的教师网络来定义一个动态的、数据依赖的前验分布。学生编码器从增强的视角生成近似的后验分布。在ELBO中的重建项被替换为跨视图去噪目标，以保持高斯KL散度的解析可处理性。此外，还引入了基于余弦的KL和似然项的公式，以增强高维潜在空间中的语义对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在CIFAR-10、CIFAR-100和ImageNet-100上的实验表明，VSSL在性能上与BYOL和MoCo V3等领先的自监督方法相当或更优。&lt;h4&gt;结论&lt;/h4&gt;VSSL提供了一种可扩展的、基于概率的方法来学习可迁移的表示，而不需要生成重建，从而弥合了变分建模和现代自监督技术之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为VSSL（变分自监督学习）的新框架，该框架结合了变分推理与自监督学习，以实现高效的、无需解码器的表示学习。与依赖于解码器进行输入重建的传统变分自编码器（VAEs）不同，VSSL对称地耦合了两个具有高斯输出的编码器。一个动量更新的教师网络定义了一个动态的、数据依赖的前验，而学生编码器从增强的视角生成近似的后验。ELBO中的重建项被替换为跨视图去噪目标，以保持高斯KL散度的解析可处理性。我们进一步引入了基于余弦的KL和似然项的公式，以增强高维潜在空间中的语义对齐。在CIFAR-10、CIFAR-100和ImageNet-100上的实验表明，VSSL在性能上与BYOL和MoCo V3等领先的自监督方法相当或更优。VSSL提供了一种可扩展的、基于概率的方法来学习可迁移的表示，而不需要生成重建，从而弥合了变分建模和现代自监督技术之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Variational Self-Supervised Learning (VSSL), a novel frameworkthat combines variational inference with self-supervised learning to enableefficient, decoder-free representation learning. Unlike traditional VAEs thatrely on input reconstruction via a decoder, VSSL symmetrically couples twoencoders with Gaussian outputs. A momentum-updated teacher network defines adynamic, data-dependent prior, while the student encoder produces anapproximate posterior from augmented views. The reconstruction term in the ELBOis replaced with a cross-view denoising objective, preserving the analyticaltractability of Gaussian KL divergence. We further introduce cosine-basedformulations of KL and log-likelihood terms to enhance semantic alignment inhigh-dimensional latent spaces. Experiments on CIFAR-10, CIFAR-100, andImageNet-100 show that VSSL achieves competitive or superior performance toleading self-supervised methods, including BYOL and MoCo V3. VSSL offers ascalable, probabilistically grounded approach to learning transferablerepresentations without generative reconstruction, bridging the gap betweenvariational modeling and modern self-supervised techniques.</description>
      <author>example@mail.com (Mehmet Can Yavuz, Berrin Yanikoglu)</author>
      <guid isPermaLink="false">2504.04318v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Directional Sign Loss: A Topology-Preserving Loss Function that Approximates the Sign of Finite Differences</title>
      <link>http://arxiv.org/abs/2504.04202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为方向符号损失（DSL）的新损失函数，用于在表示学习中保持拓扑特征，特别是在拓扑敏感数据中。&lt;h4&gt;背景&lt;/h4&gt;保持学习到的潜在空间中的关键拓扑特征是表示学习中的一个基本挑战，尤其是对于拓扑敏感数据。&lt;h4&gt;目的&lt;/h4&gt;DSL旨在通过惩罚输入和重建数据之间关键点的差异，鼓励自动编码器和其他可学习的压缩器保留原始数据的拓扑特征。&lt;h4&gt;方法&lt;/h4&gt;本文介绍了DSL的数学公式、复杂度分析和实际实现，并将其行为与不可微的对应物和其他拓扑度量进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;在单维、二维和三维数据上的实验表明，将DSL与传统损失函数相结合比单独使用传统损失函数更有效地保持拓扑特征。此外，DSL作为常见拓扑度量的可微、高效代理，使其能够在基于梯度的优化框架中使用。&lt;h4&gt;结论&lt;/h4&gt;DSL是一种有效的工具，可以帮助在表示学习中保持拓扑特征，尤其是在处理拓扑敏感数据时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Preserving critical topological features in learned latent spaces is afundamental challenge in representation learning, particularly fortopology-sensitive data. This paper introduces directional sign loss (DSL), anovel loss function that approximates the number of mismatches in the signs offinite differences between corresponding elements of two arrays. By penalizingdiscrepancies in critical points between input and reconstructed data, DSLencourages autoencoders and other learnable compressors to retain thetopological features of the original data. We present the mathematicalformulation, complexity analysis, and practical implementation of DSL,comparing its behavior to its non-differentiable counterpart and to othertopological measures. Experiments on one-, two-, and three-dimensional datashow that combining DSL with traditional loss functions preserves topologicalfeatures more effectively than traditional losses alone. Moreover, DSL servesas a differentiable, efficient proxy for common topology-based metrics,enabling its use in gradient-based optimization frameworks.</description>
      <author>example@mail.com (Harvey Dam, Tripti Agarwal, Ganesh Gopalakrishnan)</author>
      <guid isPermaLink="false">2504.04202v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Enhance Then Search: An Augmentation-Search Strategy with Foundation Models for Cross-Domain Few-Shot Object Detection</title>
      <link>http://arxiv.org/abs/2504.04517v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究展示了在大量数据集上预训练的基础模型，如GroundingDINO和LAE-DINO，在跨域小样本目标检测（CD-FSOD）任务上的出色表现，并介绍了通过图像数据增强技术和基于网格的子域搜索策略增强模型性能的方法。&lt;h4&gt;背景&lt;/h4&gt;大量数据集预训练的基础模型在跨域小样本目标检测任务中表现良好。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过数据增强和子域搜索策略提升基础模型在CD-FSOD任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;通过严格的小样本训练，采用图像数据增强方法和网格化的子域搜索策略，有效地在广阔的域空间中寻找最优子域。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法促进了小样本目标检测的效率，并提供了从基础模型中高效搜索最优参数配置的解决CD-FSOD问题的方法。&lt;h4&gt;结论&lt;/h4&gt;研究显著推动了视觉-语言模型在数据稀缺环境中的实际部署，为优化其跨域泛化能力提供了关键见解，而无需劳动密集型重新训练。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Foundation models pretrained on extensive datasets, such as GroundingDINO and LAE-DINO, have performed remarkably in the cross-domain few-shot object detection (CD-FSOD) task. Through rigorous few-shot training, we found that the integration of image-based data augmentation techniques and grid-based sub-domain search strategy significantly enhances the performance of these foundation models. Building upon GroundingDINO, we employed several widely used image augmentation methods and established optimization objectives to effectively navigate the expansive domain space in search of optimal sub-domains. This approach facilitates efficient few-shot object detection and introduces an approach to solving the CD-FSOD problem by efficiently searching for the optimal parameter configuration from the foundation model. Our findings substantially advance the practical deployment of vision-language models in data-scarce environments, offering critical insights into optimizing their cross-domain generalization capabilities without labor-intensive retraining. Code is available at https://github.com/jaychempan/ETS.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jaychempan/ETS&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models pretrained on extensive datasets, such as GroundingDINO andLAE-DINO, have performed remarkably in the cross-domain few-shot objectdetection (CD-FSOD) task. Through rigorous few-shot training, we found that theintegration of image-based data augmentation techniques and grid-basedsub-domain search strategy significantly enhances the performance of thesefoundation models. Building upon GroundingDINO, we employed several widely usedimage augmentation methods and established optimization objectives toeffectively navigate the expansive domain space in search of optimalsub-domains. This approach facilitates efficient few-shot object detection andintroduces an approach to solving the CD-FSOD problem by efficiently searchingfor the optimal parameter configuration from the foundation model. Our findingssubstantially advance the practical deployment of vision-language models indata-scarce environments, offering critical insights into optimizing theircross-domain generalization capabilities without labor-intensive retraining.Code is available at https://github.com/jaychempan/ETS.</description>
      <author>example@mail.com (Jiancheng Pan, Yanxing Liu, Xiao He, Long Peng, Jiahao Li, Yuze Sun, Xiaomeng Huang)</author>
      <guid isPermaLink="false">2504.04517v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>QE-RAG: A Robust Retrieval-Augmented Generation Benchmark for Query Entry Errors</title>
      <link>http://arxiv.org/abs/2504.04062v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QE-RAG的鲁棒RAG基准，旨在评估RAG方法在应对查询输入错误时的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管RAG方法在提高大型语言模型（LLM）的事实准确性方面得到了广泛应用，但现有基准假设用于检索的用户查询是正确的，而现实中的查询输入错误很常见。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在探索查询输入错误对RAG方法的影响，并提出改进方法。&lt;h4&gt;方法&lt;/h4&gt;作者通过在六个常用数据集中注入三种常见的查询输入错误，以20%和40%的比率模拟现实场景，分析错误对LLM输出的影响，并提出基于对比学习的鲁棒检索器训练方法和检索增强的查询纠正方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，现有的RAG方法对查询输入错误具有较差的鲁棒性，而提出的方法显著提高了RAG处理查询输入错误的鲁棒性，并且与现有RAG方法兼容，进一步提高了其鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和基准对于评估和改进RAG方法在现实世界中的表现具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：检索增强的生成（RAG）已成为提高大型语言模型（LLMs）事实准确性的广泛采用的方法。尽管当前基准从各种角度评估RAG方法的表现，但它们共享一个共同的假设，即用于检索的用户查询是无误的。然而，在用户与LLMs之间的现实交互中，查询输入错误，如键盘邻近错误、视觉相似性错误和拼写错误，很常见。这些错误对当前RAG方法的影响尚未得到充分探索。为了填补这一空白，我们提出了QE-RAG，这是第一个针对查询输入错误设计的鲁棒RAG基准。我们通过在随机选择的用户查询中注入三种常见的查询输入错误，以20%和40%的比率增强六个广泛使用的数据集，模拟典型用户行为。我们分析了这些错误对LLM输出的影响，发现损坏的查询会降低模型性能，这可以通过查询纠正和训练鲁棒的检索器来缓解。基于这些见解，我们提出了一种基于对比学习的鲁棒检索器训练方法和一个检索增强的查询纠正方法。广泛的领域内和跨领域实验表明：（1）最先进的RAG方法包括顺序、分支和迭代方法，对查询输入错误具有较差的鲁棒性；（2）我们的方法在处理查询输入错误时显著提高了RAG的鲁棒性，并且与现有RAG方法兼容，进一步提高了它们的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retriever-augmented generation (RAG) has become a widely adopted approach forenhancing the factual accuracy of large language models (LLMs). While currentbenchmarks evaluate the performance of RAG methods from various perspectives,they share a common assumption that user queries used for retrieval areerror-free. However, in real-world interactions between users and LLMs, queryentry errors such as keyboard proximity errors, visual similarity errors, andspelling errors are frequent. The impact of these errors on current RAG methodsagainst such errors remains largely unexplored. To bridge this gap, we proposeQE-RAG, the first robust RAG benchmark designed specifically to evaluateperformance against query entry errors. We augment six widely used datasets byinjecting three common types of query entry errors into randomly selected userqueries at rates of 20\% and 40\%, simulating typical user behavior inreal-world scenarios. We analyze the impact of these errors on LLM outputs andfind that corrupted queries degrade model performance, which can be mitigatedthrough query correction and training a robust retriever for retrievingrelevant documents. Based on these insights, we propose a contrastivelearning-based robust retriever training method and a retrieval-augmented querycorrection method. Extensive in-domain and cross-domain experiments revealthat: (1) state-of-the-art RAG methods including sequential, branching, anditerative methods, exhibit poor robustness to query entry errors; (2) ourmethod significantly enhances the robustness of RAG when handling query entryerrors and it's compatible with existing RAG methods, further improving theirrobustness.</description>
      <author>example@mail.com (Kepu Zhang, Zhongxiang Sun, Weijie Yu, Xiaoxue Zang, Kai Zheng, Yang Song, Han Li, Jun Xu)</author>
      <guid isPermaLink="false">2504.04062v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>MedM-VL: What Makes a Good Medical LVLM?</title>
      <link>http://arxiv.org/abs/2504.04323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于LLaVA框架的医学LVLMs的多种架构设计，构建了针对2D和3D模态的模型，旨在支持通用和特定领域的医学任务，并开发了MedM-VL代码库，发布了两个LVLM变体。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习的发展，医学图像分析从单一任务扩展到更复杂的多模态任务，如医学视觉问答和报告生成。传统的浅层和特定任务模型在处理临床实践中的复杂性和可扩展性方面越来越有限。&lt;h4&gt;目的&lt;/h4&gt;研究医学LVLMs的架构设计，构建模型以支持通用和特定领域的医学任务，并开发可复现和可扩展的代码库。&lt;h4&gt;方法&lt;/h4&gt;基于LLaVA框架，构建了针对2D和3D模态的模型，并开发了MedM-VL代码库，提供了两个LVLM变体：MedM-VL-2D和MedM-VL-CT-Chest。&lt;h4&gt;主要发现&lt;/h4&gt;提出了基于LLaVA框架的医学LVLMs的多种架构设计，并构建了支持2D和3D模态的模型，这些模型可以作为有效的基础模型。&lt;h4&gt;结论&lt;/h4&gt;医学LVLMs为处理复杂的视觉语言任务提供了统一的解决方案，MedM-VL代码库和模型为医学图像分析提供了可复现和可扩展的工具。&lt;h4&gt;翻译&lt;/h4&gt;Medical image analysis is a fundamental component. As deep learning progresses, the focus has shifted from single-task applications, such as classification and segmentation, to more complex multimodal tasks, including medical visual question answering and report generation. Traditional shallow and task-specific models are increasingly limited in addressing the complexity and scalability required in clinical practice. The emergence of large language models (LLMs) has driven the development of medical Large Vision-Language Models (LVLMs), offering a unified solution for diverse vision-language tasks. In this study, we investigate various architectural designs for medical LVLMs based on the widely adopted LLaVA framework, which follows an encoder-connector-LLM paradigm. We construct two distinct models targeting 2D and 3D modalities, respectively. These models are designed to support both general-purpose medical tasks and domain-specific fine-tuning, thereby serving as effective foundation models. To facilitate reproducibility and further research, we develop a modular and extensible codebase, MedM-VL, and release two LVLM variants: MedM-VL-2D for 2D medical image analysis and MedM-VL-CT-Chest for 3D CT-based applications. The code and models are available at: https://github.com/MSIIP/MedM-VL&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image analysis is a fundamental component. As deep learningprogresses, the focus has shifted from single-task applications, such asclassification and segmentation, to more complex multimodal tasks, includingmedical visual question answering and report generation. Traditional shallowand task-specific models are increasingly limited in addressing the complexityand scalability required in clinical practice. The emergence of large languagemodels (LLMs) has driven the development of medical Large Vision-LanguageModels (LVLMs), offering a unified solution for diverse vision-language tasks.In this study, we investigate various architectural designs for medical LVLMsbased on the widely adopted LLaVA framework, which follows anencoder-connector-LLM paradigm. We construct two distinct models targeting 2Dand 3D modalities, respectively. These models are designed to support bothgeneral-purpose medical tasks and domain-specific fine-tuning, thereby servingas effective foundation models. To facilitate reproducibility and furtherresearch, we develop a modular and extensible codebase, MedM-VL, and releasetwo LVLM variants: MedM-VL-2D for 2D medical image analysis andMedM-VL-CT-Chest for 3D CT-based applications. The code and models areavailable at: https://github.com/MSIIP/MedM-VL</description>
      <author>example@mail.com (Yiming Shi, Shaoshuai Yang, Xun Zhu, Haoyu Wang, Miao Li, Ji Wu)</author>
      <guid isPermaLink="false">2504.04323v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive and Variational Approaches in Self-Supervised Learning for Complex Data Mining</title>
      <link>http://arxiv.org/abs/2504.04032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于自监督学习的算法，通过实验验证了其在复杂数据挖掘任务中的有效性。&lt;h4&gt;背景&lt;/h4&gt;复杂数据挖掘在许多领域具有广泛的应用价值，特别是在无标签数据的特征提取和分类任务中。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种算法，并通过实验验证其在复杂数据挖掘任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;论文提出了基于自监督学习的算法，并通过实验验证了其效果。实验中使用了AdamW优化器和0.002的学习率，并通过消融实验分析了各个模块的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AdamW优化器和0.002学习率的组合在所有评估指标中表现最佳，自适应优化方法可以提高模型在复杂数据挖掘任务中的性能。对比学习、变分模块和数据增强策略在模型的泛化能力和鲁棒性方面发挥了关键作用。&lt;h4&gt;结论&lt;/h4&gt;该方法在训练过程中能够稳定收敛，有效避免严重过拟合，对不同数据集具有较强的适应性，能够有效地从无标签数据中提取高质量特征，并提高分类准确率。在复杂数据环境中，该方法仍能保持高检测精度，证明了其在复杂数据挖掘中的适用性。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is summarized as follows: This paper proposes an algorithm based on self-supervised learning and verifies its effectiveness through experiments. The study found that the combination of AdamW optimizer and 0.002 learning rate performs best in all evaluation indicators, indicating that the adaptive optimization method can improve the performance of the model in complex data mining tasks. In addition, the ablation experiment further analyzed the contribution of each module. The results show that contrastive learning, variational modules, and data augmentation strategies play a key role in the generalization ability and robustness of the model. Through the convergence curve analysis of the loss function, the experiment verifies that the method can converge stably during the training process and effectively avoid serious overfitting. Further experimental results show that the model has strong adaptability on different data sets, can effectively extract high-quality features from unlabeled data, and improves classification accuracy. At the same time, under different data distribution conditions, the method can still maintain high detection accuracy, proving its applicability in complex data environments. This study analyzed the role of self-supervised learning methods in complex data mining through systematic experiments and verified its advantages in improving feature extraction quality, optimizing classification performance, and enhancing model stability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex data mining has wide application value in many fields, especially inthe feature extraction and classification tasks of unlabeled data. This paperproposes an algorithm based on self-supervised learning and verifies itseffectiveness through experiments. The study found that in terms of theselection of optimizer and learning rate, the combination of AdamW optimizerand 0.002 learning rate performed best in all evaluation indicators, indicatingthat the adaptive optimization method can improve the performance of the modelin complex data mining tasks. In addition, the ablation experiment furtheranalyzed the contribution of each module. The results show that contrastivelearning, variational modules, and data augmentation strategies play a key rolein the generalization ability and robustness of the model. Through theconvergence curve analysis of the loss function, the experiment verifies thatthe method can converge stably during the training process and effectivelyavoid serious overfitting. Further experimental results show that the model hasstrong adaptability on different data sets, can effectively extracthigh-quality features from unlabeled data, and improves classificationaccuracy. At the same time, under different data distribution conditions, themethod can still maintain high detection accuracy, proving its applicability incomplex data environments. This study analyzed the role of self-supervisedlearning methods in complex data mining through systematic experiments andverified its advantages in improving feature extraction quality, optimizingclassification performance, and enhancing model stability</description>
      <author>example@mail.com (Yingbin Liang, Lu Dai, Shuo Shi, Minghao Dai, Junliang Du, Haige Wang)</author>
      <guid isPermaLink="false">2504.04032v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Environmental Science: A Survey of Emerging Frontiers</title>
      <link>http://arxiv.org/abs/2504.04280v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基础模型在环境科学中的应用，强调了其在预测、数据生成、数据同化、降尺度、逆建模、模型集成和跨领域决策等环境用例中的进展。&lt;h4&gt;背景&lt;/h4&gt;建模环境生态系统对于资源管理、可持续发展和理解复杂的生态过程至关重要。然而，传统的数据驱动方法在捕捉复杂和相互关联的过程方面面临挑战，并且在许多环境应用中受到有限观测数据的限制。&lt;h4&gt;目的&lt;/h4&gt;通过讨论这些新兴方法及其未来机会，旨在促进跨学科合作，加速机器学习在解决关键环境挑战中的科学发现。&lt;h4&gt;方法&lt;/h4&gt;本文详细介绍了这些模型的发展过程，包括数据收集、架构设计、训练、调整和评估。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型利用大规模预训练和复杂异构数据的通用表示，为捕捉环境过程中的时空动态和依赖关系提供了变革性的机会。&lt;h4&gt;结论&lt;/h4&gt;本文提供了对基础模型在环境科学中应用的全面概述，强调了其在不同环境用例中的进展和未来潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling environmental ecosystems is essential for effective resourcemanagement, sustainable development, and understanding complex ecologicalprocesses. However, traditional data-driven methods face challenges incapturing inherently complex and interconnected processes and are furtherconstrained by limited observational data in many environmental applications.Foundation models, which leverages large-scale pre-training and universalrepresentations of complex and heterogeneous data, offer transformativeopportunities for capturing spatiotemporal dynamics and dependencies inenvironmental processes, and facilitate adaptation to a broad range ofapplications. This survey presents a comprehensive overview of foundation modelapplications in environmental science, highlighting advancements in commonenvironmental use cases including forward prediction, data generation, dataassimilation, downscaling, inverse modeling, model ensembling, anddecision-making across domains. We also detail the process of developing thesemodels, covering data collection, architecture design, training, tuning, andevaluation. Through discussions on these emerging methods as well as theirfuture opportunities, we aim to promote interdisciplinary collaboration thataccelerates advancements in machine learning for driving scientific discoveryin addressing critical environmental challenges.</description>
      <author>example@mail.com (Runlong Yu, Shengyu Chen, Yiqun Xie, Huaxiu Yao, Jared Willard, Xiaowei Jia)</author>
      <guid isPermaLink="false">2504.04280v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Multilingual Continual Pretraining: Data Mixing for Adapting LLMs Across Languages and Resources</title>
      <link>http://arxiv.org/abs/2504.04152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统地评估了36种连续预训练（CPT）配置，旨在解决大型语言模型（LLMs）在不同语言间性能差异的问题。&lt;h4&gt;背景&lt;/h4&gt;LLMs在不同语言间的性能存在显著差异，高资源语言受益较多，而低资源语言则被边缘化。&lt;h4&gt;目的&lt;/h4&gt;评估不同CPT配置对多语言分类性能的影响，并分析不同数据策略的有效性。&lt;h4&gt;方法&lt;/h4&gt;研究涉及三种多语言基础模型，涵盖30多种语言，这些语言被分为自利、自私和停滞三种类型，并考虑了不同的资源水平。&lt;h4&gt;主要发现&lt;/h4&gt;1. 双语CPT提升了多语言分类性能，但生成过程中常出现语言混合问题；2. 在CPT过程中包含编程代码数据，能持续提升多语言分类准确率，尤其是对低资源语言，但会略微降低生成质量；3. 与先前研究不同，发现语言分类与跨语言迁移影响之间存在较大差异。&lt;h4&gt;结论&lt;/h4&gt;这些发现强调了多语言表示学习的复杂性，并突出了系统研究可推广语言分类的重要性，以指导未来的多语言CPT策略。&lt;h4&gt;翻译&lt;/h4&gt;This paper systematically evaluates 36 Continual Pretraining (CPT) configurations to address the performance disparities among different languages in Large Language Models (LLMs). The background is that LLMs exhibit significant disparities in performance across languages, with high-resource languages benefiting more while underrepresented ones are marginalized. The purpose is to assess the impact of different CPT configurations on multilingual classification performance and analyze the effectiveness of different data strategies. The study involves three multilingual base models and covers 30+ languages categorized as altruistic, selfish, and stagnant, considering various resource levels. The major findings are: 1. Bilingual CPT improves multilingual classification but often causes language mixing issues during generation; 2. Including programming code data during CPT consistently enhances multilingual classification accuracy, particularly benefiting low-resource languages, but introduces a trade-off by slightly degrading generation quality; 3. Contrary to prior work, substantial deviations from language classifications according to their impact on cross-lingual transfer are observed. These findings emphasize the complexity of multilingual representation learning and underscore the importance of systematic studies on generalizable language classification to inform future multilingual CPT strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) exhibit significant disparities in performanceacross languages, primarily benefiting high-resource languages whilemarginalizing underrepresented ones. Continual Pretraining (CPT) has emerged asa promising approach to address this imbalance, although the relativeeffectiveness of monolingual, bilingual, and code-augmented data strategiesremains unclear. This study systematically evaluates 36 CPT configurationsinvolving three multilingual base models, across 30+ languages categorized asaltruistic, selfish, and stagnant, spanning various resource levels. Ourfindings reveal three major insights: (1) Bilingual CPT improves multilingualclassification but often causes language mixing issues during generation. (2)Including programming code data during CPT consistently enhances multilingualclassification accuracy, particularly benefiting low-resource languages, butintroduces a trade-off by slightly degrading generation quality. (3) Contraryto prior work, we observe substantial deviations from language classificationsaccording to their impact on cross-lingual transfer: Languages classified asaltruistic often negatively affect related languages, selfish languages showconditional and configuration-dependent behavior, and stagnant languagesdemonstrate surprising adaptability under certain CPT conditions. These nuancedinteractions emphasize the complexity of multilingual representation learning,underscoring the importance of systematic studies on generalizable languageclassification to inform future multilingual CPT strategies.</description>
      <author>example@mail.com (Zihao Li, Shaoxiong Ji, Hengyu Luo, Jörg Tiedemann)</author>
      <guid isPermaLink="false">2504.04152v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Pathology Foundation Model: Progress and Future Directions</title>
      <link>http://arxiv.org/abs/2504.04045v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了病理学计算领域中，基于大规模病理学数据预训练的病理学基础模型（PFMs）在自动癌症诊断中的应用。这些模型在特征提取和聚合方面性能显著提升，但缺乏系统分析框架。&lt;h4&gt;背景&lt;/h4&gt;计算病理学利用全切片图像进行自动化癌症诊断，其性能依赖于特征提取器和聚合器。PFMs在特征提取和聚合方面有显著提升，但缺乏系统分析框架。&lt;h4&gt;目的&lt;/h4&gt;提出一个通过自顶向下哲学组织PFMs的分层分类法，用于分析任何领域的FMs，并对PFM评估任务进行系统分类。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种组织PFMs的分类法，并系统地将PFM评估任务分为切片级、区域级、多模态和生物学任务，提供了全面的基准评估标准。&lt;h4&gt;主要发现&lt;/h4&gt;分析确定了PFM开发（病理学特定方法、端到端预训练、数据-模型可扩展性）和利用（有效适应、模型维护）中的关键挑战。&lt;h4&gt;结论&lt;/h4&gt;本文为未来PFM领域的发展指明了方向，并提供了相关的资源链接。&lt;h4&gt;翻译&lt;/h4&gt;This survey reviews the application of Pathology Foundation Models (PFMs) in the field of computational pathology for automated cancer diagnosis, which rely on large-scale histopathology data for pretraining and have significantly enhanced the capabilities of extractors and aggregators, but lack systematic analysis frameworks. This paper proposes a hierarchical taxonomy to organize PFMs through a top-down philosophy, which can be used to analyze FMs in any domain, and systematically categorizes PFM evaluation tasks into slide-level, patch-level, multimodal, and biological tasks, providing comprehensive benchmarking criteria. The analysis identifies critical challenges in both PFM development (pathology-specific methodology, end-to-end pretraining, data-model scalability) and utilization (effective adaptation, model maintenance), paving the way for future directions in this promising field. The resources referenced in this survey are available at https://github.com/BearCleverProud/AwesomeWSI.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computational pathology, analyzing whole slide images for automated cancerdiagnosis, relies on the multiple instance learning framework where performanceheavily depends on the feature extractor and aggregator. Recent PathologyFoundation Models (PFMs), pretrained on large-scale histopathology data, havesignificantly enhanced capabilities of extractors and aggregators but lacksystematic analysis frameworks. This survey presents a hierarchical taxonomyorganizing PFMs through a top-down philosophy that can be utilized to analyzeFMs in any domain: model scope, model pretraining, and model design.Additionally, we systematically categorize PFM evaluation tasks intoslide-level, patch-level, multimodal, and biological tasks, providingcomprehensive benchmarking criteria. Our analysis identifies criticalchallenges in both PFM development (pathology-specific methodology, end-to-endpretraining, data-model scalability) and utilization (effective adaptation,model maintenance), paving the way for future directions in this promisingfield. Resources referenced in this survey are available athttps://github.com/BearCleverProud/AwesomeWSI.</description>
      <author>example@mail.com (Conghao Xiong, Hao Chen, Joseph J. Y. Sung)</author>
      <guid isPermaLink="false">2504.04045v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Transformer representation learning is necessary for dynamic multi-modal physiological data on small-cohort patients</title>
      <link>http://arxiv.org/abs/2504.04120v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer表示模型和传统机器学习算法的术后谵妄（POD）预测框架，利用多模态生理数据，包括aEEG、生命体征、心电图监测数据和血流动力学参数，以提高POD的早期和准确诊断。&lt;h4&gt;背景&lt;/h4&gt;术后谵妄是高风险手术患者中常见的一种严重神经精神并发症，其诊断在重症监护室（ICUs）中因主观监测方法而存在显著误诊。&lt;h4&gt;目的&lt;/h4&gt;旨在通过提出一种POD预测框架，实现POD的早期和准确诊断。&lt;h4&gt;方法&lt;/h4&gt;该方法包括使用Transformer表示模型和传统机器学习算法，并利用多模态生理数据进行预测。研究还构建了首个包含两种患者类型的POD多模态数据集，并评估了不同的Transformer架构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，使用Transformer表示，特别是Pathformer的融合自适应方法，在患者TYPE I中提高了敏感性和Youden指数。研究强调了从术后第1天到第3天进行有效谵妄诊断的潜力，以及通过多模态Transformer架构进行表示学习的必要性。&lt;h4&gt;结论&lt;/h4&gt;多模态生理数据和通过多模态Transformer架构进行表示学习在临床诊断中具有潜在价值，有助于提高术后谵妄的早期诊断准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Postoperative delirium (POD), a severe neuropsychiatric complicationaffecting nearly 50% of high-risk surgical patients, is defined as an acutedisorder of attention and cognition, It remains significantly underdiagnosed inthe intensive care units (ICUs) due to subjective monitoring methods. Early andaccurate diagnosis of POD is critical and achievable. Here, we propose a PODprediction framework comprising a Transformer representation model followed bytraditional machine learning algorithms. Our approaches utilizes multi-modalphysiological data, including amplitude-integrated electroencephalography(aEEG), vital signs, electrocardiographic monitor data as well as hemodynamicparameters. We curated the first multi-modal POD dataset encompassing twopatient types and evaluated the various Transformer architectures forrepresentation learning. Empirical results indicate a consistent improvementsof sensitivity and Youden index in patient TYPE I using Transformerrepresentations, particularly our fusion adaptation of Pathformer. By enablingeffective delirium diagnosis from postoperative day 1 to 3, our extensiveexperimental findings emphasize the potential of multi-modal physiological dataand highlight the necessity of representation learning via multi-modalTransformer architecture in clinical diagnosis.</description>
      <author>example@mail.com (Bingxu Wang, Kunzhi Cai, Yuqi Zhang, Yachong Guo)</author>
      <guid isPermaLink="false">2504.04120v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>UniRVQA: A Unified Framework for Retrieval-Augmented Vision Question Answering via Self-Reflective Joint Training</title>
      <link>http://arxiv.org/abs/2504.04065v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的检索增强视觉问答（UniRVQA）框架，用于解决复杂视觉问答问题，并在回答准确性方面取得显著提升。&lt;h4&gt;背景&lt;/h4&gt;现有的知识图谱视觉问答（KB-VQA）系统通常使用独立的检索器和生成器，这限制了参数知识共享，且在多模态信息集成方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出UniRVQA框架，以适应精细粒度的知识密集型任务，并在统一的框架内实现跨任务的参数知识共享。&lt;h4&gt;方法&lt;/h4&gt;UniRVQA使用通用多模态预训练模型，并引入反思回答机制以评估和优化知识边界，同时整合延迟交互到检索增强生成联合训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;UniRVQA在回答准确性方面实现了与现有最先进模型的竞争力，比基线模型提升了4.7%，并将基础的多语言语言模型（MLLMs）的VQA性能平均提升了7.5%。&lt;h4&gt;结论&lt;/h4&gt;UniRVQA框架通过有效集成多模态信息和参数知识共享，显著提高了知识密集型视觉问答系统的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge-based Vision Question Answering (KB-VQA) systems address complexvisual-grounded questions requiring external knowledge, such as web-sourcedencyclopedia articles. Existing methods often use sequential and separateframeworks for the retriever and the generator with limited parametricknowledge sharing. However, since both retrieval and generation tasks requireaccurate understanding of contextual and external information, such separationcan potentially lead to suboptimal system performance. Another key challenge isthe integration of multimodal information. General-purpose multimodalpre-trained models, while adept at multimodal representation learning, strugglewith fine-grained retrieval required for knowledge-intensive visual questions.Recent specialized pre-trained models mitigate the issue, but arecomputationally expensive. To bridge the gap, we propose a UnifiedRetrieval-Augmented VQA framework (UniRVQA). UniRVQA adapts general multimodalpre-trained models for fine-grained knowledge-intensive tasks within a unifiedframework, enabling cross-task parametric knowledge sharing and the extensionof existing multimodal representation learning capability. We further introducea reflective-answering mechanism that allows the model to explicitly evaluateand refine its knowledge boundary. Additionally, we integrate late interactioninto the retrieval-augmented generation joint training process to enhancefine-grained understanding of queries and documents. Our approach achievescompetitive performance against state-of-the-art models, delivering asignificant 4.7% improvement in answering accuracy, and brings an average 7.5%boost in base MLLMs' VQA performance.</description>
      <author>example@mail.com (Jiaqi Deng, Kaize Shi, Zonghan Wu, Huan Huo, Dingxian Wang, Guandong Xu)</author>
      <guid isPermaLink="false">2504.04065v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Re-thinking Temporal Search for Long-Form Video Understanding</title>
      <link>http://arxiv.org/abs/2504.02259v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025; A real-world long video needle-in-haystack  benchmark; long-video QA with human ref frames&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了长视频理解中的时间搜索范式，并针对当前最先进的长期上下文视觉语言模型（VLMs）存在的根本问题提出了解决方案。&lt;h4&gt;背景&lt;/h4&gt;长视频理解在计算机视觉中是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提高时间搜索的质量和效率。&lt;h4&gt;方法&lt;/h4&gt;将时间搜索问题定义为长视频海棉问题，并引入了LV-Haystack数据集；提出了一种轻量级的时间搜索框架T*，该框架借鉴了图像视觉搜索技术，并引入了自适应缩放机制。&lt;h4&gt;主要发现&lt;/h4&gt;在LV-Haystack数据集上，当前最先进的方法在时间搜索能力上存在显著差距，仅达到2.1%的时间F1分数；T*框架与现有方法的结合显著提高了长视频理解能力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高长视频理解的效果，并提供了代码、基准和模型。&lt;h4&gt;翻译&lt;/h4&gt;Efficiently understanding long-form videos remains a significant challenge in computer vision. In this work, we revisit temporal search paradigms for long-form video understanding and address a fundamental issue pertaining to all state-of-the-art (SOTA) long-context vision-language models (VLMs). Our contributions are twofold: First, we frame temporal search as a Long Video Haystack problem: finding a minimal set of relevant frames (e.g., one to five) from tens of thousands based on specific queries. Upon this formulation, we introduce LV-Haystack, the first dataset with 480 hours of videos, 15,092 human-annotated instances for both training and evaluation aiming to improve temporal search quality and efficiency. Results on LV-Haystack highlight a significant research gap in temporal search capabilities, with current SOTA search methods only achieving 2.1% temporal F1 score on the Longvideo bench subset. Next, inspired by visual search in images, we propose a lightweight temporal search framework, T* that reframes costly temporal search as spatial search. T* leverages powerful visual localization techniques commonly used in images and introduces an adaptive zooming-in mechanism that operates across both temporal and spatial dimensions. Extensive experiments show that integrating T* with existing methods significantly improves SOTA long-form video understanding. Under an inference budget of 32 frames, T* improves GPT-4o's performance from 50.5% to 53.1% and LLaVA-OneVision-OV-72B's performance from 56.5% to 62.4% on the Longvideo bench XL subset. Our code, benchmark, and models are provided in the Supplementary material.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficiently understanding long-form videos remains a significant challenge incomputer vision. In this work, we revisit temporal search paradigms forlong-form video understanding and address a fundamental issue pertaining to allstate-of-the-art (SOTA) long-context vision-language models (VLMs). Ourcontributions are twofold: First, we frame temporal search as a Long VideoHaystack problem: finding a minimal set of relevant frames (e.g., one to five)from tens of thousands based on specific queries. Upon this formulation, weintroduce LV-Haystack, the first dataset with 480 hours of videos, 15,092human-annotated instances for both training and evaluation aiming to improvetemporal search quality and efficiency. Results on LV-Haystack highlight asignificant research gap in temporal search capabilities, with current SOTAsearch methods only achieving 2.1% temporal F1 score on the Longvideobenchsubset. Next, inspired by visual search in images, we propose a lightweighttemporal search framework, T* that reframes costly temporal search as spatialsearch. T* leverages powerful visual localization techniques commonly used inimages and introduces an adaptive zooming-in mechanism that operates acrossboth temporal and spatial dimensions. Extensive experiments show thatintegrating T* with existing methods significantly improves SOTA long-formvideo understanding. Under an inference budget of 32 frames, T* improvesGPT-4o's performance from 50.5% to 53.1% and LLaVA-OneVision-OV-72B'sperformance from 56.5% to 62.4% on the Longvideobench XL subset. Our code,benchmark, and models are provided in the Supplementary material.</description>
      <author>example@mail.com (Jinhui Ye, Zihan Wang, Haosen Sun, Keshigeyan Chandrasegaran, Zane Durante, Cristobal Eyzaguirre, Yonatan Bisk, Juan Carlos Niebles, Ehsan Adeli, Li Fei-Fei, Jiajun Wu, Manling Li)</author>
      <guid isPermaLink="false">2504.02259v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Time Series: A Survey</title>
      <link>http://arxiv.org/abs/2504.04011v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于Transformer的基础模型在时间序列分析中的应用，并提出了一个新的分类法来对这些模型进行分类。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型在时间序列分析领域已成为主流范式，其在预测、异常检测、分类、趋势分析等任务中表现出前所未有的能力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供一个全面概述当前最先进的时间序列分析预训练基础模型，并引入一个新颖的分类法来对这些模型进行分类。&lt;h4&gt;方法&lt;/h4&gt;通过分析模型的架构设计、预测类型、时间序列类型、模型规模和复杂度以及训练阶段使用的目标函数等多个维度对模型进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;分类法区分了基于补丁表示和直接操作原始序列的模型，以及提供概率或确定性预测的模型，以及能够处理单变量或多变量时间序列的模型。此外，还突出了轻量级架构和大规模基础模型之间的差异。&lt;h4&gt;结论&lt;/h4&gt;本文为研究人员和实践者提供了一个资源，提供了对当前趋势的见解，并确定了基于Transformer的时间序列建模未来研究的有希望的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based foundation models have emerged as a dominant paradigm intime series analysis, offering unprecedented capabilities in tasks such asforecasting, anomaly detection, classification, trend analysis and many moretime series analytical tasks. This survey provides a comprehensive overview ofthe current state of the art pre-trained foundation models, introducing a noveltaxonomy to categorize them across several dimensions. Specifically, weclassify models by their architecture design, distinguishing between thoseleveraging patch-based representations and those operating directly on rawsequences. The taxonomy further includes whether the models provideprobabilistic or deterministic predictions, and whether they are designed towork with univariate time series or can handle multivariate time series out ofthe box. Additionally, the taxonomy encompasses model scale and complexity,highlighting differences between lightweight architectures and large-scalefoundation models. A unique aspect of this survey is its categorization by thetype of objective function employed during training phase. By synthesizingthese perspectives, this survey serves as a resource for researchers andpractitioners, providing insights into current trends and identifying promisingdirections for future research in transformer-based time series modeling.</description>
      <author>example@mail.com (Siva Rama Krishna Kottapalli, Karthik Hubli, Sandeep Chandrashekhara, Garima Jain, Sunayana Hubli, Gayathri Botla, Ramesh Doddaiah)</author>
      <guid isPermaLink="false">2504.04011v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>VideoComp: Advancing Fine-Grained Compositional and Temporal Alignment in Video-Text Models</title>
      <link>http://arxiv.org/abs/2504.03970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025, project page at  https://github.com/google-deepmind/video_comp&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出VideoComp，一个用于提升视频-文本组成性理解的基准和学习框架，旨在改善视觉语言模型（VLMs）在精细时间对齐方面的性能。&lt;h4&gt;背景&lt;/h4&gt;现有基准主要关注静态图像-文本组成性或独立单事件视频，而VideoComp旨在解决连续多事件视频中的对齐问题。&lt;h4&gt;目的&lt;/h4&gt;通过构建两个组成性基准ActivityNet-Comp和YouCook2-Comp，测试模型在扩展且连贯的视频-文本序列中的组成性敏感性。&lt;h4&gt;方法&lt;/h4&gt;利用具有时间定位事件字幕的视频-文本数据集，构建基准，并创建具有微妙时间干扰的负样本，如重新排序、动作词替换、部分字幕和组合干扰。提出层次化成对偏好损失，强化与时间准确对的对齐，并逐渐惩罚越来越被破坏的对齐，以鼓励精细的组成性学习。为了缓解密集标注视频数据的有限可用性，引入预训练策略，通过连接短视频-字幕对来模拟多事件序列。&lt;h4&gt;主要发现&lt;/h4&gt;在基准上评估视频-文本基础模型和大型多模态模型（LMMs），识别了组成性方面的优势和改进领域。&lt;h4&gt;结论&lt;/h4&gt;VideoComp提供了一个全面的框架，用于评估和增强模型在实现精细、时间一致的视频-文本对齐方面的能力。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了VideoComp，这是一个旨在提升视频-文本组成性理解的基准和学习框架，目标是改善视觉语言模型（VLMs）在精细时间对齐方面的性能。与现有基准不同，这些基准主要关注静态图像-文本组成性或独立单事件视频，我们的基准针对连续多事件视频中的对齐。利用具有时间定位事件字幕的视频-文本数据集（例如ActivityNet-Captions，YouCook2），我们构建了两个组成性基准，ActivityNet-Comp和YouCook2-Comp。我们创建了具有微妙时间干扰的负样本，如重新排序、动作词替换、部分字幕和组合干扰。这些基准全面测试了模型在扩展、连贯的视频-文本序列中的组成性敏感性。为了提高模型性能，我们提出了一个层次化成对偏好损失，它强化了与时间准确对的对齐，并逐渐惩罚越来越被破坏的对齐，鼓励精细的组成性学习。为了缓解密集标注视频数据的有限可用性，我们引入了一种预训练策略，通过连接短视频-字幕对来模拟多事件序列。我们在我们的基准上评估了视频-文本基础模型和大型多模态模型（LMMs），确定了组成性方面的优势和改进领域。总的来说，我们的工作提供了一个全面的框架，用于评估和增强模型在实现精细、时间一致的视频-文本对齐方面的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce VideoComp, a benchmark and learning framework for advancingvideo-text compositionality understanding, aimed at improving vision-languagemodels (VLMs) in fine-grained temporal alignment. Unlike existing benchmarksfocused on static image-text compositionality or isolated single-event videos,our benchmark targets alignment in continuous multi-event videos. Leveragingvideo-text datasets with temporally localized event captions (e.g.ActivityNet-Captions, YouCook2), we construct two compositional benchmarks,ActivityNet-Comp and YouCook2-Comp. We create challenging negative samples withsubtle temporal disruptions such as reordering, action word replacement,partial captioning, and combined disruptions. These benchmarks comprehensivelytest models' compositional sensitivity across extended, cohesive video-textsequences. To improve model performance, we propose a hierarchical pairwisepreference loss that strengthens alignment with temporally accurate pairs andgradually penalizes increasingly disrupted ones, encouraging fine-grainedcompositional learning. To mitigate the limited availability of denselyannotated video data, we introduce a pretraining strategy that concatenatesshort video-caption pairs to simulate multi-event sequences. We evaluatevideo-text foundational models and large multimodal models (LMMs) on ourbenchmark, identifying both strengths and areas for improvement incompositionality. Overall, our work provides a comprehensive framework forevaluating and enhancing model capabilities in achieving fine-grained,temporally coherent video-text alignment.</description>
      <author>example@mail.com (Dahun Kim, AJ Piergiovanni, Ganesh Mallya, Anelia Angelova)</author>
      <guid isPermaLink="false">2504.03970v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Is Temporal Prompting All We Need For Limited Labeled Action Recognition?</title>
      <link>http://arxiv.org/abs/2504.01890v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in CVPR-W 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，视频理解取得了显著进步，这主要得益于大规模标注数据集的可用性。本文提出了一种名为TP-CLIP的CLIP模型改编，它利用时间视觉提示进行时间适应，而无需修改CLIP的核心架构，从而保持了其泛化能力。&lt;h4&gt;背景&lt;/h4&gt;视频理解的发展依赖于大规模标注数据集，而视觉-语言模型在基于对比预训练的基础上在零样本任务中表现出良好的泛化能力，有助于克服对标注数据集的依赖。&lt;h4&gt;目的&lt;/h4&gt;提出TP-CLIP模型，旨在为视频数据提供一种高效且参数较少的时间适应方法，同时保持CLIP模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;TP-CLIP通过修改视觉-语言模型的架构以适应视频数据，同时利用时间视觉提示进行时间适应，而不改变CLIP的核心架构。&lt;h4&gt;主要发现&lt;/h4&gt;TP-CLIP在零样本和少样本学习任务中表现出高效性，参数和计算效率优于现有方法。与最新的最先进方法相比，TP-CLIP只需要1/3的GFLOPs和1/28的可调参数数量，但在性能上可以超过15.8%。&lt;h4&gt;结论&lt;/h4&gt;TP-CLIP是一种高效且参数较少的视频理解方法，在保持CLIP模型泛化能力的同时，显著提高了零样本和少样本学习任务中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding has shown remarkable improvements in recent years,largely dependent on the availability of large scaled labeled datasets. Recentadvancements in visual-language models, especially based on contrastivepretraining, have shown remarkable generalization in zero-shot tasks, helpingto overcome this dependence on labeled datasets. Adaptations of such models forvideos, typically involve modifying the architecture of vision-language modelsto cater to video data. However, this is not trivial, since such adaptationsare mostly computationally intensive and struggle with temporal modeling. Wepresent TP-CLIP, an adaptation of CLIP that leverages temporal visual promptingfor temporal adaptation without modifying the core CLIP architecture. Thispreserves its generalization abilities. TP-CLIP efficiently integrates into theCLIP architecture, leveraging its pre-trained capabilities for video data.Extensive experiments across various datasets demonstrate its efficacy inzero-shot and few-shot learning, outperforming existing approaches with fewerparameters and computational efficiency. In particular, we use just 1/3 theGFLOPs and 1/28 the number of tuneable parameters in comparison to recentstate-of-the-art and still outperform it by up to 15.8% depending on the taskand dataset.</description>
      <author>example@mail.com (Shreyank N Gowda, Boyan Gao, Xiao Gu, Xiaobo Jin)</author>
      <guid isPermaLink="false">2504.01890v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Can ChatGPT Learn My Life From a Week of First-Person Video?</title>
      <link>http://arxiv.org/abs/2504.03857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过穿戴相机设备收集个人生活数据，研究预训练模型对个人生活信息的学习能力。&lt;h4&gt;背景&lt;/h4&gt;随着生成式AI和可穿戴相机设备（如智能眼镜和AI增强别针）的进步，研究模型从第一人称相机数据中学习个人生活信息的能力成为可能。&lt;h4&gt;目的&lt;/h4&gt;探究预训练模型通过第一人称相机数据了解穿戴者个人生活的能力。&lt;h4&gt;方法&lt;/h4&gt;作者穿戴相机头显54小时，生成不同长度的摘要（如分钟级、小时级和日级摘要），并在生成的摘要层次结构上微调GPT-4o和GPT-4o-mini模型。通过查询微调后的模型，了解模型学到了什么。&lt;h4&gt;主要发现&lt;/h4&gt;两个模型都学会了关于作者的基本信息（如大致年龄、性别）。GPT-4o正确推断出作者住在匹兹堡，是CMU的博士生，是右撇子，并且有宠物猫。然而，两个模型都存在幻觉，并为视频中出现的个体编造名字。&lt;h4&gt;结论&lt;/h4&gt;预训练模型可以从个人生活数据中学习基本信息，但存在幻觉问题。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the ability of pre-trained models to learn about individuals' personal lives through first-person camera data, using wearable camera devices and generating summaries of various lengths. The results show that the models can learn basic information but suffer from hallucinations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by recent improvements in generative AI and wearable camera devices(e.g. smart glasses and AI-enabled pins), I investigate the ability offoundation models to learn about the wearer's personal life throughfirst-person camera data. To test this, I wore a camera headset for 54 hoursover the course of a week, generated summaries of various lengths (e.g.minute-long, hour-long, and day-long summaries), and fine-tuned both GPT-4o andGPT-4o-mini on the resulting summary hierarchy. By querying the fine-tunedmodels, we are able to learn what the models learned about me. The results aremixed: Both models learned basic information about me (e.g. approximate age,gender). Moreover, GPT-4o correctly deduced that I live in Pittsburgh, am a PhDstudent at CMU, am right-handed, and have a pet cat. However, both models alsosuffered from hallucination and would make up names for the individuals presentin the video footage of my life.</description>
      <author>example@mail.com (Keegan Harris)</author>
      <guid isPermaLink="false">2504.03857v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Biologically Inspired Hierarchical Temporal Memory with Hardware-Accelerated Reflex Memory</title>
      <link>http://arxiv.org/abs/2504.03746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种加速层次时间记忆（AHTM）系统，通过引入反射记忆（RM）块来提高第一阶推理的速度，从而在处理重复信息时比原始的层次时间记忆（HTM）系统更高效，同时仍支持多阶推理。&lt;h4&gt;背景&lt;/h4&gt;随着物联网的快速扩张，产生了大量数据，需要高效的无监督学习系统来处理这些数据。&lt;h4&gt;目的&lt;/h4&gt;提高层次时间记忆（HTM）算法处理第一阶推理的速度，并保持多阶推理的能力。&lt;h4&gt;方法&lt;/h4&gt;设计了一个反射记忆（RM）块，该块受到脊髓工作机制的启发，以加速第一阶推理。将RM块与HTM结合形成AHTM系统，并在内容可寻址内存（CAM）块中实现硬件加速版本（H-AHTM）。&lt;h4&gt;主要发现&lt;/h4&gt;AHTM模块预测事件的时间缩短至0.125秒，而H-AHTM模块仅需0.094秒，与原始算法相比，AHTM加速了推理速度至7.55倍，而H-AHTM进一步提高了性能，速度提升了10.10倍。&lt;h4&gt;结论&lt;/h4&gt;AHTM和H-AHTM系统通过优化HTM算法，显著提高了数据处理和预测的速度，为物联网等应用提供了更高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid expansion of the Internet of Things (IoT) generates zettabytes ofdata that demand efficient unsupervised learning systems. Hierarchical TemporalMemory (HTM), a third-generation unsupervised AI algorithm, models theneocortex of the human brain by simulating columns of neurons to process andpredict sequences. These neuron columns can memorize and infer sequences acrossmultiple orders. While multiorder inferences offer robust predictivecapabilities, they often come with significant computational overhead. TheSequence Memory (SM) component of HTM, which manages these inferences,encounters bottlenecks primarily due to its extensive programmableinterconnects. In many cases, it has been observed that first-order temporalrelationships have proven to be sufficient without any significant loss inefficiency. This paper introduces a Reflex Memory (RM) block, inspired by theSpinal Cord's working mechanisms, designed to accelerate the processing offirst-order inferences. The RM block performs these inferences significantlyfaster than the SM. The integration of RM with HTM forms a system called theAccelerated Hierarchical Temporal Memory (AHTM), which processes repetitiveinformation more efficiently than the original HTM while still supportingmultiorder inferences. The experimental results demonstrate that the HTMpredicts an event in 0.945 s, whereas the AHTM module does so in 0.125 s.Additionally, the hardware implementation of RM in a content-addressable memory(CAM) block, known as Hardware-Accelerated Hierarchical Temporal Memory(H-AHTM), predicts an event in just 0.094 s, significantly improving inferencespeed. Compared to the original algorithm \cite{bautista2020matlabhtm}, AHTMaccelerates inference by up to 7.55x, while H-AHTM further enhances performancewith a 10.10x speedup.</description>
      <author>example@mail.com (Pavia Bera, Sabrina Hassan Moon, Jennifer Adorno, Dayane Alfenas Reis, Sanjukta Bhanja)</author>
      <guid isPermaLink="false">2504.03746v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Semantic-guided Representation Learning for Multi-Label Recognition</title>
      <link>http://arxiv.org/abs/2504.03801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in ICME2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SigRL的语义引导表示学习方法，用于解决多标签识别（MLR）中的挑战，并在多个MLR基准测试中显示出优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;多标签识别在复杂场景中优于单标签分类，但面临着标注所有相关类别的不确定性问题，且现有的基于视觉和语言预训练的方法在处理零样本MLR任务时，存在语义信息不足的问题。&lt;h4&gt;目的&lt;/h4&gt;通过引入SigRL方法，旨在提高模型学习有效视觉和文本表示的能力，从而改善视觉图像和类别之间的下游对齐。&lt;h4&gt;方法&lt;/h4&gt;SigRL方法包括三个模块：基于图的多标签相关性模块（GMC），用于丰富多标签文本的语义表示；语义视觉特征重建模块（SVFR），通过集成学习到的文本表示来增强视觉表示中的语义信息；以及利用局部和全局特征优化VLP模型的图像-文本匹配能力。&lt;h4&gt;主要发现&lt;/h4&gt;SigRL在零样本MLR（包含未见过的标签）和单正多标签学习（包含有限标签）的多个MLR基准测试中，比现有方法表现出更优的性能。&lt;h4&gt;结论&lt;/h4&gt;SigRL方法通过引入新的模块和优化策略，有效提高了多标签识别的性能，为MLR任务提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为SigRL的语义引导表示学习方法，用于解决多标签识别（MLR）中的挑战，并在多个MLR基准测试中显示出优于现有方法的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-label Recognition (MLR) involves assigning multiple labels to each datainstance in an image, offering advantages over single-label classification incomplex scenarios. However, it faces the challenge of annotating all relevantcategories, often leading to uncertain annotations, such as unseen orincomplete labels. Recent Vision and Language Pre-training (VLP) based methodshave made significant progress in tackling zero-shot MLR tasks by leveragingrich vision-language correlations. However, the correlation between multi-labelsemantics has not been fully explored, and the learned visual features oftenlack essential semantic information. To overcome these limitations, weintroduce a Semantic-guided Representation Learning approach (SigRL) thatenables the model to learn effective visual and textual representations,thereby improving the downstream alignment of visual images and categories.Specifically, we first introduce a graph-based multi-label correlation module(GMC) to facilitate information exchange between labels, enriching the semanticrepresentation across the multi-label texts. Next, we propose a Semantic VisualFeature Reconstruction module (SVFR) to enhance the semantic information in thevisual representation by integrating the learned textual representation duringreconstruction. Finally, we optimize the image-text matching capability of theVLP model using both local and global features to achieve zero-shot MLR.Comprehensive experiments are conducted on several MLR benchmarks, encompassingboth zero-shot MLR (with unseen labels) and single positive multi-labellearning (with limited labels), demonstrating the superior performance of ourapproach compared to state-of-the-art methods. The code is available athttps://github.com/MVL-Lab/SigRL.</description>
      <author>example@mail.com (Ruhui Zhang, Hezhe Qiao, Pengcheng Xu, Mingsheng Shang, Lin Chen)</author>
      <guid isPermaLink="false">2504.03801v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>A High-Speed Time-Optimal Trajectory Generation Strategy via a Two-layer Planning Model</title>
      <link>http://arxiv.org/abs/2503.11072v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对优化基于实时运动规划在无人机、机械臂和火箭等领域的应用，提出了一个针对智能地面车辆的分层轨迹生成算法。&lt;h4&gt;背景&lt;/h4&gt;优化基于实时运动规划在处理非凸性和非线性规划算法限制时变得具有挑战性，特别是非线性动态、避障约束和非凸输入等因素的加剧。&lt;h4&gt;目的&lt;/h4&gt;为了提高鲁棒性和减少计算负担，提出了一种使用凸优化方法的分层轨迹生成算法，旨在为轨迹优化提供实时保证并提高运动预测的计算速度。&lt;h4&gt;方法&lt;/h4&gt;该方法将原始问题分解为基于小时间窗的规划周期，每个周期在一系列由定制搜索算法增量构建的受限凸集合中求解。&lt;h4&gt;主要发现&lt;/h4&gt;通过数学分析和实验验证，证明了该方法的鲁棒性，特别是在与通用顺序凸规划算法的比较实验中，该方法在动态地图中的计算效率和最终时间的减少方面表现出优越性能。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效解决实时运动规划中的挑战，并为智能地面车辆的轨迹优化提供了一种高效和鲁棒的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Motion planning and trajectory generation are crucial technologies in variousdomains including the control of Unmanned Aerial Vehicles, manipulators, androckets. However, optimization-based real-time motion planning becomesincreasingly challenging due to the problem's probable non-convexity and theinherent limitations of non-linear programming algorithms. Highly nonlineardynamics, obstacle avoidance constraints, and non-convex inputs can exacerbatethese difficulties. In order to enhance the robustness and reduce thecomputational burden, this paper proposes a two-layer trajectory generatingalgorithm for intelligent ground vehicles with convex optimization methods,aiming to provide real-time guarantees for trajectory optimization and toimprove the calculate speed of motion prediction. Our approach involvesbreaking down the original problem into small horizon-based planning cycleswith fixed final times, referred to as planning cycles. Each planning cycle isthen solved within a series of restricted convex sets constructed by somecustomized search algorithms incrementally. We rigorously establish theseadvantages through mathematical analysis under moderate assumptions andcomprehensive experimental validations. For linear vehicle models, comparativeexperiments with general sequential convex programming algorithms demonstratethe superior performance of our proposed method, particularly in terms of thecomputational efficiency in dynamic maps and the reduced final time.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion planning and trajectory generation are crucial technologies in variousdomains including the control of Unmanned Aerial Vehicles, manipulators, androckets. However, optimization-based real-time motion planning becomesincreasingly challenging due to the problem's probable non-convexity and theinherent limitations of non-linear programming algorithms. Highly nonlineardynamics, obstacle avoidance constraints, and non-convex inputs can exacerbatethese difficulties. In order to enhance the robustness and reduce thecomputational burden, this paper proposes a two-layer trajectory generatingalgorithm for intelligent ground vehicles with convex optimization methods,aiming to provide real-time guarantees for trajectory optimization and toimprove the calculate speed of motion prediction. Our approach involvesbreaking down the original problem into small horizon-based planning cycleswith fixed final times, referred to as planning cycles. Each planning cycle isthen solved within a series of restricted convex sets constructed by somecustomized search algorithms incrementally. We rigorously establish theseadvantages through mathematical analysis under moderate assumptions andcomprehensive experimental validations. For linear vehicle models, comparativeexperiments with general sequential convex programming algorithms demonstratethe superior performance of our proposed method, particularly in terms of thecomputational efficiency in dynamic maps and the reduced final time.</description>
      <author>example@mail.com (Haotian Tan, Yuan-Hua Ni)</author>
      <guid isPermaLink="false">2503.11072v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Semi-Self Representation Learning for Crowdsourced WiFi Trajectories</title>
      <link>http://arxiv.org/abs/2504.03756v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by VTC2025-Spring&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于WiFi指纹的定位，提出了一种半自代表学习解决方案，通过新颖的‘切分和翻转’增强方案和两阶段学习过程，实现了对大量未标记WiFi轨迹数据的自动标注，从而减轻了基于轨迹定位中人工标注的负担。&lt;h4&gt;背景&lt;/h4&gt;WiFi指纹定位技术已得到深入研究。点定位方法依赖于WiFi指纹的位置标注，而轨迹定位方法则需要WiFi轨迹的终点标注，WiFi轨迹是一系列信号特征的多元时间序列。由于在特定区域内潜在轨迹数量的指数增长，轨迹数据集通常比点数据集大得多。&lt;h4&gt;目的&lt;/h4&gt;提出一种半自代表学习解决方案，能够自动标注大量未标记的WiFi轨迹数据集，从而减轻基于轨迹定位的人工标注负担。&lt;h4&gt;方法&lt;/h4&gt;通过一个基于‘切分和翻转’增强方案的新颖‘中间相遇’范式，使用一个较小的标记轨迹数据集$ilde C$自动标注一个较大的未标记WiFi轨迹数据集$C$。两阶段学习过程包括轨迹嵌入和终点嵌入，然后使用标记数据集$ilde C$对学习到的表示进行标注，并将其连接到一个基于神经网络的定位网络。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了对未标记轨迹数据集的自动标注，同时显著降低了人工标注的负担，且在准确性方面表现出良好的潜力。&lt;h4&gt;结论&lt;/h4&gt;提出的半自代表学习解决方案能够有效减少基于轨迹定位的人工标注工作量，同时保持较高的定位精度。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies WiFi fingerprint-based localization and proposes a semi-self-representation learning solution. Through a novel 'cut-and-flip' augmentation scheme based on the meet-in-the-middle paradigm, a large dataset C of crowdsourced unlabeled WiFi trajectories can be automatically labeled by a much smaller dataset $ilde C$ of labeled WiFi trajectories. The size of $ilde C$ only needs to be proportional to the size of the physical field, while the unlabeled C could be much larger. This is made possible through a novel 'cut-and-flip' augmentation scheme based on the meet-in-the-middle paradigm. A two-stage learning process consisting of trajectory embedding followed by endpoint embedding is proposed for the unlabeled C. Then the learned representations are labeled by $ilde C$ and connected to a neural-based localization network. The result, while delivering promising accuracy, significantly relieves the burden of human annotations for trajectory-based localization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; WiFi fingerprint-based localization has been studied intensively. Point-basedsolutions rely on position annotations of WiFi fingerprints. Trajectory-basedsolutions, however, require end-position annotations of WiFi trajectories,where a WiFi trajectory is a multivariate time series of signal features. Atrajectory dataset is much larger than a pointwise dataset as the number ofpotential trajectories in a field may grow exponentially with respect to thesize of the field. This work presents a semi-self representation learningsolution, where a large dataset $C$ of crowdsourced unlabeled WiFi trajectoriescan be automatically labeled by a much smaller dataset $\tilde C$ of labeledWiFi trajectories. The size of $\tilde C$ only needs to be proportional to thesize of the physical field, while the unlabeled $C$ could be much larger. Thisis made possible through a novel ``cut-and-flip'' augmentation scheme based onthe meet-in-the-middle paradigm. A two-stage learning consisting of trajectoryembedding followed by endpoint embedding is proposed for the unlabeled $C$.Then the learned representations are labeled by $\tilde C$ and connected to aneural-based localization network. The result, while delivering promisingaccuracy, significantly relieves the burden of human annotations fortrajectory-based localization.</description>
      <author>example@mail.com (Yu-Lin Kuo, Yu-Chee Tseng, Ting-Hui Chiang, Yan-Ann Chen)</author>
      <guid isPermaLink="false">2504.03756v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Experimental Study on Time Series Analysis of Lower Limb Rehabilitation Exercise Data Driven by Novel Model Architecture and Large Models</title>
      <link>http://arxiv.org/abs/2504.03799v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了新型模型架构和大规模基础模型在下肢康复运动数据时间序列分析中的应用，旨在利用机器学习和人工智能的进步，为中风后患者肢体运动功能恢复提供主动康复指导策略。&lt;h4&gt;背景&lt;/h4&gt;研究使用了深圳先进技术研究院提出的SIAT-LLMD下肢运动数据集。&lt;h4&gt;目的&lt;/h4&gt;研究目的是系统地阐明创新性xLSTM架构和基础模型Lag-Llama在涉及关节运动学和动力学参数的短期时间预测任务中的实施和分析结果。&lt;h4&gt;方法&lt;/h4&gt;研究使用了SIAT-LLMD数据集，并采用了xLSTM架构和Lag-Llama模型进行时间序列分析。&lt;h4&gt;主要发现&lt;/h4&gt;研究提供了AI辅助医疗康复应用的见解，证明了尖端模型架构和大规模模型在康复医学时间预测中的潜力。&lt;h4&gt;结论&lt;/h4&gt;研究结果为个性化康复方案的将来应用建立了理论基础，对临床实践中定制化治疗干预措施的发展具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;This study investigates the application of novel model architectures and large-scale foundational models in temporal series analysis of lower limb rehabilitation motion data, aiming to leverage advancements in machine learning and artificial intelligence to empower active rehabilitation guidance strategies for post-stroke patients in limb motor function recovery. Utilizing the SIAT-LLMD dataset of lower limb movement data proposed by the Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, we systematically elucidate the implementation and analytical outcomes of the innovative xLSTM architecture and the foundational model Lag-Llama in short-term temporal prediction tasks involving joint kinematics and dynamics parameters. The research provides novel insights for AI-enabled medical rehabilitation applications, demonstrating the potential of cutting-edge model architectures and large-scale models in rehabilitation medicine temporal prediction. These findings establish theoretical foundations for future applications of personalized rehabilitation regimens, offering significant implications for the development of customized therapeutic interventions in clinical practice.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study investigates the application of novel model architectures andlarge-scale foundational models in temporal series analysis of lower limbrehabilitation motion data, aiming to leverage advancements in machine learningand artificial intelligence to empower active rehabilitation guidancestrategies for post-stroke patients in limb motor function recovery. Utilizingthe SIAT-LLMD dataset of lower limb movement data proposed by the ShenzhenInstitute of Advanced Technology, Chinese Academy of Sciences, wesystematically elucidate the implementation and analytical outcomes of theinnovative xLSTM architecture and the foundational model Lag-Llama inshort-term temporal prediction tasks involving joint kinematics and dynamicsparameters. The research provides novel insights for AI-enabled medicalrehabilitation applications, demonstrating the potential of cutting-edge modelarchitectures and large-scale models in rehabilitation medicine temporalprediction. These findings establish theoretical foundations for futureapplications of personalized rehabilitation regimens, offering significantimplications for the development of customized therapeutic interventions inclinical practice.</description>
      <author>example@mail.com (Hengyu Lin)</author>
      <guid isPermaLink="false">2504.03799v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>TransNet: Transfer Knowledge for Few-shot Knowledge Graph Completion</title>
      <link>http://arxiv.org/abs/2504.03720v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于迁移学习的少样本知识图谱补全方法（TransNet），旨在提高知识图谱在下游任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;现实中的知识图谱往往不完整，且关系分布呈现长尾分布，导致多数关系只有少量训练三元组，影响性能。&lt;h4&gt;目的&lt;/h4&gt;通过引入少样本学习，在只有少量训练三元组的情况下，对包含新关系的三元组进行准确预测。&lt;h4&gt;方法&lt;/h4&gt;TransNet通过学习不同任务之间的关系，有效地将相似任务的知识迁移到当前任务，并采用元学习来对新、未见过的关系进行有效泛化。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的实验表明，TransNet在性能上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;TransNet能够有效提高知识图谱在下游任务中的性能，并能够泛化到新、未见过的关系。&lt;h4&gt;翻译&lt;/h4&gt;Knowledge graphs (KGs) are ubiquitous and widely used in various applications. However, most real-world knowledge graphs are incomplete, which significantly degrades their performance on downstream tasks. Additionally, the relationships in real-world knowledge graphs often follow a long-tail distribution, meaning that most relations are represented by only a few training triplets. To address these challenges, few-shot learning has been introduced. Few-shot KG completion aims to make accurate predictions for triplets involving novel relations when only a limited number of training triplets are available. Although many methods have been proposed, they typically learn each relation individually, overlooking the correlations between different tasks and the relevant information in previously trained tasks. In this paper, we propose a transfer learning-based few-shot KG completion method (TransNet). By learning the relationships between different tasks, TransNet effectively transfers knowledge from similar tasks to improve the current task's performance. Furthermore, by employing meta-learning, TransNet can generalize effectively to new, unseen relations. Extensive experiments on benchmark datasets demonstrate the superiority of TransNet over state-of-the-art methods. Code can be found at https://github.com/lihuiliullh/TransNet/tree/main&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge graphs (KGs) are ubiquitous and widely used in variousapplications. However, most real-world knowledge graphs are incomplete, whichsignificantly degrades their performance on downstream tasks. Additionally, therelationships in real-world knowledge graphs often follow a long-taildistribution, meaning that most relations are represented by only a fewtraining triplets. To address these challenges, few-shot learning has beenintroduced. Few-shot KG completion aims to make accurate predictions fortriplets involving novel relations when only a limited number of trainingtriplets are available. Although many methods have been proposed, theytypically learn each relation individually, overlooking the correlationsbetween different tasks and the relevant information in previously trainedtasks. In this paper, we propose a transfer learning-based few-shot KGcompletion method (TransNet). By learning the relationships between differenttasks, TransNet effectively transfers knowledge from similar tasks to improvethe current task's performance. Furthermore, by employing meta-learning,TransNet can generalize effectively to new, unseen relations. Extensiveexperiments on benchmark datasets demonstrate the superiority of TransNet overstate-of-the-art methods. Code can be found athttps://github.com/lihuiliullh/TransNet/tree/main</description>
      <author>example@mail.com (Lihui Liu, Zihao Wang, Dawei Zhou, Ruijie Wang, Yuchen Yan, Bo Xiong, Sihong He, Kai Shu, Hanghang Tong)</author>
      <guid isPermaLink="false">2504.03720v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>ProtoGCD: Unified and Unbiased Prototype Learning for Generalized Category Discovery</title>
      <link>http://arxiv.org/abs/2504.03755v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IEEE TPAMI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ProtoGCD的统一且无偏的原型学习框架，用于解决广义类别发现（GCD）问题，该问题需要模型自动聚类和发现新的类别，同时利用旧类别的标注样本。该框架在解决旧类和新类不平衡、对比学习忽视潜在正样本以及与聚类目标解耦等问题上取得了显著成效。&lt;h4&gt;背景&lt;/h4&gt;广义类别发现（GCD）是一个实用但未充分探索的问题，需要模型利用旧类别的标注样本自动聚类和发现新的类别。然而，未标注的数据中既包含旧类别也包含新类别，这给模型带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种统一的、无偏的原型学习框架ProtoGCD，以解决GCD问题中旧类和新类不平衡、对比学习忽视潜在正样本以及与聚类目标解耦等问题。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种双级自适应伪标签机制以减轻确认偏差；2. 引入两个正则化项以帮助学习更适合GCD的表示；3. 设计了一种准则来估计新类别的数量；4. 将ProtoGCD扩展到检测未见过的异常值，实现任务级统一。&lt;h4&gt;主要发现&lt;/h4&gt;ProtoGCD在通用和细粒度数据集上都达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;ProtoGCD是一种有效解决GCD问题的方法，其在旧类和新类之间实现了统一的建模，并取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：广义类别发现（GCD）是一个实用但未充分探索的问题，它要求模型通过利用旧类别的标注样本来自动聚类和发现新的类别。挑战在于未标注数据中既包含旧类别也包含新类别。早期的工作利用参数化分类器的伪标签处理旧类和新类，导致它们之间不平衡的准确率。最近的方法采用对比学习，却忽视了潜在的正样本，并且与聚类目标解耦，导致偏差表示和次优结果。为了解决这些问题，我们引入了一个统一且无偏的原型学习框架，即ProtoGCD，其中旧类和新类通过联合原型和统一的学习目标进行建模，从而实现了旧类和新类之间的统一建模。具体来说，我们提出了一种双级自适应伪标签机制来减轻确认偏差，以及两个正则化项来共同帮助学习更适合GCD的表示。此外，为了实际考虑，我们制定了一种准则来估计新类别的数量。此外，我们将ProtoGCD扩展到检测未见过的异常值，实现了任务级的统一。综合实验表明，ProtoGCD在通用和细粒度数据集上都达到了最先进的性能。代码可在https://github.com/mashijie1028/ProtoGCD上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TPAMI.2025.3557502&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalized category discovery (GCD) is a pragmatic but underexploredproblem, which requires models to automatically cluster and discover novelcategories by leveraging the labeled samples from old classes. The challenge isthat unlabeled data contain both old and new classes. Early works leveragingpseudo-labeling with parametric classifiers handle old and new classesseparately, which brings about imbalanced accuracy between them. Recent methodsemploying contrastive learning neglect potential positives and are decoupledfrom the clustering objective, leading to biased representations andsub-optimal results. To address these issues, we introduce a unified andunbiased prototype learning framework, namely ProtoGCD, wherein old and newclasses are modeled with joint prototypes and unified learning objectives,{enabling unified modeling between old and new classes}. Specifically, wepropose a dual-level adaptive pseudo-labeling mechanism to mitigateconfirmation bias, together with two regularization terms to collectively helplearn more suitable representations for GCD. Moreover, for practicalconsiderations, we devise a criterion to estimate the number of new classes.Furthermore, we extend ProtoGCD to detect unseen outliers, achieving task-levelunification. Comprehensive experiments show that ProtoGCD achievesstate-of-the-art performance on both generic and fine-grained datasets. Thecode is available at https://github.com/mashijie1028/ProtoGCD.</description>
      <author>example@mail.com (Shijie Ma, Fei Zhu, Xu-Yao Zhang, Cheng-Lin Liu)</author>
      <guid isPermaLink="false">2504.03755v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Brain Network Classification Based on Graph Contrastive Learning and Graph Transformer</title>
      <link>http://arxiv.org/abs/2504.03740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, uses tikz.sty&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PHGCL-DDGformer的新型模型，该模型结合了图对比学习和图变换器，有效提升了脑网络分类任务中的表征学习能力。&lt;h4&gt;背景&lt;/h4&gt;脑网络功能网络的动态特征描述对于阐明人类大脑功能机制具有重要意义。尽管图神经网络在功能网络分析方面取得了显著进展，但数据稀缺和监督不足等问题仍然存在。&lt;h4&gt;目的&lt;/h4&gt;为了解决训练数据有限和监督不足的局限性，本文提出了一种名为PHGCL-DDGformer的新型模型。&lt;h4&gt;方法&lt;/h4&gt;该模型通过整合图对比学习和图变换器，并实施自适应图增强策略，包括属性掩码和边扰动，以增强数据。此外，构建了双重域图变换器(DDGformer)模块，以整合局部和全局信息，并通过图对比学习框架最大化正负样本对之间的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PHGCL-DDGformer模型在脑网络分类任务中优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;PHGCL-DDGformer模型通过有效提升表征学习能力，在脑网络分类任务中表现出色，为解决脑网络分析中的数据稀缺和监督不足问题提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;The dynamic characterization of functional brain networks is of great significance for elucidating the mechanisms of human brain function. Although graph neural networks have achieved remarkable progress in functional network analysis, challenges such as data scarcity and insufficient supervision persist. To address the limitations of limited training data and inadequate supervision, this paper proposes a novel model named PHGCL-DDGformer that integrates graph contrastive learning with graph transformers, effectively enhancing the representation learning capability for brain network classification tasks. To overcome the constraints of existing graph contrastive learning methods in brain network feature extraction, an adaptive graph augmentation strategy combining attribute masking and edge perturbation is implemented for data enhancement. Subsequently, a dual-domain graph transformer (DDGformer) module is constructed to integrate local and global information, where graph convolutional networks aggregate neighborhood features to capture local patterns while attention mechanisms extract global dependencies. Finally, a graph contrastive learning framework is established to maximize the consistency between positive and negative pairs, thereby obtaining high-quality graph representations. Experimental results on real-world datasets demonstrate that the PHGCL-DDGformer model outperforms existing state-of-the-art approaches in brain network classification tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The dynamic characterization of functional brain networks is of greatsignificance for elucidating the mechanisms of human brain function. Althoughgraph neural networks have achieved remarkable progress in functional networkanalysis, challenges such as data scarcity and insufficient supervisionpersist. To address the limitations of limited training data and inadequatesupervision, this paper proposes a novel model named PHGCL-DDGformer thatintegrates graph contrastive learning with graph transformers, effectivelyenhancing the representation learning capability for brain networkclassification tasks. To overcome the constraints of existing graph contrastivelearning methods in brain network feature extraction, an adaptive graphaugmentation strategy combining attribute masking and edge perturbation isimplemented for data enhancement. Subsequently, a dual-domain graph transformer(DDGformer) module is constructed to integrate local and global information,where graph convolutional networks aggregate neighborhood features to capturelocal patterns while attention mechanisms extract global dependencies. Finally,a graph contrastive learning framework is established to maximize theconsistency between positive and negative pairs, thereby obtaining high-qualitygraph representations. Experimental results on real-world datasets demonstratethat the PHGCL-DDGformer model outperforms existing state-of-the-art approachesin brain network classification tasks.</description>
      <author>example@mail.com (ZhiTeng Zhu, Lan Yao)</author>
      <guid isPermaLink="false">2504.03740v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Meshing of High-Dimensional Toroidal Manifolds from Quasi-Periodic Three-Body Problem Dynamics using Parameterization via Discrete One-Forms</title>
      <link>http://arxiv.org/abs/2504.03791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种高维视觉计算机模型，该模型通过使用一种参数化技术，能够对任意高维嵌入空间中的环面流形进行拓扑精确建模和直观可视化，从而革新空间任务设计过程。&lt;h4&gt;背景&lt;/h4&gt;高维视觉计算机模型在空间任务设计中具有革命性的潜力，而环形限制三体问题（CR3BP）产生的高维环面流形对任务设计者具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的网格化技术，能够对CR3BP中的高维点云进行精确建模和可视化。&lt;h4&gt;方法&lt;/h4&gt;该方法将基于离散一形式的方法扩展到CR3BP中的准周期轨道轨迹上的高维点云，并应用一种与嵌入无关的三角形侧向性分配算法来增强网格。&lt;h4&gt;主要发现&lt;/h4&gt;该技术提供了高维拓扑结构的新型表面表示，这些结构以前仅以点或曲线的形式展示。这种方法展示了微分几何方法在表征具有复杂高维嵌入空间的流形方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;这些模型为动态系统的解决方案空间提供了新的模型和可视化方法，有望提高空间任务轨迹视觉检查和设计的实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：高维视觉计算机模型有望革新空间任务设计过程。环形限制三体问题（CR3BP）产生了对任务设计者极具吸引力的高维环面流形。我们提出了一种网格化技术，利用一种与嵌入无关的参数化方法，在任意高维嵌入空间中对环面流形进行拓扑精确建模和直观可视化。这项工作描述了将基于离散一形式的方法扩展到CR3BP中准周期轨道轨迹上的高维点云的网格化方法。通过应用一种与嵌入无关的三角形侧向性分配算法，增强了生成的网格。这显著提高了将网格下投影到3D空间进行可视化后的可解释性。这些模型提供了高维拓扑结构的新型表面表示，这些结构以前仅以点或曲线的形式展示。这一成功证明了微分几何方法在表征具有复杂、高维嵌入空间的流形方面的有效性，为动态系统的解决方案空间的新模型和可视化奠定了基础。这种表示有望通过使计算表面可视化与分析方法应用于基础解流形，提高三体问题在空间任务轨迹视觉检查和设计中的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-dimensional visual computer models are poised to revolutionize the spacemission design process. The circular restricted three-body problem (CR3BP)gives rise to high-dimensional toroidal manifolds that are of immense interestto mission designers. We present a meshing technique which leverages anembedding-agnostic parameterization to enable topologically accurate modellingand intuitive visualization of toroidal manifolds in arbitrarilyhigh-dimensional embedding spaces. This work describes the extension of adiscrete one-form-based toroidal point cloud meshing method to high-dimensionalpoint clouds sampled along quasi-periodic orbital trajectories in the CR3BP.The resulting meshes are enhanced through the application of anembedding-agnostic triangle-sidedness assignment algorithm. This significantlyincreases the intuitiveness of interpreting the meshes after they aredownprojected to 3D for visualization. These models provide novel surface-basedrepresentations of high-dimensional topologies which have so far only beenshown as points or curves. This success demonstrates the effectiveness ofdifferential geometric methods for characterizing manifolds with complex,high-dimensional embedding spaces, laying the foundation for new models andvisualizations of high-dimensional solution spaces for dynamical systems. Suchrepresentations promise to enhance the utility of the three-body problem forthe visual inspection and design of space mission trajectories by enabling theapplication of proven computational surface visualization and analysis methodsto underlying solution manifolds.</description>
      <author>example@mail.com (Dante Basile, Xavier Tricoche, Martin Lo)</author>
      <guid isPermaLink="false">2504.03791v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>FAST: Federated Active Learning with Foundation Models for Communication-efficient Sampling and Training</title>
      <link>http://arxiv.org/abs/2504.03783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FAST的联邦主动学习框架，旨在降低在人工参与学习过程中通信成本，同时减少标注工作。&lt;h4&gt;背景&lt;/h4&gt;Federated Active Learning（FAL）是一种在保持数据隐私的前提下，利用分布式客户端大量未标记数据的框架。然而，实际部署受限于高昂的标注成本和通信密集型采样过程。&lt;h4&gt;目的&lt;/h4&gt;探讨在人工参与学习过程中，如何以最小的标注工作减少通信成本。&lt;h4&gt;方法&lt;/h4&gt;提出了一种两阶段FAL框架，第一阶段利用基础模型进行弱标注，第二阶段专注于最不确定的样本进行细化。&lt;h4&gt;主要发现&lt;/h4&gt;通过利用基础模型的表征知识并将细化步骤整合到简化的工作流程中，FAST大幅降低了迭代主动采样产生的开销。&lt;h4&gt;结论&lt;/h4&gt;在医学和自然图像基准数据集上的实验表明，与现有FAL方法相比，FAST平均提高了4.36%的性能，并在有限的5%标注预算下将通信轮次减少了八倍。&lt;h4&gt;翻译&lt;/h4&gt;摘要：联邦主动学习（Federated Active Learning，简称FAL）作为一种能够在保护数据隐私的前提下，利用分布式客户端的大量未标记数据的框架，已经逐渐成为一个有前景的框架。然而，在实际部署中，它受到高标注成本和通信密集型采样过程的限制，尤其是在跨数据孤岛设置中，客户端拥有大量本地数据集时。本文针对一个关键问题进行了探讨：在人工参与学习过程中，如何以最少的标注工作来降低通信成本？现有的FAL方法通常依赖于将主动采样与联邦更新分开的迭代标注过程，导致多次昂贵的通信和标注。为此，我们引入了FAST，一个两阶段的FAL框架，它在初步阶段利用基础模型进行弱标注，随后在专注于最不确定样本的细化阶段。通过利用基础模型的表征知识并将细化步骤整合到一个简化的工作流程中，FAST大幅减少了迭代主动采样产生的开销。在多样化的医学和自然图像基准数据集上的大量实验表明，与现有FAL方法相比，FAST平均提高了4.36%的性能，并在有限的5%标注预算下将通信轮次减少了八倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Active Learning (FAL) has emerged as a promising framework toleverage large quantities of unlabeled data across distributed clients whilepreserving data privacy. However, real-world deployments remain limited by highannotation costs and communication-intensive sampling processes, particularlyin a cross-silo setting, when clients possess substantial local datasets. Thispaper addresses the crucial question: What is the best practice to reducecommunication costs in human-in-the-loop learning with minimal annotatoreffort? Existing FAL methods typically rely on iterative annotation processesthat separate active sampling from federated updates, leading to multiplerounds of expensive communication and annotation. In response, we introduceFAST, a two-pass FAL framework that harnesses foundation models for weaklabeling in a preliminary pass, followed by a refinement pass focusedexclusively on the most uncertain samples. By leveraging representationknowledge from foundation models and integrating refinement steps into astreamlined workflow, FAST substantially reduces the overhead incurred byiterative active sampling. Extensive experiments on diverse medical and naturalimage benchmarks demonstrate that FAST outperforms existing FAL methods by anaverage of 4.36% while reducing communication rounds eightfold under a limited5% labeling budget.</description>
      <author>example@mail.com (Haoyuan Li, Jindong Wang, Mathias Funk, Aaqib Saeed)</author>
      <guid isPermaLink="false">2504.03783v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Crash Time Matters: HybridMamba for Fine-Grained Temporal Localization in Traffic Surveillance Footage</title>
      <link>http://arxiv.org/abs/2504.03235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HybridMamba的新型架构，用于在长视频监控中检测交通事故，该架构结合了视觉Transformer和状态空间时序建模，以实现精确的事故时间定位。&lt;h4&gt;背景&lt;/h4&gt;交通事故检测对于紧急响应和基础设施规划至关重要，但由于事故事件短暂且罕见，这一任务仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够准确定位交通事故发生时间的算法。&lt;h4&gt;方法&lt;/h4&gt;HybridMamba使用多级令牌压缩和分层时序处理，以保持计算效率，同时不牺牲时间分辨率。&lt;h4&gt;主要发现&lt;/h4&gt;在爱荷华州交通部的大规模数据集上评估，HybridMamba的平均绝对误差为1.50秒，其中65.2%的预测与真实值相差在一秒以内。它在参数数量显著少于TimeChat和VideoLLaMA2等最近视频语言模型的情况下，性能提升了最多2.8秒。结果表明，HybridMamba在2到40分钟的视频上具有强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;HybridMamba为交通监控中的细粒度时间定位提供了一种稳健且高效的解决方案。代码将在论文发表后发布。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在长视频监控中检测交通事故对于紧急响应和基础设施规划至关重要，但由于事故事件短暂且罕见，这一任务仍然具有挑战性。我们引入了HybridMamba，这是一种结合视觉Transformer和状态空间时序建模的新架构，以实现精确的事故时间定位。我们的方法使用多级令牌压缩和分层时序处理，以保持计算效率，同时不牺牲时间分辨率。在爱荷华州交通部的大规模数据集上评估，HybridMamba的平均绝对误差为1.50秒，其中65.2%的预测与真实值相差在一秒以内。它在参数数量显著少于TimeChat和VideoLLaMA2等最近视频语言模型的情况下，性能提升了最多2.8秒。结果表明，HybridMamba在2到40分钟的视频上具有强大的泛化能力。HybridMamba为交通监控中的细粒度时间定位提供了一种稳健且高效的解决方案。代码将在论文发表后发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic crash detection in long-form surveillance videos is critical foremergency response and infrastructure planning but remains difficult due to thebrief and rare nature of crash events. We introduce HybridMamba, a novelarchitecture that combines visual transformers with state-space temporalmodeling to achieve accurate crash time localization. Our method usesmulti-level token compression and hierarchical temporal processing to remaincomputationally efficient without sacrificing temporal resolution. Evaluated ona large-scale dataset from the Iowa Department of Transportation, HybridMambaachieves a mean absolute error of 1.50 seconds, with 65.2 percent ofpredictions within one second of the ground truth. It outperforms recentvideo-language models such as TimeChat and VideoLLaMA2 by up to 2.8 seconds,while using significantly fewer parameters. Our results demonstrate stronggeneralization across videos ranging from 2 to 40 minutes in diverseconditions. HybridMamba offers a robust and efficient solution for fine-grainedtemporal localization in traffic surveillance. The code will be released uponpublication.</description>
      <author>example@mail.com (Ibne Farabi Shihab, Anuj Sharma)</author>
      <guid isPermaLink="false">2504.03235v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
  <item>
      <title>Autonomous and Self-Adapting System for Synthetic Media Detection and Attribution</title>
      <link>http://arxiv.org/abs/2504.03615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了自主自适应合成媒体识别系统的概念，该系统能够检测合成图像并归因于已知来源，同时无需人工干预就能自主识别和纳入新型生成器。通过采用开放集识别策略和可演化的嵌入空间，系统能够区分已知和未知来源，并使用无监督聚类方法将未知样本聚集成高置信度簇，持续优化决策边界，从而保持对生成模型演变过程中的稳健检测和归因性能。&lt;h4&gt;背景&lt;/h4&gt;随着生成式人工智能的快速发展，合成图像的生成技术越来越高级，虽然有益于许多领域，但也带来了虚假信息、欺诈等风险。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够自主识别和适应新型生成器的合成媒体识别系统。&lt;h4&gt;方法&lt;/h4&gt;采用开放集识别策略、可演化的嵌入空间，以及无监督聚类方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在性能上显著优于现有方法，是迈向通用、适应性强的人工智能时代法医系统的重要一步。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效应对生成模型快速发展的挑战，为合成媒体识别提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rapid advances in generative AI have enabled the creation of highly realisticsynthetic images, which, while beneficial in many domains, also pose seriousrisks in terms of disinformation, fraud, and other malicious applications.Current synthetic image identification systems are typically static, relying onfeature representations learned from known generators; as new generative modelsemerge, these systems suffer from severe performance degradation. In thispaper, we introduce the concept of an autonomous self-adaptive synthetic mediaidentification system -- one that not only detects synthetic images andattributes them to known sources but also autonomously identifies andincorporates novel generators without human intervention. Our approachleverages an open-set identification strategy with an evolvable embedding spacethat distinguishes between known and unknown sources. By employing anunsupervised clustering method to aggregate unknown samples intohigh-confidence clusters and continuously refining its decision boundaries, oursystem maintains robust detection and attribution performance even as thegenerative landscape evolves. Extensive experiments demonstrate that our methodsignificantly outperforms existing approaches, marking a crucial step towarduniversal, adaptable forensic systems in the era of rapidly advancinggenerative models.</description>
      <author>example@mail.com (Aref Azizpour, Tai D. Nguyen, Matthew C. Stamm)</author>
      <guid isPermaLink="false">2504.03615v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>BabyLM's First Words: Word Segmentation as a Phonological Probing Task</title>
      <link>http://arxiv.org/abs/2504.03338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 10 figures, submitted to CoNLL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用大型语言模型（LLMs）进行语音分析的问题，并提出了一种基于词汇分割的语音探查任务，以研究基于儿童语音训练的跨31种语言的音素语言模型所学习的表示。&lt;h4&gt;背景&lt;/h4&gt;语音分析使用LLMs困难，因为缺乏除英语外的语音基准，且LLMs中使用的标准输入表示（图形字的子词）不适用于分析音素的表示。&lt;h4&gt;目的&lt;/h4&gt;通过词汇分割作为语音探查任务，研究基于音素的、在儿童语音上训练的语言模型所学习的表示。&lt;h4&gt;方法&lt;/h4&gt;使用无监督方法从训练模型中提取词汇边界，并利用预测误差在词汇开始处达到峰值的现象。同时，使用线性探针识别模型隐式跟踪词汇边界，即使这些边界没有出现在训练中。&lt;h4&gt;主要发现&lt;/h4&gt;该跨语言工作证实了语言习得统计学习理论，并实证地激励了训练子词标记器的新方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为语音分析提供了新的视角，并有助于提高基于音素的语言模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the difficulty of phonological analysis using large language models (LLMs) and proposes a phonological probing task based on word segmentation to study the representations learned by phoneme-based language models trained on child-directed speech across 31 languages. Using unsupervised methods to extract word boundaries from a trained model based on the observation that prediction-error peaks at the start of words, and also using linear probes to identify that these models implicitly track word boundaries even when they do not appear in training. This cross-lingual work corroborates statistical learning theories of acquisition and empirically motivates new methods for training subword tokenizers.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language models provide a key framework for studying linguistic theoriesbased on prediction, but phonological analysis using large language models(LLMs) is difficult; there are few phonological benchmarks beyond English andthe standard input representation used in LLMs (subwords of graphemes) is notsuitable for analyzing the representation of phonemes. In this work, wedemonstrate how word segmentation can be used as a phonological probing task,allowing us to study the representations learned by phoneme-based languagemodels trained on child-directed speech across 31 languages. Followingcomputational models of word segmentation, we present unsupervised methods forextracting word boundaries from a trained model using the observation thatprediction-error peaks at the start of words. We also use linear probes toidentify that these models implicitly track word boundaries, even when they donot appear in training. This cross-lingual work corroborates statisticallearning theories of acquisition and empirically motivates new methods fortraining subword tokenizers.</description>
      <author>example@mail.com (Zébulon Goriely)</author>
      <guid isPermaLink="false">2504.03338v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>RingMoE: Mixture-of-Modality-Experts Multi-Modal Foundation Models for Universal Remote Sensing Image Interpretation</title>
      <link>http://arxiv.org/abs/2504.03166v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;RingMoE是一种统一的多模态遥感基础模型，能够有效处理遥感数据的多模态特性，提高了遥感分析的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;现有的遥感模型主要处理单一或有限的模态，忽略了遥感观察的内在多模态性质。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一基本差距，提出RingMoE模型，旨在提高遥感分析的性能。&lt;h4&gt;方法&lt;/h4&gt;RingMoE模型包含三个关键创新：(1) 分层混合专家（MoE）架构，能够建模模态内知识并捕捉跨模态依赖；(2) 物理信息自监督学习，将传感器特定的辐射特性嵌入到预训练目标中；(3) 动态专家剪枝，实现自适应模型压缩。&lt;h4&gt;主要发现&lt;/h4&gt;RingMoE在23个基准测试中优于现有的基础模型，并在多个领域得到应用和验证。&lt;h4&gt;结论&lt;/h4&gt;RingMoE模型在提高遥感分析性能方面取得了显著进展，并已在多个领域得到应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着基础模型的快速发展，以自监督的方式革新了视觉表示学习。然而，它们在遥感（RS）中的应用仍然受到一个基本差距的限制：现有的模型主要处理单一或有限的模态，忽略了遥感观察的内在多模态性质。光学、合成孔径雷达（SAR）和多光谱数据提供了互补的见解，显著减少了单源分析中的固有模糊性和不确定性。为了弥合这一差距，我们引入了RingMoE，一个具有147亿参数的统一多模态RS基础模型，在来自九颗卫星的4000万多模态RS图像上进行了预训练。RingMoE包含三个关键创新：(1) 由模态专用、协作和共享专家组成的分层混合专家（MoE）架构，有效地建模模态内知识，同时捕捉跨模态依赖以减轻模态表示之间的冲突；(2) 物理信息自监督学习，将传感器特定的辐射特性明确嵌入到预训练目标中；(3) 动态专家剪枝，在保持性能的同时，将模型压缩从147亿参数降至10亿参数，便于在地球观测应用中的高效部署。在涵盖六个关键RS任务（即分类、检测、分割、跟踪、变化检测和深度估计）的23个基准测试中评估，RingMoE优于现有的基础模型，并设定了新的SOTA，证明了从单模态到多模态场景的显著适应性。除了理论进步之外，它已在多个部门得到部署和试用，包括应急响应、土地管理、海洋科学和城市规划。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of foundation models has revolutionized visualrepresentation learning in a self-supervised manner. However, their applicationin remote sensing (RS) remains constrained by a fundamental gap: existingmodels predominantly handle single or limited modalities, overlooking theinherently multi-modal nature of RS observations. Optical, synthetic apertureradar (SAR), and multi-spectral data offer complementary insights thatsignificantly reduce the inherent ambiguity and uncertainty in single-sourceanalysis. To bridge this gap, we introduce RingMoE, a unified multi-modal RSfoundation model with 14.7 billion parameters, pre-trained on 400 millionmulti-modal RS images from nine satellites. RingMoE incorporates three keyinnovations: (1) A hierarchical Mixture-of-Experts (MoE) architecturecomprising modal-specialized, collaborative, and shared experts, effectivelymodeling intra-modal knowledge while capturing cross-modal dependencies tomitigate conflicts between modal representations; (2) Physics-informedself-supervised learning, explicitly embedding sensor-specific radiometriccharacteristics into the pre-training objectives; (3) Dynamic expert pruning,enabling adaptive model compression from 14.7B to 1B parameters whilemaintaining performance, facilitating efficient deployment in Earth observationapplications. Evaluated across 23 benchmarks spanning six key RS tasks (i.e.,classification, detection, segmentation, tracking, change detection, and depthestimation), RingMoE outperforms existing foundation models and sets new SOTAs,demonstrating remarkable adaptability from single-modal to multi-modalscenarios. Beyond theoretical progress, it has been deployed and trialed inmultiple sectors, including emergency response, land management, marinesciences, and urban planning.</description>
      <author>example@mail.com (Hanbo Bi, Yingchao Feng, Boyuan Tong, Mengyu Wang, Haichen Yu, Yongqiang Mao, Hao Chang, Wenhui Diao, Peijin Wang, Yue Yu, Hanyang Peng, Yehong Zhang, Kun Fu, Xian Sun)</author>
      <guid isPermaLink="false">2504.03166v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>MedSAM2: Segment Anything in 3D Medical Images and Videos</title>
      <link>http://arxiv.org/abs/2504.03600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://medsam2.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了MedSAM2，这是一个用于3D图像和视频分割的promptable分割基础模型，通过大量医学数据集进行微调，实现了高效、可扩展和高质量的分割。&lt;h4&gt;背景&lt;/h4&gt;医学图像和视频分割对精准医学至关重要，目前2D图像分割模型发展迅速，但针对3D图像和视频的通用模型研究有限。&lt;h4&gt;目的&lt;/h4&gt;开发一个适用于3D图像和视频分割的通用模型MedSAM2，并通过大规模用户研究验证其性能。&lt;h4&gt;方法&lt;/h4&gt;在包含455,000个3D图像-掩码对和76,000帧的大规模医学数据集上微调Segment Anything Model 2，并实施人机交互流程以创建大规模数据集。&lt;h4&gt;主要发现&lt;/h4&gt;MedSAM2在广泛的器官、病变和成像模态上优于现有模型，通过标注5,000个CT病变、3,984个肝脏MRI病变和251,550个超声心动图视频帧，证明了MedSAM2可以减少超过85%的人工成本。&lt;h4&gt;结论&lt;/h4&gt;MedSAM2是一种实用工具，支持研究环境和医疗保健环境中高效、可扩展和高质量的分割。&lt;h4&gt;翻译&lt;/h4&gt;Medical image and video segmentation is a critical task for precision medicine, which has witnessed considerable progress in developing task or modality-specific and generalist models for 2D images. However, there have been limited studies on building general-purpose models for 3D images and videos with comprehensive user studies. Here, we present MedSAM2, a promptable segmentation foundation model for 3D image and video segmentation. The model is developed by fine-tuning the Segment Anything Model 2 on a large medical dataset with over 455,000 3D image-mask pairs and 76,000 frames, outperforming previous models across a wide range of organs, lesions, and imaging modalities. Furthermore, we implement a human-in-the-loop pipeline to facilitate the creation of large-scale datasets resulting in, to the best of our knowledge, the most extensive user study to date, involving the annotation of 5,000 CT lesions, 3,984 liver MRI lesions, and 251,550 echocardiogram video frames, demonstrating that MedSAM2 can reduce manual costs by more than 85%. MedSAM2 is also integrated into widely used platforms with user-friendly interfaces for local and cloud deployment, making it a practical tool for supporting efficient, scalable, and high-quality segmentation in both research and healthcare environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image and video segmentation is a critical task for precisionmedicine, which has witnessed considerable progress in developing task ormodality-specific and generalist models for 2D images. However, there have beenlimited studies on building general-purpose models for 3D images and videoswith comprehensive user studies. Here, we present MedSAM2, a promptablesegmentation foundation model for 3D image and video segmentation. The model isdeveloped by fine-tuning the Segment Anything Model 2 on a large medicaldataset with over 455,000 3D image-mask pairs and 76,000 frames, outperformingprevious models across a wide range of organs, lesions, and imaging modalities.Furthermore, we implement a human-in-the-loop pipeline to facilitate thecreation of large-scale datasets resulting in, to the best of our knowledge,the most extensive user study to date, involving the annotation of 5,000 CTlesions, 3,984 liver MRI lesions, and 251,550 echocardiogram video frames,demonstrating that MedSAM2 can reduce manual costs by more than 85%. MedSAM2 isalso integrated into widely used platforms with user-friendly interfaces forlocal and cloud deployment, making it a practical tool for supportingefficient, scalable, and high-quality segmentation in both research andhealthcare environments.</description>
      <author>example@mail.com (Jun Ma, Zongxin Yang, Sumin Kim, Bihui Chen, Mohammed Baharoon, Adibvafa Fallahpour, Reza Asakereh, Hongwei Lyu, Bo Wang)</author>
      <guid isPermaLink="false">2504.03600v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Optimization of a Triangular Delaunay Mesh Generator using Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.03610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于强化学习的三角形Delaunay网格生成器，用于优化网格质量。&lt;h4&gt;背景&lt;/h4&gt;研究Delaunay网格生成，并引入了图神经网络和标准Delaunay算法。&lt;h4&gt;目的&lt;/h4&gt;提高网格质量，实现网格生成、改进和生成不同分辨率的网格。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络分布和修改顶点，结合标准Delaunay算法进行三角剖分。&lt;h4&gt;主要发现&lt;/h4&gt;所学的网格生成器输出的网格与Triangle和DistMesh等流行的Delaunay网格生成器相当。&lt;h4&gt;结论&lt;/h4&gt;提出的网格生成器在多种任务中表现出色，包括网格生成、网格改进和生成可变分辨率网格。&lt;h4&gt;翻译&lt;/h4&gt;In this work we introduce a triangular Delaunay mesh generator that can be trained using reinforcement learning to maximize a given mesh quality metric. Our mesh generator consists of a graph neural network that distributes and modifies vertices, and a standard Delaunay algorithm to triangulate the vertices. We explore various design choices and evaluate our mesh generator on various tasks including mesh generation, mesh improvement, and producing variable resolution meshes. The learned mesh generator outputs meshes that are comparable to those produced by Triangle and DistMesh, two popular Delaunay-based mesh generators.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work we introduce a triangular Delaunay mesh generator that can betrained using reinforcement learning to maximize a given mesh quality metric.Our mesh generator consists of a graph neural network that distributes andmodifies vertices, and a standard Delaunay algorithm to triangulate thevertices. We explore various design choices and evaluate our mesh generator onvarious tasks including mesh generation, mesh improvement, and producingvariable resolution meshes. The learned mesh generator outputs meshes that arecomparable to those produced by Triangle and DistMesh, two popularDelaunay-based mesh generators.</description>
      <author>example@mail.com (Will Thacher, Per-Olof Persson, Yulong Pan)</author>
      <guid isPermaLink="false">2504.03610v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>PF3Det: A Prompted Foundation Feature Assisted Visual LiDAR 3D Detector</title>
      <link>http://arxiv.org/abs/2504.03563v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted to the CVPR 2025 Workshop on Distillation of  Foundation Models for Autonomous Driving (WDFM-AD)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Prompted Foundational 3D Detector (PF3Det)的3D目标检测方法，该方法结合了基础模型编码器和软提示技术，以增强LiDAR和摄像头特征的融合，实现了在有限训练数据下的高效3D检测。&lt;h4&gt;背景&lt;/h4&gt;3D目标检测对于自动驾驶至关重要，它需要利用LiDAR点云提供的精确深度信息和摄像头图像提供的丰富语义信息。然而，由于领域差距，有效地融合LiDAR点和图像仍然具有挑战性，并且许多模型由于高质量标注数据的有限性和高昂的成本而性能受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的多模态3D目标检测方法，以解决当前3D目标检测中的挑战。&lt;h4&gt;方法&lt;/h4&gt;PF3Det方法结合了基础模型的预训练和提示工程技术，通过整合基础模型编码器和软提示来增强LiDAR和摄像头特征的融合。&lt;h4&gt;主要发现&lt;/h4&gt;PF3Det在nuScenes数据集上实现了最先进的结果，在有限的训练数据下提高了NDS（一个度量指标）1.19%和mAP（平均精度）2.42%。&lt;h4&gt;结论&lt;/h4&gt;PF3Det展示了在3D检测中的效率，特别是在有限标注数据的情况下。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D物体检测对于自动驾驶至关重要，它利用LiDAR点云精确的深度信息和摄像头图像丰富的语义信息。因此，结合这两种模态的多模态方法提供了更稳健的检测结果。然而，由于领域差距，有效地融合LiDAR点和图像仍然具有挑战性。此外，许多模型的性能受限于高质量标注数据量，这很难创建。近年来，基于大规模预训练的不同模态的基础模型的发展，使得多模态融合更加完善。结合提示工程技术以实现高效训练，我们提出了Prompted Foundational 3D Detector (PF3Det)，该技术整合了基础模型编码器和软提示来增强LiDAR-摄像头特征融合。PF3Det在有限的训练数据下实现了最先进的成果，在nuScenes数据集上提高了NDS 1.19%和mAP 2.42%，证明了其在3D检测中的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D object detection is crucial for autonomous driving, leveraging both LiDARpoint clouds for precise depth information and camera images for rich semanticinformation. Therefore, the multi-modal methods that combine both modalitiesoffer more robust detection results. However, efficiently fusing LiDAR pointsand images remains challenging due to the domain gaps. In addition, theperformance of many models is limited by the amount of high quality labeleddata, which is expensive to create. The recent advances in foundation models,which use large-scale pre-training on different modalities, enable bettermulti-modal fusion. Combining the prompt engineering techniques for efficienttraining, we propose the Prompted Foundational 3D Detector (PF3Det), whichintegrates foundation model encoders and soft prompts to enhance LiDAR-camerafeature fusion. PF3Det achieves the state-of-the-art results under limitedtraining data, improving NDS by 1.19% and mAP by 2.42% on the nuScenes dataset,demonstrating its efficiency in 3D detection.</description>
      <author>example@mail.com (Kaidong Li, Tianxiao Zhang, Kuan-Chuan Peng, Guanghui Wang)</author>
      <guid isPermaLink="false">2504.03563v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Robust Human Registration with Body Part Segmentation on Noisy Point Clouds</title>
      <link>http://arxiv.org/abs/2504.03602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种混合方法，用于将人体网格注册到3D点云中，以改善人体姿态估计和分割的准确性。&lt;h4&gt;背景&lt;/h4&gt;由于真实世界数据中的噪声和背景杂波，将人体网格注册到3D点云中对于增强现实和人类-机器人交互等应用至关重要，但通常会产生不精确的结果。&lt;h4&gt;目的&lt;/h4&gt;提高人体姿态估计和分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;方法首先为单个点分配身体部分标签，然后引导两步SMPL-X拟合：使用身体部分质心来估计初始姿态和方向，接着全局优化点云对齐。此外，还证明拟合的人体网格可以细化身体部分标签，从而提高分割效果。&lt;h4&gt;主要发现&lt;/h4&gt;在杂乱和噪声的真实世界数据集InterCap、EgoBody和BEHAVE上，该方法在姿态估计和分割精度方面显著优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;该方法显著提高了人体网格到3D点云注册的精度，对于增强现实和人类-机器人交互等领域具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：将人体网格注册到3D点云中对于增强现实和人类-机器人交互等应用至关重要，但由于真实世界数据中的噪声和背景杂波，常常会产生不精确的结果。我们提出了一种混合方法，该方法将身体部分分割结合到网格拟合过程中，从而提高了人体姿态估计和分割的准确性。该方法首先为单个点分配身体部分标签，然后引导两步SMPL-X拟合：使用身体部分质心来估计初始姿态和方向，接着全局优化点云对齐。此外，我们还证明拟合的人体网格可以细化身体部分标签，从而提高分割效果。在杂乱和噪声的真实世界数据集InterCap、EgoBody和BEHAVE上进行的评估表明，我们的方法在姿态估计和分割精度方面显著优于先前的方法。代码和结果可在我们的项目网站上找到：https://segfit.github.io&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Registering human meshes to 3D point clouds is essential for applicationssuch as augmented reality and human-robot interaction but often yieldsimprecise results due to noise and background clutter in real-world data. Weintroduce a hybrid approach that incorporates body-part segmentation into themesh fitting process, enhancing both human pose estimation and segmentationaccuracy. Our method first assigns body part labels to individual points, whichthen guide a two-step SMPL-X fitting: initial pose and orientation estimationusing body part centroids, followed by global refinement of the point cloudalignment. Additionally, we demonstrate that the fitted human mesh can refinebody part labels, leading to improved segmentation. Evaluations on thecluttered and noisy real-world datasets InterCap, EgoBody, and BEHAVE show thatour approach significantly outperforms prior methods in both pose estimationand segmentation accuracy. Code and results are available on our projectwebsite: https://segfit.github.io</description>
      <author>example@mail.com (Kai Lascheit, Daniel Barath, Marc Pollefeys, Leonidas Guibas, Francis Engelmann)</author>
      <guid isPermaLink="false">2504.03602v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating the Impact of Electrode Shift on Classification Performance in Electromyography-Based Motion Prediction Using Sliding-Window Normalization</title>
      <link>http://arxiv.org/abs/2504.03196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在运动估计中，尤其是EMG信号的应用中，如何减少电极位移带来的分类性能下降。&lt;h4&gt;背景&lt;/h4&gt;EMG信号在假肢、辅助服装和康复等领域有广泛应用。尽管运动估计技术取得了进展，但在跨个体泛化、电极位移和日常变化方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过技术手段减少电极位移对EMG信号分类性能的影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种滑动窗口归一化（SWN）技术，结合z-score归一化和滑动窗口方法来减少电极位移导致的分类性能下降。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SWN技术可以将分类误差降低到-1.0%，相较于未归一化的情况（-7.6%）提高了6.6%的分类准确率。当SWN与使用多个电极位置混合的策略结合时，分类准确率比基准情况提高了2.4%。&lt;h4&gt;结论&lt;/h4&gt;SWN技术能够有效减少电极位移导致的性能下降，从而增强基于EMG的运动估计系统的实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：电肌电图（EMG）信号在许多应用中都有使用，包括假手、辅助服装和康复。最近在运动估计方面的进展提高了性能，但跨个体泛化、电极位移和日常变化仍然存在挑战。当发生电极位移时，迁移学习和对抗性域适应通过减少性能差距至-1%（八类场景）来提高分类性能。然而，对于迁移学习中的再训练或对抗性域适应中的训练，还需要更多的数据。为了解决这个问题，我们研究了一种滑动窗口归一化（SWN）技术，在实时预测场景中。这种方法结合了z-score归一化和滑动窗口方法来减少电极位移导致的分类性能下降。我们使用涉及右臂的目标轨迹跟踪任务的实验数据验证了SWN的有效性。对于从EMG信号中获得的三个动作分类（休息、屈曲和伸展肘部），我们的离线分析表明，SWN将分类差异准确率降低到-1.0%，相较于未归一化的情况（-7.6%）提高了6.6%。此外，当SWN与使用多个电极位置混合的策略结合时，分类准确率比基准情况提高了2.4%。这些结果表明，SWN可以有效地减少由电极位移引起的性能下降，从而增强基于EMG的运动估计系统的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electromyography (EMG) signals are used in many applications, includingprosthetic hands, assistive suits, and rehabilitation. Recent advances inmotion estimation have improved performance, yet challenges remain incross-subject generalization, electrode shift, and daily variations. Whenelectrode shift occurs, both transfer learning and adversarial domainadaptation improve classification performance by reducing the performance gapto -1\% (eight-class scenario). However, additional data are needed forre-training in transfer learning or for training in adversarial domainadaptation. To address this issue, we investigated a sliding-windownormalization (SWN) technique in a real-time prediction scenario. This methodcombines z-score normalization with a sliding-window approach to reduce thedecline in classification performance caused by electrode shift. We validatedthe effectiveness of SWN using experimental data from a target trajectorytracking task involving the right arm. For three motions classification (rest,flexion, and extension of the elbow) obtained from EMG signals, our offlineanalysis showed that SWN reduced the differential classification accuracy to-1.0\%, representing a 6.6\% improvement compared to the case withoutnormalization (-7.6\%). Furthermore, when SWN was combined with a strategy thatuses a mixture of multiple electrode positions, classification accuracyimproved by an additional 2.4\% over the baseline. These results suggest thatSWN can effectively reduce the performance degradation caused by electrodeshift, thereby enhancing the practicality of EMG-based motion estimationsystems.</description>
      <author>example@mail.com (Taichi Tanaka, Isao Nambu, Yasuhiro Wada)</author>
      <guid isPermaLink="false">2504.03196v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>MME-Unify: A Comprehensive Benchmark for Unified Multimodal Understanding and Generation Models</title>
      <link>http://arxiv.org/abs/2504.03641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://mme-unify.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个全面的评估框架，用于评估统一的多模态语言模型（U-MLLMs），并发现现有U-MLLMs在处理混合模态任务方面存在性能差距。&lt;h4&gt;背景&lt;/h4&gt;现有的MLLM基准在评估U-MLLMs时面临挑战，包括缺乏标准化基准和混合模态生成基准。&lt;h4&gt;目的&lt;/h4&gt;设计一个评估框架，以系统地评估U-MLLMs。&lt;h4&gt;方法&lt;/h4&gt;该框架包括标准化传统任务评估、统一任务评估和综合模型基准测试。标准化传统任务评估从12个数据集中采样，涵盖10个任务和30个子任务。统一任务评估引入了5个新的测试多模态推理的任务。综合模型基准测试评估了12个领先的U-MLLMs，包括Janus-Pro、EMU3、VILA-U和Gemini2-flash，以及专门的理解和生成模型。&lt;h4&gt;主要发现&lt;/h4&gt;发现现有U-MLLMs在处理混合模态任务方面存在显著的性能差距。&lt;h4&gt;结论&lt;/h4&gt;需要更强大的模型来有效处理混合模态任务。&lt;h4&gt;翻译&lt;/h4&gt;Existing MLLM benchmarks face significant challenges in evaluating UnifiedMLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditional tasks, leading to inconsistent comparisons; 2) absence of benchmarks for mixed-modality generation, which fails to assess multimodal reasoning capabilities. We present a comprehensive evaluation framework designed to systematically assess U-MLLMs. Our benchmark includes: Standardized TraditionalTask Evaluation. We sample from 12 datasets, covering 10 tasks with 30 subtasks, ensuring consistent and fair comparisons across studies. 2. UnifiedTask Assessment. We introduce five novel tasks testing multimodal reasoning, including image editing, commonsense QA with image generation, and geometric reasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs, such as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specialized understanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3). Our findings reveal substantial performance gaps in existing U-MLLMs, highlighting the need for more robust models capable of handling mixed-modality tasks effectively. The code and evaluation data can be found in https://mme-unify.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing MLLM benchmarks face significant challenges in evaluating UnifiedMLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditionaltasks, leading to inconsistent comparisons; 2) absence of benchmarks formixed-modality generation, which fails to assess multimodal reasoningcapabilities. We present a comprehensive evaluation framework designed tosystematically assess U-MLLMs. Our benchmark includes: Standardized TraditionalTask Evaluation. We sample from 12 datasets, covering 10 tasks with 30subtasks, ensuring consistent and fair comparisons across studies." 2. UnifiedTask Assessment. We introduce five novel tasks testing multimodal reasoning,including image editing, commonsense QA with image generation, and geometricreasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs,such as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specializedunderstanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3).Our findings reveal substantial performance gaps in existing U-MLLMs,highlighting the need for more robust models capable of handling mixed-modalitytasks effectively. The code and evaluation data can be found inhttps://mme-unify.github.io/.</description>
      <author>example@mail.com (Wulin Xie, Yi-Fan Zhang, Chaoyou Fu, Yang Shi, Bingyan Nie, Hongkai Chen, Zhang Zhang, Liang Wang, Tieniu Tan)</author>
      <guid isPermaLink="false">2504.03641v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>AutoSSVH: Exploring Automated Frame Sampling for Efficient Self-Supervised Video Hashing</title>
      <link>http://arxiv.org/abs/2504.03587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR'25. 11 pages, 5 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AutoSSVH的Self-Supervised Video Hashing方法，通过对抗性帧采样和基于哈希的对比学习，提高了视频哈希编码的效率和检索性能。&lt;h4&gt;背景&lt;/h4&gt;现有的Self-Supervised Video Hashing方法依赖于随机帧采样，忽略了帧间的信息密度和重建难度，导致哈希码质量不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架AutoSSVH，旨在通过改进帧采样和引入新的哈希对比学习策略，提高视频哈希编码的性能。&lt;h4&gt;方法&lt;/h4&gt;AutoSSVH采用对抗性帧采样自动选择信息丰富的挑战性帧，增强编码能力。同时，引入哈希组件投票策略和基于点到集的哈希对比目标，以捕捉视频间的复杂语义关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AutoSSVH在检索效率和性能方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;AutoSSVH是一种有效的视频哈希编码方法，能够提高视频检索的效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new framework called AutoSSVH for Self-Supervised Video Hashing, which improves the efficiency and retrieval performance of video hashing through adversarial frame sampling and hash-based contrastive learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-Supervised Video Hashing (SSVH) compresses videos into hash codes forefficient indexing and retrieval using unlabeled training videos. Existingapproaches rely on random frame sampling to learn video features and treat allframes equally. This results in suboptimal hash codes, as it ignoresframe-specific information density and reconstruction difficulty. To addressthis limitation, we propose a new framework, termed AutoSSVH, that employsadversarial frame sampling with hash-based contrastive learning. Ouradversarial sampling strategy automatically identifies and selects challengingframes with richer information for reconstruction, enhancing encodingcapability. Additionally, we introduce a hash component voting strategy and apoint-to-set (P2Set) hash-based contrastive objective, which help capturecomplex inter-video semantic relationships in the Hamming space and improve thediscriminability of learned hash codes. Extensive experiments demonstrate thatAutoSSVH achieves superior retrieval efficacy and efficiency compared tostate-of-the-art approaches. Code is available athttps://github.com/EliSpectre/CVPR25-AutoSSVH.</description>
      <author>example@mail.com (Niu Lian, Jun Li, Jinpeng Wang, Ruisheng Luo, Yaowei Wang, Shu-Tao Xia, Bin Chen)</author>
      <guid isPermaLink="false">2504.03587v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Training Enhances Machine Learning Potentials for Long-Lasting Molecular Dynamics</title>
      <link>http://arxiv.org/abs/2504.03521v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为动态训练（DT）的方法，旨在提高分子动力学（MD）模拟的模型性能，并在氢分子与锚定在石墨烯空位处的钯团簇的复杂系统中取得了比传统方法更优越的预测精度。&lt;h4&gt;背景&lt;/h4&gt;分子动力学模拟在计算物理学和化学中至关重要，但与从头计算方法相比，机器学习方法在长期模拟中的准确性仍然有限。&lt;h4&gt;目的&lt;/h4&gt;提出动态训练（DT）方法，以增强模型在长期分子动力学模拟中的性能。&lt;h4&gt;方法&lt;/h4&gt;将动态训练（DT）应用于等变图神经网络（EGNN），用于模拟氢分子与钯团簇的相互作用。&lt;h4&gt;主要发现&lt;/h4&gt;动态训练（DT）在模拟中显示出比传统方法更高的预测精度，并且其架构独立的设计确保了其在各种机器学习势能中的应用。&lt;h4&gt;结论&lt;/h4&gt;动态训练（DT）是一种实用的工具，可以推进分子动力学模拟的进展，尤其是在长期模拟中提高模型性能方面具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular Dynamics (MD) simulations are vital for exploring complex systemsin computational physics and chemistry. While machine learning methodsdramatically reduce computational costs relative to ab initio methods, theiraccuracy in long-lasting simulations remains limited. Here we propose dynamictraining (DT), a method designed to enhance model performance over extended MDsimulations. Applying DT to an equivariant graph neural network (EGNN) on thechallenging system of a hydrogen molecule interacting with a palladium clusteranchored to a graphene vacancy demonstrates a superior prediction accuracycompared to conventional approaches. Crucially, the DT architecture-independentdesign ensures its applicability across diverse machine learning potentials,making it a practical tool for advancing MD simulations.</description>
      <author>example@mail.com (Ivan Žugec, Tin Hadži Veljković, Maite Alducin, J. Iñaki Juaristi)</author>
      <guid isPermaLink="false">2504.03521v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>RANa: Retrieval-Augmented Navigation</title>
      <link>http://arxiv.org/abs/2504.03524v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基于大规模学习的导航方法，该方法能够利用先前操作收集的信息，通过引入检索增强的智能体和独特的智能体架构，在ObjectNav、ImageNav和Instance-ImageNav任务上显著提高性能。&lt;h4&gt;背景&lt;/h4&gt;现有的基于大规模学习的导航方法通常将每个场景视为新的问题，智能体在未知环境中以干净的记忆开始。然而，在实际环境中，智能体应该能够利用先前操作收集的信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，使智能体能够利用先前操作收集的信息，从而在未知环境中进行更有效的导航。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的基于强化学习的检索增强智能体，该智能体能够查询从先前场景收集的数据库，并学习如何整合额外的上下文信息。该方法采用了一种独特的智能体架构，并使用视觉基础模型（FM）进行语义和几何理解。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在ObjectNav、ImageNav和Instance-ImageNav任务上进行了评估，结果表明检索技术允许零样本迁移，并在多个任务和环境之间显著提高了性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入检索增强的智能体，可以显著提高基于大规模学习的导航方法的性能，使其在未知环境中更加有效。&lt;h4&gt;翻译&lt;/h4&gt;Methods for navigation based on large-scale learning typically treat each episode as a new problem, where the agent is spawned with a clean memory in an unknown environment. While these generalization capabilities to an unknown environment are extremely important, we claim that, in a realistic setting, an agent should have the capacity of exploiting information collected during earlier robot operations. We address this by introducing a new retrieval-augmented agent, trained with RL, capable of querying a database collected from previous episodes in the same environment and learning how to integrate this additional context information. We introduce a unique agent architecture for the general navigation task, evaluated on ObjectNav, ImageNav and Instance-ImageNav. Our retrieval and context encoding methods are data-driven and heavily employ vision foundation models (FM) for both semantic and geometric understanding. We propose new benchmarks for these settings and we show that retrieval allows zero-shot transfer across tasks and environments while significantly improving performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Methods for navigation based on large-scale learning typically treat eachepisode as a new problem, where the agent is spawned with a clean memory in anunknown environment. While these generalization capabilities to an unknownenvironment are extremely important, we claim that, in a realistic setting, anagent should have the capacity of exploiting information collected duringearlier robot operations. We address this by introducing a newretrieval-augmented agent, trained with RL, capable of querying a databasecollected from previous episodes in the same environment and learning how tointegrate this additional context information. We introduce a unique agentarchitecture for the general navigation task, evaluated on ObjectNav, ImageNavand Instance-ImageNav. Our retrieval and context encoding methods aredata-driven and heavily employ vision foundation models (FM) for both semanticand geometric understanding. We propose new benchmarks for these settings andwe show that retrieval allows zero-shot transfer across tasks and environmentswhile significantly improving performance.</description>
      <author>example@mail.com (Gianluca Monaci, Rafael S. Rezende, Romain Deffayet, Gabriela Csurka, Guillaume Bono, Hervé Déjean, Stéphane Clinchant, Christian Wolf)</author>
      <guid isPermaLink="false">2504.03524v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>ZFusion: An Effective Fuser of Camera and 4D Radar for 3D Object Perception in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.03438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 WDFM-AD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ZFusion的3D物体检测方法，该方法融合了4D雷达和视觉信息，以实现可靠的自动驾驶3D物体感知。&lt;h4&gt;背景&lt;/h4&gt;4D雷达因其全天候的感知能力而受到关注，但其提供的点云数据比LiDAR稀疏。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以提高3D物体检测的准确性，同时降低成本。&lt;h4&gt;方法&lt;/h4&gt;ZFusion方法的核心是FP-DDCA（特征金字塔-双可变形交叉注意力）融合器，它通过特征金字塔结构和Transformer块在不同尺度上交互式融合多模态特征。此外，还使用了Depth-Context-Split视图转换模块来利用4D雷达的物理特性。&lt;h4&gt;主要发现&lt;/h4&gt;在VoD（Delft视图）数据集等典型交通场景中，ZFusion在感兴趣区域实现了最先进的mAP（平均平均精度），并且在整个区域与基线方法相比具有竞争力的mAP，表明其性能接近LiDAR，并显著优于仅使用摄像头的方案。&lt;h4&gt;结论&lt;/h4&gt;ZFusion是一种有吸引力的替代方案，可以降低自动驾驶中3D物体检测的成本，同时保持高性能。&lt;h4&gt;翻译&lt;/h4&gt;Reliable 3D object perception is essential in autonomous driving. Owing to its sensing capabilities in all weather conditions, 4D radar has recently received much attention. However, compared to LiDAR, 4D radar provides much sparser point cloud. In this paper, we propose a 3D object detection method, termed ZFusion, which fuses 4D radar and vision modality. As the core of ZFusion, our proposed FP-DDCA (Feature Pyramid-Double Deformable CrossAttention) fuser complements the (sparse) radar information and (dense) vision information, effectively. Specifically, with a feature-pyramid structure, the FP-DDCA fuser packs Transformer blocks to interactively fuse multi-modal features at different scales, thus enhancing perception accuracy. In addition, we utilize the Depth-Context-Split view transformation module due to the physical properties of 4D radar. Considering that 4D radar has a much lower cost than LiDAR, ZFusion is an attractive alternative to LiDAR-based methods. In typical traffic scenarios like the VoD (View-of-Delft) dataset, experiments show that with reasonable inference speed, ZFusion achieved the state-of-the-art mAP (mean average precision) in the region of interest, while having competitive mAP in the entire area compared to the baseline methods, which demonstrates performance close to LiDAR and greatly outperforms those camera-only methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable 3D object perception is essential in autonomous driving. Owing toits sensing capabilities in all weather conditions, 4D radar has recentlyreceived much attention. However, compared to LiDAR, 4D radar provides muchsparser point cloud. In this paper, we propose a 3D object detection method,termed ZFusion, which fuses 4D radar and vision modality. As the core ofZFusion, our proposed FP-DDCA (Feature Pyramid-Double Deformable CrossAttention) fuser complements the (sparse) radar information and (dense) visioninformation, effectively. Specifically, with a feature-pyramid structure, theFP-DDCA fuser packs Transformer blocks to interactively fuse multi-modalfeatures at different scales, thus enhancing perception accuracy. In addition,we utilize the Depth-Context-Split view transformation module due to thephysical properties of 4D radar. Considering that 4D radar has a much lowercost than LiDAR, ZFusion is an attractive alternative to LiDAR-based methods.In typical traffic scenarios like the VoD (View-of-Delft) dataset, experimentsshow that with reasonable inference speed, ZFusion achieved thestate-of-the-art mAP (mean average precision) in the region of interest, whilehaving competitive mAP in the entire area compared to the baseline methods,which demonstrates performance close to LiDAR and greatly outperforms thosecamera-only methods.</description>
      <author>example@mail.com (Sheng Yang, Tong Zhan, Shichen Qiao, Jicheng Gong, Qing Yang, Yanfeng Lu, Jian Wang)</author>
      <guid isPermaLink="false">2504.03438v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Specific and Shared Parameters for Efficient Parameter Tuning</title>
      <link>http://arxiv.org/abs/2504.03450v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SaS的新型Parameter-Efficient Transfer Learning (PETL)方法，旨在高效地适应下游任务，同时减少计算开销。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型在众多应用中取得了最先进的性能，但将它们有效地适应下游任务是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;解决将基础模型适应下游任务时计算开销的问题。&lt;h4&gt;方法&lt;/h4&gt;SaS方法通过调整一小部分参数来微调模型，同时保留预训练知识。它包含一个共享模块和一个特定层模块：(1) 共享模块使用低秩投影捕获跨层共有的统计特征；(2) 特定层模块使用超网络为每一层生成定制参数。&lt;h4&gt;主要发现&lt;/h4&gt;SaS在多样化的下游任务、少样本设置和领域泛化实验中显著提高了性能，同时保持了优于现有方法的参数效率。SaS的参数量增加了不到0.05%，比现有方法更为紧凑。&lt;h4&gt;结论&lt;/h4&gt;SaS强调了在迁移学习中捕捉共享和层特定信息的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Foundation models, with a vast number of parameters and pretraining on massive datasets, achieve state-of-the-art performance across various applications. However, efficiently adapting them to downstream tasks with minimal computational overhead remains a challenge. Parameter-Efficient Transfer Learning (PETL) addresses this by fine-tuning only a small subset of parameters while preserving pre-trained knowledge. In this paper, we propose SaS, a novel PETL method that effectively mitigates distributional shifts during fine-tuning. SaS integrates (1) a shared module that captures common statistical characteristics across layers using low-rank projections and (2) a layer-specific module that employs hypernetworks to generate tailored parameters for each layer. This dual design ensures an optimal balance between performance and parameter efficiency while introducing less than 0.05% additional parameters, making it significantly more compact than existing methods. Extensive experiments on diverse downstream tasks, few-shot settings and domain generalization demonstrate that SaS significantly enhances performance while maintaining superior parameter efficiency compared to existing methods, highlighting the importance of capturing both shared and layer-specific information in transfer learning. Code and data are available at https://anonymous.4open.science/r/SaS-PETL-3565.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, with a vast number of parameters and pretraining onmassive datasets, achieve state-of-the-art performance across variousapplications. However, efficiently adapting them to downstream tasks withminimal computational overhead remains a challenge. Parameter-EfficientTransfer Learning (PETL) addresses this by fine-tuning only a small subset ofparameters while preserving pre-trained knowledge. In this paper, we proposeSaS, a novel PETL method that effectively mitigates distributional shiftsduring fine-tuning. SaS integrates (1) a shared module that captures commonstatistical characteristics across layers using low-rank projections and (2) alayer-specific module that employs hypernetworks to generate tailoredparameters for each layer. This dual design ensures an optimal balance betweenperformance and parameter efficiency while introducing less than 0.05%additional parameters, making it significantly more compact than existingmethods. Extensive experiments on diverse downstream tasks, few-shot settingsand domain generalization demonstrate that SaS significantly enhancesperformance while maintaining superior parameter efficiency compared toexisting methods, highlighting the importance of capturing both shared andlayer-specific information in transfer learning. Code and data are available athttps://anonymous.4open.science/r/SaS-PETL-3565.</description>
      <author>example@mail.com (Van-Anh Nguyen, Thanh-Toan Do, Mehrtash Harandi, Dinh Phung, Trung Le)</author>
      <guid isPermaLink="false">2504.03450v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>ATM-Net: Anatomy-Aware Text-Guided Multi-Modal Fusion for Fine-Grained Lumbar Spine Segmentation</title>
      <link>http://arxiv.org/abs/2504.03476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ATM-Net是一个创新的框架，用于腰椎结构的精细分割，显著优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;精确的腰椎脊柱分割对诊断脊柱疾病至关重要，现有方法缺乏精细细节，并且依赖于视觉模型导致分类错误。&lt;h4&gt;目的&lt;/h4&gt;提出ATM-Net框架，解决现有方法的局限性，实现腰椎结构的精细分割。&lt;h4&gt;方法&lt;/h4&gt;ATM-Net采用解剖感知、文本引导的多模态融合机制，结合ATPG将图像标注转换为解剖感知提示，并使用HASF模块整合这些提示与图像特征，通过CCAE模块进行多模态对比学习以增强分类和细化分割。&lt;h4&gt;主要发现&lt;/h4&gt;在MRSpineSeg和SPIDER数据集上的实验表明，ATM-Net在分类判别和分割细节方面均显著优于现有方法，例如在SPIDER数据集上达到Dice指数79.39%和HD95值9.91像素，优于SpineParseNet的8.31%和4.14像素。&lt;h4&gt;结论&lt;/h4&gt;ATM-Net是一个有效的腰椎脊柱分割方法，能够提供更精确的诊断结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate lumbar spine segmentation is crucial for diagnosing spinaldisorders. Existing methods typically use coarse-grained segmentationstrategies that lack the fine detail needed for precise diagnosis.Additionally, their reliance on visual-only models hinders the capture ofanatomical semantics, leading to misclassified categories and poor segmentationdetails. To address these limitations, we present ATM-Net, an innovativeframework that employs an anatomy-aware, text-guided, multi-modal fusionmechanism for fine-grained segmentation of lumbar substructures, i.e.,vertebrae (VBs), intervertebral discs (IDs), and spinal canal (SC). ATM-Netadopts the Anatomy-aware Text Prompt Generator (ATPG) to adaptively convertimage annotations into anatomy-aware prompts in different views. These insightsare further integrated with image features via the Holistic Anatomy-awareSemantic Fusion (HASF) module, building a comprehensive anatomical context. TheChannel-wise Contrastive Anatomy-Aware Enhancement (CCAE) module furtherenhances class discrimination and refines segmentation through class-wisechannel-level multi-modal contrastive learning. Extensive experiments on theMRSpineSeg and SPIDER datasets demonstrate that ATM-Net significantlyoutperforms state-of-the-art methods, with consistent improvements regardingclass discrimination and segmentation details. For example, ATM-Net achievesDice of 79.39% and HD95 of 9.91 pixels on SPIDER, outperforming the competitiveSpineParseNet by 8.31% and 4.14 pixels, respectively.</description>
      <author>example@mail.com (Sheng Lian, Dengfeng Pan, Jianlong Cai, Guang-Yong Chen, Zhun Zhong, Zhiming Luo, Shen Zhao, Shuo Li)</author>
      <guid isPermaLink="false">2504.03476v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Locations of Characters in Narratives: Andersen and Persuasion Datasets</title>
      <link>http://arxiv.org/abs/2504.03434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 3 figures, 10 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了机器在叙述语境中理解空间关系的能力，并引入了两个新的数据集：Andersen和Persuasion，用于测试AI理解人物与地点之间关系的能力。&lt;h4&gt;背景&lt;/h4&gt;机器在叙述语境中理解空间关系的能力是阅读理解中的一个有趣方面，这一领域的研究仍在进行中。&lt;h4&gt;目的&lt;/h4&gt;为了测试AI在理解叙述中人物与其相应地点关系方面的能力。&lt;h4&gt;方法&lt;/h4&gt;研究者从汉斯·克里斯蒂安·安徒生的《安徒生童话》中选择了十五个儿童故事，并对每个故事中的人物及其位置进行了手动标注，形成了Andersen数据集。同样，研究者对简·奥斯汀的小说《劝导》中的人物及其位置也进行了手动标注，形成了Persuasion数据集。然后，研究者使用这些数据集来提示大型语言模型（LLMs），通过从故事或小说中提取摘录并结合询问该摘录中提到的人物位置的问题来创建提示。&lt;h4&gt;主要发现&lt;/h4&gt;在测试的五种LLMs中，Andersen数据集表现最好的LLM准确识别出61.85%的例子中的位置，而在Persuasion数据集中，表现最好的LLM在56.06%的案例中做到了这一点。&lt;h4&gt;结论&lt;/h4&gt;这些发现表明，LLMs在理解叙述中的空间关系方面具有一定的能力，但仍存在改进空间。&lt;h4&gt;翻译&lt;/h4&gt;The study explores the ability of machines to grasp spatial understanding within narrative contexts, and introduces two new datasets: Andersen and Persuasion, to test the AI's competence in understanding the relationship between characters and their respective locations in narratives.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability of machines to grasp spatial understanding within narrativecontexts is an intriguing aspect of reading comprehension that continues to bestudied. Motivated by the goal to test the AI's competence in understanding therelationship between characters and their respective locations in narratives,we introduce two new datasets: Andersen and Persuasion. For the Andersendataset, we selected fifteen children's stories from "Andersen's Fairy Tales"by Hans Christian Andersen and manually annotated the characters and theirrespective locations throughout each story. Similarly, for the Persuasiondataset, characters and their locations in the novel "Persuasion" by JaneAusten were also manually annotated. We used these datasets to prompt LargeLanguage Models (LLMs). The prompts are created by extracting excerpts from thestories or the novel and combining them with a question asking the location ofa character mentioned in that excerpt. Out of the five LLMs we tested, thebest-performing one for the Andersen dataset accurately identified the locationin 61.85% of the examples, while for the Persuasion dataset, thebest-performing one did so in 56.06% of the cases.</description>
      <author>example@mail.com (Batuhan Ozyurt, Roya Arkhmammadova, Deniz Yuret)</author>
      <guid isPermaLink="false">2504.03434v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Quantum Circuits via ZX Diagrams using Reinforcement Learning and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.03429v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于ZX计算、图神经网络和强化学习的量子电路优化框架，旨在减少噪声对量子计算的影响。&lt;h4&gt;背景&lt;/h4&gt;量子计算受噪声影响较大，尤其是双量子比特门的引入，因此减少双量子比特门数量至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了提高量子计算的可靠性，研究提出了一种新的量子电路优化方法。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了强化学习和树搜索，通过ZX图直接操作，寻找减少CNOT门数量的电路优化规则。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够在所有可能的电路变换空间中搜索，发现任意优化规则，并在大量不同随机电路上展现出与现有电路优化器相媲美的竞争力。&lt;h4&gt;结论&lt;/h4&gt;该研究为量子电路优化提供了一种新的思路，有助于提高量子计算的可靠性。&lt;h4&gt;翻译&lt;/h4&gt;Quantum computing is currently strongly limited by the impact of noise, inparticular introduced by the application of two-qubit gates. For this reason, reducing the number of two-qubit gates is of paramount importance on noisy intermediate-scale quantum hardware. To advance towards more reliable quantum computing, we introduce a framework based on ZX calculus, graph-neural networks and reinforcement learning for quantum circuit optimization. By combining reinforcement learning and tree search, our method addresses the challenge of selecting optimal sequences of ZX calculus rewrite rules. Instead of relying on existing heuristic rules for minimizing circuits, our method trains a novel reinforcement learning policy that directly operates on ZX-graphs, therefore allowing us to search through the space of all possible circuit transformations to find a circuit significantly minimizing the number of CNOT gates. This way we can scale beyond hard-coded rules towards discovering arbitrary optimization rules. We demonstrate our method's competetiveness with state-of-the-art circuit optimizers and generalization capabilities on large sets of diverserandom circuits.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum computing is currently strongly limited by the impact of noise, inparticular introduced by the application of two-qubit gates. For this reason,reducing the number of two-qubit gates is of paramount importance on noisyintermediate-scale quantum hardware. To advance towards more reliable quantumcomputing, we introduce a framework based on ZX calculus, graph-neural networksand reinforcement learning for quantum circuit optimization. By combiningreinforcement learning and tree search, our method addresses the challenge ofselecting optimal sequences of ZX calculus rewrite rules. Instead of relying onexisting heuristic rules for minimizing circuits, our method trains a novelreinforcement learning policy that directly operates on ZX-graphs, thereforeallowing us to search through the space of all possible circuit transformationsto find a circuit significantly minimizing the number of CNOT gates. This waywe can scale beyond hard-coded rules towards discovering arbitrary optimizationrules. We demonstrate our method's competetiveness with state-of-the-artcircuit optimizers and generalization capabilities on large sets of diverserandom circuits.</description>
      <author>example@mail.com (Alexander Mattick, Maniraman Periyasamy, Christian Ufrecht, Abhishek Y. Dubey, Christopher Mutschler, Axel Plinge, Daniel D. Scherer)</author>
      <guid isPermaLink="false">2504.03429v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Early detection of diabetes through transfer learning-based eye (vision) screening and improvement of machine learning model performance and advanced parameter setting algorithms</title>
      <link>http://arxiv.org/abs/2504.03439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages,12 Figures, 1 Table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用迁移学习（TL）技术提高糖尿病视网膜病变（DR）检测的机器学习模型性能，通过降维、优化学习率调整和高级参数调优算法，提高了检测效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;糖尿病视网膜病变是糖尿病的严重并发症，由长期高血糖水平导致的视网膜小血管损伤引起。未治疗的DR可能导致视网膜静脉阻塞和异常血管生长，显著增加失明的风险。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过迁移学习技术提高糖尿病视网膜病变检测的机器学习模型性能，以实现早期诊断，及时干预，防止视力丧失并改善患者预后。&lt;h4&gt;方法&lt;/h4&gt;研究采用了迁移学习技术，包括降维、优化学习率调整和高级参数调优算法，以提高模型的效率和诊断准确性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的模型在测试数据集上实现了84%的整体准确率，超过了先前的研究。最高类别特定准确率达到89%，最大敏感性为97%，F1分数为92%，表明在识别DR病例方面具有强大性能。&lt;h4&gt;结论&lt;/h4&gt;基于迁移学习的DR筛查是早期诊断的有前景的方法，能够实现及时干预，防止视力丧失并改善患者预后。&lt;h4&gt;翻译&lt;/h4&gt;Diabetic Retinopathy (DR) is a serious and common complication of diabetes, caused by prolonged high blood sugar levels that damage the small retinal blood vessels. If left untreated, DR can progress to retinal vein occlusion and stimulate abnormal blood vessel growth, significantly increasing the risk of blindness. Traditional diabetes diagnosis methods often utilize convolutional neural networks (CNNs) to extract visual features from retinal images, followed by classification algorithms such as decision trees and k-nearest neighbors (KNN) for disease detection. However, these approaches face several challenges, including low accuracy and sensitivity, lengthy machine learning (ML) model training due to high data complexity and volume, and the use of limited datasets for testing and evaluation. This study investigates the application of transfer learning (TL) to enhance ML model performance in DR detection. Key improvements include dimensionality reduction, optimized learning rate adjustments, and advanced parameter tuning algorithms, aimed at increasing efficiency and diagnostic accuracy. The proposed model achieved an overall accuracy of 84% on the testing dataset, outperforming prior studies. The highest class-specific accuracy reached 89%, with a maximum sensitivity of 97% and an F1-score of 92%, demonstrating strong performance in identifying DR cases. These findings suggest that TL-based DR screening is a promising approach for early diagnosis, enabling timely interventions to prevent vision loss and improve patient outcomes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diabetic Retinopathy (DR) is a serious and common complication of diabetes,caused by prolonged high blood sugar levels that damage the small retinal bloodvessels. If left untreated, DR can progress to retinal vein occlusion andstimulate abnormal blood vessel growth, significantly increasing the risk ofblindness. Traditional diabetes diagnosis methods often utilize convolutionalneural networks (CNNs) to extract visual features from retinal images, followedby classification algorithms such as decision trees and k-nearest neighbors(KNN) for disease detection. However, these approaches face several challenges,including low accuracy and sensitivity, lengthy machine learning (ML) modeltraining due to high data complexity and volume, and the use of limiteddatasets for testing and evaluation. This study investigates the application oftransfer learning (TL) to enhance ML model performance in DR detection. Keyimprovements include dimensionality reduction, optimized learning rateadjustments, and advanced parameter tuning algorithms, aimed at increasingefficiency and diagnostic accuracy. The proposed model achieved an overallaccuracy of 84% on the testing dataset, outperforming prior studies. Thehighest class-specific accuracy reached 89%, with a maximum sensitivity of 97%and an F1-score of 92%, demonstrating strong performance in identifying DRcases. These findings suggest that TL-based DR screening is a promisingapproach for early diagnosis, enabling timely interventions to prevent visionloss and improve patient outcomes.</description>
      <author>example@mail.com (Mohammad Reza Yousefi, Ali Bakrani, Amin Dehghani)</author>
      <guid isPermaLink="false">2504.03439v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Decentralized Collective World Model for Emergent Communication and Coordination</title>
      <link>http://arxiv.org/abs/2504.03353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种完全去中心化的多智能体世界模型，该模型通过时间扩展的集体预测编码实现符号的涌现和协调行为。该模型同时实现了通信和协调，并通过对比学习进行信息交流，从而预测环境动态，估计状态，并共享关键信息。&lt;h4&gt;背景&lt;/h4&gt;以往的研究要么关注通信，要么关注协调，而本文提出的方法同时实现了这两者。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时实现通信和协调的多智能体世界模型。&lt;h4&gt;方法&lt;/h4&gt;该方法将世界模型与通信渠道集成，通过双向消息交换和对比学习进行信息对齐，使智能体能够预测环境动态，从部分观察中估计状态，并共享关键信息。&lt;h4&gt;主要发现&lt;/h4&gt;在两个智能体的轨迹绘制任务中，基于通信的方法在智能体具有不同的感知能力时优于非通信模型，实现了仅次于集中式模型的第二好的协调效果。去中心化的方法通过限制直接访问其他智能体的内部状态，促进了更有意义的符号系统的涌现，这些符号系统能够准确反映环境状态。&lt;h4&gt;结论&lt;/h4&gt;去中心化的通信对于支持协调并发展对环境的共享表示是有效的。&lt;h4&gt;翻译&lt;/h4&gt;We propose a fully decentralized multi-agent world model that enables both symbol emergence for communication and coordinated behavior through temporal extension of collective predictive coding. Unlike previous research that focuses on either communication or coordination separately, our approach achieves both simultaneously. Our method integrates world models with communication channels, enabling agents to predict environmental dynamics, estimate states from partial observations, and share critical information through bidirectional message exchange with contrastive learning for message alignment. Using a two-agent trajectory drawing task, we demonstrate that our communication-based approach outperforms non-communicative models when agents have divergent perceptual capabilities, achieving the second-best coordination after centralized models. Importantly, our distributed approach with constraints preventing direct access to other agents' internal states facilitates the emergence of more meaningful symbol systems that accurately reflect environmental states. These findings demonstrate the effectiveness of decentralized communication for supporting coordination while developing shared representations of the environment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a fully decentralized multi-agent world model that enables bothsymbol emergence for communication and coordinated behavior through temporalextension of collective predictive coding. Unlike previous research thatfocuses on either communication or coordination separately, our approachachieves both simultaneously. Our method integrates world models withcommunication channels, enabling agents to predict environmental dynamics,estimate states from partial observations, and share critical informationthrough bidirectional message exchange with contrastive learning for messagealignment. Using a two-agent trajectory drawing task, we demonstrate that ourcommunication-based approach outperforms non-communicative models when agentshave divergent perceptual capabilities, achieving the second-best coordinationafter centralized models. Importantly, our distributed approach withconstraints preventing direct access to other agents' internal statesfacilitates the emergence of more meaningful symbol systems that accuratelyreflect environmental states. These findings demonstrate the effectiveness ofdecentralized communication for supporting coordination while developing sharedrepresentations of the environment.</description>
      <author>example@mail.com (Kentaro Nomura, Tatsuya Aoki, Tadahiro Taniguchi, Takato Horii)</author>
      <guid isPermaLink="false">2504.03353v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>NuScenes-SpatialQA: A Spatial Understanding and Reasoning Benchmark for Vision-Language Models in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.03164v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了视觉语言模型（VLMs）在自动驾驶任务中的应用，指出其在空间理解和推理方面存在局限性，并提出了一种新的基准测试方法NuScenes-SpatialQA来评估VLMs的空间理解能力。&lt;h4&gt;背景&lt;/h4&gt;近年来，VLMs在自动驾驶任务中展现出巨大潜力，但其空间理解和推理能力仍有待提高。&lt;h4&gt;目的&lt;/h4&gt;提出NuScenes-SpatialQA基准，系统地评估VLMs在自动驾驶中的空间理解和推理能力。&lt;h4&gt;方法&lt;/h4&gt;基于NuScenes数据集，通过自动化的3D场景图生成和问答生成流程构建基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，空间增强型VLM在定性问答中表现优于其他模型，但在定量问答中并未展现出竞争力。&lt;h4&gt;结论&lt;/h4&gt;VLMs在空间理解和推理方面仍面临重大挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，视觉-语言模型（VLMs）在自动驾驶任务中显示出强大的潜力。然而，它们的空间理解和推理能力——自动驾驶的关键能力——仍然存在显著限制。值得注意的是，现有的基准测试没有一个系统地评估VLMs在驾驶场景中的空间推理能力。为了填补这一空白，我们提出了NuScenes-SpatialQA，这是第一个大规模基于真实数据的问答（QA）基准，专门设计用于评估VLMs在自动驾驶中的空间理解和推理能力。该基准建立在NuScenes数据集之上，通过自动化的3D场景图生成流程和问答生成流程构建。该基准系统地评估了VLMs在空间理解和推理方面的表现。使用这个基准，我们对多种VLMs进行了广泛的实验，包括通用模型和空间增强型模型，提供了对它们在自动驾驶中空间能力的第一项全面评估。令人惊讶的是，实验结果表明，空间增强型VLM在定性问答方面表现优于其他模型，但在定量问答方面并未显示出竞争力。总的来说，VLMs在空间理解和推理方面仍然面临相当大的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Vision-Language Models (VLMs) have demonstrated strongpotential for autonomous driving tasks. However, their spatial understandingand reasoning-key capabilities for autonomous driving-still exhibit significantlimitations. Notably, none of the existing benchmarks systematically evaluateVLMs' spatial reasoning capabilities in driving scenarios. To fill this gap, wepropose NuScenes-SpatialQA, the first large-scale ground-truth-basedQuestion-Answer (QA) benchmark specifically designed to evaluate the spatialunderstanding and reasoning capabilities of VLMs in autonomous driving. Builtupon the NuScenes dataset, the benchmark is constructed through an automated 3Dscene graph generation pipeline and a QA generation pipeline. The benchmarksystematically evaluates VLMs' performance in both spatial understanding andreasoning across multiple dimensions. Using this benchmark, we conductextensive experiments on diverse VLMs, including both general andspatial-enhanced models, providing the first comprehensive evaluation of theirspatial capabilities in autonomous driving. Surprisingly, the experimentalresults show that the spatial-enhanced VLM outperforms in qualitative QA butdoes not demonstrate competitiveness in quantitative QA. In general, VLMs stillface considerable challenges in spatial understanding and reasoning.</description>
      <author>example@mail.com (Kexin Tian, Jingrui Mao, Yunlong Zhang, Jiwan Jiang, Yang Zhou, Zhengzhong Tu)</author>
      <guid isPermaLink="false">2504.03164v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>MultiClear: Multimodal Soft Exoskeleton Glove for Transparent Object Grasping Assistance</title>
      <link>http://arxiv.org/abs/2504.03379v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MultiClear的多模态框架，旨在通过融合RGB数据、深度数据和听觉信号来增强可穿戴软外骨骼手套在抓取透明物体时的辅助功能。&lt;h4&gt;背景&lt;/h4&gt;抓取是与环境互动的基本技能，但对于某些人来说（例如由于残疾）这项能力可能很难。可穿戴机器人解决方案可以增强或恢复手的功能，而最近的研究利用计算机视觉来提高抓取能力。然而，由于透明物体视觉对比度差和深度线索模糊，抓取透明物体仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种多模态框架，以增强可穿戴软外骨骼手套在抓取透明物体时的辅助功能。&lt;h4&gt;方法&lt;/h4&gt;该手套集成了腱驱动执行器、RGB-D相机和内置麦克风。为了实现精确和自适应控制，提出了一种分层控制架构。该架构包括提供上下文感知的高层控制层、处理多模态感官输入的中层控制层以及执行PID电机控制的低层控制层。透明物体分割的挑战通过引入用于零样本分割的视觉基础模型来管理。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在透明物体操作中实现了70.37%的抓取能力评分，证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;MultiClear框架能够有效提高抓取透明物体的能力，为可穿戴机器人手套提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：抓取是与环境互动的基本技能。然而，这项能力对于一些人来说可能很难（例如由于残疾）。可穿戴机器人解决方案可以增强或恢复手的功能，而最近的研究利用计算机视觉来提高抓取能力。然而，由于透明物体视觉对比度差和深度线索模糊，抓取透明物体仍然具有挑战性。此外，虽然已经探索了结合触觉和听觉反馈的多模态控制策略来抓取透明物体，但视觉与这些模态的集成仍然处于发展阶段。本文介绍了一种名为MultiClear的多模态框架，旨在通过融合RGB数据、深度数据和听觉信号来增强可穿戴软外骨骼手套在抓取透明物体时的辅助功能。该外骨骼手套集成了腱驱动执行器、RGB-D相机和内置麦克风。为了实现精确和自适应控制，提出了一种分层控制架构。对于所提出的分层控制架构，高层控制层提供上下文感知，中层控制层处理多模态感官输入，低层控制层执行PID电机控制以进行精细的抓取调整。通过引入用于零样本分割的视觉基础模型来管理透明物体分割的挑战。所提出的系统实现了70.37%的抓取能力评分，证明了其在透明物体操作中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasping is a fundamental skill for interacting with the environment.However, this ability can be difficult for some (e.g. due to disability).Wearable robotic solutions can enhance or restore hand function, and recentadvances have leveraged computer vision to improve grasping capabilities.However, grasping transparent objects remains challenging due to their poorvisual contrast and ambiguous depth cues. Furthermore, while multimodal controlstrategies incorporating tactile and auditory feedback have been explored tograsp transparent objects, the integration of vision with these modalitiesremains underdeveloped. This paper introduces MultiClear, a multimodalframework designed to enhance grasping assistance in a wearable softexoskeleton glove for transparent objects by fusing RGB data, depth data, andauditory signals. The exoskeleton glove integrates a tendon-driven actuatorwith an RGB-D camera and a built-in microphone. To achieve precise and adaptivecontrol, a hierarchical control architecture is proposed. For the proposedhierarchical control architecture, a high-level control layer providescontextual awareness, a mid-level control layer processes multimodal sensoryinputs, and a low-level control executes PID motor control for fine-tunedgrasping adjustments. The challenge of transparent object segmentation wasmanaged by introducing a vision foundation model for zero-shot segmentation.The proposed system achieves a Grasping Ability Score of 70.37%, demonstratingits effectiveness in transparent object manipulation.</description>
      <author>example@mail.com (Chen Hu, Timothy Neate, Shan Luo, Letizia Gionfrida)</author>
      <guid isPermaLink="false">2504.03379v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>QID: Efficient Query-Informed ViTs in Data-Scarce Regimes for OCR-free Visual Document Understanding</title>
      <link>http://arxiv.org/abs/2504.02971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, accepted by CVPR 2025 MULA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QID的新方法，用于优化视觉语言模型在视觉文档理解任务中的性能，特别是在数据稀缺的微调场景中。&lt;h4&gt;背景&lt;/h4&gt;在视觉文档理解任务中，使用新的数据集微调预训练的视觉语言模型时，往往难以优化视觉编码器以识别文本丰富的文档图像中的查询特定区域。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种新的、简化的、架构保持的方法，该方法将查询嵌入集成到视觉编码器中，以实现显著的性能提升。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法引入了一个双模块框架：一个查询感知模块，用于生成独特的查询向量以精确引导模型焦点；以及一个查询无关模块，用于捕获标记之间的位置关系，确保鲁棒的空间理解。两个模块都独立于视觉注意力块运行，便于有针对性地学习查询嵌入并增强视觉语义识别。&lt;h4&gt;主要发现&lt;/h4&gt;在多个数据集上进行的实验表明，使用该方法在处理文本丰富的文档以及数据稀缺环境中的性能有显著提升。&lt;h4&gt;结论&lt;/h4&gt;QID方法在视觉文档理解任务中，特别是在数据稀缺的微调场景中，能够显著提高视觉语言模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In Visual Document Understanding (VDU) tasks, fine-tuning a pre-trainedVision-Language Model (VLM) with new datasets often falls short in optimizingthe vision encoder to identify query-specific regions in text-rich documentimages. Existing methods that directly inject queries into model layers bymodifying the network architecture often struggle to adapt to new datasets withlimited annotations. To address this, we introduce QID, a novel, streamlined,architecture-preserving approach that integrates query embeddings into thevision encoder, leading to notable performance gains, particularly indata-scarce fine-tuning scenarios. Specifically, our approach introduces adual-module framework: a query-aware module that generates a unique queryvector to precisely guide the model's focus, as well as a query-agnostic modulethat captures the positional relationships among tokens, ensuring robustspatial understanding. Notably, both modules operate independently of thevision attention blocks, facilitating targeted learning of query embeddings andenhancing visual semantic identification. Experiments with OCR-free VLMs acrossmultiple datasets demonstrate significant performance improvements using ourmethod, especially in handling text-rich documents in data-scarce environments.</description>
      <author>example@mail.com (Binh M. Le, Shaoyuan Xu, Jinmiao Fu, Zhishen Huang, Moyan Li, Yanhui Guo, Hongdong Li, Sameera Ramasinghe, Bryan Wang)</author>
      <guid isPermaLink="false">2504.02971v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Seeing is Believing: Belief-Space Planning with Foundation Models as Uncertainty Estimators</title>
      <link>http://arxiv.org/abs/2504.03245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，利用视觉语言模型（VLM）作为感知模块来估计不确定性和促进符号 grounding，以解决开放世界环境中可泛化的机器人移动操作挑战。&lt;h4&gt;背景&lt;/h4&gt;在开放世界环境中，由于长期目标、复杂目标和部分可观测性，可泛化的机器人移动操作面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来应对这些挑战，并提高机器人对部分可观测性和属性不确定性的推理能力。&lt;h4&gt;方法&lt;/h4&gt;该方法构建了一个符号信念表示，并使用信念空间规划器生成考虑不确定性并包含战略信息收集的计划。&lt;h4&gt;主要发现&lt;/h4&gt;模拟评估表明，该方法在规划战略信息收集方面优于基于 VLM 的端到端规划或基于 VLM 的状态估计基线。&lt;h4&gt;结论&lt;/h4&gt;这项工作突出了 VLM 在构建信念空间符号场景表示方面的潜力，从而能够实现下游任务，如不确定性感知规划。&lt;h4&gt;翻译&lt;/h4&gt;在开放世界环境中，通用的机器人移动操作由于长期目标、复杂目标和部分可观测性而面临重大挑战。解决这些挑战的一种有前景的方法是使用参数化技能库进行规划，其中任务规划器将这些技能按顺序排列以实现用结构化语言（如基于符号事实的逻辑表达式）指定的目标。虽然视觉语言模型（VLM）可以用于使这些表达式具体化，但它们通常假设完全可观测性，当代理缺乏足够的信息来以确定性评估事实时，会导致次优行为。本文介绍了一种新颖的框架，该框架利用 VLM 作为感知模块来估计不确定性和促进符号 grounding。我们的方法构建了一个符号信念表示，并使用信念空间规划器生成考虑不确定性并包含战略信息收集的计划。这使得代理能够有效地对部分可观测性和属性不确定性进行推理。我们在需要部分可观测环境推理的多种具有挑战性的真实世界任务上展示了我们的系统。模拟评估表明，我们的方法在规划战略信息收集方面优于基于 VLM 的端到端规划或基于 VLM 的状态估计基线。这项工作突出了 VLM 构建信念空间符号场景表示的潜力，从而能够实现下游任务，如不确定性感知规划。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalizable robotic mobile manipulation in open-world environments posessignificant challenges due to long horizons, complex goals, and partialobservability. A promising approach to address these challenges involvesplanning with a library of parameterized skills, where a task planner sequencesthese skills to achieve goals specified in structured languages, such aslogical expressions over symbolic facts. While vision-language models (VLMs)can be used to ground these expressions, they often assume full observability,leading to suboptimal behavior when the agent lacks sufficient information toevaluate facts with certainty. This paper introduces a novel framework thatleverages VLMs as a perception module to estimate uncertainty and facilitatesymbolic grounding. Our approach constructs a symbolic belief representationand uses a belief-space planner to generate uncertainty-aware plans thatincorporate strategic information gathering. This enables the agent toeffectively reason about partial observability and property uncertainty. Wedemonstrate our system on a range of challenging real-world tasks that requirereasoning in partially observable environments. Simulated evaluations show thatour approach outperforms both vanilla VLM-based end-to-end planning orVLM-based state estimation baselines by planning for and executing strategicinformation gathering. This work highlights the potential of VLMs to constructbelief-space symbolic scene representations, enabling downstream tasks such asuncertainty-aware planning.</description>
      <author>example@mail.com (Linfeng Zhao, Willie McClinton, Aidan Curtis, Nishanth Kumar, Tom Silver, Leslie Pack Kaelbling, Lawson L. S. Wong)</author>
      <guid isPermaLink="false">2504.03245v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Graph Attention for Heterogeneous Graphs with Positional Encoding</title>
      <link>http://arxiv.org/abs/2504.02938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了图神经网络（GNNs）在异构图上的应用，特别是节点分类和链接预测任务，并通过实验比较了不同的GNN架构，发现图注意力网络在这些任务上表现优异。&lt;h4&gt;背景&lt;/h4&gt;图神经网络已经成为建模图数据的黄金标准，但在处理异构图时，其性能往往不如同构图，存在一定的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在找到最有效的GNN方法来处理异构图上的节点分类和链接预测任务。&lt;h4&gt;方法&lt;/h4&gt;本文对多种GNN架构进行了基准测试，并提出了通过整合位置编码来增强注意力网络的方法，使用全拉普拉斯谱来准确捕捉图中每个节点的相对和绝对位置。&lt;h4&gt;主要发现&lt;/h4&gt;图注意力网络在节点分类和链接预测任务上表现最佳，且通过整合位置编码的方法进一步提升了性能。&lt;h4&gt;结论&lt;/h4&gt;通过使用全拉普拉斯谱和位置编码，可以显著提高GNN在异构图上的节点分类和链接预测任务中的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have emerged as the de facto standard for modeling graph data, with attention mechanisms and transformers significantly enhancing their performance on graph-based tasks. Despite these advancements, the performance of GNNs on heterogeneous graphs often remains complex, with networks generally underperforming compared to their homogeneous counterparts. This work benchmarks various GNN architectures to identify the most effective methods for heterogeneous graphs, with a particular focus on node classification and link prediction. Our findings reveal that graph attention networks excel in these tasks. As a main contribution, we explore enhancements to these attention networks by integrating positional encodings for node embeddings. This involves utilizing the full Laplacian spectrum to accurately capture both the relative and absolute positions of each node within the graph, further enhancing performance on downstream tasks such as node classification and link prediction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as the de facto standard formodeling graph data, with attention mechanisms and transformers significantlyenhancing their performance on graph-based tasks. Despite these advancements,the performance of GNNs on heterogeneous graphs often remains complex, withnetworks generally underperforming compared to their homogeneous counterparts.This work benchmarks various GNN architectures to identify the most effectivemethods for heterogeneous graphs, with a particular focus on nodeclassification and link prediction. Our findings reveal that graph attentionnetworks excel in these tasks. As a main contribution, we explore enhancementsto these attention networks by integrating positional encodings for nodeembeddings. This involves utilizing the full Laplacian spectrum to accuratelycapture both the relative and absolute positions of each node within the graph,further enhancing performance on downstream tasks such as node classificationand link prediction.</description>
      <author>example@mail.com (Nikhil Shivakumar Nayak)</author>
      <guid isPermaLink="false">2504.02938v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Objective Quality: Benchmarking Features and Quality Evaluation</title>
      <link>http://arxiv.org/abs/2504.03381v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究分析了全参考点云客观度量指标的不同特征，通过比较不同客观质量度量指标之间的差异，选择了点云质量度量、点云结构相似度、点云质量指标和多尺度图相似度等指标。研究使用了递归特征消除和回归算法，在压缩场景数据库上对模型进行训练和验证，最终发现结合点云质量度量、多尺度图相似度和PSNR MSE D2，使用岭回归得到的模型性能最佳。&lt;h4&gt;背景&lt;/h4&gt;当前全参考点云客观度量指标能提供非常准确的可感知质量表示，这些指标通常由一组特征组合而成，最终得出一个质量值。&lt;h4&gt;目的&lt;/h4&gt;分析最佳性能度量指标的不同特征，并基于这些特征选择和组合出最佳模型。&lt;h4&gt;方法&lt;/h4&gt;比较不同客观质量度量指标，使用递归特征消除和回归算法（支持向量回归和岭回归）进行特征选择，在压缩场景数据库上进行模型训练和验证，并在五个公开的主观质量评估数据集上评估最佳组合模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过递归特征消除选出的几个特征，结合所使用的回归方法，发现点云质量度量、多尺度图相似度和PSNR MSE D2的组合，结合岭回归算法，取得了最佳性能。&lt;h4&gt;结论&lt;/h4&gt;定义了特征选择模型，该模型结合了特定特征，通过岭回归算法实现了对点云质量的最佳估计。&lt;h4&gt;翻译&lt;/h4&gt;摘要：目前，全参考点云客观度量指标正在提供非常准确的可感知质量表示。这些指标通常由一组特征组合而成，从而得到一个最终的质量值。在本研究中，分析了最佳性能度量指标的不同特征。为此，比较了它们之间的不同客观质量度量指标，并研究了它们在质量表示上的差异。这提供了一组在本研究中使用的度量指标，即点到平面、点到属性、点云结构相似度、点云质量指标和多尺度图相似度。根据这些指标定义的特征，基于它们对客观估计的贡献进行了考察。为了使用递归特征选择算法，采用了支持向量回归和岭回归算法。对于这项研究，使用了静态点云压缩场景数据库进行模型的训练和验证。根据递归特征消除，选择了几个特征，并使用用于选择这些特征的回归方法进行了组合。然后，在五个不同的公开主观质量评估数据集上评估了最佳组合模型，针对不同的点云特征和失真。结论是，从点云质量度量、多尺度图相似度和PSNR MSE D2中选出的特征组合，结合岭回归，实现了最佳性能。该模型导致了特征选择模型的定义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Full-reference point cloud objective metrics are currently providing veryaccurate representations of perceptual quality. These metrics are usuallycomposed of a set of features that are somehow combined, resulting in a finalquality value. In this study, the different features of the best-performingmetrics are analyzed. For that, different objective quality metrics arecompared between them, and the differences in their quality representation arestudied. This provided a selection of the set of metrics used in this study,namely the point-to-plane, point-to-attribute, Point Cloud StructuralSimilarity, Point Cloud Quality Metric and Multiscale Graph Similarity. Thefeatures defined in those metrics are examined based on their contribution tothe objective estimation using recursive feature elimination. To employ therecursive feature selection algorithm, both the support vector regression andthe ridge regression algorithms were employed. For this study, the BroadQuality Assessment of Static Point Clouds in Compression Scenario database wasused for both training and validation of the models. According to the recursivefeature elimination, several features were selected and then combined using theregression method used to select those features. The best combination modelswere then evaluated across five different publicly available subjective qualityassessment datasets, targeting different point cloud characteristics anddistortions. It was concluded that a combination of features selected from thePoint Cloud Quality Metric, Multiscale Graph Similarity and PSNR MSE D2,combined with Ridge Regression, results in the best performance. This modelleads to the definition of the Feature Selection Model.</description>
      <author>example@mail.com (Joao Prazeres, Rafael Rodrigues, Manuela Pereira, Antonio M. G. Pinheiro)</author>
      <guid isPermaLink="false">2504.03381v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Comparative Analysis of Unsupervised and Supervised Autoencoders for Nuclei Classification in Clear Cell Renal Cell Carcinoma Images</title>
      <link>http://arxiv.org/abs/2504.03146v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted 4-page paper at IEEE ISBI 2025. 3 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了监督和自编码器在清晰细胞肾细胞癌（ccRCC）图像核分类中的应用，评估了不同的自编码器架构，并通过整合监督分类分支和优化分类性能来提高ccRCC病理分级自动化。&lt;h4&gt;背景&lt;/h4&gt;ccRCC图像的核分类通常依赖于病理学家的主观视觉评级，本研究旨在自动化这一过程。&lt;h4&gt;目的&lt;/h4&gt;自动化ccRCC图像的核分类，提高诊断准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;研究了标准自编码器、压缩自编码器（CAEs）、判别自编码器（DAEs）和基于分类器的判别自编码器（CDAE），并使用Optuna工具进行超参数调整。通过Bhattacharyya距离评估潜在空间中的类别可分性，并将F1分数纳入调整过程以优化分类性能。&lt;h4&gt;主要发现&lt;/h4&gt;CDAE在潜在空间分离和分类精度方面表现出优异的性能，通过潜在聚类和细粒度分类识别了具有挑战性的ccRCC等级，并且模型在所有评估指标上优于当前最先进的CHR-Network。&lt;h4&gt;结论&lt;/h4&gt;在ccRCC病理中，通过整合分类分支、神经网络架构搜索和对比学习，可以增强分级自动化，特别是在检测侵略性肿瘤等级方面，可能提高诊断准确性。&lt;h4&gt;翻译&lt;/h4&gt;本研究探讨了监督和自编码器在清晰细胞肾细胞癌（ccRCC）图像核分类中的应用。我们评估了各种自编码器架构，包括标准自编码器、收缩自编码器（CAEs）、判别自编码器（DAEs）以及基于分类器的判别自编码器（CDAE），并使用超参数调整工具Optuna进行优化。从多个指标中选择了Bhattacharyya距离来评估潜在空间中的类别可分性，揭示了在无监督模型中区分相邻等级的挑战。整合了监督分类分支的CDAE在潜在空间分离和分类精度方面表现出优越的性能。鉴于CDAE-CNN在分类指标上实现了显著改进，证实了监督学习对特征提取的价值，F1分数被纳入调整过程以优化分类性能。结果显示，通过利用自编码器的分类能力进行潜在聚类后的细粒度分类，可以显著提高识别侵略性ccRCC等级。我们的模型在所有评估指标上优于当前最先进的CHR-Network。这些发现表明，在自编码器中整合分类分支、结合神经网络架构搜索和对比学习，可以增强ccRCC病理中的分级自动化，特别是在检测侵略性肿瘤等级方面，并可能提高诊断准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores the application of supervised and unsupervisedautoencoders (AEs) to automate nuclei classification in clear cell renal cellcarcinoma (ccRCC) images, a diagnostic task traditionally reliant on subjectivevisual grading by pathologists. We evaluate various AE architectures, includingstandard AEs, contractive AEs (CAEs), and discriminative AEs (DAEs), as well asa classifier-based discriminative AE (CDAE), optimized using the hyperparametertuning tool Optuna. Bhattacharyya distance is selected from several metrics toassess class separability in the latent space, revealing challenges indistinguishing adjacent grades using unsupervised models. CDAE, integrating asupervised classifier branch, demonstrated superior performance in both latentspace separation and classification accuracy. Given that CDAE-CNN achievednotable improvements in classification metrics, affirming the value ofsupervised learning for class-specific feature extraction, F1 score wasincorporated into the tuning process to optimize classification performance.Results show significant improvements in identifying aggressive ccRCC grades byleveraging the classification capability of AE through latent clusteringfollowed by fine-grained classification. Our model outperforms the currentstate of the art, CHR-Network, across all evaluated metrics. These findingssuggest that integrating a classifier branch in AEs, combined with neuralarchitecture search and contrastive learning, enhances grading automation inccRCC pathology, particularly in detecting aggressive tumor grades, and mayimprove diagnostic accuracy.</description>
      <author>example@mail.com (Fatemeh Javadian, Zahra Aminparast, Johannes Stegmaier, Abin Jose)</author>
      <guid isPermaLink="false">2504.03146v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Block Toeplitz Sparse Precision Matrix Estimation for Large-Scale Interval-Valued Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2504.03322v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对大规模区间值时间序列（ITS）的特征提取方法，包括自动分段、聚类和特征迁移学习，用于预测。&lt;h4&gt;背景&lt;/h4&gt;由于ITS在各个领域中的广泛应用，建模和预测ITS受到了广泛关注。目前尚未有针对大规模ITS的建模尝试。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于大规模ITS的特征提取方法，并用于预测。&lt;h4&gt;方法&lt;/h4&gt;该方法包括自动分段和聚类，以及特征迁移学习。通过将ITS的自动分段和聚类转化为Toeplitz稀疏精度矩阵和分配集的估计，使用极大极小算法将高度非凸优化问题转化为两个子问题。通过动态规划和交替方向法交替解决这两个子问题，并建立其收敛性质。使用联合自回归图（JRP）对子序列进行图像化，并对每个聚类分配一个类别标签，构建图像数据集。然后，选择适当的神经网络在图像数据集上进行训练，并用于提取预测步骤中的特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够有效地获得原始数据的不变表示，并提高预测性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在预测ITS方面具有有效性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;Modeling and forecasting interval-valued time series (ITS) have attracted considerable attention due to their growing presence in various contexts. To the best of our knowledge, there have been no efforts to model large-scale ITS. In this paper, we propose a feature extraction procedure for large-scale ITS, which involves key steps such as auto-segmentation and clustering, and feature transfer learning. This procedure can be seamlessly integrated with any suitable prediction models for forecasting purposes. Specifically, we transform the automatic segmentation and clustering of ITS into the estimation of Toeplitz sparse precision matrices and assignment set. The majorization-minimization algorithm is employed to convert this highly non-convex optimization problem into two subproblems. We derive efficient dynamic programming and alternating direction method to solve these two subproblems alternately and establish their convergence properties. By employing the Joint Recurrence Plot (JRP) to image subsequence and assigning a class label to each cluster, an image dataset is constructed. Then, an appropriate neural network is chosen to train on this image dataset and used to extract features for the next step of forecasting. Real data applications demonstrate that the proposed method can effectively obtain invariant representations of the raw data and enhance forecasting performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling and forecasting interval-valued time series (ITS) have attractedconsiderable attention due to their growing presence in various contexts. Tothe best of our knowledge, there have been no efforts to model large-scale ITS.In this paper, we propose a feature extraction procedure for large-scale ITS,which involves key steps such as auto-segmentation and clustering, and featuretransfer learning. This procedure can be seamlessly integrated with anysuitable prediction models for forecasting purposes. Specifically, we transformthe automatic segmentation and clustering of ITS into the estimation ofToeplitz sparse precision matrices and assignment set. Themajorization-minimization algorithm is employed to convert this highlynon-convex optimization problem into two subproblems. We derive efficientdynamic programming and alternating direction method to solve these twosubproblems alternately and establish their convergence properties. Byemploying the Joint Recurrence Plot (JRP) to image subsequence and assigning aclass label to each cluster, an image dataset is constructed. Then, anappropriate neural network is chosen to train on this image dataset and used toextract features for the next step of forecasting. Real data applicationsdemonstrate that the proposed method can effectively obtain invariantrepresentations of the raw data and enhance forecasting performance.</description>
      <author>example@mail.com (Wan Tian, Zhongfeng Qin)</author>
      <guid isPermaLink="false">2504.03322v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>FontGuard: A Robust Font Watermarking Approach Leveraging Deep Font Knowledge</title>
      <link>http://arxiv.org/abs/2504.03128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了FontGuard，一种新型的字体水印模型，用于解决AI生成内容在法医和安全性问题上的挑战，如来源追踪和版权保护。&lt;h4&gt;背景&lt;/h4&gt;随着AI生成内容的增多，出现了源追踪、版权保护等法医和安全问题，强调了有效水印技术的必要性。&lt;h4&gt;目的&lt;/h4&gt;提高字体水印的质量和嵌入容量，并增强对现实世界扭曲的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;FontGuard利用字体模型和语言引导的对比学习，通过改变隐藏风格特征来修改字体，生成大量接近原始字体的字体变体，并使用图像-文本对比学习重构嵌入的位。&lt;h4&gt;主要发现&lt;/h4&gt;FontGuard在解码准确性和视觉质量方面优于现有方法，在合成、跨媒体和在线社交网络扭曲下分别提高了+5.4%、+7.4%和+5.8%的解码准确率，并在LPIPS方面提高了52.7%的视觉质量。&lt;h4&gt;结论&lt;/h4&gt;FontGuard是一种有效的字体水印模型，能够解决AI生成内容带来的法医和安全问题。&lt;h4&gt;翻译&lt;/h4&gt;The proliferation of AI-generated content brings significant concerns on the forensic and security issues such as source tracing, copyright protection, etc, highlighting the need for effective watermarking technologies. Font-based text watermarking has emerged as an effective solution to embed information, which could ensure copyright, traceability, and compliance of the generated text content. Existing font watermarking methods usually neglect essential font knowledge, which leads to watermarked fonts of low quality and limited embedding capacity. These methods are also vulnerable to real-world distortions, low-resolution fonts, and inaccurate character segmentation. In this paper, we introduce FontGuard, a novel font watermarking model that harnesses the capabilities of font models and language-guided contrastive learning. Unlike previous methods that focus solely on the pixel-level alteration, FontGuard modifies fonts by altering hidden style features, resulting in better font quality upon watermark embedding. We also leverage the font manifold to increase the embedding capacity of our proposed method by generating substantial font variants closely resembling the original font. Furthermore, in the decoder, we employ an image-text contrastive learning to reconstruct the embedded bits, which can achieve desirable robustness against various real-world transmission distortions. FontGuard outperforms state-of-the-art methods by +5.4%, +7.4%, and +5.8% in decoding accuracy under synthetic, cross-media, and online social network distortions, respectively, while improving the visual quality by 52.7% in terms of LPIPS. Moreover, FontGuard uniquely allows the generation of watermarked fonts for unseen fonts without re-training the network. The code and dataset are available at https://github.com/KAHIMWONG/FontGuard.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of AI-generated content brings significant concerns on theforensic and security issues such as source tracing, copyright protection, etc,highlighting the need for effective watermarking technologies. Font-based textwatermarking has emerged as an effective solution to embed information, whichcould ensure copyright, traceability, and compliance of the generated textcontent. Existing font watermarking methods usually neglect essential fontknowledge, which leads to watermarked fonts of low quality and limitedembedding capacity. These methods are also vulnerable to real-worlddistortions, low-resolution fonts, and inaccurate character segmentation. Inthis paper, we introduce FontGuard, a novel font watermarking model thatharnesses the capabilities of font models and language-guided contrastivelearning. Unlike previous methods that focus solely on the pixel-levelalteration, FontGuard modifies fonts by altering hidden style features,resulting in better font quality upon watermark embedding. We also leverage thefont manifold to increase the embedding capacity of our proposed method bygenerating substantial font variants closely resembling the original font.Furthermore, in the decoder, we employ an image-text contrastive learning toreconstruct the embedded bits, which can achieve desirable robustness againstvarious real-world transmission distortions. FontGuard outperformsstate-of-the-art methods by +5.4%, +7.4%, and +5.8% in decoding accuracy undersynthetic, cross-media, and online social network distortions, respectively,while improving the visual quality by 52.7% in terms of LPIPS. Moreover,FontGuard uniquely allows the generation of watermarked fonts for unseen fontswithout re-training the network. The code and dataset are available athttps://github.com/KAHIMWONG/FontGuard.</description>
      <author>example@mail.com (Kahim Wong, Jicheng Zhou, Kemou Li, Yain-Whar Si, Xiaowei Wu, Jiantao Zhou)</author>
      <guid isPermaLink="false">2504.03128v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud-based Grasping for Soft Hand Exoskeleton</title>
      <link>http://arxiv.org/abs/2504.03369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于视觉预测控制框架的软手外骨骼控制系统，用于辅助抓取，并通过深度感知实现环境上下文感知，提高抓取能力。&lt;h4&gt;背景&lt;/h4&gt;抓取是与环境中的物体互动和操作的基本技能，但对于手部有障碍的人来说，这项能力可能具有挑战性。软手外骨骼可以增强或恢复手的基本功能，但控制这些外骨骼以支持用户仍然困难。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过视觉预测控制框架，利用深度感知的环境上下文意识来预测抓取目标和确定激活的控制状态。&lt;h4&gt;方法&lt;/h4&gt;该方法基于几何建模，与需要大量标记数据集且泛化能力有限的数据驱动方法不同，能够在不同的抓取场景中实现稳健的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;使用抓取能力评分（GAS）评估性能，系统在15个物体和健康参与者中实现了91%的GAS，证明了其在不同物体类型上的有效性。&lt;h4&gt;结论&lt;/h4&gt;与基于学习模型相比，该方法在未见过的物体上保持了重建成功率，强调了其增强的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Grasping is a fundamental skill for interacting with and manipulating objects in the environment. However, this ability can be challenging for individuals with hand impairments. Soft hand exoskeletons designed to assist grasping can enhance or restore essential hand functions, yet controlling these soft exoskeletons to support users effectively remains difficult due to the complexity of understanding the environment. This study presents a vision-based predictive control framework that leverages contextual awareness from depth perception to predict the grasping target and determine the next control state for activation. Unlike data-driven approaches that require extensive labeled datasets and struggle with generalizability, our method is grounded in geometric modelling, enabling robust adaptation across diverse grasping scenarios. The Grasping Ability Score (GAS) was used to evaluate performance, with our system achieving a state-of-the-art GAS of 91% across 15 objects and healthy participants, demonstrating its effectiveness across different object types. The proposed approach maintained reconstruction success for unseen objects, underscoring its enhanced generalizability compared to learning-based models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasping is a fundamental skill for interacting with and manipulating objectsin the environment. However, this ability can be challenging for individualswith hand impairments. Soft hand exoskeletons designed to assist grasping canenhance or restore essential hand functions, yet controlling these softexoskeletons to support users effectively remains difficult due to thecomplexity of understanding the environment. This study presents a vision-basedpredictive control framework that leverages contextual awareness from depthperception to predict the grasping target and determine the next control statefor activation. Unlike data-driven approaches that require extensive labelleddatasets and struggle with generalizability, our method is grounded ingeometric modelling, enabling robust adaptation across diverse graspingscenarios. The Grasping Ability Score (GAS) was used to evaluate performance,with our system achieving a state-of-the-art GAS of 91% across 15 objects andhealthy participants, demonstrating its effectiveness across different objecttypes. The proposed approach maintained reconstruction success for unseenobjects, underscoring its enhanced generalizability compared to learning-basedmodels.</description>
      <author>example@mail.com (Chen Hu, Enrica Tricomi, Eojin Rho, Daekyum Kim, Lorenzo Masia, Shan Luo, Letizia Gionfrida)</author>
      <guid isPermaLink="false">2504.03369v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Endo3R: Unified Online Reconstruction from Dynamic Monocular Endoscopic Video</title>
      <link>http://arxiv.org/abs/2504.03198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Endo3R的3D场景重建方法，用于从单目手术视频中实现在线尺度一致重建，旨在提高外科医生对手术场景的感知，并增强计算机辅助手术任务的效果。&lt;h4&gt;背景&lt;/h4&gt;由于内窥镜视频固有的问题，如动态变形和无纹理表面，从单目手术视频中重建3D场景是一个挑战。现有的方法要么依赖于校准或工具先验来估计尺度，要么采用SfM类似的多阶段管道，导致误差累积并需要离线优化。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需先验或额外优化的在线尺度一致重建方法，以增强外科医生对手术场景的感知。&lt;h4&gt;方法&lt;/h4&gt;Endo3R模型通过预测全局对齐的点云图、尺度一致的视频深度和相机参数来实现这一目标。该方法通过不确定性感知的双记忆机制扩展了最近的双边重建模型的能力，以实现长期增量动态重建。此外，为了解决缺乏具有真实深度和相机位姿的端孔镜数据集的问题，该方法还设计了一种具有新颖动态感知流损失的自我监督机制。&lt;h4&gt;主要发现&lt;/h4&gt;Endo3R在SCARED和Hamlyn数据集上进行了大量实验，证明了其在零样本手术视频深度预测和相机姿态估计方面的优越性能，以及在线效率。&lt;h4&gt;结论&lt;/h4&gt;Endo3R为单目手术视频的在线尺度一致重建提供了一种有效的方法，有助于提高外科医生对手术场景的感知和计算机辅助手术任务的执行。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从单目手术视频中重建3D场景可以增强外科医生的感知，因此在各种计算机辅助手术任务中发挥着至关重要的作用。然而，由于内窥镜视频固有的问题，如动态变形和无纹理表面，实现尺度一致的重建仍然是一个挑战。尽管近年来取得了进展，但当前的方法要么依赖于校准或工具先验来估计尺度，要么采用SfM类似的多阶段管道，导致误差累积并需要离线优化。在本文中，我们提出了Endo3R，一个用于从单目手术视频进行在线尺度一致重建的统一3D基础模型，无需任何先验或额外优化。我们的模型通过预测全局对齐的点云图、尺度一致的视频深度和相机参数来统一任务，无需任何离线优化。我们方法的核心贡献是通过不确定性感知的双记忆机制，将最近的双边重建模型的能力扩展到长期增量动态重建。该机制维护短期动态和长期空间一致性的历史标记。值得注意的是，为了应对手术场景的高度动态性，我们通过Sampson距离测量标记的不确定性，并过滤掉具有高不确定性的标记。关于端孔镜数据集缺乏具有真实深度和相机位姿的问题，我们进一步设计了一种具有新颖动态感知流损失的自我监督机制。在SCARED和Hamlyn数据集上进行的丰富实验表明，我们在零样本手术视频深度预测和相机姿态估计方面具有优越的性能，并且具有在线效率。项目页面：https://wrld.github.io/Endo3R/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing 3D scenes from monocular surgical videos can enhance surgeon'sperception and therefore plays a vital role in various computer-assistedsurgery tasks. However, achieving scale-consistent reconstruction remains anopen challenge due to inherent issues in endoscopic videos, such as dynamicdeformations and textureless surfaces. Despite recent advances, current methodseither rely on calibration or instrument priors to estimate scale, or employSfM-like multi-stage pipelines, leading to error accumulation and requiringoffline optimization. In this paper, we present Endo3R, a unified 3D foundationmodel for online scale-consistent reconstruction from monocular surgical video,without any priors or extra optimization. Our model unifies the tasks bypredicting globally aligned pointmaps, scale-consistent video depths, andcamera parameters without any offline optimization. The core contribution ofour method is expanding the capability of the recent pairwise reconstructionmodel to long-term incremental dynamic reconstruction by an uncertainty-awaredual memory mechanism. The mechanism maintains history tokens of bothshort-term dynamics and long-term spatial consistency. Notably, to tackle thehighly dynamic nature of surgical scenes, we measure the uncertainty of tokensvia Sampson distance and filter out tokens with high uncertainty. Regarding thescarcity of endoscopic datasets with ground-truth depth and camera poses, wefurther devise a self-supervised mechanism with a novel dynamics-aware flowloss. Abundant experiments on SCARED and Hamlyn datasets demonstrate oursuperior performance in zero-shot surgical video depth prediction and camerapose estimation with online efficiency. Project page:https://wrld.github.io/Endo3R/.</description>
      <author>example@mail.com (Jiaxin Guo, Wenzhen Dong, Tianyu Huang, Hao Ding, Ziyi Wang, Haomin Kuang, Qi Dou, Yun-Hui Liu)</author>
      <guid isPermaLink="false">2504.03198v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>A model-free feature extraction procedure for interval-valued time series prediction</title>
      <link>http://arxiv.org/abs/2504.03310v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合迁移学习和图像处理方法的新颖特征提取流程，用于预测区间值时间序列。&lt;h4&gt;背景&lt;/h4&gt;区间值时间序列的预测是一个复杂的问题，本文提出的方法旨在通过改进特征提取来提升预测性能。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效预测区间值时间序列的方法，并通过实验证明其有效性。&lt;h4&gt;方法&lt;/h4&gt;1. 将区间值时间序列转换为双变量点值时间序列作为代表形式。2. 使用多种图像处理方法（如重游图、Gramian角和场、马尔可夫转换场）将时间序列转换为图像。3. 构建图像数据集，将每种图像处理方法的输出视为一个单独的类别。4. 在此数据集上训练多个特征提取网络（FEN）候选模型，特别是具有不同层数的ResNet。5. 从FEN的倒数第二层提取最相关的特征。6. 将提取的特征整合到传统的预测模型中，形成预测模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有方法相比，该方法在预测性能上有了显著提升。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高区间值时间序列的预测性能，为相关领域的研究提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we propose a novel feature extraction procedure to predict interval-valued time series by combining transfer learning and imaging approaches. Initially, we represent interval-valued time series using a bivariate point-valued time series, which serves as a representative form. We first transform each time series into images by employing various imaging approaches such as recurrence plot, gramian angular summation/difference field, and Markov transition field, and construct an image dataset by treating each imaging method's output as a separate class. Based on this dataset, we train several candidates for a feature extraction network (FEN), specifically ResNet with varying layers. Then we choose the penultimate layer of the FEN to extract the most relevant features from the transformed images. We integrate the extracted features into conventional predictive models to formulate the corresponding prediction models. To formulate prediction, we integrate the extracted features into a regular prediction model. The proposed methods are evaluated based on the S&amp;P 500 index and three data-generating processes (DGPs), and the experimental results demonstrate a notable improvement in prediction performance compared to existing methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a novel feature extraction procedure to predictinterval-valued time series by combing transfer learning and imagingapproaches. Initially, we represent interval-valued time series using abivariate point-valued time series, which serves as a representative form. Wefirst transform each time series into images by employing various imagingapproaches such as recurrence plot, gramian angular summation/difference field,and Markov transition field, and construct an image dataset by treating eachimaging method's output as a separate class. Based on this dataset, we trainseveral candidates for a feature extraction network (FEN), specifically ResNetwith varying layers. Then we choose the penultimate layer of the FEN to extractthe most relevant features from the transformed images. We integrate theextracted features into conventional predictive models to formulate thecorresponding prediction models. To formulate prediction, we integrate theextracted features into a regular prediction model. The proposed methods areevaluated based on the S\&amp;P 500 index and three data-generating processes(DGPs), and the experimental results demonstrate a notable improvement inprediction performance compared to existing methods.</description>
      <author>example@mail.com (Wan Tian, Zhongfeng Qin, Tao Hu)</author>
      <guid isPermaLink="false">2504.03310v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>SLACK: Attacking LiDAR-based SLAM with Adversarial Point Injections</title>
      <link>http://arxiv.org/abs/2504.03089v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了SLACK，一个用于攻击LiDAR扫描的端到端深度生成对抗模型，能够在不降低LiDAR质量的情况下进行多次点注入攻击，以应对基于学习的LiDAR方法的对抗攻击。&lt;h4&gt;背景&lt;/h4&gt;基于学习的LiDAR方法在自动驾驶车辆中广泛应用，但容易受到对抗攻击，即通过点注入（PiJ）方式对LiDAR数据进行攻击，这给导航和地图生成带来了严重的安全挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效攻击LiDAR扫描的方法，同时不降低LiDAR数据质量。&lt;h4&gt;方法&lt;/h4&gt;设计了SLACK，一个端到端的深度生成对抗模型，并设计了一种新的自编码器，通过结合对比学习和基于分割的注意力机制来增强对比学习，以实现精确的重建。&lt;h4&gt;主要发现&lt;/h4&gt;SLACK在KITTI和CARLA-64数据集上的点注入任务中，性能优于现有最佳基线，同时保持了扫描的准确性。通过使用LiDAR数据的一小部分，SLACK能够严重降低导航和地图质量，但不会降低LiDAR扫描质量。&lt;h4&gt;结论&lt;/h4&gt;SLACK能够有效地对LiDAR扫描进行攻击，为基于学习的LiDAR方法的安全性研究提供了新的视角和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread adoption of learning-based methods for the LiDAR makesautonomous vehicles vulnerable to adversarial attacks through adversarial\textit{point injections (PiJ)}. It poses serious security challenges fornavigation and map generation. Despite its critical nature, no major workexists that studies learning-based attacks on LiDAR-based SLAM. Our workproposes SLACK, an end-to-end deep generative adversarial model to attack LiDARscans with several point injections without deteriorating LiDAR quality. Tofacilitate SLACK, we design a novel yet simple autoencoder that augmentscontrastive learning with segmentation-based attention for precisereconstructions. SLACK demonstrates superior performance on the task of\textit{point injections (PiJ)} compared to the best baselines on KITTI andCARLA-64 dataset while maintaining accurate scan quality. We qualitatively andquantitatively demonstrate PiJ attacks using a fraction of LiDAR points. Itseverely degrades navigation and map quality without deteriorating the LiDARscan quality.</description>
      <author>example@mail.com (Prashant Kumar, Dheeraj Vattikonda, Kshitij Madhav Bhat, Kunal Dargan, Prem Kalra)</author>
      <guid isPermaLink="false">2504.03089v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language Models for Domain-Generalized Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.03193v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为MFuser的融合框架，旨在解决在领域泛化语义分割中，视觉基础模型（VFMs）和视觉-语言模型（VLMs）结合时的问题。&lt;h4&gt;背景&lt;/h4&gt;VFMs和VLMs在领域泛化语义分割（DGSS）中表现出色，但现有方法往往只依赖其中一种，忽略了它们的互补优势。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的融合框架，以有效结合VFMs和VLMs的优点，同时保持序列长度的线性可扩展性。&lt;h4&gt;方法&lt;/h4&gt;MFuser框架包括MVFuser和MTEnhancer两个主要组件：MVFuser作为共适配器，通过捕捉序列和空间动态来联合微调两个模型；MTEnhancer是一个混合注意力-Mamba模块，通过结合图像先验来细化文本嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MFuser在合成到真实和真实到真实基准测试中显著优于最先进的DGSS方法，分别达到了68.20 mIoU和71.87 mIoU。&lt;h4&gt;结论&lt;/h4&gt;MFuser在保持线性可扩展性的同时，实现了精确的特征局部性和强大的文本对齐，为领域泛化语义分割提供了有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Vision Foundation Models (VFMs) 和 Vision-Language Models (VLMs) 在 Domain Generalized Semantic Segmentation (DGSS) 中由于它们的强大泛化能力而受到关注。然而，现有的 DGSS 方法通常完全依赖于 VFMs 或 VLMs，忽视了它们的互补优势。VFMs（例如，DINOv2）擅长捕获细粒度特征，而 VLMs（例如，CLIP）提供稳健的文本对齐，但难以处理粗粒度。尽管它们具有互补的优势，但由于增加了补丁标记而使长序列建模复杂化，因此有效地将 VFMs 和 VLMs 与注意力机制集成是具有挑战性的。为了解决这个问题，我们提出了 MFuser，这是一种基于 Mamba 的新型融合框架，它有效地结合了 VFMs 和 VLMs 的优势，同时保持了序列长度的线性可扩展性。MFuser 由两个关键组件组成：MVFuser，它作为共适配器，通过捕捉序列和空间动态来联合微调两个模型；MTEnhancer，这是一个混合注意力-Mamba 模块，通过结合图像先验来细化文本嵌入。我们的方法在不增加显著计算开销的情况下，实现了精确的特征局部性和强大的文本对齐。大量的实验表明，MFuser 在合成到真实和真实到真实基准测试中显著优于最先进的 DGSS 方法，分别达到了 68.20 mIoU 和 71.87 mIoU。代码可在 https://github.com/devinxzhang/MFuser 上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Foundation Models (VFMs) and Vision-Language Models (VLMs) have gainedtraction in Domain Generalized Semantic Segmentation (DGSS) due to their stronggeneralization capabilities. However, existing DGSS methods often relyexclusively on either VFMs or VLMs, overlooking their complementary strengths.VFMs (e.g., DINOv2) excel at capturing fine-grained features, while VLMs (e.g.,CLIP) provide robust text alignment but struggle with coarse granularity.Despite their complementary strengths, effectively integrating VFMs and VLMswith attention mechanisms is challenging, as the increased patch tokenscomplicate long-sequence modeling. To address this, we propose MFuser, a novelMamba-based fusion framework that efficiently combines the strengths of VFMsand VLMs while maintaining linear scalability in sequence length. MFuserconsists of two key components: MVFuser, which acts as a co-adapter to jointlyfine-tune the two models by capturing both sequential and spatial dynamics; andMTEnhancer, a hybrid attention-Mamba module that refines text embeddings byincorporating image priors. Our approach achieves precise feature locality andstrong text alignment without incurring significant computational overhead.Extensive experiments demonstrate that MFuser significantly outperformsstate-of-the-art DGSS methods, achieving 68.20 mIoU on synthetic-to-real and71.87 mIoU on real-to-real benchmarks. The code is available athttps://github.com/devinxzhang/MFuser.</description>
      <author>example@mail.com (Xin Zhang, Robby T. Tan)</author>
      <guid isPermaLink="false">2504.03193v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>LiDAR-based Object Detection with Real-time Voice Specifications</title>
      <link>http://arxiv.org/abs/2504.02920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures, submitted as part of MSc research&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于LiDAR的对象检测系统，该系统具备实时语音指定功能，通过多模态PointNet框架整合KITTI的3D点云和RGB图像，验证集准确率达到87.0%，超过67.5%的200样本基线。系统通过结合空间和视觉数据、使用加权损失解决类别不平衡问题，并通过自适应技术优化训练。Tkinter原型提供使用Edge TTS（en-IN-PrabhatNeural）的自然印度男性语音输出，同时提供3D可视化和实时反馈，增强自动驾驶导航、辅助技术等领域的可访问性和安全性。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶导航、辅助技术等领域需要高准确度的对象检测系统，并且需要结合空间和视觉数据以及语音交互功能。&lt;h4&gt;目的&lt;/h4&gt;开发一个高准确度、具备实时语音指定功能的多模态对象检测系统，以增强自动驾驶导航、辅助技术等领域的应用。&lt;h4&gt;方法&lt;/h4&gt;使用KITTI的3D点云和RGB图像，通过多模态PointNet框架进行整合；结合空间和视觉数据，使用加权损失解决类别不平衡问题；通过自适应技术优化训练；使用Tkinter和Edge TTS实现自然语音输出。&lt;h4&gt;主要发现&lt;/h4&gt;系统在3000样本子集上的验证准确率达到87.0%，超过基线；通过结合数据和优化训练技术提高了准确率。&lt;h4&gt;结论&lt;/h4&gt;该系统是一个可扩展的进步，在人类-计算机交互和环境感知方面具有广泛应用前景，符合当前研究趋势。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a LiDAR-based object detection system with real-time voice specifications, integrating KITTI's 3D point clouds and RGB images through a multi-modal PointNet framework. It achieves 87.0% validation accuracy on a 3000-sample subset, surpassing a 200-sample baseline of 67.5% by combining spatial and visual data, addressing class imbalance with weighted loss, and refining training via adaptive techniques. A Tkinter prototype provides natural Indian male voice output using Edge TTS (en-IN-PrabhatNeural), alongside 3D visualizations and real-time feedback, enhancing accessibility and safety in autonomous navigation, assistive technology, and beyond. The study offers a detailed methodology, comprehensive experimental analysis, and a broad review of applications and challenges, establishing this work as a scalable advancement in human-computer interaction and environmental perception, aligned with current research trends.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a LiDAR-based object detection system with real-timevoice specifications, integrating KITTI's 3D point clouds and RGB imagesthrough a multi-modal PointNet framework. It achieves 87.0% validation accuracyon a 3000-sample subset, surpassing a 200-sample baseline of 67.5% by combiningspatial and visual data, addressing class imbalance with weighted loss, andrefining training via adaptive techniques. A Tkinter prototype provides naturalIndian male voice output using Edge TTS (en-IN-PrabhatNeural), alongside 3Dvisualizations and real-time feedback, enhancing accessibility and safety inautonomous navigation, assistive technology, and beyond. The study offers adetailed methodology, comprehensive experimental analysis, and a broad reviewof applications and challenges, establishing this work as a scalableadvancement in human-computer interaction and environmental perception, alignedwith current research trends.</description>
      <author>example@mail.com (Anurag Kulkarni)</author>
      <guid isPermaLink="false">2504.02920v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Improving log-based anomaly detection through learned adaptive filter</title>
      <link>http://arxiv.org/abs/2504.02994v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度强化学习（DRL）的日志异常检测方法，通过构建学习自适应过滤器，针对不同日志序列应用不同的正常/异常过滤阈值，以提升日志异常检测的性能。&lt;h4&gt;背景&lt;/h4&gt;日志记录了系统运行时的重要信息，对于检测异常行为和管理现代软件系统非常有用。现有的无监督方法在预测下一个日志事件时使用固定配置，导致检测性能不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种自适应的日志异常检测方法，以应对不同日志序列的动态性和变化性。&lt;h4&gt;方法&lt;/h4&gt;使用深度强化学习（DRL）构建学习自适应过滤器，并定义马尔可夫决策过程（MDP）来解决这个问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在两个数据集HDFS和BGL上优于固定配置，显著提升了日志异常检测的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过自适应过滤器在日志异常检测中取得了更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Log messages record important system runtime information and are useful for detecting anomalous behaviors and managing modern software systems. Many supervised and unsupervised learning methods have been proposed recently for log-based anomaly detection. State-of-the-art unsupervised methods predict the next log event given a log sequence and apply fixed configurations that use the same filter condition (i.e., k, the top k predicted log events will be regarded as normal next events), which leads to inferior performance in the detection stage because it sets one fixed k for all log sequences, which ignores the dynamic nature and variance in different log sequences. Recently, deep reinforcement learning (DRL) are widely applied to make intelligent decisions in a dynamic environment. In this work, we contend that it is necessary to apply adaptive filters for different log sequences. To achieve this, we propose a novel approach based on DRL to construct a learned adaptive filter and apply different normal/abnormal filter thresholds for different log sequences. We define the Markov Decision Process (MDP) and formulate the learned adaptive filter as a problem that can be solved by DRL. We evaluate the learned adaptive filter on two state-of-the-art log-based anomaly detection unsupervised approaches DeepLog and LogAnomaly in two datasets HDFS and BGL. Extensive experiments show that our approach outperforms the fixed configurations and achieves significantly better performance in log-based anomaly detection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Log messages record important system runtime information and are useful fordetecting anomalous behaviors and managing modern software systems. Manysupervised and unsupervised learning methods have been proposed recently forlog-based anomaly detection. State-of-the-art unsupervised methods predict thenext log event given a log sequence and apply fixed configurations that use thesame filter condition (i.e. k, the top k predicted log events will be regardedas normal next events) which leads to inferior performance in the detectionstage because it sets one fixed k for all log sequences, which ignores thedynamic nature and variance in different log sequences. Recently, deepreinforcement learning (DRL) are widely applied to make intelligent decisionsin a dynamic environment. In this work, we contend that it is necessary toapply adaptive filters for different log sequences. To achieve this, we proposea novel approach based on DRL to construct a learned adaptive filter and applydifferent normal/abnormal filter thresholds for different log sequences. Wedefine the Markov Decision Process (MDP) and formulate the learned adaptivefilter as a problem that can be solved by DRL. We evaluate the learned adaptivefilter on two state-of-the-art log-based anomaly detection unsupervisedapproaches DeepLog and LogAnomaly in two datasets HDFS and BGL. Extensiveexperiments show that our approach outperforms the fixed configurations andachieves significantly better performance in log-based anomaly detection.</description>
      <author>example@mail.com (Yiyuan Xiong, Shaofeng Cai)</author>
      <guid isPermaLink="false">2504.02994v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Overcoming Deceptiveness in Fitness Optimization with Unsupervised Quality-Diversity</title>
      <link>http://arxiv.org/abs/2504.01915v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种无监督的QD算法AURORA-XCon，该算法通过学习感官数据中的特征，能够高效地解决欺骗性优化问题，且无需领域专业知识。&lt;h4&gt;背景&lt;/h4&gt;政策优化是工程和研究的根本领域，在机器人等领域有应用。传统优化方法如强化学习和进化算法在欺骗性适应度景观中难以找到最优解。&lt;h4&gt;目的&lt;/h4&gt;研究无监督QD算法在解决欺骗性优化问题中的应用，并提高其性能。&lt;h4&gt;方法&lt;/h4&gt;提出AURORA框架，通过对比学习和周期性灭绝事件增强AURORA，形成AURORA-XCon算法。&lt;h4&gt;主要发现&lt;/h4&gt;AURORA-XCon算法在欺骗性优化问题中表现优于传统优化基线，在某些情况下甚至比具有领域特定手工特征的QD基线提高了34%。&lt;h4&gt;结论&lt;/h4&gt;AURORA-XCon算法为无监督QD算法在传统优化领域的应用开辟了新的途径，并扩大了其在特征空间定义困难的领域的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;Policy optimization seeks the best solution to a control problem according to an objective or fitness function, serving as a fundamental field of engineering and research with applications in robotics. Traditional optimization methods like reinforcement learning and evolutionary algorithms struggle with deceptive fitness landscapes, where following immediate improvements leads to suboptimal solutions. Quality-diversity (QD) algorithms offer a promising approach by maintaining diverse intermediate solutions as stepping stones for escaping local optima. However, QD algorithms require domain expertise to define hand-crafted features, limiting their applicability where characterizing solution diversity remains unclear. In this paper, we show that unsupervised QD algorithms - specifically the AURORA framework, which learns features from sensory data - efficiently solve deceptive optimization problems without domain expertise. By enhancing AURORA with contrastive learning and periodic extinction events, we propose AURORA-XCon, which outperforms all traditional optimization baselines and matches, in some cases even improving by up to 34%, the best QD baseline with domain-specific hand-crafted features. This work establishes a novel application of unsupervised QD algorithms, shifting their focus from discovering novel solutions toward traditional optimization and expanding their potential to domains where defining feature spaces poses challenges.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3712256.3726314&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lisacoiffard/aurora-xcon&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Policy optimization seeks the best solution to a control problem according toan objective or fitness function, serving as a fundamental field of engineeringand research with applications in robotics. Traditional optimization methodslike reinforcement learning and evolutionary algorithms struggle with deceptivefitness landscapes, where following immediate improvements leads to suboptimalsolutions. Quality-diversity (QD) algorithms offer a promising approach bymaintaining diverse intermediate solutions as stepping stones for escapinglocal optima. However, QD algorithms require domain expertise to definehand-crafted features, limiting their applicability where characterizingsolution diversity remains unclear. In this paper, we show that unsupervised QDalgorithms - specifically the AURORA framework, which learns features fromsensory data - efficiently solve deceptive optimization problems without domainexpertise. By enhancing AURORA with contrastive learning and periodicextinction events, we propose AURORA-XCon, which outperforms all traditionaloptimization baselines and matches, in some cases even improving by up to 34%,the best QD baseline with domain-specific hand-crafted features. This workestablishes a novel application of unsupervised QD algorithms, shifting theirfocus from discovering novel solutions toward traditional optimization andexpanding their potential to domains where defining feature spaces poseschallenges.</description>
      <author>example@mail.com (Lisa Coiffard, Paul Templier, Antoine Cully)</author>
      <guid isPermaLink="false">2504.01915v2</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Morpheus: Benchmarking Physical Reasoning of Video Generative Models with Real Physical Experiments</title>
      <link>http://arxiv.org/abs/2504.02918v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了图像和视频生成模型在物理世界建模方面的潜力，并提出了一个名为Morpheus的基准测试来评估这些模型的物理推理能力。&lt;h4&gt;背景&lt;/h4&gt;近期在图像和视频生成方面取得了显著进展，这些模型有望具备世界建模能力，即生成真实、物理上合理的视频，这可能会革新机器人、自动驾驶和科学模拟等领域。&lt;h4&gt;目的&lt;/h4&gt;在将这些模型视为世界模型之前，研究者们提出需要检验它们是否遵循物理守恒定律。&lt;h4&gt;方法&lt;/h4&gt;研究者们介绍了Morpheus，一个用于评估视频生成模型在物理推理方面的基准测试。它包含了80个反映物理现象的真实世界视频，这些视频受守恒定律指导。由于人工生成的视频缺乏真实世界数据，研究者们利用物理学信息和视觉语言基础模型，通过物理学告知的指标来评估物理合理性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，即使在高级提示和视频条件化下，当前的模型在编码物理原理方面仍存在困难，尽管它们生成的视频在美学上令人满意。&lt;h4&gt;结论&lt;/h4&gt;所有数据、排行榜和代码都在项目的页面上开源。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent advances in image and video generation raise hopes that these models possess world modeling capabilities, the ability to generate realistic, physically plausible videos. This could revolutionize applications in robotics, autonomous driving, and scientific simulation. However, before treating these models as world models, we must ask: Do they adhere to physical conservation laws? To answer this, we introduce Morpheus, a benchmark for evaluating video generation models on physical reasoning. It features 80 real-world videos capturing physical phenomena, guided by conservation laws. Since artificial generations lack ground truth, we assess physical plausibility using physics-informed metrics evaluated with respect to infallible conservation laws known per physical setting, leveraging advances in physics-informed neural networks and vision-language foundation models. Our findings reveal that even with advanced prompting and video conditioning, current models struggle to encode physical principles despite generating aesthetically pleasing videos. All data, leaderboard, and code are open-sourced at our project page.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in image and video generation raise hopes that these modelspossess world modeling capabilities, the ability to generate realistic,physically plausible videos. This could revolutionize applications in robotics,autonomous driving, and scientific simulation. However, before treating thesemodels as world models, we must ask: Do they adhere to physical conservationlaws? To answer this, we introduce Morpheus, a benchmark for evaluating videogeneration models on physical reasoning. It features 80 real-world videoscapturing physical phenomena, guided by conservation laws. Since artificialgenerations lack ground truth, we assess physical plausibility usingphysics-informed metrics evaluated with respect to infallible conservation lawsknown per physical setting, leveraging advances in physics-informed neuralnetworks and vision-language foundation models. Our findings reveal that evenwith advanced prompting and video conditioning, current models struggle toencode physical principles despite generating aesthetically pleasing videos.All data, leaderboard, and code are open-sourced at our project page.</description>
      <author>example@mail.com (Chenyu Zhang, Daniil Cherniavskii, Andrii Zadaianchuk, Antonios Tragoudaras, Antonios Vozikis, Thijmen Nijdam, Derck W. E. Prinzhorn, Mark Bodracska, Nicu Sebe, Efstratios Gavves)</author>
      <guid isPermaLink="false">2504.02918v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>SPF-Portrait: Towards Pure Portrait Customization with Semantic Pollution-Free Fine-tuning</title>
      <link>http://arxiv.org/abs/2504.00396v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SPF-Portrait的文本驱动肖像定制方法，旨在解决在微调预训练的文本到图像（T2I）模型时出现的语义污染问题，以实现更好的性能和增量学习。&lt;h4&gt;背景&lt;/h4&gt;现有的T2I模型微调方法在定制肖像属性时，由于语义污染难以保持原始模型的行为和实现增量学习。&lt;h4&gt;目的&lt;/h4&gt;提出SPF-Portrait，旨在理解定制语义的同时消除文本驱动肖像定制中的语义污染。&lt;h4&gt;方法&lt;/h4&gt;SPF-Portrait采用了一种双路径流程，将原始模型作为参考，通过对比学习确保对目标属性的适应，并有意将其他无关属性与原始肖像对齐。此外，引入了一种新的语义感知精细控制图，以空间引导对比路径之间的对齐过程。还提出了一种新的响应增强机制，以增强目标属性的性能，同时减轻跨模态监督中固有的表示差异。&lt;h4&gt;主要发现&lt;/h4&gt;SPF-Portrait不仅有效地保留了原始模型的表现，还避免了过度对齐，并通过实验证明了其达到最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;SPF-Portrait是一种有效的文本驱动肖像定制方法，能够显著提高性能并避免语义污染。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a method named SPF-Portrait for text-driven portrait customization, aiming to solve the problem of semantic pollution during the fine-tuning of pre-trained Text-to-Image (T2I) models, in order to achieve better performance and incremental learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning a pre-trained Text-to-Image (T2I) model on a tailored portraitdataset is the mainstream method for text-driven customization of portraitattributes. Due to Semantic Pollution during fine-tuning, existing methodsstruggle to maintain the original model's behavior and achieve incrementallearning while customizing target attributes. To address this issue, we proposeSPF-Portrait, a pioneering work to purely understand customized semantics whileeliminating semantic pollution in text-driven portrait customization. In ourSPF-Portrait, we propose a dual-path pipeline that introduces the originalmodel as a reference for the conventional fine-tuning path. Through contrastivelearning, we ensure adaptation to target attributes and purposefully alignother unrelated attributes with the original portrait. We introduce a novelSemantic-Aware Fine Control Map, which represents the precise response regionsof the target semantics, to spatially guide the alignment process between thecontrastive paths. This alignment process not only effectively preserves theperformance of the original model but also avoids over-alignment. Furthermore,we propose a novel response enhancement mechanism to reinforce the performanceof target attributes, while mitigating representation discrepancy inherent indirect cross-modal supervision. Extensive experiments demonstrate thatSPF-Portrait achieves state-of-the-art performance. Project webpage:https://spf-portrait.github.io/SPF-Portrait/</description>
      <author>example@mail.com (Xiaole Xian, Zhichao Liao, Qingyu Li, Wenyu Qin, Pengfei Wan, Weicheng Xie, Long Zeng, Linlin Shen, Pingfa Feng)</author>
      <guid isPermaLink="false">2504.00396v2</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Can DeepSeek Reason Like a Surgeon? An Empirical Evaluation for Vision-Language Understanding in Robotic-Assisted Surgery</title>
      <link>http://arxiv.org/abs/2503.23130v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DeepSeek模型在场景理解、问答和文本生成任务中表现出色，本研究调查了其在机器人手术场景中的对话能力，包括单短语问答、视觉问答和详细描述等任务。&lt;h4&gt;背景&lt;/h4&gt;DeepSeek模型因其高效的训练范式和强大的推理能力在通用场景理解、问答和文本生成任务中表现出色。&lt;h4&gt;目的&lt;/h4&gt;研究DeepSeek模型在机器人手术场景中的对话能力，特别是单短语问答、视觉问答和详细描述等任务。&lt;h4&gt;方法&lt;/h4&gt;使用公开数据集EndoVis18和CholecT50及其对应的对话数据进行广泛评估。&lt;h4&gt;主要发现&lt;/h4&gt;DeepSeek-VL2在手术场景的复杂理解任务上优于现有的通用多模态大型语言模型；DeepSeek-V3在直接输入图像标记时在单句问答任务上表现出更好性能；但DeepSeek模型在满足临床要求理解手术场景方面仍有不足。&lt;h4&gt;结论&lt;/h4&gt;DeepSeek模型在未经手术特定数据集微调的情况下，不适合用于手术场景中的视觉语言任务。&lt;h4&gt;翻译&lt;/h4&gt;The DeepSeek models have shown exceptional performance in general sceneunderstanding, question-answering (QA), and text generation tasks, owingto their efficient training paradigm and strong reasoning capabilities. Inthis study, we investigate the dialogue capabilities of the DeepSeek modelin robotic surgery scenarios, focusing on tasks such as Single Phrase QA,Visual QA, and Detailed Description. The Single Phrase QA tasks furtherincludesub-tasks such as surgical instrument recognition, action understanding, andspatial position analysis. We conduct extensive evaluations using publiclyavailable datasets, including EndoVis18 and CholecT50, along with theircorresponding dialogue data. Our empirical study shows that, compared toexisting general-purpose multimodal large language models, DeepSeek-VL2performs better on complex understanding tasks in surgical scenes. Additionally,although DeepSeek-V3 is purely a language model, we find that when imagetokens are directly inputted, the model demonstrates better performance onsentence QA tasks. However, overall, the DeepSeek models still fall short ofmeeting the clinical requirements for understanding surgical scenes. Undergeneral prompts, DeepSeek models lack the ability to effectively analyze global surgical concepts and fail to provide detailed insights into surgical scenarios. Based on our observations, we argue that the DeepSeek models are not ready for vision-language tasks in surgical contextswithout fine-tuning on surgery-specific datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The DeepSeek models have shown exceptional performance in general sceneunderstanding, question-answering (QA), and text generation tasks, owing totheir efficient training paradigm and strong reasoning capabilities. In thisstudy, we investigate the dialogue capabilities of the DeepSeek model inrobotic surgery scenarios, focusing on tasks such as Single Phrase QA, VisualQA, and Detailed Description. The Single Phrase QA tasks further includesub-tasks such as surgical instrument recognition, action understanding, andspatial position analysis. We conduct extensive evaluations using publiclyavailable datasets, including EndoVis18 and CholecT50, along with theircorresponding dialogue data. Our empirical study shows that, compared toexisting general-purpose multimodal large language models, DeepSeek-VL2performs better on complex understanding tasks in surgical scenes.Additionally, although DeepSeek-V3 is purely a language model, we find thatwhen image tokens are directly inputted, the model demonstrates betterperformance on single-sentence QA tasks. However, overall, the DeepSeek modelsstill fall short of meeting the clinical requirements for understandingsurgical scenes. Under general prompts, DeepSeek models lack the ability toeffectively analyze global surgical concepts and fail to provide detailedinsights into surgical scenarios. Based on our observations, we argue that theDeepSeek models are not ready for vision-language tasks in surgical contextswithout fine-tuning on surgery-specific datasets.</description>
      <author>example@mail.com (Boyi Ma, Yanguang Zhao, Jie Wang, Guankun Wang, Kun Yuan, Tong Chen, Long Bai, Hongliang Ren)</author>
      <guid isPermaLink="false">2503.23130v3</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Capabilities of LLMs for IMU-based Fine-grained Human Activity Understanding</title>
      <link>http://arxiv.org/abs/2504.02878v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to The 2nd International Workshop on Foundation Models for  Cyber-Physical Systems &amp; Internet of Things (FMSys 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用惯性测量单元（IMUs）进行人类活动识别（HAR），并探讨了利用大型语言模型（LLMs）在细粒度HAR任务上的应用。&lt;h4&gt;背景&lt;/h4&gt;现有方法主要关注粗粒度活动，如行走或跑步，而预训练的LLMs在细粒度HAR任务上，如空中书写字母识别，表现不佳。&lt;h4&gt;目的&lt;/h4&gt;旨在提高LLMs在细粒度HAR任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;通过使用自收集的数据集和少量样本学习对LLMs进行微调，并设计了一个基于编码器的流程，将3D数据映射到2D等价数据，以保持时空信息，从而实现稳健的字母预测。&lt;h4&gt;主要发现&lt;/h4&gt;在平坦表面书写场景中，通过微调和少量样本学习，在2D数据上实现了129倍的改进。在空中书写场景中，端到端流程在识别包含最多5个字母的单词时达到了78%的准确率。&lt;h4&gt;结论&lt;/h4&gt;LLMs可以作为细粒度HAR的有用工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：使用惯性测量单元（IMUs）进行的人类活动识别（HAR）越来越多地利用大型语言模型（LLMs），然而，现有方法主要关注粗粒度活动，如行走或跑步。我们的初步研究表明，预训练的LLMs在细粒度HAR任务上，如空中书写字母识别，表现极差，几乎只能达到随机猜测的准确率。在这项工作中，我们首先填补了这一差距，针对平坦表面书写场景：通过使用自收集的数据集和少量样本学习对LLMs进行微调，我们在2D数据上实现了129倍的改进。为了扩展到3D场景，我们设计了一个基于编码器的流程，将3D数据映射到2D等价数据，以保留时空信息，从而实现稳健的字母预测。我们的端到端流程在中空书写场景中识别最多5个字母的单词时达到了78%的准确率，确立了LLMs作为细粒度HAR的有用工具的地位。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human activity recognition (HAR) using inertial measurement units (IMUs)increasingly leverages large language models (LLMs), yet existing approachesfocus on coarse activities like walking or running. Our preliminary studyindicates that pretrained LLMs fail catastrophically on fine-grained HAR taskssuch as air-written letter recognition, achieving only near-random guessingaccuracy. In this work, we first bridge this gap for flat-surface writingscenarios: by fine-tuning LLMs with a self-collected dataset and few-shotlearning, we achieved up to a 129x improvement on 2D data. To extend this to 3Dscenarios, we designed an encoder-based pipeline that maps 3D data into 2Dequivalents, preserving the spatiotemporal information for robust letterprediction. Our end-to-end pipeline achieves 78% accuracy on word recognitionwith up to 5 letters in mid-air writing scenarios, establishing LLMs as viabletools for fine-grained HAR.</description>
      <author>example@mail.com (Lilin Xu, Kaiyuan Hou, Xiaofan Jiang)</author>
      <guid isPermaLink="false">2504.02878v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>LogiCity: Advancing Neuro-Symbolic AI with Abstract Urban Simulation</title>
      <link>http://arxiv.org/abs/2411.00773v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 8 figures, In Advances in Neural Information Processing  Systems (NeurIPS) 37 D&amp;B Track (2024): 69840-69864&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LogiCity是一个基于可定制一阶逻辑的城市环境模拟器，旨在解决现有NeSy AI基准测试的不足，为多智能体交互提供长周期推理任务。&lt;h4&gt;背景&lt;/h4&gt;近年来，NeSy AI系统迅速发展，但现有的NeSy AI基准测试未能提供具有复杂多智能体交互的长周期推理任务，且通常受限于固定的简单逻辑规则。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，LogiCity被引入作为第一个基于可定制一阶逻辑的模拟器，用于模拟具有多个动态智能体的城市环境。&lt;h4&gt;方法&lt;/h4&gt;LogiCity使用语义和空间概念（如IsAmbulance(X)和IsClose(X, Y)）来定义一阶逻辑规则，这些规则控制不同智能体的行为。用户可以配置抽象级别，以适应不同场景的复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;LogiCity在抽象推理方面显示了NeSy框架的优势，并突出了在长周期多智能体场景或高维、不平衡数据下处理更复杂抽象的挑战。&lt;h4&gt;结论&lt;/h4&gt;LogiCity被认为是NeSy AI发展中的一个重要步骤，其灵活的设计和特点为下一代NeSy AI的进步奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;最近几年，神经符号（NeSy）人工智能系统得到了快速发展，这些系统将符号推理集成到深度神经网络中。然而，大多数现有的NeSy AI基准测试未能提供具有复杂多智能体交互的长周期推理任务。此外，它们通常受限于固定和简化的逻辑规则，这些规则适用于有限的实体，使得它们远远不能反映现实世界的复杂性。为了解决这些关键差距，我们引入了LogiCity，这是第一个基于可定制一阶逻辑的城市环境模拟器，用于具有多个动态智能体的环境。LogiCity使用语义和空间概念（如IsAmbulance(X)和IsClose(X, Y)）来建模各种城市元素。这些概念用于定义控制各种智能体行为的FOL规则。由于概念和规则是抽象的，它们可以普遍适用于任何智能体组成的城市，从而便于实现各种场景的实例化。此外，LogiCity的一个关键特性是其支持用户可配置的抽象，这使得逻辑推理的复杂度可以定制。为了探索NeSy AI的各个方面，LogiCity引入了两个任务，一个具有长周期顺序决策的特点，另一个专注于一步视觉推理，难度和智能体行为各异。我们的广泛评估揭示了NeSy框架在抽象推理方面的优势。此外，我们强调了在长周期多智能体场景或高维、不平衡数据下处理更复杂抽象的挑战。凭借其灵活的设计、各种功能和提出的新挑战，我们认为LogiCity是NeSy AI进步中的一个关键步骤。所有代码和数据都在我们的网站上开源：https://jaraxxus-me.github.io/LogiCity/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Jaraxxus-Me/LogiCity&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent years have witnessed the rapid development of Neuro-Symbolic (NeSy) AIsystems, which integrate symbolic reasoning into deep neural networks. However,most of the existing benchmarks for NeSy AI fail to provide long-horizonreasoning tasks with complex multi-agent interactions. Furthermore, they areusually constrained by fixed and simplistic logical rules over limitedentities, making them far from real-world complexities. To address thesecrucial gaps, we introduce LogiCity, the first simulator based on customizablefirst-order logic (FOL) for an urban-like environment with multiple dynamicagents. LogiCity models diverse urban elements using semantic and spatialconcepts, such as IsAmbulance(X) and IsClose(X, Y). These concepts are used todefine FOL rules that govern the behavior of various agents. Since the conceptsand rules are abstractions, they can be universally applied to cities with anyagent compositions, facilitating the instantiation of diverse scenarios.Besides, a key feature of LogiCity is its support for user-configurableabstractions, enabling customizable simulation complexities for logicalreasoning. To explore various aspects of NeSy AI, LogiCity introduces twotasks, one features long-horizon sequential decision-making, and the otherfocuses on one-step visual reasoning, varying in difficulty and agentbehaviors. Our extensive evaluation reveals the advantage of NeSy frameworks inabstract reasoning. Moreover, we highlight the significant challenges ofhandling more complex abstractions in long-horizon multi-agent scenarios orunder high-dimensional, imbalanced data. With its flexible design, variousfeatures, and newly raised challenges, we believe LogiCity represents a pivotalstep forward in advancing the next generation of NeSy AI. All the code and dataare open-sourced at our website: https://jaraxxus-me.github.io/LogiCity/</description>
      <author>example@mail.com (Bowen Li, Zhaoyu Li, Qiwei Du, Jinqi Luo, Wenshan Wang, Yaqi Xie, Simon Stepputtis, Chen Wang, Katia P. Sycara, Pradeep Kumar Ravikumar, Alexander G. Gray, Xujie Si, Sebastian Scherer)</author>
      <guid isPermaLink="false">2411.00773v2</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    </channel>
</rss>