<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 05 Mar 2025 14:36:05 +0800</lastBuildDate>
    <item>
      <title>RoboBERT: An End-to-end Multimodal Robotic Manipulation Model</title>
      <link>http://arxiv.org/abs/2502.07837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Embodied intelligence融合了多种模态，使代理能够同时理解图像、语言和行动。然而，现有的模型依赖于额外的数据集或广泛的预训练以最大化性能提升，这需要大量的训练时间和昂贵的硬件成本。&lt;h4&gt;背景&lt;/h4&gt;当前的多模态机器人模型通常需要额外的数据集或大规模的基础模型来达到高性能，并且消耗大量资源。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的端到端机器人操作模型RoboBERT及其独特的训练策略，旨在提高效率并减少对大型数据集和基础模型的需求。&lt;h4&gt;方法&lt;/h4&gt;该模型使用基于CNN的扩散策略，通过分离不同模态的训练过程来增强和稳定模型的有效性。同时强调数据增强的重要性，并验证了多种技术以显著提升性能。&lt;h4&gt;主要发现&lt;/h4&gt;RoboBERT在CALVIN基准测试中的ABCD → D任务中实现了4.52的平均长度，创下了新的SOTA记录；当应用于真实机器人时，该模型展示了比其他使用相同数据训练的方法更高的成功率。&lt;h4&gt;结论&lt;/h4&gt;通过这些概念和方法论，RoboBERT表现出广泛的灵活性和兼容性，并为轻量级多模态机器人模型的发展做出了重要贡献。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新的端到端的机器人操作模型——RoboBERT及其独特的培训策略。该模型旨在解决现有模型由于需要额外的数据集或大量预训练而导致的时间和资源消耗问题，通过采用基于CNN的扩散政策，并强调数据增强的重要性来提高性能。实验结果表明，RoboBERT在基准测试中取得了新纪录的成功率，并且在实际应用中也优于其他方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied intelligence integrates multiple modalities, enabling agents tounderstand images, language, and actions simultaneously. However, existingmodels always depend on additional datasets or extensive pre-training tomaximize performance improvements, consuming abundant training time andexpensive hardware cost. To tackle this issue, we present RoboBERT, a novelend-to-end robotic manipulation model integrated with a unique trainingstrategy. This model utilizes a CNN-based diffusion policy, enhancing andstabilizing the effectiveness of this model by separating training processesfor different modalities. It also underscores the importance of dataaugmentation, verifying various techniques to significantly boost performance.Unlike models that depend on extra data or large foundation models, RoboBERTachieves a highly competitive success rate while using only language-labeledexpert demonstrations and maintaining a relatively smaller model size.Specifically, RoboBERT achieves an average length of 4.52 on the CALVINbenchmark for \(ABCD \rightarrow D\) task, setting a new state-of-the-art(SOTA) record. Furthermore, when tested on a real robot, the model demonstratessuperior performance, achieving a higher success rate than other methodstrained with the same data. We propose that these concepts and methodologies ofRoboBERT demonstrate extensive versatility and compatibility, contributingsignificantly to the development of lightweight multimodal robotic models. Thecode can be accessed on https://github.com/PeterWangsicheng/RoboBERT</description>
      <author>example@mail.com (Sicheng Wang, Jianhua Shan, Jianwei Zhang, Haozhang Gao, Hailiang Han, Yipeng Chen, Kang Wei, Chengkun Zhang, Kairos Wong, Jie Zhao, Lei Zhao, Bin Fang)</author>
      <guid isPermaLink="false">2502.07837v1</guid>
      <pubDate>Wed, 05 Mar 2025 14:36:05 +0800</pubDate>
    </item>
  <item>
      <title>Probing a Quarkophobic ${\mathbf{W}}^\prime$ at the High-Luminosity LHC via Vector Boson Fusion and Lorentz-Equivariant Point Cloud Learning</title>
      <link>http://arxiv.org/abs/2502.16630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过弱玻色子融合方式探测标准模型之外的W'玻色子生产，使用点云学习技术并引入新的洛伦兹等变几何代数变换器提高信号敏感度。&lt;h4&gt;背景&lt;/h4&gt;在标准模型中添加一个质量较大的、几乎不与夸克耦合的带电矢量规范玻色子W'可以解决诸如B介子异常和W玻色子质量测量差异等问题。&lt;h4&gt;目的&lt;/h4&gt;通过弱相互作用过程研究W'玻色子的产生，利用大型强子对撞机中的质子-质子碰撞数据进行研究，并采用新的学习技术提高检测信号的能力。&lt;h4&gt;方法&lt;/h4&gt;在一种简化模型中工作，该模型假设W'玻色子具有较大的衰变宽度并考虑两个喷注、大的缺失横贯动量和一个轻味道的最终态。使用点云学习技术中的新洛伦兹等变几何代数变换器。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，新型方法相比于传统方法显著提高了信号敏感度。&lt;h4&gt;结论&lt;/h4&gt;引入新的计算工具（即Lorentz-Equivariant Geometric Algebra Transformer）使得探测W'玻色子更加有效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The addition of a heavy charged vector gauge boson ${\mathbf{W}}^\prime$ tothe Standard Model (SM) with negligible quark couplings ("quarkophobic") andtriple gauge couplings can address issues with the SM, such as the B-mesonanomalies and recent discrepancies in the W boson mass measurements. We presenta phenomenology study probing ${\mathbf{W}}^\prime$ production through weakboson fusion in proton-proton collisions at the Large Hadron Collider. Weoperate under a simplified model with a large ${\mathbf{W}}^\prime$ decay widthand consider final states with two jets, large missing transverse momentum, andone light lepton. Notably, we use point cloud learning for the first time in aBSM search$\unicode{x2014}$specifically, a novel Lorentz-Equivariant GeometricAlgebra Transformer$\unicode{x2014}$providing significant improvement in signalsensitivity compared to traditional methods.</description>
      <author>example@mail.com (U. S. Qureshi, A. Gurrola, J. D. Ruiz-Álvarez)</author>
      <guid isPermaLink="false">2502.16630v1</guid>
      <pubDate>Wed, 05 Mar 2025 14:36:05 +0800</pubDate>
    </item>
    <item>
      <title>Audio Visual Segmentation Through Text Embeddings</title>
      <link>http://arxiv.org/abs/2502.16359v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为AV2T-SAM的新框架，该框架将音频特征与预训练的文本提示式SAM的文本嵌入空间连接起来。&lt;h4&gt;背景&lt;/h4&gt;音频-视觉分割（AVS）的目标是定位和从视频帧中分离出发出声音的对象。由于手工注释昂贵，研究者面临数据集有限的问题。&lt;h4&gt;目的&lt;/h4&gt;通过利用丰富的文本图像配对数据集中学习到的多模态对应关系来增强视听对齐，并提出一种新特征以强调音频和视觉模式之间的共享语义同时过滤无关噪声。&lt;h4&gt;方法&lt;/h4&gt;将预训练模型SAM与声音提示结合，使用跨模式语义对齐的方法来改进AVS任务。&lt;h4&gt;主要发现&lt;/h4&gt;通过在AVSBench数据集上的实验显示了在两个数据集上都达到了最新的性能。该方法有效地利用了预训练的分割模型以及跨模态语义对齐。&lt;h4&gt;结论&lt;/h4&gt;提出的AV2T-SAM框架解决了现有音频-视觉分割技术面临的挑战，特别是在有限的数据集限制下学习视听关系的问题。&lt;h4&gt;翻译&lt;/h4&gt;提出了一种新的AVS框架，该框架使用SAM模型，并通过引入一种新的特征来改进其在处理声音源对象分割任务上的能力。此方法利用了跨模式语义对齐，并且实验证明了它能够有效地提高模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The goal of Audio-Visual Segmentation (AVS) is to localize and segment thesounding source objects from the video frames. Researchers working on AVSsuffer from limited datasets because hand-crafted annotation is expensive.Recent works attempt to overcome the challenge of limited data by leveragingthe segmentation foundation model, SAM, prompting it with audio to enhance itsability to segment sounding source objects. While this approach alleviates themodel's burden on understanding visual modality by utilizing pre-trainedknowledge of SAM, it does not address the fundamental challenge of the limiteddataset for learning audio-visual relationships. To address these limitations,we propose \textbf{AV2T-SAM}, a novel framework that bridges audio featureswith the text embedding space of pre-trained text-prompted SAM. Our methodleverages multimodal correspondence learned from rich text-image paireddatasets to enhance audio-visual alignment. Furthermore, we introduce a novelfeature, $\mathbf{\textit{\textbf{f}}_{CLIP} \odot\textit{\textbf{f}}_{CLAP}}$, which emphasizes shared semantics of audio andvisual modalities while filtering irrelevant noise. Experiments on the AVSBenchdataset demonstrate state-of-the-art performance on both datasets of AVSBench.Our approach outperforms existing methods by effectively utilizing pretrainedsegmentation models and cross-modal semantic alignment.</description>
      <author>example@mail.com (Kyungbok Lee, You Zhang, Zhiyao Duan)</author>
      <guid isPermaLink="false">2502.16359v1</guid>
      <pubDate>Wed, 05 Mar 2025 14:36:05 +0800</pubDate>
    </item>
    <item>
      <title>Robust Deterministic Policy Gradient for Disturbance Attenuation and Its Application to Quadrotor Control</title>
      <link>http://arxiv.org/abs/2502.21057v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种名为Robust Deterministic Policy Gradient (RDPG) 的强化学习算法，该算法将H无穷控制问题转化为一个零和动态博弈，并通过深度确定性策略梯度(DPG)及其深度强化学习版本进行训练。为实际应用引入了RDDPG算法，利用深层神经网络架构并结合TD3技术来提高稳定性和学习效率。&lt;h4&gt;背景&lt;/h4&gt;在实际控制系统中，由于系统模型中的不确定性以及外部扰动的存在，识别最优控制策略面临重大挑战。传统的H无穷控制方法虽然广泛应用于设计鲁棒控制器以减轻干扰影响，但往往需要复杂的计算资源和高强度的计算能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于强化学习的方法来解决实际控制系统中由于不确定性和外部干扰导致的设计复杂性问题，并提高控制器的稳定性与实时性能。&lt;h4&gt;方法&lt;/h4&gt;将H无穷控制问题建模为一个两人零和动态博弈，其中一方试图最小化成本而另一方则最大化。采用确定性策略梯度(DPG)及其深度强化学习版本来训练鲁棒控制策略，进而提出了一种名为RDDPG的算法，并在无人机路径跟踪任务中验证了该方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法能够在扰动环境下实现精确实时的目标追踪，在对比测试中显示出了比其他控制方法更高的抗干扰性能。&lt;h4&gt;结论&lt;/h4&gt;基于强化学习的RDPG和RDDPG为实际控制系统中的鲁棒控制器设计提供了一种有效且计算效率高的解决方案，尤其适用于需要应对动态变化环境的应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Practical control systems pose significant challenges in identifying optimalcontrol policies due to uncertainties in the system model and externaldisturbances. While $H_\infty$ control techniques are commonly used to designrobust controllers that mitigate the effects of disturbances, these methodsoften require complex and computationally intensive calculations. To addressthis issue, this paper proposes a reinforcement learning algorithm calledRobust Deterministic Policy Gradient (RDPG), which formulates the $H_\infty$control problem as a two-player zero-sum dynamic game. In this formulation, oneplayer (the user) aims to minimize the cost, while the other player (theadversary) seeks to maximize it. We then employ deterministic policy gradient(DPG) and its deep reinforcement learning counterpart to train a robust controlpolicy with effective disturbance attenuation. In particular, for practicalimplementation, we introduce an algorithm called robust deep deterministicpolicy gradient (RDDPG), which employs a deep neural network architecture andintegrates techniques from the twin-delayed deep deterministic policy gradient(TD3) to enhance stability and learning efficiency. To evaluate the proposedalgorithm, we implement it on an unmanned aerial vehicle (UAV) tasked withfollowing a predefined path in a disturbance-prone environment. Theexperimental results demonstrate that the proposed method outperforms othercontrol approaches in terms of robustness against disturbances, enablingprecise real-time tracking of moving targets even under severe disturbanceconditions.</description>
      <author>example@mail.com (Taeho Lee, Donghwan Lee)</author>
      <guid isPermaLink="false">2502.21057v1</guid>
      <pubDate>Wed, 05 Mar 2025 14:36:05 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating the Robustness of LiDAR Point Cloud Tracking Against Adversarial Attack</title>
      <link>http://arxiv.org/abs/2410.20893v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文研究了基于神经网络的LiDAR点云跟踪模型在对抗攻击下的鲁棒性，重点关注其在白盒和黑盒攻击策略中的脆弱性。&lt;h4&gt;背景&lt;/h4&gt;现有的LiDAR点云跟踪模型往往忽视了抗干扰能力的重要性，而仅仅关注性能提升。然而，在面对对抗攻击、领域转换或数据损坏等问题时，这些模型表现出严重的脆弱性。&lt;h4&gt;目的&lt;/h4&gt;研究如何提高基于神经网络的LiDAR点云跟踪模型在对抗攻击下的鲁棒性，并提出一种新的黑盒攻击策略方法：目标感知扰动生成(TAPG)算法。&lt;h4&gt;方法&lt;/h4&gt;{'白盒攻击': '为各种跟踪范式定制特定损失函数，扩展了现有FGSM、C&amp;W和PGD等方法到点云领域。', '黑盒攻击': '引入TAPG算法，通过稀疏性约束和随机子向量因子化技术提高转移能力。该算法旨在实现高攻击性能的同时保持低感知度。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，先进的跟踪方法在对抗白盒和黑盒攻击时存在显著脆弱性。&lt;h4&gt;结论&lt;/h4&gt;研究强调了增强LiDAR点云跟踪模型鲁棒性的必要性，并提出了一种新的平衡有效性和隐蔽性的TAPG算法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we delve into the robustness of neural network-based LiDARpoint cloud tracking models under adversarial attacks, a critical aspect oftenoverlooked in favor of performance enhancement. These models, despiteincorporating advanced architectures like Transformer or Bird's Eye View (BEV),tend to neglect robustness in the face of challenges such as adversarialattacks, domain shifts, or data corruption. We instead focus on the robustnessof the tracking models under the threat of adversarial attacks. We begin byestablishing a unified framework for conducting adversarial attacks within thecontext of 3D object tracking, which allows us to thoroughly investigate bothwhite-box and black-box attack strategies. For white-box attacks, we tailorspecific loss functions to accommodate various tracking paradigms and extendexisting methods such as FGSM, C\&amp;W, and PGD to the point cloud domain. Inaddressing black-box attack scenarios, we introduce a novel transfer-basedapproach, the Target-aware Perturbation Generation (TAPG) algorithm, with thedual objectives of achieving high attack performance and maintaining lowperceptibility. This method employs a heuristic strategy to enforce sparseattack constraints and utilizes random sub-vector factorization to bolstertransferability. Our experimental findings reveal a significant vulnerabilityin advanced tracking methods when subjected to both black-box and white-boxattacks, underscoring the necessity for incorporating robustness againstadversarial attacks into the design of LiDAR point cloud tracking models.Notably, compared to existing methods, the TAPG also strikes an optimal balancebetween the effectiveness of the attack and the concealment of theperturbations.</description>
      <author>example@mail.com (Shengjing Tian, Yinan Han, Xiantong Zhao, Bin Liu, Xiuping Liu)</author>
      <guid isPermaLink="false">2410.20893v2</guid>
      <pubDate>Wed, 05 Mar 2025 14:36:05 +0800</pubDate>
    </item>
    <item>
      <title>Prompt-driven Transferable Adversarial Attack on Person Re-Identification with Attribute-aware Textual Inversion</title>
      <link>http://arxiv.org/abs/2502.19697v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了一种新的攻击方法Attribute-aware Prompt Attack (AP-Attack)，该方法利用视觉语言模型(VLM)的图像文本对齐能力，通过对行人属性特定的文字嵌入进行破坏来显式地扰乱行人图像中的细粒度语义特征。&lt;h4&gt;背景&lt;/h4&gt;人员重识别(re-id)模型在安全监控系统中至关重要。然而，现有的基于VLM（视觉-语言模型）的攻击方法由于过于强调整体表示中的判别性语义，缺乏对综合特征破坏的能力。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的属性感知提示攻击(AP-Attack)方法，该方法旨在通过扰动行人图像中特定属性的文字嵌入来增强细粒度语义特征的扰乱效果，并提高对抗样本在不同模型和数据集上的迁移能力。&lt;h4&gt;方法&lt;/h4&gt;设计了文本反转网络以获取个人化的文字描述，这些网络将行人图像映射到表示语义嵌入的伪标记上。训练过程中采用了对比学习方式结合图像与预先定义的文字模板，该模板明确描述了行人的属性特征。&lt;h4&gt;主要发现&lt;/h4&gt;AP-Attack 方法在跨模型和数据集攻击场景中表现出色，其平均Drop Rate比现有方法高出22.9%，展示了极佳的迁移性。&lt;h4&gt;结论&lt;/h4&gt;通过扰乱行人图像中的细粒度语义特征，AP-Attack有效增强了对抗样本的破坏力，并且提高了它们的迁移性能。&lt;h4&gt;翻译&lt;/h4&gt;人员重识别(re-id)模型在安全监控系统中非常重要。最近基于视觉语言模型（VLM）的攻击方法显示出卓越的迁移性，通过攻击VLM中的通用图像和文本特征来探索这些模型的脆弱点。然而，由于过度强调整体表示中的判别性语义，它们缺乏对综合特征的彻底破坏。在这篇论文中，我们引入了属性感知提示攻击（AP-Attack），这是一种新颖的方法，它利用VLM的图像文字对齐能力显式地扰乱行人图像中的细粒度语义特征，通过摧毁特定于属性的文字嵌入来实现这一点。为了获得针对每个个体属性的个性化文本描述，设计了文本反转网络将行人图像映射到表示语义嵌入的伪标记上，并在对比学习方式下进行训练，结合图像和预先定义的好像模板，该模板明确地描述了行人的属性特征。扰动后的良性及对抗性细粒度文本语义使攻击者能够有效地进行全面破坏，从而增强了对抗样本的迁移能力。广泛的实验表明，AP-Attack实现了最先进的迁移性能，在跨模型和数据集的攻击场景中平均Drop Rate比现有方法高出22.9%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Person re-identification (re-id) models are vital in security surveillancesystems, requiring transferable adversarial attacks to explore thevulnerabilities of them. Recently, vision-language models (VLM) based attackshave shown superior transferability by attacking generalized image and textualfeatures of VLM, but they lack comprehensive feature disruption due to theoveremphasis on discriminative semantics in integral representation. In thispaper, we introduce the Attribute-aware Prompt Attack (AP-Attack), a novelmethod that leverages VLM's image-text alignment capability to explicitlydisrupt fine-grained semantic features of pedestrian images by destroyingattribute-specific textual embeddings. To obtain personalized textualdescriptions for individual attributes, textual inversion networks are designedto map pedestrian images to pseudo tokens that represent semantic embeddings,trained in the contrastive learning manner with images and a predefined prompttemplate that explicitly describes the pedestrian attributes. Inverted benignand adversarial fine-grained textual semantics facilitate attacker ineffectively conducting thorough disruptions, enhancing the transferability ofadversarial examples. Extensive experiments show that AP-Attack achievesstate-of-the-art transferability, significantly outperforming previous methodsby 22.9% on mean Drop Rate in cross-model&amp;dataset attack scenarios.</description>
      <author>example@mail.com (Yuan Bian, Min Liu, Yunqi Yi, Xueping Wang, Yaonan Wang)</author>
      <guid isPermaLink="false">2502.19697v2</guid>
      <pubDate>Wed, 05 Mar 2025 14:36:05 +0800</pubDate>
    </item>
    <item>
      <title>OpenFly: A Versatile Toolchain and Large-scale Benchmark for Aerial Vision-Language Navigation</title>
      <link>http://arxiv.org/abs/2502.18041v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概述&lt;/h4&gt;介绍了用于户外高空Vision-Language Navigation (VLN)的OpenFly平台，该平台包括工具链和大规模基准数据集。&lt;h4&gt;背景&lt;/h4&gt;室内VLN已经得到了广泛研究，但室外高空VLN由于涉及广阔区域的数据收集难度大而研究不足。&lt;h4&gt;目的&lt;/h4&gt;提出一个完整的工具链和大规模的户外高空VLN数据集来解决现有数据缺乏的问题。&lt;h4&gt;方法&lt;/h4&gt;{'自动化工具链': '开发了高度自动化的工具链用于数据收集，包括点云获取、场景语义分割、飞行轨迹创建及指令生成。', '大规模数据集构建': '利用工具链建立了包含100k条轨迹的大规模户外高空VLN数据集，涵盖了多样化的高度和长度以及18个不同场景。', '视觉数据生成': '采用多种渲染引擎和技术（如Unreal Engine、GTA V、Google Earth及3D Gaussian Splatting）生成高质量的视觉数据。', '模型开发': '提出了关键帧感知的VLN模型OpenFly-Agent，输入语言指令、当前观察值和历史关键帧，并直接输出飞行动作。'}&lt;h4&gt;主要发现&lt;/h4&gt;平台及其模型在多项实验中展示了其优越性。&lt;h4&gt;结论&lt;/h4&gt;工具链、数据集及代码将开源以促进相关研究的发展。&lt;h4&gt;翻译&lt;/h4&gt;Vision-Language Navigation (VLN)旨在通过利用语言指令和视觉线索来引导环境中的代理，这在具身AI领域扮演着重要角色。虽然室内VLN已经得到了广泛的研究，但室外高空VLN由于涉及广阔区域的数据收集难度大而鲜少有人研究。为解决这一问题，我们提出了一种开放式飞行平台OpenFly，包括一个灵活的工具链和大规模基准数据集。首先，开发了一个高度自动化的工具链用于数据采集，实现了点云获取、场景语义分割、飞行轨迹创建及指令生成等自动化过程。其次，在此基础上建立了一个包含10万条不同高度与长度路线的大规模户外高空VLN数据集，并利用多种渲染引擎（如Unreal Engine, GTA V, Google Earth）和技术（如3D Gaussian Splatting）生成高视觉质量的数据，其中3D GS支持真实到仿真渲染。最后，我们提出了关键帧感知的VLN模型OpenFly-Agent，该模型根据语言指令、当前观察值和历史关键帧输出飞行动作。通过全面分析及实验表明了我们的平台及其模型的优势，并计划开放工具链、数据集以及相关代码以促进进一步的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Navigation (VLN) aims to guide agents through an environmentby leveraging both language instructions and visual cues, playing a pivotalrole in embodied AI. Indoor VLN has been extensively studied, whereas outdooraerial VLN remains underexplored. The potential reason is that outdoor aerialview encompasses vast areas, making data collection more challenging, whichresults in a lack of benchmarks. To address this problem, we propose OpenFly, aplatform comprising a versatile toolchain and large-scale benchmark for aerialVLN. Firstly, we develop a highly automated toolchain for data collection,enabling automatic point cloud acquisition, scene semantic segmentation, flighttrajectory creation, and instruction generation. Secondly, based on thetoolchain, we construct a large-scale aerial VLN dataset with 100ktrajectories, covering diverse heights and lengths across 18 scenes. Thecorresponding visual data are generated using various rendering engines andadvanced techniques, including Unreal Engine, GTA V, Google Earth, and 3DGaussian Splatting (3D GS). All data exhibit high visual quality. Particularly,3D GS supports real-to-sim rendering, further enhancing the realism of thedataset. Thirdly, we propose OpenFly-Agent, a keyframe-aware VLN model, whichtakes language instructions, current observations, and historical keyframes asinput, and outputs flight actions directly. Extensive analyses and experimentsare conducted, showcasing the superiority of our OpenFly platform andOpenFly-Agent. The toolchain, dataset, and codes will be open-sourced.</description>
      <author>example@mail.com (Yunpeng Gao, Chenhui Li, Zhongrui You, Junli Liu, Zhen Li, Pengan Chen, Qizhi Chen, Zhonghan Tang, Liansheng Wang, Penghui Yang, Yiwen Tang, Yuhang Tang, Shuai Liang, Songyi Zhu, Ziqin Xiong, Yifei Su, Xinyi Ye, Jianan Li, Yan Ding, Dong Wang, Zhigang Wang, Bin Zhao, Xuelong Li)</author>
      <guid isPermaLink="false">2502.18041v3</guid>
      <pubDate>Wed, 05 Mar 2025 14:36:05 +0800</pubDate>
    </item>
    <item>
      <title>CalibRefine: Deep Learning-Based Online Automatic Targetless LiDAR-Camera Calibration with Iterative and Attention-Driven Post-Refinement</title>
      <link>http://arxiv.org/abs/2502.17648v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Transportation Research Part C: Emerging Technologies&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为CalibRefine的全自动、无目标且在线校准框架，该框架可以处理原始LiDAR点云和相机图像，通过一系列阶段实现精确的多传感器校准。&lt;h4&gt;背景&lt;/h4&gt;在诸如自动驾驶汽车、机器人技术及智能交通系统等应用中，准确的多传感器校准至关重要。现有的激光雷达-摄像机校准方法通常依赖于手动放置的目标物、初步参数估计或密集的数据预处理，这限制了它们在实际环境中的可扩展性和适应性。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种全自动化的校准框架，该框架不依赖人工目标且可以在线完成，并能够直接处理原始激光雷达点云和相机图像数据。&lt;h4&gt;方法&lt;/h4&gt;CalibRefine由四个阶段组成：（1）一个共同特征鉴别器，利用自动检测到的对象的相对位置、外观嵌入以及语义类别生成可靠的激光雷达-摄像机对应关系；（2）基于粗略同构变换的校准；（3）迭代细化，在更多数据帧可用时逐步提高对齐精度；（4）注意力机制改进，通过使用视觉变压器和交叉注意机制解决非平面失真问题。&lt;h4&gt;主要发现&lt;/h4&gt;CalibRefine在两个城市交通数据集上进行了广泛的实验，结果显示它能够以最少的人工干预实现高精度校准结果，优于无目标的现有方法，并与手动调优基线保持竞争性或超越。&lt;h4&gt;结论&lt;/h4&gt;研究强调了如何通过稳健的对象级特征匹配以及迭代和自监督的注意力机制调整，在复杂的真实世界条件下实现一致的传感器融合，而无需地面真相校准矩阵或复杂的预处理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/radar-lab/Lidar_Camera_Automatic_Calibration&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate multi-sensor calibration is essential for deploying robustperception systems in applications such as autonomous driving, robotics, andintelligent transportation. Existing LiDAR-camera calibration methods oftenrely on manually placed targets, preliminary parameter estimates, or intensivedata preprocessing, limiting their scalability and adaptability in real-worldsettings. In this work, we propose a fully automatic, targetless, and onlinecalibration framework, CalibRefine, which directly processes raw LiDAR pointclouds and camera images. Our approach is divided into four stages: (1) aCommon Feature Discriminator that trains on automatically detectedobjects--using relative positions, appearance embeddings, and semanticclasses--to generate reliable LiDAR-camera correspondences, (2) a coarsehomography-based calibration, (3) an iterative refinement to incrementallyimprove alignment as additional data frames become available, and (4) anattention-based refinement that addresses non-planar distortions by leveraginga Vision Transformer and cross-attention mechanisms. Through extensiveexperiments on two urban traffic datasets, we show that CalibRefine delivershigh-precision calibration results with minimal human involvement,outperforming state-of-the-art targetless methods and remaining competitivewith, or surpassing, manually tuned baselines. Our findings highlight howrobust object-level feature matching, together with iterative andself-supervised attention-based adjustments, enables consistent sensor fusionin complex, real-world conditions without requiring ground-truth calibrationmatrices or elaborate data preprocessing.</description>
      <author>example@mail.com (Lei Cheng, Lihao Guo, Tianya Zhang, Tam Bang, Austin Harris, Mustafa Hajij, Mina Sartipi, Siyang Cao)</author>
      <guid isPermaLink="false">2502.17648v3</guid>
      <pubDate>Wed, 05 Mar 2025 14:36:05 +0800</pubDate>
    </item>
    <item>
      <title>Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model</title>
      <link>http://arxiv.org/abs/2502.16779v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025. Github  page:https://github.com/justacar/Plane-DUSt3R&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Plane-DUSt3R是一种利用3D基础模型DUSt3R进行多视角房间布局估计的新方法。&lt;h4&gt;背景&lt;/h4&gt;由于多视图几何的复杂性，从多视角图像中推断房间布局的研究较少。传统的结构从运动过程中涉及多个步骤（如相机内部和外部参数估计、图像匹配和三角测量）。然而，在3D重建领域，最近出现的3D基础模型改变了传统方法。&lt;h4&gt;目的&lt;/h4&gt;介绍并改进一种基于DUSt3R框架的方法——Plane-DUSt3R，以解决多视角房间布局估计的问题。&lt;h4&gt;方法&lt;/h4&gt;Plane-DUSt3R通过在房间布局数据集（Structure3D）上进行微调，并修改目标函数来估计结构平面。它采用单步后处理步骤和2D检测结果生成一致且简洁的结果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，Plane-DUSt3R不仅在合成数据集中优于现有最佳方法，还在具有不同图像风格（如卡通）的现实世界数据中表现出鲁棒性和有效性。&lt;h4&gt;结论&lt;/h4&gt;Plane-DUSt3R提供了一种简化流程、减少误差累积的端到端解决方案，并能处理多视角图像。此研究拓展了房间布局估计领域的可能性。&lt;h4&gt;翻译&lt;/h4&gt;从多个视角的图片中推断出房间的布局由于涉及到复杂的多视图几何问题，因此研究较少。传统的结构从运动过程需要一系列步骤（例如相机内参和外参估计、图像匹配以及三角测量）。然而，在3D重建领域，最近出现的像DUSt3R这样的3D基础模型改变了这一传统流程，使其向端到端的单步方法转变。为了解决多视角房间布局估计的问题，我们引入了Plane-DUSt3R，这是一种利用3D基础模型DUSt3R的方法。该方法基于DUSt3R框架，并在房间布局数据集（Structure3D）上进行了微调以估计结构平面。它通过单一的后处理步骤和2D检测结果生成一致且简洁的结果。与依赖单视角或全景图象的方法不同，Plane-DUSt3R能够处理多视角图像并提供了一种简化的、端到端的解决方案来简化过程，并减少误差积累。实验结果显示，相较于现有最佳方法，在合成数据集上，该方法表现更优；在不同的真实世界数据集中（例如卡通风格），该方法表现出稳健性和有效性。我们的代码可以在https://github.com/justacar/Plane-DUSt3R中获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Room layout estimation from multiple-perspective images is poorlyinvestigated due to the complexities that emerge from multi-view geometry,which requires muti-step solutions such as camera intrinsic and extrinsicestimation, image matching, and triangulation. However, in 3D reconstruction,the advancement of recent 3D foundation models such as DUSt3R has shifted theparadigm from the traditional multi-step structure-from-motion process to anend-to-end single-step approach. To this end, we introduce Plane-DUSt3R, anovel method for multi-view room layout estimation leveraging the 3D foundationmodel DUSt3R. Plane-DUSt3R incorporates the DUSt3R framework and fine-tunes ona room layout dataset (Structure3D) with a modified objective to estimatestructural planes. By generating uniform and parsimonious results, Plane-DUSt3Renables room layout estimation with only a single post-processing step and 2Ddetection results. Unlike previous methods that rely on single-perspective orpanorama image, Plane-DUSt3R extends the setting to handle multiple-perspectiveimages. Moreover, it offers a streamlined, end-to-end solution that simplifiesthe process and reduces error accumulation. Experimental results demonstratethat Plane-DUSt3R not only outperforms state-of-the-art methods on thesynthetic dataset but also proves robust and effective on in the wild data withdifferent image styles such as cartoon. Our code is available at:https://github.com/justacar/Plane-DUSt3R</description>
      <author>example@mail.com (Yaxuan Huang, Xili Dai, Jianan Wang, Xianbiao Qi, Yixing Yuan, Xiangyu Yue)</author>
      <guid isPermaLink="false">2502.16779v3</guid>
      <pubDate>Wed, 05 Mar 2025 14:36:05 +0800</pubDate>
    </item>
    <item>
      <title>Robust Prediction of Frictional Contact Network in Near-Jamming Suspensions Employing Deep Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.18743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于图神经网络（GNN）的机器学习方法，用于预测颗粒悬浮液中的摩擦接触网络（FCN），特别是在接近拥堵条件下的性能。这种方法在数据驱动模拟训练中表现出色，并且能够准确预测不同参数组合下的FCN。&lt;h4&gt;背景&lt;/h4&gt;细颗粒分散于牛顿流体中的悬浮物粘度在其接近拥挤状态时发散，这主要是由粒子间接触微观结构决定的。这种联系网络是导致固体化的行为的关键。应力传输和网络拓扑对粒子相对运动的限制非常敏感。&lt;h4&gt;目的&lt;/h4&gt;开发一种预测FCN的有效机器学习方法，尤其是在靠近拥堵条件下的情况。&lt;h4&gt;方法&lt;/h4&gt;使用了一种称为Deep Graph Convolutional Network（DeepGCN）的方法，并且展示了在不同参数组合下具有良好的泛化和外推能力。该研究包括从半稀释状态到拥挤状态的广泛相空间，同时系统地改变剪切应力、堆积分数以及滑动和滚动摩擦。&lt;h4&gt;主要发现&lt;/h4&gt;通过训练数据驱动模拟，DeepGCN能够准确预测不同流参数和相空间条件下的FCN。这些结果展示了在材料科学及相关领域创新且可转移的技术途径的潜力。&lt;h4&gt;结论&lt;/h4&gt;这项研究为预测颗粒系统性质提供了新的技术方法，特别是在拥挤条件下，这可能推动材料科学及其相关领域的进展。&lt;h4&gt;翻译&lt;/h4&gt;悬浮液中由细小颗粒分散于牛顿流体中的粘度在接近堆积极限时发散。这种宏观行为受到粒子接触微观结构的支配，通过摩擦接触网络（FCN）来实现。FCN是由机械负载支撑点组成的，在接近拥挤转变时导致刚性出现。应力传递和网络拓扑反过来取决于颗粒相对运动限制的敏感特性。尽管其重要性显而易见，但由于实验和计算障碍的存在，预测FCN特别是靠近拥挤条件下的情况仍然具有挑战性。这项研究提出了一个基于图神经网络（GNN）的成本效益机器学习方法来预测FCN，并且通过使用DeepGCN展示了在不同流参数和相空间条件下准确预测FCN的能力。该研究覆盖了广泛的相空间，从半稀释到拥挤状态以及瞬态到稳定状态，并系统地改变剪切应力、堆积分数及滑动和滚动摩擦等参数。这项研究的结果为颗粒系统的性质预测提供了创新且可转移的技术途径，为进一步发展材料科学及相关领域开辟新的道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The viscosity of the suspension consisting of fine particles dispersed in aNewtonian liquid diverges close to the jamming packing fraction. The contactmicrostructure in suspensions governs this macroscopic behavior in the vicinityof jamming through a frictional contact network (FCN). FCN is composed ofmechanical load-bearing contacts that lead to the emergence of rigidity nearthe jamming transition. The stress transmission and network topology, in turn,depend sensitively on constraints on the relative motion of the particles.Despite their significance, predicting the FCN, especially close to jammingconditions, remains challenging due to experimental and computationalimpediments. This study introduces a cost-effective machine learning approachto predict the FCN using a graph neural network (GNN), which inherentlycaptures hidden features and underlying patterns in dense suspension by mappinginterparticle interactions. Employing a variation of GNN called the Deep GraphConvolutional Network (DeepGCN) trained on data-driven simulations, this studydemonstrates robust generalization and extrapolation capabilities, accuratelypredicting FCNs in systems with divergent flow parameters and phase spaces,despite each being trained exclusively on a single condition. The study coversa wide range of phase space, from semi-dilute to jammed states, spanningtransient to steady states, while systematically varying parameters such asshear stress (${\sigma}_{xy}$), packing fraction(${\phi}$) and sliding androlling friction (${{\mu}_s, {\mu}_r}$). The results of this research pave theway for innovative transferable techniques in predicting the properties ofparticulate systems, offering new avenues for advancement in material scienceand related fields.</description>
      <author>example@mail.com (Armin Aminimajd, Joao Maia, Abhinendra Singh)</author>
      <guid isPermaLink="false">2502.18743v1</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
  <item>
      <title>Avat3r: Large Animatable Gaussian Reconstruction Model for High-fidelity 3D Head Avatars</title>
      <link>http://arxiv.org/abs/2502.20220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://tobias-kirschstein.github.io/avat3r/, Video:  https://youtu.be/P3zNVx15gYs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Avat3r的方法，可以从少量输入图像中生成高质量且可动画化的3D头像。&lt;h4&gt;背景&lt;/h4&gt;传统上，创建逼真的3D头像是一个复杂的过程，需要多视角捕捉设备和昂贵的优化过程。这限制了数字人类替身的应用范围，使其仅限于VFX行业或离线渲染。&lt;h4&gt;目的&lt;/h4&gt;开发一种减少计算需求的方法，使得高质量、可动画化的3D头像可以从少量输入图像中生成。&lt;h4&gt;方法&lt;/h4&gt;{'利用大型重建模型': '使大规模重建模型变得可动画化，并从大量的多视角视频数据集中学习三维人体头部的强大先验知识。', '改进的3D头部重构': '采用来自DUSt3R的位置图和Sapiens的人类基础模型中的泛化特征图来改善3D头部重构。', '实现动画功能': '发现简单的跨注意力到表情代码就足够用于使3D头像可动画化。', '增强鲁棒性': '通过训练时输入不同表情的图像，增强了模型从不一致输入中重建三维头部的能力。'}&lt;h4&gt;主要发现&lt;/h4&gt;Avat3r在少数输入和单个输入场景中的表现优于现有最先进的方法，并展示了广泛的适用性，能够创建来自各种来源（包括智能手机拍摄、单一图片甚至超出领域范围如古董头像）的3D头像。&lt;h4&gt;结论&lt;/h4&gt;通过项目网站https://tobias-kirschstein.github.io/avat3r可查看更多详细信息。该方法在效率和性能上表现出显著优势，为数字人类替身的应用开辟了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的传统创建逼真的3D头像过程需要复杂的多视角捕捉设备以及昂贵的计算资源，在实际应用中受到限制；本文提出了一种名为Avat3r的技术，可以从少量输入图像生成高质量且可动画化的3D头像，并通过训练模型学习泛化特征和不同表情下的鲁棒性重构方法，实现了在效率与性能上的突破。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditionally, creating photo-realistic 3D head avatars requires astudio-level multi-view capture setup and expensive optimization duringtest-time, limiting the use of digital human doubles to the VFX industry oroffline renderings.  To address this shortcoming, we present Avat3r, which regresses ahigh-quality and animatable 3D head avatar from just a few input images, vastlyreducing compute requirements during inference. More specifically, we makeLarge Reconstruction Models animatable and learn a powerful prior over 3D humanheads from a large multi-view video dataset. For better 3D headreconstructions, we employ position maps from DUSt3R and generalized featuremaps from the human foundation model Sapiens. To animate the 3D head, our keydiscovery is that simple cross-attention to an expression code is alreadysufficient. Finally, we increase robustness by feeding input images withdifferent expressions to our model during training, enabling the reconstructionof 3D head avatars from inconsistent inputs, e.g., an imperfect phone capturewith accidental movement, or frames from a monocular video.  We compare Avat3r with current state-of-the-art methods for few-input andsingle-input scenarios, and find that our method has a competitive advantage inboth tasks. Finally, we demonstrate the wide applicability of our proposedmodel, creating 3D head avatars from images of different sources, smartphonecaptures, single images, and even out-of-domain inputs like antique busts.  Project website: https://tobias-kirschstein.github.io/avat3r/</description>
      <author>example@mail.com (Tobias Kirschstein, Javier Romero, Artem Sevastopolsky, Matthias Nießner, Shunsuke Saito)</author>
      <guid isPermaLink="false">2502.20220v1</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success</title>
      <link>http://arxiv.org/abs/2502.19645v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Website: https://openvla-oft.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了用于视觉-语言-动作模型（VLAs）的优化微调策略，提出了一个集成平行解码、连续动作表示等技术的高效微调方案。&lt;h4&gt;背景&lt;/h4&gt;现有的VLAs依赖于预训练的语言和视觉模型，并利用各种机器人数据集展示了强大的任务执行能力。然而，这些模型在面对新环境时需要通过微调来适应，而最佳的微调策略尚未明确。&lt;h4&gt;目的&lt;/h4&gt;探讨不同的动作解码方案、表示方法及学习目标对VLAs性能的影响，提出一种优化微调的方法以改善推理效率和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;使用OpenVLA作为基准模型，并通过实证分析确定了最佳的动作解码策略、表示方式以及学习目标。提出的OFT框架包括并行解码、动作切块（action chunking）、连续动作表示和基于L1回归的学习目标。&lt;h4&gt;主要发现&lt;/h4&gt;优化后的微调方法显著提高了OpenVLA在LIBERO仿真基准测试中的成功率，同时增加了行动生成的吞吐量；在真实世界评估中，该策略使得OpenVLA能够优于其他VLAs以及其他从头开始训练的模仿学习策略，在平均成功率上提高15%。&lt;h4&gt;结论&lt;/h4&gt;通过引入OFT方法，可以显著改善视觉-语言-动作模型在新环境下的性能和效率，并且提供了一种有效的微调方案。该研究进一步证明了优化微调对于提升这些复杂模型的实际应用效果的重要性。&lt;h4&gt;翻译&lt;/h4&gt;近期的视觉-语言-动作（VLA）模型基于预训练的语言与视觉模型构建，利用多样化的机器人数据集展示出色的任务执行能力、跟随语言指令的能力以及语义泛化。尽管取得了一些成功，但VLAs在面对新机器人设置时仍表现不佳，需要通过微调来获得良好性能。针对这一问题，该研究探讨了关键的VLA适应设计选择，如不同的动作解码方案、表示方法和学习目标，并提出了一个优化微调（OFT）配方。实证分析表明，这种方法提高了推理效率、政策性能以及模型输入输出规范的灵活性。所提出的OpenVLA-OFT在LIBERO仿真基准上达到了新的最佳水平，在四组任务上的平均成功率从76.5%提高到97.1%，同时增加了26倍的动作生成吞吐量。实际评估显示，优化微调方案使得OpenVLA能够成功执行ALOHA双臂机器人上的精细、高频控制任务，并在平均成功率上显著优于其他VLAs和强大的从头开始训练的模仿学习策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent vision-language-action models (VLAs) build upon pretrainedvision-language models and leverage diverse robot datasets to demonstratestrong task execution, language following ability, and semantic generalization.Despite these successes, VLAs struggle with novel robot setups and requirefine-tuning to achieve good performance, yet how to most effectively fine-tunethem is unclear given many possible strategies. In this work, we study key VLAadaptation design choices such as different action decoding schemes, actionrepresentations, and learning objectives for fine-tuning, using OpenVLA as ourrepresentative base model. Our empirical analysis informs an OptimizedFine-Tuning (OFT) recipe that integrates parallel decoding, action chunking, acontinuous action representation, and a simple L1 regression-based learningobjective to altogether improve inference efficiency, policy performance, andflexibility in the model's input-output specifications. We propose OpenVLA-OFT,an instantiation of this recipe, which sets a new state of the art on theLIBERO simulation benchmark, significantly boosting OpenVLA's average successrate across four task suites from 76.5% to 97.1% while increasing actiongeneration throughput by 26$\times$. In real-world evaluations, our fine-tuningrecipe enables OpenVLA to successfully execute dexterous, high-frequencycontrol tasks on a bimanual ALOHA robot and outperform other VLAs ($\pi_0$ andRDT-1B) fine-tuned using their default recipes, as well as strong imitationlearning policies trained from scratch (Diffusion Policy and ACT) by up to 15%(absolute) in average success rate. We release code for OFT and pretrainedmodel checkpoints at https://openvla-oft.github.io/.</description>
      <author>example@mail.com (Moo Jin Kim, Chelsea Finn, Percy Liang)</author>
      <guid isPermaLink="false">2502.19645v1</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>$Δ$-model correction of Foundation Model based on the models own understanding</title>
      <link>http://arxiv.org/abs/2502.21179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要描述了一种基于Δ-learning的方法，用于改进通用原子间势能模型在特定材料子类中的应用。&lt;h4&gt;背景&lt;/h4&gt;当前的通用势能模型可能需要针对具体材料进行微调或残差修正。CHGNet是一个典型的例子，它能够在全局结构优化设置中准确预测某些氧化物的能量特性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Δ-learning的方法来改善通用势能模型在特定场景中的表现，并探讨不同聚合方式（如全局、元素分离和原子级别）的效果。&lt;h4&gt;方法&lt;/h4&gt;使用Gaussian Process Regression (GPR)模型作为Δ-model，以CHGNet内部的原子嵌入表示为基础进行修正。这种方法可以为需要精确预测的新材料或环境提供有效的校正方案。&lt;h4&gt;主要发现&lt;/h4&gt;对于铜、银和金表面上硫原子覆盖层的情况，原始CHGNet模型存在不足之处，需要通过基于GPR的Δ-model来进行校正以提高精度。&lt;h4&gt;结论&lt;/h4&gt;通用势能模型在缺乏特定类型原子环境的数据时会表现出误差，这表明了开发更有效的修正方案的重要性。研究还发现其他使用相同训练数据集（如MACE-MP0、SevenNet-0和ORB-v2-only-MPtrj）的通用势能模型也显示出类似的行为。&lt;h4&gt;翻译&lt;/h4&gt;基础材料间的相互作用势能模型可能需要针对具体应用进行微调或残差修正。文中提出了一种基于Δ-learning的方法，通过已嵌入的表示实现这种改进。在全局结构优化设置中使用CHGNet时发现其能够准确描述某些氧化物的能量特性。然而对于金属表面上硫原子覆盖层的情况，则需要利用GPR模型来进行校正以提高预测准确性。研究结果表明了开发更有效的修正方案的重要性，因为其他训练于类似数据集上的通用势能模型也存在相似问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models of interatomic potentials, so called universal potentials,may require fine-tuning or residual corrections when applied to specificsubclasses of materials. In the present work, we demonstrate how suchaugmentation can be accomplished via $\Delta$-learning based on therepresentation already embedded in the universal potentials. The $\Delta$-modelintroduced is a Gaussian Process Regression (GPR) model and various types ofaggregation (global, species-separated, and atomic) of the representationvector are discussed. Employing a specific universal potential, CHGNet [Deng etal., Nat. Mach. Intell. 5, 1031 (2023)], in a global structure optimizationsetting, we find that it correctly describes the energetics of the "8" Cuoxide, which is an ultra-thin oxide film on Cu(111). The universal potentialmodel even predicts a more favorable structure compared to that discussed inrecent DFT-based literature. Moving to sulfur adatom overlayers on Cu(111),Ag(111), and Au(111) the CHGNet model, however, requires corrections. Wedemonstrate that these are efficiently provided via the GPR-based$\Delta$-model formulated on the CHGNet's own internal atomic embeddingrepresentation. The need for corrections is tracked to the scarcity ofmetal-sulfur atomic environments in the materials project database that CHGNetis trained on leading to an overreliance on sulfur-sulfur atomic environments.Other universal potentials trained on the same data, MACE-MP0, SevenNet-0, andORB-v2-only-MPtrj show similar behavior, but with varying degrees of error,demonstrating the general need for augmentation schemes for universal potentialmodels.</description>
      <author>example@mail.com (Mads-Peter Verner Christiansen, Bjørk Hammer)</author>
      <guid isPermaLink="false">2502.21179v1</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>You Only Click Once: Single Point Weakly Supervised 3D Instance Segmentation for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2502.19698v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为YoCo的框架，用于生成高质量的3D伪标签以减少户外LiDAR点云三维实例分割任务中的人工标注工作。&lt;h4&gt;背景&lt;/h4&gt;户外LiDAR点云三维实例分割是自动驾驶中的关键任务，但由于需要大量人工劳动进行标注，训练模型变得非常困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用少量粗略点击注释生成高质量伪标签的方法，以减少标注成本并提高模型性能。&lt;h4&gt;方法&lt;/h4&gt;{'YoCo框架': '1. 利用视觉基础模型结合点云的几何约束来增强伪标签生成；2. 设计了一个基于时空的标签更新模块，利用相邻帧的预测结果，并考虑点云固有的密度变化特性（近处密集、远处稀疏）；3. 提出一个IoU引导增强模块，替换掉置信度低和IoU低的伪标签。', '效果': '在Waymo数据集上的实验表明，YoCo框架具有显著的效果，达到了弱监督方法中的最佳性能，并且超越了完全监督的方法Cylinder3D。此外，YoCo还适用于多种网络，在仅使用少量标注数据的情况下实现了与完全监督方法相当的性能。'}&lt;h4&gt;主要发现&lt;/h4&gt;1. 通过结合视觉基础模型和点云几何约束可以有效生成高质量伪标签；2. 基于时空的标签更新模块能够利用相邻帧的信息提高标签质量。&lt;h4&gt;结论&lt;/h4&gt;YoCo框架在减少标注工作量的同时，提高了户外LiDAR点云三维实例分割任务中的模型性能，并且具有广泛适用性和优秀的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Outdoor LiDAR point cloud 3D instance segmentation is a crucial task inautonomous driving. However, it requires laborious human efforts to annotatethe point cloud for training a segmentation model. To address this challenge,we propose a YoCo framework, which generates 3D pseudo labels using minimalcoarse click annotations in the bird's eye view plane. It is a significantchallenge to produce high-quality pseudo labels from sparse annotations. OurYoCo framework first leverages vision foundation models combined with geometricconstraints from point clouds to enhance pseudo label generation. Second, atemporal and spatial-based label updating module is designed to generatereliable updated labels. It leverages predictions from adjacent frames andutilizes the inherent density variation of point clouds (dense near, sparsefar). Finally, to further improve label quality, an IoU-guided enhancementmodule is proposed, replacing pseudo labels with high-confidence and high-IoUpredictions. Experiments on the Waymo dataset demonstrate YoCo's effectivenessand generality, achieving state-of-the-art performance among weakly supervisedmethods and surpassing fully supervised Cylinder3D. Additionally, the YoCo issuitable for various networks, achieving performance comparable to fullysupervised methods with minimal fine-tuning using only 0.8% of the fullylabeled data, significantly reducing annotation costs.</description>
      <author>example@mail.com (Guangfeng Jiang, Jun Liu, Yongxuan Lv, Yuzhi Wu, Xianfei Li, Wenlong Liao, Tao He, Pai Peng)</author>
      <guid isPermaLink="false">2502.19698v2</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>DV-Matcher: Deformation-based Non-Rigid Point Cloud Matching Guided by Pre-trained Visual Features</title>
      <link>http://arxiv.org/abs/2408.08568v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 21 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DV-Matcher的创新学习框架，用于估计非刚性可变形点云之间的密集对应关系。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常需要对点云进行网格化或手动标注才能学习到有效的特征信息。相比之下，基于学习的方法可以直接从无结构化的点云中提取特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需额外预处理的框架，用于生成高质量的密集对应关系，并探索如何在几何特征学习过程中引入先验知识以及设计新的变形模块以促进外部对齐。&lt;h4&gt;方法&lt;/h4&gt;1. 通过将来自预训练视觉模型的知识注入到几何特征学习中，增强局部性质的几何特征与全局和语义信息；2. 提出了一种基于变形的模块来促进由所学对应关系诱导的外在对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示该方法在匹配非刚性点云时达到了最先进的水平，无论是在接近等距形状集合还是异构形状集合中，甚至是更具现实性的部分和噪声数据上都表现出色。&lt;h4&gt;结论&lt;/h4&gt;DV-Matcher框架通过结合视觉先验知识和创新的变形模块，在密集对应估计领域开辟了一条新的道路，并展示了其在处理复杂点云数据中的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种基于学习的框架DV-Matcher，用于非刚性可变形点云之间的密集对应的估算。该框架直接从无结构化点云中学习，无需网格化或手动标记，并且能够提供高质量的密集对应关系，在点云处理中有实际应用价值。我们的主要贡献在于两点：首先，我们提出了一种方案将预训练视觉模型中的先验知识注入到几何特征学习中，有效地补充了局部性质的几何特征与全局和语义信息；其次，我们提出了一个基于变形的新模块来促进由所学对应关系诱导的外在对齐，有效增强了特征学习。实验结果表明，在匹配非刚性点云时，无论是在接近等距形状集合还是异构形状集合中，甚至是更具现实性的部分和噪声数据上，我们的方法都达到了最先进的水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-08-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present DV-Matcher, a novel learning-based framework forestimating dense correspondences between non-rigidly deformable point clouds.Learning directly from unstructured point clouds without meshing or manuallabelling, our framework delivers high-quality dense correspondences, which isof significant practical utility in point cloud processing. Our keycontributions are two-fold: First, we propose a scheme to inject priorknowledge from pre-trained vision models into geometric feature learning, whicheffectively complements the local nature of geometric features with global andsemantic information; Second, we propose a novel deformation-based module topromote the extrinsic alignment induced by the learned correspondences, whicheffectively enhances the feature learning. Experimental results show that ourmethod achieves state-of-the-art results in matching non-rigid point clouds inboth near-isometric and heterogeneous shape collection as well as morerealistic partial and noisy data.</description>
      <author>example@mail.com (Zhangquan Chen, Puhua Jiang, Ruqi Huang)</author>
      <guid isPermaLink="false">2408.08568v2</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models -- A Panacea for Artificial Intelligence in Pathology?</title>
      <link>http://arxiv.org/abs/2502.21264v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  50 pages, 15 figures and an appendix (study protocol) which is  previously published, see https://doi.org/10.1101/2024.07.04.24309948;  updated authors list format&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文评估了基础模型（FMs）与任务特定（TS）模型在前列腺癌诊断和Gleason分级中的临床表现，发现尽管FMs在数据稀缺情况下有优势，但当有足够的标注训练数据时其性能被TS模型超越。此外，专门的任务培训显著降低了误诊率，并且考虑到可持续性问题，建议结合两种方法以实现稳健且资源高效的AI病理学解决方案。&lt;h4&gt;背景&lt;/h4&gt;人工智能（AI）在病理科的作用从辅助诊断发展到揭示全切片图像中的预测形态模式。基础模型通过自监督预训练被广泛倡导为多种下游任务的通用解决方案，但它们的临床适用性和相对于特定任务学习模型的优势仍存在疑问。&lt;h4&gt;目的&lt;/h4&gt;评估AI在前列腺癌诊断和Gleason分级中具有临床级性能的方法，并比较两个FMs与完全端到端TS模型的表现。&lt;h4&gt;方法&lt;/h4&gt;使用来自15个地点、11个国家的7342名患者超过10万个核心针活检样本进行了大规模验证。将两种基础模型在一个多实例学习框架中与一个完全端到端任务特定模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;尽管FMs在数据稀缺情况下有用，但当有足够的标记训练数据时其性能被TS模型超越或低于后者；任务特定培训显著减少了临床重要性的错误分级和形态挑战性情况下的误诊；基础模型消耗的能量最多可达TS模型的35倍，引发了关于可持续性的担忧。&lt;h4&gt;结论&lt;/h4&gt;FMs在快速原型设计和研究中提供了明显优势，但作为适用于临床应用的医疗AI通用解决方案的角色仍不确定。对于高风险临床应用而言，严格的验证以及对特定任务培训的考虑至关重要。建议结合基础模型和端到端学习的优点以实现稳健且资源高效的AI病理学解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了人工智能在前列腺癌诊断及格利森评分中的作用，并通过对比两种基于大规模预训练的基础模型与传统任务特异模型，揭示了关于这两种方法临床适用性的新见解。结果强调，在充足标记数据的情况下，任务特定的训练优于基础模型；同时指出，基础模型较高的能耗问题也应引起重视。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The role of artificial intelligence (AI) in pathology has evolved from aidingdiagnostics to uncovering predictive morphological patterns in whole slideimages (WSIs). Recently, foundation models (FMs) leveraging self-supervisedpre-training have been widely advocated as a universal solution for diversedownstream tasks. However, open questions remain about their clinicalapplicability and generalization advantages over end-to-end learning usingtask-specific (TS) models. Here, we focused on AI with clinical-gradeperformance for prostate cancer diagnosis and Gleason grading. We present thelargest validation of AI for this task, using over 100,000 core needle biopsiesfrom 7,342 patients across 15 sites in 11 countries. We compared two FMs with afully end-to-end TS model in a multiple instance learning framework. Ourfindings challenge assumptions that FMs universally outperform TS models. WhileFMs demonstrated utility in data-scarce scenarios, their performance convergedwith - and was in some cases surpassed by - TS models when sufficient labeledtraining data were available. Notably, extensive task-specific trainingmarkedly reduced clinically significant misgrading, misdiagnosis of challengingmorphologies, and variability across different WSI scanners. Additionally, FMsused up to 35 times more energy than the TS model, raising concerns about theirsustainability. Our results underscore that while FMs offer clear advantagesfor rapid prototyping and research, their role as a universal solution forclinically applicable medical AI remains uncertain. For high-stakes clinicalapplications, rigorous validation and consideration of task-specific trainingremain critically important. We advocate for integrating the strengths of FMsand end-to-end learning to achieve robust and resource-efficient AI pathologysolutions fit for clinical use.</description>
      <author>example@mail.com (Nita Mulliqi, Anders Blilie, Xiaoyi Ji, Kelvin Szolnoky, Henrik Olsson, Sol Erika Boman, Matteo Titus, Geraldine Martinez Gonzalez, Julia Anna Mielcarz, Masi Valkonen, Einar Gudlaugsson, Svein R. Kjosavik, José Asenjo, Marcello Gambacorta, Paolo Libretti, Marcin Braun, Radzislaw Kordek, Roman Łowicki, Kristina Hotakainen, Päivi Väre, Bodil Ginnerup Pedersen, Karina Dalsgaard Sørensen, Benedicte Parm Ulhøi, Pekka Ruusuvuori, Brett Delahunt, Hemamali Samaratunga, Toyonori Tsuzuki, Emilius A. M. Janssen, Lars Egevad, Martin Eklund, Kimmo Kartasalo)</author>
      <guid isPermaLink="false">2502.21264v2</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>Causality Is Key to Understand and Balance Multiple Goals in Trustworthy ML and Foundation Models</title>
      <link>http://arxiv.org/abs/2502.21123v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;确保机器学习系统的可信性至关重要，尤其是在其被嵌入到高风险领域时。&lt;h4&gt;背景&lt;/h4&gt;在机器学习系统变得越来越重要和广泛应用的同时，如何保证这些系统的公平性、隐私性、健壮性、准确性和可解释性成为了研究的重点。&lt;h4&gt;目的&lt;/h4&gt;该论文旨在通过引入因果方法来解决可信机器学习中的多重目标之间的矛盾，并提高其可靠性与解释性。&lt;h4&gt;方法&lt;/h4&gt;通过回顾现有文献中将因果方法应用于机器学习的成功案例，展示如何有效结合这些原则以达成平衡。&lt;h4&gt;主要发现&lt;/h4&gt;指出采用因果推理框架能够帮助更好地管理多个相互竞争的目标，在可信机器学习和基础模型设计方面提供解决方案。&lt;h4&gt;结论&lt;/h4&gt;论文讨论了采纳因果框架面临的挑战、局限性及机会，并倡导在未来的AI系统中使用更加负责任且道德的策略。&lt;h4&gt;翻译&lt;/h4&gt;确保机器学习系统的信任度至关重要，尤其是在它们被广泛应用于高风险领域时。本文提倡将因果方法融入到机器学习中来处理关键原则之间的权衡问题，如公平性、隐私性、鲁棒性、准确性及可解释性。尽管这些目标应理想地同时满足，但现实中往往单独考虑，导致冲突和次优解的产生。通过参考现有的因果推理在机器学习中的应用案例，本文强调了采用因果方法对于平衡多重竞争目标的重要性，并探讨如何实际将因果理论应用于机器学习模型中，以提升其可靠性和可解释性。此外，还讨论了采纳这种框架所面临的挑战、限制和机遇，为更负责任及伦理规范的AI系统开发铺平道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring trustworthiness in machine learning (ML) systems is crucial as theybecome increasingly embedded in high-stakes domains. This paper advocates forintegrating causal methods into machine learning to navigate the trade-offsamong key principles of trustworthy ML, including fairness, privacy,robustness, accuracy, and explainability. While these objectives should ideallybe satisfied simultaneously, they are often addressed in isolation, leading toconflicts and suboptimal solutions. Drawing on existing applications ofcausality in ML that successfully align goals such as fairness and accuracy orprivacy and robustness, this paper argues that a causal approach is essentialfor balancing multiple competing objectives in both trustworthy ML andfoundation models. Beyond highlighting these trade-offs, we examine howcausality can be practically integrated into ML and foundation models, offeringsolutions to enhance their reliability and interpretability. Finally, wediscuss the challenges, limitations, and opportunities in adopting causalframeworks, paving the way for more accountable and ethically sound AI systems.</description>
      <author>example@mail.com (Ruta Binkyte, Ivaxi Sheth, Zhijing Jin, Mohammad Havaei, Bernhard Schölkopf, Mario Fritz)</author>
      <guid isPermaLink="false">2502.21123v2</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>GraphBridge: Towards Arbitrary Transfer Learning in GNNs</title>
      <link>http://arxiv.org/abs/2502.19252v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures, 6 tables, to be published in ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为GraphBridge的框架，旨在解决图神经网络（GNN）在不同任务和数据集之间知识迁移的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的GNN训练方式是针对特定的任务或领域进行的，这导致了跨不同、异构的数据设置的知识转移存在障碍。&lt;h4&gt;目的&lt;/h4&gt;提出一种通用的方法来实现GNN中的跨域和跨任务的知识迁移。&lt;h4&gt;方法&lt;/h4&gt;GraphBridge通过增加预训练模型上的预测头以及输入层与输出层之间的桥梁网络，以保持原模型的固有知识并支持任意维度的输出。为了减少目标领域的源偏差问题，该框架将源模型合并到一个同时训练的目标模型中。&lt;h4&gt;主要发现&lt;/h4&gt;在图转图、节点转节点、图转节点以及图转点云等多种迁移学习场景下进行了广泛的实验验证，并通过16个具有代表性的数据集证明了其在任务和领域无关的图结构数据中的知识转移能力，标志着GNN领域的重大进展。&lt;h4&gt;结论&lt;/h4&gt;GraphBridge框架提供了一种有效的方法来解决跨不同任务和域的知识迁移问题，在多个场景中显示出优越的表现。源代码可在https://github.com/jujulili888/GraphBridge获得。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）通常针对特定领域或特定任务进行训练，这在将所获取知识转移到不同的、异构的数据设置时造成了障碍。本文介绍了GraphBridge框架，一种用于实现不同任务和域之间知识转移的新方法，无需对任务配置或图结构进行修改。具体而言，GraphBridge允许通过添加预测头和连接输入层到输出层的桥梁网络来增强任何预训练的GNN模型。此架构不仅保留了原始模型的内在知识，还支持任意维度的输出。为了解决负向迁移问题，GraphBridge将源模型与同时训练的目标模型合并在一起，在应用于目标领域时减少了源偏置。我们的方法在包括图转图、节点转节点、图转节点以及图转点云在内的多种迁移学习场景中进行了全面评估，并通过代表这些场景的16个数据集上的实验证明了该框架在任务和领域无关的图结构中的知识转移能力，标志着GNN领域的重大进展。代码可在https://github.com/jujulili888/GraphBridge获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are conventionally trained on a per-domain,per-task basis. It creates a significant barrier in transferring the acquiredknowledge to different, heterogeneous data setups. This paper introducesGraphBridge, a novel framework to enable knowledge transfer across disparatetasks and domains in GNNs, circumventing the need for modifications to taskconfigurations or graph structures. Specifically, GraphBridge allows for theaugmentation of any pre-trained GNN with prediction heads and a bridgingnetwork that connects the input to the output layer. This architecture not onlypreserves the intrinsic knowledge of the original model but also supportsoutputs of arbitrary dimensions. To mitigate the negative transfer problem,GraphBridge merges the source model with a concurrently trained model, therebyreducing the source bias when applied to the target domain. Our method isthoroughly evaluated across diverse transfer learning scenarios, includingGraph2Graph, Node2Node, Graph2Node, and graph2point-cloud. Empiricalvalidation, conducted over 16 datasets representative of these scenarios,confirms the framework's capacity for task- and domain-agnostic transferlearning within graph-like data, marking a significant advancement in the fieldof GNNs. Code is available at https://github.com/jujulili888/GraphBridge.</description>
      <author>example@mail.com (Li Ju, Xingyi Yang, Qi Li, Xinchao Wang)</author>
      <guid isPermaLink="false">2502.19252v2</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>QUAD-LLM-MLTC: Large Language Models Ensemble Learning for Healthcare Text Multi-Label Classification</title>
      <link>http://arxiv.org/abs/2502.14189v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;随着收集的医疗文本数据量的不断增加，自动化多标签文本分类（MLTC）面临独特挑战，主要是由于训练所需标记文本的稀缺性和其复杂性。传统机器学习模型通常无法完全捕捉到表达的主题范围。然而，大型语言模型（LLMs）在不同领域的多项自然语言处理任务中展示了显著的效果，这些模型具有出色的计算效率，并且通过提示工程能够适用于无监督学习。因此，这些LLM为医疗叙述的MLTC提供了有效的解决方案。然而，在面对各种标签时，不同的提示可能根据主题的相关性而变化。为了应对这一挑战，提出的QUAD-LLM-MLTC方法利用了四个大型语言模型的优势：GPT-4o、BERT、PEGASUS和BART。该方法在顺序流水线中操作，其中BERT提取关键令牌，PEGASUS增强文本数据，GPT-4o进行分类，而BART提供主题分配概率，从而产生四次0-shot设置的分类结果。这些输出通过集成学习组合，并通过元分类器处理以生成最终的MLTC结果。该方法使用三个标记文本样本进行了评估，与传统和单一模型的方法形成了对比。结果显示，在大多数主题上的F1评分及一致性（F1 和 Micro-F1 分数分别达到78.17% 和 80.16%，标准偏差分别为0.025 和 0.011）上有显著改进。&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的多标签文本分类方法，QUAD-LLM-MLTC，利用多个大型语言模型处理医疗数据的复杂性和多样性，并展示了其在F1评分和一致性上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;自动化多标签文本分类（MLTC）因医疗领域的大量未标记数据而面临挑战。传统机器学习模型难以应对这种复杂性。&lt;h4&gt;目的&lt;/h4&gt;探索使用大型语言模型进行高效的无监督学习，以解决大规模医疗文本的自动分类问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架QUAD-LLM-MLTC，该框架利用GPT-4o、BERT、PEGASUS和BART四个大型语言模型来进行零样本设置下的多标签文本分类，并通过集成学习和元分类器处理输出以得到最终结果。&lt;h4&gt;主要发现&lt;/h4&gt;与传统方法相比，使用QUAD-LLM-MLTC的方法在多个主题上显示出更高的F1评分及一致性。这种方法展示出强大的性能并可广泛应用于医疗数据的快速分类。&lt;h4&gt;结论&lt;/h4&gt;大型语言模型的应用为解决复杂文本的数据分类问题提供了创新性的解决方案，并通过集成不同模型的优势，在多标签医学文本分类中实现了高效和扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The escalating volume of collected healthcare textual data presents a uniquechallenge for automated Multi-Label Text Classification (MLTC), which isprimarily due to the scarcity of annotated texts for training and their nuancednature. Traditional machine learning models often fail to fully capture thearray of expressed topics. However, Large Language Models (LLMs) havedemonstrated remarkable effectiveness across numerous Natural LanguageProcessing (NLP) tasks in various domains, which show impressive computationalefficiency and suitability for unsupervised learning through promptengineering. Consequently, these LLMs promise an effective MLTC of medicalnarratives. However, when dealing with various labels, different prompts can berelevant depending on the topic. To address these challenges, the proposedapproach, QUAD-LLM-MLTC, leverages the strengths of four LLMs: GPT-4o, BERT,PEGASUS, and BART. QUAD-LLM-MLTC operates in a sequential pipeline in whichBERT extracts key tokens, PEGASUS augments textual data, GPT-4o classifies, andBART provides topics' assignment probabilities, which results in fourclassifications, all in a 0-shot setting. The outputs are then combined usingensemble learning and processed through a meta-classifier to produce the finalMLTC result. The approach is evaluated using three samples of annotated texts,which contrast it with traditional and single-model methods. The results showsignificant improvements across the majority of the topics in theclassification's F1 score and consistency (F1 and Micro-F1 scores of 78.17% and80.16% with standard deviations of 0.025 and 0.011, respectively). Thisresearch advances MLTC using LLMs and provides an efficient and scalablesolution to rapidly categorize healthcare-related text data without furthertraining.</description>
      <author>example@mail.com (Hajar Sakai, Sarah S. Lam)</author>
      <guid isPermaLink="false">2502.14189v2</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>Doracamom: Joint 3D Detection and Occupancy Prediction with Multi-view 4D Radars and Cameras for Omnidirectional Perception</title>
      <link>http://arxiv.org/abs/2501.15394v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Doracamom的框架，该框架融合了多视角相机和4D雷达的数据，用于实现3D物体检测和语义占用预测任务。通过引入新颖的Coarse Voxel Queries Generator、设计Dual-Branch Temporal Encoder以及Cross-Modal BEV-Voxel Fusion模块，使系统能够在复杂环境感知中表现出色。&lt;h4&gt;背景&lt;/h4&gt;3D目标检测和占位预测在自动驾驶领域非常重要，但现有基于视觉的方法在恶劣条件下效果不佳。整合相机与4D成像雷达可以实现多任务统一感知，但在这一领域的研究仍然有限。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够集成多视角相机和4D雷达的框架，用于完成3D物体检测和语义占用预测任务。&lt;h4&gt;方法&lt;/h4&gt;引入了Coarse Voxel Queries Generator来初始化查询体素；设计了Dual-Branch Temporal Encoder来利用时间信息，并实现了Cross-Modal BEV-Voxel Fusion模块以融合多模态特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，Doracamom在OmniHD-Scenes、View-of-Delft (VoD)和TJ4DRadSet数据集上均达到了当前最佳性能。&lt;h4&gt;结论&lt;/h4&gt;该框架通过结合多种传感器的数据实现了强大的3D感知能力，并为未来的多模态环境感知系统建立了新的基准。&lt;h4&gt;翻译&lt;/h4&gt;三维物体检测和占用预测在自动驾驶中至关重要，吸引了大量关注。尽管最近基于视觉的方法潜力巨大，但在恶劣条件下仍面临挑战。因此，将相机与下一代4D成像雷达相结合以实现统一的多任务感知非常重要，但该领域的研究仍然有限。本文提出了一种名为Doracamom的框架，它融合了多视角摄像头和4D雷达的数据，用于联合执行3D物体检测和语义占用预测，从而实现了全面的环境感知。特别是引入了一个新的粗体素查询生成器，该生成器将从4D雷达获得的几何先验知识与图像中的语义特征相结合来初始化体素查询，为后续基于Transformer的细化建立了坚实的基础。为了利用时间信息，设计了双分支时间编码器，在鸟瞰图和体素空间中并行处理多模态时序特性，从而能够进行全面的空间-时间表示学习。此外，还提出了一个跨模态BEV-Voxel融合模块，通过注意力机制自适应地融合互补特征，并利用辅助任务来提高特征质量。在OmniHD-Scenes、View-of-Delft (VoD)和TJ4DRadSet数据集上的广泛实验表明，Doracamom在这两项任务中均达到了当前最佳性能，为多模态3D感知建立了新的基准。代码和模型将公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D object detection and occupancy prediction are critical tasks in autonomousdriving, attracting significant attention. Despite the potential of recentvision-based methods, they encounter challenges under adverse conditions. Thus,integrating cameras with next-generation 4D imaging radar to achieve unifiedmulti-task perception is highly significant, though research in this domainremains limited. In this paper, we propose Doracamom, the first framework thatfuses multi-view cameras and 4D radar for joint 3D object detection andsemantic occupancy prediction, enabling comprehensive environmental perception.Specifically, we introduce a novel Coarse Voxel Queries Generator thatintegrates geometric priors from 4D radar with semantic features from images toinitialize voxel queries, establishing a robust foundation for subsequentTransformer-based refinement. To leverage temporal information, we design aDual-Branch Temporal Encoder that processes multi-modal temporal features inparallel across BEV and voxel spaces, enabling comprehensive spatio-temporalrepresentation learning. Furthermore, we propose a Cross-Modal BEV-Voxel Fusionmodule that adaptively fuses complementary features through attentionmechanisms while employing auxiliary tasks to enhance feature quality.Extensive experiments on the OmniHD-Scenes, View-of-Delft (VoD), and TJ4DRadSetdatasets demonstrate that Doracamom achieves state-of-the-art performance inboth tasks, establishing new benchmarks for multi-modal 3D perception. Code andmodels will be publicly available.</description>
      <author>example@mail.com (Lianqing Zheng, Jianan Liu, Runwei Guan, Long Yang, Shouyi Lu, Yuanzhe Li, Xiaokai Bai, Jie Bai, Zhixiong Ma, Hui-Liang Shen, Xichan Zhu)</author>
      <guid isPermaLink="false">2501.15394v2</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>HybridLinker: Topology-Guided Posterior Sampling for Enhanced Diversity and Validity in 3D Molecular Linker Generation</title>
      <link>http://arxiv.org/abs/2502.17349v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种名为HybridLinker的框架被提出，以解决药物设计中连接子生成问题中的多样性和有效性之间的权衡。&lt;h4&gt;背景&lt;/h4&gt;在药物发现应用（如候选物优化和PROTAC设计）中，分子片段组装成不同的药物候选物时链接器生成至关重要。目前的方法可以分为PC-Free和PC-Aware两类，前者基于它们是否使用3D点云(PC)。PC-Free模型更注重多样性，但因忽视了PC约束导致有效性和合法性较低；而PC-Aware模型通过强制执行严格的PC约束来确保更高的有效性和合法性，却限制了多样性。&lt;h4&gt;目的&lt;/h4&gt;为了在不增加额外训练的情况下克服上述权衡问题，提出了一种名为HybridLinker的框架。&lt;h4&gt;方法&lt;/h4&gt;该框架的核心是LinkerDPS（链接器后验扩散采样），它是一种新的扩散后验采样方法，在PC-Free和PC-Aware空间中操作。通过一种能量启发式的函数将分子拓扑结构与3D点云联系起来，从而允许从预训练的PC-Free模型中提供多样化的键合拓扑作为指导来增强PC-Aware推理。&lt;h4&gt;主要发现&lt;/h4&gt;HybridLinker框架在基础分子设计和应用属性优化任务中显著且一致地超过了基准方法，在提高有效性和多样性方面建立了新的扩散后验采样框架，该框架超越了图像领域，适用于分子和图域。&lt;h4&gt;结论&lt;/h4&gt;通过将PC-Free模型的多样化采样分布转移到PC-Aware分布上，HybridLinker在药物设计应用中的多样性和有效性之间找到了一个很好的平衡点。&lt;h4&gt;翻译&lt;/h4&gt;链接器生成是药物发现应用程序（如候选物优化和PROTAC设计）中的关键问题，其中分子片段被组装成不同的药物候选物。现有的方法根据它们是否使用3D点云(PC)分为PC-Free和PC-Aware两类。PC-Free模型优先考虑多样性但有效性和合法性较低；而PC-Aware模型通过强制执行严格的PC约束来确保更高的有效性和合法性，却限制了多样性。为了克服这些权衡问题且不需额外训练，我们提出了HybridLinker框架，该框架通过从预训练的PC-Free模型中提供多样化的键合拓扑作为指导来增强PC-Aware推理。在核心部分，我们提出了一种新的扩散后验采样方法LinkerDPS，在PC-Free和PC-Aware空间之间操作，并通过一种能量启发式的函数将分子拓扑与3D点云联系起来。HybridLinker框架能够将PC-Free模型的多样化采样分布转移至PC-Aware分布上，从而在基础分子设计和应用属性优化任务中显著且一致地超过了基准方法，在提高有效性和多样性方面建立了新的扩散后验采样框架，该框架超越了图像领域，适用于分子和图域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Linker generation is critical in drug discovery applications such as leadoptimization and PROTAC design, where molecular fragments are assembled intodiverse drug candidates. Existing methods fall into PC-Free and PC-Awarecategories based on their use of 3D point clouds (PC). PC-Free modelsprioritize diversity but suffer from lower validity due to overlooking PCconstraints, while PC-Aware models ensure higher validity but restrictdiversity by enforcing strict PC constraints. To overcome these trade-offswithout additional training, we propose HybridLinker, a framework that enhancesPC-Aware inference by providing diverse bonding topologies from a pretrainedPC-Free model as guidance. At its core, we propose LinkerDPS, the firstdiffusion posterior sampling (DPS) method operating across PC-Free and PC-Awarespaces, bridging molecular topology with 3D point clouds via an energy-inspiredfunction. By transferring the diverse sampling distribution of PC-Free modelsinto the PC-Aware distribution, HybridLinker significantly and consistentlysurpasses baselines, improving both validity and diversity in foundationalmolecular design and applied property optimization tasks, establishing a newDPS framework in the molecular and graph domains beyond imaging.</description>
      <author>example@mail.com (Minyeong Hwang, Ziseok Lee, Kwang-Soo Kim, Kyungsu Kim, Eunho Yang)</author>
      <guid isPermaLink="false">2502.17349v2</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction</title>
      <link>http://arxiv.org/abs/2502.21186v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR2025. Code would be available at  https://github.com/BaitingLuo/L-MAP.git&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的离线强化学习框架L-MAP，旨在通过学习一组时间扩展的宏观动作来解决高维连续动作空间中的顺序决策问题。&lt;h4&gt;背景&lt;/h4&gt;在具有随机动态的复杂环境中进行顺序决策时，尤其是在需要基于历史数据训练代理以做出决策的情况下，面临计算挑战。这些环境通常包含高维度的动作空间和不确定的状态转换。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决传统离线强化学习中遇到的问题，特别是如何有效地处理高维连续动作空间中的随机性问题。&lt;h4&gt;方法&lt;/h4&gt;L-MAP通过状态条件下的向量量化变分自动编码器(VQ-VAE)来减少行动维度，并使用蒙特卡洛树搜索(MCTS)算法在决策过程中考虑环境和行为策略的随机性。此外，还引入了一个独立学习到的先验模型作为潜在转换模型，以实现可能动作的有效采样。&lt;h4&gt;主要发现&lt;/h4&gt;L-MAP在离线强化学习设置中表现优异，在处理复杂和高维的动作空间时显示出低决策延迟，并且能够保持与基于模型的方法相匹配的表现。&lt;h4&gt;结论&lt;/h4&gt;L-MAP提供了一种有效解决具有高度不确定性和动作维度问题的策略规划方法，表明了这种方法在处理具有随机性环境中的顺序决策任务的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential decision-making in high-dimensional continuous action spaces,particularly in stochastic environments, faces significant computationalchallenges. We explore this challenge in the traditional offline RL setting,where an agent must learn how to make decisions based on data collected througha stochastic behavior policy. We present Latent Macro Action Planner (L-MAP),which addresses this challenge by learning a set of temporally extendedmacro-actions through a state-conditional Vector Quantized VariationalAutoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employsa (separate) learned prior model that acts as a latent transition model andallows efficient sampling of plausible actions. During planning, our approachaccounts for stochasticity in both the environment and the behavior policy byusing Monte Carlo tree search (MCTS). In offline RL settings, includingstochastic continuous control tasks, L-MAP efficiently searches over discretelatent actions to yield high expected returns. Empirical results demonstratethat L-MAP maintains low decision latency despite increased actiondimensionality. Notably, across tasks ranging from continuous control withinherently stochastic dynamics to high-dimensional robotic hand manipulation,L-MAP significantly outperforms existing model-based methods and performson-par with strong model-free actor-critic baselines, highlighting theeffectiveness of the proposed approach in planning in complex and stochasticenvironments with high-dimensional action spaces.</description>
      <author>example@mail.com (Baiting Luo, Ava Pettet, Aron Laszka, Abhishek Dubey, Ayan Mukhopadhyay)</author>
      <guid isPermaLink="false">2502.21186v2</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>GP-GS: Gaussian Processes for Enhanced Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2502.02283v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages,11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Gaussian Processes Gaussian Splatting (GP-GS)的3D重建框架，用于提高稀疏结构从运动(SfM)点云的场景重建质量。&lt;h4&gt;背景&lt;/h4&gt;3D高斯斑点方法是一种高效的逼真新视图合成方法，但其依赖于稀疏的SfM点云，导致了场景重建的质量问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种自适应和不确定性指导的稠密化框架来改进现有的3D重建效果。&lt;h4&gt;方法&lt;/h4&gt;引入了一种多输出高斯过程模型，并提出了一种动态采样与过滤管道，利用基于GP预测的新候选点从输入2D像素和深度图中生成密集点云。&lt;h4&gt;主要发现&lt;/h4&gt;该框架通过不确定性估计指导的稀疏SfM点云稠密化提高了3D重建质量，特别是在几何一致性和稠密性方面表现突出。&lt;h4&gt;结论&lt;/h4&gt;实验结果验证了GP-GS框架的有效性和实用性，在合成数据集和真实世界数据集中均表现出优越性能。&lt;h4&gt;翻译&lt;/h4&gt;3D高斯斑点方法作为一种高效的逼真新视图合成方法已经出现。然而，其依赖于稀疏的结构从运动（SfM）点云持续地影响了场景重建的质量。为了应对这些限制，本文提出了一种新的三维重建框架——高斯过程高斯斑点（GP-GS），其中开发了一个多输出的高斯过程模型来实现对稀疏SfM点云的自适应和不确定性指导的稠密化。具体来说，我们提出了一条动态采样和过滤流水线，它通过利用基于GP预测从输入2D像素和深度图中推断新的候选点来自适应地扩展了SfM点云，并且该流程利用不确定性估计来引导高方差预测的修剪工作，确保了几何一致性并使密集点云生成成为可能。这些稠密化的点云提供了高质量的初始3D高斯分布以增强重建性能。在各种规模上的合成和真实世界数据集上进行的一系列实验验证了所提出框架的有效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhihaohaoran/GPGS&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting has emerged as an efficient photorealistic novel viewsynthesis method. However, its reliance on sparse Structure-from-Motion (SfM)point clouds consistently compromises the scene reconstruction quality. Toaddress these limitations, this paper proposes a novel 3D reconstructionframework Gaussian Processes Gaussian Splatting (GP-GS), where a multi-outputGaussian Process model is developed to achieve adaptive and uncertainty-guideddensification of sparse SfM point clouds. Specifically, we propose a dynamicsampling and filtering pipeline that adaptively expands the SfM point clouds byleveraging GP-based predictions to infer new candidate points from the input 2Dpixels and depth maps. The pipeline utilizes uncertainty estimates to guide thepruning of high-variance predictions, ensuring geometric consistency andenabling the generation of dense point clouds. The densified point cloudsprovide high-quality initial 3D Gaussians to enhance reconstructionperformance. Extensive experiments conducted on synthetic and real-worlddatasets across various scales validate the effectiveness and practicality ofthe proposed framework.</description>
      <author>example@mail.com (Zhihao Guo, Jingxuan Su, Shenglin Wang, Jinlong Fan, Jing Zhang, Liangxiu Han, Peng Wang)</author>
      <guid isPermaLink="false">2502.02283v3</guid>
      <pubDate>Tue, 04 Mar 2025 15:00:15 +0800</pubDate>
    </item>
    <item>
      <title>A Fused Gromov-Wasserstein Approach to Subgraph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.20885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;本文介绍了一种新的自监督图表示学习方法——FOSSIL，用于解决现有对比学习方法在利用结构模式和节点相似性方面的不足。&lt;h4&gt;背景&lt;/h4&gt;自我监督学习已成为处理标注数据稀缺或不可用情况的关键方法。然而，在设计有效的预训练任务以进行自监督图表示学习方面仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合了节点级与子图级对比学习的新方法，旨在更有效地利用图形的结构模式和节点相似性。&lt;h4&gt;方法&lt;/h4&gt;FOSSIL模型通过将标准的节点级别对比损失函数与融合Gromov-Wasserstein距离相结合，可以同时捕捉节点特征和图结构。此外，该方法适用于同构及异构图，并能动态创建视角以生成正负样本对。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在基准图数据集上的测试中，FOSSIL优于或达到了目前最先进的方法的性能水平。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地改善现有的自监督图表示学习技术，尤其在利用复杂结构模式和节点相似性方面有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;自我监督学习已成为训练深度学习模型的重要手段，尤其是在标注数据稀缺的情况下。尽管图机器学习在各个领域都有巨大的潜力，但设计有效的预训练任务以进行自监督图表示学习仍然具有挑战性。对比学习是图的自我监督学习的一种流行方法，它利用正负对来计算对比损失函数。然而，目前的图对比学习方法往往难以充分使用结构模式和节点相似性。为了解决这些问题，我们提出了一种名为Fused Gromov Wasserstein Subgraph Contrastive Learning（FOSSIL）的新方法。我们的模型集成了节点级和子图级别的对比学习，无缝结合了标准的节点级别对比损失函数与融合Gromov-Wasserstein距离。这种组合使我们的方法能够同时捕捉节点特征和图形结构。重要的是，该方法既适用于同构图也适用于异构图，并能动态创建视角以生成正负样本对。通过在基准图数据集上的广泛实验，我们证明FOSSIL比或与当前最先进的方法性能相当。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has become a key method for training deep learningmodels when labeled data is scarce or unavailable. While graph machine learningholds great promise across various domains, the design of effective pretexttasks for self-supervised graph representation learning remains challenging.Contrastive learning, a popular approach in graph self-supervised learning,leverages positive and negative pairs to compute a contrastive loss function.However, current graph contrastive learning methods often struggle to fully usestructural patterns and node similarities. To address these issues, we presenta new method called Fused Gromov Wasserstein Subgraph Contrastive Learning(FOSSIL). Our model integrates node-level and subgraph-level contrastivelearning, seamlessly combining a standard node-level contrastive loss with theFused Gromov-Wasserstein distance. This combination helps our method captureboth node features and graph structure together. Importantly, our approachworks well with both homophilic and heterophilic graphs and can dynamicallycreate views for generating positive and negative pairs. Through extensiveexperiments on benchmark graph datasets, we show that FOSSIL outperforms orachieves competitive performance compared to current state-of-the-art methods.</description>
      <author>example@mail.com (Amadou S. Sangare, Nicolas Dunou, Jhony H. Giraldo, Fragkiskos D. Malliaros)</author>
      <guid isPermaLink="false">2502.20885v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
  <item>
      <title>Assessing zero-shot generalisation behaviour in graph-neural-network interatomic potentials</title>
      <link>http://arxiv.org/abs/2502.21317v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了机器学习原子间势能模型（MLIP）在材料化学和分子化学之间的迁移能力。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习原子间势能模型的广泛应用，如何设计适用于多种应用领域的基础性MLIP成为了当前的研究重点。&lt;h4&gt;目的&lt;/h4&gt;评估一种特定于石墨烯氧化物扩展共价网络设计的MLIP（GO-MACE-23）在处理小型独立分子和化学反应时的表现。&lt;h4&gt;方法&lt;/h4&gt;通过将该模型与专门为某一领域训练的状态-of-the-art模型进行直接比较，来量化其零样本学习性能。&lt;h4&gt;主要发现&lt;/h4&gt;提供了图神经网络势能的迁移能力和泛化能力的定量见解。&lt;h4&gt;结论&lt;/h4&gt;这项工作促进了MLIP在化学中的更广泛应用，并为进一步研究这类模型如何在不同领域的应用中发挥作用奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;随着机器学习原子间势能（MLIP）模型在化学领域迅速可用性的增长，当前许多研究集中在开发通用且“基础性”的MLIP上。在这个背景下，一个重要的问题是这些模型是否以及在多大程度上可以在不同的应用场景之间转移。在这里，我们评估了一种MLIP模型在材料和分子化学之间的迁移能力。具体来说，我们研究了GO-MACE-23模型，该模型旨在用于石墨烯氧化物的扩展共价网络，并量化了它对小型独立分子和在其直接作用范围之外的化学反应的零样本性能——与专门为某一领域训练的状态-of-the-art模型进行直接比较。我们的工作为图神经网络势能的迁移和泛化能力提供了定量见解，更广泛地说，朝着MLIP在化学中的更广泛应用迈进了一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapidly growing availability of machine-learned interatomicpotential (MLIP) models for chemistry, much current research focuses on thedevelopment of generally applicable and ``foundational'' MLIPs. An importantquestion in this context is whether, and how well, such models can transferfrom one application domain to another. Here, we assess this transferabilityfor an MLIP model at the interface of materials and molecular chemistry.Specifically, we study GO-MACE-23, a model designed for the extended covalentnetwork of graphene oxide, and quantify its zero-shot performance for small,isolated molecules and chemical reactions outside its direct scope--in directcomparison with a state-of-the-art model which has been trained in-domain. Ourwork provides quantitative insight into the transfer and generalisation abilityof graph-neural-network potentials and, more generally, makes a step towardsthe more widespread applicability of MLIPs in chemistry.</description>
      <author>example@mail.com (Chiheb Ben Mahmoud, Zakariya El-Machachi, Krystian A. Gierczak, John L. A. Gardner, Volker L. Deringer)</author>
      <guid isPermaLink="false">2502.21317v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>RuCCoD: Towards Automated ICD Coding in Russian</title>
      <link>http://arxiv.org/abs/2502.21263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本研究探讨了在俄语等生物医学资源有限的语言环境中实现临床编码自动化的可行性。&lt;h4&gt;背景&lt;/h4&gt;当前，许多语言的生物医学资源较为匮乏，特别是在俄语中。这限制了相关领域的自动化进程，如临床编码。&lt;h4&gt;目的&lt;/h4&gt;通过创建新的ICD（国际疾病分类）编码数据集来研究在俄语等资源有限的语言环境中自动进行临床编码的可能性。&lt;h4&gt;方法&lt;/h4&gt;{'数据准备': '构建了一个包含来自电子健康记录（EHRs）的诊断字段的数据集，该数据集包括超过10,000个实体和超过1,500种独特的ICD代码。', '模型测试': '利用这个数据集作为基准，测试了几种最先进的模型，如BERT、LLaMA与LoRA结合使用以及RAG。进行了额外的跨域迁移学习实验（从PubMed摘要到医学诊断）以及术语转换实验（从UMLS概念到ICD编码）。', '应用': '将性能最佳的模型应用于公司内部EHR数据集，该数据集中包含了2017年至2021年的患者历史记录。'}&lt;h4&gt;主要发现&lt;/h4&gt;利用自动化预测代码进行训练后，与医生手动注释的数据相比，在精心准备的测试集上显示出显著提高的准确性。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，在资源有限的语言环境中实现临床编码自动化的潜力巨大，这可以提升这些语境下的医疗效率和数据准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study investigates the feasibility of automating clinical coding inRussian, a language with limited biomedical resources. We present a new datasetfor ICD coding, which includes diagnosis fields from electronic health records(EHRs) annotated with over 10,000 entities and more than 1,500 unique ICDcodes. This dataset serves as a benchmark for several state-of-the-art models,including BERT, LLaMA with LoRA, and RAG, with additional experiments examiningtransfer learning across domains (from PubMed abstracts to medical diagnosis)and terminologies (from UMLS concepts to ICD codes). We then apply thebest-performing model to label an in-house EHR dataset containing patienthistories from 2017 to 2021. Our experiments, conducted on a carefully curatedtest set, demonstrate that training with the automated predicted codes leads toa significant improvement in accuracy compared to manually annotated data fromphysicians. We believe our findings offer valuable insights into the potentialfor automating clinical coding in resource-limited languages like Russian,which could enhance clinical efficiency and data accuracy in these contexts.</description>
      <author>example@mail.com (Aleksandr Nesterov, Andrey Sakhovskiy, Ivan Sviridov, Airat Valiev, Vladimir Makharev, Petr Anokhin, Galina Zubkova, Elena Tutubalina)</author>
      <guid isPermaLink="false">2502.21263v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Parameter Efficient Source-free Post-pretraining</title>
      <link>http://arxiv.org/abs/2502.21313v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种新的无监督参数高效源无关后预训练方法UpStep，用于在没有源领域数据的情况下将预先训练的模型适应到目标领域。&lt;h4&gt;背景&lt;/h4&gt;随着NLP领域的成功，最佳视觉模型现在达到数十亿参数规模。由于计算和经济原因，在目标分布上调整这些大规模模型变得不可行。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来解决在没有源领域数据的情况下将预先训练的模型适应到新目标领域的问题。&lt;h4&gt;方法&lt;/h4&gt;{'i': '设计了一个自我监督的训练方案，可以在没有任何来源数据的情况下对未标记的目标域进行预训练模型调整。', 'ii': '提出了中心向量正则化（CVR），这是一组辅助操作，最小化灾难性遗忘，并通过在50%的训练迭代中跳过反向传播来降低计算成本。', 'iii': '采用低秩适应方法以参数高效的方式进行模型调整。'}&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法能够在各种基础架构上（包括监督和非监督训练于Imagenet上的）展示出良好的适应性和泛化能力，将其应用于八个不同的目标领域。&lt;h4&gt;结论&lt;/h4&gt;通过UpStep方法可以有效地在没有源领域数据的情况下将大规模预训练模型调整到新任务中，从而克服了计算成本的限制。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着NLP领域的成功，最佳视觉模型现在达到数十亿参数规模。由于计算和经济原因，在目标分布上调整这些大规模模型变得不可行。为了解决这个问题，我们介绍了一种新的无监督参数高效源无关后预训练方法UpStep，用于在没有源领域数据的情况下将预先训练的模型适应到目标领域：i) 设计了一个自我监督的训练方案，可以在没有任何来源数据的情况下对未标记的目标域进行预训练模型调整。由于这种源无关设置存在灾难性遗忘的风险，ii) 提出了中心向量正则化（CVR），这是一组辅助操作，最小化灾难性遗忘，并通过在50%的训练迭代中跳过反向传播来降低计算成本。最后iii) 采用低秩适应方法以参数高效的方式进行模型调整。我们利用各种一般骨干架构作为基础模型并将其适配到八个不同的目标领域中，展示了我们的方法具有良好的适用性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Following the success in NLP, the best vision models are now in the billionparameter ranges. Adapting these large models to a target distribution hasbecome computationally and economically prohibitive. Addressing this challenge,we introduce UpStep, an Unsupervised Parameter-efficient Source-freepost-pretraining approach, designed to efficiently adapt a base model from asource domain to a target domain: i) we design a self-supervised trainingscheme to adapt a pretrained model on an unlabeled target domain in a settingwhere source domain data is unavailable. Such source-free setting comes withthe risk of catastrophic forgetting, hence, ii) we propose center vectorregularization (CVR), a set of auxiliary operations that minimize catastrophicforgetting and additionally reduces the computational cost by skippingbackpropagation in 50\% of the training iterations. Finally iii) we performthis adaptation process in a parameter-efficient way by adapting the pretrainedmodel through low-rank adaptation methods, resulting in a fraction ofparameters to optimize. We utilize various general backbone architectures, bothsupervised and unsupervised, trained on Imagenet as our base model and adaptthem to a diverse set of eight target domains demonstrating the adaptabilityand generalizability of our proposed approach.</description>
      <author>example@mail.com (Abhishek Jha, Tinne Tuytelaars, Yuki M. Asano)</author>
      <guid isPermaLink="false">2502.21313v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Fast 3D point clouds retrieval for Large-scale 3D Place Recognition</title>
      <link>http://arxiv.org/abs/2502.21067v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 1 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于Transformer的加速3D点云检索的方法，通过生成一维标识符实现恒定时间内的直接检索。&lt;h4&gt;背景&lt;/h4&gt;在3D点云中寻找最相似的点云是一项具有挑战性的任务。当前方法主要集中在比较描述符以识别相似性，但这个步骤复杂且耗时。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Differentiable Search Index (DSI)的方法来加速3D点云检索过程。&lt;h4&gt;方法&lt;/h4&gt;通过集成视觉Transformer将点云描述符映射到一维标识符，并结合位置和语义编码以适应三维数据。这种方法使得可以直接根据生成的标识符进行恒定时间内的检索。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在公开基准测试中的检索质量和速度方面都优于现有最先进的技术。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为3D点云检索提供了一种高效且准确的新方案。&lt;h4&gt;翻译&lt;/h4&gt;三维点云的检索是一项具有挑战性的任务，旨在从参考点集中检索与给定查询最相似的点云。当前方法集中在通过比较描述符来识别相似性上。由于这一步骤复杂，我们专注于使用可微搜索索引(DSI)，一种最初为文本信息检索设计的基于Transformer的方法，来加速三维点云检索过程。我们的方法生成了一维标识符，该标识符基于点描述符，并使得可以直接在恒定时间内进行检索。为了将DSI适应于3D数据，我们整合了视觉变换器以将描述符映射到这些标识符，同时结合位置和语义编码。我们在公共基准测试的地点识别上评估了此方法，通过与现有最先进的方法比较其点云检索能力和返回的速度及质量来衡量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieval in 3D point clouds is a challenging task that consists inretrieving the most similar point clouds to a given query within a reference of3D points. Current methods focus on comparing descriptors of point clouds inorder to identify similar ones. Due to the complexity of this latter step, herewe focus on the acceleration of the retrieval by adapting the DifferentiableSearch Index (DSI), a transformer-based approach initially designed for textinformation retrieval, for 3D point clouds retrieval. Our approach generates 1Didentifiers based on the point descriptors, enabling direct retrieval inconstant time. To adapt DSI to 3D data, we integrate Vision Transformers to mapdescriptors to these identifiers while incorporating positional and semanticencoding. The approach is evaluated for place recognition on a public benchmarkcomparing its retrieval capabilities against state-of-the-art methods, in termsof quality and speed of returned point clouds.</description>
      <author>example@mail.com (Chahine-Nicolas Zede, Laurent Carrafa, Valérie Gouet-Brunet)</author>
      <guid isPermaLink="false">2502.21067v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>LV-DOT: LiDAR-visual dynamic obstacle detection and tracking for autonomous robot navigation</title>
      <link>http://arxiv.org/abs/2502.20607v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;室内自主机器人导航中的动态障碍物感知对于精确导航至关重要。&lt;h4&gt;背景&lt;/h4&gt;尽管在计算机视觉和自动驾驶领域对3D物体检测和跟踪方法进行了深入研究和发展，但这些方法需要昂贵且高精度的传感器设置以及大型神经网络计算资源，使其不适合用于室内机器人。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于车载相机和LiDAR数据的动态障碍物检测与跟踪框架，以实现轻量级且精确的感知。&lt;h4&gt;方法&lt;/h4&gt;{'融合策略': '采用更稳健的数据融合策略，结合了LiDAR和视觉信息，提高了检测精度。使用特征关联和卡尔曼滤波器进行目标追踪，并设计了一种动态障碍物分类算法来可靠地识别移动物体。', '集成检测方法': '基于先前的集合检测方法，该方法整合来自多个低准确度但计算效率高的探测器的结果，以确保在车载计算机上实现实时性能。'}&lt;h4&gt;主要发现&lt;/h4&gt;数据集评估显示，与基准方法相比，所提出的方法具有更好的感知性能；物理实验也证实了这种方法在实际导航中的可行性。&lt;h4&gt;结论&lt;/h4&gt;该研究成功地解决了单一传感器的限制问题，并通过结合LiDAR和视觉信息实现了更加精确且实时的动态障碍物检测与跟踪。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate perception of dynamic obstacles is essential for autonomous robotnavigation in indoor environments. Although sophisticated 3D object detectionand tracking methods have been investigated and developed thoroughly in thefields of computer vision and autonomous driving, their demands on expensiveand high-accuracy sensor setups and substantial computational resources fromlarge neural networks make them unsuitable for indoor robotics. Recently, morelightweight perception algorithms leveraging onboard cameras or LiDAR sensorshave emerged as promising alternatives. However, relying on a single sensorposes significant limitations: cameras have limited fields of view and cansuffer from high noise, whereas LiDAR sensors operate at lower frequencies andlack the richness of visual features. To address this limitation, we propose adynamic obstacle detection and tracking framework that uses both onboard cameraand LiDAR data to enable lightweight and accurate perception. Our proposedmethod expands on our previous ensemble detection approach, which integratesoutputs from multiple low-accuracy but computationally efficient detectors toensure real-time performance on the onboard computer. In this work, we proposea more robust fusion strategy that integrates both LiDAR and visual data toenhance detection accuracy further. We then utilize a tracking module thatadopts feature-based object association and the Kalman filter to track andestimate detected obstacles' states. Besides, a dynamic obstacle classificationalgorithm is designed to robustly identify moving objects. The datasetevaluation demonstrates a better perception performance compared to benchmarkmethods. The physical experiments on a quadcopter robot confirms thefeasibility for real-world navigation.</description>
      <author>example@mail.com (Zhefan Xu, Haoyu Shen, Xinming Han, Hanyu Jin, Kanlong Ye, Kenji Shimada)</author>
      <guid isPermaLink="false">2502.20607v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models for Multilingual Multimodal Idiomaticity Representation</title>
      <link>http://arxiv.org/abs/2502.20984v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;SemEval-2025 Task 1旨在根据给定的名词短语在英语和巴西葡萄牙语中可能携带的习惯用法意义对图像进行排名。&lt;h4&gt;背景&lt;/h4&gt;该任务涉及使用生成式大型语言模型（LLMs）和多语言CLIP模型来增强惯用表达的意义表示，以解决基于具有惯用含义的名词短语给图片打分的问题。&lt;h4&gt;目的&lt;/h4&gt;为了提高图片排序的效果，本文提出了一种方法结合使用LLM和多语言CLIP模型，并应用对比学习和数据增强技术对生成的嵌入进行微调。&lt;h4&gt;方法&lt;/h4&gt;大型语言模型用于生成潜在惯用表达的意义，而这些意义随后被编码为图像排名中的表示。然后通过对比学习和技术手段调整后的数据增强来精炼这些嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，通过这种方法提取的多模态表示优于仅基于原始名词短语的方法。然而，微调方法虽然显示出有前景的结果，但不如使用未经微调的嵌入有效。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一个利用大型语言模型和CLIP技术改进惯用表达图像排名的新方案，并通过实验验证了其有效性，尽管还存在进一步优化的空间。&lt;h4&gt;翻译&lt;/h4&gt;SemEval-2025 Task 1专注于根据具有潜在习惯意义的名词短语对图片进行排序。为了解决这个问题，这项工作利用生成式大型语言模型（LLMs）和多语言CLIP模型来增强惯用表达的意义表示。通过这种方式，研究者们在提高图像排名精度方面取得了显著进展，并且他们的源代码可在GitHub上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; SemEval-2025 Task 1 focuses on ranking images based on their alignment with agiven nominal compound that may carry idiomatic meaning in both English andBrazilian Portuguese. To address this challenge, this work uses generativelarge language models (LLMs) and multilingual CLIP models to enhance idiomaticcompound representations. LLMs generate idiomatic meanings for potentiallyidiomatic compounds, enriching their semantic interpretation. These meaningsare then encoded using multilingual CLIP models, serving as representations forimage ranking. Contrastive learning and data augmentation techniques areapplied to fine-tune these embeddings for improved performance. Experimentalresults show that multimodal representations extracted through this methodoutperformed those based solely on the original nominal compounds. Thefine-tuning approach shows promising outcomes but is less effective than usingembeddings without fine-tuning. The source code used in this paper is availableat https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL.</description>
      <author>example@mail.com (Thanet Markchom, Tong Wu, Liting Huang, Huizhi Liang)</author>
      <guid isPermaLink="false">2502.20984v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>JiTTER: Jigsaw Temporal Transformer for Event Reconstruction for Self-Supervised Sound Event Detection</title>
      <link>http://arxiv.org/abs/2502.20857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了JiTTER，一种改进的自监督学习框架，用于提高基于变压器的声音事件检测模型在时间建模方面的性能。&lt;h4&gt;背景&lt;/h4&gt;自我监督学习方法特别是MAT-SED在声音事件检测（SED）中取得了显著效果。然而，这种技术在捕捉瞬态音频事件和保持时间顺序方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督框架JiTTER，以增强基于变压器的声音事件检测模型的时间建模能力。&lt;h4&gt;方法&lt;/h4&gt;JiTTER引入了一种分层的随机时间重排重建策略，在块级和帧级随机打乱音频序列，强迫模型重建正确的时序。同时通过在块级重排过程中注入噪声进一步提升特征学习的正则化效果和模型鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明JiTTER相比MAT-SED提升了5.89%的PSDS值，在DESED数据集上表现出更优性能，说明结构化的时序重建任务比简单的掩码预测更有助于自监督学习在声音事件表示学习中的表现。&lt;h4&gt;结论&lt;/h4&gt;研究发现证明了有结构的时间重建任务对于基于自监督学习的声音事件检测模型来说是一种更为有效的预训练范式。&lt;h4&gt;翻译&lt;/h4&gt;声音事件检测（SED）已从自我监督学习（SSL）方法中显著受益，特别是MAT-SED，该方法利用掩码块预测来恢复丢失的音频片段。然而，尽管在捕捉全局依赖性方面有效，掩码块预测却破坏了瞬态声学事件并且缺乏对时间顺序的明确约束，使其不太适合用于精细粒度的事件边界检测。为了克服这些限制，我们提出了JiTTER（拼图时序变压器事件重建），这是一种增强基于变压器的声音事件检测的时间建模能力的SSL框架。JiTTER引入了一种层次化的随机时间重排重构策略，其中音频序列在块级和帧级上随机打乱，强迫模型恢复正确的顺序。这种预训练目标鼓励模型学习全局事件结构以及瞬态细节，从而提高其识别具有锐利起止特征的声音事件的能力。此外，在块重组过程中我们注入噪声，提供了一种细微的扰动机制以进一步正则化特征学习并增强模型鲁棒性。DESED数据集上的实验结果表明JiTTER优于MAT-SED，PSDS值提高了5.89%，这突出了显式时间推理在基于SSL的声音事件检测中的有效性。我们的研究结果表明结构化的时序重建任务比简单的掩码预测更适合声音事件表示学习的自监督预训练范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sound event detection (SED) has significantly benefited from self-supervisedlearning (SSL) approaches, particularly masked audio transformer for SED(MAT-SED), which leverages masked block prediction to reconstruct missing audiosegments. However, while effective in capturing global dependencies, maskedblock prediction disrupts transient sound events and lacks explicit enforcementof temporal order, making it less suitable for fine-grained event boundarydetection. To address these limitations, we propose JiTTER (Jigsaw TemporalTransformer for Event Reconstruction), an SSL framework designed to enhancetemporal modeling in transformer-based SED. JiTTER introduces a hierarchicaltemporal shuffle reconstruction strategy, where audio sequences are randomlyshuffled at both the block-level and frame-level, forcing the model toreconstruct the correct temporal order. This pretraining objective encouragesthe model to learn both global event structures and fine-grained transientdetails, improving its ability to detect events with sharp onset-offsetcharacteristics. Additionally, we incorporate noise injection during blockshuffle, providing a subtle perturbation mechanism that further regularizesfeature learning and enhances model robustness. Experimental results on theDESED dataset demonstrate that JiTTER outperforms MAT-SED, achieving a 5.89%improvement in PSDS, highlighting the effectiveness of explicit temporalreasoning in SSL-based SED. Our findings suggest that structured temporalreconstruction tasks, rather than simple masked prediction, offer a moreeffective pretraining paradigm for sound event representation learning.</description>
      <author>example@mail.com (Hyeonuk Nam, Yong-Hwa Park)</author>
      <guid isPermaLink="false">2502.20857v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>AMPLE: Event-Driven Accelerator for Mixed-Precision Inference of Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.21196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为AMPLE的FPGA加速器，用于改进图神经网络（GNN）在非欧几里得数据上的表现。&lt;h4&gt;背景&lt;/h4&gt;最近，由于其处理非欧几里得数据的性能，图神经网络受到了广泛关注。这些网络因其不规则的记忆访问模式而特别受益于自定义硬件架构，这种模式源于图形结构的稀疏性。&lt;h4&gt;目的&lt;/h4&gt;解决现有FPGA加速器中双缓冲机制的问题，并针对典型图形数据集中节点分布不规则的情况提出解决方案。&lt;h4&gt;方法&lt;/h4&gt;采用事件驱动编程流程的新AMPLE FPGA加速器。开发了混合算术架构，使GNN推理可以以节点级别进行量化。实现了用于优化片外内存访问和最大化节点并行性的预取器。&lt;h4&gt;主要发现&lt;/h4&gt;在引用和社交媒体图数据集上进行了评估，结果表明，在与CPU和GPU对应方相比，平均速度分别提高了243倍和7.2倍。&lt;h4&gt;结论&lt;/h4&gt;采用事件驱动编程流程的AMPLE FPGA加速器显著提升了GNN推理的速度。该方法通过利用混合算术架构、节点级量化以及片外内存访问优化来解决现有FPGA加速器中存在的问题，并在大量图数据集上展示了优秀的性能改进。&lt;h4&gt;翻译&lt;/h4&gt;最近，由于其处理非欧几里得数据的出色表现，图神经网络（GNNs）引起了广泛的关注。这些网络得益于它们不规则的记忆访问模式，这源于图形结构的稀疏性，因此，对定制硬件架构特别有利。然而，现有的FPGA加速器受到双缓冲机制的限制，这种机制未能考虑典型图数据集中的节点分布不规则问题。为了应对这一挑战，我们提出了AMPLE（加速消息传递逻辑引擎），这是一个利用新的事件驱动编程流的新FPGA加速器。我们开发了一种混合算术架构，使GNN推理能够在节点级别进行量化。此外，还实现了用于优化片外内存访问和最大化节点并行性的预取器。在引用和社交媒体图数据集上进行了评估，这些数据集的节点数量从2K到700K不等，结果表明，在与CPU和GPU对应方相比时，平均速度分别提高了243倍和7.2倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have recently gained attention due to theirperformance on non-Euclidean data. The use of custom hardware architecturesproves particularly beneficial for GNNs due to their irregular memory accesspatterns, resulting from the sparse structure of graphs. However, existing FPGAaccelerators are limited by their double buffering mechanism, which doesn'taccount for the irregular node distribution in typical graph datasets. Toaddress this, we introduce \textbf{AMPLE} (Accelerated Message Passing LogicEngine), an FPGA accelerator leveraging a new event-driven programming flow. Wedevelop a mixed-arithmetic architecture, enabling GNN inference to be quantizedat a node-level granularity. Finally, prefetcher for data and instructions isimplemented to optimize off-chip memory access and maximize node parallelism.Evaluation on citation and social media graph datasets ranging from $2$K to$700$K nodes showed a mean speedup of $243\times$ and $7.2\times$ against CPUand GPU counterparts, respectively.</description>
      <author>example@mail.com (Pedro Gimenes, Yiren Zhao, George Constantinides)</author>
      <guid isPermaLink="false">2502.21196v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Incorporating Long-Range Interactions via the Multipole Expansion into Ground and Excited-State Molecular Simulations</title>
      <link>http://arxiv.org/abs/2502.21045v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了FieldMACE，这是基于消息传递原子簇扩展（MACE）架构的一种改进版本，通过引入多极展开来更高效地模拟长程相互作用。&lt;h4&gt;背景&lt;/h4&gt;在分子机器学习势能中，准确捕捉大空间区域内的相互作用是一个重要挑战。&lt;h4&gt;目的&lt;/h4&gt;为了提高对环境和远距离效应的建模效率，特别是在基态和激发态下，本文提出了一种新的架构FieldMACE。&lt;h4&gt;方法&lt;/h4&gt;通过将多极展开集成到MACE架构中，形成一种新框架，称为FieldMACE。&lt;h4&gt;主要发现&lt;/h4&gt;基准评估显示FieldMACE在预测精度、计算效率方面优于先前的架构，并且能够准确模拟非绝热激发态动力学。&lt;h4&gt;结论&lt;/h4&gt;从基础模型中的迁移学习进一步提高了数据利用效率，使FieldMACE成为大规模分子模拟中可扩展、稳健和可转移的框架。&lt;h4&gt;翻译&lt;/h4&gt;模拟长程相互作用一直是分子机器学习势能的重要挑战。本文介绍了一种新的架构FieldMACE，它通过将多极展开整合到消息传递原子簇扩展（MACE）架构中来更高效地建模长程相互作用。FieldMACE能够有效捕捉环境和远距离效应，特别是在基态和激发态下。基准评估表明，与之前的架构相比，FieldMACE在预测准确性、计算效率方面具有优势，并且能准确模拟非绝热激发态动力学。此外，从基础模型中的迁移学习进一步提高了数据利用效率，使得FieldMACE成为一个可扩展的、稳健的以及可转移的大规模分子模拟框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulating long-range interactions remains a significant challenge formolecular machine learning potentials due to the need to accurately captureinteractions over large spatial regions. In this work, we introduce FieldMACE,an extension of the message-passing atomic cluster expansion (MACE)architecture that integrates the multipole expansion to model long-rangeinteractions more efficiently. By incorporating the multipole expansion,FieldMACE effectively captures environmental and long-range effects in bothground and excited states. Benchmark evaluations demonstrate its superiorperformance in predictions and computational efficiency compared to previousarchitectures, as well as its ability to accurately simulate nonadiabaticexcited-state dynamics. Furthermore, transfer learning from foundational modelsenhances data efficiency, making FieldMACE a scalable, robust, and transferableframework for large-scale molecular simulations.</description>
      <author>example@mail.com (Rhyan Barrett, Johannes C. B. Dietschreit, Julia Westermayr)</author>
      <guid isPermaLink="false">2502.21045v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>MESC-3D:Mining Effective Semantic Cues for 3D Reconstruction from a Single Image</title>
      <link>http://arxiv.org/abs/2502.20861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了MESC-3D，一种从单张图像中重建3D形状的新方法。&lt;h4&gt;背景&lt;/h4&gt;目前的方法主要集中在从图像中提取语义信息并将其简单地与3D点云连接起来，而没有进一步探索这种拼接后的语义特征。这些纠缠的语义特征显著阻碍了重建性能。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够主动挖掘有效语义线索以提高单张图像中的3D重建质量的方法。&lt;h4&gt;方法&lt;/h4&gt;设计了一个有效的语义挖掘模块和一个三维语义先验学习模块，前者建立了点云与图像语义属性之间的联系，后者利用先验知识增强模型的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在重建质量和鲁棒性方面显著优于先前的工作，并且具有强大的泛化能力，在零样本性能上也表现出色。&lt;h4&gt;结论&lt;/h4&gt;MESC-3D通过主动挖掘有效语义线索和使用三维语义先验知识，提高了单张图像中的3D重建的准确性和现实感。&lt;h4&gt;翻译&lt;/h4&gt;从单张图像中重建3D形状在计算机视觉领域扮演着重要角色。许多方法已经被提出并取得了显著的成绩。然而，现有的方法主要集中在提取图像中的语义信息，并简单地将其与3D点云连接起来而没有进一步探索这种拼接后的语义特征。这些纠缠的语义特征极大地阻碍了重建性能。本文提出了一个名为MESC-3D的新方法，它可以主动挖掘有效语义线索以改进单张图像的3D重建效果。具体而言，设计了一个有效的语义挖掘模块来建立点云和图像语义属性之间的联系，并使点云能够自主选择所需信息。此外，为了解决单一图像中的语义信息可能存在的不足问题（如遮挡），受人类利用日常经验中获得的先验知识表示3D对象能力的启发，我们引入了三维语义先验学习模块。此模块集成了对空间结构的语义理解，使模型能够更准确地解释和重建3D对象，并且在复杂3D环境感知方面更加贴近人类的认知。广泛的评估显示，与先前的工作相比，我们的方法在重建质量和鲁棒性方面取得了显著改进。此外，进一步的实验验证了该方法的强大泛化能力和零样本性能上的优越表现。代码可在https://github.com/QINGQINGLE/MESC-3D上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing 3D shapes from a single image plays an important role incomputer vision. Many methods have been proposed and achieve impressiveperformance. However, existing methods mainly focus on extracting semanticinformation from images and then simply concatenating it with 3D point cloudswithout further exploring the concatenated semantics. As a result, theseentangled semantic features significantly hinder the reconstructionperformance. In this paper, we propose a novel single-image 3D reconstructionmethod called Mining Effective Semantic Cues for 3D Reconstruction from aSingle Image (MESC-3D), which can actively mine effective semantic cues fromentangled features. Specifically, we design an Effective Semantic Mining Moduleto establish connections between point clouds and image semantic attributes,enabling the point clouds to autonomously select the necessary information.Furthermore, to address the potential insufficiencies in semantic informationfrom a single image, such as occlusions, inspired by the human ability torepresent 3D objects using prior knowledge drawn from daily experiences, weintroduce a 3D Semantic Prior Learning Module. This module incorporatessemantic understanding of spatial structures, enabling the model to interpretand reconstruct 3D objects with greater accuracy and realism, closely mirroringhuman perception of complex 3D environments. Extensive evaluations show thatour method achieves significant improvements in reconstruction quality androbustness compared to prior works. Additionally, further experiments validatethe strong generalization capabilities and excels in zero-shot preformance onunseen classes. Code is available at https://github.com/QINGQINGLE/MESC-3D.</description>
      <author>example@mail.com (Shaoming Li, Qing Cai, Songqi Kong, Runqing Tan, Heng Tong, Shiji Qiu, Yongguo Jiang, Zhi Liu)</author>
      <guid isPermaLink="false">2502.20861v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models -- A Panacea for Artificial Intelligence in Pathology?</title>
      <link>http://arxiv.org/abs/2502.21264v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  50 pages, 15 figures and an appendix (study protocol) which is  previously published, see https://doi.org/10.1101/2024.07.04.24309948&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了基于自监督预训练的大型基础模型（FMs）在前列腺癌诊断和Gleason分级任务中的临床应用效果，发现尽管这些模型在数据稀缺的情况下表现出一定的实用性，但在充分标注的数据集上其性能可能不及针对特定任务训练的模型。&lt;h4&gt;背景&lt;/h4&gt;人工智能在病理学中的角色已从辅助诊断发展到揭示整体切片图像（WSIs）中预测形态模式。近年来，基于自监督预训练的基础模型被广泛推崇为适用于各种下游任务的通用解决方案。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过大规模验证AI系统，在前列腺癌诊断和Gleason分级任务上评估基础模型与特定任务端到端学习模型之间的性能差异。&lt;h4&gt;方法&lt;/h4&gt;研究使用超过10万名患者的7342例核心针活检数据，涵盖全球15个地点的11个国家。采用多实例学习框架对两种基础模型和一个完全端到端训练的任务特定模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果挑战了基础模型总是优于任务特定模型的观点。在缺乏标注数据的情况下，基础模型显示出一定优势；然而，在有足够的标记训练数据时，其性能与特有任务模型相匹配或甚至被超越。此外，特定于任务的培训显著减少了临床重要分级错误和难以识别形态的误诊，并降低了不同WSI扫描器间的变异性。&lt;h4&gt;结论&lt;/h4&gt;研究表明，尽管基础模型在快速原型设计和研究中具有明显优势，但它们作为适用于临床应用的医疗AI通用解决方案的角色仍然不确定。对于高风险的应用场景，严格的验证和对特定任务培训的关注仍然是至关重要的。研究者建议将基础模型与端到端学习的优点相结合，以实现适合临床使用的稳健且资源高效的病理学AI解决方案。&lt;h4&gt;翻译&lt;/h4&gt;论文摘要描述了人工智能在病理诊断中的作用从辅助诊断到发现整个切片图像中预测性形态模式的发展历程，并讨论了基于自监督预训练的基础模型是否能成为适用于各种任务的通用解方案。研究结果表明，基础模型虽然在数据稀缺的情况下有其独特优势，但在大量标记训练数据下可能不及特定任务模型的表现。这项工作强调，在高风险临床应用中，必须进行严格的验证以确定最佳解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The role of artificial intelligence (AI) in pathology has evolved from aidingdiagnostics to uncovering predictive morphological patterns in whole slideimages (WSIs). Recently, foundation models (FMs) leveraging self-supervisedpre-training have been widely advocated as a universal solution for diversedownstream tasks. However, open questions remain about their clinicalapplicability and generalization advantages over end-to-end learning usingtask-specific (TS) models. Here, we focused on AI with clinical-gradeperformance for prostate cancer diagnosis and Gleason grading. We present thelargest validation of AI for this task, using over 100,000 core needle biopsiesfrom 7,342 patients across 15 sites in 11 countries. We compared two FMs with afully end-to-end TS model in a multiple instance learning framework. Ourfindings challenge assumptions that FMs universally outperform TS models. WhileFMs demonstrated utility in data-scarce scenarios, their performance convergedwith - and was in some cases surpassed by - TS models when sufficient labeledtraining data were available. Notably, extensive task-specific trainingmarkedly reduced clinically significant misgrading, misdiagnosis of challengingmorphologies, and variability across different WSI scanners. Additionally, FMsused up to 35 times more energy than the TS model, raising concerns about theirsustainability. Our results underscore that while FMs offer clear advantagesfor rapid prototyping and research, their role as a universal solution forclinically applicable medical AI remains uncertain. For high-stakes clinicalapplications, rigorous validation and consideration of task-specific trainingremain critically important. We advocate for integrating the strengths of FMsand end-to-end learning to achieve robust and resource-efficient AI pathologysolutions fit for clinical use.</description>
      <author>example@mail.com (Nita Mulliqi, Anders Blilie, Xiaoyi Ji, Kelvin Szolnoky, Henrik Olsson, Sol Erika Boman, Matteo Titus, Geraldine Martinez Gonzalez, Julia Anna Mielcarz, Masi Valkonen, Einar Gudlaugsson, Svein R. Kjosavik, José Asenjo, Marcello Gambacorta, Paolo Libretti, Marcin Braun, Radzislaw Kordek, Roman Łowicki, Kristina Hotakainen, Päivi Väre, Bodil Ginnerup Pedersen, Karina Dalsgaard Sørensen, Benedicte Parm Ulhøi, Pekka Ruusuvuori, Brett Delahunt, Hemamali Samaratunga, Toyonori Tsuzuki, Emilius A. M. Janssen, Lars Egevad, Martin Eklund, Kimmo Kartasalo)</author>
      <guid isPermaLink="false">2502.21264v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>On the Role of Individual Differences in Current Approaches to Computational Image Aesthetics</title>
      <link>http://arxiv.org/abs/2502.20518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个理论框架，用于解释在图像美学评估（IAA）任务中从通用模型转移到个人化模型的机制，并通过实验证明了不同群体和个体间存在的显著性能差异。&lt;h4&gt;背景&lt;/h4&gt;当前的图像美学评估方法分为两个阶段：第一阶段使用通用图像美学评估（GIAA）模型来估计平均分数，第二阶段利用转移学习的个性化图像美学评估（PIAA）模型来适应用户的主观性。然而，这种从GIAA到PIAA的理论理解仍不充分。&lt;h4&gt;目的&lt;/h4&gt;本文旨在建立一个理论基础，并提出了一种统一模型，该模型可以同时处理个体和群体评估任务。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个编码个人特征并在分布格式中表示的统一模型。实验通过不同的群体制样进行了验证，包括根据组大小进行子采样和分离的人口统计学变量。&lt;h4&gt;主要发现&lt;/h4&gt;1. 转移学习从GIAA到PIAA涉及外推，反之则是内插；2. 教育水平是影响美学差异的主要因素，其次是摄影艺术经验；3. 在艺术品中观察到了更强的个人主观性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的模型能够同时支持通用和个性化图像美学评估，并且可以提高在不同人口统计学群体中的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;图像美学评估（IAA）是一种复杂任务，由于图像多样性和用户主体性的存在而变得更为复杂。当前的方法将其分为两个阶段：第一阶段使用通用的图像美学评估模型来估计平均分数；第二阶段利用转移学习将GIAA适应为PIAA以融入用户的主观性。然而，缺乏关于在GIAA和PIAA之间进行转移学习时的理论理解，特别是在考虑群体构成、群体规模、个体之间的审美差异以及人口统计学相关性的背景下。本文提出了一个统一模型，该模型使用分布形式编码个人特征来进行个体及群体制评估。我们证明了从GIAA转移到PIAA涉及外推而相反则为内插，后者通常对机器学习更有益。通过对不同构成的群体进行实验（包括按组大小子采样和分离的人口统计学变量）发现，即使对于GIAA来说，性能也表现出显著变化，表明平均分数并不能完全消除个体主观性。性能差异分析以及基尼指数分析显示教育水平是影响审美差异的主要因素，其次是摄影及艺术经验，在艺术品中观察到更强的个人主体性。我们的模型独特地支持了通用和个性化图像美学评估，并提高了不同人口统计学群体中的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image aesthetic assessment (IAA) evaluates image aesthetics, a taskcomplicated by image diversity and user subjectivity. Current approachesaddress this in two stages: Generic IAA (GIAA) models estimate mean aestheticscores, while Personal IAA (PIAA) models adapt GIAA using transfer learning toincorporate user subjectivity. However, a theoretical understanding of transferlearning between GIAA and PIAA, particularly concerning the impact of groupcomposition, group size, aesthetic differences between groups and individuals,and demographic correlations, is lacking. This work establishes a theoreticalfoundation for IAA, proposing a unified model that encodes individualcharacteristics in a distributional format for both individual and groupassessments. We show that transferring from GIAA to PIAA involvesextrapolation, while the reverse involves interpolation, which is generallymore effective for machine learning. Experiments with varying groupcompositions, including sub-sampling by group size and disjoint demographics,reveal significant performance variation even for GIAA, indicating that meanscores do not fully eliminate individual subjectivity. Performance variationsand Gini index analysis reveal education as the primary factor influencingaesthetic differences, followed by photography and art experience, withstronger individual subjectivity observed in artworks than in photos. Our modeluniquely supports both GIAA and PIAA, enhancing generalization acrossdemographics.</description>
      <author>example@mail.com (Li-Wei Chen, Ombretta Strafforello, Anne-Sofie Maerten, Tinne Tuytelaars, Johan Wagemans)</author>
      <guid isPermaLink="false">2502.20518v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Modeling Human Beliefs about AI Behavior for Scalable Oversight</title>
      <link>http://arxiv.org/abs/2502.21262v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  53 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了如何通过建模人类评估者的信念来改进对AI系统的监督，以解决随着AI能力提升而导致的人类反馈可靠性降低的问题。&lt;h4&gt;背景&lt;/h4&gt;当前的AI系统通常依赖于人类反馈来学习人类的价值观和偏好。然而，随着AI系统的能力增强，这种人类反馈变得越来越不可靠。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过建模人的信念来提高对超出人类能力范围的AI系统的监督效率。&lt;h4&gt;方法&lt;/h4&gt;提出了形式化的模型来描述人对于AI行为的看法，并分析了这些模型在推断人类价值观中的作用。同时引入了一个放松版的人类信念模型覆盖概念，以减少依赖于精确信念模型的需求。&lt;h4&gt;主要发现&lt;/h4&gt;通过理论分析和实验研究揭示了如何利用基础模型构建覆盖信念模型的潜力，为可扩展监督提供了新方法。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够帮助更好地理解人类反馈，并且提供了一种使用基础AI系统来提高监督效率的新途径。&lt;h4&gt;翻译&lt;/h4&gt;当代的人工智能（AI）对齐工作经常依赖于人类反馈来教导AI系统学习人类的价值观和偏好。然而，随着AI系统的功能增强，这种人类反馈变得越来越不可靠。这导致了一个可扩展监控的问题：如何监管超出人类能力的AI系统？在这项工作中，我们提出通过建模人评估者对于AI行为的看法来更好地解释人的反馈。我们将人类信念模型形式化，并从理论上分析它们在推断人类价值观中的作用。然后描述了这种推理中剩余的不确定性以及这些不确定性消失的情况条件。为了减少对精确信念模型的依赖，我们引入了一个放松版的人类信念模型覆盖概念。最后，我们建议使用基础模型来构建覆盖信念模型，为可扩展监督提供了一种新的潜在方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contemporary work in AI alignment often relies on human feedback to teach AIsystems human preferences and values. Yet as AI systems grow more capable,human feedback becomes increasingly unreliable. This raises the problem ofscalable oversight: How can we supervise AI systems that exceed humancapabilities? In this work, we propose to model the human evaluator's beliefsabout the AI system's behavior to better interpret the human's feedback. Weformalize human belief models and theoretically analyze their role in inferringhuman values. We then characterize the remaining ambiguity in this inferenceand conditions for which the ambiguity disappears. To mitigate reliance onexact belief models, we then introduce the relaxation of human belief modelcovering. Finally, we propose using foundation models to construct coveringbelief models, providing a new potential approach to scalable oversight.</description>
      <author>example@mail.com (Leon Lang, Patrick Forré)</author>
      <guid isPermaLink="false">2502.21262v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Dimension Agnostic Neural Processes</title>
      <link>http://arxiv.org/abs/2502.20661v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, Accepted to ICLR 2025 (International Conference  on Learning Representations)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的元学习模型Dimension Agnostic Neural Processes(DANP)，该模型通过引入Dimension Aggregator Block(DAB)和Transformer架构，增强了处理不同维度输入的能力，并在各种回归任务上显示出优越性能。&lt;h4&gt;背景&lt;/h4&gt;传统的Neural Process(NP)方法虽然能够提取跨多种任务的数据共享特征并预测不确定性，但在适应不同输入维度的任务时面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种元学习模型DANP，以克服传统NP模型的局限性，并提升其在回归任务中的适用性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入Dimension Aggregator Block(DAB)将输入特征转换为固定维度的空间，同时采用Transformer架构和潜在编码层来学习更具普适性的特征。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证了DANP模型相比于现有NP变体在合成数据集与实际回归任务上的优越性。&lt;h4&gt;结论&lt;/h4&gt;DANP展示了其解决传统NP模型局限性和广泛适应各种回归场景的潜力，具有较高的实用价值。&lt;h4&gt;翻译&lt;/h4&gt;元学习的目标是训练可以使用有限标注数据推广到新任务的模型，通过提取多样任务数据集中的共享特征。此外，在训练和评估期间考虑预测不确定性，这是一个称为不确定感知元学习的概念。神经过程(NP)是一种著名的不确定感知元学习方法，它利用参数化神经网络构建隐式随机过程，使快速适应新任务成为可能。然而，现有的NP方法在处理多样输入维度和学习特征方面存在挑战，限制了它们在回归任务中的广泛应用性。为了克服这些局限并提高NP模型作为通用回归器的实用性，我们引入了Dimension Agnostic Neural Processes(DANP)。DANP采用Dimension Aggregator Block(DAB)，将输入特征转换为固定维度空间，增强模型处理多样数据集的能力；同时利用Transformer架构和潜在编码层，学习可跨多种任务泛化的更广泛特征。通过在各种合成和实际回归任务上的综合实验，我们实证显示了DANP优于先前的NP变体，在克服传统NP模型局限性方面展示出其有效性及其应用于多样化回归场景的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Meta-learning aims to train models that can generalize to new tasks withlimited labeled data by extracting shared features across diverse taskdatasets. Additionally, it accounts for prediction uncertainty during bothtraining and evaluation, a concept known as uncertainty-aware meta-learning.Neural Process(NP) is a well-known uncertainty-aware meta-learning method thatconstructs implicit stochastic processes using parametric neural networks,enabling rapid adaptation to new tasks. However, existing NP methods facechallenges in accommodating diverse input dimensions and learned features,limiting their broad applicability across regression tasks. To address theselimitations and advance the utility of NP models as general regressors, weintroduce Dimension Agnostic Neural Processes(DANP). DANP incorporatesDimension Aggregator Block(DAB) to transform input features into afixed-dimensional space, enhancing the model's ability to handle diversedatasets. Furthermore, leveraging the Transformer architecture and latentencoding layers, DANP learns a wider range of features that are generalizableacross various tasks. Through comprehensive experimentation on varioussynthetic and practical regression tasks, we empirically show that DANPoutperforms previous NP variations, showcasing its effectiveness in overcomingthe limitations of traditional NP models and its potential for broaderapplicability in diverse regression scenarios.</description>
      <author>example@mail.com (Hyungi Lee, Chaeyun Jang, Dongbok Lee, Juho Lee)</author>
      <guid isPermaLink="false">2502.20661v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Parallel-Learning of Invariant and Tempo-variant Attributes of Single-Lead Cardiac Signals: PLITA</title>
      <link>http://arxiv.org/abs/2502.21162v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in The 39th Annual AAAI Conference on Artificial  Intelligence. Main Track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的自监督学习方法PLITA，用于捕捉单导联心电图（ECG）信号中的不变和时变属性。&lt;h4&gt;背景&lt;/h4&gt;穿戴式传感设备在未来的数字健康领域中将发挥重要作用。目前的自监督学习方法只能编码不变属性，忽略了反映状态变化的时间变异信息。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时捕捉时间不变和时间变异心电图特征的新SSL方法。&lt;h4&gt;方法&lt;/h4&gt;通过强制相邻时间点输入的空间表示更加接近来捕获时变属性。&lt;h4&gt;主要发现&lt;/h4&gt;PLITA在时间变异属性起重要作用的设置中表现出显著更好的性能。&lt;h4&gt;结论&lt;/h4&gt;PLITA是一种有效的自监督学习框架，能够有效处理心电图信号中的不变和时变信息。&lt;h4&gt;翻译&lt;/h4&gt;可穿戴传感设备如Holter监护仪将在未来的数字健康领域扮演关键角色。无监督的学习框架（例如自我监督学习）对于将这些单导联的心电信号映射到预期的临床结果至关重要。这种信号具有时间变异成分，其模式随记录过程而演变，并且还存在不变成分，其模式保持不变。然而，现有的SSL方法只能驱动模型编码不变属性，导致模型忽略反映状态变化的时间变异信息。本文介绍了一种新的SSL方法——并行学习不变和时变属性（PLITA），该方法旨在捕捉这两种类型的心电图特征。通过强制相邻时间点输入的空间表示更加接近来捕获时变属性。我们评估了此方法在学习两种不同类型的特征方面的能力，以及与现有ECG分析的SSL方法相比的性能表现。在时间变异属性起重要作用的情况下，PLITA表现出显著更好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wearable sensing devices, such as Holter monitors, will play a crucial rolein the future of digital health. Unsupervised learning frameworks such asSelf-Supervised Learning (SSL) are essential to map these single-leadelectrocardiogram (ECG) signals with their anticipated clinical outcomes. Thesesignals are characterized by a tempo-variant component whose patterns evolvethrough the recording and an invariant component with patterns that remainunchanged. However, existing SSL methods only drive the model to encode theinvariant attributes, leading the model to neglect tempo-variant informationwhich reflects subject-state changes through time. In this paper, we presentParallel-Learning of Invariant and Tempo-variant Attributes (PLITA), a novelSSL method designed for capturing both invariant and tempo-variant ECGattributes. The latter are captured by mandating closer representations inspace for closer inputs on time. We evaluate both the capability of the methodto learn the attributes of these two distinct kinds, as well as PLITA'sperformance compared to existing SSL methods for ECG analysis. PLITA performssignificantly better in the set-ups where tempo-variant attributes play a majorrole.</description>
      <author>example@mail.com (Adtian Atienza, Jakob E. Bardram, Sadasivan Puthusserypady)</author>
      <guid isPermaLink="false">2502.21162v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Continuous Adversarial Text Representation Learning for Affective Recognition</title>
      <link>http://arxiv.org/abs/2502.20613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, The 7th International Conference on Artificial  Intelligence in Information and Communication (ICAIIC 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '提出了一种增强情感感知嵌入的框架，旨在改进基于变压器模型的情感识别能力。', '背景': '预训练语言模型在语义理解方面表现出色，但在捕捉细微的情感信息方面存在困难。', '目的': '通过引入连续的效价唤醒标签系统和动态令牌扰动机制来提高情感敏感性。', '方法': '采用连续的valence-arousal标注体系进行对比学习，并利用基于梯度的方法强调与情感相关的令牌。', '主要发现': '实验结果表明，该框架在情绪分类基准上比现有方法平均提高了15.5%。', '结论': '所提出的框架有效增强了情感表示的学习能力，并能实现精确且上下文相关的情感理解。', '翻译': '摘要原文的中文翻译。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While pre-trained language models excel at semantic understanding, they oftenstruggle to capture nuanced affective information critical for affectiverecognition tasks. To address these limitations, we propose a novel frameworkfor enhancing emotion-aware embeddings in transformer-based models. Ourapproach introduces a continuous valence-arousal labeling system to guidecontrastive learning, which captures subtle and multi-dimensional emotionalnuances more effectively. Furthermore, we employ a dynamic token perturbationmechanism, using gradient-based saliency to focus on sentiment-relevant tokens,improving model sensitivity to emotional cues. The experimental resultsdemonstrate that the proposed framework outperforms existing methods, achievingup to 15.5% improvement in the emotion classification benchmark, highlightingthe importance of employing continuous labels. This improvement demonstratesthat the proposed framework is effective in affective representation learningand enables precise and contextually relevant emotional understanding.</description>
      <author>example@mail.com (Seungah Son, Andrez Saurez, Dongsoo Har)</author>
      <guid isPermaLink="false">2502.20613v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Subtask-Aware Visual Reward Learning from Segmented Demonstrations</title>
      <link>http://arxiv.org/abs/2502.20630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project webpage: https://changyeon.site/reds/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;强化学习（RL）代理在各种机器人任务中展示了其潜力。然而，它们仍然严重依赖于人工设计的奖励函数，并且需要大量的试错以及目标行为信息，在现实世界的应用场景中这些信息往往是不可用的。本文提出了REDs：一种从演示视频片段中学习回报的新框架，该框架利用无动作标记视频进行最小监督的学习。具体而言，REDs使用来自不同来源的动作分段视频并将它们视为真实奖励信号。我们训练一个基于视频片段和相应子任务的密集奖励函数，并通过最小化等价策略不变比较距离来确保与真实奖励信号对齐。此外，我们采用对比学习目标以使视频表示与子任务保持一致，在线交互时可以实现精确的子任务推理。实验表明，REDs在Meta-World中的复杂机器人操作任务以及FurnitureBench中的家具组装等更具挑战性的现实世界任务中显著优于基线方法，并且只需要最小的人工干预。&lt;h4&gt;背景&lt;/h4&gt;强化学习代理已经在多种机器人任务上展示了其潜力，但这些代理依然严重依赖于人工设计的奖励函数。这需要大量的试错过程和对目标行为信息的访问，在许多实际应用场合下这类信息是难以获得的。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的从演示中无监督地学习回报的方法REDs，该方法能够利用来自不同来源的视频演示片段进行训练，并且只需要最小的人工干预。&lt;h4&gt;方法&lt;/h4&gt;1. REDs使用动作标记的视频作为输入并将其分割成子任务。2. 利用这些子任务和它们对应的视频段来学习密集奖励函数。3. 通过优化特定的目标函数（即等价策略不变比较距离）以确保奖励信号与真实信号一致。4. 使用对比学习目标使视频表示与子任务保持一致，从而在在线交互中实现精确的子任务推理。&lt;h4&gt;主要发现&lt;/h4&gt;REDs框架能够在Meta-World中的复杂机器人操作任务以及家具组装等更具挑战性的现实世界任务上表现出色，并且显著优于基线方法。此外，在最小的人工干预下该模型还能够推广到未知的任务和机器人的实例中，展示出其在多变环境下的可扩展性。&lt;h4&gt;结论&lt;/h4&gt;REDs是一种高效的学习框架，它通过利用视频演示片段中的信息来减轻对人工设计奖励函数的依赖，并且能够在多种机器人操作任务上表现出色。此外，REDs显示出良好的泛化能力，这表明它具有广泛的应用潜力和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement Learning (RL) agents have demonstrated their potential acrossvarious robotic tasks. However, they still heavily rely on human-engineeredreward functions, requiring extensive trial-and-error and access to targetbehavior information, often unavailable in real-world settings. This paperintroduces REDS: REward learning from Demonstration with Segmentations, a novelreward learning framework that leverages action-free videos with minimalsupervision. Specifically, REDS employs video demonstrations segmented intosubtasks from diverse sources and treats these segments as ground-truthrewards. We train a dense reward function conditioned on video segments andtheir corresponding subtasks to ensure alignment with ground-truth rewardsignals by minimizing the Equivalent-Policy Invariant Comparison distance.Additionally, we employ contrastive learning objectives to align videorepresentations with subtasks, ensuring precise subtask inference during onlineinteractions. Our experiments show that REDS significantly outperforms baselinemethods on complex robotic manipulation tasks in Meta-World and morechallenging real-world tasks, such as furniture assembly in FurnitureBench,with minimal human intervention. Moreover, REDS facilitates generalization tounseen tasks and robot embodiments, highlighting its potential for scalabledeployment in diverse environments.</description>
      <author>example@mail.com (Changyeon Kim, Minho Heo, Doohyun Lee, Jinwoo Shin, Honglak Lee, Joseph J. Lim, Kimin Lee)</author>
      <guid isPermaLink="false">2502.20630v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Dynamically Local-Enhancement Planner for Large-Scale Autonomous Driving</title>
      <link>http://arxiv.org/abs/2502.21134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了Dynamically Local-Enhancement (DLE) Planner，一种在不永久修改基本驾驶规划器的情况下通过局部驾驶数据动态增强驾驶规划的技术。&lt;h4&gt;背景&lt;/h4&gt;当前自主车辆主要限于特定区域运行，但对更广泛的应用需求日益增长。随着模型规模的扩大，有限的容量成为适应新场景的重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决单个庞大模型在处理新情况时效率低下的问题，通过局部驾驶数据动态增强基本驾驶规划器以提高自主驾驶系统的可扩展性而不显著增加规划器的大小。&lt;h4&gt;方法&lt;/h4&gt;引入了位置变化的马尔科夫决策过程(MDP)与图神经网络结合使用的方法，从本地观察数据中提取特定区域的驾驶特征，并利用学习到的特征增强基于强化学习的基本策略。&lt;h4&gt;主要发现&lt;/h4&gt;在多个场景下评估该方法并与适用于所有情况的单一驾驶模型比较后，结果显示本方法在安全性和平均奖励方面都优于基准策略，同时保持较低的规模。&lt;h4&gt;结论&lt;/h4&gt;这种技术有潜力使大规模自主车辆受益，无需大幅扩展设备上的驾驶模型。&lt;h4&gt;翻译&lt;/h4&gt;当前自主车辆主要限于特定区域运行。随着对更广泛应用的需求增加，现有模型在处理新场景时表现出容量限制问题。单个庞大模型难以适应新的情况。本文提出Dynamically Local-Enhancement (DLE) Planner，该方法通过局部驾驶数据动态增强基本驾驶规划器，不需永久修改其本身。通过位置变化的马尔科夫决策过程结合图神经网络从本地观察数据中提取区域特定的驾驶特征，使用这些特征来增强基于强化学习的基本策略。实验结果表明，在安全性和平均奖励方面优于基准模型，并保持较小规模，具备大规模自主车辆应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current autonomous vehicles operate primarily within limited regions, butthere is increasing demand for broader applications. However, as models scale,their limited capacity becomes a significant challenge for adapting to novelscenarios. It is increasingly difficult to improve models for new situationsusing a single monolithic model. To address this issue, we introduce theconcept of dynamically enhancing a basic driving planner with local drivingdata, without permanently modifying the planner itself. This approach, termedthe Dynamically Local-Enhancement (DLE) Planner, aims to improve thescalability of autonomous driving systems without significantly expanding theplanner's size. Our approach introduces a position-varying Markov DecisionProcess formulation coupled with a graph neural network that extractsregion-specific driving features from local observation data. The learnedfeatures describe the local behavior of the surrounding objects, which is thenleveraged to enhance a basic reinforcement learning-based policy. We evaluatedour approach in multiple scenarios and compared it with a one-for-all drivingmodel. The results show that our method outperforms the baseline policy in bothsafety (collision rate) and average reward, while maintaining a lighter scale.This approach has the potential to benefit large-scale autonomous vehicleswithout the need for largely expanding on-device driving models.</description>
      <author>example@mail.com (Nanshan Deng, Weitao Zhou, Bo Zhang, Junze Wen, Kun Jiang, Zhong Cao, Diange Yang)</author>
      <guid isPermaLink="false">2502.21134v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>CuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations</title>
      <link>http://arxiv.org/abs/2502.21127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章介绍了一种新型的Masked Data Modelling (MDM) 方法CuPID，该方法专门针对单导联ECG数据设计，通过提供频谱图上下文信息来增强现有MDM技术。&lt;h4&gt;背景&lt;/h4&gt;穿戴式传感设备如心电图(ECG)心率监测器将在数字健康领域发挥重要作用。这种持续监控导致了大量的未标注数据，促进了无监督学习框架的发展。&lt;h4&gt;目的&lt;/h4&gt;开发一种适用于单导联ECG的无监督学习方法，克服现有MDM技术在处理不规则心跳间隔时的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为Cueing the Predictor Increments the Detailing (CuPID) 的新方法。该方法通过向解码器提供频谱图上下文信息来改善现有的MDM技术。&lt;h4&gt;主要发现&lt;/h4&gt;CuPID 方法在编码器性能上有了显著的提升，特别是在各种不同的配置下。此外，在多个下游任务中，CuPID 表现超过了现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;CuPID是一种有效的改进MDM技术的方法，特别适用于处理单导联ECG数据，并且在广泛的配置和应用中优于现有的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;可穿戴传感设备，如心电图(ECG) 心率监测器，在数字健康领域将扮演重要角色。持续的监控导致了大量的未标记数据，促使开发无监督学习框架的需求。尽管Masked Data Modelling (MDM) 技术已广泛使用，但直接应用于单导联ECG 数据的效果不佳，因为解码器在没有上下文信息的情况下难以处理不规则的心跳间隔。本文提出了一种称为Cueing the Predictor Increments the Detailing (CuPID) 的新型MDM方法，专门针对单导联ECG 设计。通过向解码器提供由频谱图派生的上下文，CuPID 增强了现有的MDM 技术，从而激励编码器生成更详细的表示。这极大地影响了编码器在各种不同配置下的性能表现，使得CuPID 在多种下游任务中超越了现有最先进技术的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wearable sensing devices, such as Electrocardiogram (ECG) heart-ratemonitors, will play a crucial role in the future of digital health. Thiscontinuous monitoring leads to massive unlabeled data, incentivizing thedevelopment of unsupervised learning frameworks. While Masked Data Modelling(MDM) techniques have enjoyed wide use, their direct application to single-leadECG data is suboptimal due to the decoder's difficulty handling irregularheartbeat intervals when no contextual information is provided. In this paper,we present Cueing the Predictor Increments the Detailing (CuPID), a novel MDMmethod tailored to single-lead ECGs. CuPID enhances existing MDM techniques bycueing spectrogram-derived context to the decoder, thus incentivizing theencoder to produce more detailed representations. This has a significant impacton the encoder's performance across a wide range of different configurations,leading CuPID to outperform state-of-the-art methods in a variety of downstreamtasks.</description>
      <author>example@mail.com (Adtian Atienza, Gouthamaan Manimaran, Jakob E. Bardram, Sadasivan Puthusserypady)</author>
      <guid isPermaLink="false">2502.21127v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Few-Shot, No Problem: Descriptive Continual Relation Extraction</title>
      <link>http://arxiv.org/abs/2502.20596v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于检索的解决方案来解决少样本持续关系抽取问题，该方案通过大语言模型生成关系描述，并利用双编码器检索训练范式增强样本和类别表示学习。&lt;h4&gt;背景&lt;/h4&gt;传统的内存基础方法在面对有限样本时容易过拟合，无法巩固旧知识，在少样本场景中数据稀疏进一步阻碍了有效的隐空间数据增强。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来解决少样本持续关系抽取中的挑战，并保持模型在一系列任务上的鲁棒性能，同时减少灾难性遗忘问题。&lt;h4&gt;方法&lt;/h4&gt;首先使用大语言模型为每个关系生成描述；然后引入双编码器检索训练范式以丰富样本和类别表示学习；最后设计基于检索的预测方法，其中每个样本通过整合关系描述向量和类原型的反向排名融合得分来“检索”最佳匹配的关系。&lt;h4&gt;主要发现&lt;/h4&gt;在多个数据集上的广泛实验表明该方法显著地提高了性能，并且在整个顺序任务中保持了鲁棒性，有效地解决了灾难性遗忘问题。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为解决少样本持续关系抽取的挑战提供了一种有效的解决方案，通过利用增强表示来促进模型学习和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot Continual Relation Extraction is a crucial challenge for enabling AIsystems to identify and adapt to evolving relationships in dynamic real-worlddomains. Traditional memory-based approaches often overfit to limited samples,failing to reinforce old knowledge, with the scarcity of data in few-shotscenarios further exacerbating these issues by hindering effective dataaugmentation in the latent space. In this paper, we propose a novelretrieval-based solution, starting with a large language model to generatedescriptions for each relation. From these descriptions, we introduce abi-encoder retrieval training paradigm to enrich both sample and classrepresentation learning. Leveraging these enhanced representations, we design aretrieval-based prediction method where each sample "retrieves" the bestfitting relation via a reciprocal rank fusion score that integrates bothrelation description vectors and class prototypes. Extensive experiments onmultiple datasets demonstrate that our method significantly advances thestate-of-the-art by maintaining robust performance across sequential tasks,effectively addressing catastrophic forgetting.</description>
      <author>example@mail.com (Nguyen Xuan Thanh, Anh Duc Le, Quyen Tran, Thanh-Thien Le, Linh Ngo Van, Thien Huu Nguyen)</author>
      <guid isPermaLink="false">2502.20596v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Best Foot Forward: Robust Foot Reconstruction in-the-wild</title>
      <link>http://arxiv.org/abs/2502.20511v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;准确的3D脚部重建对于个性化矫形器、数字医疗和虚拟试穿至关重要。&lt;h4&gt;背景&lt;/h4&gt;现有的方法在处理不完整的扫描数据以及解剖变异时遇到困难，特别是在用户移动受限的情况下（例如自我扫描场景）难以捕捉到像足弓和后跟这样的区域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的端到端管道来改进结构从运动（SfM）重建过程。&lt;h4&gt;方法&lt;/h4&gt;该方法首先使用SE(3)正则化结合视角预测模块解决扫描对齐的不确定性，然后通过基于注意力机制的网络训练在合成增强点云上的几何补充缺失部分。&lt;h4&gt;主要发现&lt;/h4&gt;该技术实现了同类最佳性能，同时保持了临床验证的解剖学精确度。通过结合合成数据与学习到的几何先验知识，使足部重建能够适应真实世界捕捉条件下的各种情况。&lt;h4&gt;结论&lt;/h4&gt;此方法为基于移动设备的3D扫描在医疗和零售领域的应用开辟了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;准确的三维脚部重建对于个性化矫形器、数字健康护理以及虚拟试穿至关重要。然而，现有的技术难以应对不完整扫描及解剖变异的问题，在自我扫描等情况下尤其困难，因为用户移动受限影响对足弓和后跟等区域的捕捉。我们提出了一种新颖的端到端流程来改进结构从运动重建过程，首先通过SE(3)正则化结合视角预测模块解决扫描对齐问题，再利用基于注意力机制训练在合成增强点云上的网络补充缺失几何部分。此方法实现了同类最佳性能，并保持了临床验证的解剖精确度。借助合成数据和学习到的几何先验知识，在真实世界捕捉条件下实现稳健的脚部重建。这为医疗与零售领域中基于移动设备的3D扫描应用开辟了新的机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 3D foot reconstruction is crucial for personalized orthotics,digital healthcare, and virtual fittings. However, existing methods strugglewith incomplete scans and anatomical variations, particularly in self-scanningscenarios where user mobility is limited, making it difficult to capture areaslike the arch and heel. We present a novel end-to-end pipeline that refinesStructure-from-Motion (SfM) reconstruction. It first resolves scan alignmentambiguities using SE(3) canonicalization with a viewpoint prediction module,then completes missing geometry through an attention-based network trained onsynthetically augmented point clouds. Our approach achieves state-of-the-artperformance on reconstruction metrics while preserving clinically validatedanatomical fidelity. By combining synthetic training data with learnedgeometric priors, we enable robust foot reconstruction under real-world captureconditions, unlocking new opportunities for mobile-based 3D scanning inhealthcare and retail.</description>
      <author>example@mail.com (Kyle Fogarty, Jing Yang, Chayan Kumar Patodi, Aadi Bhanti, Steven Chacko, Cengiz Oztireli, Ujwal Bonde)</author>
      <guid isPermaLink="false">2502.20511v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Information Bottleneck-Guided Heterogeneous Graph Learning for Interpretable Neurodevelopmental Disorder Diagnosis</title>
      <link>http://arxiv.org/abs/2502.20769v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的框架I2B-HGNN，用于从神经发育障碍中提取有意义的生物标志物，并进行诊断。&lt;h4&gt;背景&lt;/h4&gt;现有的机器学习模型在提供综合可解释性方面存在挑战，尤其是在处理复杂的数据编码、解码和融合时。这些模型往往难以从成像数据（如fMRI）中抽取有用的生物标记物，也缺乏解释非成像数据重要性的机制。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以诊断神经发育障碍的可解释机器学习框架，该框架能够有效地利用成像与非成像多模态数据并提供清晰的结果解释。&lt;h4&gt;方法&lt;/h4&gt;提出了Interpretable Information Bottleneck Heterogeneous Graph Neural Network (I2B-HGNN)，包括两个关键模块：Information Bottleneck Graph Transformer (IBGraphFormer) 和 Information Bottleneck Heterogeneous Graph Attention Network (IB-HGAN)。IBGraphFormer用于局部模式，通过脑连接图约束的图神经网络进行全局建模并利用信息瓶颈指导的聚类提取生物标记物；IB-HGAN则用于全球多模态互动，使用异构图神经网络实现可解释的多模态融合。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，I2B-HGNN在诊断神经发育障碍方面表现出高精度，并能提供清晰的生物标志物识别和有效的非成像数据分析。&lt;h4&gt;结论&lt;/h4&gt;I2B-HGNN框架是解决当前机器学习模型面临的挑战的有效解决方案，它不仅能够提高诊断准确度，还能通过详细的解释帮助理解疾病特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing interpretable models for diagnosing neurodevelopmental disorders(NDDs) is highly valuable yet challenging, primarily due to the complexity ofencoding, decoding and integrating imaging and non-imaging data. Many existingmachine learning models struggle to provide comprehensive interpretability,often failing to extract meaningful biomarkers from imaging data, such asfunctional magnetic resonance imaging (fMRI), or lacking mechanisms to explainthe significance of non-imaging data. In this paper, we propose theInterpretable Information Bottleneck Heterogeneous Graph Neural Network(I2B-HGNN), a novel framework designed to learn from fine-grained localpatterns to comprehensive global multi-modal interactions. This frameworkcomprises two key modules. The first module, the Information Bottleneck GraphTransformer (IBGraphFormer) for local patterns, integrates global modeling withbrain connectomic-constrained graph neural networks to identify biomarkersthrough information bottleneck-guided pooling. The second module, theInformation Bottleneck Heterogeneous Graph Attention Network (IB-HGAN) forglobal multi-modal interactions, facilitates interpretable multi-modal fusionof imaging and non-imaging data using heterogeneous graph neural networks. Theresults of the experiments demonstrate that I2B-HGNN excels in diagnosing NDDswith high accuracy, providing interpretable biomarker identification andeffective analysis of non-imaging data.</description>
      <author>example@mail.com (Yueyang Li, Lei Chen, Wenhao Dong, Shengyu Gong, Zijian Kang, Boyang Wei, Weiming Zeng, Hongjie Yan, Lingbin Bian, Wai Ting Siok, Nizhuan Wang)</author>
      <guid isPermaLink="false">2502.20769v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Learning for Just-In-Time Software Defect Prediction in Autonomous Driving Systems</title>
      <link>http://arxiv.org/abs/2502.20806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种使用多模态学习的即时软件缺陷预测（JIT-SDP）方法，以提高自动驾驶软件系统的可靠性和安全性。&lt;h4&gt;背景&lt;/h4&gt;近年来，随着自主驾驶技术的发展，可靠的软件对于确保安全和性能变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过利用预训练变换器和组合模块处理多种数据模式来实现即时的软件缺陷预测。&lt;h4&gt;方法&lt;/h4&gt;该模型采用多模态变换器，其中包含针对文本、数值和分类等不同数据模式之间的注意机制。在组合模块中，将基于文本数据和包含分类及数值数据的表格特征的变压器模型输出进行结合以生成预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，相对于现有的深度学习和机器学习模型，在三个开源自动驾驶系统软件项目上该方法显著提高了评估指标的表现。&lt;h4&gt;结论&lt;/h4&gt;通过改善缺陷预测能力，多模态学习在提高自动驾驶软件系统的可靠性和安全性方面具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了利用预训练的变换器及组合模块处理包括代码特征、更改度量和上下文信息等多种数据模式的一种即时软件缺陷预测方法。该模型采用注意机制将不同形式的数据（如文本，数值，分类等）结合在一起，并在GitHub上收集三个开源自动驾驶系统项目的实验中证明其优于现有深度学习与机器学习模型的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the rise of autonomous driving technologies has highlightedthe critical importance of reliable software for ensuring safety andperformance. This paper proposes a novel approach for just-in-time softwaredefect prediction (JIT-SDP) in autonomous driving software systems usingmultimodal learning. The proposed model leverages the multimodal transformersin which the pre-trained transformers and a combining module deal with themultiple data modalities of the software system datasets such as code features,change metrics, and contextual information. The key point for adaptingmultimodal learning is to utilize the attention mechanism between the differentdata modalities such as text, numerical, and categorical. In the combiningmodule, the output of a transformer model on text data and tabular featurescontaining categorical and numerical data are combined to produce thepredictions using the fully connected layers. Experiments conducted on threeopen-source autonomous driving system software projects collected from theGitHub repository (Apollo, Carla, and Donkeycar) demonstrate that the proposedapproach significantly outperforms state-of-the-art deep learning and machinelearning models regarding evaluation metrics. Our findings highlight thepotential of multimodal learning to enhance the reliability and safety ofautonomous driving software through improved defect prediction.</description>
      <author>example@mail.com (Faisal Mohammad, Duksan Ryu)</author>
      <guid isPermaLink="false">2502.20806v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>TimesBERT: A BERT-Style Foundation Model for Time Series Understanding</title>
      <link>http://arxiv.org/abs/2502.21245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;时间序列理解包括分类、填充和异常检测等任务，现有的BERT风格架构在这些领域尚未完全解锁。&lt;h4&gt;背景&lt;/h4&gt;时间序列分析在多种场景中非常重要。虽然GPT风格模型已经作为时间序列预测的基础模型被广泛应用，但基于自然语言理解取得重大进展的BERT风格架构还未充分利用于时间序列理解。&lt;h4&gt;目的&lt;/h4&gt;设计一种名为TimesBERT的新方法，旨在学习时间序列中的通用表示形式，并解决多粒度结构的问题。&lt;h4&gt;方法&lt;/h4&gt;受到多元时间序列和多句子文档共享的多粒度结构启发，提出了TimeBERT模型。除了自然地采用掩码建模外，还提出了一种并行的任务——功能令牌预测任务来体现重要的多粒度结构。&lt;h4&gt;主要发现&lt;/h4&gt;TimesBERT在涵盖四个典型下游理解任务的数据集上取得了最先进的性能，并超越了特定任务的模型和语言预训练骨干网络，被定位为时间序列理解的基础模型。&lt;h4&gt;结论&lt;/h4&gt;TimesBERT通过利用多粒度表示形式，在多个领域的时间序列分析中表现出了卓越的能力，展示了其作为通用基础模型在时间序列理解中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;时间序列分析至关重要。除了预测任务之外，许多实际应用包括分类、填充和异常检测，这些都归结为不同的能力术语即本文所说的时间序列理解。虽然GPT风格的模型被定位为基础模型用于时间序列预测，但基于自然语言理解取得重大进展的BERT架构在时间序列理解方面尚未完全解锁。受到多元时间序列与多句子文档共享的多层次结构启发，我们设计了TimesBERT来学习包括时间模式和变量特性在内的通用时间序列表示形式。除了自然适应掩码建模之外，还提出了一种功能令牌预测任务以体现重要的多层次结构。我们的模型在涵盖各种领域的260亿个时间点上进行了预训练，并利用多层次表示，在四个典型下游理解任务中取得了最先进的性能，优于特定任务的模型和语言预训练骨干网络，被定位为时间序列理解的基础模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series analysis is crucial in diverse scenarios. Beyond forecasting,considerable real-world tasks are categorized into classification, imputation,and anomaly detection, underscoring different capabilities termed time seriesunderstanding in this paper. While GPT-style models have been positioned asfoundation models for time series forecasting, the BERT-style architecture,which has made significant advances in natural language understanding, has notbeen fully unlocked for time series understanding, possibly attributed to theundesirable dropout of essential elements of BERT. In this paper, inspired bythe shared multi-granularity structure between multivariate time series andmultisentence documents, we design TimesBERT to learn generic representationsof time series including temporal patterns and variate-centric characteristics.In addition to a natural adaptation of masked modeling, we propose a paralleltask of functional token prediction to embody vital multi-granularitystructures. Our model is pre-trained on 260 billion time points across diversedomains. Leveraging multi-granularity representations, TimesBERT achievesstate-of-the-art performance across four typical downstream understandingtasks, outperforming task-specific models and language pre-trained backbones,positioning it as a versatile foundation model for time series understanding.</description>
      <author>example@mail.com (Haoran Zhang, Yong Liu, Yunzhong Qiu, Haixuan Liu, Zhongyi Pei, Jianmin Wang, Mingsheng Long)</author>
      <guid isPermaLink="false">2502.21245v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Generating Clinically Realistic EHR Data via a Hierarchy- and Semantics-Guided Transformer</title>
      <link>http://arxiv.org/abs/2502.20719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的框架HiSGT，该框架利用层次和语义信息生成高质量的合成电子健康记录（EHRs），提高了合成数据与真实患者记录在统计上的对齐度，并支持下游临床应用。&lt;h4&gt;背景&lt;/h4&gt;现有的生成方法通常将EHRs视为离散医学代码的序列，忽视了临床编码系统的层级组织及其描述所提供的丰富语义信息，导致合成的数据缺乏临床真实性且在实际应用中效果不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架来克服现有生成模型的问题，提高合成EHR的质量和实用性。&lt;h4&gt;方法&lt;/h4&gt;HiSGT通过构建层次图来捕捉医学代码之间的关系，并使用图神经网络导出具有层级意识的嵌入。这些嵌入与从预训练临床语言模型中提取的语义信息相结合，增强了基于Transformer的生成器的能力。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC-III和MIMIC-IV数据集上进行的广泛实验表明，HiSGT显著提高了合成EHRs与真实患者记录之间的统计对齐度，并支持慢性病分类等稳健的下游应用。&lt;h4&gt;结论&lt;/h4&gt;通过解决传统基于原始代码生成模型的限制，HiSGT为临床高保真度合成数据生成提供了重要的步骤和通用框架，促进了可解释医学编码表示以及数据分析和隐私保护方面的有价值的应用。&lt;h4&gt;翻译&lt;/h4&gt;生成逼真的合成电子健康记录（EHRs）对加速医疗研究、促进AI模型开发及增强患者隐私具有巨大潜力。然而，现有的生成方法通常将EHR视为离散医疗代码的序列化结构，这种处理方式忽略了临床编码系统内在的层级组织及其描述提供的丰富语义信息。因此，合成的数据在下游临床任务中的应用价值有限。在这篇论文中，我们提出了HiSGT框架，该框架利用层次和语义信息进行生成过程。通过这种方法，HiSGT不仅提高了数据统计上的对齐度，还支持了稳健的下游应用程序（例如慢性病分类）。这项研究代表了一个重要的步骤，即从传统基于原始代码的生成模型转向临床高保真度合成数据生成，并且提供了一种适合解释性医疗编码表示的一般框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating realistic synthetic electronic health records (EHRs) holdstremendous promise for accelerating healthcare research, facilitating AI modeldevelopment and enhancing patient privacy. However, existing generative methodstypically treat EHRs as flat sequences of discrete medical codes. This approachoverlooks two critical aspects: the inherent hierarchical organization ofclinical coding systems and the rich semantic context provided by codedescriptions. Consequently, synthetic patient sequences often lack highclinical fidelity and have limited utility in downstream clinical tasks. Inthis paper, we propose the Hierarchy- and Semantics-Guided Transformer (HiSGT),a novel framework that leverages both hierarchical and semantic information forthe generative process. HiSGT constructs a hierarchical graph to encodeparent-child and sibling relationships among clinical codes and employs a graphneural network to derive hierarchy-aware embeddings. These are then fused withsemantic embeddings extracted from a pre-trained clinical language model (e.g.,ClinicalBERT), enabling the Transformer-based generator to more accuratelymodel the nuanced clinical patterns inherent in real EHRs. Extensiveexperiments on the MIMIC-III and MIMIC-IV datasets demonstrate that HiSGTsignificantly improves the statistical alignment of synthetic data with realpatient records, as well as supports robust downstream applications such aschronic disease classification. By addressing the limitations of conventionalraw code-based generative models, HiSGT represents a significant step towardclinically high-fidelity synthetic data generation and a general paradigmsuitable for interpretable medical code representation, offering valuableapplications in data augmentation and privacy-preserving healthcare analytics.</description>
      <author>example@mail.com (Guanglin Zhou, Sebastiano Barbieri)</author>
      <guid isPermaLink="false">2502.20719v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Discovering Global False Negatives On the Fly for Self-supervised Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.20612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了GloFND，一种用于自监督对比学习的方法，能够自动识别和排除虚假负样本。&lt;h4&gt;背景&lt;/h4&gt;在自监督对比学习中，通常通过锚图像与整个数据集中的其他样本来构建负对。这种方法可能导致具有相似语义的负对（即虚假负样本）的生成。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法以解决虚假负样本问题，并提高模型训练的效果和效率。&lt;h4&gt;方法&lt;/h4&gt;GloFND是一种基于优化的方法，它在训练过程中为每个锚数据动态学习阈值来识别其虚假负样本。这种方法可以在整个数据集上全局检测虚假负样本，而不是局限于小批量内局部检测。此外，该方法的每轮迭代计算成本与数据集大小无关。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在图像和图像-文本数据上的GloFND方法是有效的。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效解决自监督对比学习中的虚假负样本问题，并且具有较低的计算复杂度。&lt;h4&gt;翻译&lt;/h4&gt;在自我监督对比性学习中，负对通常是通过锚定图片与整个数据集（除去该锚点）中选取的一个样本来构建。然而，这种策略可能导致生成语义相似的负面配对（称为“虚假否定”），从而导致其嵌入物被错误地推开。为解决此问题，我们提出了一种基于优化的方法GloFND，它在训练过程中自动学习每个锚定数据的阈值以识别其虚假否定。与先前用于发现虚假否定的方法相比，我们的方法在整个数据集中全局检测虚假否定，而不是局限于小批量内局部检测。此外，其每轮迭代计算成本保持独立于数据集大小。实验结果表明，在图像和图像-文本数据上提出的该方法是有效的。我们的实现可在https://github.com/vibalcam/GloFND获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In self-supervised contrastive learning, negative pairs are typicallyconstructed using an anchor image and a sample drawn from the entire dataset,excluding the anchor. However, this approach can result in the creation ofnegative pairs with similar semantics, referred to as "false negatives",leading to their embeddings being falsely pushed apart. To address this issue,we introduce GloFND, an optimization-based approach that automatically learnson the fly the threshold for each anchor data to identify its false negativesduring training. In contrast to previous methods for false negative discovery,our approach globally detects false negatives across the entire dataset ratherthan locally within the mini-batch. Moreover, its per-iteration computationcost remains independent of the dataset size. Experimental results on image andimage-text data demonstrate the effectiveness of the proposed method. Ourimplementation is available at https://github.com/vibalcam/GloFND .</description>
      <author>example@mail.com (Vicente Balmaseda, Bokun Wang, Ching-Long Lin, Tianbao Yang)</author>
      <guid isPermaLink="false">2502.20612v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Causality Is Key to Understand and Balance Multiple Goals in Trustworthy ML and Foundation Models</title>
      <link>http://arxiv.org/abs/2502.21123v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;确保机器学习系统的可信度至关重要，尤其是在它们被广泛应用于高风险领域时。本文提倡将因果方法集成到机器学习中，以解决公平性、隐私性、健壮性、准确性和可解释性的相互之间常常产生冲突的核心原则之间的权衡。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习系统在关键领域的应用越来越多，确保这些系统的可信度变得至关重要。然而，在实际操作中，诸如公平性、隐私性等重要目标往往被孤立处理，导致解决方案不理想。&lt;h4&gt;目的&lt;/h4&gt;论文旨在通过引入因果方法来解决信任机器学习和基础模型之间的多重竞争目标的平衡问题，并探讨如何将因果推理有效集成到这些系统中以提高其可靠性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;文章回顾了现有文献中关于利用因果关系成功解决如公平性和准确性或隐私性和健壮性的冲突案例，以此证明因果框架在机器学习中的重要性和实用性。&lt;h4&gt;主要发现&lt;/h4&gt;论文强调采用因果分析可以更好地理解和解决不同目标之间的权衡问题，并提出了一些实际方法来实现这一目标。&lt;h4&gt;结论&lt;/h4&gt;尽管存在挑战和局限性，但通过使用因果框架，可以使AI系统更加负责任且伦理上更为可靠。因此，未来的研究应继续探索如何最佳地利用这些工具和技术。&lt;h4&gt;翻译&lt;/h4&gt;确保机器学习系统的可信度至关重要，尤其是在它们被广泛应用于高风险领域时。本文提倡将因果方法集成到机器学习中，以解决公平性、隐私性、健壮性、准确性和可解释性的相互之间常常产生冲突的核心原则之间的权衡。通过回顾文献中的成功案例，文章强调了因果推理在机器学习中的重要角色，并探讨如何将其有效整合进模型当中，从而提升系统的可靠性和透明度。此外，还讨论了采用这一方法所面临的挑战和机遇，指出了未来研究的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring trustworthiness in machine learning (ML) systems is crucial as theybecome increasingly embedded in high-stakes domains. This paper advocates forthe integration of causal methods into machine learning to navigate thetrade-offs among key principles of trustworthy ML, including fairness, privacy,robustness, accuracy, and explainability. While these objectives should ideallybe satisfied simultaneously, they are often addressed in isolation, leading toconflicts and suboptimal solutions. Drawing on existing applications ofcausality in ML that successfully align goals such as fairness and accuracy orprivacy and robustness, this paper argues that a causal approach is essentialfor balancing multiple competing objectives in both trustworthy ML andfoundation models. Beyond highlighting these trade-offs, we examine howcausality can be practically integrated into ML and foundation models, offeringsolutions to enhance their reliability and interpretability. Finally, wediscuss the challenges, limitations, and opportunities in adopting causalframeworks, paving the way for more accountable and ethically sound AI systems.</description>
      <author>example@mail.com (Ruta Binkyte, Ivaxi Sheth, Zhijing Jin, Muhammad Havaei, Bernhardt Schölkopf, Mario Fritz)</author>
      <guid isPermaLink="false">2502.21123v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>A Non-contrast Head CT Foundation Model for Comprehensive Neuro-Trauma Triage</title>
      <link>http://arxiv.org/abs/2502.21106v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种用于检测多种神经创伤的3D基础模型，该模型通过利用大规模语言模型进行自动标注，并采用多模态微调技术将神经网络预先训练结果整合进一个综合性的神经创伤检测网络中。&lt;h4&gt;背景&lt;/h4&gt;AI和医学成像的进步为急诊头部CT图像解读提供了变革性潜力，在请求量增加及放射科医生短缺的情况下，这些进步有助于缩短评估时间并提高准确性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效准确地识别各种神经创伤的3D基础模型。&lt;h4&gt;方法&lt;/h4&gt;使用大规模语言模型自动生成全面的多标签注释，并通过预训练和多模态微调整合出血亚型分割和大脑解剖图谱到一个综合性的神经创伤检测网络中。&lt;h4&gt;主要发现&lt;/h4&gt;在与专家标注对比及与其他方法（如CT-CLIP）比较时，该模型显示出对包括出血、脑中线移位以及脑水肿等在内的多种神经创伤情况的优异分类准确率。通过加入特定于神经系统的特征，使得诊断能力得到了显著增强。&lt;h4&gt;结论&lt;/h4&gt;这项工作推动了医学影像领域基础模型的发展，并为未来AI辅助急诊放射学中的神经创伤诊断提供了基准。&lt;h4&gt;翻译&lt;/h4&gt;近期在人工智能和医疗成像领域的进展为紧急情况下的头部CT图像解读带来了变革性的潜力。这主要是为了减少评估时间并提高准确性，面对日益增长的扫描需求以及全球范围内放射科医生短缺的问题。该研究引入了一个3D基础模型用于检测各种神经创伤发现，并且具有高准确性和效率。通过使用大规模语言模型进行自动标注，生成了全面的多标签注释以识别严重情况。我们的方法包括对出血亚型分割和大脑解剖图谱预先训练神经网络，并将其整合进一个综合性的预训练神经创伤检测网络中，通过多模态微调实现集成。与专家标记对比以及与其他模型（如CT-CLIP）比较的结果表明，在主要的神经创伤发现上具有强大的分类准确性，例如出血和脑中线移位，以及其他不常见但危急的情况，例如脑水肿和动脉高密度。特定于神经系统的特征的整合显著提升了诊断能力，平均AUC为0.861（针对16种神经创伤情况）。这项工作推进了医学成像中的基础模型，并成为未来AI辅助急诊放射学中神经创伤诊断的一个基准点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in AI and medical imaging offer transformative potentialin emergency head CT interpretation for reducing assessment times and improvingaccuracy in the face of an increasing request of such scans and a globalshortage in radiologists. This study introduces a 3D foundation model fordetecting diverse neuro-trauma findings with high accuracy and efficiency.Using large language models (LLMs) for automatic labeling, we generatedcomprehensive multi-label annotations for critical conditions. Our approachinvolved pretraining neural networks for hemorrhage subtype segmentation andbrain anatomy parcellation, which were integrated into a pretrainedcomprehensive neuro-trauma detection network through multimodal fine-tuning.Performance evaluation against expert annotations and comparison with CT-CLIPdemonstrated strong triage accuracy across major neuro-trauma findings, such ashemorrhage and midline shift, as well as less frequent critical conditions suchas cerebral edema and arterial hyperdensity. The integration of neuro-specificfeatures significantly enhanced diagnostic capabilities, achieving an averageAUC of 0.861 for 16 neuro-trauma conditions. This work advances foundationmodels in medical imaging, serving as a benchmark for future AI-assistedneuro-trauma diagnostics in emergency radiology.</description>
      <author>example@mail.com (Youngjin Yoo, Bogdan Georgescu, Yanbo Zhang, Sasa Grbic, Han Liu, Gabriela D. Aldea, Thomas J. Re, Jyotipriya Das, Poikavila Ullaskrishnan, Eva Eibenberger, Andrei Chekkoury, Uttam K. Bodanapally, Savvas Nicolaou, Pina C. Sanelli, Thomas J. Schroeppel, Yvonne W. Lui, Eli Gibson)</author>
      <guid isPermaLink="false">2502.21106v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Are foundation models useful feature extractors for electroencephalography analysis?</title>
      <link>http://arxiv.org/abs/2502.21086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项研究探讨了基础模型在医学时间序列分析中的应用，特别是对于脑电图（EEG）数据的处理。通过一系列任务实验，包括年龄预测、癫痫检测等，研究表明这些基础模型能够提取有意义的时间序列特征，并且超越专业设计的EEG模型而无需领域适应。&lt;h4&gt;背景&lt;/h4&gt;自然语言处理和计算机视觉领域的基础模型取得了巨大成功，但在医疗时间序列分析（特别是脑电图数据）中应用的基础模型研究较少。随着这类任务的数据集越来越有限，探索这些基础模型在医学时间序列中的适用性至关重要。&lt;h4&gt;目的&lt;/h4&gt;评估基础模型在医学时间序列数据分析中的有效性，特别关注EEG信号的处理能力，并对比这些模型与专门设计的EEG模型的表现。&lt;h4&gt;方法&lt;/h4&gt;实验中采用了一系列任务来测试这些基础模型的功能，包括年龄预测、癫痫检测和临床相关的脑电图事件分类等。并通过对比分析验证了这些模型在诊断准确性方面的优势。&lt;h4&gt;主要发现&lt;/h4&gt;1. 基础模型能够提取有意义的EEG特征；2. 即使没有领域适应，基础模型也超过了专门设计的EEG模型的表现；3. 研究表明架构选择（如上下文长度）对诊断准确度有重大影响。&lt;h4&gt;结论&lt;/h4&gt;研究表明基础模型在医学时间序列分析中具有巨大潜力。通过提供通用的时间序列理解能力，这些模型减少了对大规模特定领域数据集的需求，并成为临床实践中的宝贵工具。&lt;h4&gt;翻译&lt;/h4&gt;自然语言处理和计算机视觉领域的基础模型的成功激发了其在一般时间序列分析中的类似应用尝试。尽管这些模型对于多种任务非常有效，但在医疗领域（尤其是具有有限数据的场景）的应用仍然未被充分探索。为了应对这一问题，我们研究了基础模型在涉及脑电图（EEG）的医学时间序列分析中效果，并通过一系列实验如年龄预测、癫痫检测以及临床相关的EEG事件分类，将它们的表现与专用的EEG模型进行了对比。我们的研究表明，基础模型能够提取有意义的时间序列特征，在没有领域适应的情况下也能超越专用模型，并且能够定位任务特异性的生物标记物。此外，我们还展示了诊断准确性很大程度上受到架构选择（例如上下文长度）的影响。总的来说，这项研究揭示了具备通用时间序列理解能力的基础模型消除了对大规模特定领域数据集的依赖性，使其成为临床实践中有价值的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The success of foundation models in natural language processing and computervision has motivated similar approaches for general time series analysis. Whilethese models are effective for a variety of tasks, their applicability inmedical domains with limited data remains largely unexplored. To address this,we investigate the effectiveness of foundation models in medical time seriesanalysis involving electroencephalography (EEG). Through extensive experimentson tasks such as age prediction, seizure detection, and the classification ofclinically relevant EEG events, we compare their diagnostic accuracy with thatof specialised EEG models. Our analysis shows that foundation models extractmeaningful EEG features, outperform specialised models even without domainadaptation, and localise task-specific biomarkers. Moreover, we demonstratethat diagnostic accuracy is substantially influenced by architectural choicessuch as context length. Overall, our study reveals that foundation models withgeneral time series understanding eliminate the dependency on largedomain-specific datasets, making them valuable tools for clinical practice.</description>
      <author>example@mail.com (Özgün Turgut, Felix S. Bott, Markus Ploner, Daniel Rueckert)</author>
      <guid isPermaLink="false">2502.21086v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>SwimVG: Step-wise Multimodal Fusion and Adaption for Visual Grounding</title>
      <link>http://arxiv.org/abs/2502.16786v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SwimVG的分步多模态融合和适应框架，旨在解决视觉接地任务中现有的方法在跨模态对齐不足以及计算成本高的问题。&lt;h4&gt;背景&lt;/h4&gt;当前大多数用于视觉定位的方法依赖于从预训练模型中单独传输视觉或语言知识，并通过堆叠视觉-语言变压器来实现多模态融合。然而这些方法限制了视觉和语言上下文之间的充分互动并带来较高的计算成本。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一种新的分步多模态融合和适应框架SwimVG。&lt;h4&gt;方法&lt;/h4&gt;该框架提出了逐步多模态提示（Swip）以及跨模态交互适配器（CIA），用于视觉接地任务。Swip通过逐令牌方式提高视觉和语言表示之间的对齐，而CIA在权重级别上促进跨模态融合。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在四个广泛使用的基准测试中，SwimVG表现出优异的能力并显著提高了效率。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法不仅能够有效解决现有方法的不足，而且具有参数高效的特点，并且通过逐步融合浅层到深层的跨模态特征，展示了其在视觉接地任务中的强大能力。&lt;h4&gt;翻译&lt;/h4&gt;视觉定位旨在通过自然语言确定图像区域，这严重依赖于跨模态对齐。现有的大多数方法通过完全微调单模预训练模型来传输视觉/语言知识，并使用简单的视觉-语言变压器堆叠进行多模态融合。然而，这些方法不仅限制了视觉和语言上下文之间的充分互动，还带来了显著的计算成本。因此，为了应对这些问题，我们探索了一种分步多模态融合和适应框架，即SwimVG。具体来说，SwimVG提出了逐步多模态提示（Swip）以及跨模态交互适配器（CIA），用于视觉接地任务，替代冗余的变压器堆叠进行多模态融合。Swip能够以逐令牌的方式分步提高视觉和语言表示之间的对齐。此外，权重级别的CIA通过跨模态互动进一步促进多模态融合。Swip和CIA都是参数高效的模式，并逐步将浅层到深层的跨模态特征融合在一起。实验结果在四个常用的基准测试上表明，SwimVG在效率方面具有显著的优势。我们的代码可以在https://github.com/liuting20/SwimVG获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/liuting20/swimvg&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual grounding aims to ground an image region through natural language,which heavily relies on cross-modal alignment. Most existing methods transfervisual/linguistic knowledge separately by fully fine-tuning uni-modalpre-trained models, followed by a simple stack of visual-language transformersfor multimodal fusion. However, these approaches not only limit adequateinteraction between visual and linguistic contexts, but also incur significantcomputational costs. Therefore, to address these issues, we explore a step-wisemultimodal fusion and adaption framework, namely SwimVG. Specifically, SwimVGproposes step-wise multimodal prompts (Swip) and cross-modal interactiveadapters (CIA) for visual grounding, replacing the cumbersome transformerstacks for multimodal fusion. Swip can improve {the} alignment between thevision and language representations step by step, in a token-level fusionmanner. In addition, weight-level CIA further promotes multimodal fusion bycross-modal interaction. Swip and CIA are both parameter-efficient paradigms,and they fuse the cross-modal features from shallow to deep layers gradually.Experimental results on four widely-used benchmarks demonstrate that SwimVGachieves remarkable abilities and considerable benefits in terms of efficiency.Our code is available at https://github.com/liuting20/SwimVG.</description>
      <author>example@mail.com (Liangtao Shi, Ting Liu, Xiantao Hu, Yue Hu, Quanjun Yin, Richang Hong)</author>
      <guid isPermaLink="false">2502.16786v2</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Accurate 3D Grapevine Structure Extraction from High-Resolution Point Clouds</title>
      <link>http://arxiv.org/abs/2502.20417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种针对葡萄藤3D建模的Smart-Tree算法改进版，采用基于图的方法解决传统骨架化算法在复杂结构上的挑战。&lt;h4&gt;背景&lt;/h4&gt;精确的葡萄藤3D建模对精准农业至关重要，特别是对于信息丰富的修剪决策和自动化管理技术。然而，葡萄藤复杂的结构给传统的骨架化算法带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种适用于葡萄藤独特特性的三维建模方法，改善传统Smart-Tree算法在处理复杂结构上的效果。&lt;h4&gt;方法&lt;/h4&gt;提出了基于图的方法来区分骨架化过程中的个体枝条，并通过注释的现实世界点云数据进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;新方法相比原始的Smart-Tree算法，在F1分数上提高了15.8%，表明改进的有效性。&lt;h4&gt;结论&lt;/h4&gt;该研究推进了葡萄藤三维建模技术的发展，有可能通过更精确和自动化的农业实践提高葡萄生产的可持续性和盈利能力。&lt;h4&gt;翻译&lt;/h4&gt;准确地对葡萄藤进行3D建模对于精准种植至关重要，特别是在信息丰富的修剪决策以及自动化管理技术方面。然而，由于葡萄藤的复杂结构，传统的骨架化算法面临着重大挑战。本文提出了一种针对Smart-Tree算法改进的方法来应对葡萄藤的独特特点，并使用基于图的方式来解决骨架化的歧义问题。该方法能够区分出每个枝条的骨架结构，这对于精确分析和管理至关重要。我们通过使用注释过的现实世界中葡萄藤点云数据验证了我们的方法的有效性，在F1评分上较原始Smart-Tree算法提高了15.8%。这项研究为3D葡萄藤建模技术的发展做出了贡献，并有可能通过更加准确且自动化的种植实践提高葡萄生产的可持续性和盈利能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 3D modelling of grapevines is crucial for precision viticulture,particularly for informed pruning decisions and automated managementtechniques. However, the intricate structure of grapevines poses significantchallenges for traditional skeletonization algorithms. This paper presents anadaptation of the Smart-Tree algorithm for 3D grapevine modelling, addressingthe unique characteristics of grapevine structures. We introduce a graph-basedmethod for disambiguating skeletonization. Our method delineates individualcane skeletons, which are crucial for precise analysis and management. Wevalidate our approach using annotated real-world grapevine point clouds,demonstrating improvement of 15.8% in the F1 score compared to the originalSmart-Tree algorithm. This research contributes to advancing 3D grapevinemodelling techniques, potentially enhancing both the sustainability andprofitability of grape production through more precise and automatedviticulture practices</description>
      <author>example@mail.com (Harry Dobbs, Casey Peat, Oliver Batchelor, James Atlas, Richard Green)</author>
      <guid isPermaLink="false">2502.20417v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Can We Simplify Slide-level Fine-tuning of Pathology Foundation Models?</title>
      <link>http://arxiv.org/abs/2502.20823v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的策略SiMLP，通过简单的非线性映射结合均值池化和多层感知机来适应基于切片级别的任务，超越了传统的MIL方法。&lt;h4&gt;背景&lt;/h4&gt;计算病理学中基础模型的出现已经改变了组织病理图像分析的方法，其中全滑动影像（WSI）诊断是核心应用。以往主要采用弱监督微调通过多重实例学习（MIL）来适应基础模型以处理WSIs。&lt;h4&gt;目的&lt;/h4&gt;展示SiMLP策略在多种下游任务中的优越性，并挑战传统的基于MIL的微调范式。&lt;h4&gt;方法&lt;/h4&gt;提出了一种简单非线性映射策略，称为SiMLP，该策略结合均值池化和多层感知机来将基础模型从补丁级别适应到切片级别任务。&lt;h4&gt;主要发现&lt;/h4&gt;1. SiMLP在大规模癌症分类任务中超越了流行MIL方法3.52%，显示强大的少样本分类能力；2. 在肺部肿瘤亚型分类方面，SiMLP表现出显著的鲁棒性和可转移性。3. SiMLP可以不需要复杂的基于MIL的学习过程来适应WSI分析。&lt;h4&gt;结论&lt;/h4&gt;研究结果挑战了传统的基于MIL的微调范式，并表明仅通过任务无关表示策略即可有效调整基础模型以进行WSI分析，为未来数字病理学研究提供了新的视角和方法论。&lt;h4&gt;翻译&lt;/h4&gt;计算病理学中的基础模型出现已经改变了组织病理图像分析的方法，其中全滑动影像（WSI）诊断是核心应用。以往主要采用弱监督微调通过多重实例学习（MIL）来适应基础模型以处理WSIs。然而，在这项工作中我们提出了一种关键的实验发现：一种简单的非线性映射策略结合均值池化和多层感知机，称为SiMLP，可以有效将基于补丁级别的基础模型适配到切片级别任务而不需要复杂MIL基的学习方法。通过广泛的跨多种下游任务实验，我们展示了SiMLP与最新技术相比的优越性能，在大规模癌症分类任务中超越了流行MIL方法3.52%。此外，SiMLP在少样本分类中表现出强大的学习能力，并且仍然与其他预训练于数十万张切片上的切片级别基础模型竞争。最后，SiMLP在肺癌亚型分类方面表现出显著的鲁棒性和可转移性。总的来说，我们的发现挑战了传统的基于MIL的微调范式，表明仅通过任务无关表示策略就可以有效地将基础模型适配到WSI分析中。这些见解为未来数字病理学研究提供了一个独特且具有意义的新视角，并为此类研究铺平了更高效和广泛适用的方法论的道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of foundation models in computational pathology has transformedhistopathological image analysis, with whole slide imaging (WSI) diagnosisbeing a core application. Traditionally, weakly supervised fine-tuning viamultiple instance learning (MIL) has been the primary method for adaptingfoundation models to WSIs. However, in this work we present a key experimentalfinding: a simple nonlinear mapping strategy combining mean pooling and amultilayer perceptron, called SiMLP, can effectively adapt patch-levelfoundation models to slide-level tasks without complex MIL-based learning.Through extensive experiments across diverse downstream tasks, we demonstratethe superior performance of SiMLP with state-of-the-art methods. For instance,on a large-scale pan-cancer classification task, SiMLP surpasses popularMIL-based methods by 3.52%. Furthermore, SiMLP shows strong learning ability infew-shot classification and remaining highly competitive with slide-levelfoundation models pretrained on tens of thousands of slides. Finally, SiMLPexhibits remarkable robustness and transferability in lung cancer subtyping.Overall, our findings challenge the conventional MIL-based fine-tuningparadigm, demonstrating that a task-agnostic representation strategy alone caneffectively adapt foundation models to WSI analysis. These insights offer aunique and meaningful perspective for future research in digital pathology,paving the way for more efficient and broadly applicable methodologies.</description>
      <author>example@mail.com (Jiawen Li, Jiali Hu, Qiehe Sun, Renao Yan, Minxi Ouyang, Tian Guan, Anjia Han, Chao He, Yonghong He)</author>
      <guid isPermaLink="false">2502.20823v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>SemiSAM+: Rethinking Semi-Supervised Medical Image Segmentation in the Era of Foundation Models</title>
      <link>http://arxiv.org/abs/2502.20749v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种基于提示的基础模型驱动的半监督学习框架SemiSAM+，用于提高医疗图像分割任务中有限标注数据的学习效率。&lt;h4&gt;背景&lt;/h4&gt;深度学习在医学影像分割中的应用通常需要大量的标记数据进行训练，这在临床环境中由于注释成本高而难以实施。半监督学习（SSL）作为一种依赖较少专家标注的方法逐渐受到关注。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于提示的基础模型驱动的半监督框架SemiSAM+，以期通过有限数量的标签实现高效的医学影像分割任务。&lt;h4&gt;方法&lt;/h4&gt;该框架由一个或多个可提示的基础模型和一个特定于任务的学习型模型组成。在给定的新分割任务中，训练过程包括学习型模型与基础模型之间的协作，在此基础上学习型模型生成位置提示并接收来自基础模型的伪标签监督。&lt;h4&gt;主要发现&lt;/h4&gt;SemiSAM+框架在两个公共数据集及一家医院内部临床数据集中展示了显著性能提升，特别是在标注数量极为有限的情况下效果尤为突出。该框架还展现了强大的适应性作为即插即用策略可以轻松应用于不同类型的特定任务和通用模型中。&lt;h4&gt;结论&lt;/h4&gt;论文提出了一种新的半监督学习方法SemiSAM+，它通过结合基础模型的泛化能力和学习型模型的专业能力，在医学图像分割任务中实现了显著性能改进。这种方法为解决有限标签数据集下的高效训练提供了可能路径，并展示了良好的扩展性和通用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based medical image segmentation typically requires largeamount of labeled data for training, making it less applicable in clinicalsettings due to high annotation cost. Semi-supervised learning (SSL) hasemerged as an appealing strategy due to its less dependence on acquiringabundant annotations from experts compared to fully supervised methods. Beyondexisting model-centric advancements of SSL by designing novel regularizationstrategies, we anticipate a paradigmatic shift due to the emergence ofpromptable segmentation foundation models with universal segmentationcapabilities using positional prompts represented by Segment Anything Model(SAM). In this paper, we present SemiSAM+, a foundation model-driven SSLframework to efficiently learn from limited labeled data for medical imagesegmentation. SemiSAM+ consists of one or multiple promptable foundation modelsas generalist models, and a trainable task-specific segmentation model asspecialist model. For a given new segmentation task, the training is based onthe specialist-generalist collaborative learning procedure, where the trainablespecialist model delivers positional prompts to interact with the frozengeneralist models to acquire pseudo-labels, and then the generalist modeloutput provides the specialist model with informative and efficient supervisionwhich benefits the automatic segmentation and prompt generation in turn.Extensive experiments on two public datasets and one in-house clinical datasetdemonstrate that SemiSAM+ achieves significant performance improvement,especially under extremely limited annotation scenarios, and shows strongefficiency as a plug-and-play strategy that can be easily adapted to differentspecialist and generalist models.</description>
      <author>example@mail.com (Yichi Zhang, Bohao Lv, Le Xue, Wenbo Zhang, Yuchen Liu, Yu Fu, Yuan Cheng, Yuan Qi)</author>
      <guid isPermaLink="false">2502.20749v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>STPro: Spatial and Temporal Progressive Learning for Weakly Supervised Spatio-Temporal Grounding</title>
      <link>http://arxiv.org/abs/2502.20678v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR'25 Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究了弱监督时空视频定位任务，提出了一种新的学习框架STPro。&lt;h4&gt;背景&lt;/h4&gt;现有的视觉语言基础模型虽然具备零样本推理能力，但在执行弱监督时空视频定位任务时缺乏必要的时空定位能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的不足，设计了一个能够进行时空预测的学习系统。&lt;h4&gt;方法&lt;/h4&gt;引入了Tubelet Referral Grounding (TRG)，并在此基础上提出了一个新颖的进步学习框架STPro。该框架包含两个关键模块：Sub-Action Temporal Curriculum Learning (SA-TCL) 和 Congestion-Guided Spatial Curriculum Learning (CG-SCL)。&lt;h4&gt;主要发现&lt;/h4&gt;通过在三个基准数据集上的实验，证明了所提出的STPro方法的有效性，并且在VidSTG-Declarative和HCSTVG-v1两个数据集中分别取得了比之前最好的结果高出1.0% 和 3.0%的成绩。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为弱监督时空视频定位任务提供了一个新的解决方案，提高了该领域的技术水平。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们研究了使用文本查询而没有任何边界框监督的弱监督时空视频定位（WSTVG）任务。受到近期视觉-语言基础模型进展的启发，我们探索了这些模型在WSTVG中的实用性，利用它们的零样本接地能力。然而，简单地调整这些模型无法满足必要的时空定点功能。为弥补这一差距，我们提出了Tubelet Referral Grounding（TRG），该方法将文本查询与管状体连接起来以实现时空预测。尽管有潜力，但TRG在组合动作理解和密集场景方面仍然存在挑战。为了克服这些问题，我们提出了一种新的渐进式学习框架STPro，具有两个关键模块：Sub-Action Temporal Curriculum Learning（SA-TCL）和Congestion-Guided Spatial Curriculum Learning（CG-SCL）。在三个基准数据集上进行实验后，我们的方法实现了最先进的结果，在VidSTG-Declarative和HCSTVG-v1中分别提高了1.0% 和 3.0%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work we study Weakly Supervised Spatio-Temporal Video Grounding(WSTVG), a challenging task of localizing subjects spatio-temporally in videosusing only textual queries and no bounding box supervision. Inspired by recentadvances in vision-language foundation models, we investigate their utility forWSTVG, leveraging their zero-shot grounding capabilities. However, we find thata simple adaptation lacks essential spatio-temporal grounding abilities. Tobridge this gap, we introduce Tubelet Referral Grounding (TRG), which connectstextual queries to tubelets to enable spatio-temporal predictions. Despite itspromise, TRG struggles with compositional action understanding and dense scenescenarios. To address these limitations, we propose STPro, a novel progressivelearning framework with two key modules: (1) Sub-Action Temporal CurriculumLearning (SA-TCL), which incrementally builds compositional actionunderstanding, and (2) Congestion-Guided Spatial Curriculum Learning (CG-SCL),which adapts the model to complex scenes by spatially increasing taskdifficulty. STPro achieves state-of-the-art results on three benchmarkdatasets, with improvements of 1.0% on VidSTG-Declarative and 3.0% onHCSTVG-v1.</description>
      <author>example@mail.com (Aaryan Garg, Akash Kumar, Yogesh S Rawat)</author>
      <guid isPermaLink="false">2502.20678v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>SciceVPR: Stable Cross-Image Correlation Enhanced Model for Visual Place Recognition</title>
      <link>http://arxiv.org/abs/2502.20676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种名为SciceVPR的稳定跨图相关增强模型，用于视觉位置识别（VPR），旨在生成具有区分性和稳定性全局描述符。&lt;h4&gt;背景&lt;/h4&gt;当前最先进的VPR模型依赖于强大的基础模型DINOv2提取全局特征，并且要么通过探索跨图像相关性来提高性能，要么采用耗时的两阶段重排名策略。但现有工作仅利用了DINOv2的最终输出结果，导致检索效果不稳定。&lt;h4&gt;目的&lt;/h4&gt;提出一种改进方法以克服现有技术中描述符不稳定性问题，并充分利用DINOv2模型提供的特征表示能力，隐式编码有价值的上下文知识。&lt;h4&gt;方法&lt;/h4&gt;SciceVPR通过一个多层特征融合模块捕捉任务相关通道和空间信息；同时利用图像之间不变的相关性作为有价值的知识融入增强自编码器，从而获得对领域转换具有鲁棒性的全局特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，SciceVPR-B变体在多个不同领域条件的数据集上优于现有的单输入一步方法。而SciceVPR-L版本性能与最先进的两步模型相当，在挑战性东京24/7数据集中召回率@1高出3%以上。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够生成稳定的全局描述符，提高视觉位置识别的准确性和鲁棒性，并在多个数据集上优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;Visual Place Recognition（VPR）是机器人和自主系统的一个主要挑战，目标是仅基于图像的视觉特征预测其位置。最先进的模型使用强大的基础模型DINOv2作为骨干网络来提取全局描述符。这些模型要么通过探索跨图相关性提高性能，要么采用耗时的两阶段重排名策略以达到更好的效果。然而，现有的工作仅仅利用了DINOv2的最终输出，并且当前的跨图相关会导致检索结果不稳定。为了生成具有区分性和稳定性的全局描述符，本文提出了名为SciceVPR的增强模型。该模型探索了DINOv2在提供有用特征表示方面的全部潜力，隐式地编码有价值的上下文知识。具体而言，SciceVPR首先利用一个多层特征融合模块捕捉任务相关的通道和空间信息；其次考虑图像批次内的不变相关性作为有价值的知识融入提出的自增强编解码器中。这样，SciceVPR可以获取相对领域转换（例如光照、天气和视角变化）的全局特征具有鲁棒性的特性。实验结果表明，基本版本SciceVPR-B在多种不同条件的数据集上优于现有的单输入一步方法。大型变体SciceVPR-L与最先进的两步模型相当，在挑战性东京24/7数据集中召回率@1高出3%以上。我们的代码将发布于https://github.com/shuimushan/SciceVPR。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Place Recognition (VPR) is a major challenge for robotics andautonomous systems, with the goal of predicting the location of an image basedsolely on its visual features. State-of-the-art (SOTA) models extract globaldescriptors using the powerful foundation model DINOv2 as backbone. Thesemodels either explore the cross-image correlation or propose a time-consumingtwo-stage re-ranking strategy to achieve better performance. However, existingworks only utilize the final output of DINOv2, and the current cross-imagecorrelation causes unstable retrieval results. To produce both discriminativeand constant global descriptors, this paper proposes stable cross-imagecorrelation enhanced model for VPR called SciceVPR. This model explores thefull potential of DINOv2 in providing useful feature representations thatimplicitly encode valuable contextual knowledge. Specifically, SciceVPR firstuses a multi-layer feature fusion module to capture increasingly detailedtask-relevant channel and spatial information from the multi-layer output ofDINOv2. Secondly, SciceVPR considers the invariant correlation between imageswithin a batch as valuable knowledge to be distilled into the proposedself-enhanced encoder. In this way, SciceVPR can acquire fairly robust globalfeatures regardless of domain shifts (e.g., changes in illumination, weatherand viewpoint between pictures taken in the same place). Experimental resultsdemonstrate that the base variant, SciceVPR-B, outperforms SOTA one-stagemethods with single input on multiple datasets with varying domain conditions.The large variant, SciceVPR-L, performs on par with SOTA two-stage models,scoring over 3% higher in Recall@1 compared to existing models on thechallenging Tokyo24/7 dataset. Our code will be released athttps://github.com/shuimushan/SciceVPR.</description>
      <author>example@mail.com (Shanshan Wan, Yingmei Wei, Lai Kang, Tianrui Shen, Haixuan Wang, Yee-Hong Yang)</author>
      <guid isPermaLink="false">2502.20676v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>CoCa-CXR: Contrastive Captioners Learn Strong Temporal Structures for Chest X-Ray Vision-Language Understanding</title>
      <link>http://arxiv.org/abs/2502.20509v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;视觉-语言模型在医学图像分析中发挥了重要作用，通过从图像和报告中学到丰富的语义信息来提高图像理解。该研究针对胸部X光片（CXR）的报告处理流程提出了一种新的方法。&lt;h4&gt;背景&lt;/h4&gt;现有努力主要集中在图像与文本表示的一致性上以增强图像理解，但针对CXR报告中常见的时间参照进行图像对之间的语义差异对齐的问题则较少探索。&lt;h4&gt;目的&lt;/h4&gt;提出了两个组件来解决这一问题：一个用于处理CXR报告的流程和CoCa-CXR模型，该模型能够描述图像及其时间进程，并识别配对CXR图像中的局部差异。&lt;h4&gt;方法&lt;/h4&gt;(1) 提出了一种基于大规模语言模型（LLM）的CXR报告处理流水线来提取时态结构。(2) 开发了名为CoCa-CXR的对比性标题生成器，以学习描述图像及其时间变化的方法。该模型包含了一个新颖的区域交叉注意力模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CoCa-CXR在进展分析和报告生成方面优于先前方法，在MS-CXR-T进展分类上的平均测试准确率达到了65.0%，超过之前的SOTA模型BioViL-T 4.8%。同时在MIMIC-CXR上取得了24.2%的RadGraph F1，与Med-Gemini基础模型相当。&lt;h4&gt;结论&lt;/h4&gt;CoCa-CXR通过新的区域交叉注意力模块和创新性的处理流程，在医学图像的时间进程分析中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;视觉-语言模型由于能够从图像和报告中学到丰富的语义信息，在医学影像分析领域具有重要作用。以往的研究重点在于更好地对齐图像和文本表示以增强图像理解。然而，尽管胸部X射线（CXR）报告中通常会明确参考之前的影像，但如何将进展描述与成对影像之间的语义差异进行有效对齐仍有待进一步研究。为此，我们提出了两种解决方法：一种用于处理CXR报告的流水线和一个对比性标题生成器CoCa-CXR，用于学习描绘图像及其时间变化的方法。实验表明，该模型在进展分析及报告生成上均优于现有技术，并且在MS-CXR-T进步分类任务中平均测试准确率达到了65.0%，超过之前的SOTA模型BioViL-T 4.8%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models have proven to be of great benefit for medical imageanalysis since they learn rich semantics from both images and reports. Priorefforts have focused on better alignment of image and text representations toenhance image understanding. However, though explicit reference to a priorimage is common in Chest X-Ray (CXR) reports, aligning progression descriptionswith the semantics differences in image pairs remains under-explored. In thiswork, we propose two components to address this issue. (1) A CXR reportprocessing pipeline to extract temporal structure. It processes reports with alarge language model (LLM) to separate the description and comparison contexts,and extracts fine-grained annotations from reports. (2) A contrastive captionermodel for CXR, namely CoCa-CXR, to learn how to both describe images and theirtemporal progressions. CoCa-CXR incorporates a novel regional cross-attentionmodule to identify local differences between paired CXR images. Extensiveexperiments show the superiority of CoCa-CXR on both progression analysis andreport generation compared to previous methods. Notably, on MS-CXR-Tprogression classification, CoCa-CXR obtains 65.0% average testing accuracy onfive pulmonary conditions, outperforming the previous state-of-the-art (SOTA)model BioViL-T by 4.8%. It also achieves a RadGraph F1 of 24.2% on MIMIC-CXR,which is comparable to the Med-Gemini foundation model.</description>
      <author>example@mail.com (Yixiong Chen, Shawn Xu, Andrew Sellergren, Yossi Matias, Avinatan Hassidim, Shravya Shetty, Daniel Golden, Alan Yuille, Lin Yang)</author>
      <guid isPermaLink="false">2502.20509v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>OpenFly: A Versatile Toolchain and Large-scale Benchmark for Aerial Vision-Language Navigation</title>
      <link>http://arxiv.org/abs/2502.18041v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Vision-Language Navigation (VLN)在机器人导航领域扮演着重要角色，尤其是在具身人工智能中。本文提出了OpenFly平台，旨在解决户外空中VLN数据收集困难的问题，并构建了大规模的数据集和模型。&lt;h4&gt;背景&lt;/h4&gt;室内VLN已经被广泛研究，但室外空中VLN由于涉及的视野广阔、数据采集难度大而较少被探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的平台OpenFly来促进户外空中的Vision-Language Navigation（VLN）的发展，包括工具链开发和大规模数据集构建。&lt;h4&gt;方法&lt;/h4&gt;{'开发自动化工具链': '自动收集点云数据、进行场景语义分割、生成飞行轨迹以及创建指令', '构建大型数据集': '使用多种渲染引擎和技术生成包含100k轨迹的大规模数据集，涵盖多样化的高度和长度，并通过3D Gaussian Splatting技术增强数据的真实感。', '提出OpenFly-Agent模型': '基于关键帧的VLN模型，可以接收语言指令、当前观察结果以及历史上的关键帧作为输入，并直接输出飞行动作'}&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的分析和实验展示了OpenFly平台及其核心算法OpenFly-Agent的优越性能。&lt;h4&gt;结论&lt;/h4&gt;开源了工具链、数据集及代码，旨在促进户外空中VLN的研究和发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已包含详细内容，无需额外翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Navigation (VLN) aims to guide agents through an environmentby leveraging both language instructions and visual cues, playing a pivotalrole in embodied AI. Indoor VLN has been extensively studied, whereas outdooraerial VLN remains underexplored. The potential reason is that outdoor aerialview encompasses vast areas, making data collection more challenging, whichresults in a lack of benchmarks. To address this problem, we propose OpenFly, aplatform comprising a versatile toolchain and large-scale benchmark for aerialVLN. Firstly, we develop a highly automated toolchain for data collection,enabling automatic point cloud acquisition, scene semantic segmentation, flighttrajectory creation, and instruction generation. Secondly, based on thetoolchain, we construct a large-scale aerial VLN dataset with 100ktrajectories, covering diverse heights and lengths across 18 scenes. Thecorresponding visual data are generated using various rendering engines andadvanced techniques, including Unreal Engine, GTA V, Google Earth, and 3DGaussian Splatting (3D GS). All data exhibit high visual quality. Particularly,3D GS supports real-to-sim rendering, further enhancing the realism of thedataset. Thirdly, we propose OpenFly-Agent, a keyframe-aware VLN model, whichtakes language instructions, current observations, and historical keyframes asinput, and outputs flight actions directly. Extensive analyses and experimentsare conducted, showcasing the superiority of our OpenFly platform andOpenFly-Agent. The toolchain, dataset, and codes will be open-sourced.</description>
      <author>example@mail.com (Yunpeng Gao, Chenhui Li, Zhongrui You, Junli Liu, Zhen Li, Pengan Chen, Qizhi Chen, Zhonghan Tang, Liansheng Wang, Penghui Yang, Yiwen Tang, Yuhang Tang, Shuai Liang, Songyi Zhu, Ziqin Xiong, Yifei Su, Xinyi Ye, Jianan Li, Yan Ding, Dong Wang, Zhigang Wang, Bin Zhao, Xuelong Li)</author>
      <guid isPermaLink="false">2502.18041v2</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Diagnosing COVID-19 Severity from Chest X-Ray Images Using ViT and CNN Architectures</title>
      <link>http://arxiv.org/abs/2502.16622v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Upon reflection, the final version of this work does not meet the  author's personal standards for thoroughness and clarity. As a result, the  authors have chosen to withdraw the paper to prevent the dissemination of  work that may not fully reflect the level of quality they strive to maintain&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过合并三个来源创建了一个大型的COVID严重程度数据集，探讨了迁移学习在使用ImageNet和CXR预训练模型以及视觉变换器(ViTs)进行病情预测方面的有效性。&lt;h4&gt;背景&lt;/h4&gt;新冠肺炎大流行导致医疗资源紧张，并引发了关于机器学习如何减轻医生负担并有助于诊断的讨论。胸部X光片（CXRs）用于诊断COVID-19，但很少有研究从CXRs预测患者的病情严重程度。&lt;h4&gt;目的&lt;/h4&gt;探讨迁移学习在基于图像的数据集中的表现以及其对新冠肺炎患者病情预测的贡献。&lt;h4&gt;方法&lt;/h4&gt;本研究使用了ImageNet和CXR预训练模型及视觉变换器(ViTs)，并在此基础上进行了严重程度回归与分类任务的研究。&lt;h4&gt;主要发现&lt;/h4&gt;预训练DenseNet161模型在三种严重程度预测问题上表现最佳，总体准确率为80%，轻度、中度和重度病例的分别准确率分别为77.3%、83.9%和70%。视觉变换器(ViT)在回归任务中的均方绝对误差为0.5676。&lt;h4&gt;结论&lt;/h4&gt;迁移学习方法，特别是预训练模型，可以有效地用于基于图像的数据集来预测新冠肺炎的病情严重程度。&lt;h4&gt;翻译&lt;/h4&gt;摘要提供了英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/stwhitfield/covid-severity&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The COVID-19 pandemic strained healthcare resources and prompted discussionabout how machine learning can alleviate physician burdens and contribute todiagnosis. Chest x-rays (CXRs) are used for diagnosis of COVID-19, but fewstudies predict the severity of a patient's condition from CXRs. In this study,we produce a large COVID severity dataset by merging three sources andinvestigate the efficacy of transfer learning using ImageNet- andCXR-pretrained models and vision transformers (ViTs) in both severityregression and classification tasks. A pretrained DenseNet161 model performedthe best on the three class severity prediction problem, reaching 80% accuracyoverall and 77.3%, 83.9%, and 70% on mild, moderate and severe cases,respectively. The ViT had the best regression results, with a mean absoluteerror of 0.5676 compared to radiologist-predicted severity scores. Theproject's source code is publicly available.</description>
      <author>example@mail.com (Luis Lara, Lucia Eve Berger, Rajesh Raju)</author>
      <guid isPermaLink="false">2502.16622v3</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning through Enhanced Sufficient Representation: Enriching Source Domain Knowledge with Target Data</title>
      <link>http://arxiv.org/abs/2502.20414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  44 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一种新的迁移学习方法——增强充分表示的迁移学习（TESR），旨在解决传统迁移学习方法因模型假设过于严格和源域与目标域相似度要求高而导致的问题。&lt;h4&gt;背景&lt;/h4&gt;随着数据可用性的限制，迁移学习成为了解决这些问题的重要方法。它通过从已建立良好的源领域向不熟悉的靶领域转移知识来实现这一目标。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的迁移学习方法TESR，旨在克服传统方法的局限性，提高模型在不同任务中的适应性和灵活性。&lt;h4&gt;方法&lt;/h4&gt;首先估计出一个充分和不变的表现形式，然后通过来自靶数据的独立成分增强该表现形式，使其成为针对特定目标领域的充足表示且易于适应其特性。此方法不依赖于跨不同任务的相似模型结构假设。&lt;h4&gt;主要发现&lt;/h4&gt;TESR能够在有限样本环境下有效工作，并在模拟研究和实际应用中验证了它的性能。&lt;h4&gt;结论&lt;/h4&gt;论文展示了TESR作为迁移学习的一种灵活有效的策略，适用于广泛的监督学习问题。&lt;h4&gt;翻译&lt;/h4&gt;迁移学习是一种解决数据可用性限制的重要方法，通过从已建立良好的源领域向不熟悉的靶领域转移知识来实现。然而，传统的方法往往因为过于严格的模型假设和需要高度相似的域模型而面临挑战。本文提出了一种新的方法——增强充分表示的迁移学习（TESR）。该方法首先估计出一个充分不变的表现形式，并通过来自靶数据的独立成分进一步增强它，以适应特定目标领域的特性并确保其充足性。主要优点是不依赖于假设跨任务相似模型结构的存在；例如源域可以使用回归模型而靶域的任务可能是分类。这种灵活性使得TESR能够应用于广泛的监督学习问题中。论文通过理论属性探索和模拟研究以及实际数据应用验证了TESR的性能，证明它在有限样本设置下的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning is an important approach for addressing the challengesposed by limited data availability in various applications. It accomplishesthis by transferring knowledge from well-established source domains to a lessfamiliar target domain. However, traditional transfer learning methods oftenface difficulties due to rigid model assumptions and the need for a high degreeof similarity between source and target domain models. In this paper, weintroduce a novel method for transfer learning called Transfer learning throughEnhanced Sufficient Representation (TESR). Our approach begins by estimating asufficient and invariant representation from the source domains. Thisrepresentation is then enhanced with an independent component derived from thetarget data, ensuring that it is sufficient for the target domain and adaptableto its specific characteristics. A notable advantage of TESR is that it doesnot rely on assuming similar model structures across different tasks. Forexample, the source domain models can be regression models, while the targetdomain task can be classification. This flexibility makes TESR applicable to awide range of supervised learning problems. We explore the theoreticalproperties of TESR and validate its performance through simulation studies andreal-world data applications, demonstrating its effectiveness in finite samplesettings.</description>
      <author>example@mail.com (Yeheng Ge, Xueyu Zhou, Jian Huang)</author>
      <guid isPermaLink="false">2502.20414v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>CurviTrack: Curvilinear Trajectory Tracking for High-speed Chase of a USV</title>
      <link>http://arxiv.org/abs/2502.21303v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于拖曳感知模型与MPC相结合的方法，用于解决海洋环境中异构机器人团队由于需要让自主飞行器着陆充电而导致的时间和能量损失问题。&lt;h4&gt;背景&lt;/h4&gt;在海事应用中使用异构机器人团队会导致时间及能源的浪费，特别是在自主飞行器需要降落以重新充电时。这不仅影响任务效率，还限制了海洋车辆执行复杂机动的能力。&lt;h4&gt;目的&lt;/h4&gt;解决现有技术中的预测误差大、预测准确性低以及跟踪性能不足的问题，提高在动态环境下的着陆成功率。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新的拖曳感知模型，并将其与MPC（模型预测控制）结合使用，以实现高速曲线轨迹下的追踪和降落，无需通信即可完成任务。&lt;h4&gt;主要发现&lt;/h4&gt;相比现有技术，该方法降低了40%的预测误差，提高了预测准确性的三倍，并且在跟踪性能上提升了30%，成功着陆率提高到了原来的四倍，尤其是在执行剧烈转弯等传统海上任务难以应对的情况下表现尤为突出。&lt;h4&gt;结论&lt;/h4&gt;通过两个不同实际场景中大小不同的海洋船只测试验证了该方法的有效性，并进一步使用模拟中的统计分析来展示其鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;异构机器人团队在海洋环境中使用时，当海洋车辆必须停止执行任务以让自主飞行器降落进行充电时会遭受时间和能源的惩罚。本文提出了一种解决方案，利用一种新的拖曳感知模型和MPC（模型预测控制）相结合的方法来跟踪并在高速曲线轨迹中实现不依赖通信的着陆。这种方法相比于最先进的技术可以降低40%的预测误差，并提供了预测准确性的三倍提高。因此，在进行剧烈转弯等常规海上任务难以处理的情况下，这导致了30%的追踪性能改进和40%更高的在移动USV上成功的着陆概率。我们在两种不同的现实场景中测试了我们的方法，使用不同大小的海洋船只，并通过模拟中的统计分析进一步证实我们方法的稳健性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2025.3546079&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous robot teams used in marine environments incur time-and-energypenalties when the marine vehicle has to halt the mission to allow theautonomous aerial vehicle to land for recharging. In this paper, we present asolution for this problem using a novel drag-aware model formulation which iscoupled with MPC, and therefore, enables tracking and landing during high-speedcurvilinear trajectories of an USV without any communication. Compared to thestate-of-the-art, our approach yields 40% decrease in prediction errors, andprovides a 3-fold increase in certainty of predictions. Consequently, thisleads to a 30% improvement in tracking performance and 40% higher success inlanding on a moving USV even during aggressive turns that are unfeasible forconventional marine missions. We test our approach in two different real-worldscenarios with marine vessels of two different sizes and further solidify ourresults through statistical analysis in simulation to demonstrate therobustness of our method.</description>
      <author>example@mail.com (Parakh M. Gupta, Ondřej Procházka, Tiago Nascimento, Martin Saska)</author>
      <guid isPermaLink="false">2502.21303v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Back to the Future Cyclopean Stereo: a human perception approach unifying deep and geometric constraints</title>
      <link>http://arxiv.org/abs/2502.21280v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种结合几何模型和学习到的立体视觉特征的方法，用于改善3D表面建模。&lt;h4&gt;背景&lt;/h4&gt;传统的立体视觉方法在处理深度不连续性和遮挡时存在挑战。仅基于数据驱动的方法难以捕捉关键的视觉信息。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够利用几何形状描述优势，并通过单目先验模型来增强遮挡和缺乏纹理区域建模的新系统。&lt;h4&gt;方法&lt;/h4&gt;1. 使用类独眼的模型提供分析性3D表面模型，这些模型包含了深度不连续性和遮挡；2. 结合学习到的立体视觉特征；3. 调用单目先验表面模型填补遮挡或缺乏纹理的区域。&lt;h4&gt;主要发现&lt;/h4&gt;该方法结果与现有的数据驱动方法相当，但在视觉质量上有显著提升，证明了三维几何模型的重要性。&lt;h4&gt;结论&lt;/h4&gt;理解并建模三维形状属性对于计算机视觉研究至关重要，并且这种改进可以在虚拟现实和机器人技术中应用，以改善用户体验或减少错误。&lt;h4&gt;翻译&lt;/h4&gt;我们在立体视觉方面进行了创新，通过提供由独眼模型视角下的分析性3D表面模型来明确处理深度不连续性和遮挡问题。结合几何基础与学习到的立体特征使我们的系统能够从两种方法的优势中获益。此外，在数据匹配不足的情况下使用单目先验模型填补遮挡或缺乏纹理区域。我们的结果已达到现有纯数据驱动方法同等水平，但在视觉质量上更胜一筹，突显了3D几何模型捕捉关键视觉信息的重要性。这样的定性改进可能在虚拟现实中找到应用价值，以改善人类体验，并且在机器人技术中减少关键错误方面同样重要。本研究旨在证明理解并建模三维表面的几何属性对计算机视觉研究有益。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We innovate in stereo vision by explicitly providing analytical 3D surfacemodels as viewed by a cyclopean eye model that incorporate depthdiscontinuities and occlusions. This geometrical foundation combined withlearned stereo features allows our system to benefit from the strengths of bothapproaches. We also invoke a prior monocular model of surfaces to fill inocclusion regions or texture-less regions where data matching is notsufficient. Our results already are on par with the state-of-the-art purelydata-driven methods and are of much better visual quality, emphasizing theimportance of the 3D geometrical model to capture critical visual information.Such qualitative improvements may find applicability in virtual reality, for abetter human experience, as well as in robotics, for reducing critical errors.Our approach aims to demonstrate that understanding and modeling geometricalproperties of 3D surfaces is beneficial to computer vision research.</description>
      <author>example@mail.com (Sherlon Almeida da Silva, Davi Geiger, Luiz Velho, Moacir Antonelli Ponti)</author>
      <guid isPermaLink="false">2502.21280v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>RoboBrain: A Unified Brain Model for Robotic Manipulation from Abstract to Concrete</title>
      <link>http://arxiv.org/abs/2502.21257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;最近，多模态大型语言模型（MLLM）在各种多模态环境中展示了显著的能力。然而，在机器人场景中的应用，特别是长时程操作任务中表现出重大限制。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态大型语言模型（MLLM）在处理复杂的机器人操控任务时存在明显的不足，特别是在规划能力、可操作性感知和轨迹预测三个方面有缺陷。&lt;h4&gt;目的&lt;/h4&gt;为了增强机器人的核心功能，从抽象到具体的操作，提出了ShareRobot数据集以及基于此的RoboBrain模型，旨在解决现有MLLM在机器人场景中的局限性。&lt;h4&gt;方法&lt;/h4&gt;ShareRobot是一个高质量的数据集，包含任务规划、可操作性识别和末端执行器轨迹等多维度信息。该数据集经过三个标注者的细心校正以确保其多样性和准确性。利用该数据集开发了RoboBrain模型，并采用多层次训练策略以及大量的视频和高分辨率图像进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;通过详尽的实验，证明RoboBrain在多种机器人任务中达到了最先进的性能水平。&lt;h4&gt;结论&lt;/h4&gt;这些成果强调了RoboBrain在提高机器人大脑功能方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Multimodal Large Language Models (MLLMs) have shownremarkable capabilities across various multimodal contexts. However, theirapplication in robotic scenarios, particularly for long-horizon manipulationtasks, reveals significant limitations. These limitations arise from thecurrent MLLMs lacking three essential robotic brain capabilities: PlanningCapability, which involves decomposing complex manipulation instructions intomanageable sub-tasks; Affordance Perception, the ability to recognize andinterpret the affordances of interactive objects; and Trajectory Prediction,the foresight to anticipate the complete manipulation trajectory necessary forsuccessful execution. To enhance the robotic brain's core capabilities fromabstract to concrete, we introduce ShareRobot, a high-quality heterogeneousdataset that labels multi-dimensional information such as task planning, objectaffordance, and end-effector trajectory. ShareRobot's diversity and accuracyhave been meticulously refined by three human annotators. Building on thisdataset, we developed RoboBrain, an MLLM-based model that combines robotic andgeneral multi-modal data, utilizes a multi-stage training strategy, andincorporates long videos and high-resolution images to improve its roboticmanipulation capabilities. Extensive experiments demonstrate that RoboBrainachieves state-of-the-art performance across various robotic tasks,highlighting its potential to advance robotic brain capabilities.</description>
      <author>example@mail.com (Yuheng Ji, Huajie Tan, Jiayu Shi, Xiaoshuai Hao, Yuan Zhang, Hengyuan Zhang, Pengwei Wang, Mengdi Zhao, Yao Mu, Pengju An, Xinda Xue, Qinghang Su, Huaihai Lyu, Xiaolong Zheng, Jiaming Liu, Zhongyuan Wang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2502.21257v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction</title>
      <link>http://arxiv.org/abs/2502.21186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR2025. Code would be available at  \href{https://github.com/BaitingLuo/L-MAP.git}{this https URL}&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的离线强化学习框架Latent Macro Action Planner (L-MAP)，该框架通过学习一组时间延长的宏动作，解决了在高维连续行为空间中的序列决策问题。&lt;h4&gt;背景&lt;/h4&gt;在具有随机性的环境和高维行动空间中进行顺序决策面临计算挑战。传统离线增强学习设置下，代理必须基于通过随机行为策略收集的数据来学习如何做决定。&lt;h4&gt;目的&lt;/h4&gt;探索如何利用离线强化学习框架解决具有复杂动作空间的序列决策问题。&lt;h4&gt;方法&lt;/h4&gt;L-MAP 采用状态条件下的向量量化变分自动编码器 (VQ-VAE) 学习一组时间扩展的动作，通过这种方式减少动作维度。同时，它使用一个独立的学习先验模型作为潜在转换模型，并允许高效的可能行动采样。在规划过程中，通过蒙特卡洛树搜索（MCTS）来考虑环境和行为策略中的随机性。&lt;h4&gt;主要发现&lt;/h4&gt;L-MAP 能够有效地在线性时间范围内进行离线强化学习任务中的决策，即使在动作维度增加的情况下也能保持较低的延迟，并且在连续控制到高维机器人手部操作等多种任务上都表现出色。&lt;h4&gt;结论&lt;/h4&gt;通过实验证明 L-MAP 在处理复杂和随机环境下的高维行动空间规划问题时是有效的，并能够与现有的模型方法相媲美，同时表现出了比其他基于模型的方法更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;顺序决策在具有高维连续动作空间的随机环境中面临计算挑战。我们探索了传统的离线强化学习框架，在这种情况下，代理必须根据通过随机行为策略收集的数据来学习如何做出决定。我们提出了 Latent Macro Action Planner (L-MAP)，该方法通过对状态条件下的向量量化变分自动编码器进行训练来降低动作维度，并且采用一个独立的学习先验模型作为潜在转换模型和高效的可能行动采样工具。在规划过程中，通过蒙特卡洛树搜索(MCTS) 来考虑环境及行为策略中的随机性。L-MAP 在离线强化学习设置中包括随机连续控制任务时表现高效，能够在线性时间范围内进行决策，并且即使在动作维度增加的情况下也能保持低延迟。实验证明，在从具有内在随机性的连续控制到高维机器人手部操作的任务上，与现有模型方法相比 L-MAP 显著优于其他方法，并表现出与强大的无模型策略-评估者基准线相媲美的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential decision-making in high-dimensional continuous action spaces,particularly in stochastic environments, faces significant computationalchallenges. We explore this challenge in the traditional offline RL setting,where an agent must learn how to make decisions based on data collected througha stochastic behavior policy. We present \textit{Latent Macro Action Planner}(L-MAP), which addresses this challenge by learning a set of temporallyextended macro-actions through a state-conditional Vector Quantized VariationalAutoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employsa (separate) learned prior model that acts as a latent transition model andallows efficient sampling of plausible actions. During planning, our approachaccounts for stochasticity in both the environment and the behavior policy byusing Monte Carlo tree search (MCTS). In offline RL settings, includingstochastic continuous control tasks, L-MAP efficiently searches over discretelatent actions to yield high expected returns. Empirical results demonstratethat L-MAP maintains low decision latency despite increased actiondimensionality. Notably, across tasks ranging from continuous control withinherently stochastic dynamics to high-dimensional robotic hand manipulation,L-MAP significantly outperforms existing model-based methods and performson-par with strong model-free actor-critic baselines, highlighting theeffectiveness of the proposed approach in planning in complex and stochasticenvironments with high-dimensional action spaces.</description>
      <author>example@mail.com (Baiting Luo, Ava Pettet, Aron Laszka, Abhishek Dubey, Ayan Mukhopadhyay)</author>
      <guid isPermaLink="false">2502.21186v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>A Minor-Testing Approach for Coordinated Motion Planning with Sliding Robots</title>
      <link>http://arxiv.org/abs/2502.21175v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了在无向图上的一种协调移动规划问题的变体，即协作滑动运动规划(CSMP)问题。&lt;h4&gt;背景&lt;/h4&gt;CSMP问题涉及给定一个无向图G、k个机器人R1至Rk放置于G的不同顶点，并且p≤k个不同的目标顶点供机器人R1至Rp使用。该问题是NP困难的，尤其是在全网格中。&lt;h4&gt;目的&lt;/h4&gt;研究CSMP在两个参数（即机器人数量k和时间限制l）下的参数复杂性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个固定参数算法来解决CSMP问题，在第一个结果中根据k参数化；在第二个结果中，为特殊情况下只有一个目标顶点的CSMP提出了一个基于l参数化的固定参数算法，并证明了该特殊情况是NP完全的。&lt;h4&gt;主要发现&lt;/h4&gt;解决方案可以表示为输入图的小标记拓扑子图，这是两个结果的关键新元素。&lt;h4&gt;结论&lt;/h4&gt;通过这两个新的算法和理论发现，作者在解决大规模复杂问题方面取得了进展。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了一种无向图上协调运动规划问题的变体——协作滑动运动规划(CSMP)问题。该问题要求判断是否存在一个序列调度，在这个调度中最多包含l次移动，使得每个有目标顶点的机器人能够到达它的目的地。此外，还提出了解决CSMP参数复杂性的固定参数算法，并证明了在特殊情况下是NP完全的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study a variant of the Coordinated Motion Planning problem on undirectedgraphs, referred to herein as the \textsc{Coordinated Sliding-Motion Planning}(CSMP) problem. In this variant, we are given an undirected graph $G$, $k$robots $R_1,\dots,R_k$ positioned on distinct vertices of $G$, $p\leq k$distinct destination vertices for robots $R_1,\dots,R_p$, and $\ell \in\mathbb{N}$. The problem is to decide if there is a serial schedule of at most$\ell$ moves (i.e., of makespan $\ell$) such that at the end of the scheduleeach robot with a destination reaches it, where a robot's move is a free path(unoccupied by any robots) from its current position to an unoccupied vertex.The problem is known to be NP-hard even on full grids. It has been studied inseveral contexts, including coin movement and reconfiguration problems, withrespect to feasibility, complexity, and approximation. Geometric variants ofthe problem, in which congruent geometric-shape robots (e.g., unitdisk/squares) slide or translate in the Euclidean plane, have also been studiedextensively. We investigate the parameterized complexity of CSMP with respectto two parameters: the number $k$ of robots and the makespan $\ell$. As ourfirst result, we present a fixed-parameter algorithm for CSMP parameterized by$k$. For our second result, we present a fixed-parameter algorithmparameterized by $\ell$ for the special case of CSMP in which only a singlerobot has a destination and the graph is planar, which we prove to beNP-complete. A crucial new ingredient for both of our results is that thesolution admits a succinct representation as a small labeled topological minorof the input graph.</description>
      <author>example@mail.com (Eduard Eiben, Robert Ganian, Iyad Kanj, Ramanujan M. Sridharan)</author>
      <guid isPermaLink="false">2502.21175v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Rare event modeling with self-regularized normalizing flows: what can we learn from a single failure?</title>
      <link>http://arxiv.org/abs/2502.21110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为CalNF（校准归一化流程）的新框架，用于从有限的数据中进行后验学习。这种方法解决了在处理安全关键系统的罕见故障事件时由于数据稀缺而遇到的问题。&lt;h4&gt;背景&lt;/h4&gt;随着自动驾驶系统和机器人技术的广泛应用，与之相关的安全问题也日益凸显。此类系统的故障往往难以通过现有的方法来建模和调试，因为缺乏足够的失败案例的数据支持。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架CalNF，以克服由于罕见故障事件数据不足导致的传统模型训练中的局限性，如过拟合或欠拟合等问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自调节的归一化流程技术（Calibrated Normalizing Flows, CalNF），专门设计用于在数据有限的情况下进行后验学习，并且能够在处理逆问题和罕见故障建模时达到最先进的性能水平。&lt;h4&gt;主要发现&lt;/h4&gt;使用CalNF框架能够成功解析2022年美国西南航空公司调度危机的根本原因，这是一项开创性的案例研究。&lt;h4&gt;结论&lt;/h4&gt;CalNF框架为解决由于数据稀缺而引起的罕见安全关键事件的建模难题提供了一个有效的解决方案，并且已经在实际问题中得到了验证。&lt;h4&gt;翻译&lt;/h4&gt;随着无人驾驶系统和机器人技术在运输等领域的部署增加，相应的安全性关键性故障也有所上升。这些故障难以通过现有的方法进行建模和调试，因为缺乏足够的失败案例的数据支持。为了应对这一挑战，研究人员提出了一种名为CalNF的新框架，它利用了自调节的归一化流程技术，特别适用于从有限数据中进行后验学习，并且已经在处理逆问题和罕见故障事件模型方面取得了最先进的性能表现。通过这种方法的应用，能够首次对2022年美国西南航空公司调度危机的根本原因进行了深入分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Increased deployment of autonomous systems in fields like transportation androbotics have seen a corresponding increase in safety-critical failures. Thesefailures can be difficult to model and debug due to the relative lack of data:compared to tens of thousands of examples from normal operations, we may haveonly seconds of data leading up to the failure. This scarcity makes itchallenging to train generative models of rare failure events, as existingmethods risk either overfitting to noise in the limited failure dataset orunderfitting due to an overly strong prior. We address this challenge withCalNF, or calibrated normalizing flows, a self-regularized framework forposterior learning from limited data. CalNF achieves state-of-the-artperformance on data-limited failure modeling and inverse problems and enables afirst-of-a-kind case study into the root causes of the 2022 Southwest Airlinesscheduling crisis.</description>
      <author>example@mail.com (Charles Dawson, Van Tran, Max Z. Li, Chuchu Fan)</author>
      <guid isPermaLink="false">2502.21110v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Jointly Assigning Processes to Machines and Generating Plans for Autonomous Mobile Robots in a Smart Factory</title>
      <link>http://arxiv.org/abs/2502.21101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ACES是一种用于智能工厂的优化算法，可以同时解决工艺分配和路径规划问题。&lt;h4&gt;背景&lt;/h4&gt;现代智能工厂使用可编程机器进行生产，并通过移动机器人运输材料。目前现有的管理系统是顺序地解决问题，这限制了它们所能实现的最大吞吐量。&lt;h4&gt;目的&lt;/h4&gt;介绍ACES（Anytime Cyclic Embedding Solver），这是一种能够同时优化工艺分配和路径规划问题的解决方案。&lt;h4&gt;方法&lt;/h4&gt;ACES可以同时解决智能工厂中的工艺分配和移动机器人运输路线的问题，从而提高整个系统的生产效率。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验评估表明，ACES能够在现实工业场景中进行扩展，并且相较于现有系统，能够实现更高的吞吐量。&lt;h4&gt;结论&lt;/h4&gt;ACES为智能工厂提供了一种有效的解决方案来优化生产和材料运输流程。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代智能工厂使用一组可编程机器运行制造程序。通常，材料通过一群移动机器人在这些机器之间运送。为了将制造过程嵌入到智能工厂中，工厂操作员必须a) 将其工艺分配给智能工厂的机器，b) 确定代理如何在机器之间运输材料。一个好的嵌入可以最大化智能工厂的吞吐量；即它输出产品的速度。现有的智能工厂管理系统按顺序解决上述问题，限制了它们所能实现的最大吞吐量。在这篇论文中我们介绍了ACES（Anytime Cyclic Embedding Solver），这是一种首次同时优化工艺分配和路径规划问题的解决方案。我们评估了ACES，并表明它可以扩展到现实工业场景中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A modern smart factory runs a manufacturing procedure using a collection ofprogrammable machines. Typically, materials are ferried between these machinesusing a team of mobile robots. To embed a manufacturing procedure in a smartfactory, a factory operator must a) assign its processes to the smart factory'smachines and b) determine how agents should carry materials between machines. Agood embedding maximizes the smart factory's throughput; the rate at which itoutputs products. Existing smart factory management systems solve theaforementioned problems sequentially, limiting the throughput that they canachieve. In this paper we introduce ACES, the Anytime Cyclic Embedding Solver,the first solver which jointly optimizes the assignment of processes tomachines and the assignment of paths to agents. We evaluate ACES and show thatit can scale to real industrial scenarios.</description>
      <author>example@mail.com (Christopher Leet, Aidan Sciortino, Sven Koenig)</author>
      <guid isPermaLink="false">2502.21101v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>AuthSim: Towards Authentic and Effective Safety-critical Scenario Generation for Autonomous Driving Tests</title>
      <link>http://arxiv.org/abs/2502.21100v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;生成对抗性安全关键场景是测试自动驾驶系统的关键方法，有助于识别潜在弱点并增强系统的鲁棒性和可靠性。然而，现有的方法主要关注不受限制的碰撞场景，导致非玩家角色（NPC）车辆无差别攻击主控车。这些研究忽略了这些场景的真实性和合理性，产生了许多极端、人为构造且不现实的涉及激进NPC车辆的碰撞事件。&lt;h4&gt;背景&lt;/h4&gt;当前的方法在测试自动驾驶系统时过于集中于制造不受限制和过度激进的对抗性情况，导致生成的场景缺乏真实性和理性。&lt;h4&gt;目的&lt;/h4&gt;提出一种三层相对安全区域模型，并开发一个名为AuthSim的平台来产生更真实有效的安全关键场景，以解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入了三层相对安全区域模型和结合强化学习的方法，这个模型可以划分基于危险等级的不同区域并调整NPC车辆进入这些边界区域的概率。同时利用该模型与强化学习相结合构建了一个全面平台AuthSim。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示AuthSim在生成有效的安全关键场景方面比现有方法表现更佳，尤其在平均切入距离和平均碰撞间隔时间上分别提高了5.25%和27.12%，并且效率更高。&lt;h4&gt;结论&lt;/h4&gt;这是首次全面解决自动驾驶系统测试场景的真实性和有效性问题的尝试。AuthSim证明了其在生成真实场景方面的显著优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到，对抗性安全关键场景对测试自动驾驶系统的潜在弱点至关重要，并增强其鲁棒性和可靠性。然而，现有的方法过分关注无约束碰撞情况，导致NPC车辆针对主控车发动毫无选择的攻击。这些方法忽视了情景的真实性和合理性，产生了大量极端且不现实的情况，其中涉及的是激进的NPC行为。为解决这些问题，研究团队提出了一种三层相对安全区域模型，并开发了一个名为AuthSim的平台，该平台利用这个模型与强化学习相结合，以产生更加真实和有效的测试场景。实验表明，相对于现有方法，AuthSim在生成有效且关键的安全场景方面表现出色，尤其是在提高平均切入距离和减少碰撞间隔时间上取得了显著改善。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating adversarial safety-critical scenarios is a pivotal method fortesting autonomous driving systems, as it identifies potential weaknesses andenhances system robustness and reliability. However, existing approachespredominantly emphasize unrestricted collision scenarios, prompting non-playercharacter (NPC) vehicles to attack the ego vehicle indiscriminately. Theseworks overlook these scenarios' authenticity, rationality, and relevance,resulting in numerous extreme, contrived, and largely unrealistic collisionevents involving aggressive NPC vehicles. To rectify this issue, we propose athree-layer relative safety region model, which partitions the area based ondanger levels and increases the likelihood of NPC vehicles entering relativeboundary regions. This model directs NPC vehicles to engage in adversarialactions within relatively safe boundary regions, thereby augmenting thescenarios' authenticity. We introduce AuthSim, a comprehensive platform forgenerating authentic and effective safety-critical scenarios by integrating thethree-layer relative safety region model with reinforcement learning. To ourknowledge, this is the first attempt to address the authenticity andeffectiveness of autonomous driving system test scenarios comprehensively.Extensive experiments demonstrate that AuthSim outperforms existing methods ingenerating effective safety-critical scenarios. Notably, AuthSim achieves a5.25% improvement in average cut-in distance and a 27.12% enhancement inaverage collision interval time, while maintaining higher efficiency ingenerating effective safety-critical scenarios compared to existing methods.This underscores its significant advantage in producing authentic scenariosover current methodologies.</description>
      <author>example@mail.com (Yukuan Yang, Xucheng Lu, Zhili Zhang, Zepeng Wu, Guoqi Li, Lingzhong Meng, Yunzhi Xue)</author>
      <guid isPermaLink="false">2502.21100v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Vibrotactile information coding strategies for a body-worn vest to aid robot-human collaboration</title>
      <link>http://arxiv.org/abs/2502.21056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了通过身体穿戴式的振动触觉背心向操作员传递机器人实时信息的方法。研究旨在探索在高认知负荷条件下，如何有效地利用非视觉和非听觉感知方式来传达关键信息。&lt;h4&gt;背景&lt;/h4&gt;在城市搜索与救援（USAR）场景中，当人类与机器人协同工作时，尤其是在高度复杂的环境中，触觉通信可以为操作员提供重要而不影响其视听能力的信息。这种情况通常伴随着高认知负荷条件下的作业。&lt;h4&gt;目的&lt;/h4&gt;本文的目的是通过不同的振动触觉信息编码策略来探讨如何最好地传达此类信息，并引入了语义触觉的概念，以改善在机器人远程侦察时的情景理解。&lt;h4&gt;方法&lt;/h4&gt;文章介绍了一种新的信息表示技术——语义触觉（Semantic Haptics），该技术利用形状和模式来表示特定事件。这种方法试图使皮肤像屏幕一样工作，旨在提高学习能力和解释准确度。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用形状和图案来代表特定的事件，可以实现更好的可学性和解释准确性。这表明在复杂作业环境中采用触觉信息传递的有效性与优势。&lt;h4&gt;结论&lt;/h4&gt;研究结果证明了利用振动背心进行触觉通信在提高操作员对环境理解方面的潜力，并且语义触觉技术可能为未来机器人辅助搜索和救援任务提供有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;原文摘要的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the use of a body-worn vibrotactile vest to conveyreal-time information from robot to operator. Vibrotactile communication couldbe useful in providing information without compropmising or loading a person'svisual or auditory perception. This paper considers applications in UrbanSearch and Rescue (USAR) scenarios where a human working alongside a robot islikely to be operating in high cognitive load conditions. The focus is onunderstanding how best to convey information considering different vibrotactileinformation coding strategies to enhance scene understanding in scenarios wherea robot might be operating remotely as a scout. In exploring informationrepresentation, this paper introduces Semantic Haptics, using shapes andpatterns to represent certain events as if the skin was a screen, and shows howthese lead to bettter learnability and interpreation accuracy.</description>
      <author>example@mail.com (Adrian Vecina Tercero, Praminda Caleb-Solly)</author>
      <guid isPermaLink="false">2502.21056v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model</title>
      <link>http://arxiv.org/abs/2502.16779v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025. Github  page:https://github.com/justacar/Plane-DUSt3R&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多视角房间布局估计方法Plane-DUSt3R，该方法利用了三维基础模型DUSt3R。&lt;h4&gt;背景&lt;/h4&gt;从多个视角的图像中进行房间布局估计的问题由于多视图几何复杂性而研究较少。传统的结构光运动过程需要多步骤解决方案，比如相机内参和外参估计、图像匹配以及三角测量等。&lt;h4&gt;目的&lt;/h4&gt;为了简化房间布局估计的过程并减少误差累积，本文旨在提出一种新的单步端到端方法来处理这个问题。&lt;h4&gt;方法&lt;/h4&gt;Plane-DUSt3R基于DUSt3R框架，并在房间布局数据集（Structure3D）上进行微调，以修改后的目标函数来估算结构平面。此模型能够仅通过一次后处理步骤和二维检测结果来进行房间布局估计。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，与现有最先进的方法相比，Plane-DUSt3R不仅在合成数据集中表现更优，在不同图像风格（如卡通）的真实世界数据中也显示了鲁棒性和有效性。&lt;h4&gt;结论&lt;/h4&gt;通过引入Plane-DUSt3R，本文提供了一种高效的多视角房间布局估计解决方案，并展示了其在各种环境下的优越性能。&lt;h4&gt;翻译&lt;/h4&gt;从多个视角的图像进行房间布局估计问题因多视图几何复杂性而研究不足。然而，在三维重建领域，近年来出现了像DUSt3R这样的三维基础模型，改变了传统的多步骤结构光运动流程为单步端到端方法。本文引入了Plane-DUSt3R，一种利用DUSt3R框架进行多视角房间布局估计的新方法。该模型在经过修改的目标函数指导下，在一个房间布局数据集上进行了微调，并且能够通过二维检测结果和单一后处理步骤实现高效精确的结构平面预测。不同于以往依赖单视图或全景图像的方法，Plane-DUSt3R扩展了其能力以适应多视角输入，并提供了一种简化的、端到端的解决方案。实验表明，这种方法在合成数据集中超越了现有最佳方法，在不同样式的实际场景（包括卡通风格）中也展示了强大的性能和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Room layout estimation from multiple-perspective images is poorlyinvestigated due to the complexities that emerge from multi-view geometry,which requires muti-step solutions such as camera intrinsic and extrinsicestimation, image matching, and triangulation. However, in 3D reconstruction,the advancement of recent 3D foundation models such as DUSt3R has shifted theparadigm from the traditional multi-step structure-from-motion process to anend-to-end single-step approach. To this end, we introduce Plane-DUSt3R, anovel method for multi-view room layout estimation leveraging the 3D foundationmodel DUSt3R. Plane-DUSt3R incorporates the DUSt3R framework and fine-tunes ona room layout dataset (Structure3D) with a modified objective to estimatestructural planes. By generating uniform and parsimonious results, Plane-DUSt3Renables room layout estimation with only a single post-processing step and 2Ddetection results. Unlike previous methods that rely on single-perspective orpanorama image, Plane-DUSt3R extends the setting to handle multiple-perspectiveimages. Moreover, it offers a streamlined, end-to-end solution that simplifiesthe process and reduces error accumulation. Experimental results demonstratethat Plane-DUSt3R not only outperforms state-of-the-art methods on thesynthetic dataset but also proves robust and effective on in the wild data withdifferent image styles such as cartoon.Our code is available at:https://github.com/justacar/Plane-DUSt3R</description>
      <author>example@mail.com (Yaxuan Huang, Xili Dai, Jianan Wang, Xianbiao Qi, Yixing Yuan, Xiangyu Yue)</author>
      <guid isPermaLink="false">2502.16779v2</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Sixth-Sense: Self-Supervised Learning of Spatial Awareness of Humans from a Planar Lidar</title>
      <link>http://arxiv.org/abs/2502.21029v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种从1D激光雷达数据中检测人类并估计其2D姿态的自监督方法，以解决服务机器人在没有RGB-D摄像头或昂贵3D LiDAR的情况下难以感知周围人的局限性。&lt;h4&gt;背景&lt;/h4&gt;当前的服务机器人主要依赖于RGB-D相机或昂贵的3D LiDAR进行人体定位，但商业上常见的服务机器人通常配备视野狭窄的普通相机或者读数难以解析的一维激光雷达。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有设备的成本和功能限制，论文提出了一个利用1D LiDAR数据检测人类并估计其2D姿态的方法，并使用RGB-D摄像头的数据作为监督信号进行训练。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自监督学习框架，该框架通过将从1DLiDAR获得的原始距离信息与从RGB-D相机获取的人体框和关键点进行配对来实现人体检测和姿态估计任务。模型经过70分钟数据（在两个环境自主收集）训练后能够实现在新环境中基于1DLiDAR的数据进行全向人类检测。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够在新的未知环境中从单一线激光雷达信息中准确地进行全方位的人体检测，达到71%的精度和80%的召回率，并且在距离上保持了平均绝对误差为13cm，在方向角度上有44度的估计偏差。&lt;h4&gt;结论&lt;/h4&gt;论文提出的方法证明了一维LiDAR可以作为服务机器人实现自主定位与交互的有效感知工具，显著提高了机器人的环境适应性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Localizing humans is a key prerequisite for any service robot operating inproximity to people. In these scenarios, robots rely on a multitude ofstate-of-the-art detectors usually designed to operate with RGB-D cameras orexpensive 3D LiDARs. However, most commercially available service robots areequipped with cameras with a narrow field of view, making them blind when auser is approaching from other directions, or inexpensive 1D LiDARs whosereadings are difficult to interpret. To address these limitations, we propose aself-supervised approach to detect humans and estimate their 2D pose from 1DLiDAR data, using detections from an RGB-D camera as a supervision source. Ourapproach aims to provide service robots with spatial awareness of nearbyhumans. After training on 70 minutes of data autonomously collected in twoenvironments, our model is capable of detecting humans omnidirectionally from1D LiDAR data in a novel environment, with 71% precision and 80% recall, whileretaining an average absolute error of 13 cm in distance and 44{\deg} inorientation.</description>
      <author>example@mail.com (Simone Arreghini, Nicholas Carlotti, Mirko Nava, Antonio Paolillo, Alessandro Giusti)</author>
      <guid isPermaLink="false">2502.21029v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Nano Drone-based Indoor Crime Scene Analysis</title>
      <link>http://arxiv.org/abs/2502.21019v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 4 figures, to be submitted to ARSO 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文采用投机原型设计的方法，使用STAIR工具快速回顾文献并识别出犯罪现场分析中尚未受到足够关注的任务，并开发了一种小型无人机进行初步验证。&lt;h4&gt;背景&lt;/h4&gt;机器人技术、人工智能和计算机视觉可以应用于犯罪现场分析，以保护生命、促进正义和防止犯罪。但尚缺乏对可自动化任务的全面概述。&lt;h4&gt;目的&lt;/h4&gt;识别并实现犯罪现场分析中可自动化的任务，并通过原型设计展示其可行性和性能。&lt;h4&gt;方法&lt;/h4&gt;采用STAIR工具进行文献回顾，确定了访问犯罪现场（如通过窗户）、绘制和收集证据以及分析血迹等未受足够关注的任务。接着开发了一种小型无人机原型以执行这些任务。&lt;h4&gt;主要发现&lt;/h4&gt;该无人机在三个特定任务中分别达到了75%、85%和80%的性能，展示了技术应用于犯罪现场分析的可能性。&lt;h4&gt;结论&lt;/h4&gt;此次工作通过初步实验为未来的研究提供指导，并强调了进一步研究的必要性以改善自动化系统对复杂犯罪场景的支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要：机器人技术、人工智能（AI）和计算机视觉（CV）可以被用于帮助保护生命、促进正义及防止犯罪，但关于可自动化的任务概述却很缺乏。本文采用投机原型设计的方法：首先利用STAIR工具快速回顾文献并识别出访问犯罪现场通过窗户进入等尚未受到足够关注的任务；其次开发一种小型无人机以实现这些任务，并在室内犯罪场景中进行初步分析。最后报告了所学到的经验教训，为后续的研究提供指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Technologies such as robotics, Artificial Intelligence (AI), and ComputerVision (CV) can be applied to crime scene analysis (CSA) to help protect lives,facilitate justice, and deter crime, but an overview of the tasks that can beautomated has been lacking. Here we follow a speculate prototyping approach:First, the STAIR tool is used to rapidly review the literature and identifytasks that seem to have not received much attention, like accessing crime sitesthrough a window, mapping/gathering evidence, and analyzing blood smears.Secondly, we present a prototype of a small drone that implements these threetasks with 75%, 85%, and 80% performance, to perform a minimal analysis of anindoor crime scene. Lessons learned are reported, toward guiding next work inthe area.</description>
      <author>example@mail.com (Martin Cooney, Sivadinesh Ponrajan, Fernando Alonso-Fernandez)</author>
      <guid isPermaLink="false">2502.21019v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Motion ReTouch: Motion Modification Using Four-Channel Bilateral Control</title>
      <link>http://arxiv.org/abs/2502.20982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 7 figures, Accepted at ICM2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种名为Motion ReTouch的新方法被提出，该方法可以通过多边控制和动作复制系统结合的方式对通过四通道双边控制获得的运动数据进行事后修改。&lt;h4&gt;背景&lt;/h4&gt;最近的研究表明，在自主机器人操作中使用模仿学习是有效的。特别是利用能够获取位置和力信息的四通道双边控制来进行教学已被证明是有效的。&lt;h4&gt;目的&lt;/h4&gt;为了实现能够轻松执行高速、复杂任务的一次性控制性能，本研究提出了一种新的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法称为Motion ReTouch，它不仅能修改运动的位置数据，还能修改力的信息。这通过多边控制和动作复制系统的结合得以实现。&lt;h4&gt;主要发现&lt;/h4&gt;在使用真实机器人进行的实验中，试验表明测试管转移任务的成功率得到了提高，证明了修改力信息的可能性。&lt;h4&gt;结论&lt;/h4&gt;这项工作提供了一种新颖的方法来增强模仿学习的效果，并为实现更高性能的任务执行提供了可能途径。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究已经展示了模仿学习在自主机器人操作中的有用性。特别是使用四通道双边控制进行教学已被证明是有效的，它可以获取位置和力的信息。然而，尚未实现能够轻松一次性完成高速、复杂任务的控制性能。我们提出了一种叫做Motion ReTouch的方法，该方法可以通过事后修改通过四通道双边控制获得的运动数据来提高这一能力。此方法不仅可以修改位置信息，还可以修改力信息。这是通过多边控制和动作复制系统的结合得以实现的。在真实机器人的实验中验证了所提出的这种方法，并且提高了测试管转移任务的成功率，表明了修改力信息的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research has demonstrated the usefulness of imitation learning inautonomous robot operation. In particular, teaching using four-channelbilateral control, which can obtain position and force information, has beenproven effective. However, control performance that can easily executehigh-speed, complex tasks in one go has not yet been achieved. We propose amethod called Motion ReTouch, which retroactively modifies motion data obtainedusing four-channel bilateral control. The proposed method enables modificationof not only position but also force information. This was achieved by thecombination of multilateral control and motion-copying system. The proposedmethod was verified in experiments with a real robot, and the success rate ofthe test tube transfer task was improved, demonstrating the possibility ofmodification force information.</description>
      <author>example@mail.com (Koki Inami, Sho Sakaino, Toshiaki Tsuji)</author>
      <guid isPermaLink="false">2502.20982v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Optimality and Suboptimality of MPPI Control in Stochastic and Deterministic Settings</title>
      <link>http://arxiv.org/abs/2502.20953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, submitted to LCSS with CDC25 option&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了MPPI控制框架在解决最优控制问题中的应用及其性能分析。&lt;h4&gt;背景&lt;/h4&gt;Model Predictive Path Integral (MPPI) 控制方法近年来受到广泛关注，特别是在机器人和强化学习领域。&lt;h4&gt;目的&lt;/h4&gt;旨在使MPPI控制框架更容易被最优控制社区理解，并展示其应用于三类最优控制问题的效果及性能。&lt;h4&gt;方法&lt;/h4&gt;研究了在一般确定性非线性离散时间系统中，MPPI控制与最优解之间的次优性。通过数值例子来说明这一分析结果。&lt;h4&gt;主要发现&lt;/h4&gt;在一个平滑且无约束的条件下，随着不确定性的增加，由MPPI提供的控制输入轨迹和最优控制问题解之间的差距增长是二次级别的。并且指出调整超参数可以调节这种次优性。&lt;h4&gt;结论&lt;/h4&gt;通过数值例子验证了上述分析结果，并展示了如何通过适当调整超参数来减轻MPPI解决方案的次优性。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到，最近Model Predictive Path Integral (MPPI) 控制方法在机器人和强化学习领域获得了大量关注。本论文旨在使该控制框架更容易被最优控制社区理解和应用，同时展示了三种不同类型的最优控制问题以及它们通过MPPI得到的解决方案，并研究了确定性非线性离散时间系统中MPPI的次优性能。主要发现表明，在平滑且无约束条件下，随着不确定性的增加，由MPPI提供的控制输入轨迹和最优解之间的差距呈二次级增长。结果还指出，通过适当调整超参数可以调节这种次优性，并用数值例子展示了这些研究结论的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model predictive path integral (MPPI) control has recently received a lot ofattention, especially in the robotics and reinforcement learning communities.This letter aims to make the MPPI control framework more accessible to theoptimal control community. We present three classes of optimal control problemsand their solutions by MPPI. Further, we investigate the suboptimality of MPPIto general deterministic nonlinear discrete-time systems. Here, suboptimalityis defined as the deviation between the control provided by MPPI and theoptimal solution to the deterministic optimal control problem. Our findings arethat in a smooth and unconstrained setting, the growth of suboptimality in thecontrol input trajectory is second-order with the scaling of uncertainty. Theresults indicate that the suboptimality of the MPPI solution can be modulatedby appropriately tuning the hyperparameters. We illustrate our findings usingnumerical examples.</description>
      <author>example@mail.com (Hannes Homburger, Florian Messerer, Moritz Diehl, Johannes Reuter)</author>
      <guid isPermaLink="false">2502.20953v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping</title>
      <link>http://arxiv.org/abs/2502.20900v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;灵巧抓取在机器人技术中仍然是一个基础且具有挑战性的问题。通用机器人的任务是能够应对各种物体的抓取需求，并适应不同的场景。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，即DexGraspVLA框架，以实现更好的跨域迁移能力及泛化性能，从而解决现有研究依赖于特定假设（如单一物体设置或有限环境）而导致泛化受限的问题。&lt;h4&gt;方法&lt;/h4&gt;DexGraspVLA是一种层次化的框架，它利用预训练的视觉-语言模型作为高层次的任务规划器，并学习一种基于扩散的方法作为低级别的动作控制器。其核心在于能够迭代地将多样性的语言和视觉输入转换为领域不变的表示，从而减少域间偏移并使模仿学习更加有效。&lt;h4&gt;主要发现&lt;/h4&gt;在数千种未见过的对象、光照及背景组合的情况下，在零样本环境中达到了90%以上的成功抓取率，并且实验分析表明内部模型行为的一致性随着环境变化而保持稳定。&lt;h4&gt;结论&lt;/h4&gt;该研究通过设计DexGraspVLA框架，展示了实现灵巧抓取的通用能力的可能性，希望为这一领域的进步提供一步推进。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dexterous grasping remains a fundamental yet challenging problem in robotics.A general-purpose robot must be capable of grasping diverse objects inarbitrary scenarios. However, existing research typically relies on specificassumptions, such as single-object settings or limited environments, leading toconstrained generalization. Our solution is DexGraspVLA, a hierarchicalframework that utilizes a pre-trained Vision-Language model as the high-leveltask planner and learns a diffusion-based policy as the low-level Actioncontroller. The key insight lies in iteratively transforming diverse languageand visual inputs into domain-invariant representations, where imitationlearning can be effectively applied due to the alleviation of domain shift.Thus, it enables robust generalization across a wide range of real-worldscenarios. Notably, our method achieves a 90+% success rate under thousands ofunseen object, lighting, and background combinations in a ``zero-shot''environment. Empirical analysis further confirms the consistency of internalmodel behavior across environmental variations, thereby validating our designand explaining its generalization performance. We hope our work can be a stepforward in achieving general dexterous grasping. Our demo and code can be foundat https://dexgraspvla.github.io/.</description>
      <author>example@mail.com (Yifan Zhong, Xuchuan Huang, Ruochong Li, Ceyao Zhang, Yitao Liang, Yaodong Yang, Yuanpei Chen)</author>
      <guid isPermaLink="false">2502.20900v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical and Modular Network on Non-prehensile Manipulation in General Environments</title>
      <link>http://arxiv.org/abs/2502.20843v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  http://unicorn-hamnet.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种模块化和可重构的架构，以解决机器人在不同几何环境中执行非抓握操作时面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;机器人需要具备非抓取的操作能力来处理不可抓取的对象，如物体倾倒和滚动。然而现有的方法难以适应环境的变化，导致策略难以泛化。&lt;h4&gt;目的&lt;/h4&gt;研究如何让机器人能够根据不同的任务需求自适应地改变其行为模式，以应对复杂多变的几何约束。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的架构设计和接触为基础的对象表示（CORN）的扩展版本来处理环境变化。还开发了一个生成多样环境的算法来训练机器人，并发布了一个包含真实场景数字模型的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的适应性架构能够在完全没有见过的真实世界环境中进行零样本转移，显示出其泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了使用模块化和可重构设计可以解决非抓握操作的通用性和适应性的关键问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要：为了使机器人能够在家用等一般环境运行，它们必须能够执行像倾倒和滚动这样的非抓取行为来处理不可抓取的对象。然而现有的关于非抓取操纵的研究还不能泛化到几何结构多样的环境中去。主要挑战在于适应不同的环境约束：在一个橱柜内，机器人需要避开墙壁和天花板；要将物体提升至阶梯顶部，则必须考虑阶梯的姿态和延伸度。虽然深度强化学习（RL）在非抓握操作方面已经取得了显著的成功，但是考虑到这种变化性为泛化策略带来了挑战，因为这需要从每个新的约束组合中学习不同的策略。为了应对这一挑战，我们提出了一种模块化且可重构的架构，该架构能够根据任务需求自适应地重新配置网络模块。为了捕捉环境中几何结构的变化，我们将基于接触的对象表示（CORN）扩展到环境几何，并提出了一个生成多样环境以训练我们的代理的程序算法。综上所述，所得到的策略可以在完全没有见过的真实世界环境中进行零样本转移，尽管是在模拟器中完成的所有培训。此外，我们还发布了以九个真实场景数字模型为特征的数据集来支持现实领域的非抓握操作研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For robots to operate in general environments like households, they must beable to perform non-prehensile manipulation actions such as toppling androlling to manipulate ungraspable objects. However, prior works onnon-prehensile manipulation cannot yet generalize across environments withdiverse geometries. The main challenge lies in adapting to varyingenvironmental constraints: within a cabinet, the robot must avoid walls andceilings; to lift objects to the top of a step, the robot must account for thestep's pose and extent. While deep reinforcement learning (RL) has demonstratedimpressive success in non-prehensile manipulation, accounting for suchvariability presents a challenge for the generalist policy, as it must learndiverse strategies for each new combination of constraints. To address this, wepropose a modular and reconfigurable architecture that adaptively reconfiguresnetwork modules based on task requirements. To capture the geometricvariability in environments, we extend the contact-based object representation(CORN) to environment geometries, and propose a procedural algorithm forgenerating diverse environments to train our agent. Taken together, theresulting policy can zero-shot transfer to novel real-world environments andobjects despite training entirely within a simulator. We additionally release asimulation-based benchmark featuring nine digital twins of real-world sceneswith 353 objects to facilitate non-prehensile manipulation research inrealistic domains.</description>
      <author>example@mail.com (Yoonyoung Cho, Junhyek Han, Jisu Han, Beomjoon Kim)</author>
      <guid isPermaLink="false">2502.20843v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Learning-Based Leader Localization for Underwater Vehicles With Optical-Acoustic-Pressure Sensor Fusion</title>
      <link>http://arxiv.org/abs/2502.20817v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种三模态传感器融合神经网络方法，用于提高水下多车辆系统中领导者定位的精度和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;水下航行器在探索和监测海洋环境方面发挥着关键作用。多车辆系统的部署因其能够执行协作任务而引起广泛关注，但要在动态复杂的水下环境中精确确定领导者的方位仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;通过整合光学、声学和压力传感器来解决领导者定位的精度问题，并提高其鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;利用深度学习架构将三模态传感器（光学传感器提供高分辨率成像，声学传感器实现远程探测和测距，而压力传感器则感知环境背景信息）的数据融合起来以提取并结合互补特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明提出的三模态方法显著提高了领导者定位的准确性和鲁棒性，优于单模态或双模态的方法。&lt;h4&gt;结论&lt;/h4&gt;这项研究展示了如何通过智能地利用不同类型的传感器数据来提高水下多车辆系统的性能。这种方法有望在未来的海洋科学研究和应用中发挥重要作用。&lt;h4&gt;翻译&lt;/h4&gt;水下航行器已经成为探索和监测水域环境的关键技术，部署多车系统进行协同任务变得越来越受欢迎，但要在一个动态的复杂环境中精确定位领导者则仍然具有挑战性。本文提出了一种新颖的三模态传感器融合神经网络方法，该方法整合了光学、声学和压力传感器来定位领导者。通过利用各个传感模式的独特优势，这种方法提高了定位精度和鲁棒性。实验结果表明，这种三模态方法在准确性与鲁棒性上显著优于单一或双模态的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Underwater vehicles have emerged as a critical technology for exploring andmonitoring aquatic environments. The deployment of multi-vehicle systems hasgained substantial interest due to their capability to perform collaborativetasks with improved efficiency. However, achieving precise localization of aleader underwater vehicle within a multi-vehicle configuration remains asignificant challenge, particularly in dynamic and complex underwaterconditions. To address this issue, this paper presents a novel tri-modal sensorfusion neural network approach that integrates optical, acoustic, and pressuresensors to localize the leader vehicle. The proposed method leverages theunique strengths of each sensor modality to improve localization accuracy androbustness. Specifically, optical sensors provide high-resolution imaging forprecise relative positioning, acoustic sensors enable long-range detection andranging, and pressure sensors offer environmental context awareness. The fusionof these sensor modalities is implemented using a deep learning architecturedesigned to extract and combine complementary features from raw sensor data.The effectiveness of the proposed method is validated through a custom-designedtesting platform. Extensive data collection and experimental evaluationsdemonstrate that the tri-modal approach significantly improves the accuracy androbustness of leader localization, outperforming both single-modal anddual-modal methods.</description>
      <author>example@mail.com (Mingyang Yang, Zeyu Sha, Feitian Zhang)</author>
      <guid isPermaLink="false">2502.20817v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Towards Semantic 3D Hand-Object Interaction Generation via Functional Text Guidance</title>
      <link>http://arxiv.org/abs/2502.20805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种创新的两阶段框架Functional Grasp Synthesis Net (FGS-Net)，旨在基于功能文本生成手部与物体之间的三维交互姿态。&lt;h4&gt;背景&lt;/h4&gt;手势控制在人机交互中扮演关键角色，但由于抓取动作的复杂性和多样性，现有的技术难以捕捉功能性抓握任务的意义。&lt;h4&gt;目的&lt;/h4&gt;为了实现功能性的三维抓握手部-对象交互（HOI）生成，论文提出了一种新的框架来解决现有方法无法精确模拟功能性抓握的问题。&lt;h4&gt;方法&lt;/h4&gt;该方法包括一个文本引导的3D模型生成器Functional Grasp Generator (FGG)和一个姿态优化策略Functional Grasp Refiner (FGR)，前者基于文本输入生成手部与物体的3D模型，后者利用Object Pose Approximator和能量函数来调整姿态以确保符合人体意图。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够产生精确且高质量的手部-对象交互（HOI）而无需额外的三维标注数据。&lt;h4&gt;结论&lt;/h4&gt;通过实验验证了FGS-Net的有效性，在生成功能性抓握手部-物体交互方面表现出色，具有广泛应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;手部与物体之间的互动是人与环境之间的重要联系。尽管AI和机器人技术已取得重大进展，但捕捉功能抓握任务的语义仍是一个挑战。本文提出了一种新的两阶段框架Functional Grasp Synthesis Net (FGS-Net)，用于基于功能性文本生成3D HOI。该方法结合了基于文本引导的3D模型生成器和姿态优化策略，以确保手部与物体之间的相对位置符合人类意图并保持物理合理性。实验表明，在无需额外三维标注数据的情况下，我们的方法可以实现精确且高质量的手部-对象交互生成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hand-object interaction(HOI) is the fundamental link between human andenvironment, yet its dexterous and complex pose significantly challenges forgesture control. Despite significant advances in AI and robotics, enablingmachines to understand and simulate hand-object interactions, capturing thesemantics of functional grasping tasks remains a considerable challenge. Whileprevious work can generate stable and correct 3D grasps, they are still farfrom achieving functional grasps due to unconsidered grasp semantics. Toaddress this challenge, we propose an innovative two-stage framework,Functional Grasp Synthesis Net (FGS-Net), for generating 3D HOI driven byfunctional text. This framework consists of a text-guided 3D model generator,Functional Grasp Generator (FGG), and a pose optimization strategy, FunctionalGrasp Refiner (FGR). FGG generates 3D models of hands and objects based on textinput, while FGR fine-tunes the poses using Object Pose Approximator and energyfunctions to ensure the relative position between the hand and object alignswith human intent and remains physically plausible. Extensive experimentsdemonstrate that our approach achieves precise and high-quality HOI generationwithout requiring additional 3D annotation data.</description>
      <author>example@mail.com (Yongqi Tian, Xueyu Sun, Haoyuan He, Linji Hao, Ning Ding, Caigui Jiang)</author>
      <guid isPermaLink="false">2502.20805v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Characteristics Analysis of Autonomous Vehicle Pre-crash Scenarios</title>
      <link>http://arxiv.org/abs/2502.20789v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文分析了加州的自动驾驶车辆碰撞报告，并基于修订后的预碰撞场景分类法，提出了一套自动提取预碰撞场景的映射规则。&lt;h4&gt;背景&lt;/h4&gt;近年来，在自动驾驶车辆（AV）的道路测试中发生了数百起事故，强调了提高其可靠性和安全性的重要性。现有的研究主要集中在传统的人类驾驶车辆上的碰撞分析上，缺少专门针对自动驾驶汽车深入碰撞分析的研究。&lt;h4&gt;目的&lt;/h4&gt;通过分析最新的加州自动驾驶车辆碰撞报告和使用修订后的预碰撞场景分类法来识别自动驾驶车辆的预碰撞场景，并提出优化建议以提高其性能。&lt;h4&gt;方法&lt;/h4&gt;提出了用于自动提取24种不同类型预碰撞场景（准确率为98.1%）的映射规则，特别关注了追尾场景和交叉口场景两大关键场景。对这些场景进行了详细的环境因素分析和因果关系分析。&lt;h4&gt;主要发现&lt;/h4&gt;在追尾场景中，交通控制类型、地点类型以及光线等是重要因素；对于可能引发严重碰撞事故的交叉口场景，则识别出了惯常违反规则与期望特定行为为主要原因。&lt;h4&gt;结论&lt;/h4&gt;本文的研究成果可帮助政府机构制定相关法规，指导制造商设计测试场景，并改进控制算法以优化自动驾驶系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;迄今为止，在自动车辆（AV）的道路测试中发生了数百起事故，突显了提高其可靠性和安全性的必要性。基于碰撞前情景分类法对交通事故进行分类，该方法依据车辆动态和运动学特征。在此基础上，特性分析可以识别类似特征下的相似碰撞情况，为更有效地反映一般碰撞模式并提供更具针对性的建议以提升AV性能提供了可能。然而，目前的研究主要集中在传统的人类驾驶车辆上发生的碰撞事件，缺乏专门针对自动驾驶汽车深度碰撞分析的研究内容。本文中，我们分析了最新的加州AV碰撞报告，并使用新修订的预碰撞场景分类法来识别这些碰撞情况下的预碰撞情景类型。我们提出了一套映射规则以自动提取这些AV预碰撞场景，并成功确定了24种不同类型的预碰撞场景（准确率为98.1%），并通过详细的分析获取了两个关键的AV碰撞场景，即追尾场景和交叉口场景。对追尾场景进行关联性分析后发现，显著的环境影响因素包括交通控制类型、地点类型以及光线等；对于可能引发严重事故的交叉口场景，则通过因果关系分析确定出了惯常违反规则与期望特定行为为主要成因。随后，我们制定了优化建议，既考虑了政府监管方面的需求，也针对AV制造商潜在改进进行了探讨。本文的研究成果能够帮助政府部门制定相关法规，并协助制造厂商设计出更有效的测试场景，在各种现实世界情景中识别出控制系统算法的潜在缺陷并加以优化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To date, hundreds of crashes have occurred in open road testing of automatedvehicles (AVs), highlighting the need for improving AV reliability and safety.Pre-crash scenario typology classifies crashes based on vehicle dynamics andkinematics features. Building on this, characteristics analysis can identifysimilar features under comparable crashes, offering a more effective reflectionof general crash patterns and providing more targeted recommendations forenhancing AV performance. However, current studies primarily concentrated oncrashes among conventional human-driven vehicles, leaving a gap in researchdedicated to in-depth AV crash analyses. In this paper, we analyzed the latestCalifornia AV collision reports and used the newly revised pre-crash scenariotypology to identify pre-crash scenarios. We proposed a set of mapping rulesfor automatically extracting these AV pre-crash scenarios, successfullyidentifying 24 types with a 98.1% accuracy rate, and obtaining two keyscenarios of AV crashes (i.e., rear-end scenarios and intersection scenarios)through detailed analysis. Association analyses of rear-end scenarios showedthat the significant environmental influencing factors were traffic controltype, location type, light, etc. For intersection scenarios prone to severecrashes with detailed descriptions, we employed causal analyses to obtain thesignificant causal factors: habitual violations and expectations of certainbehavior. Optimization recommendations were then formulated, addressing bothgovernmental oversight and AV manufacturers' potential improvements. Thefindings of this paper could guide government authorities to develop relatedregulations, help manufacturers design AV test scenarios, and identifypotential shortcomings in control algorithms specific to various real-worldscenarios, thereby optimizing AV systems effectively.</description>
      <author>example@mail.com (Yixuan Li, Xuesong Wang, Tianyi Wang, Qian Liu)</author>
      <guid isPermaLink="false">2502.20789v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>CSubBT: A Self-Adjusting Execution Framework for Mobile Manipulation System</title>
      <link>http://arxiv.org/abs/2502.20771v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于行为树的条件子树(CSubBT)框架，用于移动机器人在非结构化环境中执行任务时调整执行策略。&lt;h4&gt;背景&lt;/h4&gt;现代智能技术的发展使得装备有机械臂的移动机器人越来越多地应用于非结构化的环境。这些机器人可以根据感知到的信息规划出完成长期任务所需的行动序列，但实际操作中由于感知信息与实际情况不符导致计划失败的情况十分常见。&lt;h4&gt;目的&lt;/h4&gt;为了提高移动机器人的执行成功率和适应性，提出了一种能够自我调整的执行框架CSubBT。&lt;h4&gt;方法&lt;/h4&gt;CSubBT通过将象征性的动作分解为子动作，并使用行为树来控制这些子动作的执行，解决执行过程中的异常问题。该框架认为常见的异常问题是约束条件未满足的问题，在检测到异常时会指导机器人在约束空间内采样新的行动参数。&lt;h4&gt;主要发现&lt;/h4&gt;CSubBT能够有效应对移动机器人的任务执行过程中遇到的各种异常情况，并通过广泛的仿真和现实世界的实验展示了其鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;提出的CSubBT框架为解决移动机械臂操作中的计划与实际情况不匹配的问题提供了一种有效的解决方案，具有较好的实用性和推广价值。&lt;h4&gt;翻译&lt;/h4&gt;随着现代智能技术的进步，配备有机械臂的移动机器人越来越多地在非结构化的环境中运行。这些机器人可以基于感知信息制定长期任务的动作序列规划。然而，在实践中，由于规划所用的感知信息与实际情况不一致，计划经常失败。本文提出了一种基于行为树（BT）的行为子树（CSubBT），这是一种为具有机械臂的任务的移动机器人的自适应执行而设计的一般框架。CSubBT将象征性动作分解成子动作，并使用BT来控制它们的执行，在过程中处理任何可能的异常情况。当检测到异常时，它会通过在约束空间内采样新的操作参数连续指导机器人完成任务。我们通过广泛的模拟和现实世界环境中的机械臂实验展示了该框架的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advancements in modern intelligent technologies, mobile robotsequipped with manipulators are increasingly operating in unstructuredenvironments. These robots can plan sequences of actions for long-horizon tasksbased on perceived information. However, in practice, the planned actions oftenfail due to discrepancies between the perceptual information used for planningand the actual conditions. In this paper, we introduce the {\itshapeConditional Subtree} (CSubBT), a general self-adjusting execution framework formobile manipulation tasks based on Behavior Trees (BTs). CSubBT decomposessymbolic action into sub-actions and uses BTs to control their execution,addressing any potential anomalies during the process. CSubBT treats commonanomalies as constraint non-satisfaction problems and continuously guides therobot in performing tasks by sampling new action parameters in the constraintspace when anomalies are detected. We demonstrate the robustness of ourframework through extensive manipulation experiments on different platforms,both in simulation and real-world settings.</description>
      <author>example@mail.com (Huihui Guo, Huizhang Luo, Huilong Pi, Mingxing Duan, Kenli Li, Chubo Liu)</author>
      <guid isPermaLink="false">2502.20771v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>A2DO: Adaptive Anti-Degradation Odometry with Deep Multi-Sensor Fusion for Autonomous Navigation</title>
      <link>http://arxiv.org/abs/2502.20767v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6+1pages, 6 figures, accept by ICRA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为A2DO的新系统，该系统通过深度神经网络在挑战性条件下提高了SLAM系统的鲁棒性和定位准确性。&lt;h4&gt;背景&lt;/h4&gt;自主车辆的安全和有效导航需要精确的定位，而同时进行定位与地图构建（SLAM）技术是实现这一目标的关键。然而，在不良天气、光线不足或障碍物等情况下，传感器退化会影响SLAM系统的性能。&lt;h4&gt;目的&lt;/h4&gt;通过结合多传感器数据并利用深度学习技术来提高在各种复杂条件下的自主车辆导航系统精度和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;A2DO是一个端到端的融合了LiDAR与视觉数据的里程计系统，它使用了一个多层次、多尺度特征编码模块，并引入注意力机制以动态减轻传感器退化问题。该模型在广泛覆盖各种退化场景的模拟数据集上进行了预训练，并通过精选的真实世界数据进一步微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，A2DO能够在多种传感器退化条件下保持优越的定位准确性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了一个具备潜在实用价值的方法来提高自主车辆导航系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;精确的定位对于自主车辆的安全和有效导航至关重要。SLAM是这个领域中的关键技术，但在诸如低光照、恶劣天气或传感器退化等不利条件下，其表现会下降。我们提出了一个基于深度神经网络的新系统A2DO，旨在通过融合LiDAR和视觉数据来提升这些情况下的鲁棒性。该系统采用了多层、多尺度特征编码模块并加入了注意力机制以动态解决传感器退化问题，并且在模拟及真实世界的数据集上进行了广泛的训练与微调。实验结果表明，A2DO能够在各种传感器降级条件下保持卓越的定位准确性和稳定性，展示出其实用实施于自主车辆系统中的巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate localization is essential for the safe and effective navigation ofautonomous vehicles, and Simultaneous Localization and Mapping (SLAM) is acornerstone technology in this context. However, The performance of the SLAMsystem can deteriorate under challenging conditions such as low light, adverseweather, or obstructions due to sensor degradation. We present A2DO, a novelend-to-end multi-sensor fusion odometry system that enhances robustness inthese scenarios through deep neural networks. A2DO integrates LiDAR and visualdata, employing a multi-layer, multi-scale feature encoding module augmented byan attention mechanism to mitigate sensor degradation dynamically. The systemis pre-trained extensively on simulated datasets covering a broad range ofdegradation scenarios and fine-tuned on a curated set of real-world data,ensuring robust adaptation to complex scenarios. Our experiments demonstratethat A2DO maintains superior localization accuracy and robustness acrossvarious degradation conditions, showcasing its potential for practicalimplementation in autonomous vehicle systems.</description>
      <author>example@mail.com (Hui Lai, Qi Chen, Junping Zhang, Jian Pu)</author>
      <guid isPermaLink="false">2502.20767v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Acquiring Grounded Representations of Words with Situated Interactive Instruction</title>
      <link>http://arxiv.org/abs/2502.20754v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种通过混合主动性、情境化的互动与人类指导者交流来获取单词的接地表示的方法。&lt;h4&gt;背景&lt;/h4&gt;研究集中在从感知知识、语义知识和程序知识中获得多样化类型的知识，并学习它们的接地含义。&lt;h4&gt;目的&lt;/h4&gt;允许代理通过请求关于未知概念的指令，控制其学习过程，从而提高学习效率。&lt;h4&gt;方法&lt;/h4&gt;该方法在Soar系统中实现了，并在一个能够操控小型物体的桌面机器人手臂上进行了测试和评估。&lt;h4&gt;主要发现&lt;/h4&gt;交互式学习使得智能体可以高效地获取不同类型的知识并理解和操作未知概念。&lt;h4&gt;结论&lt;/h4&gt;提出的这种方法有效地提高了代理通过与人类互动来学习复杂知识的能力。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种从混合主动性和情境化的互动中，通过与人类指导者的交流获得单词的接地表示的方法。该方法关注于多样化类型的知识获取，包括感知、语义和程序性知识，并且旨在学习这些概念的接地含义。交互式的学习允许智能体控制其学习过程，通过请求有关未知概念的指令，从而使其学习过程更加高效。这种方法在Soar系统中实现，并在一个能够操控小型物体的桌面机器人手臂上进行了评估。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present an approach for acquiring grounded representations of words frommixed-initiative, situated interactions with a human instructor. The workfocuses on the acquisition of diverse types of knowledge including perceptual,semantic, and procedural knowledge along with learning grounded meanings.Interactive learning allows the agent to control its learning by requestinginstructions about unknown concepts, making learning efficient. Our approachhas been instantiated in Soar and has been evaluated on a table-top robotic armcapable of manipulating small objects.</description>
      <author>example@mail.com (Shiwali Mohan, Aaron H. Mininger, James R. Kirk, John E. Laird)</author>
      <guid isPermaLink="false">2502.20754v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Indoor Localization for Autonomous Robot Navigation</title>
      <link>http://arxiv.org/abs/2502.20731v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了室内定位系统在自主机器人导航中的应用，研究团队收集了一个数据集并训练模型以测试机器人，并开发了一种A*路径规划算法。经过不同网络结构的测试，机器人的成功转弯率为50%左右。&lt;h4&gt;背景&lt;/h4&gt;随着户外导航技术的发展，在日常生活中的重要性日益增加，室内定位系统（IPS）受到了广泛关注和研究。&lt;h4&gt;目的&lt;/h4&gt;探索利用室内定位系统完成自主机器人在室内的导航任务。&lt;h4&gt;方法&lt;/h4&gt;1. 收集并训练数据集以测试机器人；2. 开发A*路径规划算法使机器人能够使用预测方向自我导航。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验，机器人的成功转弯率为50%左右。&lt;h4&gt;结论&lt;/h4&gt;利用室内定位系统进行自主机器人导航是未来研究的一个有前途的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Indoor positioning systems (IPSs) have gained attention as outdoor navigationbecomes prevalent in everyday life. Research is being actively conducted on howindoor smartphone navigation can be accomplished and improved using receivedsignal strength indication (RSSI) and machine learning (ML). IPSs have more usecases that need further exploration, and we aim to explore using IPSs for theindoor navigation of an autonomous robot. We collected a dataset and trainedmodels to test on a robot. We also developed an A* path-planning algorithm sothat our robot could navigate itself using predicted directions. After testingdifferent network structures, our robot was able to successfully navigatecorners around 50 percent of the time. The findings of this paper indicate thatusing IPSs for autonomous robots is a promising area of future research.</description>
      <author>example@mail.com (Sean Kouma, Rachel Masters)</author>
      <guid isPermaLink="false">2502.20731v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>FSMP: A Frontier-Sampling-Mixed Planner for Fast Autonomous Exploration of Complex and Large 3-D Environments</title>
      <link>http://arxiv.org/abs/2502.20707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13pages, 12 figures, accepted by IEEE Transactions on Instrumentation  and Measurement&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种使用微型空中飞行器（MAVs）快速探索复杂且庞大的3-D环境的系统框架。&lt;h4&gt;背景&lt;/h4&gt;在复杂和大规模的三维环境中进行有效的探索具有挑战性，传统的基于前沿或随机采样的方法难以实现高效和完整的覆盖。&lt;h4&gt;目的&lt;/h4&gt;为了提高探索效率并确保完整性和可靠性，提出了一种结合了基于前沿的方法和基于采样策略的新型框架。&lt;h4&gt;方法&lt;/h4&gt;{'前端检测器': '设计了一个以视野为基础（FOV）的前沿探测器，该探测器保证完成度和正确性', '确定性采样技术': '采用确定性的采样技术来建立和维护基于记录的传感器视场和新检测到的前沿的增量式道路地图。', '路径规划器': '提出了一个两阶段路径规划算法：第一阶段使用惰性评估策略快速计算全局最优探索路线；第二阶段对最佳探索路径进行平滑处理以进一步提高探索效率。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果验证了该方法在模拟和现实环境中的有效性，展示了其在探索效率、计算时间和已探索体积方面的出色表现。&lt;h4&gt;结论&lt;/h4&gt;所提出的快速探索框架为复杂3-D环境下的MAV应用提供了一种高效且可靠的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种使用微型空中飞行器（MAVs）的系统性框架，用于快速探索复杂的大型三维环境。该方法的核心见解在于有机地整合基于前沿和采样策略的方法，以实现环境的整体快速探索。设计了一个基于视野（FOV）的前端检测器，确保了完整性和正确性的前提下识别三维地图边界。与随机采样法不同的是，采用确定性采样技术来建立并维护一种增量式道路图，该图依赖于记录下来的传感器视场以及新发现的前沿。利用所构建的道路图，提出了一种两阶段路径规划算法：首阶段快速计算出全局最优探索路线；次阶段则进一步平滑优化此最佳路线以提高效率。文中通过仿真和现实世界中的实验验证了这一方法的有效性，并且比较结果表明该框架在探索效率、计算时间和已探索体积方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a systematic framework for fast exploration ofcomplex and large 3-D environments using micro aerial vehicles (MAVs). The keyinsight is the organic integration of the frontier-based and sampling-basedstrategies that can achieve rapid global exploration of the environment.Specifically, a field-of-view-based (FOV) frontier detector with the guaranteeof completeness and soundness is devised for identifying 3-D map frontiers.Different from random sampling-based methods, the deterministic samplingtechnique is employed to build and maintain an incremental road map based onthe recorded sensor FOVs and newly detected frontiers. With the resulting roadmap, we propose a two-stage path planner. First, it quickly computes the globaloptimal exploration path on the road map using the lazy evaluation strategy.Then, the best exploration path is smoothed for further improving theexploration efficiency. We validate the proposed method both in simulation andreal-world experiments. The comparative results demonstrate the promisingperformance of our planner in terms of exploration efficiency, computationaltime, and explored volume.</description>
      <author>example@mail.com (Shiyong Zhang, Xuebo Zhang, Qianli Dong, Ziyu Wang, Haobo Xi, Jing Yuan)</author>
      <guid isPermaLink="false">2502.20707v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>WorldModelBench: Judging Video Generation Models As World Models</title>
      <link>http://arxiv.org/abs/2502.20694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;视频生成模型在快速发展，能够支持决策应用如机器人和自动驾驶。然而现有的基准测试未能严格评估这些能力。&lt;h4&gt;背景&lt;/h4&gt;当前的基准测试只关注通用视频质量，忽略了世界建模所需的重要因素，例如物理规则遵守情况。&lt;h4&gt;目的&lt;/h4&gt;为了弥补这一差距，我们提出了WorldModelBench，一个旨在评价视频生成模型在应用驱动领域中世界建模能力的基准。&lt;h4&gt;方法&lt;/h4&gt;{'优势1': '通过引入指令跟随和物理规则遵守维度，WorldModelBench能检测细微的违规情况，如违反质量守恒定律的对象尺寸不规则变化的问题，这些问题被之前的基准所忽视。', '优势2': '通过大规模的人类偏好对齐，我们收集了67K人类标签来准确测量14个前沿模型。使用高质量的人类标签进一步微调了一个精确的评判者以自动化评估过程，并实现了比GPT-4o更高的预测世界建模违规平均精度。', '其他贡献': '训练模型与人工注释对齐，最大化来自评判者的奖励可以显著提高世界的建模能力'}&lt;h4&gt;主要发现&lt;/h4&gt;通过引入特定维度来检测细微问题和大规模的人类偏好对齐方法，WorldModelBench能更全面地评估视频生成模型的世界建模能力。&lt;h4&gt;结论&lt;/h4&gt;我们的研究强调了现有基准测试的局限性，并提出了一种改进的方法来准确评价这些模型的能力。该网站可以访问https://worldmodelbench-team.github.io&lt;h4&gt;翻译&lt;/h4&gt;视频生成模型正在迅速发展，将自己定位为支持决策应用（如机器人技术与自动驾驶）的世界模型。然而，当前的评估基准未能严格验证这些声明，只关注通用视频质量，忽略世界建模所需的重要因素，比如物理一致性等。为解决这一问题，我们提出了WorldModelBench，一个旨在测试视频生成模型在应用驱动领域的世界建模能力的新标准。该基准的主要优势在于：1）能够检测细微的世界建模违规情况，如违反了质量守恒定律的对象尺寸不规则变化；2）通过大规模的人类偏好对齐方法进行准确评估，利用67K人类标签来衡量多个前沿模型，并微调评判者以自动化这一过程。结果表明，该方法比GPT-4o更为精确地预测世界建模违规情况。此外，我们展示了训练与人工注释对齐可以显著提高世界的建模能力。有关WorldModelBench的更多信息，请访问https://worldmodelbench-team.github.io&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video generation models have rapidly progressed, positioning themselves asvideo world models capable of supporting decision-making applications likerobotics and autonomous driving. However, current benchmarks fail to rigorouslyevaluate these claims, focusing only on general video quality, ignoringimportant factors to world models such as physics adherence. To bridge thisgap, we propose WorldModelBench, a benchmark designed to evaluate the worldmodeling capabilities of video generation models in application-driven domains.WorldModelBench offers two key advantages: (1) Against to nuanced worldmodeling violations: By incorporating instruction-following andphysics-adherence dimensions, WorldModelBench detects subtle violations, suchas irregular changes in object size that breach the mass conservation law -issues overlooked by prior benchmarks. (2) Aligned with large-scale humanpreferences: We crowd-source 67K human labels to accurately measure 14 frontiermodels. Using our high-quality human labels, we further fine-tune an accuratejudger to automate the evaluation procedure, achieving 8.6% higher averageaccuracy in predicting world modeling violations than GPT-4o with 2Bparameters. In addition, we demonstrate that training to align humanannotations by maximizing the rewards from the judger noticeably improve theworld modeling capability. The website is available athttps://worldmodelbench-team.github.io.</description>
      <author>example@mail.com (Dacheng Li, Yunhao Fang, Yukang Chen, Shuo Yang, Shiyi Cao, Justin Wong, Michael Luo, Xiaolong Wang, Hongxu Yin, Joseph E. Gonzalez, Ion Stoica, Song Han, Yao Lu)</author>
      <guid isPermaLink="false">2502.20694v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>From Safety Standards to Safe Operation with Mobile Robotic Systems Deployment</title>
      <link>http://arxiv.org/abs/2502.20693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper published at "Workshop on Design, Learning, and control for  safe human-robot collaboration at the International Conference on Advanced  Robotics (ICAR)"&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文审查了移动机器人在工作场所部署的安全标准和方法，并提出了一个新的风险评估框架来确保建筑工地上的安全使用。&lt;h4&gt;背景&lt;/h4&gt;移动机器人被广泛应用于各种工作环境以提高生产效率，但在拥挤且有危险的环境中与人类工人互动存在安全挑战。&lt;h4&gt;目的&lt;/h4&gt;为解决移动机器人在施工场地部署时的安全问题，提出一套全面的风险评估方法，并通过领域专家验证其有效性。&lt;h4&gt;方法&lt;/h4&gt;首先回顾了现有标准和相关研究文献，然后基于这些信息提出了一个改进的风险评估框架以覆盖未被现有的安全性指南涵盖的情景。&lt;h4&gt;主要发现&lt;/h4&gt;新的风险评估框架可以更好地保护工人免受移动机器人操作的潜在危害，并提供了具体的建议来降低此类风险。&lt;h4&gt;结论&lt;/h4&gt;通过扩展现有安全标准并提出额外的安全措施，该研究有助于更安全地部署和使用移动机器人在建筑工地和其他复杂环境中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile robotic systems are increasingly used in various work environments tosupport productivity. However, deploying robots in workplaces crowded by humanworkers and interacting with them results in safety challenges and concerns,namely robot-worker collisions and worker distractions in hazardousenvironments. Moreover, the literature on risk assessment as well as thestandard specific to mobile platforms is rather limited. In this context, thispaper first conducts a review of the relevant standards and methodologies andthen proposes a risk assessment for the safe deployment of mobile robots onconstruction sites. The approach extends relevant existing safety standards toencompass uncovered scenarios. Safety recommendations are made based on theframework, after its validation by field experts.</description>
      <author>example@mail.com (Bruno Belzile, Tatiana Wanang-Siyapdjie, Sina Karimi, Rafael Gomes Braga, Ivanka Iordanova, David St-Onge)</author>
      <guid isPermaLink="false">2502.20693v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>The Common Objects Underwater (COU) Dataset for Robust Underwater Object Detection</title>
      <link>http://arxiv.org/abs/2502.20651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了COU数据集，一个包含常见人造物体实例分割图像的水下图像库。&lt;h4&gt;背景&lt;/h4&gt;在水下环境中缺乏用于实例分割的高质量和多样化的数据集。现有的数据集主要关注海洋生物，而忽视了其他类型的水下物体。&lt;h4&gt;目的&lt;/h4&gt;创建一个新的数据集COU，涵盖多种不同环境下的常见人造物品，以促进轻量级实时检测器的研发，特别是针对自主式水下航行器（AUV）的训练需求。&lt;h4&gt;方法&lt;/h4&gt;从多个地点的机器人实地试验中收集图像，并对这些图像进行了详细的实例分割标注。使用三种最先进的模型来评估COU数据集在训练水下目标检测器方面的性能和准确性。&lt;h4&gt;主要发现&lt;/h4&gt;相比于仅基于地面数据训练的目标检测器，使用COU进行训练显著提高了检测器的表现和精确度。&lt;h4&gt;结论&lt;/h4&gt;COU是一个多样化的、高质量的数据集，专门用于改进自主式水下航行器的实时对象检测能力。该数据集将对研究界开放，并采用开源许可证提供。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一个名为COU（水下的常见物体）的数据集，这是一个包含多种水生和海洋环境中常见的人造物体实例分割图像的数据集。COU包含了大约10,000张标注过的分割图像，这些图像是从不同地点进行的多次水下机器人实地试验中收集而来的。该数据集旨在解决缺乏用于水下实例分割的稳健分类覆盖的问题，这对于训练轻量级、实时能力强大的自主式水下航行器（AUV）检测器特别有用。此外，COU解决了对象类别多样性的不足问题，因为常见的水下图像数据集仅关注海洋生物。目前，COU包含了来自封闭水域（泳池）和开放水域（湖泊和海洋）环境的24种不同类别的物体图像，包括海洋垃圾、潜水工具以及AUV等。为了评估COU在训练水下目标检测器方面的效果，我们使用三种最先进的模型来评估其性能和准确性，采用了标准准确率和效率指标相结合的方法。COU训练过的检测器相较于仅基于地面数据训练的检测器表现出明显的优势。我们将在开源许可下提供COU供广泛使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce COU: Common Objects Underwater, an instance-segmented imagedataset of commonly found man-made objects in multiple aquatic and marineenvironments. COU contains approximately 10K segmented images, annotated fromimages collected during a number of underwater robot field trials in diverselocations. COU has been created to address the lack of datasets with robustclass coverage curated for underwater instance segmentation, which isparticularly useful for training light-weight, real-time capable detectors forAutonomous Underwater Vehicles (AUVs). In addition, COU addresses the lack ofdiversity in object classes since the commonly available underwater imagedatasets focus only on marine life. Currently, COU contains images from bothclosed-water (pool) and open-water (lakes and oceans) environments, of 24different classes of objects including marine debris, dive tools, and AUVs. Toassess the efficacy of COU in training underwater object detectors, we usethree state-of-the-art models to evaluate its performance and accuracy, using acombination of standard accuracy and efficiency metrics. The improvedperformance of COU-trained detectors over those solely trained on terrestrialdata demonstrates the clear advantage of training with annotated underwaterimages. We make COU available for broad use under open-source licenses.</description>
      <author>example@mail.com (Rishi Mukherjee, Sakshi Singh, Jack McWilliams, Junaed Sattar)</author>
      <guid isPermaLink="false">2502.20651v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>EDENet: Echo Direction Encoding Network for Place Recognition Based on Ground Penetrating Radar</title>
      <link>http://arxiv.org/abs/2502.20643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于地表穿透雷达(GPR)的定位技术在机器人领域中的应用，并提出了一种新的网络架构EDENet来解决大规模地图中位置识别的问题。&lt;h4&gt;背景&lt;/h4&gt;GPR由于能够探测稳定的地下特征，在机器人领域得到了广泛应用。然而，现有的方法主要集中在小规模的位置识别上，忽略了大规模地图中所面临的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究GPR回波序列与地下场景之间的几何关系，并提出一种新的网络设计来应对大尺度位置识别的难题。&lt;h4&gt;方法&lt;/h4&gt;引入可学习的Gabor滤波器以精确提取方向响应，并结合方向感知注意力机制进行有效的几何编码。还使用了移不变单元和多尺度聚合策略，提高了对介电常数变化的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的EDENet在公共数据集上的实验表明，它不仅在位置识别性能上超越了现有解决方案，还在模型大小和计算效率方面具有优势。&lt;h4&gt;结论&lt;/h4&gt;通过提出创新的方法和技术，有效解决了大规模地图中基于GPR的位置识别问题，并展示了其优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ground penetrating radar (GPR) based localization has gained significantrecognition in robotics due to its ability to detect stable subsurfacefeatures, offering advantages in environments where traditional sensors likecameras and LiDAR may struggle. However, existing methods are primarily focusedon small-scale place recognition (PR), leaving the challenges of PR inlarge-scale maps unaddressed. These challenges include the inherent sparsity ofunderground features and the variability in underground dielectric constants,which complicate robust localization. In this work, we investigate thegeometric relationship between GPR echo sequences and underground scenes,leveraging the robustness of directional features to inform our network design.We introduce learnable Gabor filters for the precise extraction of directionalresponses, coupled with a direction-aware attention mechanism for effectivegeometric encoding. To further enhance performance, we incorporate ashift-invariant unit and a multi-scale aggregation strategy to betteraccommodate variations in di-electric constants. Experiments conducted onpublic datasets demonstrate that our proposed EDENet not only surpassesexisting solutions in terms of PR performance but also offers advantages inmodel size and computational efficiency.</description>
      <author>example@mail.com (Pengyu Zhang, Xieyuanli Chen, Yuwei Chen, Beizhen Bi, Zhuo Xu, Tian Jin, Xiaotao Huang, Liang Shen)</author>
      <guid isPermaLink="false">2502.20643v1</guid>
      <pubDate>Mon, 03 Mar 2025 17:08:25 +0800</pubDate>
    </item>
    <item>
      <title>Tuning Algorithmic and Architectural Hyperparameters in Graph-Based Semi-Supervised Learning with Provable Guarantees</title>
      <link>http://arxiv.org/abs/2502.12937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages (11 pages main body), 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文研究了图半监督学习中基于参数化算法家族的超参数调优问题，特别是针对经典标签传播算法家族以及现代图卷积神经网络（GCN）和简化图卷积（SGC）网络。论文提供了关于选择最优超参数所需的理论数据量的新上界，并为不同的图神经网络架构提供了Rademacher复杂度界。&lt;h4&gt;背景&lt;/h4&gt;图半监督学习在机器学习领域具有重要地位，它通过建模未标记数据与已标记数据之间的关系来利用隐含的图形结构。许多经典算法和现代深度学习方法被提出用于解决这一问题，这些算法通常含有可调超参数。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探讨如何从一系列参数化算法家族中调整适合图半监督学习任务的超参数，并研究其理论上的复杂性。&lt;h4&gt;方法&lt;/h4&gt;对于三个经典的基于标签传播的算法系列，论文获取了新的伪维度上界和匹配的下界，这些边界与节点数量n呈对数关系。此外，还考虑现代简化图卷积网络中的自环权重调优问题以及GCN和GAT之间的可调节架构选择问题。&lt;h4&gt;主要发现&lt;/h4&gt;对于三个基于标签传播的经典算法系列，在确定最优超参数时所需的训练数据量方面获得了对数级的理论边界；提出了一种可以同时包含GCN和GAT特征的新图神经网络架构，并给出了针对此架构调优参数时的学习复杂性分析。&lt;h4&gt;结论&lt;/h4&gt;本文通过形式化研究为调整图半监督学习算法中的超参数提供了有效的理论指导，这对未来设计高效的机器学习模型具有重要价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based semi-supervised learning is a powerful paradigm in machinelearning for modeling and exploiting the underlying graph structure thatcaptures the relationship between labeled and unlabeled data. A large number ofclassical as well as modern deep learning based algorithms have been proposedfor this problem, often having tunable hyperparameters. We initiate a formalstudy of tuning algorithm hyperparameters from parameterized algorithm familiesfor this problem. We obtain novel $O(\log n)$ pseudo-dimension upper bounds forhyperparameter selection in three classical label propagation-based algorithmfamilies, where $n$ is the number of nodes, implying bounds on the amount ofdata needed for learning provably good parameters. We further provide matching$\Omega(\log n)$ pseudo-dimension lower bounds, thus asymptoticallycharacterizing the learning-theoretic complexity of the parameter tuningproblem. We extend our study to selecting architectural hyperparameters inmodern graph neural networks. We bound the Rademacher complexity for tuning theself-loop weighting in recently proposed Simplified Graph Convolution (SGC)networks. We further propose a tunable architecture that interpolates graphconvolutional neural networks (GCN) and graph attention networks (GAT) in everylayer, and provide Rademacher complexity bounds for tuning the interpolationcoefficient.</description>
      <author>example@mail.com (Ally Yalei Du, Eric Huang, Dravyansh Sharma)</author>
      <guid isPermaLink="false">2502.12937v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
  <item>
      <title>SCA3D: Enhancing Cross-modal 3D Retrieval via 3D Shape and Caption Paired Data Augmentation</title>
      <link>http://arxiv.org/abs/2502.19128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的3D形状和描述在线数据增强方法SCA3D，用于跨模式的3D检索任务。通过使用LLaVA模型生成更多的文本-3D对来解决现有方法因缺乏多样化的3D数据而导致的表现不佳的问题。&lt;h4&gt;背景&lt;/h4&gt;跨模态3D检索旨在实现自然语言与3D形状之间的互匹配，但现有的方法由于缺乏高质量的3D数据而表现出较差的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;通过生成更多的3D-文本对来改善现有3D检索方法的表现，并增强其在多样的场景中的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;使用LLaVA模型为每个分割后的3D形状的部分生成描述，产生新的3D-文本配对；采用内部和外部距离将各组件组合成新3D形状；利用模板处理部件的描述并创建新文字描述；用单模态编码器提取改进数据集上的嵌入向量，并通过对比学习增强跨模式匹配。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的SCA3D方法在Text2Shape数据集中表现优越，相较于之前的工作显著提高了形状到文本和文本到形状的检索精度。&lt;h4&gt;结论&lt;/h4&gt;提出的方法证明了通过生成更多高质量的数据可以有效提升跨模态3D检索的表现，并且代码开源可供进一步研究使用。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容为：跨模态3D检索任务旨在实现自然语言描述与3D形状之间的相互匹配，这有可能增强自然语言和三维环境间的互动，在机器人技术和具身人工智能（AI）应用领域尤其如此。然而，由于缺乏高质量的3D数据，现有方法的表现受限，并且依赖于有限数量的3D形状特征导致在不同场景下的泛化能力较差。为解决这一挑战，我们引入了SCA3D，这是一种新的用于跨模态3D检索的数据增强方法，通过LLaVA模型创建一个组件库，为数据集中的每个3D形状的部分生成描述。这种方法不仅促进了包含新语义特征的大量新的3D-文本对的生成，还采用内外距离来将各组件组合成新的3D形状，并利用模板处理各个组件的描述以产生新的文字描述。此外，我们使用单模态编码器从增强的数据集中提取基于3D形状和文本的嵌入向量，并通过地球移动者距离（EMD）计算细粒度跨模式相似性并利用对比学习提高跨模式匹配能力，实现在文本与3D形状间的双向检索。广泛的实验表明，我们的SCA3D方法在Text2Shape数据集中超越了先前的工作，在形状到文本的RR@1评分从20.03提升至27.22和文本到形状的RR@1评分从13.12提升至16.67。相关代码可在https://github.com/3DAgentWorld/SCA3D中找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The cross-modal 3D retrieval task aims to achieve mutual matching betweentext descriptions and 3D shapes. This has the potential to enhance theinteraction between natural language and the 3D environment, especially withinthe realms of robotics and embodied artificial intelligence (AI) applications.However, the scarcity and expensiveness of 3D data constrain the performance ofexisting cross-modal 3D retrieval methods. These methods heavily rely onfeatures derived from the limited number of 3D shapes, resulting in poorgeneralization ability across diverse scenarios. To address this challenge, weintroduce SCA3D, a novel 3D shape and caption online data augmentation methodfor cross-modal 3D retrieval. Our approach uses the LLaVA model to create acomponent library, captioning each segmented part of every 3D shape within thedataset. Notably, it facilitates the generation of extensive new 3D-text pairscontaining new semantic features. We employ both inter and intra distances toalign various components into a new 3D shape, ensuring that the components donot overlap and are closely fitted. Further, text templates are utilized toprocess the captions of each component and generate new text descriptions.Besides, we use unimodal encoders to extract embeddings for 3D shapes and textsbased on the enriched dataset. We then calculate fine-grained cross-modalsimilarity using Earth Mover's Distance (EMD) and enhance cross-modal matchingwith contrastive learning, enabling bidirectional retrieval between texts and3D shapes. Extensive experiments show our SCA3D outperforms previous works onthe Text2Shape dataset, raising the Shape-to-Text RR@1 score from 20.03 to27.22 and the Text-to-Shape RR@1 score from 13.12 to 16.67. Codes can be foundin https://github.com/3DAgentWorld/SCA3D.</description>
      <author>example@mail.com (Junlong Ren, Hao Wu, Hui Xiong, Hao Wang)</author>
      <guid isPermaLink="false">2502.19128v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Increasing the Task Flexibility of Heavy-Duty Manipulators Using Visual 6D Pose Estimation of Objects</title>
      <link>http://arxiv.org/abs/2502.19169v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种管道，用于通过高级机器视觉对重型长距离机械臂的工具进行精确定位。该方法结合了深度神经网络和基于运动的摄像机与机器人校准。&lt;h4&gt;背景&lt;/h4&gt;近年来，使用深层神经网络在物体6D姿态估计方面的进展推动了基于视觉控制的新方式，尤其是在重型机器人应用中。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的管道系统，利用机器视觉技术实现对重型长距离机械臂工具的精确定位。&lt;h4&gt;方法&lt;/h4&gt;{'相机配置': '采用眼在手（eye-in-hand）的摄像机配置来直接估计感兴趣物体和工件的姿态', '姿态误差计算': '根据工具与目标之间的姿态误差进行精密定位，同时通过基于运动的校准完成摄像机到机器人的校准。', '训练数据': '仅使用合成数据训练用于估计对象兴趣（OOI）姿态的深度神经网络'}&lt;h4&gt;主要发现&lt;/h4&gt;{'精度': '实验结果表明，在非深度轴上实现了小于2毫米的平均图像定位误差，这有助于提高柔性重型长距离机械臂的任务灵活性和自动化水平。', '准确性提升': '通过基于图像算法避免了由于结构柔性的刚体运动学而引起的不准确度'}&lt;h4&gt;结论&lt;/h4&gt;所提出的方法提供了一种新颖的方式，以增加非刚性重型长距离机器人的任务灵活度与自动化程度，并且已经在现实世界中进行了验证。&lt;h4&gt;翻译&lt;/h4&gt;最近在利用深层神经网络进行物体6D姿态估计方面的进展促进了基于视觉的控制方法的发展，尤其是在重型机器人应用方面。在这项研究中，我们提出了一种使用高级机器视觉技术来实现重型长距离机械臂工具精确定位的新管道系统。该方案采用眼在手配置的相机直接估算工件和目标对象的姿态，并根据姿态误差以及摄像机与机器人之间的运动校准，通过常规工业上广泛使用的机器人建模和控制方法实现可靠的精密定位。所提出的方法包括基于视觉估计OOI姿态的位置对齐，而摄像机到机器人的校准则利用基于动作的视觉SLAM进行。这些技术试图通过图像基算法避免由于结构柔性的刚体运动学引起的不准确性。为了训练用于目标对象姿态估计的深度神经网络，仅使用合成数据。该方法在具有5米伸展范围的实际重型长距离机械臂上进行了验证。实验结果表明，在非深度轴上实现了低于2毫米的平均工具定位误差，这有助于增加柔性重型长距离机械臂的任务灵活性和自动化水平的一种新方式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in visual 6D pose estimation of objects using deep neuralnetworks have enabled novel ways of vision-based control for heavy-duty roboticapplications. In this study, we present a pipeline for the precise toolpositioning of heavy-duty, long-reach (HDLR) manipulators using advancedmachine vision. A camera is utilized in the so-called eye-in-hand configurationto estimate directly the poses of a tool and a target object of interest (OOI).Based on the pose error between the tool and the target, along withmotion-based calibration between the camera and the robot, precise toolpositioning can be reliably achieved using conventional robotic modeling andcontrol methods prevalent in the industry. The proposed methodology comprisesorientation and position alignment based on the visually estimated OOI poses,whereas camera-to-robot calibration is conducted based on motion utilizingvisual SLAM. The methods seek to avert the inaccuracies resulting fromrigid-body--based kinematics of structurally flexible HDLR manipulators viaimage-based algorithms. To train deep neural networks for OOI pose estimation,only synthetic data are utilized. The methods are validated in a real-worldsetting using an HDLR manipulator with a 5 m reach. The experimental resultsdemonstrate that an image-based average tool positioning error of less than 2mm along the non-depth axes is achieved, which facilitates a new way toincrease the task flexibility and automation level of non-rigid HDLRmanipulators.</description>
      <author>example@mail.com (Petri Mäkinen, Pauli Mustalahti, Tuomo Kivelä, Jouni Mattila)</author>
      <guid isPermaLink="false">2502.19169v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Online Meta-learning for AutoML in Real-time (OnMAR)</title>
      <link>http://arxiv.org/abs/2502.20279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  First page is a graphical abstract, this is a journal article  submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个在线元学习为实时自动机器学习（AutoML）的方法，即OnMAR。该方法利用元学习收集关于机器学习算法优化过程的信息，并使用元学习器预测模型设计的准确性以改进实时AutoML的设计质量与速度。&lt;h4&gt;背景&lt;/h4&gt;自动化机器学习(AutoML)是一个研究领域，旨在通过优化技术设计机器学习(ML)算法，减少人工干预的需求。实时AutoML允许在实际应用任务中进行设计过程。现有方法在质量和时间效率方面有待改善。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的在线元学习方法来提高实时AutoML的设计质量和速度。&lt;h4&gt;方法&lt;/h4&gt;使用了一种称为OnMAR的方法，通过遗传算法和不同的元学习器（k近邻、随机森林和XGBoost）进行模型预测。这种方法适用于多个不同场景下的实时AutoML应用，并进行了相应的测试。&lt;h4&gt;主要发现&lt;/h4&gt;OnMAR方法在三个不同的应用场景下展现了良好的效果，可以匹配甚至超越现有的实时AutoML方法，在设计时间和准确性方面都有显著优势。&lt;h4&gt;结论&lt;/h4&gt;在线元学习（OnMAR）是解决实时AutoML中模型优化问题的有效途径。它可以提升现有技术的性能，并且具有快速运行时间的优势。&lt;h4&gt;翻译&lt;/h4&gt;自动化机器学习(AutoML)是一个研究领域，专注于使用优化技术设计机器学习(ML)算法，以减轻人为手动设计算法的需求。实时AutoML使设计过程能够在应用到任务的同时进行。作为新兴的研究领域，现有的实时AutoML技术在设计质量和所需时间方面需要改进。为了解决这些问题，本研究提出了一种在线元学习用于实时AutoML的方法（OnMAR）。元学习收集了由机器学习算法在其优化过程中产生的元特征信息。这些元特征与一个元学习器结合使用以优化该过程。OnMAR方法采用元学习器来预测一个ML设计的准确性；如果预测准确度足够高，则接受此设计，反之则通过优化技术创建新的设计。作为OnMAR的一部分使用的优化技术是遗传算法(GA)。测试了不同的元学习器（k近邻、随机森林和XGBoost）。由于该方法与模型无关(即不特定于单个实时AutoML应用)，因此在三个不同的实时AutoML应用场景中进行了评估，包括：组成图像聚类算法、配置卷积神经网络的超参数以及设置视频分类管道。OnMAR方法是有效的，在性能上可以匹配或超越现有的实时AutoML方法，并具有更快运行时间的优点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated machine learning (AutoML) is a research area focusing on usingoptimisation techniques to design machine learning (ML) algorithms, alleviatingthe need for a human to perform manual algorithm design. Real-time AutoMLenables the design process to happen while the ML algorithm is being applied toa task. Real-time AutoML is an emerging research area, as such existingreal-time AutoML techniques need improvement with respect to the quality ofdesigns and time taken to create designs. To address these issues, this studyproposes an Online Meta-learning for AutoML in Real-time (OnMAR) approach.Meta-learning gathers information about the optimisation process undertaken bythe ML algorithm in the form of meta-features. Meta-features are used inconjunction with a meta-learner to optimise the optimisation process. The OnMARapproach uses a meta-learner to predict the accuracy of an ML design. If theaccuracy predicted by the meta-learner is sufficient, the design is used, andif the predicted accuracy is low, an optimisation technique creates a newdesign. A genetic algorithm (GA) is the optimisation technique used as part ofthe OnMAR approach. Different meta-learners (k-nearest neighbours, randomforest and XGBoost) are tested. The OnMAR approach is model-agnostic (i.e. notspecific to a single real-time AutoML application) and therefore evaluated onthree different real-time AutoML applications, namely: composing an imageclustering algorithm, configuring the hyper-parameters of a convolutionalneural network, and configuring a video classification pipeline. The OnMARapproach is effective, matching or outperforming existing real-time AutoMLapproaches, with the added benefit of a faster runtime.</description>
      <author>example@mail.com (Mia Gerber, Anna Sergeevna Bosman, Johan Pieter de Villiers)</author>
      <guid isPermaLink="false">2502.20279v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Scale Neighborhood Occupancy Masked Autoencoder for Self-Supervised Learning in LiDAR Point Clouds</title>
      <link>http://arxiv.org/abs/2502.20316v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的点云自监督学习方法NOMAE，通过只在非屏蔽体素的邻域内进行被遮罩占用重建来克服现有MAE在3D视觉中的挑战。&lt;h4&gt;背景&lt;/h4&gt;Masked autoencoders (MAE) 在图像等领域的自我监督学习中展现出巨大潜力。然而，在自动驾驶领域使用的LiDAR点云数据面临着特殊的挑战，因为大量空旷区域的存在导致了信息泄露和计算复杂度的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服现有的3D MAE的局限性，特别是针对大型、复杂的点云场景中的问题进行优化。&lt;h4&gt;方法&lt;/h4&gt;引入了基于体素屏蔽和层级生成技术的方法NOMAE。该方法在非屏蔽体素的邻域内执行被遮罩占用重建，并且可以在不同的尺度上集成多级体素屏蔽与占用重建，以捕捉不同大小的对象特征。&lt;h4&gt;主要发现&lt;/h4&gt;NOMAE可以灵活地应用于现有的3D架构中进行自监督学习，并且在nuScenes和Waymo Open数据集上的下游感知任务（如语义分割和3D目标检测）上显示出优越的性能，超过了现有方法的表现。&lt;h4&gt;结论&lt;/h4&gt;通过实验验证了NOMAE的有效性，它不仅解决了MAE在处理点云数据时遇到的问题，并且在多个基准测试中实现了当前最佳的性能表现。&lt;h4&gt;翻译&lt;/h4&gt;被遮罩自编码器（MAE）已经在视觉等领域中的自我监督学习中展现出巨大潜力。然而，在自动驾驶领域使用的LiDAR采集到的3D点云数据特别具有挑战性，因为这些数据中有大量的空旷区域是空白的。因此，现有的工作在解码过程中泄露了占用信息，并且存在较大的计算复杂度，这使得自监督预训练仅限于2D鸟瞰视图编码器的实际应用中。本文提出了一种新颖的方法——邻域占用MAE（NOMAE），通过只在非屏蔽体素的邻域内进行被遮罩占用重建来克服上述挑战。我们利用所提出的层级掩码生成技术，在多个尺度上集成体素屏蔽与占用重建，以捕捉不同大小的对象特征。NOMAE具有极高的灵活性，并可以直接用于现有3D架构中的自监督学习。我们在nuScenes和Waymo Open数据集上的下游感知任务（如语义分割和3D目标检测）中进行了广泛的评估，与判别性和生成性自我监督方法进行比较。实验结果表明，NOMAE在多个基准测试的点云感知任务上设定了新的最佳性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked autoencoders (MAE) have shown tremendous potential for self-supervisedlearning (SSL) in vision and beyond. However, point clouds from LiDARs used inautomated driving are particularly challenging for MAEs since large areas ofthe 3D volume are empty. Consequently, existing work suffers from leakingoccupancy information into the decoder and has significant computationalcomplexity, thereby limiting the SSL pre-training to only 2D bird's eye viewencoders in practice. In this work, we propose the novel neighborhood occupancyMAE (NOMAE) that overcomes the aforementioned challenges by employing maskedoccupancy reconstruction only in the neighborhood of non-masked voxels. Weincorporate voxel masking and occupancy reconstruction at multiple scales withour proposed hierarchical mask generation technique to capture features ofobjects of different sizes in the point cloud. NOMAEs are extremely flexibleand can be directly employed for SSL in existing 3D architectures. We performextensive evaluations on the nuScenes and Waymo Open datasets for thedownstream perception tasks of semantic segmentation and 3D object detection,comparing with both discriminative and generative SSL methods. The resultsdemonstrate that NOMAE sets the new state-of-the-art on multiple benchmarks formultiple point cloud perception tasks.</description>
      <author>example@mail.com (Mohamed Abdelsamad, Michael Ulrich, Claudius Gläser, Abhinav Valada)</author>
      <guid isPermaLink="false">2502.20316v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>GenPC: Zero-shot Point Cloud Completion via 3D Generative Priors</title>
      <link>http://arxiv.org/abs/2502.19896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;现有的点云补全方法在处理现实世界扫描数据时遇到了挑战，因为它们依赖于预定义的合成训练数据集。为此，我们提出了一种名为GenPC的零样本完成框架，该框架利用明确的3D生成先验来重构高质量的真实世界扫描。&lt;h4&gt;背景&lt;/h4&gt;现有点云补全方法通常依赖于预先定义的合成训练数据集，在处理分布外的真实世界扫描时遇到困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的零样本点云补全框架，以克服现有方法在真实场景中的局限性。&lt;h4&gt;方法&lt;/h4&gt;开发了Depth Prompting模块和Geometric Preserving Fusion模块，前者通过深度图像将部分点云与单视图生成模型关联起来；后者确保最终结果保留原始的不完整结构。&lt;h4&gt;主要发现&lt;/h4&gt;基于互联网规模数据训练的最新前馈3D生成模型能够从单一视角图像中进行零样本设置下的3D生成。GenPC框架在常用基准测试上的大量实验验证了其优越性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;通过利用现有的大规模3D生成模型，我们提出了一个高效的零样本点云补全解决方案，这使我们在稳健的真实世界扫描完成上更进一步。&lt;h4&gt;翻译&lt;/h4&gt;现有点云补全方法依赖于预先定义的合成训练数据集，在处理真实世界的分布外扫描时面临重大挑战。为了解决这一限制，我们提出了一种利用明确3D生成先验来重构高质量真实世界扫描的零样本补全框架GenPC。该框架的关键见解是基于近期前馈3D生成模型能够在仅使用单一视角图像的情况下从大规模互联网数据中进行零样本设置下的3D生成。为将此能力应用于补全任务，我们开发了一种Depth Prompting模块和一种Geometric Preserving Fusion模块。前者通过深度图作为中间步骤连接部分点云与单视图到三维的生成模型；后者则确保最终结果保留了原始输入中的不完整结构。大量实验验证了GenPC框架在常用基准测试上的优越性和泛化能力，使我们更接近于稳健的真实世界扫描完成目标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing point cloud completion methods, which typically depend on predefinedsynthetic training datasets, encounter significant challenges when applied toout-of-distribution, real-world scans. To overcome this limitation, weintroduce a zero-shot completion framework, termed GenPC, designed toreconstruct high-quality real-world scans by leveraging explicit 3D generativepriors. Our key insight is that recent feed-forward 3D generative models,trained on extensive internet-scale data, have demonstrated the ability toperform 3D generation from single-view images in a zero-shot setting. Toharness this for completion, we first develop a Depth Prompting module thatlinks partial point clouds with image-to-3D generative models by leveragingdepth images as a stepping stone. To retain the original partial structure inthe final results, we design the Geometric Preserving Fusion module that alignsthe generated shape with input by adaptively adjusting its pose and scale.Extensive experiments on widely used benchmarks validate the superiority andgeneralizability of our approach, bringing us a step closer to robustreal-world scan completion.</description>
      <author>example@mail.com (An Li, Zhe Zhu, Mingqiang Wei)</author>
      <guid isPermaLink="false">2502.19896v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Sanity Checking Causal Representation Learning on a Simple Real-World System</title>
      <link>http://arxiv.org/abs/2502.20099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文评估了因果表示学习（CRL）在简单现实世界系统中的效果，并通过光学实验验证方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;因果表示学习是近年来机器学习领域的热点问题，旨在从数据中提取出具有因果关系的特征。然而，现有理论与实际应用之间存在差距，需要进行更深入的研究以解决这些问题。&lt;h4&gt;目的&lt;/h4&gt;评估现有的因果表示学习方法在现实场景中的表现，并分析其失败的原因，从而推动该领域的发展。&lt;h4&gt;方法&lt;/h4&gt;构建了一个特定为CRL设计的光学实验系统，其中包含已知的因果因素和核心假设。选择了几种典型的CRL方法进行测试，并通过替换数据生成过程为简化合成等效的方法来进一步理解算法的失效模式。&lt;h4&gt;主要发现&lt;/h4&gt;现有的大多数CRL方法在合成的简化数据集上表现不佳，这表明它们可能无法很好地应用于实际场景中。此外，论文还观察到一些常用的混合函数假设对某些方法的效果至关重要，但在实际情况中这些假设往往不成立。&lt;h4&gt;结论&lt;/h4&gt;尽管因果表示学习理论前景广阔，但要在实践中取得成功仍面临诸多挑战。该研究提供了一个简单的现实世界基准测试，为验证和进一步发展CRL方法铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;我们评估了几种因果表示学习（CRL）的方法在简单且基于真实世界的系统中的表现，这些方法在这种环境下应该有效。实验采用的是一个特别为了进行这项研究而构建的受控光学实验，在这个系统中满足了CRL的核心假设，并且了解底层因果因素（实验输入），提供了一个事实基础。我们选择了几种典型的CRL方法并发现它们都无法恢复出真正的因果因素。为了理解被评估算法的失败模式，我们在数据上进行了消融研究，通过用一个简单的合成等效过程替换真实的数据生成过程来进行分析。结果揭示了可重复性问题，即大多数方法在简化后的合成版本中已经表现不佳，尽管其数据生成过程简单。此外，我们观察到常见的混合函数假设对于某些方法的性能至关重要，但在实际数据中这些假设并不成立。我们的研究强调了现有理论与实践应用之间的差距，并希望此基准测试作为进一步发展和验证CRL方法的一个简单的现实世界基础性检查。我们在github.com/simonbing/CRLSanityCheck上公开所有代码和数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We evaluate methods for causal representation learning (CRL) on a simple,real-world system where these methods are expected to work. The system consistsof a controlled optical experiment specifically built for this purpose, whichsatisfies the core assumptions of CRL and where the underlying causal factors(the inputs to the experiment) are known, providing a ground truth. We selectmethods representative of different approaches to CRL and find that they allfail to recover the underlying causal factors. To understand the failure modesof the evaluated algorithms, we perform an ablation on the data by substitutingthe real data-generating process with a simpler synthetic equivalent. Theresults reveal a reproducibility problem, as most methods already fail on thissynthetic ablation despite its simple data-generating process. Additionally, weobserve that common assumptions on the mixing function are crucial for theperformance of some of the methods but do not hold in the real data. Ourefforts highlight the contrast between the theoretical promise of the state ofthe art and the challenges in its application. We hope the benchmark serves asa simple, real-world sanity check to further develop and validate methodology,bridging the gap towards CRL methods that work in practice. We make all codeand datasets publicly available at github.com/simonbing/CRLSanityCheck</description>
      <author>example@mail.com (Juan L. Gamella, Simon Bing, Jakob Runge)</author>
      <guid isPermaLink="false">2502.20099v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Vector-Quantized Vision Foundation Models for Object-Centric Learning</title>
      <link>http://arxiv.org/abs/2502.20263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于对象中心学习（OCL）的方法VQ-VFM-OCL（简称VVO），该方法通过使用向量量化视觉基础模型来提取特征，并将这些特征进行量化以加强重建过程中的监督。&lt;h4&gt;背景&lt;/h4&gt;人类能够将视觉场景分解为不同的物体，这有助于理解物体之间的关系和动态。然而，基于自我监督的OCL在处理复杂纹理时面临挑战。为了改善这一点，许多方法采用视觉基础模型来提取更具有对象性的特征图。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用向量量化技术结合视觉基础模型的方法VQ-VFM-OCL（简称VVO），旨在改进现有OCL方法对复杂场景的理解能力，并促进下游任务的表现。&lt;h4&gt;方法&lt;/h4&gt;VVO通过从视觉基础模型中提取特征，以帮助对象级信息聚合；同时，通过对提取的特征进行量化来增强重建过程中的监督。此外，该工作统一了现有的OCL代表方法为一个简洁架构。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明VVO在物体识别任务上超越主流方法，并对下游如视觉预测和推理等任务有积极影响。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过结合向量量化技术与现有视觉基础模型，不仅提高了复杂场景下对象的识别能力，也为进一步研究提供了新的方向。源代码已公布于补充材料中。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decomposing visual scenes into objects, as humans do, facilitates modelingobject relations and dynamics. Object-Centric Learning (OCL) achieves this byaggregating image or video feature maps into object-level feature vectors,known as \textit{slots}. OCL's self-supervision via reconstructing the inputfrom slots struggles with complex textures, thus many methods employ VisionFoundation Models (VFMs) to extract feature maps with better objectness.However, using VFMs merely as feature extractors does not fully unlock theirpotential. We propose Vector-Quantized VFMs for OCL (VQ-VFM-OCL, or VVO), whereVFM features are extracted to facilitate object-level information aggregationand further quantized to strengthen supervision in reconstruction. Our VVOunifies OCL representatives into a concise architecture. Experimentsdemonstrate that VVO not only outperforms mainstream methods on objectdiscovery tasks but also benefits downstream tasks like visual prediction andreasoning. The source code is available in the supplement.</description>
      <author>example@mail.com (Rongzhen Zhao, Vivienne Wang, Juho Kannala, Joni Pajarinen)</author>
      <guid isPermaLink="false">2502.20263v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Teasing Apart Architecture and Initial Weights as Sources of Inductive Bias in Neural Networks</title>
      <link>http://arxiv.org/abs/2502.20237v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;人工神经网络可以从数据中获取许多人类知识的方面，成为模拟人类学习模型的理想选择。但是这些网络可以学到什么取决于它们的归纳偏置——除了数据之外影响其解决方案的因素。&lt;h4&gt;背景&lt;/h4&gt;尽管人工神经网络在模仿人类学习方面显示出巨大潜力，但对它们的归纳偏置的理解仍然不足，这限制了我们从这些系统的表现中得出关于人类学习结论的能力。认知科学家和机器学习研究人员通常关注神经网络架构作为归纳偏置的一个来源。&lt;h4&gt;目的&lt;/h4&gt;本研究探索初始权重作为另一个可能影响归纳偏置的因素，并利用元学习技术寻找适应特定问题的初始权重，从而减少不同架构和数据表示之间的性能差异。&lt;h4&gt;方法&lt;/h4&gt;通过在三个需要不同类型偏置和概括形式的任务上进行430个不同模型的元训练实验，测试了四种广泛使用的架构：多层感知器（MLPs）、卷积神经网络（CNNs）、长短期记忆网络（LSTMs）以及变换器。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，通过使用元学习可以显著减少或完全消除各种体系结构和数据表示之间的性能差异。此外，在远离元训练经验的问题上，所有架构均表现出差的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;这些发现表明，对于神经网络来说，初始权重可能是比通常认为更重要的归纳偏置来源。这强调了开发更强有力的归纳偏置以实现鲁棒泛化的必要性。&lt;h4&gt;翻译&lt;/h4&gt;人工神经网络可以从数据中获取人类知识的不同方面，显示出成为人类学习模型的巨大潜力。然而，这些网络可以学到什么取决于它们的先验假设——除了数据之外影响其解决方案的因素。尽管人工神经网络在模仿人类学习方面显示出巨大潜力，但对它们的归纳偏置的理解仍然不足，这限制了我们从这些系统的表现中得出关于人类学习结论的能力。认知科学家和机器学习研究人员通常关注神经网络架构作为归纳偏置的一个来源，在本文中我们探讨了一个其他的影响因素——初始权重，并使用元学习作为一种工具来寻找适应特定问题的初始权重。通过在三个需要不同类型偏置和概括形式的任务上进行430个不同模型的元训练实验，测试了四种广泛使用的架构：多层感知器（MLPs）、卷积神经网络（CNNs）、长短期记忆网络（LSTMs）以及变换器。研究发现，在特定问题上通过使用元学习可以显著减少或完全消除各种体系结构和数据表示之间的性能差异。此外，在远离元训练经验的问题上，所有架构均表现出差的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial neural networks can acquire many aspects of human knowledge fromdata, making them promising as models of human learning. But what thosenetworks can learn depends upon their inductive biases -- the factors otherthan the data that influence the solutions they discover -- and the inductivebiases of neural networks remain poorly understood, limiting our ability todraw conclusions about human learning from the performance of these systems.Cognitive scientists and machine learning researchers often focus on thearchitecture of a neural network as a source of inductive bias. In this paperwe explore the impact of another source of inductive bias -- the initialweights of the network -- using meta-learning as a tool for finding initialweights that are adapted for specific problems. We evaluate four widely-usedarchitectures -- MLPs, CNNs, LSTMs, and Transformers -- by meta-training 430different models across three tasks requiring different biases and forms ofgeneralization. We find that meta-learning can substantially reduce or entirelyeliminate performance differences across architectures and datarepresentations, suggesting that these factors may be less important as sourcesof inductive bias than is typically assumed. When differences are present,architectures and data representations that perform well without meta-learningtend to meta-train more effectively. Moreover, all architectures generalizepoorly on problems that are far from their meta-training experience,underscoring the need for stronger inductive biases for robust generalization.</description>
      <author>example@mail.com (Gianluca Bencomo, Max Gupta, Ioana Marinescu, R. Thomas McCoy, Thomas L. Griffiths)</author>
      <guid isPermaLink="false">2502.20237v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>DIN-CTS: Low-Complexity Depthwise-Inception Neural Network with Contrastive Training Strategy for Deepfake Speech Detection</title>
      <link>http://arxiv.org/abs/2502.20225v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于低复杂度Depthwise-Inception Network (DIN)和对比训练策略(CTS)的深度神经网络方法，用于检测deepfake语音。&lt;h4&gt;背景&lt;/h4&gt;当前存在大量的伪造音频，这对社会和个人安全构成了威胁。需要一种有效的方法来区分真实语音和deepfake伪造语音。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效准确地识别deepfake语音的技术方案。&lt;h4&gt;方法&lt;/h4&gt;通过短时傅里叶变换(STFT)和线性滤波器(LF)将输入音频转换为频谱图，然后使用这些频谱图训练DIN。利用该网络提取真实语音的特征向量，并构建高斯分布模型以表示真实语音；测试样本与该分布的距离被用来判断其真实性。&lt;h4&gt;主要发现&lt;/h4&gt;在ASVspoof 2019 LA基准数据集上的实验结果表明，结合Depthwise-Inception Network和对比学习策略能够有效区分伪造音频和真实语音。使用一个参数量仅为1.77M的低复杂度DIN，在4秒短音频段上实现了4.6%的等错误率(EER)、95.4%的准确率(Acc.)、97.3%的F1值以及98.9%的AUC分数。&lt;h4&gt;结论&lt;/h4&gt;该系统在ASVspoof 2019 LA挑战赛中的单系统提交中表现最好，显示出其应用于实时应用的巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a deep neural network approach for deepfake speechdetection (DSD) based on a lowcomplexity Depthwise-Inception Network (DIN)trained with a contrastive training strategy (CTS). In this framework, inputaudio recordings are first transformed into spectrograms using Short-TimeFourier Transform (STFT) and Linear Filter (LF), which are then used to trainthe DIN. Once trained, the DIN processes bonafide utterances to extract audioembeddings, which are used to construct a Gaussian distribution representinggenuine speech. Deepfake detection is then performed by computing the distancebetween a test utterance and this distribution to determine whether theutterance is fake or bonafide. To evaluate our proposed systems, we conductedextensive experiments on the benchmark dataset of ASVspoof 2019 LA. Theexperimental results demonstrate the effectiveness of combining theDepthwise-Inception Network with the contrastive learning strategy indistinguishing between fake and bonafide utterances. We achieved Equal ErrorRate (EER), Accuracy (Acc.), F1, AUC scores of 4.6%, 95.4%, 97.3%, and 98.9%respectively using a single, low-complexity DIN with just 1.77 M parameters and985 M FLOPS on short audio segments (4 seconds). Furthermore, our proposedsystem outperforms the single-system submissions in the ASVspoof 2019 LAchallenge, showcasing its potential for real-time applications.</description>
      <author>example@mail.com (Lam Pham, Dat Tran, Florian Skopik, Alexander Schindler, Silvia Poletti, Fischinger David, Martin Boyer)</author>
      <guid isPermaLink="false">2502.20225v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>A2-GNN: Angle-Annular GNN for Visual Descriptor-free Camera Relocalization</title>
      <link>http://arxiv.org/abs/2502.20036v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in 2025 International Conference on 3D Vision (3DV)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为Angle-Annular Graph Neural Network (A2-GNN)的方法，用于直接进行2D和3D关键点匹配而无需使用视觉描述符。这种方法通过环状特征提取来高效学习鲁棒的几何结构表示，并在没有视觉描述符的情况下实现了目前最高的精度。&lt;h4&gt;背景&lt;/h4&gt;视觉定位涉及估计已知场景中6自由度（6-DoF）相机的姿态，其中识别2D查询图像与3D模型之间的像素到点对应关系是一个关键步骤。当前最先进的方法依赖于广泛的视觉描述符来建立这些对应关系，但面临存储、隐私问题和模型维护的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单的方法，该方法能够克服现有无描述符方法中的低精度或重计算量的问题，并实现高效的2D-3D关键点匹配。&lt;h4&gt;方法&lt;/h4&gt;论文引入了Angle-Annular Graph Neural Network (A2-GNN)，这种网络通过环状特征提取来学习鲁棒的几何结构表示。它将邻域聚类并嵌入每个组的距离信息和角度作为补充信息，以捕捉局部结构。&lt;h4&gt;主要发现&lt;/h4&gt;在匹配和视觉定位数据集上的评估表明，该方法在无需视觉描述符的情况下达到了最先进的精度，并且计算开销低。&lt;h4&gt;结论&lt;/h4&gt;A2-GNN提供了一种有效的方法来解决直接进行2D-3D关键点匹配的挑战，克服了现有无描述符方法中的精度和计算量问题。此研究为未来的视觉定位工作奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容：视觉定位涉及估计已知场景中6自由度（6-DoF）相机的姿态。其中的一个关键步骤是识别2D查询图像与3D模型之间的像素到点的对应关系。当前最先进的方法依赖于广泛的视觉描述符来建立这些对应关系，但是面临存储、隐私问题以及模型维护的问题挑战。无视觉描述符直接进行2D-3D关键点匹配的方法正在变得流行，因为这种方法可以克服这些问题。然而现有的无描述符方法面临着低精度或重计算量的挑战。为了解决这个问题，本文引入了一种名为Angle-Annular Graph Neural Network (A2-GNN) 的简单方法来高效学习具有鲁棒几何结构表示能力的网络，并通过环状特征提取补充距离信息和角度作为辅助信息以捕捉局部结构。在匹配和视觉定位数据集上的评估表明，我们的方法达到了无需描述符的情况下最高的精度且计算量较低。代码将在 https://github.com/YejunZhang/a2-gnn 发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization involves estimating the 6-degree-of-freedom (6-DoF)camera pose within a known scene. A critical step in this process isidentifying pixel-to-point correspondences between 2D query images and 3Dmodels. Most advanced approaches currently rely on extensive visual descriptorsto establish these correspondences, facing challenges in storage, privacyissues and model maintenance. Direct 2D-3D keypoint matching without visualdescriptors is becoming popular as it can overcome those challenges. However,existing descriptor-free methods suffer from low accuracy or heavy computation.Addressing this gap, this paper introduces the Angle-Annular Graph NeuralNetwork (A2-GNN), a simple approach that efficiently learns robust geometricstructural representations with annular feature extraction. Specifically, thisapproach clusters neighbors and embeds each group's distance information andangle as supplementary information to capture local structures. Evaluation onmatching and visual localization datasets demonstrates that our approachachieves state-of-the-art accuracy with low computational overhead among visualdescription-free methods. Our code will be released onhttps://github.com/YejunZhang/a2-gnn.</description>
      <author>example@mail.com (Yejun Zhang, Shuzhe Wang, Juho Kannala)</author>
      <guid isPermaLink="false">2502.20036v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>BEVDiffuser: Plug-and-Play Diffusion Model for BEV Denoising with Ground-Truth Guidance</title>
      <link>http://arxiv.org/abs/2502.19694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的扩散模型BEVDiffuser，用于减少鸟瞰图（BEV）表示中的噪声。该方法在nuScenes数据集上的实验表明，在不增加计算复杂度的情况下，显著提高了3D物体检测的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的BEV生成技术尽管有所进步，但仍然受到传感器限制和学习过程中的内在噪声影响，导致下游任务性能不佳。&lt;h4&gt;目的&lt;/h4&gt;通过使用地面真实对象布局作为引导来有效地减少BEV特征图中的噪声，从而提高现有BEV模型的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为BEVDiffuser的新扩散模型，在训练期间可以以插件方式增强现有的BEV模型而无需对架构进行任何修改。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明BEVDiffuser在nuScenes数据集上显著提高了3D物体检测的性能，mAP和NDS分别提高了12.3%和10.1%，且没有引入额外的计算复杂度。此外，在长尾物体检测以及恶劣天气和光照条件下表现优异。&lt;h4&gt;结论&lt;/h4&gt;BEVDiffuser能够有效提高现有BEV模型的准确性和鲁棒性，为自动驾驶任务提供更高质量的输入表示。&lt;h4&gt;翻译&lt;/h4&gt;鸟瞰图（BEV）表示在自主驾驶任务中起着关键作用。尽管最近在BEV生成方面取得了进展，但由传感器限制和学习过程产生的固有噪声仍然没有得到充分解决，导致次优的BEV表示，从而影响下游任务的表现。为了解决这个问题，我们提出了一种新的扩散模型BEVDiffuser，它使用地面真实对象布局作为指导来有效减少BEV特征图中的噪声。在nuScenes数据集上进行的广泛实验表明，BEVDiffuser具有出色的去噪和生成能力，在不增加额外计算复杂度的情况下显著提高了现有BEV模型的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bird's-eye-view (BEV) representations play a crucial role in autonomousdriving tasks. Despite recent advancements in BEV generation, inherent noise,stemming from sensor limitations and the learning process, remains largelyunaddressed, resulting in suboptimal BEV representations that adversely impactthe performance of downstream tasks. To address this, we propose BEVDiffuser, anovel diffusion model that effectively denoises BEV feature maps using theground-truth object layout as guidance. BEVDiffuser can be operated in aplug-and-play manner during training time to enhance existing BEV modelswithout requiring any architectural modifications. Extensive experiments on thechallenging nuScenes dataset demonstrate BEVDiffuser's exceptional denoisingand generation capabilities, which enable significant enhancement to existingBEV models, as evidenced by notable improvements of 12.3\% in mAP and 10.1\% inNDS achieved for 3D object detection without introducing additionalcomputational complexity. Moreover, substantial improvements in long-tailobject detection and under challenging weather and lighting conditions furthervalidate BEVDiffuser's effectiveness in denoising and enhancing BEVrepresentations.</description>
      <author>example@mail.com (Xin Ye, Burhaneddin Yaman, Sheng Cheng, Feng Tao, Abhirup Mallik, Liu Ren)</author>
      <guid isPermaLink="false">2502.19694v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>RURANET++: An Unsupervised Learning Method for Diabetic Macular Edema Based on SCSE Attention Mechanisms and Dynamic Multi-Projection Head Clustering</title>
      <link>http://arxiv.org/abs/2502.20224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 2 figures, 5 tables, submitted to The 28th International  Conference on Medical Image Computing and Computer Assisted Intervention  (MICCAI 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Diabetic Macular Edema (DME) 是糖尿病患者常见的并发症，是视力损害和失明的主要原因之一。虽然深度学习在医学图像分析中取得了显著进展，但传统的 DME 诊断仍然依赖于大量标注数据和主观的眼科医生评估，限制了实际应用。&lt;h4&gt;背景&lt;/h4&gt;糖尿病黄斑水肿（DME）是一种常见且严重的糖尿病并发症，它会导致视力障碍甚至失明。尽管基于深度学习的方法在医学图像分析方面已经取得了一定的进展，但传统的 DME 诊断依旧依赖于大量的标记数据和眼科医生主观评估，这限制了其实际应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需大量标注数据的自动化的 DME 诊断系统 RURANET++。&lt;h4&gt;方法&lt;/h4&gt;RURANET++ 框架采用优化后的 U-Net 架构，并嵌入空间和通道挤压与激励（SCSE）注意机制，以增强病变特征提取。在特征处理阶段，首先使用预训练的 GoogLeNet 提取视网膜图像中的深度特征；然后利用基于主成分分析（PCA）的方法将特征维度减少至 50 维，提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;引入了一种新的聚类算法，采用多投影头来显式地控制集群多样性，并动态调整相似性阈值以优化内类一致性与外类区分度。实验结果表明，该系统在多个指标上表现出色，包括最大准确率（0.8411）、精确度（0.8593）、召回率（0.8411）和 F1 分数（0.8390），并具备优秀的聚类质量。&lt;h4&gt;结论&lt;/h4&gt;本研究提供了一种高效的无监督解决方案，用于 DME 的诊断，在临床应用方面具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;糖尿病黄斑水肿（DME）是导致视力损害乃至失明的重要因素。尽管深度学习技术在医学图像分析领域取得了显著进展，但传统的 DME 诊断仍然依赖于大量的标注数据和眼科医生的主观判断，这限制了其实际应用范围。本研究提出了 RURANET++ 系统，它基于无监督学习方法进行自动化 DME 诊断，并通过优化 U-Net 架构、引入 SCSE 注意机制以及创新性地使用多投影头聚类算法等技术手段提高病变特征提取效率和准确性。实验结果表明该系统在多个评估指标上均表现出色，显示出其在临床应用中的巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diabetic Macular Edema (DME), a prevalent complication among diabeticpatients, constitutes a major cause of visual impairment and blindness.Although deep learning has achieved remarkable progress in medical imageanalysis, traditional DME diagnosis still relies on extensive annotated dataand subjective ophthalmologist assessments, limiting practical applications. Toaddress this, we present RURANET++, an unsupervised learning-based automatedDME diagnostic system. This framework incorporates an optimized U-Netarchitecture with embedded Spatial and Channel Squeeze &amp; Excitation (SCSE)attention mechanisms to enhance lesion feature extraction. During featureprocessing, a pre-trained GoogLeNet model extracts deep features from retinalimages, followed by PCA-based dimensionality reduction to 50 dimensions forcomputational efficiency. Notably, we introduce a novel clustering algorithmemploying multi-projection heads to explicitly control cluster diversity whiledynamically adjusting similarity thresholds, thereby optimizing intra-classconsistency and inter-class discrimination. Experimental results demonstratesuperior performance across multiple metrics, achieving maximum accuracy(0.8411), precision (0.8593), recall (0.8411), and F1-score (0.8390), withexceptional clustering quality. This work provides an efficient unsupervisedsolution for DME diagnosis with significant clinical implications.</description>
      <author>example@mail.com (Wei Yang, Yiran Zhu, Jiayu Shen, Yuhan Tang, Chengchang Pan, Hui He, Yan Su, Honggang Qi)</author>
      <guid isPermaLink="false">2502.20224v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Causal Effect Estimation under Networked Interference without Networked Unconfoundedness Assumption</title>
      <link>http://arxiv.org/abs/2502.19741v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2405.03342&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在网络环境下估计因果效应的问题，提出了一种基于可识别表示学习技术的网络效应估计器，并通过实验验证了该方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;在存在隐蔽共变量的情况下，现有的基于观察数据的方法通常无法有效估计网络影响。然而，在这种情况下，单位之间的交互可以提供重要的信息来恢复这些隐藏的共变量。&lt;h4&gt;目的&lt;/h4&gt;识别三种类型在网络推断中阻碍识别的潜在混淆因子，并通过利用可识别表示学习技术，提出一种新的网络效应估计算法。&lt;h4&gt;方法&lt;/h4&gt;提出了基于可识别表示学习技术的网络效应估计器。理论上确立了所有潜在混淆因子的可识别性，通过应用已确定的潜在混淆因子提供网络效应的识别结果。&lt;h4&gt;主要发现&lt;/h4&gt;三种类型的隐藏共变量影响个体、邻居或同时影响两者，并且这些因素阻碍了对网络效应的有效识别和估计。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅理论上证明了其在处理网络干扰下因果效应估计问题中的有效性，而且实验也验证了这一理论。通过这种方法，可以更准确地评估在网络环境中交互作用的影响。&lt;h4&gt;翻译&lt;/h4&gt;在存在网络干扰的情况下估计因果效应是一个关键且具有挑战性的问题。现有的基于观察数据的方法主要依赖于网络无偏性假设来保证网络效应的识别。然而，在实际情况下这种假设往往由于隐藏共变量的存在而被违反，这阻碍了对网络效应的有效识别。有趣的是，在这样的网络环境中，单位之间的交互提供了恢复隐藏共变量的重要信息。本文确定了在三个影响个体、仅影响邻居和同时影响两者的潜在混淆因子，并基于此提出了一个新的方法来估计网络效应并证明其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating causal effects under networked interference is a crucial yetchallenging problem. Existing methods based on observational data mainly relyon the networked unconfoundedness assumption, which guarantees theidentification of networked effects. However, the networked unconfoundednessassumption is usually violated due to the latent confounders in observationaldata, hindering the identification of networked effects. Interestingly, in suchnetworked settings, interactions between units provide valuable information forrecovering latent confounders. In this paper, we identify three types of latentconfounders in networked inference that hinder identification: those affectingonly the individual, those affecting only neighbors, and those influencingboth. Specifically, we devise a networked effect estimator based onidentifiable representation learning techniques. Theoretically, we establishthe identifiability of all latent confounders, and leveraging the identifiedlatent confounders, we provide the networked effect identification result.Extensive experiments validate our theoretical results and demonstrate theeffectiveness of the proposed method.</description>
      <author>example@mail.com (Weilin Chen, Ruichu Cai, Jie Qiao, Yuguang Yan, José Miguel Hernández-Lobato)</author>
      <guid isPermaLink="false">2502.19741v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Ev-3DOD: Pushing the Temporal Boundaries of 3D Object Detection with Event Cameras</title>
      <link>http://arxiv.org/abs/2502.19630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了在自动驾驶系统中的3D物体检测任务中使用异步事件相机的方法，解决了传统固定帧率传感器如LiDAR和摄像头带来的延迟和带宽限制问题。&lt;h4&gt;背景&lt;/h4&gt;当前的多模态方法虽然取得了良好的性能，但未能满足自动驾驶系统对于低延时、高效率的需求。传统的LiDAR和摄像头存在固有的时间延迟及带宽限制。&lt;h4&gt;目的&lt;/h4&gt;引入异步事件相机以提高3D物体检测的速度和准确性，并建立基于事件的数据集作为评估标准。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的基于事件的3D物体检测框架，利用事件相机的高时间分辨率和低带宽特性，在不同帧之间进行高效准确的3D物体检测。同时发布了一个新数据集DSEC-3DOD来支持这项研究。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入异步事件信息可以实现更快速、更低延迟的3D物体检测，特别是在常规传感器无法提供同步信息的时间间隔内也能完成任务。&lt;h4&gt;结论&lt;/h4&gt;文章证明了使用异步事件相机进行3D物体检测具有巨大的潜力，并为该领域的进一步研究提供了必要的资源。代码和数据集可在GitHub上获得。&lt;h4&gt;翻译&lt;/h4&gt;在点云中检测三维物体对于自动驾驶系统至关重要。最近，结合摄像信息的高级多模式方法取得了显著性能。为了实现安全有效的自主驾驶系统，不仅要准确还需要快速且延迟低的算法是必不可少的。然而现有的算法由于固定帧率传感器如LiDAR和摄像头的时间延迟及带宽限制未能达到这些要求。为了解决这个问题，首次将异步事件相机引入3D物体检测中。我们利用它们的高时间分辨率和低带宽特性来实现高速3D物体检测。通过在不同帧之间使用事件相机检索之前的3D信息，我们的方法甚至可以在无同步数据的时间间隔内进行检测。此外，提出了第一个基于事件的3D物体检测数据集DSEC-3DOD，该数据集中包含了每秒100帧的真实3D边界框，为基于事件的3D检测器建立了基准。代码和数据集可在https://github.com/mickeykang16/Ev3DOD获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting 3D objects in point clouds plays a crucial role in autonomousdriving systems. Recently, advanced multi-modal methods incorporating camerainformation have achieved notable performance. For a safe and effectiveautonomous driving system, algorithms that excel not only in accuracy but alsoin speed and low latency are essential. However, existing algorithms fail tomeet these requirements due to the latency and bandwidth limitations of fixedframe rate sensors, e.g., LiDAR and camera. To address this limitation, weintroduce asynchronous event cameras into 3D object detection for the firsttime. We leverage their high temporal resolution and low bandwidth to enablehigh-speed 3D object detection. Our method enables detection even duringinter-frame intervals when synchronized data is unavailable, by retrievingprevious 3D information through the event camera. Furthermore, we introduce thefirst event-based 3D object detection dataset, DSEC-3DOD, which includesground-truth 3D bounding boxes at 100 FPS, establishing the first benchmark forevent-based 3D detectors. The code and dataset are available athttps://github.com/mickeykang16/Ev3DOD.</description>
      <author>example@mail.com (Hoonhee Cho, Jae-young Kang, Youngho Kim, Kuk-Jin Yoon)</author>
      <guid isPermaLink="false">2502.19630v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Deep Convolutional Neural Networks for Palm Fruit Maturity Classification</title>
      <link>http://arxiv.org/abs/2502.20223v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项研究开发了一种基于深度卷积神经网络（CNN）的自动化视觉系统，用于准确分类油棕果图片的五个成熟度等级。&lt;h4&gt;背景&lt;/h4&gt;为了最大化油棕产量和质量，必须在最佳成熟期收获油棕果实。现有的方法依赖于人工评估，这可能导致效率低下和错误判断。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够自动分类油棕果图像成熟程度的计算机视觉系统，以便优化收割决策并提高油棕生产效率。&lt;h4&gt;方法&lt;/h4&gt;使用深度CNN对基于其成熟阶段的油棕果图片进行分类。浅层CNN作为基准模型，而迁移学习和微调则应用到预训练好的ResNet50和InceptionV3架构上。&lt;h4&gt;主要发现&lt;/h4&gt;该研究利用包含超过8,000张带有显著变化的照片的数据集，实现了超过85%的测试准确率。深度CNN模型在分类油棕果成熟阶段方面表现出了巨大的潜力。&lt;h4&gt;结论&lt;/h4&gt;这项工作强调了深度学习在自动评估油棕果实熟度方面的潜力，这可以有助于优化收割决策并提高油棕生产效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文描述了如何利用计算机视觉和深度学习技术来更准确地判断油棕果的成熟程度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To maximize palm oil yield and quality, it is essential to harvest palm fruitat the optimal maturity stage. This project aims to develop an automatedcomputer vision system capable of accurately classifying palm fruit images intofive ripeness levels. We employ deep Convolutional Neural Networks (CNNs) toclassify palm fruit images based on their maturity stage. A shallow CNN servesas the baseline model, while transfer learning and fine-tuning are applied topre-trained ResNet50 and InceptionV3 architectures. The study utilizes apublicly available dataset of over 8,000 images with significant variations,which is split into 80\% for training and 20\% for testing. The proposed deepCNN models achieve test accuracies exceeding 85\% in classifying palm fruitmaturity stages. This research highlights the potential of deep learning forautomating palm fruit ripeness assessment, which can contribute to optimizingharvesting decisions and improving palm oil production efficiency.</description>
      <author>example@mail.com (Mingqiang Han, Chunlin Yi)</author>
      <guid isPermaLink="false">2502.20223v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Generalize without Bias for Open-Vocabulary Action Recognition</title>
      <link>http://arxiv.org/abs/2502.20158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种用于开放词汇动作识别的新颖元优化框架Open-MeDe，该框架通过静态去偏改善了模型在新环境下（包括上下文中和上下文外）的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;最近的视频学习者利用CLIP初始化以提高开放词汇的动作识别中的泛化性。然而，由于CLIP自身的静态偏差问题，这些视频学习者倾向于过度拟合于快捷静态特征，从而导致对新动作的泛化性不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的元优化框架Open-MeDe来解决视频学习者的过度拟合问题，并改善其在开放词汇动作识别中的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入了跨批次元优化方案，该方案通过虚拟评估鼓励视频学习者快速泛化到任意后续数据上。此外，采用自集成策略获取可实现上下文内外新数据稳健泛化的最优参数。&lt;h4&gt;主要发现&lt;/h4&gt;Open-MeDe在没有CLIP正则化的情况下进行优化，隐式地减轻了视频元学习者的固有静态偏差，并且通过元学习方法改进了从已知到开放词汇的泛化能力以及图像到视频去偏能力。实验结果表明，Open-MeDe不仅超越了针对上下文中开放词汇动作识别定制的最佳正则化方法，在上下文外场景中也表现出色。&lt;h4&gt;结论&lt;/h4&gt;Open-MeDE通过元学习和自集成策略有效解决了当前视频模型在开放词汇动作识别中的泛化性问题，特别是对于新环境下的泛化能力有了显著提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging the effective visual-text alignment and static generalizabilityfrom CLIP, recent video learners adopt CLIP initialization with furtherregularization or recombination for generalization in open-vocabulary actionrecognition in-context. However, due to the static bias of CLIP, such videolearners tend to overfit on shortcut static features, thereby compromisingtheir generalizability, especially to novel out-of-context actions. To addressthis issue, we introduce Open-MeDe, a novel Meta-optimization framework withstatic Debiasing for Open-vocabulary action recognition. From a freshperspective of generalization, Open-MeDe adopts a meta-learning approach toimprove known-to-open generalizing and image-to-video debiasing in acost-effective manner. Specifically, Open-MeDe introduces a cross-batchmeta-optimization scheme that explicitly encourages video learners to quicklygeneralize to arbitrary subsequent data via virtual evaluation, steering asmoother optimization landscape. In effect, the free of CLIP regularizationduring optimization implicitly mitigates the inherent static bias of the videometa-learner. We further apply self-ensemble over the optimization trajectoryto obtain generic optimal parameters that can achieve robust generalization toboth in-context and out-of-context novel data. Extensive evaluations show thatOpen-MeDe not only surpasses state-of-the-art regularization methods tailoredfor in-context open-vocabulary action recognition but also substantially excelsin out-of-context scenarios.</description>
      <author>example@mail.com (Yating Yu, Congqi Cao, Yifan Zhang, Yanning Zhang)</author>
      <guid isPermaLink="false">2502.20158v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Do computer vision foundation models learn the low-level characteristics of the human visual system?</title>
      <link>http://arxiv.org/abs/2502.20256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究了基于自然图像训练的计算机视觉基础模型是否模仿人类视觉系统的基本特性，如对比度检测、对比掩蔽和对比恒常性。&lt;h4&gt;背景&lt;/h4&gt;计算机视觉基础模型（例如DINO或OpenCLIP）通过在大型图像数据集上进行自监督学习来训练。有大量证据表明，人类视觉系统受自然世界中颜色和图案统计分布的影响，这些特征也存在于基础模型的训练数据中。&lt;h4&gt;目的&lt;/h4&gt;评估45种基础和生成模型的图像编码器是否模拟了人类视觉系统的特性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个包含九个测试类型的协议来评估不同模型在对比度检测、对比掩蔽等方面的性能。&lt;h4&gt;主要发现&lt;/h4&gt;一些基础模型（例如DINO，DINOv2和OpenCLIP）具有与人类视觉相似的特性，但其他模型则表现出较少或无相似性。基础模型对低对比度的敏感性较低，并且在不同频率下的对比度响应较为不规则。&lt;h4&gt;结论&lt;/h4&gt;尽管存在差异，但在基于视觉任务训练的基础模型中，已经开始出现低级人类视觉特征的一致性趋势，尤其是DINOv2模型最为接近。&lt;h4&gt;翻译&lt;/h4&gt;计算机视觉基础模型通常通过自监督方式使用大规模图像数据集进行训练。类似于这些系统的是，大量证据表明，人类视觉系统受自然世界中颜色和图案统计分布的影响，这与基础模型训练数据中的特性相似。本研究探讨了基于自然图像训练的基础模型是否模仿了一些低级的人类视觉特性，例如对比度检测、对比掩蔽和对比恒常性。具体而言，设计了一种包含九个测试类型的协议来评估45种基础和生成模型的性能。结果表明，某些基础模型（如DINO、DINOv2和OpenCLIP）分享了一些人类视觉的特性，而其他模型则表现出较少或无相似之处。总体而言，虽然仍有差异存在，但基于视觉任务训练的基础模型开始显示出低级人类视觉特征的一致性趋势，特别是DINOv2模型最为接近。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computer vision foundation models, such as DINO or OpenCLIP, are trained in aself-supervised manner on large image datasets. Analogously, substantialevidence suggests that the human visual system (HVS) is influenced by thestatistical distribution of colors and patterns in the natural world,characteristics also present in the training data of foundation models. Thequestion we address in this paper is whether foundation models trained onnatural images mimic some of the low-level characteristics of the human visualsystem, such as contrast detection, contrast masking, and contrast constancy.Specifically, we designed a protocol comprising nine test types to evaluate theimage encoders of 45 foundation and generative models. Our results indicatethat some foundation models (e.g., DINO, DINOv2, and OpenCLIP), share some ofthe characteristics of human vision, but other models show little resemblance.Foundation models tend to show smaller sensitivity to low contrast and ratherirregular responses to contrast across frequencies. The foundation models showthe best agreement with human data in terms of contrast masking. Our findingssuggest that human vision and computer vision may take both similar anddifferent paths when learning to interpret images of the real world. Overall,while differences remain, foundation models trained on vision tasks start toalign with low-level human vision, with DINOv2 showing the closest resemblance.</description>
      <author>example@mail.com (Yancheng Cai, Fei Yin, Dounia Hammou, Rafal Mantiuk)</author>
      <guid isPermaLink="false">2502.20256v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive H&amp;E-IHC information fusion staining framework based on feature extra</title>
      <link>http://arxiv.org/abs/2502.20156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;免疫组化（IHC）染色在乳腺癌等疾病的评估中发挥着重要作用。基于生成模型的H&amp;E到IHC转换提供了一种简单且成本效益高的方法来获取IHC图像。&lt;h4&gt;背景&lt;/h4&gt;尽管之前的模型能够很好地进行数字上色，但它们仍然面临着两个挑战：(i) 仅通过HE图像中的像素特征来进行上色，容易导致染色过程中信息丢失；(ii) 缺乏像素级别的H&amp;E-IHC真实对给经典的L1损失带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;为了应对上述挑战，我们提出了一种基于特征提取器的自适应信息增强着色框架。&lt;h4&gt;方法&lt;/h4&gt;首先提出了VMFE模块，通过多尺度特征提取和小波变换卷积有效提取颜色信息特征，并结合共享解码器进行特征融合。高性能的H&amp;E-IHC双特征提取器通过对比学习训练，可以在高纬度空间内有效地执行HE-IHC特征对齐。&lt;h4&gt;主要发现&lt;/h4&gt;此外，在染色过程中使用经过训练的功能编码器来增强功能并自适应调整损失，解决了与模糊和不对称信息相关的问题。我们在不同的数据集上进行了测试，并取得了卓越的性能。&lt;h4&gt;结论&lt;/h4&gt;我们的代码可在https://github.com/babyinsunshine/CEFF获取&lt;h4&gt;翻译&lt;/h4&gt;免疫组化（IHC）染色在疾病评估中扮演重要角色，特别是在乳腺癌等疾病的诊断与研究。通过生成模型将H&amp;E图像转换为IHC图像的方法提供了一种成本效益高且简单的途径来获得IHC图像。尽管先前的模型能够很好地模拟数字着色过程，但它们仍存在两个主要问题：第一，仅使用HE图中不突出的像素特征进行染色会导致信息丢失；第二，缺乏准确的H&amp;E-IHC配对数据使得传统的L1损失难以有效应用。为了解决这些问题，我们提出了一种基于自适应增强与特征提取器的着色框架，该框架利用VMFE模块在多尺度上提取颜色信息，并通过对比学习训练提高特征匹配效果。实验结果显示了这一方法的有效性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Immunohistochemistry (IHC) staining plays a significant role in theevaluation of diseases such as breast cancer. The H&amp;E-to-IHC transformationbased on generative models provides a simple and cost-effective method forobtaining IHC images. Although previous models can perform digital coloringwell, they still suffer from (i) coloring only through the pixel features thatare not prominent in HE, which is easy to cause information loss in thecoloring process; (ii) The lack of pixel-perfect H&amp;E-IHC groundtruth pairsposes a challenge to the classical L1 loss.To address the above challenges, wepropose an adaptive information enhanced coloring framework based on featureextractors. We first propose the VMFE module to effectively extract the colorinformation features using multi-scale feature extraction and wavelet transformconvolution, while combining the shared decoder for feature fusion. Thehigh-performance dual feature extractor of H&amp;E-IHC is trained by contrastivelearning, which can effectively perform feature alignment of HE-IHC in highlatitude space. At the same time, the trained feature encoder is used toenhance the features and adaptively adjust the loss in the HE section stainingprocess to solve the problems related to unclear and asymmetric information. Wehave tested on different datasets and achieved excellent performance.Our codeis available at https://github.com/babyinsunshine/CEFF</description>
      <author>example@mail.com (Yifan Jia, Xingda Yu, Zhengyang Ji, Songning Lai, Yutao Yue)</author>
      <guid isPermaLink="false">2502.20156v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Your contrastive learning problem is secretly a distribution alignment problem</title>
      <link>http://arxiv.org/abs/2502.20141v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, NeurIPS 2024 submission, includes supplementary  material&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;尽管对比学习在视觉和语言领域的成功，其理论基础以及构建表示的机制仍不甚明了。这项工作探讨了广泛用于对比学习中的噪声对比估计损失与基于熵最优传输（OT）的分布对齐之间的联系，并由此开发了一系列新的损失函数及其多步迭代变体。&lt;h4&gt;背景&lt;/h4&gt;尽管对比学习在视觉和语言领域取得了成功，其理论基础及构建表示的方法仍然不清楚。传统的对比学习通常使用特定类型的噪声对比估计损失来实现。&lt;h4&gt;目的&lt;/h4&gt;通过建立噪声对比估计损失与基于熵最优传输的分布对齐之间的联系，发展新型对比学习方法，增强模型对于数据集中的噪音视图处理能力，并允许自定义表示空间以适应不同约束条件。&lt;h4&gt;方法&lt;/h4&gt;提出了一种利用更多潜在分布信息的方法来改进对比学习，通过这种方法可以更有效地调整扩充样本集合内的关系。此外，该研究还提供了理论洞见和实验证据证明了新方法在广义对比对齐中的优势。&lt;h4&gt;主要发现&lt;/h4&gt;通过将对比学习重新定义为一个分布对齐问题，并利用最优传输的优化工具，这项工作不仅揭示了不同自监督模型之间的新连接，而且提供了一套可以更轻松地融入领域知识的新工具。借助于这些框架和工具，能够构建不平衡损失以处理噪音视图。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，对比学习可以通过与基于熵最优传输的分布对齐相结合的方式得到新的理论洞见，并且提供了增强模型性能及适应性的新方法。&lt;h4&gt;翻译&lt;/h4&gt;尽管对比学习在视觉和语言任务中的成功令人瞩目，但对于其背后的理论基础以及如何构建有效表示的理解仍然有限。本文尝试建立噪声对比估计损失与基于熵最优传输的分布对齐之间的桥梁，开发出新的损失函数家族，并为现存的对比学习方法提供迭代变体方案。通过引入更多潜在分布的信息，研究者提出了一种更加‘感知’到数据集内部关系的方法，从而改进模型在处理噪音视图时的表现。实验结果显示了这种方法在广义对比对齐上的显著优势。此外，该研究还展示了如何重新解读对比学习为一个对齐问题，并利用现有的最优传输优化工具来揭示不同自监督学习模型之间的新连接及提供易于适应领域知识的新手段。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the success of contrastive learning (CL) in vision and language, itstheoretical foundations and mechanisms for building representations remainpoorly understood. In this work, we build connections between noise contrastiveestimation losses widely used in CL and distribution alignment with entropicoptimal transport (OT). This connection allows us to develop a family ofdifferent losses and multistep iterative variants for existing CL methods.Intuitively, by using more information from the distribution of latents, ourapproach allows a more distribution-aware manipulation of the relationshipswithin augmented sample sets. We provide theoretical insights and experimentalevidence demonstrating the benefits of our approach for {\em generalizedcontrastive alignment}. Through this framework, it is possible to leveragetools in OT to build unbalanced losses to handle noisy views and customize therepresentation space by changing the constraints on alignment. By reframingcontrastive learning as an alignment problem and leveraging existingoptimization tools for OT, our work provides new insights and connectionsbetween different self-supervised learning models in addition to new tools thatcan be more easily adapted to incorporate domain knowledge into learning.</description>
      <author>example@mail.com (Zihao Chen, Chi-Heng Lin, Ran Liu, Jingyun Xiao, Eva L Dyer)</author>
      <guid isPermaLink="false">2502.20141v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>4Deform: Neural Surface Deformation for Robust Shape Interpolation</title>
      <link>http://arxiv.org/abs/2502.20208v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法4Deform，用于生成非刚性变形形状之间的真实中间形态。&lt;h4&gt;背景&lt;/h4&gt;在计算机视觉领域，生成非刚体变形物体的现实过渡形态是一个具有挑战性的任务，尤其是在没有结构的数据（如点云）中进行这种操作时尤为困难。现有的大多数插值方法都是针对有结构的数据设计的（例如网格），对于实际世界的点云并不适用。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于无结构数据的方法4Deform，该方法可以实现自由拓扑变化的形状变形，并且不依赖于中间形态监督。&lt;h4&gt;方法&lt;/h4&gt;新方法采用神经隐式表示(NIR)来处理连续欧几里得空间中的速度场学习问题。通过物理和几何约束来正则化这种速度场，并使用修改后的水平集方程重新构建过渡表面，直接将NIR与速度场连接起来。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在各种场景（包括噪声、不完整拓扑变化等）下显著优于之前的神经隐式表示方法。此外，这种方法首次实现了新的应用，如4D Kinect序列上采样和真实世界的高分辨率网格变形。&lt;h4&gt;结论&lt;/h4&gt;通过创新的方法论和技术实现，在非结构化数据中的形状变形任务中取得重要突破，为计算机视觉领域提供了新的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;生成现实的中间形态是一个挑战性的任务，特别是在处理无结构的数据时（例如点云），而这些数据在帧间缺乏时间一致性并且拓扑会发生变化。大多数插值方法是为有结构的数据设计的（即网格）, 并不适用于真实世界的点云。相比之下, 我们的方法4Deform采用神经隐式表示(NIR)来实现自由拓扑变化下的形状变形。与以往基于网格的方法不同，我们的方法学习的是欧几里得空间中的连续速度场。因此，它更适合处理较少结构化的数据，如点云。此外，我们的方法在训练过程中不需要中间形态的监督; 相反, 我们采用物理和几何约束来正则化速度场。我们使用修改过的水平集方程重构过渡表面, 将NIR直接与速度场连接起来。实验表明, 我们的这种方法显著优于先前的神经隐式表示方法，涵盖各种场景（例如噪声、部分数据、拓扑变化及非等距形状）。此外，它首次实现了新的应用如4D Kinect序列上采样和真实世界的高分辨率网格变形。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating realistic intermediate shapes between non-rigidly deformed shapesis a challenging task in computer vision, especially with unstructured data(e.g., point clouds) where temporal consistency across frames is lacking, andtopologies are changing. Most interpolation methods are designed for structureddata (i.e., meshes) and do not apply to real-world point clouds. In contrast,our approach, 4Deform, leverages neural implicit representation (NIR) to enablefree topology changing shape deformation. Unlike previous mesh-based methodsthat learn vertex-based deformation fields, our method learns a continuousvelocity field in Euclidean space. Thus, it is suitable for less structureddata such as point clouds. Additionally, our method does not requireintermediate-shape supervision during training; instead, we incorporatephysical and geometrical constraints to regularize the velocity field. Wereconstruct intermediate surfaces using a modified level-set equation, directlylinking our NIR with the velocity field. Experiments show that our methodsignificantly outperforms previous NIR approaches across various scenarios(e.g., noisy, partial, topology-changing, non-isometric shapes) and, for thefirst time, enables new applications like 4D Kinect sequence upsampling andreal-world high-resolution mesh deformation.</description>
      <author>example@mail.com (Lu Sang, Zehranaz Canfes, Dongliang Cao, Riccardo Marin, Florian Bernard, Daniel Cremers)</author>
      <guid isPermaLink="false">2502.20208v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>WaveGAS: Waveform Relaxation for Scaling Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.19986v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了两项改进，以解决GNNAutoScale（GAS）在图神经网络训练过程中遇到的历史嵌入向量陈旧和累积误差的问题。&lt;h4&gt;背景&lt;/h4&gt;随着现实世界图数据规模的不断扩大，为克服资源限制而开发了多种方法来训练图神经网络(GNNs)。其中一种方法是GNNAutoScale (GAS)，它通过图划分允许在有限GPU内存下进行训练，并且保存历史嵌入向量。&lt;h4&gt;目的&lt;/h4&gt;提出改进方案以解决由于使用陈旧的历史嵌入向量导致的近似误差累积问题，提升节点嵌入的质量和准确性。&lt;h4&gt;方法&lt;/h4&gt;[{'WaveGAS': '受波形松弛算法启发，在GAS内部进行多次前向传播来细化历史嵌入向量和梯度的估计，从而提高训练精度'}, {'梯度追踪法': '保存并利用更准确的历史梯度以提升模型在训练过程中的表现。'}]&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，WaveGAS能够增强原始的GAS方法，并且在性能上优于直接在完整图上进行训练的方法。&lt;h4&gt;结论&lt;/h4&gt;通过提出WaveGAS和改进的梯度追踪技术，该研究显著提高了节点嵌入的质量，并展示了其在复杂大规模图数据集上的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the ever-growing size of real-world graphs, numerous techniques toovercome resource limitations when training Graph Neural Networks (GNNs) havebeen developed. One such approach, GNNAutoScale (GAS), uses graph partitioningto enable training under constrained GPU memory. GAS also stores historicalembedding vectors, which are retrieved from one-hop neighbors in otherpartitions, ensuring critical information is captured across partitionboundaries. The historical embeddings which come from the previous trainingiteration are stale compared to the GAS estimated embeddings, resulting inapproximation errors of the training algorithm. Furthermore, these errorsaccumulate over multiple layers, leading to suboptimal node embeddings. Toaddress this shortcoming, we propose two enhancements: first, WaveGAS, inspiredby waveform relaxation, performs multiple forward passes within GAS before thebackward pass, refining the approximation of historical embeddings andgradients to improve accuracy; second, a gradient-tracking method that storesand utilizes more accurate historical gradients during training. Empiricalresults show that WaveGAS enhances GAS and achieves better accuracy, evenoutperforming methods that train on full graphs, thanks to its robustestimation of node embeddings.</description>
      <author>example@mail.com (Jana Vatter, Mykhaylo Zayats, Marcos Martínez Galindo, Vanessa López, Ruben Mayer, Hans-Arno Jacobsen, Hoang Thanh Lam)</author>
      <guid isPermaLink="false">2502.19986v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Contrastive Learning with Multi-view Longitudinal Data for Chest X-ray Report Generation</title>
      <link>http://arxiv.org/abs/2502.20056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了利用多视图纵向数据的增强对比学习方法，用于胸部X光报告生成（MLRG），该方法结合了当前多视图图像的空间信息和纵向数据的时间信息，并采用放射学报告中固有的时空信息对视觉和文本表示进行预训练。&lt;h4&gt;背景&lt;/h4&gt;自动化的放射科报告生成可以有效减轻放射科医生的工作负担，但大多数现有方法主要关注单视图或固定视角的图像来建模当前疾病状况，这限制了诊断准确性并忽略了疾病的进展过程。虽然有些方法利用纵向数据追踪疾病进展，但仍依赖于单一图像进行当前访问分析。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的对比学习框架，旨在通过结合多视图和纵向数据提高胸部X光报告生成的准确性和灵活性。&lt;h4&gt;方法&lt;/h4&gt;引入了多视图纵向对比学习的方法，该方法整合了空间信息（来自当前的多个视角图像）与时间信息（从纵向数据中获取）。同时利用放射学报告中的固有时空信息来监督视觉和文本表示的学习。此外还提出了一种标记化缺失编码技术，以灵活处理特定患者的前期知识缺失。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC-CXR、MIMIC-ABN以及双视图CXR数据集上的实验表明，该方法优于最新的最先进的方法，在MIMIC-CXR上实现了BLEU-4的2.3%改进，在MIMIC-ABN上实现了F1分数5.5%的提高，在Two-view CXR上实现了F1 RadGraph 2.7%的进步。&lt;h4&gt;结论&lt;/h4&gt;通过利用多视图纵向数据及其内在时空信息，可以显著提升胸部X光报告生成的质量和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated radiology report generation offers an effective solution toalleviate radiologists' workload. However, most existing methods focusprimarily on single or fixed-view images to model current disease conditions,which limits diagnostic accuracy and overlooks disease progression. Althoughsome approaches utilize longitudinal data to track disease progression, theystill rely on single images to analyze current visits. To address these issues,we propose enhanced contrastive learning with Multi-view Longitudinal data tofacilitate chest X-ray Report Generation, named MLRG. Specifically, weintroduce a multi-view longitudinal contrastive learning method that integratesspatial information from current multi-view images and temporal informationfrom longitudinal data. This method also utilizes the inherent spatiotemporalinformation of radiology reports to supervise the pre-training of visual andtextual representations. Subsequently, we present a tokenized absence encodingtechnique to flexibly handle missing patient-specific prior knowledge, allowingthe model to produce more accurate radiology reports based on available priorknowledge. Extensive experiments on MIMIC-CXR, MIMIC-ABN, and Two-view CXRdatasets demonstrate that our MLRG outperforms recent state-of-the-art methods,achieving a 2.3% BLEU-4 improvement on MIMIC-CXR, a 5.5% F1 score improvementon MIMIC-ABN, and a 2.7% F1 RadGraph improvement on Two-view CXR.</description>
      <author>example@mail.com (Kang Liu, Zhuoqi Ma, Xiaolu Kang, Yunan Li, Kun Xie, Zhicheng Jiao, Qiguang Miao)</author>
      <guid isPermaLink="false">2502.20056v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Quantum generative classification with mixed states</title>
      <link>http://arxiv.org/abs/2502.19970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'分类方法': '可以使用判别式或生成式的机器学习方法进行分类。', '判别式学习': '构造给定输入的输出条件概率。', '生成式学习': '构造输入和输出联合概率密度。', '生成式学习优势': '应用于无监督学习、统计推断、不确定性估计和合成数据生成。', '提出模型': '一种名为量子生成分类（QGC）的量子多类分类策略。', '方法细节': '使用变分量子算法通过混合量子态估算特征和标签的数据集联合概率密度函数。', '创新点': '引入一个称为量子增强傅里叶特征（QEFF）的量子映射，利用量子叠加来用少量量子比特在硬件中准备高维数据样本。', '理论贡献': '展示量子生成分类算法可以看作是训练数据核希尔伯特空间的一个高斯混合。', '实验验证': '开发了一种用于高维数据集生成式分类的混合量子-经典神经网络，该方法已在包括10类MNIST和Fashion-MNIST数据集在内的多个低维和高维数据集上进行了测试。', '结果表现': '证明了生成式分类策略在与其他先前量子模型的竞争中具有竞争力。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classification can be performed using either a discriminative or a generativelearning approach. Discriminative learning consists of constructing theconditional probability of the outputs given the inputs, while generativelearning consists of constructing the joint probability density of the inputsand outputs. Although most classical and quantum methods are discriminative,there are some advantages of the generative learning approach. For instance, itcan be applied to unsupervised learning, statistical inference, uncertaintyestimation, and synthetic data generation. In this article, we present aquantum generative multiclass classification strategy, called quantumgenerative classification (QGC). This model uses a variational quantumalgorithm to estimate the joint probability density function of features andlabels of a data set by means of a mixed quantum state. We also introduce aquantum map called quantum-enhanced Fourier features (QEFF), which leveragesquantum superposition to prepare high-dimensional data samples in quantumhardware using a small number of qubits. We show that the quantum generativeclassification algorithm can be viewed as a Gaussian mixture that reproduces akernel Hilbert space of the training data. In addition, we developed a hybridquantum-classical neural network that shows that it is possible to performgenerative classification on high-dimensional data sets. The method was testedon various low- and high-dimensional data sets including the 10-class MNIST andFashion-MNIST data sets, illustrating that the generative classificationstrategy is competitive against other previous quantum models.</description>
      <author>example@mail.com (Diego H. Useche, Sergio Quiroga-Sandoval, Sebastian L. Molina, Vladimir Vargas-Calderón, Juan E. Ardila-García, Fabio A. González)</author>
      <guid isPermaLink="false">2502.19970v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>SuPreME: A Supervised Pre-training Framework for Multimodal ECG Representation Learning</title>
      <link>http://arxiv.org/abs/2502.19668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;心血管疾病是全球死亡和残疾的主要原因，心电图（ECG）记录对于诊断和监测心脏健康至关重要。然而，获取大规模注释的ECG数据集既费时又费力。&lt;h4&gt;背景&lt;/h4&gt;现有的ECG自监督学习方法虽然减少了标签需求，但未能捕捉到精细的临床语义，并且需要大量的任务特定微调。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，提出了SuPreME（一种用于多模态ECG表示学习的监督预训练框架）。&lt;h4&gt;方法&lt;/h4&gt;SuPreME利用大型语言模型从自由文本心电图报告中提取结构化的临床实体，过滤掉噪声和不相关信息，增强临床表示学习，并构建高质量、精细化标签的数据集。通过使用基于文本的心脏查询而不是传统的分类标签，SuPreME可以在无需额外微调的情况下实现未知疾病的零样本分类。&lt;h4&gt;主要发现&lt;/h4&gt;在六种下游数据集中进行了评估，涵盖了127种心脏状况，SuPreME取得了优于现有ECG自监督学习和多模态方法的零样本AUC性能，提高了1.96%以上。结果表明，通过利用结构化、临床相关的知识可以生成高质量的心电图表示。&lt;h4&gt;结论&lt;/h4&gt;所有代码和数据将在接受后发布。&lt;h4&gt;翻译&lt;/h4&gt;心血管疾病是全球主要死因之一，心电图（ECG）记录对心脏健康诊断和监控至关重要，但由于大规模注释的ECG数据集获取困难，研究者提出了SuPreME框架。该方法采用大型语言模型提取临床实体信息，提高学习效率，并且在不进行额外训练的情况下实现未知疾病分类，展示出优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cardiovascular diseases are a leading cause of death and disabilityworldwide. Electrocardiogram (ECG) recordings are critical for diagnosing andmonitoring cardiac health, but obtaining large-scale annotated ECG datasets islabor-intensive and time-consuming. Recent ECG Self-Supervised Learning (eSSL)methods mitigate this by learning features without extensive labels but fail tocapture fine-grained clinical semantics and require extensive task-specificfine-tuning. To address these challenges, we propose $\textbf{SuPreME}$, a$\textbf{Su}$pervised $\textbf{Pre}$-training framework for$\textbf{M}$ultimodal $\textbf{E}$CG representation learning. SuPreME appliesLarge Language Models (LLMs) to extract structured clinical entities fromfree-text ECG reports, filter out noise and irrelevant content, enhanceclinical representation learning, and build a high-quality, fine-grainedlabeled dataset. By using text-based cardiac queries instead of traditionalcategorical labels, SuPreME enables zero-shot classification of unseen diseaseswithout additional fine-tuning. We evaluate SuPreME on six downstream datasetscovering 127 cardiac conditions, achieving superior zero-shot AUC performanceover state-of-the-art eSSL and multimodal methods by over 1.96\%. Resultsdemonstrate the effectiveness of SuPreME in leveraging structured, clinicallyrelevant knowledge for high-quality ECG representations. All code and data willbe released upon acceptance.</description>
      <author>example@mail.com (Mingsheng Cai, Jiuming Jiang, Wenhao Huang, Che Liu, Rossella Arcucci)</author>
      <guid isPermaLink="false">2502.19668v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Efficient and Universal Neural-Network Decoder for Stabilizer-Based Quantum Error Correction</title>
      <link>http://arxiv.org/abs/2502.19971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了基于线性注意力序列建模和图神经网络的通用量子纠错解码器，该解码器能够直接应用于各种稳定子编码结构，并在准确性和速度方面都优于专用算法。&lt;h4&gt;背景&lt;/h4&gt;量子错误校正对于大规模量子计算至关重要，但缺乏针对新编码（如量子稀疏奇偶校验码(QLDPC)）的高效解码器阻碍了其发展。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于所有稳定子编码的新通用解码器方案，以解决当前解码算法存在的问题，并提供更有效的纠错能力。&lt;h4&gt;方法&lt;/h4&gt;采用线性注意力序列建模和图神经网络技术开发了一种新的解码框架，该框架可以直接应用于任何稳定子编码的图形结构而不需要对其做结构性修改。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明新提出的解码器在各种类型（包括表面代码、颜色代码以及QLDPC等）的稳定子编码上均表现出更高的精度和更快的速度；对于Bivariate Bicycle码，当距离为12时，逻辑错误率降低了39.4%，而所需的解码时间仅占先前最佳解码器所需时间的大约1%。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种实用且通用的量子错误校正解决方案，消除了对特定代码专用解码器的需求，并有望推动量子计算技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;量子纠错对于大规模量子计算机来说至关重要。然而，缺乏针对新类型编码（如QLDPC）的有效解码器已成为阻碍其发展的瓶颈。本文介绍了一种基于线性注意力序列建模和图神经网络的通用解码器设计方法，该方法可以无缝地应用于各种稳定子编码结构中，并且在多种类型的量子纠错代码上均表现出卓越的表现力（如精度更高、速度更快）。特别值得注意的是，在Bivariate Bicycle 12距离下实现了39.4%逻辑错误率的显著降低及解码时间仅为先前最佳解码器所需时间的大约1%，证明了此方法具有实际应用价值，为未来的量子计算技术进步铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum error correction is crucial for large-scale quantum computing, butthe absence of efficient decoders for new codes like quantum low-densityparity-check (QLDPC) codes has hindered progress. Here we introduce a universaldecoder based on linear attention sequence modeling and graph neural networkthat operates directly on any stabilizer code's graph structure. Our numericalexperiments demonstrate that this decoder outperforms specialized algorithms inboth accuracy and speed across diverse stabilizer codes, including surfacecodes, color codes, and QLDPC codes. The decoder maintains linear time scalingwith syndrome measurements and requires no structural modifications betweendifferent codes. For the Bivariate Bicycle code with distance 12, our approachachieves a 39.4% lower logical error rate than previous best decoders whilerequiring only ~1% of the decoding time. These results provide a practical,universal solution for quantum error correction, eliminating the need forcode-specific decoders.</description>
      <author>example@mail.com (Gengyuan Hu, Wanli Ouyang, Chao-Yang Lu, Chen Lin, Han-Sen Zhong)</author>
      <guid isPermaLink="false">2502.19971v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>An Amplitude-Encoding-Based Classical-Quantum Transfer Learning framework: Outperforming Classical Methods in Image Recognition</title>
      <link>http://arxiv.org/abs/2502.20184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages, 12figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了经典的量子转移学习（CQTL）方法，旨在解决当前嘈杂中等规模量子计算时代在有限数量的量子比特上训练大规模高分辨率图像数据的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的CQTL框架已经在少量参数条件下展示了量子优势，但量子神经网络对参数的数量非常敏感。目前缺少关于更大规模、更多参数量子电路的研究和探索。&lt;h4&gt;目的&lt;/h4&gt;提出了一种基于振幅编码的经典-量子转移学习（AE-CQTL）框架，并设计了两种CQTL神经网络模型：Transfer Learning Quantum Neural Network (TLQNN) 和 Transfer Learning Quantum Convolutional Neural Network (TLQCNN)，以扩大参数容量并提升性能。&lt;h4&gt;方法&lt;/h4&gt;通过多层构造来增加量子电路的参数，基于AE-CQTL框架设计实现了两个模型，并在三个基准数据集（MNIST, Fashion-MNIST and CIFAR10）和三个源模型（ResNet18, ResNet50 and DenseNet121）上进行了跨实验。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型参数容量大幅提升，从几十个扩展到超过一百个参数；在多个性能指标中超越了传统经典分类器的基准表现，包括准确率、收敛性、稳定性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该工作为未来更大规模量子设备上经典-量子转移学习的应用推进做出了贡献。&lt;h4&gt;翻译&lt;/h4&gt;经典的量子迁移学习（CQTL）方法被引入来解决当前嘈杂中等规模量子计算时代的问题，即在有限数量的量子比特下训练大规模、高分辨率图像数据。尽管现有的CQTL框架已经展示了少量参数下的量子优势，但量子神经网络对参数数量敏感。目前缺乏研究和探索更大规模且具有更多参数的量子电路。本文提出了基于振幅编码的经典-量子迁移学习（AE-CQTL）框架，并设计了两个CQTL神经网络模型：转移学习量子神经网络（TLQNN）和转移学习量子卷积神经网络（TLQCNN）。在三个基准数据集上进行跨实验，结果显示所提出的模型超越传统经典分类器。研究结果为进一步推进大规模量子设备上的经典-量子迁移学习应用提供了理论基础和支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The classical-quantum transfer learning (CQTL) method is introduced toaddress the challenge of training large-scale, high-resolution image data on alimited number of qubits (ranging from tens to hundreds) in the current NoisyIntermediate-Scale quantum (NISQ) era. existing CQTL frameworks have beendemonstrate quantum advantages with a small number of parameters (around 50),but the performance of quantum neural networks is sensitive to the number ofparameters. Currently, there is a lack of exploration into larger-scale quantumcircuits with more parameters. This paper proposes an amplitude-encoding-basedclassical-quantum transfer learning (AE-CQTL) framework, accompanied by aneffective learning algorithm. The AE-CQTL framework multiplies the parametersof quantum circuits by using multi-layer ansatz. Based on the AE-CQTLframework, we designed and implemented two CQTL neural network models: Transferlearning Quantum Neural Network (TLQNN) and Transfer Learning QuantumConvolutional Neural Network (TLQCNN). Both models significantly expand theparameter capacity of quantum circuits, elevating the parameter scale from afew dozen to over one hundred parameters. In cross-experiments with threebenchmark datasets (MNIST, Fashion-MNIST and CIFAR10) and three source models(ResNet18, ResNet50 and DenseNet121), TLQNN and TLQCNN have exceeded thebenchmark classical classifier in multiple performance metrics, includingaccuracy, convergence, stability, and generalization capability. Our workcontributes to advancing the application of classical-quantum transfer learningon larger-scale quantum devices in future.</description>
      <author>example@mail.com (Shouwei Hu, Xi Li, Banyao Ruan, Zhihao Liu)</author>
      <guid isPermaLink="false">2502.20184v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>High-fidelity Multiphysics Modelling for Rapid Predictions Using Physics-informed Parallel Neural Operator</title>
      <link>http://arxiv.org/abs/2502.19543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 11 figures, 1 table, 36 equations&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新型的物理信息并行神经算子（PIPNO）框架，用于解决由非线性和强耦合偏微分方程描述的复杂多物理系统的建模难题。&lt;h4&gt;背景&lt;/h4&gt;传统数值求解器在处理高度计算成本的问题时存在挑战，限制了它们在大规模应用中的实用性。数据驱动训练依赖于神经算子，在实际场景中由于缺乏或难以获取数据而适用性受限。&lt;h4&gt;目的&lt;/h4&gt;开发一种利用支配物理定律进行无监督学习的框架，以实现无需数据支持即可建立偏微分方程模型的目标。&lt;h4&gt;方法&lt;/h4&gt;引入并行核积分设计，结合集合学习的方法，极大地提升了算子学习中的兼容性和计算效率，使得非线性和强耦合偏微分方程的学习成为可能。该方法适用于地技术工程、材料科学、电磁学、量子力学和流体动力学等多个领域的复杂物理问题。&lt;h4&gt;主要发现&lt;/h4&gt;PIPNO能够在高度复杂的多物理系统建模中实现高保真度和快速预测，优于现有的算子学习方法。&lt;h4&gt;结论&lt;/h4&gt;PIPNO为传统的求解器提供了一种强有力的替代方案，扩展了神经算子在多物理模型中的适用性，并保证了效率、鲁棒性和可扩展性。&lt;h4&gt;翻译&lt;/h4&gt;建立复杂的多物理系统模型是计算科学和工程的重要基础。此类系统的数学描述往往涉及非线性和强耦合的偏微分方程（PDEs）。传统数值解法在处理这类问题时面临高计算成本的问题，使得它们难以应用于大规模的实际应用中。数据驱动训练方法依赖于大量高质量的数据进行神经算子的学习，在实际场景中因为获取数据的成本或难度而受限。文中提出了一种新的框架物理信息并行神经算子（PIPNO），这是一个可扩展且无需监督学习的框架，仅依靠支配的物理定律即可构建偏微分方程模型。其设计包括了并行核积分和集合学习的方法，显著提升了算子学习中的兼容性和计算效率，使得对非线性及强耦合偏微分方程的学习成为可能。PIPNO能够在地技术工程、材料科学、电磁学、量子力学以及流体动力学等多个领域中高效捕捉不同物理现象之间的非线性操作映射关系，并在模型预测的速度和准确性方面优于现有算子学习方法，为解决多物理系统的建模难题提供了一种新的有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modelling complex multiphysics systems governed by nonlinear and stronglycoupled partial differential equations (PDEs) is a cornerstone in computationalscience and engineering. However, it remains a formidable challenge fortraditional numerical solvers due to high computational cost, making themimpractical for large-scale applications. Neural operators' reliance ondata-driven training limits their applicability in real-world scenarios, asdata is often scarce or expensive to obtain. Here, we propose a novel paradigm,physics-informed parallel neural operator (PIPNO), a scalable and unsupervisedlearning framework that enables data-free PDE modelling by leveraging onlygoverning physical laws. The parallel kernel integration design, incorporatingensemble learning, significantly enhances both compatibility and computationalefficiency, enabling scalable operator learning for nonlinear and stronglycoupled PDEs. PIPNO efficiently captures nonlinear operator mappings acrossdiverse physics, including geotechnical engineering, material science,electromagnetism, quantum mechanics, and fluid dynamics. The proposed methodachieves high-fidelity and rapid predictions, outperforming existing operatorlearning approaches in modelling nonlinear and strongly coupled multiphysicssystems. Therefore, PIPNO offers a powerful alternative to conventionalsolvers, broadening the applicability of neural operators for multiphysicsmodelling while ensuring efficiency, robustness, and scalability.</description>
      <author>example@mail.com (Biao Yuan, He Wang, Yanjie Song, Ana Heitor, Xiaohui Chen)</author>
      <guid isPermaLink="false">2502.19543v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Noise-Injected Spiking Graph Convolution for Energy-Efficient 3D Point Cloud Denoising</title>
      <link>http://arxiv.org/abs/2502.19660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种注入噪声的尖峰图卷积网络，用于提升脉冲神经网络（SNN）在三维点云去噪中的回归性能。&lt;h4&gt;背景&lt;/h4&gt;脉冲神经网络由于其优越的能量效率，在二维分类任务中优于传统人工神经网络。然而，在三维点云处理方面，特别是回归任务上，SNN的潜力尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;设计一种注入噪声的尖峰图卷积方法以增强3D点云去噪能力，并展示了两种基于SNN的去噪网络性能。&lt;h4&gt;方法&lt;/h4&gt;首先模拟了带有噪声的神经元动力学，构建出带噪声的脉冲神经元。然后在此基础上设计了注入噪声的脉冲图卷积层，促进对三维数据扰动感知下的尖峰表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种全新的SNN架构用于3D点云去噪任务，并展示了其相比基于ANN的模型而言，可以显著降低能耗的同时保持较低的精度损失。此外还设计了一个结合了深度学习方法与高效能特点的混合架构。&lt;h4&gt;结论&lt;/h4&gt;这项工作揭示了脉冲神经网络在三维数据处理方面的潜力，为探索部署于类脑芯片以及开发高能效3D数据采集设备铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;受生物神经系统中尖峰计算范式的启发，脉冲神经网络（SNN）在二维分类任务中的能量效率优于传统人工神经网络（ANN）。然而，在三维点云处理方面，特别是回归任务上，SNN的潜力尚未充分探索。本文提出了一种注入噪声的尖峰图卷积网络来最大化SNN在3D点云去噪中的回归潜能。具体而言，我们首先模拟了带有噪声的神经元动力学以构建带噪声的脉冲神经元。基于此基础，设计了促进三维数据扰动感知下的尖峰表示学习的注入噪声的脉冲图卷积层。从脉冲图卷积出发，建立了两个SNN去噪网络：一个是纯脉冲图卷积网络，在两个基准数据集PU-Net和PC-Net上相比一些基于ANN的方法显示出较低的精度损失同时显著减少了能量消耗；另一个是混合架构，结合了深度学习方法并在仅几步时间步骤中就实现了高效能。这项工作揭示了SNN在三维点云去噪中的潜力，并为探索类脑芯片上的部署以及开发高能效3D数据采集设备铺平道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spiking neural networks (SNNs), inspired by the spiking computation paradigmof the biological neural systems, have exhibited superior energy efficiency in2D classification tasks over traditional artificial neural networks (ANNs).However, the regression potential of SNNs has not been well explored,especially in 3D point cloud processing.In this paper, we proposenoise-injected spiking graph convolutional networks to leverage the fullregression potential of SNNs in 3D point cloud denoising. Specifically, wefirst emulate the noise-injected neuronal dynamics to build noise-injectedspiking neurons. On this basis, we design noise-injected spiking graphconvolution for promoting disturbance-aware spiking representation learning on3D points. Starting from the spiking graph convolution, we build two SNN-baseddenoising networks. One is a purely spiking graph convolutional network, whichachieves low accuracy loss compared with some ANN-based alternatives, whileresulting in significantly reduced energy consumption on two benchmarkdatasets, PU-Net and PC-Net. The other is a hybrid architecture that combinesANN-based learning with a high performance-efficiency trade-off in just a fewtime steps. Our work lights up SNN's potential for 3D point cloud denoising,injecting new perspectives of exploring the deployment on neuromorphic chipswhile paving the way for developing energy-efficient 3D data acquisitiondevices.</description>
      <author>example@mail.com (Zikuan Li, Qiaoyun Wu, Jialin Zhang, Kaijun Zhang, Jun Wang)</author>
      <guid isPermaLink="false">2502.19660v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Mixture of Experts for Recognizing Depression from Interview and Reading Tasks</title>
      <link>http://arxiv.org/abs/2502.20213v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种利用混合专家模型（MoE）来识别抑郁的新型深度神经网络方法，它同时考虑自发和朗读语音，并使用多模态融合技术。&lt;h4&gt;背景&lt;/h4&gt;抑郁症是一种精神疾病，能够引起心理、生理和社会方面的多种症状。研究表明，言语是早期识别抑郁症的一个客观标志。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的机器学习方法，通过分析人类的自发性对话和阅读任务中的音频数据来更准确地识别抑郁症。&lt;h4&gt;方法&lt;/h4&gt;本研究首次在抑郁检测任务中利用混合专家模型（MoE），将来自两种不同类型的语音的数据结合起来。它使用了音频文件对应于访谈任务和朗读任务，并将其转换为log-Mel频谱图，然后通过共享的AlexNet模型处理图像表示，最后输出向量通过MoE模块。&lt;h4&gt;主要发现&lt;/h4&gt;该研究采用了三种MoE变体：稀疏门控混合专家（Sparsely-gated MoE）和基于分解的多线性混合专家（Multilinear MoE），在Androids语料库上的实验中，达到了87.00%的准确率和86.66%的F1分数。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种新颖且有效的方法来识别抑郁症，通过利用自发性和朗读语音的数据，并应用先进的多模态融合技术。这种方法在Androids语料库上的实验中表现出了很高的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个创新的研究工作，旨在开发一个能够同时使用自发性对话和阅读任务中的音频数据的深度学习模型来识别抑郁症。该方法使用混合专家（MoE）框架，结合了多模态融合技术，以提高对抑郁症状检测的精度。实验结果表明，在Androids语料库上该模型达到了87.00%的准确率和86.66%的F1分数，显示出在识别抑郁症方面的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depression is a mental disorder and can cause a variety of symptoms,including psychological, physical, and social. Speech has been proved anobjective marker for the early recognition of depression. For this reason, manystudies have been developed aiming to recognize depression through speech.However, existing methods rely on the usage of only the spontaneous speechneglecting information obtained via read speech, use transcripts which areoften difficult to obtain (manual) or come with high word-error rates(automatic), and do not focus on input-conditional computation methods. Toresolve these limitations, this is the first study in depression recognitiontask obtaining representations of both spontaneous and read speech, utilizingmultimodal fusion methods, and employing Mixture of Experts (MoE) models in asingle deep neural network. Specifically, we use audio files corresponding toboth interview and reading tasks and convert each audio file into log-Melspectrogram, delta, and delta-delta. Next, the image representations of the twotasks pass through shared AlexNet models. The outputs of the AlexNet models aregiven as input to a multimodal fusion method. The resulting vector is passedthrough a MoE module. In this study, we employ three variants of MoE, namelysparsely-gated MoE and multilinear MoE based on factorization. Findings suggestthat our proposed approach yields an Accuracy and F1-score of 87.00% and 86.66%respectively on the Androids corpus.</description>
      <author>example@mail.com (Loukas Ilias, Dimitris Askounis)</author>
      <guid isPermaLink="false">2502.20213v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion</title>
      <link>http://arxiv.org/abs/2502.20120v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的多模态学习方法，通过设计持续增强算法来动态平衡弱模态和强模态的分类能力，从而克服了现有方法在处理模式不平衡时的局限性。&lt;h4&gt;背景&lt;/h4&gt;尽管多模态学习已经取得了显著的进步，但存在的模态失衡问题阻碍了其在实践中超越单模态模型的优势。主流多模态学习方法主要关注于平衡学习过程，然而这些方法没有明确地增强较弱模态的分类能力，导致性能提升有限。&lt;h4&gt;目的&lt;/h4&gt;设计一种持续增强算法以动态平衡强模态和弱模态之间的分类能力，从而缓解模式失衡问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种在多模态学习中同时优化分类误差和残差误差的设计可配置分类器模块的持续增强算法。进一步提出了一个自适应分类器分配策略，以动态提升弱模态的分类性能。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验验证了该方法的有效性，并展示了与现有最先进的多模态学习基线相比的优势。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在缓解模式不平衡问题方面表现出色，能够有效提高多模态模型的整体性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although multimodal learning~(MML) has garnered remarkable progress, theexistence of modality imbalance hinders multimodal learning from achieving itsexpected superiority over unimodal models in practice. To overcome this issue,mainstream multimodal learning methods have placed greater emphasis onbalancing the learning process. However, these approaches do not explicitlyenhance the classification ability of weaker modalities, leading to limitedperformance promotion. By designing a sustained boosting algorithm, we proposea novel multimodal learning approach to dynamically balance the classificationability of weak and strong modalities. Concretely, we first propose a sustainedboosting algorithm in multimodal learning by simultaneously optimizing theclassification and residual errors using a designed configurable classifiermodule. Then, we propose an adaptive classifier assignment strategy todynamically facilitate the classification performance of weak modality. To thisend, the classification ability of strong and weak modalities is expected to bebalanced, thereby mitigating the imbalance issue. Empirical experiments onwidely used datasets reveal the superiority of our method through comparisonwith various state-of-the-art~(SoTA) multimodal learning baselines.</description>
      <author>example@mail.com (QingYuan Jiang, Longfei Huang, Yang Yang)</author>
      <guid isPermaLink="false">2502.20120v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Learning Mask Invariant Mutual Information for Masked Image Modeling</title>
      <link>http://arxiv.org/abs/2502.19718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的视角来理解Masked Autoencoders (MAEs) 的工作原理，通过信息瓶颈原则来分析和优化它们。引入了MI-MAE方法，该方法利用互信息最大化和最小化策略优化MAEs的潜在特征以提高性能。&lt;h4&gt;背景&lt;/h4&gt;Masked autoencoders在计算机视觉中的自监督学习领域非常突出，尽管有实证成功但其底层机制还不完全被理解。&lt;h4&gt;目的&lt;/h4&gt;通过理论分析揭示了平衡相关和不相关信息对于改进MAE性能的关键作用，并提出了一个基于信息瓶颈原理的新方法MI-MAE来优化潜在特征。&lt;h4&gt;方法&lt;/h4&gt;利用互信息最大化的技术，增强潜在特征以保留与输出的最大相关性；同时减少潜在特征与输入的无关信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验显示，所提出的MI-MAE在图像分类、目标检测和语义分割等任务中均显著优于原始MAE模型。这验证了理论框架的有效性和基于信息瓶颈原则优化自监督学习模型的实际优势。&lt;h4&gt;结论&lt;/h4&gt;该研究为开发更强大的自监督学习模型提供了更深的见解，强调了将信息瓶颈原则应用于MAEs的重要性。&lt;h4&gt;翻译&lt;/h4&gt;掩膜自动编码器（Masked Autoencoders，简称MAE）代表了一种在计算机视觉中自监督学习领域非常突出的方法。尽管它们在实验上表现出色，但其背后的机制尚未被充分理解。最近的研究试图通过对比学习和特征表示分析来阐明MAEs的工作原理，但是这些方法往往只能提供间接的见解。本文提出一种新的视角以信息论中的信息瓶颈原则为基础来理解MAE，并且理论分析揭示了优化潜在特征以平衡相关和不相关信息是提高MAE性能的关键。基于我们的证明，我们引入了一种名为MI-MAE的新方法，该方法通过互信息最大化和最小化策略优化掩膜自动编码器。通过增强潜在特征以保留与输出的最大关联性，并减少与输入的无关信息，我们的方法实现了更好的效果。在标准基准上的广泛实验表明，在图像分类、目标检测和语义分割等任务中，MI-MAE显著优于传统Masked Autoencoder模型。这些发现验证了理论框架的有效性，并突出了将信息瓶颈原则应用于掩膜自动编码器的实际优势，为开发更强大的自监督学习模型提供了深入的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked autoencoders (MAEs) represent a prominent self-supervised learningparadigm in computer vision. Despite their empirical success, the underlyingmechanisms of MAEs remain insufficiently understood. Recent studies haveattempted to elucidate the functioning of MAEs through contrastive learning andfeature representation analysis, yet these approaches often provide onlyimplicit insights. In this paper, we propose a new perspective forunderstanding MAEs by leveraging the information bottleneck principle ininformation theory. Our theoretical analyses reveal that optimizing the latentfeatures to balance relevant and irrelevant information is key to improving MAEperformance. Building upon our proofs, we introduce MI-MAE, a novel method thatoptimizes MAEs through mutual information maximization and minimization. Byenhancing latent features to retain maximal relevant information between themand the output, and minimizing irrelevant information between them and theinput, our approach achieves better performance. Extensive experiments onstandard benchmarks show that MI-MAE significantly outperforms MAE models intasks such as image classification, object detection, and semanticsegmentation. Our findings validate the theoretical framework and highlight thepractical advantages of applying the information bottleneck principle to MAEs,offering deeper insights for developing more powerful self-supervised learningmodels.</description>
      <author>example@mail.com (Tao Huang, Yanxiang Ma, Shan You, Chang Xu)</author>
      <guid isPermaLink="false">2502.19718v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>GraphSparseNet: a Novel Method for Large Scale Trafffic Flow Prediction</title>
      <link>http://arxiv.org/abs/2502.19823v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;交通流预测是一项关键的时空数据挖掘任务，在智能路线规划和动态交通管理中具有广泛的应用。近年来，深度学习技术特别是图神经网络（GNNs）在提高这些预测准确度方面取得了显著进展，通过捕捉复杂的时空动态特性来实现这一点。&lt;h4&gt;背景&lt;/h4&gt;交通流量预测是一个重要的时空数据分析领域，最近的研究利用深度学习方法尤其是基于图的模型大幅提高了其准确性。然而，现有的图神经网络面临的一个主要问题是随着图形中节点数量增加而产生的计算复杂度呈指数级增长。&lt;h4&gt;目的&lt;/h4&gt;本文介绍了一种称为GraphSparseNet (GSNet)的新框架，旨在同时提高GNN在交通预测中的可扩展性和准确率。&lt;h4&gt;方法&lt;/h4&gt;该框架由两个核心模块构成：特征提取器和关系压缩器。这些模块具有线性的时间和空间复杂度，这使得整个模型的计算复杂度减少到线性级别。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GraphSparseNet不仅比最先进的线性模型将训练时间减少了3.51倍，而且还保持了高预测性能。&lt;h4&gt;结论&lt;/h4&gt;GSNet框架为解决GNN可扩展性和准确性问题提供了一种新的解决方案，并展示了在实际数据集上的优越表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic flow forecasting is a critical spatio-temporal data mining task withwide-ranging applications in intelligent route planning and dynamic trafficmanagement. Recent advancements in deep learning, particularly through GraphNeural Networks (GNNs), have significantly enhanced the accuracy of theseforecasts by capturing complex spatio-temporal dynamics. However, thescalability of GNNs remains a challenge due to their exponential growth inmodel complexity with increasing nodes in the graph. Existing methods toaddress this issue, including sparsification, decomposition, and kernel-basedapproaches, either do not fully resolve the complexity issue or riskcompromising predictive accuracy. This paper introduces GraphSparseNet (GSNet),a novel framework designed to improve both the scalability and accuracy ofGNN-based traffic forecasting models. GraphSparseNet is comprised of two coremodules: the Feature Extractor and the Relational Compressor. These modulesoperate with linear time and space complexity, thereby reducing the overallcomputational complexity of the model to a linear scale. Our extensiveexperiments on multiple real-world datasets demonstrate that GraphSparseNet notonly significantly reduces training time by 3.51x compared to state-of-the-artlinear models but also maintains high predictive performance.</description>
      <author>example@mail.com (Weiyang Kong, Kaiqi Wu, Sen Zhang, Yubao Liu)</author>
      <guid isPermaLink="false">2502.19823v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning in Latent Contextual Bandits with Covariate Shift Through Causal Transportability</title>
      <link>http://arxiv.org/abs/2502.20153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the Conference of Causal Learning and Reasoning (CLeaR  2025), will be published in the Proceedings of Machine Learning Research&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了智能系统中知识从一个环境转移到另一个环境的能力，特别是在多臂赌博机框架下的因果推理视角。研究关注潜在上下文下的转移学习，并考虑跨环境的条件变化（即协变量偏移）。文章提出了一种基于因果推断运输理论的方法来开发算法，这些算法能够有效地在目标环境中转移知识。&lt;h4&gt;背景&lt;/h4&gt;在两个不同的环境中直接迁移所有知识可能会导致性能下降，这种现象被称为负向迁移。该问题需要通过更精细的知识迁移策略解决。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种有效的学习框架，以便智能系统可以更好地处理跨环境下的负向迁移，并且在这种情况下能够有效地进行知识转移。&lt;h4&gt;方法&lt;/h4&gt;文章使用因果推理理论中的可传输性理论来开发算法。利用变分自动编码器在高维代理存在的情况下近似因果效果。研究测试了这些算法在合成和半合成数据集上的性能，与基准算法相比，结果表明该框架具有持续改进的学习效率。&lt;h4&gt;主要发现&lt;/h4&gt;经典多臂赌博机算法下的直接知识转移会导致负向迁移。利用运输理论进行有效的知识转移可以提高目标环境中的学习效率。&lt;h4&gt;结论&lt;/h4&gt;本文提出的基于因果推断的框架在处理跨环境的知识转移问题上是有效且高效的，尤其是当存在高维代理时。该方法相对于基准算法展示了持续改进的学习性能，并为智能系统如何更好地从一个环境迁移到另一个环境中学习提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;知识迁移是智能系统的必备能力之一。然而，在两个不同的环境下，直接转移所有知识可能导致性能下降（负向迁移）。本研究在多臂赌博机框架下探讨了该问题，特别是针对潜在上下文下的知识转移，并考虑到了环境变化的影响（协变量偏移）。通过应用因果推理理论中的可传输性原则来开发有效的算法，这些算法旨在有效估计目标环境中感兴趣的因果效应。此外，利用变分自动编码器来处理高维代理情况下的近似因果效果。测试结果表明，在合成和半合成数据集上，该方法相对于基准算法表现出更优的学习效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transferring knowledge from one environment to another is an essentialability of intelligent systems. Nevertheless, when two environments aredifferent, naively transferring all knowledge may deteriorate the performance,a phenomenon known as negative transfer. In this paper, we address this issuewithin the framework of multi-armed bandits from the perspective of causalinference. Specifically, we consider transfer learning in latent contextualbandits, where the actual context is hidden, but a potentially high-dimensionalproxy is observable. We further consider a covariate shift in the contextacross environments. We show that naively transferring all knowledge forclassical bandit algorithms in this setting led to negative transfer. We thenleverage transportability theory from causal inference to develop algorithmsthat explicitly transfer effective knowledge for estimating the causal effectsof interest in the target environment. Besides, we utilize variationalautoencoders to approximate causal effects under the presence of ahigh-dimensional proxy. We test our algorithms on synthetic and semi-syntheticdatasets, empirically demonstrating consistently improved learning efficiencyacross different proxies compared to baseline algorithms, showing theeffectiveness of our causal framework in transferring knowledge.</description>
      <author>example@mail.com (Mingwei Deng, Ville Kyrki, Dominik Baumann)</author>
      <guid isPermaLink="false">2502.20153v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>CFTrack: Enhancing Lightweight Visual Tracking through Contrastive Learning and Feature Matching</title>
      <link>http://arxiv.org/abs/2502.19705v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为CFTrack的轻量级追踪器，该追踪器结合了对比学习和特征匹配技术，增强了区分能力。&lt;h4&gt;背景&lt;/h4&gt;在移动设备和边缘计算设备上进行高效的视觉跟踪是一个挑战，特别是当这些设备资源受限时。传统的轻量级追踪器难以应对遮挡和干扰问题，而深度学习方法压缩后性能会下降。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有技术的局限性，提出了一种新的轻量级追踪算法CFTrack，旨在解决在计算资源有限的情况下提高跟踪精度的问题。&lt;h4&gt;方法&lt;/h4&gt;该论文提出了一个新颖的对比特征匹配模块（contrastive feature matching module），通过自适应对比损失优化目标相似度动态评估过程。这个模块与传统的特征匹配相结合，形成了改进后的轻量级追踪器CFTrack。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，CFTrack在LaSOT、OTB100和UAV123数据集上优于许多最新的轻量级追踪器，在NVIDIA Jetson NX平台上可以达到每秒136帧的性能。进一步的研究表明，CFTrack具有强大的区分能力，并且在HOOT数据集中重遮挡的情况下表现尤为出色。&lt;h4&gt;结论&lt;/h4&gt;CFTrack通过引入对比学习和特征匹配技术克服了传统轻量级跟踪器的缺点，能够在资源有限的情况下提供高精度跟踪结果。&lt;h4&gt;翻译&lt;/h4&gt;实现视觉追踪中的高效性和强大的区分能力是一个挑战，尤其是在计算资源受限的手持设备上。传统的轻量级追踪器在遮挡和干扰情况下的鲁棒性不足，而深度学习方法压缩后会性能下降。本文提出了一种名为CFTrack的跟踪器，它结合了对比学习和特征匹配技术来增强区分性的特征表示能力。通过自适应对比损失优化的新颖对比特性匹配模块，CFTrack能够在预测期间动态评估目标相似度，并提高了追踪精度。实验表明，在LaSOT、OTB100和UAV123数据集上，CFTrack优于许多最新的轻量级跟踪器，在NVIDIA Jetson NX平台上可以达到每秒136帧的性能。在HOOT数据集中，进一步证实了CFTrack在严重遮挡情况下的强大区分能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving both efficiency and strong discriminative ability in lightweightvisual tracking is a challenge, especially on mobile and edge devices withlimited computational resources. Conventional lightweight trackers oftenstruggle with robustness under occlusion and interference, while deep trackers,when compressed to meet resource constraints, suffer from performancedegradation. To address these issues, we introduce CFTrack, a lightweighttracker that integrates contrastive learning and feature matching to enhancediscriminative feature representations. CFTrack dynamically assesses targetsimilarity during prediction through a novel contrastive feature matchingmodule optimized with an adaptive contrastive loss, thereby improving trackingaccuracy. Extensive experiments on LaSOT, OTB100, and UAV123 show that CFTracksurpasses many state-of-the-art lightweight trackers, operating at 136 framesper second on the NVIDIA Jetson NX platform. Results on the HOOT datasetfurther demonstrate CFTrack's strong discriminative ability under heavyocclusion.</description>
      <author>example@mail.com (Juntao Liang, Jun Hou, Weijun Zhang, Yong Wang)</author>
      <guid isPermaLink="false">2502.19705v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>cMIM: A Contrastive Mutual Information Framework for Unified Generative and Discriminative Representation Learning</title>
      <link>http://arxiv.org/abs/2502.19642v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A working draft&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新的对比互信息机(cMIM)模型，旨在提升表示学习在未知下游任务中的实用性。&lt;h4&gt;背景&lt;/h4&gt;表示学习的一个基本挑战是学习对未见下游任务有用的表示。目前该领域的主流方法包括对比学习、自监督掩码和去噪自动编码器。&lt;h4&gt;目的&lt;/h4&gt;为了增强所学表示对于下游任务的适用性，提出了cMIM方法，直接解决了现有Mutual Information Machine (MIM)模型在区分下游任务表现不佳的问题。&lt;h4&gt;方法&lt;/h4&gt;cMIM将新的对比学习损失函数与互信息机(MIM)学习框架集成在一起。cMIM不仅消除了数据增强的需求，并且对负样本数量（即批量大小）的变化具有鲁棒性；另外还引入了一种通用的方法从编码器-解码器模型中提取有用的嵌入，显著提高了在区分下游任务中的性能。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的cMIM方法不仅解决了现有MIM模型表示对于区分下游任务适用性的不足，而且还提供了一个统一的生成模型，该模型对生成和区分性任务都很有效。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，通过cMIM学习到的表示可以为下游任务提供价值的同时保持了MIM的生成能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning representations that are useful for unknown downstream tasks is afundamental challenge in representation learning. Prominent approaches in thisdomain include contrastive learning, self-supervised masking, and denoisingauto-encoders. In this paper, we introduce a novel method, termed contrastiveMutual Information Machine (cMIM), which aims to enhance the utility of learnedrepresentations for downstream tasks. cMIM integrates a new contrastivelearning loss with the Mutual Information Machine (MIM) learning framework, aprobabilistic auto-encoder that maximizes the mutual information between inputsand latent representations while clustering the latent codes. Despite MIM'spotential, initial experiments indicated that the representations learned byMIM were less effective for discriminative downstream tasks compared tostate-of-the-art (SOTA) models. The proposed cMIM method directly addressesthis limitation.  The main contributions of this work are twofold: (1) We propose a novelcontrastive extension to MIM for learning discriminative representations whicheliminates the need for data augmentation and is robust to variations in thenumber of negative examples (i.e., batch size). (2) We introduce a genericmethod for extracting informative embeddings from encoder-decoder models, whichsignificantly improves performance in discriminative downstream tasks withoutrequiring additional training. This method is applicable to any pre-trainedencoder-decoder model.  By presenting cMIM, we aim to offer a unified generative model that iseffective for both generative and discriminative tasks. Our results demonstratethat the learned representations are valuable for downstream tasks whilemaintaining the generative capabilities of MIM.</description>
      <author>example@mail.com (Micha Livne)</author>
      <guid isPermaLink="false">2502.19642v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>DGFM: Full Body Dance Generation Driven by Music Foundation Models</title>
      <link>http://arxiv.org/abs/2502.20176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the Audio Imagination Workshop of NeurlPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于扩散模型的音乐驱动舞蹈动作生成方法，该方法结合了高级音乐基础模型和手工制作特征来提升生成舞蹈序列的质量。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数音乐驱动舞蹈动作生成方法依赖于手工制作的特征，并未充分利用音乐基础模型对跨模态内容生成的影响。&lt;h4&gt;目的&lt;/h4&gt;为了弥补这一不足，本研究提出了一种基于扩散的方法，该方法可以根据文本和音乐生成舞蹈动作。&lt;h4&gt;方法&lt;/h4&gt;通过结合由音乐基础模型获得的高级特性与手工制作的特性来提取音乐特征。此方法能有效利用高级语义信息和低级时间细节的优势，提高模型理解音乐特征的能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在生成最逼真的舞蹈序列方面优于四个音乐基础模型和两组手工制作的音乐特征，并且与输入音乐匹配度最佳。&lt;h4&gt;结论&lt;/h4&gt;通过将高级语义信息和低级时间细节相结合，可以显著提高基于文本和音乐的舞蹈动作生成效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In music-driven dance motion generation, most existing methods usehand-crafted features and neglect that music foundation models have profoundlyimpacted cross-modal content generation. To bridge this gap, we propose adiffusion-based method that generates dance movements conditioned on text andmusic. Our approach extracts music features by combining high-level featuresobtained by music foundation model with hand-crafted features, therebyenhancing the quality of generated dance sequences. This method effectivelyleverages the advantages of high-level semantic information and low-leveltemporal details to improve the model's capability in music featureunderstanding. To show the merits of the proposed method, we compare it withfour music foundation models and two sets of hand-crafted music features. Theresults demonstrate that our method obtains the most realistic dance sequencesand achieves the best match with the input music.</description>
      <author>example@mail.com (Xinran Liu, Zhenhua Feng, Diptesh Kanojia, Wenwu Wang)</author>
      <guid isPermaLink="false">2502.20176v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Accurate and Scalable Graph Neural Networks via Message Invariance</title>
      <link>http://arxiv.org/abs/2502.19693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;基于消息传递的图神经网络（GNN）在许多实际应用中取得了巨大成功。然而，对于采样的目标节点小批量来说，从外部节点到内部节点的消息传递导致了随着层数增加而指数级增长的计算成本。&lt;h4&gt;背景&lt;/h4&gt;现有方法中的消息传递过程分为两部分：同一小批量内的节点间消息传递（MP-IB）和从小批量外向内节点的消息传递（MP-OB）。MP-OB依赖于更高阶的小批量外部邻居，导致了随着层数增加而指数级增长的计算成本。&lt;h4&gt;目的&lt;/h4&gt;提出一种准确且快速的大图归纳学习小批量方法——拓扑补偿(TOP)，以解决因消息传递过程导致的大规模图形中节点和边过多存储在GPU上的问题。&lt;h4&gt;方法&lt;/h4&gt;TOP通过引入消息不变性概念，将昂贵的MP-OB转化为快速的MP-IB。这保证了修改后的MP-IB与整个消息传递具有相同的输出结果。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在大规模图（数百万节点和数十亿边）上，TOP比现有的小批量方法快几个数量级，并且精度下降有限。&lt;h4&gt;结论&lt;/h4&gt;通过避免昂贵的MP-OB计算成本，TOP使得GNN在大规模图形中变得更加可行。&lt;h4&gt;翻译&lt;/h4&gt;基于消息传递的图神经网络（GNNs）在许多实际应用中取得了巨大成功。对于采样的目标节点小批量来说，消息传递过程分为两部分：同一小批量内的节点间消息传递（MP-IB）和从小批量外向内节点的消息传递（MP-OB）。然而，由于邻域爆炸问题，整个消息传递过程中需要在GPU上存储大部分节点和边。为解决这一挑战，我们提出了一种针对大规模图归纳学习的准确且快速的小批量方法——拓扑补偿(TOP)，该方法仅通过MP-IB就能获得整个消息传递的结果而无需昂贵的MP-OB计算成本。TOP的核心在于引入了一个新的概念——消息不变性，它定义了将昂贵的MP-OB转换为快速MP-IB的消息不变变换。这确保了修改后的MP-IB与整个消息传递具有相同的输出结果。实验表明，在包含数百万节点和数十亿边的大规模图上，TOP比现有的小批量方法快几个数量级，并且精度下降有限。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Message passing-based graph neural networks (GNNs) have achieved greatsuccess in many real-world applications. For a sampled mini-batch of targetnodes, the message passing process is divided into two parts: message passingbetween nodes within the batch (MP-IB) and message passing from nodes outsidethe batch to those within it (MP-OB). However, MP-OB recursively relies onhigher-order out-of-batch neighbors, leading to an exponentially growingcomputational cost with respect to the number of layers. Due to the neighborexplosion, the whole message passing stores most nodes and edges on the GPUsuch that many GNNs are infeasible to large-scale graphs. To address thischallenge, we propose an accurate and fast mini-batch approach for large graphtransductive learning, namely topological compensation (TOP), which obtains theoutputs of the whole message passing solely through MP-IB, without the costlyMP-OB. The major pillar of TOP is a novel concept of message invariance, whichdefines message-invariant transformations to convert costly MP-OB into fastMP-IB. This ensures that the modified MP-IB has the same output as the wholemessage passing. Experiments demonstrate that TOP is significantly faster thanexisting mini-batch methods by order of magnitude on vast graphs (millions ofnodes and billions of edges) with limited accuracy degradation.</description>
      <author>example@mail.com (Zhihao Shi, Jie Wang, Zhiwei Zhuang, Xize Liang, Bin Li, Feng Wu)</author>
      <guid isPermaLink="false">2502.19693v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Spatial-Spectral Diffusion Contrastive Representation Network for Hyperspectral Image Classification</title>
      <link>http://arxiv.org/abs/2502.19699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于去噪扩散概率模型（DDPM）结合对比学习（CL）的新型网络DiffCRN，用于高光谱图像分类（HSIC），旨在改进空间-光谱特征表示、无监督特征学习效率、时间步长选择和特征融合与分类。&lt;h4&gt;背景&lt;/h4&gt;在对高光谱图像进行有效提取具有区分性的空间-光谱特征时面临挑战，主要由于空间-光谱异质性和噪声效应等因素导致难以实现高效的空间-光谱特征表示。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的网络结构DiffCRN来改进高光谱图像分类中的空间-光谱特征学习效率和无监督特性提取。&lt;h4&gt;方法&lt;/h4&gt;{'架构设计': '采用具有空间自注意去噪模块（SSAD）和光谱组自注意力去噪模块（SGSAD）的分阶段架构，代替常用的UNet-like结构。', '改进损失函数': '设计新的DDPM模型结合对数绝对误差（LAE）损失和对比学习以提高损失函数的有效性和增强实例级别和类间区分性。', '时间步长选择': '引入基于像素级光谱角度映射（SAM）的可学习方法，自适应自动地为提出的DDPM模型选择合适的时间步骤。', '特征融合与分类': '设计了自适应加权添加模块（AWAM）和跨时间步空间-光谱融合模块（CTSSFM）以融合按时间步划分的特性并进行分类。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的DiffCRN模型在四个广泛使用的高光谱数据集上相比经典基础模型、最新的GAN、Transformer模型和其他预训练方法具有更好的性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效提高HSIC任务中的空间-光谱特征表示能力和无监督特性提取的效率，为该领域提供了一种新的解决方案。源代码和预训练模型将公开发布。&lt;h4&gt;翻译&lt;/h4&gt;尽管对高光谱图像分类（HSIC）来说，高效地提取具有区分性的空间-光谱特征是至关重要的，但由于诸如空间-光谱异质性和噪声效应等因素的影响，实现这些特性非常困难。本文提出了一种基于去噪扩散概率模型（DDPM）与对比学习（CL）结合的高光谱图像分类（HSIC）的空间-光谱扩散对比表示网络（DiffCRN）。该方法具有以下特点：改进空间-光谱特征表示；提高无监督特性学习效率；改进时间步长选择；改进特性融合和分类。实验结果表明，所提出的模型在四个广泛使用的高光谱数据集上相比经典基础模型、最新的GAN、Transformer模型和其他预训练方法有更优的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although efficient extraction of discriminative spatial-spectral features iscritical for hyperspectral images classification (HSIC), it is difficult toachieve these features due to factors such as the spatial-spectralheterogeneity and noise effect. This paper presents a Spatial-SpectralDiffusion Contrastive Representation Network (DiffCRN), based on denoisingdiffusion probabilistic model (DDPM) combined with contrastive learning (CL)for HSIC, with the following characteristics. First,to improve spatial-spectralfeature representation, instead of adopting the UNets-like structure which iswidely used for DDPM, we design a novel staged architecture with spatialself-attention denoising module (SSAD) and spectral group self-attentiondenoising module (SGSAD) in DiffCRN with improved efficiency forspectral-spatial feature learning. Second, to improve unsupervised featurelearning efficiency, we design new DDPM model with logarithmic absolute error(LAE) loss and CL that improve the loss function effectiveness and increase theinstance-level and inter-class discriminability. Third, to improve featureselection, we design a learnable approach based on pixel-level spectral anglemapping (SAM) for the selection of time steps in the proposed DDPM model in anadaptive and automatic manner. Last, to improve feature integration andclassification, we design an Adaptive weighted addition modul (AWAM) and Crosstime step Spectral-Spatial Fusion Module (CTSSFM) to fuse time-step-wisefeatures and perform classification. Experiments conducted on widely used fourHSI datasets demonstrate the improved performance of the proposed DiffCRN overthe classical backbone models and state-of-the-art GAN, transformer models andother pretrained methods. The source code and pre-trained model will be madeavailable publicly.</description>
      <author>example@mail.com (Yimin Zhu, Linlin Xu)</author>
      <guid isPermaLink="false">2502.19699v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>SeisMoLLM: Advancing Seismic Monitoring via Cross-modal Transfer with Pre-trained Large Language Model</title>
      <link>http://arxiv.org/abs/2502.19960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 6 figures. Code is available at  https://github.com/StarMoonWang/SeisMoLLM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SeisMoLLM，这是一个利用跨模态迁移的地震监测基础模型，它通过大规模预训练从大型语言模型中释放其潜力，并在多个复杂的地震监测任务上取得了卓越性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，深度学习技术革新了地震监控领域。然而，在处理信号退化或数据稀缺的情况下开发适用于多种复杂任务的基础模型仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究目的是提出一种新的基础模型SeisMoLLM，以提高在各种地震监测任务中的性能，并探索跨模态迁移的可能性。&lt;h4&gt;方法&lt;/h4&gt;通过精心设计的波形标记和对预训练GPT-2模型进行微调的方式实现，不直接在地震数据集上进行预训练。该模型在DiTing和STEAD数据集中执行五个关键任务：后方角估计、震中距离估计、震级估计、相位选择以及首次运动极性分类。&lt;h4&gt;主要发现&lt;/h4&gt;SeisMoLLM在43个任务度量标准中有36项达到了最佳结果，在16个少量样本泛化度量标准中的12项上取得了顶级分数。相对改进幅度范围从10%到50%&lt;h4&gt;结论&lt;/h4&gt;研究表明，SeisMoLLM是一个具有前景的基础模型，适用于实际地震监测，并且展示了跨模态迁移作为地震研究中一个令人兴奋的新方向的潜力。&lt;h4&gt;翻译&lt;/h4&gt;近年来，深度学习技术革新了地震监控领域。然而，在处理信号退化或数据稀缺的情况下开发适用于多种复杂任务的基础模型仍然具有挑战性。这项工作提出了一种名为SeisMoLLM的基础模型，它是第一个利用跨模态迁移进行地震监测的模型，该模型通过大规模预训练从大型语言模型中释放其潜力，并不直接在地震数据集上进行预训练。SeisMoLLM采用精细的波形标记化和对预先训练好的GPT-2模型进行微调的方式，在DiTing和STEAD数据集中执行五个关键任务：后方角估计、震中距离估计、震级估计、相位选择以及首次运动极性分类，并在43个任务度量标准中有36项达到了最佳结果，在16个少量样本泛化度量标准中的12项上取得了顶级分数，相对改进幅度范围从10%到50%。除了卓越的性能外，SeisMoLLM在训练和推理方面也保持了与轻量级模型相当甚至更好的效率。这些发现使SeisMoLLM成为具有前景的基础模型，适用于实际地震监测，并且展示了跨模态迁移作为地震研究中一个令人兴奋的新方向的潜力，突显了高级深度学习技术推动地震学研究发展的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/StarMoonWang/SeisMoLLM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in deep learning have revolutionized seismic monitoring, yetdeveloping a foundation model that performs well across multiple complex tasksremains challenging, particularly when dealing with degraded signals or datascarcity. This work presents SeisMoLLM, the first foundation model thatutilizes cross-modal transfer for seismic monitoring, to unleash the power oflarge-scale pre-training from a large language model without requiring directpre-training on seismic datasets. Through elaborate waveform tokenization andfine-tuning of pre-trained GPT-2 model, SeisMoLLM achieves state-of-the-artperformance on the DiTing and STEAD datasets across five critical tasks:back-azimuth estimation, epicentral distance estimation, magnitude estimation,phase picking, and first-motion polarity classification. It attains 36 bestresults out of 43 task metrics and 12 top scores out of 16 few-shotgeneralization metrics, with many relative improvements ranging from 10% to50%. In addition to its superior performance, SeisMoLLM maintains efficiencycomparable to or even better than lightweight models in both training andinference. These findings establish SeisMoLLM as a promising foundation modelfor practical seismic monitoring and highlight cross-modal transfer as anexciting new direction for earthquake studies, showcasing the potential ofadvanced deep learning techniques to propel seismology research forward.</description>
      <author>example@mail.com (Xinghao Wang, Feng Liu, Rui Su, Zhihui Wang, Lei Bai, Wanli Ouyang)</author>
      <guid isPermaLink="false">2502.19960v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Open-Vocabulary Semantic Part Segmentation of 3D Human</title>
      <link>http://arxiv.org/abs/2502.19782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3DV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了首个能够处理3D人体的开放词汇分割方法。&lt;h4&gt;背景&lt;/h4&gt;传统的监督分割方法由于标注数据有限，在泛化到未见过的人体形状和类别上效果不佳。最近，视觉-语言模型在零样本能力上的进步推动了开放世界的3D分割方法的发展，但这些方法对3D人类的泛化效果不理想。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够根据文本提示将人体划分为期望的细粒度部分的方法。&lt;h4&gt;方法&lt;/h4&gt;采用了基于SAM的多视角提案生成和一个新颖的人体CLIP模型来创建视觉和文本输入的一致性嵌入。同时，还引入了一个简单的MaskFusion模块，该模块通过分类和融合多视图特征直接形成3D语义掩膜。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在各种3D人体数据集上，本方法优于当前最先进的开放词汇3D分割方法，并且可以应用于包括网格、点云和3D高斯散布在内的多种3D表示形式。&lt;h4&gt;结论&lt;/h4&gt;提出的方法为处理复杂的3D人体场景提供了一个强有力的解决方案，并展示了在未来的AR/VR应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的直接翻译，描述了3D部分分割是三维视觉和AR/VR领域的一个开放问题。由于标注数据有限，传统的监督方法无法很好地泛化到未见过的人体形状和类别上。通过利用先进视觉-语言模型的能力，该论文提出了一种新的处理3D人体的方法，并展示了其在多种3D表示形式上的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D part segmentation is still an open problem in the field of 3D vision andAR/VR. Due to limited 3D labeled data, traditional supervised segmentationmethods fall short in generalizing to unseen shapes and categories. Recently,the advancement in vision-language models' zero-shot abilities has brought asurge in open-world 3D segmentation methods. While these methods show promisingresults for 3D scenes or objects, they do not generalize well to 3D humans. Inthis paper, we present the first open-vocabulary segmentation method capable ofhandling 3D human. Our framework can segment the human category into desiredfine-grained parts based on the textual prompt. We design a simple segmentationpipeline, leveraging SAM to generate multi-view proposals in 2D and proposing anovel HumanCLIP model to create unified embeddings for visual and textualinputs. Compared with existing pre-trained CLIP models, the HumanCLIP modelyields more accurate embeddings for human-centric contents. We also design asimple-yet-effective MaskFusion module, which classifies and fuses multi-viewfeatures into 3D semantic masks without complex voting and grouping mechanisms.The design of decoupling mask proposals and text input also significantlyboosts the efficiency of per-prompt inference. Experimental results on various3D human datasets show that our method outperforms current state-of-the-artopen-vocabulary 3D segmentation methods by a large margin. In addition, we showthat our method can be directly applied to various 3D representations includingmeshes, point clouds, and 3D Gaussian Splatting.</description>
      <author>example@mail.com (Keito Suzuki, Bang Du, Girish Krishnan, Kunyao Chen, Runfa Blark Li, Truong Nguyen)</author>
      <guid isPermaLink="false">2502.19782v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>One Model for ALL: Low-Level Task Interaction Is a Key to Task-Agnostic Image Fusion</title>
      <link>http://arxiv.org/abs/2502.19854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的图像融合框架GIFNet，该框架通过低级视觉任务进行像素级别的监督，使得特征交互更加有效。&lt;h4&gt;背景&lt;/h4&gt;高级图像融合方法主要侧重于高层次的任务，在这些任务中，任务间的互动因语义差距而变得复杂，需要复杂的桥接机制。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的图像融合方法，以简化特征之间的相互作用，并提高跨模态无监督融合的性能。&lt;h4&gt;方法&lt;/h4&gt;利用数字摄影中的低级视觉任务进行像素级别的监督，通过这种方式来实现更有效的特征交互和增强的任务共享特性学习。&lt;h4&gt;主要发现&lt;/h4&gt;GIFNet支持多种图像融合任务，并且在已见场景和未见过的场景中均表现出色。此外，该框架还能够用于单模态增强，为实际应用提供了更大的灵活性。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于低级视觉任务的像素级别监督方法提供了一种新的、强大的指导方式，无需依赖抽象语义即可实现多模式融合，并且在广泛的图像处理任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;先进的图像融合技术通常侧重于高层次的任务，在这些任务中，不同的任务之间的互动因为需要跨越较大的语义差距而变得困难。相比之下，我们提出了一种新的方法，利用数字摄影中的低级视觉任务来实现像素级别的监督和有效的特征交互。这种新的范式提供了强大的指导，可以无需依赖抽象的语义信息来进行跨模态无监督融合，并且增强了对于广泛适用性的任务共享特性学习。由于混合图像特性和增强的通用表示形式，提出的GIFNet支持多种不同的融合任务，在已见和未见过的情景中均表现出色。此外，实验结果还表明我们的框架能够支持单模态增强功能，从而为实际应用提供更优秀的灵活性。我们的代码可以在https://github.com/AWCXV/GIFNet上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advanced image fusion methods mostly prioritise high-level missions, wheretask interaction struggles with semantic gaps, requiring complex bridgingmechanisms. In contrast, we propose to leverage low-level vision tasks fromdigital photography fusion, allowing for effective feature interaction throughpixel-level supervision. This new paradigm provides strong guidance forunsupervised multimodal fusion without relying on abstract semantics, enhancingtask-shared feature learning for broader applicability. Owning to the hybridimage features and enhanced universal representations, the proposed GIFNetsupports diverse fusion tasks, achieving high performance across both seen andunseen scenarios with a single model. Uniquely, experimental results revealthat our framework also supports single-modality enhancement, offering superiorflexibility for practical applications. Our code will be available athttps://github.com/AWCXV/GIFNet.</description>
      <author>example@mail.com (Chunyang Cheng, Tianyang Xu, Zhenhua Feng, Xiaojun Wu, ZhangyongTang, Hui Li, Zeyang Zhang, Sara Atito, Muhammad Awais, Josef Kittler)</author>
      <guid isPermaLink="false">2502.19854v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>You Only Click Once: Single Point Weakly Supervised 3D Instance Segmentation for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2502.19698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;户外LiDAR点云三维实例分割是自动驾驶中的关键任务，但由于需要耗费大量人力来标注训练数据，因此该任务面临挑战。为了解决这一问题，提出了一个名为YoCo的框架，它使用稀疏的手工点击注释在俯视图平面上生成高质量的伪标签。&lt;h4&gt;背景&lt;/h4&gt;户外LiDAR点云三维实例分割对于自动驾驶至关重要，但手动标注训练数据的成本很高。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来减少人工标注的工作量，并提高伪标签的质量和可靠性。&lt;h4&gt;方法&lt;/h4&gt;{'YoCo框架': '使用视觉基础模型与点云的几何约束结合生成高质量的伪标签；设计了一个基于时间和空间的更新模块，利用相邻帧的预测结果并考虑点云的密度变化来生成可靠的更新标签；提出了一种IoU引导增强模块，以高置信度和高交并比（IoU）的预测替换低质量的伪标签。', '实验验证': '在Waymo数据集上的实验证明了YoCo框架的有效性和广泛适用性。'}&lt;h4&gt;主要发现&lt;/h4&gt;YoCo在弱监督方法中取得了最先进的性能，并且在各种网络上使用少量完全标注的数据进行微调后，其性能可以与全监督方法相媲美。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种高效生成高质量伪标签的方法，显著降低了标注成本，适用于多种网络架构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Outdoor LiDAR point cloud 3D instance segmentation is a crucial task inautonomous driving. However, it requires laborious human efforts to annotatethe point cloud for training a segmentation model. To address this challenge,we propose a YoCo framework, which generates 3D pseudo labels using minimalcoarse click annotations in the bird's eye view plane. It is a significantchallenge to produce high-quality pseudo labels from sparse annotations. OurYoCo framework first leverages vision foundation models combined with geometricconstraints from point clouds to enhance pseudo label generation. Second, atemporal and spatial-based label updating module is designed to generatereliable updated labels. It leverages predictions from adjacent frames andutilizes the inherent density variation of point clouds (dense near, sparsefar). Finally, to further improve label quality, an IoU-guided enhancementmodule is proposed, replacing pseudo labels with high-confidence and high-IoUpredictions. Experiments on the Waymo dataset demonstrate YoCo's effectivenessand generality, achieving state-of-the-art performance among weakly supervisedmethods and surpassing fully supervised Cylinder3D. Additionally, the YoCo issuitable for various networks, achieving performance comparable to fullysupervised methods with minimal fine-tuning using only 0.8% of the fullylabeled data, significantly reducing annotation costs.</description>
      <author>example@mail.com (Guangfeng Jiang, Jun Liu, Yongxuan Lv, Yuzhi Wu, Xianfei Li, Wenlong Liao, Tao He, Pai Peng)</author>
      <guid isPermaLink="false">2502.19698v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>MICINet: Multi-Level Inter-Class Confusing Information Removal for Reliable Multimodal Classification</title>
      <link>http://arxiv.org/abs/2502.19674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个可靠多模态分类方法MICINet，用于在存在噪音数据的情况下有效移除两种类型的噪声。&lt;h4&gt;背景&lt;/h4&gt;可靠的多模态学习尤其是在安全关键应用中是一个广受关注的问题。现有的许多方法只能处理特定模式或跨模态的噪音，而不能有效地处理这两种类型噪音的同时存在。&lt;h4&gt;目的&lt;/h4&gt;为了提高可靠性和应对上述挑战，提出了一种新的分类方法MICINet，该方法旨在统一并移除全球和个体水平上的干扰信息（ICI）。&lt;h4&gt;方法&lt;/h4&gt;MICINet通过全局ICI学习模块可靠地学习整体的ICI分布，并利用样本自适应跨模态信息补偿模块在个体层面上可靠地移除每个样本的噪声。此外，还引入了全局引导式样本ICILearning模块来高效去除全球级别的噪音。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在各种噪声条件下，MICINet优于其他最先进的可靠的多模态分类方法。&lt;h4&gt;结论&lt;/h4&gt;MICINet通过统一概念并有效移除干扰信息（ICI），成功地应对了现有可靠多模态学习方法的局限性，并在实际应用中展示了其优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable multimodal learning in the presence of noisy data is a widelyconcerned issue, especially in safety-critical applications. Many reliablemultimodal methods delve into addressing modality-specific or cross-modalitynoise. However, they fail to handle the coexistence of both types of noiseefficiently. Moreover, the lack of comprehensive consideration for noise atboth global and individual levels limits their reliability. To address theseissues, a reliable multimodal classification method dubbed Multi-LevelInter-Class Confusing Information Removal Network (MICINet) is proposed.MICINet achieves the reliable removal of both types of noise by unifying theminto the concept of Inter-class Confusing Information (\textit{ICI}) andeliminating it at both global and individual levels. Specifically, MICINetfirst reliably learns the global \textit{ICI} distribution through the proposed\textbf{\textit{Global \textbf{ICI} Learning Module}}. Then, it introduces the\textbf{\textit{Global-guided Sample ICI Learning module}} to efficientlyremove global-level \textit{ICI} from sample features utilizing the learnedglobal \textit{ICI} distribution. Subsequently, the\textbf{\textit{Sample-adaptive Cross-modality Information Compensationmodule}} is designed to remove individual-level \textit{ICI} from each samplereliably. This is achieved through interpretable cross-modality informationcompensation based on the complementary relationship between discriminativefeatures and \textit{ICI} and the perception of the relative quality ofmodalities introduced by the relative discriminative power. Experiments on fourdatasets demonstrate that MICINet outperforms other state-of-the-art reliablemultimodal classification methods under various noise conditions.</description>
      <author>example@mail.com (Tong Zhang, Shu Shen, C. L. Philip Chen)</author>
      <guid isPermaLink="false">2502.19674v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Machine Learning Approach for Yield Prediction in Chemical Reactions</title>
      <link>http://arxiv.org/abs/2502.19976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;机器学习模型在化学反应产率预测中的应用已成为近年来的重要研究方向。本文提出了一种新的时间高效和资源高效的预训练策略，以及一种分类后回归的模型(CFR)，用于解决不平衡及稀疏数据集的问题。&lt;h4&gt;背景&lt;/h4&gt;化学语言表示法为化学反应提供了独特的视角，自然语言处理模型（如ULMFiT）可以在这种分布设置中定制以实现产率预测。然而，目前的数据集存在规模小、偏向高产率以及分布稀疏等问题。&lt;h4&gt;目的&lt;/h4&gt;开发新的预训练策略和CFR模型来提高化学反应产率预测的精度，特别是在不平衡和稀疏数据条件下。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含860多个手动收集自文献中的催化meta-C(sp2)-H键活化反应的新数据集。采用基于子结构从PubChem数据库中构建预训练数据集SSP1（含约0.11百万条目），并将其用于ULMFiT模型的微调。&lt;h4&gt;主要发现&lt;/h4&gt;CFR模型在预测目标化学反应产率时表现优秀，特别是在高产率和低产率两类上分别实现了RMSE为8.40和6.48的结果。这表明该方法不仅有效而且比传统的直接回归方法更优越，并且具有良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;CFR模型结合ULMFiT-SSP1回归器能够提供最先进的产率预测，证明了这种方法在解决不平衡和稀疏数据挑战中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;开发用于化学反应产率预测的机器学习（ML）模型已成为近年来的重要研究领域。此类数据集面临的主要挑战源自于不平衡与稀疏性。本文中，作者使用化学语言表示来利用像ULMFiT这样的自然语言处理模型来进行产率预测，并且该方法针对分布设置进行了定制化开发。此外，贡献了一个新的反应数据集，其中包含超过860个从文献中手动提取的跨越十年的数据点，涉及一类高当代重要性的催化meta-C(sp2)-H键活化反应。考虑到数据集规模、偏向高产率以及稀疏性特点，作者提出了一种新型的时间和资源高效的预训练策略用于下游转移学习，并且开发了CFR模型以提供先进的产率预测能力，超越传统的直接回归方法。通过使用基于子结构的从PubChem数据库中提取0.11百万条目的SSP1预训练数据集，替代传统的大规模未标记分子（ChEMBL数据集中有约140万）的预训练惯例，发现这种更有效的时间和效率方法同样可以提供改进性能。ULMFiT-SSP1回归器在CFR模型下对目标反应产率预测表现出8.40和6.48的RMSE（分别对应于53%产率界限以上的高产率类和以下的低产率类）。此外，该方法展示出高度泛化的特性，并且在之前的数据集基准上取得了显著进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing machine learning (ML) models for yield prediction of chemicalreactions has emerged as an important use case scenario in very recent years.In this space, reaction datasets present a range of challenges mostly stemmingfrom imbalance and sparsity. Herein, we consider chemical languagerepresentations for reactions to tap into the potential of natural languageprocessing models such as the ULMFiT (Universal Language Model Fine Tuning) foryield prediction, which is customized to work across such distributionsettings. We contribute a new reaction dataset with more than 860 manuallycurated reactions collected from literature spanning over a decade, belongingto a family of catalytic meta-C(sp2)-H bond activation reactions of highcontemporary importance. Taking cognizance of the dataset size, skewness towardthe higher yields, and the sparse distribution characteristics, we developed anew (i) time- and resource-efficient pre-training strategy for downstreamtransfer learning, and (ii) the CFR (classification followed by regression)model that offers state-of-the-art yield predictions, surpassing conventionaldirect regression (DR) approaches. Instead of the prevailing pre-trainingpractice of using a large number of unlabeled molecules (1.4 million) from theChEMBL dataset, we first created a pre-training dataset SSP1 (0.11 million), byusing a substructure-based mining from the PubChem database, which is found tobe equally effective and more time-efficient in offering enhanced performance.The CFR model with the ULMFiT-SSP1 regressor achieved an impressive RMSE of8.40 for the CFR-major and 6.48 for the CFR-minor class in yield prediction onthe title reaction, with a class boundary of yield at 53 %. Furthermore, theCFR model is highly generalizable as evidenced by the significant improvementover the previous benchmark reaction datasets.</description>
      <author>example@mail.com (Supratim Ghosh, Nupur Jain, Raghavan B. Sunoj)</author>
      <guid isPermaLink="false">2502.19976v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Improving Representation Learning of Complex Critical Care Data with ICU-BERT</title>
      <link>http://arxiv.org/abs/2502.19593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for poster at GenAI4Health Workshop at AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了ICU-BERT模型，这是一种基于Transformer架构的预训练模型，使用MIMIC-IV数据库进行多任务学习，以最小化的预处理步骤从复杂的ICU数据中提取出健壮表示。&lt;h4&gt;背景&lt;/h4&gt;现实世界临床数据的多元性和异步性对传统的AI决策支持系统提出了挑战。这些传统系统通常假设数据具有规律性和特征独立性，并且依赖于有限的数据范围和手动特征工程，而生成式AI技术在分析临床数据方面的潜力尚未得到充分开发。&lt;h4&gt;目的&lt;/h4&gt;提出ICU-BERT模型以提高复杂多变量的ICU数据表示的可解释性和通用性。&lt;h4&gt;方法&lt;/h4&gt;ICU-BERT采用多令牌输入策略，并结合生物医学大型语言模型的密集嵌入，通过MIMIC-IV数据库进行预训练，利用多种任务学习框架来实现这一目标。该模型能够处理结构化和非结构化的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;初步评估表明，ICU-BERT在五项任务及四个额外的ICU数据集中取得的结果优于或达到当前性能基准，通过微调技术可以进一步提升表现。&lt;h4&gt;结论&lt;/h4&gt;ICU-BERT模型推进了基础模型在医学信息学中的应用，并为各种临床决策支持提供了灵活解决方案。该模型表明，在处理复杂和多变量的数据时，采用预训练的Transformer架构能够有效地超越传统AI方法。&lt;h4&gt;翻译&lt;/h4&gt;现实世界中重症监护病房（ICUs）等环境生成的多元异步医疗数据对传统的基于人工智能的决策支持系统提出了挑战。这些传统系统通常假设数据具有规律性且特征间独立，并依赖于有限的数据范围和手动特征工程。目前，生成式AI技术在分析临床数据方面尚未得到充分利用。我们介绍了ICU-BERT模型，这是一个基于Transformer架构的预训练模型，在MIMIC-IV数据库上通过多任务学习方案进行训练，从而实现复杂且多元化的重症监护病房（ICUs）数据的稳健表示，同时需要最小化预处理步骤。ICU-BERT采用了一种多令牌输入策略，并结合了生物医学大型语言模型的密集嵌入以获得通用性的表示方法。初步评估表明，在五项任务及四个额外的数据集上ICU-BERT的表现要么与当前性能基准持平或超越它们，通过微调技术可以进一步提高表现水平。此外，ICU-BERT将结构化和非结构化的数据结合起来，促进了基础模型在医学信息学中的应用，并为多种临床决策支持提供了灵活的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The multivariate, asynchronous nature of real-world clinical data, such asthat generated in Intensive Care Units (ICUs), challenges traditional AI-baseddecision-support systems. These often assume data regularity and featureindependence and frequently rely on limited data scopes and manual featureengineering. The potential of generative AI technologies has not yet been fullyexploited to analyze clinical data. We introduce ICU-BERT, a transformer-basedmodel pre-trained on the MIMIC-IV database using a multi-task scheme to learnrobust representations of complex ICU data with minimal preprocessing. ICU-BERTemploys a multi-token input strategy, incorporating dense embeddings from abiomedical Large Language Model to learn a generalizable representation ofcomplex and multivariate ICU data. With an initial evaluation of five tasks andfour additional ICU datasets, ICU-BERT results indicate that ICU-BERT eithercompares to or surpasses current performance benchmarks by leveragingfine-tuning. By integrating structured and unstructured data, ICU-BERT advancesthe use of foundational models in medical informatics, offering an adaptablesolution for clinical decision support across diverse applications.</description>
      <author>example@mail.com (Ricardo Santos, André V. Carreiro, Xi Peng, Hugo Gamboa, Holger Fröhlich)</author>
      <guid isPermaLink="false">2502.19593v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Pathology Report Generation and Multimodal Representation Learning for Cutaneous Melanocytic Lesions</title>
      <link>http://arxiv.org/abs/2502.19293v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 2 figures. arXiv admin note: text overlap with  arXiv:2502.19285&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;开发了一个专门针对皮肤黑素细胞病变的视觉-语言模型，并通过实验验证了该模型在生成普通痣病理报告方面的质量与医生写作相当。&lt;h4&gt;背景&lt;/h4&gt;每年有数百万黑色素细胞皮肤病灶被病理学家检查，大多数是普通的痣。虽然大部分病灶可以快速诊断，但撰写相应的病理报告非常耗时。&lt;h4&gt;目的&lt;/h4&gt;通过自动化部分报告编写过程来减轻病理学家的工作负担。&lt;h4&gt;方法&lt;/h4&gt;构建了一个遵循对比生成器框架的视觉-语言模型，并使用包含42,512张H&amp;E染色完整切片图像和19,645份对应病理报告的数据集进行训练和评估。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在普通痣病理报告的质量评分上与病理学家书写的报告相当，但在罕见黑色素细胞病变亚型的报告生成方面更为困难。然而，在这些病例中的跨模态检索性能有所提高。&lt;h4&gt;结论&lt;/h4&gt;通过自动化的视觉-语言模型可以有效减轻病理医生撰写常见皮肤黑素瘤病灶报告的工作负担，并且在处理复杂或罕见类型时表现出色，尤其是在信息检索上的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;每年有数百万黑色素细胞皮肤病变由病理学家检查，其中大多数涉及常见的痣。尽管大部分病变可以在几秒钟内诊断出来，但编写相应的病理报告却非常耗时。因此，自动化部分报告撰写过程可以缓解不断增加的工作量。在这项研究中，我们开发了一个专门用于皮肤黑素细胞病变领域的视觉-语言模型。该模型遵循对比生成器框架，并使用42,512张H&amp;E染色全切片图像和19,645份相应病理报告的黑色素细胞病灶数据集进行训练和评估。实验结果显示，由模型生成的报告质量评分与专家病理学家书写的报告相当，尤其是在普通痣的情况下。尽管对于罕见的黑素瘤亚型来说报告生成更为困难，但在这些情况下跨模态检索性能有了显著提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Millions of melanocytic skin lesions are examined by pathologists each year,the majority of which concern common nevi (i.e., ordinary moles). While most ofthese lesions can be diagnosed in seconds, writing the corresponding pathologyreport is much more time-consuming. Automating part of the report writingcould, therefore, alleviate the increasing workload of pathologists. In thiswork, we develop a vision-language model specifically for the pathology domainof cutaneous melanocytic lesions. The model follows the Contrastive Captionerframework and was trained and evaluated using a melanocytic lesion dataset of42,512 H&amp;E-stained whole slide images and 19,645 corresponding pathologyreports. Our results show that the quality scores of model-generated reportswere on par with pathologist-written reports for common nevi, assessed by anexpert pathologist in a reader study. While report generation revealed to bemore difficult for rare melanocytic lesion subtypes, the cross-modal retrievalperformance for these cases was considerably better.</description>
      <author>example@mail.com (Ruben T. Lucassen, Sander P. J. Moonemans, Tijn van de Luijtgaarden, Gerben E. Breimer, Willeke A. M. Blokx, Mitko Veta)</author>
      <guid isPermaLink="false">2502.19293v2</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Training Robust Graph Neural Networks by Modeling Noise Dependencies</title>
      <link>http://arxiv.org/abs/2502.19670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的噪声场景依赖感知图噪声（DANG），并设计了一种新颖的鲁棒GNN模型DA-GNN，该模型可以处理节点特征、图结构和节点标签之间相互影响的噪声情况。&lt;h4&gt;背景&lt;/h4&gt;在现实应用中，图中的节点特性常常包含来自各种来源的噪声，这会导致基于图神经网络（GNN）的性能显著下降。现有的增强鲁棒性的方法假设噪声与图结构和节点标签独立，这一假设并不符合实际情况。&lt;h4&gt;目的&lt;/h4&gt;引入一种更实际的噪声场景——依赖感知图噪声（DANG），并提出相应的模型以提高在该情况下的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个称为DA-GNN的新模型，利用变分推理捕捉数据生成过程中变量之间的因果关系，并设计了新的基准测试集来模拟现实中的DANG情形。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，无论是在依赖感知图噪声（DANG）还是传统的噪声模式下，提出的DA-GNN在各种噪音场景中都优于现有的基线方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的DA-GNN模型及其新的基准测试集为解决基于图的机器学习中的鲁棒性问题提供了一种更实际的方法。&lt;h4&gt;翻译&lt;/h4&gt;在现实世界的应用中，图中的节点特征通常包含来自各种来源的噪声，这会导致GNN性能显著下降。尽管已经开发了几种增强鲁棒性的方法，但它们依赖于一个不切实际的假设：即节点特征中的噪声与图结构和节点标签独立。为此，我们引入了一种更现实的噪声场景——依赖感知图噪声（DANG），在这种情形下，节点特征中的噪声会在图结构和节点标签之间产生噪声依赖链。我们提出了一种新的鲁棒GNN模型DA-GNN，该模型使用变分推理捕捉数据生成过程中的因果关系。此外，我们还提出了模拟现实应用中DANG的新基准测试集，使更实际的关于鲁棒GNN的研究成为可能。广泛的实验表明，在各种噪声场景（包括DANG和传统噪声模型）下，DA-GNN始终优于现有的基线方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world applications, node features in graphs often contain noise fromvarious sources, leading to significant performance degradation in GNNs.Although several methods have been developed to enhance robustness, they relyon the unrealistic assumption that noise in node features is independent of thegraph structure and node labels, thereby limiting their applicability. To thisend, we introduce a more realistic noise scenario, dependency-aware noise ongraphs (DANG), where noise in node features create a chain of noisedependencies that propagates to the graph structure and node labels. We proposea novel robust GNN, DA-GNN, which captures the causal relationships amongvariables in the data generating process (DGP) of DANG using variationalinference. In addition, we present new benchmark datasets that simulate DANG inreal-world applications, enabling more practical research on robust GNNs.Extensive experiments demonstrate that DA-GNN consistently outperforms existingbaselines across various noise scenarios, including both DANG and conventionalnoise models commonly considered in this field.</description>
      <author>example@mail.com (Yeonjun In, Kanghoon Yoon, Sukwon Yun, Kibum Kim, Sungchul Kim, Chanyoung Park)</author>
      <guid isPermaLink="false">2502.19670v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Prompt-driven Transferable Adversarial Attack on Person Re-Identification with Attribute-aware Textual Inversion</title>
      <link>http://arxiv.org/abs/2502.19697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一个新的攻击方法Attribute-aware Prompt Attack (AP-Attack)，用于探索和利用行人重识别模型的脆弱性。&lt;h4&gt;背景&lt;/h4&gt;在安全监控系统中，人再识别（re-id）模型非常重要。基于视觉语言模型（VLM）的攻击显示出优秀的迁移性，但由于过分强调辨别语义而在整体表示上缺乏全面的功能破坏。&lt;h4&gt;目的&lt;/h4&gt;提出一个新型方法AP-Attack，利用VLM图像文本对齐能力来明确干扰行人图像中的细粒度语义特征。&lt;h4&gt;方法&lt;/h4&gt;通过设计文本逆向网络将行人图像映射到代表语义嵌入的伪令牌上，并在对比学习方式下训练这些网络。使用预定义的提示模板描述具体的行人属性，以获得个性化的文本描述。&lt;h4&gt;主要发现&lt;/h4&gt;AP-Attack 方法显著提升了对抗样本的迁移性，在跨模型和数据集攻击场景中平均Drop Rate比先前的方法提高了22.9%。&lt;h4&gt;结论&lt;/h4&gt;AP-Attack 通过全面干扰细粒度语义特征，增强了对行人重识别系统的攻击能力。&lt;h4&gt;翻译&lt;/h4&gt;人再识别（re-id）模型在安全监控系统中至关重要。最近基于视觉语言模型的攻击显示出优秀的迁移性，但因为过分强调辨别语义而缺乏对整体表示的全面破坏。本文引入了一种新的方法Attribute-aware Prompt Attack (AP-Attack)，利用VLM的图像文本对齐能力，通过摧毁特定属性的文本嵌入来明确地干扰行人图像中的细粒度语义特征。设计了用于映射行人图像到代表语义嵌入的伪令牌上的文本逆向网络，并以对比学习方式训练这些网络，在预定义提示模板下具体描述行人属性。通过这种个性化的文本描述，AP-Attack 方法有效增强了攻击能力，使对抗样本具有更高的迁移性。实验表明，该方法在跨模型和数据集攻击场景中的平均Drop Rate比先前的方法提高了22.9%，达到了最先进的迁移水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Person re-identification (re-id) models are vital in security surveillancesystems, requiring transferable adversarial attacks to explore thevulnerabilities of them. Recently, vision-language models (VLM) based attackshave shown superior transferability by attacking generalized image and textualfeatures of VLM, but they lack comprehensive feature disruption due to theoveremphasis on discriminative semantics in integral representation. In thispaper, we introduce the Attribute-aware Prompt Attack (AP-Attack), a novelmethod that leverages VLM's image-text alignment capability to explicitlydisrupt fine-grained semantic features of pedestrian images by destroyingattribute-specific textual embeddings. To obtain personalized textualdescriptions for individual attributes, textual inversion networks are designedto map pedestrian images to pseudo tokens that represent semantic embeddings,trained in the contrastive learning manner with images and a predefined prompttemplate that explicitly describes the pedestrian attributes. Inverted benignand adversarial fine-grained textual semantics facilitate attacker ineffectively conducting thorough disruptions, enhancing the transferability ofadversarial examples. Extensive experiments show that AP-Attack achievesstate-of-the-art transferability, significantly outperforming previous methodsby 22.9% on mean Drop Rate in cross-model&amp;dataset attack scenarios.</description>
      <author>example@mail.com (Yuan Bian, Min Liu, Yunqi Yi, Xueping Wang, Yaonan Wang)</author>
      <guid isPermaLink="false">2502.19697v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Mixtera: A Data Plane for Foundation Model Training</title>
      <link>http://arxiv.org/abs/2502.19790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  under submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言和视觉模型通过汇集来自多种来源的万亿级标记进行训练。随着训练数据集的增长，手动管理样本变得耗时、繁琐且容易出错。&lt;h4&gt;目的&lt;/h4&gt;构建并展示一个名为Mixtera的数据平面工具，该工具用于基础模型训练，使用户可以声明性地表达在训练期间哪些数据样本应该以何种比例和顺序使用。&lt;h4&gt;方法&lt;/h4&gt;Mixtera是一个独立于文件系统结构的集中式、只读层，可部署在现有训练数据集之上，并支持跨任意属性（如语言、源数据集）的数据混合及基于模型反馈动态调整混合策略的功能。&lt;h4&gt;主要发现&lt;/h4&gt;实验性地评估了Mixtera，证明我们的实现不会成为瓶颈且能够扩展到256个GH200超级芯片。通过在系统中实施提议的自适应数据优化(ADO)算法并评估其性能影响来展示如何支持最近的数据混合策略改进。&lt;h4&gt;结论&lt;/h4&gt;探索了视觉语言模型中的混合作用，为训练大规模基础模型提供了灵活、可扩展和易于使用的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;最先进的大型语言和视觉模型通过来自各种来源的万亿级标记进行训练。随着训练数据集的增长，手动管理样本变得耗时、繁琐且容易出错。然而，最近的研究表明，在训练期间的数据混合及访问样本顺序可以显著影响模型精度。我们建立并展示了Mixtera——一个用于基础模型训练的数据平面工具，它使用户能够声明性地表达在训练过程中应使用哪些数据样本及其比例和顺序。Mixtera是一个独立于文件系统结构的集中式、只读层，可部署在现有训练数据集之上，并支持跨任意属性（如语言、源数据集）的数据混合以及基于模型反馈动态调整混合策略的功能。我们实验性地评估了Mixtera并显示我们的实现不会成为瓶颈且能够扩展到256个GH200超级芯片。通过在系统中实施提议的自适应数据优化(ADO)算法并评估其性能影响来展示如何支持最近的数据混合策略改进，并探索视觉语言模型中的混合作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State-of-the-art large language and vision models are trained over trillionsof tokens that are aggregated from a large variety of sources. As training datacollections grow, manually managing the samples becomes time-consuming,tedious, and prone to errors. Yet recent research shows that the data mixtureand the order in which samples are visited during training can significantlyinfluence model accuracy. We build and present Mixtera, a data plane forfoundation model training that enables users to declaratively express whichdata samples should be used in which proportion and in which order duringtraining. Mixtera is a centralized, read-only layer that is deployed on top ofexisting training data collections and can be declaratively queried. Itoperates independently of the filesystem structure and supports mixtures acrossarbitrary properties (e.g., language, source dataset) as well as dynamicadjustment of the mixture based on model feedback. We experimentally evaluateMixtera and show that our implementation does not bottleneck training andscales to 256 GH200 superchips. We demonstrate how Mixtera supports recentadvancements in mixing strategies by implementing the proposed Adaptive DataOptimization (ADO) algorithm in the system and evaluating its performanceimpact. We also explore the role of mixtures for vision-language models.</description>
      <author>example@mail.com (Maximilian Böther, Xiaozhe Yao, Tolga Kerimoglu, Ana Klimovic)</author>
      <guid isPermaLink="false">2502.19790v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>On the Importance of Text Preprocessing for Multimodal Representation Learning and Pathology Report Generation</title>
      <link>http://arxiv.org/abs/2502.19285v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨了病理图像与语言模型在处理病理性数据时，选取不同类型的信息对多模态表示和自动生成报告质量的影响。&lt;h4&gt;背景&lt;/h4&gt;当前许多视觉-语言模型训练所使用的病理报告包含从配对全玻片图像无法推断出的信息（如患者历史），这可能导致生成报告中出现幻觉句子。&lt;h4&gt;目的&lt;/h4&gt;研究病理报告中选择何种信息用于视觉-语言建模会影响多模态表示和自动生成报告的质量。&lt;h4&gt;方法&lt;/h4&gt;构建了基于BLIP-2框架的模型，利用42,433张HE染色全玻片图像及19,636份对应病理报告进行实验。比较了一个训练在完整报告上的模型与一个仅使用描述细胞和组织外观句子的预处理报告上训练的模型。&lt;h4&gt;主要发现&lt;/h4&gt;文本预处理能够有效防止生成报告中的幻觉，然而，完全报告训练模型在跨模态检索性能方面表现更好。&lt;h4&gt;结论&lt;/h4&gt;对于视觉-语言病理模型而言，在选择用于训练的数据时需权衡自动生成报告的质量和跨模态检索性能之间的平衡。&lt;h4&gt;翻译&lt;/h4&gt;视觉语言模型在病理性研究中能够实现多模态病例检索及自动化报告生成。然而，现有的许多模型都基于包含从配对全玻片图像无法推断出的信息（如患者历史）的病理报告训练而成，可能导致幻觉句子出现在所生成的报告中。本文探讨了选取不同信息类型用于视觉语言建模如何影响多模态表示和自动生成报告的质量。具体而言，比较了一个基于完整报告训练的模型与一个仅使用描述细胞组织外观的HE染色玻片报告上预处理后文本训练出的模型的表现。实验是在BLIP-2框架基础上建立的，利用了一套包含42,433张HE染色全玻片图像和19,636份对应病理报告的数据集进行评估。通过图片到文字以及文字到图片的检索性能，并由专家病理科医生对生成报告进行了定性评价来衡量模型表现。结果表明，文本预处理能预防幻觉在报告生成中的出现。尽管生成报告的质量有所提升，但基于完整报告训练视觉语言模型在跨模态检索性能上仍表现出更好的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models in pathology enable multimodal case retrieval andautomated report generation. Many of the models developed so far, however, havebeen trained on pathology reports that include information which cannot beinferred from paired whole slide images (e.g., patient history), potentiallyleading to hallucinated sentences in generated reports. To this end, weinvestigate how the selection of information from pathology reports forvision-language modeling affects the quality of the multimodal representationsand generated reports. More concretely, we compare a model trained on fullreports against a model trained on preprocessed reports that only includesentences describing the cell and tissue appearances based on the H&amp;E-stainedslides. For the experiments, we built upon the BLIP-2 framework and used acutaneous melanocytic lesion dataset of 42,433 H&amp;E-stained whole slide imagesand 19,636 corresponding pathology reports. Model performance was assessedusing image-to-text and text-to-image retrieval, as well as qualitativeevaluation of the generated reports by an expert pathologist. Our resultsdemonstrate that text preprocessing prevents hallucination in reportgeneration. Despite the improvement in the quality of the generated reports,training the vision-language model on full reports showed better cross-modalretrieval performance.</description>
      <author>example@mail.com (Ruben T. Lucassen, Tijn van de Luijtgaarden, Sander P. J. Moonemans, Gerben E. Breimer, Willeke A. M. Blokx, Mitko Veta)</author>
      <guid isPermaLink="false">2502.19285v2</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>A Principled Approach to Bayesian Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.19796v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 2 tables, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，即转移顺序蒙特卡洛（Transfer Sequential Monte Carlo），用于评估和改进基于幂先验的贝叶斯迁移学习方法。&lt;h4&gt;背景&lt;/h4&gt;在数据稀缺的情况下，从相关数据集中引入信息可以改善对观测数据的推断。当前的贝叶斯迁移学习方法主要依赖于所谓的幂先验来适应性地转移相关信息。&lt;h4&gt;目的&lt;/h4&gt;评估和改进现有的基于幂先验的贝叶斯迁移学习方法，并通过留一交叉验证在目标数据集上评价其效果。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的框架，即转移顺序蒙特卡洛（TSMC），该方法可以有效地选择传输参数并避免了对共轭先验的需求。此外，使用留一法交叉验证来评估贝叶斯迁移学习的方法性能。&lt;h4&gt;主要发现&lt;/h4&gt;提出的TSMC框架在两项全面的模拟研究中表现出了优越性，并且能够有效提升推断准确性。&lt;h4&gt;结论&lt;/h4&gt;通过新的TSMC框架改进了现有基于幂先验的贝叶斯迁移学习方法，为解决数据稀缺问题提供了一种有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;更新先验信息以适应观测到的数据是贝叶斯推理的核心。贝叶斯迁移学习则扩展这一理念，将相关信息从相关数据集中引入，来改善在某些条件下可能略有不同的观测数据的推断。当前基于所谓的幂先验的贝叶斯迁移学习方法可以自适应地转移相关信息。然而，并非总能清楚这种技术在哪种情况下表现最佳或是否能够改进贝叶斯推理。现有的幂先验方法依赖于共轭关系来评估感兴趣的后验分布。我们提出了一种使用目标数据集上的留一交叉验证作为评估贝叶斯迁移学习的方法。此外，引入了新的框架，即转移顺序蒙特卡洛（TSMC），用于幂先验方法，并高效地选择传输参数同时避免了对共轭先验的需求。在两项全面的模拟研究中我们评估了所提议方法的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Updating $\textit{a priori}$ information given some observed data is the coretenet of Bayesian inference. Bayesian transfer learning extends this idea byincorporating information from a related dataset to improve the inference onthe observed data which may have been collected under slightly differentsettings. The use of related information can be useful when the observed datais scarce, for example. Current Bayesian transfer learning methods that arebased on the so-called $\textit{power prior}$ can adaptively transferinformation from related data. Unfortunately, it is not always clear underwhich scenario Bayesian transfer learning performs best or even if it willimprove Bayesian inference. Additionally, current power prior methods rely onconjugacy to evaluate the posterior of interest. We propose using leave-one-outcross validation on the target dataset as a means of evaluating Bayesiantransfer learning methods. Further, we introduce a new framework,$\textit{transfer sequential Monte Carlo}$, for power prior approaches thatefficiently chooses the transfer parameter while avoiding the need forconjugate priors. We assess the performance of our proposed methods in twocomprehensive simulation studies.</description>
      <author>example@mail.com (Adam Bretherton, Joshua J. Bon, David J. Warne, Kerrie Mengersen, Christopher Drovandi)</author>
      <guid isPermaLink="false">2502.19796v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>PhenoProfiler: Advancing Phenotypic Learning for Image-based Drug Discovery</title>
      <link>http://arxiv.org/abs/2502.19568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhenoProfiler是一个用于药物发现领域的创新模型，旨在从多通道整张图像中直接提取形态表示，并通过大规模数据集的评估证明其在准确性和鲁棒性上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;现有的基于图片的药物发现方法需要复杂的多步骤计算过程，这会引入效率低下、限制泛化能力和增加潜在错误的问题。&lt;h4&gt;目的&lt;/h4&gt;提出PhenoProfiler模型以解决上述挑战，提高形态表示学习中的效率和准确性，并增强其鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;PhenoProfiler是一个端到端工具，直接处理多通道整张图像并生成低维定量表示。它包含一个多目标学习模块来提升在形态表示学习方面的准确性和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过大规模公开数据集的评估，证明了PhenoProfiler比现有方法性能更好，在准确性和鲁棒性方面有显著提高，特别是在识别生物有意义信号的能力上表现突出。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，PhenoProfiler是一个可扩展、泛化和稳健的学习表型变化的工具。&lt;h4&gt;翻译&lt;/h4&gt;在药物发现领域中，捕捉细胞对不同治疗方式反应至关重要。然而现有方法需要复杂的多步骤计算过程，导致效率低下等问题。我们提出了一种名为PhenoProfiler的新模型，它可以高效地从图像中提取形态表示，并通过大规模数据集证明其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the field of image-based drug discovery, capturing the phenotypic responseof cells to various drug treatments and perturbations is a crucial step.However, existing methods require computationally extensive and complexmulti-step procedures, which can introduce inefficiencies, limitgeneralizability, and increase potential errors. To address these challenges,we present PhenoProfiler, an innovative model designed to efficiently andeffectively extract morphological representations, enabling the elucidation ofphenotypic changes induced by treatments. PhenoProfiler is designed as anend-to-end tool that processes whole-slide multi-channel images directly intolow-dimensional quantitative representations, eliminating the extensivecomputational steps required by existing methods. It also includes amulti-objective learning module to enhance robustness, accuracy, andgeneralization in morphological representation learning. PhenoProfiler isrigorously evaluated on large-scale publicly available datasets, including over230,000 whole-slide multi-channel images in end-to-end scenarios and more than8.42 million single-cell images in non-end-to-end settings. Across thesebenchmarks, PhenoProfiler consistently outperforms state-of-the-art methods byup to 20%, demonstrating substantial improvements in both accuracy androbustness. Furthermore, PhenoProfiler uses a tailored phenotype correctionstrategy to emphasize relative phenotypic changes under treatments,facilitating the detection of biologically meaningful signals. UMAPvisualizations of treatment profiles demonstrate PhenoProfiler ability toeffectively cluster treatments with similar biological annotations, therebyenhancing interpretability. These findings establish PhenoProfiler as ascalable, generalizable, and robust tool for phenotypic learning.</description>
      <author>example@mail.com (Bo Li, Bob Zhang, Chengyang Zhang, Minghao Zhou, Weiliang Huang, Shihang Wang, Qing Wang, Mengran Li, Yong Zhang, Qianqian Song)</author>
      <guid isPermaLink="false">2502.19568v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Mixtraining: A Better Trade-Off Between Compute and Performance</title>
      <link>http://arxiv.org/abs/2502.19513v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;混合训练（MixTraining）是一种在单一训练阶段内交替执行自监督学习和有监督学习的方法，旨在提高模型性能并减少计算开销。&lt;h4&gt;背景&lt;/h4&gt;将自监督学习应用于数据限制场景中以增强模型表现已成为一种常见策略，但这种方法带来了计算资源与模型性能之间的权衡：尽管提高了表示能力，却增加了额外的训练阶段，导致效率降低。&lt;h4&gt;目的&lt;/h4&gt;解决传统方法在时间和计算资源上的瓶颈问题，提出了一种新的混合框架（MixTraining），旨在提高自监督学习和有监督学习之间的协同作用，并减少共享步骤的计算负担。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新型框架——混合训练（MixTraining），该框架在一个统一的训练阶段内交替执行SSL和SL的几个周期。同时，在两个学习目标之间引入了平滑过渡机制，使得模型能够在单一训练过程中高效完成自监督和有监督任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与传统方法相比，混合训练在多个数据集上提供了更好的计算性能权衡，并且可以在不牺牲精度的情况下加快训练速度。例如，在TinyImageNet数据集中实现了8.81%的绝对准确率提升（相对于基准而言提高了18.89%），同时使用ViT-Tiny模型时可加速多达1.29倍。&lt;h4&gt;结论&lt;/h4&gt;混合训练方法证明了其在多种任务环境下的有效性和高效性，特别是在资源受限情况下。它为解决当前深度学习研究中计算效率与性能之间的矛盾提供了一种新的视角和解决方案。&lt;h4&gt;翻译&lt;/h4&gt;将自监督学习（SSL）整合到标准有监督学习之前已成为一种广泛使用的策略来提升模型表现，尤其是在数据有限的情况下。然而，这种方法引入了计算资源和性能之间的权衡：虽然自监督学习有助于表示能力的提高，但需要额外的训练阶段，增加了计算开销并限制了资源受限条件下的效率。为了应对这些挑战，我们提出了混合训练（MixTraining），这是一种新的框架，在统一的训练过程中交替执行多个SSL和SL周期，并在两个学习目标之间实现平滑过渡。这种方法增强了自监督学习与有监督学习之间的协同作用以提高精度，并通过减少共享计算步骤来降低计算开销。混合训练具有广泛适用性，适用于单任务和多任务场景。广泛的实验表明，相对于传统流水线而言，MixTraining提供了更好的计算性能权衡，在TinyImageNet数据集中实现了8.81%的绝对准确率提升（比基准提高了18.89%），使用ViT-Tiny模型时可加速多达1.29倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Incorporating self-supervised learning (SSL) before standard supervisedlearning (SL) has become a widely used strategy to enhance model performance,particularly in data-limited scenarios. However, this approach introduces atrade-off between computation and performance: while SSL helps withrepresentation learning, it requires a separate, often time-consuming trainingphase, increasing computational overhead and limiting efficiency inresource-constrained settings. To address these challenges, we proposeMixTraining, a novel framework that interleaves several SSL and SL epochswithin a unified mixtraining training phase, featuring a smooth transitionbetween two learning objectives. MixTraining enhances synergy between SSL andSL for improved accuracy and consolidates shared computation steps to reducecomputation overhead. MixTraining is versatile and applicable to bothsingle-task and multi-task learning scenarios. Extensive experimentsdemonstrate that MixTraining offers a superior compute-performance trade-offcompared to conventional pipelines, achieving an 8.81% absolute accuracy gain(18.89% relative accuracy gain) on the TinyImageNet dataset while acceleratingtraining by up to 1.29x  with the ViT-Tiny model.</description>
      <author>example@mail.com (Zexin Li, Jiancheng Zhang, Yinglun Zhu, Cong Liu)</author>
      <guid isPermaLink="false">2502.19513v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Dictionary-based Framework for Interpretable and Consistent Object Parsing</title>
      <link>http://arxiv.org/abs/2502.19540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CoCal是一种基于字典式掩码变换器的可解释且一致的对象解析框架，它重新思考了现有的聚类基掩码变换器架构。&lt;h4&gt;背景&lt;/h4&gt;当前的对象分割方法通常依赖于将图像划分为多个部分并为每个部分分配一个特定的语义类别。然而，这种方法在保持不同对象间的一致性和逻辑关系方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架CoCal，以提高对象解析的质量和一致性，并增强对逻辑关系的理解。&lt;h4&gt;方法&lt;/h4&gt;CoCal采用了一种基于字典组件的方法，每个组件都与特定的语义类别相关联。通过引入层次化的字典组件结构，以及在同级内的对比成分和跨级别的逻辑约束，CoCal能够实现更精确的对象解析。&lt;h4&gt;主要发现&lt;/h4&gt;CoCal通过引入一种逐部件对比算法和跨级别对比学习目标，在PartImageNet和Pascal-Part-108数据集上实现了新的最佳性能。此外，它在对象级度量标准方面也有显著改进。&lt;h4&gt;结论&lt;/h4&gt;与先前的方法相比，CoCal提供了更准确的分割结果，并且能够更好地保持不同对象之间的逻辑关系。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们提出了一种基于字典式掩码变换器的可解释和一致的对象解析框架——CoCal。该框架围绕对比成分和逻辑约束设计，重新思考了现有的聚类基掩码变换器架构。具体而言，CoCal利用一组字典组件，每个组件都与特定的语义类别明确相关联。为推进这一概念，CoCal引入了一个层次化的字典组件结构，通过整合同级别内的对比成分和跨级别的逻辑约束来实现这一点。具体来说，CoCal在每一级上采用逐部件对比算法，使同一类别的字典组件与其不同类别的字典组件进行比较。此外，为了处理逻辑问题，CoCal确保表示特定部分的字典组件比其他对象更接近于相应的物体组件。为进一步增强逻辑关系建模，我们实现了一种后处理函数，该函数基于一个原理：分配给某个部分的像素也应该分配给其对应的对象。通过这些创新，CoCal在PartImageNet和Pascal-Part-108上建立了新的最佳性能，在部分mIoU方面分别比先前方法高出2.08%和0.70%，并且在整个质量的对象分割上也有显著改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we present CoCal, an interpretable and consistent objectparsing framework based on dictionary-based mask transformer. Designed aroundContrastive Components and Logical Constraints, CoCal rethinks existingcluster-based mask transformer architectures used in segmentation;Specifically, CoCal utilizes a set of dictionary components, with eachcomponent being explicitly linked to a specific semantic class. To advance thisconcept, CoCal introduces a hierarchical formulation of dictionary componentsthat aligns with the semantic hierarchy. This is achieved through theintegration of both within-level contrastive components and cross-level logicalconstraints. Concretely, CoCal employs a component-wise contrastive algorithmat each semantic level, enabling the contrasting of dictionary componentswithin the same class against those from different classes. Furthermore, CoCaladdresses logical concerns by ensuring that the dictionary componentrepresenting a particular part is closer to its corresponding object componentthan to those of other objects through a cross-level contrastive learningobjective. To further enhance our logical relation modeling, we implement apost-processing function inspired by the principle that a pixel assigned to apart should also be assigned to its corresponding object. With theseinnovations, CoCal establishes a new state-of-the-art performance on bothPartImageNet and Pascal-Part-108, outperforming previous methods by asignificant margin of 2.08% and 0.70% in part mIoU, respectively. Moreover,CoCal exhibits notable enhancements in object-level metrics across thesebenchmarks, highlighting its capacity to not only refine parsing at a finerlevel but also elevate the overall quality of object segmentation.</description>
      <author>example@mail.com (Tiezheng Zhang, Qihang Yu, Alan Yuille, Ju He)</author>
      <guid isPermaLink="false">2502.19540v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Tell me why: Visual foundation models as self-explainable classifiers</title>
      <link>http://arxiv.org/abs/2502.19577v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;视觉基础模型（VFMs）由于其先进的性能而越来越受欢迎。然而，可解释性对于关键应用仍然至关重要。&lt;h4&gt;背景&lt;/h4&gt;视觉基础模型在许多任务中表现出色，但它们的决策过程往往缺乏透明度和理解力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型自解释模型(SEM)，旨在提供能够分解预测为一系列可解释概念加权和的分类器。&lt;h4&gt;方法&lt;/h4&gt;结合了VFM与原型架构及专门训练目标。通过在冻结状态下的VFMs之上仅微调一个轻量级头（约1百万参数），实现了一种高效且可解释性的解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;评估显示该方法能实现竞争性的分类性能，同时在一系列文献衍生出的可解释性指标上超越现有模型。&lt;h4&gt;结论&lt;/h4&gt;研究提出的方法ProtoFM提供了高效的、可解释的视觉基础模型框架，并展示了其在实际应用中的潜力和效果。&lt;h4&gt;翻译&lt;/h4&gt;视觉基础模型（VFMs）因其卓越的表现而变得越来越流行。然而，在关键的应用场景中，依然需要重视可解释性问题。因此，自解释模型(SEM)试图提供一种分解预测为一系列可解释概念加权和的分类器形式。尽管这些模型显示出潜力，但最近的研究表明它们所提供的解释往往缺乏忠实度。为此，本工作将视觉基础模型与新颖的原型架构结合，并采用专门训练目标进行优化。通过仅在冻结状态下的VFMs之上微调一个轻量级头（约1百万参数），研究提出的方法(ProtoFM)提供了一种高效的、可解释性的解决方案。评估结果表明该方法能够实现竞争性分类性能，同时在一系列从文献中衍生出的可解释性指标上超越现有模型。相关代码可在https://github.com/hturbe/proto-fm获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual foundation models (VFMs) have become increasingly popular due to theirstate-of-the-art performance. However, interpretability remains crucial forcritical applications. In this sense, self-explainable models (SEM) aim toprovide interpretable classifiers that decompose predictions into a weightedsum of interpretable concepts. Despite their promise, recent studies have shownthat these explanations often lack faithfulness. In this work, we combine VFMswith a novel prototypical architecture and specialized training objectives. Bytraining only a lightweight head (approximately 1M parameters) on top of frozenVFMs, our approach (ProtoFM) offers an efficient and interpretable solution.Evaluations demonstrate that our approach achieves competitive classificationperformance while outperforming existing models across a range ofinterpretability metrics derived from the literature. Code is available athttps://github.com/hturbe/proto-fm.</description>
      <author>example@mail.com (Hugues Turbé, Mina Bjelogrlic, Gianmarco Mengaldo, Christian Lovis)</author>
      <guid isPermaLink="false">2502.19577v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>ProxyTransformation: Preshaping Point Cloud Manifold With Proxy Attention For 3D Visual Grounding</title>
      <link>http://arxiv.org/abs/2502.19247v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 3 figures. Accepted by CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Proxy Transformation的方法，该方法适用于多模态任务，并可以有效地改善点云的流形结构。这种方法利用了Deformable Point Clustering来识别目标区域中的点云子流形，然后提出了一个使用多模式代理指导点云变换的Proxy Attention模块。&lt;h4&gt;背景&lt;/h4&gt;以语言指令为基础与3D环境实时交互是具身智能的基础任务之一。然而，从RGB-D图像渲染出来的点云包含了大量冗余的背景数据和固有的噪声，这些都可能干扰目标区域的真实结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来改善点云流形结构以适应实时任务的需求。&lt;h4&gt;方法&lt;/h4&gt;该方法首先利用Deformable Point Clustering技术识别出点云子流形，接着使用Proxy Attention模块以及通过文本信息全局指导不同子流形的转换向量优化目标区域的相对空间关系。同时，图像信息引导每个子流形内的线性变换，以细化目标区域的本地点云流形。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在容易的目标上比现有所有方法提高了7.49%，在困难的目标上提高了4.60%；同时还减少了注意力块的计算开销达40.6%。&lt;h4&gt;结论&lt;/h4&gt;这种方法确立了新的SOTA（State of the Art）结果，在以自我为中心的3D视觉定位中展示了其有效性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;具身智能要求代理能够根据语言指令实时地与三维环境进行交互。在这一领域的一个基础任务是自我中心的3D视觉定位，然而，从RGB-D图像渲染出来的点云保留了大量的冗余背景数据和固有的噪声，这些都可能干扰目标区域的真实结构。现有的点云增强方法通常需要繁琐的过程来改进流形结构，并且不适合实时任务。我们提出了一种适用于多模态任务的Proxy Transformation方法，可以有效地改善点云流形结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied intelligence requires agents to interact with 3D environments inreal time based on language instructions. A foundational task in this domain isego-centric 3D visual grounding. However, the point clouds rendered from RGB-Dimages retain a large amount of redundant background data and inherent noise,both of which can interfere with the manifold structure of the target regions.Existing point cloud enhancement methods often require a tedious process toimprove the manifold, which is not suitable for real-time tasks. We proposeProxy Transformation suitable for multimodal task to efficiently improve thepoint cloud manifold. Our method first leverages Deformable Point Clustering toidentify the point cloud sub-manifolds in target regions. Then, we propose aProxy Attention module that utilizes multimodal proxies to guide point cloudtransformation. Built upon Proxy Attention, we design a submanifoldtransformation generation module where textual information globally guidestranslation vectors for different submanifolds, optimizing relative spatialrelationships of target regions. Simultaneously, image information guideslinear transformations within each submanifold, refining the local point cloudmanifold of target regions. Extensive experiments demonstrate that ProxyTransformation significantly outperforms all existing methods, achieving animpressive improvement of 7.49% on easy targets and 4.60% on hard targets,while reducing the computational overhead of attention blocks by 40.6%. Theseresults establish a new SOTA in ego-centric 3D visual grounding, showcasing theeffectiveness and robustness of our approach.</description>
      <author>example@mail.com (Qihang Peng, Henry Zheng, Gao Huang)</author>
      <guid isPermaLink="false">2502.19247v2</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>TRIX: A More Expressive Model for Zero-shot Domain Transfer in Knowledge Graphs</title>
      <link>http://arxiv.org/abs/2502.19512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;全归纳知识图谱模型可以在多个领域上进行训练，并随后在新的未见领域中执行零样本知识图谱补全(KGC)，这是朝着构建知识图谱基础模型的目标迈进的重要一步。&lt;h4&gt;目的&lt;/h4&gt;介绍一种更富有表现力和能力的全归纳模型TRIX，该模型不仅提供了比现有最佳方法更具表达性的三元组嵌入（头实体、关系、尾实体），还引入了一种新的能力：直接处理归纳设置下的实体和关系预测任务。&lt;h4&gt;方法&lt;/h4&gt;TRIX通过改进的三元组表示方式提高了零样本场景下的性能，同时可以直接应对新领域中的实体与关系预测任务，并且其表现优于现有的全归纳模型以及大上下文语言模型在未见领域的预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，TRIX在新的域中以零样本的方式进行实体和关系预测方面优于现有最佳的全归纳模型；同时，在超出训练集范围的领域预测任务上也表现出比大型上下文LLM更好的性能。&lt;h4&gt;结论&lt;/h4&gt;TRIX展示出了强大的零样本泛化能力以及应对新领域挑战的实力，对于构建通用知识图谱基础模型具有重要意义。源代码可以在GitHub上找到：https://github.com/yuchengz99/TRIX。&lt;h4&gt;翻译&lt;/h4&gt;完全归纳的知识图谱模型可以针对多个领域进行训练，并在新的未见领域中执行零样本知识图谱补全任务，这是向构建知识图谱基础模型迈进的重要一步。在这项工作中，我们引入了一种更为表达力强且能力全面的TRIX模型，它不仅提供了比现有最佳方法更强大的三元组嵌入（头实体、关系、尾实体），而且还引入了一种新的功能：直接处理归纳设置下的实体和关系预测任务。经验上表明，TRIX在新领域中的零样本实体与关系预测中优于现有的全归纳模型，并且在超出训练范围的领域预测中也超过了大型上下文LLM。源代码可从https://github.com/yuchengz99/TRIX获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fully inductive knowledge graph models can be trained on multiple domains andsubsequently perform zero-shot knowledge graph completion (KGC) in new unseendomains. This is an important capability towards the goal of having foundationmodels for knowledge graphs. In this work, we introduce a more expressive andcapable fully inductive model, dubbed TRIX, which not only yields strictly moreexpressive triplet embeddings (head entity, relation, tail entity) compared tostate-of-the-art methods, but also introduces a new capability: directlyhandling both entity and relation prediction tasks in inductive settings.Empirically, we show that TRIX outperforms the state-of-the-art fully inductivemodels in zero-shot entity and relation predictions in new domains, andoutperforms large-context LLMs in out-of-domain predictions. The source code isavailable at https://github.com/yuchengz99/TRIX.</description>
      <author>example@mail.com (Yucheng Zhang, Beatrice Bevilacqua, Mikhail Galkin, Bruno Ribeiro)</author>
      <guid isPermaLink="false">2502.19512v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>SPU-IMR: Self-supervised Arbitrary-scale Point Cloud Upsampling via Iterative Mask-recovery Network</title>
      <link>http://arxiv.org/abs/2502.19452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的点云上采样方法，该方法将点云上采样视为全局形状补全问题。通过设计的神经网络迭代地完成缺失部分，以获得稠密且均匀分布的点集。&lt;h4&gt;背景&lt;/h4&gt;现有的点云上采样方法通常将其视为插值问题，通过在局部或特征空间中进行插值来实现上采样。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的全局形状补全算法来解决点云上采样的问题，并展示其优于现有自监督和有监督方法的性能。&lt;h4&gt;方法&lt;/h4&gt;首先将点云划分成多个块，然后通过掩码操作移除一些块，留下可见的点云块。使用设计好的神经网络迭代地完成缺失部分，直至恢复所有补全后的块。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在量化和定性实验中展示了优越性能，优于现有的自监督和有监督方法。&lt;h4&gt;结论&lt;/h4&gt;通过将点云上采样视为全局形状补全问题，本文设计的算法能够生成稠密且均匀分布的点集，并显示出良好的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud upsampling aims to generate dense and uniformly distributed pointsets from sparse point clouds. Existing point cloud upsampling methodstypically approach the task as an interpolation problem. They achieveupsampling by performing local interpolation between point clouds or in thefeature space, then regressing the interpolated points to appropriatepositions. By contrast, our proposed method treats point cloud upsampling as aglobal shape completion problem. Specifically, our method first divides thepoint cloud into multiple patches. Then, a masking operation is applied toremove some patches, leaving visible point cloud patches. Finally, ourcustom-designed neural network iterative completes the missing sections of thepoint cloud through the visible parts. During testing, by selecting differentmask sequences, we can restore various complete patches. A sufficiently denseupsampled point cloud can be obtained by merging all the completed patches. Wedemonstrate the superior performance of our method through both quantitativeand qualitative experiments, showing overall superiority against both existingself-supervised and supervised methods.</description>
      <author>example@mail.com (Ziming Nie, Qiao Wu, Chenlei Lv, Siwen Quan, Zhaoshuai Qi, Muze Wang, Jiaqi Yang)</author>
      <guid isPermaLink="false">2502.19452v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Robust Prediction of Frictional Contact Network in Near-Jamming Suspensions Employing Deep Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.18743v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了悬浮液中细颗粒的分散行为，特别是在接近堵塞状态时的行为。通过引入一种成本效益高的机器学习方法（基于图神经网络GNN）来预测摩擦接触网FCN，该方法能够捕捉密集悬浮液中的隐藏特征和底层模式。&lt;h4&gt;背景&lt;/h4&gt;细小颗粒在牛顿流体中形成悬浊液的粘度会在接近堵塞密度时发散。这种宏观行为受微结构影响，尤其是由机械承载力接触点组成的摩擦接触网（FCN）的影响。应力传递和网络拓扑对颗粒相对运动的约束敏感。&lt;h4&gt;目的&lt;/h4&gt;预测接近堵塞条件下的摩擦接触网FCN仍然是一个挑战。为了应对这一问题，本研究引入了一种新的机器学习方法来解决这个问题。&lt;h4&gt;方法&lt;/h4&gt;使用一种称为Deep Graph Convolutional Network（DeepGCN）的GNN变体在数据驱动模拟上进行训练，并证明了该模型具有强大的泛化和外推能力。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，这种方法能够准确预测处于分异流动参数和相空间中的系统的FCNs。此外，研究涵盖了从半稀释状态到堵塞状态的整个范围，并系统地变化诸如剪切应力、颗粒填充率以及滑动摩擦力和滚动摩擦力等参数。&lt;h4&gt;结论&lt;/h4&gt;这项工作的结果为预测颗粒体系性质提供了创新且可转移的技术途径，为材料科学及相关领域开辟了新的前进道路。&lt;h4&gt;翻译&lt;/h4&gt;悬浮液中细小颗粒分散在牛顿流体中的粘度接近堵塞密度时发散。微结构中的接触微观结构通过摩擦接触网（FCN）控制这种宏观行为。该网络由机械承载力接触点组成，这些接触点导致在接近堵塞过渡时刚性的出现。应力传递和网络拓扑对颗粒相对运动的约束敏感。尽管其重要性，由于实验和计算障碍，预测FCN尤其是在接近堵塞条件下仍然是一个挑战。本研究提出了使用图神经网络（GNN）预测FCN的一种成本效益高的机器学习方法，该方法通过映射粒子间相互作用来固有地捕捉密集悬浮液中的隐藏特征和潜在模式。利用一种称为Deep Graph Convolutional Network (DeepGCN)的GNN变体在数据驱动模拟上进行训练，本研究展示了强大的泛化能力和外推能力，在分异流动参数和相空间中准确预测FCNs，尽管每个条件仅单独受训。该研究涵盖了广泛的相空间范围，从半稀释状态到堵塞状态，并跨越瞬态和稳态，同时系统地变化诸如剪切应力、颗粒填充率以及滑动摩擦力和滚动摩擦力等参数。这项研究的结果为预测颗粒体系性质提供了创新且可转移的技术途径，为材料科学及相关领域开辟了新的前进道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The viscosity of the suspension consisting of fine particles dispersed in aNewtonian liquid diverges close to the jamming packing fraction. The contactmicrostructure in suspensions governs this macroscopic behavior in the vicinityof jamming through a frictional contact network (FCN). FCN is composed ofmechanical load-bearing contacts that lead to the emergence of rigidity nearthe jamming transition. The stress transmission and network topology, in turn,depend sensitively on constraints on the relative motion of the particles.Despite their significance, predicting the FCN, especially close to jammingconditions, remains challenging due to experimental and computationalimpediments. This study introduces a cost-effective machine learning approachto predict the FCN using a graph neural network (GNN), which inherentlycaptures hidden features and underlying patterns in dense suspension by mappinginterparticle interactions. Employing a variation of GNN called the Deep GraphConvolutional Network (DeepGCN) trained on data-driven simulations, this studydemonstrates robust generalization and extrapolation capabilities, accuratelypredicting FCNs in systems with divergent flow parameters and phase spaces,despite each being trained exclusively on a single condition. The study coversa wide range of phase space, from semi-dilute to jammed states, spanningtransient to steady states, while systematically varying parameters such asshear stress (${\sigma}_{xy}$), packing fraction(${\phi}$) and sliding androlling friction (${{\mu}_s, {\mu}_r}$). The results of this research pave theway for innovative transferable techniques in predicting the properties ofparticulate systems, offering new avenues for advancement in material scienceand related fields.</description>
      <author>example@mail.com (Armin Aminimajd, Joao Maia, Abhinendra Singh)</author>
      <guid isPermaLink="false">2502.18743v2</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Foundation-Model-Based Industrial Defect Detection</title>
      <link>http://arxiv.org/abs/2502.19106v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;随着工业产品种类的增多和复杂度提高，视觉工业缺陷检测受到了广泛的关注。传统的研究方法依赖于统计分析、异常数据合成建模以及基于生成模型的方法来分离产品的缺陷特征并完成缺陷检测任务。&lt;h4&gt;背景&lt;/h4&gt;近年来，基础模型（Foundation Model, FM）的出现带来了丰富的视觉和文本语义先验知识。&lt;h4&gt;目的&lt;/h4&gt;探讨基于基础模型与非基础模型方法在工业产品缺陷检测领域的应用及优劣，并分析未来研究方向。&lt;h4&gt;方法&lt;/h4&gt;本论文系统地对各种基于基础模型的方法进行了比较、分类和讨论，同时简要回顾了近期发布的部分非基础模型（NFM）方法。详细分析了FM和NFM之间从训练目标到性能表现的差异，指出了可能的研究前景。&lt;h4&gt;主要发现&lt;/h4&gt;相比非基础模型方法，基础模型方法更适用于少量样本学习乃至零样本学习，在实际工业应用场景中更为契合，并值得深入研究。&lt;h4&gt;结论&lt;/h4&gt;虽然基于基础模型的方法提高了缺陷检测准确性，但同时也增加了模型复杂性和推理速度的降低。一些基于基础模型的方法开始探索轻量化建模方式，逐渐吸引人们的注意并值得系统化分析。&lt;h4&gt;翻译&lt;/h4&gt;随着工业产品变得丰富和精细，视觉工业缺陷检测（包括二维和三维视觉特征建模）受到了广泛的关注。传统的研究方法利用统计分析、异常数据合成建模以及基于生成模型的方法来分离产品的缺陷特征，并完成缺陷检测任务。近年来，基础模型的出现带来了丰富的视觉和文本语义先验知识，许多基于此的研究旨在提高检测准确性但同时增加了模型复杂性和推理速度下降的问题。一些基于基础模型方法已经开始探索轻量级建模方式，逐渐引起了人们的关注并值得系统化分析。本论文系统地对各种基于基础模型的方法进行了比较、分类和讨论，并简要回顾了近期发布的部分非基础模型（NFM）方法；此外还从训练目标、模型结构与规模以及性能表现等角度详细对比了FM与NFM之间的差异，指出了未来可能的研究方向。通过对比研究发现，基于基础模型的方法更适合少量样本学习乃至零样本学习，这些更符合实际工业应用场景，并值得深入探索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As industrial products become abundant and sophisticated, visual industrialdefect detection receives much attention, including two-dimensional andthree-dimensional visual feature modeling. Traditional methods use statisticalanalysis, abnormal data synthesis modeling, and generation-based models toseparate product defect features and complete defect detection. Recently, theemergence of foundation models has brought visual and textual semantic priorknowledge. Many methods are based on foundation models (FM) to improve theaccuracy of detection, but at the same time, increase model complexity and slowdown inference speed. Some FM-based methods have begun to explore lightweightmodeling ways, which have gradually attracted attention and deserve to besystematically analyzed. In this paper, we conduct a systematic survey withcomparisons and discussions of foundation model methods from different aspectsand briefly review non-foundation model (NFM) methods recently published.Furthermore, we discuss the differences between FM and NFM methods fromtraining objectives, model structure and scale, model performance, andpotential directions for future exploration. Through comparison, we find FMmethods are more suitable for few-shot and zero-shot learning, which are morein line with actual industrial application scenarios and worthy of in-depthresearch.</description>
      <author>example@mail.com (Tianle Yang, Luyao Chang, Jiadong Yan, Juntao Li, Zhi Wang, Ke Zhang)</author>
      <guid isPermaLink="false">2502.19106v2</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>UniGS: Unified Language-Image-3D Pretraining with Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2502.17860v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025; Corrected citation of Uni3D;&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了UniGS，一种将3D高斯散射技术与多模态预训练结合的方法，旨在提升对三维世界的表达能力。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态预训练方法虽然在学习文本、图像和点云的联合表示方面取得了进展，但使用离散点作为三维表示无法充分捕捉三维世界中的细微差别，并且存在二维像素与三维点之间的明显差距。&lt;h4&gt;目的&lt;/h4&gt;引入3D高斯散射技术来增强多模态预训练模型对三维世界的表达能力，同时提升跨模态对齐效果。&lt;h4&gt;方法&lt;/h4&gt;UniGS首先使用基于3D高斯散射的表示形式建模三维世界，并通过一个共享视觉和文本空间的语言-图像预训练模型建立语言、图像和点云之间的联系。接着，它利用一个三维编码器将优化后的3D高斯散射与语言-图像表示对齐以学习统一的多模态表示。&lt;h4&gt;主要发现&lt;/h4&gt;在Objaverse、ABO、MVImgNet 和 SUN RGBD 数据集上的零样本分类、文本驱动检索和开放世界理解任务中，UniGS展示了比现有SOTA模型（如Uni3D）更优越的表现。具体而言，在不同三维任务上取得了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;通过引入3D高斯散射技术及Gaussian-Aware Guidance模块，UniGS能够学习到更通用且对齐更好的多模态表示。&lt;h4&gt;翻译&lt;/h4&gt;最近在多模式3D预训练方法方面取得的进步显示出在文本、图像和点云联合表示学习方面的显著有效性。然而，采用点云作为三维表达无法充分捕捉三维世界的细微差别，并且存在二维像素与三维点之间的明显差距。为解决这一问题，我们提出UniGS，在多模态预训练中整合3D高斯散射技术以增强三维表示。我们首先利用基于3D高斯散射的表示形式建模整个三维世界为带有颜色和不透明度的一系列3D高斯分布，并通过广泛的现实图像-文本对，依靠语言模型建立共享视觉和文本空间。随后，UniGS使用一个3D编码器将优化后的3D高斯散射与语言-图像表示对齐以学习统一的多模态表示。为促进3D编码器提取全局显式三维特征并实现更好的跨模式对齐，我们进一步引入了一个新颖的Gaussian-Aware Guidance模块来指导3D领域的细粒度表示的学习过程。在Objaverse、ABO、MVImgNet 和 SUN RGBD 数据集上的零样本分类、文本驱动检索和开放世界理解任务中，通过广泛实验展示了UniGS学习更通用且更强对齐多模态表征的有效性，并在不同三维任务上取得显著优于现有最佳方法（如Uni3D）的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in multi-modal 3D pre-training methods have shownpromising efficacy in learning joint representations of text, images, and pointclouds. However, adopting point clouds as 3D representation fails to fullycapture the intricacies of the 3D world and exhibits a noticeable gap betweenthe discrete points and the dense 2D pixels of images. To tackle this issue, wepropose UniGS, integrating 3D Gaussian Splatting (3DGS) into multi-modalpre-training to enhance the 3D representation. We first rely on the 3DGSrepresentation to model the 3D world as a collection of 3D Gaussians with colorand opacity, incorporating all the information of the 3D scene whileestablishing a strong connection with 2D images. Then, to achieveLanguage-Image-3D pertaining, UniGS starts with a pre-trained vision-languagemodel to establish a shared visual and textual space through extensivereal-world image-text pairs. Subsequently, UniGS employs a 3D encoder to alignthe optimized 3DGS with the Language-Image representations to learn unifiedmulti-modal representations. To facilitate the extraction of global explicit 3Dfeatures by the 3D encoder and achieve better cross-modal alignment, weadditionally introduce a novel Gaussian-Aware Guidance module that guides thelearning of fine-grained representations of the 3D domain. Through extensiveexperiments across the Objaverse, ABO, MVImgNet and SUN RGBD datasets withzero-shot classification, text-driven retrieval and open-world understandingtasks, we demonstrate the effectiveness of UniGS in learning a more general andstronger aligned multi-modal representation. Specifically, UniGS achievesleading results across different 3D tasks with remarkable improvements overprevious SOTA, Uni3D, including on zero-shot classification (+9.36%),text-driven retrieval (+4.3%) and open-world understanding (+7.92%).</description>
      <author>example@mail.com (Haoyuan Li, Yanpeng Zhou, Tao Tang, Jifei Song, Yihan Zeng, Michael Kampffmeyer, Hang Xu, Xiaodan Liang)</author>
      <guid isPermaLink="false">2502.17860v2</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Diagnosing COVID-19 Severity from Chest X-Ray Images Using ViT and CNN Architectures</title>
      <link>http://arxiv.org/abs/2502.16622v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项研究探讨了使用机器学习技术来预测COVID-19患者的病情严重程度，通过整合三个数据源创建了一个大规模的COVID严重性数据库，并评估了迁移学习和视觉变换器在预测病情方面的有效性。&lt;h4&gt;背景&lt;/h4&gt;COVID-19大流行给医疗资源带来了巨大压力，促使人们讨论如何利用机器学习减轻医生负担并辅助诊断。胸部X光片（CXRs）用于诊断COVID-19，但很少有研究从这些影像中预测患者的病情严重程度。&lt;h4&gt;目的&lt;/h4&gt;通过整合多个数据源创建一个大规模的COVID严重性数据库，并评估迁移学习和视觉变换器在病情严重度分类与回归任务中的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用预训练模型（如基于ImageNet和CXRs）及视觉变换器（ViTs）进行迁移学习。其中，采用DenseNet161模型进行了三类预测问题的试验，并评估了其分类准确性和视觉变换器在病情严重度回归任务中的性能。&lt;h4&gt;主要发现&lt;/h4&gt;预训练的DenseNet161模型在三个类别上达到了最高的整体准确性（80%）；而ViT则在病情严重度回归中表现最好，平均绝对误差为0.5676，接近放射科医生预测的结果。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，在COVID-19病情预测方面，迁移学习和视觉变换器显示出潜力。预训练的DenseNet161模型对三分类问题表现出最佳性能；ViT在回归任务中表现优异。该项目的源代码是公开可用的。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/stwhitfield/covid-severity&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The COVID-19 pandemic strained healthcare resources and prompted discussionabout how machine learning can alleviate physician burdens and contribute todiagnosis. Chest x-rays (CXRs) are used for diagnosis of COVID-19, but fewstudies predict the severity of a patient's condition from CXRs. In this study,we produce a large COVID severity dataset by merging three sources andinvestigate the efficacy of transfer learning using ImageNet- andCXR-pretrained models and vision transformers (ViTs) in both severityregression and classification tasks. A pretrained DenseNet161 model performedthe best on the three class severity prediction problem, reaching 80% accuracyoverall and 77.3%, 83.9%, and 70% on mild, moderate and severe cases,respectively. The ViT had the best regression results, with a mean absoluteerror of 0.5676 compared to radiologist-predicted severity scores. Theproject's source code is publicly available.</description>
      <author>example@mail.com (Luis Lara, Lucia Eve Berger, Rajesh Raju)</author>
      <guid isPermaLink="false">2502.16622v2</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Multispectral to Hyperspectral using Pretrained Foundational model</title>
      <link>http://arxiv.org/abs/2502.19451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种结合高光谱和多光谱成像系统优势的方法，以改善温室气体监测。&lt;h4&gt;背景&lt;/h4&gt;高光谱成像提供了详细的光谱信息，对监测如CH4和NO2等温室气体具有重要意义。但是其应用受到空间覆盖率低和重复访问频率不高的限制。相比之下，多光谱成像能提供更广的空间和时间覆盖范围，但缺乏精细的光谱分辨率以进行精确的温室气体检测。&lt;h4&gt;目的&lt;/h4&gt;为了解决高光谱和多光谱成像技术之间的局限性问题，该研究提出了空间-光谱变换模型来重建从多光谱输入的数据。&lt;h4&gt;方法&lt;/h4&gt;研究中提出的模型先是在EnMAP和EMIT数据集上进行预训练，然后分别在（Sentinel-2, EnMAP）和（HLS-S30, EMIT）图像对上微调。&lt;h4&gt;主要发现&lt;/h4&gt;通过将高光谱成像的精细光谱分辨率与多光谱成像的空间覆盖范围和时间频率相结合，可以提高大气监测的效率。&lt;h4&gt;结论&lt;/h4&gt;这项研究证明了结合使用高光谱和多光谱数据的有效性，并展示了利用这些技术改善温室气体检测方法的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：高光谱成像提供了详细的光谱信息，为CH4和NO2等温室气体的监测提供重要意义。然而，其应用受到空间覆盖率低和重复访问频率不高的限制。相比之下，多光谱成像能提供更广的空间和时间覆盖范围，但缺乏精细的光谱分辨率以进行精确的温室气体检测。为了应对这些挑战，本研究提出了空间-光谱变换模型来从多光谱输入中重建高光谱数据。本文中的模型先是在EnMAP和EMIT数据集上预训练，并在（Sentinel-2, EnMAP）和（HLS-S30, EMIT）图像对上微调。我们的模型结合了高光谱和多光谱成像系统的优点，有潜力提升大气监测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperspectral imaging provides detailed spectral information, offeringsignificant potential for monitoring greenhouse gases like CH4 and NO2.However, its application is constrained by limited spatial coverage andinfrequent revisit times. In contrast, multispectral imaging delivers broaderspatial and temporal coverage but lacks the spectral granularity required forprecise GHG detection. To address these challenges, this study proposesSpectral and Spatial-Spectral transformer models that reconstruct hyperspectraldata from multispectral inputs. The models in this paper are pretrained onEnMAP and EMIT datasets and fine-tuned on spatio-temporally aligned(Sentinel-2, EnMAP) and (HLS-S30, EMIT) image pairs respectively. Our model hasthe potential to enhance atmospheric monitoring by combining the strengths ofhyperspectral and multispectral imaging systems.</description>
      <author>example@mail.com (Ruben Gonzalez, Conrad M Albrecht, Nassim Ait Ali Braham, Devyani Lambhate, Joao Lucas de Sousa Almeida, Paolo Fraccaro, Benedikt Blumenstiel, Thomas Brunschwiler, Ranjini Bangalore)</author>
      <guid isPermaLink="false">2502.19451v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Sustainable Greenhouse Management: A Comparative Analysis of Recurrent and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.17371v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了将光伏系统集成到温室中的效果，同时引入了一种新的时空图神经网络（STGNN）应用于温室微气候建模。&lt;h4&gt;背景&lt;/h4&gt;光伏系统的集成可以优化土地使用，并通过实现食品生产和可再生能源发电的双重效益来增强可持续农业实践。但是，准确预测内部环境条件对于确保作物生长的最佳状态和最大限度地提高能源生产至关重要。&lt;h4&gt;目的&lt;/h4&gt;引入一种新的时空图神经网络（STGNN）模型应用于温室微气候建模，并与传统的递归神经网络（RNN）进行性能比较。&lt;h4&gt;方法&lt;/h4&gt;研究利用在希腊沃洛斯收集的每15分钟一次的高频数据，展示了传统递归神经网络（RNNs）在冬季条件下的卓越准确度，但对夏季冷却系统操作时的表现有限。尽管STGNN模型当前表现较低，但它能够更好地整合包括光伏发电量和作物生长指标在内的额外变量。&lt;h4&gt;主要发现&lt;/h4&gt;传统的RNN模型擅长时间序列模式识别，但在处理环境变量之间的方向关系方面存在局限性；而新的STGNN架构可以解决这些问题，并且能够捕捉空间依赖性和它们的方向性。&lt;h4&gt;结论&lt;/h4&gt;虽然当前STGNN的表现略低于RNN（冬季R^2为0.947相比RNN的0.985），但其模型结构具有更大的潜力来整合更多变量，从而更好地适应和优化温室环境条件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of photovoltaic (PV) systems into greenhouses not onlyoptimizes land use but also enhances sustainable agricultural practices byenabling dual benefits of food production and renewable energy generation.However, accurate prediction of internal environmental conditions is crucial toensure optimal crop growth while maximizing energy production. This studyintroduces a novel application of Spatio-Temporal Graph Neural Networks(STGNNs) to greenhouse microclimate modeling, comparing their performance withtraditional Recurrent Neural Networks (RNNs). While RNNs excel at temporalpattern recognition, they cannot explicitly model the directional relationshipsbetween environmental variables. Our STGNN approach addresses this limitationby representing these relationships as directed graphs, enabling the model tocapture both spatial dependencies and their directionality. Usinghigh-frequency data collected at 15-minute intervals from a greenhouse inVolos, Greece, we demonstrate that RNNs achieve exceptional accuracy in winterconditions (R^2 = 0.985) but show limitations during summer cooling systemoperation. Though STGNNs currently show lower performance (winter R^2 = 0.947),their architecture offers greater potential for integrating additionalvariables such as PV generation and crop growth indicators.</description>
      <author>example@mail.com (Emiliano Seri, Marcello Petitta, Cristina Cornaro)</author>
      <guid isPermaLink="false">2502.17371v2</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Evolutionary Algorithms Approach For Search Based On Semantic Document Similarity</title>
      <link>http://arxiv.org/abs/2502.19437v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;云计算和分布式计算的发展促进了计算机科学领域的研究活动。这些领域在神经网络、遗传算法等进化计算算法方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;利用通用句子编码器(USE)捕捉文本语义相似性，并使用迁移学习技术将遗传算法(GA)和差分演化(DE)应用于基于用户查询检索相关文档的搜索与检索。&lt;h4&gt;方法&lt;/h4&gt;在斯坦福问答数据集(SQuAD)上应用所提出的方法，以识别用户查询。研究中采用曼哈顿距离、GA和DE算法进行对比实验。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明：文本可以通过USE高效地表示为句子嵌入向量；进化算法（如GA和DE）在查找顶级N结果方面比传统排名方法更有效。&lt;h4&gt;结论&lt;/h4&gt;使用进化计算算法来搜索和检索文档是一个有潜力的研究领域，它可以在各种应用中实现更好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3617733.3617753&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in cloud computing and distributed computing have fosteredresearch activities in Computer science. As a result, researchers have madesignificant progress in Neural Networks, Evolutionary Computing Algorithms likeGenetic, and Differential evolution algorithms. These algorithms are used todevelop clustering, recommendation, and question-and-answering systems usingvarious text representation and similarity measurement techniques. In thisresearch paper, Universal Sentence Encoder (USE) is used to capture thesemantic similarity of text; And the transfer learning technique is used toapply Genetic Algorithm (GA) and Differential Evolution (DE) algorithms tosearch and retrieve relevant top N documents based on user query. The proposedapproach is applied to the Stanford Question and Answer (SQuAD) Dataset toidentify a user query. Finally, through experiments, we prove that textdocuments can be efficiently represented as sentence embedding vectors usingUSE to capture the semantic similarity, and by comparing the results of theManhattan Distance, GA, and DE algorithms we prove that the evolutionaryalgorithms are good at finding the top N results than the traditional rankingapproach.</description>
      <author>example@mail.com (Chandrashekar Muniyappa, Eujin Kim)</author>
      <guid isPermaLink="false">2502.19437v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Agnostic calculation of atomic free energies with the descriptor density of states</title>
      <link>http://arxiv.org/abs/2502.18191v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的评估原子系统振动自由能的方法，该方法不需要预先指定原子间势，并且能够通过描述符的高维密度熵进行准确估算。&lt;h4&gt;背景&lt;/h4&gt;传统的计算原子系统的振动自由能需要先验地定义原子间势函数。这种方法限制了模型的灵活性和通用性。&lt;h4&gt;目的&lt;/h4&gt;开发一种与模型无关的方法来评估原子系统在不同条件下的振动自由能，以便于不确定性量化和逆向设计。&lt;h4&gt;方法&lt;/h4&gt;使用描述符（即高维特征向量）表示原子结构，并通过条件分数匹配准确估计这些描述符的密度熵。利用Legendre-Fenchel共轭关系将自由能与描述符熵联系起来，避免了复杂的高维积分计算。&lt;h4&gt;主要发现&lt;/h4&gt;该方法可以快速、精确地预测各种材料在不同相态下的振动自由能，并且通过反向传播技术成功降低了Fe的α-γ转变温度。&lt;h4&gt;结论&lt;/h4&gt;此模型无关的方法不仅能准确评估原子系统的自由能，还能应用于液体和其他基础模型的微调中。它为解决计算科学中的高维积分问题提供了新思路。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的方法来评估没有预先指定原子间势的情况下原子系统振动自由能的新方法。我们的模型无关的方法利用描述符（即原子结构的高维特征向量）进行表示，并通过条件分数匹配准确估计这些描述符的密度熵。通过将原子间势转换为在描述符特性上扩增的形式，我们展示了自由能在描述符熵的Legendre-Fenchel共轭中出现，从而避免了所有高维积分计算。所需的评分匹配活动比固定模型采样需要更少的资源，并且可以高度并行化，将实际时间减少到几分钟以内。我们的模型无关的估计器能够以微秒级的CPU努力在广泛的潜在参数范围内返回可微分自由能预测，这允许快速向前和反向传播潜在变化通过有限温度模拟，这是为了不确定性量化和逆向设计而长期需要的功能。我们通过对W、Mo和Fe的BCC、FCC和A15相态进行热力学集成计算进行了广泛的模型测试，并且在高温同源条件下预测通过了严格的准确性阈值（每原子1-2 meV或0.25至0.5 kcal/mol）用于阶段预测。我们还展示了目标微调，通过对Fe的非磁性机器学习模型使用反向传播技术将其α-γ转变温度从2030 K降低到1063 K，并且无需额外采样。讨论了该方法在液体以及基础模型细调中的应用及其对计算科学中众多估计高维积分问题的潜在影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a new method to evaluate vibrational free energies of atomicsystems without a priori specification of an interatomic potential. Ourmodel-agnostic approach leverages descriptors, high-dimensional feature vectorsof atomic structure. The entropy of a high-dimensional density, the descriptordensity of states, is accurately estimated with conditional score matching.Casting interatomic potentials into a form extensive in descriptor features, weshow free energies emerge as the Legendre-Fenchel conjugate of the descriptorentropy, avoiding all high-dimensional integration. The score matching campaignrequires less resources than fixed-model sampling and is highly parallel,reducing wall time to a few minutes, with tensor compression schemes allowinglightweight storage. Our model-agnostic estimator returns differentiable freeenergy predictions over a broad range of potential parameters in microsecondsof CPU effort, allowing rapid forward and back propagation of potentialvariations through finite temperature simulations, long desired for uncertaintyquantification and inverse design. We test predictions against thermodynamicintegration calculations over a broad range of models for BCC, FCC and A15phases of W, Mo and Fe at high homologous temperatures. Predictions pass thestringent accuracy threshold of 1-2 meV/atom (1/40-1/20 kcal/mol) for phaseprediction with propagated score uncertainties robustly bounding errors. Wealso demonstrate targeted fine-tuning, reducing the alpha-gamma transitiontemperature in a non-magnetic machine learning model of Fe from 2030 K to 1063K through back-propagation, with no additional sampling. Applications toliquids and fine-tuning foundational models are discussed along with the manyproblems in computational science which estimate high-dimensional integrals.</description>
      <author>example@mail.com (Thomas D Swinburne, Clovis Lapointe, Mihai-Cosmin Marinica)</author>
      <guid isPermaLink="false">2502.18191v2</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Graph Transformers: Architectures, Theories and Applications</title>
      <link>http://arxiv.org/abs/2502.16533v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要主题&lt;/h4&gt;Graph Transformers (GTs) 的综合回顾&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在处理图形结构时存在过度平滑和过度压缩等内在局限性，而 Graph Transformers 通过解决这些问题展示出强大的建模能力。&lt;h4&gt;目的&lt;/h4&gt;对最近关于 Graph Transformers 的快速发展进行全面回顾，涵盖架构、理论基础及应用等方面。&lt;h4&gt;方法&lt;/h4&gt;根据处理结构信息的策略分类 Graph Transformers 架构，包括图标记化、位置编码、结构感知注意力和模型集成。从理论上探讨了不同讨论架构下的表达能力，并与其他高级图形学习算法进行对比以发现联系。&lt;h4&gt;主要发现&lt;/h4&gt;Graph Transformers 在分子数据、蛋白质数据、语言处理、视觉识别、交通网络、脑科学及材料学等领域的实际应用中发挥了重要作用。&lt;h4&gt;结论&lt;/h4&gt;指出了当前 Graph Transformers 面临的挑战和未来研究的方向，为潜在的研究提供了可能的道路。&lt;h4&gt;翻译&lt;/h4&gt;Graph Transformer (GTs) 通过解决图神经网络（GNNs）固有的限制问题，在构建图形结构模型方面展现出了强大的能力。最近的研究提议了多样化的架构、增强了可解释性，并探讨了实际应用案例。考虑到这些快速的发展，我们对该领域进行了全面的综述，涵盖了 Graph Transformers 的架构设计、理论依据及其在分子数据、蛋白质数据、语言处理等众多领域的应用实例。此外，还对现有的挑战和未来的研究方向提出了建议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs) have demonstrated a strong capability in modelinggraph structures by addressing the intrinsic limitations of graph neuralnetworks (GNNs), such as over-smoothing and over-squashing. Recent studies haveproposed diverse architectures, enhanced explainability, and practicalapplications for Graph Transformers. In light of these rapid developments, weconduct a comprehensive review of Graph Transformers, covering aspects such astheir architectures, theoretical foundations, and applications within thissurvey. We categorize the architecture of Graph Transformers according to theirstrategies for processing structural information, including graph tokenization,positional encoding, structure-aware attention and model ensemble. Furthermore,from the theoretical perspective, we examine the expressivity of GraphTransformers in various discussed architectures and contrast them with otheradvanced graph learning algorithms to discover the connections. Furthermore, weprovide a summary of the practical applications where Graph Transformers havebeen utilized, such as molecule, protein, language, vision, traffic, brain andmaterial data. At the end of this survey, we will discuss the currentchallenges and prospective directions in Graph Transformers for potentialfuture research.</description>
      <author>example@mail.com (Chaohao Yuan, Kangfei Zhao, Ercan Engin Kuruoglu, Liang Wang, Tingyang Xu, Wenbing Huang, Deli Zhao, Hong Cheng, Yu Rong)</author>
      <guid isPermaLink="false">2502.16533v2</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Voting Scheme to Strengthen Localization Security in Randomly Deployed Wireless Sensor Networks</title>
      <link>http://arxiv.org/abs/2502.20218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文旨在为存在恶意节点的恶劣环境下的目标定位问题提供一个可信解决方案，这些恶意节点能够操纵距离测量数据（即执行欺骗攻击），从而妨碍准确定位。除了定位外，另一个目的是识别参与过程中的哪些节点是恶意的。&lt;h4&gt;背景&lt;/h4&gt;随着物联网和智能城市应用的扩展，依赖准确位置信息的应用面临严重的安全威胁，因为现有的大多数定位系统都容易受到欺骗攻击。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于聚类和加权质心的投票方案，在对抗性环境下安全地解决定位问题并检测恶意节点。&lt;h4&gt;方法&lt;/h4&gt;{'第一阶段': '选择一组合适的兴趣点簇，并利用问题几何学分配票数以定位目标。', '第二阶段': '通过位置估计和基本统计信息来探测攻击者'}&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在不同设置下被评估为具有较高的本地化精度，成功的恶意节点检测率以及较低的计算复杂度。计算机模拟与现实世界实验验证了该方案的有效性，并显示出相比于当前最先进的方法，可以减少30%的误差并几乎实现完美的攻击者检出率。&lt;h4&gt;结论&lt;/h4&gt;提出的解决方案在定位准确性和攻击者识别方面均优于现有技术，并能显著提高安全性&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work aspires to provide a trustworthy solution for target localizationin adverse environments, where malicious nodes, capable of manipulatingdistance measurements (i.e., performing spoofing attacks), are present, thushindering accurate localization. Besides localization, its other goal is toidentify (detect) which of the nodes participating in the process aremalicious. This problem becomes extremely important with the forthcomingexpansion of IoT and smart cities applications, that depend on accuratelocalization, and the presence of malicious attackers can represent serioussecurity threats if not taken into consideration. This is the case with mostexisting localization systems which makes them highly vulnerable to spoofingattacks. In addition, existing methods that are intended for adversarialsettings consider very specific settings or require additional knowledge aboutthe system model, making them only partially secure. Therefore, this workproposes a novel voting scheme based on clustering and weighted central mass tosecurely solve the localization problem and detect attackers. The proposedsolution has two main phases: 1) Choosing a cluster of suitable points ofinterest by taking advantage of the problem geometry to assigning votes inorder to localize the target, and 2) Attacker detection by exploiting thelocation estimate and basic statistics. The proposed method is assessed interms of localization accuracy, success in attacker detection, andcomputational complexity in different settings. Computer simulations andreal-world experiments corroborate the effectiveness of the proposed schemecompared to state-of-the-art methods, showing that it can accomplish an errorreduction of $30~\%$ and is capable of achieving almost perfect attackerdetection rate when the ratio between attacker intensity and noise standarddeviation is significant.</description>
      <author>example@mail.com (Slavisa Tomic, Marko Beko, Dejan Vukobratovic, Srdjan Krco)</author>
      <guid isPermaLink="false">2502.20218v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Systems-of-Systems for Environmental Sustainability: A Systematic Mapping Study</title>
      <link>http://arxiv.org/abs/2502.20021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该研究探讨了系统之系统的环境可持续性，分析了SoS如何促进碳减排、能源效率和生物多样性保护等可持续实践。&lt;h4&gt;背景信息&lt;/h4&gt;虽然已经有关于智慧城市的系统回顾来讨论可持续性问题，但还没有针对所有类别SoS的系统化知识综合研究。此外，尽管文献中包括其他类型的可持续性（如财务和社会），本研究专注于环境可持续性。&lt;h4&gt;研究目的&lt;/h4&gt;进行系统的映射研究以确定SoS在可持续性应用领域的范围、所面临的挑战以及未来的研究机会。&lt;h4&gt;研究方法&lt;/h4&gt;制定了一个研究协议，其中包括了四个科学数据库的自动化搜索。总共检索到了926个研究项目，并从中选择了39项相关研究进行了分析和报告。&lt;h4&gt;主要发现&lt;/h4&gt;大多数研究集中在智慧城市和智能电网领域；同时，一些应用如可持续农业和森林火灾预防则相对较少探讨。此外，还识别出了系统互操作性、可扩展性和数据治理等挑战。&lt;h4&gt;结论建议&lt;/h4&gt;提出了未来在SoS和环境可持续性方面的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;该论文摘要讨论了关于系统之系统的环境可持续性的新兴领域，并指出尽管有针对智慧城市的系统回顾存在，但缺乏综合现有知识以支持所有类型SoS的广泛应用。研究通过分析39项相关文献揭示了当前主要集中在特定领域的应用以及面临的挑战，并提出了未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Environmental sustainability in Systems-of-Systems (SoS) is an emerging fieldthat seeks to integrate technological solutions to promote the efficientmanagement of natural resources. While systematic reviews addresssustainability in the context of Smart Cities (a category of SoS), a systematicstudy synthesizing the existing knowledge on environmental sustainabilityapplied to SoS in general does not exist. Although literature includes othertypes of sustainability, such as financial and social, this study focuses onenvironmental sustainability, analyzing how SoS contribute to sustainablepractices such as carbon emission reduction, energy efficiency, andbiodiversity conservation. We conducted a Systematic Mapping Study to identifythe application domains of SoS in sustainability, the challenges faced, andresearch opportunities. We planned and executed a research protocol includingan automated search over four scientific databases. Of 926 studies retrieved,we selected, analyzed, and reported the results of 39 relevant studies. Ourfindings reveal that most studies focus on Smart Cities and Smart Grids, whileapplications such as sustainable agriculture and wildfire prevention are lessexplored. We identified challenges such as system interoperability,scalability, and data governance. Finally, we propose future researchdirections for SoS and environmental sustainability.</description>
      <author>example@mail.com (Ana Clara Araújo Gomes da Silva, Gilmar Teixeira Junior, Lívia Mancine C. de Campos, Renato F. Bulcão-Neto, Valdemar Vicente Graciano Neto)</author>
      <guid isPermaLink="false">2502.20021v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Sim-to-Real Reinforcement Learning for Vision-Based Dexterous Manipulation on Humanoids</title>
      <link>http://arxiv.org/abs/2502.20396v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page can be found at https://toruowo.github.io/recipe/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;强化学习在实现人类甚至超人类水平能力方面取得了令人振奋的结果，但灵巧机器人操作的成功仍有限。这项工作调查了将强化学习应用于人形代理执行一系列接触密集型任务的关键挑战，并提出了解决这些挑战的新方法。&lt;h4&gt;背景&lt;/h4&gt;强化学习已经在多种问题领域中实现了人类甚至超越人类的性能，但在灵巧的机器人操纵方面进展有限。&lt;h4&gt;目的&lt;/h4&gt;探讨并解决在人形化身执行复杂操作任务时应用强化学习所面临的挑战，从而提高其实际环境中的性能和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;{'自动化真实到模拟调整模块': '用于使仿真环境更接近现实世界', '通用奖励设计策略': '简化长时间跨度接触密集型操作任务的回报工程', '分而治之提炼过程': '提高难探索问题的样本效率同时保持从仿真到实际性能的一致性', '稀疏和稠密物体表示混合': '弥合从仿真到现实感知差距'}&lt;h4&gt;主要发现&lt;/h4&gt;{'自动化调整模块': '能够有效缩小模拟环境与真实环境之间的差异', '通用奖励设计策略': '简化了长时程接触密集型任务的回报工程，使得训练更加高效', '分而治之提炼过程': '在提高难探索问题效率的同时保持了一致的从仿真到现实的表现', '混合表示方法': '有效减轻了从仿真到实际操作中的感知差距'}&lt;h4&gt;结论&lt;/h4&gt;通过上述一系列创新技术，在三个灵巧的人形操作任务上取得了有希望的结果，表明利用模拟到真实强化学习可以实现人形灵巧操纵的学习，并且能够无需人类演示而达到稳健的泛化和高性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：强化学习在多种问题领域中实现了人类甚至超越人类的性能，但在灵巧机器人操作方面进展有限。这项工作探讨了将强化学习应用于人形代理执行一系列接触密集型任务的关键挑战，并提出了解决这些挑战的新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning has delivered promising results in achieving human- oreven superhuman-level capabilities across diverse problem domains, but successin dexterous robot manipulation remains limited. This work investigates the keychallenges in applying reinforcement learning to solve a collection ofcontact-rich manipulation tasks on a humanoid embodiment. We introduce noveltechniques to overcome the identified challenges with empirical validation. Ourmain contributions include an automated real-to-sim tuning module that bringsthe simulated environment closer to the real world, a generalized reward designscheme that simplifies reward engineering for long-horizon contact-richmanipulation tasks, a divide-and-conquer distillation process that improves thesample efficiency of hard-exploration problems while maintaining sim-to-realperformance, and a mixture of sparse and dense object representations to bridgethe sim-to-real perception gap. We show promising results on three humanoiddexterous manipulation tasks, with ablation studies on each technique. Our workpresents a successful approach to learning humanoid dexterous manipulationusing sim-to-real reinforcement learning, achieving robust generalization andhigh performance without the need for human demonstration.</description>
      <author>example@mail.com (Toru Lin, Kartik Sachdev, Linxi Fan, Jitendra Malik, Yuke Zhu)</author>
      <guid isPermaLink="false">2502.20396v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Point Policy: Unifying Observations and Actions with Key Points for Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.20391v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Point Policy的新方法，该方法可以从离线的人类演示视频中学习机器人的策略，并且不需要任何远程操作数据。&lt;h4&gt;背景&lt;/h4&gt;构建能够在多种环境和对象类型下运行的机器人代理仍然是一项重大挑战，通常需要大量的数据收集。由于每个数据点必须在现实世界中物理执行，这在机器人技术领域尤为限制性。&lt;h4&gt;目的&lt;/h4&gt;提出一种替代的数据源以及能够利用这些数据进行学习的框架。&lt;h4&gt;方法&lt;/h4&gt;Point Policy利用最先进的视觉模型和策略架构将人类的手部姿势转换为机器人的姿势，并通过有意义的关键点捕捉物体状态。这种方法产生了一种形态无关的表示，从而促进有效的策略学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在与训练相同的设置下评估时，相比先前的工作总体改进了75%绝对值；对于新的物体实例在所有任务上表现出74%的增长，并且能够处理显著的背景杂乱。&lt;h4&gt;结论&lt;/h4&gt;Point Policy提供了一种创新的方法来利用人类演示视频中的数据学习机器人策略，无需进行物理执行。这表明从离线数据中学习是可能的，并为未来的研究开辟了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;构建能够在多种环境和对象类型下运行的机器人代理仍然是一项重大挑战，通常需要大量的数据收集。由于每个数据点必须在现实世界中物理执行，这在机器人技术领域尤为限制性。因此，存在对替代的数据源以及能够利用这些数据进行学习的框架的需求。本文介绍了一种名为Point Policy的新方法，该方法可以从离线的人类演示视频中学习机器人的策略，并且不需要任何远程操作数据。Point Policy利用最先进的视觉模型和策略架构将人类的手部姿势转换为机器人的姿势，并通过有意义的关键点捕捉物体状态。这种方法产生了一种形态无关的表示，从而促进有效的策略学习。实验结果表明，在与训练相同的设置下评估时，相比先前的工作总体改进了75%绝对值；对于新的物体实例在所有任务上表现出74%的增长，并且能够处理显著的背景杂乱。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building robotic agents capable of operating across diverse environments andobject types remains a significant challenge, often requiring extensive datacollection. This is particularly restrictive in robotics, where each data pointmust be physically executed in the real world. Consequently, there is acritical need for alternative data sources for robotics and frameworks thatenable learning from such data. In this work, we present Point Policy, a newmethod for learning robot policies exclusively from offline human demonstrationvideos and without any teleoperation data. Point Policy leveragesstate-of-the-art vision models and policy architectures to translate human handposes into robot poses while capturing object states through semanticallymeaningful key points. This approach yields a morphology-agnosticrepresentation that facilitates effective policy learning. Our experiments on 8real-world tasks demonstrate an overall 75% absolute improvement over priorworks when evaluated in identical settings as training. Further, Point Policyexhibits a 74% gain across tasks for novel object instances and is robust tosignificant background clutter. Videos of the robot are best viewed athttps://point-policy.github.io/.</description>
      <author>example@mail.com (Siddhant Haldar, Lerrel Pinto)</author>
      <guid isPermaLink="false">2502.20391v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>InterMimic: Towards Universal Whole-Body Control for Physics-Based Human-Object Interactions</title>
      <link>http://arxiv.org/abs/2502.20390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025. Project Page: https://sirui-xu.github.io/InterMimic/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一个名为InterMimic的框架，该框架能利用不完美的动作捕捉数据来学习复杂的物体-人交互（HOI），并通过一种课程策略和强化学习微调实现了从模仿到生成模型的进步。&lt;h4&gt;背景&lt;/h4&gt;长期以来，实现人类与各种对象进行真实互动的模拟一直是目标。然而，由于复杂的物体-人的耦合、多样的几何形状以及动作捕捉数据中的不准确接触等问题，基于物理的方法扩展到复杂的人体-物体交互面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种框架，利用不完美的动作捕捉数据来学习和生成高质量且多样化的人体-物体互动模拟。&lt;h4&gt;方法&lt;/h4&gt;首先训练特定主体的教师策略以模仿、重定位并改进捕获的动作。然后将这些教师策略的知识转移到一个学生策略中，并通过强化学习微调进一步提升。&lt;h4&gt;主要发现&lt;/h4&gt;InterMimic能够产生现实且多样化的人体-物体互动，在多个HOI数据集上表现良好，还能零样本推广和无缝集成到运动学生成器中。&lt;h4&gt;结论&lt;/h4&gt;该框架不仅提高了模仿质量，还从单纯的模仿技术转变为了复杂人体-物体交互的生成模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving realistic simulations of humans interacting with a wide range ofobjects has long been a fundamental goal. Extending physics-based motionimitation to complex human-object interactions (HOIs) is challenging due tointricate human-object coupling, variability in object geometries, andartifacts in motion capture data, such as inaccurate contacts and limited handdetail. We introduce InterMimic, a framework that enables a single policy torobustly learn from hours of imperfect MoCap data covering diverse full-bodyinteractions with dynamic and varied objects. Our key insight is to employ acurriculum strategy -- perfect first, then scale up. We first trainsubject-specific teacher policies to mimic, retarget, and refine motion capturedata. Next, we distill these teachers into a student policy, with the teachersacting as online experts providing direct supervision, as well as high-qualityreferences. Notably, we incorporate RL fine-tuning on the student policy tosurpass mere demonstration replication and achieve higher-quality solutions.Our experiments demonstrate that InterMimic produces realistic and diverseinteractions across multiple HOI datasets. The learned policy generalizes in azero-shot manner and seamlessly integrates with kinematic generators, elevatingthe framework from mere imitation to generative modeling of complexhuman-object interactions.</description>
      <author>example@mail.com (Sirui Xu, Hung Yu Ling, Yu-Xiong Wang, Liang-Yan Gui)</author>
      <guid isPermaLink="false">2502.20390v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>ATLAS Navigator: Active Task-driven LAnguage-embedded Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2502.20386v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究探讨了在无结构和未知环境中进行任务导向性导航所面临的挑战。机器人需要实时构建并推理出丰富且具有语义信息的地图。&lt;h4&gt;目的&lt;/h4&gt;为了有效地执行自然语言描述的任务，提出了一种分层表示方法，该方法基于嵌入式语言的高斯散布技术，能够支持稀疏语义规划和密集几何表征。&lt;h4&gt;方法&lt;/h4&gt;采用了一种层次化地图构建方式——基于语言嵌入的高斯散布方法，以实现稀疏语义路径规划和密集几何表达的结合。这种方法在碰撞避免导航方面具有优势。&lt;h4&gt;主要发现&lt;/h4&gt;通过真实世界的机器人实验验证了该方法的有效性，在混乱的室内环境及千米级的室外环境中表现良好，并且与特权基线相比，竞争比率为约60%。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为解决任务导向性导航中遇到的问题提供了一种有效的解决方案。它能够适应广泛的任务需求并在复杂环境下运行。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容是关于如何在无结构和未知的环境中实现机器人任务导向性导航的研究，提出了结合稀疏语义规划与密集几何表达的地图表示方法，并通过实际实验验证了该方法的有效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We address the challenge of task-oriented navigation in unstructured andunknown environments, where robots must incrementally build and reason on rich,metric-semantic maps in real time. Since tasks may require clarification orre-specification, it is necessary for the information in the map to be richenough to enable generalization across a wide range of tasks. To effectivelyexecute tasks specified in natural language, we propose a hierarchicalrepresentation built on language-embedded Gaussian splatting that enables bothsparse semantic planning that lends itself to online operation and densegeometric representation for collision-free navigation. We validate theeffectiveness of our method through real-world robot experiments conducted inboth cluttered indoor and kilometer-scale outdoor environments, with acompetitive ratio of about 60% against privileged baselines. Experiment videosand more details can be found on our project page: https://atlasnav.github.io</description>
      <author>example@mail.com (Dexter Ong, Yuezhan Tao, Varun Murali, Igor Spasojevic, Vijay Kumar, Pratik Chaudhari)</author>
      <guid isPermaLink="false">2502.20386v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Physics-Driven Data Generation for Contact-Rich Manipulation via Trajectory Optimization</title>
      <link>http://arxiv.org/abs/2502.20382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种低成本的数据生成管道，利用物理仿真、人类演示和模型规划来为接触密集型机器人操作任务高效生成大规模高质量数据集。&lt;h4&gt;背景&lt;/h4&gt;在虚拟现实模拟环境中收集少量人体动作示例，并通过基于优化的运动重定位和轨迹优化进一步细化这些示例，以适应不同类型的机器人硬件和物理参数。该方法旨在创造多样且物理一致的数据集，以便于跨设备之间传输数据并重复使用之前在不同硬件配置下采集的老化数据集。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够生成大规模高质量数据集的方法，从而提高接触密集型任务中机器人的操作性能，并减少对人类输入的需求。&lt;h4&gt;方法&lt;/h4&gt;采用物理仿真、优化算法和轨迹规划相结合的方式处理人体演示动作。从虚拟现实环境中获取初始的小规模数据样本，然后通过优化过程使这些数据适应于各种不同的机器人形态及环境参数。&lt;h4&gt;主要发现&lt;/h4&gt;所生成的数据集不仅能够提高机器人的操作性能，在跨设备部署时也表现出优秀的零样本迁移能力，即在新的机器人硬件上无需进一步训练即可实现高成功率的操作任务。&lt;h4&gt;结论&lt;/h4&gt;此研究证明了通过仿真结合优化技术来生成高质量数据的有效性，并展示了这种方法在实际接触密集型任务中具有巨大的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种低成本的数据生成管道，该管道整合物理仿真的方法、人类的演示和基于模型的规划，以高效地为涉及大量接触操作的机器人抓取任务生成大规模且高质量的数据集。从少量在虚拟现实模拟环境中收集的人类动作样本开始，利用基于优化的方法进行运动重定位以及轨迹优化来调整这些示例，使其适应于不同类型的机器人形态及物理参数，从而产生了多样化、物理一致性的数据集，并为跨设备间的数据传输提供了可能，同时也能够重复使用之前在不同硬件配置下采集的老化数据。通过训练生成的数据集以应对多种机器人手臂上的挑战性接触密集型任务（包括浮动Allegro手和双臂机器人），验证了该管道的有效性；所训练的策略在零样本输入的情况下于实际设备上部署，如用于双臂iiwa机器人的操作中取得了高成功率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a low-cost data generation pipeline that integrates physics-basedsimulation, human demonstrations, and model-based planning to efficientlygenerate large-scale, high-quality datasets for contact-rich roboticmanipulation tasks. Starting with a small number of embodiment-flexible humandemonstrations collected in a virtual reality simulation environment, thepipeline refines these demonstrations using optimization-based kinematicretargeting and trajectory optimization to adapt them across various robotembodiments and physical parameters. This process yields a diverse, physicallyconsistent dataset that enables cross-embodiment data transfer, and offers thepotential to reuse legacy datasets collected under different hardwareconfigurations or physical parameters. We validate the pipeline's effectivenessby training diffusion policies from the generated datasets for challengingcontact-rich manipulation tasks across multiple robot embodiments, including afloating Allegro hand and bimanual robot arms. The trained policies aredeployed zero-shot on hardware for bimanual iiwa arms, achieving high successrates with minimal human input. Project website:https://lujieyang.github.io/physicsgen/.</description>
      <author>example@mail.com (Lujie Yang, H. J. Terry Suh, Tong Zhao, Bernhard Paus Graesdal, Tarik Kelestemur, Jiuguang Wang, Tao Pang, Russ Tedrake)</author>
      <guid isPermaLink="false">2502.20382v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Agent Path Planning in Complex Environments using Gaussian Belief Propagation with Global Path Finding</title>
      <link>http://arxiv.org/abs/2502.20369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by "International Conference on Robotics and Automation" -  ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种多智能体路径规划的新方法，结合高斯信念传播与路径积分，并引入跟踪因子来确保严格的全局路径遵循。该方法通过两种不同全局路径规划策略进行了测试：快速探索随机树和结构化规划器。&lt;h4&gt;背景&lt;/h4&gt;在机器人学中，多代理路径规划是一个关键挑战，要求智能体能够在复杂环境中导航并避免碰撞同时优化旅行效率。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法的局限性，提高多代理协调能力，特别是在结合结构化全局规划时提升效果。&lt;h4&gt;方法&lt;/h4&gt;将高斯信念传播与路径积分相结合，并引入跟踪因子；使用快速探索随机树和基于预定义车道结构的结构化规划器进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;在单智能体和多智能体场景中，跟踪因子分别减少了28%和16%的路径偏差，证明了其提高多智能体协调的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法通过引入跟踪因子和其他技术改进，在各种导航和通信挑战下表现出色，特别是在结合结构化全局规划时效果更佳。&lt;h4&gt;翻译&lt;/h4&gt;论文摘要介绍了一种新的解决多代理路径规划问题的方法，通过将高斯信念传播与路径积分相结合，并且添加了跟踪因素来确保严格遵守全局路径。这项工作旨在克服现有方法的局限性，特别是在提高多智能体协调方面的表现，尤其是在结合结构化全局规划的情况下。研究在不同的全球路径规划策略（快速探索随机树和利用预定义车道结构改进协作性的结构化规划器）上进行了测试，并在一个模拟环境中对所有场景的有效性进行了验证。实验结果显示，在单个代理和多个代理的场景中，跟踪因素分别减少了28％和16％的路径偏差，表明其提高了多智能体协调的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-agent path planning is a critical challenge in robotics, requiringagents to navigate complex environments while avoiding collisions andoptimizing travel efficiency. This work addresses the limitations of existingapproaches by combining Gaussian belief propagation with path integration andintroducing a novel tracking factor to ensure strict adherence to global paths.The proposed method is tested with two different global path-planningapproaches: rapidly exploring random trees and a structured planner, whichleverages predefined lane structures to improve coordination. A simulationenvironment was developed to validate the proposed method across diversescenarios, each posing unique challenges in navigation and communication.Simulation results demonstrate that the tracking factor reduces path deviationby 28% in single-agent and 16% in multi-agent scenarios, highlighting itseffectiveness in improving multi-agent coordination, especially when combinedwith structured global planning.</description>
      <author>example@mail.com (Jens Høigaard Jensen, Kristoffer Plagborg Bak Sørensen, Jonas le Fevre Sejersen, Andriy Sarabakha)</author>
      <guid isPermaLink="false">2502.20369v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>The Role of Tactile Sensing for Learning Reach and Grasp</title>
      <link>http://arxiv.org/abs/2502.20367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了利用强化学习和触觉传感来实现稳健且反应迅速的机器人抓取方法，并通过不同模型自由强化学习方法对比研究了视觉感知不完美情况下的多种触觉环境设置。&lt;h4&gt;背景&lt;/h4&gt;在当前的机器人应用中，稳定且鲁棒性的机械手抓握技术至关重要。最近的研究表明，利用大规模数据集和监督学习可以提高反向对称性抓取的速度和精度，但这些方法对于长时规划面临感知错误和校准误差的挑战。&lt;h4&gt;目的&lt;/h4&gt;评估不同复杂度的基于力的触觉传感如何影响抓取任务中的强化学习行为，并通过对比研究发现有效的触觉设置以改进机械手抓握性能。&lt;h4&gt;方法&lt;/h4&gt;采用两种无模型强化学习算法来研究反向对称性抓取问题，分析了在视觉感知不完美的情况下，不同的触觉和环境设定对于改善机械手抓握能力的效用。&lt;h4&gt;主要发现&lt;/h4&gt;不同种类的触觉特征可以提高学习效果；然而，复杂的触觉输入则会增加训练难度。&lt;h4&gt;结论&lt;/h4&gt;利用强化学习结合触觉传感有望成为实现更稳健、反应更快的机器人抓取运动的一种有前途的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stable and robust robotic grasping is essential for current and future robotapplications. In recent works, the use of large datasets and supervisedlearning has enhanced speed and precision in antipodal grasping. However, thesemethods struggle with perception and calibration errors due to large planninghorizons. To obtain more robust and reactive grasping motions, leveragingreinforcement learning combined with tactile sensing is a promising direction.Yet, there is no systematic evaluation of how the complexity of force-basedtactile sensing affects the learning behavior for grasping tasks. This papercompares various tactile and environmental setups using two model-freereinforcement learning approaches for antipodal grasping. Our findings suggestthat under imperfect visual perception, various tactile features improvelearning outcomes, while complex tactile inputs complicate training.</description>
      <author>example@mail.com (Boya Zhang, Iris Andrussow, Andreas Zell, Georg Martius)</author>
      <guid isPermaLink="false">2502.20367v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Video Analytics in Cloud-Edge-Terminal Collaborative Systems</title>
      <link>http://arxiv.org/abs/2502.06581v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文综述了云边端协同（CETC）系统在视频分析领域的应用和发展，特别关注其架构组件、资源管理和边缘计算平台。&lt;h4&gt;背景&lt;/h4&gt;随着视频数据的爆炸性增长，分布式视频分析在云边端协作系统中得到了快速发展，这些系统能够实现高效的视频处理、实时推理和隐私保护。&lt;h4&gt;目的&lt;/h4&gt;该综述旨在分析CETC系统的基础架构组成部分，并探讨其在视频监控、自动驾驶和智慧城市等领域的应用突破。&lt;h4&gt;方法&lt;/h4&gt;文中首先剖析了包括层级式、分布式及混合框架在内的基本架构组件，以及边缘计算平台与资源管理机制。同时，还介绍了以云为中心的方法利用强大计算能力处理复杂的视频理解和模型训练问题，并探索了结合自适应任务卸载和资源感知调度技术的混合视频分析。&lt;h4&gt;主要发现&lt;/h4&gt;文章指出，除了传统方法外，大型语言模型和多模态整合领域的最新进展揭示了在平台可扩展性、数据保护和系统可靠性方面的机会与挑战。&lt;h4&gt;结论&lt;/h4&gt;未来的研究方向包括可解释性系统的开发、高效的处理机制以及高级视频分析技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The explosive growth of video data has driven the development of distributedvideo analytics in cloud-edge-terminal collaborative (CETC) systems, enablingefficient video processing, real-time inference, and privacy-preservinganalysis. Among multiple advantages, CETC systems can distribute videoprocessing tasks and enable adaptive analytics across cloud, edge, and terminaldevices, leading to breakthroughs in video surveillance, autonomous driving,and smart cities. In this survey, we first analyze fundamental architecturalcomponents, including hierarchical, distributed, and hybrid frameworks,alongside edge computing platforms and resource management mechanisms. Buildingupon these foundations, edge-centric approaches emphasize on-device processing,edge-assisted offloading, and edge intelligence, while cloud-centric methodsleverage powerful computational capabilities for complex video understandingand model training. Our investigation also covers hybrid video analyticsincorporating adaptive task offloading and resource-aware scheduling techniquesthat optimize performance across the entire system. Beyond conventionalapproaches, recent advances in large language models and multimodal integrationreveal both opportunities and challenges in platform scalability, dataprotection, and system reliability. Future directions also encompassexplainable systems, efficient processing mechanisms, and advanced videoanalytics, offering valuable insights for researchers and practitioners in thisdynamic field.</description>
      <author>example@mail.com (Linxiao Gong, Hao Yang, Gaoyun Fang, Bobo Ju, Juncen Guo, Xiaoguang Zhu, Xiping Hu, Yan Wang, Peng Sun, Azzedine Boukerche)</author>
      <guid isPermaLink="false">2502.06581v3</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Trajectory-to-Action Pipeline (TAP): Automated Scenario Description Extraction for Autonomous Vehicle Behavior Comparison</title>
      <link>http://arxiv.org/abs/2502.20353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为Trajectory-to-Action Pipeline (TAP)的方法，该方法可以自动从大规模轨迹数据集中提取Scenario Description Languages (SDL)标签。这项工作为自动驾驶车辆(AVs)的安全分析和行为评估提供了一个可扩展的基础。&lt;h4&gt;背景&lt;/h4&gt;Scenario Description Languages (SDLs) 提供了结构化、可解释的嵌入表示法，用于描述自主车辆遇到的各种交通场景，并支持关键任务如相似场景搜索和边缘案例检测等安全分析。&lt;h4&gt;目的&lt;/h4&gt;提出一种自动化的TAP方法来从大规模轨迹数据集中提取SDL标签，从而提升自动驾驶车的安全性和评估效率。&lt;h4&gt;方法&lt;/h4&gt;TAP采用基于规则的交叉熵优化方法直接从数据中学习参数，以提高在不同驾驶环境中的泛化能力。使用Waymo Open Motion Dataset (WOMD)作为实验平台来验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;与Average Displacement Error (ADE)相比，TAP在识别行为相似轨迹时提高了30%的精度；而与Dynamic Time Warping (DTW)相比，则提升了24%。此外，该方法还能够自动检测独特的驾驶行为，简化了AV测试的安全评估过程。&lt;h4&gt;结论&lt;/h4&gt;这项工作为基于场景的自动驾驶车辆行为分析提供了可扩展的基础，并且具有在多代理环境下进行集成应用的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;Scenario Description Languages (SDLs) 提供结构化、可解释的嵌入表示来代表自动驾驶汽车遇到的各种交通场景，支持包括相似场景搜索和边缘案例检测等关键任务的安全分析。论文介绍了Trajectory-to-Action Pipeline (TAP)，这是一种从大规模轨迹数据集中提取SDL标签的大规模且自动化的方案。通过使用基于规则的方法进行交叉熵优化，TAP直接从数据中学习参数以增强在各种驾驶情境下的泛化能力。利用Waymo Open Motion Dataset (WOMD)作为实验平台，TAP在识别行为相似的轨迹方面超越了Average Displacement Error（ADE）30%，而相对于Dynamic Time Warping (DTW)则提升24%。此外，该方案还能够自动检测独特驾驶行为，简化AV测试的安全评估过程。这项研究为基于场景的自动驾驶车辆行为分析提供了可扩展的基础，并具有多代理环境集成应用的巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scenario Description Languages (SDLs) provide structured, interpretableembeddings that represent traffic scenarios encountered by autonomous vehicles(AVs), supporting key tasks such as scenario similarity searches and edge casedetection for safety analysis. This paper introduces the Trajectory-to-ActionPipeline (TAP), a scalable and automated method for extracting SDL labels fromlarge trajectory datasets. TAP applies a rules-based cross-entropy optimizationapproach to learn parameters directly from data, enhancing generalizationacross diverse driving contexts. Using the Waymo Open Motion Dataset (WOMD),TAP achieves 30% greater precision than Average Displacement Error (ADE) and24% over Dynamic Time Warping (DTW) in identifying behaviorally similartrajectories. Additionally, TAP enables automated detection of unique drivingbehaviors, streamlining safety evaluation processes for AV testing. This workprovides a foundation for scalable scenario-based AV behavior analysis, withpotential extensions for integrating multi-agent contexts.</description>
      <author>example@mail.com (Aron Harder, Madhur Behl)</author>
      <guid isPermaLink="false">2502.20353v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Reservoir Computing and Photoelectrochemical Sensors: A Marriage of Convenience</title>
      <link>http://arxiv.org/abs/2502.20342v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;感应技术是信息处理的重要组成部分。当前的人工智能系统（尤其是针对医疗和环境应用的）需要大量关于生物流体或环境样本化学组成的数据。&lt;h4&gt;目的&lt;/h4&gt;介绍将光电化学传感器与非传统计算范式——蓄水池计算进行集成的想法，以提升传感器性能并开辟新的科学路径。&lt;h4&gt;方法&lt;/h4&gt;探讨如何通过结合光电化学传感技术与蓄水池计算系统来改进感应设备和促进仿生感官信息处理的研究。&lt;h4&gt;主要发现&lt;/h4&gt;将光电化学传感器与蓄水池计算相结合可以克服一些现有障碍，并可能在自主机器人技术和仿生感知领域取得突破性进展。&lt;h4&gt;结论&lt;/h4&gt;这种集成方法不仅能够提升传感器本身的性能，还能开启有效信息采集和处理的新时代。&lt;h4&gt;翻译&lt;/h4&gt;摘要所述内容的中文翻译已经完成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.ccr.2023.215155&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sensing technology is an important aspect of information processing. Currentdevelopment in artificial intelligence systems (especially those aimed atmedical and environmental applications) requires a lot of data on the chemicalcomposition of biological fluids or environmental samples. These complexmatrices require advanced sensing devices, and photoelectrochemical ones seemto have potential to overcome at least some of the obstacles. Furthermore, thedevelopment of artificial intelligence (AI) technology for autonomous roboticsrequires technology mimicking human senses, also those operating at themolecular level, such as gustation and olfaction. Again, photoelectrochemicalsensing can provide some suitable solutions. In this review, we introduce theidea of integration of photoelectrochemical sensors with some unconventionalcomputing paradigm - reservoir computing. This approach should not only boostthe performance of the sensors itself, but also open new pathways throughscience. Integration of sensing devices with computing systems will alsocontribute to a better understanding (or at least mimicking) of the humansenses and neuromorphic sensory information processing. Although reservoirsystems can be considered magic "black boxes" and their operation is at thesame time simple and hard to comprehend, this combination is expected to open anew era of effective information harvesting and processing systems.</description>
      <author>example@mail.com (Gisya Abdi, Lulu Alluhaibi, Ewelina Kowalewska, Tomasz Mazur, Krzysztof Mech, Agnieszka Podborska, Andrzej Sławek, Hirofumi Tanaka, Konrad Szaciłowski)</author>
      <guid isPermaLink="false">2502.20342v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Deep Reinforcement Learning based Autonomous Decision-Making for Cooperative UAVs: A Search and Rescue Real World Application</title>
      <link>http://arxiv.org/abs/2502.20326v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 Pages, 21 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对无GNSS信号的室内环境中的多无人机系统的自主导航和任务分配的整体框架。&lt;h4&gt;背景&lt;/h4&gt;在没有全球导航卫星系统（GNSS）支持的室内环境中，现有的无人机系统面临着挑战，尤其是在导航、障碍物避让和任务协调方面。这些问题阻碍了无人机系统在搜索救援和其他探索活动中的有效应用。&lt;h4&gt;目的&lt;/h4&gt;提出一个基于深度强化学习（DRL）的自主指导机制，并通过图卷积网络（GCN）实现动态实时的任务分配，以提高多无人机系统的导航能力和任务协作效率。&lt;h4&gt;方法&lt;/h4&gt;{'1': '使用Twin Delayed Deep Deterministic Policy Gradient算法进行自主导航训练，引入人工势场(APF)奖励结构来优化培训过程。', '2': '利用图卷积网络（GCN）处理多无人机之间的合作任务分配问题。', '3': '采用LiDAR同步定位和建图(SLAM)技术结合深度相机解决室内环境中的精确定位问题，同时缓解走廊效应。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '基于APF的奖励结构可以显著提高无人机在室内环境中的导航效率。', '2': '采用DRL训练的GCN能够有效处理任务分配，并实现动态和实时的任务调整。', '3': 'LiDAR SLAM结合深度相机提供了一种有效的定位解决方案，增强了系统的依赖性和可靠性。'}&lt;h4&gt;结论&lt;/h4&gt;所提出的多无人机框架不仅提升了单个无人机的导航能力，还优化了复杂障碍环境中的任务分配协调，实验结果表明该系统在特定条件下的表现优异，并且在2024年NATO Sapience自主合作无人机比赛中获得了第一名。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文提出了一种针对无GNSS信号的室内环境中多无人机系统的整体框架。我们提倡使用基于深度强化学习（DRL）的方法进行自主导航，利用Twin Delayed Deep Deterministic Policy Gradient算法。为了提高训练过程中的效率，我们采用人工势场(APF)奖励结构，使代理能够优化其移动路径，从而促进更顺畅的路径和增强的障碍物避让能力。此外，通过基于DRL的图卷积网络（GCN）解决了任务分配问题，该方法表示了无人机与任务之间的交互，实现了动态和实时的任务分配，反映了当前环境条件以及无人机的能力。这种做法促进了多无人机系统在搜索救援或其他探索活动中的有效协调合作。最后，在缺乏GNSS的情况下，我们采用LiDAR SLAM配合深度相机来确保精确定位，解决了走廊效应问题。该集成提供了强大的定位和映射功能，从而增强了室内导航系统的可靠性。所提出的多无人机框架不仅提高了单个无人机的导航能力，还优化了复杂障碍环境中的任务分配协调，在为NATO Sapience自主合作无人机竞赛量身定制的实验环境中进行了测试，并取得了卓越的成绩，最终在2024年的比赛中获得第一名。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a holistic framework for autonomous guidance, navigation,and task distribution among multi-drone systems operating in Global NavigationSatellite System (GNSS)-denied indoor settings. We advocate for a DeepReinforcement Learning (DRL)-based guidance mechanism, utilising the TwinDelayed Deep Deterministic Policy Gradient algorithm. To improve the efficiencyof the training process, we incorporate an Artificial Potential Field(APF)-based reward structure, enabling the agent to refine its movements,thereby promoting smoother paths and enhanced obstacle avoidance in indoorcontexts. Furthermore, we tackle the issue of task distribution amongcooperative UAVs through a DRL-trained Graph Convolutional Network (GCN). ThisGCN represents the interactions between drones and tasks, facilitating dynamicand real-time task allocation that reflects the current environmentalconditions and the capabilities of the drones. Such an approach fosterseffective coordination and collaboration among multiple drones during searchand rescue operations or other exploratory endeavours. Lastly, to ensureprecise odometry in environments lacking GNSS, we employ Light Detection AndRanging Simultaneous Localisation and Mapping complemented by a depth camera tomitigate the hallway problem. This integration offers robust localisation andmapping functionalities, thereby enhancing the systems dependability in indoornavigation. The proposed multi-drone framework not only elevates individualnavigation capabilities but also optimises coordinated task allocation incomplex, obstacle-laden environments. Experimental evaluations conducted in asetup tailored to meet the requirements of the NATO Sapience AutonomousCooperative Drone Competition demonstrate the efficacy of the proposed system,yielding outstanding results and culminating in a first-place finish in the2024 Sapience competition.</description>
      <author>example@mail.com (Thomas Hickling, Maxwell Hogan, Abdulla Tammam, Nabil Aouf)</author>
      <guid isPermaLink="false">2502.20326v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>On Adversarial Attacks In Acoustic Drone Localization</title>
      <link>http://arxiv.org/abs/2502.20325v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;多旋翼无人驾驶飞行器（MAVs，即无人机）由于在农业、商业递送和搜救等领域应用广泛而日益受到关注。然而，在非受控环境中使用时，导航系统的潜在对抗攻击威胁对任务的成功率和安全性构成了挑战。&lt;h4&gt;背景&lt;/h4&gt;基于视觉的方法对光照条件和遮挡非常敏感，促使研究者们开始探索依赖于声学传感器等其他模态的导航方式。虽然在无人机定位方面已有利用声学方法取得的研究进展，但针对其导航系统的对抗攻击方面的研究仅限于基于视觉感知的系统。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本工作旨在通过分析PGD（Projected Gradient Descent）对抗攻击对声学无人机定位的影响进行全面分析，并开发一种算法来恢复对抗扰动以减轻这种攻击的效果。&lt;h4&gt;方法&lt;/h4&gt;本工作首先评估了在声学传感器上应用PGD对抗攻击的效果；然后设计了一种新的算法，旨在减少这些攻击对声学导航系统造成的不利影响。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，在无人机的声学定位系统中实施PGD攻击可以显著降低其准确性和可靠性。而所提出的扰动恢复方法能有效减轻此类攻击的影响。&lt;h4&gt;结论&lt;/h4&gt;这项工作强调了在开发新型无人飞行器时，对导航系统进行抗干扰设计的重要性，并为未来的对抗安全研究提供了重要方向。&lt;h4&gt;翻译&lt;/h4&gt;多旋翼无人驾驶飞行器（MAVs，即无人机）由于它们在农业、商业递送和搜救等广泛领域的应用而近年来引起了越来越多的关注。基于视觉的方法对于光线条件和遮挡非常敏感，这促使了对依赖声学感知等其他模态的导航系统研究的增长。使用无人机执行非受控环境中的任务时的一个主要担忧是其导航系统的潜在对抗攻击威胁，这种威胁可能会导致关键任务失败、安全漏洞及危及操作员和旁观者安全的风险。尽管以往的研究已经在基于视觉感知的无人机定位方面取得了进展，但是之前有关针对无人机导航系统进行对抗攻击的研究仅限于视觉感知系统。在这项工作中，我们的目标是通过提供PGD（Projected Gradient Descent）对抗攻击对声学无人机定位影响的全面分析来填补这一空白，并且开发出一种能够在我们设定的情况下显著减少这种攻击效果的扰动恢复算法。在发表后我们将公开所有实验代码以供复现研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-rotor aerial autonomous vehicles (MAVs, more widely known as "drones")have been generating increased interest in recent years due to their growingapplicability in a vast and diverse range of fields (e.g., agriculture,commercial delivery, search and rescue). The sensitivity of visual-basedmethods to lighting conditions and occlusions had prompted growing study ofnavigation reliant on other modalities, such as acoustic sensing. A majorconcern in using drones in scale for tasks in non-controlled environments isthe potential threat of adversarial attacks over their navigational systems,exposing users to mission-critical failures, security breaches, and compromisedsafety outcomes that can endanger operators and bystanders. While previous workshows impressive progress in acoustic-based drone localization, prior researchin adversarial attacks over drone navigation only addresses visualsensing-based systems. In this work, we aim to compensate for this gap bysupplying a comprehensive analysis of the effect of PGD adversarial attacksover acoustic drone localization. We furthermore develop an algorithm foradversarial perturbation recovery, capable of markedly diminishing the affectof such attacks in our setting. The code for reproducing all experiments willbe released upon publication.</description>
      <author>example@mail.com (Tamir Shor, Chaim Baskin, Alex Bronstein)</author>
      <guid isPermaLink="false">2502.20325v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>MARVEL: Multi-Agent Reinforcement Learning for constrained field-of-View multi-robot Exploration in Large-scale environments</title>
      <link>http://arxiv.org/abs/2502.20217v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  \c{opyright} 20XX IEEE. Personal use of this material is permitted.  Permission from IEEE must be obtained for all other uses, in any current or  future media, including reprinting/republishing this material for advertising  or promotional purposes, creating new collective works, for resale or  redistribution to servers or lists, or reuse of any copyrighted component of  this work in other works&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;在多机器人探索中，一支移动机器人的团队被赋予高效地绘制未知环境的任务。尽管大多数探索规划器假设使用类似LiDAR的全向传感器，但这种做法对于像无人机这样的小型机器人来说是不切实际的，因为载荷限制可能导致只能使用轻量级的方向性传感器如摄像头。&lt;h4&gt;背景&lt;/h4&gt;在多机器人探索中，当面对具有有限视场（FoV）的小型机器人时，传统的探索规划器假设全向传感器的应用变得不再现实。这些小型机器人的传感器受限于方向性和视野范围的约束，增加了问题解决的复杂度。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于拥有有限视场的多机器人系统的新框架MARVEL，以增强其在大型室内环境中的协调能力和决策能力。&lt;h4&gt;方法&lt;/h4&gt;通过结合图注意力网络和创新性的前沿及姿态特征融合技术，使用强化学习（MARL）开发了一种协作式、去中心化的策略。此外还引入了信息驱动的动作修剪策略来处理视角规划的大动作空间问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示，与现有最先进的探索规划器相比，MARVEL所学得的政策展示了有效的协同行为，并在多个评价指标上表现出色。该方法的通用性得到了验证，甚至在一个高达90米乘以90米的大规模环境中也表现良好。此外还通过真实硬件无人机团队的成功部署证明了其实用性和可操作性。&lt;h4&gt;结论&lt;/h4&gt;MARVEL框架为具有有限视场的多机器人探索提供了一个有效的解决方案，并展示了其在大规模复杂环境中的优越性能，同时适用于各种团队规模和传感器配置（即FoV和传感器范围）无需额外训练。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In multi-robot exploration, a team of mobile robot is tasked with efficientlymapping an unknown environments. While most exploration planners assumeomnidirectional sensors like LiDAR, this is impractical for small robots suchas drones, where lightweight, directional sensors like cameras may be the onlyoption due to payload constraints. These sensors have a constrainedfield-of-view (FoV), which adds complexity to the exploration problem,requiring not only optimal robot positioning but also sensor orientation duringmovement. In this work, we propose MARVEL, a neural framework that leveragesgraph attention networks, together with novel frontiers and orientationfeatures fusion technique, to develop a collaborative, decentralized policyusing multi-agent reinforcement learning (MARL) for robots with constrainedFoV. To handle the large action space of viewpoints planning, we furtherintroduce a novel information-driven action pruning strategy. MARVEL improvesmulti-robot coordination and decision-making in challenging large-scale indoorenvironments, while adapting to various team sizes and sensor configurations(i.e., FoV and sensor range) without additional training. Our extensiveevaluation shows that MARVEL's learned policies exhibit effective coordinatedbehaviors, outperforming state-of-the-art exploration planners across multiplemetrics. We experimentally demonstrate MARVEL's generalizability in large-scaleenvironments, of up to 90m by 90m, and validate its practical applicabilitythrough successful deployment on a team of real drone hardware.</description>
      <author>example@mail.com (Jimmy Chiun, Shizhe Zhang, Yizhuo Wang, Yuhong Cao, Guillaume Sartoretti)</author>
      <guid isPermaLink="false">2502.20217v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating Model-Based Reinforcement Learning with State-Space World Models</title>
      <link>http://arxiv.org/abs/2502.20168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;强化学习（RL）是机器人学习的一种有效方式，但模型无关的强化学习（MFRL）需要大量环境交互才能获得成功的控制策略。相比之下，基于模型的强化学习（MBRL）通过同时训练世界模型和策略来提高样本效率，但是这种方法增加了计算复杂性。&lt;h4&gt;背景&lt;/h4&gt;传统的MFRL方法在处理复杂的非线性和噪声传感器信号时遇到挑战，导致需要大量的环境交互以获取成功的行为策略。而MBRL可以利用世界模型进行规划或数据收集，并且能够提供一阶策略梯度来训练策略。&lt;h4&gt;目的&lt;/h4&gt;提出一种加速基于状态空间世界的模型强化学习（MBRL）的新方法，特别是针对复杂和部分可观测的现实场景。&lt;h4&gt;方法&lt;/h4&gt;该研究利用状态空间模型（SSMs）并行化世界动力学模型的训练过程，并且在训练阶段给世界模型提供特权信息以提高性能。&lt;h4&gt;主要发现&lt;/h4&gt;新方法在多个实际敏捷四旋翼飞行任务中表现出显著的速度提升，将世界模型训练时间减少高达10倍，而整个MBRL的训练时间减少4倍以上。同时，该方法并没有牺牲样本效率或任务奖励。&lt;h4&gt;结论&lt;/h4&gt;通过利用SSMs并行化和提供特权信息的方式，新的MBRL技术可以极大地加速复杂场景中的学习过程，而不降低性能指标。&lt;h4&gt;翻译&lt;/h4&gt;摘要：强化学习是机器人学习的一个强大手段。然而，模型无关的强化学习需要大量的环境交互才能成功地学习控制策略。这是因为嘈杂的学习更新以及机器人系统的复杂性通常涉及到高度非线性的动态和噪声传感器信号。相比之下，基于模型的强化学习不仅训练一个策略还同时学习一个世界模型来捕获环境的动力学和奖励。该世界模型可以用于规划、数据收集或提供一阶策略梯度来进行训练。利用世界模型相比于无模型的强化学习显著提高了样本效率。然而，与策略一起训练的世界模型增加了计算复杂性，导致了更长的训练时间，在复杂的现实场景中通常是不可行的。在这项工作中，我们提出了一种新的方法来通过状态空间世界模型加速基于模型的强化学习。我们的方法利用状态空间模型（SSMs）并行化动力学模型的训练过程，这是通常的主要计算瓶颈。此外，我们提出了一个架构，在训练过程中给世界模型提供特权信息，这对于部分可观测环境尤其相关。我们在多个实际敏捷四旋翼飞行任务中评估了这种方法，包括完全和部分可观测环境中的复杂动态。我们展示了显著的速度提升，将世界模型的训练时间减少高达10倍，并且整个基于模型的学习的时间减少了4倍以上。这种优势没有牺牲性能，因为我们的方法在样本效率和任务奖励方面与最先进的基于模型的方法类似。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning (RL) is a powerful approach for robot learning.However, model-free RL (MFRL) requires a large number of environmentinteractions to learn successful control policies. This is due to the noisy RLtraining updates and the complexity of robotic systems, which typically involvehighly non-linear dynamics and noisy sensor signals. In contrast, model-basedRL (MBRL) not only trains a policy but simultaneously learns a world model thatcaptures the environment's dynamics and rewards. The world model can either beused for planning, for data collection, or to provide first-order policygradients for training. Leveraging a world model significantly improves sampleefficiency compared to model-free RL. However, training a world model alongsidethe policy increases the computational complexity, leading to longer trainingtimes that are often intractable for complex real-world scenarios. In thiswork, we propose a new method for accelerating model-based RL using state-spaceworld models. Our approach leverages state-space models (SSMs) to parallelizethe training of the dynamics model, which is typically the main computationalbottleneck. Additionally, we propose an architecture that provides privilegedinformation to the world model during training, which is particularly relevantfor partially observable environments. We evaluate our method in severalreal-world agile quadrotor flight tasks, involving complex dynamics, for bothfully and partially observable environments. We demonstrate a significantspeedup, reducing the world model training time by up to 10 times, and theoverall MBRL training time by up to 4 times. This benefit comes withoutcompromising performance, as our method achieves similar sample efficiency andtask rewards to state-of-the-art MBRL methods.</description>
      <author>example@mail.com (Maria Krinner, Elie Aljalbout, Angel Romero, Davide Scaramuzza)</author>
      <guid isPermaLink="false">2502.20168v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Geometry and Mechanics of Non-Euclidean Curved-Crease Origami</title>
      <link>http://arxiv.org/abs/2502.20147v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近有关于弯曲折纸的理论、数值和实验工作的大量研究，但注意到缺乏一个统一且完整的几何框架来描述具有非欧曲率的弯曲折纸的几何与力学特性。本文提供了一个通用的几何框架，用于描述由两条一般带组成的弯曲折纸形状，并表明根据空间折叠线及其配置分支可以得出四种不同的状态。在该几何框架内，推导出平衡方程并研究了这种结构的机械响应，重点关注欧拉屈曲行为。通过线性稳定性分析和有限元模拟发现，重叠构型表现出较低的屈曲阈值。为了更有效地捕捉大变形行为，基于各向异性Kirchhoff杆理论开发了一个双带模型，并成功预测出主要特性。&lt;h4&gt;背景&lt;/h4&gt;最近在弯曲折纸方面开展了大量的理论、数值和实验工作，然而对于具有非欧曲率（非平直折叠线）的结构缺乏一个统一而完整的几何力学框架。&lt;h4&gt;目的&lt;/h4&gt;提供一种通用的几何框架以描述由两条一般带组成的任意形状的弯曲折纸，并研究其机械响应。&lt;h4&gt;方法&lt;/h4&gt;1. 提供了一个几何框架来描述弯曲折纸的形状，包括四种可能的状态；2. 在给定的框架内推导了平衡方程并进行了线性稳定性分析和有限元模拟以研究其机械行为；3. 基于各向异性Kirchhoff杆理论开发了一种双带模型。&lt;h4&gt;主要发现&lt;/h4&gt;四种不同状态取决于空间折叠线及其配置分支，重叠构型表现出较低的屈曲阈值。新模型能够准确预测弯曲折纸的大变形行为。&lt;h4&gt;结论&lt;/h4&gt;这项工作建立了一个关于弯曲折纸几何与力学之间的联系，为机器人学、致动器和可展开太空结构等应用提供了新的见解，并且开发的新模型可以成功预测主要特性。&lt;h4&gt;翻译&lt;/h4&gt;最近有关于弯曲折纸的理论、数值和实验工作的大量研究，但注意到缺乏一个统一且完整的几何框架来描述具有非欧曲率的弯曲折纸的几何与力学特性。本文提供了一个通用的几何框架，用于描述由两条一般带组成的弯曲折纸形状，并表明根据空间折叠线及其配置分支可以得出四种不同的状态。在该几何框架内，推导出平衡方程并研究了这种结构的机械响应，重点关注欧拉屈曲行为。通过线性稳定性分析和有限元模拟发现，重叠构型表现出较低的屈曲阈值。为了更有效地捕捉大变形行为，基于各向异性Kirchhoff杆理论开发了一个双带模型，并成功预测出主要特性。这项工作建立了一个关于弯曲折纸几何与力学之间的联系，为机器人学、致动器和可展开太空结构等应用提供了新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently there have been extensive theoretical, numerical and experimentalworks on curved-fold origami. However, we notice that a unified and completegeometric framework for describing the geometry and mechanics of curved-foldorigami, especially those with nontrivial Gaussian curvature at the crease(non-Euclidean crease), is still absent. Herein we provide a unified geometricframework that describes the shape of a generic curved-fold origami composed oftwo general strips. The explicit description indicates that four configurationsemerge, determined by its spatial crease and configuration branch. Within thisgeometric framework, we derive the equilibrium equations and study themechanical response of the curved-crease origami, focusing on Euler's bucklingbehavior. Both linear stability analysis and finite element simulation indicatethat the overlaid configuration exhibits a lower buckling threshold. To furthercapture the large deformation behavior efficiently, we develop a bistrip modelbased on the anisotropic Kirchhoff rod theory, which predicts the main featuressuccessfully. This work bridges the geometry and mechanics of curved-creaseorigami, offering insights for applications in robotics, actuators, anddeployable space structures.</description>
      <author>example@mail.com (Zhixuan Wen, Tian Yu, Fan Feng)</author>
      <guid isPermaLink="false">2502.20147v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Discovering Antagonists in Networks of Systems: Robot Deployment</title>
      <link>http://arxiv.org/abs/2502.20125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于上下文的异常检测方法，应用于执行覆盖任务的机器人集群的物理运动。&lt;h4&gt;背景&lt;/h4&gt;在模拟环境中训练正常行为数据以识别对抗性行为或异常情况。&lt;h4&gt;目的&lt;/h4&gt;通过使用机器学习模型预测机器人动作的可能范围来识别执行特定任务时出现的异常情况。&lt;h4&gt;方法&lt;/h4&gt;利用正态流(normalizing flow)预测机器人运动的可能性，并根据此概率判断机器人是正常的还是对抗性的。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在五种不同的对抗性行为策略中表现良好，准确分类至少80%的每一种对抗类型，同时保持低于5%的假阳性率。此外，硬件实验验证了与模拟场景相似的结果。&lt;h4&gt;结论&lt;/h4&gt;相较于现有最佳的方法，本文提出的方法提高了预测性能，并增强了检测标准的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：提出了上下文异常检测方法并应用于执行覆盖任务时机器人集群的物理运动。通过模拟正常行为的数据训练正态流以预测给定环境下机器人的动作可能性。在应用中，利用观察到的动作预测概率来判断机器人是否属于正常或对抗性质的行为。该方法对五种不同的对抗策略进行评估，仅使用正常机器人行为的仿真数据进行训练，在未知异常本质的情况下实现了至少80%以上的准确率分类，并保持低于5%的假阳性率。另外通过硬件实验进一步验证了这一发现。相比现有最佳的方法，本文所提出的模型在预测性能和检测标准的鲁棒性上均有所提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A contextual anomaly detection method is proposed and applied to the physicalmotions of a robot swarm executing a coverage task. Using simulations of aswarm's normal behavior, a normalizing flow is trained to predict thelikelihood of a robot motion within the current context of its environment.During application, the predicted likelihood of the observed motions is used bya detection criterion that categorizes a robot agent as normal or antagonistic.The proposed method is evaluated on five different strategies of antagonisticbehavior. Importantly, only readily available simulated data of normal robotbehavior is used for training such that the nature of the anomalies need not beknown beforehand. The best detection criterion correctly categorizes at least80% of each antagonistic type while maintaining a false positive rate of lessthan 5% for normal robot agents. Additionally, the method is validated inhardware experiments, yielding results similar to the simulated scenarios.Compared to the state-of-the-art approach, both the predictive performance ofthe normalizing flow and the robustness of the detection criterion areincreased.</description>
      <author>example@mail.com (Ingeborg Wenger, Peter Eberhard, Henrik Ebel)</author>
      <guid isPermaLink="false">2502.20125v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>VDT-Auto: End-to-end Autonomous Driving with VLM-Guided Diffusion Transformers</title>
      <link>http://arxiv.org/abs/2502.20108v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一个新的自主驾驶决策制定管道VDT-Auto，它通过结合视觉语言模型（VLM）的状态理解和基于扩散Transformer的动作生成来解决动态环境和边缘情况带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶中，动态的环境因素和边角案例对车辆决策系统的鲁棒性构成重大挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种新的方法以提升自主驾驶系统应对复杂和变化环境的能力，增强其在各种条件下的稳健性和性能表现。&lt;h4&gt;方法&lt;/h4&gt;该方法首先通过鸟瞰图（BEV）编码器提取周围图像的特征网格，并利用经过微调的视觉语言模型（VLM）生成文本嵌入和噪声路径。然后使用这些输出作为扩散过程中的正向和反向过程的条件。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，该系统在nuScenes开放环规划评估中平均L2误差为0.52米，并且碰撞率为21%，展示了其卓越的一般性能。&lt;h4&gt;结论&lt;/h4&gt;VDT-Auto不仅通过开放数据集和代码发布的途径促进了研究界的进一步探索与改进，还证明了视觉语言模型（VLM）在自动驾驶决策制定中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于一种新的用于提高自动驾驶系统鲁棒性的方法的描述。该方法利用视觉语言模型来理解环境，并生成相应的动作策略。实验结果显示其具有良好的性能和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In autonomous driving, dynamic environment and corner cases pose significantchallenges to the robustness of ego vehicle's decision-making. To address thesechallenges, commencing with the representation of state-action mapping in theend-to-end autonomous driving paradigm, we introduce a novel pipeline,VDT-Auto. Leveraging the advancement of the state understanding of VisualLanguage Model (VLM), incorporating with diffusion Transformer-based actiongeneration, our VDT-Auto parses the environment geometrically and contextuallyfor the conditioning of the diffusion process. Geometrically, we use abird's-eye view (BEV) encoder to extract feature grids from the surroundingimages. Contextually, the structured output of our fine-tuned VLM is processedinto textual embeddings and noisy paths. During our diffusion process, theadded noise for the forward process is sampled from the noisy path output ofthe fine-tuned VLM, while the extracted BEV feature grids and embedded textscondition the reverse process of our diffusion Transformers. Our VDT-Autoachieved 0.52m on average L2 errors and 21% on average collision rate in thenuScenes open-loop planning evaluation. Moreover, the real-world demonstrationexhibited prominent generalizability of our VDT-Auto. The code and dataset willbe released after acceptance.</description>
      <author>example@mail.com (Ziang Guo, Konstantin Gubernatorov, Selamawit Asfaw, Zakhar Yagudin, Dzmitry Tsetserukou)</author>
      <guid isPermaLink="false">2502.20108v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Pushing Through Clutter With Movability Awareness of Blocking Obstacles</title>
      <link>http://arxiv.org/abs/2502.20106v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages (6+1), 5 images, 1 table, preprint version of accepted paper  at ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出一种考虑可移动障碍物的路径规划框架，通过结合全局语义可见性图和局部模型预测路径积分方法来应对传统路径规划方法在面对被阻挡路径时的挑战。&lt;h4&gt;背景&lt;/h4&gt;当障碍物阻塞了到达目标的路径时，传统的路径规划方法难以处理需要推动动作的情况。&lt;h4&gt;目的&lt;/h4&gt;提出一种不依赖于显式障碍物放置信息的方法框架，以克服NAMO问题中的挑战。&lt;h4&gt;方法&lt;/h4&gt;引入全局语义可见性图和局部模型预测路径积分（SVG-MPPI）方法相结合的策略来有效采样滚动，并考虑可移动物体在整个连续范围内的移动情况。采用物理引擎模拟滚动与环境的交互结果，生成最小化接触力的轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;在定性和定量实验中，SVG-MPPI框架的表现优于仅使用二进制可移动性的现有规划方法，在成功率和减少累积接触力方面都取得了更好的成绩。&lt;h4&gt;结论&lt;/h4&gt;所提出的SVG-MPPI框架提供了一种新颖的方法来处理具有可移动障碍物的导航问题，并且其代码已经在GitHub上公开供他人参考。&lt;h4&gt;翻译&lt;/h4&gt;对于在传统路径规划中遇到的由可移动障碍物导致的问题，我们提出了一套新的解决方案，该方案结合了全局语义可见性图和局部模型预测路径积分技术。通过使用物理引擎来模拟滚动与环境之间的交互，生成最小化接触力的最佳轨迹，并取得了优于现有方法的成绩。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Navigation Among Movable Obstacles (NAMO) poses a challenge for traditionalpath-planning methods when obstacles block the path, requiring push actions toreach the goal. We propose a framework that enables movability-aware planningto overcome this challenge without relying on explicit obstacle placement. Ourframework integrates a global Semantic Visibility Graph and a local ModelPredictive Path Integral (SVG-MPPI) approach to efficiently sample rollouts,taking into account the continuous range of obstacle movability. A physicsengine is adopted to simulate the interaction result of the rollouts with theenvironment, and generate trajectories that minimize contact force. Inqualitative and quantitative experiments, SVG-MPPI outperforms the existingparadigm that uses only binary movability for planning, achieving highersuccess rates with reduced cumulative contact forces. Our code is available at:https://github.com/tud-amr/SVG-MPPI</description>
      <author>example@mail.com (Joris J. Weeda, Saray Bakker, Gang Chen, Javier Alonso-Mora)</author>
      <guid isPermaLink="false">2502.20106v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>RIZE: Regularized Imitation Learning via Distributional Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.20089v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新颖的逆向强化学习（IRL）方法，该方法通过扩展最大熵IRL框架并引入平方时差(TD)正则化器和自适应目标来优化奖励函数。&lt;h4&gt;背景&lt;/h4&gt;现有的固定奖励分配方式存在局限性，难以保证灵活且可约束的隐式奖励正则化的灵活性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的IRL方法，以克服现有方法中的限制，并在模仿学习中提供对动态目标和奖励机制的有效理解。&lt;h4&gt;方法&lt;/h4&gt;通过结合最大熵IRL框架、自适应目标以及分布式的强化学习技术来优化奖励函数。具体地，引入了平方时差(TD)正则化器，该组件允许在训练过程中动态调整目标。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法在具有挑战性的MuJoCo任务上展示了最先进的性能，在Humanoid任务中仅通过三个演示就达到了专家级别的结果。&lt;h4&gt;结论&lt;/h4&gt;广泛的实验和消融研究验证了所提方法的有效性，并提供了对模仿学习中自适应目标和奖励动态的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel Inverse Reinforcement Learning (IRL) approach thatovercomes limitations of fixed reward assignments and constrained flexibilityin implicit reward regularization. By extending the Maximum Entropy IRLframework with a squared temporal-difference (TD) regularizer and adaptivetargets, dynamically adjusted during training, our method indirectly optimizesa reward function while incorporating reinforcement learning principles.Furthermore, we integrate distributional RL to capture richer returninformation. Our approach achieves state-of-the-art performance on challengingMuJoCo tasks, demonstrating expert-level results on the Humanoid task with only3 demonstrations. Extensive experiments and ablation studies validate theeffectiveness of our method, providing insights into adaptive targets andreward dynamics in imitation learning.</description>
      <author>example@mail.com (Adib Karimi, Mohammad Mehdi Ebadzadeh)</author>
      <guid isPermaLink="false">2502.20089v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Minds on the Move: Decoding Trajectory Prediction in Autonomous Driving with Cognitive Insights</title>
      <link>http://arxiv.org/abs/2502.20084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;在混合自主驾驶环境中，准确预测周围车辆的未来轨迹对于自动驾驶汽车的安全运行至关重要。该研究提出了一种新的认知启发型变压器（Cognitive-Informed Transformer, CITF），通过引入感知安全概念来理解驾驶员的决策机制。&lt;h4&gt;背景&lt;/h4&gt;现有模型主要关注数据中的统计模式，忽略了理解和解释人类驾驶者的决策过程的重要性，这导致了模型在长期轨迹预测方面的性能不足。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的模型CITF，该模型能够捕捉到人类驾驶员真实意图，并提高长期轨迹预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的模块Leanformer来捕获车辆之间的社会互动。此外，还设计了一个感知安全感知模块，包括定量安全评估和驾驶行为特征描述。&lt;h4&gt;主要发现&lt;/h4&gt;CITF模型在三个公认的基准数据集上显示出显著性能提升：NGSIM（12.0%），HighD（28.2%）以及MoCAD（20.8%）。此外，在数据有限或缺失的情况下，该模型也表现出强大的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;CITF不仅在现有的基准测试中表现优异，并且展示了对现实世界应用的适应性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文内容。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In mixed autonomous driving environments, accurately predicting the futuretrajectories of surrounding vehicles is crucial for the safe operation ofautonomous vehicles (AVs). In driving scenarios, a vehicle's trajectory isdetermined by the decision-making process of human drivers. However, existingmodels primarily focus on the inherent statistical patterns in the data, oftenneglecting the critical aspect of understanding the decision-making processesof human drivers. This oversight results in models that fail to capture thetrue intentions of human drivers, leading to suboptimal performance inlong-term trajectory prediction. To address this limitation, we introduce aCognitive-Informed Transformer (CITF) that incorporates a cognitive concept,Perceived Safety, to interpret drivers' decision-making mechanisms. PerceivedSafety encapsulates the varying risk tolerances across drivers with differentdriving behaviors. Specifically, we develop a Perceived Safety-aware Modulethat includes a Quantitative Safety Assessment for measuring the subject risklevels within scenarios, and Driver Behavior Profiling for characterizingdriver behaviors. Furthermore, we present a novel module, Leanformer, designedto capture social interactions among vehicles. CITF demonstrates significantperformance improvements on three well-established datasets. In terms oflong-term prediction, it surpasses existing benchmarks by 12.0% on the NGSIM,28.2% on the HighD, and 20.8% on the MoCAD dataset. Additionally, itsrobustness in scenarios with limited or missing data is evident, surpassingmost state-of-the-art (SOTA) baselines, and paving the way for real-worldapplications.</description>
      <author>example@mail.com (Haicheng Liao, Chengyue Wang, Kaiqun Zhu, Yilong Ren, Bolin Gao, Shengbo Eben Li, Chengzhong Xu, Zhenning Li)</author>
      <guid isPermaLink="false">2502.20084v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>BEV-DWPVO: BEV-based Differentiable Weighted Procrustes for Low Scale-drift Monocular Visual Odometry on Ground</title>
      <link>http://arxiv.org/abs/2502.20078v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BEV-DWPVO的新型单目视觉测距系统，该系统利用鸟瞰图（Bird's-Eye View, BEV）特征地图以统一尺度表示环境，简化姿态估计过程，并通过可微加权Procrustes求解器进行姿态估计。&lt;h4&gt;背景&lt;/h4&gt;单目视觉测距(MVO)为自动驾驶车辆提供了一种成本效益高、实时定位解决方案。然而，由于缺乏来自单目相机的内在尺度信息，MVO系统面临共同问题。传统的MVO方法虽然具有良好的解释性，但只能获得相对比例，并且在长距离任务中会出现严重的比例漂移。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的MVO系统BEV-DWPVO，以解决传统MVO方法存在的局限性和挑战，提高其性能和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;采用鸟瞰图（BEV）特征地图表示环境，并假设地面为平面。通过在统一尺度的网格结构中提取并匹配关键点，利用可微加权Procrustes求解器进行姿态估计。整个系统完全可微，仅需姿态监督即可端到端训练。&lt;h4&gt;主要发现&lt;/h4&gt;提出的BEV-DWPVO方法在长序列数据集NCLT、牛津和KITTI上的表现优于现有的MVO方法，在大多数评估指标上取得了卓越的成绩。&lt;h4&gt;结论&lt;/h4&gt;通过使用鸟瞰图特征地图和可微加权Procrustes求解器，新系统BEV-DWPVO成功地解决了传统MVO系统的局限性，并在实际测试中展示了优越的性能。这种方法为未来的自动驾驶车辆定位提供了一种新的有效途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：单目视觉测距(MVO)为自主车辆提供了一种成本效益高、实时定位解决方案。然而，由于来自单目相机缺乏内在尺度信息，MVO系统面临共同问题。传统的MVO方法虽然具有良好的解释性，但只能获得相对比例，并且在长距离任务中会出现严重的比例漂移。基于学习的方法利用透视视角，通过大量训练数据获取先验知识并预测深度值以估计绝对比例。然而，由于需要准确估计每个点的深度，这种方法泛化能力有限。相比之下，我们提出了一种新的MVO系统称为BEV-DWPVO。我们的方法使用地面平面的共同假设，并通过鸟瞰图（BEV）特征地图表示环境，在统一尺度下的网格结构中简化姿态估计过程从6自由度到3自由度。关键点在BEV空间内被提取和匹配，随后通过可微加权Procrustes求解器进行姿态估计。整个系统完全可微，仅需姿态监督即可端到端训练，无需辅助任务。我们在挑战性的长序列数据集NCLT、牛津和KITTI上验证了BEV-DWPVO，并在大多数评估指标中超越现有MVO方法取得卓越结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular Visual Odometry (MVO) provides a cost-effective, real-timepositioning solution for autonomous vehicles. However, MVO systems face thecommon issue of lacking inherent scale information from monocular cameras.Traditional methods have good interpretability but can only obtain relativescale and suffer from severe scale drift in long-distance tasks. Learning-basedmethods under perspective view leverage large amounts of training data toacquire prior knowledge and estimate absolute scale by predicting depth values.However, their generalization ability is limited due to the need to accuratelyestimate the depth of each point. In contrast, we propose a novel MVO systemcalled BEV-DWPVO. Our approach leverages the common assumption of a groundplane, using Bird's-Eye View (BEV) feature maps to represent the environment ina grid-based structure with a unified scale. This enables us to reduce thecomplexity of pose estimation from 6 Degrees of Freedom (DoF) to 3-DoF.Keypoints are extracted and matched within the BEV space, followed by poseestimation through a differentiable weighted Procrustes solver. The entiresystem is fully differentiable, supporting end-to-end training with only posesupervision and no auxiliary tasks. We validate BEV-DWPVO on the challenginglong-sequence datasets NCLT, Oxford, and KITTI, achieving superior results overexisting MVO methods on most evaluation metrics.</description>
      <author>example@mail.com (Yufei Wei, Sha Lu, Wangtao Lu, Rong Xiong, Yue Wang)</author>
      <guid isPermaLink="false">2502.20078v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>HiFAR: Multi-Stage Curriculum Learning for High-Dynamics Humanoid Fall Recovery</title>
      <link>http://arxiv.org/abs/2502.20061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种针对人形机器人跌倒恢复的多阶段课程学习框架HiFAR，该框架通过逐步增加复杂性和维度来解决传统控制方法和强化学习技术在处理高维动力学和复杂碰撞场景方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;当前的人形机器人难以自主地从跌倒中恢复过来，尤其是面对动态且无结构的环境。传统的控制方法通常无法应对这些挑战，而基于强化学习的方法则受到稀疏奖励、复杂的碰撞情景以及仿真与实际应用之间差异的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架来帮助人形机器人有效地处理各种类型的跌倒场景，并能够适应现实世界的跌倒情况。&lt;h4&gt;方法&lt;/h4&gt;使用了一种名为HiFAR的多阶段课程学习框架，该框架采用分阶段的学习策略逐步引入更为复杂和高维的恢复任务。通过这种方式让机器人在不同情况下掌握高效且稳定的跌倒恢复策略。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法经过实际的人形机器人的测试，展示了其能够自主地从多种跌倒情况中快速而稳定地恢复过来，并具有较高的成功率、较快的恢复时间和较强的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究结果表明，HiFAR框架为解决人形机器人跌倒恢复问题提供了一种有效的方法。这种方法不仅提高了机器人的适应性和稳定性，还大大增强了其自主应对复杂环境的能力。&lt;h4&gt;翻译&lt;/h4&gt;人形机器人在动态和无结构环境中从跌倒中自主恢复面临巨大挑战。传统的控制方法不足以处理高维动力学和密集接触的特点，而强化学习技术则受到稀疏奖励、复杂碰撞场景以及模拟与现实应用差异的困扰。本文提出了一种名为HiFAR的多阶段课程学习框架，通过逐步纳入更加复杂的跌倒恢复任务来帮助机器人获取高效且稳定的策略。该方法已在实际的人形机器人体上进行了测试，并证明了其在跌倒恢复上的自主性、快速性和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humanoid robots encounter considerable difficulties in autonomouslyrecovering from falls, especially within dynamic and unstructured environments.Conventional control methodologies are often inadequate in addressing thecomplexities associated with high-dimensional dynamics and the contact-richnature of fall recovery. Meanwhile, reinforcement learning techniques arehindered by issues related to sparse rewards, intricate collision scenarios,and discrepancies between simulation and real-world applications. In thisstudy, we introduce a multi-stage curriculum learning framework, termed HiFAR.This framework employs a staged learning approach that progressivelyincorporates increasingly complex and high-dimensional recovery tasks, therebyfacilitating the robot's acquisition of efficient and stable fall recoverystrategies. Furthermore, it enables the robot to adapt its policy toeffectively manage real-world fall incidents. We assess the efficacy of theproposed method using a real humanoid robot, showcasing its capability toautonomously recover from a diverse range of falls with high success rates,rapid recovery times, robustness, and generalization.</description>
      <author>example@mail.com (Penghui Chen, Yushi Wang, Changsheng Luo, Wenhan Cai, Mingguo Zhao)</author>
      <guid isPermaLink="false">2502.20061v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Night-Voyager: Consistent and Efficient Nocturnal Vision-Aided State Estimation in Object Maps</title>
      <link>http://arxiv.org/abs/2502.20054v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Transactions on Robotics (T-RO), 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;夜间准确且稳健的状态估计对于实现自主机器人导航的昼夜或全天候任务至关重要。本文提出了一个利用先验对象地图和关键点进行夜视辅助状态估计的新框架Night-Voyager。&lt;h4&gt;背景&lt;/h4&gt;现有大多数视觉方法在不良照明条件下可能失败，即使使用主动光源或图像增强也难以克服这一问题。然而，在多数城市场景中，路灯作为稳定的显著前导视觉线索，在夜间导航中起到了类似深空星星的作用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的夜视辅助状态估计框架Night-Voyager，该框架可以利用先验对象地图和关键点信息实现灵活的定位。&lt;h4&gt;方法&lt;/h4&gt;Night-Voyager通过快速初始化解决全局定位问题，并采用有效的两阶段跨模态数据关联技术来提供基于地图观测的整体一致性状态更新。此外，在处理夜间视觉观察中显著不确定性的挑战时，引入了新颖的矩阵李群公式化和特征解耦多态不变滤波器。&lt;h4&gt;主要发现&lt;/h4&gt;传统的视觉方法在照明条件不佳的情况下依赖像素级度量作为其最主要的限制，而Night-Voyager利用非像素级的对象检测来促进对象地图信息的有效传播与使用。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的仿真及多样化的实际应用场景（覆盖约12.3公里）的实验验证了Night-Voyager的有效性、鲁棒性和效率，填补了夜间视觉辅助状态估计的重要空白。&lt;h4&gt;翻译&lt;/h4&gt;准确且稳健的夜间状态估计对于实现昼夜或全天候任务下的自主机器人导航至关重要。是否可以利用低成本的标准相机进行夜间环境的状态估计？现有的大多数视觉方法在不良照明条件下难以发挥作用，即使使用主动光源或图像增强也是如此。然而，在多数城市环境中，路灯作为夜晚稳定的显著先验视觉线索起到了类似星星在深空为航天器提供导航的作用。受到这一启发，我们提出了一种新的夜视辅助状态估计框架Night-Voyager，利用先前对象地图和关键点进行灵活的定位。研究发现传统的视觉方法依赖于像素级别的度量标准作为其主要限制，在不良照明条件下表现不佳。相比之下，非像素级、无度量的对象检测可以充当从像素级别到对象级别的桥梁，促进系统内部对象地图信息的有效传播与使用。Night-Voyager通过快速初始化解决全局定位问题，并利用基于地图的观察提供整体一致性状态更新。为了应对夜间视觉观测中的显著不确定性挑战，引入了新颖的矩阵李群公式化和特征解耦多态不变滤波器以确保一致且高效的估计结果。在广泛的仿真及多样化的实际应用场景（覆盖约12.3公里）中展示其有效性、鲁棒性和效率，弥补了夜视辅助状态估计的重要不足之处。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and robust state estimation at nighttime is essential for autonomousrobotic navigation to achieve nocturnal or round-the-clock tasks. An intuitivequestion arises: Can low-cost standard cameras be exploited for nocturnal stateestimation? Regrettably, most existing visual methods may fail under adverseillumination conditions, even with active lighting or image enhancement. Apivotal insight, however, is that streetlights in most urban scenarios act asstable and salient prior visual cues at night, reminiscent of stars in deepspace aiding spacecraft voyage in interstellar navigation. Inspired by this, wepropose Night-Voyager, an object-level nocturnal vision-aided state estimationframework that leverages prior object maps and keypoints for versatilelocalization. We also find that the primary limitation of conventional visualmethods under poor lighting conditions stems from the reliance on pixel-levelmetrics. In contrast, metric-agnostic, non-pixel-level object detection servesas a bridge between pixel-level and object-level spaces, enabling effectivepropagation and utilization of object map information within the system.Night-Voyager begins with a fast initialization to solve the globallocalization problem. By employing an effective two-stage cross-modal dataassociation, the system delivers globally consistent state updates usingmap-based observations. To address the challenge of significant uncertaintiesin visual observations at night, a novel matrix Lie group formulation and afeature-decoupled multi-state invariant filter are introduced, ensuringconsistent and efficient estimation. Through comprehensive experiments in bothsimulation and diverse real-world scenarios (spanning approximately 12.3 km),Night-Voyager showcases its efficacy, robustness, and efficiency, filling acritical gap in nocturnal vision-aided state estimation.</description>
      <author>example@mail.com (Tianxiao Gao, Mingle Zhao, Chengzhong Xu, Hui Kong)</author>
      <guid isPermaLink="false">2502.20054v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>3D-AffordanceLLM: Harnessing Large Language Models for Open-Vocabulary Affordance Detection in 3D Worlds</title>
      <link>http://arxiv.org/abs/2502.20041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的3D可及性检测框架，该框架通过引入大规模语言模型并设计定制化解码器来生成可及性掩模，解决了传统基于标签的语义分割方法在开放场景中的局限性。&lt;h4&gt;背景&lt;/h4&gt;传统的3D可及性检测依赖于预定义标签进行基于语义分割的任务，并且难以理解复杂的自然语言描述。这种范式在处理开放式复杂场景时存在泛化能力不足的问题。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有技术的限制，提出了一种新的任务形式——指令推理可及性分割（IRAS），该任务旨在根据给定的查询文本生成可及性掩模区域。&lt;h4&gt;方法&lt;/h4&gt;提出一种名为3D-AffordanceLLM (3D-ADLLM) 的新框架。它通过引入大规模语言模型并设计定制化解码器来实现开放世界的推理式可及性检测，并采用多阶段训练策略，包括Referring Object Part Segmentation任务的预训练。&lt;h4&gt;主要发现&lt;/h4&gt;在缺乏足够的3D可及性数据集的情况下，该方法利用通用分割数据提取知识并转移到可及性检测中。通过这种创新的方法和框架设计，在开放词汇量的可及性检测任务上实现了大约8% mIoU的改进。&lt;h4&gt;结论&lt;/h4&gt;所提出的3D-ADLLM框架充分利用了大规模语言模型中的丰富世界知识和人与物体互动推理能力，证明在处理开放世界的复杂场景时具有优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Affordance detection is a challenging problem with broad applications onvarious robotic tasks. Existing methods typically formulate the detectionparadigm as a label-based semantic segmentation task. This paradigm relies onpredefined labels and lacks the ability to comprehend complex natural language,resulting in limited generalization in open-world scene. To address theselimitations, we reformulate the traditional affordance detection paradigm into\textit{Instruction Reasoning Affordance Segmentation} (IRAS) task. This taskis designed to output a affordance mask region given a query reasoning text,which avoids fixed categories of input labels. We accordingly propose the\textit{3D-AffordanceLLM} (3D-ADLLM), a framework designed for reasoningaffordance detection in 3D open-scene. Specifically, 3D-ADLLM introduces largelanguage models (LLMs) to 3D affordance perception with a custom-designeddecoder for generating affordance masks, thus achieving open-world reasoningaffordance detection. In addition, given the scarcity of 3D affordance datasetsfor training large models, we seek to extract knowledge from generalsegmentation data and transfer it to affordance detection. Thus, we propose amulti-stage training strategy that begins with a novel pre-training task, i.e.,\textit{Referring Object Part Segmentation}~(ROPS). This stage is designed toequip the model with general recognition and segmentation capabilities at theobject-part level. Then followed by fine-tuning with the IRAS task, 3D-ADLLMobtains the reasoning ability for affordance detection. In summary, 3D-ADLLMleverages the rich world knowledge and human-object interaction reasoningability of LLMs, achieving approximately an 8\% improvement in mIoU onopen-vocabulary affordance detection tasks.</description>
      <author>example@mail.com (Hengshuo Chu, Xiang Deng, Xiaoyang Chen, Yinchuan Li, Jianye Hao, Liqiang Nie)</author>
      <guid isPermaLink="false">2502.20041v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>FuseGrasp: Radar-Camera Fusion for Robotic Grasping of Transparent Objects</title>
      <link>http://arxiv.org/abs/2502.20037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为FuseGrasp的系统，该系统是首个雷达和相机融合技术应用于透明物体抓取的技术。通过毫米波信号和深度学习网络的有效结合，改进了机器人在低光环境下的性能。&lt;h4&gt;背景&lt;/h4&gt;透明物品在日常生活环境中普遍存在，但它们独特的物理特性给依靠摄像机引导的机械臂带来了挑战。现有研究主要依赖于单独使用相机的方法，在光照不足等条件下效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够增强抓取透明物体能力的雷达-相机融合系统，以提高机器人操作透明物品的成功率和准确性。&lt;h4&gt;方法&lt;/h4&gt;利用毫米波信号可以穿透透明材料并使其呈现半透明或不透明的特点，结合摄像机数据获取高质量的雷达图像，并设计了一个深度神经网络来融合这两种模式的数据。采用两阶段训练策略解决缺乏雷达图像的问题：首先在公共RGB-D数据集上预训练系统，然后使用小规模自建的RGB-D-Radar数据集进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示FuseGrasp显著提高了透明物体的深度重建精度和材料识别能力，在真实世界中验证了其处理透明物品的能力增强。&lt;h4&gt;结论&lt;/h4&gt;通过雷达-相机融合技术，可以有效提高机器人对环境感知能力和操作效率，尤其在低光条件下性能更优。这项工作为未来的机器人系统开发提供了新的方向。&lt;h4&gt;视频链接&lt;/h4&gt;https://youtu.be/MWDqv0sRSok&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transparent objects are prevalent in everyday environments, but theirdistinct physical properties pose significant challenges for camera-guidedrobotic arms. Current research is mainly dependent on camera-only approaches,which often falter in suboptimal conditions, such as low-light environments. Inresponse to this challenge, we present FuseGrasp, the first radar-camera fusionsystem tailored to enhance the transparent objects manipulation. FuseGraspexploits the weak penetrating property of millimeter-wave (mmWave) signals,which causes transparent materials to appear opaque, and combines it with theprecise motion control of a robotic arm to acquire high-quality mmWave radarimages of transparent objects. The system employs a carefully designed deepneural network to fuse radar and camera imagery, thereby improving depthcompletion and elevating the success rate of object grasping. Nevertheless,training FuseGrasp effectively is non-trivial, due to limited radar imagedatasets for transparent objects. We address this issue utilizing large RGB-Ddataset, and propose an effective two-stage training approach: we firstpre-train FuseGrasp on a large public RGB-D dataset of transparent objects,then fine-tune it on a self-built small RGB-D-Radar dataset. Furthermore, as abyproduct, FuseGrasp can determine the composition of transparent objects, suchas glass or plastic, leveraging the material identification capability ofmmWave radar. This identification result facilitates the robotic arm inmodulating its grip force appropriately. Extensive testing reveals thatFuseGrasp significantly improves the accuracy of depth reconstruction andmaterial identification for transparent objects. Moreover, real-world robotictrials have confirmed that FuseGrasp markedly enhances the handling oftransparent items. A video demonstration of FuseGrasp is available athttps://youtu.be/MWDqv0sRSok.</description>
      <author>example@mail.com (Hongyu Deng, Tianfan Xue, He Chen)</author>
      <guid isPermaLink="false">2502.20037v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Keypoint Affordance Representation for Functional Dexterous Grasping</title>
      <link>http://arxiv.org/abs/2502.20018v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The source code and demo videos will be publicly available at  https://github.com/PopeyePxx/MKA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本研究提出了一种用于功能灵巧抓握的多关键点作用表示法，直接编码任务驱动的抓取配置，并通过接触引导的关键点提取方法实现了视觉感知和灵巧操作之间的直接连接。&lt;h4&gt;背景&lt;/h4&gt;现有的基于作用的方法主要预测粗略交互区域，无法直接约束抓取姿势，导致视觉感知与操纵之间存在断开。&lt;h4&gt;目的&lt;/h4&gt;为了弥合这一差距，我们提出了一个多关键点作用表示法来解决现有方法在预测精细交互方面的问题，并通过引入Contact-guided Multi-Keypoint Affordance (CMKA) 方法和基于关键点的抓握矩阵转换(KGT)方法改进了抓取的一致性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种多关键点作用表示法，利用人类抓握经验图像进行弱监督，并结合大型视觉模型提取精细的作用特征。此外，还提出了一种基于关键点的抓握手性变换（KGT）方法，确保手部关键点与物体接触点之间的空间一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法显著提高了作用定位精度、抓握一致性和对未知工具和任务的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本研究为视觉作用学习与灵巧机器人操作之间建立了桥梁，展示了在真实世界数据集、IsaacGym仿真环境及具有挑战性的机器人任务中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;功能性灵巧抓握需要精确的手-物体交互，超越简单的夹持。现有基于作用的方法主要预测粗略的交互区域，并且无法直接约束抓取姿势，导致视觉感知与操作之间存在断开。为解决这一问题，我们提出了一种用于功能灵巧抓握的多关键点作用表示法，该方法通过定位功能性接触点直接编码任务驱动的抓取配置。此外，还引入了Contact-guided Multi-Keypoint Affordance (CMKA) 方法，并结合大型视觉模型进行弱监督和精细的作用特征提取，实现泛化同时避免手动的关键点注释。另外提出了一种基于关键点的手部矩阵变换(KGT)方法，确保手部关键点与物体接触点之间的空间一致性，从而为视觉感知和灵巧抓握动作之间建立了直接连接。在公共真实世界FAH数据集、IsaacGym仿真及具有挑战性的机器人任务上的实验表明，我们的方法显著提高了作用定位精度、抓取一致性和对未知工具和任务的泛化能力，弥合了视觉作用学习与灵巧机器人操作之间的差距。源代码和演示视频将在https://github.com/PopeyePxx/MKA公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Functional dexterous grasping requires precise hand-object interaction, goingbeyond simple gripping. Existing affordance-based methods primarily predictcoarse interaction regions and cannot directly constrain the grasping posture,leading to a disconnection between visual perception and manipulation. Toaddress this issue, we propose a multi-keypoint affordance representation forfunctional dexterous grasping, which directly encodes task-driven graspconfigurations by localizing functional contact points. Our method introducesContact-guided Multi-Keypoint Affordance (CMKA), leveraging human graspingexperience images for weak supervision combined with Large Vision Models forfine affordance feature extraction, achieving generalization while avoidingmanual keypoint annotations. Additionally, we present a Keypoint-based Graspmatrix Transformation (KGT) method, ensuring spatial consistency between handkeypoints and object contact points, thus providing a direct link betweenvisual perception and dexterous grasping actions. Experiments on publicreal-world FAH datasets, IsaacGym simulation, and challenging robotic tasksdemonstrate that our method significantly improves affordance localizationaccuracy, grasp consistency, and generalization to unseen tools and tasks,bridging the gap between visual affordance learning and dexterous roboticmanipulation. The source code and demo videos will be publicly available athttps://github.com/PopeyePxx/MKA.</description>
      <author>example@mail.com (Fan Yang, Dongsheng Luo, Wenrui Chen, Jiacheng Lin, Junjie Cai, Kailun Yang, Zhiyong Li, Yaonan Wang)</author>
      <guid isPermaLink="false">2502.20018v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Collaborative Object Handover in a Robot Crafting Assistant</title>
      <link>http://arxiv.org/abs/2502.19991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个通过人类遥操作数据训练的合作交接模型，旨在提高机器人与人合作时的安全性和效率。&lt;h4&gt;背景&lt;/h4&gt;随着机器人的普及，它们越来越多地参与到需要与人类互动的工作中，例如在餐厅里递送食物或在装配线上帮助工人。这些场景通常涉及物品的交接过程。&lt;h4&gt;目的&lt;/h4&gt;为了实现安全和高效的协作机器人系统（HRC），有必要将人类行为上下文融入到机器人的合作策略当中。&lt;h4&gt;方法&lt;/h4&gt;研究人员开发了一种基于自然手工任务中的遥操作数据训练的合作交接模型，并通过交叉验证实验以及用户研究来评估该模型的表现。&lt;h4&gt;主要发现&lt;/h4&gt;自主政策成功实现了协作性交接，但在与人类遥操作的比较中揭示了进一步改进的空间。&lt;h4&gt;结论&lt;/h4&gt;虽然研究表明该合作交接策略能够有效实现机器人和人之间的安全高效的协作，但仍存在改善潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robots are increasingly working alongside people, delivering food to patronsin restaurants or helping workers on assembly lines. These scenarios ofteninvolve object handovers between the person and the robot. To achieve safe andefficient human-robot collaboration (HRC), it is important to incorporate humancontext in a robot's handover strategies. Therefore, in this work, we develop acollaborative handover model trained on human teleoperation data collected in anaturalistic crafting task. To evaluate the performance of this model, weconduct cross-validation experiments on the training dataset as well as a userstudy in the same HRC crafting task. The handover episodes and user perceptionsof the autonomous handover policy were compared with those of the humanteleoperated handovers. While the cross-validation experiment and user studyindicate that the autonomous policy successfully achieved collaborativehandovers, the comparison with human teleoperation revealed avenues for furtherimprovements.</description>
      <author>example@mail.com (Leimin Tian, Shiyu Xu, Kerry He, Rachel Love, Akansel Cosgun, Dana Kulic)</author>
      <guid isPermaLink="false">2502.19991v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>CarPlanner: Consistent Auto-regressive Trajectory Planning for Large-scale Reinforcement Learning in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2502.19908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CarPlanner是一种基于强化学习（RL）的轨迹规划器，旨在解决自动驾驶中的训练效率和性能提升问题。&lt;h4&gt;背景&lt;/h4&gt;当前，虽然一些基于机器学习的方法在特定场景中表现出色，但它们难以应对大规模、复杂的真实驾驶环境挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多模态轨迹生成方法——CarPlanner，该方法结合了自回归结构和一致性机制以提高训练效率并增强性能稳定性。&lt;h4&gt;方法&lt;/h4&gt;1. CarPlanner采用了自回归的强化学习框架。2. 通过一致性的引入来维护时间序列的一致性，从而稳定策略的学习过程。3. 利用专家指导奖励函数和不变视图模块简化RL训练流程。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在nuPlan大规模真实世界数据集上超越了现有基于规则、强化学习和模仿学习的方法，展示了其优越的性能。&lt;h4&gt;结论&lt;/h4&gt;CarPlanner作为一个潜在解决方案，在自动驾驶轨迹规划中显示出巨大潜力。它有效地解决了大规模真实场景下的训练效率问题，并且能够在挑战性任务中超越当前最先进的方法。&lt;h4&gt;翻译&lt;/h4&gt;路径规划是自主驾驶的关键组成部分，用于确保复杂环境中的安全高效导航。尽管最近基于学习的方法——特别是强化学习（RL）在特定情况下取得了显著成果，但它们仍然难以克服大规模现实世界场景下的训练效率问题。为此，我们引入了CarPlanner，这是一种自回归式轨迹生成器，它利用RL来生成多模态路径。此方法通过维护时间序列的一致性确保策略学习的稳定性，并且采用了指导式的奖励函数和不变视图模块来简化RL训练过程并提升性能表现。实验分析表明，该框架有效地解决了训练效率低下及性能不足的问题，是自动驾驶轨迹规划中的一个有前景的方法。根据我们的知识，在nuPlan这一大型现实世界数据集中，我们首次展示了基于RL的路径规划器可以超越基于规则和模仿学习的最佳方法（SOTAs）的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory planning is vital for autonomous driving, ensuring safe andefficient navigation in complex environments. While recent learning-basedmethods, particularly reinforcement learning (RL), have shown promise inspecific scenarios, RL planners struggle with training inefficiencies andmanaging large-scale, real-world driving scenarios. In this paper, we introduce\textbf{CarPlanner}, a \textbf{C}onsistent \textbf{a}uto-\textbf{r}egressive\textbf{Planner} that uses RL to generate multi-modal trajectories. Theauto-regressive structure enables efficient large-scale RL training, while theincorporation of consistency ensures stable policy learning by maintainingcoherent temporal consistency across time steps. Moreover, CarPlanner employs ageneration-selection framework with an expert-guided reward function and aninvariant-view module, simplifying RL training and enhancing policyperformance. Extensive analysis demonstrates that our proposed RL frameworkeffectively addresses the challenges of training efficiency and performanceenhancement, positioning CarPlanner as a promising solution for trajectoryplanning in autonomous driving. To the best of our knowledge, we are the firstto demonstrate that the RL-based planner can surpass both IL- and rule-basedstate-of-the-arts (SOTAs) on the challenging large-scale real-world datasetnuPlan. Our proposed CarPlanner surpasses RL-, IL-, and rule-based SOTAapproaches within this demanding dataset.</description>
      <author>example@mail.com (Dongkun Zhang, Jiaming Liang, Ke Guo, Sha Lu, Qi Wang, Rong Xiong, Zhenwei Miao, Yue Wang)</author>
      <guid isPermaLink="false">2502.19908v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Shared Autonomy for Proximal Teaching</title>
      <link>http://arxiv.org/abs/2502.19899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACM/IEEE International Conference on Human-Robot  Interaction, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用共享自主性的方法Z-COACH，旨在为学习复杂技能（如高性能赛车）的学生提供个性化的指导。&lt;h4&gt;背景&lt;/h4&gt;在进行运动技能的学习时，通常需要经验丰富的专业人士来进行个性化教学。然而，在特定任务领域中高质量的培训资源可能有限，尤其是在像高性能赛车这样专业化程度较高的领域。&lt;h4&gt;目的&lt;/h4&gt;旨在通过教育心理学中的支架理论来设计一种方法，利用共享自主性框架结合用户的输入与机器人的自主性，以优化教学策略。&lt;h4&gt;方法&lt;/h4&gt;提出了Z-COACH方法，该方法使用共享自主性的原则来提供个性化的指导，并重点训练学生易于理解和学习的任务子技能。&lt;h4&gt;主要发现&lt;/h4&gt;在一项有50名参与者的研究中，在模拟的Thunderhill Raceway Park环境中通过CARLA自动驾驶模拟器进行高性能赛车教学时，Z-COACH帮助识别了每位学生的最优先练习技能，从而提高了驾驶时间、行为和流畅度的表现。&lt;h4&gt;结论&lt;/h4&gt;本研究证明了可用的半自主能力（如车辆或机器人）不仅可以辅助人类用户，还能有效教导他们学习复杂的任务子技能。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了利用共享自主性的Z-COACH方法，通过模拟环境测试，在高性能赛车领域展示了该方法在个性化教学方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motor skill learning often requires experienced professionals who can providepersonalized instruction. Unfortunately, the availability of high-qualitytraining can be limited for specialized tasks, such as high performance racing.Several recent works have leveraged AI-assistance to improve instruction oftasks ranging from rehabilitation to surgical robot tele-operation. However,these works often make simplifying assumptions on the student learning process,and fail to model how a teacher's assistance interacts with differentindividuals' abilities when determining optimal teaching strategies. Inspiredby the idea of scaffolding from educational psychology, we leverage sharedautonomy, a framework for combining user inputs with robot autonomy, to aidwith curriculum design. Our key insight is that the way a student's behaviorimproves in the presence of assistance from an autonomous agent can highlightwhich sub-skills might be most ``learnable'' for the student, or within theirZone of Proximal Development. We use this to design Z-COACH, a method for usingshared autonomy to provide personalized instruction targeting interpretabletask sub-skills. In a user study (n=50), where we teach high performance racingin a simulated environment of the Thunderhill Raceway Park with the CARLAAutonomous Driving simulator, we show that Z-COACH helps identify which skillseach student should first practice, leading to an overall improvement indriving time, behavior, and smoothness. Our work shows that increasinglyavailable semi-autonomous capabilities (e.g. in vehicles, robots) can not onlyassist human users, but also help *teach* them.</description>
      <author>example@mail.com (Megha Srivastava, Reihaneh Iranmanesh, Yuchen Cui, Deepak Gopinath, Emily Sumner, Andrew Silva, Laporsha Dees, Guy Rosman, Dorsa Sadigh)</author>
      <guid isPermaLink="false">2502.19899v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>ColorDynamic: Generalizable, Scalable, Real-time, End-to-end Local Planner for Unstructured and Dynamic Environments</title>
      <link>http://arxiv.org/abs/2502.19892v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;该研究提出了一种名为ColorDynamic的框架，用于解决机器人在非结构化和动态环境中的局部规划问题。&lt;h4&gt;背景&lt;/h4&gt;深度强化学习（DRL）展示了处理机器人局部规划问题的潜力，但在高度非结构化的、动态环境中其效果受到限制。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的深度强化学习方法来提高机器人在复杂环境下的决策能力和实时性能。&lt;h4&gt;方法&lt;/h4&gt;{'框架设计': '提出了一种端到端的DRL形式化方法，直接将原始传感器数据映射为控制命令，使该方法适应于非结构化的环境。同时引入Transqer网络，它支持从时间过渡中进行在线DRL学习，增强动态场景中的决策能力。', '平台开发': '为了便于多样化数据集的可扩展训练，设计了一种高效的模拟平台E-Sparrow，并结合对称不变性技术来增加数据量。', '实验验证': '通过与最先进的方法比较评估、通用性、可伸缩性和实时性能测试来证明ColorDynamic的有效性。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'成功率': '该方法在实验中取得了超过90%的成功率。', '延迟时间': '展示了实现实时能力（每次规划1.2-1.3毫秒）的能力。', '组件贡献': '通过消融研究证明了各组成部分对整体性能的贡献。'}&lt;h4&gt;结论&lt;/h4&gt;基于ColorDynamic，开发了一种名为OkayPlan-ColorDynamic (OPCD)的导航系统，并通过模拟和真实世界的实验展示了其在复杂环境中的优越性和适用性。&lt;h4&gt;代码与数据公开&lt;/h4&gt;研究的源码及实验演示已在其官方网站上开源，以促进可重复研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Reinforcement Learning (DRL) has demonstrated potential in addressingrobotic local planning problems, yet its efficacy remains constrained in highlyunstructured and dynamic environments. To address these challenges, this studyproposes the ColorDynamic framework. First, an end-to-end DRL formulation isestablished, which maps raw sensor data directly to control commands, therebyensuring compatibility with unstructured environments. Under this formulation,a novel network, Transqer, is introduced. The Transqer enables online DRLlearning from temporal transitions, substantially enhancing decision-making indynamic scenarios. To facilitate scalable training of Transqer with diversedata, an efficient simulation platform E-Sparrow, along with a dataaugmentation technique leveraging symmetric invariance, are developed.Comparative evaluations against state-of-the-art methods, alongside assessmentsof generalizability, scalability, and real-time performance, were conducted tovalidate the effectiveness of ColorDynamic. Results indicate that our approachachieves a success rate exceeding 90% while exhibiting real-time capacity(1.2-1.3 ms per planning). Additionally, ablation studies were performed tocorroborate the contributions of individual components. Building on this, theOkayPlan-ColorDynamic (OPCD) navigation system is presented, with simulated andreal-world experiments demonstrating its superiority and applicability incomplex scenarios. The codebase and experimental demonstrations have beenopen-sourced on our website to facilitate reproducibility and further research.</description>
      <author>example@mail.com (Jinghao Xin, Zhichao Liang, Zihuan Zhang, Peng Wang, Ning Li)</author>
      <guid isPermaLink="false">2502.19892v1</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:45 +0800</pubDate>
    </item>
    <item>
      <title>Image Translation-Based Unsupervised Cross-Modality Domain Adaptation for Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2502.15193v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 1 figure. arXiv admin note: substantial text overlap with  arXiv:2303.07674&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图像转换的无监督跨模态域适应方法，该方法能够将带有标注的源模态图像转化为未标注的目标模态，并利用这些伪标签进行目标模态的学习。&lt;h4&gt;背景&lt;/h4&gt;在医学影像中，由于医生专业知识的需求，注解过程更加耗时且昂贵。同时，不同医疗机构获取的医疗影像可能因为不同的扫描设备和成像协议而具有不一致的模态特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种可以应对跨模态差异（域偏移）问题并提高深度学习模型性能的方法。&lt;h4&gt;方法&lt;/h4&gt;通过图像转换技术将源模态中的标注数据转化为目标模态，并结合自训练技术克服生成伪标签与真实图像之间的细微差别，以进一步提升任务的执行能力。&lt;h4&gt;主要发现&lt;/h4&gt;在跨模态域适应（crossMoDA 2022）挑战赛验证阶段排行榜上，对于前庭神经鞘瘤和耳蜗分割任务，提出的模型分别达到了Dice相似性系数(DSC)和平均对称表面距离(ASSD)为：VS肿瘤0.8351 ± 0.1152 和1.6712 ± 2.1948；耳蜗0.8098 ± 0.0233和0.2317 ± 0.1577。&lt;h4&gt;结论&lt;/h4&gt;所提出的无监督跨模态域适应方法能有效地解决医疗影像中的跨模态问题，提供了一种提高深度学习模型在医学图像处理中表现的新途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Supervised deep learning usually faces more challenges in medical images thanin natural images. Since annotations in medical images require the expertise ofdoctors and are more time-consuming and expensive. Thus, some researchers turnto unsupervised learning methods, which usually face inevitable performancedrops. In addition, medical images may have been acquired at different medicalcenters with different scanners and under different image acquisitionprotocols, so the modalities of the medical images are often inconsistent. Thismodality difference (domain shift) also reduces the applicability of deeplearning methods. In this regard, we propose an unsupervised crossmodalitydomain adaptation method based on image translation by transforming the sourcemodality image with annotation into the unannotated target modality and usingits annotation to achieve supervised learning of the target modality. Inaddition, the subtle differences between translated pseudo images and realimages are overcome by self-training methods to further improve the taskperformance of deep learning. The proposed method showed mean Dice SimilarityCoefficient (DSC) and Average Symmetric Surface Distance (ASSD) of $0.8351 \pm0.1152$ and $1.6712 \pm 2.1948$ for vestibular schwannoma (VS), $0.8098 \pm0.0233$ and $0.2317 \pm 0.1577$ for cochlea on the VS and cochlea segmentationtask of the Cross-Modality Domain Adaptation (crossMoDA 2022) challengevalidation phase leaderboard.</description>
      <author>example@mail.com (Tao Yang, Lisheng Wang)</author>
      <guid isPermaLink="false">2502.15193v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
  <item>
      <title>Fréchet Cumulative Covariance Net for Deep Nonlinear Sufficient Dimension Reduction with Random Objects</title>
      <link>http://arxiv.org/abs/2502.15374v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的统计依赖度量——Fréchet累积协方差（FCCov），并基于此发展了一种新的非线性充分降维框架，适用于复杂的非欧几里得数据，并具有抗异常值的能力。&lt;h4&gt;背景&lt;/h4&gt;现有大多数方法在处理复杂非欧几里得响应变量时不再适用，而这类数据在许多现代统计应用中频繁出现。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的非线性充分降维框架，以解决复杂非欧几里得数据的问题，并提高模型的鲁棒性和实用性。&lt;h4&gt;方法&lt;/h4&gt;引入了Fréchet累积协方差（FCCov）作为依赖度量，并结合前馈神经网络（FNNs）和卷积神经网络（CNNs）来估计样本层面的非线性充分方向。同时，证明了带有平方弗罗贝尼乌斯范数正则化的模型在σ-域上的无偏性。&lt;h4&gt;主要发现&lt;/h4&gt;理论结果表明该方法达到了最优的收敛速度，并通过大量的模拟研究验证了其在欧几里得和非欧几里得设置下的性能。实际应用中，该方法在面部表情识别数据集上表现良好。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法不仅对复杂的非欧几里得数据具有广泛的应用性，而且展示出了比现有方法更强的鲁棒性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;非线性充分降维构建了高维数据的非线性低维表示，以概括其核心特征。然而，当响应变量是常见的复杂非欧几里得随机对象时，大多数现有的方法不再适用。本文引入了一种新的统计依赖度量——Fréchet累积协方差（FCCov），并基于此发展了一个新的非线性充分降维框架，并结合了前馈神经网络和卷积神经网络来估计样本级别的非线性充分方向。理论证明表明，带有平方弗罗贝尼乌斯范数正则化的模型在σ-域上是无偏的。此外，建立了基于FNNs和ResNet型CNNs的估计器的非渐近收敛率，这些匹配了非参数回归的最大最小速率（忽略对数因子）。大量的模拟研究验证了所提方法在欧几里得及非欧几里得设置下的性能，并通过面部表情识别数据集的应用证明了其实际有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nonlinear sufficient dimension reduction\citep{libing_generalSDR}, whichconstructs nonlinear low-dimensional representations to summarize essentialfeatures of high-dimensional data, is an important branch of representationlearning. However, most existing methods are not applicable when the responsevariables are complex non-Euclidean random objects, which are frequentlyencountered in many recent statistical applications. In this paper, weintroduce a new statistical dependence measure termed Fr\'echet CumulativeCovariance (FCCov) and develop a novel nonlinear SDR framework based on FCCov.Our approach is not only applicable to complex non-Euclidean data, but alsoexhibits robustness against outliers. We further incorporate Feedforward NeuralNetworks (FNNs) and Convolutional Neural Networks (CNNs) to estimate nonlinearsufficient directions in the sample level. Theoretically, we prove that ourmethod with squared Frobenius norm regularization achieves unbiasedness at the$\sigma$-field level. Furthermore, we establish non-asymptotic convergencerates for our estimators based on FNNs and ResNet-type CNNs, which match theminimax rate of nonparametric regression up to logarithmic factors. Intensivesimulation studies verify the performance of our methods in both Euclidean andnon-Euclidean settings. We apply our method to facial expression recognitiondatasets and the results underscore more realistic and broader applicability ofour proposal.</description>
      <author>example@mail.com (Hang Yuan, Christina Dan Wang, Zhou Yu)</author>
      <guid isPermaLink="false">2502.15374v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>PointSea: Point Cloud Completion via Self-structure Augmentation</title>
      <link>http://arxiv.org/abs/2502.17053v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by International Journal of Computer Vision (IJCV). This  work is a journal extension of our ICCV 2023 paper arXiv:2307.08492. arXiv  admin note: text overlap with arXiv:2307.08492&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了PointSea，一种用于全局到局部点云完成的方法。通过引入自结构增强和利用多视角自我投影深度图来改进数据表示。&lt;h4&gt;背景&lt;/h4&gt;点云补全是3D视觉中的基础但尚未完全解决的问题。当前方法依赖于3D坐标信息或额外的数据（如图像和扫描视点）来填充缺失部分。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于自结构增强的全局到局部点云完成的新方法，以更好地理解和生成不完整输入中的细节。&lt;h4&gt;方法&lt;/h4&gt;{'全局阶段': '使用多视角自我投影深度图增强数据表示，并通过跨模态输入重构紧凑的全球形状。引入特征融合模块，在视内和视间层次上融合特征。', '局部阶段': '提出一种名为自结构对偶生成器的点生成器，该生成器结合了学习到的形状先验和几何自相似性进行形状细化，并根据每个点的结构性质适应不同的细化策略。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明PointSea能够有效理解全局形状并从不完整输入中产生局部细节，相对于现有方法有明显改进。&lt;h4&gt;结论&lt;/h4&gt;通过引入自我结构增强和利用多视角数据表示来提升点云补全的效果，并在多个基准测试上展示了其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud completion is a fundamental yet not well-solved problem in 3Dvision. Current approaches often rely on 3D coordinate information and/oradditional data (e.g., images and scanning viewpoints) to fill in missingparts. Unlike these methods, we explore self-structure augmentation and proposePointSea for global-to-local point cloud completion. In the global stage,consider how we inspect a defective region of a physical object, we may observeit from various perspectives for a better understanding. Inspired by this,PointSea augments data representation by leveraging self-projected depth imagesfrom multiple views. To reconstruct a compact global shape from the cross-modalinput, we incorporate a feature fusion module to fuse features at bothintra-view and inter-view levels. In the local stage, to reveal highly detailedstructures, we introduce a point generator called the self-structuredual-generator. This generator integrates both learned shape priors andgeometric self-similarities for shape refinement. Unlike existing efforts thatapply a unified strategy for all points, our dual-path design adapts refinementstrategies conditioned on the structural type of each point, addressing thespecific incompleteness of each point. Comprehensive experiments on widely-usedbenchmarks demonstrate that PointSea effectively understands global shapes andgenerates local details from incomplete input, showing clear improvements overexisting methods.</description>
      <author>example@mail.com (Zhe Zhu, Honghua Chen, Xing He, Mingqiang Wei)</author>
      <guid isPermaLink="false">2502.17053v2</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Armada: Memory-Efficient Distributed Training of Large-Scale Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.17846v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了在亿级规模图数据集上进行分布式训练的Graph Neural Networks（GNNs）的方法，提出了一个新的分布式系统Armada和一种新的最小边切割划分算法GREM。&lt;h4&gt;背景&lt;/h4&gt;现有的最优离线方法（例如METIS）虽然效果好但是对内存消耗巨大并且运行时间长；而计算效率较高的贪心流式分区方法在减少跨机通信方面表现不佳。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够高效处理大规模图数据集的分布式训练系统，以优化GNN的训练过程。&lt;h4&gt;方法&lt;/h4&gt;引入了Armada系统及其核心组件GREM算法。GREM基于改进的流式贪心算法，在执行过程中不断优化顶点分配策略而非一次性冻结选择结果。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析和实验表明，相比于传统方法（例如METIS），GREM能够在内存消耗和运行时间上减少8到65倍，并且在切割边数上达到与之相仿的水平。另外，在进行分布式训练时，Armada通过分散式架构进一步提高了效率。&lt;h4&gt;结论&lt;/h4&gt;使用分散式架构可以显著提高GNN模型在大规模图数据集上的训练性能和成本效益。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了在分布在多台机器上划分的大规模图形（即百亿级）中进行Graph Neural Networks (GNNs)分布式训练的有效方法。高效训练需要利用最小边切割分区算法来减少由于GNN邻居采样导致的跨机通信需求，但是对大图进行有效分割仍然是一个挑战：最先进的离线方法(例如METIS)，虽然效果好但它们需要比GNN训练本身多几倍到几十倍的内存和运行时间；计算效率较高的贪心流式分区算法则面临增加边切割量的问题。为此，在这项工作中我们引入了Armada，一个新的用于分布式GNN训练的端到端系统，其关键贡献是GREM，一种新的最小边切割划分算法，它能够有效处理大规模图形数据集。GREM在现有的流式贪心算法基础上加入了一项重要改进：在执行过程中对先前顶点分配进行持续优化而非冻结初始贪婪选择的结果。我们的理论分析和实验结果表明这种优化对于减少边切割至关重要，并使GREM能够在内存消耗和运行时间上少8到65倍的同时，达到与METIS相近的分区质量。给定一个已分割图，Armada通过新的分散架构进一步提升了分布式GNN训练效率；我们在普通的云机器中发现，在没有额外通信的情况下，GNN邻居采样以及特征加载已成为训练中的瓶颈。分散式架构使得Armada能够独立分配这些操作所需的资源，并确保昂贵的GPU始终保持饱和运算状态。我们评估了Armada相对于当前最优秀的分布式GNN训练系统的表现，发现分散式的架构带来了运行时间提高高达4.5倍和成本降低高达3.1倍的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study distributed training of Graph Neural Networks (GNNs) onbillion-scale graphs that are partitioned across machines. Efficient trainingin this setting relies on min-edge-cut partitioning algorithms, which minimizecross-machine communication due to GNN neighborhood sampling. Yet, min-edge-cutpartitioning over large graphs remains a challenge: State-of-the-art (SoTA)offline methods (e.g., METIS) are effective, but they require orders ofmagnitude more memory and runtime than GNN training itself, whilecomputationally efficient algorithms (e.g., streaming greedy approaches) sufferfrom increased edge cuts. Thus, in this work we introduce Armada, a newend-to-end system for distributed GNN training whose key contribution is GREM,a novel min-edge-cut partitioning algorithm that can efficiently scale to largegraphs. GREM builds on streaming greedy approaches with one key addition: priorvertex assignments are continuously refined during streaming, rather thanfrozen after an initial greedy selection. Our theoretical analysis andexperimental results show that this refinement is critical to minimizing edgecuts and enables GREM to reach partition quality comparable to METIS but with8-65x less memory and 8-46x faster. Given a partitioned graph, Armada leveragesa new disaggregated architecture for distributed GNN training to furtherimprove efficiency; we find that on common cloud machines, even with zerocommunication, GNN neighborhood sampling and feature loading bottlenecktraining. Disaggregation allows Armada to independently allocate resources forthese operations and ensure that expensive GPUs remain saturated withcomputation. We evaluate Armada against SoTA systems for distributed GNNtraining and find that the disaggregated architecture leads to runtimeimprovements up to 4.5x and cost reductions up to 3.1x.</description>
      <author>example@mail.com (Roger Waleffe, Devesh Sarda, Jason Mohoney, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Theodoros Rekatsinas, Shivaram Venkataraman)</author>
      <guid isPermaLink="false">2502.17846v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Retrieval Dexterity: Efficient Object Retrieval in Clutters with Dexterous Hand</title>
      <link>http://arxiv.org/abs/2502.18423v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种灵巧的臂手系统，用于在多物体堆叠环境中高效地检索被遮挡的目标物体。该方法通过大规模并行强化学习训练策略，在复杂环境设计中展现出了高效的清除障碍物能力。&lt;h4&gt;背景&lt;/h4&gt;在多个物体堆积的情况下检索目标物体既具有挑战性又耗时，现有的方法通常通过逐一抓取和移除遮挡的物体来解决问题，这导致了执行时间长并且需要极高的抓取技能要求。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的灵巧机械臂系统，能够高效地在复杂堆叠环境中清除障碍物以检索目标物体。&lt;h4&gt;方法&lt;/h4&gt;采用大规模并行强化学习技术，在多样化设计的拥挤场景中训练策略。这些策略发展出如推、搅拌和戳等技能，可以有效地暴露目标物体的足够表面。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验验证了该系统在多样化的居家物品混乱配置下的高效性能，并成功地将学到的策略转移到真实的灵巧多指机器人上，展示了其实际应用的可能性。&lt;h4&gt;结论&lt;/h4&gt;研究证明所提出的臂手系统可以有效解决复杂堆叠环境中目标物体检索的问题，并且能够在现实世界中实现。&lt;h4&gt;翻译&lt;/h4&gt;提取埋藏在多个物体下的对象不仅具有挑战性而且耗时。在这种环境下执行操作会因为复杂的接触关系而困难重重。现有方法通常通过逐一抓取并移除每个遮挡物来解决这个问题，这导致了长时间的执行时间和对每一个遮挡物不切实际的抓取能力需求。在本文中，我们提出了一种灵巧的臂手系统用于多物体堆叠环境中的高效对象检索。我们的方法利用大规模平行强化学习在多样化设计的混乱环境中训练策略。这些策略展现了如推、搅拌和戳等出现的操作技能，能够有效地清除遮挡物以暴露目标物体的足够表面区域。我们在一套超过10种家用物品在不同杂乱配置下进行了广泛的评估，展示了对已训练和未见过对象都具备优异的检索性能和效率。此外，我们将学习到的策略成功地转移到了真实世界中的灵巧多指机器人系统中，验证了它们的实际应用性。视频可以在我们的项目网站上找到：https://ChangWinde.github.io/RetrDex。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieving objects buried beneath multiple objects is not only challengingbut also time-consuming. Performing manipulation in such environments presentssignificant difficulty due to complex contact relationships. Existing methodstypically address this task by sequentially grasping and removing eachoccluding object, resulting in lengthy execution times and requiringimpractical grasping capabilities for every occluding object. In this paper, wepresent a dexterous arm-hand system for efficient object retrieval inmulti-object stacked environments. Our approach leverages large-scale parallelreinforcement learning within diverse and carefully designed clutteredenvironments to train policies. These policies demonstrate emergentmanipulation skills (e.g., pushing, stirring, and poking) that efficientlyclear occluding objects to expose sufficient surface area of the target object.We conduct extensive evaluations across a set of over 10 household objects indiverse clutter configurations, demonstrating superior retrieval performanceand efficiency for both trained and unseen objects. Furthermore, wesuccessfully transfer the learned policies to a real-world dexterousmulti-fingered robot system, validating their practical applicability inreal-world scenarios. Videos can be found on our project websitehttps://ChangWinde.github.io/RetrDex.</description>
      <author>example@mail.com (Fengshuo Bai, Yu Li, Jie Chu, Tawei Chou, Runchuan Zhu, Ying Wen, Yaodong Yang, Yuanpei Chen)</author>
      <guid isPermaLink="false">2502.18423v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>From planning to policy: distilling $\texttt{Skill-RRT}$ for long-horizon prehensile and non-prehensile manipulation</title>
      <link>http://arxiv.org/abs/2502.18015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website:  $\href{https://sites.google.com/view/skill-rrt}{\text{sites.google.com/view/skill-rrt}}$&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种框架，通过模仿学习将规划算法转化为策略以解决长时序操作任务中的复杂技能串联问题。&lt;h4&gt;背景&lt;/h4&gt;当前机器人在需要一系列灵巧和非灵巧抓取技巧的长时间序列操作任务中面临挑战。这包括处理复杂的接触互动和考虑多个技能长期影响的任务串连。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，将长时序规划算法转化为高效的操作策略，并通过生成高质量演示数据来优化策略性能。&lt;h4&gt;方法&lt;/h4&gt;{'Skill-RRT': '该框架引入了$\texttt{Skill-RRT}$，这是一种快速搜索随机树（RRT）的扩展版本，加入了技能适用性检查和中间对象姿态采样，以实现高效的长时序规划。', 'connectors': '提出$\\it{connectors}$概念，即基于目标条件策略，用于在技能之间过渡的同时尽量减少物体扰动。通过懒惰规划（lazy planning），这些connectors仅在相关转移上训练，从而降低成本。', '噪声重播机制': '利用$\texttt{Skill-RRT}$生成高质量的演示数据，并通过噪声基础重播机制进一步优化策略性能。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'策略性能': '所提出的策略能够在完全模拟环境中进行训练，并直接应用于现实世界，成功率超过80%，涵盖三个具有挑战性的操作任务。', '比较优势': '在仿真环境中的表现优于现有的基于技能的强化学习方法$\texttt{MAPLE}$和$\texttt{Skill-RRT}$。'}&lt;h4&gt;结论&lt;/h4&gt;通过引入$exttt{Skill-RRT}$以及$\it{connectors}$，本文提供了一种有效的方法来解决机器人长时序操作任务中的复杂技能问题。&lt;h4&gt;翻译&lt;/h4&gt;当前的机器人在执行需要一系列灵巧和非灵巧抓取技巧的操作任务中遇到挑战，这些任务涉及处理复杂的接触互动及考虑多个技能长期影响的任务串连。为了应对这些问题，该研究提出了一种框架，通过模仿学习将一个能够解决长时间序列问题但计算时间消耗大的规划算法转化为策略，从而实现高效的动作推断。本文介绍了$exttt{Skill-RRT}$方法，这是快速搜索随机树（RRT）的扩展版，加入技能适用性检查和中间对象姿态采样，以促进高效的长时序规划。此外，为了使技能能够串联起来，研究还提出了$\it{connectors}$概念——目标条件策略，用于在技能之间转换的同时尽量减少物体扰动。通过懒惰规划技术，这些连接器仅选择性地训练于相关的过渡场景上，减少了训练成本。高质量的演示数据由$exttt{Skill-RRT}$生成，并且经过噪声基础重播机制优化以确保政策性能的鲁棒性。最终策略在完全模拟环境中进行训练后，在真实世界中直接转移应用并取得超过80%的成功率，涵盖了三个具有挑战性的操作任务。在仿真环境中的表现也优于现有的基于技能的强化学习方法$exttt{MAPLE}$和$exttt{Skill-RRT}$。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current robots face challenges in manipulation tasks that require a longsequence of prehensile and non-prehensile skills. This involves handlingcontact-rich interactions and chaining multiple skills while considering theirlong-term consequences. This paper presents a framework that leveragesimitation learning to distill a planning algorithm, capable of solvinglong-horizon problems but requiring extensive computation time, into a policyfor efficient action inference. We introduce $\texttt{Skill-RRT}$, an extensionof the rapidly-exploring random tree (RRT) that incorporates skillapplicability checks and intermediate object pose sampling for efficientlong-horizon planning. To enable skill chaining, we propose$\textit{connectors}$, goal-conditioned policies that transition between skillswhile minimizing object disturbance. Using lazy planning, connectors areselectively trained on relevant transitions, reducing the cost of training.High-quality demonstrations are generated with $\texttt{Skill-RRT}$ and refinedby a noise-based replay mechanism to ensure robust policy performance. Thedistilled policy, trained entirely in simulation, zero-shot transfer to thereal world, and achieves over 80% success rates across three challengingmanipulation tasks. In simulation, our approach outperforms thestate-of-the-art skill-based reinforcement learning method, $\texttt{MAPLE}$,and $\texttt{Skill-RRT}$.</description>
      <author>example@mail.com (Haewon Jung, Donguk Lee, Haecheol Park, JunHyeop Kim, Beomjoon Kim)</author>
      <guid isPermaLink="false">2502.18015v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning-Based Transfer Learning for Classification of Cassava Disease</title>
      <link>http://arxiv.org/abs/2502.19351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, in Portuguese language, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文对比了四种卷积神经网络架构（EfficientNet-B3、InceptionV3、ResNet50 和 VGG16）在分类木薯病害图像上的性能。&lt;h4&gt;背景&lt;/h4&gt;研究使用的数据集来自一场竞赛中的不平衡图像数据集。&lt;h4&gt;目的&lt;/h4&gt;比较不同CNN架构对于识别木薯疾病图像的效果，特别是针对不平衡数据集的挑战提出解决方案。&lt;h4&gt;方法&lt;/h4&gt;使用了适当的度量标准来解决类别不平衡的问题，并评估了四种模型在分类任务上的性能指标（准确率、精确率、召回率和F1分数）。&lt;h4&gt;主要发现&lt;/h4&gt;EfficientNet-B3 在这项任务中表现出最好的结果，其准确率为87.7%，精确率为87.8%，召回率为87.8%，F1-Score为87.7%。&lt;h4&gt;结论&lt;/h4&gt;研究认为EfficientNet-B3可以作为一个有价值的工具来支持数字农业的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了该论文通过评估四种卷积神经网络架构（包括EfficientNet-B3、InceptionV3、ResNet50和VGG16）在处理一个不平衡的木薯病害图像数据集上的分类性能，发现EfficientNet-B3表现最佳，并建议这种模型可以用于支持数字农业领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a performance comparison among four Convolutional NeuralNetwork architectures (EfficientNet-B3, InceptionV3, ResNet50, and VGG16) forclassifying cassava disease images. The images were sourced from an imbalanceddataset from a competition. Appropriate metrics were employed to address classimbalance. The results indicate that EfficientNet-B3 achieved on this taskaccuracy of 87.7%, precision of 87.8%, revocation of 87.8% and F1-Score of87.7%. These findings suggest that EfficientNet-B3 could be a valuable tool tosupport Digital Agriculture.</description>
      <author>example@mail.com (Ademir G. Costa Junior, Fábio S. da Silva, Ricardo Rios)</author>
      <guid isPermaLink="false">2502.19351v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>LiDAR Registration with Visual Foundation Models</title>
      <link>http://arxiv.org/abs/2502.19374v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种使用DINOv2特征作为点描述符的方法，用于解决基于激光雷达的机器人地图注册和定位中的关键问题。&lt;h4&gt;背景&lt;/h4&gt;激光雷达数据配准在机器人制图与定位中是一项基本任务。通过识别稳健的点对来实现两个点云之间的对齐是至关重要的步骤，在领域差异、季节变化及点云结构变化的情况下尤为困难。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决上述问题，提出了一种使用DINOv2特征作为点描述符的方法，并结合传统配准算法进行激光雷达扫描和3D地图的稳健6DoF对齐。&lt;h4&gt;方法&lt;/h4&gt;通过将从环绕视图图像中获得的DINOv2特征用作点描述符，这种方法可以克服传统的基于手工设计及学习的方法在面对领域差异时的局限性。同时与RANSAC或ICP等传统配准算法相结合以实现稳健对齐。&lt;h4&gt;主要发现&lt;/h4&gt;利用额外的相机数据使该方法能够在NCLT和Oxford RobotCar数据集上超越最复杂的基线技术，分别提高了24.8%和17.3%的注册召回率。&lt;h4&gt;结论&lt;/h4&gt;本文的方法不需要领域特定重新训练，并且对点云结构无敏感性，能够处理稀疏激光雷达扫描和密集3D地图。此外，该方法在概念上虽然简单但效果显著优于更复杂的基线技术。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR registration is a fundamental task in robotic mapping and localization. A critical component of aligning two point clouds is identifying robust point correspondences using point descriptors. This step becomes particularly challenging in scenarios involving domain shifts, seasonal changes, and variations in point cloud structures. These factors substantially impact both handcrafted and learning-based approaches. In this paper, we address these problems by proposing to use DINOv2 features, obtained from surround-view images, as point descriptors. We demonstrate that coupling these descriptors with traditional registration algorithms, such as RANSAC or ICP, facilitates robust 6DoF alignment of LiDAR scans with 3D maps, even when the map was recorded more than a year before. Although conceptually straightforward, our method substantially outperforms more complex baseline techniques. In contrast to previous learning-based point descriptors, our method does not require domain-specific retraining and is agnostic to the point cloud structure, effectively handling both sparse LiDAR scans and dense 3D maps. We show that leveraging the additional camera data enables our method to outperform the best baseline by +24.8 and +17.3 registration recall on the NCLT and Oxford RobotCar datasets. We publicly release the registration benchmark and the code of our work on https://vfm-registration.cs.uni-freiburg.de.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR registration is a fundamental task in robotic mapping and localization.A critical component of aligning two point clouds is identifying robust pointcorrespondences using point descriptors. This step becomes particularlychallenging in scenarios involving domain shifts, seasonal changes, andvariations in point cloud structures. These factors substantially impact bothhandcrafted and learning-based approaches. In this paper, we address theseproblems by proposing to use DINOv2 features, obtained from surround-viewimages, as point descriptors. We demonstrate that coupling these descriptorswith traditional registration algorithms, such as RANSAC or ICP, facilitatesrobust 6DoF alignment of LiDAR scans with 3D maps, even when the map wasrecorded more than a year before. Although conceptually straightforward, ourmethod substantially outperforms more complex baseline techniques. In contrastto previous learning-based point descriptors, our method does not requiredomain-specific retraining and is agnostic to the point cloud structure,effectively handling both sparse LiDAR scans and dense 3D maps. We show thatleveraging the additional camera data enables our method to outperform the bestbaseline by +24.8 and +17.3 registration recall on the NCLT and Oxford RobotCardatasets. We publicly release the registration benchmark and the code of ourwork on https://vfm-registration.cs.uni-freiburg.de.</description>
      <author>example@mail.com (Niclas Vödisch, Giovanni Cioffi, Marco Cannici, Wolfram Burgard, Davide Scaramuzza)</author>
      <guid isPermaLink="false">2502.19374v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Preference-Based Gradient Estimation for ML-Based Approximate Combinatorial Optimization</title>
      <link>http://arxiv.org/abs/2502.19377v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preliminary work, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于数据驱动的方法，用于改进现有的非学习近似算法，以解决组合优化问题。方法是通过参数化近似算法并利用图神经网络预测最优参数值来实现。&lt;h4&gt;背景&lt;/h4&gt;组合优化问题广泛存在于医学、物流和制造业等领域中。许多应用场景要求快速找到高质量的解决方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种数据驱动的方法，结合神经网络和非学习近似算法的优点，以提高组合优化问题解的质量。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络预测能产生最优解的参数值，并通过自监督的方式进行端到端训练。同时提出了基于偏好梯度估计的新方案。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在旅行商问题和最小k切割问题上的表现与最新的学习组合优化求解器具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效地利用图神经网络的信息帮助近似算法找到更好的解决方案，同时也保证了解的可行性。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到：组合优化（CO）问题出现在从医学到物流和制造业等多个领域。虽然精确解决这些问题是不必要的，但许多应用需要快速找到高质量的解。为实现这一目标，我们提出了一种数据驱动的方法来改进现有的非学习近似算法。我们将近似算法参数化，并训练图神经网络预测能够产生最佳可能解的参数值。我们的管道在自监督环境下以端到端的方式进行梯度估计训练，将近似算法视为黑盒系统。为实现这一目标，我们提出了一种新颖的基于偏好的梯度估计方案。该方法结合了神经网络和非学习近似算法的优势：图神经网络利用数据集中的信息帮助近似算法找到更好的解，而近似算法则确保了解的可行性。我们在旅行商问题和最小k切割问题上验证了我们的方法，并表明与最新的学习组合优化求解器相比具有竞争力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Combinatorial optimization (CO) problems arise in a wide range of fields frommedicine to logistics and manufacturing. While exact solutions are often notnecessary, many applications require finding high-quality solutions quickly.For this purpose, we propose a data-driven approach to improve existingnon-learned approximation algorithms for CO. We parameterize the approximationalgorithm and train a graph neural network (GNN) to predict parameter valuesthat lead to the best possible solutions. Our pipeline is trained end-to-end ina self-supervised fashion using gradient estimation, treating the approximationalgorithm as a black box. We propose a novel gradient estimation scheme forthis purpose, which we call preference-based gradient estimation. Our approachcombines the benefits of the neural network and the non-learned approximationalgorithm: The GNN leverages the information from the dataset to allow theapproximation algorithm to find better solutions, while the approximationalgorithm guarantees that the solution is feasible. We validate our approach ontwo well-known combinatorial optimization problems, the travelling salesmanproblem and the minimum k-cut problem, and show that our method is competitivewith state of the art learned CO solvers.</description>
      <author>example@mail.com (Arman Mielke, Uwe Bauknecht, Thilo Strauss, Mathias Niepert)</author>
      <guid isPermaLink="false">2502.19377v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>FSPO: Few-Shot Preference Optimization of Synthetic Preference Data in LLMs Elicits Effective Personalization to Real Users</title>
      <link>http://arxiv.org/abs/2502.19312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Website: https://fewshot-preference-optimization.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了Few-Shot Preference Optimization (FSPO) 方法，通过少量用户偏好标签，利用大型语言模型（LLM）的在上下文学习能力快速适应用户需求。&lt;h4&gt;背景&lt;/h4&gt;有效的个人化对虚拟助手和内容推荐等应用至关重要。然而，收集真实世界的用户偏好数据既困难又耗时。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以使用少量真实的用户偏好信息并在合成数据集上进行训练的方法，以实现实用的个性化功能。&lt;h4&gt;方法&lt;/h4&gt;提出FSPO框架，通过构建合成偏好数据集来解决实际偏好的收集难题，并采用公开可用的大规模语言模型生成100万以上的个人化偏好标签。&lt;h4&gt;主要发现&lt;/h4&gt;为了有效利用合成数据进行真实用户个性化的迁移学习，数据需要具有高度多样性和一致性的结构。经过电影评论、基于教育背景的适应性教学以及通用问题解答等三个领域的测试，FSPO在个性化开放生成方面表现出色，平均胜率为87%（对合成用户）和72%（对真实人类用户）。&lt;h4&gt;结论&lt;/h4&gt;FSPO成功地将大型语言模型的在上下文学习能力应用于个人化需求优化，为开发更智能、更具个性化的应用提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;有效的个性化对于各种需要与用户交互的应用程序来说至关重要。受大型语言模型（LLM）的强大上下文学习能力启发，我们提出了Few-Shot Preference Optimization (FSPO) 方法，将奖励建模重新定义为元学习问题，在此框架下，通过少量用户的偏好标签，LM可以快速适应个人需求，并构建个性化的奖励函数。考虑到实际偏好的数据难以大规模收集，我们设计了合成的偏好数据集来实现个性化，利用公开可用的大规模语言模型生成超过100万个个性化偏好标签。为了从合成数据成功转移到真实用户上，发现需要确保数据具有高度多样性和一致性的结构。我们在三个领域进行了评估：电影评论、基于教育背景的教学适应和通用问题回答，并进行了一项受控的人类研究。总的来说，在针对最多1500个虚拟用户的个性化开放生成中，FSPO实现了平均87%的Alpaca Eval胜率（对合成用户）以及在开放性问题解答中对真实人类用户的平均72%胜率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective personalization of LLMs is critical for a broad range ofuser-interfacing applications such as virtual assistants and content curation.Inspired by the strong in-context learning capabilities of LLMs, we proposeFew-Shot Preference Optimization (FSPO), which reframes reward modeling as ameta-learning problem. Under this framework, an LLM learns to quickly adapt toa user via a few labeled preferences from that user, constructing apersonalized reward function for them. Additionally, since real-worldpreference data is scarce and challenging to collect at scale, we proposecareful design choices to construct synthetic preference datasets forpersonalization, generating over 1M synthetic personalized preferences usingpublicly available LLMs. In particular, to successfully transfer from syntheticdata to real users, we find it crucial for the data to exhibit both highdiversity and coherent, self-consistent structure. We evaluate FSPO onpersonalized open-ended generation for up to 1,500 synthetic users acrossacross three domains: movie reviews, pedagogical adaptation based oneducational background, and general question answering, along with a controlledhuman study. Overall, FSPO achieves an 87% Alpaca Eval winrate on average ingenerating responses that are personalized to synthetic users and a 72% winratewith real human users in open-ended question answering.</description>
      <author>example@mail.com (Anikait Singh, Sheryl Hsu, Kyle Hsu, Eric Mitchell, Stefano Ermon, Tatsunori Hashimoto, Archit Sharma, Chelsea Finn)</author>
      <guid isPermaLink="false">2502.19312v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>PFSD: A Multi-Modal Pedestrian-Focus Scene Dataset for Rich Tasks in Semi-Structured Environments</title>
      <link>http://arxiv.org/abs/2502.15342v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的行人关注的多模态场景数据集PFSD，并提出了一种用于复杂半结构化环境中的三维行人检测的新方法HMFN。&lt;h4&gt;背景&lt;/h4&gt;在有大量车辆交通的结构化环境中，自动驾驶感知技术表现出色。然而，在动态行人占据主导地位的半结构化环境中，当前感知模型表现不佳，主要原因在于高质量数据集的缺乏。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多模态场景数据集PFSD，以及解决复杂半结构环境挑战的新方法HMFN。&lt;h4&gt;方法&lt;/h4&gt;创建了一个名为PFSD的数据集，该数据集中包括超过130,000个行人实例的详细标注。此外，还设计了一种混合多尺度融合网络（HMFN），通过结合稀疏和普通卷积来有效地捕捉并融合不同规模的特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有方法相比，HMFN在PFSD数据集上的平均精度均值(mAP)有所提高，证明了该方法在处理复杂半结构化环境中的三维行人检测任务的有效性。&lt;h4&gt;结论&lt;/h4&gt;通过提供高质量的数据集和创新的算法模型，本文为改进自动驾驶系统中行人感知技术提供了重要的基础研究。&lt;h4&gt;翻译&lt;/h4&gt;最近，在以车辆交通为主的结构性环境中，自主驾驶感知技术已经展示了卓越的能力。然而，目前的感知模型在半结构化环境中的表现较差，这些环境下动态行人的多样性和不规则运动更加普遍，遮挡情况也更为复杂。我们认为这种情况的原因在于高质量数据集的缺乏，尤其是在涉及行人感知和预测方面的不足。在这项工作中，我们提出了一个多模态的行人场景数据集（PFSD），它在半结构化环境中进行了严格的nuScenes格式标注，并提供了点云分割、检测和对象ID以进行跟踪。该数据集涵盖了各种不同密度、运动模式以及遮挡情况下的超过130,000个行人实例的数据。此外，为了展示应对更加多样且复杂的半结构环境挑战的重要性，我们提出了一种新的混合多尺度融合网络（HMFN）。具体而言，为了在人口密集和存在大量遮挡的情况下检测行人，我们的方法能够有效地捕捉并融合不同规模的特征，通过精心设计的混合框架整合了稀疏卷积与普通卷积。对PFSD进行广泛实验表明，HMFN相较于现有技术提高了平均精度均值（mAP），从而证明其在处理复杂半结构化环境中的三维行人检测问题上的有效性。代码和基准测试可供获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in autonomous driving perception have revealedexceptional capabilities within structured environments dominated by vehiculartraffic. However, current perception models exhibit significant limitations insemi-structured environments, where dynamic pedestrians with more diverseirregular movement and occlusion prevail. We attribute this shortcoming to thescarcity of high-quality datasets in semi-structured scenes, particularlyconcerning pedestrian perception and prediction. In this work, we present themulti-modal Pedestrian-Focused Scene Dataset(PFSD), rigorously annotated insemi-structured scenes with the format of nuScenes. PFSD provides comprehensivemulti-modal data annotations with point cloud segmentation, detection, andobject IDs for tracking. It encompasses over 130,000 pedestrian instancescaptured across various scenarios with varying densities, movement patterns,and occlusions. Furthermore, to demonstrate the importance of addressing thechallenges posed by more diverse and complex semi-structured environments, wepropose a novel Hybrid Multi-Scale Fusion Network (HMFN). Specifically, todetect pedestrians in densely populated and occluded scenarios, our methodeffectively captures and fuses multi-scale features using a meticulouslydesigned hybrid framework that integrates sparse and vanilla convolutions.Extensive experiments on PFSD demonstrate that HMFN attains improvement in meanAverage Precision (mAP) over existing methods, thereby underscoring itsefficacy in addressing the challenges of 3D pedestrian detection in complexsemi-structured environments. Coding and benchmark are available.</description>
      <author>example@mail.com (Yueting Liu, Hanshi Wang, Zhengjun Zha, Weiming Hu, Jin Gao)</author>
      <guid isPermaLink="false">2502.15342v3</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>BEV-LIO(LC): BEV Image Assisted LiDAR-Inertial Odometry with Loop Closure</title>
      <link>http://arxiv.org/abs/2502.19242v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种结合了鸟瞰图（BEV）图像表示和几何点云配准的新型激光雷达惯性里程计框架，通过引入循环闭合检测来提高定位一致性。&lt;h4&gt;背景&lt;/h4&gt;现有的激光雷达惯性里程计方法在处理高密度点云时效率低下且无法有效利用特征进行循环闭合检测。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的激光雷达惯性里程计框架BEV-LIO(LC)，旨在通过鸟瞰图表示和几何点云配准，提高定位精度并实现高效的循环闭合检测。&lt;h4&gt;方法&lt;/h4&gt;{'点密度归一化': '将激光雷达点云投影到BEV图像上以提取特征', '轻量级CNN特征提取器': '用于从BEV图像中抽取局部和全局描述符', '重投影误差最小化': '与平面到点配准结合，集成于迭代扩展卡尔曼滤波器（iEKF）内', '循环闭合检测': '使用全局描述符建立KD-tree索引的关键帧数据库，并通过RANSAC提供粗略变换估计用于ICP'}&lt;h4&gt;主要发现&lt;/h4&gt;BEV-LIO(LC)在各种场景和不同类型的LiDAR中表现出优越的性能，实现了竞争性的定位精度。&lt;h4&gt;结论&lt;/h4&gt;该方法提高了激光雷达惯性里程计系统的效率和准确性，并通过引入高效的循环闭合检测进一步提升了全局一致性。&lt;h4&gt;翻译&lt;/h4&gt;这项工作介绍了BEV-LIO(LC)，这是一种新型的激光雷达-惯性里程计框架，结合了鸟瞰图（BEV）图像表示与基于几何点云配准的方法，并且通过BEV图像特征实现了循环闭合。通过对点密度进行归一化处理，将LiDAR点云投影到BEV图像上，从而能够高效地提取和匹配特征。使用轻量级的卷积神经网络（CNN）基特征提取器来从BEV图像中抽取独特的局部与全局描述符。局部描述符用于通过FAST关键点对BEV图像进行再投影误差构造，而全局描述符则有助于循环闭合检测。随后将最小化重投影误差整合进平面到点的配准，在迭代扩展卡尔曼滤波器（iEKF）中执行。在后端部分，使用全局描述符建立一个KD-tree索引的关键帧数据库来实现准确的循环闭合检测。一旦发现循环闭合，随机样本一致性（RANSAC）将从BEV图像匹配计算出粗略变换，作为迭代最近点算法（ICP）的初始估计值。随后细化后的变换被整合进因子图并结合里程计因素提升全局定位的一致性。在不同类型的LiDAR和各种场景下进行广泛的实验表明，该方法优于现有技术，并达到了具有竞争力的定位精度。我们的代码、视频及补充材料可从https://github.com/HxCa1/BEV-LIO-LC获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces BEV-LIO(LC), a novel LiDAR-Inertial Odometry (LIO)framework that combines Bird's Eye View (BEV) image representations of LiDARdata with geometry-based point cloud registration and incorporates loop closure(LC) through BEV image features. By normalizing point density, we project LiDARpoint clouds into BEV images, thereby enabling efficient feature extraction andmatching. A lightweight convolutional neural network (CNN) based featureextractor is employed to extract distinctive local and global descriptors fromthe BEV images. Local descriptors are used to match BEV images with FASTkeypoints for reprojection error construction, while global descriptorsfacilitate loop closure detection. Reprojection error minimization is thenintegrated with point-to-plane registration within an iterated Extended KalmanFilter (iEKF). In the back-end, global descriptors are used to create aKD-tree-indexed keyframe database for accurate loop closure detection. When aloop closure is detected, Random Sample Consensus (RANSAC) computes a coarsetransform from BEV image matching, which serves as the initial estimate forIterative Closest Point (ICP). The refined transform is subsequentlyincorporated into a factor graph along with odometry factors, improving theglobal consistency of localization. Extensive experiments conducted in variousscenarios with different LiDAR types demonstrate that BEV-LIO(LC) outperformsstate-of-the-art methods, achieving competitive localization accuracy. Ourcode, video and supplementary materials can be found athttps://github.com/HxCa1/BEV-LIO-LC.</description>
      <author>example@mail.com (Haoxin Cai, Shenghai Yuan, Xinyi Li, Junfeng Guo, Jianqi Liu)</author>
      <guid isPermaLink="false">2502.19242v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Pathology Report Generation and Multimodal Representation Learning for Cutaneous Melanocytic Lesions</title>
      <link>http://arxiv.org/abs/2502.19293v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;开发了一个专门用于皮肤病理领域的视觉-语言模型，该模型通过对比生成描述的方式工作，并基于42,512张HE染色的全切片图像和19,645份对应的病理报告进行训练与评估。&lt;h4&gt;背景&lt;/h4&gt;每年有数百万的黑色素细胞皮肤病变被病理学家检查，大多数是常见的痣。虽然这些病变可以在几秒钟内诊断出来，但撰写相应的病理报告却非常耗时。&lt;h4&gt;目的&lt;/h4&gt;通过自动化部分报告生成工作来减轻病理学家日益增加的工作量。&lt;h4&gt;方法&lt;/h4&gt;使用对比描述框架开发了一个视觉-语言模型，并利用一个包含42,512张HE染色的全切片图像和19,645份对应病理报告的数据集进行训练与评估。&lt;h4&gt;主要发现&lt;/h4&gt;由模型生成的常见痣的报告质量得分与专家病理学家书写的报告相当，但在稀有黑色素细胞病变亚型的情况下，报告生成较为困难，但是跨模态检索性能有了显著提升。&lt;h4&gt;结论&lt;/h4&gt;该视觉-语言模型在处理常见的黑色素细胞皮肤病变方面表现良好，并且对于罕见类型也有一定的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Millions of melanocytic skin lesions are examined by pathologists each year,the majority of which concern common nevi (i.e., ordinary moles). While most ofthese lesions can be diagnosed in seconds, writing the corresponding pathologyreport is much more time-consuming. Automating part of the report writingcould, therefore, alleviate the increasing workload of pathologists. In thiswork, we develop a vision-language model specifically for the pathology domainof cutaneous melanocytic lesions. The model follows the Contrastive Captionerframework and was trained and evaluated using a melanocytic lesion dataset of42,512 H&amp;E-stained whole slide images and 19,645 corresponding pathologyreports. Our results show that the quality scores of model-generated reportswere on par with pathologist-written reports for common nevi, assessed by anexpert pathologist in a reader study. While report generation revealed to bemore difficult for rare melanocytic lesion subtypes, the cross-modal retrievalperformance for these cases was considerably better.</description>
      <author>example@mail.com (Ruben T. Lucassen, Sander P. J. Moonemans, Tijn van de Luijtgaarden, Gerben E. Breimer, Willeke A. M. Blokx, Mitko Veta)</author>
      <guid isPermaLink="false">2502.19293v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal Contrastive Learning for Tumor-specific Missing Modality Synthesis</title>
      <link>http://arxiv.org/abs/2502.19390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究设计了一种生成模型，用于从现有模态中合成缺失的MRI影像，特别聚焦于肿瘤区域，并在对比学习过程中通过熵选择特征来提高效果。&lt;h4&gt;背景&lt;/h4&gt;多模式磁共振成像（MRI）对于提供互补的大脑解剖和病理信息至关重要，有助于更准确地诊断。但在临床环境中获取高质量的多模态MRI面临时间、成本和技术限制等挑战。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些困难，研究者开发了一种生成模型，该模型能够利用现有的源模态数据来合成缺失的目标模态影像，特别是在肿瘤区域进行有效的对比学习和特征选择。&lt;h4&gt;方法&lt;/h4&gt;所设计的网络采用了多模式对比学习，并在对比过程中通过熵选择关键特性。此外，该网络不仅可以生成目标模态图像，还可以预测分割输出，从而提高了生成肿瘤区域的能力，有助于提高下游任务的表现。&lt;h4&gt;主要发现&lt;/h4&gt;结合了对比、分割和自我表示损失的功能模型能够有效反映特定的目标信息并生成高质量的影像。&lt;h4&gt;结论&lt;/h4&gt;在Brain MR Image Synthesis挑战赛中，所提出的模型表现出色，在合成缺失模态方面超越其他方法。&lt;h4&gt;翻译&lt;/h4&gt;多模式MRI对于提供互补的大脑解剖和病理信息至关重要。然而，在临床环境中获取高质量的多模态MRI存在困难。因此，该研究设计了一种生成模型来合成缺失的目标模态影像，并在肿瘤区域使用熵选择关键特征进行对比学习，以提高效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal magnetic resonance imaging (MRI) is essential for providingcomplementary information about brain anatomy and pathology, leading to moreaccurate diagnoses. However, obtaining high-quality multi-modal MRI in aclinical setting is difficult due to factors such as time constraints, highcosts, and patient movement artifacts. To overcome this difficulty, there isincreasing interest in developing generative models that can synthesize missingtarget modality images from the available source ones. Therefore, we design agenerative model for missing MRI that integrates multi-modal contrastivelearning with a focus on critical tumor regions. Specifically, we integratemulti-modal contrastive learning, tailored for multiple source modalities, andenhance its effectiveness by selecting features based on entropy during thecontrastive learning process. Additionally, our network not only generates themissing target modality images but also predicts segmentation outputs,simultaneously. This approach improves the generator's capability to preciselygenerate tumor regions, ultimately improving performance in downstreamsegmentation tasks. By leveraging a combination of contrastive, segmentation,and additional self-representation losses, our model effectively reflectstarget-specific information and generate high-quality target images.Consequently, our results in the Brain MR Image Synthesis challenge demonstratethat the proposed model excelled in generating the missing modality.</description>
      <author>example@mail.com (Minjoo Lim, Bogyeong Kang, Tae-Eui Kam)</author>
      <guid isPermaLink="false">2502.19390v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>PointSea: Point Cloud Completion via Self-structure Augmentation</title>
      <link>http://arxiv.org/abs/2502.17053v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by International Journal of Computer Vision (IJCV).  Extension of our ICCV 2023 work: arXiv:2307.08492&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文提出了一个新的点云补全模型PointSea，该模型通过自我结构增强来实现从全局到局部的点云补全。&lt;h4&gt;背景&lt;/h4&gt;目前的点云补全方法依赖于3D坐标信息和其他额外数据（例如图像和扫描视角）来填充缺失的部分。这些方法存在一定的局限性。&lt;h4&gt;目的&lt;/h4&gt;探索如何仅利用原始点云自身的结构特征进行增强，从而实现更有效的全局到局部的点云补全任务。&lt;h4&gt;方法&lt;/h4&gt;{'全局阶段': '通过模拟从多个角度观察一个物理对象上的缺陷区域的方式，使用自投影深度图来增强数据表示。引入特征融合模块以跨模态输入为基础重构紧凑的全局形状。', '局部阶段': '提出了称为自结构对偶生成器的点生成器，该生成器将学习到的形状先验知识和几何自相似性相结合进行形状细化，并且采用适应每个点结构类型的双路径设计来调整细化策略。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PointSea能够有效地理解全局形状并从不完整输入中生成局部细节。&lt;h4&gt;结论&lt;/h4&gt;相较于现有的方法，PointSea在处理点云补全问题时表现出明显的改进效果。&lt;h4&gt;翻译&lt;/h4&gt;点云完成是3D视觉中的一个基本但尚未完全解决的问题。当前的方法通常依赖于三维坐标信息和其他附加数据（例如图像和扫描视角）来填补缺失的部分。不同于这些方法，我们探索了自我结构增强，并提出了用于全局到局部点云完成的PointSea模型。在全局阶段，考虑到如何检查物理对象上的缺陷区域时会从多个角度进行观察以获得更好的理解，因此，受此启发，PointSea通过利用来自多视角的自投影深度图来增强数据表示。为了从跨模态输入中重构紧凑的全球形状，我们整合了一个特征融合模块，在视内和视间层次上融合了特性。在局部阶段，为揭示高度细节结构，我们引入了一种称为自结构性对偶生成器的点生成器。该生成器结合了学习到的形状先验知识和几何自相似性进行形体细化。不同于现有的采用统一策略处理所有点的方法，我们的双路径设计适应于每个点的结构类型调整精炼策略以应对特定的不完整性。在广泛使用的基准测试上进行全面实验表明，PointSea有效地理解全局形状并从不完整输入中生成局部细节，显示出对现有方法的明显改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud completion is a fundamental yet not well-solved problem in 3Dvision. Current approaches often rely on 3D coordinate information and/oradditional data (e.g., images and scanning viewpoints) to fill in missingparts. Unlike these methods, we explore self-structure augmentation and proposePointSea for global-to-local point cloud completion. In the global stage,consider how we inspect a defective region of a physical object, we may observeit from various perspectives for a better understanding. Inspired by this,PointSea augments data representation by leveraging self-projected depth imagesfrom multiple views. To reconstruct a compact global shape from the cross-modalinput, we incorporate a feature fusion module to fuse features at bothintra-view and inter-view levels. In the local stage, to reveal highly detailedstructures, we introduce a point generator called the self-structuredual-generator. This generator integrates both learned shape priors andgeometric self-similarities for shape refinement. Unlike existing efforts thatapply a unified strategy for all points, our dual-path design adapts refinementstrategies conditioned on the structural type of each point, addressing thespecific incompleteness of each point. Comprehensive experiments on widely-usedbenchmarks demonstrate that PointSea effectively understands global shapes andgenerates local details from incomplete input, showing clear improvements overexisting methods.</description>
      <author>example@mail.com (Zhe Zhu, Honghua Chen, Xing He, Mingqiang Wei)</author>
      <guid isPermaLink="false">2502.17053v3</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning For Time Series Analysis With Application On Human Motion</title>
      <link>http://arxiv.org/abs/2502.19364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'时间序列数据的重要性': '时间序列数据在医学、电信和能源等领域中非常重要。', '分析任务类型': '包括分类、聚类、原型设计和回归等任务，这些任务分别用于识别异常运动、检测股市行为模式、扩展物理治疗数据集以及预测患者恢复情况。', '深度学习的应用': '近年来，在其他领域取得成功的背景下，深度学习在时间序列分析中越来越受到重视。', '研究贡献': '本论文通过特征工程提升分类性能，引入基础模型，并开发了一种紧凑且最先进的架构。同时利用自监督学习解决数据标签不足的问题。', '实际应用': '应用于人体运动分析（如动作识别和康复）以及合成样本生成方法以支持回归模型在数据稀缺的情况下进行原型设计。', '评价与展望': '评估了判别性和生成性模型的局限，并提倡建立一个稳健且标准化的评估框架。实验结果提供了新的见解和方法，推动时间序列分析的发展。'}&lt;h4&gt;翻译&lt;/h4&gt;该论文摘要讨论了时间序列数据分析在医学、电信及能源等领域的关键作用以及分类、聚类、原型设计与回归等具体任务的应用。它还强调了深度学习技术在这类数据中的重要性，并通过特征工程和基础模型的引入，旨在提升现有方法的有效性和准确性。此外，论文提出了解决有限标注数据问题的方法，例如自监督学习，在人体运动分析（如康复与动作识别）中应用这些方法以及开发用于扩展数据集的支持回归模型的合成样本生成技术。最后，作者对当前的技术进行批判性评估，并提出了一个更稳健、标准化的研究框架以促进时间序列分析领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series data, defined by equally spaced points over time, is essential infields like medicine, telecommunications, and energy. Analyzing it involvestasks such as classification, clustering, prototyping, and regression.Classification identifies normal vs. abnormal movements in skeleton-basedmotion sequences, clustering detects stock market behavior patterns,prototyping expands physical therapy datasets, and regression predicts patientrecovery. Deep learning has recently gained traction in time series analysisdue to its success in other domains. This thesis leverages deep learning toenhance classification with feature engineering, introduce foundation models,and develop a compact yet state-of-the-art architecture. We also addresslimited labeled data with self-supervised learning. Our contributions apply toreal-world tasks, including human motion analysis for action recognition andrehabilitation. We introduce a generative model for human motion data, valuablefor cinematic production and gaming. For prototyping, we propose a shape-basedsynthetic sample generation method to support regression models when data isscarce. Lastly, we critically evaluate discriminative and generative models,identifying limitations in current methodologies and advocating for a robust,standardized evaluation framework. Our experiments on public datasets providenovel insights and methodologies, advancing time series analysis with practicalapplications.</description>
      <author>example@mail.com (Ali Ismail-Fawaz)</author>
      <guid isPermaLink="false">2502.19364v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>ProxyTransformation: Preshaping Point Cloud Manifold With Proxy Attention For 3D Visual Grounding</title>
      <link>http://arxiv.org/abs/2502.19247v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种名为Proxy Transformation的方法，该方法旨在通过多模态任务有效地改进点云流形结构。&lt;h4&gt;背景&lt;/h4&gt;基于语言指令与3D环境的实时交互是实现具身智能的基础任务之一。然而，从RGB-D图像渲染出的点云包含大量冗余背景数据和内在噪声，这些干扰了目标区域的流形结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改进点云流形结构，使其适用于实时任务。&lt;h4&gt;方法&lt;/h4&gt;首先利用可变形点聚类技术识别目标区域内的点云子流形。然后引入Proxy Attention模块，该模块使用多模态代理指导点云变换。此外还设计了基于Proxy Attention的次流形变换生成模块，在全局层面由文本信息引导不同子流形的平移向量，并通过图像信息优化每个子流形内部的线性变换。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的Proxy Transformation方法在易目标和难目标上的性能分别提高了7.49%和4.60%，同时减少了注意力块的计算开销（降低40.6%）。这些成果标志着ego-centric 3D视觉定位领域的新SOTA。&lt;h4&gt;结论&lt;/h4&gt;研究展示了一种有效且稳健的方法来改进点云流形结构，进一步推动了具身智能领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;嵌入式智能要求代理根据语言指令在实时与三维环境中交互。该领域的基础任务是自体中心的3D视觉定位。然而，从RGB-D图像渲染出的点云保留了大量的冗余背景数据和内在噪声，这些干扰了目标区域的流形结构。现有的点云增强方法通常需要繁琐的过程来改进流形结构，这不适合实时任务。我们提出了一个适合多模态任务的Proxy Transformation方法，以高效地改进点云流形。该方法首先利用可变形点聚类技术识别目标区域内的点云子流形。接着引入了Proxy Attention模块，使用多模态代理引导点云变换。基于Proxy Attention设计了一个次流形变换生成模块，在全局层面由文本信息指导不同子流形的平移向量，并通过图像信息优化每个子流形内部的线性变换，从而精炼目标区域的局部点云流形结构。广泛的实验表明，Proxy Transformation显著优于现有方法，在易目标和难目标上分别提高了7.49%和4.60%，同时减少了注意力块的计算开销（降低40.6%）。这些结果建立了ego-centric 3D视觉定位领域的新SOTA，展示了该方法的有效性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied intelligence requires agents to interact with 3D environments inreal time based on language instructions. A foundational task in this domain isego-centric 3D visual grounding. However, the point clouds rendered from RGB-Dimages retain a large amount of redundant background data and inherent noise,both of which can interfere with the manifold structure of the target regions.Existing point cloud enhancement methods often require a tedious process toimprove the manifold, which is not suitable for real-time tasks. We proposeProxy Transformation suitable for multimodal task to efficiently improve thepoint cloud manifold. Our method first leverages Deformable Point Clustering toidentify the point cloud sub-manifolds in target regions. Then, we propose aProxy Attention module that utilizes multimodal proxies to guide point cloudtransformation. Built upon Proxy Attention, we design a submanifoldtransformation generation module where textual information globally guidestranslation vectors for different submanifolds, optimizing relative spatialrelationships of target regions. Simultaneously, image information guideslinear transformations within each submanifold, refining the local point cloudmanifold of target regions. Extensive experiments demonstrate that ProxyTransformation significantly outperforms all existing methods, achieving animpressive improvement of 7.49% on easy targets and 4.60% on hard targets,while reducing the computational overhead of attention blocks by 40.6%. Theseresults establish a new SOTA in ego-centric 3D visual grounding, showcasing theeffectiveness and robustness of our approach.</description>
      <author>example@mail.com (Qihang Peng, Henry Zheng, Gao Huang)</author>
      <guid isPermaLink="false">2502.19247v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>GraphBridge: Towards Arbitrary Transfer Learning in GNNs</title>
      <link>http://arxiv.org/abs/2502.19252v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures, 6 tables, to be published in ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）传统上是针对特定领域和任务进行训练的。这导致了在不同、异构的数据设置中转移所获得的知识存在重大障碍。&lt;h4&gt;目的&lt;/h4&gt;介绍GraphBridge，一个创新框架，旨在使知识能够在不同的任务和领域之间转移，避免对任务配置或图结构进行修改的需求。&lt;h4&gt;方法&lt;/h4&gt;GraphBridge允许任何预训练的GNN通过添加预测头和桥接网络来增强，该桥接网络将输入层与输出层连接起来。这种架构不仅保留了原始模型的基本知识，还支持任意维度的输出。&lt;h4&gt;主要发现&lt;/h4&gt;为了减少负向迁移问题，GraphBridge合并了源模型与一个同时训练的模型，从而减少了应用到目标域时源模型的偏差。该方法在包括图到图、节点到节点、图到节点和图到点云在内的多种转移学习场景中进行了全面评估。&lt;h4&gt;结论&lt;/h4&gt;通过16个代表这些场景的数据集进行的经验验证确认了框架对于任务无关和领域无关的知识迁移的能力，在GNN领域具有显著的进展。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络（GNNs）传统上按照每个领域的每个任务来训练。这在将所获得的知识转移到不同的、异构的数据设置中造成了重大障碍。本文引入了GraphBridge，一个新颖框架，旨在使知识能够在不同且多样化的任务和领域之间转移，同时不需要修改任务配置或图结构。具体而言，GraphBridge允许通过添加预测头和连接输入到输出层的桥接网络来增强任何预训练的GNN，这种架构不仅保留了原始模型内在的知识，并且支持任意维度的输出。为了减轻负向迁移问题，GraphBridge将源模型与一个同时训练的模型合并，从而减少应用于目标领域时源模型的偏差。我们的方法在包括图到图、节点到节点、图到节点和图到点云在内的各种转移学习场景中得到了彻底评估，并通过代表这些场景的16个数据集进行了实证验证，证实了该框架具备处理图类数据任务无关且领域无关的知识迁移的能力，在GNNs领域实现了显著的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are conventionally trained on a per-domain,per-task basis. It creates a significant barrier in transferring the acquiredknowledge to different, heterogeneous data setups. This paper introducesGraphBridge, a novel framework to enable knowledge transfer across disparatetasks and domains in GNNs, circumventing the need for modifications to taskconfigurations or graph structures. Specifically, GraphBridge allows for theaugmentation of any pre-trained GNN with prediction heads and a bridgingnetwork that connects the input to the output layer. This architecture not onlypreserves the intrinsic knowledge of the original model but also supportsoutputs of arbitrary dimensions. To mitigate the negative transfer problem,GraphBridg merges the source model with a concurrently trained model, therebyreducing the source bias when applied to the target domain. Our method isthoroughly evaluated across diverse transfer learning scenarios, includingGraph2Graph, Node2Node, Graph2Node, and graph2point-cloud. Empiricalvalidation, conducted over 16 datasets representative of these scenarios,confirms the framework's capacity for task- and domain-agnostic transferlearning within graph-like data, marking a significant advancement in the fieldof GNNs.</description>
      <author>example@mail.com (Li Ju, Xingyi Yang, Qi Li, Xinchao Wang)</author>
      <guid isPermaLink="false">2502.19252v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Global Graph Propagation with Hierarchical Information Transfer for Incomplete Contrastive Multi-view Clustering</title>
      <link>http://arxiv.org/abs/2502.19291v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种新的不完整多视角聚类方法被提出，该方法通过分层信息传递解决当前研究中存在的问题。&lt;h4&gt;背景&lt;/h4&gt;在现实世界中普遍存在大量缺失的多视图数据，使得不完整的多视图聚类成为一个重要的研究课题。然而，现有的方法虽然取得了显著进展，但仍然存在一些问题：无法有效挖掘缺失数据中的隐藏信息；大多数方法将表示学习和聚类分为两个独立阶段进行。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法以解决现有方法中存在的问题，并通过实验展示该方法的有效性和优越性。&lt;h4&gt;方法&lt;/h4&gt;首先设计特定视角的图卷积网络（GCN）来获得包含图结构信息的表示，然后将其融合到共识表示中。其次考虑了一层GCN只能转移一阶邻居节点的信息，提出了全局图传播的方法以处理缺失数据和学习深层表示。最后，通过权重共享伪分类器与对比学习设计了一个端到端框架，该框架结合了特定视角的表示学习、全局图传播以及分层信息传递进行联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;提出的模型在多个常用的数据集上进行了广泛的实验，并展示了优于其他最新方法的效果和优越性。&lt;h4&gt;结论&lt;/h4&gt;通过实验验证了所提出的方法的有效性和优越性，该方法不仅解决了现有问题，还提供了更好的聚类性能。相关代码可在指定的GitHub仓库中获取。&lt;h4&gt;翻译&lt;/h4&gt;不完整多视图聚类研究由于现实世界中存在的广泛缺失数据而变得重要。尽管现有的方法已经取得了很大的进步，但它们仍然存在一些问题：1）大多数方法不能有效挖掘隐藏在丢失数据中的信息；2）大多数方法通常将表示学习和聚类分为两个独立阶段进行，但这可能会影响聚类性能，因为聚类结果直接依赖于学到的表示。为了解决这些问题，我们提出了一种新的不完整多视图聚类方法，该方法使用分层信息传递。首先设计了特定视角的图卷积网络（GCN）以获取包含图结构信息的表示，并将其融合到共识表示中；其次提出了全局图传播的方法处理缺失数据并学习深层表示；最后通过权重共享伪分类器与对比学习建立了一个端到端框架，结合了特定视角的表示学习、全局图传播以及分层信息传递进行联合优化。广泛的实验显示我们的方法在多个常用的数据集上比其他最新方法更有效和优越。代码可在指定GitHub仓库中获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Incomplete multi-view clustering has become one of the important researchproblems due to the extensive missing multi-view data in the real world.Although the existing methods have made great progress, there are still someproblems: 1) most methods cannot effectively mine the information hidden in themissing data; 2) most methods typically divide representation learning andclustering into two separate stages, but this may affect the clusteringperformance as the clustering results directly depend on the learnedrepresentation. To address these problems, we propose a novel incompletemulti-view clustering method with hierarchical information transfer. Firstly,we design the view-specific Graph Convolutional Networks (GCN) to obtain therepresentation encoding the graph structure, which is then fused into theconsensus representation. Secondly, considering that one layer of GCN transfersone-order neighbor node information, the global graph propagation with theconsensus representation is proposed to handle the missing data and learn deeprepresentation. Finally, we design a weight-sharing pseudo-classifier withcontrastive learning to obtain an end-to-end framework that combinesview-specific representation learning, global graph propagation withhierarchical information transfer, and contrastive clustering for jointoptimization. Extensive experiments conducted on several commonly-used datasetsdemonstrate the effectiveness and superiority of our method in comparison withother state-of-the-art approaches. The code is available athttps://github.com/KelvinXuu/GHICMC.</description>
      <author>example@mail.com (Guoqing Chao, Kaixin Xu, Xijiong Xie, Yongyong Chen)</author>
      <guid isPermaLink="false">2502.19291v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>AutoML for Multi-Class Anomaly Compensation of Sensor Drift</title>
      <link>http://arxiv.org/abs/2502.19180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in Measurement Journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了两种解决传感器漂移问题的方法：一种是新的验证模型的补偿学习范式，另一种是通过自动化机器学习技术提高分类性能并补偿传感器漂移。&lt;h4&gt;背景&lt;/h4&gt;在工业测量系统中，精确的数据输出对于保持监测过程中的准确性和可靠性至关重要。然而，现有的模型训练方法使用标准交叉验证方法来估计模型性能时，未能充分考虑随时间累积的传感器漂移问题，导致模型预测未来数据偏差的能力减弱。&lt;h4&gt;目的&lt;/h4&gt;提出新的补偿学习范式和自动机器学习技术以改进分类性能，并有效应对传感器漂移。&lt;h4&gt;方法&lt;/h4&gt;论文提出了两个主要解决方案：(1) 一种新颖的用于验证模型精度的新颖传感器漂移补偿学习范例；(2) 自动化机器学习（AutoML）方法，通过采用数据平衡、元学习、自动集成学习、超参数优化、特征选择和提升等策略来改进分类性能。&lt;h4&gt;主要发现&lt;/h4&gt;标准交叉验证方法在处理长期累积的传感器漂移时过于乐观，并且现有模型难以准确预测未来的数据偏差。论文展示了一种新的补偿学习范式以及AutoML-DC（针对漂移补偿）模型，该模型通过上述技术手段显著提高了分类性能。&lt;h4&gt;结论&lt;/h4&gt;提出的AutoML-DC方法不仅改善了分类性能，还能够有效适应不同的传感器漂移严重程度，从而增强了模型的泛化能力和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Addressing sensor drift is essential in industrial measurement systems, whereprecise data output is necessary for maintaining accuracy and reliability inmonitoring processes, as it progressively degrades the performance of machinelearning models over time. Our findings indicate that the standardcross-validation method used in existing model training overestimatesperformance by inadequately accounting for drift. This is primarily becausetypical cross-validation techniques allow data instances to appear in bothtraining and testing sets, thereby distorting the accuracy of the predictiveevaluation. As a result, these models are unable to precisely predict futuredrift effects, compromising their ability to generalize and adapt to evolvingdata conditions. This paper presents two solutions: (1) a novel sensor driftcompensation learning paradigm for validating models, and (2) automated machinelearning (AutoML) techniques to enhance classification performance andcompensate sensor drift. By employing strategies such as data balancing,meta-learning, automated ensemble learning, hyperparameter optimization,feature selection, and boosting, our AutoML-DC (Drift Compensation) modelsignificantly improves classification performance against sensor drift.AutoML-DC further adapts effectively to varying drift severities.</description>
      <author>example@mail.com (Melanie Schaller, Mathis Kruse, Antonio Ortega, Marius Lindauer, Bodo Rosenhahn)</author>
      <guid isPermaLink="false">2502.19180v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>On the Importance of Text Preprocessing for Multimodal Representation Learning and Pathology Report Generation</title>
      <link>http://arxiv.org/abs/2502.19285v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了从病理报告中选择信息进行视觉-语言模型训练对多模态表示和生成报告质量的影响。&lt;h4&gt;背景&lt;/h4&gt;目前很多视觉-语言模型在病理科的应用能够实现多模态病例检索和自动化报告生成，但这些模型往往基于包含患者历史等无法从全片图像推断出的信息的病理报告进行训练，这可能导致生成报告中的幻觉句子。&lt;h4&gt;目的&lt;/h4&gt;研究通过对比两种不同训练数据集（完整报告与仅包含细胞和组织外观描述的预处理报告）对视觉-语言模型性能的影响来探究如何选择信息以提高多模态表示的质量和生成报告的质量。&lt;h4&gt;方法&lt;/h4&gt;使用BLIP-2框架，并利用一个皮肤黑色素瘤病灶的数据集进行实验，该数据集包括42,433张H&amp;E染色的全片图像及其对应的19,636份病理报告。通过图像到文本和文本到图像检索以及由专业病理学家对生成报告的质量评估来评测模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;预处理文本可以防止报告生成中的幻觉，尽管这提升了生成报告质量但使用完整报告训练视觉-语言模型在跨模态检索中表现更好。&lt;h4&gt;结论&lt;/h4&gt;选择适当的训练数据对于提高视觉-语言模型的多模态表示和自动化病理报告生成的质量至关重要。然而，在实际应用中需要权衡预处理文本以避免幻觉与保持跨模态检索性能之间的关系。&lt;h4&gt;翻译&lt;/h4&gt;视觉-语言模型在病理科的应用能够实现多模态病例检索及自动化报告生成，但目前的很多模型是在包含无法从全片图像推断出的信息（如患者历史）的病理报告上训练出来的，这可能导致报告生成中的幻觉句子。为了探讨选择信息进行视觉-语言建模对质量的影响，研究人员对比了完整报告和仅描述细胞及组织外观的预处理报告训练得到的模型效果，并使用BLIP-2框架以及一个皮肤黑色素瘤病灶的数据集进行了实验评估。结果表明：文本预处理可以防止生成中的幻觉现象；尽管改善了生成报告的质量，但以完整报告训练出的视觉语言模型在跨模态检索中表现更好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models in pathology enable multimodal case retrieval andautomated report generation. Many of the models developed so far, however, havebeen trained on pathology reports that include information which cannot beinferred from paired whole slide images (e.g., patient history), potentiallyleading to hallucinated sentences in generated reports. To this end, weinvestigate how the selection of information from pathology reports forvision-language modeling affects the quality of the multimodal representationsand generated reports. More concretely, we compare a model trained on fullreports against a model trained on preprocessed reports that only includesentences describing the cell and tissue appearances based on the H&amp;E-stainedslides. For the experiments, we built upon the BLIP-2 framework and used acutaneous melanocytic lesion dataset of 42,433 H&amp;E-stained whole slide imagesand 19,636 corresponding pathology reports. Model performance was assessedusing image-to-text and text-to-image retrieval, as well as qualitativeevaluation of the generated reports by an expert pathologist. Our resultsdemonstrate that text preprocessing prevents hallucination in reportgeneration. Despite the improvement in the quality of the generated reports,training the vision-language model on full reports showed better cross-modalretrieval performance.</description>
      <author>example@mail.com (Ruben T. Lucassen, Tijn van de Luijtgaarden, Sander P. J. Moonemans, Gerben E. Breimer, Willeke A. M. Blokx, Mitko Veta)</author>
      <guid isPermaLink="false">2502.19285v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Multiview graph dual-attention deep learning and contrastive learning for multi-criteria recommender systems</title>
      <link>http://arxiv.org/abs/2502.19271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于多边图的新型表示方式，用于解决单一标准推荐系统在处理多准则推荐时遇到的问题。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型对于推荐系统帮助用户选择符合其偏好的项目至关重要。然而，在单标准推荐系统中，存在忽视物品多样属性的问题，这些问题通过多准则推荐系统（MCRS）得以部分解决。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的表示方法和使用Multiview Dual Graph Attention Networks (MDGAT)来更好地考虑用户与物品之间的关系，并在每个视图及整个图形上运用对比学习以区分正负样本。&lt;h4&gt;方法&lt;/h4&gt;基于多边图，其中每条边代表了用户对项目的某一准则的评分；采用MDGAT模型，此模型能够有效处理局部（基于准则）和全局（多准则）的关系。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界数据集上的评估表明该方法比基线模型具有更高的预测准确性。MDGAT能有效地捕捉邻居的局部和全局影响以及节点之间的相似性。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的表示形式和MDGAT模型，能够更准确地预测项目评分，并有效解决了多准则推荐系统中的挑战。&lt;h4&gt;翻译&lt;/h4&gt;基于深度学习模型的推荐系统对于帮助用户选择符合他们偏好和兴趣的项目非常重要。然而，在单一标准推荐系统中仍然存在一个重要问题，即这些系统往往忽视物品的多样性属性，这些问题通过使用多准则推荐系统（MCRS）得以部分解决。虽然共享嵌入向量的方法用于处理基于多个标准的评分但难以捕捉用户与物品之间根据特定标准的具体关系。在这项研究中，我们提出了一种新的表示方法针对多准则推荐系统，采用一个多边图结构，其中每个边代表用户的某一项准则对项目的评分，并引入了Multiview Dual Graph Attention Networks（MDGAT）模型。使用MDGAT对于充分考虑用户与物品之间关系非常重要，因为存在局部（基于标准的）和全局（跨多个标准的）的关系。此外，在每个视图中定义锚点以相似性为基础，并运用局部和全局对比学习来区分各个视图以及整个图形中的正样本和负样本。我们在两个真实世界数据集上评估了该方法，根据项目评分预测性能进行了评估。结果表明与基线方法相比，在相同的数据集中使用我们的方法可以达到更高的准确率。MDGAT有效地捕捉邻居的局部和全局影响以及节点之间的相似性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems leveraging deep learning models have been crucial forassisting users in selecting items aligned with their preferences andinterests. However, a significant challenge persists in single-criteriarecommender systems, which often overlook the diverse attributes of items thathave been addressed by Multi-Criteria Recommender Systems (MCRS). Sharedembedding vector for multi-criteria item ratings but have struggled to capturethe nuanced relationships between users and items based on specific criteria.In this study, we present a novel representation for Multi-Criteria RecommenderSystems (MCRS) based on a multi-edge bipartite graph, where each edgerepresents one criterion rating of items by users, and Multiview Dual GraphAttention Networks (MDGAT). Employing MDGAT is beneficial and important foradequately considering all relations between users and items, given thepresence of both local (criterion-based) and global (multi-criteria) relations.Additionally, we define anchor points in each view based on similarity andemploy local and global contrastive learning to distinguish between positiveand negative samples across each view and the entire graph. We evaluate ourmethod on two real-world datasets and assess its performance based on itemrating predictions. The results demonstrate that our method achieves higheraccuracy compared to the baseline method for predicting item ratings on thesame datasets. MDGAT effectively capture the local and global impact ofneighbours and the similarity between nodes.</description>
      <author>example@mail.com (Saman Forouzandeh, Pavel N. Krivitsky, Rohitash Chandra)</author>
      <guid isPermaLink="false">2502.19271v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Biological and Machine Intelligence: Attention Mechanisms in Brain-Computer Interfaces</title>
      <link>http://arxiv.org/abs/2502.19281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了在脑机接口(BCI)应用中，传统和基于Transformer的注意力机制及其在多模态数据融合中的作用。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习技术的发展，注意力机制已经成为EEG信号分析不可或缺的一部分，并显著提升了BCI的应用效果。&lt;h4&gt;目的&lt;/h4&gt;该论文旨在全面回顾传统的和基于Transformers的注意力机制、它们的嵌入策略以及这些方法如何应用于基于EEG的BCI中，特别关注多模态数据融合。&lt;h4&gt;方法&lt;/h4&gt;本文将注意力机制分为传统注意力机制与基于Transformer的多头自注意机制两大类。前者通常结合卷积网络和递归网络使用；后者擅长捕捉长范围依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过捕获EEG信号在时间、频率及空间通道的变化，注意力机制能提高特征提取能力、表示学习能力和模型鲁棒性。此外，注意力机制不仅提升了单模态分析的能力，还增强了多模态EEG应用的效果，促进了有效融合EEG与其他生理或感觉数据。&lt;h4&gt;结论&lt;/h4&gt;本文探讨了基于注意力的EEG建模中现有的挑战和新兴趋势，并展望了未来的发展方向，以推动BCI技术的进步。&lt;h4&gt;翻译&lt;/h4&gt;随着深度学习技术的迅速发展，注意力机制已经成为脑电图（EEG）信号分析中的关键组成部分，显著增强了脑机接口（BCI）应用的效果。本文综述了传统和基于Transformer的注意力机制、它们的嵌入策略以及这些方法如何应用于基于EEG的BCI中，特别关注多模态数据融合。通过捕捉EEG信号在时间、频率及空间通道的变化，注意力机制能够提高特征提取能力、表示学习能力和模型鲁棒性。这些方法可以分为两大类：传统注意力机制，通常与卷积网络和递归网络结合使用；基于Transformer的多头自注意机制，擅长捕捉长范围依赖关系。除了单模态分析之外，注意力机制还提升了多模态EEG应用的效果，促进了有效融合EEG与其他生理或感觉数据的能力。最后，本文讨论了基于注意力的EEG建模中现有的挑战和新兴趋势，并为未来的研究方向提供了有价值的见解，以推动BCI技术的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancement of deep learning, attention mechanisms have becomeindispensable in electroencephalography (EEG) signal analysis, significantlyenhancing Brain-Computer Interface (BCI) applications. This paper presents acomprehensive review of traditional and Transformer-based attention mechanisms,their embedding strategies, and their applications in EEG-based BCI, with aparticular emphasis on multimodal data fusion. By capturing EEG variationsacross time, frequency, and spatial channels, attention mechanisms improvefeature extraction, representation learning, and model robustness. Thesemethods can be broadly categorized into traditional attention mechanisms, whichtypically integrate with convolutional and recurrent networks, andTransformer-based multi-head self-attention, which excels in capturinglong-range dependencies. Beyond single-modality analysis, attention mechanismsalso enhance multimodal EEG applications, facilitating effective fusion betweenEEG and other physiological or sensory data. Finally, we discuss existingchallenges and emerging trends in attention-based EEG modeling, highlightingfuture directions for advancing BCI technology. This review aims to providevaluable insights for researchers seeking to leverage attention mechanisms forimproved EEG interpretation and application.</description>
      <author>example@mail.com (Jiyuan Wang, Weishan Ye, Jialin He, Li Zhang, Gan Huang, Zhuliang Yu, Zhen Liang)</author>
      <guid isPermaLink="false">2502.19281v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>A Lightweight and Extensible Cell Segmentation and Classification Model for Whole Slide Images</title>
      <link>http://arxiv.org/abs/2502.19217v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种提高数字病理学中细胞级分析工具质量和性能的方法，通过创建一个轻量级、可扩展的细胞分割和分类模型来解决数据集颗粒度限制、注释不一致等问题。&lt;h4&gt;背景&lt;/h4&gt;开发临床有用的细胞级别分析工具在数字病理学中面临挑战，包括数据集粒度过粗、标注一致性差、计算需求高以及难以将新技术整合到工作流程中的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一个解决方案来改进数据质量、模型性能和可用性。&lt;h4&gt;方法&lt;/h4&gt;[{'步骤1': '更新数据标签通过交叉重标，提高PanNuke和MoNuSAC的数据注释精度，并生成包含七种不同细胞类型的统一数据集。'}, {'步骤2': '利用H-Optimus基础模型作为固定的编码器来改进同时进行分割和分类任务的特征表示。'}, {'步骤3': '为解决基础模型的计算需求问题，通过知识蒸馏减少模型大小和复杂性，保持性能大致相当。'}, {'步骤4': '将蒸馏后的模型集成到QuPath中，这是一个广泛使用的开源数字病理平台。'}]&lt;h4&gt;主要发现&lt;/h4&gt;[{'改进': '基于H-Optimus的模型在分割和分类性能上优于CNN基线模型，在R²评分从0.575提升至0.871及PQ评分从0.450升至0.492方面有明显改善，表明与实际细胞计数更一致且改进了分割质量。'}, {'性能': '蒸馏后的模型保持类似水平的性能同时参数数量减少到原来的四十八分之一。'}]&lt;h4&gt;结论&lt;/h4&gt;通过降低计算复杂度并整合至工作流程，该方法可能会对诊断产生重大影响、减轻病理学家的工作量，并提高结果质量。&lt;h4&gt;翻译&lt;/h4&gt;开发临床有用的细胞级别分析工具在数字病理学中面临数据集粒度过粗、标注一致性差等问题。为解决这些问题，论文提出了一种解决方案：创建一个轻量级的细胞分割和分类模型来提升数据质量和模型性能。此方法通过改进数据标签更新（包括交叉重标），利用H-Optimus基础模型进行特征表示优化，并通过知识蒸馏简化模型结构，同时保持性能水平。结果表明基于该方案的新模型在QuPath平台上的表现优于传统CNN基线模型，在多个评估指标上显示出显著的提升。此外，该方法还有望大幅降低计算复杂度，提高临床应用中的工作效率和诊断准确性。然而，尽管展示了很大的潜力，这种方法仍需进一步验证才能应用于临床实践中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing clinically useful cell-level analysis tools in digital pathologyremains challenging due to limitations in dataset granularity, inconsistentannotations, high computational demands, and difficulties integrating newtechnologies into workflows. To address these issues, we propose a solutionthat enhances data quality, model performance, and usability by creating alightweight, extensible cell segmentation and classification model. First, weupdate data labels through cross-relabeling to refine annotations of PanNukeand MoNuSAC, producing a unified dataset with seven distinct cell types.Second, we leverage the H-Optimus foundation model as a fixed encoder toimprove feature representation for simultaneous segmentation and classificationtasks. Third, to address foundation models' computational demands, we distillknowledge to reduce model size and complexity while maintaining comparableperformance. Finally, we integrate the distilled model into QuPath, a widelyused open-source digital pathology platform. Results demonstrate improvedsegmentation and classification performance using the H-Optimus-based modelcompared to a CNN-based model. Specifically, average $R^2$ improved from 0.575to 0.871, and average $PQ$ score improved from 0.450 to 0.492, indicatingbetter alignment with actual cell counts and enhanced segmentation quality. Thedistilled model maintains comparable performance while reducing parameter countby a factor of 48. By reducing computational complexity and integrating intoworkflows, this approach may significantly impact diagnostics, reducepathologist workload, and improve outcomes. Although the method shows promise,extensive validation is necessary prior to clinical deployment.</description>
      <author>example@mail.com (Nikita Shvetsov, Thomas K. Kilvaer, Masoud Tafavvoghi, Anders Sildnes, Kajsa Møllersen, Lill-Tove Rasmussen Busund, Lars Ailo Bongo)</author>
      <guid isPermaLink="false">2502.19217v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Multi-level Attention-guided Graph Neural Network for Image Restoration</title>
      <link>http://arxiv.org/abs/2502.19181v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文介绍了一种新的图像恢复技术，通过多级注意力引导的图神经网络解决当前深度学习方法在处理图像复原任务时忽略多重尺度信息的问题。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于卷积神经网络的方法在图像修复领域取得了显著成就。然而，大多数这些方法通常集中在单一尺度上，忽视了融合多种尺度的信息。为了补充局部特征的不足，需要集成全局特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决现有模型未能明确构建全局特性或考虑全局与局部特征之间关系的问题。&lt;h4&gt;方法&lt;/h4&gt;该论文提出了多级注意力引导图神经网络（multi-level attention-guided graph neural network）。通过使用多重注意机制，在特征映射内显式构造元素块图和元素图，以提取图像的局部结构特性和全局表示信息。这些图形通过多重注意机制实时学习动态连接，并利用图卷积算法传播和聚合信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多个经典图像恢复任务中表现出色，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效融合局部元素块信息和全局元素表示信息来更有效地修复图像中的丢失数据。&lt;h4&gt;翻译&lt;/h4&gt;近年来，深度学习在图像复原领域取得了显著成功。然而，大多数基于卷积神经网络的方法主要集中在单一尺度上，忽视了多尺度信息的整合。为了补充局部特征的不足，在图像恢复任务中需要集成全局特性。尽管最近的神经网络算法在特征提取方面取得重大进展，但许多模型未能明确构建全局特性或考虑全局与局部特性的关系。本文提出了一种新的方法——多级注意力引导图神经网络（multi-level attention-guided graph neural network），该方法显式地使用多重注意机制，在特征映射内构造元素块图和元素图以提取图像的局部结构特性和全局表示信息。在结合了本地元素块信息和全局元素表示信息后，算法可以更有效地恢复图像中的丢失数据。实验结果显示该方法在多个经典图像复原任务中表现卓越，达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, deep learning has achieved remarkable success in the fieldof image restoration. However, most convolutional neural network-based methodstypically focus on a single scale, neglecting the incorporation of multi-scaleinformation. In image restoration tasks, local features of an image are ofteninsufficient, necessitating the integration of global features to complementthem. Although recent neural network algorithms have made significant stridesin feature extraction, many models do not explicitly model global features orconsider the relationship between global and local features. This paperproposes multi-level attention-guided graph neural network. The proposednetwork explicitly constructs element block graphs and element graphs withinfeature maps using multi-attention mechanisms to extract both local structuralfeatures and global representation information of the image. Since the networkstruggles to effectively extract global information during image degradation,the structural information of local feature blocks can be used to correct andsupplement the global information. Similarly, when element block information inthe feature map is missing, it can be refined using global elementrepresentation information. The graph within the network learns real-timedynamic connections through the multi-attention mechanism, and information ispropagated and aggregated via graph convolution algorithms. By combining localelement block information and global element representation information fromthe feature map, the algorithm can more effectively restore missing informationin the image. Experimental results on several classic image restoration tasksdemonstrate the effectiveness of the proposed method, achievingstate-of-the-art performance.</description>
      <author>example@mail.com (Jiatao Jiang, Zhen Cui, Chunyan Xu, Jian Yang)</author>
      <guid isPermaLink="false">2502.19181v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Foundation-Model-Based Industrial Defect Detection</title>
      <link>http://arxiv.org/abs/2502.19106v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;随着工业产品变得丰富和复杂，视觉工业缺陷检测受到了广泛关注。研究中介绍了基于传统方法的统计分析、异常数据合成建模及生成模型的方法，并重点讨论了基础模型（FM）在提高检测精度方面的应用及其带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;工业产品的多样性和复杂性增加，促使对二维和三维视觉特征模型的研究增多。传统的缺陷检测主要依赖于统计分析方法以及基于生成的模型。&lt;h4&gt;目的&lt;/h4&gt;系统地回顾并对比了不同角度的基础模型方法，并简要回顾最近发表的非基础模型（NFM）的方法。同时讨论了FM与NFM在训练目标、模型结构和规模及性能方面的差异。&lt;h4&gt;方法&lt;/h4&gt;论文中详细比较了各种基于基础模型的技术，探讨这些技术如何利用视觉和文本语义先验知识来改进工业产品的缺陷检测，并分析了使用基础模型带来的模型复杂性和推断速度减慢的问题。此外还介绍了探索轻量级建模方式的方法。&lt;h4&gt;主要发现&lt;/h4&gt;通过对比研究发现，基于基础模型的方法更适合于少样本学习（few-shot learning）和零样本学习（zero-shot learning），这些方法更符合实际的工业应用场景，值得深入研究。&lt;h4&gt;结论&lt;/h4&gt;尽管使用基础模型可以提高检测精度，但同时也增加了模型复杂性并减慢了推理速度。因此需要探索轻量级建模方式以应对这些问题。此外，基于基础模型的方法在少样本学习和零样本学习中表现良好，这对于实际应用非常有帮助。&lt;h4&gt;翻译&lt;/h4&gt;随着工业产品变得丰富且多样化，视觉工业缺陷检测技术受到了越来越多的关注，包括二维及三维视觉特征的建模。传统方法通过统计分析、异常数据合成以及生成性模型来分离产品缺陷特征，并完成缺陷检测任务。最近，基础模型（Foundation Models）的发展带来了视觉和文本语义先验知识的应用，许多基于此的方法试图提高检测精度，但同时也增加了模型复杂度并减慢了推理速度。一些基于基础模型的方法已经开始探索轻量化建模方式，这些方法逐渐引起了关注，并值得系统性地分析。本文从多个角度对基于基础模型的视觉工业缺陷检测技术进行了系统的调查、比较和讨论，同时简要回顾最近发表的一些非基础模型的方法。此外还探讨了基于基础模型与非基础模型的方法在训练目标、模型结构及性能方面的差异，并指出了未来研究的方向。通过对比分析发现，基于基础模型的技术更适合处理少样本学习及零样本学习问题，这更符合实际工业应用场景中的需求，值得进一步深入研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As industrial products become abundant and sophisticated, visual industrialdefect detection receives much attention, including two-dimensional andthree-dimensional visual feature modeling. Traditional methods use statisticalanalysis, abnormal data synthesis modeling, and generation-based models toseparate product defect features and complete defect detection. Recently, theemergence of foundation models has brought visual and textual semantic priorknowledge. Many methods are based on foundation models (FM) to improve theaccuracy of detection, but at the same time, increase model complexity and slowdown inference speed. Some FM-based methods have begun to explore lightweightmodeling ways, which have gradually attracted attention and deserve to besystematically analyzed. In this paper, we conduct a systematic survey withcomparisons and discussions of foundation model methods from different aspectsand briefly review non-foundation model (NFM) methods recently published.Furthermore, we discuss the differences between FM and NFM methods fromtraining objectives, model structure and scale, model performance, andpotential directions for future exploration. Through comparison, we find FMmethods are more suitable for few-shot and zero-shot learning, which are morein line with actual industrial application scenarios and worthy of in-depthresearch.</description>
      <author>example@mail.com (Tianle Yang, Luyao Chang, Jiadong Yan, Juntao Li, Zhi Wang, Ke Zhang)</author>
      <guid isPermaLink="false">2502.19106v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>EndoMamba: An Efficient Foundation Model for Endoscopic Videos</title>
      <link>http://arxiv.org/abs/2502.19090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为EndoMamba的新型基础模型，旨在通过优化实时推理和增强表征学习来解决内窥镜视频任务中的计算效率低和性能不足问题。&lt;h4&gt;背景&lt;/h4&gt;内窥镜视频任务如视觉导航和手术阶段识别在微创手术中至关重要。然而，最近的视频基础模型由于计算复杂性和有限的数据集预训练而面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种专门针对内窥镜视频设计的基础模型EndoMamba，以提高实时推理能力并改善广义时空表示学习。&lt;h4&gt;方法&lt;/h4&gt;{'1': '提出了优化后的EndoMamba骨干网络，以解决计算效率问题。该网络利用双向Mamba模块进行空间建模，并使用普通Mamba模块进行时间域上的从过去到现在的推断。', '2': '设计了一种自监督分层预训练方案，用于增强EndoMamba的表征学习能力，通过结合掩码重构和辅助监督来提取内窥镜视频中的时空结构和更广泛的知识。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'1': 'EndoMamba在四个下游任务上（分类、分割、手术阶段识别和定位）的表现优于现有基础模型和特定任务方法。', '2': '实验表明，EndoMamba能够同时保持实时推理速度并提供更好的性能。'}&lt;h4&gt;结论&lt;/h4&gt;EndoMamba展示了内窥镜视频处理中的高效能与实用性，在微创外科手术中具有广泛的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了用于微创手术的内窥镜视频任务，如视觉导航和手术阶段识别，通过实时提供支持来发挥重要作用。尽管最近的视频基础模型显示出前景，但它们在计算效率低以及由于预训练时缺乏内窥镜数据而导致性能不佳方面面临问题。为了应对这些问题，论文提出了EndoMamba——一种专为实时推理而设计的基础模型，在学习泛化的时空表示的同时还能实现实时推断。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Endoscopic video-based tasks, such as visual navigation and surgical phaserecognition, play a crucial role in minimally invasive surgeries by providingreal-time assistance. While recent video foundation models have shown promise,their applications are hindered by (1) computational inefficiencies and (2)suboptimal performance caused by limited data for pre-training in endoscopy. Toaddress these issues, we present EndoMamba, a foundation model designed forreal-time inference while learning generalized spatiotemporal representations.First, to mitigate computational inefficiencies, we propose the EndoMambabackbone, optimized for real-time inference. Inspired by recent advancements instate space models, EndoMamba integrates Bidirectional Mamba blocks for spatialmodeling within individual frames and vanilla Mamba blocks for past-to-presentreasoning across the temporal domain. This design enables both strongspatiotemporal modeling and efficient inference in online video streams.Second, we propose a self-supervised hierarchical pre-training diagram toenhance EndoMamba's representation learning using endoscopic videos andincorporating general video domain knowledge. Specifically, our approachcombines masked reconstruction with auxiliary supervision, leveraging low-levelreconstruction to capture spatial-temporal structures and high-level alignmentto transfer broader knowledge from a pretrained general-video domain foundationmodel. Extensive experiments on four downstream tasks--classification,segmentation, surgical phase recognition, and localization--demonstrate thatEndoMamba outperforms existing foundation models and task-specific methodswhile maintaining real-time inference speed. The source code will be releasedupon acceptance.</description>
      <author>example@mail.com (Qingyao Tian, Huai Liao, Xinyan Huang, Bingyu Yang, Dongdong Lei, Sebastien Ourselin, Hongbin Liu)</author>
      <guid isPermaLink="false">2502.19090v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Leg Exoskeleton Odometry using a Limited FOV Depth Sensor</title>
      <link>http://arxiv.org/abs/2502.19237v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的里程计算法，该算法结合了外骨骼的本体感受数据和深度相机获取的点云信息，以生成准确的地表高度图。这种方法在有限视野和传感器运动较大的情况下尤其有效。&lt;h4&gt;背景&lt;/h4&gt;为了使腿部外骨骼能够在真实世界环境中有效地运行，必须能够感知和理解周围地形。然而，与其它腿足机器人相比，外骨骼由于人体的存在而限制了深度传感器的安装位置，导致视场受限且传感器运动更大，这使得里程计技术面临更大的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的里程计算法来解决腿部外骨骼因有限视野和传感器移动带来的问题，该算法能够生成准确的地表高度图。&lt;h4&gt;方法&lt;/h4&gt;利用扩展卡尔曼滤波器（EKF）融合了外骨骼的运动学和惯性测量数据，并通过定制化的迭代最近点（ICP）算法将新的点云与地表高度图进行配准。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证显示，该方法能够减少漂移并提高地表高度图的质量，相比单纯依靠本体感受的方法有明显改善，同时也优于传统的基于点云地图的方法。&lt;h4&gt;结论&lt;/h4&gt;提出的新里程计算法在生成准确的地表高度图方面表现良好，为外骨骼在复杂环境下的有效运行提供了技术支持。&lt;h4&gt;翻译&lt;/h4&gt;为了使腿部外骨骼能够在真实世界环境中有效地运作，它们必须能够感知并理解周围的地形。然而，与其它腿足机器人不同的是，由于人体的存在，外骨骼的深度传感器安装位置受到限制，这导致视场较小且运动更大，使得里程计技术更加困难。为了解决这个问题，我们提出了一种新的融合了外骨骼本体感受数据和来自深度相机点云信息的新里程计算法，以生成准确的地表高度图，即使是在有限视野和传感器运动较大的情况下也能做到这一点。该方法利用扩展卡尔曼滤波器（EKF）结合运动学与惯性测量，并通过定制化的迭代最近点（ICP）算法将新获取的点云数据配准到地表高度图上。实验验证表明，我们的方法可以减少漂移并提高生成的地表高度图的质量，这在单纯依靠本体感受的数据基础上得到了改善，并且也优于传统的基于点云地图的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For leg exoskeletons to operate effectively in real-world environments, theymust be able to perceive and understand the terrain around them. However,unlike other legged robots, exoskeletons face specific constraints on wheredepth sensors can be mounted due to the presence of a human user. Theseconstraints lead to a limited Field Of View (FOV) and greater sensor motion,making odometry particularly challenging. To address this, we propose a novelodometry algorithm that integrates proprioceptive data from the exoskeletonwith point clouds from a depth camera to produce accurate elevation mapsdespite these limitations. Our method builds on an extended Kalman filter (EKF)to fuse kinematic and inertial measurements, while incorporating a tailorediterative closest point (ICP) algorithm to register new point clouds with theelevation map. Experimental validation with a leg exoskeleton demonstrates thatour approach reduces drift and enhances the quality of elevation maps comparedto a purely proprioceptive baseline, while also outperforming a moretraditional point cloud map-based variant.</description>
      <author>example@mail.com (Fabio Elnecave Xavier, Matis Viozelange, Guillaume Burger, Marine Pétriaux, Jean-Emmanuel Deschaud, François Goulette)</author>
      <guid isPermaLink="false">2502.19237v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks embedded into Margules model for vapor-liquid equilibria prediction</title>
      <link>http://arxiv.org/abs/2502.18998v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文分析了嵌入扩展Margules模型中的图神经网络（GNNs）在预测气液平衡方面的性能。&lt;h4&gt;背景&lt;/h4&gt;预测热力学模型对于产品和工艺设计的早期阶段至关重要。传统的UNIFAC-Dortmund模型是这一领域的基准。&lt;h4&gt;目的&lt;/h4&gt;评估基于图神经网络嵌入扩展Margules模型的方法，与传统方法进行比较，并探索其在不同类型二元混合物中的表现以及局限性。&lt;h4&gt;方法&lt;/h4&gt;将GNNs嵌入到相对简单的过剩吉布斯自由能模型中，即扩展的Margules模型，用于预测气液平衡，并将其性能与公认的UNIFAC-Dortmund模型进行对比。&lt;h4&gt;主要发现&lt;/h4&gt;尽管整体精度略低于传统的UNIFAC-Dortmund模型，在各种类型二元混合物中的表现却更为准确。此外，由于分子断裂可行性或参数可用性限制了组贡献方法如UNIFAC的应用范围，嵌入Margules模型的GNN提供了一个替代方案。&lt;h4&gt;结论&lt;/h4&gt;研究结果为简单的过剩吉布斯自由能模型结合仅基于无限稀释数据训练的图神经网络所能达到的预测准确性建立了基准。&lt;h4&gt;翻译&lt;/h4&gt;预测热力学模型对于产品和工艺设计的早期阶段至关重要。本文分析了将图神经网络（GNNs）嵌入到相对简单的过剩吉布斯自由能模型——扩展Margules模型中，用于预测气液平衡的表现情况。通过与成熟的UNIFAC-Dortmund模型进行比较，已证明在Margules模型中的GNN整体准确性略低。然而，在各种类型二元混合物的情况下观察到了更高的准确度。此外，由于分子断裂可行性或参数可用性限制了组贡献方法如UNIFAC的应用范围，嵌入Margules模型的GNN提供了一个用于气液平衡估算的替代方案。这些发现为简单的过剩吉布斯自由能模型结合仅基于无限稀释数据训练的图神经网络所能达到的预测准确性建立了基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predictive thermodynamic models are crucial for the early stages of productand process design. In this paper the performance of Graph Neural Networks(GNNs) embedded into a relatively simple excess Gibbs energy model, theextended Margules model, for predicting vapor-liquid equilibrium is analyzed.By comparing its performance against the established UNIFAC-Dortmund model ithas been shown that GNNs embedded in Margules achieves an overall loweraccuracy. However, higher accuracy is observed in the case of various types ofbinary mixtures. Moreover, since group contribution methods, like UNIFAC, arelimited due to feasibility of molecular fragmentation or availability ofparameters, the GNN in Margules model offers an alternative for VLE estimation.The findings establish a baseline for the predictive accuracy that simpleexcess Gibbs energy models combined with GNNs trained solely on infinitedilution data can achieve.</description>
      <author>example@mail.com (Edgar Ivan Sanchez Medina, Kai Sundmacher)</author>
      <guid isPermaLink="false">2502.18998v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Neural Antidote: Class-Wise Prompt Tuning for Purifying Backdoors in Pre-trained Vision-Language Models</title>
      <link>http://arxiv.org/abs/2502.19269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;针对预训练的视觉-语言模型（VLMs）在对抗性攻击中的脆弱性，提出了Class-wise Backdoor Prompt Tuning (CBPT)方法来提高其对后门攻击的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的防御策略主要集中在整个可疑模型的微调上，但它们只能提供边际抵抗，并且往往导致干净数据准确性的下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的Class-wise Backdoor Prompt Tuning (CBPT)方法来间接净化被污染的VLMs。&lt;h4&gt;方法&lt;/h4&gt;首先通过对比学习有效地反转潜在的后门触发器；然后利用提示调优技术优化这些类别的文本提示，修改模型决策边界以重新分类后门触发器的特征区域。&lt;h4&gt;主要发现&lt;/h4&gt;CBPT能够显著减轻后门威胁，并保持模型效用。例如，在七种主流的后门攻击中，平均干净准确率为58.86%，攻击成功率仅为0.39%。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了CBPT在提高VLMs对后门攻击鲁棒性方面的优越性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容描述了现有的针对视觉-语言模型（如CLIP）的防御策略存在局限性，尤其是对于数据受限的情况。为了改进这一点，研究人员提出了一种新的方法——Class-wise Backdoor Prompt Tuning (CBPT)，该方法通过调整文本提示来间接净化被污染的模型，并且实验结果表明这种方法在提高模型鲁棒性的同时还能保持良好的性能指标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While pre-trained Vision-Language Models (VLMs) such as CLIP exhibitexcellent representational capabilities for multimodal data, recent studieshave shown that they are vulnerable to backdoor attacks. To alleviate thethreat, existing defense strategies primarily focus on fine-tuning the entiresuspicious model, yet offer only marginal resistance to state-of-the-artattacks and often result in a decrease in clean accuracy, particularly indata-limited scenarios. Their failure may be attributed to the mismatch betweeninsufficient fine-tuning data and massive parameters in VLMs. To address thischallenge, we propose Class-wise Backdoor Prompt Tuning (CBPT) defense, anefficient and effective method that operates on the text prompts to indirectlypurify the poisoned VLMs. Specifically, we first employ the advancedcontrastive learning via our carefully crafted positive and negative samples,to effectively invert the backdoor triggers that are potentially adopted by theattacker. Once the dummy trigger is established, we utilize the efficientprompt tuning technique to optimize these class-wise text prompts for modifyingthe model's decision boundary to further reclassify the feature regions ofbackdoor triggers. Extensive experiments demonstrate that CBPT significantlymitigates backdoor threats while preserving model utility, e.g. an averageClean Accuracy (CA) of 58.86\% and an Attack Success Rate (ASR) of 0.39\%across seven mainstream backdoor attacks. These results underscore thesuperiority of our prompt purifying design to strengthen model robustnessagainst backdoor attacks.</description>
      <author>example@mail.com (Jiawei Kong, Hao Fang, Sihang Guo, Chenxi Qing, Bin Chen, Bin Wang, Shu-Tao Xia)</author>
      <guid isPermaLink="false">2502.19269v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>MCLRL: A Multi-Domain Contrastive Learning with Reinforcement Learning Framework for Few-Shot Modulation Recognition</title>
      <link>http://arxiv.org/abs/2502.19071v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要主题&lt;/h4&gt;无线通信自动调制识别（AMR）及其挑战，以及如何通过少样本学习（FSL）框架解决这些问题。&lt;h4&gt;背景&lt;/h4&gt;随着无线通信技术的快速发展，自动调制识别在确保通信安全和可靠性方面扮演着重要角色。然而，在特定场景下数据采集难度大、样本量小且标签质量低等问题阻碍了其发展。&lt;h4&gt;目的&lt;/h4&gt;引入一种结合多域对比学习与强化学习的新框架（MCLRL），以解决无线信号处理中少样本学习的挑战。&lt;h4&gt;方法&lt;/h4&gt;该研究没有提出新的FSL特定信号模型，而是提出了一个名为MCLRL的框架。此框架将多域对比学习与强化学习相结合，通过增强信号特征并提取深层次分类特性来优化性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的MCLRL框架能够有效从信号中提取关键特征，在少样本任务中表现出色，并且在选择信号模型方面保持了灵活性。&lt;h4&gt;结论&lt;/h4&gt;MCLRL框架提供了一种有效的解决方案，它通过结合多域对比学习和强化学习来克服无线通信自动调制识别中存在的挑战，以实现优异的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancements in wireless communication technology, automaticmodulation recognition (AMR) plays a critical role in ensuring communicationsecurity and reliability. However, numerous challenges, including higherperformance demands, difficulty in data acquisition under specific scenarios,limited sample size, and low-quality labeled data, hinder its development.Few-shot learning (FSL) offers an effective solution by enabling models toachieve satisfactory performance with only a limited number of labeled samples.While most FSL techniques are applied in the field of computer vision, they arenot directly applicable to wireless signal processing. This study does notpropose a new FSL-specific signal model but introduces a framework calledMCLRL. This framework combines multi-domain contrastive learning withreinforcement learning. Multi-domain representations of signals enhance featurerichness, while integrating contrastive learning and reinforcement learningarchitectures enables the extraction of deep features for classification. Indownstream tasks, the model achieves excellent performance using only a fewsamples and minimal training cycles. Experimental results show that the MCLRLframework effectively extracts key features from signals, performs well in FSLtasks, and maintains flexibility in signal model selection.</description>
      <author>example@mail.com (Dongwei Xu, Yutao Zhu, Yao Lu, Youpeng Feng, Yun Lin, Qi Xuan)</author>
      <guid isPermaLink="false">2502.19071v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Invariance Pair-Guided Learning: Enhancing Robustness in Neural Networks</title>
      <link>http://arxiv.org/abs/2502.18975v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的方法来解决机器学习模型在外分布泛化上的挑战，并通过实验验证了该方法的有效性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;机器学习模型在面对训练数据分布之外的数据时，存在难以泛化的现象。尤其是在依赖于虚假相关性的模型中更为明显。&lt;h4&gt;目的&lt;/h4&gt;提供一种技术来指导神经网络在训练阶段的学习过程，以克服现有方法通常需要多域训练、群标签、专业化增广或预处理等限制。&lt;h4&gt;方法&lt;/h4&gt;首先建立输入对，表示虚假属性和描述不变性。基于这些对，形成一个与传统梯度下降互补的校正梯度，并使这种修正机制适应于预先定义的不变条件。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果在ColoredMNIST、Waterbird-100和CelebA数据集上显示出该方法的有效性和对群移位的强大鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效解决模型在外分布泛化中的挑战，并且无需依赖于多训练域或特定的预处理步骤，从而具有更高的实用价值。&lt;h4&gt;翻译&lt;/h4&gt;机器学习模型在面对训练数据分布之外的数据时面临外分布泛化的难题。现有方法通常需要额外资源来实现泛化效果，而本文提出的方法通过引导神经网络进行适应性修正，在多个数据集上验证了其有效性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution generalization of machine learning models remainschallenging since the models are inherently bound to the training datadistribution. This especially manifests, when the learned models rely onspurious correlations. Most of the existing approaches apply data manipulation,representation learning, or learning strategies to achieve generalizablemodels. Unfortunately, these approaches usually require multiple trainingdomains, group labels, specialized augmentation, or pre-processing to reachgeneralizable models. We propose a novel approach that addresses theselimitations by providing a technique to guide the neural network through thetraining phase. We first establish input pairs, representing the spuriousattribute and describing the invariance, a characteristic that should notaffect the outcome of the model. Based on these pairs, we form a correctivegradient complementing the traditional gradient descent approach. We furthermake this correction mechanism adaptive based on a predefined invariancecondition. Experiments on ColoredMNIST, Waterbird-100, and CelebA datasetsdemonstrate the effectiveness of our approach and the robustness to groupshifts.</description>
      <author>example@mail.com (Martin Surner, Abdelmajid Khelil, Ludwig Bothmann)</author>
      <guid isPermaLink="false">2502.18975v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Efficient and Distributed Large-Scale Point Cloud Bundle Adjustment via Majorization-Minimization</title>
      <link>http://arxiv.org/abs/2502.18801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;点云捆集调整是大规模点云地图构建的关键，但由于其计算和内存需求大，在处理大量扫描姿态时复杂度呈三次增长。&lt;h4&gt;背景&lt;/h4&gt;现有方法在进行大规模点云束优化时面临计算效率低、内存使用量大的问题。随着扫描姿态数量的增加，这些问题变得更加严重。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且分布式的大型点云束集调整方法（BALM3.0），以解决上述挑战，并提高整体性能。&lt;h4&gt;方法&lt;/h4&gt;该论文提出了基于majorization-minimization算法的解耦扫描姿态的方法，使用了基于点到平面距离的替代代价函数。这种方法将优化时间复杂度从三次降低到了线性。&lt;h4&gt;主要发现&lt;/h4&gt;1. 通过解耦扫描姿态，可以显著提高大规模环境中的束集调整过程的计算效率。2. 提出了一种分布式的点云束集调整框架，并成功地使用四个消费级笔记本电脑对大规模数据（包括21,436个姿势和70GB点云）进行了优化。&lt;h4&gt;结论&lt;/h4&gt;该方法在模拟和现实世界环境中均表现出色，可以提供与现有方法相当的准确性同时大幅度提高速度并减少内存消耗。&lt;h4&gt;翻译&lt;/h4&gt;点云捆集调整是大规模点云地图构建的关键。然而，它既计算密集又占用大量内存，并且随着扫描姿态数量的增加，其复杂性呈三次增长。本文介绍了BALM3.0，这是一种高效的分布式大型点云束集调整方法。所提出的方法使用majorization-minimization算法在捆集调整过程中解耦扫描姿态，从而提高了大规模数据处理时的计算效率。将扫描姿势解耦的主要优势源于两个关键方面：首先，通过这种方式，优化的时间复杂度从三次降低到线性，极大地提升了大型环境中的束集调整过程的计算效率；其次，它为分布式捆集调整奠定了理论基础。通过在多个设备之间分配数据和计算任务，这种策略有助于克服内存需求大、计算要求高的限制，而这些对于单个设备来说可能难以处理。所提出的方法已在模拟和现实环境中进行了全面评估。结果表明，该方法可以实现与现有最优残差相当的精度，同时优化速度最高提升704倍，并且内存消耗减少到1/8。此外，本文还提出了并实现了分布式的束集调整框架，并成功地使用四个消费级笔记本电脑对大规模数据（包括21,436个姿势和70GB点云）进行了优化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud bundle adjustment is critical in large-scale point cloud mapping.However, it is both computationally and memory intensive, with its complexitygrowing cubically as the number of scan poses increases. This paper presentsBALM3.0, an efficient and distributed large-scale point cloud bundle adjustmentmethod. The proposed method employs the majorization-minimization algorithm todecouple the scan poses in the bundle adjustment process, thus performing thepoint cloud bundle adjustment on large-scale data with improved computationalefficiency. The key difficulty of applying majorization-minimization on bundleadjustment is to identify the proper surrogate cost function. In this paper,the proposed surrogate cost function is based on the point-to-plane distance.The primary advantages of decoupling the scan poses via amajorization-minimization algorithm stem from two key aspects. First, thedecoupling of scan poses reduces the optimization time complexity from cubic tolinear, significantly enhancing the computational efficiency of the bundleadjustment process in large-scale environments. Second, it lays the theoreticalfoundation for distributed bundle adjustment. By distributing both data andcomputation across multiple devices, this approach helps overcome thelimitations posed by large memory and computational requirements, which may bedifficult for a single device to handle. The proposed method is extensivelyevaluated in both simulated and real-world environments. The resultsdemonstrate that the proposed method achieves the same optimal residual withcomparable accuracy while offering up to 704 times faster optimization speedand reducing memory usage to 1/8. Furthermore, this paper also presented andimplemented a distributed bundle adjustment framework and successfullyoptimized large-scale data (21,436 poses with 70 GB point clouds) with fourconsumer-level laptops.</description>
      <author>example@mail.com (Rundong Li, Zheng Liu, Hairuo Wei, Yixi Cai, Haotian Li, Fu Zhang)</author>
      <guid isPermaLink="false">2502.18801v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>SE(3)-Equivariant Ternary Complex Prediction Towards Target Protein Degradation</title>
      <link>http://arxiv.org/abs/2502.18875v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了DeepTernary，这是一种基于深度学习的方法，用于预测蛋白质、E3连接酶和小分子之间形成的三元复合物的结构。&lt;h4&gt;背景&lt;/h4&gt;靶向蛋白降解（TPD）作为一种新兴的药物发现模式在不断发展中。PROTACs 和 分子胶降解剂（MGDs）是主要的小分子诱导 TPD 的方式，它们通过与 E3 连接酶和目标蛋白质形成三元复合物来起作用。&lt;h4&gt;目的&lt;/h4&gt;该研究旨在开发一种深度学习方法来直接预测这些复杂的三元结构，以促进药物的发现过程。&lt;h4&gt;方法&lt;/h4&gt;DeepTernary 使用 SE(3)-等变图神经网络（GNN）结合了图内和三元图间注意机制，从高质训练数据集中提取复杂三元互动，并使用基于查询的 Pocket Points 解码器来解码最终的绑定结构。&lt;h4&gt;主要发现&lt;/h4&gt;DeepTernary 在现有的PROTAC基准测试中展现了最先进的准确度和速度，而在盲对接协议下的MGD基准测试中也显示出显著准确性。此外，预测出的埋藏表面积与实验获得的降解效力相关指标有很好的一致性。&lt;h4&gt;结论&lt;/h4&gt;研究表明，DeepTernary 有可能在靶向不可药物化目标的发展过程中有效且加速地发挥作用。&lt;h4&gt;翻译&lt;/h4&gt;基于小分子诱导的靶向蛋白质降解（TPD）已在药物发现领域迅速发展为一种新兴模式。PROTACs 和 分子胶降解剂（MGDs）是主要的小分子，它们通过与 E3 连接酶和目标蛋白形成三元复合物来实现 TPDS 的功能。虽然在二元结构预测方面取得了显著进展，但由于互动机制不明确以及训练数据不足，三元结构的预测仍然具有挑战性。该工作提出了一种新的基于深度学习的方法——DeepTernary，它能够直接通过编码器-解码器架构端到端地预测三元结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Targeted protein degradation (TPD) induced by small molecules has emerged asa rapidly evolving modality in drug discovery, targeting proteins traditionallyconsidered "undruggable". Proteolysis-targeting chimeras (PROTACs) andmolecular glue degraders (MGDs) are the primary small molecules that induceTPD. Both types of molecules form a ternary complex linking an E3 ligase with atarget protein, a crucial step for drug discovery. While significant advanceshave been made in binary structure prediction for proteins and small molecules,ternary structure prediction remains challenging due to obscure interactionmechanisms and insufficient training data. Traditional methods relying onmanually assigned rules perform poorly and are computationally demanding due toextensive random sampling. In this work, we introduce DeepTernary, a novel deeplearning-based approach that directly predicts ternary structures in anend-to-end manner using an encoder-decoder architecture. DeepTernary leveragesan SE(3)-equivariant graph neural network (GNN) with both intra-graph andternary inter-graph attention mechanisms to capture intricate ternaryinteractions from our collected high-quality training dataset, TernaryDB. Theproposed query-based Pocket Points Decoder extracts the 3D structure of thefinal binding ternary complex from learned ternary embeddings, demonstratingstate-of-the-art accuracy and speed in existing PROTAC benchmarks without priorknowledge from known PROTACs. It also achieves notable accuracy on the morechallenging MGD benchmark under the blind docking protocol. Remarkably, ourexperiments reveal that the buried surface area calculated from predictedstructures correlates with experimentally obtained degradation potency-relatedmetrics. Consequently, DeepTernary shows potential in effectively assisting andaccelerating the development of TPDs for previously undruggable targets.</description>
      <author>example@mail.com (Fanglei Xue, Meihan Zhang, Shuqi Li, Xinyu Gao, James A. Wohlschlegel, Wenbing Huang, Yi Yang, Weixian Deng)</author>
      <guid isPermaLink="false">2502.18875v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>A Sample-Level Evaluation and Generative Framework for Model Inversion Attacks</title>
      <link>http://arxiv.org/abs/2502.19070v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to be appeared in 39th Annual AAAI Conference on Artificial  Intelligence (AAAI-25)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文研究了模型反转攻击（MI）对机器学习隐私的影响，并提出了一个新的评估指标DDCS，用于更精确地衡量单样本级别的隐私保护情况。&lt;h4&gt;背景&lt;/h4&gt;模型反转攻击能够重构神经网络的训练数据集，威胁到机器学习中的隐私安全。现有评价标准对于样例级别隐私问题重视不够。&lt;h4&gt;目的&lt;/h4&gt;提出新的度量体系DDCS来评估个体样本在MI攻击下的脆弱性，并探索增强和防御机制。&lt;h4&gt;方法&lt;/h4&gt;引入新型度量标准DDCS以综合考量多个方面，同时设计了一种通过熵损失和自然梯度下降集成的转移学习框架，提升现有MI攻击技术。&lt;h4&gt;主要发现&lt;/h4&gt;许多训练样例对当前最先进MI攻击具备较强抵抗性；新提出的评估体系DDCS不仅提高了现有攻击方法的效果，在无监督环境中还能有效识别易受攻击的样本。&lt;h4&gt;结论&lt;/h4&gt;论文通过DDCS展示了样本级隐私保护的重要性，同时提出了一种有效的防御框架，并表明该指标在加强隐私安全方面有巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model Inversion (MI) attacks, which reconstruct the training dataset ofneural networks, pose significant privacy concerns in machine learning. RecentMI attacks have managed to reconstruct realistic label-level private data, suchas the general appearance of a target person from all training images labeledon him. Beyond label-level privacy, in this paper we show sample-level privacy,the private information of a single target sample, is also important butunder-explored in the MI literature due to the limitations of existingevaluation metrics. To address this gap, this study introduces a novel metrictailored for training-sample analysis, namely, the Diversity and DistanceComposite Score (DDCS), which evaluates the reconstruction fidelity of eachtraining sample by encompassing various MI attack attributes. This, in turn,enhances the precision of sample-level privacy assessments.  Leveraging DDCS as a new evaluative lens, we observe that many trainingsamples remain resilient against even the most advanced MI attack. As such, wefurther propose a transfer learning framework that augments the generativecapabilities of MI attackers through the integration of entropy loss andnatural gradient descent. Extensive experiments verify the effectiveness of ourframework on improving state-of-the-art MI attacks over various metricsincluding DDCS, coverage and FID. Finally, we demonstrate that DDCS can also beuseful for MI defense, by identifying samples susceptible to MI attacks in anunsupervised manner.</description>
      <author>example@mail.com (Haoyang Li, Li Bai, Qingqing Ye, Haibo Hu, Yaxin Xiao, Huadi Zheng, Jianliang Xu)</author>
      <guid isPermaLink="false">2502.19070v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>InternVQA: Advancing Compressed Video Quality Assessment with Distilling Large Foundation Model</title>
      <link>http://arxiv.org/abs/2502.19026v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ISCAS 2025(Lecture)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本论文探讨了基于InternVideo2视频基础模型在压缩场景下的视频质量评估任务中的应用，并提出了一种轻量级模型的蒸馏方法。&lt;h4&gt;背景&lt;/h4&gt;现有的视频理解任务依赖于丰富的特征，包括语义信息、纹理和时间运动等。InternVideo2由于其庞大的参数规模和大规模多模态数据的支持，在这一领域显示出了强大的潜力。&lt;h4&gt;目的&lt;/h4&gt;研究将InternVideo2转移到压缩场景下的视频质量评估任务中的可行性，并探索设计一个轻量级模型的方法以适应此任务。&lt;h4&gt;方法&lt;/h4&gt;提出了一种蒸馏方法，使较小的模型能够获得丰富的压缩质量先验知识。此外，在蒸馏过程中还对不同骨干网络的表现进行了考察。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与其它方法相比，从InternVideo2中蒸馏出来的轻量级模型在压缩视频的质量评估任务中取得了优异的成绩。&lt;h4&gt;结论&lt;/h4&gt;通过提出的方法和技术，证明了将InternVideo2应用于视频质量评估的有效性，并为开发适用于这一领域的高效解决方案提供了依据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video quality assessment tasks rely heavily on the rich features required forvideo understanding, such as semantic information, texture, and temporalmotion. The existing video foundational model, InternVideo2, has demonstratedstrong potential in video understanding tasks due to its large parameter sizeand large-scale multimodal data pertaining. Building on this, we explored thetransferability of InternVideo2 to video quality assessment under compressionscenarios. To design a lightweight model suitable for this task, we proposed adistillation method to equip the smaller model with rich compression qualitypriors. Additionally, we examined the performance of different backbones duringthe distillation process. The results showed that, compared to other methods,our lightweight model distilled from InternVideo2 achieved excellentperformance in compression video quality assessment.</description>
      <author>example@mail.com (Fengbin Guan, Zihao Yu, Yiting Lu, Xin Li, Zhibo Chen)</author>
      <guid isPermaLink="false">2502.19026v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>TabGLM: Tabular Graph Language Model for Learning Transferable Representations Through Multi-Modal Consistency Minimization</title>
      <link>http://arxiv.org/abs/2502.18847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;处理表格数据集中的异构数据对深度学习模型构成了重大挑战。&lt;h4&gt;背景&lt;/h4&gt;注意力机制架构和自监督学习方法在某些领域取得了显著成功，但在应对表格数据时不如线性或基于树的模型有效。虽然有一些突破是通过将表格转换为图像、语言或图等单一模态来实现的，但这些方法在面对特征异质性时通常表现不佳。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，我们引入了一种新型多模态架构TabGLM（表征图语言模型），旨在同时建模表格中的结构信息和语义信息。&lt;h4&gt;方法&lt;/h4&gt;TabGLM将表格的每一行转换为一个完全连接的图和序列化文本，然后分别使用图神经网络(GNN)和文本编码器对其进行编码。通过联合多模态自监督学习目标对齐这些表示，从而利用来自两种模式的互补信息来增强特征学习。&lt;h4&gt;主要发现&lt;/h4&gt;TabGLM采用灵活的图-文本流水线处理异构数据集，在现有深度学习方法中使用显著更少的参数。在25个基准数据集上的评估显示了性能的重大提升，与最先进（SoTA）的表格学习方法相比，TabGLM实现了高达5.56%的平均AUC-ROC改进。&lt;h4&gt;结论&lt;/h4&gt;这项研究提出了一个创新的方法来处理异构表格数据，并通过在多个实际数据集上显著优于现有方法证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Handling heterogeneous data in tabular datasets poses a significant challengefor deep learning models. While attention-based architectures andself-supervised learning have achieved notable success, their application totabular data remains less effective over linear and tree based models. Althoughseveral breakthroughs have been achieved by models which transform tables intouni-modal transformations like image, language and graph, these models oftenunderperform in the presence of feature heterogeneity. To address this gap, weintroduce TabGLM (Tabular Graph Language Model), a novel multi-modalarchitecture designed to model both structural and semantic information from atable. TabGLM transforms each row of a table into a fully connected graph andserialized text, which are then encoded using a graph neural network (GNN) anda text encoder, respectively. By aligning these representations through ajoint, multi-modal, self-supervised learning objective, TabGLM leveragescomplementary information from both modalities, thereby enhancing featurelearning. TabGLM's flexible graph-text pipeline efficiently processesheterogeneous datasets with significantly fewer parameters over existing DeepLearning approaches. Evaluations across 25 benchmark datasets demonstratesubstantial performance gains, with TabGLM achieving an average AUC-ROCimprovement of up to 5.56% over State-of-the-Art (SoTA) tabular learningmethods.</description>
      <author>example@mail.com (Anay Majee, Maria Xenochristou, Wei-Peng Chen)</author>
      <guid isPermaLink="false">2502.18847v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>KAN-powered large-target detection for automotive radar</title>
      <link>http://arxiv.org/abs/2502.19000v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新颖的雷达信号检测管道，用于检测大型目标如汽车和SUV。它基于Range-Doppler（RD）段的概率密度函数(pdf)，利用Kolmogorov-Arnold神经网络(KAN)来学习数据并生成二元假设的可解释符号表达式。&lt;h4&gt;背景&lt;/h4&gt;传统的方法，例如有序统计恒虚警率(OS-CFAR)，在汽车雷达中广泛应用。然而这些方法通常设计用于点目标或等向性目标模型，可能无法充分捕捉大型目标（如车辆）的Range-Doppler散射模式，特别是在高分辨率雷达系统中。&lt;h4&gt;目的&lt;/h4&gt;为了克服传统OS-CFAR检测技术在大型目标探测中的局限性，提出了一种新的基于概率密度函数和Kolmogorov-Arnold神经网络的检测方法。&lt;h4&gt;方法&lt;/h4&gt;研究通过Monte Carlo实验表明所提出的基于KAN表达式的检测性能优于传统的OS-CFAR。此外，该方法在使用现场数据进行迁移学习时，展示了96%的目标检出概率（PD），并且虚警率(PFA)与设计为$10^{-6}$的OS-CFAR相当。&lt;h4&gt;主要发现&lt;/h4&gt;研究还探讨了RD段pdf表示的分块数量对基于KAN检测性能的影响。实验表明提出的KAN表达式能够有效地处理大目标，而不需要额外的关联和跟踪模块来优化多视图下的探测结果。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在高分辨率雷达系统中对于大型目标（如汽车）的检测表现出优越性，尤其是在检出概率方面超过了传统方法，并且虚警率控制得当。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了一种新颖的雷达信号检测流程，专门用于探测大型目标，比如汽车和SUV。传统的有序统计恒虚警率(OS-CFAR)方法通常适用于点目标或各向同性模型，在高分辨率系统中可能无法充分表现大目标（如车辆）的Range-Doppler散射特性。新的方法基于Kolmogorov-Arnold神经网络(KAN)，能够学习数据并生成二元假设的概率密度函数，该方法优于传统的OS-CFAR，并且在使用现场数据进行迁移学习时达到了96%的目标检出率和相当的虚警率水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel radar signal detection pipeline focused ondetecting large targets such as cars and SUVs. Traditional methods, such asOrdered-Statistic Constant False Alarm Rate (OS-CFAR), commonly used inautomotive radar, are designed for point or isotropic target models. These maynot adequately capture the Range-Doppler (RD) scattering patterns of largertargets, especially in high-resolution radar systems. Additional modules suchas association and tracking are necessary to refine and consolidate thedetections over multiple dwells. To address these limitations, we propose adetection technique based on the probability density function (pdf) of RDsegments, leveraging the Kolmogorov-Arnold neural network (KAN) to learn thedata and generate interpretable symbolic expressions for binary hypotheses.Beside the Monte-Carlo study showing better performance for the proposed KANexpression over OS-CFAR, it is shown to exhibit a probability of detection (PD)of 96% when transfer learned with field data. The false alarm rate (PFA) iscomparable with OS-CFAR designed with PFA = $10^{-6}$. Additionally, the studyalso examines impact of the number of pdf bins representing RD segment onperformance of the KAN-based detection.</description>
      <author>example@mail.com (Vinay Kulkarni, V. V. Reddy, Neha Maheshwari)</author>
      <guid isPermaLink="false">2502.19000v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>(Mis)Fitting: A Survey of Scaling Laws</title>
      <link>http://arxiv.org/abs/2502.18969v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  41 pages, 3 figure, first two authors contributed equally. ICLR, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代基础模型依赖于使用缩放定律来指导重要的训练决策。研究者通常通过描述损失或任务性能与规模之间的关系从较小的训练运行中推断出最优架构和超参数设置。&lt;h4&gt;目的&lt;/h4&gt;讨论不同先驱工作在诸如最佳token到参数比率等问题上得出结论时存在的差异，并且探讨特定细节变化对缩放研究结果的影响以及因此导致的不同结论。此外，调查了超过50篇研究缩放趋势的论文：其中45篇使用幂定律来量化这些趋势，但大多数未能报告复制其发现所需的关键细节。&lt;h4&gt;方法&lt;/h4&gt;作者通过自己的分析来补充讨论，并为贡献于缩放律研究的研究者提出了一份检查清单，以帮助他们更好地报告关键细节。&lt;h4&gt;主要发现&lt;/h4&gt;不同的因素（如拟合的具体方程、训练设置和优化方法）可能会影响拟合的规律，进而影响给定研究的结论。大多数关于缩放趋势的研究未能充分报告必要的技术细节。&lt;h4&gt;结论&lt;/h4&gt;为了减轻这些问题的影响，作者建议所有贡献者在进行缩放律研究时参考提供的检查清单来确保他们提供了足够的细节以允许其他人重现他们的结果。&lt;h4&gt;翻译&lt;/h4&gt;现代基础模型依赖于使用扩展法则指导关键训练决策。研究人员通常从较小规模的训练中推导出最优架构和超参数设置，通过描述损失或任务性能与规模之间的关系来进行这一过程。该过程中所有因素的变化（如具体拟合方程、训练配置、优化方法等）都可能影响到得出的规则，并进而影响研究结论。论文作者讨论了先前工作的不同结论，包括有关最佳token-参数比率的问题，同时结合自身分析结果来探讨细节变化对缩放研究的影响及结论的改变。另外，调查了50余篇关于扩展趋势的研究：其中45项使用幂律量化趋势，但大多数未能充分报告实现其发现所需的详细信息。为解决这一问题，论文作者建议在进行扩展现有规则的研究时遵循特定检查清单。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern foundation models rely heavily on using scaling laws to guide crucialtraining decisions. Researchers often extrapolate the optimal architecture andhyper parameters settings from smaller training runs by describing therelationship between, loss, or task performance, and scale. All components ofthis process vary, from the specific equation being fit, to the training setup,to the optimization method. Each of these factors may affect the fitted law,and therefore, the conclusions of a given study. We discuss discrepancies inthe conclusions that several prior works reach, on questions such as theoptimal token to parameter ratio. We augment this discussion with our ownanalysis of the critical impact that changes in specific details may effect ina scaling study, and the resulting altered conclusions. Additionally, we surveyover 50 papers that study scaling trends: while 45 of these papers quantifythese trends using a power law, most under-report crucial details needed toreproduce their findings. To mitigate this, we we propose a checklist forauthors to consider while contributing to scaling law research.</description>
      <author>example@mail.com (Margaret Li, Sneha Kudugunta, Luke Zettlemoyer)</author>
      <guid isPermaLink="false">2502.18969v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning Assisted Fast Design Migration Over Technology Nodes: A Study on Transformer Matching Network</title>
      <link>http://arxiv.org/abs/2502.18636v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Publihsed and Presented at IEEE MTT-S International Microwave  Symposium (IMS 2024), Washington, DC, USA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究介绍了一种新颖的方法，利用预训练的合成神经网络模型的知识转移，在不同集成电路技术、操作频率和金属选项之间快速而可靠地设计毫米波被动网络。&lt;h4&gt;背景&lt;/h4&gt;在毫米波通信领域，传统的电路设计方法耗时且依赖于专业知识。引入了知识迁移的概念来提高设计效率。&lt;h4&gt;目的&lt;/h4&gt;通过模拟演示验证从一个技术节点的预训练合成神经网络模型的知识转移可以加速目标领域的训练过程，并提高R2值。&lt;h4&gt;方法&lt;/h4&gt;使用GF 45nm SOI（源领域）中经过训练的模型，将知识转移到GF 22nm FDX+（目标领域），并对1:1片上变压器的设计进行比较和分析。实验探索了不同数据密度的影响并评估了R2值。&lt;h4&gt;主要发现&lt;/h4&gt;知识转移可以显著减少所需的数据集大小，并且在源域和目标域之间表现出优秀的泛化能力，特别是在低数据密度下的性能提升明显。&lt;h4&gt;结论&lt;/h4&gt;研究结果证明，利用迁移学习可以有效提高毫米波被动网络设计的效率和精度。该方法可以在不同集成电路技术和操作频率下加速模型训练并获得更好的R2值。&lt;h4&gt;翻译&lt;/h4&gt;在该项研究中，我们引入了一种创新性的毫米波无源网络设计方法，这种方法使用预先训练好的合成神经网络模型的知识转移，在不同的集成电路上实现快速且可靠的设计调整。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IMS40175.2024.10600344&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we introduce an innovative methodology for the design ofmm-Wave passive networks that leverages knowledge transfer from a pre-trainedsynthesis neural network (NN) model in one technology node and achieves swiftand reliable design adaptation across different integrated circuit (IC)technologies, operating frequencies, and metal options. We prove this conceptthrough simulation-based demonstrations focusing on the training and comparisonof the coefficient of determination (R2) of synthesis NNs for 1:1 on-chiptransformers in GlobalFoundries(GF) 22nm FDX+ (target domain), with and withouttransfer learning from a model trained in GF 45nm SOI (source domain). In theexperiments, we explore varying target data densities of 0.5%, 1%, 5%, and 100%with a complete dataset of 0.33 million in GF 22FDX+, and for comparativeanalysis, apply source data densities of 25%, 50%, 75%, and 100% with acomplete dataset of 2.5 million in GF 45SOI. With the source data only at30GHz, the experiments span target data from two metal options in GF 22FDX+ atfrequencies of 30 and 39 GHz. The results prove that the transfer learning withthe source domain knowledge (GF 45SOI) can both accelerate the training processin the target domain (GF 22FDX+) and improve the R2 values compared to modelswithout knowledge transfer. Furthermore, it is observed that a model trainedwith just 5% of target data and augmented by transfer learning achieves R2values superior to a model trained with 20% of the data without transfer,validating the advantage seen from 1% to 5% data density. This demonstrates anotable reduction of 4X in the necessary dataset size highlighting the efficacyof utilizing transfer learning to mm-Wave passive network design. The PyTorchlearning and testing code is publicly available athttps://github.com/ChenhaoChu/RFIC-TL.</description>
      <author>example@mail.com (Chenhao Chu, Yuhao Mao, Hua Wang)</author>
      <guid isPermaLink="false">2502.18636v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>MaskPlanner: Learning-Based Object-Centric Motion Generation from 3D Point Clouds</title>
      <link>http://arxiv.org/abs/2502.18745v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website at https://gabrieletiboni.github.io/MaskPlanner/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种新的、完全数据驱动的框架，用于基于3D点云直接处理对象中心运动生成（OCMG）问题。&lt;h4&gt;背景&lt;/h4&gt;现有的解决方案依赖于专门的启发式方法、昂贵的优化过程或限制性的几何假设，这些都降低了它们在实际场景中的适应性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的学习框架MaskPlanner来解决OCMG问题，该框架可以从3D点云中直接预测局部路径段并进行分组，以满足任务需求。&lt;h4&gt;方法&lt;/h4&gt;MaskPlanner是一种深度学习方法，能够为给定的对象预测局部路径片段，并同时推断出“路径掩码”，将这些片段归类为不同的路径。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法对于未见过的对象能达到近乎完整的覆盖（超过99%），且无需显式优化喷漆沉积。此外，在6自由度专业喷涂机器人上的真实世界验证中展示了生成的轨迹可以直接执行并达到专家级的喷涂质量。&lt;h4&gt;结论&lt;/h4&gt;研究结果突出了所提出的学习方法在减少工程负担方面和无缝适应多种工业应用案例中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;对象中心运动生成（OCMG）在各种工业应用中起着关键作用，例如机器人喷漆和焊接。需要高效、可扩展且通用的算法来为自由形状3D物体规划多个长期轨迹。然而，现有的解决方案依赖于专门的启发式方法、昂贵的优化过程或限制性的几何假设，这限制了它们在实际场景中的适应性。本文提出了一种新的完全数据驱动框架，直接从3D点云处理OCMG问题，并学习如何跨自由形状表面泛化专家路径模式。我们提出了MaskPlanner深度学习方法，该方法预测给定物体的局部路径片段并同时推断“路径掩码”，将这些片段分类为不同的路径，从而让网络在单次前向传递中捕获局部几何模式和全局任务需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object-Centric Motion Generation (OCMG) plays a key role in a variety ofindustrial applications$\unicode{x2014}$such as robotic spray painting andwelding$\unicode{x2014}$requiring efficient, scalable, and generalizablealgorithms to plan multiple long-horizon trajectories over free-form 3Dobjects. However, existing solutions rely on specialized heuristics, expensiveoptimization routines, or restrictive geometry assumptions that limit theiradaptability to real-world scenarios. In this work, we introduce a novel, fullydata-driven framework that tackles OCMG directly from 3D point clouds, learningto generalize expert path patterns across free-form surfaces. We proposeMaskPlanner, a deep learning method that predicts local path segments for agiven object while simultaneously inferring "path masks" to group thesesegments into distinct paths. This design induces the network to capture bothlocal geometric patterns and global task requirements in a single forward pass.Extensive experimentation on a realistic robotic spray painting scenario showsthat our approach attains near-complete coverage (above 99%) for unseenobjects, while it remains task-agnostic and does not explicitly optimize forpaint deposition. Moreover, our real-world validation on a 6-DoF specializedpainting robot demonstrates that the generated trajectories are directlyexecutable and yield expert-level painting quality. Our findings cruciallyhighlight the potential of the proposed learning method for OCMG to reduceengineering overhead and seamlessly adapt to several industrial use cases.</description>
      <author>example@mail.com (Gabriele Tiboni, Raffaello Camoriano, Tatiana Tommasi)</author>
      <guid isPermaLink="false">2502.18745v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Transient Classification: From Simulations to Real Data and ZTF to LSST</title>
      <link>http://arxiv.org/abs/2502.18558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过转移学习的方法，展示了如何利用已有的模型来处理天文瞬变现象的分类问题。这种方法可以显著减少标记数据的需求，并且保持与从头开始训练的模型相当的性能。&lt;h4&gt;背景&lt;/h4&gt;机器学习在自动分类天文学中的瞬变现象中起着关键作用，但现有方法面临着诸多挑战：基于模拟数据训练的分类器难以处理真实数据；为一个调查定制的模型难以应用于其他调查。随着大型天文观测设施如维拉·鲁宾天文台（Legacy Survey of Space and Time, LSST）时代的到来，这些问题变得更加紧迫。&lt;h4&gt;目的&lt;/h4&gt;本文旨在展示转移学习如何克服现有方法面临的挑战，使得在新调查开始初期就能实现可靠的自动化分类。&lt;h4&gt;方法&lt;/h4&gt;使用了一种基于模拟数据训练的模型，并通过转移学习技术将其应用于实际数据和不同调查的数据。具体而言，从一个利用模拟Zwicky瞬变设施（ZTF）光曲线训练的模型出发，展示了这种技术如何减少75%的真实标记ZTF瞬变现象的需求，同时保持与全新训练模型相同的性能。&lt;h4&gt;主要发现&lt;/h4&gt;1. 转移学习可以在很大程度上减少了所需的真实标记数据量；2. 当将ZTF模型应用于LSST模拟时，转移学习可以达到基准性能的95%，而只需要30%的训练数据。这些结果对即将启动的LSST早期操作具有重要影响。&lt;h4&gt;结论&lt;/h4&gt;通过转移学习，即使在新调查开始初期也能实现可靠的自动化分类，无需等待数月或数年积累足够的标记训练数据。&lt;h4&gt;翻译&lt;/h4&gt;机器学习对于天文瞬变现象的自动分类至关重要，但当前方法面临诸多限制：基于模拟训练的分类器难以处理真实数据；为一个观测定制的模型难以应用于其他调查。随着大型天文设施如LSST时代的到来，现有模型将需要重新利用LSST的数据进行再培训。本文证明了转移学习可以通过重用已有的基于模拟或来自其它调查的数据训练的模型来克服这些挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has become essential for automated classification ofastronomical transients, but current approaches face significant limitations:classifiers trained on simulations struggle with real data, models developedfor one survey cannot be easily applied to another, and new surveys requireprohibitively large amounts of labelled training data. These challenges areparticularly pressing as we approach the era of the Vera Rubin Observatory'sLegacy Survey of Space and Time (LSST), where existing classification modelswill need to be retrained using LSST observations. We demonstrate that transferlearning can overcome these challenges by repurposing existing models trainedon either simulations or data from other surveys. Starting with a model trainedon simulated Zwicky Transient Facility (ZTF) light curves, we show thattransfer learning reduces the amount of labelled real ZTF transients needed by75\% while maintaining equivalent performance to models trained from scratch.Similarly, when adapting ZTF models for LSST simulations, transfer learningachieves 95\% of the baseline performance while requiring only 30\% of thetraining data. These findings have significant implications for the earlyoperations of LSST, suggesting that reliable automated classification will bepossible soon after the survey begins, rather than waiting months or years toaccumulate sufficient training data.</description>
      <author>example@mail.com (Rithwik Gupta, Daniel Muthukrishna)</author>
      <guid isPermaLink="false">2502.18558v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Graph Tasks with Pure LLMs: A Comprehensive Benchmark and Investigation</title>
      <link>http://arxiv.org/abs/2502.18771v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了大型语言模型（LLMs）在图学习任务中的应用，并评估了它们在不同场景下的性能，特别是在少样本/零样本设置、跨领域迁移能力以及对图形结构的理解和鲁棒性方面。&lt;h4&gt;背景&lt;/h4&gt;随着图状数据的普遍使用，传统的图神经网络（GNNs）虽然取得了一些进展，但在某些上下文中处理图数据的能力仍然有限。大型语言模型因其在处理限制数据、任务间转移性和鲁棒性的潜力而成为新的研究热点。&lt;h4&gt;目的&lt;/h4&gt;全面探索LLMs在图学习任务中的应用，并评估其性能，以揭示它们的优点和潜在的现实世界应用场景。&lt;h4&gt;方法&lt;/h4&gt;研究比较了16种图学习模型与6种大型语言模型（如Llama3B、GPT-4o、Qwen-plus）在Cora、PubMed、ArXiv等数据集上的表现。评估包括未进行参数优化和经过指令微调的LLMs。&lt;h4&gt;主要发现&lt;/h4&gt;具有指令微调的LLMs在少样本设置中优于传统模型，表现出强大的跨领域迁移能力，并展示了优秀的泛化性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该研究为大型语言模型用于图学习提供了有价值的见解，揭示了它们的优势和潜在的应用场景，为未来的研究铺平道路。代码与数据集可在GitHub上获得（https://github.com/myflashbarry/LLM-benchmarking）。&lt;h4&gt;翻译&lt;/h4&gt;随着图状数据在各个领域的日益普及，对有效处理节点分类和链接预测等任务的模型的需求也在增长。尽管传统的图学习模型如图神经网络已经取得了显著进展，但在某些上下文中的能力仍然有限。近年来，大型语言模型作为潜在解决方案崭露头角，但大多数研究主要关注性能基准测试，未能充分探讨其广泛潜力，包括处理限制数据的能力、任务间的转移性和鲁棒性等。本工作全面探索了大型语言模型应用于图学习任务，并评估了纯LLM（包含未优化参数和指令微调）在各种情况下的表现。我们的分析不仅局限于准确性，还涉及LLMs在少样本/零样本设置中的能力、跨领域迁移能力、理解图形结构的能力以及在挑战性场景中的鲁棒性等。我们在16种图学习模型与如Llama3B、GPT-4o、Qwen-plus等六种大型语言模型之间进行了广泛的实验，对比了它们在Cora、PubMed、ArXiv和Products等数据集上的表现。我们的研究发现显示，在少样本设置中，具有指令微调的LLMs优于传统的图学习模型，表现出强大的跨领域迁移能力，并展示了优秀的泛化性和鲁棒性。这项工作为大型语言模型用于图学习提供了宝贵的见解，突显了它们的优势和潜在的实际应用价值，并为未来的研究铺平道路。代码与数据集可在https://github.com/myflashbarry/LLM-benchmarking上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/myflashbarry/LLM-benchmarking&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-structured data has become increasingly prevalent across variousdomains, raising the demand for effective models to handle graph tasks likenode classification and link prediction. Traditional graph learning models likeGraph Neural Networks (GNNs) have made significant strides, but theircapabilities in handling graph data remain limited in certain contexts. Inrecent years, large language models (LLMs) have emerged as promising candidatesfor graph tasks, yet most studies focus primarily on performance benchmarks andfail to address their broader potential, including their ability to handlelimited data, their transferability across tasks, and their robustness. In thiswork, we provide a comprehensive exploration of LLMs applied to graph tasks. Weevaluate the performance of pure LLMs, including those without parameteroptimization and those fine-tuned with instructions, across various scenarios.Our analysis goes beyond accuracy, assessing LLM ability to perform infew-shot/zero-shot settings, transfer across domains, understand graphstructures, and demonstrate robustness in challenging scenarios. We conductextensive experiments with 16 graph learning models alongside 6 LLMs (e.g.,Llama3B, GPT-4o, Qwen-plus), comparing their performance on datasets like Cora,PubMed, ArXiv, and Products. Our findings show that LLMs, particularly thosewith instruction tuning, outperform traditional models in few-shot settings,exhibit strong domain transferability, and demonstrate excellent generalizationand robustness. This work offers valuable insights into the capabilities ofLLMs for graph learning, highlighting their advantages and potential forreal-world applications, and paving the way for future research in this area.Codes and datasets are released inhttps://github.com/myflashbarry/LLM-benchmarking.</description>
      <author>example@mail.com (Yuxiang Wang, Xinnan Dai, Wenqi Fan, Yao Ma)</author>
      <guid isPermaLink="false">2502.18771v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>CommGPT: A Graph and Retrieval-Augmented Multimodal Communication Foundation Model</title>
      <link>http://arxiv.org/abs/2502.18763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;大语言模型（LLMs）具备人类级别的认知和决策能力，是6G技术的关键。然而，在通信领域应用LLMs面临三大挑战：1) 通信数据不足；2) 输入模态受限；3) 知识检索困难。&lt;h4&gt;背景&lt;/h4&gt;大语言模型在6G中扮演关键角色，但由于其缺乏高质量的通信特定训练数据、只能处理有限输入模态及难以有效检索领域知识，因此很难直接应用于通信场景。&lt;h4&gt;目的&lt;/h4&gt;提出CommGPT，这是一个专门针对通信领域的多模态基础模型。为了克服上述问题，CommGPT旨在提供更好的通信专业知识学习能力，并能够适应多种输入类型，同时提高对已有知识的利用效率。&lt;h4&gt;方法&lt;/h4&gt;1. 创建高质预训练和微调数据集；2. 设计用于理解处理多样化信息输入的多模态编码器；3. 构建图谱增强检索增强生成框架（GRG），以结合知识图谱与检索增强生成技术，实现跨尺度学习。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证了CommGPT的有效性和可行性，表明其在通信领域的应用潜力巨大。&lt;h4&gt;结论&lt;/h4&gt;提出了专门用于通信的多模态基础模型CommGPT，并证明它可以在解决当前LLMs面临的挑战方面提供有效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) possess human-level cognitive and decision-making capabilities, making them a key technology for 6G. However, applying LLMs to the communication domain faces three major challenges: 1) Inadequate communication data; 2) Restricted input modalities; and 3) Difficulty in knowledge retrieval. To overcome these issues, we propose CommGPT, a multimodal foundation model designed specifically for communications. First, we create high-quality pretraining and fine-tuning datasets tailored to the field of communications, enabling the LLM to engage in further pretraining and fine-tuning with communication concepts and knowledge. Then, we design a multimodal encoder to understand and process information from various input modalities. Next, we construct a Graph and Retrieval-Augmented Generation (GRG) framework, efficiently coupling Knowledge Graph (KG) with Retrieval-Augmented Generation (RAG) for multi-scale learning. Finally, we demonstrate the feasibility and effectiveness of the CommGPT through experimental validation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) possess human-level cognitive anddecision-making capabilities, making them a key technology for 6G. However,applying LLMs to the communication domain faces three major challenges: 1)Inadequate communication data; 2) Restricted input modalities; and 3)Difficulty in knowledge retrieval. To overcome these issues, we proposeCommGPT, a multimodal foundation model designed specifically forcommunications. First, we create high-quality pretraining and fine-tuningdatasets tailored in communication, enabling the LLM to engage in furtherpretraining and fine-tuning with communication concepts and knowledge. Then, wedesign a multimodal encoder to understand and process information from variousinput modalities. Next, we construct a Graph and Retrieval-Augmented Generation(GRG) framework, efficiently coupling Knowledge Graph (KG) withRetrieval-Augmented Generation (RAG) for multi-scale learning. Finally, wedemonstrate the feasibility and effectiveness of the CommGPT throughexperimental validation.</description>
      <author>example@mail.com (Feibo Jiang, Wanyun Zhu, Li Dong, Kezhi Wang, Kun Yang, Cunhua Pan, Octavia A. Dobre)</author>
      <guid isPermaLink="false">2502.18763v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Spectral-Enhanced Transformers: Leveraging Large-Scale Pretrained Models for Hyperspectral Object Tracking</title>
      <link>http://arxiv.org/abs/2502.18748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to 14th Workshop on Hyperspectral Imaging and Signal  Processing: Evolution in Remote Sensing (WHISPERS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种利用预训练的大型Transformer模型进行高光谱对象跟踪的有效方法。&lt;h4&gt;背景&lt;/h4&gt;基于快照马赛克相机的高光谱目标追踪技术因提供增强的光谱信息和空间数据而备受关注，这有助于更全面地理解材料属性。然而，大规模Transformer的训练需要大量的数据集和长时间的训练过程，这对于高光谱领域现有的小规模数据集来说是一个瓶颈。&lt;h4&gt;目的&lt;/h4&gt;开发一种适应大型预训练基础模型的方法，用于高光谱对象跟踪，并通过跨模态训练管道促进不同传感器收集的数据之间的有效学习。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自适应、可学习的空间-光谱令牌融合模块，可以扩展到任何基于Transformer的骨干网络中，以学习高光谱数据中的固有空间-光谱特征。此外，模型还包含一个跨模态训练管道，允许在不同传感器模式下收集的数据之间进行有效的跨域学习。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够在较少的训练迭代次数下实现优越性能。&lt;h4&gt;结论&lt;/h4&gt;通过上述创新方法，高光谱对象跟踪任务能够克服现有数据集规模较小的问题，并利用Transformer的强大功能来提升追踪效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperspectral object tracking using snapshot mosaic cameras is emerging as itprovides enhanced spectral information alongside spatial data, contributing toa more comprehensive understanding of material properties. Using transformers,which have consistently outperformed convolutional neural networks (CNNs) inlearning better feature representations, would be expected to be effective forHyperspectral object tracking. However, training large transformersnecessitates extensive datasets and prolonged training periods. This isparticularly critical for complex tasks like object tracking, and the scarcityof large datasets in the hyperspectral domain acts as a bottleneck in achievingthe full potential of powerful transformer models. This paper proposes aneffective methodology that adapts large pretrained transformer-based foundationmodels for hyperspectral object tracking. We propose an adaptive, learnablespatial-spectral token fusion module that can be extended to anytransformer-based backbone for learning inherent spatial-spectral features inhyperspectral data. Furthermore, our model incorporates a cross-modalitytraining pipeline that facilitates effective learning across hyperspectraldatasets collected with different sensor modalities. This enables theextraction of complementary knowledge from additional modalities, whether ornot they are present during testing. Our proposed model also achieves superiorperformance with minimal training iterations.</description>
      <author>example@mail.com (Shaheer Mohamed, Tharindu Fernando, Sridha Sridharan, Peyman Moghadam, Clinton Fookes)</author>
      <guid isPermaLink="false">2502.18748v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>CalibRefine: Deep Learning-Based Online Automatic Targetless LiDAR-Camera Calibration with Iterative and Attention-Driven Post-Refinement</title>
      <link>http://arxiv.org/abs/2502.17648v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Transportation Research Part C: Emerging Technologies&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种全自动、无需目标物且在线的多传感器校准框架CalibRefine，该方法能够直接处理原始LiDAR点云和相机图像数据，并通过四个阶段实现高精度的校准。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶、机器人技术及智能交通系统等应用中，精确的多传感器校准至关重要。现有基于LIDAR-相机的方法通常依赖于手动放置的目标物或预先估计参数，这限制了其在现实环境中的可扩展性和适应性。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需人工干预和目标物的全自动在线校准框架CalibRefine，以解决传统方法中存在的问题，并提高多传感器系统在校准过程中的鲁棒性和准确性。&lt;h4&gt;方法&lt;/h4&gt;['第一阶段：通过使用相对位置、外观嵌入和语义类别自动检测对象，训练通用特征鉴别器生成可靠的LIDAR-相机对应关系', '第二阶段：基于粗略的同态变换进行校准', '第三阶段：迭代改进数据帧变得可用时对齐过程', '第四阶段：利用视觉变压器和交叉注意力机制处理非平面扭曲']&lt;h4&gt;主要发现&lt;/h4&gt;通过在两个城市交通数据集上的广泛实验，CalibRefine展示了高精度的校准结果，并且在最少的人工干预下超越了现有的无目标物方法，同时与手动调优基线保持竞争力或优于它们。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了如何利用稳健的对象级特征匹配以及迭代和自我监督的关注机制调整，在复杂的现实世界条件下实现一致的传感器融合，而无需地面实况校准矩阵或复杂的预处理数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate multi-sensor calibration is essential for deploying robustperception systems in applications such as autonomous driving, robotics, andintelligent transportation. Existing LiDAR-camera calibration methods oftenrely on manually placed targets, preliminary parameter estimates, or intensivedata preprocessing, limiting their scalability and adaptability in real-worldsettings. In this work, we propose a fully automatic, targetless, and onlinecalibration framework, CalibRefine, which directly processes raw LiDAR pointclouds and camera images. Our approach is divided into four stages: (1) aCommon Feature Discriminator that trains on automatically detectedobjects--using relative positions, appearance embeddings, and semanticclasses--to generate reliable LiDAR-camera correspondences, (2) a coarsehomography-based calibration, (3) an iterative refinement to incrementallyimprove alignment as additional data frames become available, and (4) anattention-based refinement that addresses non-planar distortions by leveraginga Vision Transformer and cross-attention mechanisms. Through extensiveexperiments on two urban traffic datasets, we show that CalibRefine delivershigh-precision calibration results with minimal human involvement,outperforming state-of-the-art targetless methods and remaining competitivewith, or surpassing, manually tuned baselines. Our findings highlight howrobust object-level feature matching, together with iterative andself-supervised attention-based adjustments, enables consistent sensor fusionin complex, real-world conditions without requiring ground-truth calibrationmatrices or elaborate data preprocessing.</description>
      <author>example@mail.com (Lei Cheng, Lihao Guo, Tianya Zhang, Tam Bang, Austin Harris, Mustafa Hajij, Mina Sartipi, Siyang Cao)</author>
      <guid isPermaLink="false">2502.17648v2</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Like Father, Like Son: Kinship-Aware Preference Mapping (KARMA) for Automatic Alignment in Large Language Models</title>
      <link>http://arxiv.org/abs/2502.18744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages,5 figures,3 tables,4 graphs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Kinship-Aware Preference MApping (KARMA)框架，该框架通过系统地配对具有相似能力的模型响应来改进大型语言模型（LLM）的行为与人类偏好的一致性的方法。&lt;h4&gt;背景&lt;/h4&gt;当前在大型语言模型（LLM）对齐方面取得的进步试图减少人工注释的成本，利用预训练模型生成偏好数据。然而，现有的方法通常比较来自能力显著不同的模型的响应，这些浅层次的区别未能提供有意义的指导以说明哪种回应更优。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法存在的局限性，提出了一种新的框架KARMA，该框架系统地配对具有类似能力的模型之间的响应。&lt;h4&gt;方法&lt;/h4&gt;通过将偏好比较约束为复杂度和质量相似的输出，增强了偏好数据的信息量，并提高了对齐信号的粒度。&lt;h4&gt;主要发现&lt;/h4&gt;实证评估表明，我们的亲缘关系感知的方法导致了更一致且可解释的对齐结果。&lt;h4&gt;结论&lt;/h4&gt;这种方法最终促进了将LLM行为与人类偏好对齐的原则性和可靠路径。&lt;h4&gt;翻译&lt;/h4&gt;最近在大型语言模型（LLM）对齐方面的进展试图通过利用预训练模型生成偏好数据来减少人工注释的成本。然而，现有的方法往往比较来自能力显著不同的模型的响应，这些差异未能提供有意义的指导以说明哪种回应更优。为了解决这一限制，我们提出了亲缘关系感知的偏好数据映射（KARMA）框架，它系统地配对具有相似能力的模型之间的响应。通过将偏好比较约束为复杂度和质量相似的输出，KARMA增强了偏好数据的信息量，并提高了对齐信号的粒度。实证评估表明，我们的亲缘关系感知的方法导致了更一致且可解释的对齐结果，最终促进了将LLM行为与人类偏好对齐的原则性和可靠路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Large Language Model (LLM) alignment have sought tomitigate the cost of human annotations by leveraging pretrained models togenerate preference data. However, existing methods often compare responsesfrom models with substantially different capabilities, yielding superficialdistinctions that fail to provide meaningful guidance on what constitutes asuperior response. To address this limitation, we propose Kinship-AwarepReference MApping (KARMA), a novel framework that systematically pairsresponses from models with comparable competencies. By constraining preferencecomparisons to outputs of similar complexity and quality, KARMA enhances theinformativeness of preference data and improves the granularity of alignmentsignals. Empirical evaluations demonstrate that our kinship-aware approachleads to more consistent and interpretable alignment outcomes, ultimatelyfacilitating a more principled and reliable pathway for aligning LLM behaviorwith human preferences.</description>
      <author>example@mail.com (Jeesu Jung, Chanjun Park, Sangkeun Jung)</author>
      <guid isPermaLink="false">2502.18744v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>What are Foundation Models Cooking in the Post-Soviet World?</title>
      <link>http://arxiv.org/abs/2502.18583v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过构建BORSch数据集，评估了基础模型对后苏联地区饮食文化的理解能力。&lt;h4&gt;背景&lt;/h4&gt;后苏联国家的文化复杂且深受历史影响，这种文化持续影响着当前的事件和人们的生活方式。&lt;h4&gt;目的&lt;/h4&gt;调查大型语言模型对于后苏联区域饮食文化知识的理解程度。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含1147道俄罗斯菜和823道乌克兰菜肴的多模态数据集BORSch。使用该数据集评估了现有基础模型在文本问答（QA）以及跨模态问答中的表现，并进一步测试这些模型生成准确视觉描述的能力。&lt;h4&gt;主要发现&lt;/h4&gt;主导的基础模型在识别后苏联国家菜系起源时遇到困难，往往过度预测与问题语言相关的国家；这些结果可以通过训练数据中误导性的菜品和来源共现现象来解释，以及俄语和乌克兰语之间的代码混合等语言学现象。&lt;h4&gt;结论&lt;/h4&gt;单纯基于问答评估文化理解可能不足以全面评价模型的能力；为了促进进一步研究，BORSch将公开发布在GitHub上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The culture of the Post-Soviet states is complex, shaped by a turbulenthistory that continues to influence current events. In this study, weinvestigate the Post-Soviet cultural food knowledge of foundation models byconstructing BORSch, a multimodal dataset encompassing 1147 and 823 dishes inthe Russian and Ukrainian languages, centered around the Post-Soviet region. Wedemonstrate that leading models struggle to correctly identify the origins ofdishes from Post-Soviet nations in both text-only and multimodal QuestionAnswering (QA), instead over-predicting countries linked to the language thequestion is asked in. Through analysis of pretraining data, we show that theseresults can be explained by misleading dish-origin co-occurrences, along withlinguistic phenomena such as Russian-Ukrainian code mixing. Finally, to movebeyond QA-based assessments, we test models' abilities to produce accuratevisual descriptions of dishes. The weak correlation between this task and QAsuggests that QA alone may be insufficient as an evaluation of culturalunderstanding. To foster further research, we will make BORSch publiclyavailable at https://github.com/alavrouk/BORSch.</description>
      <author>example@mail.com (Anton Lavrouk, Tarek Naous, Alan Ritter, Wei Xu)</author>
      <guid isPermaLink="false">2502.18583v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Rewards-based image analysis in microscopy</title>
      <link>http://arxiv.org/abs/2502.18522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;分析成像和高光谱数据在生物学、医学、化学和物理学等领域中至关重要。目标是将高质量或高维的数据转换为可解释的格式，以便生成有价值的见解。&lt;h4&gt;目的&lt;/h4&gt;研究如何优化成像及高光谱数据分析流程，以减少对人工输入的需求，并提升自动化水平和决策支持能力。&lt;h4&gt;方法&lt;/h4&gt;讨论了基于奖励的工作流程的发展，这些工作流程采用了专家决策原则，并展示了强大的跨任务迁移学习。这种方法代表图像分析为一系列可能的操作上的决策过程。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入基于奖励的框架，可以实现从监督式、黑盒模型向解释性更强、无监督且鲁棒性强的优化方法转变。&lt;h4&gt;结论&lt;/h4&gt;这些工作流程既可作为经典和深度卷积神经网络（DCNN）方法上的包装器使用，又可在无监督和有监督的工作流中发挥作用，适用于各种图像分析和高光谱数据任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容关于成像及高光谱数据分析领域的研究进展，强调了引入机器学习加速特定任务的重要性，并探讨了未来通过奖励驱动工作流程优化此类任务的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Analyzing imaging and hyperspectral data is crucial across scientific fields,including biology, medicine, chemistry, and physics. The primary goal is totransform high-resolution or high-dimensional data into an interpretable formatto generate actionable insights, aiding decision-making and advancingknowledge. Currently, this task relies on complex, human-designed workflowscomprising iterative steps such as denoising, spatial sampling, keypointdetection, feature generation, clustering, dimensionality reduction, andphysics-based deconvolutions. The introduction of machine learning over thepast decade has accelerated tasks like image segmentation and object detectionvia supervised learning, and dimensionality reduction via unsupervised methods.However, both classical and NN-based approaches still require human input,whether for hyperparameter tuning, data labeling, or both. The growing use ofautomated imaging tools, from atomically resolved imaging to biologicalapplications, demands unsupervised methods that optimize data representationfor human decision-making or autonomous experimentation. Here, we discussadvances in reward-based workflows, which adopt expert decision-makingprinciples and demonstrate strong transfer learning across diverse tasks. Werepresent image analysis as a decision-making process over possible operationsand identify desiderata and their mappings to classical decision-makingframeworks. Reward-driven workflows enable a shift from supervised, black-boxmodels sensitive to distribution shifts to explainable, unsupervised, androbust optimization in image analysis. They can function as wrappers overclassical and DCNN-based methods, making them applicable to both unsupervisedand supervised workflows (e.g., classification, regression forstructure-property mapping) across imaging and hyperspectral data.</description>
      <author>example@mail.com (Kamyar Barakati, Yu Liu, Utkarsh Pratiush, Boris N. Slautin, Sergei V. Kalinin)</author>
      <guid isPermaLink="false">2502.18522v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations</title>
      <link>http://arxiv.org/abs/2502.08279v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要主题&lt;/h4&gt;视频到文本的总结，特别是在科学领域中的应用。&lt;h4&gt;背景信息&lt;/h4&gt;将录制的视频转换为简洁准确的文字概述是多模态学习中日益增长的一项挑战。&lt;h4&gt;目的声明&lt;/h4&gt;介绍VISTA数据集，该数据集专门用于科学研究领域的视频至文字概要生成。&lt;h4&gt;研究方法&lt;/h4&gt;包括两个方面：一是收集并整理18,599个AI会议演讲记录及其对应的论文摘要；二是评估最先进的大型模型，并应用基于规划的框架以更好地捕捉摘要结构特性。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，显式计划可以增强总结质量和事实一致性。然而，模型与人类表现之间仍存在显著差距。&lt;h4&gt;结论陈述&lt;/h4&gt;尽管现有方法取得了一定的进步，但科学视频概要生成领域依旧面临诸多挑战。&lt;h4&gt;翻译&lt;/h4&gt;将记录的视频转换成简洁准确的文字摘要在多模态学习中是一个日益增长的难题。本文介绍了一个专门用于科学研究领域的视频到文本总结的数据集VISTA，该数据集中包含了18,599个AI会议演讲及其对应的论文摘要。我们评估了最先进的大型模型，并应用了一种基于规划的方法来更好地捕捉摘要的结构特性。无论是人工还是自动评估都证实，明确的计划能够提高概要质量和事实一致性。然而，模型与人类表现之间仍存在显著差距，这突显了科学视频总结面临的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transforming recorded videos into concise and accurate textual summaries is agrowing challenge in multimodal learning. This paper introduces VISTA, adataset specifically designed for video-to-text summarization in scientificdomains. VISTA contains 18,599 recorded AI conference presentations paired withtheir corresponding paper abstracts. We benchmark the performance ofstate-of-the-art large models and apply a plan-based framework to bettercapture the structured nature of abstracts. Both human and automatedevaluations confirm that explicit planning enhances summary quality and factualconsistency. However, a considerable gap remains between models and humanperformance, highlighting the challenges of scientific video summarization.</description>
      <author>example@mail.com (Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu Qiu, Mirella Lapata, Vera Demberg)</author>
      <guid isPermaLink="false">2502.08279v3</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Convolution Architecture in the Realm of DNA Foundation Models</title>
      <link>http://arxiv.org/abs/2502.18538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，基于Transformer和状态空间模型(SSM)的DNA语言模型取得了进展。然而，在基础模型基准测试中没有对这些新方法与经典卷积神经网络(CNN)进行比较的研究。&lt;h4&gt;背景&lt;/h4&gt;虽然最近提出了许多基于Transformer和SSM架构的方法来改进DNA语言模型，但在一些关键指标上缺乏与传统CNN的对比分析。&lt;h4&gt;目的&lt;/h4&gt;探讨并设计一种新型基于CNN的方法（ConvNova），以评估其在各种基础模型基准测试中的表现，并回答卷积网络是否已被这些新的方法超越的问题。&lt;h4&gt;方法&lt;/h4&gt;开发了一种称为ConvNova的新方法，该方法采用了扩增卷积、门控卷积以及用于门控机制的双分支框架三种有效设计。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实证实验显示，在超过一半的任务上，ConvNova的表现优于最近的方法。特别是在组蛋白相关任务中，ConvNova比第二好的方法高出平均5.8%，同时使用更少的参数并实现更快的计算速度。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明CNN仍然是与Transformer和SSM架构相比具有竞争力的选择。这可能激发对基于CNN方法在DNA基础模型中的重新关注。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容是关于开发了一种新的名为ConvNova的方法，通过实验展示了其优越性，并探讨了卷积网络是否被新架构超越的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, a variety of methods based on Transformer and state spacemodel (SSM) architectures have been proposed, advancing foundational DNAlanguage models. However, there is a lack of comparison between these recentapproaches and the classical architecture convolutional networks (CNNs) onfoundation model benchmarks. This raises the question: are CNNs truly beingsurpassed by these recent approaches based on transformer and SSMarchitectures? In this paper, we develop a simple but well-designed CNN-basedmethod termed ConvNova. ConvNova identifies and proposes three effectivedesigns: 1) dilated convolutions, 2) gated convolutions, and 3) a dual-branchframework for gating mechanisms. Through extensive empirical experiments, wedemonstrate that ConvNova significantly outperforms recent methods on more thanhalf of the tasks across several foundation model benchmarks. For example, inhistone-related tasks, ConvNova exceeds the second-best method by an average of5.8%, while generally utilizing fewer parameters and enabling fastercomputation. In addition, the experiments observed findings that may be relatedto biological characteristics. This indicates that CNNs are still a strongcompetitor compared to Transformers and SSMs. We anticipate that this work willspark renewed interest in CNN-based methods for DNA foundation models.</description>
      <author>example@mail.com (Yu Bo, Weian Mao, Yanjun Shao, Weiqiang Bai, Peng Ye, Xinzhu Ma, Junbo Zhao, Hao Chen, Chunhua Shen)</author>
      <guid isPermaLink="false">2502.18538v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Learning Decentralized Swarms Using Rotation Equivariant Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.17612v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  correcting contact information&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了在没有中央控制的情况下，通过自组织方式优化集体目标的代理调度问题，并特别关注如何利用图神经网络（GNN）架构来提升分布式群组协同能力。&lt;h4&gt;背景&lt;/h4&gt;无中心化控制的代理协调对于诸如自主车队管理和传感器网络中的监控侦察等应用至关重要。分散式控制器的设计受到自然界中自我组织现象，特别是鸟类群体行为的启发，但现有的分散式控制器在保持群体凝聚力方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够利用群组动态中存在的对称性的图神经网络架构，以提高分布式控制器的一般化性能和效率。&lt;h4&gt;方法&lt;/h4&gt;通过在分散式的鸟群控制GNN控制器中强制执行旋转等变性和平移不变性对称性来改进现有的GNN控制器。&lt;h4&gt;主要发现&lt;/h4&gt;与不考虑上述对称性的现有GNN控制器相比，我们的对称感知控制器可以使用更少的训练数据和更少的可调权重实现类似的效果，并且在泛化能力方面表现更好。&lt;h4&gt;结论&lt;/h4&gt;本文提出的旋转等变性和平移不变性策略改进了分散式群组控制系统的性能，证明了这种新方法的有效性。相关代码和动画可在GitHub上获取。&lt;h4&gt;翻译&lt;/h4&gt;代理的协调以优化集体目标而没有中央控制系统是具有挑战性的，但在像自主车队管理和使用传感器网络进行监控侦察等应用中至关重要。分散控制器的设计受到了自然界自组织现象，尤其是鸟类群体行为的启发，但是现有的分散式控制器在维持群组凝聚力方面存在困难。图神经网络（GNN）架构已经成为了开发能够保持群组凝聚力的分散化控制系统的不可或缺的机器学习工具，然而它们未能利用存在于群组动态中的对称性，从而限制了其泛化能力。我们强制执行旋转等变性和平移不变性的对称性以改进分散式鸟群GNN控制器，并且在使用70%更少的训练数据和75%更少的可调权重的同时达到了与没有这些对称性的现有GNN控制器相同的控制效果。此外，我们的对称感知控制器比现有的GNN控制器有更好的泛化能力。相关代码和动画可在GitHub上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The orchestration of agents to optimize a collective objective withoutcentralized control is challenging yet crucial for applications such ascontrolling autonomous fleets, and surveillance and reconnaissance using sensornetworks. Decentralized controller design has been inspired byself-organization found in nature, with a prominent source of inspiration beingflocking; however, decentralized controllers struggle to maintain flockcohesion. The graph neural network (GNN) architecture has emerged as anindispensable machine learning tool for developing decentralized controllerscapable of maintaining flock cohesion, but they fail to exploit the symmetriespresent in flocking dynamics, hindering their generalizability. We enforcerotation equivariance and translation invariance symmetries in decentralizedflocking GNN controllers and achieve comparable flocking control with 70% lesstraining data and 75% fewer trainable weights than existing GNN controllerswithout these symmetries enforced. We also show that our symmetry-awarecontroller generalizes better than existing GNN controllers. Code andanimations are available athttp://github.com/Utah-Math-Data-Science/Equivariant-Decentralized-Controllers.</description>
      <author>example@mail.com (Taos Transue, Bao Wang)</author>
      <guid isPermaLink="false">2502.17612v2</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Multimodality Helps Few-shot 3D Point Cloud Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.22489v4</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICLR 2025 (Spotlight)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的多模态少样本点云分割(MM-FSS)框架，通过结合文本标签和潜在可用的2D图像模式来增强传统单一模态的点云输入。MM-FSS使用一个共享的骨干网络、两个头部以及预训练的文本编码器，有效利用了多个模态之间的互补信息。&lt;h4&gt;背景&lt;/h4&gt;传统的少样本3D点云分割(FS-PCS)方法主要关注于单一模态的点云输入，而忽略了多模态信息可能带来的潜在优势。现有的FS-PCS技术在处理新型类别的分类时需要最少的支持样本来泛化模型。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入利用文本标签和2D图像模式的多模态少样本点云分割框架来改进现有方法，并展示结合这些自由可得的额外模态信息可以显著提升性能。&lt;h4&gt;方法&lt;/h4&gt;MM-FSS采用了共享骨干网络与两个头部相结合的方式，以提取跨模态和单模态视觉特征；同时利用预训练文本编码器生成文本嵌入。为了充分挖掘多模态数据中的信息，提出了一个多模态相关融合(MCF)模块来产生多模态关联，并且设计了一个多模态语义融合(MSF)模块来使用基于文本的语义指导细化这些关联。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在S3DIS和ScanNet数据集上，提出的MM-FSS框架相较于传统方法在性能上有显著提升。具体而言，该方法通过引入测试时间自适应跨模态校准(TACC)技术来缓解训练偏差，进一步提高泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为少样本3D点云分割提供了新的解决方案，并证明了多模态信息的有效性，这为进一步的研究工作提供了有价值的见解。该研究强调了利用通常被忽视的自由模式进行FS-PCS的潜在优势。&lt;h4&gt;翻译&lt;/h4&gt;Few-shot 3D点云分割(FS-PCS)的目标是通过少量注释支持样本使模型泛化以对新型类别进行分类。尽管现有的FS-PCS方法展示了一定的效果，但它们主要集中在单一模态的点云输入上，忽视了利用多模态信息可能带来的潜在好处。本文通过引入一种可以利用文本标签和潜在可用2D图像模式的多模态少样本分割设置来填补这一空白，并提出MultiModal Few-Shot SegNet (MM-FSS)模型，该模型能够有效利用多个来源的信息。实验结果在S3DIS和ScanNet数据集上表明了我们方法的有效性，验证了FS-PCS中结合额外可得模式的好处。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot 3D point cloud segmentation (FS-PCS) aims at generalizing models tosegment novel categories with minimal annotated support samples. While existingFS-PCS methods have shown promise, they primarily focus on unimodal point cloudinputs, overlooking the potential benefits of leveraging multimodalinformation. In this paper, we address this gap by introducing a multimodalFS-PCS setup, utilizing textual labels and the potentially available 2D imagemodality. Under this easy-to-achieve setup, we present the MultiModal Few-ShotSegNet (MM-FSS), a model effectively harnessing complementary information frommultiple modalities. MM-FSS employs a shared backbone with two heads to extractintermodal and unimodal visual features, and a pretrained text encoder togenerate text embeddings. To fully exploit the multimodal information, wepropose a Multimodal Correlation Fusion (MCF) module to generate multimodalcorrelations, and a Multimodal Semantic Fusion (MSF) module to refine thecorrelations using text-aware semantic guidance. Additionally, we propose asimple yet effective Test-time Adaptive Cross-modal Calibration (TACC)technique to mitigate training bias, further improving generalization.Experimental results on S3DIS and ScanNet datasets demonstrate significantperformance improvements achieved by our method. The efficacy of our approachindicates the benefits of leveraging commonly-ignored free modalities forFS-PCS, providing valuable insights for future research. The code is availableat https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot</description>
      <author>example@mail.com (Zhaochong An, Guolei Sun, Yun Liu, Runjia Li, Min Wu, Ming-Ming Cheng, Ender Konukoglu, Serge Belongie)</author>
      <guid isPermaLink="false">2410.22489v4</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models</title>
      <link>http://arxiv.org/abs/2502.19417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种通用型机器人系统，该系统能够处理复杂的指令和反馈，并在实际环境中执行多项任务。&lt;h4&gt;背景&lt;/h4&gt;现有的直接遵循简单命令的方法不足以应对需要复杂推理的任务场景。&lt;h4&gt;目的&lt;/h4&gt;开发一种使用层次结构的视觉语言模型的机器人系统，以理解和执行复杂的任务指令及用户反馈。&lt;h4&gt;方法&lt;/h4&gt;该系统首先通过高层推理解释复杂提示和用户的反馈信息，并确定完成当前任务的最佳下一步；然后在低层控制下执行具体的物理动作。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明了此系统可以在单臂、双臂以及移动式双臂机器人平台上演示出处理杂乱桌面清理、制作三明治等任务的能力。&lt;h4&gt;结论&lt;/h4&gt;该系统的应用证明其能够有效处理开放环境中的各种复杂指令和实时反馈，展现出广泛的潜在应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalist robots that can perform a range of different tasks in open-worldsettings must be able to not only reason about the steps needed to accomplishtheir goals, but also process complex instructions, prompts, and even feedbackduring task execution. Intricate instructions (e.g., "Could you make me avegetarian sandwich?" or "I don't like that one") require not just the abilityto physically perform the individual steps, but the ability to situate complexcommands and feedback in the physical world. In this work, we describe a systemthat uses vision-language models in a hierarchical structure, first reasoningover complex prompts and user feedback to deduce the most appropriate next stepto fulfill the task, and then performing that step with low-level actions. Incontrast to direct instruction following methods that can fulfill simplecommands ("pick up the cup"), our system can reason through complex prompts andincorporate situated feedback during task execution ("that's not trash"). Weevaluate our system across three robotic platforms, including single-arm,dual-arm, and dual-arm mobile robots, demonstrating its ability to handle taskssuch as cleaning messy tables, making sandwiches, and grocery shopping.</description>
      <author>example@mail.com (Lucy Xiaoyang Shi, Brian Ichter, Michael Equi, Liyiming Ke, Karl Pertsch, Quan Vuong, James Tanner, Anna Walling, Haohuan Wang, Niccolo Fusai, Adrian Li-Bell, Danny Driess, Lachy Groom, Sergey Levine, Chelsea Finn)</author>
      <guid isPermaLink="false">2502.19417v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>H-FLTN: A Privacy-Preserving Hierarchical Framework for Electric Vehicle Spatio-Temporal Charge Prediction</title>
      <link>http://arxiv.org/abs/2502.18697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 tables, 2 figures, Journal Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了H-FLTN框架，旨在解决电动汽车普及带来的充电时间预测、用户隐私保护和资源管理等问题。&lt;h4&gt;背景&lt;/h4&gt;电动汽车的广泛应用给能源供应商带来了挑战，包括准确预测充电时间、确保用户隐私以及高效地进行资源配置。&lt;h4&gt;目的&lt;/h4&gt;通过引入Hierarchical Federated Learning Transformer Network (H-FLTN) 框架来应对这些挑战。&lt;h4&gt;方法&lt;/h4&gt;1. 采用三级层次架构（电动汽车、社区分布式能源资源管理系统和能源提供商数据中心）。            2. 使用基于Transformer的学习增强时间预测，捕获充电行为中的复杂依赖关系。            3. 利用安全聚合、加性秘密共享和点对点共享技术来确保隐私保护。            4. 引入动态客户端上限机制（DCCM）和客户端轮换管理（CRM），以提高训练效率和资源分配。&lt;h4&gt;主要发现&lt;/h4&gt;1. H-FLTN框架在大量实际车辆移动数据的模拟中表现出良好性能，特别是在减少随着电动汽车数量增加而产生的线性增长的培训时间复杂度至常量方面。            2. DCCM和CRM能够有效防止由于参与训练的客户端增多而导致计算负担过重的问题。&lt;h4&gt;结论&lt;/h4&gt;H-FLTN框架的实施可以增强智能城市的能源需求预测、资源分配和电网稳定性，确保未来移动生态系统的可靠性和可持续性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread adoption of Electric Vehicles (EVs) poses critical challengesfor energy providers, particularly in predicting charging time (temporalprediction), ensuring user privacy, and managing resources efficiently inmobility-driven networks. This paper introduces the Hierarchical FederatedLearning Transformer Network (H-FLTN) framework to address these challenges.H-FLTN employs a three-tier hierarchical architecture comprising EVs, communityDistributed Energy Resource Management Systems (DERMS), and the Energy ProviderData Centre (EPDC) to enable accurate spatio-temporal predictions of EVcharging needs while preserving privacy. Temporal prediction is enhanced usingTransformer-based learning, capturing complex dependencies in chargingbehavior. Privacy is ensured through Secure Aggregation, Additive SecretSharing, and Peer-to-Peer (P2P) Sharing with Augmentation, which allow onlysecret shares of model weights to be exchanged while securing alltransmissions. To improve training efficiency and resource management, H-FLTNintegrates Dynamic Client Capping Mechanism (DCCM) and Client RotationManagement (CRM), ensuring that training remains both computationally andtemporally efficient as the number of participating EVs increases. DCCMoptimises client participation by limiting excessive computational loads, whileCRM balances training contributions across epochs, preventing imbalancedparticipation. Our simulation results based on large-scale empirical vehiclemobility data reveal that DCCM and CRM reduce the training time complexity withincreasing EVs from linear to constant. Its integration into real-world smartcity infrastructure enhances energy demand forecasting, resource allocation,and grid stability, ensuring reliability and sustainability in future mobilityecosystems.</description>
      <author>example@mail.com (Robert Marlin, Raja Jurdak, Alsharif Abuadbba)</author>
      <guid isPermaLink="false">2502.18697v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>SLAM in the Dark: Self-Supervised Learning of Pose, Depth and Loop-Closure from Thermal Images</title>
      <link>http://arxiv.org/abs/2502.18932v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;Visual SLAM 对移动机器人、无人机导航和 VR/AR 非常重要，但传统的 RGB 相机系统在低光条件下表现不佳，促使人们关注热像 SLAM。然而，热成像面临低对比度、高噪声以及有限的大规模标注数据集等问题，限制了深度学习在户外场景中的应用。&lt;h4&gt;背景&lt;/h4&gt;传统RGB相机系统在低光条件下效果不佳，推动了对热像SLAM技术的研究需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于复杂光照条件下的大规模定位和重建的新型单目热像SLAM系统DarkSLAM。&lt;h4&gt;方法&lt;/h4&gt;{'ECA机制': '将Efficient Channel Attention（ECA）机制应用于视觉里程计，以提高姿态准确性。', 'SKA机制': '引入Selective Kernel Attention（SKA）机制进行深度估计，缓解了热像深度退化问题。', '闭环检测和姿态优化': '基于热像深度的闭环检测以及姿态优化，确保在低纹理热场景中的鲁棒性能'}&lt;h4&gt;主要发现&lt;/h4&gt;DarkSLAM 在户外实验中显著优于现有的SC-Sfm-Learner和Shin等人提出的方法，在严峻的夜间环境中也能实现精确定位和三维稠密地图构建。&lt;h4&gt;结论&lt;/h4&gt;DarkSLAM 提供了一种强大的解决方案，适用于在低光条件下的大规模场景中的实时导航和重建任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual SLAM is essential for mobile robots, drone navigation, and VR/AR, buttraditional RGB camera systems struggle in low-light conditions, drivinginterest in thermal SLAM, which excels in such environments. However, thermalimaging faces challenges like low contrast, high noise, and limited large-scaleannotated datasets, restricting the use of deep learning in outdoor scenarios.We present DarkSLAM, a noval deep learning-based monocular thermal SLAM systemdesigned for large-scale localization and reconstruction in complex lightingconditions.Our approach incorporates the Efficient Channel Attention (ECA)mechanism in visual odometry and the Selective Kernel Attention (SKA) mechanismin depth estimation to enhance pose accuracy and mitigate thermal depthdegradation. Additionally, the system includes thermal depth-based loop closuredetection and pose optimization, ensuring robust performance in low-texturethermal scenes. Extensive outdoor experiments demonstrate that DarkSLAMsignificantly outperforms existing methods like SC-Sfm-Learner and Shin et al.,delivering precise localization and 3D dense mapping even in challengingnighttime environments.</description>
      <author>example@mail.com (Yangfan Xu, Qu Hao, Lilian Zhang, Jun Mao, Xiaofeng He, Wenqi Wu, Changhao Chen)</author>
      <guid isPermaLink="false">2502.18932v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Emerging Practices in Participatory AI Design in Public Sector Innovation</title>
      <link>http://arxiv.org/abs/2502.18689v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Extended Abstracts of the CHI Conference on Human Factors in  Computing Systems (CHI EA '25), April 26-May 1, 2025, Yokohama, Japan&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;地方政府正在利用AI系统来改进公共服务的提供，同时确保技术采用过程中民主价值和社区信任得到维护。&lt;h4&gt;背景&lt;/h4&gt;地方和联邦机构正快速采纳AI系统以增强或自动化关键决策，并提高资源使用效率。这些系统在城市规划、安全监控、能源管理等方面发挥作用，影响公民获取基本服务的能力。&lt;h4&gt;目的&lt;/h4&gt;探讨参与式算法设计的方法，在公共服务领域中通过公众参与和社区互动来确定、设计、采用和实施算法。&lt;h4&gt;方法&lt;/h4&gt;需要重新评估传统的技术采纳方式，并为公共部门制定新的资源和方法，特别是在AI创新引入的新挑战下。&lt;h4&gt;主要发现&lt;/h4&gt;在智能城市倡议背景下，地方治理层必须确保民主价值的维持并建立社区信任。社区中心化及参与式的方式对于保证科技适当采用至关重要。&lt;h4&gt;结论&lt;/h4&gt;探索新兴的参与式算法设计实践是必要的，尤其是在公共部门，因为这要求更高的实施标准和更严格的形成方法。&lt;h4&gt;翻译&lt;/h4&gt;地方和联邦机构正在迅速采纳AI系统以增强或自动化关键决策，高效利用资源，并改善公共服务交付。这些系统被用于支持与城市规划、安全、监控、能源和关键基础设施相关的任务，以及影响公民获取基本服务能力的决策。地方政府作为最接近民众的治理层级，必须在智能城市的倡议中发挥重要作用，维护民主价值并建立社区信任。基于社区的方法对于确保技术适当采用至关重要；然而，在AI创新背景下，参与式设计方法需要更严格的规定和更高的实施标准，这比私营部门更具挑战性。因此，我们需要重新审视传统的做法，并为此开发新的资源和方法。本次研讨会将探讨公共部门算法的规划、设计、采用和实施中的新兴的参与式算法设计实践。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Local and federal agencies are rapidly adopting AI systems to augment orautomate critical decisions, efficiently use resources, and improve publicservice delivery. AI systems are being used to support tasks associated withurban planning, security, surveillance, energy and critical infrastructure, andsupport decisions that directly affect citizens and their ability to accessessential services. Local governments act as the governance tier closest tocitizens and must play a critical role in upholding democratic values andbuilding community trust especially as it relates to smart city initiativesthat seek to transform public services through the adoption of AI.Community-centered and participatory approaches have been central for ensuringthe appropriate adoption of technology; however, AI innovation introduces newchallenges in this context because participatory AI design methods require morerobust formulation and face higher standards for implementation in the publicsector compared to the private sector. This requires us to reassess traditionalmethods used in this space as well as develop new resources and methods. Thisworkshop will explore emerging practices in participatory algorithm design - orthe use of public participation and community engagement - in the scoping,design, adoption, and implementation of public sector algorithms.</description>
      <author>example@mail.com (Devansh Saxena, Zoe Kahn, Erina Seh-Young Moon, Lauren M. Chambers, Corey Jackson, Min Kyung Lee, Motahhare Eslami, Shion Guha, Sheena Erete, Lilly Irani, Deirdre Mulligan, John Zimmerman)</author>
      <guid isPermaLink="false">2502.18689v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>ImageChain: Advancing Sequential Image-to-Text Reasoning in Multimodal Large Language Models</title>
      <link>http://arxiv.org/abs/2502.19409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code, dataset, and checkpoints are publicly available at  https://github.com/danaesavi/ImageChain&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'背景': '对于多模态大型语言模型而言，基于图像序列的推理仍然是一个挑战。虽然最近的一些模型在预训练过程中引入了多张图片数据，但它们仍然难以识别序列结构，往往将图像视为独立的数据进行处理。', '目的': '介绍一种名为ImageChain的框架，旨在通过模拟视觉序列作为多轮对话来增强多模态大型语言模型的顺序推理能力。', '方法': '在ImageChain中，图片与相应的文本描述交错形成一个受控对话，明确捕捉时间依赖性和叙述进展。该方法优化了下一个场景描述任务，即基于先前的视觉和文本线索生成上下文感知的后续场景描述。', '主要发现': '实验表明，这种方法显著提高了下一场景描述任务的表现，平均改进幅度在SimRate这一衡量语义相似性的指标下为3.7%至19%。此外，在从漫画到机器人等各种应用中的零样本跨领域性能也表现出色。', '结论': '通过多模态、多轮对话的设计进行指令微调是弥合静态图像理解与时间感知推理之间差距的关键方法。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reasoning over sequences of images remains a challenge for multimodal largelanguage models (MLLMs). While recent models incorporate multi-image dataduring pre-training, they still struggle to recognize sequential structures,often treating images independently. This work introduces ImageChain, aframework that enhances MLLMs with sequential reasoning capabilities over imagedata by modeling visual sequences as a multi-turn conversation. In ImageChain,images are interleaved with corresponding textual descriptions to form acontrolled dialogue that explicitly captures temporal dependencies andnarrative progression. Our method optimizes for the task of next-scenedescription, where the model generates a context-aware description of anupcoming scene based on preceding visual and textual cues. We demonstrate thatour approach improves performance on the next-scene description task --achieving an average improvement from 3.7% to 19% in SimRate, a metric thatquantifies semantic similarity to human-annotated ground truths. Moreover,ImageChain achieves robust zero-shot out-of-domain performance in applicationsranging from comics to robotics. Extensive experiments validate thatinstruction-tuning in a multimodal, multi-turn conversation design is key tobridging the gap between static image understanding and temporally-awarereasoning.</description>
      <author>example@mail.com (Danae Sánchez Villegas, Ingo Ziegler, Desmond Elliott)</author>
      <guid isPermaLink="false">2502.19409v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>ARENA: Adaptive Risk-aware and Energy-efficient NAvigation for Multi-Objective 3D Infrastructure Inspection with a UAV</title>
      <link>http://arxiv.org/abs/2502.19401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures, submitted to IEEE Robotics and Automation Letters  (RA-L)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种适用于复杂3D环境下的无人机自主巡检任务的自适应风险感知和能量效率导航方法ARENA，该方法在多目标路径规划中实现了在线轨迹优化，并通过实际测试验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;目前的多目标路径规划方法难以应对定位误差、天气变化等不断演变的风险因素。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够在复杂3D环境中实时适应风险和能量消耗，为无人机自主巡检任务提供可靠导航方案的方法。&lt;h4&gt;方法&lt;/h4&gt;利用4维NURBS表示形式及遗传算法生成帕累托前沿，通过创新性的风险感知投票算法确保自适应性。&lt;h4&gt;主要发现&lt;/h4&gt;ARENA框架能够在很大程度上优化轨迹多样性，并准确估计能量消耗。仿真和实际测试表明该规划器能够产生覆盖95%以上单一目标基准定义范围的多样化、最优化轨迹。&lt;h4&gt;结论&lt;/h4&gt;ARENA框架显著提高了无人机在关键且不断变化的3D任务中的自主性和可靠性。&lt;h4&gt;翻译&lt;/h4&gt;自主机器人巡检任务需要平衡多个相互冲突的目标，同时导航时避免靠近昂贵障碍物。当前多目标路径规划方法难以适应如定位误差、天气情况、电池状态及通信问题等不断演变的风险。本文提出了一种适用于复杂3D环境下的无人机自适应风险感知和能量效率导航（ARENA）的多目标路径规划方案。此方法通过4维NURBS表示形式与基于遗传算法生成帕累托前沿，在线优化安全性、时间和能源，使用新颖的风险感知投票算法确保其自适应性。仿真及实际测试表明该规划器能够产生多样化且最优化轨迹，覆盖单目标基准定义范围的95%以上，并且具有良好的能量消耗估计能力，平均误差代表全功率范围的14%。ARENA框架增强了无人机在关键和不断变化3D任务中的自主性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous robotic inspection missions require balancing multiple conflictingobjectives while navigating near costly obstacles. Current multi-objective pathplanning (MOPP) methods struggle to adapt to evolving risks like localizationerrors, weather, battery state, and communication issues. This letter presentsan Adaptive Risk-aware and Energy-efficient NAvigation (ARENA) MOPP approachfor UAVs in complex 3D environments. Our method enables online trajectoryadaptation by optimizing safety, time, and energy using 4D NURBS representationand a genetic-based algorithm to generate the Pareto front. A novel risk-awarevoting algorithm ensures adaptivity. Simulations and real-world testsdemonstrate the planner's ability to produce diverse, optimized trajectoriescovering 95% or more of the range defined by single-objective benchmarks andits ability to estimate power consumption with a mean error representing 14% ofthe full power range. The ARENA framework enhances UAV autonomy and reliabilityin critical, evolving 3D missions.</description>
      <author>example@mail.com (David-Alexandre Poissant, Alexis Lussier Desbiens, François Ferland, Louis Petit)</author>
      <guid isPermaLink="false">2502.19401v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Surface-Based Manipulation</title>
      <link>http://arxiv.org/abs/2502.19389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript is under revision for possible publication in the npj  Robotics. Copyright may be transferred to the publisher if the manuscript is  accepted for publication, without further notice. Supplementary video:  https://drive.google.com/drive/folders/1qbagK0VHi4DyfHGJ99ZlESX_i4rU_nmh?usp=sharing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于表面的机器人操作策略，这种策略使用平面作为末端执行器来实现物体的精确操控。&lt;h4&gt;背景&lt;/h4&gt;在机器人研究中，与物理世界的交互是至关重要的。传统的方法主要依赖于类似手指形状的抓取装置，但这种方法难以稳定地抓取脆弱、可变形或非规则形状的物体。&lt;h4&gt;目的&lt;/h4&gt;探讨一种新的操作策略，以解决现有的基于指尖的传统抓取方法存在的问题，并且能够适应各种不同大小和刚度级别的物体。&lt;h4&gt;方法&lt;/h4&gt;提出了一种利用平面表面作为末端执行器的方法，通过改变这些平面的位置和方向，可以实现对物体的平移、旋转甚至翻转。这种方法不需要依赖稳定的抓取，而是依靠闭合回路控制策略来实现稳定操作。&lt;h4&gt;主要发现&lt;/h4&gt;这种基于表面的操作方法能够适应各种形状大小及硬度不同的物体，并且还可以操控可变形物体的形态。&lt;h4&gt;结论&lt;/h4&gt;这项研究成果为解决复杂的机器人操作问题提供了一个全新的视角。这种方法不仅可以应用于多种类型的物体，而且还扩展了我们对智能的理解：它不仅仅存在于大脑中，还体现在身体和与环境互动的方式之中。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intelligence lies not only in the brain but in the body. The shape of ourbodies can influence how we think and interact with the physical world. Inrobotics research, interacting with the physical world is crucial as it allowsrobots to manipulate objects in various real-life scenarios. Conventionalrobotic manipulation strategies mainly rely on finger-shaped end effectors.However, achieving stable grasps on fragile, deformable, irregularly shaped, orslippery objects is challenging due to difficulties in establishing stableforce or geometric constraints.  Here, we present surface-based manipulation strategies that diverge fromclassical grasping approaches, using with flat surfaces as minimalistend-effectors. By changing the position and orientation of these surfaces,objects can be translated, rotated and even flipped across the surface usingclosed-loop control strategies. Since this method does not rely on stablegrasp, it can adapt to objects of various shapes, sizes, and stiffness levels,even enabling the manipulation the shape of deformable objects. Our resultsprovide a new perspective for solving complex manipulation problems.</description>
      <author>example@mail.com (Ziqiao Wang, Serhat Demirtas, Fabio Zuliani, Jamie Paik)</author>
      <guid isPermaLink="false">2502.19389v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Robot Learning for Automatic Robot Motion Planning in Manufacturing</title>
      <link>http://arxiv.org/abs/2502.19340v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 Pages, 11 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多级混合机器人运动规划方法，该方法结合了基于任务空间的强化学习和从演示中学习（RL-LfD）代理以及关节空间深度强化学习（DRL）代理。这种方法通过实现两个代理之间的切换，确保机器人的动作既可行又平滑。&lt;h4&gt;背景&lt;/h4&gt;工业机器人在各种制造环境中广泛应用，但如何使机器人能够自动规划适应不同任务的轨迹是一个重大挑战。特别是当机器人与其他设备、人类或其他机器人共同工作时，这一问题变得更加复杂。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的混合运动规划方法，以解决工业机器人面临的自动化和灵活性方面的难题。&lt;h4&gt;方法&lt;/h4&gt;该研究通过结合基于任务空间的RL-LfD代理和基于关节空间的DRL代理来实现多级混合规划。较高层次的代理负责在两个较低层次的代理之间进行切换，并且这种切换策略考虑了机器人的可达性、关节极限、操作灵活性及碰撞风险等多重因素。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的混合运动规划方法能够生成满足任务约束条件并且可行性的轨迹。&lt;h4&gt;结论&lt;/h4&gt;通过仿真和实际场景验证了该方法的有效性和实用性。此研究为工业机器人在复杂多变的工作环境中自动规划路径提供了一种有效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要的中文直接翻译版本：工业机器人广泛应用于各种制造环境，但是如何使它们能够自动地计划出适应改变任务的动作轨迹是一个重要的挑战。当机器人在其工作单元内与其他机器、人类或其它机器人一起操作时，情况会变得更复杂。本文介绍了一种多级混合型机器人运动规划方法，该方法结合了基于任务空间的强化学习从演示中学习（RL-LfD）代理和关节空间的深度强化学习（DRL）代理的方法。一个更高的层级代理被用来在两个较低层级的代理之间进行切换以实现可行且平滑的动作。可行性通过将机器人在其环境中可达到性、关节极限、操作灵活性以及碰撞风险等因素综合考虑来进行计算。因此，由此方法产生的混合型运动规划策略生成出符合任务约束条件并且是可行性的轨迹。该方法的有效性在仿真中的机器人场景和实际应用场景中得到了验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Industrial robots are widely used in diverse manufacturing environments.Nonetheless, how to enable robots to automatically plan trajectories forchanging tasks presents a considerable challenge. Further complexities arisewhen robots operate within work cells alongside machines, humans, or otherrobots. This paper introduces a multi-level hybrid robot motion planning methodcombining a task space Reinforcement Learning-based Learning from Demonstration(RL-LfD) agent and a joint-space based Deep Reinforcement Learning (DRL) basedagent. A higher level agent learns to switch between the two agents to enablefeasible and smooth motion. The feasibility is computed by incorporatingreachability, joint limits, manipulability, and collision risks of the robot inthe given environment. Therefore, the derived hybrid motion planning policygenerates a feasible trajectory that adheres to task constraints. Theeffectiveness of the method is validated through sim ulated robotic scenariosand in a real-world setup.</description>
      <author>example@mail.com (Siddharth Singh, Tian Yu, Qing Chang, John Karigiannis, Shaopeng Liu)</author>
      <guid isPermaLink="false">2502.19340v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>ObjectVLA: End-to-End Open-World Object Manipulation Without Demonstration</title>
      <link>http://arxiv.org/abs/2502.19250v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page at https://objectvla.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于Vision-Language-Action (VLA)模型的方法ObjectVLA，该方法使机器人能够在未见过的新对象上泛化所学的技能。&lt;h4&gt;背景&lt;/h4&gt;模仿学习在教授机器人的灵巧操作技巧方面非常有效，但通常依赖大量的人类演示数据，这限制了其在动态真实环境中的可扩展性和适用性。一个关键挑战是物体泛化能力的缺乏，即机器人难以将针对特定对象训练出的操作技能转移到语义相似但视觉不同的新对象上。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够实现物体级泛化的简单且有效的方法，并减少对大量人类演示的需求。&lt;h4&gt;方法&lt;/h4&gt;使用Vision-Language-Action (VLA)模型结合视觉和语言数据，使机器人能够在没有针对新目标物的具体演示的情况下泛化操作技能。通过利用预训练的模型并进行少量图像的微调来进一步增强泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在一个真实的机器人平台上测试时，ObjectVLA能够对100个从未见过的新对象以64%的成功率完成指定任务。&lt;h4&gt;结论&lt;/h4&gt;该方法有效支持了物体级别的泛化学习，并减少了需要大量人类演示的需求，为更加灵活和可扩展的机器人系统铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;模仿学习已被证明在教导机器人灵巧操作技能方面非常有效。然而，它通常依赖于大量的数据，这些数据来自人类的操作示范，这限制了其在动态现实环境中的应用范围和规模。在这种情况下的一个关键挑战是物体的泛化能力，即一个被训练来处理特定对象任务的机器人（例如“拿起苹果”）很难将所学技能转移到语义上相似但视觉上不同的新目标物上（如“拿起桃子”）。先前关于端到端视觉操作策略学习的研究尚未充分解决向这些类别之外的新物体泛化的问题。本文中，我们提出了一种简单而有效的方法ObjectVLA，通过Vision-Language-Action (VLA)模型实现物体的泛化能力。我们的方法使机器人可以在没有为每个新目标物提供明确的人类演示的情况下将学到的操作技能转移到新的对象上。通过结合视觉和语言对数据，我们的方法以一种轻量级且可扩展的方式注入关于目标对象的知识，并建立了该对象与预期操作之间的隐式联系。我们在真实机器人的平台验证了ObjectVLA的能力，展示其可以成功地在100个从训练中未见过的新型物体上进行泛化，在选择从未见过的目标物方面取得了64%的成功率。此外，我们提出了一种使用智能手机拍摄少量图像并微调预训练模型的方法来增强VLA模型中的对象泛化能力。这些结果突显了我们的方法在实现物体级别泛化和减少需要广泛人类演示需求方面的有效性，并为更灵活可扩展的机器人学习系统铺平道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning has proven to be highly effective in teaching robotsdexterous manipulation skills. However, it typically relies on large amounts ofhuman demonstration data, which limits its scalability and applicability indynamic, real-world environments. One key challenge in this context is objectgeneralization, where a robot trained to perform a task with one object, suchas "hand over the apple," struggles to transfer its skills to a semanticallysimilar but visually different object, such as "hand over the peach." This gapin generalization to new objects beyond those in the same category has yet tobe adequately addressed in previous work on end-to-end visuomotor policylearning. In this paper, we present a simple yet effective approach forachieving object generalization through Vision-Language-Action (VLA) models,referred to as \textbf{ObjectVLA}. Our model enables robots to generalizelearned skills to novel objects without requiring explicit human demonstrationsfor each new target object. By leveraging vision-language pair data, our methodprovides a lightweight and scalable way to inject knowledge about the targetobject, establishing an implicit link between the object and the desiredaction. We evaluate ObjectVLA on a real robotic platform, demonstrating itsability to generalize across 100 novel objects with a 64\% success rate inselecting objects not seen during training. Furthermore, we propose a moreaccessible method for enhancing object generalization in VLA models, using asmartphone to capture a few images and fine-tune the pre-trained model. Theseresults highlight the effectiveness of our approach in enabling object-levelgeneralization and reducing the need for extensive human demonstrations, pavingthe way for more flexible and scalable robotic learning systems.</description>
      <author>example@mail.com (Minjie Zhu, Yichen Zhu, Jinming Li, Zhongyi Zhou, Junjie Wen, Xiaoyu Liu, Chaomin Shen, Yaxin Peng, Feifei Feng)</author>
      <guid isPermaLink="false">2502.19250v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>CPG-Based Manipulation with Multi-Module Origami Robot Surface</title>
      <link>http://arxiv.org/abs/2502.19218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript is under revision for possible publication in the  IEEE Robotics and Automation Letters (RA-L). Copyright may be transferred to  IEEE if the manuscript is accepted for publication, without further notice.  Supplementary video: https://youtu.be/AEmWFmHhPOA. Code available:  https://doi.org/10.5281/zenodo.14726303&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人机械手在处理不同尺寸和材料的物体时面临挑战，特别是在操作大尺度或具有不同刚度的物体时更为明显。传统抓取技术和策略在这种情况下经常表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于表面的多模块机器人操控框架，以解决现有技术无法有效操作各种大小、形状及硬度物体的问题。&lt;h4&gt;方法&lt;/h4&gt;采用中央模式发生器（CPG）运动生成器与模拟优化法结合的方式确定用于多模块折纸机器人表面(Ori-Pixel)的最佳操控参数。&lt;h4&gt;主要发现&lt;/h4&gt;通过动态仿真和一系列原型实验，展示了这种新框架可以有效地处理从厘米到米级别的物体，并且能够适应不同大小、重量、形状及材质的物体。&lt;h4&gt;结论&lt;/h4&gt;优化后的CPG参数在广泛的测试中表现出强大的操控能力。&lt;h4&gt;翻译&lt;/h4&gt;机器人抓取器通常面临挑战，在处理各种尺寸和材料的物体时效率较低。特别是在操作大尺度或具有多变刚度的物品时，传统抓握技术和策略往往无效。本文介绍了一种新颖的基于表面的多模块机器人操纵框架，该框架使用中央模式发生器（CPG）运动生成器，并结合模拟优化法来确定用于折纸机器人表面对象的最优操作参数。这种方法能够处理从厘米到米级别的各种刚度和形状的对象。通过动态仿真及一系列原型实验测试了最佳的CPG参数，证明了该框架在多种不同大小、重量、形状以及材料物体上的稳健性操控能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic manipulators often face challenges in handling objects of differentsizes and materials, limiting their effectiveness in practical applications.This issue is particularly pronounced when manipulating meter-scale objects orthose with varying stiffness, as traditional gripping techniques and strategiesfrequently prove inadequate. In this letter, we introduce a novel surface-basedmulti-module robotic manipulation framework that utilizes a Central PatternGenerator (CPG)-based motion generator, combined with a simulation-basedoptimization method to determine the optimal manipulation parameters for amulti-module origami robotic surface (Ori-Pixel). This approach allows for themanipulation of objects ranging from centimeters to meters in size, withvarying stiffness and shape. The optimized CPG parameters are tested throughboth dynamic simulations and a series of prototype experiments involving a widerange of objects differing in size, weight, shape, and material, demonstratingrobust manipulation capabilities.</description>
      <author>example@mail.com (Yuhao Jiang, Serge El Asmar, Ziqiao Wang, Serhat Demirtas, Jamie Paik)</author>
      <guid isPermaLink="false">2502.19218v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Embodying mechano-fluidic memory in soft machines to program behaviors upon interactions</title>
      <link>http://arxiv.org/abs/2502.19192v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;软机器可以适应外部环境的变化，通过直接在结构中体现记忆能力来实现更加响应性的行为。&lt;h4&gt;目的&lt;/h4&gt;展示如何利用弹性壳体的双稳态特性改变封闭腔内的流体性质，从而切换自振荡机器的稳定频率状态。&lt;h4&gt;方法&lt;/h4&gt;开发围绕双稳态壳体的流体电路，软管在外部触碰时会弯曲和恢复原状。通过这种方式实现了长期和短期记忆功能。&lt;h4&gt;主要发现&lt;/h4&gt;设计了可以响应人类用户交互并自主改变方向来避开障碍物（如墙壁）的软机器。&lt;h4&gt;结论&lt;/h4&gt;只利用几何形状和弹性特性，将记忆直接嵌入物理结构中可以让没有中央大脑的系统表现出自主行为，这通常是由基于计算机的机器人系统完成的任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容已经用中文进行了总结。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soft machines display shape adaptation to external circumstances due to theirintrinsic compliance. To achieve increasingly more responsive behaviors uponinteractions without relying on centralized computation, embodying memorydirectly in the machines' structure is crucial. Here, we harness thebistability of elastic shells to alter the fluidic properties of an enclosedcavity, thereby switching between stable frequency states of a locomotingself-oscillating machine. To program these memory states upon interactions, wedevelop fluidic circuits surrounding the bistable shell, with soft tubes thatkink and unkink when externally touched. We implement circuits for bothlong-term and short-term memory in a soft machine that switches behaviors inresponse to a human user and that autonomously changes direction afterdetecting a wall. By harnessing only geometry and elasticity, embodying memoryallows physical structures without a central brain to exhibit autonomous featsthat are typically reserved for computer-based robotic systems.</description>
      <author>example@mail.com (Alberto Comoretto, Tanaya Mandke, Johannes T. B. Overvelde)</author>
      <guid isPermaLink="false">2502.19192v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>PlantPal: Leveraging Precision Agriculture Robots to Facilitate Remote Engagement in Urban Gardening</title>
      <link>http://arxiv.org/abs/2502.19171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PlantPal是一种支持城市居民进行园艺活动的系统，它利用精密农业机器人（PAR）来克服空间、时间和技能方面的限制。&lt;h4&gt;背景&lt;/h4&gt;城市园艺在健康和环保方面有许多好处。然而，缺乏合适的花园空间、忙碌的日程安排以及有限的园艺知识是阻碍人们参与城市园艺的主要障碍。&lt;h4&gt;目的&lt;/h4&gt;研究并开发PlantPal系统以解决当前智能家庭解决方案未能充分应对的实际问题，使用户能够在任何地点进行园艺活动，不受专业知识和时间限制的影响。&lt;h4&gt;方法&lt;/h4&gt;PlantPal利用一个配备了多种工具和多摄像头系统的精密农业机器人（PAR），通过远程操作帮助人们在日常生活中整合园艺任务。&lt;h4&gt;主要发现&lt;/h4&gt;为期三周的实验表明，PlantPal有助于将园艺任务融入日常生活，增强用户与自己田地的情感连接，并提供一种即使在远程环境下也能保持吸引力的体验。&lt;h4&gt;结论&lt;/h4&gt;研究提出了一些未来机器人辅助城市园艺概念的设计考虑事项。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban gardening is widely recognized for its numerous health andenvironmental benefits. However, the lack of suitable garden spaces, demandingdaily schedules and limited gardening expertise present major roadblocks forcitizens looking to engage in urban gardening. While prior research hasexplored smart home solutions to support urban gardeners, these approachescurrently do not fully address these practical barriers. In this paper, wepresent PlantPal, a system that enables the cultivation of garden spacesirrespective of one's location, expertise level, or time constraints. PlantPalenables the shared operation of a precision agriculture robot (PAR) that isequipped with garden tools and a multi-camera system. Insights from a 3-weekdeployment (N=18) indicate that PlantPal facilitated the integration ofgardening tasks into daily routines, fostered a sense of connection with one'sfield, and provided an engaging experience despite the remote setting. Wecontribute design considerations for future robot-assisted urban gardeningconcepts.</description>
      <author>example@mail.com (Albin Zeqiri, Julian Britten, Clara Schramm, Pascal Jansen, Michael Rietzler, Enrico Rukzio)</author>
      <guid isPermaLink="false">2502.19171v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>A Temporal Planning Framework for Multi-Agent Systems via LLM-Aided Knowledge Base Management</title>
      <link>http://arxiv.org/abs/2502.19135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将大型语言模型与基于Prolog的知识管理和规划集成到多机器人任务中的框架PLANTOR。&lt;h4&gt;背景&lt;/h4&gt;当前研究中，多机器人系统需要处理复杂的知识表示和时间、资源等约束条件。现有的解决方案可能难以扩展或解释。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够结合大型语言模型生成准确的知识库，并利用Prolog确保形式正确性和可解释性的框架。&lt;h4&gt;方法&lt;/h4&gt;{'PLANTOR框架': '采用两阶段的机器人专用知识库生成过程，以保证重用性与组合推理能力；制定三步规划程序处理时间依赖、资源限制及并行任务执行问题。', '计划转换': '最终计划通过混合整数线性编程确定后，被转化为行为树用于直接在ROS2中使用。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'知识库生成': '大型语言模型可以在少量的人工反馈下产生准确的知识库；', '形式正确性和可解释性': 'Prolog保证了系统的正式验证和透明度。', '应用效果': 'PLANTOR框架在构建块世界多机器人装配任务与拱形建筑场景中表现出色。'}&lt;h4&gt;结论&lt;/h4&gt;大型语言模型与规划系统结合的集成方法对于需要灵活、可扩展且人类易于理解计划的任务至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要全文为英文，以上内容为其中文翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel framework, called PLANTOR (PLanning with Naturallanguage for Task-Oriented Robots), that integrates Large Language Models(LLMs) with Prolog-based knowledge management and planning for multi-robottasks. The system employs a two-phase generation of a robot-oriented knowledgebase, ensuring reusability and compositional reasoning, as well as a three-stepplanning procedure that handles temporal dependencies, resource constraints,and parallel task execution via mixed-integer linear programming. The finalplan is converted into a Behaviour Tree for direct use in ROS2. We tested theframework in multi-robot assembly tasks within a block world and anarch-building scenario. Results demonstrate that LLMs can produce accurateknowledge bases with modest human feedback, while Prolog guarantees formalcorrectness and explainability. This approach underscores the potential of LLMintegration for advanced robotics tasks requiring flexible, scalable, andhuman-understandable planning.</description>
      <author>example@mail.com (Enrico Saccon, Ahmet Tikna, Davide De Martini, Edoardo Lamon, Luigi Palopoli, Marco Roveri)</author>
      <guid isPermaLink="false">2502.19135v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Ground-level Viewpoint Vision-and-Language Navigation in Continuous Environments</title>
      <link>http://arxiv.org/abs/2502.19024v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Ground-level Viewpoint Navigation (GVNav)方法，旨在解决视觉语言导航(VLN)中由于观察视角高度不同而导致的人类指令与低视点机器人之间的不匹配问题。&lt;h4&gt;背景&lt;/h4&gt;VLN任务面临的主要挑战之一是缺乏在真实场景中的泛化能力，尤其是在处理视野受限的四足机器人的指令跟随时。当前的方法往往未能充分考虑不同视觉高度带来的感知差异。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决低视点机器人执行人类指导导航任务时遇到的独特问题，并展示通过使用加权历史观测数据和转移连通性图可以提高模型在模拟环境和真实世界部署中的性能。&lt;h4&gt;方法&lt;/h4&gt;GVNav利用加权的历史观察作为增强的时空上下文，以帮助机器人处理由于视觉障碍或感知不匹配导致的问题。此外，该工作还引入了HM3D和Gibson数据集的连通性图作为额外资源来提高空间先验知识并更好地表示现实世界的场景。&lt;h4&gt;主要发现&lt;/h4&gt;GVNav方法显著提升了在模拟环境以及使用四足机器人进行真实世界部署时的表现。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了视点高度变化对VLN任务性能的影响，并为低视点导航提出了创新性解决方案，这有望改善未来机器人的感知和决策能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-and-Language Navigation (VLN) empowers agents to associatetime-sequenced visual observations with corresponding instructions to makesequential decisions. However, generalization remains a persistent challenge,particularly when dealing with visually diverse scenes or transitioning fromsimulated environments to real-world deployment. In this paper, we address themismatch between human-centric instructions and quadruped robots with alow-height field of view, proposing a Ground-level Viewpoint Navigation (GVNav)approach to mitigate this issue. This work represents the first attempt tohighlight the generalization gap in VLN across varying heights of visualobservation in realistic robot deployments. Our approach leverages weightedhistorical observations as enriched spatiotemporal contexts for instructionfollowing, effectively managing feature collisions within cells by assigningappropriate weights to identical features across different viewpoints. Thisenables low-height robots to overcome challenges such as visual obstructionsand perceptual mismatches. Additionally, we transfer the connectivity graphfrom the HM3D and Gibson datasets as an extra resource to enhance spatialpriors and a more comprehensive representation of real-world scenarios, leadingto improved performance and generalizability of the waypoint predictor inreal-world environments. Extensive experiments demonstrate that ourGround-level Viewpoint Navigation (GVnav) approach significantly improvesperformance in both simulated environments and real-world deployments withquadruped robots.</description>
      <author>example@mail.com (Zerui Li, Gengze Zhou, Haodong Hong, Yanyan Shao, Wenqi Lyu, Yanyuan Qiao, Qi Wu)</author>
      <guid isPermaLink="false">2502.19024v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>A Reliable, Time-Predictable Heterogeneous SoC for AI-Enhanced Mixed-Criticality Edge Applications</title>
      <link>http://arxiv.org/abs/2502.18953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;下一代混合关键性的片上系统（SoCs）用于机器人、汽车和空间领域，需要执行增强型的传感器处理和控制工作负载，并确保在与非关键任务共享资源的同时可靠且时间可预测地运行关键任务。这些SoC必须适应小于2W功率包络。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述多维度挑战，在本文中提出了一种16nm、可靠的、时间可预测的异构SoC，该SoC集成了多个可编程加速器。&lt;h4&gt;方法&lt;/h4&gt;为了确保共享资源（如片上互连和内存系统）上的可预测访问，SoC集成了软件配置硬件IP，并在小于1.2W功率包络内工作。通过这种方式建立了关键应用执行时间的紧上界。&lt;h4&gt;主要发现&lt;/h4&gt;该研究提出了一种可靠的多核加速器来加快混合精度任务的关键AI处理，峰值性能达到304.9 GOPS，在能源效率方面达到1.6 TOPS/W。对于非关键、计算密集型浮点工作负载，则由双核向量集群加速，并达到了121.8 GFLOPS的性能以及1.1 TFLOPS/W和106.8 GFLOPS/mm²的能效。&lt;h4&gt;结论&lt;/h4&gt;提出的设计可以有效应对新一代混合关键性的SoC设计挑战，同时满足严格的能源效率要求。&lt;h4&gt;翻译&lt;/h4&gt;下一代用于机器人、汽车和空间领域的混合关键性系统级芯片（SoCs）需要执行增强型传感器处理和控制工作负载，并确保在与非关键任务共享资源的同时可靠且时间可预测地运行关键任务。为了应对这些多维挑战，本文提出了一种16nm的可靠的、时间可预测的异构SoC，该SoC集成了多个可编程加速器。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Next-generation mixed-criticality Systems-on-chip (SoCs) for robotics,automotive, and space must execute mixed-criticality AI-enhanced sensorprocessing and control workloads, ensuring reliable and time-predictableexecution of critical tasks sharing resources with non-critical tasks, whilealso fitting within a sub-2W power envelope. To tackle these multi-dimensionalchallenges, in this brief, we present a 16nm, reliable, time-predictableheterogeneous SoC with multiple programmable accelerators. Within a 1.2W powerenvelope, the SoC integrates software-configurable hardware IPs to ensurepredictable access to shared resources, such as the on-chip interconnect andmemory system, leading to tight upper bounds on execution times of criticalapplications. To accelerate mixed-precision mission-critical AI, the SoCintegrates a reliable multi-core accelerator achieving 304.9 GOPS peakperformance at 1.6 TOPS/W energy efficiency. Non-critical, compute-intensive,floating-point workloads are accelerated by a dual-core vector cluster,achieving 121.8 GFLOPS at 1.1 TFLOPS/W and 106.8 GFLOPS/mm2.</description>
      <author>example@mail.com (Angelo Garofalo, Alessandro Ottaviano, Matteo Perotti, Thomas Benz, Yvan Tortorella, Robert Balas, Michael Rogenmoser, Chi Zhang, Luca Bertaccini, Nils Wistoff, Maicol Ciani, Cyril Koenig, Mattia Sinigaglia, Luca Valente, Paul Scheffler, Manuel Eggimann, Matheus Cavalcante, Francesco Restuccia, Alessandro Biondi, Francesco Conti, Frank K. Gurkaynak, Davide Rossi, Luca Benini)</author>
      <guid isPermaLink="false">2502.18953v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Think on your feet: Seamless Transition between Human-like Locomotion in Response to Changing Commands</title>
      <link>http://arxiv.org/abs/2502.18901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 10 figures, accepted at the 2025 IEEE International  Conference on Robotics and Automation (ICRA 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新型的人类机器人运动学习方法，通过改进经典模仿学习技术，实现了更自然、更具适应性的步行行为。&lt;h4&gt;背景&lt;/h4&gt;人形机器人的训练相对容易进行特定行走技能的模拟，但难以从各种动作中学习并适应不断变化的指令。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以精准追踪运动指令、在不同动作间无缝过渡且能够掌握参考数据之外中间状态的人形机器人系统。&lt;h4&gt;方法&lt;/h4&gt;1. 使用Wasserstein散度标准（WGAN-div）提高泛化能力；2. 采用混合内部模型提供结构化的隐藏状态和速度估计，增强移动稳定性及环境适应性；3. 引入好奇心奖励机制促进探索。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法能够实现高度人类相似的步行行为，并且具有对不同速度需求的适应性、直接适用于未见动作的任务以及在模拟器与真实世界中跨地形的零样本转移能力。&lt;h4&gt;结论&lt;/h4&gt;通过各种机器人模型的仿真和广泛的真实世界实验验证了这些改进的有效性和适用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While it is relatively easier to train humanoid robots to mimic specificlocomotion skills, it is more challenging to learn from various motions andadhere to continuously changing commands. These robots must accurately trackmotion instructions, seamlessly transition between a variety of movements, andmaster intermediate motions not present in their reference data. In this work,we propose a novel approach that integrates human-like motion transfer withprecise velocity tracking by a series of improvements to classical imitationlearning. To enhance generalization, we employ the Wasserstein divergencecriterion (WGAN-div). Furthermore, a Hybrid Internal Model provides structuredestimates of hidden states and velocity to enhance mobile stability andenvironment adaptability, while a curiosity bonus fosters exploration. Ourcomprehensive method promises highly human-like locomotion that adapts tovarying velocity requirements, direct generalization to unseen motions andmultitasking, as well as zero-shot transfer to the simulator and the real worldacross different terrains. These advancements are validated through simulationsacross various robot models and extensive real-world experiments.</description>
      <author>example@mail.com (Huaxing Huang, Wenhao Cui, Tonghe Zhang, Shengtao Li, Jinchao Han, Bangyu Qin, Tianchu Zhang, Liang Zheng, Ziyang Tang, Chenxu Hu, Ning Yan, Jiahao Chen, Shipu Zhang, Zheyuan Jiang)</author>
      <guid isPermaLink="false">2502.18901v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Distributed Online Task Assignment via Inexact ADMM for unplanned online tasks and its Applications to Security</title>
      <link>http://arxiv.org/abs/2502.18893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE TCNS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;多机器人系统（MRS）中任务分配对于协调代理和确保使命成功以及保持整体系统安全性至关重要。本文提出了一种基于优化的分布式任务分配算法，该算法能够动态地为团队分配关键安全性和可选任务。&lt;h4&gt;背景&lt;/h4&gt;在多机器人系统的应用中，有效的任务分配不仅是为了协调代理并确保任务的成功完成，还为了维护整个系统的安全性。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以在计划偏离攻击下保持在线处理任务能力的全面框架，并确保MRS能够在不降低安全性的前提下有效地应对未预见的任务。&lt;h4&gt;方法&lt;/h4&gt;{'优化算法': '提出了一种基于优化的分布式任务分配算法，通过近似交替方向乘子法（ADMM）的方法将任务分配问题分解为可分离和不可分离的子问题，并使用投影梯度下降法处理不可分离的子问题', '安全分析框架': '制定一个全面的框架来评估在线任务的安全执行性以及机器人重新加入团队的时间和地点', '控制方法': '采用基于控制Lyapunov函数（CLF）的任务履行管理和基于控制障碍函数（CBF）的安全过滤器，以确保任务完成时的安全保障'}&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟实验展示了所提出的框架能够使MRS有效地响应未计划的在线任务同时保持安全保证。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和框架证明了在维护安全性的同时可以增强多机器人系统对意外任务处理的能力，具有重要的理论和实践意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In multi-robot system (MRS) applications, efficient task assignment isessential not only for coordinating agents and ensuring mission success butalso for maintaining overall system security. In this work, we first propose anoptimization-based distributed task assignment algorithm that dynamicallyassigns mandatory security-critical tasks and optional tasks among teams.Leveraging an inexact Alternating Direction Method of Multipliers (ADMM)-basedapproach, we decompose the task assignment problem into separable andnon-separable subproblems. The non-separable subproblems are transformed intoan inexact ADMM update by projected gradient descent, which can be performedthrough several communication steps within the team.  In the second part of this paper, we formulate a comprehensive framework thatenables MRS under plan-deviation attacks to handle online tasks withoutcompromising security. The process begins with a security analysis thatdetermines whether an online task can be executed securely by a robot and, ifso, the required time and location for the robot to rejoin the team. Next, theproposed task assignment algorithm is used to allocate security-related tasksand verified online tasks. Finally, task fulfillment is managed using a ControlLyapunov Function (CLF)-based controller, while security enforcement is ensuredthrough a Control Barrier Function (CBF)-based security filter. Throughsimulations, we demonstrate that the proposed framework allows MRS toeffectively respond to unplanned online tasks while maintaining securityguarantees.</description>
      <author>example@mail.com (Ziqi Yang, Roberto Tron)</author>
      <guid isPermaLink="false">2502.18893v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>RL-OGM-Parking: Lidar OGM-Based Hybrid Reinforcement Learning Planner for Autonomous Parking</title>
      <link>http://arxiv.org/abs/2502.18846v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;自动驾驶技术中的自主泊车研究提出了一种结合规则和学习的方法，通过使用混合策略（包括基于规则的Reeds-Shepp (RS) 规划器和基于学习的强化学习(RL)规划器）来解决传统方法在多变环境下的适应性问题。&lt;h4&gt;背景&lt;/h4&gt;当前自动驾驶泊车技术面临空间有限且复杂环境的问题，传统的规则基础算法难以应对各种不可预测条件，而学习型算法在不同场景中表现不一致。因此需要一种结合两者优点的混合策略。&lt;h4&gt;目的&lt;/h4&gt;为了提高自主停车系统在现实世界中的适应性和效率，本研究提出了一种新的方法来解决模拟到实际环境转换时存在的差距问题。&lt;h4&gt;方法&lt;/h4&gt;采用一个由基于规则的Reeds-Shepp (RS) 规划器和基于学习的强化学习(RL) 规划器组成的混合策略，并使用实时LiDAR占用网格图（OGM）表示来缩小模拟与现实之间的差距。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在仿真环境和真实世界场景中都优于纯规则基础方法和学习型方法。实际测试进一步验证了该方法的可行性和效率。&lt;h4&gt;结论&lt;/h4&gt;混合策略通过结合规则和学习的优点，在自主泊车技术的实际应用中展现出了良好的性能和适应性。&lt;h4&gt;翻译&lt;/h4&gt;自动驾驶泊车研究提出了一种新颖的方法来解决传统算法在复杂环境中的局限性，利用基于规则的Reeds-Shepp (RS) 和基于强化学习(RL) 的混合策略，并通过实时LiDAR占用网格图(OGM) 表示成功解决了从模拟到实际转换的问题。实验结果显示了该方法相较于单纯使用规则或学习方式在性能上的显著提升，同时确保了其在真实环境中的有效性与高效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous parking has become a critical application in automatic drivingresearch and development. Parking operations often suffer from limited spaceand complex environments, requiring accurate perception and precisemaneuvering. Traditional rule-based parking algorithms struggle to adapt todiverse and unpredictable conditions, while learning-based algorithms lackconsistent and stable performance in various scenarios. Therefore, a hybridapproach is necessary that combines the stability of rule-based methods and thegeneralizability of learning-based methods. Recently, reinforcement learning(RL) based policy has shown robust capability in planning tasks. However, thesimulation-to-reality (sim-to-real) transfer gap seriously blocks thereal-world deployment. To address these problems, we employ a hybrid policy,consisting of a rule-based Reeds-Shepp (RS) planner and a learning-basedreinforcement learning (RL) planner. A real-time LiDAR-based Occupancy Grid Map(OGM) representation is adopted to bridge the sim-to-real gap, leading thehybrid policy can be applied to real-world systems seamlessly. We conductedextensive experiments both in the simulation environment and real-worldscenarios, and the result demonstrates that the proposed method outperformspure rule-based and learning-based methods. The real-world experiment furthervalidates the feasibility and efficiency of the proposed method.</description>
      <author>example@mail.com (Zhitao Wang, Zhe Chen, Mingyang Jiang, Tong Qin, Ming Yang)</author>
      <guid isPermaLink="false">2502.18846v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Attention-Guided Integration of CLIP and SAM for Precise Object Masking in Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2502.18842v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2025 IEEE/SICE International Symposium on System Integration&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的流水线，旨在通过集成CLIP和SAM模型来提高机器人在便利商店产品掩码操作中的精度。&lt;h4&gt;背景&lt;/h4&gt;现有的技术在识别和处理特定环境下的对象时存在局限性，特别是在需要精确对象掩码的场合，如便利店的商品处理。现有模型（例如CLIP和SAM）虽然各自有效，但它们之间的协同作用尚未被充分探索。&lt;h4&gt;目的&lt;/h4&gt;目的是开发一种新的方法来提高基于图像和文本数据集的机器人操作精度，并利用这些改进后的技术来实现更精确、适应性强的产品操纵。&lt;h4&gt;方法&lt;/h4&gt;该研究采用了一个结合了CLIP（用于理解自然语言指令）和SAM（用于分割对象掩码）的集成框架，通过多模态数据处理优化模型性能。此外，还使用了基于梯度的方法以及定制的数据集进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;提出的流水线通过有效的组合现有技术并利用定制化训练策略显著提高了目标对象掩码生成的准确性。&lt;h4&gt;结论&lt;/h4&gt;这种新的方法不仅改进了现有系统的性能，而且为解决机器人在特定环境中操纵物体时遇到的问题提供了一个有价值的框架。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译已经完成，并且以结构化的JSON格式组织。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel pipeline to enhance the precision of objectmasking for robotic manipulation within the specific domain of masking productsin convenience stores. The approach integrates two advanced AI models, CLIP andSAM, focusing on their synergistic combination and the effective use ofmultimodal data (image and text). Emphasis is placed on utilizinggradient-based attention mechanisms and customized datasets to fine-tuneperformance. While CLIP, SAM, and Grad- CAM are established components, theirintegration within this structured pipeline represents a significantcontribution to the field. The resulting segmented masks, generated throughthis combined approach, can be effectively utilized as inputs for roboticsystems, enabling more precise and adaptive object manipulation in the contextof convenience store products.</description>
      <author>example@mail.com (Muhammad A. Muttaqien, Tomohiro Motoda, Ryo Hanai, Domae Yukiyasu)</author>
      <guid isPermaLink="false">2502.18842v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Learning Autonomy: Off-Road Navigation Enhanced by Human Input</title>
      <link>http://arxiv.org/abs/2502.18760v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种基于学习的本地规划器，用于解决无人车在复杂和不可预测的越野环境中的导航挑战。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶领域面临着应对不规则地面和意外障碍物等越野地形的独特挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够通过单目摄像头捕捉人类驾驶细微差别并快速适应各种越野条件的本地规划器。&lt;h4&gt;方法&lt;/h4&gt;利用少量的人类驾驶示范数据（5-10分钟）进行学习，以掌握在不同类型的地形中导航的能力。&lt;h4&gt;主要发现&lt;/h4&gt;该规划器显著减少了获取人类驾驶偏好的现实世界数据量，并能够将学到的行为直接应用于实际场景，无需手动微调。&lt;h4&gt;结论&lt;/h4&gt;展示了快速适应性和灵活性的越野自主驾驶技术的有效性。&lt;h4&gt;翻译&lt;/h4&gt;在自动驾驶领域，越野地形导航带来了一系列挑战，例如不可预测的地表和意外障碍物等。这项工作提出了一种基于学习的新本地规划器，通过直接从现实世界演示中捕捉人类驾驶特征来应对这些挑战，仅需使用单目摄像头即可实现。该规划器的主要特点是能够应对各种类型的复杂越野环境，并且具有快速的学习能力。凭借最少的人类示范数据（5-10分钟），它能迅速学习在广泛的越野条件下导航的方法。该本地规划器显著减少了从现实世界中获取人类驾驶偏好的需求，从而使规划器无需手动微调即可将学到的行为应用于实际场景中，展示了其在越野自主驾驶技术中的快速调整和适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the area of autonomous driving, navigating off-road terrains presents aunique set of challenges, from unpredictable surfaces like grass and dirt tounexpected obstacles such as bushes and puddles. In this work, we present anovel learning-based local planner that addresses these challenges by directlycapturing human driving nuances from real-world demonstrations using only amonocular camera. The key features of our planner are its ability to navigatein challenging off-road environments with various terrain types and its fastlearning capabilities. By utilizing minimal human demonstration data (5-10mins), it quickly learns to navigate in a wide array of off-road conditions.The local planner significantly reduces the real world data required to learnhuman driving preferences. This allows the planner to apply learned behaviorsto real-world scenarios without the need for manual fine-tuning, demonstratingquick adjustment and adaptability in off-road autonomous driving technology.</description>
      <author>example@mail.com (Akhil Nagariya, Dimitar Filev, Srikanth Saripalli, Gaurav Pandey)</author>
      <guid isPermaLink="false">2502.18760v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Simulating Safe Bite Transfer in Robot-Assisted Feeding with a Soft Head and Articulated Jaw</title>
      <link>http://arxiv.org/abs/2502.18749v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于物理模拟器（MuJoCo）的软体动力学建模的方法，用于研究机器人辅助喂食过程中的人机交互问题。&lt;h4&gt;背景&lt;/h4&gt;在机器人辅助喂食中确保安全舒适的咬取传递是一个挑战，因为这需要密切的物理人机互动。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过模拟器中的真实皮肤接触动态来系统地评估咬取转移参数（如插入深度和入口角度）对用户安全性和舒适性的影响。&lt;h4&gt;方法&lt;/h4&gt;该研究将一个灵活的人头模型与刚性骨架集成在一起，并考虑了内部动力学，以便由骨骼驱动的柔性模型能够被激活。并且利用软体皮肤接触动态在模拟中进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，在假设头部静止的情况下，直入直出策略可以减少力的作用并提高用户舒适度。&lt;h4&gt;结论&lt;/h4&gt;基于仿真的方法为实际世界实验提供了一种更安全、控制更好的替代方案。&lt;h4&gt;翻译&lt;/h4&gt;确保机器人辅助喂食过程中咬取传递的安全与舒适是一个挑战，因为这需要紧密的人机物理交互。本文提出一种新的建模方式，在基于物理学的模拟器（MuJoCo）中使用软体动力学来仿真这种互动。我们整合了一个可变形头部模型和一个刚性骨架，并考虑了内部动态机制，使灵活模型可以通过骨架进行驱动。在模拟中的真实皮肤接触动态被纳入，以便系统地评估咬取转移参数如插入深度和入口角度及其对用户安全性和舒适度的影响。我们的研究结果表明，在假设头部静止的情况下，采取直入直出策略可以减少作用力并提升用户体验的舒适性。这种基于仿真的方法为实际世界实验提供了一种更安全、控制更好的替代方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring safe and comfortable bite transfer during robot-assisted feeding ischallenging due to the close physical human-robot interaction required. Thispaper presents a novel approach to modeling physical human-robot interaction ina physics-based simulator (MuJoCo) using soft-body dynamics. We integrate aflexible head model with a rigid skeleton while accounting for internaldynamics, enabling the flexible model to be actuated by the skeleton.Incorporating realistic soft-skin contact dynamics in simulation allows forsystematically evaluating bite transfer parameters, such as insertion depth andentry angle, and their impact on user safety and comfort. Our findings suggestthat a straight-in-straight-out strategy minimizes forces and enhances usercomfort in robot-assisted feeding, assuming a static head. Thissimulation-based approach offers a safer and more controlled alternative toreal-world experimentation. Supplementary videos can be found at:https://tinyurl.com/224yh2kx.</description>
      <author>example@mail.com (Yi Heng San, Vasanthamaran Ravichandram, J-Anne Yow, Sherwin Stephen Chan, Yifan Wang, Wei Tech Ang)</author>
      <guid isPermaLink="false">2502.18749v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>QueryAdapter: Rapid Adaptation of Vision-Language Models in Response to Natural Language Queries</title>
      <link>http://arxiv.org/abs/2502.18735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'问题描述': '现有视觉-语言模型(VLM)在大规模互联网数据上训练，与机器人收集的原始图像流之间存在领域差异。当前适应策略需要定义一个封闭类集合，这不适用于必须响应多样化自然语言查询的机器人。', '解决方案': '提出QueryAdapter框架，该框架能够通过以前部署期间采集的未标记数据快速调整预训练VLM以应对特定查询。', '技术手段': '利用优化可学习提示令牌和主动选择用于训练的对象来生成适应后的模型，整个过程仅需几分钟。', '处理非相关对象方法': '提出使用与查询无关的对象标题作为负类标签，有助于在自适应过程中产生更校准的置信度分数。', '实验结果': 'ScanNet++数据集上的大量实验证明，QueryAdapter比现有的无监督VLM适配器和3D场景图方法显著提高了对象检索性能。', '泛化能力': '该方法对抽象功能查询和其他数据集（如Ego4D）表现出强大的泛化能力。'}&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了在大规模互联网训练的数据与机器人收集的原始图像之间存在的领域差异，以及现有适应策略面对自然语言多样性时的实际挑战。为解决这一问题，提出了QueryAdapter框架，利用以前未标记数据来调整VLM以应对特定查询，并通过优化可学习提示令牌和主动选择用于训练的对象实现快速调整。此外，提出了一种处理无关对象的新方法，并展示了在ScanNet++等数据集上的优越性能以及对其他类型查询的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A domain shift exists between the large-scale, internet data used to train aVision-Language Model (VLM) and the raw image streams collected by a robot.Existing adaptation strategies require the definition of a closed-set ofclasses, which is impractical for a robot that must respond to diverse naturallanguage queries. In response, we present QueryAdapter; a novel framework forrapidly adapting a pre-trained VLM in response to a natural language query.QueryAdapter leverages unlabelled data collected during previous deployments toalign VLM features with semantic classes related to the query. By optimisinglearnable prompt tokens and actively selecting objects for training, an adaptedmodel can be produced in a matter of minutes. We also explore how objectsunrelated to the query should be dealt with when using real-world data foradaptation. In turn, we propose the use of object captions as negative classlabels, helping to produce better calibrated confidence scores duringadaptation. Extensive experiments on ScanNet++ demonstrate that QueryAdaptersignificantly enhances object retrieval performance compared tostate-of-the-art unsupervised VLM adapters and 3D scene graph methods.Furthermore, the approach exhibits robust generalization to abstract affordancequeries and other datasets, such as Ego4D.</description>
      <author>example@mail.com (Nicolas Harvey Chapman, Feras Dayoub, Will Browne, Christopher Lehnert)</author>
      <guid isPermaLink="false">2502.18735v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Data-Driven Ship Dynamics Model: Enhancing Physics-Based Motion Prediction with Parameter Optimization</title>
      <link>http://arxiv.org/abs/2502.18696v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;船舶部署自主导航系统需要量身定制的精确运动预测模型。传统的基于物理的方法难以适应实际情况中的船体特定行为，而完全数据驱动的方法虽然能够提供具体性但缺乏解释性和在极端情况下的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;传统基于物理学的模型和纯粹的数据驱动方法各有优缺点：前者基于流体力学原理但在实际操作中无法准确反映船舶特性；后者则具备特定船只的行为预测能力，但是不具有可解释性和应对特殊情况的稳健性。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合物理建模与数据驱动优化参数的方法，利用这两种方法的优点，确保模型既具解释性又适应性强。&lt;h4&gt;方法&lt;/h4&gt;该研究引入了一种基于数据和物理学相结合的新模型，它包含了三自由度动力学、舵机力和螺旋桨推力等物理成分，并通过合成数据来微调阻力曲线及舵系数等参数。这种方法将领域知识融入到参数优化过程中，保证了所拟合的模型在物理一致性方面具有较高的性能。&lt;h4&gt;主要发现&lt;/h4&gt;对两艘集装箱船进行实验验证后发现：与基于传统海洋工程实践调整的基本物理学模型相比，采用数据驱动和物理学结合的方法，在预测精度和可靠性方面取得了显著改善。该模型能够捕捉不同条件下船舶特定的行为，并且其预测结果比基准物理模型分别提高了51.6%（船只A）和57.8%（船只B），一致性分别提升了72.36%（船只A）和89.67%（船只B）。&lt;h4&gt;结论&lt;/h4&gt;通过结合物理学方程与数据驱动参数优化，可以创建更准确、可靠且具有解释性的船舶运动预测模型。&lt;h4&gt;翻译&lt;/h4&gt;部署在船上的自主导航系统要求有适合特定船舶的精确运动预测模型。传统基于物理的方法虽然遵循流体力学原理，但在实际条件下难以捕捉到每艘船的独特行为模式；相比之下，纯粹的数据驱动方法提供了具体性但缺乏解释性和极端情况下的稳健性。本研究提出了一种结合物理学基础方程与数据驱动参数优化的新模型，该模型融合了两种方法的优势以确保可解性及适应性。此模型包含三自由度动力学、舵机力和螺旋桨推力等物理组件，并利用合成数据对阻力曲线和舵系数等参数进行优化调整，将领域知识嵌入到参数优化过程中，保持所拟合模型的物理一致性。验证该方法的有效性通过与基于传统海洋工程实践的基本物理模型进行了定性和定量比较，结果表明结合了数据驱动和物理学的新方法在预测精度及可靠性方面显著优于传统的基础物理模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The deployment of autonomous navigation systems on ships necessitatesaccurate motion prediction models tailored to individual vessels. Traditionalphysics-based models, while grounded in hydrodynamic principles, often fail toaccount for ship-specific behaviors under real-world conditions. Conversely,purely data-driven models offer specificity but lack interpretability androbustness in edge cases. This study proposes a data-driven physics-based modelthat integrates physics-based equations with data-driven parameteroptimization, leveraging the strengths of both approaches to ensureinterpretability and adaptability. The model incorporates physics-basedcomponents such as 3-DoF dynamics, rudder, and propeller forces, whileparameters such as resistance curve and rudder coefficients are optimized usingsynthetic data. By embedding domain knowledge into the parameter optimizationprocess, the fitted model maintains physical consistency. Validation of theapproach is realized with two container ships by comparing, both qualitativelyand quantitatively, predictions against ground-truth trajectories. The resultsdemonstrate significant improvements, in predictive accuracy and reliability,of the data-driven physics-based models over baseline physics-based modelstuned with traditional marine engineering practices. The fitted models captureship-specific behaviors in diverse conditions with their predictions being,51.6% (ship A) and 57.8% (ship B) more accurate, 72.36% (ship A) and 89.67%(ship B) more consistent.</description>
      <author>example@mail.com (Papandreou Christos, Mathioudakis Michail, Stouraitis Theodoros, Iatropoulos Petros, Nikitakis Antonios, Stavros Paschalakis, Konstantinos Kyriakopoulos)</author>
      <guid isPermaLink="false">2502.18696v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Voting-Based Task Assignment in Role-Playing Games</title>
      <link>http://arxiv.org/abs/2502.18690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at Dungeons, Neurons, and Dialogues: Social  Interaction Dynamics in Contextual Games Workshop at 20th Annual ACM/IEEE  International Conference on Human-Robot Interaction (HRI 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在角色扮演游戏（RPG）中，沉浸感至关重要，尤其是当游戏中的代理向玩家传达任务、提示或想法时。为了准确解读玩家的情感状态和上下文细节，需要一个基础的理解层次，这可以通过大型语言模型（LLM）来实现。&lt;h4&gt;目的&lt;/h4&gt;保持LLM在多变的上下文中持续聚焦，需要一种更为稳健的方法，如将LLM与专用的任务分配模型结合以在整个游戏过程中引导其性能。为应对这一需求，我们提出了基于投票的任务指派框架(VBTA)，该方法借鉴了人类在任务分配和完成过程中的推理。&lt;h4&gt;方法&lt;/h4&gt;VBTA给代理分配能力配置文件，并向任务描述提供任务说明，然后生成一个适配矩阵来量化代理人能力和任务要求之间的匹配度。通过利用六种不同的投票方式、预训练的LLM以及结合冲突解决搜索（CBS）进行路径规划，VBTA能够高效地识别并为每个任务指派最合适的代理。&lt;h4&gt;主要发现&lt;/h4&gt;与现有的仅专注于生成游戏单个方面的方法不同（如单一任务或战斗遭遇），我们的方法因其通用性而显示出在生成独特的战斗和叙事方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;通过结合LLM和先进的任务分配技术，可以显著提高游戏角色的沉浸感以及玩家体验的质量。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在角色扮演游戏中，沉浸度至关重要——尤其是在游戏中的代理向玩家传达任务、提示或想法时。为了准确地解读玩家的情绪状态和情境细微差别，需要一个基础的理解层面，这可以通过大型语言模型（LLM）来实现。然而，保持LLM在整个游戏过程中对多个上下文变化的关注，则需要一种更为稳健的方法，例如将LLM与专门的任务分配模型相结合以引导其性能表现。为应对这一需求，我们提出了基于投票的任务指派框架（VBTA），该方法受人类在任务分配和完成过程中的推理启发。VBTA给代理分配能力配置文件，并向任务描述提供任务说明，然后生成一个适配矩阵来量化代理人能力和任务要求之间的匹配度。通过利用六种不同的投票方式、预训练的LLM以及结合冲突解决搜索（CBS）进行路径规划，VBTA能够高效地识别并为每个任务指派最合适的代理。与现有的仅专注于生成游戏单个方面的方法不同（如单一任务或战斗遭遇），我们的方法因其通用性而显示出在生成独特的战斗和叙事方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In role-playing games (RPGs), the level of immersion is critical-especiallywhen an in-game agent conveys tasks, hints, or ideas to the player. For anagent to accurately interpret the player's emotional state and contextualnuances, a foundational level of understanding is required, which can beachieved using a Large Language Model (LLM). Maintaining the LLM's focus acrossmultiple context changes, however, necessitates a more robust approach, such asintegrating the LLM with a dedicated task allocation model to guide itsperformance throughout gameplay. In response to this need, we introduceVoting-Based Task Assignment (VBTA), a framework inspired by human reasoning intask allocation and completion. VBTA assigns capability profiles to agents andtask descriptions to tasks, then generates a suitability matrix that quantifiesthe alignment between an agent's abilities and a task's requirements.Leveraging six distinct voting methods, a pre-trained LLM, and integratingconflict-based search (CBS) for path planning, VBTA efficiently identifies andassigns the most suitable agent to each task. While existing approaches focuson generating individual aspects of gameplay, such as single quests, or combatencounters, our method shows promise when generating both unique combatencounters and narratives because of its generalizable nature.</description>
      <author>example@mail.com (Daniel Weiner, Raj Korpan)</author>
      <guid isPermaLink="false">2502.18690v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Rapidly Built Medical Crash Cart! Lessons Learned and Impacts on High-Stakes Team Collaboration in the Emergency Room</title>
      <link>http://arxiv.org/abs/2502.18688v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures, HRI conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;研究团队设计了一种能够在紧急情况下的临床环境中使用的医疗机器人急救车（MCCR），并对其进行了现场评估。&lt;h4&gt;背景&lt;/h4&gt;在高风险的应急场景中，设计能够无缝融入快速变化环境、促进有效沟通以及适应突发状况的机器人面临着独特的挑战。尽管远程操作机器人已经在诸如消防和太空探索等高风险领域得到了成功的应用，但自主支持团队协作的机器人仍然未被充分研究。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，研究者通过一个快速原型设计过程开发了一系列看似自主的机器人，旨在帮助急诊室中的临床团队。&lt;h4&gt;方法&lt;/h4&gt;将标准急救推车改造成医疗机器人急救车（MCCR），并进行了实地部署评估以检验其对团队工作量和使用性的影响。同时，还确定了失败分类，并在与卫生专业人员的合作中完善了MCCR的设计。&lt;h4&gt;主要发现&lt;/h4&gt;该研究推进了为高风险、时间敏感场景设计的机器人理解，并提供了有关有用的MCCR能力以及有效的人机协作考虑因素的见解。&lt;h4&gt;结论&lt;/h4&gt;通过公开发布MCCR教程，希望激发HRI研究人员探索为高风险团队工作设计机器人的可能性。&lt;h4&gt;翻译&lt;/h4&gt;设计用于支持紧急情况下的高水平合作工作的机器人面临着独特的挑战，包括无缝地融入快速变化的环境、促进成员之间的有效沟通以及适应突发状况。尽管远程操作机器人已经在消防和太空探索等关键领域得到了成功应用，但自主机器人在支援关键团队工作方面仍有待进一步研究。为了填补这一空白，研究人员通过一种快速原型设计方法开发了一系列看似自主的机器人来协助急诊室中的临床团队。将标准急救推车改造为医疗机器人急救推车（MCCR），并通过实地部署评估了其对团队工作量和易用性的影响，并根据与医疗卫生专业人员的合作反馈进一步完善了该设备的设计，确定了失效分类。这项研究推进了高风险、时间紧迫场景下机器人设计的理解，提供了有关有用的MCCR能力及有效人机协作的考虑因素的见解。通过公开发布MCCR教程，研究人员希望鼓励HRI（人类-机器人互动）领域的学者们探索为关键团队工作设计机器人的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Designing robots to support high-stakes teamwork in emergency settingspresents unique challenges, including seamless integration into fast-pacedenvironments, facilitating effective communication among team members, andadapting to rapidly changing situations. While teleoperated robots have beensuccessfully used in high-stakes domains such as firefighting and spaceexploration, autonomous robots that aid highs-takes teamwork remainunderexplored. To address this gap, we conducted a rapid prototyping process todevelop a series of seemingly autonomous robot designed to assist clinicalteams in the Emergency Room. We transformed a standard crash cart--which storesmedical equipment and emergency supplies into a medical robotic crash cart(MCCR). The MCCR was evaluated through field deployments to assess its impacton team workload and usability, identified taxonomies of failure, and refinedthe MCCR in collaboration with healthcare professionals. Our work advances theunderstanding of robot design for high-stakes, time-sensitive settings,providing insights into useful MCCR capabilities and considerations foreffective human-robot collaboration. By publicly disseminating our MCCRtutorial, we hope to encourage HRI researchers to explore the design of robotsfor high-stakes teamwork.</description>
      <author>example@mail.com (Angelique Taylor, Tauhid Tanjim, Michael Joseph Sack, Maia Hirsch, Kexin Cheng, Kevin Ching, Jonathan St. George, Thijs Roumen, Malte F. Jung, Hee Rin Lee)</author>
      <guid isPermaLink="false">2502.18688v1</guid>
      <pubDate>Thu, 27 Feb 2025 17:24:01 +0800</pubDate>
    </item>
    <item>
      <title>Primitive-Swarm: An Ultra-lightweight and Scalable Planner for Large-scale Aerial Swarms</title>
      <link>http://arxiv.org/abs/2502.16887v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE Transactions on Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Primitive-Swarm的轻量级且可扩展的大规模自主空中群规划器，采用分散式和异步重规划策略，并结合了基于可达性分析的时间最优路径参数化算法（TOPP-RA）生成的时间最优化和动态可行轨迹库。&lt;h4&gt;背景&lt;/h4&gt;大规模空中无人机集群操作在计算效率与可扩展性之间存在固有的矛盾。当前的方案难以同时实现高效的计算性能与广泛的应用范围。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于大规模自主空中无人机集群的有效规划器，旨在解决上述矛盾。&lt;h4&gt;方法&lt;/h4&gt;{'策略': '采用分散式和异步重规划策略', '轨迹库': '开发了一种时间最优化的运动原语库，并基于可达性分析生成这些原语', '碰撞检测机制': '通过与离散空间关联，建立快速碰撞检查机制以处理机器人障碍物冲突及机器人间的碰撞'}&lt;h4&gt;主要发现&lt;/h4&gt;{'性能优势': '在密集环境中实现了最短飞行时间和最小移动距离，并且计算时间少于1ms。', '可扩展性验证': '通过大规模模拟实验（最多涉及1000个无人机）验证了方案的实时性和可扩展性。', '实际应用可行性': '通过真实世界实验展示了该方法的实际可行性和鲁棒性'}&lt;h4&gt;结论&lt;/h4&gt;Primitive-Swarm规划器提供了一种新的解决大规模空中集群操作中计算效率与可扩展性的矛盾的方法，适用于各种复杂环境和应用场景。同时，公开源代码以促进社区合作。&lt;h4&gt;翻译&lt;/h4&gt;实现大规模的空中群是具有挑战性的，因为需要在计算效率和可扩展性之间进行权衡。本文介绍了一种名为Primitive-Swarm的轻量级且可扩展的规划器，旨在解决大规模自主飞行器集群的问题。该方法采用分散式和异步重规划策略，并使用一种基于可达性分析的时间最优路径参数化算法（TOPP-RA）来生成轨迹库。通过结合这些运动原语与离散空间来处理碰撞检测机制。最后，实验表明这种方案能够以极短计算时间在密集环境中实现最短的飞行时间和最小的距离移动，在大规模模拟和真实世界场景中均表现出优异性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving large-scale aerial swarms is challenging due to the inherentcontradictions in balancing computational efficiency and scalability. Thispaper introduces Primitive-Swarm, an ultra-lightweight and scalable plannerdesigned specifically for large-scale autonomous aerial swarms. The proposedapproach adopts a decentralized and asynchronous replanning strategy. Within itis a novel motion primitive library consisting of time-optimal and dynamicallyfeasible trajectories. They are generated utlizing a novel time-optimial pathparameterization algorithm based on reachability analysis (TOPP-RA). Then, arapid collision checking mechanism is developed by associating the motionprimitives with the discrete surrounding space according to conflicts. Byconsidering both spatial and temporal conflicts, the mechanism handlesrobot-obstacle and robot-robot collisions simultaneously. Then, during areplanning process, each robot selects the safe and minimum cost trajectoryfrom the library based on user-defined requirements. Both the time-optimalmotion primitive library and the occupancy information are computed offline,turning a time-consuming optimization problem into a linear-complexityselection problem. This enables the planner to comprehensively explore thenon-convex, discontinuous 3-D safe space filled with numerous obstacles androbots, effectively identifying the best hidden path. Benchmark comparisonsdemonstrate that our method achieves the shortest flight time and traveleddistance with a computation time of less than 1 ms in dense environments. Superlarge-scale swarm simulations, involving up to 1000 robots, running inreal-time, verify the scalability of our method. Real-world experimentsvalidate the feasibility and robustness of our approach. The code will bereleased to foster community collaboration.</description>
      <author>example@mail.com (Jialiang Hou, Xin Zhou, Neng Pan, Ang Li, Yuxiang Guan, Chao Xu, Zhongxue Gan, Fei Gao)</author>
      <guid isPermaLink="false">2502.16887v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
  <item>
      <title>Leveraging Large Language Models for Effective and Explainable Multi-Agent Credit Assignment</title>
      <link>http://arxiv.org/abs/2502.16863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages+Appendix, 6 Figures, AAMAS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的方法LLM-MCA，利用大型语言模型来评估多智能体系统中每个代理的行为对团队成功或失败的贡献。这种方法通过将信用分配问题转化为序列改进和归因的模式识别任务，解决了现有的集中训练-分散执行范式下的挑战。&lt;h4&gt;背景&lt;/h4&gt;最近的工作表明学习协作行为对于机器人实现共同目标的重要性，并且通常使用集中训练-分散执行的方法来学习这种合作行为。然而，这带来了如何评估每个代理的行为对团队成功或失败贡献的问题。&lt;h4&gt;目的&lt;/h4&gt;解决多智能体强化学习中的信用分配问题，通过结合人类手动审查代理行为的观察结果和大型语言模型在模式识别任务中表现出的人类水平性能的研究发现，提出一种新的方法来改进协作机器人系统的信用分配机制。&lt;h4&gt;方法&lt;/h4&gt;论文提出了LLM-MCA方法，利用中心化的大型语言模型奖励评论器根据场景中的每个代理的独特贡献对环境奖励进行数值分解，并基于此反馈更新代理的策略网络。此外还介绍了一种扩展版本LLM-TACA，其中大型语言模型批评者执行显式任务分配。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在各种基准测试中大大优于现有技术，包括层次化觅食、机器人仓库和新的太空世界基准测试，后者的环境包含了碰撞相关的安全性限制。这些方法还生成了带有每个时间步长代理奖励信息的大型轨迹数据集。&lt;h4&gt;结论&lt;/h4&gt;论文证明了利用大型语言模型进行信用分配可以提高多智能体系统的性能，并为未来的研究提供了一种全新的思路和潜在的应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work, spanning from autonomous vehicle coordination to in-spaceassembly, has shown the importance of learning collaborative behavior forenabling robots to achieve shared goals. A common approach for learning thiscooperative behavior is to utilize the centralized-trainingdecentralized-execution paradigm. However, this approach also introduces a newchallenge: how do we evaluate the contributions of each agent's actions to theoverall success or failure of the team. This credit assignment problem hasremained open, and has been extensively studied in the Multi-AgentReinforcement Learning literature. In fact, humans manually inspecting agentbehavior often generate better credit evaluations than existing methods. Wecombine this observation with recent works which show Large Language Modelsdemonstrate human-level performance at many pattern recognition tasks. Our keyidea is to reformulate credit assignment to the two pattern recognitionproblems of sequence improvement and attribution, which motivates our novelLLM-MCA method. Our approach utilizes a centralized LLM reward-critic whichnumerically decomposes the environment reward based on the individualizedcontribution of each agent in the scenario. We then update the agents' policynetworks based on this feedback. We also propose an extension LLM-TACA whereour LLM critic performs explicit task assignment by passing an intermediarygoal directly to each agent policy in the scenario. Both our methods faroutperform the state-of-the-art on a variety of benchmarks, includingLevel-Based Foraging, Robotic Warehouse, and our new Spaceworld benchmark whichincorporates collision-related safety constraints. As an artifact of ourmethods, we generate large trajectory datasets with each timestep annotatedwith per-agent reward information, as sampled from our LLM critics.</description>
      <author>example@mail.com (Kartik Nagpal, Dayi Dong, Jean-Baptiste Bouvier, Negar Mehr)</author>
      <guid isPermaLink="false">2502.16863v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Graph Augmentation for Cross Graph Domain Generalization</title>
      <link>http://arxiv.org/abs/2502.18188v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个新的图结构增强技术，用于跨图节点分类问题。通过去除可能影响GNN泛化能力的低权重边，并基于同分布节点特征生成不变结构，以帮助GNN捕捉不同图结构之间的本质不变信息。&lt;h4&gt;背景&lt;/h4&gt;跨图节点分类可以看作是图神经网络领域泛化的结构转移问题，而当前的研究主要集中在模型训练上，数据增强技术尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的图结构增强方法，以解决跨图领域的泛化问题，提高GNN在不同分布的数据集上的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;通过低权重边去除减少噪声干扰，并使用基于聚类的添加边策略生成不变结构。这两种技术共同提高了GNN对领域不变信息的保持和利用。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在跨域数据集上，这种方法能够提高图神经网络的泛化能力，并且比传统增强方法取得了更好的性能表现。&lt;h4&gt;结论&lt;/h4&gt;该工作证明了通过设计针对性的数据增强策略可以显著提升跨图节点分类任务中的模型泛化性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-graph node classification, utilizing the abundant labeled nodes fromone graph to help classify unlabeled nodes in another graph, can be viewed as adomain generalization problem of graph neural networks (GNNs) due to thestructure shift commonly appearing among various graphs. Nevertheless, currentendeavors for cross-graph node classification mainly focus on model training.Data augmentation approaches, a simple and easy-to-implement domaingeneralization technique, remain under-explored. In this paper, we develop anew graph structure augmentation for the crossgraph domain generalizationproblem. Specifically, low-weight edgedropping is applied to remove potentialnoise edges that may hinder the generalization ability of GNNs, stimulating theGNNs to capture the essential invariant information underlying differentstructures. Meanwhile, clustering-based edge-adding is proposed to generateinvariant structures based on the node features from the same distribution.Consequently, with these augmentation techniques, the GNNs can maintain thedomain invariant structure information that can improve the generalizationability. The experiments on out-ofdistribution citation network datasets verifyour method achieves state-of-the-art performance among conventionalaugmentations.</description>
      <author>example@mail.com (Guanzi Chen, Jiying Zhang, Yang Li)</author>
      <guid isPermaLink="false">2502.18188v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing DNA Foundation Models to Address Masking Inefficiencies</title>
      <link>http://arxiv.org/abs/2502.18405v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了在基因组序列建模中广泛采用的遮蔽语言模型（MLM）预训练目标存在的问题，并提出了一种基于掩码自动编码器框架的修改版编解码架构来解决BERT基础变换器中的效率低下问题。&lt;h4&gt;背景&lt;/h4&gt;遮蔽语言模型（MLM）在基因组序列建模中被广泛采用，但这种模型在从预训练到推断的应用过程中存在分布偏移的问题。即，在下游任务中没有[MASK]标记，导致编码器忽视了非[MASK]标记的编码。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于掩码自动编码框架的修改版编解码架构来解决MLM模型中的效率低下问题，并在基因组管道中进行验证。&lt;h4&gt;方法&lt;/h4&gt;利用遮蔽自编码器框架设计了一种新的BERT基础变换器，通过实验展示这种方法比因果模型和双向架构（使用MLM任务预训练）在闭集和开集分类任务上表现更好。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法可以显著提高基因组序列建模中特征提取的性能，并且在BIOSCAN-5M数据集中实现了明显的性能提升。&lt;h4&gt;结论&lt;/h4&gt;新的方法比传统的遮蔽语言模型（MLM）更有效，尤其是在不进行微调的情况下用于特征提取的应用场景。这种方法提供了一种解决现有问题的新途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked language modelling (MLM) as a pretraining objective has been widelyadopted in genomic sequence modelling. While pretrained models can successfullyserve as encoders for various downstream tasks, the distribution shift betweenpretraining and inference detrimentally impacts performance, as the pretrainingtask is to map [MASK] tokens to predictions, yet the [MASK] is absent duringdownstream applications. This means the encoder does not prioritize itsencodings of non-[MASK] tokens, and expends parameters and compute on work onlyrelevant to the MLM task, despite this being irrelevant at deployment time. Inthis work, we propose a modified encoder-decoder architecture based on themasked autoencoder framework, designed to address this inefficiency within aBERT-based transformer. We empirically show that the resulting mismatch isparticularly detrimental in genomic pipelines where models are often used forfeature extraction without fine-tuning. We evaluate our approach on theBIOSCAN-5M dataset, comprising over 2 million unique DNA barcodes. We achievesubstantial performance gains in both closed-world and open-worldclassification tasks when compared against causal models and bidirectionalarchitectures pretrained with MLM tasks.</description>
      <author>example@mail.com (Monireh Safari, Pablo Millan Arias, Scott C. Lowe, Lila Kari, Angel X. Chang, Graham W. Taylor)</author>
      <guid isPermaLink="false">2502.18405v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>ExPath: Towards Explaining Targeted Pathways for Biological Knowledge Bases</title>
      <link>http://arxiv.org/abs/2502.18026v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的路径推理框架ExPath，该框架能够将实验数据（特别是氨基酸序列）与生物网络数据库中的图分类相结合。&lt;h4&gt;背景&lt;/h4&gt;现有的生物学知识库提供细胞或有机体分子互作的功能通路。然而，识别更具体的目标通路，特别是在结合实验室数据时，仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的路径推理框架ExPath来解决这个挑战，并能够明确整合实验数据。&lt;h4&gt;方法&lt;/h4&gt;该框架由三个组成部分构成：1. 一个大型蛋白质语言模型pLM；2. PathMamba混合架构；3. PathExplainer子图学习模块。这些技术组合能处理氨基酸序列、捕捉局部和全局依赖关系并识别功能关键节点与边缘。&lt;h4&gt;主要发现&lt;/h4&gt;实验涉及了对301个生物网络的评价，表明通过ExPath推理出的路径具有生物学意义，并计划公开发布经过整理的生物网络数据集。&lt;h4&gt;结论&lt;/h4&gt;提出的框架在处理氨基酸序列和生成有意义的生物路径方面表现出了有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：生物知识库提供细胞或有机体分子互作的功能通路。然而，识别更具体的目标通路尤其当结合实验室数据时仍具有挑战性，并且通常需要下游生物学分析及专业知识。本文将此视为可解的图学习和解释任务并提出了一种新的路径推理框架ExPath，该框架明确整合实验数据（特别是氨基酸序列）来分类生物数据库中的各种图形网络。对分类更有贡献的链接可以被考虑为目标通路。技术上来说，ExPath由三个组件组成：1. 大型蛋白质语言模型pLM；2. PathMamba混合架构；3. PathExplainer子图学习模块。我们还提出了ML导向的生物学评价和新度量标准。涉及301个生物网络评估的实验表明路径通过ExPath推理保持生物意义，我们将很快公开发布整理过的301个生物网络数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Biological knowledge bases provide systemically functional pathways of cellsor organisms in terms of molecular interaction. However, recognizing moretargeted pathways, particularly when incorporating wet-lab experimental data,remains challenging and typically requires downstream biological analyses andexpertise. In this paper, we frame this challenge as a solvable graph learningand explaining task and propose a novel pathway inference framework, ExPath,that explicitly integrates experimental data, specifically amino acid sequences(AA-seqs), to classify various graphs (bio-networks) in biological databases.The links (representing pathways) that contribute more to classification can beconsidered as targeted pathways. Technically, ExPath comprises threecomponents: (1) a large protein language model (pLM) that encodes and embedsAA-seqs into graph, overcoming traditional obstacles in processing AA-seq data,such as BLAST; (2) PathMamba, a hybrid architecture combining graph neuralnetworks (GNNs) with state-space sequence modeling (Mamba) to capture bothlocal interactions and global pathway-level dependencies; and (3)PathExplainer, a subgraph learning module that identifies functionally criticalnodes and edges through trainable pathway masks. We also propose ML-orientedbiological evaluations and a new metric. The experiments involving 301bio-networks evaluations demonstrate that pathways inferred by ExPath maintainbiological meaningfulness. We will publicly release curated 301 bio-networkdata soon.</description>
      <author>example@mail.com (Rikuto Kotoge, Ziwei Yang, Zheng Chen, Yushun Dong, Yasuko Matsubara, Jimeng Sun, Yasushi Sakurai)</author>
      <guid isPermaLink="false">2502.18026v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>DenoMAE2.0: Improving Denoising Masked Autoencoders by Classifying Local Patches</title>
      <link>http://arxiv.org/abs/2502.18202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;我们介绍了DenoMAE2.0，这是一种增强的去噪掩码自动编码器，它结合了局部补丁分类目标和传统的重构损失来提高表示学习和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;与传统的Masked Autoencoders (MAE)不同，后者专注于重建丢失的输入，DenoMAE2.0引入了对未掩盖补丁的位置感知分类，使模型能够捕捉细微的局部特征同时保持全局一致性。这种方法在无线通信中的半监督学习特别有帮助。&lt;h4&gt;目的&lt;/h4&gt;针对噪声水平高和数据稀缺的问题，我们在广泛的信噪比(SNR)条件下进行了广泛的实验，从极低到中等条件，并在一个低数据环境中测试了DenoMAE2.0。&lt;h4&gt;方法&lt;/h4&gt;我们对调制信号分类进行了一系列表现于宽范围SNRs的实验，在极高噪声水平和较低的数据环境下验证模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，与前辈Deno-MAE和其他基准相比，DenoMAE2.0在去噪质量和下游分类准确度方面都有显著提高。具体而言，它比DenoMAE提高了1.1%的性能，并且在RadioML基准测试中的星座图分类中，相对于DenoMAE，分别取得了11.83%和16.55%的显着改进。&lt;h4&gt;结论&lt;/h4&gt;DenoMAE2.0通过增加位置感知补丁分类目标，在去噪质量和信号分类准确度方面超越了现有的模型，特别是在高噪声水平和低数据环境下的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce DenoMAE2.0, an enhanced denoising masked autoencoder thatintegrates a local patch classification objective alongside traditionalreconstruction loss to improve representation learning and robustness. Unlikeconventional Masked Autoencoders (MAE), which focus solely on reconstructingmissing inputs, DenoMAE2.0 introduces position-aware classification of unmaskedpatches, enabling the model to capture fine-grained local features whilemaintaining global coherence. This dual-objective approach is particularlybeneficial in semi-supervised learning for wireless communication, where highnoise levels and data scarcity pose significant challenges. We conductextensive experiments on modulation signal classification across a wide rangeof signal-to-noise ratios (SNRs), from extremely low to moderately highconditions and in a low data regime. Our results demonstrate that DenoMAE2.0surpasses its predecessor, Deno-MAE, and other baselines in both denoisingquality and downstream classification accuracy. DenoMAE2.0 achieves a 1.1%improvement over DenoMAE on our dataset and 11.83%, 16.55% significant improvedaccuracy gains on the RadioML benchmark, over DenoMAE, for constellationdiagram classification of modulation signals.</description>
      <author>example@mail.com (Atik Faysal, Mohammad Rostami, Taha Boushine, Reihaneh Gh. Roshan, Huaxia Wang, Nikhil Muralidhar)</author>
      <guid isPermaLink="false">2502.18202v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>OpenFly: A Versatile Toolchain and Large-scale Benchmark for Aerial Vision-Language Navigation</title>
      <link>http://arxiv.org/abs/2502.18041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;Vision-Language Navigation (VLN)旨在通过利用语言指令和视觉线索引导代理穿过环境，在具身人工智能领域扮演关键角色。尽管室内VLN已得到广泛研究，但室外空中VLN仍待深入探索。&lt;h4&gt;背景&lt;/h4&gt;现有问题在于户外空域范围广阔，数据收集更具挑战性，导致缺乏相应的基准测试。&lt;h4&gt;目的&lt;/h4&gt;为解决上述问题，我们提出OpenFly平台及其组成部分：多功能工具链和大规模基准。&lt;h4&gt;方法&lt;/h4&gt;{'开发自动化工具链': '用于自动获取点云、场景语义分割、飞行轨迹创建及指令生成', '构建数据集': '基于该工具链建立包括10万条轨迹在内的大规模空中VLN数据集，覆盖不同高度和长度的18个场景。使用多种渲染引擎（如Unreal Engine, GTA V）和高级技术生成视觉数据。', '模型开发': '提出OpenFly-Agent，一种关键帧感知的VLN模型，该模型以语言指令、当前观察结果及历史关键帧为输入，并直接输出飞行动作'}&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的分析与实验展示了我们平台及模型的优势&lt;h4&gt;结论&lt;/h4&gt;工具链、数据集和代码将开源。&lt;h4&gt;翻译&lt;/h4&gt;视觉-语言导航(VLN)旨在利用语言指令和视觉线索引导代理穿过环境，特别是在具身人工智能领域扮演关键角色。尽管室内VLN已经得到广泛研究，但户外空域的空中导航仍然有待深入探索。主要原因在于户外空间广阔，数据收集更为困难，导致缺乏相应的基准测试。为此我们提出了OpenFly平台，包括多功能工具链和大规模数据集。此平台旨在解决数据采集难题，并开发了关键帧感知模型以提高任务表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Navigation (VLN) aims to guide agents through an environmentby leveraging both language instructions and visual cues, playing a pivotalrole in embodied AI. Indoor VLN has been extensively studied, whereas outdooraerial VLN remains underexplored. The potential reason is that outdoor aerialview encompasses vast areas, making data collection more challenging, whichresults in a lack of benchmarks. To address this problem, we propose OpenFly, aplatform comprising a versatile toolchain and large-scale benchmark for aerialVLN. Firstly, we develop a highly automated toolchain for data collection,enabling automatic point cloud acquisition, scene semantic segmentation, flighttrajectory creation, and instruction generation. Secondly, based on thetoolchain, we construct a large-scale aerial VLN dataset with 100ktrajectories, covering diverse heights and lengths across 18 scenes. Thecorresponding visual data are generated using various rendering engines andadvanced techniques, including Unreal Engine, GTA V, Google Earth, and 3DGaussian Splatting (3D GS). All data exhibit high visual quality. Particularly,3D GS supports real-to-sim rendering, further enhancing the realism of thedataset. Thirdly, we propose OpenFly-Agent, a keyframe-aware VLN model, whichtakes language instructions, current observations, and historical keyframes asinput, and outputs flight actions directly. Extensive analyses and experimentsare conducted, showcasing the superiority of our OpenFly platform andOpenFly-Agent. The toolchain, dataset, and codes will be open-sourced.</description>
      <author>example@mail.com (Yunpeng Gao, Chenhui Li, Zhongrui You, Junli Liu, Zhen Li, Pengan Chen, Qizhi Chen, Zhonghan Tang, Liansheng Wang, Penghui Yang, Yiwen Tang, Yuhang Tang, Shuai Liang, Songyi Zhu, Ziqin Xiong, Yifei Su, Xinyi Ye, Jianan Li, Yan Ding, Dong Wang, Zhigang Wang, Bin Zhao, Xuelong Li)</author>
      <guid isPermaLink="false">2502.18041v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Escaping The Big Data Paradigm in Self-Supervised Representation Learning</title>
      <link>http://arxiv.org/abs/2502.18056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and implementation available at:  https://github.com/inescopresearch/scott&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文探讨了在图像自监督表示学习中是否可以摆脱大数据范式的限制。&lt;h4&gt;背景&lt;/h4&gt;大规模数据集和计算资源的需求成为视觉领域进展的障碍，特别是在数据稀缺的情况下。&lt;h4&gt;目的&lt;/h4&gt;旨在探究能否通过新的方法让视觉变换器能够在小规模数据下有效训练，而不依赖于外部的大规模预训练数据集。&lt;h4&gt;方法&lt;/h4&gt;{'SCOTT架构': '一种浅层标记化结构，与遮罩图像建模任务兼容，并向视觉变换器注入卷积先验偏置。', 'MIM-JEPA框架': '提出了一种联合嵌入预测架构，在潜在表示空间内运行以捕捉更多语义特征。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'模型性能': '冻结预训练的SCOTT模型在三个小规模、标准分辨率、细粒度数据集上显著优于全监督方法，并且与依赖大规模预训练、复杂图像增强和更大模型尺寸的最佳方法相当。', '资源节省': '证明了稳健的现成表示可以在有限的数据、计算和模型大小的情况下学习，为医疗影像或机器人等资源受限环境中的计算机应用开辟新道路。'}&lt;h4&gt;结论&lt;/h4&gt;挑战了数据量对于有效视觉表征学习不可或缺的传统观念，并提供了一条通向更可访问且包容性更强的进展的新路径。&lt;h4&gt;翻译&lt;/h4&gt;在视觉表示学习中，大规模的数据集和计算资源的需求已经成为一个主要障碍，尤其是在数据稀缺的情况下。本文探讨了一个关键问题：我们能否摆脱大数据范式，在自监督图像表征学习中实现这一点？为此引入了SCOTT（稀疏卷积标记器转换器），这是一种浅层结构，与遮罩图像建模任务兼容。此外，还提出了一种联合嵌入预测架构，用于在潜在表示空间内运行的遮罩图像建模框架（MIM-JEPA）。这些方法使ViTs能够在比传统所需的规模小得多的数据集上从头开始训练，无需依赖大规模外部预训练数据集。实验证明了该方法的有效性，并挑战了大数据量是视觉表征学习不可或缺的传统观念，为资源受限环境中的计算机应用提供了新路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The reliance on large-scale datasets and extensive computational resourceshas become a major barrier to advancing representation learning in vision,especially in data-scarce domains. In this paper, we address the criticalquestion: Can we escape the big data paradigm in self-supervised representationlearning from images? We introduce SCOTT (Sparse Convolutional Tokenizer forTransformers), a shallow tokenization architecture that is compatible withMasked Image Modeling (MIM) tasks. SCOTT injects convolutional inductive biasesinto Vision Transformers (ViTs), enhancing their efficacy in small-scale dataregimes. Alongside, we propose to train on a Joint-Embedding PredictiveArchitecture within a MIM framework (MIM-JEPA), operating in latentrepresentation space to capture more semantic features. Our approach enablesViTs to be trained from scratch on datasets orders of magnitude smaller thantraditionally required --without relying on massive external datasets forpretraining. We validate our method on three small-size, standard-resoultion,fine-grained datasets: Oxford Flowers-102, Oxford IIIT Pets-37, andImageNet-100. Despite the challenges of limited data and high intra-classsimilarity, frozen SCOTT models pretrained with MIM-JEPA significantlyoutperform fully supervised methods and achieve competitive results with SOTAapproaches that rely on large-scale pretraining, complex image augmentationsand bigger model sizes. By demonstrating that robust off-the-shelfrepresentations can be learned with limited data, compute, and model sizes, ourwork paves the way for computer applications in resource constrainedenvironments such as medical imaging or robotics. Our findings challenge theprevailing notion that vast amounts of data are indispensable for effectiverepresentation learning in vision, offering a new pathway toward moreaccessible and inclusive advancements in the field.</description>
      <author>example@mail.com (Carlos Vélez García, Miguel Cazorla, Jorge Pomares)</author>
      <guid isPermaLink="false">2502.18056v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>GCDance: Genre-Controlled 3D Full Body Dance Generation Driven By Music</title>
      <link>http://arxiv.org/abs/2502.18309v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;生成高质量的全身舞蹈序列是一项挑战，需要严格遵循特定风格的动作编排，并且产生的序列必须是物理上真实的并且与音乐的节拍和节奏精确同步。&lt;h4&gt;背景&lt;/h4&gt;现有的方法难以同时满足严格的风格特性和物理真实性以及精确的时间对齐需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种无分类器扩散框架GCDance，用于生成基于音乐和文本提示的特定类型的舞蹈动作。&lt;h4&gt;方法&lt;/h4&gt;{'特征提取': '结合高级预训练音乐基础模型特征与手工制作的多粒度特性融合来提取音乐特征', '时间步嵌入': '利用CLIP在每个时间步骤内有效地嵌入基于风格的文本提示表示'}&lt;h4&gt;主要发现&lt;/h4&gt;GCDance框架可以生成同一首音乐的不同舞蹈风格，同时确保与音乐节奏和旋律的一致性。&lt;h4&gt;结论&lt;/h4&gt;实验证明了GCDance在FineDance数据集上显著优于现有的最先进方法，并且在AIST++数据集上也取得了竞争性的结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating high-quality full-body dance sequences from music is a challengingtask as it requires strict adherence to genre-specific choreography. Moreover,the generated sequences must be both physically realistic and preciselysynchronized with the beats and rhythm of the music. To overcome thesechallenges, we propose GCDance, a classifier-free diffusion framework forgenerating genre-specific dance motions conditioned on both music and textualprompts. Specifically, our approach extracts music features by combininghigh-level pre-trained music foundation model features with hand-craftedfeatures for multi-granularity feature fusion. To achieve genrecontrollability, we leverage CLIP to efficiently embed genre-based textualprompt representations at each time step within our dance generation pipeline.Our GCDance framework can generate diverse dance styles from the same piece ofmusic while ensuring coherence with the rhythm and melody of the music.Extensive experimental results obtained on the FineDance dataset demonstratethat GCDance significantly outperforms the existing state-of-the-artapproaches, which also achieve competitive results on the AIST++ dataset. Ourablation and inference time analysis demonstrate that GCDance provides aneffective solution for high-quality music-driven dance generation.</description>
      <author>example@mail.com (Xinran Liu, Xu Dong, Diptesh Kanojia, Wenwu Wang, Zhenhua Feng)</author>
      <guid isPermaLink="false">2502.18309v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense Retrievers</title>
      <link>http://arxiv.org/abs/2502.18460v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DRAMA是一个利用大型语言模型训练较小的、具有泛化能力的密集检索器的框架。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在作为密集检索器时表现出色，但其庞大的参数规模带来了推理时间上的计算挑战，包括大规模语料库编码成本高和查询延迟增加的问题。相比之下，小型检索器虽然效率更高，但在有限监督数据下的泛化能力较弱。&lt;h4&gt;目的&lt;/h4&gt;介绍DRAMA框架，旨在利用大型语言模型训练出更小且具有更好泛化的密集检索器。&lt;h4&gt;方法&lt;/h4&gt;采用剪枝后的大型语言模型作为骨干，并在单一阶段对比学习设置下使用多样性的大型语言模型增强数据进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示，与传统的编码器基础的检索器相比，DRAMA提供了更好的多语言和长上下文处理能力，并在多种任务和语言上取得了强大的性能。&lt;h4&gt;结论&lt;/h4&gt;该框架展示了连接较小检索器训练与大规模语言模型进展之间的潜在价值，从而弥合了效率与泛化之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have demonstrated strong effectiveness androbustness while fine-tuned as dense retrievers. However, their large parametersize brings significant inference time computational challenges, including highencoding costs for large-scale corpora and increased query latency, limitingtheir practical deployment. While smaller retrievers offer better efficiency,they often fail to generalize effectively with limited supervised fine-tuningdata. In this work, we introduce DRAMA, a training framework that leveragesLLMs to train smaller generalizable dense retrievers. In particular, we adoptpruned LLMs as the backbone and train on diverse LLM-augmented data in asingle-stage contrastive learning setup. Experiments show that DRAMA offersbetter multilingual and long-context capabilities than traditionalencoder-based retrievers, and achieves strong performance across multiple tasksand languages. These highlight the potential of connecting the training ofsmaller retrievers with the growing advancements in LLMs, bridging the gapbetween efficiency and generalization.</description>
      <author>example@mail.com (Xueguang Ma, Xi Victoria Lin, Barlas Oguz, Jimmy Lin, Wen-tau Yih, Xilun Chen)</author>
      <guid isPermaLink="false">2502.18460v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies</title>
      <link>http://arxiv.org/abs/2502.18438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了ToMCAT框架，用于基于心智理论（Theory-of-Mind, ToM）生成合作型多智能体系统的轨迹。&lt;h4&gt;背景&lt;/h4&gt;在合作性任务中，了解队友的目标和行为对于团队性能至关重要。现有的方法通常无法动态适应环境变化和队友的行为。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合元学习机制和多代理去噪扩散模型的框架（ToMCAT），以生成条件于心智理论推理的轨迹，并实现在线规划系统来减少资源使用而不损害团队表现。&lt;h4&gt;方法&lt;/h4&gt;1. 使用元学习机制，进行关于队友潜在目标和未来行为的心智理论推理；2. 利用多代理去噪扩散模型，根据代理的目标以及通过ToM计算得出的队友特性生成计划。3. 实现在线规划系统，在检测到先前生成的计划与当前世界状态之间存在差异时动态采样新的轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;1. 动态再规划机制在减少资源使用的同时不损害团队性能方面至关重要；2. 关于环境和队友行为的近期观察结合心智理论推断对于生成适应性策略以应对队友变化至关重要，尤其是在没有关于它们的先前信息的情况下。&lt;h4&gt;结论&lt;/h4&gt;ToMCAT框架提供了一种有效的方法来实现动态的合作智能体系统，通过利用心智理论推理，提高了团队在未知环境中的适应性和效率。&lt;h4&gt;翻译&lt;/h4&gt;在这篇文章中我们提出了ToMCAT（合作型多代理团队的心智理论），这是一个新的基于心智理论生成轨迹的框架。它结合了一个元学习机制，该机制可以对队友潜在的目标和未来行为进行心智理论推理，以及一个多重代理去噪扩散模型，该模型可以根据智能体及其队友的特性来为智能体及其队友生成计划，这些特性是通过心智理论计算得出的。我们实施了一种在线规划系统，它会在检测到先前生成的计划与当前世界状态之间存在差异时从扩散模型中动态采样新的轨迹（重计划）。我们在模拟烹饪领域使用ToMCAT进行了多次实验。我们的结果强调了动态再规划机制在不牺牲团队性能的前提下减少资源使用的至关重要性。我们还表明，在一个时间段内，代理收集到的关于世界的近期观察和队友的行为结合心智理论推断对于生成适应性的策略以应对队友变化是至关重要的，尤其是在没有提供有关他们的先前信息的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper we present ToMCAT (Theory-of-Mind for Cooperative Agents inTeams), a new framework for generating ToM-conditioned trajectories. Itcombines a meta-learning mechanism, that performs ToM reasoning over teammates'underlying goals and future behavior, with a multiagent denoising-diffusionmodel, that generates plans for an agent and its teammates conditioned on boththe agent's goals and its teammates' characteristics, as computed via ToM. Weimplemented an online planning system that dynamically samples new trajectories(replans) from the diffusion model whenever it detects a divergence between apreviously generated plan and the current state of the world. We conductedseveral experiments using ToMCAT in a simulated cooking domain. Our resultshighlight the importance of the dynamic replanning mechanism in reducing theusage of resources without sacrificing team performance. We also show thatrecent observations about the world and teammates' behavior collected by anagent over the course of an episode combined with ToM inferences are crucial togenerate team-aware plans for dynamic adaptation to teammates, especially whenno prior information is provided about them.</description>
      <author>example@mail.com (Pedro Sequeira, Vidyasagar Sadhu, Melinda Gervasio)</author>
      <guid isPermaLink="false">2502.18438v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>GNN-XAR: A Graph Neural Network for Explainable Activity Recognition in Smart Homes</title>
      <link>http://arxiv.org/abs/2502.17999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is a preprint. Paper accepted for publication at the 21st EAI  International Conference on Mobile and Ubiquitous Systems: Computing,  Networking and Services (Mobiquitous)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文提出了一种新的基于图神经网络的可解释性模型，用于智能家居环境中的传感器数据驱动的人体活动识别。&lt;h4&gt;背景&lt;/h4&gt;在智能家居环境中，传感器数据驱动的人体活动识别对于医疗保健领域尤为重要。目前大多数现有方法依赖于深度学习模型，但这些模型通常不透明且难以理解。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的图神经网络，该网络不仅能够有效地进行人体活动识别，同时还能提供清晰、直观的解释以增强可解释性。&lt;h4&gt;方法&lt;/h4&gt;利用图神经网络（GNN）来提高传感器数据驱动的人体活动识别的效果，并在此基础上设计了首个为智能家居环境中的HAR任务专门定制的可解释模型。&lt;h4&gt;主要发现&lt;/h4&gt;提出的模型在两个公开数据集上的实验结果表明，它不仅提供了比现有最佳方法更好的解释性，同时还能略微提升人体活动的识别率。&lt;h4&gt;结论&lt;/h4&gt;这项工作是首次将图神经网络应用于传感器数据驱动的人体活动识别，并且通过提高可解释性和性能为该领域的研究开辟了新方向。&lt;h4&gt;翻译&lt;/h4&gt;基于传感器的人体活动识别（HAR）在智能家居环境中的应用至关重要，特别是在医疗保健领域。目前大多数现有方法依赖于深度学习模型如CNN或RNN，这些方法虽有效但输出的原理不透明。最近，提出了一种新的可解释性人工智能（XAI）方法来提供直观的解释。然而，现有的HAR方法并未专门设计为考虑可解释性。本文首次提出了一个专用于智能家居环境中的基于图神经网络的可解释模型，实验证明该方法在提高解释性和识别率方面优于现有最佳方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sensor-based Human Activity Recognition (HAR) in smart home environments iscrucial for several applications, especially in the healthcare domain. Themajority of the existing approaches leverage deep learning models. While theseapproaches are effective, the rationale behind their outputs is opaque.Recently, eXplainable Artificial Intelligence (XAI) approaches emerged toprovide intuitive explanations to the output of HAR models. To the best of ourknowledge, these approaches leverage classic deep models like CNNs or RNNs.Recently, Graph Neural Networks (GNNs) proved to be effective for sensor-basedHAR. However, existing approaches are not designed with explainability in mind.In this work, we propose the first explainable Graph Neural Network explicitlydesigned for smart home HAR. Our results on two public datasets show that thisapproach provides better explanations than state-of-the-art methods while alsoslightly improving the recognition rate.</description>
      <author>example@mail.com (Michele Fiori, Davide Mor, Gabriele Civitarese, Claudio Bettini)</author>
      <guid isPermaLink="false">2502.17999v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Conformal Prediction Under Generalized Covariate Shift with Posterior Drift</title>
      <link>http://arxiv.org/abs/2502.17744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to AISTATS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了一种新的转移学习环境下分类问题的解决策略，即在先验分布发生变化的情况下利用带有后验漂移的协变量偏移假设。&lt;h4&gt;背景&lt;/h4&gt;统计学习中收集足够多训练数据往往耗时费力或不切实际。转移学习通过从相关源领域获取知识来改善目标领域的学习性能成为一种有益的方法。&lt;h4&gt;目的&lt;/h4&gt;研究并提出在特定分布假设下的转移学习方法，特别是在后验漂移的协变量偏移设置下实现具有覆盖保证的目标分类。&lt;h4&gt;方法&lt;/h4&gt;提出了一个加权的符合预测分类器，在此框架下，每个数据实例将被赋予一组可能的标签，而不是单个标签。该方法利用了源领域和目标领域的样本。&lt;h4&gt;主要发现&lt;/h4&gt;理论研究表明提出的加权符合预测分类器具有良好的渐近性质；数值研究进一步展示了所提方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;该转移学习方法可以提高目标领域的分类性能，并提供了可靠的覆盖保证。&lt;h4&gt;翻译&lt;/h4&gt;在许多统计学习的实际应用中，收集足够的训练数据往往是昂贵、耗时或不现实的。在这种情况下，通过利用相关源领域中的知识来改进目标领域的学习表现的迁移学习方法更为有利。在此背景下，我们研究了一种特定类型的分类问题——符合预测，在新的分布假设下进行转移学习。基于符合预测框架的分类器为每个数据实例提供一组可能标签而不是单个标签，从而做出更谨慎且安全的决策。在转移学习中，我们考虑了一个广义的‘具有后验漂移的协变量偏移’设置，并提出了一种加权的符合预测分类器，在目标域内保证覆盖的同时利用源和目标样本。理论研究表明这种方法有良好的渐近性质，数值研究进一步证实了所提出的方案的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many real applications of statistical learning, collecting sufficientlymany training data is often expensive, time-consuming, or even unrealistic. Inthis case, a transfer learning approach, which aims to leverage knowledge froma related source domain to improve the learning performance in the targetdomain, is more beneficial. There have been many transfer learning methodsdeveloped under various distributional assumptions. In this article, we study aparticular type of classification problem, called conformal prediction, under anew distributional assumption for transfer learning. Classifiers under theconformal prediction framework predict a set of plausible labels instead of onesingle label for each data instance, affording a more cautious and saferdecision. We consider a generalization of the \textit{covariate shift withposterior drift} setting for transfer learning. Under this setting, we proposea weighted conformal classifier that leverages both the source and targetsamples, with a coverage guarantee in the target domain. Theoretical studiesdemonstrate favorable asymptotic properties. Numerical studies furtherillustrate the usefulness of the proposed method.</description>
      <author>example@mail.com (Baozhen Wang, Xingye Qiao)</author>
      <guid isPermaLink="false">2502.17744v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>VLM-E2E: Enhancing End-to-End Autonomous Driving with Multimodal Driver Attention Fusion</title>
      <link>http://arxiv.org/abs/2502.18042v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的基于视觉-语言模型的端到端框架VLM-E2E，旨在通过利用高级场景理解和推理能力来增强自动驾驶系统在复杂动态环境中的性能。&lt;h4&gt;背景&lt;/h4&gt;人类驾驶员可以灵活地处理复杂的驾驶情况，但当前的自动化系统难以复制这一技能，因为它们在将二维观察转换为三维空间时往往会丢失关键的语义信息。&lt;h4&gt;目的&lt;/h4&gt;利用视觉-语言模型的优势来增强自动驾驶系统的训练过程，并通过引入注意力线索和文本表示来改善其对环境的理解能力。&lt;h4&gt;方法&lt;/h4&gt;1. 采用VLM-E2E框架，将文本描述融入到鸟瞰图（BEV）特征中以提供语义监督；       2. 引入了BEV-Text可学习加权融合策略以解决多模态信息融合中的模式重要性不平衡问题。&lt;h4&gt;主要发现&lt;/h4&gt;通过关注注意力语义，该框架能够更好地模拟人类驾驶行为，并且在nuScenes数据集上的实验结果显示其性能优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;VLM-E2E提供了一种有效的方法来改善自动驾驶系统在复杂动态环境中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human drivers adeptly navigate complex scenarios by utilizing richattentional semantics, but the current autonomous systems struggle to replicatethis ability, as they often lose critical semantic information when converting2D observations into 3D space. In this sense, it hinders their effectivedeployment in dynamic and complex environments. Leveraging the superior sceneunderstanding and reasoning abilities of Vision-Language Models (VLMs), wepropose VLM-E2E, a novel framework that uses the VLMs to enhance training byproviding attentional cues. Our method integrates textual representations intoBird's-Eye-View (BEV) features for semantic supervision, which enables themodel to learn richer feature representations that explicitly capture thedriver's attentional semantics. By focusing on attentional semantics, VLM-E2Ebetter aligns with human-like driving behavior, which is critical fornavigating dynamic and complex environments. Furthermore, we introduce aBEV-Text learnable weighted fusion strategy to address the issue of modalityimportance imbalance in fusing multimodal information. This approachdynamically balances the contributions of BEV and text features, ensuring thatthe complementary information from visual and textual modality is effectivelyutilized. By explicitly addressing the imbalance in multimodal fusion, ourmethod facilitates a more holistic and robust representation of drivingenvironments. We evaluate VLM-E2E on the nuScenes dataset and demonstrate itssuperiority over state-of-the-art approaches, showcasing significantimprovements in performance.</description>
      <author>example@mail.com (Pei Liu, Haipeng Liu, Haichao Liu, Xin Liu, Jinxin Ni, Jun Ma)</author>
      <guid isPermaLink="false">2502.18042v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Deep-JGAC: End-to-End Deep Joint Geometry and Attribute Compression for Dense Colored Point Clouds</title>
      <link>http://arxiv.org/abs/2502.17939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种针对密集彩色点云的深度联合几何与属性压缩框架Deep-JGAC，旨在通过利用几何和属性之间的关联来实现高效的点云压缩。&lt;h4&gt;背景&lt;/h4&gt;彩色点云在3D视觉领域中已成为基础表示。然而，庞大的数据量使得有效的点云压缩技术变得迫切需要。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够同时处理几何和属性信息的深度联合压缩框架Deep-JGAC，以提高压缩效率并减少存储需求。&lt;h4&gt;方法&lt;/h4&gt;{'灵活的架构设计': '该框架包括可兼容学习或非学习基元的几何与属性子编码器。', '辅助深度几何编码器': '通过融合属性信息来增强几何潜在表示，并保持解码过程不变。', '属性信息融合模块AIFM': '在几何编码过程中引入，用于融合属性信息。', '优化的颜色化模块': '为解决压缩过程中几何和属性之间的不匹配问题而设计。此模块可以提高颜色化效果并降低计算复杂性。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'D1-PSNR性能指标': '相较于G-PCC、V-PCC、GRASP以及PCGCv2，Deep-JGAC分别平均减少了82.96%、36.46%、41.72%和31.16%的比特率。', 'MS-GraphSIM性能指标': '相较于G-PCC、V-PCC及IT-DL-PCC，Deep-JGAC分别平均降低了48.72%、14.67%与57.14%的比特率。', '编码和解码时间成本': '相比于V-PCC和IT-DL-PCC，该方法的编码/解码时间成本分别平均减少了94.29%/24.70%，以及96.75%/91.02%'}&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，Deep-JGAC框架在保持高质量几何重建的同时显著降低了比特率和计算复杂性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的完整中文翻译已包含于以上各个字段中&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Colored point cloud becomes a fundamental representation in the realm of 3Dvision. Effective Point Cloud Compression (PCC) is urgently needed due to hugeamount of data. In this paper, we propose an end-to-end Deep Joint Geometry andAttribute point cloud Compression (Deep-JGAC) framework for dense colored pointclouds, which exploits the correlation between the geometry and attribute forhigh compression efficiency. Firstly, we propose a flexible Deep-JGACframework, where the geometry and attribute sub-encoders are compatible toeither learning or non-learning based geometry and attribute encoders.Secondly, we propose an attribute-assisted deep geometry encoder that enhancesthe geometry latent representation with the help of attribute, where thegeometry decoding remains unchanged. Moreover, Attribute Information FusionModule (AIFM) is proposed to fuse attribute information in geometry coding.Thirdly, to solve the mismatch between the point cloud geometry and attributecaused by the geometry compression distortion, we present an optimizedre-colorization module to attach the attribute to the geometrically distortedpoint cloud for attribute coding. It enhances the colorization and lowers thecomputational complexity. Extensive experimental results demonstrate that interms of the geometry quality metric D1-PSNR, the proposed Deep-JGAC achievesan average of 82.96%, 36.46%, 41.72%, and 31.16% bit-rate reductions ascompared to the state-of-the-art G-PCC, V-PCC, GRASP, and PCGCv2, respectively.In terms of perceptual joint quality metric MS-GraphSIM, the proposed Deep-JGACachieves an average of 48.72%, 14.67%, and 57.14% bit-rate reductions comparedto the G-PCC, V-PCC, and IT-DL-PCC, respectively. The encoding/decoding timecosts are also reduced by 94.29%/24.70%, and 96.75%/91.02% on average ascompared with the V-PCC and IT-DL-PCC.</description>
      <author>example@mail.com (Yun Zhang, Zixi Guo, Linwei Zhu, C. -C. Jay Kuo)</author>
      <guid isPermaLink="false">2502.17939v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge-enhanced Multimodal ECG Representation Learning with Arbitrary-Lead Inputs</title>
      <link>http://arxiv.org/abs/2502.17900v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态心电图表示学习的最新进展集中在将ECG信号与配对的自由文本报告进行对齐。然而，由于医学语言的复杂性和依赖完整的12导联设置（这种配置在资源不足的情况下经常不可用），这种对齐仍然存在次优的问题。&lt;h4&gt;目的&lt;/h4&gt;提出了一种知识增强的多模态心电图表示学习框架K-MERL，以解决上述问题。该方法利用大型语言模型从自由文本报告中提取结构化知识，并使用一种导联感知的心电图编码器和动态导联掩蔽技术来适应任意输入的导联。&lt;h4&gt;方法&lt;/h4&gt;K-MERL框架通过结合大型语言模型的知识抽取能力和特定于ECG的编码机制，旨在提高心电图数据在不同临床场景下的表示学习效果。它能够处理非标准或不完整的导联设置，使得该方法更加适用于资源受限环境中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;K-MERL在六个外部心电图数据集上的评估中，在零样本分类和线性探针任务上均达到了最先进的性能，并且在部分导联的零样本分类任务上平均比现有方法提高了16%的AUC（曲线下面积）。&lt;h4&gt;结论&lt;/h4&gt;K-MERL框架为解决资源受限条件下心电图分析的问题提供了一个有效的解决方案，通过引入结构化医学知识和改进的心电图编码技术，显著提升了模型在关键临床指标上的表现。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译已经包含在上述各个分点中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in multimodal ECG representation learning center on aligningECG signals with paired free-text reports. However, suboptimal alignmentpersists due to the complexity of medical language and the reliance on a full12-lead setup, which is often unavailable in under-resourced settings. Totackle these issues, we propose **K-MERL**, a knowledge-enhanced multimodal ECGrepresentation learning framework. **K-MERL** leverages large language modelsto extract structured knowledge from free-text reports and employs a lead-awareECG encoder with dynamic lead masking to accommodate arbitrary lead inputs.Evaluations on six external ECG datasets show that **K-MERL** achievesstate-of-the-art performance in zero-shot classification and linear probingtasks, while delivering an average **16%** AUC improvement over existingmethods in partial-lead zero-shot classification.</description>
      <author>example@mail.com (Che Liu, Cheng Ouyang, Zhongwei Wan, Haozhe Wang, Wenjia Bai, Rossella Arcucci)</author>
      <guid isPermaLink="false">2502.17900v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>VVRec: Reconstruction Attacks on DL-based Volumetric Video Upstreaming via Latent Diffusion Model with Gamma Distribution</title>
      <link>http://arxiv.org/abs/2502.17880v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;随着3D体积视频应用的流行，如自动驾驶、虚拟现实和混合现实，开发者开始使用深度学习来压缩用于视频上传的点云。这种基于深度学习的方法在效率、失真率和硬件支持方面都优于传统的MPEG和JPEG等方法。然而，这些新的技术带来了隐私威胁，尤其是重建攻击能够从中间结果中恢复原始输入点云。&lt;h4&gt;背景&lt;/h4&gt;3D体积视频应用变得越来越受欢迎，开发者开始使用深度学习来压缩用于上传的点云数据，这种新型的技术相比传统的方法具有更高的效率和更好的硬件支持。但是这样的技术也带来了一些隐私威胁，比如针对中间结果进行重建攻击。&lt;h4&gt;目的&lt;/h4&gt;设计VVRec，这是一个基于深度学习的体积视频重建攻击方案，能够从拦截传输中的中间结果中恢复高质量的点云。&lt;h4&gt;方法&lt;/h4&gt;VVRec使用了四个精心设计并训练好的神经网络模块，结合最新的潜在扩散模型和Gamma分布以及细化算法来完成高精度的重建任务。&lt;h4&gt;主要发现&lt;/h4&gt;通过三个体积视频数据集对VVRec进行了评估。结果显示，VVRec实现了64.70dB的重建准确度，并且比基线方法减少了46.39%的失真率。&lt;h4&gt;结论&lt;/h4&gt;VVRec展示了其在点云重建中的优越性能，同时对于现有的防御措施提出了挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the popularity of 3D volumetric video applications, such as AutonomousDriving, Virtual Reality, and Mixed Reality, current developers have turned todeep learning for compressing volumetric video frames, i.e., point clouds forvideo upstreaming. The latest deep learning-based solutions offer higherefficiency, lower distortion, and better hardware support compared totraditional ones like MPEG and JPEG. However, privacy threats arise, especiallyreconstruction attacks targeting to recover the original input point cloud fromthe intermediate results. In this paper, we design VVRec, to the best of ourknowledge, which is the first targeting DL-based Volumetric VideoReconstruction attack scheme. VVRec demonstrates the ability to reconstructhigh-quality point clouds from intercepted transmission intermediate resultsusing four well-trained neural network modules we design. Leveraging the latestlatent diffusion models with Gamma distribution and a refinement algorithm,VVRec excels in reconstruction quality, color recovery, and surpasses existingdefenses. We evaluate VVRec using three volumetric video datasets. The resultsdemonstrate that VVRec achieves 64.70dB reconstruction accuracy, with animpressive 46.39% reduction of distortion over baselines.</description>
      <author>example@mail.com (Rui Lu, Bihai Zhang, Dan Wang)</author>
      <guid isPermaLink="false">2502.17880v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>BRIDO: Bringing Democratic Order to Abstractive Summarization</title>
      <link>http://arxiv.org/abs/2502.18342v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 1 figure; AAAI-25 Workshop on PDLM camera ready&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的方法来减少大型语言模型在抽象文本摘要中的hallucination（幻觉）问题。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型在许多任务中展现出巨大潜力，但幻觉问题仍然是其实用性的主要挑战之一。&lt;h4&gt;目的&lt;/h4&gt;通过减轻暴露偏差来解决抽象文本摘要中的幻觉问题。&lt;h4&gt;方法&lt;/h4&gt;该研究提出了一种使用对比学习的方法，该方法的目标是减少候选输出中的幻觉内容。这种方法假设包含幻觉的候选输出在一组候选输出中占少数，并且与其他候选人相比具有较低的相似性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在XSum和CNN/DM摘要数据集上，所提方法相对于现有模型BRIO分别提高了6.25%和3.82%的一致性G-Eval得分。&lt;h4&gt;结论&lt;/h4&gt;利用对比学习策略可以有效减少大型语言模型生成的文本中的幻觉问题。&lt;h4&gt;翻译&lt;/h4&gt;该论文旨在通过改进现有的针对暴露偏差的方法来减轻摘要中出现的不准确、无关或不一致的内容，进而提高大语言模型在抽象文本总结任务上的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hallucination refers to the inaccurate, irrelevant, and inconsistent textgenerated from large language models (LLMs). While the LLMs have shown greatpromise in a variety of tasks, the issue of hallucination still remains a majorchallenge for many practical uses. In this paper, we tackle the issue ofhallucination in abstract text summarization by mitigating exposure bias.Existing models targeted for exposure bias mitigation, namely BRIO, aim forbetter summarization quality in the ROUGE score. We propose a model that uses asimilar exposure bias mitigation strategy but with a goal that is aligned withless hallucination. We conjecture that among a group of candidate outputs, oneswith hallucinations will comprise the minority of the whole group. That is,candidates with less similarity with others will have a higher chance ofcontaining hallucinated content. Our method uses this aspect and utilizescontrastive learning, incentivizing candidates with high inter-candidate ROUGEscores. We performed experiments on the XSum and CNN/DM summarization datasets,and our method showed 6.25% and 3.82% improvement, respectively, on theconsistency G-Eval score over BRIO.</description>
      <author>example@mail.com (Junhyun Lee, Harshith Goka, Hyeonmok Ko)</author>
      <guid isPermaLink="false">2502.18342v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>A graph neural network-based multispectral-view learning model for diabetic macular ischemia detection from color fundus photographs</title>
      <link>http://arxiv.org/abs/2502.17886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图神经网络的多光谱视图学习模型，用于从彩色眼底照片中检测糖尿病性黄斑缺血(DMI)。&lt;h4&gt;背景&lt;/h4&gt;尽管通过人工智能(AI)结合彩色眼底照片(CFPs)在检测各种眼科疾病（包括糖尿病视网膜病变）方面得到了广泛应用，但CFPs在DMI检测中的应用尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于图神经网络的多光谱视图学习(GNN-MSVL)模型来从彩色眼底照片中检测糖尿病性黄斑缺血(DMI)。&lt;h4&gt;方法&lt;/h4&gt;该模型首先通过计算多光谱成像(CMI)重建24波长的眼底图像。使用ResNeXt101作为骨干网络进行多视图学习，提取重建图像的特征。此外，设计了一个带有定制跳跃连接策略的GNN以增强跨光谱关系。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在眼水平上的准确率为84.7%，AUROC为0.900（95% CI: 0.852-0.937），优于单纯基于CFPs训练的基本模型和人类专家，p值小于0.01。&lt;h4&gt;结论&lt;/h4&gt;AI驱动的彩色眼底照片分析有望用于早期、低成本地筛查DMI。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diabetic macular ischemia (DMI), marked by the loss of retinal capillaries inthe macular area, contributes to vision impairment in patients with diabetes.Although color fundus photographs (CFPs), combined with artificial intelligence(AI), have been extensively applied in detecting various eye diseases,including diabetic retinopathy (DR), their applications in detecting DMI remainunexplored, partly due to skepticism among ophthalmologists regarding itsfeasibility. In this study, we propose a graph neural network-basedmultispectral view learning (GNN-MSVL) model designed to detect DMI from CFPs.The model leverages higher spectral resolution to capture subtle changes infundus reflectance caused by ischemic tissue, enhancing sensitivity toDMI-related features. The proposed approach begins with computationalmultispectral imaging (CMI) to reconstruct 24-wavelength multispectral fundusimages from CFPs. ResNeXt101 is employed as the backbone for multi-viewlearning to extract features from the reconstructed images. Additionally, a GNNwith a customized jumper connection strategy is designed to enhancecross-spectral relationships, facilitating comprehensive and efficientmultispectral view learning. The study included a total of 1,078macula-centered CFPs from 1,078 eyes of 592 patients with diabetes, of which530 CFPs from 530 eyes of 300 patients were diagnosed with DMI. The modelachieved an accuracy of 84.7 percent and an area under the receiver operatingcharacteristic curve (AUROC) of 0.900 (95 percent CI: 0.852-0.937) oneye-level, outperforming both the baseline model trained from CFPs and humanexperts (p-values less than 0.01). These findings suggest that AI-based CFPanalysis holds promise for detecting DMI, contributing to its early andlow-cost screening.</description>
      <author>example@mail.com (Qinghua He, Hongyang Jiang, Danqi Fang, Dawei Yang, Truong X. Nguyen, Anran Ran, Clement C. Tham, Simon K. H. Szeto, Sobha Sivaprasad, Carol Y. Cheung)</author>
      <guid isPermaLink="false">2502.17886v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>On-device edge learning for IoT data streams: a survey</title>
      <link>http://arxiv.org/abs/2502.17788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;这篇文献综述探讨了在神经网络和决策树分类任务的智能环境中进行连续学习方法的研究。文章重点关注数据架构（批量 vs 流式）和网络容量（云端 vs 边缘设备）对TinyML算法设计的影响，这是因为自然到达的数据流是不受控制的。&lt;h4&gt;背景&lt;/h4&gt;部署深度学习模型在资源受限的边缘设备上面临挑战，包括灾难性遗忘、数据低效性和处理IoT表格数据于开放世界环境中的困难。决策树虽然更节省内存，但其表达能力有限，需要动态适应（如剪枝和元学习）来处理复杂模式和概念漂移。&lt;h4&gt;目的&lt;/h4&gt;强调为边缘应用定制多指标性能评估的重要性，这些评估不仅考虑输出基础的度量还考虑内部表示的度量。主要挑战在于将这些构建块整合到自适应在线系统中时需兼顾稳定性与可塑性、正向反向迁移以及模型收敛。&lt;h4&gt;方法&lt;/h4&gt;综述详细介绍了在资源受限边缘设备上部署深度学习所面临的各种挑战，并总结了决策树和神经网络各自的特点，指出需要结合多种技术来应对持续变化的环境。&lt;h4&gt;主要发现&lt;/h4&gt;连续学习对于边缘设备上的TinyML算法设计至关重要。尽管决策树具有内存效率优势但其灵活性不如神经网络。因此，在处理复杂模式时，可能需要额外的技术手段如动态适应和元学习机制。&lt;h4&gt;结论&lt;/h4&gt;为了有效利用资源受限的边缘设备进行深度学习任务，需开发新的连续学习方法来优化模型性能、减少灾难性遗忘，并提高对概念漂移的响应能力。&lt;h4&gt;翻译&lt;/h4&gt;此文献综述探索了在神经网络（NN）和决策树（DT）分类任务中的智能环境中为设备上训练而采用的连续学习方法。重点强调数据架构（批量 vs 流式）与网络容量（云端 vs 边缘）对TinyML算法设计的影响，这是由于自然到达的数据流是不受控制的。综述详细描述了在资源受限边缘设备上部署深度学习所面临的挑战，包括灾难性遗忘、数据低效性和处理IoT表格数据于开放世界环境中的困难。虽然决策树对于设备上的训练更节省内存，但其表达能力有限，需要动态适应（如剪枝和元学习）来处理复杂模式和概念漂移。强调了为边缘应用定制多指标性能评估的重要性，这些评估不仅考虑输出基础的度量还考虑内部表示的度量。关键挑战在于将这些构建块整合到自适应在线系统中时需兼顾稳定性与可塑性、正向反向迁移以及模型收敛。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This literature review explores continual learning methods for on-devicetraining in the context of neural networks (NNs) and decision trees (DTs) forclassification tasks on smart environments. We highlight key constraints, suchas data architecture (batch vs. stream) and network capacity (cloud vs. edge),which impact TinyML algorithm design, due to the uncontrolled natural arrivalof data streams. The survey details the challenges of deploying deep learnerson resource-constrained edge devices, including catastrophic forgetting, datainefficiency, and the difficulty of handling IoT tabular data in open-worldsettings. While decision trees are more memory-efficient for on-devicetraining, they are limited in expressiveness, requiring dynamic adaptations,like pruning and meta-learning, to handle complex patterns and concept drifts.We emphasize the importance of multi-criteria performance evaluation tailoredto edge applications, which assess both output-based and internalrepresentation metrics. The key challenge lies in integrating these buildingblocks into autonomous online systems, taking into account stability-plasticitytrade-offs, forward-backward transfer, and model convergence.</description>
      <author>example@mail.com (Afonso Lourenço, João Rodrigo, João Gama, Goreti Marreiros)</author>
      <guid isPermaLink="false">2502.17788v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Task-Agnostic Semantic Communication with Multimodal Foundation Models</title>
      <link>http://arxiv.org/abs/2502.18200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个无任务依赖的语义通信框架SemCLIP，基于对比语言-图像预训练模型CLIP。通过传输CLIP生成的图像令牌而非原始图像，在低带宽和挑战性信道条件下实现高效的语义通信。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数语义通信系统使用深度联合源信道编码来以目标导向的方式对特定任务进行语义编码，但这限制了它们在实际部署中的灵活性和泛化能力。多模态基础模型通过生成通用的语义令牌提供了潜在解决方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无任务依赖的语义通信框架SemCLIP，利用对比语言-图像预训练模型（CLIP）来实现高效、灵活且鲁棒的语义通信系统。&lt;h4&gt;方法&lt;/h4&gt;1. 使用CLIP生成的图像令牌代替原始图像进行传输。2. 设计了一种深度联合源信道编码方案以高效地对CLIP令牌进行编码。3. 在接收端设计了一个多模态传输感知提示学习机制，该机制根据传输质量调整提示，增强了系统的鲁棒性和信道适应性。&lt;h4&gt;主要发现&lt;/h4&gt;1. SemCLIP在低信号噪声比下实现了零样本准确性提高41%的性能优于基线模型。2. 与不同的图像传输方法相比，SemCLIP减少了超过50倍的带宽使用量。&lt;h4&gt;结论&lt;/h4&gt;通过利用基础模型和无任务依赖的方法，展示了语义通信系统在实际部署中的潜力，并为未来的通用、无任务依赖的语义通信解决方案开辟了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most existing semantic communication (SemCom) systems use deep jointsource-channel coding (DeepJSCC) to encode task-specific semantics in agoal-oriented manner. However, their reliance on predefined tasks and datasetssignificantly limits their flexibility and generalizability in practicaldeployments. Multi-modal foundation models provide a promising solution bygenerating universal semantic tokens. Inspired by this, we introduce SemCLIP, atask-agnostic SemCom framework leveraging the contrastive language-imagepre-training (CLIP) model. By transmitting CLIP-generated image tokens insteadof raw images, SemCLIP enables efficient semantic communications under lowbandwidth and challenging channel conditions, facilitating diverse downstreamtasks and zero-shot applications. Specifically, we propose a DeepJSCC schemefor efficient CLIP tokens encoding. To mitigate potential degradation caused bycompression and channel noise, a multi-modal transmission-aware prompt learningmechanism is designed at the receiver, which adapts prompts based ontransmission quality, enhancing system robustness and channel adaptability.Simulation results demonstrate that SemCLIP outperforms the baselines,achieving a $41\%$ improvement in zero-shot accuracy at a low signal-to-noiseratio. Meanwhile, SemCLIP reduces bandwidth usage by more than $50$-foldcompared to different image transmission methods, demonstrating the potentialof foundation models towards a generalized, task-agnostic SemCom solution.</description>
      <author>example@mail.com (Jiangjing Hu, Haotian Wu, Wenjing Zhang, Fengyu Wang, Wenjun Xu, Hui Gao, Deniz Gündüz)</author>
      <guid isPermaLink="false">2502.18200v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>UniGS: Unified Language-Image-3D Pretraining with Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2502.17860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的多模态预训练模型UniGS，通过将3D高斯点集（3D Gaussian Splatting）引入到文本、图像和三维空间的联合表示学习中，以改进当前基于离散点云的方法。&lt;h4&gt;背景&lt;/h4&gt;现有技术在多模态3D预训练方法取得了显著效果，但用离散点来表达复杂的3D世界存在局限性，无法完全捕捉到2D像素与3D结构之间的联系。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合了3D高斯点集的多模态预训练框架UniGS，以增强从文本、图像和三维空间中提取联合表示的能力。&lt;h4&gt;方法&lt;/h4&gt;首先通过3D高斯点集来建模彩色和透明度信息；接着利用预训练的视觉语言模型建立共享的视觉和文本空间，并引入一个新型模块（Gaussian-Aware Guidance）帮助学习更细粒度的3D表示，促进跨模式对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在不同数据集上进行广泛的实验表明，UniGS能够更好地捕捉到多模态信息之间的关系，尤其在零样本分类、基于文本驱动检索以及开放世界理解任务中表现优异，超越了之前的SOTA模型（如Uni3D）。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的建模方式和学习机制，UniGS提供了一种更为通用且更强的跨模态表示方法。&lt;h4&gt;翻译&lt;/h4&gt;最近在多模态3D预训练方法上的进展已经在文本、图像及点云联合表示的学习方面展现了有前景的效果。然而，仅采用点云作为三维表现形式未能充分捕捉到复杂三维世界的细微差别，并且在离散点与密集2D像素间存在明显的差距。为解决这一问题，我们提出了一种名为UniGS的方法，将3D高斯撒播（3D Gaussian Splatting）整合进多模态预训练中以提升三维表现形式。首先，我们使用3D GS表示来模拟三维世界作为一系列带有颜色和透明度的3D高斯分布体，在保留所有3D场景信息的同时建立起与2D图像之间的紧密联系。然后为了实现跨语言、图象及3D模态学习，UniGS从预训练的视觉文本模型开始，通过大量的现实世界图像-文本对建立共享的视觉和文字空间。接下来，UniGS采用一个三维编码器将优化后的3D GS与语言-图像表示进行一致化以获取统一多模态表示。为了帮助提取全球性的明确3D特征并通过更好的跨模式对齐实现这一点，我们进一步引入了新的Gaussian-Aware Guidance模块来引导学习细粒度的三维领域的表示。通过在Objaverse、ABO、MVImgNet和SUN RGBD数据集上进行广泛的零样本分类、基于文本驱动检索和开放世界理解任务实验，我们证明了UniGS在学习更通用和更好对齐的多模态表现形式方面的有效性。具体来说，在各种3D任务中，包括零样本分类（+9.36%）、基于文本驱动检索（+4.3%）和开放世界理解（+7.92%），与之前的SOTA模型Uni3D相比，UniGS取得了领先的成果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in multi-modal 3D pre-training methods have shownpromising efficacy in learning joint representations of text, images, and pointclouds. However, adopting point clouds as 3D representation fails to fullycapture the intricacies of the 3D world and exhibits a noticeable gap betweenthe discrete points and the dense 2D pixels of images. To tackle this issue, wepropose UniGS, integrating 3D Gaussian Splatting (3DGS) into multi-modalpre-training to enhance the 3D representation. We first rely on the 3DGSrepresentation to model the 3D world as a collection of 3D Gaussians with colorand opacity, incorporating all the information of the 3D scene whileestablishing a strong connection with 2D images. Then, to achieveLanguage-Image-3D pertaining, UniGS starts with a pre-trained vision-languagemodel to establish a shared visual and textual space through extensivereal-world image-text pairs. Subsequently, UniGS employs a 3D encoder to alignthe optimized 3DGS with the Language-Image representations to learn unifiedmulti-modal representations. To facilitate the extraction of global explicit 3Dfeatures by the 3D encoder and achieve better cross-modal alignment, weadditionally introduce a novel Gaussian-Aware Guidance module that guides thelearning of fine-grained representations of the 3D domain. Through extensiveexperiments across the Objaverse, ABO, MVImgNet and SUN RGBD datasets withzero-shot classification, text-driven retrieval and open-world understandingtasks, we demonstrate the effectiveness of UniGS in learning a more general andstronger aligned multi-modal representation. Specifically, UniGS achievesleading results across different 3D tasks with remarkable improvements overprevious SOTA, Uni3D, including on zero-shot classification (+9.36%),text-driven retrieval (+4.3%) and open-world understanding (+7.92%).</description>
      <author>example@mail.com (Haoyuan Li, Yanpeng Zhou, Tao Tang, Jifei Song, Yihan Zeng, Michael Kampffmeyer, Hang Xu, Xiaodan Liang)</author>
      <guid isPermaLink="false">2502.17860v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Progressive Local Alignment for Medical Multimodal Pre-training</title>
      <link>http://arxiv.org/abs/2502.18047v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Progressive Local Alignment Network (PLAN)的新型网络，用于提高医学图像与文本之间的局部对齐精度和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在医疗影像诊断中，准确地将文本描述与对应的像素区域进行配对是一个挑战，因为传统的硬边界方法存在不确定性，并且难以处理不规则结构。&lt;h4&gt;目的&lt;/h4&gt;通过设计一种基于对比学习的新方法来建立有意义的词-像素关系，并采用渐进式学习策略迭代优化这些关系，以提高软区域识别的效果并减少噪声干扰。&lt;h4&gt;方法&lt;/h4&gt;PLAN网络利用了对比学习和渐进式学习技术来改进局部对齐，提升医学图像与文本之间的关联性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PLAN在短语定位、图文检索、目标检测及零样本分类等多个任务上超越了现有的最佳方法，确立了一个新的基准。&lt;h4&gt;结论&lt;/h4&gt;PLAN网络为医疗图像和文本配准提供了一种有效的方法，提高了软区域识别的准确性和鲁棒性，并且能够抑制噪声干扰。&lt;h4&gt;翻译&lt;/h4&gt;本地医学影像与文字之间的对齐对于精确诊断至关重要，尽管由于缺乏自然局部配对和刚性区域识别方法的局限性而仍然具有挑战性。传统方法依赖于硬边界，引入了不确定性，然而医疗成像需要灵活处理不规则结构的软区域识别方法。为了克服这些挑战，我们提出了渐进式本地对齐网络（PLAN），它设计了一种基于对比学习的新局部对齐方法来建立有意义的文字-像素关系，并采用逐步学习策略迭代优化这些关系，以提高配准精度和鲁棒性。通过结合这些技术，PLAN有效地提高了软区域识别的效果同时抑制了噪声干扰。在多个医疗数据集上的大量实验表明，PLAN在短语定位、图像文字检索、目标检测和零样本分类任务上超越了最先进的方法，为医学影像-文本对齐设定了新的基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Local alignment between medical images and text is essential for accuratediagnosis, though it remains challenging due to the absence of natural localpairings and the limitations of rigid region recognition methods. Traditionalapproaches rely on hard boundaries, which introduce uncertainty, whereasmedical imaging demands flexible soft region recognition to handle irregularstructures. To overcome these challenges, we propose the Progressive LocalAlignment Network (PLAN), which designs a novel contrastive learning-basedapproach for local alignment to establish meaningful word-pixel relationshipsand introduces a progressive learning strategy to iteratively refine theserelationships, enhancing alignment precision and robustness. By combining thesetechniques, PLAN effectively improves soft region recognition while suppressingnoise interference. Extensive experiments on multiple medical datasetsdemonstrate that PLAN surpasses state-of-the-art methods in phrase grounding,image-text retrieval, object detection, and zero-shot classification, setting anew benchmark for medical image-text alignment.</description>
      <author>example@mail.com (Huimin Yan, Xian Yang, Liang Bai, Jiye Liang)</author>
      <guid isPermaLink="false">2502.18047v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Neural Graph Matching Improves Retrieval Augmented Generation in Molecular Machine Learning</title>
      <link>http://arxiv.org/abs/2502.17874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;分子机器学习由于几何深度学习的进步而变得流行。同时，检索增强生成已经成为语言模型中常用的一种基本原则方法。然而，如何将检索增强有效地整合到分子机器学习中仍然不清楚。&lt;h4&gt;背景&lt;/h4&gt;随着几何深度学习的发展，分子机器学习变得越来越受欢迎。与此同时，检索增强生成作为一种基本的方法被广泛应用于语言模型中。&lt;h4&gt;目的&lt;/h4&gt;探讨和实现一种有效的方式，即通过神经图匹配来改进分子机器学习中的查询-检索问题。&lt;h4&gt;方法&lt;/h4&gt;引入MARASON模型，该模型结合了神经图匹配技术以提升基于碎片化的神经网络性能。具体来说，它采用了噪声鲁棒的、端到端的神经网络来学习结构相似性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，MARASON模型在质量指标上取得了显著的进步，比最佳非检索方法高出28%（Top-1准确率从19%提升到了47%），并且超过了简单检索增强生成和传统图匹配方法的性能。&lt;h4&gt;结论&lt;/h4&gt;神经图匹配技术能够有效地帮助分子机器学习中更好地理解和应用结构对齐。MARASON模型在质量指标上展示了显著的优势，证明了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;分子机器学习随着几何深度学习的进步而日益受到关注。同时，检索增强生成已经成为语言模型中的标准方法之一。然而，在分子机器学习中如何最优地集成检索增强技术仍不清楚。图神经网络可以从巧妙的匹配中受益，以理解检索到的分子与查询分子之间的结构对齐情况。通过显式建模两个结构图形间的节点和边亲和度，并利用噪声鲁棒、端到端的神经网络来学习相似性指标，神经图匹配提供了一种有竞争力的解决方案。我们将这种方法应用于质谱模拟并提出MARASON模型——一种引入神经图匹配技术以增强基于碎片化的神经网络的新方法。实验结果表明我们的设计是有效的：MARASON在Top-1准确率上达到了47%，比现有的最佳非检索基准提高了28%（后者为19%）。此外，MARASON优于简单的检索增强生成方法和传统的图匹配方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular machine learning has gained popularity with the advancements ofgeometric deep learning. In parallel, retrieval-augmented generation has becomea principled approach commonly used with language models. However, the optimalintegration of retrieval augmentation into molecular machine learning remainsunclear. Graph neural networks stand to benefit from clever matching tounderstand the structural alignment of retrieved molecules to a query molecule.Neural graph matching offers a compelling solution by explicitly modeling nodeand edge affinities between two structural graphs while employing anoise-robust, end-to-end neural network to learn affinity metrics. We applythis approach to mass spectrum simulation and introduce MARASON, a novel modelthat incorporates neural graph matching to enhance a fragmentation-based neuralnetwork. Experimental results highlight the effectiveness of our design, withMARASON achieving 28% top-1 accuracy, a substantial improvement over thenon-retrieval state-of-the-art accuracy of 19%. Moreover, MARASON outperformsboth naive retrieval-augmented generation methods and traditional graphmatching approaches.</description>
      <author>example@mail.com (Runzhong Wang, Rui-Xi Wang, Mrunali Manjrekar, Connor W. Coley)</author>
      <guid isPermaLink="false">2502.17874v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Agnostic calculation of atomic free energies with the descriptor density of states</title>
      <link>http://arxiv.org/abs/2502.18191v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的评估原子系统振动自由能的方法，无需预先指定相互作用势函数。该方法通过描述符密度的熵来估计高维分布，并利用条件分数匹配进行计算。&lt;h4&gt;背景&lt;/h4&gt;传统的振动能量计算依赖于特定的相互作用势模型，限制了应用范围和灵活性。&lt;h4&gt;目的&lt;/h4&gt;开发一种通用评估框架，能够跨各种原子系统精确预测自由能而无需具体了解相互作用势函数。&lt;h4&gt;方法&lt;/h4&gt;通过描述符密度的状态，引入高维特征向量进行振动自由能估计；利用条件分数匹配技术避免复杂的高维积分计算。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够在微秒级别的CPU时间内返回可导的自由能预测值，并支持潜在参数变化的快速前向和反向传播。测试表明，所提出的模型独立估算器能够通过热力学集成法在多种金属相（如BCC, FCC 和 A15）中达到1-2 meV/原子精度。&lt;h4&gt;结论&lt;/h4&gt;该方法为不确定性量化、逆设计及其他计算科学领域的高维积分问题提供了有效的解决方案，并展示了其强大的应用潜力，特别是在液体系统和基础模型的微调方面。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新方法来评估无预先指定相互作用势函数条件下的原子体系振动自由能。我们的模型无关方式利用描述符——原子结构的高维特征向量。通过条件分数匹配准确估算高维密度熵，将相互作用势函数转化为在描述符特性上扩展的形式。我们展示了自由能作为描述符熵的Legendre-Fenchel共轭形式出现，从而避免了所有高维积分计算。该分数匹配活动比固定模型采样需要更少资源且高度并行化，使得耗时减少到几分钟，并通过张量压缩方案实现轻量化存储。我们的模型无关估计器能够以微秒级的CPU努力返回广泛的潜在参数范围内的可导自由能预测值，支持热力学模拟中快速传播势变差异及误差，这是进行不确定性量化和逆设计长期追求的目标。我们测试了在高同质温度下W、Mo和Fe的BCC、FCC和A15相模型中的预测结果与热力学集成计算的一致性，并通过反向传播微调非磁机器学习模型中Fe的alpha-gamma过渡温度，无需额外采样。讨论了该方法在液体体系及基础模型微调等领域的应用以及其他估计高维积分问题的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a new method to evaluate vibrational free energies of atomicsystems without a priori specification of an interatomic potential. Ourmodel-agnostic approach leverages descriptors, high-dimensional feature vectorsof atomic structure. The entropy of a high-dimensional density, the descriptordensity of states, is accurately estimated with conditional score matching.Casting interatomic potentials into a form extensive in descriptor features, weshow free energies emerge as the Legendre-Fenchel conjugate of the descriptorentropy, avoiding all high-dimensional integration. The score matching campaignrequires less resources than fixed-model sampling and is highly parallel,reducing wall time to a few minutes, with tensor compression schemes allowinglightweight storage. Our model-agnostic estimator returns differentiable freeenergy predictions over a broad range of potential parameters in microsecondsof CPU effort, allowing rapid forward and back propagation of potentialvariations through finite temperature simulations, long desired for uncertaintyquantification and inverse design. We test predictions against thermodynamicintegration calculations over a broad range of models for BCC, FCC and A15phases of W, Mo and Fe at high homologous temperatures. Predictions pass thestringent accuracy threshold of 1-2 meV/atom (1/40-1/20 kcal/mol) for phaseprediction with propagated score uncertainties robustly bounding errors. Wealso demonstrate targeted fine-tuning, reducing the alpha-gamma transitiontemperature in a non-magnetic machine learning model of Fe from 2030 K to 1063K through back-propagation, with no additional sampling. Applications toliquids and fine-tuning foundational models are discussed along with the manyproblems in computational science which estimate high-dimensional integrals.</description>
      <author>example@mail.com (Thomas D Swinburne, Clovis Lapointe, Mihai-Cosmin Marinica)</author>
      <guid isPermaLink="false">2502.18191v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>CPVis: Evidence-based Multimodal Learning Analytics for Evaluation in Collaborative Programming</title>
      <link>http://arxiv.org/abs/2502.17835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为CPVis的互动式可视化分析系统，旨在帮助编程教育中的教师评估学生的合作学习情况。&lt;h4&gt;背景&lt;/h4&gt;随着编程教育的发展，越来越多非计算机专业的学生开始接触编程。在这种背景下，协作编程成为了一种有效的教学方法，但也给教师带来了管理上的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够动态评估学生合作能力和个人表现的系统，以解决现有条件下教师难以全面监控和评价学生的问题。&lt;h4&gt;方法&lt;/h4&gt;收集实际场景中的多模态数据，并利用这些数据创建了一个基于花型编码的独特视觉表示形式。CPVis提供了时间序列视图来展示协作行为的发展趋势。&lt;h4&gt;主要发现&lt;/h4&gt;通过与两个基准系统的对比实验（N=22），参与者在使用CPVis时报告获得了更多的洞察力，感觉可视化更加直观，并且对其合作评估的自信度有所提高。&lt;h4&gt;结论&lt;/h4&gt;CPVis提供了一种有效的方法来帮助教师动态地评估学生的协作编程表现。这种系统有助于提高教育质量和学生的学习体验。&lt;h4&gt;翻译&lt;/h4&gt;随着编程教育变得越来越普及，越来越多非计算机专业的大学生开始学习编程。然而，在有限的教学时间和注意力范围内，教师难以监控和评估团队或个人的进步与成绩。为了解决这个问题，研究人员收集了现实世界中的多模态数据，并开发了一种名为CPVis的互动式可视化分析系统来动态地评价学生合作。该系统允许教师高效地评估小组和个人的表现，并采用新颖的花卉编码视觉表现形式展示成绩和提供基于时间视图捕捉协作行为的发展趋势。实验结果表明，用户在使用CPVis时获得了更多的洞见、发现可视化更为直观且增加了他们对评估信心。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As programming education becomes more widespread, many college students fromnon-computer science backgrounds begin learning programming. Collaborativeprogramming emerges as an effective method for instructors to support novicestudents in developing coding and teamwork abilities. However, due to limitedclass time and attention, instructors face challenges in monitoring andevaluating the progress and performance of groups or individuals. To addressthis issue, we collect multimodal data from real-world settings and developCPVis, an interactive visual analytics system designed to assess studentcollaboration dynamically. Specifically, CPVis enables instructors to evaluateboth group and individual performance efficiently. CPVis employs a novelflower-based visual encoding to represent performance and provides time-basedviews to capture the evolution of collaborative behaviors. A within-subjectexperiment (N=22), comparing CPVis with two baseline systems, reveals thatusers gain more insights, find the visualization more intuitive, and reportincreased confidence in their assessments of collaboration.</description>
      <author>example@mail.com (Gefei Zhang, Shenming Ji, Yicao Li, Jingwei Tang, Jihong Ding, Meng Xia, Guodao Sun, Ronghua Liang)</author>
      <guid isPermaLink="false">2502.17835v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning with Nasty Noise</title>
      <link>http://arxiv.org/abs/2502.17872v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文分析了在存在恶意干扰的情况下对比学习的理论极限，并通过PAC学习和VC维数分析建立了对抗设置下的样本复杂度上下界。&lt;h4&gt;背景&lt;/h4&gt;对比学习作为一种自监督表征学习的强大范式，其性能受到训练数据中可能存在恶意噪声的影响。这种情况下，训练样本可能会被修改或替换。&lt;h4&gt;目的&lt;/h4&gt;探讨并确定在存在恶意干扰的情况下，对比学习的理论极限以及样本复杂度的上界和下界。&lt;h4&gt;方法&lt;/h4&gt;利用PAC（概率可近似）学习框架和VC维数分析来建立对抗设置下的对比学习模型的样本复杂度上下限。此外还根据l2距离函数导出了基于数据相关的样本复杂度界限。&lt;h4&gt;主要发现&lt;/h4&gt;在存在恶意噪声的情况下，可以通过使用PAC理论和VC维数分析来限定对比学习算法的有效性及所需的最小训练样本数量。同时证明了特定条件下，利用l2距离作为损失函数可以优化样本选择过程。&lt;h4&gt;结论&lt;/h4&gt;通过理论分析揭示了对抗环境中对比学习面临的挑战，并提供了改进模型性能的新视角和方法论建议。&lt;h4&gt;翻译&lt;/h4&gt;对比学习已经成为自监督表示学习的强大范式。这项工作在存在恶意噪声的背景下探讨了对比学习的理论极限，其中对手可能会修改或替换训练样本。利用PAC学习以及VC维数分析，在对抗环境下建立了样本复杂度的上下界，并且基于l2距离函数推导出数据依赖性的样本复杂度界限。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has emerged as a powerful paradigm for self-supervisedrepresentation learning. This work analyzes the theoretical limits ofcontrastive learning under nasty noise, where an adversary modifies or replacestraining samples. Using PAC learning and VC-dimension analysis, lower and upperbounds on sample complexity in adversarial settings are established.Additionally, data-dependent sample complexity bounds based on the l2-distancefunction are derived.</description>
      <author>example@mail.com (Ziruo Zhao)</author>
      <guid isPermaLink="false">2502.17872v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Label-free Prediction of Vascular Connectivity in Perfused Microvascular Networks in vitro</title>
      <link>http://arxiv.org/abs/2502.17759v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的无标记血管连接网络（VC-Net），该网络可以连续监测和评估微血管的连通性，无需荧光标签即可进行测量。&lt;h4&gt;背景&lt;/h4&gt;现有的微血管连接评估方法大多依赖于可能引起生物相容性问题或干扰细胞正常生长过程的荧光标签。&lt;h4&gt;目的&lt;/h4&gt;开发一种无标记的方法来持续且非侵入地监测和评估组织培养中的微血管连通性，以改善器官体外培养及优化治疗策略。&lt;h4&gt;方法&lt;/h4&gt;使用Vessel Queue Contrastive Learning (VQCL) 方法结合解决样本量有限、类别特征不明显以及类别分布不平衡问题的算法构建VC-Net。通过采集不同培养条件下生成的微血管网络(MVN) 的显微图像作为训练数据集来验证该模型。&lt;h4&gt;主要发现&lt;/h4&gt;1. VC-Net 能够成功评估微血管连通性，其结果与荧光成像方法的结果无显著差异。2. VC-Net 成功区分了正常和肿瘤相关的MVN之间的连接特性。在与常规培养环境中的相比，肿瘤相关环境中培养的平均血管连接降低了30.8%，而未连接区域增加了37.3%。&lt;h4&gt;结论&lt;/h4&gt;这项研究为无标记、连续评估体外培养器官或肿瘤的血管化提供了一种新的途径。&lt;h4&gt;翻译&lt;/h4&gt;持续监测和原位评估微血管连通性在培养血管化的类器官以及优化治疗策略方面具有重要意义。然而，常用的血管连接评估方法严重依赖于荧光标签，这些荧光标签可能会引发生物相容性问题或干扰正常的细胞生长过程。为了解决这个问题，开发了一种无标记的血管连接网络（VC-Net），用于评估微血管连通性。通过在不同培养条件下采集体外培养的微血管网络（MVN）的显微图像作为训练数据集来验证该模型的有效性。VC-Net 使用了Vessel Queue Contrastive Learning (VQCL) 方法和处理样本量有限、类别特征不明显以及类别分布不平衡问题的算法。VC-Net 成功评估了血管连通性，并且结果与荧光成像方法的结果没有显著差异。此外，该研究还展示了VC-Net 能够区分正常和肿瘤相关的MVN之间的连接特性。相比常规培养环境中的情况，在肿瘤相关环境中培养的平均血管连接降低了30.8%，而未连接区域增加了37.3%。这项工作为体外无标记且连续地评估类器官或肿瘤的血管化提供了一种新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continuous monitoring and in-situ assessment of microvascular connectivityhave significant implications for culturing vascularized organoids andoptimizing the therapeutic strategies. However, commonly used methods forvascular connectivity assessment heavily rely on fluorescent labels that mayeither raise biocompatibility concerns or interrupt the normal cell growthprocess. To address this issue, a Vessel Connectivity Network (VC-Net) wasdeveloped for label-free assessment of vascular connectivity. To validate theVC-Net, microvascular networks (MVNs) were cultured in vitro and theirmicroscopic images were acquired at different culturing conditions as atraining dataset. The VC-Net employs a Vessel Queue Contrastive Learning (VQCL)method and a class imbalance algorithm to address the issues of limited samplesize, indistinctive class features and imbalanced class distribution in thedataset. The VC-Net successfully evaluated the vascular connectivity with nosignificant deviation from that by fluorescence imaging. In addition, theproposed VC-Net successfully differentiated the connectivity characteristicsbetween normal and tumor-related MVNs. In comparison with those cultured in theregular microenvironment, the averaged connectivity of MVNs cultured in thetumor-related microenvironment decreased by 30.8%, whereas the non-connectedarea increased by 37.3%. This study provides a new avenue for label-free andcontinuous assessment of organoid or tumor vascularization in vitro.</description>
      <author>example@mail.com (Liang Xu, Pengwu Song, Shilu Zhu, Yang Zhang, Ru Zhang, Zhiyuan Zheng, Qingdong Zhang, Jie Gao, Chen Han, Mingzhai Sun, Peng Yao, Min Ye, Ronald X. Xu)</author>
      <guid isPermaLink="false">2502.17759v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>CLEP-GAN: An Innovative Approach to Subject-Independent ECG Reconstruction from PPG Signals</title>
      <link>http://arxiv.org/abs/2502.17536v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项研究解决从PPG信号重建未见过的ECG信号的挑战，提出了一个使用ODE模型生成合成ECG-PPG数据的方法，并开发了一种基于对比学习、对抗学习和注意门控的新建模方法。&lt;h4&gt;背景&lt;/h4&gt;非侵入性心脏监测需要通过PPG信号重建ECG信号。现有的公共ECG-PPG数据集缺乏多样性，且收集过程中的噪音使得ECG的重建变得复杂。&lt;h4&gt;目的&lt;/h4&gt;提出一种增强训练多样性的合成ECG-PPG数据生成技术，并开发出一个独立于受试者的PPG到ECG的重建模型。&lt;h4&gt;方法&lt;/h4&gt;使用ODE模型来生成合成的ECG-PPG数据，为机器学习模型提供更多的训练样本。开发了一种结合对比学习、对抗学习和注意力门控的新建模方法。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型在未见过的数据上的重构效果与现有方法相当甚至更好，并强调了在模型训练和数据集扩充时考虑人口统计数据多样性的必要性。&lt;h4&gt;结论&lt;/h4&gt;通过引入新颖的数据生成技术和改进的重建模型，可以提高ECG信号从PPG信号的准确性。研究结果表明，应重视性别、年龄等人口统计学因素对重构精度的影响。&lt;h4&gt;翻译&lt;/h4&gt;这项研究解决了利用PPG信号重建未见过的ECG信号的问题，并提出了一种新的合成ECG-PPG数据生成技术以及一种新颖的独立于受试者的PPG到ECG的重建模型，该模型结合了对比学习、对抗学习和注意力门控。研究表明这些方法能够改善重构效果并强调考虑人口统计数据的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study addresses the challenge of reconstructing unseen ECG signals fromPPG signals, a critical task for non-invasive cardiac monitoring. Whilenumerous public ECG-PPG datasets are available, they lack the diversity seen inimage datasets, and data collection processes often introduce noise,complicating ECG reconstruction from PPG even with advanced machine learningmodels. To tackle these challenges, we first introduce a novel syntheticECG-PPG data generation technique using an ODE model to enhance trainingdiversity. Next, we develop a novel subject-independent PPG-to-ECGreconstruction model that integrates contrastive learning, adversariallearning, and attention gating, achieving results comparable to or evensurpassing existing approaches for unseen ECG reconstruction. Finally, weexamine factors such as sex and age that impact reconstruction accuracy,emphasizing the importance of considering demographic diversity during modeltraining and dataset augmentation.</description>
      <author>example@mail.com (Xiaoyan Li, Shixin Xu, Faisal Habib, Neda Aminnejad, Arvind Gupta, Huaxiong Huang)</author>
      <guid isPermaLink="false">2502.17536v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Learning Density Evolution from Snapshot Data</title>
      <link>http://arxiv.org/abs/2502.17738v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一种基于标量回归的分布估计方法，用于从噪声时间点云数据中估计随机过程的概率密度演化。&lt;h4&gt;背景动机&lt;/h4&gt;受学习静态快照数据中的动态结构启发，该研究旨在通过利用标量上的分布来解决这一问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于熵正则化的非参数极大似然估计器（E-NPMLE）以从带有噪声的时间点云中估计随机过程的概率密度演化。&lt;h4&gt;方法&lt;/h4&gt;提出了一个结合了最优传输理论中的熵正则化，用于平滑概率密度流。设计了一种无网格的粒子基座 KL散度梯度下降算法来有效计算 E-NPMLE。&lt;h4&gt;主要发现&lt;/h4&gt;E-NPMLE 方法在统计上具有几乎不依赖于维度的收敛率，并且展示出显著的数量级转换现象，这取决于快照数量和每快照样本大小。该方法的有效性和理论结果通过合成数据进行了验证。&lt;h4&gt;结论&lt;/h4&gt;研究为从带有噪声的任意维数观测中估计概率密度演化提供了理论上和技术上的贡献。&lt;h4&gt;翻译&lt;/h4&gt;受学习静态快照数据中的动态结构启发，本文提出了一种基于标量回归的方法来从其含噪时间点云中估计随机过程的概率密度演变。我们提出了一个熵正则化非参数极大似然估计器（E-NPMLE），利用最优传输的熵作为概率流的平滑正则化项。展示了 E-NPMLE 对于真实分布具有几乎不依赖于维度的统计收敛率，并且在快照数量和每快照样本大小上表现出显著的数量级转换现象。为了高效计算 E-NPMLE，设计了一种新的无网格粒子基座 KL 散度梯度下降算法并证明了其多项式迭代复杂性。此外，在合成数据上提供了数值证据来支持理论发现。这项工作为从带有噪声的观测中估计任意维度中的概率密度演化提供了理论上和技术上的贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by learning dynamical structures from static snapshot data, thispaper presents a distribution-on-scalar regression approach for estimating thedensity evolution of a stochastic process from its noisy temporal point clouds.We propose an entropy-regularized nonparametric maximum likelihood estimator(E-NPMLE), which leverages the entropic optimal transport as a smoothingregularizer for the density flow. We show that the E-NPMLE has almostdimension-free statistical rates of convergence to the ground truthdistributions, which exhibit a striking phase transition phenomenon in terms ofthe number of snapshots and per-snapshot sample size. To efficiently computethe E-NPMLE, we design a novel particle-based and grid-free coordinate KLdivergence gradient descent (CKLGD) algorithm and prove its polynomialiteration complexity. Moreover, we provide numerical evidence on synthetic datato support our theoretical findings. This work contributes to the theoreticalunderstanding and practical computation of estimating density evolution fromnoisy observations in arbitrary dimensions.</description>
      <author>example@mail.com (Rentian Yao, Atsushi Nitanda, Xiaohui Chen, Yun Yang)</author>
      <guid isPermaLink="false">2502.17738v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>PromptMID: Modal Invariant Descriptors Based on Diffusion and Vision Foundation Models for Optical-SAR Image Matching</title>
      <link>http://arxiv.org/abs/2502.18104v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了PromptMID，一种基于土地利用分类先验信息构建模态不变描述符的方法，用于光学和SAR图像匹配。&lt;h4&gt;背景&lt;/h4&gt;现有的学习型光-SAR图像匹配方法在特定场景中有效但泛化能力有限，难以适应实际应用需求。&lt;h4&gt;目的&lt;/h4&gt;通过有效利用基础模型来提升光-SAR图像匹配的泛化性能。&lt;h4&gt;方法&lt;/h4&gt;PromptMID使用预训练扩散模型和视觉基础模型提取多尺度模态不变特征，并设计了专门的特征聚合模块以跨不同粒度融合特征。&lt;h4&gt;主要发现&lt;/h4&gt;在来自四个不同地区的光学-SAR数据集上，PromptMID的表现优于现有的匹配方法，在已见和未见过的数据域中都表现出色且具有强大的跨领域泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究成功地提出了一个新颖的方法来解决光-SAR图像匹配中的模态不变性和泛化问题，并通过实验验证了其优越性。&lt;h4&gt;翻译&lt;/h4&gt;理想化的图像匹配目标是在未知环境下实现稳定和高效的性能。然而，许多现有的基于学习的光学-SAR图像匹配方法，在特定场景下虽然有效但泛化能力有限且难以适应实际应用需求。重复训练或微调匹配模型以解决领域差异不仅不够优雅而且会引入额外的计算开销和数据生产成本。近年来，通用基础模型在增强泛化方面显示了巨大的潜力，然而自然图像与遥感图像之间的视觉域差异使得它们直接应用于光学-SAR图像匹配存在挑战。因此，有效利用基础模型来改进光-SAR图像匹配的泛化能力仍然是一项挑战。为了应对上述挑战，我们提出了PromptMID，一种基于土地使用分类先验信息构建模态不变描述符的方法，用于光学和SAR图像匹配。PromptMID通过利用预训练扩散模型和视觉基础模型（VFMs）提取多尺度模态不变特征，并设计了专门的特征聚合模块以跨不同粒度融合特征。在来自四个不同地区的光学-SAR数据集上的广泛实验表明，PromptMID优于现有的匹配方法，在已见和未见过的数据域中都表现出色且具有强大的跨领域泛化能力。源代码将在https://github.com/HanNieWHU/PromptMID公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ideal goal of image matching is to achieve stable and efficientperformance in unseen domains. However, many existing learning-basedoptical-SAR image matching methods, despite their effectiveness in specificscenarios, exhibit limited generalization and struggle to adapt to practicalapplications. Repeatedly training or fine-tuning matching models to addressdomain differences is not only not elegant enough but also introducesadditional computational overhead and data production costs. In recent years,general foundation models have shown great potential for enhancinggeneralization. However, the disparity in visual domains between natural andremote sensing images poses challenges for their direct application. Therefore,effectively leveraging foundation models to improve the generalization ofoptical-SAR image matching remains challenge. To address the above challenges,we propose PromptMID, a novel approach that constructs modality-invariantdescriptors using text prompts based on land use classification as priorsinformation for optical and SAR image matching. PromptMID extracts multi-scalemodality-invariant features by leveraging pre-trained diffusion models andvisual foundation models (VFMs), while specially designed feature aggregationmodules effectively fuse features across different granularities. Extensiveexperiments on optical-SAR image datasets from four diverse regions demonstratethat PromptMID outperforms state-of-the-art matching methods, achievingsuperior results in both seen and unseen domains and exhibiting strongcross-domain generalization capabilities. The source code will be made publiclyavailable https://github.com/HanNieWHU/PromptMID.</description>
      <author>example@mail.com (Han Nie, Bin Luo, Jun Liu, Zhitao Fu, Huan Zhou, Shuo Zhang, Weixing Liu)</author>
      <guid isPermaLink="false">2502.18104v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Examining the Threat Landscape: Foundation Models and Model Stealing</title>
      <link>http://arxiv.org/abs/2502.18077v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to BMVC 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了基础模型（FMs）在计算机视觉中的安全性问题，特别是它们对模型窃取攻击的脆弱性。通过实验分析发现，基于这些模型的应用更容易遭受窃取攻击。&lt;h4&gt;背景&lt;/h4&gt;基础模型具备强大的适应能力，在少量或不进行微调的情况下可以应用于特定任务和领域。然而，这种灵活性也可能导致安全风险：攻击者可能利用预训练的基础模型来获取有价值的信息，并将其用于非法目的。&lt;h4&gt;目的&lt;/h4&gt;该研究旨在探讨基于基础模型的应用是否适合商业API部署，尤其是在考虑安全威胁的情况下。&lt;h4&gt;方法&lt;/h4&gt;作者通过实验分析了不同架构的模型在遭受窃取攻击时的表现。具体来说，他们比较了从基础模型微调后的模型与传统的视觉网络（如ResNets）之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;基于Vision Transformer的基础模型更容易受到模型窃取攻击；相比之下，ResNet-18这种传统架构则更加安全。例如，在使用CIFAR-10数据集进行训练时，通过基础模型微调的ViT-L/16模型（作为受害模型）与另一个ViT-L/16模型（作为盗窃者模型）之间有94.28%的一致性；而ResNet-18仅有73.20%。&lt;h4&gt;结论&lt;/h4&gt;论文指出，尽管基础模型在性能上有显著优势，但它们对商业API的部署构成了安全风险。因此，论文呼吁模型所有者注意潜在的安全隐患，并强调了采取强有力的防护措施的重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) for computer vision learn rich and robustrepresentations, enabling their adaptation to task/domain-specific deploymentswith little to no fine-tuning. However, we posit that the very same strengthcan make applications based on FMs vulnerable to model stealing attacks.Through empirical analysis, we reveal that models fine-tuned from FMs harborheightened susceptibility to model stealing, compared to conventional visionarchitectures like ResNets. We hypothesize that this behavior is due to thecomprehensive encoding of visual patterns and features learned by FMs duringpre-training, which are accessible to both the attacker and the victim. Wereport that an attacker is able to obtain 94.28% agreement (matched predictionswith victim) for a Vision Transformer based victim model (ViT-L/16) trained onCIFAR-10 dataset, compared to only 73.20% agreement for a ResNet-18 victim,when using ViT-L/16 as the thief model. We arguably show, for the first time,that utilizing FMs for downstream tasks may not be the best choice fordeployment in commercial APIs due to their susceptibility to model theft. Wethereby alert model owners towards the associated security risks, and highlightthe need for robust security measures to safeguard such models against theft.Code is available at https://github.com/rajankita/foundation_model_stealing.</description>
      <author>example@mail.com (Ankita Raj, Deepankar Varma, Chetan Arora)</author>
      <guid isPermaLink="false">2502.18077v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Are GNNs doomed by the topology of their input graph?</title>
      <link>http://arxiv.org/abs/2502.17739v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了图神经网络（GNNs）在处理图结构数据时的局限性及其输入图拓扑对模型性能的影响。通过引入$k$-hop相似性的概念来分析局部特征如何与消息传递方案交互，以产生有效的学习或不可避免的过度平滑现象。&lt;h4&gt;背景&lt;/h4&gt;图神经网络已经显示出在其领域内的显著成功，但人们对图结构数据对其行为影响的理解仍然不足。&lt;h4&gt;目的&lt;/h4&gt;研究GNN是否固有地受到其输入图拓扑结构的影响，并探讨局部特征与消息传递机制之间的相互作用如何影响全局表现。&lt;h4&gt;方法&lt;/h4&gt;引入了$k$-hop相似性的概念来衡量局部相似的邻域是否会导致一致的节点表示。通过实验验证这些假设和发现的实际意义。&lt;h4&gt;主要发现&lt;/h4&gt;研究揭示了图结构中的固有属性对于GNN的有效学习或不可避免的过度平滑现象有着重要影响，而不仅仅是基于局部特征的相似性。&lt;h4&gt;结论&lt;/h4&gt;该工作强调了理解输入图拓扑对GNN性能影响的重要性，并为进一步的研究提供了理论基础和实验依据。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已包含在内，无需额外翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated remarkable success in learningfrom graph-structured data. However, the influence of the input graph'stopology on GNN behavior remains poorly understood. In this work, we explorewhether GNNs are inherently limited by the structure of their input graphs,focusing on how local topological features interact with the message-passingscheme to produce global phenomena such as oversmoothing or expressiverepresentations. We introduce the concept of $k$-hop similarity and investigatewhether locally similar neighborhoods lead to consistent node representations.This interaction can result in either effective learning or inevitableoversmoothing, depending on the inherent properties of the graph. Our empiricalexperiments validate these insights, highlighting the practical implications ofgraph topology on GNN performance.</description>
      <author>example@mail.com (Amine Mohamed Aboussalah, Abdessalam Ed-dib)</author>
      <guid isPermaLink="false">2502.17739v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>AutoCas: Autoregressive Cascade Predictor in Social Networks via Large Language Models</title>
      <link>http://arxiv.org/abs/2502.18040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种基于大型语言模型（LLM）的新型信息传播预测模型AutoCas，该模型针对信息传播数据的特点进行了专门优化。&lt;h4&gt;背景&lt;/h4&gt;信息传播机制、用户行为以及时间活动模式存在显著多样性，现有的模型难以适应这种变化。同时，可用的信息传播数据量相对有限。&lt;h4&gt;目的&lt;/h4&gt;构建一个能够利用大型语言模型的架构优势进行信息传播预测的基础模型，并提高其在流行度预测方面的性能。&lt;h4&gt;方法&lt;/h4&gt;将信息传播数据分词以匹配序列建模原则；重新定义信息传播扩散为自回归建模任务，以充分利用LLM的架构特点；引入提示学习技术增强LLM与信息传播预测之间的协同作用。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AutoCas在信息流流行度预测方面显著优于基线模型，并且展示了源自LLMs的可扩展行为。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的自回归信息传播预测器（AutoCas），通过专门适应大型语言模型的优势和挑战来提高信息传播流行度预测的效果。&lt;h4&gt;翻译&lt;/h4&gt;在信息级联中进行受欢迎程度预测是社会计算中的重要任务，广泛应用于病毒式营销、错误信息控制以及内容推荐。然而，信息传播机制、用户行为及时间活动模式显示出了显著的多样性，这要求一种能够适应这些变化的基础模型。同时，在用于训练大型语言模型（LLMs）的巨大数据集面前，可用的信息级联数据量相对有限。最近的研究表明，通过利用不同时间序列领域之间的共同点来应用LLM进行时间序列预测是可行的。基于这一洞察，我们引入了自回归信息级联预测器（AutoCas），这是一种专门用于级联流行度预测、由大型语言模型增强的模型。与自然语言序列相比，级联数据具有复杂的本地拓扑结构、传播上下文和不断变化的动力学特点，这需要为有效的LLM集成进行专门适应。为了应对这些挑战，我们首先将级联数据分词以使其符合序列建模原则。接下来，我们将信息传播扩散重新定义为自回归建模任务，以便充分利用LLMs的架构优势。此外，在常规方法之外，我们进一步引入了提示学习来增强LLM和级联预测之间的协同作用。广泛的实验表明，AutoCas在级联流行度预测方面显著优于基线模型，并且展示了源自LLMs的可扩展行为。代码可在以下仓库中获取：https://anonymous.4open.science/r/AutoCas-85C6&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Popularity prediction in information cascades plays a crucial role in socialcomputing, with broad applications in viral marketing, misinformation control,and content recommendation. However, information propagation mechanisms, userbehavior, and temporal activity patterns exhibit significant diversity,necessitating a foundational model capable of adapting to such variations. Atthe same time, the amount of available cascade data remains relatively limitedcompared to the vast datasets used for training large language models (LLMs).Recent studies have demonstrated the feasibility of leveraging LLMs fortime-series prediction by exploiting commonalities across different time-seriesdomains. Building on this insight, we introduce the Autoregressive InformationCascade Predictor (AutoCas), an LLM-enhanced model designed specifically forcascade popularity prediction. Unlike natural language sequences, cascade datais characterized by complex local topologies, diffusion contexts, and evolvingdynamics, requiring specialized adaptations for effective LLM integration. Toaddress these challenges, we first tokenize cascade data to align it withsequence modeling principles. Next, we reformulate cascade diffusion as anautoregressive modeling task to fully harness the architectural strengths ofLLMs. Beyond conventional approaches, we further introduce prompt learning toenhance the synergy between LLMs and cascade prediction. Extensive experimentsdemonstrate that AutoCas significantly outperforms baseline models in cascadepopularity prediction while exhibiting scaling behavior inherited from LLMs.Code is available at this repository:https://anonymous.4open.science/r/AutoCas-85C6</description>
      <author>example@mail.com (Yuhao Zheng, Chenghua Gong, Rui Sun, Juyuan Zhang, Liming Pan, Linyuan Lv)</author>
      <guid isPermaLink="false">2502.18040v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Learning Decentralized Swarms Using Rotation Equivariant Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.17612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的去中心化控制方法，通过在图神经网络控制器中强制执行旋转等方性和平移不变性对称性，以优化群集的凝聚和一致性。&lt;h4&gt;背景&lt;/h4&gt;没有集中式控制的情况下协调代理以实现集体目标是具有挑战性的，尤其是在控制自主车队和使用传感器网络进行监控与侦察的应用场景中。现有方法受到自然界自我组织现象（如鸟群行为）启发，但这些去中心化控制器难以保持群体的凝聚性。&lt;h4&gt;目的&lt;/h4&gt;通过引入对称性约束在图神经网络架构中开发出一种新的去中心化控制器，以提高其维持群集凝聚力的能力以及泛化性能。&lt;h4&gt;方法&lt;/h4&gt;强制执行旋转等方性和平移不变性对称性来设计适用于鸟群控制的GNN控制器，这些是对鸟群动态中存在的自然规律。此方法比没有这种限制的现有模型使用更少的数据和参数量，并且在测试中的表现更加优异。&lt;h4&gt;主要发现&lt;/h4&gt;该研究证明了新的去中心化控制器需要较少的训练数据和可学习权重即可实现与传统GNN控制器相当的鸟群控制性能，同时展现出更好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;通过应用对称性约束设计出来的新型图神经网络架构为构建更加高效且灵活的去中心化控制系统提供了可能，在减少模型复杂度的同时提高了系统的鲁棒性和适应性。&lt;h4&gt;翻译&lt;/h4&gt;将代理在没有集中控制的情况下协调以优化集体目标是具有挑战性的，尤其是在诸如自主车队管理和使用传感器网络进行监控和侦察的应用中。分散控制器的设计受到了自然界中的自组织现象（如鸟群行为）的启发，然而现有方法难以保持群集的凝聚力。图神经网络架构已经作为开发能够维持群体凝聚性的去中心化控制工具成为必不可少的机器学习技术，但它们未能利用存在于鸟类动态中的对称性，限制了其泛化能力。研究强制执行旋转等方性和平移不变性在分散鸟群GNN控制器中，并实现与没有这些约束的传统模型相比使用70%更少的训练数据和75%更少的可学习权重即可获得类似的整体控制效果。此外，该方法展示出更好的泛化能力。相关代码和动画可在GitHub上获取（链接：http://github.com/Utah-Math-Data-Science/Equivariant-Decentralized-Controllers）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The orchestration of agents to optimize a collective objective withoutcentralized control is challenging yet crucial for applications such ascontrolling autonomous fleets, and surveillance and reconnaissance using sensornetworks. Decentralized controller design has been inspired byself-organization found in nature, with a prominent source of inspiration beingflocking; however, decentralized controllers struggle to maintain flockcohesion. The graph neural network (GNN) architecture has emerged as anindispensable machine learning tool for developing decentralized controllerscapable of maintaining flock cohesion, but they fail to exploit the symmetriespresent in flocking dynamics, hindering their generalizability. We enforcerotation equivariance and translation invariance symmetries in decentralizedflocking GNN controllers and achieve comparable flocking control with 70% lesstraining data and 75% fewer trainable weights than existing GNN controllerswithout these symmetries enforced. We also show that our symmetry-awarecontroller generalizes better than existing GNN controllers. Code andanimations are available athttp://github.com/Utah-Math-Data-Science/Equivariant-Decentralized-Controllers.</description>
      <author>example@mail.com (Taos Transue, Bao Wang)</author>
      <guid isPermaLink="false">2502.17612v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>FetchBot: Object Fetching in Cluttered Shelves via Zero-Shot Sim2Real</title>
      <link>http://arxiv.org/abs/2502.17894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FetchBot是一个从杂乱的货架上拾取物品的模拟到现实框架，旨在实现零样本泛化和安全意识的能力。通过利用高效的体积网格方法生成多样化的仿真场景，并采用动态感知强化学习策略来获取物体抓取轨迹。&lt;h4&gt;背景&lt;/h4&gt;在混乱环境中从货架上抓取物品是机器人帮助人类完成实际任务的重要能力，但受到运动空间受限、视野有限以及复杂对象动力学的影响而极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;介绍FetchBot框架，以解决数据稀缺问题，并开发一种能够泛化到不同真实世界场景中的安全意识物体抓取策略。&lt;h4&gt;方法&lt;/h4&gt;提出了一个高效的体积网格方法来生成大规模的混乱货架场景；训练了感知动态强化学习策略以获取物体抓取轨迹；并将这种策略提炼成基于视觉的政策，用于现实世界的部署。采用深度信息输入以减少模拟到现实的差距，并设计了一种新颖的多视图表示学习架构。&lt;h4&gt;主要发现&lt;/h4&gt;FetchBot框架通过有效的数据生成和转移机制，在广泛的环境中表现出强大的泛化能力。实验结果证明了其在处理多种真实世界场景时的有效性和安全性。&lt;h4&gt;结论&lt;/h4&gt;提出的FetchBot方法为机器人从混乱货架中安全地抓取物品提供了一个新的途径，显示出潜在的广泛应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object fetching from cluttered shelves is an important capability for robotsto assist humans in real-world scenarios. Achieving this task demands roboticbehaviors that prioritize safety by minimizing disturbances to surroundingobjects, an essential but highly challenging requirement due to restrictedmotion space, limited fields of view, and complex object dynamics. In thispaper, we introduce FetchBot, a sim-to-real framework designed to enablezero-shot generalizable and safety-aware object fetching from cluttered shelvesin real-world settings. To address data scarcity, we propose an efficientvoxel-based method for generating diverse simulated cluttered shelf scenes atscale and train a dynamics-aware reinforcement learning (RL) policy to generateobject fetching trajectories within these scenes. This RL policy, whichleverages oracle information, is subsequently distilled into a vision-basedpolicy for real-world deployment. Considering that sim-to-real discrepanciesstem from texture variations mostly while from geometric dimensions rarely, wepropose to adopt depth information estimated by full-fledged depth foundationmodels as the input for the vision-based policy to mitigate sim-to-real gap. Totackle the challenge of limited views, we design a novel architecture forlearning multi-view representations, allowing for comprehensive encoding ofcluttered shelf scenes. This enables FetchBot to effectively minimizecollisions while fetching objects from varying positions and depths, ensuringrobust and safety-aware operation. Both simulation and real-robot experimentsdemonstrate FetchBot's superior generalization ability, particularly inhandling a broad range of real-world scenarios, includ</description>
      <author>example@mail.com (Weiheng Liu, Yuxuan Wan, Jilong Wang, Yuxuan Kuang, Xuesong Shi, Haoran Li, Dongbin Zhao, Zhizheng Zhang, He Wang)</author>
      <guid isPermaLink="false">2502.17894v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>CalibRefine: Deep Learning-Based Online Automatic Targetless LiDAR-Camera Calibration with Iterative and Attention-Driven Post-Refinement</title>
      <link>http://arxiv.org/abs/2502.17648v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Transportation Research Part C: Emerging Technologies&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CalibRefine 是一种自动、无目标的在线校准框架，适用于 LiDAR 和相机传感器，能够直接处理原始点云和图像。&lt;h4&gt;背景&lt;/h4&gt;现有的LiDAR-摄像头校准方法通常依赖于手动放置的目标或初步参数估计等步骤，这限制了它们在真实环境中的可扩展性和适应性。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需人工参与的自动校准框架以提高多传感器系统的鲁棒性感知能力。&lt;h4&gt;方法&lt;/h4&gt;{'阶段一': '通过共同特征判别器使用相对位置、外观嵌入和语义类别来生成可靠的 LiDAR-相机对应关系', '阶段二': '基于粗略同构变换的校准', '阶段三': '在新增数据帧可用的情况下，采用迭代细化逐步改进对齐精度', '阶段四': '利用视觉变换器和跨注意力机制解决非平面畸变问题'}&lt;h4&gt;主要发现&lt;/h4&gt;CalibRefine 可以提供高精度的校准结果，并且不需要复杂的前期准备或大量人工干预，在真实环境中保持了与手动调优基线方法的竞争性甚至超越。&lt;h4&gt;结论&lt;/h4&gt;研究展示了如何通过稳健的对象级特征匹配、迭代和自我监督注意机制调整，实现复杂条件下传感器融合的一致性。&lt;h4&gt;翻译&lt;/h4&gt;准确的多传感器校准对于部署自动驾驶汽车、机器人技术以及智能交通系统中的强大感知系统至关重要。现有的LiDAR-相机校准方法往往依赖于手动放置的目标物或初步参数估计等步骤，这些限制了其在现实世界环境下的可扩展性和适应性。这项工作提出了一种全自动的无目标在线校准框架 CalibRefine ，可以直接处理原始 LiDAR 点云和摄像机图像。该方案分为四个阶段：首先是一个共同特征判别器，使用相对位置、外观嵌入以及语义类别信息生成可靠的LiDAR-相机对应关系；接着是基于粗略同构变换的校准；然后在新数据帧可用时进行迭代细化，逐步提高对齐精度；最后通过利用视觉变换器和跨注意力机制解决非平面畸变问题。经过两项城市交通数据集上的广泛实验验证，CalibRefine 在不依赖人工参与的前提下提供了高精度的校准结果，并且超过了最先进的无目标方法，同时与手动调优基线保持了竞争性甚至超越其性能表现。我们的研究强调了通过稳健的对象级特征匹配以及迭代和自我监督注意机制调整，在复杂真实世界条件下实现传感器融合一致性的重要性，无需地面真值校准矩阵或复杂的前期数据处理步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate multi-sensor calibration is essential for deploying robustperception systems in applications such as autonomous driving, robotics, andintelligent transportation. Existing LiDAR-camera calibration methods oftenrely on manually placed targets, preliminary parameter estimates, or intensivedata preprocessing, limiting their scalability and adaptability in real-worldsettings. In this work, we propose a fully automatic, targetless, and onlinecalibration framework, CalibRefine, which directly processes raw LiDAR pointclouds and camera images. Our approach is divided into four stages: (1) aCommon Feature Discriminator that trains on automatically detectedobjects--using relative positions, appearance embeddings, and semanticclasses--to generate reliable LiDAR-camera correspondences, (2) a coarsehomography-based calibration, (3) an iterative refinement to incrementallyimprove alignment as additional data frames become available, and (4) anattention-based refinement that addresses non-planar distortions by leveraginga Vision Transformer and cross-attention mechanisms. Through extensiveexperiments on two urban traffic datasets, we show that CalibRefine delivershigh-precision calibration results with minimal human involvement,outperforming state-of-the-art targetless methods and remaining competitivewith, or surpassing, manually tuned baselines. Our findings highlight howrobust object-level feature matching, together with iterative andself-supervised attention-based adjustments, enables consistent sensor fusionin complex, real-world conditions without requiring ground-truth calibrationmatrices or elaborate data preprocessing.</description>
      <author>example@mail.com (Lei Chenga, Lihao Guoa, Tianya Zhangb, Tam Bangb, Austin Harrisb, Mustafa Hajijc, Mina Sartipib, Siyang Cao)</author>
      <guid isPermaLink="false">2502.17648v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Bearing Fault Classification Under Variable Conditions: A 1D CNN with Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.17524v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文提出了一种基于振动和电机相电流信号的滚动轴承故障分类方法，利用一维卷积神经网络框架。&lt;h4&gt;背景&lt;/h4&gt;滚动轴承在确保旋转机械的可靠性和效率方面发挥着关键作用，减少摩擦并处理重要负载。然而，高达90%的机械故障是由轴承失效引起的，这凸显了可靠的状况监测和故障检测的重要性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于振动信号和电机相电流的一维卷积神经网络（1D CNN）框架下的多模态滚动轴承故障分类方法，以提高故障检测准确性。&lt;h4&gt;方法&lt;/h4&gt;该研究通过融合来自不同传感器的特征来增强故障检测精度，并在基线条件下实现了96%的准确率。此外，在使用L2正则化的情况下，模型性能得到了显著改善。&lt;h4&gt;主要发现&lt;/h4&gt;提出的1D CNN框架与迁移学习策略相结合，不仅提高了轴承故障分类的准确性，还在不同的操作条件下展示了稳健性表现。&lt;h4&gt;结论&lt;/h4&gt;虽然该方法在计算时间上需要更多资源，但为适应工业环境中可变工作条件下的更准确、更具适应性和效率的滚动轴承故障分类奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;滚动轴承在旋转机械中起着至关重要的作用，通过减少摩擦并处理重要负载来确保其可靠性和效率。高达90%的机械故障是由轴承失效引起的，这突显了可靠状态监测和故障检测的重要性。本文提出了一种基于振动信号和电机相电流的一维卷积神经网络（1D CNN）框架下的多模态滚动轴承故障分类方法，以提高故障检测准确性。该研究通过融合来自不同传感器的特征来增强故障检测精度，并在基线条件下实现了96%的准确率。此外，在使用L2正则化的情况下，模型性能得到了显著改善。提出的1D CNN框架与迁移学习策略相结合，不仅提高了轴承故障分类的准确性，还在不同的操作条件下展示了稳健性表现。虽然该方法在计算时间上需要更多资源，但为适应工业环境中可变工作条件下的更准确、更具适应性和效率的滚动轴承故障分类奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bearings play an integral role in ensuring the reliability and efficiency ofrotating machinery - reducing friction and handling critical loads. Bearingfailures that constitute up to 90% of mechanical faults highlight theimperative need for reliable condition monitoring and fault detection. Thisstudy proposes a multimodal bearing fault classification approach that relieson vibration and motor phase current signals within a one-dimensionalconvolutional neural network (1D CNN) framework. The method fuses features frommultiple signals to enhance the accuracy of fault detection. Under the baselinecondition (1,500 rpm, 0.7 Nm load torque, and 1,000 N radial force), the modelreaches an accuracy of 96% with addition of L2 regularization. This representsa notable improvement of 2% compared to the non-regularized model. In addition,the model demonstrates robust performance across three distinct operatingconditions by employing transfer learning (TL) strategies. Among the tested TLvariants, the approach that preserves parameters up to the first max-pool layerand then adjusts subsequent layers achieves the highest performance. While thisapproach attains excellent accuracy across varied conditions, it requires morecomputational time due to its greater number of trainable parameters. Toaddress resource constraints, less computationally intensive models offerfeasible trade-offs, albeit at a slight accuracy cost. Overall, this multimodal1D CNN framework with late fusion and TL strategies lays a foundation for moreaccurate, adaptable, and efficient bearing fault classification in industrialenvironments with variable operating conditions.</description>
      <author>example@mail.com (Tasfiq E. Alam, Md Manjurul Ahsan, Shivakumar Raman)</author>
      <guid isPermaLink="false">2502.17524v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>EEGM2: An Efficient Mamba-2-Based Self-Supervised Framework for Long-Sequence EEG Modeling</title>
      <link>http://arxiv.org/abs/2502.17873v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的EEG基础模型框架EEGM2，旨在克服基于Transformer架构在处理脑电图数据时遇到的计算复杂度问题。EEGM2利用结构化状态空间对偶性（SSD）进行自监督学习，并通过Mamba-2模型捕捉局部和全局特征。&lt;h4&gt;背景&lt;/h4&gt;深度学习已经在脑电图基础模型的发展中取得了显著进展，其中基于Transformer架构的模型在捕获长距离依赖方面表现出色。然而，它们的二次计算复杂度导致了内存效率低下、训练和推理速度慢的问题，限制了其作为基础模型的大规模应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的EEG自监督框架EEGM2，以克服现有基于Transformer架构的脑电图模型在计算复杂性和泛化能力上的局限性。&lt;h4&gt;方法&lt;/h4&gt;1. 重建基线框架：通过Mamba-2结构状态空间模型捕获局部和全局EEG特征；2. 空间时间感知损失函数：增强对噪声的鲁棒性并保留光谱信息；3. 多分支感受野输入嵌入策略：改进跨受试者泛化能力和序列长度变化时的稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;与传统的预训练方法相比，EEGM2在长序列任务中表现出色，并通过实验验证了其在六个EEG数据集上的优越性能和计算效率。此外，它还实现了跨域最佳准确性并降低了计算开销。&lt;h4&gt;结论&lt;/h4&gt;EEGM2不仅达到了最先进的跨领域准确性，而且减少了计算开销，在资源受限的BCI设备上部署时更高效。&lt;h4&gt;翻译&lt;/h4&gt;深度学习在脑电图基础模型的发展中取得了显著进步，尤其是基于Transformer架构的方法。然而，这些方法面临的二次复杂性挑战限制了它们的可扩展性和泛化能力。本文提出了一种新的自监督框架EEGM2，它引入了结构状态空间对偶性的概念，并利用Mamba-2模型来捕捉局部和全局特征。此外，通过改进的空间时间损失函数增强了鲁棒性和光谱信息保留。实验结果显示，与传统预训练方法相比，EEGM2在长序列任务中的表现更优，并且计算开销更低，适合资源受限的设备使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning has achieved significant progress in the development ofelectroencephalogram (EEG) foundation models, with Transformer-basedarchitectures excelling at capturing long-range dependencies. However, theirquadratic computational complexity presents challenges in memory efficiency,training, and inference speed, limiting their scalability and generalizabilityas a foundation model. In this paper, we propose EEGM2, a self-supervisedframework based on structured state space duality (SSD) that overcomes theselimitations. EEGM2 introduces three key innovations: (1) a reconstruction-basedframework that captures both local and global EEG features through Mamba-2structured state space models, (2) a spatiotemporal-aware loss function thatenhances robustness to noise and preserves spectral information, and (3) amulti-branch receptive field input embedding strategy that improvescross-subject generalization and stability for EEG sequences of varyinglengths. In comparison to traditional pretraining methods, on raw EEG or latentrepresentation spaces, EEGM2 shows superior performance on long-sequence tasks,where conventional models struggle. Our experimental results on six EEGdatasets validate that EEGM2 not only achieves state-of-the-art cross-domainaccuracy but also reduces computational overhead, making it a more efficientsolution for deployment on resource-constrained BCI devices.</description>
      <author>example@mail.com (Jiazhen Hong, Geoffrey Mackellar, Soheila Ghane)</author>
      <guid isPermaLink="false">2502.17873v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>ASurvey: Spatiotemporal Consistency in Video Generation</title>
      <link>http://arxiv.org/abs/2502.17863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了最近在视频生成领域的进展，涵盖了基础模型、信息表示、生成方案、后处理技术以及评估指标五个关键方面。&lt;h4&gt;背景&lt;/h4&gt;通过利用动态视觉生成方法，视频生成推动了人工智能生成内容（AIGC）的发展。相比静态图像生成，视频生成具有独特挑战，需要高质量的单帧画面和时间一致性以保持空间和时间序列的一致性。&lt;h4&gt;目的&lt;/h4&gt;回顾最近的进展并探讨维持时空一致性的贡献，填补相关文献综述的空白，以便更深入地理解高质量视频生成的基础机制。&lt;h4&gt;方法&lt;/h4&gt;系统地审查了五个关键方面：基础模型、信息表示、生成方案、后处理技术和评估指标，并特别关注它们在保持时空一致性方面的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;近期的工作主要集中于解决视频生成中的时空一致性问题，但很少有从这个角度组织的文献综述。&lt;h4&gt;结论&lt;/h4&gt;讨论了该领域未来的发展方向和挑战，旨在激励进一步的努力以推进视频生成技术的进步。&lt;h4&gt;翻译&lt;/h4&gt;通过利用动态视觉生成方法，视频生成推动了人工智能生成内容（AIGC）的发展。相比静态图像生成，视频生成具有独特挑战，需要高质量的单帧画面和时间一致性以保持空间和时间序列的一致性。近期的工作主要集中于解决视频生成中的时空一致性问题，但很少有从这个角度组织的文献综述。该论文系统地回顾了最近在五个关键方面的进展：基础模型、信息表示、生成方案、后处理技术和评估指标，并特别关注它们如何保持时空一致性的贡献。此外，讨论了未来的发展方向和挑战，旨在激励进一步的努力以推进视频生成技术的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video generation, by leveraging a dynamic visual generation method, pushesthe boundaries of Artificial Intelligence Generated Content (AIGC). Videogeneration presents unique challenges beyond static image generation, requiringboth high-quality individual frames and temporal coherence to maintainconsistency across the spatiotemporal sequence. Recent works have aimed ataddressing the spatiotemporal consistency issue in video generation, while fewliterature review has been organized from this perspective. This gap hinders adeeper understanding of the underlying mechanisms for high-quality videogeneration. In this survey, we systematically review the recent advances invideo generation, covering five key aspects: foundation models, informationrepresentations, generation schemes, post-processing techniques, and evaluationmetrics. We particularly focus on their contributions to maintainingspatiotemporal consistency. Finally, we discuss the future directions andchallenges in this field, hoping to inspire further efforts to advance thedevelopment of video generation.</description>
      <author>example@mail.com (Zhiyu Yin, Kehai Chen, Xuefeng Bai, Ruili Jiang, Juntao Li, Hongdong Li, Jin Liu, Yang Xiang, Jun Yu, Min Zhang)</author>
      <guid isPermaLink="false">2502.17863v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Laplace-Beltrami Operator for Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2502.17531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种计算拉普拉斯-贝尔特拉米算子的新方法，直接在高斯点阵上使用马氏距离来实现。这种方法提高了处理由3D高斯点阵表示的数据时的准确性。&lt;h4&gt;背景&lt;/h4&gt;随着3D高斯点阵技术的流行和其应用从渲染扩展到3D重建，对这种新数据表示形式进行几何处理的需求也日益增长。&lt;h4&gt;目的&lt;/h4&gt;提出一种直接在3D高斯点阵上计算拉普拉斯-贝尔特拉米算子的方法，以提高基于该表示的数据处理准确性，并能够评估优化过程中的输出质量。&lt;h4&gt;方法&lt;/h4&gt;通过使用马氏距离来定义和计算拉普拉斯-贝尔特拉米算子，从而直接在3D高斯点阵上进行几何处理。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在基于3D高斯点阵中心的点云数据中，该方法比传统的点云拉普拉斯算子具有更高的准确性，并且能够评估优化过程中的输出质量。&lt;h4&gt;结论&lt;/h4&gt;通过直接在3D高斯点阵上计算拉普拉斯-贝尔特拉米算子，可以提高基于该表示的数据处理效率和准确性，尤其是在处理大量离群值的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rising popularity of 3D Gaussian splatting and the expanse ofapplications from rendering to 3D reconstruction, there comes also a need forgeometry processing applications directly on this new representation. Whileconsidering the centers of Gaussians as a point cloud or meshing them is anoption that allows to apply existing algorithms, this might ignore informationpresent in the data or be unnecessarily expensive. Additionally, Gaussiansplatting tends to contain a large number of outliers which do not affect therendering quality but need to be handled correctly in order not to producenoisy results in geometry processing applications. In this work, we propose aformulation to compute the Laplace-Beltrami operator, a widely used tool ingeometry processing, directly on Gaussian splatting using the Mahalanobisdistance. While conceptually similar to a point cloud Laplacian, ourexperiments show superior accuracy on the point clouds encoded in the Gaussiansplatting centers and, additionally, the operator can be used to evaluate thequality of the output during optimization.</description>
      <author>example@mail.com (Hongyu Zhou, Zorah Lähner)</author>
      <guid isPermaLink="false">2502.17531v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Spectral Theory for Edge Pruning in Asynchronous Recurrent Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.17522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种基于图谱理论的动态修剪方法，用于简化异步递归图神经网络（ARGNN），以提高其在处理动态图形数据时的效率。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）已经成为学习结构化图形数据的强大工具，在社交网络分析和分子生物学等领域中得到广泛应用。特别地，ARGNN因其能捕捉到动态图形中的复杂依赖关系而脱颖而出，类似于活体生物复杂的适应性特征。&lt;h4&gt;目的&lt;/h4&gt;尽管ARGNN在性能上表现出色，但其复杂性往往导致模型庞大且计算成本高昂。因此，修剪不必要的边成为提高效率而不显著降低性能的关键。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种基于图谱理论的动态修剪策略，利用网络图形拉普拉斯矩阵特征值的虚部来识别和去除不重要的连接。&lt;h4&gt;主要发现&lt;/h4&gt;该论文展示了如何通过有效减少ARGNN中的冗余边来提高模型效率，并且在保证性能的同时减少了计算资源的需求。&lt;h4&gt;结论&lt;/h4&gt;所提出的动态修剪方法为优化复杂GNN架构提供了一种有效的解决方案，特别适用于处理大量数据的场景中需要高效推理的应用场合。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容直接用于英文到中文的翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as a powerful tool for learning ongraph-structured data, finding applications in numerous domains includingsocial network analysis and molecular biology. Within this broad category,Asynchronous Recurrent Graph Neural Networks (ARGNNs) stand out for theirability to capture complex dependencies in dynamic graphs, resembling livingorganisms' intricate and adaptive nature. However, their complexity often leadsto large and computationally expensive models. Therefore, pruning unnecessaryedges becomes crucial for enhancing efficiency without significantlycompromising performance. This paper presents a dynamic pruning method based ongraph spectral theory, leveraging the imaginary component of the eigenvalues ofthe network graph's Laplacian.</description>
      <author>example@mail.com (Nicolas Bessone)</author>
      <guid isPermaLink="false">2502.17522v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Multimodality Helps Few-shot 3D Point Cloud Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.22489v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICLR 2025 (Spotlight)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种用于三维点云分割的多模态少样本分割模型（MM-FSS），该模型利用文本标签和可能存在的二维图像模式，弥补了现有方法忽略多模态信息的问题。&lt;h4&gt;背景&lt;/h4&gt;目前的少样本3D点云分割方法主要关注单一模态的点云输入，忽略了多模态信息的优势。&lt;h4&gt;目的&lt;/h4&gt;引入一个利用多种模态数据（如文本标签和2D图像）的多模态少样本设置，并开发相应的模型以提升性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的模型——MultiModal Few-Shot SegNet (MM-FSS)，该模型通过共享骨干网络从多个模式中提取互补信息，使用预训练的文字编码器生成文字嵌入。还设计了Multimodal Correlation Fusion（MCF）模块和Multimodal Semantic Fusion（MSF）模块来利用多模态数据。此外提出Test-time Adaptive Cross-modal Calibration（TACC）技术以减轻训练偏差。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MM-FSS在S3DIS和ScanNet等数据集上的性能显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;本文证明了利用被忽视的自由模态信息可以提高少样本三维点云分割任务的效果，并为未来的研究提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文版&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot 3D point cloud segmentation (FS-PCS) aims at generalizing models tosegment novel categories with minimal annotated support samples. While existingFS-PCS methods have shown promise, they primarily focus on unimodal point cloudinputs, overlooking the potential benefits of leveraging multimodalinformation. In this paper, we address this gap by introducing a multimodalFS-PCS setup, utilizing textual labels and the potentially available 2D imagemodality. Under this easy-to-achieve setup, we present the MultiModal Few-ShotSegNet (MM-FSS), a model effectively harnessing complementary information frommultiple modalities. MM-FSS employs a shared backbone with two heads to extractintermodal and unimodal visual features, and a pretrained text encoder togenerate text embeddings. To fully exploit the multimodal information, wepropose a Multimodal Correlation Fusion (MCF) module to generate multimodalcorrelations, and a Multimodal Semantic Fusion (MSF) module to refine thecorrelations using text-aware semantic guidance. Additionally, we propose asimple yet effective Test-time Adaptive Cross-modal Calibration (TACC)technique to mitigate training bias, further improving generalization.Experimental results on S3DIS and ScanNet datasets demonstrate significantperformance improvements achieved by our method. The efficacy of our approachindicates the benefits of leveraging commonly-ignored free modalities forFS-PCS, providing valuable insights for future research. The code is availableat https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot</description>
      <author>example@mail.com (Zhaochong An, Guolei Sun, Yun Liu, Runjia Li, Min Wu, Ming-Ming Cheng, Ender Konukoglu, Serge Belongie)</author>
      <guid isPermaLink="false">2410.22489v3</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>A Macro- and Micro-Hierarchical Transfer Learning Framework for Cross-Domain Fake News Detection</title>
      <link>http://arxiv.org/abs/2502.14403v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 8 figures, to be published in The 2025 ACM Web Conference  (WWW '25)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于跨域假新闻检测的宏微观分层迁移学习框架（MMHT），该框架旨在解决现有方法在知识转移和假新闻检测性能方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;跨域假新闻检测的目标是通过在不同领域之间传输知识来减轻领域的偏移并提高检测性能。现有的方法基于源领域的新闻内容和用户互动向目标领域传递知识，但它们面临着两个主要限制：忽略新闻内容中无关事实特征的负面影响以及忽视用户参与度与新闻内容之间的关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效解决现有假新闻检测方法存在的问题，并优化知识传输效率的新框架。&lt;h4&gt;方法&lt;/h4&gt;1. 微观分层解缠模块，旨在从源域的新闻内容中分离出相关性和无关性的事实特征，以提高目标领域的假新闻检测性能。2. 宏观分层迁移学习模块，根据不同领域中用户共享行为生成参与度特征，从而增强知识传输的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明所提出的框架在真实数据集上的表现明显优于现有的最先进的基准方法。&lt;h4&gt;结论&lt;/h4&gt;通过解决现有跨域假新闻检测方法中的两个关键限制，MMHT 框架能够有效提高跨领域假新闻检测的性能和知识传输效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714517&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-domain fake news detection aims to mitigate domain shift and improvedetection performance by transferring knowledge across domains. Existingapproaches transfer knowledge based on news content and user engagements from asource domain to a target domain. However, these approaches face two mainlimitations, hindering effective knowledge transfer and optimal fake newsdetection performance. Firstly, from a micro perspective, they neglect thenegative impact of veracity-irrelevant features in news content whentransferring domain-shared features across domains. Secondly, from a macroperspective, existing approaches ignore the relationship between userengagement and news content, which reveals shared behaviors of common usersacross domains and can facilitate more effective knowledge transfer. To addressthese limitations, we propose a novel macro- and micro- hierarchical transferlearning framework (MMHT) for cross-domain fake news detection. Firstly, wepropose a micro-hierarchical disentangling module to disentangleveracity-relevant and veracity-irrelevant features from news content in thesource domain for improving fake news detection performance in the targetdomain. Secondly, we propose a macro-hierarchical transfer learning module togenerate engagement features based on common users' shared behaviors indifferent domains for improving effectiveness of knowledge transfer. Extensiveexperiments on real-world datasets demonstrate that our framework significantlyoutperforms the state-of-the-art baselines.</description>
      <author>example@mail.com (Xuankai Yang, Yan Wang, Xiuzhen Zhang, Shoujin Wang, Huaxiong Wang, Kwok Yan Lam)</author>
      <guid isPermaLink="false">2502.14403v2</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Mechanistic Interpretability for Multi-Modal Foundation Models</title>
      <link>http://arxiv.org/abs/2502.17516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 4 Figures, 10 Tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了基础模型的发展对机器学习研究的影响，特别是大型语言模型（LLMs）和多模态基础模型（MMFMs）。虽然在解释LLM方面取得了显著进展，但MMFMs（如对比视觉-语言模型、生成式视觉-语言模型以及文本到图像模型）在单模态框架之外提出了独特的可解释性挑战。&lt;h4&gt;背景&lt;/h4&gt;大规模基础模型的兴起改变了机器学习研究的方向，并促使研究人员努力揭示这些模型的工作原理以开发更高效和可靠的控制应用。虽然LLM的理解已经取得了很大进展，但MMFMs的透明度仍然落后于LLM。&lt;h4&gt;目的&lt;/h4&gt;该综述探讨了两个关键方面：一是将LLM解释方法应用于多模态模型；二是理解单模态语言模型与跨模式系统之间的机制差异。&lt;h4&gt;方法&lt;/h4&gt;通过系统性地回顾现有的MMFM分析技术，提出了可解释性的结构分类法，并比较了单模态和多模态架构的见解。&lt;h4&gt;主要发现&lt;/h4&gt;指出了当前在LLM和MMFM之间理解上的重大差距，并强调了几项关键的研究空白。&lt;h4&gt;结论&lt;/h4&gt;该综述提供了一种对MMFMs进行系统性研究的方法，旨在促进机器学习领域的进一步发展。它还为研究人员提供了关于如何改进多模态基础模型的解释性的指导。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型（LLM）的可解释方法在多模态框架下的适应以及单模态语言模型与跨模式系统之间的机制性差异是研究重点，通过比较和分类不同架构中的见解来填补LLM和MMFM之间存在的理解差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rise of foundation models has transformed machine learning research,prompting efforts to uncover their inner workings and develop more efficientand reliable applications for better control. While significant progress hasbeen made in interpreting Large Language Models (LLMs), multimodal foundationmodels (MMFMs) - such as contrastive vision-language models, generativevision-language models, and text-to-image models - pose unique interpretabilitychallenges beyond unimodal frameworks. Despite initial studies, a substantialgap remains between the interpretability of LLMs and MMFMs. This surveyexplores two key aspects: (1) the adaptation of LLM interpretability methods tomultimodal models and (2) understanding the mechanistic differences betweenunimodal language models and crossmodal systems. By systematically reviewingcurrent MMFM analysis techniques, we propose a structured taxonomy ofinterpretability methods, compare insights across unimodal and multimodalarchitectures, and highlight critical research gaps.</description>
      <author>example@mail.com (Zihao Lin, Samyadeep Basu, Mohammad Beigi, Varun Manjunatha, Ryan A. Rossi, Zichao Wang, Yufan Zhou, Sriram Balasubramanian, Arman Zarei, Keivan Rezaei, Ying Shen, Barry Menglong Yao, Zhiyang Xu, Qin Liu, Yuxiang Zhang, Yan Sun, Shilong Liu, Li Shen, Hongxuan Li, Soheil Feizi, Lifu Huang)</author>
      <guid isPermaLink="false">2502.17516v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Learning multi-phase flow and transport in fractured porous media with auto-regressive and recurrent graph neural networks</title>
      <link>http://arxiv.org/abs/2502.17512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了一种使用图神经网络（GNN）来模拟多相流和输运动力学的新方法，这种方法在处理复杂裂缝网络时比传统的方法更有效。&lt;h4&gt;背景&lt;/h4&gt;过去三十年间，用于解决裂隙多孔介质中多重流动和传输过程建模的计算方法和仿真框架层出不穷。其中共形网格方法因其高精度而备受青睐，但需要极细的网格划分，在大型或复杂的裂缝网络中变得不可行。&lt;h4&gt;目的&lt;/h4&gt;提出基于图神经网络的方法来模拟复杂裂隙多孔介质中的多相流动和传输动力学。&lt;h4&gt;方法&lt;/h4&gt;提出了两种深度学习架构：一种是GNN（图神经网络），另一种是递归GNN。这两种网络均采用两阶段训练策略：自回归一步滚动，然后通过完整的真实地面序列进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示了两阶段训练的有效性，在测试阶段的自回归模型滚动过程中减少了误差积累；两种GNN都展示了对未见过裂缝结构的良好泛化能力。递归GNN在预测长期序列方面显示出显著优势，尤其是在压力序列预测中表现更佳。&lt;h4&gt;结论&lt;/h4&gt;基于图神经网络的方法为复杂裂隙多孔介质中的流动和传输过程建模提供了一种有效的新途径，特别是对于大型或复杂的裂缝网络来说更是如此。&lt;h4&gt;翻译&lt;/h4&gt;在过去三十年间，多种计算方法和模拟框架被开发出来以应对在裂隙性多孔介质中多重流体流动与输运过程的复杂建模挑战。共形网格技术通过确保计算网格与裂缝表面对齐而被视为最准确的方法之一。然而，这类方法需要极细的网格划分，在处理大型或复杂的裂缝网络时变得不切实际。在这项工作中，我们提出使用图神经网络（GNN）来学习裂隙性多孔介质中的复杂多相流动和输运动力学现象。鉴于嵌入离散裂缝模型（EDFM）所导致计算网格的非结构化特性，GNN非常适合这一任务。我们提出了两种深度学习架构：一种是GNN，另一种是递归GNN。这两个网络都遵循两阶段训练策略：首先是自回归一步滚动，然后通过完整的真实地面序列进行微调。结果显示，两阶段训练方法在测试期间的模型自回归展开时有效减少了误差积累。我们的研究发现表明，两种GNN都能很好地泛化到未见过的裂缝结构，并且它们在预测饱和度序列方面表现相当，而递归GNN则略微优于GNN在压力序列预测中的性能。尽管第二阶段训练对GNN模型有益，但其对递归GNN的影响不那么显著。最后，测试了两种GNN的时间外推性能。递归GNN以更高的准确性明显超越了GNN，在长期序列的预测中展示了优越的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the past three decades, a wide array of computational methodologies andsimulation frameworks has emerged to address the complexities of modelingmulti-phase flow and transport processes in fractured porous media. Theconformal mesh approaches which explicitly align the computational grid withfracture surfaces are considered by many to be the most accurate. However, suchmethods require excessive fine-scale meshing, rendering them impractical forlarge or complex fracture networks. In this work, we propose to learn thecomplex multi-phase flow and transport dynamics in fractured porous media withgraph neural networks (GNN). GNNs are well suited for this task due to theunstructured topology of the computation grid resulting from the EmbeddedDiscrete Fracture Model (EDFM) discretization. We propose two deep learningarchitectures, a GNN and a recurrent GNN. Both networks follow a two-stagetraining strategy: an autoregressive one step roll-out, followed by afine-tuning step where the model is supervised using the whole ground-truthsequence. We demonstrate that the two-stage training approach is effective inmitigating error accumulation during autoregressive model rollouts in thetesting phase. Our findings indicate that both GNNs generalize well to unseenfracture realizations, with comparable performance in forecasting saturationsequences, and slightly better performance for the recurrent GNN in predictingpressure sequences. While the second stage of training proved to be beneficialfor the GNN model, its impact on the recurrent GNN model was less pronounced.Finally, the performance of both GNNs for temporal extrapolation is tested. Therecurrent GNN significantly outperformed the GNN in terms of accuracy, therebyunderscoring its superior capability in predicting long sequences.</description>
      <author>example@mail.com (Mohammed Al Kobaisi, Wenjuan Zhang, Waleed Diab, Hadi Hajibeygi)</author>
      <guid isPermaLink="false">2502.17512v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Supervised Reward Inference</title>
      <link>http://arxiv.org/abs/2502.18447v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章提出了一种基于监督学习的框架，用于从人类行为中推断奖励函数。这种方法能够在温和假设下实现渐进贝叶斯最优，并且通过模拟机器人操作任务实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的奖励推理方法通常假设人类提供的演示遵循特定的行为模型。然而，在实际情况下，人们可能表现出各种类型的次优行为来指示他们的目标。&lt;h4&gt;目的&lt;/h4&gt;提出一种从任意类型的人类行为中推断奖励函数的统一框架，并展示这种方法在温和假设下的渐进贝叶斯最优性。&lt;h4&gt;方法&lt;/h4&gt;利用监督学习技术建立一个模型，该模型可以从广泛的、可能是次优的行为演示中推断出奖励函数。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法能够从各种各样的次优行为演示中有效地推断出奖励函数。&lt;h4&gt;结论&lt;/h4&gt;基于监督学习的框架为从人类行为数据中推断奖励提供了一种灵活而有效的方法，并且在模拟任务中的表现证明了这一点。&lt;h4&gt;翻译&lt;/h4&gt;现有方法假设人类提供的示例符合特定的行为模型。然而，实际情况是人们通过各种各样的行为来指示目标，这些行为可能由于计划或执行不当而不理想，也可能是为了传达目的而不是实现它们。我们提出监督学习能够提供一个统一的框架从任何类型的人类行为中推断奖励函数，并展示了在温和假设下的渐进贝叶斯最优性。模拟机器人操作任务实验表明这种方法可以从各种次优演示中有效推断出奖励。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing approaches to reward inference from behavior typically assume thathumans provide demonstrations according to specific models of behavior.However, humans often indicate their goals through a wide range of behaviors,from actions that are suboptimal due to poor planning or execution to behaviorswhich are intended to communicate goals rather than achieve them. We proposethat supervised learning offers a unified framework to infer reward functionsfrom any class of behavior, and show that such an approach is asymptoticallyBayes-optimal under mild assumptions. Experiments on simulated roboticmanipulation tasks show that our method can efficiently infer rewards from awide variety of arbitrarily suboptimal demonstrations.</description>
      <author>example@mail.com (Will Schwarzer, Jordan Schneider, Philip S. Thomas, Scott Niekum)</author>
      <guid isPermaLink="false">2502.18447v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>CRESSim-MPM: A Material Point Method Library for Surgical Soft Body Simulation with Cutting and Suturing</title>
      <link>http://arxiv.org/abs/2502.18437v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 12 figures, submitted to IEEE/RSJ International Conference  on Intelligent Robots and Systems (IROS) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的手术模拟平台CRESSim-MPM，使用材料点法（MPM）来克服现有平台上在软组织切割和缝合等复杂行为的模拟问题。&lt;h4&gt;背景&lt;/h4&gt;现有的手术仿真平台难以精确地模拟软体组织的行为，特别是像切割、缝合这样复杂的操作。这主要是由于有限元方法(FEM)在这种情况下处理材料分裂等问题时存在困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够更准确模拟软体组织复杂行为的新型物理引擎，以便更好地训练机器学习模型进行手术辅助。&lt;h4&gt;方法&lt;/h4&gt;采用材料点法（MPM）来应对FEM在处理软质物体分割和缝合问题上的不足。提出了新的刚性几何形状以及适用于这种场景下的软硬接触方法。开发了CRESSim-MPM, 一个加速的GPU库，集成了多种MPM求解器，并加入了用于切割和缝合等手术操作的物理引擎。&lt;h4&gt;主要发现&lt;/h4&gt;通过在实时模拟中展示其能力来验证该平台的有效性，包括对软组织进行切割和缝合。同时进行了不同数量颗粒仿真时各MPM求解器性能评估。&lt;h4&gt;结论&lt;/h4&gt;CRESSim-MPM为复杂的手术操作提供了更好的物理建模方法，并且能够有效地与Unity集成，便于现有项目的扩展和应用。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究集中于开发用于训练机器学习代理或模型的合成数据的外科模拟平台。尽管现有的平台在刚体操纵和软体变形方面表现出色，但它们难以精确地模拟诸如切割和缝合等更复杂的软体行为。一个重要挑战在于使用有限元法（FEM）建模软体分裂问题，在当前平台上这种方法是主要手段。当需要处理手术中的两向缝线接触时，这会进一步复杂化。在本研究中，我们采用材料点法（MPM）进行此类困难模拟，并提出了用于该方法的新刚性几何形状和软硬接触方法。我们引入了CRESSim-MPM，这是一个基于GPU加速的MPM库，集成了多个MPM求解器并包含了手术几何图形以支持切割和缝合操作，作为专门用于外科应用的物理引擎。它还被集成到了Unity中，只需对现有项目进行最小改动即可实现软体模拟。我们展示了该仿真器在实时模拟软组织切割和缝合方面的能力，并提供了不同数量颗粒时各种MPM求解器性能评估的初步结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A number of recent studies have focused on developing surgical simulationplatforms to train machine learning (ML) agents or models with synthetic datafor surgical assistance. While existing platforms excel at tasks such as rigidbody manipulation and soft body deformation, they struggle to simulate morecomplex soft body behaviors like cutting and suturing. A key challenge lies inmodeling soft body fracture and splitting using the finite-element method(FEM), which is the predominant approach in current platforms. Additionally,the two-way suture needle/thread contact inside a soft body is furthercomplicated when using FEM. In this work, we use the material point method(MPM) for such challenging simulations and propose new rigid geometries andsoft-rigid contact methods specifically designed for them. We introduceCRESSim-MPM, a GPU-accelerated MPM library that integrates multiple MPM solversand incorporates surgical geometries for cutting and suturing, serving as aspecialized physics engine for surgical applications. It is further integratedinto Unity, requiring minimal modifications to existing projects for soft bodysimulation. We demonstrate the simulator's capabilities in real-time simulationof cutting and suturing on soft tissue and provide an initial performanceevaluation of different MPM solvers when simulating varying numbers ofparticles.</description>
      <author>example@mail.com (Yafei Ou, Mahdi Tavakoli)</author>
      <guid isPermaLink="false">2502.18437v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Stretchable Capacitive and Resistive Strain Sensors: Accessible Manufacturing Using Direct Ink Writing</title>
      <link>http://arxiv.org/abs/2502.18363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 8 figures, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;随着机器人技术的发展，软结构、类人形态和复杂任务的集成变得越来越重要，因此研发出可靠测量触觉和本体感觉数据的同时兼具形变适应性、可拉伸性和可调整性的柔性传感器至关重要。&lt;h4&gt;背景&lt;/h4&gt;当前许多用于制造可拉伸传感器的方法仅限于单一配置的设计，限制了设计灵活性。研究人员正在探索多样化的转换原理以及规模生产和多功能生产技术以解决这个问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于打印的灵活、定制化且易于实现的可拉伸传感器制造方法。&lt;h4&gt;方法&lt;/h4&gt;使用商用3D打印机与自定义喷头集成，可以将导电墨水直接书写在固化硅胶基底上。通过堆叠托盘支持的逐层制造工艺，在硅胶矩阵内沉积多层液态导电墨水。&lt;h4&gt;主要发现&lt;/h4&gt;展示的方法具有高度的设计灵活性，并且制造出和评估了包括电容式和电阻式的应变传感器形态。实验表征显示，电容式应变传感器具备高线性度（R^2 = 0.99）、接近理论极限的高灵敏度（GF = 0.95）、极小的滞后效应(DH = 1.36%)以及高达550%的最大拉伸能力。&lt;h4&gt;结论&lt;/h4&gt;该方法提供了一种新的制造方式，能够满足高度可定制化的需求，并且生产出的传感器性能达到当前先进水平。&lt;h4&gt;翻译&lt;/h4&gt;随着机器人技术向集成软结构、类人形态和复杂任务的发展，柔软且高度可拉伸的力学转换器变得越来越重要。为了在确保形状适应性的同时可靠地测量触觉和本体感觉数据，研究人员正在探索多样化的转换原理以及规模生产和多功能生产技术。然而，许多当前用于制造可拉伸传感器的方法仅限于单一配置的设计，限制了设计灵活性。在这里，我们提出了一种基于打印的灵活、定制化且易于实现的新方法来制作可拉伸传感器。我们的方法采用商用3D打印机与自定义喷头集成，可以将导电墨水直接书写在固化硅胶基底上。通过堆叠托盘支持的逐层制造工艺，在硅胶矩阵内沉积多层液态导电墨水。为了展示该方法的设计灵活性，我们制作并评估了包括电容式和电阻式的应变传感器形态。实验表征显示，电容式应变传感器具有高线性度（R^2 = 0.99）、接近理论极限的高灵敏度（GF = 0.95）、极小的滞后效应(DH = 1.36%)以及高达550%的最大拉伸能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As robotics advances toward integrating soft structures, anthropomorphicshapes, and complex tasks, soft and highly stretchable mechanotransducers arebecoming essential. To reliably measure tactile and proprioceptive data whileensuring shape conformability, stretchability, and adaptability, researchershave explored diverse transduction principles alongside scalable and versatilemanufacturing techniques. Nonetheless, many current methods for stretchablesensors are designed to produce a single sensor configuration, thereby limitingdesign flexibility. Here, we present an accessible, flexible, printing-basedfabrication approach for customizable, stretchable sensors. Our method employsa custom-built printhead integrated with a commercial 3D printer to enabledirect ink writing (DIW) of conductive ink onto cured silicone substrates. Alayer-wise fabrication process, facilitated by stackable trays, allows for thedeposition of multiple liquid conductive ink layers within a silicone matrix.To demonstrate the method's capacity for high design flexibility, we fabricateand evaluate both capacitive and resistive strain sensor morphologies.Experimental characterization showed that the capacitive strain sensorpossesses high linearity (R^2 = 0.99), high sensitivity near the 1.0theoretical limit (GF = 0.95), minimal hysteresis (DH = 1.36%), and largestretchability (550%), comparable to state-of-the-art stretchable strainsensors reported in the literature.</description>
      <author>example@mail.com (Lukas Cha, Sonja Groß, Shuai Mao, Tim Braun, Sami Haddadin, Liang He)</author>
      <guid isPermaLink="false">2502.18363v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>MegaLoc: One Retrieval to Place Them All</title>
      <link>http://arxiv.org/abs/2502.17237v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Tech Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了MegaLoc模型，该模型在多个计算机视觉任务中表现出色。&lt;h4&gt;背景&lt;/h4&gt;从给定查询检索来自相同位置的图像对于多项计算机视觉任务（如视觉地方识别、地标检索、视觉定位、3D重建和SLAM）至关重要。然而，现有解决方案只能针对特定的任务设计，并且当需求变化或遇到分布外数据时会失败。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型MegaLoc，该模型能够同时在多个计算机视觉任务中表现良好。&lt;h4&gt;方法&lt;/h4&gt;结合了多种现有的方法、训练技术以及数据集来训练一个检索模型MegaLoc。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': 'MegaLoc在大量视觉地方识别数据集中达到了最先进水平。', '2': 'MegaLoc在常用的地标检索数据集中取得了令人印象深刻的结果。', '3': 'MegaLoc为LaMAR数据集上的视觉定位设定了新的最先进的标准，只需将检索方法替换到现有定位管道中即可。'}&lt;h4&gt;结论&lt;/h4&gt;提出的模型MegaLoc展示了其跨多个任务的优越性能，并且源代码已公开发布在GitHub上。&lt;h4&gt;翻译&lt;/h4&gt;从给定查询检索来自相同位置的图像对多项计算机视觉任务（包括视觉地方识别、地标检索、视觉定位、3D重建和SLAM）至关重要。然而，现有解决方案设计专门用于特定的任务，在需求变化或遇到分布外数据时会失效。本文结合了多种现有的方法、训练技术以及数据集来训练一个名为MegaLoc的检索模型，该模型在多个任务上表现出色。研究发现，MegaLoc（1）在大量视觉地方识别的数据集中达到了最先进水平；（2）在常用的地标检索数据集中取得了令人印象深刻的结果；（3）为LaMAR数据集上的视觉定位设定了新的最先进的标准，只需将检索方法替换到现有定位管道中即可。MegaLoc的代码可在https://github.com/gmberton/MegaLoc 获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/gmberton/megaloc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieving images from the same location as a given query is an importantcomponent of multiple computer vision tasks, like Visual Place Recognition,Landmark Retrieval, Visual Localization, 3D reconstruction, and SLAM. However,existing solutions are built to specifically work for one of these tasks, andare known to fail when the requirements slightly change or when they meetout-of-distribution data. In this paper we combine a variety of existingmethods, training techniques, and datasets to train a retrieval model, calledMegaLoc, that is performant on multiple tasks. We find that MegaLoc (1)achieves state of the art on a large number of Visual Place Recognitiondatasets, (2) impressive results on common Landmark Retrieval datasets, and (3)sets a new state of the art for Visual Localization on the LaMAR datasets,where we only changed the retrieval method to the existing localizationpipeline. The code for MegaLoc is available athttps://github.com/gmberton/MegaLoc</description>
      <author>example@mail.com (Gabriele Berton, Carlo Masone)</author>
      <guid isPermaLink="false">2502.17237v2</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Data Generation for Precision Agriculture: Blending Simulated Environments with Real Imagery</title>
      <link>http://arxiv.org/abs/2502.18320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at 2024 IEEE 20th International Conference on Automation  Science and Engineering (CASE)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;在精准农业中，由于缺乏标注数据和显著的协变量变化，训练机器学习模型面临独特的挑战。本文提出了一种基于Unity引擎的葡萄园模拟器系统，该系统通过剪切粘贴技术生成逼真的合成图像及标签，以解决这些问题。&lt;h4&gt;背景&lt;/h4&gt;精准农业领域存在数据标注不足的问题，并且环境动态性导致农作物外观随时间变化，这使得训练机器学习模型变得困难。缺乏多样化的数据限制了算法的性能和适应能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种生成真实感合成图像的方法来克服这些挑战，以便更好地训练用于监测和管理农业活动的检测算法。&lt;h4&gt;方法&lt;/h4&gt;利用Unity引擎创建一个虚拟葡萄园模拟器，并采用几何一致性剪切粘贴技术从合成环境中生成精确的照片级现实图像及标签。该系统可以自动生成各种视角和光照条件下的数据样本。&lt;h4&gt;主要发现&lt;/h4&gt;通过在提子栽培训练最先进的检测算法上应用这种方法，取得了显著的性能改进，表明所提出的组合技术可以有效增强模型的学习能力和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;基于合成数据的方法为精准农业提供了新的可能性。它不仅可以生成大量高质量的数据以克服标注不足的问题，而且能够模拟各种环境条件下的图像变化。此外，该方法易于自动化实施，对于其在实际农业生产中的应用非常重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于一种用于解决精准农业中由于缺乏标记数据和显著协变量变化所带来的挑战的方法介绍。通过使用基于Unity引擎的葡萄园仿真器，并利用剪切粘贴技术生成逼真的合成图像与标签，可以训练检测算法以应对不同的视角和光照条件。这种方法在提子栽培场景下的应用表明它能够极大地改进最先进的检测模型性能。该方法由于其易于自动化的特性而可能被广泛采纳于实际农业生产实践中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/CASE59546.2024.10711594&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In precision agriculture, the scarcity of labeled data and significantcovariate shifts pose unique challenges for training machine learning models.This scarcity is particularly problematic due to the dynamic nature of theenvironment and the evolving appearance of agricultural subjects as livingthings. We propose a novel system for generating realistic synthetic data toaddress these challenges. Utilizing a vineyard simulator based on the Unityengine, our system employs a cut-and-paste technique with geometricalconsistency considerations to produce accurate photo-realistic images andlabels from synthetic environments to train detection algorithms. This approachgenerates diverse data samples across various viewpoints and lightingconditions. We demonstrate considerable performance improvements in training astate-of-the-art detector by applying our method to table grapes cultivation.The combination of techniques can be easily automated, an increasinglyimportant consideration for adoption in agricultural practice.</description>
      <author>example@mail.com (Leonardo Saraceni, Ionut Marian Motoi, Daniele Nardi, Thomas Alessandro Ciarfuglia)</author>
      <guid isPermaLink="false">2502.18320v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>RSSI-Based Localization Utilizing Antenna Radiation Pattern And Biased CRLB Analysis</title>
      <link>http://arxiv.org/abs/2502.18311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;本文提出了一种新颖的室内定位方法，利用单天线系统中接收信号强度指示（RSSI）测量来获取天线辐射模式特征。通过旋转天线或重新配置其辐射模式，我们推导出了极大似然估计算法，该算法实现了接近克拉美罗下界（CRLB）的近优化定位精度。&lt;h4&gt;背景&lt;/h4&gt;现有的室内定位技术往往依赖于多天线系统，难以在保证高精度的同时保持系统的简洁性。本文通过研究单天线辐射模式特性，试图找到一种简化且高效的解决方案。&lt;h4&gt;目的&lt;/h4&gt;提出一个利用单天线辐射特性的新型室内定位方法，并验证其在复杂环境下的性能表现。&lt;h4&gt;方法&lt;/h4&gt;设计并实施了一种基于RSSI测量的极大似然估计（MLE）算法；通过旋转或重新配置天线的辐射模式来改善信号质量，减少位置误差。此外，提出了一种两步测量策略以消除对接收天线模式依赖的需求。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，随着信噪比、天线旋转次数和辐射模式变化的增加，估计精度有显著提高；模拟结果验证了该方法在室内机器人跟踪应用中的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文所提出的定位技术能够有效解决室内环境下的机器人追踪问题，同时保持系统结构简单。这一方法为未来基于单天线系统的高精度室内定位提供了新的思路和依据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel indoor positioning approach that leveragesantenna radiation pattern characteristics through Received Signal StrengthIndication (RSSI) measurements in a single-antenna system. By rotating theantenna or reconfiguring its radiation pattern, we derive a maximum likelihoodestimation (MLE) algorithm that achieves near-optimal positioning accuracyapproaching the Cramer-Rao lower bound (CRLB). Through theoretical analysis, weestablish three fundamental theorems characterizing the estimation accuracybounds and demonstrating how performance improves with increasedsignal-to-noise ratio, antenna rotation count, and radiation patternvariations. Additionally, we propose a two-position measurement strategy thateliminates dependence on receiving antenna patterns. Simulation resultsvalidate that our approach provides an effective solution for indoor robottracking applications where both accuracy and system simplicity are essentialconsiderations.</description>
      <author>example@mail.com (Zhisheng Rong, Wenzhi Liu, Xiayue Liu, Zhixiang Xu, Yufei Jiang)</author>
      <guid isPermaLink="false">2502.18311v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Pre-Surgical Planner for Robot-Assisted Vitreoretinal Surgery: Integrating Eye Posture, Robot Position and Insertion Point</title>
      <link>http://arxiv.org/abs/2502.18230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种优化框架，用于调整眼科手术中眼睛的倾斜角度和机器人位置，以实现不同的患者目标区域。&lt;h4&gt;背景&lt;/h4&gt;最近开发了几种辅助视网膜手术的机器人系统。这些系统的准确性受限于其工作体积，并且通过外科显微镜看到的视野有限。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有手术机器人的限制，优化眼睛姿态和机器人定位以扩大可达性并减少重置准备过程的可能性。&lt;h4&gt;方法&lt;/h4&gt;研究使用了一种可以调整的眼模型来验证所提出的框架的有效性。评估了该工作流程在不同轴向的误差，并分析了可能的误差来源。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，优化后的框架能够以平均0.13度（Y轴旋转），-1.40度（X轴旋转）和1.80毫米（深度Z方向）的误差达到目标位置。这些误差在临床上是可接受的。&lt;h4&gt;结论&lt;/h4&gt;该优化框架可以提高手术机器人系统的目标可达性，并减少重置准备过程的可能性，具有显著的实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经完整地进行了中文翻译并以JSON格式呈现出来。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Several robotic frameworks have been recently developed to assist ophthalmicsurgeons in performing complex vitreoretinal procedures such as subretinalinjection of advanced therapeutics. These surgical robots show promisingcapabilities; however, most of them have to limit their working volume toachieve maximum accuracy. Moreover, the visible area seen through the surgicalmicroscope is limited and solely depends on the eye posture. If the eyeposture, trocar position, and robot configuration are not correctly arranged,the instrument may not reach the target position, and the preparation will haveto be redone. Therefore, this paper proposes the optimization framework of theeye tilting and the robot positioning to reach various target areas fordifferent patients. Our method was validated with an adjustable phantom eyemodel, and the error of this workflow was 0.13 +/- 1.65 deg (rotational jointaround Y axis), -1.40 +/- 1.13 deg (around X axis), and 1.80 +/- 1.51 mm(depth, Z). The potential error sources are also analyzed in the discussionsection.</description>
      <author>example@mail.com (Satoshi Inagaki, Alireza Alikhani, Nassir Navab, Peter C. Issa, M. Ali Nasseri)</author>
      <guid isPermaLink="false">2502.18230v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>iTrash: Incentivized Token Rewards for Automated Sorting and Handling</title>
      <link>http://arxiv.org/abs/2502.18161v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Article submitted to IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为iTrash的智能垃圾桶，用于提高小型办公室环境中的回收率。&lt;h4&gt;背景&lt;/h4&gt;随着机器人系统的自主性增强，它们越来越多地被应用于小空间和办公环境中进行自动化任务。&lt;h4&gt;目的&lt;/h4&gt;通过引入一种新型智能垃圾桶iTrash来改善小型办公区域内的垃圾分类效率，并收集有关用户行为及垃圾箱使用模式的有价值数据。&lt;h4&gt;方法&lt;/h4&gt;进行了为期5天的实验以评估iTrash相较于传统垃圾桶的优势，发现其回收率提高了30%以上。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，使用智能垃圾桶不仅能提高回收利用率，还能提供诸如用户行为和垃圾桶使用情况等重要信息，这些是普通垃圾桶无法获取的数据。利用这些数据可以预测并优化某些任务。&lt;h4&gt;结论&lt;/h4&gt;探索了通过区块链技术创建经济激励机制以促进回收活动的可能性，采用了节约型付费模式（Save-as-you-Throw, SAYT）。&lt;h4&gt;翻译&lt;/h4&gt;随着机器人系统的自主性增强，它们越来越多地被应用于小空间和办公环境中进行自动化任务。本文提出了一种名为iTrash的智能垃圾桶，用于提高小型办公室环境中的回收率。进行了为期5天的实验以评估iTrash相较于传统垃圾桶的优势，发现其回收率提高了30%以上。研究结果表明，使用这种新型智能垃圾桶不仅能提高回收利用率，还能提供诸如用户行为和垃圾箱使用情况等重要信息，这些是普通垃圾桶无法获取的数据。利用这些数据可以预测并优化某些任务。最后，本文探讨了通过区块链技术创建经济激励机制以促进回收活动的可能性，并采用了节约型付费模式（Save-as-you-Throw, SAYT）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As robotic systems (RS) become more autonomous, they are becomingincreasingly used in small spaces and offices to automate tasks such ascleaning, infrastructure maintenance, or resource management. In this paper, wepropose iTrash, an intelligent trashcan that aims to improve recycling rates insmall office spaces. For that, we ran a 5 day experiment and found that iTrashcan produce an efficiency increase of more than 30% compared to traditionaltrashcans. The findings derived from this work, point to the fact that usingiTrash not only increase recyclying rates, but also provides valuable data suchas users behaviour or bin usage patterns, which cannot be taken from a normaltrashcan. This information can be used to predict and optimize some tasks inthese spaces. Finally, we explored the potential of using blockchain technologyto create economic incentives for recycling, following a Save-as-you-Throw(SAYT) model.</description>
      <author>example@mail.com (Pablo Ortega, Eduardo Castelló Ferrer)</author>
      <guid isPermaLink="false">2502.18161v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>A Real-time Spatio-Temporal Trajectory Planner for Autonomous Vehicles with Semantic Graph Optimization</title>
      <link>http://arxiv.org/abs/2502.18151v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted for publication in IEEE Robotics and  Automation Letters (RA-L). The final published version is available in IEEE  Xplore (DOI: 10.1109/LRA.2024.3504239)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图优化的空间时间轨迹规划方法，用于实时为自主车辆在复杂城市环境中计划安全和可行的路径。&lt;h4&gt;背景&lt;/h4&gt;在复杂的城市环境中，通过充分利用感知信息实现实时的安全且可行的自动驾驶车辆轨迹规划是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种高效的多模式感知信息提取及快速生成可行路径的方法。&lt;h4&gt;方法&lt;/h4&gt;通过构建语义空间时间图并通过静态和动态障碍物的分离处理有效提取感知模块的多模态信息，然后基于语义空间时间超图进行稀疏图优化快速生成轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法能够有效地处理复杂的城区公共道路场景，并能在实时运行中表现出色。&lt;h4&gt;结论&lt;/h4&gt;该研究方法在复杂的城市环境中的性能得到了验证。此外还将发布代码供科研社区使用以支持基准测试。&lt;h4&gt;翻译&lt;/h4&gt;计划在复杂城市环境中，为自主车辆在实时内利用感知信息规划出安全且可行的轨迹是一项挑战。本文提出了一种基于图优化的空间时间轨迹规划方法。该方法通过构建语义空间时间图，并对静态和动态障碍物进行分离处理以有效提取感知模块的多模态信息，然后通过基于语义空间时间超图的稀疏图优化快速生成可行路径。大量实验表明所提出的方法能够有效地应对复杂的城区公共道路场景并能实时运行。我们也将发布代码来支持科研社区的基准测试研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2024.3504239&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Planning a safe and feasible trajectory for autonomous vehicles in real-timeby fully utilizing perceptual information in complex urban environments ischallenging. In this paper, we propose a spatio-temporal trajectory planningmethod based on graph optimization. It efficiently extracts the multi-modalinformation of the perception module by constructing a semantic spatio-temporalmap through separation processing of static and dynamic obstacles, and thenquickly generates feasible trajectories via sparse graph optimization based ona semantic spatio-temporal hypergraph. Extensive experiments have proven thatthe proposed method can effectively handle complex urban public road scenariosand perform in real time. We will also release our codes to accommodatebenchmarking for the research community</description>
      <author>example@mail.com (Shan He, Yalong Ma, Tao Song, Yongzhi Jiang, Xinkai Wu)</author>
      <guid isPermaLink="false">2502.18151v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Reusability of Learned Skills for Robot Manipulation via Gaze and Bottleneck</title>
      <link>http://arxiv.org/abs/2502.18121v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的算法GazeBot，该算法通过利用注视信息和运动瓶颈来提高机器人操作的可重用性。&lt;h4&gt;背景&lt;/h4&gt;虽然深度学习的进步使得复制人类远程操作机器人的灵巧度变得越来越可行，但是将这些获得的能力推广到未见过的情景中仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的算法GazeBot，以克服现有模仿学习方法在泛化性能方面的限制。&lt;h4&gt;方法&lt;/h4&gt;利用注视信息和运动瓶颈作为关键特征来提高机器人的操作技能的可重用性。通过提供带有注视数据的演示数据集，整个训练过程是完全基于数据驱动的。&lt;h4&gt;主要发现&lt;/h4&gt;GazeBot算法实现了比现有模仿学习方法更高的泛化性能，并且不牺牲其灵巧性和反应能力。&lt;h4&gt;结论&lt;/h4&gt;提供的视频和代码可以在https://crumbyrobotics.github.io/gazebot获取。&lt;h4&gt;翻译&lt;/h4&gt;自主代理能够进行多样化的物体操作，应该能够以高可重用性的方式获得广泛的操纵技能。尽管深度学习的进步使得复制人类远程操作的灵巧度在机器人中变得越来越可行，但将这些获得的能力推广到未见过的情景中仍然是一个挑战。在这项研究中，我们提出了一种新的算法GazeBot（基于注视信息和运动瓶颈感知的机器人操作），它即使当物体位置和末端执行器姿态与提供的演示不同时，也能实现所学动作的高可重用性。通过利用注视信息和运动瓶颈作为进行物体操作的关键特征，GazeBot在泛化性能方面相比当前最先进的模仿学习方法具有显著优势，同时不牺牲其灵巧性和反应能力。此外，在提供带有注视数据的演示数据集之后，GazeBot的训练过程完全基于数据驱动。视频和代码可在https://crumbyrobotics.github.io/gazebot获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous agents capable of diverse object manipulations should be able toacquire a wide range of manipulation skills with high reusability. Althoughadvances in deep learning have made it increasingly feasible to replicate thedexterity of human teleoperation in robots, generalizing these acquired skillsto previously unseen scenarios remains a significant challenge. In this study,we propose a novel algorithm, Gaze-based Bottleneck-aware Robot Manipulation(GazeBot), which enables high reusability of the learned motions even when theobject positions and end-effector poses differ from those in the provideddemonstrations. By leveraging gaze information and motion bottlenecks, bothcrucial features for object manipulation, GazeBot achieves high generalizationperformance compared with state-of-the-art imitation learning methods, withoutsacrificing its dexterity and reactivity. Furthermore, the training process ofGazeBot is entirely data-driven once a demonstration dataset with gaze data isprovided. Videos and code are available athttps://crumbyrobotics.github.io/gazebot.</description>
      <author>example@mail.com (Ryo Takizawa, Izumi Karino, Koki Nakagawa, Yoshiyuki Ohmura, Yasuo Kuniyoshi)</author>
      <guid isPermaLink="false">2502.18121v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>MRBTP: Efficient Multi-Robot Behavior Tree Planning and Collaboration</title>
      <link>http://arxiv.org/abs/2502.18072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了一种名为MRBTP的多机器人行为树规划算法，适用于同质和异质机器人群体，并具有理论上的完整性和正确性保证。&lt;h4&gt;背景&lt;/h4&gt;在机器人领域，多机器人任务规划与协作是非常关键的问题。尽管行为树（BT）作为一种流行控制架构被广泛应用于单个机器人的规划中，但为多机器人开发有效的BT规划算法仍然面临复杂性挑战。&lt;h4&gt;目的&lt;/h4&gt;为了应对协调不同动作空间的复杂性问题，论文旨在设计一种适用于同质和异质多机器人群体的行为树规划方法，并探讨如何利用大型语言模型进一步提高其效率。&lt;h4&gt;方法&lt;/h4&gt;MRBTP算法通过跨树扩展实现异构动作之间的协调；对于同类动作，则保留各行为树间的备份结构以确保鲁棒性及避免冗余执行。此外，当有大型语言模型可用时，MRBTP可以额外使用此插件来预规划与目标相关的长时期子树。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估表明，在仓库管理和日常服务场景下，MRBTP算法表现出良好的稳健性和执行效率，并且借助于预先训练的语言模型生成的任务特定子树能显著提高其计划速度和协作效率。&lt;h4&gt;结论&lt;/h4&gt;论文提出了一种适用于同质与异质机器人群体的多机器人行为树规划方法MRBTP，并证明了该方法在实际应用中的有效性和优越性。此外，通过引入大型语言模型插件进一步提升了算法的速度和效果。&lt;h4&gt;翻译&lt;/h4&gt;Multi-robot task planning and collaboration are critical challenges in robotics. While Behavior Trees (BTs) have been established as a popular control architecture for single robots, the development of effective multi-robot BT planning algorithms remains challenging due to the complexity of coordinating diverse action spaces. The paper proposes the Multi-Robot Behavior Tree Planning (MRBTP) algorithm with theoretical guarantees of soundness and completeness. MRBTP features cross-tree expansion to coordinate heterogeneous actions across different BTs for achieving team goals, and retains backup structures among homogeneous actions to ensure robustness and prevent redundant execution through intention sharing. Additionally, when available, a plugin using Large Language Models (LLMs) can pre-plan goal-related actions forming long-horizon subtrees significantly enhancing planning speed and collaboration efficiency. Evaluations in warehouse management and everyday service scenarios demonstrate MRBTP's robustness and execution efficiency under varying settings, along with the ability of the pre-trained LLM to generate effective task-specific subtrees for MRBTP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-robot task planning and collaboration are critical challenges inrobotics. While Behavior Trees (BTs) have been established as a popular controlarchitecture and are plannable for a single robot, the development of effectivemulti-robot BT planning algorithms remains challenging due to the complexity ofcoordinating diverse action spaces. We propose the Multi-Robot Behavior TreePlanning (MRBTP) algorithm, with theoretical guarantees of both soundness andcompleteness. MRBTP features cross-tree expansion to coordinate heterogeneousactions across different BTs to achieve the team's goal. For homogeneousactions, we retain backup structures among BTs to ensure robustness and preventredundant execution through intention sharing. While MRBTP is capable ofgenerating BTs for both homogeneous and heterogeneous robot teams, itsefficiency can be further improved. We then propose an optional plugin forMRBTP when Large Language Models (LLMs) are available to reason goal-relatedactions for each robot. These relevant actions can be pre-planned to formlong-horizon subtrees, significantly enhancing the planning speed andcollaboration efficiency of MRBTP. We evaluate our algorithm in warehousemanagement and everyday service scenarios. Results demonstrate MRBTP'srobustness and execution efficiency under varying settings, as well as theability of the pre-trained LLM to generate effective task-specific subtrees forMRBTP.</description>
      <author>example@mail.com (Yishuai Cai, Xinglin Chen, Zhongxuan Cai, Yunxin Mao, Minglong Li, Wenjing Yang, Ji Wang)</author>
      <guid isPermaLink="false">2502.18072v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>HEROS-GAN: Honed-Energy Regularized and Optimal Supervised GAN for Enhancing Accuracy and Range of Low-Cost Accelerometers</title>
      <link>http://arxiv.org/abs/2502.18064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI Oral; AI for Sensors; Generative Deep Learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的生成对抗网络HEROS-GAN，用于改善低成本加速度计的精度和范围限制问题。&lt;h4&gt;背景&lt;/h4&gt;低成本加速度计因其体积小、易于集成、穿戴舒适以及可大规模生产等优点，在汽车系统、航空航天及可穿戴技术等领域得到广泛应用。然而，此类传感器存在严重的准确度与量程局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够将低成本传感器信号转化为高成本等价信号的技术，以克服低性能加速度计的精度和范围限制问题。&lt;h4&gt;方法&lt;/h4&gt;{'HEROS-GAN': '一种能量调节和最优监督生成对抗网络，用于改善低成本加速度计信号的质量。', 'OTS': '基于最优传输理论探索未配对数据之间的潜在一致性，最大化监督信息的方法。', 'MLE': '调制拉普拉斯能量注入方法，旨在鼓励生成器打破范围限制、增强局部变化并丰富信号细节。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'性能提升': '实验结果显示单独使用OTS或MLE的GAN相比现有信号增强SOTA方法有显著提升。', '综合效果': '结合OTS和MLE后，HEROS-GAN能够将加速度计范围加倍，并降低信号噪声两个数量级，在加速度计信号处理方面建立了一个新的基准。'}&lt;h4&gt;结论&lt;/h4&gt;通过引入HEROS-GAN及其相关技术，本研究为解决低成本加速度计的精度与量程限制提供了有效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了用于改善低成本加速度计性能的技术方法和实验结果，包括提出的框架HEROS-GAN以及专门建立的数据集LASED。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-cost accelerometers play a crucial role in modern society due to theiradvantages of small size, ease of integration, wearability, and massproduction, making them widely applicable in automotive systems, aerospace, andwearable technology. However, this widely used sensor suffers from severeaccuracy and range limitations. To this end, we propose a honed-energyregularized and optimal supervised GAN (HEROS-GAN), which transforms low-costsensor signals into high-cost equivalents, thereby overcoming the precision andrange limitations of low-cost accelerometers. Due to the lack of frame-levelpaired low-cost and high-cost signals for training, we propose an OptimalTransport Supervision (OTS), which leverages optimal transport theory toexplore potential consistency between unpaired data, thereby maximizingsupervisory information. Moreover, we propose a Modulated Laplace Energy (MLE),which injects appropriate energy into the generator to encourage it to breakrange limitations, enhance local changes, and enrich signal details. Given theabsence of a dedicated dataset, we specifically establish a Low-costAccelerometer Signal Enhancement Dataset (LASED) containing tens of thousandsof samples, which is the first dataset serving to improve the accuracy andrange of accelerometers and is released in Github. Experimental resultsdemonstrate that a GAN combined with either OTS or MLE alone can surpass theprevious signal enhancement SOTA methods by an order of magnitude. Integratingboth OTS and MLE, the HEROS-GAN achieves remarkable results, which doubles theaccelerometer range while reducing signal noise by two orders of magnitude,establishing a benchmark in the accelerometer signal processing.</description>
      <author>example@mail.com (Yifeng Wang, Yi Zhao)</author>
      <guid isPermaLink="false">2502.18064v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Ordered Genetic Algorithm for Entrance Dependent Vehicle Routing Problem in Farms</title>
      <link>http://arxiv.org/abs/2502.18062v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的车辆路径问题（EDVRP），并针对农场场景提出了数学模型和一种有序遗传算法（OGA）来解决此问题。&lt;h4&gt;背景&lt;/h4&gt;在一些实际的车辆路径问题场景中，城市的规模及其入口数量对优化过程有着显著的影响。&lt;h4&gt;目的&lt;/h4&gt;为了应对上述情况，作者构建了依赖于入口的车辆路径问题（EDVRP），并通过实验验证了有序遗传算法的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了用于农场场景中的EDVRP数学模型，并开发了一种名为OGA的新颖遗传算法来解决该问题。此外还通过删除实验验证了新操作符的效果。&lt;h4&gt;主要发现&lt;/h4&gt;与随机策略基线和没有排序的遗传算法相比，OGA在优化过程中显示出一定的优势。新型的操作符也证明了它们对提高算法性能的有效性。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，针对特定场景设计的EDVRP及其相应的有序遗传算法可以在解决实际问题时提供更加有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;车辆路径问题是许多生产场景中广泛研究的重要议题。在某些实际应用场景下，城市的规模和入口数量显著影响优化过程。为了解决这一问题，作者构建了依赖于入口的车辆路径问题（EDVRP）以描述此类问题，并提供了农场场景下的数学模型以及提出了一种有序遗传算法（OGA）。通过多组随机生成案例实验表明，与基准线策略相比，OGA展示出一定的优势。此外，新引入的操作符在消除实验中证明了其对改进算法性能的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicle Routing Problems (VRP) are widely studied issues that play importantroles in many production scenarios. We have noticed that in some practicalscenarios of VRP, the size of cities and their entrances can significantlyinfluence the optimization process. To address this, we have constructed theEntrance Dependent VRP (EDVRP) to describe such problems. We provide amathematical formulation for the EDVRP in farms and propose an Ordered GeneticAlgorithm (OGA) to solve it. The effectiveness of OGA is demonstrated throughour experiments, which involve a multitude of randomly generated cases. Theresults indicate that OGA offers certain advantages compared to a randomstrategy baseline and a genetic algorithm without ordering. Furthermore, thenovel operators introduced in this paper have been validated through ablationexperiments, proving their effectiveness in enhancing the performance of thealgorithm.</description>
      <author>example@mail.com (Haotian Xu, Xiaohui Fan, Jialin Zhu, Qing Zhuo, Tao Zhang)</author>
      <guid isPermaLink="false">2502.18062v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>S-Graphs 2.0 -- A Hierarchical-Semantic Optimization and Loop Closure for SLAM</title>
      <link>http://arxiv.org/abs/2502.18044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 9 figures, RAL submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的机器人定位和制图算法Situation Graphs 2.0，该算法利用室内场景的层次结构来提高数据管理和优化效率。通过构建四个层级的情境图形（关键帧、墙壁、房间、楼层），实现了更高效的多层环境中的姿态管理与地图优化。&lt;h4&gt;背景&lt;/h4&gt;基于定位和制图的方法通常没有充分利用环境中固有的语义信息，导致机器人姿势不准确且在大规模环境下计算效率低下。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来利用3D场景图形的层次化表示来提高机器人位置管理和优化的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 构建包含关键帧、墙壁、房间、楼层四个层级的情境图；2. 前端模块包括一个能识别楼梯并分配楼层级语义关系的楼层检测模块，这使得可以拒绝视觉上相似但位于不同楼层区域中的假阳性闭环；3. 利用层次结构进行改进优化，包括局部优化、楼层面全局优化和房间级别局部优化。&lt;h4&gt;主要发现&lt;/h4&gt;Situation Graphs 2.0 在多层真实环境中表现出了优越的性能，并能够创建层级地图同时限制计算复杂性，而一些基准方法在大规模场景中难以有效执行。&lt;h4&gt;结论&lt;/h4&gt;Situation Graphs 2.0 是一种有效的机器人定位和制图算法，在大型多层环境中的数据管理和优化方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Works based on localization and mapping do not exploit the inherentsemantic-relational information from the environment for faster and efficientmanagement and optimization of the robot poses and its map elements, oftenleading to pose and map inaccuracies and computational inefficiencies in largescale environments. 3D scene graph representations which distributes theenvironment in an hierarchical manner can be exploited to enhance themanagement/optimization of underlying robot poses and its map.  In this direction, we present our work Situational Graphs 2.0, whichleverages the hierarchical structure of indoor scenes for efficient datamanagement and optimization. Our algorithm begins by constructing a situationalgraph that organizes the environment into four layers: Keyframes, Walls, Rooms,and Floors. Our first novelty lies in the front-end which includes a floordetection module capable of identifying stairways and assigning a floor-levelsemantic-relations to the underlying layers. This floor-level semantic enablesa floor-based loop closure strategy, rejecting false-positive loop closures invisually similar areas on different floors. Our second novelty is in exploitingthe hierarchy for an improved optimization. It consists of: (1) localoptimization, optimizing a window of recent keyframes and their connectedcomponents, (2) floor-global optimization, which focuses only on keyframes andtheir connections within the current floor during loop closures, and (3)room-local optimization, marginalizing redundant keyframes that shareobservations within the room.  We validate our algorithm extensively in different real multi-floorenvironments. Our approach can demonstrate state-of-art-art results in largescale multi-floor environments creating hierarchical maps while bounding thecomputational complexity where several baseline works fail to executeefficiently.</description>
      <author>example@mail.com (Hriday Bavle, Jose Luis Sanchez-Lopez, Muhammad Shaheer, Javier Civera, Holger Voos)</author>
      <guid isPermaLink="false">2502.18044v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Interaction and Intention Communication for Industrial Robots</title>
      <link>http://arxiv.org/abs/2502.17971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the 1st German Robotics Conference (GRC)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种设计和评估非人形工业机器人表达性的人机交互系统的方法，特别是通过一个小类人的机器人作为其主机（如叉车）的代理来沟通。&lt;h4&gt;背景&lt;/h4&gt;为了实现高级的人机交互水平，工业机器人需要能够安全有效地在人类环境中操作、进行自然交流、理解用户，并以直观的方式表达意图而不引起不必要的干扰。&lt;h4&gt;目的&lt;/h4&gt;论文旨在为非人形工业机器人设计和增强表达性的人机交互系统，通过开发一种结合语音、运动等多种模态的多模式通信框架来实现这一目标。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种概念，即使用一个小类人的机器人作为非人形主机（例如叉车）的代理进行交流，并为此机器人开发了一个多模态和大型语言模型增强的通讯框架。实验通过凝视追踪和动作捕捉技术量化了用户对机器人的感知以及任务进度。&lt;h4&gt;主要发现&lt;/h4&gt;论文展示了如何通过结合不同通信方式，可以使工业机器人在人机交互中更加有效且自然地交流。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，使用多模态通讯框架的表达性人机交互系统对于提高非人形工业机器人的互动性和用户接受度至关重要。&lt;h4&gt;翻译&lt;/h4&gt;成功的工业机器人采用将强烈依赖于它们能够在人类环境中安全有效地操作、进行自然沟通、理解用户，并以直观的方式表达意图而不引起不必要的干扰。为了实现这种高级水平的人机交互，机器人需要获取并整合对用户任务和环境的知识，并采取结合语音、动作等多模态的通讯方式。本文介绍了一些设计、增强和完善非人形工业机器人表达性人机交互系统的方案。我们提出了一个小型类人机器人作为其主机（如叉车）的代理进行沟通的概念，为此机器人开发了一个多模式且增强了大型语言模型的通信框架，并通过实验室实验进行了评估。这些实验利用凝视追踪和动作捕捉技术量化了用户对机器人的感知以及任务进度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Successful adoption of industrial robots will strongly depend on theirability to safely and efficiently operate in human environments, engage innatural communication, understand their users, and express intentionsintuitively while avoiding unnecessary distractions. To achieve this advancedlevel of Human-Robot Interaction (HRI), robots need to acquire and incorporateknowledge of their users' tasks and environment and adopt multimodalcommunication approaches with expressive cues that combine speech, movement,gazes, and other modalities. This paper presents several methods to design,enhance, and evaluate expressive HRI systems for non-humanoid industrialrobots. We present the concept of a small anthropomorphic robot communicatingas a proxy for its non-humanoid host, such as a forklift. We developed amultimodal and LLM-enhanced communication framework for this robot andevaluated it in several lab experiments, using gaze tracking and motion captureto quantify how users perceive the robot and measure the task progress.</description>
      <author>example@mail.com (Tim Schreiter, Andrey Rudenko, Jens V. Rüppel, Martin Magnusson, Achim J. Lilienthal)</author>
      <guid isPermaLink="false">2502.17971v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Quadrotor Neural Dead Reckoning in Periodic Trajectories</title>
      <link>http://arxiv.org/abs/2502.17964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于神经网络的四旋翼无人机死 reckoning 方法，用于在纯惯性导航模式下飞行时提高定位精度。&lt;h4&gt;背景&lt;/h4&gt;由于环境或硬件限制，在室内和室外操作时，四旋翼无人机被迫以纯惯性导航模式运行。这导致了惯性漂移的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来增强基于周期轨迹的四旋翼无人机在纯惯性导航模式下的定位性能。&lt;h4&gt;方法&lt;/h4&gt;采用了一种简单的高效神经网络模型直接从惯性读数中估计四旋翼的位置向量，而不是将距离回归与基于惯性模型的方向估计相结合的方法。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过仅进行软件修改，在室外实现了平均误差降低 27%，在室内实现平均误差降低了 79% 的定位精度提升。&lt;h4&gt;结论&lt;/h4&gt;改进的定位准确度使得四旋翼无人机可以无缝地完成其任务，而无需额外的硬件支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：现实世界中，由于环境或硬件限制，在室内或室外操作时，四旋翼被迫以纯惯性导航模式运行。为减少惯性漂移，提出了结合了四旋翼周期轨迹的端到端神经网络方法。其中，通过回归四旋翼距离并将其与基于惯性模型的方向估计相结合来估算四旋翼的位置向量。为了进一步增强定位性能，在本文中我们提出了一种针对沿周期轨迹飞行的四旋翼无人机的神经死 reckoning 方法。在这种情况下，惯性读数被馈送到一个简单而高效的网络中以直接估计四旋翼位置向量。我们的方法在两种不同的四旋翼上进行了评估：一种在室内操作，另一种在室外操作。与深度学习方法相比，我们的方法提高了定位精度，在户外平均误差减少了 27%，在室内减少了 79%，并且只需要软件修改。通过我们方法实现的改进定位准确度，四旋翼可以无缝执行其任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real world scenarios, due to environmental or hardware constraints, thequadrotor is forced to navigate in pure inertial navigation mode whileoperating indoors or outdoors. To mitigate inertial drift, end-to-end neuralnetwork approaches combined with quadrotor periodic trajectories weresuggested. There, the quadrotor distance is regressed and combined withinertial model-based heading estimation, the quadrotor position vector isestimated. To further enhance positioning performance, in this paper we proposea quadrotor neural dead reckoning approach for quadrotors flying on periodictrajectories. In this case, the inertial readings are fed into a simple andefficient network to directly estimate the quadrotor position vector. Ourapproach was evaluated on two different quadrotors, one operating indoors whilethe other outdoors. Our approach improves the positioning accuracy of otherdeep-learning approaches, achieving an average 27% reduction in error outdoorsand an average 79% reduction indoors, while requiring only softwaremodifications. With the improved positioning accuracy achieved by our method,the quadrotor can seamlessly perform its tasks.</description>
      <author>example@mail.com (Shira Massas, Itzik Klein)</author>
      <guid isPermaLink="false">2502.17964v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>InVDriver: Intra-Instance Aware Vectorized Query-Based Autonomous Driving Transformer</title>
      <link>http://arxiv.org/abs/2502.17949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to JICV (Journal of Intelligent and Connected Vehicles)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了InVDriver系统，这是一种新型的向量化查询框架，用于解决现有自动驾驶中基于点的空间关联忽略问题，从而提高规划精度和轨迹平滑度。&lt;h4&gt;背景&lt;/h4&gt;端到端自动驾驶因其整体优化能力而在学术界和工业界越来越受到关注。向量化表示方法通过保留实例级别的拓扑信息并减少计算开销而变得流行起来。然而，现有的向量化查询框架往往忽略了实例内部点之间的空间关联，导致几何不一致的输出。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有系统的问题，提出了一种新的基于向量化的查询系统InVDriver，它通过屏蔽自注意力层系统地建模了实例内空间依赖关系。&lt;h4&gt;方法&lt;/h4&gt;InVDriver在感知、预测和规划的所有核心模块中都集成了屏蔽的自我注意机制，这些机制限制了对内部点交互的关注，并允许结构元素的同时细化，同时抑制不相关的跨实例噪声。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在nuScenes基准测试上，InVDriver实现了最先进的性能，超越了先前的方法，不仅在精度和安全性方面表现出色，而且还保持了计算效率。这验证了对实例内部几何一致性进行显式建模对于向量化自动驾驶系统的重要性，弥合了端到端框架的理论优势与实际部署需求之间的差距。&lt;h4&gt;结论&lt;/h4&gt;InVDriver通过精确建模空间依赖关系来改进端到端自动驾驶系统的性能和可靠性，证明了在自动驾驶技术中引入这种新方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;端到端自主驾驶因其整体优化能力，在学术界和工业界越来越受欢迎。向量化表示方法由于保留实例级别的拓扑信息并且减少计算负担而崭露头角。然而，现有的基于查询的框架往往忽视了实例内点之间的固有空间关联，导致几何不一致的结果（例如片段化的HD地图元素或振荡轨迹）。为了解决这些问题，我们提出了InVDriver——一个新颖的向量化查询系统，通过屏蔽自注意力层来系统性地建模内部的空间依赖关系，从而提高规划精度和轨迹平滑度。在感知、预测以及规划的所有核心模块中，InVDriver采用了屏蔽自注意机制，这种机制限制了对内部点交互的关注，允许同时优化结构元素的同时抑制无关的跨实例噪音。实验结果表明，在nuScenes基准测试上，InVDriver实现了最先进的性能，并且超过了之前的方法在准确性和安全性方面的要求，同时保持了高计算效率。我们的工作验证了显式建模内部几何一致性的关键性对于推进向量化自动驾驶系统的重要性，这使得端到端框架的理论优势和实际部署要求之间差距得以缩小。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; End-to-end autonomous driving with its holistic optimization capabilities,has gained increasing traction in academia and industry. Vectorizedrepresentations, which preserve instance-level topological information whilereducing computational overhead, have emerged as a promising paradigm. Whileexisting vectorized query-based frameworks often overlook the inherent spatialcorrelations among intra-instance points, resulting in geometricallyinconsistent outputs (e.g., fragmented HD map elements or oscillatorytrajectories). To address these limitations, we propose InVDriver, a novelvectorized query-based system that systematically models intra-instance spatialdependencies through masked self-attention layers, thereby enhancing planningaccuracy and trajectory smoothness. Across all core modules, i.e., perception,prediction, and planning, InVDriver incorporates masked self-attentionmechanisms that restrict attention to intra-instance point interactions,enabling coordinated refinement of structural elements while suppressingirrelevant inter-instance noise. Experimental results on the nuScenes benchmarkdemonstrate that InVDriver achieves state-of-the-art performance, surpassingprior methods in both accuracy and safety, while maintaining high computationalefficiency. Our work validates that explicit modeling of intra-instancegeometric coherence is critical for advancing vectorized autonomous drivingsystems, bridging the gap between theoretical advantages of end-to-endframeworks and practical deployment requirements.</description>
      <author>example@mail.com (Bo Zhang, Heye Huang, Chunyang Liu, Yaqin Zhang, Zhenhua Xu)</author>
      <guid isPermaLink="false">2502.17949v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>corobos: A Design for Mobile Robots Enabling Cooperative Transitions between Table and Wall Surfaces</title>
      <link>http://arxiv.org/abs/2502.17868v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CHI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': 'corobos 是一种概念设计，使得多机器人系统能够在没有人为干预的情况下，在桌面和墙面之间平滑过渡。', '背景': '群组用户界面允许通过多个移动机器人的使用来动态安排用户环境，但由于其两轮推进系统的限制，操作范围通常局限于单一平面。', '目的': '展示 corobos 设计概念，该设计让机器人能够在水平面（桌面）和垂直面（墙面）之间平滑过渡，而无需额外的主动电气组件。', '方法': '每个机器人都装备了独特的斜坡结构，在其他机器人推动时能够实现平稳旋转。研究了这种结构的设计参数，并通过实验评估其转换成功率。', '主要发现': '设计仅依赖于被动机械元件，无需额外的主动电气部件即可实现无缝过渡。', '结论': '展示了 corobos 的各种应用实例，证明其在增强用户环境中具有巨大潜力。', '翻译': 'Swarm User Interfaces 允许通过使用多个移动机器人来动态调整用户环境，但它们的操作范围通常受限于两轮推进系统的限制而局限于单一平面。我们提出了一种概念设计 corobos，使得这些机器人可以在没有人为干预的情况下，在水平的桌面和垂直的墙面之间平滑过渡。每个机器人都配备了独特的斜坡结构，在其他机器人推动时可以实现平稳旋转，并且这种设计仅依赖于被动机械元件，不需要额外的主动电气组件。我们研究了这一结构的设计参数并通过实验评估其转换成功率，此外还展示了各种应用示例以展示 corobos 在增强用户环境方面的潜力。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3713440&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Swarm User Interfaces allow dynamic arrangement of user environments throughthe use of multiple mobile robots, but their operational range is typicallyconfined to a single plane due to constraints imposed by their two-wheelpropulsion systems. We present corobos, a proof-of-concept design that enablesthese robots to cooperatively transition between table (horizontal) and wall(vertical) surfaces seamlessly, without human intervention. Each robot isequipped with a uniquely designed slope structure that facilitates smoothrotation when another robot pushes it toward a target surface. Notably, thisdesign relies solely on passive mechanical elements, eliminating the need foradditional active electrical components. We investigated the design parametersof this structure and evaluated its transition success rate throughexperiments. Furthermore, we demonstrate various application examples toshowcase the potential of corobos in enhancing user environments.</description>
      <author>example@mail.com (Changyo Han, Yosuke Nakagawa, Takeshi Naemura)</author>
      <guid isPermaLink="false">2502.17868v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Impact of Object Weight in Handovers: Inspiring Robotic Grip Release and Motion from Human Handovers</title>
      <link>http://arxiv.org/abs/2502.17834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Submission at IEEE-IEEE Transactions on Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项工作探讨了物体重量对人手交接过程中人体运动和抓取-释放动作的影响，旨在通过引入基于人类行为分析的自适应机器人策略来增强机器人与人的互动自然性、安全性和效率。&lt;h4&gt;背景&lt;/h4&gt;研究发现不同重量的物体会影响人在进行手部交互时的动作，这对设计更符合人类行为习惯的机器人至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够根据物体重量调整抓取-释放方式的自适应策略，提升机器人与人之间在不同重量物品交换过程中的表现和用户体验。&lt;h4&gt;方法&lt;/h4&gt;通过分析人在不同重量下进行手部交互的行为模式，提出并测试了基于人类行为模型的自适应机器人技术，并创建了一个包含多种物体重量数据集（包括YCB handover dataset）以验证策略的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;研究证明了提出的自适应抓取-释放技术和运动调整方法能够在自然度、效率和用户感知方面超越基准方法，显著改善机器人与人的手部交互体验。&lt;h4&gt;结论&lt;/h4&gt;通过将机器人的动作设计得更接近于人类的行为模式，可以大大提高机器人在处理不同重量物品时的手动交换过程的安全性和流畅性。这项工作为进一步研究提供了重要数据和理论基础。&lt;h4&gt;翻译&lt;/h4&gt;这项工作的摘要描述了一项探索物体重量对人手交接中人体运动及抓取释放行为影响的研究，旨在通过引入基于人类交互分析的自适应机器人策略来提升机器人的自然、安全且高效的人机互动能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work explores the effect of object weight on human motion and griprelease during handovers to enhance the naturalness, safety, and efficiency ofrobot-human interactions. We introduce adaptive robotic strategies based on theanalysis of human handover behavior with varying object weights. The keycontributions of this work includes the development of an adaptive grip-releasestrategy for robots, a detailed analysis of how object weight influences humanmotion to guide robotic motion adaptations, and the creation ofhandover-datasets incorporating various object weights, including the YCBhandover dataset. By aligning robotic grip release and motion with humanbehavior, this work aims to improve robot-human handovers for differentweighted objects. We also evaluate these human-inspired adaptive roboticstrategies in robot-to-human handovers to assess their effectiveness andperformance and demonstrate that they outperform the baseline approaches interms of naturalness, efficiency, and user perception.</description>
      <author>example@mail.com (Parag Khanna, Mårten Björkman, Christian Smith)</author>
      <guid isPermaLink="false">2502.17834v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>CAML: Collaborative Auxiliary Modality Learning for Multi-Agent Systems</title>
      <link>http://arxiv.org/abs/2502.17821v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Collaborative Auxiliary Modality Learning (CAML)，一种新型的多智能体跨模态学习框架，适用于动态环境如自动驾驶车辆，并通过实验验证了其在事故检测和协作语义分割中的效果。&lt;h4&gt;背景&lt;/h4&gt;现有的跨模态学习方法主要在单个代理环境下工作，在具有复杂动态环境的情况下会导致决策盲点问题。这些问题尤其影响到连接自主汽车（CAV）的安全性和性能。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的多智能体框架，使多个代理能够共享和协作使用多种模式的数据，并且能够在测试期间减少每个代理的模态输入。&lt;h4&gt;方法&lt;/h4&gt;提出了CAML框架，在训练时允许跨模态数据的合作，并在测试阶段可以进行单个模式的推理。该框架特别关注不确定性的降低和数据覆盖范围的增加，提供了理论上的优势分析。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有技术相比，CAML能显著提高事故检测准确率（最高提升58.13%）；同时，在真实的空地机器人协作语义分割任务中也表现出色，达到了高达10.61%mIoU的改进。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了CAML在解决动态环境下的决策问题方面具有巨大潜力，并为进一步的研究提供了一个新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modality learning has become a crucial technique for improving theperformance of machine learning applications across domains such as autonomousdriving, robotics, and perception systems. While existing frameworks such asAuxiliary Modality Learning (AML) effectively utilize multiple data sourcesduring training and enable inference with reduced modalities, they primarilyoperate in a single-agent context. This limitation is particularly critical indynamic environments, such as connected autonomous vehicles (CAV), whereincomplete data coverage can lead to decision-making blind spots. To addressthese challenges, we propose Collaborative Auxiliary Modality Learning($\textbf{CAML}$), a novel multi-agent multi-modality framework that enablesagents to collaborate and share multimodal data during training while allowinginference with reduced modalities per agent during testing. We systematicallyanalyze the effectiveness of $\textbf{CAML}$ from the perspective ofuncertainty reduction and data coverage, providing theoretical insights intoits advantages over AML. Experimental results in collaborative decision-makingfor CAV in accident-prone scenarios demonstrate that \ours~achieves up to a${\bf 58.13}\%$ improvement in accident detection. Additionally, we validate$\textbf{CAML}$ on real-world aerial-ground robot data for collaborativesemantic segmentation, achieving up to a ${\bf 10.61}\%$ improvement in mIoU.</description>
      <author>example@mail.com (Rui Liu, Yu Shen, Peng Gao, Pratap Tokekar, Ming Lin)</author>
      <guid isPermaLink="false">2502.17821v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Safe Multi-Agent Navigation guided by Goal-Conditioned Safe Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.17813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Due to the limitation "The abstract field cannot be longer than 1,920  characters", the abstract here is shorter than that in the PDF file&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要类型&lt;/h4&gt;安全导航对于在危险环境中操作的自主系统至关重要。&lt;h4&gt;背景&lt;/h4&gt;传统规划方法擅长处理长时任务，但依赖于预定义的距离图。相比之下，安全强化学习（Safe RL）可以不用手动启发式就能学习复杂行为，但在目标条件和多代理场景中的长期任务中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合了规划与安全强化学习优点的新方法。&lt;h4&gt;方法&lt;/h4&gt;{'融合': '将目标导向的RL和安全RL结合来学习导航策略', '估算': '通过自动化自训练算法使用学得的价值函数同时估计累积距离和安全性水平', '图构建': '从回放缓存中构造状态图，并修剪不安全边，生成基于航点的计划'}&lt;h4&gt;主要发现&lt;/h4&gt;{'长时导航': '在扩展距离上有效平衡快速与安全路线。', '多代理问题': '利用冲突基础搜索（CBS）创建多个代理的安全路径规划，以解决长期范围内的多代理安全导航问题。这种方法提高了目标导向安全RL的可扩展性，并促进了代理之间的高效协调'}&lt;h4&gt;结论&lt;/h4&gt;{'效果证明': '通过广泛的基准测试，证明了该方法在复杂危险环境中实现多代理距离目标时的有效性和安全性。', '未来工作': '将发布代码以支持未来的相关研究。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Safe navigation is essential for autonomous systems operating in hazardousenvironments. Traditional planning methods excel at long-horizon tasks but relyon a predefined graph with fixed distance metrics. In contrast, safeReinforcement Learning (RL) can learn complex behaviors without relying onmanual heuristics but fails to solve long-horizon tasks, particularly ingoal-conditioned and multi-agent scenarios.  In this paper, we introduce a novel method that integrates the strengths ofboth planning and safe RL. Our method leverages goal-conditioned RL and safe RLto learn a goal-conditioned policy for navigation while concurrently estimatingcumulative distance and safety levels using learned value functions via anautomated self-training algorithm. By constructing a graph with states from thereplay buffer, our method prunes unsafe edges and generates a waypoint-basedplan that the agent follows until reaching its goal, effectively balancingfaster and safer routes over extended distances.  Utilizing this unified high-level graph and a shared low-levelgoal-conditioned safe RL policy, we extend this approach to address themulti-agent safe navigation problem. In particular, we leverage Conflict-BasedSearch (CBS) to create waypoint-based plans for multiple agents allowing fortheir safe navigation over extended horizons. This integration enhances thescalability of goal-conditioned safe RL in multi-agent scenarios, enablingefficient coordination among agents.  Extensive benchmarking against state-of-the-art baselines demonstrates theeffectiveness of our method in achieving distance goals safely for multipleagents in complex and hazardous environments. Our code will be released tosupport future research.</description>
      <author>example@mail.com (Meng Feng, Viraj Parimi, Brian Williams)</author>
      <guid isPermaLink="false">2502.17813v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Design of a Breakaway Utensil Attachment for Enhanced Safety in Robot-Assisted Feeding</title>
      <link>http://arxiv.org/abs/2502.17774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种新的机械安全机制，以提高机器人辅助喂食系统的安全性，并减轻护理者的负担。&lt;h4&gt;背景&lt;/h4&gt;现有的机器人辅助喂食系统主要依赖软件安全特性来减少意外碰撞时的风险。然而，这些方法在实际应用中可能不够可靠。&lt;h4&gt;目的&lt;/h4&gt;探索使用一种机械的紧急脱离装置，该装置能够在机器人施加过大力量时自动断开与用户的连接。&lt;h4&gt;方法&lt;/h4&gt;设计了一种可以分离力矩的手持餐具附件，并通过有限元分析（FEA）预测了不同加载条件下的失效点。之后利用3D打印技术制作带有各种槽深和壁环变化的样品，进行了实验验证。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在特定参数下（例如1毫米的槽深度和三个壁环），该装置在承受65牛顿力时能够按预期失效。此外，这种设计可以根据个人舒适度等因素进行调整，定制化安全脱开力度。&lt;h4&gt;结论&lt;/h4&gt;这项研究提供了一种创新的方法来提高机器人辅助喂食系统的安全性，并为未来的研究提供了有用的参数和设计方案。&lt;h4&gt;翻译&lt;/h4&gt;机器人辅助进食系统通过增强身体运动障碍个体的独立性并减轻护理人员的压力而发挥作用。尽管现有的系统主要依赖于基于软件的安全特性以在未预见的碰撞时降低风险，但本研究探讨了使用机械安全机制来提高安全性的问题。设计了一种可以在机器人施加力过大时从用户那里分离的餐具附件，从而防止对用户的伤害。通过有限元分析预测了不同加载条件下的失败点，并利用带有槽深和壁环变化的不同3D打印样品进行了实验验证。为了便于测试，开发并验证了一个跌落试验装置。结果显示，在1毫米深度的槽口和三个壁环的情况下，当施力达到65牛顿时会以预期的方式失效。此外，可以根据用户的特定因素（如舒适度和个人承受能力）调整参数来定制化脱开力量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot-assisted feeding systems enhance the independence of individuals withmotor impairments and alleviate caregiver burden. While existing systemspredominantly rely on software-based safety features to mitigate risks duringunforeseen collisions, this study explores the use of a mechanical fail-safe toimprove safety. We designed a breakaway utensil attachment that decouplesforces exerted by the robot on the user when excessive forces occur. Finiteelement analysis (FEA) simulations were performed to predict failure pointsunder various loading conditions, followed by experimental validation using3D-printed attachments with variations in slot depth and wall loops. Tofacilitate testing, a drop test rig was developed and validated. Our resultsdemonstrated a consistent failure point at the slot of the attachment, with aslot depth of 1 mm and three wall loops achieving failure at the target forceof 65 N. Additionally, the parameters can be tailored to customize thebreakaway force based on user-specific factors, such as comfort and paintolerance. CAD files and utensil assembly instructions can be found here:https://tinyurl.com/rfa-utensil-attachment</description>
      <author>example@mail.com (Hau Wen Chang, J-Anne Yow, Lek Syn Lim, Wei Tech Ang)</author>
      <guid isPermaLink="false">2502.17774v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Toward 6-DOF Autonomous Underwater Vehicle Energy-Aware Position Control based on Deep Reinforcement Learning: Preliminary Results</title>
      <link>http://arxiv.org/abs/2502.17742v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures, submitted to 2024 IEEE OES AUV Symposium&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于深度强化学习（DRL）的新颖方法，用于控制六自由度的自主水下航行器。使用截断分位数评论家(TQC)算法直接将命令发送给推进器，并且不需要关于推进器配置的知识。&lt;h4&gt;背景&lt;/h4&gt;在进行深海勘探时，自主水下航行器(AUVs)的操纵性和能源效率是关键因素，使得六自由度平台成为必备工具。PID和模型预测控制控制器尽管广泛使用，但它们需要准确的系统知识，并且面对负载或配置变化时难以重复。&lt;h4&gt;目的&lt;/h4&gt;开发一种新型基于深度强化学习的方法来增强自主水下航行器在六个自由度上的操作性能，同时减少能量消耗。&lt;h4&gt;方法&lt;/h4&gt;利用截断分位数评论家(TQC)算法作为控制工具，设计了一种无需手动调整的DRL控制系统，该系统可以直接将命令发送给推进器，并且考虑了功率消耗因素。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果表明，TQC高性能方法在达到目标点时的表现优于精细调优后的PID控制器。而能量感知型TQC方法虽然性能稍低，但平均节省了30%的能源。&lt;h4&gt;结论&lt;/h4&gt;TQC算法适用于六自由度AUVs控制，并且具有节能的优势，未来可能成为自主水下航行器控制领域的重要技术之一。&lt;h4&gt;翻译&lt;/h4&gt;论文摘要&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The use of autonomous underwater vehicles (AUVs) for surveying, mapping, andinspecting unexplored underwater areas plays a crucial role, wheremaneuverability and power efficiency are key factors for extending the use ofthese platforms, making six degrees of freedom (6-DOF) holonomic platformsessential tools. Although Proportional-Integral-Derivative (PID) and ModelPredictive Control controllers are widely used in these applications, theyoften require accurate system knowledge, struggle with repeatability whenfacing payload or configuration changes, and can be time-consuming tofine-tune. While more advanced methods based on Deep Reinforcement Learning(DRL) have been proposed, they are typically limited to operating in fewerdegrees of freedom. This paper proposes a novel DRL-based approach forcontrolling holonomic 6-DOF AUVs using the Truncated Quantile Critics (TQC)algorithm, which does not require manual tuning and directly feeds commands tothe thrusters without prior knowledge of their configuration. Furthermore, itincorporates power consumption directly into the reward function. Simulationresults show that the TQC High-Performance method achieves better performanceto a fine-tuned PID controller when reaching a goal point, while the TQCEnergy-Aware method demonstrates slightly lower performance but consumes 30%less power on average.</description>
      <author>example@mail.com (Gustavo Boré, Vicente Sufán, Sebastián Rodríguez-Martínez, Giancarlo Troni)</author>
      <guid isPermaLink="false">2502.17742v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>IBURD: Image Blending for Underwater Robotic Detection</title>
      <link>http://arxiv.org/abs/2502.17706v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种图像融合管道IBURD，用于生成逼真的合成图像，以辅助训练深度检测器在水下自主车辆（AUV）上进行海洋垃圾检测任务。&lt;h4&gt;背景&lt;/h4&gt;现有的数据集不足以满足复杂水下环境中的深度学习视觉算法的需求，特别是在数据稀缺和多样性方面存在明显问题。&lt;h4&gt;目的&lt;/h4&gt;通过生成具有实际海底背景的海洋垃圾图像来解决现有数据集的问题，并为使用AUV执行环保清理任务提供技术支持。&lt;h4&gt;方法&lt;/h4&gt;{'IBURD技术': '利用源图（包含目标物体）及其标注，以及目标环境背景图像作为输入；通过泊松编辑和风格迁移等技术将透明物体制作到任意背景中并自动调整合成图像的样式。', '生成方式': '能够基于源图和目标背景创建垃圾对象图像及像素级别的注释。', '图像质量改善': '使用目标背景图像的模糊度指标自动调整合成图像的风格，使输出更加真实且适配于具体场景。'}&lt;h4&gt;主要发现&lt;/h4&gt;IBURD在机器人检测海洋垃圾任务中的表现得到了验证，并展示了其有效性和实用性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够生成高质量的真实海底环境下的海洋垃圾图像，从而促进AUV在环保清理任务中应用的进一步发展。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种用于创建逼真合成图像以帮助训练水下自主车辆（AUV）上深度检测器来完成海洋垃圾检测任务的图像融合管道IBURD。具体来说，IBURD能够生成海底垃圾图像及其像素级标注，并使用源图中的物体、其注释以及目标背景环境图作为输入。利用泊松编辑和风格迁移等技术，IBURD甚至可以将透明物体制作到任意背景下并自动调整合成图片的样式以适应背景模糊度指标的变化。这些包含实际海底背景的真实海洋垃圾图像解决了深度学习视觉算法在挑战性水下条件下的数据稀缺与多样性问题，并促进了AUV用于环境清理任务的应用。通过定量和机器人评估证明了该方法在机器人检测海洋垃圾方面具有有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present an image blending pipeline, \textit{IBURD}, that creates realisticsynthetic images to assist in the training of deep detectors for use onunderwater autonomous vehicles (AUVs) for marine debris detection tasks.Specifically, IBURD generates both images of underwater debris and theirpixel-level annotations, using source images of debris objects, theirannotations, and target background images of marine environments. With Poissonediting and style transfer techniques, IBURD is even able to robustly blendtransparent objects into arbitrary backgrounds and automatically adjust thestyle of blended images using the blurriness metric of target backgroundimages. These generated images of marine debris in actual underwaterbackgrounds address the data scarcity and data variety problems faced bydeep-learned vision algorithms in challenging underwater conditions, and canenable the use of AUVs for environmental cleanup missions. Both quantitativeand robotic evaluations of IBURD demonstrate the efficacy of the proposedapproach for robotic detection of marine debris.</description>
      <author>example@mail.com (Jungseok Hong, Sakshi Singh, Junaed Sattar)</author>
      <guid isPermaLink="false">2502.17706v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>The Geometry of Optimal Gait Families for Steering Kinematic Locomoting Systems</title>
      <link>http://arxiv.org/abs/2502.17672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, submitted to IEEE Transactions on Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文探讨了基于蛇形机器人等复杂系统的运动规划，提出了一种生成连续优化步伐族的方法，并展示了如何利用全局和局部搜索策略构建这些最优步伐族。&lt;h4&gt;背景&lt;/h4&gt;对于类似于蛇机器人的系统来说，将高层次刚体任务转换为低层次的关节轨迹是一个更具挑战性的过程。这个映射依赖于当前配置并受到关节限制的约束。&lt;h4&gt;目的&lt;/h4&gt;该研究旨在提高复杂运动系统的控制性和机动性。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一种结合全局和局部搜索策略的方法来生成连续优化步伐族，其中局部搜索提供更高的精度但可能在非平滑区域不稳定，而全局搜索则对非平滑行为具有鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;研究揭示了最优步伐家族的底层几何结构，并展示了这种方法对于粘性和理想流体三连杆游泳器的有效性。&lt;h4&gt;结论&lt;/h4&gt;这项工作为低层次关节控制器与高层次运动规划器在复杂运动系统中的集成奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;运动计划通常需要将高层次刚性体任务转换成低层次的关节轨迹。这个过程对于具有固定、不受限制驱动输入的小车式机器人来说是直接明了的，但对于蛇形机器人等系统而言则更具挑战性。因为在这个情况下，映射取决于当前配置并受到关节限制的影响。在这篇论文中，我们关注于生成连续家族的最佳步伐集——用步伐大小或转向速率参数化的最佳步伐集合，以增强控制性和机动性。我们揭示了这些最佳步伐家族的底层几何结构，并提出了使用全局和局部搜索策略构建它们的方法，在这种方法中局部方法与全球方法相互补充。全局搜索方式对非平滑行为具有鲁棒性，尽管这导致了解决方案顺序降低，而局部搜索则提供了更高的精度但可能在非平滑区域不稳定。为了证明我们的框架的有效性，我们为粘性和理想流体三连杆游泳器生成了最佳的步伐家族。这项工作为基础运动规划器和低级关节控制器之间的集成奠定了基础，在复杂的运动系统中使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion planning for locomotion systems typically requires translatinghigh-level rigid-body tasks into low-level joint trajectories-a process that isstraightforward for car-like robots with fixed, unbounded actuation inputs butmore challenging for systems like snake robots, where the mapping depends onthe current configuration and is constrained by joint limits. In this paper, wefocus on generating continuous families of optimal gaits-collections of gaitsparameterized by step size or steering rate-to enhance controllability andmaneuverability. We uncover the underlying geometric structure of these optimalgait families and propose methods for constructing them using both global andlocal search strategies, where the local method and the global methodcompensate each other. The global search approach is robust to nonsmoothbehavior, albeit yielding reduced-order solutions, while the local searchprovides higher accuracy but can be unstable near nonsmooth regions. Todemonstrate our framework, we generate optimal gait families for viscous andperfect-fluid three-link swimmers. This work lays a foundation for integratinglow-level joint controllers with higher-level motion planners in complexlocomotion systems.</description>
      <author>example@mail.com (Jinwoo Choi, Siming Deng, Nathan Justus, Noah J. Cowan, Ross L. Hatton)</author>
      <guid isPermaLink="false">2502.17672v1</guid>
      <pubDate>Wed, 26 Feb 2025 17:03:55 +0800</pubDate>
    </item>
    <item>
      <title>Building reliable sim driving agents by scaling self-play</title>
      <link>http://arxiv.org/abs/2502.14706v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  First version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于大规模自我游戏训练的方法，旨在提高模拟代理的可靠性，并应用于Waymo开放运动数据集中的数千个场景。&lt;h4&gt;背景&lt;/h4&gt;设计和测试与人类交互的系统（如自动驾驶汽车）时需要可靠的仿真代理。这些代理在评估自动驾驶性能、压力测试等方面都有应用，但所有用例都需要高度可靠的表现，以确保分析的有效性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够解决大规模训练集并在未见过的场景中有效推广的方法，并展示其对分布外场景的部分鲁棒性以及通过微调快速达到近乎完美表现的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于自我游戏的大规模训练策略，利用Waymo开放运动数据集中的数千个半现实主义限制造成的场景进行训练。所有训练均在单GPU上从零开始完成，并且能够在一天内几乎解决整个训练集。&lt;h4&gt;主要发现&lt;/h4&gt;经过训练的代理能够达到99.8%的目标完成率，在10,000个未见过的场景中，碰撞和脱轨事件的发生率低于0.8%，展示了有效的推广能力。此外，这些代理对分布外场景表现出部分鲁棒性，并且可以通过微调在几分钟内实现近乎完美的性能。&lt;h4&gt;结论&lt;/h4&gt;通过开放源代码库提供了预训练的代理以及完整的代码基础，以便于研究者进一步探索和改进仿真代理技术。&lt;h4&gt;翻译&lt;/h4&gt;该论文探讨了如何通过大规模自我游戏来提升自动驾驶车辆等与人类交互系统的模拟代理的可靠性。通过对Waymo Open Motion Dataset进行半现实限制造成的大规模场景训练，在单GPU上从零开始训练的代理能够实现高可靠性和有效推广，同时展示出对分布外情况的部分鲁棒性，并可以通过快速微调达到近乎完美的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation agents are essential for designing and testing systems thatinteract with humans, such as autonomous vehicles (AVs). These agents servevarious purposes, from benchmarking AV performance to stress-testing thesystem's limits, but all use cases share a key requirement: reliability. Asimulation agent should behave as intended by the designer, minimizingunintended actions like collisions that can compromise the signal-to-noiseratio of analyses. As a foundation for reliable sim agents, we propose scalingself-play to thousands of scenarios on the Waymo Open Motion Dataset undersemi-realistic limits on human perception and control. Training from scratch ona single GPU, our agents nearly solve the full training set within a day. Theygeneralize effectively to unseen test scenes, achieving a 99.8% goal completionrate with less than 0.8% combined collision and off-road incidents across10,000 held-out scenarios. Beyond in-distribution generalization, our agentsshow partial robustness to out-of-distribution scenes and can be fine-tuned inminutes to reach near-perfect performance in those cases. Demonstrations ofagent behaviors can be found at this link. We open-source both the pre-trainedagents and the complete code base. Demonstrations of agent behaviors can befound at \url{https://sites.google.com/view/reliable-sim-agents}.</description>
      <author>example@mail.com (Daphne Cornelisse, Aarav Pandya, Kevin Joseph, Joseph Suárez, Eugene Vinitsky)</author>
      <guid isPermaLink="false">2502.14706v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
  <item>
      <title>Enhancing CoMP-RSMA Performance with Movable Antennas: A Meta-Learning Optimization Framework</title>
      <link>http://arxiv.org/abs/2502.17389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;本研究探讨了一种下行链路速率分割多址接入（RSMA）场景，在该场景中，多个基站采用协同多点（CoMP）传输方案为配备移动天线（MA）技术的用户提供服务。与传统的固定位置天线（FPA）相比，后者受无线信道随机变化的影响，MAs可以战略性地重新定位到信道条件更优的位置，从而实现增强的空间分集增益。&lt;h4&gt;背景&lt;/h4&gt;在传统FPA受限于无线信道随机性的情况下，移动天线技术通过优化位置来改善无线通信性能。这种改进带来了更高的空间多样性收益，并且可以通过调整基站的发射波束成形矢量、不同用户的公共流分配以及MA的最佳定位进一步提高总的可达和速率。&lt;h4&gt;目的&lt;/h4&gt;为了最大化可达到的总速率并确保符合服务质量（QoS）约束，研究提出一个优化问题以确定BS的最佳传输波束形成矢量、各用户之间的共同流分配以及移动天线的最优位置。但该问题由于变量间的强依赖关系而复杂且计算上具有挑战性。&lt;h4&gt;方法&lt;/h4&gt;为了解决大规模优化任务中的计算难题，提出了一种无需预训练的基于梯度的元学习（GML）算法，这种方法特别适合于处理大型优化任务，并通过数值结果证明了其有效性和准确性。该方法能够实现接近最优的结果（与最佳解决方案相比超过97%）。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，移动天线增强型CoMP-RSMA模型在性能上显著优于传统基准方案，在空间分割多址接入(SDMA)方案和基于固定位置天线的RSMA模型上分别实现了高达190%和80%的性能提升。此外，该方法能够减轻SDMA中总速率受限于干扰的问题，并通过较少的基站实现更优表现。&lt;h4&gt;结论&lt;/h4&gt;所提出的GML算法在优化移动天线增强型CoMP-RSMA场景中的总体可达速率方面取得了显著成效，特别是在处理大规模复杂优化问题时展示了其优越性。该研究为未来的无线通信系统设计提供了一种有效的策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study investigates a downlink rate-splitting multiple access (RSMA)scenario in which multiple base stations (BSs), employing a coordinatedmulti-point (CoMP) transmission scheme, serve users equipped with movableantenna (MA) technology. Unlike traditional fixed-position antennas (FPAs),which are subject to random variations in wireless channels, MAs can bestrategically repositioned to locations with more favorable channel conditions,thereby achieving enhanced spatial diversity gains.To leverage these advantagesand maximize the achievable sum rate, we formulate an optimization problem thatjointly determines the optimal transmit beamforming vectors at the BSs, thecommon stream allocation for different users, and the optimal positioning ofthe MAs, all while ensuring compliance with quality of service (QoS)constraints. However, the formulated problem is non-convex and computationallychallenging due to the strong interdependence among the optimization variables.Traditional methods for solving large-scale optimization problems typicallyincur prohibitively high computational complexity. To address the abovechallenge, we propose a gradient-based meta-learning (GML) algorithm thatoperates without pre-training and is well-suited for handling large-scaleoptimization tasks. Numerical results demonstrate the effectiveness andaccuracy of the proposed approach, achieving near-optimal performance(exceeding 97% compared to the optimal solution). Moreover, the MA-enabledCoMP-RSMA model significantly outperforms conventional benchmark schemes,yielding performance gains of up to 190% over the spatial division multipleaccess (SDMA) scheme and 80% over the RSMA FPA-based model. Finally, theproposed approach is shown to mitigate the sum-rate limitations imposed byinterference in SDMA, achieving superior performance with fewer BSs.</description>
      <author>example@mail.com (Ali Amhaz, Shreya Khisa, Mohamed Elhattab, Chadi Assi, Sanaa Sharafeddine)</author>
      <guid isPermaLink="false">2502.17389v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Sustainable Greenhouse Management: A Comparative Analysis of Recurrent and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.17371v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种使用时空图神经网络（STGNN）对温室微气候进行建模的新方法，与传统的递归神经网络（RNN）相比，该方法在考虑环境变量之间的空间依赖关系及其方向性方面具有优势。&lt;h4&gt;背景&lt;/h4&gt;将光伏系统集成到温室中可以优化土地利用并促进可持续农业实践，同时提供食品生产和可再生能源发电的双重效益。然而，准确预测内部环境条件对于确保作物生长最佳和最大化能源生产至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过引入STGNN方法来改善温室微气候建模，提高对环境变量间空间依赖关系的理解，并在传统RNN模型的基础上进一步优化性能。&lt;h4&gt;方法&lt;/h4&gt;论文使用从希腊沃洛斯的一个温室每15分钟收集的高频数据进行实验。这些数据用于评估STGNN和RNN在不同季节条件下的表现差异。&lt;h4&gt;主要发现&lt;/h4&gt;RNN模型在冬季条件下表现出卓越的准确性（R^2 = 0.985），但在夏季冷却系统运行期间显示出局限性；相比之下，尽管目前STGNN的表现略低（冬季R^2 = 0.947），但其架构为整合诸如光伏发电和作物生长指标等额外变量提供了更大的潜力。&lt;h4&gt;结论&lt;/h4&gt;虽然现有的STGNN模型在性能上不如传统RNN，在温室微气候建模方面表现出一定的限制，但是考虑到它们在未来应用中的潜在优势，研究认为进一步探索STGNN的应用是值得的。&lt;h4&gt;翻译&lt;/h4&gt;该摘要描述了将时空图神经网络应用于温室内部环境条件预测的研究成果。论文通过对比分析不同模型在特定时间段内的表现，强调了STGNN的独特优势和未来可能的发展方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of photovoltaic (PV) systems into greenhouses not onlyoptimizes land use but also enhances sustainable agricultural practices byenabling dual benefits of food production and renewable energy generation.However, accurate prediction of internal environmental conditions is crucial toensure optimal crop growth while maximizing energy production. This studyintroduces a novel application of Spatio-Temporal Graph Neural Networks(STGNNs) to greenhouse microclimate modeling, comparing their performance withtraditional Recurrent Neural Networks (RNNs). While RNNs excel at temporalpattern recognition, they cannot explicitly model the directional relationshipsbetween environmental variables. Our STGNN approach addresses this limitationby representing these relationships as directed graphs, enabling the model tocapture both spatial dependencies and their directionality. Usinghigh-frequency data collected at 15-minute intervals from a greenhouse inVolos, Greece, we demonstrate that RNNs achieve exceptional accuracy in winterconditions (R^2 = 0.985) but show limitations during summer cooling systemoperation. Though STGNNs currently show lower performance (winter R^2 = 0.947),their architecture offers greater potential for integrating additionalvariables such as PV generation and crop growth indicators.</description>
      <author>example@mail.com (Emiliano Seri, Marcello Petitta, Cristina Cornaro)</author>
      <guid isPermaLink="false">2502.17371v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>HybridLinker: Topology-Guided Posterior Sampling for Enhanced Diversity and Validity in 3D Molecular Linker Generation</title>
      <link>http://arxiv.org/abs/2502.17349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种名为HybridLinker的框架，旨在解决药物设计中分子片段组合生成的有效性和多样性之间的权衡问题。&lt;h4&gt;背景&lt;/h4&gt;在药物发现应用如先导优化和PROTAC设计过程中，链接子生成是关键步骤。现有方法主要分为PC-Free（不使用3D点云）和PC-Aware（依赖于3D点云约束）两类。前者注重多样性但有效性较低；后者确保高有效性但限制了多样性。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需额外训练就能提高有效性和多样性的新框架HybridLinker。&lt;h4&gt;方法&lt;/h4&gt;通过将预训练的PC-Free模型提供的多样化键合拓扑结构作为指导，增强了PC-Aware模型的推理能力。核心是提出了首个跨PC-Free和PC-Aware空间的操作的方法——LinkerDPS（链接子扩散后验采样），利用能量启发式函数连接分子拓扑与3D点云。&lt;h4&gt;主要发现&lt;/h4&gt;HybridLinker框架通过将PC-Free模型中多样化的采样分布转换为PC-Aware模型中的分布，显著且一致地提高了基础分子设计和应用属性优化任务的有效性和多样性。&lt;h4&gt;结论&lt;/h4&gt;本文建立了一种新的扩散后验采样（DPS）框架，在分子和图域内超越了成像领域，具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;链接子生成在药物发现中的先导优化和PROTAC设计等应用中至关重要。现有的方法根据是否使用3D点云划分为PC-Free和PC-Aware两类。前者追求多样性但有效性较低；后者确保高有效性但限制了多样性。为解决此权衡问题，我们提出了HybridLinker框架，通过引入预训练的PC-Free模型提供的多样化键合拓扑结构来增强PC-Aware模型的推理能力。我们的核心贡献是提出了一种新的扩散后验采样方法LinkerDPS，在分子和图域内建立了有效的连接，显著提高了有效性和多样性，开创了新的研究领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Linker generation is critical in drug discovery applications such as leadoptimization and PROTAC design, where molecular fragments are assembled intodiverse drug candidates. Existing methods fall into PC-Free and PC-Awarecategories based on their use of 3D point clouds (PC). PC-Free modelsprioritize diversity but suffer from lower validity due to overlooking PCconstraints, while PC-Aware models ensure higher validity but restrictdiversity by enforcing strict PC constraints. To overcome these trade-offswithout additional training, we propose HybridLinker, a framework that enhancesPC-Aware inference by providing diverse bonding topologies from a pretrainedPC-Free model as guidance. At its core, we propose LinkerDPS, the firstdiffusion posterior sampling (DPS) method operating across PC-Free and PC-Awarespaces, bridging molecular topology with 3D point clouds via an energy-inspiredfunction. By transferring the diverse sampling distribution of PC-Free modelsinto the PC-Aware distribution, HybridLinker significantly and consistentlysurpasses baselines, improving both validity and diversity in foundationalmolecular design and applied property optimization tasks, establishing a newDPS framework in the molecular and graph domains beyond imaging.</description>
      <author>example@mail.com (Minyeong Hwang, Ziseok Lee, Gwangsoo Kim, Kyungsu Kim, Eunho Yang)</author>
      <guid isPermaLink="false">2502.17349v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>LCV2I: Communication-Efficient and High-Performance Collaborative Perception Framework with Low-Resolution LiDAR</title>
      <link>http://arxiv.org/abs/2502.17039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种新的车辆到基础设施（V2I）协同感知框架LCV2I，该框架使用低成本低分辨率激光雷达和摄像头数据来提高协作感知的性能。&lt;h4&gt;背景&lt;/h4&gt;当前V2I合作感知系统主要依赖于高成本的高分辨率激光雷达，但这种传感器价格昂贵且难以普及。同时，传统通信方法带宽利用率较低。&lt;h4&gt;目的&lt;/h4&gt;为了实现低成本的V2I协同感知，研究旨在降低车辆端使用高分辨率激光雷达的成本，并提高数据传输效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架LCV2I，该框架采用低分辨率激光雷达和摄像头的数据作为输入，并利用特征偏移校正模块和区域特征增强算法来改进特征表示。此外，通过区域差异图和区域评分图评估协作内容的价值，从而提高通信带宽效率。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的LCV2I方法在保持高水平感知性能的同时，显著减少了对车辆端高分辨率传感器的需求，并且在真实世界场景中的3D目标检测测试中超越了现有算法的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究成功开发了一种高效的低成本V2I协同感知框架，能够通过低分辨率激光雷达和摄像头的数据实现高质量的感知结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicle-to-Infrastructure (V2I) collaborative perception leverages datacollected by infrastructure's sensors to enhance vehicle perceptualcapabilities. LiDAR, as a commonly used sensor in cooperative perception, iswidely equipped in intelligent vehicles and infrastructure. However, itssuperior performance comes with a correspondingly high cost. To achievelow-cost V2I, reducing the cost of LiDAR is crucial. Therefore, we studyadopting low-resolution LiDAR on the vehicle to minimize cost as much aspossible. However, simply reducing the resolution of vehicle's LiDAR results insparse point clouds, making distant small objects even more blurred.Additionally, traditional communication methods have relatively low bandwidthutilization efficiency. These factors pose challenges for us. To balance costand perceptual accuracy, we propose a new collaborative perception framework,namely LCV2I. LCV2I uses data collected from cameras and low-resolution LiDARas input. It also employs feature offset correction modules and regionalfeature enhancement algorithms to improve feature representation. Finally, weuse regional difference map and regional score map to assess the value ofcollaboration content, thereby improving communication bandwidth efficiency. Insummary, our approach achieves high perceptual performance while substantiallyreducing the demand for high-resolution sensors on the vehicle. To evaluatethis algorithm, we conduct 3D object detection in the real-world scenario ofDAIR-V2X, demonstrating that the performance of LCV2I consistently surpassescurrently existing algorithms.</description>
      <author>example@mail.com (Xinxin Feng, Haoran Sun, Haifeng Zheng, Huacong Chen, Wenqiang Chen)</author>
      <guid isPermaLink="false">2502.17039v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Supervised contrastive learning from weakly-labeled audio segments for musical version matching</title>
      <link>http://arxiv.org/abs/2502.16936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 6 figures, 7 tables; includes Appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;检测音乐版本是一项具有挑战性的任务，现有方法通常在曲目级别上匹配音乐版本，而实际应用中需要在片段级别进行匹配。&lt;h4&gt;背景描述&lt;/h4&gt;现有的音乐版本检测技术大多基于整个音频文件的完全标注，并使用分类和三元组损失等传统方法，忽略了更现代的损失函数可能带来的改进。&lt;h4&gt;研究目的&lt;/h4&gt;开发一种可以在弱监督学习条件下工作的新方法，该方法利用对比损失变体在片段级别上提高性能。&lt;h4&gt;主要方法&lt;/h4&gt;{'弱标记段学习': '基于成对的音乐片段距离减少进行训练', '对比损失修改': '通过解耦、超参数和几何学考虑改进现有损失函数'}&lt;h4&gt;关键发现&lt;/h4&gt;提出的方法不仅在标准曲目级评估中达到了最先进的性能，在片段级别上也实现了突破性的效果。&lt;h4&gt;结论&lt;/h4&gt;由于所解决问题的通用性，该方法可能超越音频或音乐版本匹配领域，在其他领域找到应用价值。&lt;h4&gt;翻译&lt;/h4&gt;检测音乐版本是一项具有挑战性的任务，并且具有重要的实际应用场景。现有的方法通常基于完全标注数据进行曲目级别的匹配（例如整首歌曲）。然而大多数实际应用场景需要在片段级别上进行匹配（例如20秒的音频段落）。此外，现有研究大多依赖于分类和三元组损失函数，而忽视了更现代的损失函数可能带来的性能提升。本文中我们提出了一种基于弱监督学习的新型方法以及一种改进的对比损失变体，在片段级别的评估上达到了前所未有的性能水平，并且在传统的曲目级别评估上也取得了领先的结果。我们认为由于所解决问题的普遍性，该方法有望在音频或音乐版本匹配之外的其他领域找到应用机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting musical versions (different renditions of the same piece) is achallenging task with important applications. Because of the ground truthnature, existing approaches match musical versions at the track level (e.g.,whole song). However, most applications require to match them at the segmentlevel (e.g., 20s chunks). In addition, existing approaches resort toclassification and triplet losses, disregarding more recent losses that couldbring meaningful improvements. In this paper, we propose a method to learn fromweakly annotated segments, together with a contrastive loss variant thatoutperforms well-studied alternatives. The former is based on pairwise segmentdistance reductions, while the latter modifies an existing loss followingdecoupling, hyper-parameter, and geometric considerations. With these twoelements, we do not only achieve state-of-the-art results in the standardtrack-level evaluation, but we also obtain a breakthrough performance in asegment-level evaluation. We believe that, due to the generality of thechallenges addressed here, the proposed methods may find utility in domainsbeyond audio or musical version matching.</description>
      <author>example@mail.com (Joan Serrà, R. Oguz Araz, Dmitry Bogdanov, Yuki Mitsufuji)</author>
      <guid isPermaLink="false">2502.16936v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models are Powerful EHR Encoders</title>
      <link>http://arxiv.org/abs/2502.17403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探索了使用通用大型语言模型（LLM）嵌入方法作为电子健康记录（EHR）编码器的潜力，特别是在临床预测任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;电子健康记录数据复杂且异质性高，传统机器学习方法难以有效利用这些资源。领域特定的EHR基础模型虽然在提高预测准确性方面表现出色，但其训练受到高质量多样化数据集有限和编码标准不一致的影响。&lt;h4&gt;目的&lt;/h4&gt;评估通用LLM嵌入方法作为EHR编码器的有效性和潜在优势。&lt;h4&gt;方法&lt;/h4&gt;通过将患者记录转换为结构化的Markdown文本并利用预训练的大型语言模型（GTE-Qwen2-7B-Instruct和LLM2Vec-Llama3.1-8B-Instruct）进行代码转译，研究者在EHRSHOT基准测试的15个不同临床预测任务上比较了这些方法与特定于EHR的基础模型CLIMBR-T-Base及传统机器学习基线的表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在少量样本的情况下，LLM基于嵌入的方法经常能够达到甚至超过专门模型的性能，并且其有效性随着基础LLM规模和上下文窗口大小的增长而提高。&lt;h4&gt;结论&lt;/h4&gt;重新利用LLM作为EHR编码器提供了一种可扩展且有效的临床预测方法，有助于克服传统EHR建模中的局限性并促进更互操作性和普遍性的医疗保健应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electronic Health Records (EHRs) offer rich potential for clinicalprediction, yet their inherent complexity and heterogeneity pose significantchallenges for traditional machine learning approaches. Domain-specific EHRfoundation models trained on large collections of unlabeled EHR data havedemonstrated promising improvements in predictive accuracy and generalization;however, their training is constrained by limited access to diverse,high-quality datasets and inconsistencies in coding standards and healthcarepractices. In this study, we explore the possibility of using general-purposeLarge Language Models (LLMs) based embedding methods as EHR encoders. Byserializing patient records into structured Markdown text, transforming codesinto human-readable descriptors, we leverage the extensive generalizationcapabilities of LLMs pretrained on vast public corpora, thereby bypassing theneed for proprietary medical datasets. We systematically evaluate twostate-of-the-art LLM-embedding models, GTE-Qwen2-7B-Instruct andLLM2Vec-Llama3.1-8B-Instruct, across 15 diverse clinical prediction tasks fromthe EHRSHOT benchmark, comparing their performance to an EHRspecific foundationmodel, CLIMBR-T-Base, and traditional machine learning baselines. Our resultsdemonstrate that LLM-based embeddings frequently match or exceed theperformance of specialized models, even in few-shot settings, and that theireffectiveness scales with the size of the underlying LLM and the availablecontext window. Overall, our findings demonstrate that repurposing LLMs for EHRencoding offers a scalable and effective approach for clinical prediction,capable of overcoming the limitations of traditional EHR modeling andfacilitating more interoperable and generalizable healthcare applications.</description>
      <author>example@mail.com (Stefan Hegselmann, Georg von Arnim, Tillmann Rheude, Noel Kronenberg, David Sontag, Gerhard Hindricks, Roland Eils, Benjamin Wild)</author>
      <guid isPermaLink="false">2502.17403v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Electrical Load Forecasting over Multihop Smart Metering Networks with Federated Learning</title>
      <link>http://arxiv.org/abs/2502.17226v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2411.10619&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;本论文提出了一个新型的个性化联邦学习(PFL) 方法，用于电表网络中的高质量负载预测。&lt;h4&gt;背景&lt;/h4&gt;电力负载预测对于智能电网的管理与稳定性至关重要。传统机器学习方法在负载预测中通常被使用，但会涉及到数据交换从而引发隐私问题。联邦学习（FL）可以通过不进行数据交换而在本地智能电表上运行分布式机器学习模型来解决这一问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型个性化联邦学习(PFL) 方法以实现高效的负载预测，并减少延迟。&lt;h4&gt;方法&lt;/h4&gt;提出了基于元学习的策略，用于处理本地智能电表中的数据异质性。同时研究了一种新的基于最优资源分配的新延迟优化问题来降低PFL模型中负载预测延迟。&lt;h4&gt;主要发现&lt;/h4&gt;通过详尽的真实世界数据集仿真表明本论文的方法在负载预测和运营延迟成本方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该方法为联邦学习的设计提供了理论收敛性分析，以提供关于联合负荷预测的见解。&lt;h4&gt;翻译&lt;/h4&gt;电力负载预测对于智能电网管理和稳定性至关重要。通常通过高级计量基础设施实现这一点，在这种基础设施中，智能电表记录家庭能耗数据。虽然传统机器学习方法被广泛用于负荷预测，但它们需要数据共享并且引发了隐私问题。联邦学习可以通过在本地智能电表上运行分布式模型而无需交换数据来解决这个问题。然而，当前基于FL的方法由于异构智能电表之间的数据分布不平衡而难以实现有效的负载预测。本文提出了一种新的个性化联邦学习（PFL）方法用于计量网络中的高质量负荷预测。研究团队开发了一个基于元学习的策略来处理在本地智能电表中联合训练本地负荷预测模型时的数据异质性问题。此外，为了最小化我们提出的PFL模型中的负载预测延迟，他们研究了一种新的基于最优资源分配的延迟优化问题。还进行了理论收敛性分析以提供关于联邦学习设计用于联邦负荷预测的见解。大量来自真实数据集的仿真显示该方法在提高负荷预测质量和减少运营延迟成本方面优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electric load forecasting is essential for power management and stability insmart grids. This is mainly achieved via advanced metering infrastructure,where smart meters (SMs) record household energy data. Traditional machinelearning (ML) methods are often employed for load forecasting but require datasharing which raises data privacy concerns. Federated learning (FL) can addressthis issue by running distributed ML models at local SMs without data exchange.However, current FL-based approaches struggle to achieve efficient loadforecasting due to imbalanced data distribution across heterogeneous SMs. Thispaper presents a novel personalized federated learning (PFL) method forhigh-quality load forecasting in metering networks. A meta-learning-basedstrategy is developed to address data heterogeneity at local SMs in thecollaborative training of local load forecasting models. Moreover, to minimizethe load forecasting delays in our PFL model, we study a new latencyoptimization problem based on optimal resource allocation at SMs. A theoreticalconvergence analysis is also conducted to provide insights into FL design forfederated load forecasting. Extensive simulations from real-world datasets showthat our method outperforms existing approaches in terms of better loadforecasting and reduced operational latency costs.</description>
      <author>example@mail.com (Ratun Rahman, Pablo Moriano, Samee U. Khan, Dinh C. Nguyen)</author>
      <guid isPermaLink="false">2502.17226v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>PFSD: A Multi-Modal Pedestrian-Focus Scene Dataset for Rich Tasks in Semi-Structured Environments</title>
      <link>http://arxiv.org/abs/2502.15342v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近的自动驾驶感知技术在结构化的车辆主导环境中展示了卓越的能力，但在半结构化环境中存在显著限制。这些限制主要是由于高质量数据集缺乏造成的，尤其是在行人感知和预测方面。&lt;h4&gt;背景&lt;/h4&gt;当前的自动驾驶感知模型在半结构化环境（如动态行人频繁出现的地方）中表现出明显的局限性，因为现有的数据集中缺乏足够高质量的数据来支持这类场景的研究。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种新的多模态数据集——Pedestrian-Focused Scene Dataset (PFSD)，专门针对半结构化的复杂环境，并提出了Hybrid Multi-Scale Fusion Network（HMFN）模型以解决行人检测的挑战问题。&lt;h4&gt;方法&lt;/h4&gt;{'PFSD': '该数据集包含超过130,000个行人的实例，涵盖了各种密度、移动模式和遮挡情况。它提供了全面的多模态数据注释，包括点云分割、检测以及对象ID追踪。', 'HMFN': '为了在密集且被部分阻挡的情况下更好地识别行人，该方法使用精心设计的混合框架捕获并融合多尺度特征，整合了稀疏和标准卷积技术。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在PFSD上进行测试时，所提出的HMFN模型相比现有方法在3D行人检测方面实现了更高的平均精度(mAP)提升。&lt;h4&gt;结论&lt;/h4&gt;通过提出新的数据集和有效的网络架构来解决半结构化环境中复杂的行人感知挑战问题，证明了该工作的实用性和创新性。&lt;h4&gt;翻译&lt;/h4&gt;近期自动驾驶车辆的感知技术在高度结构化的交通场景中展示出了卓越的能力。然而，在行人活动更为多样且复杂遮挡更加普遍的半结构化环境下，现有的感知模型表现出了明显的局限性。这种现象主要是由于缺乏高质量的数据集，特别是关于行人的感知和预测数据。本文提出了一种新的多模态行人聚焦场景数据集（PFSD），它在nuScenes格式下被详细标注，并提供了全面的多模态注释，包括点云分割、检测及对象ID追踪等信息。该数据集覆盖了超过130,000个行人的实例，它们涵盖了不同密度、移动模式和遮挡情况下的各种场景。为了应对半结构化环境中更加多样复杂的情况带来的挑战，我们提出了一种新的混合多尺度融合网络（HMFN）。具体而言，在人口密集且存在部分阻挡的情况下，我们的方法通过精心设计的框架有效地捕捉并融合了多种规模特征，该框架集成了稀疏和传统卷积技术。在PFSD上的大量实验表明，与现有方法相比，HMFN在网络架构中实现了显著提高的平均精度（mAP），这证明了其解决半结构化环境中3D行人检测挑战的有效性。代码和基准测试结果已经开放提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in autonomous driving perception have revealedexceptional capabilities within structured environments dominated by vehiculartraffic. However, current perception models exhibit significant limitations insemi-structured environments, where dynamic pedestrians with more diverseirregular movement and occlusion prevail. We attribute this shortcoming to thescarcity of high-quality datasets in semi-structured scenes, particularlyconcerning pedestrian perception and prediction. In this work, we present themulti-modal Pedestrian-Focused Scene Dataset(PFSD), rigorously annotated insemi-structured scenes with the format of nuScenes. PFSD provides comprehensivemulti-modal data annotations with point cloud segmentation, detection, andobject IDs for tracking. It encompasses over 130,000 pedestrian instancescaptured across various scenarios with varying densities, movement patterns,and occlusions. Furthermore, to demonstrate the importance of addressing thechallenges posed by more diverse and complex semi-structured environments, wepropose a novel Hybrid Multi-Scale Fusion Network (HMFN). Specifically, todetect pedestrians in densely populated and occluded scenarios, our methodeffectively captures and fuses multi-scale features using a meticulouslydesigned hybrid framework that integrates sparse and vanilla convolutions.Extensive experiments on PFSD demonstrate that HMFN attains improvement in meanAverage Precision (mAP) over existing methods, thereby underscoring itsefficacy in addressing the challenges of 3D pedestrian detection in complexsemi-structured environments. Coding and benchmark are available.</description>
      <author>example@mail.com (Yueting Liu, Hanshi Wang, Yunfei Lei, Zhengjun Zha, Weiming Hu, Jin Gao)</author>
      <guid isPermaLink="false">2502.15342v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Applications of Large Models in Medicine</title>
      <link>http://arxiv.org/abs/2502.17132v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了大规模模型在医疗领域的进展与应用，特别关注医学大型模型（MedLMs）的应用。&lt;h4&gt;背景&lt;/h4&gt;这些模型包括大型语言模型（LLMs）、视觉模型、3D大型模型和多模态模型。它们通过增强疾病预测、诊断辅助、个性化治疗计划及药物发现来革新医疗服务。&lt;h4&gt;目的&lt;/h4&gt;该研究旨在提供大规模模型在医学领域现状与未来方向的全面概述，强调其在全球健康进步中的重要性。&lt;h4&gt;方法&lt;/h4&gt;论文重点介绍了大型图神经网络如何融入医疗知识图谱和药物发现中，以及视觉-语言模型（VLMs）和3D大型模型在医学图像分析、解剖建模及假肢设计方面的应用。&lt;h4&gt;主要发现&lt;/h4&gt;尽管存在挑战，但这些技术正在为医疗服务设定新的标准，并为个性化健康解决方案铺平道路。&lt;h4&gt;结论&lt;/h4&gt;大规模模型正在医疗领域实现变革性的进步，通过改善诊断准确性来推动全球卫生的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文翻译为：本文探讨了大型规模模型在医学领域的进展和应用，特别关注医学大模型（MedLMs）。这些模型包括大型语言模型、视觉模型、3D大型模型以及多模态模型。它们正在通过增强疾病预测、诊断辅助、个性化治疗计划及药物发现等方面革新医疗服务。研究还强调了大型图模型（LGMs）在理解复杂生物医学关系中的潜力，特别是在医疗知识图谱和药物发现中的集成应用。视觉-语言模型（VLMs）和3D大型模型在医学图像分析、解剖建模以及假肢设计方面的使用也得到突出展示。尽管存在挑战，这些技术正在为医疗服务设定新的标准，提高诊断准确性，并推动个性化健康解决方案的发展。本文旨在提供大规模模型在医学领域现状与未来方向的全面概述，强调它们在全球健康进步中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.71423/aimed.20250105&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the advancements and applications of large-scale modelsin the medical field, with a particular focus on Medical Large Models (MedLMs).These models, encompassing Large Language Models (LLMs), Vision Models, 3DLarge Models, and Multimodal Models, are revolutionizing healthcare byenhancing disease prediction, diagnostic assistance, personalized treatmentplanning, and drug discovery. The integration of graph neural networks inmedical knowledge graphs and drug discovery highlights the potential of LargeGraph Models (LGMs) in understanding complex biomedical relationships. Thestudy also emphasizes the transformative role of Vision-Language Models (VLMs)and 3D Large Models in medical image analysis, anatomical modeling, andprosthetic design. Despite the challenges, these technologies are setting newbenchmarks in medical innovation, improving diagnostic accuracy, and paving theway for personalized healthcare solutions. This paper aims to provide acomprehensive overview of the current state and future directions of largemodels in medicine, underscoring their significance in advancing global health.</description>
      <author>example@mail.com (YunHe Su, Zhengyang Lu, Junhui Liu, Ke Pang, Haoran Dai, Sa Liu Yuxin Jia, Lujia Ge, Jing-min Yang)</author>
      <guid isPermaLink="false">2502.17132v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>CAR-LOAM: Color-Assisted Robust LiDAR Odometry and Mapping</title>
      <link>http://arxiv.org/abs/2502.17249v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种结合颜色信息的稳健框架，用于准确的LiDAR里程计和地图构建（LOAM），通过同时利用LiDAR点云和相机图像中的边缘及平面特征来提高定位精度。&lt;h4&gt;背景&lt;/h4&gt;现有的LiDAR Odometry and Mapping (LOAM)技术在使用单模态数据时存在局限性，难以处理复杂的环境场景。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够融合颜色信息的稳健框架，以实现更加准确和鲁棒性的LiDAR里程计及地图构建方法。&lt;h4&gt;方法&lt;/h4&gt;该框架包括：1）利用相机图像中的颜色为LiDAR点云着色；2）采用感知均匀的颜色差异权重策略来排除颜色对应异常值；3）使用基于Welsch函数的稳健误差度量法处理位置对应异常值。&lt;h4&gt;主要发现&lt;/h4&gt;新方法在复杂森林和校园等挑战性场景中表现出更高的准确性和鲁棒性，相较于当前最先进的技术有所改进。&lt;h4&gt;结论&lt;/h4&gt;利用相机图像中的颜色信息能够显著提高LiDAR里程计及地图构建的精度与稳定性。&lt;h4&gt;翻译&lt;/h4&gt;在这封信中，我们提出了一种结合颜色信息用于精确LiDAR里程估计和制图（LOAM）的稳健框架。同时从激光雷达和摄像机接收数据，该框架利用摄像机图像中的颜色信息对激光雷达点云进行着色，然后执行迭代姿态优化。对于每个激光雷达扫描，提取边缘和平面特征，并使用相应图像对其着色并匹配到全局地图中。特别地，我们采用感知均匀的颜色差异权重策略来排除颜色对应异常值，并基于Welsch函数的稳健误差度量法在姿态优化过程中减少位置对应异常值的影响。因此，该系统实现了精确定位，并重建了环境密集、准确、彩色且三维的地图。具有挑战性的场景（包括复杂森林和校园）中的彻底实验表明，我们的方法相比当前最先进的技术提供了更高的鲁棒性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this letter, we propose a color-assisted robust framework for accurateLiDAR odometry and mapping (LOAM). Simultaneously receiving data from both theLiDAR and the camera, the framework utilizes the color information from thecamera images to colorize the LiDAR point clouds and then performs iterativepose optimization. For each LiDAR scan, the edge and planar features areextracted and colored using the corresponding image and then matched to aglobal map. Specifically, we adopt a perceptually uniform color differenceweighting strategy to exclude color correspondence outliers and a robust errormetric based on the Welsch's function to mitigate the impact of positionalcorrespondence outliers during the pose optimization process. As a result, thesystem achieves accurate localization and reconstructs dense, accurate, coloredand three-dimensional (3D) maps of the environment. Thorough experiments withchallenging scenarios, including complex forests and a campus, show that ourmethod provides higher robustness and accuracy compared with currentstate-of-the-art methods.</description>
      <author>example@mail.com (Yufei Lu, Yuetao Li, Zhizhou Jia, Qun Hao, Shaohui Zhang)</author>
      <guid isPermaLink="false">2502.17249v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>An Expert Ensemble for Detecting Anomalous Scenes, Interactions, and Behaviors in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2502.16389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by International Journal of Robotics Research (IJRR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;自动驾驶汽车的安全性是实现完全自主驾驶的关键，特别是在检测超出操作设计领域的异常情况方面。论文提出了一种新颖的无监督异常检测专家系统来解决这个问题。&lt;h4&gt;背景&lt;/h4&gt;随着自动化车辆进入公共道路，确保无数驾驶场景中的安全性成为广泛采用全自动驾驶的重要挑战之一。&lt;h4&gt;目的&lt;/h4&gt;为了提高自动驾驶系统的可信度，研究提出了能够检测出道路上不常见情况的方法。&lt;h4&gt;方法&lt;/h4&gt;{'三类无监督异常检测专家': ['场景专家：专注于帧级别的外观来识别异常场景和未预期的场景运动；交互专家：建立两个道路参与者的相对正常移动模型，并在出现异常互动时发出警告；行为专家：通过未来轨迹预测监测个体对象的异常行为。'], '专家集成系统(Xen)': '利用卡尔曼滤波器将所有模块的优点结合起来，最终异常得分被作为其中一个状态，而观察结果则由各个专家生成。', '新颖评估协议': '采用了一种新的模型性能评估协议来测试实际应用中的表现'}&lt;h4&gt;主要发现&lt;/h4&gt;{'优越性': '实验结果显示该方法在检测道路上的异常情况时比先前的方法更胜一筹', '潜力': '通过无监督学习处理大规模数据集，该框架有分类不同类型的异常行为的潜力'}&lt;h4&gt;结论&lt;/h4&gt;提出了一种新颖且有效的方法来实现自动驾驶汽车中的安全性和可靠性，并展示了其在现实世界应用中的潜在价值。&lt;h4&gt;翻译&lt;/h4&gt;随着自动化车辆进入公共道路，确保无数驾驶场景中的安全性成为广泛采用全自动驾驶的重要挑战之一。论文提出了三种无监督异常检测专家：场景专家、交互专家和行为专家，以及一个通过卡尔曼滤波器将各模块的优点结合起来的专家集成系统(Xen)。实验显示该方法在道路上检测异常情况方面优于先前的方法，并且具有利用大规模数据集进行无监督学习来分类不同类型的异常行为的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1177/02783649241297998&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As automated vehicles enter public roads, safety in a near-infinite number ofdriving scenarios becomes one of the major concerns for the widespread adoptionof fully autonomous driving. The ability to detect anomalous situations outsideof the operational design domain is a key component in self-driving cars,enabling us to mitigate the impact of abnormal ego behaviors and to realizetrustworthy driving systems. On-road anomaly detection in egocentric videosremains a challenging problem due to the difficulties introduced by complex andinteractive scenarios. We conduct a holistic analysis of common on-road anomalypatterns, from which we propose three unsupervised anomaly detection experts: ascene expert that focuses on frame-level appearances to detect abnormal scenesand unexpected scene motions; an interaction expert that models normal relativemotions between two road participants and raises alarms whenever anomalousinteractions emerge; and a behavior expert which monitors abnormal behaviors ofindividual objects by future trajectory prediction. To combine the strengths ofall the modules, we propose an expert ensemble (Xen) using a Kalman filter, inwhich the final anomaly score is absorbed as one of the states and theobservations are generated by the experts. Our experiments employ a novelevaluation protocol for realistic model performance, demonstrate superioranomaly detection performance than previous methods, and show that ourframework has potential in classifying anomaly types using unsupervisedlearning on a large-scale on-road anomaly dataset.</description>
      <author>example@mail.com (Tianchen Ji, Neeloy Chakraborty, Andre Schreiber, Katherine Driggs-Campbell)</author>
      <guid isPermaLink="false">2502.16389v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Detecting Code Vulnerabilities with Heterogeneous GNN Training</title>
      <link>http://arxiv.org/abs/2502.16835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;检测源代码中的漏洞是软件安全保障的关键任务。图神经网络（GNN）机器学习通过将源代码建模为图形，可以成为一种有前途的方法。&lt;h4&gt;背景&lt;/h4&gt;早期方法将代码元素统一处理，限制了其模拟多样化关系的能力，这些关系有助于识别各种类型的漏洞。最近的研究通过考虑节点类型的不同性，并使用门控图神经网络（GGNN）来解决这一问题，以不同的边类型聚合节点信息。&lt;h4&gt;目的&lt;/h4&gt;介绍Inter-Procedural Abstract Graphs (IPAG)作为一种高效的、与语言无关的源代码表示方法，结合异构GNN训练进行漏洞预测。提出Heterogeneous Attention GNN（HAGNN）模型来集成捕捉源代码不同特征的多个子图。&lt;h4&gt;方法&lt;/h4&gt;该模型使用异构注意力机制将这些分别学习到的不同子图结合起来，并通过全连接神经网络进行最终分类。&lt;h4&gt;主要发现&lt;/h4&gt;提出的这种方法在包含108种漏洞类型的大型C数据集上达到了高达96.6%的准确性，在包含114种漏洞类型的大型Java数据集上达到了97.8%，优于现有最先进的方法。此外，该方法应用于各种实际软件项目时也显示出了较低的假阳性率。&lt;h4&gt;结论&lt;/h4&gt;通过引入Inter-Procedural Abstract Graphs（IPAG）和Heterogeneous Attention GNN（HAGNN），为源代码漏洞检测提供了一种高效且准确的方法，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;检测源代码中的漏洞是软件安全保障的关键任务。图神经网络（GNN）机器学习通过将源代码建模为图形，可以成为一种有前途的方法。早期方法统一处理代码元素，限制了其对导致各种类型漏洞的多样化关系进行建模的能力。最近的研究通过考虑节点类型的异质性，并使用门控图神经网络（GGNN）来解决这一问题，以不同的边类型聚合节点信息。然而，这些边缘主要作为传递节点信息的渠道，可能无法捕捉到不同类型的详细特征。本文提出了Inter-Procedural Abstract Graphs (IPAG)作为一种高效的、与语言无关的源代码表示方法，并结合异构GNN训练进行漏洞预测。IPAG捕获了代码元素及其关系的结构和上下文属性。我们还提出了一种Heterogeneous Attention GNN（HAGNN）模型，该模型集成了捕捉源代码不同特征的多个子图。这些子图分别学习并通过全局注意力机制结合在一起，并通过全连接神经网络进行最终分类。在大型C数据集中，提出的这种方法达到了高达96.6%的准确性，涵盖了108种漏洞类型；而在包含114种漏洞类型的大型Java数据集中，则达到了97.8%，优于现有最先进的方法。此外，在各种实际软件项目中的应用也显示出了较低的假阳性率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting vulnerabilities in source code is a critical task for softwaresecurity assurance. Graph Neural Network (GNN) machine learning can be apromising approach by modeling source code as graphs. Early approaches treatedcode elements uniformly, limiting their capacity to model diverse relationshipsthat contribute to various vulnerabilities. Recent research addresses thislimitation by considering the heterogeneity of node types and using Gated GraphNeural Networks (GGNN) to aggregate node information through different edgetypes. However, these edges primarily function as conduits for passing nodeinformation and may not capture detailed characteristics of distinct edgetypes. This paper presents Inter-Procedural Abstract Graphs (IPAGs) as anefficient, language-agnostic representation of source code, complemented byheterogeneous GNN training for vulnerability prediction. IPAGs capture thestructural and contextual properties of code elements and their relationships.We also propose a Heterogeneous Attention GNN (HAGNN) model that incorporatesmultiple subgraphs capturing different features of source code. These subgraphsare learned separately and combined using a global attention mechanism,followed by a fully connected neural network for final classification. Theproposed approach has achieved up to 96.6% accuracy on a large C dataset of 108vulnerability types and 97.8% on a large Java dataset of 114 vulnerabilitytypes, outperforming state-of-the-art methods. Its applications to variousreal-world software projects have also demonstrated low false positive rates.</description>
      <author>example@mail.com (Yu Luo, Weifeng Xu, Dianxiang Xu)</author>
      <guid isPermaLink="false">2502.16835v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Continuous Scatterplot and Image Moments for Time-Varying Bivariate Field Analysis of Electronic Structure Evolution</title>
      <link>http://arxiv.org/abs/2502.17118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的时间变化双变量场分析方法，用于理解光诱导动力学中电子结构的变化。&lt;h4&gt;背景&lt;/h4&gt;由于光照吸收引起的电子在能级间的跃迁是一个复杂的量子力学过程，这会影响分子内的核几何和电子结构。研究这些密度场有助于了解分子内供体区域与受体区域之间的电荷移动情况。&lt;h4&gt;目的&lt;/h4&gt;通过连续散点图（Continuous Scatterplots, CSP）及基于图像的时刻描述符来分析时间变化中的双变量字段，并针对光激发后的不断变化的电子结构，提出一种特征导向可视化探索的方法。&lt;h4&gt;方法&lt;/h4&gt;核运动产生的多个时间步长，使用CSP和基于图像的时刻描述符进行动态场数据的探索性分析。将每个时间步骤的CSP表示为四个长度的图矩向量，并形成一个R^4中的点云。&lt;h4&gt;主要发现&lt;/h4&gt;选取适当的主要成分可以将点云表示为平面上的一条曲线，从而有助于识别关键的时间步长、发现双变量字段内的模式以及追踪其随时间的变化。文中通过两个光激发分子动力学的案例研究展示了这种方法的应用。&lt;h4&gt;结论&lt;/h4&gt;此方法可有效揭示电子结构变化规律，并提供具有应用特定洞察力的方法来深入理解光诱导过程中的物理和化学机制。&lt;h4&gt;翻译&lt;/h4&gt;光致电子跃迁是由于光照吸收引起的复杂量子力学过程，其中电子在能级之间移动。这会引起电子结构和核几何的变化，推动了光生物学、材料设计以及医学等领域的重要物理和化学进程。不断演变的电子结构可以通过两个电子密度场来表征：空穴自然过渡轨道（NTO）和粒子自然过渡轨道（NTO）。研究这些密度领域有助于了解分子内供体区域与受体区域之间的电荷移动情况。以往的研究多依赖于等值面并排视觉比较、统计方法或双变量字段分析，实例较少。我们提出了一种新的时间变化双变量场分析方法，适用于理解大量实例下的光诱导电子结构变化。由于NTO领域取决于核几何，因此需通过许多时间步长来解析由核运动产生的复杂现象。本文采用连续散点图（Continuous Scatterplots, CSP）及基于图像的时刻描述符来进行动态场数据探索性分析，并针对光激发后的不断变化的电子结构，提出一种特征导向可视化探索的方法。每个时间步骤中的CSP通过四个长度的图矩向量来表示；将所有矢量描述符集合形成R^4空间里的点云并利用主成分分析技术进行可视化呈现。选择适当的主成分可以简化点云为平面上的一条曲线，有助于识别关键的时间步长、发现双变量字段内的模式以及追踪其随时间的变化。我们通过两个光激发分子动力学案例研究展示这种方法的有效性，并展示了双变量场分析在特定应用中提供的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Photoinduced electronic transitions are complex quantum-mechanical processeswhere electrons move between energy levels due to light absorption. Thisinduces dynamics in electronic structure and nuclear geometry, drivingimportant physical and chemical processes in fields like photobiology,materials design, and medicine. The evolving electronic structure can becharacterized by two electron density fields: hole and particle naturaltransition orbitals (NTOs). Studying these density fields helps understandelectronic charge movement between donor and acceptor regions within amolecule. Previous works rely on side-by-side visual comparisons ofisosurfaces, statistical approaches, or bivariate field analysis with fewinstances. We propose a new method to analyze time-varying bivariate fieldswith many instances, which is relevant for understanding electronic structurechanges during light-induced dynamics. Since NTO fields depend on nucleargeometry, the nuclear motion results in numerous time steps to analyze. Thispaper presents a structured approach to feature-directed visual exploration oftime-varying bivariate fields using continuous scatterplots (CSPs) and imagemoment-based descriptors, tailored for studying evolving electronic structurespost-photoexcitation. The CSP of the bivariate field at each time step isrepresented by a four-length image moment vector. The collection of all vectordescriptors forms a point cloud in R^4, visualized using principal componentanalysis. Selecting appropriate principal components results in arepresentation of the point cloud as a curve on the plane, aiding tasks such asidentifying key time steps, recognizing patterns within the bivariate field,and tracking the temporal evolution. We demonstrate this with two case studieson excited-state molecular dynamics, showing how bivariate field analysisprovides application-specific insights.</description>
      <author>example@mail.com (Mohit Sharma, Talha Bin Masood, Nanna Holmgaard List, Ingrid Hotz, Vijay Natarajan)</author>
      <guid isPermaLink="false">2502.17118v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Snoopy: Effective and Efficient Semantic Join Discovery via Proxy Columns</title>
      <link>http://arxiv.org/abs/2502.16813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TKDE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的列级语义连接发现框架Snoopy，通过使用代理列来计算列嵌入以解决现有方法在有效性和效率方面的问题。&lt;h4&gt;背景&lt;/h4&gt;语义连接发现旨在从表库中找到与查询列有高语义连接性的列。现有方法分为单元格级别和列级别两种方法，但两者都无法同时保证有效性和效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架Snoopy来解决当前方法中存在的有效性低、效率不足的问题。&lt;h4&gt;方法&lt;/h4&gt;通过使用代理列计算列嵌入，并引入了一个基于排名的对比学习范式来获取指导列投影的良好代理列，提出了一个轻量级近似图匹配基线的列投射以捕捉隐式的列到代理列关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，Snoopy在Recall@25和NDCG@25上分别比现有最佳方法高出16%和10%，并且至少快五倍于单元级解决方案，在速度上是现有的列级方法的3.5倍。&lt;h4&gt;结论&lt;/h4&gt;提出的框架Snoopy不仅提高了语义连接发现的有效性，同时显著提升了效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语义连接发现旨在从表库中找到与查询列有高语义连接性的列。现存的方法可以分为两种类型：单元格级别方法和列级别方法。然而，两者都无法同时保证有效性和效率。单元级方法通过计算列之间的单元匹配来计算连接性，具有理想的有效性但效率低下。相比之下，列级别方法仅通过计算列嵌入的相似度来确定连接性，虽然效率尚可但由于其在列嵌入中存在的问题（i）语义-连接差距，（ii）大小限制，和（iii）排列敏感性而导致有效性较差。为了解决这些问题，本文提出使用代理列来计算列嵌入；此外还提出了一种新的列级语义连接发现框架Snoopy，利用基于代理列的嵌入在有效性和效率之间建立桥梁。具体而言，提出的列嵌入来自隐式的列到代理列关系，通过轻量级近似图匹配基线捕捉该关系。为了获取指导列投影的良好代理列，我们引入了一个排名感知对比学习范式。大量的实验结果表明，Snoopy在Recall@25和NDCG@25上分别比现有最佳方法高出16%和10%，并且至少快五倍于单元级解决方案，在速度上是现有的列级方法的3.5倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic join discovery, which aims to find columns in a table repositorywith high semantic joinabilities to a query column, is crucial for datasetdiscovery. Existing methods can be divided into two categories: cell-levelmethods and column-level methods. However, neither of them ensures botheffectiveness and efficiency simultaneously. Cell-level methods, which computethe joinability by counting cell matches between columns, enjoy idealeffectiveness but suffer poor efficiency. In contrast, column-level methods,which determine joinability only by computing the similarity of columnembeddings, enjoy proper efficiency but suffer poor effectiveness due to theissues occurring in their column embeddings: (i) semantics-joinability-gap,(ii) size limit, and (iii) permutation sensitivity. To address these issues,this paper proposes to compute column embeddings via proxy columns;furthermore, a novel column-level semantic join discovery framework, Snoopy, ispresented, leveraging proxy-column-based embeddings to bridge effectiveness andefficiency. Specifically, the proposed column embeddings are derived from theimplicit column-to-proxy-column relationships, which are captured by thelightweight approximate-graph-matching-based column projection.To acquire goodproxy columns for guiding the column projection, we introduce a rank-awarecontrastive learning paradigm. Extensive experiments on four real-worlddatasets demonstrate that Snoopy outperforms SOTA column-level methods by 16%in Recall@25 and 10% in NDCG@25, and achieves superior efficiency--being atleast 5 orders of magnitude faster than cell-level solutions, and 3.5x fasterthan existing column-level methods.</description>
      <author>example@mail.com (Yuxiang Guo, Yuren Mao, Zhonghao Hu, Lu Chen, Yunjun Gao)</author>
      <guid isPermaLink="false">2502.16813v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Image Translation-Based Unsupervised Cross-Modality Domain Adaptation for Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2502.15193v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图像转换的无监督跨模态领域适应方法，通过将带注释的源模态图像转换为未注释的目标模态，并使用其注释来实现目标模态的监督学习。该方法在跨模态领域适应挑战中的验证阶段表现出色。&lt;h4&gt;背景&lt;/h4&gt;在医学影像中进行监督深度学习通常面临更多挑战，因为标注需要医生的专业知识且耗时费钱；无监督学习方法虽然被采用但性能降低不可避免；医学图像可能来自不同的医疗中心、使用不同设备和采集协议，导致模态差异，进一步降低了深度学习方法的适用性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能有效解决跨模态领域适应问题的方法，并在真实场景中验证其有效性。&lt;h4&gt;方法&lt;/h4&gt;通过将带注释的源模态图像转换为目标模态未标注图像，利用目标模态伪图像上的自训练方法克服细微差异，进一步提高深度学习任务性能。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在跨模态领域适应挑战中的验证阶段中，针对内耳神经瘤（VS）分割任务取得了平均Dice相似系数(DSC)为0.8351 ± 0.1152和对侧半规管（cochlea）的平均对称表面距离(ASSD)为1.6712±2.1948，在针对内耳神经瘤VS及耳蜗分割任务中取得了平均Dice相似系数(DSC)为0.8098 ± 0.0233和平均对称表面距离(ASSD)为0.2317±0.1577。&lt;h4&gt;结论&lt;/h4&gt;所提方法在跨模态领域适应问题上具有显著优势，能够有效应对医学图像的复杂性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Supervised deep learning usually faces more challenges in medical images thanin natural images. Since annotations in medical images require the expertise ofdoctors and are more time-consuming and expensive. Thus, some researchers turnto unsupervised learning methods, which usually face inevitable performancedrops. In addition, medical images may have been acquired at different medicalcenters with different scanners and under different image acquisitionprotocols, so the modalities of the medical images are often inconsistent. Thismodality difference (domain shift) also reduces the applicability of deeplearning methods. In this regard, we propose an unsupervised crossmodalitydomain adaptation method based on image translation by transforming the sourcemodality image with annotation into the unannotated target modality and usingits annotation to achieve supervised learning of the target modality. Inaddition, the subtle differences between translated pseudo images and realimages are overcome by self-training methods to further improve the taskperformance of deep learning. The proposed method showed mean Dice SimilarityCoefficient (DSC) and Average Symmetric Surface Distance (ASSD) of $0.8351 \pm0.1152$ and $1.6712 \pm 2.1948$ for vestibular schwannoma (VS), $0.8098 \pm0.0233$ and $0.2317 \pm 0.1577$ for cochlea on the VS and cochlea segmentationtask of the Cross-Modality Domain Adaptation (crossMoDA 2022) challengevalidation phase leaderboard.</description>
      <author>example@mail.com (Tao Yang, Lisheng Wang)</author>
      <guid isPermaLink="false">2502.15193v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>PointSea: Point Cloud Completion via Self-structure Augmentation</title>
      <link>http://arxiv.org/abs/2502.17053v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by International Journal of Computer Vision. arXiv admin  note: text overlap with arXiv:2307.08492&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;点云补全是3D视觉中的一个基本但尚未完全解决的问题。现有的方法通常依赖于3D坐标信息和/或其他数据（如图像和扫描视角）来填补缺失部分。与这些方法不同，我们探索了自结构增强，并提出了用于全局到局部点云补全的PointSea。&lt;h4&gt;背景&lt;/h4&gt;点云补全是3D视觉中一个基本但仍未完全解决的问题，现有方法通常依赖于额外的数据来进行补全。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法PointSea，利用自投影深度图进行数据增强，并通过特征融合模块从跨模态输入重建紧凑的全局形状，同时在局部阶段揭示高度详细的结构。&lt;h4&gt;方法&lt;/h4&gt;{'全局阶段': 'PointSea通过使用来自多个视角的自我投影深度图像来增强数据表示。它还集成了一种特性融合模块以融合跨视图和同视图级别特征，以便从跨模态输入中重建紧凑的整体形状。', '局部阶段': '在局部阶段，为了揭示高度详细的结构，我们引入了一个名为自结构对偶生成器的点生成器。该生成器结合了学习到的形状先验知识和几何自相似性来进行形状细化。与现有技术使用统一策略不同的是，我们的双路径设计根据每个点的结构类型适应不同的细化策略。', '创新': 'PointSea提出了一种新的方法来处理全局到局部点云补全的问题，通过利用自投影深度图增强数据表示，并采用特征融合模块和自结构对偶生成器进行形状细化。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PointSea能够有效地理解整体形状并从不完整输入中生成详细信息，明显优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;提出的PointSea在广泛的基准测试中展示了优越的表现，证明了其在全球和局部点云补全中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud completion is a fundamental yet not well-solved problem in 3Dvision. Current approaches often rely on 3D coordinate information and/oradditional data (e.g., images and scanning viewpoints) to fill in missingparts. Unlike these methods, we explore self-structure augmentation and proposePointSea for global-to-local point cloud completion. In the global stage,consider how we inspect a defective region of a physical object, we may observeit from various perspectives for a better understanding. Inspired by this,PointSea augments data representation by leveraging self-projected depth imagesfrom multiple views. To reconstruct a compact global shape from the cross-modalinput, we incorporate a feature fusion module to fuse features at bothintra-view and inter-view levels. In the local stage, to reveal highly detailedstructures, we introduce a point generator called the self-structuredual-generator. This generator integrates both learned shape priors andgeometric self-similarities for shape refinement. Unlike existing efforts thatapply a unified strategy for all points, our dual-path design adapts refinementstrategies conditioned on the structural type of each point, addressing thespecific incompleteness of each point. Comprehensive experiments on widely-usedbenchmarks demonstrate that PointSea effectively understands global shapes andgenerates local details from incomplete input, showing clear improvements overexisting methods.</description>
      <author>example@mail.com (Zhe Zhu, Honghua Chen, Xing He, Mingqiang Wei)</author>
      <guid isPermaLink="false">2502.17053v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>A Closer Look at TabPFN v2: Strength, Limitation, and Extension</title>
      <link>http://arxiv.org/abs/2502.17361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文对基于Transformer的Tabular Prior-data Fitted Network v2 (TabPFN v2)模型进行了详尽评估，确认其在小规模至中等规模任务中的卓越泛化能力。&lt;h4&gt;背景&lt;/h4&gt;表格数据集具有内在异质性，给预训练基础模型的发展带来了巨大挑战。最近引入的基于Transformer的Tabular Prior-data Fitted Network v2 (TabPFN v2) 在多个表格数据集中实现了前所未有的上下文学习准确度。&lt;h4&gt;目的&lt;/h4&gt;全面评估TabPFN v2在超过300个数据集上的性能，揭示其成功的机制，并提出扩大其适用性的策略。&lt;h4&gt;方法&lt;/h4&gt;采用随机化特征标记将异质性数据集统一为固定维度表示；通过leave-one-fold-out方法将其转化为特征提取器；引入Chain-of-Thought提示的分而治之机制以支持大规模任务。&lt;h4&gt;主要发现&lt;/h4&gt;分析显示，随机化特征令牌是TabPFN v2成功的关键因素。此外，该模型能够简化数据分布并提高准确性。&lt;h4&gt;结论&lt;/h4&gt;通过揭示TabPFN v2背后的机制，并提出策略来扩大其适用范围，这项研究为未来表格基础模型的发展提供了关键见解。&lt;h4&gt;翻译&lt;/h4&gt;表格数据集具有内在异质性，给预训练基础模型的发展带来了巨大挑战。最近引入的基于Transformer的Tabular Prior-data Fitted Network v2 (TabPFN v2) 在多个表格数据集中实现了前所未有的上下文学习准确度，标志着表格基础模型的重要进展。在该论文中，我们全面评估了TabPFN v2在超过300个数据集上的性能，确认其卓越的小到中等规模任务的泛化能力。我们的分析确定随机化特征令牌是TabPFN v2成功的关键因素，因为它们将异质性表格数据集统一为固定维度表示，从而更有效的训练和推理。为了进一步理解TabPFN v2的预测结果，我们提出了一种leave-one-fold-out方法，使TabPFN v2转变为一个特征提取器，并揭示其简化数据分布并提高准确性的能力。最后，针对TabPFN v2在高维、大规模和多类别任务中的局限性，我们引入了受Chain-of-Thought提示启发的分而治之机制，实现可扩展推理。通过揭示TabPFN v2成功背后的机制并提出策略来扩大其适用范围，这项研究为未来表格基础模型的发展提供了关键见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular datasets are inherently heterogeneous, posing significant challengesfor developing pre-trained foundation models. The recently introducedtransformer-based Tabular Prior-data Fitted Network v2 (TabPFN v2) achievesunprecedented in-context learning accuracy across multiple tabular datasets,marking a pivotal advancement in tabular foundation models. In this paper, wecomprehensively evaluate TabPFN v2 on over 300 datasets, confirming itsexceptional generalization capabilities on small- to medium-scale tasks. Ouranalysis identifies randomized feature tokens as a key factor behind TabPFNv2's success, as they unify heterogeneous datasets into a fixed-dimensionalrepresentation, enabling more effective training and inference. To furtherunderstand TabPFN v2's predictions, we propose a leave-one-fold-out approach,transforming TabPFN v2 into a feature extractor and revealing its capability tosimplify data distributions and boost accuracy. Lastly, to address TabPFN v2'slimitations in high-dimensional, large-scale, and many-category tasks, weintroduce a divide-and-conquer mechanism inspired by Chain-of-Thoughtprompting, enabling scalable inference. By uncovering the mechanisms behindTabPFN v2's success and introducing strategies to expand its applicability,this study provides key insights into the future of tabular foundation models.</description>
      <author>example@mail.com (Han-Jia Ye, Si-Yang Liu, Wei-Lun Chao)</author>
      <guid isPermaLink="false">2502.17361v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>In-context learning of evolving data streams with tabular foundational models</title>
      <link>http://arxiv.org/abs/2502.16840v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;监督分类中的数据流挖掘传统上依赖于增量决策树集成。然而，大型表格模型（即为结构化数值数据设计的transformer）标志着一个重要的范式转变。&lt;h4&gt;目的&lt;/h4&gt;探索实时模型适应性，并探讨transformer在动态环境下的自适应学习能力。&lt;h4&gt;方法&lt;/h4&gt;使用预训练模型和在线提示调整进行上下文学习。通过利用滑动窗口内存策略，TabPFN能够有效处理无限流数据。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，TabPFN结合简单的滑动内存策略，在所有非平稳基准测试中始终优于Hoeffding树集成。&lt;h4&gt;结论&lt;/h4&gt;论文概述了几种有前景的研究方向，并鼓励社区探索这些想法，以便在上下文流学习方面取得进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了当前监督分类中的数据流挖掘技术从传统的增量决策树转向大型表格模型（transformer）的转变。通过引入在线提示调整和预训练模型来处理无界流数据，实现了实时模型适应性研究，并展示了TabPFN在这种场景下的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State-of-the-art data stream mining in supervised classification hastraditionally relied on ensembles of incremental decision trees. However, theemergence of large tabular models, i.e., transformers designed for structurednumerical data, marks a significant paradigm shift. These models move beyondtraditional weight updates, instead employing in-context learning throughprompt tuning. By using on-the-fly sketches to summarize unbounded streamingdata, one can feed this information into a pre-trained model for efficientprocessing. This work bridges advancements from both areas, highlighting howtransformers' implicit meta-learning abilities, pre-training on driftingnatural data, and reliance on context optimization directly address the corechallenges of adaptive learning in dynamic environments. Exploring real-timemodel adaptation, this research demonstrates that TabPFN, coupled with a simplesliding memory strategy, consistently outperforms ensembles of Hoeffding treesacross all non-stationary benchmarks. Several promising research directions areoutlined in the paper. The authors urge the community to explore these ideas,offering valuable opportunities to advance in-context stream learning.</description>
      <author>example@mail.com (Afonso Lourenço, João Gama, Eric P. Xing, Goreti Marreiros)</author>
      <guid isPermaLink="false">2502.16840v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>VGFL-SA: Vertical Graph Federated Learning Structure Attack Based on Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.16793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为VGFL-SA的新颖图对抗攻击，旨在通过修改本地客户端的结构而不使用标签信息来降低垂直联邦学习（VGFL）框架的性能。&lt;h4&gt;背景&lt;/h4&gt;由于隐私保护和利益冲突，需要开发出能够在不直接分享图数据的情况下进行协作训练的垂直联邦图神经网络。现有的对抗性攻击依赖于标签信息的有效性受到限制，这在实际应用中存在局限性。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有VGFL框架中的未标记客户端问题并提高其安全性，研究人员提出了一种新的对抗攻击方法。&lt;h4&gt;方法&lt;/h4&gt;研究者采用对比学习的方法，在本地客户端训练之前完成攻击任务。具体来说，该方法利用图结构和节点特征信息生成对比视图，并通过共享的图编码器获取每个视图的嵌入表示，进而获得邻接矩阵的梯度并生成扰动边。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，提出的VGFL-SA在现实世界数据集上的节点分类任务中展现了良好的攻击效果和可转移性。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习技术完成无标签信息参与的图对抗攻击可以有效地降低基于垂直联邦框架下GNNs模型的学习性能，这为未来的安全研究提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have gained attention for their ability to learnrepresentations from graph data. Due to privacy concerns and conflicts ofinterest that prevent clients from directly sharing graph data with oneanother, Vertical Graph Federated Learning (VGFL) frameworks have beendeveloped. Recent studies have shown that VGFL is vulnerable to adversarialattacks that degrade performance. However, it is a common problem that clientnodes are often unlabeled in the realm of VGFL. Consequently, the existingattacks, which rely on the availability of labeling information to obtaingradients, are inherently constrained in their applicability. This limitationprecludes their deployment in practical, real-world environments. To addressthe above problems, we propose a novel graph adversarial attack against VGFL,referred to as VGFL-SA, to degrade the performance of VGFL by modifying thelocal clients structure without using labels. Specifically, VGFL-SA uses acontrastive learning method to complete the attack before the local clients aretrained. VGFL-SA first accesses the graph structure and node featureinformation of the poisoned clients, and generates the contrastive views bynode-degree-based edge augmentation and feature shuffling augmentation. Then,VGFL-SA uses the shared graph encoder to get the embedding of each view, andthe gradients of the adjacency matrices are obtained by the contrastivefunction. Finally, perturbed edges are generated using gradient modificationrules. We validated the performance of VGFL-SA by performing a nodeclassification task on real-world datasets, and the results show that VGFL-SAachieves good attack effectiveness and transferability.</description>
      <author>example@mail.com (Yang Chen, Bin Zhou)</author>
      <guid isPermaLink="false">2502.16793v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MetaSym: A Symplectic Meta-learning Framework for Physical Intelligence</title>
      <link>http://arxiv.org/abs/2502.16667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8+10 pages, 5 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的深度学习架构MetaSym，结合了强对称归纳偏差和自回归解码器，用于解决物理感知深度学习的挑战。&lt;h4&gt;背景&lt;/h4&gt;具有广泛应用领域的可扩展且通用的物理感知深度学习长期以来一直被视为重大难题。几乎所有物理系统的核心都是辛形式，它支撑着能量、动量等基本不变性。&lt;h4&gt;目的&lt;/h4&gt;引入MetaSym架构，确保核心物理不变性的完整性和灵活的数据高效适应系统异质性。&lt;h4&gt;方法&lt;/h4&gt;将一个获得自对称编码器的强辛归纳偏差和一个具有元注意力机制的自回归解码器相结合来构建新型深度学习架构MetaSym。&lt;h4&gt;主要发现&lt;/h4&gt;在包括高维弹簧网格系统、开放量子系统以及四旋翼动态等多样化数据集上的基准测试中，MetaSym表现出色，在少样本适应情况下模型性能优于现有的最先进的基线方法，并且使用远小于这些基线方法的规模模型就达到了这一效果。&lt;h4&gt;结论&lt;/h4&gt;提出的MetaSym架构在物理感知深度学习任务上具有显著优势，尤其适用于需要灵活适应系统异质性的场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scalable and generalizable physics-aware deep learning has long beenconsidered a significant challenge with various applications across diversedomains ranging from robotics to molecular dynamics. Central to almost allphysical systems are symplectic forms, the geometric backbone that underpinsfundamental invariants like energy and momentum. In this work, we introduce anovel deep learning architecture, MetaSym. In particular, MetaSym combines astrong symplectic inductive bias obtained from a symplectic encoder and anautoregressive decoder with meta-attention. This principled design ensures thatcore physical invariants remain intact while allowing flexible, data-efficientadaptation to system heterogeneities. We benchmark MetaSym on highly varieddatasets such as a high-dimensional spring mesh system (Otness et al., 2021),an open quantum system with dissipation and measurement backaction, androbotics-inspired quadrotor dynamics. Our results demonstrate superiorperformance in modeling dynamics under few-shot adaptation, outperformingstate-of-the-art baselines with far larger models.</description>
      <author>example@mail.com (Pranav Vaidhyanathan, Aristotelis Papatheodorou, Mark T. Mitchison, Natalia Ares, Ioannis Havoutis)</author>
      <guid isPermaLink="false">2502.16667v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>RELICT: A Replica Detection Framework for Medical Image Generation</title>
      <link>http://arxiv.org/abs/2502.17360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;尽管合成医疗数据在增强和提高深度学习模型的泛化能力方面具有潜力，但生成模型中的记忆效应可能导致敏感患者信息意外泄露，并限制了模型的实用性。因此，在医学领域使用能够记住训练数据的生成模型可能会危及患者的隐私。&lt;h4&gt;背景&lt;/h4&gt;在医疗领域，利用合成医疗数据来增强和提高深度学习模型的泛化能力是一个潜在的重要研究方向。然而，生成模型中存在的记忆问题可能导致敏感患者信息的泄露，并限制了这些模型的实际应用价值。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架用于识别合成医学图像数据集中的副本（即与训练数据几乎相同的近似拷贝），旨在为医疗成像领域负责任和伦理地使用合成图像提供标准化且易于使用的工具。&lt;h4&gt;方法&lt;/h4&gt;RELICT框架通过三种互补的方法评估图像的相似性：1）体素级别分析；2）由预训练的医学基础模型进行特征级别分析；3）分割级别分析。针对两种临床相关的三维生成建模应用场景进行了研究：非对比头CT与脑内出血（N=774）和圈套动脉的时间飞跃磁共振血管成像（TOF-MRA，N=1,782）。使用专家视觉评分作为参考标准来评估副本的存在。&lt;h4&gt;主要发现&lt;/h4&gt;对于NCCT用例，在选择了最佳阈值的情况下，图像级别和特征级别测量方法可以完美地分类副本，平衡准确率为1；而对于TOF-MRA案例，则无法在任何阈值下实现完美的副本分类，但分割级别分析的平衡准确性为0.79。&lt;h4&gt;结论&lt;/h4&gt;副本检测是生成模型开发中的一个关键但被忽视的验证步骤。RELICT框架提供了一个标准化、易于使用的工具来识别副本，并旨在促进医学图像合成的责任感和伦理规范。&lt;h4&gt;其他细节&lt;/h4&gt;本研究强调了在医疗影像领域发展生成模型时，防止敏感信息泄露的重要性，并提出了一种新的评估方法用于检测合成数据集中可能出现的真实训练数据副本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the potential of synthetic medical data for augmenting and improvingthe generalizability of deep learning models, memorization in generative modelscan lead to unintended leakage of sensitive patient information and limit modelutility. Thus, the use of memorizing generative models in the medical domaincan jeopardize patient privacy. We propose a framework for identifyingreplicas, i.e. nearly identical copies of the training data, in syntheticmedical image datasets. Our REpLIca deteCTion (RELICT) framework for medicalimage generative models evaluates image similarity using three complementaryapproaches: (1) voxel-level analysis, (2) feature-level analysis by apretrained medical foundation model, and (3) segmentation-level analysis. Twoclinically relevant 3D generative modelling use cases were investigated:non-contrast head CT with intracerebral hemorrhage (N=774) and time-of-flightMR angiography of the Circle of Willis (N=1,782). Expert visual scoring wasused as the reference standard to assess the presence of replicas. We reportthe balanced accuracy at the optimal threshold to assess replica classificationperformance. The reference visual rating identified 45 of 50 and 5 of 50generated images as replicas for the NCCT and TOF-MRA use cases, respectively.Image-level and feature-level measures perfectly classified replicas with abalanced accuracy of 1 when an optimal threshold was selected for the NCCT usecase. A perfect classification of replicas for the TOF-MRA case was notpossible at any threshold, with the segmentation-level analysis achieving abalanced accuracy of 0.79. Replica detection is a crucial but neglectedvalidation step for the development of generative models in medical imaging.The proposed RELICT framework provides a standardized, easy-to-use tool forreplica detection and aims to facilitate responsible and ethical medical imagesynthesis.</description>
      <author>example@mail.com (Orhun Utku Aydin, Alexander Koch, Adam Hilbert, Jana Rieger, Felix Lohrke, Fujimaro Ishida, Satoru Tanioka, Dietmar Frey)</author>
      <guid isPermaLink="false">2502.17360v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Cross-domain Few-shot Object Detection with Multi-modal Textual Enrichment</title>
      <link>http://arxiv.org/abs/2502.16469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2403.16188&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于元学习的框架，通过引入丰富的文本语义作为辅助模态来解决跨域多模态少样本目标检测中的领域偏移问题。&lt;h4&gt;背景&lt;/h4&gt;当前的多模态物体检测方法在遇到显著的领域变化时会表现出性能下降。现有的跨模态特征提取和集成的进步提高了少量样本学习任务的表现，但仍然面临挑战。&lt;h4&gt;目的&lt;/h4&gt;通过结合丰富的文本信息来增强模型建立视觉实例与其语言描述之间的知识关系的能力，从而减轻领域偏移带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架用于解决跨域多模态少样本目标检测问题。该框架包含两个关键组件：一个多模态特征聚合模块和一个丰富文本语义修正模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在常见的跨域物体检测基准上，所提方法显著超越了现有的少样本物体检测方法。&lt;h4&gt;结论&lt;/h4&gt;通过引入元学习的框架并利用丰富的文本信息，论文成功地提高了模型在领域偏移情况下的适应性和准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个旨在解决跨域多模态少样本目标检测问题的方法。该方法结合了视觉和语言特征，并采用了文本语义修正模块来增强其性能。实验结果显示，在标准基准测试中，这种方法优于现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in cross-modal feature extraction and integration havesignificantly enhanced performance in few-shot learning tasks. However, currentmulti-modal object detection (MM-OD) methods often experience notableperformance degradation when encountering substantial domain shifts. We proposethat incorporating rich textual information can enable the model to establish amore robust knowledge relationship between visual instances and theircorresponding language descriptions, thereby mitigating the challenges ofdomain shift. Specifically, we focus on the problem of Cross-Domain Multi-ModalFew-Shot Object Detection (CDMM-FSOD) and introduce a meta-learning-basedframework designed to leverage rich textual semantics as an auxiliary modalityto achieve effective domain adaptation. Our new architecture incorporates twokey components: (i) A multi-modal feature aggregation module, which alignsvisual and linguistic feature embeddings to ensure cohesive integration acrossmodalities. (ii) A rich text semantic rectification module, which employsbidirectional text feature generation to refine multi-modal feature alignment,thereby enhancing understanding of language and its application in objectdetection. We evaluate the proposed method on common cross-domain objectdetection benchmarks and demonstrate that it significantly surpasses existingfew-shot object detection approaches.</description>
      <author>example@mail.com (Zeyu Shangguan, Daniel Seita, Mohammad Rostami)</author>
      <guid isPermaLink="false">2502.16469v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Utilizing AI and Machine Learning for Predictive Analysis of Post-Treatment Cancer Recurrence</title>
      <link>http://arxiv.org/abs/2502.15825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;探讨了人工智能和机器学习在癌症复发预测中的应用，以及它们如何通过分析大量遗传学、临床表现和治疗数据来提高个性化医疗水平。&lt;h4&gt;背景&lt;/h4&gt;肿瘤复发是肿瘤学中一个主要挑战，传统的癌症复发预测依赖于统计模型支持的临床观察，但无法完全解释其复杂的多因素特性。&lt;h4&gt;目的&lt;/h4&gt;研究AI和ML在癌症复发预测中的潜在应用，以改善治疗后的患者生存率和生活质量。&lt;h4&gt;方法&lt;/h4&gt;描述了使用监督学习和无监督学习技术来识别模式并预测癌症患者的结局的各种AI和ML技术。&lt;h4&gt;主要发现&lt;/h4&gt;AI和ML技术能够提供早期干预的机会，并有助于设计更有效的治疗计划。&lt;h4&gt;结论&lt;/h4&gt;AI和ML为个性化医学和患者管理提供了新的机会，提高了复发预测的准确性和可靠性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已从英文翻译为中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.60087/jklst.vol2.n3.p599&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In oncology, recurrence after treatment is one of the major challenges,related to patients' survival and quality of life. Conventionally, predictionof cancer relapse has always relied on clinical observation with statisticalmodel support, which almost fails to explain the complex, multifactorial natureof tumor recurrence. This research explores how AI and ML models may increasethe accuracy and reliability of recurrence prediction in cancer. Therefore, AIand ML create new opportunities not only for personalized medicine but also forproactive management of patients through analyzing large volumes of data ongenetics, clinical manifestations, and treatment. The paper describes thevarious AI and ML techniques for pattern identification and outcome predictionin cancer patients using supervised and unsupervised learning. Clinicalimplications provide an opportunity to review how early interventions couldhappen and the design of treatment planning.</description>
      <author>example@mail.com (Muhammad Umer Qayyum, Muhammad Fahad, Nasrullah Abbasi)</author>
      <guid isPermaLink="false">2502.15825v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Trunk-branch Contrastive Network with Multi-view Deformable Aggregation for Multi-view Action Recognition</title>
      <link>http://arxiv.org/abs/2502.16493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的称为TBCNet的框架，用于基于RGB多视角的动作识别。该网络通过主干和分支的对比学习过程获得融合特征，并补充关键细节。&lt;h4&gt;背景&lt;/h4&gt;传统的动作识别研究通常从每个视图中提取精炼特征，然后实现配对交互和整合，但这种方法可能会忽视每个视图中的重要局部特征。&lt;h4&gt;目的&lt;/h4&gt;为了模拟人类从多个角度观察物体时形成的综合印象以及随后填补具体细节的认知过程，提出了一种新的网络框架TBCNet。&lt;h4&gt;方法&lt;/h4&gt;设计了两个核心组件：多视角可变形聚集（MVDA）和主干-分支对比学习。 MVDA利用全局汇聚模块强调重要的空间信息，并通过复合相对位置偏差捕捉视图内的及跨视图的相对位置，而主干-分支对比损失则是在聚合特征与每个视图中的精炼细节之间构建。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示TBCNet在NTU-RGB+D 60, NTU-RGB+D 120, PKU-MMD和N-UCLA等四个数据集上优于其他基于RGB的方法，尤其在跨主体（Cross-Subject）及跨场景（Cross-View）协议下取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为RGB多视角动作识别提供了一种有效的新方法TBCNet，并通过实验验证了其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view action recognition aims to identify actions in a given multi-viewscene. Traditional studies initially extracted refined features from each view,followed by implemented paired interaction and integration, but theypotentially overlooked the critical local features in each view. When observingobjects from multiple perspectives, individuals typically form a comprehensiveimpression and subsequently fill in specific details. Drawing inspiration fromthis cognitive process, we propose a novel trunk-branch contrastive network(TBCNet) for RGB-based multi-view action recognition. Distinctively, TBCNetfirst obtains fused features in the trunk block and then implicitly supplementsvital details provided by the branch block via contrastive learning, generatinga more informative and comprehensive action representation. Within thisframework, we construct two core components: the multi-view deformableaggregation and the trunk-branch contrastive learning. MVDA employed in thetrunk block effectively facilitates multi-view feature fusion and adaptivecross-view spatio-temporal correlation, where a global aggregation module isutilized to emphasize significant spatial information and a composite relativeposition bias is designed to capture the intra- and cross-view relativepositions. Moreover, a trunk-branch contrastive loss is constructed betweenaggregated features and refined details from each view. By incorporating twodistinct weights for positive and negative samples, a weighted trunk-branchcontrastive loss is proposed to extract valuable information and emphasizesubtle inter-class differences. The effectiveness of TBCNet is verified byextensive experiments on four datasets including NTU-RGB+D 60, NTU-RGB+D 120,PKU-MMD, and N-UCLA dataset. Compared to other RGB-based methods, our approachachieves state-of-the-art performance in cross-subject and cross-settingprotocols.</description>
      <author>example@mail.com (Yingyuan Yang, Guoyuan Liang, Can Wang, Xiaojun Wu)</author>
      <guid isPermaLink="false">2502.16493v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Layer-Wise Evolution of Representations in Fine-Tuned Transformers: Insights from Sparse AutoEncoders</title>
      <link>http://arxiv.org/abs/2502.16722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了预训练变压器微调过程中的内部机制，特别是BERT模型，并通过分析激活相似性、训练稀疏自编码器以及可视化不同层的标记级激活来探索这一过程。&lt;h4&gt;背景&lt;/h4&gt;微调预训练的变换器是增强基础模型在特定任务上性能的强大技术。这种方法对于将通用架构适应于专门的任务非常关键，从早期应用到如BERT这样的模型到现在用于大型语言模型（LLM）的应用。&lt;h4&gt;目的&lt;/h4&gt;理解微调过程对于揭示变压器如何根据具体目标进行调整、保留一般表示以及获取任务特有特征至关重要。&lt;h4&gt;方法&lt;/h4&gt;论文通过分析激活相似性、训练稀疏自编码器和可视化不同层的标记级激活来探索微调机制，特别是针对BERT变换器。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示随着深度增加，特征如何适应任务的变化：早期层次主要保留一般表示；中间层次充当通用与任务特有特征之间的过渡；后期层次完全专注于任务适应。&lt;h4&gt;结论&lt;/h4&gt;这些发现在理解微调过程和它对转换架构内表征学习的影响方面提供了关键见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning pre-trained transformers is a powerful technique for enhancingthe performance of base models on specific tasks. From early applications inmodels like BERT to fine-tuning Large Language Models (LLMs), this approach hasbeen instrumental in adapting general-purpose architectures for specializeddownstream tasks. Understanding the fine-tuning process is crucial foruncovering how transformers adapt to specific objectives, retain generalrepresentations, and acquire task-specific features. This paper explores theunderlying mechanisms of fine-tuning, specifically in the BERT transformer, byanalyzing activation similarity, training Sparse AutoEncoders (SAEs), andvisualizing token-level activations across different layers. Based onexperiments conducted across multiple datasets and BERT layers, we observe asteady progression in how features adapt to the task at hand: early layersprimarily retain general representations, middle layers act as a transitionbetween general and task-specific features, and later layers fully specializein task adaptation. These findings provide key insights into the inner workingsof fine-tuning and its impact on representation learning within transformerarchitectures.</description>
      <author>example@mail.com (Suneel Nadipalli)</author>
      <guid isPermaLink="false">2502.16722v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning of English Language and Crystal Graphs for Multimodal Representation of Materials Knowledge</title>
      <link>http://arxiv.org/abs/2502.16451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 14 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了用于材料逆向设计的人工智能（AI）在晶体领域的应用，提出了对比语言-晶体模型CLaC，并通过实验验证了其优越性。&lt;h4&gt;背景&lt;/h4&gt;人工智能技术越来越多地应用于材料的逆向设计中，尤其是在分子领域，已经成功将化学结构与文本知识结合使用。然而，在晶体研究方面，由于偏斜的数据分布和学术文献中的语义监督不足，这种方法难以实现。&lt;h4&gt;目的&lt;/h4&gt;为了克服数据稀缺问题，并展示合成数据在解决这一问题上的优势，提出了一种新的对比语言-晶体模型CLaC。&lt;h4&gt;方法&lt;/h4&gt;通过构建包含126k晶体结构文本对的新合成数据集和一个从学术论文中提取的相似数据集，预训练了CLaC模型。然后评估其跨模态任务和下游应用中的零样本泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CLaC在理解晶体结构方面实现了最新的零样本泛化性能，并且超越了现有的大型语言模型。&lt;h4&gt;结论&lt;/h4&gt;所提出的CLaC模型展示了其在理解和设计晶体材料方面的潜力，为未来的AI辅助逆向材料设计提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的原文是关于介绍了一种对比语言-晶体模型（CLaC），该模型基于126K个合成的数据集进行预训练，并通过跨模态任务和下游应用验证了其优越性，特别是在零样本泛化性能方面超越了当前的大规模语言模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) is increasingly used for the inverse design ofmaterials, such as crystals and molecules. Existing AI research on moleculeshas integrated chemical structures of molecules with textual knowledge to adaptto complex instructions. However, this approach has been unattainable forcrystals due to data scarcity from the biased distribution of investigatedcrystals and the lack of semantic supervision in peer-reviewed literature. Inthis work, we introduce a contrastive language-crystals model (CLaC)pre-trained on a newly synthesized dataset of 126k crystal structure-textpairs. To demonstrate the advantage of using synthetic data to overcome datascarcity, we constructed a comparable dataset extracted from academic papers.We evaluate CLaC's generalization ability through various zero-shot cross-modaltasks and downstream applications. In experiments, CLaC achievesstate-of-the-art zero-shot generalization performance in understanding crystalstructures, surpassing latest large language models.</description>
      <author>example@mail.com (Yang Jeong Park, Mayank Kumaran, Chia-Wei Hsu, Elsa Olivetti, Ju Li)</author>
      <guid isPermaLink="false">2502.16451v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Shakti-VLMs: Scalable Vision-Language Models for Enterprise AI</title>
      <link>http://arxiv.org/abs/2502.17092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Shakti VLM是一个包含10亿和40亿参数的视觉-语言模型家族，旨在解决多模态学习中的数据效率挑战。&lt;h4&gt;背景&lt;/h4&gt;近年来，许多视觉-语言模型通过大量训练数据取得了优异的成绩。然而，在大规模数据集不可用的情况下，现有方法难以有效解决问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种可以利用架构创新来减少对海量训练数据依赖的视觉-语言模型。&lt;h4&gt;方法&lt;/h4&gt;1. 使用QK-Normalization提高注意力机制的稳定性2. 引入混合归一化技术以增强模型性能3. 采用改进的位置编码提升多模态理解能力4. 实施三阶段训练策略优化学习效率&lt;h4&gt;主要发现&lt;/h4&gt;Shakti VLM-1B和Shakti VLM-4B在文档理解、视觉推理、光学字符识别提取以及通用的多模态推理任务中表现出色，证明了良好的模型设计和有效的训练策略同样可以实现高精度。&lt;h4&gt;结论&lt;/h4&gt;研究表明，通过精心设计的架构和技术创新可以使模型更加高效地处理大规模的多模态任务，并且不必依赖海量的数据集。Shakti VLM为解决企业级应用场景中的问题提供了一个高效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：我们介绍了Shakti VLM，这是一个参数容量分别为10亿和40亿的视觉-语言模型家族，旨在应对多模态学习中数据效率方面的挑战。尽管最近的一些视觉-语言模型通过大量训练数据取得了良好的成绩，但Shakti模型则利用架构创新，在较少的数据量下也能取得竞争性的结果。关键改进包括用于提高注意力机制稳定性的QK归一化技术、混合归一化方法以及增强的位置编码策略。此外，一种三阶段的训练策略进一步优化了学习效率。评估结果显示，无论是文档理解还是视觉推理等多模态任务，Shakti VLM-1B和Shakti VLM-4B均表现出色。我们的研究结果表明，通过模型设计和有效的训练策略可以实现高精度，而不需要依靠大量数据集的支持。这使得Shakti成为大规模多模态应用场景下的一种高效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Shakti VLM, a family of vision-language models in the capacityof 1B and 4B parameters designed to address data efficiency challenges inmultimodal learning. While recent VLMs achieve strong performance throughextensive training data, Shakti models leverage architectural innovations toattain competitive results with fewer tokens. Key advancements includeQK-Normalization for attention stability, hybrid normalization techniques, andenhanced positional encoding. A three-stage training strategy further optimizeslearning efficiency. Evaluations show that Shakti-Shakti-VLM-1B andShakti-VLM-4B excel in document understanding, Visual Reasoning, OCRextraction, and general multimodal reasoning. Our results highlight that highperformance can be achieved through model design and training strategy ratherthan sheer data volume, making Shakti an efficient solution forenterprise-scale multimodal tasks.</description>
      <author>example@mail.com (Syed Abdul Gaffar Shakhadri, Kruthika KR, Kartik Basavaraj Angadi)</author>
      <guid isPermaLink="false">2502.17092v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>DemoGen: Synthetic Demonstration Generation for Data-Efficient Visuomotor Policy Learning</title>
      <link>http://arxiv.org/abs/2502.16932v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://demo-generation.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种低成本的合成数据生成方法DemoGen，该方法能够在不需要大量人工采集的情况下自动生成演示任务，并通过3D点云和场景编辑来增强空间推广能力。&lt;h4&gt;背景&lt;/h4&gt;视觉运动策略在机器人操作中显示出巨大潜力，但由于其有限的空间泛化能力，通常需要大量的手工收集的数据以实现有效性能。&lt;h4&gt;目的&lt;/h4&gt;提出一个低成本、全合成的方法DemoGen，用于自动生成演示，仅需少量的人类收集的示例即可推广到新的对象配置上。&lt;h4&gt;方法&lt;/h4&gt;通过使用3D点云作为观察模式，并通过场景编辑重新排列主体来生成视觉观测。这种方法允许将已有的动作轨迹适应于新的物体布局中。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，DemoGen能够显著提高在各种现实世界操作任务中的策略性能，甚至包括复杂的情境如变形对象、灵巧的手末端执行器和双臂平台的操作。&lt;h4&gt;结论&lt;/h4&gt;除了改进空间推广能力外，DemoGen还可以扩展以提供额外的分布外功能，例如对干扰的抵抗能力和避障能力。&lt;h4&gt;翻译&lt;/h4&gt;视觉运动策略在机器人操作中已显示出巨大的潜力，但为了实现有效性能，通常需要大量的手工收集的数据。一个主要原因在于其有限的空间泛化能力，这要求必须跨越不同物体配置广泛地采集数据。在这项工作中，我们提出了DemoGen，这是一种低成本、完全合成的方法来自动生成演示。利用仅需一次的人工收集的示例，DemoGen通过适应已展示的动作轨迹到新的物体布局中来生成空间增强的演示。视觉观测是通过使用3D点云作为模态并重新排列场景中的主体以实现3D编辑的方式进行合成。实证上，DemoGen显著提升了在各种现实世界操作任务中的策略性能，并展示了其在涉及可变形对象、灵巧手末端执行器和双臂平台的挑战性情况下的应用潜力。此外，DemoGen可以扩展以提供额外的分布外功能，包括干扰抵抗能力和避障能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visuomotor policies have shown great promise in robotic manipulation butoften require substantial amounts of human-collected data for effectiveperformance. A key reason underlying the data demands is their limited spatialgeneralization capability, which necessitates extensive data collection acrossdifferent object configurations. In this work, we present DemoGen, a low-cost,fully synthetic approach for automatic demonstration generation. Using only onehuman-collected demonstration per task, DemoGen generates spatially augmenteddemonstrations by adapting the demonstrated action trajectory to novel objectconfigurations. Visual observations are synthesized by leveraging 3D pointclouds as the modality and rearranging the subjects in the scene via 3Dediting. Empirically, DemoGen significantly enhances policy performance acrossa diverse range of real-world manipulation tasks, showing its applicabilityeven in challenging scenarios involving deformable objects, dexterous handend-effectors, and bimanual platforms. Furthermore, DemoGen can be extended toenable additional out-of-distribution capabilities, including disturbanceresistance and obstacle avoidance.</description>
      <author>example@mail.com (Zhengrong Xue, Shuying Deng, Zhenyang Chen, Yixuan Wang, Zhecheng Yuan, Huazhe Xu)</author>
      <guid isPermaLink="false">2502.16932v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Adversarial Training for Defense Against Label Poisoning Attacks</title>
      <link>http://arxiv.org/abs/2502.17121v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the International Conference on Learning Representations  (ICLR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的对抗训练防御策略FLORAL，该策略基于支持向量机（SVM）来应对模型训练过程中标签中毒攻击的威胁。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习模型越来越复杂且依赖于公共数据源进行训练，例如大规模语言模型使用的标注数据，这些模型更容易受到标签中毒攻击。这种攻击方式是通过对手微妙地改变训练集中的标签来进行的，这可能导致模型性能严重下降，在关键应用中造成重大风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的防御策略FLORAL来对抗由标签中毒造成的威胁。&lt;h4&gt;方法&lt;/h4&gt;基于支持向量机（SVM）和双层优化框架，将训练过程描述为攻防双方的非零和斯塔克伯格博弈。该方法适应多种模型架构，并使用带有核函数的支持向量机进行投影梯度下降算法以执行对抗训练。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明了算法收敛性的特性，实验结果证实FLORAL在各种分类任务中均能取得比Robust基线和RoBERTa等基础模型更好的鲁棒准确性。当攻击者预算增加时，FLORAL仍然能够保持更高的稳健精度。&lt;h4&gt;结论&lt;/h4&gt;FLORAL策略具有提高机器学习模型对抗标签中毒威胁的鲁棒性的潜力，在敌对环境中确保分类任务的安全性和稳定性。&lt;h4&gt;翻译&lt;/h4&gt;随着机器学习模型变得越来越复杂，并且越来越多地依赖于公开来源的数据，例如在训练大型语言模型时使用的由人类标注的标签，这些模型更容易受到标签中毒攻击。这种攻击方式是通过对手微妙地改变训练数据集中的标签来执行的，这可能导致模型性能严重下降，在关键应用中造成重大风险。在这篇论文中，我们提出了FLORAL策略，这是一种基于支持向量机（SVM）的新对抗性训练防御策略，用于应对这些威胁。使用双层优化框架，我们将训练过程描述为攻防双方之间的非零和斯塔克伯格博弈，一方是战略性地污染关键训练标签的攻击者，另一方是试图从这些攻击中恢复过来的模型。该方法适用于多种架构，并采用带有核函数的支持向量机进行投影梯度下降算法来进行对抗性训练。我们提供了该算法收敛性质的理论分析，并通过实验证明了FLORAL策略在各种分类任务中的有效性。与鲁棒基线和基础模型（如RoBERTa）相比，随着攻击者预算增加时，FLORAL始终能保持更高的稳健精度。这些结果强调了FLORAL提高机器学习模型对抗标签中毒威胁的韧性潜力，在敌对环境中确保分类任务的安全性和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As machine learning models grow in complexity and increasingly rely onpublicly sourced data, such as the human-annotated labels used in traininglarge language models, they become more vulnerable to label poisoning attacks.These attacks, in which adversaries subtly alter the labels within a trainingdataset, can severely degrade model performance, posing significant risks incritical applications. In this paper, we propose FLORAL, a novel adversarialtraining defense strategy based on support vector machines (SVMs) to counterthese threats. Utilizing a bilevel optimization framework, we cast the trainingprocess as a non-zero-sum Stackelberg game between an attacker, whostrategically poisons critical training labels, and the model, which seeks torecover from such attacks. Our approach accommodates various modelarchitectures and employs a projected gradient descent algorithm with kernelSVMs for adversarial training. We provide a theoretical analysis of ouralgorithm's convergence properties and empirically evaluate FLORAL'seffectiveness across diverse classification tasks. Compared to robust baselinesand foundation models such as RoBERTa, FLORAL consistently achieves higherrobust accuracy under increasing attacker budgets. These results underscore thepotential of FLORAL to enhance the resilience of machine learning modelsagainst label poisoning threats, thereby ensuring robust classification inadversarial settings.</description>
      <author>example@mail.com (Melis Ilayda Bal, Volkan Cevher, Michael Muehlebach)</author>
      <guid isPermaLink="false">2502.17121v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Unified Semantic and ID Representation Learning for Deep Recommenders</title>
      <link>http://arxiv.org/abs/2502.16474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合ID和语义表示的推荐系统框架，旨在解决传统基于ID令牌的推荐系统的冗余问题以及新项目冷启动时的表现不佳的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的推荐系统依赖于ID令牌来唯一标识项目，但在处理项目重复和新项目的推荐方面存在不足。最近的方法尝试使用语义令牌作为替代方案，但面临挑战如项目复制和不一致的性能提升。&lt;h4&gt;目的&lt;/h4&gt;开发一种综合了ID和语义表示的学习框架以克服现有方法的局限性，并探索余弦相似度和欧几里得距离在嵌入搜索中的作用。&lt;h4&gt;方法&lt;/h4&gt;提出了一个统一的ID与语义表示学习框架，该框架利用两种令牌类型的优势。在这个框架中，ID令牌捕捉项目独特属性，而语义令牌则代表共享、可转移的特点。此外，还分析了余弦相似度和欧几里得距离在嵌入搜索中的作用，并整合这两种方法来优化表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法显著优于现有的基准模型，在三个基准数据集上的性能提高了6%至17%，并且令牌大小减少了超过80%。&lt;h4&gt;结论&lt;/h4&gt;本文证明了将ID和语义标记结合可以增强推荐系统的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;有效的推荐对大型在线平台至关重要。传统的推荐系统主要依赖于标识符（ID）令牌来唯一识别项目，能够有效捕捉特定项目的联系，但在冗余性和冷启动场景中的表现不佳。最近的研究探索了使用语义令牌作为替代方法，但面临诸如项目复制和不一致性能收益的问题。为解决这些局限性，本文提出了一种综合ID与语义表示的学习框架，利用两种标记类型的优势。实验显示该方法在三个基准数据集上显著优于现有基线模型，改善幅度从6%到17%，并且令牌大小减少了超过80%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective recommendation is crucial for large-scale online platforms.Traditional recommendation systems primarily rely on ID tokens to uniquelyidentify items, which can effectively capture specific item relationships butsuffer from issues such as redundancy and poor performance in cold-startscenarios. Recent approaches have explored using semantic tokens as analternative, yet they face challenges, including item duplication andinconsistent performance gains, leaving the potential advantages of semantictokens inadequately examined. To address these limitations, we propose aUnified Semantic and ID Representation Learning framework that leverages thecomplementary strengths of both token types. In our framework, ID tokenscapture unique item attributes, while semantic tokens represent shared,transferable characteristics. Additionally, we analyze the role of cosinesimilarity and Euclidean distance in embedding search, revealing that cosinesimilarity is more effective in decoupling accumulated embeddings, whileEuclidean distance excels in distinguishing unique items. Our frameworkintegrates cosine similarity in earlier layers and Euclidean distance in thefinal layer to optimize representation learning. Experiments on three benchmarkdatasets show that our method significantly outperforms state-of-the-artbaselines, with improvements ranging from 6\% to 17\% and a reduction in tokensize by over 80%. These results demonstrate the effectiveness of combining IDand semantic tokenization to enhance the generalization ability of recommendersystems.</description>
      <author>example@mail.com (Guanyu Lin, Zhigang Hua, Tao Feng, Shuang Yang, Bo Long, Jiaxuan You)</author>
      <guid isPermaLink="false">2502.16474v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Separated Contrastive Learning for Matching in Cross-domain Recommendation with Curriculum Scheduling</title>
      <link>http://arxiv.org/abs/2502.16239v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TheWebConf 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SCCDR的新框架，用于解决跨域推荐任务中的训练不稳定问题。&lt;h4&gt;背景&lt;/h4&gt;跨域推荐(CDR)旨在通过利用源领域信息来改善目标领域的推荐性能。对比学习方法在处理同一领域内的用户或项目时被广泛采用，并且对于知识迁移和表示学习也很有效。&lt;h4&gt;目的&lt;/h4&gt;解决直接应用对比学习于混合的同域内和跨域任务所带来的训练不稳定问题，这会导致表示学习过程恶化以及生成嵌入质量降低的问题。&lt;h4&gt;方法&lt;/h4&gt;SCCDR基于分离的同域内和跨域内的对比学习模式以及一个停止梯度操作来处理这一不足。该框架包括两个专门的课程阶段：同异域分离和跨域课程调度。前者为源域和目标域分别使用了两种不同的对比视角，后者则通过考虑重叠用户所锚定的负样本难度，采用了课程调度策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明SCCDR在多个基准上达到了最新的性能水平，并且在线A/B测试也验证了这一点。&lt;h4&gt;结论&lt;/h4&gt;提出的框架能够有效地解决跨域推荐任务中的训练不稳定问题，并提高表示学习的质量和生成嵌入的效果，从而提升整体推荐系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了SCCDR框架的创新方法及其在解决跨域推荐（CDR）中对比学习时遇到的问题方面的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3701716.3715260&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-domain recommendation (CDR) is a task that aims to improve therecommendation performance in a target domain by leveraging the informationfrom source domains. Contrastive learning methods have been widely adoptedamong intra-domain (intra-CL) and inter-domain (inter-CL) users/items for theirrepresentation learning and knowledge transfer during the matching stage ofCDR. However, we observe that directly employing contrastive learning onmixed-up intra-CL and inter-CL tasks ignores the difficulty of learning frominter-domain over learning from intra-domain, and thus could cause severetraining instability. Therefore, this instability deteriorates therepresentation learning process and hurts the quality of generated embeddings.To this end, we propose a novel framework named SCCDR built up on a separatedintra-CL and inter-CL paradigm and a stop-gradient operation to handle thedrawback. Specifically, SCCDR comprises two specialized curriculum stages:intra-inter separation and inter-domain curriculum scheduling. The former stageexplicitly uses two distinct contrastive views for the intra-CL task in thesource and target domains, respectively. Meanwhile, the latter stagedeliberately tackles the inter-CL tasks with a curriculum scheduling strategythat derives effective curricula by accounting for the difficulty of negativesamples anchored by overlapping users. Empirical experiments on variousopen-source datasets and an offline proprietary industrial dataset extractedfrom a real-world recommender system, and an online A/B test verify that SCCDRachieves state-of-the-art performance over multiple baselines.</description>
      <author>example@mail.com (Heng Chang, Liang Gu, Cheng Hu, Zhinan Zhang, Hong Zhu, Yuhui Xu, Yuan Fang, Zhen Chen)</author>
      <guid isPermaLink="false">2502.16239v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Set a Thief to Catch a Thief: Combating Label Noise through Noisy Meta Learning</title>
      <link>http://arxiv.org/abs/2502.16104v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一个新颖的噪声元标签校正框架STCT，旨在利用带有噪声的数据来纠正标签错误，并通过实验验证了其在高噪声率场景下的卓越性能。&lt;h4&gt;背景&lt;/h4&gt;从嘈杂的标签中学习（LNL）的目标是使用带噪数据集训练高性能深度模型。基于元学习的方法已经在LNL任务上表现出色，但需要额外的干净验证集来执行标签校正，这限制了其实用性。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一问题，本文提出了一种新颖的噪声元标签校正框架STCT，该框架可以使用带噪数据作为验证集，并在不依赖于额外干净数据的情况下进行标签校正。&lt;h4&gt;方法&lt;/h4&gt;STCT通过将复杂的双层优化分解为表示学习和标签校正两个部分，并采用交替训练策略来解决这个问题。具体来说，在元学习框架中利用与训练数据独立同分布的噪声数据作为验证集评估模型性能并执行标签校正。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，STCT在合成数据集和真实世界数据集上展示了卓越的表现，特别是在高噪声率场景下。当CIFAR-10数据集中含有80%对称噪声时，STCT的标签校正准确率为96.9%，分类性能为95.2%，显著优于现有最佳方法。&lt;h4&gt;结论&lt;/h4&gt;与现有的基于元学习的LNL方法相比，所提出的STCT框架通过利用带噪数据进行自我纠正，在不依赖额外干净验证集的情况下实现了更优的标签校正和模型训练效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning from noisy labels (LNL) aims to train high-performance deep modelsusing noisy datasets. Meta learning based label correction methods havedemonstrated remarkable performance in LNL by designing various meta labelrectification tasks. However, extra clean validation set is a prerequisite forthese methods to perform label correction, requiring extra labor and greatlylimiting their practicality. To tackle this issue, we propose a novel noisymeta label correction framework STCT, which counterintuitively uses noisy datato correct label noise, borrowing the spirit in the saying ``Set a Thief toCatch a Thief''. The core idea of STCT is to leverage noisy data which isi.i.d. with the training data as a validation set to evaluate model performanceand perform label correction in a meta learning framework, eliminating the needfor extra clean data. By decoupling the complex bi-level optimization in metalearning into representation learning and label correction, STCT is solvedthrough an alternating training strategy between noisy meta correction andsemi-supervised representation learning. Extensive experiments on synthetic andreal-world datasets demonstrate the outstanding performance of STCT,particularly in high noise rate scenarios. STCT achieves 96.9% label correctionand 95.2% classification performance on CIFAR-10 with 80% symmetric noise,significantly surpassing the current state-of-the-art.</description>
      <author>example@mail.com (Hanxuan Wang, Na Lu, Xueying Zhao, Yuxuan Yan, Kaipeng Ma, Kwoh Chee Keong, Gustavo Carneiro)</author>
      <guid isPermaLink="false">2502.16104v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling Institution-Specific Bias in Pathology Foundation Models: Detriments, Causes, and Potential Solutions</title>
      <link>http://arxiv.org/abs/2502.16889v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages,1 figure,14 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;病理基础模型在提取有价值的区别性特征方面具有优势，但存在图像特异性信息污染的问题，影响了其泛化能力。&lt;h4&gt;背景&lt;/h4&gt;病理基础模型简化了深度学习模型的开发，并通过利用先验知识提高了诊断准确性。然而，在实际临床应用中，由于机构特定的信息干扰，这些模型的表现可能会下降。&lt;h4&gt;目的&lt;/h4&gt;揭示病理基础模型中的特征污染问题及其对性能的影响，并探讨其背后的原因及可能的解决方案。&lt;h4&gt;方法&lt;/h4&gt;识别并验证了病理图像中的机构特定信息如何被当前的基础模型捕捉到，通过广泛的实验展示了非诊断相关的信息在出界分布场景下对性能的负面影响。&lt;h4&gt;主要发现&lt;/h4&gt;病理基础模型容易提取与疾病无关但又存在于不同医疗机构之间的特征信息。这些污染导致了虚假的相关性，削弱了模型的应用能力。&lt;h4&gt;结论&lt;/h4&gt;提出了减轻机构特定信息影响的方法，并呼吁未来的研究关注创新训练策略而非单纯依赖规模效应来发展更具有泛化的病理基础模型。&lt;h4&gt;翻译&lt;/h4&gt;病理基础模型（PFMs）从图像中提取有价值的区别性特征用于下游临床任务。虽然它们简化了深度学习模型的开发，有效利用先验知识提高了不同场景下的诊断准确性，但发现PFMs有时面临挑战：从图像中提取出的特性经常受到与诊断无关的信息干扰，即特定机构相关的特性，这可能导致虚假的相关性并削弱模型在现实中的应用能力。在这项研究中，我们揭示了特征污染的问题，展示了病理基础模型中存在的机构特有特性，并深入调查其负面影响、分析原因并提出见解。我们发现当前的PFMs可以轻易捕捉到病理图像中的特定信息，通过广泛的实验表明，非诊断相关信息对性能有害，特别是在出界分布设置下，依赖于这些被污染的特征会导致显著的表现下降。这揭示了模型可能受到误导的因素。进一步探讨了PFMs提取机构特定信息的原因，并验证了这一发现。最后提出了一个简单而有效的方法来缓解无关信息的影响。这项研究并非旨在批评现有的病理基础模型，而是要启发未来的科研专注于创新训练策略而非仅依赖规模效应以实现更加泛化的病理基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathology foundation models (PFMs) extract valuable discriminative featuresfrom images for downstream clinical tasks. PFMs have simplified the developmentof deep learning models, effectively leveraging prior knowledge to improvediagnostic accuracy in diverse scenarios. However, we find that PFMs sometimesstruggle with certain challenges. Specifically, features extracted by PFMs areoften contaminated by diagnosis-irrelevant information, i.e.,institution-specific features associated with the images. This contaminationcan lead to spurious correlations, undermining the models' generalizationability when applied in real-world clinical settings. In this work, we firstreveal the issue of feature contamination in PFMs, demonstrate the presence ofinstitution-specific features, thoroughly investigate its negative impacts,analyze the underlying causes, and provide insights into potential solutions.Specifically, we find that institution-specific information is embedded inpathological images and can be readily captured by current PFMs. Throughextensive experiments, we demonstrate the detrimental impact of this irrelevantinformation, particularly in out-of-distribution (OOD) settings, where relianceon contaminated features leads to significant performance degradation. Thisindicates that the models are being misled by non-diagnostic information. Wefurther delve into the reasons PFMs extract such institution-specificinformation and validate our findings. Finally, we propose a simple yeteffective solution to mitigate the influence of irrelevant information. Thisstudy is not intended to criticize existing PFMs, as they have indeed greatlyadvanced the development of computational pathology. our aim is to inspirefuture research to focus on innovative training strategies, rather than relyingexclusively on scaling laws, to realize more generalized PFMs.</description>
      <author>example@mail.com (Weiping Lin, Shen Liu, Runchen Zhu, Liansheng Wang)</author>
      <guid isPermaLink="false">2502.16889v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Subsampling Graphs with GNN Performance Guarantees</title>
      <link>http://arxiv.org/abs/2502.16703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的图数据子采样方法，利用树移动距离减少图的数量和大小，该方法在理论上保证了训练后的模型损失相比完整数据集的增加是有限制的。&lt;h4&gt;背景&lt;/h4&gt;如何从大规模图数据集中有效地选择一个子样本进行GNN训练，使得其性能与整个数据集上的训练效果相当是一个重要的研究问题。较小的数据集可以减少标注成本、存储需求和所需的计算资源。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的基于理论支持的图数据子采样方法，能够在不牺牲模型性能的情况下减小数据集规模。&lt;h4&gt;方法&lt;/h4&gt;利用树移动距离作为度量标准来选择一个有效的子样本。该方法既对模型架构无特定要求也无需完全标注训练集即可实施。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示所提出的方法在多个数据集上优于现有的子采样技术，同时证明了其理论上的性能保证。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法可以在早期的数据预处理阶段进行有效的图数据子采样，从而减少存储、标注和训练所需的资源。该方法具有广泛的适用性，因为它对模型架构和标签信息没有强依赖性。&lt;h4&gt;翻译&lt;/h4&gt;如何从大规模图数据集中有效地选择一个子样本进行GNN训练，使得其性能与整个数据集上的训练效果相当是一个重要的研究问题。较小的数据集可以减少标注成本、存储需求和所需的计算资源。现有技术的不足之处在于它们可能严重降低模型性能或需要大量实验来验证质量，从而消除了子采样的好处。因此，作者提出了一种新的基于理论支持的方法：利用树移动距离进行图数据子采样，并且证明了在子样本上训练GNN会导致损失增加是有限制的。这种方法具有广泛的适用性，因为它对模型架构和标签信息没有强依赖性。实验结果验证了该方法的有效性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How can we subsample graph data so that a graph neural network (GNN) trainedon the subsample achieves performance comparable to training on the fulldataset? This question is of fundamental interest, as smaller datasets reducelabeling costs, storage requirements, and computational resources needed fortraining. Selecting an effective subset is challenging: a poorly chosensubsample can severely degrade model performance, and empirically testingmultiple subsets for quality obviates the benefits of subsampling. Therefore,it is critical that subsampling comes with guarantees on model performance. Inthis work, we introduce new subsampling methods for graph datasets thatleverage the Tree Mover's Distance to reduce both the number of graphs and thesize of individual graphs. To our knowledge, our approach is the first that issupported by rigorous theoretical guarantees: we prove that training a GNN onthe subsampled data results in a bounded increase in loss compared to trainingon the full dataset. Unlike existing methods, our approach is bothmodel-agnostic, requiring minimal assumptions about the GNN architecture, andlabel-agnostic, eliminating the need to label the full training set. Thisenables subsampling early in the model development pipeline (before dataannotation, model selection, and hyperparameter tuning) reducing costs andresources needed for storage, labeling, and training. We validate ourtheoretical results with experiments showing that our approach outperformsexisting subsampling methods across multiple datasets.</description>
      <author>example@mail.com (Mika Sarkin Jain, Stefanie Jegelka, Ishani Karmarkar, Luana Ruiz, Ellen Vitercik)</author>
      <guid isPermaLink="false">2502.16703v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>An Autonomous Network Orchestration Framework Integrating Large Language Models with Continual Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.16198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Communications Magazine&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;6G网络旨在实现全球覆盖、海量连接和超严格的要求。为了实现这些目标，空间-空中-地面综合网络（SAGIN）和语义通信（SemCom）是必不可少的组成部分，但它们在资源调配方面带来了相当大的复杂性。&lt;h4&gt;背景&lt;/h4&gt;当前的研究提出了利用大型语言模型（LLMs）来解决上述问题的一种可行方法。尽管最近在网络调度中使用LLMs已经引起了关注，但现有的解决方案并没有充分解决LLMs幻觉或适应网络动态的问题。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种名为自主强化协调（ARC）的框架，该框架针对具有语义通信功能的空间-空中-地面综合网络设计。&lt;h4&gt;方法&lt;/h4&gt;ARC框架利用基于大型语言模型增强检索生成器(RAG)来监控服务、用户和资源，并处理收集到的数据。同时，分层行动规划器(HAP)负责资源调度工作。ARC通过两个层次来分解资源调配任务：高层使用LLMs进行计划，低层由强化学习(Reinforcement Learning, RL)代理进行决策。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs利用链式思维(CoT)推理进行少样本学习，并通过对比学习增强能力；RL代理则采用重放缓冲区管理来实现持续学习。因此，这种方法可以达到高效、准确和适应性。&lt;h4&gt;结论&lt;/h4&gt;论文通过模拟展示了ARC的有效性，并提供了一个关于如何进一步改进和完善ARC的深入讨论，包括未来的潜在研究方向。&lt;h4&gt;翻译&lt;/h4&gt;6G网络追求全球覆盖、海量连接以及超高标准的要求。空间-空中-地面综合网络(SAGIN)与语义通信技术为实现上述目标是不可或缺的技术手段，然而它们带来了资源协调上的巨大挑战。借鉴机器人领域的研究成果，本文提出了一种运用大型语言模型(如LLMs)作为解决方案的思路来应对这种复杂性，并设计了一个名为自主强化协调(ARC)的新框架以支持SAGIN内的语义通信系统。该框架通过分层架构实现对网络资源的有效管理与优化，在高层采用LLMs进行策略规划，低层使用RL代理作出具体决策；并且针对LLMs易产生的“幻觉”问题及适应网络动态的需求提出了改进方案。实验结果表明该方法具备高效的性能、准确的预测能力和良好的适应性，并探讨了未来可能的研究方向以进一步完善ARC框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 6G networks aim to achieve global coverage, massive connectivity, andultra-stringent requirements. Space-Air-Ground Integrated Networks (SAGINs) andSemantic Communication (SemCom) are essential for realizing these goals, yetthey introduce considerable complexity in resource orchestration. Drawinginspiration from research in robotics, a viable solution to manage thiscomplexity is the application of Large Language Models (LLMs). Although the useof LLMs in network orchestration has recently gained attention, existingsolutions have not sufficiently addressed LLM hallucinations or theiradaptation to network dynamics. To address this gap, this paper proposes aframework called Autonomous Reinforcement Coordination (ARC) for aSemCom-enabled SAGIN. This framework employs an LLM-based Retrieval-AugmentedGenerator (RAG) monitors services, users, and resources and processes thecollected data, while a Hierarchical Action Planner (HAP) orchestratesresources. ARC decomposes orchestration into two tiers, utilizing LLMs forhigh-level planning and Reinforcement Learning (RL) agents for low-leveldecision-making, in alignment with the Mixture of Experts (MoE) concept. TheLLMs utilize Chain-of-Thought (CoT) reasoning for few-shot learning, empoweredby contrastive learning, while the RL agents employ replay buffer managementfor continual learning, thereby achieving efficiency, accuracy, andadaptability. Simulations are provided to demonstrate the effectiveness of ARC,along with a comprehensive discussion on potential future research directionsto enhance and upgrade ARC.</description>
      <author>example@mail.com (Masoud Shokrnezhad, Tarik Taleb)</author>
      <guid isPermaLink="false">2502.16198v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Fair Foundation Models for Medical Image Analysis: Challenges and Perspectives</title>
      <link>http://arxiv.org/abs/2502.16841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;确保医疗保健中的人工智能（AI）公平性需要能够跨越所有人口群体做出无偏见决策的系统，这要求技术革新与伦理原则相结合。&lt;h4&gt;背景&lt;/h4&gt;基础模型(FMs)通过自我监督学习训练于大规模数据集上，可以在各种医学影像任务中高效地进行适应，同时减少对标注数据的依赖。然而，在不同的人口群体间实现一致性能面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;回顾表明，有效的偏见缓解需要在开发过程的所有阶段采取系统性干预措施，不仅包括模型层面的偏见缓解方法，还需要从数据文档到部署协议的一体化介入。&lt;h4&gt;方法&lt;/h4&gt;本文分析强调了公平基础模型(FMs)在整个开发管道中的综合干预的需求，并展示了如何通过结合系统性的偏见缓解和政策参与来有效地解决技术及机构障碍以实现医疗保健中公正的AI。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，为了推动面向服务不足人群和地区（尤其是那些基础设施有限、计算资源匮乏的地方）的先进医疗技术民主化，公平基础模型(FMs)的发展是至关重要的一步。&lt;h4&gt;结论&lt;/h4&gt;本文提出了一种综合框架来推进当前知识，展示了系统性偏见缓解结合政策参与如何有效解决技术及机构障碍，以实现医疗保健中公正的人工智能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring equitable Artificial Intelligence (AI) in healthcare demands systemsthat make unbiased decisions across all demographic groups, bridging technicalinnovation with ethical principles. Foundation Models (FMs), trained on vastdatasets through self-supervised learning, enable efficient adaptation acrossmedical imaging tasks while reducing dependency on labeled data. These modelsdemonstrate potential for enhancing fairness, though significant challengesremain in achieving consistent performance across demographic groups. Ourreview indicates that effective bias mitigation in FMs requires systematicinterventions throughout all stages of development. While previous approachesfocused primarily on model-level bias mitigation, our analysis reveals thatfairness in FMs requires integrated interventions throughout the developmentpipeline, from data documentation to deployment protocols. This comprehensiveframework advances current knowledge by demonstrating how systematic biasmitigation, combined with policy engagement, can effectively address bothtechnical and institutional barriers to equitable AI in healthcare. Thedevelopment of equitable FMs represents a critical step toward democratizingadvanced healthcare technologies, particularly for underserved populations andregions with limited medical infrastructure and computational resources.</description>
      <author>example@mail.com (Dilermando Queiroz, Anderson Carlos, André Anjos, Lilian Berton)</author>
      <guid isPermaLink="false">2502.16841v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>DUNIA: Pixel-Sized Embeddings via Cross-Modal Alignment for Earth Observation Applications</title>
      <link>http://arxiv.org/abs/2502.17066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种名为DUNIA的方法，该方法通过图像与全波形LiDAR数据之间的跨模态对齐来学习像素级别的嵌入。这种方法能够直接应用于各种环境监测任务，并在零样本设置下展示了其有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的自我监督多模式学习方法为地球观测应用生成的是粗糙的补丁大小的嵌入，这限制了它们的有效性和与其他模式（如LiDAR）的集成能力。&lt;h4&gt;目的&lt;/h4&gt;为了弥补现有方法的不足，提出了一种新的跨模态对齐方法来学习像素级别的嵌入。&lt;h4&gt;方法&lt;/h4&gt;通过对比训练方式，该模型学会了在零样本设置下应用于各种环境监测任务的像素级别嵌入。具体来说，该研究使用图像和全波形LiDAR数据之间的跨模态对齐进行像素级嵌入的学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在七项环境监测任务中（包括冠层高度测绘、分层冠层覆盖率等），这些嵌入及其零样本分类器通常优于专门的监督模型，即使在低数据量环境下也是如此。此外，在微调设置下，DUNIA展示了强大的低样本能力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种新的方法来解决地球观测任务中像素级别嵌入的学习问题，并展示了其优越的表现和潜力。&lt;h4&gt;翻译&lt;/h4&gt;大量的努力已经被投入到自监督多模态学习为地球观察应用进行适应。然而，现有的方法产生的是粗糙的补丁大小的嵌入，这限制了它们的有效性和与其他模式（如LiDAR）的集成能力。为了弥补这一差距，我们提出了DUNIA——一种通过图像和全波形LiDAR数据之间的跨模态对齐来学习像素级别的嵌入的方法。由于模型以对比方式训练，因此这些嵌入可以直接在各种环境监测任务中零样本设置下应用。在我们的实验中，我们展示了这些嵌入对于七项此类任务的有效性（包括冠层高度测绘、分层冠层覆盖率等）。结果表明，这些嵌入与零样本分类器经常优于专门的监督模型，在低数据量环境下也是如此。在微调设置下，我们在五项任务中的表现接近或超过最新技术水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Significant efforts have been directed towards adapting self-supervisedmultimodal learning for Earth observation applications. However, existingmethods produce coarse patch-sized embeddings, limiting their effectiveness andintegration with other modalities like LiDAR. To close this gap, we presentDUNIA, an approach to learn pixel-sized embeddings through cross-modalalignment between images and full-waveform LiDAR data. As the model is trainedin a contrastive manner, the embeddings can be directly leveraged in thecontext of a variety of environmental monitoring tasks in a zero-shot setting.In our experiments, we demonstrate the effectiveness of the embeddings forseven such tasks (canopy height mapping, fractional canopy cover, land covermapping, tree species identification, plant area index, crop typeclassification, and per-pixel waveform-based vertical structure mapping). Theresults show that the embeddings, along with zero-shot classifiers, oftenoutperform specialized supervised models, even in low data regimes. In thefine-tuning setting, we show strong low-shot capabilities with performancesnear or better than state-of-the-art on five out of six tasks.</description>
      <author>example@mail.com (Ibrahim Fayad, Max Zimmer, Martin Schwartz, Philippe Ciais, Fabian Gieseke, Gabriel Belouze, Sarah Brood, Aurelien De Truchis, Alexandre d'Aspremont)</author>
      <guid isPermaLink="false">2502.17066v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MambaFlow: A Novel and Flow-guided State Space Model for Scene Flow Estimation</title>
      <link>http://arxiv.org/abs/2502.16907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一种名为MambaFlow的新型场景流估算网络，该网络利用基于Mamba的状态空间模型（SSM）的解码器来解决现有的点云帧间3D运动预测方法在时空建模和特征丢失方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;场景流估计是自动驾驶领域的一个重要研究方向，旨在从连续的点云帧中预测3D运动。现有方法面临时空建模不足以及体素化过程中细粒度特征损失的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于Mamba的状态空间模型（SSM）解码器的方法，以解决现有场景流估计方法中的问题，并提升模型在不同场景下的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了名为MambaFlow的新型场景流估算网络。该网络利用一个设计良好的主干网，通过高效的基于Mamba的解码器来指导体素特征的全局注意力建模，学习体素到点的模式，并将共享体素表示去体素化为点级别的特性。&lt;h4&gt;主要发现&lt;/h4&gt;提出了用于增强模型泛化的场景自适应损失函数。在Argoverse 2基准上的大量实验表明，MambaFlow实现了现有的实时推理速度和最先进的性能，能够准确估计现实世界的城市场景中的流。&lt;h4&gt;结论&lt;/h4&gt;MambaFlow展示了其解决现有方法问题的能力，并且证明了使用基于Mamba的解码器进行全局注意力建模的有效性。此外，提出的自适应损失函数进一步增强了模型在不同场景下的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;场景流估计旨在从连续的点云帧中预测3D运动，在自动驾驶领域备受关注。现有方法面临时空建模不足和体素化过程中细粒度特征丢失的问题。然而，Mamba的成功展示了全局建模和线性复杂性的可能性。本文提出了一种基于Mamba的状态空间模型（SSM）解码器的新型场景流估计网络——MambaFlow，它可以利用设计良好的主干网实现时空特征的深度交互耦合，并且提出了一个全新的场景自适应损失函数来提升泛化能力。在Argoverse 2基准上的大量实验表明，MambaFlow实现了现有方法中的实时推理速度和最先进的性能，在现实世界的城市环境中能够准确估计流。代码可以从 https://github.com/SCNU-RISLAB/MambaFlow 获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scene flow estimation aims to predict 3D motion from consecutive point cloudframes, which is of great interest in autonomous driving field. Existingmethods face challenges such as insufficient spatio-temporal modeling andinherent loss of fine-grained feature during voxelization. However, the successof Mamba, a representative state space model (SSM) that enables global modelingwith linear complexity, provides a promising solution. In this paper, wepropose MambaFlow, a novel scene flow estimation network with a mamba-baseddecoder. It enables deep interaction and coupling of spatio-temporal featuresusing a well-designed backbone. Innovatively, we steer the global attentionmodeling of voxel-based features with point offset information using anefficient Mamba-based decoder, learning voxel-to-point patterns that are usedto devoxelize shared voxel representations into point-wise features. To furtherenhance the model's generalization capabilities across diverse scenarios, wepropose a novel scene-adaptive loss function that automatically adapts todifferent motion patterns.Extensive experiments on the Argoverse 2 benchmarkdemonstrate that MambaFlow achieves state-of-the-art performance with real-timeinference speed among existing works, enabling accurate flow estimation inreal-world urban scenarios. The code is available athttps://github.com/SCNU-RISLAB/MambaFlow.</description>
      <author>example@mail.com (Jiehao Luo, Jintao Cheng, Xiaoyu Tang, Qingwen Zhang, Bohuan Xue, Rui Fan)</author>
      <guid isPermaLink="false">2502.16907v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>UniDyG: A Unified and Effective Representation Learning Approach for Large Dynamic Graphs</title>
      <link>http://arxiv.org/abs/2502.16431v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'背景': '动态图在连续时间（CTDGs）和离散时间（DTDGs）下被定义，分别展现出快速局部变化和逐渐全局更新的特点。现有的表示学习研究主要针对其中一种类型的动态图进行，并且通常只关注时间域内的局部动态传播，难以准确捕捉与每种时间粒度相关的结构演变。', '目的': '为了更好地建模这两种类型的动态图，并提升模型的鲁棒性和有效性，提出了一种统一有效的表示学习方法UniDyG。', '方法': '该研究首先提出了一个新颖的傅立叶图注意力（FGAT）机制，可以基于最近邻居和复数选择性聚合来同时建模局部和全局结构相关性，并在理论上确保动态图的时间一致性。通过设计能量门控单元增强FGAT对抗时间噪声的能力，并利用频率增强线性函数进行节点级的动态更新。', '主要发现': '实验表明，所提出的UniDyG方法相较于16个基准模型，在9种动态图上平均改进了14.4%。', '结论': '这项工作提出了一种新的表示学习框架，能够有效应对CTDGs和DTDGs中的挑战，并通过实证研究证明其优越性。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic graphs are formulated in continuous-time or discrete-time dynamicgraphs. They differ in temporal granularity: Continuous-Time Dynamic Graphs(CTDGs) exhibit rapid, localized changes, while Discrete-Time Dynamic Graphs(DTDGs) show gradual, global updates. This difference leads to isolateddevelopments in representation learning for each type. To advancerepresentation learning, recent research attempts to design a unified modelcapable of handling both CTDGs and DTDGs. However, it typically focuses onlocal dynamic propagation for temporal structure learning in the time domain,failing to accurately capture the structural evolution associated with eachtemporal granularity. In addition, existing works-whether specific orunified-often overlook the issue of temporal noise, compromising the modelrobustness and effectiveness. To better model both types of dynamic graphs, wepropose UniDyG, a unified and effective representation learning approach, whichscales to large dynamic graphs. We first propose a novel Fourier GraphAttention (FGAT) mechanism that can model local and global structuralcorrelations based on recent neighbors and complex-number selectiveaggregation, while theoretically ensuring consistent representations of dynamicgraphs over time. Based on approximation theory, we demonstrate that FGAT iswell-suited to capture the underlying structures in CTDGs and DTDGs. We furtherenhance FGAT to resist temporal noise by designing an energy-gated unit, whichadaptively filters out high-frequency noise according to the energy. Last, weleverage our FGAT mechanisms for temporal structure learning and employ thefrequency-enhanced linear function for node-level dynamic updates, facilitatingthe generation of high-quality temporal embeddings. Extensive experiments showthat our UniDyG achieves an average improvement of 14.4% over sixteen baselinesacross nine dynamic graphs.</description>
      <author>example@mail.com (Yuanyuan Xu, Wenjie Zhang, Xuemin Lin, Ying Zhang)</author>
      <guid isPermaLink="false">2502.16431v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SwimVG: Step-wise Multimodal Fusion and Adaption for Visual Grounding</title>
      <link>http://arxiv.org/abs/2502.16786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 7 figures.Our code is available at  https://github.com/liuting20/SwimVG&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;Visual grounding通过自然语言来定位图像区域，这项任务很大程度上依赖于跨模态对齐。现有大多数方法分别传输视觉和语言知识，并在预训练的单模模型完全微调后简单堆叠视觉-语言变换器进行多模态融合。&lt;h4&gt;背景问题&lt;/h4&gt;当前的方法限制了视觉与语言上下文之间的充分交互，同时带来了显著的计算成本。&lt;h4&gt;研究目的&lt;/h4&gt;提出一种分步式多模态融合和适应框架SwimVG来解决上述问题，并在效率上获得明显优势。&lt;h4&gt;方法介绍&lt;/h4&gt;提出了分步式多模态提示(Swip)和跨模态互动适配器(CIA)，分别用于逐步提升视觉与语言表示的对齐度以及进一步促进多模态融合。这些新的架构以参数高效的方式替换原有的繁琐变换器堆栈，从浅层到深层渐进地融合跨模式特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SwimVG在四个广泛使用的基准数据集上实现了卓越的能力和效率上的显著优势。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种新颖的视觉接地方法，通过分步多模态融合和适应框架提高了任务性能并优化了计算资源利用。代码已公开供社区进一步探索和应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉定位旨在通过自然语言来确定图像区域，这很大程度上依赖于跨模态对齐。现有的大多数方法分别传输视觉或语言知识，并在预训练的单模式模型完全微调后简单堆叠视觉-语言变换器进行多模态融合。然而，这些方法不仅限制了视觉和语言上下文之间的充分交互，还带来了显著的计算成本。因此，为了应对这些问题，我们探索了一种分步式的多模态融合和适应框架，即SwimVG。具体来说，SwimVG提出了步骤式多模态提示（Swip）和跨模式互动适配器（CIA），用于视觉定位，在此过程中用简单的变换器堆栈替换原有的跨模式融合方式。Swip可以通过令牌级别的融合逐步提升视觉与语言表示的对齐度。此外，重量级的CIA通过跨模态交互进一步促进多模态融合。Swip和CIA都是参数效率高，并且它们逐渐从浅层到深层地融合了跨模式特征。在四个广泛使用的基准测试中进行的实验结果表明，在效率方面，SwimVG获得了显著的能力和收益。我们的代码可以在https://github.com/liuting20/SwimVG上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual grounding aims to ground an image region through natural language,which heavily relies on cross-modal alignment. Most existing methods transfervisual/linguistic knowledge separately by fully fine-tuning uni-modalpre-trained models, followed by a simple stack of visual-language transformersfor multimodal fusion. However, these approaches not only limit adequateinteraction between visual and linguistic contexts, but also incur significantcomputational costs. Therefore, to address these issues, we explore a step-wisemultimodal fusion and adaption framework, namely SwimVG. Specifically, SwimVGproposes step-wise multimodal prompts (Swip) and cross-modal interactiveadapters (CIA) for visual grounding, replacing the cumbersome transformerstacks for multimodal fusion. Swip can improve {the} alignment between thevision and language representations step by step, in a token-level fusionmanner. In addition, weight-level CIA further promotes multimodal fusion bycross-modal interaction. Swip and CIA are both parameter-efficient paradigms,and they fuse the cross-modal features from shallow to deep layers gradually.Experimental results on four widely-used benchmarks demonstrate that SwimVGachieves remarkable abilities and considerable benefits in terms of efficiency.Our code is available at https://github.com/liuting20/SwimVG.</description>
      <author>example@mail.com (Liangtao Shi, Ting Liu, Xiantao Hu, Yue Hu, Quanjun Yin, Richang Hong)</author>
      <guid isPermaLink="false">2502.16786v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging recurrence in neural network wavefunctions for large-scale simulations of Heisenberg antiferromagnets: the square lattice</title>
      <link>http://arxiv.org/abs/2502.17144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 13 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种使用递归神经网络（RNN）进行变分蒙特卡洛模拟的方法，用于研究二维量子多体系统的基态性质。通过转移学习技术，能够有效地在大规模系统中应用这种方法而不需要从头开始优化。&lt;h4&gt;背景&lt;/h4&gt;机器学习支持的变分蒙特卡罗方法被用来寻找量子多体系统的基态，特别是在二维情况下和非平凡符号结构的情况下。尽管已经达到了许多最先进的有限大小系统的变分能量，但在热力学极限中的研究较少。&lt;h4&gt;目的&lt;/h4&gt;使用RNN作为变分近似来模拟自旋$rac{1}{2}$系统的基态，并通过迭代重新训练的方法逐步增加系统规模以减少计算资源需求。&lt;h4&gt;方法&lt;/h4&gt;在本工作中，作者专注于二维反铁磁海森堡模型（SLAHM），并利用递归神经网络的特性进行大规模系统的基态模拟。通过延长训练时间来提高结果精度，并将有限大小格点上的数值与文献值对比验证。&lt;h4&gt;主要发现&lt;/h4&gt;实现了系统性地提高模拟结果准确性，同时获得了热力学极限下的精确估计。&lt;h4&gt;结论&lt;/h4&gt;该工作证明了RNN波函数可以用来准确研究量子多体物理在热力学极限中的性质。&lt;h4&gt;翻译&lt;/h4&gt;基于机器学习的变分蒙特卡洛仿真是瞄准量子多体基态的一种有前途的方法，特别是在二维和已知基态具有非平凡符号结构的情况下。尽管这些方法已经达到了许多最先进的有限尺寸系统的变分能量，但很少有人利用这些结果来提取目标状态在热力学极限中的信息。本文中，我们采用递归神经网络（RNN）作为变分近似，并利用其递归性质通过迭代重新训练逐步模拟更大规模的系统，从而减少计算资源的需求。在这项研究中，我们专注于二维反铁磁海森堡模型，在这里可以仔细地验证我们的结果。我们展示了可以通过增加训练时间来有条不紊地提高模拟结果的精度，并且对于有限大小格点上的数值与文献值之间具有很好的一致性。此外，我们利用这些结果提取了热力学极限下基态性质的精确估计。这项工作证明了RNN波函数可以用来准确研究量子多体物理在热力学极限中的特性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learning-based variational Monte Carlo simulations are a promisingapproach for targeting quantum many body ground states, especially in twodimensions and in cases where the ground state is known to have a non-trivialsign structure. While many state-of-the-art variational energies have beenreached with these methods for finite-size systems, little work has been doneto use these results to extract information about the target state in thethermodynamic limit. In this work, we employ recurrent neural networks (RNNs)as a variational ans\"{a}tze, and leverage their recurrent nature to simulatethe ground states of progressively larger systems through iterative retraining.This transfer learning technique allows us to simulate spin-$\frac{1}{2}$systems on lattices with more than 1,000 spins without beginning optimizationfrom scratch for each system size, thus reducing the demands for computationalresources. In this study, we focus on the square-lattice antiferromagneticHeisenberg model (SLAHM), where it is possible to carefully benchmark ourresults. We show that we are able to systematically improve the accuracy of theresults from our simulations by increasing the training time, and obtainresults for finite-sized lattices that are in good agreement with theliterature values. Furthermore, we use these results to extract accurateestimates of the ground-state properties in the thermodynamic limit. This workdemonstrates that RNN wavefunctions can be used to accurately study quantummany-body physics in the thermodynamic limit.</description>
      <author>example@mail.com (M. Schuyler Moss, Roeland Wiersema, Mohamed Hibat-Allah, Juan Carrasquilla, Roger G. Melko)</author>
      <guid isPermaLink="false">2502.17144v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Noise2Score3D:Unsupervised Tweedie's Approach for Point Cloud Denoising</title>
      <link>http://arxiv.org/abs/2502.16826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Noise2Score3D是一个完全无监督的点云去噪框架，它利用贝叶斯统计和图像去噪领域的最新进展来解决干净数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的去噪方法通常需要大量的干净数据进行训练，这在实际应用中是难以获得的。而本研究提出的Noise2Score3D方法直接从带噪声的数据中学习点云分布的梯度。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的方法来处理点云去噪问题，特别是在没有或很少有干净数据的情况下。&lt;h4&gt;方法&lt;/h4&gt;该方法利用Tweedie公式进行一步式推理，避免了现有无监督方法中的迭代过程，并且通过Total Variation for Point Cloud标准估计未知噪声参数，增强了方法的实用性和通用性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，Noise2Score3D在Chamfer距离和点到网格度量方面优于其他无监督方法，在一些性能指标上甚至可以与有监督的方法相媲美，并且具有很强的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种新的去噪框架Noise2Score3D，不仅提升了算法效率和性能，还提高了其在实际应用中的适应性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;本文基于贝叶斯统计学和图像去噪领域的最新进展，提出了一个完全无监督的点云去噪框架Noise2Score3D。该方法直接从带噪声的数据中学习潜在分布的梯度，并通过Tweedie公式执行一步式推理。实验结果表明，在标准基准测试上，这种方法在Chamfer距离和点到网格度量方面优于其他无监督方法，甚至可以与一些有监督的方法相媲美。此外，Noise2Score3D还引入了Total Variation for Point Cloud的标准来估计未知的噪声参数，进一步增强了该方法的灵活性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building on recent advances in Bayesian statistics and image denoising, wepropose Noise2Score3D, a fully unsupervised framework for point cloud denoisingthat addresses the critical challenge of limited availability of clean data.Noise2Score3D learns the gradient of the underlying point cloud distributiondirectly from noisy data, eliminating the need for clean data during training.By leveraging Tweedie's formula, our method performs inference in a singlestep, avoiding the iterative processes used in existing unsupervised methods,thereby improving both performance and efficiency. Experimental resultsdemonstrate that Noise2Score3D achieves state-of-the-art performance onstandard benchmarks, outperforming other unsupervised methods in Chamferdistance and point-to-mesh metrics, and rivaling some supervised approaches.Furthermore, Noise2Score3D demonstrates strong generalization ability beyondtraining datasets. Additionally, we introduce Total Variation for Point Cloud,a criterion that allows for the estimation of unknown noise parameters, whichfurther enhances the method's versatility and real-world utility.</description>
      <author>example@mail.com (Xiangbin Wei)</author>
      <guid isPermaLink="false">2502.16826v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Retinal Disease Prediction Using Biology-Informed Heterogeneous Graph Representations</title>
      <link>http://arxiv.org/abs/2502.16697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新颖的方法，利用基于生物学信息的异构图表示来提高糖尿病视网膜病变分期预测的可解释性，并在两个数据集上超过了现有的机器学习模型。&lt;h4&gt;背景&lt;/h4&gt;目前最先进的基于神经网络的图像分类器大多不可解释。虽然生物标志物是临床诊断的重要依据，但生物标志物基础分类性能通常不如大型神经网络。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法以超越现有机器学习模型的表现并提高糖尿病视网膜病变分期预测的可解释性。&lt;h4&gt;方法&lt;/h4&gt;利用新颖的生物学信息异构图表示来建模视网膜血管段、间隔区以及中央凹无血管区，将糖尿病视网膜病变分期问题转化为图形分类任务，并使用高效的图神经网络解决该问题。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法在两个数据集上优于传统的生物标志物基础分类器、卷积神经网络（CNN）和视觉变换器等基准方法。此外，还提供了前所未有的详细解释来定位关键血管或间隔区并赋予关键特性有意义的人类可解读归因。&lt;h4&gt;结论&lt;/h4&gt;该研究贡献了有助于眼科临床决策支持工具发展的新方法。&lt;h4&gt;翻译&lt;/h4&gt;可解释性对于增强医学诊断中机器学习模型的信任至关重要。然而，大多数基于神经网络的先进图像分类器不可解释。因此，尽管生物标志物基础分类通常表现不如大型神经网络，但临床上仍依赖于已知的生物标志物进行诊断。这项工作提出了一种方法，该方法超越了现有的机器学习模型的表现，并同时提高了糖尿病视网膜病变分期从光学相干断层扫描血管成像（OCTA）图像中预测的可解释性。我们的方法基于一种新颖的生物学信息异构图表示，以人类可理解的方式建模视网膜血管段、间隔区以及中央凹无血管区（FAZ）。这种图形表示使我们能够将糖尿病视网膜病变分期视为一个图形级别的分类任务，并使用高效的图神经网络解决该问题。我们在两个数据集上对我们的方法进行了基准测试，与包括经典生物标志物基础分类器、卷积神经网络（CNN）和视觉变换器在内的现有基线模型相比表现更佳。我们使用生物学信息图提供了前所未有的详细解释，并且在精确定位关键血管或间隔区以及赋予有意义的人类可解读归因方面超越了现有的方法。我们的工作对眼科临床决策支持工具的发展做出了贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretability is crucial to enhance trust in machine learning models formedical diagnostics. However, most state-of-the-art image classifiers based onneural networks are not interpretable. As a result, clinicians often resort toknown biomarkers for diagnosis, although biomarker-based classificationtypically performs worse than large neural networks. This work proposes amethod that surpasses the performance of established machine learning modelswhile simultaneously improving prediction interpretability for diabeticretinopathy staging from optical coherence tomography angiography (OCTA)images. Our method is based on a novel biology-informed heterogeneous graphrepresentation that models retinal vessel segments, intercapillary areas, andthe foveal avascular zone (FAZ) in a human-interpretable way. This graphrepresentation allows us to frame diabetic retinopathy staging as a graph-levelclassification task, which we solve using an efficient graph neural network. Webenchmark our method against well-established baselines, including classicalbiomarker-based classifiers, convolutional neural networks (CNNs), and visiontransformers. Our model outperforms all baselines on two datasets. Crucially,we use our biology-informed graph to provide explanations of unprecedenteddetail. Our approach surpasses existing methods in precisely localizing andidentifying critical vessels or intercapillary areas. In addition, we giveinformative and human-interpretable attributions to critical characteristics.Our work contributes to the development of clinical decision-support tools inophthalmology.</description>
      <author>example@mail.com (Laurin Lux, Alexander H. Berger, Maria Romeo Tricas, Alaa E. Fayed, Sobha Sivaprasada, Linus Kreitner, Jonas Weidner, Martin J. Menten, Daniel Rueckert, Johannes C. Paetzold)</author>
      <guid isPermaLink="false">2502.16697v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Understanding the Emergence of Multimodal Representation Alignment</title>
      <link>http://arxiv.org/abs/2502.16282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 22 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态学习中不同模态之间表示对齐的形成机制及其与任务性能的关系，通过实验表明其依赖于数据特性。&lt;h4&gt;背景&lt;/h4&gt;多模态表征学习旨在将不同的不可比较模态转换为可比较的表示。以往的研究主要集中在显式对齐上，但最近发现独立训练的大规模单模态模型可以隐式对齐。&lt;h4&gt;目的&lt;/h4&gt;探讨在多模态学习中，不同模态之间如何以及为何会形成隐式的表示对齐；同时探究这种对齐是否可靠地指示任务性能。&lt;h4&gt;方法&lt;/h4&gt;通过全面的实证研究来分析不同数据特性（如模态相似度和信息冗余度）对表示对齐及其与任务表现关系的影响。&lt;h4&gt;主要发现&lt;/h4&gt;表示对齐的出现及其实现任务性能的相关性依赖于关键的数据特征，包括但不限于模态之间的相似性和冗余/独特信息的比例。这些发现表明，对齐不一定总是有益的；其影响取决于特定数据集和任务的情况。&lt;h4&gt;结论&lt;/h4&gt;研究结果有助于实践者根据具体情况确定增加不同模态之间表示对齐是否有利于获得最优性能。&lt;h4&gt;翻译&lt;/h4&gt;多模式表征学习是将不同的不可比较模态转换为可比较表示的过程。之前的研究主要集中在通过明确的学习目标和模型架构来显式地对准这些表示，但最近的一系列工作发现独立训练的规模更大、性能更好的单模态模型可以彼此隐式对齐。这一研究结果引发了关于多模式学习中对齐表示出现的基本问题：（1）何时以及为什么会出现隐式的对齐？（2）对齐是否可靠地指示了任务性能？通过全面的经验调查，我们证明了对齐的产生及其与任务表现的关系依赖于多个关键数据特征。这包括但不限于模态之间的相似性和它们提供的冗余和独特信息的比例等。我们的研究结果表明对齐不一定总是有益的；相反，它对性能的影响根据数据集和任务的不同而变化。这些见解可以帮助实践者确定增加不同模式之间表示对准是否有利或在某些情况下有害于获得最佳性能。代码发布在 https://github.com/MeganTj/multimodal_alignment 上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation learning is fundamentally about transformingincomparable modalities into comparable representations. While prior researchprimarily focused on explicitly aligning these representations through targetedlearning objectives and model architectures, a recent line of work has foundthat independently trained unimodal models of increasing scale and performancecan become implicitly aligned with each other. These findings raise fundamentalquestions regarding the emergence of aligned representations in multimodallearning. Specifically: (1) when and why does alignment emerge implicitly? and(2) is alignment a reliable indicator of performance? Through a comprehensiveempirical investigation, we demonstrate that both the emergence of alignmentand its relationship with task performance depend on several critical datacharacteristics. These include, but are not necessarily limited to, the degreeof similarity between the modalities and the balance between redundant andunique information they provide for the task. Our findings suggest thatalignment may not be universally beneficial; rather, its impact on performancevaries depending on the dataset and task. These insights can help practitionersdetermine whether increasing alignment between modalities is advantageous or,in some cases, detrimental to achieving optimal performance. Code is releasedat https://github.com/MeganTj/multimodal_alignment.</description>
      <author>example@mail.com (Megan Tjandrasuwita, Chanakya Ekbote, Liu Ziyin, Paul Pu Liang)</author>
      <guid isPermaLink="false">2502.16282v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Category-Selective Neurons in Deep Networks: Comparing Purely Visual and Visual-Language Models</title>
      <link>http://arxiv.org/abs/2502.16456v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文研究了人工神经网络（ANNs）中是否存在与人类大脑相似的类别选择性区域，并探讨这些区域在视觉和视觉-语言模型中的差异。&lt;h4&gt;背景&lt;/h4&gt;人类大脑中有专门处理特定类型视觉信息的区域，如面部、身体、场景等。作者探索了人工神经网络中是否存在类似的特性。&lt;h4&gt;目的&lt;/h4&gt;研究不同深度学习模型中的类别选择性神经元及其分布规律，并探讨多模态学习对这些神经元的影响。&lt;h4&gt;方法&lt;/h4&gt;通过向深层网络展示不同类别的图像（如人脸、身体、场景等）并使用统计标准识别类别选择性神经元，模拟功能性定位实验的方法进行研究。&lt;h4&gt;主要发现&lt;/h4&gt;ResNet和基于CLIP的模型都包含类别选择性神经元，但CLIP模型中这些神经元的比例更高且分布更均匀。这表明多模态学习增加了这类神经元的数量却减少了它们的选择特异性。&lt;h4&gt;结论&lt;/h4&gt;这项研究表明人工神经网络模仿了生物视觉系统，并揭示了多模态学习如何影响深度网络中的类别选择性表示。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文译文为：人类大脑中负责高级视觉处理的区域，如梭状回面孔区（FFA）、额外体素体区（EBA）、海马旁场景区（PPA）和视觉词形区（VWFA），在人脸识别、身体识别、场景理解和文字阅读等方面起着关键作用。本文探讨了人工神经网络（ANNs）中是否存在类似的类别选择性区域，以及这些区域在网络的各个层面上的变化情况，并且比较了纯视觉模型与视觉-语言模型之间的差异。通过模拟功能定位实验的方法，在深层网络上展示了来自不同类别的图像（包括面部、身体、场景、文字及其随机组合），并使用统计标准来识别类别选择性神经元。研究发现，无论是ResNet还是基于CLIP的结构控制模型，都包含了类别选择性神经元，并且随着层数的增加，这些神经元的比例也在增加，这与高级视觉大脑区域中的选择性一致。然而，相较于ResNet，CLIP显示了更高的比例但更低的选择特异性，在特征图上的分布更均匀，并在不同层之间展现出更强的表现一致性。研究结果表明语言学习增加了类别选择性神经元的数量而减少了它们的特定强度，重新塑造了深度网络中的视觉表示形式。这项研究提供了关于ANNs如何模仿生物视觉系统以及多模态学习影响类别选择性表征的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Category-selective regions in the human brain, such as the fusiform face area(FFA), extrastriate body area (EBA), parahippocampal place area (PPA), andvisual word form area (VWFA), play a crucial role in high-level visualprocessing. Here, we investigate whether artificial neural networks (ANNs)exhibit similar category-selective neurons and how these neurons vary acrossmodel layers and between purely visual and vision-language models. Inspired byfMRI functional localizer experiments, we presented images from differentcategories (faces, bodies, scenes, words, scrambled scenes, and scrambledwords) to deep networks and identified category-selective neurons usingstatistical criteria. Comparing ResNet and the structurally controlledResNet-based CLIP model, we found that both models contain category-selectiveneurons, with their proportion increasing across layers, mirroring categoryselectivity in higher-level visual brain regions. However, CLIP exhibited ahigher proportion but lower specificity of category-selective neurons comparedto ResNet. Additionally, CLIP's category-selective neurons were more evenlydistributed across feature maps and demonstrated greater representationalconsistency across layers. These findings suggest that language learningincreases the number of category-selective neurons while reducing theirselectivity strength, reshaping visual representations in deep networks. Ourstudy provides insights into how ANNs mirror biological vision and howmultimodal learning influences category-selective representations.</description>
      <author>example@mail.com (Zitong Lu, Yuxin Wang)</author>
      <guid isPermaLink="false">2502.16456v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Similarity Learning for Market Forecasting: The ContraSim Framework</title>
      <link>http://arxiv.org/abs/2502.16023v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 3 appendices&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;我们介绍了一种新的框架Contrastive Similarity Space Embedding Algorithm (ContraSim)，用于揭示日常金融新闻头条与市场动态之间的全球语义关系。&lt;h4&gt;背景&lt;/h4&gt;金融市场中的新闻报道和股票价格之间存在复杂的相互作用，现有的方法难以有效捕捉这些关系。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够更有效地揭示金融新闻与市场动态之间关联性的算法框架。&lt;h4&gt;方法&lt;/h4&gt;{'Weighted Headline Augmentation': '生成带有语义细粒度相似性评分的增强型金融新闻头条', 'Weighted Self-Supervised Contrastive Learning (WSSCL)': '利用相似性度量创建细化加权嵌入空间，使语义相似的新闻头条聚类在一起'}&lt;h4&gt;主要发现&lt;/h4&gt;{'提高分类精度': '将ContraSim特性融入金融预测任务后，从《华尔街日报》新闻中提高了7%的分类准确率。', '市场动态捕捉': '通过信息密度分析，发现了由ContraSim构造出的相似空间内在地聚类了具有相同市场移动方向的日子，表明该算法能够独立于地面真实标签捕获市场的动态变化。', '参考过去事件': '识别历史新闻日，这些日子与当前日期头条内容非常接近，为预测市场趋势提供可操作见解'}&lt;h4&gt;结论&lt;/h4&gt;ContraSim不仅提高了金融预测任务中的分类精度，还为金融市场分析师提供了基于类似过去的事件进行市场趋势预测的实用工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce the Contrastive Similarity Space Embedding Algorithm(ContraSim), a novel framework for uncovering the global semantic relationshipsbetween daily financial headlines and market movements. ContraSim operates intwo key stages: (I) Weighted Headline Augmentation, which generates augmentedfinancial headlines along with a semantic fine-grained similarity score, and(II) Weighted Self-Supervised Contrastive Learning (WSSCL), an extended versionof classical self-supervised contrastive learning that uses the similaritymetric to create a refined weighted embedding space. This embedding spaceclusters semantically similar headlines together, facilitating deeper marketinsights. Empirical results demonstrate that integrating ContraSim featuresinto financial forecasting tasks improves classification accuracy from WSJheadlines by 7%. Moreover, leveraging an information density analysis, we findthat the similarity spaces constructed by ContraSim intrinsically cluster dayswith homogeneous market movement directions, indicating that ContraSim capturesmarket dynamics independent of ground truth labels. Additionally, ContraSimenables the identification of historical news days that closely resemble theheadlines of the current day, providing analysts with actionable insights topredict market trends by referencing analogous past events.</description>
      <author>example@mail.com (Nicholas Vinden, Raeid Saqur, Zining Zhu, Frank Rudzicz)</author>
      <guid isPermaLink="false">2502.16023v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Provable Benefits of Unsupervised Pre-training and Transfer Learning via Single-Index Models</title>
      <link>http://arxiv.org/abs/2502.16849v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了无监督预训练和迁移学习如何影响高维有监督学习的样本复杂度，特别是在标签数据有限的情况下。研究结果显示，在特定条件下，这些技术能显著减少所需的训练样本数量。&lt;h4&gt;背景&lt;/h4&gt;在深度学习领域中，无监督预训练和迁移学习通常被用来初始化神经网络模型以应对标签数据稀缺的问题。&lt;h4&gt;目的&lt;/h4&gt;目的是分析无监督预训练和转移学习如何影响单层神经网络通过在线随机梯度下降进行训练时的样本复杂性。&lt;h4&gt;方法&lt;/h4&gt;研究考虑了使用在线随机梯度下降法来训练单层神经网络的情况，并探讨了无监督预训练与迁移学习在这种情况下的效果。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，在较为宽松的一般假设条件下，无监督预训练和转移学习能够通过多项式因素减少样本复杂性。此外，研究还发现了某些情况下无监督预训练可以提供指数级的改善，相对于随机初始化而言。&lt;h4&gt;结论&lt;/h4&gt;该论文提供了无监督预训练和迁移学习对深度神经网络模型在高维数据上的影响的重要见解，并强调了其在样本效率方面的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无监督预训练和迁移学习是常见的技术手段，用于初始化神经网络的训练算法，特别是在标签数据有限的情况下。本文研究了无监督预训练和迁移学习如何影响高维有监督学习的样本复杂度。具体来说，我们考虑通过在线随机梯度下降法来训练单层神经网络的问题，并建立在非常一般性的假设下，预训练和转移学习（在概念转变的情况下）可以通过多项式因素减少样本复杂性。此外，研究还揭示了某些情况，在无监督预训练方面可以提供相对于随机初始化而言的指数级改进效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised pre-training and transfer learning are commonly used techniquesto initialize training algorithms for neural networks, particularly in settingswith limited labeled data. In this paper, we study the effects of unsupervisedpre-training and transfer learning on the sample complexity of high-dimensionalsupervised learning. Specifically, we consider the problem of training asingle-layer neural network via online stochastic gradient descent. Weestablish that pre-training and transfer learning (under concept shift) reducesample complexity by polynomial factors (in the dimension) under very generalassumptions. We also uncover some surprising settings where pre-training grantsexponential improvement over random initialization in terms of samplecomplexity.</description>
      <author>example@mail.com (Taj Jones-McCormick, Aukosh Jagannath, Subhabrata Sen)</author>
      <guid isPermaLink="false">2502.16849v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Graph Transformers: Architectures, Theories and Applications</title>
      <link>http://arxiv.org/abs/2502.16533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;Graph Transformers (GTs) 在处理图结构时展示了强大的能力，通过解决图神经网络（GNNs）固有的问题如过度平滑和过度挤压。&lt;h4&gt;背景&lt;/h4&gt;近年来，针对 Graph Transformers 的研究提出了多种架构、增强了可解释性，并在实际应用中取得了进展。&lt;h4&gt;目的&lt;/h4&gt;综述 Graph Transformers 在其架构设计、理论基础及具体应用场景等方面的发展状况。&lt;h4&gt;方法&lt;/h4&gt;根据处理结构信息的策略对 Graph Transformers 架构进行分类，包括图标记化、位置编码、基于结构的注意力机制和模型集成等。&lt;h4&gt;主要发现&lt;/h4&gt;探讨了不同架构下 Graph Transformers 的表达能力，并将其与其它先进的图学习算法进行了对比。&lt;h4&gt;应用领域&lt;/h4&gt;总结了 Graph Transformers 在分子数据、蛋白质信息、自然语言处理、视觉交通、脑科学及材料研究等多个领域的实际应用案例。&lt;h4&gt;未来挑战和方向&lt;/h4&gt;讨论了当前 Graph Transformers 面临的挑战以及潜在的研究发展方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs) have demonstrated a strong capability in modelinggraph structures by addressing the intrinsic limitations of graph neuralnetworks (GNNs), such as over-smoothing and over-squashing. Recent studies haveproposed diverse architectures, enhanced explainability, and practicalapplications for Graph Transformers. In light of these rapid developments, weconduct a comprehensive review of Graph Transformers, covering aspects such astheir architectures, theoretical foundations, and applications within thissurvey. We categorize the architecture of Graph Transformers according to theirstrategies for processing structural information, including graph tokenization,positional encoding, structure-aware attention and model ensemble. Furthermore,from the theoretical perspective, we examine the expressivity of GraphTransformers in various discussed architectures and contrast them with otheradvanced graph learning algorithms to discover the connections. Furthermore, weprovide a summary of the practical applications where Graph Transformers havebeen utilized, such as molecule, protein, language, vision traffic, brain andmaterial data. At the end of this survey, we will discuss the currentchallenges and prospective directions in Graph Transformers for potentialfuture research.</description>
      <author>example@mail.com (Chaohao Yuan, Kangfei Zhao, Ercan Engin Kuruoglu, Liang Wang, Tingyang Xu, Wenbing Huang, Deli Zhao, Hong Cheng, Yu Rong)</author>
      <guid isPermaLink="false">2502.16533v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>PLS-based approach for fair representation learning</title>
      <link>http://arxiv.org/abs/2502.16263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文重新审视了公平表征学习的问题，提出了引入公平性的偏最小二乘法（PLS）组件的方法。&lt;h4&gt;背景&lt;/h4&gt;偏最小二乘法在统计学中被广泛应用于通过提供预测专用的表示来高效地降低数据维度。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，在构建PLS成分时纳入公平性约束，以实现在线性和非线性情况下的特征构造。&lt;h4&gt;方法&lt;/h4&gt;该新算法利用核嵌入技术，在PLS组件构建过程中加入公平性的考量，并在不同数据集上进行了效率评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的方法相比于标准的公平主成分分析（PCA）方法具有明显的优势。&lt;h4&gt;结论&lt;/h4&gt;通过引入公平性约束到偏最小二乘法中，可以更有效地进行表征学习和预测。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We revisit the problem of fair representation learning by proposing FairPartial Least Squares (PLS) components. PLS is widely used in statistics toefficiently reduce the dimension of the data by providing representationtailored for the prediction. We propose a novel method to incorporate fairnessconstraints in the construction of PLS components. This new algorithm providesa feasible way to construct such features both in the linear and the non linearcase using kernel embeddings. The efficiency of our method is evaluated ondifferent datasets, and we prove its superiority with respect to standard fairPCA method.</description>
      <author>example@mail.com (Elena M. De-Diego, Adrián Perez-Suay, Paula Gordaliza, Jean-Michel Loubes)</author>
      <guid isPermaLink="false">2502.16263v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Industrial Anomalies Synthesis</title>
      <link>http://arxiv.org/abs/2502.16412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文全面回顾了异常合成的方法论，提供了第一个工业异常合成（IAS）分类体系。&lt;h4&gt;背景&lt;/h4&gt;现有综述关注的技术范围有限，忽视了跨模态数据和视觉语言模型在异常合成中的作用。&lt;h4&gt;目的&lt;/h4&gt;提供一个统一的、涵盖约40种代表方法的综合回顾，并提出首个细粒度框架来反映方法学进展及其实际应用意义。&lt;h4&gt;方法&lt;/h4&gt;将研究对象分为手工设计、基于分布假设、基于生成模型（GM）和基于视觉语言模型（VLM）四大类，详细介绍了每种类别的代表性技术。&lt;h4&gt;主要发现&lt;/h4&gt;首次提出工业异常合成的分类体系，并深入探讨跨模态合成和大规模视觉语言模型的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;为未来的研究提供指导路径，强调了多模态学习在推进IAS方面的优势、挑战及前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到这篇论文全面回顾了异常生成的方法论。现有的综述通常只关注有限的技术，并没有涵盖整个领域的全貌或理解方法间的相互联系。与这些工作不同的是，我们的研究提供了一种统一的视角，涵盖了约40个代表性方法，分为手工设计、基于分布假设、基于生成模型和基于视觉语言模型四类合成方法。此外，我们提出了首个工业异常合成（IAS）分类体系。之前的文献缺乏正式的分类或者使用简化的分类方式，这阻碍了结构化比较和趋势识别的工作。我们的分类体系提供了一个细粒度框架来反映方法学进步及其实际应用意义，并为未来的研究奠定基础。除此之外，我们还探讨了跨模态合成以及大规模视觉语言模型的应用。以往的综述忽视了多模态数据和视觉语言模型在异常生成中的作用，限制了对其优势的理解。我们的调查分析了它们的融合、益处、挑战及前景，提供了一条通过多模态学习提升IAS的道路。更多资源可访问：https://github.com/M-3LAB/awesome-anomaly-synthesis。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper comprehensively reviews anomaly synthesis methodologies. Existingsurveys focus on limited techniques, missing an overall field view andunderstanding method interconnections. In contrast, our study offers a unifiedreview, covering about 40 representative methods across Hand-crafted,Distribution-hypothesis-based, Generative models (GM)-based, andVision-language models (VLM)-based synthesis. We introduce the first industrialanomaly synthesis (IAS) taxonomy. Prior works lack formal classification or usesimplistic taxonomies, hampering structured comparisons and trendidentification. Our taxonomy provides a fine-grained framework reflectingmethodological progress and practical implications, grounding future research.Furthermore, we explore cross-modality synthesis and large-scale VLM. Previoussurveys overlooked multimodal data and VLM in anomaly synthesis, limitinginsights into their advantages. Our survey analyzes their integration,benefits, challenges, and prospects, offering a roadmap to boost IAS withmultimodal learning. More resources are available athttps://github.com/M-3LAB/awesome-anomaly-synthesis.</description>
      <author>example@mail.com (Xichen Xu, Yanshu Wang, Yawen Huang, Jiaqi Liu, Xiaoning Lei, Guoyang Xie, Guannan Jiang, Zhichao Lu)</author>
      <guid isPermaLink="false">2502.16412v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking</title>
      <link>http://arxiv.org/abs/2502.16514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;大型语言模型在生成长文本时容易出现细微的事实错误，尤其是在医学等专业领域。现有的事实核查方法面临难以理解复杂多跳关系和高资源消耗的问题。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型被广泛应用，但它们常常会产生轻微的事实性错误，特别是在需要高度准确性的专业领域如医学中。现有基于文档查证的方法在处理长篇文本的复杂多跳关系时存在困难，并且大多数专业化方法依赖于成对比较，导致计算和资源成本高。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的事实核查框架GraphCheck，利用提取的知识图来改进文本表示，以解决当前事实核查方法存在的问题。&lt;h4&gt;方法&lt;/h4&gt;GraphCheck使用知识图并通过图神经网络进一步处理这些知识图作为软提示，使大型语言模型能够更有效地整合结构化知识。此框架特别擅长捕捉多跳推理链，并通过一次推断调用即可完成精确高效的事实核查。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在七个涵盖一般和医学领域的基准测试上，GraphCheck比基线模型总体提高了6.1%的性能。值得注意的是，该方法不仅超过了现有的专业化事实核查工具，还与最先进语言模型DeepSeek-V3和OpenAI-o1达到了相当的表现，同时参数显著减少。&lt;h4&gt;结论&lt;/h4&gt;GraphCheck框架通过引入知识图来改进大型语言模型的事实核查能力，在提高准确性的同时大幅减少了资源需求。这为在专业领域内进行有效事实核查提供了一种新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) are widely used, but they often generate subtlefactual errors, especially in long-form text. These errors are fatal in somespecialized domains such as medicine. Existing fact-checking with groundingdocuments methods face two main challenges: (1) they struggle to understandcomplex multihop relations in long documents, often overlooking subtle factualerrors; (2) most specialized methods rely on pairwise comparisons, requiringmultiple model calls, leading to high resource and computational costs. Toaddress these challenges, we propose \textbf{\textit{GraphCheck}}, afact-checking framework that uses extracted knowledge graphs to enhance textrepresentation. Graph Neural Networks further process these graphs as a softprompt, enabling LLMs to incorporate structured knowledge more effectively.Enhanced with graph-based reasoning, GraphCheck captures multihop reasoningchains which are often overlooked by existing methods, enabling precise andefficient fact-checking in a single inference call. Experimental results onseven benchmarks spanning both general and medical domains demonstrate a 6.1\%overall improvement over baseline models. Notably, GraphCheck outperformsexisting specialized fact-checkers and achieves comparable performance withstate-of-the-art LLMs, such as DeepSeek-V3 and OpenAI-o1, with significantlyfewer parameters.</description>
      <author>example@mail.com (Yingjian Chen, Haoran Liu, Yinhong Liu, Rui Yang, Han Yuan, Yanran Fu, Pengyuan Zhou, Qingyu Chen, James Caverlee, Irene Li)</author>
      <guid isPermaLink="false">2502.16514v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MAPN: Enhancing Heterogeneous Sparse Graph Representation by Mamba-based Asynchronous Aggregation</title>
      <link>http://arxiv.org/abs/2502.16454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为Mamba异步传播网络（MAPN）的新模型，旨在解决图神经网络在处理大规模稀疏异构图时面临的问题。&lt;h4&gt;背景&lt;/h4&gt;图神经网络(GNNs)已经成为各种图形相关任务的前沿技术，并且在处理异构图(HetGs)时特别突出。然而，GNN面临着过度压缩、过度平滑和传统消息传递神经网络训练大尺度稀疏图效果不佳等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决深度神经网络在大规模异构图形上存在的问题。&lt;h4&gt;方法&lt;/h4&gt;MAPN包括两个主要组件：节点序列生成和语义信息聚合。首先，基于元路径通过随机游走生成节点序列，并使用空间状态模型提取不同距离节点的关键信息。随后，它以异步方式汇总多跳和多层的语义信息，有效地保持独特节点特征并缓解深度网络退化问题。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验证明了MAPN在各种下游任务中的图嵌入的有效性，特别是在大尺度稀疏异构图形中具有显著优势。&lt;h4&gt;结论&lt;/h4&gt;通过提出创新性的MAPN模型，论文提供了一种有效处理大规模稀疏异构图的新途径。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）已成为各种与图相关的任务的前沿技术，并且在异构图（HetGs）中尤为突出。然而，这种范式面临一些问题：首先，难以充分利用长距离信息，即过度压缩；其次，过多的消息传递层会产生无法区分的表示形式，称为过度平滑；最后，传统的MPNN在大规模稀疏图上训练效果不佳。为了解决这些挑战，在大型异构图形中使用深度神经网络的问题，本文介绍了基于Mamba的异步传播网络（MAPN），该模型增强了异构稀疏图的表现力。MAPN包括两个主要组件：节点序列生成和语义信息聚合。节点序列最初是根据元路径通过随机游走生成的，这些元路径构成了空间状态模型的基础，该模型提取了不同距离的节点的关键信息。然后，它以异步方式汇总多跳和多层的信息，有效地保持独特的节点特征，并缓解与深度网络退化相关的问题。在各种数据集上的广泛实验表明，在图嵌入的各种下游任务中MAPN的有效性，强调其在大规模稀疏异构图形表示中的显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have become the state of the art for variousgraph-related tasks and are particularly prominent in heterogeneous graphs(HetGs). However, several issues plague this paradigm: first, the difficulty infully utilizing long-range information, known as over-squashing; second, thetendency for excessive message-passing layers to produce indistinguishablerepresentations, referred to as over-smoothing; and finally, the inadequacy ofconventional MPNNs to train effectively on large sparse graphs. To addressthese challenges in deep neural networks for large-scale heterogeneous graphs,this paper introduces the Mamba-based Asynchronous Propagation Network (MAPN),which enhances the representation of heterogeneous sparse graphs. MAPN consistsof two primary components: node sequence generation and semantic informationaggregation. Node sequences are initially generated based on meta-paths throughrandom walks, which serve as the foundation for a spatial state model thatextracts essential information from nodes at various distances. It thenasynchronously aggregates semantic information across multiple hops and layers,effectively preserving unique node characteristics and mitigating issuesrelated to deep network degradation. Extensive experiments across diversedatasets demonstrate the effectiveness of MAPN in graph embeddings for variousdownstream tasks underscoring its substantial benefits for graph representationin large sparse heterogeneous graphs.</description>
      <author>example@mail.com (Xuqi Mao, Zhenying He, X. Sean Wang)</author>
      <guid isPermaLink="false">2502.16454v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Network Tomography with Path-Centric Graph Neural Network</title>
      <link>http://arxiv.org/abs/2502.16430v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为DeepNT的深度网络拓扑学框架，用于预测路径性能指标，并能推理出部分先验知识下的网络拓扑结构。&lt;h4&gt;背景&lt;/h4&gt;网络拓扑学在网络监控中至关重要，它利用可观察的路径性能度量值来推断未被观测到的度量值。然而现有的方法要么假设完全了解网络拓扑和度量公式（在许多实际情况下这是不现实的），要么依赖于端到端的黑箱模型。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架DeepNT，该框架能够结合数据知识以及适当的归纳偏置来解决网络拓扑学问题。&lt;h4&gt;方法&lt;/h4&gt;引入了以路径为中心的图神经网络，通过推理和聚合构成路径节点序列的嵌入表示来预测性能指标。同时设计了一种学习目标，施加连通性和稀疏性约束在拓扑结构上，并且满足路径性能三角不等式条件。&lt;h4&gt;主要发现&lt;/h4&gt;DeepNT框架在真实世界数据集和合成数据集上的实验表明，在预测性能指标和推理图结构方面超越了最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;通过结合部分先验知识以及数据驱动的方法，可以有效地解决网络拓扑学问题，并能够提供更准确的路径性能度量值预测。&lt;h4&gt;翻译&lt;/h4&gt;摘要：网络拓扑学是网络监控中的关键问题，其中可观察的路径性能指标用于推断未被观测到的指标。然而，大多数现有方法要么假设完全了解网络拓扑和度量公式（在许多实际情况下这是不现实的），要么依赖于端到端的黑箱模型。为了应对这一挑战，在本文中我们提出了一种新的框架DeepNT，该框架利用以路径为中心的图神经网络来预测性能指标，无需预定义的手工设计的指标、假设或真实网络拓扑结构。通过推理和聚合构成路径节点序列的嵌入表示来学习路径嵌入。训练这种以路径为中心的图神经网络需要在离散约束下同时学习神经网络参数和网络拓扑结构，这些约束是由观察到的路径性能指标引入的。这促使我们设计了一个施加连通性和稀疏性约束于拓扑结构以及路径性能三角不等式的学习目标。大量的真实世界数据集和合成数据集上的实验表明，在预测性能指标和推理图拓扑方面，DeepNT优于最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Network tomography is a crucial problem in network monitoring, where theobservable path performance metric values are used to infer the unobservedones, making it essential for tasks such as route selection, fault diagnosis,and traffic control. However, most existing methods either assume completeknowledge of network topology and metric formulas-an unrealistic expectation inmany real-world scenarios with limited observability-or rely entirely onblack-box end-to-end models. To tackle this, in this paper, we argue that agood network tomography requires synergizing the knowledge from both data andappropriate inductive bias from (partial) prior knowledge. To see this, wepropose Deep Network Tomography (DeepNT), a novel framework that leverages apath-centric graph neural network to predict path performance metrics withoutrelying on predefined hand-crafted metrics, assumptions, or the real networktopology. The path-centric graph neural network learns the path embedding byinferring and aggregating the embeddings of the sequence of nodes that composethis path. Training path-centric graph neural networks requires learning theneural netowrk parameters and network topology under discrete constraintsinduced by the observed path performance metrics, which motivates us to designa learning objective that imposes connectivity and sparsity constraints ontopology and path performance triangle inequality on path performance.Extensive experiments on real-world and synthetic datasets demonstrate thesuperiority of DeepNT in predicting performance metrics and inferring graphtopology compared to state-of-the-art methods.</description>
      <author>example@mail.com (Yuntong Hu, Junxiang Wang, Liang Zhao)</author>
      <guid isPermaLink="false">2502.16430v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Automated Keypoint Estimation for Self-Piercing Rivet Joints Using micro-CT Imaging and Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.16752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于微计算机断层扫描（Micro-CT）成像、机器视觉和深度学习技术的自穿铆钉（SPR）接头非破坏性评价方法。通过合成数据预训练模型，并使用少量真实数据进行迁移学习，以实现关键点自动估计，评估接头的质量。&lt;h4&gt;背景&lt;/h4&gt;在汽车工业中，自穿铆钉接头的结构完整性至关重要，但传统破坏性检测手段存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一种成本效益高且可扩展的方法来评价SPR接头的品质。&lt;h4&gt;方法&lt;/h4&gt;使用微计算机断层扫描（Micro-CT）结合机器视觉和深度学习技术，特别是自动关键点估计，利用合成数据进行初始模型训练，并通过真实数据迁移学习适应实际条件。&lt;h4&gt;主要发现&lt;/h4&gt;预训练在合成数据上，再用少量的真实数据进行细化训练，可以缩小领域差距并提高预测精度。该框架为SPR接头评价提供了一种可扩展、成本效益高的解决方案，并为制造过程中的机器视觉和非破坏性检测的更广泛应用奠定了基础。&lt;h4&gt;结论&lt;/h4&gt;通过解决数据稀缺问题并利用先进的机器学习技术，这项工作代表了在工程环境中实现自动质量控制的重要步骤。&lt;h4&gt;翻译&lt;/h4&gt;自穿铆钉（SPR）接头结构完整性对汽车工业至关重要，但传统破坏性方法评价存在挑战。本文提出了一种基于微计算机断层扫描成像、结合机器视觉和深度学习技术的非破坏性评估方案，重点在于自动关键点估计以评估接头质量。鉴于实际微CT数据稀少，本研究使用合成数据进行初始模型训练，并通过迁移学习适应真实情况。采用UNet架构精确定位三个关键点，实现头部高度、锁紧度和底部层厚度等重要参数的测量。详尽验证表明，在合成数据上预训练并在有限的真实数据上微调可以缩小领域差异并提高预测精度。本框架不仅为评价SPR接头提供了可扩展且成本效益高的解决方案，并确立了机器视觉及非破坏性检测在制造流程中更广泛应用的基础。通过处理数据稀缺问题和应用高级机器学习技术，这项工作代表了工程环境中自动质量控制的重要进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The structural integrity of self-piercing rivet (SPR) joints is critical inautomotive industries, yet its evaluation poses challenges due to thelimitations of traditional destructive methods. This research introduces aninnovative approach for non-destructive evaluation using micro-CT imaging,Micro-Computed Tomography, combined with machine vision and deep learningtechniques, specifically focusing on automated keypoint estimation to assessjoint quality. Recognizing the scarcity of real micro-CT data, this studyutilizes synthetic data for initial model training, followed by transferlearning to adapt the model for real-world conditions. A UNet-basedarchitecture is employed to localize three keypoints with precision, enablingthe measurement of critical parameters such as head height, interlock, andbottom layer thickness. Extensive validation demonstrates that pre-training onsynthetic data, complemented by fine-tuning with limited real data, bridgesdomain gaps and enhances predictive accuracy. The proposed framework not onlyoffers a scalable and cost-efficient solution for evaluating SPR joints butalso establishes a foundation for broader applications of machine vision andnon-destructive testing in manufacturing processes. By addressing data scarcityand leveraging advanced machine learning techniques, this work represents asignificant step toward automated quality control in engineering contexts.</description>
      <author>example@mail.com (Wei Qin Chuah, Ruwan Tennakoon, Amanda Freis, Mark Easton, Reza Hoseinnezhad, Alireza Bab-Hadiashar)</author>
      <guid isPermaLink="false">2502.16752v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Med-gte-hybrid: A contextual embedding transformer model for extracting actionable information from clinical texts</title>
      <link>http://arxiv.org/abs/2502.15996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新型上下文嵌入模型med-gte-hybrid，该模型从gte-large句子变换器中派生而来，用于提取无结构临床叙述中的信息。&lt;h4&gt;目的&lt;/h4&gt;评估med-gte-hybrid在大规模患者队列（来源于MIMIC-IV数据集）上的几种临床预测任务的性能，并展示其在患者分层、聚类和文本检索方面的改进效果。&lt;h4&gt;方法&lt;/h4&gt;采用结合对比学习和去噪自动编码器的模型微调策略，用于评估med-gte-hybrid的性能。同时，在慢性肾脏病（CKD）患者的预后、估计肾小球滤过率(eGFR)预测以及患者死亡率预测等多个临床任务中进行了实验。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，该混合模型在大规模文本嵌入基准测试（MTEB）上优于当前最先进的模型。此外，在某些评估任务侧重于CKD的情况下，句子变换器的混合微调策略可以应用于其他医学领域，并有潜力改善各种医疗应用中的临床决策和个性化治疗路径。&lt;h4&gt;结论&lt;/h4&gt;med-gte-hybrid在多个方面表现出色，包括患者分层、聚类以及文本检索等，特别是在大规模文本嵌入基准测试中超越了当前最先进的模型。该方法对其他医疗领域的潜在应用也进行了展望，强调其可能改善临床决策和个性化治疗路径的能力。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了一种新型上下文嵌入模型med-gte-hybrid，它是从gte-large句子变换器派生而来的，用于提取无结构化临床叙述中的信息。我们的模型微调策略结合了对比学习和去噪自动编码器。为了评估med-gte-hybrid的性能，我们在MIMIC-IV数据集中提取的大规模患者队列中进行了多个临床预测任务的研究，包括慢性肾脏病（CKD）患者的预后、估计肾小球滤过率(eGFR)预测以及患者死亡率预测。此外，我们展示了该模型在患者分层、聚类和文本检索方面的改进效果，并且在大规模文本嵌入基准测试中超过了当前最先进的模型。虽然我们的某些评估集中在CKD上，但句子变换器的混合微调策略可以转移到其他医疗领域，并具有改善各种医疗应用中的临床决策和个人化治疗路径的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel contextual embedding model med-gte-hybrid that wasderived from the gte-large sentence transformer to extract information fromunstructured clinical narratives. Our model tuning strategy for med-gte-hybridcombines contrastive learning and a denoising autoencoder. To evaluate theperformance of med-gte-hybrid, we investigate several clinical prediction tasksin large patient cohorts extracted from the MIMIC-IV dataset, including ChronicKidney Disease (CKD) patient prognosis, estimated glomerular filtration rate(eGFR) prediction, and patient mortality prediction. Furthermore, wedemonstrate that the med-gte-hybrid model improves patient stratification,clustering, and text retrieval, thus outperforms current state-of-the-artmodels on the Massive Text Embedding Benchmark (MTEB). While some of ourevaluations focus on CKD, our hybrid tuning of sentence transformers could betransferred to other medical domains and has the potential to improve clinicaldecision-making and personalised treatment pathways in various healthcareapplications.</description>
      <author>example@mail.com (Aditya Kumar, Simon Rauch, Mario Cypko, Oliver Amft)</author>
      <guid isPermaLink="false">2502.15996v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>AAD-LLM: Neural Attention-Driven Auditory Scene Understanding</title>
      <link>http://arxiv.org/abs/2502.16794v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的听觉场景理解模型AAD-LLM，该模型通过结合脑电信号来推断听众的注意力，并据此调整响应生成。研究证明了这种方法在多个多说话者场景任务中的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的听觉基础模型对所有的声音输入处理方式相同，忽略人类听力感知中固有的选择性特点，即人们倾向于关注特定的声音来源而忽略其他声音。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够根据听众注意力生成相应响应的系统，以提高音频生成与人类感知的一致性。&lt;h4&gt;方法&lt;/h4&gt;提出Intention-Informed Auditory Scene Understanding (II-ASU)框架，并构建了一个原型系统AAD-LLM。该模型通过整合颅内脑电图(iEEG)记录来解码听众关注的具体说话者，然后根据推断出的注意力状态调整响应生成。&lt;h4&gt;主要发现&lt;/h4&gt;在多说话者的场景下，AAD-LLM在说话人描述、语音转录与提取以及问答任务中表现出更好的一致性。评估结果显示，客观和主观评价均表明该模型能够更好地符合听众的意图。&lt;h4&gt;结论&lt;/h4&gt;本研究为面向意图感知的听觉人工智能领域铺平了道路，通过将听众感知信息融入机器处理过程，探索了一种新的聆听机制。这为未来的以用户为中心的音频系统开发提供了可能的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文主要探讨了现有听觉模型忽视人类听力选择性的问题，并提出了AAD-LLM原型系统来解决这一问题，展示其在多说话者场景任务中的优越表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Auditory foundation models, including auditory large language models (LLMs),process all sound inputs equally, independent of listener perception. However,human auditory perception is inherently selective: listeners focus on specificspeakers while ignoring others in complex auditory scenes. Existing models donot incorporate this selectivity, limiting their ability to generateperception-aligned responses. To address this, we introduce Intention-InformedAuditory Scene Understanding (II-ASU) and present Auditory Attention-Driven LLM(AAD-LLM), a prototype system that integrates brain signals to infer listenerattention. AAD-LLM extends an auditory LLM by incorporating intracranialelectroencephalography (iEEG) recordings to decode which speaker a listener isattending to and refine responses accordingly. The model first predicts theattended speaker from neural activity, then conditions response generation onthis inferred attentional state. We evaluate AAD-LLM on speaker description,speech transcription and extraction, and question answering in multitalkerscenarios, with both objective and subjective ratings showing improvedalignment with listener intention. By taking a first step towardintention-aware auditory AI, this work explores a new paradigm where listenerperception informs machine listening, paving the way for futurelistener-centered auditory systems. Demo and code available:https://aad-llm.github.io.</description>
      <author>example@mail.com (Xilin Jiang, Sukru Samet Dindar, Vishal Choudhari, Stephan Bickel, Ashesh Mehta, Guy M McKhann, Adeen Flinker, Daniel Friedman, Nima Mesgarani)</author>
      <guid isPermaLink="false">2502.16794v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Diagnosing COVID-19 Severity from Chest X-Ray Images Using ViT and CNN Architectures</title>
      <link>http://arxiv.org/abs/2502.16622v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究构建了一个大型的COVID严重程度数据集，并探讨了迁移学习和视觉变换器在预测患者病情严重程度中的有效性。&lt;h4&gt;背景&lt;/h4&gt;新冠疫情对医疗资源造成了压力，促使人们讨论机器学习如何减轻医生负担并有助于诊断。胸部X光（CXRs）被用于诊断新冠，但很少有研究根据CXRs预测患者的病情严重性。&lt;h4&gt;目的&lt;/h4&gt;通过合并多个数据来源创建一个大型的COVID严重程度数据集，并调查迁移学习在病情严重性和分类任务中的效果。&lt;h4&gt;方法&lt;/h4&gt;使用预训练模型DenseNet161、基于ImageNet和CXR的数据预处理以及视觉变换器（ViT）进行研究。其中，DenseNet161模型在三类病情预测问题中表现出色，而ViT的回归结果最佳。&lt;h4&gt;主要发现&lt;/h4&gt;1. 预训练的DenseNet161模型对三个类别严重程度的预测表现最好，在整体上达到80%的准确性。2. ViT在根据放射科医生评分进行病情严重性评分的回归任务中表现出最优的结果，均方绝对误差为0.5676。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了迁移学习和视觉变换器在从胸部X光预测患者病情严重程度方面具有显著潜力。预训练模型DenseNet161在分类任务上表现最好，而ViT则在回归任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;摘要：新冠疫情给医疗资源带来了巨大压力，并引发了关于机器学习如何减轻医生负担并支持诊断的讨论。胸部X光（CXRs）被用于诊断新冠，但鲜有研究依据CXRs预测患者的病情严重性。本研究通过合并三个来源创建了一个大型COVID严重程度数据集，并探讨了使用ImageNet和CXR预训练模型以及视觉变换器在病情回归与分类任务中的有效性的迁移学习方法。其中，一个预训练的DenseNet161模型在三类病情预测问题中表现出色，在整体上达到了80%的准确性（具体为轻度、中度及重度病例准确率分别为77.3%，83.9%，和70%）。ViT则表现出了最优的回归结果，其均方绝对误差仅为0.5676。研究项目源代码公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The COVID-19 pandemic strained healthcare resources and prompted discussionabout how machine learning can alleviate physician burdens and contribute todiagnosis. Chest x-rays (CXRs) are used for diagnosis of COVID-19, but fewstudies predict the severity of a patient's condition from CXRs. In this study,we produce a large COVID severity dataset by merging three sources andinvestigate the efficacy of transfer learning using ImageNet- andCXR-pretrained models and vision transformers (ViTs) in both severityregression and classification tasks. A pretrained DenseNet161 model performedthe best on the three class severity prediction problem, reaching 80% accuracyoverall and 77.3%, 83.9%, and 70% on mild, moderate and severe cases,respectively. The ViT had the best regression results, with a mean absoluteerror of 0.5676 compared to radiologist-predicted severity scores. Theproject's source code is publicly available.</description>
      <author>example@mail.com (Luis Lara, Lucia Eve Berger, Rajesh Raju, Shawn Whitfield)</author>
      <guid isPermaLink="false">2502.16622v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model</title>
      <link>http://arxiv.org/abs/2502.16779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究介绍了一种名为Plane-DUSt3R的新方法，用于多视角房间布局估计。&lt;h4&gt;背景&lt;/h4&gt;目前从多个视角的图像中进行房间布局估计的研究较少，因为涉及复杂的多视图几何结构问题。传统的方法需要分步骤解决相机内参和外参估计、图像匹配以及三角测量等问题。&lt;h4&gt;目的&lt;/h4&gt;引入Plane-DUSt3R方法，利用三维基础模型DUSt3R来简化房间布局估计的过程，并提高其准确性。&lt;h4&gt;方法&lt;/h4&gt;Plane-DUSt3R结合了DUSt3R框架，并在房间布局数据集（Structure3D）上进行微调以估算结构平面。该方法通过生成统一和简洁的结果，仅需一步后处理步骤和2D检测结果即可完成房间布局估计。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，Plane-DUSt3R不仅在合成数据集中优于现有最佳方法，在不同图像风格（如卡通）的真实世界数据中也表现出强大的鲁棒性和有效性。&lt;h4&gt;结论&lt;/h4&gt;相比传统多步骤的方法，Plane-DUSt3R提供了一种更直接、更有效的解决方案。该模型能够处理多个视角的图像，并且减少了错误累积。&lt;h4&gt;翻译&lt;/h4&gt;房间布局估计从多个视角的图像出发受到的关注较少，这是由于复杂的多视图几何结构问题造成的，需要进行相机内参和外参估计、图像匹配以及三角测量等步骤。然而，在三维重建领域，近期3D基础模型（如DUSt3R）的发展改变了传统的基于结构的运动过程到端到端一步式的转变。为此，我们介绍了一种名为Plane-DUSt3R的方法，利用3D基础模型DUSt3R来进行多视角房间布局估计。通过在房间布局数据集上微调并修改目标以估算结构平面，生成一致且简洁的结果使仅需要一个后处理步骤和2D检测结果就可完成房间布局的估计。与依赖于单视角或全景图像的方法不同，Plane-DUSt3R可以处理多视角图像，并提供了一种简化流程减少错误累积的端到端解决方案。实验结果显示，无论是合成数据还是真实世界中具有多种风格（如卡通）的数据集，Plane-DUSt3R都优于现有最佳方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Room layout estimation from multiple-perspective images is poorlyinvestigated due to the complexities that emerge from multi-view geometry,which requires muti-step solutions such as camera intrinsic and extrinsicestimation, image matching, and triangulation. However, in 3D reconstruction,the advancement of recent 3D foundation models such as DUSt3R has shifted theparadigm from the traditional multi-step structure-from-motion process to anend-to-end single-step approach. To this end, we introduce Plane-DUSt3R}, anovel method for multi-view room layout estimation leveraging the 3D foundationmodel DUSt3R. Plane-DUSt3R incorporates the DUSt3R framework and fine-tunes ona room layout dataset (Structure3D) with a modified objective to estimatestructural planes. By generating uniform and parsimonious results, Plane-DUSt3Renables room layout estimation with only a single post-processing step and 2Ddetection results. Unlike previous methods that rely on single-perspective orpanorama image, Plane-DUSt3R extends the setting to handle multiple-perspectiveimages. Moreover, it offers a streamlined, end-to-end solution that simplifiesthe process and reduces error accumulation. Experimental results demonstratethat Plane-DUSt3R not only outperforms state-of-the-art methods on thesynthetic dataset but also proves robust and effective on in the wild data withdifferent image styles such as cartoon.</description>
      <author>example@mail.com (Yaxuan Huang, Xili Dai, Jianan Wang, Xianbiao Qi, Yixing Yuan, Xiangyu Yue)</author>
      <guid isPermaLink="false">2502.16779v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SDA-DDA Semi-supervised Domain Adaptation with Dynamic Distribution Alignment Network For Emotion Recognition Using EEG Signals</title>
      <link>http://arxiv.org/abs/2502.16485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的半监督领域适应框架SDA-DDA，该框架使用动态分布对齐机制和伪标签置信度过滤模块来解决情感脑机接口技术中个体间EEG数据差异的问题。&lt;h4&gt;背景&lt;/h4&gt;情感脑机接口（aBCI）通过监测并识别人类情绪状态促进情感感知技术的发展。然而，不同个体间的EEG信号存在显著的变异性，这阻碍了有效且广泛适用的情感脑机接口模型的发展。&lt;h4&gt;目的&lt;/h4&gt;为了应对这种挑战，研究旨在开发一种新的迁移学习框架，以提高aBCI在跨受试者和跨时段条件下的情感识别准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为SDA-DDA的新半监督领域适应框架。该框架通过最大均值差异（MMD）和条件最大均值差异（CMMD）来对齐源域与目标域的边际及条件概率分布，并引入动态分布对齐机制以在整个训练过程中调整差异，提高适应性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明SDA-DDA框架在情感识别方面优于现有方法，在跨受试者和跨时段条件下表现尤为突出。这证明了该方法的强大鲁棒性和有效性。&lt;h4&gt;结论&lt;/h4&gt;这项研究推进了情感脑机接口技术的发展，提高了情绪识别的泛化能力和准确性，有助于实现个性化的情感脑机接口应用。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们专注于解决个体差异在情感脑机接口（aBCI）中的挑战。通过EEG信号监测和识别人类的情绪状态，从而促进情感感知技术的发展。然而，不同个体间的EEG数据变异性是开发有效且广泛应用的情感脑机接口模型的主要障碍。为了解决这一问题，我们提出了一种新的迁移学习框架——半监督领域适应与动态分布对齐（SDA-DDA）。该方法使用最大均值差异（MMD）和条件最大均值差异（CMMD）来对齐源域与目标域的边际及条件概率分布。引入了动态分布对齐机制在整个训练过程中调整差异，提高适应性。此外，在半监督流程中集成了伪标签置信度过滤模块以优化伪标签生成并改善条件分布估计。在EEG基准数据库（SEED、SEED-IV和DEAP）上的广泛实验验证了SDA-DDA的强大鲁棒性和有效性。结果表明，相较于现有方法，该框架在各种场景下的情感识别中具有优越性，包括跨受试者和跨时段条件。这项进步增强了情感识别的泛化能力和准确性，可能促进个性化aBCI应用的发展。源代码可从https://github.com/XuanSuTrum/SDA-DDA获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we focus on the challenge of individual variability inaffective brain-computer interfaces (aBCI), which employs electroencephalogram(EEG) signals to monitor and recognize human emotional states, therebyfacilitating the advancement of emotion-aware technologies. The variability inEEG data across individuals poses a significant barrier to the development ofeffective and widely applicable aBCI models. To tackle this issue, we propose anovel transfer learning framework called Semi-supervised Domain Adaptation withDynamic Distribution Alignment (SDA-DDA). This approach aligns the marginal andconditional probability distribution of source and target domains using maximummean discrepancy (MMD) and conditional maximum mean discrepancy (CMMD). Weintroduce a dynamic distribution alignment mechanism to adjust differencesthroughout training and enhance adaptation. Additionally, a pseudo-labelconfidence filtering module is integrated into the semi-supervised process torefine pseudo-label generation and improve the estimation of conditionaldistributions. Extensive experiments on EEG benchmark databases (SEED, SEED-IVand DEAP) validate the robustness and effectiveness of SDA-DDA. The resultsdemonstrate its superiority over existing methods in emotion recognition acrossvarious scenarios, including cross-subject and cross-session conditions. Thisadvancement enhances the generalization and accuracy of emotion recognition,potentially fostering the development of personalized aBCI applications. Thesource code is accessible at https://github.com/XuanSuTrum/SDA-DDA.</description>
      <author>example@mail.com (Jiahao Tang)</author>
      <guid isPermaLink="false">2502.16485v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Keeping up with dynamic attackers: Certifying robustness to adaptive online data poisoning</title>
      <link>http://arxiv.org/abs/2502.16737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 28th International Conference on Artificial  Intelligence and Statistics (AISTATS) 2025, Mai Khao, Thailand. PMLR: Volume  258&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文研究了在在线学习环境中，动态对手进行数据投毒攻击对机器学习算法的影响，并提出了计算这种影响的认证边界的新框架。&lt;h4&gt;背景&lt;/h4&gt;随着基于人类反馈微调基础模型的发展，不信任用户提供的人类反馈增加了对抗性数据中毒的风险。现有研究表明静态对手通过修改训练集可以降低模型鲁棒性，但在实际应用中，动态对手能够观察和响应学习过程，并更有效地注入毒害样本以优化其目标。&lt;h4&gt;目的&lt;/h4&gt;提出一种新框架来计算动态投毒影响的认证边界，并利用这些证书设计出更加稳健的学习算法。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一个新的计算认证边界的框架，并通过均值估计和二元分类问题进行了说明，展示了如何使用该框架设计对抗数据投毒攻击更为有效的学习算法。&lt;h4&gt;主要发现&lt;/h4&gt;在线动态对手相较于静态对手更具威胁性。提出的框架能够帮助构建更稳健的机器学习模型，抵御更复杂的数据中毒攻击。&lt;h4&gt;结论&lt;/h4&gt;研究为解决在线学习中的动态数据投毒问题提供了新方法和理论支持，并指出未来工作应进一步探索该领域。&lt;h4&gt;翻译&lt;/h4&gt;基础模型根据潜在不可信用户的人类反馈进行微调的风险增加了对抗性数据中毒的风险，这需要对学习算法在面对此类攻击时的鲁棒性的研究。现有关于可证明认证鲁棒性以抵御数据投毒攻击的研究主要集中在静态对手上，这些对手可以在训练算法应用前修改一部分用于训练模型的数据集。但在实践中，尤其是在根据人类反馈进行在线学习的情况下，对抗者可以观察和响应学习过程，并注入优化其目标的有毒样本，比他们仅被限制在一次性中毒静态数据集中时更有效。事实上，在先前的工作中已经表明，在线动态对手可能远比静态对手更为强大。我们提出了一种用于计算动态投毒影响认证边界的新型框架，并使用这些证书来设计稳健的学习算法。论文展示了该框架在均值估计和二元分类问题上的应用示例，并概述了进一步工作的扩展方向。实现我们的证书并复制结果的代码可在https://github.com/Avinandan22/Certified-Robustness上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rise of foundation models fine-tuned on human feedback from potentiallyuntrusted users has increased the risk of adversarial data poisoning,necessitating the study of robustness of learning algorithms against suchattacks. Existing research on provable certified robustness against datapoisoning attacks primarily focuses on certifying robustness for staticadversaries who modify a fraction of the dataset used to train the model beforethe training algorithm is applied. In practice, particularly when learning fromhuman feedback in an online sense, adversaries can observe and react to thelearning process and inject poisoned samples that optimize adversarialobjectives better than when they are restricted to poisoning a static datasetonce, before the learning algorithm is applied. Indeed, it has been shown inprior work that online dynamic adversaries can be significantly more powerfulthan static ones. We present a novel framework for computing certified boundson the impact of dynamic poisoning, and use these certificates to design robustlearning algorithms. We give an illustration of the framework for the meanestimation and binary classification problems and outline directions forextending this in further work. The code to implement our certificates andreplicate our results is available athttps://github.com/Avinandan22/Certified-Robustness.</description>
      <author>example@mail.com (Avinandan Bose, Laurent Lessard, Maryam Fazel, Krishnamurthy Dj Dvijotham)</author>
      <guid isPermaLink="false">2502.16737v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Improving Monocular Visual-Inertial Initialization with Structureless Visual-Inertial Bundle Adjustment</title>
      <link>http://arxiv.org/abs/2502.16598v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;单目视觉惯性里程计（VIO）在实时运动追踪应用中表现出色，得益于传感器套件的小巧和低功耗。为了成功启动VIO算法，初始化模块非常重要。&lt;h4&gt;背景&lt;/h4&gt;大多数初始化方法依赖于三维视觉点云的重建。这些方法由于状态向量包含运动状态和三维特征点而导致计算成本较高。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，并提高无结构初始化法的准确性，提出了新的无结构视觉惯性捆绑调整方法以进一步细化先前的无结构解。&lt;h4&gt;方法&lt;/h4&gt;该论文提出了一种新型的无结构视觉惯性捆绑调整算法来改进初始状态估计问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在保持实时性能的同时显著提高了VIO初始化精度。&lt;h4&gt;结论&lt;/h4&gt;通过新的无结构视觉惯性捆绑调整技术，不仅解决了计算效率的问题，还提升了VIO系统的初始化准确性。&lt;h4&gt;翻译&lt;/h4&gt;单目视觉惯性里程计（VIO）由于传感器套件的小巧和低功耗，在实时运动追踪应用中得到广泛应用。为了成功启动这些算法，初始化模块至关重要。大多数现有方法依赖于三维点云重建，这导致计算成本较高。为解决此问题并提升无结构化方法的性能准确性，研究者提出了新的无结构视觉惯性捆绑调整技术以进一步优化初始状态估计。实验结果表明，该方法显著提高了VIO系统的初始化精度，并保持了实时处理能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular visual inertial odometry (VIO) has facilitated a wide range ofreal-time motion tracking applications, thanks to the small size of the sensorsuite and low power consumption. To successfully bootstrap VIO algorithms, theinitialization module is extremely important. Most initialization methods relyon the reconstruction of 3D visual point clouds. These methods suffer from highcomputational cost as state vector contains both motion states and 3D featurepoints. To address this issue, some researchers recently proposed astructureless initialization method, which can solve the initial state withoutrecovering 3D structure. However, this method potentially compromisesperformance due to the decoupled estimation of rotation and translation, aswell as linear constraints. To improve its accuracy, we propose novelstructureless visual-inertial bundle adjustment to further refine previousstructureless solution. Extensive experiments on real-world datasets show ourmethod significantly improves the VIO initialization accuracy, whilemaintaining real-time performance.</description>
      <author>example@mail.com (Junlin Song, Antoine Richard, Miguel Olivares-Mendez)</author>
      <guid isPermaLink="false">2502.16598v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MOB-GCN: A Novel Multiscale Object-Based Graph Neural Network for Hyperspectral Image Classification</title>
      <link>http://arxiv.org/abs/2502.16289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种名为MOB-GCN的新型多尺度对象基于图神经网络，用于高光谱图像(HSI)分类。该研究的主要目标是通过利用多尺度对象基础影像分析(OBIA)，提高特征提取和分类性能。&lt;h4&gt;背景&lt;/h4&gt;传统的像素级方法通常由于准确性低和斑点噪声问题而效果不佳，单一尺度的OBIA方法可能忽略了不同细节层次下影像物体的重要信息。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，MOB-GCN通过从多个分割尺度中提取并整合特征来提升分类结果。该模型利用多分辨率图网络（MGN）架构捕捉细粒度和全局空间模式。&lt;h4&gt;方法&lt;/h4&gt;通过构建动态的多尺度图层级结构，MOB-GCN提供了对HSI复杂细节与全局上下文更全面的理解。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，与单一尺度图卷积网络(GCN)相比，MOB-GCN在分类准确性、计算效率和降噪方面表现更为出色，尤其是在标注数据有限的情况下。&lt;h4&gt;结论&lt;/h4&gt;MOB-GCN的实现代码可在https://github.com/HySonLab/MultiscaleHSI 上公开获得。&lt;h4&gt;翻译&lt;/h4&gt;该论文提出了一种名为MOB-GCN的新颖多尺度对象基于图神经网络以改进高光谱图像(HSI)分类中的特征提取和分类性能。传统像素级方法因准确性低及斑点噪声而受限，单一尺度OBIA方法容易忽略不同层次细节下的关键信息。为了克服这些问题，MOB-GCN通过从多个分割层级中整合并提取特征来增强其性能，并采用多分辨率图网络（MGN）架构捕捉细粒度与全局空间模式。构建的动态多尺度图层级结构使对HSI复杂性有更深入理解的同时提高了准确性、效率及抗噪能力，特别是在数据标记有限的情况下表现更加突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel multiscale object-based graph neural networkcalled MOB-GCN for hyperspectral image (HSI) classification. The central aim ofthis study is to enhance feature extraction and classification performance byutilizing multiscale object-based image analysis (OBIA). Traditionalpixel-based methods often suffer from low accuracy and speckle noise, whilesingle-scale OBIA approaches may overlook crucial information of image objectsat different levels of detail. MOB-GCN overcomes these challenges by extractingand integrating features from multiple segmentation scales, leveraging theMultiresolution Graph Network (MGN) architecture to capture both fine-grainedand global spatial patterns. MOB-GCN addresses this issue by extracting andintegrating features from multiple segmentation scales to improveclassification results using the Multiresolution Graph Network (MGN)architecture that can model fine-grained and global spatial patterns. Byconstructing a dynamic multiscale graph hierarchy, MOB-GCN offers a morecomprehensive understanding of the intricate details and global context ofHSIs. Experimental results demonstrate that MOB-GCN consistently outperformssingle-scale graph convolutional networks (GCNs) in terms of classificationaccuracy, computational efficiency, and noise reduction, particularly whenlabeled data is limited. The implementation of MOB-GCN is publicly available athttps://github.com/HySonLab/MultiscaleHSI</description>
      <author>example@mail.com (Tuan-Anh Yang, Truong-Son Hy, Phuong D. Dao)</author>
      <guid isPermaLink="false">2502.16289v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MimeQA: Towards Socially-Intelligent Nonverbal Foundation Models</title>
      <link>http://arxiv.org/abs/2502.16671v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究介绍了一种新的数据集MimeQA，旨在促进社会智能AI的发展。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能越来越深入人们的日常生活，理解并进行无缝交流的社交智能AI变得愈发重要。然而当前的人工智能在非语言交互的理解上表现不佳。&lt;h4&gt;目的&lt;/h4&gt;通过利用哑剧视频这一富含非言语和社交互动的数据源，改进现有模型对非语言社会互动的理解能力。&lt;h4&gt;方法&lt;/h4&gt;创建了一个新的数据集MimeQA，该数据集中包含221个源自YouTube的哑剧视频，并从中选取了101个视频进行详细标注，形成了806个问题答案配对。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用MimeQA评估最先进的视频大型语言模型(vLLMs)，研究者们发现这些模型在解释非言语互动时准确性较低（15%-30%），且存在过分依赖文本提示而忽视微妙的非言语互动的问题。&lt;h4&gt;结论&lt;/h4&gt;发布数据集旨在推动基础模型的发展，使其能更好地理解非言语的人类交互，促进真正具备社会智能的AI系统的发展。&lt;h4&gt;翻译&lt;/h4&gt;社交智慧型人工智能能够理解和无缝地与人类进行日常生活的交流变得越来越重要。然而目前关于人工社交推理的研究都依赖于语言或以语言为主的方法来进行基准测试和训练模型，导致这些系统在口头沟通方面有所进步但在非言语的社会理解上存在困难。为了克服这一局限性，我们利用了一个新的数据源——哑剧视频来研究非言语社会互动。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Socially intelligent AI that can understand and interact seamlessly withhumans in daily lives is increasingly important as AI becomes more closelyintegrated with peoples' daily activities. However, current works in artificialsocial reasoning all rely on language-only, or language-dominant approaches tobenchmark and training models, resulting in systems that are improving inverbal communication but struggle with nonverbal social understanding. Toaddress this limitation, we tap into a novel source of data rich in nonverbaland social interactions -- mime videos. Mimes refer to the art of expressionthrough gesture and movement without spoken words, which presents uniquechallenges and opportunities in interpreting non-verbal social communication.We contribute a new dataset called MimeQA, obtained by sourcing 221 videos fromYouTube, through rigorous annotation and verification, resulting in a benchmarkwith 101 videos and 806 question-answer pairs. Using MimeQA, we evaluatestate-of-the-art video large language models (vLLMs) and find that theiroverall accuracy ranges from 15-30%. Our analysis reveals that vLLMs often failto ground imagined objects and over-rely on the text prompt while ignoringsubtle nonverbal interactions. Our data resources are released athttps://github.com/MIT-MI/MimeQA to inspire future work in foundation modelsthat embody true social intelligence capable of interpreting non-verbal humaninteractions.</description>
      <author>example@mail.com (Hengzhi Li, Megan Tjandrasuwita, Yi R. Fung, Armando Solar-Lezama, Paul Pu Liang)</author>
      <guid isPermaLink="false">2502.16671v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Geometry-Aware 3D Salient Object Detection Network</title>
      <link>http://arxiv.org/abs/2502.16488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于几何感知的3D显著对象检测网络，该网络通过将点聚类成超级点来提升物体的几何边界，并清晰地分割出具有复杂背景的对象。&lt;h4&gt;背景&lt;/h4&gt;近年来，研究人员对点云显著性目标检测产生了兴趣。然而，现有的工作未能充分利用3D对象的几何上下文，在处理具有复杂背景的对象时会导致模糊边界。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效利用3D对象的几何信息来清晰分割出完整物体的网络模型。&lt;h4&gt;方法&lt;/h4&gt;首先设计了一个简单的超级点划分模块以将点聚类成超级点，并提出了一种无类别感知损失函数来提高超级点的质量。然后，通过超级点-点注意力机制聚合几何信息到点特征中，预测具有清晰边界的显著图。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在PCSOD数据集上取得了最新的最优性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效提升3D显著对象检测的效果，并且对于处理复杂背景下的物体分割任务特别有效。&lt;h4&gt;翻译&lt;/h4&gt;点云显著性目标检测已经引起了研究人员的注意。由于现有的工作未能充分利用3D对象的几何上下文，当对具有复杂背景的对象进行分割时会产生模糊边界。在这篇论文中，我们提出了一种基于几何感知的3D显著性对象检测网络，该网络通过将点显式地聚类成超级点来增强物体的几何边界，从而清晰地分割出具有完整边界的物体。具体来说，首先设计了一个简单的超级点划分模块以将点聚类成超级点，并提出了一种无类别感知损失函数来提高超级点的质量。然后，通过超级点-点注意力机制聚合几何信息到点特征中，预测具有清晰边界的显著图。广泛的实验表明，该方法在PCSOD数据集上取得了最新的最优性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud salient object detection has attracted the attention ofresearchers in recent years. Since existing works do not fully utilize thegeometry context of 3D objects, blurry boundaries are generated when segmentingobjects with complex backgrounds. In this paper, we propose a geometry-aware 3Dsalient object detection network that explicitly clusters points intosuperpoints to enhance the geometric boundaries of objects, thereby segmentingcomplete objects with clear boundaries. Specifically, we first propose a simpleyet effective superpoint partition module to cluster points into superpoints.In order to improve the quality of superpoints, we present a point cloudclass-agnostic loss to learn discriminative point features for clusteringsuperpoints from the object. After obtaining superpoints, we then propose ageometry enhancement module that utilizes superpoint-point attention toaggregate geometric information into point features for predicting the salientmap of the object with clear boundaries. Extensive experiments show that ourmethod achieves new state-of-the-art performance on the PCSOD dataset.</description>
      <author>example@mail.com (Chen Wang, Liyuan Zhang, Le Hui, Qi Liu, Yuchao Dai)</author>
      <guid isPermaLink="false">2502.16488v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>HetFS: A Method for Fast Similarity Search with Ad-hoc Meta-paths on Heterogeneous Information Networks</title>
      <link>http://arxiv.org/abs/2502.16288v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现实世界的信息网络形成了异构信息网络（HIN），节点和边表示为不同类型的对象和关系。相似性衡量的是两个节点的接近程度，并且主要基于它们连接到的其他节点的相似性递归地确定。&lt;h4&gt;问题定义&lt;/h4&gt;用户可能只对特定类型的链接感兴趣，这些链接在相似性的定义中作为元路径（meta-paths）表示。现有方法要么需要为不同的元路径重新训练异构图神经网络（HGNN），要么使用基于路径的方法进行灵活转换但准确性较低。&lt;h4&gt;目的&lt;/h4&gt;提出HetFS（Fast Similarity for Hetereogeneous information networks with user-given meta-paths）以解决实时查询中的问题，能够根据用户指定的元路径快速提供相似性结果。&lt;h4&gt;方法&lt;/h4&gt;HetFS利用满足元路径限制的路径信息和节点内容来计算相似度。它结合了路径信息与节点本身的特性，提高了准确性。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验验证，HetFS在处理实时查询方面表现出色，超越现有的HGNN和基于路径的方法，并且在下游应用中也展现了强大的性能，包括链路预测、节点分类以及聚类。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的方法HetFS来解决异构信息网络中的相似性搜索问题，它能够灵活应对用户指定的元路径并提高准确性与效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文，上面内容是根据摘要总结和翻译的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s11280-024-01303-1&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Numerous real-world information networks form Heterogeneous InformationNetworks (HINs) with diverse objects and relations represented as nodes andedges in heterogeneous graphs. Similarity between nodes quantifies how closelytwo nodes resemble each other, mainly depending on the similarity of the nodesthey are connected to, recursively. Users may be interested in only specifictypes of connections in the similarity definition, represented as meta-paths,i.e., a sequence of node and edge types. Existing Heterogeneous Graph NeuralNetwork (HGNN)-based similarity search methods may accommodate meta-paths, butrequire retraining for different meta-paths. Conversely, existing path-basedsimilarity search methods may switch flexibly between meta-paths but oftensuffer from lower accuracy, as they rely solely on path information. This paperproposes HetFS, a Fast Similarity method for ad-hoc queries with user-givenmeta-paths on Heterogeneous information networks. HetFS provides similarityresults based on path information that satisfies the meta-path restriction, aswell as node content. Extensive experiments demonstrate the effectiveness andefficiency of HetFS in addressing ad-hoc queries, outperformingstate-of-the-art HGNNs and path-based approaches, and showing strongperformance in downstream applications, including link prediction, nodeclassification, and clustering.</description>
      <author>example@mail.com (Xuqi Mao, Zhenyi Chen, Zhenying He, Yinan Jing, Kai Zhang, X. Sean Wang)</author>
      <guid isPermaLink="false">2502.16288v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Semantic Gaussian Mixture Variational Autoencoder for Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2502.16140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by DASFAA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于变分自编码器（VAE）的顺序推荐模型SIGMA，以克服现有VAE在处理用户多重兴趣时能力有限的问题。&lt;h4&gt;背景&lt;/h4&gt;目前大多数基于VAE的顺序推荐系统假设序列表示遵循单一高斯分布作为先验分布。然而，在实际应用中，由于用户的多种多样的兴趣，这种单峰分布难以捕捉复杂且多元化的兴趣模式，导致推荐效果受限。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一个新的基于VAE的顺序推荐模型SIGMA，旨在更好地适应用户的不同兴趣并提高推荐性能。&lt;h4&gt;方法&lt;/h4&gt;SIGMA通过假设序列表示遵循混合高斯分布作为先验来建立一个多模态的兴趣模型。此外，为了将这些多模态兴趣纳入序列表示学习中，SIGMA设计了一个概率多重兴趣提取模块和一个兼容混合高斯先验的多兴趣感知ELBO。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SIGMA在公共数据集上的推荐性能明显优于传统的基于VAE的方法。该模型通过考虑用户的多个兴趣点来提高用户个性化体验。&lt;h4&gt;结论&lt;/h4&gt;SIGMA为顺序推荐提供了一种新的方法论，特别是在处理用户复杂和多元化的兴趣方面显示出潜力。这将对未来的推荐系统设计产生积极影响。&lt;h4&gt;翻译&lt;/h4&gt;变分自编码器（VAE）在序列推荐中通过学习每个用户-项目交互序列的连续分布而不是确定性嵌入来提高数据缺乏下的稳健性和性能表现。然而，现有的基于VAE的序列推荐模型假设序列表示遵循单一高斯分布作为先验，这限制了捕捉复杂用户兴趣的能力，并且当用户具有多种兴趣时会降低推荐性能。由于用户通常会有多个不同的兴趣点，因此，在顺序推荐场景中建立多模态而非单峰的先验更为合理。本文提出了一种新的VAE基于序列推荐模型SIGMA。SIGMA假设序列表示遵循高斯混合分布作为先验，并且每个分量代表一个单独的兴趣。为了提取多重兴趣，SIGMA包括一个多兴趣概率抽取模块以学习每个兴趣的单一高斯分布根据隐含项目超类别进行学习。此外，SIGMA建立了与混合高斯先验兼容的多兴趣感知ELBO，以将多重兴趣整合到序列表示学习中。广泛的实验表明了SIGMA的有效性，代码可以在GitHub上获取（https://github.com/libeibei95/SIGMA）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Variational AutoEncoder (VAE) for Sequential Recommendation (SR), whichlearns a continuous distribution for each user-item interaction sequence ratherthan a determinate embedding, is robust against data deficiency and achievessignificant performance. However, existing VAE-based SR models assume aunimodal Gaussian distribution as the prior distribution of sequencerepresentations, leading to restricted capability to capture complex userinterests and limiting recommendation performance when users have more than oneinterest. Due to that it is common for users to have multiple disparateinterests, we argue that it is more reasonable to establish a multimodal priordistribution in SR scenarios instead of a unimodal one. Therefore, in thispaper, we propose a novel VAE-based SR model named SIGMA. SIGMA assumes thatthe prior of sequence representation conforms to a Gaussian mixturedistribution, where each component of the distribution semantically correspondsto one of multiple interests. For multi-interest elicitation, SIGMA includes aprobabilistic multi-interest extraction module that learns a unimodal Gaussiandistribution for each interest according to implicit item hyper-categories.Additionally, to incorporate the multimodal interests into sequencerepresentation learning, SIGMA constructs a multi-interest-aware ELBO, which iscompatible with the Gaussian mixture prior. Extensive experiments on publicdatasets demonstrate the effectiveness of SIGMA. The code is available athttps://github.com/libeibei95/SIGMA.</description>
      <author>example@mail.com (Beibei Li, Tao Xiang, Beihong Jin, Yiyuan Zheng, Rui Zhao)</author>
      <guid isPermaLink="false">2502.16140v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Anomaly preserving contrastive neural embeddings for end-to-end model-independent searches at the LHC</title>
      <link>http://arxiv.org/abs/2502.15926v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文探讨了通过对比神经嵌入学习强大的低维表示以解决大型强子对撞机(LHC)中异常检测的问题。&lt;h4&gt;背景&lt;/h4&gt;在LHC这样的设备中，由于数据集的规模和复杂性，异常检测是一项关键挑战。通常采用的方法是将高维度探测器数据转换为具有物理意义的低维度特征。&lt;h4&gt;目的&lt;/h4&gt;该研究旨在通过对比神经嵌入方法从数据中提取物理信号并识别潜在的新物理现象。&lt;h4&gt;方法&lt;/h4&gt;文中比较了监督和自我监督的对比学习方法，包括多层感知机(MLP)和Transformer架构。这些方法基于LHC碰撞事件中的动力学可观测属性进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;利用学习到的嵌入表示作为信号无关统计检测方法的输入，在包含所有最终状态中实现了超过十倍于原始特征表现的异常检测性能，并且相对于相同维度的物理信息选择，最多有四倍的改进。研究还展示了这些模型在搜索多种信号时的有效性。&lt;h4&gt;结论&lt;/h4&gt;发现用于背景分类的最佳表示不一定最大化新物理信号的敏感度，表明保持背景结构和增强异常之间存在内在权衡。该论文强调了基础模型在粒子物理学数据中的应用潜力，能够显著提高神经特征提取，并为全包含最终状态下的科学发现提供了可能。&lt;h4&gt;翻译&lt;/h4&gt;异常检测——识别与标准模型预测的偏差——是大型强子对撞机(LHC)面临的关键挑战，由于其数据集的巨大规模和复杂性。这通常通过将高维度探测器数据转换成低维度、物理意义明确的功能来解决。我们利用对比神经嵌入学习强大的低维表示方式处理特征提取以用于异常检测。这种方法保留了潜在的异常信号，这些信号可能指示新物理学，并且使用基于新型机器学习的统计方法进行无信号假设检验，从而可以提取稀有信号。我们比较了监督和自我监督对比学习方法，包括多层感知机(MLP)和Transformer架构，训练时使用的都是LHC碰撞事件中物理对象的动力学可观测属性。所学到的嵌入表示作为包含所有最终状态中的信号无关统计检测方法的输入，在异常检测性能方面比原始特征表现提高了十倍以上，并且相对于相同维度的基于物理学的选择最多提高四倍。我们证明了对于罕见的新物理信号和罕见的标准模型过程，无论在何种最终状态中都能显著提升发现能力，表明其能够同时有效地搜索多种信号。研究还指出背景分类的最佳表示不总是最大化对新物理信号的敏感度，揭示了保持背景结构与异常增强之间的固有权衡。本研究表明基础模型对于粒子物理学数据具有重要的改进潜力，能够提高神经特征提取，并为全包含最终状态下的科学发现提供可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection -- identifying deviations from Standard Model predictions-- is a key challenge at the Large Hadron Collider due to the size andcomplexity of its datasets. This is typically addressed by transforminghigh-dimensional detector data into lower-dimensional, physically meaningfulfeatures. We tackle feature extraction for anomaly detection by learningpowerful low-dimensional representations via contrastive neural embeddings.This approach preserves potential anomalies indicative of new physics andenables rare signal extraction using novel machine learning-based statisticalmethods for signal-independent hypothesis testing. We compare supervised andself-supervised contrastive learning methods, for both MLP- andTransformer-based neural embeddings, trained on the kinematic observables ofphysics objects in LHC collision events. The learned embeddings serve as inputrepresentations for signal-agnostic statistical detection methods in inclusivefinal states, achieving over ten fold improved detection performance over theoriginal feature representation and up to four fold improvement over using aphysics-informed selections of the same dimensionality. We achieve significantimprovement in discovery power for both rare new physics signals and rareStandard Model processes across diverse final states, demonstrating itsapplicability for efficiently searching for diverse signals simultaneously. Weshow that the optimal representation for background classification does notalways maximize sensitivity to new physics signals, revealing an inherenttrade-off between background structure preservation and anomaly enhancement.Our findings demonstrate that foundation models for particle physics data holdsignificant potential for improving neural feature extraction, enablingscientific discovery in inclusive final states at collider experiments.</description>
      <author>example@mail.com (Kyle Metzger, Lana Xu, Mia Sodini, Thea K. Arrestad, Katya Govorkova, Gaia Grosso, Philip Harris)</author>
      <guid isPermaLink="false">2502.15926v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>FHGE: A Fast Heterogeneous Graph Embedding with Ad-hoc Meta-paths</title>
      <link>http://arxiv.org/abs/2502.16281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;Graph神经网络(GNNs)在各种与图相关的任务中取得了最先进的成果，并被广泛应用于异构图(HetGs)，其中元路径有助于编码不同节点类型之间的特定语义。尽管现有的异构GNNs（HGNNs）由于其专注于改进对异质性的捕捉效果而具有革命性的表示能力，但高昂的训练成本阻碍了它们在需要处理基于用户定义元路径的即时查询的真实场景中的实际部署。&lt;h4&gt;背景&lt;/h4&gt;现有技术通过改进对异构图中不同节点类型之间特定语义的理解达到了最先进的水平，然而这些方法面临着高昂的计算开销，这使得它们难以应用于实时应用场景。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一挑战，本文提出了一种快速异构图嵌入(FHGE)框架，旨在实现高效、无需重新训练即可生成元路径引导下的图嵌入。&lt;h4&gt;方法&lt;/h4&gt;FHGE采用了两部分设计：分割和重构模块。该系统利用元路径单元(MPUs)将图形分解为局部和全局组件，并在重组过程中迅速整合相关MPU的节点嵌入，使快速适应特定元路径成为可能；此外还应用了双重注意力机制来增强语义捕捉能力。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，FHGE框架在生成基于元路径引导下的图嵌入以及下游任务（例如链路预测和节点分类）方面既有效又高效，证明其对实时图形分析具有显著优势。&lt;h4&gt;结论&lt;/h4&gt;FHGE框架提供了一种经济高效的解决方案，在处理异构图中的即时查询时能够快速生成所需的图表示，从而在实际应用中展示出良好的性能和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have emerged as the state of the art for avariety of graph-related tasks and have been widely used in HeterogeneousGraphs (HetGs), where meta-paths help encode specific semantics between variousnode types. Despite the revolutionary representation capabilities of existingheterogeneous GNNs (HGNNs) due to their focus on improving the effectiveness ofheterogeneity capturing, the huge training costs hinder their practicaldeployment in real-world scenarios that frequently require handling ad-hocqueries with user-defined meta-paths. To address this, we propose FHGE, a FastHeterogeneous Graph Embedding designed for efficient, retraining-freegeneration of meta-path-guided graph embeddings. The key design of the proposedframework is two-fold: segmentation and reconstruction modules. It employsMeta-Path Units (MPUs) to segment the graph into local and global components,enabling swift integration of node embeddings from relevant MPUs duringreconstruction and allowing quick adaptation to specific meta-paths. Inaddition, a dual attention mechanism is applied to enhance semantics capturing.Extensive experiments across diverse datasets demonstrate the effectiveness andefficiency of FHGE in generating meta-path-guided graph embeddings anddownstream tasks, such as link prediction and node classification, highlightingits significant advantages for real-time graph analysis in ad-hoc queries.</description>
      <author>example@mail.com (Xuqi Mao, Zhenying He, X. Sean Wang)</author>
      <guid isPermaLink="false">2502.16281v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>AdverX-Ray: Ensuring X-Ray Integrity Through Frequency-Sensitive Adversarial VAEs</title>
      <link>http://arxiv.org/abs/2502.16610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SPIE Medical Imaging 2025 Runner-up 2025 Robert F. Wagner  All-Conference Best Student Paper Award&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AdverX-Ray的方法，用于评估医疗影像的质量。该方法利用对抗生成网络的高频率伪影来训练一个判别器，以检测数据分布的变化（即协变量偏移），从而保证基于深度学习的计算机辅助诊断和检测系统的性能。&lt;h4&gt;背景&lt;/h4&gt;医学影像质量对基于深度学习的计算机辅助诊断和检测系统至关重要。协变量偏移（由不同成像设备或设置引起的细微数据分布变化）会严重降低模型性能，类似于对抗攻击的影响。&lt;h4&gt;目的&lt;/h4&gt;开发一种快速、轻量的方法来评估医疗影像的质量，以便在使用计算机辅助诊断和检测模型之前进行质量检查。&lt;h4&gt;方法&lt;/h4&gt;AdverX-Ray是一个图像质量评估层，它通过利用生成器产生的次优输出作为负面样本来微调判别器的能力。该系统训练于特定机器型号的X射线图像补丁，并能判断扫描是否符合训练分布或同一设备在不同设置下采集。&lt;h4&gt;主要发现&lt;/h4&gt;AdverX-Ray与各种异常数据检测方法相比，显著优于现有的技术，在使用64个随机选取的X射线图像补丁时达到了96.2%的平均AUROC。&lt;h4&gt;结论&lt;/h4&gt;该系统的轻量级和快速架构使其适合实时应用，并增强医疗成像系统的可靠性。代码和预训练模型公开可用。&lt;h4&gt;翻译&lt;/h4&gt;确保医学影像的质量与完整性对于保持基于深度学习的计算机辅助诊断（CAD）和检测（CAD）系统中的诊断准确性至关重要。协变量偏移是由不同成像设备或设置引起的数据分布细微变化，可严重降低模型性能，类似于对抗攻击的影响。因此，评估这些图像质量的方法必须是快速且轻量级的，以便在使用CAD模型之前完成。AdverX-Ray通过充当一个影像质量评估层来满足此需求，并有效检测协变量偏移。经过特定型号机器X射线图像补丁训练的AdverX-Ray能够判断扫描是否符合训练分布或同一设备不同设置下采集的图像。与各种异常数据检测方法相比，AdverX-Ray显著优于现有的技术，在使用64个随机选取的X射线图像补丁时达到了96.2%的平均AUROC。该系统轻量级和快速架构适合实时应用，并增强了医疗成像系统的可靠性。代码和预训练模型公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the quality and integrity of medical images is crucial formaintaining diagnostic accuracy in deep learning-based Computer-Aided Diagnosisand Computer-Aided Detection (CAD) systems. Covariate shifts are subtlevariations in the data distribution caused by different imaging devices orsettings and can severely degrade model performance, similar to the effects ofadversarial attacks. Therefore, it is vital to have a lightweight and fastmethod to assess the quality of these images prior to using CAD models.AdverX-Ray addresses this need by serving as an image-quality assessment layer,designed to detect covariate shifts effectively. This Adversarial VariationalAutoencoder prioritizes the discriminator's role, using the suboptimal outputsof the generator as negative samples to fine-tune the discriminator's abilityto identify high-frequency artifacts. Images generated by adversarial networksoften exhibit severe high-frequency artifacts, guiding the discriminator tofocus excessively on these components. This makes the discriminator ideal forthis approach. Trained on patches from X-ray images of specific machine models,AdverX-Ray can evaluate whether a scan matches the training distribution, or ifa scan from the same machine is captured under different settings. Extensivecomparisons with various OOD detection methods show that AdverX-Raysignificantly outperforms existing techniques, achieving a 96.2% average AUROCusing only 64 random patches from an X-ray. Its lightweight and fastarchitecture makes it suitable for real-time applications, enhancing thereliability of medical imaging systems. The code and pretrained models arepublicly available.</description>
      <author>example@mail.com (Francisco Caetano, Christiaan Viviers, Lena Filatova, Peter H. N. de With, Fons van der Sommen)</author>
      <guid isPermaLink="false">2502.16610v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Iterative Auto-Annotation for Scientific Named Entity Recognition Using BERT-Based Models</title>
      <link>http://arxiv.org/abs/2502.16312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种使用基于BERT的模型进行科学命名实体识别（SciNER）的迭代方法，并利用少量高质量的手动标注数据集通过迁移学习来微调预训练模型。&lt;h4&gt;背景&lt;/h4&gt;在缺乏大规模标注数据的情况下，如何有效地提高自然语言处理任务中的预测准确性是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于BERT的SciNER迭代改进方法，并评估其性能。&lt;h4&gt;方法&lt;/h4&gt;采用两种不同的模型（dslim/bert-large-NER和bert-large-cased），通过高质量的手动注释数据集进行微调，然后使用微调后的模型自动标注更大的数据集，并进一步进行多轮微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于BERT的模型在预测准确性和F1分数方面有了显著提高，特别是对于较少见的实体类。bert-large-cased模型始终优于dslim/bert-large-NER模型。&lt;h4&gt;结论&lt;/h4&gt;该方法展示了一种有效的SciNER迭代改进技术，在标注数据有限的情况下具有广泛的应用潜力，并且未来的研究可以考虑使用未标记的数据进行微调以及探索更强力的编码器如RoBERTa。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容为：本文提出了一种使用基于BERT的模型进行科学命名实体识别（SciNER）的迭代方法。利用转移学习来对预训练模型进行微调，其中使用了少量但高质量的手动标注数据集。通过使用经过微调后的模型自动标注更大的数据集，并随后进一步多轮微调这一过程得到了反复精炼。我们评估了两种模型（dslim/bert-large-NER和bert-largecased），结果表明后者始终优于前者。该方法在预测准确性和F1分数方面表现出了显著的改进，尤其是对于较少见的实体类。未来的研究可以考虑使用未标注的数据进行微调，并探索更强大的编码器如RoBERTa以及扩展手动注释的范围。这一方法在自然语言处理任务中具有广泛应用潜力，尤其是在数据标签受限的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an iterative approach to performing Scientific NamedEntity Recognition (SciNER) using BERT-based models. We leverage transferlearning to fine-tune pretrained models with a small but high-quality set ofmanually annotated data. The process is iteratively refined by using thefine-tuned model to auto-annotate a larger dataset, followed by additionalrounds of fine-tuning. We evaluated two models, dslim/bert-large-NER andbert-largecased, and found that bert-large-cased consistently outperformed theformer. Our approach demonstrated significant improvements in predictionaccuracy and F1 scores, especially for less common entity classes. Future workcould include pertaining with unlabeled data, exploring more powerful encoderslike RoBERTa, and expanding the scope of manual annotations. This methodologyhas broader applications in NLP tasks where access to labeled data is limited.</description>
      <author>example@mail.com (Kartik Gupta)</author>
      <guid isPermaLink="false">2502.16312v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Verifying Quantized Graph Neural Networks is PSPACE-complete</title>
      <link>http://arxiv.org/abs/2502.16244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究验证量化图神经网络（GNNs）的可行性，其中使用固定宽度算术表示数。&lt;h4&gt;目的&lt;/h4&gt;引入线性约束有效性问题(LVP)来验证GNNs属性，并提供一个从LVP实例到逻辑语言的有效翻译。&lt;h4&gt;方法&lt;/h4&gt;提出了一种证明系统并展示了对于任何合理的激活函数，LVP属于PSPACE复杂度类别。同时表明了PSPACE难度，暗示虽然关于量化GNN的推理是可行的，但仍然是计算上具有挑战性的任务。&lt;h4&gt;主要发现&lt;/h4&gt;验证量化GNNs属性的问题(LVP)被定义为在PSPACE中，并证明了其PSPACE难解性。&lt;h4&gt;结论&lt;/h4&gt;尽管存在一定的计算难度，但对于合理激活函数而言，在PSPACE复杂度类别内解决问题是可能的。这表明对量化GNN的推理虽然具有挑战性但仍可实现。&lt;h4&gt;翻译&lt;/h4&gt;本论文研究使用固定宽度算术表示数的量化图神经网络（GNNs）的验证问题，并引入线性约束有效性(LVP)问题，以验证GNN属性的有效性和提供LVP实例到逻辑语言的高效转换。结果显示，对于任何合理激活函数来说，该问题属于PSPACE复杂度类别；同时证明了其PSPACE难度。表明虽然对量化GNN进行推理是可行的，但计算上仍然具有挑战性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we investigate verification of quantized Graph Neural Networks(GNNs), where some fixed-width arithmetic is used to represent numbers. Weintroduce the linear-constrained validity (LVP) problem for verifying GNNsproperties, and provide an efficient translation from LVP instances into alogical language. We show that LVP is in PSPACE, for any reasonable activationfunctions. We provide a proof system. We also prove PSPACE-hardness, indicatingthat while reasoning about quantized GNNs is feasible, it remains generallycomputationally challenging.</description>
      <author>example@mail.com (Marco Sälzer, François Schwarzentruber, Nicolas Troquard)</author>
      <guid isPermaLink="false">2502.16244v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SelaVPR++: Towards Seamless Adaptation of Foundation Models for Efficient Place Recognition</title>
      <link>http://arxiv.org/abs/2502.16601v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种改进的视觉地方识别(SelaVPR++)方法，通过使用轻量级多尺度卷积(MultiConv)适配器来提高基础模型向视觉地方识别任务适应的有效性和性能。&lt;h4&gt;背景&lt;/h4&gt;近期研究表明，利用预训练的视觉基础模型进行视觉位置识别(VPR)可以取得良好的效果。作者之前的工作提出了SelaVPR方法，该方法通过参数高效的方法实现了基础模型向VPR的无缝转换。&lt;h4&gt;目的&lt;/h4&gt;为了提高效率和性能，论文提出了一种SelaVPR的扩展版本——SelaVPR++。&lt;h4&gt;方法&lt;/h4&gt;引入了参数、时间和内存高效的适应策略，利用轻量级多尺度卷积适配器来细化从冻结基础骨干网络获得的中间特征；创新性地提出了更有效的重新排序范式，通过使用紧凑型二进制特征进行初步检索，并采用鲁棒的浮点特征进行重新排序。&lt;h4&gt;主要发现&lt;/h4&gt;提出的相似度约束深度哈希方法可以获得这样的二进制特征，并且可以很容易地集成到VPR流程中；优化了训练策略，统一了几种常见训练数据集的训练协议以更好地培训VPR模型。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明……&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，使用预训练视觉基础模型进行视觉位置识别（VPR）可以实现令人满意的结果。在我们的先前工作中，我们提出了一种方法，将视觉基础模型无缝转换为VPR（SelaVPR）。这种适应方法可以通过参数高效的方法产生全局和局部特征来区分地标，从而用于两阶段的视觉位置识别。尽管SelaVPR已经取得了具有竞争力的效果，但我们认为之前的适应方法在训练时间和GPU内存使用上是低效的，并且重新排序范式在检索延迟和存储使用方面也是昂贵的。为了追求更高的效率和更好的性能，我们提出了SelaVPR的一种扩展版本——SelaVPR++。具体来说，首先设计了一种参数、时间、内存高效的适应方法，该方法利用轻量级多尺度卷积（MultiConv）适配器来细化来自冻结基础骨干网络的中间特征，在训练期间不会反向传播通过基础模型的梯度，并且这种MultiConv适配器可以促进沿空间轴上的特征交互并引入适当的局部先验，从而实现更高的效率和更好的性能。此外，我们提出了一种创新性的重新排序范式以实现更高效的VPR：不依赖于本地特征进行重新排序，这在延迟和存储使用方面会产生巨大的开销，而是采用紧凑的二进制特征用于初步检索，并用鲁棒的浮点（全局）特征用于重新排序。为了获得这些二进制特征，我们提出了一种相似度约束深度哈希方法，可以很容易地整合到VPR流程中。最后，我们改进了我们的训练策略并统一了几种常见训练数据集的训练协议以合并它们以便更好地培训VPR模型。广泛的实验表明……&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies show that the visual place recognition (VPR) method usingpre-trained visual foundation models can achieve promising performance. In ourprevious work, we propose a novel method to realize seamless adaptation offoundation models to VPR (SelaVPR). This method can produce both global andlocal features that focus on discriminative landmarks to recognize places fortwo-stage VPR by a parameter-efficient adaptation approach. Although SelaVPRhas achieved competitive results, we argue that the previous adaptation isinefficient in training time and GPU memory usage, and the re-ranking paradigmis also costly in retrieval latency and storage usage. In pursuit of higherefficiency and better performance, we propose an extension of the SelaVPR,called SelaVPR++. Concretely, we first design a parameter-, time-, andmemory-efficient adaptation method that uses lightweight multi-scaleconvolution (MultiConv) adapters to refine intermediate features from thefrozen foundation backbone. This adaptation method does not back-propagategradients through the backbone during training, and the MultiConv adapterfacilitates feature interactions along the spatial axes and introduces properlocal priors, thus achieving higher efficiency and better performance.Moreover, we propose an innovative re-ranking paradigm for more efficient VPR.Instead of relying on local features for re-ranking, which incurs huge overheadin latency and storage, we employ compact binary features for initial retrievaland robust floating-point (global) features for re-ranking. To obtain suchbinary features, we propose a similarity-constrained deep hashing method, whichcan be easily integrated into the VPR pipeline. Finally, we improve ourtraining strategy and unify the training protocol of several common trainingdatasets to merge them for better training of VPR models. Extensive experimentsshow that ......</description>
      <author>example@mail.com (Feng Lu, Tong Jin, Xiangyuan Lan, Lijun Zhang, Yunpeng Liu, Yaowei Wang, Chun Yuan)</author>
      <guid isPermaLink="false">2502.16601v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Graph Attention Convolutional U-NET: A Semantic Segmentation Model for Identifying Flooded Areas</title>
      <link>http://arxiv.org/abs/2502.15907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图神经网络的自动化洪水区域识别模型，即Graph Attention Convolutional U-NET (GAC-UNET)，该模型结合了图注意力机制和Chebyshev层，并在实验中显示出优于其他方法的表现。&lt;h4&gt;背景&lt;/h4&gt;近年来，由于人为气候变化和无规划的城市建设导致洪灾事件增多。准确地识别洪水区域对于有效的灾害管理和城市规划至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于图神经网络的方法来自动识别洪水区域，利用转移学习和模型重新编程以提高洪水区域分割模型的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用Graph Attention Convolutional U-NET (GAC-UNET) 模型，该模型将图注意力机制和Chebyshev层融入到U-Net架构中，并探索了转移学习的应用。&lt;h4&gt;主要发现&lt;/h4&gt;提出的GAC-UNET模型在mAP、Dice分数和IoU指标上分别达到了91%，94%和89%，超过了其他方法，显示出了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;该研究为洪水易发区域未来的基础设施规划提供了有价值的见解，并表明图神经网络可以在自动化识别洪水区域方面提供改进的机会。&lt;h4&gt;翻译&lt;/h4&gt;不断加剧的人类活动导致的气候变化以及未规划的城市建设在过去几年里增加了洪灾事件。准确地辨识受影响地区对于有效的灾害管理和城市规划至关重要。虽然有少量研究采用卷积神经网络和基于变压器的语义分割技术来识别航空影像中的洪水区域，但图神经网络的发展创造了许多改进的机会。这篇论文提出了一种创新的方法——基于图神经网络（GAC-UNET）模型，用于自动化地辨识洪水区域，并在实验中展示了显著优于其他方法的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing impact of human-induced climate change and unplanned urbanconstructions has increased flooding incidents in recent years. Accurateidentification of flooded areas is crucial for effective disaster managementand urban planning. While few works have utilized convolutional neural networksand transformer-based semantic segmentation techniques for identifying floodedareas from aerial footage, recent developments in graph neural networks havecreated improvement opportunities. This paper proposes an innovative approach,the Graph Attention Convolutional U-NET (GAC-UNET) model, based on graph neuralnetworks for automated identification of flooded areas. The model incorporatesa graph attention mechanism and Chebyshev layers into the U-Net architecture.Furthermore, this paper explores the applicability of transfer learning andmodel reprogramming to enhance the accuracy of flood area segmentation models.Empirical results demonstrate that the proposed GAC-UNET model, outperformsother approaches with 91\% mAP, 94\% dice score, and 89\% IoU, providingvaluable insights for informed decision-making and better planning of futureinfrastructures in flood-prone areas.</description>
      <author>example@mail.com (Muhammad Umair Danish, Madhushan Buwaneswaran, Tehara Fonseka, Katarina Grolinger)</author>
      <guid isPermaLink="false">2502.15907v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Dragen3D: Multiview Geometry Consistent 3D Gaussian Generation with Drag-Based Control</title>
      <link>http://arxiv.org/abs/2502.16475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;单张图像3D生成已成为一个重要的研究领域，在虚拟现实、三维建模和数字内容创作中起着重要作用。&lt;h4&gt;问题&lt;/h4&gt;现有的方法面临多视角几何一致性不足及生成过程可控性有限的问题，这些问题显著限制了它们的实用性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法Drage3D来解决这些挑战，该方法利用3D高斯斑点实现具有几何一致性和可控制性的3D生成。&lt;h4&gt;方法&lt;/h4&gt;{'Anchor-Gaussian变分自编码器(AGSVAE)': '将点云和单张图像编码成锚定潜在变量，并通过解码锚定潜在变量生成3DGS，从而实现高效的潜在空间生成。', 'Seed-Point-Driven策略': '该策略包括两步：首先生成稀疏种子点作为粗糙的几何表示；其次通过Seed-Anchor映射模块将这些种子点映射到锚定潜在变量。这种策略确保了几何一致性，并且用户可以直观地拖动种子点来变形最终3DGS几何，变化会通过锚定潜在变量传播。', '无需2D扩散先验': '我们是首个实现不依赖于2D扩散先验的几何可控制性3D高斯生成和编辑的方法。'}&lt;h4&gt;主要发现&lt;/h4&gt;Drage3D在保持高质量3D生成的同时，实现了多视角几何一致性和用户可控性。&lt;h4&gt;结论&lt;/h4&gt;Drage3D为单图像到三维生成开辟了新的道路，显著提高了现有技术的实用性。&lt;h4&gt;翻译&lt;/h4&gt;单张图像3D生成已作为一项重要研究课题崛起，在虚拟现实、3D建模和数字内容创建中扮演着至关重要的角色。然而，现存的方法面临着诸如缺乏多视角几何一致性以及在生成过程中可控性有限等挑战，这些严重限制了它们的实用性。为了解决这些问题，我们引入了一种名为Drage3D的新方法，利用三维高斯斑点（3DGS）实现了具有几何一致性和可控制性的3D生成。通过Anchor-Gaussian变分自编码器(AGSVAE)，该模型将点云和单张图像编码为锚定潜在变量，并通过这些潜在变量解码出3DGS，从而实现高效的潜在空间生成。为了达成多视角几何一致性及可控性生成目标，我们提出了一种Seed-Point驱动策略：首先生成稀疏种子点作为粗糙的几何表示；其次通过Seed-Anchor映射模块将它们映射到锚定潜在变量。这种策略确保了几何一致性，并且用户可以直观地拖动这些种子点来变形最终3DGS几何，变化会经过锚定潜在变量传播。据我们所知，我们在不依赖于2D扩散先验的情况下首次实现了具有可控制性三维高斯生成和编辑的方法，同时保持了与最先进方法相当的3D生成质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-image 3D generation has emerged as a prominent research topic, playinga vital role in virtual reality, 3D modeling, and digital content creation.However, existing methods face challenges such as a lack of multi-viewgeometric consistency and limited controllability during the generationprocess, which significantly restrict their usability. % To tackle thesechallenges, we introduce Dragen3D, a novel approach that achieves geometricallyconsistent and controllable 3D generation leveraging 3D Gaussian Splatting(3DGS). We introduce the Anchor-Gaussian Variational Autoencoder (Anchor-GSVAE), which encodes a point cloud and a single image into anchor latents anddecode these latents into 3DGS, enabling efficient latent-space generation. Toenable multi-view geometry consistent and controllable generation, we propose aSeed-Point-Driven strategy: first generate sparse seed points as a coarsegeometry representation, then map them to anchor latents via the Seed-AnchorMapping Module. Geometric consistency is ensured by the easily learned sparseseed points, and users can intuitively drag the seed points to deform the final3DGS geometry, with changes propagated through the anchor latents. To the bestof our knowledge, we are the first to achieve geometrically controllable 3DGaussian generation and editing without relying on 2D diffusion priors,delivering comparable 3D generation quality to state-of-the-art methods.</description>
      <author>example@mail.com (Jinbo Yan, Alan Zhao, Yixin Hu)</author>
      <guid isPermaLink="false">2502.16475v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Graph Self-Supervised Learning with Learnable Structural and Positional Encodings</title>
      <link>http://arxiv.org/abs/2502.16233v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted by The World Wide Web Conference (WWW) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了新型图自监督学习框架GenHopNet，该框架旨在解决传统GSSL难以捕捉复杂结构特征的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的图自监督学习（GSSL）在捕获复杂的结构性质方面存在困难。这主要是由于两个原因：一是常规图神经网络（GNNs）无法很好地表示复杂的拓扑特征；二是自监督学习仅仅关注最终的图表示，而忽略了整个过程中的结构信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服这些限制，并增强在区分具有相似局部但不同全局拓扑的图形的能力。&lt;h4&gt;方法&lt;/h4&gt;引入了GenHopNet框架，这是一个融合$k$-跳消息传递机制的GNN框架。此外还提出了一个既考虑结构性又注重位置信息的自监督学习框架，该框架能够在整个学习过程中整合图的拓扑信息。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明GenHopNet超越了经典的Weisfeiler-Lehman（WL）测试在图同构上的表达能力，并且实验结果显示这种方法在图分类数据集上优于现有方法，特别是在那些用于测试结构敏感性的数据集上表现尤为突出。同时保持计算效率。&lt;h4&gt;结论&lt;/h4&gt;所提出的GenHopNet框架及其相关的自监督学习策略显著增强了GSSL区分具有相似局部但不同全局拓扑的图形的能力。&lt;h4&gt;翻译&lt;/h4&gt;传统的图自我监督学习(GSSL)在捕捉复杂的结构特性方面存在困难，这主要是由于两个因素：(1) 常规图神经网络（GNNs）无法充分代表复杂的拓扑特征；(2) 自我监督学习仅关注最终的图表示。为了解决这些问题，我们提出了一个新的框架GenHopNet，它是一个融合了$k$-跳消息传递机制的GNN架构，增强了捕捉局部结构信息的能力而无需显式地提取子结构。理论证明表明，GenHopNet在表达能力上超越了经典的Weisfeiler-Lehman (WL) 测试用于图同构测试。此外，我们还提出了一种基于位置和结构感知的GSSL框架，在整个学习过程中整合拓扑信息，使模型能够同时敏感于图形的拓扑且对特定的结构及特征增强保持不变性。在包括旨在测试结构敏感性的图分类数据集上的全面实验表明，我们的方法在性能上始终优于现有的方法，并且计算效率高。我们的重要贡献在于大幅提升了GSSL区分具有相似局部但不同全局拓扑的图形的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714745&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional Graph Self-Supervised Learning (GSSL) struggles to capturecomplex structural properties well. This limitation stems from two mainfactors: (1) the inadequacy of conventional Graph Neural Networks (GNNs) inrepresenting sophisticated topological features, and (2) the focus ofself-supervised learning solely on final graph representations. To addressthese issues, we introduce \emph{GenHopNet}, a GNN framework that integrates a$k$-hop message-passing scheme, enhancing its ability to capture localstructural information without explicit substructure extraction. Wetheoretically demonstrate that \emph{GenHopNet} surpasses the expressiveness ofthe classical Weisfeiler-Lehman (WL) test for graph isomorphism. Furthermore,we propose a structural- and positional-aware GSSL framework that incorporatestopological information throughout the learning process. This approach enablesthe learning of representations that are both sensitive to graph topology andinvariant to specific structural and feature augmentations. Comprehensiveexperiments on graph classification datasets, including those designed to teststructural sensitivity, show that our method consistently outperforms theexisting approaches and maintains computational efficiency. Our worksignificantly advances GSSL's capability in distinguishing graphs with similarlocal structures but different global topologies.</description>
      <author>example@mail.com (Asiri Wijesinghe, Hao Zhu, Piotr Koniusz)</author>
      <guid isPermaLink="false">2502.16233v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>COMPASS: Cross-embodiment Mobility Policy via Residual RL and Skill Synthesis</title>
      <link>http://arxiv.org/abs/2502.16372v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的工作流程COMPASS，旨在开发跨机器人形态的移动策略，通过结合模仿学习（IL）、残差强化学习（RL）和策略蒸馏的方法来克服现有方法在面对新硬件平台或不同环境时所面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;随着机器人应用领域的扩展，通用且可应用于多种物理形态的移动策略变得日益重要。传统的移动栈虽然在特定平台上有效，但在新的机器人形态上难以大规模部署。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够解决现有方法中普遍存在的协变量偏移、稀疏采样和环境适应性问题的工作流程，实现高效的跨身体形式（embodiment）的移动策略开发。&lt;h4&gt;方法&lt;/h4&gt;通过模仿学习在移动机器人上训练基础模型，结合世界模型与移动策略；使用残差强化学习进一步微调特定身体形态的策略，并利用预训练表示提高采样效率以处理各种物理约束和传感器模式；最后通过策略蒸馏将这些专家策略合并为单一稳健的跨身形态策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，COMPASS能够有效扩展至不同的机器人平台，在适应不同环境配置的同时保持高成功率（相较于预训练模仿学习策略高出约5倍）。&lt;h4&gt;结论&lt;/h4&gt;提出的框架提供了高效且可扩展的方法来实现跨身体形式的移动策略，使具有不同设计的机器人能够在复杂场景中安全有效地导航。&lt;h4&gt;翻译&lt;/h4&gt;随着机器人的广泛应用领域越来越多，通用化的跨形态机动性策略变得越来越重要。经典机动栈在特定平台上已经证明是有效的，但在新的实体上进行规模化部署存在挑战。基于学习的方法（如模仿学习和强化学习）提供了解决方案，但它们也面临协变量漂移、大型环境中的稀疏采样以及实体特异性约束的问题。本文介绍了COMPASS，这是一个通过结合模仿学习、残差RL和策略蒸馏来开发跨实体机动性策略的新工作流程。我们首先在移动机器人上进行模仿学习，并利用易于访问的教师策略训练一个基础模型，该模型将世界模型与机动策略相结合。在此基础上，我们使用残差RL来微调特定实体上的策略，利用预训练表示提高采样效率，在处理各种物理约束和传感器模式方面更加高效。最后，通过策略蒸馏将这些实体专家策略合并为单一稳健的跨实体策略。实验证明了COMPASS能够有效地在不同的机器人平台上扩展，同时保持对不同环境配置的适应性，实现了一个成功率比预训练模仿学习策略高约5倍的一般策略。该框架提供了一种高效且可扩展的方法来解决跨实体机动问题，使设计不同的机器人能够在复杂场景中安全和有效地导航。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As robots are increasingly deployed in diverse application domains,generalizable cross-embodiment mobility policies are increasingly essential.While classical mobility stacks have proven effective on specific robotplatforms, they pose significant challenges when scaling to new embodiments.Learning-based methods, such as imitation learning (IL) and reinforcementlearning (RL), offer alternative solutions but suffer from covariate shift,sparse sampling in large environments, and embodiment-specific constraints.  This paper introduces COMPASS, a novel workflow for developingcross-embodiment mobility policies by integrating IL, residual RL, and policydistillation. We begin with IL on a mobile robot, leveraging easily accessibleteacher policies to train a foundational model that combines a world model witha mobility policy. Building on this base, we employ residual RL to fine-tuneembodiment-specific policies, exploiting pre-trained representations to improvesampling efficiency in handling various physical constraints and sensormodalities. Finally, policy distillation merges these embodiment-specialistpolicies into a single robust cross-embodiment policy.  We empirically demonstrate that COMPASS scales effectively across diverserobot platforms while maintaining adaptability to various environmentconfigurations, achieving a generalist policy with a success rate approximately5X higher than the pre-trained IL policy. The resulting framework offers anefficient, scalable solution for cross-embodiment mobility, enabling robotswith different designs to navigate safely and efficiently in complex scenarios.</description>
      <author>example@mail.com (Wei Liu, Huihua Zhao, Chenran Li, Joydeep Biswas, Soha Pouya, Yan Chang)</author>
      <guid isPermaLink="false">2502.16372v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Robust Dynamic Facial Expression Recognition</title>
      <link>http://arxiv.org/abs/2502.16129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Robust Dynamic Facial Expression Recognition (RDFER)的新方法，该方法旨在解决动态面部表情识别中的硬样本和噪声样本共存的问题。&lt;h4&gt;背景&lt;/h4&gt;目前关于动态面部表情识别的研究主要集中在学习在有噪音或难以处理的数据下的表示形式上，但如何同时处理这两种类型的数据仍然是一个未解之谜。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有问题并提高模型的鲁棒性，该研究设计了一个能够区分硬样本和噪声样本的方法，并提出了一种关键表情重采样框架以及双重流分层网络来增强模型对主要表达的理解能力。&lt;h4&gt;方法&lt;/h4&gt;通过评估模型在不同视频片段上的预测一致性来识别硬样本和噪声样本。采用关键表情重新采样的框架来减少非目标表情带来的干扰，同时使用双序列模型分离短期面部运动与长期情绪变化。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在DFEW和FERV39K等基准数据集上进行了广泛的实验，并证明了其优于现有的最先进的动态面部表情识别方法。&lt;h4&gt;结论&lt;/h4&gt;该工作对于促进动态面部表情识别领域的进一步发展具有重要意义，特别是在噪声一致的鲁棒学习方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要：动态面部表情识别（DFER）的研究是一个新兴领域，涉及视频数据中自动识别面部表情。尽管现有研究主要集中在处理噪音和难以处理样本的学习表示上，但如何同时解决这两种类型的问题仍然没有得到很好的解决。为了克服这一挑战，本文提出了一种区分硬样本和噪声样本的稳健方法。通过评估模型在不同采样片段上的预测一致性来实现这一点，并随后采用强化学习难例和削弱噪声影响的方法。此外，为识别视频中的主要表情并增强模型表示学习的能力，提出了关键表情重采样的框架以及双流分层网络，即鲁棒动态面部表情识别（RDFER）。该方法通过在DFEW和FERV39K等基准数据集上的广泛实验展示出优于现有最先进的DFER方法的表现。综合分析提供了关于所提一致性的有价值见解与观察结果。这项工作对动态面部表情识别领域具有重要意义，并促进了噪声一致性鲁棒学习领域的进一步发展。代码可以从[https://github.com/Cross-Innovation-Lab/RDFER]获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The study of Dynamic Facial Expression Recognition (DFER) is a nascent fieldof research that involves the automated recognition of facial expressions invideo data. Although existing research has primarily focused on learningrepresentations under noisy and hard samples, the issue of the coexistence ofboth types of samples remains unresolved. In order to overcome this challenge,this paper proposes a robust method of distinguishing between hard and noisysamples. This is achieved by evaluating the prediction agreement of the modelon different sampled clips of the video. Subsequently, methodologies thatreinforce the learning of hard samples and mitigate the impact of noisy samplescan be employed. Moreover, to identify the principal expression in a video andenhance the model's capacity for representation learning, comprising a keyexpression re-sampling framework and a dual-stream hierarchical network isproposed, namely Robust Dynamic Facial Expression Recognition (RDFER). The keyexpression re-sampling framework is designed to identify the key expression,thereby mitigating the potential confusion caused by non-target expressions.RDFER employs two sequence models with the objective of disentanglingshort-term facial movements and long-term emotional changes. The proposedmethod has been shown to outperform current State-Of-The-Art approaches in DFERthrough extensive experimentation on benchmark datasets such as DFEW andFERV39K. A comprehensive analysis provides valuable insights and observationsregarding the proposed agreement. This work has significant implications forthe field of dynamic facial expression recognition and promotes the furtherdevelopment of the field of noise-consistent robust learning in dynamic facialexpression recognition. The code is available from[https://github.com/Cross-Innovation-Lab/RDFER].</description>
      <author>example@mail.com (Feng Liu, Hanyang Wang, Siyuan Shen)</author>
      <guid isPermaLink="false">2502.16129v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Asteroid shape inversion with light curves using deep learning</title>
      <link>http://arxiv.org/abs/2502.16455v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;小行星形状反演利用光度数据一直是行星科学和天文研究的关键领域，但现有方法需要大量的迭代计算，使过程耗时且容易陷入局部最优解。我们直接通过深度神经网络建立了光度数据与形状分布之间的映射关系，并使用3D点云表示小行星的形状。&lt;h4&gt;背景&lt;/h4&gt;利用光度数据进行小行星形状反演是天文研究中的一个重要课题。然而，现有的方法需要大量的迭代计算过程耗时且容易陷入局部最优解。&lt;h4&gt;目的&lt;/h4&gt;通过深度学习建立光度数据与小行星形状分布之间的直接映射关系，并开发一种预测非凸小行星凹陷区域的新方法。&lt;h4&gt;方法&lt;/h4&gt;采用3D点云表示小行星的形状，利用非凸小行星光线曲线与其凸包之间的偏差来预测非凸小行星上的凹陷区域。使用Chamfer距离评估传统方法与新方法的结果，并利用Lowell天文台观测数据验证该方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用深度学习技术，我们能够更有效地反演小行星的形状，特别是在处理特殊形状时表现更好。对于凸包上凹陷区域的检测，预测结果的IoU达到0.89，表明了方法的高度准确性。&lt;h4&gt;结论&lt;/h4&gt;实验结果显示该方法具有很强的鲁棒性和适应性，并且优于传统的光度曲线拟合方法。&lt;h4&gt;翻译&lt;/h4&gt;使用基于深度学习的方法进行小行星形状反演的研究。这种方法通过直接映射关系减少了计算时间和局部最优的问题，提高了处理非凸小行星时的效果和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Asteroid shape inversion using photometric data has been a key area of studyin planetary science and astronomical research.However, the current methods forasteroid shape inversion require extensive iterative calculations, making theprocess time-consuming and prone to becoming stuck in local optima. We directlyestablished a mapping between photometric data and shape distribution throughdeep neural networks. In addition, we used 3D point clouds to representasteroid shapes and utilized the deviation between the light curves ofnon-convex asteroids and their convex hulls to predict the concave areas ofnon-convex asteroids. We compared the results of different shape models usingthe Chamfer distance between traditional methods and ours and found that ourmethod performs better, especially when handling special shapes. For thedetection of concave areas on the convex hull, the intersection over union(IoU) of our predictions reached 0.89. We further validated this method usingobservational data from the Lowell Observatory to predict the convex shapes ofthe asteroids 3337 Milo and 1289 Kuta, and conducted light curve fittingexperiments. The experimental results demonstrated the robustness andadaptability of the method</description>
      <author>example@mail.com (YiJun Tang, ChenChen Ying, ChengZhe Xia, XiaoMing Zhang, XiaoJun Jiang)</author>
      <guid isPermaLink="false">2502.16455v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Interpreting core forms of urban morphology linked to urban functions with explainable graph neural network</title>
      <link>http://arxiv.org/abs/2502.16210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究提出了核心城市形态表示的概念，发展了一种可解释的深度学习框架，用于将复杂的都市形式解析为一种新的表示（CoMo），从而揭示了都市功能与形态之间的联系。&lt;h4&gt;背景&lt;/h4&gt;理解城市的高阶关系对于可持续城市发展至关重要。然而，准确地描述复杂的城市形式并使其易于人类理解是一项挑战。&lt;h4&gt;目的&lt;/h4&gt;提出核心城市形态表示的概念，并开发可解释的深度学习框架将复杂的都市形式解析为新的表示（CoMo）。&lt;h4&gt;方法&lt;/h4&gt;利用一个稳定的加权F1分数为89.14%的经过训练的深度学习模型进行解释，以揭示基于核心城市形态表示的城市功能与形态之间的联系。&lt;h4&gt;主要发现&lt;/h4&gt;['波士顿的研究显示，在个人建筑、街区和社区层面上的核心城市形式对相应城市功能非常重要。', '住宅核心形式沿都市脊线呈现出渐进的形态模式，并且这种模式与从市中心到郊区的过渡一致。', '城市形态直接影响土地使用效率，二者具有显著的相关性（R2=0.721, p&lt;0.001）']&lt;h4&gt;结论&lt;/h4&gt;CoMo能够可解释地表示都市形式，提供经典城市位置理论的支持，并为数字孪生体提供了机制见解。&lt;h4&gt;翻译&lt;/h4&gt;理解城市形态与功能之间的高阶关系对于建模可持续城市的内在机制至关重要。然而，准确描述复杂的城市形式并使其易于人类理解是一项挑战。本研究提出核心城市形态表示的概念，并开发了一种可解释的深度学习框架，用于将复杂的都市形式解析为新的表示（CoMo）。通过解释经过良好训练的深度学习模型（稳定的加权F1分数89.14%），CoMo为揭示基于核心城市形态表示的城市功能与形态之间的联系提供了一个有希望的方法。以波士顿作为研究区域，分析了个人建筑、街区和社区层面的核心城市形式对相应城市功能的重要性。住宅核心形式沿都市脊线呈现出渐进的形态模式，并且这种模式与从市中心到郊区的过渡一致。此外，研究表明城市形态直接影响土地使用效率，并具有显著的相关性（R2=0.721, p&lt;0.001）。总的来说，CoMo能够可解释地表示都市形式，提供经典城市位置理论的支持，并为数字孪生体提供了机制见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the high-order relationship between urban form and function isessential for modeling the underlying mechanisms of sustainable urban systems.Nevertheless, it is challenging to establish an accurate data representationfor complex urban forms that are readily explicable in human terms. This studyproposed the concept of core urban morphology representation and developed anexplainable deep learning framework for explicably symbolizing complex urbanforms into the novel representation, which we call CoMo. By interpretating thewell-trained deep learning model with a stable weighted F1-score of 89.14%,CoMo presents a promising approach for revealing links between urban functionand urban form in terms of core urban morphology representation. Using Bostonas a study area, we analyzed the core urban forms at the individual-building,block, and neighborhood level that are important to corresponding urbanfunctions. The residential core forms follow a gradual morphological patternalong the urban spine, which is consistent with a center-urban-suburbantransition. Furthermore, we prove that urban morphology directly affects landuse efficiency, which has a significantly strong correlation with the location(R2=0.721, p&lt;0.001). Overall, CoMo can explicably symbolize urban forms,provide evidence for the classic urban location theory, and offer mechanisticinsights for digital twins.</description>
      <author>example@mail.com (Dongsheng Chen, Yu Feng, Xun Li, Mingya Qu, Peng Luo, Liqiu Meng)</author>
      <guid isPermaLink="false">2502.16210v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Weather Station Data and Radar for Precipitation Nowcasting: SmaAt-fUsion and SmaAt-Krige-GNet</title>
      <link>http://arxiv.org/abs/2502.16116v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究介绍了两种新的深度学习架构，旨在通过整合多变量气象站数据和雷达数据来提高降水短时预报的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于数据驱动和深度学习的方法在降水短时预报中引起了广泛关注，并取得了显著成果。然而，许多现有的模型未能充分利用广泛可用的大气信息，主要依赖于降水量数据。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过引入新的深度学习架构来改善降水短时预报的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了两种新型深度学习架构：SmaAt-fUsion 和 SmaAt-Krige-GNet。SmaAt-fUsion 扩展了 SmaAt-UNet 架构，通过卷积层将气象站数据整合到网络瓶颈部分。而 SmaAt-Krige-GNet 结合了降水图与使用 Kriging 方法处理的气象站数据，生成特定变量的地图，并在基于 SmaAt-GNet 的双编码器架构中利用这些地图进行多级数据集成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在低降水量场景下，SmaAt-Krige-GNet 比仅依赖降水雷达数据的标准 SmaAt-UNet 表现更好；而在低和高降水量场景下，SmaAt-fUsion 超过了 SmaAt-UNet。&lt;h4&gt;结论&lt;/h4&gt;本研究强调了将离散的气象站数据整合到深度学习天气短时预报模型中以提高性能的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容已经涵盖了上述各个要点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, data-driven, deep learning-based approaches forprecipitation nowcasting have attracted significant attention, showingpromising results. However, many existing models fail to fully exploit theextensive atmospheric information available, relying primarily on precipitationdata alone. This study introduces two novel deep learning architectures,SmaAt-fUsion and SmaAt-Krige-GNet, specifically designed to enhanceprecipitation nowcasting by integrating multi-variable weather station datawith radar datasets. By leveraging additional meteorological information, thesemodels improve representation learning in the latent space, resulting inenhanced nowcasting performance. The SmaAt-fUsion model extends the SmaAt-UNetframework by incorporating weather station data through a convolutional layer,integrating it into the bottleneck of the network. Conversely, theSmaAt-Krige-GNet model combines precipitation maps with weather station dataprocessed using Kriging, a geo-statistical interpolation method, to generatevariable-specific maps. These maps are then utilized in a dual-encoderarchitecture based on SmaAt-GNet, allowing multi-level data integration.Experimental evaluations were conducted using four years (2016--2019) ofweather station and precipitation radar data from the Netherlands. Resultsdemonstrate that SmaAt-Krige-GNet outperforms the standard SmaAt-UNet, whichrelies solely on precipitation radar data, in low precipitation scenarios,while SmaAt-fUsion surpasses SmaAt-UNet in both low and high precipitationscenarios. This highlights the potential of incorporating discrete weatherstation data to enhance the performance of deep learning-based weathernowcasting models.</description>
      <author>example@mail.com (Aleksej Cornelissen, Jie Shi, Siamak Mehrkanoon)</author>
      <guid isPermaLink="false">2502.16116v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Ultra fast, event-by-event heavy-ion simulations for next generation experiments</title>
      <link>http://arxiv.org/abs/2502.16330v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新型深度生成框架，利用概率扩散模型进行重离子碰撞事件级别的快速模拟。&lt;h4&gt;背景&lt;/h4&gt;当前的物理实验中，对重离子碰撞数据的模拟是一项耗时的任务。传统方法难以满足大规模和高精度需求。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效、精准地模拟重离子碰撞输出的新框架。&lt;h4&gt;方法&lt;/h4&gt;该框架基于概率扩散模型，结合归一化流条件生成器和粒子点云合成模块，从UrQMD级联数据中学习并生成包含26种不同介子物种的完整碰撞事件输出。&lt;h4&gt;主要发现&lt;/h4&gt;提出的条件点云扩散模型能够产生逼真的重离子碰撞结果，成功再现了UrQMD分布中的多重性、动量和快度特性。&lt;h4&gt;结论&lt;/h4&gt;该框架不仅在质量和速度上优于现有方法，还为逆向问题求解和参数估计提供了便利，并且可以轻松适应加速任何事件级别的模型计算或探测器模拟任务。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新颖的深度生成框架，利用概率扩散模型进行超快速、逐事件重离子碰撞输出模拟。此新框架基于UrQMD级联数据训练，以生成包含26个不同介子物种的完整碰撞事件输出。每个点由粒子动量向量及其对应种类信息（ID）定义。架构中整合了基于归一化流的条件生成器，将全局事件特征编码为潜在矢量，并利用扩散模型根据此条件合成粒子点云。详细描述了模型及深入分析其性能。有条件点云扩散模型学习产生真实碰撞事件输出的颗粒物，成功再现了UrQMD分布中的多重性、动量和快度特性。灵活的点云表示方法保留了完整的事件级粒度，直接应用于逆向问题求解和参数估计任务，并且易于适应加速任何逐事件模型计算或探测器模拟。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel deep generative framework that uses probabilisticdiffusion models for ultra fast, event-by-event simulations of heavy-ioncollision output. This new framework is trained on UrQMD cascade data togenerate a full collision event output containing 26 distinct hadron species.The output is represented as a point cloud, where each point is defined by aparticle's momentum vector and its corresponding species information (ID). Ourarchitecture integrates a normalizing flow-based condition generator thatencodes global event features into a latent vector, and a diffusion model thatsynthesizes a point cloud of particles based on this condition. A detaileddescription of the model and an in-depth analysis of its performance isprovided. The conditional point cloud diffusion model learns to generaterealistic output particles of collision events which successfully reproduce theUrQMD distributions for multiplicity, momentum and rapidity of each hadrontype. The flexible point cloud representation of the event output preservesfull event-level granularity, enabling direct application to inverse problemsand parameter estimation tasks while also making it easily adaptable foraccelerating any event-by-event model calculation or detector simulation.</description>
      <author>example@mail.com (Manjunath Omana Kuttan, Kai Zhou, Jan Steinheimer, Horst Stoecker)</author>
      <guid isPermaLink="false">2502.16330v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>BalanceBenchmark: A Survey for Multimodal Imbalance Learning</title>
      <link>http://arxiv.org/abs/2502.10816v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个全面评估多模态不平衡算法的基准测试平台BalanceBenchmark，包括多个常用的数据集和评价指标，并开发了一个标准化实验流程的工具包。&lt;h4&gt;背景&lt;/h4&gt;多模态学习通过整合不同模态的信息得到了广泛关注。然而，该领域常受到模态失衡问题的影响，即某些模态过于主导而其他模态被利用不足。&lt;h4&gt;目的&lt;/h4&gt;系统分类主流多模态不平衡算法，并提供一个全面的评估方法以促进研究的发展。&lt;h4&gt;方法&lt;/h4&gt;引入BalanceBenchmark基准测试平台和标准化实验流程工具包，通过多个数据集从性能、失衡程度及复杂性三个角度进行综合评价。&lt;h4&gt;主要发现&lt;/h4&gt;基于实验结果，识别出不同方法在性能、平衡度以及计算复杂性方面的特征与优势。&lt;h4&gt;结论&lt;/h4&gt;此分析有望激发未来研究中更有效的不平衡问题解决方案，并可能影响基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;多模态学习因其整合多种信息模态的能力而备受关注。然而，它常因模态失衡问题受到限制，即某些模态主导其他未充分利用的模态。尽管最近的研究提出了各种方法来缓解该问题，但缺乏全面且公平的比较。本文将主流的多模态不平衡算法基于其减轻不平衡的方法分为四大类，并引入BalanceBenchmark基准测试平台以促进综合评估。为确保公平比较，开发了标准化实验流程工具包。通过使用BalanceBenchmark进行实验，识别出不同方法组在性能、平衡度和计算复杂性方面的特征与优势。我们期待这种分析能够启发未来更高效地解决不平衡问题的方法，并可能影响基础模型的发展。工具代码可在https://github.com/GeWu-Lab/BalanceBenchmark获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/gewu-lab/balancebenchmark&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning has gained attention for its capacity to integrateinformation from different modalities. However, it is often hindered by themultimodal imbalance problem, where certain modality dominates while othersremain underutilized. Although recent studies have proposed various methods toalleviate this problem, they lack comprehensive and fair comparisons. In thispaper, we systematically categorize various mainstream multimodal imbalancealgorithms into four groups based on the strategies they employ to mitigateimbalance. To facilitate a comprehensive evaluation of these methods, weintroduce BalanceBenchmark, a benchmark including multiple widely usedmultidimensional datasets and evaluation metrics from three perspectives:performance, imbalance degree, and complexity. To ensure fair comparisons, wehave developed a modular and extensible toolkit that standardizes theexperimental workflow across different methods. Based on the experiments usingBalanceBenchmark, we have identified several key insights into thecharacteristics and advantages of different method groups in terms ofperformance, balance degree and computational complexity. We expect suchanalysis could inspire more efficient approaches to address the imbalanceproblem in the future, as well as foundation models. The code of the toolkit isavailable at https://github.com/GeWu-Lab/BalanceBenchmark.</description>
      <author>example@mail.com (Shaoxuan Xu, Menglu Cui, Chengxiang Huang, Hongfa Wang, Di Hu)</author>
      <guid isPermaLink="false">2502.10816v3</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Co-evolution-based Metal-binding Residue Prediction with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.16189v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为MBGNN的金属结合预测模型，该模型利用共进化残基网络并使用图神经网络来捕捉蛋白质结构中的复杂依赖关系。&lt;h4&gt;背景&lt;/h4&gt;预测金属结合位点及其对应的金属类型在计算结构生物学中具有挑战性，因为涉及到蛋白质结构和相互作用的复杂性。传统的方法无法有效捕获驱动这些相互作用的复杂进化关系，而基于共进化的最近方法没有充分考虑整个共进化残基网络。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的预测模型MBGNN，以改进金属结合位点及其相关金属类型的预测性能。&lt;h4&gt;方法&lt;/h4&gt;MBGNN利用完整的共进化残基网络并通过图神经网络有效捕捉蛋白质结构中的复杂依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MBGNN在公共数据集上的表现优于现有的基于共进化的金属结合预测方法，并且在序列基础上的方法中具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;该模型展示了将共进化见解与高级机器学习技术相结合的潜力，有助于深入理解蛋白质-金属相互作用。MBGNN的代码可在GitHub上公开获得。&lt;h4&gt;翻译&lt;/h4&gt;在计算结构生物学领域，由于蛋白质结构和相互作用的复杂性，预测金属结合位点及其对应的金属类型极具挑战性。传统基于序列和结构的方法无法有效捕捉这些交互背后的复杂进化关系以促进理解，而最近基于共进化的技术未能充分考虑整个共进化残基网络的结构。本文提出了一种名为MBGNN（Metal-Binding Graph Neural Network）的新方法，该模型利用了完整的共进化残基网络并通过图神经网络有效地捕获蛋白质结构中的复杂依赖关系，以提高共进化金属结合位点及其相关金属类型的预测能力。公共数据集上的实验结果表明，MBGNN在基于共进化的金属结合预测方法中表现出色，并且也与最近的序列基础方法相媲美，展示了将共进化见解与高级机器学习相结合的潜力，有助于深入了解蛋白质-金属相互作用。MBGNN代码可以在https://github.com/SRastegari/MBGNN上公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In computational structural biology, predicting metal-binding sites and theircorresponding metal types is challenging due to the complexity of proteinstructures and interactions. Conventional sequence- and structure-basedprediction approaches cannot capture the complex evolutionary relationshipsdriving these interactions to facilitate understanding, while recentco-evolution-based approaches do not fully consider the entire structure of theco-evolved residue network. In this paper, we introduce MBGNN (Metal-BindingGraph Neural Network) that utilizes the entire co-evolved residue network andeffectively captures the complex dependencies within protein structures viagraph neural networks to enhance the prediction of co-evolved metal-bindingresidues and their associated metal types. Experimental results on a publicdataset show that MBGNN outperforms existing co-evolution-based metal-bindingprediction methods, and it is also competitive against recent sequence-basedmethods, showing the potential of integrating co-evolutionary insights withadvanced machine learning to deepen our understanding of protein-metalinteractions. The MBGNN code is publicly available athttps://github.com/SRastegari/MBGNN.</description>
      <author>example@mail.com (Sayedmohammadreza Rastegari, Sina Tabakhi, Xianyuan Liu, Wei Sang, Haiping Lu)</author>
      <guid isPermaLink="false">2502.16189v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Supermarket-6DoF: A Real-World Grasping Dataset and Grasp Pose Representation Analysis</title>
      <link>http://arxiv.org/abs/2502.16311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'研究名称': 'Supermarket-6DoF', '数据规模': '包含1500次抓取尝试，涉及20种超市物品', '特点': '提供真实机器人执行的地面实况抓取结果，并且包含完全的6自由度抓取姿势注释，包括初始抓取成功和被抓取后受到外部扰动的稳定性', '用途': '用于分析三种抓取姿态表示方法对点云中抓取成功的预测准确性'}&lt;h4&gt;背景&lt;/h4&gt;现有的大多数抓取数据集依赖于解析指标或模拟进行抓取标注。相比之下，Supermarket-6DoF提供了物理机器人执行的真实地面实况结果&lt;h4&gt;目的&lt;/h4&gt;展示一个真实的超市物品抓取数据集，并验证其在基于点云的抓取姿态表示中的价值和准确性&lt;h4&gt;方法&lt;/h4&gt;通过分析三种不同的抓取姿态表示来预测抓取成功的准确度，比较了显式表达夹爪几何形状的点云表示与传统的四元数编码的表现&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，将夹爪几何结构作为点云明确表示的方法比传统基于四元数的姿态表示方法在抓取成功率预测中更加精确&lt;h4&gt;结论&lt;/h4&gt;Supermarket-6DoF数据集为研究真实环境中的机器人手部操作提供了一个宝贵的资源，并且证明了使用点云来表达夹爪姿态的有效性&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Supermarket-6DoF, a real-world dataset of 1500 grasp attemptsacross 20 supermarket objects with publicly available 3D models. Unlike mostexisting grasping datasets that rely on analytical metrics or simulation forgrasp labeling, our dataset provides ground-truth outcomes from physical robotexecutions. Among the few real-world grasping datasets, wile more modest insize, Supermarket-6DoF uniquely features full 6-DoF grasp poses annotated withboth initial grasp success and post-grasp stability under externalperturbation. We demonstrate the dataset's utility by analyzing three grasppose representations for grasp success prediction from point clouds. Ourresults show that representing the gripper geometry explicitly as a point cloudachieves higher prediction accuracy compared to conventional quaternion-basedgrasp pose encoding.</description>
      <author>example@mail.com (Jason Toskov, Akansel Cosgun)</author>
      <guid isPermaLink="false">2502.16311v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Advanced Text Analytics -- Graph Neural Network for Fake News Detection in Social Media</title>
      <link>http://arxiv.org/abs/2502.16157v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的图神经网络（GNN）在假新闻检测中通常依赖于辅助的非文本数据，如用户互动历史或内容传播模式。然而这些数据源并不总是可以获取到，限制了方法的有效性和适用性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，本文提出了一种先进的文本分析图神经网络（ATA-GNN），该模型仅基于文本数据进行操作。&lt;h4&gt;方法&lt;/h4&gt;ATA-GNN采用了创新的主题建模技术来识别每个主题的典型词汇，并通过多维聚类实现对文本内容的全面语义理解。这种多层次的设计使模型能够发现复杂的文本模式，同时将这些模式置于更广泛的语境中以增强其解释能力。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛使用的基准数据集上的大量评估表明，ATA-GNN的表现优于现有的基于GNN的方法，在假新闻检测方面更加可靠和专注于文本信息。&lt;h4&gt;结论&lt;/h4&gt;这项研究证明了在图神经网络架构中整合先进的文本聚类方法具有实现更可靠且以文本为中心的解决方案的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;传统的图神经网络（GNN）通常依赖于辅助非文本数据，如用户互动历史或内容传播模式来进行假新闻检测。然而这些数据源并不总是可得，这限制了现有方法的有效性和应用范围。此外，现有的模型常常难以捕捉到文本信息中的详细且复杂的关系，从而降低其整体准确性。为了应对这一挑战，本文提出了一种先进的文本分析图神经网络（ATA-GNN），该模型仅基于文本数据进行操作，并采用了创新的主题建模技术来识别每个主题的典型词汇。通过多维聚类和多层次设计，实现了对文本内容的全面语义理解及复杂模式的发现，在广泛的基准数据集上，该方法的表现超过了现有的GNN方法，表明在图神经网络架构中结合先进的文本聚类方法可以实现更可靠且以文本为中心的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional Graph Neural Network (GNN) approaches for fake news detection(FND) often depend on auxiliary, non-textual data such as user interactionhistories or content dissemination patterns. However, these data sources arenot always accessible, limiting the effectiveness and applicability of suchmethods. Additionally, existing models frequently struggle to capture thedetailed and intricate relationships within textual information, reducing theiroverall accuracy. In order to address these challenges Advanced Text AnalysisGraph Neural Network (ATA-GNN) is proposed in this paper. The proposed model isdesigned to operate solely on textual data. ATA-GNN employs innovative topicmodelling (clustering) techniques to identify typical words for each topic,leveraging multiple clustering dimensions to achieve a comprehensive semanticunderstanding of the text. This multi-layered design enables the model touncover intricate textual patterns while contextualizing them within a broadersemantic framework, significantly enhancing its interpretative capabilities.Extensive evaluations on widely used benchmark datasets demonstrate thatATA-GNN surpasses the performance of current GNN-based FND methods. Thesefindings validate the potential of integrating advanced text clustering withinGNN architectures to achieve more reliable and text-focused detectionsolutions.</description>
      <author>example@mail.com (Anantram Patel, Vijay Kumar Sutrakar)</author>
      <guid isPermaLink="false">2502.16157v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>voc2vec: A Foundation Model for Non-Verbal Vocalization</title>
      <link>http://arxiv.org/abs/2502.16298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;提出了一种新的非言语人类数据基础模型voc2vec，旨在克服现有语音和音频基础模型在处理非语言声音时的不足。&lt;h4&gt;背景信息&lt;/h4&gt;现有的语音基础模型虽然在相关的任务中表现出色，但在处理如婴儿哭泣等非语言音频数据方面存在困难。同样地，传统的音频基础模型虽然能够很好地处理非言语音频，但无法捕捉到人类声音中的细微特征。&lt;h4&gt;研究目的&lt;/h4&gt;旨在克服现有模型的缺点，并提出了一种新的基础模型voc2vec，专门用于处理非言语人类数据。&lt;h4&gt;所用方法&lt;/h4&gt;采用了包含10个数据集、总计约125小时非言语音频的数据集合。这些数据集完全由开源资源构成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，voc2vec在非语言声音分类任务中表现优异，并且超越了传统的语音和音频基础模型以及强大的基准线OpenSmile和emotion2vec。&lt;h4&gt;结论&lt;/h4&gt;据作者所知，voc2vec是首个为发声任务设计的通用表示模型。&lt;h4&gt;翻译&lt;/h4&gt;语音基础模型已经在相关的任务中显示出了非凡的能力。然而，在处理诸如婴儿哭泣等非语言音频数据时，这些模型常常面临困难。这类非语言音频对于各种现实世界的应用至关重要。传统音频基础模型能够很好地处理非言语数据，但无法捕捉到人类声音中的细微特征。本研究旨在克服上述不足，并提出了一种新的基础模型voc2vec，专门设计用于处理非言语人类数据，仅使用开源的非言语音频数据集。实验结果证明，voc2vec在非语言发声分类任务中表现出色，超越了传统的语音和音频基础模型。此外，voc2vec在六个不同的基准测试数据集中也始终优于强大的基准线OpenSmile和emotion2vec。据作者所知，voc2vec是首个为发声任务设计的通用表示模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech foundation models have demonstrated exceptional capabilities inspeech-related tasks. Nevertheless, these models often struggle with non-verbalaudio data, such as vocalizations, baby crying, etc., which are critical forvarious real-world applications. Audio foundation models well handle non-speechdata but also fail to capture the nuanced features of non-verbal human sounds.In this work, we aim to overcome the above shortcoming and propose a novelfoundation model, termed voc2vec, specifically designed for non-verbal humandata leveraging exclusively open-source non-verbal audio datasets. We employ acollection of 10 datasets covering around 125 hours of non-verbal audio.Experimental results prove that voc2vec is effective in non-verbal vocalizationclassification, and it outperforms conventional speech and audio foundationmodels. Moreover, voc2vec consistently outperforms strong baselines, namelyOpenSmile and emotion2vec, on six different benchmark datasets. To the best ofthe authors' knowledge, voc2vec is the first universal representation model forvocalization tasks.</description>
      <author>example@mail.com (Alkis Koudounas, Moreno La Quatra, Marco Sabato Siniscalchi, Elena Baralis)</author>
      <guid isPermaLink="false">2502.16298v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Discovery and Deployment of Emergent Robot Swarm Behaviors via Representation Learning and Real2Sim2Real Transfer</title>
      <link>http://arxiv.org/abs/2502.15937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures. To be included in Proc. of the 24th  International Conference on Autonomous Agents and Multiagent Systems (AAMAS  2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于自监督表示学习的Real2Sim2Real行为发现方法，该方法可以在仿真环境中自动发现可能的行为模式，并将这些行为直接部署到真实机器人集群中。&lt;h4&gt;背景&lt;/h4&gt;之前的方法依赖于人工反馈或手工设计的行为度量来表征和进化行为，仅限于在模拟环境中发现行为，未考虑将这些新行为部署到实际的机器人集群上。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以自动探索有限能力机器人群体潜在可出现行为集合的方法，并能够直接应用这些行为到真实的机器人集群中。&lt;h4&gt;方法&lt;/h4&gt;结合表示学习和新颖性搜索，在模拟环境中发现可能的行为，同时通过引入群集sim2real迁移的最新工作缩小现实差距，使得所有在仿真中发现的行为可以直接部署到真实机器人上。&lt;h4&gt;主要发现&lt;/h4&gt;提出的自监督表示学习方法优于手工设计的度量标准，能够更准确地表征潜在行为空间，并且可以通过轻量化模拟器实现从模拟直接转移到实际应用。&lt;h4&gt;结论&lt;/h4&gt;通过展示方法的有效性及其实现的可行性，表明这种方法为自动探索机器人集群中可能出现的行为提供了新途径，并可以无缝地部署到真实环境中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Given a swarm of limited-capability robots, we seek to automatically discoverthe set of possible emergent behaviors. Prior approaches to behavior discoveryrely on human feedback or hand-crafted behavior metrics to represent and evolvebehaviors and only discover behaviors in simulation, without testing orconsidering the deployment of these new behaviors on real robot swarms. In thiswork, we present Real2Sim2Real Behavior Discovery via Self-SupervisedRepresentation Learning, which combines representation learning and noveltysearch to discover possible emergent behaviors automatically in simulation andenable direct controller transfer to real robots. First, we evaluate our methodin simulation and show that our proposed self-supervised representationlearning approach outperforms previous hand-crafted metrics by more accuratelyrepresenting the space of possible emergent behaviors. Then, we address thereality gap by incorporating recent work in sim2real transfer for swarms intoour lightweight simulator design, enabling direct robot deployment of allbehaviors discovered in simulation on an open-source and low-cost robotplatform.</description>
      <author>example@mail.com (Connor Mattson, Varun Raveendra, Ricardo Vega, Cameron Nowzari, Daniel S. Drew, Daniel S. Brown)</author>
      <guid isPermaLink="false">2502.15937v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Para-Lane: Multi-Lane Dataset Registering Parallel Scans for Benchmarking Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2502.15635v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by International Conference on 3D Vision (3DV) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;为了评估端到端的自主驾驶系统，需要一个基于新颖视图合成技术（NVS）的模拟环境来生成逼真的图像和点云。本文介绍了一个新的多车道数据集和基准测试，用于评价现有的NeRF和3DGS方法在真实世界场景中的表现。&lt;h4&gt;背景&lt;/h4&gt;当前的基于场景的NVS数据集中存在缺少与实际捕捉到的真实性和细节的问题，特别是针对跨车道的评估场景仍然不足。&lt;h4&gt;目的&lt;/h4&gt;为了进一步评估现有基于NeRF和3DGS的方法，在逼真的多传感器环境中建立一个可用于自主驾驶系统性能测试的数据集。&lt;h4&gt;方法&lt;/h4&gt;开发了一个包含25组关联序列的多车道数据集，这些序列由实际世界扫描生成，包括16,000张前视图图像、64,000张环视图像和16,000帧LiDAR点云。所有帧都进行了标注以区分移动物体与静止元素。&lt;h4&gt;主要发现&lt;/h4&gt;通过该数据集可以对现有方法在不同车道和距离下的测试场景中进行性能评估，并解决了多传感器姿态求解及质量评价的问题，从而实现了跨模态数据的对齐。&lt;h4&gt;结论&lt;/h4&gt;计划持续添加新的序列以测试现有方法在各种情况下的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;为了评估端到端自主驾驶系统的性能，基于新颖视图合成技术（NVS）创建一个模拟环境是必要的，它可以从先前记录的序列中生成逼真的图像和点云，特别是在跨车道场景下。因此，开发一个多车道数据集和基准测试是必不可少的。尽管最近的一些基于合成场景的NVS数据集已经为跨车道基准测试做好了准备，但它们仍然缺乏真实捕捉到的图像和点云的真实感。为了进一步评估现有的基于NeRF和3DGS方法的性能，我们提出了第一个注册平行扫描的多车道数据集，特别针对新型驾驶视图合成的数据集，该数据集由实际世界扫描衍生而来，包含25组相关序列，包括16,000张前视图像、64,000张环绕视图图像和16,000帧LiDAR帧。所有帧都进行了标注以区分移动对象与静态元素。利用这个数据集，在不同的车道和距离下对现有方法在各种测试场景中的性能进行评估。此外，我们的方法提供了求解并评估多模态数据对齐的多传感器姿态质量的问题解决方案，以便策划这样的数据集。我们计划继续添加新的序列以测试现有方法在不同情况下的泛化能力。该数据集已公开发布于项目页面：https://nizqleo.github.io/paralane-dataset/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To evaluate end-to-end autonomous driving systems, a simulation environmentbased on Novel View Synthesis (NVS) techniques is essential, which synthesizesphoto-realistic images and point clouds from previously recorded sequencesunder new vehicle poses, particularly in cross-lane scenarios. Therefore, thedevelopment of a multi-lane dataset and benchmark is necessary. While recentsynthetic scene-based NVS datasets have been prepared for cross-lanebenchmarking, they still lack the realism of captured images and point clouds.To further assess the performance of existing methods based on NeRF and 3DGS,we present the first multi-lane dataset registering parallel scans specificallyfor novel driving view synthesis dataset derived from real-world scans,comprising 25 groups of associated sequences, including 16,000 front-viewimages, 64,000 surround-view images, and 16,000 LiDAR frames. All frames arelabeled to differentiate moving objects from static elements. Using thisdataset, we evaluate the performance of existing approaches in various testingscenarios at different lanes and distances. Additionally, our method providesthe solution for solving and assessing the quality of multi-sensor poses formulti-modal data alignment for curating such a dataset in real-world. We planto continually add new sequences to test the generalization of existing methodsacross different scenarios. The dataset is released publicly at the projectpage: https://nizqleo.github.io/paralane-dataset/.</description>
      <author>example@mail.com (Ziqian Ni, Sicong Du, Zhenghua Hou, Chenming Wu, Sheng Yang)</author>
      <guid isPermaLink="false">2502.15635v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Model for Lossless Image Compression with Visual Prompts</title>
      <link>http://arxiv.org/abs/2502.16163v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用大规模语言模型（LLM）进行无损图像压缩的新范式，通过将视觉提示与LLM结合来改进熵编码。&lt;h4&gt;背景&lt;/h4&gt;近年来深度学习在无损图像压缩方面取得了显著进展。随着大型语言模型的出现，初步尝试开始探索如何利用预训练模型中的丰富先验知识来增强无损图像压缩性能，特别是在改进熵模型方面的应用。&lt;h4&gt;目的&lt;/h4&gt;为了克服将LLM中嵌入的文字先验信息与无损图像压缩技术有效结合的问题，并挖掘出该方法的潜力，本文提出了一种新的方案。&lt;h4&gt;方法&lt;/h4&gt;首先生成输入图像的一个有损重建版本作为视觉提示，从中提取特征以作为LLM的视觉嵌入。然后将原始图像和这个有损重建版本之间的残差与这些视觉嵌入一起传递给LLM，使LLM能够充当熵模型来预测该残差的概率分布。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在多个基准数据集上，本文的方法在无损压缩性能方面达到了当前的最佳水平，并超越了传统的和基于学习的无损图像编码方法。此外，所提出的技术还能方便地扩展到其他领域中的图像（如医学影像和屏幕内容），并显示出出色的效果。&lt;h4&gt;结论&lt;/h4&gt;结果表明LLM对于无损图像压缩具有巨大潜力，并有望激励相关领域的进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;最近在深度学习上的进步极大地推动了无损图像压缩技术的发展。随着大规模语言模型的出现，初步尝试开始利用这些预训练模型中的丰富先验知识来改进熵编码，从而增强无损图像压缩性能。然而，在将文本型先前知识与图像无损压缩之间建立联系仍面临挑战。为了应对这一难题并发掘LLM的应用潜能，本文介绍了一种新颖的方法，即通过生成输入图像的有损重建版本作为视觉提示，并从这些提示中提取特征供大型语言模型使用，以此来改进熵编码的过程。研究发现该方法在多个基准数据集上表现出了卓越的压缩效果，超越了传统和基于学习的无损图像编码器。此外，这种方法还可以方便地应用于其他领域的图像（如医学影像和屏幕内容），并取得出色的表现。这些结果凸显了LLM对于无损图像压缩技术的巨大潜力，并有可能激发更多相关方向的研究工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in deep learning have driven significant progress inlossless image compression. With the emergence of Large Language Models (LLMs),preliminary attempts have been made to leverage the extensive prior knowledgeembedded in these pretrained models to enhance lossless image compression,particularly by improving the entropy model. However, a significant challengeremains in bridging the gap between the textual prior knowledge within LLMs andlossless image compression. To tackle this challenge and unlock the potentialof LLMs, this paper introduces a novel paradigm for lossless image compressionthat incorporates LLMs with visual prompts. Specifically, we first generate alossy reconstruction of the input image as visual prompts, from which weextract features to serve as visual embeddings for the LLM. The residualbetween the original image and the lossy reconstruction is then fed into theLLM along with these visual embeddings, enabling the LLM to function as anentropy model to predict the probability distribution of the residual.Extensive experiments on multiple benchmark datasets demonstrate our methodachieves state-of-the-art compression performance, surpassing both traditionaland learning-based lossless image codecs. Furthermore, our approach can beeasily extended to images from other domains, such as medical and screencontent images, achieving impressive performance. These results highlight thepotential of LLMs for lossless image compression and may inspire furtherresearch in related directions.</description>
      <author>example@mail.com (Junhao Du, Chuqin Zhou, Ning Cao, Gang Chen, Yunuo Chen, Zhengxue Cheng, Li Song, Guo Lu, Wenjun Zhang)</author>
      <guid isPermaLink="false">2502.16163v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MedForge: Building Medical Foundation Models Like Open Source Software Development</title>
      <link>http://arxiv.org/abs/2502.16055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了Medical Foundation Models Merging (MedForge)框架，用于促进社区驱动的医疗基础模型开发。&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）在医疗领域取得了显著进展。然而，在医疗系统中数据孤岛问题和隐私保护仍然是阻碍安全医学数据共享和跨机构合作的主要障碍。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战并收集和整理可扩展的临床数据集，用于训练强大的基础模型，提出了MedForge框架。&lt;h4&gt;方法&lt;/h4&gt;MedForge通过灵活地合并特定任务的低秩适应（LoRA）模块来提供一种自下而上的模型构建机制。该方法可以同时调整下游任务且保留原始模型参数，并利用异步LoRA模块集成方案逐步增强复合模型在各种临床任务中的综合性能。&lt;h4&gt;主要发现&lt;/h4&gt;MedForge框架展示了其在多个临床数据集（如乳腺癌、肺癌和结肠癌）上的强大性能，这些数据集来自不同机构。研究表明，协作基础模型可以有效并一致地推进多中心临床合作。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了跨医疗机构协同开发医疗基础模型的重要性，并公开发布了相关代码以便其他研究人员使用。&lt;h4&gt;翻译&lt;/h4&gt;在该研究中提出了一种名为Medical Foundation Models Merging (MedForge)的框架，该框架旨在通过灵活合并特定任务的低秩适应（LoRA）模块来促进社区驱动的医学基础模型的发展。此方法能够避免原始患者数据的信息泄露，并解决跨临床机构同步开发模型的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundational models (FMs) have made significant strides in the healthcaredomain. Yet the data silo challenge and privacy concern remain in healthcaresystems, hindering safe medical data sharing and collaborative modeldevelopment among institutions. The collection and curation of scalableclinical datasets increasingly become the bottleneck for training strong FMs.In this study, we propose Medical Foundation Models Merging (MedForge), acooperative framework enabling a community-driven medical foundation modeldevelopment, meanwhile preventing the information leakage of raw patient dataand mitigating synchronization model development issues across clinicalinstitutions. MedForge offers a bottom-up model construction mechanism byflexibly merging task-specific Low-Rank Adaptation (LoRA) modules, which canadapt to downstream tasks while retaining original model parameters. Through anasynchronous LoRA module integration scheme, the resulting composite model canprogressively enhance its comprehensive performance on various clinical tasks.MedForge shows strong performance on multiple clinical datasets (e.g., breastcancer, lung cancer, and colon cancer) collected from different institutions.Our major findings highlight the value of collaborative foundation models inadvancing multi-center clinical collaboration effectively and cohesively. Ourcode is publicly available at https://github.com/TanZheling/MedForge.</description>
      <author>example@mail.com (Zheling Tan, Kexin Ding, Jin Gao, Mu Zhou, Dimitris Metaxas, Shaoting Zhang, Dequan Wang)</author>
      <guid isPermaLink="false">2502.16055v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>DiffCheck: a Scan-CAD Evaluation Tool for Digital Manufacturing and Assembly Processes in Timber Construction</title>
      <link>http://arxiv.org/abs/2502.15864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Andrea Settimi, Damien Gilliard and Eleni Skevaki contributed equally  to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一款名为diffCheck的软件，该软件使用先进的点云分析技术来比较木质结构的扫描结果与其CAD模型之间的差异。&lt;h4&gt;背景&lt;/h4&gt;在数字木材建造中，由于3D传感器、摄影测量和用户友好的CAD工具易于获得，因此广泛采用扫描技术和点云数据。然而，这些工具通常不用于精度检查，因为标准机械可以提供更高的精度。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为diffCheck的软件来填补这一空白，以便于实验研究和原型制作中评估精确度和准确性。&lt;h4&gt;方法&lt;/h4&gt;diffCheck是一个用C++/Python编写的软件，集成到了Grasshopper平台。它利用先进的点云分析技术进行精度检查，并且可以与各种木材元件和数字制造方法（如机器人装配、AR辅助木工以及数控机床）兼容。&lt;h4&gt;主要发现&lt;/h4&gt;通过测试不同的木材元素和数字制造方法，diffCheck旨在建立一个用户友好的基准框架，用于评估使用木材组件的数字制造系统。此外，该软件及其源代码可以以开放许可的方式与数字化制造社区分享。&lt;h4&gt;结论&lt;/h4&gt;diffCheck具有在其他材料中找到应用潜力的能力，并且其设计是为了促进更高效的精度和准确性检查。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在数字木材建造中，由于3D传感器、摄影测量和用户友好的CAD工具易于获得，因此广泛采用扫描技术和点云数据。虽然通常不用于准确性的校验，因为标准机械可以提供更高的精确度，但是实验研究和原型制作可以从精度和准确性评估工具中获益。我们介绍了一款名为diffCheck的软件，它使用先进的点云分析技术比较加工木材结构的扫描结果与相应的CAD模型之间的差异，并且能够帮助识别出不一致的地方。经过各种木材元件及如机器人装配、AR辅助木工以及数控机床等数字制造方法的测试后，diffCheck旨在为采用木材组件的数字制造系统建立一个用户友好的基准框架，同时具有在其他材料中找到应用潜力的能力。其源代码和分析数据以开放许可的方式与数字化制造社区共享。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In digital timber construction, scanning technologies and point cloud dataare widely used due to the accessibility of affordable 3D sensors,photogrammetry, and user-friendly CAD tools. While typically not employed foraccuracy checks in timber fabrication due to the precision of standardmachinery, experimental research and prototyping with joinery and assembly canbenefit from precision and accuracy evaluation tools.  We introduce diffCheck, a C++/Python software integrated into Grasshopper toaddress this need. It uses advanced point cloud analysis to compare scans offabricated timber structures with their respective CAD models, helping toidentify discrepancies. Tested on various timber elements and digitalfabrication methods like robotic assembly, AR-assisted woodworking, and CNCmachining, diffCheck aims to establish a user-friendly benchmark framework fordigital fabrication systems using timber components, with the potential to findapplications in other materials. Its source code and the analyzed data areopenly shared with the digital fabrication community under a permissivelicense.</description>
      <author>example@mail.com (Andrea Settimi, Damien Gilliard, Eleni Skevaki, Marirena Kladeftira, Julien Gamerro, Stefana Parascho, Yves Weinand)</author>
      <guid isPermaLink="false">2502.15864v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>AutoMedPrompt: A New Framework for Optimizing LLM Medical Prompts Using Textual Gradients</title>
      <link>http://arxiv.org/abs/2502.15944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为AutoMedPrompt的技术，利用文本梯度优化系统提示来提高通用基础模型在医学领域的问题解答能力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）已在医疗和知识领域展示了越来越复杂的性能。传统的专家化方法需要对大量数据集进行广泛的微调和训练。然而，最近的提示工程方法展示出不通过微调也能提升一般基础模型的能力，但这些方法在特定子领域的适用性有限。&lt;h4&gt;目的&lt;/h4&gt;探索使用文本梯度来优化系统提示，从而激发医学相关推理，并评估这种方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;利用TextGrad的自动文本差异化技术改进通用基础LLM的表现。测试了开源大型语言模型Llama 3，在MedQA、PubMedQA和特定肾脏病亚专业的NephSAP等多个问答基准上进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;与先前的方法相比，使用文本梯度进行提示在开源LLMs上表现更优，并且超越了专有模型如GPT-4、Claude 3 Opus和Med-PaLM 2。AutoMedPrompt在PubMedQA上的准确率为82.6%，超过了此前所有方法的表现。&lt;h4&gt;结论&lt;/h4&gt;文本梯度引导的提示技术展示了其在医学领域问答任务中的显著优势，有望成为未来模型改进的一个方向。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型（LLMs）已经在医疗和其他知识领域展示出越来越高级别的性能。传统的创建专业LLM的方法需要对大量数据集进行广泛的微调和训练。然而，最近的提示工程方法展示了无需微调即可提升通用基础模型的能力的潜力。但是，例如链式思考（CoT）的提示方法可能不适用于所有子专科，并且k-shot方法可能会在上下文中引入无关词汇。我们提出了AutoMedPrompt，该技术探索了利用文本梯度通过优化系统提示来激发医学相关推理的可能性。AutoMedPrompt使用TextGrad的基于文本的自动微分技术提高了一般基础LLMs的能力。我们在开源LLM Llama 3上评估了AutoMedPrompt，在包括MedQA、PubMedQA和特定肾脏病亚专业的NephSAP等多个问答基准中进行了测试。我们的结果表明，使用文本梯度进行提示超越了以往方法在开源LLMs上的表现，并且超过了GPT-4、Claude 3 Opus以及Med-PaLM 2等专有模型的表现。AutoMedPrompt在PubMedQA上达到了新的最先进（SOTA）性能水平，准确率为82.6%，并且在开源模型中为MedQA（77.7%）和NephSAP（63.8%）的问答任务表现也优于先前的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have demonstrated increasingly sophisticatedperformance in medical and other fields of knowledge. Traditional methods ofcreating specialist LLMs require extensive fine-tuning and training of modelson large datasets. Recently, prompt engineering, instead of fine-tuning, hasshown potential to boost the performance of general foundation models. However,prompting methods such as chain-of-thought (CoT) may not be suitable for allsubspecialty, and k-shot approaches may introduce irrelevant tokens into thecontext space. We present AutoMedPrompt, which explores the use of textualgradients to elicit medically relevant reasoning through system promptoptimization. AutoMedPrompt leverages TextGrad's automatic differentiation viatext to improve the ability of general foundation LLMs. We evaluatedAutoMedPrompt on Llama 3, an open-source LLM, using several QA benchmarks,including MedQA, PubMedQA, and the nephrology subspecialty-specific NephSAP.Our results show that prompting with textual gradients outperforms previousmethods on open-source LLMs and surpasses proprietary models such as GPT-4,Claude 3 Opus, and Med-PaLM 2. AutoMedPrompt sets a new state-of-the-art (SOTA)performance on PubMedQA with an accuracy of 82.6$\%$, while also outperformingprevious prompting strategies on open-sourced models for MedQA (77.7$\%$) andNephSAP (63.8$\%$).</description>
      <author>example@mail.com (Sean Wu, Michael Koo, Fabien Scalzo, Ira Kurtz)</author>
      <guid isPermaLink="false">2502.15944v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors</title>
      <link>http://arxiv.org/abs/2502.14627v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多语言音频文本检索（ML-ATR）方案，通过理论分析和实验验证了现有方法在跨语种实例相似性匹配中的不一致性问题，并提出了改进策略。&lt;h4&gt;背景&lt;/h4&gt;多语言音频文本检索是一个具有挑战性的任务，目标是从数据库中检索音频片段或多种语言的文本。当前的方法存在跨语种实例相似性匹配的不一致问题。&lt;h4&gt;目的&lt;/h4&gt;分析和解决现有ML-ATR方案在不同语言之间匹配上的不一致性，并提出改进措施来提高召回率和一致性。&lt;h4&gt;方法&lt;/h4&gt;通过1-to-k对比学习和音频-英语共锚对比学习，设计了一种新的多语言音频文本检索框架以减少数据分布误差对结果的影响。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，跨语种实例相似性匹配的不一致问题是由于随机采样语言造成的数据分布错误所引起的。新方法在召回率和一致性指标上取得了主流八种语言（包括英语）的最佳性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的学习策略来解决多语言音频文本检索中的数据分布问题，该研究为提高跨语言信息检索的精度提供了理论依据和技术支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已经以中文形式给出，无需再次翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/atri-acl/atri-acl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims toretrieve audio clips or multilingual texts from databases. However, existingML-ATR schemes suffer from inconsistencies for instance similarity matchingacross languages. We theoretically analyze the inconsistency in terms of bothmultilingual modal alignment direction error and weight error, and propose thetheoretical weight error upper bound for quantifying the inconsistency. Basedon the analysis of the weight error upper bound, we find that the inconsistencyproblem stems from the data distribution error caused by random sampling oflanguages. We propose a consistent ML-ATR scheme using 1-to-k contrastivelearning and audio-English co-anchor contrastive learning, aiming to mitigatethe negative impact of data distribution error on recall and consistency inML-ATR. Experimental results on the translated AudioCaps and Clotho datasetsshow that our scheme achieves state-of-the-art performance on recall andconsistency metrics for eight mainstream languages, including English. Our codewill be available at https://github.com/ATRI-ACL/ATRI-ACL.</description>
      <author>example@mail.com (Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou)</author>
      <guid isPermaLink="false">2502.14627v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Directional Gradient Projection for Robust Fine-Tuning of Foundation Models</title>
      <link>http://arxiv.org/abs/2502.15895v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;鲁棒微调的目标是将大规模基础模型适应到下游任务，同时保持其对分布变化的稳健性。现有方法主要集中在基于微调权重和预训练权重之间幅度来约束和投影当前模型向预训练初始化。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的分层可训练的方法——方向梯度投影（DiGraP），该方法利用梯度的方向信息，以弥合正则化与多目标优化之间的差距，并将其推广到多模态评估设置中鲁棒微调的场景。&lt;h4&gt;方法&lt;/h4&gt;介绍了一种称为Directional Gradient Projection (DiGraP)的新技术，它通过结合从梯度方向获取的信息来连接正则化和多目标优化。该研究不仅在图像分类上展示了其效果，还将其扩展到视觉问答（VQA）等多模态评估设置。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，与现有基准方法相比，DiGraP 在图像分类及具备判别性和生成性骨干的 VQA 任务中均有更好的性能表现，尤其是在分布变化上具有较高的稳健性。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法有效地解决了当前鲁棒微调方法中存在的问题，并证明了其在多模态评估设置中的应用潜力。DiGraP 方法展示了其对现有基准方法的优势，在多种任务和设置中均显示出更好的性能，包括改进的分布内泛化能力和分布外稳健性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust fine-tuning aims to adapt large foundation models to downstream taskswhile preserving their robustness to distribution shifts. Existing methodsprimarily focus on constraining and projecting current model towards thepre-trained initialization based on the magnitudes between fine-tuned andpre-trained weights, which often require extensive hyper-parameter tuning andcan sometimes result in underfitting. In this work, we propose DirectionalGradient Projection (DiGraP), a novel layer-wise trainable method thatincorporates directional information from gradients to bridge regularizationand multi-objective optimization. Besides demonstrating our method on imageclassification, as another contribution we generalize this area to themulti-modal evaluation settings for robust fine-tuning. Specifically, we firstbridge the uni-modal and multi-modal gap by performing analysis on ImageClassification reformulated Visual Question Answering (VQA) benchmarks andfurther categorize ten out-of-distribution (OOD) VQA datasets by distributionshift types and degree (i.e. near versus far OOD). Experimental results showthat DiGraP consistently outperforms existing baselines across ImageClassfication and VQA tasks with discriminative and generative backbones,improving both in-distribution (ID) generalization and OOD robustness.</description>
      <author>example@mail.com (Chengyue Huang, Junjiao Tian, Brisa Maneechotesuwan, Shivang Chopra, Zsolt Kira)</author>
      <guid isPermaLink="false">2502.15895v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Token Adaptation via Side Graph Convolution for Efficient Fine-tuning of 3D Point Cloud Transformers</title>
      <link>http://arxiv.org/abs/2502.14142v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个名为Side Token Adaptation on a neighborhood Graph (STAG)的新PEFT算法，用于提高3D点云变换器的时序和空间效率。&lt;h4&gt;背景&lt;/h4&gt;参数高效的微调（PEFT）技术已成为分析3D点云的一种有前景的方法。然而现有的PEFT方法在减少可调节参数的同时，往往面临高计算成本的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的名为STAG的技术，以同时提高时序和空间效率。&lt;h4&gt;方法&lt;/h4&gt;STAG采用图卷积侧面网络，在冻结的骨干Transformer并行操作中适应令牌以便进行下游任务。通过高效的图卷积、参数共享以及减少梯度计算来显著降低微调的时间和空间成本。&lt;h4&gt;主要发现&lt;/h4&gt;提出的STAG算法能够保持与其他现有方法相当的分类准确性，同时将可调节参数减少到仅0.43M，并且在微调时大大减少了时间和内存消耗。此外，还提出了一个新的基准测试Point Cloud Classification 13 (PCC13)。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的实验验证了STAG的有效性，表明它能够显著降低计算成本并保持较高的分类精度。&lt;h4&gt;翻译&lt;/h4&gt;参数高效的微调（PEFT）技术在3D点云分析中崭露头角。尽管现有的PEFT方法试图减少可调节参数的数量，但在细调过程中经常遭受高时间和空间计算成本的问题。本文提出了一种名为Side Token Adaptation on a neighborhood Graph (STAG)的新型PEFT算法以实现卓越的时间和空间效率。STAG采用图卷积侧网络，并行于冻结的骨干Transformer进行操作，以将令牌适应到下游任务中。通过高效的图卷积、参数共享以及减少梯度计算，STAG显著降低了微调过程中的时间和空间成本。此外还介绍了一个新的基准测试Point Cloud Classification 13 (PCC13)，该基准集包括多种公开的3D点云数据集以促进全面评估。使用多个预训练模型和PCC13进行的广泛实验显示了STAG的有效性，特别是保持分类精度与现有方法相当的同时将可调节参数减少到仅0.43M，并且在计算时间和内存消耗方面取得显著降低。代码和基准将在https://github.com/takahikof/STAG提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/takahikof/stag&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient fine-tuning (PEFT) of pre-trained 3D point cloudTransformers has emerged as a promising technique for 3D point cloud analysis.While existing PEFT methods attempt to minimize the number of tunableparameters, they often suffer from high temporal and spatial computationalcosts during fine-tuning. This paper proposes a novel PEFT algorithm calledSide Token Adaptation on a neighborhood Graph (STAG) to achieve superiortemporal and spatial efficiency. STAG employs a graph convolutional sidenetwork operating in parallel with a frozen backbone Transformer to adapttokens to downstream tasks. Through efficient graph convolution, parametersharing, and reduced gradient computation, STAG significantly reduces bothtemporal and spatial costs for fine-tuning. We also present Point CloudClassification 13 (PCC13), a new benchmark comprising diverse publiclyavailable 3D point cloud datasets to facilitate comprehensive evaluation.Extensive experiments using multiple pre-trained models and PCC13 demonstratesthe effectiveness of STAG. Specifically, STAG maintains classification accuracycomparable to existing methods while reducing tunable parameters to only 0.43Mand achieving significant reductions in both computation time and memoryconsumption for fine-tuning. Code and benchmark will be available at:https://github.com/takahikof/STAG.</description>
      <author>example@mail.com (Takahiko Furuya)</author>
      <guid isPermaLink="false">2502.14142v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>UniGenCoder: Merging Seq2Seq and Seq2Tree Paradigms for Unified Code Generation</title>
      <link>http://arxiv.org/abs/2502.12490v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to 47th International Conference on Software Engineering  (ICSE 2025), NIER track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;基于深度学习的代码生成已彻底改变了当今开发人员编写程序的方式。&lt;h4&gt;背景&lt;/h4&gt;现有的代码生成方法要么集中在序列到序列（Sequence-to-Sequence）范式，即以标记序列的形式生成目标代码；要么是序列到树（Sequence-to-Tree）范式，即输出作为动作序列的目标代码。这两个范式的结合尚未被探索过。&lt;h4&gt;目的&lt;/h4&gt;通过比较这两种范式下产生的代码，作者发现了整合两者的潜在价值，并提出了一种名为UniGenCoder的新模型来解决与代码生成相关的任务。&lt;h4&gt;方法&lt;/h4&gt;UniGenCoder包含一个共享编码器、一个带有最小额外参数集的共享解码器以及一个选择器，该选择器动态地为每个实例选择最优范式。在模型训练过程中，作者首先实施多任务学习和蒸馏策略来促进两个范式的知识转移，并利用对比学习方法训练选择器。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果证明了所提出模型在文本到代码以及代码到代码生成任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的UniGenCoder模型展示了将序列到序列（Sequence-to-Sequence）和序列到树（Sequence-to-Tree）范式结合的潜力，并通过实验证明其优越性。&lt;h4&gt;翻译&lt;/h4&gt;基于深度学习的代码生成已彻底改变了当今开发人员编写程序的方式。现有方法要么集中在序列到序列或序列到树的方法上，这两种方式都存在一定的局限性。为了克服这些限制，作者提出了一种新的模型UniGenCoder，并证明了它在文本到代码和代码到代码任务上的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based code generation has completely transformed the waydevelopers write programs today. Existing approaches to code generation havefocused either on the Sequence-to-Sequence paradigm, which generates targetcode as a sequence of tokens, or the Sequence-to-Tree paradigm, which outputscode as a sequence of actions. While these two paradigms are intuitivelycomplementary, their combination has not been previously explored. By comparingthe code generated under these two paradigms, we find that integrating themholds significant potential. In this paper, we propose UniGenCoder forcode-related generation tasks, which consists of a shared encoder, a shareddecoder with a minimal set of additional parameters to unify two paradigms, anda selector that dynamically chooses optimal paradigm for each instance. Also,during the model training, we first perform the multi-task learning anddistillation strategies to facilitate knowledge transfer between two paradigms,and then leverage contrastive learning to train the selector. Experimentalresults on the text-to-code and code-to-code generation tasks demonstrate theeffectiveness of our proposed model. We release our code athttps://github.com/DeepLearnXMU/UniGenCoder.</description>
      <author>example@mail.com (Liangying Shao, Yanfu Yan, Denys Poshyvanyk, Jinsong Su)</author>
      <guid isPermaLink="false">2502.12490v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Breast Lump Detection and Localization with a Tactile Glove Using Deep Learning</title>
      <link>http://arxiv.org/abs/2502.15767v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发了一种基于柔性织物的可穿戴触觉手套，用于通过深度学习技术检测模拟乳房模型内的肿块。&lt;h4&gt;背景&lt;/h4&gt;乳腺癌是女性死亡的主要原因之一。通过触摸检查乳房以早期发现肿瘤至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计一种利用深度学习方法来定位乳房内肿块的可穿戴触觉手套。&lt;h4&gt;方法&lt;/h4&gt;该研究使用了定制的硅胶乳房原型（SBPs）以及球形硅胶肿瘤，其中包含不同直径大小的模拟肿块。采用InceptionTime深度学习架构结合迁移学习技术，并收集了10名普通参与者和一位肿瘤-乳腺科医生的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;深度学习模型在判断肿块存在、大小及位置上的准确率分别为82.22%，67.08%和62.63%；同时，该模型对未见过的有经验用户数据的表现也非常好，准确率达到95.01%，88.54%以及82.98%。&lt;h4&gt;结论&lt;/h4&gt;这项技术可以帮助没有经验的人或医疗保健提供者进行更频繁的常规检查，有助于早期发现乳腺癌。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Breast cancer is the leading cause of mortality among women. Inspection ofbreasts by palpation is the key to early detection. We aim to create a wearabletactile glove that could localize the lump in breasts using deep learning (DL).In this work, we present our flexible fabric-based and soft wearable tactileglove for detecting the lumps within custom-made silicone breast prototypes(SBPs). SBPs are made of soft silicone that imitates the human skin and theinner part of the breast. Ball-shaped silicone tumors of 1.5-, 1.75- and 2.0-cmdiameters are embedded inside to create another set with lumps. Our approach isbased on the InceptionTime DL architecture with transfer learning betweenexperienced and non-experienced users. We collected a dataset from 10 naiveparticipants and one oncologist-mammologist palpating SBPs. We demonstratedthat the DL model can classify lump presence, size and location with anaccuracy of 82.22%, 67.08% and 62.63%, respectively. In addition, we showedthat the model adapted to unseen experienced users with an accuracy of 95.01%,88.54% and 82.98% for lump presence, size and location classification,respectively. This technology can assist inexperienced users or healthcareproviders, thus facilitating more frequent routine checks.</description>
      <author>example@mail.com (Togzhan Syrymova, Amir Yelenov, Karina Burunchina, Nazgul Abulkhanova, Huseyin Atakan Varol, Juan Antonio Corrales Ramon, Zhanat Kappassov)</author>
      <guid isPermaLink="false">2502.15767v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>V-HOP: Visuo-Haptic 6D Object Pose Tracking</title>
      <link>http://arxiv.org/abs/2502.17434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个结合视觉和触觉反馈的新型统一触觉表示法，旨在提高物体姿态估计在现实世界中的性能。&lt;h4&gt;背景&lt;/h4&gt;人类自然地通过视觉和触觉来感知物体，在抓取过程中丢失任何一种感觉都会影响性能。尽管早期研究尝试结合这两种感觉以改善对象姿态估计，但在实际应用中效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的统一化表示法以及基于该表示法的新型视觉-触觉变换器模型，旨在提高跨不同夹持器、传感器布局或仿真与现实环境下的物体跟踪性能。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新统一化的触觉表征来处理多个夹持器实现，并在此基础上提出一种新的视觉-触觉转换器基对象姿态追踪器，该追踪器能够无缝集成视觉和触觉输入。&lt;h4&gt;主要发现&lt;/h4&gt;在自定义数据集和Feelsight数据集中验证了该模型的有效性，证明其在挑战序列中表现出显著性能提升。特别是在面对新型夹持方式、物体及传感器类型时，本方法显示出卓越的泛化性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过现实世界实验表明，所提出的方法大大优于现有的视觉跟踪器，并且能够实现精确的操作任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans naturally integrate vision and haptics for robust object perceptionduring manipulation. The loss of either modality significantly degradesperformance. Inspired by this multisensory integration, prior object poseestimation research has attempted to combine visual and haptic/tactilefeedback. Although these works demonstrate improvements in controlledenvironments or synthetic datasets, they often underperform vision-onlyapproaches in real-world settings due to poor generalization across diversegrippers, sensor layouts, or sim-to-real environments. Furthermore, theytypically estimate the object pose for each frame independently, resulting inless coherent tracking over sequences in real-world deployments. To addressthese limitations, we introduce a novel unified haptic representation thateffectively handles multiple gripper embodiments. Building on thisrepresentation, we introduce a new visuo-haptic transformer-based object posetracker that seamlessly integrates visual and haptic input. We validate ourframework in our dataset and the Feelsight dataset, demonstrating significantperformance improvement on challenging sequences. Notably, our method achievessuperior generalization and robustness across novel embodiments, objects, andsensor types (both taxel-based and vision-based tactile sensors). In real-worldexperiments, we demonstrate that our approach outperforms state-of-the-artvisual trackers by a large margin. We further show that we can achieve precisemanipulation tasks by incorporating our real-time object tracking result intomotion plans, underscoring the advantages of visuo-haptic perception. Our modeland dataset will be made open source upon acceptance of the paper. Projectwebsite: https://lhy.xyz/projects/v-hop/</description>
      <author>example@mail.com (Hongyu Li, Mingxi Jia, Tuluhan Akbulut, Yu Xiang, George Konidaris, Srinath Sridhar)</author>
      <guid isPermaLink="false">2502.17434v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>FACTR: Force-Attending Curriculum Training for Contact-Rich Policy Learning</title>
      <link>http://arxiv.org/abs/2502.17432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Website at https://jasonjzliu.com/factr/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '提出了一个低成本且直观的双边遥操作系统，该系统将从动臂接收到的外部力传递给主动臂，促进复杂接触密集任务的数据收集，并引入了一个基于课程学习的策略学习方法FACTR。', '背景': '许多人类操作任务依赖于力反馈以可靠执行，但机器人领域中这种力量信息未得到充分利用，导致机器人行为局限于不需要精细力反馈的任务。', '目的': '开发一种能够利用外部力数据进行复杂接触密集型任务的有效遥操作系统和策略学习方法。', '方法': '首先设计了一种低成本且直观的双边遥操作平台，其次提出了一种名为FACTR的策略学习方法，该方法通过在训练过程中逐渐减少视觉输入的干扰来防止过度拟合，并引导策略关注力模态。', '主要发现': '该研究展示了通过充分使用力信息，与不采用课程学习的基线方法相比，在未见过物体上的泛化性能提高了43%。', '结论': '利用力反馈信息可以显著改善机器人在复杂任务中的表现和适应性。'}&lt;h4&gt;翻译&lt;/h4&gt;许多人类执行的任务，如拾取盒子或擀面团，都依赖于力反馈以确保可靠的完成。然而，在大多数机器人手臂中容易获得的这种力信息并未被广泛用于遥操作和策略学习。因此，机器人的行为通常仅限于不需要复杂力反馈的准静态动力学任务。在这篇论文中，我们首先提出了一种低成本且直观的双边遥操作系统，该系统将从动臂接收到的外部力量传递给主动臂，以促进复杂接触密集型任务的数据收集。接下来，我们介绍了FACTR策略学习方法，该方法在训练过程中采用一种课程，通过逐渐减少视觉输入的干扰来防止基于变压器的政策过度拟合，并引导策略正确关注力模态。我们证明了充分利用力量信息能够显著提高与基线相比，在未见过物体上的泛化性能达43%。视频结果和指南可在https://jasonjzliu.com/factr/获得&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many contact-rich tasks humans perform, such as box pickup or rolling dough,rely on force feedback for reliable execution. However, this force information,which is readily available in most robot arms, is not commonly used inteleoperation and policy learning. Consequently, robot behavior is oftenlimited to quasi-static kinematic tasks that do not require intricateforce-feedback. In this paper, we first present a low-cost, intuitive,bilateral teleoperation setup that relays external forces of the follower armback to the teacher arm, facilitating data collection for complex, contact-richtasks. We then introduce FACTR, a policy learning method that employs acurriculum which corrupts the visual input with decreasing intensity throughouttraining. The curriculum prevents our transformer-based policy fromover-fitting to the visual input and guides the policy to properly attend tothe force modality. We demonstrate that by fully utilizing the forceinformation, our method significantly improves generalization to unseen objectsby 43\% compared to baseline approaches without a curriculum. Video results andinstructions at https://jasonjzliu.com/factr/</description>
      <author>example@mail.com (Jason Jingzhou Liu, Yulong Li, Kenneth Shaw, Tony Tao, Ruslan Salakhutdinov, Deepak Pathak)</author>
      <guid isPermaLink="false">2502.17432v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Enriching Physical-Virtual Interaction in AR Gaming by Tracking Identical Real Objects</title>
      <link>http://arxiv.org/abs/2502.17399v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种新的增强现实(AR)技术，旨在改善同质物体在动态环境中的追踪问题，并通过农场到餐桌的游戏展示了该方法的有效性和实用性。&lt;h4&gt;背景&lt;/h4&gt;随着硬件和软件的进步，头戴式AR游戏变得越来越流行。然而，大多数AR游戏仍然依赖于预先扫描的静态场景，互动方式也有限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决AR游戏中相同物体追踪的问题，并丰富物理与虚拟环境之间的交互体验。&lt;h4&gt;方法&lt;/h4&gt;通过使用AR头盔的部分场景观察数据，结合整数规划解决问题标签分配问题来确定场景中对象的身份，并采用基于Voronoi图的剪枝方法提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法能够有效地追踪和区分相同的物体，展示了其在增强现实游戏、故事讲述和模拟机器人中的多功能性和实用性。&lt;h4&gt;结论&lt;/h4&gt;新方法证明了其实用性，在农场到餐桌AR游戏中表现良好，并且通过视频演示展现了其潜力。未来的研究可以探索更多实际应用场景来进一步验证该技术的有效性和适应性。&lt;h4&gt;翻译&lt;/h4&gt;增强现实(AR)游戏，尤其是专为头戴设备设计的游戏，随着硬件和软件的进步变得越来越普遍。然而，大多数AR游戏仍然依赖于预扫描或静态场景，并且交互机制通常限制在控制器或手部跟踪上。此外，在AR游戏中存在相同物体的挑战，传统的对象跟踪技术往往难以区分这些物体或者需要安装固定摄像机来追踪全球物体运动。为了解决这些问题，我们提出了一种新的方法，以解决AR场景中相同物体的跟踪问题，从而丰富物理虚拟交互体验。我们的方法利用了AR头盔捕捉的部分场景观察数据，并结合提供的视角和空间信息，通过整数规划解决方案中的标签分配问题确定场景内对象的身份。为了提高计算效率，我们在方法中引入了一种基于Voronoi图的剪枝技术。在农场到餐桌AR游戏中实现该方法展示了其满意的性能和稳健性。此外，我们通过增强现实故事讲述以及模拟游戏机器人的应用展现了该方法的多功能性和实用性。我们的视频演示可在以下链接查看：https://youtu.be/rPGkLYuKvCQ。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Augmented reality (AR) games, particularly those designed for headsets, havebecome increasingly prevalent with advancements in both hardware and software.However, the majority of AR games still rely on pre-scanned or static scenes,and interaction mechanisms are often limited to controllers or hand-tracking.Additionally, the presence of identical objects in AR games poses challengesfor conventional object tracking techniques, which often struggle todifferentiate between identical objects or necessitate the installation offixed cameras for global object movement tracking. In response to theselimitations, we present a novel approach to address the tracking of identicalobjects in an AR scene to enrich physical-virtual interaction. Our methodleverages partial scene observations captured by an AR headset, utilizing theperspective and spatial data provided by this technology. Object identitieswithin the scene are determined through the solution of a label assignmentproblem using integer programming. To enhance computational efficiency, weincorporate a Voronoi diagram-based pruning method into our approach. Ourimplementation of this approach in a farm-to-table AR game demonstrates itssatisfactory performance and robustness. Furthermore, we showcase theversatility and practicality of our method through applications in ARstorytelling and a simulated gaming robot. Our video demo is available at:https://youtu.be/rPGkLYuKvCQ.</description>
      <author>example@mail.com (Liuchuan Yu, Ching-I Huang, Hsueh-Cheng Wang, Lap-Fai Yu)</author>
      <guid isPermaLink="false">2502.17399v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Experimental validation of UAV search and detection system in real wilderness environment</title>
      <link>http://arxiv.org/abs/2502.17372v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本论文研究了在地中海喀斯特环境中利用自主无人机搜索人类的实验设计与实施，以提高搜救任务效率并增强参与人员的安全性。&lt;h4&gt;背景&lt;/h4&gt;搜索和救援任务需要可靠的搜索方法来定位幸存者，尤其是在挑战性强或难以到达的环境中。因此引入无人驾驶飞机可以在提高搜救任务效率的同时增加所有参与者在任务中的安全性。&lt;h4&gt;目的&lt;/h4&gt;设计并实验验证了一种基于热方程驱动区域覆盖（HEDAC）控制方法和计算机视觉对象检测框架的自主无人机搜索系统，并评估其性能是否与实际情况相符。&lt;h4&gt;方法&lt;/h4&gt;该研究通过概率搜索模型、运动控制系统以及计算机视觉目标检测组成的感知框架，使用热方程驱动区域覆盖（HEDAC）控制方法并根据已知的概率密度和检测函数来指导无人飞机。实验中使用了YOLO算法为基础的目标检测模型，并通过先前收集的正射影像数据库进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过对运动控制系统、目标检测以及搜索验证进行了全面分析，表明设计的目标检测模型与实际世界结果相一致，为无人机控制算法提供了强有力的证据支持。&lt;h4&gt;结论&lt;/h4&gt;研究证明了基于HEDAC方法和YOLO算法的自主无人飞机系统在实际搜救任务中的有效性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Search and rescue (SAR) missions require reliable search methods to locatesurvivors, especially in challenging or inaccessible environments. This is whyintroducing unmanned aerial vehicles (UAVs) can be of great help to enhance theefficiency of SAR missions while simultaneously increasing the safety ofeveryone involved in the mission. Motivated by this, we design and experimentwith autonomous UAV search for humans in a Mediterranean karst environment. TheUAVs are directed using Heat equation-driven area coverage (HEDAC) ergodiccontrol method according to known probability density and detection function.The implemented sensing framework consists of a probabilistic search model,motion control system, and computer vision object detection. It enablescalculation of the probability of the target being detected in the SAR mission,and this paper focuses on experimental validation of proposed probabilisticframework and UAV control. The uniform probability density to ensure the evenprobability of finding the targets in the desired search area is achieved byassigning suitably thought-out tasks to 78 volunteers. The detection model isbased on YOLO and trained with a previously collected ortho-photo imagedatabase. The experimental search is carefully planned and conducted, while asmany parameters as possible are recorded. The thorough analysis consists of themotion control system, object detection, and the search validation. Theassessment of the detection and search performance provides strong indicationthat the designed detection model in the UAV control algorithm is aligned withreal-world results.</description>
      <author>example@mail.com (Stella Dumenčić, Luka Lanča, Karlo Jakac, Stefan Ivić)</author>
      <guid isPermaLink="false">2502.17372v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>HATPIC: An Open-Source Single Axis Haptic Joystick for Robotic Development</title>
      <link>http://arxiv.org/abs/2502.17362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2 pages, 1 figure, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;人类通过触觉处理的信息远超视觉，因此远程操作中的触觉技术将在未来变得至关重要。当前的触觉设备要么难以获取，要么提供的力反馈质量较低，本文提出了一种单轴开源触觉设备设计方案来解决这些问题。&lt;h4&gt;背景&lt;/h4&gt;人的大部分信息处理是依靠触觉完成的，在极端条件下尤其如此，这意味着触觉对于远程操作的重要性将日益增加。&lt;h4&gt;目的&lt;/h4&gt;设计一种易于访问且具有高质量力反馈功能的开源单轴触觉装置以促进远程操作技术的发展和应用。&lt;h4&gt;方法&lt;/h4&gt;介绍了一种新的触觉设备，并展示了其与常见机器人工具集成的可能性。&lt;h4&gt;主要发现&lt;/h4&gt;新设计的手柄式控制器有可能加速各种机器人应用程序中触觉技术的应用，从而提高操作人员的反馈质量和控制水平。&lt;h4&gt;结论&lt;/h4&gt;通过引入这种低成本、高质量力反馈的触觉装置可以极大地促进远程操作技术的发展和广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为：人类处理的信息中有相当大的一部分是通过触觉完成的，而不是视觉。因此，在未来几年中，用于远程操控的触觉技术将变得至关重要，因为它为运营商提供了一种额外的感觉通道，这对于在极端条件下进行解释非常重要。然而，目前的触觉设备设置要么难以访问，要么提供的力反馈质量低劣。这项工作提出了一个旨在解决这些问题的单轴、开源的远程操作设计方案。首先介绍了该触觉装置，并展示了其与常见机器人工具集成的可能性。所提出的操纵杆有望加速各种机器人应用中触觉技术的发展和部署，从而增强操作人员的反馈和控制能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans process significantly more information through the sense of touch thanthrough vision. Consequently, haptics for telemanipulation is poised to becomeessential in the coming years, as it offers operators an additional sensorychannel crucial for interpretation in extreme conditions. However, currenthaptic device setups are either difficult to access or provide low-qualityforce feedback rendering. This work proposes the design of a single-axis,open-source setup for telemanipulation development, aimed at addressing theseissues. We first introduce the haptic device and demonstrate its integrationwith common robotic tools. The proposed joystick has the potential toaccelerate the development and deployment of haptic technology in a wide rangeof robotics applications, enhancing operator feedback and control.</description>
      <author>example@mail.com (Julien Mellet, Fabio Ruggiero, Vincenzo Lippiello)</author>
      <guid isPermaLink="false">2502.17362v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MegaLoc: One Retrieval to Place Them All</title>
      <link>http://arxiv.org/abs/2502.17237v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Tech Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MegaLoc的检索模型，该模型结合了多种现有技术，在多个计算机视觉任务中表现出色。&lt;h4&gt;背景&lt;/h4&gt;从给定查询获取相同位置的图像对于多项计算机视觉任务至关重要。然而，现有的解决方案仅针对单一任务设计，并且在遇到需求变化或未见数据时可能会失败。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在不同任务和环境要求下均能高效工作的通用检索模型。&lt;h4&gt;方法&lt;/h4&gt;结合了多种现有技术和训练技术来构建MegaLoc模型。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': 'MegaLoc在大量视觉位置识别数据集上达到最新技术水平，', '2': '在常见的地标检索数据集中表现出色，', '3': '在LaMAR数据集的图像定位任务中引入新方法后，设定了新的性能标准。'}&lt;h4&gt;结论&lt;/h4&gt;MegaLoc展示出了跨多个计算机视觉任务领域的强大适应性和通用性。&lt;h4&gt;翻译&lt;/h4&gt;从给定查询获取相同位置的图像是多项重要视觉任务（如视觉地方识别、地标检索、图像定位、三维重建和SLAM）的关键部分。然而，现有的解决方案通常只为特定任务设计，在遇到需求变化或未见数据时表现不佳。本文通过结合多种现有方法和技术训练出了一种名为MegaLoc的新模型，该模型在多个计算机视觉任务中均表现出色，并且其代码开源可获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieving images from the same location as a given query is an importantcomponent of multiple computer vision tasks, like Visual Place Recognition,Landmark Retrieval, Visual Localization, 3D reconstruction, and SLAM. However,existing solutions are built to specifically work for one of these tasks, andare known to fail when the requirements slightly change or when they meetout-of-distribution data. In this paper we combine a variety of existingmethods, training techniques, and datasets to train a retrieval model, calledMegaLoc, that is performant on multiple tasks. We find that MegaLoc (1)achieves state of the art on a large number of Visual Place Recognitiondatasets, (2) impressive results on common Landmark Retrieval datasets, and (3)sets a new state of the art for Visual Localization on the LaMAR datasets,where we only changed the retrieval method to the existing localizationpipeline. The code for MegaLoc is available athttps://github.com/gmberton/MegaLoc</description>
      <author>example@mail.com (Gabriele Berton, Carlo Masone)</author>
      <guid isPermaLink="false">2502.17237v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SoFFT: Spatial Fourier Transform for Modeling Continuum Soft Robots</title>
      <link>http://arxiv.org/abs/2502.17347v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于傅里叶变换的方法，用于紧凑地描述连续软机器人的变形，并通过数值模拟和实验验证了该方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;连续软机器人由柔性材料组成，理论上具有无限自由度，在非结构化环境中表现出色的适应能力。Cosserat Rod理论作为建模这些机器人的有效框架已得到广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于信号处理的方法来描述和建模连续软机器人的变形过程。&lt;h4&gt;方法&lt;/h4&gt;将机器人骨架视为时空中的信号，应用傅里叶变换将其变形简化为频域表示。该方法不仅统一了现有建模策略，并提供了实验捕捉机器人变形的基于数据驱动的方法。&lt;h4&gt;主要发现&lt;/h4&gt;通过数值模拟和现实原型实验验证了所提方法的有效性，表明在减少自由度的同时保持变形准确性的能力。&lt;h4&gt;结论&lt;/h4&gt;提出的新方法为连续软机器人的研究提供了一种有效途径，展示了傅里叶变换用于机器人建模的潜力。&lt;h4&gt;翻译&lt;/h4&gt;连续软机器人由柔性材料组成，在非结构化环境中表现出高度适应性。基于Cosserat Rod理论的应用提出了将机器人骨架视为时空信号的方法，并通过傅里叶变换来描述其变形过程。这种方法不仅统一了现有的建模策略，还提供了一种实验捕捉机器人变形的数据驱动方法。数值模拟和现实原型实验验证了该方法的有效性，在减少自由度的同时保持了变形的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continuum soft robots, composed of flexible materials, exhibit theoreticallyinfinite degrees of freedom, enabling notable adaptability in unstructuredenvironments. Cosserat Rod Theory has emerged as a prominent framework formodeling these robots efficiently, representing continuum soft robots astime-varying curves, known as backbones. In this work, we propose viewing therobot's backbone as a signal in space and time, applying the Fourier transformto describe its deformation compactly. This approach unifies existing modelingstrategies within the Cosserat Rod Theory framework, offering insights intocommonly used heuristic methods. Moreover, the Fourier transform enables thedevelopment of a data-driven methodology to experimentally capture the robot'sdeformation. The proposed approach is validated through numerical simulationsand experiments on a real-world prototype, demonstrating a reduction in thedegrees of freedom while preserving the accuracy of the deformationrepresentation.</description>
      <author>example@mail.com (Daniele Caradonna, Diego Bianchi, Franco Angelini, Egidio Falotico)</author>
      <guid isPermaLink="false">2502.17347v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Modeling, Simulation, and Application of Spatio-Temporal Characteristics Detection in Incipient Slip</title>
      <link>http://arxiv.org/abs/2502.17335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 19 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法，用于检测机器人抓握和操作任务中的初始滑动。该方法通过分析局部位移现象建立了特征应变率极端事件与局部滑动状态之间的关系。&lt;h4&gt;背景&lt;/h4&gt;早期滑动检测对于机器人抓取和操作任务至关重要，但由于物体属性的多样性和复杂的工作条件，保持其适应性仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来完全表示滑动的空间-时间特征，并建立特征应变率极端事件与局部滑动状态之间的关系。&lt;h4&gt;方法&lt;/h4&gt;基于局部位移现象分析建立了特征应变率极端事件和局部滑动状态之间的联系，该方法能检测到粘着-滑动区域的时空分布。同时，这种方法可以应用于基于视觉的触觉传感器等应变分布传感设备。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟和原型实验验证了在不同接触条件下（包括不同的接触几何形状、摩擦系数和组合负载）此方法的有效性。实验表明，该方法不仅能够准确可靠地界定初始滑动，还促进了摩擦参数估计和适应性抓握控制的实现。&lt;h4&gt;结论&lt;/h4&gt;提出的模型及其检测方法具有广泛的适用性和可靠性，在复杂的工作条件下表现出色，并为机器人抓取任务提供了关键反馈。&lt;h4&gt;翻译&lt;/h4&gt;初期滑动检测对于机器人的抓取与操作至关重要。然而，使其在多样的物体特性和复杂的作业环境下保持适应性依然面临挑战。本文重点在于完全表示滑移的时空特性，并提出了一种新的模型来捕捉初期滑动现象及其检测方法。通过对局部位移的研究建立了应变率极端事件和本地化滑动状态之间的联系，该方法可以识别出粘着-滑移区域的空间分布与时间动力学特征，且适用于基于视觉的触觉传感设备等应变分布传感器的应用场景。模拟及原型实验验证了其在不同接触条件下的有效性（比如不同的几何形状、摩擦系数和组合负载），并表明这种新方法不仅能够精确地描绘初期滑动现象，并有助于实现摩擦参数估计与自适应抓取控制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Incipient slip detection provides critical feedback for robotic grasping andmanipulation tasks. However, maintaining its adaptability under diverse objectproperties and complex working conditions remains challenging. This articlehighlights the importance of completely representing spatio-temporal featuresof slip, and proposes a novel approach for incipient slip modeling anddetection. Based on the analysis of localized displacement phenomenon, weestablish the relationship between the characteristic strain rate extremeevents and the local slip state. This approach enables the detection of boththe spatial distribution and temporal dynamics of stick-slip regions. Also, theproposed method can be applied to strain distribution sensing devices, such asvision-based tactile sensors. Simulations and prototype experiments validatedthe effectiveness of this approach under varying contact conditions, includingdifferent contact geometries, friction coefficients, and combined loads.Experiments demonstrated that this method not only accurately and reliablydelineates incipient slip, but also facilitates friction parameter estimationand adaptive grasping control.</description>
      <author>example@mail.com (Mingxuan Li, Lunwei Zhang, Qiyin Huang, Tiemin Li, Yao Jiang)</author>
      <guid isPermaLink="false">2502.17335v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Computation Offloading Strategies in Integrated Terrestrial and Non-Terrestrial Networks</title>
      <link>http://arxiv.org/abs/2502.15903v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper accepted as chapter to Elsevier&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文探讨了集成地面和非地面网络（IT-NTNs）在计算密集型应用中的作用，这些应用包括增强现实、自动驾驶、远程医疗和智能城市等。&lt;h4&gt;背景&lt;/h4&gt;传统地面网络由于覆盖不足、容量有限以及偏远地区的高延迟而限制了上述应用的发展。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过集成的地面与非地面网络来应对这些问题，并实现高效的计算卸载。&lt;h4&gt;方法&lt;/h4&gt;首先介绍了移动边缘计算（MEC）及其向多接入边缘计算演化的路径，接着详细探讨了IT-NTNs架构，包括地面基站、无人机、高空平台和低轨卫星如何协同工作以提供无缝连接。文章还分析了几种不同的计算卸载策略，并讨论了关键使能技术。&lt;h4&gt;主要发现&lt;/h4&gt;各种计算卸载方法各有优缺点；关键技术如非正交多址接入（NOMA）、毫米波/太赫兹通信和可重构智能表面等对于现有资源分配、任务卸载决策及移动管理算法至关重要。&lt;h4&gt;结论&lt;/h4&gt;本文强调了计算卸载在IT-NTNs中的变革性影响，展望未来的研究方向，并指出了此类网络在未来重新定义通信与计算范式的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of computation-intensive applications like augmentedreality, autonomous driving, remote healthcare, and smart cities has exposedthe limitations of traditional terrestrial networks, particularly in terms ofinadequate coverage, limited capacity, and high latency in remote areas. Thischapter explores how integrated terrestrial and non-terrestrial networks(IT-NTNs) can address these challenges and enable efficient computationoffloading. We examine mobile edge computing (MEC) and its evolution towardmultiple-access edge computing, highlighting the critical role computationoffloading plays for resource-constrained devices. We then discuss thearchitecture of IT-NTNs, focusing on how terrestrial base stations, unmannedaerial vehicles (UAVs), high-altitude platforms (HAPs), and LEO satellites worktogether to deliver ubiquitous connectivity. Furthermore, we analyze variouscomputation offloading strategies, including edge, cloud, and hybridoffloading, outlining their strengths and weaknesses. Key enabling technologiessuch as NOMA, mmWave/THz communication, and reconfigurable intelligent surfaces(RIS) are also explored as essential components of existing algorithms forresource allocation, task offloading decisions, and mobility management.Finally, we conclude by highlighting the transformative impact of computationoffloading in IT-NTNs across diverse application areas and discuss keychallenges and future research directions, emphasizing the potential of thesenetworks to revolutionize communication and computation paradigms.</description>
      <author>example@mail.com (Muhammad Ahmed Mohsin, Muhammad Umer, Amara Umar, Hatem Abou-Zeid, Syed Ali Hassan)</author>
      <guid isPermaLink="false">2502.15903v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration</title>
      <link>http://arxiv.org/abs/2410.18032v4</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种名为GraphTeam的多代理系统，用于基于大型语言模型（LLM）进行图分析。&lt;h4&gt;背景&lt;/h4&gt;现有的图数据分析方法要么将图形神经网络与特定机器学习任务相结合，限制了其可移植性；要么仅依赖于LLMs内部推理能力，导致性能不佳。为解决这些问题，本文利用最近关于LLM代理的进展来提高外部知识或工具使用的能力。&lt;h4&gt;目的&lt;/h4&gt;通过模拟人类解决问题策略（如类比和协作），提出一种基于多代理系统的图分析解决方案GraphTeam。&lt;h4&gt;方法&lt;/h4&gt;{'输入-输出标准化模块': '包括问题代理提取并细化四个关键参数，以促进问题理解；答案代理组织结果以满足输出要求。', '外部知识检索模块': '构建了一个包含相关文档和经验信息的知识库，并通过搜索代理为每个问题检索最相关的条目。', '问题解决模块': '编码代理根据从搜索代理获得的信息使用编程生成解决方案，如果编码代理无法工作，则推理代理将直接计算结果。'}&lt;h4&gt;主要发现&lt;/h4&gt;在六个图分析基准上的广泛实验显示，GraphTeam实现了最先进的性能，比最佳基线平均提高了25.85%的准确性。&lt;h4&gt;结论&lt;/h4&gt;GraphTeam通过模拟人类问题解决策略并有效利用外部知识和工具，为复杂图形数据分析任务提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要提供了关于GraphTeam系统的设计细节、模块功能以及实验结果的信息。该研究展示了在图数据处理方面的新进展，并强调了LLM代理协同工作的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bupt-gamma/graphteam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are widely used for modeling relational data in real-world scenarios,such as social networks and urban computing. Existing LLM-based graph analysisapproaches either integrate graph neural networks (GNNs) for specific machinelearning tasks, limiting their transferability, or rely solely on LLMs'internal reasoning ability, resulting in suboptimal performance. To addressthese limitations, we take advantage of recent advances in LLM-based agents,which have shown capabilities of utilizing external knowledge or tools forproblem solving. By simulating human problem-solving strategies such as analogyand collaboration, we propose a multi-agent system based on LLMs namedGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents fromthree modules, and the agents with different specialities can collaborate witheach other to address complex problems. Specifically, (1) input-outputnormalization module: the question agent extracts and refines four keyarguments from the original question, facilitating the problem understanding,and the answer agent organizes the results to meet the output requirement; (2)external knowledge retrieval module: we first build a knowledge base consistingof relevant documentation and experience information, and then the search agentretrieves the most relevant entries for each question. (3) problem-solvingmodule: given the retrieved information from search agent, the coding agentuses established algorithms via programming to generate solutions, and in casethe coding agent does not work, the reasoning agent will directly compute theresults without programming. Extensive experiments on six graph analysisbenchmarks demonstrate that GraphTeam achieves state-of-the-art performancewith an average 25.85% improvement over the best baseline in terms of accuracy.The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.</description>
      <author>example@mail.com (Xin Sky Li, Qizhi Chu, Yubin Chen, Yang Liu, Yaoqi Liu, Zekai Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang)</author>
      <guid isPermaLink="false">2410.18032v4</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>TDMPBC: Self-Imitative Reinforcement Learning for Humanoid Robot Control</title>
      <link>http://arxiv.org/abs/2502.17322v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了SIRL框架，通过模仿任务相关的轨迹来改进强化学习算法在高维空间中的表现。&lt;h4&gt;背景&lt;/h4&gt;复杂高维度的空间对于配备灵巧手的人形机器人等系统来说，在有限样本预算下平衡探索和利用方面对强化学习算法构成了挑战。可行的任务完成区域通常非常狭窄。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的强化学习框架，以改善在复杂行动空间中任务表现的问题。&lt;h4&gt;方法&lt;/h4&gt;通过引入自模仿强化学习（SIRL）框架，该框架使RL算法能够模仿潜在任务相关的轨迹，并根据轨迹回报调整行为克隆的权重。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的算法在HumanoidBench上实现了120%的性能提升，同时仅增加了5%的计算开销。进一步的可视化分析表明，这种性能改进确实带来了有意义的行为改善。&lt;h4&gt;结论&lt;/h4&gt;SIRL框架提供了一种有效的方法来增强RL算法处理复杂高维空间任务的能力。&lt;h4&gt;翻译&lt;/h4&gt;复杂的高维度空间（具有大量自由度和复杂行动空间），如装备灵巧手的人形机器人，对强化学习算法构成了重大挑战。这类算法需要在有限的样本预算下巧妙地平衡探索与利用之间的关系。通常情况下，在这种复杂的高维空间中完成任务的有效区域极其狭窄。例如，在人形机器人的运动控制领域，绝大多数的空间都对应于跌倒的状态，而能够执行后续任务的小部分状态则仅占微不足道的比例。一旦机器人进入了潜在的任务相关区域，它应该更加重视该区域内的数据。基于这一见解，我们提出了自模仿强化学习（SIRL）框架，在此框架下RL算法也模仿潜在的任务相关的轨迹。具体来说，使用轨迹回报来确定其任务的相关性，并采用额外的行为克隆方法，权重根据轨迹回报动态调整。结果表明，所提出的算法在具有挑战性的HumanoidBench上实现了120%的性能提升，同时仅增加了5%的计算开销。通过进一步可视化分析发现，显著的性能改进确实导致了有意义的行为改善，成功解决了多个任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex high-dimensional spaces with high Degree-of-Freedom and complicatedaction spaces, such as humanoid robots equipped with dexterous hands, posesignificant challenges for reinforcement learning (RL) algorithms, which needto wisely balance exploration and exploitation under limited sample budgets. Ingeneral, feasible regions for accomplishing tasks within complexhigh-dimensional spaces are exceedingly narrow. For instance, in the context ofhumanoid robot motion control, the vast majority of space corresponds tofalling, while only a minuscule fraction corresponds to standing upright, whichis conducive to the completion of downstream tasks. Once the robot exploresinto a potentially task-relevant region, it should place greater emphasis onthe data within that region. Building on this insight, we propose the$\textbf{S}$elf-$\textbf{I}$mitative $\textbf{R}$einforcement$\textbf{L}$earning ($\textbf{SIRL}$) framework, where the RL algorithm alsoimitates potentially task-relevant trajectories. Specifically, trajectoryreturn is utilized to determine its relevance to the task and an additionalbehavior cloning is adopted whose weight is dynamically adjusted based on thetrajectory return. As a result, our proposed algorithm achieves 120%performance improvement on the challenging HumanoidBench with 5% extracomputation overhead. With further visualization, we find the significantperformance gain does lead to meaningful behavior improvement that severaltasks are solved successfully.</description>
      <author>example@mail.com (Zifeng Zhuang, Diyuan Shi, Runze Suo, Xiao He, Hongyin Zhang, Ting Wang, Shangke Lyu, Donglin Wang)</author>
      <guid isPermaLink="false">2502.17322v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Inverse Kinematics on Guiding Vector Fields for Robot Path Following</title>
      <link>http://arxiv.org/abs/2502.17313v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Yu Zhou and Jes\'us Bautista contributed equally to this work. In the  proceedings of the IEEE International Conference on Robotics and Automation  (ICRA) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;逆向运动学是一种在机器人学中用于姿态和定位控制的基础技术，通常应用于末端执行器。然而，在这篇论文中，研究者们扩展了逆向运动学的概念，将其应用到自主移动机器人的路径跟随上的导向矢量场。&lt;h4&gt;目的&lt;/h4&gt;为了使机器人能够沿着期望的路径收敛并行进，文章提出了如何使用逆向运动学方法构建误差信号，并驱动导向矢量场朝向期望路径。&lt;h4&gt;方法&lt;/h4&gt;首先，从形式上展示了如何将逆向运动学应用于单积分器机器人的导向矢量场上。然后利用逆向运动学确保层次集误差信号表现为线性系统，从而方便对机器人在向目标路径过渡时的行为进行控制，并允许注入前馈信号以实现沿路径的精确运动行为。&lt;h4&gt;主要发现&lt;/h4&gt;研究提出了如何将该技术应用于常速单轮车（如固定翼无人机），以便它们能够跟踪二维路径并具有精细的瞬态控制能力。&lt;h4&gt;结论&lt;/h4&gt;通过实际飞行测试验证了预测的理论结果，表明这种方法在指导自主移动机器人沿特定路径精确运动方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;逆向运动学被扩展应用于导向矢量场中，使自主移动机器人能够准确地跟踪预定路径。该技术不仅确保了层次集误差信号呈线性系统特征，还通过注入前馈信号提升了瞬态控制性能，并在实际应用中证明其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inverse kinematics is a fundamental technique for motion and positioningcontrol in robotics, typically applied to end-effectors. In this paper, weextend the concept of inverse kinematics to guiding vector fields for pathfollowing in autonomous mobile robots. The desired path is defined by itsimplicit equation, i.e., by a collection of points belonging to one or morezero-level sets. These level sets serve as a reference to construct an errorsignal that drives the guiding vector field toward the desired path, enablingthe robot to converge and travel along the path by following such a vectorfield. We start with the formal exposition on how inverse kinematics can beapplied to guiding vector fields for single-integrator robots in anm-dimensional Euclidean space. Then, we leverage inverse kinematics to ensurethat the level-set error signal behaves as a linear system, facilitatingcontrol over the robot's transient motion toward the desired path and allowingfor the injection of feed-forward signals to induce precise motion behavioralong the path. We then propose solutions to the theoretical and practicalchallenges of applying this technique to unicycles with constant speeds tofollow 2D paths with precise transient control. We finish by validating thepredicted theoretical results through real flights with fixed-wing drones.</description>
      <author>example@mail.com (Yu Zhou, Jesús Bautista, Weijia Yao, Héctor García de Marina)</author>
      <guid isPermaLink="false">2502.17313v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Human-Machine Perception via Adaptive LiDAR for Advanced Driver Assistance Systems</title>
      <link>http://arxiv.org/abs/2502.17309v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;准确的环境感知对于高级驾驶辅助系统（ADAS）至关重要。激光雷达（LiDAR）在ADAS中起着至关重要的作用，可以可靠地检测障碍物并帮助确保交通安全。&lt;h4&gt;背景&lt;/h4&gt;现有研究表明，根据环境特性调整激光雷达的分辨率和范围可以提高机器感知能力。然而，目前针对ADAS的自适应激光雷达方法尚未探索将车辆感知能力和驾驶员视觉感知结合起来的可能性，这可能进一步提升探测性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的系统，该系统可根据驾驶员的视觉感知来调整LiDAR特性，以增强超出人类视野范围外的LiDAR感应。在虚拟环境CARLA中开发系统的概念验证原型。&lt;h4&gt;方法&lt;/h4&gt;系统整合实时数据监控驾驶员视线，识别环境中驾驶员正在观察的区域，并通过动态增加外围未关注区域的激光雷达的范围和分辨率来优化激光雷达资源。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果表明，这种基于注视的LiDAR相对于基准独立式LiDAR，在雾等具有挑战性的环境条件下性能更佳。该混合的人机感知方法在实时驾驶场景中为ADAS应用提供更好的安全性和态势感知能力。&lt;h4&gt;结论&lt;/h4&gt;通过结合车辆和驾驶员的感知能力来优化激光雷达特性，可以提高复杂环境下ADAS系统的检测性能和安全性。&lt;h4&gt;翻译&lt;/h4&gt;准确的环境感知对高级驾驶辅助系统（ADAS）至关重要。现有的研究表明，根据环境特征调整LiDAR的分辨率和范围可以改善机器感知。然而，目前用于ADAS的自适应LiDAR方法还没有探索将车辆感知能力与驾驶员视觉感知结合的可能性，这有可能进一步提升检测性能。本文提出了一种新的系统，该系统可根据人类驾驶员的视觉感知来定制LiDAR特性，以增强超出人眼视野之外的LiDAR感应。我们开发了一个在虚拟环境CARLA中的概念验证原型系统。该系统集成了实时数据监控司机视线的功能，可以识别出环境中司机正在查看的区域，并通过动态增加未被注视周围区域中激光雷达的范围和分辨率来优化其资源分配。模拟结果表明，这种基于目光追踪的LiDAR相对于独立式LiDAR基准在具有挑战性的环境条件下（例如雾）表现更佳。该混合的人机感知方法可能为ADAS应用中的实时驾驶场景提供增强的安全性和态势感知能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate environmental perception is critical for advanced driver assistancesystems (ADAS). Light detection and ranging (LiDAR) systems play a crucial rolein ADAS; they can reliably detect obstacles and help ensure traffic safety.Existing research on LiDAR sensing has demonstrated that adapting the LiDAR'sresolution and range based on environmental characteristics can improve machineperception. However, current adaptive LiDAR approaches for ADAS have notexplored the possibility of combining the perception abilities of the vehicleand the human driver, which can potentially further enhance the detectionperformance. In this paper, we propose a novel system that adapts LiDARcharacteristics to human driver's visual perception to enhance LiDAR sensingoutside human's field of view. We develop a proof-of-concept prototype of thesystem in the virtual environment CARLA. Our system integrates real-time dataon the driver's gaze to identify regions in the environment that the driver ismonitoring. This allows the system to optimize LiDAR resources by dynamicallyincreasing the LiDAR's range and resolution in peripheral areas that the drivermay not be attending to. Our simulations show that this gaze-aware LiDARenhances detection performance compared to a baseline standalone LiDAR,particularly in challenging environmental conditions like fog. Our hybridhuman-machine sensing approach potentially offers improved safety andsituational awareness in real-time driving scenarios for ADAS applications.</description>
      <author>example@mail.com (Federico Scarì, Nitin Jonathan Myers, Chen Quan, Arkady Zgonnikov)</author>
      <guid isPermaLink="false">2502.17309v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SmartEdge: Smart Healthcare End-to-End Integrated Edge and Cloud Computing System for Diabetes Prediction Enabled by Ensemble Machine Learning</title>
      <link>http://arxiv.org/abs/2502.15762v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了SmartEdge系统，该系统利用边缘计算和云端协同工作，在糖尿病预测中实现了低延迟、高效能的解决方案。通过集成多种风险因素，并使用投票算法提高了模型预测准确率。&lt;h4&gt;背景&lt;/h4&gt;物联网（IoT）正在推动智能城市的医疗、交通、工业和教育等领域的发展。特别是在智能医院和远程患者监测（RPM）方面，互联网医疗事物（IoMT）变得尤为重要。然而，现有基于云计算的方法在延迟敏感的应用中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种新的AI驱动的边缘计算与云协同系统SmartEdge，旨在解决糖尿病预测中的低延迟问题，并展示其在健康应用中的有效性和可扩展性。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一个基于边缘和云端的框架，在不同配置下部署糖尿病预测模型。评估了系统的性能指标包括延迟、准确性及响应时间。&lt;h4&gt;主要发现&lt;/h4&gt;使用集成机器学习投票算法，可以将预测准确率提高5%，优于单一模型。&lt;h4&gt;结论&lt;/h4&gt;SmartEdge系统展示了在医疗领域中边缘计算和云服务结合的有效性和潜力，并为未来的研究提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Internet of Things (IoT) revolutionizes smart city domains such ashealthcare, transportation, industry, and education. The Internet of MedicalThings (IoMT) is gaining prominence, particularly in smart hospitals and RemotePatient Monitoring (RPM). The vast volume of data generated by IoMT devicesshould be analyzed in real-time for health surveillance, prognosis, andprediction of diseases. Current approaches relying on Cloud computing toprovide the necessary computing and storage capabilities do not scale for theselatency-sensitive applications. Edge computing emerges as a solution bybringing cloud services closer to IoMT devices. This paper introducesSmartEdge, an AI-powered smart healthcare end-to-end integrated edge and cloudcomputing system for diabetes prediction. This work addresses latency concernsand demonstrates the efficacy of edge resources in healthcare applicationswithin an end-to-end system. The system leverages various risk factors fordiabetes prediction. We propose an Edge and Cloud-enabled framework to deploythe proposed diabetes prediction models on various configurations using edgenodes and main cloud servers. Performance metrics are evaluated using, latency,accuracy, and response time. By using ensemble machine learning votingalgorithms we can improve the prediction accuracy by 5% versus a single modelprediction.</description>
      <author>example@mail.com (Alain Hennebelle, Qifan Dieng, Leila Ismail, Rajkumar Buyya)</author>
      <guid isPermaLink="false">2502.15762v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Co-Designing Augmented Reality Tools for High-Stakes Clinical Teamwork</title>
      <link>http://arxiv.org/abs/2502.17295v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 7 figures, submitted to DIS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项研究探讨了医疗工作者如何利用增强现实头戴式显示器（AR-HMDs）来提高急诊团队的工作效率，通过参与性设计与医疗工作者合作，发现了七个基于角色的AR-HMD应用场景，并提供了针对高风险环境下的团队工作的设计建议。&lt;h4&gt;背景&lt;/h4&gt;尽管AR-HMD在支持医疗环境中团队协作方面显示出巨大潜力，但在急诊科（ER）团队中的应用却很少得到研究。ER具有特殊的挑战，如程序记忆、医疗错误和沟通障碍。&lt;h4&gt;目的&lt;/h4&gt;通过与医疗工作者的合作进行参与性设计研究，探索AR-HMD如何促进急诊流程中团队合作的潜在能力。&lt;h4&gt;方法&lt;/h4&gt;进行了一个参与者驱动的设计研究项目，旨在了解HCWs在ER环境中利用AR-HMD的可能性。&lt;h4&gt;主要发现&lt;/h4&gt;AR-HMD可以作为信息共享和检索系统使用，在知识鸿沟方面发挥作用，并解决了将AR-HMD集成到ER工作流程中的担忧。提出了七种基于角色的场景设计建议，适用于不同专业背景、执行多项医疗任务的HCWs。&lt;h4&gt;结论&lt;/h4&gt;希望通过这项研究激发设计师开发新的AR-HMD应用程序，用于高风险团队环境。&lt;h4&gt;翻译&lt;/h4&gt;医护人员如何利用增强现实头戴式显示器（AR-HMDs）来改善急诊科内的团队协作？尽管在支持医疗服务中的团队合作方面显示了巨大潜力，但专门针对ER团队的设计却很少见。这项研究通过与医疗工作者的合作设计研究，揭示了AR-HMD可以作为信息共享和检索系统使用，解决了将AR-HMD集成到ER工作流程中的问题，并提出了适用于不同专业背景的HCWs在执行多种医疗任务时的角色基于的应用场景设计建议。希望此项研究能激发设计师开发新的适合高风险团队环境下的AR-HMD应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How might healthcare workers (HCWs) leverage augmented reality head-mounteddisplays (AR-HMDs) to enhance teamwork? Although AR-HMDs have shown immensepromise in supporting teamwork in healthcare settings, design for EmergencyDepartment (ER) teams has received little attention. The ER presents uniquechallenges, including procedural recall, medical errors, and communicationgaps. To address this gap, we engaged in a participatory design study withhealthcare workers to gain a deep understanding of the potential for AR-HMDs tofacilitate teamwork during ER procedures. Our results reveal that AR-HMDs canbe used as an information-sharing and information-retrieval system to bridgeknowledge gaps, and concerns about integrating AR-HMDs in ER workflows. Wecontribute design recommendations for seven role-based AR-HMD applicationscenarios involving HCWs with various expertise, working across multiplemedical tasks. We hope our research inspires designers to embark on thedevelopment of new AR-HMD applications for high-stakes, team environments.</description>
      <author>example@mail.com (Angelique Taylor, Tauhid Tanjim, Huajie Cao, Jalynn Blu Nicoly, Jonathan I. Segal, Jonathan St. George, Soyon Kim, Kevin Ching, Francisco R. Ortega, Hee Rin Lee)</author>
      <guid isPermaLink="false">2502.17295v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Continuous Wrist Control on the Hannes Prosthesis: a Vision-based Shared Autonomy Framework</title>
      <link>http://arxiv.org/abs/2502.17265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025. Project website:  https://hsp-iit.github.io/hannes-wrist-control&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于计算机视觉的系统，该系统结合用户和自动系统的合作，在共享自主框架中实现假肢腕关节连续控制。&lt;h4&gt;背景&lt;/h4&gt;大多数用于假肢抓握的技术集中在灵巧的手指控制上，而忽视了手腕动作。这迫使用户通过肘部、肩部和臀部的动作来适应手腕的抓取需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合计算机视觉的方法，在假肢臂中实现腕关节自由度的连续控制，以促进更自然的接近目标物体并根据用户的意图进行抓握。&lt;h4&gt;方法&lt;/h4&gt;该系统利用用户与自动系统的协作，采用基于计算机视觉的技术来无缝控制假肢手腕。系统可以追踪目标对象，并最终按照用户意愿调整手腕姿态。&lt;h4&gt;主要发现&lt;/h4&gt;通过定量分析评估了每个系统组件的有效性，并在Hannes假肢臂上部署该方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的系统能够有效改善假肢的自然抓握能力，提供更好的用户体验。&lt;h4&gt;翻译&lt;/h4&gt;大多数用于假肢抓握的技术集中在灵巧的手指控制上，而忽视了手腕动作。这迫使用户通过肘部、肩部和臀部的动作来适应手腕的抓取需求。我们提出了一种基于计算机视觉的方法，在共享自主框架中结合用户与自动系统的合作，实现假肢腕关节自由度的连续控制，以促进更自然的接近目标物体并根据用户的意图进行抓握。我们的系统可以无缝地控制假肢手腕追踪目标对象，并最终按照用户意愿调整手腕姿态。我们通过定量分析评估了每个系统组件的有效性，并在Hannes假肢臂上部署该方法。代码和视频：https://hsp-iit.github.io/hannes-wrist-control.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most control techniques for prosthetic grasping focus on dexterous fingerscontrol, but overlook the wrist motion. This forces the user to performcompensatory movements with the elbow, shoulder and hip to adapt the wrist forgrasping. We propose a computer vision-based system that leverages thecollaboration between the user and an automatic system in a shared autonomyframework, to perform continuous control of the wrist degrees of freedom in aprosthetic arm, promoting a more natural approach-to-grasp motion. Our pipelineallows to seamlessly control the prosthetic wrist to follow the target objectand finally orient it for grasping according to the user intent. We assess theeffectiveness of each system component through quantitative analysis andfinally deploy our method on the Hannes prosthetic arm. Code and videos:https://hsp-iit.github.io/hannes-wrist-control.</description>
      <author>example@mail.com (Federico Vasile, Elisa Maiettini, Giulia Pasquale, Nicolò Boccardo, Lorenzo Natale)</author>
      <guid isPermaLink="false">2502.17265v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Tidiness Score-Guided Monte Carlo Tree Search for Visual Tabletop Rearrangement</title>
      <link>http://arxiv.org/abs/2502.17235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的框架TSMCTS，该框架利用RGB-D相机解决桌面整理问题。&lt;h4&gt;背景&lt;/h4&gt;当前的桌面整理研究面临两大挑战：缺乏公开的数据集和基准以及难以指定未见物体的目标配置。&lt;h4&gt;目的&lt;/h4&gt;为了应对这些挑战，作者提出了一个结构化的数据集（TTU），并开发了一种基于视觉的判别器来预测整洁度分数，并结合蒙特卡洛树搜索算法寻找整理轨迹。&lt;h4&gt;方法&lt;/h4&gt;1. 创建了一个桌面整理数据集(TTU)；2. 利用该数据训练出一种能够评估不同配置下整洁度的基于视觉的判别器；3. 使用MCTS在不指定具体目标的情况下找到整理路径，并利用整洁度分数作为指导；4. 提出了TSMCTS，它将一个清洁度判断器与一个基于MCTS的整理规划器结合在一起。&lt;h4&gt;主要发现&lt;/h4&gt;提出的TSMCTS框架能够在多种环境中有效工作，包括咖啡桌、餐桌、办公桌和浴室等场景。&lt;h4&gt;结论&lt;/h4&gt;通过使用TTU数据集训练出的视觉判别器和MCTS算法相结合的方法能够有效地解决桌面整理问题，并且具有较高的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们提出了一种基于整洁度分数指导的蒙特卡洛树搜索(TSMCTS)框架，旨在仅使用RGB-D相机来解决桌面上的清理问题。该研究解决了两个主要难题：缺乏公开数据集和基准以及难以指定未见物体的目标配置。为了解决第一个问题，我们提供了桌面整理（TTU）数据集，在模拟中收集了一个结构化的数据集。利用这个数据集，我们训练出一种基于视觉的判别器能够预测整洁度分数。这种判别器可以一致地评估未知配置下的整洁程度，包括真实世界中的场景。为了解决第二个问题，我们采用了蒙特卡洛树搜索(MCTS)方法在不指定明确目标的情况下寻找整理路径。而不是提供特定的目标，我们展示我们的MCTS基规划程序能够使用整洁度分数作为指导找到多样化的整理配置。因此，我们提出了TSMCTS，它将一个清洁度判断器与一个基于MCTS的整理规划器结合在一起以找到最优的整理排列。在咖啡桌、餐桌、办公桌和浴室等各种环境中，TSMCTS已经展示了其能力。TTU数据集可以在 https://github.com/rllab-snu/TTU-Dataset 获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present the tidiness score-guided Monte Carlo tree search(TSMCTS), a novel framework designed to address the tabletop tidying up problemusing only an RGB-D camera. We address two major problems for tabletop tidyingup problem: (1) the lack of public datasets and benchmarks, and (2) thedifficulty of specifying the goal configuration of unseen objects. We addressthe former by presenting the tabletop tidying up (TTU) dataset, a structureddataset collected in simulation. Using this dataset, we train a vision-baseddiscriminator capable of predicting the tidiness score. This discriminator canconsistently evaluate the degree of tidiness across unseen configurations,including real-world scenes. Addressing the second problem, we employ MonteCarlo tree search (MCTS) to find tidying trajectories without specifyingexplicit goals. Instead of providing specific goals, we demonstrate that ourMCTS-based planner can find diverse tidied configurations using the tidinessscore as a guidance. Consequently, we propose TSMCTS, which integrates atidiness discriminator with an MCTS-based tidying planner to find optimaltidied arrangements. TSMCTS has successfully demonstrated its capability acrossvarious environments, including coffee tables, dining tables, office desks, andbathrooms. The TTU dataset is available at:https://github.com/rllab-snu/TTU-Dataset.</description>
      <author>example@mail.com (Hogun Kee, Wooseok Oh, Minjae Kang, Hyemin Ahn, Songhwai Oh)</author>
      <guid isPermaLink="false">2502.17235v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>A Reinforcement Learning Approach to Non-prehensile Manipulation through Sliding</title>
      <link>http://arxiv.org/abs/2502.17221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种针对非抓握式任务的深度确定性策略梯度（DDPG）强化学习框架，用于高效地在水平表面上滑动物体。该算法通过精确控制机械臂的加速度生成线性轨迹，实现了物体的相对操作。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数技术主要集中在基于抓握的操作上，这限制了它们在非抓握任务中的适用性。为了满足日益增长的需求，本文提出了一种新的方法来解决这个问题。&lt;h4&gt;目的&lt;/h4&gt;引入一种DDPG强化学习框架，以实现高效的非抓握操作，特别是在滑动物体方面的应用。&lt;h4&gt;方法&lt;/h4&gt;算法通过精确控制机器人臂的加速度生成线性轨迹，实现了物体在水平表面上滑动时的操作。此外还开发了两种不同的算法来动态估计滑动过程中的摩擦力。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法能够在线估算每次操作后的摩擦力，并将其反馈到演员模型中作为关键反馈，从而提高了策略的适应性和鲁棒性。实验结果表明该框架能够有效推广滑动物体的操作并适应不同表面。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过模拟和实际实验验证了其有效性，展示了零样本仿真到现实环境的转移能力。&lt;h4&gt;翻译&lt;/h4&gt;虽然机器人应用程序越来越需要多功能和动态的对象处理，但大多数现有技术主要集中在基于抓握的操作上，限制了它们在非抓握任务中的适用性。为了解决这一需求，本文介绍了一种用于有效进行非抓取操作（特别是物体在水平表面上滑动）的深度确定性策略梯度（DDPG）强化学习框架。该算法通过精确控制与水平表面刚性连接的机器人臂加速度生成线性轨迹，实现了滑动物体时相对的操作。此外还开发了两种不同的算法来动态估算滑动过程中的摩擦力。这些算法在线提供了每次动作后的摩擦估计，并将其反馈到演员模型中作为关键反馈，增强了策略的适应性和鲁棒性，确保在不同表面条件下更精确地控制平台加速度。所提出的算法通过模拟和实际实验进行了验证。结果表明该框架能够有效推广滑动物体操作，并且特别能够在不同摩擦性质表面上进行调整。值得注意的是，训练后的模型展示了零样本仿真到现实环境的转移能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although robotic applications increasingly demand versatile and dynamicobject handling, most existing techniques are predominantly focused ongrasp-based manipulation, limiting their applicability in non-prehensile tasks.To address this need, this study introduces a Deep Deterministic PolicyGradient (DDPG) reinforcement learning framework for efficient non-prehensilemanipulation, specifically for sliding an object on a surface. The algorithmgenerates a linear trajectory by precisely controlling the acceleration of arobotic arm rigidly coupled to the horizontal surface, enabling the relativemanipulation of an object as it slides on top of the surface. Furthermore, twodistinct algorithms have been developed to estimate the frictional forcesdynamically during the sliding process. These algorithms provide onlinefriction estimates after each action, which are fed back into the actor modelas critical feedback after each action. This feedback mechanism enhances thepolicy's adaptability and robustness, ensuring more precise control of theplatform's acceleration in response to varying surface condition. The proposedalgorithm is validated through simulations and real-world experiments. Resultsdemonstrate that the proposed framework effectively generalizes slidingmanipulation across varying distances and, more importantly, adapts todifferent surfaces with diverse frictional properties. Notably, the trainedmodel exhibits zero-shot sim-to-real transfer capabilities.</description>
      <author>example@mail.com (Hamidreza Raei, Elena De Momi, Arash Ajoudani)</author>
      <guid isPermaLink="false">2502.17221v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Humanoid Whole-Body Locomotion on Narrow Terrain via Dynamic Balance and Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.17219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于动态平衡和强化学习的新型全身行走算法，使类人机器人能够仅通过本体感觉在极端地形上行走。&lt;h4&gt;背景&lt;/h4&gt;人类具有精细的动力平衡机制，能够在各种地形和极端条件下保持稳定。然而，现有的类人机器人步行算法难以应对缺乏外部感知（如视觉或激光雷达）的极端环境。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的全身行走算法来解决现有方法在处理不可见障碍物和突然失去平衡方面的能力不足问题。&lt;h4&gt;方法&lt;/h4&gt;引入了一个动态平衡机制，通过扩展的零力矩点(ZMP)驱动奖励和任务驱动奖励，在一个全身演员-评论家框架中实现上肢与下肢的协调动作。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该算法能够使机器人在极其狭窄的地面上保持平衡，并且对外部干扰具有适应性。&lt;h4&gt;结论&lt;/h4&gt;通过这种新型方法，类人机器人的行走能力得到了显著增强，使其能更好地应对复杂环境。&lt;h4&gt;翻译&lt;/h4&gt;人类拥有精细的动力平衡机制，在各种地形和极端条件下都能维持稳定。然而，尽管最近取得了重大进展，现有的类人机器人步行算法仍然难以穿越极端环境，尤其是在缺乏外部感知（如视觉或激光雷达）的情况下。这是因为当前的方法通常依赖于基于步态的或者需要特定感知条件的奖励策略，缺少有效处理不可见障碍物和突然失去平衡的有效机制。为了解决这一挑战，我们提出了一种新的全身行走算法，该算法基于动力平衡和强化学习（RL），使类人机器人能够仅通过本体感觉在极端地形上行走，特别是在狭窄路径和意外障碍的情况下。具体来说，我们引入了一个动态平衡机制，利用了扩展的零力矩点(ZMP)驱动奖励和任务驱动奖励，在一个全身演员-评论家框架中实现上下肢体的协调动作。全尺寸Unitree H1-2机器人的实验验证了该方法在极端狭窄地形上保持平衡以及对抗外部干扰的能力，证明了其增强机器人对复杂环境适应性的有效性。视频可以在https://whole-body-loco.github.io观看。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans possess delicate dynamic balance mechanisms that enable them tomaintain stability across diverse terrains and under extreme conditions.However, despite significant advances recently, existing locomotion algorithmsfor humanoid robots are still struggle to traverse extreme environments,especially in cases that lack external perception (e.g., vision or LiDAR). Thisis because current methods often rely on gait-based or perception-conditionrewards, lacking effective mechanisms to handle unobservable obstacles andsudden balance loss. To address this challenge, we propose a novel whole-bodylocomotion algorithm based on dynamic balance and Reinforcement Learning (RL)that enables humanoid robots to traverse extreme terrains, particularly narrowpathways and unexpected obstacles, using only proprioception. Specifically, weintroduce a dynamic balance mechanism by leveraging an extended measure ofZero-Moment Point (ZMP)-driven rewards and task-driven rewards in a whole-bodyactor-critic framework, aiming to achieve coordinated actions of the upper andlower limbs for robust locomotion. Experiments conducted on a full-sizedUnitree H1-2 robot verify the ability of our method to maintain balance onextremely narrow terrains and under external disturbances, demonstrating itseffectiveness in enhancing the robot's adaptability to complex environments.The videos are given at https://whole-body-loco.github.io.</description>
      <author>example@mail.com (Weiji Xie, Chenjia Bai, Jiyuan Shi, Junkai Yang, Yunfei Ge, Weinan Zhang, Xuelong Li)</author>
      <guid isPermaLink="false">2502.17219v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Mechanical non-reciprocity programmed by shear jamming in soft composite solids</title>
      <link>http://arxiv.org/abs/2502.17083v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种通过利用颗粒物理中的剪切堵塞转换来设计非互易机械性的原理，从而在软复合固体中实现可调、方向依赖的不对称性。&lt;h4&gt;背景&lt;/h4&gt;传统的非互易性通常通过复杂结构非线性在超材料中实现。而具有内在非互易力学特性的连续体固体由于其潜在的应用前景（如波导、机器人技术及自适应材料）却未被充分探索。&lt;h4&gt;目的&lt;/h4&gt;引入一种设计原则，利用颗粒物理中的剪切堵塞转换来工程化软复合固体中的非互易机械性。&lt;h4&gt;方法&lt;/h4&gt;通过控制包含接触网络与基质弹性之间的相互作用，在软复合固体中实现了对剪切和正交力学响应的方向依赖的不对称性。结合响应性磁轮廓线，展示了程序化的非互易动力学特性。&lt;h4&gt;主要发现&lt;/h4&gt;实现了可调、方向相关的不对称性；展示了通过组合响应性磁图案和剪切堵塞系统的各向异性特性的程序化非互易动力学；以及在软材料中实现之前难以达到的不对称时空控制运动传输的能力。&lt;h4&gt;结论&lt;/h4&gt;此项工作为设计非互易物质开创了一个新的范例，将颗粒物理与软材料工程相结合以实现对机械智能系统至关重要的功能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mechanical non-reciprocity-manifested as asymmetric responses to opposingmechanical stimuli-has traditionally been achieved through intricate structuralnonlinearities in metamaterials. However, continuum solids with inherentnon-reciprocal mechanics remain underexplored, despite their promisingpotential for applications such as wave guiding, robotics, and adaptivematerials. Here, we introduce a design principle by employing the shear jammingtransition from granular physics to engineering non-reciprocal mechanics insoft composite solids. Through the control of the interplay between inclusioncontact networks and matrix elasticity, we achieve tunable, direction-dependentasymmetry in both shear and normal mechanical responses. In addition to staticregimes, we demonstrate programmable non-reciprocal dynamics by combiningresponsive magnetic profiles with the anisotropic characteristics ofshear-jammed systems. This strategy enables asymmetric spatiotemporal controlover motion transmission, a previously challenging feat in soft materials. Ourwork establishes a novel paradigm for designing non-reciprocal matter, bridginggranular physics with soft material engineering to realize functionalitiesessential for mechano-intelligent systems.</description>
      <author>example@mail.com (Chang Xu, Shuaihu Wang, Hong Wang, Xu Liu, Zemin Liu, Yiqiu Zhao, Wenqi Hu, Qin Xu)</author>
      <guid isPermaLink="false">2502.17083v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Evolution 6.0: Evolving Robotic Capabilities Through Generative Design</title>
      <link>http://arxiv.org/abs/2502.17034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IROS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出Evolution 6.0的概念，这是一种由生成式人工智能驱动的机器人技术进化。当机器人缺乏完成任务所需的工具时，它能够自主设计所需工具并学习如何使用它们来实现目标。&lt;h4&gt;背景&lt;/h4&gt;随着Generative AI的发展，机器人系统需要更加智能化和自适应以应对各种复杂任务的需求。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的机器人系统Evolution 6.0，使其能够在没有事先准备的情况下完成人类请求的任务，并且自主设计必要的工具和学习使用方法。&lt;h4&gt;方法&lt;/h4&gt;该系统包括两个关键模块：工具生成模块和动作生成模块。前者利用视觉-语言模型（VLM）和3D工具生成器来根据任务需求设计并制造专用工具；后者则通过自然语言指令转为机器人行动。具体实现中采用了QwenVLM、OpenVLA和Llama-Mesh等技术。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，该系统在10秒内能以90%的成功率生成所需工具，并且83.5%的物理和视觉泛化能力，在动作生成方面表现良好。然而，在运动和语义泛化上还有待提高。&lt;h4&gt;结论&lt;/h4&gt;尽管初步结果令人鼓舞，但为了进一步提升其在现实世界中的适用性，未来的工作将重点放在双臂操作、扩展任务范围以及增强环境理解等方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要的原始英文内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a new concept, Evolution 6.0, which represents the evolution ofrobotics driven by Generative AI. When a robot lacks the necessary tools toaccomplish a task requested by a human, it autonomously designs the requiredinstruments and learns how to use them to achieve the goal. Evolution 6.0 is anautonomous robotic system powered by Vision-Language Models (VLMs),Vision-Language Action (VLA) models, and Text-to-3D generative models for tooldesign and task execution. The system comprises two key modules: the ToolGeneration Module, which fabricates task-specific tools from visual and textualdata, and the Action Generation Module, which converts natural languageinstructions into robotic actions. It integrates QwenVLM for environmentalunderstanding, OpenVLA for task execution, and Llama-Mesh for 3D toolgeneration. Evaluation results demonstrate a 90% success rate for toolgeneration with a 10-second inference time, and action generation achieving83.5% in physical and visual generalization, 70% in motion generalization, and37% in semantic generalization. Future improvements will focus on bimanualmanipulation, expanded task capabilities, and enhanced environmentalinterpretation to improve real-world adaptability.</description>
      <author>example@mail.com (Muhammad Haris Khan, Artyom Myshlyaev, Artyom Lykov, Miguel Altamirano Cabrera, Dzmitry Tsetserukou)</author>
      <guid isPermaLink="false">2502.17034v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Task-Oriented 6-DoF Grasp Pose Detection in Clutters</title>
      <link>http://arxiv.org/abs/2502.16976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了任务导向的6自由度抓取姿态检测在杂乱环境中的问题，并构建了一个大规模的数据集以解决这一难题。提出了一种名为One-Stage TaskGrasp（OSTG）的方法，该方法采用了基于特定任务的对象点选择策略以及基于任务的手势生成模块来确定如何抓取。&lt;h4&gt;背景&lt;/h4&gt;人类会根据不同任务采取不同的抓握方式，例如刀具的把手用于切割而刀片则用于传递。现有的机器人抓握姿态检测研究在一定程度上考虑了这种任务导向性的问题，并且已经取得了一些进展；然而这些方法通常受制于低自由度夹爪类型或非杂乱设置。&lt;h4&gt;目的&lt;/h4&gt;为了解决更通用和实用的抓取模型问题，本文提出了一个名为Task-Oriented 6-DoF Grasp Pose Detection in Clutters（TO6DGC）的问题，并构造了一个大规模的数据集用于解决这一问题。&lt;h4&gt;方法&lt;/h4&gt;提出了OSTG方法，该方法采用了任务导向点选择策略来确定何处抓握，以及一种任务导向手势生成模块以决定如何抓取特定对象。实验是在构建的大型数据集上进行的。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，在多个指标下，本文提出的方法均优于现有基线；实际机器人实验也验证了OSTG方法在识别任务导向抓握点和6自由度抓握姿态上的优越性。&lt;h4&gt;结论&lt;/h4&gt;提出了一个处理杂乱环境中具有任务导向性的6自由度抓取问题的有效解决方案，并展示了其对于实现更通用且实用的机器人抓取模型的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的是关于人类基于不同任务选择不同的抓握方式，研究者们在机器人抓取姿态检测领域进行了一些任务导向性的工作并取得了进展。然而这些工作大多数局限于低自由度夹爪或者非杂乱场景下，并不适用于现实生活中的辅助需求。本文旨在开发更通用和实际的应用模型，提出了一个名为“任务导向的6自由度抓取姿态检测在复杂环境下的问题”，并且构建了一个大规模的数据集来支持这一研究。此外还提出了一种名为One-Stage TaskGrasp（OSTG）的方法来解决这个问题，并通过大量实验验证了该方法的有效性及其对于实际应用的意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In general, humans would grasp an object differently for different tasks,e.g., "grasping the handle of a knife to cut" vs. "grasping the blade to handover". In the field of robotic grasp pose detection research, some existingworks consider this task-oriented grasping and made some progress, but they aregenerally constrained by low-DoF gripper type or non-cluttered setting, whichis not applicable for human assistance in real life. With an aim to get moregeneral and practical grasp models, in this paper, we investigate the problemnamed Task-Oriented 6-DoF Grasp Pose Detection in Clutters (TO6DGC), whichextends the task-oriented problem to a more general 6-DOF Grasp Pose Detectionin Cluttered (multi-object) scenario. To this end, we construct a large-scale6-DoF task-oriented grasping dataset, 6-DoF Task Grasp (6DTG), which features4391 cluttered scenes with over 2 million 6-DoF grasp poses. Each grasp isannotated with a specific task, involving 6 tasks and 198 objects in total.Moreover, we propose One-Stage TaskGrasp (OSTG), a strong baseline to addressthe TO6DGC problem. Our OSTG adopts a task-oriented point selection strategy todetect where to grasp, and a task-oriented grasp generation module to decidehow to grasp given a specific task. To evaluate the effectiveness of OSTG,extensive experiments are conducted on 6DTG. The results show that our methodoutperforms various baselines on multiple metrics. Real robot experiments alsoverify that our OSTG has a better perception of the task-oriented grasp pointsand 6-DoF grasp poses.</description>
      <author>example@mail.com (An-Lan Wang, Nuo Chen, Kun-Yu Lin, Li Yuan-Ming, Wei-Shi Zheng)</author>
      <guid isPermaLink="false">2502.16976v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Design of a low-cost and lightweight 6 DoF bimanual arm for dynamic and contact-rich manipulation</title>
      <link>http://arxiv.org/abs/2502.16908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了ARMADA，一个专为动态操作研究设计的双臂机器人。它采用了低成本和易于组装的设计，能够执行打击、抢夺、锤击等复杂任务。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数机器人由于硬件限制（如高惯性设计、有限的柔韧性以及对昂贵扭矩传感器的依赖）难以处理具有挑战性的动态接触操作任务。&lt;h4&gt;目的&lt;/h4&gt;开发一种经济且灵活的双臂机器人，用于动态手动动作的研究和实验。&lt;h4&gt;方法&lt;/h4&gt;ARMADA采用了低惯量、反驱能力强的执行器，并使用了轻质设计以及现成可用组件和3D打印链接。整个系统的成本仅为6100美元。&lt;h4&gt;主要发现&lt;/h4&gt;ARMADA可以达到每秒高达6.16米的速度，负载为2.5公斤；在真实环境中能完成诸如抢夺、锤击等动态操作任务，并且通过强化学习训练后可以在现实世界中进行零样本迁移。&lt;h4&gt;结论&lt;/h4&gt;ARMADA的开源性质提供了详细的组装指南、CAD模型和仿真代码，方便研究者使用。推荐观看补充视频以获得更多信息。&lt;h4&gt;翻译&lt;/h4&gt;该摘要介绍了ARMADA（用于操纵与动态动作的可承受机器人），一个专为动态操作研究设计的双臂机器人。它采用了低成本且易于在实验室中组装的设计，结合低惯量、反驱能力执行器和轻质结构，使用现成组件及3D打印链接构建。整个系统的成本仅为6100美元，每只手臂的速度可达每秒6.16米，与大多数协作机器人相比几乎快了一倍，负载为2.5公斤。展示的动态操作包括抢夺、锤击和双手抛掷等任务，并且在强化学习中表现出色：能够在模拟环境中训练非抓取式操纵策略并在现实世界中实现零样本迁移；以及通过人体动作阴影进行双臂物体抛掷研究。ARMADA是完全开源的，包含详细的组装说明、CAD模型、URDFs（Universal Robot Description Format）、仿真和学习代码。强烈推荐查看补充视频了解更多信息：https://sites.google.com/view/im2-humanoid-arm&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic and contact-rich object manipulation, such as striking, snatching, orhammering, remains challenging for robotic systems due to hardware limitations.Most existing robots are constrained by high-inertia design, limitedcompliance, and reliance on expensive torque sensors. To address this, weintroduce ARMADA (Affordable Robot for Manipulation and Dynamic Actions), a 6degrees-of-freedom bimanual robot designed for dynamic manipulation research.ARMADA combines low-inertia, back-drivable actuators with a lightweight design,using readily available components and 3D-printed links for ease of assembly inresearch labs. The entire system, including both arms, is built for just$6,100. Each arm achieves speeds up to 6.16m/s, almost twice that of mostcollaborative robots, with a comparable payload of 2.5kg. We demonstrate ARMADAcan perform dynamic manipulation like snatching, hammering, and bimanualthrowing in real-world environments. We also showcase its effectiveness inreinforcement learning (RL) by training a non-prehensile manipulation policy insimulation and transferring it zero-shot to the real world, as well as humanmotion shadowing for dynamic bimanual object throwing. ARMADA is fullyopen-sourced with detailed assembly instructions, CAD models, URDFs,simulation, and learning codes. We highly recommend viewing the supplementaryvideo at https://sites.google.com/view/im2-humanoid-arm.</description>
      <author>example@mail.com (Jaehyung Kim, Jiho Kim, Dongryung Lee, Yujin Jang, Beomjoon Kim)</author>
      <guid isPermaLink="false">2502.16908v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Gazing at Failure: Investigating Human Gaze in Response to Robot Failure in Collaborative Tasks</title>
      <link>http://arxiv.org/abs/2502.16899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  this paper is accepted in HRI conference as a full paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了人类的非语言行为，特别是目光动态如何作为机器人故障的信号，并分析不同类型的机器人失败对人们感知机器人的影响。&lt;h4&gt;背景&lt;/h4&gt;机器人在与人类用户合作完成任务时可能会出现错误，这些错误会损害它们作为团队成员的信任度。检测和恢复此类故障对于维持有效的信任水平至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过分析人类的目光动态来检测机器人未察觉的失败，并探讨不同类型及时间发生的失败如何影响人们对机器人的看法。&lt;h4&gt;方法&lt;/h4&gt;进行了一项针对27名参与者的研究，他们与移动机械臂协作解决拼图游戏。机器人被编程以经历两种类型的故障——执行型和决策型，在任务开始或结束时发生，且有时会承认这些故障的存在。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现显示，不同类型及时间发生的机器人的失败显著影响了参与者的目光行为和对机器人的看法。例如，执行性故障导致更多的目光转移以及更关注机器人；而决策性故障则在任务末尾时导致目标区域间的眼球运动熵降低。&lt;h4&gt;结论&lt;/h4&gt;研究表明，通过观察人类的目光动态可以作为识别机器人故障及其类型的可靠指标，并且这些信息可用来预测适当的恢复行动。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robots are prone to making errors, which can negatively impact theircredibility as teammates during collaborative tasks with human users. Detectingand recovering from these failures is crucial for maintaining effective levelof trust from users. However, robots may fail without being aware of it. Oneway to detect such failures could be by analysing humans' non-verbal behavioursand reactions to failures. This study investigates how human gaze dynamics cansignal a robot's failure and examines how different types of failures affectpeople's perception of robot. We conducted a user study with 27 participantscollaborating with a robotic mobile manipulator to solve tangram puzzles. Therobot was programmed to experience two types of failures -- executional anddecisional -- occurring either at the beginning or end of the task, with orwithout acknowledgement of the failure. Our findings reveal that the type andtiming of the robot's failure significantly affect participants' gaze behaviourand perception of the robot. Specifically, executional failures led to moregaze shifts and increased focus on the robot, while decisional failuresresulted in lower entropy in gaze transitions among areas of interest,particularly when the failure occurred at the end of the task. These resultshighlight that gaze can serve as a reliable indicator of robot failures andtheir types, and could also be used to predict the appropriate recoveryactions.</description>
      <author>example@mail.com (Ramtin Tabatabaei, Vassilis Kostakos, Wafa Johal)</author>
      <guid isPermaLink="false">2502.16899v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Variations of Augmented Lagrangian for Robotic Multi-Contact Simulation</title>
      <link>http://arxiv.org/abs/2502.16898v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个新的多接触非线性互补问题（NCP）求解器系列，基于增广拉格朗日理论。&lt;h4&gt;背景&lt;/h4&gt;多接触非线性互补问题是机器人模拟中自然出现的挑战。在涉及密集接触和刚性相互作用的情况下，同时实现高精度和效率是一个重大难题。&lt;h4&gt;目的&lt;/h4&gt;介绍一类新的多接触NCP求解器，并展示其在机器人模拟中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;通过迭代替代问题解决方案并更新原始-对偶变量的方式，将传统的增广拉格朗日理论应用于处理多接触NCP。提出了两种针对机器人仿真的特定变体：级联牛顿增广拉格朗日（CANAL）和基于子系统的交替方向乘子法（SubADMM）。&lt;h4&gt;主要发现&lt;/h4&gt;CANAL能够准确且稳健地管理多接触NCP，而SubADMM则提供了计算速度、可扩展性和并行处理能力方面的优势。&lt;h4&gt;结论&lt;/h4&gt;所提出的求解器框架在各种机器人操纵场景中展示了其有效性，特别是在高自由度和大量接触点的多体系统中表现出了显著的优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的描述已经被中文内容替代，作为对原文本信息的理解与总结，无需额外添加此键值对。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The multi-contact nonlinear complementarity problem (NCP) is a naturallyarising challenge in robotic simulations. Achieving high performance in termsof both accuracy and efficiency remains a significant challenge, particularlyin scenarios involving intensive contacts and stiff interactions. In thisarticle, we introduce a new class of multi-contact NCP solvers based on thetheory of the Augmented Lagrangian (AL). We detail how the standard derivationof AL in convex optimization can be adapted to handle multi-contact NCP throughthe iteration of surrogate problem solutions and the subsequent update ofprimal-dual variables. Specifically, we present two tailored variations of ALfor robotic simulations: the Cascaded Newton-based Augmented Lagrangian (CANAL)and the Subsystem-based Alternating Direction Method of Multipliers (SubADMM).We demonstrate how CANAL can manage multi-contact NCP in an accurate and robustmanner, while SubADMM offers superior computational speed, scalability, andparallelizability for high degrees-of-freedom multibody systems with numerouscontacts. Our results showcase the effectiveness of the proposed solverframework, illustrating its advantages in various robotic manipulationscenarios.</description>
      <author>example@mail.com (Jeongmin Lee, Minji Lee, Sunkyung Park, Jinhee Yun, Dongjun Lee)</author>
      <guid isPermaLink="false">2502.16898v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Primitive-Planner: An Ultra Lightweight Quadrotor Planner with Time-optimal Primitives</title>
      <link>http://arxiv.org/abs/2502.16882v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种超轻量级四旋翼飞行器轨迹规划方法，该方法利用时间最优的基本运动单元，在保证轨迹质量和系统轻量化的同时实现高效率。&lt;h4&gt;背景&lt;/h4&gt;目前许多研究致力于解决四旋翼飞行器同时满足高质量轨迹和低计算负载的问题，但现有的解决方案与实际需求之间仍存在差距。&lt;h4&gt;目的&lt;/h4&gt;提出一种超轻量级的四旋翼飞行器规划方法，以实现实时高效、碰撞安全且用户可定制的最优路径规划。&lt;h4&gt;方法&lt;/h4&gt;{'1': '设计了一种新的运动基本单元库，用于生成时间最优化和动力学可行性的轨迹，并实现离线计算。', '2': '提出了一种快速的碰撞检测算法，该算法具有确定的时间消耗且与采样分辨率无关。', '3': '根据用户的定义需求从安全的基本运动中选择最低成本的路径进行执行。', '4': '利用局部轨迹之间的转换关系来确保全局轨迹的平滑性。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '该方法能生成最短飞行时间和距离且计算负担最小化的最优轨迹。', '2': '现实世界中的挑战实验验证了所提方法在各种环境下的鲁棒性。'}&lt;h4&gt;结论&lt;/h4&gt;提出的规划方法通过减少在线计算的功率消耗，同时确保高质量的轨迹，并展示了其在实际应用中优越的时间效率和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; It is a significant requirement for a quadrotor trajectory planner tosimultaneously guarantee trajectory quality and system lightweight. Manyresearchers focus on this problem, but there's still a gap between theirperformance and our common wish. In this paper, we propose an ultra lightweightquadrotor planner with time-optimal primitives. Firstly, a novel motionprimitive library is proposed to generate time-optimal and dynamical feasibletrajectories offline. Secondly, we propose a fast collision checking methodwith a deterministic time consumption, independent of the sampling resolutionof the primitives. Finally, we select the minimum cost trajectory to executeamong the safe primitives based on user-defined requirements. The propsedtransformation relation between the local trajectories ensures the smoothnessof the global trajectory. The planner reduces unnecessary online computingpower consumption as much as possible, while ensuring a high-qualitytrajectory. Benchmark comparisons show that our method can generate theshortest flight time and distance of trajectory with the lowest computationoverload. Challenging real-world experiments validate the robustness of ourmethod.</description>
      <author>example@mail.com (Jialiang Hou, Neng Pan, Zhepei Wang, Jialin Ji, Yuxiang Guan, Zhongxue Gan, Fei Gao)</author>
      <guid isPermaLink="false">2502.16882v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Fast Finite-Time Sliding Mode Control for Chattering-Free Trajectory Tracking of Robotic Manipulators</title>
      <link>http://arxiv.org/abs/2502.16867v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种无颤振快速终端滑模控制（FTSMC）策略，用于提高三自由度机械臂的轨迹跟踪精度和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;传统滑模控制由于系统不确定性及抖动效应，在实现高精度高效轨迹追踪方面仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了一种新型无颤振快速终端滑模控制策略，以增强机械臂的跟踪精度和稳定性，并确保有限时间内收敛。&lt;h4&gt;方法&lt;/h4&gt;采用牛顿-欧拉动力学建立控制框架并转化为状态空间表示形式。通过引入改进后的滑动面以及基于李雅普诺夫稳定性的分析来设计控制器，从而减少颤振同时保持了传统滑模控制的优点如快速响应和强大的抗干扰能力。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果显示该策略在轨迹跟踪性能、更快的收敛速度及更强稳定性方面优于传统的PD滑模控制（PDSMC）和终端滑模控制（TSMC），尤其适用于高精度机器人应用。&lt;h4&gt;结论&lt;/h4&gt;提出的FTSMC方法为解决机械臂精确轨迹追踪中的挑战提供了有前景的解决方案，展示了其在实现高性能、快速响应及稳健控制方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;实现机器人手臂的精确且高效的轨迹跟踪依然是一个关键难题，因为传统滑模控制（SMC）面临系统不确定性和抖动效应的问题。本文提出了一种无颤振快速终端滑模控制（FTSMC）策略用于三自由度（3-DOF）机械臂设计中，旨在增强其跟踪精度和鲁棒性，并确保有限时间内的收敛。该控制系统框架基于牛顿-欧拉动力学建立并进一步转化为状态空间表示形式以捕捉系统的角位移与速度信息。通过采用改进的滑动面以及李雅普诺夫稳定性分析为基础的设计方法，所提出的FTSMC有效减轻了颤振现象，同时保留了传统滑模控制的优点，如快速响应和强大的干扰抑制能力。经过与常规PD滑模控制（PDSMC）及终端滑模控制（TSMC）的对比实验严格评估控制器性能后发现，本论文提出的方法在轨迹跟踪性能、更快的收敛速度以及更强稳定性方面都优于现有方法，为高精度机器人应用提供了有前景的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving precise and efficient trajectory tracking in robotic arms remains akey challenge due to system uncertainties and chattering effects inconventional sliding mode control (SMC). This paper presents a chattering-freefast terminal sliding mode control (FTSMC) strategy for athree-degree-of-freedom (3-DOF) robotic arm, designed to enhance trackingaccuracy and robustness while ensuring finite-time convergence. The controlframework is developed using Newton-Euler dynamics, followed by a state-spacerepresentation that captures the system's angular position and velocity. Byincorporating an improved sliding surface and a Lyapunov-based stabilityanalysis, the proposed FTSMC effectively mitigates chattering while preservingthe advantages of SMC, such as fast response and strong disturbance rejection.The controller's performance is rigorously evaluated through comparisons withconventional PD sliding mode control (PDSMC) and terminal sliding mode control(TSMC). Simulation results demonstrate that the proposed approach achievessuperior trajectory tracking performance, faster convergence, and enhancedstability compared to existing methods, making it a promising solution forhigh-precision robotic applications.</description>
      <author>example@mail.com (Momammad Ali Ranjbar)</author>
      <guid isPermaLink="false">2502.16867v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SLABIM: A SLAM-BIM Coupled Dataset in HKUST Main Building</title>
      <link>http://arxiv.org/abs/2502.16856v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025. Dataset aviliable at  https://github.com/HKUST-Aerial-Robotics/SLABIM . Video attachment at  https://youtu.be/7NckgY15ABQ&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;介绍了一种新的数据集SLABIM，该数据集结合了室内定位和建筑信息模型（BIM），旨在解决现有室内SLAM数据集中缺乏建筑物结构信息的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的室内SLAM数据集主要关注机器人传感器的数据采集，较少包含详细的建筑结构信息。这种不足限制了研究者们对真实场景中SLAM算法性能的全面评估和优化。&lt;h4&gt;目的&lt;/h4&gt;设计并建立首个结合BIM与SLAM技术的公开数据集SLABIM，用于促进室内定位系统的研究进展，并提高其在实际环境中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;该数据集基于香港科技大学的一栋大学建筑进行构建。首先建立了详细的BIM模型；然后通过多传感器套件采集真实场景下的数据，并生成施工后模型（As-Built Model）；最后，所有数据均进行了时间戳标注并组织成易于访问的形式。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果展示了SLABIM在三个关键任务上的性能表现：注册、定位以及语义地图构建。这些测试验证了该数据集的有效性和实用性。&lt;h4&gt;结论&lt;/h4&gt;通过发布开源的SLABIM数据集，研究者们可以更好地进行室内定位算法的研究，并且能够更有效地评估和改进相关技术的应用效果。&lt;h4&gt;翻译&lt;/h4&gt;现有室内同步定位与建图（SLAM）数据集主要关注机器人感知信息，缺乏对建筑结构的关注。为弥补这一不足，我们设计并构建了首个将SLAM和BIM相结合的数据集——SLABIM。该数据集提供了针对大学建筑的传感器数据，并将其分解、转换成易于使用的格式。通过多传感器套件采集多个会话下的数据及地图制作，我们获取到实际施工模型。所有相关数据均被时间戳标记并组织好，方便用户部署和测试使用。此外，我们部署了先进方法并在注册、定位和语义映射三项任务上报告实验结果，证明SLABIM的有效性和实用性。该数据集已在https://github.com/HKUST-Aerial-Robotics/SLABIM开放源代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing indoor SLAM datasets primarily focus on robot sensing, often lackingbuilding architectures. To address this gap, we design and construct the firstdataset to couple the SLAM and BIM, named SLABIM. This dataset provides BIM andSLAM-oriented sensor data, both modeling a university building at HKUST. Theas-designed BIM is decomposed and converted for ease of use. We employ amulti-sensor suite for multi-session data collection and mapping to obtain theas-built model. All the related data are timestamped and organized, enablingusers to deploy and test effectively. Furthermore, we deploy advanced methodsand report the experimental results on three tasks: registration, localizationand semantic mapping, demonstrating the effectiveness and practicality ofSLABIM. We make our dataset open-source athttps://github.com/HKUST-Aerial-Robotics/SLABIM.</description>
      <author>example@mail.com (Haoming Huang, Zhijian Qiao, Zehuan Yu, Chuhao Liu, Shaojie Shen, Fumin Zhang, Huan Yin)</author>
      <guid isPermaLink="false">2502.16856v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Characterizing Structured versus Unstructured Environments based on Pedestrians' and Vehicles' Motion Trajectories</title>
      <link>http://arxiv.org/abs/2502.16847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过分析不同环境类型中行人和车辆的轨迹特征，提出了一种区分结构化和非结构化环境的方法，并利用K-means聚类和广义线性模型对现有数据集进行了分类。&lt;h4&gt;背景&lt;/h4&gt;行人在接近车辆运行时的行为在无结构环境中与有结构环境中存在差异。然而，现有的行人和车辆的轨迹数据集并未根据它们所处环境的性质进行分类，且关于无结构和有结构环境的定义难以量化。&lt;h4&gt;目的&lt;/h4&gt;开发一种更定量的方法来区分不同类型的行进环境，并为现有数据集提供一个基于环境特性的分类。&lt;h4&gt;方法&lt;/h4&gt;采用从各种轨迹中提取出来的特征（如平均速度、轨迹变化率）进行分析，利用K-means聚类和广义线性模型对这些特征进行处理以量化不同环境类型之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;行人轨迹的变异性和停车频率以及行人的密度在两种类型的环境中表现出明显的不同，可以用来分类现有的数据集。&lt;h4&gt;结论&lt;/h4&gt;通过对现有数据集中行人与车辆轨迹行为的研究，提出了一种区分结构化和非结构化环境的新方法。这种方法有助于改善自动驾驶汽车的行为预测算法。&lt;h4&gt;翻译&lt;/h4&gt;行人在接近车辆运行时的行为在无结构环境中（如繁忙的街道）与有结构环境中（如专用的人行道或公园）存在差异。这种行为上的差异对于开发适用于自动行驶车辆的轨迹预测算法非常重要，因为现有的行人和车辆的轨迹数据集并未根据它们所处环境的性质进行分类，并且关于非结构化和结构化环境的标准定义通常难以量化。本文通过分析不同数据集中提取出的各种特征（例如平均速度、路径变化率），应用K-means聚类与广义线性模型，提出了一种新方法来区分这些不同的环境类型。研究结果表明，行人轨迹的变异性和停止频率以及行人的密度在两种类型的环境中显著不同，可以用于现有数据集的分类。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ITSC55140.2022.9921899&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory behaviours of pedestrians and vehicles operating close to eachother can be different in unstructured compared to structured environments.These differences in the motion behaviour are valuable to be considered in thetrajectory prediction algorithm of an autonomous vehicle. However, theavailable datasets on pedestrians' and vehicles' trajectories that are commonlyused as benchmarks for trajectory prediction have not been classified based onthe nature of their environment. On the other hand, the definitions providedfor unstructured and structured environments are rather qualitative and hard tobe used for justifying the type of a given environment. In this paper, we havecompared different existing datasets based on a couple of extracted trajectoryfeatures, such as mean speed and trajectory variability. Through K-meansclustering and generalized linear models, we propose more quantitative measuresfor distinguishing the two different types of environments. Our results showthat features such as trajectory variability, stop fraction and density ofpedestrians are different among the two environmental types and can be used toclassify the existing datasets.</description>
      <author>example@mail.com (Mahsa Golchoubian, Moojan Ghafurian, Nasser Lashgarian Azad, Kerstin Dautenhahn)</author>
      <guid isPermaLink="false">2502.16847v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Online Friction Coefficient Identification for Legged Robots on Slippery Terrain Using Smoothed Contact Gradients</title>
      <link>http://arxiv.org/abs/2502.16843v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, IEEE RA-L (2025) accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在线识别腿足机器人在滑坡地形上摩擦系数的框架，通过最小化实际状态和预测状态之间的残差来解决这一问题。&lt;h4&gt;背景&lt;/h4&gt;在腿足机器人的动态环境下，尤其是在滑坡地形上，准确地估计地面摩擦力对机器人的稳定性和效率至关重要。传统的摩擦系数识别方法在面对非光滑接触动力学时会产生无信息梯度。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于刚体接触动力学的优化问题框架，通过引入平滑处理后的互补条件下的库仑摩擦来解决非光滑接触动力学带来的挑战，并利用拒绝法过滤掉不适宜的数据。&lt;h4&gt;方法&lt;/h4&gt;该框架将优化问题参数化为最小化实际状态和预测状态之间的残差之和。利用了分析的光滑梯度，解决了由非平滑接触动力学引发的无信息梯度的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示，在各种初始条件下，所提出的框架能够快速且一致地识别出摩擦系数，并在使用四足机器人平台KAIST HOUND进行实验时验证了该框架的有效性。&lt;h4&gt;结论&lt;/h4&gt;这项工作提供了一种有效的在线方法来估计腿足机器人的摩擦系数，从而为实际应用中的运动规划和控制奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2025.3541428&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an online friction coefficient identification frameworkfor legged robots on slippery terrain. The approach formulates the optimizationproblem to minimize the sum of residuals between actual and predicted statesparameterized by the friction coefficient in rigid body contact dynamics.Notably, the proposed framework leverages the analytic smoothed gradient ofcontact impulses, obtained by smoothing the complementarity condition ofCoulomb friction, to solve the issue of non-informative gradients induced fromthe nonsmooth contact dynamics. Moreover, we introduce the rejection method tofilter out data with high normal contact velocity following contact initiationsduring friction coefficient identification for legged robots. To validate theproposed framework, we conduct the experiments using a quadrupedal robotplatform, KAIST HOUND, on slippery and nonslippery terrain. We observe that ourframework achieves fast and consistent friction coefficient identificationwithin various initial conditions.</description>
      <author>example@mail.com (Hajun Kim, Dongyun Kang, Min-Gyu Kim, Gijeong Kim, Hae-Won Park)</author>
      <guid isPermaLink="false">2502.16843v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>NavigateDiff: Visual Predictors are Zero-Shot Navigation Assistants</title>
      <link>http://arxiv.org/abs/2502.13894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的导航方法，通过将大型视觉-语言模型与扩散网络结合来实现零样本学习环境下的机器人导航。这种方法利用预训练的基础模型进行知识迁移和泛化能力的传递。&lt;h4&gt;背景&lt;/h4&gt;家庭机器人在陌生环境中面临挑战，需要能够识别并推理关于新装饰和布局的信息。现有的强化学习方法无法直接应用于新的环境，因为它们通常依赖于广泛的映射和探索，导致耗时且效率低下。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，论文试图将预训练基础模型的逻辑知识和泛化能力转移到零样本导航中。&lt;h4&gt;方法&lt;/h4&gt;通过结合大型视觉-语言模型与扩散网络构建了一个视觉预测器，能够连续预测代理人在下一步可能观察到的内容。此外，为适应导航的时间特性，引入了历史时间信息以确保预测图像与导航场景对齐。最后设计了一种信息融合框架，将预测的未来帧嵌入目标导向策略中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在模拟和真实环境中增强了导航控制，并展示了其强大的鲁棒性和通用性。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的实验验证了所提出方法的有效性和效率，展现了它改善机器人在各种场景下导航能力的巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Navigating unfamiliar environments presents significant challenges forhousehold robots, requiring the ability to recognize and reason about noveldecoration and layout. Existing reinforcement learning methods cannot bedirectly transferred to new environments, as they typically rely on extensivemapping and exploration, leading to time-consuming and inefficient. To addressthese challenges, we try to transfer the logical knowledge and thegeneralization ability of pre-trained foundation models to zero-shotnavigation. By integrating a large vision-language model with a diffusionnetwork, our approach named \mname ~constructs a visual predictor thatcontinuously predicts the agent's potential observations in the next step whichcan assist robots generate robust actions. Furthermore, to adapt the temporalproperty of navigation, we introduce temporal historical information to ensurethat the predicted image is aligned with the navigation scene. We thencarefully designed an information fusion framework that embeds the predictedfuture frames as guidance into goal-reaching policy to solve downstream imagenavigation tasks. This approach enhances navigation control and generalizationacross both simulated and real-world environments. Through extensiveexperimentation, we demonstrate the robustness and versatility of our method,showcasing its potential to improve the efficiency and effectiveness of roboticnavigation in diverse settings.</description>
      <author>example@mail.com (Yiran Qin, Ao Sun, Yuze Hong, Benyou Wang, Ruimao Zhang)</author>
      <guid isPermaLink="false">2502.13894v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
  <item>
      <title>Appeal prediction for AI up-scaled Images</title>
      <link>http://arxiv.org/abs/2502.14013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过开发一个包含136个基础图像和五种不同上采样方法的全面数据集，评估了各种深度学习模型在图像上采样任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;基于DNN或AI的上采样算法由于机器学习的进步变得越来越流行。然而，缺乏对真实世界图像范围广泛且包含主观评价的表现评测。&lt;h4&gt;目的&lt;/h4&gt;填补现有研究空白，通过对大量实际图像进行主观和客观评估来比较不同上采样方法的效果，并训练用于检测这些方法的深度学习模型。&lt;h4&gt;方法&lt;/h4&gt;使用136个基础图像和五种不同的上采样方法（Real-ESRGAN, BSRGAN, waifu2x, KXNet以及Lanczos）构建数据集，总共包含1496张注释图像。通过众包服务进行主观评价，并开发了开源工具AVRate Voyager来辅助标注。&lt;h4&gt;主要发现&lt;/h4&gt;在主观评价中，Real-ESRGAN和BSRGAN表现最佳。训练的深度神经网络能够有效地检测不同的上采样方法。同时评估了现有最先进的图像吸引力和质量模型的表现，结果表明这些模型预测性能不高，并因此开发了自己的两种新模型以改进性能。&lt;h4&gt;结论&lt;/h4&gt;研究证明了主观评价的重要性以及对广泛数据集进行详细评测的价值，并通过提供开源工具与数据促进了该领域的进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于深度神经网络或人工智能的上采样算法由于机器学习的进步而变得越来越流行。使用卷积神经网络、生成对抗网络或者混合方法的各种上采样模型已发表。大多数模型仅利用PSNR和SSIM进行评估，或是通过少量示例图像来进行评价。然而，缺乏广泛的现实世界图像以及主观评价的表现评测，这是我们研究论文要解决的问题。为此，我们描述了开发的数据集，该数据集使用136个基础图像并采用五种不同的上采样方法，即Real-ESRGAN、BSRGAN、waifu2x、KXNet和Lanczos。总体而言，整个数据集中包含有1496张注释的图像。我们的数据集标注专注于图像吸引力，并使用众包工具AVRate Voyager进行操作。我们评估了不同方法在吸引力上的表现，结果显示Real-ESRGAN和BSRGAN是最好的。此外，我们也训练了一个深度神经网络来检测用于上采样的哪种方法，在评估中这些模型表现出较好的总体性能。除此之外，还对现有最先进的图像吸引力与质量模型进行了评估，结果表明没有一个模型显示出高的预测性能，因此我们又开发了两个自己的方法。第一个采用迁移学习并具有最佳表现，第二个模型则使用信号基特征和随机森林模型并具备整体优秀的性能。为促进开放科学领域的进一步研究，我们将数据集、标注工具及实现方法对外公开分享。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; DNN- or AI-based up-scaling algorithms are gaining in popularity due to theimprovements in machine learning. Various up-scaling models using CNNs, GANs ormixed approaches have been published. The majority of models are evaluatedusing PSRN and SSIM or only a few example images. However, a performanceevaluation with a wide range of real-world images and subjective evaluation ismissing, which we tackle in the following paper. For this reason, we describeour developed dataset, which uses 136 base images and five different up-scalingmethods, namely Real-ESRGAN, BSRGAN, waifu2x, KXNet, and Lanczos. Overall thedataset consists of 1496 annotated images. The labeling of our dataset focusedon image appeal and has been performed using crowd-sourcing employing ouropen-source tool AVRate Voyager. We evaluate the appeal of the differentmethods, and the results indicate that Real-ESRGAN and BSRGAN are the best.Furthermore, we train a DNN to detect which up-scaling method has been used,the trained models have a good overall performance in our evaluation. Inaddition to this, we evaluate state-of-the-art image appeal and quality models,here none of the models showed a high prediction performance, therefore we alsotrained two own approaches. The first uses transfer learning and has the bestperformance, and the second model uses signal-based features and a randomforest model with good overall performance. We share the data andimplementation to allow further research in the context of open science.</description>
      <author>example@mail.com (Steve Göring, Rasmus Merten, Alexander Raake)</author>
      <guid isPermaLink="false">2502.14013v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Game State and Spatio-temporal Action Detection in Soccer using Graph Neural Networks and 3D Convolutional Networks</title>
      <link>http://arxiv.org/abs/2502.15462v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合视觉信息和比赛状态信息的时空动作检测方法，通过图神经网络与先进的3D卷积神经网络相结合，实现了更好的性能。&lt;h4&gt;背景&lt;/h4&gt;足球数据分析依赖于两种数据源：球员在场上的位置以及他们执行的动作序列。大约每场比赛有2000个球事件需要进行精确和详尽的标注，这是一项繁琐且成本高昂的手动任务。&lt;h4&gt;目的&lt;/h4&gt;为了减少人工注释的工作量并提高自动化程度，本文旨在探索结合视觉信息和比赛状态信息的方法来改进动作检测算法。&lt;h4&gt;方法&lt;/h4&gt;假设职业球员的行为是相互依赖的，并认为加入周围球员的信息（例如位置、速度和团队归属）可以增强纯视觉预测。为此，作者提出了一种基于图神经网络与3D卷积神经网络相结合的方法。&lt;h4&gt;主要发现&lt;/h4&gt;通过将比赛状态信息整合进模型中，该方法展示了改进后的性能指标。&lt;h4&gt;结论&lt;/h4&gt;结合视觉和游戏状态数据能够提高时空动作检测的准确性，并为自动化足球分析提供了一个有前景的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：足球数据分析依赖于两种数据源：球员在场上的位置以及他们执行的动作序列。大约每场比赛有2000个球事件需要进行精确且详尽的手动注释，这是一项繁琐和成本高昂的任务。尽管最先进的时空动作检测方法显示出自动化此任务的前景，但它们缺乏对游戏上下文的理解。假设职业球员的行为是相互依赖的，我们假定将周围球员的信息（如位置、速度及团队归属）加入到纯粹视觉预测中可以增强其准确性。我们提出了一种结合图神经网络与最先进的3D卷积神经网络相结合的方法，展示了通过整合比赛状态信息而改进的性能指标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soccer analytics rely on two data sources: the player positions on the pitchand the sequences of events they perform. With around 2000 ball events pergame, their precise and exhaustive annotation based on a monocular video streamremains a tedious and costly manual task. While state-of-the-artspatio-temporal action detection methods show promise for automating this task,they lack contextual understanding of the game. Assuming professional players'behaviors are interdependent, we hypothesize that incorporating surroundingplayers' information such as positions, velocity and team membership canenhance purely visual predictions. We propose a spatio-temporal actiondetection approach that combines visual and game state information via GraphNeural Networks trained end-to-end with state-of-the-art 3D CNNs, demonstratingimproved metrics through game state integration.</description>
      <author>example@mail.com (Jeremie Ochin, Guillaume Devineau, Bogdan Stanciulescu, Sotiris Manitsaris)</author>
      <guid isPermaLink="false">2502.15462v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Mantis: Lightweight Calibrated Foundation Model for User-Friendly Time Series Classification</title>
      <link>http://arxiv.org/abs/2502.15637v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，人们对开发能够跨多种下游任务泛化的时序数据基础模型产生了浓厚的兴趣。虽然已经引入了大量面向预测的基础模型，但针对时间序列分类的专门模型却相对稀缺。&lt;h4&gt;目的&lt;/h4&gt;为了弥补这一空白，我们提出了一种新的开源基础模型Mantis，该模型基于视觉变换器（ViT）架构，并通过对比学习方法进行预训练，以用于时间序列分类任务。&lt;h4&gt;方法&lt;/h4&gt;Mantis模型采用了对比学习方法来进行预训练。此外，还提出了几个适配器来处理多变量设置，这可以减少内存需求并建模通道间的相互依赖性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，无论是在骨干网络被冻结的情况下还是在经过微调之后，Mantis都优于现有的基础模型，并且实现了最低的校准误差。&lt;h4&gt;结论&lt;/h4&gt;Mantis为时间序列分类提供了一种有效的解决方案，同时通过引入适配器机制处理多变量设置问题，进一步优化了性能和内存使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, there has been increasing interest in developing foundationmodels for time series data that can generalize across diverse downstreamtasks. While numerous forecasting-oriented foundation models have beenintroduced, there is a notable scarcity of models tailored for time seriesclassification. To address this gap, we present Mantis, a new open-sourcefoundation model for time series classification based on the Vision Transformer(ViT) architecture that has been pre-trained using a contrastive learningapproach. Our experimental results show that Mantis outperforms existingfoundation models both when the backbone is frozen and when fine-tuned, whileachieving the lowest calibration error. In addition, we propose severaladapters to handle the multivariate setting, reducing memory requirements andmodeling channel interdependence.</description>
      <author>example@mail.com (Vasilii Feofanov, Songkang Wen, Marius Alonso, Romain Ilbert, Hongbo Guo, Malik Tiomoko, Lujia Pan, Jianfeng Zhang, Ievgen Redko)</author>
      <guid isPermaLink="false">2502.15637v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>A Universal Framework for Compressing Embeddings in CTR Prediction</title>
      <link>http://arxiv.org/abs/2502.15355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by DASFAA2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种模型无关的嵌入压缩框架（MEC），用于压缩点击率预测中的嵌入表，以减少内存使用和延迟，同时保持推荐质量。&lt;h4&gt;背景&lt;/h4&gt;准确的点击率预测对在线广告和推荐系统至关重要。虽然深度学习技术进步提高了捕捉特征交互和理解用户兴趣的能力，但是优化嵌入层仍常常被忽视。大型嵌入表会超过GPU内存限制，并且需要存储在CPU内存中，导致高内存消耗和频繁的数据传输延迟。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的压缩方法来解决现有推荐系统中的内存使用量过大和延迟问题。&lt;h4&gt;方法&lt;/h4&gt;1. 应用流行度加权正则化以平衡高频和低频特征的代码分布。2. 集成对比学习机制，确保量化码的均匀分布，提高嵌入的独特性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在三个数据集上，我们的方法能够将内存使用量减少超过50倍，并且保持或提高了推荐性能。&lt;h4&gt;结论&lt;/h4&gt;提出的MEC框架可以有效地压缩嵌入表，降低内存消耗和延迟，同时不牺牲推荐质量。这为构建高效、大规模的推荐系统提供了一个新的途径。&lt;h4&gt;翻译&lt;/h4&gt;准确点击率预测对在线广告与推荐系统至关重要。近期深度学习的进步提高了捕捉特征交互及理解用户兴趣的能力，但优化嵌入层常被忽视。本文提出了一种模型无关的嵌入压缩（MEC）框架，通过量化预训练嵌入来压缩嵌入表，在不牺牲推荐质量的前提下减少内存使用和延迟。实验表明该方法在三个数据集上可以将内存消耗降低50倍以上，并保持或提高推荐性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate click-through rate (CTR) prediction is vital for online advertisingand recommendation systems. Recent deep learning advancements have improved theability to capture feature interactions and understand user interests. However,optimizing the embedding layer often remains overlooked. Embedding tables,which represent categorical and sequential features, can become excessivelylarge, surpassing GPU memory limits and necessitating storage in CPU memory.This results in high memory consumption and increased latency due to frequentGPU-CPU data transfers. To tackle these challenges, we introduce aModel-agnostic Embedding Compression (MEC) framework that compresses embeddingtables by quantizing pre-trained embeddings, without sacrificing recommendationquality. Our approach consists of two stages: first, we applypopularity-weighted regularization to balance code distribution between high-and low-frequency features. Then, we integrate a contrastive learning mechanismto ensure a uniform distribution of quantized codes, enhancing thedistinctiveness of embeddings. Experiments on three datasets reveal that ourmethod reduces memory usage by over 50x while maintaining or improvingrecommendation performance compared to existing models. The implementation codeis accessible in our project repository https://github.com/USTC-StarTeam/MEC.</description>
      <author>example@mail.com (Kefan Wang, Hao Wang, Kenan Song, Wei Guo, Kai Cheng, Zhi Li, Yong Liu, Defu Lian, Enhong Chen)</author>
      <guid isPermaLink="false">2502.15355v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Drug-Target Interaction/Affinity Prediction: Deep Learning Models and Advances Review</title>
      <link>http://arxiv.org/abs/2502.15346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  64 pages, 7 figures, 10 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;药物研发是一个耗时且成本高昂的过程，涉及到从目标结构检测到获得食品药品监督管理局(FDA)批准的多个步骤，并常伴随着安全问题。&lt;h4&gt;背景&lt;/h4&gt;传统方法在预测药物与靶标之间的相互作用方面存在局限性，特别是在捕捉复杂关系上。为此，深度学习模型被提出以克服这一挑战并提供精确和高效的预测结果。&lt;h4&gt;目的&lt;/h4&gt;通过概述有前途的研究方向和模型，各具有不同解决方案但针对同一问题，这篇论文旨在为研究人员提供更多准确且高效地预测药物-靶标相互作用的方法，从而加速更有效药物的开发。&lt;h4&gt;方法&lt;/h4&gt;从2016年到2025年间，总共分析了基于机器学习（主要是深度学习和图神经网络）的不同框架下的180种药物-靶标交互预测方法。&lt;h4&gt;主要发现&lt;/h4&gt;论文讨论了这些模型的新颖性、架构以及输入表示。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的技术和更优的方法，有可能加速药物研发过程并提高药物安全性。深度学习和图神经网络等先进技术在该领域展现出巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;药物发现仍是一个缓慢且成本高昂的过程，包括从目标结构检测到获得FDA批准的多个步骤，并经常伴随着安全问题。准确预测药物与其靶标之间的相互作用以及使用更好的方法和技术开发新药，具有极大可能加速这一过程，最终实现更快地提供救命药物。传统的药物-靶标交互预测方法显示出局限性，在捕捉复杂关系方面尤其如此。因此，深度学习模型被提出以通过其精确和高效的最终结果克服这些挑战。通过概述有前途的研究方向和模型，各具不同的解决方案但针对同一问题，这篇论文旨在为研究人员提供更准确且高效地预测药物-靶标相互作用的方法的更好理解，从而加速开发出更有效的药物。在2016年到2025年间，总共分析了基于机器学习（主要是深度学习和图神经网络）的不同框架下的180种药物-靶标交互预测方法。此外，该论文还讨论了这些模型的新颖性、架构以及输入表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug discovery remains a slow and expensive process that involves many steps,from detecting the target structure to obtaining approval from the Food andDrug Administration (FDA), and is often riddled with safety concerns. Accurateprediction of how drugs interact with their targets and the development of newdrugs by using better methods and technologies have immense potential to speedup this process, ultimately leading to faster delivery of life-savingmedications. Traditional methods used for drug-target interaction predictionshow limitations, particularly in capturing complex relationships between drugsand their targets. As an outcome, deep learning models have been presented toovercome the challenges of interaction prediction through their precise andefficient end results. By outlining promising research avenues and models, eachwith a different solution but similar to the problem, this paper aims to giveresearchers a better idea of methods for even more accurate and efficientprediction of drug-target interaction, ultimately accelerating the developmentof more effective drugs. A total of 180 prediction methods for drug-targetinteractions were analyzed throughout the period spanning 2016 to 2025 usingdifferent frameworks based on machine learning, mainly deep learning and graphneural networks. Additionally, this paper discusses the novelty, architecture,and input representation of these models.</description>
      <author>example@mail.com (Ali Vefghi, Zahed Rahmati, Mohammad Akbari)</author>
      <guid isPermaLink="false">2502.15346v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Fixed Variables: Expanding-variate Time Series Forecasting via Flat Scheme and Spatio-temporal Focal Learning</title>
      <link>http://arxiv.org/abs/2502.15296v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一个新的时间序列预测任务：扩展变量的时间序列预测（EVTSF），并提出了一个新的灵活的时空预测框架STEV来应对新增变量带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列预测（MTSF）长期是研究重点。传统研究假设固定的变量数量，但实际应用中随着新传感器部署，系统的变量会增多。&lt;h4&gt;目的&lt;/h4&gt;解决由于新变量加入导致的数据形状不一致和时空学习不平衡的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了STEV框架，包括一个新的Flat Scheme来处理数据形状不一致问题，并引入了一种新的时空聚焦学习策略，解决了对比学习与图表示之间的潜在冲突。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，STEV在扩展变量上的表现显著优于其竞争对手。即使只使用5%的观察值，STEV也能达到最先进的MTSF模型的表现水平。&lt;h4&gt;结论&lt;/h4&gt;STEV是一个通用性强、性能优越的时空预测框架，适用于实际应用中的各种扩展策略。&lt;h4&gt;翻译&lt;/h4&gt;多变量时间序列预测（MTSF）一直是研究的核心领域。传统方法假设固定的变量数量，但在现实世界的应用中，随着新传感器部署，Cyber-Physical系统的变量会增加。为此，我们提出了一个新的任务——扩展变量的时间序列预测（EVTSF）。这个任务面临两个挑战：一是处理新增变量导致的数据形状不一致问题；二是解决时空学习不平衡的问题，即由于需要及时操作而新加入的变量观测数据有限。为了解决这些问题，我们提出了一种灵活的时空预测框架STEV，它包含了一个新的Flat Scheme来应对数据形状不一致，并引入了新颖的时空聚焦学习策略。通过三个真实世界的数据集对EVTSF的表现进行了基准测试，并与三个可能解决方案（采用最先进的MTSF模型定制为EVSTF）进行了比较。实验结果表明，STEV在扩展变量上的表现显著优于竞争对手，甚至使用仅5%的新增时期观察值时也能达到最佳水平的效果。进一步研究各种扩展策略证实了STEV在现实应用中的通用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate Time Series Forecasting (MTSF) has long been a key researchfocus. Traditionally, these studies assume a fixed number of variables, but inreal-world applications, Cyber-Physical Systems often expand as new sensors aredeployed, increasing variables in MTSF. In light of this, we introduce a noveltask, Expanding-variate Time Series Forecasting (EVTSF). This task presentsunique challenges, specifically (1) handling inconsistent data shapes caused byadding new variables, and (2) addressing imbalanced spatio-temporal learning,where expanding variables have limited observed data due to the necessity fortimely operation. To address these challenges, we propose STEV, a flexiblespatio-temporal forecasting framework. STEV includes a new Flat Scheme totackle the inconsistent data shape issue, which extends the graph-basedspatio-temporal modeling architecture into 1D space by flattening the 2Dsamples along the variable dimension, making the model variable-scale-agnosticwhile still preserving dynamic spatial correlations through a holistic graph.We introduce a novel Spatio-temporal Focal Learning strategy that incorporatesa negative filter to resolve potential conflicts between contrastive learningand graph representation, and a focal contrastive loss as its core to guide theframework to focus on optimizing the expanding variables. We benchmark EVTSFperformance using three real-world datasets and compare it against threepotential solutions employing SOTA MTSF models tailored for EVSTF. Experimentalresults show that STEV significantly outperforms its competitors, particularlyon expanding variables. Notably, STEV, with only 5% of observations from theexpanding period, is on par with SOTA MTSF models trained with completeobservations. Further exploration of various expanding strategies underscoresthe generalizability of STEV in real-world applications.</description>
      <author>example@mail.com (Minbo Ma, Kai Tang, Huan Li, Fei Teng, Dalin Zhang, Tianrui Li)</author>
      <guid isPermaLink="false">2502.15296v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Learning Maritime Inventory Routing Optimization</title>
      <link>http://arxiv.org/abs/2502.15244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于机器学习的局部搜索方法，用于解决大规模海洋库存路由优化问题。&lt;h4&gt;背景&lt;/h4&gt;海洋物流中的库存路由优化问题是组合复杂性很高的问题。&lt;h4&gt;目的&lt;/h4&gt;为了提高大规模海洋库存路由问题解决方案的质量和效率。&lt;h4&gt;方法&lt;/h4&gt;集成图神经网络（GNN）来选择邻域以提升局部搜索的效率，实现对船舶邻近区域的有结构探索。&lt;h4&gt;主要发现&lt;/h4&gt;在大量实际案例中证明了该方法比直接使用混合整数规划法更加高效。&lt;h4&gt;结论&lt;/h4&gt;新方法提高了大规模海洋库存路由优化问题求解的质量和效率。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种基于机器学习的局部搜索方法，用于寻找大规模海上库存路由优化问题的可行解决方案。鉴于此类问题组合复杂度高，我们将图神经网络（GNN）为基础的邻域选择法融入进来以增强局部搜索效率。该方法实现了对船舶邻近区域有结构化的探索，在改善了解质量的同时也保证了计算效率。通过大量的实证实验验证，我们证明在真实案例中本研究的方法相比直接应用混合整数规划方法在求解时间上表现更优。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a machine learning-based local search approach for findingfeasible solutions of large-scale maritime inventory routing optimizationproblems. Given the combinatorial complexity of the problems, we integrate agraph neural network-based neighborhood selection method to enhance localsearch efficiency. Our approach enables a structured exploration of vesselneighborhoods, improving solution quality while maintaining computationalefficiency. Through extensive computational experiments on realistic instances,we demonstrate that our method outperforms direct mixed-integer programming insolution time.</description>
      <author>example@mail.com (Rui Chen, Defeng Liu, Nan Jiang, Rishabh Gupta, Mustafa Kilinc, Andrea Lodi)</author>
      <guid isPermaLink="false">2502.15244v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>SiMHand: Mining Similar Hands for Large-Scale 3D Hand Pose Pre-training</title>
      <link>http://arxiv.org/abs/2502.15251v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025. arXiv admin note: text overlap with arXiv:2409.09714&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于从野外视频中获取的手图像预训练三维手部姿态估计的框架SimHand。&lt;h4&gt;背景&lt;/h4&gt;现有的3D手部姿势预训练方法未能充分利用来自野外视频中的多样化手部图像的潜力。&lt;h4&gt;目的&lt;/h4&gt;为了实现可扩展性的预训练，准备了一个广泛的包含200多万张手部图像的数据池，并设计了基于对比学习的方法。&lt;h4&gt;方法&lt;/h4&gt;从最近的人类中心视频中收集超过2.0M的手部图像；通过关注手部相似性来提取区分信息，即非相同样本但具有类似手部姿势的成对样本；提出了一种新的对比学习方法，将类似的双手对在特征空间中嵌得更近，并根据样本间的距离自适应地调整对比学习损失权重。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法优于基于单张图像数据增强生成正例的传统对比学习方法。相比最先进的方法PeCLR，在FreiHand、DexYCB和AssemblyHands数据集上的表现分别提高了15%、10%和4%&lt;h4&gt;结论&lt;/h4&gt;我们的SimHand方法在预训练3D手部姿态估计方面提供了显著的性能改进。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种框架，用于从具有类似手部特征的手图像中进行三维手部姿势的预训练。使用大规模图像可以在各种任务中实现令人满意的结果，但现有的3D手部姿势预训练方法尚未充分利用从野外视频中获取的各种手部图像的潜力。为了促进可扩展性的预训练，我们首先准备了一个包含超过2.0M手部图像的数据池，并设计了一种基于对比学习的方法进行预训练。通过关注手部相似性来提取区分信息：即非相同的样本但具有类似的手部姿势对。然后，我们提出了一种新的对比学习方法，该方法将类似的双手对在特征空间中嵌得更近，并根据样本间的距离自适应地调整对比学习损失权重。实验表明，我们的方法优于基于单张图像数据增强生成正例的传统对比学习方法。在FreiHand、DexYCB和AssemblyHands数据集上，相比最先进的方法PeCLR，我们实现了显著的性能提升（分别提高了15%、10%和4%）。&lt;h4&gt;代码链接&lt;/h4&gt;https://github.com/ut-vision/SiMHand&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a framework for pre-training of 3D hand pose estimation fromin-the-wild hand images sharing with similar hand characteristics, dubbedSimHand. Pre-training with large-scale images achieves promising results invarious tasks, but prior methods for 3D hand pose pre-training have not fullyutilized the potential of diverse hand images accessible from in-the-wildvideos. To facilitate scalable pre-training, we first prepare an extensive poolof hand images from in-the-wild videos and design our pre-training method withcontrastive learning. Specifically, we collect over 2.0M hand images fromrecent human-centric videos, such as 100DOH and Ego4D. To extractdiscriminative information from these images, we focus on the similarity ofhands: pairs of non-identical samples with similar hand poses. We then proposea novel contrastive learning method that embeds similar hand pairs closer inthe feature space. Our method not only learns from similar samples but alsoadaptively weights the contrastive learning loss based on inter-sampledistance, leading to additional performance gains. Our experiments demonstratethat our method outperforms conventional contrastive learning approaches thatproduce positive pairs sorely from a single image with data augmentation. Weachieve significant improvements over the state-of-the-art method (PeCLR) invarious datasets, with gains of 15% on FreiHand, 10% on DexYCB, and 4% onAssemblyHands.  Our code is available at https://github.com/ut-vision/SiMHand.</description>
      <author>example@mail.com (Nie Lin, Takehiko Ohkawa, Yifei Huang, Mingfang Zhang, Minjie Cai, Ming Li, Ryosuke Furuta, Yoichi Sato)</author>
      <guid isPermaLink="false">2502.15251v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>ELIP: Enhanced Visual-Language Foundation Models for Image Retrieval</title>
      <link>http://arxiv.org/abs/2502.15682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架ELIP，用于增强大规模预训练的视觉-语言模型在文本到图像检索中的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的大型预训练视觉-语言模型难以直接应用于文本到图像重排序任务。&lt;h4&gt;目的&lt;/h4&gt;通过引入一个新框架来提高大规模预训练视觉-语言模型在文本到图像检索上的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了一种增强的语言-图像预训练（ELIP）方法，该方法利用文本查询预测一组视觉提示以调节ViT图像编码。此方法可以应用于CLIP/SigLIP和最先进的BLIP-2架构，并开发了适用于计算资源有限情况下的'学生友好型'最佳实践。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证，ELIP框架显著提高了CLIP/SigLIP的性能，并在文本到图像检索任务上超过了当前最先进模型BLIP-2的表现。&lt;h4&gt;结论&lt;/h4&gt;使用新架构和数据整理方法能够有效提升大规模视觉语言预训练模型用于文本到图像检索时的效果。&lt;h4&gt;翻译&lt;/h4&gt;该论文的目标是改进从文本到图像检索的性能。为此，研究者们提出了一种新的框架，可以增强大规模预训练视觉-语言模型的表现力，使其可用于重排序任务中。通过使用文本查询预测一组视觉提示来调节ViT图象编码的方法被称作ELIP，并且可以在常见的CLIP/SigLIP和最先进BLIP-2架构上应用。为了在计算资源有限的情况下训练该框架，研究者们开发了一种友好的实践方法，包括全局难例挖掘、大规模数据集的选择与整理等措施。评估方面，论文设立了两个新的分布外基准测试（Occluded COCO 和 ImageNet-R），用以衡量模型在不同领域中的零样本泛化能力。实验表明，由于新颖的架构和数据整理技术，增强后的网络显著提高了CLIP/SigLIP的表现，并且在文本到图像检索任务上超过了最先进的BLIP-2模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The objective in this paper is to improve the performance of text-to-imageretrieval. To this end, we introduce a new framework that can boost theperformance of large-scale pre-trained vision-language models, so that they canbe used for text-to-image re-ranking. The approach, Enhanced Language-ImagePre-training (ELIP), uses the text query to predict a set of visual prompts tocondition the ViT image encoding. ELIP can easily be applied to the commonlyused CLIP/SigLIP and the state-of-the-art BLIP-2 architectures. To train thearchitecture with limited computing resources, we develop a 'student friendly'best practice involving global hard sample mining, and selection and curationof a large-scale dataset. On the evaluation side, we set up two newout-of-distribution benchmarks, Occluded COCO and ImageNet-R, to assess thezero-shot generalisation of the models to different domains. Benefiting fromthe novel architecture and data curation, experiments show our enhanced networksignificantly boosts CLIP/SigLIP performance and outperforms thestate-of-the-art BLIP-2 model on text-to-image retrieval.</description>
      <author>example@mail.com (Guanqi Zhan, Yuanpei Liu, Kai Han, Weidi Xie, Andrew Zisserman)</author>
      <guid isPermaLink="false">2502.15682v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>GNN-Coder: Boosting Semantic Code Retrieval with Combined GNNs and Transformer</title>
      <link>http://arxiv.org/abs/2502.15202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GNN-Coder是一种基于图神经网络（GNN）的新型框架，用于利用抽象语法树（AST），该方法旨在提高代码检索任务中的结构和语义特征捕捉能力。&lt;h4&gt;背景&lt;/h4&gt;现有的依赖于序列模型的方法在大型项目中难以完全发挥代码内在结构依赖的作用，尤其是在处理复杂结构的代码片段时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;通过研究如何将GNN与Transformer结合来促进语义检索任务的发展，并引入一种新颖的图池化方法以及一个新的量化代码嵌入分布均匀性的度量指标MAM。&lt;h4&gt;方法&lt;/h4&gt;提出了基于抽象语法树（AST）的图神经网络框架GNN-Coder，该框架使用子节点数量作为关键特征来突出AST内的内在拓扑关系。同时引入了新的度量标准Mean Angular Margin (MAM) 来衡量代码嵌入分布的一致性和特征分离性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，GNN-Coder在CSN数据集上的MRR（平均准确率）提高了1%-10%，在CosQA数据集上的零样本性能显著提升了20%。&lt;h4&gt;结论&lt;/h4&gt;基于图神经网络的框架GNN-Coder可以有效提高代码检索任务中的结构和语义特征捕捉能力，从而增强模型对不同代码片段的区分能力和检索准确性。&lt;h4&gt;翻译&lt;/h4&gt;代码检索是现代软件开发的关键组成部分，在大型项目中尤为重要。然而，现有的序列模型方法往往未能充分利用代码固有的结构性依赖关系，导致在复杂结构代码片段上的检索性能不佳。本文介绍了一种基于图神经网络（GNN）的新框架——GNN-Coder，用于利用抽象语法树（AST）。这是首次尝试研究如何通过捕获代码的结构和语义特征来促进语义检索任务的发展，并引入了一个新的针对AST设计的图池化方法，使用子节点数量作为关键特性以突出显示AST内的内在拓扑关系。该设计有效集成了序列表示与层次表示，增强了模型捕捉代码结构和语义的能力。此外，还提出了一种新的度量指标——均值角度余量（MAM），用于量化代码嵌入分布的均匀性，提供了特征分离性的标准化衡量方法。所提出的这种方法实现了更低的MAM值，表明了更具有区分性的特征表示能力。这强调了GNN-Coder在区分不同代码片段方面的优越能力，并提高了检索准确性。实验结果表明，GNN-Coder显著提升了检索性能，在CSN数据集上平均准确率（MRR）提高了1%-10%，在CosQA数据集上的零样本性能显著提升20%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Code retrieval is a crucial component in modern software development,particularly in large-scale projects. However, existing approaches relying onsequence-based models often fail to fully exploit the structural dependenciesinherent in code, leading to suboptimal retrieval performance, particularlywith structurally complex code fragments. In this paper, we introduceGNN-Coder, a novel framework based on Graph Neural Network (GNN) to utilizeAbstract Syntax Tree (AST). We make the first attempt to study howGNN-integrated Transformer can promote the development of semantic retrievaltasks by capturing the structural and semantic features of code. We furtherpropose an innovative graph pooling method tailored for AST, utilizing thenumber of child nodes as a key feature to highlight the intrinsic topologicalrelationships within the AST. This design effectively integrates bothsequential and hierarchical representations, enhancing the model's ability tocapture code structure and semantics. Additionally, we introduce the MeanAngular Margin (MAM), a novel metric for quantifying the uniformity of codeembedding distributions, providing a standardized measure of featureseparability. The proposed method achieves a lower MAM, indicating a morediscriminative feature representation. This underscores GNN-Coder's superiorability to distinguish between code snippets, thereby enhancing retrievalaccuracy. Experimental results show that GNN-Coder significantly boostsretrieval performance, with a 1\%-10\% improvement in MRR on the CSN dataset,and a notable 20\% gain in zero-shot performance on the CosQA dataset.</description>
      <author>example@mail.com (Yufan Ye, Pu Pang, Ting Zhang, Hua Huang)</author>
      <guid isPermaLink="false">2502.15202v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Context Transformer for Multi-level Semantic Scene Understanding</title>
      <link>http://arxiv.org/abs/2502.15184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted by the IEEE TCSVT&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种多层次语义场景理解（MSSU）的方法，用于手术场景的理解，并设计了一个层次化上下文变换器（HCT）网络。&lt;h4&gt;背景&lt;/h4&gt;在开发基于上下文感知的计算机辅助系统中，对手术场景的全面理解和显式认识至关重要。然而，很少有研究提供系统的分析以实现分层的手术场景理解。&lt;h4&gt;目的&lt;/h4&gt;提出一个多层级语义场景理解的方法和层次化上下文变换器网络来解决现有不足，并探索不同级别任务之间的关系。&lt;h4&gt;方法&lt;/h4&gt;设计了一个层次化相关聚合模块（HRAM），同时关联多级交互信息内部条目，然后增强特定于任务的特征。为了进一步促进各种任务的表示学习，提出了跨任务对比学习（ICL）以引导模型通过吸收其他任务提供的补充信息来学习具有任务特性的功能。&lt;h4&gt;主要发现&lt;/h4&gt;通过在白内障数据集和公共可用的内窥镜PSI-AVA数据集上的广泛实验，显示了该方法卓越的性能，并且始终大幅超越现有最佳方法。&lt;h4&gt;结论&lt;/h4&gt;提出的HCT+能够利用空间和时间适配器，在大量可调参数减少的情况下实现竞争力的表现。这些发现表明该方法在手术场景理解方面具有重要潜力。&lt;h4&gt;翻译&lt;/h4&gt;对手术场景进行全面而明确的理解对开发基于上下文感知的计算机辅助系统至关重要，但关于分层手术场景理解的研究较少提供系统分析。这项工作提出了将任务集表示为多层次语义场景理解（MSSU），并提出了一种新型层次化上下文变换器（HCT）网络来解决这一问题，并彻底探索了不同级别任务之间的关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A comprehensive and explicit understanding of surgical scenes plays a vitalrole in developing context-aware computer-assisted systems in the operatingtheatre. However, few works provide systematical analysis to enablehierarchical surgical scene understanding. In this work, we propose torepresent the tasks set [phase recognition --&gt; step recognition --&gt; action andinstrument detection] as multi-level semantic scene understanding (MSSU). Forthis target, we propose a novel hierarchical context transformer (HCT) networkand thoroughly explore the relations across the different level tasks.Specifically, a hierarchical relation aggregation module (HRAM) is designed toconcurrently relate entries inside multi-level interaction information and thenaugment task-specific features. To further boost the representation learning ofthe different tasks, inter-task contrastive learning (ICL) is presented toguide the model to learn task-wise features via absorbing complementaryinformation from other tasks. Furthermore, considering the computational costsof the transformer, we propose HCT+ to integrate the spatial and temporaladapter to access competitive performance on substantially fewer tunableparameters. Extensive experiments on our cataract dataset and a publiclyavailable endoscopic PSI-AVA dataset demonstrate the outstanding performance ofour method, consistently exceeding the state-of-the-art methods by a largemargin. The code is available at https://github.com/Aurora-hao/HCT.</description>
      <author>example@mail.com (Luoying Hao, Yan Hu, Yang Yue, Li Wu, Huazhu Fu, Jinming Duan, Jiang Liu)</author>
      <guid isPermaLink="false">2502.15184v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Expansion for Hypergraph Learning</title>
      <link>http://arxiv.org/abs/2502.15564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了新的自适应扩展方法AdE，该方法通过基于团的扩展方式将超图转换为加权图，并利用全局模拟网络和距离感知核函数来保持高阶结构信息。&lt;h4&gt;背景&lt;/h4&gt;近年来，随着对捕获更高阶关系能力的要求，超图受到了广泛关注。许多超图表示学习方法也随之出现。&lt;h4&gt;目的&lt;/h4&gt;为了克服经典扩展方法在固定边权重设计中导致的信息丢失或冗余问题，提出了一种新的自适应扩展方法AdE。&lt;h4&gt;方法&lt;/h4&gt;通过引入全局模拟网络选择每个超边中的两个代表性节点，并将同一超边中的其余节点连接到相应的选定节点。设计了距离感知核函数，动态调整边缘权重以确保相似的节点具有更大的重量。&lt;h4&gt;主要发现&lt;/h4&gt;AdE相比经典的扩展模型在理论合理性、泛化能力和有效性方面都表现出色&lt;h4&gt;结论&lt;/h4&gt;提出的AdE方法能够更好地保持和利用超图中的高阶结构信息&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hypergraph, with its powerful ability to capture higher-order relationships,has gained significant attention recently. Consequently, many hypergraphrepresentation learning methods have emerged to model the complex relationshipsamong hypergraphs. In general, these methods leverage classic expansion methodsto convert hypergraphs into weighted or bipartite graphs, and further employmessage passing mechanisms to model the complex structures within hypergraphs.However, classical expansion methods are designed in straightforward mannerswith fixed edge weights, resulting in information loss or redundancy. In lightof this, we design a novel clique expansion-based Adaptive Expansion methodcalled AdE to adaptively expand hypergraphs into weighted graphs that preservethe higher-order structure information. Specifically, we introduce a novelGlobal Simulation Network to select two representative nodes for adaptivelysymbolizing each hyperedge and connect the rest of the nodes within the samehyperedge to the corresponding selected nodes. Afterward, we design adistance-aware kernel function, dynamically adjusting edge weights to ensuresimilar nodes within a hyperedge are connected with larger weights. Extensivetheoretical justifications and empirical experiments over seven benchmarkhypergraph datasets demonstrate that AdE has excellent rationality,generalization, and effectiveness compared to classic expansion models.</description>
      <author>example@mail.com (Tianyi Ma, Yiyue Qian, Shinan Zhang, Chuxu Zhang, Yanfang Ye)</author>
      <guid isPermaLink="false">2502.15564v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>mStyleDistance: Multilingual Style Embeddings and their Evaluation</title>
      <link>http://arxiv.org/abs/2502.15168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2410.12757&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '提出了一种多语言风格嵌入模型mStyleDistance，该模型使用合成数据和对比学习进行训练。', '背景': '现有的风格嵌入仅限于英语，缺乏对多种语言的支持。', '目的': '开发一种能够在多种语言中有效工作的风格嵌入模型，并用于评估其质量和性能。', '方法': '利用来自九种不同语言的数据训练mStyleDistance模型；创建一个多语言的STEL或内容基准测试来评估嵌入的质量；在跨语种作者身份验证任务中应用该模型。', '主要发现': '实验结果表明，mStyleDistance风格嵌入优于现有模型，在多语言风格基准上表现出色，并且能够很好地推广到未见过的语言和特征。', '结论': '展示了mStyleDistance的潜在价值及其在跨语种分析中的优势；源代码已公开发布。'}&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新的多语言风格嵌入模型，名为Multilingual Style Distance (mStyleDistance)，该模型通过合成数据和对比学习进行了训练，并用于评估其质量和性能。研究显示了该方法在处理多种语言的风格分析任务中的优越性，并且能够很好地推广到新场景中去使用。研究成果已经公开分享。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Style embeddings are useful for stylistic analysis and style transfer;however, only English style embeddings have been made available. We introduceMultilingual StyleDistance (mStyleDistance), a multilingual style embeddingmodel trained using synthetic data and contrastive learning. We train the modelon data from nine languages and create a multilingual STEL-or-Content benchmark(Wegmann et al., 2022) that serves to assess the embeddings' quality. We alsoemploy our embeddings in an authorship verification task involving differentlanguages. Our results show that mStyleDistance embeddings outperform existingmodels on these multilingual style benchmarks and generalize well to unseenfeatures and languages. We make our model publicly available athttps://huggingface.co/StyleDistance/mstyledistance .</description>
      <author>example@mail.com (Justin Qiu, Jiacheng Zhu, Ajay Patel, Marianna Apidianaki, Chris Callison-Burch)</author>
      <guid isPermaLink="false">2502.15168v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Para-Lane: Multi-Lane Dataset Registering Parallel Scans for Benchmarking Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2502.15635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;为了评估端到端的自动驾驶系统，基于新颖视图合成（NVS）技术的模拟环境是必不可少的。这种模拟可以生成新的车辆姿态下的真实感图像和点云数据，尤其是在跨车道场景中。&lt;h4&gt;目的&lt;/h4&gt;由于现有的合成场景基础的NVS数据集在现实性和捕捉到的图像及点云的真实度方面仍然存在不足，因此开发一个多车道的数据集和基准是必要的。该研究旨在基于NeRF和3DGS方法进一步评估现有方法的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新方法来创建第一个多车道数据集，通过并行扫描真实世界获取25组相关序列，其中包括16,000张前置视图图像、64,000张环视图像以及16,000个LiDAR帧。所有帧都被标记以区分移动物体和静态元素。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用该数据集，在不同车道和距离的多种测试场景中评估现有方法的表现，并提供解决多传感器姿态问题的方法，实现跨模式数据对齐。&lt;h4&gt;结论&lt;/h4&gt;该研究公开了一个名为Paralane的数据集（网址：https://nizqleo.github.io/paralane-dataset/），用于持续添加新的序列以测试现有的方法在不同场景中的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;为了评估端到端的自动驾驶系统，一个基于新颖视图合成技术的模拟环境是必要的。该研究提出了一种新型多车道数据集和基准，旨在进一步检验NeRF和3DGS等现有方法的表现。新创建的数据集包括来自真实世界扫描并行扫描25组相关序列，含16000张前置视角图像、64,000环视图像及16,000个LiDAR帧，并且提供了解决跨模式数据对齐的多传感器姿态问题的方法。研究者计划持续添加新的序列以测试现有方法在不同场景中的泛化能力，数据集公开于项目页面：https://nizqleo.github.io/paralane-dataset/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To evaluate end-to-end autonomous driving systems, a simulation environmentbased on Novel View Synthesis (NVS) techniques is essential, which synthesizesphoto-realistic images and point clouds from previously recorded sequencesunder new vehicle poses, particularly in cross-lane scenarios. Therefore, thedevelopment of a multi-lane dataset and benchmark is necessary. While recentsynthetic scene-based NVS datasets have been prepared for cross-lanebenchmarking, they still lack the realism of captured images and point clouds.To further assess the performance of existing methods based on NeRF and 3DGS,we present the first multi-lane dataset registering parallel scans specificallyfor novel driving view synthesis dataset derived from real-world scans,comprising 25 groups of associated sequences, including 16,000 front-viewimages, 64,000 surround-view images, and 16,000 LiDAR frames. All frames arelabeled to differentiate moving objects from static elements. Using thisdataset, we evaluate the performance of existing approaches in various testingscenarios at different lanes and distances. Additionally, our method providesthe solution for solving and assessing the quality of multi-sensor poses formulti-modal data alignment for curating such a dataset in real-world. We planto continually add new sequences to test the generalization of existing methodsacross different scenarios. The dataset is released publicly at the projectpage: https://nizqleo.github.io/paralane-dataset/.</description>
      <author>example@mail.com (Ziqian Ni, Sicong Du, Zhenghua Hou, Chenming Wu, Sheng Yang)</author>
      <guid isPermaLink="false">2502.15635v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Based Deep Learning on Stereo EEG for Predicting Seizure Freedom in Epilepsy Patients</title>
      <link>http://arxiv.org/abs/2502.15198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;预测癫痫患者无发作状态对于个性化治疗至关重要。然而，传统的预测方法难以在不同类型的患者群体中实现准确的预测。&lt;h4&gt;背景&lt;/h4&gt;难治性癫痫患者的预后评估需要更有效的工具来提高治疗效果和减少副作用。&lt;h4&gt;目的&lt;/h4&gt;开发基于深度学习的图神经网络（GNN）模型以预测从立体脑电图（sEEG）数据中获得的无发作状态。&lt;h4&gt;方法&lt;/h4&gt;利用15名儿科难治性癫痫患者的高质量sEEG数据训练模型，使用图形卷积和多尺度注意力机制捕捉局部与全局连接性。&lt;h4&gt;主要发现&lt;/h4&gt;{'准确性': '在二元分类分析、患者级分析及多类分析中分别达到了92.4%、86.6%和81.4%的准确率；', '关键区域': '前扣带皮层与额极是预测无发作状态的关键脑区，并且这些区域更可能对应于癫痫发作起始区。', '模型识别': '模型标识出的节点更有可能重合于癫痫发作起始区，强调了基于连接性的新深度学习模型对于提高无发作状态预测、定位癫痫发作起始区及大脑在癫痫期间的连接性分析的重要性。'}&lt;h4&gt;结论&lt;/h4&gt;新型基于连接性的深度学习模型如GNN为改善难治性癫痫患者的个性化治疗提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;预测癫痫患者无发作状态对于个性化治疗至关重要。然而，传统的预测方法难以在不同类型的患者群体中实现准确的预测。本研究开发了一种基于深度学习的图神经网络（GNN）模型以预测从立体脑电图（sEEG）数据获得的无发作状态结果，并加深了对癫痫起始区大脑连接性的理解。该模型结合局部和全局连接性使用图形卷积与多尺度注意力机制来捕捉如丘脑及运动区域这样难以研究区域之间的连接，成功提高了预测精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting seizure freedom is essential for tailoring epilepsy treatment. Butaccurate prediction remains challenging with traditional methods, especiallywith diverse patient populations. This study developed a deep learning-basedgraph neural network (GNN) model to predict seizure freedom from stereoelectroencephalography (sEEG) data in patients with refractory epilepsy. Weutilized high-quality sEEG data from 15 pediatric patients to train a deeplearning model that can accurately predict seizure freedom outcomes and advanceunderstanding of brain connectivity at the seizure onset zone. Our modelintegrates local and global connectivity using graph convolutions withmulti-scale attention mechanisms to capture connections betweendifficult-to-study regions such as the thalamus and motor regions. The modelachieved an accuracy of 92.4% in binary class analysis, 86.6% in patient-wiseanalysis, and 81.4% in multi-class analysis. Node and edge-level featureanalysis highlighted the anterior cingulate and frontal pole regions as keycontributors to seizure freedom outcomes. The nodes identified by our modelwere also more likely to coincide with seizure onset zones. Our findingsunderscore the potential of new connectivity-based deep learning models such asGNNs for enhancing the prediction of seizure freedom, predicting seizure onsetzones, connectivity analysis of the brain during seizure, as well as informingAI-assisted personalized epilepsy treatment planning.</description>
      <author>example@mail.com (Artur Agaronyan, Syeda Abeera Amir, Nunthasiri Wittayanakorn, John Schreiber, Marius G. Linguraru, William Gaillard, Chima Oluigbo, Syed Muhammad Anwar)</author>
      <guid isPermaLink="false">2502.15198v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Fine-tuning foundation models of materials interatomic potentials with frozen transfer learning</title>
      <link>http://arxiv.org/abs/2502.15582v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;机器学习的原子间势能是通过提供训练数据覆盖范围内准确且可扩展的预测来革新原子材料模拟，但生成一个精确且稳健的数据集仍然是个挑战。本文展示了使用迁移学习可以提高基础模型的准确性，并构建了一个更为高效的人工智能模拟工作流程。&lt;h4&gt;背景&lt;/h4&gt;机器学习的原子间势能能够提供训练数据覆盖范围内准确和可扩展的预测，然而，要生成这种精准而健壮的数据集，通常需要数千次第一原理计算。现在开始出现一种旨在创建可以适用于广泛材料领域的基础模型。&lt;h4&gt;目的&lt;/h4&gt;展示通过迁移学习提高基础模型势能准确性，并构建一个改进了数据效率和计算效率的人工智能模拟工作流程。&lt;h4&gt;方法&lt;/h4&gt;利用部分冻结的权重和偏差进行微调，使用两个具有挑战性的表面反应化学以及三元合金稳定性和弹性性质的数据集作为案例研究。&lt;h4&gt;主要发现&lt;/h4&gt;通过迁移学习，在只使用少量（几百个数据点）的情况下可以达到与从零开始训练模型相媲美的精度。此外，还可以利用这种经过调整的势能构建一个准确度相当但更高效的代理模型。&lt;h4&gt;结论&lt;/h4&gt;本文提出了一种改进了机器学习潜在效率的人工智能模拟工作流程，该流程提高了数据和计算使用率。&lt;h4&gt;翻译&lt;/h4&gt;机器学习原子间势场通过提供训练数据范围内的精确且可扩展的预测来革新原子材料模拟。生成准确且稳健的数据集仍然是一个挑战，通常需要数千次第一性原理计算才能获得高精度。现在正在出现一种基础模型，其目标是在广泛的材料中通用适用潜在场。虽然这些基础模型可以是健壮和转移的，但它们尚未达到预测反应势垒、相变以及物质稳定性所需的精确度。这项工作展示了通过使用部分冻结权重和偏差进行迁移学习微调的基础模型潜力可以实现化学精度。对于两个具有挑战性的数据集：表面反应化学与三元合金稳定性和弹性性质的研究表明，在使用10-20%的数据（几百个数据点）情况下，冻结转移学习达到的准确度与从头开始训练模型相仿（需要数千个数据点）。此外还展示了可以建立一个同样精确但计算更高效的替代模型，该模型以迁移学习后的势能为真值。综合来看，我们提出了一种改进了机器学习潜在效率的人工智能模拟工作流程，此流程提高了数据和计算使用率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learned interatomic potentials are revolutionising atomisticmaterials simulations by providing accurate and scalable predictions within thescope covered by the training data. However, generation of an accurate androbust training data set remains a challenge, often requiring thousands offirst-principles calculations to achieve high accuracy. Foundation models havestarted to emerge with the ambition to create universally applicable potentialsacross a wide range of materials. While foundation models can be robust andtransferable, they do not yet achieve the accuracy required to predict reactionbarriers, phase transitions, and material stability. This work demonstratesthat foundation model potentials can reach chemical accuracy when fine-tunedusing transfer learning with partially frozen weights and biases. For twochallenging datasets on reactive chemistry at surfaces and stability andelastic properties of tertiary alloys, we show that frozen transfer learningwith 10-20% of the data (hundreds of datapoints) achieves similar accuracies tomodels trained from scratch (on thousands of datapoints). Moreover, we showthat an equally accurate, but significantly more efficient surrogate model canbe built using the transfer learned potential as the ground truth. Incombination, we present a simulation workflow for machine learning potentialsthat improves data efficiency and computational efficiency.</description>
      <author>example@mail.com (Mariia Radova, Wojciech G. Stark, Connor S. Allen, Reinhard J. Maurer, Albert P. Bartók)</author>
      <guid isPermaLink="false">2502.15582v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Generalization Guarantees for Representation Learning via Data-Dependent Gaussian Mixture Priors</title>
      <link>http://arxiv.org/abs/2502.15540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as a Spotlight Paper at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文建立了表示学习算法的期望和尾部泛化误差界限，并通过相对熵来描述训练集和测试集中提取出的表征分布之间的差异。&lt;h4&gt;背景&lt;/h4&gt;当前对于表示学习算法的泛化误差研究较少，现有的界限无法充分反映编码器结构与简单性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的数据依赖性对称先验（即训练和测试数据集潜在变量的最小描述长度）来建立更精确的泛化误差界限。&lt;h4&gt;方法&lt;/h4&gt;利用期望边界设计了一种合适的数据依赖正则项，并提出了同时学习数据依赖高斯混合先验并用其作为正则化的系统性方法，显示出了加权注意力机制的自然出现。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该方法优于流行的变分信息瓶颈（VIB）和最近的类别依赖的VIB（CDVIB）。&lt;h4&gt;结论&lt;/h4&gt;新提出的界限和学习先验的方法有助于改善表示学习算法的表现。&lt;h4&gt;翻译&lt;/h4&gt;我们建立了表示学习类型算法的期望和尾部泛化误差界，这些边界以训练集和“测试”数据集中提取出的表征分布之间的相对熵来描述，并且相对于一个数据依赖性对称先验（即，对于训练和测试数据集潜在变量的最小描述长度）。我们证明了我们的界限反映了编码器的“结构”和“简单性”，并且显著改进了现有的少量边界。然后，我们将期望界用于设计合适的数据依赖正则项；并详细探讨了重要的先验选择问题。我们提出了一种系统方法，可以同时学习数据依赖高斯混合先验，并将其用作正则化器。有趣的是，在此过程中自然地出现了加权注意力机制。我们的实验表明，我们提出的方法优于流行的变分信息瓶颈（VIB）方法以及最近的类别依赖的VIB（CDVIB）方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We establish in-expectation and tail bounds on the generalization error ofrepresentation learning type algorithms. The bounds are in terms of therelative entropy between the distribution of the representations extracted fromthe training and "test'' datasets and a data-dependent symmetric prior, i.e.,the Minimum Description Length (MDL) of the latent variables for the trainingand test datasets. Our bounds are shown to reflect the "structure" and"simplicity'' of the encoder and significantly improve upon the few existingones for the studied model. We then use our in-expectation bound to devise asuitable data-dependent regularizer; and we investigate thoroughly theimportant question of the selection of the prior. We propose a systematicapproach to simultaneously learning a data-dependent Gaussian mixture prior andusing it as a regularizer. Interestingly, we show that a weighted attentionmechanism emerges naturally in this procedure. Our experiments show that ourapproach outperforms the now popular Variational Information Bottleneck (VIB)method as well as the recent Category-Dependent VIB (CDVIB).</description>
      <author>example@mail.com (Milad Sefidgaran, Abdellatif Zaidi, Piotr Krasnowski)</author>
      <guid isPermaLink="false">2502.15540v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>PDeepPP:A Deep learning framework with Pretrained Protein language for peptide classification</title>
      <link>http://arxiv.org/abs/2502.15610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, submitted to arXiv&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;蛋白质后翻译修饰（PTMs）和生物活性肽（BPs）在各种生物学过程中起着关键作用，并具有重要的治疗潜力。然而，通过实验方法识别这些位点既耗时又成本高昂。&lt;h4&gt;背景&lt;/h4&gt;现有计算工具，尤其是基于深度学习的方法，在预测PTM位点和肽类生物活性方面表现出色，但仍然面临蛋白质序列复杂性和跨不同数据集提供高质量预测的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合预训练蛋白质语言模型与融合Transformer和CNN的神经网络框架，以提高特征提取能力和预测准确性。&lt;h4&gt;方法&lt;/h4&gt;该框架应用于多项任务中，包括PTM位点及生物活性肽预测，并通过大规模数据集提升模型鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;在33项任务比较中，此模型在其中25项达到最先进水平，超越现有方法并展示出跨不同数据集的多功能性。&lt;h4&gt;结论&lt;/h4&gt;这种新方法为大规模肽类发现和PTM分析提供了可扩展且有效的方法，开启了更高效地肽类分类及功能注释的新途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Protein post-translational modifications (PTMs) and bioactive peptides (BPs)play critical roles in various biological processes and have significanttherapeutic potential. However, identifying PTM sites and bioactive peptidesthrough experimental methods is often labor-intensive, costly, andtime-consuming. As a result, computational tools, particularly those based ondeep learning, have become effective solutions for predicting PTM sites andpeptide bioactivity. Despite progress in this field, existing methods stillstruggle with the complexity of protein sequences and the challenge ofrequiring high-quality predictions across diverse datasets.  To address these issues, we propose a deep learning framework that integratespretrained protein language models with a neural network combining transformerand CNN for peptide classification. By leveraging the ability of pretrainedmodels to capture complex relationships within protein sequences, combined withthe predictive power of parallel networks, our approach improves featureextraction while enhancing prediction accuracy.  This framework was applied to multiple tasks involving PTM site and bioactivepeptide prediction, utilizing large-scale datasets to enhance the model'srobustness. In the comparison across 33 tasks, the model achievedstate-of-the-art (SOTA) performance in 25 of them, surpassing existing methodsand demonstrating its versatility across different datasets. Our resultssuggest that this approach provides a scalable and effective solution forlarge-scale peptide discovery and PTM analysis, paving the way for moreefficient peptide classification and functional annotation.</description>
      <author>example@mail.com (Jixiu Zhai, Tianchi Lu, Haitian Zhong, Ziyang Xu, Yuhuan Liu, Xueying Wang, Dan Huang)</author>
      <guid isPermaLink="false">2502.15610v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>P2W: From Power Traces to Weights Matrix -- An Unconventional Transfer Learning Approach</title>
      <link>http://arxiv.org/abs/2502.14968v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的非传统迁移学习方法，用于在嵌入式SoC中训练机器学习模型。该方法通过提取已部署在SoC中的现有ML模型的权重来初始化新模型，而不是直接访问这些模型。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习（ML）模型在嵌入式芯片系统（SoCs）上的快速部署，医疗保健和自动驾驶汽车等领域发生了变革性的变化。然而，在这些场景中训练嵌入式ML模型的一个主要挑战是缺乏高质量的公开训练数据。&lt;h4&gt;目的&lt;/h4&gt;解决现有迁移学习方法需要直接访问已存在模型这一限制问题，特别是在嵌入式SoC上运行的情况下。&lt;h4&gt;方法&lt;/h4&gt;通过从执行机器学习模型的SoC捕获功耗测量值并将这些值转换为权重矩阵来初始化新的ML模型。这种方法不需要直接获取嵌入式系统中的现有模型的具体信息。&lt;h4&gt;主要发现&lt;/h4&gt;新方法可以显著提高在数据稀缺环境下的模型准确性和预测性能，相比传统训练方式，在使用相同数量的受限训练数据的情况下，可以使新模型的准确性提升高达3倍。&lt;h4&gt;结论&lt;/h4&gt;提出的方法提供了一种有效的途径来利用现有的嵌入式ML模型的知识，以改进新模型的学习效率和预测表现。这种方法对于那些难以直接访问已有模型场景下的机器学习应用来说特别有用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在芯片上的系统（SoCs）上部署的机器学习（ML）模型数量快速增长已经对医疗保健、自动驾驶汽车等领域带来了变革性的变化。然而，在这些领域训练嵌入式ML模型的一个主要挑战是缺乏高质量的公共可用训练数据。迁移学习方法通过利用现有ML模型中的知识作为起点来应对这一挑战，从而用于训练新的ML模型。但是，现有的迁移学习方法需要直接访问现有的模型，这在许多情况下是不可行的，尤其是在部署在嵌入式SoC上的ML模型的情况下。因此，在本文中，我们提出了一种新颖的方法：通过提取并使用一个运行在嵌入式SoC中的现有ML模型的权重来训练一个新的ML模型，而不需要直接访问该模型。我们的方法采集了执行ML模型时从SoC捕捉到的能量消耗测量值，并将其转换为用于初始化新ML模型的大致权重矩阵。这提高了新模型的学习效率和预测性能，尤其是在可用来培训模型的数据量有限的情况下。与使用相同数量的受限训练数据的传统训练方式相比，我们新颖的方法可以有效提高新ML模型的准确度高达3倍。&lt;h4&gt;其他信息&lt;/h4&gt;{'关键词': ['迁移学习', '嵌入式SoC', '机器学习', '功耗测量', '权重初始化']}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of deploying machine learning (ML) models within embeddedsystems on a chip (SoCs) has led to transformative shifts in fields likehealthcare and autonomous vehicles. One of the primary challenges for trainingsuch embedded ML models is the lack of publicly available high-quality trainingdata. Transfer learning approaches address this challenge by utilizing theknowledge encapsulated in an existing ML model as a starting point for traininga new ML model. However, existing transfer learning approaches require directaccess to the existing model which is not always feasible, especially for MLmodels deployed on embedded SoCs. Therefore, in this paper, we introduce anovel unconventional transfer learning approach to train a new ML model byextracting and using weights from an existing ML model running on an embeddedSoC without having access to the model within the SoC. Our approach capturespower consumption measurements from the SoC while it is executing the ML modeland translates them to an approximated weights matrix used to initialize thenew ML model. This improves the learning efficiency and predictive performanceof the new model, especially in scenarios with limited data available to trainthe model. Our novel approach can effectively increase the accuracy of the newML model up to 3 times compared to classical training methods using the sameamount of limited training data.</description>
      <author>example@mail.com (Roozbeh Siyadatzadeh, Fatemeh Mehrafrooz, Nele Mentens, Todor Stefanov)</author>
      <guid isPermaLink="false">2502.14968v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Riemannian Sparse Representation Learning Network for Polarimetric SAR Image Classification</title>
      <link>http://arxiv.org/abs/2502.15302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的Riemannian稀疏表示学习网络(SRSR CNN)用于极化合成孔径雷达(PolSAR)图像分类。&lt;h4&gt;背景&lt;/h4&gt;深度学习是Polarimetric SAR图像分类的有效方法，但缺乏相关的数学原理指导，并且通常将复数协方差矩阵转换为欧几里得空间中的向量输入，这可能破坏了矩阵结构和通道关系。&lt;h4&gt;目的&lt;/h4&gt;通过引入Riemannian度量来更好地处理PolSAR的复杂矩阵结构，以提高分类准确性和边缘细节准确性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个基于超像素的Riemannian稀疏表示模型(SRSR)，该模型能够在黎曼空间中学习几何结构和稀疏特征。然后将其展开为一个网络，可以自动地学习稀疏系数和字典原子，并添加了CNN增强模块以提高上下文高级特征的学习能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明所提出的方法在保持准确的边缘细节和正确的区域同质性方面优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;提出的基于SR指导的深度学习模型可以直接使用协方差矩阵作为网络输入，并且可以利用黎曼度量来学习复数矩阵在黎曼空间中的几何结构和稀疏特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning is an effective end-to-end method for Polarimetric SyntheticAperture Radar(PolSAR) image classification, but it lacks the guidance ofrelated mathematical principle and is essentially a black-box model. Inaddition, existing deep models learn features in Euclidean space, where PolSARcomplex matrix is commonly converted into a complex-valued vector as thenetwork input, distorting matrix structure and channel relationship. However,the complex covariance matrix is Hermitian positive definite (HPD), and resideson a Riemannian manifold instead of a Euclidean one. Existing methods cannotmeasure the geometric distance of HPD matrices and easily cause somemisclassifications due to inappropriate Euclidean measures. To address theseissues, we propose a novel Riemannian Sparse Representation Learning Network(SRSR CNN) for PolSAR images. Firstly, a superpixel-based Riemannian SparseRepresentation (SRSR) model is designed to learn the sparse features withRiemannian metric. Then, the optimization procedure of the SRSR model isinferred and further unfolded into an SRSRnet, which can automatically learnthe sparse coefficients and dictionary atoms. Furthermore, to learn contextualhigh-level features, a CNN-enhanced module is added to improve classificationperformance. The proposed network is a Sparse Representation (SR) guided deeplearning model, which can directly utilize the covariance matrix as the networkinput, and utilize Riemannian metric to learn geometric structure and sparsefeatures of complex matrices in Riemannian space. Experiments on three realPolSAR datasets demonstrate that the proposed method surpasses state-of-the-arttechniques in ensuring accurate edge details and correct region homogeneity forclassification.</description>
      <author>example@mail.com (Junfei Shi, Mengmeng Nie, Weisi Lin, Haiyan Jin, Junhuai Li, Rui Wang)</author>
      <guid isPermaLink="false">2502.15302v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Depth-aware Fusion Method based on Image and 4D Radar Spectrum for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.15516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文讨论了毫米波雷达和相机在自动驾驶环境感知中的互补作用，通过结合4D毫米波雷达和深度感知的摄像机图像来提高3D物体检测精度。&lt;h4&gt;背景&lt;/h4&gt;安全性和可靠性对于公众接受自动驾驶至关重要。传统的3D毫米波雷达只能提供目标的距离、多普勒频移及方位信息，在恶劣天气条件下仍能保持良好性能，但点云稀疏。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过结合4D毫米波雷达和相机的优势来增强环境感知的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;['利用4D毫米波雷达提供的深度感知数据与相机图像进行融合，采用注意机制在鸟瞰图视角下将丰富的纹理图像与深度信息相结合', '提出了一种基于GAN的方法，在没有深度传感器的情况下从雷达频谱生成深度图像']&lt;h4&gt;主要发现&lt;/h4&gt;['通过结合4D毫米波雷达和相机可以有效提升环境感知的准确性，特别是在恶劣天气条件下。', '使用注意力机制能够更好地融合不同类型的感知数据，提高3D物体检测精度。', '基于GAN的方法有助于在缺乏直接深度信息的情况下生成有效的深度图像']&lt;h4&gt;结论&lt;/h4&gt;该研究证明了将4D毫米波雷达与相机结合可以显著提升自动驾驶系统的环境感知能力，并提出了一种新颖的解决方案来克服现有技术局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Safety and reliability are crucial for the public acceptance of autonomousdriving. To ensure accurate and reliable environmental perception, intelligentvehicles must exhibit accuracy and robustness in various environments.Millimeter-wave radar, known for its high penetration capability, can operateeffectively in adverse weather conditions such as rain, snow, and fog.Traditional 3D millimeter-wave radars can only provide range, Doppler, andazimuth information for objects. Although the recent emergence of 4Dmillimeter-wave radars has added elevation resolution, the radar point cloudsremain sparse due to Constant False Alarm Rate (CFAR) operations. In contrast,cameras offer rich semantic details but are sensitive to lighting and weatherconditions. Hence, this paper leverages these two highly complementary andcost-effective sensors, 4D millimeter-wave radar and camera. By integrating 4Dradar spectra with depth-aware camera images and employing attentionmechanisms, we fuse texture-rich images with depth-rich radar data in theBird's Eye View (BEV) perspective, enhancing 3D object detection. Additionally,we propose using GAN-based networks to generate depth images from radar spectrain the absence of depth sensors, further improving detection accuracy.</description>
      <author>example@mail.com (Yue Sun, Yeqiang Qian, Chunxiang Wang, Ming Yang)</author>
      <guid isPermaLink="false">2502.15516v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Decoding lithium's subtle phase stability with a machine learning force field</title>
      <link>http://arxiv.org/abs/2502.15190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了锂金属在锂-金属电池阳极中的相稳定性，揭示了量子效应和非谐性对锂的热力学性质的重要性。&lt;h4&gt;背景&lt;/h4&gt;锂金属在作为锂电池阳极材料时表现出复杂的多晶型特性，这对优化其性能至关重要。然而，这种看似简单的金属具有平坦的能量地形图，需要考虑量子效应、声子重整化和热膨胀效应来准确描述。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于图形神经网络的机器学习势场，并进行高效自洽声子计算，以研究在近环境条件下bcc-，fcc-和9R-Li相的稳定性。&lt;h4&gt;方法&lt;/h4&gt;利用了图神经网络机器学习力场以及声子重整化效应并考虑量子、热力学膨胀影响下的自洽声子计算来模拟锂的不同晶型结构。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明非谐性在决定Li的热力学性质中起着重要作用。fcc-Li在零温度和压力下被确认为基态，预测的bcc-fcc相边界与实验相变线具有定性的匹配。&lt;h4&gt;结论&lt;/h4&gt;这些研究提供了锂多晶型复杂特性的关键见解，并建立了一种有效的计算方法来模拟更现实条件下锂的大规模原子尺度仿真，以支持实际能源存储应用。&lt;h4&gt;翻译&lt;/h4&gt;理解元素锂的相稳定性对于优化其在锂-金属电池阳极中的性能至关重要。然而，这种看似简单的金属表现出复杂的多晶型特性，需要准确考虑量子效应和非谐性来捕捉平坦能量地形图中的细微差别。为了应对这一挑战，我们开发了一种基于图形神经网络的机器学习力场，并进行了高效的自洽声子计算，在近环境条件下对bcc-、fcc-和9R-Li进行了研究，将量子效应、声子重整化以及热膨胀效应结合考虑在内。我们的研究表明非谐性在决定锂的热力学性质中起着重要作用。这些相之间的自由能差值（特别是fcc-与9R-Li）仅几毫电子伏特/原子，解释了实验上难以获得纯相样品的问题，并暗示了堆垛层错和相关缺陷形成的可能性。在零温度和压力下确认了fcc-Li为基态，预测的bcc-fcc相边界虽然低估了相变温度和压力斜率，但与实验相变线具有定性的匹配。这些发现提供了锂复杂多晶型的关键见解，并建立了一种有效的计算方法来模拟更现实条件下锂的大规模原子尺度仿真，以支持实际能源存储应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1039/D4TA08860C&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the phase stability of elemental lithium (Li) is crucial foroptimizing its performance in lithium-metal battery anodes, yet this seeminglysimple metal exhibits complex polymorphism that requires proper accounting forquantum and anharmonic effects to capture the subtleties in its flat energylandscape. Here we address this challenge by developing an accurate graphneural network-based machine learning force field and performing efficientself-consistent phonon calculations for bcc-, fcc-, and 9R-Li undernear-ambient conditions, incorporating quantum, phonon renormalization andthermal expansion effects. Our results reveal the important role ofanharmonicity in determining Li's thermodynamic properties. The free energydifferences between these phases, particularly fcc- and 9R-Li are found to beonly a few meV/atom, explaining the experimental challenges in obtainingphase-pure samples and suggesting a propensity for stacking faults and relateddefect formation. fcc-Li is confirmed as the ground state at zero temperatureand pressure, and the predicted bcc-fcc phase boundary qualitatively matchesexperimental phase transition lines, despite overestimation of the transitiontemperature and pressure slope. These findings provide crucial insights intoLi's complex polymorphism and establish an effective computational approach forlarge-scale atomistic simulations of Li in more realistic settings forpractical energy storage applications.</description>
      <author>example@mail.com (Yiheng Shen, Wei Xie)</author>
      <guid isPermaLink="false">2502.15190v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>PFSD: A Multi-Modal Pedestrian-Focus Scene Dataset for Rich Tasks in Semi-Structured Environments</title>
      <link>http://arxiv.org/abs/2502.15342v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一个新的多模态行人场景数据集PFSD，旨在解决半结构化环境中行人感知和预测的挑战。同时提出了一种新的混合多尺度融合网络(HMFN)，以提高在复杂半结构化环境中的3D行人检测性能。&lt;h4&gt;背景&lt;/h4&gt;当前自动驾驶感知系统在处理车辆主导的结构化环境时表现出色，但在存在更多动态行人的半结构化环境中表现不佳，这主要是由于高质量数据集的缺乏，特别是在涉及行人场景的数据集中。&lt;h4&gt;目的&lt;/h4&gt;开发一个多模态、全面标注的数据集PFSD，并提出了一种新的方法HMFN来应对半结构化环境中行人检测和预测的问题。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含130,000多个人行实例的PFSD数据集，该数据集在nuScenes格式下对点云进行了详细的分割、检测和对象ID跟踪。此外，提出了一个混合多尺度融合网络(HMFN)，用于处理高密度人群场景中的行人检测问题。&lt;h4&gt;主要发现&lt;/h4&gt;HMFN通过捕获并融合多种规模的特征显著提高了3D行人检测的性能，在PFSD数据集上达到了更高的平均精度(mAP)。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了高质量的数据和先进的算法在解决半结构化环境中行人感知挑战方面的必要性，并为未来的相关工作奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;最近，自主驾驶领域的感知技术取得了显著进展，尤其是在以车辆为主的结构化环境中。然而，目前的感知模型在半结构化的场景中面临重大局限性，特别是在存在动态行人的复杂和多样运动模式以及遮挡情况下表现不佳。我们归因于高质量数据集的缺乏，尤其是关于行人感知的数据集。在此研究中，我们提出了一个多模态行人焦点场景数据集PFSD，在nuScenes格式下为半结构化的场景提供了全面的多模态数据标注，包括点云分割、检测和对象ID用于追踪。该数据集涵盖了超过130,000个在各种情况下捕捉到的行人实例，包括不同的密度、移动模式及遮挡情况。为了证明解决多样且复杂的半结构化环境中的挑战的重要性，我们提出了一种新颖的混合多尺度融合网络(HMFN)。具体而言，在处理高密度人群场景中的行人检测时，我们的方法通过精心设计的混合框架有效捕捉并融合了多种规模的特征，该框架集成了稀疏和常规卷积。在PFSD上的广泛实验表明，HMFN在平均精度(mAP)上优于现有的方法，从而证明其在复杂半结构化环境中3D行人检测方面的有效性。代码和基准测试可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in autonomous driving perception have revealedexceptional capabilities within structured environments dominated by vehiculartraffic. However, current perception models exhibit significant limitations insemi-structured environments, where dynamic pedestrians with more diverseirregular movement and occlusion prevail. We attribute this shortcoming to thescarcity of high-quality datasets in semi-structured scenes, particularlyconcerning pedestrian perception and prediction. In this work, we present themulti-modal Pedestrian-Focused Scene Dataset(PFSD), rigorously annotated insemi-structured scenes with the format of nuScenes. PFSD provides comprehensivemulti-modal data annotations with point cloud segmentation, detection, andobject IDs for tracking. It encompasses over 130,000 pedestrian instancescaptured across various scenarios with varying densities, movement patterns,and occlusions. Furthermore, to demonstrate the importance of addressing thechallenges posed by more diverse and complex semi-structured environments, wepropose a novel Hybrid Multi-Scale Fusion Network (HMFN). Specifically, todetect pedestrians in densely populated and occluded scenarios, our methodeffectively captures and fuses multi-scale features using a meticulouslydesigned hybrid framework that integrates sparse and vanilla convolutions.Extensive experiments on PFSD demonstrate that HMFN attains improvement in meanAverage Precision (mAP) over existing methods, thereby underscoring itsefficacy in addressing the challenges of 3D pedestrian detection in complexsemi-structured environments. Coding and benchmark are available.</description>
      <author>example@mail.com (Yueting Liu, Hanshi Wang, Yunfei Lei, Zhengjun Zha, Weiming Hu, Jin Gao)</author>
      <guid isPermaLink="false">2502.15342v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking machine learning for bowel sound pattern classification from tabular features to pretrained models</title>
      <link>http://arxiv.org/abs/2502.15607v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures and 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了电子听诊器和可穿戴记录传感器的发展如何推动了肠鸣音信号的自动化分析，从而通过数据驱动的方法研究肠鸣音模式及其与不同病理的关系。&lt;h4&gt;背景&lt;/h4&gt;随着电子听诊器和可穿戴记录设备的进步，可以自动分析肠鸣音（BS）信号，这为基于数据的研究肠鸣音模式、它们之间的相互关系以及它们与各种疾病的相关性提供了可能性。&lt;h4&gt;目的&lt;/h4&gt;利用来自16名健康受试者的标注良好的BS数据集来评估机器学习模型在检测和/或分类BS模式方面的性能。&lt;h4&gt;方法&lt;/h4&gt;该研究使用了基于表格特征的模型，以光谱图为输入的卷积神经网络（CNN），以及预训练的大规模音频数据集上的模型，并对其进行了性能评估。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，特别是对于样本较少的类别的检测任务中，预训练模型表现出了明显的优越性。使用HuBERT模型在区分肠鸣音信号和非肠鸣音信号上实现了AUC为0.89；使用Wav2Vec 2.0模型在不同肠鸣音模式之间区分时也达到了AUC为0.89。&lt;h4&gt;结论&lt;/h4&gt;这些结果为进一步理解肠鸣音及其潜在的机器学习辅助诊断应用铺平了道路，特别是在胃肠检查方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of electronic stethoscopes and wearable recording sensorsopened the door to the automated analysis of bowel sound (BS) signals. Thisenables a data-driven analysis of bowel sound patterns, their interrelations,and their correlation to different pathologies. This work leverages a BSdataset collected from 16 healthy subjects that was annotated according to fourestablished BS patterns. This dataset is used to evaluate the performance ofmachine learning models to detect and/or classify BS patterns. The selection ofconsidered models covers models using tabular features, convolutional neuralnetworks based on spectrograms and models pre-trained on large audio datasets.The results highlight the clear superiority of pre-trained models, particularlyin detecting classes with few samples, achieving an AUC of 0.89 indistinguishing BS from non-BS using a HuBERT model and an AUC of 0.89 indifferentiating bowel sound patterns using a Wav2Vec 2.0 model. These resultspave the way for an improved understanding of bowel sounds in general andfuture machine-learning-driven diagnostic applications for gastrointestinalexaminations</description>
      <author>example@mail.com (Zahra Mansour, Verena Uslar, Dirk Weyhe, Danilo Hollosi, Nils Strodthoff)</author>
      <guid isPermaLink="false">2502.15607v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>GiGL: Large-Scale Graph Neural Networks at Snapchat</title>
      <link>http://arxiv.org/abs/2502.15054v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文介绍了GiGL，一个用于大规模分布式图机器学习的开源库。&lt;h4&gt;背景&lt;/h4&gt;随着图神经网络（GNNs）的发展，它们在商业应用中的兴趣日益增长。然而，由于规模挑战，工业界对GNNs的应用仍然落后于研究领域。&lt;h4&gt;目的&lt;/h4&gt;分享Snapchat采用GiGL进行大规模分布式图机器学习的方法和经验。&lt;h4&gt;方法&lt;/h4&gt;开发了GiGL库以解决大型社交数据上的图形ML的规模化问题，并简化内部实践者在建模方面的工作，同时支持与学术界常用的开源GNN建模库（如PyTorch Geometric）的接口。&lt;h4&gt;主要发现&lt;/h4&gt;GiGL已在多个生产环境中使用，在过去的两年中推动了超过35个跨多种业务领域的发布，包括好友推荐、内容推荐和广告领域。&lt;h4&gt;结论&lt;/h4&gt;论文详细描述了GiGL的设计、提供的工具、缩放属性以及在大规模社交图上的应用案例研究，并总结了一些关键经验教训。&lt;h4&gt;翻译&lt;/h4&gt;近期的图机器学习（ML）进展引入了图形神经网络（GNNs），这引发了将这些方法应用于商业规模应用的兴趣。GNNs使根据给定的图结构进行端到端(E2E)模型参数微分学习成为可能，从而优化流行节点、边（链接）和图级任务的目标函数。虽然在新GNN层和训练策略方面取得了迅速的研究创新，但由于大规模图形ML问题所特有的规模挑战，工业界对GNNs的应用明显滞后。在这项工作中，我们分享了Snapchat在培训、推理以及利用GNN时的方法。为此，我们介绍了GiGL（Gigantic Graph Learning），这是一个开源库，旨在使大型分布式图机器学习能够服务于研究人员、ML工程师和实践者的需求。我们在内部使用GiGL来处理GNN工作流程的繁重任务，包括从关系数据库中进行图数据预处理、子图采样、分布式训练、推理以及编排。GiGL的设计目的是清晰地与学术界常用的开源GNN建模库（如PyTorch Geometric）接口，并解决规模和生产化挑战，以使内部实践者能够专注于模型构建。GiGL在多个生产环境中使用，在过去的两年中推动了超过35个跨多种业务领域的发布，包括好友推荐、内容推荐以及广告领域。本工作详细描述了该库的高级设计和工具提供情况，扩展特性，并在各种行业规模图中的实际应用案例研究，以及在大规模社交数据上采用图形ML的关键经验教训。GiGL在https://github.com/snap-research/GiGL开源可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in graph machine learning (ML) with the introduction of GraphNeural Networks (GNNs) have led to a widespread interest in applying theseapproaches to business applications at scale. GNNs enable differentiableend-to-end (E2E) learning of model parameters given graph structure whichenables optimization towards popular node, edge (link) and graph-level tasks.While the research innovation in new GNN layers and training strategies hasbeen rapid, industrial adoption and utility of GNNs has lagged considerably dueto the unique scale challenges that large-scale graph ML problems create. Inthis work, we share our approach to training, inference, and utilization ofGNNs at Snapchat. To this end, we present GiGL (Gigantic Graph Learning), anopen-source library to enable large-scale distributed graph ML to the benefitof researchers, ML engineers, and practitioners. We use GiGL internally atSnapchat to manage the heavy lifting of GNN workflows, including graph datapreprocessing from relational DBs, subgraph sampling, distributed training,inference, and orchestration. GiGL is designed to interface cleanly withopen-source GNN modeling libraries prominent in academia like PyTorch Geometric(PyG), while handling scaling and productionization challenges that make iteasier for internal practitioners to focus on modeling. GiGL is used inmultiple production settings, and has powered over 35 launches across multiplebusiness domains in the last 2 years in the contexts of friend recommendation,content recommendation and advertising. This work details high-level design andtools the library provides, scaling properties, case studies in diversebusiness settings with industry-scale graphs, and several key lessons learnedin employing graph ML at scale on large social data. GiGL is open-sourced athttps://github.com/snap-research/GiGL.</description>
      <author>example@mail.com (Tong Zhao, Yozen Liu, Matthew Kolodner, Kyle Montemayor, Elham Ghazizadeh, Ankit Batra, Zihao Fan, Xiaobin Gao, Xuan Guo, Jiwen Ren, Serim Park, Peicheng Yu, Jun Yu, Shubham Vij, Neil Shah)</author>
      <guid isPermaLink="false">2502.15054v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Realm: Real-Time Line-of-Sight Maintenance in Multi-Robot Navigation with Unknown Obstacles</title>
      <link>http://arxiv.org/abs/2502.15162v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 9 figures, accepted by IEEE ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的多机器人导航框架，该框架在未知且复杂环境中通过实时点云测量来维护线视（LoS）连接约束。提出了一个基于点云可见性分析的新LoS距离度量方法，并设计了融合函数以确保机器人之间的协作移动和保持LoS连接。&lt;h4&gt;背景&lt;/h4&gt;多机器人系统在复杂环境中的导航需要依赖于机器人之间的通信与相互观测，而以前的研究工作大多是在已知的环境中进行的，难以应用于未知且复杂的场景中。&lt;h4&gt;目的&lt;/h4&gt;研究解决未知复杂环境中多机器人导航问题的方法，并提出一种新的LoS距离度量方法和融合函数来保持机器人的连接性。&lt;h4&gt;方法&lt;/h4&gt;通过实时点云测量直接定义了机器人之间的线视（LoS）约束，利用点云可见性分析技术量化了由于潜在的机器人移动而可能失去LoS的重要性与敏感程度。设计了一个新的融合函数以确保两个机器人之间丢失LoS的需求平衡，并将LoS约束编码到势能函数中。&lt;h4&gt;主要发现&lt;/h4&gt;提出了新颖的基于点云的LoS距离度量方法，能够同时考虑保持连接性和紧急性；设计了一种新的融合功能来处理两台机器人的紧迫感不均衡的问题；实现了结合上述方法的多机器人探索框架，并通过分布式传感和通信确保了未知环境下的持续导航。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的框架在复杂且未知的环境中，通过点云测量实现LoS约束的有效维护，增强了机器人的合作能力和实时感知能力。此成果对于未来自主系统的开发具有重要价值。&lt;h4&gt;翻译&lt;/h4&gt;多机器人系统在复杂环境中的导航需要依靠机器人之间的通信和相互观察来协调并提高态势感知能力。本文研究了未知环境中基于视距（LoS）连接限制的多机器人导航问题，而以前的工作仅限于从已知的环境模型中推导出LoS约束条件，本论文通过实时点云测量直接建立了这些约束，并利用点云可见性分析技术来实现这一点。我们提出了一种新的LoS距离度量方法，该方法可以量化由于潜在的机器人移动而可能失去视距的重要性和敏感性。此外，为了应对两个机器人之间丢失视距时紧迫感不均衡的问题，设计了一个融合功能以捕捉整体紧迫感并生成有利于保持视距的协作运动梯度。&lt;h4&gt;开源链接&lt;/h4&gt;https://github.com/bairuofei/LoS_constrained_navigation&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-robot navigation in complex environments relies on inter-robotcommunication and mutual observations for coordination and situationalawareness. This paper studies the multi-robot navigation problem in unknownenvironments with line-of-sight (LoS) connectivity constraints. While previousworks are limited to known environment models to derive the LoS constraints,this paper eliminates such requirements by directly formulating the LoSconstraints between robots from their real-time point cloud measurements,leveraging point cloud visibility analysis techniques. We propose a novelLoS-distance metric to quantify both the urgency and sensitivity of losing LoSbetween robots considering potential robot movements. Moreover, to address theimbalanced urgency of losing LoS between two robots, we design a fusionfunction to capture the overall urgency while generating gradients thatfacilitate robots' collaborative movement to maintain LoS. The LoS constraintsare encoded into a potential function that preserves the positivity of theFiedler eigenvalue of the robots' network graph to ensure connectivity.Finally, we establish a LoS-constrained exploration framework that integratesthe proposed connectivity controller. We showcase its applications inmulti-robot exploration in complex unknown environments, where robots canalways maintain the LoS connectivity through distributed sensing andcommunication, while collaboratively mapping the unknown environment. Theimplementations are open-sourced athttps://github.com/bairuofei/LoS_constrained_navigation.</description>
      <author>example@mail.com (Ruofei Bai, Shenghai Yuan, Kun Li, Hongliang Guo, Wei-Yun Yau, Lihua Xie)</author>
      <guid isPermaLink="false">2502.15162v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Accurate and efficient machine learning interatomic potentials for finite temperature modeling of molecular crystals</title>
      <link>http://arxiv.org/abs/2502.15530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了机器学习（ML）势能模型在分子晶体计算中的应用，特别是用于准确高效地计算升华焓。通过利用化学和材料科学领域的基础模型以及量子扩散蒙特卡洛基准测试的最新进展，该研究展示了使用少量高质量数据结构生成高精度MLIP的能力。&lt;h4&gt;背景&lt;/h4&gt;机器学习势能（MLIP）在模拟分子晶体方面具有革命性意义，但准确高效地计算升华焓仍面临挑战。现有方法需要大量的高精度参考结构，并且依赖于可能不够可靠的密度泛函理论来产生这些数据。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够使用较少的数据生成准确的机器学习势能模型的方法，以改进分子晶体在有限温度和压力下的描述能力。&lt;h4&gt;方法&lt;/h4&gt;利用化学和材料科学领域的基础模型以及量子扩散蒙特卡洛（QDMC）基准测试，通过训练数据集中的约200个高质量结构来构建MLIP模型。该框架还考虑了非谐性和核量子效应，并应用于X23数据集。&lt;h4&gt;主要发现&lt;/h4&gt;生成的机器学习势能模型在计算升华焓时达到了次化学精度水平，甚至可以推广到具有药物相关性的晶体系统中，准确捕捉核量子效应（如对天青酸的研究）。&lt;h4&gt;结论&lt;/h4&gt;这项工作为研究药理学和生物学系统的环境条件下的精确模拟铺平了道路。通过减少所需的数据量，它不仅提高了计算效率，还提供了关于药物分子稳定性的重要见解。&lt;h4&gt;翻译&lt;/h4&gt;机器学习在模拟分子晶体方面的潜力巨大，但准确计算升华焓仍存在挑战。本文提出了一种新方法，使用更少的高质量数据结构生成精确的MLIP模型，并通过X23数据集验证了该框架的有效性及对药物相关系统的适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As with many parts of the natural sciences, machine learning interatomicpotentials (MLIPs) are revolutionizing the modeling of molecular crystals.However, challenges remain for the accurate and efficient calculation ofsublimation enthalpies - a key thermodynamic quantity measuring the stabilityof a molecular crystal. Specifically, two key stumbling blocks are: (i) theneed for thousands of ab initio quality reference structures to generatetraining data; and (ii) the sometimes unreliable nature of density functionaltheory, the main technique for generating such data. Exploiting recentdevelopments in foundational models for chemistry and materials sciencealongside accurate quantum diffusion Monte Carlo benchmarks, offers a promisingpath forward. Herein, we demonstrate the generation of MLIPs capable ofdescribing molecular crystals at finite temperature and pressure withsub-chemical accuracy, using as few as $\sim 200$ data structures; an order ofmagnitude improvement over the current state-of-the-art. We apply thisframework to compute the sublimation enthalpies of the X23 dataset, accountingfor anharmonicity and nuclear quantum effects, achieving sub-chemical accuracywith respect to experiment. Importantly, we show that our framework can begeneralized to crystals of pharmaceutical relevance, including paracetamol andaspirin. Nuclear quantum effects are also accurately captured as shown for thecase of squaric acid. By enabling accurate modeling at ambient conditions, thiswork paves the way for deeper insights into pharmaceutical and biologicalsystems.</description>
      <author>example@mail.com (Flaviano Della Pia, Benjamin X. Shi, Venkat Kapil, Andrea Zen, Dario Alfè, Angelos Michaelides)</author>
      <guid isPermaLink="false">2502.15530v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Android Malware Detection: Rethinking the Role of Traditional and Deep Learning Models</title>
      <link>http://arxiv.org/abs/2502.15041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文系统地评估了Android恶意软件检测模型，比较了传统的机器学习和深度学习方法在不同数据集上的表现。&lt;h4&gt;背景&lt;/h4&gt;近年来，使用传统机器学习（ML）和深度学习（DL）技术对Android恶意软件进行检测的研究得到了广泛的关注。然而，尽管基于DL的方法声称具有优越的性能，它们往往依赖于有限的对比测试，并且缺乏与传统ML模型在多样化数据集上的全面基准比较。&lt;h4&gt;目的&lt;/h4&gt;通过使用四个不同数据集来评估不同的Android恶意软件检测模型（包括传统的随机森林和CatBoost以及先进的Capsule Graph Neural Networks等），论文旨在探讨各种模型的表现，并为未来的研究提供更加全面的基准测试。&lt;h4&gt;方法&lt;/h4&gt;该研究实施了一系列传统机器学习模型，如Random Forests (RF) 和 CatBoost，同时对比了先进的深度学习模型，例如CapsGNN、BERT和ExcelFormer等。使用的数据集包括三个最近发布的公开可用的数据集以及一个大规模的数据集（作者系统地收集的）。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，尽管高级DL模型可以实现强大的性能，但它们通常只与少量的传统ML基线进行比较。在许多情况下，更简单且计算效率更高的传统ML模型实现了可比甚至更好的性能。&lt;h4&gt;结论&lt;/h4&gt;论文强调了Android恶意软件检测研究中需要更加严格基准测试的重要性，并建议未来的研究应进行全面的对比研究以确保对检测能力的准确评估。此外，为促进进一步的研究，作者提供了其数据集的访问权限。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Android malware detection has been extensively studied using both traditionalmachine learning (ML) and deep learning (DL) approaches. While manystate-of-the-art detection models, particularly those based on DL, claimsuperior performance, they often rely on limited comparisons, lackingcomprehensive benchmarking against traditional ML models across diversedatasets. This raises concerns about the robustness of DL-based approaches'performance and the potential oversight of simpler, more efficient ML models.In this paper, we conduct a systematic evaluation of Android malware detectionmodels across four datasets: three recently published, publicly availabledatasets and a large-scale dataset we systematically collected. We implement arange of traditional ML models, including Random Forests (RF) and CatBoost,alongside advanced DL models such as Capsule Graph Neural Networks (CapsGNN),BERT-based models, and ExcelFormer based models. Our results reveal that whileadvanced DL models can achieve strong performance, they are often comparedagainst an insufficient number of traditional ML baselines. In many cases,simpler and more computationally efficient ML models achieve comparable or evensuperior performance. These findings highlight the need for rigorousbenchmarking in Android malware detection research. We encourage future studiesto conduct more comprehensive benchmarking comparisons between traditional andadvanced models to ensure a more accurate assessment of detection capabilities.To facilitate further research, we provide access to our dataset, including appIDs, hash values, and labels.</description>
      <author>example@mail.com (Guojun Liu, Doina Caragea, Xinming Ou, Sankardas Roy)</author>
      <guid isPermaLink="false">2502.15041v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Data Scarcity in Time Series Analysis: A Foundation Model with Series-Symbol Data Generation</title>
      <link>http://arxiv.org/abs/2502.15466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个针对时间序列分析（TSA）的数据生成机制和预训练模型，旨在克服数据稀缺性和不平衡的问题。&lt;h4&gt;背景&lt;/h4&gt;在时间序列分析领域，基础模型正受到越来越多的关注。然而，由于数据稀缺和数据不平衡等问题的存在，其发展受到了阻碍。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，研究者们提出了一种新的方法来建模复杂系统，并引入了一系列-符号（S2）双模式数据生成机制。&lt;h4&gt;方法&lt;/h4&gt;通过这种机制，可以无限制地创建高质量的时间序列数据并配以相应的符号表示。基于这些数据，他们开发了SymTime预训练基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;SymTime在五个主要时间序列分析任务中表现出竞争力，并且其性能与直接用真实世界数据集进行预训练的基础模型相媲美。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了双模态数据生成和预训练机制在克服数据稀缺性、提升任务性能方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;基础模型用于时间序列分析（TSA）吸引了大量的关注。然而，诸如数据稀缺和不平衡等问题依然阻碍着其发展。为解决这些问题，我们考虑通过符号表达式来建模复杂系统，这些符号表达式可以作为时间序列的语义描述符。在此基础上，我们引入了一种系列-符号（S2）双模式性数据生成机制，能够无限制地创建高质量的时间序列数据及其相应的符号表示。利用S2数据集，我们开发了SymTime，这是一个为TSA设计的预训练基础模型。当在下游任务中进行微调时，SymTime在五个主要TSA任务中的表现是竞争性的，并且其性能可以与直接基于真实世界数据集预训练的基础模型相媲美。这种方法强调了双模态数据生成和预训练机制在克服数据稀缺性和提升任务性能方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models for time series analysis (TSA) have attracted significantattention. However, challenges such as data scarcity and data imbalancecontinue to hinder their development. To address this, we consider modelingcomplex systems through symbolic expressions that serve as semantic descriptorsof time series. Building on this concept, we introduce a series-symbol (S2)dual-modulity data generation mechanism, enabling the unrestricted creation ofhigh-quality time series data paired with corresponding symbolicrepresentations. Leveraging the S2 dataset, we develop SymTime, a pre-trainedfoundation model for TSA. SymTime demonstrates competitive performance acrossfive major TSA tasks when fine-tuned with downstream task, rivaling foundationmodels pre-trained on real-world datasets. This approach underscores thepotential of dual-modality data generation and pretraining mechanisms inovercoming data scarcity and enhancing task performance.</description>
      <author>example@mail.com (Wenxuan Wang, Kai Wu, Yujian Betterest Li, Dan Wang, Xiaoyu Zhang, Jing Liu)</author>
      <guid isPermaLink="false">2502.15466v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Graph in the Vault: Protecting Edge GNN Inference with Trusted Execution Environment</title>
      <link>http://arxiv.org/abs/2502.15012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work is accepted by DAC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为GNNVault的安全策略，用于在边缘设备上部署基于TEE的图神经网络模型。&lt;h4&gt;背景&lt;/h4&gt;机器学习模型在边缘设备上的广泛应用使得其知识产权和数据隐私面临威胁。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于TEE的解决方案来保护图神经网络(GNN)模型及其使用的私有图形数据的安全性。&lt;h4&gt;方法&lt;/h4&gt;GNNVault采用'训练前划分'的设计理念，并结合了私人GNN校正器与公共骨干模型。在推理过程中，重要的GNN参数和使用到的私有图表均被安全地隔离在TEE中。&lt;h4&gt;主要发现&lt;/h4&gt;通过真实世界的应用（例如Intel SGX环境）证明，GNNVault能够有效防御最先进的链接盗窃攻击，并且对精度的影响微乎其微（小于2%）。&lt;h4&gt;结论&lt;/h4&gt;提出的GNNVault方案为保护部署于边缘设备上的图神经网络模型提供了一种新颖而有效的安全机制。&lt;h4&gt;翻译&lt;/h4&gt;广泛地在边缘设备上部署机器学习模型已经使得这些模型的知识产权和数据隐私变得脆弱。我们提出了基于可信执行环境(TEE)的第一个安全图形神经网络(GNN)部署策略，称为GNNVault。该策略遵循'训练前划分'的设计理念，并且包括了一个私人GNN校正器来补充公共骨干模型。通过这种方式，在推理过程中使用的关键性GNN模型参数和私有图都被保护在安全的TEE隔间中。基于Intel SGX的真实世界实现表明，GNNVault可以有效地抵御最先进的链接盗窃攻击，同时不会导致精度显著下降（小于2%）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wide deployment of machine learning models on edge devices has rendered themodel intellectual property (IP) and data privacy vulnerable. We proposeGNNVault, the first secure Graph Neural Network (GNN) deployment strategy basedon Trusted Execution Environment (TEE). GNNVault follows the design of'partition-before-training' and includes a private GNN rectifier to complementwith a public backbone model. This way, both critical GNN model parameters andthe private graph used during inference are protected within secure TEEcompartments. Real-world implementations with Intel SGX demonstrate thatGNNVault safeguards GNN inference against state-of-the-art link stealingattacks with negligible accuracy degradation (&lt;2%).</description>
      <author>example@mail.com (Ruyi Ding, Tianhong Xu, Aidong Adam Ding, Yunsi Fei)</author>
      <guid isPermaLink="false">2502.15012v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Synth It Like KITTI: Synthetic Data Generation for Object Detection in Driving Scenarios</title>
      <link>http://arxiv.org/abs/2502.15076v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, to appear in ROBOVIS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文旨在通过改进仿真数据集生成流程，提高从虚拟环境到真实世界场景的自主驾驶系统物体检测模型的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;在推进自动驾驶系统的进程中，模拟技术是一个重要因素。然而，目前尚无显著进展解决虚拟与现实之间转换的问题，特别是在基于LiDAR点云进行3D目标检测方面。&lt;h4&gt;目的&lt;/h4&gt;该研究重新审视了从仿真数据到真实世界应用的转化问题，并提出了一种新的数据集生成管道以增强模型在真实环境中的泛化性能。&lt;h4&gt;方法&lt;/h4&gt;采用CARLA模拟器，结合领域随机化策略和细致建模技术来训练基于合成数据的目标检测模型。同时对比不同虚拟传感器变体，探究哪些传感器属性是导致域间隙的主要因素。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用少量真实世界的数据进行微调，该模型几乎可以达到基准性能；而当使用完整的真实训练集时，则能够超过基准表现。&lt;h4&gt;结论&lt;/h4&gt;利用精心设计的模拟数据生成流程和领域随机化策略可以使仿真训练的目标检测器在现实世界的任务中表现出色。进一步的研究应该集中在如何最小化传感器属性差异，以进一步提高模型的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：推动自动驾驶系统发展的关键因素之一是模拟技术的应用。然而，在虚拟环境向真实世界场景迁移的问题上进展甚微。我们重新审视了针对基于LiDAR点云进行3D物体检测任务中的领域转移问题，提出了一种基于CARLA仿真器的生成数据集管道。通过采用领域随机化策略和精心建模方法，我们在合成数据上训练了一个目标探测器，并展示了其在KITTI数据集上的强大泛化能力。此外，我们对比了不同虚拟传感器变体以获得洞见，哪些传感器特性可能造成显著的域间隙现象。最后，在少量真实世界数据的基础上进行微调几乎可以达到基准性能水平；而使用完整的真实训练集时则超过了该基准线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; An important factor in advancing autonomous driving systems is simulation.Yet, there is rather small progress for transferability between the virtual andreal world. We revisit this problem for 3D object detection on LiDAR pointclouds and propose a dataset generation pipeline based on the CARLA simulator.Utilizing domain randomization strategies and careful modeling, we are able totrain an object detector on the synthetic data and demonstrate stronggeneralization capabilities to the KITTI dataset. Furthermore, we comparedifferent virtual sensor variants to gather insights, which sensor attributescan be responsible for the prevalent domain gap. Finally, fine-tuning with asmall portion of real data almost matches the baseline and with the fulltraining set slightly surpasses it.</description>
      <author>example@mail.com (Richard Marcus, Christian Vogel, Inga Jatzkowski, Niklas Knoop, Marc Stamminger)</author>
      <guid isPermaLink="false">2502.15076v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Fed-SB: A Silver Bullet for Extreme Communication Efficiency and Performance in (Private) Federated LoRA Fine-Tuning</title>
      <link>http://arxiv.org/abs/2502.15436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Raghav Singhal and Kaustubh Ponkshe contributed equally to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Fed-SB，一种使用LoRA-SB方法进行联邦微调的新颖方式。该方法通过学习两个适配器之间的小型正方形矩阵来优化低秩适应过程，并直接平均该矩阵以减少通信成本和保证精确更新。&lt;h4&gt;背景&lt;/h4&gt;低秩适应（LoRA）已成为有效调整基础模型的普遍技术，但使用LoRA进行联邦微调存在挑战，因为传统的个体适配器平均方法会导致次优更新。现有解决方案要么导致高昂的通信成本，要么由于表达能力受限而性能下降。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的联邦微调方法，既能减少通信开销又能保证高性能。&lt;h4&gt;方法&lt;/h4&gt;提出Fed-SB，该方法基于最近提出的LoRA-SB低秩适应技术。在两个适配器之间学习一个小型正方形矩阵R，并直接平均这个矩阵以确保精确更新和降低通信成本。&lt;h4&gt;主要发现&lt;/h4&gt;Fed-SB在常识推理、算术推理和语言推断任务上实现了最先进的性能，同时将通信开销最多减少了230倍。此外，在私人设置下，通过减少可训练参数数量来提高隐私保护，并避免其他方法引入的噪声放大问题。&lt;h4&gt;结论&lt;/h4&gt;总体而言，Fed-SB在通信成本与性能之间的权衡中开辟了一个新的帕累托前沿，为私有和非私有的联邦微调提供了高效且可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Lo-Rank 适应（LoRA）已成为有效调整基础模型的标准技术。然而，使用 LoRA 进行联邦细调具有挑战性，因为传统的个体适配器平均会导致次优更新。现有的解决方法要么导致高昂的通信成本，要么由于表达能力受限而降低性能表现。我们介绍了一种新的方法 Fed-SB，它利用了最近提出的低秩适应技术 LoRA-SB 来进行大规模语言模型（LLMs）的联邦细调。LoRA-SB 通过在适配器之间学习一个小方阵矩阵 R，并保持其他组件不变来优化适应过程。直接平均这个小方阵保证了精确更新，大大降低了通信成本，使其不受客户端数量的影响，从而实现了可扩展性。Fed-SB 在常识推理、算术推理和语言推断任务上达到了最先进的性能，同时将通信成本最多减少了230倍。在私人设置中，Fed-SB 通过减少训练参数的数量来提高差分隐私的噪声需求，并避免了其他方法引入的噪声放大问题，进一步提高了表现。总体而言，Fed-SB 在通信和性能之间的权衡上开辟了一个新的帕累托前沿，为私有和非私有的联邦细调提供了高效且可扩展的解决方案。我们的代码公开可用：https://github.com/CERT-Lab/fed-sb。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/CERT-Lab/fed-sb&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adaptation (LoRA) has become ubiquitous for efficiently fine-tuningfoundation models. However, federated fine-tuning using LoRA is challenging dueto suboptimal updates arising from traditional federated averaging ofindividual adapters. Existing solutions either incur prohibitively highcommunication cost that scales linearly with the number of clients or sufferfrom performance degradation due to limited expressivity. We introduceFederated Silver Bullet (Fed-SB), a novel approach for federated fine-tuning ofLLMs using LoRA-SB, a recently proposed low-rank adaptation method. LoRA-SBoptimally aligns the optimization trajectory with the ideal low-rank fullfine-tuning projection by learning a small square matrix (R) between adapters Band A, keeping other components fixed. Direct averaging of R guarantees exactupdates, substantially reducing communication cost, which remains independentof the number of clients, and enables scalability. Fed-SB achievesstate-of-the-art performance across commonsense reasoning, arithmeticreasoning, and language inference tasks while reducing communication costs byup to 230x. In private settings, Fed-SB further improves performance by (1)reducing trainable parameters, thereby lowering the noise required fordifferential privacy and (2) avoiding noise amplification introduced by othermethods. Overall, Fed-SB establishes a new Pareto frontier in the tradeoffbetween communication and performance, offering an efficient and scalablesolution for both private and non-private federated fine-tuning. Our code ispublicly available at https://github.com/CERT-Lab/fed-sb.</description>
      <author>example@mail.com (Raghav Singhal, Kaustubh Ponkshe, Rohit Vartak, Lav R. Varshney, Praneeth Vepakomma)</author>
      <guid isPermaLink="false">2502.15436v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Understanding the Design Principles of Link Prediction in Directed Settings</title>
      <link>http://arxiv.org/abs/2502.15008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图表示学习中有向链接预测的挑战，提出了适用于该任务的有效启发式方法，并展示了这些改进能够与为无向图设计的最佳图神经网络相媲美。&lt;h4&gt;背景&lt;/h4&gt;传统的图表示学习理论基于对称邻接矩阵假设，即认为数据是无方向性的。然而，现实世界中的关系经常包含通过方向传达的重要信息，这限制了现有模型捕捉复杂有向交互的能力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决有向链接预测的问题，并提出适用于该任务的有效方法。&lt;h4&gt;方法&lt;/h4&gt;在论文中评估了一些成功应用于无向图的关键启发式算法，然后对其进行了简单但有效的改进以适应有向链接预测的任务。&lt;h4&gt;主要发现&lt;/h4&gt;通过一系列广泛的实验研究，作者开发了一个新颖的框架来解决有向链接预测问题。该框架不仅超过了基线方法，在多个基准上的性能也优于为无向图设计的最佳图神经网络。&lt;h4&gt;结论&lt;/h4&gt;这项工作表明，对现有启发式算法进行简单的调整可以在有向图任务中实现与复杂神经网络模型相竞争的性能，并且这些改进可以提供对图表示学习框架发展的宝贵见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3701716.3717803&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction is a widely studied task in Graph Representation Learning(GRL) for modeling relational data. The early theories in GRL were based on theassumption of a symmetric adjacency matrix, reflecting an undirected setting.As a result, much of the following state-of-the-art research has continued tooperate under this symmetry assumption, even though real-world data ofteninvolve crucial information conveyed through the direction of relationships.This oversight limits the ability of these models to fully capture thecomplexity of directed interactions. In this paper, we focus on the challengeof directed link prediction by evaluating key heuristics that have beensuccessful in undirected settings. We propose simple but effective adaptationsof these heuristics to the directed link prediction task and demonstrate thatthese modifications produce competitive performance compared to the leadingGraph Neural Networks (GNNs) originally designed for undirected graphs. Throughan extensive set of experiments, we derive insights that inform the developmentof a novel framework for directed link prediction, which not only surpassesbaseline methods but also outperforms state-of-the-art GNNs on multiplebenchmarks.</description>
      <author>example@mail.com (Jun Zhai, Muberra Ozmen, Thomas Markovich)</author>
      <guid isPermaLink="false">2502.15008v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Chitrarth: Bridging Vision and Language for a Billion People</title>
      <link>http://arxiv.org/abs/2502.15392v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Chitrarth，这是一个针对印度10种语言的包容性视觉-语言模型。该模型结合了最先进的多语言大型语言模型和视觉模块，并主要在多语言图像文本数据上进行训练。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态基础模型主要是基于英语或高资源欧洲语言的数据集进行训练，这限制了它们在中低资源语言中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一局限性，研究者们引入了一个名为Chitrarth的视觉-语言模型，旨在支持印度丰富的语言多样性及跨10种主要印度语言的视觉推理。&lt;h4&gt;方法&lt;/h4&gt;研究团队使用最先进的多语言大型语言模型与视觉模块相结合的方法，并且这种结合主要是通过在包含多种语言图像文本数据集上进行训练来实现的。&lt;h4&gt;主要发现&lt;/h4&gt;该模型不仅在低资源语言基准测试中取得了最佳结果，同时在英语中的效率也得以保持。此外，他们还提出了BharatBench框架用于评估跨不同印度语言的视觉-语言模型的表现。&lt;h4&gt;结论&lt;/h4&gt;通过这项研究，研究者们旨在为多语种和多模态能力设置新的基准，并为未来的发展提供基础。&lt;h4&gt;翻译&lt;/h4&gt;最近的多种模态基础模型主要是基于英语或高资源欧洲语言的数据进行训练，这限制了它们在中低资源语言中的应用。为了应对这一局限性，我们介绍了Chitrarth（图像：图片；意义：含义），这是一个面向10种主要印度语言的语言多样性及视觉推理问题的目标包容性视觉-语言模型(VLM)。我们的模型有效地集成了最先进的多语言大型语言模型和一个视觉模块，主要是基于多种语言的图文数据进行训练。此外，我们还引入了BharatBench，这个框架用于在不同印度语中评估VLM的表现，最终促进了更加多样化的AI系统的发展。我们的模型在低资源语言基准测试中取得了最佳结果，并保持了其在英语中的效率。通过我们的研究，我们旨在为多语种和多模态能力设立新的基准，并对现有模型进行实质性的改进，从而为基础未来在这个领域的进步奠定基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent multimodal foundation models are primarily trained on English or highresource European language data, which hinders their applicability to othermedium and low-resource languages. To address this limitation, we introduceChitrarth (Chitra: Image; Artha: Meaning), an inclusive Vision-Language Model(VLM), specifically targeting the rich linguistic diversity and visualreasoning across 10 prominent Indian languages. Our model effectivelyintegrates a state-of-the-art (SOTA) multilingual Large Language Model (LLM)with a vision module, primarily trained on multilingual image-text data.Furthermore, we also introduce BharatBench, a comprehensive framework forevaluating VLMs across various Indian languages, ultimately contributing tomore diverse and effective AI systems. Our model achieves SOTA results forbenchmarks across low resource languages while retaining its efficiency inEnglish. Through our research, we aim to set new benchmarks inmultilingual-multimodal capabilities, offering substantial improvements overexisting models and establishing a foundation to facilitate future advancementsin this arena.</description>
      <author>example@mail.com (Shaharukh Khan, Ayush Tarun, Abhinav Ravi, Ali Faraz, Akshat Patidar, Praveen Kumar Pokala, Anagha Bhangare, Raja Kolla, Chandra Khatri, Shubham Agarwal)</author>
      <guid isPermaLink="false">2502.15392v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>CrossOver: 3D Scene Cross-Modal Alignment</title>
      <link>http://arxiv.org/abs/2502.15011v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: sayands.github.io/crossover/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CrossOver是一种用于多模态3D场景理解的新框架，通过灵活的场景级别模式对齐来解决传统方法需要所有对象实例都具有严格对齐的模式数据的问题。&lt;h4&gt;背景&lt;/h4&gt;当前的方法通常假设完全的数据可用性以及各模式之间的刚性对齐，这在实际应用中可能难以实现。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的框架CrossOver，该框架旨在通过灵活、场景级别的模式对齐进行跨模态3D场景理解，并且无需显式的对象语义即可学习统一的多模式无关嵌入空间。&lt;h4&gt;方法&lt;/h4&gt;利用特定于维度的编码器和多阶段训练管道，CrossOver支持具有缺失模式的数据场景检索和物体定位任务。该框架包括RGB图像、点云、CAD模型、平面图以及文本描述等多种类型的数据输入。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果在ScanNet和3RScan数据集上表现出色，显示了其在各种指标上的优越性能，并强调了适应现实世界应用的能力。&lt;h4&gt;结论&lt;/h4&gt;CrossOver框架展示了它在多模态3D场景理解中的强大能力，尤其是在处理不完整或缺失的模式时的表现。这为未来的研究提供了坚实的基础和新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;跨模式三维物体理解已经获得了相当的关注，然而当前的方法往往假设完全的数据可用性以及各模式之间的刚性对齐。我们提出了一种新的框架CrossOver，该框架通过灵活、场景级别的模式对齐进行跨模态3D场景理解，并且无需显式的对象语义即可学习统一的多模式无关嵌入空间。实验结果在ScanNet和3RScan数据集上表现出色，显示了其适应现实世界应用的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal 3D object understanding has gained significant attention, yetcurrent approaches often assume complete data availability and rigid alignmentacross all modalities. We present CrossOver, a novel framework for cross-modal3D scene understanding via flexible, scene-level modality alignment. Unliketraditional methods that require aligned modality data for every objectinstance, CrossOver learns a unified, modality-agnostic embedding space forscenes by aligning modalities - RGB images, point clouds, CAD models,floorplans, and text descriptions - with relaxed constraints and withoutexplicit object semantics. Leveraging dimensionality-specific encoders, amulti-stage training pipeline, and emergent cross-modal behaviors, CrossOversupports robust scene retrieval and object localization, even with missingmodalities. Evaluations on ScanNet and 3RScan datasets show its superiorperformance across diverse metrics, highlighting adaptability for real-worldapplications in 3D scene understanding.</description>
      <author>example@mail.com (Sayan Deb Sarkar, Ondrej Miksik, Marc Pollefeys, Daniel Barath, Iro Armeni)</author>
      <guid isPermaLink="false">2502.15011v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>DynamicGSG: Dynamic 3D Gaussian Scene Graphs for Environment Adaptation</title>
      <link>http://arxiv.org/abs/2502.15309v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种动态、高保真和开放词汇的场景图生成系统（DynamicGSG），用于机器人在不断变化的环境中有效理解和适应。&lt;h4&gt;背景&lt;/h4&gt;现实世界中，环境由于代理或人类活动的变化使得机器人执行长期任务变得非常具有挑战性。感知系统需要提取实例级别的语义信息并根据环境变化更新内存中的表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够构建层次化场景图、优化高保真重建以及动态适应长时环境变化的系统。&lt;h4&gt;方法&lt;/h4&gt;{'构造层次化场景图': '使用先进的视觉基础模型来表示环境中对象的空间和语义关系', '设计联合特征损失': '为了增量式地提高高质量重建，优化高斯地图', '更新高斯地图与场景图': '根据实际环境变化进行动态更新'}&lt;h4&gt;主要发现&lt;/h4&gt;{'性能实验': '在语义分割、语言引导的对象检索和重建质量方面展示了所提方法的效能。', '真实实验室验证': '验证了系统动态更新能力的有效性'}&lt;h4&gt;结论&lt;/h4&gt;DynamicGSG能够有效提高机器人在复杂多变环境中的适应性和执行长期任务的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于一个叫做DynamicGSG的新提出的用于机器人感知系统的解决方案，它能帮助机器人在不断变化的环境中更高效地理解和工作。该系统主要由三个部分构成：一是使用先进的视觉基础模型构建描述物体空间和语义关系的层次化场景图；二是通过设计联合特征损失来优化高斯地图，以获得增量式的高质量重建效果；三是根据真实环境的变化更新高斯地图和场景图，实现长时间内的环境适应。实验结果表明该方法在关键任务如语义分割、语言引导对象检索以及重建质量方面表现出色，并且其动态更新能力已经在实验室环境中得到了验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world scenarios, the environment changes caused by agents or humanactivities make it extremely challenging for robots to perform variouslong-term tasks. To effectively understand and adapt to dynamic environments,the perception system of a robot needs to extract instance-level semanticinformation, reconstruct the environment in a fine-grained manner, and updateits environment representation in memory according to environment changes. Toaddress these challenges, We propose \textbf{DynamicGSG}, a dynamic,high-fidelity, open-vocabulary scene graph generation system leveragingGaussian splatting. Our system comprises three key components: (1) constructinghierarchical scene graphs using advanced vision foundation models to representthe spatial and semantic relationships of objects in the environment, (2)designing a joint feature loss to optimize the Gaussian map for incrementalhigh-fidelity reconstruction, and (3) updating the Gaussian map and scene graphaccording to real environment changes for long-term environment adaptation.Experiments and ablation studies demonstrate the performance and efficacy ofthe proposed method in terms of semantic segmentation, language-guided objectretrieval, and reconstruction quality. Furthermore, we have validated thedynamic updating capabilities of our system in real laboratory environments.The source code will be releasedat:~\href{https://github.com/GeLuzhou/Dynamic-GSG}{https://github.com/GeLuzhou/DynamicGSG}.</description>
      <author>example@mail.com (Luzhou Ge, Xiangyu Zhu, Zhuo Yang, Xuesong Li)</author>
      <guid isPermaLink="false">2502.15309v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Lung-DDPM: Semantic Layout-guided Diffusion Models for Thoracic CT Image Synthesis</title>
      <link>http://arxiv.org/abs/2502.15204v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code and pretrained models are available at  https://github.com/Manem-Lab/Lung-DDPM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种基于AI的胸部CT影像合成方法Lung-DDPM，旨在解决肺癌早期筛查中数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能技术的发展，AI辅助医学影像分析在肺癌早期筛查方面表现出色。然而，高昂的数据标注成本和隐私问题限制了大规模医疗数据集的构建，阻碍了AI在医疗领域的进一步应用。&lt;h4&gt;目的&lt;/h4&gt;为了应对肺癌筛查中的数据稀缺问题，提出了一种胸部CT图像合成方法Lung-DDPM，以生成高质量的3D合成CT影像，并应用于下游肺结节分割任务中。&lt;h4&gt;方法&lt;/h4&gt;该方法基于语义布局引导去噪扩散概率模型（DDPM），能够从不完整的语义布局中生成解剖学合理的、无缝且一致的样本图像。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，Lung-DDPM在图像质量评估和下游肺结节分割任务方面优于其他最先进的生成模型。具体而言，在验证队列中FID为0.0047、MMD为0.0070、MSE为0.0024，分别比第二好的竞争对手高7.4倍、3.1倍和29.5倍。此外，结合真实数据与Lung-DDPM生成的数据训练的肺结节分割模型在Dice系数和敏感性方面分别优于单独使用真实数据模型8.8%和18.6%。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明Lung-DDPM具有更广泛的应用潜力，例如肿瘤分割、癌症生存估计以及风险预测等方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着人工智能（AI）的快速发展，基于AI的医学影像分析在肺癌早期筛查中展现出显著的效果。然而，高昂的数据标注成本和隐私问题限制了大规模医疗数据集的构建，阻碍了AI在医疗领域的进一步应用。为了应对肺癌筛查中的数据稀缺问题，本文提出了一种胸部CT图像合成方法Lung-DDPM，该方法能够有效生成高保真的3D合成CT影像，在下游肺结节分割任务中证明很有帮助。本研究基于语义布局引导去噪扩散概率模型（DDPM），即使从不完整的语义布局也能生成解剖学合理的、无缝且一致的样本图像。实验结果显示，该方法在图像质量评估和下游肺结节分割任务方面优于其他最先进的生成模型。具体而言，在验证队列中分别取得了FID为0.0047、MMD为0.0070以及MSE为0.0024的成绩，并且这些结果分别为第二好的竞争对手的7.4倍、3.1倍和29.5倍更好。此外，结合真实数据与Lung-DDPM生成的数据训练的肺结节分割模型在Dice系数和敏感性方面分别达到了0.3914和0.4393的成绩，比单独使用真实数据模型高8.8%和18.6%。实验结果表明Lung-DDPM具有更广泛的应用潜力，例如肿瘤分割、癌症生存估计以及风险预测等方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of artificial intelligence (AI), AI-assistedmedical imaging analysis demonstrates remarkable performance in early lungcancer screening. However, the costly annotation process and privacy concernslimit the construction of large-scale medical datasets, hampering the furtherapplication of AI in healthcare. To address the data scarcity in lung cancerscreening, we propose Lung-DDPM, a thoracic CT image synthesis approach thateffectively generates high-fidelity 3D synthetic CT images, which prove helpfulin downstream lung nodule segmentation tasks. Our method is based on semanticlayout-guided denoising diffusion probabilistic models (DDPM), enablinganatomically reasonable, seamless, and consistent sample generation even fromincomplete semantic layouts. Our results suggest that the proposed methodoutperforms other state-of-the-art (SOTA) generative models in image qualityevaluation and downstream lung nodule segmentation tasks. Specifically,Lung-DDPM achieved superior performance on our large validation cohort, with aFr\'echet inception distance (FID) of 0.0047, maximum mean discrepancy (MMD) of0.0070, and mean squared error (MSE) of 0.0024. These results were 7.4$\times$,3.1$\times$, and 29.5$\times$ better than the second-best competitors,respectively. Furthermore, the lung nodule segmentation model, trained on adataset combining real and Lung-DDPM-generated synthetic samples, attained adice coefficient (Dice) of 0.3914 and sensitivity of 0.4393. This represents8.8\% and 18.6\% improvements in DICE and sensitivity compared to the modeltrained solely on real samples. The experimental results highlight Lung-DDPM'spotential for a broader range of medical imaging applications, such as generaltumor segmentation, cancer survival estimation, and risk prediction.</description>
      <author>example@mail.com (Yifan Jiang, Yannick Lemaréchal, Josée Bafaro, Jessica Abi-Rjeile, Philippe Joubert, Philippe Després, Venkata Manem)</author>
      <guid isPermaLink="false">2502.15204v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>FacaDiffy: Inpainting Unseen Facade Parts Using Diffusion Models</title>
      <link>http://arxiv.org/abs/2502.14940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for GeoSpatial Week 2025, ISPRS Annals&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了FacaDiffy，这是一种利用个性化稳定扩散模型填补2D冲突地图中未见立面部分的方法，从而提高高精度3D语义建筑重建中的开口位置检测率。&lt;h4&gt;背景&lt;/h4&gt;在创建高细节的三维建筑物模型时，2D冲突图用于识别建筑物外墙上的开口位置。然而，在实际激光扫描过程中，这些2D冲突图由于障碍物的影响往往是不完整的。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来填补2D冲突地图中未见立面部分，并使用个性化稳定扩散模型来完成冲突地图的绘制。&lt;h4&gt;方法&lt;/h4&gt;{'1': '首先提出了一个确定性的光线分析方法，从现有的3D建筑模型和对应的激光扫描点云数据中推导出2D冲突图', '2': '利用个性化稳定扩散模型的能力将未见立面对象填充到这些2D冲突图中。', '3': '为了补充真实世界训练数据的不足，开发了一条可扩展的数据生成流水线，使用随机城市模型生成器和标记后的立面图像来创建合成冲突地图。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，FacaDiffy在与各种填补基线相比时，在2D冲突图完成方面达到了最先进的性能，并且当应用到高精度3D语义建筑重建中时，检测率提高了22%。&lt;h4&gt;结论&lt;/h4&gt;该方法通过个性化稳定扩散模型有效地解决了实际激光扫描过程中遇到的建筑物外墙部分缺失的问题，为高细节三维模型创建提供了强有力的支持。&lt;h4&gt;翻译&lt;/h4&gt;详细摘要的中文翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-detail semantic 3D building models are frequently utilized in robotics,geoinformatics, and computer vision. One key aspect of creating such models isemploying 2D conflict maps that detect openings' locations in building facades.Yet, in reality, these maps are often incomplete due to obstacles encounteredduring laser scanning. To address this challenge, we introduce FacaDiffy, anovel method for inpainting unseen facade parts by completing conflict mapswith a personalized Stable Diffusion model. Specifically, we first propose adeterministic ray analysis approach to derive 2D conflict maps from existing 3Dbuilding models and corresponding laser scanning point clouds. Furthermore, wefacilitate the inpainting of unseen facade objects into these 2D conflict mapsby leveraging the potential of personalizing a Stable Diffusion model. Tocomplement the scarcity of real-world training data, we also develop a scalablepipeline to produce synthetic conflict maps using random city model generatorsand annotated facade images. Extensive experiments demonstrate that FacaDiffyachieves state-of-the-art performance in conflict map completion compared tovarious inpainting baselines and increases the detection rate by $22\%$ whenapplying the completed conflict maps for high-definition 3D semantic buildingreconstruction. The code is be publicly available in the corresponding GitHubrepository: https://github.com/ThomasFroech/InpaintingofUnseenFacadeObjects</description>
      <author>example@mail.com (Thomas Froech, Olaf Wysocki, Yan Xia, Junyu Xie, Benedikt Schwab, Daniel Cremers, Thomas H. Kolbe)</author>
      <guid isPermaLink="false">2502.14940v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>TransMamba: Fast Universal Architecture Adaption from Transformers to Mamba</title>
      <link>http://arxiv.org/abs/2502.15130v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨了利用现有的Transformer模型如LLaVA、CLIP和DEIT的知识，通过跨架构训练来增强Mamba架构的性能。提出了TransMamba方法，并采用两阶段策略加速新Mamba模型的训练。&lt;h4&gt;背景&lt;/h4&gt;Transformer因其注意力模块在单模态和多模态基础模型中的灵活扩展性而受到青睐，但从头开始为特定任务培训专门的次二次架构既耗时又耗费资源。&lt;h4&gt;目的&lt;/h4&gt;探索如何通过跨架构训练将现有的预训练Transformer模型的知识转移到Mamba架构上，以提升其性能并减少所需的训练时间和计算资源。&lt;h4&gt;方法&lt;/h4&gt;采用两种主要策略：一是引入Weight Subcloning and Adaptive Bidirectional distillation (WSAB) 方法来实现不受层数限制的知识迁移；二是设计了一个跨模态学习模块——cross-Mamba模块，该模块将语言感知与Mamba的视觉特征相结合，从而增强其处理跨模态任务的能力。&lt;h4&gt;主要发现&lt;/h4&gt;TransMamba在使用不到常规从头训练所需75%的数据量的情况下，在各种网络架构和下游任务中（如图像分类、视觉问答、文本视频检索等）表现出色。&lt;h4&gt;结论&lt;/h4&gt;通过将现有的Transformer模型的知识转移到Mamba架构上，可以显著提高后者的性能，并且代码将在未来公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformers have been favored in both uni-modal and multi-modal foundationmodels for their flexible scalability in attention modules. Consequently, anumber of pre-trained Transformer models, e.g., LLaVA, CLIP, and DEIT, arepublicly available. Recent research has introduced subquadratic architectureslike Mamba, which enables global awareness with linear complexity.Nevertheless, training specialized subquadratic architectures from scratch forcertain tasks is both resource-intensive and time-consuming. As a motivator, weexplore cross-architecture training to transfer the ready knowledge in existingTransformer models to alternative architecture Mamba, termed TransMamba. Ourapproach employs a two-stage strategy to expedite training new Mamba models,ensuring effectiveness in across uni-modal and cross-modal tasks. Concerningarchitecture disparities, we project the intermediate features into an alignedlatent space before transferring knowledge. On top of that, a Weight Subcloningand Adaptive Bidirectional distillation method (WSAB) is introduced forknowledge transfer without limitations on varying layer counts. For cross-modallearning, we propose a cross-Mamba module that integrates language awarenessinto Mamba's visual features, enhancing the cross-modal interactioncapabilities of Mamba architecture. Despite using less than 75% of the trainingdata typically required for training from scratch, TransMamba boastssubstantially stronger performance across various network architectures anddownstream tasks, including image classification, visual question answering,and text-video retrieval. The code will be publicly available.</description>
      <author>example@mail.com (Xiuwei Chen, Sihao Lin, Xiao Dong, Zisheng Chen, Meng Cao, Jianhua Han, Hang Xu, Xiaodan Liang)</author>
      <guid isPermaLink="false">2502.15130v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning</title>
      <link>http://arxiv.org/abs/2502.15082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/Vaidehi99/UPCORE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;UPCORE是一种用于减轻遗忘过程中附带损害的数据选择框架。该方法通过减少模型在忘记集上的表示方差来最小化模型退化。&lt;h4&gt;背景&lt;/h4&gt;当需要从预训练模型中删除特定信息时，通常会导致模型性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够平衡信息删除和保留模型其他能力的方法，避免因失去平衡导致的模型不可用或效果不佳。&lt;h4&gt;方法&lt;/h4&gt;UPCORE是一种与方法无关的数据选择框架。通过选择性修剪忘记集来减少离群值，以最小化遗忘后的模型退化。&lt;h4&gt;主要发现&lt;/h4&gt;在三种标准删除方法上评估了UPCORE的表现，并引入了一个新的度量标准（AUC），用于衡量其效果优于其他现有技术。&lt;h4&gt;结论&lt;/h4&gt;UPCORE不仅提高了标准指标和AUC的得分，还通过减少负面迁移并利用核心集与修剪点之间的积极迁移效应来增强模型性能。&lt;h4&gt;翻译&lt;/h4&gt;用户规格或法律法规通常要求从预训练模型（包括大型语言模型）中移除信息。这需要删除或“忘记”一组已训练模型中的数据点，通常会导致其在其他数据点上的表现下降。因此，在去除信息和保持模型其余功能之间必须找到平衡，否则可能导致较差的删除效果或不可用的模型。为此，我们提出了UPCORE（Utility-Preserving Coreset Selection），这是一种用于减轻遗忘过程中附带损害的方法无关的数据选择框架。发现模型损坏与忘记集上表示方差相关，通过选择性地修剪该集合来去除离群值从而最小化遗忘后的退化。我们在三种标准删除方法中评估了UPCORE，并始终达到在删除有效性和模型保留之间竞争目标的优越平衡。为了更好地衡量这种权衡，我们引入了一个新的度量指标（AUC），其结果表明UPCORE提高了标准指标和AUC的得分，通过减少负面迁移并利用核心集与修剪点之间的积极迁移效应来增强模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; User specifications or legal frameworks often require information to beremoved from pretrained models, including large language models (LLMs). Thisrequires deleting or "forgetting" a set of data points from an already-trainedmodel, which typically degrades its performance on other data points. Thus, abalance must be struck between removing information and keeping the model'sother abilities intact, with a failure to balance this trade-off leading topoor deletion or an unusable model. To this end, we propose UPCORE(Utility-Preserving Coreset Selection), a method-agnostic data selectionframework for mitigating collateral damage during unlearning. Finding that themodel damage is correlated with the variance of the model's representations onthe forget set, we selectively prune the forget set to remove outliers, therebyminimizing model degradation after unlearning. We evaluate UPCORE across threestandard unlearning methods consistently achieving a superior balance betweenthe competing objectives of deletion efficacy and model preservation. To betterevaluate this trade-off, we introduce a new metric, measuring thearea-under-the-curve (AUC) across standard metrics. We find that UPCOREimproves both standard metrics and AUC, benefitting from positive transferbetween the coreset and pruned points while reducing negative transfer from theforget set to points outside of it.</description>
      <author>example@mail.com (Vaidehi Patil, Elias Stengel-Eskin, Mohit Bansal)</author>
      <guid isPermaLink="false">2502.15082v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Towards Physics-Guided Foundation Models</title>
      <link>http://arxiv.org/abs/2502.15013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的物理引导基础模型（PGFM），旨在将广泛领域的物理知识集成到传统基础模型中。&lt;h4&gt;背景&lt;/h4&gt;传统的基础模型是通过大规模数据集预训练的，目的是减少微调大量下游任务所需的资源。&lt;h4&gt;目的&lt;/h4&gt;解决传统基础模型在处理分布外预测时的问题，并避免产生不现实或物理上不可行的输出。&lt;h4&gt;方法&lt;/h4&gt;提出将广泛领域的（例如科学领域）通用知识集成到基础模型中的方法，形成物理引导基础模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统的基础模型通过大规模数据集进行预训练，以减少在广泛的下游任务中微调所需的资源（如时间、能量和标记样本）。然而，传统的基础模型难以处理分布外预测，并且会产生不现实或物理上不可行的输出。我们提出了物理引导基础模型（PGFM）的概念，即将适用于广泛下游任务的广义或通用领域知识（例如科学领域的知识）集成到基础模型中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional foundation models are pre-trained on broad datasets to reduce thetraining resources (e.g., time, energy, labeled samples) needed for fine-tuninga wide range of downstream tasks. However, traditional foundation modelsstruggle with out-of-distribution prediction and can produce outputs that areunrealistic and physically infeasible. We propose the notation ofphysics-guided foundation models (PGFM), that is, foundation models integratedwith broad or general domain (e.g., scientific) physical knowledge applicableto a wide range of downstream tasks.</description>
      <author>example@mail.com (Majid Farhadloo, Arun Sharma, Mingzhou Yang, Bharat Jayaprakash, William Northrop, Shashi Shekhar)</author>
      <guid isPermaLink="false">2502.15013v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Obliviate: Efficient Unmemorization for Protecting Intellectual Property in Large Language Models</title>
      <link>http://arxiv.org/abs/2502.15010v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近的版权协议强调了对语言模型复制受版权保护的内容的能力进行精确控制的需求。提出了一种名为Obliviate的新方法，该方法是一种新型的后训练技术，能够选择性地防止特定文本的逐字复制，同时保持语义理解。&lt;h4&gt;背景&lt;/h4&gt;AI公司与内容创作者之间的最近版权协议强调了对语言模型在复制受版权保护的内容时进行精确控制的需求。现有方法依赖于通过去学习或简单输出过滤来完全移除概念。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的后训练技术Obliviate，该技术能够选择性地防止逐字复制特定文本，同时保持语义理解。&lt;h4&gt;方法&lt;/h4&gt;Obliviate通过在记忆序列中选择标记并修改模型的概率分布以防止精确复制来工作，同时维持上下文理解。评估了多个大型语言模型（LLaMA-3.1 8B、LLaMA-3.1-instruct 8B、Qwen-2.5-7B 和 Yi-1.5 6B）在合成记忆任务和有机版权内容上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Obliviate实现了逐字记忆的数个数量级（例如100倍）的减少，同时保持了模型性能与基准线相比仅下降不到1%。这对于解决预训练模型中的版权问题尤其有效，而不损害其通用能力。&lt;h4&gt;结论&lt;/h4&gt;由于在解决语言模型中出现的版权复制风险方面表现出了显著的效果，并且能够在不影响整体功能的情况下大幅度降低逐字记忆的风险，Obliviate非常适合于实际部署场景。&lt;h4&gt;翻译&lt;/h4&gt;最近的版权协议强调了对AI语言模型复制受版权保护内容能力进行精确控制的需求。现有方法依赖完全移除概念或简单输出过滤来解决此问题。然而，这项研究提出了一种名为Obliviate的新后训练技术，该技术能够选择性地防止逐字复现特定文本，同时保持语义理解。通过在大型语言模型上进行了测试，证明了这种方法可以大幅度减少复制风险，而不会影响模型的性能和通用能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent copyright agreements between AI companies and content creators havehighlighted the need for precise control over language models' ability toreproduce copyrighted content. While existing approaches rely on eithercomplete concept removal through unlearning or simple output filtering, wepropose Obliviate, a novel post-training technique that selectively preventsverbatim reproduction of specific text while preserving semantic understanding.  Obliviate operates by selecting tokens within memorized sequences andmodifying the model's probability distribution to prevent exact reproductionwhile maintaining contextual understanding. We evaluate Obliviate on multiplelarge language models (LLaMA-3.1 8B, LLaMA-3.1-instruct 8B, Qwen-2.5-7B, andYi-1.5 6B) across both synthetic memorization tasks and organic copyrightcontent. Our results demonstrate that Obliviate achieves orders of magnitudereduction, e.g., 100x, in verbatim memorization while maintaining modelperformance within 1% of baseline on standard benchmarks (HellaSwag, MMLU,TruthfulQA, and Winogrande). This makes Obliviate particularly suitable forpractical deployment scenarios where companies need to efficiently addresscopyright concerns in pretrained models without compromising their generalcapabilities.</description>
      <author>example@mail.com (Mark Russinovich, Ahmed Salem)</author>
      <guid isPermaLink="false">2502.15010v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Vision Foundation Models in Medical Image Analysis: Advances and Challenges</title>
      <link>http://arxiv.org/abs/2502.14584v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了视觉基础模型在医学图像分割领域适应性的最新研究进展，重点讨论了域适应、模型压缩和联邦学习的挑战，并提出了未来的研究方向。&lt;h4&gt;背景&lt;/h4&gt;随着Vision Foundation Models (VFMs)的发展，特别是ViT和SAM模型，在医疗影像分析中的应用显示出卓越的能力。然而，将这些大型模型应用于医学图像分析面临多个挑战，包括医学图像与自然图像之间的领域差异、高效的适应策略需求以及小规模数据集的限制。&lt;h4&gt;目的&lt;/h4&gt;该论文旨在提供关于视觉基础模型在医学图像分割中适应性的最新研究进展的一个全面概述，并指出未来研究的关键领域以推动下一轮创新。&lt;h4&gt;方法&lt;/h4&gt;文章回顾了基于适配器改进的方法、知识蒸馏技术以及多尺度上下文特征建模的发展。&lt;h4&gt;主要发现&lt;/h4&gt;最新的发展包括通过新兴的技术如联邦学习和模型压缩，增强了视觉基础模型在医学图像分析领域的潜力。&lt;h4&gt;结论&lt;/h4&gt;文中强调了VFMs的未来应用前景，并指出了克服现有瓶颈的关键方法。文章呼吁研究者们关注这些领域以推动医疗影像分割技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了Vision Foundation Models (VFMs)迅速发展，特别是在医学图像分析中展示了出色的能力。但是将它们应用于医疗图像存在许多挑战，如领域差异、模型适应策略效率需求和小规模数据集的限制。本文综述了相关最新研究，并提出了未来的研究方向以克服这些瓶颈。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of Vision Foundation Models (VFMs), particularly VisionTransformers (ViT) and Segment Anything Model (SAM), has sparked significantadvances in the field of medical image analysis. These models have demonstratedexceptional capabilities in capturing long-range dependencies and achievinghigh generalization in segmentation tasks. However, adapting these large modelsto medical image analysis presents several challenges, including domaindifferences between medical and natural images, the need for efficient modeladaptation strategies, and the limitations of small-scale medical datasets.This paper reviews the state-of-the-art research on the adaptation of VFMs tomedical image segmentation, focusing on the challenges of domain adaptation,model compression, and federated learning. We discuss the latest developmentsin adapter-based improvements, knowledge distillation techniques, andmulti-scale contextual feature modeling, and propose future directions toovercome these bottlenecks. Our analysis highlights the potential of VFMs,along with emerging methodologies such as federated learning and modelcompression, to revolutionize medical image analysis and enhance clinicalapplications. The goal of this work is to provide a comprehensive overview ofcurrent approaches and suggest key areas for future research that can drive thenext wave of innovation in medical image segmentation.</description>
      <author>example@mail.com (Pengchen Liang, Bin Pu, Haishan Huang, Yiwei Li, Hualiang Wang, Weibo Ma, Qing Chang)</author>
      <guid isPermaLink="false">2502.14584v2</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>M2LADS Demo: A System for Generating Multimodal Learning Analytics Dashboards</title>
      <link>http://arxiv.org/abs/2502.15363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in the Workshop on Innovation and Responsibility in  AI-Supported Education (iRAISE25) at AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍了一种基于Web的系统M2LADS，该系统旨在整合、同步并可视化在计算机学习过程中通过生物传感器记录的多模态数据。&lt;h4&gt;目的&lt;/h4&gt;提供详细的生理和活动相关的指标见解，并帮助数据科学家通过综合视图展示参与者的体验以及简化错误活动信息的数据重标记过程。&lt;h4&gt;方法&lt;/h4&gt;使用EEG数据评估注意力和大脑活动，心率指标、眼动追踪数据测量视觉注意，网络摄像头视频录制以及监控任务的日志记录等多模态数据进行可视化。&lt;h4&gt;主要发现&lt;/h4&gt;M2LADS系统能将多种生物信号及视频同步，并通过基于Web的仪表板展示参与者的行为和生理数据，使研究人员能够更详细地了解学习者在不同活动中的表现。&lt;h4&gt;结论&lt;/h4&gt;该系统的使用为教育研究领域提供了新的视角，增强了对计算机辅助学习环境中学生行为和生理状态的理解。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一个名为M2LADS的基于Web的系统（用于生成多模态学习分析仪表板），旨在整合、同步、可视化并分析在使用生物传感器记录计算机辅助学习过程中的多模态数据。该系统在一个Web仪表板上展示了广泛的生物测量和行为数据，提供了对各种生理和活动相关指标的深入了解。可视化的多模态数据包括用于评估注意力和大脑活动的脑电图（EEG）数据、心率指标、通过眼动追踪来衡量视觉关注的数据、网络摄像头视频记录以及监控任务的日志。M2LADS旨在以两种关键方式帮助数据科学家：(1)提供参与者体验的综合视图，将所有数据按参与者的活动进行分类展示；(2)同步所有的生物信号和视频，使在错误活动中更容易重标记数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a demonstration of a web-based system called M2LADS ("System forGenerating Multimodal Learning Analytics Dashboards"), designed to integrate,synchronize, visualize, and analyze multimodal data recorded duringcomputer-based learning sessions with biosensors. This system presents a rangeof biometric and behavioral data on web-based dashboards, providing detailedinsights into various physiological and activity-based metrics. The multimodaldata visualized include electroencephalogram (EEG) data for assessing attentionand brain activity, heart rate metrics, eye-tracking data to measure visualattention, webcam video recordings, and activity logs of the monitored tasks.M2LADS aims to assist data scientists in two key ways: (1) by providing acomprehensive view of participants' experiences, displaying all datacategorized by the activities in which participants are engaged, and (2) bysynchronizing all biosignals and videos, facilitating easier data relabeling ifany activity information contains errors.</description>
      <author>example@mail.com (Alvaro Becerra, Roberto Daza, Ruth Cobos, Aythami Morales, Julian Fierrez)</author>
      <guid isPermaLink="false">2502.15363v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Research advances on fish feeding behavior recognition and intensity quantification methods in aquaculture</title>
      <link>http://arxiv.org/abs/2502.15311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 4 figures,&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了基于计算机视觉、声学和传感器单一模态的鱼类进食行为识别与强度量化方法的研究进展，并探讨了当前新兴多模态融合技术在鱼类进食行为识别与强度量化的应用。&lt;h4&gt;背景&lt;/h4&gt;鱼饲料投喂行为的识别与定量分析是水产养殖管理的关键部分，对于监测鱼类健康、指导饲喂工作和提高水产养殖效率具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;为了更好地进行未来相关研究，本论文回顾了基于单一模态技术（计算机视觉、声学及传感器）的研究进展，并探讨多模态融合在该领域的应用。此外还分析了各种方法的优缺点并展望了未来的研发方向。&lt;h4&gt;方法&lt;/h4&gt;论文首先总结了单模态技术如计算机视觉、声学和传感器技术在此研究领域内的研究成果，随后详细介绍了新兴的多模态融合技术的应用情况。&lt;h4&gt;主要发现&lt;/h4&gt;通过对比分析不同技术的优点与不足之处，揭示未来的研究趋势和方向。&lt;h4&gt;结论&lt;/h4&gt;基于对已有工作的回顾以及当前研究状况的理解，论文认为结合多种数据源和技术手段（特别是多模态方法）来解决鱼类进食行为识别及强度量化问题具有广阔的前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As a key part of aquaculture management, fish feeding behavior recognitionand intensity quantification has been a hot area of great concern toresearchers, and it plays a crucial role in monitoring fish health, guidingbaiting work and improving aquaculture efficiency. In order to better carry outthe related work in the future, this paper firstly reviews the researchadvances of fish feeding behavior recognition and intensity quantificationmethods based on computer vision, acoustics and sensors in a single modality.Then the application of the current emerging multimodal fusion in fish feedingbehavior recognition and intensity quantification methods is expounded.Finally, the advantages and disadvantages of various techniques are comparedand analyzed, and the future research directions are envisioned.</description>
      <author>example@mail.com (Shulong Zhang, Daoliang Li, Jiayin Zhao, Mingyuan Yao, Yingyi Chen, Yukang Huo, Xiao Liu, Haihua Wang)</author>
      <guid isPermaLink="false">2502.15311v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Q-PETR: Quant-aware Position Embedding Transformation for Multi-View 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.15488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的量化感知位置嵌入变换(Q-PETR)方法，以提高多视角3D物体检测模型在INT8推理时的精度。&lt;h4&gt;背景&lt;/h4&gt;PETR系列的方法在3D感知领域占据主导地位，并成为现代自动驾驶系统的关键组件。但是，在需要INT8推理的情况下，这些模型的量化性能显著下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的量化感知位置嵌入变换方法(Q-PETR)，以解决PETR系列方法在INT8推理时精度下降的问题。&lt;h4&gt;方法&lt;/h4&gt;设计了一种针对多视角3D物体检测任务的量化友好的位置嵌入转换机制，即Q-PETR，它可以在保持原始性能的同时提供更友好的部署环境。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在标准的8位定点后训练量化中，该方法将mAP和NDS下降限制在1%以内。此外，该方法还超过了原PETR模型在浮点精度上的表现，并且具有广泛的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;Q-PETR提供了一种同时解决性能和部署问题的有效解决方案，在INT8推理时能够大幅缩小与FP32推理之间的准确度差距。&lt;h4&gt;翻译&lt;/h4&gt;基于PETR的方法已经在3D感知领域占据主导地位，越来越成为现代自动驾驶系统中的关键组件。然而，当需要进行INT8推理时，它们的量化表现显著下降，例如在NuScenes数据集上分别导致了58.2% mAP和36.9% NDS的性能损失。为了解决这一问题，我们提出了一种针对多视角3D物体检测任务的量化感知位置嵌入变换方法(Q-PETR)，它提供了更加友好的量化部署环境同时保持了PETR的原始性能。此外，该方法在标准8位定点后训练量化下大幅缩小了INT8和FP32推理之间的准确度差距，并且在浮点精度上超过了原PETR模型的表现。通过针对多种PETR系列模型进行广泛的实验验证了其泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; PETR-based methods have dominated benchmarks in 3D perception and areincreasingly becoming a key component in modern autonomous driving systems.However, their quantization performance significantly degrades when INT8inference is required, with a degradation of 58.2% in mAP and 36.9% in NDS onthe NuScenes dataset. To address this issue, we propose a quantization-awareposition embedding transformation for multi-view 3D object detection, termedQ-PETR. Q-PETR offers a quantizationfriendly and deployment-friendlyarchitecture while preserving the original performance of PETR. Itsubstantially narrows the accuracy gap between INT8 and FP32 inference forPETR-series methods. Without bells and whistles, our approach reduces the mAPand NDS drop to within 1% under standard 8-bit per-tensor post-trainingquantization. Furthermore, our method exceeds the performance of the originalPETR in terms of floating-point precision. Extensive experiments across avariety of PETR-series models demonstrate its broad generalization.</description>
      <author>example@mail.com (Jiangyong Yu, Changyong Shu, Dawei Yang, Zichen Yu, Xing Hu, Yan Chen)</author>
      <guid isPermaLink="false">2502.15488v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>CoDiff: Conditional Diffusion Model for Collaborative 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.14891v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;合作3D物体检测在自动驾驶领域具有重要意义，它通过多代理系统之间的信息交换极大地增强了单个代理的感知能力。&lt;h4&gt;背景&lt;/h4&gt;由于姿态估计误差和时间延迟的影响，在实际应用中，跨多个代理的信息融合通常会导致带有空间和时间噪声的功能表示，并导致检测错误。&lt;h4&gt;目的&lt;/h4&gt;为了应对多代理系统之间存在的噪音问题，我们探索了使用扩散模型来净化嘈杂样本并将其转化为理想数据的可能性。&lt;h4&gt;方法&lt;/h4&gt;提出了CoDiff框架，该框架利用预训练的自编码器的强大潜在空间将高维特征图转换为低维度，并通过条件引导的方式让各个代理的信息指导扩散模型进行采样。这一过程可以去除粗糙特征图中的噪声，并逐步细化融合后的特征。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和真实世界数据集上的实验研究表明，所提出的CoDiff框架在合作物体检测性能方面比现有的相关方法更加出色，尤其当代理的姿态信息和延迟带有高水平的噪音时，其表现出高度期望的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;这是首次将扩散模型应用于多代理协作感知的工作。该工作表明了扩散模型解决多代理系统中噪声问题的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了合作3D物体检测在自动驾驶中的重要性，指出当前方法面临的挑战，并提出了一种新的框架CoDiff，利用扩散模型来提高特征表示的质量和清晰度，实验结果证明其优越性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collaborative 3D object detection holds significant importance in the fieldof autonomous driving, as it greatly enhances the perception capabilities ofeach individual agent by facilitating information exchange among multipleagents. However, in practice, due to pose estimation errors and time delays,the fusion of information across agents often results in featurerepresentations with spatial and temporal noise, leading to detection errors.Diffusion models naturally have the ability to denoise noisy samples to theideal data, which motivates us to explore the use of diffusion models toaddress the noise problem between multi-agent systems. In this work, we proposeCoDiff, a novel robust collaborative perception framework that leverages thepotential of diffusion models to generate more comprehensive and clearerfeature representations. To the best of our knowledge, this is the first workto apply diffusion models to multi-agent collaborative perception.Specifically, we project high-dimensional feature map into the latent space ofa powerful pre-trained autoencoder. Within this space, individual agentinformation serves as a condition to guide the diffusion model's sampling. Thisprocess denoises coarse feature maps and progressively refines the fusedfeatures. Experimental study on both simulated and real-world datasetsdemonstrates that the proposed framework CoDiff consistently outperformsexisting relevant methods in terms of the collaborative object detectionperformance, and exhibits highly desired robustness when the pose and delayinformation of agents is with high-level noise.</description>
      <author>example@mail.com (Zhe Huang, Shuo Wang, Yongcai Wang, Lei Wang)</author>
      <guid isPermaLink="false">2502.14891v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Network Resource Optimization for ML-Based UAV Condition Monitoring with Vibration Analysis</title>
      <link>http://arxiv.org/abs/2502.15491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in IEEE Networking Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;随着智慧城市的发展，无人飞行器（UAVs）及其可靠性变得越来越重要。本文通过优化基于机器学习的UAV条件监测框架中的网络资源利用来提高其在边缘计算环境下的效率。&lt;h4&gt;背景&lt;/h4&gt;智慧城市的构建推动了对UAV可靠性的需求，其中机器学习模型用于识别异常和不利条件是关键环节之一。&lt;h4&gt;目的&lt;/h4&gt;探索如何最小化下一代边缘网络中珍贵的网络资源使用，并优化基于ML的UAV状态监测框架中的网络资源配置。&lt;h4&gt;方法&lt;/h4&gt;开发了一种利用实验数据并调整特征提取聚合间隔来选择最有效机器学习模型的方法，同时采用维度降低技术减少了99.9%的网络资源消耗。&lt;h4&gt;主要发现&lt;/h4&gt;通过上述方法，在保证准确性的前提下显著降低了网络资源使用量。&lt;h4&gt;结论&lt;/h4&gt;提出的框架能够有效地减少基于ML的UAV状态监测系统所需的网络资源，并提高了在有限资源条件下的性能表现。&lt;h4&gt;翻译&lt;/h4&gt;随着智慧城市的发展，无人飞行器（UAVs）及其可靠性变得越来越重要。本文通过优化基于机器学习的UAV条件监测框架中的网络资源利用来提高其在边缘计算环境下的效率。研究指出，在资源受限的下一代边缘网络环境中，需要尽可能地减少珍贵的网络资源使用量。所提出的方法通过调整特征提取聚合间隔，并采用维度降低技术实现了这一目标，同时保证了模型性能和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As smart cities begin to materialize, the role of Unmanned Aerial Vehicles(UAVs) and their reliability becomes increasingly important. One aspect ofreliability relates to Condition Monitoring (CM), where Machine Learning (ML)models are leveraged to identify abnormal and adverse conditions. Given theresource-constrained nature of next-generation edge networks, the utilizationof precious network resources must be minimized. This work explores theoptimization of network resources for ML-based UAV CM frameworks. The developedframework uses experimental data and varies the feature extraction aggregationinterval to optimize ML model selection. Additionally, by leveragingdimensionality reduction techniques, there is a 99.9% reduction in networkresource consumption.</description>
      <author>example@mail.com (Alexandre Gemayel, Dimitrios Michael Manias, Abdallah Shami)</author>
      <guid isPermaLink="false">2502.15491v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>BOSS: Benchmark for Observation Space Shift in Long-Horizon Task</title>
      <link>http://arxiv.org/abs/2502.15679v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于评估观察空间移位（OSS）对长时任务影响的新基准测试BOSS，并展示了几种模仿学习算法在面对此类问题时的性能下降情况。&lt;h4&gt;背景&lt;/h4&gt;视觉伺服机器人旨在完成前所未见的长期任务，而分层方法通过执行由任务计划器安排的技能组合来实现这一目标。然而，在简单如技巧串联的任务中，观察空间移位的问题会破坏单独训练的技能策略的表现。&lt;h4&gt;目的&lt;/h4&gt;提出并验证BOSS基准测试，评估模仿学习算法在面对观察空间移位问题时的性能下降情况，并探索解决OSS的方法。&lt;h4&gt;方法&lt;/h4&gt;引入了BOSS（观察空间移位基准）来衡量和评估观察空间移位对长时任务的影响。BOSS包括三个不同的挑战：单一谓词转移、累积谓词转移和技巧串联，用于测试不同方面的负面影响。此外，作者还测试了几种流行的模仿学习算法在BOSS上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;在最简单的挑战下，各种算法性能下降显著，分别为67%，35%，34%和54%。增加训练数据的规模以解决OSS问题的方法并未达到预期效果。&lt;h4&gt;结论&lt;/h4&gt;观察空间移位对长时任务中技能策略的表现具有负面影响，而现有解决方案不足以完全解决这一问题。&lt;h4&gt;翻译&lt;/h4&gt;机器人技术长期以来一直致力于开发能够完成未见过的长期任务的视觉伺服机器人。分层方法通过执行由任务计划器安排的技能组合来实现这个目标，并且每个视觉运动技能都使用特定的模仿学习（IL）算法预先训练。然而，即使在简单的长期任务如技巧串联中，分层方法也常常因观察空间移位问题而难以实现目标。为了验证这一问题并评估其对长期任务的影响，我们引入了BOSS基准测试来衡量这个问题。BOSS包括三个不同的挑战：“单一谓词转移”、“累积谓词转移”和“技巧串联”，每个挑战都旨在评估OSS的负面影响的不同方面。我们在BOSS上评估了几种最近流行的IL算法，其中包括三种行为克隆方法和视觉语言动作模型OpenVLA。即使在最简单的挑战中，我们观察到当技能性能在有无观察空间移位的情况下对比时，平均性能下降分别为67%，35%，34%和54%。此外，我们研究了一种解决OSS的潜在解决方案，即通过使用更大且视觉上更加多样的示例数据集来增加每个技能训练数据的规模，但结果显示这种方法不足以解决问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotics has long sought to develop visual-servoing robots capable ofcompleting previously unseen long-horizon tasks. Hierarchical approaches offera pathway for achieving this goal by executing skill combinations arranged by atask planner, with each visuomotor skill pre-trained using a specific imitationlearning (IL) algorithm. However, even in simple long-horizon tasks like skillchaining, hierarchical approaches often struggle due to a problem we identifyas Observation Space Shift (OSS), where the sequential execution of precedingskills causes shifts in the observation space, disrupting the performance ofsubsequent individually trained skill policies. To validate OSS and evaluateits impact on long-horizon tasks, we introduce BOSS (a Benchmark forObservation Space Shift). BOSS comprises three distinct challenges: "SinglePredicate Shift", "Accumulated Predicate Shift", and "Skill Chaining", eachdesigned to assess a different aspect of OSS's negative effect. We evaluatedseveral recent popular IL algorithms on BOSS, including three BehavioralCloning methods and the Visual Language Action model OpenVLA. Even on thesimplest challenge, we observed average performance drops of 67%, 35%, 34%, and54%, respectively, when comparing skill performance with and without OSS.Additionally, we investigate a potential solution to OSS that scales up thetraining data for each skill with a larger and more visually diverse set ofdemonstrations, with our results showing it is not sufficient to resolve OSS.The project page is: https://boss-benchmark.github.io/</description>
      <author>example@mail.com (Yue Yang, Linfeng Zhao, Mingyu Ding, Gedas Bertasius, Daniel Szafir)</author>
      <guid isPermaLink="false">2502.15679v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>VaViM and VaVAM: Autonomous Driving through Video Generative Modeling</title>
      <link>http://arxiv.org/abs/2502.15672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and model: https://github.com/valeoai/VideoActionModel, project  page: https://valeoai.github.io/vavim-vavam/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了大规模生成式视频模型在自动驾驶中的潜力，介绍了开源的自回归视频模型（VaViM）和其辅助视频动作模型（VaVAM），以探索视频预训练如何应用于实际驾驶。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习的发展，视频生成技术被引入到自动驾驶领域，特别是在理解和预测复杂的动态场景方面具有巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;研究的目的是通过开发新的视频预训练模型来提升自动驾驶系统在真实世界中的表现和安全性。&lt;h4&gt;方法&lt;/h4&gt;VaViM是一个简单的自回归视频模型，通过时空令牌序列预测帧；VaVAM则利用VaViM学习到的表示生成驾驶轨迹。两个模型共同形成了从感知到动作的完整管道，并且研究者们对其进行了开放循环和闭环驾驶场景评估。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，基于视频的预训练对于自动驾驶具有前景，包括所学表示的语义丰富性、视频合成中规模效应的好处以及在闭环评估中的模型大小与数据之间的复杂关系及其对安全度量的影响。&lt;h4&gt;结论&lt;/h4&gt;通过发布代码和模型权重，研究团队希望促进相关领域的进一步发展，并鼓励其他研究人员探索该方向的潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们探讨了大规模生成式视频模型在自主驾驶中的潜力，介绍了开源自回归视频模型（VaViM）及其辅助动作视频模型（VaVAM），以探究视频预训练如何应用于现实世界的自动驾驶。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We explore the potential of large-scale generative video models forautonomous driving, introducing an open-source auto-regressive video model(VaViM) and its companion video-action model (VaVAM) to investigate how videopre-training transfers to real-world driving. VaViM is a simple auto-regressivevideo model that predicts frames using spatio-temporal token sequences. We showthat it captures the semantics and dynamics of driving scenes. VaVAM, thevideo-action model, leverages the learned representations of VaViM to generatedriving trajectories through imitation learning. Together, the models form acomplete perception-to-action pipeline. We evaluate our models in open- andclosed-loop driving scenarios, revealing that video-based pre-training holdspromise for autonomous driving. Key insights include the semantic richness ofthe learned representations, the benefits of scaling for video synthesis, andthe complex relationship between model size, data, and safety metrics inclosed-loop evaluations. We release code and model weights athttps://github.com/valeoai/VideoActionModel</description>
      <author>example@mail.com (Florent Bartoccioni, Elias Ramzi, Victor Besnier, Shashanka Venkataramanan, Tuan-Hung Vu, Yihong Xu, Loick Chambon, Spyros Gidaris, Serkan Odabas, David Hurych, Renaud Marlet, Alexandre Boulch, Mickael Chen, Éloi Zablocki, Andrei Bursuc, Eduardo Valle, Matthieu Cord)</author>
      <guid isPermaLink="false">2502.15672v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Automating Curriculum Learning for Reinforcement Learning using a Skill-Based Bayesian Network</title>
      <link>http://arxiv.org/abs/2502.15662v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于技能-环境贝叶斯网络(SEBN)的方法，以减少强化学习训练时间或提高目标任务的性能。&lt;h4&gt;背景&lt;/h4&gt;在强化学习中，自动生成课程以减少训练时间和提升性能是主要挑战之一。&lt;h4&gt;目的&lt;/h4&gt;通过使用SEBN模型来预测代理在各种任务上的表现，并根据这些预测来加权可能的任务，从而开发一种算法来优化课程设置。&lt;h4&gt;方法&lt;/h4&gt;利用SEBN模型对代理成功概率的推断估计来评估下一个潜在任务的预期改进。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在三种不同环境中（离散格子世界、连续控制和模拟机器人）使用SEBN构建的课程比其他基准线更有效。&lt;h4&gt;结论&lt;/h4&gt;通过将技能与环境特征及奖励结构相关联，SEBN能够预测代理在各种任务上的表现并优化学习过程中的课程设置。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了SEBN模型及其用于减少训练时间和提升性能的方法，并展示了它优于传统基线的实验结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A major challenge for reinforcement learning is automatically generatingcurricula to reduce training time or improve performance in some target task.We introduce SEBNs (Skill-Environment Bayesian Networks) which model aprobabilistic relationship between a set of skills, a set of goals that relateto the reward structure, and a set of environment features to predict policyperformance on (possibly unseen) tasks. We develop an algorithm that uses theinferred estimates of agent success from SEBN to weigh the possible next tasksby expected improvement. We evaluate the benefit of the resulting curriculum onthree environments: a discrete gridworld, continuous control, and simulatedrobotics. The results show that curricula constructed using SEBN frequentlyoutperform other baselines.</description>
      <author>example@mail.com (Vincent Hsiao, Mark Roberts, Laura M. Hiatt, George Konidaris, Dana Nau)</author>
      <guid isPermaLink="false">2502.15662v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>A Simulation Pipeline to Facilitate Real-World Robotic Reinforcement Learning Applications</title>
      <link>http://arxiv.org/abs/2502.15649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper accepted to be presented at IEEE SysCon 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种帮助减少仿真与现实差距、促进在真实世界机器人系统中开发和部署强化学习策略的流水线。&lt;h4&gt;背景&lt;/h4&gt;强化学习（RL）在解决复杂任务方面取得成功，特别是在机器人应用领域。然而，在物理机器人上实现它仍然充满挑战性，主要是由于安全风险和高昂的训练成本。为了解决这些问题，通常是在模拟器中训练RL代理，这又引入了关于仿真与现实之间差距的新问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种流水线来帮助减少仿真实验到现实操作之间的差距，并促进强化学习策略在实际机器人系统中的开发和部署。&lt;h4&gt;方法&lt;/h4&gt;该流程将RL的培训过程组织为初始的系统识别阶段，以及三个训练阶段：核心仿真培训、高保真仿真，然后是实地部署。每个阶段都会增加现实感的程度以减少模拟到真实之间的差距，并且通过迭代传递并改进策略来逐步达到所需性能。&lt;h4&gt;主要发现&lt;/h4&gt;该流水线的有效性在一项案例研究中得到证明，在这项研究中使用了Boston Dynamics Spot移动机器人执行监控应用。&lt;h4&gt;结论&lt;/h4&gt;提出的RL流程展示了通过各个阶段如何逐渐减少仿真与现实之间的差距，使开发的策略能够成功部署于真实环境中的机器人系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning (RL) has gained traction for its success in solvingcomplex tasks for robotic applications. However, its deployment on physicalrobots remains challenging due to safety risks and the comparatively high costsof training. To avoid these problems, RL agents are often trained onsimulators, which introduces a new problem related to the gap betweensimulation and reality. This paper presents an RL pipeline designed to helpreduce the reality gap and facilitate developing and deploying RL policies forreal-world robotic systems. The pipeline organizes the RL training process intoan initial step for system identification and three training stages: coresimulation training, high-fidelity simulation, and real-world deployment, eachadding levels of realism to reduce the sim-to-real gap. Each training stagetakes an input policy, improves it, and either passes the improved policy tothe next stage or loops it back for further improvement. This iterative processcontinues until the policy achieves the desired performance. The pipeline'seffectiveness is shown through a case study with the Boston Dynamics Spotmobile robot used in a surveillance application. The case study presents thesteps taken at each pipeline stage to obtain an RL agent to control the robot'sposition and orientation.</description>
      <author>example@mail.com (Jefferson Silveira, Joshua A. Marshall, Sidney N. Givigi Jr)</author>
      <guid isPermaLink="false">2502.15649v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Reduced-Order Model Guided Contact-Implicit Model Predictive Control for Humanoid Locomotion</title>
      <link>http://arxiv.org/abs/2502.15630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种结合简化的混合线性倒立摆模型（HLIP）和接触隐式模型预测控制（CI-MPC）优点的控制框架，旨在提高人形机器人的灵活性和实用性。&lt;h4&gt;背景&lt;/h4&gt;人形机器人在人类环境中操作具有巨大的应用潜力，但由于高维度非线性混合动力学的复杂性，部署面临挑战。虽然HLIP简化了模型，但丧失了全身表达能力；而CI-MPC能够处理多种接触模式下的规划问题，但仍存在局部最优和大量调优需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合HLIP与CI-MPC优点的新控制框架，以克服当前方法的局限性，并增强人形机器人的适应性和实用性。&lt;h4&gt;方法&lt;/h4&gt;该框架利用HLIP生成名义步态模式，同时使用CI-MPC处理全身动力学并根据需要调整接触序列。实验在24自由度的人形机器人Achilles上进行模拟测试。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的控制框架能够在粗糙地形行走、恢复外部干扰后的稳定性以及面对模型和状态不确定性时保持鲁棒性，同时能够与环境中的障碍物互动，并且以50Hz的频率实现实时在线运行。&lt;h4&gt;结论&lt;/h4&gt;结合HLIP和CI-MPC的优点可以显著提升人形机器人在复杂环境下的控制性能和适应能力。该框架为未来的人形机器人开发提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;人形机器人的潜在应用领域因它们能在为人设计的环境中操作而广受期待，但其部署受到管理高维度非线性混合动力学挑战的影响。虽然简化的模型如HLIP简单且计算效率高，但这些模型缺乏全身表达能力。最近在CI-MPC上的进展使机器人能够通过多个混合接触模式进行规划，但仍容易陷入局部最优，并需要大量的调优工作。我们提出了一种结合HLIP和CI-MPC优点的控制框架：简化的模型产生名义步态，而CI-MPC管理全身动力学并根据需要调整接触安排。我们在模拟中使用一个新型24自由度的人形机器人Achilles展示了这种方法的有效性。我们的方法实现了粗糙地形行走、干扰恢复能力，在面对模型和状态不确定性时保持鲁棒性，并且能够与环境中的障碍物互动，所有这一切都在实时在线环境中以50Hz的频率运行。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humanoid robots have great potential for real-world applications due to theirability to operate in environments built for humans, but their deployment ishindered by the challenge of controlling their underlying high-dimensionalnonlinear hybrid dynamics. While reduced-order models like the Hybrid LinearInverted Pendulum (HLIP) are simple and computationally efficient, they losewhole-body expressiveness. Meanwhile, recent advances in Contact-Implicit ModelPredictive Control (CI-MPC) enable robots to plan through multiple hybridcontact modes, but remain vulnerable to local minima and require significanttuning. We propose a control framework that combines the strengths of HLIP andCI-MPC. The reduced-order model generates a nominal gait, while CI-MPC managesthe whole-body dynamics and modifies the contact schedule as needed. Wedemonstrate the effectiveness of this approach in simulation with a novel 24degree-of-freedom humanoid robot: Achilles. Our proposed framework achievesrough terrain walking, disturbance recovery, robustness under model and stateuncertainty, and allows the robot to interact with obstacles in theenvironment, all while running online in real-time at 50 Hz.</description>
      <author>example@mail.com (Sergio A. Esteban, Vince Kurtz, Adrian B. Ghansah, Aaron D. Ames)</author>
      <guid isPermaLink="false">2502.15630v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Pick-and-place Manipulation Across Grippers Without Retraining: A Learning-optimization Diffusion Policy Approach</title>
      <link>http://arxiv.org/abs/2502.15613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Video and code are available at https://github.com/yaoxt3/GADP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于扩散的策略和混合学习优化框架，使机器人能在零样本条件下适应新的夹爪配置。&lt;h4&gt;背景&lt;/h4&gt;当前大多数抓取放置策略需要在训练和推理阶段保持一致的夹爪设置，这会导致高昂的成本，特别是在使用模仿学习方法时。当要适应新类型的末端执行器（即夹爪）时，这一问题尤为突出。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的策略以减少为适应不同夹爪而进行额外训练或微调的需求。&lt;h4&gt;方法&lt;/h4&gt;利用基于扩散的优化策略，在推理阶段动态地强制执行机械和安全约束。通过这种受限的去噪过程，该策略能够根据具体的夹爪参数（如工具中心点偏移量、颚宽）调整轨迹，同时确保碰撞避免和任务可行性。&lt;h4&gt;主要发现&lt;/h4&gt;在六种不同的夹爪配置上进行实验验证后，提出的方法实现了93.3%的平均任务成功率，而扩散政策基线方法的成功率仅为23.3-26.7%。该策略支持工具中心点偏移量从16至23.5厘米以及颚宽从7.5到11.5厘米的变化。&lt;h4&gt;结论&lt;/h4&gt;通过引入受限的扩散过程，可以实现跨夹爪操作的鲁棒性，并且保持了模仿学习方法的样本效率。这消除了针对特定夹爪进行重新训练的需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的具体中文翻译：当前抓取放置策略通常需要在训练和推理阶段维持一致的机械臂末端执行器设置，这一要求导致了高成本的再训练或微调需求，特别是在基于模仿学习的方法中。为解决这个问题，我们提出了一种扩散式的策略结合混合学习优化框架，使得机器人可以无须额外的数据收集便能在新的夹爪上进行零样本适应。在训练过程中，该政策通过使用基础夹爪采集的演示数据来学习抓取和放置的基本操作方法。而在推理阶段，基于扩散的优化策略动态地施加机械和安全约束，确保生成的动作轨迹与未见过的新夹爪的实际物理特性相匹配。这一过程通过一个受限去噪程序实现，该程序能够适应特定夹爪参数（例如工具中心点偏移量、颚宽）的同时保持碰撞避免和任务可行性。我们在Franka Panda机器人上进行了一系列实验测试，在六种不同的夹爪配置中验证了我们的方法的有效性，包括3D打印的手指末端执行器、柔软的硅胶抓手以及Robotiq 2F-85夹爪等。与扩散政策基线相比，我们提出的策略达到了93.3%的平均任务成功率（相比之下基线为23.3至26.7%），支持工具中心点偏移量从16到23.5厘米和颚宽范围从7.5到11.5厘米的变化。实验结果表明，受限扩散过程能够实现跨不同夹爪配置操作的鲁棒性同时维持了模仿学习方法的样本效率，并且无需为特定类型夹爪重新训练策略。代码与视频可在https://github.com/yaoxt3/GADP上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current robotic pick-and-place policies typically require consistent gripperconfigurations across training and inference. This constraint imposes highretraining or fine-tuning costs, especially for imitation learning-basedapproaches, when adapting to new end-effectors. To mitigate this issue, wepresent a diffusion-based policy with a hybrid learning-optimization framework,enabling zero-shot adaptation to novel grippers without additional datacollection for retraining policy. During training, the policy learnsmanipulation primitives from demonstrations collected using a base gripper. Atinference, a diffusion-based optimization strategy dynamically enforceskinematic and safety constraints, ensuring that generated trajectories alignwith the physical properties of unseen grippers. This is achieved through aconstrained denoising procedure that adapts trajectories to gripper-specificparameters (e.g., tool-center-point offsets, jaw widths) while preservingcollision avoidance and task feasibility. We validate our method on a FrankaPanda robot across six gripper configurations, including 3D-printed fingertips,flexible silicone gripper, and Robotiq 2F-85 gripper. Our approach achieves a93.3% average task success rate across grippers (vs. 23.3-26.7% for diffusionpolicy baselines), supporting tool-center-point variations of 16-23.5 cm andjaw widths of 7.5-11.5 cm. The results demonstrate that constrained diffusionenables robust cross-gripper manipulation while maintaining the sampleefficiency of imitation learning, eliminating the need for gripper-specificretraining. Video and code are available at https://github.com/yaoxt3/GADP.</description>
      <author>example@mail.com (Xiangtong Yao, Yirui Zhou, Yuan Meng, Liangyu Dong, Lin Hong, Zitao Zhang, Zhenshan Bing, Kai Huang, Fuchun Sun, Alois Knoll)</author>
      <guid isPermaLink="false">2502.15613v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Autonomous helicopter aerial refueling: controller design and performance guarantees</title>
      <link>http://arxiv.org/abs/2502.15562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种用于自主直升机空中加油的控制设计方法、稳定性标准和性能界限。&lt;h4&gt;背景&lt;/h4&gt;自主空中加油由于加油机尾流的影响、接触敏感操作特性和加油管运动不确定性而变得十分困难。此外，探针位于直升机重心之外，其位置与速度对直升机姿态及其角速率非常敏感。&lt;h4&gt;目的&lt;/h4&gt;为了提高自主空中加油的性能和稳定性，提出了一种新的外环位置控制器，并使用闭环误差动力学中的极限有界性特性来提供分析保证。&lt;h4&gt;方法&lt;/h4&gt;提出了一个将探针的位置和速度纳入反馈回路的新外环位置控制器。通过在高保真UH60直升机模型中进行仿真测试，验证了新控制策略的有效性和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;新的控制方法能够显著减少2-范数对接误差，与现有标准控制器相比改进了36%。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了所提出的自主空中加油控制系统在复杂和动态环境中的有效性，并为未来的应用提供了理论基础和技术支持。&lt;h4&gt;翻译&lt;/h4&gt;在这篇文章中，我们提出了一种用于无人直升机空中加油的控制设计方法、稳定性标准和性能界限。自主空中加油由于受到加油机尾流影响、操作接触敏感性和加油管运动不确定性的限制而变得非常困难。探针位置远离直升机重心，其位置（速度）对直升机姿态（角速率）极其敏感。此外，为了匹配加油机的速度，直升机需要高速运行并保持特定的姿态，这使得对接更加具有挑战性。我们提出了一种新的外环位置控制器，将探针的位置和速度纳入反馈回路中。通过闭环误差动态的极限有界特性，推导了关于对接性能与加油管运动不确定性及直升机角加速度之间的关系的分析保证。在考虑风力影响的情况下，利用高保真度UH60直升机模型进行了仿真测试，以验证新方法在现实场景中的有效性。高保真度模拟显示，相比于现有标准控制器，所提出的控制策略能将2-范数对接误差减少36%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a control design methodology, stability criteria,and performance bounds for autonomous helicopter aerial refueling. Autonomousaerial refueling is particularly difficult due to the aerodynamic interactionbetween the wake of the tanker, the contact-sensitive nature of the maneuver,and the uncertainty in drogue motion. Since the probe tip is locatedsignificantly away from the helicopter's center-of-gravity, its position (andvelocity) is strongly sensitive to the helicopter's attitude (and angularrates). In addition, the fact that the helicopter is operating at high speedsto match the velocity of the tanker forces it to maintain a particularorientation, making the docking maneuver especially challenging. In this paper,we propose a novel outer-loop position controller that incorporates the probeposition and velocity into the feedback loop. The position and velocity of theprobe tip depend both on the position (velocity) and on the attitude (angularrates) of the aircraft. We derive analytical guarantees for docking performancein terms of the uncertainty of the drogue motion and the angular accelerationof the helicopter, using the ultimate boundedness property of the closed-looperror dynamics. Simulations are performed on a high-fidelity UH60 helicoptermodel with a high-fidelity drogue motion under wind effects to validate theproposed approach for realistic refueling scenarios. These high-fidelitysimulations reveal that the proposed control methodology yields an improvementof 36% in the 2-norm docking error compared to the existing standardcontroller.</description>
      <author>example@mail.com (Damsara Jayarathne, Santiago Paternain, Sandipan Mishra)</author>
      <guid isPermaLink="false">2502.15562v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Probabilistic Collision Detection for Motion Planning Under Sensing Uncertainty</title>
      <link>http://arxiv.org/abs/2502.15525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了用于机器人在非结构化环境中的运动规划的增强概率碰撞检测（PCD）方法。&lt;h4&gt;背景&lt;/h4&gt;现有的PCD方法主要使用简化的几何模型，且仅考虑位置估计误差，未充分考虑到姿态估计误差和形状精度的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种改进的方法，以提高在感知不确定性下的鲁棒性，并减少路径长度与规划时间。&lt;h4&gt;方法&lt;/h4&gt;{'要点1': '利用超二次曲面（superquadrics）进行更精确的形状近似', '要点2': '考虑位置和姿态估计误差，通过扩大每个物体的表面来封装其观察到的所有旋转副本'}&lt;h4&gt;主要发现&lt;/h4&gt;该PCD方法比现有最佳方法更接近蒙特卡洛采样的基线，并且在减少路径长度和规划时间方面分别表现出色。&lt;h4&gt;结论&lt;/h4&gt;研究证明了考虑姿态估计误差的重要性，当仅考虑位置估计误差或忽略时，在仿真中执行计划路径的碰撞概率远高于此方法。&lt;h4&gt;翻译&lt;/h4&gt;概率碰撞检测（PCD）对于操作于非结构化环境中的机器人运动规划至关重要，通过考虑到感知不确定性有助于防止损坏。现有PCD方法主要使用简化的几何模型，并且仅解决位置估计误差问题。本文提出了一种增强的PCD方法，具有两个关键改进：(a) 使用超二次曲面进行更准确的形状近似；(b) 考虑到位置和姿态估计误差以提高在感知不确定性下的鲁棒性。该方法首先为每个对象计算一个扩大的表面，该表面封装了其观察到的所有旋转副本，从而解决了姿态估计误差问题。然后将位置估计误差下的碰撞概率作为机会约束问题进行公式化，并通过超二次曲面的正常参数化求解紧致上限。结果表明，与现有最佳PCD方法相比，该方法更接近蒙特卡洛采样的基线，并且在减少路径长度和规划时间方面表现出色。一种Real2Sim管道进一步验证了考虑姿态估计误差的重要性：执行仿真中计划路径的碰撞概率仅为2%，而仅考虑位置估计误差或完全不考虑时则分别为9% 和 29%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Probabilistic collision detection (PCD) is essential in motion planning forrobots operating in unstructured environments, where considering sensinguncertainty helps prevent damage. Existing PCD methods mainly used simplifiedgeometric models and addressed only position estimation errors. This paperpresents an enhanced PCD method with two key advancements: (a) usingsuperquadrics for more accurate shape approximation and (b) accounting for bothposition and orientation estimation errors to improve robustness under sensinguncertainty. Our method first computes an enlarged surface for each object thatencapsulates its observed rotated copies, thereby addressing the orientationestimation errors. Then, the collision probability under the positionestimation errors is formulated as a chance-constraint problem that is solvedwith a tight upper bound. Both the two steps leverage the recently developednormal parameterization of superquadric surfaces. Results show that our PCDmethod is twice as close to the Monte-Carlo sampled baseline as the bestexisting PCD method and reduces path length by 30% and planning time by 37%,respectively. A Real2Sim pipeline further validates the importance ofconsidering orientation estimation errors, showing that the collisionprobability of executing the planned path in simulation is only 2%, compared to9% and 29% when considering only position estimation errors or none at all.</description>
      <author>example@mail.com (Xiaoli Wang, Sipu Ruan, Xin Meng, Gregory Chirikjian)</author>
      <guid isPermaLink="false">2502.15525v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Robust 4D Radar-aided Inertial Navigation for Aerial Vehicles</title>
      <link>http://arxiv.org/abs/2502.15452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于高效且鲁棒的误差状态卡尔曼滤波器(ESKF)雷达惯性导航系统的开发方案，用于无人驾驶飞行器(UAV)，并利用毫米波(MMW)雷达提供的稳健3D测距和多普勒速度测量来增强UAV在复杂环境下的导航能力。&lt;h4&gt;背景&lt;/h4&gt;随着激光雷达和摄像头在无人机上的广泛应用，在挑战性的环境中它们可能会变得不那么有效。相反，能够提供稳健的三维测距和多普勒速度测量的4D毫米波(MMW)雷达对于空中导航来说利用不够充分。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于ESKF的方法来提高UAV利用毫米波雷达进行导航时的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种点对分布雷达扫描匹配技术，以提供具有适当不确定性资格的动作约束，并结合多普勒速度测量结果紧密耦合地更新导航状态。此外还设计了一个基于关键帧的方法来对抗先前地图（如果可用的话），从而限制累积的导航误差并提供高精度的雷达辅助全局定位解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的现实世界实验验证，该提出的雷达增强惯性导航方法在准确性和鲁棒性方面都超过了现有的最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;基于毫米波雷达和惯性传感器的数据融合技术可以提高UAV在复杂环境下的导航性能，并具有广阔的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While LiDAR and cameras are becoming ubiquitous for unmanned aerial vehicles(UAVs) but can be ineffective in challenging environments, 4D millimeter-wave(MMW) radars that can provide robust 3D ranging and Doppler velocitymeasurements are less exploited for aerial navigation. In this paper, wedevelop an efficient and robust error-state Kalman filter (ESKF)-basedradar-inertial navigation for UAVs. The key idea of the proposed approach isthe point-to-distribution radar scan matching to provide motion constraintswith proper uncertainty qualification, which are used to update the navigationstates in a tightly coupled manner, along with the Doppler velocitymeasurements. Moreover, we propose a robust keyframe-based matching schemeagainst the prior map (if available) to bound the accumulated navigation errorsand thus provide a radar-based global localization solution with high accuracy.Extensive real-world experimental validations have demonstrated that theproposed radar-aided inertial navigation outperforms state-of-the-art methodsin both accuracy and robustness.</description>
      <author>example@mail.com (Jinwen Zhu, Jun Hu, Xudong Zhao, Xiaoming Lang, Yinian Mao, Guoquan Huang)</author>
      <guid isPermaLink="false">2502.15452v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Learning Long-Horizon Robot Manipulation Skills via Privileged Action</title>
      <link>http://arxiv.org/abs/2502.15442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种结构化的框架，利用特权动作和课程学习来解决长期接触密集型任务中的强化学习挑战。&lt;h4&gt;背景&lt;/h4&gt;在处理长时序的、高维度状态空间的任务时，传统强化学习方法由于稀疏奖励导致探索效率低下且容易陷入局部最优。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的学习框架，在不依赖大量人工设计奖励或参考轨迹的情况下，使策略能够掌握长期技能。&lt;h4&gt;方法&lt;/h4&gt;在模拟环境中使用特权动作进行训练，包括放松约束条件和虚拟力等手段来增强对象交互和探索。通过课程学习逐步移除这些特权以逼近真实世界情况。&lt;h4&gt;主要发现&lt;/h4&gt;成功完成了涉及非抓取姿势物体提升的复杂多阶段长期任务，展示了方法的一般性和奖励结构的简洁性，并且在多种环境中都能达到收敛。&lt;h4&gt;结论&lt;/h4&gt;实验表明所学技能可以转移到现实世界中表现得既稳健又细腻。相比于现有方法，在这些任务上的性能更优。&lt;h4&gt;翻译&lt;/h4&gt;长时序接触密集型任务由于高维状态空间和稀疏奖励的存在，对强化学习来说是一个挑战。传统的解决方案往往陷入局部最优并且需要针对特定任务进行复杂的奖励调参。为了解决这些问题，我们提出了一种使用特权动作与课程学习相结合的方法框架。该方法通过模拟中的特权训练提升了对象交互和探索效率，并且逐步移除这些特权以适应真实环境的约束条件。最终结果表明所提出的算法能够成功完成多种复杂任务，并在不同环境中展现出多样性和鲁棒性的行为模式，证明了其有效性和普遍性。此外，现实世界实验进一步验证了学到技能的有效转移能力以及在实际应用中的卓越性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-horizon contact-rich tasks are challenging to learn with reinforcementlearning, due to ineffective exploration of high-dimensional state spaces withsparse rewards. The learning process often gets stuck in local optimum anddemands task-specific reward fine-tuning for complex scenarios. In this work,we propose a structured framework that leverages privileged actions withcurriculum learning, enabling the policy to efficiently acquire long-horizonskills without relying on extensive reward engineering or referencetrajectories. Specifically, we use privileged actions in simulation with ageneral training procedure that would be infeasible to implement in real-worldscenarios. These privileges include relaxed constraints and virtual forces thatenhance interaction and exploration with objects. Our results successfullyachieve complex multi-stage long-horizon tasks that naturally combinenon-prehensile manipulation with grasping to lift objects from non-graspableposes. We demonstrate generality by maintaining a parsimonious reward structureand showing convergence to diverse and robust behaviors across variousenvironments. Additionally, real-world experiments further confirm that theskills acquired using our approach are transferable to real-world environments,exhibiting robust and intricate performance. Our approach outperformsstate-of-the-art methods in these tasks, converging to solutions where othersfail.</description>
      <author>example@mail.com (Xiaofeng Mao, Yucheng Xu, Zhaole Sun, Elle Miller, Daniel Layeghi, Michael Mistry)</author>
      <guid isPermaLink="false">2502.15442v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Self-Mixing Laser Interferometry for Robotic Tactile Sensing</title>
      <link>http://arxiv.org/abs/2502.15390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for ICRA2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种利用自混合干涉仪（SMI）技术的机器人指尖，用于检测物体滑动和外部接触。研究通过实验验证了该设计的有效性，并将其与声学传感器进行了比较。&lt;h4&gt;背景&lt;/h4&gt;自混合干涉仪因其在无需物理接触的情况下探测微振动的高度敏感性而受到赞誉。在机器人领域中，微振动通常被视为物体滑动的标志，最近也被认为是外接触的重要指标。&lt;h4&gt;目的&lt;/h4&gt;展示首个采用SMI技术检测滑动和外部接触信号的机器人指尖，并比较其与声学传感器的效果。&lt;h4&gt;方法&lt;/h4&gt;通过测量控制下的振动源进行设计验证，包括封装读取电路前后的情况。然后进行了三个实验将SMI指尖与声学传感相比较。&lt;h4&gt;主要发现&lt;/h4&gt;SMI对细微滑动事件更加敏感且在背景噪声下表现出显著更高的鲁棒性&lt;h4&gt;结论&lt;/h4&gt;将自混合干涉仪集成到机器人指尖中为触觉感应提供了新的有前景的分支技术&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-mixing interferometry (SMI) has been lauded for its sensitivity indetecting microvibrations, while requiring no physical contact with its target.In robotics, microvibrations have traditionally been interpreted as a markerfor object slip, and recently as a salient indicator of extrinsic contact. Wepresent the first-ever robotic fingertip making use of SMI for slip andextrinsic contact sensing. The design is validated through measurement ofcontrolled vibration sources, both before and after encasing the readoutcircuit in its fingertip package. Then, the SMI fingertip is compared toacoustic sensing through three experiments. The results are distilled into atechnology decision map. SMI was found to be more sensitive to subtle slipevents and significantly more robust against ambient noise. We conclude thatthe integration of SMI in robotic fingertips offers a new, promising branch oftactile sensing in robotics.</description>
      <author>example@mail.com (Remko Proesmans, Ward Goossens, Lowiek Van den Stockt, Lowie Christiaen, Francis wyffels)</author>
      <guid isPermaLink="false">2502.15390v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Rapid Online Learning of Hip Exoskeleton Assistance Preferences</title>
      <link>http://arxiv.org/abs/2502.15366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Copyright 2025 IEEE. Personal use of this material is permitted.  Permission from IEEE must be obtained for all other uses, in any current or  future media, including reprinting/republishing this material for advertising  or promotional purposes, creating new collective works, for resale or  redistribution to servers or lists, or reuse of any copyrighted component of  this work in other works&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;髋部外骨骼装置在各种场景中表现出色，能够适应不同用户的需求。然而，个性化调整通常需要复杂的调参过程和计算密集型算法，并且大多数现有方法不考虑用户的反馈。&lt;h4&gt;背景&lt;/h4&gt;随着技术的发展，髋部外骨骼因其适应性广、适用性强而越来越受欢迎。但是，在个性化提供帮助方面仍存在挑战，如长时间的调整过程以及缺乏用户反馈整合机制。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于快速学习用户偏好来调整个体化辅助扭矩配置的方法。&lt;h4&gt;方法&lt;/h4&gt;通过随机生成不同助行方案进行成对比较，并主动向参与者提问以收集其偏好的信息。这些反馈被集成到一个优先级学习算法中，该算法根据个人行为动态更新奖励函数并相应调整外骨骼的助力模式。&lt;h4&gt;主要发现&lt;/h4&gt;来自八位健康受试者的实验数据显示了不同的最佳扭矩配置；用户的选择在面对微调后的方案时依然保持一致；用户偏好与个体步行策略有密切联系；助行力矩不会干扰运动学关节协同作用，且参与者倾向于选择与其步态模式同步的助力。&lt;h4&gt;结论&lt;/h4&gt;这一方法简单有效地实现了快速学习用户的偏好和奖励机制，为基于奖励的人机交互奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;髋部外骨骼由于其在各种场景中的有效性以及能够适应不同用户的能力而日益流行。然而，个性化调整通常需要长时间的调优过程和计算密集型算法，并且大多数现有方法没有整合用户反馈。本文提出了一种快速学习用户对髋部外骨骼辅助偏好并据此优化助动力矩配置的新方法。通过随机生成不同的助力方案进行成对比较，并收集参与者的选择偏好的方式，研究发现不同受试者拥有各自的最优扭矩模式；用户的偏好与他们的步行策略紧密相关；且被测的力矩不会破坏关节协同运动关系，用户更倾向于那些与其步态一致的辅助力矩。这种方法为未来基于奖励的人机交互的研究提供了坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hip exoskeletons are increasing in popularity due to their effectivenessacross various scenarios and their ability to adapt to different users.However, personalizing the assistance often requires lengthy tuning proceduresand computationally intensive algorithms, and most existing methods do notincorporate user feedback. In this work, we propose a novel approach forrapidly learning users' preferences for hip exoskeleton assistance. We performpairwise comparisons of distinct randomly generated assistive profiles, andcollect participants preferences through active querying. Users' feedback isintegrated into a preference-learning algorithm that updates its belief, learnsa user-dependent reward function, and changes the assistive torque profilesaccordingly. Results from eight healthy subjects display distinct preferredtorque profiles, and users' choices remain consistent when compared to aperturbed profile. A comprehensive evaluation of users' preferences reveals aclose relationship with individual walking strategies. The tested torqueprofiles do not disrupt kinematic joint synergies, and participants favorassistive torques that are synchronized with their movements, resulting inlower negative power from the device. This straightforward approach enables therapid learning of users preferences and rewards, grounding future studies onreward-based human-exoskeleton interaction.</description>
      <author>example@mail.com (Giulia Ramella, Auke Ijspeert, Mohamed Bouri)</author>
      <guid isPermaLink="false">2502.15366v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Embodied Multimodal Large Models: Development, Datasets, and Future Directions</title>
      <link>http://arxiv.org/abs/2502.15336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  81 pages, submitted to a journal for review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文综述了嵌入式多模态大型模型（EMLMs）的发展，包括大语言模型、大视觉模型及其他相关模型，并探讨了这些模型在感知、导航和交互等方面的应用。&lt;h4&gt;背景介绍&lt;/h4&gt;近年来，由于EMLMs具有连接感知、认知和行动的潜力，在复杂现实环境中引起了广泛关注。EMLMs试图解决大规模环境下的多种挑战，如数据多样性与质量等。&lt;h4&gt;目的陈述&lt;/h4&gt;本文旨在详细分析EMLMs的发展历程及其面临的挑战，并探讨未来的方向，强调跨模态感知、推理及动作的重要性以促进更加自主系统的发展。&lt;h4&gt;方法概述&lt;/h4&gt;文章讨论了EMLMs的演化过程，重点关注嵌入式感知、导航、交互和模拟等方面。同时，对训练与评估这些模型所使用的数据集进行了深入分析，并指出了多样化高质量数据对于有效学习的重要意义。&lt;h4&gt;主要发现&lt;/h4&gt;文中指出了当前EMLMs面临的关键挑战，包括规模性问题、泛化能力和实时决策制定等方面的难题。&lt;h4&gt;未来方向&lt;/h4&gt;文章最后概述了未来的研究方向，强调多模态感知、推理和动作的集成是推进自主系统发展的关键。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied multimodal large models (EMLMs) have gained significant attention inrecent years due to their potential to bridge the gap between perception,cognition, and action in complex, real-world environments. This comprehensivereview explores the development of such models, including Large Language Models(LLMs), Large Vision Models (LVMs), and other models, while also examiningother emerging architectures. We discuss the evolution of EMLMs, with a focuson embodied perception, navigation, interaction, and simulation. Furthermore,the review provides a detailed analysis of the datasets used for training andevaluating these models, highlighting the importance of diverse, high-qualitydata for effective learning. The paper also identifies key challenges faced byEMLMs, including issues of scalability, generalization, and real-timedecision-making. Finally, we outline future directions, emphasizing theintegration of multimodal sensing, reasoning, and action to advance thedevelopment of increasingly autonomous systems. By providing an in-depthanalysis of state-of-the-art methods and identifying critical gaps, this paperaims to inspire future advancements in EMLMs and their applications acrossdiverse domains.</description>
      <author>example@mail.com (Shoubin Chen, Zehao Wu, Kai Zhang, Chunyu Li, Baiyang Zhang, Fei Ma, Fei Richard Yu, Qingquan Li)</author>
      <guid isPermaLink="false">2502.15336v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Moving Flock Detection in Pedestrian Trajectories Using Sequential Deep Learning Models</title>
      <link>http://arxiv.org/abs/2502.15252v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;理解集体行人运动对于人群管理、自主导航和人机交互至关重要。本文探讨了使用序列深度学习模型，包括循环神经网络（RNN）、长短期记忆（LSTM）网络和变压器，用于多行人轨迹中的实时群体检测。&lt;h4&gt;背景&lt;/h4&gt;理解和预测人群的行为对于许多应用如安全、交通规划以及机器人与人类的互动非常重要。&lt;h4&gt;目的&lt;/h4&gt;调查并开发基于序列深度学习模型的方法来识别多个人行进动轨迹中形成的集体运动模式（例如鸟群）。&lt;h4&gt;方法&lt;/h4&gt;{'两阶段过程': '首先，使用预训练的二元分类模型进行成对行人轨迹分类；其次，利用学到的表示动态地确定多代理群体。', '使用的模型': ['循环神经网络（RNN）', '长短期记忆网络（LSTM）', '变压器']}&lt;h4&gt;主要发现&lt;/h4&gt;{'实验结果': '所提出的方法在真实世界的群体运动数据集上进行了验证，显示了其在不同序列长度和多样化移动模式下的鲁棒性。', '准确性与稳定性': '模型可以高精度且稳定地检测行人群体，即使是在动态和嘈杂的环境中也能表现出色。', '进一步应用': '该方法被扩展以识别其他形式的集体运动，如车队和蜂群，为更全面的多代理行为分析铺平了道路。'}&lt;h4&gt;结论&lt;/h4&gt;提出的基于序列深度学习的方法在检测行人群体及其动态变化方面展示了优异的表现，并为进一步研究提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;理解集体行人的移动模式对于人群管理、自主导航和人机交互至关重要。这项工作探讨了使用包括循环神经网络（RNN）、长短期记忆（LSTM）网络和变压器在内的序列深度学习模型，来实现实时群体检测在多行人轨迹中的应用。提出的方法包含两个阶段：首先利用预训练的二元分类模型对成对的人行进动轨迹进行分类；然后使用学到的表示动态地识别多代理群体。通过真实世界人群运动数据集验证了方法的有效性，证明其具有跨变序列长度和多样移动模式的稳健性。实验结果显示，该模型能在高精度和稳定性下检测行人群体，即使在动态且嘈杂的情况下也能保持良好的表现。此外，还扩展到识别其他形式的集体运动（如车队、蜂群），为多代理行为分析铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding collective pedestrian movement is crucial for applications incrowd management, autonomous navigation, and human-robot interaction. Thispaper investigates the use of sequential deep learning models, includingRecurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, andTransformers, for real-time flock detection in multi-pedestrian trajectories.Our proposed approach consists of a two-stage process: first, a pre-trainedbinary classification model is used for pairwise trajectory classification, andsecond, the learned representations are applied to identify multi-agent flocksdynamically.  We validate our method using real-world group movement datasets,demonstrating its robustness across varying sequence lengths and diversemovement patterns. Experimental results indicate that our model consistentlydetects pedestrian flocks with high accuracy and stability, even in dynamic andnoisy environments. Furthermore, we extend our approach to identify other formsof collective motion, such as convoys and swarms, paving the way for morecomprehensive multi-agent behavior analysis.</description>
      <author>example@mail.com (Amartaivan Sanjjamts, Hiroshi Morita, Togootogtokh Enkhtogtokh)</author>
      <guid isPermaLink="false">2502.15252v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>OccProphet: Pushing Efficiency Frontier of Camera-Only 4D Occupancy Forecasting with Observer-Forecaster-Refiner Framework</title>
      <link>http://arxiv.org/abs/2502.15180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新颖的框架OccProphet，用于有效和高效地学习占用预测，显著降低计算需求并提高预测精度。&lt;h4&gt;背景&lt;/h4&gt;在复杂的交通环境中预测变化对于自动驾驶的安全性至关重要。最近的进步使通过观察历史2D图像来预测驾驶环境中的未来3D占用状态成为可能。然而，高计算需求使得占用预测在训练和推理阶段效率较低，限制了其在边缘设备上的可行性。&lt;h4&gt;目的&lt;/h4&gt;提出OccProphet框架以降低占用预测的计算要求，并提高预测精度。&lt;h4&gt;方法&lt;/h4&gt;OccProphet包含三个轻量级组件：观察者、预报器和精炼器。观察者通过提出的Efficient 4D Aggregation with Tripling-Attention Fusion从3D多帧体素中提取时空特征，而预报器和精炼器则有条件地预测并细化未来的占用状态。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes、Lyft-Level5和nuScenes-Occupancy数据集上的实验结果表明OccProphet训练友好且推理效率高。与最先进的Cam4DOcc相比，OccProphet减少了58%~78%的计算成本，并提高了2.6倍的速度；此外，它还实现了4%~18%相对更高的预测精度。&lt;h4&gt;结论&lt;/h4&gt;OccProphet在保持或提高预测准确性的同时显著降低了计算需求，显示出其部署到边缘设备中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;预测复杂的交通环境中变化对于自动驾驶的安全性至关重要。最近的进步使通过观察历史2D图像来预测驾驶环境中的未来3D占用状态成为可能。然而，高计算需求使得占用预测在训练和推理阶段效率较低，限制了其在边缘设备上的可行性。在这篇论文中，我们提出了一种新颖的框架OccProphet，用于有效且高效地学习占用预测，显著降低计算需求并提高预测精度。OccProphet包含三个轻量级组件：观察者、预报器和精炼器。观察者通过提出的Efficient 4D Aggregation with Tripling-Attention Fusion从3D多帧体素中提取时空特征，而预报器和精炼器则有条件地预测并细化未来的占用状态。实验结果表明OccProphet在nuScenes、Lyft-Level5和nuScenes-Occupancy数据集上训练友好且推理效率高。与最先进的Cam4DOcc相比，OccProphet减少了58%~78%的计算成本，并提高了2.6倍的速度；此外，它还实现了4%~18%相对更高的预测精度。代码和模型可在https://github.com/JLChen-C/OccProphet上公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting variations in complex traffic environments is crucial for thesafety of autonomous driving. Recent advancements in occupancy forecasting haveenabled forecasting future 3D occupied status in driving environments byobserving historical 2D images. However, high computational demands makeoccupancy forecasting less efficient during training and inference stages,hindering its feasibility for deployment on edge agents. In this paper, wepropose a novel framework, i.e., OccProphet, to efficiently and effectivelylearn occupancy forecasting with significantly lower computational requirementswhile improving forecasting accuracy. OccProphet comprises three lightweightcomponents: Observer, Forecaster, and Refiner. The Observer extractsspatio-temporal features from 3D multi-frame voxels using the proposedEfficient 4D Aggregation with Tripling-Attention Fusion, while the Forecasterand Refiner conditionally predict and refine future occupancy inferences.Experimental results on nuScenes, Lyft-Level5, and nuScenes-Occupancy datasetsdemonstrate that OccProphet is both training- and inference-friendly.OccProphet reduces 58\%$\sim$78\% of the computational cost with a 2.6$\times$speedup compared with the state-of-the-art Cam4DOcc. Moreover, it achieves4\%$\sim$18\% relatively higher forecasting accuracy. Code and models arepublicly available at https://github.com/JLChen-C/OccProphet.</description>
      <author>example@mail.com (Junliang Chen, Huaiyuan Xu, Yi Wang, Lap-Pui Chau)</author>
      <guid isPermaLink="false">2502.15180v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>CurricuVLM: Towards Safe Autonomous Driving via Personalized Safety-Critical Curriculum Learning with Vision-Language Models</title>
      <link>http://arxiv.org/abs/2502.15119v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;确保自动驾驶系统的安全性是当前面临的关键挑战，尤其是在处理罕见但可能造成严重后果的安全临界场景时。尽管现有研究已经探讨了生成用于自主车辆（AV）测试的安全临界场景的方法，但在将这些场景有效地融入策略学习以提升安全性能方面的工作仍相对有限。此外，开发适应自主车辆行为模式和性能瓶颈变化的训练课程也尚未得到充分探索。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶系统中的安全性是目前研究的重点领域之一，特别是如何处理那些虽然罕见但可能导致严重事故的安全临界场景问题。&lt;h4&gt;目的&lt;/h4&gt;提出CurricuVLM框架以解决现有方法在生成安全临界测试场景和适应自主车辆行为模式方面存在的不足。该框架利用视觉语言模型（VLM）来实现个性化课程学习，从而提升自动驾驶系统的整体性能与安全性。&lt;h4&gt;方法&lt;/h4&gt;CurricuVLM通过运用VLM的多模态理解能力分析自动驾驶代理的行为、识别其性能弱点，并动态生成量身定制的训练场景进行课程适应。通过对不安全驾驶情况及其叙述性描述进行全面分析，该框架能够深入推理评估AV的能力并确定关键行为模式。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在Waymo Open Motion数据集上，CurricuVLM在常规及安全临界情景中均优于现有的基准方法，特别是在导航成功率、行驶效率和安全性指标方面表现更优。此外，进一步的分析揭示了CurricuVLM作为一种通用方法可以与各种强化学习算法相结合以增强自动驾驶系统。&lt;h4&gt;结论&lt;/h4&gt;CurricuVLM框架通过利用视觉语言模型的独特能力来改善自主驾驶代理的安全性和整体性能，并且它可以被广泛应用于不同的强化学习环境中。此外，该框架的源代码和演示视频可在GitHub页面上获取。&lt;h4&gt;翻译&lt;/h4&gt;原文摘要已经以中文形式呈现，无需再次翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring safety in autonomous driving systems remains a critical challenge,particularly in handling rare but potentially catastrophic safety-criticalscenarios. While existing research has explored generating safety-criticalscenarios for autonomous vehicle (AV) testing, there is limited work oneffectively incorporating these scenarios into policy learning to enhancesafety. Furthermore, developing training curricula that adapt to an AV'sevolving behavioral patterns and performance bottlenecks remains largelyunexplored. To address these challenges, we propose CurricuVLM, a novelframework that leverages Vision-Language Models (VLMs) to enable personalizedcurriculum learning for autonomous driving agents. Our approach uniquelyexploits VLMs' multimodal understanding capabilities to analyze agent behavior,identify performance weaknesses, and dynamically generate tailored trainingscenarios for curriculum adaptation. Through comprehensive analysis of unsafedriving situations with narrative descriptions, CurricuVLM performs in-depthreasoning to evaluate the AV's capabilities and identify critical behavioralpatterns. The framework then synthesizes customized training scenariostargeting these identified limitations, enabling effective and personalizedcurriculum learning. Extensive experiments on the Waymo Open Motion Datasetshow that CurricuVLM outperforms state-of-the-art baselines across both regularand safety-critical scenarios, achieving superior performance in terms ofnavigation success, driving efficiency, and safety metrics. Further analysisreveals that CurricuVLM serves as a general approach that can be integratedwith various RL algorithms to enhance autonomous driving systems. The code anddemo video are available at: https://zihaosheng.github.io/CurricuVLM/.</description>
      <author>example@mail.com (Zihao Sheng, Zilin Huang, Yansong Qu, Yue Leng, Sruthi Bhavanam, Sikai Chen)</author>
      <guid isPermaLink="false">2502.15119v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>DDAT: Diffusion Policies Enforcing Dynamically Admissible Robot Trajectories</title>
      <link>http://arxiv.org/abs/2502.15043v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种利用扩散模型生成机器人动态可接受轨迹的方法，名为DDAT。通过在训练和推理过程中将预测投影到动态可接受流形上，该方法解决了传统扩散模型与机器人动力学方程之间不匹配的问题。&lt;h4&gt;背景&lt;/h4&gt;扩散模型因其多模态生成能力而在图像和视频创建中表现出色，并逐渐被应用于机器人研究以生成机器人运动。然而，由于其随机性质，它难以满足描述可行机器人运动的精确动态方程。&lt;h4&gt;目的&lt;/h4&gt;解决利用扩散模型生成符合动力学约束的机器人轨迹的问题，提高长时域规划性能。&lt;h4&gt;方法&lt;/h4&gt;DDAT通过迭代采样预测状态前一个状态的可达集多面体下近似，并将预测状态投影到该集合中来确保动态可接受性。这种方法减少了扩散模型需要不断重新计划的需求，从而能够进行一次性长时间范围内的轨迹规划。&lt;h4&gt;主要发现&lt;/h4&gt;提出的框架在四旋翼飞行器和各种MuJoCo环境的广泛模拟以及Unitree GO1和GO2的真实世界实验中生成了更高品质的动态可接受机器人轨迹。&lt;h4&gt;结论&lt;/h4&gt;DDAT通过在扩散模型预测过程中引入动力学可行性约束，有效地解决了利用这种随机生成方法进行精确机器人运动规划的挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：扩散模型因其多模态生成能力而擅长创建图像和视频，在机器人研究中也越来越流行，用于生成机器人运动。然而，扩散模型的本质随机性与描述可行机器人运动的动力学方程不一致。因此，利用扩散模型生成动态可接受的机器人轨迹是一个挑战。为解决这一问题，我们引入了DDAT：适用于动态可接受轨迹的扩散策略，以使用扩散模型对黑盒机器人系统进行能够被证明是可接受的轨迹生成。如果序列中的每个状态都属于其前驱者按照机器人运动方程计算出的可达集合，则称该序列是一条动力学上可接受的轨迹。为了生成这样的轨迹，我们的扩散策略在训练和推理过程中将预测投影到动态可接受流形上来使去噪神经网络的目标与动力学可行性约束对齐。这些预测的自回归性质以及机器人动力学的黑盒特性使得这种投影非常具有挑战性。因此，我们通过迭代采样状态可达集的一个多面体下近似，并将其预测的后继投影到该集合上，来强制执行可接受性；随后将此过程重复应用于经过投影后的后续状态。这种方法生成了准确轨迹，从而消除了扩散模型不断重新计划的需求，使得一次性长时域规划成为可能。我们通过广泛的四旋翼飞行器模拟和各种MuJoCo环境中的实验以及Unitree GO1和GO2的真实世界测试来证明我们的框架能够生成更高品质的动态可接受机器人轨迹。&lt;h4&gt;关键词&lt;/h4&gt;扩散模型, 动态可行性, 机器人运动规划&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models excel at creating images and videos thanks to theirmultimodal generative capabilities. These same capabilities have made diffusionmodels increasingly popular in robotics research, where they are used forgenerating robot motion. However, the stochastic nature of diffusion models isfundamentally at odds with the precise dynamical equations describing thefeasible motion of robots. Hence, generating dynamically admissible robottrajectories is a challenge for diffusion models. To alleviate this issue, weintroduce DDAT: Diffusion policies for Dynamically Admissible Trajectories togenerate provably admissible trajectories of black-box robotic systems usingdiffusion models. A sequence of states is a dynamically admissible trajectoryif each state of the sequence belongs to the reachable set of its predecessorby the robot's equations of motion. To generate such trajectories, ourdiffusion policies project their predictions onto a dynamically admissiblemanifold during both training and inference to align the objective of thedenoiser neural network with the dynamical admissibility constraint. Theauto-regressive nature of these projections along with the black-box nature ofrobot dynamics render these projections immensely challenging. We thus enforceadmissibility by iteratively sampling a polytopic under-approximation of thereachable set of a state onto which we project its predicted successor, beforeiterating this process with the projected successor. By producing accuratetrajectories, this projection eliminates the need for diffusion models tocontinually replan, enabling one-shot long-horizon trajectory planning. Wedemonstrate that our framework generates higher quality dynamically admissiblerobot trajectories through extensive simulations on a quadcopter and variousMuJoCo environments, along with real-world experiments on a Unitree GO1 andGO2.</description>
      <author>example@mail.com (Jean-Baptiste Bouvier, Kanghyun Ryu, Kartik Nagpal, Qiayuan Liao, Koushil Sreenath, Negar Mehr)</author>
      <guid isPermaLink="false">2502.15043v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>DEFT: Differentiable Branched Discrete Elastic Rods for Modeling Furcated DLOs in Real-Time</title>
      <link>http://arxiv.org/abs/2502.15037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的框架DEFT，用于实时建模复杂的分支柔性线性物体（BDLOs），解决了机器人自动化电线束装配中的关键挑战。&lt;h4&gt;背景&lt;/h4&gt;现有的研究已经成功地对单一线性的可变形物体进行了建模，但对于具有复杂力交互和应变传播模式的分支结构来说，这些方法难以直接适用。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够准确预测分支柔性线性物体动态行为的方法，并实现高效的实时计算以及规划能力。&lt;h4&gt;方法&lt;/h4&gt;DEFT结合了基于物理的模型与机器学习框架，用于建模BDLO的动力学特性、动态传播和抓取操作。&lt;h4&gt;主要发现&lt;/h4&gt;通过一系列现实世界的实验展示了DEFT在准确性、计算速度和泛化性方面的优越性能。&lt;h4&gt;结论&lt;/h4&gt;DEFT为复杂柔性线性物体的自动化装配提供了强大的工具，并且展示了其在实际应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;自主电线束组装要求机器人能够高精度地操作复杂的分支电缆。现有的研究虽然对单一线性的可变形对象建模取得了一定进展，但对于具有复杂力交互和应变传播模式的分支结构来说，这些方法难以直接适用。为了解决这一挑战，本文提出了一种新的框架DEFT，该框架结合了基于物理模型的方法与机器学习技术，能够准确地模拟BDLO的动力学特性，并实现了高效的实时计算及规划能力，在一系列现实世界的实验中证明了其优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous wire harness assembly requires robots to manipulate complexbranched cables with high precision and reliability. A key challenge inautomating this process is predicting how these flexible and branchedstructures behave under manipulation. Without accurate predictions, it isdifficult for robots to reliably plan or execute assembly operations. Whileexisting research has made progress in modeling single-threaded DeformableLinear Objects (DLOs), extending these approaches to Branched Deformable LinearObjects (BDLOs) presents fundamental challenges. The junction points in BDLOscreate complex force interactions and strain propagation patterns that cannotbe adequately captured by simply connecting multiple single-DLO models. Toaddress these challenges, this paper presents Differentiable discrete branchedElastic rods for modeling Furcated DLOs in real-Time (DEFT), a novel frameworkthat combines a differentiable physics-based model with a learning frameworkto: 1) accurately model BDLO dynamics, including dynamic propagation atjunction points and grasping in the middle of a BDLO, 2) achieve efficientcomputation for real-time inference, and 3) enable planning to demonstratedexterous BDLO manipulation. A comprehensive series of real-world experimentsdemonstrates DEFT's efficacy in terms of accuracy, computational speed, andgeneralizability compared to state-of-the-art alternatives. Projectpage:https://roahmlab.github.io/DEFT/.</description>
      <author>example@mail.com (Yizhou Chen, Xiaoyue Wu, Yeheng Zong, Anran Li, Yuzhen Chen, Julie Wu, Bohao Zhang, Ram Vasudevan)</author>
      <guid isPermaLink="false">2502.15037v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Safe Beyond the Horizon: Efficient Sampling-based MPC with Neural Control Barrier Functions</title>
      <link>http://arxiv.org/abs/2502.15006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'问题描述': '在实践中使用模型预测控制（MPC）时，满足超出预测范围的安全规范是一个常见问题。', '现有方法的局限性': '理论研究表明可以通过施加合适的终端集约束或足够长的预测范围来保证安全性。然而这些技术难以应用且很少被实际操作者采用，特别是在处理一般非线性动态系统的情况下。', '提出的解决方案': '提出了一种新的方法，通过学习一个近似的离散时间控制屏障函数，并将其融入到变分推理MPC（VIMPC）中来解决上述问题。这种方法在精确递归可行性、计算可行性和适用于‘黑盒’动力学之间做出权衡。', '改进措施': '提出了一种新的采样策略，该策略显著减少了估计的最优控制方差，并提高了采样的效率，从而可以在CPU上实现实时规划。', '性能验证': 'Neural Shield-VIMPC（NS-VIMPC）控制器在模拟和实际硬件实验中均显示出比现有基于采样的MPC控制器更高的安全性改进。特别是在成本函数设计不佳的情况下也能获得显著的安全性提升。', '技术实现': '通过学习近似离散时间控制屏障函数，并将其集成到变分推理MPC（VIMPC）框架中的方式来解决上述问题，同时引入了一种新的采样策略以优化状态约束处理。'}&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了在实际应用中使用模型预测控制时遇到的安全性保障难题以及现有的理论方法难以实施的问题。研究提出通过结合变分推理MPC与近似离散时间控制屏障函数的学习来解决这一挑战，同时引入了新的采样策略以提高计算效率和实时规划能力。实验表明，这种新方法在实际应用中表现出色，尤其是在处理复杂动态系统时有显著的安全性提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A common problem when using model predictive control (MPC) in practice is thesatisfaction of safety specifications beyond the prediction horizon. Whiletheoretical works have shown that safety can be guaranteed by enforcing asuitable terminal set constraint or a sufficiently long prediction horizon,these techniques are difficult to apply and thus are rarely used bypractitioners, especially in the case of general nonlinear dynamics. To solvethis problem, we impose a tradeoff between exact recursive feasibility,computational tractability, and applicability to ''black-box'' dynamics bylearning an approximate discrete-time control barrier function andincorporating it into a variational inference MPC (VIMPC), a sampling-based MPCparadigm. To handle the resulting state constraints, we further propose a newsampling strategy that greatly reduces the variance of the estimated optimalcontrol, improving the sample efficiency, and enabling real-time planning on aCPU. The resulting Neural Shield-VIMPC (NS-VIMPC) controller yields substantialsafety improvements compared to existing sampling-based MPC controllers, evenunder badly designed cost functions. We validate our approach in bothsimulation and real-world hardware experiments.</description>
      <author>example@mail.com (Ji Yin, Oswin So, Eric Yang Yu, Chuchu Fan, Panagiotis Tsiotras)</author>
      <guid isPermaLink="false">2502.15006v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Ultra-High-Frequency Harmony: mmWave Radar and Event Camera Orchestrate Accurate Drone Landing</title>
      <link>http://arxiv.org/abs/2502.14992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted by ACM SenSys 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;为了实现精确、高效和安全的无人机着陆，地面平台需要实时且准确地定位下降中的无人机，并引导它们到达指定位置。虽然毫米波（mmWave）感应与相机结合可以提高定位精度，但传统帧照相机较低的采样频率相比毫米波雷达形成了系统吞吐量瓶颈。本文通过在地面平台设置中用新型事件摄像机取代传统的帧照相机来解决这一问题，并引入了针对无人机着陆设计的高度精确且低延迟的地面对准系统mmE-Loc。&lt;h4&gt;背景&lt;/h4&gt;传统的方法结合毫米波雷达和帧照相机构建定位系统，但其较低的采样频率限制了系统的吞吐量。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的高精度、低延迟地面定位系统（mmE-Loc）用于无人机着陆，以改善现有的瓶颈问题，并提高整体性能。&lt;h4&gt;方法&lt;/h4&gt;将事件摄像机与毫米波雷达结合使用，在这种设置中，采样频率得到了统一。为了充分利用这两种模式之间的时间一致性以及空间互补性，提出了两个创新模块：时间一致性指导的协作跟踪和基于图信息自适应联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实地实验表明，mmE-Loc在定位精度和延迟方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的mmE-Loc系统能够提供更精确、低延迟的无人机着陆支持，并且在实际应用中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For precise, efficient, and safe drone landings, ground platforms shouldreal-time, accurately locate descending drones and guide them to designatedspots. While mmWave sensing combined with cameras improves localizationaccuracy, the lower sampling frequency of traditional frame cameras compared tommWave radar creates bottlenecks in system throughput. In this work, we replacethe traditional frame camera with event camera, a novel sensor that harmonizesin sampling frequency with mmWave radar within the ground platform setup, andintroduce mmE-Loc, a high-precision, low-latency ground localization systemdesigned for drone landings. To fully leverage the \textit{temporalconsistency} and \textit{spatial complementarity} between these modalities, wepropose two innovative modules, \textit{consistency-instructed collaborativetracking} and \textit{graph-informed adaptive joint optimization}, for accuratedrone measurement extraction and efficient sensor fusion. Extensive real-worldexperiments in landing scenarios from a leading drone delivery companydemonstrate that mmE-Loc outperforms state-of-the-art methods in bothlocalization accuracy and latency.</description>
      <author>example@mail.com (Haoyang Wang, Jingao Xu, Xinyu Luo, Xuecheng Chen, Ting Zhang, Ruiyang Duan, Yunhao Liu, Xinlei Chen)</author>
      <guid isPermaLink="false">2502.14992v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>A novel step-by-step procedure for the kinematic calibration of robots using a single draw-wire encoder</title>
      <link>http://arxiv.org/abs/2502.14983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;机器人定位精度在进行高精度制造任务时是一个关键因素。为了有效提高机械臂的精度，校准扮演着至关重要的角色。&lt;h4&gt;背景&lt;/h4&gt;现有的文献中提出了多种机器人校准方法，这些方法使用的测量系统和识别算法差异很大。&lt;h4&gt;目的&lt;/h4&gt;开发一种新型逐步运动学校准程序，仅使用通过拉线编码器获取的一维距离测量数据来逐次估计参数。&lt;h4&gt;方法&lt;/h4&gt;为了实现这一目标，我们推导了一种分析方法，在这种方法中，对于每个未知参数，可以找到一组校准点，其中测得的距离与预测的距离之间的差异只依赖于那个未知参数。这减少了识别过程中的计算负担，并有可能提高其精度。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和实验测试中，该策略的有效性得到了证实。结果表明，所提出的逐步校准方法为标准校准方法提供了一种实用、成本效益高且计算需求较低的替代方案。&lt;h4&gt;结论&lt;/h4&gt;这种校准方法使得机器人校准更加易于实现，从而提高了机械臂执行任务时的精度和可靠性。&lt;h4&gt;翻译&lt;/h4&gt;机器人定位精度是进行精密制造作业的关键。为提高机械臂精度，提出了一种使用拉线编码器一维距离测量数据逐步校准的新方法，并通过推导分析法验证了其有效性。该方法是一种成本效益高、计算负担小的替代方案，使机器人校准更加简便和经济。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s00170-024-13219-1&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot positioning accuracy is a key factory when performing high-precisionmanufacturing tasks. To effectively improve the accuracy of a manipulator,often up to a value close to its repeatability, calibration plays a crucialrole. In the literature, various approaches to robot calibration have beenproposed, and they range considerably in the type of measurement system andidentification algorithm used. Our aim was to develop a novel step-by-stepkinematic calibration procedure - where the parameters are subsequentlyestimated one at a time - that only uses 1D distance measurement data obtainedthrough a draw-wire encoder. To pursue this objective, we derived an analyticalapproach to find, for each unknown parameter, a set of calibration points wherethe discrepancy between the measured and predicted distances only depends onthat unknown parameter. This reduces the computational burden of theidentification process while potentially improving its accuracy. Simulationsand experimental tests were carried out on a 6 degrees-of-freedom robot arm:the results confirmed the validity of the proposed strategy. As a result, theproposed step-by-step calibration approach represents a practical,cost-effective and computationally less demanding alternative to standardcalibration approaches, making robot calibration more accessible and easier toperform.</description>
      <author>example@mail.com (Giovanni Boschetti, Teresa Sinico)</author>
      <guid isPermaLink="false">2502.14983v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Humanoid-VLA: Towards Universal Humanoid Control with Visual Integration</title>
      <link>http://arxiv.org/abs/2502.14795v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架Humanoid-VLA，该框架整合了语言理解、自我中心场景感知和运动控制，旨在实现通用的人形机器人控制。&lt;h4&gt;背景&lt;/h4&gt;当前人形机器人的控制系统主要依赖于反应机制，并且由于数据稀缺缺乏自主互动能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够解决现有局限性的新方法，即Humanoid-VLA框架，以提高人形机器人在理解和执行任务时的自主性和适应性。&lt;h4&gt;方法&lt;/h4&gt;该研究通过使用非自我中心的人体运动数据集与文本描述进行语言-动作预对齐来开始。然后利用参数高效的视频条件微调技术融入自我中心视觉上下文。此外还提出了一种自监督数据增强策略，可以直接从运动数据中生成伪标注。&lt;h4&gt;主要发现&lt;/h4&gt;Humanoid-VLA框架能够通过利用大规模未标记的视频数据进行训练，提高在物体互动和环境探索任务中的情境意识能力。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，基于全身控制架构的人形机器人控制系统实现了更像人类的行为表现，具备更强适应性和智能性交互能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文，此JSON格式包含对摘要内容的中文总结与分类&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the limitations of current humanoid robot controlframeworks, which primarily rely on reactive mechanisms and lack autonomousinteraction capabilities due to data scarcity. We propose Humanoid-VLA, a novelframework that integrates language understanding, egocentric scene perception,and motion control, enabling universal humanoid control. Humanoid-VLA beginswith language-motion pre-alignment using non-egocentric human motion datasetspaired with textual descriptions, allowing the model to learn universal motionpatterns and action semantics. We then incorporate egocentric visual contextthrough a parameter efficient video-conditioned fine-tuning, enablingcontext-aware motion generation. Furthermore, we introduce a self-superviseddata augmentation strategy that automatically generates pseudoannotationsdirectly derived from motion data. This process converts raw motion sequencesinto informative question-answer pairs, facilitating the effective use oflarge-scale unlabeled video data. Built upon whole-body control architectures,extensive experiments show that Humanoid-VLA achieves object interaction andenvironment exploration tasks with enhanced contextual awareness, demonstratinga more human-like capacity for adaptive and intelligent engagement.</description>
      <author>example@mail.com (Pengxiang Ding, Jianfei Ma, Xinyang Tong, Binghong Zou, Xinxin Luo, Yiguo Fan, Ting Wang, Hongchao Lu, Panzhong Mo, Jinxin Liu, Yuefan Wang, Huaicheng Zhou, Wenshuo Feng, Jiacheng Liu, Siteng Huang, Donglin Wang)</author>
      <guid isPermaLink="false">2502.14795v2</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Design of a Visual Pose Estimation Algorithm for Moon Landing</title>
      <link>http://arxiv.org/abs/2502.14942v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 8 figures, Presented in 11th Nano-Satellite Symposium&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;为了实现月球精确着陆，提出了一种基于地形的绝对导航算法来估计航天器的位置和姿态。&lt;h4&gt;背景&lt;/h4&gt;在月球着陆任务中，需要提高航天器导航系统的准确性以减少惯性传感器引起的漂移误差。&lt;h4&gt;目的&lt;/h4&gt;通过使用预定的陨石坑数据库对拍摄到的陨石坑进行识别与匹配，并利用这些信息来校正导航偏差，从而实现精确导航。&lt;h4&gt;方法&lt;/h4&gt;该算法采用基于影像处理和地面特征识别的技术，但为了专注于估计算法的研究，在实验中跳过了图像处理及陨石坑匹配步骤。进行了仿真实验以评估算法的准确性以及使用不同数量的陨石坑进行估算的效果。&lt;h4&gt;主要发现&lt;/h4&gt;通过仿真验证了提出的绝对导航方法的有效性和准确性，并探讨了用于估计所需的陨石坑数量的影响。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种有效的地形绝对导航解决方案，可以显著提高月球着陆任务中航天器导航的精度。&lt;h4&gt;翻译&lt;/h4&gt;为了实现月球精确着陆，需要校正惯性传感器引起的导航漂移。本研究提出了一种基于地面特征识别技术的绝对导航方法，并通过仿真验证了其有效性及准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In order to make a pinpoint landing on the Moon, the spacecraft's navigationsystem must be accurate. To achieve the desired accuracy, navigational driftcaused by the inertial sensors must be corrected. One way to correct this driftis to use absolute navigation solutions. In this study, a terrain absolutenavigation method to estimate the spacecraft's position and attitude isproposed. This algorithm uses the position of the craters below the spacecraftfor estimation. Craters seen by the camera onboard the spacecraft are detectedand identified using a crater database known beforehand. In order to focus onestimation algorithms, image processing and crater matching steps are skipped.The accuracy of the algorithm and the effect of the crater number used forestimation are inspected by performing simulations.</description>
      <author>example@mail.com (Atakan Süslü, Betül Rana Kuran, Halil Ersin Söken)</author>
      <guid isPermaLink="false">2502.14942v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>PLDR-LLMs Learn A Generalizable Tensor Operator That Can Replace Its Own Deep Neural Net At Inference</title>
      <link>http://arxiv.org/abs/2502.13502v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 1 figure, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;大型语言模型PLDR-LLM通过学习一个奇异性条件，使得在推理时可以使用能量曲率张量G_{LM}来代替生成演绎输出的深度神经网络。&lt;h4&gt;背景&lt;/h4&gt;研究探讨了一种基于幂律解码表示（Power Law Decoder Representations）的大型语言模型PLDR-LLM，并揭示了其演绎输出具有高度不变性和可泛化性，且能够通过缓存机制提高推理效率。&lt;h4&gt;目的&lt;/h4&gt;展示PLDR-LLM作为一种基础模型的特点及其在不同条件下的表现特性；探讨演绎输出不变性的原因和影响；提出一种有效的推理框架来优化模型性能。&lt;h4&gt;方法&lt;/h4&gt;构建了一个学习奇异性条件的框架，该框架允许使用能量曲率张量G_{LM}替换原有的深度神经网络进行推理，并通过缓存机制（包括KV-cache和G-cache）加速推理过程。&lt;h4&gt;主要发现&lt;/h4&gt;演绎输出具有高度不变性，在缓存后仍保持相同均方根误差(RMSE)及行列式值，且零样本基准分数未受影响；学习到的演绎输出与使用转移初始化、随机初始化或单位张量作为常数操作符预训练模型在损失和准确性上有不同特征。&lt;h4&gt;结论&lt;/h4&gt;观察到不变性特性引入了训练和推理阶段之间的新颖不对称关系，并为PLDR-LLM提供了一个有效的训练和推理框架，该框架利用KV-cache和G-cache来优化性能。&lt;h4&gt;翻译&lt;/h4&gt;我们展示了基于幂律解码表示的大型语言模型(PLDR-LLM)是一种基础模型，其演绎输出在小扰动下是不变张量。PLDR-LLM学习了一个奇异性条件，使得生成演绎输出的深度神经网络（如幂定律图注意力PLGA）可以在推理阶段被能量曲率张量G_{LM}所替代。我们证明了可以通过简单的实现缓存机制来提高推理时间效率，包括用于G_{LM}和KV-cache的缓存。在缓存后，演绎输出具有非常高的不变性和可泛化性（例如RMSE和行列式的值保持到15位小数）。消融研究显示，学习得到的演绎输出与使用转移初始化、随机初始化或单位张量作为常数操作符预训练模型有不同的损失和准确性特征。观察到了一个由缓存所引入的新颖不对称关系在训练和推理阶段之间。我们提出了PLDR-LLM的学习奇异性条件的共同特性，并提供了一个带有KV-cache和G-cache的有效训练和推理框架实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We show that Large Language Model from Power Law Decoder Representations(PLDR-LLM) is a foundational model whose deductive outputs are invarianttensors up to a small perturbation. PLDR-LLM learns a singularity condition forthe deductive outputs that enable the once-inferred energy-curvature tensor$\mathbf{G}_{LM}$ to replace the deep neural network of power law graphattention (PLGA) generating the deductive outputs at inference. We demonstratethat a cache for $\mathbf{G}_{LM}$ (G-cache) and KV-cache can be implemented ina straightforward manner to improve the inference time. The invariance andgeneralizable nature of deductive outputs is at a very high fidelity wheredeductive outputs have same RMSE and determinant values up to 15 decimal placesafter caching, and zero-shot benchmark scores remain unchanged. Ablationstudies show that learned deductive outputs have distinct loss and accuracycharacteristics from models pretrained with transferred, randomly initializedor identity tensors as a constant tensor operator and an LLM with scaled-dotproduct attention (SDPA) is a special case of PLDR-LLM where $\mathbf{G}_{LM}$is predefined as identity. The observed invariance characteristic introduces anovel asymmetry between training and inference phases with caching. We outlineobserved common characteristics of the deductive outputs for the learnedsingularity condition. We provide an implementation of a training and inferenceframework for PLDR-LLM with KV-cache and G-cache.</description>
      <author>example@mail.com (Burc Gokden)</author>
      <guid isPermaLink="false">2502.13502v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
  <item>
      <title>Large Language-Geometry Model: When LLM meets Equivariance</title>
      <link>http://arxiv.org/abs/2502.11149v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EquiLLM的新框架，该框架旨在准确预测物理系统的3D结构和动态。EquiLLM通过整合几何感知提示、等变编码器、大型语言模型（LLMs）以及等变适配器，实现了E(3)-等方性与LLMs能力的无缝融合。&lt;h4&gt;背景&lt;/h4&gt;在科学应用中，准确预测物理系统的3D结构和动态至关重要。现有的基于几何图神经网络（GNNs）的方法虽然有效执行了E(3)等方性，但难以充分利用广泛的外部信息。直接使用大型语言模型则可以融入外部知识，但在空间推理方面缺乏保证的等方性能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架EquiLLM，以解决现有方法在预测物理系统3D结构和动态时存在的局限性和不足。&lt;h4&gt;方法&lt;/h4&gt;EquiLLM主要由四个关键组件组成：几何感知提示、等变编码器、大型语言模型（LLMs）以及等变适配器。这些组件协同工作，使LLM能够作为高级不变特征处理器，并且3D方向信息则完全由等变的编码器和适配器处理。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，EquiLLM在分子动力学模拟、人类运动仿真和抗体设计方面均显著优于先前的方法，展现了其出色的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了通过融合大型语言模型与等变性特征处理技术，可以更有效地预测物理系统的3D结构及其动态。这一方法为解决实际问题提供了新的途径，并且显示出在多个领域中的广泛应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;准确地预测物理系统的三维结构和动力学是科学应用中至关重要的任务。现有的基于几何图神经网络（GNNs）的方法虽然成功实现了E(3)等方性，但往往难以充分利用广泛的外部信息。而直接使用大型语言模型可以融入外部知识，但在进行空间推理时缺乏保证的等方性能力。在本文中，我们提出了EquiLLM这一新框架，它能够无缝地将E(3)-等方性和大型语言模型的能力结合起来来表示三维物理系统。具体来说，EquiLLM包括四个关键部分：几何感知提示、等变编码器、一个大型语言模型以及等变适配器。在这种情况下，通过指导性提示引导的大型语言模型可以作为一个高级不变特征处理器，而3D方向信息则完全由等方性编码器和适配器处理模块来管理。实验结果表明，在分子动力学模拟、人类运动仿真和抗体设计方面，EquiLLM方法都显著优于先前的方法，这凸显了它的泛化能力的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting 3D structures and dynamics of physical systems iscrucial in scientific applications. Existing approaches that rely on geometricGraph Neural Networks (GNNs) effectively enforce $\mathrm{E}(3)$-equivariance,but they often fall in leveraging extensive broader information. While directapplication of Large Language Models (LLMs) can incorporate external knowledge,they lack the capability for spatial reasoning with guaranteed equivariance. Inthis paper, we propose EquiLLM, a novel framework for representing 3D physicalsystems that seamlessly integrates E(3)-equivariance with LLM capabilities.Specifically, EquiLLM comprises four key components: geometry-aware prompting,an equivariant encoder, an LLM, and an equivariant adaptor. Essentially, theLLM guided by the instructive prompt serves as a sophisticated invariantfeature processor, while 3D directional information is exclusively handled bythe equivariant encoder and adaptor modules. Experimental results demonstratethat EquiLLM delivers significant improvements over previous methods acrossmolecular dynamics simulation, human motion simulation, and antibody design,highlighting its promising generalizability.</description>
      <author>example@mail.com (Zongzhao Li, Jiacheng Cen, Bing Su, Wenbing Huang, Tingyang Xu, Yu Rong, Deli Zhao)</author>
      <guid isPermaLink="false">2502.11149v2</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Covering a Point Set by $m$ Disks with Minimum Total Area</title>
      <link>http://arxiv.org/abs/2502.13773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 Pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人感知中的一个常见问题是放置传感器以确保对一组资产进行稳健监控。&lt;h4&gt;目的&lt;/h4&gt;研究如何在最小化总观察区域的前提下，通过特定数量的圆盘形状传感区来监测给定的一组资产。&lt;h4&gt;方法&lt;/h4&gt;提供并分析了一个快速启发式算法，并利用该算法初始化精确的整数规划解决方案。随后对整数程序进行修改，以强制传感器之间的分离约束。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一个有效的解决策略用于优化机器人系统中传感器布局问题。&lt;h4&gt;结论&lt;/h4&gt;通过将启发式方法与改进后的整数编程相结合，可以有效地确定传感器的位置，以便在给定条件下最小化监测所需的空间区域。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个研究方向，旨在使用圆盘形状传感区的m个传感器来稳健地监控n个资产。目标是通过确保每个资产由至少kappa(p)数量的传感器监视的同时尽量减少总观察面积。为了解决这个问题，作者提出了一种快速启发式算法，并利用该方法初始化精确整数规划解决方案，从而进一步优化传感器布局以满足分离约束条件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A common robotics sensing problem is to place sensors to robustly monitor aset of assets, where robustness is assured by requiring asset $p$ to bemonitored by at least $\kappa(p)$ sensors. Given $n$ assets that must beobserved by $m$ sensors, each with a disk-shaped sensing region, where shouldthe sensors be placed to minimize the total area observed? We provide andanalyze a fast heuristic for this problem. We then use the heuristic toinitialize an exact Integer Programming solution. Subsequently, we enforceseparation constraints between the sensors by modifying the integer programformulation and by changing the disk candidate set.</description>
      <author>example@mail.com (Mariem Guitouni, Chek-Manh Loi, Sándor P. Fekete, Michael Perk, Aaron T. Becker)</author>
      <guid isPermaLink="false">2502.13773v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Multi-dataset synergistic in supervised learning to pre-label structural components in point clouds from shell construction scenes</title>
      <link>http://arxiv.org/abs/2502.14721v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 8 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在壳式建筑工地中，通过利用标准数据集和最新的Transformer模型架构来适应点云语义分割的方法。&lt;h4&gt;背景&lt;/h4&gt;构建新的训练数据集所需的重大努力阻碍了计算机视觉研究和建筑业中的机器学习发展。传统的室内物体分割方法无法有效应对复杂结构组件的语义分割挑战。&lt;h4&gt;目的&lt;/h4&gt;解决在AEC领域中复杂结构性件分割的问题，通过利用现有的大规模室内数据集进行跨域推理，并应用迁移学习以最小化新标注数据的需求来最大化分割性能。&lt;h4&gt;方法&lt;/h4&gt;建立了通过监督训练和自定义验证数据集建立基准的方法；评估了跨域推理与大型室内数据集的使用效果；并利用转移学习策略在小规模注释下最大化语义分割性能。&lt;h4&gt;主要发现&lt;/h4&gt;预训练的Transformer架构即使经过最小限度的微调也能提供有效的建筑组件分割策略，这为自动化新未见过的数据标注以及频繁出现的对象分割提供了有前景的方法。&lt;h4&gt;结论&lt;/h4&gt;利用迁移学习和现有的大规模室内数据集进行训练可以有效地解决AEC领域中复杂结构性件语义分割的问题，并且能够显著减少新的标注工作量。这种方法对于构建更大规模的训练资源具有重要意义，同时也为自动化注释新类型的数据提供了一条可行的道路。&lt;h4&gt;翻译&lt;/h4&gt;创建用于建筑工地点云语义分割的新数据集是一个劳动密集型的过程，这阻碍了计算机视觉研究和建筑业中机器学习的发展。本文探索了使用标准数据集以及最近的Transformer模型架构来处理壳式建筑工地中的问题。与通常专注于建筑物内部家具物体分割的方法不同，本研究侧重于在AEC（建筑、工程和施工）领域内复杂结构组件的语义分割挑战。我们通过监督训练建立了一个基准，并用一个自定义验证数据集进行了评估；同时利用大规模室内数据集进行跨域推理，并尝试了转移学习策略以最小化新标注数据的需求来优化性能。研究发现表明，即使是经过少量微调，预训练的Transformer架构也能提供有效的建筑组件分割策略，这为构建更大规模的训练资源以及自动化注释未见过的数据类型提供了有前景的方法和可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The significant effort required to annotate data for new training datasetshinders computer vision research and machine learning in the constructionindustry. This work explores adapting standard datasets and the latesttransformer model architectures for point cloud semantic segmentation in thecontext of shell construction sites. Unlike common approaches focused on objectsegmentation of building interiors and furniture, this study addressed thechallenges of segmenting complex structural components in Architecture,Engineering, and Construction (AEC). We establish a baseline through supervisedtraining and a custom validation dataset, evaluate the cross-domain inferencewith large-scale indoor datasets, and utilize transfer learning to maximizesegmentation performance with minimal new data. The findings indicate that withminimal fine-tuning, pre-trained transformer architectures offer an effectivestrategy for building component segmentation. Our results are promising forautomating the annotation of new, previously unseen data when creating largertraining resources and for the segmentation of frequently recurring objects.</description>
      <author>example@mail.com (Lukas Rauch, Thomas Braml)</author>
      <guid isPermaLink="false">2502.14721v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Small Graph Is All You Need: DeepStateGNN for Scalable Traffic Forecasting</title>
      <link>http://arxiv.org/abs/2502.14525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Yannick W\"olker and Arash Hajisafi contributed equally to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新的图神经网络模型DeepStateGNN，用于分析交通数据，并展示了其在预测和重建任务中的有效性。&lt;h4&gt;背景&lt;/h4&gt;传统的GNN方法将每个交通传感器视为图节点，而新提出的DeepStateGNN通过相似性标准对传感器进行聚类形成更高层次的图节点（称为深层状态节点），从而固定了图中节点的数量。&lt;h4&gt;目的&lt;/h4&gt;提出并验证一种新的用于分析大规模交通数据的高效和准确的方法DeepStateGNN。&lt;h4&gt;方法&lt;/h4&gt;DeepStateGNN根据空间接近度、功能相似性和特定条件下行为相似性对传感器进行聚类，形成深层状态节点。这种聚类方式允许动态且适应性的节点分组，并支持更快更精确的大规模交通网络分析。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，DeepStateGNN在可扩展性、训练速度和预测及重建准确性方面均优于传统方法，在大规模传感器网络中表现出色。&lt;h4&gt;结论&lt;/h4&gt;DeepStateGNN作为一种创新的图神经网络模型，在处理复杂且动态变化的大规模交通数据时具有显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel Graph Neural Network (GNN) model, named DeepStateGNN, foranalyzing traffic data, demonstrating its efficacy in two critical tasks:forecasting and reconstruction. Unlike typical GNN methods that treat eachtraffic sensor as an individual graph node, DeepStateGNN clusters sensors intohigher-level graph nodes, dubbed Deep State Nodes, based on various similaritycriteria, resulting in a fixed number of nodes in a Deep State graph. The term"Deep State" nodes is a play on words, referencing hidden networks of powerthat, like these nodes, secretly govern traffic independently of visiblesensors. These Deep State Nodes are defined by several similarity factors,including spatial proximity (e.g., sensors located nearby in the road network),functional similarity (e.g., sensors on similar types of freeways), andbehavioral similarity under specific conditions (e.g., traffic behavior duringrain). This clustering approach allows for dynamic and adaptive node grouping,as sensors can belong to multiple clusters and clusters may evolve over time.Our experimental results show that DeepStateGNN offers superior scalability andfaster training, while also delivering more accurate results than competitors.It effectively handles large-scale sensor networks, outperforming other methodsin both traffic forecasting and reconstruction accuracy.</description>
      <author>example@mail.com (Yannick Wölker, Arash Hajisafi, Cyrus Shahabi, Matthias Renz)</author>
      <guid isPermaLink="false">2502.14525v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>OG-Gaussian: Occupancy Based Street Gaussians for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2502.14235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;3D场景重建对于创建逼真的自动驾驶模拟环境至关重要。随着3DGaussian Splatting（3DGS）技术的进步，先前的研究已经将其应用于复杂动态驾驶场景的重建。然而，这些方法通常需要昂贵的LiDAR传感器和预注释的数据集来处理动态对象。为了解决这些问题，我们提出了一种新的方法OG-Gaussian。&lt;h4&gt;背景&lt;/h4&gt;准确且真实的3D场景重建对于创建逼真的自动驾驶模拟环境至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有技术对昂贵设备和复杂手动标注的依赖，研究者提出了一个新框架来优化动态驾驶场景的三维重建过程。&lt;h4&gt;方法&lt;/h4&gt;我们提出了一种新的方法OG-Gaussian，该方法使用来自周围视图相机图像生成的Occupancy Grids（OGs）代替LiDAR点云。通过在ONet的帮助下预测占位网格中的语义信息，我们的方法能够将动态车辆与静态街道背景分离，并将其转换为用于重建静态和动态对象的初始点云集合。此外，我们采用基于学习的方法来估计动态物体的轨迹和姿态。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，OG-Gaussian在Waymo Open数据集上，在重建质量和渲染速度方面与当前最先进技术相当，平均PSNR达到35.13，渲染速率达到143 FPS。同时，我们的方法显著降低了计算成本和经济负担。&lt;h4&gt;结论&lt;/h4&gt;提出的OG-Gaussian提供了一种高效且经济的方法来实现高质量的动态驾驶场景三维重建。&lt;h4&gt;翻译&lt;/h4&gt;准确且真实的3D场景重建对于创建逼真的自动驾驶模拟环境至关重要。随着3DGaussian Splatting（3DGS）技术的进步，先前的研究已经将其应用于复杂动态驾驶场景的重建。然而，这些方法通常需要昂贵的LiDAR传感器和预注释的数据集来处理动态对象。为了解决这些问题，我们提出了一种新的方法OG-Gaussian，该方法使用来自周围视图相机图像生成的Occupancy Grids（OGs）代替LiDAR点云，并在ONet的帮助下预测占位网格中的语义信息，将动态车辆与静态街道背景分离并转换为用于重建的初始点云集合。此外，我们采用基于学习的方法来估计动态物体的轨迹和姿态。实验结果表明，在Waymo Open数据集上，OG-Gaussian在重建质量和渲染速度方面表现优异（平均PSNR：35.13；FPS：143），同时显著降低了计算成本和经济负担。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and realistic 3D scene reconstruction enables the lifelike creationof autonomous driving simulation environments. With advancements in 3D GaussianSplatting (3DGS), previous studies have applied it to reconstruct complexdynamic driving scenes. These methods typically require expensive LiDAR sensorsand pre-annotated datasets of dynamic objects. To address these challenges, wepropose OG-Gaussian, a novel approach that replaces LiDAR point clouds withOccupancy Grids (OGs) generated from surround-view camera images usingOccupancy Prediction Network (ONet). Our method leverages the semanticinformation in OGs to separate dynamic vehicles from static street background,converting these grids into two distinct sets of initial point clouds forreconstructing both static and dynamic objects. Additionally, we estimate thetrajectories and poses of dynamic objects through a learning-based approach,eliminating the need for complex manual annotations. Experiments on Waymo Opendataset demonstrate that OG-Gaussian is on par with the currentstate-of-the-art in terms of reconstruction quality and rendering speed,achieving an average PSNR of 35.13 and a rendering speed of 143 FPS, whilesignificantly reducing computational costs and economic overhead.</description>
      <author>example@mail.com (Yedong Shen, Xinran Zhang, Yifan Duan, Shiqi Zhang, Heng Li, Yilong Wu, Jianmin Ji, Yanyong Zhang)</author>
      <guid isPermaLink="false">2502.14235v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>DAG: Deep Adaptive and Generative $K$-Free Community Detection on Attributed Graphs</title>
      <link>http://arxiv.org/abs/2502.14294v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGKDD 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种用于社区检测的新模型DAG，该模型能够自动寻找最佳的社团数量，并无需人工指定社团的数量。通过在节点表示学习、社区隶属度读取和社团数量搜索三个模块的设计上进行创新，实现了端到端的学习过程。&lt;h4&gt;背景&lt;/h4&gt;带有丰富语义和拓扑信息的图上的社区检测对于现实世界网络分析尤其是在线游戏中的用户匹配具有巨大潜力。然而，在现有的深度图聚类方法中，确定最优社区数量需要昂贵的人工成本以及可能侵犯隐私的数据获取方式。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需事先指定社团数量K的方法来解决社区发现问题，即K-Free Community Detection问题。&lt;h4&gt;方法&lt;/h4&gt;设计了Deep Adaptive and Generative (DAG)模型。该模型包含三个关键组成部分：带掩码属性重建的节点表示学习模块、社区隶属度读取模块以及采用群稀疏策略寻找社团数量的搜索模块。通过这些创新，实现了端到端同时进行社区检测和社团数量搜索。&lt;h4&gt;主要发现&lt;/h4&gt;提出的DAG模型在五个公共数据集及一个真实在线手游数据集中表现出了优越性。特别是在腾讯的一个游戏中，相对于最佳竞争方法，DAG提高了7.35%的团队效率。&lt;h4&gt;结论&lt;/h4&gt;通过创新性的算法设计，所提出的方法克服了传统社区检测面临的参数选择难题，并展现了实际应用中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;带有丰富语义和拓扑信息的图上的社区发现为现实世界网络分析提供了巨大潜力，特别是在在线游戏用户匹配方面。近年来，图神经网络（GNN）使深度图聚类方法能够从语义和拓扑信息中学习社团分配。然而，其成功依赖于关于社群数量K的先验知识，这在获取成本高昂以及存在隐私问题的情况下是不现实的。本文探讨了无需先验知识确定社区数量的情况下的社区发现问题，并提出了一种新颖的深度自适应与生成模型（DAG），该模型能够在不指定社团数量的前提下进行社区检测。此外还设计了一个新指标EDGE，用于在标签难以获取的真实世界应用中评估社区检测方法的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Community detection on attributed graphs with rich semantic and topologicalinformation offers great potential for real-world network analysis, especiallyuser matching in online games. Graph Neural Networks (GNNs) have recentlyenabled Deep Graph Clustering (DGC) methods to learn cluster assignments fromsemantic and topological information. However, their success depends on theprior knowledge related to the number of communities $K$, which is unrealisticdue to the high costs and privacy issues of acquisition.In this paper, weinvestigate the community detection problem without prior $K$, referred to as$K$-Free Community Detection problem. To address this problem, we propose anovel Deep Adaptive and Generative model~(DAG) for community detection withoutspecifying the prior $K$. DAG consists of three key components, \textit{i.e.,}a node representation learning module with masked attribute reconstruction, acommunity affiliation readout module, and a community number search module withgroup sparsity. These components enable DAG to convert the process ofnon-differentiable grid search for the community number, \textit{i.e.,} adiscrete hyperparameter in existing DGC methods, into a differentiable learningprocess. In such a way, DAG can simultaneously perform community detection andcommunity number search end-to-end. To alleviate the cost of acquiringcommunity labels in real-world applications, we design a new metric, EDGE, toevaluate community detection methods even when the labels are not feasible.Extensive offline experiments on five public datasets and a real-world onlinemobile game dataset demonstrate the superiority of our DAG over the existingstate-of-the-art (SOTA) methods. DAG has a relative increase of 7.35\% in teamsin a Tencent online game compared with the best competitor.</description>
      <author>example@mail.com (Chang Liu, Yuwen Yang, Yue Ding, Hongtao Lu, Wenqing Lin, Ziming Wu, Wendong Bi)</author>
      <guid isPermaLink="false">2502.14294v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis</title>
      <link>http://arxiv.org/abs/2502.14807v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为FetalCLIP的视觉-语言基础模型，该模型能够生成胎儿超声图像的通用表示。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型在医疗领域变得越来越有效，但胎儿超声图像仍然是一个具有挑战性的领域，因为它们自身复杂性高，并且缺乏配对的多模态数据。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，引入了FetalCLIP这一视觉-语言基础模型。&lt;h4&gt;方法&lt;/h4&gt;使用包含210,035张胎儿超声图像与文本配对的大规模多样本数据集进行预训练。这是迄今为止用于基础模型开发的最大规模的配对数据集。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛的基准测试中，FetalCLIP在分类、妊娠年龄估计、先天性心脏病检测和胎儿结构分割等关键胎儿超声应用中表现优于所有基线，并且展示了出色的泛化能力，在有限标签数据的情况下仍表现出色。&lt;h4&gt;结论&lt;/h4&gt;计划公开发布FetalCLIP模型以造福更广泛的科学界。&lt;h4&gt;翻译&lt;/h4&gt;基础模型在医疗领域的有效性正在不断提升，提供了可以轻松适应下游任务的大型数据集上的预训练模型。尽管取得了进展，胎儿超声图像仍然是一个具有挑战性的领域，因为它们固有的复杂性通常需要大量的额外训练，并且由于多模态配对数据的缺乏而面临限制。为了克服这些挑战，我们引入了FetalCLIP这一视觉-语言基础模型，它可以生成胎儿超声图像的通用表示。FetalCLIP使用包含210,035张胎儿超声图像与文本配对的大规模多样本数据集进行预训练。这是迄今为止用于基础模型开发的最大规模的配对数据集。这种独特的培训方法使FetalCLIP能够有效地学习胎儿超声图像中复杂的解剖特征，从而产生可用于多种下游应用的强大表示。在广泛的基准测试中，包括分类、妊娠年龄估计、先天性心脏病(CHD)检测和胎儿结构分割等关键胎儿超声应用，FetalCLIP的表现优于所有基线，并且展示了出色的泛化能力，在有限标签数据的情况下仍表现出色。我们计划公开发布FetalCLIP模型以造福更广泛的科学界。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are becoming increasingly effective in the medical domain,offering pre-trained models on large datasets that can be readily adapted fordownstream tasks. Despite progress, fetal ultrasound images remain achallenging domain for foundation models due to their inherent complexity,often requiring substantial additional training and facing limitations due tothe scarcity of paired multimodal data. To overcome these challenges, here weintroduce FetalCLIP, a vision-language foundation model capable of generatinguniversal representation of fetal ultrasound images. FetalCLIP was pre-trainedusing a multimodal learning approach on a diverse dataset of 210,035 fetalultrasound images paired with text. This represents the largest paired datasetof its kind used for foundation model development to date. This unique trainingapproach allows FetalCLIP to effectively learn the intricate anatomicalfeatures present in fetal ultrasound images, resulting in robustrepresentations that can be used for a variety of downstream applications. Inextensive benchmarking across a range of key fetal ultrasound applications,including classification, gestational age estimation, congenital heart defect(CHD) detection, and fetal structure segmentation, FetalCLIP outperformed allbaselines while demonstrating remarkable generalizability and strongperformance even with limited labeled data. We plan to release the FetalCLIPmodel publicly for the benefit of the broader scientific community.</description>
      <author>example@mail.com (Fadillah Maani, Numan Saeed, Tausifa Saleem, Zaid Farooq, Hussain Alasmawi, Werner Diehl, Ameera Mohammad, Gareth Waring, Saudabi Valappi, Leanne Bricker, Mohammad Yaqub)</author>
      <guid isPermaLink="false">2502.14807v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Dual-level Mixup for Graph Few-shot Learning with Fewer Tasks</title>
      <link>http://arxiv.org/abs/2502.14158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WWW25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个名为SMILE的方法，用于在少量任务的情况下进行图的少样本学习。该方法通过双层mixup策略增强了元学习中的节点和任务多样性，并利用了图中节点度数提供的先验信息。&lt;h4&gt;背景&lt;/h4&gt;当前领先的图形模型需要大量的标记样本以避免在少样本场景下出现过拟合的情况，而最近的研究试图通过结合图学习与元学习来缓解这一问题。然而，这样的假设可能不现实，因为构建任务和涉及的成本很高。&lt;h4&gt;目的&lt;/h4&gt;提出一个简单有效的方法（SMILE），用于解决图形元学习中需要大量任务的问题，并在少样本场景下提高模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入双层mixup策略，包括在同一任务内的以及跨任务的混合技术。此外，利用图中的节点度数信息来编码更表达式的节点表示。&lt;h4&gt;主要发现&lt;/h4&gt;理论上证明了SMILE能够增强模型的泛化能力；实验上，在所有评估数据集（无论是领域内还是跨域）中，SMILE均以显著优势超过了其他竞争性模型。&lt;h4&gt;结论&lt;/h4&gt;SMILE是一种简单有效的解决图形少样本学习问题的方法，通过丰富元学习中的节点和任务多样性，并利用图结构的先验信息来提升模型性能。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络已经被证明可以在网络上有效地学习图数据并从中挖掘内容。然而，现有的领先图形模型需要大量标记样本以避免在少量样本场景下的过拟合问题。最近的研究试图通过结合图学习与元学习来缓解这一问题。但是，这样的假设可能不现实，因为构建任务和涉及的成本很高。因此，我们提出了一种称为SMILE的方法，用于解决图形少样本学习中的任务数量较少的问题。该方法引入了双层mixup策略，在丰富元学习中可获得的节点和任务的同时，利用图结构提供的先验信息（即节点度数），以编码表达式的节点表示。理论上证明了SMILE可以提高模型的泛化能力；在实验上，SMILE在所有评估的数据集下均优于其他竞争性模型。我们的匿名代码可以在给定链接处找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714905&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have been demonstrated as a powerful paradigm foreffectively learning graph-structured data on the web and mining content fromit.Current leading graph models require a large number of labeled samples fortraining, which unavoidably leads to overfitting in few-shot scenarios. Recentresearch has sought to alleviate this issue by simultaneously leveraging graphlearning and meta-learning paradigms. However, these graph meta-learning modelsassume the availability of numerous meta-training tasks to learn transferablemeta-knowledge. Such assumption may not be feasible in the real world due tothe difficulty of constructing tasks and the substantial costs involved.Therefore, we propose a SiMple yet effectIve approach for graph few-shotLearning with fEwer tasks, named SMILE. We introduce a dual-level mixupstrategy, encompassing both within-task and across-task mixup, tosimultaneously enrich the available nodes and tasks in meta-learning. Moreover,we explicitly leverage the prior information provided by the node degrees inthe graph to encode expressive node representations. Theoretically, wedemonstrate that SMILE can enhance the model generalization ability.Empirically, SMILE consistently outperforms other competitive models by a largemargin across all evaluated datasets with in-domain and cross-domain settings.Our anonymous code can be found here.</description>
      <author>example@mail.com (Yonghao Liu, Mengyu Li, Fausto Giunchiglia, Lan Huang, Ximing Li, Xiaoyue Feng, Renchu Guan)</author>
      <guid isPermaLink="false">2502.14158v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>LXLv2: Enhanced LiDAR Excluded Lean 3D Object Detection with Fusion of 4D Radar and Camera</title>
      <link>http://arxiv.org/abs/2502.14503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE Robotics and Automation Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了LXLv2，改进了之前最先进的4D雷达相机融合的3D目标检测方法（LXL），通过新的深度监督策略和基于通道与空间注意力机制的融合模块，提升了模型的准确性、速度和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的LXL方法利用预测的图像深度分布图和雷达三维占用网格来辅助样本基础的图像视角转换。然而，该方法在深度预测的准确性和一致性上存在不足，并且基于拼接的融合方式影响了模型的健壮性。&lt;h4&gt;目的&lt;/h4&gt;改进现有技术中的缺陷，提高3D目标检测的精度、速度及鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;[{'一到多深度监督策略': '该策略通过雷达点的位置误差进行设计，并利用雷达散射截面（RCS）值调整监管区域以增强对象级别的深度一致性。'}, {'CSAFusion模块': '引入了基于通道和空间注意机制的融合模块，用于提高特征适应性。'}]&lt;h4&gt;主要发现&lt;/h4&gt;['在View-of-Delft和TJ4DRadSet数据集上的实验结果表明LXLv2优于原始方法LXL，在检测精度、推断速度以及鲁棒性方面均表现出显著优势。', '模型的改进策略有效提升了3D目标检测任务的整体性能。']&lt;h4&gt;结论&lt;/h4&gt;通过改进深度预测和特征融合机制，可以有效地解决现有雷达-相机融合技术中的问题，并提高其在复杂场景下的应用效果。&lt;h4&gt;翻译&lt;/h4&gt;作为之前的最先进的4D雷达-相机融合基础的3D对象检测方法LXL使用了预测的图像深度分布图和雷达三维占用网格来辅助基于采样的图像视角转换。然而，深度预测缺乏准确性和一致性，而LXL中的基于拼接的融合方式阻碍了模型的鲁棒性。在这项工作中，我们提出了LXLv2，在该版本中进行了修改以克服限制并提高性能。具体来说，考虑到雷达测量的位置误差，我们设计了一种通过雷达点实现的一对多深度监督策略，并利用雷达散射截面（RCS）值进一步调整监管区域以增强对象级别的深度一致性。此外，引入了一个名为CSAFusion的通道和空间注意机制融合模块来提高特征适应性。在View-of-Delft和TJ4DRadSet数据集上的实验结果表明所提出的LXLv2能够优于原始方法LXL，在检测精度、推理速度和鲁棒性方面都有改进，显示了模型的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2025.3536840&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the previous state-of-the-art 4D radar-camera fusion-based 3D objectdetection method, LXL utilizes the predicted image depth distribution maps andradar 3D occupancy grids to assist the sampling-based image viewtransformation. However, the depth prediction lacks accuracy and consistency,and the concatenation-based fusion in LXL impedes the model robustness. In thiswork, we propose LXLv2, where modifications are made to overcome thelimitations and improve the performance. Specifically, considering the positionerror in radar measurements, we devise a one-to-many depth supervision strategyvia radar points, where the radar cross section (RCS) value is furtherexploited to adjust the supervision area for object-level depth consistency.Additionally, a channel and spatial attention-based fusion module namedCSAFusion is introduced to improve feature adaptiveness. Experimental resultson the View-of-Delft and TJ4DRadSet datasets show that the proposed LXLv2 canoutperform LXL in detection accuracy, inference speed and robustness,demonstrating the effectiveness of the model.</description>
      <author>example@mail.com (Weiyi Xiong, Zean Zou, Qiuchi Zhao, Fengchun He, Bing Zhu)</author>
      <guid isPermaLink="false">2502.14503v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors</title>
      <link>http://arxiv.org/abs/2502.14627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多语言音频-文本检索（ML-ATR）方案，旨在解决跨语言实例相似性匹配的不一致性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的ML-ATR方案在跨语言相似性匹配中存在不一致性问题。这些问题源于跨模态对齐方向误差和权重误差。&lt;h4&gt;目的&lt;/h4&gt;理论分析了权重误差上限，并提出了一种基于1-to-k对比学习和音频-英语共锚对比学习的一致性ML-ATR方案，以减轻数据分布误差对召回率和一致性的负面影响。&lt;h4&gt;方法&lt;/h4&gt;使用1-to-k对比学习和音频-英语共锚对比学习来解决多语言模态对齐问题，并通过理论分析确定权重误差上限。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在翻译的AudioCaps和Clotho数据集上，该方案在八种主流语言（包括英语）上的召回率和一致性指标方面达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的ML-ATR方案有效提高了多语言音频-文本检索的一致性和召回率，并且源代码可在指定网址获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims toretrieve audio clips or multilingual texts from databases. However, existingML-ATR schemes suffer from inconsistencies for instance similarity matchingacross languages. We theoretically analyze the inconsistency in terms of bothmultilingual modal alignment direction error and weight error, and propose thetheoretical weight error upper bound for quantifying the inconsistency. Basedon the analysis of the weight error upper bound, we find that the inconsistencyproblem stems from the data distribution error caused by random sampling oflanguages. We propose a consistent ML-ATR scheme using 1-to-k contrastivelearning and audio-English co-anchor contrastive learning, aiming to mitigatethe negative impact of data distribution error on recall and consistency inML-ATR. Experimental results on the translated AudioCaps and Clotho datasetsshow that our scheme achieves state-of-the-art performance on recall andconsistency metrics for eight mainstream languages, including English. Our codewill be available at https://github.com/ATRI-ACL/ATRI-ACL.</description>
      <author>example@mail.com (Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou)</author>
      <guid isPermaLink="false">2502.14627v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>QUAD-LLM-MLTC: Large Language Models Ensemble Learning for Healthcare Text Multi-Label Classification</title>
      <link>http://arxiv.org/abs/2502.14189v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;介绍了一种名为QUAD-LLM-MLTC的方法，该方法使用四种大型语言模型（LLMs）来处理多标签文本分类问题，尤其是在医疗领域的应用。&lt;h4&gt;背景描述&lt;/h4&gt;随着医疗领域内收集到的文本数据量不断增加，传统的机器学习模型难以有效应对这种大规模且复杂的数据集。此外，标记化的训练样本稀缺且具有复杂的语义特征。&lt;h4&gt;研究目的&lt;/h4&gt;提出一种利用大型语言模型（LLMs）进行多标签文本分类的新方法，并证明这种方法在医疗文本分类上的有效性。&lt;h4&gt;采用的方法&lt;/h4&gt;引入了QUAD-LLM-MLTC框架，该框架结合了四个不同的预训练模型：BERT、PEGASUS、GPT-4o和BART。这些模型分别用于提取关键词、增强数据、执行分类以及提供标签概率。&lt;h4&gt;实验结果&lt;/h4&gt;通过三个标注文本样本的评估对比传统方法与单一模型的方法，结果显示在F1分数和一致性上均有显著提高（分别为78.17%和80.16%，标准偏差为0.025和0.011）。&lt;h4&gt;结论&lt;/h4&gt;此研究展示了大型语言模型在多标签文本分类上的强大潜力，并提出了一种无需额外训练即可快速准确地处理医疗领域内海量数据的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The escalating volume of collected healthcare textual data presents a uniquechallenge for automated Multi-Label Text Classification (MLTC), which isprimarily due to the scarcity of annotated texts for training and their nuancednature. Traditional machine learning models often fail to fully capture thearray of expressed topics. However, Large Language Models (LLMs) havedemonstrated remarkable effectiveness across numerous Natural LanguageProcessing (NLP) tasks in various domains, which show impressive computationalefficiency and suitability for unsupervised learning through promptengineering. Consequently, these LLMs promise an effective MLTC of medicalnarratives. However, when dealing with various labels, different prompts can berelevant depending on the topic. To address these challenges, the proposedapproach, QUAD-LLM-MLTC, leverages the strengths of four LLMs: GPT-4o, BERT,PEGASUS, and BART. QUAD-LLM-MLTC operates in a sequential pipeline in whichBERT extracts key tokens, PEGASUS augments textual data, GPT-4o classifies, andBART provides topics' assignment probabilities, which results in fourclassifications, all in a 0-shot setting. The outputs are then combined usingensemble learning and processed through a meta-classifier to produce the finalMLTC result. The approach is evaluated using three samples of annotated texts,which contrast it with traditional and single-model methods. The results showsignificant improvements across the majority of the topics in theclassification's F1 score and consistency (F1 and Micro-F1 scores of 78.17% and80.16% with standard deviations of 0.025 and 0.011, respectively). Thisresearch advances MLTC using LLMs and provides an efficient and scalablesolution to rapidly categorize healthcare-related text data without furthertraining.</description>
      <author>example@mail.com (Hajar Sakai, Sarah S. Lam)</author>
      <guid isPermaLink="false">2502.14189v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Spiking Neural Networks from an Ensemble Learning Perspective</title>
      <link>http://arxiv.org/abs/2502.14218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as a conference paper at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;该论文提出了一种新的方法来提高脉冲神经网络（SNNs）的性能。&lt;h4&gt;背景信息&lt;/h4&gt;SNNs具有较高的能源效率，但存在性能不足的问题。研究者发现时间步长之间的初始状态差异过大是导致不稳定输出和性能下降的关键原因。&lt;h4&gt;主要目的&lt;/h4&gt;通过减少初始膜电位分布及其输出在不同时间步上的不一致性来提高SNN的稳定性和整体性能。&lt;h4&gt;提出方法&lt;/h4&gt;{'膜电位平滑': '一种改进措施，旨在促进信息向前传播并解决时间梯度消失问题。', '相邻子网络指导': '另一种策略，通过调整相邻的时间子网之间的关系以进一步提升稳定性。'}&lt;h4&gt;主要发现&lt;/h4&gt;该技术只需对脉冲神经元进行轻微修改而不需改变网络结构，并在1D语音、2D物体和3D点云识别任务中展示了稳定且一致的性能改进。&lt;h4&gt;具体成就&lt;/h4&gt;在CIFAR10-DVS数据集上，仅使用四个时间步就达到了83.20%的准确率。&lt;h4&gt;结论与意义&lt;/h4&gt;该研究为释放SNNs潜力提供了宝贵见解，并可能对神经形态计算领域产生深远影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spiking neural networks (SNNs) exhibit superior energy efficiency but sufferfrom limited performance. In this paper, we consider SNNs as ensembles oftemporal subnetworks that share architectures and weights, and highlight acrucial issue that affects their performance: excessive differences in initialstates (neuronal membrane potentials) across timesteps lead to unstablesubnetwork outputs, resulting in degraded performance. To mitigate this, wepromote the consistency of the initial membrane potential distribution andoutput through membrane potential smoothing and temporally adjacent subnetworkguidance, respectively, to improve overall stability and performance. Moreover,membrane potential smoothing facilitates forward propagation of information andbackward propagation of gradients, mitigating the notorious temporal gradientvanishing problem. Our method requires only minimal modification of the spikingneurons without adapting the network structure, making our method generalizableand showing consistent performance gains in 1D speech, 2D object, and 3D pointcloud recognition tasks. In particular, on the challenging CIFAR10-DVS dataset,we achieved 83.20\% accuracy with only four timesteps. This provides valuableinsights into unleashing the potential of SNNs.</description>
      <author>example@mail.com (Yongqi Ding, Lin Zuo, Mengmeng Jing, Pei He, Hanpu Deng)</author>
      <guid isPermaLink="false">2502.14218v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing PDF Data for Improving Japanese Large Multimodal Models</title>
      <link>http://arxiv.org/abs/2502.14778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用日本PDF数据训练大模态模型（LMM）以提高其在日本语言环境中的效果。&lt;h4&gt;背景&lt;/h4&gt;当前的大模态模型在英语中表现出色，但在日语环境中由于高质量训练数据的缺乏，性能受限。现有的日语大模态模型往往依赖于翻译后的英文数据集，限制了它们捕捉日本特定文化知识的能力。&lt;h4&gt;目的&lt;/h4&gt;探索利用日本PDF文档作为训练资源的可能性，并构建一个自动化流程来从这些文档中提取图像-文本对以丰富日语大模态模型的训练数据。&lt;h4&gt;方法&lt;/h4&gt;提出了一个完全自动化的管道，该管道使用预训练模型通过版面分析、OCR和视觉语言配对技术从PDF文件中抽取图像-文本对。此外，还构建了指令数据集来进一步增强训练数据。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果表明，基于PDF的数据显著提高了日语大模态模型的性能，在Heron-Bench上的表现提升了3.9%到13.8%不等。&lt;h4&gt;结论&lt;/h4&gt;PDF文档作为多模态资源对各种因素（如模型大小和语言模型）的影响得到了强化，证明了其在提高日语文本模型性能方面的价值。&lt;h4&gt;翻译&lt;/h4&gt;原文摘要描述了一个旨在提升日本大模态模型训练效果的研究项目。该项目探索利用未充分利用的日本PDF数据集，并开发了一种自动化流程来从这些文档中提取高质量的数据对进行模型训练。研究结果表明，这种方法显著改善了日语大模态模型在特定基准上的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Multimodal Models (LMMs) have demonstrated strong performance inEnglish, but their effectiveness in Japanese remains limited due to the lack ofhigh-quality training data. Current Japanese LMMs often rely on translatedEnglish datasets, restricting their ability to capture Japan-specific culturalknowledge. To address this, we explore the potential of Japanese PDF data as atraining resource, an area that remains largely underutilized. We introduce afully automated pipeline that leverages pretrained models to extract image-textpairs from PDFs through layout analysis, OCR, and vision-language pairing,removing the need for manual annotation. Additionally, we construct instructiondata from extracted image-text pairs to enrich the training data. To evaluatethe effectiveness of PDF-derived data, we train Japanese LMMs and assess theirperformance on the Japanese LMM Benchmark. Our results demonstrate substantialimprovements, with performance gains ranging from 3.9% to 13.8% on Heron-Bench.Further analysis highlights the impact of PDF-derived data on various factors,such as model size and language models, reinforcing its value as a multimodalresource for Japanese LMMs. We plan to make the source code and data publiclyavailable upon acceptance.</description>
      <author>example@mail.com (Jeonghun Baek, Akiko Aizawa, Kiyoharu Aizawa)</author>
      <guid isPermaLink="false">2502.14778v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Graph Anomaly Detection via Adaptive Test-time Representation Learning across Out-of-Distribution Domains</title>
      <link>http://arxiv.org/abs/2502.14293v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了AdaGraph-T3，一种针对跨领域图异常检测的测试时训练框架。&lt;h4&gt;背景&lt;/h4&gt;在新兴应用中，图结构数据中的标签异常通常稀缺，现有的监督式图异常检测方法由于分布偏移和异构特征空间的问题，在跨域情况下效果不佳或不可用。&lt;h4&gt;目的&lt;/h4&gt;为了应对这些挑战，提出了一个新颖的测试时训练框架AdaGraph-T3，旨在解决跨领域图异常检测问题。&lt;h4&gt;方法&lt;/h4&gt;AdaGraph-T3结合了监督学习和自监督学习，并在测试阶段仅使用自监督学习进行领域适应，通过基于同质性的亲和力分数捕捉异常的域不变属性。引入四种关键创新：有效的自监督方案、基于注意力机制的学习边权重的方法、处理异构特征的特定领域的编码器以及解决不平衡问题的类别感知正则化。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AdaGraph-T3在多个跨领域设置下显著优于现有方法，在AUROC和AUPRC上平均分别提高了6.6%和7.9%。&lt;h4&gt;结论&lt;/h4&gt;AdaGraph-T3能够有效地应对标签稀缺的挑战，并且在不同的图结构数据异常检测任务中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Anomaly Detection (GAD) has demonstrated great effectiveness inidentifying unusual patterns within graph-structured data. However, whilelabeled anomalies are often scarce in emerging applications, existingsupervised GAD approaches are either ineffective or not applicable when movedacross graph domains due to distribution shifts and heterogeneous featurespaces. To address these challenges, we present AdaGraph-T3, a novel test-timetraining framework for cross-domain GAD. AdaGraph-T3 combines supervised andself-supervised learning during training while adapting to a new domain duringtest time using only self-supervised learning by leveraging a homophily-basedaffinity score that captures domain-invariant properties of anomalies. Ourframework introduces four key innovations to cross-domain GAD: an effectiveself-supervision scheme, an attention-based mechanism that dynamically learnsedge importance weights during message passing, domain-specific encoders forhandling heterogeneous features, and class-aware regularization to addressimbalance. Experiments across multiple cross-domain settings demonstrate thatAdaGraph-T3 significantly outperforms existing approaches, achieving averageimprovements of over 6.6% in AUROC and 7.9% in AUPRC compared to the bestcompeting model.</description>
      <author>example@mail.com (Delaram Pirhayati, Arlei Silva)</author>
      <guid isPermaLink="false">2502.14293v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Nearshore Underwater Target Detection Meets UAV-borne Hyperspectral Remote Sensing: A Novel Hybrid-level Contrastive Learning Framework and Benchmark Dataset</title>
      <link>http://arxiv.org/abs/2502.14495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18pages,13figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为HUCLNet的新框架，用于改进近岸区域水下目标检测（UTD）的准确性。该方法利用对比学习和自适应学习策略来提取受光谱畸变影响的数据中具有区分性的特征。&lt;h4&gt;背景&lt;/h4&gt;无人机携带的高光谱遥感技术在水下目标探测领域展现出巨大潜力，但在近岸环境中的光谱扭曲限制了其效果。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的网络框架以克服传统基于海底模型的高光谱水下目标检测方法面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为HUCLNet的新框架，该框架结合对比学习和自适应学习策略，从受畸变影响的数据中提取区分性特征。此外，还使用了可靠性引导的聚类策略来增强所学表示的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;通过在新的近岸高光谱水下目标检测基准数据集ATR2-HUTD上进行广泛的实验表明，HUCLNet显著优于现有的先进方法。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效地提高无人机携带的高光谱遥感技术在复杂水域中进行水下目标探测的能力。&lt;h4&gt;翻译&lt;/h4&gt;无人机搭载的高光谱遥感技术已经成为一种有前景的水下目标检测（UTD）方法，但其在近岸环境中的效能受到光谱畸变的影响。这些畸变降低了传统基于海底模型的高光谱UTD方法的有效性，并增加了目标和背景光谱的不确定性。为了应对这一挑战，我们提出了一种新的框架——Hyperspectral Underwater Contrastive Learning Network (HUCLNet)，它结合了对比学习与自适应学习策略来增强近岸区域水下目标检测的鲁棒性。此外，在一系列实验中，通过一个新的基准数据集ATR2-HUTD证明了该方法的有效性，并显示出优于现有最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; UAV-borne hyperspectral remote sensing has emerged as a promising approachfor underwater target detection (UTD). However, its effectiveness is hinderedby spectral distortions in nearshore environments, which compromise theaccuracy of traditional hyperspectral UTD (HUTD) methods that rely onbathymetric model. These distortions lead to significant uncertainty in targetand background spectra, challenging the detection process. To address this, wepropose the Hyperspectral Underwater Contrastive Learning Network (HUCLNet), anovel framework that integrates contrastive learning with a self-paced learningparadigm for robust HUTD in nearshore regions. HUCLNet extracts discriminativefeatures from distorted hyperspectral data through contrastive learning, whilethe self-paced learning strategy selectively prioritizes the most informativesamples. Additionally, a reliability-guided clustering strategy enhances therobustness of learned representations.To evaluate the method effectiveness, weconduct a novel nearshore HUTD benchmark dataset, ATR2-HUTD, covering threediverse scenarios with varying water types and turbidity, and target types.Extensive experiments demonstrate that HUCLNet significantly outperformsstate-of-the-art methods. The dataset and code will be publicly available at:https://github.com/qjh1996/HUTD</description>
      <author>example@mail.com (Jiahao Qi, Chuanhong Zhou, Xingyue Liu, Chen Chen, Dehui Zhu, Kangcheng Bin, Ping Zhong)</author>
      <guid isPermaLink="false">2502.14495v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Mixed Signals: A Diverse Point Cloud Dataset for Heterogeneous LiDAR V2X Collaboration</title>
      <link>http://arxiv.org/abs/2502.14156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为Mixed Signals的全面车辆到一切（V2X）数据集，该数据集旨在解决现有V2X数据集中存在的局限性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的V2X数据集在范围、多样性和质量方面存在限制，这影响了单个车辆感知系统的性能。&lt;h4&gt;目的&lt;/h4&gt;为了填补这些空白，作者创建了一个名为Mixed Signals的数据集，它包含来自三辆配备两种不同类型的LiDAR传感器的连接自主汽车（CAVs）以及路边单元的数据。&lt;h4&gt;方法&lt;/h4&gt;该数据集提供了精确对齐的点云和跨越10类别的边界框注释，并且还进行了详细的统计分析和现有V2X方法的基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;Mixed Signals V2X Dataset是目前公开可用的用于V2X感知研究的最高质量和大规模的数据集之一。&lt;h4&gt;结论&lt;/h4&gt;该数据集提供了高质量、多样的数据，有助于推动V2X协作感知技术的发展，并为未来的相关研究奠定了坚实的基础。&lt;h4&gt;翻译&lt;/h4&gt;车辆到一切（V2X）协作感知作为一种解决方案已出现，旨在解决单个车辆感知系统中的限制。然而，现有的V2X数据集在范围、多样性和质量方面存在局限性。为了填补这些空白，我们提出了Mixed Signals，这是一个综合的V2X数据集，其中包含45.1k点云和来自三个配备两种不同类型的LiDAR传感器的连接自主汽车（CAVs）以及一个带有双LiDAR的路边单元采集到的240.6k边界框。该数据集提供精确对齐的点云和跨越十类别的边界框注释，确保了用于感知训练的数据可靠且高质量。我们提供了关于数据集质量的详细统计分析，并对其进行了广泛的基准测试以评估现有的V2X方法。Mixed Signals V2X Dataset是目前公开可用的质量最高、规模最大的V2X感知研究数据集之一。详情请访问我们的网站 https://mixedsignalsdataset.cs.cornell.edu/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicle-to-everything (V2X) collaborative perception has emerged as apromising solution to address the limitations of single-vehicle perceptionsystems. However, existing V2X datasets are limited in scope, diversity, andquality. To address these gaps, we present Mixed Signals, a comprehensive V2Xdataset featuring 45.1k point clouds and 240.6k bounding boxes collected fromthree connected autonomous vehicles (CAVs) equipped with two different types ofLiDAR sensors, plus a roadside unit with dual LiDARs. Our dataset providesprecisely aligned point clouds and bounding box annotations across 10 classes,ensuring reliable data for perception training. We provide detailed statisticalanalysis on the quality of our dataset and extensively benchmark existing V2Xmethods on it. Mixed Signals V2X Dataset is one of the highest quality,large-scale datasets publicly available for V2X perception research. Details onthe website https://mixedsignalsdataset.cs.cornell.edu/.</description>
      <author>example@mail.com (Katie Z Luo, Minh-Quan Dao, Zhenzhen Liu, Mark Campbell, Wei-Lun Chao, Kilian Q. Weinberger, Ezio Malis, Vincent Fremont, Bharath Hariharan, Mao Shan, Stewart Worrall, Julie Stephany Berrio Perez)</author>
      <guid isPermaLink="false">2502.14156v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Sparsified Graph Learning Framework for Vessel Behavior Anomalies</title>
      <link>http://arxiv.org/abs/2502.14197v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Anomaly Detection in Scientific Domains AAAI Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种用于学习时空交互的图神经网络的新方法。&lt;h4&gt;背景&lt;/h4&gt;传统的图神经网络依赖于预定义的图结构，这可能模糊了模型中被精确描述的关系。现有的方法通常基于固定的空间位置来定义节点，这种策略在动态环境中（如海洋环境）并不适用。&lt;h4&gt;目的&lt;/h4&gt;提出一种创新的图表示方法，旨在明确捕捉时间依赖关系和空间交互，并适用于动态环境。&lt;h4&gt;方法&lt;/h4&gt;将时间戳作为独立节点建模，通过图边显式地捕获时间依赖性。这种方法被扩展以构建多船图，能够有效地捕捉空间互动同时保持图形稀疏性。使用图卷积网络层处理该图，用于捕获时空模式，并结合预测层和变分图自编码器进行特征预测及重构。&lt;h4&gt;主要发现&lt;/h4&gt;新方法能够在动态环境中有效学习时空交互，通过创新的节点定义策略增强对时间依赖性的捕捉能力。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为在复杂且动态的环境下利用图神经网络建模提供了新的视角，并具有强大的异常检测能力。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络已经成为学习时空交互的强大工具。然而，传统的做法通常依赖于预定义的图结构，这可能会模糊模型中被精确描述的关系。此外，现有的方法一般基于固定的空间位置来定义节点，这种方法对于像海洋环境这样的动态环境是不合适的。我们的方法引入了一种创新的图表示方式，其中时间戳被建模为独立的节点，允许通过图边显式地捕获时间依赖性。此设置被扩展以构建一个多船图，能够有效地捕捉空间互动同时保持图形稀疏性。该图使用图卷积网络层来处理，用于捕捉时空模式，并结合预测层和变分图自编码器进行特征预测及重构，从而实现强大的异常检测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have emerged as a powerful tool for learningspatiotemporal interactions. However, conventional approaches often rely onpredefined graphs, which may obscure the precise relationships being modeled.Additionally, existing methods typically define nodes based on fixed spatiallocations, a strategy that is ill-suited for dynamic environments like maritimeenvironments. Our method introduces an innovative graph representation wheretimestamps are modeled as distinct nodes, allowing temporal dependencies to beexplicitly captured through graph edges. This setup is extended to construct amulti-ship graph that effectively captures spatial interactions whilepreserving graph sparsity. The graph is processed using Graph ConvolutionalNetwork layers to capture spatiotemporal patterns, with a forecasting layer forfeature prediction and a Variational Graph Autoencoder for reconstruction,enabling robust anomaly detection.</description>
      <author>example@mail.com (Jeehong Kim, Minchan Kim, Jaeseong Ju, Youngseok Hwang, Wonhee Lee, Hyunwoo Park)</author>
      <guid isPermaLink="false">2502.14197v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Distribution Matching for Self-Supervised Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.14424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一个新颖的自监督迁移学习方法——分布匹配(DM)，该方法在保持增强不变性的同时，驱动表示向预定义的参考分布靠拢。&lt;h4&gt;背景&lt;/h4&gt;现有的自监督迁移学习方法可能难以解释其内部结构和超参数的意义。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够提供直观且易于理解的表示空间的设计，并通过理论保证来证明该方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新的自监督转移学习方法，称为分布匹配(DM)，这种方法使得学习到的表示空间具有结构性并且其超参数可解释。此外，提供了DM的方法论上的保证，包括一个总体定理和端到端样本理论。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明了在多个现实世界数据集上以及评估指标中，相对于现有的自监督迁移学习方法，DM在目标分类任务上有竞争力的表现。即使样本数量有限的情况下，如果未标记的样本足够大，DM也可以提供出色的分类性能。&lt;h4&gt;结论&lt;/h4&gt;通过理论和实验结果证实了分布匹配(DM)方法的有效性，并且其设计使得表示空间具有结构化、可解释的特性。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种新颖的自监督迁移学习方法，称为分布匹配（DM），该方法在保持增强不变性的前提下驱动表示向预定义的参考分布靠拢。实验结果显示，在多个真实世界的数据集和评估指标上，与现有的自监督转移学习方法相比，DM在目标分类任务上有竞争力的表现。此外，我们还为DM提供了坚实的理论保证，包括总体定理和端到端样本定理。总体定理连接了自我监督学习任务和目标分类准确性之间的差距，而样本定理表明，即使从目标领域得到的样本数量有限，如果未标记的样本数量足够大，DM也能提供卓越的分类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/vincen-github/DM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel self-supervised transfer learning methodcalled Distribution Matching (DM), which drives the representation distributiontoward a predefined reference distribution while preserving augmentationinvariance. The design of DM results in a learned representation space that isintuitively structured and offers easily interpretable hyperparameters.Experimental results across multiple real-world datasets and evaluation metricsdemonstrate that DM performs competitively on target classification taskscompared to existing self-supervised transfer learning methods. Additionally,we provide robust theoretical guarantees for DM, including a population theoremand an end-to-end sample theorem. The population theorem bridges the gapbetween the self-supervised learning task and target classification accuracy,while the sample theorem shows that, even with a limited number of samples fromthe target domain, DM can deliver exceptional classification performance,provided the unlabeled sample size is sufficiently large.</description>
      <author>example@mail.com (Yuling Jiao, Wensen Ma, Defeng Sun, Hansheng Wang, Yang Wang)</author>
      <guid isPermaLink="false">2502.14424v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Token Adaptation via Side Graph Convolution for Temporally and Spatially Efficient Fine-tuning of 3D Point Cloud Transformers</title>
      <link>http://arxiv.org/abs/2502.14142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Currently under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;参数高效的微调（PEFT）是3D点云分析中预训练的3D点云Transformer的一种有前景的技术。尽管现有的PEFT方法试图减少可调整参数的数量，但在微调过程中仍然存在较高的时间和空间计算成本。&lt;h4&gt;背景&lt;/h4&gt;当前基于PEFT的方法虽然减少了可调参数的数量，但是在微调过程中的时间与空间效率仍然不尽如人意。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的针对3D点云Transformer的PEFT算法STAG，以在不牺牲性能的前提下提高时间和空间效率。&lt;h4&gt;方法&lt;/h4&gt;采用图卷积侧网络（Side Token Adaptation on a neighborhood Graph, STAG）作为冻结主干Transformer的并行组件，通过连接、参数共享框架和高效的图卷积来实现高效率。同时提出Point Cloud Classification 13 (PCC13)基准测试集，涵盖多种公开的3D点云数据集。&lt;h4&gt;主要发现&lt;/h4&gt;STAG算法在保持现有方法分类准确率的同时，将可调参数数量减少至0.43M，并且显著降低了微调过程中的计算时间和内存消耗。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，STAG不仅实现了高精度和高效的PEFT，在多项预训练模型上的表现均优于其他方法。这一成果为未来的3D点云分析提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;参数高效微调（PEFT）是针对预训练的3D点云Transformer的一种有前景的技术，用于3D点云分析。尽管现有的PEFT方法尝试减少可调整参数的数量，但在精细调节过程中仍然存在高计算时间和空间成本的问题。本文提出了一种名为Side Token Adaptation on a neighborhood Graph (STAG) 的新颖PEFT算法，旨在实现卓越的时间和空间效率。STAG使用与冻结主干Transformer并行工作的图卷积侧网络来适应下游任务的令牌。通过连接、参数共享框架以及高效的图卷积，STAG的侧面网络实现了高效率。我们还提出了一个新的基准测试集Point Cloud Classification 13 (PCC13)，该基准集合成了多种公开可用的3D点云数据集，可以全面评估PEFT方法。使用多个预训练模型和PCC13进行广泛的实验表明了STAG的有效性。具体而言，STAG在保持现有方法的分类准确性的同时，将可调参数减少到仅0.43M，并显著减少了微调过程中的计算时间和内存消耗。代码和基准测试将在以下网址提供：https://github.com/takahikof/STAG&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient fine-tuning (PEFT) of pre-trained 3D point cloudTransformers has emerged as a promising technique for 3D point cloud analysis.While existing PEFT methods attempt to minimize the number of tunableparameters, they still suffer from high temporal and spatial computationalcosts during fine-tuning. This paper proposes a novel PEFT algorithm for 3Dpoint cloud Transformers, called Side Token Adaptation on a neighborhood Graph(STAG), to achieve superior temporal and spatial efficiency. STAG employs agraph convolutional side network that operates in parallel with a frozenbackbone Transformer to adapt tokens to downstream tasks. STAG's side networkrealizes high efficiency through three key components: connection with thebackbone that enables reduced gradient computation, parameter sharingframework, and efficient graph convolution. Furthermore, we present Point CloudClassification 13 (PCC13), a new benchmark comprising diverse publiclyavailable 3D point cloud datasets, enabling comprehensive evaluation of PEFTmethods. Extensive experiments using multiple pre-trained models and PCC13demonstrates the effectiveness of STAG. Specifically, STAG maintainsclassification accuracy comparable to existing methods while reducing tunableparameters to only 0.43M and achieving significant reductions in bothcomputational time and memory consumption for fine-tuning. Code and benchmarkwill be available at: https://github.com/takahikof/STAG</description>
      <author>example@mail.com (Takahiko Furuya)</author>
      <guid isPermaLink="false">2502.14142v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Geometry Scalable Coding Using a Resolution and Quality-conditioned Latents Probability Estimator</title>
      <link>http://arxiv.org/abs/2502.14099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE and currently under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了一种新的点云（PC）编码可扩展解决方案，名为SRQH。这种方案能够在单个比特流中实现不同质量和分辨率的解码。&lt;h4&gt;背景&lt;/h4&gt;当前多媒体内容消费场景多样化，对网络、硬件和显示能力要求各异，传统的编码方法难以适应这些需求而不会导致存储和计算成本大幅增加。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于基于深度学习点云编码的标准JPEG Pleno的新可扩展编码方案SRQH。&lt;h4&gt;方法&lt;/h4&gt;该方案通过同时实现质量和分辨率的可扩展性来解决传统问题，能够建模由不同RD折衷训练的模型获得潜在变量之间的关系，并且在不同分辨率下仍有效。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明SRQH能够在单个比特流中解码出不同质量和分辨率的点云，同时仅稍微增加复杂性和损失一些压缩效率。&lt;h4&gt;结论&lt;/h4&gt;SRQH是一种创新性的可扩展编码方案，在JPEG Pleno标准中的集成证明了其有效性和适用性。&lt;h4&gt;翻译&lt;/h4&gt;在当今时代，用户以各种各样的网络、硬件和显示能力场景消费多媒体内容。一个简单的解决方案是为每种可能的客户需求生成独立流，但这种做法会大大增加存储和计算需求。通过使用能够生成渐进式比特流（包含基础层后跟多个增强层）的编码器可以避免这些问题，从而允许多次解码相同的比特流以满足不同重建和显示要求。虽然可扩展编码在传统图像和视频编解码器中已为人所知且得到解决，但本论文关注的是开发一种基于深度学习点云（PC）的新问题解决方案。由于这种3D表示的特性，实现灵活而不损害编解码器其他功能的方案难度很大。本文提出了一种名为可伸缩分辨率和质量超先验(SRQH)的联合质量和分辨率可扩展性方案，该方案与先前的方法不同，能够建模使用针对不同RD权衡训练模型获得潜在变量之间的关系，并且在不同分辨率下仍有效。实验结果表明，当将SRQH集成到新兴的JPEG Pleno学习PC编码标准中时，SRQH允许仅通过单个比特流解码具有不同质量和分辨率的PC，同时相较于需要针对每种编解码配置单独比特流的非可扩展性JPEG PCC只带来有限的RD惩罚和复杂度增量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the current age, users consume multimedia content in very heterogeneousscenarios in terms of network, hardware, and display capabilities. A naivesolution to this problem is to encode multiple independent streams, eachcovering a different possible requirement for the clients, with an obviousnegative impact in both storage and computational requirements. These drawbackscan be avoided by using codecs that enable scalability, i.e., the ability togenerate a progressive bitstream, containing a base layer followed by multipleenhancement layers, that allow decoding the same bitstream serving multiplereconstructions and visualization specifications. While scalable coding is awell-known and addressed feature in conventional image and video codecs, thispaper focuses on a new and very different problem, notably the development ofscalable coding solutions for deep learning-based Point Cloud (PC) coding. Thepeculiarities of this 3D representation make it hard to implement flexiblesolutions that do not compromise the other functionalities of the codec. Thispaper proposes a joint quality and resolution scalability scheme, namedScalable Resolution and Quality Hyperprior (SRQH), that, contrary to previoussolutions, can model the relationship between latents obtained with modelstrained for different RD tradeoffs and/or at different resolutions.Experimental results obtained by integrating SRQH in the emerging JPEG Plenolearning-based PC coding standard show that SRQH allows decoding the PC atdifferent qualities and resolutions with a single bitstream while incurringonly in a limited RD penalty and increment in complexity w.r.t. non-scalableJPEG PCC that would require one bitstream per coding configuration.</description>
      <author>example@mail.com (Daniele Mari, André F. R. Guarda, Nuno M. M. Rodrigues, Simone Milani, Fernando Pereira)</author>
      <guid isPermaLink="false">2502.14099v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Data-Efficient Pretraining with Group-Level Data Influence Modeling</title>
      <link>http://arxiv.org/abs/2502.14709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Group-Level Data Influence Modeling (Group-MATES) 的新方法，用于高效的数据预训练。这种方法通过收集数据集对预训练模型的群体级影响，并利用关系加权聚合的个体影响力来优化群体级别的数据效用。&lt;h4&gt;背景&lt;/h4&gt;数据高效的预训练在提升缩放规律方面展示了巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，能够更有效地进行数据预训练，特别是在群组级别而不是独立数据点上优化数据的使用效率。&lt;h4&gt;方法&lt;/h4&gt;Group-MATES 方法包括：收集群体级别的影响力，通过本地探测预训练模型来获得；随后微调一个关系性数据影响模型以近似这些群体级影响力，并选择具有最大预测群体级影响力的子集数据。该过程还采用影响力感知聚类技术，以便更高效地进行推断。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，Group-MATES 方法在22个下游任务上比DCLM-Baseline提高了10%的相对核心评分，比基于个体影响的方法提高5%，确立了新的状态-of-the-art。&lt;h4&gt;结论&lt;/h4&gt;关系性数据影响模型能够有效地捕捉到数据点之间的复杂交互作用，从而提升预训练模型的效果和效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到数据高效预训练展现了巨大的潜力，提出一种新方法Group-Level Data Influence Modeling (Group-MATES)，该方法旨在通过收集和优化群组级别的数据效用来改进预训练过程。经过实验验证，这种方法在特定基准测试中表现出色，确立了新的最佳实践标准，并展示了捕捉复杂数据点交互的模型的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-efficient pretraining has shown tremendous potential to elevate scalinglaws. This paper argues that effective pretraining data should be curated atthe group level, treating a set of data points as a whole rather than asindependent contributors. To achieve that, we propose Group-Level DataInfluence Modeling (Group-MATES), a novel data-efficient pretraining methodthat captures and optimizes group-level data utility. Specifically, Group-MATEScollects oracle group-level influences by locally probing the pretraining modelwith data sets. It then fine-tunes a relational data influence model toapproximate oracles as relationship-weighted aggregations of individualinfluences. The fine-tuned model selects the data subset by maximizing itsgroup-level influence prediction, with influence-aware clustering to enableefficient inference. Experiments on the DCLM benchmark demonstrate thatGroup-MATES achieves a 10% relative core score improvement on 22 downstreamtasks over DCLM-Baseline and 5% over individual-influence-based methods,establishing a new state-of-the-art. Further analyses highlight theeffectiveness of relational data influence models in capturing intricateinteractions between data points.</description>
      <author>example@mail.com (Zichun Yu, Fei Peng, Jie Lei, Arnold Overwijk, Wen-tau Yih, Chenyan Xiong)</author>
      <guid isPermaLink="false">2502.14709v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>A Macro- and Micro-Hierarchical Transfer Learning Framework for Cross-Domain Fake News Detection</title>
      <link>http://arxiv.org/abs/2502.14403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;跨域假新闻检测旨在通过在不同领域之间转移知识来减轻领域的偏移，从而改善检测性能。&lt;h4&gt;背景&lt;/h4&gt;现有的方法是基于从源域到目标域的新闻内容和用户互动的知识迁移。然而，这些方法存在两个主要限制，阻碍了有效的知识传输及最优的假新闻检测性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的宏观和微观层级传递学习框架（MMHT），以解决现有方法在跨领域假新闻检测中的局限性。&lt;h4&gt;方法&lt;/h4&gt;{'微层级模块': '提出了一个用于从源域的新闻内容中区分事实相关和无关特征，从而改进目标领域的假新闻检测性能的微层级解构模块。', '宏观层级模块': '提出了一种基于不同领域之间常见用户共享行为生成参与度特征的宏观层级传递学习模块，以提高知识迁移的有效性。'}&lt;h4&gt;主要发现&lt;/h4&gt;通过在现实世界数据集上的广泛实验，证明了该框架显著优于现有基准。&lt;h4&gt;结论&lt;/h4&gt;提出的MMHT框架有效解决了跨域假新闻检测中的挑战，并展示了其优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714517&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-domain fake news detection aims to mitigate domain shift and improvedetection performance by transferring knowledge across domains. Existingapproaches transfer knowledge based on news content and user engagements from asource domain to a target domain. However, these approaches face two mainlimitations, hindering effective knowledge transfer and optimal fake newsdetection performance. Firstly, from a micro perspective, they neglect thenegative impact of veracity-irrelevant features in news content whentransferring domain-shared features across domains. Secondly, from a macroperspective, existing approaches ignore the relationship between userengagement and news content, which reveals shared behaviors of common usersacross domains and can facilitate more effective knowledge transfer. To addressthese limitations, we propose a novel macro- and micro- hierarchical transferlearning framework (MMHT) for cross-domain fake news detection. Firstly, wepropose a micro-hierarchical disentangling module to disentangleveracity-relevant and veracity-irrelevant features from news content in thesource domain for improving fake news detection performance in the targetdomain. Secondly, we propose a macro-hierarchical transfer learning module togenerate engagement features based on common users' shared behaviors indifferent domains for improving effectiveness of knowledge transfer. Extensiveexperiments on real-world datasets demonstrate that our framework significantlyoutperforms the state-of-the-art baselines.</description>
      <author>example@mail.com (Xuankai Yang, Yan Wang, Xiuzhen Zhang, Shoujin Wang, Huaxiong Wang, Kwok Yan Lam)</author>
      <guid isPermaLink="false">2502.14403v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Vision Foundation Models in Medical Image Analysis: Advances and Challenges</title>
      <link>http://arxiv.org/abs/2502.14584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;本文综述了视觉基础模型（VFMs）在医学图像分析中的适应性研究，特别关注领域适应、模型压缩和联邦学习的挑战。&lt;h4&gt;背景&lt;/h4&gt;随着Vision Foundation Models (VFMs)的发展，尤其是Vision Transformers(ViT)和Segment Anything Model(SAM)，医学影像分析领域取得了显著进展。这些模型展现了捕捉长距离依赖性和实现高泛化的卓越能力。&lt;h4&gt;目的&lt;/h4&gt;探讨将大型视觉基础模型适应于医学图像分割的挑战，并讨论最新的基于适配器的方法改进、知识蒸馏技术和多尺度上下文特征建模的发展，同时提出未来的研究方向。&lt;h4&gt;方法&lt;/h4&gt;本文回顾了VFMs在医学图像分割中的最新研究成果，重点关注领域适应、模型压缩和联邦学习的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;VFMs和其他新兴技术（如联邦学习和模型压缩）具有革新医学影像分析和增强临床应用的巨大潜力。论文强调了当前的研究方向，并指出了未来研究的关键领域。&lt;h4&gt;结论&lt;/h4&gt;该工作旨在提供一个全面的方法概述，为驱动医学图像分割领域的下一波创新提出关键建议。&lt;h4&gt;翻译&lt;/h4&gt;视觉基础模型在医疗影像分析中的快速发展，特别是在Vision Transformers和Segment Anything Model的应用，已引发了该领域的显著进步。这些模型展现出了捕捉长距离依赖关系及实现高泛化的出色能力。然而，将大型视觉基础模型应用于医学图像分析面临着诸如医学与自然图像之间的领域差异、有效适应策略的需求以及小型医疗数据集限制等挑战。本文综述了VFMs在医学图像分割中的最新研究进展，重点探讨了领域适应、模型压缩和联邦学习的挑战，并讨论了基于适配器的改进方法、知识蒸馏技术及多尺度上下文特征建模的发展趋势，同时提出了未来的潜在发展方向。我们的分析强调了VFMs及其他新兴如联邦学习和模型压缩的技术在革新医学影像分析与提高临床应用方面所具有的巨大潜力。本文旨在为当前的研究方法提供全面概述，并建议未来关键研究领域以驱动下一轮创新浪潮的到来。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of Vision Foundation Models (VFMs), particularly VisionTransformers (ViT) and Segment Anything Model (SAM), has sparked significantadvances in the field of medical image analysis. These models have demonstratedexceptional capabilities in capturing long-range dependencies and achievinghigh generalization in segmentation tasks. However, adapting these large modelsto medical image analysis presents several challenges, including domaindifferences between medical and natural images, the need for efficient modeladaptation strategies, and the limitations of small-scale medical datasets.This paper reviews the state-of-the-art research on the adaptation of VFMs tomedical image segmentation, focusing on the challenges of domain adaptation,model compression, and federated learning. We discuss the latest developmentsin adapter-based improvements, knowledge distillation techniques, andmulti-scale contextual feature modeling, and propose future directions toovercome these bottlenecks. Our analysis highlights the potential of VFMs,along with emerging methodologies such as federated learning and modelcompression, to revolutionize medical image analysis and enhance clinicalapplications. The goal of this work is to provide a comprehensive overview ofcurrent approaches and suggest key areas for future research that can drive thenext wave of innovation in medical image segmentation.</description>
      <author>example@mail.com (Pengchen Liang, Bin Pu, Haishan Huang, Yiwei Li, Hualiang Wang, Weibo Ma, Qing Chang)</author>
      <guid isPermaLink="false">2502.14584v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>SALTY: Explainable Artificial Intelligence Guided Structural Analysis for Hardware Trojan Detection</title>
      <link>http://arxiv.org/abs/2502.14116v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;硬件木马是在数字设计中由不可信供应链实体插入的恶意修改。这些木马可以导致信息泄露（例如MOLES木马）和拒绝服务等多样化的攻击向量。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效检测数字设计中的恶意修改的技术，特别是那些来自第三方知识产权供应商的设计。&lt;h4&gt;方法&lt;/h4&gt;提出了一个框架（SALTY），该框架使用新颖的图神经网络架构（利用跳跃知识机制生成初步预测）以及可解释的人工智能（XAI）方法进行后续处理来细化结果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，该方法能够达到98%的真实正样本率（TPR）和真实负样本率（TNR），在一系列标准基准测试中显著优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架有效解决了现有检测技术的可扩展性问题，并且大大减少了误报的数量。&lt;h4&gt;翻译&lt;/h4&gt;硬件木马是数字设计中的一种恶意修改，可能由不可信供应链中的实体插入。它们会导致信息泄露（例如MOLES木马）和拒绝服务等多样化的攻击向量。这些攻击在关键系统（如医疗保健和航空领域）中可能导致人员伤亡及巨大的经济损失。已经开发了几种技术来检测数字设计中的这类恶意修改，尤其是从第三方知识产权供应商获取的设计。然而，大多数方法存在可扩展性问题（由于评估过程中不合理的假设），并且会产生大量的误报。我们的框架（SALTY）通过使用一种基于跳跃知识机制的新型图神经网络架构生成初步预测，并且利用可解释人工智能(XAI)的方法进行细化处理来缓解这些问题。实验结果表明，该方法在一系列标准基准测试中实现了98%的真实正样本率(TPR)和真实负样本率(TNR)，显著优于现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hardware Trojans are malicious modifications in digital designs that can beinserted by untrusted supply chain entities. Hardware Trojans can give rise todiverse attack vectors such as information leakage (e.g. MOLES Trojan) anddenial-of-service (rarely triggered bit flip). Such an attack in criticalsystems (e.g. healthcare and aviation) can endanger human lives and lead tocatastrophic financial loss. Several techniques have been developed to detectsuch malicious modifications in digital designs, particularly for designssourced from third-party intellectual property (IP) vendors. However, mosttechniques have scalability concerns (due to unsound assumptions duringevaluation) and lead to large number of false positive detections (falsealerts). Our framework (SALTY) mitigates these concerns through the use of anovel Graph Neural Network architecture (using Jumping-Knowledge mechanism) forgenerating initial predictions and an Explainable Artificial Intelligence (XAI)approach for fine tuning the outcomes (post-processing). Experiments show 98%True Positive Rate (TPR) and True Negative Rate (TNR), significantlyoutperforming state-of-the-art techniques across a large set of standardbenchmarks.</description>
      <author>example@mail.com (Tanzim Mahfuz, Pravin Gaikwad, Tasneem Suha, Swarup Bhunia, Prabuddha Chakraborty)</author>
      <guid isPermaLink="false">2502.14116v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Extending the RANGE of Graph Neural Networks: Relaying Attention Nodes for Global Encoding</title>
      <link>http://arxiv.org/abs/2502.13797v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;RANGE是一个模型无关的框架，旨在解决图神经网络在处理长程相互作用时的信息瓶颈问题。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）被广泛应用于分子物理、社会科学和经济学等领域。然而，GNN本质上是局部性的，并且当用于模拟具有长程相互作用的大规模分子系统时容易产生信息流动瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决大规模分子系统的计算成本高以及模型扩展性差的问题。&lt;h4&gt;方法&lt;/h4&gt;RANGE采用基于注意力的聚合-广播机制，该机制能够显著减少过度压缩效应，并以几乎可以忽略不计的计算成本捕捉长程相互作用。此外，这是首次在虚拟节点消息传递中整合注意力机制、位置编码和正则化来动态扩展虚拟表示的方法。&lt;h4&gt;主要发现&lt;/h4&gt;RANGE框架不仅大幅提高了对大规模分子系统中的长程相互作用建模的能力，而且保持了较低的计算成本。&lt;h4&gt;结论&lt;/h4&gt;该研究为下一代机器学习力场奠定了基础，并提供了既准确又高效的长期互动模型。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）经常用于模拟分子物理、社会科学和经济学中类似图形系统中的多体相互作用。然而，GNN本质上是局部性的并且在信息传递时可能会遭遇瓶颈问题。特别是在大规模分子系统的建模过程中，分散力和局部电场变化会驱动结构上的集体性改变，这使得问题更为复杂。现有的解决方案面临着计算成本高、可扩展性差的挑战。我们提出了一种模型无关的方法——RANGE，它采用了基于注意力机制的聚合-广播方法，大幅度减少了信息过度压缩的问题，并以极低的成本实现了长程相互作用的有效捕捉。值得注意的是，RANGE是首个将位置编码和正则化与注意力相结合，从而动态扩展虚拟表示的虚拟节点消息传递实现方案。这项研究为下一代机器学习力场奠定了基础，提供了一种既准确又高效的对大规模分子系统中的长程互动进行建模的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are routinely used in molecular physics, socialsciences, and economics to model many-body interactions in graph-like systems.However, GNNs are inherently local and can suffer from information flowbottlenecks. This is particularly problematic when modeling large molecularsystems, where dispersion forces and local electric field variations drivecollective structural changes. Existing solutions face challenges related tocomputational cost and scalability. We introduce RANGE, a model-agnosticframework that employs an attention-based aggregation-broadcast mechanism thatsignificantly reduces oversquashing effects, and achieves remarkable accuracyin capturing long-range interactions at a negligible computational cost.Notably, RANGE is the first virtual-node message-passing implementation tointegrate attention with positional encodings and regularization to dynamicallyexpand virtual representations. This work lays the foundation fornext-generation of machine-learned force fields, offering accurate andefficient modeling of long-range interactions for simulating large molecularsystems.</description>
      <author>example@mail.com (Alessandro Caruso, Jacopo Venturin, Lorenzo Giambagli, Edoardo Rolando, Frank Noé, Cecilia Clementi)</author>
      <guid isPermaLink="false">2502.13797v2</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Multiscale Byte Language Models -- A Hierarchical Architecture for Causal Million-Length Sequence Modeling</title>
      <link>http://arxiv.org/abs/2502.14553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '字节构成了数字世界的基石，是多模态基础模型的潜在构建块。提出了Multiscale Byte Language Model (MBLM)，这是一种基于层次解码器堆栈、能够以全精度在单个GPU上使用5M字节上下文窗口进行训练的模型。', '背景': 'Byte语言模型（BLMs）最近出现，旨在克服分词问题，但字节流过长需要新的架构范式。MBLM是一个与模型无关的层次解码器堆栈，可以高效处理极长的字节序列并在生成效率上接近线性增长。', '目的': '介绍并评估Multiscale Byte Language Model (MBLM)，探讨其在视觉问答任务中的表现，并展示其适应各种数据表示的能力。', '方法': '通过Transformer和Mamba块对单模态和多模态任务进行全面性能测试，展示了混合架构的有效性。另外，首次评估了BLMs在视觉问答任务上的表现。', '主要发现': '尽管序列化图像且没有编码器，MBLM仅基于纯下一个令牌预测就可与专用的CNN-LSTM架构相匹配，后者具有指定分类头。', '结论': 'MBLM展示了强大的适应性，在集成各种数据表示（包括像素和图像文件流字节）方面表现出巨大潜力，这使其成为通用多模态基础模型的发展方向。'}&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到了Bytes在数字世界中的重要性，并介绍了Multiscale Byte Language Model (MBLM)，这种模型可以高效处理极长的序列数据并适用于视觉问答任务等多模态场景。研究结果表明，MBLM在生成效率上接近线性增长，且其表现可与复杂的CNN-LSTM架构相媲美。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bytes form the basis of the digital world and thus are a promising buildingblock for multimodal foundation models. Recently, Byte Language Models (BLMs)have emerged to overcome tokenization, yet the excessive length of bytestreamsrequires new architectural paradigms. Therefore, we present the Multiscale ByteLanguage Model (MBLM), a model-agnostic hierarchical decoder stack that allowstraining with context windows of $5$M bytes on single GPU in full modelprecision. We thoroughly examine MBLM's performance with Transformer and Mambablocks on both unimodal and multimodal tasks. Our experiments demonstrate thathybrid architectures are efficient in handling extremely long byte sequencesduring training while achieving near-linear generational efficiency. To thebest of our knowledge, we present the first evaluation of BLMs on visual Q\&amp;Atasks and find that, despite serializing images and the absence of an encoder,a MBLM with pure next token prediction can match custom CNN-LSTM architectureswith designated classification heads. We show that MBLMs exhibit strongadaptability in integrating diverse data representations, including pixel andimage filestream bytes, underlining their potential toward omnimodal foundationmodels. Source code is publicly available at:https://github.com/ai4sd/multiscale-byte-lm</description>
      <author>example@mail.com (Eric Egli, Matteo Manica, Jannis Born)</author>
      <guid isPermaLink="false">2502.14553v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Asymmetric Co-Training for Source-Free Few-Shot Domain Adaptation</title>
      <link>http://arxiv.org/abs/2502.14214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个针对源无标签领域自适应（SFFSDA）场景的不对称协同训练(ACT)方法，该方法旨在解决传统无监督域自适应在缺乏大量目标数据时表现不佳的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的无监督域自适应依赖于有标签的源数据的持续可用性。然而，在实际应用中获取大量的未标记目标数据是不现实的，因此需要寻求一种新的解决方案来克服这个限制。&lt;h4&gt;目的&lt;/h4&gt;提出了一种针对SFFSDA场景的有效方法，即不对称协同训练（ACT），通过该方法可以在少量有标签的目标数据的基础上对预训练模型进行适应性改进。&lt;h4&gt;方法&lt;/h4&gt;ACT方法首先采用弱强增强技术增加数据多样性。然后利用两步优化过程来训练目标模型：第一步优化标签平滑交叉熵损失、条件分布的熵以及反向熵损失，以提高模型区分能力并减少过拟合；第二步则通过最小化分类器确定性差异来降低输出空间中的冗余。&lt;h4&gt;主要发现&lt;/h4&gt;在四个基准上的广泛实验表明，所提出的ACT方法优于现有的源无标签领域自适应（SFUDA）方法和迁移学习技术。&lt;h4&gt;结论&lt;/h4&gt;使用少量的有标签目标数据调整预训练模型可以提供一种实用且可靠的方法来解决域自适应问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要提供了关于如何克服传统无监督域自适应方法依赖大量未标记目标数据的问题，提出了一种新的源无标签领域自适应（SFFSDA）方法。该方法通过不对称协同训练技术在少量有标签的目标数据基础上优化预训练模型性能，并展示了优于现有方法的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Source-free unsupervised domain adaptation (SFUDA) has gained significantattention as an alternative to traditional unsupervised domain adaptation(UDA), which relies on the constant availability of labeled source data.However, SFUDA approaches come with inherent limitations that are frequentlyoverlooked. These challenges include performance degradation when the unlabeledtarget data fails to meet critical assumptions, such as having a closed-setlabel distribution identical to that of the source domain, or when sufficientunlabeled target data is unavailable-a common situation in real-worldapplications. To address these issues, we propose an asymmetric co-training(ACT) method specifically designed for the SFFSDA scenario. SFFSDA presents amore practical alternative to SFUDA, as gathering a few labeled targetinstances is more feasible than acquiring large volumes of unlabeled targetdata in many real-world contexts. Our ACT method begins by employing aweak-strong augmentation to enhance data diversity. Then we use a two-stepoptimization process to train the target model. In the first step, we optimizethe label smoothing cross-entropy loss, the entropy of the class-conditionaldistribution, and the reverse-entropy loss to bolster the model'sdiscriminative ability while mitigating overfitting. The second step focuses onreducing redundancy in the output space by minimizing classifier determinacydisparity. Extensive experiments across four benchmarks demonstrate thesuperiority of our ACT approach, which outperforms state-of-the-art SFUDAmethods and transfer learning techniques. Our findings suggest that adapting asource pre-trained model using only a small amount of labeled target dataoffers a practical and dependable solution. The code is available athttps://github.com/gengxuli/ACT.</description>
      <author>example@mail.com (Gengxu Li, Yuan Wu)</author>
      <guid isPermaLink="false">2502.14214v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Position: Graph Learning Will Lose Relevance Due To Poor Benchmarks</title>
      <link>http://arxiv.org/abs/2502.14546v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文摘要强调了在图学习应用于药物设计和分子属性预测方面的挑战，提出需要改进的基准测试方法以促进研究的进步。&lt;h4&gt;背景&lt;/h4&gt;机器学习在图上的应用显示出其在药物设计和分子性质预测中的潜力，但目前存在的大量基准测试问题阻碍了这些领域的进一步发展和相关性。&lt;h4&gt;目的&lt;/h4&gt;论文呼吁进行范式转变，采用更具意义的基准测试、严格的评估协议，并与领域专家加强合作，以推动有意义且可靠的图学习研究进展。&lt;h4&gt;方法&lt;/h4&gt;摘要中并未详细描述具体的方法论或实验过程。&lt;h4&gt;主要发现&lt;/h4&gt;当前的基准测试实践中倾向于关注狭窄的应用域如二维分子图，而不是更广泛和有影响力的应用领域。此外，许多基准数据集未能准确反映基础数据特征，导致抽象不充分且应用场景与实际脱节。&lt;h4&gt;结论&lt;/h4&gt;需要建立更加合理、更具代表性的基准体系来推动图学习技术在真实世界中的有效应用。&lt;h4&gt;翻译&lt;/h4&gt;虽然基于图的机器学习在药物设计和分子属性预测方面展现出了巨大潜力，但现有的基准测试挑战阻碍了其进一步的发展和实用性。当前的基准测试方法倾向于关注如二维分子图等狭窄领域，而不是更广泛且有影响力的应用领域，例如组合优化、关系数据库或芯片设计。此外，许多数据集未能准确反映实际基础数据特征，导致抽象不充分及应用场景与需求不符的问题加剧。这种碎片化的评估和对准确性过度重视的情况进一步促进了过拟合问题的出现，从而阻碍了通用性见解的发展。这些局限性已经阻止了真正有用的基础图模型的发展。这篇立场论文呼吁进行范式转变，采用更加有意义的基准测试标准、严格的评价流程，并与领域专家加强合作，以推动有影响力的和可靠的图学习研究进展，释放基于图的学习技术的巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While machine learning on graphs has demonstrated promise in drug design andmolecular property prediction, significant benchmarking challenges hinder itsfurther progress and relevance. Current benchmarking practices often lack focuson transformative, real-world applications, favoring narrow domains liketwo-dimensional molecular graphs over broader, impactful areas such ascombinatorial optimization, relational databases, or chip design. Additionally,many benchmark datasets poorly represent the underlying data, leading toinadequate abstractions and misaligned use cases. Fragmented evaluations and anexcessive focus on accuracy further exacerbate these issues, incentivizingoverfitting rather than fostering generalizable insights. These limitationshave prevented the development of truly useful graph foundation models. Thisposition paper calls for a paradigm shift toward more meaningful benchmarks,rigorous evaluation protocols, and stronger collaboration with domain expertsto drive impactful and reliable advances in graph learning research, unlockingthe potential of graph learning.</description>
      <author>example@mail.com (Maya Bechler-Speicher, Ben Finkelshtein, Fabrizio Frasca, Luis Müller, Jan Tönshoff, Antoine Siraudin, Viktor Zaverkin, Michael M. Bronstein, Mathias Niepert, Bryan Perozzi, Mikhail Galkin, Christopher Morris)</author>
      <guid isPermaLink="false">2502.14546v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Precise Geolocation Inference Capabilities of Vision Language Models</title>
      <link>http://arxiv.org/abs/2502.14412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2025 Workshop DATASAFE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;视觉语言模型（VLMs）的广泛应用引发了关于隐私的问题，尤其是在图像信息越来越容易获得的时代。这项研究专注于评估这些基础模型从之前未见过的图像数据中推断地理位置的能力。&lt;h4&gt;背景&lt;/h4&gt;随着视觉信息变得日益丰富和易于获取，视觉语言模型（Vision-Language Models, VLMs）的应用变得广泛起来，这引发了一系列关于隐私保护的问题。基础VLM模型虽然展现出了广博的知识和学习能力，但研究人员特别关注它们从新图像中推断地理位置的能力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在评估基础VLM模型在未见过的图像数据上进行地理位置推测的有效性，并探讨其对在线隐私可能带来的风险。&lt;h4&gt;方法&lt;/h4&gt;研究团队创建了一个基准数据集，该数据集是从Google Street View收集的数据，涵盖了全球范围内的地理分布。这些基础模型被用来测试单张图片地理位置推断的能力。此外，研究人员还评估了具有额外工具访问权限的VLM '代理'的表现，并观察到了最高30.6%的距离误差减少。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，现代的基础视觉语言模型在没有专门训练的情况下也能成为强大的图像地理定位工具；它们可以有效地从新图片中推断出地理位置信息。当这些模型变得越来越容易获取时，这给在线隐私带来了更大的挑战和风险。&lt;h4&gt;结论&lt;/h4&gt;尽管基础VLM具有作为高效图像地理定位工具的潜力，但研究人员强调了这对个人数据保护可能造成的潜在威胁，并提出了进一步研究的方向来缓解这些问题&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The prevalence of Vision-Language Models (VLMs) raises important questionsabout privacy in an era where visual information is increasingly available.While foundation VLMs demonstrate broad knowledge and learned capabilities, wespecifically investigate their ability to infer geographic location frompreviously unseen image data. This paper introduces a benchmark datasetcollected from Google Street View that represents its global distribution ofcoverage. Foundation models are evaluated on single-image geolocationinference, with many achieving median distance errors of &lt;300 km. We furtherevaluate VLM "agents" with access to supplemental tools, observing up to a30.6% decrease in distance error. Our findings establish that modern foundationVLMs can act as powerful image geolocation tools, without being specificallytrained for this task. When coupled with increasing accessibility of thesemodels, our findings have greater implications for online privacy. We discussthese risks, as well as future work in this area.</description>
      <author>example@mail.com (Neel Jay, Hieu Minh Nguyen, Trung Dung Hoang, Jacob Haimes)</author>
      <guid isPermaLink="false">2502.14412v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>SegAnyPET: Universal Promptable Segmentation from Positron Emission Tomography Images</title>
      <link>http://arxiv.org/abs/2502.14351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种专门用于PET图像分割的3D基础模型SegAnyPET，并通过大规模数据集PETS-5k验证了其性能。&lt;h4&gt;背景&lt;/h4&gt;正电子发射断层扫描（PET）成像在现代医学诊断中发挥重要作用，但PET图像的低对比度和边界模糊使其难以进行有效分割。现有的自然图像分割方法对于结构化的医疗影像表现出较差的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种专门针对PET图像的通用可提示分割基础模型，并解决其标注质量差异带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;构建了大规模PET图像分割数据集PETS-5k，包含超过1.3M张2D图像；提出SegAnyPET模型，采用交叉提示自信学习策略提高低质量和高质量标签之间的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，与现有基础模型和特定任务的监督模型相比，SegAnyPET在分割精度和泛化能力方面表现出更佳性能，仅使用少量提示点即可正确分割已知及未知目标。&lt;h4&gt;结论&lt;/h4&gt;作为首个专门针对PET图像的基础模型，SegAnyPET将推进分子成像下游任务的应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Positron Emission Tomography (PET) imaging plays a crucial role in modernmedical diagnostics by revealing the metabolic processes within a patient'sbody, which is essential for quantification of therapy response and monitoringtreatment progress. However, the segmentation of PET images presents uniquechallenges due to their lower contrast and less distinct boundaries compared toother structural medical modalities. Recent developments in segmentationfoundation models have shown superior versatility across diverse natural imagesegmentation tasks. Despite the efforts of medical adaptations, these worksprimarily focus on structural medical images with detailed physiologicalstructural information and exhibit poor generalization ability when adapted tomolecular PET imaging. In this paper, we collect and construct PETS-5k, thelargest PET segmentation dataset to date, comprising 5,731 three-dimensionalwhole-body PET images and encompassing over 1.3M 2D images. Based on theestablished dataset, we develop SegAnyPET, a modality-specific 3D foundationmodel for universal promptable segmentation from PET images. To issue thechallenge of discrepant annotation quality of PET images, we adopt a crossprompting confident learning (CPCL) strategy with an uncertainty-guidedself-rectification process to robustly learn segmentation from high-qualitylabeled data and low-quality noisy labeled data. Experimental resultsdemonstrate that SegAnyPET can correctly segment seen and unseen targets usingonly one or a few prompt points, outperforming state-of-the-art foundationmodels and task-specific fully supervised models with higher accuracy andstrong generalization ability for universal segmentation. As the firstfoundation model for PET images, we believe that SegAnyPET will advance theapplications to various downstream tasks for molecular imaging.</description>
      <author>example@mail.com (Yichi Zhang, Le Xue, Wenbo Zhang, Lanlan Li, Yuchen Liu, Chen Jiang, Yuan Cheng, Yuan Qi)</author>
      <guid isPermaLink="false">2502.14351v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>On the Trustworthiness of Generative Foundation Models: Guideline, Assessment, and Perspective</title>
      <link>http://arxiv.org/abs/2502.14296v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一套全面的框架，旨在解决生成式基础模型（GenFMs）在可信赖性方面面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;Generative Foundation Models (GenFMs) 作为变革性的工具出现，但其广泛应用引发了一系列关于信任度的重要问题。&lt;h4&gt;目的&lt;/h4&gt;通过系统地审查全球AI治理法规和政策、行业实践及标准，并提出一套整合了技术、伦理、法律和社会视角的指导原则来解决这些问题。&lt;h4&gt;方法&lt;/h4&gt;{'第一部分': '全面评估现有法律法规与行业标准，提出跨学科合作产生的指导原则。', '第二部分': '引入TrustGen平台，这是一个动态基准测试工具，用于从多个维度和模型类型中评估可信赖性。', '第三部分': '深入讨论当前挑战及未来的方向，强调实用性和可信度之间的复杂权衡，以及针对不同下游应用的考虑。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'TrustGen平台功能': '通过模块化组件实现灵活、迭代的评估方法，并揭示了在多个维度上可信赖性的进步和持续存在的挑战。', '未来方向': '论文指出了可信生成式基础模型在未来研究中的复杂性和演变性质。'}&lt;h4&gt;结论&lt;/h4&gt;该工作为推进GenAI领域的信任度提供了全面框架，为进一步的研究和应用奠定了坚实的基础，并公开了动态评估工具包以促进社区发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已包含英文翻译内容。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative Foundation Models (GenFMs) have emerged as transformative tools.However, their widespread adoption raises critical concerns regardingtrustworthiness across dimensions. This paper presents a comprehensiveframework to address these challenges through three key contributions. First,we systematically review global AI governance laws and policies fromgovernments and regulatory bodies, as well as industry practices and standards.Based on this analysis, we propose a set of guiding principles for GenFMs,developed through extensive multidisciplinary collaboration that integratestechnical, ethical, legal, and societal perspectives. Second, we introduceTrustGen, the first dynamic benchmarking platform designed to evaluatetrustworthiness across multiple dimensions and model types, includingtext-to-image, large language, and vision-language models. TrustGen leveragesmodular components--metadata curation, test case generation, and contextualvariation--to enable adaptive and iterative assessments, overcoming thelimitations of static evaluation methods. Using TrustGen, we reveal significantprogress in trustworthiness while identifying persistent challenges. Finally,we provide an in-depth discussion of the challenges and future directions fortrustworthy GenFMs, which reveals the complex, evolving nature oftrustworthiness, highlighting the nuanced trade-offs between utility andtrustworthiness, and consideration for various downstream applications,identifying persistent challenges and providing a strategic roadmap for futureresearch. This work establishes a holistic framework for advancingtrustworthiness in GenAI, paving the way for safer and more responsibleintegration of GenFMs into critical applications. To facilitate advancement inthe community, we release the toolkit for dynamic evaluation.</description>
      <author>example@mail.com (Yue Huang, Chujie Gao, Siyuan Wu, Haoran Wang, Xiangqi Wang, Yujun Zhou, Yanbo Wang, Jiayi Ye, Jiawen Shi, Qihui Zhang, Yuan Li, Han Bao, Zhaoyi Liu, Tianrui Guan, Dongping Chen, Ruoxi Chen, Kehan Guo, Andy Zou, Bryan Hooi Kuen-Yew, Caiming Xiong, Elias Stengel-Eskin, Hongyang Zhang, Hongzhi Yin, Huan Zhang, Huaxiu Yao, Jaehong Yoon, Jieyu Zhang, Kai Shu, Kaijie Zhu, Ranjay Krishna, Swabha Swayamdipta, Taiwei Shi, Weijia Shi, Xiang Li, Yiwei Li, Yuexing Hao, Yuexing Hao, Zhihao Jia, Zhize Li, Xiuying Chen, Zhengzhong Tu, Xiyang Hu, Tianyi Zhou, Jieyu Zhao, Lichao Sun, Furong Huang, Or Cohen Sasson, Prasanna Sattigeri, Anka Reuel, Max Lamparth, Yue Zhao, Nouha Dziri, Yu Su, Huan Sun, Heng Ji, Chaowei Xiao, Mohit Bansal, Nitesh V. Chawla, Jian Pei, Jianfeng Gao, Michael Backes, Philip S. Yu, Neil Zhenqiang Gong, Pin-Yu Chen, Bo Li, Xiangliang Zhang)</author>
      <guid isPermaLink="false">2502.14296v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Transfer-Prompting: Enhancing Cross-Task Adaptation in Large Language Models via Dual-Stage Prompts Optimization</title>
      <link>http://arxiv.org/abs/2502.14211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为Transfer-Prompting的新型框架，旨在改进大型语言模型（LLM）在不同任务之间的适应能力。&lt;h4&gt;背景&lt;/h4&gt;LLMs面临平衡生成连贯、相关且高质量响应与跨多种任务高效适应的重要挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种两阶段框架以增强提示生成过程中的跨任务适应性。&lt;h4&gt;方法&lt;/h4&gt;{'源提示构建': '通过在原始数据集上改进原始提示，创建具有更强泛化能力的源提示。', '目标提示生成': '通过对一组高分源提示进行微调，在特定于任务的数据集上增强目标提示的跨任务适应能力。', '反馈循环': '参考LLM根据历史提示-分数对和任务描述生成候选提示，并通过评分LLM使用多维度指标评估其有效性，从而形成一个促进持续改进的反馈回路。'}&lt;h4&gt;主要发现&lt;/h4&gt;在包括7个基础模型和18个专业化模型在内的25种不同LLMs上进行的广泛实验显示了Transfer-Prompting可以显著改善特定任务性能。&lt;h4&gt;结论&lt;/h4&gt;该框架对增强LLM中的跨任务适应性有潜在价值，并且代码已公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) face significant challenges when balancingmultiple high-level objectives, such as generating coherent, relevant, andhigh-quality responses while maintaining efficient task adaptation acrossdiverse tasks. To address these challenges, we introduce Transfer-Prompting, anovel two-stage framework designed to enhance cross-task adaptation in promptgeneration. The framework comprises two key components: (1) source promptconstruction, which refines the original prompts on source task datasets togenerate source prompts with enhanced generalization ability, and (2) targetprompt generation, which enhances cross-task adaptation of target prompts byfine-tuning a set of high-scored source prompts on task-specific datasets. Ineach optimization cycle, a reference LLM generates candidate prompts based onhistorical prompt-score pairs and task descriptions in our designed referenceprompt. These candidate prompts are refined iteratively, while a scorer LLMevaluates their effectiveness using the multi-dimensional metrics designed inthe objective prompts evaluator-a novel contribution in this work that providesa holistic evaluation of prompt quality and task performance. This feedbackloop facilitates continuous refinement, optimizing both prompt quality andtask-specific outcomes. We validate Transfer-Prompting through extensiveexperiments across 25 LLMs, including 7 foundational models and 18 specializedmodels, evaluated on 9 diverse datasets. The results demonstrate thatTransfer-Prompting significantly improves task-specific performance,highlighting its potential for enhancing cross-task adaptation in LLMs. Thecode is available at https://github.com/llm172/Transfer-Prompting.</description>
      <author>example@mail.com (Yupeng Chang, Yi Chang, Yuan Wu)</author>
      <guid isPermaLink="false">2502.14211v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Triad: Vision Foundation Model for 3D Magnetic Resonance Imaging</title>
      <link>http://arxiv.org/abs/2502.14064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的3D MRI视觉基础模型Triad，该模型采用自编码器架构从大量MRI数据集中学习鲁棒的表示，并通过器官无关的成像描述来约束语义分布。&lt;h4&gt;背景&lt;/h4&gt;现有的视觉基础模型主要针对CT图像进行了预训练，这使得它们在处理MRI特定应用时可能遇到性能和适应性问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种适用于3D MRI的新型视觉基础模型Triad，并评估其在多个下游任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;使用大规模MRI数据集（称为Triad-131K）对模型进行预训练，然后将其应用于多种下游任务并比较与未经过预训练的模型相比的表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在器官和成像模式一致的情况下，采用Triad预训练权重的模型在分割、分类和图像配准等任务上取得了显著性能提升。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了针对MRI数据进行预训练可以最大化下游任务中的表现，并为开发专用于医学影像领域的视觉基础模型提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models (VFMs) are pre-trained on extensive image datasetsto learn general representations for diverse types of data. These models cansubsequently be fine-tuned for specific downstream tasks, significantlyboosting performance across a broad range of applications. However, existingvision foundation models that claim to be applicable to various radiology tasksare mostly pre-trained on 3D computed tomography (CT), which benefits from theavailability of extensive 3D CT databases. Significant differences between CTand magnetic resonance imaging (MRI) in imaging principles, signalcharacteristics, and data distribution may hinder their practical performanceand versatility in MRI-specific applications. Here, we propose Triad, a visionfoundation model for 3D MRI. Triad adopts a widely used autoencoderarchitecture to learn robust representations from 131,170 3D MRI volumes anduses organ-independent imaging descriptions to constrain the semanticdistribution of the visual modality. The above pre-training dataset is calledTriad-131K, which is currently the largest 3D MRI pre-training dataset. Weevaluate Triad across three tasks, namely, organ/tumor segmentation,organ/cancer classification, and medical image registration, in two datamodalities (within-domain and out-of-domain) settings using 25 downstreamdatasets. By initializing models with Triad's pre-trained weights, nnUNet-Triadimproves segmentation performance by 6.88% compared to nnUNet-Scratch across 17datasets. Swin-B-Triad achieves a 3.97% improvement over Swin-B-Scratch inclassification tasks across five datasets. SwinUNETR-Triad improves by 4.00%compared to SwinUNETR-Scratch in registration tasks across two datasets. Ourstudy demonstrates that pre-training can maximize performance when the datamodalities and organs of upstream and downstream tasks are consistent.</description>
      <author>example@mail.com (Shansong Wang, Mojtaba Safari, Qiang Li, Chih-Wei Chang, Richard LJ Qiu, Justin Roper, David S. Yu, Xiaofeng Yang)</author>
      <guid isPermaLink="false">2502.14064v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Cognition and Explainability of Multimodal Foundation Models with Self-Synthesized Data</title>
      <link>http://arxiv.org/abs/2502.14044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025. Code: https://github.com/sycny/SelfSynthX&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一个新颖的视觉拒绝采样框架，利用自合成数据提升大型多模态模型（LMMs）的认知和可解释性。&lt;h4&gt;背景&lt;/h4&gt;大型多模态模型在广泛的任务中表现出色，但在细粒度视觉推理上存在困难，难以提供充分合理的预测解释。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来改进大型多模态模型的细粒度视觉推理能力及其对特定领域目标的理解和可解释性。&lt;h4&gt;方法&lt;/h4&gt;通过合成易于解读的答案，这些答案包含基于专家定义的概念的人类可验证的视觉特征。在每一轮微调后使用无奖励模型过滤机制选出最高质量的易解答案以进行下一次微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明该方法有效提高了特定视觉分类任务的准确性和可解释性。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架通过不断迭代的数据合成和微调，逐步提高大型多模态模型生成准确合理解释的能力。&lt;h4&gt;翻译&lt;/h4&gt;大规模多模态模型在一系列视觉任务中表现出色。然而，它们往往难以进行细粒度的视觉推理，并且无法提供合理的预测说明。为了解决这个问题，我们提出了一种新的基于自合成数据改进大模型认知能力和可解释性的视觉拒绝采样框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large multimodal models (LMMs) have shown impressive capabilities in a widerange of visual tasks. However, they often struggle with fine-grained visualreasoning, failing to identify domain-specific objectives and providejustifiable explanations for their predictions. To address this, we propose anovel visual rejection sampling framework to improve the cognition andexplainability of LMMs using self-synthesized data. Specifically, visualfine-tuning requires images, queries, and target answers. Our approach beginsby synthesizing interpretable answers that include human-verifiable visualfeatures. These features are based on expert-defined concepts, carefullyselected based on their alignment with the image content. After each round offine-tuning, we apply a reward model-free filtering mechanism to select thehighest-quality interpretable answers for the next round of tuning. Thisiterative process of data synthesis and fine-tuning progressively improves themodel's ability to generate accurate and reasonable explanations. Experimentalresults demonstrate the effectiveness of our method in improving both theaccuracy and explainability of specialized visual classification tasks.</description>
      <author>example@mail.com (Yucheng Shi, Quanzheng Li, Jin Sun, Xiang Li, Ninghao Liu)</author>
      <guid isPermaLink="false">2502.14044v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>A Method to Simultaneously Facilitate All Jet Physics Tasks</title>
      <link>http://arxiv.org/abs/2502.14652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;机器学习在喷射物理中发挥着关键作用，特别是在处理高维数据的复杂性方面。通过专门设计的机器学习模型进行特定任务训练后，可以改进所有其他喷射物理学任务的准确度、精确性和速度。&lt;h4&gt;背景&lt;/h4&gt;由于喷射具有复杂的高维度性质，人工无法全面分析其特性，而神经网络能够从整体上探索这些特性。&lt;h4&gt;目的&lt;/h4&gt;展示专门构建的机器学习模型在特定喷射分类任务上的训练可以提高所有其他喷射物理学任务的表现，并介绍OmniLearn方法作为一个基础模型应用于喷射物理领域。&lt;h4&gt;方法&lt;/h4&gt;通过使用特定多类生成和分类任务进行训练，然后将学到的表示用于不同类型的生成和分类任务、具有不同的探测器模拟数据集的任务、来自不同碰撞系统的喷射任务（pp与ep）、似然比估计以及异常检测中。&lt;h4&gt;主要发现&lt;/h4&gt;专门构建的机器学习模型可以提高所有其他喷射物理任务的表现，且OmniLearn方法作为一个通用的基础模型适用于需要高精度分析的情况。&lt;h4&gt;结论&lt;/h4&gt;OmniLearn方法作为一种基础模型在任何需要顶尖精确度的涉及喷射及其结构分析的应用中公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has become an essential tool in jet physics. Due to theircomplex, high-dimensional nature, jets can be explored holistically by neuralnetworks in ways that are not possible manually. However, innovations in allareas of jet physics are proceeding in parallel. We show that speciallyconstructed machine learning models trained for a specific jet classificationtask can improve the accuracy, precision, or speed of all other jet physicstasks. This is demonstrated by training on a particular multiclass generationand classification task and then using the learned representation for differentgeneration and classification tasks, for datasets with a different (full)detector simulation, for jets from a different collision system (pp versus ep),for generative models, for likelihood ratio estimation, and for anomalydetection. We consider, our OmniLearn approach thus as a jet-physics foundationmodel. It is made publicly available for use in any area where state-of-the-artprecision is required for analyses involving jets and their substructure.</description>
      <author>example@mail.com (Vinicius Mikuni, Benjamin Nachman)</author>
      <guid isPermaLink="false">2502.14652v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>SelfAge: Personalized Facial Age Transformation Using Self-reference Images</title>
      <link>http://arxiv.org/abs/2502.13987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于扩散模型的个性化面部年龄变换方法，旨在生成更接近个人实际年龄变化特征的人脸图像。&lt;h4&gt;背景&lt;/h4&gt;现有的深度学习方法虽然能够产生自然的老化效果，但无法准确反映个人因生活经历而产生的独特老化特征。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以利用少量自参考图片进行个性化训练的扩散模型，以实现更加个性化的面部年龄变换。&lt;h4&gt;方法&lt;/h4&gt;通过引入自我参照图像作为额外监督信息，对预训练的扩散模型进行微调，并设计有效的提示来提高效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在定量和定性评估中均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够更好地保留个人身份的同时实现更加自然且个性化的面部年龄变化。&lt;h4&gt;翻译&lt;/h4&gt;面部图像的年龄转换是一种编辑与年龄相关的人脸外观的技术，在保持个人识别性的前提下进行。现有的基于深度学习的方法可以再现自然的衰老过程；然而，它们只能再现平均化的过渡效果，而无法考虑到由于生活经历影响的独特个体特征。在本文中，我们提出了第一个基于扩散模型的个性化年龄变换方法。我们的扩散模型以面部图像和目标年龄作为输入，并生成经过年龄编辑后的面部图像输出。为了反映个人特定特征，我们将使用自我参照图片（即同一人的不同年龄段的照片）作为额外监督信息来微调预训练的扩散模型。我们还设计了一种有效的提示来增强年龄编辑效果和身份保存能力。实验结果表明，在定量与定性评估中，我们的方法都优于现有方法。代码及预训练模型可在 https://github.com/shiiiijp/SelfAge 查找。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Age transformation of facial images is a technique that edits age-relatedperson's appearances while preserving the identity. Existing deeplearning-based methods can reproduce natural age transformations; however, theyonly reproduce averaged transitions and fail to account for individual-specificappearances influenced by their life histories. In this paper, we propose thefirst diffusion model-based method for personalized age transformation. Ourdiffusion model takes a facial image and a target age as input and generates anage-edited face image as output. To reflect individual-specific features, weincorporate additional supervision using self-reference images, which arefacial images of the same person at different ages. Specifically, we fine-tunea pretrained diffusion model for personalized adaptation using approximately 3to 5 self-reference images. Additionally, we design an effective prompt toenhance the performance of age editing and identity preservation. Experimentsdemonstrate that our method achieves superior performance both quantitativelyand qualitatively compared to existing methods. The code and the pretrainedmodel are available at https://github.com/shiiiijp/SelfAge.</description>
      <author>example@mail.com (Taishi Ito, Yuki Endo, Yoshihiro Kanamori)</author>
      <guid isPermaLink="false">2502.13987v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>VB-Com: Learning Vision-Blind Composite Humanoid Locomotion Against Deficient Perception</title>
      <link>http://arxiv.org/abs/2502.14814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种复合框架VB-Com，该框架使类人机器人能够在感知不足的情况下决定何时依赖视觉策略和何时切换到盲策略。&lt;h4&gt;背景&lt;/h4&gt;腿足运动性能与状态观察的准确性和全面性密切相关。仅依靠本体感觉的盲策略被认为高度可靠，但限制了行走速度，并且经常需要通过碰撞地形来适应。相比之下，视觉策略允许机器人提前规划动作并积极应对未结构化的地形，但由于真实环境中的噪音、传感器故障以及当前模拟中动态或可变形地形的局限性，感知常常受到影响。&lt;h4&gt;目的&lt;/h4&gt;为了利用视觉策略和盲策略的优势，该研究旨在开发一种能够帮助类人机器人在感知不足的情况下做出决策的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为VB-Com的新框架，使类人机器人能够在动态或不可预测地形中进行导航时决定何时依赖于视觉信息，以及何时切换到仅使用本体感觉的策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VB-Com能够帮助类人机器人克服由动态环境或感知噪声引起的障碍，成功穿越具有挑战性的地形和障碍物。&lt;h4&gt;结论&lt;/h4&gt;通过结合视觉策略与盲策略的优点，VB-Com框架提供了一种更鲁棒、高效的解决方案来应对真实世界中的复杂挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The performance of legged locomotion is closely tied to the accuracy andcomprehensiveness of state observations. Blind policies, which rely solely onproprioception, are considered highly robust due to the reliability ofproprioceptive observations. However, these policies significantly limitlocomotion speed and often require collisions with the terrain to adapt. Incontrast, Vision policies allows the robot to plan motions in advance andrespond proactively to unstructured terrains with an online perception module.However, perception is often compromised by noisy real-world environments,potential sensor failures, and the limitations of current simulations inpresenting dynamic or deformable terrains. Humanoid robots, with high degreesof freedom and inherently unstable morphology, are particularly susceptible tomisguidance from deficient perception, which can result in falls or terminationon challenging dynamic terrains. To leverage the advantages of both vision andblind policies, we propose VB-Com, a composite framework that enables humanoidrobots to determine when to rely on the vision policy and when to switch to theblind policy under perceptual deficiency. We demonstrate that VB-Comeffectively enables humanoid robots to traverse challenging terrains andobstacles despite perception deficiencies caused by dynamic terrains orperceptual noise.</description>
      <author>example@mail.com (Junli Ren, Tao Huang, Huayi Wang, Zirui Wang, Qingwei Ben, Jiangmiao Pang, Ping Luo)</author>
      <guid isPermaLink="false">2502.14814v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Planning, scheduling, and execution on the Moon: the CADRE technology demonstration mission</title>
      <link>http://arxiv.org/abs/2502.14803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be presented at AAMAS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;NASA的CADRE任务计划于2025/2026年飞往月球Reiner Gamma地区，旨在演示多代理自主探索月球表面和次表层。该团队包括三台机器人和一个基站，将自主地在着陆器附近的一个区域内进行探索。&lt;h4&gt;背景&lt;/h4&gt;NASA的CADRE任务的目标是展示多个自治机器人如何协同工作来收集数据并绘制月球表面及其地下部分的地图。&lt;h4&gt;目的&lt;/h4&gt;演示多代理自主探索技术和分布式规划、调度与执行系统的功能。该系统确保在没有人类输入的情况下，机器人能够高效且安全地执行各种任务。&lt;h4&gt;方法&lt;/h4&gt;CADRE的软件架构基于一个新颖的自治、分布式的计划、调度和执行（PS&amp;E）系统。此系统采用集中式规划和分布式执行的概念，并利用选举领导者机制来增强系统的鲁棒性，确保在个别代理失效时仍能继续正常运作。&lt;h4&gt;主要发现&lt;/h4&gt;论文描述了CADRE PS&amp;E系统的架构、设计理由以及该系统在硬件上的验证与测试情况。&lt;h4&gt;结论&lt;/h4&gt;准备将PS&amp;E系统部署到月球上进行实际操作，并通过此次任务展示其有效性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; NASA's Cooperative Autonomous Distributed Robotic Exploration (CADRE)mission, slated for flight to the Moon's Reiner Gamma region in 2025/2026, isdesigned to demonstrate multi-agent autonomous exploration of the Lunar surfaceand sub-surface. A team of three robots and a base station will autonomouslyexplore a region near the lander, collecting the data required for 3Dreconstruction of the surface with no human input; and then autonomouslyperform distributed sensing with multi-static ground penetrating radars (GPR),driving in formation while performing coordinated radar soundings to create amap of the subsurface. At the core of CADRE's software architecture is a novelautonomous, distributed planning, scheduling, and execution (PS&amp;E) system. Thesystem coordinates the robots' activities, planning and executing tasks thatrequire multiple robots' participation while ensuring that each individualrobot's thermal and power resources stay within prescribed bounds, andrespecting ground-prescribed sleep-wake cycles. The system uses acentralized-planning, distributed-execution paradigm, and a leader electionmechanism ensures robustness to failures of individual agents. In this paper,we describe the architecture of CADRE's PS&amp;E system; discuss its designrationale; and report on verification and validation (V&amp;V) testing of thesystem on CADRE's hardware in preparation for deployment on the Moon.</description>
      <author>example@mail.com (Gregg Rabideau, Joseph Russino, Andrew Branch, Nihal Dhamani, Tiago Stegun Vaquero, Steve Chien, Jean-Pierre de la Croix, Federico Rossi)</author>
      <guid isPermaLink="false">2502.14803v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Humanoid-VLA: Towards Universal Humanoid Control with Visual Integration</title>
      <link>http://arxiv.org/abs/2502.14795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Humanoid-VLA框架，用于解决现有类人机器人控制框架在自主交互能力和数据稀缺性方面的局限性。该框架结合了语言理解、第一视角场景感知和运动控制。&lt;h4&gt;背景&lt;/h4&gt;当前的人形机器人控制框架主要依赖于反应机制，并且由于缺乏足够的数据而难以实现自主互动能力。&lt;h4&gt;目的&lt;/h4&gt;提出Humanoid-VLA框架，旨在通过整合多方面的能力来增强人形机器人的交互能力和环境适应性。&lt;h4&gt;方法&lt;/h4&gt;首先使用非第一视角的配有人类动作描述的数据集进行语言和运动的预对齐；然后引入参数高效的视频条件微调以结合第一视觉上下文；最后采用一种自监督数据增强策略生成伪注释，将原始运动序列转化为问题回答对。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，基于全身控制架构的人形机器人VLA框架能够执行对象交互和环境探索任务，并且具备更强的语境感知能力。&lt;h4&gt;结论&lt;/h4&gt;通过结合语言理解、场景感知及运动控制，Humanoid-VLA展示了更接近人类的表现，即能够进行适应性和智能性的互动，从而克服了当前人形机器人在自主性方面的限制。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文，上述内容为其对应中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the limitations of current humanoid robot controlframeworks, which primarily rely on reactive mechanisms and lack autonomousinteraction capabilities due to data scarcity. We propose Humanoid-VLA, a novelframework that integrates language understanding, egocentric scene perception,and motion control, enabling universal humanoid control. Humanoid-VLA beginswith language-motion pre-alignment using non-egocentric human motion datasetspaired with textual descriptions, allowing the model to learn universal motionpatterns and action semantics. We then incorporate egocentric visual contextthrough a parameter efficient video-conditioned fine-tuning, enablingcontext-aware motion generation. Furthermore, we introduce a self-superviseddata augmentation strategy that automatically generates pseudoannotationsdirectly derived from motion data. This process converts raw motion sequencesinto informative question-answer pairs, facilitating the effective use oflarge-scale unlabeled video data. Built upon whole-body control architectures,extensive experiments show that Humanoid-VLA achieves object interaction andenvironment exploration tasks with enhanced contextual awareness, demonstratinga more human-like capacity for adaptive and intelligent engagement.</description>
      <author>example@mail.com (Pengxiang Ding, Jianfei Ma, Xinyang Tong, Binghong Zou, Xinxin Luo, Yiguo Fan, Ting Wang, Hongchao Lu, Panzhong Mo, Jinxin Liu, Yuefan Wang, Huaicheng Zhou, Wenshuo Feng, Jiacheng Liu, Siteng Huang, Donglin Wang)</author>
      <guid isPermaLink="false">2502.14795v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Agent Coordination across Diverse Applications: A Survey</title>
      <link>http://arxiv.org/abs/2502.14743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 4 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文综述了多智能体系统（MAS）中的协调研究现状，通过回答四个基本的协调问题来提供统一的理解。&lt;h4&gt;背景&lt;/h4&gt;随着新兴应用和快速的人工智能发展，对多代理系统中趋势传播的基本机制的研究受到了越来越多的关注。&lt;h4&gt;目的&lt;/h4&gt;探索现有的协调思想和技术，并指出不同应用程序之间的联系以及未来的研究方向。&lt;h4&gt;方法&lt;/h4&gt;首先识别并分析了在各种应用程序中都至关重要的一般性协调问题。其次，综述了一系列的MAS应用案例。最后，分析和讨论了关于可扩展性、异质性和学习机制等开放挑战。&lt;h4&gt;主要发现&lt;/h4&gt;指出了分层与去中心化协调结合、人机协作以及基于大语言模型（LLM）的多智能体系统作为未来的有前景的研究方向。&lt;h4&gt;结论&lt;/h4&gt;通过统一的理解，明确了当前MAS协调研究的状态，并为未来提出了具有潜力的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-agent coordination studies the underlying mechanism enabling thetrending spread of diverse multi-agent systems (MAS) and has receivedincreasing attention, driven by the expansion of emerging applications andrapid AI advances. This survey outlines the current state of coordinationresearch across applications through a unified understanding that answers fourfundamental coordination questions: (1) what is coordination; (2) whycoordination; (3) who to coordinate with; and (4) how to coordinate. Ourpurpose is to explore existing ideas and expertise in coordination and theirconnections across diverse applications, while identifying and highlightingemerging and promising research directions. First, general coordinationproblems that are essential to varied applications are identified and analyzed.Second, a number of MAS applications are surveyed, ranging from widely studieddomains, e.g., search and rescue, warehouse automation and logistics, andtransportation systems, to emerging fields including humanoid andanthropomorphic robots, satellite systems, and large language models (LLMs).Finally, open challenges about the scalability, heterogeneity, and learningmechanisms of MAS are analyzed and discussed. In particular, we identify thehybridization of hierarchical and decentralized coordination, human-MAScoordination, and LLM-based MAS as promising future directions.</description>
      <author>example@mail.com (Lijun Sun, Yijun Yang, Qiqi Duan, Yuhui Shi, Chao Lyu, Yu-Cheng Chang, Chin-Teng Lin, Yang Shen)</author>
      <guid isPermaLink="false">2502.14743v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Performance Scores: Directed Functional Connectivity as a Brain-Based Biomarker for Motor Skill Learning and Retention</title>
      <link>http://arxiv.org/abs/2502.14731v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于脑电图（EEG）的定向功能连接性（dFC）作为新的生物标记物，用于评估运动技能学习和保持阶段。研究通过应用Fitts和Posner模型的不同阶段来展示dFC在神经机制中的作用，并展示了其在整个训练过程中及六周停训期后的稳定性和有效性。&lt;h4&gt;背景&lt;/h4&gt;传统的性能指标如执行时间和错误率对捕捉复杂的任务序列学习过程中的神经机制提供了有限的见解。这些指标难以深入理解技能习得和保持背后的认知变化。&lt;h4&gt;目的&lt;/h4&gt;引入基于EEG的dFC作为新的生物标记物，用以更好地评估运动技能的学习与保留情况，并提供对神经机制的新视角。&lt;h4&gt;方法&lt;/h4&gt;应用定向功能连接性（dFC）来映射Fitts和Posner模型的不同阶段，同时对比对照组，确保观察到的变化是由于训练而非其他因素引起的。&lt;h4&gt;主要发现&lt;/h4&gt;1. dFC能够有效地识别并追踪通过Fitts和Posner模型各个学习阶段的进展。2. 与传统方法相比，dFC捕捉到了神经信息流动的方向性和强度，提供了更全面的理解。3. 在六周停训期内，观察到dFC具有较高的稳定性，表明其在长期保持中的监测作用。4. 对照组未显示出显著变化，进一步确认了训练引起的特定神经适应性。&lt;h4&gt;结论&lt;/h4&gt;dFC作为一种强有力的生物标记物补充了传统的性能指标，对运动技能学习和保留提供了更深入的理解。它有助于个性化、靶向的训练协议的发展，特别是在外科教育等领域中至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容为中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motor skill acquisition in fields like surgery, robotics, and sports involveslearning complex task sequences through extensive training. Traditionalperformance metrics, like execution time and error rates, offer limited insightas they fail to capture the neural mechanisms underlying skill learning andretention. This study introduces directed functional connectivity (dFC),derived from electroencephalography (EEG), as a novel brain-based biomarker forassessing motor skill learning and retention. For the first time, dFC isapplied as a biomarker to map the stages of the Fitts and Posner motor learningmodel, offering new insights into the neural mechanisms underlying skillacquisition and retention. Unlike traditional measures, it captures both thestrength and direction of neural information flow, providing a comprehensiveunderstanding of neural adaptations across different learning stages. Theanalysis demonstrates that dFC can effectively identify and track theprogression through various stages of the Fitts and Posner model. Furthermore,its stability over a six-week washout period highlights its utility inmonitoring long-term retention. No significant changes in dFC were observed ina control group, confirming that the observed neural adaptations were specificto training and not due to external factors. By offering a granular view of thelearning process at the group and individual levels, dFC facilitates thedevelopment of personalized, targeted training protocols aimed at enhancingoutcomes in fields where precision and long-term retention are critical, suchas surgical education. These findings underscore the value of dFC as a robustbiomarker that complements traditional performance metrics, providing a deeperunderstanding of motor skill learning and retention.</description>
      <author>example@mail.com (Anil Kamat, Rahul Rahul, Lora Cavuoto, Harry Burke, Matthew Hackett, Jack Norfleet, Steven Schwaitzberg, Suvranu De)</author>
      <guid isPermaLink="false">2502.14731v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>CDGS: Confidence-Aware Depth Regularization for 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2502.14684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;3D高斯点阵（3DGS）在新颖视图合成中表现出色，但其几何准确性受限于缺乏明确的几何约束。本文提出了一种新的方法CDGS来增强3DGS。&lt;h4&gt;背景&lt;/h4&gt;3DGS在渲染速度和图像质量方面具有优势，但在三维重建中的几何精度受到限制。&lt;h4&gt;目的&lt;/h4&gt;通过引入一种基于深度正则化的信心感知方法（CDGS）以提高3DGS的几何细节保持能力和几何准确度。&lt;h4&gt;方法&lt;/h4&gt;使用多线索信心图来自单目深度估计和稀疏的结构从运动深度来适应性地调整优化过程中的深度监督。&lt;h4&gt;主要发现&lt;/h4&gt;在新颖视图合成的质量和几何精度方面都取得了竞争性的性能，特别是在训练早期阶段改善了细节保持能力，并且在Tanks and Temples基准数据集上的实验表明，该方法可以实现更稳定的收敛行为及更高的几何重建准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅提高了3DGS的效率和准确度，还可能为数字孪生创建、文化遗产保护或林业应用等现实世界中的高效和精确三维重建系统的发展提供帮助。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D高斯点阵（3DGS）在新颖视图合成中表现出显著的优势，特别是在实现高速渲染和高质量结果方面。然而，由于优化过程中缺乏明确的几何约束，其在三维重建中的几何准确性仍然有限。本文介绍了一种新的方法CDGS来增强3DGS。我们利用单目深度估计的多线索信心图以及稀疏结构从运动深度，在优化过程中自适应地调整深度监督。我们的方法展示了在训练早期阶段改善了细节保持能力，并且实现了新颖视图合成质量和几何精度方面的竞争性性能。在公开可用的Tanks and Temples基准数据集上的实验表明，该方法可以实现更稳定的收敛行为及更高的几何重建准确性，在PSNR方面提升了最多2.31 dB，而M3C2距离度量中的几何误差更低。值得注意的是，我们的方法仅用50%的训练迭代次数就达到了与原始3DGS相当的F分数。我们预计这项工作将有助于开发高效的三维重建系统用于现实世界的应用，如数字孪生创建、文化遗产保护或林业应用等。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) has shown significant advantages in novel viewsynthesis (NVS), particularly in achieving high rendering speeds andhigh-quality results. However, its geometric accuracy in 3D reconstructionremains limited due to the lack of explicit geometric constraints duringoptimization. This paper introduces CDGS, a confidence-aware depthregularization approach developed to enhance 3DGS. We leverage multi-cueconfidence maps of monocular depth estimation and sparse Structure-from-Motiondepth to adaptively adjust depth supervision during the optimization process.Our method demonstrates improved geometric detail preservation in earlytraining stages and achieves competitive performance in both NVS quality andgeometric accuracy. Experiments on the publicly available Tanks and Templesbenchmark dataset show that our method achieves more stable convergencebehavior and more accurate geometric reconstruction results, with improvementsof up to 2.31 dB in PSNR for NVS and consistently lower geometric errors inM3C2 distance metrics. Notably, our method reaches comparable F-scores to theoriginal 3DGS with only 50% of the training iterations. We expect this workwill facilitate the development of efficient and accurate 3D reconstructionsystems for real-world applications such as digital twin creation, heritagepreservation, or forestry applications.</description>
      <author>example@mail.com (Qilin Zhang, Olaf Wysocki, Steffen Urban, Boris Jutzi)</author>
      <guid isPermaLink="false">2502.14684v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Structure-from-Sherds++: Robust Incremental 3D Reassembly of Axially Symmetric Pots from Unordered and Mixed Fragment Collections</title>
      <link>http://arxiv.org/abs/2502.13986v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种用于重新组装多个轴对称陶器的高效方法，该方法基于逐片迭代注册技术，通过利用多图束搜索来探索多种注册路径，并过滤出无法区分的虚假匹配。&lt;h4&gt;背景&lt;/h4&gt;碎片化陶片重新组装对于文化遗产保护至关重要，但薄且锋利的断裂面导致大量错误匹配，使得大规模拼图解决变得困难。现有的全局方法在处理多重混杂时面临局部极小值和可扩展性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的重组成型方法，以克服现有技术挑战并提高轴对称陶器碎片重新组装的成功率。&lt;h4&gt;方法&lt;/h4&gt;受到基于多图像的三维重建结构从运动（SfM）方法启发，我们开发了一种基于逐片迭代注册的新方法Structure-from-Sherds++ (SfS++)。此方法通过探索多种可能的匹配路径来过滤错误匹配，并且不需要先验信息如底座或混合物体的数量。&lt;h4&gt;主要发现&lt;/h4&gt;在包含142个真实碎片和来自10种不同陶器的数据集上，我们的方法实现了87%的重新组装准确率，优于其他处理复杂裂纹图案和混杂数据的方法。&lt;h4&gt;结论&lt;/h4&gt;提出的SfS++方法展示了其在文化遗产保护中的潜力，特别是在处理混合轴对称陶器碎片时。它克服了现有技术的局限性，并且无需任何先验信息即可有效重新组装多个物体。&lt;h4&gt;翻译&lt;/h4&gt;重新组装破碎的具有轴向对称性的陶器对于文化遗迹保存极为重要，但由于这些陶器碎片薄而尖锐，容易产生大量误匹配，使得大规模拼图解决成为一项巨大挑战。现有的全局方法和数据驱动模型在处理复杂情况时易陷入局部最小值，并且面对多重混杂的数据集时可扩展性较差。受结构从运动(SfM)技术的启发，我们提出了一种基于逐片迭代注册的重新组装方法Structure-from-Sherds++ (SfS++)，能够有效过滤出无法区分的误匹配并同时重构多个陶器而不需任何先验信息。在包含142个真实碎片和来自十种不同陶器的数据集上，我们的方法实现了87%的成功率，优于其他处理复杂裂纹图案与混合数据的方法，并且达到了当前的最佳水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reassembling multiple axially symmetric pots from fragmentary sherds iscrucial for cultural heritage preservation, yet it poses significant challengesdue to thin and sharp fracture surfaces that generate numerous false positivematches and hinder large-scale puzzle solving. Existing global approaches,which optimize all potential fragment pairs simultaneously or data-drivenmodels, are prone to local minima and face scalability issues when multiplepots are intermixed. Motivated by Structure-from-Motion (SfM) for 3Dreconstruction from multiple images, we propose an efficient reassembly methodfor axially symmetric pots based on iterative registration of one sherd at atime, called Structure-from-Sherds++ (SfS++). Our method extends beyond simplereplication of incremental SfM and leverages multi-graph beam search to exploremultiple registration paths. This allows us to effectively filter outindistinguishable false matches and simultaneously reconstruct multiple potswithout requiring prior information such as base or the number of mixedobjects. Our approach achieves 87% reassembly accuracy on a dataset of 142 realfragments from 10 different pots, outperforming other methods in handlingcomplex fracture patterns with mixed datasets and achieving state-of-the-artperformance. Code and results can be found in our project pagehttps://sj-yoo.info/sfs/.</description>
      <author>example@mail.com (Seong Jong Yoo, Sisung Liu, Muhammad Zeeshan Arshad, Jinhyeok Kim, Young Min Kim, Yiannis Aloimonos, Cornelia Fermuller, Kyungdon Joo, Jinwook Kim, Je Hyeong Hong)</author>
      <guid isPermaLink="false">2502.13986v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>AlphaMaze: Enhancing Large Language Models' Spatial Intelligence via GRPO</title>
      <link>http://arxiv.org/abs/2502.14669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的两阶段训练框架，旨在为标准的大型语言模型（LLMs）赋予空间视觉推理能力，特别是在迷宫导航任务中表现出色。&lt;h4&gt;背景&lt;/h4&gt;尽管大模型在语言处理方面表现出色，但在需要真实的空间视觉推理的任务上存在困难。&lt;h4&gt;目的&lt;/h4&gt;通过一种创新的方法来增强现有语言模型的空间推理能力，特别是用于解决迷宫导航问题。&lt;h4&gt;方法&lt;/h4&gt;{'第一阶段': '使用监督微调（SFT）在包含标记化迷宫表示的数据集上训练模型以预测步骤指令', '第二阶段': '应用集团相对策略优化（GRPO），通过精心设计的奖励函数进一步提高模型的序列决策能力'}&lt;h4&gt;主要发现&lt;/h4&gt;{'基准测试结果': '基础模型无法导航迷宫，而SFT微调后的模型达到了86%的准确性', '增强效果': '进一步应用GRPO后，模型准确率提升至93%，显示出更稳健且自我纠正的空间推理能力'}&lt;h4&gt;结论&lt;/h4&gt;这项研究展示了将语言模型与视觉空间任务相结合的巨大潜力，并为机器人、自主导航等领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型在处理自然语言方面表现出色，但在需要真实空间视觉推理的任务中却表现不佳。本论文提出了一种创新的两阶段训练框架，旨在增强标准LLMs的空间视觉推理能力，特别是在迷宫导航任务上。该方法包括使用监督微调（SFT）和集团相对策略优化（GRPO），并在合成生成的迷宫实验中取得了86%至93%的准确率提升。研究结果表明，通过适当的技术改进，可以显著提高语言模型处理视觉空间问题的能力，并为机器人技术、自主导航等领域的应用提供了新的可能路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have demonstrated impressive capabilities inlanguage processing, yet they often struggle with tasks requiring genuinevisual spatial reasoning. In this paper, we introduce a novel two-stagetraining framework designed to equip standard LLMs with visual reasoningabilities for maze navigation. First, we leverage Supervised Fine Tuning (SFT)on a curated dataset of tokenized maze representations to teach the model topredict step-by-step movement commands. Next, we apply Group Relative PolicyOptimization (GRPO)-a technique used in DeepSeekR1-with a carefully craftedreward function to refine the model's sequential decision-making and encourageemergent chain-of-thought behaviors. Experimental results on syntheticallygenerated mazes show that while a baseline model fails to navigate the maze,the SFT-trained model achieves 86% accuracy, and further GRPO fine-tuningboosts accuracy to 93%. Qualitative analyses reveal that GRPO fosters morerobust and self-corrective reasoning, highlighting the potential of ourapproach to bridge the gap between language models and visual spatial tasks.These findings offer promising implications for applications in robotics,autonomous navigation, and other domains that require integrated visual andsequential reasoning.</description>
      <author>example@mail.com (Alan Dao, Dinh Bach Vu)</author>
      <guid isPermaLink="false">2502.14669v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Monocular Depth Estimation and Segmentation for Transparent Object with Iterative Semantic and Geometric Fusion</title>
      <link>http://arxiv.org/abs/2502.14616v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA(2025). The code is accessible through:  https://github.com/L-J-Yuan/MODEST&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种用于透明物体分割和深度估计的单目框架，该框架利用单一图像输入，并通过语义与几何融合模块及迭代策略优化预测结果。&lt;h4&gt;背景&lt;/h4&gt;透明物体的感知对于许多机器人任务至关重要。然而，由于其复杂的光学特性，准确地对透明物体进行分割并估算深度仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够在只使用单张图像输入的情况下，在透明对象的分割和深度估计方面表现卓越的方法。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新颖的语义与几何融合模块，有效整合了任务之间的多尺度信息，并采用迭代策略逐步优化初始特征以获得更清晰的结果。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该模型在两个具有挑战性的合成数据集和真实世界数据集中超越了现有的单目、立体以及多视角方法，改进幅度达到了约38.8%-46.2%。&lt;h4&gt;结论&lt;/h4&gt;提出的框架是第一个能够在单一图像输入下同时优化透明物体分割与深度估计的方法，并且其效果显著优于现有技术。&lt;h4&gt;翻译&lt;/h4&gt;透明物体感知对于许多机器人任务来说至关重要。然而，由于复杂的光学特性，准确地对透明物体进行分割并估算其深度仍然具有挑战性。现有的方法主要专注于单独的任务，使用额外的输入或专用传感器，忽略了任务之间的有价值交互以及后续精炼过程，导致预测结果模糊且不理想。为了解决这些问题，我们提出了一种单目框架，这是第一个在仅用单张图像作为输入的情况下，在透明物体分割和深度估计方面表现出色的方法。具体来说，我们设计了一个新颖的语义与几何融合模块，有效整合了多尺度信息之间的任务，并受到人类感知对象方式的启发，进一步采用了迭代策略，逐步优化初始特征以获得更清晰的结果。在两个具有挑战性的合成数据集和真实世界数据集中进行的实验表明，我们的模型超越了现有的单目、立体以及多视角方法，在只有单一RGB输入的情况下，性能提高了约38.8%-46.2%。相关代码和模型可在https://github.com/L-J-Yuan/MODEST公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transparent object perception is indispensable for numerous robotic tasks.However, accurately segmenting and estimating the depth of transparent objectsremain challenging due to complex optical properties. Existing methodsprimarily delve into only one task using extra inputs or specialized sensors,neglecting the valuable interactions among tasks and the subsequent refinementprocess, leading to suboptimal and blurry predictions. To address these issues,we propose a monocular framework, which is the first to excel in bothsegmentation and depth estimation of transparent objects, with only asingle-image input. Specifically, we devise a novel semantic and geometricfusion module, effectively integrating the multi-scale information betweentasks. In addition, drawing inspiration from human perception of objects, wefurther incorporate an iterative strategy, which progressively refines initialfeatures for clearer results. Experiments on two challenging synthetic andreal-world datasets demonstrate that our model surpasses state-of-the-artmonocular, stereo, and multi-view methods by a large margin of about38.8%-46.2% with only a single RGB input. Codes and models are publiclyavailable at https://github.com/L-J-Yuan/MODEST.</description>
      <author>example@mail.com (Jiangyuan Liu, Hongxuan Ma, Yuxin Guo, Yuhao Zhao, Chi Zhang, Wei Sui, Wei Zou)</author>
      <guid isPermaLink="false">2502.14616v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Real-world Troublemaker: A Novel Track Testing Framework for Automated Driving Systems in Safety-critical Interaction Scenarios</title>
      <link>http://arxiv.org/abs/2502.14574v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages,14 figures,2tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为Real-world Troublemaker的新型测试框架，用于生成对抗性目标对象运动轨迹，并促进被测车辆与环境之间的智能交互。&lt;h4&gt;背景&lt;/h4&gt;当前自动驾驶系统的轨道测试场景通常是固定的和有限的，这是由于物体控制方法缺乏灵活性以及缺乏智能化互动行为造成的。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够产生对抗性目标物运动轨迹并促进车辆与环境间智能互动的新框架，从而创建更加真实且动态的测试环境。&lt;h4&gt;方法&lt;/h4&gt;利用云控制系统远程动态地操控对象以模拟真实的交通场景，并引入游戏理论结构下的互动具体场景生成法来实现智能化交互。&lt;h4&gt;主要发现&lt;/h4&gt;在同济大学智能网联汽车测评基地成功实施了此框架，结果显示它能够准确有效地执行动态交互测试。与传统方法相比，Troublemaker提高了场景再现精度65.2%，增加了目标车辆互动策略的多样性大约9.2倍，并将无保护左转安全临界情景的曝光频率提高3.5倍。&lt;h4&gt;结论&lt;/h4&gt;Real-world Troublemaker框架克服了现有自动驾驶系统测试中物体控制和智能交互方面的局限性，提供了更准确、高效且多样的场景再现能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Track testing plays a critical role in the safety evaluation of autonomousdriving systems (ADS), as it provides real-world object targets and asafety-controllable interaction environment. However, existing track testingscenarios are often pre-fixed and limited, primarily due to the inflexibilityof object target control methods and the lack of intelligent interactivebehaviors. To overcome this limitation, we propose a novel track testingframework, Real-world Troublemaker, which can generate adversarial objecttarget motion trajectories and facilitate intelligent interactions with thevehicle under test (VUT), creating a more realistic and dynamic testingenvironment. To enable flexible motion trajectories, cloud-controlledtechnology is utilized to remotely and dynamically control object targets tocreate a realistic traffic environment. To achieve intelligent interactions, aninteractive concrete scenario generation method is introduced within agame-theoretic structure. The proposed framework has been successfullyimplemented at the Tongji University Intelligent Connected Vehicle EvaluationBase. Field test results demonstrate that Troublemaker can perform dynamicinteractive testing of ADS accurately and effectively. Compared to traditionaltrack testing methods, Troublemaker improves scenario reproduction accuracy by65.2\%, increases the diversity of target vehicle interaction strategies byapproximately 9.2 times, and enhances exposure frequency of safety-criticalscenarios by 3.5 times in unprotected left-turn scenarios.</description>
      <author>example@mail.com (Xinrui Zhang, Lu Xiong, Peizhi Zhang, Junpeng Huang, Yining Ma)</author>
      <guid isPermaLink="false">2502.14574v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>A Mobile Robotic Approach to Autonomous Surface Scanning in Legal Medicine</title>
      <link>http://arxiv.org/abs/2502.14514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted and accepted for presentation at CARS 2025. This preprint  has not undergone peer review or post-submission revisions. The final version  of this work will appear in the official CARS 2025 proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了一种移动机器人系统在法医学领域中的应用，该系统能够进行全身体表RGB-D扫描。&lt;h4&gt;背景&lt;/h4&gt;目前的法医文档记录主要依赖于手动操作，时间成本高且主观误差大。采用固定安装的机器人系统则需要大量空间和专用房间。&lt;h4&gt;目的&lt;/h4&gt;研究开发一种移动机器人系统用于尸体外部损伤的数字化文档记录，并评估其在实际应用中的有效性。&lt;h4&gt;方法&lt;/h4&gt;设计并实现了一种能够进行全身体表RGB-D扫描的移动机器人系统，通过实验室实验验证系统的环境配置参数及适用性。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，在三个特定位置上使用该系统可以达到94.96%的身体覆盖范围，并且在模拟和实际尸体上的表面覆盖率分别为96.90%±3.16%和92.45%±1.43%，证明了系统的有效性。&lt;h4&gt;结论&lt;/h4&gt;移动机器人系统能够有效支持法医学中的RGB-D扫描，有助于提高文档记录的效率和自动化程度，并减少手动干预的需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容：目的包括尸体内外部检查在内的全面法律医学文件记录通常由手动常规解剖过程中完成。特别地，外部伤口的数字化文档记录对于法医分析越来越重要。为此，引入了RGB表面扫描技术。然而，手持相机进行全表面扫描耗时且依赖操作者；而固定安装的机器人系统则需要大量空间和专用房间。因此，我们探讨了一种移动机器人系统的可行性用于尸体外层文档记录的方法开发：我们设计并实现了一个可全身RGB-D扫描的移动机器人系统，并通过实验室实验验证了其环境配置参数及实际应用效果。结果表明，在三个特定位置上的全身体表覆盖率为94.96%；模拟和真实尸体表面覆盖率分别为96.90±3.16%和92.45±1.43%，证明系统有效。结论：移动机器人系统的RGB-D扫描在法医领域显示出了极大的潜力，可以支持更高效的自动文档记录过程，并减少手动干预的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: Comprehensive legal medicine documentation includes both an internalbut also an external examination of the corpse. Typically, this documentationis conducted manually during conventional autopsy. A systematic digitaldocumentation would be desirable, especially for the external examination ofwounds, which is becoming more relevant for legal medicine analysis. For thispurpose, RGB surface scanning has been introduced. While a manual full surfacescan using a handheld camera is timeconsuming and operator dependent, floor orceiling mounted robotic systems require substantial space and a dedicated room.Hence, we consider whether a mobile robotic system can be used for externaldocumentation. Methods: We develop a mobile robotic system that enablesfull-body RGB-D surface scanning. Our work includes a detailed configurationspace analysis to identify the environmental parameters that need to beconsidered to successfully perform a surface scan. We validate our findingsthrough an experimental study in the lab and demonstrate the system'sapplication in a legal medicine environment. Results: Our configuration spaceanalysis shows that a good trade-off between coverage and time is reached withthree robot base positions, leading to a coverage of 94.96 %. Experimentsvalidate the effectiveness of the system in accurately capturing body surfacegeometry with an average surface coverage of 96.90 +- 3.16 % and 92.45 +- 1.43% for a body phantom and actual corpses, respectively. Conclusion: This workdemonstrates the potential of a mobile robotic system to automate RGB-D surfacescanning in legal medicine, complementing the use of post-mortem CT scans forinner documentation. Our results indicate that the proposed system cancontribute to more efficient and autonomous legal medicine documentation,reducing the need for manual intervention.</description>
      <author>example@mail.com (Sarah Grube, Sarah Latus, Martin Fischer, Vidas Raudonis, Axel Heinemann, Benjamin Ondruschka, Alexander Schlaefer)</author>
      <guid isPermaLink="false">2502.14514v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Watch Less, Feel More: Sim-to-Real RL for Generalizable Articulated Object Manipulation via Motion Adaptation and Impedance Control</title>
      <link>http://arxiv.org/abs/2502.14457v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种新的基于强化学习的流水线，该流水线装备了可变阻抗控制和利用观测历史进行运动适应的方法，专门用于通用化的关节对象操纵。&lt;h4&gt;背景&lt;/h4&gt;关节物体操作相对于刚性物体操作具有独特的挑战，因为物体本身代表了一个动态环境。传统的视觉数据（RGBD/点云）通常作为策略输入直接使用，但这种做法会增加仿真到现实的差距。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的强化学习流水线，旨在实现零样本模拟到真实场景转换中的平滑且灵巧的动作操作。&lt;h4&gt;方法&lt;/h4&gt;[{'减少对视觉数据依赖': '通过现成模块提取有用的低维数据来间接使用视觉数据特征'}, {'利用观测历史': '推断物体运动及其内在属性以减轻仿真与现实的差距'}, {'阻抗控制': '在模拟和真实环境中均采用阻抗控制'}]&lt;h4&gt;主要发现&lt;/h4&gt;[{'训练设置': '设计了一个具有良好随机化和专门奖励系统的训练环境，使多阶段、端到端操作成为可能而无需启发式运动规划'}, {'实验结果': '通过广泛的未见过物体的实验，在真实世界中实现了84%的成功率，据我们所知这是首次报告的结果'}]&lt;h4&gt;结论&lt;/h4&gt;我们的策略是首个在广泛的真实对象上实现高效关节操纵的成功案例。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新颖的方法来解决关节物体操作的独特挑战，并通过广泛的实验验证了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Articulated object manipulation poses a unique challenge compared to rigidobject manipulation as the object itself represents a dynamic environment. Inthis work, we present a novel RL-based pipeline equipped with variableimpedance control and motion adaptation leveraging observation history forgeneralizable articulated object manipulation, focusing on smooth and dexterousmotion during zero-shot sim-to-real transfer. To mitigate the sim-to-real gap,our pipeline diminishes reliance on vision by not leveraging the vision datafeature (RGBD/pointcloud) directly as policy input but rather extracting usefullow-dimensional data first via off-the-shelf modules. Additionally, weexperience less sim-to-real gap by inferring object motion and its intrinsicproperties via observation history as well as utilizing impedance control bothin the simulation and in the real world. Furthermore, we develop awell-designed training setting with great randomization and a specializedreward system (task-aware and motion-aware) that enables multi-staged,end-to-end manipulation without heuristic motion planning. To the best of ourknowledge, our policy is the first to report 84\% success rate in the realworld via extensive experiments with various unseen objects.</description>
      <author>example@mail.com (Tan-Dzung Do, Nandiraju Gireesh, Jilong Wang, He Wang)</author>
      <guid isPermaLink="false">2502.14457v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>An Efficient Ground-aerial Transportation System for Pest Control Enabled by AI-based Autonomous Nano-UAVs</title>
      <link>http://arxiv.org/abs/2502.14455v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;高效农作物生产需要早期检测害虫爆发并及时进行处理；本文提出了一种基于多架自主微型无人机（纳米UAV）的解决方案，用于视觉检测害虫，并由一辆较慢但功能强大的车辆运送处理物资。&lt;h4&gt;背景&lt;/h4&gt;农业生产中，及时发现和处理害虫爆发对于保证作物产量至关重要。然而，现有的方法在资源利用效率上存在不足。&lt;h4&gt;目的&lt;/h4&gt;设计一种基于纳米UAV的高效害虫监测与处理系统，以提高农作物生产的可持续性和经济效益。&lt;h4&gt;方法&lt;/h4&gt;['为应对纳米UAV上的极端限制（例如低分辨率传感器和计算能力），我们设计并优化了一个轻量级图像识别卷积神经网络(CNN)。该CNN在检测有害昆虫方面取得了0.79的平均精度(mAP)，同时减少了32倍的操作。', '为了处理田间意外障碍，采用了基于A*算法的全局+局部路径规划器。全局路径规划器确定纳米UAV的最佳飞行路线，而局部规划器可以达到50Hz的运行频率，通过调整近距离路径来防止碰撞。', '进行仿真实验，展示了一架25个纳米UAV组成的机队如何在200x200m的葡萄园中执行任务，并收集信息以优化拖拉机的最佳行进路线。']&lt;h4&gt;主要发现&lt;/h4&gt;['设计并实现了轻量级CNN，在低计算预算下，仍能实现高精度的害虫检测。', '提出了一种基于A*算法的路径规划方法，使纳米UAV能够避免障碍物，并高效完成飞行任务。', '实验表明，使用25架纳米UAV组成的机队可以比传统单一地面车辆节省高达20小时的工作时间。']&lt;h4&gt;结论&lt;/h4&gt;所提出的系统为农业生产提供了高效的害虫监测与处理方案，大幅提升了资源利用效率和作业速度。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3719210&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient crop production requires early detection of pest outbreaks andtimely treatments; we consider a solution based on a fleet of multipleautonomous miniaturized unmanned aerial vehicles (nano-UAVs) to visually detectpests and a single slower heavy vehicle that visits the detected outbreaks todeliver treatments. To cope with the extreme limitations aboard nano-UAVs,e.g., low-resolution sensors and sub-100 mW computational power budget, wedesign, fine-tune, and optimize a tiny image-based convolutional neural network(CNN) for pest detection. Despite the small size of our CNN (i.e., 0.58GOps/inference), on our dataset, it scores a mean average precision (mAP) of0.79 in detecting harmful bugs, i.e., 14% lower mAP but 32x fewer operationsthan the best-performing CNN in the literature. Our CNN runs in real-time at6.8 frame/s, requiring 33 mW on a GWT GAP9 System-on-Chip aboard a Crazyflienano-UAV. Then, to cope with in-field unexpected obstacles, we leverage aglobal+local path planner based on the A* algorithm. The global path plannerdetermines the best route for the nano-UAV to sweep the entire area, while thelocal one runs up to 50 Hz aboard our nano-UAV and prevents collision byadjusting the short-distance path. Finally, we demonstrate with in-simulatorexperiments that once a 25 nano-UAVs fleet has combed a 200x200 m vineyard,collected information can be used to plan the best path for the tractor,visiting all and only required hotspots. In this scenario, our efficienttransportation system, compared to a traditional single-ground vehicleperforming both inspection and treatment, can save up to 20 h working time.</description>
      <author>example@mail.com (Luca Crupi, Luca Butera, Alberto Ferrante, Alessandro Giusti, Daniele Palossi)</author>
      <guid isPermaLink="false">2502.14455v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>ChatVLA: Unified Multimodal Understanding and Robot Control with Vision-Language-Action Model</title>
      <link>http://arxiv.org/abs/2502.14420v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为ChatVLA的新框架，用于解决视觉-语言-行动模型(VLA)中的两项关键挑战：虚假遗忘和任务干扰。该框架通过分阶段对齐训练和专家混合架构来克服这些问题，并展示了在多模态理解和机器人操作方面的优越性能。&lt;h4&gt;背景&lt;/h4&gt;人类具有感知、理解并与物理世界互动的统一认知能力，而大型语言模型难以复制这种综合理解能力。&lt;h4&gt;目的&lt;/h4&gt;探讨现有视觉-语言-行动模型中的训练模式存在的问题并提出改进方案。&lt;h4&gt;方法&lt;/h4&gt;通过系统性地分析现有的VLA模型训练范式，识别了两个主要挑战：虚假遗忘和任务干扰。为解决这些问题，提出了一个称为ChatVLA的新框架，它包含分阶段对齐训练（Phased Alignment Training）以及专家混合架构(Mixture-of-Experts)。&lt;h4&gt;主要发现&lt;/h4&gt;ChatVLA在视觉问答数据集上表现出具有竞争力的性能，并且在多模态理解基准测试中显著超越了最先进的VLA方法。它以更加参数高效的架构设计，在MMMU和MMStar上的表现分别优于现有模型六倍和47.2%，并在25个实际机器人操作任务中超越了OpenVLA等现有的VLA方法。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了统一框架在实现强大的多模态理解和有效的机器人控制方面的潜力，这表明ChatVLA为这些目标提供了有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans possess a unified cognitive ability to perceive, comprehend, andinteract with the physical world. Why can't large language models replicatethis holistic understanding? Through a systematic analysis of existing trainingparadigms in vision-language-action models (VLA), we identify two keychallenges: spurious forgetting, where robot training overwrites crucialvisual-text alignments, and task interference, where competing control andunderstanding tasks degrade performance when trained jointly. To overcome theselimitations, we propose ChatVLA, a novel framework featuring Phased AlignmentTraining, which incrementally integrates multimodal data after initial controlmastery, and a Mixture-of-Experts architecture to minimize task interference.ChatVLA demonstrates competitive performance on visual question-answeringdatasets and significantly surpasses state-of-the-art vision-language-action(VLA) methods on multimodal understanding benchmarks. Notably, it achieves asix times higher performance on MMMU and scores 47.2% on MMStar with a moreparameter-efficient design than ECoT. Furthermore, ChatVLA demonstratessuperior performance on 25 real-world robot manipulation tasks compared toexisting VLA methods like OpenVLA. Our findings highlight the potential of ourunified framework for achieving both robust multimodal understanding andeffective robot control.</description>
      <author>example@mail.com (Zhongyi Zhou, Yichen Zhu, Minjie Zhu, Junjie Wen, Ning Liu, Zhiyuan Xu, Weibin Meng, Ran Cheng, Yaxin Peng, Chaomin Shen, Feifei Feng)</author>
      <guid isPermaLink="false">2502.14420v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>OrchardDepth: Precise Metric Depth Estimation of Orchard Scene from Monocular Camera Images</title>
      <link>http://arxiv.org/abs/2502.14279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, Australasian Conference on Robotics and  Automation, ACRA, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;单目深度估计是机器人感知的基础任务，近年来随着更准确和稳健的神经网络模型的发展以及不同类型数据集的应用，单目深度估计在性能和效率方面有了显著提升。然而，大多数相关研究集中在特定领域内，特别是在户外场景中的基准测试主要针对城市环境以改善自主驾驶设备，这与果园/葡萄园等农业环境差异巨大。&lt;h4&gt;背景&lt;/h4&gt;单目深度估计是机器人感知中的基础任务，并且该领域的进步依赖于更准确和稳健的神经网络模型的发展以及不同类型数据集的应用。然而，现有的研究大多集中在特定领域内（如城市环境），缺乏针对果园或葡萄园等农业环境的研究。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有单目深度估计方法在果园/葡萄园环境中性能不足的问题，提出一种填补该领域的空白的解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新的重训练方法，通过监控稠密深度图和稀疏点之间的连贯正则化来改进训练结果。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的 OrchardDepth 方法显著提高了单目相机在果园环境中的度量深度估计性能，将 RMSE 从 1.5337 减少到了 0.6738。&lt;h4&gt;结论&lt;/h4&gt;该研究通过提出一个新的方法和新的数据集填补了现有的单目深度估计模型中关于农业环境的空白，并证明了其有效性和应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular depth estimation is a rudimentary task in robotic perception.Recently, with the development of more accurate and robust neural networkmodels and different types of datasets, monocular depth estimation hassignificantly improved performance and efficiency. However, most of theresearch in this area focuses on very concentrated domains. In particular, mostof the benchmarks in outdoor scenarios belong to urban environments for theimprovement of autonomous driving devices, and these benchmarks have a massivedisparity with the orchard/vineyard environment, which is hardly helpful forresearch in the primary industry. Therefore, we propose OrchardDepth, whichfills the gap in the estimation of the metric depth of the monocular camera inthe orchard/vineyard environment. In addition, we present a new retrainingmethod to improve the training result by monitoring the consistentregularization between dense depth maps and sparse points. Our method improvesthe RMSE of depth estimation in the orchard environment from 1.5337 to 0.6738,proving our method's validation.</description>
      <author>example@mail.com (Zhichao Zheng, Henry Williams, Bruce A MacDonald)</author>
      <guid isPermaLink="false">2502.14279v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Mem2Ego: Empowering Vision-Language Models with Global-to-Ego Memory for Long-Horizon Embodied Navigation</title>
      <link>http://arxiv.org/abs/2502.14254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近，在大型语言模型（LLMs）和视觉-语言模型（VLMs）方面的进展使它们成为具身导航的强大工具，使得代理能够利用常识和空间推理来在不熟悉的环境中高效探索。&lt;h4&gt;背景&lt;/h4&gt;现有的基于LLM的方法将全局记忆，如语义或拓扑地图转换为语言描述以指导导航。这种方法提高了效率并减少了冗余的探索，但是用语言表示方式丢失了几何信息，这阻碍了复杂的环境中的空间推理。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于视觉-语言模型（VLM）的导航框架来解决这些问题，该框架通过从全局记忆模块中自适应检索任务相关的线索，并将其与代理的第一人称观察相结合，从而增强长期任务中的空间推理和决策制定。&lt;h4&gt;方法&lt;/h4&gt;利用动态对齐全局上下文信息与局部感知的技术来提高空间推理和决策的效率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在对象导航任务中超越了以前最先进的方法，并为具身导航提供了一个更有效和可扩展的解决方案。&lt;h4&gt;结论&lt;/h4&gt;新的VLM框架通过结合全局记忆信息与第一人称视觉输入的优点，在复杂的导航环境中实现了更加高效和精准的空间推理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Large Language Models (LLMs) and Vision-LanguageModels (VLMs) have made them powerful tools in embodied navigation, enablingagents to leverage commonsense and spatial reasoning for efficient explorationin unfamiliar environments. Existing LLM-based approaches convert globalmemory, such as semantic or topological maps, into language descriptions toguide navigation. While this improves efficiency and reduces redundantexploration, the loss of geometric information in language-basedrepresentations hinders spatial reasoning, especially in intricateenvironments. To address this, VLM-based approaches directly processego-centric visual inputs to select optimal directions for exploration.However, relying solely on a first-person perspective makes navigation apartially observed decision-making problem, leading to suboptimal decisions incomplex environments. In this paper, we present a novel vision-language model(VLM)-based navigation framework that addresses these challenges by adaptivelyretrieving task-relevant cues from a global memory module and integrating themwith the agent's egocentric observations. By dynamically aligning globalcontextual information with local perception, our approach enhances spatialreasoning and decision-making in long-horizon tasks. Experimental resultsdemonstrate that the proposed method surpasses previous state-of-the-artapproaches in object navigation tasks, providing a more effective and scalablesolution for embodied navigation.</description>
      <author>example@mail.com (Lingfeng Zhang, Yuecheng Liu, Zhanguang Zhang, Matin Aghaei, Yaochen Hu, Hongjian Gu, Mohammad Ali Alomrani, David Gamaliel Arcos Bravo, Raika Karimi, Atia Hamidizadeh, Haoping Xu, Guowei Huang, Zhanpeng Zhang, Tongtong Cao, Weichao Qiu, Xingyue Quan, Jianye Hao, Yuzheng Zhuang, Yingxue Zhang)</author>
      <guid isPermaLink="false">2502.14254v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>No Minima, No Collisions: Combining Modulation and Control Barrier Function Strategies for Feasible Dynamical Collision Avoidance</title>
      <link>http://arxiv.org/abs/2502.14238v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了控制栅栏函数二次规划（CBF-QP）和动力学系统调制（Mod-DS）在实时安全关键反应控制系统中的应用，提出了结合两者优点的新方法。&lt;h4&gt;背景&lt;/h4&gt;CBF-QP适用于一般性控制仿射系统但会产生局部极小值；而Mod-DS可以减少甚至避免局部最小值，但在某些约束下难以实现最优解，并且只适用于完全驱动的系统。&lt;h4&gt;目的&lt;/h4&gt;揭示CBF-QP和Mod-DS之间的理论联系并提出一种结合两者优势的新方法来提高实时障碍物规避系统的性能。&lt;h4&gt;方法&lt;/h4&gt;通过数学证明正常调制动力学系统是CBF-QP的一种特殊情况，参考Mod-DS与CBF-QP之间存在一个连接的方程。基于此理论基础，提出了基于Mod的CBF-QP控制器。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的基于Mod的CBF-QP方法能够为控制仿射系统实现局部极小值免费的反应障碍物规避，并在模拟和真实世界实验中表现出了优于传统方法的效果。&lt;h4&gt;结论&lt;/h4&gt;结合CBF-QP与Mod-DS的方法可以有效地解决现有技术的问题，提高系统的安全性和性能。&lt;h4&gt;翻译&lt;/h4&gt;作为重要的实时安全关键响应控制技术，控制屏障函数二次规划(CBF-QPs)适用于一般的控制仿射系统，但会产生局部极小值，并不能确保达到目标。与此相反，动力学系统调制(Mod-DS)，包括常规、参考和在流形上的Mod-DS，可以实现具有很少甚至没有局部最小值的障碍物规避，但在最优地减少受约束与不受约束控制器输出之间的差异方面遇到困难，其应用仅限于完全驱动的系统。我们深入探讨了CBF-QP和Mod-DS的基础理论，并证明尽管它们来自不同的起源，常规Mod-DS是CBF-QP的一种特殊情况，而参考Mod-DS的解决方案通过一个方程与CBF-QP中的解存在数学联系。基于揭示出的CBF-QP和Mod-DS之间的理论联系，我们提出了参考Mod基CBF-QP和在流形上的Mod基CBF-QP控制器来结合这两种方法的优势，并为控制仿射系统实现局部最小值免费的反应障碍物规避。我们在模拟医院环境和使用Ridgeback完全驱动系统的实际世界实验中验证了我们的方法，同时也在Fetch机器人的欠驱动系统中进行了实验。在所有实验中，基于Mod的CBF-QP都超过了传统的CBF-QPs以及我们提出的最优约束执行的Mod-DS方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As prominent real-time safety-critical reactive control techniques, ControlBarrier Function Quadratic Programs (CBF-QPs) work for control affine systemsin general but result in local minima in the generated trajectories andconsequently cannot ensure convergence to the goals. Contrarily, Modulation ofDynamical Systems (Mod-DSs), including normal, reference, and on-manifoldMod-DS, achieve obstacle avoidance with few and even no local minima but havetrouble optimally minimizing the difference between the constrained and theunconstrained controller outputs, and its applications are limited tofully-actuated systems. We dive into the theoretical foundations of CBF-QP andMod-DS, proving that despite their distinct origins, normal Mod-DS is a specialcase of CBF-QP, and reference Mod-DS's solutions are mathematically connectedto that of the CBF-QP through one equation. Building on top of the unveiledtheoretical connections between CBF-QP and Mod-DS, reference Mod-based CBF-QPand on-manifold Mod-based CBF-QP controllers are proposed to combine thestrength of CBF-QP and Mod-DS approaches and realize local-minimum-freereactive obstacle avoidance for control affine systems in general. We validateour methods in both simulated hospital environments and real-world experimentsusing Ridgeback for fully-actuated systems and Fetch robots for underactuatedsystems. Mod-based CBF-QPs outperform CBF-QPs as well as the optimallyconstrained-enforcing Mod-DS approaches we proposed in all experiments.</description>
      <author>example@mail.com (Yifan Xue, Nadia Figueroa)</author>
      <guid isPermaLink="false">2502.14238v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Sampling-based Online Planning for Drone Interception</title>
      <link>http://arxiv.org/abs/2502.14231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICRA 2025. Supplementary video:  https://youtu.be/dDdshfEAZpg&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了动态环境中高速在线规划问题，提出了一种基于神经网络的采样式算法来解决时间最优轨迹生成、计算约束以及环境不确定性带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;在动态环境中，需要找到符合系统动力学的时间最优路径，并满足实时适应性的计算限制。同时还要考虑来自环境变化带来的不确定性影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够快速探索多种可能的不确定情况下的轨迹选择方法，解决无人机拦截问题中目标预测不完善和碰撞避免的问题。&lt;h4&gt;方法&lt;/h4&gt;采用采样为基础的在线规划算法结合神经网络推理技术来替代耗时的非线性路径优化过程。该算法可以平行生成多个潜在目标位置的轨迹，并评估这些轨迹的时间可达性以选择最优解。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的模拟和现实环境中的验证，证明了所提出方法具有高速率在线规划的能力以及在无结构场景中应对不可预测运动变化的良好适应性。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了利用神经网络辅助采样式算法的有效性和可行性，为动态环境中需要快速决策的任务提供了一种新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper studies high-speed online planning in dynamic environments. Theproblem requires finding time-optimal trajectories that conform to systemdynamics, meeting computational constraints for real-time adaptation, andaccounting for uncertainty from environmental changes. To address thesechallenges, we propose a sampling-based online planning algorithm thatleverages neural network inference to replace time-consuming nonlineartrajectory optimization, enabling rapid exploration of multiple trajectoryoptions under uncertainty. The proposed method is applied to the droneinterception problem, where a defense drone must intercept a target whileavoiding collisions and handling imperfect target predictions. The algorithmefficiently generates trajectories toward multiple potential target dronepositions in parallel. It then assesses trajectory reachability by comparingtraversal times with the target drone's predicted arrival time, ultimatelyselecting the minimum-time reachable trajectory. Through extensive validationin both simulated and real-world environments, we demonstrate our method'scapability for high-rate online planning and its adaptability to unpredictablemovements in unstructured settings.</description>
      <author>example@mail.com (Gilhyun Ryou, Lukas Lao Beyer, Sertac Karaman)</author>
      <guid isPermaLink="false">2502.14231v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Text and Vision: A Multi-View Text-Vision Registration Approach for Cross-Modal Place Recognition</title>
      <link>http://arxiv.org/abs/2502.14195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为Text4VPR的方法，用于通过多视图（360度）文本-视觉注册来识别地点。这种方法首次完全利用了语言描述而非单一视角的图像信息。&lt;h4&gt;背景&lt;/h4&gt;移动机器人需要先进的自然语言理解能力以准确地识别位置并执行任务如包裹递送。然而传统的视觉地方识别方法依赖于单视图视觉信息，无法解读人类的语言描述。&lt;h4&gt;目的&lt;/h4&gt;目的是通过提出Text4VPR来克服现有方法的局限性，该方法将文本和图像结合起来，并使用冻结版T5语言模型以及Sinkhorn算法进行处理，以解决基于文本的地方识别任务中的挑战。&lt;h4&gt;方法&lt;/h4&gt;Text4VPR在训练阶段强调单个文本-图像对之间的精确描述。它还使用了级联交叉注意力余弦匹配（CCCA）来解决内部文本和图像组的不一致，并实现了通过语言描述与图像进行精准地点匹配。&lt;h4&gt;主要发现&lt;/h4&gt;Text4VPR方法首次建立了基于文字到图片地方识别任务的一个稳健基线，达到了57%的第一名精度以及92%的前十名精度（在测试集内半径为5米的情况下），这表明从文本描述定位至图像不仅是可行的，还有进一步发展的巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;Text4VPR方法展示了将语言和视觉信息结合解决地方识别任务的有效性，并为未来研究提供了坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nuozimiaowu/Text4VPR&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile robots necessitate advanced natural language understandingcapabilities to accurately identify locations and perform tasks such as packagedelivery. However, traditional visual place recognition (VPR) methods relysolely on single-view visual information and cannot interpret human languagedescriptions. To overcome this challenge, we bridge text and vision byproposing a multiview (360{\deg} views of the surroundings) text-visionregistration approach called Text4VPR for place recognition task, which is thefirst method that exclusively utilizes textual descriptions to match a databaseof images. Text4VPR employs the frozen T5 language model to extract globaltextual embeddings. Additionally, it utilizes the Sinkhorn algorithm withtemperature coefficient to assign local tokens to their respective clusters,thereby aggregating visual descriptors from images. During the training stage,Text4VPR emphasizes the alignment between individual text-image pairs forprecise textual description. In the inference stage, Text4VPR uses the CascadedCross-Attention Cosine Alignment (CCCA) to address the internal mismatchbetween text and image groups. Subsequently, Text4VPR performs precisely placematch based on the descriptions of text-image groups. On Street360Loc, thefirst text to image VPR dataset we created, Text4VPR builds a robust baseline,achieving a leading top-1 accuracy of 57% and a leading top-10 accuracy of 92%within a 5-meter radius on the test set, which indicates that localization fromtextual descriptions to images is not only feasible but also holds significantpotential for further advancement, as shown in Figure 1.</description>
      <author>example@mail.com (Tianyi Shang, Zhenyu Li, Pengjie Xu, Jinwei Qiao, Gang Chen, Zihan Ruan, Weijun Hu)</author>
      <guid isPermaLink="false">2502.14195v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>REFLEX Dataset: A Multimodal Dataset of Human Reactions to Robot Failures and Explanations</title>
      <link>http://arxiv.org/abs/2502.14185v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted and to appear in the IEEE/ACM Conference on Human Robot  Interaction 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一个名为REFLEX的多模态数据集，该数据集记录了机器人在合作环境中因故障而向人类解释时引发的人类反应。&lt;h4&gt;背景&lt;/h4&gt;当前研究中缺乏对机器人出现故障及其后续解释过程中人类反应的系统性捕捉和分析。&lt;h4&gt;目的&lt;/h4&gt;为了促进对人机交互动态的研究，特别是针对初始失败、解释以及长期互动中的情感演变的探讨。&lt;h4&gt;方法&lt;/h4&gt;构建了一个丰富的数据集，包含了人类对于不同类型故障的反应，并且详细注释了不同的解释层次与策略变化。&lt;h4&gt;主要发现&lt;/h4&gt;该数据集为开发更加稳健、适应性和用户满意的机器人系统提供了支持，这些系统能够在面对如重复性失败等挑战时维持积极的人机合作关系。&lt;h4&gt;结论&lt;/h4&gt;通过提供丰富的人类对不同故障类型的反应注释数据，REFLEX促进了更深入地理解和改善人机交互的机制。&lt;h4&gt;翻译&lt;/h4&gt;这项工作介绍了REFLEX（机器人解释给人类以应对失败和人类表达）：一个全面的多模态数据集，捕捉了合作环境中因机器人故障而引起的人类反应以及后续解释。它旨在促进对人机互动动态的研究，并解决需要研究初始失败、解释及长期互动中这些情感变化的需求。通过提供丰富的注释数据来描述人类对于不同类型的失败、不同的解释层次和策略的变化的响应，该数据集有助于开发更加稳健、适应性更强且满足用户需求的机器人系统，在面对如重复故障等挑战时仍能保持与人类合作者之间的积极关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents REFLEX: Robotic Explanations to FaiLures and HumanEXpressions, a comprehensive multimodal dataset capturing human reactions torobot failures and subsequent explanations in collaborative settings. It aimsto facilitate research into human-robot interaction dynamics, addressing theneed to study reactions to both initial failures and explanations, as well asthe evolution of these reactions in long-term interactions. By providing rich,annotated data on human responses to different types of failures, explanationlevels, and explanation varying strategies, the dataset contributes to thedevelopment of more robust, adaptive, and satisfying robotic systems capable ofmaintaining positive relationships with human collaborators, even duringchallenges like repeated failures.</description>
      <author>example@mail.com (Parag Khanna, Andreas Naoum, Elmira Yadollahi, Mårten Björkman, Christian Smith)</author>
      <guid isPermaLink="false">2502.14185v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>ModSkill: Physical Character Skill Modularization</title>
      <link>http://arxiv.org/abs/2502.14140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新型技能学习框架ModSkill，该框架将复杂的全身运动分解为独立的身体部位的模块化技能。&lt;h4&gt;背景&lt;/h4&gt;人类动作高度多样和动态变化，对模仿学习算法提出了挑战，这些算法旨在泛化控制模拟角色的运动技能。先前的方法通常依赖于全身体控制器来追踪参考动作或统一的全身心态嵌入空间，但难以在更大的运动数据集中进行泛化和扩展。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够处理大规模多样化人体动作并能有效学习模块化技能的新框架。&lt;h4&gt;方法&lt;/h4&gt;引入了ModSkill框架，该框架包括一个技能模块化注意层，将策略观察转换为引导各身体部位低级控制器的模块化技能嵌入。同时提出了一种带有生成适应性采样的主动技能学习方法，使用大规模动作生成模型在挑战性的追踪场景中增强策略学习。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在精确全身影子动作跟踪方面优于现有方法，并且能够为各种目标驱动的任务提供可重复使用的技能嵌入。&lt;h4&gt;结论&lt;/h4&gt;ModSkill框架通过分解复杂的身体运动技能，提高了模仿学习算法的泛化能力，在处理大规模人体动作数据集时表现出了优越性。&lt;h4&gt;翻译&lt;/h4&gt;人类的动作非常多样和动态变化，这对旨在将运动技能泛化到模拟角色控制中的模仿学习算法提出了挑战。先前的方法通常依赖于一个通用的全身体控制器来追踪参考动作或统一的全身心态嵌入空间。然而，在更大规模的数据集中这些方法往往难以实现泛化和扩展。在这项工作中，我们介绍了一种新的技能学习框架ModSkill，它将复杂的全身体运动分解为独立的身体部位模块化的技能。我们的框架包括一个技能模块化注意层，该层处理策略观察并将其转换为引导各身体部位低级控制器的模块化技能嵌入。此外，我们还提出了一种结合生成适应性采样（Generative Adaptive Sampling）的主动技能学习方法，使用大规模动作生成模型在挑战性的追踪场景中增强策略学习。我们的研究结果表明，该框架通过分解成模块化的技能学习并利用生成采样技术，在精确全身影子动作跟踪方面超过了现有的方法，并且能够为多样化目标驱动的任务提供可重复使用的技能嵌入。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human motion is highly diverse and dynamic, posing challenges for imitationlearning algorithms that aim to generalize motor skills for controllingsimulated characters. Previous methods typically rely on a universal full-bodycontroller for tracking reference motion (tracking-based model) or a unifiedfull-body skill embedding space (skill embedding). However, these approachesoften struggle to generalize and scale to larger motion datasets. In this work,we introduce a novel skill learning framework, ModSkill, that decouples complexfull-body skills into compositional, modular skills for independent body parts.Our framework features a skill modularization attention layer that processespolicy observations into modular skill embeddings that guide low-levelcontrollers for each body part. We also propose an Active Skill Learningapproach with Generative Adaptive Sampling, using large motion generationmodels to adaptively enhance policy learning in challenging tracking scenarios.Our results show that this modularized skill learning framework, enhanced bygenerative sampling, outperforms existing methods in precise full-body motiontracking and enables reusable skill embeddings for diverse goal-driven tasks.</description>
      <author>example@mail.com (Yiming Huang, Zhiyang Dou, Lingjie Liu)</author>
      <guid isPermaLink="false">2502.14140v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Visual Servoing of Tendon-driven Continuum Robots</title>
      <link>http://arxiv.org/abs/2502.14092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于控制肌腱驱动连续机器人（TDCR）的新型混合视觉伺服系统（HVS）。该方法结合了图像基视觉伺服(IBVS)和深度学习基视觉伺服(DLBVS)，以克服单一方法的局限性，提高整体性能。&lt;h4&gt;背景&lt;/h4&gt;在处理动态、无结构环境中的问题时，传统的IBVS和DLBVS各有优缺点。IBVS具有更高的精度和较快的收敛速度，而DLBVS则对干扰有更强的鲁棒性，并且工作空间更大。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够根据需要平滑过渡于IBVS与DLBVS之间控制方法，以提高处理复杂环境的能力。&lt;h4&gt;方法&lt;/h4&gt;混合视觉伺服系统(HVS)结合了IBVS和DLBVS的优点，通过模拟实验和真实世界测试验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;HVS相较于单独使用DLBVS，在迭代时间、收敛速度、最终误差和性能平滑性方面均有所改进。同时保留了DLBVS在诸如遮挡、光照变化等挑战条件下的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;提出的混合视觉伺服系统能够有效应对复杂多变的环境，展示了比单独使用IBVS或DLBVS更好的综合性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文介绍了一种针对肌腱驱动连续机器人控制的新颖混合视觉伺服（HVS）方法。该HVS系统结合了基于图像的视觉伺服(IBVS)与基于深度学习的视觉伺服(DLBVS)，克服了各自方法的局限性，以提升整体性能。IBVS在特征丰富环境中提供了更高的精度和更快的收敛速度；而DLBVS则增强了对抗干扰的能力，并拥有更大的工作空间。通过使IBVS与DLBVS之间实现平滑转换，所提出的HVS确保了复杂、无结构环境中的有效控制。该方法的有效性已通过仿真及真实世界实验得到验证，展示了相较于单独使用DLBVS时，HVS在减少迭代时间、加快收敛速度、降低最终误差以及改善性能方面的优势，同时保持了DLBVS面对诸如遮挡、光照变化、驱动器噪声和物理冲击等挑战条件下的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel Hybrid Visual Servoing (HVS) approach forcontrolling tendon-driven continuum robots (TDCRs). The HVS system combinesImage-Based Visual Servoing (IBVS) with Deep Learning-Based Visual Servoing(DLBVS) to overcome the limitations of each method and improve overallperformance. IBVS offers higher accuracy and faster convergence in feature-richenvironments, while DLBVS enhances robustness against disturbances and offers alarger workspace. By enabling smooth transitions between IBVS and DLBVS, theproposed HVS ensures effective control in dynamic, unstructured environments.The effectiveness of this approach is validated through simulations andreal-world experiments, demonstrating that HVS achieves reduced iteration time,faster convergence, lower final error, and smoother performance compared toDLBVS alone, while maintaining DLBVS's robustness in challenging conditionssuch as occlusions, lighting changes, actuator noise, and physical impacts.</description>
      <author>example@mail.com (Rana Danesh, Farrokh Janabi-Sharifi, Farhad Aghili)</author>
      <guid isPermaLink="false">2502.14092v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>EfficientPose 6D: Scalable and Efficient 6D Object Pose Estimation</title>
      <link>http://arxiv.org/abs/2502.14061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于GDRNPP的快速且可扩展的姿态估计器集合，旨在实现实时应用中速度与精度之间的良好平衡。&lt;h4&gt;背景&lt;/h4&gt;在工业实时反馈应用场景（如质量控制和机器人操作）中，高准确度的姿态估计算法需求仍然非常重要。尽管目前有一些算法提高了姿态估计的速度和准确性，但在动态环境中实现高效计算能力和精确性的平衡仍面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于GDRNPP的快速、可扩展姿势估计算法集合，以满足或超越当前基准在准确性和鲁棒性方面的表现，特别是在实时场景中的效率-精度权衡问题上进行改进。&lt;h4&gt;方法&lt;/h4&gt;提出了AMIS算法来根据特定应用场景中推理时间和准确性之间的应用特定位平衡选择合适的模型。该研究展示了基于AMIS的模型选择在四个著名的基准数据集（LM-O、YCB-V、T-LESS和ITODD）上的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的AMIS方法可以在不同应用场景之间灵活调整，从而实现实时应用中速度与精度之间的良好平衡。&lt;h4&gt;结论&lt;/h4&gt;本文通过改进现有的姿态估计算法模型，并提出了新的AMIS方法来优化实时场景中的效率-准确性的权衡，为工业自动化和机器人技术等领域提供了更好的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In industrial applications requiring real-time feedback, such as qualitycontrol and robotic manipulation, the demand for high-speed and accurate poseestimation remains critical. Despite advances improving speed and accuracy inpose estimation, finding a balance between computational efficiency andaccuracy poses significant challenges in dynamic environments. Most currentalgorithms lack scalability in estimation time, especially for diversedatasets, and the state-of-the-art (SOTA) methods are often too slow. Thisstudy focuses on developing a fast and scalable set of pose estimators based onGDRNPP to meet or exceed current benchmarks in accuracy and robustness,particularly addressing the efficiency-accuracy trade-off essential inreal-time scenarios. We propose the AMIS algorithm to tailor the utilized modelaccording to an application-specific trade-off between inference time andaccuracy. We further show the effectiveness of the AMIS-based model choice onfour prominent benchmark datasets (LM-O, YCB-V, T-LESS, and ITODD).</description>
      <author>example@mail.com (Zixuan Fang, Thomas Pöllabauer, Tristan Wirth, Sarah Berkei, Volker Knauthe, Arjan Kuijper)</author>
      <guid isPermaLink="false">2502.14061v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Detecting Cadastral Boundary from Satellite Images Using U-Net model</title>
      <link>http://arxiv.org/abs/2502.11044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文利用深度学习方法，采用迁移学习训练具有ResNet34骨干网络的U-Net模型，通过三类语义分割（边界、农田和背景）来检测农地的土地权属界限。&lt;h4&gt;背景&lt;/h4&gt;土地管理中找到农地的土地权属界限是一个关键问题。使用卫星图像和无人机(UAV)图像进行该任务是必要的。&lt;h4&gt;目的&lt;/h4&gt;利用深度学习方法加速并简化从卫星和UAV图像中提取土地权属边界的流程。&lt;h4&gt;方法&lt;/h4&gt;采用迁移学习训练具有ResNet34骨干网络的U-Net模型，用于三类语义分割以检测土地权属边界。使用的类别包括“边界”，“农田”以及“背景”。&lt;h4&gt;主要发现&lt;/h4&gt;在伊朗农业地区的两张卫星图像上评估了模型性能，分别得到了88%，75%和81%的精确度、召回率及F值。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明该方法具有良好的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Finding the cadastral boundaries of farmlands is a crucial concern for landadministration. Therefore, using deep learning methods to expedite and simplifythe extraction of cadastral boundaries from satellite and unmanned aerialvehicle (UAV) images is critical. In this paper, we employ transfer learning totrain a U-Net model with a ResNet34 backbone to detect cadastral boundariesthrough three-class semantic segmentation: "boundary", "field", and"background". We evaluate the performance on two satellite images fromfarmlands in Iran using "precision", "recall", and "F-score", achieving highvalues of 88%, 75%, and 81%, respectively, which indicate promising results.</description>
      <author>example@mail.com (Neda Rahimpour Anaraki, Maryam Tahmasbi, Saeed Reza Kheradpisheh)</author>
      <guid isPermaLink="false">2502.11044v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
  <item>
      <title>Lost in Transcription, Found in Distribution Shift: Demystifying Hallucination in Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2502.12414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first two authors contributed equally as co-first authors. The  manuscript is 21 pages long and is a work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文探讨了大规模训练的语音基础模型在自动语音识别（ASR）任务中的性能评估挑战。&lt;h4&gt;背景&lt;/h4&gt;现有的传统评价指标如WER和CER无法有效反映转录质量，尤其是伪造输出检测方面的问题。这使得这些模型在诸如医疗、法律及航空等高风险领域中可能隐藏严重错误。&lt;h4&gt;目的&lt;/h4&gt;研究自动语音识别（ASR）模型中的hallucination现象，并引入HER来量化这一问题。&lt;h4&gt;方法&lt;/h4&gt;分析了20个不同的ASR模型，探究分布变化、模型大小和架构对HER的影响。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '高WER可能掩盖低HER，而低WER也可能隐藏危险的hallucinations。', '2': '对抗性合成噪声（如白噪音、音调偏移和时间拉伸）会增加HER。', '3': '分布变化与HER之间有强相关性（α = 0.91）。'}&lt;h4&gt;结论&lt;/h4&gt;建议在评估ASR模型时，不仅要考虑传统的WER等指标，还要结合新的HER指标来更全面地衡量性能，特别是在高风险领域中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech foundation models trained at a massive scale, both in terms of modeland data size, result in robust systems capable of performing multiple speechtasks, including automatic speech recognition (ASR). These models transcendlanguage and domain barriers, yet effectively measuring their performanceremains a challenge. Traditional metrics like word error rate (WER) andcharacter error rate (CER) are commonly used to evaluate ASR performance butoften fail to reflect transcription quality in critical contexts, particularlywhen detecting fabricated outputs. This phenomenon, known as hallucination, isespecially concerning in high-stakes domains such as healthcare, legal, andaviation, where errors can have severe consequences. In our work, we addressthis gap by investigating hallucination in ASR models. We examine how factorssuch as distribution shifts, model size, and model architecture influence thehallucination error rate (HER), a metric we introduce to quantifyhallucinations. Our analysis of 20 ASR models reveals \numinsights~keyinsights: (1) High WERs can mask low hallucination rates, while low WERs mayconceal dangerous hallucinations. (2) Synthetic noise, both adversarial andcommon perturbations like white noise, pitch shift, and time stretching,increase HER. (3) Distribution shift correlates strongly with HER ($\alpha =0.91$). Our findings highlight the importance of incorporating HER alongsidetraditional metrics like WER to better assess ASR model performance,particularly in high-stakes domains.</description>
      <author>example@mail.com (Hanin Atwany, Abdul Waheed, Rita Singh, Monojit Choudhury, Bhiksha Raj)</author>
      <guid isPermaLink="false">2502.12414v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised CP-UNet Framework for Denoising DAS Data with Decay Noise</title>
      <link>http://arxiv.org/abs/2502.13395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;分布式声学传感器(DAS)技术利用光纤电缆检测声信号，提供成本效益高且密集的监测能力。该技术具备多种优势，包括在极端条件下的耐受性、对电磁干扰的免疫性和精确探测能力。&lt;h4&gt;背景&lt;/h4&gt;DAS技术虽然具有诸多优点，但其信噪比(S/N)通常低于地震检波器，并且容易受到随机噪声、突发噪声、水平噪声和长周期噪声的影响。这些噪音可能会降低数据分析中反演和解释的质量。&lt;h4&gt;目的&lt;/h4&gt;为了改善DAS数据中的噪音问题，作者开发了一个基于上下文金字塔模块(Context-Pyramid-UNet, CP-UNet)的无监督学习(UL)网络模型，以抑制DAS数据中的突发噪声和随机噪声。&lt;h4&gt;方法&lt;/h4&gt;该CP-UNet模型利用了编码和解码过程中的Context Pyramid Module来提取特征并重构DAS数据。为了增强浅层与深层特征之间的连接性，在编码和解码部分加入了Connected Module(CM)。在训练过程中，用Layer Normalization(LN)代替常用的Batch Normalization(BN)，以加速模型的收敛速度，并防止梯度爆炸。&lt;h4&gt;主要发现&lt;/h4&gt;该研究提出的CP-UNet网络在二维合成数据和现场数据上都展示了出色的去噪性能，优于传统的去噪方法以及最新的无监督学习框架。&lt;h4&gt;结论&lt;/h4&gt;通过实验结果验证了基于上下文金字塔模块的无监督学习模型具有优秀的噪声抑制能力，能够有效提高DAS数据的质量。&lt;h4&gt;翻译&lt;/h4&gt;分布式声学传感器技术利用光纤电缆来检测声信号，并提供成本效益高、密度大的监测功能。虽然它具有许多优势，例如在极端条件下的抵抗力、对电磁干扰的免疫力以及准确的检测，但它通常表现出比地震检波器更低的信噪比(S/N)，并且容易受到各种噪声的影响，如随机噪声、不规则噪声、水平噪声和长周期噪声。这些减少的S/N可能会影响包含反演和解释的数据分析。虽然人工智能在去噪方面已经展示了出色的能力，但大多数现有方法依赖于监督学习并需要标签数据的支持。为了解决这一问题，我们开发了一个基于Context-Pyramid-UNet (CP-UNet)的无监督学习(UL)网络模型来抑制DAS数据中的不规则和随机噪声。该CP-UNet利用编码和解码过程中的上下文金字塔模块(Context Pyramid Module)提取特征并重构DAS数据。为了增强浅层与深层特征之间的连接性，我们在编码和解码部分加入了Connected Module (CM)。在训练过程中使用Layer Normalization (LN)替代常用的Batch Normalization (BN)，以加速模型的收敛速度，并防止梯度爆炸的发生。我们采用Huber损失作为我们的损失函数，其参数通过实验确定。该网络被应用于二维合成数据和现场数据上。与传统去噪方法以及最新无监督学习框架相比，所提出的去噪方法展示出了更好的噪声抑制性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Distributed acoustic sensor (DAS) technology leverages optical fiber cablesto detect acoustic signals, providing cost-effective and dense monitoringcapabilities. It offers several advantages including resistance to extremeconditions, immunity to electromagnetic interference, and accurate detection.However, DAS typically exhibits a lower signal-to-noise ratio (S/N) compared togeophones and is susceptible to various noise types, such as random noise,erratic noise, level noise, and long-period noise. This reduced S/N cannegatively impact data analyses containing inversion and interpretation. Whileartificial intelligence has demonstrated excellent denoising capabilities, mostexisting methods rely on supervised learning with labeled data, which imposesstringent requirements on the quality of the labels. To address this issue, wedevelop a label-free unsupervised learning (UL) network model based onContext-Pyramid-UNet (CP-UNet) to suppress erratic and random noises in DASdata. The CP-UNet utilizes the Context Pyramid Module in the encoding anddecoding process to extract features and reconstruct the DAS data. To enhancethe connectivity between shallow and deep features, we add a Connected Module(CM) to both encoding and decoding section. Layer Normalization (LN) isutilized to replace the commonly employed Batch Normalization (BN),accelerating the convergence of the model and preventing gradient explosionduring training. Huber-loss is adopted as our loss function whose parametersare experimentally determined. We apply the network to both the 2-D syntheticand filed data. Comparing to traditional denoising methods and the latest ULframework, our proposed method demonstrates superior noise reductionperformance.</description>
      <author>example@mail.com (Tianye Huang, Aopeng Li, Xiang Li, Jing Zhang, Sijing Xian, Qi Zhang, Mingkong Lu, Guodong Chen, Liangming Xiong, Xiangyun Hu)</author>
      <guid isPermaLink="false">2502.13395v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Multi-view Video-Pose Pretraining for Operating Room Surgical Activity Recognition</title>
      <link>http://arxiv.org/abs/2502.13883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的无校准多视角多模态预训练框架PreViPS，用于手术活动识别，该框架能够将不同摄像机视图下的2D姿态和视觉嵌入对齐。&lt;h4&gt;背景&lt;/h4&gt;理解复杂手术室中临床医生与环境的交互需要深入理解外科程序的工作流程。现有的手术活动识别（SAR）模型通常无法准确捕捉细微的动作变化或充分利用多视角信息，或者它们需要精确校准的多视图摄像机设置和高级点云处理。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需多相机标定即可有效进行视频姿态和视觉特征预训练的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为PreViPS的新框架。该模型采用CLIP风格的双编码器架构，一个用于处理视觉特性，另一个则负责人类姿态嵌入的生成。为了处理连续2D人体姿势坐标数据，引入了分词后的离散表示法将这些坐标转换为离散姿态嵌入，从而可以在双编码器框架中高效集成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在两个不同手术室数据集上的表现优于强基线模型，并且展示了其在多视图和单视图设置下的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究为复杂手术环境中的SAR任务提供了一种高效、实用的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;理解复杂的外科手术工作流程需要深入了解临床医生与其操作环境之间的交互作用。手术活动识别（SAR）是一项关键的计算机视觉任务，它从多视角摄像机记录中检测动作或阶段。现有的SAR模型往往无法准确捕捉细微的临床医生动作变化或多视角知识，或者它们需要精确校准的多视角摄像机设置和高级点云处理以获得更好的结果。在这项工作中，我们提出了一种新的无校准多视图多模态预训练框架PreViPS，该框架将不同摄像机视图下的2D姿态与视觉嵌入对齐。我们的模型采用了CLIP风格的双编码器架构：一个编码器处理视觉特征，另一个则用于编码人类姿势嵌入。为了处理连续的2D人体姿态坐标，我们引入了一种分词后的离散表示法，将连续的2D姿态坐标转换为离散的姿态嵌入，从而可以在双编码器框架中高效集成。为了弥合这两种模式之间的差距，我们提出了一些跨模态和同模态几何约束下的预训练目标，并采用掩码姿势令牌预测策略来增强表征学习能力。广泛的实验和消融研究表明，与强大的基线相比有所改进，并且在两个不同的手术室数据集上的数据效率测试进一步突显了该方法的有效性。我们强调这种方法对于多视图和单视图设置中的外科活动识别的益处，展示了其在复杂手术环境中的实际适用性。代码将在以下地址发布：https://github.com/CAMMA-public/PreViPS。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the workflow of surgical procedures in complex operating roomsrequires a deep understanding of the interactions between clinicians and theirenvironment. Surgical activity recognition (SAR) is a key computer vision taskthat detects activities or phases from multi-view camera recordings. ExistingSAR models often fail to account for fine-grained clinician movements andmulti-view knowledge, or they require calibrated multi-view camera setups andadvanced point-cloud processing to obtain better results. In this work, wepropose a novel calibration-free multi-view multi-modal pretraining frameworkcalled Multiview Pretraining for Video-Pose Surgical Activity RecognitionPreViPS, which aligns 2D pose and vision embeddings across camera views. Ourmodel follows CLIP-style dual-encoder architecture: one encoder processesvisual features, while the other encodes human pose embeddings. To handle thecontinuous 2D human pose coordinates, we introduce a tokenized discreterepresentation to convert the continuous 2D pose coordinates into discrete poseembeddings, thereby enabling efficient integration within the dual-encoderframework. To bridge the gap between these two modalities, we propose severalpretraining objectives using cross- and in-modality geometric constraintswithin the embedding space and incorporating masked pose token predictionstrategy to enhance representation learning. Extensive experiments and ablationstudies demonstrate improvements over the strong baselines, whiledata-efficiency experiments on two distinct operating room datasets furtherhighlight the effectiveness of our approach. We highlight the benefits of ourapproach for surgical activity recognition in both multi-view and single-viewsettings, showcasing its practical applicability in complex surgicalenvironments. Code will be made available at:https://github.com/CAMMA-public/PreViPS.</description>
      <author>example@mail.com (Idris Hamoud, Vinkle Srivastav, Muhammad Abdullah Jamal, Didier Mutter, Omid Mohareri, Nicolas Padoy)</author>
      <guid isPermaLink="false">2502.13883v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Toward Robust Non-Transferable Learning: A Survey and Benchmark</title>
      <link>http://arxiv.org/abs/2502.13593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对非可传输学习（NTL）进行了首次全面的综述，并提出了评估NTL性能和鲁棒性的基准测试NLTBench。&lt;h4&gt;背景&lt;/h4&gt;过去几十年的研究主要集中在提高模型泛化能力上，较少关注调节这种泛化。然而，不良对手可以利用模型在未经授权或有害数据上的泛化能力，这可能违反了模型伦理。&lt;h4&gt;目的&lt;/h4&gt;解决现有NTL方法中缺乏全面综述和系统性分析的不足，并提出首个评估NTL性能及鲁棒性的统一框架NLTBench。&lt;h4&gt;方法&lt;/h4&gt;文章首先介绍了NTL的任务设置、通用框架以及评价标准。随后，总结现有的NTL方法并重点讨论了这些方法在面对破坏非可传输机制的各种攻击时所面临的鲁棒性问题。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用NLTBench进行实验验证，揭示现有NTL方法的局限性，尤其是在抵御不同攻击方面的鲁棒性不足。&lt;h4&gt;结论&lt;/h4&gt;本文还探讨了NTL的实际应用、未来研究方向及挑战，并强调了在实现NTL时需要注意的问题和面临的挑战。&lt;h4&gt;翻译&lt;/h4&gt;过去几十年的研究主要集中在提高模型泛化能力上。但是，这种泛化能力也可能被不良对手利用来造成未经授权或有害数据的使用，从而违背伦理原则。为了解决这个问题，研究人员提出了非可传输学习（NTL）任务，即重塑深度学习模型的泛化能力。尽管已经提出许多方法，但目前仍缺乏全面的综述和系统性分析。因此，本文填补了这一空白，并介绍了首个评估NTL性能及鲁棒性的基准NLTBench，在这个统一框架下进行了详细的实验验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Over the past decades, researchers have primarily focused on improving thegeneralization abilities of models, with limited attention given to regulatingsuch generalization. However, the ability of models to generalize to unintendeddata (e.g., harmful or unauthorized data) can be exploited by maliciousadversaries in unforeseen ways, potentially resulting in violations of modelethics. Non-transferable learning (NTL), a task aimed at reshaping thegeneralization abilities of deep learning models, was proposed to address thesechallenges. While numerous methods have been proposed in this field, acomprehensive review of existing progress and a thorough analysis of currentlimitations remain lacking. In this paper, we bridge this gap by presenting thefirst comprehensive survey on NTL and introducing NTLBench, the first benchmarkto evaluate NTL performance and robustness within a unified framework.Specifically, we first introduce the task settings, general framework, andcriteria of NTL, followed by a summary of NTL approaches. Furthermore, weemphasize the often-overlooked issue of robustness against various attacks thatcan destroy the non-transferable mechanism established by NTL. Experimentsconducted via NTLBench verify the limitations of existing NTL methods inrobustness. Finally, we discuss the practical applications of NTL, along withits future directions and associated challenges.</description>
      <author>example@mail.com (Ziming Hong, Yongli Xiang, Tongliang Liu)</author>
      <guid isPermaLink="false">2502.13593v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Extending the RANGE of Graph Neural Networks: Relaying Attention Nodes for Global Encoding</title>
      <link>http://arxiv.org/abs/2502.13797v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;介绍了一种名为RANGE的新框架，该框架旨在解决图神经网络在处理大型分子系统时遇到的信息流瓶颈问题。&lt;h4&gt;背景&lt;/h4&gt;图神经网络(GNNs)被广泛应用于建模物理、社会科学和经济学中的多体相互作用。然而，在模拟大型分子系统的分散力和局部电场变化导致的集体结构变化方面，GNN存在局限性，这使得现有的解决方案在计算成本和可扩展性上面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出了一种模型无关的方法RANGE框架，以有效地捕捉长距离交互并提高处理大规模分子系统的能力。&lt;h4&gt;方法&lt;/h4&gt;该框架采用了基于注意力的聚合-广播机制，通过引入虚拟节点消息传递来动态地扩大表示，并在计算成本低的情况下显著减少信息流瓶颈问题。&lt;h4&gt;主要发现&lt;/h4&gt;RANGE是第一个将注意和位置编码以及正则化整合到虚拟节点消息传递中的实现方案。这使它能够在捕捉长程相互作用方面表现出色，同时保持较低的计算开销。&lt;h4&gt;结论&lt;/h4&gt;这项工作为下一代机器学习力场奠定了基础，能够准确而有效地模拟大规模分子系统的长距离交互。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）被常规地用于建模分子物理学、社会科学和经济学中的图形系统多体相互作用。然而，由于其固有的局部性，它们在信息流方面可能遭受瓶颈问题，特别是在建模大型分子系统时，这会驱动集体结构变化的分散力和局部电场的变化尤为严重。现有的解决方案面临计算成本及可扩展性的挑战。我们介绍了RANGE模型无关框架，该框架采用基于注意力机制的聚合广播机制，大大减少了信息压缩效应，并以几乎可以忽略不计的计算开销实现了对长程相互作用的精确捕获。值得注意的是，RANGE是首个将注意力机制与位置编码及正则化结合来动态扩展虚拟表示的虚拟节点消息传递实现方案。这项工作为下一代机器学习力场奠定了基础，提供了准确而高效的建模方式以模拟大型分子系统的长程交互。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are routinely used in molecular physics, socialsciences, and economics to model many-body interactions in graph-like systems.However, GNNs are inherently local and can suffer from information flowbottlenecks. This is particularly problematic when modeling large molecularsystems, where dispersion forces and local electric field variations drivecollective structural changes. Existing solutions face challenges related tocomputational cost and scalability. We introduce RANGE, a model-agnosticframework that employs an attention-based aggregation-broadcast mechanism thatsignificantly reduces oversquashing effects, and achieves remarkable accuracyin capturing long-range interactions at a negligible computational cost.Notably, RANGE is the first virtual-node message-passing implementation tointegrate attention with positional encodings and regularization to dynamicallyexpand virtual representations. This work lays the foundation fornext-generation of machine-learned force fields, offering accurate andefficient modeling of long-range interactions for simulating large molecularsystems.</description>
      <author>example@mail.com (Alessandro Caruso, Jacopo Venturin, Lorenzo Giambagli, Edoardo Rolando, Frank Noé, Cecilia Clementi)</author>
      <guid isPermaLink="false">2502.13797v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Machine Learning Performance through Intelligent Data Quality Assessment: An Unsupervised Data-centric Framework</title>
      <link>http://arxiv.org/abs/2502.13198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  42 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个智能数据为中心的评估框架，该框架能够识别高质量的数据并提高机器学习系统的性能。&lt;h4&gt;背景&lt;/h4&gt;由于数据量和复杂性的增加，现代数据更容易受到质量低下的影响。这导致在将数据输入到ML管道之前需要进行大量繁琐且耗时的工作来准备和改进数据。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一挑战，提出了一种智能的数据为中心的评估框架，用于识别高质量数据并提高机器学习系统的性能。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了质量测量的整理和无监督学习技术，能够区分高质量和低质量的数据。此外，该框架设计为具有灵活性和通用性，可以应用于各种领域和应用。&lt;h4&gt;主要发现&lt;/h4&gt;在实际案例中验证了所提出的框架的有效性，在分析化学领域的实验中，通过三个反义寡核苷酸数据集进行了测试，并咨询了相关领域的专家以确定相关的质量测量并评估框架的结果。结果表明该框架能够识别高质量数据的特性，从而指导高效的实验室实验进行，并提高机器学习系统的性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的质量为中心的数据评估框架能够在多种应用场景中有效提升数据质量和机器学习模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;低质量的数据限制了机器学习（ML）的优势并削弱了高性能的ML软件系统。由于数据量和复杂性的增加，现代数据更容易受到质量问题的影响。因此，在将数据输入到ML管道之前需要进行大量繁琐且耗时的工作来准备和改进数据。为了应对这一挑战，我们提出了一种智能的数据为中心的评估框架，该框架能够识别高质量数据并提高机器学习系统的性能。该框架结合了质量测量的整理和无监督学习技术以区分高质量和低质量的数据。此外，该框架设计为具有灵活性和通用性，可以应用于各种领域和应用。为了验证所提出的框架的效果，在分析化学领域的实验中进行了实际案例测试，并通过咨询相关专家评估结果。结果显示，基于数据质量的评估框架能够识别出高质量数据的特点，从而指导实验室高效的实验操作并提高机器学习系统的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Poor data quality limits the advantageous power of Machine Learning (ML) andweakens high-performing ML software systems. Nowadays, data are more prone tothe risk of poor quality due to their increasing volume and complexity.Therefore, tedious and time-consuming work goes into data preparation andimprovement before moving further in the ML pipeline. To address thischallenge, we propose an intelligent data-centric evaluation framework that canidentify high-quality data and improve the performance of an ML system. Theproposed framework combines the curation of quality measurements andunsupervised learning to distinguish high- and low-quality data. The frameworkis designed to integrate flexible and general-purpose methods so that it isdeployed in various domains and applications. To validate the outcomes of thedesigned framework, we implemented it in a real-world use case from the fieldof analytical chemistry, where it is tested on three datasets of anti-senseoligonucleotides. A domain expert is consulted to identify the relevant qualitymeasurements and evaluate the outcomes of the framework. The results show thatthe quality-centric data evaluation framework identifies the characteristics ofhigh-quality data that guide the conduct of efficient laboratory experimentsand consequently improve the performance of the ML system.</description>
      <author>example@mail.com (Manal Rahal, Bestoun S. Ahmed, Gergely Szabados, Torgny Fornstedt, Jorgen Samuelsson)</author>
      <guid isPermaLink="false">2502.13198v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Non-Euclidean Hierarchical Representational Learning using Hyperbolic Graph Neural Networks for Environmental Claim Detection</title>
      <link>http://arxiv.org/abs/2502.13628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了图神经网络和双曲空间图神经网络作为环境声明检测任务中的轻量级替代方案，证明了这些基于结构化图的方法在保持高性能的同时具有更高的效率、可解释性和计算效率。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型主导着自然语言处理领域的各项任务，但其巨大的计算需求和缺乏透明性给实际应用带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;探索轻量级且有效的Graph Neural Networks (GNNs) 和Hyperbolic Graph Neural Networks (HGNNs) 作为环境声明检测中的替代方案，并重新定义该问题为图分类问题。&lt;h4&gt;方法&lt;/h4&gt;构造了依赖句法解析图，使用简单的词向量（word2vec）表示节点特征，将依存关系编码到边缘特征中。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，这些基于结构化的图模型能够在参数减少30倍的情况下达到与最先进的Transformer模型相当或更好的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了在自然语言处理任务中使用结构化、可解释和计算效率高的图方法的潜力。&lt;h4&gt;翻译&lt;/h4&gt;变压器主导着如情感分析，机器翻译，声明验证等NLP任务，然而它们庞大的计算需求和缺乏透明性阻碍了对高效和透明度要求的应用。在这项工作中，我们探讨了图神经网络（GNNs）和双曲图神经网络（HGNNs）作为环境声明检测中轻量级且有效的替代方案，重新将其定义为一个图形分类问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based models dominate NLP tasks like sentiment analysis, machinetranslation, and claim verification. However, their massive computationaldemands and lack of interpretability pose challenges for real-worldapplications requiring efficiency and transparency. In this work, we exploreGraph Neural Networks (GNNs) and Hyperbolic Graph Neural Networks (HGNNs) aslightweight yet effective alternatives for Environmental Claim Detection,reframing it as a graph classification problem. We construct dependency parsinggraphs to explicitly model syntactic structures, using simple word embeddings(word2vec) for node features with dependency relations encoded as edgefeatures. Our results demonstrate that these graph-based models achievecomparable or superior performance to state-of-the-art transformers while using30x fewer parameters. This efficiency highlights the potential of structured,interpretable, and computationally efficient graph-based approaches.</description>
      <author>example@mail.com (Darpan Aswal, Manjira Sinha)</author>
      <guid isPermaLink="false">2502.13628v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Refining embeddings with fill-tuning: data-efficient generalised performance improvements for materials foundation models</title>
      <link>http://arxiv.org/abs/2502.13886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;预训练基础模型学习的嵌入可以用于广泛的任务，当在特定任务上表现不足时可以通过微调来改进。然而当前的方法会导致对所有分布外任务的表现下降。这项工作提出了一种新的方法'fill-tuning'，生成针对特定下游任务不合适的预训练数据集，并通过粗糙度分析技术改善模型的嵌入表示。&lt;h4&gt;背景&lt;/h4&gt;预训练基础模型在各种下游任务中表现出色，但是它们可能无法准确处理特定的任务而需要微调。传统的微调会导致对未见过的数据的表现下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法'fill-tuning'来生成针对不合适的下游任务的预训练数据集，并通过该方法提高模型在所有下游任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;'fill-tuning' 方法使用粗糙度分析技术识别并改善模型嵌入表示中质量较差的部分，从而有针对性地改进特定领域的性能。&lt;h4&gt;主要发现&lt;/h4&gt;应用 fill-tuning 到多个先进材料基础模型上，在添加仅仅 100 个数据点的情况下实现了所有下游任务表现平均提升接近 1% 的效果。&lt;h4&gt;结论&lt;/h4&gt;该方法提供了一种在计算成本等于微调的情况下，对预训练基础模型进行整体改进的途径。&lt;h4&gt;翻译&lt;/h4&gt;预训练的基础模型学习到的嵌入可用于多种下游任务。这些嵌入优化了总体性能，如果在特定任务上不够准确，则可以通过微调来提升性能。然而，所有当前的方法都会导致其他未见过数据上的表现下降。在这项工作中我们提出了一种新的方法'fill-tuning'，用于生成针对不适合具体下游任务的预训练基础模型的数据集，而不是旨在纠正嵌入表示中的不良区域。我们展示了粗糙度分析如何应用于潜在空间拓扑结构，并说明了它可以用来推荐最有价值改进嵌入表示的数据点。我们将 fill-tuning 应用到一组最先进的材料基础模型上，这些模型是在 $O(10^9)$ 数据点的基础上训练的，在添加仅 100 条数据的情况下实现了所有下游任务中平均表现提高接近 1% 的效果。该方法提供了一种以与微调相当的计算成本来改进预训练基础模型的方法途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pretrained foundation models learn embeddings that can be used for a widerange of downstream tasks. These embeddings optimise general performance, andif insufficiently accurate at a specific task the model can be fine-tuned toimprove performance. For all current methodologies this operation necessarilydegrades performance on all out-of-distribution tasks. In this work we present'fill-tuning', a novel methodology to generate datasets for continuedpretraining of foundation models that are not suited to a particular downstreamtask, but instead aim to correct poor regions of the embedding. We present theapplication of roughness analysis to latent space topologies and illustrate howit can be used to propose data that will be most valuable to improving theembedding. We apply fill-tuning to a set of state-of-the-art materialsfoundation models trained on $O(10^9)$ data points and show model improvementof almost 1% in all downstream tasks with the addition of only 100 data points.This method provides a route to the general improvement of foundation models atthe computational cost of fine-tuning.</description>
      <author>example@mail.com (Matthew P. Wilson, Edward O. Pyzer-Knapp, Nicolas Galichet, Luke Dicks)</author>
      <guid isPermaLink="false">2502.13886v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Machine Learning Potentials through Transfer Learning across Chemical Elements</title>
      <link>http://arxiv.org/abs/2502.13522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '机器学习势能（MLPs）可以在显著降低计算成本的情况下实现从头算精度的模拟，但其有效性依赖于具有足够化学空间和热力学条件覆盖的大规模数据集。本文提出了在元素之间转移训练潜在能量面的方法。', '背景': 'MLPs的有效性需要大量的数据集来确保在整个化学空间中的稳健泛化，而这些大规模的数据集生成可能非常耗时。', '目的': '探索如何利用较少的数据进行MLPs的训练，特别是在缺乏大量初始数据的情况下。', '方法': '提出了转移学习的方法，即使用已训练好的硅原子MLP模型初始化并加速锗原子MLP模型的训练。', '主要发现': '与从零开始的传统训练相比，转移学习在力预测方面表现更佳，提高了模拟的稳定性，并且温度传递性更好。随着训练数据集的减小，这些优势变得更加明显。', '结论': '跨化学元素的迁移学习是一种开发准确和数值稳定的MLPs的有效技术，尤其是在数据稀少的情况下。', '翻译': '机器学习势能可以以数量级降低的成本实现从头算精度的模拟，但其有效性依赖于具有足够化学空间覆盖的大规模数据集。为此，文章提出了在相似元素之间迁移训练潜在能量面的方法，并通过实验验证了转移学习能够提高力预测准确性和温度传递性，尤其适用于小数据集情况下的模型开发。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine Learning Potentials (MLPs) can enable simulations of ab initioaccuracy at orders of magnitude lower computational cost. However, theireffectiveness hinges on the availability of considerable datasets to ensurerobust generalization across chemical space and thermodynamic conditions. Thegeneration of such datasets can be labor-intensive, highlighting the need forinnovative methods to train MLPs in data-scarce scenarios. Here, we introducetransfer learning of potential energy surfaces between chemically similarelements. Specifically, we leverage the trained MLP for silicon to initializeand expedite the training of an MLP for germanium. Utilizing classical forcefield and ab initio datasets, we demonstrate that transfer learning surpassestraditional training from scratch in force prediction, leading to more stablesimulations and improved temperature transferability. These advantages becomeeven more pronounced as the training dataset size decreases. The out-of-targetproperty analysis shows that transfer learning leads to beneficial butsometimes adversarial effects. Our findings demonstrate that transfer learningacross chemical elements is a promising technique for developing accurate andnumerically stable MLPs, particularly in a data-scarce regime.</description>
      <author>example@mail.com (Sebastien Röcken, Julija Zavadlav)</author>
      <guid isPermaLink="false">2502.13522v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>A Chain-of-Thought Subspace Meta-Learning for Few-shot Image Captioning with Large Vision and Language Models</title>
      <link>http://arxiv.org/abs/2502.13942v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种多模态元学习框架，利用调优提示来连接两个预训练的大规模视觉和语言模型，以解决在少量数据训练时的领域差距问题。&lt;h4&gt;背景&lt;/h4&gt;大规模的视觉和语言预训练模型已经在大量的数据上编码了视觉和语言先验知识，使得生成更自然、更真实的图像和文本变得更加容易。然而，在小样本设置中（即只有非常有限的数据可用于训练），视觉和语言模态之间的领域差距仍然显著。&lt;h4&gt;目的&lt;/h4&gt;为了减轻这个领域差距问题，提出了一种多模态元学习框架来连接两个预训练的大规模视觉和语言模型，并引入一个可调的提示以促进两者的交互。&lt;h4&gt;方法&lt;/h4&gt;在少量样本图像描述任务中，现有的多模态元学习框架采用了一步式提示方案来积累输入图像的视觉特征并指导语言模型。然而，这种策略难以仅通过有限的训练样本生成准确的图像描述。因此，提出了一个链条思维（CoT）元学习方案作为多步骤图像描述程序，更有效地模仿人类如何描述图像，并进一步提出在每个CoT步骤中学习不同的子空间元参数以避免干扰。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在不同数据集上评估的方法优于基线方法，尤其是在少样本设置下的MSCOCO、Flickr8k和Flickr30k三个常用图像描述数据集中表现更为出色。&lt;h4&gt;结论&lt;/h4&gt;所提出的链条思维子空间元学习策略在性能方面超越了基准模型，并且能够更好地处理视觉和语言模态之间的领域差距问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A large-scale vision and language model that has been pretrained on massivedata encodes visual and linguistic prior, which makes it easier to generateimages and language that are more natural and realistic. Despite this, there isstill a significant domain gap between the modalities of vision and language,especially when training data is scarce in few-shot settings, where only verylimited data are available for training. In order to mitigate this issue, amulti-modal meta-learning framework has been proposed to bridge the gap betweentwo frozen pretrained large vision and language models by introducing a tunableprompt connecting these two large models. For few-shot image captioning, theexisting multi-model meta-learning framework utilizes a one-step promptingscheme to accumulate the visual features of input images to guide the languagemodel, which struggles to generate accurate image descriptions with only a fewtraining samples. Instead, we propose a chain-of-thought (CoT) meta-learningscheme as a multi-step image captioning procedure to better imitate how humansdescribe images. In addition, we further propose to learn differentmeta-parameters of the model corresponding to each CoT step in distinctsubspaces to avoid interference. We evaluated our method on three commonly usedimage captioning datasets, i.e., MSCOCO, Flickr8k, and Flickr30k, underfew-shot settings. The results of our experiments indicate that ourchain-of-thought subspace meta-learning strategy is superior to the baselinesin terms of performance across different datasets measured by differentmetrics.</description>
      <author>example@mail.com (Hao Huang, Shuaihang Yuan, Yu Hao, Congcong Wen, Yi Fang)</author>
      <guid isPermaLink="false">2502.13942v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>MuDAF: Long-Context Multi-Document Attention Focusing through Contrastive Learning on Attention Heads</title>
      <link>http://arxiv.org/abs/2502.13963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了MuDAF方法来解决大型语言模型在长上下文问答任务中由于输入信息不相关而导致的注意力分散问题。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型常因输入中的无关信息而表现出注意力分散，严重损害了它们处理长上下文的能力。最近的研究表明检索头在长上下文事实性方面的有效性。&lt;h4&gt;目的&lt;/h4&gt;通过改进检索头直接解决这种分心问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一个多文档注意聚焦（MuDAF）的新颖方法，该方法通过对比学习显式优化头部级别的注意力分布。&lt;h4&gt;主要发现&lt;/h4&gt;根据实验结果，MuDAF可以显著提高大型语言模型在长上下文问答任务中的表现，特别是在多文档问答场景下。广泛的检索评分和注意可视化评估表明MuDAF具有使注意力头更专注于相关信息并减少注意力分散的潜力。&lt;h4&gt;结论&lt;/h4&gt;MuDAF通过优化头部级别的注意力分布来解决大型语言模型中存在的注意力分散问题，并在长上下文问答任务中显示出显著改善的表现，特别是在多文档问答方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) frequently show distracted attention due toirrelevant information in the input, which severely impairs their long-contextcapabilities. Inspired by recent studies on the effectiveness of retrievalheads in long-context factutality, we aim at addressing this distraction issuethrough improving such retrieval heads directly. We propose Multi-DocumentAttention Focusing (MuDAF), a novel method that explicitly optimizes theattention distribution at the head level through contrastive learning.According to the experimental results, MuDAF can significantly improve thelong-context question answering performance of LLMs, especially inmulti-document question answering. Extensive evaluations on retrieval scoresand attention visualizations show that MuDAF possesses great potential inmaking attention heads more focused on relevant information and reducingattention distractions.</description>
      <author>example@mail.com (Weihao Liu, Ning Wu, Shiping Yang, Wenbiao Ding, Shining Liang, Ming Gong, Dongmei Zhang)</author>
      <guid isPermaLink="false">2502.13963v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Graph Embeddings for Session-based Recommendation with Item Features</title>
      <link>http://arxiv.org/abs/2502.13763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要类型&lt;/h4&gt;论文&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合图神经网络和基于会话相似性的推荐算法的新方法——Graph Convolutional Network Extension (GCNext)，该方法通过在图卷积网络中直接集成物品特征来增强现有的序列推荐系统。&lt;h4&gt;背景&lt;/h4&gt;现有最先进的顺序推荐算法主要采用图神经网络建模会话或利用物品特性之间的相似性进行推荐。这些方法要么使用复杂的计算模型，要么依赖于大量的用户行为数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的序列推荐方法GCNext，该方法结合了两种当前主流的推荐技术的优点，通过在图表示中直接整合物品特征来改进会话基线推荐系统。&lt;h4&gt;方法&lt;/h4&gt;GCNext创建一个丰富物品共现图并利用无监督学习方式获取对应的物品嵌入。此外，研究团队还将这种方法与最近邻算法和神经网络模型相结合以验证其效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在三个数据集上将GCNext融入序列推荐算法可以显著提升近似邻居方法以及神经网络模型的性能，并且提高了MRR@20指标值高达12.79%。此外，该技术对于最先进的推荐方法来说易于集成并且具有灵活性。&lt;h4&gt;结论&lt;/h4&gt;通过直接整合物品特征到图卷积网络中的创新性设计，GCNext不仅改进了现有推荐系统的性能还提供了一种新的研究方向和策略用于未来的研究和发展。&lt;h4&gt;翻译&lt;/h4&gt;在基于会话的推荐系统中，预测是根据用户在此会话之前的行动进行的。最先进的顺序推荐算法要么使用图形神经网络来建模图中的会话，要么通过利用物品特征来挖掘会话之间的相似性。本文结合这两种方法并提出了一种新颖的方法Graph Convolutional Network Extension (GCNext)，它直接将项目特性纳入到图表示中。 GCNext创建了一个丰富的共现图，并在无监督的方式下学习对应的物品嵌入。我们在三个数据集上展示了将其融入顺序推荐算法可以显著提升最近邻方法和神经网络模型的性能，我们的灵活扩展易于在最先进的方法中集成并且可提高MRR@20达12.79%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In session-based recommender systems, predictions are based on the user'spreceding behavior in the session. State-of-the-art sequential recommendationalgorithms either use graph neural networks to model sessions in a graph orleverage the similarity of sessions by exploiting item features. In this paper,we combine these two approaches and propose a novel method, Graph ConvolutionalNetwork Extension (GCNext), which incorporates item features directly into thegraph representation via graph convolutional networks. GCNext creates afeature-rich item co-occurrence graph and learns the corresponding itemembeddings in an unsupervised manner. We show on three datasets thatintegrating GCNext into sequential recommendation algorithms significantlyboosts the performance of nearest-neighbor methods as well as neural networkmodels. Our flexible extension is easy to incorporate in state-of-the-artmethods and increases the MRR@20 by up to 12.79%.</description>
      <author>example@mail.com (Andreas Peintner, Marta Moscati, Emilia Parada-Cabaleiro, Markus Schedl, Eva Zangerle)</author>
      <guid isPermaLink="false">2502.13763v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Model Agnostic Social Influence Maximization in Hyperbolic Space</title>
      <link>http://arxiv.org/abs/2502.13571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了HIM，一种利用双曲表示学习来估计用户潜在影响力传播的新颖扩散模型无关方法。&lt;h4&gt;背景&lt;/h4&gt;传统影响最大化（IM）问题的方法依赖于具有已知参数的固定扩散模型，这限制了它们在现实场景中的应用。基于图表示的学习方法虽然能够克服这一局限性，但现有的研究建立在欧氏空间上，无法有效捕捉社会影响力分布的潜在层次特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的影响最大化（IM）问题解决方法，以更好地适应现实世界的社会网络。&lt;h4&gt;方法&lt;/h4&gt;HIM包括两个关键组成部分：一是双曲影响力表示模块，它从网络结构和历史影响力激活中编码出有表现力的双曲用户表示；二是自适应种子选择模块，该模块利用学习到的用户表示的位置信息灵活有效地选择种子用户。&lt;h4&gt;主要发现&lt;/h4&gt;在五个网络数据集上的广泛实验表明了HIM方法对于具有未知扩散模型参数的影响最大化问题的有效性和效率。&lt;h4&gt;结论&lt;/h4&gt;通过使用双曲空间中的几何属性来反映用户的影响力大小，以及自适应的种子选择模块，HIM能够更准确地预测用户潜在的影响力传播，并在大规模现实世界的社会网络中展现出巨大的潜力。&lt;h4&gt;翻译&lt;/h4&gt;影响最大化（IM）问题旨在寻找一组具有影响力的用户，以最大限度地扩大他们在社交网络中的影响力。传统的解决方案依赖于固定扩散模型和已知参数，这限制了它们在真实场景中的应用。基于图表示学习的方法虽然能够克服这一局限性，但现有的研究建立在欧氏空间上，无法有效捕捉社会影响力分布的潜在层次特征。为解决这些问题，我们提出了HIM，一种新颖的扩散模型无关方法，利用双曲表示学习从社交传播数据中估计用户潜在的影响传播。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Influence Maximization (IM) problem aims to find a small set ofinfluential users to maximize their influence spread in a social network.Traditional methods rely on fixed diffusion models with known parameters,limiting their generalization to real-world scenarios. In contrast, graphrepresentation learning-based methods have gained wide attention for overcomingthis limitation by learning user representations to capture influencecharacteristics. However, existing studies are built on Euclidean space, whichfails to effectively capture the latent hierarchical features of socialinfluence distribution. As a result, users' influence spread cannot beeffectively measured through the learned representations. To alleviate theselimitations, we propose HIM, a novel diffusion model agnostic method thatleverages hyperbolic representation learning to estimate users' potentialinfluence spread from social propagation data. HIM consists of two keycomponents. First, a hyperbolic influence representation module encodesinfluence spread patterns from network structure and historical influenceactivations into expressive hyperbolic user representations. Hence, theinfluence magnitude of users can be reflected through the geometric propertiesof hyperbolic space, where highly influential users tend to cluster near thespace origin. Second, a novel adaptive seed selection module is developed toflexibly and effectively select seed users using the positional information oflearned user representations. Extensive experiments on five network datasetsdemonstrate the superior effectiveness and efficiency of our method for the IMproblem with unknown diffusion model parameters, highlighting its potential forlarge-scale real-world social networks.</description>
      <author>example@mail.com (Hongliang Qiao)</author>
      <guid isPermaLink="false">2502.13571v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Web Phishing Net (WPN): A scalable machine learning approach for real-time phishing campaign detection</title>
      <link>http://arxiv.org/abs/2502.13171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Intelligent Cybersecurity Conference (ICSC2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;钓鱼攻击是当今最常见的网络攻击类型，被认为是数据泄露的主要源头，并对个人和企业造成重大后果。&lt;h4&gt;背景&lt;/h4&gt;网页基础的钓鱼攻击最为频繁，通过社交媒体帖子或包含链接到钓鱼网站的电子邮件来实施。这些现有的检测方法依赖于监督学习技术，需要大量数据进行训练，具有高计算需求，并且侵犯用户隐私。此外，由于生成式人工智能技术的发展，现有系统对于日益演变的安全威胁缺乏抵抗力。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督的学习方法，以解决现有钓鱼URL检测系统的不足，实现快速、可扩展的检测方案，同时保持用户的隐私。&lt;h4&gt;方法&lt;/h4&gt;采用了一种不涉及配对比较的新颖无监督学习方法，能够实时识别完整的钓鱼攻击活动，并且对于使用生成式AI技术创建的目标性更强的钓鱼URL也能有效防御。&lt;h4&gt;主要发现&lt;/h4&gt;该论文所提出的无监督学习方法能够在检测效率和准确性上超越现有解决方案。它可以在没有用户数据的前提下高效地工作，同时仍能提供高准确率的威胁识别。&lt;h4&gt;结论&lt;/h4&gt;这种新颖的方法为应对不断变化的安全环境提供了有力工具，并在保护用户隐私的同时增强了对抗生成式AI驱动钓鱼攻击的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了现今最常见且最具危害性的网络攻击——钓鱼攻击所带来的问题。当前基于监督学习技术的解决方案存在计算需求高、侵犯隐私及抵抗新兴威胁能力弱等问题。论文提出了一个新的无监督方法，旨在提高检测速度和准确性，同时保护用户隐私，并应对由生成式AI驱动的新一轮有针对性的钓鱼URL攻击浪潮。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Phishing is the most prevalent type of cyber-attack today and is recognizedas the leading source of data breaches with significant consequences for bothindividuals and corporations. Web-based phishing attacks are the most frequentwith vectors such as social media posts and emails containing links to phishingURLs that once clicked on render host systems vulnerable to more sinisterattacks. Research efforts to detect phishing URLs have involved the use ofsupervised learning techniques that use large amounts of data to train modelsand have high computational requirements. They also involve analysis offeatures derived from vectors including email contents thus affecting userprivacy. Additionally, they suffer from a lack of resilience against evolutionof threats especially with the advent of generative AI techniques to bypassthese systems as with AI-generated phishing URLs. Unsupervised methods such asclustering techniques have also been used in phishing detection in the past,however, they are at times unscalable due to the use of pair-wise comparisons.They also lack high detection rates while detecting phishing campaigns. In thispaper, we propose an unsupervised learning approach that is not only fast butscalable, as it does not involve pair-wise comparisons. It is able to detectentire campaigns at a time with a high detection rate while preserving userprivacy; this includes the recent surge of campaigns with targeted phishingURLs generated by malicious entities using generative AI techniques.</description>
      <author>example@mail.com (Muhammad Fahad Zia, Sri Harish Kalidass)</author>
      <guid isPermaLink="false">2502.13171v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Performance Evaluation of Sentiment Analysis on Text and Emoji Data Using End-to-End, Transfer Learning, Distributed and Explainable AI Models</title>
      <link>http://arxiv.org/abs/2502.13278v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了使用表情符号进行情感分析和基于文本的情感分类，并采用分布式训练方式提高了模型的效率。&lt;h4&gt;背景&lt;/h4&gt;当前，数字世界中频繁使用表情符号来表达从简单到复杂的思想。因此，在情感分析和定向营销活动中也越来越多地使用它们。&lt;h4&gt;目的&lt;/h4&gt;研究使用不同嵌入模型对推特及Kaggle上的情感数据进行情感分类，并探索分布式训练方法以提高效率。&lt;h4&gt;方法&lt;/h4&gt;{'模型选择': '采用Universal Sentence Encoder (USE) 和Sentence Bidirectional Encoder Representations from Transformers (SBERT)生成句子嵌入，用于训练标准全连接神经网络（NN）和LSTM NN模型。', '数据处理': '对推特文本使用上述嵌入模型进行情感分类。同时，利用表情符号数据集作为验证集来评估模型性能。', '分布式训练': '采用分布式训练方法替代传统单线程模型以提高可扩展性，减少了大约15%的运行时间而不会牺牲准确性。', '解释性AI': '使用Shap算法解释模型行为并检查给定特征集中的潜在偏见。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'情感分类准确度': '对于推特文本的情感分析，全连接NN和LSTM NN模型的分类准确率都在98%左右。', '表情符号验证数据集': '当使用训练集中没有的表情符号作为验证集时，两个模型的准确率都急剧下降到70%左右。'}&lt;h4&gt;结论&lt;/h4&gt;虽然表情符号在情感分析中的准确性存在局限性，但采用分布式训练方法可以提高计算效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到，在当前数字世界中，表情符号被广泛用于表达各种思想，并且在情感分析和定向营销活动中也得到了应用。研究者对Twitter数据及Kaggle上的表情符号数据进行了情感分类，使用了Universal Sentence Encoder (USE) 和Sentence Bidirectional Encoder Representations from Transformers (SBERT)，生成句子嵌入并训练标准全连接神经网络（NN）和LSTM NN模型。对于推特文本的测试集，两种模型的情感分类准确率均约为98%；然而，当验证数据集中包含未出现在训练中的表情符号时，两个模型的准确度大幅下降至70%左右。此外，研究还使用了分布式训练方法来提高模型可扩展性，并通过Shap算法进行了解释性AI的应用，以检查给定特征集上的潜在偏见。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.12720/jait.13.2.167-172&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emojis are being frequently used in todays digital world to express fromsimple to complex thoughts more than ever before. Hence, they are also beingused in sentiment analysis and targeted marketing campaigns. In this work, weperformed sentiment analysis of Tweets as well as on emoji dataset from theKaggle. Since tweets are sentences we have used Universal Sentence Encoder(USE) and Sentence Bidirectional Encoder Representations from Transformers(SBERT) end-to-end sentence embedding models to generate the embeddings whichare used to train the Standard fully connected Neural Networks (NN), and LSTMNN models. We observe the text classification accuracy was almost the same forboth the models around 98 percent. On the contrary, when the validation set wasbuilt using emojis that were not present in the training set then the accuracyof both the models reduced drastically to 70 percent. In addition, the modelswere also trained using the distributed training approach instead of atraditional singlethreaded model for better scalability. Using the distributedtraining approach, we were able to reduce the run-time by roughly 15% withoutcompromising on accuracy. Finally, as part of explainable AI the Shap algorithmwas used to explain the model behaviour and check for model biases for thegiven feature set.</description>
      <author>example@mail.com (Sirisha Velampalli, Chandrashekar Muniyappa, Ashutosh Saxena)</author>
      <guid isPermaLink="false">2502.13278v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Helix-mRNA: A Hybrid Foundation Model For Full Sequence mRNA Therapeutics</title>
      <link>http://arxiv.org/abs/2502.13785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 3 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Helix-mRNA，一种用于优化mRNA疫苗序列的深度学习模型。该模型通过结构化的状态空间和注意力机制的结合，在处理UTR（非编码区）和编码区域时表现出色。&lt;h4&gt;背景&lt;/h4&gt;基于mRNA的疫苗在制药行业受到高度重视，但mRNA序列中包括编码区和非翻译区在内的各种因素共同决定了疫苗的有效性。当前深度学习模型主要关注于优化编码区而忽略了非翻译区。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时优化mRNA序列中的UTR和编码区域，并且具备高效处理长序列能力的深度学习模型。&lt;h4&gt;方法&lt;/h4&gt;引入了Helix-mRNA，一个结合结构化状态空间和注意力机制的混合模型。该模型使用单核苷酸标记化及密码子分离来保持原始mRNA序列中的生物和结构性信息，在初次预训练之后进行了第二次高质数据预训练以提升性能。&lt;h4&gt;主要发现&lt;/h4&gt;Helix-mRNA在分析UTR和编码区域特性方面超越了现有方法，能够处理比当前技术长六倍的序列且仅使用其他基础模型10%的参数。此外，其预测能力覆盖所有mRNA区域。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种高效的深度学习框架Helix-mRNA用于优化mRNA疫苗序列，它在准确性、效率和数据利用方面都有显著改进，并将源代码与权重开放共享以供社区使用。&lt;h4&gt;翻译&lt;/h4&gt;基于mRNA的疫苗已成为制药业的主要焦点。编码序列以及非翻译区（UTRs）可以强烈影响蛋白质合成的效率、稳定性和降解等特性，这些共同决定了疫苗的效果。然而，优化mRNA序列仍然是一项复杂的挑战。现有的深度学习模型通常仅关注于编码区域的优化，而忽略了UTR。我们提出了Helix-mRNA，这是一种基于结构化的状态空间和注意力机制相结合的方法来解决这些问题。除了初步预训练外，通过高质量数据的二次预训练使模型专业化。采用单核苷酸标记法对mRNA序列进行处理，并分离密码子以确保保留原始mRNA序列中的生物和结构信息。Helix-mRNA在分析UTR和编码区域性质方面超过了现有方法的表现，在仅使用当前基础模型10%参数的情况下，可以处理比目前技术长六倍的序列。该模型具有广泛的预测能力，适用于所有mRNA区段。我们将开放源代码（https://github.com/helicalAI/helical）及模型权重（https://huggingface.co/helical-ai/helix-mRNA）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; mRNA-based vaccines have become a major focus in the pharmaceutical industry.The coding sequence as well as the Untranslated Regions (UTRs) of an mRNA canstrongly influence translation efficiency, stability, degradation, and otherfactors that collectively determine a vaccine's effectiveness. However,optimizing mRNA sequences for those properties remains a complex challenge.Existing deep learning models often focus solely on coding region optimization,overlooking the UTRs. We present Helix-mRNA, a structured state-space-based andattention hybrid model to address these challenges. In addition to a firstpre-training, a second pre-training stage allows us to specialise the modelwith high-quality data. We employ single nucleotide tokenization of mRNAsequences with codon separation, ensuring prior biological and structuralinformation from the original mRNA sequence is not lost. Our model, Helix-mRNA,outperforms existing methods in analysing both UTRs and coding regionproperties. It can process sequences 6x longer than current approaches whileusing only 10% of the parameters of existing foundation models. Its predictivecapabilities extend to all mRNA regions. We open-source the model(https://github.com/helicalAI/helical) and model weights(https://huggingface.co/helical-ai/helix-mRNA).</description>
      <author>example@mail.com (Matthew Wood, Mathieu Klop, Maxime Allard)</author>
      <guid isPermaLink="false">2502.13785v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>AI-Driven Discovery of High Performance Polymer Electrodes for Next-Generation Batteries</title>
      <link>http://arxiv.org/abs/2502.13899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  33 pages, 10 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;使用过渡族金属在电动电池中的应用，面临着锂、钴和镍等关键元素大量消耗的挑战，这些元素对环境造成了显著的影响。为了减少这种影响，用具有氧化还原活性的有机材料替代这些金属是一种有希望的方法，可以将电池的碳足迹降低一个数量级。&lt;h4&gt;背景&lt;/h4&gt;过渡族金属在电动电池中的广泛应用导致了锂、钴和镍等关键元素资源的巨大消耗，这对环境构成了严重挑战。为了减轻这一问题，研究转向寻找新的材料来取代这些金属。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于机器学习的电池信息学框架，以加速并优化具有氧化还原活性的有机材料的选择、优化与设计过程，从而克服其电压和特定容量方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;建立了一个结合数据融合和元学习模型的机器学习框架，该框架能够预测各种有机负极材料和载流子（正极材料）组合下的电池性能参数，包括电压和特定容量。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用先进的机器学习技术和广泛的电池数据库，研究成功地识别并设计出了适合可持续储能技术的候选材料。&lt;h4&gt;结论&lt;/h4&gt;该研究成果为加速具有氧化还原活性有机材料的研究提供了重要的手段，有助于推动更环保、高效的能源存储解决方案的发展。&lt;h4&gt;翻译&lt;/h4&gt;原文摘要是关于探索使用红ox活性有机材料替代过渡族金属在电池中的应用。通过机器学习驱动的方法，研究旨在克服现有材料的局限性，并推进可持续储能技术的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The use of transition group metals in electric batteries requires extensiveusage of critical elements like lithium, cobalt and nickel, which posessignificant environmental challenges. Replacing these metals with redox-activeorganic materials offers a promising alternative, thereby reducing the carbonfootprint of batteries by one order of magnitude. However, this approach facescritical obstacles, including the limited availability of suitable redox-activeorganic materials and issues such as lower electronic conductivity, voltage,specific capacity, and long-term stability. To overcome the limitations forlower voltage and specific capacity, a machine learning (ML) driven batteryinformatics framework is developed and implemented. This framework utilizes anextensive battery dataset and advanced ML techniques to accelerate and enhancethe identification, optimization, and design of redox-active organic materials.In this contribution, a data-fusion ML coupled meta learning model capable ofpredicting the battery properties, voltage and specific capacity, for variousorganic negative electrodes and charge carriers (positive electrode materials)combinations is presented. The ML models accelerate experimentation, facilitatethe inverse design of battery materials, and identify suitable candidates fromthree extensive material libraries to advance sustainable energy-storagetechnologies.</description>
      <author>example@mail.com (Subhash V. S. Ganti, Lukas Woelfel, Christopher Kuenneth)</author>
      <guid isPermaLink="false">2502.13899v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning-Based privacy metrics in Tabular Synthetic Datasets</title>
      <link>http://arxiv.org/abs/2502.13833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;合成数据作为一种隐私保护技术在医疗和金融等行业中受到关注。为了确保使用合成数据的实际应用中的隐私保障，本文提出了一种对比学习方法，该方法通过将数据嵌入到更具代表性的空间来改进对合成数据集的隐私评估。&lt;h4&gt;背景&lt;/h4&gt;利用合成数据提供保护保证是一个关键问题，尤其是在医疗和金融等敏感行业中。目前有两种主要的方法：基于相似度的方法以及基于攻击的方法。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的对比学习方法以提升合成数据集的隐私评估，并通过实验验证其有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了将数据嵌入到更加代表性的空间中的对比学习方法，使其能够利用直观的距离测量指标来改进对隐私保护度的估计。同时，该研究还比较了基于相似性和攻击的方法在使用和不使用此嵌入技术时的表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，相对简单且易于实施的隐私评估指标可以与更复杂、专门针对GDPR条件设计的指标一样有效。&lt;h4&gt;结论&lt;/h4&gt;本文提出了一种改进合成数据集隐私保护度评估的新方法，并展示了其在多种公共可用数据集上的有效性。这种方法为实际应用中的合成数据分析提供了一个有效的工具。&lt;h4&gt;翻译&lt;/h4&gt;合成数据作为增强隐私的技术，在医疗和金融领域等得到了广泛应用。为了保障将合成数据应用于实践时的隐私安全，研究文献中提出了两种处理表格数据的方法：基于相似度的方法旨在寻找训练数据与合成数据之间的相似性程度；而基于攻击的方法则故意对合成数据集进行攻击，通过成功概率来评估其安全性。本文介绍了一种对比方法，该方法通过将数据嵌入到更具代表性的空间来改善对生成数据隐私保护的评价，从而克服了不同类型和属性的数据面临的障碍，并使得使用直观的距离度量指标成为可能。在一系列公开可用数据集上进行的实验中，我们比较了基于相似性和攻击的方法，在使用与不使用对比学习基嵌入的情况下两种方法的表现情况。我们的结果表明，相对简单且容易实现的隐私评估指标可以像更高级、专门针对GDPR条件设计的隐私模型一样有效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Synthetic data has garnered attention as a Privacy Enhancing Technology (PET)in sectors such as healthcare and finance. When using synthetic data inpractical applications, it is important to provide protection guarantees. Inthe literature, two family of approaches are proposed for tabular data: on theone hand, Similarity-based methods aim at finding the level of similaritybetween training and synthetic data. Indeed, a privacy breach can occur if thegenerated data is consistently too similar or even identical to the train data.On the other hand, Attack-based methods conduce deliberate attacks on syntheticdatasets. The success rates of these attacks reveal how secure the syntheticdatasets are.  In this paper, we introduce a contrastive method that improves privacyassessment of synthetic datasets by embedding the data in a more representativespace. This overcomes obstacles surrounding the multitude of data types andattributes. It also makes the use of intuitive distance metrics possible forsimilarity measurements and as an attack vector. In a series of experimentswith publicly available datasets, we compare the performances ofsimilarity-based and attack-based methods, both with and without use of thecontrastive learning-based embeddings. Our results show that relativelyefficient, easy to implement privacy metrics can perform equally well as moreadvanced metrics explicitly modeling conditions for privacy referred to by theGDPR.</description>
      <author>example@mail.com (Milton Nicolás Plasencia Palacios, Sebastiano Saccani, Gabriele Sgroi, Alexander Boudewijn, Luca Bortolussi)</author>
      <guid isPermaLink="false">2502.13833v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Integrated Sensing and Communication for 6G Holographic Digital Twins</title>
      <link>http://arxiv.org/abs/2502.13352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文探讨了6G网络下全息通信的发展前景，特别是全息数字孪生（HDT）的应用。提出了一个基于感知与通信集成(ISAC)的四层架构来支持低成本、高精度环境数据收集以构建HDT。&lt;h4&gt;背景&lt;/h4&gt;随着6G网络的到来和终端设备分辨率的提升，全息通信逐渐成为可能。HDT是其关键应用之一，能够实时映射和预测物理实体状态，并进行空间信息三维再现。&lt;h4&gt;目的&lt;/h4&gt;提出一种集成感知与通信（ISAC）辅助架构以支持低成本、高精度环境数据收集用于构建HDT。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一个四层架构，通过探索超分辨率技术来增强感知解析度，同时研究多点协作感应在构建HDT中的应用，并详细回顾了四种关键技术：节点选择、多频带合作、协作波束形成和数据融合。&lt;h4&gt;主要发现&lt;/h4&gt;论文提出并分析了几种可以提高全息数字孪生性能的关键技术和方法。其中强调了超分辨率技术和多点协同感应的重要性。&lt;h4&gt;结论&lt;/h4&gt;本文指出了几个未来研究的有趣方向，旨在指导和启发后续的工作。&lt;h4&gt;翻译&lt;/h4&gt;随着6G网络的到来，提供超高带宽和极低延迟，并且终端设备分辨率的提升，全息通信正逐渐成为现实。HDT被认为是全息通信中的关键应用之一，能够为物理实体的状态进行实时映射与预测，并实现空间信息的三维再现。在此背景下，感知与通信集成(ISAC)有望成为一个提供数据源给HDT的关键路径。本文提出了一种基于ISAC辅助四层架构的HDT方案，整合新兴范式和技术以实现低成本、高精度环境数据收集来构建HDT。具体而言，在提高感应分辨率方面，从参数估计和点云构造的角度探讨了超分辨率技术，并专注于多点协作感应在构建HDT中的应用，提供节点选择、多频带合作、协作波束形成和数据融合四种关键技术的全面回顾。最后指出了几个未来研究的方向以指导并启发后续工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advent of 6G networks, offering ultra-high bandwidth and ultra-lowlatency, coupled with the enhancement of terminal device resolutions,holographic communication is gradually becoming a reality. Holographic digitaltwin (HDT) is considered one of key applications of holographic communication,capable of creating virtual replicas for real-time mapping and prediction ofphysical entity states, and performing three-dimensional reproduction ofspatial information. In this context, integrated sensing and communication(ISAC) is expected to be a crucial pathway for providing data sources to HDT.This paper proposes a four-layer architecture assisted by ISAC for HDT,integrating emerging paradigms and key technologies to achieve low-cost,high-precision environmental data collection for constructing HDT.Specifically, to enhance sensing resolution, we explore super-resolutiontechniques from the perspectives of parameter estimation and point cloudconstruction. Additionally, we focus on multi-point collaborative sensing forconstructing HDT, and provide a comprehensive review of four key techniques:node selection, multi-band collaboration, cooperative beamforming, and datafusion. Finally, we highlight several interesting research directions to guideand inspire future work.</description>
      <author>example@mail.com (Haijun Zhang, Ziyang Zhang, Xiangnan Liu, Wei Li, Haojin Li, Chen Sun)</author>
      <guid isPermaLink="false">2502.13352v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Refining Sentence Embedding Model through Ranking Sentences Generation with Large Language Models</title>
      <link>http://arxiv.org/abs/2502.13656v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的句子嵌入生成和精炼的方法，该方法通过控制大规模语言模型（LLMs）在潜在空间中的生成方向来确保语义差异，并结合排名信息对现有句子嵌入模型进行改进。&lt;h4&gt;背景&lt;/h4&gt;对比学习方法在使用如NLI等标注数据集的情况下为许多自然语言处理任务提供了强大的句嵌入，但依赖人工标签限制了可扩展性。最近的研究利用大规模语言模型生成句子对以减少注释需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的控制大规模语言模型生成方向的方法，并结合排名信息来改进现有句子嵌入模型的性能。&lt;h4&gt;方法&lt;/h4&gt;通过控制LLMs在潜在空间中的生成方向，确保语义差异，并引入排名和语义信息来精炼现有的句子嵌入模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在适度增加句对合成成本的情况下，该方法达到了新的SOTA（State-of-the-Art）性能水平。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在不显著增加计算成本的前提下提高了句子嵌入的精度和语义区分能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sentence embedding is essential for many NLP tasks, with contrastive learningmethods achieving strong performance using annotated datasets like NLI. Yet,the reliance on manual labels limits scalability. Recent studies leverage largelanguage models (LLMs) to generate sentence pairs, reducing annotationdependency. However, they overlook ranking information crucial for fine-grainedsemantic distinctions. To tackle this challenge, we propose a method forcontrolling the generation direction of LLMs in the latent space. Unlikeunconstrained generation, the controlled approach ensures meaningful semanticdivergence. Then, we refine exist sentence embedding model by integratingranking information and semantic information. Experiments on multiplebenchmarks demonstrate that our method achieves new SOTA performance with amodest cost in ranking sentence synthesis.</description>
      <author>example@mail.com (Liyang He, Chenglong Liu, Rui Li, Zhenya Huang, Shulan Ruan, Jun Zhou, Enhong Chen)</author>
      <guid isPermaLink="false">2502.13656v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Homophily Heterogeneity Matters in Graph Federated Learning: A Spectrum Sharing and Complementing Perspective</title>
      <link>http://arxiv.org/abs/2502.13732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的联邦学习方法FedGSP，该方法通过挖掘图的谱性质来解决图联邦学习中的同质性异质性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的许多方法主要关注于处理节点特征异质性和结构异质性，而忽视了同质性水平在不同客户端之间存在的显著变化，即同质性异质性。这个问题导致局部模型之间的合作效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的联邦学习方法FedGSP，以有效地解决图数据中的同质性异质性问题，并提高各客户端间的协作效率和性能。&lt;h4&gt;方法&lt;/h4&gt;引入谱Graph神经网络(GNN)，并通过挖掘图的谱性质来实现跨客户端共享通用的谱属性(即低频信息)。此外，允许客户端通过获取其缺乏的谱特性（即高频信息）来互补非通用的谱特性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果验证了FedGSP在处理同质性和异质性图数据时的表现优越性，并且在所有异质性数据集上比现有最佳方法平均高出3.28%。&lt;h4&gt;结论&lt;/h4&gt;通过挖掘和利用图形的谱性质，可以有效地解决联邦学习中的同质性异质性问题。FedGSP提供了一种有效的方法来提高各客户端间模型合作的效果。&lt;h4&gt;翻译&lt;/h4&gt;由于异质性是图联邦学习的基本挑战，许多现有方法主要关注于处理节点特征异质性和结构异质性。然而，它们忽视了关键的同质性异质性问题，即不同客户图数据中的同质水平存在显著变化。同质水平表示连接属于同一类别的节点之间的边的比例。由于适应各自的本地同质性，局部模型在不同的客户端之间捕获不一致的频谱特性，这大大减少了合作的有效性。具体来说，在高同质性的图上训练的局部模型倾向于捕捉低频信息，而那些在低同质性的图上训练的局部模型则倾向于捕捉高频信息。为了有效处理同质异质性问题，我们引入了谱Graph神经网络（GNN），并提出了一种通过挖掘图形谱特性进行联邦学习的新方法FedGSP。一方面，我们的提议FedGSP使客户端能够共享通用的频谱属性（即低频信息），从而使所有参与者都能从合作中受益。另一方面，受到理论发现的启发，我们提出的FedGSP允许客户端通过获取它们所缺乏的频谱特征来补充非通用的谱特性（即高频信息），从而获得额外的信息增益。在六种同质性和五种异质性图数据集上的广泛实验表明了我们的方法优于现有的11个最先进的方法。值得注意的是，我们的FedGSP在所有异质性数据集中比第二好的方法平均高出3.28%的性能差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Since heterogeneity presents a fundamental challenge in graph federatedlearning, many existing methods are proposed to deal with node featureheterogeneity and structure heterogeneity. However, they overlook the criticalhomophily heterogeneity, which refers to the substantial variation in homophilylevels across graph data from different clients. The homophily level representsthe proportion of edges connecting nodes that belong to the same class. Due toadapting to their local homophily, local models capture inconsistent spectralproperties across different clients, significantly reducing the effectivenessof collaboration. Specifically, local models trained on graphs with highhomophily tend to capture low-frequency information, whereas local modelstrained on graphs with low homophily tend to capture high-frequencyinformation. To effectively deal with homophily heterophily, we introduce thespectral Graph Neural Network (GNN) and propose a novel Federated learningmethod by mining Graph Spectral Properties (FedGSP). On one hand, our proposedFedGSP enables clients to share generic spectral properties (i.e.,low-frequency information), allowing all clients to benefit throughcollaboration. On the other hand, inspired by our theoretical findings, ourproposed FedGSP allows clients to complement non-generic spectral properties byacquiring the spectral properties they lack (i.e., high-frequency information),thereby obtaining additional information gain. Extensive experiments conductedon six homophilic and five heterophilic graph datasets, across bothnon-overlapping and overlapping settings, validate the superiority of ourmethod over eleven state-of-the-art methods. Notably, our FedGSP outperformsthe second-best method by an average margin of 3.28% on all heterophilicdatasets.</description>
      <author>example@mail.com (Wentao Yu)</author>
      <guid isPermaLink="false">2502.13732v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Democratizing Large Language Model-Based Graph Data Augmentation via Latent Knowledge Graphs</title>
      <link>http://arxiv.org/abs/2502.13555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种黑盒上下文驱动的图数据增强方法，该方法利用大型语言模型（LLM）生成的知识图谱来丰富原始图数据。&lt;h4&gt;背景&lt;/h4&gt;图表示学习中由于图数据稀疏性和噪声问题，需要进行数据增强。现有的大多数增强方法忽视了来自数据集的上下文信息，并且依赖于图结构单一地进行数据增强。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于LLM指导的数据增强方法，以便更好地利用图数据中的上下文知识并提高预测性能和可解释性。&lt;h4&gt;方法&lt;/h4&gt;该方法通过使用文本提示作为与上下文相关的信息来引导LLM生成知识图谱，并设计了一种动态合并策略以随机地将生成的知识图谱合并到原始图中。同时，提出了一种粒度感知的指令微调模块，根据数据集的不同粒度级别无缝生成文本提示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明该方法在各种图学习任务上都优于现有图数据增强方法，并且特别适用于电子健康记录（EHR）等场景。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够最大化地利用上下文知识，从而提升预测性能和可解释性。此方法可以克服现有LLM封闭源代码的问题，使之为更多人所用。&lt;h4&gt;翻译&lt;/h4&gt;为了克服这些限制，我们提出了一个黑盒上下文驱动的图数据增强方法——DemoGraph，在大型语言模型的指导下进行操作。通过使用文本提示作为与上下文相关的信息，我们让大模型生成知识图谱，这使我们可以捕捉到从文本输出中的结构交互。然后，我们在训练过程中设计了一个动态合并策略，随机地将这些由LLM生成的知识图谱整合进原始图中。为了控制增强后的图的稀疏性，我们还开发了一种粒度感知提示策略和指令微调模块，这可以根据数据集的不同粒度级别无缝生成文本提示。在各种图学习任务上的广泛实验验证了我们的方法优于现有的图数据增强方法。特别地，在涉及电子健康记录（EHR）的情境下，我们的方法表现出色，表明其能够充分运用上下文知识，从而提升预测性能和可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data augmentation is necessary for graph representation learning due to thescarcity and noise present in graph data. Most of the existing augmentationmethods overlook the context information inherited from the dataset as theyrely solely on the graph structure for augmentation. Despite the success ofsome large language model-based (LLM) graph learning methods, they are mostlywhite-box which require access to the weights or latent features from theopen-access LLMs, making them difficult to be democratized for everyone asexisting LLMs are mostly closed-source for commercial considerations. Toovercome these limitations, we propose a black-box context-driven graph dataaugmentation approach, with the guidance of LLMs -- DemoGraph. Leveraging thetext prompt as context-related information, we task the LLM with generatingknowledge graphs (KGs), which allow us to capture the structural interactionsfrom the text outputs. We then design a dynamic merging schema tostochastically integrate the LLM-generated KGs into the original graph duringtraining. To control the sparsity of the augmented graph, we further devise agranularity-aware prompting strategy and an instruction fine-tuning module,which seamlessly generates text prompts according to different granularitylevels of the dataset. Extensive experiments on various graph learning tasksvalidate the effectiveness of our method over existing graph data augmentationmethods. Notably, our approach excels in scenarios involving electronic healthrecords (EHRs), which validates its maximal utilization of contextualknowledge, leading to enhanced predictive performance and interpretability.</description>
      <author>example@mail.com (Yushi Feng, Tsai Hor Chan, Guosheng Yin, Lequan Yu)</author>
      <guid isPermaLink="false">2502.13555v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Towards Invariance to Node Identifiers in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.13660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2411.02271&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的正则化方法，用于增强图神经网络（GNN）对于节点ID不变性的能力，提高了模型的泛化性能。&lt;h4&gt;背景&lt;/h4&gt;消息传递结构导致了图神经网络表达力受限的问题。添加唯一节点标识符可以打破限制表达力的基本对称性。&lt;h4&gt;目的&lt;/h4&gt;解决现有ID框架的关键局限，并提出一种新的方法来实现节点ID不变性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新的正则化技术，该技术能有效增强GNN对于节点ID的不变性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在现实世界和合成任务上，所提出的模型改善了节点ID不变性，进而提高了泛化性能。&lt;h4&gt;结论&lt;/h4&gt;新的正则化方法增强了图神经网络模型对节点标识符变化的鲁棒性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;消息传递图神经网络（GNN）由于其消息传递结构而被认为具有有限的表达力。一种规避这种限制的方法是添加独特的节点标识符，这打破了导致表达力受限的基本对称性。在这项工作中，我们指出了ID框架的关键局限，并提出了解决方案。我们首先观察到最终输出不应依赖于特定的ID。然后显示在实践中这是不成立的，这意味着学习网络并不具备所需的结构属性。可以通过几种方式强制执行节点ID不变性，我们将讨论它们的理论性质。接着我们提出了一种新的正则化方法，有效地增强了对网络中的ID不变性的要求。大量的真实世界和合成任务评估表明，我们的方法显著提高了ID不变性，并且在实践中通常也提升了泛化性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Message-Passing Graph Neural Networks (GNNs) are known to have limitedexpressive power, due to their message passing structure. One mechanism forcircumventing this limitation is to add unique node identifiers (IDs), whichbreak the symmetries that underlie the expressivity limitation. In this work,we highlight a key limitation of the ID framework, and propose an approach foraddressing it. We begin by observing that the final output of the GNN shouldclearly not depend on the specific IDs used. We then show that in practice thisdoes not hold, and thus the learned network does not possess this desiredstructural property. Such invariance to node IDs may be enforced in severalways, and we discuss their theoretical properties.  We then propose a novel regularization method that effectively enforces IDinvariance to the network. Extensive evaluations on both real-world andsynthetic tasks demonstrate that our approach significantly improves IDinvariance and, in turn, often boosts generalization performance.</description>
      <author>example@mail.com (Maya Bechler-Speicher, Moshe Eliasof, Carola-Bibiane Schonlieb, Ran Gilad-Bachrach, Amir Globerson)</author>
      <guid isPermaLink="false">2502.13660v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>CARE: Confidence-Aware Regression Estimation of building density fine-tuning EO Foundation Models</title>
      <link>http://arxiv.org/abs/2502.13734v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 3 figures, Submitted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Confidence-Aware Regression Estimation (CARE)的新模型，用于解决像素级回归任务中的置信度量化和评估问题。&lt;h4&gt;背景&lt;/h4&gt;在深度神经网络的实际应用中，准确地量化和评估信心是非常重要的。然而，在像素级别的回归任务（如建筑密度估计）中，这一方面还没有得到充分的研究。&lt;h4&gt;目的&lt;/h4&gt;开发并验证一种用于解决像素级回归问题的新模型CARE，并展示其相对于其他方法的优势。&lt;h4&gt;方法&lt;/h4&gt;提出了名为Confidence-Aware Regression Estimation (CARE)的模型。该模型可以为回归输出结果计算和分配置信度，从而更好地处理像素级回归任务。&lt;h4&gt;主要发现&lt;/h4&gt;在使用Copernicus Sentinel-2卫星数据进行实验时，显示提出的CARE方法能够成功应用于回归问题，并且其性能优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在解决像素级回归任务的置信度量化和评估方面表现出色，为实际应用中深度神经网络模型的表现改进提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;执行准确的信心量化和评估对于深度神经网络预测故障、提高性能以及增强其在现实世界中的能力至关重要。然而，与分类任务（如语义分割）相比，在像素级回归任务上这方面的问题并没有得到很好的解决。为了应对这一挑战，我们提出并训练了名为Confidence-Aware Regression Estimation (CARE)的模型。该模型计算并分配给回归输出结果信心值，并聚焦于作为地球观测(AI Foundation Model for Earth Observation, EO)下游任务的回归问题。实验结果显示，在估计建筑密度的任务上，所提出的CARE方法可以成功应用于回归问题，并且在Copernicus Sentinel-2卫星数据集上的表现优于其他方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Performing accurate confidence quantification and assessment is important fordeep neural networks to predict their failures, improve their performance andenhance their capabilities in real-world applications, for their practicaldeployment in real life. For pixel-wise regression tasks, confidencequantification and assessment has not been well addressed in the literature, incontrast to classification tasks like semantic segmentation. The softmax outputlayer is not used in deep neural networks that solve pixel-wise regressionproblems. In this paper, to address these problems, we develop, train andevaluate the proposed model Confidence-Aware Regression Estimation (CARE). Ourmodel CARE computes and assigns confidence to regression output results. Wefocus on solving regression problems as downstream tasks of an AI FoundationModel for Earth Observation (EO). We evaluate the proposed model CARE andexperimental results on data from the Copernicus Sentinel-2 satelliteconstellation for estimating the density of buildings show that the proposedmethod can be successfully applied to regression problems. We also show thatour approach outperforms other methods.</description>
      <author>example@mail.com (Nikolaos Dionelis, Jente Bosmans, Nicolas Longépé)</author>
      <guid isPermaLink="false">2502.13734v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Random Forest Autoencoders for Guided Representation Learning</title>
      <link>http://arxiv.org/abs/2502.13257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Random Forest Autoencoders (RF-AE)的新框架，用于解决监督可视化中的扩展性问题。&lt;h4&gt;背景&lt;/h4&gt;长期以来，无监督数据可视化方法已经非常成熟，而基于专家标签指导表示的监督可视化研究相对较少。尽管最近一种基于扩散和随机森林的方法RF-PHATE取得了一些进展，但其缺乏显式映射函数限制了它在大规模数据集和标签稀疏场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效地将新样本纳入现有模型，并保持高准确性和可解释性的框架。&lt;h4&gt;方法&lt;/h4&gt;RF-AE结合了自编码器的灵活性、随机森林的监督学习优势以及RF-PHATE所捕捉到的信息几何特性，形成了一种新的神经网络基础架构。它解决了RF-PHATE在扩展性上的问题并改善了性能。&lt;h4&gt;主要发现&lt;/h4&gt;RF-AE不仅在准确性和可解释性方面优于现有方法和标准内核扩展的RF-PHATE，还具有对超参数选择的鲁棒性和通用性。&lt;h4&gt;结论&lt;/h4&gt;通过利用自编码器、随机森林以及信息几何的优势，RF-AE为监督数据可视化提供了一种新的强大工具。它不仅能解决现存的方法在大规模或标签稀疏场景下的局限性问题，还能提高可视化的质量和实用性。&lt;h4&gt;翻译&lt;/h4&gt;数十年的研究产生了稳健的无监督数据可视化方法，而以专家标签指导表示的监督可视化研究仍然较少，因为大多数监督方法优先考虑分类而非可视化。最近，RF-PHATE，一种利用随机森林和信息几何的基于扩散的流形学习方法，在监督可视化方面取得了显著进展。然而，其缺乏显式映射函数限制了可扩展性和应用于未见数据的能力，对大型数据集和标签稀少场景提出了挑战。为了克服这些局限性，我们引入了一种名为Random Forest Autoencoders (RF-AE)的框架，这是一种基于神经网络的方法，结合了自编码器的灵活性、随机森林的学习优势以及RF-PHATE所捕捉到的信息几何特性。RF-AE使高效的未见数据监督可视化成为可能，并在准确性和可解释性方面超越了包括RF-PHATE的标准内核扩展在内的现有方法。此外，RF-AE对超参数的选择具有鲁棒性，并可以推广应用于任何基于内核的降维方法中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decades of research have produced robust methods for unsupervised datavisualization, yet supervised visualization$\unicode{x2013}$where expert labelsguide representations$\unicode{x2013}$remains underexplored, as most supervisedapproaches prioritize classification over visualization. Recently, RF-PHATE, adiffusion-based manifold learning method leveraging random forests andinformation geometry, marked significant progress in supervised visualization.However, its lack of an explicit mapping function limits scalability andprevents application to unseen data, posing challenges for large datasets andlabel-scarce scenarios. To overcome these limitations, we introduce RandomForest Autoencoders (RF-AE), a neural network-based framework for out-of-samplekernel extension that combines the flexibility of autoencoders with thesupervised learning strengths of random forests and the geometry captured byRF-PHATE. RF-AE enables efficient out-of-sample supervised visualization andoutperforms existing methods, including RF-PHATE's standard kernel extension,in both accuracy and interpretability. Additionally, RF-AE is robust to thechoice of hyper-parameters and generalizes to any kernel-based dimensionalityreduction method.</description>
      <author>example@mail.com (Adrien Aumon, Shuang Ni, Myriam Lizotte, Guy Wolf, Kevin R. Moon, Jake S. Rhodes)</author>
      <guid isPermaLink="false">2502.13257v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Adapting Large Language Models for Time Series Modeling via a Novel Parameter-efficient Adaptation Method</title>
      <link>http://arxiv.org/abs/2502.13725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;时间序列建模在许多现实世界的应用中具有重要意义，并且已经被广泛研究。虽然预训练基础模型在自然语言处理和计算机视觉领域取得了显著进展，但在时间序列领域的开发受到数据稀疏性的限制。&lt;h4&gt;背景&lt;/h4&gt;最近的研究表明，大型语言模型（LLMs）具备识别复杂令牌序列模式的稳健能力和推理能力。&lt;h4&gt;目的&lt;/h4&gt;为了实现时间序列和自然语言模态之间的高质量平衡，并保持推断效率，本文提出了Time-LlaMA框架。&lt;h4&gt;方法&lt;/h4&gt;首先，通过线性标记机制将时间序列输入转换为令牌嵌入。其次，对齐时间序列令牌嵌入与文本提示。第三，开发了一种动态低秩适应技术（D-LoRA），该技术在Transformer骨干网络的每一层中根据每个时间序列输入动态选择最合适的LoRA模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Time-LlaMA框架提出的改进方法在一系列具有挑战性的现实世界时间序列任务上达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;通过上述方法和创新技术的应用，该研究展示了预训练语言模型在时间序列建模中的强大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于时间序列建模的重要性和现状，并提出了一个新的框架Time-LlaMA来解决当前文献中存在的问题。该框架包括将时间序列输入转换为令牌嵌入、对齐文本提示和动态低秩适应技术等方法，从而实现了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series modeling holds significant importance in many real-worldapplications and has been extensively studied. While pre-trained foundationmodels have made impressive strides in the fields of natural languageprocessing (NLP) and computer vision (CV), their development in time seriesdomains has been constrained by data sparsity. A series of recent studies havedemonstrated that large language models (LLMs) possess robust patternrecognition and reasoning abilities over complex sequences of tokens. However,the current literature have yet striked a high-quality balance between (a)effectively aligning the time series and natural language modalities, and (b)keeping the inference efficiency. To address the above issues, we now proposethe Time-LlaMA framework. Time-LlaMA first converts the time series input intotoken embeddings through a linear tokenization mechanism. Second, the timeseries token embeddings are aligned with the text prompts. Third, to furtheradapt the LLM backbone for time series modeling, we have developed a dynamiclow-rank adaptation technique (D-LoRA). D-LoRA dynamically chooses the mostsuitable LoRA modules at each layer of the Transformer backbone for each timeseries input, enhancing the model's predictive capabilities. Our experimentalresults on an extensive collection of challenging real-world time series tasksconfirm that our proposed method achieves the state-of-the-art (SOTA)performance.</description>
      <author>example@mail.com (Juyuan Zhang, Wei Zhu, Jiechao Gao)</author>
      <guid isPermaLink="false">2502.13725v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Uncertain Multi-Objective Recommendation via Orthogonal Meta-Learning Enhanced Bayesian Optimization</title>
      <link>http://arxiv.org/abs/2502.13180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新型推荐系统框架，该框架借鉴了自动驾驶汽车的分类方法，并将其应用于推荐系统的自主性水平上。这个框架旨在提升用户个性化体验的同时减少负面效应如回音室效应。&lt;h4&gt;背景&lt;/h4&gt;传统的推荐系统研究主要关注提高推荐准确率，这往往会带来诸如形成回音室等意外后果，限制用户的互动方式。&lt;h4&gt;目的&lt;/h4&gt;通过引入一个动态的多目标优化方法来响应不同用户的多样化需求（例如准确性、多样性和平等性），促进更加智能和伦理化的个性化推荐体验。&lt;h4&gt;方法&lt;/h4&gt;开发了一个基于贝叶斯优化框架的方法来处理不确定性并捕捉用户在多个目标之间的个人偏好，同时利用正交元学习范式提高效率。&lt;h4&gt;主要发现&lt;/h4&gt;该研究展示了一种有效的方式以根据个体用户的不确定多目标需求进行最优化。&lt;h4&gt;结论&lt;/h4&gt;研究表明新的推荐系统方法能够适应性和集中于用户体验的提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems (RSs) play a crucial role in shaping our digitalinteractions, influencing how we access and engage with information acrossvarious domains. Traditional research has predominantly centered on maximizingrecommendation accuracy, often leading to unintended side effects such as echochambers and constrained user experiences. Drawing inspiration from autonomousdriving, we introduce a novel framework that categorizes RS autonomy into fivedistinct levels, ranging from basic rule-based accuracy-driven systems tobehavior-aware, uncertain multi-objective RSs - where users may have varyingneeds, such as accuracy, diversity, and fairness. In response, we propose anapproach that dynamically identifies and optimizes multiple objectives based onindividual user preferences, fostering more ethical and intelligentuser-centric recommendations. To navigate the uncertainty inherent inmulti-objective RSs, we develop a Bayesian optimization (BO) framework thatcaptures personalized trade-offs between different objectives while accountingfor their uncertain interdependencies. Furthermore, we introduce an orthogonalmeta-learning paradigm to enhance BO efficiency and effectiveness by leveragingshared knowledge across similar tasks and mitigating conflicts among objectivesthrough the discovery of orthogonal information. Finally, extensive empiricalevaluations demonstrate the effectiveness of our method in optimizing uncertainmulti-objectives for individual users, paving the way for more adaptive anduser-focused RSs.</description>
      <author>example@mail.com (Hongxu Wang, Zhu Sun, Yingpeng Du, Lu Zhang, Tiantian He, Yew-Soon Ong)</author>
      <guid isPermaLink="false">2502.13180v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>AS-GCL: Asymmetric Spectral Augmentation on Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.13525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TMM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;图对比学习（GCL）已经成为图结构数据自监督学习的主要方法。然而，现有的GCL方法通常依赖于一致的随机增强，这忽视了它们对谱域内固有结构的影响，从而限制了模型的有效泛化能力。&lt;h4&gt;背景&lt;/h4&gt;图对比学习是一种用于图结构数据的自监督学习方法，通过从各种增强视图中学习鲁棒表示来减少对标记数据的依赖。然而，现有的GCL方法忽视了它们对谱域内固有结构的影响。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法的局限性，提出了一种新的范式——AS-GCL，它将不对称光谱增强引入到图对比学习中。&lt;h4&gt;方法&lt;/h4&gt;我们的方法在数据增强、视图编码和对比损失三个关键组成部分上都进行了显著改进。具体来说，在数据增强方面，我们采用了基于谱的增强来最小化谱变异性，并减少噪声；在编码过程中，使用具有不同扩散操作符的参数共享编码器生成多样且抗噪的图视图；对于对比损失，引入了上限损失函数以保持类内和类间距离分布的平衡。&lt;h4&gt;主要发现&lt;/h4&gt;我们是首次利用不对称编码器对谱域中的增强视图进行编码的方法。大量的实验在八种基准数据集上证明了所提出方法的优势。&lt;h4&gt;结论&lt;/h4&gt;所提出的AS-GCL范式通过引入不对称光谱增强和改进的对比损失函数，提高了模型的泛化能力，并在多个节点级任务上的表现优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;Graph Contrastive Learning (GCL) has emerged as the foremost approach for self-supervised learning on graph-structured data. GCL reduces reliance on labeled data by learning robust representations from various augmented views. However, existing GCL methods typically depend on consistent stochastic augmentations, which overlook their impact on the intrinsic structure of the spectral domain, thereby limiting the model's ability to generalize effectively. To address these limitations, we propose a novel paradigm called AS-GCL that incorporates asymmetric spectral augmentation for graph contrastive learning. A typical GCL framework consists of three key components: graph data augmentation, view encoding, and contrastive loss. Our method introduces significant enhancements to each of these components. Specifically, for data augmentation, we apply spectral-based augmentation to minimize spectral variations, strengthen structural invariance, and reduce noise. With respect to encoding, we employ parameter-sharing encoders with distinct diffusion operators to generate diverse, noise-resistant graph views. For contrastive loss, we introduce an upper-bound loss function that promotes generalization by maintaining a balanced distribution of intra- and inter-class distance. To our knowledge, we are the first to encode augmentation views of the spectral domain using asymmetric encoders. Extensive experiments on eight benchmark datasets across various node-level tasks demonstrate the advantages of the proposed method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning (GCL) has emerged as the foremost approach forself-supervised learning on graph-structured data. GCL reduces reliance onlabeled data by learning robust representations from various augmented views.However, existing GCL methods typically depend on consistent stochasticaugmentations, which overlook their impact on the intrinsic structure of thespectral domain, thereby limiting the model's ability to generalizeeffectively. To address these limitations, we propose a novel paradigm calledAS-GCL that incorporates asymmetric spectral augmentation for graph contrastivelearning. A typical GCL framework consists of three key components: graph dataaugmentation, view encoding, and contrastive loss. Our method introducessignificant enhancements to each of these components. Specifically, for dataaugmentation, we apply spectral-based augmentation to minimize spectralvariations, strengthen structural invariance, and reduce noise. With respect toencoding, we employ parameter-sharing encoders with distinct diffusionoperators to generate diverse, noise-resistant graph views. For contrastiveloss, we introduce an upper-bound loss function that promotes generalization bymaintaining a balanced distribution of intra- and inter-class distance. To ourknowledge, we are the first to encode augmentation views of the spectral domainusing asymmetric encoders. Extensive experiments on eight benchmark datasetsacross various node-level tasks demonstrate the advantages of the proposedmethod.</description>
      <author>example@mail.com (Ruyue Liu, Rong Yin, Yong Liu, Xiaoshuai Hao, Haichao Shi, Can Ma, Weiping Wang)</author>
      <guid isPermaLink="false">2502.13525v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>HyperGCL: Multi-Modal Graph Contrastive Learning via Learnable Hypergraph Views</title>
      <link>http://arxiv.org/abs/2502.13277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种基于超图视角的多模态对比学习框架HyperGCL，该框架通过自适应拓扑增强技术来改进图表示。&lt;h4&gt;背景&lt;/h4&gt;现有Graph Contrastive Learning（GCL）方法依赖于预定义的数据增强方式，在任务相关的信息保留和对不同输入数据的适应性方面存在不足。同时，负样本的选择问题也未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于超图视角的多模态GCL框架HyperGCL，以解决现有模型在图表示改进中的局限性。&lt;h4&gt;方法&lt;/h4&gt;HyperGCL通过联合利用输入图结构和属性信息构造三个不同的超图视图，并使用可学习的自适应拓扑增强技术来优化这些视图。引入特定于视图的编码器来捕捉每个视图的关键特征，同时采用网络感知对比损失定义正负样本。&lt;h4&gt;主要发现&lt;/h4&gt;HyperGCL在基准数据集上的实验结果表明，其在节点分类任务上达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的框架通过创新地融合了超图和多模态学习策略，在改进图表示方面展示了显著的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Graph Contrastive Learning (GCL) have demonstratedremarkable effectiveness in improving graph representations. However, relyingon predefined augmentations (e.g., node dropping, edge perturbation, attributemasking) may result in the loss of task-relevant information and a lack ofadaptability to diverse input data. Furthermore, the selection of negativesamples remains rarely explored. In this paper, we introduce HyperGCL, a novelmultimodal GCL framework from a hypergraph perspective. HyperGCL constructsthree distinct hypergraph views by jointly utilizing the input graph'sstructure and attributes, enabling a comprehensive integration of multiplemodalities in contrastive learning. A learnable adaptive topology augmentationtechnique enhances these views by preserving important relations and filteringout noise. View-specific encoders capture essential characteristics from eachview, while a network-aware contrastive loss leverages the underlying topologyto define positive and negative samples effectively. Extensive experiments onbenchmark datasets demonstrate that HyperGCL achieves state-of-the-art nodeclassification performance.</description>
      <author>example@mail.com (Khaled Mohammed Saifuddin, Jonathan Shihao Ji, Esra Akbas)</author>
      <guid isPermaLink="false">2502.13277v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>The impact of conformer quality on learned representations of molecular conformer ensembles</title>
      <link>http://arxiv.org/abs/2502.13220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了机器学习模型预测分子构象集合性质时输入的3D构象质量对模型性能的影响。&lt;h4&gt;背景&lt;/h4&gt;训练机器学习模型来预测分子构象集合的性质已成为加速药物类似小分子、反应性有机底物和均相催化剂构象分析的一种流行策略。特别是对于高通量分析，经过训练的代理模型可以帮助规避依赖昂贵构象搜索和几何优化的传统方法。&lt;h4&gt;目的&lt;/h4&gt;研究较低质量的3D构象如何影响对高质量构象性质预测的效果；探讨随机构象的几何优化精度在编码中的重要性；探究包含引发目标属性活性构象的集合对于模型准确性的影响；比较代理模型预测与直接从便宜的构象集合估计性质的方法。&lt;h4&gt;方法&lt;/h4&gt;在基于密度泛函理论优化的构象集合中，研究了Sterimol参数的预测情况。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明3D表示学习模型的表现取决于输入数据的质量。较低质量的3D构象可能无法准确预测高质量构象的特性；随机构象的几何精度对于编码的效果至关重要；当活性构象存在时，能够提高模型的准确性；直接从便宜集合估计性质的方法有时可以与代理模型预测的结果相媲美。&lt;h4&gt;结论&lt;/h4&gt;虽然具体问题的答案会因情况而异，但研究提供了关于3D表示学习模型和构象质量重要性的宝贵见解，并提出了实际考虑因素。&lt;h4&gt;翻译&lt;/h4&gt;训练机器学习模型以预测分子构象集合的性质已成为加速药物类似小分子、反应性有机底物和均相催化剂构象分析的一种流行策略。尤其是高通量分析，经过训练的代理模型可以帮助规避依赖昂贵构象搜索和几何优化的传统方法。在这里，我们质疑所用3D构象质量对预测单一活性构象依赖性质的性能的影响。较低质量的构象能否准确反映高质量构象的性质？随机构象编码时，几何优化精度是否重要？对于将一系列构象作为输入的模型来说，目标属性引发活性构象的存在如何影响准确性？代理模型的预测与从便宜集合中估计性质的方法相比如何？我们在此背景下探讨了基于密度泛函理论优化的构象集合Sterimol参数的预测情况。虽然答案会因具体情况而异，但我们的分析提供了关于3D表示学习模型的重要视角，并提出了实际考虑因素，即何时构象质量很重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training machine learning models to predict properties of molecular conformerensembles is an increasingly popular strategy to accelerate the conformationalanalysis of drug-like small molecules, reactive organic substrates, andhomogeneous catalysts. For high-throughput analyses especially, trainedsurrogate models can help circumvent traditional approaches to conformationalanalysis that rely on expensive conformer searches and geometry optimizations.Here, we question how the performance of surrogate models for predicting 3Dconformer-dependent properties (of a single, active conformer) is affected bythe quality of the 3D conformers used as their input. How well do lower-qualityconformers inform the prediction of properties of higher-quality conformers?Does the fidelity of geometry optimization matter when encoding randomconformers? For models that encode sets of conformers, how does the presence ofthe active conformer that induces the target property affect model accuracy?How do predictions from a surrogate model compare to estimating the propertiesfrom cheap ensembles themselves? We explore these questions in the context ofpredicting Sterimol parameters of conformer ensembles optimized with densityfunctional theory. Although answers will be case-specific, our analyses providea valuable perspective on 3D representation learning models and raise practicalconsiderations regarding when conformer quality matters.</description>
      <author>example@mail.com (Keir Adams, Connor W. Coley)</author>
      <guid isPermaLink="false">2502.13220v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Integration of Agentic AI with 6G Networks for Mission-Critical Applications: Use-case and Challenges</title>
      <link>http://arxiv.org/abs/2502.13476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  FEMA  [https://www.fema.gov/openfema-data-page/disaster-declarations-summaries-v2]  National Oceanic and Atmospheric Administration  [https://www.ncdc.noaa.gov/stormevents/details.jsp] packages Pytorch  [https://pytorch.org/] RLib [https://docs.ray.io/en/latest/rllib/index.html]  Neo4j [https://neo4j.com/] Apache Kafka [https://kafka.apache.org/]&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新型的代理人工智能（AAI）框架，用于关键任务的安全应用。该框架具有多层架构，并通过详细实现的AAI层将网络基础设施与关键任务应用程序连接起来。&lt;h4&gt;背景&lt;/h4&gt;随着AI技术的进步，特别是基础模型的发展，AI已经成为许多依赖自动化服务交付的应用程序的重要组成部分之一，其中包括对公共安全至关重要的使命级应用。&lt;h4&gt;目的&lt;/h4&gt;提出一个基于代理的人工智能框架用于关键任务应用，以解决传统AI系统中人机交互的问题和在维持情境感知的同时缺乏适应动态条件的能力问题。&lt;h4&gt;方法&lt;/h4&gt;本研究设计了一个具有多层架构的新型AAI框架，并实现了一种新的AAI层，该层连接网络基础设施与关键任务应用程序，使其能够快速分析文本数据并迅速适应环境变化。&lt;h4&gt;主要发现&lt;/h4&gt;初步分析表明，所提出的AAI框架可以将初始响应时间平均减少5.6分钟，警报生成时间平均缩短15.6秒，并且资源分配提高了最多13.4%。此外，它还可以使并发操作数增加40个，从而最多可减少恢复时间至多5.2分钟。&lt;h4&gt;结论&lt;/h4&gt;本文展示了AAI框架在关键任务应用中的有效性及优势，但同时也指出了实施过程中需考虑的一些问题和挑战。&lt;h4&gt;翻译&lt;/h4&gt;我们正处于一个变革的时代，人工智能（AI）的进步，尤其是基础模型的发展，一直在新闻中占据重要位置。AI已经成为许多依赖自动化服务交付的应用程序的重要组成部分之一，其中包括对公共安全至关重要的使命级应用。关键任务型AI应用程序的问题在于人机交互系统及在保持情境感知的同时缺乏适应动态条件的能力。由于代理人工智能（AAI）能够通过上下文分析文本数据并快速适应环境变化，因此最近它得到了广泛关注。在此背景下，本文提出了一种用于关键任务应用的AAI框架。我们提出了一个具有多层架构的新框架来实现AAI，并展示了一个详细的AAI实施，以弥合网络基础设施与关键任务应用程序之间的差距。我们的初步分析表明，AAI平均减少了5.6分钟的初始响应时间，警报生成时间平均缩短了15.6秒，资源分配最多提高了13.4%。我们还展示了AAI方法使并发操作数增加40个，从而最多可减少恢复时间至多5.2分钟。最后，我们强调了一些在实现AAI框架时需要考虑的问题和挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We are in a transformative era, and advances in Artificial Intelligence (AI),especially the foundational models, are constantly in the news. AI has been anintegral part of many applications that rely on automation for servicedelivery, and one of them is mission-critical public safety applications. Theproblem with AI-oriented mission-critical applications is the humanin-the-loopsystem and the lack of adaptability to dynamic conditions while maintainingsituational awareness. Agentic AI (AAI) has gained a lot of attention recentlydue to its ability to analyze textual data through a contextual lens whilequickly adapting to conditions. In this context, this paper proposes an AAIframework for mission-critical applications. We propose a novel framework witha multi-layer architecture to realize the AAI. We also present a detailedimplementation of AAI layer that bridges the gap between network infrastructureand missioncritical applications. Our preliminary analysis shows that the AAIreduces initial response time by 5.6 minutes on average, while alert generationtime is reduced by 15.6 seconds on average and resource allocation is improvedby up to 13.4%. We also show that the AAI methods improve the number ofconcurrent operations by 40, which reduces the recovery time by up to 5.2minutes. Finally, we highlight some of the issues and challenges that need tobe considered when implementing AAI frameworks.</description>
      <author>example@mail.com (Sunder Ali Khowaja, Kapal Dev, Muhammad Salman Pathan, Engin Zeydan, Merouane Debbah)</author>
      <guid isPermaLink="false">2502.13476v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>NoKSR: Kernel-Free Neural Surface Reconstruction via Point Cloud Serialization</title>
      <link>http://arxiv.org/abs/2502.12534v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: see https://theialab.github.io/noksr/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新的大规模点云曲面重建方法，通过开发了一个高效的框架将不规则的点云转换为带符号的距离场（Signed Distance Field, SDF）。&lt;h4&gt;背景&lt;/h4&gt;当前基于Transformer架构的方法能够处理点云数据，但需要有效的序列化以保持局部性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的高效框架用于大规模点云曲面重建，并通过序列化方法将点云转换为SDF。&lt;h4&gt;方法&lt;/h4&gt;采用最近的基于Transformer的架构（如PointTransformerV3），该架构能够按保序的方式序列化点云。在预测某一点处的SDF值时，可以利用附近token的有效聚集来快速近似找到邻居。同时，在不同的层级/尺度下序列化点云，并通过非线性地聚合特征来预测SDF值。&lt;h4&gt;主要发现&lt;/h4&gt;跨多个尺度进行聚合对于克服序列化引入的近似误差（即局部邻域中的假阴性）至关重要，这有助于提高重建精度和效率。该框架在准确性和效率上均优于现有方法，在户外数据集上尤其表现出色，尤其是在稀疏网格方法表现不佳的情况下。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架通过结合序列化点云和多尺度特征聚合的方法，实现了前所未有的性能优势，并且具有更简单的实现方式。&lt;h4&gt;翻译&lt;/h4&gt;We present a novel approach to large-scale point cloud surface reconstruction by developing an efficient framework that converts an irregular point cloud into a signed distance field (SDF). Our backbone builds upon recent transformer-based architectures (i.e., PointTransformerV3), that serializes the point cloud into a locality-preserving sequence of tokens. We efficiently predict the SDF value at a point by aggregating nearby tokens, where fast approximate neighbors can be retrieved thanks to the serialization. We serialize the point cloud at different levels/scales, and non-linearly aggregate a feature to predict the SDF value. We show that aggregating across multiple scales is critical to overcome the approximations introduced by the serialization (i.e., false negatives in the neighborhood). Our framework sets the new state-of-the-art in terms of accuracy and efficiency (better or similar performance with half the latency of the best prior method, coupled with a simpler implementation), particularly on outdoor datasets where sparse-grid methods have shown limited performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel approach to large-scale point cloud surface reconstructionby developing an efficient framework that converts an irregular point cloudinto a signed distance field (SDF). Our backbone builds upon recenttransformer-based architectures (i.e., PointTransformerV3), that serializes thepoint cloud into a locality-preserving sequence of tokens. We efficientlypredict the SDF value at a point by aggregating nearby tokens, where fastapproximate neighbors can be retrieved thanks to the serialization. Weserialize the point cloud at different levels/scales, and non-linearlyaggregate a feature to predict the SDF value. We show that aggregating acrossmultiple scales is critical to overcome the approximations introduced by theserialization (i.e. false negatives in the neighborhood). Our frameworks setsthe new state-of-the-art in terms of accuracy and efficiency (better or similarperformance with half the latency of the best prior method, coupled with asimpler implementation), particularly on outdoor datasets where sparse-gridmethods have shown limited performance.</description>
      <author>example@mail.com (Zhen Li, Weiwei Sun, Shrisudhan Govindarajan, Shaobo Xia, Daniel Rebain, Kwang Moo Yi, Andrea Tagliasacchi)</author>
      <guid isPermaLink="false">2502.12534v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Are Large Language Models In-Context Graph Learners?</title>
      <link>http://arxiv.org/abs/2502.13562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '大型语言模型（LLMs）在处理各种任务中表现出了出色的上下文推理能力，尤其是在面对非结构化数据时。然而，在处理图形等结构化数据方面存在不足。', '背景': 'LLMs缺乏对非欧几里得结构的理解，导致它们无法有效处理图学习任务中的结构化数据，并且其性能远低于专门的图神经网络（GNNs）。', '目的': '提出一种基于检索增强生成（RAG）过程的概念框架来改进LLMs在图形学习任务中的上下文学习能力。', '方法': '将图形数据的学习过程视为一个查询和从图中检索出背景信息的过程，进而开发了一系列增强LLM性能的RAG框架。', '主要发现': '实验表明这些提出的RAG框架显著提升了LLM在基于图形的任务上的表现，特别是在需要使用预训练的LLM而无需修改或通过API访问的情况下。', '结论': '该方法为改进大型语言模型处理结构化数据的能力提供了一种有效途径。', '翻译': '大型语言模型（LLMs）在各种任务中展示了显著的上下文推理能力，尤其是对于非结构化的输入如语言和图像等。然而，在无额外微调的情况下，它们难以处理图形这样的结构化数据，并且其性能远低于专门用于图学习任务的图神经网络（GNNs）。本文展示了一种通过将基于图的数据的学习看作是检索增强生成（RAG）过程来提升LLM在图学习上的上下文学习能力的方法。一系列实验表明，这些提出的RAG框架能够显著改善LLMs处理图形相关任务的表现，尤其适用于无需修改的预训练LLM或API访问场景中。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have demonstrated remarkable in-contextreasoning capabilities across a wide range of tasks, particularly withunstructured inputs such as language or images. However, LLMs struggle tohandle structured data, such as graphs, due to their lack of understanding ofnon-Euclidean structures. As a result, without additional fine-tuning, theirperformance significantly lags behind that of graph neural networks (GNNs) ingraph learning tasks. In this paper, we show that learning on graph data can beconceptualized as a retrieval-augmented generation (RAG) process, wherespecific instances (e.g., nodes or edges) act as queries, and the graph itselfserves as the retrieved context. Building on this insight, we propose a seriesof RAG frameworks to enhance the in-context learning capabilities of LLMs forgraph learning tasks. Comprehensive evaluations demonstrate that our proposedRAG frameworks significantly improve LLM performance on graph-based tasks,particularly in scenarios where a pretrained LLM must be used withoutmodification or accessed via an API.</description>
      <author>example@mail.com (Jintang Li, Ruofan Wu, Yuchang Zhu, Huizhe Zhang, Liang Chen, Zibin Zheng)</author>
      <guid isPermaLink="false">2502.13562v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Some Insights of Construction of Feature Graph to Learn Pairwise Feature Interactions with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.13471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is the draft before submitting to any journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了特征交互在图神经网络（GNN）模型中的重要性，通过实验揭示了有效的特征交互建模需要保留相互作用的特征之间的边缘，并避免非交互边缘带来的噪音。&lt;h4&gt;背景&lt;/h4&gt;特征交互对于预测机器学习模型至关重要，因为它捕捉到了影响模型性能的特征之间关系。此工作关注成对交互并研究其在构建用于GNN的特征图中的重要性。&lt;h4&gt;目的&lt;/h4&gt;利用现有的GNN模型和工具来探索特征图结构与其建模交互有效性的关系，并提供稀疏特征选择的理论支持。&lt;h4&gt;方法&lt;/h4&gt;通过对合成数据集进行实验，研究了边缘对GNN在建模特征交互上的影响。使用MDL原理来证明保持必要相互作用边界的特征图比完全图更高效且可解释性更强。&lt;h4&gt;主要发现&lt;/h4&gt;1. 互作用特征之间的边对于有效建模特征交互是重要的。2. 包含非互动边缘会引入噪音，降低模型性能。3. 使用MDL原理可以有效地选择稀疏的特征图。&lt;h4&gt;结论&lt;/h4&gt;研究结果提供了有关设计能够提高GNN模型性能和可解释性的特征图的理论见解和实用指南。&lt;h4&gt;翻译&lt;/h4&gt;特性交互在预测机器学习模型中至关重要，因为它捕获了影响模型性能的特性之间的关系。在这项工作中，我们专注于成对互动，并探讨其在为图神经网络（GNN）构建特征图中的重要性。我们并没有提出新的方法，而是利用现有的GNN模型和工具来探索特征图结构及其建模交互的有效性的关系。通过合成数据集上的实验，我们发现相互作用的特性之间的边缘对于使GNN能够有效建模特性互动是重要的。我们也观察到包括非互动边可以作为噪音降低模型性能。此外，我们使用最小描述长度（MDL）原则提供了稀疏特征图选择的理论依据。我们证明了只保留必要交互边界的特征图比完整图更高效且可解释性更强，这与奥卡姆剃刀原理一致。我们的发现为设计改进GNN模型性能和可解释性的特征图提供理论见解和实用指南。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Feature interaction is crucial in predictive machine learning models, as itcaptures the relationships between features that influence model performance.In this work, we focus on pairwise interactions and investigate theirimportance in constructing feature graphs for Graph Neural Networks (GNNs).Rather than proposing new methods, we leverage existing GNN models and tools toexplore the relationship between feature graph structures and theireffectiveness in modeling interactions. Through experiments on synthesizeddatasets, we uncover that edges between interacting features are important forenabling GNNs to model feature interactions effectively. We also observe thatincluding non-interaction edges can act as noise, degrading model performance.Furthermore, we provide theoretical support for sparse feature graph selectionusing the Minimum Description Length (MDL) principle. We prove that featuregraphs retaining only necessary interaction edges yield a more efficient andinterpretable representation than complete graphs, aligning with Occam's Razor.  Our findings offer both theoretical insights and practical guidelines fordesigning feature graphs that improve the performance and interpretability ofGNN models.</description>
      <author>example@mail.com (Phaphontee Yamchote, Saw Nay Htet Win, Chainarong Amornbunchornvej, Thanapon Noraset)</author>
      <guid isPermaLink="false">2502.13471v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>How Expressive are Knowledge Graph Foundation Models?</title>
      <link>http://arxiv.org/abs/2502.13339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文对知识图谱基础模型（KGFMs）的表达能力进行了严格的理论研究，揭示了其在处理不同关系词汇的新知识图谱时具有的泛化能力，并发现最典型的学习动机是二元性的，这限制了模型的表现力。设计并验证了使用更丰富的学习动机构建的KGFMs可以提高模型性能。&lt;h4&gt;背景&lt;/h4&gt;知识图谱基础模型（KGFMs）在深度学习领域的知识图谱处理中具有前沿地位，能够对全新的、关系词汇不同的知识图谱进行泛化处理。然而尽管其实验效果良好，对其理论理解仍十分有限。&lt;h4&gt;目的&lt;/h4&gt;探讨并明确KGFMs的表达能力及其依赖的学习动机的关系，提出使用更丰富动机设计更具表现力的KGFMs，并通过实证研究验证这些理论发现。&lt;h4&gt;方法&lt;/h4&gt;首先分析现有文献中典型的学习动机（二元性），然后设计基于三元关系交互来学习关系表示的更加丰富的学习动机，并构建相应的KGFMs。进行广泛的实验，以测试和验证不同的模型在不同领域的数据集上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;KGFMs的表现力直接依赖于用于学习关系表示的学习动机。二元性动机限制了表现力；基于三元关系交互的更丰富的动机可以提高模型的表现能力。&lt;h4&gt;结论&lt;/h4&gt;使用更丰富和复杂动机设计的知识图谱基础模型能够显著提升在各种领域数据集上的性能，这为KGFMs的设计提供了新的理论指导。&lt;h4&gt;翻译&lt;/h4&gt;Knowledge Graph Foundation Models (KGFMs) are at the frontier for deep learning on knowledge graphs, as they can generalize to completely novel knowledge graphs with different relational vocabularies. Despite their empirical success, our theoretical understanding of KGFMs remains very limited. In this paper, we conduct a rigorous study of the expressive power of KGFMs. Specifically, we show that the expressive power of KGFMs directly depends on the motifs used for learning relation representations. We then observe that the most typical motifs used in existing literature are binary, as the representations are learned based on how pairs of relations interact, which limits model expressiveness. As part of our study, we design more expressive KGFMs using richer motifs, necessitating learning relation representations based on how triples of relations interact with each other. Finally, we empirically validate our theoretical findings, showing that the use of richer motifs results in better performance on a wide range of datasets drawn from different domains.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge Graph Foundation Models (KGFMs) are at the frontier for deeplearning on knowledge graphs (KGs), as they can generalize to completely novelknowledge graphs with different relational vocabularies. Despite theirempirical success, our theoretical understanding of KGFMs remains very limited.In this paper, we conduct a rigorous study of the expressive power of KGFMs.Specifically, we show that the expressive power of KGFMs directly depends onthe motifs that are used to learn the relation representations. We then observethat the most typical motifs used in the existing literature are binary, as therepresentations are learned based on how pairs of relations interact, whichlimits the model's expressiveness. As part of our study, we design moreexpressive KGFMs using richer motifs, which necessitate learning relationrepresentations based on, e.g., how triples of relations interact with eachother. Finally, we empirically validate our theoretical findings, showing thatthe use of richer motifs results in better performance on a wide range ofdatasets drawn from different domains.</description>
      <author>example@mail.com (Xingyue Huang, Pablo Barceló, Michael M. Bronstein, İsmail İlkan Ceylan, Mikhail Galkin, Juan L Reutter, Miguel Romero Orth)</author>
      <guid isPermaLink="false">2502.13339v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Towards Fusing Point Cloud and Visual Representations for Imitation Learning</title>
      <link>http://arxiv.org/abs/2502.12320v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的模仿学习方法FPV-Net，该方法能够有效地结合点云和RGB图像的优点，在复杂的RoboCasa基准测试中取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;手动操作的学习需要使用可以访问丰富的感官信息（如点云或RGB图象）的策略。点云在捕获几何结构方面非常有效，而RGB图像则提供了重要的纹理和语义信息。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法将2D图像特征映射到点云时丢失全局上下文信息的问题，提出了一种新的模仿学习方法FPV-Net。&lt;h4&gt;方法&lt;/h4&gt;该方法通过使用自适应层范数条件化使点云编码器依赖于全局和局部图象令牌，从而结合了两种模态的优点。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在复杂基准测试中，仅依靠单一模式存在局限性，并且FPV-Net在所有任务上都达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过有效融合点云和RGB图像的优势解决了现有技术的不足，展示了其广泛的适用性和优越性。&lt;h4&gt;翻译&lt;/h4&gt;模仿学习需要使用具有丰富感觉信息（如点云或RGB图象）访问策略。点云有效地捕获几何结构，在模拟学习中的操作任务中至关重要。相比之下，RGB图象提供重要的纹理和语义信息，对于某些任务来说是必不可少的。现有融合两种模态的方法将2D图像特征分配给点云，但往往会丢失原始图像的整体上下文信息。在本文工作中，我们提出了FPV-Net，这是一种新的模仿学习方法，有效结合了点云和RGB模式的优点。我们的方法通过使用自适应层范数条件化使点云编码器依赖于全局和局部图象令牌来利用两种模式的有利特性。在具有挑战性的RoboCasa基准测试中进行广泛的实验表明，在复杂任务中仅依靠一种模态存在局限性，并且我们证明了该方法在整个任务上都达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning for manipulation requires using policies that have access to richsensory information such as point clouds or RGB images. Point cloudsefficiently capture geometric structures, making them essential formanipulation tasks in imitation learning. In contrast, RGB images provide richtexture and semantic information that can be crucial for certain tasks.Existing approaches for fusing both modalities assign 2D image features topoint clouds. However, such approaches often lose global contextual informationfrom the original images. In this work, we propose FPV-Net, a novel imitationlearning method that effectively combines the strengths of both point cloud andRGB modalities. Our method conditions the point-cloud encoder on global andlocal image tokens using adaptive layer norm conditioning, leveraging thebeneficial properties of both modalities. Through extensive experiments on thechallenging RoboCasa benchmark, we demonstrate the limitations of relying oneither modality alone and show that our method achieves state-of-the-artperformance across all tasks.</description>
      <author>example@mail.com (Atalay Donat, Xiaogang Jia, Xi Huang, Aleksandar Taranovic, Denis Blessing, Ge Li, Hongyi Zhou, Hanyi Zhang, Rudolf Lioutikov, Gerhard Neumann)</author>
      <guid isPermaLink="false">2502.12320v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>K-Paths: Reasoning over Graph Paths for Drug Repurposing and Drug Interaction Prediction</title>
      <link>http://arxiv.org/abs/2502.13344v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;K-Paths 是一种从大规模生物医学知识图谱中提取结构化、多样性和生物学意义路径的检索框架，该框架可促进大语言模型和图神经网络有效预测未观察到的药物间及药物与疾病间的相互作用。&lt;h4&gt;背景&lt;/h4&gt;药物发现是一个复杂且耗时的过程，需要识别和验证新的治疗候选者。利用大规模生物医学知识图谱（KGs）的计算方法为加速这一过程提供了可能的解决方案，但从中提取有意义的信息仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以与大语言模型和其他模型兼容的方法来从大规模 KGs 中提取结构化路径，并提高药物再定位和相互作用严重性预测的零样本性能。&lt;h4&gt;方法&lt;/h4&gt;K-Paths 框架利用 Yen 算法的一种多样性感知变体，检索查询中实体之间的 K 条最短无环路径，优先考虑生物学相关的多样关系。将这些路径转换为结构化格式以供大语言模型直接处理。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的实验表明，K-Paths 能够显著提高 Llama 8.1B 和 Llama 70B 的 F1 分数，在药物再定位和相互作用严重性预测中分别提高了12.45分和6.18分。此外，它还能有效降低知识图谱的规模并维持强大的预测性能。&lt;h4&gt;结论&lt;/h4&gt;K-Paths 提供了一种连接 KGs 和 LLM 的新方法，为药物发现提供了可解释的基础，并且在提高零样本性能的同时也提高了监督训练效率。&lt;h4&gt;翻译&lt;/h4&gt;药物发现是一个复杂和耗时的过程，需要识别和验证新的治疗候选者。计算方法利用大规模生物医学知识图谱（KGs）作为解决方案来加速这一过程显示出巨大潜力，但挑战在于如何从这些复杂的图结构中提取有意义的信息。现有的基于子图的方法主要针对图神经网络设计，导致它们与大语言模型等其他类型模型不兼容。为此，我们提出了一种名为 K-Paths 的检索框架，它可以从 KGs 中抽取结构化、多样化且生物上具有意义的路径，并让这些路径便于大语言模型和 GNN 用于预测未观察到的药物相互作用及药物与疾病之间的关系。与其他传统的基于路径排名的方法不同，K-Paths 检索并转换路径以一种大语言模型可以直接处理的形式呈现出来，从而实现可解释性推理。该方法利用了一种改进的 Yen 算法来优先考虑生物学相关的多样化的关联，并检索查询实体间 K 条最短无环路径。实验结果表明，在药物再定位和相互作用严重程度预测任务上，K-Paths 显著提升了零样本性能。此外，对于监督学习任务，它还能显著提高训练效率并保持强大的预测效果。这些特性表明 K-Paths 是一种高效的数据驱动药物发现工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug discovery is a complex and time-intensive process that requiresidentifying and validating new therapeutic candidates. Computational approachesusing large-scale biomedical knowledge graphs (KGs) offer a promising solutionto accelerate this process. However, extracting meaningful insights fromlarge-scale KGs remains challenging due to the complexity of graph traversal.Existing subgraph-based methods are tailored to graph neural networks (GNNs),making them incompatible with other models, such as large language models(LLMs). We introduce K-Paths, a retrieval framework that extracts structured,diverse, and biologically meaningful paths from KGs. Integrating these pathsenables LLMs and GNNs to effectively predict unobserved drug-drug anddrug-disease interactions. Unlike traditional path-ranking approaches, K-Pathsretrieves and transforms paths into a structured format that LLMs can directlyprocess, facilitating explainable reasoning. K-Paths employs a diversity-awareadaptation of Yen's algorithm to retrieve the K shortest loopless paths betweenentities in an interaction query, prioritizing biologically relevant anddiverse relationships. Our experiments on benchmark datasets show that K-Pathsimproves the zero-shot performance of Llama 8.1B's F1-score by 12.45 points ondrug repurposing and 13.42 points on interaction severity prediction. We alsoshow that Llama 70B achieves F1-score gains of 6.18 and 8.46 points,respectively. K-Paths also improves the supervised training efficiency ofEmerGNN, a state-of-the-art GNN, by reducing KG size by 90% while maintainingstrong predictive performance. Beyond its scalability and efficiency, K-Pathsuniquely bridges the gap between KGs and LLMs, providing explainable rationalesfor predicted interactions. These capabilities show that K-Paths is a valuabletool for efficient data-driven drug discovery.</description>
      <author>example@mail.com (Tassallah Abdullahi, Ioanna Gemou, Nihal V. Nayak, Ghulam Murtaza, Stephen H. Bach, Carsten Eickhoff, Ritambhara Singh)</author>
      <guid isPermaLink="false">2502.13344v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Two Tickets are Better than One: Fair and Accurate Hiring Under Strategic LLM Manipulations</title>
      <link>http://arxiv.org/abs/2502.13221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;在基础模型能力日益增强的时代，求职者开始利用生成式AI工具来提升他们的申请材料。然而，这种不平等的访问权限和知识水平可能导致招聘决策的准确性降低，并且给一些候选人带来不公平的优势。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型功能的提高，越来越多的人使用这些技术来改进简历等求职文件。但是，不同人之间获取生成式AI工具的能力存在差异，这可能会影响招聘过程中的公平性和准确度。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的策略分类框架变体，以解决由于利用大规模语言模型而产生的操纵问题，并为此类操作制定相应规则。&lt;h4&gt;方法&lt;/h4&gt;引入了一个名为“双票制”的方案，在该方案中，招聘算法会对提交的每份简历进行额外的操作处理，并与原始版本一起考虑。此外还扩展了这一方法为更一般的n-票制度。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明表明，这种'双票制'方案能够提升招聘决策的准确性和公平性。并且，当正向预测率最大化并限制错误阳性发生时，最终的招聘结果将趋于稳定且不依赖于群体差异。&lt;h4&gt;结论&lt;/h4&gt;通过使用开源简历筛选工具对真实简历进行实验验证了该框架及其性能的有效性，这表明这种双票制方案能够在一定程度上缓解由于大型语言模型访问权的不同而引起的不公平现象。&lt;h4&gt;翻译&lt;/h4&gt;在技术不断进步的时代背景下，论文提出了一种新的策略分类方法来改善招聘过程中的公平性和准确性问题。通过引入一种名为‘双票制’的机制，并理论上证明了其有效性，最终通过实验验证表明这种方法能够解决由于大型语言模型使用差异带来的不公平现象。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In an era of increasingly capable foundation models, job seekers are turningto generative AI tools to enhance their application materials. However, unequalaccess to and knowledge about generative AI tools can harm both employers andcandidates by reducing the accuracy of hiring decisions and giving somecandidates an unfair advantage. To address these challenges, we introduce a newvariant of the strategic classification framework tailored to manipulationsperformed using large language models, accommodating varying levels ofmanipulations and stochastic outcomes. We propose a ``two-ticket'' scheme,where the hiring algorithm applies an additional manipulation to each submittedresume and considers this manipulated version together with the originalsubmitted resume. We establish theoretical guarantees for this scheme, showingimprovements for both the fairness and accuracy of hiring decisions when thetrue positive rate is maximized subject to a no false positives constraint. Wefurther generalize this approach to an $n$-ticket scheme and prove that hiringoutcomes converge to a fixed, group-independent decision, eliminatingdisparities arising from differential LLM access. Finally, we empiricallyvalidate our framework and the performance of our two-ticket scheme on realresumes using an open-source resume screening tool.</description>
      <author>example@mail.com (Lee Cohen, Jack Hsieh, Connie Hong, Judy Hanwen Shen)</author>
      <guid isPermaLink="false">2502.13221v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Myna: Masking-Based Contrastive Learning of Musical Representations</title>
      <link>http://arxiv.org/abs/2502.12511v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Myna 是一种简单的自监督音乐表示学习方法，基于对比学习框架，并引入了两个关键创新：使用 Vision Transformer (ViT) 处理频谱图和新颖的 token masking 数据增强策略。&lt;h4&gt;背景&lt;/h4&gt;音乐领域的自监督学习需要有效的数据表征方式以及高效的训练策略以提高模型性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法 Myna，能够通过对比学习框架提升音乐表示的学习效果，并且在有限资源下实现优秀的模型表现。&lt;h4&gt;方法&lt;/h4&gt;Myna 使用 ViT 作为主要架构并引入 token masking 数据增强技术。使用垂直补丁来捕捉关键特征，同时提高音高敏感性以改善任务性能。Myna-22M-Hybrid 版本同时处理不同大小的频谱图块，并且在单 GPU 上进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;(i) Token masking 技术使每张 GPU 的批量大小从之前的 48 或者 120 增加到 4096，提高了效率。(ii) Myna 避免了传统增强方法，保持音高敏感性，从而在诸如关键检测的任务中表现更佳。(iii) 使用垂直补丁能更好地捕捉用于关键检测的特征。&lt;h4&gt;结论&lt;/h4&gt;Myna-22M-Hybrid 版本经过单 GPU 训练，在性能上超过了 MULE (62M)，并且与训练于 16 和 64 张 GPU 的 MERT-95M 相媲美，甚至在使用公开数据时表现更佳。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Myna, a simple yet effective approach for self-supervised musicalrepresentation learning. Built on a contrastive learning framework, Mynaintroduces two key innovations: (1) the use of a Vision Transformer (ViT) onmel-spectrograms as the backbone and (2) a novel data augmentation strategy,token masking, that masks 90 percent of spectrogram tokens. These innovationsdeliver both effectiveness and efficiency: (i) Token masking enables asignificant increase in per-GPU batch size, from 48 or 120 in prior methods(CLMR, MULE) to 4096. (ii) By avoiding traditional augmentations, Myna retainspitch sensitivity, enhancing performance in tasks like key detection. (iii) Theuse of vertical patches allows the model to better capture critical featuresfor key detection. Our hybrid model, Myna-22M-Hybrid, processes both 16x16 and128x2 patches, achieving state-of-the-art results. Trained on a single GPU, itoutperforms MULE (62M) on average and rivals MERT-95M, which was trained on 16and 64 GPUs, respectively. Additionally, it surpasses MERT-95M-public,establishing itself as the best-performing model trained on publicly availabledata. We release our code and models to promote reproducibility and facilitatefuture research.</description>
      <author>example@mail.com (Ori Yonay, Tracy Hammond, Tianbao Yang)</author>
      <guid isPermaLink="false">2502.12511v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Databases: A Survey</title>
      <link>http://arxiv.org/abs/2502.12908v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A survey focus on GNNs and databases. 9 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了图神经网络（GNN）在数据库系统中的应用，提出了一个将现有方法分类为两类的新体系结构：关系型数据库和图形数据库。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在处理图数据方面展示了强大的能力，并且在数据库社区中引起了越来越多的关注。然而，在如何通过基于GNN的方法改进数据库系统的全面理解和综述方面还存在空白。&lt;h4&gt;目的&lt;/h4&gt;本文旨在填补这一知识空白，提供一种结构化和深入的关于GNN在数据库系统中的应用的概述。&lt;h4&gt;方法&lt;/h4&gt;提出了一个分类体系结构，将现有方法分为两大类：（1）关系型数据库，包括性能预测、查询优化以及文本到SQL转换等任务；（2）图数据库，解决高效图形查询处理及相似性计算等问题。同时对各类关键方法进行了系统性的回顾。&lt;h4&gt;主要发现&lt;/h4&gt;概述了各种GNN在不同类型的数据库中应用的关键贡献和实际影响，并提出了将GNN进一步集成进数据库系统的潜在路径。&lt;h4&gt;结论&lt;/h4&gt;论文强调了图神经网络在改进数据库性能方面的潜力，同时也指出了一些未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are powerful deep learning models forgraph-structured data, demonstrating remarkable success across diverse domains.Recently, the database (DB) community has increasingly recognized thepotentiality of GNNs, prompting a surge of researches focusing on improvingdatabase systems through GNN-based approaches. However, despite notableadvances, There is a lack of a comprehensive review and understanding of howGNNs could improve DB systems. Therefore, this survey aims to bridge this gapby providing a structured and in-depth overview of GNNs for DB systems.Specifically, we propose a new taxonomy that classifies existing methods intotwo key categories: (1) Relational Databases, which includes tasks likeperformance prediction, query optimization, and text-to-SQL, and (2) GraphDatabases, addressing challenges like efficient graph query processing andgraph similarity computation. We systematically review key methods in eachcategory, highlighting their contributions and practical implications. Finally,we suggest promising avenues for integrating GNNs into Database systems.</description>
      <author>example@mail.com (Ziming Li, Youhuan Li, Yuyu Luo, Guoliang Li, Chuxu Zhang)</author>
      <guid isPermaLink="false">2502.12908v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond</title>
      <link>http://arxiv.org/abs/2502.12048v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本论文综述了基于脑电图（EEG）的多模态生成技术的发展现状，重点关注通过生成对抗网络（GANs）、变分自编码器（VAEs）和扩散模型进行的EEG到图像生成，以及利用Transformer语言模型和对比学习方法实现的EEG到文本生成。&lt;h4&gt;背景&lt;/h4&gt;脑机接口（BCI）与生成人工智能（GenAI）的结合开启了大脑信号解码的新领域，实现了辅助通信、神经表示学习及多模态集成。特别是基于脑电图（EEG）的非侵入性方法，在将神经活动转化为有意义的输出方面发挥了重要作用。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供基于EEG生成人工智能领域的结构化概述，为研究人员和从业者提供有关神经解码、增强辅助技术以及扩展人机交互边界的见解。&lt;h4&gt;方法&lt;/h4&gt;综述了通过GANs、VAEs和扩散模型实现的EEG到图像生成，以及借助Transformer语言模型和对比学习方法进行的EEG到文本生成。同时探讨了新兴领域——EEG到语音合成，并重点讨论关键数据集、使用案例、挑战及EEG特征编码方法。&lt;h4&gt;主要发现&lt;/h4&gt;近年来深度学习技术的进步显著改善了基于脑电图（EEG）产生图像、文本和语音的效果，特别是GANs和基于Transformer的大规模语言模型（LLMs）。&lt;h4&gt;结论&lt;/h4&gt;通过提供结构化概述，本文为推动神经解码的进展、增强辅助技术和拓展脑机交互领域提供了重要的研究视角。&lt;h4&gt;翻译&lt;/h4&gt;将脑电图（EEG）与生成人工智能结合的技术发展开辟了大脑信号解析的新方向。论文回顾了这些技术的应用现状，并指出了关键挑战和未来发展方向，强调其在神经解码、辅助通信及多模态数据融合方面的重要作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integration of Brain-Computer Interfaces (BCIs) and Generative ArtificialIntelligence (GenAI) has opened new frontiers in brain signal decoding,enabling assistive communication, neural representation learning, andmultimodal integration. BCIs, particularly those leveragingElectroencephalography (EEG), provide a non-invasive means of translatingneural activity into meaningful outputs. Recent advances in deep learning,including Generative Adversarial Networks (GANs) and Transformer-based LargeLanguage Models (LLMs), have significantly improved EEG-based generation ofimages, text, and speech. This paper provides a literature review of thestate-of-the-art in EEG-based multimodal generation, focusing on (i)EEG-to-image generation through GANs, Variational Autoencoders (VAEs), andDiffusion Models, and (ii) EEG-to-text generation leveraging Transformer basedlanguage models and contrastive learning methods. Additionally, we discuss theemerging domain of EEG-to-speech synthesis, an evolving multimodal frontier. Wehighlight key datasets, use cases, challenges, and EEG feature encoding methodsthat underpin generative approaches. By providing a structured overview ofEEG-based generative AI, this survey aims to equip researchers andpractitioners with insights to advance neural decoding, enhance assistivetechnologies, and expand the frontiers of brain-computer interaction.</description>
      <author>example@mail.com (Shreya Shukla, Jose Torres, Abhijit Mishra, Jacek Gwizdka, Shounak Roychowdhury)</author>
      <guid isPermaLink="false">2502.12048v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Graph Structure Learning</title>
      <link>http://arxiv.org/abs/2502.12618v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted by TheWebConf 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'背景': '图神经网络（GNNs）已成为处理图结构数据学习的一种重要方法，但在图结构不理想时其效果会大打折扣。', '目的': '为了解决现有图结构学习（Graph Structure Learning, GSL）方法的两个关键局限性：一是忽视节点信息质量的重要性；二是构建的图结构通常受到对称性的限制，影响模型灵活性和有效性。', '方法': '提出了一种不确定性感知图结构学习（Uncertainty-aware Graph Structure Learning, UnGSL）策略。UnGSL通过估计节点信息的不确定性并利用它调整方向连接强度来减少具有高不确定性的节点的影响，并且可以无缝集成到现有的GSL方法中，几乎无需额外计算成本。', '主要发现': '实验显示，在将UnGSL应用于六种代表性GSL方法时，性能得到了一致的改进。', '结论': '通过引入不确定性感知机制和非对称连接调整策略，UnGSL能够提升现有图结构学习方法的有效性和灵活性。'}&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have become a prominent approach for learning from graph-structured data. However, their effectiveness can be significantly compromised when the graph structure is suboptimal. To address this issue, Graph Structure Learning (GSL) has emerged as a promising technique that refines node connections adaptively. Nevertheless, we identify two key limitations in existing GSL methods: 1) Most methods primarily focus on node similarity to construct relationships, while overlooking the quality of node information. Blindly connecting low-quality nodes and aggregating their ambiguous information can degrade the performance of other nodes. 2) The constructed graph structures are often constrained to be symmetric, which may limit the model's flexibility and effectiveness. To overcome these limitations, we propose an Uncertainty-aware Graph Structure Learning (UnGSL) strategy. UnGSL estimates the uncertainty of node information and utilizes it to adjust the strength of directional connections, where the influence of nodes with high uncertainty is adaptively reduced. Importantly, UnGSL serves as a plug-in module that can be seamlessly integrated into existing GSL methods with minimal additional computational cost. In our experiments, we implement UnGSL into six representative GSL methods, demonstrating consistent performance improvements.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become a prominent approach for learningfrom graph-structured data. However, their effectiveness can be significantlycompromised when the graph structure is suboptimal. To address this issue,Graph Structure Learning (GSL) has emerged as a promising technique thatrefines node connections adaptively. Nevertheless, we identify two keylimitations in existing GSL methods: 1) Most methods primarily focus on nodesimilarity to construct relationships, while overlooking the quality of nodeinformation. Blindly connecting low-quality nodes and aggregating theirambiguous information can degrade the performance of other nodes. 2) Theconstructed graph structures are often constrained to be symmetric, which maylimit the model's flexibility and effectiveness. To overcome these limitations,we propose an Uncertainty-aware Graph Structure Learning (UnGSL) strategy.UnGSL estimates the uncertainty of node information and utilizes it to adjustthe strength of directional connections, where the influence of nodes with highuncertainty is adaptively reduced. Importantly, UnGSL serves as a plug-inmodule that can be seamlessly integrated into existing GSL methods with minimaladditional computational cost. In our experiments, we implement UnGSL into sixrepresentative GSL methods, demonstrating consistent performance improvements.</description>
      <author>example@mail.com (Shen Han, Zhiyao Zhou, Jiawei Chen, Zhezheng Hao, Sheng Zhou, Gang Wang, Yan Feng, Chun Chen, Can Wang)</author>
      <guid isPermaLink="false">2502.12618v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>ExoMiner++ on TESS with Transfer Learning from Kepler: Transit Classification and Vetting Catalog for 2-min Data</title>
      <link>http://arxiv.org/abs/2502.09790v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ExoMiner++是一种改进的深度学习模型，用于提高TESS（凌日系外行星巡天卫星）2分钟数据中的凌日信号分类准确性。&lt;h4&gt;背景&lt;/h4&gt;基于ExoMiner的成功经验，研究人员开发了ExoMiner++以更好地处理凌日信号，并区分出更多的假阳性源。&lt;h4&gt;目的&lt;/h4&gt;通过整合多种诊断输入和利用从开普勒太空望远镜中获得的高质量标签数据进行迁移学习来提升模型性能。&lt;h4&gt;方法&lt;/h4&gt;ExoMiner++引入了额外的诊断信息，包括周期图、通量趋势、差分图像、展开后的通量以及航天器姿态控制数据。&lt;h4&gt;主要发现&lt;/h4&gt;在147,568个未标记的凌日候选体中（TCE），ExoMiner++识别出了7330个为行星候选，其余则被分类为假阳性。这其中包括了与已知TESS目标对象相匹配的和新提出的社区TESS目标对象。&lt;h4&gt;结论&lt;/h4&gt;通过ExoMiner++的高准确性和优秀的排名质量，后续调查可以更加集中于最有希望的候选体上，从而提高发现行星的整体效率。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了ExoMiner++，这是一种改进型深度学习模型，在2分钟TESS数据中提升凌日信号分类。该模型利用周期图、通量趋势、差分图像等作为额外诊断输入，并通过从开普勒空间望远镜高质量标签数据进行迁移学习来优化性能。ExoMiner++在多种分类和排名指标上达到了高精度，显著缩小了后续调查的搜索范围以确认新的行星。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present ExoMiner++, an enhanced deep learning model that builds on thesuccess of ExoMiner to improve transit signal classification in 2-minute TESSdata. ExoMiner++ incorporates additional diagnostic inputs, includingperiodogram, flux trend, difference image, unfolded flux, and spacecraftattitude control data, all of which are crucial for effectively distinguishingtransit signals from more challenging sources of false positives. To furtherenhance performance, we leverage transfer learning from high-quality labeleddata from the Kepler space telescope, mitigating the impact of TESS's noisierand more ambiguous labels. ExoMiner++ achieves high accuracy across variousclassification and ranking metrics, significantly narrowing the search spacefor follow-up investigations to confirm new planets. To serve the exoplanetcommunity, we introduce new TESS catalogs containing ExoMiner++ classificationsand confidence scores for each transit signal. Among the 147,568 unlabeledTCEs, ExoMiner++ identifies 7,330 as planet candidates, with the remainderclassified as false positives. These 7,330 planet candidates correspond to1,868 existing TESS Objects of Interest (TOIs), 69 Community TESS Objects ofInterest (CTOIs), and 50 newly introduced CTOIs. 1,797 out of the 2,506 TOIspreviously labeled as planet candidates in ExoFOP are classified as planetcandidates by ExoMiner++. This reduction in plausible candidates combined withthe excellent ranking quality of ExoMiner++ allows the follow-up efforts to befocused on the most likely candidates, increasing the overall planet yield.</description>
      <author>example@mail.com (Hamed Valizadegan, Miguel J. S. Martinho, Jon M. Jenkins, Joseph D. Twicken, Douglas A. Caldwell, Patrick Maynard, Hongbo Wei, William Zhong, Charles Yates, Sam Donald, Karen A. Collins, David Latham, Khalid Barkaoui, Perry Berlind, Michael L. Calkins, Kylee Carden, Nikita Chazov, Gilbert A. Esquerdo, Tristan Guillot, Vadim Krushinsky, Grzegorz Nowak, Benjamin V. Rackham, Amaury Triaud, Richard P. Schwarz, Denise Stephens, Chris Stockdale, Jiaqi Wang, Cristilyn N. Watkins, Francis P. Wilkin)</author>
      <guid isPermaLink="false">2502.09790v3</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Sim-to-Real Methods in RL: Progress, Prospects and Challenges with Foundation Models</title>
      <link>http://arxiv.org/abs/2502.13187v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 6 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;深度强化学习（RL）在机器人、交通系统和推荐系统等多个领域被证明对于解决决策任务是有效且实用的。它通过与环境互动并根据收集到的经验更新策略来学习。&lt;h4&gt;背景&lt;/h4&gt;受限于真实世界的有限数据以及执行有害行为可能带来的不可接受后果，RL策略的学习主要局限于模拟器中进行。这确保了在学习过程中的安全性但带来了部署时的模拟现实差距（sim-to-real gap），导致性能下降和潜在风险。&lt;h4&gt;目的&lt;/h4&gt;这篇综述论文旨在首次为解决不同领域的模拟到真实问题的技术提供一个基于马尔可夫决策过程关键元素（状态、行动、转换和奖励）的形式框架。并涵盖了从经典方法到最近由大基础模型支持的高级方法在内的全面文献，同时讨论了各种领域中值得特别注意的特点。&lt;h4&gt;方法&lt;/h4&gt;根据提出的方法框架，对模拟现实性能进行了正式评估过程，并使用可访问代码或基准进行总结。&lt;h4&gt;主要发现&lt;/h4&gt;论文还概述了解决模拟到真实问题所面临的挑战以及未来研究的机会。&lt;h4&gt;结论&lt;/h4&gt;作者积极维护一个资源库以包含最新的模拟到真实的研究成果来帮助研究人员的工作。&lt;h4&gt;翻译&lt;/h4&gt;深度强化学习已被探索和验证为在机器人、运输系统和推荐系统等各个领域解决决策任务的有效方法。它通过与环境互动并根据收集的经验更新策略来进行学习。然而，由于现实世界数据的限制以及执行有害行为可能带来的不可接受后果，RL策略的学习主要局限于模拟器中进行。这虽然保证了学习过程中的安全性但带来了部署时的模拟现实差距（sim-to-real gap），导致性能下降和潜在风险。在不同领域中有各种技术尝试解决这个问题，特别是在大型基础模型或语言模型等新兴技术时代，这些问题得到了更多关注。&lt;h4&gt;关键词&lt;/h4&gt;['深度强化学习', '马尔可夫决策过程', '模拟到真实问题', '模拟器']&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Reinforcement Learning (RL) has been explored and verified to beeffective in solving decision-making tasks in various domains, such asrobotics, transportation, recommender systems, etc. It learns from theinteraction with environments and updates the policy using the collectedexperience. However, due to the limited real-world data and unbearableconsequences of taking detrimental actions, the learning of RL policy is mainlyrestricted within the simulators. This practice guarantees safety in learningbut introduces an inevitable sim-to-real gap in terms of deployment, thuscausing degraded performance and risks in execution. There are attempts tosolve the sim-to-real problems from different domains with various techniques,especially in the era with emerging techniques such as large foundations orlanguage models that have cast light on the sim-to-real. This survey paper, tothe best of our knowledge, is the first taxonomy that formally frames thesim-to-real techniques from key elements of the Markov Decision Process (State,Action, Transition, and Reward). Based on the framework, we cover comprehensiveliterature from the classic to the most advanced methods including thesim-to-real techniques empowered by foundation models, and we also discuss thespecialties that are worth attention in different domains of sim-to-realproblems. Then we summarize the formal evaluation process of sim-to-realperformance with accessible code or benchmarks. The challenges andopportunities are also presented to encourage future exploration of thisdirection. We are actively maintaining a to include the most up-to-datesim-to-real research outcomes to help the researchers in their work.</description>
      <author>example@mail.com (Longchao Da, Justin Turnau, Thirulogasankar Pranav Kutralingam, Alvaro Velasquez, Paulo Shakarian, Hua Wei)</author>
      <guid isPermaLink="false">2502.13187v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training Quantization Methods for Large Language Models</title>
      <link>http://arxiv.org/abs/2502.13179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为PTQ1.61的极低比特量化（Post-Training Quantization，简称PTQ）方法，首次实现将权重量化到1.61比特。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在面对极其低比特（小于2比特）量化时性能严重下降。现有的一些次2位后训练量化方法使用混合精度方案，并引入了额外的0.5或更多的比特以区分显著权重。&lt;h4&gt;目的&lt;/h4&gt;探索PTQ的真实极限，开发一种极低比特量化的方法。&lt;h4&gt;方法&lt;/h4&gt;引入了一维结构化掩码和基于输入激活降低量化误差上限的方法，使显著权重通道能分配到4位。对于非显著通道二值化，提出高效的块级缩放因子优化框架，考虑隐含的行相关性和角度偏差。此外，论文还提出了量化预处理的概念。&lt;h4&gt;主要发现&lt;/h4&gt;PTQ1.61在极低比特量化中实现了最先进的性能，并展示了代码库的位置。&lt;h4&gt;结论&lt;/h4&gt;通过新的结构化掩码和高效优化框架，首次实现了模型权重到1.61位的量化，在极端低比特环境下保持了良好的性能。同时强调了量化预处理对于提高低比特PTQ效果的重要性。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型在面对极低比特（小于2比特）量化时表现出严重性能下降。现有的一些次2位后训练量化方法通过混合精度方案使用未结构化的细粒度掩码来区分显著权重，而这种方法会为每个权重引入额外的0.5个或更多的比特。为了探索PTQ的真实极限，我们提出了一种称为PTQ1.61的极低比特量化方法，首次实现了将权重量化到1.61比特的能力。具体而言，我们首先基于输入激活量从减少量化误差上限的角度引入了一个一维结构化掩码，每个权重仅增加几乎可以忽略不计的0.0002个比特，并允许相应的显著权重重分配至4位。对于非显著通道二值化，提出了一种高效的块级缩放因子优化框架来考虑隐含的行相关性和角度偏差。不同于以往的工作集中于调整量化方法论，我们进一步提出了量化预处理的新范式，即在量化前转换预先训练模型的权重分布可以缓解极低比特PTQ中的困难。广泛的实验表明我们的PTQ1.61在极低比特量化中达到了最先进的性能。代码可在https://github.com/zjq0455/PTQ1.61获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) suffer severe performance degradation whenfacing extremely low-bit (sub 2-bit) quantization. Several existing sub 2-bitpost-training quantization (PTQ) methods utilize a mix-precision scheme byleveraging an unstructured fine-grained mask to explicitly distinguish salientweights, while which introduces an extra 1-bit or more per weight. To explorethe real limit of PTQ, we propose an extremely low-bit PTQ method calledPTQ1.61, which enables weight quantization to 1.61-bit for the first time.Specifically, we first introduce a one-dimensional structured mask withnegligibly additional 0.0002-bit per weight based on input activations from theperspective of reducing the upper bound of quantization error to allocatecorresponding salient weight channels to 4-bit. For non-salient channelsbinarization, an efficient block-wise scaling factors optimization framework isthen presented to take implicit row-wise correlations and angular biases intoaccount. Different from prior works that concentrate on adjusting quantizationmethodologies, we further propose a novel paradigm called quantizationpreprocessing, where we argue that transforming the weight distribution of thepretrained model before quantization can alleviate the difficulty inper-channel extremely low-bit PTQ. Extensive experiments indicate our PTQ1.61achieves state-of-the-art performance in extremely low-bit quantization. Codesare available at https://github.com/zjq0455/PTQ1.61.</description>
      <author>example@mail.com (Jiaqi Zhao, Miao Zhang, Ming Wang, Yuzhang Shang, Kaihao Zhang, Weili Guan, Yaowei Wang, Min Zhang)</author>
      <guid isPermaLink="false">2502.13179v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>A Training-Free Framework for Precise Mobile Manipulation of Small Everyday Objects</title>
      <link>http://arxiv.org/abs/2502.13964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project webpage: https://arjung128.github.io/svm&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种称为视觉模型伺服控制（SVM）的新框架，用于移动机械臂在现实世界中处理需要精准操作小物体的任务。该方法无需训练，通过利用先进的视觉模型和腕部RGB-D相机实现目标的可靠检测与定位。&lt;h4&gt;背景&lt;/h4&gt;日常生活中许多任务都需要对小物件进行精确的操作，例如打开柜子或按下开关等。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需先期培训且适用于多种环境下的移动机械臂操作框架，以应对涉及小物体精准处理的任务。&lt;h4&gt;方法&lt;/h4&gt;使用RGB-D腕部相机和视觉伺服控制技术；采用先进的计算机视觉模型来计算3D目标位置；利用‘出画’（out-painting）技术减轻因末端执行器造成遮挡的影响，并提高目标定位的准确性；通过开放词汇的对象检测算法识别语义上的目标物体，用户点击确定交互点。&lt;h4&gt;主要发现&lt;/h4&gt;借助于‘出画’方法，无需训练的方法在处理未见过的对象时达到了85%的成功率，在真实世界环境中显著优于开环控制及基于模仿学习的基线模型（后者经过1000多次演示训练）。&lt;h4&gt;结论&lt;/h4&gt;SVM框架展示了其强大的泛化能力以及对未知环境和任务的有效适应，为移动机器人在实际应用中的操作提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many everyday mobile manipulation tasks require precise interaction withsmall objects, such as grasping a knob to open a cabinet or pressing a lightswitch. In this paper, we develop Servoing with Vision Models (SVM), aclosed-loop training-free framework that enables a mobile manipulator to tacklesuch precise tasks involving the manipulation of small objects. SVM employs anRGB-D wrist camera and uses visual servoing for control. Our novelty lies inthe use of state-of-the-art vision models to reliably compute 3D targets fromthe wrist image for diverse tasks and under occlusion due to the end-effector.To mitigate occlusion artifacts, we employ vision models to out-paint theend-effector thereby significantly enhancing target localization. Wedemonstrate that aided by out-painting methods, open-vocabulary objectdetectors can serve as a drop-in module to identify semantic targets (e.g.knobs) and point tracking methods can reliably track interaction sitesindicated by user clicks. This training-free method obtains an 85% zero-shotsuccess rate on manipulating unseen objects in novel environments in the realworld, outperforming an open-loop control method and an imitation learningbaseline trained on 1000+ demonstrations by an absolute success rate of 50%.</description>
      <author>example@mail.com (Arjun Gupta, Rishik Sathua, Saurabh Gupta)</author>
      <guid isPermaLink="false">2502.13964v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>IM360: Textured Mesh Reconstruction for Large-scale Indoor Mapping with 360$^\circ$ Cameras</title>
      <link>http://arxiv.org/abs/2502.12545v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;我们提出了一种用于360°相机的新型3D重建流水线，旨在进行室内环境的3D映射和渲染。&lt;h4&gt;背景&lt;/h4&gt;传统的基于运动结构（SfM）的方法可能不适合大规模的室内场景，因为这些场景中存在无纹理和重复区域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服传统SfM方法在处理大型室内场景中的不足。&lt;h4&gt;方法&lt;/h4&gt;{'IM360方法': '利用全景图像的广阔视野，并将球形相机模型集成到SfM流水线的核心组件中。引入神经隐式曲面重建技术，从稀疏输入数据生成高质量表面；使用基于网格的神经渲染技术来细化纹理图并准确捕捉依赖视点属性。', '评价': '在Matterport3D和Stanford2D3D数据集中的大规模室内场景上进行评估。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'性能提升': 'IM360在纹理网格重建方面优于现有最佳方法（SOTA）。', '改进的准确性': '观察到相机定位、注册以及渲染高频细节方面的准确度有所提高。'}&lt;h4&gt;结论&lt;/h4&gt;我们的研究为大型室内场景的高质量3D重建提供了一种有前景的方法，展示出优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的360°摄像机3D重建流水线，用于大型室内环境的3D映射和渲染。传统的基于运动结构（SfM）方法在大规模无纹理且重复区域较多的场景中表现不佳。为了克服这些挑战，我们的IM360方法利用了全景图像的广阔视野，并将球形相机模型集成到了SfM流水线的核心组件中。此外，我们还整合了一个神经隐式表面重建技术来从稀疏输入数据生成高质量曲面，并且采用了一种基于网格的神经渲染方式来细化纹理图并准确捕捉依赖视点属性。我们在Matterport3D和Stanford2D3D数据集的大规模室内场景中评估了我们的流水线，IM360在纹理网格重建方面表现出比现有最佳方法（SOTA）更好的性能，同时我们还观察到了相机定位、注册以及渲染高频细节方面的准确度提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel 3D reconstruction pipeline for 360$^\circ$ cameras for 3Dmapping and rendering of indoor environments. Traditional Structure-from-Motion(SfM) methods may not work well in large-scale indoor scenes due to theprevalence of textureless and repetitive regions. To overcome these challenges,our approach (IM360) leverages the wide field of view of omnidirectional imagesand integrates the spherical camera model into every core component of the SfMpipeline. In order to develop a comprehensive 3D reconstruction solution, weintegrate a neural implicit surface reconstruction technique to generatehigh-quality surfaces from sparse input data. Additionally, we utilize amesh-based neural rendering approach to refine texture maps and accuratelycapture view-dependent properties by combining diffuse and specular components.We evaluate our pipeline on large-scale indoor scenes from the Matterport3D andStanford2D3D datasets. In practice, IM360 demonstrate superior performance interms of textured mesh reconstruction over SOTA. We observe accuracyimprovements in terms of camera localization and registration as well asrendering high frequency details.</description>
      <author>example@mail.com (Dongki Jung, Jaehoon Choi, Yonghan Lee, Dinesh Manocha)</author>
      <guid isPermaLink="false">2502.12545v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>3D Gaussian Splatting aided Localization for Large and Complex Indoor-Environments</title>
      <link>http://arxiv.org/abs/2502.13803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了通过增加渲染图像来显著提高视觉定位精度和可靠性的新方法。&lt;h4&gt;背景&lt;/h4&gt;视觉定位领域经过几十年的研究，已经找到了许多实际应用。然而，在某些挑战性情况下，现有方法仍然表现不佳。&lt;h4&gt;目的&lt;/h4&gt;改进现有的视觉定位技术的准确性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;首先使用现代视觉SLAM（Simultaneous Localization and Mapping）方法生成3D Gaussian Splatting (3DGS) 基于的地图作为参考数据；然后通过在随机采样的姿态下从3DGS渲染图像来丰富参考数据，以提升基于几何的视觉定位和Scene Coordinate Regression (SCR) 方法的表现。&lt;h4&gt;主要发现&lt;/h4&gt;增加渲染图像可以显著提高基于几何的方法和SCRe方法的性能，在工业环境中进行了全面评估，并分析了加入额外渲染视图对性能的影响。&lt;h4&gt;结论&lt;/h4&gt;通过添加渲染图像，能够有效提升视觉定位技术在复杂环境中的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;视觉定位领域经过几十年的研究，已经找到了许多实际应用。然而，尽管该领域取得了巨大进展，在某些挑战情况下，现有方法仍然表现出局限性。我们提出了一种改进传统视觉定位方法精度和可靠性的新途径，即通过添加渲染图像实现。具体而言，首先使用现代的视觉SLAM技术生成3D Gaussian Splatting (3DGS) 基的地图作为参考数据；然后通过从该地图随机采样的姿态下进行渲染来丰富这些参考数据，并证明这种做法可以显著提高基于几何的定位方法和Scene Coordinate Regression (SCR) 方法的表现。在大型工业环境中进行了全面评估，分析了添加额外渲染视图对性能的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The field of visual localization has been researched for several decades andhas meanwhile found many practical applications. Despite the strong progress inthis field, there are still challenging situations in which established methodsfail. We present an approach to significantly improve the accuracy andreliability of established visual localization methods by adding renderedimages. In detail, we first use a modern visual SLAM approach that provides a3D Gaussian Splatting (3DGS) based map to create reference data. We demonstratethat enriching reference data with images rendered from 3DGS at randomlysampled poses significantly improves the performance of both geometry-basedvisual localization and Scene Coordinate Regression (SCR) methods. Throughcomprehensive evaluation in a large industrial environment, we analyze theperformance impact of incorporating these additional rendered views.</description>
      <author>example@mail.com (Vincent Ress, Jonas Meyer, Wei Zhang, David Skuddis, Uwe Soergel, Norbert Haala)</author>
      <guid isPermaLink="false">2502.13803v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>The NavINST Dataset for Multi-Sensor Autonomous Navigation</title>
      <link>http://arxiv.org/abs/2502.13863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 20 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;NavINST实验室开发了一套全面的多感官数据集，该数据集包含了城市环境中的各种道路测试轨迹，并涵盖了不同的照明条件，包括室内车库场景以及密集3D地图。&lt;h4&gt;背景&lt;/h4&gt;为了支持高精度定位、导航、制图、计算机视觉和多传感器融合等领域的高级研究，NavINST实验室创建了一个包含多个商用级IMU和高端战术级IMU的数据集。&lt;h4&gt;目的&lt;/h4&gt;该数据集旨在为自动驾驶车辆算法的开发和验证提供丰富的、多传感器信息。它包括了各种感知基础传感器以及准确后处理过的高精度GNSS/IMU数据，以提供精确的位置定位和导航信息。&lt;h4&gt;方法&lt;/h4&gt;NavINST实验室创建的数据集使用多种商用级惯性测量单元（IMUs）和高端战术级IMU，还包括固态激光雷达、机械式激光雷达、四个电子扫描雷达、单目摄像头以及两个立体摄像机。此外，该数据集还包含了从车辆里程表中提取的前向速度信息。&lt;h4&gt;主要发现&lt;/h4&gt;NavINST数据集是首个包含固态激光雷达的数据集之一，并且提供了精确的地面真实位置和导航信息，适用于开发和验证自主驾驶汽车的鲁棒算法。&lt;h4&gt;结论&lt;/h4&gt;该数据集已完全集成到ROS中，确保了对研究社区的易用性和可访问性。整个数据集及其开发工具可通过https://navinst.github.io获取。&lt;h4&gt;翻译&lt;/h4&gt;NavINST实验室在城市环境中通过各种道路测试轨迹创建了一个全面的多感官数据集，涵盖了不同的照明条件，包括带有密集3D地图的室内车库场景。该数据集包含多个商用级IMU和高端战术级IMU以及多种感知基础传感器（如固态激光雷达、机械式激光雷达、四个电子扫描雷达、单目摄像头及两个立体摄像机）。此外，还包括从车辆里程表中提取的前向速度信息，并提供高精度后处理后的GNSS/IMU数据。NavINST数据集用于支持高精度定位、导航、制图、计算机视觉和多传感器融合等领域的高级研究，为自动驾驶汽车算法的发展与验证提供了丰富的多传感器数据。整个数据集已完全集成到ROS中，确保了对研究社区的易用性和可访问性，并可通过https://navinst.github.io获取其全部内容及开发工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The NavINST Laboratory has developed a comprehensive multisensory datasetfrom various road-test trajectories in urban environments, featuring diverselighting conditions, including indoor garage scenarios with dense 3D maps. Thisdataset includes multiple commercial-grade IMUs and a high-end tactical-gradeIMU. Additionally, it contains a wide array of perception-based sensors, suchas a solid-state LiDAR - making it one of the first datasets to do so - amechanical LiDAR, four electronically scanning RADARs, a monocular camera, andtwo stereo cameras. The dataset also includes forward speed measurementsderived from the vehicle's odometer, along with accurately post-processedhigh-end GNSS/IMU data, providing precise ground truth positioning andnavigation information. The NavINST dataset is designed to support advancedresearch in high-precision positioning, navigation, mapping, computer vision,and multisensory fusion. It offers rich, multi-sensor data ideal for developingand validating robust algorithms for autonomous vehicles. Finally, it is fullyintegrated with the ROS, ensuring ease of use and accessibility for theresearch community. The complete dataset and development tools are available athttps://navinst.github.io.</description>
      <author>example@mail.com (Paulo Ricardo Marques de Araujo, Eslam Mounier, Qamar Bader, Emma Dawson, Shaza I. Kaoud Abdelaziz, Ahmed Zekry, Mohamed Elhabiby, Aboelmagd Noureldin)</author>
      <guid isPermaLink="false">2502.13863v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Minimally sufficient structures for information-feedback policies</title>
      <link>http://arxiv.org/abs/2502.13852v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The 16th International Workshop on the Algorithmic Foundations of  Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;论文探讨了机器人在物理世界中的任务需求，这些任务需要通过有限感知、记忆和计算来实现。&lt;h4&gt;目的&lt;/h4&gt;设计一个过滤器来维持对物理世界的有用表示，并根据这个表示制定策略。&lt;h4&gt;方法&lt;/h4&gt;将过滤器看作机器人基于其感官信息的物理世界的视角。研究了内部系统（如过滤器）与外部物理世界如何通过传感器映射和信息反馈政策相互作用，以实现给定任务。&lt;h4&gt;主要发现&lt;/h4&gt;论文建立了使信息反馈政策存在的必要条件，并证明在轻微假设下存在唯一最小化内部系统来表示特定的规划/策略。&lt;h4&gt;结论&lt;/h4&gt;结果应用于确定距离最优导航所需的结构，在多边形环境中特别有效。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们考虑了机器人需要完成的任务，这些任务要求在一个物理世界中实现期望的结果。为了达到这一目标，我们需要设计一个过滤器来维持对这个物理世界的有用表示，并在此基础上制定策略。过滤器被视为机器人基于有限感官、记忆和计算的视角，并通过传感器映射和信息反馈政策将内部系统（如过滤器）与外部物理世界联系起来。论文确立了使这些结构存在的必要条件，以及在轻微假设下唯一最小化内部系统的存在性和独特性。最后，研究结果应用于确定多边形环境中的距离最优导航所需的足够结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we consider robotic tasks which require a desirable outcome tobe achieved in the physical world that the robot is embedded in and interactingwith. Accomplishing this objective requires designing a filter that maintains auseful representation of the physical world and a policy over the filterstates. A filter is seen as the robot's perspective of the physical world basedon limited sensing, memory, and computation and it is represented as atransition system over a space of information states. To this end, theinteractions result from the coupling of an internal and an external system, afilter, and the physical world, respectively, through a sensor mapping and aninformation-feedback policy. Within this setup, we look for sufficientstructures, that is, sufficient internal systems and sensors, for accomplishinga given task. We establish necessary and sufficient conditions for thesestructures to satisfy for information-feedback policies that can be definedover the states of an internal system to exist. We also show that under mildassumptions, minimal internal systems that can represent a particularplan/policy described over the action-observation histories exist and areunique. Finally, the results are applied to determine sufficient structures fordistance-optimal navigation in a polygonal environment.</description>
      <author>example@mail.com (Basak Sakcak, Vadim K. Weinstein, Kalle G. Timperi, Steven M. LaValle)</author>
      <guid isPermaLink="false">2502.13852v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>An Online Optimization-Based Trajectory Planning Approach for Cooperative Landing Tasks</title>
      <link>http://arxiv.org/abs/2502.13823v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种针对由四旋翼和地面移动机器人组成的异构多机器人系统的实时轨迹规划方案，用于协作着陆任务。&lt;h4&gt;背景&lt;/h4&gt;现有系统缺乏对协同作业的灵活性和自主性的支持，特别是在需要动态调整以满足用户需求的情况下。&lt;h4&gt;目的&lt;/h4&gt;开发一种框架来实现基于可行性与用户规范的自动决定着陆位置、时间和机器人协调的任务。&lt;h4&gt;方法&lt;/h4&gt;利用互补性约束作为决策制定工具，并将其应用于协作降落场景中。该方案在模拟和实际应用中进行了验证。&lt;h4&gt;主要发现&lt;/h4&gt;通过将地面移动机器人用作移动充电站并与需要充电的四旋翼进行实时协同，实现了安全有效的会合与着陆。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架展示了其实时能力，并为类似协作任务提供了潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已翻译成中文并进行了分点总结。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a real-time trajectory planning scheme for aheterogeneous multi-robot system (consisting of a quadrotor and a ground mobilerobot) for a cooperative landing task, where the landing position, landingtime, and coordination between the robots are determined autonomously under theconsideration of feasibility and user specifications. The proposed frameworkleverages the potential of the complementarity constraint as a decision-makerand an indicator for diverse cooperative tasks and extends it to thecollaborative landing scenario. In a potential application of the proposedmethodology, a ground mobile robot may serve as a mobile charging station andcoordinates in real-time with a quadrotor to be charged, facilitating a safeand efficient rendezvous and landing. We verified the generated trajectories insimulation and real-world applications, demonstrating the real-timecapabilities of the proposed landing planning framework.</description>
      <author>example@mail.com (Jingshan Chen, Lihan Xu, Henrik Ebel, Peter Eberhard)</author>
      <guid isPermaLink="false">2502.13823v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Embodied Emotional Communication: A Human-oriented Review of Mediated Social Touch</title>
      <link>http://arxiv.org/abs/2502.13816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is 41 pages long, including references and appendices, and  contains 8 figures. The manuscript has been accepted for publication in CCF  Transactions on Pervasive Computing and Interaction but has not yet been  officially published&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文通过回顾文献，为中介社会触摸（MST）提供了以人为主体的理解框架。&lt;h4&gt;研究背景&lt;/h4&gt;涵盖了触觉接口、情感信息、映射机制以及人际和人机交互的动态变化。&lt;h4&gt;研究目的&lt;/h4&gt;通过对37个选定的MST案例进行现有及探索性映射策略的研究，构建了容纳各种情绪的情感表达空间，并探讨了如何将情感线索转化为触觉信号。此外，还根据MST的表现力构建了一个设计空间。&lt;h4&gt;主要发现&lt;/h4&gt;建立了基于类别模型和效价-唤醒模型结合的情感表达空间；提出了包括工作流程、评估方法及伦理与文化考虑在内的多种MST设计方案；指出了未来的研究方向。&lt;h4&gt;结论&lt;/h4&gt;论文旨在为设计研究人员和从业者提供一个全面的参考，扩大情感交流范围，促进情感触觉应用探索，增强触觉交互的自然性和社交性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：This paper offers a structured understanding of mediated social touch (MST)using a human-oriented approach, through an extensive review of literaturespanning tactile interfaces, emotional information, mapping mechanisms, and thedynamics of human-human and human-robot interactions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper offers a structured understanding of mediated social touch (MST)using a human-oriented approach, through an extensive review of literaturespanning tactile interfaces, emotional information, mapping mechanisms, and thedynamics of human-human and human-robot interactions. By investigating theexisting and exploratory mapping strategies of the 37 selected MST cases, weestablished the emotional expression space of MSTs that accommodated a diversespectrum of emotions by integrating the categorical and Valence-arousal models,showcasing how emotional cues can be translated into tactile signals. Based onthe expressive capacity of MSTs, a practical design space was structuredencompassing factors such as the body locations, device form, tactilemodalities, and parameters. We also proposed various design strategies for MSTsincluding workflow, evaluation methods, and ethical and culturalconsiderations, as well as several future research directions. MSTs' potentialis reflected not only in conveying emotional information but also in fosteringempathy, comfort, and connection in both human-human and human-robotinteractions. This paper aims to serve as a comprehensive reference for designresearchers and practitioners, which helps expand the scope of emotionalcommunication of MSTs, facilitating the exploration of diverse applications ofaffective haptics, and enhancing the naturalness and sociability of hapticinteraction.</description>
      <author>example@mail.com (Liwen He, Zichun Guo, Yanru Mo, Yue Wen, Yun Wang)</author>
      <guid isPermaLink="false">2502.13816v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Muscle Activation Estimation by Optimzing the Musculoskeletal Model for Personalized Strength and Conditioning Training</title>
      <link>http://arxiv.org/abs/2502.13760v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发了一个全身肌肉骨骼模型用于力量和体能训练，并通过基于表面肌电图的优化方法校准相关肌肉参数。&lt;h4&gt;背景&lt;/h4&gt;肌肉骨骼模型在康复与抗阻训练领域中对于分析肌肉状况至关重要。然而，个体间肌肉骨骼参数差异及一些内部生物力学变量无法直接测量的问题导致个性化建模非常困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的全身肌肉骨骼模型，并通过基于表面肌电图的优化方法校准相关的肌肉参数，以更准确地估计肌肉激活情况，从而分析训练表现。&lt;h4&gt;方法&lt;/h4&gt;使用基于表面肌电图（EMG）的优化方法来个性化调整全身肌肉骨骼模型中的相关肌肉参数。利用这个个性化的肌肉骨骼模型，研究者能够随后估算肌肉激活情况，进而分析运动表现。&lt;h4&gt;主要发现&lt;/h4&gt;通过选择杠铃卧推和硬拉作为实验验证的方法，证实了该方法的有效性，并展示了如何更准确地估计肌肉激活和性能。&lt;h4&gt;结论&lt;/h4&gt;开发的全身肌肉骨骼模型及其优化参数对于个性化训练方案设计具有重要意义。这些成果为未来康复医学和运动科学的研究提供了新的视角和工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Musculoskeletal models are pivotal in the domains of rehabilitation andresistance training to analyze muscle conditions. However, individualvariability in musculoskeletal parameters and the immeasurability of someinternal biomechanical variables pose significant obstacles to accuratepersonalized modelling. Furthermore, muscle activation estimation can bechallenging due to the inherent redundancy of the musculoskeletal system, wheremultiple muscles drive a single joint. This study develops a whole-bodymusculoskeletal model for strength and conditioning training and calibratesrelevant muscle parameters with an electromyography-based optimization method.By utilizing the personalized musculoskeletal model, muscle activation can besubsequently estimated to analyze the performance of exercises. Bench press anddeadlift are chosen for experimental verification to affirm the efficacy ofthis approach.</description>
      <author>example@mail.com (Xi Wu, Chenzui Li, Kehan Zou, Ning Xi, Fei Chen)</author>
      <guid isPermaLink="false">2502.13760v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Active Illumination for Visual Ego-Motion Estimation in the Dark</title>
      <link>http://arxiv.org/abs/2502.13708v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉里程计（VO）和视觉同步定位与地图构建（V-SLAM）系统在低光或黑暗环境中表现不佳，因为缺乏稳健的视觉特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型主动照明框架，用于增强这些算法在挑战性条件下的性能。&lt;h4&gt;方法&lt;/h4&gt;{'主动照明框架': '动态控制移动光源以照亮具有高度纹理的区域', '探测器块': '结合深度学习增强网络来识别具有相关特征的区域', '云台控制器': '负责将光线引导至这些区域，提供富含信息的图像给自运动估计算法'}&lt;h4&gt;主要发现&lt;/h4&gt;在实际机器人平台上进行实验的结果显示，与传统的固定照明技术相比，所提出的方法可减少姿态估计误差高达75%。&lt;h4&gt;结论&lt;/h4&gt;该主动照明框架显著提高了VO和V-SLAM系统在低光条件下的性能表现。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了视觉里程计（VO）和视觉同步定位与地图构建（V-SLAM）技术在低光或黑暗环境中存在的挑战，并提出了一种基于动态控制移动光源的主动照明框架来提高这些算法的表现，通过实验验证了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Odometry (VO) and Visual SLAM (V-SLAM) systems often struggle inlow-light and dark environments due to the lack of robust visual features. Inthis paper, we propose a novel active illumination framework to enhance theperformance of VO and V-SLAM algorithms in these challenging conditions. Thedeveloped approach dynamically controls a moving light source to illuminatehighly textured areas, thereby improving feature extraction and tracking.Specifically, a detector block, which incorporates a deep learning-basedenhancing network, identifies regions with relevant features. Then, a pan-tiltcontroller is responsible for guiding the light beam toward these areas, sothat to provide information-rich images to the ego-motion estimation algorithm.Experimental results on a real robotic platform demonstrate the effectivenessof the proposed method, showing a reduction in the pose estimation error up to75% with respect to a traditional fixed lighting technique.</description>
      <author>example@mail.com (Francesco Crocetti, Alberto Dionigi, Raffaele Brilli, Gabriele Costante, Paolo Valigi)</author>
      <guid isPermaLink="false">2502.13708v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Human-Like Robot Impedance Regulation Skill Learning from Human-Human Demonstrations</title>
      <link>http://arxiv.org/abs/2502.13707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种创新的阻抗调节技能学习框架，旨在实现多种物理协作任务中的人机合作（HRC）。该框架通过调整机器人与人类伙伴状态相适应的顺应性来工作，并根据人与人的示范提供的参考轨迹进行操作。&lt;h4&gt;背景&lt;/h4&gt;人类在基于对同伴状态和任务需求感知的基础上调节顺从行为方面擅长协作。让机器人掌握这种技能可以促进更高效的人机协作（HRC）。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架，通过调整机器人的顺应性来实现有效的人机物理合作。&lt;h4&gt;方法&lt;/h4&gt;收集并分析人类肌肉的肌电图(EMG)信号以提取肢体阻抗；采用概率学习方法捕捉和表示人体端点运动，并创建参考轨迹和相应的阻抗配置文件。使用LSTM模块开发任务导向型阻抗调节策略，同时提出一种针对类人机器人的全身阻抗控制器。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证表明，在协作运输任务以及两个互动太极推手任务中，与恒定阻抗控制方法相比，本文所提出的框架从交互力的角度表现出更优性能。&lt;h4&gt;结论&lt;/h4&gt;该研究通过开发适应性更好的人机合作技能，促进了更加高效和自然的人机物理协作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans are experts in collaborating with others physically by regulatingcompliance behaviors based on the perception of their partner states and thetask requirements. Enabling robots to develop proficiency in humancollaboration skills can facilitate more efficient human-robot collaboration(HRC). This paper introduces an innovative impedance regulation skill learningframework for achieving HRC in multiple physical collaborative tasks. Theframework is designed to adjust the robot compliance to the human partnerstates while adhering to reference trajectories provided by human-humandemonstrations. Specifically, electromyography (EMG) signals from human musclesare collected and analyzed to extract limb impedance, representing compliancebehaviors during demonstrations. Human endpoint motions are captured andrepresented using a probabilistic learning method to create referencetrajectories and corresponding impedance profiles. Meanwhile, an LSTMbasedmodule is implemented to develop task-oriented impedance regulation policies bymapping the muscle synergistic contributions between two demonstrators.Finally, we propose a wholebody impedance controller for a human-like robot,coordinating joint outputs to achieve the desired impedance and referencetrajectory during task execution. Experimental validation was conducted througha collaborative transportation task and two interactive Tai Chi pushing handstasks, demonstrating superior performance from the perspective of interactiveforces compared to a constant impedance control method.</description>
      <author>example@mail.com (Chenzui Li, Xi Wu, Junjia Liu, Tao Teng, Yiming Chen, Sylvain Calinon, Darwin Caldwell, Fei Chen)</author>
      <guid isPermaLink="false">2502.13707v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>A Framework for Semantics-based Situational Awareness during Mobile Robot Deployments</title>
      <link>http://arxiv.org/abs/2502.13677v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在危险环境中部署机器人时，人机团队合作中情景意识的高级语义信息理解和获取的方法。提出了一种可扩展框架，用于远程部署移动机器人的多模态语义级情景意识采集和整合，并通过灾难响应机器人中的搜索与救援应用来演示该框架。&lt;h4&gt;背景&lt;/h4&gt;在危险环境中部署机器人通常采用人机团队合作模式，其中人类监督者与远程操作的机器人协同工作。情景意识对于支持导航、规划和决策至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究不同自主程度下语义信息的重要性和差异，并提出一种获取和整合多模态语义级情景意识的通用框架。&lt;h4&gt;方法&lt;/h4&gt;提出了“环境语义指标”，这些指标可以反映风险指示或人类活动迹象等不同类型的语义信息。基于这些指标，设计了一种称为“情境语义丰富度（SSR）”的综合评估指标，该指标结合了多种语义指示来总结整体情况。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示提出的语义指标对不同场景中各种模态的语义信息变化敏感，且SSR度量能够反映遇到的情境的整体语义变化。这表明信息丰富和复杂的情况可能需要高级推理能力和专家人类操作员的关注。&lt;h4&gt;结论&lt;/h4&gt;该框架为远程部署移动机器人提供了强大的情景意识支持，有助于提高人机团队合作的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deployment of robots into hazardous environments typically involves a``Human-Robot Teaming'' (HRT) paradigm, in which a human supervisor interactswith a remotely operating robot inside the hazardous zone. SituationalAwareness (SA) is vital for enabling HRT, to support navigation, planning, anddecision-making. This paper explores issues of higher-level ``semantic''information and understanding in SA. In semi-autonomous, or variable-autonomyparadigms, different types of semantic information may be important, indifferent ways, for both the human operator and an autonomous agent controllingthe robot. We propose a generalizable framework for acquiring and combiningmultiple modalities of semantic-level SA during remote deployments of mobilerobots. We demonstrate the framework with an example application of search andrescue (SAR) in disaster response robotics. We propose a set of ``environmentsemantic indicators" that can reflect a variety of different types of semanticinformation, e.g. indicators of risk, or signs of human activity, as the robotencounters different scenes. Based on these indicators, we propose a metric todescribe the overall situation of the environment called ``Situational SemanticRichness (SSR)". This metric combines multiple semantic indicators to summarisethe overall situation. The SSR indicates if an information-rich and complexsituation has been encountered, which may require advanced reasoning for robotsand humans and hence the attention of the expert human operator. The frameworkis tested on a Jackal robot in a mock-up disaster response environment.Experimental results demonstrate that the proposed semantic indicators aresensitive to changes in different modalities of semantic information indifferent scenes, and the SSR metric reflects overall semantic changes in thesituations encountered.</description>
      <author>example@mail.com (Tianshu Ruan, Aniketh Ramesh, Hao Wang, Alix Johnstone-Morfoisse, Gokcenur Altindal, Paul Norman, Grigoris Nikolaou, Rustam Stolkin, Manolis Chiou)</author>
      <guid isPermaLink="false">2502.13677v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>An Adaptive Data-Enabled Policy Optimization Approach for Autonomous Bicycle Control</title>
      <link>http://arxiv.org/abs/2502.13676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一控制框架，该框架结合了内环的反馈线性化（FL）控制器和外环的自适应数据增强策略优化（DeePO）控制器来平衡自主自行车。&lt;h4&gt;背景&lt;/h4&gt;由于自主自行车系统本质上是不稳定且非线性的，因此使用FL控制器可以稳定并部分线性化系统。然而，性能会因未建模动态效应以及时间变化特性而受到影响。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些限制，并增强系统的适应性和鲁棒性，引入了DeePO控制器来与FL控制器协同工作。&lt;h4&gt;方法&lt;/h4&gt;初始控制策略通过离线的持续激励输入和状态数据获得。利用一种促进鲁棒性的正则化器改进初始策略，同时增加一个遗忘因子以提升适应时间变化动态的能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟和实际实验验证了DeePO+FL方法的有效性，并表明其在跟踪参考倾斜角度和倾斜速率的精确度上优于仅使用FL的方法。&lt;h4&gt;结论&lt;/h4&gt;提出的控制框架能够显著提高自主自行车系统的稳定性和性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要的内容描述了一种结合反馈线性化和自适应数据增强策略优化来平衡自主自行车的新方法，展示了该方法在模拟和实际实验中的优越表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a unified control framework that integrates a FeedbackLinearization (FL) controller in the inner loop with an adaptive Data-EnabledPolicy Optimization (DeePO) controller in the outer loop to balance anautonomous bicycle. While the FL controller stabilizes and partially linearizesthe inherently unstable and nonlinear system, its performance is compromised byunmodeled dynamics and time-varying characteristics. To overcome theselimitations, the DeePO controller is introduced to enhance adaptability androbustness. The initial control policy of DeePO is obtained from a finite setof offline, persistently exciting input and state data. To improve stabilityand compensate for system nonlinearities and disturbances, arobustness-promoting regularizer refines the initial policy, while the adaptivesection of the DeePO framework is enhanced with a forgetting factor to improveadaptation to time-varying dynamics. The proposed DeePO+FL approach isevaluated through simulations and real-world experiments on an instrumentedautonomous bicycle. Results demonstrate its superiority over the FL-onlyapproach, achieving more precise tracking of the reference lean angle and leanrate.</description>
      <author>example@mail.com (Niklas Persson, Feiran Zhao, Mojtaba Kaheni, Florian Dörfler, Alessandro V. Papadopoulos)</author>
      <guid isPermaLink="false">2502.13676v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>SLAMSpoof: Practical LiDAR Spoofing Attacks on Localization Systems Guided by Scan Matching Vulnerability Analysis</title>
      <link>http://arxiv.org/abs/2502.13641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7pages, 6figures, accepted at IEEE International Conference on  Robotics and Automation (ICRA) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SLAMSpoof是一种针对自动驾驶车辆定位系统的LiDAR欺骗攻击，通过评估LiDAR在实际环境中的易受攻击性来检验其对自主驾驶的影响。&lt;h4&gt;背景&lt;/h4&gt;现代全自动驾驶服务依赖于地图交通信息进行精确的车道形状、交通灯位置和标志识别。为了实现这一点，需要厘米级的定位精度，而目前只有LiDAR传感器能够达到这一要求。然而，由于LiDAR容易受到激光欺骗攻击的影响，这种安全威胁引起了人们的关注。&lt;h4&gt;目的&lt;/h4&gt;设计SLAMSpoof来评估实际场景中对基于LiDAR的自动驾驶车辆定位系统进行欺骗攻击的安全性影响。&lt;h4&gt;方法&lt;/h4&gt;通过扫描匹配脆弱性评分（SMVS）找到有效的攻击位置，并在真实环境中测试了该攻击的有效性，证明其能够在所有流行的LiDAR定位算法上引入超过4.2米的位置误差。&lt;h4&gt;主要发现&lt;/h4&gt;SLAMSpoof能够有效利用基于LiDAR的定位系统中的漏洞，在现实世界场景中诱导出显著的位置错误。&lt;h4&gt;结论&lt;/h4&gt;论文指出了自动驾驶车辆在使用LiDAR时可能面临的安全威胁，并提出了评估该类攻击实际影响的方法。同时，讨论了对抗此类攻击的潜在对策。&lt;h4&gt;翻译&lt;/h4&gt;精确定位对于实现现代全自动驾驶服务至关重要。这些服务高度依赖于基于地图的交通信息来减少识别车道形状、交通信号灯位置和标志等不确定性的程度。为了达到这种对地图数据的高度信赖，需要厘米级精度的定位能力，目前只有激光雷达（LiDAR）传感器可以提供这样的精确度。然而，由于激光雷达容易受到恶意发射激光欺骗其读数的安全威胁，一旦定位系统被攻破，可能导致车辆偏离道路或忽视交通信号灯等严重后果。鉴于此类攻击所带来的安全问题，研究团队设计了SLAMSpoof，这是首个针对自动驾驶车辆定位系统的实际LiDAR欺骗攻击方法，用以评估这种攻击对自主驾驶汽车的实际影响。通过扫描匹配脆弱性评分（SMVS），该技术能够找到有效的攻击位置，并在实地测试中证明其能够在所有流行的基于激光雷达的定位算法上引入显著的位置误差。研究团队还讨论了针对此类攻击可能采取的安全措施。代码可在https://github.com/Keio-CSG/slamspoof获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate localization is essential for enabling modern full self-drivingservices. These services heavily rely on map-based traffic information toreduce uncertainties in recognizing lane shapes, traffic light locations, andtraffic signs. Achieving this level of reliance on map information requirescentimeter-level localization accuracy, which is currently only achievable withLiDAR sensors. However, LiDAR is known to be vulnerable to spoofing attacksthat emit malicious lasers against LiDAR to overwrite its measurements. Oncelocalization is compromised, the attack could lead the victim off roads or makethem ignore traffic lights. Motivated by these serious safety implications, wedesign SLAMSpoof, the first practical LiDAR spoofing attack on localizationsystems for self-driving to assess the actual attack significance on autonomousvehicles. SLAMSpoof can effectively find the effective attack location based onour scan matching vulnerability score (SMVS), a point-wise metric representingthe potential vulnerability to spoofing attacks. To evaluate the effectivenessof the attack, we conduct real-world experiments on ground vehicles and confirmits high capability in real-world scenarios, inducing position errors of$\geq$4.2 meters (more than typical lane width) for all 3 popular LiDAR-basedlocalization algorithms. We finally discuss the potential countermeasures ofthis attack. Code is available at https://github.com/Keio-CSG/slamspoof</description>
      <author>example@mail.com (Rokuto Nagata, Kenji Koide, Yuki Hayakawa, Ryo Suzuki, Kazuma Ikeda, Ozora Sako, Qi Alfred Chen, Takami Sato, Kentaro Yoshioka)</author>
      <guid isPermaLink="false">2502.13641v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Model Evolution Framework with Genetic Algorithm for Multi-Task Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.13569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于遗传算法的模型进化框架（MEGA），旨在通过调整模型结构以适应不同任务难度，从而提升多任务强化学习中单一策略的泛化能力和效率。&lt;h4&gt;背景&lt;/h4&gt;在多任务强化学习中，单个策略用于完成多个任务，并通过参数共享来提高代理的学习效率。现有的方法通常使用路由网络为每个任务生成特定路径，并将一组模块重组以同时完成多种任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够根据任务难度自动调整模型结构的框架，提升多任务强化学习中的资源分配和学习效率。&lt;h4&gt;方法&lt;/h4&gt;引入了基于遗传算法的模型进化框架（MEGA），该框架允许在训练过程中根据任务难度动态调整模型。具体而言，采用二进制序列作为基因型策略进行模型重建，并使用非梯度遗传算法优化这些基因型策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的MEGA框架通过自适应地添加模块和动态调整结构，在机器人抓取等多任务场景中实现了优越的性能表现。&lt;h4&gt;结论&lt;/h4&gt;论文证明了基于遗传算法的模型进化方法的有效性，并计划向公众开放源代码。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容描述了一种新的研究方法，该方法通过采用遗传算法优化策略来改进强化学习中的多任务处理能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-task reinforcement learning employs a single policy to complete varioustasks, aiming to develop an agent with generalizability across differentscenarios. Given the shared characteristics of tasks, the agent's learningefficiency can be enhanced through parameter sharing. Existing approachestypically use a routing network to generate specific routes for each task andreconstruct a set of modules into diverse models to complete multiple taskssimultaneously. However, due to the inherent difference between tasks, it iscrucial to allocate resources based on task difficulty, which is constrained bythe model's structure. To this end, we propose a Model Evolution framework withGenetic Algorithm (MEGA), which enables the model to evolve during trainingaccording to the difficulty of the tasks. When the current model isinsufficient for certain tasks, the framework will automatically incorporateadditional modules, enhancing the model's capabilities. Moreover, to adapt toour model evolution framework, we introduce a genotype module-level model,using binary sequences as genotype policies for model reconstruction, whileleveraging a non-gradient genetic algorithm to optimize these genotypepolicies. Unlike routing networks with fixed output dimensions, our approachallows for the dynamic adjustment of the genotype policy length, enabling it toaccommodate models with a varying number of modules. We conducted experimentson various robotics manipulation tasks in the Meta-World benchmark. Ourstate-of-the-art performance demonstrated the effectiveness of the MEGAframework. We will release our source code to the public.</description>
      <author>example@mail.com (Yan Yu, Wengang Zhou, Yaodong Yang, Wanxuan Lu, Yingyan Hou, Houqiang Li)</author>
      <guid isPermaLink="false">2502.13569v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>MILE: Model-based Intervention Learning</title>
      <link>http://arxiv.org/abs/2502.13519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  International Conference on Robotics and Automation (ICRA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种模型，能够从少量专家干预中学习策略，并展示了如何在模拟环境和实际机器人任务中应用此方法。&lt;h4&gt;背景&lt;/h4&gt;模仿学习技术在现实世界的控制场景（例如机器人）中非常有效，但这些方法容易出现累积误差问题，且需要人类专家提供完整的轨迹数据。现有互动方法仅利用干预期间的数据，忽视了非干预时间步长中的反馈信号。&lt;h4&gt;目的&lt;/h4&gt;创建一种模型来描述在这种情况下如何发生干预，并展示可以通过少量的专家干预学习策略。&lt;h4&gt;方法&lt;/h4&gt;提出了一个能够从专家反馈中获取关于当前状态质量和所选动作最优性的关键信息的方法，无论是否有干预都适用。该方法在离散和连续模拟环境、实际机器人操作任务以及人类主题研究中进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;可以通过少量的专家干预学习出有效策略，并且可以利用非干预时间段中的反馈信号进行更有效的学习。&lt;h4&gt;结论&lt;/h4&gt;新的模型能够通过较少的数据实现更高效的模仿学习，为现实世界控制场景提供了改进的方法。&lt;h4&gt;翻译&lt;/h4&gt;论文摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning techniques have been shown to be highly effective inreal-world control scenarios, such as robotics. However, these approaches notonly suffer from compounding error issues but also require human experts toprovide complete trajectories. Although there exist interactive methods wherean expert oversees the robot and intervenes if needed, these extensions usuallyonly utilize the data collected during intervention periods and ignore thefeedback signal hidden in non-intervention timesteps. In this work, we create amodel to formulate how the interventions occur in such cases, and show that itis possible to learn a policy with just a handful of expert interventions. Ourkey insight is that it is possible to get crucial information about the qualityof the current state and the optimality of the chosen action from expertfeedback, regardless of the presence or the absence of intervention. Weevaluate our method on various discrete and continuous simulation environments,a real-world robotic manipulation task, as well as a human subject study.Videos and the code can be found at https://liralab.usc.edu/mile .</description>
      <author>example@mail.com (Yigit Korkmaz, Erdem Bıyık)</author>
      <guid isPermaLink="false">2502.13519v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>VLAS: Vision-Language-Action Model With Speech Instructions For Customized Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.13508v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as a conference paper at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了VLAS，一种将语音识别直接集成到机器人策略模型中的新型端到端vision-language-action (VLA) 模型。&lt;h4&gt;背景&lt;/h4&gt;现有的VLA模型主要依赖于仅支持文本指令的视觉-语言模型(VLM)，忽略了更适合人机交互的自然语音模式。传统的语音融合方法通常涉及一个独立的语音识别系统，这会增加复杂性并引入错误传播。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的问题，提出了一种新的端到端VLA模型（VLAS），它直接将语音识别集成到机器人策略模型中。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了VLAS，该模型可以直接理解口语指令并通过内部语音-文本对齐来生成相应的动作。2. 创建了两个新数据集SQA和CSI，支持针对语音命令的三阶段微调过程，使VLAS能够跨文本、图像、语音和机器人动作进行多模式交互。3. 设计了一个基于检索增强生成（RAG）的方法，让模型可以有效处理需要特定知识的任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VLAS能够在广泛的口语命令下有效地完成机器人操作任务，并提供无缝且个性化的交互体验。&lt;h4&gt;结论&lt;/h4&gt;提出了一种全新的VLA框架，直接在机器人策略中集成语音识别功能，显著提高了人机对话的自然性和效率。该模型能够处理多样化的语音指令并成功执行任务，开启了未来机器人和人类更紧密合作的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Vision-language-action 模型（VLAs）由于其端到端的设计和卓越性能，在机器人操作中越来越受欢迎。然而，现有的VLAs主要依赖于仅支持文本指令的视觉-语言模型（VLMs），忽略了更适合人机交互的自然语音模式。传统的语音融合方法通常涉及一个独立的语音识别系统，这会增加复杂性并引入错误传播。此外，转录过程可能会丢失原始语音中的非语义信息，例如声纹，在机器人完成定制任务时这些信息可能至关重要。为了解决上述挑战，我们提出了VLAS，一种新型端到端VLA模型，它直接将语音识别集成到机器人策略模型中。VLAS允许机器人通过内部的语音-文本对齐来理解口头命令，并生成相应动作以执行任务。我们还介绍了两个新数据集SQA和CSI，支持针对语音指令的三阶段微调过程，使VLAS能够跨文本、图像、语音和机器人操作进行多模式交互。更进一步地，设计了一种基于检索增强生成（RAG）的方法来使我们的模型可以有效处理需要特定知识的任务。广泛的实验表明，VLAS能够使用多样化的语音命令有效地完成机器人操作任务，并提供无缝且个性化的交互体验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language-action models (VLAs) have become increasingly popular inrobot manipulation for their end-to-end design and remarkable performance.However, existing VLAs rely heavily on vision-language models (VLMs) that onlysupport text-based instructions, neglecting the more natural speech modalityfor human-robot interaction. Traditional speech integration methods usuallyinvolves a separate speech recognition system, which complicates the model andintroduces error propagation. Moreover, the transcription procedure would losenon-semantic information in the raw speech, such as voiceprint, which may becrucial for robots to successfully complete customized tasks. To overcome abovechallenges, we propose VLAS, a novel end-to-end VLA that integrates speechrecognition directly into the robot policy model. VLAS allows the robot tounderstand spoken commands through inner speech-text alignment and producescorresponding actions to fulfill the task. We also present two new datasets,SQA and CSI, to support a three-stage tuning process for speech instructions,which empowers VLAS with the ability of multimodal interaction across text,image, speech, and robot actions. Taking a step further, a voiceretrieval-augmented generation (RAG) paradigm is designed to enable our modelto effectively handle tasks that require individual-specific knowledge. Ourextensive experiments show that VLAS can effectively accomplish robotmanipulation tasks with diverse speech commands, offering a seamless andcustomized interaction experience.</description>
      <author>example@mail.com (Wei Zhao, Pengxiang Ding, Min Zhang, Zhefei Gong, Shuanghao Bai, Han Zhao, Donglin Wang)</author>
      <guid isPermaLink="false">2502.13508v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Improving Collision-Free Success Rate For Object Goal Visual Navigation Via Two-Stage Training With Collision Prediction</title>
      <link>http://arxiv.org/abs/2502.13498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文研究了基于深度强化学习的端到端导航模型在目标物体导向视觉导航中的碰撞问题，并提出了一种两阶段训练方法来提高现有RGB观测下的导航模型的无碰撞成功率。&lt;h4&gt;背景&lt;/h4&gt;现有的深度强化学习导航模型虽然能较好地发现和到达目标对象，但在导航过程中的碰撞问题仍未解决。碰撞通常被忽略不计，在评估成功时不会对其施加负反馈，导致模型过于保守且难以有效避开障碍物。&lt;h4&gt;目的&lt;/h4&gt;引入无碰撞成功率的概念来衡量导航模型找到通往目标物体的无碰撞路径的能力，并提出一种新的两阶段训练方法以改善现有RGB观测下的导航模型的性能。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段训练策略：在第一阶段，通过监督代理人在探索过程中的碰撞状态学习预测可能发生的碰撞；在第二阶段，利用训练好的碰撞预测模块引导代理人学会在没有碰撞的情况下到达目标物体。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的两阶段训练方法能够显著提高现有导航模型的无碰撞成功率，并优于其他类似的方法。&lt;h4&gt;结论&lt;/h4&gt;新方法提高了基于深度强化学习的目标导向视觉导航系统的性能，在实际应用中可能具有更高的稳定性和安全性。&lt;h4&gt;翻译&lt;/h4&gt;目标导向视觉导航任务是通过第一人称视角的视觉观察来定位特定目标物体。本文针对该任务中的碰撞问题提出了解决方案，即利用两阶段训练策略提高现有模型的无碰撞成功率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The object goal visual navigation is the task of navigating to a specifictarget object using egocentric visual observations. Recent end-to-endnavigation models based on deep reinforcement learning have achieved remarkableperformance in finding and reaching target objects. However, the collisionproblem of these models during navigation remains unresolved, since thecollision is typically neglected when evaluating the success. Althoughincorporating a negative reward for collision during training appearsstraightforward, it results in a more conservative policy, thereby limiting theagent's ability to reach targets. In addition, many of these models utilizeonly RGB observations, further increasing the difficulty of collision avoidancewithout depth information. To address these limitations, a new concept --collision-free success is introduced to evaluate the ability of navigationmodels to find a collision-free path towards the target object. A two-stagetraining method with collision prediction is proposed to improve thecollision-free success rate of the existing navigation models using RGBobservations. In the first training stage, the collision prediction modulesupervises the agent's collision states during exploration to learn to predictthe possible collision. In the second stage, leveraging the trained collisionprediction, the agent learns to navigate to the target without collision. Theexperimental results in the AI2-THOR environment demonstrate that the proposedmethod greatly improves the collision-free success rate of different navigationmodels and outperforms other comparable collision-avoidance methods.</description>
      <author>example@mail.com (Shiwei Lian, Feitian Zhang)</author>
      <guid isPermaLink="false">2502.13498v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Ephemerality meets LiDAR-based Lifelong Mapping</title>
      <link>http://arxiv.org/abs/2502.13452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6+2 pages, 11 figures, accepted at ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ELite是一种基于LiDAR的终生地图构建框架，能够无缝地对多时段数据进行校准、移除动态物体并更新地图。&lt;h4&gt;背景&lt;/h4&gt;长期部署机器人在动态环境中的关键在于终身制图能力。常规的地图元素分类为静态或动态不能完全满足需求，例如停车的车辆需要更详细的类别划分。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够准确区分瞬时与持续性地图元素，并维护可靠、更新及时静态地图的方法。&lt;h4&gt;方法&lt;/h4&gt;通过将世界建模为两阶段$extit{ephemerality}$（瞬时性）的概率模型，该模型在两个不同的时间尺度内表示映射点的易逝性。利用瞬时性所编码的空间和时间上下文信息，ELite能够更精细地校准新数据并提高鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;ELite框架可以准确推断出瞬时地图元素，并维持可靠的更新静态地图。&lt;h4&gt;结论&lt;/h4&gt;该系统的有效性和鲁棒性已在长期的现实世界实验中得到了验证。开源代码可供机器人社区使用。&lt;h4&gt;翻译&lt;/h4&gt;终身制图对于在动态环境中长时间部署机器人至关重要。本文提出了ELite，一种基于LiDAR的终生映射框架，能够无缝地对多时段数据进行校准、移除动态物体并更新地图。地图元素通常被分类为静态或动态，但像停放车辆的情况表明需要比二元更详细类别的划分。我们的方法的核心是将世界建模为两阶段$extit{ephemerality}$的概率模型，它表示了映射点在两个不同时间尺度内的易逝性。通过利用瞬时性所编码的空间和时间上下文信息，ELite能够准确推断出瞬时地图元素，并维持可靠的更新静态地图，并且以更精细的方式提高新数据校准的鲁棒性。广泛的现实世界长期实验展示了我们系统的有效性和鲁棒性。开源代码可供机器人社区使用：https://github.com/dongjae0107/ELite&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lifelong mapping is crucial for the long-term deployment of robots in dynamicenvironments. In this paper, we present ELite, an ephemerality-aidedLiDAR-based lifelong mapping framework which can seamlessly align multiplesession data, remove dynamic objects, and update maps in an end-to-end fashion.Map elements are typically classified as static or dynamic, but cases likeparked cars indicate the need for more detailed categories than binary. Centralto our approach is the probabilistic modeling of the world into two-stage$\textit{ephemerality}$, which represent the transiency of points in the mapwithin two different time scales. By leveraging the spatiotemporal contextencoded in ephemeralities, ELite can accurately infer transient map elements,maintain a reliable up-to-date static map, and improve robustness in aligningthe new data in a more fine-grained manner. Extensive real-world experiments onlong-term datasets demonstrate the robustness and effectiveness of our system.The source code is publicly available for the robotics community:https://github.com/dongjae0107/ELite.</description>
      <author>example@mail.com (Hyeonjae Gil, Dongjae Lee, Giseop Kim, Ayoung Kim)</author>
      <guid isPermaLink="false">2502.13452v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>MapNav: A Novel Memory Representation via Annotated Semantic Maps for VLM-based Vision-and-Language Navigation</title>
      <link>http://arxiv.org/abs/2502.13451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为MapNav的新颖端到端视觉和语言导航模型，该模型在构建Annotated Semantic Map（ASM）时利用了语义地图来替代历史帧，并通过文本标签增强了结构化的导航信息。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉和语言导航方法依赖于大量的时空上下文存储以进行决策，导致显著的存储与计算开销。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型MapNav，旨在减轻传统方法中对大量历史观测数据的需求并改进性能。&lt;h4&gt;方法&lt;/h4&gt;在每次任务开始时构建一个基于顶视图的语义地图，并且随着每一步的时间步更新该地图。通过文本标签为关键区域添加明确的导航提示来生成ASM。利用VLM的强大端到端能力进行导航。&lt;h4&gt;主要发现&lt;/h4&gt;MapNav模型在模拟和真实世界环境中均表现出色，达到了最先进的性能水平。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效减少存储与计算资源需求，并且通过开放源代码和数据集进一步促进了研究的可重复性。&lt;h4&gt;贡献&lt;/h4&gt;为视觉语言导航提供了一种新的记忆表示方法，有望推动该领域未来的研究发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-and-language navigation (VLN) is a key task in Embodied AI, requiringagents to navigate diverse and unseen environments while following naturallanguage instructions. Traditional approaches rely heavily on historicalobservations as spatio-temporal contexts for decision making, leading tosignificant storage and computational overhead. In this paper, we introduceMapNav, a novel end-to-end VLN model that leverages Annotated Semantic Map(ASM) to replace historical frames. Specifically, our approach constructs atop-down semantic map at the start of each episode and update it at eachtimestep, allowing for precise object mapping and structured navigationinformation. Then, we enhance this map with explicit textual labels for keyregions, transforming abstract semantics into clear navigation cues andgenerate our ASM. MapNav agent using the constructed ASM as input, and use thepowerful end-to-end capabilities of VLM to empower VLN. Extensive experimentsdemonstrate that MapNav achieves state-of-the-art (SOTA) performance in bothsimulated and real-world environments, validating the effectiveness of ourmethod. Moreover, we will release our ASM generation source code and dataset toensure reproducibility, contributing valuable resources to the field. Webelieve that our proposed MapNav can be used as a new memory representationmethod in VLN, paving the way for future research in this field.</description>
      <author>example@mail.com (Lingfeng Zhang, Xiaoshuai Hao, Qinwen Xu, Qiang Zhang, Xinyao Zhang, Pengwei Wang, Jing Zhang, Zhongyuan Wang, Shanghang Zhang, Renjing Xu)</author>
      <guid isPermaLink="false">2502.13451v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Physics-Aware Robotic Palletization with Online Masking Inference</title>
      <link>http://arxiv.org/abs/2502.13443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一种基于强化学习的方法来解决在线环境下的箱子堆放问题，这种方法考虑了盒子的物理属性，并在实际应用中证明其有效性。&lt;h4&gt;背景&lt;/h4&gt;现代仓储和物流管理中的物品堆叠计划是一个重要挑战。现有解决方案通常处理不同尺寸的盒子，但忽略它们的密度、刚度等内在和物理特性。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用强化学习并结合动作空间屏蔽的新方法来解决箱子堆放问题，使其更加适应实际场景的需求。&lt;h4&gt;方法&lt;/h4&gt;使用强化学习并通过动作空间掩码机制动态训练有效动作，不需要人为设计启发式规则。这种方法能够在线学习盒子的物理特性，并据此规划堆叠策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验验证了新提出的方法在性能上超越现有的最先进算法；并且将该方法部署到一个实际应用中的机器人托盘装载机中进行测试。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于强化学习的方法有效地解决了在线环境下的箱子堆放问题，并展示了其在真实世界操作设置中的实用性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The efficient planning of stacking boxes, especially in the online settingwhere the sequence of item arrivals is unpredictable, remains a criticalchallenge in modern warehouse and logistics management. Existing solutionsoften address box size variations, but overlook their intrinsic and physicalproperties, such as density and rigidity, which are crucial for real-worldapplications. We use reinforcement learning (RL) to solve this problem byemploying action space masking to direct the RL policy toward valid actions.Unlike previous methods that rely on heuristic stability assessments which aredifficult to assess in physical scenarios, our framework utilizes onlinelearning to dynamically train the action space mask, eliminating the need formanual heuristic design. Extensive experiments demonstrate that our proposedmethod outperforms existing state-of-the-arts. Furthermore, we deploy ourlearned task planner in a real-world robotic palletizer, validating itspractical applicability in operational settings.</description>
      <author>example@mail.com (Tianqi Zhang, Zheng Wu, Yuxin Chen, Yixiao Wang, Boyuan Liang, Scott Moura, Masayoshi Tomizuka, Mingyu Ding, Wei Zhan)</author>
      <guid isPermaLink="false">2502.13443v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Generative Predictive Control: Flow Matching Policies for Dynamic and Difficult-to-Demonstrate Tasks</title>
      <link>http://arxiv.org/abs/2502.13406v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种新的机器人控制策略——生成式预测控制，旨在解决现有的基于行为克隆的生成政策方法在获取专家演示数据上的时间和成本问题以及处理快速动态任务时的局限性。&lt;h4&gt;背景&lt;/h4&gt;近年来，通过扩散或流匹配产生的行动序列的方法为机器人技术带来了重大进展。然而，这些方法存在两个主要限制：需要专家提供的大量时间与资金以获取高质量的演示数据，并且现有方法仅限于处理相对缓慢、准静态的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决当前生成策略局限性的新框架——生成式预测控制（Generative Predictive Control），用于处理快速动态任务，这类任务虽然难以展示但易于模拟。&lt;h4&gt;方法&lt;/h4&gt;利用采样基础的预测控制与生成模型之间的紧密联系。该论文介绍了如何在运行时通过流匹配政策进行热启动来保持时间一致性并实现快速反馈速率。&lt;h4&gt;主要发现&lt;/h4&gt;生成式预测控制能够提供一种不同于现有行为克隆方法的新途径，并有望为超越准静态任务领域的通才策略铺平道路。&lt;h4&gt;结论&lt;/h4&gt;该论文提出了一种新的机器人控制框架，通过结合采样基础的预测控制和生成模型的方法来处理快速动态的任务。这种方法在理论上解决了基于演示数据的传统生成式政策的关键限制，从而开辟了未来研究的新方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成性控制策略最近为机器人技术带来了重大突破。这些方法通过扩散或流匹配产生行动序列，并利用演示数据进行训练。然而，在困难的操作问题上虽然取得了相当大的成功，但这种策略却存在两个主要限制：首先，行为克隆需要专家示范，获取起来耗时且昂贵；其次，现有方法仅限于相对缓慢、准静态的任务。在本文中，我们借助采样基础的预测控制与生成建模之间的紧密联系来解决这些问题。具体来说，我们引入了一种用于具有快速动态特性的任务的新框架——生成式预测控制（Generative Predictive Control），这些任务易于模拟但难以演示。接着展示了如何在运行时通过训练好的流匹配政策进行热启动以保持时间一致性并实现高速反馈率。我们认为，生成式预测控制为现有的行为克隆方法提供了一种互补的方法，并希望它能开启超越准静态展示导向型任务的通才策略之路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative control policies have recently unlocked major progress inrobotics. These methods produce action sequences via diffusion or flowmatching, with training data provided by demonstrations. But despite enjoyingconsiderable success on difficult manipulation problems, generative policiescome with two key limitations. First, behavior cloning requires expertdemonstrations, which can be time-consuming and expensive to obtain. Second,existing methods are limited to relatively slow, quasi-static tasks. In thispaper, we leverage a tight connection between sampling-based predictive controland generative modeling to address each of these issues. In particular, weintroduce generative predictive control, a supervised learning framework fortasks with fast dynamics that are easy to simulate but difficult todemonstrate. We then show how trained flow-matching policies can bewarm-started at run-time, maintaining temporal consistency and enabling fastfeedback rates. We believe that generative predictive control offers acomplementary approach to existing behavior cloning methods, and hope that itpaves the way toward generalist policies that extend beyond quasi-staticdemonstration-oriented tasks.</description>
      <author>example@mail.com (Vince Kurtz, Joel W. Burdick)</author>
      <guid isPermaLink="false">2502.13406v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Object-Pose Estimation With Neural Population Codes</title>
      <link>http://arxiv.org/abs/2502.13403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了机器人装配任务中物体姿态估计的问题，特别是对于避免昂贵机械约束的任务。提出了使用神经群体编码表示对象旋转的方法，克服了现有方法计算量大的问题。&lt;h4&gt;背景&lt;/h4&gt;在进行机器人的装配作业时，准确地对齐物体的姿势是必要的，特别是在需要减少机械限制成本的情况下。然而，当面对具有镜像或旋转对称性的物体时，这种对齐过程变得复杂且难以直接将感官输入映射到对象旋转上。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过引入神经网络群体编码来实现更为高效准确的物体姿态估计方法，并避免传统解决方法中大量计算开销的问题。&lt;h4&gt;方法&lt;/h4&gt;利用神经网络群体编码表示物体旋转，这使得可以直接对齐输入图像与目标旋转角度，从而能够端到端地训练模型。该方法通过概率分布预测多个假设的可能性来克服先前提出的解决方案所面临的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示，在T-LESS数据集上采用灰度图像作为唯一输入的情况下，使用群体编码的模型能够在Apple M1 CPU上实现3.2毫秒内的推断速度，并达到84.7%的最大对称性感知表面距离精度。相比之下，直接映射到姿态的方法仅能达到69.7%的准确性。&lt;h4&gt;结论&lt;/h4&gt;神经网络群体编码为物体旋转提供了有效的表示方法，从而使得机器人装配任务中的对象姿态估计变得更快更准确。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经进行了中文翻译，并且上述所有项目均已根据原始英文摘要的内容进行填充。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic assembly tasks require object-pose estimation, particularly for tasksthat avoid costly mechanical constraints. Object symmetry complicates thedirect mapping of sensory input to object rotation, as the rotation becomesambiguous and lacks a unique training target. Some proposed solutions involveevaluating multiple pose hypotheses against the input or predicting aprobability distribution, but these approaches suffer from significantcomputational overhead. Here, we show that representing object rotation with aneural population code overcomes these limitations, enabling a direct mappingto rotation and end-to-end learning. As a result, population codes facilitatefast and accurate pose estimation. On the T-LESS dataset, we achieve inferencein 3.2 milliseconds on an Apple M1 CPU and a Maximum Symmetry-Aware SurfaceDistance accuracy of 84.7% using only gray-scale image input, compared to 69.7%accuracy when directly mapping to pose.</description>
      <author>example@mail.com (Heiko Hoffmann, Richard Hoffmann)</author>
      <guid isPermaLink="false">2502.13403v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Reflection of Episodes: Learning to Play Game from Expert and Self Experiences</title>
      <link>http://arxiv.org/abs/2502.13388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;StarCraft II是一款复杂且动态的即时战略游戏环境，适用于人工智能和强化学习研究。为解决大型语言模型在复杂环境中通过自我反思进行学习的问题，提出了一种基于专家经验和自我经验的反射事件（ROE）框架。&lt;h4&gt;背景&lt;/h4&gt;StarCraft II是一个高度复杂的实时策略游戏环境，非常适合用于人工智能和强化学习的研究领域。&lt;h4&gt;目的&lt;/h4&gt;为了应对大型语言模型在复杂环境下通过自我反思来学习这一挑战，开发了一种新的框架。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于专家经验和自我经验的反射事件(ROE)框架。该框架首先通过关键帧选择法获取游戏中的关键信息，然后根据这些信息做出决策；每完成一局游戏后，进行回顾以获得新的自我经验。&lt;h4&gt;主要发现&lt;/h4&gt;实验中，我们的方法在TextStarCraft II的非常难难度下击败了机器人。&lt;h4&gt;结论&lt;/h4&gt;详细分析了大型语言模型在游戏中各个阶段的数据，验证了该方法的有效性&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已翻译为中文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; StarCraft II is a complex and dynamic real-time strategy (RTS) gameenvironment, which is very suitable for artificial intelligence andreinforcement learning research. To address the problem of Large LanguageModel(LLM) learning in complex environments through self-reflection, we proposea Reflection of Episodes(ROE) framework based on expert experience andself-experience. This framework first obtains key information in the gamethrough a keyframe selection method, then makes decisions based on expertexperience and self-experience. After a game is completed, it reflects on theprevious experience to obtain new self-experience. Finally, in the experiment,our method beat the robot under the Very Hard difficulty in TextStarCraft II.We analyze the data of the LLM in the process of the game in detail, verifiedits effectiveness.</description>
      <author>example@mail.com (Xiaojie Xu, Zongyuan Li, Chang Lu, Runnan Qi, Yanan Ni, Lumin Jiang, Xiangbei Liu, Xuebo Zhang, Yongchun Fang, Kuihua Huang, Xian Guo, Zhanghua Wu, Zhenya Li)</author>
      <guid isPermaLink="false">2502.13388v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Low-Complexity Cooperative Payload Transportation for Nonholonomic Mobile Robots Under Scalable Constraints</title>
      <link>http://arxiv.org/abs/2502.13366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;合作运输是物流网络中的一个关键环节，在这种情况下，通常使用分布式控制和基于优化的方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的非完整移动机器人的合作运输方法来克服传统方法的缺点，该方法能够有效处理约束且具有可扩展性。&lt;h4&gt;方法&lt;/h4&gt;改进了传统的编队控制方式，提出了一个新型的合作运输方法。这个方法分为两个部分：机器人轨迹生成和轨迹跟踪。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的基于控制的方法不仅容易扩展到多个约束条件上，还降低了优化方法的时间复杂度，从多项式降至线性。&lt;h4&gt;结论&lt;/h4&gt;通过仿真实验验证了所提合作运输方法的可行性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种改进传统编队控制的合作运输方法的应用于非完整移动机器人领域。该方法具有分布式特性，时间复杂度低，并能适应可扩展约束条件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cooperative transportation, a key aspect of logistics  cyber-physical systems (CPS), is typically approached using dis tributedcontrol and optimization-based methods. The distributed  control methods consume less time, but poorly handle and extend  to multiple constraints. Instead, optimization-based methods  handle constraints effectively, but they are usually centralized,  time-consuming and thus not easily scalable to numerous robots.  To overcome drawbacks of both, we propose a novel cooperative  transportation method for nonholonomic mobile robots by im provingconventional formation control, which is distributed, has  a low time-complexity and accommodates scalable constraints.  The proposed control-based method is testified on a cable suspended payloadand divided into two parts, including robot  trajectory generation and trajectory tracking. Unlike most time consumingtrajectory generation methods, ours can generate  trajectories with only constant time-complexity, needless of global  maps. As for trajectory tracking, our control-based method not  only scales easily to multiple constraints as those optimization basedmethods, but reduces their time-complexity from poly nomial to linear.Simulations and experiments can verify the  feasibility of our method.</description>
      <author>example@mail.com (Renhe Guan, Yuanzhe Wang, Tao Liu, Yan Wang)</author>
      <guid isPermaLink="false">2502.13366v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>BoundPlanner: A convex-set-based approach to bounded manipulator trajectory planning</title>
      <link>http://arxiv.org/abs/2502.13286v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于凸集的在线轨迹规划框架，包括新的笛卡尔路径规划器BoundPlanner和扩展后的在线轨迹规划器BoundMPC。该框架能够在复杂环境中快速为机器人制定合适的轨迹，并考虑机器人的动力学限制和碰撞问题。&lt;h4&gt;背景&lt;/h4&gt;现有的许多机器人轨迹规划方法虽然适用于已知环境，但在实时计算方面效率较低，无法在具有挑战性的场景中找到满足机器人约束条件的路径。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的在线轨迹规划框架，能够为机器人制定合适的、符合其物理限制且考虑碰撞问题的路径。&lt;h4&gt;方法&lt;/h4&gt;{'BoundPlanner': '利用凸集探索和映射无障碍空间，并计算出具有边界的参考路径。', 'BoundMPC': '扩展了模型预测控制算法以处理路径偏移时的凸集合，使机器人能够在边界内最优地跟随路径并考虑其动力学特性。', '碰撞避免方法': '开发了一种独立于障碍物数量的新颖凸集基碰撞规避公式，来应对机器人连杆之间的碰撞问题。'}&lt;h4&gt;主要发现&lt;/h4&gt;在仿真和实验中验证了所提规划器的性能优于现有先进技术，并且该框架适用于具有7个自由度的机械臂。&lt;h4&gt;结论&lt;/h4&gt;新提出的轨迹规划方法能够有效解决在线环境中的挑战性问题，为机器人提供了快速反应能力和路径优化方案。源代码可在GitHub上获得，实验视频可通过提供的网站链接观看。&lt;h4&gt;翻译&lt;/h4&gt;在线轨迹规划使机器人能够迅速应对变化的工作环境或任务需求。许多现有的机器人轨迹规划器仅适用于已知环境，并且通常无法满足实时计算的要求。目前的方法在处理具有挑战性的场景时不能找到符合机器人类型限制并考虑碰撞的合适路径。本文提出了一种新的轨迹规划框架，包括基于凸集的新笛卡尔路径规划器BoundPlanner和在线轨迹规划器BoundMPC（扩展版）。BoundPlanner利用凸集合探索无障碍空间，并计算出具有边界的参考路径。BoundMPC被扩展来处理路径偏差时的凸集合问题，使机器人能够在其边界内最优地跟随路径同时考虑机器人的动力学特性。我们提出了一种新的基于凸集的碰撞规避公式独立于障碍物的数量，从而考虑到机器人连杆之间的碰撞问题。通过与最先进的方法进行比较，在一个具有7个自由度机械臂上的仿真和实验展示了所提出的规划器的表现能力。源代码可在GitHub（github.com/Thieso/BoundPlanner）上获得，并且在提供的网站链接www.acin.tuwien.ac.at/42d4可找到实验视频。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Online trajectory planning enables robot manipulators to react quickly tochanging environments or tasks. Many robot trajectory planners exist for knownenvironments but are often too slow for online computations. Current methods inonline trajectory planning do not find suitable trajectories in challengingscenarios that respect the limits of the robot and account for collisions. Thiswork proposes a trajectory planning framework consisting of the novel Cartesianpath planner based on convex sets, called BoundPlanner, and the onlinetrajectory planner BoundMPC. BoundPlanner explores and maps the collision-freespace using convex sets to compute a reference path with bounds. BoundMPC isextended in this work to handle convex sets for path deviations, which allowsthe robot to optimally follow the path within the bounds while accounting forthe robot's kinematics. Collisions of the robot's kinematic chain areconsidered by a novel convex-set-based collision avoidance formulationindependent on the number of obstacles. Simulations and experiments with a7-DoF manipulator show the performance of the proposed planner compared tostate-of-the-art methods. The source code is available atgithub.com/Thieso/BoundPlanner and videos of the experiments can be found atwww.acin.tuwien.ac.at/42d4</description>
      <author>example@mail.com (Thies Oelerich, Christian Hartl-Nesic, Florian Beck, Andreas Kugi)</author>
      <guid isPermaLink="false">2502.13286v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>PCB Renewal: Iterative Reuse of PCB Substrates for Sustainable Electronic Making</title>
      <link>http://arxiv.org/abs/2502.13255v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了PCB Renewal技术，该技术通过在旧PCB上选择性地沉积导电环氧树脂来擦除和重新配置电路路径，从而减少电子制造过程中的材料浪费。&lt;h4&gt;背景&lt;/h4&gt;印刷电路板（PCB）基材通常是一次性的，这导致了电子产品的材料浪费问题。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的技术——PCB Renewal，该技术能够通过沉积导电环氧树脂将旧的PCB进行改造和再利用。&lt;h4&gt;方法&lt;/h4&gt;展示了PCB Renewal的工作流程，并对其电气性能、机械耐久性进行了评估。还建立了一个软件插件来指导环氧树脂的沉积过程以及生成更新后的PCB配置文件。&lt;h4&gt;主要发现&lt;/h4&gt;通过四个设计迭代实例（包括相机滚轮、WiFi电台和ESPboy游戏控制台）展示了技术的有效性和多功能性，同时还展示了一块外包生产的双层PCB从LED手表转换为互动猫玩具的过程。&lt;h4&gt;结论&lt;/h4&gt;文章总结了该方法的局限性，并探讨了未来的研究方向。这项技术在减少材料浪费方面具有巨大的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：PCB（印刷电路板）基材通常是一次性的，导致电子制造中的材料浪费问题。我们介绍了PCB Renewal这一新技术，它通过选择性沉积导电环氧树脂来擦除和重新配置PCB迹线，将孤立路径转变为支持新迹线的导电平面。文章展示了PCB Renewal的工作流程，并对其电气性能、机械耐久性和可持续性影响进行了评估，包括材料使用情况、成本、能源消耗和时间节省等方面。还开发了一个软件插件来指导环氧树脂沉积过程、生成更新后的PCB配置文件以及计算资源使用情况。为了证明该技术的有效性和多功能性，我们在三个项目中进行了一块PCB的四个设计迭代：相机滚轮、WiFi电台和ESPboy游戏控制台；此外，还展示了如何将一个外包生产的双层PCB从LED手表重新配置为互动猫玩具的过程。文章最后总结了限制条件并探讨了未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3714276&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; PCB (printed circuit board) substrates are often single-use, leading tomaterial waste in electronics making. We introduce PCB Renewal, a noveltechnique that "erases" and "reconfigures" PCB traces by selectively depositingconductive epoxy onto outdated areas, transforming isolated paths intoconductive planes that support new traces. We present the PCB Renewal workflow,evaluate its electrical performance and mechanical durability, and model itssustainability impact, including material usage, cost, energy consumption, andtime savings. We develop a software plug-in that guides epoxy deposition,generates updated PCB profiles, and calculates resource usage. To demonstratePCB Renewal's effectiveness and versatility, we repurpose a single PCB acrossfour design iterations spanning three projects: a camera roller, a WiFi radio,and an ESPboy game console. We also show how an outsourced double-layer PCB canbe reconfigured, transforming it from an LED watch to an interactive cat toy.The paper concludes with limitations and future directions.</description>
      <author>example@mail.com (Zeyu Yan, Advait Vartak, Jiasheng Li, Zining Zhang, Huaishu Peng)</author>
      <guid isPermaLink="false">2502.13255v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Intelligent Soft Matter: Towards Embodied Intelligence</title>
      <link>http://arxiv.org/abs/2502.13224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概述&lt;/h4&gt;智能软物质位于材料科学、物理学和认知科学的交汇点，旨在改变我们设计与使用材料的方式。&lt;h4&gt;背景&lt;/h4&gt;传统材料通常执行静态或预定义的功能，而智能软物质能够动态地与其环境相互作用。它结合了多种感官输入，保留经验并作出决策以优化其反应。&lt;h4&gt;目的&lt;/h4&gt;通过借鉴生物系统，这些材料旨在利用柔软物质的固有属性（如灵活性、自演化和响应性）来执行模仿认知过程的功能，并展望智能软物质如何被构建。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种前瞻性的视角，讨论了设计传感、记忆与动作之间的集成以及内部低功耗操作的新途径，并探讨了具有“智能行为”的材料在实际应用中的挑战。&lt;h4&gt;结论&lt;/h4&gt;这些方法勾勒出一条通往更具鲁棒性、多功能性和可扩展性材料的道路，这种材料能够通过其固有的内在物质行为来行动、计算和“思考”，超越传统的需要外部控制的智能技术。&lt;h4&gt;翻译&lt;/h4&gt;智能软物质处于材料科学、物理学及认知科学的交汇点，承诺将改变我们设计与互动使用材料的方式。这一变革性的领域旨在创造具备生命特征能力（如感知、学习、记忆和适应性行为）的材料。与传统材料通常执行静态或预定义功能不同，智能软物质能与其环境动态交互。它融合了多种感官输入，保留经验并作出决策以优化其响应。受生物系统的启发，这些材料旨在利用柔软物质的固有属性（如灵活性、自演化及响应性）来实现模仿认知过程的功能。通过整合当前研究趋势和展望未来的发展方向，本文提供了一种前瞻性观点，即智能软物质如何构建，并意在激发包括生物医学设备和适应性机器人在内的领域的创新。文中还强调了将传感设计、记忆与动作的集成以及内部低功耗操作的新途径，并讨论了具有'智能行为'材料的实际应用挑战。这些方法描绘出了一条通往更为鲁棒、多功能及可扩展材料的道路，这种材料能够通过其内在固有的物质特性来行动、计算并“思考”，超越依赖外部控制的传统智能技术的范畴。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intelligent soft matter stands at the intersection of materials science,physics, and cognitive science, promising to change how we design and interactwith materials. This transformative field seeks to create materials thatpossess life-like capabilities, such as perception, learning, memory, andadaptive behavior. Unlike traditional materials, which typically perform staticor predefined functions, intelligent soft matter dynamically interacts with itsenvironment. It integrates multiple sensory inputs, retains experiences, andmakes decisions to optimize its responses. Inspired by biological systems,these materials intend to leverage the inherent properties of soft matter:flexibility, self-evolving, and responsiveness to perform functions that mimiccognitive processes. By synthesizing current research trends and projectingtheir evolution, we present a forward-looking perspective on how intelligentsoft matter could be constructed, with the aim of inspiring innovations infields such as biomedical devices, adaptive robotics, and beyond. We highlightnew pathways for integrating design of sensing, memory and action with internallow-power operations and discuss challenges for practical implementation ofmaterials with "intelligent behavior". These approaches outline a path towardsto more robust, versatile and scalable materials that can potentially act,compute, and "think" by their inherent intrinsic material behaviour beyondtraditional smart technologies relying on external control.</description>
      <author>example@mail.com (Vladimir A. Baulin, Achille Giacometti, Dmitry Fedosov, Stephen Ebbens, Nydia R. Varela-Rosales, Neus Feliu, Mithun Chowdhury, Minghan Hu, Rudolf Füchslin, Marjolein Dijkstra, Matan Mussel, René van Roij, Dong Xie, Vassil Tzanov, Mengjie Zu, Samuel Hidalgo-Caballero, Ye Yuan, Luca Cocconi, Cheol-Min Ghim, Cécile Cottin-Bizonne, M. Carmen Miguel, Maria Jose Esplandiu, Juliane Simmchen, Wolfgang J. Parak, Marco Werner, Gerhard Gompper, Martin M. Hanczyc)</author>
      <guid isPermaLink="false">2502.13224v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>ReStyle3D: Scene-Level Appearance Transfer with Semantic Correspondences</title>
      <link>http://arxiv.org/abs/2502.10377v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://restyle3d.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了一种名为ReStyle3D的新框架，用于从单张风格图像到多视图表示的真实世界场景的场景级别外观转换。&lt;h4&gt;背景&lt;/h4&gt;现有的风格化方法通常以全局方式应用参考样式，这可能导致语义不匹配和多视角一致性问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架来实现更精确、一致且语义忠实的场景级风格转移。&lt;h4&gt;方法&lt;/h4&gt;{'开放词汇分割': '用于在风格图像和真实世界图像之间建立密集、实例级别的对应关系，确保每个对象都使用语义匹配的纹理进行样式化。', '训练自由机制': '首先在一个扩散模型中通过语义注意力机制将风格转移到单个视图上。', '学习网络': '然后通过一个受单眼深度和像素级对应信息指导的学习变形并细化网络，将风格提升到额外的视角。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'结构保存': 'ReStyle3D在结构保持、感知样式相似性和多视角一致性方面优于先前的方法。', '用户研究': '进一步验证了其生成逼真且语义忠实的结果的能力。'}&lt;h4&gt;结论&lt;/h4&gt;代码、预训练模型和数据集将公开发布，以支持室内设计、虚拟布景以及3D一致风格化的新应用。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为ReStyle3D的新型框架，用于从单张样式图像向由多视角表示的真实世界场景进行场景级外观转移。该方法结合了显式的语义对应与多视图一致性来实现精确且连贯的风格化。不同于传统的将参考样式全局应用的方法，ReStyle3D使用开放词汇分割在风格和真实世界图像之间建立了密集、实例级别的对应关系，确保每个对象都用语义匹配的纹理进行样式化。它首先在一个训练自由的语义注意力机制中通过扩散模型将样式转移到单个视图上，并随后通过受单眼深度和像素级对应信息指导的学习变形并细化网络提升到额外视图。实验表明，在结构保持、感知风格相似性和多视角一致性方面，ReStyle3D优于先前的方法。用户研究进一步验证了其生成逼真且语义忠实结果的能力。我们的代码、预训练模型以及数据集将公开发布以支持室内设计、虚拟布景及3D一致的样式化的新应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce ReStyle3D, a novel framework for scene-level appearance transferfrom a single style image to a real-world scene represented by multiple views.The method combines explicit semantic correspondences with multi-viewconsistency to achieve precise and coherent stylization. Unlike conventionalstylization methods that apply a reference style globally, ReStyle3D usesopen-vocabulary segmentation to establish dense, instance-level correspondencesbetween the style and real-world images. This ensures that each object isstylized with semantically matched textures. It first transfers the style to asingle view using a training-free semantic-attention mechanism in a diffusionmodel. It then lifts the stylization to additional views via a learnedwarp-and-refine network guided by monocular depth and pixel-wisecorrespondences. Experiments show that ReStyle3D consistently outperforms priormethods in structure preservation, perceptual style similarity, and multi-viewcoherence. User studies further validate its ability to producephoto-realistic, semantically faithful results. Our code, pretrained models,and dataset will be publicly released, to support new applications in interiordesign, virtual staging, and 3D-consistent stylization.</description>
      <author>example@mail.com (Liyuan Zhu, Shengqu Cai, Shengyu Huang, Gordon Wetzstein, Naji Khosravan, Iro Armeni)</author>
      <guid isPermaLink="false">2502.10377v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
  <item>
      <title>Pre-training Auto-regressive Robotic Models with 4D Representations</title>
      <link>http://arxiv.org/abs/2502.13142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文介绍了一种新的自动回归机器人模型ARM4R，它利用从人类视频数据中学习到的低级4D表示来预训练更优的机器人模型。&lt;h4&gt;背景&lt;/h4&gt;大规模未标记的数据集预先训练的基石模型已经在自然语言和计算机视觉领域引发了革命性的变化，并展示了出色的泛化能力，这突显了预训练的重要性。然而，在机器人技术方面的努力却难以取得类似的成功，受到高昂的人工注释成本或缺乏有效建模物理世界的表示形式限制。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的自动回归机器人模型ARM4R，利用人类视频数据中的低级4D表示来改进机器人的预训练。&lt;h4&gt;方法&lt;/h4&gt;通过单目深度估计从时间上提升2D表示到3D空间中获取的点跟踪表示，这些4D表示在点和机器人状态之间保持了一致的几何结构。这种方法使人类视频数据的有效转移学习到低级机器人控制成为可能。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明ARM4R能够有效地将从人类视频数据转移到机器人，并且能在各种环境和配置下的任务中持续提高性能。&lt;h4&gt;结论&lt;/h4&gt;ARM4R提供了一种新的途径来利用大规模的人类视频数据进行机器人的预训练，这有助于解决当前机器人技术面临的挑战。&lt;h4&gt;翻译&lt;/h4&gt;基石模型在大量未标记的数据集上预先训练，在自然语言处理和计算机视觉领域引发了革命性的变化，并展示了卓越的泛化能力。然而，机器人领域的研究努力却难以取得同样的成功，受限于昂贵的人工注释成本或无法有效建模物理世界的表示方法。本文提出了一种新的自动回归机器人模型ARM4R，它利用从人类视频数据中学习到的低级4D表示来预训练更优的机器人模型。实验表明，这种模型能够高效地将知识从人类视频转移到机器人的控制任务上，并在多种机器人环境和配置下持续提升性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models pre-trained on massive unlabeled datasets haverevolutionized natural language and computer vision, exhibiting remarkablegeneralization capabilities, thus highlighting the importance of pre-training.Yet, efforts in robotics have struggled to achieve similar success, limited byeither the need for costly robotic annotations or the lack of representationsthat effectively model the physical world. In this paper, we introduce ARM4R,an Auto-regressive Robotic Model that leverages low-level 4D Representationslearned from human video data to yield a better pre-trained robotic model.Specifically, we focus on utilizing 3D point tracking representations fromvideos derived by lifting 2D representations into 3D space via monocular depthestimation across time. These 4D representations maintain a shared geometricstructure between the points and robot state representations up to a lineartransformation, enabling efficient transfer learning from human video data tolow-level robotic control. Our experiments show that ARM4R can transferefficiently from human video data to robotics and consistently improvesperformance on tasks across various robot environments and configurations.</description>
      <author>example@mail.com (Dantong Niu, Yuvan Sharma, Haoru Xue, Giscard Biamby, Junyi Zhang, Ziteng Ji, Trevor Darrell, Roei Herzig)</author>
      <guid isPermaLink="false">2502.13142v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Databases: A Survey</title>
      <link>http://arxiv.org/abs/2502.12908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A survey focus on GNNs and databases. 9 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了图神经网络（GNN）在数据库系统中的应用，并提出了一个新的分类体系。&lt;h4&gt;背景&lt;/h4&gt;近年来，图神经网络因其处理图结构数据的强大能力，在各个领域展现了显著的成功。数据库社区也逐渐认识到GNN的潜力，并涌现出大量研究试图通过基于GNN的方法改进数据库系统。&lt;h4&gt;目的&lt;/h4&gt;为了填补现有研究中关于如何利用GNN提升数据库系统的全面理解和综述这一空白，本调查旨在提供一个结构化且深入的概览。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新的分类体系将现有的方法分为两大类：关系型数据库和图形数据库，并对每一类别中的关键技术进行了系统性回顾。&lt;h4&gt;主要发现&lt;/h4&gt;分别总结了每种类型的方法及其贡献与实际应用，指出了在关系型数据库中包括性能预测、查询优化以及文本到SQL任务等，在图数据库中则涉及高效图查询处理及相似度计算等领域面临的挑战和解决方案。&lt;h4&gt;结论&lt;/h4&gt;本论文建议了一些有前景的途径，旨在将GNN更深入地集成到数据库系统当中。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）是用于图形结构数据的强大深度学习模型，在各个领域展示出了显著的成功。近年来，数据库社区逐渐认识到GNN的巨大潜力，因此越来越多的研究关注通过基于GNN的方法改进数据库系统。然而，尽管已经取得了可观的进步，关于如何利用GNN提升数据库系统的全面理解仍然不足。因此，本文旨在填补这一空白，提供一个结构化和深入的综述。具体而言，我们提出了一种新的分类体系，将现有的方法分为两类：关系型数据库（包括性能预测、查询优化和文本到SQL任务）以及图形数据库（解决高效图查询处理和相似性计算等挑战）。系统地回顾了每个类别中的关键方法，并强调了它们的贡献和实际意义。最后，我们建议了一些有前景的方法，以将GNN更好地融入到数据库系统中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are powerful deep learning models forgraph-structured data, demonstrating remarkable success across diverse domains.Recently, the database (DB) community has increasingly recognized thepotentiality of GNNs, prompting a surge of researches focusing on improvingdatabase systems through GNN-based approaches. However, despite notableadvances, There is a lack of a comprehensive review and understanding of howGNNs could improve DB systems. Therefore, this survey aims to bridge this gapby providing a structured and in-depth overview of GNNs for DB systems.Specifically, we propose a new taxonomy that classifies existing methods intotwo key categories: (1) Relational Databases, which includes tasks likeperformance prediction, query optimization, and text-to-SQL, and (2) GraphDatabases, addressing challenges like efficient graph query processing andgraph similarity computation. We systematically review key methods in eachcategory, highlighting their contributions and practical implications. Finally,we suggest promising avenues for integrating GNNs into Database systems.</description>
      <author>example@mail.com (Ziming Li, Youhuan Li, Yuyu Luo, Guoliang Li, Chuxu Zhang)</author>
      <guid isPermaLink="false">2502.12908v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RobuRCDet: Enhancing Robustness of Radar-Camera Fusion in Bird's Eye View for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.13071v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种鲁棒的雷达-相机3D目标检测模型，以应对环境和固有干扰。&lt;h4&gt;背景&lt;/h4&gt;低成本雷达-相机方法在多模态3D对象检测中表现出色，但这些传感器面临着来自环境（如光线或天气条件）以及内在因素（如噪声、位置模糊性）的挑战。为了实现鲁棒的雷达-相机3D目标检测，在各种条件下保持一致性能的要求尚未被充分探索。&lt;h4&gt;目的&lt;/h4&gt;首次系统分析了雷达-相机在五种不同噪音下的稳健性，并提出了一个新颖的鲁棒对象检测模型RobuRCDet，该模型适用于基于鸟瞰图（BEV）中的3D物体检测。&lt;h4&gt;方法&lt;/h4&gt;设计了一种3DGaussian Expansion (3DGE)模块来减少雷达点错误，包括位置、雷达截面(RCS)和速度。此外，引入了一个天气自适应融合模块，根据相机信号信心进行雷达与摄像头特征的动态融合。&lt;h4&gt;主要发现&lt;/h4&gt;RobuRCDet模型在常规条件和有噪声条件下均表现出竞争力的结果，在nuScenes基准测试中尤其有效。&lt;h4&gt;结论&lt;/h4&gt;该研究为克服环境干扰带来的挑战提供了新的视角，并通过3DGE模块和天气自适应融合机制，显著提高了雷达-相机目标检测的准确性与鲁棒性。未来工作可能继续探索更多稳健策略以进一步提高性能。&lt;h4&gt;翻译&lt;/h4&gt;最近低成本的雷达-相机方法在多模态三维物体检测中显示了令人鼓舞的结果，但是这些传感器都面临着环境和固有干扰的问题。不良照明或恶劣天气条件会降低摄像机的表现，而雷达则遭受噪声和位置模糊性的困扰。为了实现鲁棒的雷达-相机3D目标检测，在各种条件下保持一致性能的要求尚未被充分探索。在这项工作中，我们首先对五种不同噪音下的雷达-相机检测进行了系统分析，并提出了一种名为RobuRCDet的新鲁棒物体检测模型，该模型适用于基于鸟瞰图（BEV）中的3D物体检测。特别地，我们设计了一个三维高斯扩展模块（3DGaussian Expansion, 3DGE），用于减少雷达点的不准确性包括位置、雷达截面（RCS）、和速度方面的错误。这个3DGE使用了RCS和速度的先验知识来生成可变形核图并调整内核大小以进行值分布调节。此外，我们引入了一个天气适应性融合模块，能够根据相机信号信心动态地融合雷达与摄像头特征。在流行基准nuScenes上进行的大量实验表明，我们的模型即使在常规和有噪声条件下也能实现具有竞争力的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While recent low-cost radar-camera approaches have shown promising results inmulti-modal 3D object detection, both sensors face challenges fromenvironmental and intrinsic disturbances. Poor lighting or adverse weatherconditions degrade camera performance, while radar suffers from noise andpositional ambiguity. Achieving robust radar-camera 3D object detectionrequires consistent performance across varying conditions, a topic that has notyet been fully explored. In this work, we first conduct a systematic analysisof robustness in radar-camera detection on five kinds of noises and proposeRobuRCDet, a robust object detection model in BEV. Specifically, we design a 3DGaussian Expansion (3DGE) module to mitigate inaccuracies in radar points,including position, Radar Cross-Section (RCS), and velocity. The 3DGE uses RCSand velocity priors to generate a deformable kernel map and variance for kernelsize adjustment and value distribution. Additionally, we introduce aweather-adaptive fusion module, which adaptively fuses radar and camerafeatures based on camera signal confidence. Extensive experiments on thepopular benchmark, nuScenes, show that our model achieves competitive resultsin regular and noisy conditions.</description>
      <author>example@mail.com (Jingtong Yue, Zhiwei Lin, Xin Lin, Xiaoyu Zhou, Xiangtai Li, Lu Qi, Yongtao Wang, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2502.13071v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Circuit Representation Learning with Masked Gate Modeling and Verilog-AIG Alignment</title>
      <link>http://arxiv.org/abs/2502.12732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了MGVGA，一种新的约束掩码建模范式，旨在解决电路表示学习中的逻辑等价性问题，并促进从大语言模型中学习电路功能。&lt;h4&gt;背景&lt;/h4&gt;理解电路结构和功能对于电子设计自动化（EDA）至关重要。将电路作为And-Inverter图（AIG）进行建模有助于通过图神经网络（GNNs）实现高效的表示学习，而掩码建模方法已被证明在图表示学习中有效。&lt;h4&gt;目的&lt;/h4&gt;解决现有掩码建模范式破坏逻辑等价性和忽略抽象信息如电路功能的问题，并引入一种新的约束掩码建模方法，该方法能够从大语言模型获取电路的功能知识。&lt;h4&gt;方法&lt;/h4&gt;MGVGA结合了掩码门模型（MGM）和Verilog-AIG对齐（VGA）。MGM通过在隐空间而非原始电路中进行掩码来保持逻辑等价性，并随后重构这些被掩码的门的属性。而VGA则利用大语言模型理解Verilog代码功能的能力，执行原始电路中的掩码操作并在等效Verilog代码约束下重构被掩码的门。&lt;h4&gt;主要发现&lt;/h4&gt;MGVGA在各种逻辑综合任务上表现出优于现有最佳方法的性能。&lt;h4&gt;结论&lt;/h4&gt;通过将MGM和VGA结合使用，实现了更有效的电路表示学习，并证明了这种方法对EDA领域的影响。&lt;h4&gt;翻译&lt;/h4&gt;理解电路结构和功能对于电子设计自动化（EDA）至关重要。电路可以被表述为And-Inverter图（AIG），从而可以通过图神经网络（GNNs）实现高效的表示学习。掩码建模范式已被证明在图表示学习中有效，但是对原始电路进行掩码操作会破坏其逻辑等价性，这不适合用于电路表示学习。此外，现有的掩码建模方法往往优先考虑结构信息而牺牲了如电路功能的抽象信息。为了解决这些限制，我们引入了一种新的约束掩码建模范式MGVGA，它结合了掩码门模型（MGM）和Verilog-AIG对齐（VGA）。具体来说，MGM通过在隐空间中而不是原始电路里进行掩码操作来保持逻辑等价性，并随后重构被掩码的门属性。同时，大型语言模型已经展示了它们理解Verilog代码功能的良好能力。基于这种能力，VGA执行原始电路中的掩码操作，并根据等效Verilog代码约束条件重构掩码后的门，使得GNNs可以从大语言模型中学习到电路的功能。我们在各种逻辑综合任务上评估了MGVGA在EDA上的表现，并显示出其优于先前最先进的方法的性能优势。我们的代码可在https://github.com/wuhy68/MGVGA获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the structure and function of circuits is crucial forelectronic design automation (EDA). Circuits can be formulated as And-Invertergraphs (AIGs), enabling efficient implementation of representation learningthrough graph neural networks (GNNs). Masked modeling paradigms have beenproven effective in graph representation learning. However, maskingaugmentation to original circuits will destroy their logical equivalence, whichis unsuitable for circuit representation learning. Moreover, existing maskedmodeling paradigms often prioritize structural information at the expense ofabstract information such as circuit function. To address these limitations, weintroduce MGVGA, a novel constrained masked modeling paradigm incorporatingmasked gate modeling (MGM) and Verilog-AIG alignment (VGA). Specifically, MGMpreserves logical equivalence by masking gates in the latent space rather thanin the original circuits, subsequently reconstructing the attributes of thesemasked gates. Meanwhile, large language models (LLMs) have demonstrated anexcellent understanding of the Verilog code functionality. Building upon thiscapability, VGA performs masking operations on original circuits andreconstructs masked gates under the constraints of equivalent Verilog codes,enabling GNNs to learn circuit functions from LLMs. We evaluate MGVGA onvarious logic synthesis tasks for EDA and show the superior performance ofMGVGA compared to previous state-of-the-art methods. Our code is available athttps://github.com/wuhy68/MGVGA.</description>
      <author>example@mail.com (Haoyuan Wu, Haisheng Zheng, Yuan Pu, Bei Yu)</author>
      <guid isPermaLink="false">2502.12732v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>FedHC: A Hierarchical Clustered Federated Learning Framework for Satellite Networks</title>
      <link>http://arxiv.org/abs/2502.12783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种层级聚类联邦学习框架FedHC，旨在解决卫星网络中大数据处理的性能、能耗和时间效率问题。&lt;h4&gt;背景&lt;/h4&gt;随着数据驱动服务的增长，需要通过卫星网络处理的数据量显著增加。在分布式且资源受限的环境中，联邦学习非常适合于大型数据处理，但如何确保其收敛性的同时减少计算时间和能量消耗是挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架FedHC以优化卫星网络中的联邦学习过程，同时保持模型准确性。&lt;h4&gt;方法&lt;/h4&gt;采用卫星聚类参数服务器（PS）选择算法，在簇聚合阶段将附近卫星分为不同的簇，并指定每个簇的中心作为PS加速模型聚合。引入元学习驱动的卫星再聚类算法来增强对动态卫星集群变化的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与比较方法相比，FedHC框架可以显著减少处理时间（最多3倍）和能耗（最多2倍），同时保持模型准确性。&lt;h4&gt;结论&lt;/h4&gt;所提出的FedHC框架通过优化参数服务器的选择和增强对动态环境的适应性，在卫星网络中实现了更高效的联邦学习过程。&lt;h4&gt;翻译&lt;/h4&gt;随着数据驱动服务的增长，需要通过卫星网络处理的数据量显著增加。在分布式且资源受限的环境中，联邦学习非常适合于大型数据处理，但如何确保其收敛性的同时减少计算时间和能量消耗是挑战。为此，我们提出了一种层级聚类联邦学习框架FedHC。此框架使用了集群聚合阶段的卫星群集参数服务器（PS）选择算法，将附近的卫星分组为不同的簇，并指定一个簇中心作为PS来加速模型聚合。然后通过地面站选出几个能够通信的簇PS卫星以聚集全局参数，从而促进联邦学习过程。此外，还引入了一种基于元学习驱动的卫星再聚类算法，增强对动态卫星集群变化的适应性。在卫星网络实验平台上的大量试验表明，FedHC可以在保持模型准确性的前提下，与其它比较方法相比显著减少处理时间（最多3倍）和能耗（最多2倍）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the proliferation of data-driven services, the volume of data that needsto be processed by satellite networks has significantly increased. Federatedlearning (FL) is well-suited for big data processing in distributed,resource-constrained satellite environments. However, ensuring its convergenceperformance while minimizing processing time and energy consumption remains achallenge. To this end, we propose a hierarchical clustered federated learningframework, FedHC. This framework employs a satellite-clustered parameter server(PS) selection algorithm at the cluster aggregation stage, grouping nearbysatellites into distinct clusters and designating a cluster center as the PS toaccelerate model aggregation. Several communicable cluster PS satellites arethen selected through ground stations to aggregate global parameters,facilitating the FL process. Moreover, a meta-learning-driven satellitere-clustering algorithm is introduced to enhance adaptability to dynamicsatellite cluster changes. The extensive experiments on satellite networkstestbed demonstrate that FedHC can significantly reduce processing time (up to3x) and energy consumption (up to 2x) compared to other comparative methodswhile maintaining model accuracy.</description>
      <author>example@mail.com (Zhuocheng Liu, Zhishu Shen, Pan Zhou, Qiushi Zheng, Jiong Jin)</author>
      <guid isPermaLink="false">2502.12783v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Diverse Human Preference Learning through Principal Component Analysis</title>
      <link>http://arxiv.org/abs/2502.13131v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;理解人类偏好对于改进基础模型和构建个性化AI系统至关重要。&lt;h4&gt;背景&lt;/h4&gt;由于偏好的多样性和复杂性，传统奖励模型难以捕捉其全部范围。收集精细粒度的偏好数据虽然有助于改善这一状况，但成本高昂且难以扩展。&lt;h4&gt;目的&lt;/h4&gt;介绍Decomposed Reward Models (DRMs)——一种新颖的方法，能够从二元比较中提取多样的人类偏好，无需细粒度标注。&lt;h4&gt;方法&lt;/h4&gt;将人类偏好表示为向量，并使用主成分分析（PCA）进行分析。通过构建首选和拒绝响应之间嵌入差异的数据集，DRM识别出能捕获不同偏好方面的正交基向量。&lt;h4&gt;主要发现&lt;/h4&gt;分解后的奖励可以灵活组合以适应不同的用户需求，并且能够提取有意义的偏好维度（如有用性、安全性、幽默等），并适应新用户而无需额外训练。&lt;h4&gt;结论&lt;/h4&gt;DRM为个性化和可解释的LLM对齐提供了一个强大的框架，展示出其在理解和应用人类偏好的潜力。&lt;h4&gt;翻译&lt;/h4&gt;理解人类偏好对于改进基础模型和构建个性化的AI系统至关重要。由于偏好具有多样性和复杂性，传统奖励模型难以完全捕捉这些特点。收集精细粒度的偏好数据虽然有所帮助，但成本高且扩展困难。为此，本文提出了一种新方法——Decomposed Reward Models (DRMs)，能够从二元比较中提取多样的人类偏好而无需细粒度标注。通过将偏好表示为向量并使用PCA分析来识别捕捉不同偏好的正交基向量。研究结果显示该模型可以灵活组合奖励以适应用户需求，并能有效提取有意义的偏好维度如有用性、安全性及幽默等，还能够适应新用户而不需要额外训练，表明DRM框架在个性化和可解释性的LLM对齐中有强大的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding human preferences is crucial for improving foundation modelsand building personalized AI systems. However, preferences are inherentlydiverse and complex, making it difficult for traditional reward models tocapture their full range. While fine-grained preference data can help,collecting it is expensive and hard to scale. In this paper, we introduceDecomposed Reward Models (DRMs), a novel approach that extracts diverse humanpreferences from binary comparisons without requiring fine-grained annotations.Our key insight is to represent human preferences as vectors and analyze themusing Principal Component Analysis (PCA). By constructing a dataset ofembedding differences between preferred and rejected responses, DRMs identifyorthogonal basis vectors that capture distinct aspects of preference. Thesedecomposed rewards can be flexibly combined to align with different user needs,offering an interpretable and scalable alternative to traditional rewardmodels. We demonstrate that DRMs effectively extract meaningful preferencedimensions (e.g., helpfulness, safety, humor) and adapt to new users withoutadditional training. Our results highlight DRMs as a powerful framework forpersonalized and interpretable LLM alignment.</description>
      <author>example@mail.com (Feng Luo, Rui Yang, Hao Sun, Chunyuan Deng, Jiarui Yao, Jingyan Shen, Huan Zhang, Hanjie Chen)</author>
      <guid isPermaLink="false">2502.13131v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Detection and Geographic Localization of Natural Objects in the Wild: A Case Study on Palms</title>
      <link>http://arxiv.org/abs/2502.13023v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PRISM是一种用于在密集热带森林中检测和定位棕榈的灵活管道，基于大尺度正射影像图，该系统通过集成最先进的对象检测器以及零样本SAM进行分割，并优化地理映射。&lt;h4&gt;背景&lt;/h4&gt;棕榈是衡量热带雨林健康、生物多样性和人类影响的重要指标，对地方经济和全球森林产品供应链有重要支持作用。但是，在密集的自然森林中检测棕榈仍然受限于重叠树冠、不均匀阴影和异质景观。&lt;h4&gt;目的&lt;/h4&gt;开发一种用于在复杂环境中准确检测和定位棕榈的技术方案，并建立一个大规模的数据集用于该技术方案的训练与评估。&lt;h4&gt;方法&lt;/h4&gt;1. 建立了一个基于无人机收集的大规模正射影像数据集，包含来自21个生态多样性地区共8,830个边界框以及5,026个棕榈中心点。2. 评价了多个最先进的对象检测器，并将零样本SAM集成作为分割骨干网。3. 应用校准方法来对齐置信分数和IoU，同时探索显著性地图以提高特征解释性。&lt;h4&gt;主要发现&lt;/h4&gt;PRISM通过优化的管道可以更精确地在密集热带森林中定位棕榈，并且这种方法具有识别其他自然对象（如东部白松）的能力。此外，未来的工作将探索较低分辨率数据集（0.5到1米）上的迁移学习方法。&lt;h4&gt;结论&lt;/h4&gt;PRISM为解决密集森林中的复杂检测问题提供了一个有效的解决方案，不仅限于棕榈的检测，还可以应用于多种自然物体的识别。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Palms are ecologically and economically indicators of tropical forest health,biodiversity, and human impact that support local economies and global forestproduct supply chains. While palm detection in plantations is well-studied,efforts to map naturally occurring palms in dense forests remain limited byoverlapping crowns, uneven shading, and heterogeneous landscapes. We developPRISM (Processing, Inference, Segmentation, and Mapping), a flexible pipelinefor detecting and localizing palms in dense tropical forests using largeorthomosaic images. Orthomosaics are created from thousands of aerial imagesand spanning several to hundreds of gigabytes. Our contributions are threefold.First, we construct a large UAV-derived orthomosaic dataset collected across 21ecologically diverse sites in western Ecuador, annotated with 8,830 boundingboxes and 5,026 palm center points. Second, we evaluate multiplestate-of-the-art object detectors based on efficiency and performance,integrating zero-shot SAM 2 as the segmentation backbone, and refining theresults for precise geographic mapping. Third, we apply calibration methods toalign confidence scores with IoU and explore saliency maps for featureexplainability. Though optimized for palms, PRISM is adaptable for identifyingother natural objects, such as eastern white pines. Future work will exploretransfer learning for lower-resolution datasets (0.5 to 1m).</description>
      <author>example@mail.com (Kangning Cui, Rongkun Zhu, Manqi Wang, Wei Tang, Gregory D. Larsen, Victor P. Pauca, Sarra Alqahtani, Fan Yang, David Segurado, David Lutz, Jean-Michel Morel, Miles R. Silman)</author>
      <guid isPermaLink="false">2502.13023v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Power Grid Inspections with Machine Learning</title>
      <link>http://arxiv.org/abs/2502.13037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用3D计算机视觉技术来自动化电力网络检查的方法，通过处理TS40K数据集中的点云信息，提高了对关键电网组件如电线和塔的检测准确率。&lt;h4&gt;背景&lt;/h4&gt;随着全球能源需求的增长，确保电力网的安全性和可靠性变得至关重要。传统的手动观察或直升机巡查方法资源消耗大且不具备扩展性。&lt;h4&gt;目的&lt;/h4&gt;探索使用3D计算机视觉技术来自动化电力网络检查的方法，提高电网维护工作的效率，并实现主动风险管理策略。&lt;h4&gt;方法&lt;/h4&gt;利用TS40K数据集进行研究，该数据集是一个高密度、标注完整的3D LiDAR点云集合。通过集中于3D语义分割，解决了类别不平衡和噪声数据的问题。&lt;h4&gt;主要发现&lt;/h4&gt;基准测试结果表明性能有了显著的提高，使用基于转换器的模型检测电线时交并比（IoU）得分达到了95.53%。&lt;h4&gt;结论&lt;/h4&gt;研究展示了将机器学习集成到电网维护工作流程中的巨大潜力，提高了效率，并支持了主动的风险管理策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety and reliability of power grids is critical as globalenergy demands continue to rise. Traditional inspection methods, such as manualobservations or helicopter surveys, are resource-intensive and lackscalability. This paper explores the use of 3D computer vision to automatepower grid inspections, utilizing the TS40K dataset -- a high-density,annotated collection of 3D LiDAR point clouds. By concentrating on 3D semanticsegmentation, our approach addresses challenges like class imbalance and noisydata to enhance the detection of critical grid components such as power linesand towers. The benchmark results indicate significant performanceimprovements, with IoU scores reaching 95.53% for the detection of power linesusing transformer-based models. Our findings illustrate the potential forintegrating ML into grid maintenance workflows, increasing efficiency andenabling proactive risk management strategies.</description>
      <author>example@mail.com (Diogo Lavado, Ricardo Santos, Andre Coelho, Joao Santos, Alessandra Micheletti, Claudia Soares)</author>
      <guid isPermaLink="false">2502.13037v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>NTP-INT: Network Traffic Prediction-Driven In-band Network Telemetry for High-load Switches</title>
      <link>http://arxiv.org/abs/2502.12834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;入带网络遥测（INT）在网络管理中至关重要，因为它提供了实时可见性。然而，由于网络设备和服务的迅速增加，在动态网络环境中进行有针对性地访问详细网络信息已成为必要。本文提出了一种智能网络遥测系统NTP-INT，用于获取高负载交换机上的更细化的网络信息。具体而言，NTP-INT由三个模块组成：网络流量预测模块、网络修剪模块和探针路径规划模块。首先，网络流量预测模块采用多时间图神经网络（MTGNN）来预测未来的网络流量并识别出高负载交换机。然后，我们设计了一种网络修剪算法以生成一个覆盖所有高负载交换机的子网，从而降低探针路径规划的复杂度。最后，探针路径规划模块使用基于注意力机制的深度强化学习（DEL）模型在网络切片中规划有效的探针路径。实验结果表明，NTP-INT可以在减少控制开销50%的同时获取更精确的高负载交换机网络信息。&lt;h4&gt;背景&lt;/h4&gt;随着网络设备和服务的增长，需要在动态环境中访问详细的实时网络信息&lt;h4&gt;目的&lt;/h4&gt;提出一种智能网络遥测系统NTP-INT以获取高负载交换机上的详细和精确的信息并减少控制开销&lt;h4&gt;方法&lt;/h4&gt;{'模块组成': ['网络流量预测模块', '网络修剪模块', '探针路径规划模块'], '网络流量预测模块': '采用多时间图神经网络（MTGNN）进行未来的网络流量预测，并识别高负载交换机', '网络修剪算法': '设计用于生成一个覆盖所有高负载交换机的子网，以简化探针路径规划过程', '探针路径规划模块': '使用基于注意力机制的深度强化学习模型在网络切片中规划有效的探针路径'}&lt;h4&gt;主要发现&lt;/h4&gt;NTP-INT可以获取高负载交换机上的更精确网络信息，并将控制开销减少50%&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-band network telemetry (INT) is essential to network management due to itsreal-time visibility. However, because of the rapid increase in network devicesand services, it has become crucial to have targeted access to detailed networkinformation in a dynamic network environment. This paper proposes anintelligent network telemetry system called NTP-INT to obtain more fine-grainednetwork information on high-load switches. Specifically, NTP-INT consists ofthree modules: network traffic prediction module, network pruning module, andprobe path planning module. Firstly, the network traffic prediction moduleadopts a Multi-Temporal Graph Neural Network (MTGNN) to predict future networktraffic and identify high-load switches. Then, we design the network pruningalgorithm to generate a subnetwork covering all high-load switches to reducethe complexity of probe path planning. Finally, the probe path planning moduleuses an attention-mechanism-based deep reinforcement learning (DEL) model toplan efficient probe paths in the network slice. The experimental resultsdemonstrate that NTP-INT can acquire more precise network information onhigh-load switches while decreasing the control overhead by 50\%.</description>
      <author>example@mail.com (Penghui Zhang, Hua Zhang, Yuqi Dai, Cheng Zeng, Jingyu Wang, Jianxin Liao)</author>
      <guid isPermaLink="false">2502.12834v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>CAST: Component-Aligned 3D Scene Reconstruction from an RGB Image</title>
      <link>http://arxiv.org/abs/2502.12894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://sites.google.com/view/cast4&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CAST是一种从单张RGB图像中重建高质量3D场景的新方法，解决了现有方法在特定领域限制和低质量物体生成上的问题。&lt;h4&gt;背景&lt;/h4&gt;从单张RGB图像恢复高保真度的3D场景是计算机图形学中的一个挑战性任务。当前的方法往往受限于特定领域的局限性和低质量的对象生成。&lt;h4&gt;目的&lt;/h4&gt;提出CAST，以解决现有方法在重建高质量3D场景时遇到的问题，并提供一种更有效的解决方案。&lt;h4&gt;方法&lt;/h4&gt;{'步骤一': '提取输入图像中的对象级2D分割和相对深度信息', '步骤二': '使用基于GPT的模型分析物体间的空间关系', '步骤三': '利用一个感知遮挡的大规模3D生成模型独立生成每个物体的完整几何形状，通过MAE和点云条件来缓解遮挡和部分对象信息的影响', '步骤四': '计算必要的转换以将生成的网格精确放置并整合到场景的点云中', '步骤五': '利用一个基于物理感知的修正步骤来优化对象姿态，并确保它们在空间上的一致性和连贯性'}&lt;h4&gt;主要发现&lt;/h4&gt;通过使用符号距离场(SDF)，该模型有效解决了遮挡、物体穿透和漂浮物等问题，使生成的场景能够准确地反映现实世界中的物理相互作用。&lt;h4&gt;结论&lt;/h4&gt;CAST可以在机器人技术领域中得到应用，用于高效的从真实到模拟的工作流程，并提供给机器人系统一个现实且可扩展的仿真环境。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的内容已经用中文进行了总结。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recovering high-quality 3D scenes from a single RGB image is a challengingtask in computer graphics. Current methods often struggle with domain-specificlimitations or low-quality object generation. To address these, we propose CAST(Component-Aligned 3D Scene Reconstruction from a Single RGB Image), a novelmethod for 3D scene reconstruction and recovery. CAST starts by extractingobject-level 2D segmentation and relative depth information from the inputimage, followed by using a GPT-based model to analyze inter-object spatialrelationships. This enables the understanding of how objects relate to eachother within the scene, ensuring more coherent reconstruction. CAST thenemploys an occlusion-aware large-scale 3D generation model to independentlygenerate each object's full geometry, using MAE and point cloud conditioning tomitigate the effects of occlusions and partial object information, ensuringaccurate alignment with the source image's geometry and texture. To align eachobject with the scene, the alignment generation model computes the necessarytransformations, allowing the generated meshes to be accurately placed andintegrated into the scene's point cloud. Finally, CAST incorporates aphysics-aware correction step that leverages a fine-grained relation graph togenerate a constraint graph. This graph guides the optimization of objectposes, ensuring physical consistency and spatial coherence. By utilizing SignedDistance Fields (SDF), the model effectively addresses issues such asocclusions, object penetration, and floating objects, ensuring that thegenerated scene accurately reflects real-world physical interactions. CAST canbe leveraged in robotics, enabling efficient real-to-simulation workflows andproviding realistic, scalable simulation environments for robotic systems.</description>
      <author>example@mail.com (Kaixin Yao, Longwen Zhang, Xinhao Yan, Yan Zeng, Qixuan Zhang, Lan Xu, Wei Yang, Jiayuan Gu, Jingyi Yu)</author>
      <guid isPermaLink="false">2502.12894v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Task-Oriented Semantic Communication for Stereo-Vision 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.12735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于光学流的语义通信框架，旨在减少立体视觉3D物体检测任务中的数据传输开销。&lt;h4&gt;背景&lt;/h4&gt;随着计算机视觉的发展，3D物体检测在许多实际应用中变得越来越重要。然而，受限于传感器硬件的计算能力，复杂的算法需要部署到远程设备或云端执行，这带来了大量的数据传输负担。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架来减少立体视觉3D对象检测中的数据传输量，并确保检测精度。&lt;h4&gt;方法&lt;/h4&gt;提出了一个光学流驱动模块联合提取和恢复左右图像中的语义信息以减少左-右光度对齐的语义信息损失，设计了一个2D语义提取模块识别并提取物体周围的语义意义，最后使用融合网络将恢复的语义进行融合，并重构立体视觉图像。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在检测精度上比传统方法提高了近70%，特别是在低信噪比的情况下表现更佳。&lt;h4&gt;结论&lt;/h4&gt;所提出的光学流驱动的语义通信框架能够有效减少数据传输量，同时保持或提高3D物体检测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;随着计算机视觉的发展，三维（3D）对象检测在许多现实世界应用中变得越来越重要。由于传感器侧硬件计算能力的限制，复杂的算法有时需要部署到远程设备或云上执行，这带来了大量的数据传输开销。为了应对这一问题，本文提出了一种基于光学流的语义通信框架来解决立体视觉3D对象检测任务中的挑战。该框架充分地利用了立体视觉3D检测对图像中语义信息的依赖，并优先传输这些语义信息以减少总的数据传输量同时确保检测准确性。特别地，我们开发了一个光学流驱动模块来联合提取和恢复左右图像中的语义信息，减少了左-右光度对齐的语义信息损失并改善了深度推断精度。然后设计了一种2D语义提取模块来识别并提取物体周围区域的语义意义，增强关键区域中语义信息的传输。最后使用融合网络将恢复的语义进行融合，并重构立体视觉图像以供3D检测。仿真结果表明该方法在检测准确性上提高了近70%，并且优于传统方法，尤其是在低信噪比的情况下表现更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the development of computer vision, 3D object detection has becomeincreasingly important in many real-world applications. Limited by thecomputing power of sensor-side hardware, the detection task is sometimesdeployed on remote computing devices or the cloud to execute complexalgorithms, which brings massive data transmission overhead. In response, thispaper proposes an optical flow-driven semantic communication framework for thestereo-vision 3D object detection task. The proposed framework fully exploitsthe dependence of stereo-vision 3D detection on semantic information in imagesand prioritizes the transmission of this semantic information to reduce totaltransmission data sizes while ensuring the detection accuracy. Specifically, wedevelop an optical flow-driven module to jointly extract and recover semanticsfrom the left and right images to reduce the loss of the left-right photometricalignment semantic information and improve the accuracy of depth inference.Then, we design a 2D semantic extraction module to identify and extractsemantic meaning around the objects to enhance the transmission of semanticinformation in the key areas. Finally, a fusion network is used to fuse therecovered semantics, and reconstruct the stereo-vision images for 3D detection.Simulation results show that the proposed method improves the detectionaccuracy by nearly 70% and outperforms the traditional method, especially forthe low signal-to-noise ratio regime.</description>
      <author>example@mail.com (Zijian Cao, Hua Zhang, Le Liang, Haotian Wang, Shi Jin, Geoffrey Ye Li)</author>
      <guid isPermaLink="false">2502.12735v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Semi-supervised Learning with Noisy Zero-shot Pseudolabels</title>
      <link>http://arxiv.org/abs/2502.12584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review for ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为ZMT的框架，该框架旨在通过结合零样本学习和无监督表示学习来改进半监督学习方法。&lt;h4&gt;背景&lt;/h4&gt;现有的半监督学习（SSL）方法依赖于有限标记数据和大量未标记数据。虽然基础模型可以通过零样本推断提供帮助，但尝试通过伪标签将其整合到SSL中的效果不稳定。&lt;h4&gt;目的&lt;/h4&gt;开发一种机制，该机制可以有效地利用零样本预测并结合当代SSL的无监督表示学习目标，以提高半监督学习的有效性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;ZMT框架采用多任务学习的方法，在生成伪标签的同时优化其质量，并确保对不同伪标签可靠性的适应能力。&lt;h4&gt;主要发现&lt;/h4&gt;在视觉、语言和音频领域的8个数据集上的实验结果表明，与传统的SSL方法相比，ZMT可以将错误率最多降低56%，特别是在伪标签不可靠的情况下表现尤为突出。&lt;h4&gt;结论&lt;/h4&gt;ZMT代表了半监督学习在资源受限环境中更有效和可访问性的重大进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semi-supervised learning (SSL) leverages limited labeled data alongsideabundant unlabeled data to address labeling costs in machine learning. Whilerecent foundation models enable zero-shot inference, attempts to integratethese capabilities into SSL through pseudo-labeling have shown mixed resultsdue to unreliable zero-shot predictions. We present ZMT (Zero-Shot Multi-TaskLearning), a framework that jointly optimizes zero-shot pseudo-labels andunsupervised representation learning objectives from contemporary SSLapproaches. Our method introduces a multi-task learning-based mechanism thatincorporates pseudo-labels while ensuring robustness to varying pseudo-labelquality. Experiments across 8 datasets in vision, language, and audio domainsdemonstrate that ZMT reduces error by up to 56% compared to traditional SSLmethods, with particularly compelling results when pseudo-labels are noisy andunreliable. ZMT represents a significant step toward making semi-supervisedlearning more effective and accessible in resource-constrained environments.</description>
      <author>example@mail.com (Jichan Chung, Irene Y. Chen)</author>
      <guid isPermaLink="false">2502.12584v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Improved Fine-Tuning of Large Multimodal Models for Hateful Meme Detection</title>
      <link>http://arxiv.org/abs/2502.13061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于检测仇恨表情包的新型两阶段微调框架LMM-RGCL，该框架在多个数据集上取得了最先进的性能，并展示了跨领域泛化的优越性。&lt;h4&gt;背景&lt;/h4&gt;互联网上的仇恨表情包成为了一个重要的问题，大模态模型虽然在多种任务中表现出色，但在检测仇恨表情包时表现不佳，因为表情包与新兴的社会趋势和突发事件紧密相关。传统的监督微调方法在这种情况下也显示出局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架来提高大型多模态模型对仇恨表情包检测的准确性，并增强其跨领域泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了Large Multimodal Model Retrieval-Guided Contrastive Learning (LMM-RGCL)，这是一种两阶段微调框架，旨在通过对比学习和基于检索的方法改进大模型在该任务上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，LMM-RGCL不仅在六个广泛使用的表情包分类数据集上实现了最先进的性能，而且在资源有限的情况下能够有效地泛化到未见过的表情包。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法超越了现有的代理系统和其他模型，并为仇恨表情包检测提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;网络上的仇恨表情包已经成为一个重要问题。虽然大型多模态模型在很多任务中表现出色，但由于表情包和新兴的社会趋势及突发事件的联系密切，这些模型在仇恨表情包检测方面表现不佳。最近的研究进一步指出，在这种情况下常规监督微调方法的局限性。为了应对这一挑战，我们提出了一种名为Large Multimodal Model Retrieval-Guided Contrastive Learning (LMM-RGCL)的新框架，旨在提高大模态模型在该任务中的准确性及跨领域泛化能力。实验结果表明，在六个常用的表情包分类数据集上，LMM-RGCL达到了最先进的性能，并且在低资源条件下能够有效地泛化到未见过的表情包，超过了包括VPD-PALI-X-55B和GPT-4o在内的其他模型的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hateful memes have become a significant concern on the Internet,necessitating robust automated detection systems. While large multimodal modelshave shown strong generalization across various tasks, they exhibit poorgeneralization to hateful meme detection due to the dynamic nature of memestied to emerging social trends and breaking news. Recent work furtherhighlights the limitations of conventional supervised fine-tuning for largemultimodal models in this context. To address these challenges, we proposeLarge Multimodal Model Retrieval-Guided Contrastive Learning (LMM-RGCL), anovel two-stage fine-tuning framework designed to improve both in-domainaccuracy and cross-domain generalization. Experimental results on six widelyused meme classification datasets demonstrate that LMM-RGCL achievesstate-of-the-art performance, outperforming agent-based systems such asVPD-PALI-X-55B. Furthermore, our method effectively generalizes toout-of-domain memes under low-resource settings, surpassing models like GPT-4o.</description>
      <author>example@mail.com (Jingbiao Mei, Jinghong Chen, Guangyu Yang, Weizhe Lin, Bill Byrne)</author>
      <guid isPermaLink="false">2502.13061v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>UniMatch: Universal Matching from Atom to Task for Few-Shot Drug Discovery</title>
      <link>http://arxiv.org/abs/2502.12453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted as ICLR 2025 Spotlight&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了Universal Matching Networks (UniMatch)模型，旨在解决药物发现过程中由于低成功率导致的数据稀缺问题。&lt;h4&gt;背景&lt;/h4&gt;药物研发在寻找治疗各种疾病的候选药物中至关重要。然而，其低成功率往往会导致数据标注不足，形成少样本学习的问题。现有方法主要关注单一尺度的特征提取，忽略了决定分子不同性质的多层次分子结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理多层次分子表示和任务级泛化的统一匹配框架UniMatch，以提高药物发现的成功率。&lt;h4&gt;方法&lt;/h4&gt;采用双层次匹配框架：显式的分层池化和匹配机制用于捕捉多尺度的结构性特征；隐式的元学习策略进行跨任务级别的匹配，帮助模型快速适应新任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，UniMatch在MoleculeNet和FS-Mol基准测试中优于现有最佳方法，AUROC提升了2.87%，delta AUPRC提高了6.52%。同时，在Meta-MolNet基准上展现了优秀的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;提出的方法通过结合显式的多层次分子匹配与隐式的任务级匹配，有效解决了药物发现中的少样本学习问题，并展示了优于现有方法的性能和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;药物发现对于识别治疗各种疾病的候选药物至关重要。然而，其低成功率往往导致数据标注不足，形成少样本学习的问题。现有的方法主要集中在单一尺度特征上，忽略了决定不同分子性质的多层次分子结构。为解决这些问题，我们引入了Universal Matching Networks (UniMatch)，这是一种双匹配框架，通过元学习将显式的层次化分子匹配与隐式的任务级匹配相结合，连接多层次分子表示和任务级别泛化。具体来说，我们的方法利用分层池化和匹配技术跨多个尺度（如原子、子结构和完整分子）捕捉结构性特征，促进精确的分子表达式和比较。此外，我们采用元学习策略进行隐式的任务级匹配，使模型能够捕获任务间的共享模式并快速适应新任务。这种统一的匹配框架确保了有效的分子对齐，并利用共享元知识实现快速适应。实验结果表明，在MoleculeNet和FS-Mol基准测试中，UniMatch优于现有最佳方法，分别在AUROC和delta AUPRC方面提高了2.87%和6.52%。此外，UniMatch在Meta-MolNet基准上的泛化能力也表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug discovery is crucial for identifying candidate drugs for variousdiseases.However, its low success rate often results in a scarcity ofannotations, posing a few-shot learning problem. Existing methods primarilyfocus on single-scale features, overlooking the hierarchical molecularstructures that determine different molecular properties. To address theseissues, we introduce Universal Matching Networks (UniMatch), a dual matchingframework that integrates explicit hierarchical molecular matching withimplicit task-level matching via meta-learning, bridging multi-level molecularrepresentations and task-level generalization. Specifically, our approachexplicitly captures structural features across multiple levels, such as atoms,substructures, and molecules, via hierarchical pooling and matching,facilitating precise molecular representation and comparison. Additionally, weemploy a meta-learning strategy for implicit task-level matching, allowing themodel to capture shared patterns across tasks and quickly adapt to new ones.This unified matching framework ensures effective molecular alignment whileleveraging shared meta-knowledge for fast adaptation. Our experimental resultsdemonstrate that UniMatch outperforms state-of-the-art methods on theMoleculeNet and FS-Mol benchmarks, achieving improvements of 2.87% in AUROC and6.52% in delta AUPRC. UniMatch also shows excellent generalization ability onthe Meta-MolNet benchmark.</description>
      <author>example@mail.com (Ruifeng Li, Mingqian Li, Wei Liu, Yuhua Zhou, Xiangxin Zhou, Yuan Yao, Qiang Zhang, Hongyang Chen)</author>
      <guid isPermaLink="false">2502.12453v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Universal Embedding Function for Traffic Classification via QUIC Domain Recognition Pretraining: A Transfer Learning Success</title>
      <link>http://arxiv.org/abs/2502.12930v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于迁移学习的加密流量分类方法，通过预训练模型来适应不断变化的网络协议和机器学习领域的发展。&lt;h4&gt;背景&lt;/h4&gt;随着TLS加密客户端Hello的广泛使用，QUIC流量中的SNI域名识别变得越来越困难。传统的加密流量分类技术难以应对新出现的网络协议及其扩展。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于迁移学习的方法来改进加密流量分类的性能。&lt;h4&gt;方法&lt;/h4&gt;首先在一个复杂的任务上训练一个嵌入模型（识别QUIC流量中的SNI域名），然后将这个预训练模型转移到五个已知的TC数据集上。使用了独立类设置、ArcFace损失函数以及现代深度学习架构，旨在生成适用于各种任务的通用嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;基于最近邻搜索方法在四个数据集中超过了现有最优性能，并且与利用原始报文序列的基线方法相比有意外的发现，这可能对整个加密流量分类领域产生影响。&lt;h4&gt;结论&lt;/h4&gt;论文提出了一个有效的迁移学习方案来提升加密流量分类的效果，同时发布了模型架构、训练权重和实验结果以供进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的方法利用预训练的嵌入模型，通过处理复杂任务（如识别QUIC中的SNI域名），然后将其应用到其他五个已知的数据集上。该方法在四个数据集中表现出超越现有最佳性能的结果，并且与基线方法相比有一些意外发现，可能会影响整个加密流量分类领域的发展方向和研究趋势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Encrypted traffic classification (TC) methods must adapt to new protocols andextensions as well as to advancements in other machine learning fields. In thispaper, we follow a transfer learning setup best known from computer vision. Wefirst pretrain an embedding model on a complex task with a large number ofclasses and then transfer it to five well-known TC datasets. The pretrainingtask is recognition of SNI domains in encrypted QUIC traffic, which in itselfis a problem for network monitoring due to the growing adoption of TLSEncrypted Client Hello. Our training pipeline -- featuring a disjoint classsetup, ArcFace loss function, and a modern deep learning architecture -- aimsto produce universal embeddings applicable across tasks. The proposed solution,based on nearest neighbors search in the embedding space, surpasses SOTAperformance on four of the five TC datasets. A comparison with a baselinemethod utilizing raw packet sequences revealed unexpected findings withpotential implications for the broader TC field. We published the modelarchitecture, trained weights, and transfer learning experiments.</description>
      <author>example@mail.com (Jan Luxemburk, Karel Hynek, Richard Plný, Tomáš Čejka)</author>
      <guid isPermaLink="false">2502.12930v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Magma: A Foundation Model for Multimodal AI Agents</title>
      <link>http://arxiv.org/abs/2502.13130v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 16 figures, technical report from MSR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为Magma的模型，该模型旨在支持多模态AI代理任务，不仅涵盖了视觉-语言的理解能力，还具备规划和执行实际世界中行动的能力。&lt;h4&gt;背景&lt;/h4&gt;现有的视觉-语言(VL)模型主要用于理解静态图像中的语义信息，而缺乏在动态环境中进行动作规划和执行的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够同时处理数字和物理世界的多模态AI代理任务的新模型Magma。&lt;h4&gt;方法&lt;/h4&gt;通过使用大量异构数据集（包括图片、视频到机器人数据）对Magma进行预训练，其中的可操作视觉对象在图像中标记为Set-of-Mark (SoM)，以实现动作定位；而在视频中，则使用Trace-of-Mark (ToM)标记物体运动轨迹来辅助行动规划。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SoM和ToM技术结合效果显著，并能够帮助Magma模型获取空间-时间智能，在UI导航和机器人操作等任务上达到了新的最佳性能。同时，它在图像和视频相关的多模态任务中也表现优越。&lt;h4&gt;结论&lt;/h4&gt;Magma展示出强大的跨领域适应性和高性能，特别是在UI导航和机器人操作方面超越了专为此类任务设计的其他模型，并且公开源代码以供重复研究。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了Magma，这是一种基础模型，能够服务于数字世界和物理世界的多模态AI代理任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Magma, a foundation model that serves multimodal AI agentic tasksin both the digital and physical worlds. Magma is a significant extension ofvision-language (VL) models in that it not only retains the VL understandingability (verbal intelligence) of the latter, but is also equipped with theability to plan and act in the visual-spatial world (spatial-temporalintelligence) and complete agentic tasks ranging from UI navigation to robotmanipulation. To endow the agentic capabilities, Magma is pretrained on largeamounts of heterogeneous datasets spanning from images, videos to roboticsdata, where the actionable visual objects (e.g., clickable buttons in GUI) inimages are labeled by Set-of-Mark (SoM) for action grounding, and the objectmovements (e.g., the trace of human hands or robotic arms) in videos arelabeled by Trace-of-Mark (ToM) for action planning. Extensive experiments showthat SoM and ToM reach great synergy and facilitate the acquisition ofspatial-temporal intelligence for our Magma model, which is fundamental to awide range of tasks as shown in Fig.1. In particular, Magma creates newstate-of-the-art results on UI navigation and robotic manipulation tasks,outperforming previous models that are specifically tailored to these tasks. Onimage and video-related multimodal tasks, Magma also compares favorably topopular large multimodal models that are trained on much larger datasets. Wemake our model and code public for reproducibility athttps://microsoft.github.io/Magma.</description>
      <author>example@mail.com (Jianwei Yang, Reuben Tan, Qianhui Wu, Ruijie Zheng, Baolin Peng, Yongyuan Liang, Yu Gu, Mu Cai, Seonghyeon Ye, Joel Jang, Yuquan Deng, Lars Liden, Jianfeng Gao)</author>
      <guid isPermaLink="false">2502.13130v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning Transformation-Isomorphic Latent Space for Accurate Hand Pose Estimation</title>
      <link>http://arxiv.org/abs/2502.12535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种名为TI-Net的视觉网络骨干，用于构建等变变换隐式空间，旨在解决现有表征学习方法在处理低层次信息和去除任务无关信息方面的不足。&lt;h4&gt;背景介绍&lt;/h4&gt;基于视觉的回归任务（如手部姿态估计）通过表示学习已经取得了更高的精度和更快的收敛速度。然而，现有的表示学习方法仍然面临特征提取问题：提取的高级语义特征不足以进行低级信息回归，并且包含的任务不相关信息会干扰回归任务。&lt;h4&gt;研究目的&lt;/h4&gt;提出一种新的网络架构（TI-Net），解决当前表征学习中存在的问题，以提高手部姿态估计等回归任务的表现。&lt;h4&gt;创新方法&lt;/h4&gt;采用线性变换在隐式空间中建模几何变换，并确保这些变换与图像空间中的对应变换对齐。这种方法保证了提取的特征紧凑且有利于低层次信息（如姿态）的回归。&lt;h4&gt;实验验证&lt;/h4&gt;通过手部姿态估计任务评估TI-Net，在DexYCB数据集上，相比最先进的专门用于手部姿态估计的方法在PA-MPJPE指标上取得了10%的改进。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新颖且通用的视觉网络架构，能够有效地解决现有表示学习方法中存在的问题，并展示了其在特定任务上的优越性能。未来将开源代码以供研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;Vision-based regression tasks, such as hand pose estimation, have achieved higher accuracy and faster convergence through representation learning. However, existing representation learning methods often encounter issues: the high semantic level of features extracted from images is inadequate for regressing low-level information, and the extracted features include task-irrelevant information, reducing their compactness and interfering with regression tasks. To address these challenges, we propose TI-Net, a highly versatile visual Network backbone designed to construct a Transformation Isomorphic latent space. Specifically, we employ linear transformations to model geometric transformations in the latent space and ensure that TI-Net aligns them with those in the image space. This ensures that the latent features capture compact, low-level information beneficial for pose estimation tasks. We evaluated TI-Net on the hand pose estimation task to demonstrate the network's superiority. On the DexYCB dataset, TI-Net achieved a 10% improvement in the PA-MPJPE metric compared to specialized state-of-the-art (SOTA) hand pose estimation methods. Our code will be released in the future.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-based regression tasks, such as hand pose estimation, have achievedhigher accuracy and faster convergence through representation learning.However, existing representation learning methods often encounter the followingissues: the high semantic level of features extracted from images is inadequatefor regressing low-level information, and the extracted features includetask-irrelevant information, reducing their compactness and interfering withregression tasks. To address these challenges, we propose TI-Net, a highlyversatile visual Network backbone designed to construct a TransformationIsomorphic latent space. Specifically, we employ linear transformations tomodel geometric transformations in the latent space and ensure that {\rmTI-Net} aligns them with those in the image space. This ensures that the latentfeatures capture compact, low-level information beneficial for pose estimationtasks. We evaluated TI-Net on the hand pose estimation task to demonstrate thenetwork's superiority. On the DexYCB dataset, TI-Net achieved a 10% improvementin the PA-MPJPE metric compared to specialized state-of-the-art (SOTA) handpose estimation methods. Our code will be released in the future.</description>
      <author>example@mail.com (Kaiwen Ren, Lei Hu, Zhiheng Zhang, Yongjing Ye, Shihong Xia)</author>
      <guid isPermaLink="false">2502.12535v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>An Experimental Study of SOTA LiDAR Segmentation Models</title>
      <link>http://arxiv.org/abs/2502.12860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  No comments&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;点云分割（PCS）是将每个点分类的任务，它使机器人能够解析其三维环境并自主运行。&lt;h4&gt;背景&lt;/h4&gt;现有PCP模型根据不同的点云表示方式大致可分为基于点、体素和范围图像的模型。然而，尚未有研究从应用角度对这些先进的点基、体素基和范围图像基模型进行全面比较。&lt;h4&gt;目的&lt;/h4&gt;提供关于不同模型在考虑LiDAR数据运动补偿以及模型参数、测试期间分配的最大GPU内存、推理延迟、每秒帧数、交并比（IoU）和平均交并比（mIoU）得分等方面的详尽对比。&lt;h4&gt;方法&lt;/h4&gt;实验结果有助于工程师根据应用场景选择合适的PCS模型，同时也启发了研究者在PCS领域设计更适合实际场景的模型。&lt;h4&gt;主要发现&lt;/h4&gt;提供了一套详细的数据，帮助工程师了解不同点云分割模型的优劣。&lt;h4&gt;结论&lt;/h4&gt;通过全面比较现有的点、体素和范围图像基模型，有助于提高机器人自主解析三维环境的能力，并促进更实用的PCS模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud segmentation (PCS) is to classify each point in point clouds. Thetask enables robots to parse their 3D surroundings and run autonomously.According to different point cloud representations, existing PCS models can beroughly divided into point-, voxel-, and range image-based models. However, nowork has been found to report comprehensive comparisons among thestate-of-the-art point-, voxel-, and range image-based models from anapplication perspective, bringing difficulty in utilizing these models forreal-world scenarios. In this paper, we provide thorough comparisons among themodels by considering the LiDAR data motion compensation and the metrics ofmodel parameters, max GPU memory allocated during testing, inference latency,frames per second, intersection-over-union (IoU) and mean IoU (mIoU) scores.The experimental results benefit engineers when choosing a reasonable PCS modelfor an application and inspire researchers in the PCS field to design morepractical models for a real-world scenario.</description>
      <author>example@mail.com (Bike Chen, Antti Tikanmäki, Juha Röning)</author>
      <guid isPermaLink="false">2502.12860v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Contrast-Unity for Partially-Supervised Temporal Sentence Grounding</title>
      <link>http://arxiv.org/abs/2502.12917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICASSP 2025.The first two authors share the same  contribution. arXiv admin note: text overlap with arXiv:2302.09850&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个中间的半监督设置，旨在通过只在训练期间提供短片段视频来降低标注成本，并同时保持高性能。为此设计了一种对比统一框架，采用隐式-显式的渐进式定位方法。&lt;h4&gt;背景&lt;/h4&gt;时间句子对齐的目标是从给定的未经修剪的视频中检测由自然语言查询描述的事件的时间戳。完全监督的方法虽然效果好但需要昂贵的标注成本；而弱监督的方法使用廉价标签但性能较差。&lt;h4&gt;目的&lt;/h4&gt;为了追求在减少标注成本的同时保持高性能，论文引入了一种中间部分监督设置，并设计了对比-统一框架来充分利用有限的标注信息。&lt;h4&gt;方法&lt;/h4&gt;提出了一种隐式阶段和显式阶段两阶段目标：在隐式阶段使用综合四元组对比学习对事件查询表示进行细粒度对齐；在显式阶段，利用获得的伪标签训练完全监督模型以实现定位细化和去噪。&lt;h4&gt;主要发现&lt;/h4&gt;部分监督的重要性及其框架的有效性得到了充分验证，在Charades-STA和ActivityNet Captions数据集上的大量实验也表明了这一点。&lt;h4&gt;结论&lt;/h4&gt;论文提出的半监督设置结合对比统一框架，为时间句子对齐问题提供了一种新的解决方案，实现了高精度定位的同时减少了标注成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal sentence grounding aims to detect event timestamps described by thenatural language query from given untrimmed videos. The existingfully-supervised setting achieves great results but requires expensiveannotation costs; while the weakly-supervised setting adopts cheap labels butperforms poorly. To pursue high performance with less annotation costs, thispaper introduces an intermediate partially-supervised setting, i.e., onlyshort-clip is available during training. To make full use of partial labels, wespecially design one contrast-unity framework, with the two-stage goal ofimplicit-explicit progressive grounding. In the implicit stage, we alignevent-query representations at fine granularity using comprehensive quadruplecontrastive learning: event-query gather, event-background separation,intra-cluster compactness and inter-cluster separability. Then, high-qualityrepresentations bring acceptable grounding pseudo-labels. In the explicitstage, to explicitly optimize grounding objectives, we train onefully-supervised model using obtained pseudo-labels for grounding refinementand denoising. Extensive experiments and thoroughly ablations on Charades-STAand ActivityNet Captions demonstrate the significance of partial supervision,as well as our superior performance.</description>
      <author>example@mail.com (Haicheng Wang, Chen Ju, Weixiong Lin, Chaofan Ma, Shuai Xiao, Ya Zhang, Yanfeng Wang)</author>
      <guid isPermaLink="false">2502.12917v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>tn4ml: Tensor Network Training and Customization for Machine Learning</title>
      <link>http://arxiv.org/abs/2502.13090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一个新的名为tn4ml的库，旨在将张量网络集成到机器学习优化流程中。&lt;h4&gt;背景&lt;/h4&gt;张量网络作为一种新兴的技术在基础科学领域内的机器学习挑战中展现了其潜力，并开始应用于现实世界的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一个易于使用的库（tn4ml），以支持基于张量网络的机器学习任务，并展示它的灵活性和应用范围。&lt;h4&gt;方法&lt;/h4&gt;该库提供了数据嵌入、目标函数定义以及使用多种优化策略进行模型训练的功能模块，演示了其在监督学习和无监督学习中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;通过两个实例展示了tn4ml库的灵活性：一个是表格数据上的有监督学习，另一个是图像数据集上的无监督学习。此外还分析了为张量网络定制机器学习管道的部分如何影响性能指标。&lt;h4&gt;结论&lt;/h4&gt;这个新的库能够促进张量网络在处理现实世界问题中的应用，并展示了其作为传统神经网络替代品的潜力。&lt;h4&gt;翻译&lt;/h4&gt;张量网络作为一种新兴的技术，已经成为解决基础科学领域内机器学习挑战的重要方案。本文介绍了一个名为tn4ml的新库，旨在将这些张量网络无缝集成到机器学习任务的优化流程中。受到现有机器学习框架的启发，该库提供了一个用户友好的结构，并包括用于数据嵌入、目标函数定义以及使用多种策略进行模型训练的功能模块。通过在表格数据上的有监督学习和图像数据集上的无监督学习中的应用实例展示了其灵活性，并分析了为张量网络定制化机器学习流程的各个部分如何影响性能指标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tensor Networks have emerged as a prominent alternative to neural networksfor addressing Machine Learning challenges in foundational sciences, paving theway for their applications to real-life problems. This paper introduces tn4ml,a novel library designed to seamlessly integrate Tensor Networks intooptimization pipelines for Machine Learning tasks. Inspired by existing MachineLearning frameworks, the library offers a user-friendly structure with modulesfor data embedding, objective function definition, and model training usingdiverse optimization strategies. We demonstrate its versatility through twoexamples: supervised learning on tabular data and unsupervised learning on animage dataset. Additionally, we analyze how customizing the parts of theMachine Learning pipeline for Tensor Networks influences performance metrics.</description>
      <author>example@mail.com (Ema Puljak, Sergio Sanchez-Ramirez, Sergi Masot-Llima, Jofre Vallès-Muns, Artur Garcia-Saez, Maurizio Pierini)</author>
      <guid isPermaLink="false">2502.13090v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>A deep learning framework for efficient pathology image analysis</title>
      <link>http://arxiv.org/abs/2502.13027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;人工智能通过从高分辨率全切片图像预测生物标志物，正在改变数字病理学。然而，当前的方法在计算上效率低下，处理每个全切片图像的数千个冗余切片，并且需要复杂的聚合模型。EAGLE（高效引导局部检查方法）是一个深度学习框架，模拟了病理学家通过选择性地分析信息区域来工作。&lt;h4&gt;背景&lt;/h4&gt;人工智能技术已经开始应用于数字病理学领域，其中最典型的应用是从全切片图像中预测生物标志物。但是现有的方法存在计算资源消耗大和处理效率低的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且精确的深度学习框架EAGLE，通过选择性分析有信息量的区域来提高模型的表现，并减少所需的计算时间。&lt;h4&gt;方法&lt;/h4&gt;EAGLE使用两个基础模型：CHIEF用于有效切片选择，Virchow2用于提取高质量特征。此研究对包括31个任务在内的四种癌症类型进行了基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;相比于现有的前沿滑动和切片级别基础模型，EAGLE在最高AUROC指标上表现出色，并且处理速度更快，耗时仅需2.27秒，而减少了超过99%的计算时间。&lt;h4&gt;结论&lt;/h4&gt;EAGLE不仅提高了数字病理学中的AI效率，还提供了更加可靠和可解释的结果。这使得实时工作流程成为可能，并消除了对高性能计算机的需求，使基于人工智能的病理诊断变得更加普及。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到，AI已经通过从高分辨率全切片图像中预测生物标志物而彻底改变了数字病理学领域。然而，当前的方法在计算上存在低效的问题，需要处理大量冗余切片并使用复杂的聚合模型。为了解决这些问题，研究人员开发了EAGLE（Efficient Approach for Guided Local Examination），这是一种模仿病理学家工作方式的深度学习框架，通过选择性地分析有信息量的区域来提高效率和准确性。这项研究在四种癌症类型上进行了基准测试，涵盖了形态学、生物标志物预测以及预后任务，结果显示EAGLE相比现有的前沿模型表现出色，并且大大减少了处理时间，使其更适合实时工作流程，并且使得病理学家可以验证所有用于分析中的切片。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has transformed digital pathology by enablingbiomarker prediction from high-resolution whole slide images (WSIs). However,current methods are computationally inefficient, processing thousands ofredundant tiles per WSI and requiring complex aggregator models. We introduceEAGLE (Efficient Approach for Guided Local Examination), a deep learningframework that emulates pathologists by selectively analyzing informativeregions. EAGLE incorporates two foundation models: CHIEF for efficient tileselection and Virchow2 for extracting high-quality features. Benchmarking wasconducted against leading slide- and tile-level foundation models across 31tasks from four cancer types, spanning morphology, biomarker prediction andprognosis. EAGLE outperformed state-of-the-art foundation models by up to 23%and achieved the highest AUROC overall. It processed a slide in 2.27 seconds,reducing computational time by more than 99% compared to existing models. Thisefficiency enables real-time workflows, allows pathologists to validate alltiles which are used by the model during analysis, and eliminates dependence onhigh-performance computing, making AI-powered pathology more accessible. Byreliably identifying meaningful regions and minimizing artifacts, EAGLEprovides robust and interpretable outputs, supporting rapid slide searches,integration into multi-omics pipelines and emerging clinical foundation models.</description>
      <author>example@mail.com (Peter Neidlinger, Tim Lenz, Sebastian Foersch, Chiara M. L. Loeffler, Jan Clusmann, Marco Gustav, Lawrence A. Shaktah, Rupert Langer, Bastian Dislich, Lisa A. Boardman, Amy J. French, Ellen L. Goode, Andrea Gsur, Stefanie Brezina, Marc J. Gunter, Robert Steinfelder, Hans-Michael Behrens, Christoph Röcken, Tabitha Harrison, Ulrike Peters, Amanda I. Phipps, Giuseppe Curigliano, Nicola Fusco, Antonio Marra, Michael Hoffmeister, Hermann Brenner, Jakob Nikolas Kather)</author>
      <guid isPermaLink="false">2502.13027v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Transferable Machine Learning Potential X-MACE for Excited States using Integrated DeepSets</title>
      <link>http://arxiv.org/abs/2502.12870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了用于精确建模激发态并在关键非平滑区域提高准确性的深度学习架构，解决了量子化学计算中的锥形交叉问题。&lt;h4&gt;背景&lt;/h4&gt;在光化学反应中，锥形交叉是重要的通道，它们促进了潜在能级表面之间的快速无辐射跃迁。然而，使用量子化学计算这些交叉是非常计算密集的，并且由于其本质上非平滑和复杂的性质，利用机器学习进行建模也面临巨大挑战。&lt;h4&gt;目的&lt;/h4&gt;通过引入深度学习架构来精确模拟激发态并在锥形交叉区域提高准确性，解决锥形交叉建模中的问题。&lt;h4&gt;方法&lt;/h4&gt;将Deep Sets集成到消息传递原子簇扩展（MACE）框架中，形成非光滑激发态势能表面的平滑表示。使用多种分子验证这种方法，并将其与传统激发态模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;开发的方法在准确模拟锥形交叉附近的能量景观方面显著优于常规激发态模型。此外，还展示了基于基态基础机器学习模型来构建激发态，这表明所发展的模型不仅可以在基态和激发态之间转移，还可以应用于超出训练数据集的分子系统。&lt;h4&gt;结论&lt;/h4&gt;这项研究增强了激发态建模的准确性，并为更复杂分子系统的调查奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conical intersections serve as critical gateways in photochemical reactions,enabling rapid nonradiative transitions between potential energy surfaces thatunderpin fundamental processes such as photosynthesis or vision. Theircalculation with quantum chemistry is, however, extremely computationallyintensive and their modeling with machine learning poses a significantchallenge due to their inherently non-smooth and complex nature. To addressthis challenge, we introduce a deep learning architecture designed to preciselymodel excited states and improve their accuracy around these critical,non-smooth regions. Our model integrates Deep Sets into the Message PassingAtomic Cluster Expansion (MACE) framework resulting in a smooth representationof the non-smooth excited-state potential energy surfaces. We validate ourmethod using numerous molecules, showcasing a significant improvement inaccurately modeling the energy landscape around conical intersections comparedto conventional excited-state models. Additionally, we apply ground-statefoundational machine learning models as a basis for excited states. By doingso, we showcase that the developed model is capable of transferring not onlyfrom the ground state to excited states, but also within chemical space tomolecular systems beyond those included in the training dataset. Thisadvancement not only enhances the fidelity of excited-state modeling, but alsolays the foundations for the investigation of more complex molecular systems.</description>
      <author>example@mail.com (Rhyan Barrett, Christoph Ortner, Julia Westermayr)</author>
      <guid isPermaLink="false">2502.12870v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RealSyn: An Effective and Scalable Multimodal Interleaved Document Transformation Paradigm</title>
      <link>http://arxiv.org/abs/2502.12513v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 12 figures, Webpage: https://garygutc.github.io/RealSyn&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的数据集RealSyn，该数据集结合了真实和合成文本，并通过创新的方法有效利用了大量的非成对的多模态交织文档。&lt;h4&gt;背景&lt;/h4&gt;Contrastive Language-Image Pre-training (CLIP) 在经过广泛的图像文字配对预训练后，在多种基准测试中表现出色。然而，大量的非配对数据（例如，多模态交织文档）尚未得到充分利用。&lt;h4&gt;目的&lt;/h4&gt;充分利用未被使用的大量非配对的多模态交织文档，通过创建一个真实世界的视觉-语言表示学习的新数据集来提高模型性能。&lt;h4&gt;方法&lt;/h4&gt;['建立了一个真实世界的数据提取管道以从多源中抽取高质量的图像和文本。', '设计了一种分层检索方法高效地将每张图片与多个语义相关的现实文本相匹配。', '提出了一个增强图像语义生成模块，用于合成文本生产，进一步提升细粒度视觉信息。', '采用一种语义平衡采样策略提高数据集的多样性，有助于学习长尾概念。']&lt;h4&gt;主要发现&lt;/h4&gt;['构建了包含真实和合成文本的数据集RealSyn，分别提供三种规模：15M、30M 和 100M。', '实验表明，基于 RealSyn 预训练的模型在多个下游任务上达到了最先进的性能。', 'RealSyn 数据集具有良好的可扩展性，为未来的研究提供了重要的资源。']&lt;h4&gt;结论&lt;/h4&gt;提出的创新方法和数据集有效提升了视觉-语言表示学习的能力，并通过多种基准测试验证了其优越性。&lt;h4&gt;翻译&lt;/h4&gt;在大量的图像文字配对预训练后，对比语言图像预训练（CLIP）在众多标准评估中展示了显著的性能。然而，大量未配对的数据如多模态交织文档仍然没有得到充分利用。为了充分挖掘这些未配对文档的价值，我们首先构建了一个真实世界数据抽取管道，用于提取高质量的图像和文本。随后设计了一种层级检索方法来高效地将每张图片与多个语义相关的现实文本联系起来。为了进一步增强细粒度视觉信息，我们提出了一种基于图像语义增强生成模块合成文本的方法，并采用一种语义平衡采样策略提高数据集多样性，有利于长尾概念的学习。基于这些创新，我们构建了一个结合真实和合成文本的数据集RealSyn，在15M、30M 和 100M三个规模下可用。大量的实验验证了RealSyn在视觉语言表示学习中的有效性，并展示了其良好的可扩展性。在多个下游任务上预训练于RealSyn上的模型取得了最佳性能表现。为了促进未来研究，我们开放了数据集和预训练的权重访问：https://github.com/deepglint/RealSyn&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; After pre-training on extensive image-text pairs, Contrastive Language-ImagePre-training (CLIP) demonstrates promising performance on a wide variety ofbenchmarks. However, a substantial volume of non-paired data, such asmultimodal interleaved documents, remains underutilized for vision-languagerepresentation learning. To fully leverage these unpaired documents, weinitially establish a Real-World Data Extraction pipeline to extracthigh-quality images and texts. Then we design a hierarchical retrieval methodto efficiently associate each image with multiple semantically relevantrealistic texts. To further enhance fine-grained visual information, we proposean image semantic augmented generation module for synthetic text production.Furthermore, we employ a semantic balance sampling strategy to improve datasetdiversity, enabling better learning of long-tail concepts. Based on theseinnovations, we construct RealSyn, a dataset combining realistic and synthetictexts, available in three scales: 15M, 30M, and 100M. Extensive experimentsdemonstrate that RealSyn effectively advances vision-language representationlearning and exhibits strong scalability. Models pre-trained on RealSyn achievestate-of-the-art performance on multiple downstream tasks. To facilitate futureresearch, the RealSyn dataset and pre-trained model weights are released athttps://github.com/deepglint/RealSyn.</description>
      <author>example@mail.com (Tiancheng Gu, Kaicheng Yang, Chaoyi Zhang, Yin Xie, Xiang An, Ziyong Feng, Dongnan Liu, Weidong Cai, Jiankang Deng)</author>
      <guid isPermaLink="false">2502.12513v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Graph Structure Learning</title>
      <link>http://arxiv.org/abs/2502.12618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted by TheWebConf 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;图神经网络（GNNs）已成为处理图结构数据学习任务的主流方法，但其性能会因不理想的图结构而大幅下降。为解决这一问题，提出了图结构学习（Graph Structure Learning, GSL），该技术可以自适应地优化节点连接。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在处理图结构数据方面表现卓越，但是当面对次优的图结构时，其性能会显著降低。现有的图结构学习方法主要关注于基于节点相似度来构建关系，但往往忽视了节点信息的质量问题，并且所生成的图结构通常是对称的。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有图结构学习技术中的不足，研究团队提出了一种不确定性感知的图结构学习（UnGSL）策略。该方法旨在通过估计节点信息的不确定性来调整方向连接的强度，从而减少高不确定性的节点的影响，并且可以作为插件模块集成到现有的图结构学习方法中。&lt;h4&gt;方法&lt;/h4&gt;所提出的UnGSL策略能够估算每个节点的信息质量并相应地调节其与其他节点之间的连接强度。此外，此策略设计为一种易于与现有模型结合的无创性解决方案，几乎不需要额外的计算资源。&lt;h4&gt;主要发现&lt;/h4&gt;通过将UnGSL应用到六种代表性图结构学习方法中进行实验验证后显示，所有情况下均实现了性能提升的效果。该工作表明了改进图数据的质量对于提升基于GNN的方法的有效性和灵活性的重要性。&lt;h4&gt;结论&lt;/h4&gt;研究团队提出了一种新颖的不确定性感知图结构学习（UnGSL）策略，有效地解决了现有图结构学习技术中的关键问题，并且展示出在多个基准测试中具有良好的性能表现。这项工作强调了通过提高数据质量来增强机器学习模型效果的一种新途径。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络（GNNs）已经成为处理图形结构化数据的主要方法，但其有效性可能会受到次优的图结构的重大影响。为解决这个问题，提出了图结构学习（GSL），这是一种能够自适应优化节点连接的技术。然而，我们发现现有GSL方法存在两个主要限制：1) 大多数方法侧重于通过相似性来构建关系，而忽视了信息质量的问题；2) 所构造的图形通常需要对称，这可能限制了模型的灵活性和效率。为克服这些局限，本研究提出了一种基于不确定性感知图结构学习（UnGSL）策略。该方法评估节点的信息不确定性，并利用它来调整有向连接的强度，在此过程中自适应地减少高不确定性的节点影响。值得注意的是，UnGSL可以作为插入式模块无缝集成到现有的GSL方法中，几乎不增加额外计算成本。在实验中，我们把UnGSL整合进了六种代表性GSL方法中，并展示了所有情况下性能都有提升的效果。代码可在https://github.com/UnHans/UnGSL上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become a prominent approach for learningfrom graph-structured data. However, their effectiveness can be significantlycompromised when the graph structure is suboptimal. To address this issue,Graph Structure Learning (GSL) has emerged as a promising technique thatrefines node connections adaptively. Nevertheless, we identify two keylimitations in existing GSL methods: 1) Most methods primarily focus on nodesimilarity to construct relationships, while overlooking the quality of nodeinformation. Blindly connecting low-quality nodes and aggregating theirambiguous information can degrade the performance of other nodes. 2) Theconstructed graph structures are often constrained to be symmetric, which maylimit the model's flexibility and effectiveness. To overcome these limitations,we propose an Uncertainty-aware Graph Structure Learning (UnGSL) strategy.UnGSL estimates the uncertainty of node information and utilizes it to adjustthe strength of directional connections, where the influence of nodes with highuncertainty is adaptively reduced.Importantly, UnGSL serves as a plug-in modulethat can be seamlessly integrated into existing GSL methods with minimaladditional computational cost. In our experiments, we implement UnGSL into sixrepresentative GSL methods, demonstrating consistent performance improvements.The code is available at https://github.com/UnHans/UnGSL.</description>
      <author>example@mail.com (Shen Han, Zhiyao Zhou, Jiawei Chen, Zhezheng Hao, Sheng Zhou, Gang Wang, Yan Feng, Chun Chen, Can Wang)</author>
      <guid isPermaLink="false">2502.12618v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Timesteps: A Novel Activation-wise Membrane Potential Propagation Mechanism for Spiking Neural Networks in 3D cloud</title>
      <link>http://arxiv.org/abs/2502.12791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的激活策略，用于解决基于脉冲神经网络（SNN）在处理视觉任务时的延迟和计算成本问题。&lt;h4&gt;背景&lt;/h4&gt;由于事件数据与点云有相似特性，一些研究开始将事件数据视作类似点云的数据进行分析。此外，从事件视觉角度出发的方法也采用异步性质的SNN来处理点云。然而这些方法通常局限于特定领域，难以在其他交叉领域应用。&lt;h4&gt;目的&lt;/h4&gt;为了克服传统时间步长激活策略对脉冲神经元更新策略限制的问题，论文提出了一种新的激活策略，可以提升基于事件和点云数据的任务性能，并减少延迟。&lt;h4&gt;方法&lt;/h4&gt;提出了名为Activation-wise Membrane Potential Propagation (AMP2)的新激活策略。该策略将时间步骤的概念从手动设定的参数扩展到任何现有的网络结构中。&lt;h4&gt;主要发现&lt;/h4&gt;在常见点云任务（分类、对象和场景分割）以及事件云任务（动作识别）上的实验表明，相比传统的基于时间步长的方法，AMP2能够稳定SNN训练并保持竞争力的同时减少延迟。&lt;h4&gt;结论&lt;/h4&gt;所提出的AMP2激活策略可以作为一种通用的解决方案来改善SNN在各种视觉任务中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the similar characteristics between event-based visual data and pointclouds, recent studies have emerged that treat event data as event clouds tolearn based on point cloud analysis. Additionally, some works approach pointclouds from the perspective of event vision, employing Spiking Neural Network(SNN) due to their asynchronous nature. However, these contributions are oftendomain-specific, making it difficult to extend their applicability to otherintersecting fields. Moreover, while SNN-based visual tasks have seensignificant growth, the conventional timestep-wise iterative activationstrategy largely limits their real-world applications by large timesteps,resulting in significant delays and increased computational costs. Althoughsome innovative methods achieve good performance with short timesteps (&lt;10),few have fundamentally restructured the update strategy of spiking neurons tocompletely overcome the limitations of timesteps. In response to theseconcerns, we propose a novel and general activation strategy for spikingneurons called Activation-wise Membrane Potential Propagation (AMP2). Thisapproach extends the concept of timesteps from a manually crafted parameterwithin the activation function to any existing network structure. Inexperiments on common point cloud tasks (classification, object, and scenesegmentation) and event cloud tasks (action recognition), we found that AMP2stabilizes SNN training, maintains competitive performance, and reduces latencycompared to the traditional timestep-wise activation paradigm.</description>
      <author>example@mail.com (Jian Song, Boxuan Zheng, Xiangfei Yang, Donglin Wang)</author>
      <guid isPermaLink="false">2502.12791v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RadSplatter: Extending 3D Gaussian Splatting to Radio Frequencies for Wireless Radiomap Extrapolation</title>
      <link>http://arxiv.org/abs/2502.12686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;RadSplatter是一个将3D高斯散射扩展到无线电频率的框架，旨在通过稀疏测量有效且准确地构建无线信号强度的空间分布图（即辐射图），适用于网络优化和自动驾驶等场景。&lt;h4&gt;背景&lt;/h4&gt;无线信号强度空间分布图对于网络优化、自动驾驶等领域至关重要。然而，在大型室外网络中，由于规模大，构造此类地图的成本很高。&lt;h4&gt;目的&lt;/h4&gt;提出RadSplatter框架，用于从稀疏测量中高效准确地推断出完整的辐射图。&lt;h4&gt;方法&lt;/h4&gt;利用3D高斯模型表示环境散射器和无线电路径，并通过放松均值方案重新参数化3D高斯的位置。此外，还开发了一种相机无关的3DGS投影技术来将3D高斯映射到2D无线电波束模式上。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，RadSplatter在合成数据和真实世界场景中展示了最先进的外推准确性和执行速度。&lt;h4&gt;结论&lt;/h4&gt;通过结合环境散射器建模、优化的参数化方案以及高效的投影技术，RadSplatter能够从稀疏信号测量中生成高精度的辐射图，适用于大规模无线网络。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个新的框架RadSplatter，它将3D高斯散点扩展到无线电频率，旨在通过稀疏测量高效准确地推断出整个系统的无线信号强度分布地图（即辐射图）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A radiomap represents the spatial distribution of wireless signal strength,critical for applications like network optimization and autonomous driving.However, constructing radiomap relies on measuring radio signal power acrossthe entire system, which is costly in outdoor environments due to large networkscales. We present RadSplatter, a framework that extends 3D Gaussian Splatting(3DGS) to radio frequencies for efficient and accurate radiomap extrapolationfrom sparse measurements. RadSplatter models environmental scatterers and radiopaths using 3D Gaussians, capturing key factors of radio wave propagation. Itemploys a relaxed-mean (RM) scheme to reparameterize the positions of 3DGaussians from noisy and dense 3D point clouds. A camera-free 3DGS-basedprojection is proposed to map 3D Gaussians onto 2D radio beam patterns.Furthermore, a regularized loss function and recursive fine-tuning using highlystructured sparse measurements in real-world settings are applied to ensurerobust generalization. Experiments on synthetic and real-world data showstate-of-the-art extrapolation accuracy and execution speed.</description>
      <author>example@mail.com (Yiheng Wang, Ye Xue, Shutao Zhang, Tsung-Hui Chang)</author>
      <guid isPermaLink="false">2502.12686v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>S2C: Learning Noise-Resistant Differences for Unsupervised Change Detection in Multimodal Remote Sensing Images</title>
      <link>http://arxiv.org/abs/2502.12604v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的无监督变化检测（UCD）框架，该框架适用于同质和异构的遥感图像。通过结合视觉基础模型（VFM）和对比学习方法论，引入了Semantic-to-Change (S2C) 学习框架。&lt;h4&gt;背景&lt;/h4&gt;多模态遥感影像中的无监督变化检测是一个具有挑战性的问题，由于其固有的时空复杂性和不同成像传感器导致的异质性。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的对比学习方法论，将视觉基础模型中隐含的知识转化为变化表示，以消除显式监督的需求。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的三元组学习策略，明确地建模时间差异，并引入随机空间和光谱扰动来增强对时间噪声的鲁棒性。定义了网格稀疏正则化以抑制不重要的变化，并开发了一个IoU匹配算法来优化变化检测结果。&lt;h4&gt;主要发现&lt;/h4&gt;在四个基准变化检测数据集上的实验表明，提出的S2C学习框架实现了显著的准确性改进，分别超过了当前最佳方法31%，9%，23%和15%。该方法还展示了良好的鲁棒性和样本效率，适用于各种视觉基础模型或骨干神经网络的训练和适应。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在无监督变化检测任务中具有优势，并且易于与其他视觉基础模型集成。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised Change Detection (UCD) in multimodal Remote Sensing (RS) images remains a difficult challenge due to the inherent spatio-temporal complexity within data, and the heterogeneity arising from different imaging sensors. Inspired by recent advancements in Visual Foundation Models (VFMs) and Contrastive Learning (CL) methodologies, this research aims to develop CL methodologies to translate implicit knowledge in VFM into change representations, thus eliminating the need for explicit supervision.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised Change Detection (UCD) in multimodal Remote Sensing (RS) imagesremains a difficult challenge due to the inherent spatio-temporal complexitywithin data, and the heterogeneity arising from different imaging sensors.Inspired by recent advancements in Visual Foundation Models (VFMs) andContrastive Learning (CL) methodologies, this research aims to develop CLmethodologies to translate implicit knowledge in VFM into changerepresentations, thus eliminating the need for explicit supervision. To thisend, we introduce a Semantic-to-Change (S2C) learning framework for UCD in bothhomogeneous and multimodal RS images. Differently from existing CLmethodologies that typically focus on learning multi-temporal similarities, weintroduce a novel triplet learning strategy that explicitly models temporaldifferences, which are crucial to the CD task. Furthermore, random spatial andspectral perturbations are introduced during the training to enhance robustnessto temporal noise. In addition, a grid sparsity regularization is defined tosuppress insignificant changes, and an IoU-matching algorithm is developed torefine the CD results. Experiments on four benchmark CD datasets demonstratethat the proposed S2C learning framework achieves significant improvements inaccuracy, surpassing current state-of-the-art by over 31\%, 9\%, 23\%, and15\%, respectively. It also demonstrates robustness and sample efficiency,suitable for training and adaptation of various Visual Foundation Models (VFMs)or backbone neural networks. The relevant code will be available at:github.com/DingLei14/S2C.</description>
      <author>example@mail.com (Lei Ding, Xibing Zuo, Danfeng Hong, Haitao Guo, Jun Lu, Zhihui Gong, Lorenzo Bruzzone)</author>
      <guid isPermaLink="false">2502.12604v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for Improved Text-Based Learning for LGE Detection</title>
      <link>http://arxiv.org/abs/2502.12948v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Poster at Workshop on Large Language Models and Generative AI for  Health at AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种仅基于临床报告文本训练的模型，用于检测心脏LGE MRI图像中的疤痕。通过引入合成数据增强、标准化图像方向以及使用描述性损失来改进性能。&lt;h4&gt;背景&lt;/h4&gt;检测心脏LGE MRI图像中的高增强（hyperenhancement）是一个需要大量临床专业知识的任务。虽然基于深度学习的方法在该任务上取得了显著成果，但这些方法通常需要大量的带细粒度标注的数据。&lt;h4&gt;目的&lt;/h4&gt;开发一种仅利用临床报告文本训练的模型来执行LGE检测，并通过各种策略提高其性能。&lt;h4&gt;方法&lt;/h4&gt;1. 使用合成数据增强技术创建疤痕图像及关联文本；2. 采用解剖学导向的方式标准化图像方向，以更好地对齐空间和文本特征；3. 利用描述性损失提供细粒度监督；4. 探索视觉编码器预训练对性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;通过上述方法的结合使用，模型在相对较小的临床队列（965名患者）上表现优异。此外，进行了消融实验以阐明每个设计组件对于整体性能的贡献。&lt;h4&gt;结论&lt;/h4&gt;本研究提出的方法证明了仅依靠文本信息进行心脏病变检测的可能性，并展示了如何通过合成数据和描述性损失等技术提高模型性能。&lt;h4&gt;翻译&lt;/h4&gt;心脏LGE MRI图像中高增强（hyperenhancement）的检测是一项需要高水平临床知识的任务。尽管深度学习方法在该领域取得了进展，但这些方法通常依赖于大量带有详细标注的数据。研究团队利用来自心脏病理MRI检查报告中的丰富信息训练模型，并采用一系列策略提升性能，如通过合成数据扩展文本和图像对、解剖学导向标准化图像方向等。实验表明，在较小规模的患者样本中这种方法可以有效工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detection of hyperenhancement from cardiac LGE MRI images is a complex taskrequiring significant clinical expertise. Although deep learning-based modelshave shown promising results for the task, they require large amounts of datawith fine-grained annotations. Clinical reports generated for cardiac MRstudies contain rich, clinically relevant information, including the location,extent and etiology of any scars present. Although recently developedCLIP-based training enables pretraining models with image-text pairs, itrequires large amounts of data and further finetuning strategies on downstreamtasks. In this study, we use various strategies rooted in domain knowledge totrain a model for LGE detection solely using text from clinical reports, on arelatively small clinical cohort of 965 patients. We improve performancethrough the use of synthetic data augmentation, by systematically creating scarimages and associated text. In addition, we standardize the orientation of theimages in an anatomy-informed way to enable better alignment of spatial andtext features. We also use a captioning loss to enable fine-grained supervisionand explore the effect of pretraining of the vision encoder on performance.Finally, ablation studies are carried out to elucidate the contributions ofeach design component to the overall performance of the model.</description>
      <author>example@mail.com (Athira J Jacob, Puneet Sharma, Daniel Rueckert)</author>
      <guid isPermaLink="false">2502.12948v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Myna: Masking-Based Contrastive Learning of Musical Representations</title>
      <link>http://arxiv.org/abs/2502.12511v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Myna是一种基于对比学习框架的简单而有效的自监督音乐表示学习方法。&lt;h4&gt;背景&lt;/h4&gt;之前的自监督学习方法在批处理大小、音高敏感性以及关键特征捕捉上存在一定的局限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的数据增强策略，即token masking，并采用视觉变换器（ViT）作为骨干网络，以提升模型性能和效率。&lt;h4&gt;方法&lt;/h4&gt;利用垂直补丁和masking 90%的光谱图标记来改进表示学习，同时避免了传统增广方式对音高敏感性的破坏。&lt;h4&gt;主要发现&lt;/h4&gt;{'批处理大小提升': 'token masking使得每个GPU上的批量尺寸显著增加到4096', '增强音高敏感性': '通过避免传统的数据增强方法，保留了音高的敏感性，在如音调检测等任务中表现更佳', '关键特征捕捉': '使用垂直补丁更好地捕获用于音调检测的关键特性'}&lt;h4&gt;结论&lt;/h4&gt;{'性能优越': '在单个GPU上训练的Myna-22M-Hybrid模型超越了之前的方法，包括62M参数量的MULE模型', '设置新记录': '在公开可用的数据上训练的Myna-22M-Hybrid模型超过了95M参数量的MERT-95M-public'}&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的英文原文已经给出，此处省略&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Myna, a simple yet effective approach for self-supervised musicalrepresentation learning. Built on a contrastive learning framework, Mynaintroduces two key innovations: (1) the use of a Vision Transformer (ViT) onmel-spectrograms as the backbone and (2) a novel data augmentation strategy,token masking, that masks 90 percent of spectrogram tokens. These innovationsdeliver both effectiveness and efficiency: (i) Token masking enables asignificant increase in per-GPU batch size, from 48 or 120 in prior methods(CLMR, MULE) to 4096. (ii) By avoiding traditional augmentations, Myna retainspitch sensitivity, enhancing performance in tasks like key detection. (iii) Theuse of vertical patches allows the model to better capture critical featuresfor key detection. Our hybrid model, Myna-22M-Hybrid, processes both 16x16 and128x2 patches, achieving state-of-the-art results. Trained on a single GPU, itoutperforms MULE (62M) on average and rivals MERT-95M, which was trained on 16and 64 GPUs, respectively. Additionally, it surpasses MERT-95M-public,establishing itself as the best-performing model trained on publicly availabledata. We release our code and models to promote reproducibility and facilitatefuture research.</description>
      <author>example@mail.com (Ori Yonay, Tracy Hammond, Tianbao Yang)</author>
      <guid isPermaLink="false">2502.12511v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Performance of Zero-Shot Time Series Foundation Models on Cloud Data</title>
      <link>http://arxiv.org/abs/2502.12944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了时间序列基础模型在云数据上的有效性，发现这些模型往往无法生成有意义或准确的零样本预测，并且其性能被简单的线性基线模型超越。&lt;h4&gt;背景&lt;/h4&gt;时间序列基础模型（FMs）作为跨多个不同领域的时间序列进行零样本预测的一种流行范式而出现。它们声称在包括云计算数据在内的多个领域中具有有效性。&lt;h4&gt;目的&lt;/h4&gt;探讨时间序列基础模型在云数据上的实际效果是否与其声称的一致。&lt;h4&gt;方法&lt;/h4&gt;通过实验评估了多种知名的基础模型在处理云数据时的性能，并将这些模型与简单的线性基线模型进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;许多流行的时间序列基础模型无法生成有意义或准确的零样本预测，其性能被简单的线性模型超越。此外，研究还揭示了一些有趣的病态现象，例如某些情况下，模型会突然输出看似随机的预测结果。&lt;h4&gt;结论&lt;/h4&gt;研究表明，时间序列基础模型在建模云数据方面存在广泛的问题和挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series foundation models (FMs) have emerged as a popular paradigm forzero-shot multi-domain forecasting. FMs are trained on numerous diversedatasets and claim to be effective forecasters across multiple different timeseries domains, including cloud data. In this work we investigate this claim,exploring the effectiveness of FMs on cloud data. We demonstrate that manywell-known FMs fail to generate meaningful or accurate zero-shot forecasts inthis setting. We support this claim empirically, showing that FMs areoutperformed consistently by simple linear baselines. We also illustrate anumber of interesting pathologies, including instances where FMs suddenlyoutput seemingly erratic, random-looking forecasts. Our results suggest awidespread failure of FMs to model cloud data.</description>
      <author>example@mail.com (William Toner, Thomas L. Lee, Artjom Joosen, Rajkarn Singh, Martin Asenov)</author>
      <guid isPermaLink="false">2502.12944v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation</title>
      <link>http://arxiv.org/abs/2502.12638v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025, 10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个用于3D分子生成的模型NExT-Mol，结合了1D语言模型和3D扩散模型的优势。&lt;h4&gt;背景&lt;/h4&gt;当前在药物发现和材料设计中的3D分子生成中，大多数研究集中在使用3D扩散模型来建模连续的3D构象，但忽视了基于SELFIES的一维语言模型（LM）的优势。一维语言模型可以生成100%有效的分子，并利用大规模的一维分子数据集。&lt;h4&gt;目的&lt;/h4&gt;提出一个结合了一维SELFIES基语言模型和三维扩散模型优点的基础模型NExT-Mol以提高3D分子生成的性能。&lt;h4&gt;方法&lt;/h4&gt;NExT-Mol使用广泛预训练的分子LM进行一维分子生成，随后用3D扩散模型预测该分子的3D构象。通过增大LM模型尺寸、改进扩散神经网络架构和应用1D到3D迁移学习来提高其性能。&lt;h4&gt;主要发现&lt;/h4&gt;提出的1D分子LM在分布相似性上显著优于基线，并确保了有效性；3D扩散模型在构象预测方面取得了领先的成绩。基于这些改善，在GEOM-DRUGS的从头3D生成中，NExT-Mol实现了26%相对改进的3DFCD；在QM9-2014上的条件3D生成中平均获得13%相对收益。&lt;h4&gt;结论&lt;/h4&gt;通过结合SELFIES语言模型和扩散模型的优势，NExT-Mol为3D分子生成提供了一种新的方法。该方法提高了生成有效且高质量的3D分子的能力。&lt;h4&gt;翻译&lt;/h4&gt;3D分子生成对于药物发现及材料设计至关重要。先前的研究主要集中在利用三维扩散模型来建模连续的三维构象上，但忽略了基于SELFIES的一维语言模型的优势，后者可以完全生成有效的分子，并能利用大规模的一维分子数据集进行训练。为了结合这些优势，我们提出了一个基础模型NExT-Mol：将一维语言建模与三维扩散相结合以实现3D分子生成。NExT-Mol首先使用经过充分预训练的1D分子LM来生成分子，随后通过一个3D扩散模型预测该分子的3D构象，并在此基础上进行了一系列性能增强措施，包括增大LM模型尺寸、改进扩散神经网络架构以及应用从一维到三维的迁移学习。实验表明，我们的一维分子LM在分布相似性上显著优于基线模型并保证了生成的有效性；我们的三维扩散模型在构象预测方面取得了领先的成绩。基于这些提升，在GEOM-DRUGS上的从头3D生成中，NExT-Mol实现了26%相对改进的FCD分数，并且在QM9-2014数据集上进行条件生成时平均获得13%的相对收益。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D molecule generation is crucial for drug discovery and material design.While prior efforts focus on 3D diffusion models for their benefits in modelingcontinuous 3D conformers, they overlook the advantages of 1D SELFIES-basedLanguage Models (LMs), which can generate 100% valid molecules and leverage thebillion-scale 1D molecule datasets. To combine these advantages for 3D moleculegeneration, we propose a foundation model -- NExT-Mol: 3D Diffusion Meets 1DLanguage Modeling for 3D Molecule Generation. NExT-Mol uses an extensivelypretrained molecule LM for 1D molecule generation, and subsequently predictsthe generated molecule's 3D conformers with a 3D diffusion model. We enhanceNExT-Mol's performance by scaling up the LM's model size, refining thediffusion neural architecture, and applying 1D to 3D transfer learning.Notably, our 1D molecule LM significantly outperforms baselines indistributional similarity while ensuring validity, and our 3D diffusion modelachieves leading performances in conformer prediction. Given these improvementsin 1D and 3D modeling, NExT-Mol achieves a 26% relative improvement in 3D FCDfor de novo 3D generation on GEOM-DRUGS, and a 13% average relative gain forconditional 3D generation on QM9-2014. Our codes and pretrained checkpoints areavailable at https://github.com/acharkq/NExT-Mol.</description>
      <author>example@mail.com (Zhiyuan Liu, Yanchen Luo, Han Huang, Enzhi Zhang, Sihang Li, Junfeng Fang, Yaorui Shi, Xiang Wang, Kenji Kawaguchi, Tat-Seng Chua)</author>
      <guid isPermaLink="false">2502.12638v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>A Graph-Enhanced Deep-Reinforcement Learning Framework for the Aircraft Landing Problem</title>
      <link>http://arxiv.org/abs/2502.12617v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper presents a novel deep reinforcement learning framework  combining graph neural networks with actor-critic architectures to address  the aircraft landing problem. The framework achieves a 99.95% reduction in  computational time compared to Mixed Integer Programming while maintaining  safety compliance, and 38% higher runway throughput over First Come First  Serve&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文提出了一种基于深度强化学习的新型框架，用于解决飞机着陆问题（ALP）。该方法结合了图神经网络和演员评论家架构，并展示了在标准基准数据集上优于传统操作研究算法的结果。&lt;h4&gt;背景&lt;/h4&gt;飞机着陆问题是航空运输管理中的一个挑战性难题。现有的解决方案大多基于运营研究算法和元启发式算法，但这些方法在处理实时再调度和计算可扩展性方面仍存在问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的深度强化学习框架来解决ALP，并展示其在不同因素上的改进效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一个图基状态表示法、用于多目标竞争着陆调度的专业演员评论家架构以及跑道平衡策略，后者确保资源利用效率同时满足安全约束条件。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该算法与操作研究算法相比计算时间减少了99.95%，并且在跑道吞吐量方面比先到先服务方法高38%。此外，它可以在1秒内生成解决方案，并且不需要重新训练，非常适用于工业部署。&lt;h4&gt;结论&lt;/h4&gt;所提出的解决方案具有显著的性能改进和实用性，在实时再调度方面特别有优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：飞机着陆问题是航空运输管理中的一个挑战性难题，其目标是通过优化成本和延迟来安排到达的飞机序列。尽管传统方法在某些因素上表现良好，但它们在处理实际时间重新调度和计算可扩展性方面仍存在问题。本文介绍了一种结合图神经网络与演员评论家架构的深度强化学习框架，用于解决ALP，并提出了三个关键贡献：一种有效的捕捉飞机之间时空关系的图基状态表示法；一种处理多目标竞争着陆调度的专业化演员评论家架构以及确保资源利用效率并保持安全约束条件的跑道平衡策略。实验结果表明，训练后的算法在不同的问题集上表现出竞争力，并且与混合整数规划相比，在标准基准数据集上的计算时间减少了99.95%，比先到先服务方法高38%的跑道吞吐量。因此，该方案对于传统方法具有竞争力并实现了显著进步。值得注意的是，它不需要重新训练，使其特别适合于工业部署。框架生成解决方案的能力在1秒内使其实现了实时再调度，满足了空中交通管理的关键需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Aircraft Landing Problem (ALP) is one of the challenging problems inaircraft transportation and management. The challenge is to schedule thearriving aircraft in a sequence so that the cost and delays are optimized.There are various solution approaches to solving this problem, most of whichare based on operations research algorithms and meta-heuristics. Althoughtraditional methods perform better on one or the other factors, there remains aproblem of solving real-time rescheduling and computational scalabilityaltogether. This paper presents a novel deep reinforcement learning (DRL)framework that combines graph neural networks with actor-critic architecturesto address the ALP. This paper introduces three key contributions: Agraph-based state representation that efficiently captures temporal and spatialrelationships between aircraft, a specialized actor-critic architecturedesigned to handle multiple competing objectives in landing scheduling, and arunway balance strategy that ensures efficient resource utilization whilemaintaining safety constraints. The results show that the trained algorithm canbe tested on different problem sets and the results are competitive tooperation research algorithms. The experimental results on standard benchmarkdata sets demonstrate a 99.95 reduction in computational time compared to MixedInteger Programming (MIP) and 38 higher runway throughput over First Come FirstServe (FCFS) approaches. Therefore, the proposed solution is competitive totraditional approaches and achieves substantial advancements. Notably, it doesnot require retraining, making it particularly suitable for industrialdeployment. The frameworks capability to generate solutions within 1 secondenables real-time rescheduling, addressing critical requirements of air trafficmanagement.</description>
      <author>example@mail.com (Vatsal Maru)</author>
      <guid isPermaLink="false">2502.12617v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>UniGenCoder: Merging Seq2Seq and Seq2Tree Paradigms for Unified Code Generation</title>
      <link>http://arxiv.org/abs/2502.12490v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICSE2025 NIER track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;基于深度学习的代码生成已经彻底改变了当今开发者编写程序的方式。&lt;h4&gt;背景&lt;/h4&gt;现有的代码生成方法主要集中在序列到序列（Sequence-to-Sequence）或序列到树（Sequence-to-Tree）两个范式上，这两种范式虽然直观互补，但之前没有结合探索过。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一个统一这两个范式的框架，并探讨其在文本转代码和代码转代码任务上的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了名为UniGenCoder的模型，该模型包括一个共享编码器、带有少量额外参数的共享解码器以及一个动态选择最优范式的选择器。同时，在训练过程中采用了多任务学习和蒸馏策略来促进两种范式的知识转移，并利用对比学习训练选择器。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，通过结合序列到序列和序列到树两个范式生成代码具有显著潜力。&lt;h4&gt;结论&lt;/h4&gt;提出的UniGenCoder模型在文本转代码和代码转代码任务上都显示出了有效性。该研究证明了集成这两个范式的可行性，并且为未来的相关研究提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;基于深度学习的代码生成已经彻底改变了当今开发者编写程序的方式。现有的方法主要集中在序列到序列（Sequence-to-Sequence）或序列到树（Sequence-to-Tree）两种模式上，这两种模式虽然直观互补，但之前没有结合探索过。我们提出了一种名为UniGenCoder的新框架，它包括一个共享编码器、带有少量额外参数的共享解码器以及一个动态选择最优范式的选择器，并且在训练过程中采用了多任务学习和蒸馏策略来促进两种模式之间的知识转移。此外，利用对比学习技术训练了选择器以提高模型性能。实验结果显示，在文本转代码及代码转代码的任务中，该模型表现出了良好的效果，证明了结合使用这两种方法的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based code generation has completely transformed the waydevelopers write programs today. Existing approaches to code generation havefocused either on the Sequence-to-Sequence paradigm, which generates targetcode as a sequence of tokens, or the Sequence-to-Tree paradigm, which outputscode as a sequence of actions. While these two paradigms are intuitivelycomplementary, their combination has not been previously explored. By comparingthe code generated under these two paradigms, we find that integrating themholds significant potential. In this paper, we propose UniGenCoder forcode-related generation tasks, which consists of a shared encoder, a shareddecoder with a minimal set of additional parameters to unify two paradigms, anda selector that dynamically chooses optimal paradigm for each instance. Also,during the model training, we first perform the multi-task learning anddistillation strategies to facilitate knowledge transfer between two paradigms,and then leverage contrastive learning to train the selector. Experimentalresults on the text-to-code and code-to-code generation tasks demonstrate theeffectiveness of our proposed model. We release our code athttps://github.com/DeepLearnXMU/UniGenCoder.</description>
      <author>example@mail.com (Liangying Shao, Yanfu Yan, Denys Poshyvanyk, Jinsong Su)</author>
      <guid isPermaLink="false">2502.12490v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>DivIL: Unveiling and Addressing Over-Invariance for Out-of- Distribution Generalization</title>
      <link>http://arxiv.org/abs/2502.12413v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文研究了机器学习模型在面对不同于训练数据分布的新环境时的表现问题，提出了一种新的方法来解决过度不变性导致的性能下降。&lt;h4&gt;背景&lt;/h4&gt;跨不同分布进行泛化的挑战。一种常见的策略是不变学习（IL），它试图使模型关注于不变特征而不是虚假相关特性。&lt;h4&gt;目的&lt;/h4&gt;减轻不变约束过强带来的不利影响，并探索如何通过添加额外机制来补偿这些限制，从而提高模型的泛化性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架Diverse Invariant Learning (DivIL)，结合了无监督对比学习和随机掩码机制来对抗过度不变性的问题。该方法适用于多种不变学习策略。&lt;h4&gt;主要发现&lt;/h4&gt;在理论层面定义了过度不变性的概念，并观察到这种问题出现在不同的经典不变学习方法中。实验结果表明，DivIL框架有效减轻了过度不变性的影响。&lt;h4&gt;结论&lt;/h4&gt;通过引入无监督对比学习和随机掩码机制来补偿过强的不变约束，可以提高模型的泛化能力，特别是在多样化的环境和多模态数据集上表现更佳。&lt;h4&gt;翻译&lt;/h4&gt;跨分布泛化是一个常见问题，期望模型在训练数据之外的不同分布中也能表现出色。一种流行的解决方法是不变学习（IL），通过在训练过程中添加强约束使模型专注于不变特征而非虚假相关特性。然而，这种方法可能存在过度不变性的问题，即由于有限的多样化环境和特征空间中的过正则化导致重要细节丢失。本文定义了过度不变性的概念，并观察到这种问题存在于各种经典IL方法中。为解决此问题，提出了一种简单的方法Diverse Invariant Learning (DivIL)，通过添加无监督对比学习和随机掩码机制来补偿强约束。该方法适用于多种IL方法。实验在多个模式的12个数据集和6种经典模型上进行，验证了过度不变性的见解以及DivIL框架的有效性。代码位于https://github.com/kokolerk/DivIL。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution generalization is a common problem that expects the modelto perform well in the different distributions even far from the train data. Apopular approach to addressing this issue is invariant learning (IL), in whichthe model is compiled to focus on invariant features instead of spuriousfeatures by adding strong constraints during training. However, there are somepotential pitfalls of strong invariant constraints. Due to the limited numberof diverse environments and over-regularization in the feature space, it maylead to a loss of important details in the invariant features while alleviatingthe spurious correlations, namely the over-invariance, which can also degradethe generalization performance. We theoretically define the over-invariance andobserve that this issue occurs in various classic IL methods. To alleviate thisissue, we propose a simple approach Diverse Invariant Learning (DivIL) byadding the unsupervised contrastive learning and the random masking mechanismcompensatory for the invariant constraints, which can be applied to various ILmethods. Furthermore, we conduct experiments across multiple modalities across12 datasets and 6 classic models, verifying our over-invariance insight and theeffectiveness of our DivIL framework. Our code is available athttps://github.com/kokolerk/DivIL.</description>
      <author>example@mail.com (Jiaqi Wang, Yuhang Zhou, Zhixiong Zhang, Qiguang Chen, Yongqiang Chen, James Cheng)</author>
      <guid isPermaLink="false">2502.12413v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>NoKSR: Kernel-Free Neural Surface Reconstruction via Point Cloud Serialization</title>
      <link>http://arxiv.org/abs/2502.12534v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: see /https://theialab.github.io/noksr&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的大规模点云表面重构的方法，通过开发一个高效的框架将不规则的点云转换为符号距离场（SDF）。&lt;h4&gt;背景&lt;/h4&gt;现有的大规模点云处理方法存在效率和准确性之间的权衡问题，特别是在稀疏网格方法在室外数据集上的表现有限的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于Transformer架构的方法来提高点云表面重构的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;{'框架基础': '该研究建立于最近的Transformer架构（PointTransformerV3）之上，将点云序列化为一个保持局部性的令牌序列。', 'SDF预测': '通过聚合附近令牌来高效地预测某一点上的SDF值，并且可以快速检索近似邻居以提高效率。', '多尺度处理': '在不同的层次/尺度上序列化点云，非线性聚合特征以预测SDF值。跨多个尺度的聚集对于克服由序列化引入的假阴性问题至关重要。', '框架特点': '该方法不仅性能优异（与现有最佳方法相比，在延迟减少一半的情况下保持了相似或更好的性能），而且实现更为简单。'}&lt;h4&gt;主要发现&lt;/h4&gt;跨多尺度处理是提高SDF预测准确性的重要因素，特别是在稀疏点云数据中。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架在精度和效率方面均优于现有方法，并且特别适用于室外场景的处理。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容为中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel approach to large-scale point cloud surface reconstructionby developing an efficient framework that converts an irregular point cloudinto a signed distance field (SDF). Our backbone builds upon recenttransformer-based architectures (i.e., PointTransformerV3), that serializes thepoint cloud into a locality-preserving sequence of tokens. We efficientlypredict the SDF value at a point by aggregating nearby tokens, where fastapproximate neighbors can be retrieved thanks to the serialization. Weserialize the point cloud at different levels/scales, and non-linearlyaggregate a feature to predict the SDF value. We show that aggregating acrossmultiple scales is critical to overcome the approximations introduced by theserialization (i.e. false negatives in the neighborhood). Our frameworks setsthe new state-of-the-art in terms of accuracy and efficiency (better or similarperformance with half the latency of the best prior method, coupled with asimpler implementation), particularly on outdoor datasets where sparse-gridmethods have shown limited performance.</description>
      <author>example@mail.com (Zhen Li, Weiwei Sun, Shrisudhan Govindarajan, Shaobo Xia, Daniel Rebain, Kwang Moo Yi, Andrea Tagliasacchi)</author>
      <guid isPermaLink="false">2502.12534v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Time-series attribution maps with regularized contrastive learning</title>
      <link>http://arxiv.org/abs/2502.12977v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at The 28th International Conference on Artificial  Intelligence and Statistics (AISTATS 2025). Code is available at  https://github.com/AdaptiveMotorControlLab/CEBRA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的时间序列数据可识别的归因图生成算法和方法（xCEBRA），通过对比学习和逆神经元梯度法，理论上证明其能更准确地标识生成过程中的雅克比矩阵，并在合成数据集上展示出对真实属性映射零与非零项的良好拟合。&lt;h4&gt;背景&lt;/h4&gt;现有的基于梯度的归因方法用于解释深度学习模型的决策但缺乏可识别性保证。当前，时间序列数据的归因图生成仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的对比学习算法以及逆神经元梯度法（Inverted Neuron Gradient），以生成具有理论保障的时间序列属性映射。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结合正则化对比学习和新提出的逆神经元梯度法的框架，旨在生成可识别的归因图，并验证其在合成数据集上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;理论上证明了xCEBRA能有效标识时间序列数据中雅克比矩阵的零与非零项；实证上显示，在各种基于特征删除、Shapley值以及其他梯度方法前，展示了显著改进。&lt;h4&gt;结论&lt;/h4&gt;这项工作为可识别的时间序列归因图推断提供了首个实例，并为神经动态学和决策过程的理解开辟了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gradient-based attribution methods aim to explain decisions of deep learningmodels but so far lack identifiability guarantees. Here, we propose a method togenerate attribution maps with identifiability guarantees by developing aregularized contrastive learning algorithm trained on time-series data plus anew attribution method called Inverted Neuron Gradient (collectively namedxCEBRA). We show theoretically that xCEBRA has favorable properties foridentifying the Jacobian matrix of the data generating process. Empirically, wedemonstrate robust approximation of zero vs. non-zero entries in theground-truth attribution map on synthetic datasets, and significantimprovements across previous attribution methods based on feature ablation,Shapley values, and other gradient-based methods. Our work constitutes a firstexample of identifiable inference of time-series attribution maps and opensavenues to a better understanding of time-series data, such as for neuraldynamics and decision-processes within neural networks.</description>
      <author>example@mail.com (Steffen Schneider, Rodrigo González Laiz, Anastasiia Filippova, Markus Frey, Mackenzie Weygandt Mathis)</author>
      <guid isPermaLink="false">2502.12977v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Healthcare cost prediction for heterogeneous patient profiles using deep learning models with administrative claims data</title>
      <link>http://arxiv.org/abs/2502.12277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于深度学习的框架，用于设计患者成本预测模型，以有效解决管理性索赔数据中的异质性和复杂性问题。&lt;h4&gt;背景&lt;/h4&gt;准确且公平的患者成本预测对于制定健康管理制度和优化资源配置至关重要，这有助于在医疗支付方（包括政府机构和私人保险公司）中实现显著的成本节约。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够应对行政索赔数据中异质性的方法，并特别关注具有复杂慢性病的高需求患者的准确、公正及可推广的预测模型。&lt;h4&gt;方法&lt;/h4&gt;该研究基于社会技术考量，强调技术系统（如深度学习模型）与人文主义结果（例如医疗决策中的公平性）之间的相互作用。它采用表示学习和熵度量来处理数据异质性和复杂性，特别是对于高需求患者。提出了一种通道化深度学习框架，通过根据类型对管理索赔数据进行细分来缓解数据异质性。&lt;h4&gt;主要发现&lt;/h4&gt;与单通道模型相比，所提出的通道化模型将预测误差降低了23%，分别导致过度支付和不足支付减少16.4%和19.3%。对于高需求患者的预测偏差降低尤为显著，这表明该框架在处理数据和患者档案的异质性和复杂性方面有效。&lt;h4&gt;结论&lt;/h4&gt;这种通道化建模方法具有应用于类似异质性挑战领域的潜力。&lt;h4&gt;翻译&lt;/h4&gt;问题是如何设计能有效解决管理索赔（AC）数据异质性的患者成本预测模型，以确保准确、公平且可推广的预测，尤其是针对高需求（HN）患者的复杂慢性病。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Problem: How can we design patient cost prediction models that effectivelyaddress the challenges of heterogeneity in administrative claims (AC) data toensure accurate, fair, and generalizable predictions, especially for high-need(HN) patients with complex chronic conditions?  Relevance: Accurate and equitable patient cost predictions are vital fordeveloping health management policies and optimizing resource allocation, whichcan lead to significant cost savings for healthcare payers, includinggovernment agencies and private insurers. Addressing disparities in predictionoutcomes for HN patients ensures better economic and clinical decision-making,benefiting both patients and payers.  Methodology: This study is grounded in socio-technical considerations thatemphasize the interplay between technical systems (e.g., deep learning models)and humanistic outcomes (e.g., fairness in healthcare decisions). Itincorporates representation learning and entropy measurement to addressheterogeneity and complexity in data and patient profiles, particularly for HNpatients. We propose a channel-wise deep learning framework that mitigates dataheterogeneity by segmenting AC data into separate channels based on types ofcodes (e.g., diagnosis, procedures) and costs. This approach is paired with aflexible evaluation design that uses multi-channel entropy measurement toassess patient heterogeneity.  Results: The proposed channel-wise models reduce prediction errors by 23%compared to single-channel models, leading to 16.4% and 19.3% reductions inoverpayments and underpayments, respectively. Notably, the reduction inprediction bias is significantly higher for HN patients, demonstratingeffectiveness in handling heterogeneity and complexity in data and patientprofiles. This demonstrates the potential for applying channel-wise modeling todomains with similar heterogeneity challenges.</description>
      <author>example@mail.com (Mohammad Amin Morid, Olivia R. Liu Sheng)</author>
      <guid isPermaLink="false">2502.12277v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards Transparent and Accurate Plasma State Monitoring at JET</title>
      <link>http://arxiv.org/abs/2502.12182v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种透明且数据驱动的方法来监测托卡马克装置中的等离子体状态，该方法结合了监督学习和非监督学习技术，并通过多任务学习首次应用于等离子体状态监控。&lt;h4&gt;背景&lt;/h4&gt;控制和监控托卡马克设备中的等离子体是复杂而具有挑战性的。异常的等离子体事件（如中断）阻碍了稳定运行，并可能威胁大型装置的安全，这在未来的发电厂应用中是一个主要担忧。&lt;h4&gt;目的&lt;/h4&gt;提供一种可解释的等离子体状态表示方法来展示JET的操作空间，通过多任务学习首次应用于等离子体状态监控。&lt;h4&gt;方法&lt;/h4&gt;采用了一种结合监督和非监督机器学习技术的数据驱动方法。研究基于520个专家验证过的JET放电数据集进行。&lt;h4&gt;主要发现&lt;/h4&gt;序列基模型在预测中断方面显示出显著改进，特别是在结合物理指标并考虑邻近不稳定性的条件下取得了令人满意的交叉验证成功率。同时揭示了操作区域和破坏性区域以及学习的动力学模式的关联。&lt;h4&gt;结论&lt;/h4&gt;该方法为定义触发机制以切换不同的控制场景、数据分析和学习提供了新的可能性，并展示了在预测时间警告方面具有潜在的应用价值，且结果与已知物理机制相一致。&lt;h4&gt;翻译&lt;/h4&gt;控制和监测托卡马克装置中的等离子体是复杂而具有挑战性的。异常的等离子体事件（如中断）阻碍了稳定运行，并可能威胁大型装置的安全性，这在未来的发电厂应用中是一个主要担忧。为了更好地理解这些现象及其演变过程，有效监控等离子体状态至关重要。本文介绍了首次将多任务学习应用于JET操作空间的研究方法，结合监督和非监督机器学习技术来监测等离子体状态。序列基模型显示了预测中断方面的显著改进，并揭示了操作区域和破坏性模式的关联。此外，该研究展示了在定义触发机制、数据分析和探索潜在动力学方面的新可能性以及预警时间的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controlling and monitoring plasma within a tokamak device is complex andchallenging. Plasma off-normal events, such as disruptions, are hinderingsteady-state operation. For large devices, they can even endanger the machine'sintegrity and it represents in general one of the most serious concerns for theexploitation of the tokamak concept for future power plants. Effective plasmastate monitoring carries the potential to enable an understanding of suchphenomena and their evolution which is crucial for the successful operation oftokamaks. This paper presents the application of a transparent and data-drivenmethodology to monitor the plasma state in a tokamak. Compared to previousstudies in the field, supervised and unsupervised learning techniques arecombined. The dataset consisted of 520 expert-validated discharges from JET.The goal was to provide an interpretable plasma state representation for theJET operational space by leveraging multi-task learning for the first time inthe context of plasma state monitoring. When evaluated as disruptionpredictors, a sequence-based approach showed significant improvements comparedto the state-based models. The best resulting network achieved a promisingcross-validated success rate when combined with a physical indicator andaccounting for nearby instabilities. Qualitative evaluations of the learnedlatent space uncovered operational and disruptive regions as well as patternsrelated to learned dynamics and global feature importance. The appliedmethodology provides novel possibilities for the definition of triggers toswitch between different control scenarios, data analysis, and learning as wellas exploring latent dynamics for plasma state monitoring. It also showedpromising quantitative and qualitative results with warning times suitable foravoidance purposes and distributions that are consistent with known physicalmechanisms.</description>
      <author>example@mail.com (Andrin Bürli, Alessandro Pau, Thomas Koller, Olivier Sauter, JET Contributors)</author>
      <guid isPermaLink="false">2502.12182v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Keep what you need : extracting efficient subnetworks from large audio representation models</title>
      <link>http://arxiv.org/abs/2502.12925v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了从大型基础模型中提取轻量级专业子网络的方法，通过引入可学习的二进制掩码和稀疏性诱导损失来实现。这种方法在保持原始权重不变的情况下训练得到一个专注于单一任务的小型化模型。&lt;h4&gt;背景&lt;/h4&gt;近年来音频基础模型的研究取得了显著进展，在复杂下游任务上不断取得改进结果。然而，这些模型的大小和复杂度大幅增加，导致无法部署到消费级设备或用于实时应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单有效的方法来解决大型音频基础模型在小型化和专门化方面的挑战。&lt;h4&gt;方法&lt;/h4&gt;通过在网络层之间添加可学习的二进制掩码，并引入稀疏性损失函数，在下游任务上训练端到端模型，从而学到一个专精于单一任务的小型子网络。保持原始模型权重不变，降低额外训练成本。&lt;h4&gt;主要发现&lt;/h4&gt;评估了该方法在三种广泛使用的音频基础模型上的效果，表明这种方法能够显著提高性能，并且适用于语音、音乐和通用音频等多种场景。&lt;h4&gt;结论&lt;/h4&gt;提出的方法为解决大型音频基础模型的小型化问题提供了一种有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, research on audio foundation models has witnessed notable advances,as illustrated by the ever improving results on complex downstream tasks.Subsequently, those pretrained networks have quickly been used for variousaudio applications. These improvements have however resulted in a considerableincrease both in size and complexity of these models. Along the environmentalconcerns this issue raises, this prevents the deployment of such networks onconsumer-level devices, and precludes their use for real-time applications.Moreover, this appears contradictory with the specificity of the tasks forwhich these models are used, which are often simpler compared to extracting arich, multi-purpose representation from any type of audio data. In this paper,we address this issue with a simple, yet effective method to extractlightweight specialist subnetworks from large foundation models. Specifically,we introduce learnable binary masks in-between the layers of a pretrainedrepresentation model. When training the end-to-end model on a downstream task,we add a sparsity-inducing loss to the overall objective, hence learning acompact subnetwork specialized on a single task. Importantly, the weights ofthe foundation model are kept frozen, resulting into low additional trainingcosts. Once trained, the masked computational units can then be removed fromthe network, implying significant performance gains. We assess our method onthree widespread audio foundation models, each based on a different backbonearchitecture, and illustrate its effectiveness on common audio representationevaluation tasks, as well as its versatility on both speech, music, and generalaudio. Code for reproducing the results and supporting webpage are available athttps://github.com/gnvIRCAM/Audio-representation-trimming</description>
      <author>example@mail.com (David Genova, Philippe Esling, Tom Hurlin)</author>
      <guid isPermaLink="false">2502.12925v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling Mode Connectivity in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.12608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了图神经网络（GNNs）中的模式连接性，揭示了其独特的非线性特性，并与图结构的性质建立了联系。&lt;h4&gt;背景&lt;/h4&gt;理解GNN优化动态和损失景观几何对于提高模型可解释性和鲁棒性至关重要。虽然模式连接性已用于分析其他深度学习架构的几何属性，但其在GNN中的应用尚属空白。&lt;h4&gt;目的&lt;/h4&gt;首次探索GNNs中的模式连接性，并研究它对理论理解和实际应用的意义。&lt;h4&gt;方法&lt;/h4&gt;通过实验揭示了不同图结构和模型架构下的非线性模式连接特性。建立了模式连接与泛化的联系，提出了基于损失障碍的泛化界。&lt;h4&gt;主要发现&lt;/h4&gt;1. GNNs展示出不同于全连接网络或CNN的独特非线性模式连接。2. 图结构（如同质性）而非模型架构主导了这种行为。3. 模式连接与泛化能力之间存在联系，有助于作为诊断工具。&lt;h4&gt;结论&lt;/h4&gt;研究结果不仅为GNN理论提供了新的见解，还指出了在图学习领域中进行领域对齐策略和改进训练范式的方向。&lt;h4&gt;翻译&lt;/h4&gt;理解图神经网络（GNNs）的核心挑战在于表征其优化动态和损失景观几何，这对于提高可解释性和鲁棒性至关重要。虽然模式连接已经为其他深度学习架构提供了有价值的视角来分析损失景观的几何性质，但对于GNN的影响仍然未被探索。这项工作首次对GNN中的模式连接进行了调查，并揭示了与全连接网络或CNN所观察到的不同非线性模式连接特性。更重要的是，研究结果表明图结构而非模型架构决定了这种行为，其中同质性等图属性会关联于模式连接的模式。此外，该研究建立了模式连接和泛化之间的联系，并提出了基于损失障碍的泛化界，揭示了其作为诊断工具的作用。我们的发现将理论洞察与实际应用相结合：它们为图学习中的领域对齐策略提供了理据，并为改进GNN训练范式奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A fundamental challenge in understanding graph neural networks (GNNs) lies incharacterizing their optimization dynamics and loss landscape geometry,critical for improving interpretability and robustness. While modeconnectivity, a lens for analyzing geometric properties of loss landscapes hasproven insightful for other deep learning architectures, its implications forGNNs remain unexplored. This work presents the first investigation of modeconnectivity in GNNs. We uncover that GNNs exhibit distinct non-linear modeconnectivity, diverging from patterns observed in fully-connected networks orCNNs. Crucially, we demonstrate that graph structure, rather than modelarchitecture, dominates this behavior, with graph properties like homophilycorrelating with mode connectivity patterns. We further establish a linkbetween mode connectivity and generalization, proposing a generalization boundbased on loss barriers and revealing its utility as a diagnostic tool. Ourfindings further bridge theoretical insights with practical implications: theyrationalize domain alignment strategies in graph learning and provide afoundation for refining GNN training paradigms.</description>
      <author>example@mail.com (Bingheng Li, Zhikai Chen, Haoyu Han, Shenglai Zeng, Jingzhe Liu, Jiliang Tang)</author>
      <guid isPermaLink="false">2502.12608v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Robust Disentangled Counterfactual Learning for Physical Audiovisual Commonsense Reasoning</title>
      <link>http://arxiv.org/abs/2502.12425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的鲁棒且分解化的反事实学习(RDCL)方法，用于物理视听常识推理。该方法旨在通过视频和音频输入来推断物体的物理常识，并针对缺失模态的情况模仿人类的推理能力。&lt;h4&gt;背景&lt;/h4&gt;当前大多数方法未能充分利用多模态数据的不同特征，而且模型缺乏因果推理能力，阻碍了隐含物理知识推理的进步。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够解耦视频中的静态和动态因素的方法，并引入反事实学习模块以增强模型的推理能力。&lt;h4&gt;方法&lt;/h4&gt;通过变分自编码器（VAE）结合对比损失函数在潜在空间中将视频分解为静态和动态因子；引入一个反事实学习模块来建模不同物体之间的物理知识关系；提出一种鲁棒多模态学习方法，通过解耦共享特征和特定于模型的特征以恢复缺失数据。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的RDCL方法不仅提高了基线方法的推理准确性和鲁棒性，还取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了在物理视听常识推理任务中应用反事实学习模块的有效性，并展示了其在处理多模态输入时增强模型因果推理能力的能力。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种新的稳健分解式反事实学习（RDCL）方法，用于物理视听常识推理。该任务旨在基于视频和音频输入推断物体的物理常识，主要挑战是如何在缺少模态的情况下模仿人类的推理能力。目前大多数的方法未能充分利用多模态数据的不同特征，并且模型缺乏因果推理能力阻碍了隐含物理知识推理的进步。为了解决这些问题，我们提出的RDCL方法通过分解式序列编码器将视频在潜在空间中解耦为静态（时间不变）和动态（时间变化）因子，该编码器采用变分自编码器（VAE），通过对比损失函数最大化互信息。此外，我们引入了一个反事实学习模块以增强模型的推理能力，通过模拟不同物体之间的物理知识关系在假设干预的情况下进行建模。为了缓解缺失模态数据的问题，我们提出了一种鲁棒多模态学习方法，通过解耦共享特征和特定于模型的特征来恢复缺失的数据。所提出的RDCL是一个即插即用模块，可以被集成到任何基线中包括视觉语言模型（VLM）。在实验中，我们展示了我们的方法提高了基线方法的推理准确性和鲁棒性，并且达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a new Robust Disentangled Counterfactual Learning(RDCL) approach for physical audiovisual commonsense reasoning. The task aimsto infer objects' physics commonsense based on both video and audio input, withthe main challenge being how to imitate the reasoning ability of humans, evenunder the scenario of missing modalities. Most of the current methods fail totake full advantage of different characteristics in multi-modal data, andlacking causal reasoning ability in models impedes the progress of implicitphysical knowledge inferring. To address these issues, our proposed RDCL methoddecouples videos into static (time-invariant) and dynamic (time-varying)factors in the latent space by the disentangled sequential encoder, whichadopts a variational autoencoder (VAE) to maximize the mutual information witha contrastive loss function. Furthermore, we introduce a counterfactuallearning module to augment the model's reasoning ability by modeling physicalknowledge relationships among different objects under counterfactualintervention. To alleviate the incomplete modality data issue, we introduce arobust multimodal learning method to recover the missing data by decomposingthe shared features and model-specific features. Our proposed method is aplug-and-play module that can be incorporated into any baseline including VLMs.In experiments, we show that our proposed method improves the reasoningaccuracy and robustness of baseline methods and achieves the state-of-the-artperformance.</description>
      <author>example@mail.com (Mengshi Qi, Changsheng Lv, Huadong Ma)</author>
      <guid isPermaLink="false">2502.12425v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Lightweight Online Adaption for Time Series Foundation Model Forecasts</title>
      <link>http://arxiv.org/abs/2502.12920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AdapTS是一种轻量级机制，旨在通过利用在线反馈来增强基础模型（FMs）在时间序列预测中的性能。&lt;h4&gt;背景&lt;/h4&gt;随着计算成本高昂，基础模型通常在部署时保持固定不变，无法根据当前数据特征调整其预测。&lt;h4&gt;目的&lt;/h4&gt;探讨如何通过有效使用在线反馈来提高基础模型的性能。&lt;h4&gt;方法&lt;/h4&gt;AdapTS由两部分组成：1）AdapTS-Forecaster用于学习当前数据分布；2）AdapTS-Weighter用于结合基础模型和AdapTS-Forecaster的预测结果。&lt;h4&gt;主要发现&lt;/h4&gt;在使用多种最近的基础模型以及一系列标准时间序列数据集进行评估后，发现在所有实验中使用AdapTS都能提高性能。&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了如何通过高效利用在线反馈来改进基础模型的时间序列预测能力。&lt;h4&gt;翻译&lt;/h4&gt;基础模型（FMs）作为时间序列预测的一种有前途的方法已经出现。虽然有效，但由于在线学习时的高计算成本，这些模型在部署后通常保持固定不变。因此，尽管有新数据到达时提供的在线反馈可用性，已部署的基础模型仍无法根据当前数据特征调整其预测。这引发了关于基础模型性能是否可以通过有效地使用这种反馈来提升的问题。我们提出了AdapTS来解答这个问题。AdapTS是一种轻量级机制，旨在让基础模型的预测能够响应在线反馈而进行在线适应。该系统包含两部分：a）AdapTS-Forecaster用于学习当前数据分布；b）AdapTS-Weighter用于结合基础模型和AdapTS-Forecaster的预测结果。我们评估了在多种最近的基础模型与一系列标准时间序列数据集相结合时，使用AdapTS的效果。实验结果显示，在所有情况下使用AdapTS都能提高性能。这项工作展示了如何通过有效利用在线反馈来改进基础模型的时间序列预测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) have emerged as a promising approach for time seriesforecasting. While effective, FMs typically remain fixed during deployment dueto the high computational costs of learning them online. Consequently, deployedFMs fail to adapt their forecasts to current data characteristics, despite theavailability of online feedback from newly arriving data. This raises thequestion of whether FM performance can be enhanced by the efficient usage ofthis feedback. We propose AdapTS to answer this question.  AdapTS is a lightweight mechanism for the online adaption of FM forecasts inresponse to online feedback. AdapTS consists of two parts: a) theAdapTS-Forecaster which is used to learn the current data distribution; and b)the AdapTS-Weighter which is used to combine the forecasts of the FM and theAdapTS-Forecaster. We evaluate the performance of AdapTS in conjunction withseveral recent FMs across a suite of standard time series datasets. In all ofour experiments we find that using AdapTS improves performance. This workdemonstrates how efficient usage of online feedback can be used to improve FMforecasts.</description>
      <author>example@mail.com (Thomas L. Lee, William Toner, Rajkarn Singh, Artjom Joosem, Martin Asenov)</author>
      <guid isPermaLink="false">2502.12920v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Portable Reward Tuning: Towards Reusable Fine-Tuning across Different Pretrained Models</title>
      <link>http://arxiv.org/abs/2502.12776v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的微调原则，即可移植奖励微调（PRT），它通过将其视为奖励最大化来减少推理开销。&lt;h4&gt;背景&lt;/h4&gt;基础模型会因为知识过时或能力有限而变得过时，需要被更新的基础模型替换，这会导致反复对新模型进行微调的额外成本。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够降低推理时间调整开销的新方法——可移植奖励微调（PRT）。&lt;h4&gt;方法&lt;/h4&gt;基于将微调重新定义为最大化奖励的方法，PRT通过相同的损失函数显式地训练奖励模型。在推理阶段，可以使用该奖励模型与任何基础模型一起工作。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在视觉和语言模型中，经过PRT训练的模型能够达到与其他方法（例如推理时间调整）相当的效果，但具有更低的推理成本。&lt;h4&gt;结论&lt;/h4&gt;可移植奖励微调是一种有效的技术，能够在减少计算开销的同时保持模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While foundation models have been exploited for various expert tasks throughfine-tuning, any foundation model will become outdated due to its old knowledgeor limited capability. Thus the underlying foundation model should beeventually replaced by new ones, which leads to repeated cost of fine-tuningthese new models. Existing work addresses this problem by inference-timetuning, i.e., modifying the output probabilities from the new foundation modelwith the outputs from the old foundation model and its fine-tuned model, whichinvolves an additional overhead in inference by the latter two models. In thispaper, we propose a new fine-tuning principle, Portable Reward Tuning (PRT),that reduces the inference overhead by its nature, based on the reformulationof fine-tuning as the reward maximization. Specifically, instead of fine-tuningparameters of the foundation models, PRT trains the reward model explicitlythrough the same loss function as in fine-tuning. During inference, the rewardmodel can be used with any foundation model (with the same set of vocabulariesor labels) through the formulation of reward maximization. Experimentalresults, covering both vision and language models, demonstrate that thePRT-trained model can achieve comparable accuracy to the existing work ofinference-time tuning, with less inference cost.</description>
      <author>example@mail.com (Daiki Chijiwa, Taku Hasegawa, Kyosuke Nishida, Kuniko Saito, Susumu Takeuchi)</author>
      <guid isPermaLink="false">2502.12776v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Not-So-Optimal Transport Flows for 3D Point Cloud Generation</title>
      <link>http://arxiv.org/abs/2502.12456v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成3D点云的模型是三维生成学习中的一个基本问题。点云的一个关键特性是它们对置换不变性，即改变点云中点的顺序不会改变其所代表的形状。&lt;h4&gt;目的&lt;/h4&gt;分析最近提出的等变OT流，这类方法旨在为基于分子数据的学习置换不变性的生成模型，并指出这些模型在大规模点云上的扩展性较差。同时解决学习（等变）OT流的一般挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种不太优化的运输流量模型，通过离线预计算近似OT，使能够在训练中更高效地构建OT对。此外，在训练过程中可以通过结合我们的近似OT和独立耦合来构造混合耦合，从而使目标流模型更容易学习。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛的实证研究中显示，所提出的模型在ShapeNet基准测试的无条件生成和形状完成上优于先前的扩散方法和基于流的方法。&lt;h4&gt;结论&lt;/h4&gt;新的不那么优化运输流量模型能够有效解决大规模点云问题，并且在各种任务上的性能表现更优。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning generative models of 3D point clouds is one of the fundamentalproblems in 3D generative learning. One of the key properties of point cloudsis their permutation invariance, i.e., changing the order of points in a pointcloud does not change the shape they represent. In this paper, we analyze therecently proposed equivariant OT flows that learn permutation invariantgenerative models for point-based molecular data and we show that these modelsscale poorly on large point clouds. Also, we observe learning (equivariant) OTflows is generally challenging since straightening flow trajectories makes thelearned flow model complex at the beginning of the trajectory. To remedy these,we propose not-so-optimal transport flow models that obtain an approximate OTby an offline OT precomputation, enabling an efficient construction of OT pairsfor training. During training, we can additionally construct a hybrid couplingby combining our approximate OT and independent coupling to make the targetflow models easier to learn. In an extensive empirical study, we show that ourproposed model outperforms prior diffusion- and flow-based approaches on a widerange of unconditional generation and shape completion on the ShapeNetbenchmark.</description>
      <author>example@mail.com (Ka-Hei Hui, Chao Liu, Xiaohui Zeng, Chi-Wing Fu, Arash Vahdat)</author>
      <guid isPermaLink="false">2502.12456v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>GeneralizeFormer: Layer-Adaptive Model Generation across Test-Time Distribution Shifts</title>
      <link>http://arxiv.org/abs/2502.12195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种在测试时实现领域泛化的轻量级元学习Transformer模型GeneralizeFormer，该模型通过生成多层参数来适应未知的目标域分布。&lt;h4&gt;背景&lt;/h4&gt;传统的领域泛化方法通常使用微调或在线调整分类器参数的方法，在新的目标域上进行适应。然而这些方法往往在处理多个目标分布时效果不佳，并且可能遗忘源领域的特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的方法，能够在测试阶段动态生成多层参数，以更好地适应领域泛化问题中不同和多变的目标分布。&lt;h4&gt;方法&lt;/h4&gt;利用一个轻量级的元学习Transformer，在推理过程中为每个目标批次实时生成多个层的参数。通过这种方式，模型能够避免微调或在线调整，并且能够在各种分布偏移下进行自我调节。为了减少计算成本，固定了卷积参数的同时只生成Batch Normalization层和线性分类器的参数。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在处理多种领域泛化数据集上展示了优越的表现能力，在动态场景中实现泛化，并且避免遗忘源域中的有价值特征。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，GeneralizeFormer模型能够有效地解决各种分布偏移问题，并在测试时通过实时生成参数的方式提升了对未知目标领域的适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of test-time domain generalization, where a model istrained on several source domains and adjusted on target domains never seenduring training. Different from the common methods that fine-tune the model oradjust the classifier parameters online, we propose to generate multiple layerparameters on the fly during inference by a lightweight meta-learnedtransformer, which we call \textit{GeneralizeFormer}. The layer-wise parametersare generated per target batch without fine-tuning or online adjustment. Bydoing so, our method is more effective in dynamic scenarios with multipletarget distributions and also avoids forgetting valuable source distributioncharacteristics. Moreover, by considering layer-wise gradients, the proposedmethod adapts itself to various distribution shifts. To reduce thecomputational and time cost, we fix the convolutional parameters while onlygenerating parameters of the Batch Normalization layers and the linearclassifier. Experiments on six widely used domain generalization datasetsdemonstrate the benefits and abilities of the proposed method to efficientlyhandle various distribution shifts, generalize in dynamic scenarios, and avoidforgetting.</description>
      <author>example@mail.com (Sameer Ambekar, Zehao Xiao, Xiantong Zhen, Cees G. M. Snoek)</author>
      <guid isPermaLink="false">2502.12195v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>BalanceBenchmark: A Survey for Imbalanced Learning</title>
      <link>http://arxiv.org/abs/2502.10816v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文系统地分类了主流的多模态不平衡算法，并提出了BalanceBenchmark基准测试，以全面评估这些方法。&lt;h4&gt;背景&lt;/h4&gt;多模态学习因能整合不同模态的信息而受到关注，但常受制于模态失衡问题，即某一模态主导其他模态被忽略。尽管已有研究提出多种解决该问题的方法，但仍缺乏全面公平的比较。&lt;h4&gt;目的&lt;/h4&gt;系统地分类主流的多模态不平衡算法，并通过BalanceBenchmark基准测试来评估这些方法的效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一个包括多个常用数据集和评价指标的BalanceBenchmark，从性能、失衡程度和复杂性三个视角进行综合评估。为确保公平比较，开发了一个模块化且可扩展的工具包，标准化了不同方法之间的实验流程。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用BalanceBenchmark的实验结果，发现了不同类型方法在性能、平衡度以及计算复杂性方面的特点和优势。&lt;h4&gt;结论&lt;/h4&gt;期望这样的分析能激发未来更有效的方法来解决多模态失衡问题，并有助于基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;多模态学习因其集成不同模态信息的能力而受到关注。然而，它常常受限于模态不平衡的问题，即某些模态主导而其他模态未被充分利用。尽管近期有研究提出多种方法以减轻这一问题，但缺乏全面且公平的比较。本文系统地将各种主流多模态不平衡算法根据其减少失衡的策略分类为四组，并介绍了BalanceBenchmark基准测试，其中包括多个常用的多维数据集和从性能、失衡程度及复杂性三个角度评估的方法。为了确保公平对比，我们开发了一个模块化且可扩展的工具包，该工具包标准化了不同方法之间的实验流程。基于使用BalanceBenchmark的实验结果，我们在性能、平衡度以及计算复杂性方面发现了不同类型方法的特点和优势。我们期望这样的分析能够启发未来更有效的方法来解决多模态不平衡问题，并为基础模型提供帮助。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning has gained attention for its capacity to integrateinformation from different modalities. However, it is often hindered by themultimodal imbalance problem, where certain modality dominates while othersremain underutilized. Although recent studies have proposed various methods toalleviate this problem, they lack comprehensive and fair comparisons. In thispaper, we systematically categorize various mainstream multimodal imbalancealgorithms into four groups based on the strategies they employ to mitigateimbalance. To facilitate a comprehensive evaluation of these methods, weintroduce BalanceBenchmark, a benchmark including multiple widely usedmultidimensional datasets and evaluation metrics from three perspectives:performance, imbalance degree, and complexity. To ensure fair comparisons, wehave developed a modular and extensible toolkit that standardizes theexperimental workflow across different methods. Based on the experiments usingBalanceBenchmark, we have identified several key insights into thecharacteristics and advantages of different method groups in terms ofperformance, balance degree and computational complexity. We expect suchanalysis could inspire more efficient approaches to address the imbalanceproblem in the future, as well as foundation models. The code of the toolkit isavailable at https://github.com/GeWu-Lab/BalanceBenchmark.</description>
      <author>example@mail.com (Shaoxuan Xu, Menglu Cui, Chengxiang Huang, Hongfa Wang, DiHu)</author>
      <guid isPermaLink="false">2502.10816v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards Fusing Point Cloud and Visual Representations for Imitation Learning</title>
      <link>http://arxiv.org/abs/2502.12320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的模仿学习方法，该方法结合了点云和RGB图像的优点，在机器人操作任务中展示了优于现有技术的性能。&lt;h4&gt;背景&lt;/h4&gt;学习操纵通常需要使用能够访问丰富感官信息（如点云或RGB图像）的策略。点云可以有效地捕捉几何结构，对于基于模仿的学习中的操纵任务至关重要；而RGB图像提供了丰富的纹理和语义信息，在某些任务中必不可少。然而，现有的融合两种模态的方法往往会导致原始图像中的全局上下文信息丢失。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的模仿学习方法，能够有效结合点云和RGB图像的强项。&lt;h4&gt;方法&lt;/h4&gt;通过使用自适应层归一化条件对点云编码器进行调整，将全局和局部图像标记应用于点云，从而融合两种模态的优点。&lt;h4&gt;主要发现&lt;/h4&gt;在RoboCasa基准测试上的广泛实验表明，单独依赖任一单一模态存在局限性；而所提出的方法在所有任务中均达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了有效结合点云和RGB图像的必要性和优势，在复杂的机器人操作任务上显著提高了模仿学习的效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning for manipulation requires using policies that have access to richsensory information such as point clouds or RGB images. Point cloudsefficiently capture geometric structures, making them essential formanipulation tasks in imitation learning. In contrast, RGB images provide richtexture and semantic information that can be crucial for certain tasks.Existing approaches for fusing both modalities assign 2D image features topoint clouds. However, such approaches often lose global contextual informationfrom the original images. In this work, we propose a novel imitation learningmethod that effectively combines the strengths of both point cloud and RGBmodalities. Our method conditions the point-cloud encoder on global and localimage tokens using adaptive layer norm conditioning, leveraging the beneficialproperties of both modalities. Through extensive experiments on the challengingRoboCasa benchmark, we demonstrate the limitations of relying on eithermodality alone and show that our method achieves state-of-the-art performanceacross all tasks.</description>
      <author>example@mail.com (Atalay Donat, Xiaogang Jia, Xi Huang, Aleksandar Taranovic, Denis Blessing, Ge Li, Hongyi Zhou, Hanyi Zhang, Rudolf Lioutikov, Gerhard Neumann)</author>
      <guid isPermaLink="false">2502.12320v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation</title>
      <link>http://arxiv.org/abs/2502.08826v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  GitHub repository:  https://github.com/llm-lab-org/Multimodal-RAG-Survey&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文对检索增强生成(RAG)的多模态版本进行了全面分析，涵盖了数据集、评估指标、基准测试、评价方法以及在检索、融合、增广和生成方面的方法论创新。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型(LLMs)由于依赖静态训练数据而面临幻觉和知识过时的问题。RAG通过整合外部动态信息来减轻这些问题，并且最近的多模态学习进展促进了多模态RAG的发展，它结合了文本、图像、音频和视频等多种模式。&lt;h4&gt;目的&lt;/h4&gt;对多模态RAG系统进行结构化全面分析，审查训练策略，增强鲁棒性以及损失函数等，同时探索多样的多模态RAG场景，并讨论开放挑战及未来研究方向。&lt;h4&gt;方法&lt;/h4&gt;论文综述了多种数据集、评估指标和基准测试，同时也探讨了在检索、融合、增广和生成方面的创新方法论。&lt;h4&gt;主要发现&lt;/h4&gt;跨模式对齐和推理为多模态RAG引入了独特的挑战，使其区别于传统的单一模式RAG。此外还讨论了在训练策略、增强鲁棒性和损失函数等方面的具体审查。&lt;h4&gt;结论&lt;/h4&gt;论文为开发更强大且可靠的AI系统提供了基础，这些系统能够有效利用多模态动态外部知识库。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型(LLMs)因依赖静态训练数据而面临幻觉和过时知识的问题。RAG通过整合外部动态信息来解决这些问题，并提高了事实的准确性和更新性。最近在跨模式学习领域的进展已经导致了多模态RAG的发展，它结合了文本、图像、音频和视频等多种模式以增强生成输出的效果。然而，跨模式对齐和推理为多模态RAG引入了独特的挑战，使其与传统的单一模式RAG区分开来。这项综述提供了一个关于多模态RAG系统的结构化且全面的分析，涵盖了数据集、评估指标、基准测试、评价方法以及在检索、融合、增广和生成方面的创新方法论。此外还详细审查了训练策略、增强鲁棒性及损失函数等，并探讨了多元化的多模态RAG应用场景。论文最后讨论了一些开放问题及未来的研究方向，支持这一领域的发展。这项综述为开发更强大且可靠的AI系统奠定了基础，这些系统能够有效地利用多模态动态外部知识库。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/llm-lab-org/multimodal-rag-survey&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) struggle with hallucinations and outdatedknowledge due to their reliance on static training data. Retrieval-AugmentedGeneration (RAG) mitigates these issues by integrating external dynamicinformation enhancing factual and updated grounding. Recent advances inmultimodal learning have led to the development of Multimodal RAG,incorporating multiple modalities such as text, images, audio, and video toenhance the generated outputs. However, cross-modal alignment and reasoningintroduce unique challenges to Multimodal RAG, distinguishing it fromtraditional unimodal RAG. This survey offers a structured and comprehensiveanalysis of Multimodal RAG systems, covering datasets, metrics, benchmarks,evaluation, methodologies, and innovations in retrieval, fusion, augmentation,and generation. We precisely review training strategies, robustnessenhancements, and loss functions, while also exploring the diverse MultimodalRAG scenarios. Furthermore, we discuss open challenges and future researchdirections to support advancements in this evolving field. This survey lays thefoundation for developing more capable and reliable AI systems that effectivelyleverage multimodal dynamic external knowledge bases. Resources are availableat https://github.com/llm-lab-org/Multimodal-RAG-Survey.</description>
      <author>example@mail.com (Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari)</author>
      <guid isPermaLink="false">2502.08826v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>GVTNet: Graph Vision Transformer For Face Super-Resolution</title>
      <link>http://arxiv.org/abs/2502.12570v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了基于图神经网络的Transformer架构，即Graph Vision Transformer Network（GVTNet），以解决现有超分辨率算法在处理人脸图像时面部组件关系不佳的问题。&lt;h4&gt;背景&lt;/h4&gt;近年来，人脸识别增强领域利用了Transformer架构。然而，在对低分辨率图片进行超分辨率处理时，现有的算法无法很好地处理不同补丁之间的关系。&lt;h4&gt;目的&lt;/h4&gt;通过改进Transformer架构来提高低分辨率脸部图像的超分辨率质量。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络（GNN）的方法，每个小块都被视为一个图形节点，并根据这些节点间的信息建立邻接矩阵。这使得每个块只与其相邻的块进行交互，从而更好地处理面部组件的关系。&lt;h4&gt;主要发现&lt;/h4&gt;定量和可视化实验表明，与现有的最先进的技术相比，该算法在增强脸部组件方面具有更先进的超分辨率能力。&lt;h4&gt;结论&lt;/h4&gt;通过详细的比较证明了所提出的GVTNet方法在人脸图像超分辨率任务中优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;近期在面部超分辨率研究领域利用Transformer架构的进展已经出现。然而，由于面部图像是高度相关的特性，在处理低分辨率图像时现有的算法不能很好地管理不同补丁之间的关系。这导致了面部组件失真问题。为了解决这些问题，我们提出了一种基于图神经网络的Transformer架构，名为Graph Vision Transformer Network（GVTNet）。我们把每个小块视为一个图形节点，并根据这些节点间的信息建立邻接矩阵。这样可以使得每个块只与其相邻的块进行交互，进一步处理面部组件的关系。通过定量和可视化实验证明了我们的算法优于现有的最先进的技术。与现有方法进行了详细比较后展示了该算法在增强面部组件方面的先进超分辨率能力。PyTorch代码可在https://github.com/continueyang/GVTNet获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in face super-resolution research have utilized theTransformer architecture. This method processes the input image into a seriesof small patches. However, because of the strong correlation between differentfacial components in facial images. When it comes to super-resolution oflow-resolution images, existing algorithms cannot handle the relationshipsbetween patches well, resulting in distorted facial components in thesuper-resolution results. To solve the problem, we propose a transformerarchitecture based on graph neural networks called graph vision transformernetwork. We treat each patch as a graph node and establish an adjacency matrixbased on the information between patches. In this way, the patch only interactsbetween neighboring patches, further processing the relationship of facialcomponents. Quantitative and visualization experiments have underscored thesuperiority of our algorithm over state-of-the-art techniques. Through detailedcomparisons, we have demonstrated that our algorithm possesses more advancedsuper-resolution capabilities, particularly in enhancing facial components. ThePyTorch code is available at https://github.com/continueyang/GVTNet</description>
      <author>example@mail.com (Chao Yang, Yong Fan, Cheng Lu, Minghao Yuan, Zhijing Yang)</author>
      <guid isPermaLink="false">2502.12570v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Spatiotemporal-aware Trend-Seasonality Decomposition Network for Traffic Flow Forecasting</title>
      <link>http://arxiv.org/abs/2502.12213v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;交通预测对于优化出行调度和提升公共安全至关重要，但交通数据中复杂的时空动态特性给准确预测带来了挑战。本文介绍了一种新的模型——时空间趋势-季节性分解网络（STDN），该模型通过构建动态图结构来表示交通流，并引入新颖的时空嵌入以共同捕捉全局交通动态。&lt;h4&gt;背景&lt;/h4&gt;交通预测在优化出行调度和提升公共安全方面具有重要作用，但现有的方法难以有效应对复杂的时空数据特性带来的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型STDN，旨在通过分解交通流量的时间趋势与季节性因素来提高交通预测的准确性，并降低计算成本。&lt;h4&gt;方法&lt;/h4&gt;该模型首先构建动态图结构表示交通流，使用创新的空间时间嵌入共同捕捉全局交通动态。然后通过专门设计的趋势-季节性分解模块分离出每个交通节点在不同时间内的趋势循环和季节成分，最后这些成分经过编码器解码器网络处理生成最终预测。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验结果表明，在现实世界的交通数据集上，STDN模型能够以显著的计算成本实现更好的性能。此外，研究人员还发布了一个名为JiNan的新交通数据集，该数据集具有独特的城市内部动态特性。&lt;h4&gt;结论&lt;/h4&gt;提出的STDN模型通过分解时间趋势和季节性因素，提高了交通流量预测的准确性，并且新发布的JiNan数据集丰富了评估场景全面性的选项。&lt;h4&gt;翻译&lt;/h4&gt;交通预测对优化行程安排和提高公共安全至关重要，但是复杂的空间时间和动态特性在交通数据中给准确预测带来了挑战。本文介绍了新的模型——时空趋势-季节性分解网络（STDN），该模型开始通过构建表示流量的动态图结构，并结合新颖的时间空间嵌入共同捕捉全局交通动态。这些学习到的表示进一步由特别设计的趋势-季节性分解模块细化，该模块将每个时间点和节点的交通趋势循环和季节因素分离开来。然后这些组件通过编码器解码器网络处理生成最终预测结果。在现实世界交通数据集上的广泛实验表明，STDN实现了卓越性能，并且计算成本显著降低。此外，我们发布了名为JiNan的新交通数据集，该数据集包含独特的城市内部动态特性，因此丰富了交通预测评估的场景全面性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic prediction is critical for optimizing travel scheduling and enhancingpublic safety, yet the complex spatial and temporal dynamics within trafficdata present significant challenges for accurate forecasting. In this paper, weintroduce a novel model, the Spatiotemporal-aware Trend-SeasonalityDecomposition Network (STDN). This model begins by constructing a dynamic graphstructure to represent traffic flow and incorporates novel spatio-temporalembeddings to jointly capture global traffic dynamics. The representationslearned are further refined by a specially designed trend-seasonalitydecomposition module, which disentangles the trend-cyclical component andseasonal component for each traffic node at different times within the graph.These components are subsequently processed through an encoder-decoder networkto generate the final predictions. Extensive experiments conducted onreal-world traffic datasets demonstrate that STDN achieves superior performancewith remarkable computation cost. Furthermore, we have released a new trafficdataset named JiNan, which features unique inner-city dynamics, therebyenriching the scenario comprehensiveness in traffic prediction evaluation.</description>
      <author>example@mail.com (Lingxiao Cao, Bin Wang, Guiyuan Jiang, Yanwei Yu, Junyu Dong)</author>
      <guid isPermaLink="false">2502.12213v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Improving the Stability of GNN Force Field Models by Reducing Feature Correlation</title>
      <link>http://arxiv.org/abs/2502.12548v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于特征相关性的方法，用于增强GNNFF模型在分子动力学模拟中的稳定性，并通过实验证明该方法可以显著提高模型的稳定性，尤其是在处理出界数据集时。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于图神经网络的力场(GNNFF)模型被广泛应用于半导体材料研究中成本效益最高的分子动力学(MD)仿真。然而，即使这些模型在训练过的(入样分布)数据集中提供高精度的能量和力的绝对误差（MAE），它们在长时间MD模拟时面对出界数据集经常变得不稳定。&lt;h4&gt;目的&lt;/h4&gt;提出一种增强GNNFF模型稳定性的方法，以改善分子动力学仿真的稳定性。&lt;h4&gt;方法&lt;/h4&gt;揭示了特征相关性和GNNFF模型稳定性之间的负面关系，并设计了一个动态损失系数调度器的损失函数来减少边缘特征的相关性。此外，还提出了一个经验指标用于评估MD仿真中的稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;基于特征相关性的新方法可以显著提高GNNFF模型在处理出界数据集时的稳定性，且计算开销不超过3%。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的损失函数和评估标准，该研究成功提高了GNNFF模型在分子动力学仿真中的稳定性和可靠性。这种方法为半导体材料的研究提供了更可靠的工具。&lt;h4&gt;翻译&lt;/h4&gt;最近，基于图神经网络的力场(GNNFF)模型广泛应用于分子动力学(MD)仿真中，这是半导体材料研究中最经济有效的手段之一。然而，尽管这些模型在训练过的(入样分布)数据集中提供高精度的能量和力的绝对误差（MAE），它们在长时间MD模拟时面对出界数据集经常变得不稳定。本文提出了一种基于特征相关性的方法来增强GNNFF模型中的MD仿真的稳定性，并揭示了特征相关性与GNNFF模型稳定性之间的负面关系，设计了一个带有动态损失系数调度器的损失函数以减少边缘特征的相关性，适用于一般GNNFF训练。我们还提出了一个经验指标用于评估MD仿真中的稳定性。实验表明，我们的方法可以显著提高GNNFF模型在处理出界数据集时的稳定性，计算开销不超过3%。例如，在Allegro模型中，我们可以确保从0.03ps到10ps的稳定的MD模拟时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Graph Neural Network based Force Field (GNNFF) models are widelyused in Molecular Dynamics (MD) simulation, which is one of the mostcost-effective means in semiconductor material research. However, even suchmodels provide high accuracy in energy and force Mean Absolute Error (MAE) overtrained (in-distribution) datasets, they often become unstable during long-timeMD simulation when used for out-of-distribution datasets. In this paper, wepropose a feature correlation based method for GNNFF models to enhance thestability of MD simulation. We reveal the negative relationship between featurecorrelation and the stability of GNNFF models, and design a loss function witha dynamic loss coefficient scheduler to reduce edge feature correlation thatcan be applied in general GNNFF training. We also propose an empirical metricto evaluate the stability in MD simulation. Experiments show our method cansignificantly improve stability for GNNFF models especially inout-of-distribution data with less than 3% computational overhead. For example,we can ensure the stable MD simulation time from 0.03ps to 10ps for Allegromodel.</description>
      <author>example@mail.com (Yujie Zeng, Wenlong He, Ihor Vasyltsov, Jiaxin Wei, Ying Zhang, Lin Chen, Yuehua Dai)</author>
      <guid isPermaLink="false">2502.12548v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>USPilot: An Embodied Robotic Assistant Ultrasound System with Large Language Model Enhanced Graph Planner</title>
      <link>http://arxiv.org/abs/2502.12498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于大型语言模型的机器人辅助超声系统USPilot，该系统能够自主进行超声检查。&lt;h4&gt;背景&lt;/h4&gt;随着大语言模型的发展，实体人工智能在机器人操控任务中提供了变革性的机遇。然而，在医疗诊断过程中广泛应用且成本效益高的超声成像面临着专业超声技师短缺的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一个基于LLM的框架，使USPilot能够作为虚拟超声技师自主完成超声检查，并回答患者相关问题。&lt;h4&gt;方法&lt;/h4&gt;通过微调大语言模型以增强对特定于超声的操作和任务的理解；并结合改进后的图神经网络(GNN)来管理超声机器人API和服务于任务规划。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，基于LLM的GNN在公共数据集上的任务规划准确性达到了前所未有的水平。USPilot系统显示出显著地能够自主理解和执行超声检查程序的能力。&lt;h4&gt;结论&lt;/h4&gt;这一进展使我们更接近实现完全自主且可能无人值守的机器人超声系统，从而填补了医疗成像中的关键资源缺口。&lt;h4&gt;翻译&lt;/h4&gt;在大型语言模型的时代，实体人工智能为机器人操控任务提供了变革性的机会。超声成像作为一种广泛应用和成本效益高的医学诊断程序面临着专业技师短缺的问题。为此，我们提出了USPilot——一个基于LLM的框架支持的机器人辅助超声系统，旨在实现自主进行超声检查的能力。该系统能够响应患者的超声相关问题，并根据用户意图执行超声扫描。通过微调大语言模型，USPilot在特定于超声的问题和任务中展现出了深刻的理解力。此外，它整合了一个增强的图神经网络(GNN)，用于管理超声机器人API并作为任务规划器使用。实验结果显示，在公共数据集上的该GNN实现了前所未有的任务规划准确性。此外，该系统展示了自主理解和执行超声程序的巨大潜力。这些进步使我们更接近于实现完全自主且可能无人值守的机器人超声系统，从而解决医学成像中的关键资源缺口问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of Large Language Models (LLMs), embodied artificial intelligencepresents transformative opportunities for robotic manipulation tasks.Ultrasound imaging, a widely used and cost-effective medical diagnosticprocedure, faces challenges due to the global shortage of professionalsonographers. To address this issue, we propose USPilot, an embodied roboticassistant ultrasound system powered by an LLM-based framework to enableautonomous ultrasound acquisition. USPilot is designed to function as a virtualsonographer, capable of responding to patients' ultrasound-related queries andperforming ultrasound scans based on user intent. By fine-tuning the LLM,USPilot demonstrates a deep understanding of ultrasound-specific questions andtasks. Furthermore, USPilot incorporates an LLM-enhanced Graph Neural Network(GNN) to manage ultrasound robotic APIs and serve as a task planner.Experimental results show that the LLM-enhanced GNN achieves unprecedentedaccuracy in task planning on public datasets. Additionally, the systemdemonstrates significant potential in autonomously understanding and executingultrasound procedures. These advancements bring us closer to achievingautonomous and potentially unmanned robotic ultrasound systems, addressingcritical resource gaps in medical imaging.</description>
      <author>example@mail.com (Mingcong Chen, Siqi Fan, Guanglin Cao, Hongbin Liu)</author>
      <guid isPermaLink="false">2502.12498v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Cheesemap: A High-Performance Point-Indexing Data Structure for Neighbor Search in LiDAR Data</title>
      <link>http://arxiv.org/abs/2502.11602v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提供了一个关于各种数据结构与邻近搜索方法的全面比较分析，并引入了一种新颖的数据结构cheesemap来处理3D LiDAR点云。&lt;h4&gt;背景&lt;/h4&gt;点云数据是表示三维空间信息的基本形式，在索引和查询这些点云时，高效的操作对于物体识别、自主导航以及环境建模等任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;比较分析不同类型的点云中各种数据结构及其邻近搜索方法，并提出一种新颖的数据结构cheesemap以处理3D LiDAR点云。&lt;h4&gt;方法&lt;/h4&gt;对不同的点云类型进行数据结构和相邻搜索策略的综合对比。提出了用于管理3D LiDAR点云的新颖数据结构，称为cheesemap，并根据点分布的不同特性设计了三种变体：稠密型、稀疏型以及混合型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，相较于现有的先进数据结构，cheesemap在每个查询的执行时间方面有显著优势，尤其是在航空激光扫描（ALS）点云上。此外，在稀疏和混合表示中内存消耗也较低。&lt;h4&gt;结论&lt;/h4&gt;鉴于其优越性能以及低内存占用的特点，cheesemap成为涉及三维点云应用的理想选择。&lt;h4&gt;翻译&lt;/h4&gt;点云数据作为三维空间信息的表示形式，在物体识别、自主导航及环境建模等领域具有重要的意义。本论文对各种数据结构与邻近搜索方法进行了全面比较，并提出了用于处理3D LiDAR点云的新颖数据结构cheesemap，实验结果表明这种新数据结构在执行效率上优于现有技术，特别是在ALS点云中表现出色，同时内存消耗较小，尤其是在稀疏和混合表示中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud data, as the representation of three-dimensional spatialinformation, is a fundamental piece of information in various domains whereindexing and querying these point clouds efficiently is crucial for tasks suchas object recognition, autonomous navigation, and environmental modeling. Inthis paper, we present a comprehensive comparative analysis of various datastructures combined with neighboring search methods across different types ofpoint clouds. Additionally, we introduce a novel data structure, cheesemap, tohandle 3D LiDAR point clouds. Exploring the sparsity and irregularity in thedistribution of points, there are three flavors of the cheesemap: dense,sparse, and mixed. Results show that the cheesemap can outperformstate-of-the-art data structures in terms of execution time per query,particularly for ALS (Aerial Laser Scanning) point clouds. Memory consumptionis also minimal, especially in the sparse and mixed representations, making thecheesemap a suitable choice for applications involving three-dimensional pointclouds.</description>
      <author>example@mail.com (Ruben Laso, Miguel Yermo)</author>
      <guid isPermaLink="false">2502.11602v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer</title>
      <link>http://arxiv.org/abs/2502.07158v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于Transformer框架的PedCA-FT，用于早期预测儿科心脏骤停（CA），该方法融合了电子健康记录（EHR）的数据表视图和衍生的文本视图，以全面释放高维风险因素及其动态变化之间的相互作用。&lt;h4&gt;背景&lt;/h4&gt;在高危重症监护环境中，儿童心脏骤停（CA）的早期预测对于及时干预至关重要。现有的人工智能模型难以充分捕捉复杂的时间序列数据中的模式以及各维度风险因素间的交互效应。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的基于Transformer的方法来融合电子健康记录的数据表视图和文本视图，以生成更为精确的心脏骤停风险评估。&lt;h4&gt;方法&lt;/h4&gt;PedCA-FT通过为每种模态视图（数据表或文本）设计特定的Transformer模块，捕捉复杂的时间序列模式以及上下文关系。这种方法可以更好地理解高维风险因素及其动态变化之间的相互作用。&lt;h4&gt;主要发现&lt;/h4&gt;在CHOA-CICU数据库中的一个经过精心选择的儿科群体上进行了评估，PedCA-FT模型在五个关键性能指标上的表现优于其他十种人工智能方法，并且能够识别出具有临床意义的风险因素。这些结果表明了多模态融合技术在提高早期心脏骤停检测和改善患者护理方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;通过使用PedCA-FT模型，可以有效地进行儿科心脏骤停的早期预测，该模型展示了其在真实世界数据集上的强大性能，并为未来的研究提供了重要的参考价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early prediction of pediatric cardiac arrest (CA) is critical for timelyintervention in high-risk intensive care settings. We introduce PedCA-FT, anovel transformer-based framework that fuses tabular view of EHR with thederived textual view of EHR to fully unleash the interactions ofhigh-dimensional risk factors and their dynamics. By employing dedicatedtransformer modules for each modality view, PedCA-FT captures complex temporaland contextual patterns to produce robust CA risk estimates. Evaluated on acurated pediatric cohort from the CHOA-CICU database, our approach outperformsten other artificial intelligence models across five key performance metricsand identifies clinically meaningful risk factors. These findings underscorethe potential of multimodal fusion techniques to enhance early CA detection andimprove patient care.</description>
      <author>example@mail.com (Jiaying Lu, Stephanie R. Brown, Songyuan Liu, Shifan Zhao, Kejun Dong, Del Bold, Michael Fundora, Alaa Aljiffry, Alex Fedorov, Jocelyn Grunwell, Xiao Hu)</author>
      <guid isPermaLink="false">2502.07158v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>On the Robust Approximation of ASR Metrics</title>
      <link>http://arxiv.org/abs/2502.12408v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 Pages. Work in Progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;近期语音基础模型的进步主要是通过扩大模型规模和数据来实现的，使其能够执行包括语音识别在内的各种任务。然而，受限于来自不同领域的有限标注数据以及测试条件，这些模型在标准基准之外的真实泛化能力仍然不明确。&lt;h4&gt;背景&lt;/h4&gt;传统上，自动语音识别（ASR）模型使用像词错误率（WER）和字符错误率（CER）这样的指标来评估性能。但是受限于多领域、多环境的标注数据不足以及标注成本高耗时长的问题，这些标准基准之外的真实性能仍不清楚。&lt;h4&gt;目的&lt;/h4&gt;为了克服传统方法中的局限性，研究人员提出了一种无需真实标签的新颖无标签方法来估计ASR性能指标。&lt;h4&gt;方法&lt;/h4&gt;该方法利用统一空间内的多模态嵌入，结合高质量的代理模型计算出代理度量，并使用这些特征训练回归模型预测像WER和CER这样的关键ASR指标。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在多种标准测试环境以及实际场景下进行超过40种不同模型的评估后，该方法在所有配置中能够将误差保持在一个很小范围内，并且比最近的最佳基线性能高出50%以上。&lt;h4&gt;结论&lt;/h4&gt;通过采用无标签的方法来估算自动语音识别模型的关键性能指标，可以有效减少数据标注的成本和时间消耗，同时提供更可靠的泛化能力评估。&lt;h4&gt;翻译&lt;/h4&gt;近期在语音基础模型上的进展主要依靠扩大模型的规模和训练数据，使得这些模型能够执行包括语音识别在内的广泛任务。然而，在受限于不同领域和测试条件下的有限标签数据之后，这些模型的真实性能超出标准基准的能力尚不明确。为了解决这个问题，提出了一种新颖的无标签方法来估计自动语音识别（ASR）性能指标，从而避免了对真实标签的需求。该方法利用统一空间内的多模态嵌入结合高质量代理模型计算出代理度量，并用于训练回归模型预测像WER和CER这样的关键ASR指标。实验结果表明，在超过40种模型和14个数据集（包括标准测试条件和现实世界环境）上，这种方法能够以单个数字的绝对差异估算这些度量，性能比最近的最佳基线高出50%以上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in speech foundation models are largely driven by scalingboth model size and data, enabling them to perform a wide range of tasks,including speech recognition. Traditionally, ASR models are evaluated usingmetrics like Word Error Rate (WER) and Character Error Rate (CER), which dependon ground truth labels. As a result of limited labeled data from diversedomains and testing conditions, the true generalization capabilities of thesemodels beyond standard benchmarks remain unclear. Moreover, labeling data isboth costly and time-consuming. To address this, we propose a novel label-freeapproach for approximating ASR performance metrics, eliminating the need forground truth labels. Our method utilizes multimodal embeddings in a unifiedspace for speech and transcription representations, combined with ahigh-quality proxy model to compute proxy metrics. These features are used totrain a regression model to predict key ASR metrics like Word Error Rate (WER)and Character Error Rate (CER). We experiment with over 40 models across 14datasets representing both standard and in-the-wild testing conditions. Ourresults show that we approximate the metrics within a single-digit absolutedifference across all experimental configurations, outperforming the mostrecent baseline by more than 50\%.</description>
      <author>example@mail.com (Abdul Waheed, Hanin Atwany, Rita Singh, Bhiksha Raj)</author>
      <guid isPermaLink="false">2502.12408v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards Mechanistic Interpretability of Graph Transformers via Attention Graphs</title>
      <link>http://arxiv.org/abs/2502.12352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Attention Graphs，一种用于解释图神经网络(GNN)和图变换器的机制性可解释性的新工具。&lt;h4&gt;背景&lt;/h4&gt;基于GNN中的消息传递与Transformer中的自注意力机制之间的数学等价性。&lt;h4&gt;目的&lt;/h4&gt;通过在同质性和异质性节点分类任务上的实验，从网络科学的角度分析Attention Graphs。&lt;h4&gt;方法&lt;/h4&gt;聚合Transformer层和头的注意力矩阵以描述信息如何在网络输入节点之间流动。&lt;h4&gt;主要发现&lt;/h4&gt;{'(1)': '当图变换器被允许使用输入节点之间的全连接注意来学习最优图结构时，模型学到的Attention Graphs通常不会与输入/原始图结构相关联；(2)对于异质性图，不同的图变换器变体可以通过利用不同的信息流动模式获得相似的表现。', '(2)': '不同变种的Graph Transformer在性能相似的情况下会使用截然不同的信息流模式'}&lt;h4&gt;结论&lt;/h4&gt;提出了一个新的工具Attention Graphs，并通过实验展示了其在网络科学分析中的潜力和特性。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了Attention Graphs，这是一种新的用于机制性解释图神经网络(GNN)和图变换器的工具。该工具基于GNN中消息传递与Transformer中自注意力机制之间的数学等价性。通过在同质性和异质性的节点分类任务上进行实验，并从网络科学的角度分析了Attention Graphs。我们发现：当Graph Transformers能够利用输入节点间的全连接注意来学习最优图结构时，所学到的Attention Graphs通常不会与原始/输入图的相关结构相匹配；对于异质性图而言，不同的Graph Transformer变体在性能相似的同时会采用截然不同的信息流动模式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Attention Graphs, a new tool for mechanistic interpretability ofGraph Neural Networks (GNNs) and Graph Transformers based on the mathematicalequivalence between message passing in GNNs and the self-attention mechanism inTransformers. Attention Graphs aggregate attention matrices across Transformerlayers and heads to describe how information flows among input nodes. Throughexperiments on homophilous and heterophilous node classification tasks, weanalyze Attention Graphs from a network science perspective and find that: (1)When Graph Transformers are allowed to learn the optimal graph structure usingall-to-all attention among input nodes, the Attention Graphs learned by themodel do not tend to correlate with the input/original graph structure; and (2)For heterophilous graphs, different Graph Transformer variants can achievesimilar performance while utilising distinct information flow patterns. Opensource code: https://github.com/batu-el/understanding-inductive-biases-of-gnns</description>
      <author>example@mail.com (Batu El, Deepro Choudhury, Pietro Liò, Chaitanya K. Joshi)</author>
      <guid isPermaLink="false">2502.12352v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Achieving Upper Bound Accuracy of Joint Training in Continual Learning</title>
      <link>http://arxiv.org/abs/2502.12388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文综述了连续学习领域的研究进展，重点介绍了如何通过理论和大模型的力量实现理想精度。&lt;h4&gt;背景&lt;/h4&gt;连续学习是机器学习中的一个活跃领域，主要关注于增量地学习一系列任务。该领域面临的主要挑战包括灾难性遗忘（CF）和任务间类别的分离（ICS）。&lt;h4&gt;目的&lt;/h4&gt;论文旨在探讨最新的研究进展，解释为什么通过利用理论与大型基础模型，可以使连续学习算法达到联合训练的理想精度。&lt;h4&gt;方法&lt;/h4&gt;最近的研究表明，可以通过充分利用大模型的潜力并结合有效的连续学习策略来克服传统挑战，并实现上界性能。这些发现已在文本和图像分类数据集上得到实验证明。&lt;h4&gt;主要发现&lt;/h4&gt;通过采用适当的理论框架和大型预训练模型，现在可以实现与一次性联合训练相媲美的精度水平，这标志着连续学习在实际应用中的成熟。&lt;h4&gt;结论&lt;/h4&gt;论文总结了使连续学习算法接近理想性能的研究进展，并强调了这种方法在现实世界应用场景中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;持续学习已经成为机器学习的一个活跃研究领域，重点在于增量地学习一系列任务序列。该领域的关键挑战是灾难性遗忘（CF），大多数研究努力集中在缓解这个问题上。然而，最先进的连续学习算法的准确性与所有任务联合训练时的理想或上限准确度之间仍存在显著差距。这种差距阻碍了持续学习在许多应用中的采用，因为精度往往至关重要。最近还发现了一个名为跨任务类别分离（ICS）的新挑战，这促使人们进行理论研究来寻找解决持续学习问题的原则性方法。进一步的研究表明，通过利用这些理论和大型基础模型的力量，现在可以达到理想性能水平，并且这个结论已经在文本分类和图像分类的数据集上得到了实验证明。因此，持续学习现在准备好用于实际应用中了。该论文回顾了实现这一成就的主要研究工作，并从直观理解和神经科学研究的角度解释这种方法的合理性，还讨论了一些见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning has been an active research area in machine learning,focusing on incrementally learning a sequence of tasks. A key challenge iscatastrophic forgetting (CF), and most research efforts have been directedtoward mitigating this issue. However, a significant gap remains between theaccuracy achieved by state-of-the-art continual learning algorithms and theideal or upper-bound accuracy achieved by training all tasks together jointly.This gap has hindered or even prevented the adoption of continual learning inapplications, as accuracy is often of paramount importance. Recently, anotherchallenge, termed inter-task class separation (ICS), was also identified, whichspurred a theoretical study into principled approaches for solving continuallearning. Further research has shown that by leveraging the theory and thepower of large foundation models, it is now possible to achieve upper-boundaccuracy, which has been empirically validated using both text and imageclassification datasets. Continual learning is now ready for real-lifeapplications. This paper surveys the main research leading to this achievement,justifies the approach both intuitively and from neuroscience research, anddiscusses insights gained.</description>
      <author>example@mail.com (Saleh Momeni, Bing Liu)</author>
      <guid isPermaLink="false">2502.12388v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Detecting Systematic Weaknesses in Vision Models along Predefined Human-Understandable Dimensions</title>
      <link>http://arxiv.org/abs/2502.12360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种结合现代基础模型和组合搜索算法的工作流程，用于在图像数据中寻找深度神经网络（DNN）的系统性弱点。&lt;h4&gt;背景&lt;/h4&gt;随着建立安全AI系统的关注增加，在过去几年里研究DNN的系统性弱点变得越来越重要。现有的方法通常难以直接使用这些发现，因为它们缺乏与人类理解相关的元数据。&lt;h4&gt;目的&lt;/h4&gt;提出一个工作流程来寻找基于图像数据中DNN错误和结构化数据的系统性弱点，并确保这些弱点能够与预定义的人类可理解维度相一致。&lt;h4&gt;方法&lt;/h4&gt;结合现代基础模型进行组合搜索算法，以识别具有低性能的数据切片或子集。同时考虑到元数据噪声的影响。&lt;h4&gt;主要发现&lt;/h4&gt;该研究在四个流行的计算机视觉数据集中进行了评估，并使用多个最先进的DNN作为测试对象，这些数据集包括自动驾驶数据集如Cityscapes、BDD100k和RailSem19。&lt;h4&gt;结论&lt;/h4&gt;通过将基础模型与组合搜索算法相结合的工作流程可以有效地识别图像中的系统性弱点。这种方法为理解深度神经网络在现实世界应用中的行为提供了新的视角，特别是对于安全相关领域来说尤为重要。&lt;h4&gt;翻译&lt;/h4&gt;研究DNN系统的薄弱环节近年来受到越来越多的关注，尤其是在构建安全AI系统的背景下。切片发现方法（SDM）是寻找这些系统性弱性的算法方法之一，它们可以识别数据集的一部分，在这部分中，被测试的深度神经网络性能较低。为了使这些发现直接有用，例如作为安全性论证中的证据，切片需要与人类理解的安全相关维度对齐，这通常由安全和领域专家定义为操作设计领域的部分。尽管对于结构化数据来说这是显而易见的，但缺乏语义元数据使得在无结构数据中进行此类调查变得具有挑战性。因此，我们提出了一种结合现代基础模型以及考虑结构化数据和DNN错误以寻找图像中的系统性弱点的工作流程。与现有方法不同的是，我们的方法识别出与预定义的人类可理解维度一致的弱切片。由于该工作流包括基础模型，其中间和最终结果可能并不总是准确的。因此，在我们的工作流程中构建了一种解决元数据噪声影响的方法。我们在四个流行计算机视觉数据集（包括自动驾驶数据集如Cityscapes、BDD100k和RailSem19）上评估了我们的方法，并使用多个最先进的模型作为被测试的DNN进行实验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Studying systematic weaknesses of DNNs has gained prominence in the last fewyears with the rising focus on building safe AI systems. Slice discoverymethods (SDMs) are prominent algorithmic approaches for finding such systematicweaknesses. They identify top-k semantically coherent slices/subsets of datawhere a DNN-under-test has low performance. For being directly useful, e.g., asevidences in a safety argumentation, slices should be aligned withhuman-understandable (safety-relevant) dimensions, which, for example, aredefined by safety and domain experts as parts of the operational design domain(ODD). While straightforward for structured data, the lack of semantic metadatamakes these investigations challenging for unstructured data. Therefore, wepropose a complete workflow which combines contemporary foundation models withalgorithms for combinatorial search that consider structured data and DNNerrors for finding systematic weaknesses in images. In contrast to existingapproaches, ours identifies weak slices that are in line with predefinedhuman-understandable dimensions. As the workflow includes foundation models,its intermediate and final results may not always be exact. Therefore, we buildinto our workflow an approach to address the impact of noisy metadata. Weevaluate our approach w.r.t. its quality on four popular computer visiondatasets, including autonomous driving datasets like Cityscapes, BDD100k, andRailSem19, while using multiple state-of-the-art models as DNNs-under-test.</description>
      <author>example@mail.com (Sujan Sai Gannamaneni, Rohil Prakash Rao, Michael Mock, Maram Akila, Stefan Wrobel)</author>
      <guid isPermaLink="false">2502.12360v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>ExoMiner++ on TESS with Transfer Learning from Kepler: Transit Classification and Vetting Catalog for 2-min Data</title>
      <link>http://arxiv.org/abs/2502.09790v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ExoMiner++ 是一个改进的深度学习模型，用于提高对 TESS 数据中的过渡信号分类准确性。&lt;h4&gt;背景&lt;/h4&gt;在成功的 ExoMiner 模型基础上开发了 ExoMiner++，它使用额外的诊断输入来区分真实过渡信号和假阳性来源。&lt;h4&gt;目的&lt;/h4&gt;通过引入更多诊断性特征并利用从开普勒太空望远镜获取的数据进行迁移学习，提高过渡信号分类准确性。&lt;h4&gt;方法&lt;/h4&gt;ExoMiner++ 使用多种数据源作为输入（如周期图、通量趋势等），并在 Kepler 数据上进行了迁移学习以提升模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;在 147,568 个未标记的 TCEs 中，ExoMiner++ 确定了 7,330 个作为潜在新行星候选者，并且与之前的分类相比减少了不必要假阳性的搜索范围。&lt;h4&gt;结论&lt;/h4&gt;通过提高过渡信号分类的质量和准确性，ExoMiner++ 大大缩小了后续调查的搜索空间，使得研究可以更专注于最有可能的新行星发现。此外，该模型为天文学家提供了新的 TESS 目录，包含每条过渡信号的分类结果及其置信度分数。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了 ExoMiner++，这是一个基于 ExoMiner 成功改进的深度学习模型，用于提高对 2 分钟 TESS 数据中的过渡信号分类准确性。ExoMiner++ 包括额外的诊断输入，包括周期图、通量趋势等关键特征，这些对于有效区分真实过渡信号和假阳性来源至关重要。为了进一步增强性能，我们利用了从高质量标签数据（来自开普勒空间望远镜）进行迁移学习，缓解了 TESS 数据噪声更大且更难以界定的问题。ExoMiner++ 在各种分类和排名指标上均达到了高准确性，显著缩小了后续调查以确认新行星的搜索范围。为了服务外星人社区，我们引入了包含每个过渡信号的 ExoMiner++ 分类和置信度分数的新 TESS 目录。在 147,568 个未标记的 TCEs 中，ExoMiner++ 确定了 7,330 个作为行星候选者，其余则被分类为假阳性来源。这些 7,330 个候选行星对应于 1,868 个现有的 TESS 目标物体 (TOIs)，69 个社区 TESS 目标物体 (CTOIs) 和新的 50 个 CTOIs。在先前被标记为潜在新行星候选者的 2,506 TOI 中，1,797 被 ExoMiner++ 分类为行星候选者。这种减少的可能候选者数量结合了 ExoMiner++ 的优秀排名质量，使得后续努力可以集中在最有可能的新行星发现上，从而提高了整体新行星产率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present ExoMiner++, an enhanced deep learning model that builds on thesuccess of ExoMiner to improve transit signal classification in 2-minute TESSdata. ExoMiner++ incorporates additional diagnostic inputs, includingperiodogram, flux trend, difference image, unfolded flux, and spacecraftattitude control data, all of which are crucial for effectively distinguishingtransit signals from more challenging sources of false positives. To furtherenhance performance, we leverage transfer learning from high-quality labeleddata from the Kepler space telescope, mitigating the impact of TESS's noisierand more ambiguous labels. ExoMiner++ achieves high accuracy across variousclassification and ranking metrics, significantly narrowing the search spacefor follow-up investigations to confirm new planets. To serve the exoplanetcommunity, we introduce new TESS catalogs containing ExoMiner++ classificationsand confidence scores for each transit signal. Among the 147,568 unlabeledTCEs, ExoMiner++ identifies 7,330 as planet candidates, with the remainderclassified as false positives. These 7,330 planet candidates correspond to1,868 existing TESS Objects of Interest (TOIs), 69 Community TESS Objects ofInterest (CTOIs), and 50 newly introduced CTOIs. 1,797 out of the 2,506 TOIspreviously labeled as planet candidates in ExoFOP are classified as planetcandidates by ExoMiner++. This reduction in plausible candidates combined withthe excellent ranking quality of ExoMiner++ allows the follow-up efforts to befocused on the most likely candidates, increasing the overall planet yield.</description>
      <author>example@mail.com (Hamed Valizadegan, Miguel J. S. Martinho, Jon M. Jenkins, Joseph D. Twicken, Douglas A. Caldwell, Patrick Maynard, Hongbo Wei, William Zhong, Charles Yates, Sam Donald, Karen A. Collins, David Latham, Khalid Barkaoui, Perry Berlind, Michael L. Calkins, Kylee Carden, Nikita Chazov, Gilbert A. Esquerdo, Tristan Guillot, Vadim Krushinsky, Grzegorz Nowak, Benjamin V. Rackham, Amaury Triaud, Richard P. Schwarz, Denise Stephens, Chris Stockdale, Jiaqi Wang, Cristilyn N. Watkins, Francis P. Wilkin)</author>
      <guid isPermaLink="false">2502.09790v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Motion planning for highly-dynamic unconditioned reflexes based on chained Signed Distance Functions</title>
      <link>http://arxiv.org/abs/2502.10734v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要原文&lt;/h4&gt;The unconditioned reflex (e.g., protective reflex), which is the innate reaction of the organism and usually performed through the spinal cord rather than the brain, can enable organisms to escape harms from environments. In this paper, we propose an online, highly-dynamic motion planning algorithm to endow manipulators the highly-dynamic unconditioned reflexes to humans and/orenvironments. Our method is based on a chained version of Signed Distance Functions (SDFs), which can be pre-computed and stored. Our proposed algorithm is divided into two stages. In the offline stage, we create 3 groups of local SDFs to store the geometric information of the manipulator and its working environment. In the online stage, the pre-computed local SDFs are chained together according the configuration of the manipulator, to provide global geometric information about the environment. While the point clouds of the dynamic objects serve as query points to look up these local SDFs for quickly generating escape velocity. Then we propose a modified geometric Jacobian matrix and use the Jacobian-pseudo-inverse method to generate real-time reflex behaviors to avoid the static and dynamic obstacles in the environment. The benefits of our method are validated in both static and dynamic scenarios. In the static scenario, our method identifies the path solutions with lower time consumption and shorter trajectory length compared to existing solutions. In the dynamic scenario, our method can reliably pursue the dynamic target point, avoid dynamic obstacles, and react to these obstacles within 1ms, which surpasses the unconditioned reflex reaction time of humans.&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于签名距离函数（SDF）的在线、高度动态的运动规划算法，为机械臂赋予类似于生物本能反应的能力，使其能快速避开静态和动态障碍物。&lt;h4&gt;背景&lt;/h4&gt;无条件反射是生物体的一种先天反应机制，通常通过脊髓而非大脑执行，用于帮助生物从环境中逃脱伤害。当前缺乏一种能够实时避免障碍物的高效运动规划算法。&lt;h4&gt;目的&lt;/h4&gt;设计并实现一种高效的在线、高度动态的运动规划算法，使机械臂能快速响应并避开静态和动态环境中的障碍物，模拟人类无条件反射反应机制。&lt;h4&gt;方法&lt;/h4&gt;{'离线阶段': '创建3组局部SDF存储机械臂及其工作环境的几何信息', '在线阶段': '根据机械臂配置将预先计算好的局部SDF链接起来提供全局几何信息；利用动态对象的点云数据作为查询点，快速生成避障速度向量'}&lt;h4&gt;主要发现&lt;/h4&gt;在静态场景中，提出的方法能够在较低的时间消耗下获得较短轨迹长度的路径解决方案；在动态场景中，该方法能可靠地追踪动态目标点、避开动态障碍物，并且对这些障碍物做出反应的时间小于1毫秒。&lt;h4&gt;结论&lt;/h4&gt;所提出的算法能够有效地使机械臂模拟生物体的无条件反射行为，在静态和动态环境中都能快速避障并响应环境变化，性能优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The unconditioned reflex (e.g., protective reflex), which is the innatereaction of the organism and usually performed through the spinal cord ratherthan the brain, can enable organisms to escape harms from environments. In thispaper, we propose an online, highly-dynamic motion planning algorithm to endowmanipulators the highly-dynamic unconditioned reflexes to humans and/orenvironments. Our method is based on a chained version of Signed DistanceFunctions (SDFs), which can be pre-computed and stored. Our proposed algorithmis divided into two stages. In the offline stage, we create 3 groups of localSDFs to store the geometric information of the manipulator and its workingenvironment. In the online stage, the pre-computed local SDFs are chainedtogether according the configuration of the manipulator, to provide globalgeometric information about the environment. While the point clouds of thedynamic objects serve as query points to look up these local SDFs for quicklygenerating escape velocity. Then we propose a modified geometric Jacobianmatrix and use the Jacobian-pseudo-inverse method to generate real-time reflexbehaviors to avoid the static and dynamic obstacles in the environment. Thebenefits of our method are validated in both static and dynamic scenarios. Inthe static scenario, our method identifies the path solutions with lower timeconsumption and shorter trajectory length compared to existing solutions. Inthe dynamic scenario, our method can reliably pursue the dynamic target point,avoid dynamic obstacles, and react to these obstacles within 1ms, whichsurpasses the unconditioned reflex reaction time of humans.</description>
      <author>example@mail.com (Ken Lin, Qi Ye, Tin Lun Lam, Zhibin Li, Jiming Chen, Gaofeng Li)</author>
      <guid isPermaLink="false">2502.10734v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>ClusMFL: A Cluster-Enhanced Framework for Modality-Incomplete Multimodal Federated Learning in Brain Imaging Analysis</title>
      <link>http://arxiv.org/abs/2502.12180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了ClusMFL框架，用于处理跨机构脑影像分析中的模态不完整性问题。&lt;h4&gt;背景&lt;/h4&gt;多模式联邦学习（MFL）在分布式客户端上协同训练多模式模型方面显示出巨大潜力。特别是在脑成像领域，不同医疗机构可能由于隐私、设备限制或数据可用性等问题而缺少特定的成像模态。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的MFL框架ClusMFL，以应对跨机构脑影像分析中的模态不完整性问题。&lt;h4&gt;方法&lt;/h4&gt;利用FINCH算法构建每个模态标签对的特征嵌入簇中心池，并通过监督对比学习进行模内特征对齐。同时，这些簇中心作为缺失模态的代理来促进跨模式知识迁移。此外，该框架采用了基于模态的聚合策略以进一步增强模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;在ADNI数据集上进行了实验评估，结果表明ClusMFL在各种程度的模态不完整性下均优于多种基线方法。&lt;h4&gt;结论&lt;/h4&gt;ClusMFL为跨机构脑影像分析提供了可扩展解决方案，并且其性能超越了现有的许多基准技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Federated Learning (MFL) has emerged as a promising approach forcollaboratively training multimodal models across distributed clients,particularly in healthcare domains. In the context of brain imaging analysis,modality incompleteness presents a significant challenge, where someinstitutions may lack specific imaging modalities (e.g., PET, MRI, or CT) dueto privacy concerns, device limitations, or data availability issues. Whileexisting work typically assumes modality completeness or oversimplifiesmissing-modality scenarios, we simulate a more realistic setting by consideringboth client-level and instance-level modality incompleteness in this study.Building on this realistic simulation, we propose ClusMFL, a novel MFLframework that leverages feature clustering for cross-institutional brainimaging analysis under modality incompleteness. Specifically, ClusMFL utilizesthe FINCH algorithm to construct a pool of cluster centers for the featureembeddings of each modality-label pair, effectively capturing fine-grained datadistributions. These cluster centers are then used for feature alignment withineach modality through supervised contrastive learning, while also acting asproxies for missing modalities, allowing cross-modal knowledge transfer.Furthermore, ClusMFL employs a modality-aware aggregation strategy, furtherenhancing the model's performance in scenarios with severe modalityincompleteness. We evaluate the proposed framework on the ADNI dataset,utilizing structural MRI and PET scans. Extensive experimental resultsdemonstrate that ClusMFL achieves state-of-the-art performance compared tovarious baseline methods across varying levels of modality incompleteness,providing a scalable solution for cross-institutional brain imaging analysis.</description>
      <author>example@mail.com (Xinpeng Wang, Rong Zhou, Han Xie, Xiaoying Tang, Lifang He, Carl Yang)</author>
      <guid isPermaLink="false">2502.12180v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>AnyTouch: Learning Unified Static-Dynamic Representation across Multiple Visuo-tactile Sensors</title>
      <link>http://arxiv.org/abs/2502.12191v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文旨在通过统一的多传感器表示学习框架提高机器人触觉感知能力。&lt;h4&gt;背景&lt;/h4&gt;视触传感器用于模拟人类触觉感知，帮助机器人精确理解与操作物体。然而，低标准化特征阻碍了强大的触觉感知系统的发展。&lt;h4&gt;目的&lt;/h4&gt;提出一个解决方法来整合不同的触觉数据来源，并通过统一的多模态表示学习框架促进跨传感器知识转移。&lt;h4&gt;方法&lt;/h4&gt;{'TacQuad': '这是一个从四种不同视触传感器获取的数据集，旨在实现各种传感器之间的直接融合。', 'AnyTouch': '该框架集成静态和动态视角来学习统一体现多层次结构的多传感表示。通过掩码建模捕捉像素级细节并利用跨模式对齐与交叉感应匹配技术增强感知及传输能力。'}&lt;h4&gt;主要发现&lt;/h4&gt;方法在各种数据集上表现优秀，并且能够有效应对真实世界的倾倒任务。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法克服了现有方法的局限性，展示了强大的静态和动态感知能力以及跨传感器转移的能力。&lt;h4&gt;翻译&lt;/h4&gt;视觉-触觉传感器旨在模拟人类触觉感知，使机器人能够精确理解并操作物体。随着时间推移，大量精心设计的视觉-触觉传感器被集成到机器人系统中，以帮助完成各种任务。然而，这些低标准化特征的感官数据特性阻碍了强大触觉感知系统的建立。我们认为解决这个问题的关键在于学习统一的多传感表示，从而整合传感器，并促进它们之间的触觉知识转移。为了实现这种性质的统一表示，我们介绍了TacQuad，这是一个来自四种不同视觉-触觉传感器的数据集，它使各种传感器能够明确融合。认识到人类通过获取包括纹理和压力变化在内的多样化触觉信息来感知物理环境，我们进一步提出从静态和动态角度学习统一多传感表示的方法。通过集成触觉图像和视频，我们提出了AnyTouch，这是一个多层次结构的统一体现静态-动态多传感表示学习框架，旨在增强综合感知能力并使有效的跨感应传输成为可能。这种多层次架构通过掩码建模捕捉触觉数据中的像素级细节，并通过多模式对齐和交叉传感器匹配学习语义级别的无感觉特征来提高感知和可转移性。我们提供了全面的多传感传输分析，并在各种数据集以及现实世界的倾倒任务中验证了我们的方法。实验结果显示，该方法优于现有方法，在多种传感器上展示出卓越的静态和动态感知能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visuo-tactile sensors aim to emulate human tactile perception, enablingrobots to precisely understand and manipulate objects. Over time, numerousmeticulously designed visuo-tactile sensors have been integrated into roboticsystems, aiding in completing various tasks. However, the distinct datacharacteristics of these low-standardized visuo-tactile sensors hinder theestablishment of a powerful tactile perception system. We consider that the keyto addressing this issue lies in learning unified multi-sensor representations,thereby integrating the sensors and promoting tactile knowledge transferbetween them. To achieve unified representation of this nature, we introduceTacQuad, an aligned multi-modal multi-sensor tactile dataset from fourdifferent visuo-tactile sensors, which enables the explicit integration ofvarious sensors. Recognizing that humans perceive the physical environment byacquiring diverse tactile information such as texture and pressure changes, wefurther propose to learn unified multi-sensor representations from both staticand dynamic perspectives. By integrating tactile images and videos, we presentAnyTouch, a unified static-dynamic multi-sensor representation learningframework with a multi-level structure, aimed at both enhancing comprehensiveperceptual abilities and enabling effective cross-sensor transfer. Thismulti-level architecture captures pixel-level details from tactile data viamasked modeling and enhances perception and transferability by learningsemantic-level sensor-agnostic features through multi-modal alignment andcross-sensor matching. We provide a comprehensive analysis of multi-sensortransferability, and validate our method on various datasets and in thereal-world pouring task. Experimental results show that our method outperformsexisting methods, exhibits outstanding static and dynamic perceptioncapabilities across various sensors.</description>
      <author>example@mail.com (Ruoxuan Feng, Jiangyu Hu, Wenke Xia, Tianci Gao, Ao Shen, Yuhao Sun, Bin Fang, Di Hu)</author>
      <guid isPermaLink="false">2502.12191v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>On Creating a Causally Grounded Usable Rating Method for Assessing the Robustness of Foundation Models Supporting Time Series</title>
      <link>http://arxiv.org/abs/2502.12226v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文提出了一个因果框架，用于评估基于基础模型的时间序列（FMTS）预测在输入扰动下的鲁棒性，并通过股票价格预测问题验证了该方法的有效性和实用性。&lt;h4&gt;背景&lt;/h4&gt;基础模型已经在金融等领域提高了时间序列预测的准确性，但它们对输入干扰的脆弱性阻碍了其广泛应用。因此需要一种新的评估工具来提高这些模型的可靠性和接受度。&lt;h4&gt;目的&lt;/h4&gt;提出一个因果框架用于评价FMTS在面对输入扰动时的鲁棒性，并为模型选择和部署提供实用建议。&lt;h4&gt;方法&lt;/h4&gt;以股票价格预测为例，研究了六个最先进的单模态及多模态FMTS模型对六种主要股票的时间序列数据进行评估。同时进行了用户测试来验证框架的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '多模态的FMTS比单一模态版本表现出更好的鲁棒性和准确性', '2': '专门针对时间序列预测任务预训练的模型在鲁棒性和预测准确度方面优于跨多种场景下通用目的预训练的模型'}&lt;h4&gt;结论&lt;/h4&gt;所提出的框架能够有效评估不同FMTS模型的性能，并通过用户测试证明了该框架可以降低比较各种系统鲁棒性的难度。&lt;h4&gt;翻译&lt;/h4&gt;基础模型在金融等领域提高了时间序列预测，但其对输入扰动的脆弱性限制了其应用。为了应对这一挑战，我们提出了一种因果方法来评估FMTS面对输入干扰时的表现，并通过股票价格预测问题测试了六个最先进的时间序列模型的有效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models (FMs) have improved time series forecasting in varioussectors, such as finance, but their vulnerability to input disturbances canhinder their adoption by stakeholders, such as investors and analysts. Toaddress this, we propose a causally grounded rating framework to study therobustness of Foundational Models for Time Series (FMTS) with respect to inputperturbations. We evaluate our approach to the stock price prediction problem,a well-studied problem with easily accessible public data, evaluating sixstate-of-the-art (some multi-modal) FMTS across six prominent stocks spanningthree industries. The ratings proposed by our framework effectively assess therobustness of FMTS and also offer actionable insights for model selection anddeployment. Within the scope of our study, we find that (1) multi-modal FMTSexhibit better robustness and accuracy compared to their uni-modal versionsand, (2) FMTS pre-trained on time series forecasting task exhibit betterrobustness and forecasting accuracy compared to general-purpose FMTSpre-trained across diverse settings. Further, to validate our framework'susability, we conduct a user study showcasing FMTS prediction errors along withour computed ratings. The study confirmed that our ratings reduced thedifficulty for users in comparing the robustness of different systems.</description>
      <author>example@mail.com (Kausik Lakkaraju, Rachneet Kaur, Parisa Zehtabi, Sunandita Patra, Siva Likitha Valluru, Zhen Zeng, Biplav Srivastava, Marco Valtorta)</author>
      <guid isPermaLink="false">2502.12226v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>iMOVE: Instance-Motion-Aware Video Understanding</title>
      <link>http://arxiv.org/abs/2502.11594v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种改进视频大型语言模型（Video Large Language Models）的方法，以提高其对细粒度实例时空运动感知的能力。&lt;h4&gt;背景&lt;/h4&gt;当前的视频理解和时间理解能力在处理复杂和细节丰富的实例运动时存在挑战。&lt;h4&gt;目的&lt;/h4&gt;通过数据和模型两个方面进行改进，从而提升视频大型语言模型的时间感知能力和总体视频理解能力。&lt;h4&gt;方法&lt;/h4&gt;{'数据改进': '创建了iMOVE-IT，这是第一个大规模的以实例运动为意识的视频指令调优数据集，该数据集包含详尽的实例运动注释和时空相互监督任务。', '模型改进': '提出了iMOVE，这是一种基于实例运动感知的视频基础模型，它利用事件感知的空间时间高效建模来保留信息丰富的实例空间时间细节，并采用相对空间时间位置令牌确保对实例空间时间位置的认识。'}&lt;h4&gt;主要发现&lt;/h4&gt;iMOVE在视频时间和总体理解以及长期视频理解方面表现出显著优势。&lt;h4&gt;结论&lt;/h4&gt;该方法为提高视频大型语言模型的时间感知能力和总体视频理解能力提供了一种有效的途径。&lt;h4&gt;翻译&lt;/h4&gt;提升视频大型语言模型细粒度实例时空运动感知的能力，对于改善其时间理解和整体视频理解至关重要。然而，当前的模型在感知详细和复杂的实例运动方面存在困难。为了应对这些挑战，我们从数据和模型两方面进行了改进。在数据层面，我们精心策划了iMOVE-IT，这是第一个大规模以实例运动为意识的视频指令调优数据集，该数据集包含详尽的实例运动注释和时空相互监督任务，提供了广泛的训练来提升模型对实例运动的感知能力。在此基础上，我们引入了iMOVE，这是一种基于实例运动感知的视频基础模型，它利用事件感知的空间时间高效建模来保留信息丰富的实例空间时间细节，并采用相对空间时间位置令牌确保对实例空间时间位置的认识。评估表明，iMOVE不仅在视频时间和总体理解方面表现出色，在长期视频理解中也显示出显著的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Enhancing the fine-grained instance spatiotemporal motion perceptioncapabilities of Video Large Language Models is crucial for improving theirtemporal and general video understanding. However, current models struggle toperceive detailed and complex instance motions. To address these challenges, wehave made improvements from both data and model perspectives. In terms of data,we have meticulously curated iMOVE-IT, the first large-scaleinstance-motion-aware video instruction-tuning dataset. This dataset isenriched with comprehensive instance motion annotations and spatiotemporalmutual-supervision tasks, providing extensive training for the model'sinstance-motion-awareness. Building on this foundation, we introduce iMOVE, aninstance-motion-aware video foundation model that utilizes Event-awareSpatiotemporal Efficient Modeling to retain informative instance spatiotemporalmotion details while maintaining computational efficiency. It also incorporatesRelative Spatiotemporal Position Tokens to ensure awareness of instancespatiotemporal positions. Evaluations indicate that iMOVE excels not only invideo temporal understanding and general video understanding but alsodemonstrates significant advantages in long-term video understanding.</description>
      <author>example@mail.com (Jiaze Li, Yaya Shi, Zongyang Ma, Haoran Xu, Feng Cheng, Huihui Xiao, Ruiwen Kang, Fan Yang, Tingting Gao, Di Zhang)</author>
      <guid isPermaLink="false">2502.11594v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>SessionRec: Next Session Prediction Paradigm For Generative Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2502.10157v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了一种新的下一会话预测范式（NSPP）SessionRec，用于生成式的序列推荐。&lt;h4&gt;背景&lt;/h4&gt;现有传统的下一个项目预测范式（NIPP）与实际的基于会话用户交互存在基本不匹配的问题。&lt;h4&gt;目的&lt;/h4&gt;通过引入会话感知表示学习以及多项目推荐下一会话预测目标来更好地捕捉用户的多样化兴趣。&lt;h4&gt;方法&lt;/h4&gt;采用层次序列聚合进行会话意识表示学习，减少注意力计算复杂性，并在下一会话预测中使用排名损失函数改进生成式序列推荐模型的排序效果。&lt;h4&gt;主要发现&lt;/h4&gt;SessionRec展示了与大型语言模型类似的幂律标度规律，在美团应用中的在线A/B测试表明其有效性。&lt;h4&gt;结论&lt;/h4&gt;通过其无模型特定架构和计算效率，所提出的范式为开发工业规模的生成性推荐系统建立了新的基础。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种新型的下一会话预测范式（NSPP）SessionRec，用于解决传统的下一个项目预测范式与现实世界中的推荐场景之间的根本不匹配。我们的框架通过层次序列聚合引入了基于会话的表示学习，并在下一会话中采用了多项目的推荐目标，以更好地捕捉用户的多样化兴趣。此外，在下一会话预测范式下为会话内的物品加入排名损失可以显著提高生成式序列推荐模型的排序效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce SessionRec, a novel next-session prediction paradigm (NSPP) forgenerative sequential recommendation, addressing the fundamental misalignmentbetween conventional next-item prediction paradigm (NIPP) and real-worldrecommendation scenarios. Unlike NIPP's item-level autoregressive generationthat contradicts actual session-based user interactions, our frameworkintroduces a session-aware representation learning through hierarchicalsequence aggregation (intra/inter-session), reducing attention computationcomplexity while enabling implicit modeling of massive negative interactions,and a session-based prediction objective that better captures users' diverseinterests through multi-item recommendation in next sessions. Moreover, wefound that incorporating a rank loss for items within the session under thenext session prediction paradigm can significantly improve the rankingeffectiveness of generative sequence recommendation models. We also verifiedthat SessionRec exhibits clear power-law scaling laws similar to those observedin LLMs. Extensive experiments conducted on public datasets and online A/B testin Meituan App demonstrate the effectiveness of SessionRec. The proposedparadigm establishes new foundations for developing industrial-scale generativerecommendation systems through its model-agnostic architecture andcomputational efficiency.</description>
      <author>example@mail.com (Lei Huang, Hao Guo, Linzhi Peng, Long Zhang, Xiaoteng Wang, Daoyuan Wang, Shichao Wang, Jinpeng Wang, Lei Wang, Sheng Chen)</author>
      <guid isPermaLink="false">2502.10157v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.13144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://hgao-cv.github.io/RAD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于3DGS的闭环强化学习训练范式，用于自动驾驶算法，以解决因果混淆和开环差距等问题。通过构建逼真的数字副本，使政策能够广泛探索状态空间并处理边缘情况。&lt;h4&gt;背景&lt;/h4&gt;现有端到端自主驾驶（AD）算法通常遵循模仿学习（IL）模式，但面临如因果混淆及开环间隙等挑战。&lt;h4&gt;目的&lt;/h4&gt;建立基于3DGS的闭环强化学习训练范式，以改进自动驾驶策略的学习和安全性。&lt;h4&gt;方法&lt;/h4&gt;利用3DGS技术创建逼真的数字世界，设计特殊奖励引导政策响应关键安全事件，并理解真实世界的因果关系。同时结合模仿学习作为正则化项以更好地与人类驾驶行为对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在各种闭合回路指标中，RAD相比基于IL的方法表现出更强的性能，特别是在碰撞率方面降低了3倍。&lt;h4&gt;结论&lt;/h4&gt;通过闭环评估基准测试和多样化的3DGS环境验证了所提出方法的有效性，并展示了其卓越的安全性和行为一致性。&lt;h4&gt;翻译&lt;/h4&gt;现有的端到端自动驾驶算法多采用模仿学习模式，面临因果混淆及开环差距等挑战。本研究建立了基于3DGS的闭环强化学习训练框架，利用逼真的数字副本实现广泛状态空间探索，有效处理边缘情况，并设计特殊奖励以提升安全性与政策响应能力。为了更好地模拟人类驾驶行为，在RL训练中引入了模仿学习作为正则化项。此外，还构建了一个包含多种未见3DGS环境的闭环评估基准测试集。实验结果表明，相比基于IL的方法，RAD在大多数闭合回路指标上表现更优，特别是在碰撞率方面下降了3倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing end-to-end autonomous driving (AD) algorithms typically follow theImitation Learning (IL) paradigm, which faces challenges such as causalconfusion and the open-loop gap. In this work, we establish a 3DGS-basedclosed-loop Reinforcement Learning (RL) training paradigm. By leveraging 3DGStechniques, we construct a photorealistic digital replica of the real physicalworld, enabling the AD policy to extensively explore the state space and learnto handle out-of-distribution scenarios through large-scale trial and error. Toenhance safety, we design specialized rewards that guide the policy toeffectively respond to safety-critical events and understand real-world causalrelationships. For better alignment with human driving behavior, IL isincorporated into RL training as a regularization term. We introduce aclosed-loop evaluation benchmark consisting of diverse, previously unseen 3DGSenvironments. Compared to IL-based methods, RAD achieves stronger performancein most closed-loop metrics, especially 3x lower collision rate. Abundantclosed-loop results are presented at https://hgao-cv.github.io/RAD.</description>
      <author>example@mail.com (Hao Gao, Shaoyu Chen, Bo Jiang, Bencheng Liao, Yiang Shi, Xiaoyang Guo, Yuechuan Pu, Haoran Yin, Xiangyu Li, Xinbang Zhang, Ying Zhang, Wenyu Liu, Qian Zhang, Xinggang Wang)</author>
      <guid isPermaLink="false">2502.13144v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and Object Manipulation</title>
      <link>http://arxiv.org/abs/2502.13143v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://qizekun.github.io/sofar/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了语义方向的概念，通过自然语言描述对象的方向（例如USB插口的方向或刀具手柄的方向），从而提升机器人理解并处理物体姿态的能力。&lt;h4&gt;背景&lt;/h4&gt;空间智能是具身AI的关键组成部分，它促进了机器人对环境的理解和互动。尽管最近的进步增强了视觉语言模型感知物体位置及位置关系的能力，但它们仍然缺乏精确理解和表达对象方向的能力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决现有系统中关于对象姿态理解的局限性，提出了一种利用自然语言表达语义方向的方法，并通过构建大规模数据集支持这一概念。&lt;h4&gt;方法&lt;/h4&gt;提出了基于自然语言描述物体位置的新概念——语义方向；构建了一个大型数据集OrienText300K，该数据集中包含有三维模型和与几何理解及功能语义相联系的语义方向注释。将语义方向融入视觉语言模型系统中。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，通过采用本文提出的方法，机器人在处理需要精确方向控制的任务时表现出显著提高的能力，例如在Open6DOR测试中的准确率为48.7%，在SIMPLER测试中的准确率高达74.9%。&lt;h4&gt;结论&lt;/h4&gt;利用自然语言来表示物体的方向可以为具身AI系统提供更灵活、更具表现力的解决方案，有助于提升机器人处理复杂任务的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial intelligence is a critical component of embodied AI, promoting robotsto understand and interact with their environments. While recent advances haveenhanced the ability of VLMs to perceive object locations and positionalrelationships, they still lack the capability to precisely understand objectorientations-a key requirement for tasks involving fine-grained manipulations.Addressing this limitation not only requires geometric reasoning but also anexpressive and intuitive way to represent orientation. In this context, wepropose that natural language offers a more flexible representation space thancanonical frames, making it particularly suitable for instruction-followingrobotic systems. In this paper, we introduce the concept of semanticorientation, which defines object orientations using natural language in areference-frame-free manner (e.g., the ''plug-in'' direction of a USB or the''handle'' direction of a knife). To support this, we construct OrienText300K,a large-scale dataset of 3D models annotated with semantic orientations thatlink geometric understanding to functional semantics. By integrating semanticorientation into a VLM system, we enable robots to generate manipulationactions with both positional and orientational constraints. Extensiveexperiments in simulation and real world demonstrate that our approachsignificantly enhances robotic manipulation capabilities, e.g., 48.7% accuracyon Open6DOR and 74.9% accuracy on SIMPLER.</description>
      <author>example@mail.com (Zekun Qi, Wenyao Zhang, Yufei Ding, Runpei Dong, Xinqiang Yu, Jingwen Li, Lingyun Xu, Baoyu Li, Xialin He, Guofan Fan, Jiazhao Zhang, Jiawei He, Jiayuan Gu, Xin Jin, Kaisheng Ma, Zhizheng Zhang, He Wang, Li Yi)</author>
      <guid isPermaLink="false">2502.13143v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RHINO: Learning Real-Time Humanoid-Human-Object Interaction from Human Demonstrations</title>
      <link>http://arxiv.org/abs/2502.13134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://humanoid-interaction.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为RHINO的框架，旨在使类人机器人能够在多模态的人机交互信号中快速理解和响应人类指令，实现即时反馈和中断。&lt;h4&gt;背景&lt;/h4&gt;现有的研究大多关注于分阶段的任务执行，忽视了实时反馈的重要性。为了在日常生活中更好地辅助人类，类人机器人需要能够根据人类的互动信号迅速做出反应。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，使类人机器人能够在任何时间点响应并处理来自人类的不同指令，并确保它们的安全性、灵活性和即时性。&lt;h4&gt;方法&lt;/h4&gt;RHINO是一个分层学习框架，它允许类人机器人通过观察人类与物体的互动以及远程操作的数据来学习反应技能。该框架将交互过程分为两个层次：高层次计划者从实时的人类行为中推断意图；低级控制器基于预测的意图执行即时动作和物体操纵。&lt;h4&gt;主要发现&lt;/h4&gt;RHINO能够在多种场景下有效、灵活且安全地工作，特别是在处理人类指令和保证机器人与环境的安全互动方面表现优异。&lt;h4&gt;结论&lt;/h4&gt;通过引入RHINO框架，类人机器人可以更有效地融入日常生活并提供实时帮助。该研究为未来的人机交互提供了新的视角，并证明了其在提高机器人实用性和用户体验方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;类人机器人已经在步行和操纵等方面展示了成功之处。尽管具备这些基本能力，为了更好地成为人类日常生活的有价值的助手，它们仍然需要快速理解并根据人的互动信号做出反应。然而，大多数现有的研究只关注于多阶段的互动过程，并且忽略了实时反馈的重要性。本文提出了一种框架（RHINO），使类人机器人能够进行即时反馈和中断处理的能力，允许人们随时打断机器人的任务执行，并使得机器人可以立即回应人类的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humanoid robots have shown success in locomotion and manipulation. Despitethese basic abilities, humanoids are still required to quickly understand humaninstructions and react based on human interaction signals to become valuableassistants in human daily life. Unfortunately, most existing works only focuson multi-stage interactions, treating each task separately, and neglectingreal-time feedback. In this work, we aim to empower humanoid robots withreal-time reaction abilities to achieve various tasks, allowing human tointerrupt robots at any time, and making robots respond to humans immediately.To support such abilities, we propose a general humanoid-human-objectinteraction framework, named RHINO, i.e., Real-time Humanoid-human Interactionand Object manipulation. RHINO provides a unified view of reactive motion,instruction-based manipulation, and safety concerns, over multiple human signalmodalities, such as languages, images, and motions. RHINO is a hierarchicallearning framework, enabling humanoids to learn reaction skills fromhuman-human-object demonstrations and teleoperation data. In particular, itdecouples the interaction process into two levels: 1) a high-level plannerinferring human intentions from real-time human behaviors; and 2) a low-levelcontroller achieving reactive motion behaviors and object manipulation skillsbased on the predicted intentions. We evaluate the proposed framework on a realhumanoid robot and demonstrate its effectiveness, flexibility, and safety invarious scenarios.</description>
      <author>example@mail.com (Jingxiao Chen, Xinyao Li, Jiahang Cao, Zhengbang Zhu, Wentao Dong, Minghuan Liu, Ying Wen, Yong Yu, Liqing Zhang, Weinan Zhang)</author>
      <guid isPermaLink="false">2502.13134v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>IM360: Textured Mesh Reconstruction for Large-scale Indoor Mapping with 360$^\circ$ Cameras</title>
      <link>http://arxiv.org/abs/2502.12545v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于室内环境3D映射和渲染的全新360度相机3D重建管道。针对大规模室内场景中存在的纹理缺失与重复区域的问题，IM360方法利用全景图像的宽视野特性，并将球形相机模型集成到SfM管线的核心组件中。&lt;h4&gt;背景&lt;/h4&gt;传统的从运动结构（Structure-from-Motion, SfM）方法在处理大规模室内环境时存在局限性，特别是在纹理不足和重复区域广泛存在的情况下表现不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够全面解决室内3D重建问题的解决方案。该方案结合了神经隐式表面重构技术和基于网格的神经渲染技术，以生成高质量的表面并精炼纹理图。&lt;h4&gt;方法&lt;/h4&gt;IM360方法利用球形相机模型，将全景图像的优势整合到SfM管线中的每个核心组件，并且集成了神经隐式表面重建技术和基于网格的神经渲染技术来提高质量。&lt;h4&gt;主要发现&lt;/h4&gt;在实际测试中，IM360方法相对于现有最优方法（State-of-the-Art, SOTA）显示出了更优越的表现。具体来说，在纹理网格重构、相机定位和注册精度以及高频细节捕捉方面均有显著改进。&lt;h4&gt;结论&lt;/h4&gt;提出的IM360方法在大规模室内场景的3D重建上展示了出色的性能，为室内环境的精细建模提供了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一个用于从360度摄像头获取的数据进行三维映射和渲染的全新三维重建管道。传统基于运动结构的方法可能不适合处理大型室内场景中的纹理缺失及重复区域问题。为了克服这些挑战，我们的方法IM360利用了全景图像的大视野范围，并将球形相机模型整合到SfM流水线的核心组件中。为实现全面的3D重建解决方案，我们结合了一种基于神经隐式的表面重建技术来从稀疏输入数据生成高质量的表面，并采用了基于网格的神经渲染方法来优化纹理图和准确捕捉视角依赖属性，通过组合漫反射和镜面成分。我们在Matterport3D及Stanford2D3D大型室内场景上评估了该管道，并观察到在纹理网格重构、相机定位和注册精度以及高频细节捕捉方面的改进，证明IM360相对于现有最优方法具有优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel 3D reconstruction pipeline for 360$^\circ$ cameras for 3Dmapping and rendering of indoor environments. Traditional Structure-from-Motion(SfM) methods may not work well in large-scale indoor scenes due to theprevalence of textureless and repetitive regions. To overcome these challenges,our approach (IM360) leverages the wide field of view of omnidirectional imagesand integrates the spherical camera model into every core component of the SfMpipeline. In order to develop a comprehensive 3D reconstruction solution, weintegrate a neural implicit surface reconstruction technique to generatehigh-quality surfaces from sparse input data. Additionally, we utilize amesh-based neural rendering approach to refine texture maps and accuratelycapture view-dependent properties by combining diffuse and specular components.We evaluate our pipeline on large-scale indoor scenes from the Matterport3D andStanford2D3D datasets. In practice, IM360 demonstrate superior performance interms of textured mesh reconstruction over SOTA. We observe accuracyimprovements in terms of camera localization and registration as well asrendering high frequency details.</description>
      <author>example@mail.com (Dongki Jung, Jaehoon Choi, Yonghan Lee, Dinesh Manocha)</author>
      <guid isPermaLink="false">2502.12545v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>HOMIE: Humanoid Loco-Manipulation with Isomorphic Exoskeleton Cockpit</title>
      <link>http://arxiv.org/abs/2502.13013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为HOMIE的新系统，该系统整合了一个用于人形机器人操作的政策和一个低成本的外骨骼硬件系统。此系统使得单个操作者能够通过简单设备操控整个机器人的运动。&lt;h4&gt;背景&lt;/h4&gt;当前的人形机器人远程操作系统要么缺乏可靠的低级控制策略，要么难以获取准确的整体肢体控制命令，从而使人形机器人的移动与抓取任务变得困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型人形机器人远程操作舱——HOMIE，以解决现有系统的问题，并促进更加稳定、快速和精确的人形机器人移动和操控。&lt;h4&gt;方法&lt;/h4&gt;通过结合外骨骼双臂装置、动作感应手套及脚踏板的低成本硬件系统以及基于强化学习训练框架设计的新策略。此策略使机器人能够根据任意上身姿态进行行走与下蹲至特定高度，同时收集的数据可用于模仿学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该远程操作舱显著提高了人形机器人的移动和操控效率，加速任务完成并减少重定位错误，并验证了其硬件系统数据在模仿学习中的有效性。&lt;h4&gt;结论&lt;/h4&gt;HOMIE不仅解决了现有系统的问题，还提供了用于模仿学习的有效训练数据。项目开源，可访问https://homietele.github.io/获取更多演示及代码。&lt;h4&gt;翻译&lt;/h4&gt;目前的人形机器人遥操作系统要么缺乏可靠的低级控制策略，要么难以获得精确的整体身体操控命令，这使得远程操作人形机器人为移动操作任务变得困难。为了解决这些问题，我们提出了HOMIE，一种新的基于人形机器人运动策略和低成本外骨骼硬件系统的远程操作舱。该策略使人形机器人能够在任意上身姿态的情况下行走，并蹲下至特定高度。这是通过我们的新颖强化学习训练框架实现的，该框架结合了上半身姿势课程、高度跟踪奖励以及对称性利用，而不依赖任何运动先验知识。配合政策，硬件系统集成了同构外骨骼双臂、一对动作感应手套和一个脚踏板，允许单个操作员完全控制人形机器人。我们的实验表明我们的远程操作系统能够实现更稳定、快速且精确的人形机器人移动与操控任务，加速了任务完成，并消除了逆向动力学方法的重定位错误。我们还验证了由我们系统收集的数据对于模仿学习的有效性。项目全部开源，演示和代码可在此网址中找到: https://homietele.github.io/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current humanoid teleoperation systems either lack reliable low-level controlpolicies, or struggle to acquire accurate whole-body control commands, makingit difficult to teleoperate humanoids for loco-manipulation tasks. To solvethese issues, we propose HOMIE, a novel humanoid teleoperation cockpitintegrates a humanoid loco-manipulation policy and a low-cost exoskeleton-basedhardware system. The policy enables humanoid robots to walk and squat tospecific heights while accommodating arbitrary upper-body poses. This isachieved through our novel reinforcement learning-based training framework thatincorporates upper-body pose curriculum, height-tracking reward, and symmetryutilization, without relying on any motion priors. Complementing the policy,the hardware system integrates isomorphic exoskeleton arms, a pair ofmotion-sensing gloves, and a pedal, allowing a single operator to achieve fullcontrol of the humanoid robot. Our experiments show our cockpit facilitatesmore stable, rapid, and precise humanoid loco-manipulation teleoperation,accelerating task completion and eliminating retargeting errors compared toinverse kinematics-based methods. We also validate the effectiveness of thedata collected by our cockpit for imitation learning. Our project is fullyopen-sourced, demos and code can be found in https://homietele.github.io/.</description>
      <author>example@mail.com (Qingwei Ben, Feiyu Jia, Jia Zeng, Junting Dong, Dahua Lin, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2502.13013v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>D3-ARM: High-Dynamic, Dexterous and Fully Decoupled Cable-driven Robotic Arm</title>
      <link>http://arxiv.org/abs/2502.12963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的运动解耦机制，用于减轻电缆驱动的机械臂在远程操作中出现的移动耦合和电缆布线问题，并通过一个完全解耦且轻量化的D3-Arm机器人手臂验证了该方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;电缆传输使机械臂能够在各种环境中以轻量级、低惯性的关节运行，但同时也带来了运动耦合和电缆布线的问题，这些问题会降低手臂的控制精度和性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的解耦机制来解决由电缆驱动引起的移动耦合问题，并开发出一款高效且稳定的机器人机械臂（D3-Arm）。&lt;h4&gt;方法&lt;/h4&gt;设计了一种低摩擦度的运动解耦机制，通过在关节处安装这些装置制造了一个完全解耦、轻量化的电缆驱动机器人手臂（D3-Arm），所有电气元件均位于底座上。此外，还集成了一个缆线预张紧机构来提高长距离电缆传输的稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;这款776毫米长且拥有六自由度（DOF）、仅重1.6公斤的机械臂，在一系列全面测试中证明了其卓越的表现：平均定位误差为1.29毫米，载荷能力可达2.0千克。这表明所提出的解耦机制在电缆驱动机器人手臂中具有实用性。&lt;h4&gt;结论&lt;/h4&gt;通过D3-Arm的实验结果证实了解耦机制的有效性，并展示了该设计对于实现高性能和高精度电缆驱动机械臂的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的运动解耦机制，用于减轻电缆驱动的机械臂在远程操作中出现的移动耦合和电缆布线问题。通过一系列广泛的测试，表明了这种基于低摩擦度的设计可以提高动力传输效率，并且证明所提出的解耦方法对实现高性能和高精度的电缆驱动机器人手臂的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cable transmission enables motors of robotic arm to operate lightweight andlow-inertia joints remotely in various environments, but it also creates issueswith motion coupling and cable routing that can reduce arm's control precisionand performance. In this paper, we present a novel motion decoupling mechanismwith low-friction to align the cables and efficiently transmit the motor'spower. By arranging these mechanisms at the joints, we fabricate a fullydecoupled and lightweight cable-driven robotic arm called D3-Arm with all theelectrical components be placed at the base. Its 776 mm length moving partboasts six degrees of freedom (DOF) and only 1.6 kg weights. To address theissue of cable slack, a cable-pretension mechanism is integrated to enhance thestability of long-distance cable transmission. Through a series ofcomprehensive tests, D3-Arm demonstrated 1.29 mm average positioning error and2.0 kg payload capacity, proving the practicality of the proposed decouplingmechanisms in cable-driven robotic arm.</description>
      <author>example@mail.com (Hong Luo, Jianle Xu, Shoujie Li, Huayue Liang, Yanbo Chen, Chongkun Xia, Xueqian Wang)</author>
      <guid isPermaLink="false">2502.12963v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RobotIQ: Empowering Mobile Robots with Human-Level Planning for Real-World Execution</title>
      <link>http://arxiv.org/abs/2502.12862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一个名为RobotIQ的框架，该框架使移动机器人具备了类似人类级别的规划能力，并能够通过大型语言模型进行自然语言指令交流。此框架基于ROS架构设计，旨在弥合人与机器之间的差距，让机器人能够理解和执行用户输入的文字或语音命令。&lt;h4&gt;背景&lt;/h4&gt;当前机器人技术在理解复杂的人类指示和任务执行方面面临挑战，尤其是在需要高度智能规划能力的任务中。&lt;h4&gt;目的&lt;/h4&gt;提出一个集成大型语言模型的框架，使得移动机器人可以理解和响应自然语言指令，并能够在广泛的任务上实现人类级别的规划能力和行为适应性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个基于ROS架构的框架RobotIQ，该框架允许机器人理解并执行用户通过文本或语音输入的命令。此外，该系统在模拟和现实世界环境中均进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;RobotIQ成功地将大型语言模型整合到机器人控制系统中，使得机器人能够在导航、操作以及物体定位等任务上表现出色，并且能够从模拟环境中学得的行为迁移到真实场景应用中。&lt;h4&gt;结论&lt;/h4&gt;RobotIQ是一个开源的、易于使用和高度可适应性的机器人库套件，适用于各种类型的机器人。其有效性和实用性已在家庭服务场景中的协助老年人的应用程序中得到验证。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces RobotIQ, a framework that empowers mobile robots withhuman-level planning capabilities, enabling seamless communication via naturallanguage instructions through any Large Language Model. The proposed frameworkis designed in the ROS architecture and aims to bridge the gap between humansand robots, enabling robots to comprehend and execute user-expressed text orvoice commands. Our research encompasses a wide spectrum of robotic tasks,ranging from fundamental logical, mathematical, and learning reasoning fortransferring knowledge in domains like navigation, manipulation, and objectlocalization, enabling the application of learned behaviors from simulatedenvironments to real-world operations. All encapsulated within a modularcrafted robot library suite of API-wise control functions, RobotIQ offers afully functional AI-ROS-based toolset that allows researchers to design anddevelop their own robotic actions tailored to specific applications and robotconfigurations. The effectiveness of the proposed system was tested andvalidated both in simulated and real-world experiments focusing on a homeservice scenario that included an assistive application designed for elderlypeople. RobotIQ with an open-source, easy-to-use, and adaptable robotic librarysuite for any robot can be found at https://github.com/emmarapt/RobotIQ.</description>
      <author>example@mail.com (Emmanuel K. Raptis, Athanasios Ch. Kapoutsis, Elias B. Kosmatopoulos)</author>
      <guid isPermaLink="false">2502.12862v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>InstructRobot: A Model-Free Framework for Mapping Natural Language Instructions into Robot Motion</title>
      <link>http://arxiv.org/abs/2502.12861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一种名为InstructRobot的框架，该框架能够将自然语言指令转换为机器人的物理动作，而无需构建大型数据集或预先了解机器人动力学模型。&lt;h4&gt;背景&lt;/h4&gt;人类与机器人的交互中使用自然语言交流是一个重要的进步。然而，准确地将口头命令转化为物理动作仍然面临挑战，现有的方法需要大量的训练数据且主要适用于最多具有6个自由度的机器人。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法所需的大规模数据集和对机器人动力学模型先验知识的需求问题。&lt;h4&gt;方法&lt;/h4&gt;InstructRobot框架利用强化学习算法，实现语言表示与逆向运动学模型的同时学习，简化整个学习过程。该框架已在具有26个旋转关节的复杂机器人的物体操作任务中得到验证。&lt;h4&gt;主要发现&lt;/h4&gt;通过在复杂的机器人环境中测试，证明了该框架的有效性、鲁棒性和适应性，特别适用于数据集稀缺且难以创建的任务或领域。&lt;h4&gt;结论&lt;/h4&gt;InstructRobot提供了一种直观且可访问的方法来解决使用语言交流训练机器人的挑战，并公开了源代码以供进一步研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了如何利用自然语言命令指导机器人执行物理动作的框架，名为InstructRobot。它克服了传统方法中对大规模数据集及先验动力学模型的需求限制，展示了在复杂环境中的强大适应性和实用性，并提供了一个开源平台促进进一步的研究和发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to communicate with robots using natural language is asignificant step forward in human-robot interaction. However, accuratelytranslating verbal commands into physical actions is promising, but stillpresents challenges. Current approaches require large datasets to train themodels and are limited to robots with a maximum of 6 degrees of freedom. Toaddress these issues, we propose a framework called InstructRobot that mapsnatural language instructions into robot motion without requiring theconstruction of large datasets or prior knowledge of the robot's kinematicsmodel. InstructRobot employs a reinforcement learning algorithm that enablesjoint learning of language representations and inverse kinematics model,simplifying the entire learning process. The proposed framework is validatedusing a complex robot with 26 revolute joints in object manipulation tasks,demonstrating its robustness and adaptability in realistic environments. Theframework can be applied to any task or domain where datasets are scarce anddifficult to create, making it an intuitive and accessible solution to thechallenges of training robots using linguistic communication. Open source codefor the InstructRobot framework and experiments can be accessed athttps://github.com/icleveston/InstructRobot.</description>
      <author>example@mail.com (Iury Cleveston, Alana C. Santana, Paula D. P. Costa, Ricardo R. Gudwin, Alexandre S. Simões, Esther L. Colombini)</author>
      <guid isPermaLink="false">2502.12861v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Applications of Stretch Reflex for the Upper Limb of Musculoskeletal Humanoids: Protective Behavior, Postural Stability, and Active Induction</title>
      <link>http://arxiv.org/abs/2502.12811v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IROS2020&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在类人机器人上嵌入和评估人类反射行为的重要性，并具体分析了伸展反射（即牵张反射）在机器人的应用。&lt;h4&gt;背景&lt;/h4&gt;肌肉骨骼的仿生人体模型具有多种生物模仿的好处，将人类反射特性植入实际机器人中进行评估是研究的重点。目前虽然已经对下肢进行了类似的实验，但上肢的应用还未广泛探索。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过实施伸展反射在类人机器人的手臂部分来发现其潜在应用价值，并探讨参数差异如何影响行为表现。&lt;h4&gt;方法&lt;/h4&gt;文章讨论了实际机器人中伸张反射的实现方式及其主动和被动应用场景，同时分析了不同参数对机器人行为的影响。&lt;h4&gt;主要发现&lt;/h4&gt;实施上肢的伸展反射不仅有助于提高仿人机器人的运动灵活性和反应能力，还能通过调整参数来改变其动作特性。&lt;h4&gt;结论&lt;/h4&gt;上肢伸张反射的应用为未来类人机器人的设计提供了新的思路和技术基础。这项研究强调了进一步探索人体反射机制与机器人集成之间关系的重要性。&lt;h4&gt;翻译&lt;/h4&gt;肌肉骨骼的人形机器人具有多种仿生学上的好处，嵌入并评估人类的反射行为对于实际机器人来说很重要。虽然已经在下肢实现了伸展反射（牵张反射），但本论文将其应用于上肢以发现其潜在的应用价值。本文考虑了在实际机器人中实现伸展反射的方式、主动和被动应用以及由于参数差异引起的行为变化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IROS45743.2020.9341488&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The musculoskeletal humanoid has various biomimetic benefits, and it isimportant that we can embed and evaluate human reflexes in the actual robot.Although stretch reflex has been implemented in lower limbs of musculoskeletalhumanoids, we apply it to the upper limb to discover its useful applications.We consider the implementation of stretch reflex in the actual robot, itsactive/passive applications, and the change in behavior according to thedifference of parameters.</description>
      <author>example@mail.com (Kento Kawaharazuka, Yuya Koga, Kei Tsuzuki, Moritaka Onitsuka, Yuki Asano, Kei Okada, Koji Kawasaki, Masayuki Inaba)</author>
      <guid isPermaLink="false">2502.12811v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Exceeding the Maximum Speed Limit of the Joint Angle for the Redundant Tendon-driven Structures of Musculoskeletal Humanoids</title>
      <link>http://arxiv.org/abs/2502.12808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IROS2020&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出并验证了两种克服冗余肌肉中速度限制的方法，使得多自由度人形机器人能够实现关节角度的最大角速度超越传统极限。&lt;h4&gt;背景&lt;/h4&gt;具有仿生特性的骨骼肌人体型机器人拥有冗余的肌肉结构，这种结构允许其在故障安全和变量刚度控制方面表现出色。然而，在实际应用中存在一个问题，即最大关节角度速度受限于冗余肌肉中最慢的一块。&lt;h4&gt;目的&lt;/h4&gt;提出并验证两种方法来克服由冗余肌肉带来的关节运动速度限制问题。&lt;h4&gt;方法&lt;/h4&gt;设计了能够超出传统速度极限的两种方案，并通过实体机器人实验验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的解决方案在实际应用中证明有效，成功超越了由于最慢冗余肌肉导致的速度上限。&lt;h4&gt;结论&lt;/h4&gt;本研究为未来基于冗余肌肉结构的人形机器人的设计提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;多自由度人形机器人因其具有生物模仿特性而拥有诸多好处，其中最重要的特点之一就是其冗余的肌肉安排。这种冗余可以实现故障安全的冗余驱动以及变量刚度控制。然而，在实践中存在这样一个问题：最大关节角度速度受制于冗余肌肉中最慢的那一块。在这项研究中，我们提出了两种能够超越限制性最高速度的方法，并通过实际机器人的实验验证了这些方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IROS45743.2020.9341510&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The musculoskeletal humanoid has various biomimetic benefits, and theredundant muscle arrangement is one of its most important characteristics. Thisredundancy can achieve fail-safe redundant actuation and variable stiffnesscontrol. However, there is a problem that the maximum joint angle velocity islimited by the slowest muscle among the redundant muscles. In this study, wepropose two methods that can exceed the limited maximum joint angle velocity,and verify the effectiveness with actual robot experiments.</description>
      <author>example@mail.com (Kento Kawaharazuka, Yuya Koga, Kei Tsuzuki, Moritaka Onitsuka, Yuki Asano, Kei Okada, Koji Kawasaki, Masayuki Inaba)</author>
      <guid isPermaLink="false">2502.12808v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Design Optimization of Musculoskeletal Humanoids with Maximization of Redundancy to Compensate for Muscle Rupture</title>
      <link>http://arxiv.org/abs/2502.12803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IROS2021&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了肌肉冗余在类人机器人中的重要性，特别是当一个肌肉失效时仍然保持运动的能力。&lt;h4&gt;背景&lt;/h4&gt;骨骼肌型类人机器人的优势之一是可以通过调整肌肉的排列来控制关节的刚度。然而，许多研究并未关注单一肌肉损坏后系统仍能继续运作的问题。&lt;h4&gt;目的&lt;/h4&gt;优化肌肉排列设计以最大化在某一肌肉失效时仍可施加的最小可用扭矩。&lt;h4&gt;方法&lt;/h4&gt;采用仿真技术对类人机器人Musashi的手肘进行分析，并通过实际机器人的实验验证了该设计策略的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现了优化肌肉布置可以提高机器人在特定条件下（例如单一肌肉损坏）下的性能和稳定性。&lt;h4&gt;结论&lt;/h4&gt;通过对肌肉排列的设计优化，提高了类人机器人的鲁棒性和适应性。&lt;h4&gt;翻译&lt;/h4&gt;骨骼肌型人类机器人具有多种仿生优势，其中允许可变刚度控制的冗余肌肉布置是最重要的特点之一。在这项研究中，我们专注于其中一个冗余特性，即即使一个肌肉损坏，该机器人仍然能够继续移动，这一点在许多研究中尚未被充分考虑。为了充分利用这一优点，通过最大化单一肌肉失效时仍可施加的最小可用扭矩来优化肌肉排列设计。该方法应用于具有骨骼肌结构的人形机器人Musashi的手肘，并从仿真结果中提取了设计策略，然后通过实际机器人的实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IROS51168.2021.9636845&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Musculoskeletal humanoids have various biomimetic advantages, and theredundant muscle arrangement allowing for variable stiffness control is one ofthe most important. In this study, we focus on one feature of the redundancy,which enables the humanoid to keep moving even if one of its muscles breaks, anadvantage that has not been dealt with in many studies. In order to make themost of this advantage, the design of muscle arrangement is optimized byconsidering the maximization of minimum available torque that can be exertedwhen one muscle breaks. This method is applied to the elbow of amusculoskeletal humanoid Musashi with simulations, the design policy isextracted from the optimization results, and its effectiveness is confirmedwith the actual robot.</description>
      <author>example@mail.com (Kento Kawaharazuka, Yasunori Toshimitsu, Manabu Nishiura, Yuya Koga, Yusuke Omura, Yuki Asano, Kei Okada, Koji Kawasaki, Masayuki Inaba)</author>
      <guid isPermaLink="false">2502.12803v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>ExoKit: A Toolkit for Rapid Prototyping of Interactions for Arm-based Exoskeletons</title>
      <link>http://arxiv.org/abs/2502.12747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Conditionally accepted to CHI '25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;ExoKit是一款针对初学者的快速原型制作工具包，用于低精度、功能性的外骨骼原型开发。&lt;h4&gt;背景&lt;/h4&gt;人类与外骨骼之间的交互虽然具有潜力，但因缺乏易于使用的原型设计工具而未被充分探索。这阻碍了设计师轻松地开发定制化外骨骼设计和互动行为。&lt;h4&gt;目的&lt;/h4&gt;通过提供易于制作和重新配置的模块化硬件组件以及简化编程的高级功能抽象，ExoKit旨在降低早期交互设计阶段的门槛，并支持各种经验水平的设计者。&lt;h4&gt;方法&lt;/h4&gt;ExoKit包含用于感应和驱动肩部与肘部关节的模块化硬件组件。此外，它还提供了命令行接口、图形用户界面、Processing库以及微控制器固件等多种编程方式供不同技能水平的人使用。&lt;h4&gt;主要发现&lt;/h4&gt;通过实施的应用案例及两项使用研究证明了ExoKit在外骨骼原型设计中的多功能性和易用性。&lt;h4&gt;结论&lt;/h4&gt;ExoKit为外骨骼的早期互动设计提供了有力支持，展示了其在HCI（人机交互）领域的潜力。&lt;h4&gt;翻译&lt;/h4&gt;外骨骼开辟了一种独特的人体运动与机器人驱动无缝结合的交互空间。尽管有巨大潜力，但由于缺乏易于使用的原型制作工具，人类与外骨骼之间的交互一直是HCI领域的一个未被充分探索的研究方向。我们推出了ExoKit，这是一个针对初学者的DIY（自己动手做）快速原型开发套件，用于低精度、功能性的外骨骼设计，并能支持定制化的互动行为发展。ExoKit包括感应和驱动肩部及肘部关节的模块化硬件组件，这些组件易于制作且可重新配置以适应个性化需求与舒适度。为了简化交互行为的编程过程，我们提出了包含高层次人类-外骨骼互动的功能抽象概念。这些可以方便地通过ExoKit的命令行接口、图形用户界面（GUI）、Processing库或微控制器固件来访问，每种方式都针对不同的经验水平进行设计。实施的应用案例以及两项使用研究的结果表明了ExoKit在外骨骼早期交互设计中的灵活性和易用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3713815&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Exoskeletons open up a unique interaction space that seamlessly integratesusers' body movements with robotic actuation. Despite its potential,human-exoskeleton interaction remains an underexplored area in HCI, largely dueto the lack of accessible prototyping tools that enable designers to easilydevelop exoskeleton designs and customized interactive behaviors. We presentExoKit, a do-it-yourself toolkit for rapid prototyping of low-fidelity,functional exoskeletons targeted at novice roboticists. ExoKit includes modularhardware components for sensing and actuating shoulder and elbow joints, whichare easy to fabricate and (re)configure for customized functionality andwearability. To simplify the programming of interactive behaviors, we proposefunctional abstractions that encapsulate high-level human-exoskeletoninteractions. These can be readily accessed either through ExoKit'scommand-line or graphical user interface, a Processing library, ormicrocontroller firmware, each targeted at different experience levels.Findings from implemented application cases and two usage studies demonstratethe versatility and accessibility of ExoKit for early-stage interaction design.</description>
      <author>example@mail.com (Marie Muehlhaus, Alexander Liggesmeyer, Jürgen Steimle)</author>
      <guid isPermaLink="false">2502.12747v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Form and function in biological filaments: A physicist's review</title>
      <link>http://arxiv.org/abs/2502.12731v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自然界利用延长的形状和丝状结构来构建稳定结构、产生运动，并允许复杂的几何相互作用。&lt;h4&gt;目的&lt;/h4&gt;在本次综述中，我们探讨了不同尺度下生物丝状体的作用。&lt;h4&gt;主要发现&lt;/h4&gt;{'分子水平': '细胞骨架丝提供了一个既牢固又动态的细胞支架', '细胞附属物水平': '类似纤毛和鞭毛等细胞附肢的功能', '微小微生物水平': '蓝藻等丝状微生物在地球上是最成功的种群之一', '长形动物水平': '如蠕虫和蛇等长形动物，其运动方式启发了机器人的类比'}&lt;h4&gt;结论&lt;/h4&gt;强调了一般机制将形式与功能联系起来的原理。物理原则（例如经典弹性及主动物质的非互易性）可以用于追踪跨越约六个数量级长度尺度这些系统的统一主题。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了生物丝状体在不同尺度下的作用，从分子水平到长形动物等不同尺度下探讨了它们的功能，并强调了一般机制将形式与功能联系起来的原理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nature uses elongated shapes and filaments to build stable structures,generate motion, and allow complex geometric interactions. In this Review, weexamine the role of biological filaments across different length scales. Fromthe molecular scale, where cytoskeletal filaments provides a robust but dynamiccellular scaffolding, over the scale of cellular appendages like cilia andflagella, to the scale of filamentous microorganisms like cyanobacteria whichare among the most successful genera on Earth, and even to the scale ofelongated animals like worms and snakes, whose motility modes inspire roboticanalogues. We highlight the general mechanisms that couple form and function.Physical principles, such as classical elasticity and the non-reciprocity ofactive matter can be used to trace unifying themes linking these systemsspanning about six orders of magnitude in length.</description>
      <author>example@mail.com (Jan Cammann, Hannah Laeverenz-Schlogelhofer, Kirsty Y. Wan, Marco G. Mazza)</author>
      <guid isPermaLink="false">2502.12731v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Responsive Noise-Relaying Diffusion Policy: Responsive and Efficient Visuomotor Control</title>
      <link>http://arxiv.org/abs/2502.12724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的机器人模仿学习策略，即响应式噪声中继扩散政策(RNR-DP)，解决了现有Diffusion Policy在处理需要即时反应的任务时的局限性。&lt;h4&gt;背景&lt;/h4&gt;模仿学习是一种高效的机器人任务教学方法。特别是基于条件去噪扩散过程生成动作的Diffusion Policy，在从多模态演示中学习方面表现出色，但依赖于执行多个动作以保持性能并防止模式跳跃。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的策略来解决现有Diffusion Policy响应性不足的问题，同时保留其在任务处理上的优势。&lt;h4&gt;方法&lt;/h4&gt;引入了RNR-DP，该政策通过维护一个噪声中继缓冲区和采用顺序去噪机制，生成基于最新观测的即时、无噪声动作，而将有噪音的动作添加到序列尾部。这种设计确保了动作响应性和运动一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在需要快速反应的任务上，RNR-DP相比Diffusion Policy提高了18%的成功率；而在常规任务中也超过了最佳加速方法6.9%，展示了其计算效率上的优势。&lt;h4&gt;结论&lt;/h4&gt;RNR-DP通过引入噪声中继缓冲区和顺序去噪机制解决了现有策略的响应性问题，并在需要快速反应的任务上表现出色，同时保持了良好的计算效率。&lt;h4&gt;翻译&lt;/h4&gt;模仿学习是一种高效地教机器人执行各种任务的方法。Diffusion Policy利用条件去噪扩散过程生成动作，在从多模态演示中学习方面表现优异。然而，它依赖于执行多个动作来维持性能和防止模式跳跃，这限制了它的响应性，因为动作不是基于最新的观察。为了解决这个问题，我们提出了响应式噪声中继扩散政策(RNR-DP)，该策略维护一个噪声水平逐渐增加的噪声中继缓冲区，并采用顺序去噪机制生成即时、无噪音的动作序列头部和在序列尾部添加有噪音的动作。这确保了动作基于最新的观察并保持运动一致性。这种设计能够处理需要响应控制的任务，通过重用去噪步骤加速动作生成。在敏感于反应的任务上的实验表明，与Diffusion Policy相比，我们实现了18%的成功率提升。进一步对常规任务的评估显示，RNR-DP也超过了最佳加速方法6.9%，突显了其在响应性要求较低场景中的计算效率优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning is an efficient method for teaching robots a variety oftasks. Diffusion Policy, which uses a conditional denoising diffusion processto generate actions, has demonstrated superior performance, particularly inlearning from multi-modal demonstrates. However, it relies on executingmultiple actions to retain performance and prevent mode bouncing, which limitsits responsiveness, as actions are not conditioned on the most recentobservations. To address this, we introduce Responsive Noise-Relaying DiffusionPolicy (RNR-DP), which maintains a noise-relaying buffer with progressivelyincreasing noise levels and employs a sequential denoising mechanism thatgenerates immediate, noise-free actions at the head of the sequence, whileappending noisy actions at the tail. This ensures that actions are responsiveand conditioned on the latest observations, while maintaining motionconsistency through the noise-relaying buffer. This design enables the handlingof tasks requiring responsive control, and accelerates action generation byreusing denoising steps. Experiments on response-sensitive tasks demonstratethat, compared to Diffusion Policy, ours achieves 18% improvement in successrate. Further evaluation on regular tasks demonstrates that RNR-DP also exceedsthe best acceleration method by 6.9%, highlighting its computational efficiencyadvantage in scenarios where responsiveness is less critical.</description>
      <author>example@mail.com (Zhuoqun Chen, Xiu Yuan, Tongzhou Mu, Hao Su)</author>
      <guid isPermaLink="false">2502.12724v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Soft Arm-Motor Thrust Characterization for a Pneumatically Actuated Soft Morphing Quadrotor</title>
      <link>http://arxiv.org/abs/2502.12716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This extended abstract was accepted for RoboSoft Conference, 2025 but  later withdrawn&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文研究了一种软体、气动驱动变形四旋翼无人机的配置空间，并重点分析了其柔性臂在考虑下洗流影响下的精确推力特性。&lt;h4&gt;背景&lt;/h4&gt;传统的四旋翼无人机使用固定的刚性结构，而这种新型的软体无人机采用气动驱动的柔性臂。这种设计引入了电机推力与臂变形之间的复杂非线性相互作用，使得精密控制变得非常具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;对软体无人机配置空间进行实验表征，并特别关注其在考虑下洗流效应的情况下精确推进臂特性的分析。&lt;h4&gt;方法&lt;/h4&gt;通过采用不同的气动压力实现柔性臂的可变工作空间，并在整个飞行过程中监控和控制柔性臂在压缩和扩张时的偏转。实验中还研究了电机产生的下洗流对臂偏转角度的影响。&lt;h4&gt;主要发现&lt;/h4&gt;下洗流显著且随机地影响着软体无人机的稳定性及臂部期望偏转，这种干扰难以实时预测与补偿。&lt;h4&gt;结论&lt;/h4&gt;论文为软体、气动驱动变形四旋翼在实际飞行中可能遇到的问题提供了重要的实验表征和分析基础。这项工作有助于提升对柔性臂精确控制的理解，并为进一步优化该类无人机的设计提供了有价值的指导。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们展示了一种软体、气动驱动变形四旋翼无人机配置空间的实验表征，重点在于其柔性的推进臂在考虑到下洗流影响情况下的精确推力特性分析。不同于传统的刚性结构四旋翼无人机，该软体无人机使用了通过不同压力控制的硅胶柔性臂。这种设计带来了电机产生的推力与臂变形之间的复杂非线性相互作用，增加了实现精密控制的难度。在飞行过程中，安装于柔性臂末端的电机所产生的下洗流显著且随机地干扰着臂偏转角度及系统稳定性，对此进行了实验表征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, an experimental characterization of the configuration space ofa soft, pneumatically actuated morphing quadrotor is presented, with a focus onprecise thrust characterization of its flexible arms, considering the effect ofdownwash. Unlike traditional quadrotors, the soft drone has pneumaticallyactuated arms, introducing complex, nonlinear interactions between motor thrustand arm deformation, which make precise control challenging. The silicone armsare actuated using differential pressure to achieve flexibility and thus have avariable workspace compared to their fixed counter-parts. The deflection of thesoft arms during compression and expansion is controlled throughout the flight.However, in real time, the downwash from the motor attached at the tip of thesoft arm generates a significant and random disturbance on the arm. Thisdisturbance affects both the desired deflection of the arm and the overallstability of the system. To address this factor, an experimentalcharacterization of the effect of downwash on the deflection angle of the armis conducted.</description>
      <author>example@mail.com (Vidya Sumathy, Jakub Haluska, George Nikolokopoulos)</author>
      <guid isPermaLink="false">2502.12716v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Introducing ROADS: A Systematic Comparison of Remote Control Interaction Concepts for Automated Vehicles at Road Works</title>
      <link>http://arxiv.org/abs/2502.12680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to be presented at CHI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;随着车辆自动化技术的成熟，远程监控和干预功能变得越来越重要。这项研究设计并评估了三种人机交互概念（路径规划、轨迹引导和航点引导），结果表明参与者更偏好路径规划方法。&lt;h4&gt;背景&lt;/h4&gt;随着自动驾驶技术的发展，需要强大的远程监控与干预系统来确保车辆在出现故障或复杂路况时能够得到及时的人工介入。这要求人类操作员的角色从持续的驾驶员转变为间歇性的远程操控者。&lt;h4&gt;目的&lt;/h4&gt;评估三种不同的人机交互概念（路径规划、轨迹引导和航点引导）的有效性，为未来自动驾驶汽车的人机接口开发提供指导。&lt;h4&gt;方法&lt;/h4&gt;设计并实施了三个交互概念，并在包含23名参与者的受试内研究中进行了测试，每个参与者都面对着多达四个同时发生的自动化车辆请求。&lt;h4&gt;主要发现&lt;/h4&gt;路径规划的概念得到了最高的偏好度和最佳的可用性表现；轨迹引导解决了最少的问题，但没有具体说明满意度如何。这些结果有助于未来远程协助自动驾驶汽车的人机接口开发。&lt;h4&gt;结论&lt;/h4&gt;研究证明了不同人机交互概念的有效性和局限性，并建议在未来的发展中进一步优化这些系统。&lt;h4&gt;翻译&lt;/h4&gt;随着车辆自动化技术的成熟，需要强大的远程监控和干预功能来应对故障、恶劣驾驶条件或难以导航区域。这要求人类操作员的角色从持续驾驶员转变为间歇性的远程操控者，从而促使开发适合的人机接口。尽管提出了某些界面概念，但没有比较研究。这项工作设计并评估了三种交互模式（路径规划、轨迹引导和航点引导），每个参与者最多面对四个同时发生的自动化车辆请求。结果显示了对路径规划概念的明确偏好，并达到了最高的可用性水平，尽管满意度相对较低。使用轨迹引导时，解决了最少的问题。这些发现为未来专注于远程协助自动驾驶汽车的人机接口开发做出了贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3713476&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As vehicle automation technology continues to mature, there is a necessityfor robust remote monitoring and intervention features. These are essential forintervening during vehicle malfunctions, challenging road conditions, or inareas that are difficult to navigate. This evolution in the role of the humanoperator - from a constant driver to an intermittent teleoperator -necessitates the development of suitable interaction interfaces. While someinterfaces were suggested, a comparative study is missing. We designed,implemented, and evaluated three interaction concepts (path planning,trajectory guidance, and waypoint guidance) with up to four concurrent requestsof automated vehicles in a within-subjects study with N=23 participants. Theresults showed a clear preference for the path planning concept. It also led tothe highest usability but lower satisfaction. With trajectory guidance, thefewest requests were resolved. The study's findings contribute to the ongoingdevelopment of HMIs focused on the remote assistance of automated vehicles.</description>
      <author>example@mail.com (Mark Colley, Jonathan Westhauser, Jonas Andersson, Alexander G. Mirnig, Enrico Rukzio)</author>
      <guid isPermaLink="false">2502.12680v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>SATA: Safe and Adaptive Torque-Based Locomotion Policies Inspired by Animal Learning</title>
      <link>http://arxiv.org/abs/2502.12674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于生物力学原理的SATA框架，用于学习扭矩控制策略，以提高四足机器人在复杂环境中的适应性和安全性。&lt;h4&gt;背景&lt;/h4&gt;当前多数腿部机器人的控制方法采用位置控制，这种方法难以应对训练外的新环境或干扰。动物通过肌肉的伸缩实现平滑且适应性的运动，基于扭矩的方法可以更直接地控制执行器，但其推广受到非线性状态空间和探索效率低下的限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种生物启发式的SATA框架以解决现有方法在复杂环境中的挑战，同时实现在模拟到现实场景中的零样本迁移能力。&lt;h4&gt;方法&lt;/h4&gt;通过模仿动物运动的机械结构和自适应学习机制来设计控制策略，提高早期探索效率，最终获得高性能策略，并实现从模拟环境到真实环境的有效迁移。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明SATA能够在软滑地形、狭窄通道等复杂环境中表现出良好的顺应性和安全性，在面对重大外部干扰时也能保持稳定运行。这为机器人在人类中心场景中的实际部署提供了可能。&lt;h4&gt;结论&lt;/h4&gt;生物启发式的控制策略有助于提高腿部机器人的适应性，通过优化探索阶段的性能可以有效促进扭矩控制方法的学习过程，并具有现实应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent advances in learning-based controllers for legged robots,deployments in human-centric environments remain limited by safety concerns.Most of these approaches use position-based control, where policies outputtarget joint angles that must be processed by a low-level controller (e.g., PDor impedance controllers) to compute joint torques. Although impressive resultshave been achieved in controlled real-world scenarios, these methods oftenstruggle with compliance and adaptability when encountering environments ordisturbances unseen during training, potentially resulting in extreme or unsafebehaviors. Inspired by how animals achieve smooth and adaptive movements bycontrolling muscle extension and contraction, torque-based policies offer apromising alternative by enabling precise and direct control of the actuatorsin torque space. In principle, this approach facilitates more effectiveinteractions with the environment, resulting in safer and more adaptablebehaviors. However, challenges such as a highly nonlinear state space andinefficient exploration during training have hindered their broader adoption.To address these limitations, we propose SATA, a bio-inspired framework thatmimics key biomechanical principles and adaptive learning mechanisms observedin animal locomotion. Our approach effectively addresses the inherentchallenges of learning torque-based policies by significantly improvingearly-stage exploration, leading to high-performance final policies.Remarkably, our method achieves zero-shot sim-to-real transfer. Ourexperimental results indicate that SATA demonstrates remarkable compliance andsafety, even in challenging environments such as soft/slippery terrain ornarrow passages, and under significant external disturbances, highlighting itspotential for practical deployments in human-centric and safety-criticalscenarios.</description>
      <author>example@mail.com (Peizhuo Li, Hongyi Li, Ge Sun, Jin Cheng, Xinrong Yang, Guillaume Bellegarda, Milad Shafiee, Yuhong Cao, Auke Ijspeert, Guillaume Sartoretti)</author>
      <guid isPermaLink="false">2502.12674v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>LiMo-Calib: On-Site Fast LiDAR-Motor Calibration for Quadruped Robot-Based Panoramic 3D Sensing System</title>
      <link>http://arxiv.org/abs/2502.12655v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种高效的现场校准方法LiMo-Calib，用于解决四足机器人搭载的电机化激光雷达系统在高频振动下的校准难题。&lt;h4&gt;背景&lt;/h4&gt;传统的单个激光雷达系统受限于视野范围（FoV）较小的问题，在携带重量有限的移动平台上尤为明显。通过使用集成式可旋转激光雷达可以显著扩大其观测范围，但在四足机器人等动态平台上的应用面临由于高频率振动带来的校准问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需外部参考目标、仅依赖于原始激光雷达扫描几何特征的现场校准方法LiMo-Calib，以提高3D感知精度和效率。&lt;h4&gt;方法&lt;/h4&gt;通过利用点云数据中的正常分布优化特征选择过程，并引入重新加权机制来评估局部平面拟合质量，从而提升算法鲁棒性。同时在四足机器人上进行了实验验证。&lt;h4&gt;主要发现&lt;/h4&gt;所提方法LiMo-Calib显著提高了校准效率和3D感知准确性，在实际应用中表现出色。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法解决了现有校准方案的局限性，并证明了其适用于现实世界中的机器人应用。&lt;h4&gt;翻译&lt;/h4&gt;传统单一激光雷达系统由于视场范围（FoV）有限，导致盲点和环境认知不完整的问题尤为严重，尤其是在负载受限的移动平台上。将电机化激光雷达集成提供了一个实用解决方案，通过大幅扩展传感器的视野并实现适应性全景3D感知。然而，四足机器人上出现的高频振动带来了校准挑战，这种振动能改变激光雷达与电机间的转换关系从而影响感知准确性。现有依赖于人工目标或密集特征提取的传统校准方法在实地应用和实时处理中缺乏可行性。为解决这些局限，我们提出了一种名为LiMo-Calib的有效现场校准方法，它无需外部参考点即可通过直接从原始激光雷达扫描中获取几何特性实现高效校准。该算法通过基于正态分布的特征选择优化过程加快收敛速度的同时保持准确性，并引入重新加权机制评估局部平面拟合质量以提高鲁棒性。我们将此方法在四足机器人搭载的电机化激光雷达系统上进行集成和验证，证明了它显著提升了校准效率与3D感知精度，使之更适合实际中的机器人应用需求。相关演示视频可访问：https://youtu.be/FMINa-sap7g&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conventional single LiDAR systems are inherently constrained by their limitedfield of view (FoV), leading to blind spots and incomplete environmentalawareness, particularly on robotic platforms with strict payload limitations.Integrating a motorized LiDAR offers a practical solution by significantlyexpanding the sensor's FoV and enabling adaptive panoramic 3D sensing. However,the high-frequency vibrations of the quadruped robot introduce calibrationchallenges, causing variations in the LiDAR-motor transformation that degradesensing accuracy. Existing calibration methods that use artificial targets ordense feature extraction lack feasibility for on-site applications andreal-time implementation. To overcome these limitations, we propose LiMo-Calib,an efficient on-site calibration method that eliminates the need for externaltargets by leveraging geometric features directly from raw LiDAR scans.LiMo-Calib optimizes feature selection based on normal distribution toaccelerate convergence while maintaining accuracy and incorporates areweighting mechanism that evaluates local plane fitting quality to enhancerobustness. We integrate and validate the proposed method on a motorized LiDARsystem mounted on a quadruped robot, demonstrating significant improvements incalibration efficiency and 3D sensing accuracy, making LiMo-Calib well-suitedfor real-world robotic applications. The demo video is available at:https://youtu.be/FMINa-sap7g</description>
      <author>example@mail.com (Jianping Li, Zhongyuan Liu, Xinhang Xu, Jinxin Liu, Shenghai Yuan, Lihua Xie)</author>
      <guid isPermaLink="false">2502.12655v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning-based Dynamic Robot-to-Human Handover</title>
      <link>http://arxiv.org/abs/2502.12602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025. For associated videos, see  https://zerotohero7886.github.io/dyn-r2h-handover&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于学习的方法，用于动态的机器人向人类的手递送过程，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;当前大多数手递送方法假设接收者是静止的，而实际情况中的人类往往在移动。这种不匹配导致交互效率低下和用户体验不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种适应于动态环境下的机器人与人类之间的物体传递系统，以提高互动效率及舒适度。&lt;h4&gt;方法&lt;/h4&gt;使用非参数技术生成根据接收者动作连续调整的递送动作，并通过1000个真人之间手递送的数据集训练模型。引入了偏好学习和阻抗控制来优化性能并确保用户安全。&lt;h4&gt;主要发现&lt;/h4&gt;动态手递送比静态手递送在减少传递时间和提高用户体验方面有显著优势，这些优点已经在模拟环境以及实际测试中得到验证。&lt;h4&gt;结论&lt;/h4&gt;该研究为机器人与人类之间的更高效、舒适互动提供了可能的解决方案。视频演示和更多资料可在提供的网址上找到。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：本文提出了一种基于学习的方法用于动态的机器人向人类的手递送过程，解决了将物体传递给移动接收者时遇到的问题。假设在动态手递送中，当机器人根据接收者的动作做出调整时，相比静态手递送（即假定接收者是静止不动的），这样可以实现更高效和舒适的互动。为了验证这一点，我们开发了一种非参数方法来生成连续的手递送运动，这些运动基于接收者的动作，并使用了1000个真人之间手递送的数据集训练模型。我们还结合了偏好学习以提高手递送效果，并应用阻抗控制确保用户安全和适应性。该方案在模拟环境及真实场景中进行了评估，在用户研究中显示，动态手递送相比于静态方法大大减少了手递送时间并提高了用户的舒适度。我们的方法的视频演示和其他相关资料可在此网址上找到：https://zerotohero7886.github.io/dyn-r2h-handover 。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel learning-based approach to dynamic robot-to-humanhandover, addressing the challenges of delivering objects to a moving receiver.We hypothesize that dynamic handover, where the robot adjusts to the receiver'smovements, results in more efficient and comfortable interaction compared tostatic handover, where the receiver is assumed to be stationary. To validatethis, we developed a nonparametric method for generating continuous handovermotion, conditioned on the receiver's movements, and trained the model using adataset of 1,000 human-to-human handover demonstrations. We integratedpreference learning for improved handover effectiveness and applied impedancecontrol to ensure user safety and adaptiveness. The approach was evaluated inboth simulation and real-world settings, with user studies demonstrating thatdynamic handover significantly reduces handover time and improves user comfortcompared to static methods. Videos and demonstrations of our approach areavailable at https://zerotohero7886.github.io/dyn-r2h-handover .</description>
      <author>example@mail.com (Hyeonseong Kim, Chanwoo Kim, Matthew Pan, Kyungjae Lee, Sungjoon Choi)</author>
      <guid isPermaLink="false">2502.12602v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning a High-quality Robotic Wiping Policy Using Systematic Reward Analysis and Visual-Language Model Based Curriculum</title>
      <link>http://arxiv.org/abs/2502.12599v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度强化学习（Deep RL）的方法来解决自主机器人擦拭问题，并通过引入新的奖励机制和视觉-语言模型指导的学习过程来改善该方法。&lt;h4&gt;背景&lt;/h4&gt;自主机器人的擦拭任务在工业制造到医疗保健消毒等众多行业中都很重要。尽管深度强化学习表现出了极大的潜力，但是它往往需要大量的重复性奖励工程工作。&lt;h4&gt;目的&lt;/h4&gt;减少对人工调节的依赖，并提出一种新的有界奖励公式来提高问题可行性。&lt;h4&gt;方法&lt;/h4&gt;1. 分析质量关键性的机器人擦拭任务的收敛情况；2. 提出一个新的有界奖励公式；3. 引入视觉-语言模型（VLM）指导的学习过程，它能够主动监测进度并建议超参数调整。&lt;h4&gt;主要发现&lt;/h4&gt;结合上述方法可以在具有不同曲率、摩擦力和路径点的各种表面上找到合适的擦拭策略。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能有效解决高质量机器人擦拭任务的问题，并展示了一种新的深度强化学习应用途径。&lt;h4&gt;翻译&lt;/h4&gt;自主机器人的擦拭工作在各种行业中非常重要，从工业制造到医疗保健的消毒。尽管深度强化学习已经成为一个有前景的算法，但它经常面临着重复性奖励工程需求高的问题。为了减少对人工调整的依赖，我们首先分析了质量关键性的机器人擦拭任务（需要高质量的擦拭和快速的任务完成）的收敛情况，并指出该问题是难以收敛的，然后提出了一个新的有界奖励公式来解决这个问题。进一步地，通过提出一种新的视觉-语言模型（VLM）基于课程的学习方法，积极监测学习进度并建议超参数调整，从而改进了学习过程。我们证明结合这种新方法可以在具有各种曲率、摩擦力和路径点的表面上找到一个满意的擦拭策略，而基线公式则无法实现这一点。该项目演示可以在这里查看：https://sites.google.com/view/highqualitywiping&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous robotic wiping is an important task in various industries, rangingfrom industrial manufacturing to sanitization in healthcare. Deep reinforcementlearning (Deep RL) has emerged as a promising algorithm, however, it oftensuffers from a high demand for repetitive reward engineering. Instead ofrelying on manual tuning, we first analyze the convergence of quality-criticalrobotic wiping, which requires both high-quality wiping and fast taskcompletion, to show the poor convergence of the problem and propose a newbounded reward formulation to make the problem feasible. Then, we furtherimprove the learning process by proposing a novel visual-language model (VLM)based curriculum, which actively monitors the progress and suggestshyperparameter tuning. We demonstrate that the combined method can find adesirable wiping policy on surfaces with various curvatures, frictions, andwaypoints, which cannot be learned with the baseline formulation. The demo ofthis project can be found at: https://sites.google.com/view/highqualitywiping.</description>
      <author>example@mail.com (Yihong Liu, Dongyeop Kang, Sehoon Ha)</author>
      <guid isPermaLink="false">2502.12599v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Design and Implementation of a Dual Uncrewed Surface Vessel Platform for Bathymetry Research under High-flow Conditions</title>
      <link>http://arxiv.org/abs/2502.12539v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Corresponding author: Iman Soltani (isoltani@ucdavis.edu)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了两个互补的无人水面船系统的设计与实现，旨在解决水下地形测量（测深学）中设备昂贵和操作风险高的问题。&lt;h4&gt;背景&lt;/h4&gt;测深学依赖于声纳技术对水下结构进行测绘。然而，现有的基于船只的操作方式成本高昂、存在人员安全威胁，并且在高流速条件下难以获得稳定的数据采集环境。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过设计并实现两个无人水面船系统来推进自主控制、导航和数据处理技术的研究，特别是针对测深学的应用。&lt;h4&gt;方法&lt;/h4&gt;提出了一个低成本的USV用于导航与控制研究（NAC-USV）和一个高端配置的USV配备高分辨率多波束声纳及后处理硬件（BEP-USV）。这两个系统可以分别用来测试自主避障、稳定性和数据评价技术，同时开放了设计源代码。&lt;h4&gt;主要发现&lt;/h4&gt;通过详细的实验验证，两个系统均展示了良好的性能，在多种操作环境中能够有效进行测深学研究，并且降低了设备和人员的风险。&lt;h4&gt;结论&lt;/h4&gt;本文提供的无人水面船平台为未来的测深学及相关领域提供了重要的工具和支持。这些系统的开放设计可以促进后续的研究和发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文译文是：水下地形测量，即通过声纳测绘水下的地貌特征，通常是依赖于对淹没结构进行声纳扫描来完成的。这些数据对于基础设施健康监测至关重要，但通常需要昂贵的仪器设备支持。由于传感器损坏或船只损失导致的高昂财务风险使得无人水面船（USV）在执行测深任务时受到限制。然而，载人船队的水下地形测量操作成本高、人员安全风险大，并且经常无法达到采集高质量测深数据所需的稳定条件，尤其是在强水流条件下。因此，进一步的研究对于推进自主控制、导航和数据处理技术至关重要，特别是在测深领域的应用中更为重要。目前，缺乏能够同时支持测深领域自动控制和导航研究以及数据评估与后处理的可访问硬件平台。本文通过设计并实施两种互补的无人水面船系统来填补这一空白，一种是低成本USV用于导航与控制研究（NAC-USV），另一种则是配备了高分辨率多波束声纳及其相关硬件用于测深数据质量评估和后处理研究的高端USV（BEP-USV）。NAC-USV平台旨在促进自主、故障安全导航和控制的研究，强调了采集高质量测深数据所需的稳定性和减少设备风险。随后使用与NAC-USV硬件相似配置的BEP-USV进行额外的控制验证，并深入探讨水下地形数据评估和后处理的方法论。本文详细阐述了两个系统的设计实现过程并开源设计。此外，还展示了该系统的有效性在一系列操作场景中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bathymetry, the study of underwater topography, relies on sonar mapping ofsubmerged structures. These measurements, critical for infrastructure healthmonitoring, often require expensive instrumentation. The high financial riskassociated with sensor damage or vessel loss creates a reluctance to deployuncrewed surface vessels (USVs) for bathymetry. However, the crewed-boatbathymetry operations, are costly, pose hazards to personnel, and frequentlyfail to achieve the stable conditions necessary for bathymetry data collection,especially under high currents. Further research is essential to advanceautonomous control, navigation, and data processing technologies, with aparticular focus on bathymetry. There is a notable lack of accessible hardwareplatforms that allow for integrated research in both bathymetry-focusedautonomous control and navigation, as well as data evaluation and processing.This paper addresses this gap through the design and implementation of twocomplementary USV systems tailored for uncrewed bathymetry research. Thisincludes a low-cost USV for Navigation And Control research (NAC-USV) and asecond, high-end USV equipped with a high-resolution multi-beam sonar and theassociated hardware for Bathymetry data quality Evaluation and Post-processingresearch (BEP-USV). The NAC-USV facilitates the investigation of autonomous,fail-safe navigation and control, emphasizing the stability requirements forhigh-quality bathymetry data collection while minimizing the risk to equipment.The BEP-USV, which mirrors the NAC-USV hardware, is then used for additionalcontrol validation and in-depth exploration of bathymetry data evaluation andpost-processing methodologies. We detail the design and implementation of bothsystems, and open source the design. Furthermore, we demonstrate the system'seffectiveness in a range of operational scenarios.</description>
      <author>example@mail.com (Dinesh Kumar, Amin Ghorbanpour, Kin Yen, Iman Soltani)</author>
      <guid isPermaLink="false">2502.12539v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>GSCE: A Prompt Framework with Enhanced Reasoning for Reliable LLM-driven Drone Control</title>
      <link>http://arxiv.org/abs/2502.12531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种增强推理的提示框架GSCE，用于支持可靠的大规模语言模型驱动的无人机控制。&lt;h4&gt;背景&lt;/h4&gt;大规模语言模型（LLMs）在机器人控制中的集成有可能革新自主系统。研究证明了LLMs可以用来支持机器人的操作，但当面对复杂推理任务时，关于解决方案可靠性的担忧和挑战也随之而来。&lt;h4&gt;目的&lt;/h4&gt;提出一种增强推理的提示框架GSCE，以实现可靠的LLM驱动无人机控制。&lt;h4&gt;方法&lt;/h4&gt;GSCE框架包括使用Guidelines（准则）、Skill APIs（技能API）、Constraints（约束）和Examples（示例）构建的新技术组件。该框架具有可靠且符合约束条件的代码生成特点。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验，证明了GSCE可以显著提高不同复杂度任务的成功率和完整性，优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;GSCE展示出用于开发可靠的大规模语言模型驱动的自主无人机系统的潜力。&lt;h4&gt;翻译&lt;/h4&gt;将大型语言模型（LLMs）集成到机器人控制中，包括无人机，有可能革新自主系统。研究表明，可以利用LLMs支持机器人的操作，但当面临需要复杂推理的任务时，对LLM生成解决方案可靠性的担忧和挑战也随之产生。本文提出了一种增强推理的提示框架GSCE，以实现可靠的LLM驱动无人机控制。该框架由使用准则、技能APIs、约束条件和示例构建的新技术组件组成。通过广泛的实验测试了GSCE在不同复杂度任务中对无人机控制的效果，结果显示GSCE可以显著提高成功率和完整性，优于基线方法，展示了其开发可靠的大规模语言模型驱动的自主无人机系统的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of Large Language Models (LLMs) into robotic control,including drones, has the potential to revolutionize autonomous systems.Research studies have demonstrated that LLMs can be leveraged to supportrobotic operations. However, when facing tasks with complex reasoning, concernsand challenges are raised about the reliability of solutions produced by LLMs.In this paper, we propose a prompt framework with enhanced reasoning to enablereliable LLM-driven control for drones. Our framework consists of noveltechnical components designed using Guidelines, Skill APIs, Constraints, andExamples, namely GSCE. GSCE is featured by its reliable andconstraint-compliant code generation. We performed thorough experiments usingGSCE for the control of drones with a wide level of task complexities. Ourexperiment results demonstrate that GSCE can significantly improve task successrates and completeness compared to baseline approaches, highlighting itspotential for reliable LLM-driven autonomous drone systems.</description>
      <author>example@mail.com (Wenhao Wang, Yanyan Li, Long Jiao, Jiawei Yuan)</author>
      <guid isPermaLink="false">2502.12531v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Memory-updated-based Framework for 100% Reliable Flexible Flat Cables Insertion</title>
      <link>http://arxiv.org/abs/2502.12514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种模仿人类行为的新型框架，用于解决柔性扁平电缆（FFC）插入任务中的自动化挑战。&lt;h4&gt;背景&lt;/h4&gt;自动装配线已取代了许多手工劳动，但因反馈和动态操作需求高，FFC插入尚未实现自动化，影响了约11%的全球工业产能。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以精确感知、理解和控制FFC插入过程的框架，以提高插入的成功率并最终实现完全自动化的生产线。&lt;h4&gt;方法&lt;/h4&gt;该框架包括三个模块：感应模块用于收集三维力数据；感知模块将这些数据转换为有意义的物理信号；基于贝叶斯理论的记忆模块用于可靠性估计和控制。&lt;h4&gt;主要发现&lt;/h4&gt;使用此框架的机器人可以检测到0.5毫米的对准误差，并在几次迭代后达到100%的成功率，展示了可靠感知和复杂插入任务中精准控制的能力。&lt;h4&gt;结论&lt;/h4&gt;该工作解决了不稳定的感知和控制问题，为全自动生产线的发展指明了方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic assembly lines have increasingly replaced human labor in varioustasks; however, the automation of Flexible Flat Cable (FFC) insertion remainsunrealized due to its high requirement for effective feedback and dynamicoperation, limiting approximately 11% of global industrial capacity. Despitelots of approaches, like vision-based tactile sensors and reinforcementlearning, having been proposed, the implementation of human-like high-reliableinsertion (i.e., with a 100% success rate in completed insertion) remains a bigchallenge. Drawing inspiration from human behavior in FFC insertion, whichinvolves sensing three-dimensional forces, translating them into physicalconcepts, and continuously improving estimates, we propose a novel framework.This framework includes a sensing module for collecting three-dimensionaltactile data, a perception module for interpreting this data into meaningfulphysical signals, and a memory module based on Bayesian theory for reliabilityestimation and control. This strategy enables the robot to accurately assessits physical state and generate reliable status estimations and correctiveactions. Experimental results demonstrate that the robot using this frameworkcan detect alignment errors of 0.5 mm with an accuracy of 97.92% and thenachieve a 100% success rate in all completed tests after a few iterations. Thiswork addresses the challenges of unreliable perception and control in complexinsertion tasks, highlighting the path toward the development of fullyautomated production lines.</description>
      <author>example@mail.com (Zhengrong Ling, Xiong Yang, Dong Guo, Hongyuan Chang, Tieshan Zhang, Ruijia Zhang, Yajing Shen)</author>
      <guid isPermaLink="false">2502.12514v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Predicate Hierarchies Improve Few-Shot State Classification</title>
      <link>http://arxiv.org/abs/2502.12481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025. First two authors contributed equally. Project page:  https://emilyzjin.github.io/projects/phier.html&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '介绍了一种名为PHIER的模型，该模型通过利用谓词层次结构，在少样本场景下有效推广，并在CALVIN和BEHAVIOR机器人环境中表现出色。', '背景': '对象状态分类及其关系对于许多长期任务至关重要，尤其是在机器人规划和操作中。但是，可能的对象-谓词组合的数量呈指数增长，加上适应新现实环境的需求，使得模型需要能够用少量示例推广到新的查询上。', '目的': '提出了一种名为PHIER的模型，该模型利用谓词层次结构来在少样本场景下有效地推广。', '方法': 'PHIER使用以对象为中心的场景编码器、自监督损失函数（用于推断谓词之间的语义关系）和双曲距离度量（捕捉层级结构），学习图像-谓词对的有结构的潜在空间，从而指导状态分类查询上的推理。', '主要发现': '在少样本、分布外的状态分类任务中显著优于现有方法，并展示了从模拟到真实世界任务的零样本和少量样本推广的强大能力。', '结论': '利用谓词层次结构可以改善在数据有限的情况下进行状态分类任务的表现。'}&lt;h4&gt;翻译&lt;/h4&gt;状态分类是许多长期任务的核心，尤其是在机器人规划和操作中。但是，对象-谓词组合的数量爆炸加上适应新现实环境的需求使得模型需要能够用少量示例推广到新的查询上。为此，我们提出了一种名为PHIER的模型，该模型利用谓词层次结构来在少样本场景下有效地推广。PHIER使用以对象为中心的场景编码器、自监督损失函数和双曲距离度量，捕捉层级结构；它学习图像-谓词对的有结构的潜在空间，从而指导状态分类查询上的推理。我们在CALVIN和BEHAVIOR机器人环境中评估了PHIER，并展示了该模型在少样本、分布外的状态分类中显著优于现有方法，并展示了从模拟到真实世界任务的强大零样本和少量样本推广能力。我们的结果表明，在数据有限的情况下利用谓词层次结构可以改善状态分类任务的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State classification of objects and their relations is core to manylong-horizon tasks, particularly in robot planning and manipulation. However,the combinatorial explosion of possible object-predicate combinations, coupledwith the need to adapt to novel real-world environments, makes it a desideratumfor state classification models to generalize to novel queries with fewexamples. To this end, we propose PHIER, which leverages predicate hierarchiesto generalize effectively in few-shot scenarios. PHIER uses an object-centricscene encoder, self-supervised losses that infer semantic relations betweenpredicates, and a hyperbolic distance metric that captures hierarchicalstructure; it learns a structured latent space of image-predicate pairs thatguides reasoning over state classification queries. We evaluate PHIER in theCALVIN and BEHAVIOR robotic environments and show that PHIER significantlyoutperforms existing methods in few-shot, out-of-distribution stateclassification, and demonstrates strong zero- and few-shot generalization fromsimulated to real-world tasks. Our results demonstrate that leveragingpredicate hierarchies improves performance on state classification tasks withlimited data.</description>
      <author>example@mail.com (Emily Jin, Joy Hsu, Jiajun Wu)</author>
      <guid isPermaLink="false">2502.12481v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RTPD: Penetration Depth calculation using Hardware accelerated Ray-Tracing</title>
      <link>http://arxiv.org/abs/2502.12463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 8 figures, under review for a journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的利用RT-cores计算穿透深度的算法，该算法在不同类型和代次的RTX GPU上进行了测试，并显示出优于现有技术和传统GPU实现的巨大性能优势。&lt;h4&gt;背景&lt;/h4&gt;穿透深度计算对于模拟、元宇宙及机器人等领域至关重要。为了加速此计算过程，人们已经尝试使用并行计算资源如CPU和GPU来优化性能。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的基于RT-cores的算法用于提高穿透深度计算效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型算法，包括基于光线追踪技术提取穿透表面的方法以及计算Hausdorff距离的方法，旨在充分利用现代GPU中的RT-cores进行高效处理。&lt;h4&gt;主要发现&lt;/h4&gt;在不同代次和类型的RTX GPU上测试了所提出的算法，并且结果表明该方法相比最先进的穿透深度计算技术和传统的GPU实现分别快37.66倍和5.33倍。&lt;h4&gt;结论&lt;/h4&gt;研究表明基于RT-cores的方法非常高效，这暗示了RT-cores在广泛的计算任务中具有广泛的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译已经完成并以JSON格式输出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Penetration depth calculation quantifies the extent of overlap between twoobjects and is crucial in fields like simulations, the metaverse, and robotics.Recognizing its significance, efforts have been made to accelerate thiscomputation using parallel computing resources, such as CPUs and GPUs. Unliketraditional GPU cores, modern GPUs incorporate specialized ray-tracing cores(RT-cores) primarily used for rendering applications. We introduce a novelalgorithm for penetration depth calculation that leverages RT-cores. Ourapproach includes a ray-tracing based algorithm for penetration surfaceextraction and another for calculating Hausdorff distance, optimizing the useof RT-cores. We tested our method across various generations of RTX GPUs withdifferent benchmark scenes. The results demonstrated that our algorithmoutperformed a state-of-the-art penetration depth calculation method andconventional GPU implementations by up to 37.66 and 5.33 times, respectively.These findings demonstrate the efficiency of our RT core-based method andsuggest broad applicability for RT-cores in diverse computational tasks.</description>
      <author>example@mail.com (YoungWoo Kim, Sungmin Kwon, Duksu Kim)</author>
      <guid isPermaLink="false">2502.12463v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Multi-vision-based Picking Point Localisation of Target Fruit for Harvesting Robots</title>
      <link>http://arxiv.org/abs/2502.12406v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了用于收获机器人的多视觉定位策略，旨在提高水果采摘的准确性。&lt;h4&gt;背景&lt;/h4&gt;准确识别采收点对于机械采摘至关重要，因为不稳定的抓取可能导致经济损失和果实损坏。&lt;h4&gt;目的&lt;/h4&gt;研究提出并评估了两种基于多视觉的方法：解析法和模型驱动算法，以确定水果的实际几何中心。&lt;h4&gt;方法&lt;/h4&gt;{'数据收集': '使用动作捕捉系统（mocap）收集实际的水果几何中心点，并通过两个RGB-D相机提取不同的表面点Cfix和Ceih。', '检测技术': '首先用解析法探测目标水果的采收点，然后利用各种初级学习和集成学习方法预测水果的几何中心。', '算法比较': '对Adaboost回归等模型驱动定位算法进行了评估，并与单相机系统进行对比。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'效果对比': '多视觉系统的性能优于单摄像头系统，其中最成功的模型基于Adaboost回归方法，收获准确率为88.8%，平均欧氏距离（MED）为4.40mm。', '传统方法表现': '解析法的采摘成功率较低，为81.4%，MED为14.25mm。单相机系统的性能最差，采摘成功率为77.7%，MED为24.02mm。', '实验验证': '通过一系列机器人收获试验验证了多视觉系统对提高采收点定位准确性的重要作用，并展示了更高的采摘成功率'}&lt;h4&gt;结论&lt;/h4&gt;研究表明，基于多视觉的定位策略可以显著改善机械收割中的水果识别和采摘精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents multi-vision-based localisation strategies for harvestingrobots. Identifying picking points accurately is essential for roboticharvesting because insecure grasping can lead to economic loss through fruitdamage and dropping. In this study, two multi-vision-based localisationmethods, namely the analytical approach and model-based algorithms, wereemployed. The actual geometric centre points of fruits were collected using amotion capture system (mocap), and two different surface points Cfix and Ceihwere extracted using two Red-Green-Blue-Depth (RGB-D) cameras. First, thepicking points of the target fruit were detected using analytical methods.Second, various primary and ensemble learning methods were employed to predictthe geometric centre of target fruits by taking surface points as input.Adaboost regression, the most successful model-based localisation algorithm,achieved 88.8% harvesting accuracy with a Mean Euclidean Distance (MED) of 4.40mm, while the analytical approach reached 81.4% picking success with a MED of14.25 mm, both demonstrating better performance than the single-camera, whichhad a picking success rate of 77.7% with a MED of 24.02 mm. To evaluate theeffect of picking point accuracy in collecting fruits, a series of roboticharvesting experiments were performed utilising a collaborative robot (cobot).It is shown that multi-vision systems can improve picking point localisation,resulting in higher success rates of picking in robotic harvesting.</description>
      <author>example@mail.com (C. Beldek, A. Dunn, J. Cunningham, E. Sariyildiz, S. L. Phung, G. Alici)</author>
      <guid isPermaLink="false">2502.12406v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Optimal Transport Barycenter via Nonconvex-Concave Minimax Optimization</title>
      <link>http://arxiv.org/abs/2501.14635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了Wasserstein-Descent $\dot{\mathbb{H}}^1$-Ascent (WDHA) 算法，该算法能够在$m$点网格上计算离散概率分布的精确barycenter。&lt;h4&gt;背景&lt;/h4&gt;最优传输重心（即Wasserstein barycenter）是欧氏空间到概率分布Wasserstein空间中平均的概念扩展。对于在$d&gt;1$维域上的点云上离散的概率分布，求解未正则化的barycenter是一个具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的计算精确barycenter的方法，该方法基于$m$-点网格的输入概率密度函数，并且不依赖于传统的熵正则化技术。&lt;h4&gt;方法&lt;/h4&gt;提出了一个近似线性时间复杂度为$O(m \log{m})$和线性空间复杂度为$O(m)$的WDHA算法，该算法通过交替优化Wasserstein和Sobolev几何结构来求解原始barycenter问题及其对偶Kantorovich势能子问题。&lt;h4&gt;主要发现&lt;/h4&gt;证明了在适当选择步长的情况下，WDHA算法的收敛速率及迭代复杂度，并且实验结果表明相比于现有的Sinkhorn类算法，该方法具有更优的计算效率、可扩展性和准确性。&lt;h4&gt;结论&lt;/h4&gt;提出了一个高效精确求解Wasserstein barycenter问题的新算法，为处理高分辨率二维合成和实际数据提供了可能。&lt;h4&gt;翻译&lt;/h4&gt;最优传输重心（又称为Wasserstein重心）是将平均概念从欧氏空间扩展到概率分布的Wasserstein空间中的基本概念。计算离散在点云上的概率分布的无正则化的barycenter，当领域维度$d &gt; 1$时是一个具有挑战性的任务。大多数用于近似解barycenter问题的实际算法都是基于熵正则化技术的。本文引入了一种几乎线性时间复杂度为$O(m \log{m})$和线性空间复杂度为$O(m)$的原始-对偶算法WDHA（Wasserstein下降$\dot{\mathbb{H}}^1$上升）用于在$m$点网格上计算输入概率密度函数离散化时的确切barycenter。WDHA算法成功的关键在于交替使用两种不同的但密切相关于Wasserstein和Sobolev优化几何的原始barycenter问题及其对偶Kantorovich势能子问题。在合理的假设下，我们建立了当步长适当选择时的WDHA收敛速率与迭代复杂度，并通过高分辨率（例如$1024 \times 1024$图像）二维合成和真实数据证明了其相比现有Sinkhorn型算法具有更优的计算效率、可扩展性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The optimal transport barycenter (a.k.a. Wasserstein barycenter) is afundamental notion of averaging that extends from the Euclidean space to theWasserstein space of probability distributions. Computation of theunregularized barycenter for discretized probability distributions on pointclouds is a challenging task when the domain dimension $d &gt; 1$. Most practicalalgorithms for approximating the barycenter problem are based on entropicregularization. In this paper, we introduce a nearly linear time $O(m \log{m})$and linear space complexity $O(m)$ primal-dual algorithm, theWasserstein-Descent $\dot{\mathbb{H}}^1$-Ascent (WDHA) algorithm, for computingthe exact barycenter when the input probability density functions arediscretized on an $m$-point grid. The key success of the WDHA algorithm hingeson alternating between two different yet closely related Wasserstein andSobolev optimization geometries for the primal barycenter and dual Kantorovichpotential subproblems. Under reasonable assumptions, we establish theconvergence rate and iteration complexity of WDHA to its stationary point whenthe step size is appropriately chosen. Superior computational efficacy,scalability, and accuracy over the existing Sinkhorn-type algorithms aredemonstrated on high-resolution (e.g., $1024 \times 1024$ images) 2D syntheticand real data.</description>
      <author>example@mail.com (Kaheon Kim, Rentian Yao, Changbo Zhu, Xiaohui Chen)</author>
      <guid isPermaLink="false">2501.14635v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
  <item>
      <title>Near-Optimal Online Learning for Multi-Agent Submodular Coordination: Tight Approximation and Communication Efficiency</title>
      <link>http://arxiv.org/abs/2502.05028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一种新的算法（MA-OSMA）以及其改进版（MA-OSEA），旨在解决多代理系统在不确定环境中的子模函数最大化问题，这些问题是机器学习、机器人规划和控制等领域的关键挑战。&lt;h4&gt;背景&lt;/h4&gt;现有方法如OSG算法的近似保证较差且要求完全连接的通信图，在实际应用中存在限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的算法框架（MA-OSMA），通过多线性扩展将离散问题转化为连续优化，减少对完全网络的要求；同时引入避免次优解的新颖梯度方法，并进一步开发了无需投影操作的变种算法（MA-OSEA）以提高计算效率。&lt;h4&gt;方法&lt;/h4&gt;- MA-OSMA算法：使用多线性扩展和共识技术来降低通信图完整性的要求，利用新提出的代理梯度避开次优稳定点；- MA-OSEA算法：通过混合均匀分布有效利用KL散度，减少计算复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明两种算法均能达到$\widetilde{O}(\sqrt{\frac{C_{T}T}{1-eta}})$的遗憾界限，并且对子模目标函数提供了一个显著改善的近似比$(\frac{1-e^{-c}}{c})$，优于现有方法（OSG算法）提供的$(\frac{1}{1+c})$。&lt;h4&gt;结论&lt;/h4&gt;通过基于模拟的多目标跟踪实验验证了提出的MA-OSMA和MA-OSEA算法的有效性，在不确定性环境中协调多个代理协同最大化子模函数方面取得了进展。&lt;h4&gt;翻译&lt;/h4&gt;协调多个代理在不可预测环境下协作最大化子模函数是一个充满应用前景的重要任务，特别是在机器学习、机器人规划和控制领域。现有的解决方案（如OSG算法）因为近似保证不足及需要完全连通的通信图而受到限制。为解决这些问题，我们首先提出了一种MA-OSMA算法，它使用多线性扩展将离散子模最大化问题转换为连续优化问题，并通过共识技术减少了对完整图形结构的依赖要求。此外，MA-OSMA算法利用一种新颖的代理梯度方法来避免陷入次优解点。为了减少MA-OSMA中的计算密集型投影操作，我们还引入了一种无需投影的操作（MA-OSEA）算法，该算法通过混合均匀分布有效使用KL散度。理论上，我们证明了这两个算法在与最优后见比较器的$(\frac{1-e^{-c}}{c})$近似值时能够实现遗憾界限为$\widetilde{O}(\sqrt{\frac{C_{T}T}{1-eta}})$的效果，其中$C_{T}$是最大化序列偏差、$\beta$是网络的谱隙以及$c$是子模目标函数的联合曲率。这一结果显著提升了现有最佳OSG算法提供的$(\frac{1}{1+c})$近似比。最后，我们通过基于模拟的多目标跟踪实验展示了所提出算法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Coordinating multiple agents to collaboratively maximize submodular functionsin unpredictable environments is a critical task with numerous applications inmachine learning, robot planning and control. The existing approaches, such asthe OSG algorithm, are often hindered by their poor approximation guaranteesand the rigid requirement for a fully connected communication graph. To addressthese challenges, we firstly present a $\textbf{MA-OSMA}$ algorithm, whichemploys the multi-linear extension to transfer the discrete submodularmaximization problem into a continuous optimization, thereby allowing us toreduce the strict dependence on a complete graph through consensus techniques.Moreover, $\textbf{MA-OSMA}$ leverages a novel surrogate gradient to avoidsub-optimal stationary points. To eliminate the computationally intensiveprojection operations in $\textbf{MA-OSMA}$, we also introduce aprojection-free $\textbf{MA-OSEA}$ algorithm, which effectively utilizes the KLdivergence by mixing a uniform distribution. Theoretically, we confirm thatboth algorithms achieve a regret bound of$\widetilde{O}(\sqrt{\frac{C_{T}T}{1-\beta}})$ against a$(\frac{1-e^{-c}}{c})$-approximation to the best comparator in hindsight, where$C_{T}$ is the deviation of maximizer sequence, $\beta$ is the spectral gap ofthe network and $c$ is the joint curvature of submodular objectives. Thisresult significantly improves the $(\frac{1}{1+c})$-approximation provided bythe state-of-the-art OSG algorithm. Finally, we demonstrate the effectivenessof our proposed algorithms through simulation-based multi-target tracking.</description>
      <author>example@mail.com (Qixin Zhang, Zongqi Wan, Yu Yang, Li Shen, Dacheng Tao)</author>
      <guid isPermaLink="false">2502.05028v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked Entities</title>
      <link>http://arxiv.org/abs/2502.12128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://ml-jku.github.io/LaM-SLidE/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的生成模型LaM-SLidE，用于时空动力系统的轨迹采样。&lt;h4&gt;背景&lt;/h4&gt;生成模型在深度学习领域取得了显著进展，并显示出对动态系统轨迹采样的强大潜力。然而，与图像和视频生成相比，在大多数动态系统中应用潜在空间建模方法更为困难。&lt;h4&gt;目的&lt;/h4&gt;通过引入标识表示（IDs），使从潜在系统表示检索实体属性成为可能，从而实现追溯性，并结合图神经网络的优势以及最近在图像和视频生成中的效率和可扩展性，提高动力系统的轨迹采样性能。&lt;h4&gt;方法&lt;/h4&gt;LaM-SLidE方法结合了图神经网络的时效性和跟踪能力，与目前用于图像和视频生成模型中预训练编码器和解码器冻结后的潜在空间建模技术的高效性和可伸缩性。它引入标识表示（IDs）以允许从潜在系统表示检索实体属性，从而增强时间追踪。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在不同领域，LaM-SLidE在速度、准确度和泛化能力方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了通过将图神经网络的时效性和跟踪优势与图像及视频生成模型中潜在空间建模技术结合在一起可以提高动力系统的轨迹采样性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative models are spearheading recent progress in deep learning, showingstrong promise for trajectory sampling in dynamical systems as well. However,while latent space modeling paradigms have transformed image and videogeneration, similar approaches are more difficult for most dynamical systems.Such systems -- from chemical molecule structures to collective human behavior-- are described by interactions of entities, making them inherently linked toconnectivity patterns and the traceability of entities over time. Our approach,LaM-SLidE (Latent Space Modeling of Spatial Dynamical Systems via LinkedEntities), combines the advantages of graph neural networks, i.e., thetraceability of entities across time-steps, with the efficiency and scalabilityof recent advances in image and video generation, where pre-trained encoder anddecoder are frozen to enable generative modeling in the latent space. The coreidea of LaM-SLidE is to introduce identifier representations (IDs) to allow forretrieval of entity properties, e.g., entity coordinates, from latent systemrepresentations and thus enables traceability. Experimentally, across differentdomains, we show that LaM-SLidE performs favorably in terms of speed, accuracy,and generalizability. (Code is available athttps://github.com/ml-jku/LaM-SLidE)</description>
      <author>example@mail.com (Florian Sestak, Artur Toshev, Andreas Fürst, Günter Klambauer, Andreas Mayr, Johannes Brandstetter)</author>
      <guid isPermaLink="false">2502.12128v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>PreAdaptFWI: Pretrained-Based Adaptive Residual Learning for Full-Waveform Inversion Without Dataset Dependency</title>
      <link>http://arxiv.org/abs/2502.11913v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合神经网络和全波形反演（FWI）的简单而有效的训练框架，该框架通过适配残差学习模块避免局部最优解。&lt;h4&gt;背景&lt;/h4&gt;全波形反演方法利用地震数据来最小化模拟波形与观测波形之间的差异，以反转地下介质的物理参数。然而由于其固有的病态性，FWI容易陷入局部极小值。&lt;h4&gt;目的&lt;/h4&gt;通过引入神经网络和残差学习模块改进FWI过程稳定性，并减少对特定数据集的依赖。&lt;h4&gt;方法&lt;/h4&gt;提出了一个独立于数据集依赖性的训练框架，在预训练阶段只需要在一个简单的初始模型上进行适度训练，随后在迁移学习阶段通过传统FWI梯度同时更新神经网络和残差学习模块。&lt;h4&gt;主要发现&lt;/h4&gt;该算法能有效地将物理先验知识转化为地层分布的全局表示，并捕捉到相邻层速度变化的细微差异，从而避免局部最优解。实验表明，在不同条件下的两个基准模型上应用此方法均表现出色。&lt;h4&gt;结论&lt;/h4&gt;提出的算法在各种条件下均优于传统FWI及其他相关技术，能够更准确有效地进行全波形反演。&lt;h4&gt;翻译&lt;/h4&gt;摘要：全波形反演（FWI）是一种利用地震数据来反转地下介质物理参数的方法，通过最小化模拟和观测波形之间的差异。由于其病态性质，FWI容易陷入局部极小值。因此，各种研究尝试将神经网络与FWI结合以稳定反演过程。本文提出了一种简单且有效的训练框架，该框架独立于数据集依赖性，并仅需对一个简单的初始模型进行适度预训练即可稳定网络输出。在迁移学习阶段，传统的FWI梯度同时更新了神经网络和提出的自适应残差学习模块，后者学习的是网络输出中大规模分布特征的残差映射，而不是直接拟合目标映射。通过这种协同训练范式，所提算法将物理先验知识有效转化为地层分布的全局表示，并捕捉到相邻层速度变化中的局部细节差异，从而避免了局部极小值。在两个基准模型的各种条件下评估该方法，包括缺乏低频数据、噪声干扰和不同初始模型的情况下，以及相应的消融实验中，一致证明了所提方法的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Full-waveform inversion (FWI) is a method that utilizes seismic data toinvert the physical parameters of subsurface media by minimizing the differencebetween simulated and observed waveforms. Due to its ill-posed nature, FWI issusceptible to getting trapped in local minima. Consequently, various researchefforts have attempted to combine neural networks with FWI to stabilize theinversion process. This study presents a simple yet effective trainingframework that is independent of dataset reliance and requires only moderatepre-training on a simple initial model to stabilize network outputs. During thetransfer learning phase, the conventional FWI gradients will simultaneouslyupdate both the neural network and the proposed adaptive residual learningmodule, which learns the residual mapping of large-scale distribution featuresin the network's output, rather than directly fitting the target mapping.Through this synergistic training paradigm, the proposed algorithm effectivelyinfers the physically-informed prior knowledge into a global representation ofstratigraphic distribution, as well as capturing subtle variations ininter-layer velocities within local details, thereby escaping local optima.Evaluating the method on two benchmark models under various conditions,including absent low-frequency data, noise interference, and differing initialmodels, along with corresponding ablation experiments, consistentlydemonstrates the superiority of the proposed approach.</description>
      <author>example@mail.com (Xintong Dong, Zhengyi Yuan, Jun Lin, Shiqi Dong, Xunqian Tong, Yue Li)</author>
      <guid isPermaLink="false">2502.11913v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling the Power of Complex-Valued Transformers in Wireless Communications</title>
      <link>http://arxiv.org/abs/2502.11151v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE for possible publications&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了复值神经网络（CVNN）在无线通信中的应用，并提出了适用于该领域的复杂值转换器模型。&lt;h4&gt;背景&lt;/h4&gt;利用复数信号的自然表示，复值神经网络在处理无线通信任务中显示出优越性。然而，现有的研究大多集中在简单的复数版本的神经网络架构上，对现代深度学习技术的应用理解不足。&lt;h4&gt;目的&lt;/h4&gt;本文旨在填补复数神经网络在理论和实践上的空白，并提出一种用于无线通信的基本复杂值转换器范式。&lt;h4&gt;方法&lt;/h4&gt;详细描述了CVNN中的各种操作，并通过实验验证了CVNN相较于实数值网络所需的层数更少。此外，针对无线通信的三个代表性应用（信道估计、用户活动检测和预编码设计），开发了定制化的复数变换模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在这三个应用场景中，复杂值转换器的表现优于传统的实数值神经网络方法。&lt;h4&gt;结论&lt;/h4&gt;通过理论分析和实际验证，本文证明了CVNN在无线通信领域的优越性，并为未来的深度学习研究提供了方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Utilizing complex-valued neural networks (CVNNs) in wireless communicationtasks has received growing attention for their ability to provide natural andeffective representation of complex-valued signals and data. However, existingstudies typically employ complex-valued versions of simple neural networkarchitectures. Not only they merely scratch the surface of the extensive rangeof modern deep learning techniques, theoretical understanding of the superiorperformance of CVNNs is missing. To this end, this paper aims to fill both thetheoretical and practice gap of employing CVNNs in wireless communications. Inparticular, we provide a comprehensive description on the various operations inCVNNs and theoretically prove that the CVNN requires fewer layers than thereal-valued counterpart to achieve a given approximation error of a continuousfunction. Furthermore, to advance CVNNs in the field of wirelesscommunications, this paper focuses on the transformer model, which represents amore sophisticated deep learning architecture and has been shown to haveexcellent performance in wireless communications but only in its real-valuedform. In this aspect, we propose a fundamental paradigm of complex-valuedtransformers for wireless communications. Leveraging this structure, we developcustomized complex-valued transformers for three representative applications inwireless communications: channel estimation, user activity detection, andprecoding design. These applications utilize transformers with varying levelsof sophistication and span a variety of tasks, ranging from regression toclassification, supervised to unsupervised learning, and specific module designto end-to-end design. Experimental results demonstrate the superior performanceof the complex-valued transformers for the above three applications compared toother traditional real-valued neural network-based methods.</description>
      <author>example@mail.com (Yang Leng, Qingfeng Lin, Long-Yin Yung, Jingreng Lei, Yang Li, Yik-Chung Wu)</author>
      <guid isPermaLink="false">2502.11151v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis</title>
      <link>http://arxiv.org/abs/2502.11824v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了面向多语言的方面基础情感分析（ABSA）任务，特别是M-ABSA数据集。&lt;h4&gt;背景&lt;/h4&gt;现有的ABSA数据集主要以英语为中心，限制了多语种研究和评估的可能性。&lt;h4&gt;目的&lt;/h4&gt;创建一个涵盖7个领域及21种语言的数据集M-ABSA，以填补现有研究的空白。&lt;h4&gt;方法&lt;/h4&gt;通过自动翻译并结合人工审核的方式构建数据集，侧重于三元组抽取（包括方面术语、类别以及情感极性）。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该数据集适用于多语种和跨领域迁移学习，并且能够评估大规模语言模型的性能。&lt;h4&gt;结论&lt;/h4&gt;M-ABSA数据集因其广泛的覆盖范围和高质量的数据，有望推动多语言ABSA研究的发展。&lt;h4&gt;翻译&lt;/h4&gt;通过自动翻译结合人工审核的过程构建了一个包含7个领域21种语言的大规模平行语料库，为跨语言的情感分析提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Aspect-based sentiment analysis (ABSA) is a crucial task in informationextraction and sentiment analysis, aiming to identify aspects with associatedsentiment elements in text. However, existing ABSA datasets are predominantlyEnglish-centric, limiting the scope for multilingual evaluation and research.To bridge this gap, we present M-ABSA, a comprehensive dataset spanning 7domains and 21 languages, making it the most extensive multilingual paralleldataset for ABSA to date. Our primary focus is on triplet extraction, whichinvolves identifying aspect terms, aspect categories, and sentiment polarities.The dataset is constructed through an automatic translation process with humanreview to ensure quality. We perform extensive experiments using variousbaselines to assess performance and compatibility on M-ABSA. Our empiricalfindings highlight that the dataset enables diverse evaluation tasks, such asmultilingual and multi-domain transfer learning, and large language modelevaluation, underscoring its inclusivity and its potential to driveadvancements in multilingual ABSA research.</description>
      <author>example@mail.com (Chengyan Wu, Bolei Ma, Yihong Liu, Zheyu Zhang, Ningyuan Deng, Yanshu Li, Baolan Chen, Yi Zhang, Barbara Plank, Yun Xue)</author>
      <guid isPermaLink="false">2502.11824v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>Data assimilation performed with robust shape registration and graph neural networks: application to aortic coarctation</title>
      <link>http://arxiv.org/abs/2502.12097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于图像的、特定于患者的血流动力学建模可以提高诊断能力并提供互补见解，有助于更好地理解治疗结果。然而，在临床环境中计算流体动力学模拟仍然相对昂贵。&lt;h4&gt;目的&lt;/h4&gt;探索一种解决方案：形状配准技术，即从一系列可用几何形状中设计一个参考模板几何，并将其通过微分同胚映射到每个个体上，以减少解算器的复杂度并提高机器学习架构的效果。&lt;h4&gt;方法&lt;/h4&gt;比较了最新的图神经网络模型和数据同化策略，在主动脉狭窄背景下用于预测物理量和临床相关生物标志物的表现。&lt;h4&gt;主要发现&lt;/h4&gt;形状配准技术提供了一种自然编码，这种编码可以被机器学习架构利用，并且同时提供了参考计算域，在此域内可以执行高效的维数减少策略。这种方法在处理解剖结构形状的高度变化时具有优势。&lt;h4&gt;结论&lt;/h4&gt;本文的方法和策略为基于图像的、患者特异性血流动力学建模提供了一种有效的途径，有助于提高临床诊断能力和治疗结果理解。&lt;h4&gt;翻译&lt;/h4&gt;图片为基础的，以病人为中心的心血管血液动力模型可以增强诊断效果，并提供补充信息来更好地了解治疗结果。尽管计算流体动力模拟在临床上仍较为昂贵，形状配准技术（将参考模板几何从一系列可用几何中设计并映射到每个个体）为解决这个问题提供了可能的解决方案。研究比较了图神经网络和数据同化策略，在主动脉狭窄背景下用于预测物理量和临床相关生物标志物的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-based, patient-specific modelling of hemodynamics can improvediagnostic capabilities and provide complementary insights to better understandthe hemodynamic treatment outcomes. However, computational fluid dynamicssimulations remain relatively costly in a clinical context. Moreover,projection-based reduced-order models and purely data-driven surrogate modelsstruggle due to the high variability of anatomical shapes in a population. Apossible solution is shape registration: a reference template geometry isdesigned from a cohort of available geometries, which can then bediffeomorphically mapped onto it. This provides a natural encoding that can beexploited by machine learning architectures and, at the same time, a referencecomputational domain in which efficient dimension-reduction strategies can beperformed. We compare state-of-the-art graph neural network models with recentdata assimilation strategies for the prediction of physical quantities andclinically relevant biomarkers in the context of aortic coarctation.</description>
      <author>example@mail.com (Francesco Romor, Felipe Galarce, Jan Brüning, Leonid Goubergrits, Alfonso Caiazzo)</author>
      <guid isPermaLink="false">2502.12097v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>UniGO: A Unified Graph Neural Network for Modeling Opinion Dynamics on Graphs</title>
      <link>http://arxiv.org/abs/2502.11519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WWW2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于建模意见演化的框架UniGO，该框架利用统一的意见动力学模型生成合成数据集，并通过图神经网络有效模拟了意见动态过程。&lt;h4&gt;背景&lt;/h4&gt;社交媒体中的极化和碎片化加剧了用户的偏见，理解意见演变变得越来越重要。虽然意见动力学为研究意见演变提供了可解释性，但将其见解融入预测模型仍具挑战。&lt;h4&gt;目的&lt;/h4&gt;构建统一的意见动力学模型来整合不同的意见融合规则，并生成相应的合成数据集；引入UniGO框架以建模图上的意见演化。&lt;h4&gt;方法&lt;/h4&gt;使用统一意见动态机制生成合成数据集并预训练模型。通过精细-粗糙化机制和图神经网络，有效模拟复杂的意见演进过程，并避免过平滑问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，UniGO在捕捉复杂的意见形成过程以及预测未来演变方面非常有效；使用合成数据预先训练的模型展示了强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文提供了一种基于统一意见动力学的新框架，通过生成性地处理合成数据集来增强真实世界应用中的表现，并验证了这种方法的有效性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了如何构建一个能够整合多种意见融合规则的统一模型，并提出了UniGO框架。该框架利用图神经网络有效模拟复杂的意见动态过程，并展示了在合成和实际数据上的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714636&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Polarization and fragmentation in social media amplify user biases, making itincreasingly important to understand the evolution of opinions. Opiniondynamics provide interpretability for studying opinion evolution, yetincorporating these insights into predictive models remains challenging. Thischallenge arises due to the inherent complexity of the diversity of opinionfusion rules and the difficulty in capturing equilibrium states while avoidingover-smoothing. This paper constructs a unified opinion dynamics model tointegrate different opinion fusion rules and generates corresponding syntheticdatasets. To fully leverage the advantages of unified opinion dynamics, weintroduces UniGO, a framework for modeling opinion evolution on graphs. Using acoarsen-refine mechanism, UniGO efficiently models opinion dynamics through agraph neural network, mitigating over-smoothing while preserving equilibriumphenomena. UniGO leverages pretraining on synthetic datasets, which enhancesits ability to generalize to real-world scenarios, providing a viable paradigmfor applications of opinion dynamics. Experimental results on both syntheticand real-world datasets demonstrate UniGO's effectiveness in capturing complexopinion formation processes and predicting future evolution. The pretrainedmodel also shows strong generalization capability, validating the benefits ofusing synthetic data to boost real-world performance.</description>
      <author>example@mail.com (Hao Li, Hao Jiang, Yuke Zheng, Hao Sun, Wenying Gong)</author>
      <guid isPermaLink="false">2502.11519v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural Deformation Correntropy</title>
      <link>http://arxiv.org/abs/2502.10704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  [ICLR 2025] Project and code at: https://github.com/zikai1/OAReg&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的无监督点云非刚性对齐方法——Occlusion-Aware Registration (OAR)，该方法利用自适应相关熵函数作为局部相似度测量，解决了现有技术在处理遮挡场景时的挑战。&lt;h4&gt;背景&lt;/h4&gt;点云的非刚性对准对于场景理解和重建以及计算机视觉和机器人任务至关重要。最新的隐式变形网络的发展大大减少了对大量标记训练数据的需求，但仍然面临处理遮挡情况的困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无监督方法来改进现有技术在处理点云遮挡问题时的表现。&lt;h4&gt;方法&lt;/h4&gt;利用自适应相关熵函数作为局部相似度测量，并结合非刚性隐式神经表示和最大相关熵准则优化未被遮挡区域的变形，同时引入局部线性重构以确保缺乏对应关系的区域经历物理上合理的形变。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在处理带有遮挡的几何结构时优于或与现有方法竞争，并展示了其在大规模形变、形状插值和存在遮挡干扰下的形状补全等挑战任务中的灵活性。同时，该方法理论上将最大相关熵准则与常用的查默斯距离建立了联系。&lt;h4&gt;结论&lt;/h4&gt;Occlusion-Aware Registration (OAR) 方法通过创新性地利用自适应相关熵函数解决了现有技术在处理点云遮挡问题时的不足，展示了出色的性能和广泛的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;非刚性对齐点云对于场景理解和重建至关重要，并且影响着计算机视觉和机器人领域的多种任务。近年来，隐式变形网络的发展显著减少了非刚性注册对大量标记训练数据的需求。然而，现有的最先进的方法在处理遮挡情况时仍然面临挑战。为了解决这个问题，本文介绍了一种创新的无监督方法——Occlusion-Aware Registration (OAR)，用于非刚性地对齐点云。该方法的关键创新在于使用自适应相关熵函数作为局部相似度测量，使我们能够区分处理各个点。与以往的方法只最小化两个形状之间的总体偏差不同，我们将未标记的隐式神经表示与最大相关熵准则相结合来优化未被遮挡区域的变形，从而有效避免了折叠、撕裂和其他物理上不合理的结果。此外，我们还进行了理论分析，并建立了最大相关熵准则和常用查默斯距离之间的关系，强调了由相关熵诱导的度量可以用作点云分析中的通用标准。另外，我们引入局部线性重构以确保即使在缺乏形状对应区域的情况下也能进行物理上自然的变形。我们的方法相比现有技术取得了优越或竞争性的性能，在处理带有遮挡结构时尤为突出，并展示了其在大规模形变、形状插值和存在遮挡干扰下的形状补全等挑战任务中的多功能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-rigid alignment of point clouds is crucial for scene understanding,reconstruction, and various computer vision and robotics tasks. Recentadvancements in implicit deformation networks for non-rigid registration havesignificantly reduced the reliance on large amounts of annotated training data.However, existing state-of-the-art methods still face challenges in handlingocclusion scenarios. To address this issue, this paper introduces an innovativeunsupervised method called Occlusion-Aware Registration (OAR) for non-rigidlyaligning point clouds. The key innovation of our method lies in the utilizationof the adaptive correntropy function as a localized similarity measure,enabling us to treat individual points distinctly. In contrast to previousapproaches that solely minimize overall deviations between two shapes, wecombine unsupervised implicit neural representations with the maximumcorrentropy criterion to optimize the deformation of unoccluded regions. Thiseffectively avoids collapsed, tearing, and other physically implausibleresults. Moreover, we present a theoretical analysis and establish therelationship between the maximum correntropy criterion and the commonly usedChamfer distance, highlighting that the correntropy-induced metric can beserved as a more universal measure for point cloud analysis. Additionally, weintroduce locally linear reconstruction to ensure that regions lackingcorrespondences between shapes still undergo physically natural deformations.Our method achieves superior or competitive performance compared to existingapproaches, particularly when dealing with occluded geometries. We alsodemonstrate the versatility of our method in challenging tasks such as largedeformations, shape interpolation, and shape completion under occlusiondisturbances.</description>
      <author>example@mail.com (Mingyang Zhao, Gaofeng Meng, Dong-Ming Yan)</author>
      <guid isPermaLink="false">2502.10704v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning of CATE with Kernel Ridge Regression</title>
      <link>http://arxiv.org/abs/2502.11331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的适应性转移学习方法，用于估计条件平均处理效果（CATE），并使用数值研究验证了该方法的有效性和优越性。&lt;h4&gt;背景&lt;/h4&gt;数据的增多促使人们利用一个研究的结果来估算不同目标群体中的治疗效应，但这种迁移学习过程常受到显著协变量变化和有限重叠的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于核岭回归（KRR）的方法进行适应性的转移学习，以便在源与目标人群以及内部对照组之间的有限重叠情况下估计CATE。&lt;h4&gt;方法&lt;/h4&gt;该方法通过将标记的来源数据划分为两部分来进行候选CATE模型的选择：一部分用于训练模型，另一部分和未标注的目标数据一起选择最优模型。&lt;h4&gt;主要发现&lt;/h4&gt;提供了一个理论依据，并通过尖锐的非渐近均方误差界限证明了其对弱重叠和复杂度适应性的有效性。数值研究证实该方法在有限样本中的效率和适应性都优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;通过使用401(k)资格数据集，展示了所提出方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of data has sparked significant interest in leveragingfindings from one study to estimate treatment effects in a different targetpopulation without direct outcome observations. However, the transfer learningprocess is frequently hindered by substantial covariate shift and limitedoverlap between (i) the source and target populations, as well as (ii) thetreatment and control groups within the source. We propose a novel method foroverlap-adaptive transfer learning of conditional average treatment effect(CATE) using kernel ridge regression (KRR). Our approach involves partitioningthe labeled source data into two subsets. The first one is used to traincandidate CATE models based on regression adjustment and pseudo-outcomes. Anoptimal model is then selected using the second subset and unlabeled targetdata, employing another pseudo-outcome-based strategy. We provide a theoreticaljustification for our method through sharp non-asymptotic MSE bounds,highlighting its adaptivity to both weak overlaps and the complexity of CATEfunction. Extensive numerical studies confirm that our method achieves superiorfinite-sample efficiency and adaptability. We conclude by demonstrating theeffectiveness of our approach using a 401(k) eligibility dataset.</description>
      <author>example@mail.com (Seok-Jin Kim, Hongjie Liu, Molei Liu, Kaizheng Wang)</author>
      <guid isPermaLink="false">2502.11331v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>REGNav: Room Expert Guided Image-Goal Navigation</title>
      <link>http://arxiv.org/abs/2502.10785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAAI 2025 Oral&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新的图像目标导航模型，该模型模仿人类行为以提高代理在不同房间环境中导航到目标位置的能力。&lt;h4&gt;背景&lt;/h4&gt;大多数先前的方法通过学习导航策略来解决从观察图像引导智能体到达由另一张图像指定的目标位置的任务。当代理处于与目标图像不同的房间时，识别相似性并推断可能的定位非常具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;本文旨在模仿人类行为，设计一种新的模型，以帮助智能体确定当前观测和目标图像是不是位于同一房间里，并以此来改善导航性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种由房型专家指导的图像目标导航模型(REGNav)。首先对未标记的房间图像进行无监督学习预训练，生成一个能够提取隐藏的房间风格信息并预测两者是否属于同一个房间的关系的房型专家。然后探索了两种不同的融合方法来利用这种关系知识有效地引导代理导航。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的REGNav模型在三个流行基准上的性能优于先前最先进的作品。&lt;h4&gt;结论&lt;/h4&gt;通过模仿人类行为并采用房型专家指导的方法，可以显著提高图像目标导航任务中的智能体表现。&lt;h4&gt;翻译&lt;/h4&gt;图象-目标导航旨在引导代理到达由一张图指定的目标位置。大多数先前的方法是通过学习导航策略来解决这个问题的，该策略提取目标和观察图像的视觉特征、比较它们之间的相似性并预测行为。然而如果代理处于不同于目标图片的位置（例如不同的房间），识别其相似性和推断可能的目标位置变得极其具有挑战性，这可能导致代理迷失方向。从直观上看，当人类执行这个任务时，他们可能会粗略地将当前的观察与目标图像进行比较，并在采取行动之前大致了解自己是否在同一房间内。受到这种直觉的启发，我们试图模仿人的行为并提出了一种由房型专家指导的图象-目标导航模型（REGNav），以使代理能够分析目标和观察图片是否是在同一个房间拍摄的。具体来说，我们首先使用无监督学习技术在收集到未标记的房间图像上训练了一个房型专家。该专家可以提取目标和观察图像中隐藏的房间风格信息，并预测它们之间关于是否属于同一房间的关系。此外，还探讨了两种不同的融合方法来有效地指导代理导航，以利用关系知识。广泛的实验表明，我们的REGNav模型在三个流行的基准测试上超越了现有的最先进的工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-goal navigation aims to steer an agent towards the goal locationspecified by an image. Most prior methods tackle this task by learning anavigation policy, which extracts visual features of goal and observationimages, compares their similarity and predicts actions. However, if the agentis in a different room from the goal image, it's extremely challenging toidentify their similarity and infer the likely goal location, which may resultin the agent wandering around. Intuitively, when humans carry out this task,they may roughly compare the current observation with the goal image, having anapproximate concept of whether they are in the same room before executing theactions. Inspired by this intuition, we try to imitate human behaviour andpropose a Room Expert Guided Image-Goal Navigation model (REGNav) to equip theagent with the ability to analyze whether goal and observation images are takenin the same room. Specifically, we first pre-train a room expert with anunsupervised learning technique on the self-collected unlabelled room images.The expert can extract the hidden room style information of goal andobservation images and predict their relationship about whether they belong tothe same room. In addition, two different fusion approaches are explored toefficiently guide the agent navigation with the room relation knowledge.Extensive experiments show that our REGNav surpasses prior state-of-the-artworks on three popular benchmarks.</description>
      <author>example@mail.com (Pengna Li, Kangyi Wu, Jingwen Fu, Sanping Zhou)</author>
      <guid isPermaLink="false">2502.10785v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond</title>
      <link>http://arxiv.org/abs/2502.12048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本论文综述了基于EEG的多模态生成领域的最新进展，重点讨论了通过GAN、VAE和扩散模型实现的EEG到图像生成以及利用Transformer语言模型和对比学习方法进行的EEG到文本生成。&lt;h4&gt;背景&lt;/h4&gt;脑机接口（BCIs）与生成式人工智能（GenAI）的结合为大脑信号解码开辟了新的领域，使得辅助通信、神经表示学习及多模态融合成为可能。特别是采用EEG技术的非侵入性方法可以将神经活动转化为有意义的输出。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供基于EEG生成式人工智能领域的结构化概览，帮助研究人员和实践者深入了解如何推进大脑信号解码，增强辅助技术，并扩展脑机交互的边界。&lt;h4&gt;方法&lt;/h4&gt;综述了通过GAN、VAE以及扩散模型实现的EEG到图像生成；利用Transformer语言模型及对比学习方法进行的EEG到文本生成；新兴领域包括基于EEG的声音合成。&lt;h4&gt;主要发现&lt;/h4&gt;关键数据集、应用场景、挑战及EEG特征编码方法在生成式方法中起着基础作用。这些技术的应用范围广泛，从辅助通信到神经表示学习以及多模态融合。&lt;h4&gt;结论&lt;/h4&gt;该综述为研究人员和实践者提供了有关基于EEG的生成AI领域的深入见解，并展示了BCI与GenAI结合的可能性及其潜在影响。&lt;h4&gt;翻译&lt;/h4&gt;脑机接口（BCIs）与生成式人工智能（GenAI）的整合开辟了大脑信号解码的新领域，使辅助通信、神经表示学习和多模态融合成为可能。尤其是利用EEG技术的方法提供了将神经活动转化为有意义输出的非侵入性手段。近年来，包括GAN和基于Transformer的大规模语言模型在内的深度学习进步显著提高了基于EEG生成图像、文本和语音的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integration of Brain-Computer Interfaces (BCIs) and Generative ArtificialIntelligence (GenAI) has opened new frontiers in brain signal decoding,enabling assistive communication, neural representation learning, andmultimodal integration. BCIs, particularly those leveragingElectroencephalography (EEG), provide a non-invasive means of translatingneural activity into meaningful outputs. Recent advances in deep learning,including Generative Adversarial Networks (GANs) and Transformer-based LargeLanguage Models (LLMs), have significantly improved EEG-based generation ofimages, text, and speech. This paper provides a literature review of thestate-of-the-art in EEG-based multimodal generation, focusing on (i)EEG-to-image generation through GANs, Variational Autoencoders (VAEs), andDiffusion Models, and (ii) EEG-to-text generation leveraging Transformer basedlanguage models and contrastive learning methods. Additionally, we discuss theemerging domain of EEG-to-speech synthesis, an evolving multimodal frontier. Wehighlight key datasets, use cases, challenges, and EEG feature encoding methodsthat underpin generative approaches. By providing a structured overview ofEEG-based generative AI, this survey aims to equip researchers andpractitioners with insights to advance neural decoding, enhance assistivetechnologies, and expand the frontiers of brain-computer interaction.</description>
      <author>example@mail.com (Shreya Shukla, Jose Torres, Abhijit Mishra, Jacek Gwizdka, Shounak Roychowdhury)</author>
      <guid isPermaLink="false">2502.12048v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>AudioSpa: Spatializing Sound Events with Text</title>
      <link>http://arxiv.org/abs/2502.11219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种基于文本的双耳音频生成技术，结合大型语言模型和声学信息，能够从单声道参考音频中生成具有空间感的双耳音频。&lt;h4&gt;背景&lt;/h4&gt;最近的文本文本到音频（TTA）系统在合成单声道音频方面表现出了强大的性能。然而，将文字转化为提供更沉浸式听觉体验的双耳空间音频的任务尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;提出了一种基于文本指导的双耳音频生成方法，并专注于给定单声道参考音频的情况下进行实验。&lt;h4&gt;方法&lt;/h4&gt;提出了AudioSpa模型，这是一个端到端的方法，使用大型语言模型处理声学和文本信息。同时引入了融合多头注意力（FMHA）机制来增强多模态学习的能力。还设计了一种数据增强策略以生成多样化且具有不同空间位置的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示该模型能够将声音准确地定位在指定的位置，并在定位精度和信号失真方面表现出竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;这项工作为基于文本的双耳音频生成提供了一个初步但有前景的方法，利用大规模语言模型来处理复杂的声学描述。所提出的数据增强策略有助于提高空间化声音事件的能力。&lt;h4&gt;翻译&lt;/h4&gt;最近，文本文本到音频（TTA）系统在合成单声道音频方面表现出色。然而，从文本中生成双耳立体声音频的任务还未被探索。这项工作介绍了基于文本的双耳音频生成技术，并专注于同时给定单声道参考音频的情况。核心问题是如何将特定的声音事件与方向关联起来以创建具有空间感的双耳音频。挑战在于复杂的文本描述和单一来源声音事件数据集的稀缺性。为此，我们提出了AudioSpa模型，这是一个端到端的方法，结合大型语言模型处理声学和文本信息，并提出了一种双耳源定位模型来评估生成音频的质量。此外，还设计了数据增强策略以生成多样化且具有各种空间位置的数据集，使该模型能够将声音事件的空间化至多个位置。实验结果表明该模型在指定位置准确放置声音方面表现出色，在定位精度和信号失真两方面均达到了竞争水平的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-to-audio (TTA) systems have recently demonstrated strong performance insynthesizing monaural audio from text. However, the task of generating binauralspatial audio from text, which provides a more immersive auditory experience byincorporating the sense of spatiality, have not been explored yet. In thiswork, we introduce text-guided binaural audio generation. As an early effort,we focus on the scenario where a monaural reference audio is givenadditionally. The core problem is to associate specific sound events with theirdirections, thereby creating binaural spatial audio. The challenge lies in thecomplexity of textual descriptions and the limited availability ofsingle-source sound event datasets. To address this, we propose AudioSpa, anend-to-end model that applies large language models to process both acousticand textual information. We employ fusion multi-head attention (FMHA) tointegrate text tokens, which enhances the generation capability of themultimodal learning. Additionally, we propose a binaural source localizationmodel to assess the quality of the generated audio. Finally, we design a dataaugmentation strategy to generate diverse datasets, which enables the model tospatialize sound events across various spatial positions. Experimental resultsdemonstrate that our model is able to put sounds at the specified locationsaccurately. It achieves competitive performance in both localization accuracyand signal distortion. Our demonstrations are available athttps://linfeng-feng.github.io/AudioSpa-demo.</description>
      <author>example@mail.com (Linfeng Feng, Lei Zhao, Boyu Zhu, Xiao-Lei Zhang, Xuelong Li)</author>
      <guid isPermaLink="false">2502.11219v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation</title>
      <link>http://arxiv.org/abs/2502.12148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/Gen-Verse/HermesFlow&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;研究揭示了多模态大型语言模型（MLLMs）在理解和生成能力之间存在显著差距，提出了HermesFlow框架以缩小这一差距。&lt;h4&gt;背景&lt;/h4&gt;自回归范式的成功推动了多模态大型语言模型的发展，如Show-o、Transfusion和Emu3等模型在统一的图像理解和生成方面取得了重大进展。然而，研究发现这些模型的理解能力通常比其生成能力更强，两者之间存在显著差异。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架HermesFlow来弥合多模态大型语言模型中理解与生成之间的差距。&lt;h4&gt;方法&lt;/h4&gt;使用同源数据输入来创建理解和生成的偏好数据。通过Pair-DPO和自我对弈迭代优化，利用同源偏好数据有效对接多模态理解和生成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，HermesFlow在缩小多模态理解和生成之间的差距方面优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;研究表明，HermesFlow作为下一代多模态基础模型的一般对齐框架具有巨大的潜力。&lt;h4&gt;翻译&lt;/h4&gt;自回归范式的成功使得多模态大型语言模型（MLLMs）取得了显著进展，强大的模型如Show-o、Transfusion和Emu3在统一的图像理解和生成方面实现了明显的进步。首次揭示了一个共同现象：这些模型的理解能力通常比其生成能力强得多，并且两者之间存在显著差距。基于这一发现，我们提出了HermesFlow框架，这是一个简单而通用的方法，旨在无缝对接多模态大型语言模型中的理解与生成之间的差距。通过使用同源数据作为输入来创建理解和生成的偏好数据集，并利用Pair-DPO和自我对弈迭代优化，该方法有效地将多模态理解和生成进行对齐。广泛的实验表明了我们的方法相对于先前的方法具有显著的优势，特别是在缩小多模态理解和生成之间差距方面。这些发现突显了HermesFlow作为下一代多模态基础模型通用对齐框架的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The remarkable success of the autoregressive paradigm has made significantadvancement in Multimodal Large Language Models (MLLMs), with powerful modelslike Show-o, Transfusion and Emu3 achieving notable progress in unified imageunderstanding and generation. For the first time, we uncover a commonphenomenon: the understanding capabilities of MLLMs are typically stronger thantheir generative capabilities, with a significant gap between the two. Buildingon this insight, we propose HermesFlow, a simple yet general framework designedto seamlessly bridge the gap between understanding and generation in MLLMs.Specifically, we take the homologous data as input to curate homologouspreference data of both understanding and generation. Through Pair-DPO andself-play iterative optimization, HermesFlow effectively aligns multimodalunderstanding and generation using homologous preference data. Extensiveexperiments demonstrate the significant superiority of our approach over priormethods, particularly in narrowing the gap between multimodal understanding andgeneration. These findings highlight the potential of HermesFlow as a generalalignment framework for next-generation multimodal foundation models. Code:https://github.com/Gen-Verse/HermesFlow</description>
      <author>example@mail.com (Ling Yang, Xinchen Zhang, Ye Tian, Chenming Shang, Minghao Xu, Wentao Zhang, Bin Cui)</author>
      <guid isPermaLink="false">2502.12148v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Range and Bird's Eye View Fused Cross-Modal Visual Place Recognition</title>
      <link>http://arxiv.org/abs/2502.11742v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submmitted to IEEE IV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种创新的图像到点云跨模态视觉位置识别（VPR）方法，该方法结合了范围或RGB图像以及鸟瞰图（BEV）图像的信息，并采用全局描述符相似性搜索过程进行重新排序。&lt;h4&gt;背景&lt;/h4&gt;在跨模态VPR任务中，查询是RGB图像，数据库样本为LiDAR点云。这种方法利用了RGB相机的普及性和点云提供的准确空间几何和距离信息的鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效结合范围（或RGB）图像与鸟瞰图（BEV）图像信息的方法，并通过全局描述符相似性搜索过程实现重新排序。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新颖的相似度标签监督技术，以最大限度地利用有限的训练数据。具体来说，采用点平均距离来近似外观相似度，并根据相似度差异将自适应边距融入标准三元组损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在KITTI数据集上显著优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过创新的初始检索与重新排序策略有效结合了范围或RGB图像和鸟瞰图信息，并且能够最大化利用有限训练数据中的信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-to-point cloud cross-modal Visual Place Recognition (VPR) is achallenging task where the query is an RGB image, and the database samples areLiDAR point clouds. Compared to single-modal VPR, this approach benefits fromthe widespread availability of RGB cameras and the robustness of point cloudsin providing accurate spatial geometry and distance information. However,current methods rely on intermediate modalities that capture either thevertical or horizontal field of view, limiting their ability to fully exploitthe complementary information from both sensors. In this work, we propose aninnovative initial retrieval + re-rank method that effectively combinesinformation from range (or RGB) images and Bird's Eye View (BEV) images. Ourapproach relies solely on a computationally efficient global descriptorsimilarity search process to achieve re-ranking. Additionally, we introduce anovel similarity label supervision technique to maximize the utility of limitedtraining data. Specifically, we employ points average distance to approximateappearance similarity and incorporate an adaptive margin, based on similaritydifferences, into the vanilla triplet loss. Experimental results on the KITTIdataset demonstrate that our method significantly outperforms state-of-the-artapproaches.</description>
      <author>example@mail.com (Jianyi Peng, Fan Lu, Bin Li, Yuan Huang, Sanqing Qu, Guang Chen)</author>
      <guid isPermaLink="false">2502.11742v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>PrivilegedDreamer: Explicit Imagination of Privileged Information for Rapid Adaptation of Learned Policies</title>
      <link>http://arxiv.org/abs/2502.11377v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025. Website:  https://morganbyrd03.github.io/icra25_privileged_dreamer/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;许多现实世界中的控制问题涉及不可观察的隐藏参数影响的动力学和目标，从自动驾驶到机器人操作等，这些问题在模拟到实际转移过程中会导致性能下降。为表示这类领域，我们采用了带隐含参数马尔可夫决策过程（HIP-MDP），它用于建模由隐藏变量参数化的转换函数和奖励函数的序列决策问题。&lt;h4&gt;背景&lt;/h4&gt;现实世界中的控制问题通常涉及受不可观察隐藏参数影响的动力学和目标，这导致了从模拟环境到真实环境转移时性能下降的问题。这些问题在各种领域中普遍存在，例如自动驾驶汽车和机器人操作。&lt;h4&gt;目的&lt;/h4&gt;为了解决由未观测的隐藏变量引起的影响，在本文中提出了一种新的基于模型的强化学习框架——Privileged-Dreamer，旨在通过引入一个显式的参数估计模块来有效处理带有隐含参数马尔可夫决策过程（HIP-MDP）的问题。&lt;h4&gt;方法&lt;/h4&gt;该论文提出的Privileged-Dreamer模型利用其独特的双循环架构从有限的历史数据中明确地估计出隐藏的参数，并使我们能够将这些估计出来的参数作为条件作用于模型、行为者和评价器网络上。&lt;h4&gt;主要发现&lt;/h4&gt;对五种不同的HIP-MDP任务进行的经验分析表明，Privileged-Dreamer框架在性能上优于现有的基于模型的方法、无模型方法以及领域适应学习算法。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了通过显式地估计隐藏参数并在强化学习过程中考虑这些参数的有效性。实验结果表明，在处理受不可观测变量影响的复杂环境时，Privileged-Dreamer能够显著提高性能和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;许多现实世界中的控制问题涉及由未观察到的隐藏参数影响的动力学和目标，这些问题在从模拟转移到真实系统的过程中会引起性能下降。为了表示这些类型的问题领域，我们采用了带有隐含参数马尔可夫决策过程（HIP-MDP）。HIP-MDP建模了序列决策问题，在这些问题中，隐藏变量参数化转换函数和奖励函数。现有方法，如领域随机化、领域适应和元学习等，简单地将隐藏参数的影响视为额外的方差，并且经常难以有效处理带有隐含参数马尔可夫决策过程（HIP-MDP）的问题，特别是在奖励函数由隐藏变量参数化的情况下。我们提出了Privileged-Dreamer，这是一种基于模型的强化学习框架，它通过引入显式的参数估计模块扩展了现有的基于模型的方法。Privileged-Dreamer具有其新颖的双循环架构，从有限的历史数据中明确地估计出隐藏的参数，并允许我们将这些估计出来的参数作为条件作用于模型、行为者和评价器网络上。在五种不同的HIP-MDP任务上的经验分析表明，Privileged-Dreamer优于现有的基于模型的、无模型的和领域适应学习算法。此外，我们进行了消融研究以证明所提出架构中每个组件的必要性。&lt;h4&gt;实验验证&lt;/h4&gt;通过一系列实验，论文展示了提出的框架在五种不同的HIP-MDP任务上均表现出色，并且显著超越了现有技术方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Numerous real-world control problems involve dynamics and objectives affectedby unobservable hidden pa- rameters, ranging from autonomous driving to roboticmanipu- lation, which cause performance degradation during sim-to-realtransfer. To represent these kinds of domains, we adopt hidden- parameterMarkov decision processes (HIP-MDPs), which model sequential decision problemswhere hidden variables parameterize transition and reward functions. Existingap- proaches, such as domain randomization, domain adaptation, andmeta-learning, simply treat the effect of hidden param- eters as additionalvariance and often struggle to effectively handle HIP-MDP problems, especiallywhen the rewards are parameterized by hidden variables. We introducePrivileged- Dreamer, a model-based reinforcement learning framework thatextends the existing model-based approach by incorporating an explicitparameter estimation module. PrivilegedDreamer features its novel dualrecurrent architecture that explicitly estimates hidden parameters from limitedhistorical data and enables us to condition the model, actor, and criticnetworks on these estimated parameters. Our empirical analysis on five diverseHIP-MDP tasks demonstrates that PrivilegedDreamer outperforms state-of-the-artmodel-based, model-free, and do- main adaptation learning algorithms.Additionally, we conduct ablation studies to justify the inclusion of eachcomponent in the proposed architecture.</description>
      <author>example@mail.com (Morgan Byrd, Jackson Crandell, Mili Das, Jessica Inman, Robert Wright, Sehoon Ha)</author>
      <guid isPermaLink="false">2502.11377v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A MIMO Wireless Channel Foundation Model via CIR-CSI Consistency</title>
      <link>http://arxiv.org/abs/2502.11965v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2025 ICMLCN accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于自我监督学习的多输入多输出（MIMO）无线信道基础模型CSI-CLIP。&lt;h4&gt;背景&lt;/h4&gt;在人工智能领域，自监督学习通过利用大规模未标记数据集进行预训练，在泛化能力方面表现出了优越性。这对于适应各种场景的无线通信模型尤为重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的MIMO无线信道基础模型，以提高跨场景的适应性和特征提取的能力。&lt;h4&gt;方法&lt;/h4&gt;该论文创新地将通道状态信息(CSI)和通道脉冲响应(CIR)视为自然对齐的多模态数据，并提出了CSI-CLIP模型。通过有效地捕捉CIR和CSI的联合表示，模型表现出卓越的跨场景适应性和稳健性特征提取能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在定位任务中，CSI-CLIP将平均误差距离减少了22%；在波束管理任务中，与传统的监督方法相比，准确率提高了1%，并在信道识别任务中也有所提升。这些改进不仅突显了CSI-CLIP在整合感知和通信方面的潜力和价值，还展示了其相对于现有技术的重大优势。&lt;h4&gt;结论&lt;/h4&gt;将CSI和CIR视为多模态对，并通过对比学习为无线通道基础模型开辟了新的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的中文翻译是：在人工智能领域，自监督学习通过利用大规模未标记数据集进行预训练，在泛化能力方面表现出了优越性。这对于适应各种场景的无线通信模型尤为重要。该论文创新地将通道状态信息(CSI)和通道脉冲响应(CIR)视为自然对齐的多模态数据，并提出了CSI-CLIP模型。通过有效地捕捉CIR和CSI的联合表示，模型表现出卓越的跨场景适应性和稳健性特征提取能力。实验结果显示，在定位任务中，CSI-CLIP将平均误差距离减少了22%；在波束管理任务中，与传统的监督方法相比，准确率提高了1%，并在信道识别任务中也有所提升。这些改进不仅突显了CSI-CLIP在整合感知和通信方面的潜力和价值，还展示了其相对于现有技术的重大优势。将CSI和CIR视为多模态对，并通过对比学习为无线通道基础模型开辟了新的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the field of artificial intelligence, self-supervised learning hasdemonstrated superior generalization capabilities by leveraging large-scaleunlabeled datasets for pretraining, which is especially critical for wirelesscommunication models to adapt to a variety of scenarios. This paperinnovatively treats Channel State Information (CSI) and Channel ImpulseResponse (CIR) as naturally aligned multi-modal data and proposes the firstMIMO wireless channel foundation model, named CSI-CLIP. By effectivelycapturing the joint representations of both CIR and CSI, CSI-CLIP exhibitsremarkable adaptability across scenarios and robust feature extractioncapabilities. Experimental results show that in positioning task, CSI-CLIPreduces the mean error distance by 22%; in beam management task, it increasesaccuracy by 1% compared to traditional supervised methods, as well as in thechannel identification task. These improvements not only highlight thepotential and value of CSI-CLIP in integrating sensing and communication butalso demonstrate its significant advantages over existing techniques. Moreover,viewing CSI and CIR as multi-modal pairs and contrastive learning for wirelesschannel foundation model open up new research directions in the domain of MIMOwireless communications.</description>
      <author>example@mail.com (Jun Jiang, Wenjun Yu, Yunfan Li, Yuan Gao, Shugong Xu)</author>
      <guid isPermaLink="false">2502.11965v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A GNN-based Spectral Filtering Mechanism for Imbalance Classification in Network Digital Twin</title>
      <link>http://arxiv.org/abs/2502.11505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2406.06595&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图神经网络模型Class-Fourier Graph Neural Network (CF-GNN)，该模型通过引入类特定的谱滤波机制，解决了5G核心网络数字孪生中的多类别不平衡分类问题。&lt;h4&gt;背景&lt;/h4&gt;在第五代（5G）核心网络的数字孪生系统中，由于罕见故障类型的出现以及复杂的数据结构，传统的图神经网络难以准确地进行故障类型识别。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法在处理复杂且不均衡分布数据时的不足，本文旨在提出一种能够有效解决多类别不平衡问题的新模型，并探讨其在网络数字孪生系统中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;提出的CF-GNN引入了类特定的谱滤波机制，该机制通过估计每个类别的独特谱滤波器来确保精确分类。利用特征值和特征向量的谱滤波技术可以捕捉并适应少数类别数据的变化，从而实现精准的类特异性特征区分。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CF-GNN能够有效提高数字孪生系统的多类别不平衡数据处理能力，并能为改进现有分类器技术和深入研究网络数字孪生系统中的多类别不平衡问题提供新思路。&lt;h4&gt;结论&lt;/h4&gt;提出的Class-Fourier Graph Neural Network (CF-GNN) 在处理5G核心网络的数字孪生中遇到的复杂和不均衡分布的数据时，表现出了卓越的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks are gaining attention in Fifth-Generation (5G) corenetwork digital twins, which are data-driven complex systems with numerouscomponents. Analyzing these data can be challenging due to rare failure types,leading to imbalanced classification in multiclass settings. Digital twins of5G networks increasingly employ graph classification as the main method foridentifying failure types. However, the skewed distribution of failureoccurrences is a major class imbalance issue that prevents effective graph datamining. Previous studies have not sufficiently tackled this complex problem. Inthis paper, we propose Class-Fourier Graph Neural Network (CF-GNN) introduces aclass-oriented spectral filtering mechanism that ensures precise classificationby estimating a unique spectral filter for each class. We employ eigenvalue andeigenvector spectral filtering to capture and adapt to variations in theminority classes, ensuring accurate class-specific feature discrimination, andadept at graph representation learning for complex local structures amongneighbors in an end-to-end setting. Extensive experiments have demonstratedthat the proposed CF-GNN could help with both the creation of new techniquesfor enhancing classifiers and the investigation of the characteristics of themulti-class imbalanced data in a network digital twin system.</description>
      <author>example@mail.com (Abubakar Isah, Ibrahim Aliyu, Sulaiman Muhammad Rashid, Jaehyung Park, Minsoo Hahn, Jinsul Kim)</author>
      <guid isPermaLink="false">2502.11505v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Masked Latent Prediction and Classification for Self-Supervised Audio Representation Learning</title>
      <link>http://arxiv.org/abs/2502.12031v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Copyright 2025 IEEE. Personal use of this material is permitted.  Permission from IEEE must be obtained for all other uses, in any current or  future media, including reprinting/republishing this material for advertising  or promotional purposes, creating new collective works, for resale or  redistribution to servers or lists, or reuse of any copyrighted component of  this work in other works&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近，基于遮蔽潜在预测的自我监督学习方法被证明能够将输入数据编码为强大的表示。然而，在训练过程中，可以进一步变换所学的潜在空间以提取更适于下游分类任务的高级信息。&lt;h4&gt;背景&lt;/h4&gt;现有的自监督学习方法在通过遮蔽潜在预测的方式获取强大表示上表现出色，但它们可能没有充分利用潜在空间来实现更好的下游分类性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法MATPAC（MAsked latenTPrediction And Classification），它通过解决两个预设任务联合训练，旨在进一步优化所学的潜在空间以适应更高级的信息提取和分类需求。&lt;h4&gt;方法&lt;/h4&gt;该方法包括两个预设任务：一个是遮蔽潜在预测任务，确保在潜在线性中的稳健输入表示；另一个是无监督分类任务，利用第一个预设任务生成的潜在线条来匹配教师模型和学生模型之间的概率分布。MATPAC通过与现有最先进的提议进行比较以及执行消融研究来进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;MATPAC在参考音频分类数据集（如OpenMIC、GTZAN、ESC-50和US8K）上实现了自监督学习的最新结果，并且在音乐自动标记任务Magna-tag-a-tune上的表现优于可比较的监督方法。&lt;h4&gt;结论&lt;/h4&gt;通过将遮蔽潜在预测与无监督分类相结合，MATPAC能够显著提高所学表示的有效性，在各种音频数据集上的性能优于其他自监督学习方法和一些监督方法。&lt;h4&gt;翻译&lt;/h4&gt;最近，基于遮蔽潜在预测的自我监督学习方法被证明能够将输入数据编码为强大的表示形式。然而，在训练过程中，可以进一步变换所学的潜在空间以提取更适于下游分类任务的信息。因此，我们提出了一种新方法：MAsked latenTPrediction And Classification (MATPAC)，它通过解决两个预设任务联合进行训练。如之前的工作所述，第一个预设任务是遮蔽潜在预测任务，确保在潜在线性中的稳健输入表示形式。第二个则是无监督分类任务，该任务利用第一个预设任务生成的潜在线条来匹配教师模型和学生模型之间的概率分布。我们通过与其他最先进的提议进行比较并执行消融研究验证了MATPAC方法的有效性。MATPAC在参考音频分类数据集（如OpenMIC、GTZAN、ESC-50和US8K）上实现了自监督学习的最新结果，并且在音乐自动标记任务Magna-tag-a-tune上的表现优于可比较的监督方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, self-supervised learning methods based on masked latent predictionhave proven to encode input data into powerful representations. However, duringtraining, the learned latent space can be further transformed to extracthigher-level information that could be more suited for downstreamclassification tasks. Therefore, we propose a new method: MAsked latenTPrediction And Classification (MATPAC), which is trained with two pretext taskssolved jointly. As in previous work, the first pretext task is a masked latentprediction task, ensuring a robust input representation in the latent space.The second one is unsupervised classification, which utilises the latentrepresentations of the first pretext task to match probability distributionsbetween a teacher and a student. We validate the MATPAC method by comparing itto other state-of-the-art proposals and conducting ablations studies. MATPACreaches state-of-the-art self-supervised learning results on reference audioclassification datasets such as OpenMIC, GTZAN, ESC-50 and US8K and outperformscomparable supervised methods results for musical auto-tagging onMagna-tag-a-tune.</description>
      <author>example@mail.com (Aurian Quelennec, Pierre Chouteau, Geoffroy Peeters, Slim Essid)</author>
      <guid isPermaLink="false">2502.12031v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>BalanceBenchmark: A Survey for Imbalanced Learning</title>
      <link>http://arxiv.org/abs/2502.10816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多模态学习中的不平衡问题，并提出了一个基准测试框架BalanceBenchmark来评估不同方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;多模态学习通过融合来自不同模态的信息得到了广泛关注，但面临的一个主要问题是某些模态的数据量远远大于其他模态导致的不平衡现象。尽管已有研究提出了一些缓解措施，但缺乏系统的对比分析。&lt;h4&gt;目的&lt;/h4&gt;系统地分类主流的多模态不平衡算法，并引入一个新的基准测试框架来全面评估不同方法的效果。&lt;h4&gt;方法&lt;/h4&gt;根据所采用的不同策略将现有算法分为四类；设计了包括多个常用数据集和从三个维度（性能，不平衡程度及计算复杂度）进行评估的新基准测试；开发了一个模块化且可扩展的工具包以确保实验的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用BalanceBenchmark进行了详尽的实验，揭示了不同方法组在处理多模态不平衡问题时的特点和优势。研究结果为未来解决此类问题提供了有价值的见解，并可能对基础模型的设计产生影响。&lt;h4&gt;结论&lt;/h4&gt;本文的工作不仅有助于更好地理解现有的多模态不平衡算法，还期望能够激发更多高效的解决方案以应对未来的挑战，包括对基础模型的影响。&lt;h4&gt;翻译&lt;/h4&gt;多模态学习因其整合来自不同来源的信息的能力而备受关注。然而，在这种环境下一个常见的问题是数据的多模态不平衡问题，即某些类型的数据主导整个系统的同时其他类型的使用不足。尽管最近的研究提出了一些缓解策略，但缺乏全面和公平的比较研究。本文中，我们根据所用的不同方法将主流的解决不平衡的方法分为了四类。为使这些不同方法能有一个综合评估，我们引入了一个基准测试框架（BalanceBenchmark），包括多个广泛使用的多维数据集以及从三个维度进行评价的标准：性能、不平衡程度和复杂度。通过标准化整个实验流程以确保公平比较，开发了一种模块化且扩展性强的工具包。基于使用该框架进行的实验，我们得出了关于不同方法组在处理不平衡问题方面的特征及优势的关键见解，并期望此分析能够在未来启发更有效的解决多模态学习中不平衡问题的方法，以及对于基础模型的影响。平衡基准测试的相关代码可以在https://github.com/GeWu-Lab/BalanceBenchmark获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning has gained attention for its capacity to integrateinformation from different modalities. However, it is often hindered by themultimodal imbalance problem, where certain modality dominates while othersremain underutilized. Although recent studies have proposed various methods toalleviate this problem, they lack comprehensive and fair comparisons. In thispaper, we systematically categorize various mainstream multimodal imbalancealgorithms into four groups based on the strategies they employ to mitigateimbalance. To facilitate a comprehensive evaluation of these methods, weintroduce BalanceBenchmark, a benchmark including multiple widely usedmultidimensional datasets and evaluation metrics from three perspectives:performance, imbalance degree, and complexity. To ensure fair comparisons, wehave developed a modular and extensible toolkit that standardizes theexperimental workflow across different methods. Based on the experiments usingBalanceBenchmark, we have identified several key insights into thecharacteristics and advantages of different method groups in terms ofperformance, balance degree and computational complexity. We expect suchanalysis could inspire more efficient approaches to address the imbalanceproblem in the future, as well as foundation models. The code of the toolkit isavailable at https://github.com/GeWu-Lab/BalanceBenchmark.</description>
      <author>example@mail.com (Shaoxuan Xu, Menglu Cui, Chengxiang Huang, Hongfa Wang, DiHu)</author>
      <guid isPermaLink="false">2502.10816v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Structure based SAT dataset for analysing GNN generalisation</title>
      <link>http://arxiv.org/abs/2502.11410v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to be published in 28th International Conference on Artificial  Intelligence and Statistics (AISTATS) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了在SAT问题求解领域，CDCL（冲突驱动的子句学习）技术已经取得了显著成果。然而，针对GNN（图神经网络）方法在此领域的应用还存在一个被忽视的问题：结构属性与模型泛化能力之间的关系研究不足。&lt;h4&gt;背景&lt;/h4&gt;基于CDCL的技术已经在合成和实际工业问题中实现了卓越性能。但是，虽然这些CDCL求解器仅在特定问题上操作，GNN求解器通过利用已解决问题的知识来加速新SAT问题的解决带来了新的益处。&lt;h4&gt;目的&lt;/h4&gt;提出StructureSAT数据集及其生成代码，旨在研究结构属性（如模块性、自相似性）与基于图神经网络的SAT求解器泛化能力之间的关系，并揭示现有GNN SAT求解器中存在问题的原因。&lt;h4&gt;方法&lt;/h4&gt;利用了一种新的分割方法，该方法侧重于根据其结构性质将家族细化为更详细的层次结构。通过新数据集帮助解释现有GNN SAT求解器中的问题泛化难题。&lt;h4&gt;主要发现&lt;/h4&gt;文章未明确指出具体的研究结果或实验数据，但强调了研究的潜在贡献和未来发展方向。&lt;h4&gt;结论&lt;/h4&gt;为了促进基于图神经网络的SAT解决技术的发展，提出了多个未来研究方向，以帮助研究人员开发出更加有效且具有泛化能力的SAT求解器。&lt;h4&gt;翻译&lt;/h4&gt;可满足性（SAT）求解器基于冲突驱动子句学习等技术，在合成和现实世界工业问题上表现出色。然而，尽管CDCL求解器仅针对特定问题操作，图神经网络（GNN）求解器通过允许实践者利用已解决问题的知识来加速新SAT问题的解决带来了新的益处。但是，一个在CDCL求解器中经常研究但在GNN求解器中被忽视的问题是：SAT问题中的结构属性与GNN求解器泛化能力之间的关系。为了弥合结构性图特性（如模块性、自相似性）与基于图神经网络的SAT求解器泛化的差距，我们提出了StructureSAT：一个包含多样化来自知名问题领域SAT问题的数据集，并提供了生成新示例的代码。此外，我们利用了一种新的分割方法，该方法侧重于根据其结构性质将家族细化为更详细的层次结构。通过此数据集，我们旨在帮助解释现有GNN SAT求解器中的泛化难题，并利用对结构图属性的知识。最后，我们总结了可以帮助基于图神经网络的SAT解决技术发展的多个未来研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Satisfiability (SAT) solvers based on techniques such as conflict drivenclause learning (CDCL) have produced excellent performance on both syntheticand real world industrial problems. While these CDCL solvers only operate on aper-problem basis, graph neural network (GNN) based solvers bring new benefitsto the field by allowing practitioners to exploit knowledge gained from solvedproblems to expedite solving of new SAT problems. However, one specific areathat is often studied in the context of CDCL solvers, but largely overlooked inGNN solvers, is the relationship between graph theoretic measure of structurein SAT problems and the generalisation ability of GNN solvers. To bridge thegap between structural graph properties (e.g., modularity, self-similarity) andthe generalisability (or lack thereof) of GNN based SAT solvers, we presentStructureSAT: a curated dataset, along with code to further generate novelexamples, containing a diverse set of SAT problems from well known problemdomains. Furthermore, we utilise a novel splitting method that focuses ondeconstructing the families into more detailed hierarchies based on theirstructural properties. With the new dataset, we aim to help explain problematicgeneralisation in existing GNN SAT solvers by exploiting knowledge ofstructural graph properties. We conclude with multiple future directions thatcan help researchers in GNN based SAT solving develop more effective andgeneralisable SAT solvers.</description>
      <author>example@mail.com (Yi Fu, Anthony Tompkins, Yang Song, Maurice Pagnucco)</author>
      <guid isPermaLink="false">2502.11410v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge-aware contrastive heterogeneous molecular graph learning</title>
      <link>http://arxiv.org/abs/2502.11711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个新的框架，用于改善分子表示学习，特别是在药物设计中的应用。通过引入异构图结构和对比学习方法，该框架能够更好地整合外部知识并提升分子性质预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;传统的分子性质预测方法主要依赖同质图编码，这种方法无法有效地融入外部知识，并且难以在不同粒度级别上表示分子结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的机器学习框架Knowledge-aware Contrastive Heterogeneous Molecular Graph Learning (KCHML)，以解决传统方法的局限性并提高分子性质预测能力。&lt;h4&gt;方法&lt;/h4&gt;该研究通过引入异构图编码和对比学习，创建了一个基于三种不同视角（分子、元素及药理）的新颖表示模型。此框架利用双层消息传递机制来增强分子图的表现力。&lt;h4&gt;主要发现&lt;/h4&gt;KCHML不仅在预测分子特性方面超越了现有最佳模型，在下游任务如药物相互作用预测上也表现出色，这表明该方法能有效捕捉到复杂分子特征。&lt;h4&gt;结论&lt;/h4&gt;通过引入异构图编码和对比学习技术，KCHML框架能够显著提升分子表示的学习效果及其应用价值。这一方法为未来的分子性质研究提供了新的视角和可能。&lt;h4&gt;翻译&lt;/h4&gt;分子表示学习在预测分子属性和推进药物设计方面至关重要。传统的依赖于同质图编码的方法由于无法整合外部知识以及难以跨不同粒度级别表示分子结构，而存在局限性。为了克服这些限制，我们提出了一种向异构图结构进行图编码的范式转变，并引入了一个新的框架：具有嵌入外部知识对比学习功能的知识感知异构分子图学习（KCHML）。该方法利用了三种不同的图视角——分子、元素和药理学，通过增强型的异构分子图以及双消息传递机制来丰富分子表示。这种设计为属性预测提供了全面的表征，并且对于下游任务如药物-药物相互作用预测同样适用。广泛的基准测试证明KCHML在最先进的分子属性预测模型中具有优越性，突显了其捕捉复杂分子特征的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular representation learning is pivotal in predicting molecularproperties and advancing drug design. Traditional methodologies, whichpredominantly rely on homogeneous graph encoding, are limited by theirinability to integrate external knowledge and represent molecular structuresacross different levels of granularity. To address these limitations, wepropose a paradigm shift by encoding molecular graphs into heterogeneousstructures, introducing a novel framework: Knowledge-aware ContrastiveHeterogeneous Molecular Graph Learning (KCHML). This approach leveragescontrastive learning to enrich molecular representations with embedded externalknowledge. KCHML conceptualizes molecules through three distinct graphviews-molecular, elemental, and pharmacological-enhanced by heterogeneousmolecular graphs and a dual message-passing mechanism. This design offers acomprehensive representation for property prediction, as well as for downstreamtasks such as drug-drug interaction (DDI) prediction. Extensive benchmarkingdemonstrates KCHML's superiority over state-of-the-art molecular propertyprediction models, underscoring its ability to capture intricate molecularfeatures.</description>
      <author>example@mail.com (Mukun Chen, Jia Wu, Shirui Pan, Fu Lin, Bo Du, Xiuwen Gong, Wenbin Hu)</author>
      <guid isPermaLink="false">2502.11711v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Oversmoothing as Loss of Sign: Towards Structural Balance in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.11394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的解决图神经网络过度平滑问题的方法，通过将抗过度平滑技术解释为在带有正负边的签名图上进行消息传递，从而提供了对这些方法内在机制的新见解。&lt;h4&gt;背景&lt;/h4&gt;在图神经网络中，随着层数增加节点表示变得过于同质化的问题很常见。现有解决该问题的技术主要基于直觉而非理论支持，缺乏统一的理解。&lt;h4&gt;目的&lt;/h4&gt;通过分析签名图传播的渐进行为，展示负边如何使节点相互排斥，并提出一种新的方法来减轻过度平滑现象。&lt;h4&gt;方法&lt;/h4&gt;引入了结构平衡传播（SBP），这种方法利用标签和特征信息创建一个结构上平衡的图用于消息传递。&lt;h4&gt;主要发现&lt;/h4&gt;负边可以将节点在某种程度上推开，这对于长期聚类表示非常重要。此外，正边存在于集群内部而负边出现在集群之间时，签名图中的结构均衡对于节点表示的长期聚类至关重要。&lt;h4&gt;结论&lt;/h4&gt;实验证明了我们的方法能够有效地缓解过度平滑问题，并展示了从签名图角度理解GNN的方法的价值。&lt;h4&gt;翻译&lt;/h4&gt;过度平滑是图神经网络中常见的一种现象，在层数增加时，节点表示变得过于同质化。本文通过将抗过度平滑技术解释为在带有正负边的签名图上进行消息传递，提供了对这些方法内在机制的新见解，并提出了一种新的理论上有保证的方法——结构平衡传播（SBP），该方法利用标签和特征信息创建一个结构上均衡的图用于消息传递。实验结果表明了我们方法的有效性，并强调了从签名图角度理解GNN的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Oversmoothing is a common issue in graph neural networks (GNNs), where noderepresentations become excessively homogeneous as the number of layersincreases, resulting in degraded performance. Various strategies have beenproposed to combat oversmoothing in practice, yet they are based on differentheuristics and lack a unified understanding of their inherent mechanisms. Inthis paper, we show that three major classes of anti-oversmoothing techniquescan be mathematically interpreted as message passing over signed graphscomprising both positive and negative edges. By analyzing the asymptoticbehavior of signed graph propagation, we demonstrate that negative edges canrepel nodes to a certain extent, providing deeper insights into how thesemethods mitigate oversmoothing. Furthermore, our results suggest that thestructural balance of a signed graph-where positive edges exist only withinclusters and negative edges appear only between clusters-is crucial forclustering node representations in the long term through signed graphpropagation. Motivated by these observations, we propose a solution to mitigateoversmoothing with theoretical guarantees-Structural Balance Propagation (SBP),by incorporating label and feature information to create a structurallybalanced graph for message-passing. Experiments on nine datasets against twelvebaselines demonstrate the effectiveness of our method, highlighting the valueof our signed graph perspective.</description>
      <author>example@mail.com (Jiaqi Wang, Xinyi Wu, James Cheng, Yifei Wang)</author>
      <guid isPermaLink="false">2502.11394v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>No-reference geometry quality assessment for colorless point clouds via list-wise rank learning</title>
      <link>http://arxiv.org/abs/2502.11726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于列表排序学习的无参考几何质量评估（GQA）方法，名为LRL-GQA。此方法包括一个用于捕捉点云内在多尺度特征的质量评估网络（GQANet），以及用于训练和排名降级点云列表的学习网络（LRLNet）。实验表明该方法在性能上优于现有的全参考GQA指标。&lt;h4&gt;背景&lt;/h4&gt;目前，客观的几何质量评估对于评价基于点云的新解决方案（如水印、压缩和3D重建）的重要性日益增加。然而，现有方法要么是传统的全参考度量标准，要么针对的是颜色和几何失真的综合学习方法，这些都不适用于无参考的GQA任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无参考仅几何质量评估的方法，以解决当前方法中存在的局限性，并推动基于学习的质量评估指标的发展。&lt;h4&gt;方法&lt;/h4&gt;该研究构建了一个名为LRL数据集的大规模数据库，其中包含多种几何失真，并开发了两个网络：GQANet用于捕捉点云的多尺度特征并预测质量指数；LRLNet则利用可能性损失函数来训练GQANet并对降级点云列表进行排名。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的无参考LRL-GQA方法在评估几何质量和排序受损点云方面表现出色，优于现有的全参考GQA度量标准。&lt;h4&gt;结论&lt;/h4&gt;该论文提出了一种有效的无参考仅几何质量评估的方法，并通过实验验证了其优越性。这种方法为基于学习的GQA指标的发展提供了新的方向和可能性。&lt;h4&gt;翻译&lt;/h4&gt;几何质量评估（GQA）对于评价新兴点云解决方案的重要性日益增加，但现有的客观方法要么是传统的全参考度量标准，要么针对的是颜色和几何失真的综合学习方法，这些都不适合无参考的质量评估任务。此外，由于缺乏大规模的具有主观评分的GQA数据集，这进一步阻碍了基于学习的方法的发展。该论文提出了一种新的基于列表排序学习的无参考仅几何质量评估方法LRL-GQA，包括一个捕捉多尺度特征的质量评估网络和用于训练和排名降级点云列表的学习网络。实验表明其性能优于现有的全参考GQA度量标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.cag.2025.104176&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometry quality assessment (GQA) of colorless point clouds is crucial forevaluating the performance of emerging point cloud-based solutions (e.g.,watermarking, compression, and 3-Dimensional (3D) reconstruction).Unfortunately, existing objective GQA approaches are traditional full-referencemetrics, whereas state-of-the-art learning-based point cloud quality assessment(PCQA) methods target both color and geometry distortions, neither of which arequalified for the no-reference GQA task. In addition, the lack of large-scaleGQA datasets with subjective scores, which are always imprecise, biased, andinconsistent, also hinders the development of learning-based GQA metrics.Driven by these limitations, this paper proposes a no-reference geometry-onlyquality assessment approach based on list-wise rank learning, termed LRL-GQA,which comprises of a geometry quality assessment network (GQANet) and alist-wise rank learning network (LRLNet). The proposed LRL-GQA formulates theno-reference GQA as a list-wise rank problem, with the objective of directlyoptimizing the entire quality ordering. Specifically, a large datasetcontaining a variety of geometry-only distortions is constructed first, namedLRL dataset, in which each sample is label-free but coupled with qualityranking information. Then, the GQANet is designed to capture intrinsicmulti-scale patch-wise geometric features in order to predict a quality indexfor each point cloud. After that, the LRLNet leverages the LRL dataset and alikelihood loss to train the GQANet and ranks the input list of degraded pointclouds according to their distortion levels. In addition, the pre-trainedGQANet can be fine-tuned further to obtain absolute quality scores.Experimental results demonstrate the superior performance of the proposedno-reference LRL-GQA method compared with existing full-reference GQA metrics.</description>
      <author>example@mail.com (Zheng Li, Bingxu Xie, Chao Chu, Weiqing Li, Zhiyong Su)</author>
      <guid isPermaLink="false">2502.11726v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Generalizable speech deepfake detection via meta-learned LoRA</title>
      <link>http://arxiv.org/abs/2502.10838v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了利用元学习和LoRA适配器结合的方法，以应对深度伪造检测中的分布变化问题。&lt;h4&gt;背景&lt;/h4&gt;深度伪造检测面临的问题是标签固定但深度伪造样本的生成方法会改变。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够泛化的深度伪造检测方法，该方法可以适应各种不同类型的攻击。&lt;h4&gt;方法&lt;/h4&gt;采用元学习和LoRA适配器来学习训练数据中所有攻击类型共有的结构特征。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入元学习技术，可以使模型更好地掌握不同攻击模式下的共享特性，从而提高泛化能力。&lt;h4&gt;结论&lt;/h4&gt;利用元学习结合LoRA的技术能够有效应对深度伪造样本的分布变化问题。&lt;h4&gt;翻译&lt;/h4&gt;通用的深度伪造检测可以被定义为一种标签固定但数据生成分布发生变化的问题。我们可以在训练时使用选定的攻击类型和真实数据集，但是攻击者可以通过改变种子重新训练生成器来制造新的攻击。一个合理的方法是将所有不同类型的攻击模式在训练阶段整合在一起。我们的方法利用了元学习结合LoRA适配器技术来从训练集中学习出适用于各种攻击类型的数据结构特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalizable deepfake detection can be formulated as a detection problemwhere labels (bonafide and fake) are fixed but distributional drift affects thedeepfake set. We can always train our detector with one-selected attacks andbonafide data, but an attacker can generate new attacks by just retraining hisgenerator with a different seed. One reasonable approach is to simply pool alldifferent attack types available in training time. Our proposed approach is toutilize meta-learning in combination with LoRA adapters to learn the structurein the training data that is common to all attack types.</description>
      <author>example@mail.com (Janne Laakkonen, Ivan Kukanov, Ville Hautamäki)</author>
      <guid isPermaLink="false">2502.10838v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A-MEM: Agentic Memory for LLM Agents</title>
      <link>http://arxiv.org/abs/2502.12110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种用于大型语言模型代理的新型记忆系统，这种系统能动态地组织记忆，并根据Zettelkasten方法创建知识网络。&lt;h4&gt;背景&lt;/h4&gt;现有的记忆系统虽然能够存储和检索信息，但缺乏对复杂任务的适应性和灵活的记忆结构，限制了它们在不同任务中的应用。&lt;h4&gt;目的&lt;/h4&gt;设计一种可以自动识别、链接相关记忆并随时间演化的动态记忆管理系统，以增强大型语言模型代理的能力。&lt;h4&gt;方法&lt;/h4&gt;结合Zettelkasten的知识组织原则和基于代理的决策灵活性，通过动态索引和关联构建互联知识网络。每个新记忆都被记录为包含多个结构化属性（如上下文描述、关键词和标签）的综合笔记，并与历史记忆进行比较以建立有意义的联系。&lt;h4&gt;主要发现&lt;/h4&gt;该系统的实验结果表明，在六个基础模型上相较于现有最先进的基准系统有显著改进，这表明动态组织的记忆方法可以有效提升大型语言模型代理在实际任务中的表现。&lt;h4&gt;结论&lt;/h4&gt;通过引入一种新颖的记忆管理系统，论文解决了当前记忆系统对于复杂现实世界任务适应性不足的问题，并为未来的大型语言模型研究提供了新的思路和方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新提出的用于大型语言模型（LLM）代理的记忆系统。该系统旨在解决现有记忆系统的局限性问题，这些系统虽然能够实现基本的存储和检索功能，但缺乏灵活的记忆组织结构。论文中的解决方案是通过引入一种基于Zettelkasten方法、具备动态索引和关联能力的知识网络，来增强大型语言模型在不同任务中应用的能力。这种方法允许新记忆被整合进现有的知识体系，并触发对已有信息的更新或重新评估，从而实现更智能的记忆管理方式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While large language model (LLM) agents can effectively use external toolsfor complex real-world tasks, they require memory systems to leveragehistorical experiences. Current memory systems enable basic storage andretrieval but lack sophisticated memory organization, despite recent attemptsto incorporate graph databases. Moreover, these systems' fixed operations andstructures limit their adaptability across diverse tasks. To address thislimitation, this paper proposes a novel agentic memory system for LLM agentsthat can dynamically organize memories in an agentic way. Following the basicprinciples of the Zettelkasten method, we designed our memory system to createinterconnected knowledge networks through dynamic indexing and linking. When anew memory is added, we generate a comprehensive note containing multiplestructured attributes, including contextual descriptions, keywords, and tags.The system then analyzes historical memories to identify relevant connections,establishing links where meaningful similarities exist. Additionally, thisprocess enables memory evolution - as new memories are integrated, they cantrigger updates to the contextual representations and attributes of existinghistorical memories, allowing the memory network to continuously refine itsunderstanding. Our approach combines the structured organization principles ofZettelkasten with the flexibility of agent-driven decision making, allowing formore adaptive and context-aware memory management. Empirical experiments on sixfoundation models show superior improvement against existing SOTA baselines.The source code is available at https://github.com/WujiangXu/AgenticMemory.</description>
      <author>example@mail.com (Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, Yongfeng Zhang)</author>
      <guid isPermaLink="false">2502.12110v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Deep Reinforcement Learning-Based User Scheduling for Collaborative Perception</title>
      <link>http://arxiv.org/abs/2502.10456v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于深度强化学习的V2X用户调度算法，以优化协作感知中的通信资源利用。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶中独立感知系统由于传感范围有限和远距离遮挡问题而存在潜在风险。通过使用车辆到一切(V2X)通信来促进联网与自动驾驶汽车及路边单元间的合作可以提高感知精度。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够优化V2X通信资源调度的深度强化学习算法，以实现高效的协作感知。&lt;h4&gt;方法&lt;/h4&gt;开发了一种基于双层深度Q网络(DDQN)的用户调度框架SchedCP，该框架结合信道状态信息(CSI)和语义信息，将传统的依赖标签的目标重构为无标签的目标，以便于3D目标检测。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果验证了所提方法在协作感知中的有效性和鲁棒性。此外，通过案例研究展示了算法如何根据即时的CSI和感知语义动态调整调度决策。&lt;h4&gt;结论&lt;/h4&gt;SchedCP框架提供了一种改进V2X用户调度的新途径，它有效地解决了由于通信资源有限而无法传输所有传感数据的问题。&lt;h4&gt;翻译&lt;/h4&gt;独立运行的自动驾驶感知系统面临传感器检测范围有限及远距离遮挡导致的重大问题。为了解决这些问题，并通过车辆与路边单元之间的V2X通讯来提高感知精度，本研究提出了一个基于深度强化学习的方法来进行用户调度优化。在获取感知标签难度大的情况下，我们创新性地将传统的依赖于标签的目标转变为无需标签的准则，这主要是由于3D目标检测的特点所决定的。通过结合信道状态信息和语义信息，设计了一个名为SchedCP的基于双层深度Q网络(DDQN)的用户调度框架以支持协作感知，并且实验表明该方法相比传统V2X调度方式在效率和鲁棒性方面具有优势。最后，我们还提供了一项案例研究来展示如何根据即时信道状态信息和感知语义调整调度决策。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stand-alone perception systems in autonomous driving suffer from limitedsensing ranges and occlusions at extended distances, potentially resulting incatastrophic outcomes. To address this issue, collaborative perception isenvisioned to improve perceptual accuracy by using vehicle-to-everything (V2X)communication to enable collaboration among connected and autonomous vehiclesand roadside units. However, due to limited communication resources, it isimpractical for all units to transmit sensing data such as point clouds orhigh-definition video. As a result, it is essential to optimize the schedulingof communication links to ensure efficient spectrum utilization for theexchange of perceptual data. In this work, we propose a deep reinforcementlearning-based V2X user scheduling algorithm for collaborative perception.Given the challenges in acquiring perceptual labels, we reformulate theconventional label-dependent objective into a label-free goal, based oncharacteristics of 3D object detection. Incorporating both channel stateinformation (CSI) and semantic information, we develop a double deep Q-Network(DDQN)-based user scheduling framework for collaborative perception, namedSchedCP. Simulation results verify the effectiveness and robustness of SchedCPcompared with traditional V2X scheduling methods. Finally, we present a casestudy to illustrate how our proposed algorithm adaptively modifies thescheduling decisions by taking both instantaneous CSI and perceptual semanticsinto account.</description>
      <author>example@mail.com (Yandi Liu, Guowei Liu, Le Liang, Hao Ye, Chongtao Guo, Shi Jin)</author>
      <guid isPermaLink="false">2502.10456v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Graph Topic Modeling with Topic Tree-based Transformer</title>
      <link>http://arxiv.org/abs/2502.11345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个集成文本内部主题层次和文档间图结构的模型，以统一处理文档中的复杂信息。&lt;h4&gt;背景&lt;/h4&gt;现有的Hyperbolic Graph Neural Networks (HGNNs)在捕捉图层级结构方面表现出色，但无法很好地建模文档中的丰富语义。同时，大多数Hierarchical Topic Models (HTMs)专注于文本内容内的主题层次发现，而忽略了文档间链接的图邻接关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来整合话题层次和图层级到统一的Transformer模型中。&lt;h4&gt;方法&lt;/h4&gt;设计了一个主题树，并提出了Hyperbolic Doubly Recurrent Neural Network（双循环神经网络），利用双曲空间来建模祖先结构和同辈结构，同时在每层Transformer中嵌入两者以学习统一表示。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够有效地结合话题层次和图层级信息，在有监督和无监督实验中表现出色。&lt;h4&gt;结论&lt;/h4&gt;新的Hierarchical Graph Topic Modeling Transformer成功地整合了文本内部的主题层次与文档间的关系，展示了其在处理复杂结构化数据中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Textual documents are commonly connected in a hierarchical graph structurewhere a central document links to others with an exponentially growingconnectivity. Though Hyperbolic Graph Neural Networks (HGNNs) excel atcapturing such graph hierarchy, they cannot model the rich textual semanticswithin documents. Moreover, text contents in documents usually discuss topicsof different specificity. Hierarchical Topic Models (HTMs) discover such latenttopic hierarchy within text corpora. However, most of them focus on the textualcontent within documents, and ignore the graph adjacency across interlinkeddocuments. We thus propose a Hierarchical Graph Topic Modeling Transformer tointegrate both topic hierarchy within documents and graph hierarchy acrossdocuments into a unified Transformer. Specifically, to incorporate topichierarchy within documents, we design a topic tree and infer a hierarchicaltree embedding for hierarchical topic modeling. To preserve both topic andgraph hierarchies, we design our model in hyperbolic space and proposeHyperbolic Doubly Recurrent Neural Network, which models ancestral andfraternal tree structure. Both hierarchies are inserted into each Transformerlayer to learn unified representations. Both supervised and unsupervisedexperiments verify the effectiveness of our model.</description>
      <author>example@mail.com (Delvin Ce Zhang, Menglin Yang, Xiaobao Wu, Jiasheng Zhang, Hady W. Lauw)</author>
      <guid isPermaLink="false">2502.11345v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>The Worse The Better: Content-Aware Viewpoint Generation Network for Projection-related Point Cloud Quality Assessment</title>
      <link>http://arxiv.org/abs/2502.11710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in IEEE Transactions on Circuits and Systems for  Video Technology&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于木桶理论的新视角生成网络(CAVGN)，该网络考虑降质点云的几何和属性特征分布，以学习更好的视点。&lt;h4&gt;背景&lt;/h4&gt;现有的投影相关PCQA方法在不同视图设置下预测的质量评分不稳定且变化显著。&lt;h4&gt;目的&lt;/h4&gt;通过引入一种新的内容感知视点生成网络(CAVGN)来解决现有问题，该网络能够更好地优化视角。&lt;h4&gt;方法&lt;/h4&gt;1. 提出的CAVGN分别提取整个输入点云的多尺度几何和纹理特征；2. 对每个默认独立于内容的视角，将提取到的几何和纹理特征进行细化，聚焦于对应部分的可见区域；3. 将精细化后的几何和纹理特性合并生成优化视角。&lt;h4&gt;主要发现&lt;/h4&gt;通过自监督视点排序网络(SSVRN)选择质量投影图像最差的视点来构建默认-优化视角数据集，实验表明使用所提出的CAVGN生成的视点可以提高基于投影的相关PCQA方法的表现。&lt;h4&gt;结论&lt;/h4&gt;该研究成功开发了一种新的内容感知视角生成机制(CAVGN)，在多种情况下提高了PCQA的质量评分预测稳定性。&lt;h4&gt;翻译&lt;/h4&gt;通过实验证明现有的点云质量评估(PCQA)方法存在最终预测质量分数不稳定的问题。本文提出基于“木桶理论”的全新视角生成网络，该网络根据降质点云的几何及属性特性分布来学习更好的视图角度，并利用自监督训练技术提高投影相关PCQA方法性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TCSVT.2025.3541445&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Through experimental studies, however, we observed the instability of finalpredicted quality scores, which change significantly over different viewpointsettings. Inspired by the "wooden barrel theory", given the defaultcontent-independent viewpoints of existing projection-related PCQA approaches,this paper presents a novel content-aware viewpoint generation network (CAVGN)to learn better viewpoints by taking the distribution of geometric andattribute features of degraded point clouds into consideration. Firstly, theproposed CAVGN extracts multi-scale geometric and texture features of theentire input point cloud, respectively. Then, for each defaultcontent-independent viewpoint, the extracted geometric and texture features arerefined to focus on its corresponding visible part of the input point cloud.Finally, the refined geometric and texture features are concatenated togenerate an optimized viewpoint. To train the proposed CAVGN, we present aself-supervised viewpoint ranking network (SSVRN) to select the viewpoint withthe worst quality projected image to construct a default-optimized viewpointdataset, which consists of thousands of paired default viewpoints andcorresponding optimized viewpoints. Experimental results show that theprojection-related PCQA methods can achieve higher performance using theviewpoints generated by the proposed CAVGN.</description>
      <author>example@mail.com (Zhiyong Su, Bingxu Xie, Zheng Li, Jincan Wu, Weiqing Li)</author>
      <guid isPermaLink="false">2502.11710v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Fast Transmission Control Adaptation for URLLC via Channel Knowledge Map and Meta-Learning</title>
      <link>http://arxiv.org/abs/2502.10777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures. This paper has been submitted to IEEE Internet  of Things Journal for possible publication (Second revision completed)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在无线环境中提供超高可靠低延迟通信（URLLC）的方法，以支持关键任务的物联网服务。&lt;h4&gt;背景&lt;/h4&gt;在未知信道分布的无线环境中，为实现超可靠和低延时通信(URLLC)，需要解决传输控制适应性问题。&lt;h4&gt;目的&lt;/h4&gt;提出两种解决方案来满足URLLC的要求，并验证它们的适应能力。&lt;h4&gt;方法&lt;/h4&gt;{'第一种方案': '功率缩放方案结合深度强化学习(DRL)算法，在不重新训练的情况下使用信道知识图(CKM)，该图利用历史信道增益样本中的空间相关性。', '第二种方案': '基于模型无关的元学习(MAML)的元强化学习算法，根据不同的信道分布进行训练，并能迅速适应新的环境。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'第一种方法': 'DRL算法在各种服务质量(QoS)约束下能够有效满足URLLC的要求。', '第二种方法': '功率缩放方案和元强化学习算法的适应能力得到了验证，能够在有限步骤内调整并快速适应新环境。'}&lt;h4&gt;结论&lt;/h4&gt;所提出的两种解决方案都能有效地解决无线环境中未知信道分布下的超可靠低延迟通信问题，并满足关键任务物联网服务的需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文考虑了在具有未知信道分布的无线环境中为实现关键任务的物联网服务提供超高可靠低延时通信(URLLC)的方法。这些方法依赖于目标区域中少数几个位置的历史信道增益样本。我们根据URLLC约束，在整个目标区域内提出一个复杂的传输控制适应性问题，然后提出了两种解决方案来解决这个问题。第一个是功率缩放方案结合深度强化学习(DRL)算法，利用信道知识图(CKM)，无需重新训练就能使用该图的信道特征的空间相关性。第二个方案是一种基于模型无关元学习(MAML)的元强化学习算法，它根据已知的不同分布信道增益样本进行训练，并能在少量梯度更新后快速适应新环境。模拟结果表明，DRL基线算法在各种服务质量(QoS)约束下能有效满足URLLC的要求。然后验证了功率缩放方案和元强化学习算法的适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper considers methods for delivering ultra reliable low latencycommunication (URLLC) to enable mission-critical Internet of Things (IoT)services in wireless environments with unknown channel distribution. Themethods rely upon the historical channel gain samples of a few locations in atarget area. We formulate a non-trivial transmission control adaptation problemacross the target area under the URLLC constraints. Then we propose twosolutions to solve this problem. The first is a power scaling scheme inconjunction with the deep reinforcement learning (DRL) algorithm with the helpof the channel knowledge map (CKM) without retraining, where the CKM employsthe spatial correlation of the channel characteristics from the historicalchannel gain samples. The second solution is model agnostic meta-learning(MAML) based metareinforcement learning algorithm that is trained from theknown channel gain samples following distinct channel distributions and canquickly adapt to the new environment within a few steps of gradient update.Simulation results indicate that the DRL-based algorithm can effectively meetthe reliability requirement of URLLC under various quality-of-service (QoS)constraints. Then the adaptation capabilities of the power scaling scheme andmeta-reinforcement learning algorithm are also validated.</description>
      <author>example@mail.com (Hongsen Peng, Tobias Kallehauge, Meixia Tao, Petar Popovski)</author>
      <guid isPermaLink="false">2502.10777v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Controlling Neural Collapse Enhances Out-of-Distribution Detection and Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.10691v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了深度神经网络中的OOD检测和泛化之间的关系，并提出了通过控制神经崩溃（NC）来解决这两者之间权衡的方法。&lt;h4&gt;背景&lt;/h4&gt;在深度神经网络中，OO D检测和泛化的研究非常广泛，但它们之间的联系仍未被充分理解。&lt;h4&gt;目的&lt;/h4&gt;探讨神经崩溃与OOD检测及泛化的关系，提出一种可以同时改善这两种任务的新方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一个理论框架来连接神经崩溃到OOD检测和泛化的关联，并展示了熵正则化如何减少NC以提高泛化性能，而固定SIMPLEX等角紧致框架投影器如何强制执行NC以便于更好的检测。基于这些见解，提出了一种控制不同深度神经网络层中NC的方法。&lt;h4&gt;主要发现&lt;/h4&gt;神经崩溃的强度与OOD检测和泛化的权衡关系密切：更强的神经崩溃有助于OOD检测但损害了泛化能力；较弱的神经崩溃则有利于泛化而牺牲了一些检测性能。因此，单一特征空间无法同时完成这两项任务。&lt;h4&gt;结论&lt;/h4&gt;通过控制不同深度神经网络层中的神经崩溃程度，可以在OOD检测和泛化之间找到一种折衷方案，并且实验结果表明这种方法在不同的OOD数据集和DNN架构上表现优异。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution (OOD) detection and OOD generalization are widely studiedin Deep Neural Networks (DNNs), yet their relationship remains poorlyunderstood. We empirically show that the degree of Neural Collapse (NC) in anetwork layer is inversely related with these objectives: stronger NC improvesOOD detection but degrades generalization, while weaker NC enhancesgeneralization at the cost of detection. This trade-off suggests that a singlefeature space cannot simultaneously achieve both tasks. To address this, wedevelop a theoretical framework linking NC to OOD detection and generalization.We show that entropy regularization mitigates NC to improve generalization,while a fixed Simplex Equiangular Tight Frame (ETF) projector enforces NC forbetter detection. Based on these insights, we propose a method to control NC atdifferent DNN layers. In experiments, our method excels at both tasks acrossOOD datasets and DNN architectures.</description>
      <author>example@mail.com (Md Yousuf Harun, Jhair Gallardo, Christopher Kanan)</author>
      <guid isPermaLink="false">2502.10691v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Following the Autoregressive Nature of LLM Embeddings via Compression and Alignment</title>
      <link>http://arxiv.org/abs/2502.11401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新的对比学习方法AutoRegEmbed，该方法利用嵌入条件概率分布来解决大型语言模型(LLM)在作为密集文本编码器时遇到的问题。&lt;h4&gt;背景&lt;/h4&gt;当前趋势是将LLM用作通过对比学习实现的密集文本编码器。然而，由于LLM嵌入预测下一个令牌的概率分布，它们本质上具有生成性和分散性，这与需要捕获全文语义并通过余弦相似度对齐的对比学习相矛盾。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决这一问题，使得大型语言模型在作为密集文本编码器时能够更好地利用其预训练能力。&lt;h4&gt;方法&lt;/h4&gt;提出的方法AutoRegEmbed整合了信息压缩和条件分布对齐两个核心任务。其中，信息压缩任务将文本编码到嵌入空间中，确保嵌入向量捕获全局语义；而条件分布对齐任务则通过利用嵌入的条件分布来实现与正样本嵌入的对齐，并同时降低从文本嵌入生成负样本的概率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示该方法在使用相同数据量的情况下显著优于传统的对比学习方法，且性能可与当前最先进的模型相媲美。&lt;h4&gt;结论&lt;/h4&gt;通过利用嵌入条件概率分布的新对比学习方法AutoRegEmbed有效地解决了现有问题，并展示了其在文本编码任务中的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A new trend uses LLMs as dense text encoders via contrastive learning.However, since LLM embeddings predict the probability distribution of the nexttoken, they are inherently generative and distributive, conflicting withcontrastive learning, which requires embeddings to capture full-text semanticsand align via cosine similarity. This discrepancy hinders the full utilizationof LLMs' pre-training capabilities, resulting in inefficient learning. Inresponse to this issue, we propose AutoRegEmbed, a new contrastive learningmethod built on embedding conditional probability distributions, whichintegrates two core tasks: information compression and conditional distributionalignment. The information compression task encodes text into the embeddingspace, ensuring that the embedding vectors capture global semantics. Theconditional distribution alignment task focuses on aligning text embeddingswith positive samples embeddings by leveraging the conditional distribution ofembeddings while simultaneously reducing the likelihood of generating negativesamples from text embeddings, thereby achieving embedding alignment anduniformity. Experimental results demonstrate that our method significantlyoutperforms traditional contrastive learning approaches and achievesperformance comparable to state-of-the-art models when using the same amount ofdata.</description>
      <author>example@mail.com (Jingcheng Deng, Zhongtao Jiang, Liang Pang, Liwei Chen, Kun Xu, Zihao Wei, Huawei Shen, Xueqi Cheng)</author>
      <guid isPermaLink="false">2502.11401v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations</title>
      <link>http://arxiv.org/abs/2502.08279v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VISTA是一个专门用于科学领域视频到文本摘要的大型数据集，包含18,599个AI会议演讲及其对应的论文摘要。&lt;h4&gt;背景&lt;/h4&gt;将录制的视频转换为简洁准确的文字摘要在多模态学习中是一项日益增长的挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍VISTA数据集，并评估最先进的大规模模型在此任务上的表现以及使用基于计划框架的效果。&lt;h4&gt;方法&lt;/h4&gt;基准测试了当前最佳的大规模模型，同时采用了一种基于规划的方法来更好地捕捉摘要结构化的特性。&lt;h4&gt;主要发现&lt;/h4&gt;无论是人工还是自动评价都表明明确的规划能够提高总结的质量和事实的一致性，但与人类性能相比仍存在显著差距。&lt;h4&gt;结论&lt;/h4&gt;科学视频摘要化任务仍然面临挑战，这表明模型在理解和生成高质量科学文本摘要方面仍有改进的空间。&lt;h4&gt;翻译&lt;/h4&gt;将录制的视频转换为简洁准确的文字摘要在多模态学习中是一项日益增长的挑战。本文介绍了一个专门用于科学研究领域的视频到文字总结的数据集VISTA。该数据集包含18,599个AI会议演讲及其对应的论文摘要。我们基准测试了最先进的大规模模型，并应用了一种基于规划的方法，以更好地捕捉摘要结构化的特性。无论是人工还是自动评价都确认明确的计划能够提高总结的质量和事实的一致性，但是与人类性能相比仍存在显著差距，这表明科学视频摘要化任务仍然面临挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transforming recorded videos into concise and accurate textual summaries is agrowing challenge in multimodal learning. This paper introduces VISTA, adataset specifically designed for video-to-text summarization in scientificdomains. VISTA contains 18,599 recorded AI conference presentations paired withtheir corresponding paper abstracts. We benchmark the performance ofstate-of-the-art large models and apply a plan-based framework to bettercapture the structured nature of abstracts. Both human and automatedevaluations confirm that explicit planning enhances summary quality and factualconsistency. However, a considerable gap remains between models and humanperformance, highlighting the challenges of scientific video summarization.</description>
      <author>example@mail.com (Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu Qiu, Mirella Lapata, Vera Demberg)</author>
      <guid isPermaLink="false">2502.08279v2</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Token Communications: A Unified Framework for Cross-modal Context-aware Semantic Communications</title>
      <link>http://arxiv.org/abs/2502.12096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;在这篇文章中，我们介绍了token通信（TokCom），这是一种统一的框架，在生成式语义通信（GenSC）中利用跨模态上下文信息。TokCom是一个新的范式，受到最近生成基础模型和多模态大型语言模型(GFM/MLLMs)成功的启发，其中通信单位是token，这使得在发送方和接收方可以高效地进行基于transformer的token处理。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于生成的基础模型和多模态大规模语言模型（GFM/MLLMs）取得了显著的成功。这些模型能够有效地利用跨模态上下文信息，并且通过引入token通信(TokCom)，可以在无线通信系统中更好地整合这种能力。&lt;h4&gt;目的&lt;/h4&gt;文章旨在探讨在生成式语义通信(GenSC)中利用上下文的潜在机会和挑战，研究如何将基于GFM/MLLMs的token处理集成到语义通信系统中以有效利用跨模态上下文信息，并提出未来无线网络各层上高效TokenCom的关键原则。&lt;h4&gt;方法&lt;/h4&gt;文中探讨了TokCom在不同层级上的实现方式，特别是在图像传输场景下如何利用跨模态背景信息。通过这种方式，能够显著提升带宽效率并保持语义或感知质量的损失最小化。&lt;h4&gt;主要发现&lt;/h4&gt;文章展示了一个基于GenSC的实验实例，在该实验中使用跨模态上下文信息可以将带宽效率提高70.8%，同时确保语义/感知质量几乎不受影响。&lt;h4&gt;结论&lt;/h4&gt;研究确定了未来在无线网络中实现和采用TokCom的研究方向，以进一步增强其效果并推动相关技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce token communications (TokCom), a unifiedframework to leverage cross-modal context information in generative semanticcommunications (GenSC). TokCom is a new paradigm, motivated by the recentsuccess of generative foundation models and multimodal large language models(GFM/MLLMs), where the communication units are tokens, enabling efficienttransformer-based token processing at the transmitter and receiver. In thispaper, we introduce the potential opportunities and challenges of leveragingcontext in GenSC, explore how to integrate GFM/MLLMs-based token processinginto semantic communication systems to leverage cross-modal contexteffectively, present the key principles for efficient TokCom at various layersin future wireless networks. We demonstrate the corresponding TokCom benefitsin a GenSC setup for image, leveraging cross-modal context information, whichincreases the bandwidth efficiency by 70.8% with negligible loss ofsemantic/perceptual quality. Finally, the potential research directions areidentified to facilitate adoption of TokCom in future wireless networks.</description>
      <author>example@mail.com (Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Rahim Tafazolli, Mehdi Bennis, Dusit Niyato)</author>
      <guid isPermaLink="false">2502.12096v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Deep Subspace Learning for Surface Anomaly Classification Based on 3D Point Cloud Data</title>
      <link>http://arxiv.org/abs/2502.11669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于深度子空间学习的3D异常分类模型，该模型通过轻量级编码器提取潜在表示，并将每个类视为一个子空间来处理类内变异和类间相似性。&lt;h4&gt;背景&lt;/h4&gt;表面异常分类对于制造系统的故障诊断和质量控制至关重要。然而，在实践中存在三个主要挑战：异常模式在类内的变化、不同类别之间的相似性和生产过程中可能出现的新类型异常，以及罕见的异常数据限制了模型的学习能力。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够同时解决上述挑战的方法。&lt;h4&gt;方法&lt;/h4&gt;基于深度子空间学习的3D异常分类模型。该模型利用轻量级编码器提取潜在表示，并将每个类视为一个子空间来处理类内变化，同时促进不同类别之间的区别以应对类间相似性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的模型能够更好地识别新类型的异常并达到比基准方法更好的异常分类结果。&lt;h4&gt;结论&lt;/h4&gt;该模型在广泛数值实验中展示了其优越的性能和有效性。&lt;h4&gt;翻译&lt;/h4&gt;表面异常分类对于制造系统的故障诊断和质量控制至关重要。然而，实践中存在三个挑战：一是异常模式在类内的变化以及不同类别之间的相似性；二是生产过程中可能出现的新类型异常需要准确检测；三是罕见的异常数据限制了模型的学习能力。为解决这些挑战，本文提出了一种基于深度子空间学习的3D异常分类模型，该模型能够更好地处理类内变异和类间相似性，并具备识别新类型异常的能力。实验结果表明该方法优于基准方法，在异常检测方面表现更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surface anomaly classification is critical for manufacturing system faultdiagnosis and quality control. However, the following challenges always hinderaccurate anomaly classification in practice: (i) Anomaly patterns exhibitintra-class variation and inter-class similarity, presenting challenges in theaccurate classification of each sample. (ii) Despite the predefined classes,new types of anomalies can occur during production that require to be detectedaccurately. (iii) Anomalous data is rare in manufacturing processes, leading tolimited data for model learning. To tackle the above challenges simultaneously,this paper proposes a novel deep subspace learning-based 3D anomalyclassification model. Specifically, starting from a lightweight encoder toextract the latent representations, we model each class as a subspace toaccount for the intra-class variation, while promoting distinct subspaces ofdifferent classes to tackle the inter-class similarity. Moreover, the explicitmodeling of subspaces offers the capability to detect out-of-distributionsamples, i.e., new types of anomalies, and the regularization effect with muchfewer learnable parameters of our proposed subspace classifier, compared to thepopular Multi-Layer Perceptions (MLPs). Extensive numerical experimentsdemonstrate our method achieves better anomaly classification results thanbenchmark methods, and can effectively identify the new types of anomalies.</description>
      <author>example@mail.com (Xuanming Cao, Chengyu Tao, Juan Du)</author>
      <guid isPermaLink="false">2502.11669v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Unlocking the Potential of Generative AI through Neuro-Symbolic Architectures: Benefits and Limitations</title>
      <link>http://arxiv.org/abs/2502.11269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  54 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了神经符号人工智能（NSAI）的不同架构，探讨它们如何结合深度学习处理大规模和非结构化数据的能力与符号方法的结构化推理能力。研究评估了这些架构在泛化、推理能力、迁移能力和可解释性等标准下的表现。&lt;h4&gt;背景&lt;/h4&gt;神经符号人工智能通过整合深度学习和符号方法的优势，在人工智能领域代表了一种变革性的方法，解决了透明度和数据效率等问题。&lt;h4&gt;目的&lt;/h4&gt;系统地研究不同的NSAI架构及其与当前AI技术（如增强检索生成、图神经网络、强化学习和多智能体系统）的结合方式，并评估它们在各种标准下的性能表现。&lt;h4&gt;方法&lt;/h4&gt;论文详细分析了不同NSAI架构如何整合神经和符号组件，以及这些架构如何与现有AI技术相适应。然后对这些模型进行了全面的比较分析。&lt;h4&gt;主要发现&lt;/h4&gt;Neuro &gt; Symbolic &lt; Neural模型（即具有明确象征性和较强神经网络能力的模型）在所有评估标准中均表现出色，这表明了这种架构利用先进科技如多智能体系统的优势。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了不同NSAI架构之间的比较分析，并指出了每种架构的优点和局限性。特别强调的是，结合了象征性和神经网络特征的新架构在未来人工智能技术中的潜在价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文，上述内容为其中文翻译及总结。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuro-symbolic artificial intelligence (NSAI) represents a transformativeapproach in artificial intelligence (AI) by combining deep learning's abilityto handle large-scale and unstructured data with the structured reasoning ofsymbolic methods. By leveraging their complementary strengths, NSAI enhancesgeneralization, reasoning, and scalability while addressing key challenges suchas transparency and data efficiency. This paper systematically studies diverseNSAI architectures, highlighting their unique approaches to integrating neuraland symbolic components. It examines the alignment of contemporary AItechniques such as retrieval-augmented generation, graph neural networks,reinforcement learning, and multi-agent systems with NSAI paradigms. This studythen evaluates these architectures against comprehensive set of criteria,including generalization, reasoning capabilities, transferability, andinterpretability, therefore providing a comparative analysis of theirrespective strengths and limitations. Notably, the Neuro &gt; Symbolic &lt; Neuromodel consistently outperforms its counterparts across all evaluation metrics.This result aligns with state-of-the-art research that highlight the efficacyof such architectures in harnessing advanced technologies like multi-agentsystems.</description>
      <author>example@mail.com (Oualid Bougzime, Samir Jabbar, Christophe Cruz, Frédéric Demoly)</author>
      <guid isPermaLink="false">2502.11269v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Demographic Attributes Prediction from Speech Using WavLM Embeddings</title>
      <link>http://arxiv.org/abs/2502.12007v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, accepted by The Conference on Information Sciences and  Systems (CISS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;本文介绍了一种基于WavLM特征的通用分类器，用于从语音中推断人口统计学特征，如年龄、性别、母语、教育背景和国家。这种人口统计信息预测在语言学习、无障碍技术和数字取证等应用中扮演着关键角色，使技术更加个性化和包容性。&lt;h4&gt;研究背景&lt;/h4&gt;人口统计数据的预测对于开发个性化的和包容性的技术具有重要意义，特别是在语言学习、无障碍技术以及数字取证等领域。&lt;h4&gt;研究目的&lt;/h4&gt;利用预训练模型进行嵌入提取，提出了一种能够识别与人口统计特征相关的声学和语言关键特征的框架，并通过各种数据集验证了该方法的有效性。&lt;h4&gt;采用的方法&lt;/h4&gt;基于WavLM特征，提出了一个用于预测年龄、性别等人口统计信息的分类器。同时利用大量的预训练模型来确保系统的鲁棒性和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;{'年龄预测误差': '提出的系统在年龄预测任务上的平均绝对误差（MAE）为4.94', '性别分类准确性': '性别分类准确率超过99.81%', '改进幅度': '相比于现有模型，本研究的系统在各个任务中的性能提高了最多30%（以相对MAE衡量），以及高达10%的精度和F1分数提升'}&lt;h4&gt;结论&lt;/h4&gt;这项研究表明了说话人多样性的新见解，并为基于语音的人口统计特征分析提供了坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a general classifier based on WavLM features, to inferdemographic characteristics, such as age, gender, native language, education,and country, from speech. Demographic feature prediction plays a crucial rolein applications like language learning, accessibility, and digital forensics,enabling more personalized and inclusive technologies. Leveraging pretrainedmodels for embedding extraction, the proposed framework identifies key acousticand linguistic fea-tures associated with demographic attributes, achieving aMean Absolute Error (MAE) of 4.94 for age prediction and over 99.81% accuracyfor gender classification across various datasets. Our system improves uponexisting models by up to relative 30% in MAE and up to relative 10% in accuracyand F1 scores across tasks, leveraging a diverse range of datasets and largepretrained models to ensure robustness and generalizability. This study offersnew insights into speaker diversity and provides a strong foundation for futureresearch in speech-based demographic profiling.</description>
      <author>example@mail.com (Yuchen Yang, Thomas Thebaud, Najim Dehak)</author>
      <guid isPermaLink="false">2502.12007v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Real-time Neural Rendering of LiDAR Point Clouds</title>
      <link>http://arxiv.org/abs/2502.11618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, 1 table,&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;静态LiDAR扫描仪可以生成准确、密集且彩色的点云数据，但由于包含明显的伪影（如遮挡导致的数据缺失），直接显示时效果较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法，用于从这些LiDAR扫描中渲染逼真的图像，并不涉及昂贵的预处理或特定场景模型的训练。&lt;h4&gt;方法&lt;/h4&gt;{'关键步骤1': '使用朴素投影法（1x1像素）将点云数据投影到输出视图上。该方法速度快且保留细节，但会导致背景点泄漏至前景像素区域形成难以理解的结果。', '关键步骤2': '利用U-Net深度卷积模型和基于深度的预处理算法来优化投影结果。', '具体问题解决': '提出的解决方案可以有效地应对LiDAR特有的问题如遮挡导致的数据缺失、颜色不一致性和点密度变化等。'}&lt;h4&gt;主要发现&lt;/h4&gt;通过合成训练数据的方法解决了地面真实图像不完全对齐的问题，该方法在使用现成GPU时能够实现实时渲染速度，并且在速度和质量上都优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能在不需要昂贵预处理或特定场景模型训练的情况下生成逼真的LiDAR扫描图像，具有速度快、效果好的优点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Static LiDAR scanners produce accurate, dense, colored point clouds, butoften contain obtrusive artifacts which makes them ill-suited for directdisplay. We propose an efficient method to render photorealistic images of suchscans without any expensive preprocessing or training of a scene-specificmodel. A naive projection of the point cloud to the output view using 1x1pixels is fast and retains the available detail, but also results inunintelligible renderings as background points leak in between the foregroundpixels. The key insight is that these projections can be transformed into arealistic result using a deep convolutional model in the form of a U-Net, and adepth-based heuristic that prefilters the data. The U-Net also handlesLiDAR-specific problems such as missing parts due to occlusion, colorinconsistencies and varying point densities. We also describe a method togenerate synthetic training data to deal with imperfectly-aligned ground truthimages. Our method achieves real-time rendering rates using an off-the-shelfGPU and outperforms the state-of-the-art in both speed and quality.</description>
      <author>example@mail.com (Joni Vanherck, Brent Zoomers, Tom Mertens, Lode Jorissen, Nick Michiels)</author>
      <guid isPermaLink="false">2502.11618v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Large Language-Geometry Model: When LLM meets Equivariance</title>
      <link>http://arxiv.org/abs/2502.11149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的框架EquiLLM，它将几何感知提示、等变编码器、大语言模型和等变适配器结合在一起，用于表示三维物理系统。&lt;h4&gt;背景&lt;/h4&gt;现有的基于几何图神经网络（GNN）的方法在3D结构预测中表现出E(3)等变性，但它们难以利用广泛的外部信息。直接应用大型语言模型可以集成外部知识，但缺乏空间推理能力以及等变性保证。&lt;h4&gt;目的&lt;/h4&gt;开发一个新框架EquiLLM，它将大语言模型的能力与E(3)-等变性质结合在一起。&lt;h4&gt;方法&lt;/h4&gt;EquiLLM由四个关键组件组成：几何感知提示、等变编码器、大语言模型和等变适配器。该方法通过引导式提示指导的大语言模型处理不变特征，同时三维方向信息由等变编码器和适配器模块处理。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明EquiLLM在分子动力学模拟、人类运动模拟和抗体设计方面优于先前的方法，展示了其出色的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;EquiLLM框架成功地将大语言模型的外部知识集成能力和等变性质相结合，在多个领域表现出色，为准确预测3D物理系统的结构和动态提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;精确预测物理系统中的3D结构和动力学对于科学应用至关重要。现有的基于几何图神经网络（GNN）的方法虽然在E(3)等变性方面表现良好，但难以利用广泛的信息。直接使用大型语言模型可以整合外部知识，但缺乏空间推理能力以及确保的等变性。本文提出了一种新的框架EquiLLM，它将E(3)-等变性质与大语言模型的能力相结合。具体来说，EquiLLM由四个关键组件组成：几何感知提示、等变编码器、大语言模型和等变适配器。通过指导式提示引导的大语言模型作为高级不变特征处理器发挥作用，而三维方向信息则专门由等变编码器和适配器模块处理。实验结果表明，在分子动力学模拟、人类运动模拟和抗体设计方面，EquiLLM显著优于先前的方法，展示了其出色的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting 3D structures and dynamics of physical systems iscrucial in scientific applications. Existing approaches that rely on geometricGraph Neural Networks (GNNs) effectively enforce $\mathrm{E}(3)$-equivariance,but they often fall in leveraging extensive broader information. While directapplication of Large Language Models (LLMs) can incorporate external knowledge,they lack the capability for spatial reasoning with guaranteed equivariance. Inthis paper, we propose EquiLLM, a novel framework for representing 3D physicalsystems that seamlessly integrates E(3)-equivariance with LLM capabilities.Specifically, EquiLLM comprises four key components: geometry-aware prompting,an equivariant encoder, an LLM, and an equivariant adaptor. Essentially, theLLM guided by the instructive prompt serves as a sophisticated invariantfeature processor, while 3D directional information is exclusively handled bythe equivariant encoder and adaptor modules. Experimental results demonstratethat EquiLLM delivers significant improvements over previous methods acrossmolecular dynamics simulation, human motion simulation, and antibody design,highlighting its promising generalizability.</description>
      <author>example@mail.com (Zongzhao Li, Jiacheng Cen, Bing Su, Wenbing Huang, Tingyang Xu, Yu Rong, Deli Zhao)</author>
      <guid isPermaLink="false">2502.11149v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Without Paired Labeled Data: An End-to-End Self-Supervised Paradigm for UAV-View Geo-Localization</title>
      <link>http://arxiv.org/abs/2502.11381v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种轻量级的端到端自监督框架DMNIL，用于无人机视图地理定位。该框架通过基于双路径聚类对比学习架构建模同一视图内的结构关系，并利用动态记忆驱动分层学习模块逐步挖掘局部和全局信息，提高了模型鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有方法主要依赖于需要标注成对数据进行训练的监督学习范式，这带来了高昂的数据注释成本，阻碍了大规模部署。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要配对训练数据的方法来克服上述限制，并提高无人机地理定位的准确性与鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种动态记忆驱动和邻域信息学习网络(DMNIL)，该框架利用基于双路径聚类的对比学习架构建模同一视图内的结构关系，同时引入了动态记忆驱动分层模块挖掘局部和全局特征。此外，还提出一种信息一致性进化学习机制来探索无人机与卫星图像之间的领域差距。&lt;h4&gt;主要发现&lt;/h4&gt;DMNIL框架在三个基准数据集上取得了接近现有最优监督方法的性能，并且无需配对训练数据的支持，证明了其计算效率及实用性。&lt;h4&gt;结论&lt;/h4&gt;提出的DMNIL网络不仅提高了地理定位精度和模型鲁棒性，而且由于不需要昂贵的数据标注过程而更加适合实际应用部署。代码即将发布。&lt;h4&gt;翻译&lt;/h4&gt;UAV-View Geo-Localization (UVGL)旨在通过检索最相似的带有GPS标签的卫星图像来确定无人机的确切位置。然而，现有的方法主要依赖于需要成对训练数据进行监督学习的方法，这带来了高昂的数据标注成本，并阻碍了大规模部署。为了克服这一限制，我们提出了一种轻量级的端到端自监督框架DMNIL（Dynamic Memory-Driven and Neighborhood Information Learning）。该框架通过基于双路径聚类对比学习架构建模同一视图内的结构关系，增强了特征的一致性和区分度。同时，提出了动态记忆驱动分层学习模块以逐步挖掘局部和全局信息，强化多级特征关联来提高模型鲁棒性。为了缩小无人机与卫星视图之间的领域差距，我们设计了一种信息一致性进化学习机制系统地探索同一视图内部的潜在关系以及跨视图领域的联系，最终构建统一的跨视图特征表示空间。在三个基准数据集上的广泛实验表明，DMNIL达到了接近最先进的监督方法的表现水平，同时保持了计算效率。值得注意的是，这种优越性是在没有依赖配对训练数据的情况下实现的，突显出该框架的实际部署潜力。代码将在近期发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; UAV-View Geo-Localization (UVGL) aims to ascertain the precise location of aUAV by retrieving the most similar GPS-tagged satellite image. However,existing methods predominantly rely on supervised learning paradigms thatnecessitate annotated paired data for training, which incurs substantialannotation costs and impedes large-scale deployment. To overcome thislimitation, we propose the Dynamic Memory-Driven and Neighborhood InformationLearning (DMNIL) network, a lightweight end-to-end self-supervised frameworkfor UAV-view geo-localization. The DMNIL framework utilizes a dual-pathclustering-based contrastive learning architecture as its baseline to modelintra-view structural relationships, enhancing feature consistency anddiscriminability. Additionally, a dynamic memory-driven hierarchical learningmodule is proposed to progressively mine local and global information,reinforcing multi-level feature associations to improve model robustness. Tobridge the domain gap between UAV and satellite views, we design aninformation-consistent evolutionary learning mechanism that systematicallyexplores latent correlations within intra-view neighborhoods and acrosscross-view domains, ultimately constructing a unified cross-view featurerepresentation space. Extensive experiments on three benchmarks(University-1652, SUES-200, and DenseUAV) demonstrate that DMNIL achievescompetitive performance against state-of-the-art supervised methods whilemaintaining computational efficiency. Notably, this superiority is attainedwithout relying on paired training data, underscoring the framework'spracticality for real-world deployment. Codes will be released soon.</description>
      <author>example@mail.com (Zhongwei Chen, Zhao-Xu Yang, Hai-Jun Rong)</author>
      <guid isPermaLink="false">2502.11381v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Personalized Ranking on Cascading Behavior Graphs for Accurate Multi-Behavior Recommendation</title>
      <link>http://arxiv.org/abs/2502.11335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了CascadingRank，一种用于多行为推荐的新颖图排名方法。&lt;h4&gt;背景&lt;/h4&gt;现有的多行为推荐方法分为表征学习和图排序两类。前者通过生成用户和项目的嵌入来捕捉潜在的交互模式，但常受过度平滑和频繁互动偏见的影响；后者直接计算个性化评分以更好地反映用户的偏好，但在多行为场景中的应用较少。&lt;h4&gt;目的&lt;/h4&gt;提出CascadingRank方法，利用级联行为图模型自然的行为序列，并通过迭代算法计算排名分数，确保其在平滑性、查询适应性和级联对齐方面的性能。&lt;h4&gt;方法&lt;/h4&gt;1. CascadingRank通过级联行为图来建模用户行为的自然顺序。2. 使用迭代算法计算评分以优化推荐结果。3. 提供理论分析以展示CascadingRank的有效性，收敛性和可扩展性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CascadingRank在三个真实世界数据集上优于现有技术方法，HR@10和NDCG@10分别提高了9.56%和7.16%。&lt;h4&gt;结论&lt;/h4&gt;研究表明，图排序方法适用于多行为推荐，能够显著提高推荐性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的直接中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-behavior recommendation predicts items a user may purchase by analyzingdiverse behaviors like viewing, adding to a cart, and purchasing. Existingmethods fall into two categories: representation learning and graph ranking.Representation learning generates user and item embeddings to capture latentinteraction patterns, leveraging multi-behavior properties for bettergeneralization. However, these methods often suffer from over-smoothing andbias toward frequent interactions, limiting their expressiveness. Graph rankingmethods, on the other hand, directly compute personalized ranking scores,capturing user preferences more effectively. Despite their potential, graphranking approaches have been primarily explored in single-behavior settings andremain underutilized for multi-behavior recommendation. In this paper, wepropose CascadingRank, a novel graph ranking method for multi-behaviorrecommendation. It models the natural sequence of user behaviors (e.g.,viewing, adding to cart, and purchasing) through a cascading behavior graph. Aniterative algorithm computes ranking scores, ensuring smoothness, queryfitting, and cascading alignment. Experiments on three real-world datasetsdemonstrate that CascadingRank outperforms state-of-the-art methods, with up to9.56% and 7.16% improvements in HR@10 and NDCG@10, respectively. Furthermore,we provide theoretical analysis highlighting its effectiveness, convergence,and scalability, showcasing the advantages of graph ranking in multi-behaviorrecommendation.</description>
      <author>example@mail.com (Geonwoo Ko, Minseo Jeon, Jinhong Jung)</author>
      <guid isPermaLink="false">2502.11335v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Cheesemap: A High-Performance Point-Indexing Data Structure for Neighbor~Search in LiDAR Data</title>
      <link>http://arxiv.org/abs/2502.11602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提供了一种针对点云数据的全面比较分析，引入了名为cheesemap的新数据结构来处理3D LiDAR点云，并展示了其在不同类型的点云（特别是ALS）中的性能优势。&lt;h4&gt;背景&lt;/h4&gt;点云数据作为三维空间信息的表示，在物体识别、自主导航和环境建模等任务中至关重要。高效的索引和查询对于提高这些应用的效果来说非常重要。&lt;h4&gt;目的&lt;/h4&gt;论文旨在通过比较分析各种数据结构及其邻域搜索方法，引入新的cheesemap数据结构来优化3D LiDAR点云的处理效率。&lt;h4&gt;方法&lt;/h4&gt;该研究采用了多种数据结构结合不同的邻域搜索方法对不同类型（密集、稀疏和混合）的点云进行了全面评估，并测试了新提出的cheesemap在这些情况下的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，新的cheesemap数据结构在执行时间和内存消耗方面优于现有的先进技术，特别是在ALS点云中表现尤为突出。&lt;h4&gt;结论&lt;/h4&gt;cheesemap由于其高效的查询时间和较低的内存使用量，在处理三维点云的应用场景下表现出色，尤其适用于大规模稀疏和混合类型的点云数据集。&lt;h4&gt;翻译&lt;/h4&gt;点云数据作为三维空间信息的表现形式，在物体识别、自主导航以及环境建模等各个领域中扮演着重要角色。文中提出了一种新的数据结构——cheesemap，旨在更有效地索引和查询3D LiDAR点云，并针对不同的点分布情况设计了三种版本：密集型、稀疏型及混合型。实验证明，相比于现有方法，这种新型的数据结构在执行效率上具有明显的优势，尤其是在ALS（空中激光扫描）点云场景下性能尤为突出，同时其内存消耗较低，特别是在处理稀疏和混合类型数据时表现更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud data, as the representation of three-dimensional spatialinformation, is a fundamental piece of information in various domains whereindexing and querying these point clouds efficiently is crucial for tasks suchas object recognition, autonomous navigation, and environmental modeling. Inthis paper, we present a comprehensive comparative analysis of various datastructures combined with neighboring search methods across different types ofpoint clouds. Additionally, we introduce a novel data structure, cheesemap, tohandle 3D LiDAR point clouds. Exploring the sparsity and irregularity in thedistribution of points, there are three flavors of the cheesemap: dense,sparse, and mixed. Results show that the cheesemap can outperformstate-of-the-art data structures in terms of execution time per query,particularly for ALS (Aerial Laser Scanning) point clouds. Memory consumptionis also minimal, especially in the sparse and mixed representations, making thecheesemap a suitable choice for applications involving three-dimensional pointclouds.</description>
      <author>example@mail.com (Ruben Laso, Miguel Yermo)</author>
      <guid isPermaLink="false">2502.11602v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>ILIAS: Instance-Level Image retrieval At Scale</title>
      <link>http://arxiv.org/abs/2502.11748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的测试数据集ILIAS，用于评估大规模实例级图像检索的能力。&lt;h4&gt;背景&lt;/h4&gt;当前的基准测试不足以全面评估大型基础模型和检索技术在识别特定对象时的表现。&lt;h4&gt;目的&lt;/h4&gt;创建一个大规模、跨领域多样性且带有准确真实性的测试数据集，以充分挑战现有的图像检索方法。&lt;h4&gt;方法&lt;/h4&gt;ILIAS包含了1000个物体实例的查询图片及其正样本图片，并与来自YFCC100M的数据集中的一亿张干扰图进行大规模检索。&lt;h4&gt;主要发现&lt;/h4&gt;{'模型性能差异': '特定领域微调的模型在它们擅长的领域表现优秀，但在ILIAS上却失效了；', '多域学习提升': '通过使用多个领域的类别监督来学习线性适配层可以提高性能，特别是对于视觉-语言模型来说；', '局部描述子作用': '检索重新排名中的局部描述子仍然是一个关键因素，在存在严重背景干扰的情况下尤其重要；', '文本到图像性能': '视觉-语言基础模型的文本到图像性能与对应的图像到图像情况非常接近。'}&lt;h4&gt;结论&lt;/h4&gt;ILIAS是一个评估大型基础模型和检索技术在大规模实例级图像检索中能力的有效工具。&lt;h4&gt;翻译&lt;/h4&gt;这项工作引入了ILIAS，这是一个新的测试数据集，用于评估当前和未来的基础模型以及检索方法识别特定对象的能力。相较于现有的数据集，它具有规模大、领域多样性和准确的真实标签等优势，并且其性能尚未饱和。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces ILIAS, a new test dataset for Instance-Level Imageretrieval At Scale. It is designed to evaluate the ability of current andfuture foundation models and retrieval techniques to recognize particularobjects. The key benefits over existing datasets include large scale, domaindiversity, accurate ground truth, and a performance that is far from saturated.ILIAS includes query and positive images for 1,000 object instances, manuallycollected to capture challenging conditions and diverse domains. Large-scaleretrieval is conducted against 100 million distractor images from YFCC100M. Toavoid false negatives without extra annotation effort, we include only queryobjects confirmed to have emerged after 2014, i.e. the compilation date ofYFCC100M. An extensive benchmarking is performed with the followingobservations: i) models fine-tuned on specific domains, such as landmarks orproducts, excel in that domain but fail on ILIAS ii) learning a linearadaptation layer using multi-domain class supervision results in performanceimprovements, especially for vision-language models iii) local descriptors inretrieval re-ranking are still a key ingredient, especially in the presence ofsevere background clutter iv) the text-to-image performance of thevision-language foundation models is surprisingly close to the correspondingimage-to-image case. website: https://vrg.fel.cvut.cz/ilias/</description>
      <author>example@mail.com (Giorgos Kordopatis-Zilos, Vladan Stojnić, Anna Manko, Pavel Šuma, Nikolaos-Antonios Ypsilantis, Nikos Efthymiadis, Zakaria Laskar, Jiří Matas, Ondřej Chum, Giorgos Tolias)</author>
      <guid isPermaLink="false">2502.11748v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Deep Contrastive Learning for Feature Alignment: Insights from Housing-Household Relationship Inference</title>
      <link>http://arxiv.org/abs/2502.11205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发了一种基于深度对比学习(DCL)的模型，用于分析美国社区调查(ACS)公共使用微数据样本(PUMS)中的住房与家庭之间的关系。&lt;h4&gt;背景&lt;/h4&gt;住房及住户特征是社会经济福祉的关键决定因素，但目前对它们之间相互影响的理解仍存在局限性。&lt;h4&gt;目的&lt;/h4&gt;填补知识空白，利用深度对比学习模型研究和理解住房与住户之间的联系，并提出适用于无明确标签数据问题的一般方法论框架。&lt;h4&gt;方法&lt;/h4&gt;采用双编码器的DCL架构，通过PUMS中的共现模式识别引入了一种二分K均值聚类技术来处理缺乏地面真实标签的问题。此外，模型设计考虑了住房与住户特征之间的语义差异，并且可以减少由聚类过程产生的噪声。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在特拉华州表现出比现有最佳方法更强的能力，在北卡罗莱纳州的可迁移性测试中也证明了其跨多种社会人口和地理背景的一般适用性。此外，通过SHAP值进行事后解释性人工智能分析表明：产权状态和按揭信息对于住房与住户匹配的影响大于传统重视的因素（如人员数量和房间数）。&lt;h4&gt;结论&lt;/h4&gt;研究提出的DCL模型在解决缺乏明确标签的数据问题方面表现出了优越性，并且为社会经济福祉相关领域的进一步研究提供了强有力的方法支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Housing and household characteristics are key determinants of social andeconomic well-being, yet our understanding of their interrelationships remainslimited. This study addresses this knowledge gap by developing a deepcontrastive learning (DCL) model to infer housing-household relationships usingthe American Community Survey (ACS) Public Use Microdata Sample (PUMS). Morebroadly, the proposed model is suitable for a class of problems where the goalis to learn joint relationships between two distinct entities withoutexplicitly labeled ground truth data. Our proposed dual-encoder DCL approachleverages co-occurrence patterns in PUMS and introduces a bisect K-meansclustering method to overcome the absence of ground truth labels. Thedual-encoder DCL architecture is designed to handle the semantic differencesbetween housing (building) and household (people) features while mitigatingnoise introduced by clustering. To validate the model, we generate a syntheticground truth dataset and conduct comprehensive evaluations. The model furtherdemonstrates its superior performance in capturing housing-householdrelationships in Delaware compared to state-of-the-art methods. Atransferability test in North Carolina confirms its generalizability acrossdiverse sociodemographic and geographic contexts. Finally, the post-hocexplainable AI analysis using SHAP values reveals that tenure status andmortgage information play a more significant role in housing-household matchingthan traditionally emphasized factors such as the number of persons and rooms.</description>
      <author>example@mail.com (Xiao Qian, Shangjia Dong, Rachel Davidson)</author>
      <guid isPermaLink="false">2502.11205v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Deep Incomplete Multi-view Learning via Cyclic Permutation of VAEs</title>
      <link>http://arxiv.org/abs/2502.11037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures, ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为多视角置换变分自编码器（MVP）的方法，用于处理缺失不规则的数据情况下的多视图表示学习。&lt;h4&gt;背景&lt;/h4&gt;当前的多视图表征学习技术在面对不规则数据缺失时会生成缺乏充分性和一致性的表征。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来解决由不完整数据引起的表示不足和一致性问题，该方法能够从不规则丢失的数据中挖掘出不同视图之间的不变关系。&lt;h4&gt;方法&lt;/h4&gt;引入了MVP模型，在变分自编码器的潜在空间内建立了跨视角对应，并通过随机排列变量来进行交叉视图生成。此外，使用循环后验置换来增强一致性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的MVP方法在具有不同缺失比率的七种多样数据集上进行了测试，证明了其在多视图聚类和生成任务中的优越性能。&lt;h4&gt;结论&lt;/h4&gt;MVP成功地解决了由不规则丢失引起的表示不足和一致性问题，并展示了在处理缺失不规则的数据时的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容为：多视角表征学习（MVRL）旨在通过利用不同视图间的共享信息以及互补信息来从多视图数据中推导出统一的表征。然而，当视图以不规则方式丢失时，这种不完整数据会导致生成的表示不足和缺乏一致性。为了应对这一挑战，我们提出了一种名为多视角置换变分自编码器（MVP）的方法，该方法挖掘了在缺失数据中不同视图之间的不变关系。通过建立潜在空间中的跨视角对应，MVP能够推断出缺失的视图并汇总更多的充分信息。为学习时获得有效的证据下界（ELBO），我们应用置换来随机重新排列变量以进行交叉视图生成，并将其按视图分割以便在置换条件下保持不变的意义。此外，通过引入带有循环后验置换的信息先验，增强了表示的一致性，将正则化项转换为分布之间的相似度量。我们在具有不同缺失率的七个多样数据集上展示了我们方法的有效性，在多视角聚类和生成任务中取得了优越的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-View Representation Learning (MVRL) aims to derive a unifiedrepresentation from multi-view data by leveraging shared and complementaryinformation across views. However, when views are irregularly missing, theincomplete data can lead to representations that lack sufficiency andconsistency. To address this, we propose Multi-View Permutation of VariationalAuto-Encoders (MVP), which excavates invariant relationships between views inincomplete data. MVP establishes inter-view correspondences in the latent spaceof Variational Auto-Encoders, enabling the inference of missing views and theaggregation of more sufficient information. To derive a valid Evidence LowerBound (ELBO) for learning, we apply permutations to randomly reorder variablesfor cross-view generation and then partition them by views to maintaininvariant meanings under permutations. Additionally, we enhance consistency byintroducing an informational prior with cyclic permutations of posteriors,which turns the regularization term into a similarity measure acrossdistributions. We demonstrate the effectiveness of our approach on sevendiverse datasets with varying missing ratios, achieving superior performance inmulti-view clustering and generation tasks.</description>
      <author>example@mail.com (Xin Gao, Jian Pu)</author>
      <guid isPermaLink="false">2502.11037v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Doppler Correspondence: Non-Iterative Scan Matching With Doppler Velocity-Based Correspondence</title>
      <link>http://arxiv.org/abs/2502.11461v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在恶劣天气条件或重复几何图案等挑战性环境中，LiDAR测距性能会受到负面影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于多普勒速度的方法来改进4D LiDAR和雷达技术中的扫描匹配。&lt;h4&gt;方法&lt;/h4&gt;首次提出了一个简单且鲁棒的多普勒对应关系（Doppler Correspondence），该方法利用点云数据的时间、空间信息和速度信息，不依赖于迭代最近邻搜索算法。它能有效应对小角度旋转和平移变化。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明所提出的非迭代直接匹配算法效率高，并且能够更准确地估计重复几何环境中点之间的对应关系。&lt;h4&gt;结论&lt;/h4&gt;基于多普勒速度的扫描匹配方法能够在不良条件下提高LiDAR测距系统的性能，具有重要的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;实现成功的扫描配准对于激光雷达里程计至关重要。然而，在恶劣天气条件或存在重复几何图案等挑战性环境中，由于不正确的扫描配准，会导致激光雷达测距性能下降。最近出现的调频连续波4D LiDAR和4D雷达技术提供了解决这些不利条件的可能性。所谓的“4D”是指在距离、方位角和高度的基础上增加了多普勒速度信息。尽管可以获取这种数据，但大多数现有的用于4D LiDAR和4D雷达扫描配准的方法仍然通过反复识别连续扫描之间的最近点来建立对应关系，忽略了多普勒信息的作用。本文首次引入了一种简单基于多普勒速度的对应方法——“多普勒对应”（Doppler Correspondence），该方法不受传感器平移或小旋转的影响，并且具有几何和运动学基础理论支持。广泛的实验表明所提出的直接匹配连续点云的方法不需要迭代过程，因此计算效率更高，并且在重复几何环境中提供了更加稳健的对应关系估计能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving successful scan matching is essential for LiDAR odometry. However,in challenging environments with adverse weather conditions or repetitivegeometric patterns, LiDAR odometry performance is degraded due to incorrectscan matching. Recently, the emergence of frequency-modulated continuous wave4D LiDAR and 4D radar technologies has provided the potential to address theseunfavorable conditions. The term 4D refers to point cloud data characterized byrange, azimuth, and elevation along with Doppler velocity. Although 4D data isavailable, most scan matching methods for 4D LiDAR and 4D radar still establishcorrespondence by repeatedly identifying the closest points between consecutivescans, overlooking the Doppler information. This paper introduces, for thefirst time, a simple Doppler velocity-based correspondence -- DopplerCorrespondence -- that is invariant to translation and small rotation of thesensor, with its geometric and kinematic foundations. Extensive experimentsdemonstrate that the proposed method enables the direct matching of consecutivepoint clouds without an iterative process, making it computationally efficient.Additionally, it provides a more robust correspondence estimation inenvironments with repetitive geometric patterns.</description>
      <author>example@mail.com (Jiwoo Kim, Geunsik Bae, Changseung Kim, Jinwoo Lee, Woojae Shin, Hyondong Oh)</author>
      <guid isPermaLink="false">2502.11461v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Hyperspherical Energy Transformer with Recurrent Depth</title>
      <link>http://arxiv.org/abs/2502.11646v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 13 figures, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种新的Transformer架构，即Hyper-SET，旨在提高模型的可解释性和实际性能。&lt;h4&gt;背景&lt;/h4&gt;基于Transformer的基础模型已经取得了巨大的成功，但其核心构建块（Transformer层）的设计主要依赖于从下至上的工程方法和直觉驱动。这些设计缺乏高可解释性，并且难以扩展到更深的层次。&lt;h4&gt;目的&lt;/h4&gt;为了探索下一代架构，该研究旨在设计一种具有高可解释性和实际性能的基础模型。&lt;h4&gt;方法&lt;/h4&gt;该论文采用自顶向下视角，从能量最小化角度设计神经网络。通过在嵌入子空间的超球体上修改Hopfield能量函数，设计了具有对称结构的Transformer层作为能量函数迭代优化的一部分。整合具有相同参数设置的层数后提出了Hyper-SET架构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在合成和现实世界任务（如解决数独和掩码图像建模）中，Hyper-SET能够利用更少的参数实现与标准Transformer相当甚至更好的性能。&lt;h4&gt;结论&lt;/h4&gt;通过采用新的设计思路，该论文提出了一种新型的高效、可扩展且具有高解释性的模型架构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based foundation models have achieved unprecedented success witha gigantic amount of parameters and computational resources. Yet, the corebuilding blocks of these models, the Transformer layers, and how they arearranged and configured are primarily engineered from the bottom up and drivenby heuristics. For advancing next-generation architectures, it demandsexploring a prototypical model that is amenable to high interpretability and ofpractical competence. To this end, we take a step from the top-down view anddesign neural networks from an energy minimization perspective. Specifically,to promote isotropic token distribution on the sphere, we formulate a modifiedHopfield energy function on the subspace-embedded hypersphere, based on whichTransformer layers with symmetric structures are designed as the iterativeoptimization for the energy function. By integrating layers with the sameparameters, we propose \textit{Hyper-Spherical Energy Transformer} (Hyper-SET),an alternative to the vanilla Transformer with recurrent depth. This designinherently provides greater interpretability and allows for scaling to deeperlayers without a significant increase in the number of parameters. We alsoempirically demonstrate that Hyper-SET achieves comparable or even superiorperformance on both synthetic and real-world tasks, such as solving Sudoku andmasked image modeling, while utilizing fewer parameters.</description>
      <author>example@mail.com (Yunzhe Hu, Difan Zou, Dong Xu)</author>
      <guid isPermaLink="false">2502.11646v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening</title>
      <link>http://arxiv.org/abs/2502.11001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Gen Zhou and Sugitha Janarthanan contributed equally; Accepted at  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;针对抗菌药物研发领域中抗微生物耐药性的挑战，研究人员利用机器学习技术来预测和开发具有抗生素潜力的新化合物。本文提出了CL-MFAP模型，这是一个基于对比学习的多模态基础模型，用于发现可能具有抗菌特性的小分子。&lt;h4&gt;背景&lt;/h4&gt;由于抗生素耐药性问题日益严重，寻找新型具有潜在抗菌作用的化合物变得至关重要。然而，传统药物开发方法成本高且效率低下。因此，研究人员转向机器学习技术以加速新抗生素化合物的研发进程。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于对比学习（CL）的多模态基础模型，该模型专门用于发现可能具有抗微生物特性的小分子，并通过利用三种类型的数据来提高抗菌特性预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用了来自ChEMBL数据集中的160万种具有药物样性质的生物活性分子进行预训练，包括：（1）带有旋转位置嵌入的SMILES字符串处理变换器编码器；（2）用于处理分子图表示的新颖双层路由注意机制的变换器编码器；以及（3）使用多层感知机的Morgan指纹编码器。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在抗生素性质预测任务中优于基线模型，并且当针对与抗生素相关的特性预测任务进行微调时，表现出优异的专业领域性能。&lt;h4&gt;结论&lt;/h4&gt;CL-MFAP通过有效利用不同的分子模态，在抗菌剂开发的预训练和微调过程中展示了出色的性能。这表明，多模式数据在新型抗生素发现中的价值尚未被完全挖掘出来。&lt;h4&gt;翻译&lt;/h4&gt;鉴于全球公共卫生问题中抗微生物耐药性的增加，寻找具有潜在抗生素特性的新化合物至关重要。然而，传统的药物研发方式既昂贵又低效。研究人员已经转向使用机器学习技术来预测和开发新的抗菌化合物。虽然基础模型在抗生素发现方面显示出前景，但主流努力仍未能充分利用多模式分子数据的潜力。研究表明，利用对比学习框架进行跨领域表示学习时，结合多种模态的数据可以表现出卓越性能。基于此，我们推出了CL-MFAP，这是一种专门用于从三种类型的分子数据中识别潜在抗菌特性的新型小分子发现模型。该模型使用ChEMBL数据集中具有药物样性质的160万种生物活性分子进行预训练，包括：（1）带有旋转位置嵌入处理SMILES字符串的变换器编码器；（2）为处理分子图表示设计的一种新颖双层路由注意机制的变换器编码器；以及（3）使用多层感知机的Morgan指纹编码器。CL-MFAP在抗生素特性预测中优于基线模型，通过有效利用不同模态的数据，并且当针对与抗生素相关的特性预测任务进行微调时表现出优异的专业领域性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the rise in antimicrobial resistance, identifying novel compounds withantibiotic potential is crucial for combatting this global health issue.However, traditional drug development methods are costly and inefficient.Recognizing the pressing need for more effective solutions, researchers haveturned to machine learning techniques to streamline the prediction anddevelopment of novel antibiotic compounds. While foundation models have shownpromise in antibiotic discovery, current mainstream efforts still fall short offully leveraging the potential of multimodal molecular data. Recent studiessuggest that contrastive learning frameworks utilizing multimodal data exhibitexcellent performance in representation learning across various domains.Building upon this, we introduce CL-MFAP, an unsupervised contrastive learning(CL)-based multimodal foundation (MF) model specifically tailored fordiscovering small molecules with potential antibiotic properties (AP) usingthree types of molecular data. This model employs 1.6 million bioactivemolecules with drug-like properties from the ChEMBL dataset to jointly pretrainthree encoders: (1) a transformer-based encoder with rotary position embeddingfor processing SMILES strings; (2) another transformer-based encoder,incorporating a novel bi-level routing attention mechanism to handle moleculargraph representations; and (3) a Morgan fingerprint encoder using a multilayerperceptron, to achieve the contrastive learning purpose. The CL-MFAPoutperforms baseline models in antibiotic property prediction by effectivelyutilizing different molecular modalities and demonstrates superiordomain-specific performance when fine-tuned for antibiotic-related propertyprediction tasks.</description>
      <author>example@mail.com (Gen Zhou, Sugitha Janarthanan, Yutong Lu, Pingzhao Hu)</author>
      <guid isPermaLink="false">2502.11001v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>iMOVE: Instance-Motion-Aware Video Understanding</title>
      <link>http://arxiv.org/abs/2502.11594v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了iMOVE视频基础模型，该模型通过引入事件感知时空高效建模和相对时空位置令牌机制来增强对视频中细粒度实例时空运动的感知能力。&lt;h4&gt;背景&lt;/h4&gt;目前的视频大语言模型在理解和捕捉视频中的细粒度实例时空运动细节方面存在不足，这限制了它们的时间理解和泛化视频理解的能力。&lt;h4&gt;目的&lt;/h4&gt;通过数据和模型两方面的改进来增强视频中细粒度实例时空运动的理解能力。&lt;h4&gt;方法&lt;/h4&gt;{'数据层面': '精心制作iMOVE-IT，这是一个新的大规模视频指令微调数据集，该数据集包含丰富的实例运动注释及空间时间互监督任务。', '模型层面': '提出了iMOVE模型，它利用事件感知时空高效建模来保留信息丰富的实例时空运动细节，并通过相对时空位置令牌机制确保实例的时空位置意识。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，iMOVE在视频的时间理解、泛化视频理解和长期视频理解方面都表现出显著优势。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的数据集和改进模型结构，能够有效提高视频中细粒度实例时空运动的理解能力，从而提升视频分析的准确性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Enhancing the fine-grained instance spatiotemporal motion perceptioncapabilities of Video Large Language Models is crucial for improving theirtemporal and general video understanding. However, current models struggle toperceive detailed and complex instance motions. To address these challenges, wehave made improvements from both data and model perspectives. In terms of data,we have meticulously curated iMOVE-IT, the first large-scaleinstance-motion-aware video instruction-tuning dataset. This dataset isenriched with comprehensive instance motion annotations and spatiotemporalmutual-supervision tasks, providing extensive training for the model'sinstance-motion-awareness. Building on this foundation, we introduce iMOVE, aninstance-motion-aware video foundation model that utilizes Event-awareSpatiotemporal Efficient Modeling to retain informative instance spatiotemporalmotion details while maintaining computational efficiency. It also incorporatesRelative Spatiotemporal Position Tokens to ensure awareness of instancespatiotemporal positions. Evaluations indicate that iMOVE excels not only invideo temporal understanding and general video understanding but alsodemonstrates significant advantages in long-term video understanding.</description>
      <author>example@mail.com (Jiaze Li, Yaya Shi, Zongyang Ma, Haoran Xu, Feng Cheng, Huihui Xiao, Ruiwen Kang, Fan Yang, Tingting Gao, Di Zhang)</author>
      <guid isPermaLink="false">2502.11594v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model</title>
      <link>http://arxiv.org/abs/2502.10707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 8 figures, accepted by International Conference on Learning  Representations 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;心电图(ECG)在心律失常和其他心脏病的临床诊断中至关重要，但基于ECG的深度学习方法由于需要高质量注释而面临限制。尽管之前的心电图自监督学习(eSSL)方法从未标注的ECG数据中进行表示学习方面取得了显著进展，它们通常将ECG信号视为普通时间序列数据，并使用固定大小和步长的时间窗口分割信号，这往往忽略了心电信号的形式、节奏特征及其潜在语义关系。在这项工作中，我们引入了对ECG信号的新视角，将其心脏跳动视为单词，而节奏则被视为句子。基于这种观点，首先设计QRS-Tokenizer，从原始心电图数据中生成具有语义意义的心电图句子。在此基础上，提出HeartLang，一种新的自监督学习框架，用于处理ECG语言，在形式和节奏水平上进行通用表示的学习。此外，我们构建了迄今为止最大的基于心跳的ECG词汇表，这将进一步促进ECG语言处理的发展。我们在六个公开心电图数据集上对HeartLang进行了评估，它在与其他eSSL方法的竞争中表现出强大的竞争力。&lt;h4&gt;背景&lt;/h4&gt;目前基于ECG的心律失常和其他心脏疾病的诊断依赖深度学习方法，然而这些方法由于需要高质量的注释而受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的视角和自监督框架来改进ECG信号处理，并构建一个大型的ECG词汇表以促进该领域的发展。&lt;h4&gt;方法&lt;/h4&gt;设计QRS-Tokenizer从原始心电图数据中生成有意义的心电图句子，提出了HeartLang这一基于新观点的自监督学习框架，以及构建了迄今为止最大的心跳为基础的ECG词汇表。&lt;h4&gt;主要发现&lt;/h4&gt;HeartLang在形式和节奏水平上进行通用表示的学习，并通过六个公开的数据集验证其有效性与竞争力。&lt;h4&gt;结论&lt;/h4&gt;提出的QRS-Tokenizer和HeartLang方法展示了心电图处理的新方向，且HeartLang显示了优越的表现，在实际应用中具有潜在的临床价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已全部翻译成中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electrocardiogram (ECG) is essential for the clinical diagnosis ofarrhythmias and other heart diseases, but deep learning methods based on ECGoften face limitations due to the need for high-quality annotations. Althoughprevious ECG self-supervised learning (eSSL) methods have made significantprogress in representation learning from unannotated ECG data, they typicallytreat ECG signals as ordinary time-series data, segmenting the signals usingfixed-size and fixed-step time windows, which often ignore the form and rhythmcharacteristics and latent semantic relationships in ECG signals. In this work,we introduce a novel perspective on ECG signals, treating heartbeats as wordsand rhythms as sentences. Based on this perspective, we first designed theQRS-Tokenizer, which generates semantically meaningful ECG sentences from theraw ECG signals. Building on these, we then propose HeartLang, a novelself-supervised learning framework for ECG language processing, learninggeneral representations at form and rhythm levels. Additionally, we constructthe largest heartbeat-based ECG vocabulary to date, which will further advancethe development of ECG language processing. We evaluated HeartLang across sixpublic ECG datasets, where it demonstrated robust competitiveness against othereSSL methods. Our data and code are publicly available athttps://github.com/PKUDigitalHealth/HeartLang.</description>
      <author>example@mail.com (Jiarui Jin, Haoyu Wang, Hongyan Li, Jun Li, Jiahui Pan, Shenda Hong)</author>
      <guid isPermaLink="false">2502.10707v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems</title>
      <link>http://arxiv.org/abs/2502.11127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了G-Safeguard，一种旨在增强基于大型语言模型的多智能体系统（LLM-MAS）安全性的方法。&lt;h4&gt;背景&lt;/h4&gt;当前的LLM-MAS在复杂任务中表现出了非凡的能力，但同时面临对抗性攻击、虚假信息传播和意外行为等风险。&lt;h4&gt;目的&lt;/h4&gt;提出G-Safeguard以检测并缓解LLM-MAS中的异常行为，提高其鲁棒性和安全性。&lt;h4&gt;方法&lt;/h4&gt;利用图神经网络分析多智能体话语图来发现异常，并使用拓扑干预进行攻击修复。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，G-Safeguard在各种攻击策略下表现出显著的有效性；它能够适应不同LLM架构和大规模MAS；并且可以与主流MAS安全结合。&lt;h4&gt;结论&lt;/h4&gt;通过代码公开，展示了G-Safeguard对于提高LLM-MAS的安全性的潜力。&lt;h4&gt;翻译&lt;/h4&gt;基于大型语言模型的多智能体系统（LLM-MAS）在各种复杂任务中表现出非凡的能力，但面临的安全问题促使研究人员提出了一种利用图神经网络进行异常检测和攻击缓解的方法。实验结果表明这种方法具有良好的适应性和效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Model (LLM)-based Multi-agent Systems (MAS) have demonstratedremarkable capabilities in various complex tasks, ranging from collaborativeproblem-solving to autonomous decision-making. However, as these systems becomeincreasingly integrated into critical applications, their vulnerability toadversarial attacks, misinformation propagation, and unintended behaviors haveraised significant concerns. To address this challenge, we introduceG-Safeguard, a topology-guided security lens and treatment for robust LLM-MAS,which leverages graph neural networks to detect anomalies on the multi-agentutterance graph and employ topological intervention for attack remediation.Extensive experiments demonstrate that G-Safeguard: (I) exhibits significanteffectiveness under various attack strategies, recovering over 40% of theperformance for prompt injection; (II) is highly adaptable to diverse LLMbackbones and large-scale MAS; (III) can seamlessly combine with mainstream MASwith security guarantees. The code is available athttps://github.com/wslong20/G-safeguard.</description>
      <author>example@mail.com (Shilong Wang, Guibin Zhang, Miao Yu, Guancheng Wan, Fanci Meng, Chongye Guo, Kun Wang, Yang Wang)</author>
      <guid isPermaLink="false">2502.11127v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Occlusion-aware Text-Image-Point Cloud Pretraining for Open-World 3D Object Recognition</title>
      <link>http://arxiv.org/abs/2502.10674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近的开放世界表示学习方法利用CLIP实现了零样本3D物体识别。然而，由于预训练设置与实际情况不符，真实点云中的遮挡问题仍然影响性能，且这些方法在推理过程中计算成本高。&lt;h4&gt;背景&lt;/h4&gt;当前的方法依赖于CLIP进行零样本3D对象识别，但由于预训练环境与实际场景存在差距以及使用Transformer带来的高计算需求，它们的性能仍有待提高。&lt;h4&gt;目的&lt;/h4&gt;提出新的预训练框架和模型来解决现有方法在处理真实世界点云时的遮挡问题，并降低推理成本。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种考虑遮挡情况下的文本-图像-点云联合预训练，生成大量模拟现实世界的不完整点云进行模型优化。2. 开发了DuoMamba模型，这是一种专为点云设计的两流线性状态空间模型，利用两个填充曲线和1维卷积来建模点之间的空间依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过提出的预训练框架生成的数据集显著提高了现有3D网络在实际环境中的识别性能；同时，新开发的DuoMamba模型不仅提升了性能，还降低了延迟和计算量。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法展示了在处理真实世界的点云数据时提高准确性和减少计算成本方面的巨大潜力，并计划发布相关资源以促进未来研究。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，通过CLIP进行零样本3D物体识别虽然有潜力，但在实际应用中仍然存在挑战。本文通过引入新的预训练方法和模型架构解决了这些问题，展示了在真实场景下的性能提升以及计算效率的改善。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent open-world representation learning approaches have leveraged CLIP toenable zero-shot 3D object recognition. However, performance on real pointclouds with occlusions still falls short due to the unrealistic pretrainingsettings. Additionally, these methods incur high inference costs because theyrely on Transformer's attention modules. In this paper, we make twocontributions to address these limitations. First, we propose occlusion-awaretext-image-point cloud pretraining to reduce the training-testing domain gap.From 52K synthetic 3D objects, our framework generates nearly 630K partialpoint clouds for pretraining, consistently improving real-world recognitionperformances of existing popular 3D networks. Second, to reduce computationalrequirements, we introduce DuoMamba, a two-stream linear state space modeltailored for point clouds. By integrating two space-filling curves with 1Dconvolutions, DuoMamba effectively models spatial dependencies between pointtokens, offering a powerful alternative to Transformer. When pretrained withour framework, DuoMamba surpasses current state-of-the-art methods whilereducing latency and FLOPs, highlighting the potential of our approach forreal-world applications. We will release our data and code to facilitate futureresearch.</description>
      <author>example@mail.com (Khanh Nguyen, Ghulam Mubashar Hassan, Ajmal Mian)</author>
      <guid isPermaLink="false">2502.10674v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Open-Set Cross-Network Node Classification via Unknown-Excluded Adversarial Graph Domain Alignment</title>
      <link>http://arxiv.org/abs/2502.10967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个新的跨网络节点分类问题（开放集跨网络节点分类）以及解决此问题的未知排除对抗图领域对齐模型。&lt;h4&gt;背景&lt;/h4&gt;现有的跨网络节点分类方法主要针对封闭集设置，即源网络和目标网络共享完全相同的标签空间。然而，在实际应用中这种情况受到限制，因为目标网络可能包含源网络中不存在的新类别。&lt;h4&gt;目的&lt;/h4&gt;研究一个更贴近现实的开放集跨网络节点分类问题，并提出有效的解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了未知排除对抗图领域对齐（UAGA）模型和分离适应训练策略。通过设计一种对抗框架，将已知类与未知类初步分开，然后定制了未知排除对抗领域对齐以仅对来自已知类别的目标节点进行源领域的对齐，并且远离源自未见过的类别。&lt;h4&gt;主要发现&lt;/h4&gt;UAGA模型在现实世界数据集上的实验结果表明其比现有的最佳方法显著更优。&lt;h4&gt;结论&lt;/h4&gt;提出的开放集跨网络节点分类问题更加贴近实际应用，而未知排除对抗图领域对齐（UAGA）模型是解决该类问题的有效途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的中文直接翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing cross-network node classification methods are mainly proposed forclosed-set setting, where the source network and the target network shareexactly the same label space. Such a setting is restricted in real-worldapplications, since the target network might contain additional classes thatare not present in the source. In this work, we study a more realistic open-setcross-network node classification (O-CNNC) problem, where the target networkcontains all the known classes in the source and further contains severaltarget-private classes unseen in the source. Borrowing the concept fromopen-set domain adaptation, all target-private classes are defined as anadditional unknown class. To address the challenging O-CNNC problem, we proposean unknown-excluded adversarial graph domain alignment (UAGA) model with aseparate-adapt training strategy. Firstly, UAGA roughly separates known classesfrom unknown class, by training a graph neural network encoder and aneighborhood-aggregation node classifier in an adversarial framework. Then,unknown-excluded adversarial domain alignment is customized to align onlytarget nodes from known classes with the source, while pushing target nodesfrom unknown class far away from the source, by assigning positive and negativedomain adaptation coefficient to known class nodes and unknown class nodes.Extensive experiments on real-world datasets demonstrate significantoutperformance of the proposed UAGA over state-of-the-art methods on O-CNNC.</description>
      <author>example@mail.com (Xiao Shen, Zhihao Chen, Shirui Pan, Shuang Zhou, Laurence T. Yang, Xi Zhou)</author>
      <guid isPermaLink="false">2502.10967v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Exploiting Point-Language Models with Dual-Prompts for 3D Anomaly Detection</title>
      <link>http://arxiv.org/abs/2502.11307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为PLANE的点云异常检测新模型，它利用双模态提示扩展了预训练的Point-Language Models在3D点云领域的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;在工业应用中，特别是精密制造领域，三维点云异常检测至关重要。目前的方法大多需要为每个类别分别训练单独的模型，导致内存占用高且缺乏灵活性。&lt;h4&gt;目的&lt;/h4&gt;开发一个单一模型可以跨多个类别的3D点云异常检测方法，提高效率和性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双提示学习方法，结合了文本和点云提示。通过动态提示创建模块（DPCM）生成特定样本的动态提示，并与每个模式下的类别特异性静态提示相结合，以驱动预训练的语言模型实现高效的异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在Anomaly-ShapeNet数据集上比现有的单类单模型方法提升了8.7%/17%在异常检测和定位性能；对于Real3D-AD数据集则分别提高了4.3%/4.1%。这些提升是在多类别单一模型框架下实现的。&lt;h4&gt;结论&lt;/h4&gt;PLANE模型通过结合双模态提示，成功地将预训练的语言模型应用于三维点云的异常检测中，展示了其在广泛工业应用中的潜力和有效性。&lt;h4&gt;翻译&lt;/h4&gt;3D点云异常检测在众多工业应用中至关重要，特别是在精密制造领域。为了满足行业需求，已经开发了几种方法。然而，大多数这些方法通常需要为每个类别分别训练单独的模型，这会导致内存使用量大且缺乏灵活性。本文提出了一种新的Point-Language模型，带双提示用于3D异常检测（PLANE）。该方法利用多模态提示将预训练的语言模型强大的泛化能力扩展到3D点云异常检测领域，在单一模型上实现了跨多个类别的出色检测性能。具体而言，提出了一个双提示学习法，结合了文本和点云提示，并使用动态提示创建模块（DPCM）来生成特定样本的动态提示，然后将这些与每个模式下的类别特异性静态提示相结合，有效地驱动预训练语言模型。基于点云数据的特点，提出了一种伪3D异常生成方法（Ano3D），以在无监督设置中提高模型的检测能力。实验结果显示，在多类单模框架下，所提方法相对于现有的一类一模型方法分别在Anomaly-ShapeNet数据集上提高了8.7%/17%，而在Real3D-AD数据集中则分别提高了4.3%/4.1%。代码发布后将公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection (AD) in 3D point clouds is crucial in a wide range ofindustrial applications, especially in various forms of precisionmanufacturing. Considering the industrial demand for reliable 3D AD, severalmethods have been developed. However, most of these approaches typicallyrequire training separate models for each category, which is memory-intensiveand lacks flexibility. In this paper, we propose a novel Point-Language modelwith dual-prompts for 3D ANomaly dEtection (PLANE). The approach leveragesmulti-modal prompts to extend the strong generalization capabilities ofpre-trained Point-Language Models (PLMs) to the domain of 3D point cloud AD,achieving impressive detection performance across multiple categories using asingle model. Specifically, we propose a dual-prompt learning method,incorporating both text and point cloud prompts. The method utilizes a dynamicprompt creator module (DPCM) to produce sample-specific dynamic prompts, whichare then integrated with class-specific static prompts for each modality,effectively driving the PLMs. Additionally, based on the characteristics ofpoint cloud data, we propose a pseudo 3D anomaly generation method (Ano3D) toimprove the model's detection capabilities in an unsupervised setting.Experimental results demonstrate that the proposed method, which is under themulti-class-one-model paradigm, achieves a +8.7%/+17% gain on anomaly detectionand localization performance as compared to the state-of-the-artone-class-one-model methods for the Anomaly-ShapeNet dataset, and obtains+4.3%/+4.1% gain for the Real3D-AD dataset. Code will be available uponpublication.</description>
      <author>example@mail.com (Jiaxiang Wang, Haote Xu, Xiaolu Chen, Haodi Xu, Yue Huang, Xinghao Ding, Xiaotong Tu)</author>
      <guid isPermaLink="false">2502.11307v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Hierarchical Contrastive Self-supervising Learning for Time Series Classification via Importance-aware Resolution Selection</title>
      <link>http://arxiv.org/abs/2502.10567v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Appears in IEEEBigData-2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种新的训练方法，用于解决时间序列数据中层级对比学习自监督框架在处理长时序数据时计算成本过高的问题。&lt;h4&gt;背景&lt;/h4&gt;近期设计针对时间序列的自监督学习(SSM)框架有了显著进展。这些基于层级对比学习的方法通过多分辨率的数据嵌入对比来学习表示，能够收集更多信息并表现出更好的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;为了应对长时序数据计算成本高的挑战，提出了一种高效的训练方法来降低计算负担。&lt;h4&gt;方法&lt;/h4&gt;受每个分辨率间数据嵌入依赖关系的启发，引入了基于重要性感知的分辨率选择训练框架。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该方法显著提高了训练时间效率，并且在广泛的时间序列分类性能评估中保持原有模型结构完整性和准确性。&lt;h4&gt;结论&lt;/h4&gt;论文提出的解决方案有助于提升层级对比学习模型的训练效率和实用性，特别是在处理长时序数据场景下。&lt;h4&gt;翻译&lt;/h4&gt;最近，在设计针对时间序列的数据自监督学习(SSM)框架方面取得了显著进展，以减少对数据标签的依赖。这些基于层级对比学习的方法通过多分辨率下的数据嵌入对比来学习表示，并因其能够收集更多信息而表现出更好的泛化能力。然而，当时间序列长度较长时，其计算成本通常比其他SSM框架高得多。本文提出了一种高效的训练方法，旨在应对这一挑战：引入了基于重要性感知的分辨率选择训练框架以降低计算负担。实验表明该方法显著提高了训练效率，并在广泛的时间序列分类性能评估中保持了原有模型结构完整性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, there has been a significant advancement in designingSelf-Supervised Learning (SSL) frameworks for time series data to reduce thedependency on data labels. Among these works, hierarchical contrastivelearning-based SSL frameworks, which learn representations by contrasting dataembeddings at multiple resolutions, have gained considerable attention. Due totheir ability to gather more information, they exhibit better generalization invarious downstream tasks. However, when the time series data length issignificant long, the computational cost is often significantly higher thanthat of other SSL frameworks. In this paper, to address this challenge, wepropose an efficient way to train hierarchical contrastive learning models.Inspired by the fact that each resolution's data embedding is highly dependent,we introduce importance-aware resolution selection based training framework toreduce the computational cost. In the experiment, we demonstrate that theproposed method significantly improves training time while preserving theoriginal model's integrity in extensive time series classification performanceevaluations. Our code could be found here, https://github.com/KEEBVIN/IARS</description>
      <author>example@mail.com (Kevin Garcia, Juan Manuel Perez, Yifeng Gao)</author>
      <guid isPermaLink="false">2502.10567v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Implicit Neural Representations of Molecular Vector-Valued Functions</title>
      <link>http://arxiv.org/abs/2502.10848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is a tiny paper track submission to the LRML workshop at ICLR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;分子有多种计算表示形式，包括数值描述符、字符串、图结构、点云和表面。为了补充现有的表示方法，本文引入了通过向量值函数或由神经网络参数化的$n$维矢量场来表示分子的新方法。&lt;h4&gt;背景&lt;/h4&gt;当前的分子表示方法涵盖了从线性回归到与大型语言模型结合使用的图神经网络等机器学习技术的应用。&lt;h4&gt;目的&lt;/h4&gt;为了改进现有分子表示，提出了使用向量值函数或称为分子神经场（molecular neural fields）的方法来更好地捕捉分子外部特征和疏水核心。&lt;h4&gt;方法&lt;/h4&gt;介绍了基于自动解码器架构的蛋白质-配体复合物参数化和超分辨率重构以及基于自编码器架构的分子体积嵌入到潜在空间中的框架。&lt;h4&gt;主要发现&lt;/h4&gt;与离散图或点表示相比，分子神经场具有紧凑性、分辨率独立性和在时空维度上内插的能力。这些特性使它们适合生成基于形状、结构和成分的分子，并能进行时间和空间维度上的分辨率无关插值。&lt;h4&gt;结论&lt;/h4&gt;本文提供了一个框架和概念验证示例来支持使用向量值函数表示分子的新方法，展示了其在分子科学中的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecules have various computational representations, including numericaldescriptors, strings, graphs, point clouds, and surfaces. Each representationmethod enables the application of various machine learning methodologies fromlinear regression to graph neural networks paired with large language models.To complement existing representations, we introduce the representation ofmolecules through vector-valued functions, or $n$-dimensional vector fields,that are parameterized by neural networks, which we denote molecular neuralfields. Unlike surface representations, molecular neural fields captureexternal features and the hydrophobic core of macromolecules such as proteins.Compared to discrete graph or point representations, molecular neural fieldsare compact, resolution independent and inherently suited for interpolation inspatial and temporal dimensions. These properties inherited by molecular neuralfields lend themselves to tasks including the generation of molecules based ontheir desired shape, structure, and composition, and the resolution-independentinterpolation between molecular conformations in space and time. Here, weprovide a framework and proofs-of-concept for molecular neural fields, namely,the parametrization and superresolution reconstruction of a protein-ligandcomplex using an auto-decoder architecture and the embedding of molecularvolumes in latent space using an auto-encoder architecture.</description>
      <author>example@mail.com (Jirka Lhotka, Daniel Probst)</author>
      <guid isPermaLink="false">2502.10848v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>CLaMP 3: Universal Music Information Retrieval Across Unaligned Modalities and Unseen Languages</title>
      <link>http://arxiv.org/abs/2502.10362v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 8 figures, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;CLaMP 3是一个统一的框架，用于解决音乐信息检索中的跨模态和跨语言泛化挑战。&lt;h4&gt;背景&lt;/h4&gt;当前音乐信息检索系统在处理不同语言和模式之间的通用性上面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够将包括乐谱、表演信号、音频记录在内的所有主要音乐模态与多语言文本统一在一个共享表示空间中的框架，从而实现跨不相关模式的检索，并且以文本作为桥梁。&lt;h4&gt;方法&lt;/h4&gt;使用对比学习技术，构建了一个可适应未见过的语言的多语言文本编码器，利用增强生成的检索技术创建了包含2.31万音乐-文本对的大规模网络级数据集M4-RAG，以及一个包含乐谱、音频和详细文字描述的WikiMT-X基准。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CLaMP 3在多项MIR任务上实现了最先进的性能，并且在多模态和多语言音乐场景中表现出色的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;通过发布具有挑战性的基准集，研究人员能够进一步推进跨语言、跨模式音乐信息检索领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;CLaMP 3是为了解决音乐信息检索中的跨模态与跨语言问题而开发的一个统一框架。它利用对比学习方法将不同的音乐形式（乐谱、表演信号和音频记录）及多语言文本整合到一个共享的表示空间中，使得不同模式之间可以通过文本作为桥梁进行检索。该系统具有适应未知语言的能力，并通过大规模数据集M4-RAG和基准测试集WikiMT-X展示了其在多种音乐信息检索任务中的优越性能和广泛的适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; CLaMP 3 is a unified framework developed to address challenges of cross-modaland cross-lingual generalization in music information retrieval. Usingcontrastive learning, it aligns all major music modalities--including sheetmusic, performance signals, and audio recordings--with multilingual text in ashared representation space, enabling retrieval across unaligned modalitieswith text as a bridge. It features a multilingual text encoder adaptable tounseen languages, exhibiting strong cross-lingual generalization. Leveragingretrieval-augmented generation, we curated M4-RAG, a web-scale datasetconsisting of 2.31 million music-text pairs. This dataset is enriched withdetailed metadata that represents a wide array of global musical traditions. Toadvance future research, we release WikiMT-X, a benchmark comprising 1,000triplets of sheet music, audio, and richly varied text descriptions.Experiments show that CLaMP 3 achieves state-of-the-art performance on multipleMIR tasks, significantly surpassing previous strong baselines and demonstratingexcellent generalization in multimodal and multilingual music contexts.</description>
      <author>example@mail.com (Shangda Wu, Zhancheng Guo, Ruibin Yuan, Junyan Jiang, Seungheon Doh, Gus Xia, Juhan Nam, Xiaobing Li, Feng Yu, Maosong Sun)</author>
      <guid isPermaLink="false">2502.10362v2</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Automatic Prompt Engineering: An Optimization Perspective</title>
      <link>http://arxiv.org/abs/2502.11560v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了自动化提示工程的研究，提出了一种统一的优化理论视角来综合各种方法。&lt;h4&gt;背景&lt;/h4&gt;基础模型的发展使得研究从资源密集型的微调转向了通过输入设计引导模型行为的提示工程。然而，手动提示工程在可扩展性、适应性和跨模态一致性方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提供首个关于自动化提示工程的全面综述，涵盖多种方法和理论框架。&lt;h4&gt;方法&lt;/h4&gt;将提示优化问题形式化为在离散、连续以及混合提示空间中的最大化问题，并根据不同变量（指令、软提示、示例）、特定任务目标以及计算框架来系统地组织各种方法。&lt;h4&gt;主要发现&lt;/h4&gt;通过统一的优化视角，该综述连接了理论设计与实践实施，涵盖了文本、视觉和多模态领域。同时指出了在受限优化及代理导向型提示设计中的未探索前沿。&lt;h4&gt;结论&lt;/h4&gt;为研究者和从业者提供了一个基础框架，并强调了一些关键的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;随着基础模型的发展，注意力从资源密集的微调转向了通过输入设计来引导模型行为的提示工程。手动提示工程在可扩展性、适应性和跨模态一致性方面存在局限。自动化方法涵盖基于基础模型的优化、进化方法、梯度基优化和强化学习等，提供了有前景的解决方案。本文首次提出了一个关于自动化提示工程的全面综述，通过统一的优化理论视角进行。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rise of foundation models has shifted focus from resource-intensivefine-tuning to prompt engineering, a paradigm that steers model behaviorthrough input design rather than weight updates. While manual promptengineering faces limitations in scalability, adaptability, and cross-modalalignment, automated methods, spanning foundation model (FM) basedoptimization, evolutionary methods, gradient-based optimization, andreinforcement learning, offer promising solutions. Existing surveys, however,remain fragmented across modalities and methodologies. This paper presents thefirst comprehensive survey on automated prompt engineering through a unifiedoptimization-theoretic lens. We formalize prompt optimization as a maximizationproblem over discrete, continuous, and hybrid prompt spaces, systematicallyorganizing methods by their optimization variables (instructions, soft prompts,exemplars), task-specific objectives, and computational frameworks. By bridgingtheoretical formulation with practical implementations across text, vision, andmultimodal domains, this survey establishes a foundational framework for bothresearchers and practitioners, while highlighting underexplored frontiers inconstrained optimization and agent-oriented prompt design.</description>
      <author>example@mail.com (Wenwu Li, Xiangfeng Wang, Wenhao Li, Bo Jin)</author>
      <guid isPermaLink="false">2502.11560v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Motion planning for highly-dynamic unconditioned reflexes based on chained Signed Distance Functions</title>
      <link>http://arxiv.org/abs/2502.10734v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在线、高度动态的运动规划算法，旨在赋予机器人机械臂以类人的无条件反射能力，使其能够迅速避开环境中的静态和动态障碍。&lt;h4&gt;背景&lt;/h4&gt;无条件反射（如保护性反射）是生物体在遇到危险时自然发生的反应，通常是通过脊髓而不是大脑来执行的。此类反射帮助有机体避免来自环境的危害。&lt;h4&gt;目的&lt;/h4&gt;设计一种算法，使机器人机械臂能够具备高度动态的无条件反射能力，以避开人类和/或环境中的潜在危害。&lt;h4&gt;方法&lt;/h4&gt;{'离线阶段': '创建3组局部距离函数（SDFs）来存储机械臂及其工作环境的几何信息，并预先计算和存储这些数据。', '在线阶段': '根据机械臂的配置将预先计算好的局部SDF链式连接起来，提供全局几何信息。动态对象的点云作为查询点以快速生成逃逸速度。', '实时行为生成': '提出修改后的几何雅可比矩阵并使用雅可比伪逆方法，在遇到静态和动态障碍物时产生即时避障行为'}&lt;h4&gt;主要发现&lt;/h4&gt;{'静态场景': '在静态场景中，本文的方法相比现有解决方案耗时更少且轨迹长度更短。', '动态场景': '在动态场景下，该算法能够可靠地追踪动态目标点、避开动态障碍物，并能在1ms内对这些障碍作出反应，超越了人类的无条件反射时间。'}&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过高效的运动规划和即时避障策略，在静态与动态环境中均表现出色，具有重要的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一个基于链式距离函数的在线、高度动态运动规划算法，赋予机械臂类似人类无条件反射的能力来避开环境中的障碍物。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The unconditioned reflex (e.g., protective reflex), which is the innatereaction of the organism and usually performed through the spinal cord ratherthan the brain, can enable organisms to escape harms from environments. In thispaper, we propose an online, highly-dynamic motion planning algorithm to endowmanipulators the highly-dynamic unconditioned reflexes to humans and/orenvironments. Our method is based on a chained version of Signed DistanceFunctions (SDFs), which can be pre-computed and stored. Our proposed algorithmis divided into two stages. In the offline stage, we create 3 groups of localSDFs to store the geometric information of the manipulator and its workingenvironment. In the online stage, the pre-computed local SDFs are chainedtogether according the configuration of the manipulator, to provide globalgeometric information about the environment. While the point clouds of thedynamic objects serve as query points to look up these local SDFs for quicklygenerating escape velocity. Then we propose a modified geometric Jacobianmatrix and use the Jacobian-pseudo-inverse method to generate real-time reflexbehaviors to avoid the static and dynamic obstacles in the environment. Thebenefits of our method are validated in both static and dynamic scenarios. Inthe static scenario, our method identifies the path solutions with lower timeconsumption and shorter trajectory length compared to existing solutions. Inthe dynamic scenario, our method can reliably pursue the dynamic target point,avoid dynamic obstacles, and react to these obstacles within 1ms, whichsurpasses the unconditioned reflex reaction time of humans.</description>
      <author>example@mail.com (Ken Lin, Qi Ye, Tin Lun Lam, Zhibin Li, Jiming Chen)</author>
      <guid isPermaLink="false">2502.10734v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>LLM-driven Knowledge Distillation for Dynamic Text-Attributed Graphs</title>
      <link>http://arxiv.org/abs/2502.10914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the AI4TS: AI for Time Series Analysis workshop, AAAI  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的模型LKD4DyTAG，该模型通过将LLM的知识蒸馏到动态文本属性图中，解决了在包含时间信息的动态图中的挑战。&lt;h4&gt;背景&lt;/h4&gt;Dynamic Text-Attributed Graphs (DyTAGs) 在社交媒体、合作网络等领域有广泛应用。这些网络中的节点和边经常包含描述性文本，并且图形结构会随着时间变化。&lt;h4&gt;目的&lt;/h4&gt;为未来链接预测，边缘分类等任务开发一种能够同时编码时间、结构信息的强大的表示方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种通过知识蒸馏将大型语言模型（LLM）的能力注入到动态图中的方法，这种方法可以在轻量级GNN模型中利用邻域文本属性来生成时空表示。&lt;h4&gt;主要发现&lt;/h4&gt;在六个现实世界的数据集上进行了广泛的实验验证了该方法的有效性，并显示它比基线模型显著提高了下游任务的表现。&lt;h4&gt;结论&lt;/h4&gt;LKD4DyTAG通过结合时间编码和知识蒸馏，能够有效地解决动态文本属性图中的结构化信息、时间信息和文本信息的表示问题。&lt;h4&gt;翻译&lt;/h4&gt;动态文本属性图（Dynamic Text-Attributed Graphs, DyTAGs）在现实世界中有许多应用，例如社交网络、合作网络等。节点和边通常包含描述性文本，并且图形结构会随时间演变。为了处理未来链接预测等问题，需要强大的表示来编码结构化信息、时间信息和文本信息。本文提出了一种新的模型LKD4DyTAG，通过知识蒸馏将大型语言模型（LLM）的文本处理能力注入到动态图中，以生成更丰富的时空表示。实验表明该方法在六个现实世界的数据集上显著提升了未来链接预测等任务的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic Text-Attributed Graphs (DyTAGs) have numerous real-worldapplications, e.g. social, collaboration, citation, communication, and reviewnetworks. In these networks, nodes and edges often contain text descriptions,and the graph structure can evolve over time. Future link prediction, edgeclassification, relation generation, and other downstream tasks on DyTAGsrequire powerful representations that encode structural, temporal, and textualinformation. Although graph neural networks (GNNs) excel at handling structureddata, encoding temporal information within dynamic graphs remains a significantchallenge. In this work, we propose LLM-driven Knowledge Distillation forDynamic Text Attributed Graph (LKD4DyTAG) with temporal encoding to addressthese challenges. We use a simple, yet effective approach to encode temporalinformation in edges so that graph convolution can simultaneously capture bothtemporal and structural information in the hidden representations. To leverageLLM's text processing capabilities for learning richer representations onDyTAGs, we distill knowledge from LLM-driven edge representations (based on aneighborhood's text attributes) into saptio-temporal representations using alightweight GNN model that encodes temporal and structural information. Theobjective of knowledge distillation enables the GNN to learn representationsthat more effectively encode the available structural, temporal, and textualinformation in DyTAG. We conducted extensive experimentation on six real-worldDyTAG datasets to verify the effectiveness of our approach LKD4DyTAG for futurelink prediction and edge classification task. The results show that ourapproach significantly improves the performance of downstream tasks compared tothe baseline models.</description>
      <author>example@mail.com (Amit Roy, Ning Yan, Masood Mortazavi)</author>
      <guid isPermaLink="false">2502.10914v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Generative Adversarial Networks for High-Dimensional Item Factor Analysis: A Deep Adversarial Learning Algorithm</title>
      <link>http://arxiv.org/abs/2502.10650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种改进的变分自动编码器（VAE）技术，即对抗性变分贝叶斯算法（AVB），用于项目因素分析（IFA）。这项工作通过结合生成对抗网络（GAN）的优势，提升了传统 VAE 的灵活性和准确性。&lt;h4&gt;背景&lt;/h4&gt;深度学习和表示学习的进步已经改变了项因子分析在项目响应理论文献中的面貌，使得更高效、更准确的参数估计成为可能。然而，基于传统变分自动编码器（VAE）的推断模型表达能力有限，仍然限制了其性能。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入 AVB 算法改进 IFA 中 VAE 的灵活性和准确性，并进一步提出了一种增强算法——重要加权对抗性变分贝叶斯（IWAVB），以应对更高维度的挑战。&lt;h4&gt;方法&lt;/h4&gt;将 GAN 和 VAE 结合形成 AVB，通过引入辅助判别网络重新定义估计过程为一个二人博弈问题。此算法还消除了标准正态分布假设的传统推断模型限制，并提出了重要加权对抗性变分贝叶斯（IWAVB）。&lt;h4&gt;主要发现&lt;/h4&gt;在真实数据的探索性分析中，IWAVB 通过实现更高的似然比展示出更好的表达能力，优于 IWAE。而在模拟数据的确证研究中，IWAVB 达到了与 IWAE 相同的平均平方误差结果，同时实现了更高的似然值，并且对于多模式分布的潜在变量情况，IWAVB 提供了更准确的参数估计。&lt;h4&gt;结论&lt;/h4&gt;鉴于其对 GAN 的创新使用，IWAVB 展示出在处理大规模数据方面扩展 IFA 的潜力，促进了心理测量学与多模态数据分析的融合可能性。&lt;h4&gt;翻译&lt;/h4&gt;在深度学习和表示学习的进步推动下，项目因子分析（IFA）得到了极大改进。然而，传统的变分自动编码器（VAE）表达能力不足限制了估计性能。此研究引入对抗性变分贝叶斯（AVB）算法提升 IFA 的灵活性与准确性，并提出重要加权对抗性变分贝叶斯（IWAVB），通过真实数据和模拟数据验证其优于传统方法，显示了在大规模数据处理中的潜力及心理测量学多模态数据分析的可能融合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in deep learning and representation learning have transformed itemfactor analysis (IFA) in the item response theory (IRT) literature by enablingmore efficient and accurate parameter estimation. Variational Autoencoders(VAEs) have been one of the most impactful techniques in modelinghigh-dimensional latent variables in this context. However, the limitedexpressiveness of the inference model based on traditional VAEs can stillhinder the estimation performance. This study introduces AdversarialVariational Bayes (AVB) algorithms as an improvement to VAEs for IFA withimproved flexibility and accuracy. By bridging the strengths of VAEs andGenerative Adversarial Networks (GANs), AVB incorporates an auxiliarydiscriminator network to reframe the estimation process as a two-playeradversarial game and removes the restrictive assumption of standard normaldistributions in the inference model. Theoretically, AVB can achieve similar orhigher likelihood compared to VAEs. A further enhanced algorithm,Importance-weighted Adversarial Variational Bayes (IWAVB) is proposed andcompared with Importance-weighted Autoencoders (IWAE). In an exploratoryanalysis of real empirical data, IWAVB demonstrated superior expressiveness byachieving a higher likelihood compared to IWAE. In confirmatory studies withsimulated data, IWAVB achieved similar mean-square error results to IWAE whileconsistently achieving higher likelihoods. Moreover, in simulations wherelatent variables followed a multimodal distribution, IWAVB outperformed IWAE byproviding more accurate parameter estimates. With its innovative use of GANs,IWAVB is shown to have the potential to extend IFA to handle large-scale data,facilitating the potential integration of psychometrics and multimodal dataanalysis.</description>
      <author>example@mail.com (Nanyu Luo, Feng Ji)</author>
      <guid isPermaLink="false">2502.10650v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Robust Multidimensional Graph Neural Networks for Signal Processing in Wireless Communications with Edge-Graph Information Bottleneck</title>
      <link>http://arxiv.org/abs/2502.10869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的信号处理框架，结合了多维图神经网络（MDGNN）和边图信息瓶颈（EGIB），以应对未来第六代无线网络中的数据速率需求。&lt;h4&gt;背景&lt;/h4&gt;随着无线网络的快速增长，产生了大量的数据流量，传统优化理论算法的应用受到限制。同时，传统的图神经网络专注于将输入压缩到顶点上更新表示，这导致难以区分输入特征并削弱了性能。&lt;h4&gt;目的&lt;/h4&gt;设计高效的信号处理框架以解决当前面临的挑战，并在多径干扰和噪声的实际场景中提供鲁棒性解决方案。&lt;h4&gt;方法&lt;/h4&gt;通过引入多维图神经网络（MDGNN）来替代顶点更新表示，同时利用边图信息瓶颈（EGIB）减少不相关的信息聚合，从而提高框架的性能和稳健性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的信号处理框架在多个任务中表现出色，在频谱效率（SE）和网络开销方面优于现有框架。尤其是当干扰噪声增加时，该框架的频谱效率逐渐稳定下来，显示出其在干扰环境中的优秀鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;论文提出的方法为未来第六代无线网络中的信号处理提供了一种新颖且有效的解决方案，在多径干扰和高噪音环境中具有出色的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Signal processing is crucial for satisfying the high data rate requirementsof future sixth-generation (6G) wireless networks. However, the rapid growth ofwireless networks has brought about massive data traffic, which hinders theapplication of traditional optimization theory-based algorithms. Meanwhile,traditional graph neural networks (GNNs) focus on compressing inputs ontovertices to update representations, which often leads to their inability toeffectively distinguish input features and severely weakens performance. Inthis context, designing efficient signal processing frameworks becomesimperative. Moreover, actual scenarios are susceptible to multipathinterference and noise, resulting in specific differences between the receivedand actual information. To address these challenges, this paper incorporatesmultidimensional graph neural networks (MDGNNs) with edge-graph informationbottleneck (EGIB) to design a robust framework for signal processing.Specifically, MDGNNs utilize hyper-edges instead of vertices to updaterepresentations to avoid indistinguishable features and reduce informationloss, while EGIB encourages providing minimal sufficient information aboutoutputs to avoid aggregation of irrelevant information. We numericallydemonstrate that compared with existing frameworks, the proposed frameworksachieve excellent performance in terms of spectrum efficiency (SE) and networkoverhead under multiple signal processing tasks. Remarkably, as theinterference noise increases, the SE performance of the proposed frameworksgradually stabilizes. This reveals the proposed frameworks have excellentrobustness in interference prone environments, especially in wireless policiesrelated to channel matrices.</description>
      <author>example@mail.com (Ziheng Liu, Jiayi Zhang, Yiyang Zhu, Enyu Shi, Bo Ai)</author>
      <guid isPermaLink="false">2502.10869v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>SinSim: Sinkhorn-Regularized SimCLR</title>
      <link>http://arxiv.org/abs/2502.10478v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SinSim是一种基于对比学习的自监督表示学习方法，通过引入Sinkhorn正则化来改进特征空间的结构。&lt;h4&gt;背景&lt;/h4&gt;自监督学习改变了无标签数据下的表示学习方式。然而，现有的对比学习方法如SimCLR虽然能够最大化图像增强视图间的相似度，但缺乏明确的正则化手段来确保全局结构化的潜在空间。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过结合最优传输理论中的Sinkhorn正则化，改进自监督对比学习的方法以克服现有技术的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的SimCLR扩展版本SinSim，该版本在训练过程中引入了熵正则化的Wasserstein距离（即Sinkhorn损失），以此鼓励特征空间的良好分散和几何感知能力，同时保持其判别力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与SimCLR相比，SinSim具有更好的性能。并且，在多个数据集上的评估显示，SinSim的表现优于其他著名的方法如VICReg和Barlow Twins；UMAP可视化进一步揭示了类别分离性得到提高以及特征分布变得更加结构化。&lt;h4&gt;结论&lt;/h4&gt;将最优传输正则化融入对比学习中提供了一种原则性和有效的机制来学习稳健且具有良好结构的表示。这为自监督框架中的运输约束的应用开辟了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了通过引入Sinkhorn正则化的SinSim方法如何超越传统的SimCLR，展示了其在特征空间结构化和泛化能力上的改进，并强调了这种方法对未来研究的意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has revolutionized representation learning byeliminating the need for labeled data. Contrastive learning methods, such asSimCLR, maximize the agreement between augmented views of an image but lackexplicit regularization to enforce a globally structured latent space. Thislimitation often leads to suboptimal generalization. We propose SinSim, a novelextension of SimCLR that integrates Sinkhorn regularization from optimaltransport theory to enhance representation structure. The Sinkhorn loss, anentropy-regularized Wasserstein distance, encourages a well-dispersed andgeometry-aware feature space, preserving discriminative power. Empiricalevaluations on various datasets demonstrate that SinSim outperforms SimCLR andachieves competitive performance against prominent self-supervised methods suchas VICReg and Barlow Twins. UMAP visualizations further reveal improved classseparability and structured feature distributions. These results indicate thatintegrating optimal transport regularization into contrastive learning providesa principled and effective mechanism for learning robust, well-structuredrepresentations. Our findings open new directions for applying transport-basedconstraints in self-supervised learning frameworks.</description>
      <author>example@mail.com (M. Hadi Sepanj, Paul Fiegth)</author>
      <guid isPermaLink="false">2502.10478v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review</title>
      <link>http://arxiv.org/abs/2502.11518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对具身多智能体系统（EMAS）如何利用生成模型的潜在能力进行了系统性综述，分析了这些系统的架构和实体表现形式，并探讨了集成基础模型对EMAS灵活性和鲁棒性的提升。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于复杂现实挑战的需求，尤其是物流和机器人领域，具身多智能体系统（EMAS）逐渐受到关注。随着基础模型的快速发展，生成型代理在丰富交流和适应性问题解决方面展现出了巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;本综述旨在探讨如何使EMAS从这些生成能力中受益，并提出一种分类法来根据系统的架构和实体表现形式对它们进行分类。&lt;h4&gt;方法&lt;/h4&gt;文章分析了构建模块（如感知、规划、通信和反馈）如何利用生成技术增强系统鲁棒性和灵活性，通过具体例子说明基础模型如何融入具身多代理框架带来的变革效应。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，集成基础模型到EMAS中可以显著提高其适应性、协作能力和解决问题的效率。&lt;h4&gt;结论&lt;/h4&gt;综述讨论了挑战和未来方向，强调了EMAS在重塑AI驱动合作领域的重大前景。&lt;h4&gt;翻译&lt;/h4&gt;具身多智能体系统（Embodied Multi-Agent Systems, EMAS）因其处理复杂现实世界挑战的能力而受到越来越多的关注。随着基础模型的最新进展，生成型代理具备更丰富的通信能力和适应性问题解决能力成为可能。本文提供了一个系统的EMAS如何从这些生成能力中受益的研究，并提出了一个分类法来根据系统架构和实体表现形式对它们进行分类。通过具体例子展示了将基础模型融入到具身多智能体框架中的变革效应，最终讨论了挑战与未来方向，强调了EMAS在重塑AI驱动合作领域的重大前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied multi-agent systems (EMAS) have attracted growing attention fortheir potential to address complex, real-world challenges in areas such aslogistics and robotics. Recent advances in foundation models pave the way forgenerative agents capable of richer communication and adaptive problem-solving.This survey provides a systematic examination of how EMAS can benefit fromthese generative capabilities. We propose a taxonomy that categorizes EMAS bysystem architectures and embodiment modalities, emphasizing how collaborationspans both physical and virtual contexts. Central building blocks, perception,planning, communication, and feedback, are then analyzed to illustrate howgenerative techniques bolster system robustness and flexibility. Throughconcrete examples, we demonstrate the transformative effects of integratingfoundation models into embodied, multi-agent frameworks. Finally, we discusschallenges and future directions, underlining the significant promise of EMASto reshape the landscape of AI-driven collaboration.</description>
      <author>example@mail.com (Di Wu, Xian Wei, Guang Chen, Hao Shen, Xiangfeng Wang, Wenhao Li, Bo Jin)</author>
      <guid isPermaLink="false">2502.11518v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>To Bin or not to Bin: Alternative Representations of Mass Spectra</title>
      <link>http://arxiv.org/abs/2502.10851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript has been submitted to the tiny paper track at the  LMRL workshop at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了如何通过不同的表示方法改进质谱数据在机器学习任务中的应用，特别是针对质量碎片光谱的处理。&lt;h4&gt;背景&lt;/h4&gt;质谱技术尤其是串联质谱被广泛用于评估样品的化学多样性。然而，这些技术产生的光谱往往需要进一步解析以确定分子结构或性质。&lt;h4&gt;目的&lt;/h4&gt;研究两种不依赖于光谱预处理（如分箱）的方法来直接表示质量碎片光谱：集合基和图基表示方法。&lt;h4&gt;方法&lt;/h4&gt;对比了基于这两种新表示法的机器学习模型，包括集变换器(Set Transformer) 和图神经网络(Graph Neural Network)，并将其与传统的多层感知机(MLP) 进行性能比较。&lt;h4&gt;主要发现&lt;/h4&gt;新的集合基和图基表示都显著优于用分箱数据训练的传统多层感知机。这表明直接处理原始光谱而不进行预处理可以提高模型的预测能力。&lt;h4&gt;结论&lt;/h4&gt;研究结果支持了采用新型表示法来直接使用原始质谱数据的有效性，为后续机器学习任务提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;质量谱分析，特别是所谓的串联质量谱分析，通常用于评估样品的化学多样性。生成的质量碎片光谱代表了可能未确定结构的分子。这给实验上确定或通过计算预测分子结构从质量光谱带来了挑战。一种替代方案是从光谱直接预测分子属性或相似性。已经提出了多种方法将质量光谱嵌入以供进一步用于机器学习任务。然而，这些方法通常需要对光谱进行预处理，例如分箱或子采样峰，主要原因是创造统一向量大小和去除噪声。在此研究中，我们探讨了两种在下游机器学习任务之前不使用分箱的替代方案：集合基表示法和图基表示法。对比这两种提议的方法分别训练一个集变换器（用于回归任务）和图神经网络，显示它们都比基于分箱数据的传统多层感知机模型表现出色得多。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mass spectrometry, especially so-called tandem mass spectrometry, is commonlyused to assess the chemical diversity of samples. The resulting massfragmentation spectra are representations of molecules of which the structuremay have not been determined. This poses the challenge of experimentallydetermining or computationally predicting molecular structures from massspectra. An alternative option is to predict molecular properties or molecularsimilarity directly from spectra. Various methodologies have been proposed toembed mass spectra for further use in machine learning tasks. However, thesemethodologies require preprocessing of the spectra, which often includesbinning or sub-sampling peaks with the main reasoning of creating uniformvector sizes and removing noise. Here, we investigate two alternatives to thebinning of mass spectra before down-stream machine learning tasks, namely,set-based and graph-based representations. Comparing the two proposedrepresentations to train a set transformer and a graph neural network on aregression task, respectively, we show that they both perform substantiallybetter than a multilayer perceptron trained on binned data.</description>
      <author>example@mail.com (Niek de Jonge, Justin J. J. van der Hooft, Daniel Probst)</author>
      <guid isPermaLink="false">2502.10851v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Medical Image Registration Meets Vision Foundation Model: Prototype Learning and Contour Awareness</title>
      <link>http://arxiv.org/abs/2502.11440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Information Processing in Medical Imaging (IPMI) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的医学图像配准框架，该框架利用Segment Anything Model (SAM) 生成的分割掩码来提供显式的解剖结构信息，并通过原型学习和边缘感知损失改进了传统方法仅依赖于强度相似度的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督可变形注册方法主要依靠基于强度的相似度指标，缺少明确的解剖学知识，导致其准确性和鲁棒性有限。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法的限制，提出了一种新的SAM辅助配准框架，通过集成显式的解剖信息、原型学习和边缘感知损失来提高图像注册的准确性与鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;(1) 显式解剖信息注入：使用由SAM生成的分割掩码作为训练和测试过程中的辅助输入；(2) 原型学习：利用分割掩码提取原型特征，并对齐原型以优化图像间的语义对应关系；(3) 边缘感知损失：设计了一种基于分割掩码边缘信息的损失函数，用于改善模型在精细变形场上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，所提出的框架在多个数据集上显著优于现有方法，在具有复杂解剖结构和模糊边界的情况下尤其表现出色。&lt;h4&gt;结论&lt;/h4&gt;通过引入显式的解剖知识和利用边缘感知损失，本文的工作提供了一种有效的方法来改善医学图像配准任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了医疗影像注册的基本任务，并提出了一个新的基于SAM辅助的配准框架，该框架包含三个主要部分：显式解剖信息注入、原型学习以及轮廓意识损耗。通过利用高质量的分割掩码和边缘信息来改进现有方法依赖强度相似度的局限性。实验表明所提出的方法在多个数据集上都表现优异，特别是在复杂结构下表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image registration is a fundamental task in medical image analysis,aiming to establish spatial correspondences between paired images. However,existing unsupervised deformable registration methods rely solely onintensity-based similarity metrics, lacking explicit anatomical knowledge,which limits their accuracy and robustness. Vision foundation models, such asthe Segment Anything Model (SAM), can generate high-quality segmentation masksthat provide explicit anatomical structure knowledge, addressing thelimitations of traditional methods that depend only on intensity similarity.Based on this, we propose a novel SAM-assisted registration frameworkincorporating prototype learning and contour awareness. The framework includes:(1) Explicit anatomical information injection, where SAM-generated segmentationmasks are used as auxiliary inputs throughout training and testing to ensurethe consistency of anatomical information; (2) Prototype learning, whichleverages segmentation masks to extract prototype features and alignsprototypes to optimize semantic correspondences between images; and (3)Contour-aware loss, a contour-aware loss is designed that leverages the edgesof segmentation masks to improve the model's performance in fine-graineddeformation fields. Extensive experiments demonstrate that the proposedframework significantly outperforms existing methods across multiple datasets,particularly in challenging scenarios with complex anatomical structures andambiguous boundaries. Our code is available athttps://github.com/HaoXu0507/IPMI25-SAM-Assisted-Registration.</description>
      <author>example@mail.com (Hao Xu, Tengfei Xue, Jianan Fan, Dongnan Liu, Yuqian Chen, Fan Zhang, Carl-Fredrik Westin, Ron Kikinis, Lauren J. O'Donnell, Weidong Cai)</author>
      <guid isPermaLink="false">2502.11440v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>An Efficient Row-Based Sparse Fine-Tuning</title>
      <link>http://arxiv.org/abs/2502.11439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种新的稀疏微调（Sparse Fine-tuning, SFT）框架，该框架基于神经网络修剪的原理。通过实验表明，在保持训练时间和实现复杂度不变的同时，可以显著提高SFT的记忆效率，并且在准确率上与最先进的方法如LoRA及其变体相当。&lt;h4&gt;背景&lt;/h4&gt;为了使具有有限计算预算的用户能够更便捷地适应大型语言模型到下游任务中，需要开发内存和计算效率更高的微调方法。稀疏微调（Sparse Fine-tuning, SFT）和低秩适应（Low-rank adaptation, LoRA）是为解决这一问题而出现并广泛应用的方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的基于神经网络修剪原理的SFT框架，以提高其内存效率，并保持训练时间和实现复杂度不变的同时，在准确率上与最先进的方法如LoRA及其变体相当。&lt;h4&gt;方法&lt;/h4&gt;首先使用来自神经网络修剪中的结构化剪枝方法识别出'重要'的神经元/节点；然后在涉及这些神经元的权重范围内进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验，在常见语言任务上证明了该方法能够在不增加训练时间复杂度和实现复杂度的情况下，显著提高SFT的记忆效率，并且达到与最先进的方法（如LoRA及其变体）相媲美的准确率。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的基于修剪原理的稀疏微调框架，该框架在保持高准确性的同时提升了内存效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning is an important step in adapting foundation models such as largelanguage models to downstream tasks. To make this step more accessible to userswith limited computational budgets, it is crucial to develop fine-tuningmethods that are memory and computationally efficient. Sparse Fine-tuning (SFT)and Low-rank adaptation (LoRA) are two frameworks that have emerged foraddressing this problem and have been adopted widely in practice. In this work,we develop a new SFT framework, based on ideas from neural network pruning. Ata high level, we first identify "important" neurons/nodes using featureimportance metrics from network pruning (specifically, we use the structuralpruning method), and then perform fine-tuning by restricting to weightsinvolving these neurons. Using experiments on common language tasks, wedemonstrate that our method significantly improves the memory efficiency of SFTwithout increasing training time complexity and implementation complexity,while achieving accuracy comparable to state-of-the-art methods such as LoRAand its variants.</description>
      <author>example@mail.com (Cen-Jhih Li, Aditya Bhaskara)</author>
      <guid isPermaLink="false">2502.11439v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>On Vanishing Gradients, Over-Smoothing, and Over-Squashing in GNNs: Bridging Recurrent and Graph Learning</title>
      <link>http://arxiv.org/abs/2502.10818v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了通过线性控制理论的视角来统一理解图神经网络（GNN）中的过度平滑和过度压缩问题的方法。&lt;h4&gt;背景&lt;/h4&gt;GNN利用消息传递机制在节点之间传输信息，然而这种方法容易遭受过度平滑和过度压缩现象的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的理解和缓解这些问题的方法，并探讨如何设计更深层且高效的图神经网络。&lt;h4&gt;方法&lt;/h4&gt;通过将GNN视作递归模型并应用线性控制理论中的思想来分析问题。同时，通过简单的状态空间形式化有效减轻了过度平滑和过度压缩的问题。&lt;h4&gt;主要发现&lt;/h4&gt;(i) GNN由于设计原因在经过几层后容易出现极端梯度消失；(ii) 过度平滑直接与导致梯度消失的机制相关联；(iii) 过度压缩可以通过图重新布线和缓解梯度消失的方式最有效地减轻。&lt;h4&gt;结论&lt;/h4&gt;这项工作有助于弥合递归神经网络和图神经网络文献之间的差距，并为设计新的深度高效GNN打开了道路。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) 是利用图形结构通过消息传递机制在节点之间传输信息的模型。尽管取得了广泛的成功，这种做法已知会遭受过度平滑和过度压缩现象的影响，导致随着层数增加而代表性的崩溃，并且对于距离遥远及连接不良节点的信息不敏感。在这篇论文中，我们从消失梯度的角度提出了一种统一理解这些问题的方法，使用了线性控制理论的思想进行分析。我们提出了将GNN视作递归模型的解释，并通过实验证明，一个简单的状态空间形式化能够有效地缓解过度平滑和过度压缩的问题而无需额外可训练参数成本。此外，我们从理论上和实验上表明：(i) 由于设计原因，即使经过几层后GNN也容易出现极端梯度消失；(ii) 过度平滑直接与导致梯度消失的机制相关；(iii) 过度压缩可以通过图重新布线和缓解梯度消失的方式最有效地减轻。我们相信这项工作将有助于弥合递归和图神经网络文献之间的差距，并为设计新的深度且高效的GNN打开新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are models that leverage the graph structure totransmit information between nodes, typically through the message-passingoperation. While widely successful, this approach is well known to suffer fromthe over-smoothing and over-squashing phenomena, which result inrepresentational collapse as the number of layers increases and insensitivityto the information contained at distant and poorly connected nodes,respectively. In this paper, we present a unified view of these problemsthrough the lens of vanishing gradients, using ideas from linear control theoryfor our analysis. We propose an interpretation of GNNs as recurrent models andempirically demonstrate that a simple state-space formulation of a GNNeffectively alleviates over-smoothing and over-squashing at no extra trainableparameter cost. Further, we show theoretically and empirically that (i) GNNsare by design prone to extreme gradient vanishing even after a few layers; (ii)Over-smoothing is directly related to the mechanism causing vanishinggradients; (iii) Over-squashing is most easily alleviated by a combination ofgraph rewiring and vanishing gradient mitigation. We believe our work will helpbridge the gap between the recurrent and graph neural network literature andwill unlock the design of new deep and performant GNNs.</description>
      <author>example@mail.com (Álvaro Arroyo, Alessio Gravina, Benjamin Gutteridge, Federico Barbero, Claudio Gallicchio, Xiaowen Dong, Michael Bronstein, Pierre Vandergheynst)</author>
      <guid isPermaLink="false">2502.10818v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Small World of Word Embeddings: A Comparative Study on Conceptual Spaces from LLMs of Different Scales</title>
      <link>http://arxiv.org/abs/2502.11380v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;概念空间表示概念为节点和语义相关性为边。词嵌入结合相似度指标提供了一种有效的方法来构建这种空间。&lt;h4&gt;目的&lt;/h4&gt;研究不同规模的大语言模型（LLMs）的词嵌入属性，探索它们在构建概念空间中的作用，并进行跨语言语义映射分析。&lt;h4&gt;方法&lt;/h4&gt;使用不同规模的LLM构造概念空间，基于语言类型学启发的连通性假设建立网络，分析全局统计性质和比较不同规模的LLMs。局部层面则探讨概念对、WordNet关系以及跨语言语义网络。&lt;h4&gt;主要发现&lt;/h4&gt;构建的空间具有小世界特性，表现为高聚类系数和短路径长度；更大规模的LLM生成更为复杂的空间，长路径反映了更丰富的关系结构和连接；网络作为高效的跨语言语义映射桥梁。&lt;h4&gt;结论&lt;/h4&gt;研究揭示了不同规模的大语言模型在构造概念空间中的独特贡献以及它们如何促进有效的跨语言语义理解。&lt;h4&gt;翻译&lt;/h4&gt;A conceptual space represents concepts as nodes and semantic relatedness as edges. Word embeddings, combined with a similarity metric, provide an effective approach to constructing such a space. Typically, embeddings are derived from traditional distributed models or encoder-only pretrained models, whose objectives directly capture the meaning of the current token. In contrast, decoder-only models, including large language models (LLMs), predict the next token, making their embeddings less directly tied to the current token's semantics. Moreover, comparative studies on LLMs of different scales remain underexplored. In this paper, we construct a conceptual space using word embeddings from LLMs of varying scales and comparatively analyze their properties.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A conceptual space represents concepts as nodes and semantic relatedness asedges. Word embeddings, combined with a similarity metric, provide an effectiveapproach to constructing such a space. Typically, embeddings are derived fromtraditional distributed models or encoder-only pretrained models, whoseobjectives directly capture the meaning of the current token. In contrast,decoder-only models, including large language models (LLMs), predict the nexttoken, making their embeddings less directly tied to the current token'ssemantics. Moreover, comparative studies on LLMs of different scales remainunderexplored. In this paper, we construct a conceptual space using wordembeddings from LLMs of varying scales and comparatively analyze theirproperties. We establish a network based on a linguistic typology-inspiredconnectivity hypothesis, examine global statistical properties, and compareLLMs of varying scales. Locally, we analyze conceptual pairs, WordNetrelations, and a cross-lingual semantic network for qualitative words. Ourresults indicate that the constructed space exhibits small-world properties,characterized by a high clustering coefficient and short path lengths. LargerLLMs generate more intricate spaces, with longer paths reflecting richerrelational structures and connections. Furthermore, the network serves as anefficient bridge for cross-lingual semantic mapping.</description>
      <author>example@mail.com (Zhu Liu, Ying Liu, KangYang Luo, Cunliang Kong, Maosong Sun)</author>
      <guid isPermaLink="false">2502.11380v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A Distillation-based Future-aware Graph Neural Network for Stock Trend Prediction</title>
      <link>http://arxiv.org/abs/2502.10776v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种新的基于蒸馏的未来感知图神经网络框架（DishFT-GNN），用于股票趋势预测。&lt;h4&gt;背景&lt;/h4&gt;股票趋势预测涉及通过分析历史数据和各种市场指标来预测未来的股价走势。随着机器学习的进步，由于其强大的能力能够捕捉股票的空间时间依赖关系，图神经网络(GNNs)在股市预测中得到了广泛的应用。&lt;h4&gt;目的&lt;/h4&gt;尽管已有多种GNN股票预测器尝试提高预测性能，但它们仅关注分析历史空间时间依赖性，忽视了历史和未来模式之间的相关性。因此，研究目的是提出一种能够同时捕捉历史和未来数据分布变化之间关系的模型。&lt;h4&gt;方法&lt;/h4&gt;DishFT-GNN通过迭代训练教师模型和学生模型来实现。教师模型学习到的历史和未来数据分布变化的相关信息被用作中间监督信号，引导学生模型学习对未来感知的空间时间嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;通过在两个真实世界的数据集上进行广泛的实验验证了DishFT-GNN的最先进的性能表现。&lt;h4&gt;结论&lt;/h4&gt;提出的基于蒸馏的未来感知图神经网络框架（DishFT-GNN）可以有效地捕捉历史和未来的相关性，从而提高股票趋势预测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;股票趋势预测涉及通过分析历史数据和各种市场指标来预测未来的股价走势。随着机器学习的进步，由于其强大的能力能够捕捉股票的空间时间依赖关系，图神经网络(GNNs)在股市预测中得到了广泛的应用。然而，尽管已有多种GNN股票预测器尝试提高预测性能，但它们仅关注分析历史空间时间依赖性，忽视了历史和未来模式之间的相关性。本文提出了一种新的基于蒸馏的未来感知图神经网络框架（DishFT-GNN）。通过在两个真实世界的数据集上进行广泛的实验验证了该方法的先进性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stock trend prediction involves forecasting the future price movements byanalyzing historical data and various market indicators. With the advancementof machine learning, graph neural networks (GNNs) have been extensivelyemployed in stock prediction due to their powerful capability to capturespatiotemporal dependencies of stocks. However, despite the efforts of variousGNN stock predictors to enhance predictive performance, the improvements remainlimited, as they focus solely on analyzing historical spatiotemporaldependencies, overlooking the correlation between historical and futurepatterns. In this study, we propose a novel distillation-based future-aware GNNframework (DishFT-GNN) for stock trend prediction. Specifically, DishFT-GNNtrains a teacher model and a student model, iteratively. The teacher modellearns to capture the correlation between distribution shifts of historical andfuture data, which is then utilized as intermediate supervision to guide thestudent model to learn future-aware spatiotemporal embeddings for accurateprediction. Through extensive experiments on two real-world datasets, we verifythe state-of-the-art performance of DishFT-GNN.</description>
      <author>example@mail.com (Zhipeng Liu, Peibo Duan, Mingyang Geng, Bin Zhang)</author>
      <guid isPermaLink="false">2502.10776v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>WRT-SAM: Foundation Model-Driven Segmentation for Generalized Weld Radiographic Testing</title>
      <link>http://arxiv.org/abs/2502.11338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Segment Anything Model (SAM)的新型焊缝射线检测缺陷分割模型WRT-SAM，通过适配器集成和专业化提示生成架构，提升了对灰度焊缝射线图像的适应性。此外，引入了频域提示生成模块来增强模型敏感性，并使用多尺度提示生成模块处理焊接缺陷的多层次特性。&lt;h4&gt;背景&lt;/h4&gt;放射检测是非破坏评估技术之一，用于识别焊接缺陷并评价工业应用中的质量。近年来，深度学习在焊缝缺陷识别中取得了显著进步。然而，传统的基于单一场景数据集训练的小规模模型泛化能力较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于SAM的焊缝射线缺陷分割方法，以提高跨领域泛化的性能，并在不同焊接检测场景中实现应用。&lt;h4&gt;方法&lt;/h4&gt;WRT-SAM通过adapter-based集成方式利用了预先训练好的视觉基础模型SAM。此外，为了增强适应性，引入了一个频率提示生成模块和一个多尺度提示生成模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，WRT-SAM在焊缝射线图像缺陷分割任务上取得了78.87%的召回率、84.04%的精确度以及0.9746的AUC值，刷新了该领域的最新基准。同时展示了优异的零样本泛化性能。&lt;h4&gt;结论&lt;/h4&gt;WRT-SAM模型展现了在焊缝射线图像缺陷分割中的卓越性能和广泛适用性，为实际部署提供了坚实基础。&lt;h4&gt;翻译&lt;/h4&gt;放射检测是一种基本的非破坏性评估技术，利用其高分辨率成像能力来识别焊接缺陷并评价工业应用中的质量。近年来，深度学习技术显著推进了焊接缺陷在射线图像中的识别进展。然而，依赖于单一场景数据集训练的小规模模型的传统方法，在跨领域泛化方面表现不佳。最近，Segment Anything Model (SAM)，一个基于大规模数据集预训练的视觉基础模型，展示了卓越的零样本泛化能力。利用有限的特定领域数据对SAM进行微调，在医学图像分割和异常检测等领域取得了显著成果。据我们所知，这项工作是首次将基于SAM的分割技术应用于通用焊接射线检测图像。我们提出了一种新的焊缝射线缺陷分割模型WRT-SAM，该模型利用了SAM并通过适配器集成与专业化提示生成架构结合。为了提高对灰度焊缝射线图像的适应性，引入了一个频率提示生成模块，增强了模型对频域信息的敏感性。此外，为了解决焊接缺陷多尺度问题，我们集成了一个多尺度提示生成模块，使模型能够有效地在不同尺度下提取和编码缺陷信息。广泛的实验评估表明，WRT-SAM实现了78.87%的召回率、84.04%的精确度以及AUC值为0.9746，设立了一个新的行业标准（SOTA）。此外，该模型展示了优秀的零样本泛化性能，突显了其在各种射线检测场景中实际部署的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radiographic testing is a fundamental non-destructive evaluation techniquefor identifying weld defects and assessing quality in industrial applicationsdue to its high-resolution imaging capabilities. Over the past decade, deeplearning techniques have significantly advanced weld defect identification inradiographic images. However, conventional approaches, which rely on trainingsmall-scale, task-specific models on single-scenario datasets, exhibit poorcross-scenario generalization. Recently, the Segment Anything Model (SAM), apre-trained visual foundation model trained on large-scale datasets, hasdemonstrated exceptional zero-shot generalization capabilities. Fine-tuning SAMwith limited domain-specific data has yielded promising results in fields suchas medical image segmentation and anomaly detection. To the best of ourknowledge, this work is the first to introduce SAM-based segmentation forgeneral weld radiographic testing images. We propose WRT-SAM, a novel weldradiographic defect segmentation model that leverages SAM through anadapter-based integration with a specialized prompt generator architecture. Toimprove adaptability to grayscale weld radiographic images, we introduce afrequency prompt generator module, which enhances the model's sensitivity tofrequency-domain information. Furthermore, to address the multi-scale nature ofweld defects, we incorporate a multi-scale prompt generator module, enablingthe model to effectively extract and encode defect information across varyingscales. Extensive experimental evaluations demonstrate that WRT-SAM achieves arecall of 78.87%, a precision of 84.04%, and an AUC of 0.9746, setting a newstate-of-the-art (SOTA) benchmark. Moreover, the model exhibits superiorzero-shot generalization performance, highlighting its potential for practicaldeployment in diverse radiographic testing scenarios.</description>
      <author>example@mail.com (Yunyi Zhou, Kun Shi, Gang Hao)</author>
      <guid isPermaLink="false">2502.11338v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Human-Centric Community Detection in Hybrid Metaverse Networks with Integrated AI Entities</title>
      <link>http://arxiv.org/abs/2502.10750v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, Accepted for publication in the ACM WWW 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'研究背景': '社区检测是社交网络分析中的重要问题，旨在识别内部联系紧密而外部链接较少的社团。然而，随着生成式AI和元宇宙的发展，出现了混合的人类-AI社交网络（HASN），这使得传统的社区检测方法在处理人类为中心的情境时效果不佳。', '研究目的': '提出一种新的MetaCD问题，即在HASN中增强人类连接的同时减少AI节点的存在。旨在解决排除某些AI节点与保持社团结构之间的微妙平衡问题。', '所提方案': '提出了CUSA框架，该框架使用了考虑AI的聚类技术来优化这种权衡，在保留对社区完整性有益的AI节点的同时，排除不适当的AI节点。', '数据策略': '鉴于现实世界中的HASN稀缺，设计了四种方法在各种假设场景下合成这些网络。', '实验结果': '实验证明了该方法与传统的非深度学习和图神经网络（GNN）技术相比，在重新配置为HASN的真实社交网络上的有效性及实用性。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714679&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Community detection is a cornerstone problem in social network analysis(SNA), aimed at identifying cohesive communities with minimal external links.However, the rise of generative AI and Metaverse introduce complexities bycreating hybrid human-AI social networks (denoted by HASNs), where traditionalmethods fall short, especially in human-centric settings. This paper introducesa novel community detection problem in HASNs (denoted by MetaCD), which seeksto enhance human connectivity within communities while reducing the presence ofAI nodes. Effective processing of MetaCD poses challenges due to the delicatetrade-off between excluding certain AI nodes and maintaining communitystructure. To address this, we propose CUSA, an innovative frameworkincorporating AI-aware clustering techniques that navigate this trade-off byselectively retaining AI nodes that contribute to community integrity.Furthermore, given the scarcity of real-world HASNs, we devise four strategiesfor synthesizing these networks under various hypothetical scenarios. Empiricalevaluations on real social networks, reconfigured as HASNs, demonstrate theeffectiveness and practicality of our approach compared to traditional non-deeplearning and graph neural network (GNN)-based methods.</description>
      <author>example@mail.com (Shih-Hsuan Chiu, Ya-Wen Teng, De-Nian Yang, Ming-Syan Chen)</author>
      <guid isPermaLink="false">2502.10750v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Phantom: Subject-consistent video generation via cross-modal alignment</title>
      <link>http://arxiv.org/abs/2502.11079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Phantom是一个用于生成单个和多个参考主体的统一视频生成框架，通过跨模态对齐学习提高了文本和图像提示之间的平衡。&lt;h4&gt;背景&lt;/h4&gt;基础模型在视频生成领域的持续发展正在向各种应用拓展，而基于主题一致性的视频生成仍处于探索阶段。这个领域被称为Subject-to-Video。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决Subject-to-Video中的跨模态对齐问题，特别是针对人类主体的一致性生成。&lt;h4&gt;方法&lt;/h4&gt;构建了一个统一的框架Phantom，该框架基于现有的文本到视频和图像到视频架构，重新设计了联合文本-图像注入模型，并通过文本-图像-视频三元组数据驱动其学习跨模态对齐。&lt;h4&gt;主要发现&lt;/h4&gt;强调人类生成中的主体一致性，覆盖现有的身份保持型视频生成同时提供增强的优势。&lt;h4&gt;结论&lt;/h4&gt;Phantom框架在Subject-to-Video问题上取得了显著进展，为未来的视频生成技术提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;基础模型在视频生成领域的持续发展正在向各种应用拓展，而基于主题一致性的视频生成仍处于探索阶段。我们称之为Subject-to-Video，该方法从参考图像中提取主体元素，并通过文本指令生成主体一致性视频。我们认为，Subject-to-Video的核心在于平衡文本和图像双模态提示，从而同时深入对齐文本和视觉内容。为此，我们提出了Phantom框架，用于单个和多个参考主体的统一视频生成。该框架基于现有的文本到视频和图像到视频架构，重新设计了联合文本-图像注入模型，并通过文本-图像-视频三元组数据驱动其学习跨模态对齐。特别地，我们在人类生成中强调主体一致性，涵盖了现有身份保持型视频生成的同时提供了增强的优势。该项目主页在这里：https://phantom-video.github.io/Phantom/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The continuous development of foundational models for video generation isevolving into various applications, with subject-consistent video generationstill in the exploratory stage. We refer to this as Subject-to-Video, whichextracts subject elements from reference images and generatessubject-consistent video through textual instructions. We believe that theessence of subject-to-video lies in balancing the dual-modal prompts of textand image, thereby deeply and simultaneously aligning both text and visualcontent. To this end, we propose Phantom, a unified video generation frameworkfor both single and multi-subject references. Building on existingtext-to-video and image-to-video architectures, we redesign the jointtext-image injection model and drive it to learn cross-modal alignment viatext-image-video triplet data. In particular, we emphasize subject consistencyin human generation, covering existing ID-preserving video generation whileoffering enhanced advantages. The project homepage is herehttps://phantom-video.github.io/Phantom/.</description>
      <author>example@mail.com (Lijie Liu, Tianxiang Ma, Bingchuan Li, Zhuowei Chen, Jiawei Liu, Qian He, Xinglong Wu)</author>
      <guid isPermaLink="false">2502.11079v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Automated Data Quality Validation in an End-to-End GNN Framework</title>
      <link>http://arxiv.org/abs/2502.10667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于改进的图神经网络（GNN）和多任务学习的数据质量验证与修复框架DQuag。该方法采用双解码器设计，分别用于数据质量和数据修复，并且能够自动检测显式和隐藏的数据错误。&lt;h4&gt;背景&lt;/h4&gt;确保数据质量对于现代数据生态系统至关重要，尤其是在机器学习中的训练或测试数据集方面。现有验证方法依赖于计算数据质量指标和/或使用专家定义的约束条件。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需手动输入约束生成、能够自动检测复杂特征关系的数据质量验证与修复框架，以提高数据质量和解决传统系统难以发现的问题。&lt;h4&gt;方法&lt;/h4&gt;DQuag采用改进的图神经网络（GNN）架构和多任务学习技术来捕捉表格数据中的复杂特性关系，并通过双解码器设计实现数据质量验证和数据修复功能。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够自动检测传统系统经常忽略的隐藏错误，无需手动生成约束条件即可学习底层特征依赖关系。&lt;h4&gt;结论&lt;/h4&gt;实验结果证明了这种方法在识别和解决数据质量问题方面的有效性，并强调其不需要人工干预来定义约束条件的优势。&lt;h4&gt;翻译&lt;/h4&gt;确保数据质量是现代数据生态系统的关键要素，特别是在训练或测试机器学习模型的数据集中。现有验证方法通常依赖于计算数据质量指标以及专家定义的规则。尽管存在自动化的约束生成技术，但它们往往不完整且可能过于严格或宽松，导致误报或遗漏错误，从而需要人工调整。此外，这些方法在检测由复杂关系掩盖的细微数据差异时表现不佳。本文提出了一种基于改进图神经网络和多任务学习的端到端框架DQuag，用于数据质量验证与修复。该框架使用双解码器结构，一个用于数据质量验证，另一个用于数据修复。通过采用多层次图神经网络架构，我们的方法可以捕捉表格数据集中的复杂特性关系，并自动检测显性和隐性的数据错误。与以往的方法不同的是，我们这种方法不需要人为生成约束条件，而是学习到特征之间的依赖性，从而能够识别传统系统常会忽视的隐藏错误。此外，它还可以建议修复值，进一步提升整体的数据质量。实验结果证明了该方法的有效性，在识别和解决数据质量问题方面表现优异。本文发表于2025年EDBT会议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring data quality is crucial in modern data ecosystems, especially fortraining or testing datasets in machine learning. Existing validationapproaches rely on computing data quality metrics and/or using expert-definedconstraints. Although there are automated constraint generation methods, theyare often incomplete and may be too strict or too soft, causing false positivesor missed errors, thus requiring expert adjustment. These methods may also failto detect subtle data inconsistencies hidden by complex interdependencieswithin the data. In this paper, we propose DQuag, an end-to-end data qualityvalidation and repair framework based on an improved Graph Neural Network (GNN)and multi-task learning. The proposed method incorporates a dual-decoderdesign: one for data quality validation and the other for data repair. Ourapproach captures complex feature relationships within tabular datasets using amulti-layer GNN architecture to automatically detect explicit and hidden dataerrors. Unlike previous methods, our model does not require manual input forconstraint generation and learns the underlying feature dependencies, enablingit to identify complex hidden errors that traditional systems often miss.Moreover, it can recommend repair values, improving overall data quality.Experimental results validate the effectiveness of our approach in identifyingand resolving data quality issues. The paper appeared in EDBT 2025.</description>
      <author>example@mail.com (Sijie Dong, Soror Sahri, Themis Palpanas, Qitong Wang)</author>
      <guid isPermaLink="false">2502.10667v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>ClimateLLM: Efficient Weather Forecasting via Frequency-Aware Large Language Models</title>
      <link>http://arxiv.org/abs/2502.11059v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;天气预报对于公共安全、灾害预防和缓解、农业生产以及能源管理至关重要。虽然深度学习在气象预测方面取得了显著进展，但目前的方法存在局限性：难以捕捉动态时间依赖性和短期突变变化，导致极端天气建模困难；计算成本高昂；对多尺度频率的适应能力有限。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，我们提出了ClimateLLM这一用于天气预报的基础模型。该模型旨在通过融合基于傅里叶的方法和大型语言模型来加强空间和时间建模，同时处理全球信号和局部极端事件。&lt;h4&gt;方法&lt;/h4&gt;ClimateLLM使用了一种混合专家机制（MoE），能够灵活处理不同的频率成分；还引入了跨时间和空间的动态提示机制，使大型语言模型能够有效地整合多尺度气象模式。此外，其框架集成了基于傅里叶的方法与大型语言模型来增强空间和时间建模。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在真实世界数据集上ClimateLLM比现有的最佳方法在准确性和效率方面表现更佳，是一个可扩展的全球天气预报解决方案。&lt;h4&gt;结论&lt;/h4&gt;该论文提出了一种新的基于深度学习的方法，用于改进极端气象事件预测及提高计算资源利用率。这种方法通过增强时间序列分析和频率分解能力，有望为未来的研究提供一个坚实的基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要的原始内容已经包含中文表述&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Weather forecasting is crucial for public safety, disaster prevention andmitigation, agricultural production, and energy management, with globalrelevance. Although deep learning has significantly advanced weatherprediction, current methods face critical limitations: (i) they often struggleto capture both dynamic temporal dependencies and short-term abrupt changes,making extreme weather modeling difficult; (ii) they incur high computationalcosts due to extensive training and resource requirements; (iii) they havelimited adaptability to multi-scale frequencies, leading to challenges whenseparating global trends from local fluctuations. To address these issues, wepropose ClimateLLM, a foundation model for weather forecasting. It capturesspatiotemporal dependencies via a cross-temporal and cross-spatialcollaborative modeling framework that integrates Fourier-based frequencydecomposition with Large Language Models (LLMs) to strengthen spatial andtemporal modeling. Our framework uses a Mixture-of-Experts (MoE) mechanism thatadaptively processes different frequency components, enabling efficienthandling of both global signals and localized extreme events. In addition, weintroduce a cross-temporal and cross-spatial dynamic prompting mechanism,allowing LLMs to incorporate meteorological patterns across multiple scaleseffectively. Extensive experiments on real-world datasets show that ClimateLLMoutperforms state-of-the-art approaches in accuracy and efficiency, as ascalable solution for global weather forecasting.</description>
      <author>example@mail.com (Shixuan Li, Wei Yang, Peiyu Zhang, Xiongye Xiao, Defu Cao, Yuehan Qin, Xiaole Zhang, Yue Zhao, Paul Bogdan)</author>
      <guid isPermaLink="false">2502.11059v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Recent Advances in Malware Detection: Graph Learning and Explainability</title>
      <link>http://arxiv.org/abs/2502.10556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概述&lt;/h4&gt;该论文综述了恶意软件检测领域的最新进展，特别是图学习技术和可解释性技术之间的相互作用。&lt;h4&gt;背景&lt;/h4&gt;恶意软件的快速演变需要超越传统基于签名的方法的复杂检测手段。图学习技术利用图神经网络（GNN）和其他相关方法，成为了建模和分析恶意软件行为中固有复杂关系的强大工具。&lt;h4&gt;目的&lt;/h4&gt;综述旨在全面探索近期在恶意软件检测方面的进展，并强调图学习与可解释性之间的相互作用的重要性。&lt;h4&gt;研究范围&lt;/h4&gt;论文首先回顾了恶意软件分析技术和数据集的现状，这些是理解恶意软件行为和支持检测策略的基础。然后讨论了特征工程、图简化和图嵌入方法，以展示将原始数据转换为实用见解的重要意义，并确保系统可扩展性和效率。&lt;h4&gt;重点技术&lt;/h4&gt;强调了在恶意软件检测中应用可解释性技术的重要性，包括透明度和信任度的保证。&lt;h4&gt;综合贡献&lt;/h4&gt;通过整合这些组件，该综述展示了图学习与可解释性的结合如何有助于构建稳健、可解释且高效的恶意软件检测系统。&lt;h4&gt;未来方向&lt;/h4&gt;论文还概述了未来的研究方向，以解决当前挑战并开启新的机遇。&lt;h4&gt;翻译&lt;/h4&gt;摘要：恶意软件的快速演变促使发展出超越传统基于签名方法的复杂检测手段。图学习技术已作为建模和分析恶意行为中固有复杂关系的强大工具而出现，并利用图神经网络（GNNs）和其他相关方法的进步。这篇综述全面探讨了近期在恶意软件检测方面的进展，重点是图学习与可解释性的相互作用。它首先回顾了恶意软件分析技术和数据集，强调它们理解恶意行为和支撑检测策略的基础性角色。然后讨论了特征工程、图简化及图嵌入方法，突显这些技术将原始数据转化为实用见解的重要意义，并确保系统的可扩展性和效率。此外，综述重点在于解释性技术和其在恶意软件检测中的应用，以保证透明度与信任度。通过整合这些组件，该综述展示了如何利用图学习和解释性构建稳健、可解读且高效的恶意软件检测系统。它还概述了未来的研究方向，旨在应对现有挑战并解锁新的机遇，以解决这个网络安全关键领域的难题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid evolution of malware has necessitated the development ofsophisticated detection methods that go beyond traditional signature-basedapproaches. Graph learning techniques have emerged as powerful tools formodeling and analyzing the complex relationships inherent in malware behavior,leveraging advancements in Graph Neural Networks (GNNs) and related methods.This survey provides a comprehensive exploration of recent advances in malwaredetection, focusing on the interplay between graph learning and explainability.It begins by reviewing malware analysis techniques and datasets, emphasizingtheir foundational role in understanding malware behavior and supportingdetection strategies. The survey then discusses feature engineering, graphreduction, and graph embedding methods, highlighting their significance intransforming raw data into actionable insights, while ensuring scalability andefficiency. Furthermore, this survey focuses on explainability techniques andtheir applications in malware detection, ensuring transparency andtrustworthiness. By integrating these components, this survey demonstrates howgraph learning and explainability contribute to building robust, interpretable,and scalable malware detection systems. Future research directions are outlinedto address existing challenges and unlock new opportunities in this criticalarea of cybersecurity.</description>
      <author>example@mail.com (Hossein Shokouhinejad, Roozbeh Razavi-Far, Hesamodin Mohammadian, Mahdi Rabbani, Samuel Ansong, Griffin Higgins, Ali A Ghorbani)</author>
      <guid isPermaLink="false">2502.10556v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Accelerated co-design of robots through morphological pretraining</title>
      <link>http://arxiv.org/abs/2502.10862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了'零样本进化'的概念，即通过形态预训练来快速获得适用于多种机器人身体布局的通用控制器，并展示了这种方法可以比同时优化控制器和设计群体的方法产生更大的多样性。&lt;h4&gt;背景&lt;/h4&gt;传统的机器人形态与神经控制共设计方法需要大量的训练数据来评估每种设计方案的表现。这通常涉及到使用强化学习来为每个身体计划近似一个唯一的控制策略梯度。&lt;h4&gt;目的&lt;/h4&gt;展示通过可微模拟的基于梯度优化可以直接快速获得适用于所有机器人体形的通用控制器，从而减少对大量训练数据的需求，并促进机器人设计探索。&lt;h4&gt;方法&lt;/h4&gt;采用形态预训练过程：首先使用可微分模拟进行优化得到一个通用控制器；然后在不改变控制器的前提下，通过非连续变化调整机器人的物理布局（例如添加、删除或重新组合离散的身体部件）来评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;零样本进化方法能够迅速产生多种高性能的设计方案，并且在整个进化过程中通过对当前设计群体进行微调来保持和增加多样性。相比之下，同时优化控制器与不断演化的设计方案会导致“多样性崩溃”，即群体（及其训练数据）会收敛到易于使用共享通用控制器控制的类似设计。&lt;h4&gt;结论&lt;/h4&gt;零样本进化方法不仅能够有效地探索机器人设计空间，还能够在不牺牲性能的前提下实现更广泛的多样性，从而避免了多样性的丧失。这种方法为快速高效的机器人形态和控制系统的设计提供了一个新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The co-design of robot morphology and neural control typically requires usingreinforcement learning to approximate a unique control policy gradient for eachbody plan, demanding massive amounts of training data to measure theperformance of each design. Here we show that a universal, morphology-agnosticcontroller can be rapidly and directly obtained by gradient-based optimizationthrough differentiable simulation. This process of morphological pretrainingallows the designer to explore non-differentiable changes to a robot's physicallayout (e.g. adding, removing and recombining discrete body parts) andimmediately determine which revisions are beneficial and which are deleterioususing the pretrained model. We term this process "zero-shot evolution" andcompare it with the simultaneous co-optimization of a universal controlleralongside an evolving design population. We find the latter results indiversity collapse, a previously unknown pathology whereby the population --and thus the controller's training data -- converges to similar designs thatare easier to steer with a shared universal controller. We show that zero-shotevolution with a pretrained controller quickly yields a diversity of highlyperformant designs, and by fine-tuning the pretrained controller on the currentpopulation throughout evolution, diversity is not only preserved butsignificantly increased as superior performance is achieved.</description>
      <author>example@mail.com (Luke Strgar, Sam Kriegman)</author>
      <guid isPermaLink="false">2502.10862v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Preconditioned Inexact Stochastic ADMM for Deep Model</title>
      <link>http://arxiv.org/abs/2502.10784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PISA的算法，该算法在训练基础模型时能够支持大规模并行计算，并且能够在仅假设梯度李普希兹连续性的条件下保证收敛。&lt;h4&gt;背景&lt;/h4&gt;近年来，基础模型（FMs）的发展带来了范式转变，在全球各个领域产生革命性影响。然而，基于随机梯度下降的常用优化算法在分布式设置下遇到数据异质性和理论及数值性能方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的优化算法PISA，以解决现有算法面对的数据异质性和并行计算规模问题，并提高训练基础模型时的数值表现和收敛效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为PISA（预处理不精确随机交替方向乘子法）的新算法，该算法支持多种二阶矩方案，并在严格的理论保证下证明了其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估结果表明，在训练或微调不同类型的基础模型时，包括视觉模型、大型语言模型、强化学习模型等，PISA的数值性能优于现有的多种最先进优化器。&lt;h4&gt;结论&lt;/h4&gt;通过解决数据异质性问题和提高并行计算能力，PISA算法为大规模基础模型的有效训练提供了强大支持。&lt;h4&gt;翻译&lt;/h4&gt;最近基础模型的发展带来了范式转变，在全球各个领域产生了革命性的影响。本文提出了一个名为PISA的算法来应对这些问题，该算法能够支持大规模并行计算，并在理论上保证了即使存在数据异质性的条件下也具有良好的数值性能和收敛性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent advancement of foundation models (FMs) has brought about aparadigm shift, revolutionizing various sectors worldwide. The popularoptimizers used to train these models are stochastic gradient descent-basedalgorithms, which face inherent limitations, such as slow convergence andstringent assumptions for convergence. In particular, data heterogeneityarising from distributed settings poses significant challenges to theirtheoretical and numerical performance. This paper develops an algorithm, PISA({P}reconditioned {I}nexact {S}tochastic {A}lternating Direction Method ofMultipliers), which enables scalable parallel computing and supports varioussecond-moment schemes. Grounded in rigorous theoretical guarantees, thealgorithm converges under the sole assumption of Lipschitz continuity of thegradient, thereby removing the need for other conditions commonly imposed bystochastic methods. This capability enables PISA to tackle the challenge ofdata heterogeneity effectively. Comprehensive experimental evaluations fortraining or fine-tuning diverse FMs, including vision models, large languagemodels, reinforcement learning models, generative adversarial networks, andrecurrent neural networks, demonstrate its superior numerical performancecompared to various state-of-the-art optimizers.</description>
      <author>example@mail.com (Shenglong Zhou, Ouya Wang, Ziyan Luo, Yongxu Zhu, Geoffrey Ye Li)</author>
      <guid isPermaLink="false">2502.10784v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>HIPPo: Harnessing Image-to-3D Priors for Model-free Zero-shot 6D Pose Estimation</title>
      <link>http://arxiv.org/abs/2502.10606v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种无需预处理CAD模型和参考图像的零样本6D物体姿态估计框架HIPPo。&lt;h4&gt;背景&lt;/h4&gt;现有的方法在精确估算6D物体姿态时，严重依赖于精心准备的CAD模型或参考图像。然而，在实际场景中这些资源可能不可用，且准备过程耗时费力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架HIPPo，利用扩散模型中的图像到3D先验知识进行零样本6D姿态估计。&lt;h4&gt;方法&lt;/h4&gt;{'构建HIPPo Dreamer': '这是一个基于多视角扩散模型和三维重建基础模型的快速图象转网格模型。它可以仅凭一张图片生成任何未见过物体的三维网格。', '逐步优化': '通过测量引导方案，逐步用更可靠的在线观测替换初步的扩散先验，以实现持续优化。'}&lt;h4&gt;主要发现&lt;/h4&gt;HIPPo能够在瞬间估算和跟踪新颖对象的6D姿态，并保持一个完整的网格模型用于即时机器人应用。&lt;h4&gt;结论&lt;/h4&gt;在各种基准测试中，当先前参考图像有限时，HIPPo在6D物体姿态估计方面优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;这项工作关注的是无需预处理CAD模型和参考图像的零样本六自由度（6D）物体姿态估计技术。现有的方法虽然能够精确估算6D物体姿态，但它们严重依赖于精心准备的CAD模型或参考图像。这些资源在实际场景中可能不可用，并且准备工作耗时费力。本文提出了一种新框架HIPPo，它利用扩散模型中的图象到3D先验知识进行零样本6D姿态估计。通过一个快速的图像转网格模型HIPPo Dreamer，该框架能够在几秒钟内仅凭一张图片生成任何未见过物体的三维网格，并随着观察数据增加持续优化其性能。实验表明，在先前参考图像有限的情况下，HIPPo在六自由度（6D）物体姿态估计方面优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work focuses on model-free zero-shot 6D object pose estimation forrobotics applications. While existing methods can estimate the precise 6D poseof objects, they heavily rely on curated CAD models or reference images, thepreparation of which is a time-consuming and labor-intensive process. Moreover,in real-world scenarios, 3D models or reference images may not be available inadvance and instant robot reaction is desired. In this work, we propose a novelframework named HIPPo, which eliminates the need for curated CAD models andreference images by harnessing image-to-3D priors from Diffusion Models,enabling model-free zero-shot 6D pose estimation. Specifically, we constructHIPPo Dreamer, a rapid image-to-mesh model built on a multiview Diffusion Modeland a 3D reconstruction foundation model. Our HIPPo Dreamer can generate a 3Dmesh of any unseen objects from a single glance in just a few seconds. Then, asmore observations are acquired, we propose to continuously refine the diffusionprior mesh model by joint optimization of object geometry and appearance. Thisis achieved by a measurement-guided scheme that gradually replaces theplausible diffusion priors with more reliable online observations.Consequently, HIPPo can instantly estimate and track the 6D pose of a novelobject and maintain a complete mesh for immediate robotic applications.Thorough experiments on various benchmarks show that HIPPo outperformsstate-of-the-art methods in 6D object pose estimation when prior referenceimages are limited.</description>
      <author>example@mail.com (Yibo Liu, Zhaodong Jiang, Binbin Xu, Guile Wu, Yuan Ren, Tongtong Cao, Bingbing Liu, Rui Heng Yang, Amir Rasouli, Jinjun Shan)</author>
      <guid isPermaLink="false">2502.10606v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>SAMRI-2: A Memory-based Model for Cartilage and Meniscus Segmentation in 3D MRIs of the Knee Joint</title>
      <link>http://arxiv.org/abs/2502.10559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究介绍了一种用于从3D MRI图像中分割软骨和半月板的深度学习方法，该方法基于交互式的、具有记忆功能的视觉基础模型，并通过融合策略改进空间感知。&lt;h4&gt;背景&lt;/h4&gt;膝关节骨关节炎监测需要准确评估软骨厚度/体积等形态学参数。然而，当前的软骨分割技术依赖于大量专家标注的数据集，并且容易受到阅读者间差异的影响。&lt;h4&gt;目的&lt;/h4&gt;探索视觉基础模型（尤其是记忆型方法）在提高泛化能力和鲁棒性方面的机会，开发一种深度学习方法来改善膝关节MRI图像中软骨和半月板的分割准确性。&lt;h4&gt;方法&lt;/h4&gt;研究团队训练了四个AI模型：一个基于CNN的3D-VNet、两个自动变压器模型（SaMRI2D和SaMRI3D），以及一个记忆型视觉基础模型（SAMRI-2）。这些模型在包含来自270名患者的公共和内部数据集上进行训练，并在外部分为57例患者的数据集中进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;引入了混合洗牌策略（HSS）以提高空间感知能力和收敛性，使用分割掩码传播技术来提升注释效率。实验表明，SAMRI-2模型在所有其他模型中表现最佳，在Dice Score和交并比上平均提高了5分，对于胫骨软骨最高甚至提升了12分。&lt;h4&gt;结论&lt;/h4&gt;这种基于记忆的视觉基础模型提供了可靠的人工智能辅助膝关节MRI分割的新方法，并显著降低了软骨厚度误差。SAMRI-2模型仅需最少三个用户点击即可实现高精度解剖学注释，为肌骨骼成像领域的深度学习研究开辟了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;Accurate morphometric assessment of cartilage such as thickness/volume via MRI is essential for monitoring knee osteoarthritis. Segmenting cartilage remains challenging and dependent on extensive expert-annotated datasets, which are heavily subjected to inter-reader variability. Recent advancements in Visual Foundational Models (VFM), especially memory-based approaches, offer opportunities for improving generalizability and robustness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate morphometric assessment of cartilage-such as thickness/volume-viaMRI is essential for monitoring knee osteoarthritis. Segmenting cartilageremains challenging and dependent on extensive expert-annotated datasets, whichare heavily subjected to inter-reader variability. Recent advancements inVisual Foundational Models (VFM), especially memory-based approaches, offeropportunities for improving generalizability and robustness. This studyintroduces a deep learning (DL) method for cartilage and meniscus segmentationfrom 3D MRIs using interactive, memory-based VFMs. To improve spatial awarenessand convergence, we incorporated a Hybrid Shuffling Strategy (HSS) duringtraining and applied a segmentation mask propagation technique to enhanceannotation efficiency. We trained four AI models-a CNN-based 3D-VNet, twoautomatic transformer-based models (SaMRI2D and SaMRI3D), and atransformer-based promptable memory-based VFM (SAMRI-2)-on 3D knee MRIs from270 patients using public and internal datasets and evaluated on 57 externalcases, including multi-radiologist annotations and different data acquisitions.Model performance was assessed against reference standards using Dice Score(DSC) and Intersection over Union (IoU), with additional morphometricevaluations to further quantify segmentation accuracy. SAMRI-2 model, trainedwith HSS, outperformed all other models, achieving an average DSC improvementof 5 points, with a peak improvement of 12 points for tibial cartilage. It alsodemonstrated the lowest cartilage thickness errors, reducing discrepancies byup to threefold. Notably, SAMRI-2 maintained high performance with as few asthree user clicks per volume, reducing annotation effort while ensuringanatomical precision. This memory-based VFM with spatial awareness offers anovel approach for reliable AI-assisted knee MRI segmentation, advancing DL inmusculoskeletal imaging.</description>
      <author>example@mail.com (Danielle L. Ferreira, Bruno A. A. Nunes, Xuzhe Zhang, Laura Carretero Gomez, Maggie Fung, Ravi Soni)</author>
      <guid isPermaLink="false">2502.10559v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>GraphiT: Efficient Node Classification on Text-Attributed Graphs with Prompt Optimized LLMs</title>
      <link>http://arxiv.org/abs/2502.10522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了一种名为GraphiT的框架，用于将图数据编码成文本格式，并优化大语言模型（LLMs）在图预测任务中的提示语。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型应用于图形数据的研究受到了广泛关注。这些模型允许使用预先训练好的模型的深度上下文嵌入来处理带有文本属性的节点。然而，如何有效地将图结构和特征编码成序列形式以供LLMs使用仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法（GraphiT框架），以便更高效地利用图数据中的信息，并优化LLM提示语，使得它们在没有人工干预的情况下也能有效工作。&lt;h4&gt;方法&lt;/h4&gt;1. 将每个节点及其邻域的图数据编码成简洁的文本格式；2. 使用DSPy框架对LLM提示语进行程序化优化，以提高效率和可重复性。&lt;h4&gt;主要发现&lt;/h4&gt;GraphiT在三个数据集上的性能优于基于LLMs的基本模型，并且通过自动化的优化步骤可以在没有手动调整的情况下获得更好的结果。此外，该图编码方法的成本较低，因为它使用的令牌数量显著减少。&lt;h4&gt;结论&lt;/h4&gt;GraphiT提供了一种新的有效的方法来处理带有文本属性的节点分类问题，同时降低了计算成本和人工干预的需求。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型（LLMs）在图形数据中的应用最近引起了广泛关注。这些模型允许我们使用预先训练好的深度上下文嵌入来进行具有文本属性图上的任务，在这种情况下，通常为节点的文本属性使用浅层嵌入。然而，如何有效地将图结构和特征编码成序列形式以供LLMs使用仍然是一个挑战。此外，单一LLM的表现高度依赖于输入提示语的结构，这限制了它们作为可靠方法的有效性，并且往往需要反复的手动调整，这种做法可能缓慢、繁琐并且难以编程地复制。在本文中，我们提出了一种名为GraphiT（文本中的图）的框架，该框架将图形编码为文本格式，并优化LLM提示语以用于图预测任务。在这里，我们专注于带有文本属性图的节点分类。我们将每个节点及其邻域的图数据编码成简洁文本，使LLMs能够更好地利用图中的信息。然后，我们进一步使用DSPy框架对LLM提示语进行程序化优化，以便自动化这一步骤并使其更高效和可重复。GraphiT在三个数据集上优于我们的基于LLMs的基本模型，并展示了GraphiT中优化步骤如何导致没有手动调整提示词的明显更好的结果。我们也证明了我们的图编码方法与其他图编码方法具有竞争力，但成本更低，因为它使用相同的任务显著较少的令牌。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The application of large language models (LLMs) to graph data has attracted alot of attention recently. LLMs allow us to use deep contextual embeddings frompretrained models in text-attributed graphs, where shallow embeddings are oftenused for the text at- tributes of nodes. However, it is still challenging toefficiently en- code the graph structure and features into a sequential formfor use by LLMs. In addition, the performance of an LLM alone, is highlydependent on the structure of the input prompt, which limits theireffectiveness as a reliable approach and often requires iterative man- ualadjustments that could be slow, tedious and difficult to replicateprogrammatically. In this paper, we propose GraphiT (Graphs in Text), aframework for encoding graphs into a textual format and optimizing LLM promptsfor graph prediction tasks. Here we focus on node classification fortext-attributed graphs. We encode the graph data for every node and itsneighborhood into a concise text to enable LLMs to better utilize theinformation in the graph. We then further programmatically optimize the LLMprompts us- ing the DSPy framework to automate this step and make it moreefficient and reproducible. GraphiT outperforms our LLM-based baselines onthree datasets and we show how the optimization step in GraphiT leads tomeasurably better results without manual prompt tweaking. We also demonstratedthat our graph encoding approach is competitive to other graph encoding methodswhile being less expensive because it uses significantly less tokens for thesame task.</description>
      <author>example@mail.com (Shima Khoshraftar, Niaz Abedini, Amir Hajian)</author>
      <guid isPermaLink="false">2502.10522v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Cluster and Predict Latent Patches for Improved Masked Image Modeling</title>
      <link>http://arxiv.org/abs/2502.08769v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 7 figures, submitted to TMLR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的自我监督表示学习框架CAPI，该框架通过预测潜在聚类来改进现有的Masked Image Modeling (MIM) 方法。&lt;h4&gt;背景&lt;/h4&gt;当前的MIM模型虽然在自监督表征学习方面有前景，但性能仍落后于最先进的方法。研究者分析了目标表征、损失函数和架构，以期提升MIM的表现力。&lt;h4&gt;目的&lt;/h4&gt;通过设计一种全新的基于聚类的损失函数并采用纯MIM框架来改进现有模型的表现。&lt;h4&gt;方法&lt;/h4&gt;引入CAPI框架，利用稳定的聚类损失，并在ViT-L骨干网络上实现了这一创新。此外还展示了该方法在ImageNet和ADE20K数据集上的性能表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，使用简单的线性探测器，CAPI在ImageNet上达到了83.8%的准确率，在ADE20K上实现了32.1%mIoU，显著优于之前的MIM方法，并接近于DINOv2的最佳效果。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种新的纯MIM框架CAPI，通过预测潜在聚类来改进自监督学习表示。实验结果证明了其优越性，并且发布了所有代码和模型以供社区使用。&lt;h4&gt;翻译&lt;/h4&gt;掩码图像建模（MIM）为自我监督表征学习提供了一个有前景的方法，然而现有MIM模型仍然落后于最先进的技术。在本文中，我们系统地分析了目标表示、损失函数和架构，引入了一种新的纯MIM框架CAPI，该框架依赖于潜在聚类的预测。我们的方法利用基于聚类的损失，训练稳定，并展示了有前景的扩展属性。使用ViT-L骨干网络，我们的模型在ImageNet上达到了83.8%的准确率，在ADE20K上实现了32.1%mIoU，显著优于以前的MIM方法并接近目前最先进的性能DINOv2。我们发布了所有代码和模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/facebookresearch/capi&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked Image Modeling (MIM) offers a promising approach to self-supervisedrepresentation learning, however existing MIM models still lag behind thestate-of-the-art. In this paper, we systematically analyze targetrepresentations, loss functions, and architectures, to introduce CAPI - a novelpure-MIM framework that relies on the prediction of latent clusterings. Ourapproach leverages a clustering-based loss, which is stable to train, andexhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8%accuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes,substantially outperforming previous MIM methods and approaching theperformance of the current state-of-the-art, DINOv2. We release all our codeand models.</description>
      <author>example@mail.com (Timothée Darcet, Federico Baldassarre, Maxime Oquab, Julien Mairal, Piotr Bojanowski)</author>
      <guid isPermaLink="false">2502.08769v2</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Applying Deep Learning to Ads Conversion Prediction in Last Mile Delivery Marketplace</title>
      <link>http://arxiv.org/abs/2502.10514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, submitted to KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;Deep神经网络（DNN）在大规模网页排名系统中实现了革命性的变革，通过捕捉复杂用户行为和驱动性能提升。DoorDash首次将主页广告排名系统从传统的树模型转变为前沿的多任务DNN，在此过程中推动了数据基础、模型设计、训练效率、评估严谨性和线上服务等方面的发展。&lt;h4&gt;背景&lt;/h4&gt;Deep神经网络（DNN）在大规模网页排序系统中实现了革命性的变革，特别是在捕捉复杂用户行为和驱动性能提升方面。在此之前，DoorDash使用传统的树基模型来管理其主页广告排名系统。&lt;h4&gt;目的&lt;/h4&gt;通过分享从识别正确问题到开发和扩展深度学习推荐系统的整个过程中所遇到的挑战和解决方案，为其他寻求类似机器学习系统改进的团队提供见解和实际指导。&lt;h4&gt;方法&lt;/h4&gt;详细介绍了将传统决策树模型转换为多任务DNN的过程，并探讨了这一转变所带来的数据基础、模型设计、训练效率等方面的进步。&lt;h4&gt;主要发现&lt;/h4&gt;此次转变为DoorDash带来了显著的业务影响，改善了其广告排名系统的性能，并且重塑了公司对机器学习应用的理解和方法论。&lt;h4&gt;结论&lt;/h4&gt;通过展示将传统系统转化为基于DNN的多任务排序系统的过程中的经验和教训，论文鼓励其他团队在追求类似技术改进时借鉴这些经验。&lt;h4&gt;翻译&lt;/h4&gt;深度神经网络（DNN）已经在大规模网页排名系统中引发了革命，使捕捉复杂用户行为和性能提升成为可能。DoorDash首次利用这一变革性力量，将主页广告排名系统从传统的树模型转换为最先进的多任务DNN。这种演变促进了数据基础、模型设计、训练效率、评估严谨性和在线服务等方面的发展，并带来了显著的业务影响，重新定义了公司在机器学习方面的做法。在本文中，我们讨论了问题驱动的研究旅程，从识别正确的挑战并制定针对性解决方案到克服开发和扩展深度学习推荐系统的复杂性。通过我们的成功经验和教训，我们旨在为寻求类似机器学习系统改进团队提供见解和实用指南。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks (DNNs) have revolutionized web-scale ranking systems,enabling breakthroughs in capturing complex user behaviors and drivingperformance gains. At DoorDash, we first harnessed this transformative power bytransitioning our homepage Ads ranking system from traditional tree basedmodels to cutting edge multi task DNNs. This evolution sparked advancements indata foundations, model design, training efficiency, evaluation rigor, andonline serving, delivering substantial business impact and reshaping ourapproach to machine learning. In this paper, we talk about our problem drivenjourney, from identifying the right problems and crafting targeted solutions toovercoming the complexity of developing and scaling a deep learningrecommendation system. Through our successes and learned lessons, we aim toshare insights and practical guidance to teams pursuing similar advancements inmachine learning systems.</description>
      <author>example@mail.com (Di Li, Xiaochang Miao, Huiyu Song, Chao Chu, Hao Xu, Mandar Rahurkar)</author>
      <guid isPermaLink="false">2502.10514v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of World Models for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2501.11260v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Ongoing project&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统地回顾了自动驾驶领域世界模型的最新进展，并提出了一种三层次分类体系，包括未来物理世界的生成、智能代理的行为规划以及预测与规划之间的交互。&lt;h4&gt;背景&lt;/h4&gt;最近在自主驾驶方面的突破主要得益于稳健的世界建模技术的进步，这从根本上改变了车辆对动态场景的理解和安全决策执行的方式。世界模型已经成为关键技术，提供高保真度的驾驶环境表示，并整合了多传感器数据、语义线索和时间动力学。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在分析世界模型在自动驾驶中的应用进展，并提出未来的研究挑战，以推进复杂城市环境中自主驾驶解决方案的安全性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个三层次的世界模型分类体系：1) 生成未来的物理世界；2) 智能代理的行为规划；3) 预测与规划之间的交互。此外，还分析了包括自监督学习、多模态预训练和生成数据增强在内的培训范例。&lt;h4&gt;主要发现&lt;/h4&gt;文章强调了在场景理解和运动预测任务中评估世界模型性能的重要性，并指出未来研究需要解决关键挑战如自我监督表示学习、长尾场景生成以及多模态融合，以推动复杂城市环境中的实际部署。&lt;h4&gt;结论&lt;/h4&gt;通过全面分析，本文提供了利用世界模型的变革潜力来推进安全可靠的自主驾驶解决方案的理论框架和技术路线图。&lt;h4&gt;翻译&lt;/h4&gt;最近在自动驾驶方面的突破主要得益于稳健的世界建模技术的进步，这从根本上改变了车辆对动态场景的理解和安全决策执行的方式。研究提出了一种三层次分类体系：1) 生成未来的物理世界；2) 智能代理的行为规划；3) 预测与规划之间的交互。此外还分析了训练范例，包括自监督学习、多模态预训练以及生成数据增强，并评估了在场景理解和运动预测任务中世界模型的性能。未来研究必须解决关键挑战如自我监督表示学习、长尾场景生成及多模态融合来推进复杂城市环境中的实际部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent breakthroughs in autonomous driving have been propelled by advances inrobust world modeling, fundamentally transforming how vehicles interpretdynamic scenes and execute safe decision-making. In particular, world modelshave emerged as a linchpin technology, offering high-fidelity representationsof the driving environment that integrate multi-sensor data, semantic cues, andtemporal dynamics. This paper systematically reviews recent advances in worldmodels for autonomous driving, proposing a three-tiered taxonomy: 1) Generationof Future Physical World, covering image-, BEV-, OG-, and PC-based generationmethods that enhance scene evolution modeling through diffusion models and 4Doccupancy forecasting; 2) Behavior Planning for Intelligent Agents, combiningrule-driven and learning-based paradigms with cost map optimization andreinforcement learning for trajectory generation in complex traffic conditions;3) Interaction Between Prediction and Planning, achieving multi-agentcollaborative decision-making through latent space diffusion andmemory-augmented architectures. The study further analyzes training paradigmsincluding self-supervised learning, multimodal pretraining, and generative dataaugmentation, while evaluating world models' performance in scene understandingand motion prediction tasks. Future research must address key challenges inself-supervised representation learning, long-tail scenario generation, andmultimodal fusion to advance the practical deployment of world models incomplex urban environments. Overall, our comprehensive analysis provides atheoretical framework and technical roadmap for harnessing the transformativepotential of world models in advancing safe and reliable autonomous drivingsolutions.</description>
      <author>example@mail.com (Tuo Feng, Wenguan Wang, Yi Yang)</author>
      <guid isPermaLink="false">2501.11260v2</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model</title>
      <link>http://arxiv.org/abs/2502.10248v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  36 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要要点总结&lt;/h4&gt;{'模型名称': 'Step-Video-T2V', '参数数量': '30B 参数', '视频生成能力': '最多可生成 204 帧的视频', '压缩技术': '设计了深度压缩Variational Autoencoder (Video-VAE)，空间压缩比为16x16，时间压缩比为8倍', '编码方式': '使用两种双语文本编码器处理英语和中文', '去噪方法': '采用DiT（具有3D全注意力机制）进行去噪输入噪声到潜在帧中', '质量改进技术': '应用视频基底DPO (Video-DPO) 方法减少伪影，提高生成视频的视觉质量', '训练策略和观察': '详细描述了训练策略，并分享关键观察结果和见解', '评估基准': '在Step-Video-T2V-Eval上进行性能评估，显示与开源及商业引擎相比具有先进的文本到视频质量', '未来方向': '讨论当前基于扩散模型的范式的局限性并提出未来研究的方向', '可用资源': '在 https://github.com/stepfun-ai/Step-Video-T2V 和 https://yuewen.cn/videos 上提供在线版本'}&lt;h4&gt;翻译&lt;/h4&gt;我们提出了Step-Video-T2V，这是一个拥有30B参数的最先进的文本到视频预训练模型，能够生成最长达到204帧的视频。为了视频生成任务设计了一种深度压缩的Variational Autoencoder (Video-VAE)，实现了16x16的空间和8倍的时间压缩率，并保持了卓越的视频重建质量。用户提示使用两种双语文本编码器进行处理，以支持英语和中文输入。通过流动匹配技术训练了一个具有3D全注意力机制的DiT用于将输入噪声去噪为潜在帧。采用了一种基于视频的DPO方法（Video-DPO）来减少伪影并提高生成视频的视觉质量。我们详细描述了我们的训练策略，并分享了关键观察结果和见解。Step-Video-T2V在一项新颖的视频生成基准测试，即Step-Video-T2V-Eval上进行了性能评估，在与开源及商业引擎比较时展示了先进的文本到视频质量。此外，我们还讨论了当前基于扩散模型范式的局限性，并提出了未来研究的方向。我们将Step-Video-T2V及其评估工具公开在https://github.com/stepfun-ai/Step-Video-T2V上，并且在线版本可以通过 https://yuewen.cn/videos 访问。我们的目标是加速视频基础模型的创新并支持视频内容创作者。&lt;h4&gt;背景&lt;/h4&gt;当前存在对高效、高质量文本到视频转换的需求，尤其是在人工智能和多媒体领域&lt;h4&gt;目的&lt;/h4&gt;开发一个能够生成高品质长视频序列的新一代预训练模型，并探索其在不同应用中的潜力&lt;h4&gt;方法&lt;/h4&gt;利用深度学习技术（包括压缩算法和去噪技术）以及双语支持来提高视频质量及通用性&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Step-Video-T2V, a state-of-the-art text-to-video pre-trained modelwith 30B parameters and the ability to generate videos up to 204 frames inlength. A deep compression Variational Autoencoder, Video-VAE, is designed forvideo generation tasks, achieving 16x16 spatial and 8x temporal compressionratios, while maintaining exceptional video reconstruction quality. Userprompts are encoded using two bilingual text encoders to handle both Englishand Chinese. A DiT with 3D full attention is trained using Flow Matching and isemployed to denoise input noise into latent frames. A video-based DPO approach,Video-DPO, is applied to reduce artifacts and improve the visual quality of thegenerated videos. We also detail our training strategies and share keyobservations and insights. Step-Video-T2V's performance is evaluated on a novelvideo generation benchmark, Step-Video-T2V-Eval, demonstrating itsstate-of-the-art text-to-video quality when compared with both open-source andcommercial engines. Additionally, we discuss the limitations of currentdiffusion-based model paradigm and outline future directions for videofoundation models. We make both Step-Video-T2V and Step-Video-T2V-Evalavailable at https://github.com/stepfun-ai/Step-Video-T2V. The online versioncan be accessed from https://yuewen.cn/videos as well. Our goal is toaccelerate the innovation of video foundation models and empower video contentcreators.</description>
      <author>example@mail.com (Guoqing Ma, Haoyang Huang, Kun Yan, Liangyu Chen, Nan Duan, Shengming Yin, Changyi Wan, Ranchen Ming, Xiaoniu Song, Xing Chen, Yu Zhou, Deshan Sun, Deyu Zhou, Jian Zhou, Kaijun Tan, Kang An, Mei Chen, Wei Ji, Qiling Wu, Wen Sun, Xin Han, Yanan Wei, Zheng Ge, Aojie Li, Bin Wang, Bizhu Huang, Bo Wang, Brian Li, Changxing Miao, Chen Xu, Chenfei Wu, Chenguang Yu, Dapeng Shi, Dingyuan Hu, Enle Liu, Gang Yu, Ge Yang, Guanzhe Huang, Gulin Yan, Haiyang Feng, Hao Nie, Haonan Jia, Hanpeng Hu, Hanqi Chen, Haolong Yan, Heng Wang, Hongcheng Guo, Huilin Xiong, Huixin Xiong, Jiahao Gong, Jianchang Wu, Jiaoren Wu, Jie Wu, Jie Yang, Jiashuai Liu, Jiashuo Li, Jingyang Zhang, Junjing Guo, Junzhe Lin, Kaixiang Li, Lei Liu, Lei Xia, Liang Zhao, Liguo Tan, Liwen Huang, Liying Shi, Ming Li, Mingliang Li, Muhua Cheng, Na Wang, Qiaohui Chen, Qinglin He, Qiuyan Liang, Quan Sun, Ran Sun, Rui Wang, Shaoliang Pang, Shiliang Yang, Sitong Liu, Siqi Liu, Shuli Gao, Tiancheng Cao, Tianyu Wang, Weipeng Ming, Wenqing He, Xu Zhao, Xuelin Zhang, Xianfang Zeng, Xiaojia Liu, Xuan Yang, Yaqi Dai, Yanbo Yu, Yang Li, Yineng Deng, Yingming Wang, Yilei Wang, Yuanwei Lu, Yu Chen, Yu Luo, Yuchu Luo, Yuhe Yin, Yuheng Feng, Yuxiang Yang, Zecheng Tang, Zekai Zhang, Zidong Yang, Binxing Jiao, Jiansheng Chen, Jing Li, Shuchang Zhou, Xiangyu Zhang, Xinhao Zhang, Yibo Zhu, Heung-Yeung Shum, Daxin Jiang)</author>
      <guid isPermaLink="false">2502.10248v2</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Learning Getting-Up Policies for Real-World Humanoid Robots</title>
      <link>http://arxiv.org/abs/2502.12152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://humanoid-getup.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;自动恢复站立是人形机器人可靠部署的一个关键前提。本文开发了一个学习框架来生成控制器，使人形机器人能够在不同地形和摔倒后各种姿态的情况下重新站起来。&lt;h4&gt;背景&lt;/h4&gt;手动设计用于帮助人形机器人从摔倒中恢复的控制器非常困难，因为机器人可能处于多种不同的姿势，并且需要在复杂的地面上工作。&lt;h4&gt;目的&lt;/h4&gt;通过一个学习框架开发能够让人形机器人从复杂情况下站立起来的控制策略。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段的方法来解决这一问题：第一阶段关注发现良好的重新站立轨迹，而第二阶段则将这种运动改进为可以在实际环境中稳定运行的动作。&lt;h4&gt;主要发现&lt;/h4&gt;新的创新使得一个真实的G1人形机器人能够在多种摔倒情况和地形下重新站起来。例如，无论是面部朝上还是面部朝下，机器人都能在平坦的、变形的、滑溜的地面上以及斜坡（如泥泞草地或雪地）中重新站立。&lt;h4&gt;结论&lt;/h4&gt;据我们所知，这是首次成功展示的人形机器人在真实世界环境中学习到的重新站立策略。&lt;h4&gt;翻译&lt;/h4&gt;自动恢复站立是人形机器人可靠部署的一个关键前提。手动设计用于帮助人形机器人从摔倒中恢复的控制器非常困难，因为机器人可能处于多种不同的姿势，并且需要在复杂的地面上工作。本论文开发了一种学习框架来生成控制器，使人形机器人能够在不同地形和摔倒后各种姿态的情况下重新站起来。与之前的人形行走学习成功案例不同的是，站立起来的任务涉及到复杂的接触模式，这需要准确地建模碰撞几何图形并使用更稀疏的奖励。我们通过一个遵循课程大纲的两阶段方法解决了这些挑战：第一阶段关注发现良好的重新站立轨迹，在此阶段不会对平滑度或速度/扭矩限制施加过多约束；第二阶段则将这种运动改进为可以在实际环境中稳定运行的动作，使其能够应对初始配置和地形的变化。实验结果表明，通过这种方法，一个真实的G1人形机器人能够在两种主要情况下重新站立：面部朝上或者面部朝下，并且这两种情况都是在平坦的、变形的、滑溜的地面上以及斜坡（如泥泞草地或雪地）中进行测试。据我们所知，这是首次成功展示的人形机器人在真实世界环境中学习到的重新站立策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic fall recovery is a crucial prerequisite before humanoid robots canbe reliably deployed. Hand-designing controllers for getting up is difficultbecause of the varied configurations a humanoid can end up in after a fall andthe challenging terrains humanoid robots are expected to operate on. This paperdevelops a learning framework to produce controllers that enable humanoidrobots to get up from varying configurations on varying terrains. Unlikeprevious successful applications of humanoid locomotion learning, thegetting-up task involves complex contact patterns, which necessitatesaccurately modeling the collision geometry and sparser rewards. We addressthese challenges through a two-phase approach that follows a curriculum. Thefirst stage focuses on discovering a good getting-up trajectory under minimalconstraints on smoothness or speed / torque limits. The second stage thenrefines the discovered motions into deployable (i.e. smooth and slow) motionsthat are robust to variations in initial configuration and terrains. We findthese innovations enable a real-world G1 humanoid robot to get up from two mainsituations that we considered: a) lying face up and b) lying face down, bothtested on flat, deformable, slippery surfaces and slopes (e.g., sloppy grassand snowfield). To the best of our knowledge, this is the first successfuldemonstration of learned getting-up policies for human-sized humanoid robots inthe real world. Project page: https://humanoid-getup.github.io/</description>
      <author>example@mail.com (Xialin He, Runpei Dong, Zixuan Chen, Saurabh Gupta)</author>
      <guid isPermaLink="false">2502.12152v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A Monocular Event-Camera Motion Capture System</title>
      <link>http://arxiv.org/abs/2502.12113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种基于单目事件相机的运动捕捉系统被开发出来，适用于狭窄空间中的物体跟踪。&lt;h4&gt;背景&lt;/h4&gt;传统的多视角运动捕捉系统依赖于多个摄像头和被动反射标记物来确定对象的位置，这使得它们不适合在狭窄的空间中使用。&lt;h4&gt;目的&lt;/h4&gt;提出一个适合在狭窄空间使用的单目事件相机运动捕捉系统，并克服现有系统的局限性。&lt;h4&gt;方法&lt;/h4&gt;该系统利用主动闪烁的LED标志物（每个标志物通过不同的闪烁频率进行唯一标识），并结合PnP问题解决技术来确定物体的位置和姿态。&lt;h4&gt;主要发现&lt;/h4&gt;开发的系统具有毫米级精度，毫秒级延迟，并且可以用于控制小型、灵活的四旋翼飞行器。&lt;h4&gt;结论&lt;/h4&gt;提出的单目事件相机运动捕捉系统为狭窄空间内的对象跟踪提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;动作捕捉系统在研究中广泛使用以记录物体的真实姿态。商用系统通过在物体上附加反射标记并从多个摄像机视角进行三角定位来确定物体的姿态。因此，该物体必须对多个摄像头可见，这使得多视图运动捕捉系统不适合狭窄、受限空间（例如船舶压载舱）的部署。在这份技术报告中，我们描述了一种单目事件相机动作捕捉系统，它克服了这一限制，并特别适合于狭小的空间使用。代替被动标记物，该系统依赖于主动闪烁的LED标志物，每个标志物通过不同的闪烁频率进行唯一标识。这些标志物被放置在跟踪物体上的已知位置。然后我们解决PnP（透视N点）问题以获得对象的位置和方向。开发的系统的精度为毫米级，延迟为毫秒级，并且我们可以证明其状态估计可以用于飞行小型、敏捷的四旋翼飞行器。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion capture systems are a widespread tool in research to recordground-truth poses of objects. Commercial systems use reflective markersattached to the object and then triangulate pose of the object from multiplecamera views. Consequently, the object must be visible to multiple cameraswhich makes such multi-view motion capture systems unsuited for deployments innarrow, confined spaces (e.g. ballast tanks of ships). In this technical reportwe describe a monocular event-camera motion capture system which overcomes thislimitation and is ideally suited for narrow spaces. Instead of passive markersit relies on active, blinking LED markers such that each marker can be uniquelyidentified from the blinking frequency. The markers are placed at knownlocations on the tracking object. We then solve the PnP (perspective-n-points)problem to obtain the position and orientation of the object. The developedsystem has millimeter accuracy, millisecond latency and we demonstrate that itsstate estimate can be used to fly a small, agile quadrotor.</description>
      <author>example@mail.com (Leonard Bauersfeld, Davide Scaramuzza)</author>
      <guid isPermaLink="false">2502.12113v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Bandwidth-Adaptive Spatiotemporal Correspondence Identification for Collaborative Perception</title>
      <link>http://arxiv.org/abs/2502.12098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了一种新的带宽自适应时空对应识别（CoID）方法，用于解决多机器人协作感知中的通信限制问题。&lt;h4&gt;背景&lt;/h4&gt;在现实世界的应用中，如互联自主驾驶车辆面临由于有限的通信带宽而无法直接共享原始观察数据的问题。这阻碍了多机器人系统在各自视野内一致地引用同一对象的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，该研究提出了一种新的方法来解决协作感知中的带宽适应性时空CoID问题。&lt;h4&gt;方法&lt;/h4&gt;所提出的方案允许机器人逐步选择部分时空观察并与他人共享这些信息，并且能够根据不断变化的通信限制进行调整。&lt;h4&gt;实验结果&lt;/h4&gt;通过连接自主驾驶模拟的各种场景对所提出的方法进行了评估，结果显示该方法能够在动态通信带宽下实现CoID并适应其变化。&lt;h4&gt;性能改进&lt;/h4&gt;与以前的技术相比，该方法在可看见对象检索方面实现了8%-56%的整体改进，并且在数据共享效率上达到了目前最先进的水平。&lt;h4&gt;翻译&lt;/h4&gt;对应识别（CoID）是多机器人协作感知中的关键能力之一，使一组机器人能够在各自的视野内一致地引用相同的目标。为了解决直接共享原始观察结果时面临的带宽限制问题，我们提出了一种新的基于带宽自适应时空CoID的协作感知方法。这种方法允许机器人逐步选择部分时空观察并与他人分享这些信息，并根据动态变化的时间通信约束进行调整。我们在连接自主驾驶模拟中的各种场景下对该方法进行了评估。实验结果显示该方法能够在动态通信带宽下实现CoID并适应其变化，同时在可看见对象检索方面实现了8%-56%的整体改进，在数据共享效率上达到了目前最先进的水平。更多详情请参见：https://gaopeng5.github.io/acoid.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Correspondence identification (CoID) is an essential capability inmulti-robot collaborative perception, which enables a group of robots toconsistently refer to the same objects within their respective fields of view.In real-world applications, such as connected autonomous driving, vehicles facechallenges in directly sharing raw observations due to limited communicationbandwidth. In order to address this challenge, we propose a novel approach forbandwidth-adaptive spatiotemporal CoID in collaborative perception. Thisapproach allows robots to progressively select partial spatiotemporalobservations and share with others, while adapting to communication constraintsthat dynamically change over time. We evaluate our approach across variousscenarios in connected autonomous driving simulations. Experimental resultsvalidate that our approach enables CoID and adapts to dynamic communicationbandwidth changes. In addition, our approach achieves 8%-56% overallimprovements in terms of covisible object retrieval for CoID and data sharingefficiency, which outperforms previous techniques and achieves thestate-of-the-art performance. More information is available at:https://gaopeng5.github.io/acoid.</description>
      <author>example@mail.com (Peng Gao, Williard Joshua Jose, Hao Zhang)</author>
      <guid isPermaLink="false">2502.12098v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Multimodal-LLMs Assisted by Instance Segmentation for Intelligent Traffic Monitoring</title>
      <link>http://arxiv.org/abs/2502.11304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 7 figures, submitted to 30th IEEE International Symposium on  Computers and Communications (ISCC) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一个基于LLaVA多模态大语言模型的交通监控系统，用于在实时Quanser交互实验室平台上模拟城市中的各种交通场景。该系统利用部署于多个位置的摄像头收集数据，并通过LAVA模型进行分析。&lt;h4&gt;背景&lt;/h4&gt;智能城市和ITS需要一套强大的交通监测系统来优化交通流、减少拥堵并提高道路安全。&lt;h4&gt;目的&lt;/h4&gt;研究旨在开发一个既能理解动态的城市条件，又能提供直观用户界面以实现有效管理的交通监控系统。&lt;h4&gt;方法&lt;/h4&gt;使用LLaVA视觉定位多模态大语言模型在实时Quanser交互实验室平台上进行交通监测任务。摄像头捕捉来自模拟场景的真实图像并将其输入到LLaVA模型中进行分析。集成到摄像机中的实例分割模型突出显示关键元素，如车辆和行人。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在识别车辆位置方面准确率达84.3%，确定转向方向的准确性为76.4%，优于传统方法。&lt;h4&gt;结论&lt;/h4&gt;LLaVA多模态大语言模型应用于交通监控任务中显示出卓越的效果。此技术可以进一步优化并推广到实际应用中，提高城市的智能化管理水平。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已提供&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A robust and efficient traffic monitoring system is essential for smartcities and Intelligent Transportation Systems (ITS), using sensors and camerasto track vehicle movements, optimize traffic flow, reduce congestion, enhanceroad safety, and enable real-time adaptive traffic control. Traffic monitoringmodels must comprehensively understand dynamic urban conditions and provide anintuitive user interface for effective management. This research leverages theLLaVA visual grounding multimodal large language model (LLM) for trafficmonitoring tasks on the real-time Quanser Interactive Lab simulation platform,covering scenarios like intersections, congestion, and collisions. Camerasplaced at multiple urban locations collect real-time images from thesimulation, which are fed into the LLaVA model with queries for analysis. Aninstance segmentation model integrated into the cameras highlights key elementssuch as vehicles and pedestrians, enhancing training and throughput. The systemachieves 84.3% accuracy in recognizing vehicle locations and 76.4% indetermining steering direction, outperforming traditional models.</description>
      <author>example@mail.com (Murat Arda Onsu, Poonam Lohan, Burak Kantarci, Aisha Syed, Matthew Andrews, Sean Kennedy)</author>
      <guid isPermaLink="false">2502.11304v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Transparent Object Pose Estimation: A Fusion of GDR-Net and Edge Detection</title>
      <link>http://arxiv.org/abs/2502.12027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at First Austrian Symposium on AI, Robotics, and Vision  (AIROV 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过在物体检测和姿态估计任务中引入边缘检测的预处理步骤，探讨了透明物体的物体姿态估计问题。&lt;h4&gt;背景&lt;/h4&gt;由于光照、背景和反射的影响，机器人视觉领域中的透明物体的姿态估计仍然是一个具有挑战性的课题。&lt;h4&gt;目的&lt;/h4&gt;利用透明物体边缘具有最高对比度的特点，通过实验研究不同边缘检测方法对6D物体姿态估计性能的影响。&lt;h4&gt;方法&lt;/h4&gt;使用GDR-Net进行6D物体姿态估计和YOLOX作为物体检测器，并应用不同的边缘检测预处理步骤（如Canny边缘检测，带或不带颜色信息，以及整体嵌套边缘HED）进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明，在透明对象数据集Trans6D-32 K上使用基于物理渲染的数据集时，采用边缘检测作为预处理可以提高某些物体的性能。&lt;h4&gt;结论&lt;/h4&gt;引入边缘检测作为预处理步骤能够增强特定情况下的物体姿态估计效果。&lt;h4&gt;翻译&lt;/h4&gt;物体姿态估计是机器人视觉领域中的一项挑战性任务，特别是对于透明对象。此研究提出了一种新颖的方法，即在物体识别和姿态估计之前加入边缘检测步骤，来提高性能。实验结果表明这种方法对某些透明物体有显著的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object pose estimation of transparent objects remains a challenging task inthe field of robot vision due to the immense influence of lighting, background,and reflections. However, the edges of clear objects have the highest contrast,which leads to stable and prominent features. We propose a novel approach byincorporating edge detection in a pre-processing step for the tasks of objectdetection and object pose estimation. We conducted experiments to investigatethe effect of edge detectors on transparent objects. We examine the performanceof the state-of-the-art 6D object pose estimation pipeline GDR-Net and theobject detector YOLOX when applying different edge detectors as pre-processingsteps (i.e., Canny edge detection with and without color information, andholistically-nested edges (HED)). We evaluate the physically-based rendereddataset Trans6D-32 K of transparent objects with parameters proposed by the BOPChallenge. Our results indicate that applying edge detection as apre-processing enhances performance for certain objects.</description>
      <author>example@mail.com (Tessa Pulli, Peter Hönig, Stefan Thalhammer, Matthias Hirschmanner, Markus Vincze)</author>
      <guid isPermaLink="false">2502.12027v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Robotic CBCT Meets Robotic Ultrasound</title>
      <link>http://arxiv.org/abs/2502.12019v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种新的临床设置，其中通过预校准和动态共注册的机器人锥形束计算机断层扫描（CBCT）和超声波（US）系统实现了多模态成像。这种设置为无变形组织下的多模态引导程序提供了无需注册的刚性注册，并在验证实验中表现出显著改进。&lt;h4&gt;背景&lt;/h4&gt;传统的影像设备由于灵活性和移动性的限制，难以整合到标准化的工作流程中，这阻碍了全自主干预系统的进步。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新型临床配置，用于提高多模态引导操作效率、准确性和成功率。&lt;h4&gt;方法&lt;/h4&gt;通过一次性预校准两个系统，并利用SAM2算法从B模式图像中分割血管。然后将多普勒图像或分割出的血管掩码映射到CBCT上，以创建一个优化融合后的图像。&lt;h4&gt;主要发现&lt;/h4&gt;在使用含有病变和多个血管的特定设计的仿体进行验证实验后，US和CBCT之间的映射误差平均偏差为1.72±0.62毫米。用户研究显示，CBCT-US融合比传统超声引导的工作流程有显著改进。&lt;h4&gt;结论&lt;/h4&gt;提出的机器人双模态成像系统在针插入指导方面相比传统的手动干预展示了明显的效果提升。&lt;h4&gt;翻译&lt;/h4&gt;多模式影像系统为现代临床实践中安全和精确的介入提供了最佳的融合图像，例如CT-US引导下的穿刺术。但是，当前影像设备的手动性质限制了它们整合到标准化工作流程中的能力，并阻碍向全自主操作系统的进步。本文介绍了一种新的临床设置，其中预先校准并动态共注册的机器人CBCT和超声波系统实现了这种可能性。该设置允许无注册刚性注册，在没有组织变形的情况下进行多模态引导程序。首先执行了两个系统之间的一次性预校准。为了通过在3D CBCT上突出关键血管来确保安全插入路径，SAM2利用B模式图像中的多普勒信号作为自主生成的提示来分割血管。基于共注册，将多普勒图像或分割后的血管掩码映射到CBCT上，创建了一个包含详细信息的最佳融合图像。为了验证该系统，我们使用了一种专门设计的仿体进行测试，该仿体具有肋骨覆盖的病变和多个模拟流动状态下的血管。US与CBCT之间的映射误差导致平均偏差为1.72±0.62毫米。用户研究证明了CBCT-US融合用于针插入指导的有效性，并显示出在时间效率、准确性和成功率方面的显著改进，相较于传统的超声引导工作流程提高了大约50%的性能表现。我们提出了首个专为临床应用设计的机器人双模态成像系统，其结果表明与传统手动干预相比有明显的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The multi-modality imaging system offers optimal fused images for safe andprecise interventions in modern clinical practices, such as computed tomography- ultrasound (CT-US) guidance for needle insertion. However, the limiteddexterity and mobility of current imaging devices hinder their integration intostandardized workflows and the advancement toward fully autonomous interventionsystems. In this paper, we present a novel clinical setup where robotic conebeam computed tomography (CBCT) and robotic US are pre-calibrated anddynamically co-registered, enabling new clinical applications. This setupallows registration-free rigid registration, facilitating multi-modal guidedprocedures in the absence of tissue deformation. First, a one-timepre-calibration is performed between the systems. To ensure a safe insertionpath by highlighting critical vasculature on the 3D CBCT, SAM2 segments vesselsfrom B-mode images, using the Doppler signal as an autonomously generatedprompt. Based on the registration, the Doppler image or segmented vessel masksare then mapped onto the CBCT, creating an optimally fused image withcomprehensive detail. To validate the system, we used a specially designedphantom, featuring lesions covered by ribs and multiple vessels with simulatedmoving flow. The mapping error between US and CBCT resulted in an averagedeviation of 1.72+-0.62 mm. A user study demonstrated the effectiveness ofCBCT-US fusion for needle insertion guidance, showing significant improvementsin time efficiency, accuracy, and success rate. Needle intervention performanceimproved by approximately 50% compared to the conventional US-guided workflow.We present the first robotic dual-modality imaging system designed to guideclinical applications. The results show significant performance improvementscompared to traditional manual interventions.</description>
      <author>example@mail.com (Feng Li, Yuan Bi, Dianye Huang, Zhongliang Jiang, Nassir Navab)</author>
      <guid isPermaLink="false">2502.12019v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>pySLAM: An Open-Source, Modular, and Extensible Framework for SLAM</title>
      <link>http://arxiv.org/abs/2502.11955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;pySLAM是一个开源的Python框架，用于视觉同时定位与地图构建（Visual SLAM），支持单目、立体和RGB-D相机。&lt;h4&gt;背景&lt;/h4&gt;当前的SLAM研究需要一个灵活且适应性强的平台来集成经典和现代局部特征以及深度预测模型等。&lt;h4&gt;目的&lt;/h4&gt;提供一个适用于初学者和资深研究人员的框架，促进视觉SLAM领域的社区合作与开发。&lt;h4&gt;方法&lt;/h4&gt;pySLAM框架包括不同的环路闭合技术、体素重建流水线，并支持多种视觉里程计和SLAM应用工具。&lt;h4&gt;主要发现&lt;/h4&gt;该框架为各种SLAM任务提供了灵活性，能够整合经典和现代局部特征以及深度预测模型。&lt;h4&gt;结论&lt;/h4&gt;通过鼓励社区贡献，pySLAM旨在成为Visual SLAM领域的标准平台之一，促进领域内的创新和发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：pySLAM是一个开源的Python框架，用于视觉同时定位与地图构建（Visual SLAM），支持单目、立体和RGB-D相机。它提供了集成经典和现代局部特征的灵活接口，使其能够适应各种SLAM任务。该框架包括不同的环路闭合方法，体素重建流水线，并支持深度预测模型。此外，它还提供了一系列用于视觉里程计和SLAM应用的工具。pySLAM旨在为初学者和经验丰富的研究人员设计，鼓励社区贡献，在Visual SLAM领域推动协作开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; pySLAM is an open-source Python framework for Visual SLAM, supportingmonocular, stereo, and RGB-D cameras. It provides a flexible interface forintegrating both classical and modern local features, making it adaptable tovarious SLAM tasks. The framework includes different loop closure methods, avolumetric reconstruction pipeline, and support for depth prediction models.Additionally, it offers a suite of tools for visual odometry and SLAMapplications. Designed for both beginners and experienced researchers, pySLAMencourages community contributions, fostering collaborative development in thefield of Visual SLAM.</description>
      <author>example@mail.com (Luigi Freda)</author>
      <guid isPermaLink="false">2502.11955v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>The Dynamic Model of the UR10 Robot and its ROS2 Integration</title>
      <link>http://arxiv.org/abs/2502.11940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures, 6 tables, IEEE Transactions on Industrial  Informatics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于UR10工业机器人的完整动态模型，并采用三级识别方法来估计操作臂的动态系数。&lt;h4&gt;背景&lt;/h4&gt;现有机器人动力学模型可能无法准确预测电流或调整电机增益，特别是在负载变化的情况下。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的动态模型和相应的软件工具，以便更好地用于控制和规划。&lt;h4&gt;方法&lt;/h4&gt;{'线性参数估计': '使用标准的线性回归算法计算', '非线性摩擦参数估计': '基于S形函数模型进行估算', '电机驱动增益设计': '将估计到的关节电流映射为扭矩'}&lt;h4&gt;主要发现&lt;/h4&gt;实验验证表明，该模型在预测电流准确性上比现有最优模型提高了最多4.43倍，并且更精确地调整了电机增益。&lt;h4&gt;结论&lt;/h4&gt;提出的新方法可以有效地提高机器人的动力学性能和控制精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TII.2025.3534415&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents the full dynamic model of the UR10 industrial robot. Atriple-stage identification approach is adopted to estimate the manipulator'sdynamic coefficients. First, linear parameters are computed using a standardlinear regression algorithm. Subsequently, nonlinear friction parameters areestimated according to a sigmoidal model. Lastly, motor drive gains are devisedto map estimated joint currents to torques. The overall identified model can beused for both control and planning purposes, as the accompanied ROS2 softwarecan be easily reconfigured to account for a generic payload. The estimatedrobot model is experimentally validated against a set of exciting trajectoriesand compared to the state-of-the-art model for the same manipulator, achievinghigher current prediction accuracy (up to a factor of 4.43) and more precisemotor gains. The related software is available athttps://codeocean.com/capsule/8515919/tree/v2.</description>
      <author>example@mail.com (Vincenzo Petrone, Enrico Ferrentino, Pasquale Chiacchio)</author>
      <guid isPermaLink="false">2502.11940v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Continual Learning Should Move Beyond Incremental Classification</title>
      <link>http://arxiv.org/abs/2502.11927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文探讨了连续学习（CL）领域在面对超出标准分类任务时的局限性，通过具体案例分析指出当前CL方法在处理多目标分类、机器人技术中的受限输出空间、连续任务域中的学习以及高级概念记忆等问题上的不足。&lt;h4&gt;背景&lt;/h4&gt;连续学习是机器学习的一个子领域，专注于动态环境中知识积累。然而，目前的研究主要集中在增量分类任务上，即模型能够学习新的类别同时保留之前学过的知识。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过分析具体实例来拓宽CL研究的范围，并提出克服当前挑战的具体建议，以加强其理论基础和实际应用性。&lt;h4&gt;方法&lt;/h4&gt;通过对多目标分类、机器人技术中的受限输出空间问题、连续任务域的学习以及高级概念记忆等方面的详细案例分析，识别并讨论了三个根本性的挑战：学习问题的连续性本质（C1）、用于测量相似性的适当空间和度量的选择（C2），以及超出分类之外的学习目标的作用（C3）。&lt;h4&gt;主要发现&lt;/h4&gt;目前CL方法在解决上述提及的具体应用场景时往往表现不佳，表明现有理论和技术框架存在局限。识别了三个核心挑战并提出了相应的建议，如通过分布过程的形式化时间动态、为连续任务空间开发原理性的方法以及引入密度估计和生成目标等。&lt;h4&gt;结论&lt;/h4&gt;本文呼吁扩大CL研究的范围，强调其在解决现实世界问题中的重要性，并指出上述提出的策略可以帮助推进领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到连续学习（CL）是机器学习的一个子领域，处理的是动态环境下的知识积累。至今为止，CL的研究主要集中在增量分类任务上，在这类任务中模型能够学会对新的类别进行分类同时保留已经学到的知识。本文认为这种单一的焦点限制了理论的发展和实用性的应用范围。通过分析具体例子——包括多目标分类、受限输出空间中的机器人技术学习、连续任务域中的学习以及高级概念记忆，展示如何在超出标准分类的情况下，当前的方法经常失效。作者识别出了三个基本挑战：（C1）学习问题的连续性本质；（C2）选择用于测量相似性的适当的空间和度量；（C3）超越分类的学习目标的作用。针对每个挑战，提供了一些具体的建议以推动领域向前发展，包括通过分布过程的形式化时间动态、为连续任务空间开发原理性的方法以及引入密度估计和生成目标。通过这种方式，本文旨在扩大CL研究的范围并加强其理论基础，使其更适用于解决实际问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning (CL) is the sub-field of machine learning concerned withaccumulating knowledge in dynamic environments. So far, CL research has mainlyfocused on incremental classification tasks, where models learn to classify newcategories while retaining knowledge of previously learned ones. Here, we arguethat maintaining such a focus limits both theoretical development and practicalapplicability of CL methods. Through a detailed analysis of concrete examples -including multi-target classification, robotics with constrained output spaces,learning in continuous task domains, and higher-level concept memorization - wedemonstrate how current CL approaches often fail when applied beyond standardclassification. We identify three fundamental challenges: (C1) the nature ofcontinuity in learning problems, (C2) the choice of appropriate spaces andmetrics for measuring similarity, and (C3) the role of learning objectivesbeyond classification. For each challenge, we provide specific recommendationsto help move the field forward, including formalizing temporal dynamics throughdistribution processes, developing principled approaches for continuous taskspaces, and incorporating density estimation and generative objectives. In sodoing, this position paper aims to broaden the scope of CL research whilestrengthening its theoretical foundations, making it more applicable toreal-world problems.</description>
      <author>example@mail.com (Rupert Mitchell, Antonio Alliegro, Raffaello Camoriano, Dustin Carrión-Ojeda, Antonio Carta, Georgia Chalvatzaki, Nikhil Churamani, Carlo D'Eramo, Samin Hamidi, Robin Hesse, Fabian Hinder, Roshni Ramanna Kamath, Vincenzo Lomonaco, Subarnaduti Paul, Francesca Pistilli, Tinne Tuytelaars, Gido M van de Ven, Kristian Kersting, Simone Schaub-Meyer, Martin Mundt)</author>
      <guid isPermaLink="false">2502.11927v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>VLP: Vision-Language Preference Learning for Embodied Manipulation</title>
      <link>http://arxiv.org/abs/2502.11918v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一个新颖的Vision-Language Preference (VLP)框架，旨在解决强化学习中的奖励工程问题。该框架通过构建无标注的视觉-语言偏好数据集来训练偏好模型。&lt;h4&gt;背景&lt;/h4&gt;强化学习中的奖励设计是一项关键挑战，传统的基于偏好的RL方法需要大量的人类反馈标签，这既耗时又昂贵。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需人工注释就可以提供有效反馈的方法，并提高在下游任务中的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;定义了三种语言条件下的偏好类型并构建了一个视觉-语言的无标注数据集。提出了VLP框架，该框架能够从文本描述中提取出相关的特征，为仿真环境中的机器人操作任务生成偏好标签。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在模拟的物理环境中进行的各种机器人抓取和操纵任务上，基于该方法训练出来的策略优于基线模型，并且可以泛化到未见过的任务以及语言指令。&lt;h4&gt;结论&lt;/h4&gt;VLP框架有效地解决了强化学习中奖励设计的问题，为无需人工干预的情况下提供有效的反馈提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;奖励工程是强化学习(RL)中的一个关键挑战。基于偏好的RL通过从人类反馈中学习来有效解决这一问题。然而，收集人类偏好标签既耗时又昂贵。本文提出了一种新颖的Vision-Language Preference (VLP)框架，该框架用于为机器人实体操作任务提供偏好反馈。为了实现这一点，我们定义了三种语言条件下的偏好类型，并构建了一个包含多种隐式偏好顺序而无需人工注释的视觉-语言偏好数据集。偏好模型学习提取与语言相关的特征，然后作为偏好标注器在各种下游任务中使用。策略可以通过奖励学习或直接策略优化根据这些标注偏好数据进行学习。广泛的实验证明了该方法提供了准确的偏好，并且能泛化到未见过的任务和语言指令上，大大优于基线模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reward engineering is one of the key challenges in Reinforcement Learning(RL). Preference-based RL effectively addresses this issue by learning fromhuman feedback. However, it is both time-consuming and expensive to collecthuman preference labels. In this paper, we propose a novel\textbf{V}ision-\textbf{L}anguage \textbf{P}reference learning framework, named\textbf{VLP}, which learns a vision-language preference model to providepreference feedback for embodied manipulation tasks. To achieve this, we definethree types of language-conditioned preferences and construct a vision-languagepreference dataset, which contains versatile implicit preference orders withouthuman annotations. The preference model learns to extract language-relatedfeatures, and then serves as a preference annotator in various downstreamtasks. The policy can be learned according to the annotated preferences viareward learning or direct policy optimization. Extensive empirical results onsimulated embodied manipulation tasks demonstrate that our method providesaccurate preferences and generalizes to unseen tasks and unseen languageinstructions, outperforming the baselines by a large margin.</description>
      <author>example@mail.com (Runze Liu, Chenjia Bai, Jiafei Lyu, Shengjie Sun, Yali Du, Xiu Li)</author>
      <guid isPermaLink="false">2502.11918v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>1 A formal implementation of Behavior Trees to act in robotics</title>
      <link>http://arxiv.org/abs/2502.11904v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了通过将行为树（BT）转换为形式语言来定义其正式语义的方法，以此进行程序验证和运行时验证。&lt;h4&gt;背景&lt;/h4&gt;行为树作为自主机器人系统中的行动组件越来越受欢迎。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法以便于对使用行为树编写的程序进行正式验证，并支持运行时的动态验证。&lt;h4&gt;方法&lt;/h4&gt;采用形式框架Fiacre及其语言、TTS模型，利用Tina进行模型检查以及Hippo进行运行时验证。此外，还展示了将BT自动转换为Fiacre的过程，讨论了离线和在线可以验证的形式化属性（LTL和CTL）。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一个正式的框架来支持行为树程序的正确性验证，并且不需行为树程序员掌握形式语言；同时保留了模块化、灵活性及可重用性的特点。此外，展示了在机器人应用中如何利用Fiacre提供的其他特性（状态变量、时间等）。&lt;h4&gt;结论&lt;/h4&gt;通过这种方式可以使行为树的开发和使用更加高效和可靠，并为未来的研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;将行为树转换为形式语言以进行正式验证的方法，使程序验证更为便捷且不需要程序员掌握复杂的正式语言。这种方法保留了行为树的优点，如模块化、灵活性及重用性，同时也展示了在机器人应用中的实际效果和新特性利用的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Behavior Trees (BT) are becoming quite popular as an Acting component ofautonomous robotic systems. We propose to define a formal semantics to BT bytranslating them to a formal language which enables us to perform verificationof programs written with BT, as well as runtime verification while these BTexecute. This allows us to formally verify BT correctness without requiring BTprogrammers to master formal language and without compromising BT most valuablefeatures: modularity, flexibility and reusability. We present the formalframework we use: Fiacre, its langage and the produced TTS model; Tina, itsmodel checking tools and Hippo, its runtime verification engine. We then showhow the translation from BT to Fiacre is automatically done, the type of formalLTL and CTL properties we can check offline and how to execute the formal modelonline in place of a regular BT engine. We illustrate our approach on tworobotics applications, and show how BT could benefit of other featuresavailable in the Fiacre formal framework (state variables, time, etc).</description>
      <author>example@mail.com (Felix Ingrand)</author>
      <guid isPermaLink="false">2502.11904v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Stonefish: Supporting Machine Learning Research in Marine Robotics</title>
      <link>http://arxiv.org/abs/2502.11887v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as full paper at ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Stonefish仿真器的最新改进，这是一个专为海洋机器人开发和测试设计的开源平台。这些更新包括新增传感器、支持缆绳操作、改进推进器建模、更灵活的水动力学以及增强声纳精度。&lt;h4&gt;背景&lt;/h4&gt;模拟技术在海洋机器人领域极其重要，能够提供一个成本效益高且可控的环境来应对复杂的海底作业条件。&lt;h4&gt;目的&lt;/h4&gt;鉴于真实世界测试中的高昂费用和后勤挑战，开发出可以捕捉海底环境操作条件的仿真器对于研发遥控和自主水下车辆算法至关重要。&lt;h4&gt;方法&lt;/h4&gt;文中概述了Stonefish平台的关键更新，涵盖了额外传感器（事件相机、热像仪、光学流相机）、可见光通信支持、更灵活的水动力学建模以及推进器模拟改进等。&lt;h4&gt;主要发现&lt;/h4&gt;这些开发成果和自动注释工具极大地增强了Stonefish在海洋机器人研究中的作用，特别是在机器学习领域，训练数据收集困难的情况下更为重要。&lt;h4&gt;结论&lt;/h4&gt;通过改善仿真环境，能够更好地支持海洋机器人系统的算法研发和性能测试，提高其在实际操作中的效率与可靠性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文描述了模拟技术如何为开发用于遥控及自主水下车辆的算法提供了成本效益高的测试平台，并重点介绍了Stonefish仿真器的新特性及其对海洋机器人研究尤其是机器学习领域的贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulations are highly valuable in marine robotics, offering a cost-effectiveand controlled environment for testing in the challenging conditions ofunderwater and surface operations. Given the high costs and logisticaldifficulties of real-world trials, simulators capable of capturing theoperational conditions of subsea environments have become key in developing andrefining algorithms for remotely-operated and autonomous underwater vehicles.This paper highlights recent enhancements to the Stonefish simulator, anadvanced open-source platform supporting development and testing of marinerobotics solutions. Key updates include a suite of additional sensors, such asan event-based camera, a thermal camera, and an optical flow camera, as wellas, visual light communication, support for tethered operations, improvedthruster modelling, more flexible hydrodynamics, and enhanced sonar accuracy.These developments and an automated annotation tool significantly bolsterStonefish's role in marine robotics research, especially in the field ofmachine learning, where training data with a known ground truth is hard orimpossible to collect.</description>
      <author>example@mail.com (Michele Grimaldi, Patryk Cieslak, Eduardo Ochoa, Vibhav Bharti, Hayat Rajani, Ignacio Carlucho, Maria Koskinopoulou, Yvan R. Petillot, Nuno Gracias)</author>
      <guid isPermaLink="false">2502.11887v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Does Knowledge About Perceptual Uncertainty Help an Agent in Automated Driving?</title>
      <link>http://arxiv.org/abs/2502.11864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了代理在感知不确定性的环境中的行为表现及其变化，特别是当代理接收到有关当前不确定性信息时的行为调整。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶等现实场景中存在感知不确定性问题，而强化学习算法通常不考虑这些环境的不确定性。目前，关于如何利用感知领域的不确定性来指导目标导向行动的研究很少。&lt;h4&gt;目的&lt;/h4&gt;探究不确定感知对代理行为的影响以及当有关这种不确定性的信息可用时其行为的变化情况。&lt;h4&gt;方法&lt;/h4&gt;通过设定一个代理任务，在该任务中，代理被奖励以最快的速度完成路线驾驶而不与其他道路使用者发生碰撞。实验引入了观察空间中的不确定性，通过扰动给定代理的感知并通知它来执行受控实验。&lt;h4&gt;主要发现&lt;/h4&gt;不准确的观测空间（由感知扰动建模）会导致防御性驾驶行为；当直接将当前不确定性的信息添加到观察空间时，代理会适应特定情况，并总体上更快地完成其任务同时考虑风险。&lt;h4&gt;结论&lt;/h4&gt;利用不确定性信息可以改善自动驾驶等场景中代理的行为表现和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Agents in real-world scenarios like automated driving deal with uncertaintyin their environment, in particular due to perceptual uncertainty. Although,reinforcement learning is dedicated to autonomous decision-making underuncertainty these algorithms are typically not informed about the uncertaintycurrently contained in their environment. On the other hand, uncertaintyestimation for perception itself is typically directly evaluated in theperception domain, e.g., in terms of false positive detection rates orcalibration errors based on camera images. Its use for deciding ongoal-oriented actions remains largely unstudied. In this paper, we investigatehow an agent's behavior is influenced by an uncertain perception and how thisbehavior changes if information about this uncertainty is available. Therefore,we consider a proxy task, where the agent is rewarded for driving a route asfast as possible without colliding with other road users. For controlledexperiments, we introduce uncertainty in the observation space by perturbingthe perception of the given agent while informing the latter. Our experimentsshow that an unreliable observation space modeled by a perturbed perceptionleads to a defensive driving behavior of the agent. Furthermore, when addingthe information about the current uncertainty directly to the observationspace, the agent adapts to the specific situation and in general accomplishesits task faster while, at the same time, accounting for risks.</description>
      <author>example@mail.com (Natalie Grabowsky, Annika Mütze, Joshua Wendland, Nils Jansen, Matthias Rottmann)</author>
      <guid isPermaLink="false">2502.11864v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Bi-invariant Geodesic Regression with Data from the Osteoarthritis Initiative</title>
      <link>http://arxiv.org/abs/2502.11826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at the Information Processing in Medical Imaging (IPMI) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了李群上的测地线回归方法，并提出了一种非度量估计器，该估计器在计算时保留数据的对称性。&lt;h4&gt;背景&lt;/h4&gt;许多现象自然地通过连续变换来表征，例如医学中的形状变化或机器人技术中的连杆系统。为了描述这些数据集的变化性，需要执行李群上的统计方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够尊重李群上对称性的非度量估计器，使其不敏感于参考坐标系统的改变等干扰因素。&lt;h4&gt;方法&lt;/h4&gt;基于黎曼流形上的线性回归发展了一种测地线回归方法。提出了一个利用仿射连接的设置来开发非度量估计器，并设计了一个高效的固定点算法来进行计算。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法能够捕捉到尊重李群中左、右平移对称性的测地线关系，且可以通过自动微分计算得出所需的基本导数表达式。实验结果证明了其有效性和适用性。&lt;h4&gt;结论&lt;/h4&gt;该非度量估计器在实际应用中有很大潜力，尤其是在医学图像分析和机器人技术等领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容已经全部被翻译成中文，并按照要求进行了分点总结&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many phenomena are naturally characterized by measuring continuoustransformations such as shape changes in medicine or articulated systems inrobotics. Modeling the variability in such datasets requires performingstatistics on Lie groups, that is, manifolds carrying an additional groupstructure. As the Lie group captures the symmetries in the data, it isessential from a theoretical and practical perspective to ask for statisticalmethods that respect these symmetries; this way they are insensitive toconfounding effects, e.g., due to the choice of reference coordinate systems.In this work, we investigate geodesic regression -- a generalization of linearregression originally derived for Riemannian manifolds. While Lie groups can beendowed with Riemannian metrics, these are generally incompatible with thegroup structure. We develop a non-metric estimator using an affine connectionsetting. It captures geodesic relationships respecting the symmetries given byleft and right translations. For its computation, we propose an efficient fixedpoint algorithm requiring simple differential expressions that can becalculated through automatic differentiation. We perform experiments on asynthetic example and evaluate our method on an open-access, clinical datasetstudying knee joint configurations under the progression of osteoarthritis.</description>
      <author>example@mail.com (Johannes Schade, Christoph von Tycowicz, Martin Hanik)</author>
      <guid isPermaLink="false">2502.11826v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Residual Learning towards High-fidelity Vehicle Dynamics Modeling with Transformer</title>
      <link>http://arxiv.org/abs/2502.11800v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度神经网络的车辆动力学校正系统，该系统通过修正物理模型的状态残差而非直接估计状态来提高车辆动态预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;长期以来，研究人员致力于准确建模车辆的动力学特性。传统的基于物理学的方法使用数学公式进行建模，但因为简化处理而无法充分描述复杂车辆系统的动力学行为。近年来，基于深度学习的方法通过直接回归车辆动力学特征试图解决这一问题，但在性能和泛化能力方面仍有改进空间。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在提出一种新的方法来提升车辆动态预测的准确性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;作者开发了一种新型的Transformer基的动力残差校正网络DyTR。该网络将状态残差隐式表示为高维查询，并通过与动力学状态特征交互迭代更新估计残差。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的系统在模拟环境中的表现优于传统物理模型。此外，作者的DyTR模型在动态状态残差校正任务中表现出最佳性能，在两个数据集上分别减少了简单3自由度车辆模型的状态预测误差92.3%和59.9%。&lt;h4&gt;结论&lt;/h4&gt;提出的车辆动力学校正系统通过使用深度神经网络修正物理模型的残差，大大降低了学习难度，并提高了估计准确性。这种创新方法为未来的自动驾驶研究提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要：汽车动力学模型是自主驾驶系统的组成部分之一，它描述了车辆状态随时间的变化情况。长期以来，研究人员在准确建模车辆动态方面做出了巨大努力。传统的基于物理学的方法使用数学公式进行车辆动力学建模，但由于简化处理而无法充分描述复杂车辆系统。近年来，基于深度学习的方法通过直接回归车辆动力学解决了这一限制。然而，性能和泛化能力仍然需要进一步改进。在这封信中，我们提出了一种新的方法来解决这些问题，即利用深度神经网络修正物理模型的状态残差而非直接估计状态。这种方法大大降低了网络的学习难度，并提高了对车辆动态的预测准确性。此外，我们开发了一种新型Transformer基的动力学残差校正网络DyTR。该网络将高维查询隐式表示为状态残差，并通过与动力学状态特征交互迭代更新估计残差。在模拟实验中表明，所提出的系统表现优于传统物理模型，而我们的DyTR模型在动态状态残差校正任务中的性能最佳，在两个数据集上分别减少了简单3自由度车辆模型的状态预测误差92.3%和59.9%&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The vehicle dynamics model serves as a vital component of autonomous drivingsystems, as it describes the temporal changes in vehicle state. In a longperiod, researchers have made significant endeavors to accurately model vehicledynamics. Traditional physics-based methods employ mathematical formulae tomodel vehicle dynamics, but they are unable to adequately describe complexvehicle systems due to the simplifications they entail. Recent advancements indeep learning-based methods have addressed this limitation by directlyregressing vehicle dynamics. However, the performance and generalizationcapabilities still require further enhancement. In this letter, we addressthese problems by proposing a vehicle dynamics correction system that leveragesdeep neural networks to correct the state residuals of a physical model insteadof directly estimating the states. This system greatly reduces the difficultyof network learning and thus improves the estimation accuracy of vehicledynamics. Furthermore, we have developed a novel Transformer-based dynamicsresidual correction network, DyTR. This network implicitly represents stateresiduals as high-dimensional queries, and iteratively updates the estimatedresiduals by interacting with dynamics state features. The experiments insimulations demonstrate the proposed system works much better than physicsmodel, and our proposed DyTR model achieves the best performances on dynamicsstate residual correction task, reducing the state prediction errors of asimple 3 DoF vehicle model by an average of 92.3% and 59.9% in two dataset,respectively.</description>
      <author>example@mail.com (Jinyu Miao, Rujun Yan, Bowei Zhang, Tuopu Wen, Kun Jiang, Mengmeng Yang, Jin Huang, Zhihua Zhong, Diange Yang)</author>
      <guid isPermaLink="false">2502.11800v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Deep Neural Networks for Accurate Depth Estimation with Latent Space Features</title>
      <link>http://arxiv.org/abs/2502.11777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文提出了一种新的单目深度估计框架，通过利用深层卷积神经网络中的潜在空间特征来提升单目深度图的精度。&lt;h4&gt;背景&lt;/h4&gt;在室内环境中，准确的3D场景重建对导航和物体处理等任务至关重要。然而，传统的双目摄像头或激光雷达方法成本高昂，相比之下，基于单个RGB摄像头的单目深度估计更为经济且具有发展潜力。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有单目深度估计方法难以精确定义深度边界的问题，本研究旨在开发一种新的框架来改进这一技术。&lt;h4&gt;方法&lt;/h4&gt;该框架采用了一种双编码器-解码器结构，能够实现颜色到深度以及深度之间的转换。同时引入了一种结合潜在损失和梯度损失的新损失函数以进一步提高深度边界和局部特征的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在NYU Depth V2数据集上该方法达到了新的基准水平，并在复杂的室内场景中表现出色，有效地减少了深度模糊性。&lt;h4&gt;结论&lt;/h4&gt;这种方法为人类与机器人交互以及3D场景重建的应用提供了有前景的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/biomimetics9120747&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth estimation plays a pivotal role in advancing human-robot interactions,especially in indoor environments where accurate 3D scene reconstruction isessential for tasks like navigation and object handling. Monocular depthestimation, which relies on a single RGB camera, offers a more affordablesolution compared to traditional methods that use stereo cameras or LiDAR.However, despite recent progress, many monocular approaches struggle withaccurately defining depth boundaries, leading to less precise reconstructions.In response to these challenges, this study introduces a novel depth estimationframework that leverages latent space features within a deep convolutionalneural network to enhance the precision of monocular depth maps. The proposedmodel features dual encoder-decoder architecture, enabling both color-to-depthand depth-to-depth transformations. This structure allows for refined depthestimation through latent space encoding. To further improve the accuracy ofdepth boundaries and local features, a new loss function is introduced. Thisfunction combines latent loss with gradient loss, helping the model maintainthe integrity of depth boundaries. The framework is thoroughly tested using theNYU Depth V2 dataset, where it sets a new benchmark, particularly excelling incomplex indoor scenarios. The results clearly show that this approacheffectively reduces depth ambiguities and blurring, making it a promisingsolution for applications in human-robot interaction and 3D scenereconstruction.</description>
      <author>example@mail.com (Siddiqui Muhammad Yasir, Hyunsik Ahn)</author>
      <guid isPermaLink="false">2502.11777v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Early Detection of Human Handover Intentions in Human-Robot Collaboration: Comparing EEG, Gaze, and Hand Motion</title>
      <link>http://arxiv.org/abs/2502.11752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In submission at Robotics and Autonomous Systems, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文研究了人类在物体交接过程中产生的非运动生理信号是否可以用于识别机器人协作中的人类意图。&lt;h4&gt;背景&lt;/h4&gt;现有的HRC任务主要是通过视觉检测运动轨迹来判断人机交互的意图，但这种方法容易产生延迟或误报，尤其是在动作重叠的情况下。&lt;h4&gt;目的&lt;/h4&gt;研究在物体交接过程中人类非运动生理信号是否可以用于识别手部动作是为物体交接还是其他行动。&lt;h4&gt;方法&lt;/h4&gt;进行了多模式分析，比较了三种数据模态：脑电波（EEG）、视线和手臂运动信号，以区分HRC场景中意图进行物体交接的人类动作与其他动作。&lt;h4&gt;主要发现&lt;/h4&gt;所有三个模态都可以检测到交接的意图，但视线信号在分类意图为交接或非交接动作时是最准确且最早的。&lt;h4&gt;结论&lt;/h4&gt;这是首次系统地开发和测试多个模态下的意向探测器的研究，在相同的实验环境下进行了验证。结果表明，基于多模式生理信号可以有效预测人类进行物体交接的动作意图。&lt;h4&gt;翻译&lt;/h4&gt;人机协作（HRC）依赖于对人类意图的准确及时识别以确保无缝交互。在常见的HRC任务中，从人类到机器人的物体传递已经广泛研究用于规划机器人接物时的行为。然而，在动作重叠的情况下，仅通过视觉检测运动轨迹的方法会导致延迟或误报。本文探讨了非运动生理信号是否可以反映人在交接物体时的意图，并进行了多模式分析比较三种数据模态：脑电波（EEG）、视线和手臂运动信号。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-robot collaboration (HRC) relies on accurate and timely recognition ofhuman intentions to ensure seamless interactions. Among common HRC tasks,human-to-robot object handovers have been studied extensively for planning therobot's actions during object reception, assuming the human intention forobject handover. However, distinguishing handover intentions from other actionshas received limited attention. Most research on handovers has focused onvisually detecting motion trajectories, which often results in delays or falsedetections when trajectories overlap. This paper investigates whether humanintentions for object handovers are reflected in non-movement-basedphysiological signals. We conduct a multimodal analysis comparing three datamodalities: electroencephalogram (EEG), gaze, and hand-motion signals. Ourstudy aims to distinguish between handover-intended human motions andnon-handover motions in an HRC setting, evaluating each modality's performancein predicting and classifying these actions before and after human movementinitiation. We develop and evaluate human intention detectors based on thesemodalities, comparing their accuracy and timing in identifying handoverintentions. To the best of our knowledge, this is the first study tosystematically develop and test intention detectors across multiple modalitieswithin the same experimental context of human-robot handovers. Our analysisreveals that handover intention can be detected from all three modalities.Nevertheless, gaze signals are the earliest as well as the most accurate toclassify the motion as intended for handover or non-handover.</description>
      <author>example@mail.com (Parag Khanna, Nona Rajabi, Sumeyra U. Demir Kanik, Danica Kragic, Mårten Björkman, Christian Smith)</author>
      <guid isPermaLink="false">2502.11752v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>FUNCTO: Function-Centric One-Shot Imitation Learning for Tool Manipulation</title>
      <link>http://arxiv.org/abs/2502.11744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为FUNCTO的新方法，该方法能够在仅通过单个人类演示视频的情况下，使机器人学会并推广使用不同几何形状但功能相同的工具的技能。&lt;h4&gt;背景&lt;/h4&gt;人类能够轻松地将观察到的一项动作技巧应用到支持相同功能的不同物体上。然而现有的一次性模仿学习（OSIL）方法在这种情况下效果不佳，因为它们难以处理具有相似功能但在外形上有很大差异的对象之间的对应关系问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在保持工具功能的同时，有效应对不同几何形状的同功能对象之间变化的新一代OSIL方法。&lt;h4&gt;方法&lt;/h4&gt;FUNCTO通过使用3D功能性关键点表示来建立功能中心的对应关系。该方法被细分为三个阶段：功能性关键点提取、功能中心的对应关系确定和基于功能性关键点的动作规划。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有的模块化OSIL方法和端到端行为克隆方法相比，FUNCTO在处理具有显著几何变化的不同工具时表现更优。&lt;h4&gt;结论&lt;/h4&gt;通过使用3D功能关键点表示来建立对应关系，FUNCTO成功地解决了现有OSIL方法难以应对的问题，并为机器人学习如何灵活应用不同但相似功能的工具提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;从单个人类演示视频中学习工具使用提供了一种直观且高效的机器人教学方式。尽管人类可以轻松将展示过的操作技能推广到支持相同功能的不同工具上，现有的一次性模仿学习方法却难以做到这一点。为了解决这个问题，提出了FUNCTO这一OSIL方法，该方法通过3D功能性关键点表示来建立对应关系，使得机器人能够从单个人类演示视频中推广出对具有相同功能但几何形状不同的新工具的操作技能。此方法分解为三个阶段：功能性关键点提取、基于功能的对应关系确定以及基于功能性关键点的动作规划。在多种工具操作任务上的真实机器人实验结果表明，与现有的模块化OSIL方法和端到端行为克隆方法相比，FUNCTO在处理具有显著几何变化的不同工具时更具优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning tool use from a single human demonstration video offers a highlyintuitive and efficient approach to robot teaching. While humans caneffortlessly generalize a demonstrated tool manipulation skill to diverse toolsthat support the same function (e.g., pouring with a mug versus a teapot),current one-shot imitation learning (OSIL) methods struggle to achieve this. Akey challenge lies in establishing functional correspondences betweendemonstration and test tools, considering significant geometric variationsamong tools with the same function (i.e., intra-function variations). Toaddress this challenge, we propose FUNCTO (Function-Centric OSIL for ToolManipulation), an OSIL method that establishes function-centric correspondenceswith a 3D functional keypoint representation, enabling robots to generalizetool manipulation skills from a single human demonstration video to novel toolswith the same function despite significant intra-function variations. With thisformulation, we factorize FUNCTO into three stages: (1) functional keypointextraction, (2) function-centric correspondence establishment, and (3)functional keypoint-based action planning. We evaluate FUNCTO against exitingmodular OSIL methods and end-to-end behavioral cloning methods throughreal-robot experiments on diverse tool manipulation tasks. The resultsdemonstrate the superiority of FUNCTO when generalizing to novel tools withintra-function geometric variations. More details are available athttps://sites.google.com/view/functo.</description>
      <author>example@mail.com (Chao Tang, Anxing Xiao, Yuhong Deng, Tianrun Hu, Wenlong Dong, Hanbo Zhang, David Hsu, Hong Zhang)</author>
      <guid isPermaLink="false">2502.11744v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Can you pass that tool?: Implications of Indirect Speech in Physical Human-Robot Collaboration</title>
      <link>http://arxiv.org/abs/2502.11720v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CHI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;研究探讨了间接言语行为（ISAs）在人机协作中的作用，表明具备理解ISAs的机器人能够显著提升人类对机器人的拟人化感知、团队表现和信任。然而，这种效果取决于任务和环境的具体情况。&lt;h4&gt;背景&lt;/h4&gt;间接言语行为是人类交流中的一种自然实用特性，允许通过含蓄的方式进行请求，同时保持微妙性和灵活性。尽管语音识别的进步使得机器人能够理解直接明确的命令，但大型语言模型的兴起为机器人理解ISAs提供了可能。&lt;h4&gt;目的&lt;/h4&gt;探讨在人机协作（HRC）中使用间接言语行为的效果，并评估其对合作体验和任务表现的影响。&lt;h4&gt;方法&lt;/h4&gt;通过一项巫师之奥兹实验（N=36），参与者与一个机器人共同完成物理任务，以此研究ISAs的效果。&lt;h4&gt;主要发现&lt;/h4&gt;能够理解ISAs的机器人显著提高了人类感知到的机器人的拟人化、团队绩效和信任。然而，这种效果取决于具体任务和环境的情境特征。&lt;h4&gt;结论&lt;/h4&gt;间接请求的有效性取决于具体的任务与环境背景，在设计人机交互系统时应谨慎使用直接和间接请求。&lt;h4&gt;翻译&lt;/h4&gt;间接言语行为是人类交流中的自然实用特性，允许通过含蓄的方式进行请求。尽管语音识别技术的进步使得机器人能够理解明确的命令，但大型语言模型的发展开启了机器人能理解ISAs的新可能。目前关于HRC中ISAs影响的研究尚不充分。研究者们进行了巫师之奥兹实验（N=36），结果显示具备理解ISAs能力的机器人显著提升了人类对机器人的拟人化感知、团队表现和信任，但这种效果受具体任务和环境的影响，因此需要谨慎使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3713780&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Indirect speech acts (ISAs) are a natural pragmatic feature of humancommunication, allowing requests to be conveyed implicitly while maintainingsubtlety and flexibility. Although advancements in speech recognition haveenabled natural language interactions with robots through direct, explicitcommands--providing clarity in communication--the rise of large language modelspresents the potential for robots to interpret ISAs. However, empiricalevidence on the effects of ISAs on human-robot collaboration (HRC) remainslimited. To address this, we conducted a Wizard-of-Oz study (N=36), engaging aparticipant and a robot in collaborative physical tasks. Our findings indicatethat robots capable of understanding ISAs significantly improve human'sperceived robot anthropomorphism, team performance, and trust. However, theeffectiveness of ISAs is task- and context-dependent, thus requiring carefuluse. These results highlight the importance of appropriately integrating directand indirect requests in HRC to enhance collaborative experiences and taskperformance.</description>
      <author>example@mail.com (Yan Zhang, Tharaka Sachintha Ratnayake, Cherie Sew, Jarrod Knibbe, Jorge Goncalves, Wafa Johal)</author>
      <guid isPermaLink="false">2502.11720v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>An Innovative Brain-Computer Interface Interaction System Based on the Large Language Model</title>
      <link>http://arxiv.org/abs/2502.11659v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages,3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于SSVEP拼写器与大型语言模型接口结合的脑机接口系统，提高了系统的多语言支持、智能化和功能多样性。&lt;h4&gt;背景&lt;/h4&gt;现有的BCI技术在日常应用场景中的广泛应用受到单一功能性、限制性的范式设计、弱化的多语言支持以及较低智能水平的影响。&lt;h4&gt;目的&lt;/h4&gt;通过引入大型语言模型来改进现有BCI的技术性能，提高用户体验并扩展其实际应用范围。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新的BCI系统，该系统结合了SSVEP拼写器和LLM接口，实现自然语言输入并通过动态调用大模型生成SSVEP范式。&lt;h4&gt;主要发现&lt;/h4&gt;提出的系统支持多种任务场景，包括家用电器控制、机器人手臂操作以及无人机管理等，并且可以通过用户的习惯、使用情景和设备特性进行个性化设置。&lt;h4&gt;结论&lt;/h4&gt;结合SSVEP拼写器与大型语言模型的BCI系统克服了当前BCI系统的许多挑战，在功能、智能和支持多语种方面取得了突破。同时，引入LLM提升了用户体验并扩大了BCI技术在现实世界中的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;最近的大规模语言模型（LLMs）的进步为通过用户交互改进脑机接口（BCI）技术提供了一条更有效的路径。然而，由于其单一的功能性、受限的范式设计、弱多语言支持以及较低的智能水平等限制因素的存在，BCI在日常应用中的广泛采用仍然受到阻碍。在这篇文章中，我们提出了一种创新性的BCI系统，该系统将稳定态视觉诱发电位（SSVEP）拼写器与大型语言模型的应用程序接口(API)深度整合起来。这一方法允许通过SSVEP拼写器输入自然语言，并且能够根据用户在不同场景中的控制需求动态调用大规模模型来生成新的SSVEP范式。命令提示、闪烁频率和布局位置都是可调整的，同时该系统支持超过十种不同的语言。此创新技术为用户提供了一系列任务场景的选择，包括家用电器控制、机器人手臂操作以及无人机管理等选项，并且可以依据用户习惯、使用情景及设备特性进行个性化定制。通过将SSVEP拼写器与大型语言模型相结合，所提出的系统解决了当前BCI系统面临的主要挑战，在功能性、智能化和多语种支持方面实现了突破性的进展。同时，引入LLM不仅改善了用户体验，还扩大了BCI技术在现实世界中的潜在应用范围。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large language models (LLMs) provide a more effectivepathway for upgrading brain-computer interface (BCI) technology in terms ofuser interaction. The widespread adoption of BCIs in daily applicationscenarios is still limited by factors such as their single functionality,restricted paradigm design, weak multilingual support, and low levels ofintelligence. In this paper, we propose an innovative BCI system that deeplyintegrates a steady-state visual evoked potential (SSVEP) speller with an LLMapplication programming interface (API). It allows natural language inputthrough the SSVEP speller and dynamically calls large models to generate SSVEPparadigms. The command prompt, blinking frequency, and layout position areadjustable to meet the user's control requirements in various scenarios. Morethan ten languages are compatible with the multilingual support of LLM. Avariety of task scenarios, such as home appliance control, robotic armoperation, and unmanned aerial vehicle (UAV) management are provided. The taskinterfaces of the system can be personalized according to the user's habits,usage scenarios, and equipment characteristics. By combining the SSVEP spellerwith an LLM, the system solves numerous challenges faced by current BCI systemsand makes breakthroughs in functionality, intelligence, and multilingualsupport. The introduction of LLM not only enhances user experience but alsoexpands the potential applications of BCI technology in real-worldenvironments.</description>
      <author>example@mail.com (Jing Jina, Yutao Zhang, Ruitian Xu, Yixin Chen)</author>
      <guid isPermaLink="false">2502.11659v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Object-Centric Image to Video Generation with Language Guidance</title>
      <link>http://arxiv.org/abs/2502.11655v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了TextOCVP，一个基于文本描述指导的图像到视频生成的对象中心模型。&lt;h4&gt;背景&lt;/h4&gt;准确且灵活的世界模型对于自主系统理解环境和预测未来事件至关重要。对象中心模型通过结构化的潜在空间在建模物体动态和交互方面展示了潜力，但往往难以扩展至复杂数据集并结合外部引导，限制了其在机器人技术中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，我们提出了一种新的方法来构建准确且可控制的预测模型。&lt;h4&gt;方法&lt;/h4&gt;TextOCVP将观察到的场景解析成对象表示（称为槽），并且使用文本条件变压器预测器来预测未来物体状态和视频帧。这种模型同时建模物体动态和交互，并结合了文本指导，增强了对预测过程的控制。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过其结构化的潜在空间提供了更精细的过程控制，在与几种图像到视频生成基线相比时表现出色。此外，它展示了结构化对象中心表示提供了更好的可控性和可解释性，有助于精确和易理解的预测。&lt;h4&gt;结论&lt;/h4&gt;TextOCVP不仅能够提供准确且可控制的预测，还能增强模型对复杂环境的理解能力，为机器人技术中的自主系统应用提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;精确而灵活的世界模型对于自主系统的环境理解和未来事件预测至关重要。对象中心模型通过结构化潜在空间展示了建模物体动态和交互方面的潜力，但往往难以扩展至复杂数据集并结合外部引导，限制了其在机器人技术中的应用。为了解决这些局限性，我们提出了一种新的方法TextOCVP——一个基于文本描述指导的图像到视频生成的对象中心模型。该模型将观察场景解析成对象表示（称为槽），并且使用文本条件变压器预测器来预测未来物体状态和视频帧。这种模型同时建模物体动态和交互，并结合了文本引导，增强了对预测过程的控制。通过其结构化的潜在空间提供了更精细的过程控制，在与几种图像到视频生成基线相比时表现出色。此外，它展示了结构化对象中心表示提供了更好的可控性和可解释性，有助于精确和易理解的预测。TextOCVP不仅能够提供准确且可控制的预测，还能增强模型对复杂环境的理解能力，为机器人技术中的自主系统应用提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and flexible world models are crucial for autonomous systems tounderstand their environment and predict future events. Object-centric models,with structured latent spaces, have shown promise in modeling object dynamicsand interactions, but often face challenges in scaling to complex datasets andincorporating external guidance, limiting their applicability in robotics. Toaddress these limitations, we propose TextOCVP, an object-centric model forimage-to-video generation guided by textual descriptions. TextOCVP parses anobserved scene into object representations, called slots, and utilizes atext-conditioned transformer predictor to forecast future object states andvideo frames. Our approach jointly models object dynamics and interactionswhile incorporating textual guidance, thus leading to accurate and controllablepredictions. Our method's structured latent space offers enhanced control overthe prediction process, outperforming several image-to-video generativebaselines. Additionally, we demonstrate that structured object-centricrepresentations provide superior controllability and interpretability,facilitating the modeling of object dynamics and enabling more precise andunderstandable predictions. Videos and code are available athttps://play-slot.github.io/TextOCVP/.</description>
      <author>example@mail.com (Angel Villar-Corrales, Gjergj Plepi, Sven Behnke)</author>
      <guid isPermaLink="false">2502.11655v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Leader and Follower: Interactive Motion Generation under Trajectory Constraints</title>
      <link>http://arxiv.org/abs/2502.11563v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;随着游戏和电影制作的快速发展，从文本生成交互式运动因具有革新内容创作流程的巨大潜力而备受关注。&lt;h4&gt;背景&lt;/h4&gt;在许多实际应用中，需要对虚拟角色的动作范围或轨迹施加严格限制。然而，仅依赖于文本输入的方法面临着捕捉用户意图的重大挑战，特别是在指定所需的轨迹时存在困难。因此，生成的运动通常缺乏真实性和准确性。&lt;h4&gt;目的&lt;/h4&gt;本文旨在开发一种无需重新训练即可为定制化动作生成提供灵活性和适应性的方法。&lt;h4&gt;方法&lt;/h4&gt;基于两人舞蹈中的角色分配概念，本文将复杂运动分解为引导者-跟随者的动态结构，并提出了一种无需训练的方法，该方法整合了步速控制器和动力学同步适配器。通过控制领导者的行为并纠正追随者的动作以与领导者保持一致，框架提升了现有模型生成符合轨迹的动作的能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，所提出的利用轨迹信息更有效的办法，在真实性和准确性方面都优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;这项研究为从文本生成交互式运动提供了新的方向，并展示了一种可以应用于不同类型数据集的灵活、适应性强的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancement of game and film production, generatinginteractive motion from texts has garnered significant attention due to itspotential to revolutionize content creation processes. In many practicalapplications, there is a need to impose strict constraints on the motion rangeor trajectory of virtual characters. However, existing methods that rely solelyon textual input face substantial challenges in accurately capturing the user'sintent, particularly in specifying the desired trajectory. As a result, thegenerated motions often lack plausibility and accuracy. Moreover, existingtrajectory - based methods for customized motion generation rely on retrainingfor single - actor scenarios, which limits flexibility and adaptability todifferent datasets, as well as interactivity in two-actor motions. To generateinteractive motion following specified trajectories, this paper decouplescomplex motion into a Leader - Follower dynamic, inspired by role allocation inpartner dancing. Based on this framework, this paper explores the motion rangerefinement process in interactive motion generation and proposes atraining-free approach, integrating a Pace Controller and a KinematicSynchronization Adapter. The framework enhances the ability of existing modelsto generate motion that adheres to trajectory by controlling the leader'smovement and correcting the follower's motion to align with the leader.Experimental results show that the proposed approach, by better leveragingtrajectory information, outperforms existing methods in both realism andaccuracy.</description>
      <author>example@mail.com (Runqi Wang, Caoyuan Ma, Jian Zhao, Hanrui Xu, Dongfang Sun, Haoyang Chen, Lin Xiong, Zheng Wang, Xuelong Li)</author>
      <guid isPermaLink="false">2502.11563v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Statistical and Deterministic RCS Characterization for ISAC Channel Modeling</title>
      <link>http://arxiv.org/abs/2502.11540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;在这项研究中，我们对在室内工厂环境下25-28GHz频段的各种测试目标的雷达反射截面（RCS）进行了统计分析，旨在为未来无线系统的目标识别和其他传感应用制定参数。我们的分析基于单站和双站配置下的测量数据，在发射器-接收器（T-R）以及目标位置的函数下进行双站角度20°、40°和60°的测试。我们使用精确的3dB波束宽度为10°，在方位角和平面内进行测量。测试目标包括无人驾驶飞机、自主移动机器人和机械臂。我们利用参数统计分布拟合测得的RCS数据。分析表明，对数正态和伽玛分布模型适用于描述不同反射点上的目标运动情况下的RCS。此外，为评估矩形木板在双站配置中的确定性RCS提供了一个框架，并对其广泛应用于室内热点环境进行了探讨。我们还评估了新型的确定性和统计性的RCS模型，这些模型依赖于双站角度、T-R距离（2m-10m）和目标的不同特性。结果表明，一些提出的RCS模型准确地拟合了测得的数据，突出了它们在双站配置中的适用性。&lt;h4&gt;背景&lt;/h4&gt;研究针对未来无线系统的目标识别和其他传感应用，在特定频段内对室内工厂环境下的测试目标的雷达反射截面进行了统计分析。&lt;h4&gt;目的&lt;/h4&gt;制定可用于未来无线系统的参数，这些参数可以用于目标识别及其他类型的传感器应用中。&lt;h4&gt;方法&lt;/h4&gt;使用单站和双站配置在不同发射器-接收器位置和特定角度下进行测量，并利用对数正态分布和伽玛分布来拟合测得的雷达反射截面数据。此外还开发了一个评估矩形木板在双站配置中的确定性RCS框架。&lt;h4&gt;主要发现&lt;/h4&gt;对数正态和伽玛分布有效模拟了测试目标运动时的不同点上的雷达反射截面；提出的某些RCS模型能够很好地拟合测得的数据，尤其适用于双站配置。&lt;h4&gt;结论&lt;/h4&gt;研究提供了一个用于评估矩形木板在室内环境中的双站雷达反射截面的框架，并且提出了有效的RCS统计分布模型和确定性模型。这些结果对理解未来无线通信系统中目标识别的重要性具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we perform a statistical analysis of the radar cross section(RCS) for various test targets in an indoor factory at \(25\)-\(28\) GHz, withthe goal of formulating parameters that may be used for target identificationand other sensing applications for future wireless systems. The analysis isconducted based on measurements in monostatic and bistatic configurations forbistatic angles of \(20^\circ\), \(40^\circ\), and \(60^\circ\), which arefunctions of transmitter-receiver (T-R) and target positions, via accurate\(3\)dB beamwidth of \(10^\circ\) in both azimuth and elevation planes. Thetest targets include unmanned aerial vehicles, an autonomous mobile robot, anda robotic arm. We utilize parametric statistical distributions to fit themeasured RCS data. The analysis reveals that the \textit{lognormal and gammadistributions} are effective in modeling the RCS of the test targets overdifferent reflecting points of the target itself, i.e. when target is inmotion. Additionally, we provide a framework for evaluating the deterministicbistatic RCS of a rectangular sheet of laminated wood, due to its widespreaduse in indoor hotspot environments. Novel deterministic and statistical RCSmodels are evaluated, incorporating dependencies on the bistatic angle, T-Rdistance (\(2\)m -\(10\)m) and the target. The results demonstrate that someproposed RCS models accurately fit the measured data, highlighting theirapplicability in bistatic configurations.</description>
      <author>example@mail.com (Ali Waqar Azim, Ahmad Bazzi, Roberto Bomfin, Nikolaos Giakoumidis, Theodore S. Rappaport, Marwa Chafii)</author>
      <guid isPermaLink="false">2502.11540v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Disentangled Iterative Surface Fitting for Contact-stable Grasp Planning</title>
      <link>http://arxiv.org/abs/2502.11535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 6 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的表面拟合算法，旨在解决现有抓取规划算法忽略接触点稳定性的问题。新方法分为三个步骤：旋转优化以对齐接触法线、平移精炼以改善质心（CoM）对齐和夹爪开口调整来优化接触点分布。&lt;h4&gt;背景&lt;/h4&gt;当前基于表面拟合的抓取规划算法侧重于机械手与物体表面之间的几何对应关系，而忽略了接触稳定性的重要性。这导致了由于接触配置不足而导致的不稳定的抓取情况。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法中的局限性，论文提出了一种新的表面拟合算法，该算法在保持几何兼容性的基础上考虑到了接触点分布的稳定性。&lt;h4&gt;方法&lt;/h4&gt;受人类抓握行为启发，新方法将抓取姿态优化分解为三个步骤：旋转以对齐接触法线、平移以改进质心（CoM）对齐以及调整夹爪开口来优化接触点分布。&lt;h4&gt;主要发现&lt;/h4&gt;通过在YCB数据集的十个物体上进行仿真实验，所提出的方法相比忽视了接触稳定性的传统表面拟合方法，在抓取成功率方面提高了80%。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了考虑接触稳定性对提高抓取成功的有效性，并且证明了分步骤优化策略的有效性。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们解决了基于表面拟合的抓取规划算法的主要局限性，这种算法主要关注夹爪和物体表面之间的几何匹配，而忽略了接触点分布稳定性的考量。这往往导致由于接触配置不足而导致的不稳定抓取情况。为了克服这个限制，我们提出了一种新的表面拟合算法，在保持几何兼容性的同时考虑了接触稳定性。受人类抓握行为启发的方法将抓取姿态优化分解为三个连续步骤：（1）旋转优化以对齐接触法线；（2）平移精炼以改进质心（CoM）对齐；（3）夹爪开口调整以优化接触点分布。我们通过在YCB数据集的十个对象上的模拟验证了我们的方法，展示了比传统忽视接触稳定性的表面拟合方法高出80%的成功抓取率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we address the limitation of surface fitting-based graspplanning algorithm, which primarily focuses on geometric alignment between thegripper and object surface while overlooking the stability of contact pointdistribution, often resulting in unstable grasps due to inadequate contactconfigurations. To overcome this limitation, we propose a novel surface fittingalgorithm that integrates contact stability while preserving geometriccompatibility. Inspired by human grasping behavior, our method disentangles thegrasp pose optimization into three sequential steps: (1) rotation optimizationto align contact normals, (2) translation refinement to improve Center of Mass(CoM) alignment, and (3) gripper aperture adjustment to optimize contact pointdistribution. We validate our approach through simulations on ten YCB datasetobjects, demonstrating an 80% improvement in grasp success over conventionalsurface fitting methods that disregard contact stability. Further details canbe found on our project page:https://tomoya-yamanokuchi.github.io/disf-project-page/.</description>
      <author>example@mail.com (Tomoya Yamanokuchi, Alberto Bacchin, Emilio Olivastri, Takamitsu Matsubara, Emanuele Menegatti)</author>
      <guid isPermaLink="false">2502.11535v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>SurgPose: a Dataset for Articulated Robotic Surgical Tool Pose Estimation and Tracking</title>
      <link>http://arxiv.org/abs/2502.11534v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为SurgPose的数据集，用于视觉外科工具姿态估计和跟踪。该数据集包括不同光照条件下收集的原始视频和关键点注释。&lt;h4&gt;背景&lt;/h4&gt;准确且高效的手术机器人工具姿态估计对于诸如增强现实（AR）等下游应用以及基于学习的自主操作至关重要。然而，在缺乏公开数据的情况下，这仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有数据集的限制并提高手术机器人工具姿态估计的质量，研究人员创建了一个包含实例感知语义关键点和骨架的新数据集SurgPose。&lt;h4&gt;方法&lt;/h4&gt;使用紫外线反应油漆在视频中进行标记，并在不同照明条件下执行相同的轨迹来收集原始视频和关键点注释。该数据集由6类外科器械的约120,000个实例组成，每个实例都标注了7个语义关键点。&lt;h4&gt;主要发现&lt;/h4&gt;SurgPose数据集中包含的数据可用于测试几种基于视觉的方法来进行手术工具跟踪。&lt;h4&gt;结论&lt;/h4&gt;通过发布SurgPose数据集以及展示几个基线方法的有效性，研究工作为未来的研究提供了重要的资源和参考。&lt;h4&gt;翻译&lt;/h4&gt;准确且高效的外科机器人工具姿态估计对于下游应用（例如增强现实(AR)在手术培训中的应用及基于学习的自主操作）具有基础性的意义。尽管人类和动物的姿态估计取得了显著进展，在外科手术机器人领域，由于公开数据的稀缺性，这一问题仍然是一个挑战。达芬奇末端执行器运动学的大绝对误差以及复杂的校准程序使得收集标定后的运动学数据十分昂贵。鉴于这些限制，我们创建了一个名为SurgPose的数据集，用于视觉外科工具姿态估计和跟踪。通过使用在白光下不可见但在紫外线照射下显形的紫外线反应油漆进行标记，我们在不同照明条件下执行相同轨迹以分别获取原始视频和关键点注释。SurgPose数据集中包含大约120,000个手术器械实例（用于训练80,000个，验证40,000个），包括6类。每种工具实例都被标注了7个语义关键点。由于视频以立体成对形式采集，因此可以基于立体匹配深度将二维姿态提升到三维。除了发布数据集之外，我们还测试了几种手术器械跟踪的基线方法来展示SurgPose的有效性。更多细节请访问surgpose.github.io网站。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and efficient surgical robotic tool pose estimation is offundamental significance to downstream applications such as augmented reality(AR) in surgical training and learning-based autonomous manipulation. Whilesignificant advancements have been made in pose estimation for humans andanimals, it is still a challenge in surgical robotics due to the scarcity ofpublished data. The relatively large absolute error of the da Vinci endeffector kinematics and arduous calibration procedure make calibratedkinematics data collection expensive. Driven by this limitation, we collected adataset, dubbed SurgPose, providing instance-aware semantic keypoints andskeletons for visual surgical tool pose estimation and tracking. By markingkeypoints using ultraviolet (UV) reactive paint, which is invisible under whitelight and fluorescent under UV light, we execute the same trajectory underdifferent lighting conditions to collect raw videos and keypoint annotations,respectively. The SurgPose dataset consists of approximately 120k surgicalinstrument instances (80k for training and 40k for validation) of 6 categories.Each instrument instance is labeled with 7 semantic keypoints. Since the videosare collected in stereo pairs, the 2D pose can be lifted to 3D based onstereo-matching depth. In addition to releasing the dataset, we test a fewbaseline approaches to surgical instrument tracking to demonstrate the utilityof SurgPose. More details can be found at surgpose.github.io.</description>
      <author>example@mail.com (Zijian Wu, Adam Schmidt, Randy Moore, Haoying Zhou, Alexandre Banks, Peter Kazanzides, Septimiu E. Salcudean)</author>
      <guid isPermaLink="false">2502.11534v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Anti-Degeneracy Scheme for Lidar SLAM based on Particle Filter in Geometry Feature-Less Environments</title>
      <link>http://arxiv.org/abs/2502.11486v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种基于深度学习的抗退化系统，以解决粒子滤波SLAM在缺乏几何特征场景中的精度问题。&lt;h4&gt;背景&lt;/h4&gt;粒子过滤SLAM方法因高效性被广泛应用于室内环境。然而，在缺少几何特征的环境中，该方法的准确性会大幅下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的抗退化系统来提升粒子过滤SLAM在不具备明显几何特征的环境下的性能和精度。&lt;h4&gt;方法&lt;/h4&gt;{'线性映射设计': '采用尺度不变的线性映射将连续空间坐标转换为离散索引，并通过基于高斯模型的数据增强方法确保模型性能不受粒子数量变化影响。', '退化检测模型开发': '使用残差神经网络和变换器来发展一个能够识别退化的模型，该模型能通过观察粒子分布的特征来判断是否出现退化。', '自适应抗退化策略设计': '在重采样过程中进行融合和扰动操作以提供更加丰富且准确的姿态初始值，并采用分层姿态优化方法结合粗匹配与细匹配，在不同程度的退化下能动态调整优化频率及传感器可信度，提升寻找全局最优位置的能力。'}&lt;h4&gt;主要发现&lt;/h4&gt;通过消融实验验证了模型的有效性、改进图像矩阵法和GPU计算时间上的优势，并且通过模拟实验和真实环境中的测试证明了该抗退化系统在各种场景下的性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的工作已被提交至IEEE发表，其旨在解决几何特征缺乏的环境中SLAM系统的精度问题，并展示了通过深度学习技术可以显著提升粒子滤波算法的表现。&lt;h4&gt;翻译&lt;/h4&gt;基于粒子过滤的定位与地图构建（SLAM）方法由于其高效率被广泛应用于室内场景。然而，在缺少几何特性的情况下，因为约束条件的缺失导致了准确性的严重下降。本文提出了一个基于深度学习的抗退化系统，旨在提高在缺乏明显特征环境中的性能和精度。该系统包括设计尺度不变的线性映射、开发残差神经网络与变换器结合的退化检测模型以及自适应抗退化策略的设计等三个主要部分，并通过实验验证了系统的有效性及优化方法的效果。这项工作已经被提交给IEEE进行发表。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneous localization and mapping (SLAM) based on particle filtering hasbeen extensively employed in indoor scenarios due to its high efficiency.However, in geometry feature-less scenes, the accuracy is severely reduced dueto lack of constraints. In this article, we propose an anti-degeneracy systembased on deep learning. Firstly, we design a scale-invariant linear mapping toconvert coordinates in continuous space into discrete indexes, in which a dataaugmentation method based on Gaussian model is proposed to ensure the modelperformance by effectively mitigating the impact of changes in the number ofparticles on the feature distribution. Secondly, we develop a degeneracydetection model using residual neural networks (ResNet) and transformer whichis able to identify degeneracy by scrutinizing the distribution of the particlepopulation. Thirdly, an adaptive anti-degeneracy strategy is designed, whichfirst performs fusion and perturbation on the resample process to provide richand accurate initial values for the pose optimization, and use a hierarchicalpose optimization combining coarse and fine matching, which is able toadaptively adjust the optimization frequency and the sensor trustworthinessaccording to the degree of degeneracy, in order to enhance the ability ofsearching the global optimal pose. Finally, we demonstrate the optimality ofthe model, as well as the improvement of the image matrix method and GPU on thecomputation time through ablation experiments, and verify the performance ofthe anti-degeneracy system in different scenarios through simulationexperiments and real experiments. This work has been submitted to IEEE forpublication. Copyright may be transferred without notice, after which thisversion may no longer be available.</description>
      <author>example@mail.com (Yanbin Li, Wei Zhang, Zhiguo Zhang, Xiaogang Shi, Ziruo Li, Mingming Zhang, Hongping Xie, Wenzheng Chi)</author>
      <guid isPermaLink="false">2502.11486v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Learning Dexterous Bimanual Catch Skills through Adversarial-Cooperative Heterogeneous-Agent Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.11437v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025 Accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的异构代理强化学习框架，用于学习灵巧的双臂接球技能。&lt;h4&gt;背景&lt;/h4&gt;传统的机器人接球研究主要集中在单手系统上，这种系统的处理能力有限，无法应对大型或复杂的物体。而双臂接球在灵活性和物体处理方面具有巨大潜力，但同时也带来了新的协调与控制挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种使用异构代理强化学习（HARL）框架的方法来解决这些问题，旨在提高机器人在复杂环境中的接球能力。&lt;h4&gt;方法&lt;/h4&gt;引入了一种对抗性奖励机制，其中投掷器和接球器分别作为两个不同的智能体进行互动：投掷器通过调整物体的抛出速度增加挑战难度；而接球器则学习如何协调两只手来接住这些变化条件下的物体。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟环境中使用15种不同物体进行了评估，显示了该方法在处理多样性和复杂性方面具有良好的鲁棒性和灵活性。实验结果表明，与单智能体基线相比，在所有测试条件下均实现了大约2倍的接球奖励提升。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为开发能够处理更大、更复杂的对象提供了可能，并展示了双臂机器人协调技术的新前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经作为中文进行了详细解释。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic catching has traditionally focused on single-handed systems, whichare limited in their ability to handle larger or more complex objects. Incontrast, bimanual catching offers significant potential for improved dexterityand object handling but introduces new challenges in coordination and control.In this paper, we propose a novel framework for learning dexterous bimanualcatching skills using Heterogeneous-Agent Reinforcement Learning (HARL). Ourapproach introduces an adversarial reward scheme, where a throw agent increasesthe difficulty of throws-adjusting speed-while a catch agent learns tocoordinate both hands to catch objects under these evolving conditions. Weevaluate the framework in simulated environments using 15 different objects,demonstrating robustness and versatility in handling diverse objects. Ourmethod achieved approximately a 2x increase in catching reward compared tosingle-agent baselines across 15 diverse objects.</description>
      <author>example@mail.com (Taewoo Kim, Youngwoo Yoon, Jaehong Kim)</author>
      <guid isPermaLink="false">2502.11437v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Verti-Bench: A General and Scalable Off-Road Mobility Benchmark for Vertically Challenging Terrain</title>
      <link>http://arxiv.org/abs/2502.11426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了Verti-Bench，一个专注于极崎岖、垂直挑战性越野环境的移动性能基准。它提供了100个独特的越野环境和1000项不同的导航任务，用于对自主移动机器人的移动系统进行标准化和客观评估。&lt;h4&gt;背景&lt;/h4&gt;近年来，自动驾驶技术在户外非公路环境中部署取得了显著进展，并从模拟和真实世界的实验中获得了令人鼓舞的结果。然而，在评估越野移动性时仍面临巨大挑战，主要是由于车辆平台和地形性质的多样性。&lt;h4&gt;目的&lt;/h4&gt;提出Verti-Bench这一基准工具来解决现有越野环境评价中存在的问题，通过高保真多物理仿真提供标准化和客观的评价。&lt;h4&gt;方法&lt;/h4&gt;通过在极高精度的模拟环境中设置100种不同的越野条件和1000个独特的导航任务来进行评估。这些环境包括各种几何形状、语义信息以及刚性和可变形表面等特性，同时支持不同规模与驱动机制的车辆平台。&lt;h4&gt;主要发现&lt;/h4&gt;使用Verti-Bench对十个越野移动系统进行了基准测试，并基于结果提出了未来的研究方向。&lt;h4&gt;结论&lt;/h4&gt;Verti-Bench不仅为现有的越野自动驾驶研究提供了一个有价值的评估工具，还推动了该领域的进一步发展。&lt;h4&gt;翻译&lt;/h4&gt;近期，在户外非公路环境中的自主移动机器人的部署方面取得了重大进展。从模拟和实际世界实验中获得了令人鼓舞的结果。然而，与在静态数据集上评估越野感知任务不同，评价越野机动性仍然面临着许多挑战，如车辆平台和地形属性的多样性。此外，在进行机动性评估时需要展开不同的车地互动方式，这要求移动系统必须能够与其环境相互作用而不是与预收集的数据集比较。本文中，我们介绍了Verti-Bench，一个专注于极端崎岖、垂直挑战性越野环境的机动性基准工具。它包括100个独特的非公路环境和1000项不同的导航任务，并且包含了数百万种不同类型的地形属性，如各种几何形状与语义信息、刚性和变形表面以及大型自然障碍物，从而在高保真度多物理仿真中提供标准化和客观的评估。Verti-Bench还可扩展到不同规模及驱动机制的各种车辆平台。我们还提供了专家演示数据集、随机探索数据、失败案例（包括翻车和困住的情况）以及一个用于强化学习的gym-like接口。使用Verti-Bench对十个非公路机动系统进行了基准测试，并提出了我们的研究结果，指出了未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancement in off-road autonomy has shown promises in deployingautonomous mobile robots in outdoor off-road environments. Encouraging resultshave been reported from both simulated and real-world experiments. However,unlike evaluating off-road perception tasks on static datasets, benchmarkingoff-road mobility still faces significant challenges due to a variety offactors, including variations in vehicle platforms and terrain properties.Furthermore, different vehicle-terrain interactions need to be unfolded duringmobility evaluation, which requires the mobility systems to interact with theenvironments instead of comparing against a pre-collected dataset. In thispaper, we present Verti-Bench, a mobility benchmark that focuses on extremelyrugged, vertically challenging off-road environments. 100 unique off-roadenvironments and 1000 distinct navigation tasks with millions of off-roadterrain properties, including a variety of geometry and semantics, rigid anddeformable surfaces, and large natural obstacles, provide standardized andobjective evaluation in high-fidelity multi-physics simulation. Verti-Bench isalso scalable to various vehicle platforms with different scales and actuationmechanisms. We also provide datasets from expert demonstration, randomexploration, failure cases (rolling over and getting stuck), as well as agym-like interface for reinforcement learning. We use Verti-Bench to benchmarkten off-road mobility systems, present our findings, and identify futureoff-road mobility research directions.</description>
      <author>example@mail.com (Tong Xu, Chenhui Pan, Madhan B. Rao, Aniket Datar, Anuj Pokhrel, Yuanjie Lu, Xuesu Xiao)</author>
      <guid isPermaLink="false">2502.11426v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    </channel>
</rss>